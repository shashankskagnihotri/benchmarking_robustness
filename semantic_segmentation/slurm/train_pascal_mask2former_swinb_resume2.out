Started at Sat Jun  1 07:36:00 CEST 2024
06/01 07:38:50 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.10.14 (main, Mar 21 2024, 16:24:04) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1341472963
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 4.9.0
    MMEngine: 0.10.4

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1341472963
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

06/01 07:38:51 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16, enable=False)
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
crop_size = (
    512,
    512,
)
custom_imports = dict(allow_failed_imports=False, imports='mmdet.models')
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.10.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.11.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.12.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.13.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.14.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.15.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.16.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.17.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.6.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.7.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.8.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.9.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        512,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False, interval=5000, save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    18,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        attn_drop_rate=0.0,
        depths=[
            2,
            2,
            18,
            2,
        ],
        drop_path_rate=0.3,
        drop_rate=0.0,
        embed_dims=128,
        frozen_stages=-1,
        init_cfg=dict(
            checkpoint=
            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_base_patch4_window12_384_20220317-55b0104a.pth',
            type='Pretrained'),
        mlp_ratio=4,
        num_heads=[
            4,
            8,
            16,
            32,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        pretrain_img_size=384,
        qk_scale=None,
        qkv_bias=True,
        type='SwinTransformer',
        window_size=12,
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            128,
            256,
            512,
            1024,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=21,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 21
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.10.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.11.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.12.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.13.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.14.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.15.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.16.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.17.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.6.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.7.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.8.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.9.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_base_patch4_window12_384_20220317-55b0104a.pth'
resume = True
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        512,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=5000)
train_dataloader = dict(
    batch_size=4,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512'

/pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
06/01 07:39:20 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
/pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/engine/hooks/visualization_hook.py:60: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.
  warnings.warn('The draw is False, it means that the '
06/01 07:39:20 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:decay_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
06/01 07:39:23 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
06/01 07:39:23 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
06/01 07:39:23 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_base_patch4_window12_384_20220317-55b0104a.pth
06/01 07:39:27 - mmengine - INFO - Auto resumed from the latest checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512/iter_145000.pth.
Loads checkpoint by local backend from path: /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512/iter_145000.pth
06/01 07:39:33 - mmengine - INFO - Load checkpoint from /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512/iter_145000.pth
06/01 07:39:33 - mmengine - INFO - resumed epoch: 0, iter: 145000
06/01 07:39:33 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
06/01 07:39:33 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
06/01 07:39:33 - mmengine - INFO - Checkpoints will be saved to /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512.
06/01 07:39:33 - mmengine - WARNING - Advance dataloader 145000 steps to skip data that has already been trained
/pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/miniconda3/envs/py310/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541990/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
06/01 11:33:34 - mmengine - INFO - Iter(train) [145050/160000]  base_lr: 1.1843e-05 lr: 1.1843e-06  eta: 48 days, 14:08:50  time: 0.6375  data_time: 0.0105  memory: 17702  grad_norm: 445.5841  loss: 14.0398  decode.loss_cls: 0.0737  decode.loss_mask: 0.7533  decode.loss_dice: 0.5202  decode.d0.loss_cls: 0.4103  decode.d0.loss_mask: 0.7748  decode.d0.loss_dice: 0.5330  decode.d1.loss_cls: 0.1058  decode.d1.loss_mask: 0.7561  decode.d1.loss_dice: 0.5288  decode.d2.loss_cls: 0.0998  decode.d2.loss_mask: 0.7546  decode.d2.loss_dice: 0.5246  decode.d3.loss_cls: 0.0856  decode.d3.loss_mask: 0.7612  decode.d3.loss_dice: 0.5352  decode.d4.loss_cls: 0.0845  decode.d4.loss_mask: 0.7579  decode.d4.loss_dice: 0.5230  decode.d5.loss_cls: 0.0840  decode.d5.loss_mask: 0.7563  decode.d5.loss_dice: 0.5236  decode.d6.loss_cls: 0.0766  decode.d6.loss_mask: 0.7542  decode.d6.loss_dice: 0.5275  decode.d7.loss_cls: 0.0875  decode.d7.loss_mask: 0.7579  decode.d7.loss_dice: 0.5218  decode.d8.loss_cls: 0.0914  decode.d8.loss_mask: 0.7550  decode.d8.loss_dice: 0.5214
06/01 11:34:06 - mmengine - INFO - Iter(train) [145100/160000]  base_lr: 1.1808e-05 lr: 1.1808e-06  eta: 24 days, 6:27:03  time: 0.6376  data_time: 0.0104  memory: 10506  grad_norm: 455.1822  loss: 14.4524  decode.loss_cls: 0.0718  decode.loss_mask: 0.8014  decode.loss_dice: 0.5295  decode.d0.loss_cls: 0.5496  decode.d0.loss_mask: 0.7958  decode.d0.loss_dice: 0.5165  decode.d1.loss_cls: 0.0672  decode.d1.loss_mask: 0.8254  decode.d1.loss_dice: 0.5144  decode.d2.loss_cls: 0.0616  decode.d2.loss_mask: 0.8261  decode.d2.loss_dice: 0.5127  decode.d3.loss_cls: 0.0710  decode.d3.loss_mask: 0.8035  decode.d3.loss_dice: 0.5193  decode.d4.loss_cls: 0.0678  decode.d4.loss_mask: 0.8090  decode.d4.loss_dice: 0.5158  decode.d5.loss_cls: 0.0722  decode.d5.loss_mask: 0.7965  decode.d5.loss_dice: 0.5214  decode.d6.loss_cls: 0.0683  decode.d6.loss_mask: 0.7950  decode.d6.loss_dice: 0.5282  decode.d7.loss_cls: 0.0872  decode.d7.loss_mask: 0.7997  decode.d7.loss_dice: 0.5155  decode.d8.loss_cls: 0.0768  decode.d8.loss_mask: 0.8098  decode.d8.loss_dice: 0.5233
06/01 11:34:38 - mmengine - INFO - Iter(train) [145150/160000]  base_lr: 1.1772e-05 lr: 1.1772e-06  eta: 16 days, 3:52:33  time: 0.6382  data_time: 0.0106  memory: 10499  grad_norm: 747.6464  loss: 15.9559  decode.loss_cls: 0.1153  decode.loss_mask: 0.8564  decode.loss_dice: 0.5879  decode.d0.loss_cls: 0.4744  decode.d0.loss_mask: 0.8683  decode.d0.loss_dice: 0.5966  decode.d1.loss_cls: 0.0959  decode.d1.loss_mask: 0.8635  decode.d1.loss_dice: 0.5887  decode.d2.loss_cls: 0.1116  decode.d2.loss_mask: 0.8463  decode.d2.loss_dice: 0.5930  decode.d3.loss_cls: 0.1012  decode.d3.loss_mask: 0.8619  decode.d3.loss_dice: 0.5941  decode.d4.loss_cls: 0.0969  decode.d4.loss_mask: 0.8633  decode.d4.loss_dice: 0.6061  decode.d5.loss_cls: 0.0967  decode.d5.loss_mask: 0.8686  decode.d5.loss_dice: 0.5947  decode.d6.loss_cls: 0.0907  decode.d6.loss_mask: 0.8751  decode.d6.loss_dice: 0.6054  decode.d7.loss_cls: 0.0818  decode.d7.loss_mask: 0.8586  decode.d7.loss_dice: 0.5976  decode.d8.loss_cls: 0.1180  decode.d8.loss_mask: 0.8601  decode.d8.loss_dice: 0.5875
06/01 11:35:09 - mmengine - INFO - Iter(train) [145200/160000]  base_lr: 1.1736e-05 lr: 1.1736e-06  eta: 12 days, 2:35:03  time: 0.6391  data_time: 0.0105  memory: 10502  grad_norm: 359.0052  loss: 14.0407  decode.loss_cls: 0.0376  decode.loss_mask: 0.7716  decode.loss_dice: 0.5557  decode.d0.loss_cls: 0.5384  decode.d0.loss_mask: 0.7639  decode.d0.loss_dice: 0.5400  decode.d1.loss_cls: 0.0265  decode.d1.loss_mask: 0.7575  decode.d1.loss_dice: 0.5496  decode.d2.loss_cls: 0.0223  decode.d2.loss_mask: 0.7648  decode.d2.loss_dice: 0.5495  decode.d3.loss_cls: 0.0315  decode.d3.loss_mask: 0.7558  decode.d3.loss_dice: 0.5585  decode.d4.loss_cls: 0.0519  decode.d4.loss_mask: 0.7515  decode.d4.loss_dice: 0.5486  decode.d5.loss_cls: 0.0871  decode.d5.loss_mask: 0.7507  decode.d5.loss_dice: 0.5372  decode.d6.loss_cls: 0.0413  decode.d6.loss_mask: 0.7583  decode.d6.loss_dice: 0.5458  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 0.7549  decode.d7.loss_dice: 0.5480  decode.d8.loss_cls: 0.0930  decode.d8.loss_mask: 0.7493  decode.d8.loss_dice: 0.5401
06/01 11:35:41 - mmengine - INFO - Iter(train) [145250/160000]  base_lr: 1.1701e-05 lr: 1.1701e-06  eta: 9 days, 16:12:21  time: 0.6404  data_time: 0.0106  memory: 10499  grad_norm: 302.1739  loss: 14.1187  decode.loss_cls: 0.0773  decode.loss_mask: 0.7772  decode.loss_dice: 0.5282  decode.d0.loss_cls: 0.4923  decode.d0.loss_mask: 0.7756  decode.d0.loss_dice: 0.5168  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.7760  decode.d1.loss_dice: 0.5082  decode.d2.loss_cls: 0.0807  decode.d2.loss_mask: 0.7771  decode.d2.loss_dice: 0.5071  decode.d3.loss_cls: 0.0795  decode.d3.loss_mask: 0.7746  decode.d3.loss_dice: 0.5033  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 0.7765  decode.d4.loss_dice: 0.5241  decode.d5.loss_cls: 0.0709  decode.d5.loss_mask: 0.7750  decode.d5.loss_dice: 0.5339  decode.d6.loss_cls: 0.0703  decode.d6.loss_mask: 0.7785  decode.d6.loss_dice: 0.5184  decode.d7.loss_cls: 0.0777  decode.d7.loss_mask: 0.7796  decode.d7.loss_dice: 0.5159  decode.d8.loss_cls: 0.0712  decode.d8.loss_mask: 0.7803  decode.d8.loss_dice: 0.5198
06/01 11:36:13 - mmengine - INFO - Iter(train) [145300/160000]  base_lr: 1.1665e-05 lr: 1.1665e-06  eta: 8 days, 1:17:02  time: 0.6388  data_time: 0.0105  memory: 10500  grad_norm: 410.8558  loss: 12.4324  decode.loss_cls: 0.0172  decode.loss_mask: 0.6998  decode.loss_dice: 0.4668  decode.d0.loss_cls: 0.4721  decode.d0.loss_mask: 0.7538  decode.d0.loss_dice: 0.4789  decode.d1.loss_cls: 0.0174  decode.d1.loss_mask: 0.7059  decode.d1.loss_dice: 0.4690  decode.d2.loss_cls: 0.0367  decode.d2.loss_mask: 0.7040  decode.d2.loss_dice: 0.4651  decode.d3.loss_cls: 0.0300  decode.d3.loss_mask: 0.7022  decode.d3.loss_dice: 0.4636  decode.d4.loss_cls: 0.0222  decode.d4.loss_mask: 0.6999  decode.d4.loss_dice: 0.4544  decode.d5.loss_cls: 0.0312  decode.d5.loss_mask: 0.7039  decode.d5.loss_dice: 0.4620  decode.d6.loss_cls: 0.0356  decode.d6.loss_mask: 0.7043  decode.d6.loss_dice: 0.4653  decode.d7.loss_cls: 0.0266  decode.d7.loss_mask: 0.6968  decode.d7.loss_dice: 0.4566  decode.d8.loss_cls: 0.0293  decode.d8.loss_mask: 0.7036  decode.d8.loss_dice: 0.4583
06/01 11:36:45 - mmengine - INFO - Iter(train) [145350/160000]  base_lr: 1.1629e-05 lr: 1.1629e-06  eta: 6 days, 21:28:48  time: 0.6395  data_time: 0.0106  memory: 10513  grad_norm: 294.2966  loss: 11.3409  decode.loss_cls: 0.0346  decode.loss_mask: 0.6273  decode.loss_dice: 0.4171  decode.d0.loss_cls: 0.4855  decode.d0.loss_mask: 0.6174  decode.d0.loss_dice: 0.4435  decode.d1.loss_cls: 0.0413  decode.d1.loss_mask: 0.6387  decode.d1.loss_dice: 0.4335  decode.d2.loss_cls: 0.0369  decode.d2.loss_mask: 0.6311  decode.d2.loss_dice: 0.4180  decode.d3.loss_cls: 0.0387  decode.d3.loss_mask: 0.6271  decode.d3.loss_dice: 0.4240  decode.d4.loss_cls: 0.0435  decode.d4.loss_mask: 0.6275  decode.d4.loss_dice: 0.4230  decode.d5.loss_cls: 0.0372  decode.d5.loss_mask: 0.6231  decode.d5.loss_dice: 0.4226  decode.d6.loss_cls: 0.0358  decode.d6.loss_mask: 0.6255  decode.d6.loss_dice: 0.4151  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.6234  decode.d7.loss_dice: 0.4147  decode.d8.loss_cls: 0.0422  decode.d8.loss_mask: 0.6320  decode.d8.loss_dice: 0.4224
06/01 11:37:17 - mmengine - INFO - Iter(train) [145400/160000]  base_lr: 1.1593e-05 lr: 1.1593e-06  eta: 6 days, 0:37:30  time: 0.6388  data_time: 0.0105  memory: 10506  grad_norm: 200.2314  loss: 12.4705  decode.loss_cls: 0.0419  decode.loss_mask: 0.6698  decode.loss_dice: 0.4799  decode.d0.loss_cls: 0.4735  decode.d0.loss_mask: 0.6770  decode.d0.loss_dice: 0.4718  decode.d1.loss_cls: 0.0825  decode.d1.loss_mask: 0.6734  decode.d1.loss_dice: 0.4734  decode.d2.loss_cls: 0.0730  decode.d2.loss_mask: 0.6674  decode.d2.loss_dice: 0.4686  decode.d3.loss_cls: 0.0466  decode.d3.loss_mask: 0.6748  decode.d3.loss_dice: 0.4812  decode.d4.loss_cls: 0.0505  decode.d4.loss_mask: 0.6774  decode.d4.loss_dice: 0.4815  decode.d5.loss_cls: 0.0467  decode.d5.loss_mask: 0.6701  decode.d5.loss_dice: 0.4743  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.6736  decode.d6.loss_dice: 0.4844  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.6799  decode.d7.loss_dice: 0.4800  decode.d8.loss_cls: 0.0516  decode.d8.loss_mask: 0.6735  decode.d8.loss_dice: 0.4782
06/01 11:37:49 - mmengine - INFO - Iter(train) [145450/160000]  base_lr: 1.1558e-05 lr: 1.1558e-06  eta: 5 days, 8:24:09  time: 0.6408  data_time: 0.0105  memory: 10514  grad_norm: 263.4858  loss: 16.1312  decode.loss_cls: 0.1296  decode.loss_mask: 0.7502  decode.loss_dice: 0.6823  decode.d0.loss_cls: 0.6054  decode.d0.loss_mask: 0.7266  decode.d0.loss_dice: 0.6486  decode.d1.loss_cls: 0.1713  decode.d1.loss_mask: 0.7479  decode.d1.loss_dice: 0.6714  decode.d2.loss_cls: 0.1584  decode.d2.loss_mask: 0.7523  decode.d2.loss_dice: 0.6689  decode.d3.loss_cls: 0.1392  decode.d3.loss_mask: 0.7533  decode.d3.loss_dice: 0.6659  decode.d4.loss_cls: 0.1355  decode.d4.loss_mask: 0.7463  decode.d4.loss_dice: 0.6761  decode.d5.loss_cls: 0.1250  decode.d5.loss_mask: 0.7530  decode.d5.loss_dice: 0.6891  decode.d6.loss_cls: 0.1451  decode.d6.loss_mask: 0.7457  decode.d6.loss_dice: 0.6574  decode.d7.loss_cls: 0.1889  decode.d7.loss_mask: 0.7545  decode.d7.loss_dice: 0.6588  decode.d8.loss_cls: 0.1539  decode.d8.loss_mask: 0.7544  decode.d8.loss_dice: 0.6763
06/01 11:38:22 - mmengine - INFO - Iter(train) [145500/160000]  base_lr: 1.1522e-05 lr: 1.1522e-06  eta: 4 days, 19:25:23  time: 0.6391  data_time: 0.0106  memory: 10511  grad_norm: 432.3822  loss: 18.2346  decode.loss_cls: 0.2190  decode.loss_mask: 0.9236  decode.loss_dice: 0.6024  decode.d0.loss_cls: 0.7880  decode.d0.loss_mask: 0.8807  decode.d0.loss_dice: 0.6369  decode.d1.loss_cls: 0.2262  decode.d1.loss_mask: 0.9483  decode.d1.loss_dice: 0.6243  decode.d2.loss_cls: 0.2718  decode.d2.loss_mask: 0.9316  decode.d2.loss_dice: 0.6326  decode.d3.loss_cls: 0.1896  decode.d3.loss_mask: 0.9114  decode.d3.loss_dice: 0.6543  decode.d4.loss_cls: 0.1822  decode.d4.loss_mask: 0.9589  decode.d4.loss_dice: 0.6409  decode.d5.loss_cls: 0.2176  decode.d5.loss_mask: 0.9262  decode.d5.loss_dice: 0.6206  decode.d6.loss_cls: 0.2543  decode.d6.loss_mask: 0.8835  decode.d6.loss_dice: 0.6187  decode.d7.loss_cls: 0.2333  decode.d7.loss_mask: 0.9271  decode.d7.loss_dice: 0.5922  decode.d8.loss_cls: 0.2198  decode.d8.loss_mask: 0.9169  decode.d8.loss_dice: 0.6021
06/01 11:38:54 - mmengine - INFO - Iter(train) [145550/160000]  base_lr: 1.1486e-05 lr: 1.1486e-06  eta: 4 days, 8:48:07  time: 0.6401  data_time: 0.0105  memory: 10506  grad_norm: 407.8200  loss: 16.8999  decode.loss_cls: 0.2642  decode.loss_mask: 0.7922  decode.loss_dice: 0.6211  decode.d0.loss_cls: 0.6974  decode.d0.loss_mask: 0.7991  decode.d0.loss_dice: 0.6200  decode.d1.loss_cls: 0.2201  decode.d1.loss_mask: 0.7962  decode.d1.loss_dice: 0.6029  decode.d2.loss_cls: 0.2004  decode.d2.loss_mask: 0.8203  decode.d2.loss_dice: 0.6168  decode.d3.loss_cls: 0.2375  decode.d3.loss_mask: 0.7979  decode.d3.loss_dice: 0.5967  decode.d4.loss_cls: 0.2182  decode.d4.loss_mask: 0.7825  decode.d4.loss_dice: 0.5808  decode.d5.loss_cls: 0.1914  decode.d5.loss_mask: 0.8494  decode.d5.loss_dice: 0.6080  decode.d6.loss_cls: 0.2607  decode.d6.loss_mask: 0.7970  decode.d6.loss_dice: 0.6112  decode.d7.loss_cls: 0.2669  decode.d7.loss_mask: 0.7892  decode.d7.loss_dice: 0.6048  decode.d8.loss_cls: 0.2511  decode.d8.loss_mask: 0.8040  decode.d8.loss_dice: 0.6017
06/01 11:39:26 - mmengine - INFO - Iter(train) [145600/160000]  base_lr: 1.1450e-05 lr: 1.1450e-06  eta: 3 days, 23:56:58  time: 0.6417  data_time: 0.0106  memory: 10506  grad_norm: 891.4710  loss: 16.3535  decode.loss_cls: 0.0749  decode.loss_mask: 0.8812  decode.loss_dice: 0.6335  decode.d0.loss_cls: 0.4980  decode.d0.loss_mask: 0.8737  decode.d0.loss_dice: 0.6278  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.8769  decode.d1.loss_dice: 0.6337  decode.d2.loss_cls: 0.1034  decode.d2.loss_mask: 0.8924  decode.d2.loss_dice: 0.6238  decode.d3.loss_cls: 0.0783  decode.d3.loss_mask: 0.8780  decode.d3.loss_dice: 0.6355  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 0.8697  decode.d4.loss_dice: 0.6210  decode.d5.loss_cls: 0.0983  decode.d5.loss_mask: 0.8707  decode.d5.loss_dice: 0.6176  decode.d6.loss_cls: 0.1136  decode.d6.loss_mask: 0.8791  decode.d6.loss_dice: 0.6187  decode.d7.loss_cls: 0.0913  decode.d7.loss_mask: 0.8844  decode.d7.loss_dice: 0.6303  decode.d8.loss_cls: 0.0764  decode.d8.loss_mask: 0.8769  decode.d8.loss_dice: 0.6317
06/01 11:39:58 - mmengine - INFO - Iter(train) [145650/160000]  base_lr: 1.1415e-05 lr: 1.1415e-06  eta: 3 days, 16:27:26  time: 0.6394  data_time: 0.0106  memory: 10500  grad_norm: 212.8416  loss: 15.5824  decode.loss_cls: 0.0403  decode.loss_mask: 0.9124  decode.loss_dice: 0.5614  decode.d0.loss_cls: 0.5309  decode.d0.loss_mask: 0.8869  decode.d0.loss_dice: 0.5438  decode.d1.loss_cls: 0.0466  decode.d1.loss_mask: 0.9092  decode.d1.loss_dice: 0.5628  decode.d2.loss_cls: 0.0458  decode.d2.loss_mask: 0.9111  decode.d2.loss_dice: 0.5517  decode.d3.loss_cls: 0.0385  decode.d3.loss_mask: 0.9161  decode.d3.loss_dice: 0.5614  decode.d4.loss_cls: 0.0470  decode.d4.loss_mask: 0.9138  decode.d4.loss_dice: 0.5542  decode.d5.loss_cls: 0.0514  decode.d5.loss_mask: 0.9077  decode.d5.loss_dice: 0.5508  decode.d6.loss_cls: 0.0530  decode.d6.loss_mask: 0.9054  decode.d6.loss_dice: 0.5524  decode.d7.loss_cls: 0.0415  decode.d7.loss_mask: 0.9080  decode.d7.loss_dice: 0.5618  decode.d8.loss_cls: 0.0439  decode.d8.loss_mask: 0.9092  decode.d8.loss_dice: 0.5632
06/01 11:40:30 - mmengine - INFO - Iter(train) [145700/160000]  base_lr: 1.1379e-05 lr: 1.1379e-06  eta: 3 days, 10:02:03  time: 0.6394  data_time: 0.0105  memory: 10500  grad_norm: 256.0789  loss: 13.0692  decode.loss_cls: 0.0340  decode.loss_mask: 0.7596  decode.loss_dice: 0.4676  decode.d0.loss_cls: 0.4247  decode.d0.loss_mask: 0.7706  decode.d0.loss_dice: 0.4844  decode.d1.loss_cls: 0.0357  decode.d1.loss_mask: 0.7639  decode.d1.loss_dice: 0.4745  decode.d2.loss_cls: 0.0351  decode.d2.loss_mask: 0.7574  decode.d2.loss_dice: 0.4661  decode.d3.loss_cls: 0.0292  decode.d3.loss_mask: 0.7606  decode.d3.loss_dice: 0.4711  decode.d4.loss_cls: 0.0343  decode.d4.loss_mask: 0.7584  decode.d4.loss_dice: 0.4692  decode.d5.loss_cls: 0.0369  decode.d5.loss_mask: 0.7613  decode.d5.loss_dice: 0.4710  decode.d6.loss_cls: 0.0288  decode.d6.loss_mask: 0.7645  decode.d6.loss_dice: 0.4774  decode.d7.loss_cls: 0.0324  decode.d7.loss_mask: 0.7630  decode.d7.loss_dice: 0.4695  decode.d8.loss_cls: 0.0356  decode.d8.loss_mask: 0.7637  decode.d8.loss_dice: 0.4687
06/01 11:41:02 - mmengine - INFO - Iter(train) [145750/160000]  base_lr: 1.1343e-05 lr: 1.1343e-06  eta: 3 days, 4:28:00  time: 0.6404  data_time: 0.0106  memory: 10508  grad_norm: 368.5395  loss: 12.1707  decode.loss_cls: 0.0129  decode.loss_mask: 0.6515  decode.loss_dice: 0.5003  decode.d0.loss_cls: 0.3976  decode.d0.loss_mask: 0.6513  decode.d0.loss_dice: 0.5002  decode.d1.loss_cls: 0.0568  decode.d1.loss_mask: 0.6560  decode.d1.loss_dice: 0.4935  decode.d2.loss_cls: 0.0341  decode.d2.loss_mask: 0.6504  decode.d2.loss_dice: 0.5033  decode.d3.loss_cls: 0.0130  decode.d3.loss_mask: 0.6551  decode.d3.loss_dice: 0.5077  decode.d4.loss_cls: 0.0154  decode.d4.loss_mask: 0.6568  decode.d4.loss_dice: 0.5147  decode.d5.loss_cls: 0.0134  decode.d5.loss_mask: 0.6533  decode.d5.loss_dice: 0.5028  decode.d6.loss_cls: 0.0131  decode.d6.loss_mask: 0.6571  decode.d6.loss_dice: 0.5104  decode.d7.loss_cls: 0.0153  decode.d7.loss_mask: 0.6572  decode.d7.loss_dice: 0.5016  decode.d8.loss_cls: 0.0128  decode.d8.loss_mask: 0.6570  decode.d8.loss_dice: 0.5060
06/01 11:41:34 - mmengine - INFO - Iter(train) [145800/160000]  base_lr: 1.1307e-05 lr: 1.1307e-06  eta: 2 days, 23:35:36  time: 0.6392  data_time: 0.0105  memory: 10515  grad_norm: 337.6234  loss: 14.6939  decode.loss_cls: 0.0650  decode.loss_mask: 0.7804  decode.loss_dice: 0.5894  decode.d0.loss_cls: 0.4610  decode.d0.loss_mask: 0.7663  decode.d0.loss_dice: 0.5927  decode.d1.loss_cls: 0.0676  decode.d1.loss_mask: 0.7820  decode.d1.loss_dice: 0.6053  decode.d2.loss_cls: 0.0677  decode.d2.loss_mask: 0.7775  decode.d2.loss_dice: 0.5809  decode.d3.loss_cls: 0.0646  decode.d3.loss_mask: 0.7794  decode.d3.loss_dice: 0.5853  decode.d4.loss_cls: 0.0718  decode.d4.loss_mask: 0.7776  decode.d4.loss_dice: 0.5790  decode.d5.loss_cls: 0.0676  decode.d5.loss_mask: 0.7753  decode.d5.loss_dice: 0.5854  decode.d6.loss_cls: 0.0745  decode.d6.loss_mask: 0.7712  decode.d6.loss_dice: 0.5784  decode.d7.loss_cls: 0.0617  decode.d7.loss_mask: 0.7718  decode.d7.loss_dice: 0.5796  decode.d8.loss_cls: 0.0690  decode.d8.loss_mask: 0.7783  decode.d8.loss_dice: 0.5875
06/01 11:42:06 - mmengine - INFO - Iter(train) [145850/160000]  base_lr: 1.1271e-05 lr: 1.1271e-06  eta: 2 days, 19:17:34  time: 0.6399  data_time: 0.0105  memory: 10506  grad_norm: 335.4026  loss: 14.4701  decode.loss_cls: 0.0595  decode.loss_mask: 0.7802  decode.loss_dice: 0.5696  decode.d0.loss_cls: 0.6094  decode.d0.loss_mask: 0.7283  decode.d0.loss_dice: 0.5437  decode.d1.loss_cls: 0.0976  decode.d1.loss_mask: 0.7700  decode.d1.loss_dice: 0.5525  decode.d2.loss_cls: 0.0816  decode.d2.loss_mask: 0.7657  decode.d2.loss_dice: 0.5620  decode.d3.loss_cls: 0.0764  decode.d3.loss_mask: 0.7533  decode.d3.loss_dice: 0.5565  decode.d4.loss_cls: 0.0770  decode.d4.loss_mask: 0.7667  decode.d4.loss_dice: 0.5616  decode.d5.loss_cls: 0.0685  decode.d5.loss_mask: 0.7626  decode.d5.loss_dice: 0.5618  decode.d6.loss_cls: 0.0680  decode.d6.loss_mask: 0.7562  decode.d6.loss_dice: 0.5545  decode.d7.loss_cls: 0.0837  decode.d7.loss_mask: 0.7565  decode.d7.loss_dice: 0.5573  decode.d8.loss_cls: 0.0666  decode.d8.loss_mask: 0.7650  decode.d8.loss_dice: 0.5578
06/01 11:42:38 - mmengine - INFO - Iter(train) [145900/160000]  base_lr: 1.1235e-05 lr: 1.1235e-06  eta: 2 days, 15:28:08  time: 0.6406  data_time: 0.0106  memory: 10518  grad_norm: 442.9983  loss: 17.3357  decode.loss_cls: 0.2118  decode.loss_mask: 0.8271  decode.loss_dice: 0.6618  decode.d0.loss_cls: 0.6848  decode.d0.loss_mask: 0.7862  decode.d0.loss_dice: 0.6416  decode.d1.loss_cls: 0.2419  decode.d1.loss_mask: 0.8133  decode.d1.loss_dice: 0.6499  decode.d2.loss_cls: 0.2059  decode.d2.loss_mask: 0.8256  decode.d2.loss_dice: 0.6597  decode.d3.loss_cls: 0.2389  decode.d3.loss_mask: 0.8211  decode.d3.loss_dice: 0.6669  decode.d4.loss_cls: 0.2155  decode.d4.loss_mask: 0.8170  decode.d4.loss_dice: 0.6575  decode.d5.loss_cls: 0.1830  decode.d5.loss_mask: 0.8425  decode.d5.loss_dice: 0.6614  decode.d6.loss_cls: 0.2115  decode.d6.loss_mask: 0.8154  decode.d6.loss_dice: 0.6632  decode.d7.loss_cls: 0.2075  decode.d7.loss_mask: 0.8276  decode.d7.loss_dice: 0.6439  decode.d8.loss_cls: 0.1687  decode.d8.loss_mask: 0.8252  decode.d8.loss_dice: 0.6592
06/01 11:43:10 - mmengine - INFO - Iter(train) [145950/160000]  base_lr: 1.1200e-05 lr: 1.1200e-06  eta: 2 days, 12:02:48  time: 0.6396  data_time: 0.0105  memory: 10518  grad_norm: 449.9716  loss: 17.5569  decode.loss_cls: 0.1322  decode.loss_mask: 0.8988  decode.loss_dice: 0.6668  decode.d0.loss_cls: 0.7019  decode.d0.loss_mask: 0.8430  decode.d0.loss_dice: 0.6751  decode.d1.loss_cls: 0.1534  decode.d1.loss_mask: 0.9056  decode.d1.loss_dice: 0.6535  decode.d2.loss_cls: 0.1639  decode.d2.loss_mask: 0.9049  decode.d2.loss_dice: 0.6534  decode.d3.loss_cls: 0.1339  decode.d3.loss_mask: 0.8815  decode.d3.loss_dice: 0.6501  decode.d4.loss_cls: 0.1688  decode.d4.loss_mask: 0.8781  decode.d4.loss_dice: 0.6572  decode.d5.loss_cls: 0.1819  decode.d5.loss_mask: 0.8747  decode.d5.loss_dice: 0.6652  decode.d6.loss_cls: 0.1289  decode.d6.loss_mask: 0.8932  decode.d6.loss_dice: 0.6599  decode.d7.loss_cls: 0.1721  decode.d7.loss_mask: 0.8879  decode.d7.loss_dice: 0.6538  decode.d8.loss_cls: 0.1447  decode.d8.loss_mask: 0.8964  decode.d8.loss_dice: 0.6759
06/01 11:43:42 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 11:43:42 - mmengine - INFO - Iter(train) [146000/160000]  base_lr: 1.1164e-05 lr: 1.1164e-06  eta: 2 days, 8:57:57  time: 0.6394  data_time: 0.0105  memory: 10518  grad_norm: 323.9593  loss: 10.7830  decode.loss_cls: 0.0326  decode.loss_mask: 0.5804  decode.loss_dice: 0.4341  decode.d0.loss_cls: 0.4232  decode.d0.loss_mask: 0.5620  decode.d0.loss_dice: 0.4180  decode.d1.loss_cls: 0.0194  decode.d1.loss_mask: 0.5787  decode.d1.loss_dice: 0.4373  decode.d2.loss_cls: 0.0138  decode.d2.loss_mask: 0.5892  decode.d2.loss_dice: 0.4433  decode.d3.loss_cls: 0.0325  decode.d3.loss_mask: 0.5787  decode.d3.loss_dice: 0.4282  decode.d4.loss_cls: 0.0167  decode.d4.loss_mask: 0.5834  decode.d4.loss_dice: 0.4414  decode.d5.loss_cls: 0.0170  decode.d5.loss_mask: 0.5822  decode.d5.loss_dice: 0.4403  decode.d6.loss_cls: 0.0197  decode.d6.loss_mask: 0.5846  decode.d6.loss_dice: 0.4427  decode.d7.loss_cls: 0.0196  decode.d7.loss_mask: 0.5860  decode.d7.loss_dice: 0.4402  decode.d8.loss_cls: 0.0192  decode.d8.loss_mask: 0.5800  decode.d8.loss_dice: 0.4386
06/01 11:44:14 - mmengine - INFO - Iter(train) [146050/160000]  base_lr: 1.1128e-05 lr: 1.1128e-06  eta: 2 days, 6:10:39  time: 0.6395  data_time: 0.0113  memory: 10500  grad_norm: 229.9223  loss: 11.3618  decode.loss_cls: 0.0337  decode.loss_mask: 0.6239  decode.loss_dice: 0.4411  decode.d0.loss_cls: 0.4029  decode.d0.loss_mask: 0.6235  decode.d0.loss_dice: 0.4538  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.6217  decode.d1.loss_dice: 0.4465  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.6245  decode.d2.loss_dice: 0.4323  decode.d3.loss_cls: 0.0498  decode.d3.loss_mask: 0.6114  decode.d3.loss_dice: 0.4181  decode.d4.loss_cls: 0.0537  decode.d4.loss_mask: 0.6166  decode.d4.loss_dice: 0.4302  decode.d5.loss_cls: 0.0341  decode.d5.loss_mask: 0.6181  decode.d5.loss_dice: 0.4326  decode.d6.loss_cls: 0.0351  decode.d6.loss_mask: 0.6166  decode.d6.loss_dice: 0.4314  decode.d7.loss_cls: 0.0440  decode.d7.loss_mask: 0.6247  decode.d7.loss_dice: 0.4413  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 0.6188  decode.d8.loss_dice: 0.4267
06/01 11:44:46 - mmengine - INFO - Iter(train) [146100/160000]  base_lr: 1.1092e-05 lr: 1.1092e-06  eta: 2 days, 3:38:30  time: 0.6396  data_time: 0.0105  memory: 10506  grad_norm: 272.8191  loss: 12.4650  decode.loss_cls: 0.0453  decode.loss_mask: 0.6728  decode.loss_dice: 0.4755  decode.d0.loss_cls: 0.4473  decode.d0.loss_mask: 0.6647  decode.d0.loss_dice: 0.4680  decode.d1.loss_cls: 0.0621  decode.d1.loss_mask: 0.6811  decode.d1.loss_dice: 0.5057  decode.d2.loss_cls: 0.0624  decode.d2.loss_mask: 0.6720  decode.d2.loss_dice: 0.4748  decode.d3.loss_cls: 0.0614  decode.d3.loss_mask: 0.6731  decode.d3.loss_dice: 0.4758  decode.d4.loss_cls: 0.0571  decode.d4.loss_mask: 0.6733  decode.d4.loss_dice: 0.4752  decode.d5.loss_cls: 0.0619  decode.d5.loss_mask: 0.6720  decode.d5.loss_dice: 0.4746  decode.d6.loss_cls: 0.0653  decode.d6.loss_mask: 0.6697  decode.d6.loss_dice: 0.4687  decode.d7.loss_cls: 0.0499  decode.d7.loss_mask: 0.6734  decode.d7.loss_dice: 0.4840  decode.d8.loss_cls: 0.0627  decode.d8.loss_mask: 0.6692  decode.d8.loss_dice: 0.4662
06/01 11:45:18 - mmengine - INFO - Iter(train) [146150/160000]  base_lr: 1.1056e-05 lr: 1.1056e-06  eta: 2 days, 1:19:33  time: 0.6388  data_time: 0.0105  memory: 10498  grad_norm: 315.8868  loss: 13.6638  decode.loss_cls: 0.0301  decode.loss_mask: 0.7665  decode.loss_dice: 0.5208  decode.d0.loss_cls: 0.4111  decode.d0.loss_mask: 0.7830  decode.d0.loss_dice: 0.5139  decode.d1.loss_cls: 0.0531  decode.d1.loss_mask: 0.7777  decode.d1.loss_dice: 0.5172  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.7712  decode.d2.loss_dice: 0.5131  decode.d3.loss_cls: 0.0460  decode.d3.loss_mask: 0.7644  decode.d3.loss_dice: 0.5058  decode.d4.loss_cls: 0.0413  decode.d4.loss_mask: 0.7694  decode.d4.loss_dice: 0.5169  decode.d5.loss_cls: 0.0348  decode.d5.loss_mask: 0.7732  decode.d5.loss_dice: 0.5185  decode.d6.loss_cls: 0.0369  decode.d6.loss_mask: 0.7674  decode.d6.loss_dice: 0.5166  decode.d7.loss_cls: 0.0387  decode.d7.loss_mask: 0.7717  decode.d7.loss_dice: 0.5183  decode.d8.loss_cls: 0.0331  decode.d8.loss_mask: 0.7717  decode.d8.loss_dice: 0.5254
06/01 11:45:50 - mmengine - INFO - Iter(train) [146200/160000]  base_lr: 1.1020e-05 lr: 1.1020e-06  eta: 1 day, 23:12:08  time: 0.6392  data_time: 0.0105  memory: 10506  grad_norm: 227.7124  loss: 13.3770  decode.loss_cls: 0.0410  decode.loss_mask: 0.7570  decode.loss_dice: 0.5098  decode.d0.loss_cls: 0.4276  decode.d0.loss_mask: 0.7803  decode.d0.loss_dice: 0.5057  decode.d1.loss_cls: 0.0447  decode.d1.loss_mask: 0.7382  decode.d1.loss_dice: 0.5126  decode.d2.loss_cls: 0.0393  decode.d2.loss_mask: 0.7373  decode.d2.loss_dice: 0.5111  decode.d3.loss_cls: 0.0438  decode.d3.loss_mask: 0.7374  decode.d3.loss_dice: 0.5072  decode.d4.loss_cls: 0.0438  decode.d4.loss_mask: 0.7369  decode.d4.loss_dice: 0.5092  decode.d5.loss_cls: 0.0357  decode.d5.loss_mask: 0.7778  decode.d5.loss_dice: 0.5229  decode.d6.loss_cls: 0.0391  decode.d6.loss_mask: 0.7364  decode.d6.loss_dice: 0.5048  decode.d7.loss_cls: 0.0394  decode.d7.loss_mask: 0.7350  decode.d7.loss_dice: 0.5057  decode.d8.loss_cls: 0.0440  decode.d8.loss_mask: 0.7417  decode.d8.loss_dice: 0.5113
06/01 11:46:22 - mmengine - INFO - Iter(train) [146250/160000]  base_lr: 1.0984e-05 lr: 1.0984e-06  eta: 1 day, 21:14:51  time: 0.6394  data_time: 0.0105  memory: 10507  grad_norm: 439.0074  loss: 16.1000  decode.loss_cls: 0.1112  decode.loss_mask: 0.9012  decode.loss_dice: 0.5634  decode.d0.loss_cls: 0.7015  decode.d0.loss_mask: 0.8405  decode.d0.loss_dice: 0.5453  decode.d1.loss_cls: 0.1348  decode.d1.loss_mask: 0.8868  decode.d1.loss_dice: 0.5656  decode.d2.loss_cls: 0.1619  decode.d2.loss_mask: 0.8453  decode.d2.loss_dice: 0.5362  decode.d3.loss_cls: 0.0852  decode.d3.loss_mask: 0.8998  decode.d3.loss_dice: 0.5587  decode.d4.loss_cls: 0.1431  decode.d4.loss_mask: 0.8707  decode.d4.loss_dice: 0.5573  decode.d5.loss_cls: 0.1404  decode.d5.loss_mask: 0.8519  decode.d5.loss_dice: 0.5690  decode.d6.loss_cls: 0.1626  decode.d6.loss_mask: 0.8219  decode.d6.loss_dice: 0.5487  decode.d7.loss_cls: 0.1201  decode.d7.loss_mask: 0.9183  decode.d7.loss_dice: 0.5367  decode.d8.loss_cls: 0.1843  decode.d8.loss_mask: 0.8005  decode.d8.loss_dice: 0.5372
06/01 11:46:54 - mmengine - INFO - Iter(train) [146300/160000]  base_lr: 1.0948e-05 lr: 1.0948e-06  eta: 1 day, 19:26:34  time: 0.6419  data_time: 0.0106  memory: 10511  grad_norm: 314.2981  loss: 15.5039  decode.loss_cls: 0.0965  decode.loss_mask: 0.8290  decode.loss_dice: 0.5666  decode.d0.loss_cls: 0.5282  decode.d0.loss_mask: 0.8350  decode.d0.loss_dice: 0.5587  decode.d1.loss_cls: 0.1407  decode.d1.loss_mask: 0.8261  decode.d1.loss_dice: 0.5674  decode.d2.loss_cls: 0.1116  decode.d2.loss_mask: 0.8324  decode.d2.loss_dice: 0.5725  decode.d3.loss_cls: 0.0974  decode.d3.loss_mask: 0.8283  decode.d3.loss_dice: 0.5782  decode.d4.loss_cls: 0.1209  decode.d4.loss_mask: 0.8260  decode.d4.loss_dice: 0.5730  decode.d5.loss_cls: 0.0970  decode.d5.loss_mask: 0.8262  decode.d5.loss_dice: 0.5734  decode.d6.loss_cls: 0.0964  decode.d6.loss_mask: 0.8460  decode.d6.loss_dice: 0.5689  decode.d7.loss_cls: 0.1213  decode.d7.loss_mask: 0.8243  decode.d7.loss_dice: 0.5680  decode.d8.loss_cls: 0.0945  decode.d8.loss_mask: 0.8194  decode.d8.loss_dice: 0.5800
06/01 11:47:26 - mmengine - INFO - Iter(train) [146350/160000]  base_lr: 1.0912e-05 lr: 1.0912e-06  eta: 1 day, 17:46:15  time: 0.6394  data_time: 0.0105  memory: 10495  grad_norm: 257.1185  loss: 12.8491  decode.loss_cls: 0.0297  decode.loss_mask: 0.7179  decode.loss_dice: 0.4964  decode.d0.loss_cls: 0.4709  decode.d0.loss_mask: 0.6868  decode.d0.loss_dice: 0.4884  decode.d1.loss_cls: 0.0479  decode.d1.loss_mask: 0.7124  decode.d1.loss_dice: 0.5062  decode.d2.loss_cls: 0.0245  decode.d2.loss_mask: 0.7066  decode.d2.loss_dice: 0.4951  decode.d3.loss_cls: 0.0112  decode.d3.loss_mask: 0.7066  decode.d3.loss_dice: 0.4869  decode.d4.loss_cls: 0.0515  decode.d4.loss_mask: 0.7104  decode.d4.loss_dice: 0.4890  decode.d5.loss_cls: 0.0347  decode.d5.loss_mask: 0.7197  decode.d5.loss_dice: 0.5019  decode.d6.loss_cls: 0.0576  decode.d6.loss_mask: 0.7138  decode.d6.loss_dice: 0.4805  decode.d7.loss_cls: 0.0371  decode.d7.loss_mask: 0.7179  decode.d7.loss_dice: 0.4977  decode.d8.loss_cls: 0.0347  decode.d8.loss_mask: 0.7128  decode.d8.loss_dice: 0.5025
06/01 11:47:58 - mmengine - INFO - Iter(train) [146400/160000]  base_lr: 1.0876e-05 lr: 1.0876e-06  eta: 1 day, 16:13:04  time: 0.6390  data_time: 0.0104  memory: 10506  grad_norm: 496.5398  loss: 16.4447  decode.loss_cls: 0.0559  decode.loss_mask: 0.9725  decode.loss_dice: 0.5544  decode.d0.loss_cls: 0.5576  decode.d0.loss_mask: 0.9167  decode.d0.loss_dice: 0.5420  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.9916  decode.d1.loss_dice: 0.5808  decode.d2.loss_cls: 0.0710  decode.d2.loss_mask: 0.9853  decode.d2.loss_dice: 0.5569  decode.d3.loss_cls: 0.0786  decode.d3.loss_mask: 0.9666  decode.d3.loss_dice: 0.5587  decode.d4.loss_cls: 0.0593  decode.d4.loss_mask: 0.9739  decode.d4.loss_dice: 0.5551  decode.d5.loss_cls: 0.0767  decode.d5.loss_mask: 0.9711  decode.d5.loss_dice: 0.5527  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.9745  decode.d6.loss_dice: 0.5551  decode.d7.loss_cls: 0.0557  decode.d7.loss_mask: 0.9747  decode.d7.loss_dice: 0.5581  decode.d8.loss_cls: 0.0670  decode.d8.loss_mask: 0.9788  decode.d8.loss_dice: 0.5638
06/01 11:48:30 - mmengine - INFO - Iter(train) [146450/160000]  base_lr: 1.0840e-05 lr: 1.0840e-06  eta: 1 day, 14:46:16  time: 0.6395  data_time: 0.0105  memory: 10516  grad_norm: 499.5923  loss: 18.6453  decode.loss_cls: 0.2220  decode.loss_mask: 0.9042  decode.loss_dice: 0.7143  decode.d0.loss_cls: 0.6095  decode.d0.loss_mask: 0.9165  decode.d0.loss_dice: 0.6953  decode.d1.loss_cls: 0.2098  decode.d1.loss_mask: 0.9254  decode.d1.loss_dice: 0.6787  decode.d2.loss_cls: 0.2308  decode.d2.loss_mask: 0.9066  decode.d2.loss_dice: 0.6838  decode.d3.loss_cls: 0.2290  decode.d3.loss_mask: 0.9141  decode.d3.loss_dice: 0.6802  decode.d4.loss_cls: 0.2087  decode.d4.loss_mask: 0.9192  decode.d4.loss_dice: 0.6955  decode.d5.loss_cls: 0.2329  decode.d5.loss_mask: 0.9067  decode.d5.loss_dice: 0.6780  decode.d6.loss_cls: 0.2319  decode.d6.loss_mask: 0.9077  decode.d6.loss_dice: 0.6942  decode.d7.loss_cls: 0.2241  decode.d7.loss_mask: 0.9018  decode.d7.loss_dice: 0.6988  decode.d8.loss_cls: 0.2310  decode.d8.loss_mask: 0.8984  decode.d8.loss_dice: 0.6963
06/01 11:49:02 - mmengine - INFO - Iter(train) [146500/160000]  base_lr: 1.0804e-05 lr: 1.0804e-06  eta: 1 day, 13:25:13  time: 0.6381  data_time: 0.0105  memory: 10497  grad_norm: 344.8929  loss: 13.9406  decode.loss_cls: 0.0840  decode.loss_mask: 0.7059  decode.loss_dice: 0.5507  decode.d0.loss_cls: 0.5446  decode.d0.loss_mask: 0.6780  decode.d0.loss_dice: 0.5551  decode.d1.loss_cls: 0.0934  decode.d1.loss_mask: 0.7047  decode.d1.loss_dice: 0.5503  decode.d2.loss_cls: 0.0717  decode.d2.loss_mask: 0.7083  decode.d2.loss_dice: 0.5739  decode.d3.loss_cls: 0.0824  decode.d3.loss_mask: 0.7083  decode.d3.loss_dice: 0.5892  decode.d4.loss_cls: 0.0953  decode.d4.loss_mask: 0.7016  decode.d4.loss_dice: 0.5528  decode.d5.loss_cls: 0.0946  decode.d5.loss_mask: 0.6967  decode.d5.loss_dice: 0.5645  decode.d6.loss_cls: 0.1071  decode.d6.loss_mask: 0.6984  decode.d6.loss_dice: 0.5523  decode.d7.loss_cls: 0.0881  decode.d7.loss_mask: 0.6966  decode.d7.loss_dice: 0.5557  decode.d8.loss_cls: 0.0883  decode.d8.loss_mask: 0.7007  decode.d8.loss_dice: 0.5475
06/01 11:49:34 - mmengine - INFO - Iter(train) [146550/160000]  base_lr: 1.0768e-05 lr: 1.0768e-06  eta: 1 day, 12:09:22  time: 0.6387  data_time: 0.0104  memory: 10506  grad_norm: 141.9131  loss: 12.0837  decode.loss_cls: 0.0128  decode.loss_mask: 0.6982  decode.loss_dice: 0.4599  decode.d0.loss_cls: 0.3669  decode.d0.loss_mask: 0.7149  decode.d0.loss_dice: 0.4606  decode.d1.loss_cls: 0.0137  decode.d1.loss_mask: 0.6983  decode.d1.loss_dice: 0.4638  decode.d2.loss_cls: 0.0131  decode.d2.loss_mask: 0.6969  decode.d2.loss_dice: 0.4593  decode.d3.loss_cls: 0.0128  decode.d3.loss_mask: 0.6976  decode.d3.loss_dice: 0.4601  decode.d4.loss_cls: 0.0143  decode.d4.loss_mask: 0.6984  decode.d4.loss_dice: 0.4571  decode.d5.loss_cls: 0.0110  decode.d5.loss_mask: 0.6986  decode.d5.loss_dice: 0.4609  decode.d6.loss_cls: 0.0117  decode.d6.loss_mask: 0.6963  decode.d6.loss_dice: 0.4575  decode.d7.loss_cls: 0.0115  decode.d7.loss_mask: 0.7001  decode.d7.loss_dice: 0.4603  decode.d8.loss_cls: 0.0124  decode.d8.loss_mask: 0.7027  decode.d8.loss_dice: 0.4618
06/01 11:50:06 - mmengine - INFO - Iter(train) [146600/160000]  base_lr: 1.0732e-05 lr: 1.0732e-06  eta: 1 day, 10:58:14  time: 0.6397  data_time: 0.0106  memory: 10500  grad_norm: 182.8110  loss: 14.4928  decode.loss_cls: 0.0324  decode.loss_mask: 0.8422  decode.loss_dice: 0.5273  decode.d0.loss_cls: 0.4706  decode.d0.loss_mask: 0.8061  decode.d0.loss_dice: 0.5411  decode.d1.loss_cls: 0.0379  decode.d1.loss_mask: 0.8484  decode.d1.loss_dice: 0.5205  decode.d2.loss_cls: 0.0343  decode.d2.loss_mask: 0.8471  decode.d2.loss_dice: 0.5367  decode.d3.loss_cls: 0.0350  decode.d3.loss_mask: 0.8502  decode.d3.loss_dice: 0.5262  decode.d4.loss_cls: 0.0337  decode.d4.loss_mask: 0.8488  decode.d4.loss_dice: 0.5243  decode.d5.loss_cls: 0.0340  decode.d5.loss_mask: 0.8504  decode.d5.loss_dice: 0.5250  decode.d6.loss_cls: 0.0289  decode.d6.loss_mask: 0.8471  decode.d6.loss_dice: 0.5264  decode.d7.loss_cls: 0.0335  decode.d7.loss_mask: 0.8529  decode.d7.loss_dice: 0.5269  decode.d8.loss_cls: 0.0292  decode.d8.loss_mask: 0.8471  decode.d8.loss_dice: 0.5287
06/01 11:50:38 - mmengine - INFO - Iter(train) [146650/160000]  base_lr: 1.0696e-05 lr: 1.0696e-06  eta: 1 day, 9:51:22  time: 0.6384  data_time: 0.0108  memory: 10502  grad_norm: 249.8089  loss: 15.6241  decode.loss_cls: 0.0802  decode.loss_mask: 0.8305  decode.loss_dice: 0.6076  decode.d0.loss_cls: 0.4957  decode.d0.loss_mask: 0.8426  decode.d0.loss_dice: 0.6249  decode.d1.loss_cls: 0.0749  decode.d1.loss_mask: 0.8364  decode.d1.loss_dice: 0.5886  decode.d2.loss_cls: 0.0749  decode.d2.loss_mask: 0.8292  decode.d2.loss_dice: 0.6196  decode.d3.loss_cls: 0.0823  decode.d3.loss_mask: 0.8282  decode.d3.loss_dice: 0.6222  decode.d4.loss_cls: 0.0742  decode.d4.loss_mask: 0.8332  decode.d4.loss_dice: 0.6286  decode.d5.loss_cls: 0.0742  decode.d5.loss_mask: 0.8329  decode.d5.loss_dice: 0.5990  decode.d6.loss_cls: 0.0832  decode.d6.loss_mask: 0.8269  decode.d6.loss_dice: 0.6155  decode.d7.loss_cls: 0.0692  decode.d7.loss_mask: 0.8332  decode.d7.loss_dice: 0.6024  decode.d8.loss_cls: 0.0744  decode.d8.loss_mask: 0.8265  decode.d8.loss_dice: 0.6129
06/01 11:51:10 - mmengine - INFO - Iter(train) [146700/160000]  base_lr: 1.0660e-05 lr: 1.0660e-06  eta: 1 day, 8:48:28  time: 0.6379  data_time: 0.0104  memory: 10500  grad_norm: 292.2530  loss: 13.4650  decode.loss_cls: 0.0498  decode.loss_mask: 0.7550  decode.loss_dice: 0.5199  decode.d0.loss_cls: 0.4253  decode.d0.loss_mask: 0.7244  decode.d0.loss_dice: 0.5092  decode.d1.loss_cls: 0.0421  decode.d1.loss_mask: 0.7464  decode.d1.loss_dice: 0.5126  decode.d2.loss_cls: 0.0525  decode.d2.loss_mask: 0.7517  decode.d2.loss_dice: 0.5156  decode.d3.loss_cls: 0.0516  decode.d3.loss_mask: 0.7461  decode.d3.loss_dice: 0.5197  decode.d4.loss_cls: 0.0589  decode.d4.loss_mask: 0.7498  decode.d4.loss_dice: 0.5011  decode.d5.loss_cls: 0.0451  decode.d5.loss_mask: 0.7488  decode.d5.loss_dice: 0.5137  decode.d6.loss_cls: 0.0506  decode.d6.loss_mask: 0.7526  decode.d6.loss_dice: 0.4977  decode.d7.loss_cls: 0.0522  decode.d7.loss_mask: 0.7508  decode.d7.loss_dice: 0.5052  decode.d8.loss_cls: 0.0518  decode.d8.loss_mask: 0.7472  decode.d8.loss_dice: 0.5175
06/01 11:51:42 - mmengine - INFO - Iter(train) [146750/160000]  base_lr: 1.0624e-05 lr: 1.0624e-06  eta: 1 day, 7:49:04  time: 0.6390  data_time: 0.0104  memory: 10502  grad_norm: 207.6892  loss: 12.8709  decode.loss_cls: 0.0712  decode.loss_mask: 0.6911  decode.loss_dice: 0.4956  decode.d0.loss_cls: 0.4770  decode.d0.loss_mask: 0.6887  decode.d0.loss_dice: 0.4742  decode.d1.loss_cls: 0.0710  decode.d1.loss_mask: 0.6922  decode.d1.loss_dice: 0.4868  decode.d2.loss_cls: 0.0663  decode.d2.loss_mask: 0.6864  decode.d2.loss_dice: 0.4866  decode.d3.loss_cls: 0.0761  decode.d3.loss_mask: 0.6867  decode.d3.loss_dice: 0.4926  decode.d4.loss_cls: 0.1140  decode.d4.loss_mask: 0.6745  decode.d4.loss_dice: 0.4677  decode.d5.loss_cls: 0.0924  decode.d5.loss_mask: 0.6844  decode.d5.loss_dice: 0.4840  decode.d6.loss_cls: 0.0901  decode.d6.loss_mask: 0.6772  decode.d6.loss_dice: 0.4697  decode.d7.loss_cls: 0.0811  decode.d7.loss_mask: 0.6748  decode.d7.loss_dice: 0.4729  decode.d8.loss_cls: 0.0920  decode.d8.loss_mask: 0.6826  decode.d8.loss_dice: 0.4711
06/01 11:52:14 - mmengine - INFO - Iter(train) [146800/160000]  base_lr: 1.0588e-05 lr: 1.0588e-06  eta: 1 day, 6:52:57  time: 0.6385  data_time: 0.0105  memory: 10500  grad_norm: 454.0604  loss: 16.3412  decode.loss_cls: 0.1216  decode.loss_mask: 0.8598  decode.loss_dice: 0.6047  decode.d0.loss_cls: 0.5501  decode.d0.loss_mask: 0.8457  decode.d0.loss_dice: 0.5882  decode.d1.loss_cls: 0.1130  decode.d1.loss_mask: 0.8597  decode.d1.loss_dice: 0.6023  decode.d2.loss_cls: 0.0879  decode.d2.loss_mask: 0.8649  decode.d2.loss_dice: 0.6104  decode.d3.loss_cls: 0.1359  decode.d3.loss_mask: 0.8626  decode.d3.loss_dice: 0.6133  decode.d4.loss_cls: 0.1737  decode.d4.loss_mask: 0.8312  decode.d4.loss_dice: 0.6082  decode.d5.loss_cls: 0.1563  decode.d5.loss_mask: 0.8421  decode.d5.loss_dice: 0.6177  decode.d6.loss_cls: 0.1027  decode.d6.loss_mask: 0.8606  decode.d6.loss_dice: 0.6079  decode.d7.loss_cls: 0.1611  decode.d7.loss_mask: 0.8344  decode.d7.loss_dice: 0.6005  decode.d8.loss_cls: 0.1301  decode.d8.loss_mask: 0.8741  decode.d8.loss_dice: 0.6206
06/01 11:52:46 - mmengine - INFO - Iter(train) [146850/160000]  base_lr: 1.0552e-05 lr: 1.0552e-06  eta: 1 day, 5:59:49  time: 0.6386  data_time: 0.0104  memory: 10502  grad_norm: 399.7787  loss: 13.6415  decode.loss_cls: 0.1770  decode.loss_mask: 0.6520  decode.loss_dice: 0.4752  decode.d0.loss_cls: 0.5627  decode.d0.loss_mask: 0.6773  decode.d0.loss_dice: 0.4948  decode.d1.loss_cls: 0.1700  decode.d1.loss_mask: 0.6587  decode.d1.loss_dice: 0.5233  decode.d2.loss_cls: 0.1646  decode.d2.loss_mask: 0.6725  decode.d2.loss_dice: 0.4725  decode.d3.loss_cls: 0.1656  decode.d3.loss_mask: 0.6732  decode.d3.loss_dice: 0.4761  decode.d4.loss_cls: 0.1664  decode.d4.loss_mask: 0.6693  decode.d4.loss_dice: 0.5128  decode.d5.loss_cls: 0.1573  decode.d5.loss_mask: 0.6570  decode.d5.loss_dice: 0.5075  decode.d6.loss_cls: 0.1507  decode.d6.loss_mask: 0.6694  decode.d6.loss_dice: 0.4924  decode.d7.loss_cls: 0.1556  decode.d7.loss_mask: 0.6583  decode.d7.loss_dice: 0.4920  decode.d8.loss_cls: 0.1655  decode.d8.loss_mask: 0.6764  decode.d8.loss_dice: 0.4953
06/01 11:53:18 - mmengine - INFO - Iter(train) [146900/160000]  base_lr: 1.0516e-05 lr: 1.0516e-06  eta: 1 day, 5:09:28  time: 0.6384  data_time: 0.0105  memory: 10497  grad_norm: 832.4116  loss: 13.6537  decode.loss_cls: 0.0672  decode.loss_mask: 0.7802  decode.loss_dice: 0.4865  decode.d0.loss_cls: 0.4915  decode.d0.loss_mask: 0.7682  decode.d0.loss_dice: 0.4993  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.7871  decode.d1.loss_dice: 0.4823  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.7803  decode.d2.loss_dice: 0.4629  decode.d3.loss_cls: 0.0542  decode.d3.loss_mask: 0.7859  decode.d3.loss_dice: 0.4713  decode.d4.loss_cls: 0.0557  decode.d4.loss_mask: 0.7734  decode.d4.loss_dice: 0.4750  decode.d5.loss_cls: 0.0615  decode.d5.loss_mask: 0.7913  decode.d5.loss_dice: 0.4749  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.7886  decode.d6.loss_dice: 0.4748  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.7925  decode.d7.loss_dice: 0.4783  decode.d8.loss_cls: 0.0733  decode.d8.loss_mask: 0.7754  decode.d8.loss_dice: 0.4821
06/01 11:53:50 - mmengine - INFO - Iter(train) [146950/160000]  base_lr: 1.0480e-05 lr: 1.0480e-06  eta: 1 day, 4:21:40  time: 0.6383  data_time: 0.0105  memory: 10507  grad_norm: 1430.2476  loss: 13.0299  decode.loss_cls: 0.0831  decode.loss_mask: 0.7117  decode.loss_dice: 0.4504  decode.d0.loss_cls: 0.4784  decode.d0.loss_mask: 0.7115  decode.d0.loss_dice: 0.4969  decode.d1.loss_cls: 0.0903  decode.d1.loss_mask: 0.7205  decode.d1.loss_dice: 0.4680  decode.d2.loss_cls: 0.0710  decode.d2.loss_mask: 0.7186  decode.d2.loss_dice: 0.4556  decode.d3.loss_cls: 0.0918  decode.d3.loss_mask: 0.7131  decode.d3.loss_dice: 0.4690  decode.d4.loss_cls: 0.0949  decode.d4.loss_mask: 0.7114  decode.d4.loss_dice: 0.4469  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 0.7077  decode.d5.loss_dice: 0.4478  decode.d6.loss_cls: 0.0988  decode.d6.loss_mask: 0.7101  decode.d6.loss_dice: 0.4730  decode.d7.loss_cls: 0.0985  decode.d7.loss_mask: 0.7121  decode.d7.loss_dice: 0.4493  decode.d8.loss_cls: 0.0659  decode.d8.loss_mask: 0.7195  decode.d8.loss_dice: 0.4777
06/01 11:54:22 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 11:54:22 - mmengine - INFO - Iter(train) [147000/160000]  base_lr: 1.0443e-05 lr: 1.0443e-06  eta: 1 day, 3:36:13  time: 0.6405  data_time: 0.0106  memory: 10505  grad_norm: 434.1847  loss: 17.8094  decode.loss_cls: 0.1406  decode.loss_mask: 0.8968  decode.loss_dice: 0.7035  decode.d0.loss_cls: 0.5822  decode.d0.loss_mask: 0.8612  decode.d0.loss_dice: 0.6761  decode.d1.loss_cls: 0.1910  decode.d1.loss_mask: 0.8847  decode.d1.loss_dice: 0.6797  decode.d2.loss_cls: 0.1531  decode.d2.loss_mask: 0.8691  decode.d2.loss_dice: 0.6723  decode.d3.loss_cls: 0.1620  decode.d3.loss_mask: 0.8982  decode.d3.loss_dice: 0.7052  decode.d4.loss_cls: 0.1856  decode.d4.loss_mask: 0.8919  decode.d4.loss_dice: 0.6770  decode.d5.loss_cls: 0.1425  decode.d5.loss_mask: 0.8911  decode.d5.loss_dice: 0.7007  decode.d6.loss_cls: 0.1849  decode.d6.loss_mask: 0.8713  decode.d6.loss_dice: 0.6811  decode.d7.loss_cls: 0.1566  decode.d7.loss_mask: 0.9037  decode.d7.loss_dice: 0.6767  decode.d8.loss_cls: 0.1500  decode.d8.loss_mask: 0.9099  decode.d8.loss_dice: 0.7106
06/01 11:54:54 - mmengine - INFO - Iter(train) [147050/160000]  base_lr: 1.0407e-05 lr: 1.0407e-06  eta: 1 day, 2:52:58  time: 0.6381  data_time: 0.0105  memory: 10499  grad_norm: 306.9210  loss: 14.6498  decode.loss_cls: 0.0985  decode.loss_mask: 0.7731  decode.loss_dice: 0.5287  decode.d0.loss_cls: 0.5326  decode.d0.loss_mask: 0.7667  decode.d0.loss_dice: 0.5377  decode.d1.loss_cls: 0.1390  decode.d1.loss_mask: 0.7893  decode.d1.loss_dice: 0.5275  decode.d2.loss_cls: 0.1204  decode.d2.loss_mask: 0.7767  decode.d2.loss_dice: 0.5277  decode.d3.loss_cls: 0.1104  decode.d3.loss_mask: 0.7777  decode.d3.loss_dice: 0.5316  decode.d4.loss_cls: 0.1082  decode.d4.loss_mask: 0.7691  decode.d4.loss_dice: 0.5279  decode.d5.loss_cls: 0.1045  decode.d5.loss_mask: 0.7798  decode.d5.loss_dice: 0.5275  decode.d6.loss_cls: 0.1192  decode.d6.loss_mask: 0.7794  decode.d6.loss_dice: 0.5295  decode.d7.loss_cls: 0.1382  decode.d7.loss_mask: 0.7755  decode.d7.loss_dice: 0.5246  decode.d8.loss_cls: 0.1283  decode.d8.loss_mask: 0.7743  decode.d8.loss_dice: 0.5262
06/01 11:55:26 - mmengine - INFO - Iter(train) [147100/160000]  base_lr: 1.0371e-05 lr: 1.0371e-06  eta: 1 day, 2:11:45  time: 0.6385  data_time: 0.0105  memory: 10514  grad_norm: 326.1912  loss: 13.6026  decode.loss_cls: 0.1462  decode.loss_mask: 0.6984  decode.loss_dice: 0.4936  decode.d0.loss_cls: 0.5692  decode.d0.loss_mask: 0.6765  decode.d0.loss_dice: 0.5013  decode.d1.loss_cls: 0.1610  decode.d1.loss_mask: 0.6573  decode.d1.loss_dice: 0.4869  decode.d2.loss_cls: 0.1246  decode.d2.loss_mask: 0.6626  decode.d2.loss_dice: 0.5061  decode.d3.loss_cls: 0.1638  decode.d3.loss_mask: 0.6581  decode.d3.loss_dice: 0.4786  decode.d4.loss_cls: 0.1453  decode.d4.loss_mask: 0.6813  decode.d4.loss_dice: 0.4830  decode.d5.loss_cls: 0.1308  decode.d5.loss_mask: 0.6864  decode.d5.loss_dice: 0.5144  decode.d6.loss_cls: 0.1222  decode.d6.loss_mask: 0.6834  decode.d6.loss_dice: 0.4765  decode.d7.loss_cls: 0.1579  decode.d7.loss_mask: 0.6797  decode.d7.loss_dice: 0.4966  decode.d8.loss_cls: 0.1554  decode.d8.loss_mask: 0.7014  decode.d8.loss_dice: 0.5042
06/01 11:55:58 - mmengine - INFO - Iter(train) [147150/160000]  base_lr: 1.0335e-05 lr: 1.0335e-06  eta: 1 day, 1:32:26  time: 0.6398  data_time: 0.0106  memory: 10510  grad_norm: 575.5031  loss: 15.2716  decode.loss_cls: 0.0429  decode.loss_mask: 0.8452  decode.loss_dice: 0.5835  decode.d0.loss_cls: 0.5159  decode.d0.loss_mask: 0.8342  decode.d0.loss_dice: 0.5646  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.8486  decode.d1.loss_dice: 0.5932  decode.d2.loss_cls: 0.0480  decode.d2.loss_mask: 0.8441  decode.d2.loss_dice: 0.5880  decode.d3.loss_cls: 0.0397  decode.d3.loss_mask: 0.8462  decode.d3.loss_dice: 0.5912  decode.d4.loss_cls: 0.0436  decode.d4.loss_mask: 0.8459  decode.d4.loss_dice: 0.5912  decode.d5.loss_cls: 0.0437  decode.d5.loss_mask: 0.8488  decode.d5.loss_dice: 0.5905  decode.d6.loss_cls: 0.0479  decode.d6.loss_mask: 0.8475  decode.d6.loss_dice: 0.5854  decode.d7.loss_cls: 0.0433  decode.d7.loss_mask: 0.8457  decode.d7.loss_dice: 0.5926  decode.d8.loss_cls: 0.0500  decode.d8.loss_mask: 0.8470  decode.d8.loss_dice: 0.5859
06/01 11:56:30 - mmengine - INFO - Iter(train) [147200/160000]  base_lr: 1.0299e-05 lr: 1.0299e-06  eta: 1 day, 0:54:54  time: 0.6397  data_time: 0.0105  memory: 10500  grad_norm: 335.4164  loss: 15.6661  decode.loss_cls: 0.1274  decode.loss_mask: 0.7920  decode.loss_dice: 0.5913  decode.d0.loss_cls: 0.5356  decode.d0.loss_mask: 0.8249  decode.d0.loss_dice: 0.6295  decode.d1.loss_cls: 0.1249  decode.d1.loss_mask: 0.7976  decode.d1.loss_dice: 0.6137  decode.d2.loss_cls: 0.0999  decode.d2.loss_mask: 0.7898  decode.d2.loss_dice: 0.6059  decode.d3.loss_cls: 0.1375  decode.d3.loss_mask: 0.7896  decode.d3.loss_dice: 0.5916  decode.d4.loss_cls: 0.1031  decode.d4.loss_mask: 0.7909  decode.d4.loss_dice: 0.6010  decode.d5.loss_cls: 0.1299  decode.d5.loss_mask: 0.7972  decode.d5.loss_dice: 0.6044  decode.d6.loss_cls: 0.1594  decode.d6.loss_mask: 0.7874  decode.d6.loss_dice: 0.5941  decode.d7.loss_cls: 0.1298  decode.d7.loss_mask: 0.7942  decode.d7.loss_dice: 0.5968  decode.d8.loss_cls: 0.1445  decode.d8.loss_mask: 0.7853  decode.d8.loss_dice: 0.5972
06/01 11:57:02 - mmengine - INFO - Iter(train) [147250/160000]  base_lr: 1.0263e-05 lr: 1.0263e-06  eta: 1 day, 0:18:59  time: 0.6388  data_time: 0.0105  memory: 10505  grad_norm: 492.9260  loss: 12.3751  decode.loss_cls: 0.0334  decode.loss_mask: 0.6708  decode.loss_dice: 0.4908  decode.d0.loss_cls: 0.4485  decode.d0.loss_mask: 0.6498  decode.d0.loss_dice: 0.4965  decode.d1.loss_cls: 0.0399  decode.d1.loss_mask: 0.6791  decode.d1.loss_dice: 0.4986  decode.d2.loss_cls: 0.0437  decode.d2.loss_mask: 0.6773  decode.d2.loss_dice: 0.4937  decode.d3.loss_cls: 0.0360  decode.d3.loss_mask: 0.6630  decode.d3.loss_dice: 0.4861  decode.d4.loss_cls: 0.0373  decode.d4.loss_mask: 0.6628  decode.d4.loss_dice: 0.4884  decode.d5.loss_cls: 0.0329  decode.d5.loss_mask: 0.6609  decode.d5.loss_dice: 0.4786  decode.d6.loss_cls: 0.0417  decode.d6.loss_mask: 0.6720  decode.d6.loss_dice: 0.4947  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 0.6666  decode.d7.loss_dice: 0.4912  decode.d8.loss_cls: 0.0403  decode.d8.loss_mask: 0.6709  decode.d8.loss_dice: 0.4908
06/01 11:57:34 - mmengine - INFO - Iter(train) [147300/160000]  base_lr: 1.0226e-05 lr: 1.0226e-06  eta: 23:44:36  time: 0.6389  data_time: 0.0106  memory: 10506  grad_norm: 272.4668  loss: 13.9199  decode.loss_cls: 0.0189  decode.loss_mask: 0.8193  decode.loss_dice: 0.5187  decode.d0.loss_cls: 0.3574  decode.d0.loss_mask: 0.8491  decode.d0.loss_dice: 0.5173  decode.d1.loss_cls: 0.0192  decode.d1.loss_mask: 0.8203  decode.d1.loss_dice: 0.5124  decode.d2.loss_cls: 0.0148  decode.d2.loss_mask: 0.8213  decode.d2.loss_dice: 0.5127  decode.d3.loss_cls: 0.0149  decode.d3.loss_mask: 0.8209  decode.d3.loss_dice: 0.5150  decode.d4.loss_cls: 0.0151  decode.d4.loss_mask: 0.8203  decode.d4.loss_dice: 0.5174  decode.d5.loss_cls: 0.0129  decode.d5.loss_mask: 0.8245  decode.d5.loss_dice: 0.5207  decode.d6.loss_cls: 0.0153  decode.d6.loss_mask: 0.8232  decode.d6.loss_dice: 0.5190  decode.d7.loss_cls: 0.0234  decode.d7.loss_mask: 0.8208  decode.d7.loss_dice: 0.5186  decode.d8.loss_cls: 0.0278  decode.d8.loss_mask: 0.8136  decode.d8.loss_dice: 0.5151
06/01 11:58:06 - mmengine - INFO - Iter(train) [147350/160000]  base_lr: 1.0190e-05 lr: 1.0190e-06  eta: 23:11:40  time: 0.6387  data_time: 0.0105  memory: 10511  grad_norm: 2127.1242  loss: 17.0569  decode.loss_cls: 0.1514  decode.loss_mask: 0.8746  decode.loss_dice: 0.6300  decode.d0.loss_cls: 0.6401  decode.d0.loss_mask: 0.8024  decode.d0.loss_dice: 0.5898  decode.d1.loss_cls: 0.1708  decode.d1.loss_mask: 0.8880  decode.d1.loss_dice: 0.6416  decode.d2.loss_cls: 0.1663  decode.d2.loss_mask: 0.8831  decode.d2.loss_dice: 0.6318  decode.d3.loss_cls: 0.1653  decode.d3.loss_mask: 0.8771  decode.d3.loss_dice: 0.6373  decode.d4.loss_cls: 0.1407  decode.d4.loss_mask: 0.8762  decode.d4.loss_dice: 0.6205  decode.d5.loss_cls: 0.1722  decode.d5.loss_mask: 0.8767  decode.d5.loss_dice: 0.6208  decode.d6.loss_cls: 0.1645  decode.d6.loss_mask: 0.8728  decode.d6.loss_dice: 0.6208  decode.d7.loss_cls: 0.1500  decode.d7.loss_mask: 0.8897  decode.d7.loss_dice: 0.6298  decode.d8.loss_cls: 0.1717  decode.d8.loss_mask: 0.8771  decode.d8.loss_dice: 0.6238
06/01 11:58:38 - mmengine - INFO - Iter(train) [147400/160000]  base_lr: 1.0154e-05 lr: 1.0154e-06  eta: 22:40:05  time: 0.6389  data_time: 0.0105  memory: 10507  grad_norm: 461.5635  loss: 11.4721  decode.loss_cls: 0.0438  decode.loss_mask: 0.6476  decode.loss_dice: 0.4236  decode.d0.loss_cls: 0.4442  decode.d0.loss_mask: 0.6408  decode.d0.loss_dice: 0.4093  decode.d1.loss_cls: 0.0349  decode.d1.loss_mask: 0.6503  decode.d1.loss_dice: 0.4238  decode.d2.loss_cls: 0.0182  decode.d2.loss_mask: 0.6490  decode.d2.loss_dice: 0.4262  decode.d3.loss_cls: 0.0189  decode.d3.loss_mask: 0.6541  decode.d3.loss_dice: 0.4254  decode.d4.loss_cls: 0.0437  decode.d4.loss_mask: 0.6451  decode.d4.loss_dice: 0.4288  decode.d5.loss_cls: 0.0400  decode.d5.loss_mask: 0.6452  decode.d5.loss_dice: 0.4311  decode.d6.loss_cls: 0.0417  decode.d6.loss_mask: 0.6416  decode.d6.loss_dice: 0.4252  decode.d7.loss_cls: 0.0219  decode.d7.loss_mask: 0.6530  decode.d7.loss_dice: 0.4229  decode.d8.loss_cls: 0.0535  decode.d8.loss_mask: 0.6420  decode.d8.loss_dice: 0.4262
06/01 11:59:10 - mmengine - INFO - Iter(train) [147450/160000]  base_lr: 1.0118e-05 lr: 1.0118e-06  eta: 22:09:46  time: 0.6386  data_time: 0.0105  memory: 10506  grad_norm: 370.0074  loss: 14.9630  decode.loss_cls: 0.0674  decode.loss_mask: 0.8358  decode.loss_dice: 0.5538  decode.d0.loss_cls: 0.4108  decode.d0.loss_mask: 0.8474  decode.d0.loss_dice: 0.5434  decode.d1.loss_cls: 0.0676  decode.d1.loss_mask: 0.8365  decode.d1.loss_dice: 0.5560  decode.d2.loss_cls: 0.0687  decode.d2.loss_mask: 0.8376  decode.d2.loss_dice: 0.5510  decode.d3.loss_cls: 0.0603  decode.d3.loss_mask: 0.8553  decode.d3.loss_dice: 0.5573  decode.d4.loss_cls: 0.0672  decode.d4.loss_mask: 0.8483  decode.d4.loss_dice: 0.5653  decode.d5.loss_cls: 0.0672  decode.d5.loss_mask: 0.8246  decode.d5.loss_dice: 0.5561  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 0.8371  decode.d6.loss_dice: 0.5648  decode.d7.loss_cls: 0.0819  decode.d7.loss_mask: 0.8336  decode.d7.loss_dice: 0.5419  decode.d8.loss_cls: 0.0727  decode.d8.loss_mask: 0.8360  decode.d8.loss_dice: 0.5530
06/01 11:59:42 - mmengine - INFO - Iter(train) [147500/160000]  base_lr: 1.0081e-05 lr: 1.0081e-06  eta: 21:40:39  time: 0.6386  data_time: 0.0105  memory: 10506  grad_norm: 367.8164  loss: 14.8039  decode.loss_cls: 0.0614  decode.loss_mask: 0.7946  decode.loss_dice: 0.5959  decode.d0.loss_cls: 0.4283  decode.d0.loss_mask: 0.7708  decode.d0.loss_dice: 0.5882  decode.d1.loss_cls: 0.0615  decode.d1.loss_mask: 0.7962  decode.d1.loss_dice: 0.6019  decode.d2.loss_cls: 0.0592  decode.d2.loss_mask: 0.7935  decode.d2.loss_dice: 0.6002  decode.d3.loss_cls: 0.0393  decode.d3.loss_mask: 0.7974  decode.d3.loss_dice: 0.6032  decode.d4.loss_cls: 0.0881  decode.d4.loss_mask: 0.7542  decode.d4.loss_dice: 0.5942  decode.d5.loss_cls: 0.0392  decode.d5.loss_mask: 0.7947  decode.d5.loss_dice: 0.6014  decode.d6.loss_cls: 0.0595  decode.d6.loss_mask: 0.7979  decode.d6.loss_dice: 0.6008  decode.d7.loss_cls: 0.0309  decode.d7.loss_mask: 0.7964  decode.d7.loss_dice: 0.6055  decode.d8.loss_cls: 0.0612  decode.d8.loss_mask: 0.7923  decode.d8.loss_dice: 0.5960
06/01 12:00:14 - mmengine - INFO - Iter(train) [147550/160000]  base_lr: 1.0045e-05 lr: 1.0045e-06  eta: 21:12:38  time: 0.6400  data_time: 0.0105  memory: 10499  grad_norm: 407.6930  loss: 14.8326  decode.loss_cls: 0.1057  decode.loss_mask: 0.7800  decode.loss_dice: 0.5394  decode.d0.loss_cls: 0.5022  decode.d0.loss_mask: 0.7782  decode.d0.loss_dice: 0.5401  decode.d1.loss_cls: 0.1270  decode.d1.loss_mask: 0.7841  decode.d1.loss_dice: 0.5318  decode.d2.loss_cls: 0.1356  decode.d2.loss_mask: 0.7823  decode.d2.loss_dice: 0.5403  decode.d3.loss_cls: 0.1348  decode.d3.loss_mask: 0.7853  decode.d3.loss_dice: 0.5251  decode.d4.loss_cls: 0.1020  decode.d4.loss_mask: 0.7876  decode.d4.loss_dice: 0.5299  decode.d5.loss_cls: 0.0992  decode.d5.loss_mask: 0.7887  decode.d5.loss_dice: 0.5533  decode.d6.loss_cls: 0.1755  decode.d6.loss_mask: 0.7595  decode.d6.loss_dice: 0.5537  decode.d7.loss_cls: 0.1098  decode.d7.loss_mask: 0.7801  decode.d7.loss_dice: 0.5462  decode.d8.loss_cls: 0.1100  decode.d8.loss_mask: 0.7895  decode.d8.loss_dice: 0.5559
06/01 12:00:46 - mmengine - INFO - Iter(train) [147600/160000]  base_lr: 1.0009e-05 lr: 1.0009e-06  eta: 20:45:41  time: 0.6387  data_time: 0.0104  memory: 10513  grad_norm: 432.7503  loss: 14.6504  decode.loss_cls: 0.0967  decode.loss_mask: 0.7861  decode.loss_dice: 0.5496  decode.d0.loss_cls: 0.4394  decode.d0.loss_mask: 0.7937  decode.d0.loss_dice: 0.5472  decode.d1.loss_cls: 0.1241  decode.d1.loss_mask: 0.7883  decode.d1.loss_dice: 0.5751  decode.d2.loss_cls: 0.1014  decode.d2.loss_mask: 0.7891  decode.d2.loss_dice: 0.5227  decode.d3.loss_cls: 0.1169  decode.d3.loss_mask: 0.7894  decode.d3.loss_dice: 0.5424  decode.d4.loss_cls: 0.1185  decode.d4.loss_mask: 0.7878  decode.d4.loss_dice: 0.5250  decode.d5.loss_cls: 0.0917  decode.d5.loss_mask: 0.7910  decode.d5.loss_dice: 0.5294  decode.d6.loss_cls: 0.0918  decode.d6.loss_mask: 0.7851  decode.d6.loss_dice: 0.5408  decode.d7.loss_cls: 0.1095  decode.d7.loss_mask: 0.7923  decode.d7.loss_dice: 0.5394  decode.d8.loss_cls: 0.1007  decode.d8.loss_mask: 0.7829  decode.d8.loss_dice: 0.5024
06/01 12:01:18 - mmengine - INFO - Iter(train) [147650/160000]  base_lr: 9.9723e-06 lr: 9.9723e-07  eta: 20:19:44  time: 0.6384  data_time: 0.0103  memory: 10499  grad_norm: 277.1644  loss: 14.1520  decode.loss_cls: 0.0070  decode.loss_mask: 0.8940  decode.loss_dice: 0.4890  decode.d0.loss_cls: 0.4054  decode.d0.loss_mask: 0.8562  decode.d0.loss_dice: 0.4626  decode.d1.loss_cls: 0.0084  decode.d1.loss_mask: 0.8984  decode.d1.loss_dice: 0.4817  decode.d2.loss_cls: 0.0076  decode.d2.loss_mask: 0.8822  decode.d2.loss_dice: 0.4787  decode.d3.loss_cls: 0.0072  decode.d3.loss_mask: 0.8829  decode.d3.loss_dice: 0.4824  decode.d4.loss_cls: 0.0079  decode.d4.loss_mask: 0.8901  decode.d4.loss_dice: 0.4812  decode.d5.loss_cls: 0.0085  decode.d5.loss_mask: 0.8895  decode.d5.loss_dice: 0.4805  decode.d6.loss_cls: 0.0080  decode.d6.loss_mask: 0.8875  decode.d6.loss_dice: 0.4814  decode.d7.loss_cls: 0.0108  decode.d7.loss_mask: 0.8892  decode.d7.loss_dice: 0.4772  decode.d8.loss_cls: 0.0075  decode.d8.loss_mask: 0.8948  decode.d8.loss_dice: 0.4943
06/01 12:01:50 - mmengine - INFO - Iter(train) [147700/160000]  base_lr: 9.9359e-06 lr: 9.9359e-07  eta: 19:54:44  time: 0.6382  data_time: 0.0104  memory: 10515  grad_norm: 314.1334  loss: 16.4764  decode.loss_cls: 0.1047  decode.loss_mask: 0.8915  decode.loss_dice: 0.5934  decode.d0.loss_cls: 0.5760  decode.d0.loss_mask: 0.9048  decode.d0.loss_dice: 0.5796  decode.d1.loss_cls: 0.0497  decode.d1.loss_mask: 0.9433  decode.d1.loss_dice: 0.6280  decode.d2.loss_cls: 0.0545  decode.d2.loss_mask: 0.9538  decode.d2.loss_dice: 0.6258  decode.d3.loss_cls: 0.1099  decode.d3.loss_mask: 0.8979  decode.d3.loss_dice: 0.5979  decode.d4.loss_cls: 0.0971  decode.d4.loss_mask: 0.8902  decode.d4.loss_dice: 0.5970  decode.d5.loss_cls: 0.1011  decode.d5.loss_mask: 0.8861  decode.d5.loss_dice: 0.5986  decode.d6.loss_cls: 0.0730  decode.d6.loss_mask: 0.9498  decode.d6.loss_dice: 0.6203  decode.d7.loss_cls: 0.0951  decode.d7.loss_mask: 0.8906  decode.d7.loss_dice: 0.5913  decode.d8.loss_cls: 0.0968  decode.d8.loss_mask: 0.8944  decode.d8.loss_dice: 0.5844
06/01 12:02:22 - mmengine - INFO - Iter(train) [147750/160000]  base_lr: 9.8996e-06 lr: 9.8996e-07  eta: 19:30:37  time: 0.6393  data_time: 0.0104  memory: 10507  grad_norm: 419.4121  loss: 16.0039  decode.loss_cls: 0.0774  decode.loss_mask: 0.8644  decode.loss_dice: 0.5951  decode.d0.loss_cls: 0.5814  decode.d0.loss_mask: 0.8484  decode.d0.loss_dice: 0.6071  decode.d1.loss_cls: 0.1038  decode.d1.loss_mask: 0.8769  decode.d1.loss_dice: 0.6220  decode.d2.loss_cls: 0.0708  decode.d2.loss_mask: 0.8658  decode.d2.loss_dice: 0.5987  decode.d3.loss_cls: 0.0557  decode.d3.loss_mask: 0.8741  decode.d3.loss_dice: 0.6189  decode.d4.loss_cls: 0.0572  decode.d4.loss_mask: 0.8746  decode.d4.loss_dice: 0.6202  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.8658  decode.d5.loss_dice: 0.6132  decode.d6.loss_cls: 0.0768  decode.d6.loss_mask: 0.8748  decode.d6.loss_dice: 0.6147  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.8641  decode.d7.loss_dice: 0.6056  decode.d8.loss_cls: 0.0752  decode.d8.loss_mask: 0.8611  decode.d8.loss_dice: 0.5990
06/01 12:02:54 - mmengine - INFO - Iter(train) [147800/160000]  base_lr: 9.8632e-06 lr: 9.8632e-07  eta: 19:07:20  time: 0.6391  data_time: 0.0103  memory: 10509  grad_norm: 752.2532  loss: 12.1474  decode.loss_cls: 0.0458  decode.loss_mask: 0.6978  decode.loss_dice: 0.4261  decode.d0.loss_cls: 0.4728  decode.d0.loss_mask: 0.7302  decode.d0.loss_dice: 0.4477  decode.d1.loss_cls: 0.0615  decode.d1.loss_mask: 0.7002  decode.d1.loss_dice: 0.4185  decode.d2.loss_cls: 0.0495  decode.d2.loss_mask: 0.6997  decode.d2.loss_dice: 0.4208  decode.d3.loss_cls: 0.0319  decode.d3.loss_mask: 0.7012  decode.d3.loss_dice: 0.4210  decode.d4.loss_cls: 0.0470  decode.d4.loss_mask: 0.7140  decode.d4.loss_dice: 0.4234  decode.d5.loss_cls: 0.0470  decode.d5.loss_mask: 0.6919  decode.d5.loss_dice: 0.4238  decode.d6.loss_cls: 0.0317  decode.d6.loss_mask: 0.7058  decode.d6.loss_dice: 0.4247  decode.d7.loss_cls: 0.0378  decode.d7.loss_mask: 0.6947  decode.d7.loss_dice: 0.4198  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.7000  decode.d8.loss_dice: 0.4200
06/01 12:03:26 - mmengine - INFO - Iter(train) [147850/160000]  base_lr: 9.8268e-06 lr: 9.8268e-07  eta: 18:44:51  time: 0.6398  data_time: 0.0105  memory: 10507  grad_norm: 203.3952  loss: 12.3367  decode.loss_cls: 0.0343  decode.loss_mask: 0.6770  decode.loss_dice: 0.4634  decode.d0.loss_cls: 0.5094  decode.d0.loss_mask: 0.6530  decode.d0.loss_dice: 0.4496  decode.d1.loss_cls: 0.0376  decode.d1.loss_mask: 0.6830  decode.d1.loss_dice: 0.4809  decode.d2.loss_cls: 0.0391  decode.d2.loss_mask: 0.6819  decode.d2.loss_dice: 0.4762  decode.d3.loss_cls: 0.0348  decode.d3.loss_mask: 0.6828  decode.d3.loss_dice: 0.4859  decode.d4.loss_cls: 0.0314  decode.d4.loss_mask: 0.6834  decode.d4.loss_dice: 0.4675  decode.d5.loss_cls: 0.0340  decode.d5.loss_mask: 0.6842  decode.d5.loss_dice: 0.4691  decode.d6.loss_cls: 0.0338  decode.d6.loss_mask: 0.6863  decode.d6.loss_dice: 0.4728  decode.d7.loss_cls: 0.0377  decode.d7.loss_mask: 0.6831  decode.d7.loss_dice: 0.4694  decode.d8.loss_cls: 0.0363  decode.d8.loss_mask: 0.6889  decode.d8.loss_dice: 0.4699
06/01 12:03:58 - mmengine - INFO - Iter(train) [147900/160000]  base_lr: 9.7904e-06 lr: 9.7904e-07  eta: 18:23:08  time: 0.6380  data_time: 0.0103  memory: 10500  grad_norm: 571.3218  loss: 15.6789  decode.loss_cls: 0.0326  decode.loss_mask: 0.9165  decode.loss_dice: 0.5819  decode.d0.loss_cls: 0.5059  decode.d0.loss_mask: 0.8859  decode.d0.loss_dice: 0.5998  decode.d1.loss_cls: 0.0879  decode.d1.loss_mask: 0.8805  decode.d1.loss_dice: 0.5746  decode.d2.loss_cls: 0.0334  decode.d2.loss_mask: 0.9029  decode.d2.loss_dice: 0.5748  decode.d3.loss_cls: 0.0329  decode.d3.loss_mask: 0.8974  decode.d3.loss_dice: 0.5828  decode.d4.loss_cls: 0.0555  decode.d4.loss_mask: 0.8960  decode.d4.loss_dice: 0.5700  decode.d5.loss_cls: 0.0339  decode.d5.loss_mask: 0.8965  decode.d5.loss_dice: 0.5813  decode.d6.loss_cls: 0.0379  decode.d6.loss_mask: 0.9024  decode.d6.loss_dice: 0.5720  decode.d7.loss_cls: 0.0301  decode.d7.loss_mask: 0.9058  decode.d7.loss_dice: 0.5875  decode.d8.loss_cls: 0.0317  decode.d8.loss_mask: 0.9106  decode.d8.loss_dice: 0.5779
06/01 12:04:30 - mmengine - INFO - Iter(train) [147950/160000]  base_lr: 9.7540e-06 lr: 9.7540e-07  eta: 18:02:08  time: 0.6381  data_time: 0.0103  memory: 10510  grad_norm: 482.9929  loss: 16.4403  decode.loss_cls: 0.0844  decode.loss_mask: 0.8509  decode.loss_dice: 0.6593  decode.d0.loss_cls: 0.5116  decode.d0.loss_mask: 0.8482  decode.d0.loss_dice: 0.6535  decode.d1.loss_cls: 0.0816  decode.d1.loss_mask: 0.8603  decode.d1.loss_dice: 0.6680  decode.d2.loss_cls: 0.0703  decode.d2.loss_mask: 0.8695  decode.d2.loss_dice: 0.6766  decode.d3.loss_cls: 0.0520  decode.d3.loss_mask: 0.8794  decode.d3.loss_dice: 0.6703  decode.d4.loss_cls: 0.0710  decode.d4.loss_mask: 0.8716  decode.d4.loss_dice: 0.6607  decode.d5.loss_cls: 0.0734  decode.d5.loss_mask: 0.8771  decode.d5.loss_dice: 0.6762  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.8570  decode.d6.loss_dice: 0.6404  decode.d7.loss_cls: 0.0927  decode.d7.loss_mask: 0.8548  decode.d7.loss_dice: 0.6564  decode.d8.loss_cls: 0.1010  decode.d8.loss_mask: 0.8475  decode.d8.loss_dice: 0.6617
06/01 12:05:01 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 12:05:01 - mmengine - INFO - Iter(train) [148000/160000]  base_lr: 9.7176e-06 lr: 9.7176e-07  eta: 17:41:48  time: 0.6378  data_time: 0.0103  memory: 10505  grad_norm: 267.3036  loss: 13.3743  decode.loss_cls: 0.0203  decode.loss_mask: 0.8179  decode.loss_dice: 0.4550  decode.d0.loss_cls: 0.3992  decode.d0.loss_mask: 0.8326  decode.d0.loss_dice: 0.4479  decode.d1.loss_cls: 0.0176  decode.d1.loss_mask: 0.8232  decode.d1.loss_dice: 0.4595  decode.d2.loss_cls: 0.0216  decode.d2.loss_mask: 0.8213  decode.d2.loss_dice: 0.4558  decode.d3.loss_cls: 0.0197  decode.d3.loss_mask: 0.8223  decode.d3.loss_dice: 0.4537  decode.d4.loss_cls: 0.0209  decode.d4.loss_mask: 0.8266  decode.d4.loss_dice: 0.4601  decode.d5.loss_cls: 0.0215  decode.d5.loss_mask: 0.8190  decode.d5.loss_dice: 0.4584  decode.d6.loss_cls: 0.0213  decode.d6.loss_mask: 0.8273  decode.d6.loss_dice: 0.4591  decode.d7.loss_cls: 0.0219  decode.d7.loss_mask: 0.8227  decode.d7.loss_dice: 0.4547  decode.d8.loss_cls: 0.0208  decode.d8.loss_mask: 0.8178  decode.d8.loss_dice: 0.4544
06/01 12:05:33 - mmengine - INFO - Iter(train) [148050/160000]  base_lr: 9.6811e-06 lr: 9.6811e-07  eta: 17:22:07  time: 0.6376  data_time: 0.0103  memory: 10523  grad_norm: 400.1919  loss: 14.6591  decode.loss_cls: 0.0765  decode.loss_mask: 0.7704  decode.loss_dice: 0.5613  decode.d0.loss_cls: 0.5596  decode.d0.loss_mask: 0.7601  decode.d0.loss_dice: 0.5670  decode.d1.loss_cls: 0.0491  decode.d1.loss_mask: 0.7838  decode.d1.loss_dice: 0.5866  decode.d2.loss_cls: 0.0639  decode.d2.loss_mask: 0.7818  decode.d2.loss_dice: 0.5781  decode.d3.loss_cls: 0.0847  decode.d3.loss_mask: 0.7724  decode.d3.loss_dice: 0.5644  decode.d4.loss_cls: 0.0687  decode.d4.loss_mask: 0.7590  decode.d4.loss_dice: 0.5771  decode.d5.loss_cls: 0.0850  decode.d5.loss_mask: 0.7676  decode.d5.loss_dice: 0.5612  decode.d6.loss_cls: 0.0829  decode.d6.loss_mask: 0.7793  decode.d6.loss_dice: 0.5787  decode.d7.loss_cls: 0.0774  decode.d7.loss_mask: 0.7653  decode.d7.loss_dice: 0.5752  decode.d8.loss_cls: 0.0791  decode.d8.loss_mask: 0.7739  decode.d8.loss_dice: 0.5691
06/01 12:06:05 - mmengine - INFO - Iter(train) [148100/160000]  base_lr: 9.6447e-06 lr: 9.6447e-07  eta: 17:03:04  time: 0.6376  data_time: 0.0103  memory: 10529  grad_norm: 210.9504  loss: 13.1556  decode.loss_cls: 0.0409  decode.loss_mask: 0.7060  decode.loss_dice: 0.5418  decode.d0.loss_cls: 0.3562  decode.d0.loss_mask: 0.7111  decode.d0.loss_dice: 0.5441  decode.d1.loss_cls: 0.0121  decode.d1.loss_mask: 0.7133  decode.d1.loss_dice: 0.5500  decode.d2.loss_cls: 0.0127  decode.d2.loss_mask: 0.7175  decode.d2.loss_dice: 0.5537  decode.d3.loss_cls: 0.0109  decode.d3.loss_mask: 0.7126  decode.d3.loss_dice: 0.5517  decode.d4.loss_cls: 0.0341  decode.d4.loss_mask: 0.7123  decode.d4.loss_dice: 0.5439  decode.d5.loss_cls: 0.0109  decode.d5.loss_mask: 0.7146  decode.d5.loss_dice: 0.5530  decode.d6.loss_cls: 0.0346  decode.d6.loss_mask: 0.7052  decode.d6.loss_dice: 0.5385  decode.d7.loss_cls: 0.0103  decode.d7.loss_mask: 0.7170  decode.d7.loss_dice: 0.5557  decode.d8.loss_cls: 0.0440  decode.d8.loss_mask: 0.7075  decode.d8.loss_dice: 0.5394
06/01 12:06:37 - mmengine - INFO - Iter(train) [148150/160000]  base_lr: 9.6082e-06 lr: 9.6082e-07  eta: 16:44:36  time: 0.6380  data_time: 0.0103  memory: 10500  grad_norm: 244.9130  loss: 12.4277  decode.loss_cls: 0.0489  decode.loss_mask: 0.6699  decode.loss_dice: 0.4965  decode.d0.loss_cls: 0.4594  decode.d0.loss_mask: 0.6717  decode.d0.loss_dice: 0.4862  decode.d1.loss_cls: 0.0397  decode.d1.loss_mask: 0.6790  decode.d1.loss_dice: 0.4960  decode.d2.loss_cls: 0.0385  decode.d2.loss_mask: 0.6755  decode.d2.loss_dice: 0.4823  decode.d3.loss_cls: 0.0194  decode.d3.loss_mask: 0.6710  decode.d3.loss_dice: 0.4960  decode.d4.loss_cls: 0.0203  decode.d4.loss_mask: 0.6796  decode.d4.loss_dice: 0.4954  decode.d5.loss_cls: 0.0351  decode.d5.loss_mask: 0.6758  decode.d5.loss_dice: 0.4906  decode.d6.loss_cls: 0.0356  decode.d6.loss_mask: 0.6786  decode.d6.loss_dice: 0.4924  decode.d7.loss_cls: 0.0346  decode.d7.loss_mask: 0.6775  decode.d7.loss_dice: 0.4914  decode.d8.loss_cls: 0.0189  decode.d8.loss_mask: 0.6760  decode.d8.loss_dice: 0.4960
06/01 12:07:09 - mmengine - INFO - Iter(train) [148200/160000]  base_lr: 9.5717e-06 lr: 9.5717e-07  eta: 16:26:42  time: 0.6378  data_time: 0.0103  memory: 10506  grad_norm: 231.3109  loss: 14.1287  decode.loss_cls: 0.0810  decode.loss_mask: 0.7810  decode.loss_dice: 0.4974  decode.d0.loss_cls: 0.5020  decode.d0.loss_mask: 0.7863  decode.d0.loss_dice: 0.5046  decode.d1.loss_cls: 0.0772  decode.d1.loss_mask: 0.7952  decode.d1.loss_dice: 0.5072  decode.d2.loss_cls: 0.0812  decode.d2.loss_mask: 0.7834  decode.d2.loss_dice: 0.5032  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.7944  decode.d3.loss_dice: 0.5050  decode.d4.loss_cls: 0.0735  decode.d4.loss_mask: 0.7906  decode.d4.loss_dice: 0.5186  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.7928  decode.d5.loss_dice: 0.5143  decode.d6.loss_cls: 0.0749  decode.d6.loss_mask: 0.7860  decode.d6.loss_dice: 0.5031  decode.d7.loss_cls: 0.0763  decode.d7.loss_mask: 0.7916  decode.d7.loss_dice: 0.5015  decode.d8.loss_cls: 0.0889  decode.d8.loss_mask: 0.7868  decode.d8.loss_dice: 0.5002
06/01 12:07:41 - mmengine - INFO - Iter(train) [148250/160000]  base_lr: 9.5352e-06 lr: 9.5352e-07  eta: 16:09:19  time: 0.6483  data_time: 0.0103  memory: 10497  grad_norm: 356.3856  loss: 15.6301  decode.loss_cls: 0.1268  decode.loss_mask: 0.8333  decode.loss_dice: 0.5809  decode.d0.loss_cls: 0.4873  decode.d0.loss_mask: 0.8530  decode.d0.loss_dice: 0.5964  decode.d1.loss_cls: 0.1238  decode.d1.loss_mask: 0.8242  decode.d1.loss_dice: 0.5743  decode.d2.loss_cls: 0.1253  decode.d2.loss_mask: 0.8239  decode.d2.loss_dice: 0.5588  decode.d3.loss_cls: 0.1333  decode.d3.loss_mask: 0.8271  decode.d3.loss_dice: 0.5755  decode.d4.loss_cls: 0.1117  decode.d4.loss_mask: 0.8191  decode.d4.loss_dice: 0.5625  decode.d5.loss_cls: 0.1199  decode.d5.loss_mask: 0.8220  decode.d5.loss_dice: 0.5692  decode.d6.loss_cls: 0.1223  decode.d6.loss_mask: 0.8261  decode.d6.loss_dice: 0.5611  decode.d7.loss_cls: 0.1426  decode.d7.loss_mask: 0.8492  decode.d7.loss_dice: 0.5727  decode.d8.loss_cls: 0.1228  decode.d8.loss_mask: 0.8242  decode.d8.loss_dice: 0.5608
06/01 12:08:13 - mmengine - INFO - Iter(train) [148300/160000]  base_lr: 9.4986e-06 lr: 9.4986e-07  eta: 15:52:28  time: 0.6388  data_time: 0.0103  memory: 10523  grad_norm: 205.7497  loss: 13.9386  decode.loss_cls: 0.0360  decode.loss_mask: 0.7653  decode.loss_dice: 0.5572  decode.d0.loss_cls: 0.3566  decode.d0.loss_mask: 0.7679  decode.d0.loss_dice: 0.5527  decode.d1.loss_cls: 0.0391  decode.d1.loss_mask: 0.7697  decode.d1.loss_dice: 0.5576  decode.d2.loss_cls: 0.0383  decode.d2.loss_mask: 0.7693  decode.d2.loss_dice: 0.5601  decode.d3.loss_cls: 0.0343  decode.d3.loss_mask: 0.7638  decode.d3.loss_dice: 0.5536  decode.d4.loss_cls: 0.0351  decode.d4.loss_mask: 0.7693  decode.d4.loss_dice: 0.5544  decode.d5.loss_cls: 0.0384  decode.d5.loss_mask: 0.7676  decode.d5.loss_dice: 0.5575  decode.d6.loss_cls: 0.0432  decode.d6.loss_mask: 0.7677  decode.d6.loss_dice: 0.5559  decode.d7.loss_cls: 0.0302  decode.d7.loss_mask: 0.7728  decode.d7.loss_dice: 0.5623  decode.d8.loss_cls: 0.0363  decode.d8.loss_mask: 0.7700  decode.d8.loss_dice: 0.5563
06/01 12:08:45 - mmengine - INFO - Iter(train) [148350/160000]  base_lr: 9.4621e-06 lr: 9.4621e-07  eta: 15:36:05  time: 0.6379  data_time: 0.0103  memory: 10499  grad_norm: 369.9647  loss: 16.0341  decode.loss_cls: 0.1691  decode.loss_mask: 0.8248  decode.loss_dice: 0.5619  decode.d0.loss_cls: 0.5788  decode.d0.loss_mask: 0.8661  decode.d0.loss_dice: 0.5987  decode.d1.loss_cls: 0.1050  decode.d1.loss_mask: 0.8504  decode.d1.loss_dice: 0.6070  decode.d2.loss_cls: 0.1338  decode.d2.loss_mask: 0.8498  decode.d2.loss_dice: 0.5967  decode.d3.loss_cls: 0.1534  decode.d3.loss_mask: 0.8214  decode.d3.loss_dice: 0.5747  decode.d4.loss_cls: 0.1606  decode.d4.loss_mask: 0.8272  decode.d4.loss_dice: 0.5593  decode.d5.loss_cls: 0.1406  decode.d5.loss_mask: 0.8412  decode.d5.loss_dice: 0.5743  decode.d6.loss_cls: 0.1685  decode.d6.loss_mask: 0.8196  decode.d6.loss_dice: 0.5567  decode.d7.loss_cls: 0.1620  decode.d7.loss_mask: 0.8171  decode.d7.loss_dice: 0.5636  decode.d8.loss_cls: 0.1650  decode.d8.loss_mask: 0.8264  decode.d8.loss_dice: 0.5604
06/01 12:09:17 - mmengine - INFO - Iter(train) [148400/160000]  base_lr: 9.4255e-06 lr: 9.4255e-07  eta: 15:20:10  time: 0.6378  data_time: 0.0103  memory: 10499  grad_norm: 469.8898  loss: 13.9648  decode.loss_cls: 0.0589  decode.loss_mask: 0.8097  decode.loss_dice: 0.5215  decode.d0.loss_cls: 0.5049  decode.d0.loss_mask: 0.7665  decode.d0.loss_dice: 0.5236  decode.d1.loss_cls: 0.0557  decode.d1.loss_mask: 0.7784  decode.d1.loss_dice: 0.5240  decode.d2.loss_cls: 0.0468  decode.d2.loss_mask: 0.7853  decode.d2.loss_dice: 0.5114  decode.d3.loss_cls: 0.0434  decode.d3.loss_mask: 0.7788  decode.d3.loss_dice: 0.5121  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.7775  decode.d4.loss_dice: 0.5110  decode.d5.loss_cls: 0.0470  decode.d5.loss_mask: 0.7774  decode.d5.loss_dice: 0.5103  decode.d6.loss_cls: 0.0707  decode.d6.loss_mask: 0.7788  decode.d6.loss_dice: 0.5102  decode.d7.loss_cls: 0.0591  decode.d7.loss_mask: 0.7806  decode.d7.loss_dice: 0.5075  decode.d8.loss_cls: 0.0610  decode.d8.loss_mask: 0.7889  decode.d8.loss_dice: 0.5094
06/01 12:09:49 - mmengine - INFO - Iter(train) [148450/160000]  base_lr: 9.3890e-06 lr: 9.3890e-07  eta: 15:04:43  time: 0.6386  data_time: 0.0103  memory: 10506  grad_norm: 323.4214  loss: 14.5453  decode.loss_cls: 0.1252  decode.loss_mask: 0.7393  decode.loss_dice: 0.5276  decode.d0.loss_cls: 0.5116  decode.d0.loss_mask: 0.7716  decode.d0.loss_dice: 0.5658  decode.d1.loss_cls: 0.0786  decode.d1.loss_mask: 0.7837  decode.d1.loss_dice: 0.5356  decode.d2.loss_cls: 0.0421  decode.d2.loss_mask: 0.8520  decode.d2.loss_dice: 0.5457  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.7939  decode.d3.loss_dice: 0.5356  decode.d4.loss_cls: 0.0813  decode.d4.loss_mask: 0.8146  decode.d4.loss_dice: 0.5435  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.7712  decode.d5.loss_dice: 0.5385  decode.d6.loss_cls: 0.0886  decode.d6.loss_mask: 0.7720  decode.d6.loss_dice: 0.5333  decode.d7.loss_cls: 0.0448  decode.d7.loss_mask: 0.8431  decode.d7.loss_dice: 0.5377  decode.d8.loss_cls: 0.1157  decode.d8.loss_mask: 0.7676  decode.d8.loss_dice: 0.5259
06/01 12:10:21 - mmengine - INFO - Iter(train) [148500/160000]  base_lr: 9.3524e-06 lr: 9.3524e-07  eta: 14:49:40  time: 0.6368  data_time: 0.0103  memory: 10497  grad_norm: 956.7751  loss: 14.3293  decode.loss_cls: 0.1036  decode.loss_mask: 0.7224  decode.loss_dice: 0.5650  decode.d0.loss_cls: 0.4952  decode.d0.loss_mask: 0.7745  decode.d0.loss_dice: 0.5877  decode.d1.loss_cls: 0.1636  decode.d1.loss_mask: 0.6954  decode.d1.loss_dice: 0.5583  decode.d2.loss_cls: 0.0954  decode.d2.loss_mask: 0.7212  decode.d2.loss_dice: 0.5575  decode.d3.loss_cls: 0.0960  decode.d3.loss_mask: 0.7286  decode.d3.loss_dice: 0.5648  decode.d4.loss_cls: 0.0949  decode.d4.loss_mask: 0.7206  decode.d4.loss_dice: 0.5699  decode.d5.loss_cls: 0.0955  decode.d5.loss_mask: 0.7230  decode.d5.loss_dice: 0.5709  decode.d6.loss_cls: 0.1041  decode.d6.loss_mask: 0.7260  decode.d6.loss_dice: 0.5750  decode.d7.loss_cls: 0.0997  decode.d7.loss_mask: 0.7170  decode.d7.loss_dice: 0.5655  decode.d8.loss_cls: 0.1066  decode.d8.loss_mask: 0.6955  decode.d8.loss_dice: 0.5361
06/01 12:10:53 - mmengine - INFO - Iter(train) [148550/160000]  base_lr: 9.3158e-06 lr: 9.3158e-07  eta: 14:35:03  time: 0.6384  data_time: 0.0103  memory: 10514  grad_norm: 472.9802  loss: 14.8864  decode.loss_cls: 0.0988  decode.loss_mask: 0.8062  decode.loss_dice: 0.5579  decode.d0.loss_cls: 0.5070  decode.d0.loss_mask: 0.7998  decode.d0.loss_dice: 0.5540  decode.d1.loss_cls: 0.0931  decode.d1.loss_mask: 0.8137  decode.d1.loss_dice: 0.5644  decode.d2.loss_cls: 0.0732  decode.d2.loss_mask: 0.8040  decode.d2.loss_dice: 0.5527  decode.d3.loss_cls: 0.0771  decode.d3.loss_mask: 0.7924  decode.d3.loss_dice: 0.5609  decode.d4.loss_cls: 0.1037  decode.d4.loss_mask: 0.7960  decode.d4.loss_dice: 0.5527  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 0.7957  decode.d5.loss_dice: 0.5544  decode.d6.loss_cls: 0.0869  decode.d6.loss_mask: 0.8159  decode.d6.loss_dice: 0.5532  decode.d7.loss_cls: 0.0829  decode.d7.loss_mask: 0.7978  decode.d7.loss_dice: 0.5512  decode.d8.loss_cls: 0.0867  decode.d8.loss_mask: 0.7978  decode.d8.loss_dice: 0.5704
06/01 12:11:25 - mmengine - INFO - Iter(train) [148600/160000]  base_lr: 9.2792e-06 lr: 9.2792e-07  eta: 14:20:48  time: 0.6391  data_time: 0.0103  memory: 10510  grad_norm: 517.7302  loss: 16.5623  decode.loss_cls: 0.1350  decode.loss_mask: 0.8637  decode.loss_dice: 0.6272  decode.d0.loss_cls: 0.4481  decode.d0.loss_mask: 0.8597  decode.d0.loss_dice: 0.6303  decode.d1.loss_cls: 0.1549  decode.d1.loss_mask: 0.8597  decode.d1.loss_dice: 0.6044  decode.d2.loss_cls: 0.1441  decode.d2.loss_mask: 0.8628  decode.d2.loss_dice: 0.6275  decode.d3.loss_cls: 0.1290  decode.d3.loss_mask: 0.8641  decode.d3.loss_dice: 0.6384  decode.d4.loss_cls: 0.1285  decode.d4.loss_mask: 0.8711  decode.d4.loss_dice: 0.6518  decode.d5.loss_cls: 0.1539  decode.d5.loss_mask: 0.8542  decode.d5.loss_dice: 0.6262  decode.d6.loss_cls: 0.1425  decode.d6.loss_mask: 0.8551  decode.d6.loss_dice: 0.6151  decode.d7.loss_cls: 0.1354  decode.d7.loss_mask: 0.8492  decode.d7.loss_dice: 0.6305  decode.d8.loss_cls: 0.1369  decode.d8.loss_mask: 0.8480  decode.d8.loss_dice: 0.6149
06/01 12:11:57 - mmengine - INFO - Iter(train) [148650/160000]  base_lr: 9.2425e-06 lr: 9.2425e-07  eta: 14:06:57  time: 0.6378  data_time: 0.0103  memory: 10500  grad_norm: 495.4887  loss: 14.4315  decode.loss_cls: 0.0463  decode.loss_mask: 0.8116  decode.loss_dice: 0.5404  decode.d0.loss_cls: 0.4461  decode.d0.loss_mask: 0.7771  decode.d0.loss_dice: 0.5149  decode.d1.loss_cls: 0.0937  decode.d1.loss_mask: 0.7992  decode.d1.loss_dice: 0.5243  decode.d2.loss_cls: 0.0547  decode.d2.loss_mask: 0.8078  decode.d2.loss_dice: 0.5330  decode.d3.loss_cls: 0.0521  decode.d3.loss_mask: 0.8132  decode.d3.loss_dice: 0.5302  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 0.8065  decode.d4.loss_dice: 0.5415  decode.d5.loss_cls: 0.0567  decode.d5.loss_mask: 0.7998  decode.d5.loss_dice: 0.5490  decode.d6.loss_cls: 0.0723  decode.d6.loss_mask: 0.8246  decode.d6.loss_dice: 0.5594  decode.d7.loss_cls: 0.0486  decode.d7.loss_mask: 0.8224  decode.d7.loss_dice: 0.5480  decode.d8.loss_cls: 0.0469  decode.d8.loss_mask: 0.8033  decode.d8.loss_dice: 0.5383
06/01 12:12:29 - mmengine - INFO - Iter(train) [148700/160000]  base_lr: 9.2059e-06 lr: 9.2059e-07  eta: 13:53:26  time: 0.6379  data_time: 0.0103  memory: 10511  grad_norm: 545.8129  loss: 16.5384  decode.loss_cls: 0.0797  decode.loss_mask: 0.8853  decode.loss_dice: 0.6337  decode.d0.loss_cls: 0.4884  decode.d0.loss_mask: 0.9080  decode.d0.loss_dice: 0.6432  decode.d1.loss_cls: 0.1341  decode.d1.loss_mask: 0.8541  decode.d1.loss_dice: 0.6396  decode.d2.loss_cls: 0.0854  decode.d2.loss_mask: 0.8767  decode.d2.loss_dice: 0.6345  decode.d3.loss_cls: 0.0922  decode.d3.loss_mask: 0.8783  decode.d3.loss_dice: 0.6381  decode.d4.loss_cls: 0.0828  decode.d4.loss_mask: 0.8800  decode.d4.loss_dice: 0.6312  decode.d5.loss_cls: 0.0872  decode.d5.loss_mask: 0.8986  decode.d5.loss_dice: 0.6447  decode.d6.loss_cls: 0.0832  decode.d6.loss_mask: 0.8845  decode.d6.loss_dice: 0.6385  decode.d7.loss_cls: 0.0858  decode.d7.loss_mask: 0.8898  decode.d7.loss_dice: 0.6388  decode.d8.loss_cls: 0.0892  decode.d8.loss_mask: 0.8940  decode.d8.loss_dice: 0.6387
06/01 12:13:01 - mmengine - INFO - Iter(train) [148750/160000]  base_lr: 9.1692e-06 lr: 9.1692e-07  eta: 13:40:17  time: 0.6390  data_time: 0.0104  memory: 10506  grad_norm: 637.5436  loss: 14.9822  decode.loss_cls: 0.0557  decode.loss_mask: 0.8594  decode.loss_dice: 0.5573  decode.d0.loss_cls: 0.4158  decode.d0.loss_mask: 0.8601  decode.d0.loss_dice: 0.5411  decode.d1.loss_cls: 0.0333  decode.d1.loss_mask: 0.8586  decode.d1.loss_dice: 0.5717  decode.d2.loss_cls: 0.0582  decode.d2.loss_mask: 0.8560  decode.d2.loss_dice: 0.5525  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.8603  decode.d3.loss_dice: 0.5458  decode.d4.loss_cls: 0.0329  decode.d4.loss_mask: 0.8573  decode.d4.loss_dice: 0.5528  decode.d5.loss_cls: 0.0537  decode.d5.loss_mask: 0.8587  decode.d5.loss_dice: 0.5601  decode.d6.loss_cls: 0.0565  decode.d6.loss_mask: 0.8562  decode.d6.loss_dice: 0.5479  decode.d7.loss_cls: 0.0597  decode.d7.loss_mask: 0.8600  decode.d7.loss_dice: 0.5352  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.8642  decode.d8.loss_dice: 0.5445
06/01 12:13:32 - mmengine - INFO - Iter(train) [148800/160000]  base_lr: 9.1325e-06 lr: 9.1325e-07  eta: 13:27:28  time: 0.6389  data_time: 0.0103  memory: 10499  grad_norm: 305.8169  loss: 16.1859  decode.loss_cls: 0.1768  decode.loss_mask: 0.8121  decode.loss_dice: 0.5829  decode.d0.loss_cls: 0.5228  decode.d0.loss_mask: 0.8200  decode.d0.loss_dice: 0.6001  decode.d1.loss_cls: 0.2152  decode.d1.loss_mask: 0.8189  decode.d1.loss_dice: 0.5833  decode.d2.loss_cls: 0.1813  decode.d2.loss_mask: 0.8109  decode.d2.loss_dice: 0.5881  decode.d3.loss_cls: 0.1770  decode.d3.loss_mask: 0.8238  decode.d3.loss_dice: 0.5759  decode.d4.loss_cls: 0.1937  decode.d4.loss_mask: 0.8028  decode.d4.loss_dice: 0.5773  decode.d5.loss_cls: 0.1790  decode.d5.loss_mask: 0.8126  decode.d5.loss_dice: 0.5838  decode.d6.loss_cls: 0.1962  decode.d6.loss_mask: 0.8062  decode.d6.loss_dice: 0.5784  decode.d7.loss_cls: 0.1907  decode.d7.loss_mask: 0.8107  decode.d7.loss_dice: 0.5974  decode.d8.loss_cls: 0.1726  decode.d8.loss_mask: 0.8067  decode.d8.loss_dice: 0.5887
06/01 12:14:04 - mmengine - INFO - Iter(train) [148850/160000]  base_lr: 9.0958e-06 lr: 9.0958e-07  eta: 13:14:58  time: 0.6394  data_time: 0.0104  memory: 10510  grad_norm: 805.2530  loss: 15.6278  decode.loss_cls: 0.0810  decode.loss_mask: 0.8792  decode.loss_dice: 0.5567  decode.d0.loss_cls: 0.4468  decode.d0.loss_mask: 0.9074  decode.d0.loss_dice: 0.5561  decode.d1.loss_cls: 0.0885  decode.d1.loss_mask: 0.8771  decode.d1.loss_dice: 0.5362  decode.d2.loss_cls: 0.0911  decode.d2.loss_mask: 0.8827  decode.d2.loss_dice: 0.5447  decode.d3.loss_cls: 0.0894  decode.d3.loss_mask: 0.8889  decode.d3.loss_dice: 0.5557  decode.d4.loss_cls: 0.0864  decode.d4.loss_mask: 0.8850  decode.d4.loss_dice: 0.5630  decode.d5.loss_cls: 0.0841  decode.d5.loss_mask: 0.8900  decode.d5.loss_dice: 0.5656  decode.d6.loss_cls: 0.0920  decode.d6.loss_mask: 0.8800  decode.d6.loss_dice: 0.5395  decode.d7.loss_cls: 0.0866  decode.d7.loss_mask: 0.8778  decode.d7.loss_dice: 0.5680  decode.d8.loss_cls: 0.0922  decode.d8.loss_mask: 0.8797  decode.d8.loss_dice: 0.5565
06/01 12:14:36 - mmengine - INFO - Iter(train) [148900/160000]  base_lr: 9.0591e-06 lr: 9.0591e-07  eta: 13:02:46  time: 0.6387  data_time: 0.0103  memory: 10500  grad_norm: 706.5943  loss: 13.4246  decode.loss_cls: 0.0220  decode.loss_mask: 0.7669  decode.loss_dice: 0.5150  decode.d0.loss_cls: 0.5367  decode.d0.loss_mask: 0.7266  decode.d0.loss_dice: 0.4992  decode.d1.loss_cls: 0.0193  decode.d1.loss_mask: 0.7690  decode.d1.loss_dice: 0.5155  decode.d2.loss_cls: 0.0176  decode.d2.loss_mask: 0.7654  decode.d2.loss_dice: 0.5080  decode.d3.loss_cls: 0.0165  decode.d3.loss_mask: 0.7614  decode.d3.loss_dice: 0.5092  decode.d4.loss_cls: 0.0170  decode.d4.loss_mask: 0.7618  decode.d4.loss_dice: 0.5145  decode.d5.loss_cls: 0.0166  decode.d5.loss_mask: 0.7581  decode.d5.loss_dice: 0.5077  decode.d6.loss_cls: 0.0168  decode.d6.loss_mask: 0.7602  decode.d6.loss_dice: 0.5150  decode.d7.loss_cls: 0.0216  decode.d7.loss_mask: 0.7711  decode.d7.loss_dice: 0.5152  decode.d8.loss_cls: 0.0183  decode.d8.loss_mask: 0.7658  decode.d8.loss_dice: 0.5165
06/01 12:15:08 - mmengine - INFO - Iter(train) [148950/160000]  base_lr: 9.0224e-06 lr: 9.0224e-07  eta: 12:50:52  time: 0.6388  data_time: 0.0103  memory: 10507  grad_norm: 226.8329  loss: 13.1335  decode.loss_cls: 0.0157  decode.loss_mask: 0.7225  decode.loss_dice: 0.5456  decode.d0.loss_cls: 0.4013  decode.d0.loss_mask: 0.7077  decode.d0.loss_dice: 0.5338  decode.d1.loss_cls: 0.0193  decode.d1.loss_mask: 0.7265  decode.d1.loss_dice: 0.5466  decode.d2.loss_cls: 0.0155  decode.d2.loss_mask: 0.7243  decode.d2.loss_dice: 0.5334  decode.d3.loss_cls: 0.0176  decode.d3.loss_mask: 0.7276  decode.d3.loss_dice: 0.5364  decode.d4.loss_cls: 0.0154  decode.d4.loss_mask: 0.7238  decode.d4.loss_dice: 0.5274  decode.d5.loss_cls: 0.0146  decode.d5.loss_mask: 0.7292  decode.d5.loss_dice: 0.5311  decode.d6.loss_cls: 0.0148  decode.d6.loss_mask: 0.7225  decode.d6.loss_dice: 0.5386  decode.d7.loss_cls: 0.0144  decode.d7.loss_mask: 0.7212  decode.d7.loss_dice: 0.5333  decode.d8.loss_cls: 0.0152  decode.d8.loss_mask: 0.7190  decode.d8.loss_dice: 0.5390
06/01 12:15:40 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 12:15:40 - mmengine - INFO - Iter(train) [149000/160000]  base_lr: 8.9856e-06 lr: 8.9856e-07  eta: 12:39:15  time: 0.6389  data_time: 0.0103  memory: 10499  grad_norm: 225.5839  loss: 13.5080  decode.loss_cls: 0.0580  decode.loss_mask: 0.7235  decode.loss_dice: 0.5226  decode.d0.loss_cls: 0.5169  decode.d0.loss_mask: 0.7031  decode.d0.loss_dice: 0.5106  decode.d1.loss_cls: 0.0903  decode.d1.loss_mask: 0.7177  decode.d1.loss_dice: 0.5212  decode.d2.loss_cls: 0.0703  decode.d2.loss_mask: 0.7126  decode.d2.loss_dice: 0.5275  decode.d3.loss_cls: 0.0652  decode.d3.loss_mask: 0.7236  decode.d3.loss_dice: 0.5279  decode.d4.loss_cls: 0.0636  decode.d4.loss_mask: 0.7202  decode.d4.loss_dice: 0.5302  decode.d5.loss_cls: 0.0566  decode.d5.loss_mask: 0.7185  decode.d5.loss_dice: 0.5212  decode.d6.loss_cls: 0.0523  decode.d6.loss_mask: 0.7195  decode.d6.loss_dice: 0.5219  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.7198  decode.d7.loss_dice: 0.5330  decode.d8.loss_cls: 0.0565  decode.d8.loss_mask: 0.7187  decode.d8.loss_dice: 0.5285
06/01 12:16:12 - mmengine - INFO - Iter(train) [149050/160000]  base_lr: 8.9488e-06 lr: 8.9488e-07  eta: 12:27:54  time: 0.6380  data_time: 0.0103  memory: 10507  grad_norm: 487.0834  loss: 14.2803  decode.loss_cls: 0.1129  decode.loss_mask: 0.7481  decode.loss_dice: 0.5372  decode.d0.loss_cls: 0.4734  decode.d0.loss_mask: 0.7559  decode.d0.loss_dice: 0.5371  decode.d1.loss_cls: 0.1121  decode.d1.loss_mask: 0.7484  decode.d1.loss_dice: 0.5327  decode.d2.loss_cls: 0.1057  decode.d2.loss_mask: 0.7461  decode.d2.loss_dice: 0.5274  decode.d3.loss_cls: 0.0820  decode.d3.loss_mask: 0.7663  decode.d3.loss_dice: 0.5478  decode.d4.loss_cls: 0.0914  decode.d4.loss_mask: 0.7642  decode.d4.loss_dice: 0.5349  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 0.7613  decode.d5.loss_dice: 0.5384  decode.d6.loss_cls: 0.0825  decode.d6.loss_mask: 0.7563  decode.d6.loss_dice: 0.5330  decode.d7.loss_cls: 0.0926  decode.d7.loss_mask: 0.7698  decode.d7.loss_dice: 0.5466  decode.d8.loss_cls: 0.0939  decode.d8.loss_mask: 0.7632  decode.d8.loss_dice: 0.5401
06/01 12:16:44 - mmengine - INFO - Iter(train) [149100/160000]  base_lr: 8.9121e-06 lr: 8.9121e-07  eta: 12:16:49  time: 0.6384  data_time: 0.0103  memory: 10502  grad_norm: 374.2767  loss: 14.4434  decode.loss_cls: 0.0696  decode.loss_mask: 0.7847  decode.loss_dice: 0.5234  decode.d0.loss_cls: 0.5698  decode.d0.loss_mask: 0.7759  decode.d0.loss_dice: 0.5165  decode.d1.loss_cls: 0.0934  decode.d1.loss_mask: 0.7926  decode.d1.loss_dice: 0.5243  decode.d2.loss_cls: 0.0720  decode.d2.loss_mask: 0.7929  decode.d2.loss_dice: 0.5347  decode.d3.loss_cls: 0.0907  decode.d3.loss_mask: 0.7912  decode.d3.loss_dice: 0.5237  decode.d4.loss_cls: 0.0866  decode.d4.loss_mask: 0.7959  decode.d4.loss_dice: 0.5402  decode.d5.loss_cls: 0.0821  decode.d5.loss_mask: 0.7945  decode.d5.loss_dice: 0.5347  decode.d6.loss_cls: 0.0679  decode.d6.loss_mask: 0.7911  decode.d6.loss_dice: 0.5283  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 0.7967  decode.d7.loss_dice: 0.5291  decode.d8.loss_cls: 0.0716  decode.d8.loss_mask: 0.7890  decode.d8.loss_dice: 0.5203
06/01 12:17:16 - mmengine - INFO - Iter(train) [149150/160000]  base_lr: 8.8753e-06 lr: 8.8753e-07  eta: 12:06:00  time: 0.6394  data_time: 0.0104  memory: 10500  grad_norm: 537.7629  loss: 15.6398  decode.loss_cls: 0.0892  decode.loss_mask: 0.8425  decode.loss_dice: 0.5548  decode.d0.loss_cls: 0.5112  decode.d0.loss_mask: 0.8415  decode.d0.loss_dice: 0.5629  decode.d1.loss_cls: 0.1302  decode.d1.loss_mask: 0.8544  decode.d1.loss_dice: 0.5807  decode.d2.loss_cls: 0.0945  decode.d2.loss_mask: 0.8877  decode.d2.loss_dice: 0.5698  decode.d3.loss_cls: 0.1266  decode.d3.loss_mask: 0.8180  decode.d3.loss_dice: 0.5414  decode.d4.loss_cls: 0.1023  decode.d4.loss_mask: 0.8588  decode.d4.loss_dice: 0.5611  decode.d5.loss_cls: 0.0845  decode.d5.loss_mask: 0.8774  decode.d5.loss_dice: 0.5851  decode.d6.loss_cls: 0.0936  decode.d6.loss_mask: 0.8717  decode.d6.loss_dice: 0.5873  decode.d7.loss_cls: 0.0958  decode.d7.loss_mask: 0.8542  decode.d7.loss_dice: 0.5615  decode.d8.loss_cls: 0.1094  decode.d8.loss_mask: 0.8421  decode.d8.loss_dice: 0.5496
06/01 12:17:48 - mmengine - INFO - Iter(train) [149200/160000]  base_lr: 8.8384e-06 lr: 8.8384e-07  eta: 11:55:25  time: 0.6384  data_time: 0.0103  memory: 10502  grad_norm: 1610.3745  loss: 14.2294  decode.loss_cls: 0.0344  decode.loss_mask: 0.8066  decode.loss_dice: 0.5405  decode.d0.loss_cls: 0.4771  decode.d0.loss_mask: 0.7523  decode.d0.loss_dice: 0.5404  decode.d1.loss_cls: 0.0379  decode.d1.loss_mask: 0.8029  decode.d1.loss_dice: 0.5411  decode.d2.loss_cls: 0.0374  decode.d2.loss_mask: 0.8016  decode.d2.loss_dice: 0.5388  decode.d3.loss_cls: 0.0393  decode.d3.loss_mask: 0.8073  decode.d3.loss_dice: 0.5382  decode.d4.loss_cls: 0.0365  decode.d4.loss_mask: 0.8107  decode.d4.loss_dice: 0.5409  decode.d5.loss_cls: 0.0408  decode.d5.loss_mask: 0.8093  decode.d5.loss_dice: 0.5442  decode.d6.loss_cls: 0.0416  decode.d6.loss_mask: 0.8079  decode.d6.loss_dice: 0.5384  decode.d7.loss_cls: 0.0363  decode.d7.loss_mask: 0.8067  decode.d7.loss_dice: 0.5398  decode.d8.loss_cls: 0.0382  decode.d8.loss_mask: 0.8024  decode.d8.loss_dice: 0.5400
06/01 12:18:20 - mmengine - INFO - Iter(train) [149250/160000]  base_lr: 8.8016e-06 lr: 8.8016e-07  eta: 11:45:04  time: 0.6385  data_time: 0.0103  memory: 10511  grad_norm: 297.0386  loss: 14.0777  decode.loss_cls: 0.0791  decode.loss_mask: 0.7633  decode.loss_dice: 0.5080  decode.d0.loss_cls: 0.5191  decode.d0.loss_mask: 0.7468  decode.d0.loss_dice: 0.5218  decode.d1.loss_cls: 0.1121  decode.d1.loss_mask: 0.7616  decode.d1.loss_dice: 0.5084  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.7648  decode.d2.loss_dice: 0.5128  decode.d3.loss_cls: 0.0890  decode.d3.loss_mask: 0.7685  decode.d3.loss_dice: 0.5161  decode.d4.loss_cls: 0.0904  decode.d4.loss_mask: 0.7609  decode.d4.loss_dice: 0.5176  decode.d5.loss_cls: 0.0820  decode.d5.loss_mask: 0.7676  decode.d5.loss_dice: 0.5160  decode.d6.loss_cls: 0.0742  decode.d6.loss_mask: 0.7704  decode.d6.loss_dice: 0.5082  decode.d7.loss_cls: 0.0848  decode.d7.loss_mask: 0.7703  decode.d7.loss_dice: 0.5148  decode.d8.loss_cls: 0.0777  decode.d8.loss_mask: 0.7779  decode.d8.loss_dice: 0.5123
06/01 12:18:52 - mmengine - INFO - Iter(train) [149300/160000]  base_lr: 8.7648e-06 lr: 8.7648e-07  eta: 11:34:57  time: 0.6389  data_time: 0.0103  memory: 10508  grad_norm: 194.6568  loss: 12.8195  decode.loss_cls: 0.0542  decode.loss_mask: 0.6599  decode.loss_dice: 0.5235  decode.d0.loss_cls: 0.4460  decode.d0.loss_mask: 0.6674  decode.d0.loss_dice: 0.5197  decode.d1.loss_cls: 0.0692  decode.d1.loss_mask: 0.6575  decode.d1.loss_dice: 0.5193  decode.d2.loss_cls: 0.0496  decode.d2.loss_mask: 0.6650  decode.d2.loss_dice: 0.5249  decode.d3.loss_cls: 0.0553  decode.d3.loss_mask: 0.6653  decode.d3.loss_dice: 0.5275  decode.d4.loss_cls: 0.0520  decode.d4.loss_mask: 0.6647  decode.d4.loss_dice: 0.5254  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.6602  decode.d5.loss_dice: 0.5191  decode.d6.loss_cls: 0.0607  decode.d6.loss_mask: 0.6669  decode.d6.loss_dice: 0.5278  decode.d7.loss_cls: 0.0517  decode.d7.loss_mask: 0.6595  decode.d7.loss_dice: 0.5214  decode.d8.loss_cls: 0.0606  decode.d8.loss_mask: 0.6628  decode.d8.loss_dice: 0.5208
06/01 12:19:24 - mmengine - INFO - Iter(train) [149350/160000]  base_lr: 8.7279e-06 lr: 8.7279e-07  eta: 11:25:04  time: 0.6386  data_time: 0.0103  memory: 10515  grad_norm: 708.3342  loss: 19.1564  decode.loss_cls: 0.1294  decode.loss_mask: 1.0238  decode.loss_dice: 0.6890  decode.d0.loss_cls: 0.5524  decode.d0.loss_mask: 0.9848  decode.d0.loss_dice: 0.6771  decode.d1.loss_cls: 0.1671  decode.d1.loss_mask: 1.0380  decode.d1.loss_dice: 0.7011  decode.d2.loss_cls: 0.1320  decode.d2.loss_mask: 1.0492  decode.d2.loss_dice: 0.7298  decode.d3.loss_cls: 0.1307  decode.d3.loss_mask: 1.0545  decode.d3.loss_dice: 0.6972  decode.d4.loss_cls: 0.1804  decode.d4.loss_mask: 1.0129  decode.d4.loss_dice: 0.6827  decode.d5.loss_cls: 0.1567  decode.d5.loss_mask: 1.0253  decode.d5.loss_dice: 0.6795  decode.d6.loss_cls: 0.2021  decode.d6.loss_mask: 1.0463  decode.d6.loss_dice: 0.6787  decode.d7.loss_cls: 0.0988  decode.d7.loss_mask: 1.0821  decode.d7.loss_dice: 0.6823  decode.d8.loss_cls: 0.1238  decode.d8.loss_mask: 1.0619  decode.d8.loss_dice: 0.6868
06/01 12:19:56 - mmengine - INFO - Iter(train) [149400/160000]  base_lr: 8.6910e-06 lr: 8.6910e-07  eta: 11:15:23  time: 0.6385  data_time: 0.0103  memory: 10515  grad_norm: 636.3927  loss: 12.8566  decode.loss_cls: 0.1148  decode.loss_mask: 0.6680  decode.loss_dice: 0.4375  decode.d0.loss_cls: 0.5036  decode.d0.loss_mask: 0.6780  decode.d0.loss_dice: 0.4701  decode.d1.loss_cls: 0.1127  decode.d1.loss_mask: 0.6876  decode.d1.loss_dice: 0.4547  decode.d2.loss_cls: 0.1017  decode.d2.loss_mask: 0.6913  decode.d2.loss_dice: 0.4434  decode.d3.loss_cls: 0.1088  decode.d3.loss_mask: 0.6909  decode.d3.loss_dice: 0.4487  decode.d4.loss_cls: 0.1138  decode.d4.loss_mask: 0.6903  decode.d4.loss_dice: 0.4455  decode.d5.loss_cls: 0.1083  decode.d5.loss_mask: 0.6906  decode.d5.loss_dice: 0.4439  decode.d6.loss_cls: 0.1105  decode.d6.loss_mask: 0.7011  decode.d6.loss_dice: 0.4446  decode.d7.loss_cls: 0.1156  decode.d7.loss_mask: 0.6952  decode.d7.loss_dice: 0.4433  decode.d8.loss_cls: 0.1071  decode.d8.loss_mask: 0.6929  decode.d8.loss_dice: 0.4419
06/01 12:20:28 - mmengine - INFO - Iter(train) [149450/160000]  base_lr: 8.6541e-06 lr: 8.6541e-07  eta: 11:05:55  time: 0.6385  data_time: 0.0103  memory: 10499  grad_norm: 175.8865  loss: 10.9117  decode.loss_cls: 0.0090  decode.loss_mask: 0.6232  decode.loss_dice: 0.4226  decode.d0.loss_cls: 0.4032  decode.d0.loss_mask: 0.6088  decode.d0.loss_dice: 0.4089  decode.d1.loss_cls: 0.0131  decode.d1.loss_mask: 0.6188  decode.d1.loss_dice: 0.4211  decode.d2.loss_cls: 0.0111  decode.d2.loss_mask: 0.6170  decode.d2.loss_dice: 0.4180  decode.d3.loss_cls: 0.0094  decode.d3.loss_mask: 0.6214  decode.d3.loss_dice: 0.4234  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.6231  decode.d4.loss_dice: 0.4214  decode.d5.loss_cls: 0.0096  decode.d5.loss_mask: 0.6248  decode.d5.loss_dice: 0.4272  decode.d6.loss_cls: 0.0104  decode.d6.loss_mask: 0.6259  decode.d6.loss_dice: 0.4243  decode.d7.loss_cls: 0.0106  decode.d7.loss_mask: 0.6227  decode.d7.loss_dice: 0.4204  decode.d8.loss_cls: 0.0098  decode.d8.loss_mask: 0.6198  decode.d8.loss_dice: 0.4228
06/01 12:21:00 - mmengine - INFO - Iter(train) [149500/160000]  base_lr: 8.6172e-06 lr: 8.6172e-07  eta: 10:56:38  time: 0.6387  data_time: 0.0104  memory: 10497  grad_norm: 245.1674  loss: 12.8925  decode.loss_cls: 0.0480  decode.loss_mask: 0.7164  decode.loss_dice: 0.4862  decode.d0.loss_cls: 0.4865  decode.d0.loss_mask: 0.7049  decode.d0.loss_dice: 0.4757  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.7162  decode.d1.loss_dice: 0.4901  decode.d2.loss_cls: 0.0472  decode.d2.loss_mask: 0.7192  decode.d2.loss_dice: 0.4944  decode.d3.loss_cls: 0.0243  decode.d3.loss_mask: 0.7221  decode.d3.loss_dice: 0.5015  decode.d4.loss_cls: 0.0224  decode.d4.loss_mask: 0.7209  decode.d4.loss_dice: 0.4888  decode.d5.loss_cls: 0.0242  decode.d5.loss_mask: 0.7117  decode.d5.loss_dice: 0.4934  decode.d6.loss_cls: 0.0265  decode.d6.loss_mask: 0.7149  decode.d6.loss_dice: 0.4984  decode.d7.loss_cls: 0.0247  decode.d7.loss_mask: 0.7191  decode.d7.loss_dice: 0.5221  decode.d8.loss_cls: 0.0441  decode.d8.loss_mask: 0.7073  decode.d8.loss_dice: 0.4871
06/01 12:21:32 - mmengine - INFO - Iter(train) [149550/160000]  base_lr: 8.5802e-06 lr: 8.5802e-07  eta: 10:47:33  time: 0.6385  data_time: 0.0102  memory: 10498  grad_norm: 331.0761  loss: 12.2030  decode.loss_cls: 0.0642  decode.loss_mask: 0.6531  decode.loss_dice: 0.4409  decode.d0.loss_cls: 0.4589  decode.d0.loss_mask: 0.6480  decode.d0.loss_dice: 0.4779  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.6605  decode.d1.loss_dice: 0.4709  decode.d2.loss_cls: 0.0633  decode.d2.loss_mask: 0.6600  decode.d2.loss_dice: 0.4620  decode.d3.loss_cls: 0.0565  decode.d3.loss_mask: 0.6610  decode.d3.loss_dice: 0.4670  decode.d4.loss_cls: 0.0668  decode.d4.loss_mask: 0.6592  decode.d4.loss_dice: 0.4552  decode.d5.loss_cls: 0.0580  decode.d5.loss_mask: 0.6589  decode.d5.loss_dice: 0.4717  decode.d6.loss_cls: 0.0653  decode.d6.loss_mask: 0.6512  decode.d6.loss_dice: 0.4667  decode.d7.loss_cls: 0.0562  decode.d7.loss_mask: 0.6615  decode.d7.loss_dice: 0.4641  decode.d8.loss_cls: 0.0622  decode.d8.loss_mask: 0.6518  decode.d8.loss_dice: 0.4476
06/01 12:22:04 - mmengine - INFO - Iter(train) [149600/160000]  base_lr: 8.5433e-06 lr: 8.5433e-07  eta: 10:38:39  time: 0.6388  data_time: 0.0103  memory: 10496  grad_norm: 345.1832  loss: 11.8212  decode.loss_cls: 0.1115  decode.loss_mask: 0.6023  decode.loss_dice: 0.4176  decode.d0.loss_cls: 0.5285  decode.d0.loss_mask: 0.6036  decode.d0.loss_dice: 0.4153  decode.d1.loss_cls: 0.1081  decode.d1.loss_mask: 0.6005  decode.d1.loss_dice: 0.4374  decode.d2.loss_cls: 0.1058  decode.d2.loss_mask: 0.6021  decode.d2.loss_dice: 0.4319  decode.d3.loss_cls: 0.1070  decode.d3.loss_mask: 0.6035  decode.d3.loss_dice: 0.4289  decode.d4.loss_cls: 0.1169  decode.d4.loss_mask: 0.6043  decode.d4.loss_dice: 0.4299  decode.d5.loss_cls: 0.1143  decode.d5.loss_mask: 0.6038  decode.d5.loss_dice: 0.4252  decode.d6.loss_cls: 0.1018  decode.d6.loss_mask: 0.6047  decode.d6.loss_dice: 0.4211  decode.d7.loss_cls: 0.1223  decode.d7.loss_mask: 0.5984  decode.d7.loss_dice: 0.4307  decode.d8.loss_cls: 0.1136  decode.d8.loss_mask: 0.6035  decode.d8.loss_dice: 0.4266
06/01 12:22:36 - mmengine - INFO - Iter(train) [149650/160000]  base_lr: 8.5063e-06 lr: 8.5063e-07  eta: 10:29:56  time: 0.6387  data_time: 0.0104  memory: 10498  grad_norm: 329.3784  loss: 16.1229  decode.loss_cls: 0.1116  decode.loss_mask: 0.8709  decode.loss_dice: 0.5838  decode.d0.loss_cls: 0.6010  decode.d0.loss_mask: 0.8606  decode.d0.loss_dice: 0.6018  decode.d1.loss_cls: 0.1625  decode.d1.loss_mask: 0.8316  decode.d1.loss_dice: 0.5678  decode.d2.loss_cls: 0.1426  decode.d2.loss_mask: 0.8513  decode.d2.loss_dice: 0.5598  decode.d3.loss_cls: 0.1242  decode.d3.loss_mask: 0.8677  decode.d3.loss_dice: 0.5803  decode.d4.loss_cls: 0.1385  decode.d4.loss_mask: 0.8496  decode.d4.loss_dice: 0.5653  decode.d5.loss_cls: 0.1112  decode.d5.loss_mask: 0.8611  decode.d5.loss_dice: 0.5756  decode.d6.loss_cls: 0.1688  decode.d6.loss_mask: 0.8409  decode.d6.loss_dice: 0.5624  decode.d7.loss_cls: 0.1259  decode.d7.loss_mask: 0.8843  decode.d7.loss_dice: 0.5887  decode.d8.loss_cls: 0.1389  decode.d8.loss_mask: 0.8332  decode.d8.loss_dice: 0.5609
06/01 12:23:08 - mmengine - INFO - Iter(train) [149700/160000]  base_lr: 8.4693e-06 lr: 8.4693e-07  eta: 10:21:23  time: 0.6392  data_time: 0.0103  memory: 10510  grad_norm: 363.2296  loss: 13.9659  decode.loss_cls: 0.1284  decode.loss_mask: 0.7120  decode.loss_dice: 0.5227  decode.d0.loss_cls: 0.5289  decode.d0.loss_mask: 0.7207  decode.d0.loss_dice: 0.5248  decode.d1.loss_cls: 0.1240  decode.d1.loss_mask: 0.7122  decode.d1.loss_dice: 0.5260  decode.d2.loss_cls: 0.1204  decode.d2.loss_mask: 0.7064  decode.d2.loss_dice: 0.5225  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 0.7186  decode.d3.loss_dice: 0.5163  decode.d4.loss_cls: 0.1121  decode.d4.loss_mask: 0.7109  decode.d4.loss_dice: 0.5291  decode.d5.loss_cls: 0.1133  decode.d5.loss_mask: 0.7101  decode.d5.loss_dice: 0.5130  decode.d6.loss_cls: 0.1168  decode.d6.loss_mask: 0.7070  decode.d6.loss_dice: 0.5176  decode.d7.loss_cls: 0.1289  decode.d7.loss_mask: 0.7135  decode.d7.loss_dice: 0.5349  decode.d8.loss_cls: 0.1059  decode.d8.loss_mask: 0.7319  decode.d8.loss_dice: 0.5355
06/01 12:23:40 - mmengine - INFO - Iter(train) [149750/160000]  base_lr: 8.4323e-06 lr: 8.4323e-07  eta: 10:13:00  time: 0.6389  data_time: 0.0104  memory: 10524  grad_norm: 270.5679  loss: 12.0776  decode.loss_cls: 0.0889  decode.loss_mask: 0.6250  decode.loss_dice: 0.4618  decode.d0.loss_cls: 0.5252  decode.d0.loss_mask: 0.6195  decode.d0.loss_dice: 0.4665  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.6213  decode.d1.loss_dice: 0.4681  decode.d2.loss_cls: 0.0653  decode.d2.loss_mask: 0.6231  decode.d2.loss_dice: 0.4624  decode.d3.loss_cls: 0.0754  decode.d3.loss_mask: 0.6290  decode.d3.loss_dice: 0.4624  decode.d4.loss_cls: 0.0728  decode.d4.loss_mask: 0.6227  decode.d4.loss_dice: 0.4564  decode.d5.loss_cls: 0.0623  decode.d5.loss_mask: 0.6304  decode.d5.loss_dice: 0.4582  decode.d6.loss_cls: 0.0641  decode.d6.loss_mask: 0.6276  decode.d6.loss_dice: 0.4646  decode.d7.loss_cls: 0.0809  decode.d7.loss_mask: 0.6257  decode.d7.loss_dice: 0.4673  decode.d8.loss_cls: 0.0741  decode.d8.loss_mask: 0.6266  decode.d8.loss_dice: 0.4712
06/01 12:24:12 - mmengine - INFO - Iter(train) [149800/160000]  base_lr: 8.3953e-06 lr: 8.3953e-07  eta: 10:04:48  time: 0.6393  data_time: 0.0103  memory: 10507  grad_norm: 244.2725  loss: 14.6362  decode.loss_cls: 0.0649  decode.loss_mask: 0.7949  decode.loss_dice: 0.5732  decode.d0.loss_cls: 0.4242  decode.d0.loss_mask: 0.7842  decode.d0.loss_dice: 0.5615  decode.d1.loss_cls: 0.0471  decode.d1.loss_mask: 0.8086  decode.d1.loss_dice: 0.5737  decode.d2.loss_cls: 0.0397  decode.d2.loss_mask: 0.8035  decode.d2.loss_dice: 0.5721  decode.d3.loss_cls: 0.0353  decode.d3.loss_mask: 0.8016  decode.d3.loss_dice: 0.5760  decode.d4.loss_cls: 0.0436  decode.d4.loss_mask: 0.8085  decode.d4.loss_dice: 0.5726  decode.d5.loss_cls: 0.0465  decode.d5.loss_mask: 0.8061  decode.d5.loss_dice: 0.5654  decode.d6.loss_cls: 0.0765  decode.d6.loss_mask: 0.7948  decode.d6.loss_dice: 0.5697  decode.d7.loss_cls: 0.0765  decode.d7.loss_mask: 0.7980  decode.d7.loss_dice: 0.5683  decode.d8.loss_cls: 0.0728  decode.d8.loss_mask: 0.8030  decode.d8.loss_dice: 0.5736
06/01 12:24:44 - mmengine - INFO - Iter(train) [149850/160000]  base_lr: 8.3582e-06 lr: 8.3582e-07  eta: 9:56:44  time: 0.6390  data_time: 0.0103  memory: 10514  grad_norm: 418.0010  loss: 17.3661  decode.loss_cls: 0.1015  decode.loss_mask: 0.9933  decode.loss_dice: 0.5902  decode.d0.loss_cls: 0.5615  decode.d0.loss_mask: 0.9714  decode.d0.loss_dice: 0.5710  decode.d1.loss_cls: 0.1347  decode.d1.loss_mask: 0.9952  decode.d1.loss_dice: 0.5898  decode.d2.loss_cls: 0.1121  decode.d2.loss_mask: 1.0104  decode.d2.loss_dice: 0.6049  decode.d3.loss_cls: 0.1161  decode.d3.loss_mask: 0.9910  decode.d3.loss_dice: 0.5825  decode.d4.loss_cls: 0.1156  decode.d4.loss_mask: 0.9826  decode.d4.loss_dice: 0.5734  decode.d5.loss_cls: 0.1192  decode.d5.loss_mask: 0.9850  decode.d5.loss_dice: 0.5766  decode.d6.loss_cls: 0.1251  decode.d6.loss_mask: 0.9906  decode.d6.loss_dice: 0.5863  decode.d7.loss_cls: 0.1267  decode.d7.loss_mask: 0.9902  decode.d7.loss_dice: 0.5748  decode.d8.loss_cls: 0.1380  decode.d8.loss_mask: 0.9830  decode.d8.loss_dice: 0.5735
06/01 12:25:16 - mmengine - INFO - Iter(train) [149900/160000]  base_lr: 8.3212e-06 lr: 8.3212e-07  eta: 9:48:50  time: 0.6394  data_time: 0.0103  memory: 10500  grad_norm: 1011.3623  loss: 13.5461  decode.loss_cls: 0.0625  decode.loss_mask: 0.7299  decode.loss_dice: 0.5224  decode.d0.loss_cls: 0.4204  decode.d0.loss_mask: 0.7036  decode.d0.loss_dice: 0.5218  decode.d1.loss_cls: 0.0783  decode.d1.loss_mask: 0.7063  decode.d1.loss_dice: 0.5276  decode.d2.loss_cls: 0.0637  decode.d2.loss_mask: 0.7084  decode.d2.loss_dice: 0.5333  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.7361  decode.d3.loss_dice: 0.5261  decode.d4.loss_cls: 0.0851  decode.d4.loss_mask: 0.7299  decode.d4.loss_dice: 0.5215  decode.d5.loss_cls: 0.0964  decode.d5.loss_mask: 0.7317  decode.d5.loss_dice: 0.5138  decode.d6.loss_cls: 0.0846  decode.d6.loss_mask: 0.7240  decode.d6.loss_dice: 0.5120  decode.d7.loss_cls: 0.0970  decode.d7.loss_mask: 0.7210  decode.d7.loss_dice: 0.5082  decode.d8.loss_cls: 0.0705  decode.d8.loss_mask: 0.7263  decode.d8.loss_dice: 0.5190
06/01 12:25:48 - mmengine - INFO - Iter(train) [149950/160000]  base_lr: 8.2841e-06 lr: 8.2841e-07  eta: 9:41:05  time: 0.6388  data_time: 0.0103  memory: 10503  grad_norm: 261.0483  loss: 13.3198  decode.loss_cls: 0.1202  decode.loss_mask: 0.6964  decode.loss_dice: 0.4939  decode.d0.loss_cls: 0.5449  decode.d0.loss_mask: 0.7039  decode.d0.loss_dice: 0.5291  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.7229  decode.d1.loss_dice: 0.4956  decode.d2.loss_cls: 0.0601  decode.d2.loss_mask: 0.7129  decode.d2.loss_dice: 0.4968  decode.d3.loss_cls: 0.0736  decode.d3.loss_mask: 0.7051  decode.d3.loss_dice: 0.4981  decode.d4.loss_cls: 0.0873  decode.d4.loss_mask: 0.7123  decode.d4.loss_dice: 0.4900  decode.d5.loss_cls: 0.0720  decode.d5.loss_mask: 0.7008  decode.d5.loss_dice: 0.4971  decode.d6.loss_cls: 0.0948  decode.d6.loss_mask: 0.7089  decode.d6.loss_dice: 0.5025  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 0.7194  decode.d7.loss_dice: 0.4960  decode.d8.loss_cls: 0.0666  decode.d8.loss_mask: 0.7049  decode.d8.loss_dice: 0.5022
06/01 12:26:20 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 12:26:20 - mmengine - INFO - Iter(train) [150000/160000]  base_lr: 8.2470e-06 lr: 8.2470e-07  eta: 9:33:29  time: 0.6389  data_time: 0.0103  memory: 10499  grad_norm: 193.5953  loss: 11.7418  decode.loss_cls: 0.0576  decode.loss_mask: 0.6166  decode.loss_dice: 0.4483  decode.d0.loss_cls: 0.4305  decode.d0.loss_mask: 0.6265  decode.d0.loss_dice: 0.4653  decode.d1.loss_cls: 0.0907  decode.d1.loss_mask: 0.6220  decode.d1.loss_dice: 0.4497  decode.d2.loss_cls: 0.0695  decode.d2.loss_mask: 0.6257  decode.d2.loss_dice: 0.4566  decode.d3.loss_cls: 0.0594  decode.d3.loss_mask: 0.6230  decode.d3.loss_dice: 0.4558  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.6211  decode.d4.loss_dice: 0.4497  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.6175  decode.d5.loss_dice: 0.4437  decode.d6.loss_cls: 0.0610  decode.d6.loss_mask: 0.6206  decode.d6.loss_dice: 0.4444  decode.d7.loss_cls: 0.0587  decode.d7.loss_mask: 0.6225  decode.d7.loss_dice: 0.4567  decode.d8.loss_cls: 0.0624  decode.d8.loss_mask: 0.6192  decode.d8.loss_dice: 0.4442
06/01 12:26:20 - mmengine - INFO - Saving checkpoint at 150000 iterations
06/01 12:26:48 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:11:15  time: 0.2478  data_time: 0.0012  memory: 18409  
06/01 12:26:57 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:07:19  time: 0.0740  data_time: 0.0012  memory: 18331  
06/01 12:27:04 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:05:45  time: 0.1282  data_time: 0.0013  memory: 18423  
06/01 12:27:09 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:04:37  time: 0.1554  data_time: 0.0012  memory: 18309  
06/01 12:27:12 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:03:50  time: 0.0732  data_time: 0.0012  memory: 2229  
06/01 12:27:16 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:03:18  time: 0.0732  data_time: 0.0013  memory: 2208  
06/01 12:27:21 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:02:56  time: 0.0737  data_time: 0.0013  memory: 18309  
06/01 12:27:25 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:02:40  time: 0.0761  data_time: 0.0013  memory: 18360  
06/01 12:27:29 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:02:23  time: 0.0726  data_time: 0.0013  memory: 2229  
06/01 12:27:34 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:02:12  time: 0.1530  data_time: 0.0013  memory: 18432  
06/01 12:27:41 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:02:05  time: 0.0736  data_time: 0.0012  memory: 18365  
06/01 12:27:45 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:01:53  time: 0.0743  data_time: 0.0012  memory: 2228  
06/01 12:27:48 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:01:43  time: 0.0747  data_time: 0.0012  memory: 2133  
06/01 12:27:54 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:01:35  time: 0.1746  data_time: 0.0013  memory: 18364  
06/01 12:27:59 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:01:27  time: 0.0747  data_time: 0.0012  memory: 18356  
06/01 12:28:05 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:01:21  time: 0.1873  data_time: 0.0013  memory: 18411  
06/01 12:28:08 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:01:13  time: 0.0733  data_time: 0.0013  memory: 2208  
06/01 12:28:12 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:01:05  time: 0.0745  data_time: 0.0012  memory: 2133  
06/01 12:28:16 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:58  time: 0.0751  data_time: 0.0012  memory: 2133  
06/01 12:28:20 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:52  time: 0.0735  data_time: 0.0013  memory: 18365  
06/01 12:28:24 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:45  time: 0.0729  data_time: 0.0012  memory: 2172  
06/01 12:28:28 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:39  time: 0.1301  data_time: 0.0013  memory: 18417  
06/01 12:28:32 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:33  time: 0.0733  data_time: 0.0013  memory: 2190  
06/01 12:28:36 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:27  time: 0.0751  data_time: 0.0013  memory: 2228  
06/01 12:28:40 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:21  time: 0.0744  data_time: 0.0013  memory: 18414  
06/01 12:28:44 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:15  time: 0.0730  data_time: 0.0013  memory: 2228  
06/01 12:28:47 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:10  time: 0.0765  data_time: 0.0013  memory: 2208  
06/01 12:28:51 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:05  time: 0.0731  data_time: 0.0013  memory: 2133  
06/01 12:28:55 - mmengine - INFO - per class results:
06/01 12:28:55 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 96.16 | 97.89 |
|  aeroplane  | 93.79 | 99.16 |
|   bicycle   | 46.43 |  94.5 |
|     bird    | 96.51 | 98.49 |
|     boat    | 73.08 | 88.87 |
|    bottle   | 87.72 | 96.47 |
|     bus     | 96.82 | 98.29 |
|     car     | 90.19 | 95.66 |
|     cat     | 96.14 | 98.12 |
|    chair    | 49.46 | 69.25 |
|     cow     |  91.5 | 93.51 |
| diningtable | 64.66 | 69.84 |
|     dog     | 94.48 | 98.75 |
|    horse    | 88.25 | 95.51 |
|  motorbike  | 90.03 | 94.07 |
|    person   | 90.77 | 94.76 |
| pottedplant | 75.01 |  90.4 |
|    sheep    | 94.51 | 97.67 |
|     sofa    | 62.12 | 70.76 |
|    train    | 95.37 | 98.67 |
|  tvmonitor  | 86.12 | 93.96 |
+-------------+-------+-------+
06/01 12:28:55 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 96.5300  mIoU: 83.7700  mAcc: 92.1200  data_time: 0.0044  time: 0.1035
06/01 12:29:27 - mmengine - INFO - Iter(train) [150050/160000]  base_lr: 8.2099e-06 lr: 8.2099e-07  eta: 9:26:02  time: 0.6401  data_time: 0.0106  memory: 10533  grad_norm: 497.5761  loss: 14.1392  decode.loss_cls: 0.1063  decode.loss_mask: 0.7113  decode.loss_dice: 0.5743  decode.d0.loss_cls: 0.4515  decode.d0.loss_mask: 0.7179  decode.d0.loss_dice: 0.5536  decode.d1.loss_cls: 0.1032  decode.d1.loss_mask: 0.7089  decode.d1.loss_dice: 0.5633  decode.d2.loss_cls: 0.1027  decode.d2.loss_mask: 0.7186  decode.d2.loss_dice: 0.5630  decode.d3.loss_cls: 0.1021  decode.d3.loss_mask: 0.7086  decode.d3.loss_dice: 0.5622  decode.d4.loss_cls: 0.1056  decode.d4.loss_mask: 0.7061  decode.d4.loss_dice: 0.5587  decode.d5.loss_cls: 0.0997  decode.d5.loss_mask: 0.7224  decode.d5.loss_dice: 0.5548  decode.d6.loss_cls: 0.0974  decode.d6.loss_mask: 0.7157  decode.d6.loss_dice: 0.5973  decode.d7.loss_cls: 0.0978  decode.d7.loss_mask: 0.7246  decode.d7.loss_dice: 0.5525  decode.d8.loss_cls: 0.0971  decode.d8.loss_mask: 0.7107  decode.d8.loss_dice: 0.5516
06/01 12:29:59 - mmengine - INFO - Iter(train) [150100/160000]  base_lr: 8.1727e-06 lr: 8.1727e-07  eta: 9:18:42  time: 0.6407  data_time: 0.0105  memory: 10511  grad_norm: 616.9758  loss: 14.9746  decode.loss_cls: 0.0439  decode.loss_mask: 0.8677  decode.loss_dice: 0.5470  decode.d0.loss_cls: 0.4907  decode.d0.loss_mask: 0.8529  decode.d0.loss_dice: 0.5407  decode.d1.loss_cls: 0.0436  decode.d1.loss_mask: 0.8580  decode.d1.loss_dice: 0.5534  decode.d2.loss_cls: 0.0366  decode.d2.loss_mask: 0.8681  decode.d2.loss_dice: 0.5447  decode.d3.loss_cls: 0.0355  decode.d3.loss_mask: 0.8642  decode.d3.loss_dice: 0.5551  decode.d4.loss_cls: 0.0346  decode.d4.loss_mask: 0.8646  decode.d4.loss_dice: 0.5510  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.8621  decode.d5.loss_dice: 0.5601  decode.d6.loss_cls: 0.0363  decode.d6.loss_mask: 0.8643  decode.d6.loss_dice: 0.5591  decode.d7.loss_cls: 0.0362  decode.d7.loss_mask: 0.8656  decode.d7.loss_dice: 0.5525  decode.d8.loss_cls: 0.0383  decode.d8.loss_mask: 0.8636  decode.d8.loss_dice: 0.5471
06/01 12:30:31 - mmengine - INFO - Iter(train) [150150/160000]  base_lr: 8.1356e-06 lr: 8.1356e-07  eta: 9:11:30  time: 0.6403  data_time: 0.0106  memory: 10496  grad_norm: 536.1211  loss: 12.5823  decode.loss_cls: 0.0178  decode.loss_mask: 0.6664  decode.loss_dice: 0.5430  decode.d0.loss_cls: 0.4277  decode.d0.loss_mask: 0.6420  decode.d0.loss_dice: 0.5191  decode.d1.loss_cls: 0.0195  decode.d1.loss_mask: 0.6549  decode.d1.loss_dice: 0.5408  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.6591  decode.d2.loss_dice: 0.5320  decode.d3.loss_cls: 0.0179  decode.d3.loss_mask: 0.6607  decode.d3.loss_dice: 0.5365  decode.d4.loss_cls: 0.0142  decode.d4.loss_mask: 0.6630  decode.d4.loss_dice: 0.5347  decode.d5.loss_cls: 0.0173  decode.d5.loss_mask: 0.6685  decode.d5.loss_dice: 0.5412  decode.d6.loss_cls: 0.0156  decode.d6.loss_mask: 0.6704  decode.d6.loss_dice: 0.5438  decode.d7.loss_cls: 0.0150  decode.d7.loss_mask: 0.6662  decode.d7.loss_dice: 0.5457  decode.d8.loss_cls: 0.0197  decode.d8.loss_mask: 0.6663  decode.d8.loss_dice: 0.5444
06/01 12:31:03 - mmengine - INFO - Iter(train) [150200/160000]  base_lr: 8.0984e-06 lr: 8.0984e-07  eta: 9:04:26  time: 0.6419  data_time: 0.0106  memory: 10500  grad_norm: 682.3750  loss: 19.1507  decode.loss_cls: 0.1479  decode.loss_mask: 1.1406  decode.loss_dice: 0.6589  decode.d0.loss_cls: 0.6226  decode.d0.loss_mask: 1.0229  decode.d0.loss_dice: 0.6234  decode.d1.loss_cls: 0.1536  decode.d1.loss_mask: 1.0866  decode.d1.loss_dice: 0.6385  decode.d2.loss_cls: 0.1454  decode.d2.loss_mask: 1.0911  decode.d2.loss_dice: 0.6409  decode.d3.loss_cls: 0.1779  decode.d3.loss_mask: 1.0032  decode.d3.loss_dice: 0.6331  decode.d4.loss_cls: 0.1893  decode.d4.loss_mask: 1.0322  decode.d4.loss_dice: 0.6227  decode.d5.loss_cls: 0.1497  decode.d5.loss_mask: 1.1127  decode.d5.loss_dice: 0.6513  decode.d6.loss_cls: 0.1461  decode.d6.loss_mask: 1.1217  decode.d6.loss_dice: 0.6536  decode.d7.loss_cls: 0.1842  decode.d7.loss_mask: 1.0032  decode.d7.loss_dice: 0.6190  decode.d8.loss_cls: 0.1415  decode.d8.loss_mask: 1.0948  decode.d8.loss_dice: 0.6421
06/01 12:31:36 - mmengine - INFO - Iter(train) [150250/160000]  base_lr: 8.0612e-06 lr: 8.0612e-07  eta: 8:57:30  time: 0.6753  data_time: 0.0107  memory: 10499  grad_norm: 945.7197  loss: 18.8859  decode.loss_cls: 0.1328  decode.loss_mask: 0.9814  decode.loss_dice: 0.7197  decode.d0.loss_cls: 0.5295  decode.d0.loss_mask: 1.0241  decode.d0.loss_dice: 0.7613  decode.d1.loss_cls: 0.1296  decode.d1.loss_mask: 0.9794  decode.d1.loss_dice: 0.7327  decode.d2.loss_cls: 0.1610  decode.d2.loss_mask: 0.9687  decode.d2.loss_dice: 0.7446  decode.d3.loss_cls: 0.1429  decode.d3.loss_mask: 0.9621  decode.d3.loss_dice: 0.7279  decode.d4.loss_cls: 0.1489  decode.d4.loss_mask: 0.9701  decode.d4.loss_dice: 0.7227  decode.d5.loss_cls: 0.1100  decode.d5.loss_mask: 1.0149  decode.d5.loss_dice: 0.7253  decode.d6.loss_cls: 0.1136  decode.d6.loss_mask: 0.9760  decode.d6.loss_dice: 0.7406  decode.d7.loss_cls: 0.1443  decode.d7.loss_mask: 0.9639  decode.d7.loss_dice: 0.7136  decode.d8.loss_cls: 0.1365  decode.d8.loss_mask: 0.9918  decode.d8.loss_dice: 0.7160
06/01 12:32:08 - mmengine - INFO - Iter(train) [150300/160000]  base_lr: 8.0240e-06 lr: 8.0240e-07  eta: 8:50:41  time: 0.6416  data_time: 0.0106  memory: 10509  grad_norm: 281.3375  loss: 17.2336  decode.loss_cls: 0.0863  decode.loss_mask: 0.9006  decode.loss_dice: 0.6628  decode.d0.loss_cls: 0.7224  decode.d0.loss_mask: 0.8861  decode.d0.loss_dice: 0.6930  decode.d1.loss_cls: 0.1801  decode.d1.loss_mask: 0.8946  decode.d1.loss_dice: 0.6707  decode.d2.loss_cls: 0.1065  decode.d2.loss_mask: 0.8890  decode.d2.loss_dice: 0.6664  decode.d3.loss_cls: 0.1005  decode.d3.loss_mask: 0.8728  decode.d3.loss_dice: 0.6586  decode.d4.loss_cls: 0.0935  decode.d4.loss_mask: 0.8976  decode.d4.loss_dice: 0.6593  decode.d5.loss_cls: 0.0921  decode.d5.loss_mask: 0.8908  decode.d5.loss_dice: 0.6636  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.8925  decode.d6.loss_dice: 0.6731  decode.d7.loss_cls: 0.1102  decode.d7.loss_mask: 0.8820  decode.d7.loss_dice: 0.6653  decode.d8.loss_cls: 0.0908  decode.d8.loss_mask: 0.8880  decode.d8.loss_dice: 0.6540
06/01 12:32:40 - mmengine - INFO - Iter(train) [150350/160000]  base_lr: 7.9867e-06 lr: 7.9867e-07  eta: 8:43:59  time: 0.6417  data_time: 0.0106  memory: 10492  grad_norm: 218.4237  loss: 14.3470  decode.loss_cls: 0.0944  decode.loss_mask: 0.8026  decode.loss_dice: 0.5310  decode.d0.loss_cls: 0.4801  decode.d0.loss_mask: 0.8159  decode.d0.loss_dice: 0.5322  decode.d1.loss_cls: 0.0622  decode.d1.loss_mask: 0.8012  decode.d1.loss_dice: 0.5223  decode.d2.loss_cls: 0.0553  decode.d2.loss_mask: 0.8001  decode.d2.loss_dice: 0.5429  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.8000  decode.d3.loss_dice: 0.5366  decode.d4.loss_cls: 0.0565  decode.d4.loss_mask: 0.8003  decode.d4.loss_dice: 0.5265  decode.d5.loss_cls: 0.0571  decode.d5.loss_mask: 0.8001  decode.d5.loss_dice: 0.5244  decode.d6.loss_cls: 0.0568  decode.d6.loss_mask: 0.8009  decode.d6.loss_dice: 0.5272  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.8023  decode.d7.loss_dice: 0.5309  decode.d8.loss_cls: 0.0550  decode.d8.loss_mask: 0.8002  decode.d8.loss_dice: 0.5211
06/01 12:33:12 - mmengine - INFO - Iter(train) [150400/160000]  base_lr: 7.9495e-06 lr: 7.9495e-07  eta: 8:37:23  time: 0.6427  data_time: 0.0106  memory: 10492  grad_norm: 424.3907  loss: 12.6684  decode.loss_cls: 0.0579  decode.loss_mask: 0.6875  decode.loss_dice: 0.4709  decode.d0.loss_cls: 0.4671  decode.d0.loss_mask: 0.6733  decode.d0.loss_dice: 0.4786  decode.d1.loss_cls: 0.0627  decode.d1.loss_mask: 0.6973  decode.d1.loss_dice: 0.4871  decode.d2.loss_cls: 0.0578  decode.d2.loss_mask: 0.6912  decode.d2.loss_dice: 0.4871  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.6922  decode.d3.loss_dice: 0.4831  decode.d4.loss_cls: 0.0500  decode.d4.loss_mask: 0.6858  decode.d4.loss_dice: 0.4844  decode.d5.loss_cls: 0.0525  decode.d5.loss_mask: 0.6863  decode.d5.loss_dice: 0.4908  decode.d6.loss_cls: 0.0445  decode.d6.loss_mask: 0.6830  decode.d6.loss_dice: 0.4963  decode.d7.loss_cls: 0.0452  decode.d7.loss_mask: 0.6945  decode.d7.loss_dice: 0.4820  decode.d8.loss_cls: 0.0478  decode.d8.loss_mask: 0.6965  decode.d8.loss_dice: 0.4788
06/01 12:33:45 - mmengine - INFO - Iter(train) [150450/160000]  base_lr: 7.9122e-06 lr: 7.9122e-07  eta: 8:30:55  time: 0.6809  data_time: 0.0106  memory: 10504  grad_norm: 372.2351  loss: 15.8799  decode.loss_cls: 0.0953  decode.loss_mask: 0.8705  decode.loss_dice: 0.5946  decode.d0.loss_cls: 0.4794  decode.d0.loss_mask: 0.8257  decode.d0.loss_dice: 0.5816  decode.d1.loss_cls: 0.1071  decode.d1.loss_mask: 0.8552  decode.d1.loss_dice: 0.6264  decode.d2.loss_cls: 0.1040  decode.d2.loss_mask: 0.8534  decode.d2.loss_dice: 0.5998  decode.d3.loss_cls: 0.0700  decode.d3.loss_mask: 0.8714  decode.d3.loss_dice: 0.6125  decode.d4.loss_cls: 0.0728  decode.d4.loss_mask: 0.8664  decode.d4.loss_dice: 0.6094  decode.d5.loss_cls: 0.0691  decode.d5.loss_mask: 0.8669  decode.d5.loss_dice: 0.6160  decode.d6.loss_cls: 0.0722  decode.d6.loss_mask: 0.8505  decode.d6.loss_dice: 0.6102  decode.d7.loss_cls: 0.0743  decode.d7.loss_mask: 0.8663  decode.d7.loss_dice: 0.6188  decode.d8.loss_cls: 0.0955  decode.d8.loss_mask: 0.8293  decode.d8.loss_dice: 0.6151
06/01 12:34:17 - mmengine - INFO - Iter(train) [150500/160000]  base_lr: 7.8749e-06 lr: 7.8749e-07  eta: 8:24:33  time: 0.6440  data_time: 0.0106  memory: 10496  grad_norm: 247.8498  loss: 14.1190  decode.loss_cls: 0.0920  decode.loss_mask: 0.7156  decode.loss_dice: 0.5466  decode.d0.loss_cls: 0.4480  decode.d0.loss_mask: 0.7382  decode.d0.loss_dice: 0.5772  decode.d1.loss_cls: 0.0781  decode.d1.loss_mask: 0.7418  decode.d1.loss_dice: 0.5594  decode.d2.loss_cls: 0.0878  decode.d2.loss_mask: 0.7299  decode.d2.loss_dice: 0.5604  decode.d3.loss_cls: 0.0753  decode.d3.loss_mask: 0.7343  decode.d3.loss_dice: 0.5335  decode.d4.loss_cls: 0.1013  decode.d4.loss_mask: 0.7371  decode.d4.loss_dice: 0.5366  decode.d5.loss_cls: 0.0836  decode.d5.loss_mask: 0.7378  decode.d5.loss_dice: 0.5661  decode.d6.loss_cls: 0.0831  decode.d6.loss_mask: 0.7138  decode.d6.loss_dice: 0.5505  decode.d7.loss_cls: 0.0805  decode.d7.loss_mask: 0.7279  decode.d7.loss_dice: 0.5776  decode.d8.loss_cls: 0.0744  decode.d8.loss_mask: 0.7489  decode.d8.loss_dice: 0.5817
06/01 12:34:49 - mmengine - INFO - Iter(train) [150550/160000]  base_lr: 7.8376e-06 lr: 7.8376e-07  eta: 8:18:17  time: 0.6404  data_time: 0.0106  memory: 10495  grad_norm: 404.4421  loss: 16.8748  decode.loss_cls: 0.0785  decode.loss_mask: 0.9178  decode.loss_dice: 0.6519  decode.d0.loss_cls: 0.5101  decode.d0.loss_mask: 0.8845  decode.d0.loss_dice: 0.6408  decode.d1.loss_cls: 0.0848  decode.d1.loss_mask: 0.9115  decode.d1.loss_dice: 0.6471  decode.d2.loss_cls: 0.0977  decode.d2.loss_mask: 0.9139  decode.d2.loss_dice: 0.6485  decode.d3.loss_cls: 0.0717  decode.d3.loss_mask: 0.9145  decode.d3.loss_dice: 0.6592  decode.d4.loss_cls: 0.0774  decode.d4.loss_mask: 0.9175  decode.d4.loss_dice: 0.6512  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.9176  decode.d5.loss_dice: 0.6596  decode.d6.loss_cls: 0.0742  decode.d6.loss_mask: 0.9207  decode.d6.loss_dice: 0.6562  decode.d7.loss_cls: 0.0853  decode.d7.loss_mask: 0.9133  decode.d7.loss_dice: 0.6534  decode.d8.loss_cls: 0.0764  decode.d8.loss_mask: 0.9178  decode.d8.loss_dice: 0.6471
06/01 12:35:21 - mmengine - INFO - Iter(train) [150600/160000]  base_lr: 7.8003e-06 lr: 7.8003e-07  eta: 8:12:07  time: 0.6429  data_time: 0.0107  memory: 10500  grad_norm: 1155.1837  loss: 16.6459  decode.loss_cls: 0.0388  decode.loss_mask: 0.9360  decode.loss_dice: 0.6300  decode.d0.loss_cls: 0.5119  decode.d0.loss_mask: 0.9360  decode.d0.loss_dice: 0.6038  decode.d1.loss_cls: 0.0395  decode.d1.loss_mask: 0.9691  decode.d1.loss_dice: 0.6414  decode.d2.loss_cls: 0.0281  decode.d2.loss_mask: 0.9588  decode.d2.loss_dice: 0.6412  decode.d3.loss_cls: 0.0350  decode.d3.loss_mask: 0.9422  decode.d3.loss_dice: 0.6305  decode.d4.loss_cls: 0.0494  decode.d4.loss_mask: 0.9467  decode.d4.loss_dice: 0.6290  decode.d5.loss_cls: 0.0454  decode.d5.loss_mask: 0.9443  decode.d5.loss_dice: 0.6346  decode.d6.loss_cls: 0.0457  decode.d6.loss_mask: 0.9352  decode.d6.loss_dice: 0.6275  decode.d7.loss_cls: 0.0426  decode.d7.loss_mask: 0.9486  decode.d7.loss_dice: 0.6347  decode.d8.loss_cls: 0.0445  decode.d8.loss_mask: 0.9431  decode.d8.loss_dice: 0.6324
06/01 12:35:53 - mmengine - INFO - Iter(train) [150650/160000]  base_lr: 7.7629e-06 lr: 7.7629e-07  eta: 8:06:03  time: 0.6423  data_time: 0.0107  memory: 10492  grad_norm: 1222.3338  loss: 13.3046  decode.loss_cls: 0.0271  decode.loss_mask: 0.7479  decode.loss_dice: 0.5124  decode.d0.loss_cls: 0.4762  decode.d0.loss_mask: 0.7583  decode.d0.loss_dice: 0.5095  decode.d1.loss_cls: 0.0385  decode.d1.loss_mask: 0.7518  decode.d1.loss_dice: 0.5111  decode.d2.loss_cls: 0.0100  decode.d2.loss_mask: 0.7501  decode.d2.loss_dice: 0.5236  decode.d3.loss_cls: 0.0271  decode.d3.loss_mask: 0.7449  decode.d3.loss_dice: 0.5024  decode.d4.loss_cls: 0.0295  decode.d4.loss_mask: 0.7444  decode.d4.loss_dice: 0.5083  decode.d5.loss_cls: 0.0117  decode.d5.loss_mask: 0.7489  decode.d5.loss_dice: 0.5197  decode.d6.loss_cls: 0.0304  decode.d6.loss_mask: 0.7451  decode.d6.loss_dice: 0.5069  decode.d7.loss_cls: 0.0285  decode.d7.loss_mask: 0.7475  decode.d7.loss_dice: 0.5064  decode.d8.loss_cls: 0.0240  decode.d8.loss_mask: 0.7479  decode.d8.loss_dice: 0.5144
06/01 12:36:26 - mmengine - INFO - Iter(train) [150700/160000]  base_lr: 7.7255e-06 lr: 7.7255e-07  eta: 8:00:05  time: 0.6440  data_time: 0.0107  memory: 10491  grad_norm: 469.8007  loss: 13.3025  decode.loss_cls: 0.0445  decode.loss_mask: 0.7213  decode.loss_dice: 0.5205  decode.d0.loss_cls: 0.4523  decode.d0.loss_mask: 0.7209  decode.d0.loss_dice: 0.5221  decode.d1.loss_cls: 0.0480  decode.d1.loss_mask: 0.7255  decode.d1.loss_dice: 0.5192  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.7250  decode.d2.loss_dice: 0.5280  decode.d3.loss_cls: 0.0420  decode.d3.loss_mask: 0.7254  decode.d3.loss_dice: 0.5126  decode.d4.loss_cls: 0.0431  decode.d4.loss_mask: 0.7199  decode.d4.loss_dice: 0.5232  decode.d5.loss_cls: 0.0426  decode.d5.loss_mask: 0.7207  decode.d5.loss_dice: 0.5217  decode.d6.loss_cls: 0.0515  decode.d6.loss_mask: 0.7213  decode.d6.loss_dice: 0.5212  decode.d7.loss_cls: 0.0492  decode.d7.loss_mask: 0.7195  decode.d7.loss_dice: 0.5204  decode.d8.loss_cls: 0.0436  decode.d8.loss_mask: 0.7213  decode.d8.loss_dice: 0.5246
06/01 12:36:58 - mmengine - INFO - Iter(train) [150750/160000]  base_lr: 7.6882e-06 lr: 7.6882e-07  eta: 7:54:14  time: 0.6422  data_time: 0.0106  memory: 10491  grad_norm: 393.3411  loss: 16.5468  decode.loss_cls: 0.1217  decode.loss_mask: 0.8547  decode.loss_dice: 0.6252  decode.d0.loss_cls: 0.6970  decode.d0.loss_mask: 0.7968  decode.d0.loss_dice: 0.5600  decode.d1.loss_cls: 0.1675  decode.d1.loss_mask: 0.8459  decode.d1.loss_dice: 0.6225  decode.d2.loss_cls: 0.1507  decode.d2.loss_mask: 0.8487  decode.d2.loss_dice: 0.6415  decode.d3.loss_cls: 0.1183  decode.d3.loss_mask: 0.8522  decode.d3.loss_dice: 0.6310  decode.d4.loss_cls: 0.1191  decode.d4.loss_mask: 0.8626  decode.d4.loss_dice: 0.6232  decode.d5.loss_cls: 0.1260  decode.d5.loss_mask: 0.8538  decode.d5.loss_dice: 0.6165  decode.d6.loss_cls: 0.1271  decode.d6.loss_mask: 0.8618  decode.d6.loss_dice: 0.6154  decode.d7.loss_cls: 0.1388  decode.d7.loss_mask: 0.8460  decode.d7.loss_dice: 0.6216  decode.d8.loss_cls: 0.1307  decode.d8.loss_mask: 0.8482  decode.d8.loss_dice: 0.6224
06/01 12:37:30 - mmengine - INFO - Iter(train) [150800/160000]  base_lr: 7.6507e-06 lr: 7.6507e-07  eta: 7:48:27  time: 0.6428  data_time: 0.0107  memory: 10504  grad_norm: 261.4572  loss: 14.2060  decode.loss_cls: 0.0750  decode.loss_mask: 0.7842  decode.loss_dice: 0.5406  decode.d0.loss_cls: 0.4463  decode.d0.loss_mask: 0.7273  decode.d0.loss_dice: 0.5391  decode.d1.loss_cls: 0.1109  decode.d1.loss_mask: 0.7271  decode.d1.loss_dice: 0.5371  decode.d2.loss_cls: 0.0800  decode.d2.loss_mask: 0.7817  decode.d2.loss_dice: 0.5369  decode.d3.loss_cls: 0.0756  decode.d3.loss_mask: 0.7818  decode.d3.loss_dice: 0.5328  decode.d4.loss_cls: 0.1190  decode.d4.loss_mask: 0.7302  decode.d4.loss_dice: 0.5311  decode.d5.loss_cls: 0.1115  decode.d5.loss_mask: 0.7309  decode.d5.loss_dice: 0.5478  decode.d6.loss_cls: 0.0746  decode.d6.loss_mask: 0.7786  decode.d6.loss_dice: 0.5317  decode.d7.loss_cls: 0.1158  decode.d7.loss_mask: 0.7243  decode.d7.loss_dice: 0.5319  decode.d8.loss_cls: 0.0697  decode.d8.loss_mask: 0.7906  decode.d8.loss_dice: 0.5420
06/01 12:38:02 - mmengine - INFO - Iter(train) [150850/160000]  base_lr: 7.6133e-06 lr: 7.6133e-07  eta: 7:42:45  time: 0.6418  data_time: 0.0105  memory: 10513  grad_norm: 694.2868  loss: 19.5429  decode.loss_cls: 0.0801  decode.loss_mask: 1.1141  decode.loss_dice: 0.7214  decode.d0.loss_cls: 0.5808  decode.d0.loss_mask: 1.0687  decode.d0.loss_dice: 0.6486  decode.d1.loss_cls: 0.0813  decode.d1.loss_mask: 1.1867  decode.d1.loss_dice: 0.7013  decode.d2.loss_cls: 0.0762  decode.d2.loss_mask: 1.1365  decode.d2.loss_dice: 0.6989  decode.d3.loss_cls: 0.0847  decode.d3.loss_mask: 1.1057  decode.d3.loss_dice: 0.6997  decode.d4.loss_cls: 0.0967  decode.d4.loss_mask: 1.1181  decode.d4.loss_dice: 0.6898  decode.d5.loss_cls: 0.0859  decode.d5.loss_mask: 1.1088  decode.d5.loss_dice: 0.6922  decode.d6.loss_cls: 0.0737  decode.d6.loss_mask: 1.1188  decode.d6.loss_dice: 0.7049  decode.d7.loss_cls: 0.0916  decode.d7.loss_mask: 1.1086  decode.d7.loss_dice: 0.6887  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 1.1860  decode.d8.loss_dice: 0.7353
06/01 12:38:35 - mmengine - INFO - Iter(train) [150900/160000]  base_lr: 7.5759e-06 lr: 7.5759e-07  eta: 7:37:09  time: 0.6424  data_time: 0.0107  memory: 10494  grad_norm: 452.7959  loss: 14.4673  decode.loss_cls: 0.0198  decode.loss_mask: 0.8555  decode.loss_dice: 0.5180  decode.d0.loss_cls: 0.5351  decode.d0.loss_mask: 0.7867  decode.d0.loss_dice: 0.5030  decode.d1.loss_cls: 0.0384  decode.d1.loss_mask: 0.8392  decode.d1.loss_dice: 0.5291  decode.d2.loss_cls: 0.0187  decode.d2.loss_mask: 0.8585  decode.d2.loss_dice: 0.5258  decode.d3.loss_cls: 0.0194  decode.d3.loss_mask: 0.8629  decode.d3.loss_dice: 0.5311  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 0.8519  decode.d4.loss_dice: 0.5103  decode.d5.loss_cls: 0.0199  decode.d5.loss_mask: 0.8546  decode.d5.loss_dice: 0.5192  decode.d6.loss_cls: 0.0190  decode.d6.loss_mask: 0.8564  decode.d6.loss_dice: 0.5199  decode.d7.loss_cls: 0.0291  decode.d7.loss_mask: 0.8591  decode.d7.loss_dice: 0.5206  decode.d8.loss_cls: 0.0373  decode.d8.loss_mask: 0.8600  decode.d8.loss_dice: 0.5224
06/01 12:39:07 - mmengine - INFO - Iter(train) [150950/160000]  base_lr: 7.5384e-06 lr: 7.5384e-07  eta: 7:31:38  time: 0.6415  data_time: 0.0106  memory: 10495  grad_norm: 664.1746  loss: 15.1867  decode.loss_cls: 0.1366  decode.loss_mask: 0.7742  decode.loss_dice: 0.5457  decode.d0.loss_cls: 0.5244  decode.d0.loss_mask: 0.7621  decode.d0.loss_dice: 0.5108  decode.d1.loss_cls: 0.1238  decode.d1.loss_mask: 0.8599  decode.d1.loss_dice: 0.5530  decode.d2.loss_cls: 0.0951  decode.d2.loss_mask: 0.8470  decode.d2.loss_dice: 0.5368  decode.d3.loss_cls: 0.1463  decode.d3.loss_mask: 0.7880  decode.d3.loss_dice: 0.5522  decode.d4.loss_cls: 0.1705  decode.d4.loss_mask: 0.7857  decode.d4.loss_dice: 0.5419  decode.d5.loss_cls: 0.1071  decode.d5.loss_mask: 0.8501  decode.d5.loss_dice: 0.5422  decode.d6.loss_cls: 0.1073  decode.d6.loss_mask: 0.8524  decode.d6.loss_dice: 0.5462  decode.d7.loss_cls: 0.1076  decode.d7.loss_mask: 0.8570  decode.d7.loss_dice: 0.5459  decode.d8.loss_cls: 0.1310  decode.d8.loss_mask: 0.7628  decode.d8.loss_dice: 0.5230
06/01 12:39:39 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 12:39:39 - mmengine - INFO - Iter(train) [151000/160000]  base_lr: 7.5009e-06 lr: 7.5009e-07  eta: 7:26:12  time: 0.6420  data_time: 0.0107  memory: 10498  grad_norm: 488.5807  loss: 16.0311  decode.loss_cls: 0.1088  decode.loss_mask: 0.8559  decode.loss_dice: 0.5826  decode.d0.loss_cls: 0.5721  decode.d0.loss_mask: 0.8432  decode.d0.loss_dice: 0.5930  decode.d1.loss_cls: 0.1151  decode.d1.loss_mask: 0.8274  decode.d1.loss_dice: 0.5885  decode.d2.loss_cls: 0.0907  decode.d2.loss_mask: 0.8870  decode.d2.loss_dice: 0.5811  decode.d3.loss_cls: 0.1227  decode.d3.loss_mask: 0.8381  decode.d3.loss_dice: 0.5764  decode.d4.loss_cls: 0.1241  decode.d4.loss_mask: 0.8527  decode.d4.loss_dice: 0.5808  decode.d5.loss_cls: 0.0841  decode.d5.loss_mask: 0.9327  decode.d5.loss_dice: 0.5844  decode.d6.loss_cls: 0.1339  decode.d6.loss_mask: 0.8524  decode.d6.loss_dice: 0.5814  decode.d7.loss_cls: 0.1078  decode.d7.loss_mask: 0.8579  decode.d7.loss_dice: 0.5715  decode.d8.loss_cls: 0.1271  decode.d8.loss_mask: 0.8665  decode.d8.loss_dice: 0.5912
06/01 12:40:11 - mmengine - INFO - Iter(train) [151050/160000]  base_lr: 7.4634e-06 lr: 7.4634e-07  eta: 7:20:51  time: 0.6435  data_time: 0.0108  memory: 10492  grad_norm: 342.3648  loss: 13.9543  decode.loss_cls: 0.0490  decode.loss_mask: 0.8014  decode.loss_dice: 0.4963  decode.d0.loss_cls: 0.5004  decode.d0.loss_mask: 0.7858  decode.d0.loss_dice: 0.4716  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.7843  decode.d1.loss_dice: 0.4889  decode.d2.loss_cls: 0.0793  decode.d2.loss_mask: 0.7848  decode.d2.loss_dice: 0.5121  decode.d3.loss_cls: 0.0830  decode.d3.loss_mask: 0.7866  decode.d3.loss_dice: 0.4889  decode.d4.loss_cls: 0.0894  decode.d4.loss_mask: 0.7843  decode.d4.loss_dice: 0.4903  decode.d5.loss_cls: 0.0783  decode.d5.loss_mask: 0.7828  decode.d5.loss_dice: 0.4883  decode.d6.loss_cls: 0.0753  decode.d6.loss_mask: 0.7822  decode.d6.loss_dice: 0.4764  decode.d7.loss_cls: 0.0851  decode.d7.loss_mask: 0.7927  decode.d7.loss_dice: 0.4789  decode.d8.loss_cls: 0.0927  decode.d8.loss_mask: 0.7851  decode.d8.loss_dice: 0.4830
06/01 12:40:43 - mmengine - INFO - Iter(train) [151100/160000]  base_lr: 7.4258e-06 lr: 7.4258e-07  eta: 7:15:34  time: 0.6426  data_time: 0.0107  memory: 10505  grad_norm: 1079.7236  loss: 13.9259  decode.loss_cls: 0.0936  decode.loss_mask: 0.7175  decode.loss_dice: 0.4997  decode.d0.loss_cls: 0.4870  decode.d0.loss_mask: 0.7280  decode.d0.loss_dice: 0.5274  decode.d1.loss_cls: 0.1110  decode.d1.loss_mask: 0.7133  decode.d1.loss_dice: 0.5245  decode.d2.loss_cls: 0.1203  decode.d2.loss_mask: 0.7213  decode.d2.loss_dice: 0.5137  decode.d3.loss_cls: 0.1656  decode.d3.loss_mask: 0.7238  decode.d3.loss_dice: 0.5320  decode.d4.loss_cls: 0.1055  decode.d4.loss_mask: 0.7255  decode.d4.loss_dice: 0.5497  decode.d5.loss_cls: 0.0978  decode.d5.loss_mask: 0.7093  decode.d5.loss_dice: 0.5138  decode.d6.loss_cls: 0.1159  decode.d6.loss_mask: 0.7116  decode.d6.loss_dice: 0.5200  decode.d7.loss_cls: 0.0747  decode.d7.loss_mask: 0.7241  decode.d7.loss_dice: 0.5208  decode.d8.loss_cls: 0.1138  decode.d8.loss_mask: 0.7317  decode.d8.loss_dice: 0.5331
06/01 12:41:15 - mmengine - INFO - Iter(train) [151150/160000]  base_lr: 7.3883e-06 lr: 7.3883e-07  eta: 7:10:22  time: 0.6413  data_time: 0.0106  memory: 10492  grad_norm: 409.6831  loss: 13.7218  decode.loss_cls: 0.0669  decode.loss_mask: 0.7464  decode.loss_dice: 0.5036  decode.d0.loss_cls: 0.4850  decode.d0.loss_mask: 0.7506  decode.d0.loss_dice: 0.5009  decode.d1.loss_cls: 0.1258  decode.d1.loss_mask: 0.7542  decode.d1.loss_dice: 0.5064  decode.d2.loss_cls: 0.0845  decode.d2.loss_mask: 0.7523  decode.d2.loss_dice: 0.4904  decode.d3.loss_cls: 0.0733  decode.d3.loss_mask: 0.7479  decode.d3.loss_dice: 0.5216  decode.d4.loss_cls: 0.0652  decode.d4.loss_mask: 0.7436  decode.d4.loss_dice: 0.4971  decode.d5.loss_cls: 0.0735  decode.d5.loss_mask: 0.7410  decode.d5.loss_dice: 0.4966  decode.d6.loss_cls: 0.0728  decode.d6.loss_mask: 0.7437  decode.d6.loss_dice: 0.4999  decode.d7.loss_cls: 0.0781  decode.d7.loss_mask: 0.7527  decode.d7.loss_dice: 0.5108  decode.d8.loss_cls: 0.0797  decode.d8.loss_mask: 0.7458  decode.d8.loss_dice: 0.5117
06/01 12:41:47 - mmengine - INFO - Iter(train) [151200/160000]  base_lr: 7.3507e-06 lr: 7.3507e-07  eta: 7:05:15  time: 0.6420  data_time: 0.0107  memory: 10492  grad_norm: 429.0380  loss: 15.5182  decode.loss_cls: 0.1016  decode.loss_mask: 0.8611  decode.loss_dice: 0.5603  decode.d0.loss_cls: 0.5390  decode.d0.loss_mask: 0.8521  decode.d0.loss_dice: 0.5622  decode.d1.loss_cls: 0.1028  decode.d1.loss_mask: 0.8659  decode.d1.loss_dice: 0.5791  decode.d2.loss_cls: 0.0977  decode.d2.loss_mask: 0.8432  decode.d2.loss_dice: 0.5502  decode.d3.loss_cls: 0.1082  decode.d3.loss_mask: 0.8709  decode.d3.loss_dice: 0.5567  decode.d4.loss_cls: 0.1043  decode.d4.loss_mask: 0.8225  decode.d4.loss_dice: 0.5408  decode.d5.loss_cls: 0.1082  decode.d5.loss_mask: 0.8402  decode.d5.loss_dice: 0.5371  decode.d6.loss_cls: 0.1202  decode.d6.loss_mask: 0.8541  decode.d6.loss_dice: 0.5395  decode.d7.loss_cls: 0.1262  decode.d7.loss_mask: 0.8292  decode.d7.loss_dice: 0.5369  decode.d8.loss_cls: 0.1294  decode.d8.loss_mask: 0.8419  decode.d8.loss_dice: 0.5369
06/01 12:42:20 - mmengine - INFO - Iter(train) [151250/160000]  base_lr: 7.3131e-06 lr: 7.3131e-07  eta: 7:00:12  time: 0.6415  data_time: 0.0106  memory: 10492  grad_norm: 392.8085  loss: 13.6369  decode.loss_cls: 0.0631  decode.loss_mask: 0.6867  decode.loss_dice: 0.5598  decode.d0.loss_cls: 0.5466  decode.d0.loss_mask: 0.6590  decode.d0.loss_dice: 0.5465  decode.d1.loss_cls: 0.1057  decode.d1.loss_mask: 0.6785  decode.d1.loss_dice: 0.5406  decode.d2.loss_cls: 0.0794  decode.d2.loss_mask: 0.6799  decode.d2.loss_dice: 0.5518  decode.d3.loss_cls: 0.0731  decode.d3.loss_mask: 0.6875  decode.d3.loss_dice: 0.5606  decode.d4.loss_cls: 0.0953  decode.d4.loss_mask: 0.6893  decode.d4.loss_dice: 0.5619  decode.d5.loss_cls: 0.0970  decode.d5.loss_mask: 0.6772  decode.d5.loss_dice: 0.5468  decode.d6.loss_cls: 0.0745  decode.d6.loss_mask: 0.6838  decode.d6.loss_dice: 0.5572  decode.d7.loss_cls: 0.0767  decode.d7.loss_mask: 0.6841  decode.d7.loss_dice: 0.5572  decode.d8.loss_cls: 0.0763  decode.d8.loss_mask: 0.6846  decode.d8.loss_dice: 0.5564
06/01 12:42:52 - mmengine - INFO - Iter(train) [151300/160000]  base_lr: 7.2755e-06 lr: 7.2755e-07  eta: 6:55:13  time: 0.6427  data_time: 0.0105  memory: 10495  grad_norm: 188.7742  loss: 12.7831  decode.loss_cls: 0.0174  decode.loss_mask: 0.7675  decode.loss_dice: 0.4608  decode.d0.loss_cls: 0.3625  decode.d0.loss_mask: 0.7771  decode.d0.loss_dice: 0.4686  decode.d1.loss_cls: 0.0419  decode.d1.loss_mask: 0.7709  decode.d1.loss_dice: 0.4552  decode.d2.loss_cls: 0.0161  decode.d2.loss_mask: 0.7628  decode.d2.loss_dice: 0.4543  decode.d3.loss_cls: 0.0158  decode.d3.loss_mask: 0.7642  decode.d3.loss_dice: 0.4572  decode.d4.loss_cls: 0.0152  decode.d4.loss_mask: 0.7641  decode.d4.loss_dice: 0.4601  decode.d5.loss_cls: 0.0153  decode.d5.loss_mask: 0.7675  decode.d5.loss_dice: 0.4579  decode.d6.loss_cls: 0.0162  decode.d6.loss_mask: 0.7581  decode.d6.loss_dice: 0.4594  decode.d7.loss_cls: 0.0184  decode.d7.loss_mask: 0.7645  decode.d7.loss_dice: 0.4576  decode.d8.loss_cls: 0.0156  decode.d8.loss_mask: 0.7650  decode.d8.loss_dice: 0.4561
06/01 12:43:24 - mmengine - INFO - Iter(train) [151350/160000]  base_lr: 7.2378e-06 lr: 7.2378e-07  eta: 6:50:19  time: 0.6415  data_time: 0.0107  memory: 10495  grad_norm: 878.4897  loss: 16.1134  decode.loss_cls: 0.0390  decode.loss_mask: 0.8994  decode.loss_dice: 0.6525  decode.d0.loss_cls: 0.4569  decode.d0.loss_mask: 0.8582  decode.d0.loss_dice: 0.6406  decode.d1.loss_cls: 0.0290  decode.d1.loss_mask: 0.8925  decode.d1.loss_dice: 0.6563  decode.d2.loss_cls: 0.0561  decode.d2.loss_mask: 0.8843  decode.d2.loss_dice: 0.6324  decode.d3.loss_cls: 0.0560  decode.d3.loss_mask: 0.8809  decode.d3.loss_dice: 0.6281  decode.d4.loss_cls: 0.0627  decode.d4.loss_mask: 0.8879  decode.d4.loss_dice: 0.6381  decode.d5.loss_cls: 0.0663  decode.d5.loss_mask: 0.8823  decode.d5.loss_dice: 0.6285  decode.d6.loss_cls: 0.0323  decode.d6.loss_mask: 0.8865  decode.d6.loss_dice: 0.6471  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.8863  decode.d7.loss_dice: 0.6375  decode.d8.loss_cls: 0.0419  decode.d8.loss_mask: 0.8836  decode.d8.loss_dice: 0.6350
06/01 12:43:56 - mmengine - INFO - Iter(train) [151400/160000]  base_lr: 7.2002e-06 lr: 7.2002e-07  eta: 6:45:28  time: 0.6424  data_time: 0.0107  memory: 10504  grad_norm: 265.1310  loss: 13.4296  decode.loss_cls: 0.0316  decode.loss_mask: 0.7262  decode.loss_dice: 0.5389  decode.d0.loss_cls: 0.4351  decode.d0.loss_mask: 0.7287  decode.d0.loss_dice: 0.5467  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.7266  decode.d1.loss_dice: 0.5404  decode.d2.loss_cls: 0.0257  decode.d2.loss_mask: 0.7261  decode.d2.loss_dice: 0.5424  decode.d3.loss_cls: 0.0305  decode.d3.loss_mask: 0.7257  decode.d3.loss_dice: 0.5473  decode.d4.loss_cls: 0.0341  decode.d4.loss_mask: 0.7271  decode.d4.loss_dice: 0.5435  decode.d5.loss_cls: 0.0318  decode.d5.loss_mask: 0.7286  decode.d5.loss_dice: 0.5437  decode.d6.loss_cls: 0.0306  decode.d6.loss_mask: 0.7298  decode.d6.loss_dice: 0.5447  decode.d7.loss_cls: 0.0247  decode.d7.loss_mask: 0.7310  decode.d7.loss_dice: 0.5412  decode.d8.loss_cls: 0.0297  decode.d8.loss_mask: 0.7281  decode.d8.loss_dice: 0.5436
06/01 12:44:28 - mmengine - INFO - Iter(train) [151450/160000]  base_lr: 7.1625e-06 lr: 7.1625e-07  eta: 6:40:42  time: 0.6423  data_time: 0.0106  memory: 10494  grad_norm: 322.3233  loss: 11.1079  decode.loss_cls: 0.0233  decode.loss_mask: 0.6129  decode.loss_dice: 0.4346  decode.d0.loss_cls: 0.3991  decode.d0.loss_mask: 0.6198  decode.d0.loss_dice: 0.4495  decode.d1.loss_cls: 0.0213  decode.d1.loss_mask: 0.6140  decode.d1.loss_dice: 0.4424  decode.d2.loss_cls: 0.0166  decode.d2.loss_mask: 0.6115  decode.d2.loss_dice: 0.4395  decode.d3.loss_cls: 0.0160  decode.d3.loss_mask: 0.6103  decode.d3.loss_dice: 0.4440  decode.d4.loss_cls: 0.0180  decode.d4.loss_mask: 0.6136  decode.d4.loss_dice: 0.4429  decode.d5.loss_cls: 0.0179  decode.d5.loss_mask: 0.6112  decode.d5.loss_dice: 0.4391  decode.d6.loss_cls: 0.0165  decode.d6.loss_mask: 0.6097  decode.d6.loss_dice: 0.4408  decode.d7.loss_cls: 0.0205  decode.d7.loss_mask: 0.6124  decode.d7.loss_dice: 0.4402  decode.d8.loss_cls: 0.0216  decode.d8.loss_mask: 0.6095  decode.d8.loss_dice: 0.4394
06/01 12:45:00 - mmengine - INFO - Iter(train) [151500/160000]  base_lr: 7.1248e-06 lr: 7.1248e-07  eta: 6:36:00  time: 0.6420  data_time: 0.0108  memory: 10490  grad_norm: 996.4862  loss: 17.0473  decode.loss_cls: 0.0700  decode.loss_mask: 0.9570  decode.loss_dice: 0.6233  decode.d0.loss_cls: 0.5044  decode.d0.loss_mask: 0.9572  decode.d0.loss_dice: 0.6305  decode.d1.loss_cls: 0.0910  decode.d1.loss_mask: 0.9598  decode.d1.loss_dice: 0.6323  decode.d2.loss_cls: 0.0802  decode.d2.loss_mask: 0.9585  decode.d2.loss_dice: 0.6280  decode.d3.loss_cls: 0.0778  decode.d3.loss_mask: 0.9501  decode.d3.loss_dice: 0.6261  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.9545  decode.d4.loss_dice: 0.6266  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.9573  decode.d5.loss_dice: 0.6313  decode.d6.loss_cls: 0.0687  decode.d6.loss_mask: 0.9552  decode.d6.loss_dice: 0.6299  decode.d7.loss_cls: 0.0714  decode.d7.loss_mask: 0.9570  decode.d7.loss_dice: 0.6256  decode.d8.loss_cls: 0.0814  decode.d8.loss_mask: 0.9540  decode.d8.loss_dice: 0.6276
06/01 12:45:32 - mmengine - INFO - Iter(train) [151550/160000]  base_lr: 7.0870e-06 lr: 7.0870e-07  eta: 6:31:21  time: 0.6418  data_time: 0.0107  memory: 10498  grad_norm: 838.9210  loss: 14.1411  decode.loss_cls: 0.0189  decode.loss_mask: 0.8369  decode.loss_dice: 0.5301  decode.d0.loss_cls: 0.4428  decode.d0.loss_mask: 0.8140  decode.d0.loss_dice: 0.5161  decode.d1.loss_cls: 0.0216  decode.d1.loss_mask: 0.8083  decode.d1.loss_dice: 0.5310  decode.d2.loss_cls: 0.0191  decode.d2.loss_mask: 0.8193  decode.d2.loss_dice: 0.5363  decode.d3.loss_cls: 0.0179  decode.d3.loss_mask: 0.8110  decode.d3.loss_dice: 0.5313  decode.d4.loss_cls: 0.0194  decode.d4.loss_mask: 0.8201  decode.d4.loss_dice: 0.5304  decode.d5.loss_cls: 0.0190  decode.d5.loss_mask: 0.8236  decode.d5.loss_dice: 0.5298  decode.d6.loss_cls: 0.0192  decode.d6.loss_mask: 0.8278  decode.d6.loss_dice: 0.5299  decode.d7.loss_cls: 0.0216  decode.d7.loss_mask: 0.8288  decode.d7.loss_dice: 0.5318  decode.d8.loss_cls: 0.0235  decode.d8.loss_mask: 0.8312  decode.d8.loss_dice: 0.5304
06/01 12:46:04 - mmengine - INFO - Iter(train) [151600/160000]  base_lr: 7.0493e-06 lr: 7.0493e-07  eta: 6:26:46  time: 0.6408  data_time: 0.0106  memory: 10492  grad_norm: 287.5048  loss: 12.7688  decode.loss_cls: 0.0987  decode.loss_mask: 0.6718  decode.loss_dice: 0.4569  decode.d0.loss_cls: 0.5069  decode.d0.loss_mask: 0.6384  decode.d0.loss_dice: 0.4564  decode.d1.loss_cls: 0.0887  decode.d1.loss_mask: 0.6847  decode.d1.loss_dice: 0.4512  decode.d2.loss_cls: 0.1307  decode.d2.loss_mask: 0.6451  decode.d2.loss_dice: 0.4448  decode.d3.loss_cls: 0.1098  decode.d3.loss_mask: 0.6876  decode.d3.loss_dice: 0.4666  decode.d4.loss_cls: 0.1144  decode.d4.loss_mask: 0.6472  decode.d4.loss_dice: 0.4518  decode.d5.loss_cls: 0.0998  decode.d5.loss_mask: 0.6877  decode.d5.loss_dice: 0.4582  decode.d6.loss_cls: 0.1052  decode.d6.loss_mask: 0.6876  decode.d6.loss_dice: 0.4620  decode.d7.loss_cls: 0.1198  decode.d7.loss_mask: 0.6879  decode.d7.loss_dice: 0.4678  decode.d8.loss_cls: 0.0912  decode.d8.loss_mask: 0.6842  decode.d8.loss_dice: 0.4656
06/01 12:46:37 - mmengine - INFO - Iter(train) [151650/160000]  base_lr: 7.0115e-06 lr: 7.0115e-07  eta: 6:22:15  time: 0.6415  data_time: 0.0106  memory: 10496  grad_norm: 201.9490  loss: 12.7967  decode.loss_cls: 0.0905  decode.loss_mask: 0.6423  decode.loss_dice: 0.5013  decode.d0.loss_cls: 0.5432  decode.d0.loss_mask: 0.6430  decode.d0.loss_dice: 0.4985  decode.d1.loss_cls: 0.0983  decode.d1.loss_mask: 0.6338  decode.d1.loss_dice: 0.4961  decode.d2.loss_cls: 0.0719  decode.d2.loss_mask: 0.6450  decode.d2.loss_dice: 0.5087  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.6429  decode.d3.loss_dice: 0.5089  decode.d4.loss_cls: 0.0739  decode.d4.loss_mask: 0.6526  decode.d4.loss_dice: 0.5061  decode.d5.loss_cls: 0.0823  decode.d5.loss_mask: 0.6584  decode.d5.loss_dice: 0.5061  decode.d6.loss_cls: 0.0866  decode.d6.loss_mask: 0.6494  decode.d6.loss_dice: 0.5119  decode.d7.loss_cls: 0.0917  decode.d7.loss_mask: 0.6352  decode.d7.loss_dice: 0.4988  decode.d8.loss_cls: 0.0961  decode.d8.loss_mask: 0.6417  decode.d8.loss_dice: 0.5084
06/01 12:47:09 - mmengine - INFO - Iter(train) [151700/160000]  base_lr: 6.9737e-06 lr: 6.9737e-07  eta: 6:17:47  time: 0.6416  data_time: 0.0106  memory: 10495  grad_norm: 198.2242  loss: 13.6410  decode.loss_cls: 0.0784  decode.loss_mask: 0.7465  decode.loss_dice: 0.5066  decode.d0.loss_cls: 0.5426  decode.d0.loss_mask: 0.7410  decode.d0.loss_dice: 0.5150  decode.d1.loss_cls: 0.0792  decode.d1.loss_mask: 0.7417  decode.d1.loss_dice: 0.5224  decode.d2.loss_cls: 0.0790  decode.d2.loss_mask: 0.7362  decode.d2.loss_dice: 0.5066  decode.d3.loss_cls: 0.0686  decode.d3.loss_mask: 0.7504  decode.d3.loss_dice: 0.5234  decode.d4.loss_cls: 0.0765  decode.d4.loss_mask: 0.7255  decode.d4.loss_dice: 0.5037  decode.d5.loss_cls: 0.0796  decode.d5.loss_mask: 0.7235  decode.d5.loss_dice: 0.4954  decode.d6.loss_cls: 0.0915  decode.d6.loss_mask: 0.7175  decode.d6.loss_dice: 0.4963  decode.d7.loss_cls: 0.0842  decode.d7.loss_mask: 0.7253  decode.d7.loss_dice: 0.5078  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.7265  decode.d8.loss_dice: 0.4763
06/01 12:47:41 - mmengine - INFO - Iter(train) [151750/160000]  base_lr: 6.9359e-06 lr: 6.9359e-07  eta: 6:13:23  time: 0.6432  data_time: 0.0108  memory: 10494  grad_norm: 380.3577  loss: 14.5663  decode.loss_cls: 0.0888  decode.loss_mask: 0.7748  decode.loss_dice: 0.5385  decode.d0.loss_cls: 0.5267  decode.d0.loss_mask: 0.7708  decode.d0.loss_dice: 0.5139  decode.d1.loss_cls: 0.1127  decode.d1.loss_mask: 0.7738  decode.d1.loss_dice: 0.5229  decode.d2.loss_cls: 0.0925  decode.d2.loss_mask: 0.7719  decode.d2.loss_dice: 0.5324  decode.d3.loss_cls: 0.0954  decode.d3.loss_mask: 0.7838  decode.d3.loss_dice: 0.5333  decode.d4.loss_cls: 0.0993  decode.d4.loss_mask: 0.7700  decode.d4.loss_dice: 0.5298  decode.d5.loss_cls: 0.0958  decode.d5.loss_mask: 0.7878  decode.d5.loss_dice: 0.5471  decode.d6.loss_cls: 0.0994  decode.d6.loss_mask: 0.7933  decode.d6.loss_dice: 0.5523  decode.d7.loss_cls: 0.0998  decode.d7.loss_mask: 0.7924  decode.d7.loss_dice: 0.5417  decode.d8.loss_cls: 0.1124  decode.d8.loss_mask: 0.7753  decode.d8.loss_dice: 0.5377
06/01 12:48:13 - mmengine - INFO - Iter(train) [151800/160000]  base_lr: 6.8981e-06 lr: 6.8981e-07  eta: 6:09:02  time: 0.6417  data_time: 0.0107  memory: 10495  grad_norm: 704.5450  loss: 15.9844  decode.loss_cls: 0.1217  decode.loss_mask: 0.7835  decode.loss_dice: 0.6497  decode.d0.loss_cls: 0.5314  decode.d0.loss_mask: 0.8315  decode.d0.loss_dice: 0.6361  decode.d1.loss_cls: 0.1052  decode.d1.loss_mask: 0.8185  decode.d1.loss_dice: 0.6484  decode.d2.loss_cls: 0.0841  decode.d2.loss_mask: 0.8201  decode.d2.loss_dice: 0.6432  decode.d3.loss_cls: 0.1030  decode.d3.loss_mask: 0.8166  decode.d3.loss_dice: 0.6555  decode.d4.loss_cls: 0.1110  decode.d4.loss_mask: 0.8166  decode.d4.loss_dice: 0.6555  decode.d5.loss_cls: 0.1289  decode.d5.loss_mask: 0.7862  decode.d5.loss_dice: 0.6341  decode.d6.loss_cls: 0.1303  decode.d6.loss_mask: 0.7797  decode.d6.loss_dice: 0.6343  decode.d7.loss_cls: 0.1173  decode.d7.loss_mask: 0.7761  decode.d7.loss_dice: 0.6315  decode.d8.loss_cls: 0.1179  decode.d8.loss_mask: 0.7766  decode.d8.loss_dice: 0.6400
06/01 12:48:45 - mmengine - INFO - Iter(train) [151850/160000]  base_lr: 6.8602e-06 lr: 6.8602e-07  eta: 6:04:45  time: 0.6416  data_time: 0.0106  memory: 10503  grad_norm: 432.3697  loss: 14.8830  decode.loss_cls: 0.0426  decode.loss_mask: 0.8359  decode.loss_dice: 0.5627  decode.d0.loss_cls: 0.5129  decode.d0.loss_mask: 0.8357  decode.d0.loss_dice: 0.5352  decode.d1.loss_cls: 0.0429  decode.d1.loss_mask: 0.8338  decode.d1.loss_dice: 0.5704  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.8395  decode.d2.loss_dice: 0.5567  decode.d3.loss_cls: 0.0502  decode.d3.loss_mask: 0.8366  decode.d3.loss_dice: 0.5576  decode.d4.loss_cls: 0.0539  decode.d4.loss_mask: 0.8416  decode.d4.loss_dice: 0.5629  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.8400  decode.d5.loss_dice: 0.5562  decode.d6.loss_cls: 0.0497  decode.d6.loss_mask: 0.8330  decode.d6.loss_dice: 0.5522  decode.d7.loss_cls: 0.0494  decode.d7.loss_mask: 0.8375  decode.d7.loss_dice: 0.5546  decode.d8.loss_cls: 0.0429  decode.d8.loss_mask: 0.8368  decode.d8.loss_dice: 0.5512
06/01 12:49:17 - mmengine - INFO - Iter(train) [151900/160000]  base_lr: 6.8223e-06 lr: 6.8223e-07  eta: 6:00:30  time: 0.6433  data_time: 0.0107  memory: 10501  grad_norm: 535.1695  loss: 16.8243  decode.loss_cls: 0.1840  decode.loss_mask: 0.8677  decode.loss_dice: 0.5760  decode.d0.loss_cls: 0.6591  decode.d0.loss_mask: 0.8176  decode.d0.loss_dice: 0.5692  decode.d1.loss_cls: 0.2490  decode.d1.loss_mask: 0.8583  decode.d1.loss_dice: 0.5788  decode.d2.loss_cls: 0.1640  decode.d2.loss_mask: 0.8818  decode.d2.loss_dice: 0.5800  decode.d3.loss_cls: 0.1670  decode.d3.loss_mask: 0.8668  decode.d3.loss_dice: 0.5812  decode.d4.loss_cls: 0.1879  decode.d4.loss_mask: 0.8687  decode.d4.loss_dice: 0.5976  decode.d5.loss_cls: 0.1626  decode.d5.loss_mask: 0.8770  decode.d5.loss_dice: 0.5803  decode.d6.loss_cls: 0.1983  decode.d6.loss_mask: 0.8737  decode.d6.loss_dice: 0.5831  decode.d7.loss_cls: 0.1784  decode.d7.loss_mask: 0.8730  decode.d7.loss_dice: 0.5948  decode.d8.loss_cls: 0.1712  decode.d8.loss_mask: 0.8884  decode.d8.loss_dice: 0.5891
06/01 12:49:49 - mmengine - INFO - Iter(train) [151950/160000]  base_lr: 6.7844e-06 lr: 6.7844e-07  eta: 5:56:19  time: 0.6412  data_time: 0.0106  memory: 10504  grad_norm: 856.6149  loss: 15.3330  decode.loss_cls: 0.1291  decode.loss_mask: 0.8033  decode.loss_dice: 0.5801  decode.d0.loss_cls: 0.5301  decode.d0.loss_mask: 0.8152  decode.d0.loss_dice: 0.5791  decode.d1.loss_cls: 0.1180  decode.d1.loss_mask: 0.8133  decode.d1.loss_dice: 0.5721  decode.d2.loss_cls: 0.1004  decode.d2.loss_mask: 0.8225  decode.d2.loss_dice: 0.5671  decode.d3.loss_cls: 0.0970  decode.d3.loss_mask: 0.8153  decode.d3.loss_dice: 0.5728  decode.d4.loss_cls: 0.1254  decode.d4.loss_mask: 0.7903  decode.d4.loss_dice: 0.5484  decode.d5.loss_cls: 0.0984  decode.d5.loss_mask: 0.8281  decode.d5.loss_dice: 0.5745  decode.d6.loss_cls: 0.1523  decode.d6.loss_mask: 0.7923  decode.d6.loss_dice: 0.5587  decode.d7.loss_cls: 0.0915  decode.d7.loss_mask: 0.8150  decode.d7.loss_dice: 0.5726  decode.d8.loss_cls: 0.1136  decode.d8.loss_mask: 0.7920  decode.d8.loss_dice: 0.5647
06/01 12:50:22 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 12:50:22 - mmengine - INFO - Iter(train) [152000/160000]  base_lr: 6.7465e-06 lr: 6.7465e-07  eta: 5:52:12  time: 0.6417  data_time: 0.0106  memory: 10492  grad_norm: 340.7203  loss: 17.1014  decode.loss_cls: 0.1723  decode.loss_mask: 0.8485  decode.loss_dice: 0.6439  decode.d0.loss_cls: 0.5012  decode.d0.loss_mask: 0.8624  decode.d0.loss_dice: 0.6415  decode.d1.loss_cls: 0.1942  decode.d1.loss_mask: 0.8783  decode.d1.loss_dice: 0.6307  decode.d2.loss_cls: 0.1418  decode.d2.loss_mask: 0.8936  decode.d2.loss_dice: 0.6426  decode.d3.loss_cls: 0.1063  decode.d3.loss_mask: 0.9039  decode.d3.loss_dice: 0.6478  decode.d4.loss_cls: 0.1299  decode.d4.loss_mask: 0.9104  decode.d4.loss_dice: 0.6497  decode.d5.loss_cls: 0.1406  decode.d5.loss_mask: 0.8848  decode.d5.loss_dice: 0.6519  decode.d6.loss_cls: 0.1092  decode.d6.loss_mask: 0.9119  decode.d6.loss_dice: 0.6503  decode.d7.loss_cls: 0.1890  decode.d7.loss_mask: 0.8736  decode.d7.loss_dice: 0.6453  decode.d8.loss_cls: 0.1290  decode.d8.loss_mask: 0.8754  decode.d8.loss_dice: 0.6413
06/01 12:50:54 - mmengine - INFO - Iter(train) [152050/160000]  base_lr: 6.7085e-06 lr: 6.7085e-07  eta: 5:48:07  time: 0.6418  data_time: 0.0108  memory: 10517  grad_norm: 328.1692  loss: 16.2135  decode.loss_cls: 0.0362  decode.loss_mask: 0.9451  decode.loss_dice: 0.6008  decode.d0.loss_cls: 0.4803  decode.d0.loss_mask: 0.9253  decode.d0.loss_dice: 0.5921  decode.d1.loss_cls: 0.0281  decode.d1.loss_mask: 0.9457  decode.d1.loss_dice: 0.6071  decode.d2.loss_cls: 0.0246  decode.d2.loss_mask: 0.9449  decode.d2.loss_dice: 0.6050  decode.d3.loss_cls: 0.0239  decode.d3.loss_mask: 0.9393  decode.d3.loss_dice: 0.5993  decode.d4.loss_cls: 0.0328  decode.d4.loss_mask: 0.9442  decode.d4.loss_dice: 0.6024  decode.d5.loss_cls: 0.0355  decode.d5.loss_mask: 0.9442  decode.d5.loss_dice: 0.6002  decode.d6.loss_cls: 0.0423  decode.d6.loss_mask: 0.9405  decode.d6.loss_dice: 0.6039  decode.d7.loss_cls: 0.0390  decode.d7.loss_mask: 0.9374  decode.d7.loss_dice: 0.6031  decode.d8.loss_cls: 0.0398  decode.d8.loss_mask: 0.9453  decode.d8.loss_dice: 0.6054
06/01 12:51:26 - mmengine - INFO - Iter(train) [152100/160000]  base_lr: 6.6705e-06 lr: 6.6705e-07  eta: 5:44:05  time: 0.6422  data_time: 0.0107  memory: 10536  grad_norm: 498.8910  loss: 18.0485  decode.loss_cls: 0.1470  decode.loss_mask: 0.9344  decode.loss_dice: 0.6509  decode.d0.loss_cls: 0.5887  decode.d0.loss_mask: 0.9466  decode.d0.loss_dice: 0.6494  decode.d1.loss_cls: 0.1965  decode.d1.loss_mask: 0.9466  decode.d1.loss_dice: 0.6527  decode.d2.loss_cls: 0.1405  decode.d2.loss_mask: 0.9628  decode.d2.loss_dice: 0.6658  decode.d3.loss_cls: 0.1481  decode.d3.loss_mask: 0.9431  decode.d3.loss_dice: 0.6477  decode.d4.loss_cls: 0.1621  decode.d4.loss_mask: 0.9666  decode.d4.loss_dice: 0.6539  decode.d5.loss_cls: 0.1785  decode.d5.loss_mask: 0.9327  decode.d5.loss_dice: 0.6382  decode.d6.loss_cls: 0.1742  decode.d6.loss_mask: 0.9683  decode.d6.loss_dice: 0.6434  decode.d7.loss_cls: 0.1765  decode.d7.loss_mask: 0.9261  decode.d7.loss_dice: 0.6362  decode.d8.loss_cls: 0.1967  decode.d8.loss_mask: 0.9293  decode.d8.loss_dice: 0.6452
06/01 12:51:58 - mmengine - INFO - Iter(train) [152150/160000]  base_lr: 6.6325e-06 lr: 6.6325e-07  eta: 5:40:06  time: 0.6414  data_time: 0.0107  memory: 10492  grad_norm: 223.7998  loss: 13.1585  decode.loss_cls: 0.0727  decode.loss_mask: 0.7042  decode.loss_dice: 0.4834  decode.d0.loss_cls: 0.6053  decode.d0.loss_mask: 0.6785  decode.d0.loss_dice: 0.4936  decode.d1.loss_cls: 0.1067  decode.d1.loss_mask: 0.7049  decode.d1.loss_dice: 0.4750  decode.d2.loss_cls: 0.0761  decode.d2.loss_mask: 0.7052  decode.d2.loss_dice: 0.5010  decode.d3.loss_cls: 0.0658  decode.d3.loss_mask: 0.6998  decode.d3.loss_dice: 0.4793  decode.d4.loss_cls: 0.0880  decode.d4.loss_mask: 0.7087  decode.d4.loss_dice: 0.4770  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.7061  decode.d5.loss_dice: 0.4889  decode.d6.loss_cls: 0.0642  decode.d6.loss_mask: 0.6986  decode.d6.loss_dice: 0.4805  decode.d7.loss_cls: 0.0669  decode.d7.loss_mask: 0.7036  decode.d7.loss_dice: 0.4904  decode.d8.loss_cls: 0.0716  decode.d8.loss_mask: 0.7027  decode.d8.loss_dice: 0.4818
06/01 12:52:30 - mmengine - INFO - Iter(train) [152200/160000]  base_lr: 6.5945e-06 lr: 6.5945e-07  eta: 5:36:10  time: 0.6428  data_time: 0.0107  memory: 10492  grad_norm: 264.6839  loss: 13.5276  decode.loss_cls: 0.0627  decode.loss_mask: 0.7885  decode.loss_dice: 0.4656  decode.d0.loss_cls: 0.4583  decode.d0.loss_mask: 0.7951  decode.d0.loss_dice: 0.4707  decode.d1.loss_cls: 0.0287  decode.d1.loss_mask: 0.7945  decode.d1.loss_dice: 0.4715  decode.d2.loss_cls: 0.0472  decode.d2.loss_mask: 0.7906  decode.d2.loss_dice: 0.4704  decode.d3.loss_cls: 0.0336  decode.d3.loss_mask: 0.8010  decode.d3.loss_dice: 0.4789  decode.d4.loss_cls: 0.0426  decode.d4.loss_mask: 0.7878  decode.d4.loss_dice: 0.4664  decode.d5.loss_cls: 0.0770  decode.d5.loss_mask: 0.7897  decode.d5.loss_dice: 0.4742  decode.d6.loss_cls: 0.0399  decode.d6.loss_mask: 0.8016  decode.d6.loss_dice: 0.4674  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.7843  decode.d7.loss_dice: 0.4555  decode.d8.loss_cls: 0.0630  decode.d8.loss_mask: 0.7887  decode.d8.loss_dice: 0.4657
06/01 12:53:02 - mmengine - INFO - Iter(train) [152250/160000]  base_lr: 6.5564e-06 lr: 6.5564e-07  eta: 5:32:17  time: 0.6428  data_time: 0.0107  memory: 10507  grad_norm: 1714.5518  loss: 12.0465  decode.loss_cls: 0.0185  decode.loss_mask: 0.6923  decode.loss_dice: 0.4569  decode.d0.loss_cls: 0.3903  decode.d0.loss_mask: 0.6894  decode.d0.loss_dice: 0.4368  decode.d1.loss_cls: 0.0196  decode.d1.loss_mask: 0.6929  decode.d1.loss_dice: 0.4546  decode.d2.loss_cls: 0.0202  decode.d2.loss_mask: 0.6924  decode.d2.loss_dice: 0.4585  decode.d3.loss_cls: 0.0162  decode.d3.loss_mask: 0.6899  decode.d3.loss_dice: 0.4636  decode.d4.loss_cls: 0.0160  decode.d4.loss_mask: 0.6916  decode.d4.loss_dice: 0.4616  decode.d5.loss_cls: 0.0168  decode.d5.loss_mask: 0.6999  decode.d5.loss_dice: 0.4647  decode.d6.loss_cls: 0.0182  decode.d6.loss_mask: 0.6920  decode.d6.loss_dice: 0.4594  decode.d7.loss_cls: 0.0168  decode.d7.loss_mask: 0.6946  decode.d7.loss_dice: 0.4587  decode.d8.loss_cls: 0.0191  decode.d8.loss_mask: 0.6862  decode.d8.loss_dice: 0.4586
06/01 12:53:34 - mmengine - INFO - Iter(train) [152300/160000]  base_lr: 6.5183e-06 lr: 6.5183e-07  eta: 5:28:26  time: 0.6442  data_time: 0.0107  memory: 10501  grad_norm: 487.3826  loss: 16.4643  decode.loss_cls: 0.1191  decode.loss_mask: 0.8914  decode.loss_dice: 0.5918  decode.d0.loss_cls: 0.6169  decode.d0.loss_mask: 0.8790  decode.d0.loss_dice: 0.6039  decode.d1.loss_cls: 0.1341  decode.d1.loss_mask: 0.8786  decode.d1.loss_dice: 0.5909  decode.d2.loss_cls: 0.1188  decode.d2.loss_mask: 0.8864  decode.d2.loss_dice: 0.5976  decode.d3.loss_cls: 0.1100  decode.d3.loss_mask: 0.8704  decode.d3.loss_dice: 0.5978  decode.d4.loss_cls: 0.1388  decode.d4.loss_mask: 0.8879  decode.d4.loss_dice: 0.5804  decode.d5.loss_cls: 0.1268  decode.d5.loss_mask: 0.8864  decode.d5.loss_dice: 0.5873  decode.d6.loss_cls: 0.1079  decode.d6.loss_mask: 0.8814  decode.d6.loss_dice: 0.5943  decode.d7.loss_cls: 0.1324  decode.d7.loss_mask: 0.8725  decode.d7.loss_dice: 0.5897  decode.d8.loss_cls: 0.1321  decode.d8.loss_mask: 0.8738  decode.d8.loss_dice: 0.5858
06/01 12:54:07 - mmengine - INFO - Iter(train) [152350/160000]  base_lr: 6.4802e-06 lr: 6.4802e-07  eta: 5:24:39  time: 0.6432  data_time: 0.0107  memory: 10495  grad_norm: 436.4343  loss: 14.2054  decode.loss_cls: 0.0949  decode.loss_mask: 0.7170  decode.loss_dice: 0.5667  decode.d0.loss_cls: 0.6883  decode.d0.loss_mask: 0.6602  decode.d0.loss_dice: 0.5442  decode.d1.loss_cls: 0.1398  decode.d1.loss_mask: 0.6597  decode.d1.loss_dice: 0.5448  decode.d2.loss_cls: 0.0980  decode.d2.loss_mask: 0.7070  decode.d2.loss_dice: 0.5609  decode.d3.loss_cls: 0.0873  decode.d3.loss_mask: 0.7073  decode.d3.loss_dice: 0.5619  decode.d4.loss_cls: 0.1005  decode.d4.loss_mask: 0.7111  decode.d4.loss_dice: 0.5647  decode.d5.loss_cls: 0.0943  decode.d5.loss_mask: 0.7112  decode.d5.loss_dice: 0.5656  decode.d6.loss_cls: 0.1108  decode.d6.loss_mask: 0.7122  decode.d6.loss_dice: 0.5655  decode.d7.loss_cls: 0.0898  decode.d7.loss_mask: 0.7140  decode.d7.loss_dice: 0.5664  decode.d8.loss_cls: 0.1125  decode.d8.loss_mask: 0.7073  decode.d8.loss_dice: 0.5418
06/01 12:54:39 - mmengine - INFO - Iter(train) [152400/160000]  base_lr: 6.4421e-06 lr: 6.4421e-07  eta: 5:20:54  time: 0.6418  data_time: 0.0107  memory: 10504  grad_norm: 792.2224  loss: 19.0045  decode.loss_cls: 0.1305  decode.loss_mask: 0.9760  decode.loss_dice: 0.7173  decode.d0.loss_cls: 0.7027  decode.d0.loss_mask: 0.9382  decode.d0.loss_dice: 0.7139  decode.d1.loss_cls: 0.1886  decode.d1.loss_mask: 0.9734  decode.d1.loss_dice: 0.6940  decode.d2.loss_cls: 0.1441  decode.d2.loss_mask: 1.0168  decode.d2.loss_dice: 0.7182  decode.d3.loss_cls: 0.1126  decode.d3.loss_mask: 0.9985  decode.d3.loss_dice: 0.7235  decode.d4.loss_cls: 0.1235  decode.d4.loss_mask: 1.0061  decode.d4.loss_dice: 0.7160  decode.d5.loss_cls: 0.1385  decode.d5.loss_mask: 0.9942  decode.d5.loss_dice: 0.7022  decode.d6.loss_cls: 0.1601  decode.d6.loss_mask: 0.9580  decode.d6.loss_dice: 0.7042  decode.d7.loss_cls: 0.1425  decode.d7.loss_mask: 1.0163  decode.d7.loss_dice: 0.7195  decode.d8.loss_cls: 0.1444  decode.d8.loss_mask: 1.0090  decode.d8.loss_dice: 0.7217
06/01 12:55:11 - mmengine - INFO - Iter(train) [152450/160000]  base_lr: 6.4039e-06 lr: 6.4039e-07  eta: 5:17:11  time: 0.6425  data_time: 0.0107  memory: 10494  grad_norm: 305.8988  loss: 15.0160  decode.loss_cls: 0.1095  decode.loss_mask: 0.7607  decode.loss_dice: 0.5632  decode.d0.loss_cls: 0.5213  decode.d0.loss_mask: 0.8038  decode.d0.loss_dice: 0.5752  decode.d1.loss_cls: 0.1426  decode.d1.loss_mask: 0.7643  decode.d1.loss_dice: 0.5730  decode.d2.loss_cls: 0.1270  decode.d2.loss_mask: 0.7634  decode.d2.loss_dice: 0.5512  decode.d3.loss_cls: 0.1292  decode.d3.loss_mask: 0.7676  decode.d3.loss_dice: 0.5609  decode.d4.loss_cls: 0.1457  decode.d4.loss_mask: 0.7628  decode.d4.loss_dice: 0.5676  decode.d5.loss_cls: 0.1191  decode.d5.loss_mask: 0.7585  decode.d5.loss_dice: 0.5556  decode.d6.loss_cls: 0.1158  decode.d6.loss_mask: 0.7624  decode.d6.loss_dice: 0.5602  decode.d7.loss_cls: 0.1092  decode.d7.loss_mask: 0.8202  decode.d7.loss_dice: 0.5709  decode.d8.loss_cls: 0.1224  decode.d8.loss_mask: 0.7585  decode.d8.loss_dice: 0.5741
06/01 12:55:43 - mmengine - INFO - Iter(train) [152500/160000]  base_lr: 6.3658e-06 lr: 6.3658e-07  eta: 5:13:31  time: 0.6426  data_time: 0.0106  memory: 10501  grad_norm: 318.1392  loss: 13.0630  decode.loss_cls: 0.0769  decode.loss_mask: 0.7061  decode.loss_dice: 0.4938  decode.d0.loss_cls: 0.4064  decode.d0.loss_mask: 0.6998  decode.d0.loss_dice: 0.4920  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.7049  decode.d1.loss_dice: 0.5020  decode.d2.loss_cls: 0.0745  decode.d2.loss_mask: 0.7032  decode.d2.loss_dice: 0.4941  decode.d3.loss_cls: 0.0696  decode.d3.loss_mask: 0.7025  decode.d3.loss_dice: 0.4885  decode.d4.loss_cls: 0.0634  decode.d4.loss_mask: 0.7061  decode.d4.loss_dice: 0.5038  decode.d5.loss_cls: 0.0717  decode.d5.loss_mask: 0.7017  decode.d5.loss_dice: 0.5039  decode.d6.loss_cls: 0.0838  decode.d6.loss_mask: 0.7045  decode.d6.loss_dice: 0.4973  decode.d7.loss_cls: 0.0741  decode.d7.loss_mask: 0.7065  decode.d7.loss_dice: 0.5003  decode.d8.loss_cls: 0.0825  decode.d8.loss_mask: 0.7047  decode.d8.loss_dice: 0.5046
06/01 12:56:15 - mmengine - INFO - Iter(train) [152550/160000]  base_lr: 6.3275e-06 lr: 6.3275e-07  eta: 5:09:54  time: 0.6415  data_time: 0.0107  memory: 10500  grad_norm: 498.5904  loss: 16.3631  decode.loss_cls: 0.1482  decode.loss_mask: 0.8453  decode.loss_dice: 0.5895  decode.d0.loss_cls: 0.5591  decode.d0.loss_mask: 0.9149  decode.d0.loss_dice: 0.6045  decode.d1.loss_cls: 0.1601  decode.d1.loss_mask: 0.8576  decode.d1.loss_dice: 0.5989  decode.d2.loss_cls: 0.1424  decode.d2.loss_mask: 0.8289  decode.d2.loss_dice: 0.5911  decode.d3.loss_cls: 0.1301  decode.d3.loss_mask: 0.8399  decode.d3.loss_dice: 0.5927  decode.d4.loss_cls: 0.1143  decode.d4.loss_mask: 0.8436  decode.d4.loss_dice: 0.5904  decode.d5.loss_cls: 0.1479  decode.d5.loss_mask: 0.8486  decode.d5.loss_dice: 0.5915  decode.d6.loss_cls: 0.1410  decode.d6.loss_mask: 0.8724  decode.d6.loss_dice: 0.6013  decode.d7.loss_cls: 0.1292  decode.d7.loss_mask: 0.8667  decode.d7.loss_dice: 0.6093  decode.d8.loss_cls: 0.1412  decode.d8.loss_mask: 0.8625  decode.d8.loss_dice: 0.6000
06/01 12:56:47 - mmengine - INFO - Iter(train) [152600/160000]  base_lr: 6.2893e-06 lr: 6.2893e-07  eta: 5:06:19  time: 0.6415  data_time: 0.0107  memory: 10496  grad_norm: 421.8692  loss: 15.3126  decode.loss_cls: 0.1713  decode.loss_mask: 0.8050  decode.loss_dice: 0.5336  decode.d0.loss_cls: 0.5719  decode.d0.loss_mask: 0.7462  decode.d0.loss_dice: 0.5227  decode.d1.loss_cls: 0.1917  decode.d1.loss_mask: 0.7523  decode.d1.loss_dice: 0.5176  decode.d2.loss_cls: 0.2069  decode.d2.loss_mask: 0.7800  decode.d2.loss_dice: 0.5119  decode.d3.loss_cls: 0.1979  decode.d3.loss_mask: 0.7883  decode.d3.loss_dice: 0.5187  decode.d4.loss_cls: 0.2078  decode.d4.loss_mask: 0.7829  decode.d4.loss_dice: 0.5280  decode.d5.loss_cls: 0.1807  decode.d5.loss_mask: 0.7842  decode.d5.loss_dice: 0.5050  decode.d6.loss_cls: 0.1986  decode.d6.loss_mask: 0.8016  decode.d6.loss_dice: 0.5186  decode.d7.loss_cls: 0.1933  decode.d7.loss_mask: 0.7918  decode.d7.loss_dice: 0.5091  decode.d8.loss_cls: 0.1709  decode.d8.loss_mask: 0.7963  decode.d8.loss_dice: 0.5275
06/01 12:57:19 - mmengine - INFO - Iter(train) [152650/160000]  base_lr: 6.2511e-06 lr: 6.2511e-07  eta: 5:02:46  time: 0.6414  data_time: 0.0106  memory: 10492  grad_norm: 342.5560  loss: 15.5116  decode.loss_cls: 0.0525  decode.loss_mask: 0.8787  decode.loss_dice: 0.5590  decode.d0.loss_cls: 0.6002  decode.d0.loss_mask: 0.8722  decode.d0.loss_dice: 0.5562  decode.d1.loss_cls: 0.0638  decode.d1.loss_mask: 0.8862  decode.d1.loss_dice: 0.5606  decode.d2.loss_cls: 0.0651  decode.d2.loss_mask: 0.8910  decode.d2.loss_dice: 0.5653  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.8845  decode.d3.loss_dice: 0.5570  decode.d4.loss_cls: 0.0581  decode.d4.loss_mask: 0.8766  decode.d4.loss_dice: 0.5603  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.8737  decode.d5.loss_dice: 0.5544  decode.d6.loss_cls: 0.0634  decode.d6.loss_mask: 0.8786  decode.d6.loss_dice: 0.5609  decode.d7.loss_cls: 0.0390  decode.d7.loss_mask: 0.8810  decode.d7.loss_dice: 0.5676  decode.d8.loss_cls: 0.0540  decode.d8.loss_mask: 0.8750  decode.d8.loss_dice: 0.5598
06/01 12:57:51 - mmengine - INFO - Iter(train) [152700/160000]  base_lr: 6.2128e-06 lr: 6.2128e-07  eta: 4:59:16  time: 0.6416  data_time: 0.0107  memory: 10503  grad_norm: 555.1064  loss: 14.8575  decode.loss_cls: 0.0663  decode.loss_mask: 0.8311  decode.loss_dice: 0.5386  decode.d0.loss_cls: 0.4664  decode.d0.loss_mask: 0.8382  decode.d0.loss_dice: 0.5481  decode.d1.loss_cls: 0.0693  decode.d1.loss_mask: 0.8497  decode.d1.loss_dice: 0.5590  decode.d2.loss_cls: 0.0478  decode.d2.loss_mask: 0.8379  decode.d2.loss_dice: 0.5494  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 0.8314  decode.d3.loss_dice: 0.5380  decode.d4.loss_cls: 0.0692  decode.d4.loss_mask: 0.8364  decode.d4.loss_dice: 0.5383  decode.d5.loss_cls: 0.0619  decode.d5.loss_mask: 0.8332  decode.d5.loss_dice: 0.5485  decode.d6.loss_cls: 0.0726  decode.d6.loss_mask: 0.8289  decode.d6.loss_dice: 0.5407  decode.d7.loss_cls: 0.0652  decode.d7.loss_mask: 0.8406  decode.d7.loss_dice: 0.5422  decode.d8.loss_cls: 0.0662  decode.d8.loss_mask: 0.8357  decode.d8.loss_dice: 0.5396
06/01 12:58:24 - mmengine - INFO - Iter(train) [152750/160000]  base_lr: 6.1745e-06 lr: 6.1745e-07  eta: 4:55:48  time: 0.6421  data_time: 0.0107  memory: 10512  grad_norm: 256.6206  loss: 14.8336  decode.loss_cls: 0.1054  decode.loss_mask: 0.7933  decode.loss_dice: 0.5541  decode.d0.loss_cls: 0.5421  decode.d0.loss_mask: 0.7947  decode.d0.loss_dice: 0.5576  decode.d1.loss_cls: 0.0843  decode.d1.loss_mask: 0.8012  decode.d1.loss_dice: 0.5668  decode.d2.loss_cls: 0.0910  decode.d2.loss_mask: 0.7958  decode.d2.loss_dice: 0.5634  decode.d3.loss_cls: 0.0655  decode.d3.loss_mask: 0.7881  decode.d3.loss_dice: 0.5598  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.8050  decode.d4.loss_dice: 0.5640  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 0.8000  decode.d5.loss_dice: 0.5587  decode.d6.loss_cls: 0.0682  decode.d6.loss_mask: 0.8007  decode.d6.loss_dice: 0.5623  decode.d7.loss_cls: 0.0849  decode.d7.loss_mask: 0.7983  decode.d7.loss_dice: 0.5588  decode.d8.loss_cls: 0.0723  decode.d8.loss_mask: 0.7992  decode.d8.loss_dice: 0.5604
06/01 12:58:56 - mmengine - INFO - Iter(train) [152800/160000]  base_lr: 6.1361e-06 lr: 6.1361e-07  eta: 4:52:22  time: 0.6420  data_time: 0.0106  memory: 10491  grad_norm: 302.9920  loss: 15.8543  decode.loss_cls: 0.1039  decode.loss_mask: 0.8486  decode.loss_dice: 0.5917  decode.d0.loss_cls: 0.5560  decode.d0.loss_mask: 0.8338  decode.d0.loss_dice: 0.5937  decode.d1.loss_cls: 0.1130  decode.d1.loss_mask: 0.8396  decode.d1.loss_dice: 0.6017  decode.d2.loss_cls: 0.0992  decode.d2.loss_mask: 0.8510  decode.d2.loss_dice: 0.5935  decode.d3.loss_cls: 0.0947  decode.d3.loss_mask: 0.8261  decode.d3.loss_dice: 0.5903  decode.d4.loss_cls: 0.1085  decode.d4.loss_mask: 0.8665  decode.d4.loss_dice: 0.6021  decode.d5.loss_cls: 0.1041  decode.d5.loss_mask: 0.8646  decode.d5.loss_dice: 0.5867  decode.d6.loss_cls: 0.0756  decode.d6.loss_mask: 0.8364  decode.d6.loss_dice: 0.5935  decode.d7.loss_cls: 0.1049  decode.d7.loss_mask: 0.8416  decode.d7.loss_dice: 0.5969  decode.d8.loss_cls: 0.0953  decode.d8.loss_mask: 0.8395  decode.d8.loss_dice: 0.6009
06/01 12:59:28 - mmengine - INFO - Iter(train) [152850/160000]  base_lr: 6.0978e-06 lr: 6.0978e-07  eta: 4:48:59  time: 0.6419  data_time: 0.0107  memory: 10494  grad_norm: 309.2538  loss: 13.0437  decode.loss_cls: 0.0979  decode.loss_mask: 0.6661  decode.loss_dice: 0.4751  decode.d0.loss_cls: 0.5942  decode.d0.loss_mask: 0.6552  decode.d0.loss_dice: 0.4635  decode.d1.loss_cls: 0.1045  decode.d1.loss_mask: 0.6892  decode.d1.loss_dice: 0.4787  decode.d2.loss_cls: 0.0916  decode.d2.loss_mask: 0.6799  decode.d2.loss_dice: 0.4732  decode.d3.loss_cls: 0.1256  decode.d3.loss_mask: 0.6813  decode.d3.loss_dice: 0.4893  decode.d4.loss_cls: 0.1117  decode.d4.loss_mask: 0.6821  decode.d4.loss_dice: 0.4710  decode.d5.loss_cls: 0.0935  decode.d5.loss_mask: 0.6702  decode.d5.loss_dice: 0.4824  decode.d6.loss_cls: 0.0878  decode.d6.loss_mask: 0.6764  decode.d6.loss_dice: 0.4847  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.6891  decode.d7.loss_dice: 0.4817  decode.d8.loss_cls: 0.1092  decode.d8.loss_mask: 0.6776  decode.d8.loss_dice: 0.4704
06/01 13:00:00 - mmengine - INFO - Iter(train) [152900/160000]  base_lr: 6.0594e-06 lr: 6.0594e-07  eta: 4:45:37  time: 0.6416  data_time: 0.0107  memory: 10492  grad_norm: 742.1308  loss: 14.0443  decode.loss_cls: 0.0195  decode.loss_mask: 0.8533  decode.loss_dice: 0.5069  decode.d0.loss_cls: 0.3656  decode.d0.loss_mask: 0.8746  decode.d0.loss_dice: 0.5006  decode.d1.loss_cls: 0.0234  decode.d1.loss_mask: 0.8424  decode.d1.loss_dice: 0.4956  decode.d2.loss_cls: 0.0153  decode.d2.loss_mask: 0.8489  decode.d2.loss_dice: 0.5084  decode.d3.loss_cls: 0.0157  decode.d3.loss_mask: 0.8482  decode.d3.loss_dice: 0.4974  decode.d4.loss_cls: 0.0187  decode.d4.loss_mask: 0.8494  decode.d4.loss_dice: 0.5001  decode.d5.loss_cls: 0.0186  decode.d5.loss_mask: 0.8536  decode.d5.loss_dice: 0.5029  decode.d6.loss_cls: 0.0182  decode.d6.loss_mask: 0.8487  decode.d6.loss_dice: 0.4978  decode.d7.loss_cls: 0.0180  decode.d7.loss_mask: 0.8463  decode.d7.loss_dice: 0.4995  decode.d8.loss_cls: 0.0169  decode.d8.loss_mask: 0.8418  decode.d8.loss_dice: 0.4978
06/01 13:00:32 - mmengine - INFO - Iter(train) [152950/160000]  base_lr: 6.0209e-06 lr: 6.0209e-07  eta: 4:42:18  time: 0.6417  data_time: 0.0106  memory: 10492  grad_norm: 367.5511  loss: 16.0515  decode.loss_cls: 0.0262  decode.loss_mask: 0.9134  decode.loss_dice: 0.6190  decode.d0.loss_cls: 0.5996  decode.d0.loss_mask: 0.8707  decode.d0.loss_dice: 0.5602  decode.d1.loss_cls: 0.0380  decode.d1.loss_mask: 0.9226  decode.d1.loss_dice: 0.6181  decode.d2.loss_cls: 0.0231  decode.d2.loss_mask: 0.9215  decode.d2.loss_dice: 0.6209  decode.d3.loss_cls: 0.0324  decode.d3.loss_mask: 0.9015  decode.d3.loss_dice: 0.6080  decode.d4.loss_cls: 0.0264  decode.d4.loss_mask: 0.9136  decode.d4.loss_dice: 0.6201  decode.d5.loss_cls: 0.0241  decode.d5.loss_mask: 0.9129  decode.d5.loss_dice: 0.6179  decode.d6.loss_cls: 0.0257  decode.d6.loss_mask: 0.9164  decode.d6.loss_dice: 0.6210  decode.d7.loss_cls: 0.0212  decode.d7.loss_mask: 0.9240  decode.d7.loss_dice: 0.6260  decode.d8.loss_cls: 0.0296  decode.d8.loss_mask: 0.8973  decode.d8.loss_dice: 0.5997
06/01 13:01:04 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 13:01:04 - mmengine - INFO - Iter(train) [153000/160000]  base_lr: 5.9825e-06 lr: 5.9825e-07  eta: 4:39:01  time: 0.6438  data_time: 0.0107  memory: 10505  grad_norm: 315.4925  loss: 15.1607  decode.loss_cls: 0.0473  decode.loss_mask: 0.8483  decode.loss_dice: 0.6012  decode.d0.loss_cls: 0.3823  decode.d0.loss_mask: 0.8538  decode.d0.loss_dice: 0.6021  decode.d1.loss_cls: 0.0339  decode.d1.loss_mask: 0.8443  decode.d1.loss_dice: 0.5901  decode.d2.loss_cls: 0.0428  decode.d2.loss_mask: 0.8396  decode.d2.loss_dice: 0.5897  decode.d3.loss_cls: 0.0439  decode.d3.loss_mask: 0.8426  decode.d3.loss_dice: 0.5940  decode.d4.loss_cls: 0.0435  decode.d4.loss_mask: 0.8464  decode.d4.loss_dice: 0.5960  decode.d5.loss_cls: 0.0427  decode.d5.loss_mask: 0.8410  decode.d5.loss_dice: 0.5930  decode.d6.loss_cls: 0.0408  decode.d6.loss_mask: 0.8471  decode.d6.loss_dice: 0.5886  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.8430  decode.d7.loss_dice: 0.5999  decode.d8.loss_cls: 0.0430  decode.d8.loss_mask: 0.8440  decode.d8.loss_dice: 0.5975
06/01 13:01:36 - mmengine - INFO - Iter(train) [153050/160000]  base_lr: 5.9440e-06 lr: 5.9440e-07  eta: 4:35:46  time: 0.6411  data_time: 0.0106  memory: 10492  grad_norm: 355.4987  loss: 13.1680  decode.loss_cls: 0.0513  decode.loss_mask: 0.6600  decode.loss_dice: 0.5732  decode.d0.loss_cls: 0.5543  decode.d0.loss_mask: 0.6579  decode.d0.loss_dice: 0.5567  decode.d1.loss_cls: 0.0783  decode.d1.loss_mask: 0.6525  decode.d1.loss_dice: 0.5341  decode.d2.loss_cls: 0.0510  decode.d2.loss_mask: 0.6526  decode.d2.loss_dice: 0.5565  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.6525  decode.d3.loss_dice: 0.5543  decode.d4.loss_cls: 0.0459  decode.d4.loss_mask: 0.6529  decode.d4.loss_dice: 0.5593  decode.d5.loss_cls: 0.0511  decode.d5.loss_mask: 0.6551  decode.d5.loss_dice: 0.5595  decode.d6.loss_cls: 0.0580  decode.d6.loss_mask: 0.6564  decode.d6.loss_dice: 0.5577  decode.d7.loss_cls: 0.0547  decode.d7.loss_mask: 0.6554  decode.d7.loss_dice: 0.5572  decode.d8.loss_cls: 0.0624  decode.d8.loss_mask: 0.6568  decode.d8.loss_dice: 0.5481
06/01 13:02:09 - mmengine - INFO - Iter(train) [153100/160000]  base_lr: 5.9055e-06 lr: 5.9055e-07  eta: 4:32:33  time: 0.6411  data_time: 0.0106  memory: 10499  grad_norm: 2376.3014  loss: 16.7943  decode.loss_cls: 0.1564  decode.loss_mask: 0.8783  decode.loss_dice: 0.6308  decode.d0.loss_cls: 0.5888  decode.d0.loss_mask: 0.8126  decode.d0.loss_dice: 0.6270  decode.d1.loss_cls: 0.1221  decode.d1.loss_mask: 0.8925  decode.d1.loss_dice: 0.6292  decode.d2.loss_cls: 0.1154  decode.d2.loss_mask: 0.8746  decode.d2.loss_dice: 0.6316  decode.d3.loss_cls: 0.1334  decode.d3.loss_mask: 0.8749  decode.d3.loss_dice: 0.6361  decode.d4.loss_cls: 0.1452  decode.d4.loss_mask: 0.8542  decode.d4.loss_dice: 0.6279  decode.d5.loss_cls: 0.1249  decode.d5.loss_mask: 0.8904  decode.d5.loss_dice: 0.6325  decode.d6.loss_cls: 0.1433  decode.d6.loss_mask: 0.8824  decode.d6.loss_dice: 0.6333  decode.d7.loss_cls: 0.1309  decode.d7.loss_mask: 0.8670  decode.d7.loss_dice: 0.6146  decode.d8.loss_cls: 0.1546  decode.d8.loss_mask: 0.8645  decode.d8.loss_dice: 0.6249
06/01 13:02:41 - mmengine - INFO - Iter(train) [153150/160000]  base_lr: 5.8670e-06 lr: 5.8670e-07  eta: 4:29:21  time: 0.6426  data_time: 0.0109  memory: 10495  grad_norm: 384.2657  loss: 14.6289  decode.loss_cls: 0.1543  decode.loss_mask: 0.7312  decode.loss_dice: 0.5640  decode.d0.loss_cls: 0.5420  decode.d0.loss_mask: 0.7163  decode.d0.loss_dice: 0.5505  decode.d1.loss_cls: 0.1482  decode.d1.loss_mask: 0.7249  decode.d1.loss_dice: 0.5245  decode.d2.loss_cls: 0.1887  decode.d2.loss_mask: 0.7299  decode.d2.loss_dice: 0.5151  decode.d3.loss_cls: 0.1419  decode.d3.loss_mask: 0.7331  decode.d3.loss_dice: 0.5203  decode.d4.loss_cls: 0.1521  decode.d4.loss_mask: 0.7230  decode.d4.loss_dice: 0.5503  decode.d5.loss_cls: 0.1512  decode.d5.loss_mask: 0.7234  decode.d5.loss_dice: 0.5548  decode.d6.loss_cls: 0.1480  decode.d6.loss_mask: 0.7253  decode.d6.loss_dice: 0.5315  decode.d7.loss_cls: 0.1565  decode.d7.loss_mask: 0.7345  decode.d7.loss_dice: 0.5519  decode.d8.loss_cls: 0.1502  decode.d8.loss_mask: 0.7304  decode.d8.loss_dice: 0.5608
06/01 13:03:13 - mmengine - INFO - Iter(train) [153200/160000]  base_lr: 5.8284e-06 lr: 5.8284e-07  eta: 4:26:12  time: 0.6420  data_time: 0.0107  memory: 10499  grad_norm: 884.5680  loss: 15.6146  decode.loss_cls: 0.1137  decode.loss_mask: 0.8767  decode.loss_dice: 0.5377  decode.d0.loss_cls: 0.5515  decode.d0.loss_mask: 0.8448  decode.d0.loss_dice: 0.5583  decode.d1.loss_cls: 0.1017  decode.d1.loss_mask: 0.8648  decode.d1.loss_dice: 0.5404  decode.d2.loss_cls: 0.0961  decode.d2.loss_mask: 0.8569  decode.d2.loss_dice: 0.5396  decode.d3.loss_cls: 0.1399  decode.d3.loss_mask: 0.8745  decode.d3.loss_dice: 0.5467  decode.d4.loss_cls: 0.1480  decode.d4.loss_mask: 0.8404  decode.d4.loss_dice: 0.5270  decode.d5.loss_cls: 0.0897  decode.d5.loss_mask: 0.8674  decode.d5.loss_dice: 0.5498  decode.d6.loss_cls: 0.1283  decode.d6.loss_mask: 0.8614  decode.d6.loss_dice: 0.5361  decode.d7.loss_cls: 0.1159  decode.d7.loss_mask: 0.8621  decode.d7.loss_dice: 0.5393  decode.d8.loss_cls: 0.1148  decode.d8.loss_mask: 0.8527  decode.d8.loss_dice: 0.5381
06/01 13:03:45 - mmengine - INFO - Iter(train) [153250/160000]  base_lr: 5.7899e-06 lr: 5.7899e-07  eta: 4:23:05  time: 0.6415  data_time: 0.0106  memory: 10500  grad_norm: 358.4505  loss: 15.3551  decode.loss_cls: 0.0441  decode.loss_mask: 0.8215  decode.loss_dice: 0.6199  decode.d0.loss_cls: 0.5082  decode.d0.loss_mask: 0.7921  decode.d0.loss_dice: 0.5917  decode.d1.loss_cls: 0.0529  decode.d1.loss_mask: 0.8300  decode.d1.loss_dice: 0.6271  decode.d2.loss_cls: 0.0425  decode.d2.loss_mask: 0.8224  decode.d2.loss_dice: 0.6305  decode.d3.loss_cls: 0.0526  decode.d3.loss_mask: 0.8219  decode.d3.loss_dice: 0.6244  decode.d4.loss_cls: 0.0455  decode.d4.loss_mask: 0.8215  decode.d4.loss_dice: 0.6245  decode.d5.loss_cls: 0.0464  decode.d5.loss_mask: 0.8218  decode.d5.loss_dice: 0.6209  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.8252  decode.d6.loss_dice: 0.6208  decode.d7.loss_cls: 0.0441  decode.d7.loss_mask: 0.8311  decode.d7.loss_dice: 0.6329  decode.d8.loss_cls: 0.0432  decode.d8.loss_mask: 0.8235  decode.d8.loss_dice: 0.6235
06/01 13:04:17 - mmengine - INFO - Iter(train) [153300/160000]  base_lr: 5.7512e-06 lr: 5.7512e-07  eta: 4:20:00  time: 0.6423  data_time: 0.0108  memory: 10496  grad_norm: 202.3539  loss: 14.2627  decode.loss_cls: 0.1207  decode.loss_mask: 0.7635  decode.loss_dice: 0.5201  decode.d0.loss_cls: 0.4556  decode.d0.loss_mask: 0.7722  decode.d0.loss_dice: 0.5056  decode.d1.loss_cls: 0.0935  decode.d1.loss_mask: 0.7630  decode.d1.loss_dice: 0.5111  decode.d2.loss_cls: 0.1011  decode.d2.loss_mask: 0.7704  decode.d2.loss_dice: 0.5154  decode.d3.loss_cls: 0.1004  decode.d3.loss_mask: 0.7734  decode.d3.loss_dice: 0.5216  decode.d4.loss_cls: 0.1086  decode.d4.loss_mask: 0.7668  decode.d4.loss_dice: 0.5120  decode.d5.loss_cls: 0.1107  decode.d5.loss_mask: 0.7683  decode.d5.loss_dice: 0.5145  decode.d6.loss_cls: 0.1183  decode.d6.loss_mask: 0.7697  decode.d6.loss_dice: 0.5219  decode.d7.loss_cls: 0.1174  decode.d7.loss_mask: 0.7589  decode.d7.loss_dice: 0.5086  decode.d8.loss_cls: 0.1224  decode.d8.loss_mask: 0.7634  decode.d8.loss_dice: 0.5137
06/01 13:04:49 - mmengine - INFO - Iter(train) [153350/160000]  base_lr: 5.7126e-06 lr: 5.7126e-07  eta: 4:16:56  time: 0.6420  data_time: 0.0107  memory: 10509  grad_norm: 345.3772  loss: 13.6522  decode.loss_cls: 0.0428  decode.loss_mask: 0.8062  decode.loss_dice: 0.4878  decode.d0.loss_cls: 0.4540  decode.d0.loss_mask: 0.7711  decode.d0.loss_dice: 0.4661  decode.d1.loss_cls: 0.0747  decode.d1.loss_mask: 0.7512  decode.d1.loss_dice: 0.4809  decode.d2.loss_cls: 0.0615  decode.d2.loss_mask: 0.7954  decode.d2.loss_dice: 0.4725  decode.d3.loss_cls: 0.0703  decode.d3.loss_mask: 0.7974  decode.d3.loss_dice: 0.4713  decode.d4.loss_cls: 0.0510  decode.d4.loss_mask: 0.7889  decode.d4.loss_dice: 0.4687  decode.d5.loss_cls: 0.0511  decode.d5.loss_mask: 0.7953  decode.d5.loss_dice: 0.4749  decode.d6.loss_cls: 0.0511  decode.d6.loss_mask: 0.8022  decode.d6.loss_dice: 0.4811  decode.d7.loss_cls: 0.0658  decode.d7.loss_mask: 0.7960  decode.d7.loss_dice: 0.4786  decode.d8.loss_cls: 0.0602  decode.d8.loss_mask: 0.7997  decode.d8.loss_dice: 0.4846
06/01 13:05:21 - mmengine - INFO - Iter(train) [153400/160000]  base_lr: 5.6739e-06 lr: 5.6739e-07  eta: 4:13:54  time: 0.6408  data_time: 0.0107  memory: 10500  grad_norm: 500.8147  loss: 15.4799  decode.loss_cls: 0.0925  decode.loss_mask: 0.8350  decode.loss_dice: 0.5799  decode.d0.loss_cls: 0.5693  decode.d0.loss_mask: 0.8505  decode.d0.loss_dice: 0.5270  decode.d1.loss_cls: 0.1042  decode.d1.loss_mask: 0.8553  decode.d1.loss_dice: 0.5383  decode.d2.loss_cls: 0.0829  decode.d2.loss_mask: 0.8476  decode.d2.loss_dice: 0.5480  decode.d3.loss_cls: 0.1033  decode.d3.loss_mask: 0.8471  decode.d3.loss_dice: 0.5511  decode.d4.loss_cls: 0.0978  decode.d4.loss_mask: 0.8550  decode.d4.loss_dice: 0.5544  decode.d5.loss_cls: 0.1008  decode.d5.loss_mask: 0.8569  decode.d5.loss_dice: 0.5517  decode.d6.loss_cls: 0.0898  decode.d6.loss_mask: 0.8730  decode.d6.loss_dice: 0.5546  decode.d7.loss_cls: 0.1010  decode.d7.loss_mask: 0.8639  decode.d7.loss_dice: 0.5275  decode.d8.loss_cls: 0.0973  decode.d8.loss_mask: 0.8678  decode.d8.loss_dice: 0.5563
06/01 13:05:54 - mmengine - INFO - Iter(train) [153450/160000]  base_lr: 5.6352e-06 lr: 5.6352e-07  eta: 4:10:54  time: 0.6422  data_time: 0.0107  memory: 10500  grad_norm: 345.6047  loss: 12.6450  decode.loss_cls: 0.0522  decode.loss_mask: 0.6837  decode.loss_dice: 0.4990  decode.d0.loss_cls: 0.4230  decode.d0.loss_mask: 0.6782  decode.d0.loss_dice: 0.4914  decode.d1.loss_cls: 0.0475  decode.d1.loss_mask: 0.6839  decode.d1.loss_dice: 0.4938  decode.d2.loss_cls: 0.0474  decode.d2.loss_mask: 0.6838  decode.d2.loss_dice: 0.4924  decode.d3.loss_cls: 0.0470  decode.d3.loss_mask: 0.6809  decode.d3.loss_dice: 0.4933  decode.d4.loss_cls: 0.0558  decode.d4.loss_mask: 0.6827  decode.d4.loss_dice: 0.4806  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.6852  decode.d5.loss_dice: 0.5000  decode.d6.loss_cls: 0.0480  decode.d6.loss_mask: 0.6833  decode.d6.loss_dice: 0.4881  decode.d7.loss_cls: 0.0500  decode.d7.loss_mask: 0.6826  decode.d7.loss_dice: 0.4936  decode.d8.loss_cls: 0.0554  decode.d8.loss_mask: 0.6842  decode.d8.loss_dice: 0.5003
06/01 13:06:26 - mmengine - INFO - Iter(train) [153500/160000]  base_lr: 5.5965e-06 lr: 5.5965e-07  eta: 4:07:56  time: 0.6418  data_time: 0.0106  memory: 10492  grad_norm: 427.3929  loss: 17.1235  decode.loss_cls: 0.0584  decode.loss_mask: 1.0071  decode.loss_dice: 0.6281  decode.d0.loss_cls: 0.6049  decode.d0.loss_mask: 0.9162  decode.d0.loss_dice: 0.6056  decode.d1.loss_cls: 0.1022  decode.d1.loss_mask: 0.9497  decode.d1.loss_dice: 0.6171  decode.d2.loss_cls: 0.0848  decode.d2.loss_mask: 0.9513  decode.d2.loss_dice: 0.6161  decode.d3.loss_cls: 0.0842  decode.d3.loss_mask: 0.9466  decode.d3.loss_dice: 0.6197  decode.d4.loss_cls: 0.0820  decode.d4.loss_mask: 0.9536  decode.d4.loss_dice: 0.6215  decode.d5.loss_cls: 0.0724  decode.d5.loss_mask: 0.9493  decode.d5.loss_dice: 0.6202  decode.d6.loss_cls: 0.0793  decode.d6.loss_mask: 0.9439  decode.d6.loss_dice: 0.6255  decode.d7.loss_cls: 0.0486  decode.d7.loss_mask: 1.0209  decode.d7.loss_dice: 0.6279  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 1.0041  decode.d8.loss_dice: 0.6158
06/01 13:06:58 - mmengine - INFO - Iter(train) [153550/160000]  base_lr: 5.5577e-06 lr: 5.5577e-07  eta: 4:04:59  time: 0.6408  data_time: 0.0106  memory: 10495  grad_norm: 279.9256  loss: 13.8471  decode.loss_cls: 0.0825  decode.loss_mask: 0.7435  decode.loss_dice: 0.5192  decode.d0.loss_cls: 0.4598  decode.d0.loss_mask: 0.7870  decode.d0.loss_dice: 0.5285  decode.d1.loss_cls: 0.0941  decode.d1.loss_mask: 0.7481  decode.d1.loss_dice: 0.5204  decode.d2.loss_cls: 0.0637  decode.d2.loss_mask: 0.7465  decode.d2.loss_dice: 0.5164  decode.d3.loss_cls: 0.0783  decode.d3.loss_mask: 0.7478  decode.d3.loss_dice: 0.5180  decode.d4.loss_cls: 0.0640  decode.d4.loss_mask: 0.7487  decode.d4.loss_dice: 0.5141  decode.d5.loss_cls: 0.0589  decode.d5.loss_mask: 0.7498  decode.d5.loss_dice: 0.5210  decode.d6.loss_cls: 0.0579  decode.d6.loss_mask: 0.7483  decode.d6.loss_dice: 0.5166  decode.d7.loss_cls: 0.1030  decode.d7.loss_mask: 0.7461  decode.d7.loss_dice: 0.5197  decode.d8.loss_cls: 0.0894  decode.d8.loss_mask: 0.7427  decode.d8.loss_dice: 0.5131
06/01 13:07:30 - mmengine - INFO - Iter(train) [153600/160000]  base_lr: 5.5189e-06 lr: 5.5189e-07  eta: 4:02:05  time: 0.6419  data_time: 0.0107  memory: 10500  grad_norm: 510.9873  loss: 14.6081  decode.loss_cls: 0.1031  decode.loss_mask: 0.7448  decode.loss_dice: 0.5410  decode.d0.loss_cls: 0.6216  decode.d0.loss_mask: 0.7043  decode.d0.loss_dice: 0.5638  decode.d1.loss_cls: 0.1712  decode.d1.loss_mask: 0.7255  decode.d1.loss_dice: 0.5437  decode.d2.loss_cls: 0.1377  decode.d2.loss_mask: 0.7155  decode.d2.loss_dice: 0.5543  decode.d3.loss_cls: 0.1486  decode.d3.loss_mask: 0.7260  decode.d3.loss_dice: 0.5458  decode.d4.loss_cls: 0.1210  decode.d4.loss_mask: 0.7458  decode.d4.loss_dice: 0.5451  decode.d5.loss_cls: 0.1477  decode.d5.loss_mask: 0.7253  decode.d5.loss_dice: 0.5333  decode.d6.loss_cls: 0.1076  decode.d6.loss_mask: 0.7630  decode.d6.loss_dice: 0.5602  decode.d7.loss_cls: 0.1249  decode.d7.loss_mask: 0.7387  decode.d7.loss_dice: 0.5498  decode.d8.loss_cls: 0.1038  decode.d8.loss_mask: 0.7444  decode.d8.loss_dice: 0.5505
06/01 13:08:02 - mmengine - INFO - Iter(train) [153650/160000]  base_lr: 5.4801e-06 lr: 5.4801e-07  eta: 3:59:11  time: 0.6412  data_time: 0.0107  memory: 10504  grad_norm: 218.0969  loss: 13.6967  decode.loss_cls: 0.0993  decode.loss_mask: 0.7342  decode.loss_dice: 0.5034  decode.d0.loss_cls: 0.5149  decode.d0.loss_mask: 0.7452  decode.d0.loss_dice: 0.5326  decode.d1.loss_cls: 0.1007  decode.d1.loss_mask: 0.7418  decode.d1.loss_dice: 0.4970  decode.d2.loss_cls: 0.1061  decode.d2.loss_mask: 0.7240  decode.d2.loss_dice: 0.4949  decode.d3.loss_cls: 0.1037  decode.d3.loss_mask: 0.7252  decode.d3.loss_dice: 0.4967  decode.d4.loss_cls: 0.1056  decode.d4.loss_mask: 0.7259  decode.d4.loss_dice: 0.4973  decode.d5.loss_cls: 0.0989  decode.d5.loss_mask: 0.7253  decode.d5.loss_dice: 0.4965  decode.d6.loss_cls: 0.0970  decode.d6.loss_mask: 0.7247  decode.d6.loss_dice: 0.4918  decode.d7.loss_cls: 0.0850  decode.d7.loss_mask: 0.7364  decode.d7.loss_dice: 0.4909  decode.d8.loss_cls: 0.0907  decode.d8.loss_mask: 0.7211  decode.d8.loss_dice: 0.4901
06/01 13:08:34 - mmengine - INFO - Iter(train) [153700/160000]  base_lr: 5.4413e-06 lr: 5.4413e-07  eta: 3:56:20  time: 0.6429  data_time: 0.0107  memory: 10504  grad_norm: 431.8411  loss: 15.4389  decode.loss_cls: 0.1473  decode.loss_mask: 0.7892  decode.loss_dice: 0.5657  decode.d0.loss_cls: 0.5482  decode.d0.loss_mask: 0.7910  decode.d0.loss_dice: 0.5699  decode.d1.loss_cls: 0.1636  decode.d1.loss_mask: 0.7902  decode.d1.loss_dice: 0.5687  decode.d2.loss_cls: 0.1775  decode.d2.loss_mask: 0.7847  decode.d2.loss_dice: 0.5604  decode.d3.loss_cls: 0.1268  decode.d3.loss_mask: 0.7909  decode.d3.loss_dice: 0.5667  decode.d4.loss_cls: 0.1284  decode.d4.loss_mask: 0.7884  decode.d4.loss_dice: 0.5738  decode.d5.loss_cls: 0.1291  decode.d5.loss_mask: 0.7849  decode.d5.loss_dice: 0.5650  decode.d6.loss_cls: 0.1230  decode.d6.loss_mask: 0.7958  decode.d6.loss_dice: 0.5662  decode.d7.loss_cls: 0.1384  decode.d7.loss_mask: 0.8001  decode.d7.loss_dice: 0.5778  decode.d8.loss_cls: 0.1523  decode.d8.loss_mask: 0.7968  decode.d8.loss_dice: 0.5779
06/01 13:09:06 - mmengine - INFO - Iter(train) [153750/160000]  base_lr: 5.4024e-06 lr: 5.4024e-07  eta: 3:53:30  time: 0.6422  data_time: 0.0107  memory: 10492  grad_norm: 391.5615  loss: 16.5170  decode.loss_cls: 0.1476  decode.loss_mask: 0.8106  decode.loss_dice: 0.6039  decode.d0.loss_cls: 0.6374  decode.d0.loss_mask: 0.8085  decode.d0.loss_dice: 0.6221  decode.d1.loss_cls: 0.2053  decode.d1.loss_mask: 0.8442  decode.d1.loss_dice: 0.6168  decode.d2.loss_cls: 0.1616  decode.d2.loss_mask: 0.8034  decode.d2.loss_dice: 0.6100  decode.d3.loss_cls: 0.1689  decode.d3.loss_mask: 0.8005  decode.d3.loss_dice: 0.5986  decode.d4.loss_cls: 0.1594  decode.d4.loss_mask: 0.8221  decode.d4.loss_dice: 0.6316  decode.d5.loss_cls: 0.1510  decode.d5.loss_mask: 0.8102  decode.d5.loss_dice: 0.6270  decode.d6.loss_cls: 0.1731  decode.d6.loss_mask: 0.8350  decode.d6.loss_dice: 0.6408  decode.d7.loss_cls: 0.1848  decode.d7.loss_mask: 0.8361  decode.d7.loss_dice: 0.6190  decode.d8.loss_cls: 0.1824  decode.d8.loss_mask: 0.8120  decode.d8.loss_dice: 0.5931
06/01 13:09:38 - mmengine - INFO - Iter(train) [153800/160000]  base_lr: 5.3635e-06 lr: 5.3635e-07  eta: 3:50:41  time: 0.6413  data_time: 0.0106  memory: 10492  grad_norm: 209.3126  loss: 12.7525  decode.loss_cls: 0.0733  decode.loss_mask: 0.6572  decode.loss_dice: 0.5077  decode.d0.loss_cls: 0.4830  decode.d0.loss_mask: 0.6343  decode.d0.loss_dice: 0.4990  decode.d1.loss_cls: 0.0930  decode.d1.loss_mask: 0.6580  decode.d1.loss_dice: 0.5072  decode.d2.loss_cls: 0.0742  decode.d2.loss_mask: 0.6549  decode.d2.loss_dice: 0.5016  decode.d3.loss_cls: 0.0678  decode.d3.loss_mask: 0.6544  decode.d3.loss_dice: 0.5010  decode.d4.loss_cls: 0.0689  decode.d4.loss_mask: 0.6592  decode.d4.loss_dice: 0.5023  decode.d5.loss_cls: 0.0772  decode.d5.loss_mask: 0.6574  decode.d5.loss_dice: 0.5102  decode.d6.loss_cls: 0.0792  decode.d6.loss_mask: 0.6553  decode.d6.loss_dice: 0.5091  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.6552  decode.d7.loss_dice: 0.5208  decode.d8.loss_cls: 0.0751  decode.d8.loss_mask: 0.6487  decode.d8.loss_dice: 0.4966
06/01 13:10:10 - mmengine - INFO - Iter(train) [153850/160000]  base_lr: 5.3245e-06 lr: 5.3245e-07  eta: 3:47:54  time: 0.6426  data_time: 0.0107  memory: 10500  grad_norm: 1719.3099  loss: 12.6613  decode.loss_cls: 0.0256  decode.loss_mask: 0.7415  decode.loss_dice: 0.4476  decode.d0.loss_cls: 0.4216  decode.d0.loss_mask: 0.7800  decode.d0.loss_dice: 0.4576  decode.d1.loss_cls: 0.0280  decode.d1.loss_mask: 0.7526  decode.d1.loss_dice: 0.4575  decode.d2.loss_cls: 0.0289  decode.d2.loss_mask: 0.7411  decode.d2.loss_dice: 0.4510  decode.d3.loss_cls: 0.0280  decode.d3.loss_mask: 0.7414  decode.d3.loss_dice: 0.4534  decode.d4.loss_cls: 0.0299  decode.d4.loss_mask: 0.7401  decode.d4.loss_dice: 0.4515  decode.d5.loss_cls: 0.0284  decode.d5.loss_mask: 0.7400  decode.d5.loss_dice: 0.4492  decode.d6.loss_cls: 0.0212  decode.d6.loss_mask: 0.7488  decode.d6.loss_dice: 0.4541  decode.d7.loss_cls: 0.0264  decode.d7.loss_mask: 0.7459  decode.d7.loss_dice: 0.4537  decode.d8.loss_cls: 0.0246  decode.d8.loss_mask: 0.7410  decode.d8.loss_dice: 0.4507
06/01 13:10:43 - mmengine - INFO - Iter(train) [153900/160000]  base_lr: 5.2856e-06 lr: 5.2856e-07  eta: 3:45:09  time: 0.6422  data_time: 0.0107  memory: 10512  grad_norm: 313.1475  loss: 15.8182  decode.loss_cls: 0.0787  decode.loss_mask: 0.8758  decode.loss_dice: 0.5934  decode.d0.loss_cls: 0.4825  decode.d0.loss_mask: 0.8561  decode.d0.loss_dice: 0.5725  decode.d1.loss_cls: 0.0744  decode.d1.loss_mask: 0.8875  decode.d1.loss_dice: 0.5749  decode.d2.loss_cls: 0.0796  decode.d2.loss_mask: 0.8800  decode.d2.loss_dice: 0.6041  decode.d3.loss_cls: 0.0758  decode.d3.loss_mask: 0.8837  decode.d3.loss_dice: 0.5976  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.8825  decode.d4.loss_dice: 0.5607  decode.d5.loss_cls: 0.0749  decode.d5.loss_mask: 0.8805  decode.d5.loss_dice: 0.5830  decode.d6.loss_cls: 0.0764  decode.d6.loss_mask: 0.8784  decode.d6.loss_dice: 0.6087  decode.d7.loss_cls: 0.0739  decode.d7.loss_mask: 0.8844  decode.d7.loss_dice: 0.5867  decode.d8.loss_cls: 0.0706  decode.d8.loss_mask: 0.8754  decode.d8.loss_dice: 0.5881
06/01 13:11:15 - mmengine - INFO - Iter(train) [153950/160000]  base_lr: 5.2466e-06 lr: 5.2466e-07  eta: 3:42:25  time: 0.6414  data_time: 0.0106  memory: 10519  grad_norm: 389.4870  loss: 16.1233  decode.loss_cls: 0.1045  decode.loss_mask: 0.8621  decode.loss_dice: 0.6115  decode.d0.loss_cls: 0.5276  decode.d0.loss_mask: 0.8379  decode.d0.loss_dice: 0.6173  decode.d1.loss_cls: 0.1012  decode.d1.loss_mask: 0.8563  decode.d1.loss_dice: 0.6221  decode.d2.loss_cls: 0.1066  decode.d2.loss_mask: 0.8574  decode.d2.loss_dice: 0.6001  decode.d3.loss_cls: 0.1091  decode.d3.loss_mask: 0.8572  decode.d3.loss_dice: 0.6110  decode.d4.loss_cls: 0.1072  decode.d4.loss_mask: 0.8590  decode.d4.loss_dice: 0.6029  decode.d5.loss_cls: 0.1063  decode.d5.loss_mask: 0.8652  decode.d5.loss_dice: 0.6121  decode.d6.loss_cls: 0.1035  decode.d6.loss_mask: 0.8665  decode.d6.loss_dice: 0.6080  decode.d7.loss_cls: 0.1397  decode.d7.loss_mask: 0.8123  decode.d7.loss_dice: 0.5822  decode.d8.loss_cls: 0.1095  decode.d8.loss_mask: 0.8621  decode.d8.loss_dice: 0.6047
06/01 13:11:47 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 13:11:47 - mmengine - INFO - Iter(train) [154000/160000]  base_lr: 5.2075e-06 lr: 5.2075e-07  eta: 3:39:43  time: 0.6419  data_time: 0.0107  memory: 10492  grad_norm: 302.9784  loss: 13.9558  decode.loss_cls: 0.0591  decode.loss_mask: 0.7624  decode.loss_dice: 0.5290  decode.d0.loss_cls: 0.4873  decode.d0.loss_mask: 0.8182  decode.d0.loss_dice: 0.5282  decode.d1.loss_cls: 0.0618  decode.d1.loss_mask: 0.7685  decode.d1.loss_dice: 0.5255  decode.d2.loss_cls: 0.0500  decode.d2.loss_mask: 0.7612  decode.d2.loss_dice: 0.5267  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.7577  decode.d3.loss_dice: 0.5272  decode.d4.loss_cls: 0.0583  decode.d4.loss_mask: 0.7601  decode.d4.loss_dice: 0.5255  decode.d5.loss_cls: 0.0591  decode.d5.loss_mask: 0.7639  decode.d5.loss_dice: 0.5291  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.7637  decode.d6.loss_dice: 0.5250  decode.d7.loss_cls: 0.0529  decode.d7.loss_mask: 0.7599  decode.d7.loss_dice: 0.5250  decode.d8.loss_cls: 0.0602  decode.d8.loss_mask: 0.7645  decode.d8.loss_dice: 0.5300
06/01 13:12:19 - mmengine - INFO - Iter(train) [154050/160000]  base_lr: 5.1684e-06 lr: 5.1684e-07  eta: 3:37:02  time: 0.6417  data_time: 0.0107  memory: 10504  grad_norm: 304.0501  loss: 15.8999  decode.loss_cls: 0.0517  decode.loss_mask: 0.8985  decode.loss_dice: 0.5904  decode.d0.loss_cls: 0.4900  decode.d0.loss_mask: 0.8433  decode.d0.loss_dice: 0.5866  decode.d1.loss_cls: 0.0595  decode.d1.loss_mask: 0.9011  decode.d1.loss_dice: 0.5902  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 0.8935  decode.d2.loss_dice: 0.5895  decode.d3.loss_cls: 0.0582  decode.d3.loss_mask: 0.9137  decode.d3.loss_dice: 0.5892  decode.d4.loss_cls: 0.0557  decode.d4.loss_mask: 0.9136  decode.d4.loss_dice: 0.6012  decode.d5.loss_cls: 0.0324  decode.d5.loss_mask: 0.9500  decode.d5.loss_dice: 0.5958  decode.d6.loss_cls: 0.0609  decode.d6.loss_mask: 0.9004  decode.d6.loss_dice: 0.5875  decode.d7.loss_cls: 0.0524  decode.d7.loss_mask: 0.8993  decode.d7.loss_dice: 0.5904  decode.d8.loss_cls: 0.0485  decode.d8.loss_mask: 0.8973  decode.d8.loss_dice: 0.5966
06/01 13:12:51 - mmengine - INFO - Iter(train) [154100/160000]  base_lr: 5.1293e-06 lr: 5.1293e-07  eta: 3:34:22  time: 0.6414  data_time: 0.0107  memory: 10504  grad_norm: 231.2578  loss: 15.7891  decode.loss_cls: 0.0699  decode.loss_mask: 0.8408  decode.loss_dice: 0.5982  decode.d0.loss_cls: 0.5266  decode.d0.loss_mask: 0.8207  decode.d0.loss_dice: 0.5907  decode.d1.loss_cls: 0.1138  decode.d1.loss_mask: 0.8426  decode.d1.loss_dice: 0.6138  decode.d2.loss_cls: 0.0972  decode.d2.loss_mask: 0.8520  decode.d2.loss_dice: 0.6149  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 0.8934  decode.d3.loss_dice: 0.6162  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.8407  decode.d4.loss_dice: 0.6080  decode.d5.loss_cls: 0.0836  decode.d5.loss_mask: 0.8393  decode.d5.loss_dice: 0.6104  decode.d6.loss_cls: 0.0755  decode.d6.loss_mask: 0.8447  decode.d6.loss_dice: 0.5953  decode.d7.loss_cls: 0.0732  decode.d7.loss_mask: 0.8546  decode.d7.loss_dice: 0.6025  decode.d8.loss_cls: 0.0674  decode.d8.loss_mask: 0.8462  decode.d8.loss_dice: 0.6121
06/01 13:13:23 - mmengine - INFO - Iter(train) [154150/160000]  base_lr: 5.0902e-06 lr: 5.0902e-07  eta: 3:31:44  time: 0.6420  data_time: 0.0106  memory: 10499  grad_norm: 452.4409  loss: 14.7520  decode.loss_cls: 0.0485  decode.loss_mask: 0.8367  decode.loss_dice: 0.5389  decode.d0.loss_cls: 0.4712  decode.d0.loss_mask: 0.8313  decode.d0.loss_dice: 0.5360  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.8404  decode.d1.loss_dice: 0.5357  decode.d2.loss_cls: 0.0787  decode.d2.loss_mask: 0.8358  decode.d2.loss_dice: 0.5419  decode.d3.loss_cls: 0.0592  decode.d3.loss_mask: 0.8359  decode.d3.loss_dice: 0.5414  decode.d4.loss_cls: 0.0541  decode.d4.loss_mask: 0.8321  decode.d4.loss_dice: 0.5287  decode.d5.loss_cls: 0.0593  decode.d5.loss_mask: 0.8320  decode.d5.loss_dice: 0.5394  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.8356  decode.d6.loss_dice: 0.5424  decode.d7.loss_cls: 0.0562  decode.d7.loss_mask: 0.8349  decode.d7.loss_dice: 0.5434  decode.d8.loss_cls: 0.0465  decode.d8.loss_mask: 0.8343  decode.d8.loss_dice: 0.5418
06/01 13:13:55 - mmengine - INFO - Iter(train) [154200/160000]  base_lr: 5.0510e-06 lr: 5.0510e-07  eta: 3:29:07  time: 0.6419  data_time: 0.0107  memory: 10496  grad_norm: 298.8499  loss: 14.5731  decode.loss_cls: 0.0761  decode.loss_mask: 0.8347  decode.loss_dice: 0.5009  decode.d0.loss_cls: 0.5181  decode.d0.loss_mask: 0.7853  decode.d0.loss_dice: 0.4699  decode.d1.loss_cls: 0.1105  decode.d1.loss_mask: 0.8421  decode.d1.loss_dice: 0.5048  decode.d2.loss_cls: 0.0885  decode.d2.loss_mask: 0.8303  decode.d2.loss_dice: 0.4908  decode.d3.loss_cls: 0.0883  decode.d3.loss_mask: 0.8305  decode.d3.loss_dice: 0.5012  decode.d4.loss_cls: 0.0938  decode.d4.loss_mask: 0.8318  decode.d4.loss_dice: 0.4981  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.8317  decode.d5.loss_dice: 0.5001  decode.d6.loss_cls: 0.0833  decode.d6.loss_mask: 0.8357  decode.d6.loss_dice: 0.5008  decode.d7.loss_cls: 0.0794  decode.d7.loss_mask: 0.8384  decode.d7.loss_dice: 0.5025  decode.d8.loss_cls: 0.0871  decode.d8.loss_mask: 0.8345  decode.d8.loss_dice: 0.5014
06/01 13:14:28 - mmengine - INFO - Iter(train) [154250/160000]  base_lr: 5.0118e-06 lr: 5.0118e-07  eta: 3:26:32  time: 0.6429  data_time: 0.0108  memory: 10495  grad_norm: 623.6812  loss: 13.0329  decode.loss_cls: 0.0252  decode.loss_mask: 0.7129  decode.loss_dice: 0.5159  decode.d0.loss_cls: 0.4950  decode.d0.loss_mask: 0.7204  decode.d0.loss_dice: 0.5106  decode.d1.loss_cls: 0.0393  decode.d1.loss_mask: 0.7133  decode.d1.loss_dice: 0.5161  decode.d2.loss_cls: 0.0264  decode.d2.loss_mask: 0.7133  decode.d2.loss_dice: 0.5110  decode.d3.loss_cls: 0.0236  decode.d3.loss_mask: 0.7162  decode.d3.loss_dice: 0.5180  decode.d4.loss_cls: 0.0232  decode.d4.loss_mask: 0.7148  decode.d4.loss_dice: 0.5229  decode.d5.loss_cls: 0.0232  decode.d5.loss_mask: 0.7131  decode.d5.loss_dice: 0.5136  decode.d6.loss_cls: 0.0236  decode.d6.loss_mask: 0.7130  decode.d6.loss_dice: 0.5166  decode.d7.loss_cls: 0.0234  decode.d7.loss_mask: 0.7156  decode.d7.loss_dice: 0.5129  decode.d8.loss_cls: 0.0259  decode.d8.loss_mask: 0.7139  decode.d8.loss_dice: 0.5200
06/01 13:15:00 - mmengine - INFO - Iter(train) [154300/160000]  base_lr: 4.9726e-06 lr: 4.9726e-07  eta: 3:23:58  time: 0.6426  data_time: 0.0107  memory: 10496  grad_norm: 324.1673  loss: 14.5703  decode.loss_cls: 0.0725  decode.loss_mask: 0.8024  decode.loss_dice: 0.5529  decode.d0.loss_cls: 0.5220  decode.d0.loss_mask: 0.8063  decode.d0.loss_dice: 0.5320  decode.d1.loss_cls: 0.0738  decode.d1.loss_mask: 0.8081  decode.d1.loss_dice: 0.5375  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.8101  decode.d2.loss_dice: 0.5591  decode.d3.loss_cls: 0.0663  decode.d3.loss_mask: 0.8034  decode.d3.loss_dice: 0.5376  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.8027  decode.d4.loss_dice: 0.5518  decode.d5.loss_cls: 0.0732  decode.d5.loss_mask: 0.7954  decode.d5.loss_dice: 0.5360  decode.d6.loss_cls: 0.0705  decode.d6.loss_mask: 0.8004  decode.d6.loss_dice: 0.5362  decode.d7.loss_cls: 0.0663  decode.d7.loss_mask: 0.8003  decode.d7.loss_dice: 0.5323  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.7986  decode.d8.loss_dice: 0.5376
06/01 13:15:32 - mmengine - INFO - Iter(train) [154350/160000]  base_lr: 4.9333e-06 lr: 4.9333e-07  eta: 3:21:25  time: 0.6427  data_time: 0.0107  memory: 10505  grad_norm: 188.4859  loss: 12.4213  decode.loss_cls: 0.0705  decode.loss_mask: 0.6684  decode.loss_dice: 0.4511  decode.d0.loss_cls: 0.4513  decode.d0.loss_mask: 0.6848  decode.d0.loss_dice: 0.4504  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.6736  decode.d1.loss_dice: 0.4551  decode.d2.loss_cls: 0.0841  decode.d2.loss_mask: 0.6728  decode.d2.loss_dice: 0.4528  decode.d3.loss_cls: 0.0729  decode.d3.loss_mask: 0.6789  decode.d3.loss_dice: 0.4535  decode.d4.loss_cls: 0.0742  decode.d4.loss_mask: 0.6704  decode.d4.loss_dice: 0.4495  decode.d5.loss_cls: 0.0811  decode.d5.loss_mask: 0.6709  decode.d5.loss_dice: 0.4466  decode.d6.loss_cls: 0.0802  decode.d6.loss_mask: 0.6687  decode.d6.loss_dice: 0.4521  decode.d7.loss_cls: 0.0789  decode.d7.loss_mask: 0.6804  decode.d7.loss_dice: 0.4501  decode.d8.loss_cls: 0.0817  decode.d8.loss_mask: 0.6697  decode.d8.loss_dice: 0.4543
06/01 13:16:04 - mmengine - INFO - Iter(train) [154400/160000]  base_lr: 4.8940e-06 lr: 4.8940e-07  eta: 3:18:53  time: 0.6423  data_time: 0.0107  memory: 10495  grad_norm: 242.7364  loss: 13.6320  decode.loss_cls: 0.0447  decode.loss_mask: 0.7577  decode.loss_dice: 0.5132  decode.d0.loss_cls: 0.5822  decode.d0.loss_mask: 0.7173  decode.d0.loss_dice: 0.5102  decode.d1.loss_cls: 0.0725  decode.d1.loss_mask: 0.7524  decode.d1.loss_dice: 0.5195  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.7563  decode.d2.loss_dice: 0.5163  decode.d3.loss_cls: 0.0426  decode.d3.loss_mask: 0.7526  decode.d3.loss_dice: 0.5112  decode.d4.loss_cls: 0.0532  decode.d4.loss_mask: 0.7477  decode.d4.loss_dice: 0.5095  decode.d5.loss_cls: 0.0658  decode.d5.loss_mask: 0.7417  decode.d5.loss_dice: 0.5054  decode.d6.loss_cls: 0.0435  decode.d6.loss_mask: 0.7516  decode.d6.loss_dice: 0.5063  decode.d7.loss_cls: 0.0426  decode.d7.loss_mask: 0.7543  decode.d7.loss_dice: 0.5087  decode.d8.loss_cls: 0.0370  decode.d8.loss_mask: 0.7511  decode.d8.loss_dice: 0.5101
06/01 13:16:36 - mmengine - INFO - Iter(train) [154450/160000]  base_lr: 4.8547e-06 lr: 4.8547e-07  eta: 3:16:23  time: 0.6427  data_time: 0.0106  memory: 10495  grad_norm: 327.2340  loss: 13.2924  decode.loss_cls: 0.1316  decode.loss_mask: 0.7387  decode.loss_dice: 0.4432  decode.d0.loss_cls: 0.4972  decode.d0.loss_mask: 0.7271  decode.d0.loss_dice: 0.4471  decode.d1.loss_cls: 0.0923  decode.d1.loss_mask: 0.7374  decode.d1.loss_dice: 0.4572  decode.d2.loss_cls: 0.0958  decode.d2.loss_mask: 0.7370  decode.d2.loss_dice: 0.4325  decode.d3.loss_cls: 0.1081  decode.d3.loss_mask: 0.7331  decode.d3.loss_dice: 0.4579  decode.d4.loss_cls: 0.1045  decode.d4.loss_mask: 0.7385  decode.d4.loss_dice: 0.4399  decode.d5.loss_cls: 0.1024  decode.d5.loss_mask: 0.7335  decode.d5.loss_dice: 0.4459  decode.d6.loss_cls: 0.1016  decode.d6.loss_mask: 0.7356  decode.d6.loss_dice: 0.4497  decode.d7.loss_cls: 0.1187  decode.d7.loss_mask: 0.7258  decode.d7.loss_dice: 0.4414  decode.d8.loss_cls: 0.1266  decode.d8.loss_mask: 0.7529  decode.d8.loss_dice: 0.4392
06/01 13:17:08 - mmengine - INFO - Iter(train) [154500/160000]  base_lr: 4.8153e-06 lr: 4.8153e-07  eta: 3:13:54  time: 0.6426  data_time: 0.0107  memory: 10503  grad_norm: 388.8102  loss: 12.4918  decode.loss_cls: 0.0361  decode.loss_mask: 0.6966  decode.loss_dice: 0.4526  decode.d0.loss_cls: 0.4326  decode.d0.loss_mask: 0.7527  decode.d0.loss_dice: 0.4814  decode.d1.loss_cls: 0.0415  decode.d1.loss_mask: 0.7404  decode.d1.loss_dice: 0.4654  decode.d2.loss_cls: 0.0363  decode.d2.loss_mask: 0.6938  decode.d2.loss_dice: 0.4544  decode.d3.loss_cls: 0.0413  decode.d3.loss_mask: 0.6874  decode.d3.loss_dice: 0.4537  decode.d4.loss_cls: 0.0464  decode.d4.loss_mask: 0.6869  decode.d4.loss_dice: 0.4552  decode.d5.loss_cls: 0.0413  decode.d5.loss_mask: 0.6921  decode.d5.loss_dice: 0.4544  decode.d6.loss_cls: 0.0409  decode.d6.loss_mask: 0.6971  decode.d6.loss_dice: 0.4535  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.7479  decode.d7.loss_dice: 0.4636  decode.d8.loss_cls: 0.0414  decode.d8.loss_mask: 0.6990  decode.d8.loss_dice: 0.4525
06/01 13:17:41 - mmengine - INFO - Iter(train) [154550/160000]  base_lr: 4.7759e-06 lr: 4.7759e-07  eta: 3:11:26  time: 0.6445  data_time: 0.0124  memory: 10513  grad_norm: 147.9569  loss: 11.7690  decode.loss_cls: 0.0225  decode.loss_mask: 0.6431  decode.loss_dice: 0.4683  decode.d0.loss_cls: 0.3802  decode.d0.loss_mask: 0.6609  decode.d0.loss_dice: 0.4733  decode.d1.loss_cls: 0.0184  decode.d1.loss_mask: 0.6877  decode.d1.loss_dice: 0.4810  decode.d2.loss_cls: 0.0290  decode.d2.loss_mask: 0.6416  decode.d2.loss_dice: 0.4673  decode.d3.loss_cls: 0.0256  decode.d3.loss_mask: 0.6439  decode.d3.loss_dice: 0.4656  decode.d4.loss_cls: 0.0232  decode.d4.loss_mask: 0.6459  decode.d4.loss_dice: 0.4671  decode.d5.loss_cls: 0.0195  decode.d5.loss_mask: 0.6434  decode.d5.loss_dice: 0.4638  decode.d6.loss_cls: 0.0199  decode.d6.loss_mask: 0.6450  decode.d6.loss_dice: 0.4639  decode.d7.loss_cls: 0.0224  decode.d7.loss_mask: 0.6438  decode.d7.loss_dice: 0.4684  decode.d8.loss_cls: 0.0210  decode.d8.loss_mask: 0.6448  decode.d8.loss_dice: 0.4687
06/01 13:18:13 - mmengine - INFO - Iter(train) [154600/160000]  base_lr: 4.7364e-06 lr: 4.7364e-07  eta: 3:09:00  time: 0.6431  data_time: 0.0107  memory: 10512  grad_norm: 411.2419  loss: 16.4955  decode.loss_cls: 0.0900  decode.loss_mask: 0.8542  decode.loss_dice: 0.6379  decode.d0.loss_cls: 0.5542  decode.d0.loss_mask: 0.8363  decode.d0.loss_dice: 0.6317  decode.d1.loss_cls: 0.1658  decode.d1.loss_mask: 0.8672  decode.d1.loss_dice: 0.6405  decode.d2.loss_cls: 0.1050  decode.d2.loss_mask: 0.8605  decode.d2.loss_dice: 0.6329  decode.d3.loss_cls: 0.1349  decode.d3.loss_mask: 0.8600  decode.d3.loss_dice: 0.6244  decode.d4.loss_cls: 0.1475  decode.d4.loss_mask: 0.8630  decode.d4.loss_dice: 0.6274  decode.d5.loss_cls: 0.1088  decode.d5.loss_mask: 0.8560  decode.d5.loss_dice: 0.6293  decode.d6.loss_cls: 0.1062  decode.d6.loss_mask: 0.8543  decode.d6.loss_dice: 0.6249  decode.d7.loss_cls: 0.1024  decode.d7.loss_mask: 0.8635  decode.d7.loss_dice: 0.6230  decode.d8.loss_cls: 0.0971  decode.d8.loss_mask: 0.8593  decode.d8.loss_dice: 0.6374
06/01 13:18:45 - mmengine - INFO - Iter(train) [154650/160000]  base_lr: 4.6969e-06 lr: 4.6969e-07  eta: 3:06:34  time: 0.6435  data_time: 0.0106  memory: 10500  grad_norm: 557.0848  loss: 13.0199  decode.loss_cls: 0.0629  decode.loss_mask: 0.7222  decode.loss_dice: 0.4616  decode.d0.loss_cls: 0.4927  decode.d0.loss_mask: 0.7116  decode.d0.loss_dice: 0.4651  decode.d1.loss_cls: 0.0657  decode.d1.loss_mask: 0.7335  decode.d1.loss_dice: 0.4577  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.7272  decode.d2.loss_dice: 0.4597  decode.d3.loss_cls: 0.0601  decode.d3.loss_mask: 0.7307  decode.d3.loss_dice: 0.4608  decode.d4.loss_cls: 0.0770  decode.d4.loss_mask: 0.7287  decode.d4.loss_dice: 0.4622  decode.d5.loss_cls: 0.0755  decode.d5.loss_mask: 0.7299  decode.d5.loss_dice: 0.4615  decode.d6.loss_cls: 0.0662  decode.d6.loss_mask: 0.7262  decode.d6.loss_dice: 0.4591  decode.d7.loss_cls: 0.1076  decode.d7.loss_mask: 0.7238  decode.d7.loss_dice: 0.4606  decode.d8.loss_cls: 0.0734  decode.d8.loss_mask: 0.7216  decode.d8.loss_dice: 0.4619
06/01 13:19:17 - mmengine - INFO - Iter(train) [154700/160000]  base_lr: 4.6574e-06 lr: 4.6574e-07  eta: 3:04:10  time: 0.6425  data_time: 0.0108  memory: 10492  grad_norm: 162.9097  loss: 12.2078  decode.loss_cls: 0.0526  decode.loss_mask: 0.6462  decode.loss_dice: 0.4774  decode.d0.loss_cls: 0.3982  decode.d0.loss_mask: 0.6467  decode.d0.loss_dice: 0.4966  decode.d1.loss_cls: 0.0593  decode.d1.loss_mask: 0.6389  decode.d1.loss_dice: 0.4742  decode.d2.loss_cls: 0.0571  decode.d2.loss_mask: 0.6412  decode.d2.loss_dice: 0.4769  decode.d3.loss_cls: 0.0559  decode.d3.loss_mask: 0.6437  decode.d3.loss_dice: 0.4774  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.6444  decode.d4.loss_dice: 0.4868  decode.d5.loss_cls: 0.0557  decode.d5.loss_mask: 0.6482  decode.d5.loss_dice: 0.4875  decode.d6.loss_cls: 0.0569  decode.d6.loss_mask: 0.6433  decode.d6.loss_dice: 0.4959  decode.d7.loss_cls: 0.0612  decode.d7.loss_mask: 0.6459  decode.d7.loss_dice: 0.4779  decode.d8.loss_cls: 0.0601  decode.d8.loss_mask: 0.6463  decode.d8.loss_dice: 0.4897
06/01 13:19:49 - mmengine - INFO - Iter(train) [154750/160000]  base_lr: 4.6178e-06 lr: 4.6178e-07  eta: 3:01:47  time: 0.6425  data_time: 0.0107  memory: 10492  grad_norm: 221.5396  loss: 16.0241  decode.loss_cls: 0.0526  decode.loss_mask: 0.8518  decode.loss_dice: 0.6365  decode.d0.loss_cls: 0.5003  decode.d0.loss_mask: 0.8349  decode.d0.loss_dice: 0.6121  decode.d1.loss_cls: 0.0554  decode.d1.loss_mask: 0.8886  decode.d1.loss_dice: 0.6449  decode.d2.loss_cls: 0.0591  decode.d2.loss_mask: 0.8749  decode.d2.loss_dice: 0.6474  decode.d3.loss_cls: 0.0541  decode.d3.loss_mask: 0.8550  decode.d3.loss_dice: 0.6428  decode.d4.loss_cls: 0.0757  decode.d4.loss_mask: 0.8453  decode.d4.loss_dice: 0.6431  decode.d5.loss_cls: 0.0431  decode.d5.loss_mask: 0.8763  decode.d5.loss_dice: 0.6464  decode.d6.loss_cls: 0.0557  decode.d6.loss_mask: 0.8546  decode.d6.loss_dice: 0.6402  decode.d7.loss_cls: 0.0556  decode.d7.loss_mask: 0.8673  decode.d7.loss_dice: 0.6372  decode.d8.loss_cls: 0.0504  decode.d8.loss_mask: 0.8793  decode.d8.loss_dice: 0.6434
06/01 13:20:21 - mmengine - INFO - Iter(train) [154800/160000]  base_lr: 4.5782e-06 lr: 4.5782e-07  eta: 2:59:25  time: 0.6428  data_time: 0.0107  memory: 10504  grad_norm: 431.5155  loss: 15.6591  decode.loss_cls: 0.0979  decode.loss_mask: 0.8207  decode.loss_dice: 0.5958  decode.d0.loss_cls: 0.4526  decode.d0.loss_mask: 0.8265  decode.d0.loss_dice: 0.6122  decode.d1.loss_cls: 0.1433  decode.d1.loss_mask: 0.8260  decode.d1.loss_dice: 0.5918  decode.d2.loss_cls: 0.1177  decode.d2.loss_mask: 0.8115  decode.d2.loss_dice: 0.5951  decode.d3.loss_cls: 0.0796  decode.d3.loss_mask: 0.8799  decode.d3.loss_dice: 0.6051  decode.d4.loss_cls: 0.1080  decode.d4.loss_mask: 0.8136  decode.d4.loss_dice: 0.5978  decode.d5.loss_cls: 0.1122  decode.d5.loss_mask: 0.8145  decode.d5.loss_dice: 0.5955  decode.d6.loss_cls: 0.1253  decode.d6.loss_mask: 0.8075  decode.d6.loss_dice: 0.5828  decode.d7.loss_cls: 0.1168  decode.d7.loss_mask: 0.8124  decode.d7.loss_dice: 0.5881  decode.d8.loss_cls: 0.0642  decode.d8.loss_mask: 0.8707  decode.d8.loss_dice: 0.5937
06/01 13:20:54 - mmengine - INFO - Iter(train) [154850/160000]  base_lr: 4.5386e-06 lr: 4.5386e-07  eta: 2:57:04  time: 0.6432  data_time: 0.0108  memory: 10504  grad_norm: 318.6280  loss: 13.6328  decode.loss_cls: 0.1136  decode.loss_mask: 0.6693  decode.loss_dice: 0.5422  decode.d0.loss_cls: 0.5451  decode.d0.loss_mask: 0.6436  decode.d0.loss_dice: 0.5285  decode.d1.loss_cls: 0.1346  decode.d1.loss_mask: 0.6716  decode.d1.loss_dice: 0.5158  decode.d2.loss_cls: 0.1169  decode.d2.loss_mask: 0.6616  decode.d2.loss_dice: 0.5294  decode.d3.loss_cls: 0.1211  decode.d3.loss_mask: 0.6752  decode.d3.loss_dice: 0.5379  decode.d4.loss_cls: 0.1292  decode.d4.loss_mask: 0.6612  decode.d4.loss_dice: 0.5203  decode.d5.loss_cls: 0.1441  decode.d5.loss_mask: 0.6641  decode.d5.loss_dice: 0.5222  decode.d6.loss_cls: 0.1411  decode.d6.loss_mask: 0.6668  decode.d6.loss_dice: 0.5418  decode.d7.loss_cls: 0.1210  decode.d7.loss_mask: 0.6719  decode.d7.loss_dice: 0.5199  decode.d8.loss_cls: 0.1176  decode.d8.loss_mask: 0.6631  decode.d8.loss_dice: 0.5422
06/01 13:21:26 - mmengine - INFO - Iter(train) [154900/160000]  base_lr: 4.4989e-06 lr: 4.4989e-07  eta: 2:54:45  time: 0.6428  data_time: 0.0107  memory: 10495  grad_norm: 374.3481  loss: 12.7258  decode.loss_cls: 0.0913  decode.loss_mask: 0.6717  decode.loss_dice: 0.4478  decode.d0.loss_cls: 0.4811  decode.d0.loss_mask: 0.6631  decode.d0.loss_dice: 0.4765  decode.d1.loss_cls: 0.0895  decode.d1.loss_mask: 0.7064  decode.d1.loss_dice: 0.4630  decode.d2.loss_cls: 0.0747  decode.d2.loss_mask: 0.7080  decode.d2.loss_dice: 0.4571  decode.d3.loss_cls: 0.0733  decode.d3.loss_mask: 0.6743  decode.d3.loss_dice: 0.4895  decode.d4.loss_cls: 0.0908  decode.d4.loss_mask: 0.6810  decode.d4.loss_dice: 0.4590  decode.d5.loss_cls: 0.0765  decode.d5.loss_mask: 0.7020  decode.d5.loss_dice: 0.4663  decode.d6.loss_cls: 0.0770  decode.d6.loss_mask: 0.6874  decode.d6.loss_dice: 0.4627  decode.d7.loss_cls: 0.0929  decode.d7.loss_mask: 0.6929  decode.d7.loss_dice: 0.4668  decode.d8.loss_cls: 0.0962  decode.d8.loss_mask: 0.6600  decode.d8.loss_dice: 0.4473
06/01 13:21:58 - mmengine - INFO - Iter(train) [154950/160000]  base_lr: 4.4592e-06 lr: 4.4592e-07  eta: 2:52:26  time: 0.6452  data_time: 0.0109  memory: 10494  grad_norm: 394.6406  loss: 14.8396  decode.loss_cls: 0.1003  decode.loss_mask: 0.7911  decode.loss_dice: 0.5552  decode.d0.loss_cls: 0.5389  decode.d0.loss_mask: 0.7840  decode.d0.loss_dice: 0.5522  decode.d1.loss_cls: 0.1177  decode.d1.loss_mask: 0.7977  decode.d1.loss_dice: 0.5628  decode.d2.loss_cls: 0.0993  decode.d2.loss_mask: 0.7858  decode.d2.loss_dice: 0.5476  decode.d3.loss_cls: 0.0953  decode.d3.loss_mask: 0.8047  decode.d3.loss_dice: 0.5652  decode.d4.loss_cls: 0.0936  decode.d4.loss_mask: 0.7829  decode.d4.loss_dice: 0.5521  decode.d5.loss_cls: 0.0887  decode.d5.loss_mask: 0.7769  decode.d5.loss_dice: 0.5484  decode.d6.loss_cls: 0.0880  decode.d6.loss_mask: 0.7814  decode.d6.loss_dice: 0.5606  decode.d7.loss_cls: 0.0931  decode.d7.loss_mask: 0.7983  decode.d7.loss_dice: 0.5567  decode.d8.loss_cls: 0.0912  decode.d8.loss_mask: 0.7803  decode.d8.loss_dice: 0.5497
06/01 13:22:30 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 13:22:30 - mmengine - INFO - Iter(train) [155000/160000]  base_lr: 4.4194e-06 lr: 4.4194e-07  eta: 2:50:08  time: 0.6425  data_time: 0.0106  memory: 10503  grad_norm: 439.5215  loss: 14.7287  decode.loss_cls: 0.0744  decode.loss_mask: 0.7758  decode.loss_dice: 0.5552  decode.d0.loss_cls: 0.5948  decode.d0.loss_mask: 0.7616  decode.d0.loss_dice: 0.5897  decode.d1.loss_cls: 0.1031  decode.d1.loss_mask: 0.7793  decode.d1.loss_dice: 0.5717  decode.d2.loss_cls: 0.0860  decode.d2.loss_mask: 0.7748  decode.d2.loss_dice: 0.5600  decode.d3.loss_cls: 0.0702  decode.d3.loss_mask: 0.7730  decode.d3.loss_dice: 0.5619  decode.d4.loss_cls: 0.0933  decode.d4.loss_mask: 0.7724  decode.d4.loss_dice: 0.5592  decode.d5.loss_cls: 0.0834  decode.d5.loss_mask: 0.7698  decode.d5.loss_dice: 0.5581  decode.d6.loss_cls: 0.0839  decode.d6.loss_mask: 0.7736  decode.d6.loss_dice: 0.5545  decode.d7.loss_cls: 0.0909  decode.d7.loss_mask: 0.7767  decode.d7.loss_dice: 0.5683  decode.d8.loss_cls: 0.0862  decode.d8.loss_mask: 0.7702  decode.d8.loss_dice: 0.5567
06/01 13:22:30 - mmengine - INFO - Saving checkpoint at 155000 iterations
06/01 13:22:38 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:44  time: 0.0739  data_time: 0.0013  memory: 2320  
06/01 13:22:41 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:39  time: 0.0732  data_time: 0.0013  memory: 2133  
06/01 13:22:45 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:37  time: 0.0780  data_time: 0.0013  memory: 2529  
06/01 13:22:49 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:33  time: 0.0741  data_time: 0.0013  memory: 2230  
06/01 13:22:52 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:01:29  time: 0.0731  data_time: 0.0013  memory: 2230  
06/01 13:22:56 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:01:25  time: 0.0733  data_time: 0.0013  memory: 2215  
06/01 13:23:00 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:01:21  time: 0.0733  data_time: 0.0013  memory: 2152  
06/01 13:23:04 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:01:17  time: 0.0755  data_time: 0.0013  memory: 2231  
06/01 13:23:07 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:01:14  time: 0.0727  data_time: 0.0013  memory: 2230  
06/01 13:23:11 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:01:10  time: 0.0788  data_time: 0.0013  memory: 2662  
06/01 13:23:15 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:01:06  time: 0.0737  data_time: 0.0013  memory: 2264  
06/01 13:23:18 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:01:02  time: 0.0737  data_time: 0.0013  memory: 2230  
06/01 13:23:22 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:59  time: 0.0743  data_time: 0.0013  memory: 2133  
06/01 13:23:26 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:55  time: 0.0758  data_time: 0.0013  memory: 2245  
06/01 13:23:29 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:51  time: 0.0724  data_time: 0.0013  memory: 2215  
06/01 13:23:33 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:48  time: 0.0805  data_time: 0.0013  memory: 2339  
06/01 13:23:37 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:44  time: 0.0724  data_time: 0.0013  memory: 2215  
06/01 13:23:41 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:40  time: 0.0751  data_time: 0.0013  memory: 2133  
06/01 13:23:44 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:36  time: 0.0748  data_time: 0.0013  memory: 2133  
06/01 13:23:48 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:33  time: 0.0727  data_time: 0.0013  memory: 2264  
06/01 13:23:52 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:29  time: 0.0728  data_time: 0.0013  memory: 2171  
06/01 13:23:55 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:25  time: 0.0774  data_time: 0.0013  memory: 2433  
06/01 13:23:59 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:22  time: 0.0732  data_time: 0.0013  memory: 2190  
06/01 13:24:03 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:18  time: 0.0750  data_time: 0.0013  memory: 2230  
06/01 13:24:07 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:14  time: 0.0734  data_time: 0.0013  memory: 2379  
06/01 13:24:10 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:11  time: 0.0742  data_time: 0.0019  memory: 2230  
06/01 13:24:14 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:07  time: 0.0763  data_time: 0.0013  memory: 2215  
06/01 13:24:18 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:03  time: 0.0731  data_time: 0.0013  memory: 2133  
06/01 13:24:21 - mmengine - INFO - per class results:
06/01 13:24:21 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 96.23 | 98.14 |
|  aeroplane  | 94.05 | 99.07 |
|   bicycle   | 47.56 | 96.62 |
|     bird    | 96.51 | 98.48 |
|     boat    | 74.11 | 88.46 |
|    bottle   | 87.89 | 96.25 |
|     bus     | 96.76 | 98.23 |
|     car     | 92.87 | 96.68 |
|     cat     | 96.16 | 98.07 |
|    chair    | 43.86 | 59.64 |
|     cow     | 91.37 | 93.42 |
| diningtable | 61.01 | 63.88 |
|     dog     |  94.4 | 98.58 |
|    horse    | 87.93 | 95.46 |
|  motorbike  | 92.55 |  95.7 |
|    person   | 91.29 |  94.3 |
| pottedplant | 74.31 | 88.87 |
|    sheep    | 94.63 | 97.65 |
|     sofa    | 58.38 | 69.28 |
|    train    | 95.34 | 98.58 |
|  tvmonitor  | 85.11 | 93.44 |
+-------------+-------+-------+
06/01 13:24:21 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 96.5300  mIoU: 83.4400  mAcc: 91.3700  data_time: 0.0014  time: 0.0740
06/01 13:24:54 - mmengine - INFO - Iter(train) [155050/160000]  base_lr: 4.3796e-06 lr: 4.3796e-07  eta: 2:47:52  time: 0.6425  data_time: 0.0107  memory: 10504  grad_norm: 539.4700  loss: 18.6785  decode.loss_cls: 0.0700  decode.loss_mask: 1.1138  decode.loss_dice: 0.6874  decode.d0.loss_cls: 0.5603  decode.d0.loss_mask: 1.0406  decode.d0.loss_dice: 0.6770  decode.d1.loss_cls: 0.0715  decode.d1.loss_mask: 1.0818  decode.d1.loss_dice: 0.6678  decode.d2.loss_cls: 0.0717  decode.d2.loss_mask: 1.0804  decode.d2.loss_dice: 0.6678  decode.d3.loss_cls: 0.0776  decode.d3.loss_mask: 1.0724  decode.d3.loss_dice: 0.6574  decode.d4.loss_cls: 0.0643  decode.d4.loss_mask: 1.0860  decode.d4.loss_dice: 0.6697  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 1.0740  decode.d5.loss_dice: 0.6558  decode.d6.loss_cls: 0.0999  decode.d6.loss_mask: 1.0425  decode.d6.loss_dice: 0.6441  decode.d7.loss_cls: 0.0670  decode.d7.loss_mask: 1.0840  decode.d7.loss_dice: 0.6649  decode.d8.loss_cls: 0.0865  decode.d8.loss_mask: 1.0902  decode.d8.loss_dice: 0.6845
06/01 13:25:26 - mmengine - INFO - Iter(train) [155100/160000]  base_lr: 4.3398e-06 lr: 4.3398e-07  eta: 2:45:36  time: 0.6429  data_time: 0.0107  memory: 10504  grad_norm: 421.0526  loss: 14.2578  decode.loss_cls: 0.1209  decode.loss_mask: 0.6934  decode.loss_dice: 0.5679  decode.d0.loss_cls: 0.5684  decode.d0.loss_mask: 0.6788  decode.d0.loss_dice: 0.5613  decode.d1.loss_cls: 0.1505  decode.d1.loss_mask: 0.6943  decode.d1.loss_dice: 0.5712  decode.d2.loss_cls: 0.1012  decode.d2.loss_mask: 0.6994  decode.d2.loss_dice: 0.5861  decode.d3.loss_cls: 0.1101  decode.d3.loss_mask: 0.6979  decode.d3.loss_dice: 0.5737  decode.d4.loss_cls: 0.1097  decode.d4.loss_mask: 0.6906  decode.d4.loss_dice: 0.5715  decode.d5.loss_cls: 0.1079  decode.d5.loss_mask: 0.6882  decode.d5.loss_dice: 0.5772  decode.d6.loss_cls: 0.0856  decode.d6.loss_mask: 0.7101  decode.d6.loss_dice: 0.5944  decode.d7.loss_cls: 0.0877  decode.d7.loss_mask: 0.6885  decode.d7.loss_dice: 0.5916  decode.d8.loss_cls: 0.0896  decode.d8.loss_mask: 0.7022  decode.d8.loss_dice: 0.5879
06/01 13:25:58 - mmengine - INFO - Iter(train) [155150/160000]  base_lr: 4.2999e-06 lr: 4.2999e-07  eta: 2:43:22  time: 0.6430  data_time: 0.0107  memory: 10508  grad_norm: 257.1394  loss: 13.1632  decode.loss_cls: 0.0461  decode.loss_mask: 0.7221  decode.loss_dice: 0.4999  decode.d0.loss_cls: 0.5241  decode.d0.loss_mask: 0.7067  decode.d0.loss_dice: 0.5227  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.7177  decode.d1.loss_dice: 0.5032  decode.d2.loss_cls: 0.0615  decode.d2.loss_mask: 0.7144  decode.d2.loss_dice: 0.5085  decode.d3.loss_cls: 0.0371  decode.d3.loss_mask: 0.7214  decode.d3.loss_dice: 0.4986  decode.d4.loss_cls: 0.0423  decode.d4.loss_mask: 0.7154  decode.d4.loss_dice: 0.4948  decode.d5.loss_cls: 0.0504  decode.d5.loss_mask: 0.7196  decode.d5.loss_dice: 0.4995  decode.d6.loss_cls: 0.0469  decode.d6.loss_mask: 0.7170  decode.d6.loss_dice: 0.4914  decode.d7.loss_cls: 0.0403  decode.d7.loss_mask: 0.7130  decode.d7.loss_dice: 0.5046  decode.d8.loss_cls: 0.0555  decode.d8.loss_mask: 0.7178  decode.d8.loss_dice: 0.5040
06/01 13:26:30 - mmengine - INFO - Iter(train) [155200/160000]  base_lr: 4.2600e-06 lr: 4.2600e-07  eta: 2:41:08  time: 0.6425  data_time: 0.0106  memory: 10500  grad_norm: 150.9230  loss: 11.4625  decode.loss_cls: 0.0517  decode.loss_mask: 0.6209  decode.loss_dice: 0.4377  decode.d0.loss_cls: 0.4047  decode.d0.loss_mask: 0.6209  decode.d0.loss_dice: 0.4296  decode.d1.loss_cls: 0.0476  decode.d1.loss_mask: 0.6198  decode.d1.loss_dice: 0.4380  decode.d2.loss_cls: 0.0521  decode.d2.loss_mask: 0.6195  decode.d2.loss_dice: 0.4334  decode.d3.loss_cls: 0.0556  decode.d3.loss_mask: 0.6230  decode.d3.loss_dice: 0.4399  decode.d4.loss_cls: 0.0572  decode.d4.loss_mask: 0.6204  decode.d4.loss_dice: 0.4397  decode.d5.loss_cls: 0.0533  decode.d5.loss_mask: 0.6195  decode.d5.loss_dice: 0.4361  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.6199  decode.d6.loss_dice: 0.4402  decode.d7.loss_cls: 0.0532  decode.d7.loss_mask: 0.6176  decode.d7.loss_dice: 0.4369  decode.d8.loss_cls: 0.0552  decode.d8.loss_mask: 0.6216  decode.d8.loss_dice: 0.4391
06/01 13:27:02 - mmengine - INFO - Iter(train) [155250/160000]  base_lr: 4.2201e-06 lr: 4.2201e-07  eta: 2:38:56  time: 0.6429  data_time: 0.0108  memory: 10509  grad_norm: 263.5577  loss: 12.5977  decode.loss_cls: 0.0375  decode.loss_mask: 0.6918  decode.loss_dice: 0.4868  decode.d0.loss_cls: 0.4467  decode.d0.loss_mask: 0.6886  decode.d0.loss_dice: 0.4953  decode.d1.loss_cls: 0.0413  decode.d1.loss_mask: 0.6923  decode.d1.loss_dice: 0.4939  decode.d2.loss_cls: 0.0385  decode.d2.loss_mask: 0.6920  decode.d2.loss_dice: 0.4880  decode.d3.loss_cls: 0.0418  decode.d3.loss_mask: 0.6874  decode.d3.loss_dice: 0.4884  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.6870  decode.d4.loss_dice: 0.4824  decode.d5.loss_cls: 0.0447  decode.d5.loss_mask: 0.6925  decode.d5.loss_dice: 0.4886  decode.d6.loss_cls: 0.0367  decode.d6.loss_mask: 0.6917  decode.d6.loss_dice: 0.4877  decode.d7.loss_cls: 0.0367  decode.d7.loss_mask: 0.6930  decode.d7.loss_dice: 0.4874  decode.d8.loss_cls: 0.0336  decode.d8.loss_mask: 0.6962  decode.d8.loss_dice: 0.4906
06/01 13:27:34 - mmengine - INFO - Iter(train) [155300/160000]  base_lr: 4.1801e-06 lr: 4.1801e-07  eta: 2:36:44  time: 0.6429  data_time: 0.0107  memory: 10509  grad_norm: 1867.2336  loss: 18.2681  decode.loss_cls: 0.1162  decode.loss_mask: 1.0239  decode.loss_dice: 0.6707  decode.d0.loss_cls: 0.6252  decode.d0.loss_mask: 0.9687  decode.d0.loss_dice: 0.6392  decode.d1.loss_cls: 0.1405  decode.d1.loss_mask: 1.0037  decode.d1.loss_dice: 0.6421  decode.d2.loss_cls: 0.1062  decode.d2.loss_mask: 0.9974  decode.d2.loss_dice: 0.6485  decode.d3.loss_cls: 0.0925  decode.d3.loss_mask: 1.0088  decode.d3.loss_dice: 0.6438  decode.d4.loss_cls: 0.1193  decode.d4.loss_mask: 1.0277  decode.d4.loss_dice: 0.6690  decode.d5.loss_cls: 0.0972  decode.d5.loss_mask: 1.0176  decode.d5.loss_dice: 0.6471  decode.d6.loss_cls: 0.1530  decode.d6.loss_mask: 1.0028  decode.d6.loss_dice: 0.6441  decode.d7.loss_cls: 0.1228  decode.d7.loss_mask: 1.0057  decode.d7.loss_dice: 0.6517  decode.d8.loss_cls: 0.1290  decode.d8.loss_mask: 1.0066  decode.d8.loss_dice: 0.6471
06/01 13:28:07 - mmengine - INFO - Iter(train) [155350/160000]  base_lr: 4.1400e-06 lr: 4.1400e-07  eta: 2:34:34  time: 0.6426  data_time: 0.0106  memory: 10503  grad_norm: 209.1388  loss: 15.0383  decode.loss_cls: 0.0796  decode.loss_mask: 0.8038  decode.loss_dice: 0.5737  decode.d0.loss_cls: 0.5396  decode.d0.loss_mask: 0.7872  decode.d0.loss_dice: 0.5444  decode.d1.loss_cls: 0.1214  decode.d1.loss_mask: 0.8081  decode.d1.loss_dice: 0.5732  decode.d2.loss_cls: 0.0846  decode.d2.loss_mask: 0.8017  decode.d2.loss_dice: 0.5700  decode.d3.loss_cls: 0.0873  decode.d3.loss_mask: 0.8064  decode.d3.loss_dice: 0.5586  decode.d4.loss_cls: 0.0865  decode.d4.loss_mask: 0.8073  decode.d4.loss_dice: 0.5733  decode.d5.loss_cls: 0.0967  decode.d5.loss_mask: 0.8024  decode.d5.loss_dice: 0.5570  decode.d6.loss_cls: 0.1000  decode.d6.loss_mask: 0.8058  decode.d6.loss_dice: 0.5542  decode.d7.loss_cls: 0.1018  decode.d7.loss_mask: 0.8097  decode.d7.loss_dice: 0.5554  decode.d8.loss_cls: 0.0811  decode.d8.loss_mask: 0.8037  decode.d8.loss_dice: 0.5640
06/01 13:28:39 - mmengine - INFO - Iter(train) [155400/160000]  base_lr: 4.0999e-06 lr: 4.0999e-07  eta: 2:32:24  time: 0.6424  data_time: 0.0107  memory: 10501  grad_norm: 370.4249  loss: 14.8145  decode.loss_cls: 0.0902  decode.loss_mask: 0.7714  decode.loss_dice: 0.5641  decode.d0.loss_cls: 0.5304  decode.d0.loss_mask: 0.7634  decode.d0.loss_dice: 0.5765  decode.d1.loss_cls: 0.1286  decode.d1.loss_mask: 0.7825  decode.d1.loss_dice: 0.5629  decode.d2.loss_cls: 0.1017  decode.d2.loss_mask: 0.7693  decode.d2.loss_dice: 0.5568  decode.d3.loss_cls: 0.0921  decode.d3.loss_mask: 0.7581  decode.d3.loss_dice: 0.5518  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 0.7928  decode.d4.loss_dice: 0.5753  decode.d5.loss_cls: 0.0817  decode.d5.loss_mask: 0.8010  decode.d5.loss_dice: 0.5704  decode.d6.loss_cls: 0.0959  decode.d6.loss_mask: 0.7579  decode.d6.loss_dice: 0.5515  decode.d7.loss_cls: 0.0903  decode.d7.loss_mask: 0.7750  decode.d7.loss_dice: 0.5767  decode.d8.loss_cls: 0.1040  decode.d8.loss_mask: 0.7889  decode.d8.loss_dice: 0.5737
06/01 13:29:11 - mmengine - INFO - Iter(train) [155450/160000]  base_lr: 4.0598e-06 lr: 4.0598e-07  eta: 2:30:16  time: 0.6427  data_time: 0.0107  memory: 10504  grad_norm: 465.9387  loss: 14.1491  decode.loss_cls: 0.0643  decode.loss_mask: 0.7698  decode.loss_dice: 0.5386  decode.d0.loss_cls: 0.4596  decode.d0.loss_mask: 0.7888  decode.d0.loss_dice: 0.5425  decode.d1.loss_cls: 0.0766  decode.d1.loss_mask: 0.7709  decode.d1.loss_dice: 0.5351  decode.d2.loss_cls: 0.0666  decode.d2.loss_mask: 0.7675  decode.d2.loss_dice: 0.5250  decode.d3.loss_cls: 0.0668  decode.d3.loss_mask: 0.7724  decode.d3.loss_dice: 0.5361  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.7722  decode.d4.loss_dice: 0.5320  decode.d5.loss_cls: 0.0691  decode.d5.loss_mask: 0.7820  decode.d5.loss_dice: 0.5340  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.7705  decode.d6.loss_dice: 0.5249  decode.d7.loss_cls: 0.0641  decode.d7.loss_mask: 0.7724  decode.d7.loss_dice: 0.5348  decode.d8.loss_cls: 0.0680  decode.d8.loss_mask: 0.7724  decode.d8.loss_dice: 0.5381
06/01 13:29:43 - mmengine - INFO - Iter(train) [155500/160000]  base_lr: 4.0196e-06 lr: 4.0196e-07  eta: 2:28:08  time: 0.6423  data_time: 0.0107  memory: 10500  grad_norm: 217.0056  loss: 15.7526  decode.loss_cls: 0.1220  decode.loss_mask: 0.8480  decode.loss_dice: 0.5516  decode.d0.loss_cls: 0.6830  decode.d0.loss_mask: 0.8467  decode.d0.loss_dice: 0.5491  decode.d1.loss_cls: 0.0857  decode.d1.loss_mask: 0.8564  decode.d1.loss_dice: 0.5707  decode.d2.loss_cls: 0.1322  decode.d2.loss_mask: 0.8563  decode.d2.loss_dice: 0.5495  decode.d3.loss_cls: 0.1327  decode.d3.loss_mask: 0.8481  decode.d3.loss_dice: 0.5271  decode.d4.loss_cls: 0.1210  decode.d4.loss_mask: 0.8483  decode.d4.loss_dice: 0.5448  decode.d5.loss_cls: 0.1105  decode.d5.loss_mask: 0.8506  decode.d5.loss_dice: 0.5482  decode.d6.loss_cls: 0.1174  decode.d6.loss_mask: 0.8513  decode.d6.loss_dice: 0.5554  decode.d7.loss_cls: 0.1222  decode.d7.loss_mask: 0.8515  decode.d7.loss_dice: 0.5437  decode.d8.loss_cls: 0.1339  decode.d8.loss_mask: 0.8453  decode.d8.loss_dice: 0.5492
06/01 13:30:15 - mmengine - INFO - Iter(train) [155550/160000]  base_lr: 3.9794e-06 lr: 3.9794e-07  eta: 2:26:01  time: 0.6428  data_time: 0.0107  memory: 10512  grad_norm: 816.6663  loss: 13.5648  decode.loss_cls: 0.0906  decode.loss_mask: 0.6839  decode.loss_dice: 0.5113  decode.d0.loss_cls: 0.5743  decode.d0.loss_mask: 0.6681  decode.d0.loss_dice: 0.5168  decode.d1.loss_cls: 0.0575  decode.d1.loss_mask: 0.7273  decode.d1.loss_dice: 0.5315  decode.d2.loss_cls: 0.0590  decode.d2.loss_mask: 0.7271  decode.d2.loss_dice: 0.5349  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.7220  decode.d3.loss_dice: 0.5323  decode.d4.loss_cls: 0.0595  decode.d4.loss_mask: 0.7304  decode.d4.loss_dice: 0.5337  decode.d5.loss_cls: 0.0587  decode.d5.loss_mask: 0.7318  decode.d5.loss_dice: 0.5344  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.7361  decode.d6.loss_dice: 0.5314  decode.d7.loss_cls: 0.0961  decode.d7.loss_mask: 0.6677  decode.d7.loss_dice: 0.5026  decode.d8.loss_cls: 0.0597  decode.d8.loss_mask: 0.7292  decode.d8.loss_dice: 0.5320
06/01 13:30:47 - mmengine - INFO - Iter(train) [155600/160000]  base_lr: 3.9391e-06 lr: 3.9391e-07  eta: 2:23:55  time: 0.6426  data_time: 0.0107  memory: 10492  grad_norm: 266.0320  loss: 13.2090  decode.loss_cls: 0.0315  decode.loss_mask: 0.7182  decode.loss_dice: 0.5073  decode.d0.loss_cls: 0.5280  decode.d0.loss_mask: 0.7094  decode.d0.loss_dice: 0.4975  decode.d1.loss_cls: 0.0758  decode.d1.loss_mask: 0.7234  decode.d1.loss_dice: 0.5100  decode.d2.loss_cls: 0.0625  decode.d2.loss_mask: 0.7313  decode.d2.loss_dice: 0.5108  decode.d3.loss_cls: 0.0307  decode.d3.loss_mask: 0.7218  decode.d3.loss_dice: 0.5023  decode.d4.loss_cls: 0.0313  decode.d4.loss_mask: 0.7257  decode.d4.loss_dice: 0.5170  decode.d5.loss_cls: 0.0226  decode.d5.loss_mask: 0.7366  decode.d5.loss_dice: 0.5191  decode.d6.loss_cls: 0.0236  decode.d6.loss_mask: 0.7314  decode.d6.loss_dice: 0.5175  decode.d7.loss_cls: 0.0268  decode.d7.loss_mask: 0.7254  decode.d7.loss_dice: 0.5134  decode.d8.loss_cls: 0.0301  decode.d8.loss_mask: 0.7206  decode.d8.loss_dice: 0.5074
06/01 13:31:20 - mmengine - INFO - Iter(train) [155650/160000]  base_lr: 3.8988e-06 lr: 3.8988e-07  eta: 2:21:50  time: 0.6437  data_time: 0.0107  memory: 10501  grad_norm: 482.3408  loss: 14.7119  decode.loss_cls: 0.0712  decode.loss_mask: 0.7400  decode.loss_dice: 0.6056  decode.d0.loss_cls: 0.5502  decode.d0.loss_mask: 0.7506  decode.d0.loss_dice: 0.5933  decode.d1.loss_cls: 0.1099  decode.d1.loss_mask: 0.7477  decode.d1.loss_dice: 0.6094  decode.d2.loss_cls: 0.0533  decode.d2.loss_mask: 0.7453  decode.d2.loss_dice: 0.6075  decode.d3.loss_cls: 0.0739  decode.d3.loss_mask: 0.7378  decode.d3.loss_dice: 0.5982  decode.d4.loss_cls: 0.0826  decode.d4.loss_mask: 0.7363  decode.d4.loss_dice: 0.6024  decode.d5.loss_cls: 0.1005  decode.d5.loss_mask: 0.7402  decode.d5.loss_dice: 0.5991  decode.d6.loss_cls: 0.0963  decode.d6.loss_mask: 0.7364  decode.d6.loss_dice: 0.5947  decode.d7.loss_cls: 0.0737  decode.d7.loss_mask: 0.7421  decode.d7.loss_dice: 0.6061  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 0.7482  decode.d8.loss_dice: 0.5998
06/01 13:31:57 - mmengine - INFO - Iter(train) [155700/160000]  base_lr: 3.8585e-06 lr: 3.8585e-07  eta: 2:19:48  time: 0.6436  data_time: 0.0107  memory: 10507  grad_norm: 541.2268  loss: 15.4495  decode.loss_cls: 0.1952  decode.loss_mask: 0.7475  decode.loss_dice: 0.5629  decode.d0.loss_cls: 0.5483  decode.d0.loss_mask: 0.7305  decode.d0.loss_dice: 0.5890  decode.d1.loss_cls: 0.1666  decode.d1.loss_mask: 0.7470  decode.d1.loss_dice: 0.5856  decode.d2.loss_cls: 0.1467  decode.d2.loss_mask: 0.8081  decode.d2.loss_dice: 0.6055  decode.d3.loss_cls: 0.1734  decode.d3.loss_mask: 0.7509  decode.d3.loss_dice: 0.5634  decode.d4.loss_cls: 0.1870  decode.d4.loss_mask: 0.7201  decode.d4.loss_dice: 0.5538  decode.d5.loss_cls: 0.1507  decode.d5.loss_mask: 0.7629  decode.d5.loss_dice: 0.6055  decode.d6.loss_cls: 0.1698  decode.d6.loss_mask: 0.7556  decode.d6.loss_dice: 0.5889  decode.d7.loss_cls: 0.1662  decode.d7.loss_mask: 0.7660  decode.d7.loss_dice: 0.5884  decode.d8.loss_cls: 0.1650  decode.d8.loss_mask: 0.7608  decode.d8.loss_dice: 0.5881
06/01 13:32:29 - mmengine - INFO - Iter(train) [155750/160000]  base_lr: 3.8181e-06 lr: 3.8181e-07  eta: 2:17:44  time: 0.6431  data_time: 0.0107  memory: 10499  grad_norm: 255.8480  loss: 12.4475  decode.loss_cls: 0.0282  decode.loss_mask: 0.7176  decode.loss_dice: 0.4592  decode.d0.loss_cls: 0.4262  decode.d0.loss_mask: 0.7142  decode.d0.loss_dice: 0.4517  decode.d1.loss_cls: 0.0302  decode.d1.loss_mask: 0.7140  decode.d1.loss_dice: 0.4643  decode.d2.loss_cls: 0.0294  decode.d2.loss_mask: 0.7104  decode.d2.loss_dice: 0.4566  decode.d3.loss_cls: 0.0334  decode.d3.loss_mask: 0.7118  decode.d3.loss_dice: 0.4553  decode.d4.loss_cls: 0.0385  decode.d4.loss_mask: 0.7072  decode.d4.loss_dice: 0.4529  decode.d5.loss_cls: 0.0472  decode.d5.loss_mask: 0.7144  decode.d5.loss_dice: 0.4470  decode.d6.loss_cls: 0.0575  decode.d6.loss_mask: 0.7177  decode.d6.loss_dice: 0.4490  decode.d7.loss_cls: 0.0317  decode.d7.loss_mask: 0.7152  decode.d7.loss_dice: 0.4630  decode.d8.loss_cls: 0.0261  decode.d8.loss_mask: 0.7187  decode.d8.loss_dice: 0.4588
06/01 13:33:05 - mmengine - INFO - Iter(train) [155800/160000]  base_lr: 3.7776e-06 lr: 3.7776e-07  eta: 2:15:43  time: 0.6445  data_time: 0.0107  memory: 10494  grad_norm: 263.8706  loss: 16.1790  decode.loss_cls: 0.0902  decode.loss_mask: 0.8697  decode.loss_dice: 0.6312  decode.d0.loss_cls: 0.4912  decode.d0.loss_mask: 0.8314  decode.d0.loss_dice: 0.6230  decode.d1.loss_cls: 0.0858  decode.d1.loss_mask: 0.8641  decode.d1.loss_dice: 0.6313  decode.d2.loss_cls: 0.0776  decode.d2.loss_mask: 0.8693  decode.d2.loss_dice: 0.6268  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.8662  decode.d3.loss_dice: 0.6331  decode.d4.loss_cls: 0.0932  decode.d4.loss_mask: 0.8642  decode.d4.loss_dice: 0.6265  decode.d5.loss_cls: 0.0788  decode.d5.loss_mask: 0.8585  decode.d5.loss_dice: 0.6237  decode.d6.loss_cls: 0.0861  decode.d6.loss_mask: 0.8706  decode.d6.loss_dice: 0.6357  decode.d7.loss_cls: 0.0936  decode.d7.loss_mask: 0.8607  decode.d7.loss_dice: 0.6286  decode.d8.loss_cls: 0.0731  decode.d8.loss_mask: 0.8810  decode.d8.loss_dice: 0.6349
06/01 13:33:37 - mmengine - INFO - Iter(train) [155850/160000]  base_lr: 3.7371e-06 lr: 3.7371e-07  eta: 2:13:41  time: 0.6430  data_time: 0.0107  memory: 10492  grad_norm: 847.5349  loss: 13.2997  decode.loss_cls: 0.0233  decode.loss_mask: 0.7821  decode.loss_dice: 0.4839  decode.d0.loss_cls: 0.3952  decode.d0.loss_mask: 0.7839  decode.d0.loss_dice: 0.4797  decode.d1.loss_cls: 0.0253  decode.d1.loss_mask: 0.7910  decode.d1.loss_dice: 0.4897  decode.d2.loss_cls: 0.0254  decode.d2.loss_mask: 0.7891  decode.d2.loss_dice: 0.4870  decode.d3.loss_cls: 0.0220  decode.d3.loss_mask: 0.7881  decode.d3.loss_dice: 0.4887  decode.d4.loss_cls: 0.0236  decode.d4.loss_mask: 0.7881  decode.d4.loss_dice: 0.4846  decode.d5.loss_cls: 0.0201  decode.d5.loss_mask: 0.7834  decode.d5.loss_dice: 0.4856  decode.d6.loss_cls: 0.0229  decode.d6.loss_mask: 0.7765  decode.d6.loss_dice: 0.4801  decode.d7.loss_cls: 0.0212  decode.d7.loss_mask: 0.7836  decode.d7.loss_dice: 0.4847  decode.d8.loss_cls: 0.0221  decode.d8.loss_mask: 0.7829  decode.d8.loss_dice: 0.4860
06/01 13:34:15 - mmengine - INFO - Iter(train) [155900/160000]  base_lr: 3.6966e-06 lr: 3.6966e-07  eta: 2:11:43  time: 0.6424  data_time: 0.0107  memory: 10496  grad_norm: 325.3027  loss: 13.1779  decode.loss_cls: 0.0807  decode.loss_mask: 0.7566  decode.loss_dice: 0.4594  decode.d0.loss_cls: 0.3789  decode.d0.loss_mask: 0.7610  decode.d0.loss_dice: 0.4579  decode.d1.loss_cls: 0.0659  decode.d1.loss_mask: 0.7512  decode.d1.loss_dice: 0.4551  decode.d2.loss_cls: 0.0799  decode.d2.loss_mask: 0.7563  decode.d2.loss_dice: 0.4607  decode.d3.loss_cls: 0.0689  decode.d3.loss_mask: 0.7581  decode.d3.loss_dice: 0.4584  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.7511  decode.d4.loss_dice: 0.4612  decode.d5.loss_cls: 0.0700  decode.d5.loss_mask: 0.7541  decode.d5.loss_dice: 0.4612  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.7527  decode.d6.loss_dice: 0.4557  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.7563  decode.d7.loss_dice: 0.4593  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.7636  decode.d8.loss_dice: 0.4824
06/01 13:34:47 - mmengine - INFO - Iter(train) [155950/160000]  base_lr: 3.6560e-06 lr: 3.6560e-07  eta: 2:09:43  time: 0.6433  data_time: 0.0108  memory: 10512  grad_norm: 339.0333  loss: 12.3017  decode.loss_cls: 0.0461  decode.loss_mask: 0.6706  decode.loss_dice: 0.4791  decode.d0.loss_cls: 0.4856  decode.d0.loss_mask: 0.5967  decode.d0.loss_dice: 0.4514  decode.d1.loss_cls: 0.0873  decode.d1.loss_mask: 0.6462  decode.d1.loss_dice: 0.4618  decode.d2.loss_cls: 0.0663  decode.d2.loss_mask: 0.6429  decode.d2.loss_dice: 0.4670  decode.d3.loss_cls: 0.0723  decode.d3.loss_mask: 0.6738  decode.d3.loss_dice: 0.4753  decode.d4.loss_cls: 0.0708  decode.d4.loss_mask: 0.6394  decode.d4.loss_dice: 0.4550  decode.d5.loss_cls: 0.0447  decode.d5.loss_mask: 0.6743  decode.d5.loss_dice: 0.4844  decode.d6.loss_cls: 0.0488  decode.d6.loss_mask: 0.6728  decode.d6.loss_dice: 0.4781  decode.d7.loss_cls: 0.0434  decode.d7.loss_mask: 0.6806  decode.d7.loss_dice: 0.4814  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.6736  decode.d8.loss_dice: 0.4796
06/01 13:35:20 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 13:35:20 - mmengine - INFO - Iter(train) [156000/160000]  base_lr: 3.6153e-06 lr: 3.6153e-07  eta: 2:07:43  time: 0.6426  data_time: 0.0107  memory: 10508  grad_norm: 213.5911  loss: 13.7546  decode.loss_cls: 0.1474  decode.loss_mask: 0.6948  decode.loss_dice: 0.4854  decode.d0.loss_cls: 0.5566  decode.d0.loss_mask: 0.7001  decode.d0.loss_dice: 0.5215  decode.d1.loss_cls: 0.1686  decode.d1.loss_mask: 0.6851  decode.d1.loss_dice: 0.4854  decode.d2.loss_cls: 0.1399  decode.d2.loss_mask: 0.6936  decode.d2.loss_dice: 0.4953  decode.d3.loss_cls: 0.1572  decode.d3.loss_mask: 0.6944  decode.d3.loss_dice: 0.4796  decode.d4.loss_cls: 0.1418  decode.d4.loss_mask: 0.6914  decode.d4.loss_dice: 0.4799  decode.d5.loss_cls: 0.1510  decode.d5.loss_mask: 0.6885  decode.d5.loss_dice: 0.5011  decode.d6.loss_cls: 0.1475  decode.d6.loss_mask: 0.6919  decode.d6.loss_dice: 0.5003  decode.d7.loss_cls: 0.1447  decode.d7.loss_mask: 0.6871  decode.d7.loss_dice: 0.5066  decode.d8.loss_cls: 0.1286  decode.d8.loss_mask: 0.6912  decode.d8.loss_dice: 0.4982
06/01 13:35:52 - mmengine - INFO - Iter(train) [156050/160000]  base_lr: 3.5746e-06 lr: 3.5746e-07  eta: 2:05:45  time: 0.6393  data_time: 0.0106  memory: 10509  grad_norm: 524.8287  loss: 15.2690  decode.loss_cls: 0.0789  decode.loss_mask: 0.7881  decode.loss_dice: 0.6058  decode.d0.loss_cls: 0.5709  decode.d0.loss_mask: 0.8115  decode.d0.loss_dice: 0.6234  decode.d1.loss_cls: 0.0953  decode.d1.loss_mask: 0.7808  decode.d1.loss_dice: 0.6096  decode.d2.loss_cls: 0.0853  decode.d2.loss_mask: 0.7770  decode.d2.loss_dice: 0.6132  decode.d3.loss_cls: 0.0921  decode.d3.loss_mask: 0.7764  decode.d3.loss_dice: 0.6039  decode.d4.loss_cls: 0.0727  decode.d4.loss_mask: 0.7822  decode.d4.loss_dice: 0.6047  decode.d5.loss_cls: 0.0928  decode.d5.loss_mask: 0.7708  decode.d5.loss_dice: 0.6019  decode.d6.loss_cls: 0.1029  decode.d6.loss_mask: 0.7752  decode.d6.loss_dice: 0.6063  decode.d7.loss_cls: 0.0925  decode.d7.loss_mask: 0.7838  decode.d7.loss_dice: 0.6076  decode.d8.loss_cls: 0.0682  decode.d8.loss_mask: 0.7760  decode.d8.loss_dice: 0.6191
06/01 13:36:25 - mmengine - INFO - Iter(train) [156100/160000]  base_lr: 3.5339e-06 lr: 3.5339e-07  eta: 2:03:47  time: 0.6436  data_time: 0.0107  memory: 10496  grad_norm: 390.2453  loss: 14.7292  decode.loss_cls: 0.0311  decode.loss_mask: 0.8562  decode.loss_dice: 0.5503  decode.d0.loss_cls: 0.4202  decode.d0.loss_mask: 0.8542  decode.d0.loss_dice: 0.5679  decode.d1.loss_cls: 0.0300  decode.d1.loss_mask: 0.8594  decode.d1.loss_dice: 0.5487  decode.d2.loss_cls: 0.0301  decode.d2.loss_mask: 0.8482  decode.d2.loss_dice: 0.5513  decode.d3.loss_cls: 0.0357  decode.d3.loss_mask: 0.8502  decode.d3.loss_dice: 0.5508  decode.d4.loss_cls: 0.0323  decode.d4.loss_mask: 0.8486  decode.d4.loss_dice: 0.5469  decode.d5.loss_cls: 0.0299  decode.d5.loss_mask: 0.8501  decode.d5.loss_dice: 0.5452  decode.d6.loss_cls: 0.0286  decode.d6.loss_mask: 0.8502  decode.d6.loss_dice: 0.5478  decode.d7.loss_cls: 0.0373  decode.d7.loss_mask: 0.8493  decode.d7.loss_dice: 0.5542  decode.d8.loss_cls: 0.0326  decode.d8.loss_mask: 0.8427  decode.d8.loss_dice: 0.5490
06/01 13:36:57 - mmengine - INFO - Iter(train) [156150/160000]  base_lr: 3.4931e-06 lr: 3.4931e-07  eta: 2:01:50  time: 0.6420  data_time: 0.0106  memory: 10500  grad_norm: 266.2324  loss: 14.6071  decode.loss_cls: 0.0596  decode.loss_mask: 0.8599  decode.loss_dice: 0.5117  decode.d0.loss_cls: 0.4635  decode.d0.loss_mask: 0.8132  decode.d0.loss_dice: 0.4851  decode.d1.loss_cls: 0.0678  decode.d1.loss_mask: 0.8571  decode.d1.loss_dice: 0.5070  decode.d2.loss_cls: 0.0636  decode.d2.loss_mask: 0.8509  decode.d2.loss_dice: 0.5051  decode.d3.loss_cls: 0.0618  decode.d3.loss_mask: 0.8560  decode.d3.loss_dice: 0.5035  decode.d4.loss_cls: 0.0581  decode.d4.loss_mask: 0.8499  decode.d4.loss_dice: 0.4997  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 0.8582  decode.d5.loss_dice: 0.5030  decode.d6.loss_cls: 0.0713  decode.d6.loss_mask: 0.8612  decode.d6.loss_dice: 0.5101  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.8584  decode.d7.loss_dice: 0.5143  decode.d8.loss_cls: 0.0601  decode.d8.loss_mask: 0.8628  decode.d8.loss_dice: 0.5107
06/01 13:37:29 - mmengine - INFO - Iter(train) [156200/160000]  base_lr: 3.4522e-06 lr: 3.4522e-07  eta: 1:59:54  time: 0.6522  data_time: 0.0107  memory: 10492  grad_norm: 547.1353  loss: 15.7882  decode.loss_cls: 0.1255  decode.loss_mask: 0.8152  decode.loss_dice: 0.5978  decode.d0.loss_cls: 0.5735  decode.d0.loss_mask: 0.8193  decode.d0.loss_dice: 0.5990  decode.d1.loss_cls: 0.1476  decode.d1.loss_mask: 0.8053  decode.d1.loss_dice: 0.6054  decode.d2.loss_cls: 0.1097  decode.d2.loss_mask: 0.8166  decode.d2.loss_dice: 0.5979  decode.d3.loss_cls: 0.1193  decode.d3.loss_mask: 0.8042  decode.d3.loss_dice: 0.6026  decode.d4.loss_cls: 0.1303  decode.d4.loss_mask: 0.8037  decode.d4.loss_dice: 0.6024  decode.d5.loss_cls: 0.1188  decode.d5.loss_mask: 0.8110  decode.d5.loss_dice: 0.6023  decode.d6.loss_cls: 0.1221  decode.d6.loss_mask: 0.8058  decode.d6.loss_dice: 0.6003  decode.d7.loss_cls: 0.1182  decode.d7.loss_mask: 0.8039  decode.d7.loss_dice: 0.5875  decode.d8.loss_cls: 0.1310  decode.d8.loss_mask: 0.8052  decode.d8.loss_dice: 0.6070
06/01 13:38:01 - mmengine - INFO - Iter(train) [156250/160000]  base_lr: 3.4113e-06 lr: 3.4113e-07  eta: 1:57:59  time: 0.6438  data_time: 0.0107  memory: 10512  grad_norm: 172.6950  loss: 10.2715  decode.loss_cls: 0.0532  decode.loss_mask: 0.5421  decode.loss_dice: 0.3895  decode.d0.loss_cls: 0.4800  decode.d0.loss_mask: 0.5482  decode.d0.loss_dice: 0.3968  decode.d1.loss_cls: 0.0554  decode.d1.loss_mask: 0.5517  decode.d1.loss_dice: 0.4030  decode.d2.loss_cls: 0.0564  decode.d2.loss_mask: 0.5415  decode.d2.loss_dice: 0.3884  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 0.5510  decode.d3.loss_dice: 0.3934  decode.d4.loss_cls: 0.0366  decode.d4.loss_mask: 0.5468  decode.d4.loss_dice: 0.3914  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.5408  decode.d5.loss_dice: 0.3876  decode.d6.loss_cls: 0.0406  decode.d6.loss_mask: 0.5413  decode.d6.loss_dice: 0.3908  decode.d7.loss_cls: 0.0390  decode.d7.loss_mask: 0.5479  decode.d7.loss_dice: 0.3954  decode.d8.loss_cls: 0.0523  decode.d8.loss_mask: 0.5458  decode.d8.loss_dice: 0.3902
06/01 13:38:34 - mmengine - INFO - Iter(train) [156300/160000]  base_lr: 3.3704e-06 lr: 3.3704e-07  eta: 1:56:04  time: 0.6438  data_time: 0.0106  memory: 10504  grad_norm: 560.8734  loss: 17.1732  decode.loss_cls: 0.0486  decode.loss_mask: 0.9553  decode.loss_dice: 0.6632  decode.d0.loss_cls: 0.5336  decode.d0.loss_mask: 0.9101  decode.d0.loss_dice: 0.6685  decode.d1.loss_cls: 0.0615  decode.d1.loss_mask: 0.9544  decode.d1.loss_dice: 0.6725  decode.d2.loss_cls: 0.0433  decode.d2.loss_mask: 0.9539  decode.d2.loss_dice: 0.6707  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.9548  decode.d3.loss_dice: 0.6635  decode.d4.loss_cls: 0.0532  decode.d4.loss_mask: 0.9554  decode.d4.loss_dice: 0.6696  decode.d5.loss_cls: 0.0459  decode.d5.loss_mask: 0.9550  decode.d5.loss_dice: 0.6668  decode.d6.loss_cls: 0.0483  decode.d6.loss_mask: 0.9520  decode.d6.loss_dice: 0.6650  decode.d7.loss_cls: 0.0504  decode.d7.loss_mask: 0.9566  decode.d7.loss_dice: 0.6724  decode.d8.loss_cls: 0.0499  decode.d8.loss_mask: 0.9542  decode.d8.loss_dice: 0.6697
06/01 13:39:06 - mmengine - INFO - Iter(train) [156350/160000]  base_lr: 3.3293e-06 lr: 3.3293e-07  eta: 1:54:10  time: 0.6438  data_time: 0.0107  memory: 10496  grad_norm: 293.7540  loss: 13.6886  decode.loss_cls: 0.0122  decode.loss_mask: 0.7662  decode.loss_dice: 0.5546  decode.d0.loss_cls: 0.4306  decode.d0.loss_mask: 0.7587  decode.d0.loss_dice: 0.5521  decode.d1.loss_cls: 0.0436  decode.d1.loss_mask: 0.7574  decode.d1.loss_dice: 0.5323  decode.d2.loss_cls: 0.0317  decode.d2.loss_mask: 0.7581  decode.d2.loss_dice: 0.5357  decode.d3.loss_cls: 0.0268  decode.d3.loss_mask: 0.7610  decode.d3.loss_dice: 0.5397  decode.d4.loss_cls: 0.0263  decode.d4.loss_mask: 0.7551  decode.d4.loss_dice: 0.5387  decode.d5.loss_cls: 0.0233  decode.d5.loss_mask: 0.7603  decode.d5.loss_dice: 0.5420  decode.d6.loss_cls: 0.0295  decode.d6.loss_mask: 0.7590  decode.d6.loss_dice: 0.5461  decode.d7.loss_cls: 0.0158  decode.d7.loss_mask: 0.7620  decode.d7.loss_dice: 0.5483  decode.d8.loss_cls: 0.0131  decode.d8.loss_mask: 0.7595  decode.d8.loss_dice: 0.5490
06/01 13:39:38 - mmengine - INFO - Iter(train) [156400/160000]  base_lr: 3.2883e-06 lr: 3.2883e-07  eta: 1:52:16  time: 0.6430  data_time: 0.0107  memory: 10495  grad_norm: 450.6201  loss: 14.6193  decode.loss_cls: 0.0801  decode.loss_mask: 0.7777  decode.loss_dice: 0.5456  decode.d0.loss_cls: 0.4844  decode.d0.loss_mask: 0.7606  decode.d0.loss_dice: 0.5748  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.8005  decode.d1.loss_dice: 0.5678  decode.d2.loss_cls: 0.0905  decode.d2.loss_mask: 0.7942  decode.d2.loss_dice: 0.5591  decode.d3.loss_cls: 0.0634  decode.d3.loss_mask: 0.7873  decode.d3.loss_dice: 0.5619  decode.d4.loss_cls: 0.0557  decode.d4.loss_mask: 0.8101  decode.d4.loss_dice: 0.5863  decode.d5.loss_cls: 0.0645  decode.d5.loss_mask: 0.7837  decode.d5.loss_dice: 0.5510  decode.d6.loss_cls: 0.0904  decode.d6.loss_mask: 0.7791  decode.d6.loss_dice: 0.5489  decode.d7.loss_cls: 0.0898  decode.d7.loss_mask: 0.7774  decode.d7.loss_dice: 0.5463  decode.d8.loss_cls: 0.0757  decode.d8.loss_mask: 0.7914  decode.d8.loss_dice: 0.5521
06/01 13:40:10 - mmengine - INFO - Iter(train) [156450/160000]  base_lr: 3.2471e-06 lr: 3.2471e-07  eta: 1:50:24  time: 0.6423  data_time: 0.0107  memory: 10492  grad_norm: 289.8476  loss: 12.8682  decode.loss_cls: 0.0544  decode.loss_mask: 0.7270  decode.loss_dice: 0.4703  decode.d0.loss_cls: 0.4237  decode.d0.loss_mask: 0.7307  decode.d0.loss_dice: 0.4595  decode.d1.loss_cls: 0.0744  decode.d1.loss_mask: 0.7215  decode.d1.loss_dice: 0.4625  decode.d2.loss_cls: 0.0788  decode.d2.loss_mask: 0.7125  decode.d2.loss_dice: 0.4562  decode.d3.loss_cls: 0.0781  decode.d3.loss_mask: 0.7182  decode.d3.loss_dice: 0.4609  decode.d4.loss_cls: 0.0803  decode.d4.loss_mask: 0.7176  decode.d4.loss_dice: 0.4523  decode.d5.loss_cls: 0.0620  decode.d5.loss_mask: 0.7199  decode.d5.loss_dice: 0.4610  decode.d6.loss_cls: 0.0529  decode.d6.loss_mask: 0.7136  decode.d6.loss_dice: 0.4556  decode.d7.loss_cls: 0.0749  decode.d7.loss_mask: 0.7176  decode.d7.loss_dice: 0.4638  decode.d8.loss_cls: 0.0862  decode.d8.loss_mask: 0.7211  decode.d8.loss_dice: 0.4605
06/01 13:40:42 - mmengine - INFO - Iter(train) [156500/160000]  base_lr: 3.2059e-06 lr: 3.2059e-07  eta: 1:48:32  time: 0.6471  data_time: 0.0122  memory: 10500  grad_norm: 786.8941  loss: 13.4140  decode.loss_cls: 0.0684  decode.loss_mask: 0.7275  decode.loss_dice: 0.5221  decode.d0.loss_cls: 0.4150  decode.d0.loss_mask: 0.7084  decode.d0.loss_dice: 0.5324  decode.d1.loss_cls: 0.0775  decode.d1.loss_mask: 0.7209  decode.d1.loss_dice: 0.5161  decode.d2.loss_cls: 0.0795  decode.d2.loss_mask: 0.7217  decode.d2.loss_dice: 0.5217  decode.d3.loss_cls: 0.0723  decode.d3.loss_mask: 0.7165  decode.d3.loss_dice: 0.5075  decode.d4.loss_cls: 0.0630  decode.d4.loss_mask: 0.7172  decode.d4.loss_dice: 0.5145  decode.d5.loss_cls: 0.0799  decode.d5.loss_mask: 0.7125  decode.d5.loss_dice: 0.5030  decode.d6.loss_cls: 0.0672  decode.d6.loss_mask: 0.7284  decode.d6.loss_dice: 0.5309  decode.d7.loss_cls: 0.0608  decode.d7.loss_mask: 0.7146  decode.d7.loss_dice: 0.5281  decode.d8.loss_cls: 0.0531  decode.d8.loss_mask: 0.7169  decode.d8.loss_dice: 0.5163
06/01 13:41:15 - mmengine - INFO - Iter(train) [156550/160000]  base_lr: 3.1647e-06 lr: 3.1647e-07  eta: 1:46:41  time: 0.6440  data_time: 0.0106  memory: 10499  grad_norm: 451.2248  loss: 15.6451  decode.loss_cls: 0.0703  decode.loss_mask: 0.9023  decode.loss_dice: 0.5966  decode.d0.loss_cls: 0.5156  decode.d0.loss_mask: 0.8586  decode.d0.loss_dice: 0.5690  decode.d1.loss_cls: 0.1174  decode.d1.loss_mask: 0.8628  decode.d1.loss_dice: 0.5702  decode.d2.loss_cls: 0.1191  decode.d2.loss_mask: 0.8406  decode.d2.loss_dice: 0.5650  decode.d3.loss_cls: 0.0794  decode.d3.loss_mask: 0.8512  decode.d3.loss_dice: 0.5569  decode.d4.loss_cls: 0.1058  decode.d4.loss_mask: 0.8468  decode.d4.loss_dice: 0.5561  decode.d5.loss_cls: 0.0832  decode.d5.loss_mask: 0.8529  decode.d5.loss_dice: 0.5560  decode.d6.loss_cls: 0.1317  decode.d6.loss_mask: 0.8273  decode.d6.loss_dice: 0.5630  decode.d7.loss_cls: 0.0731  decode.d7.loss_mask: 0.8925  decode.d7.loss_dice: 0.5590  decode.d8.loss_cls: 0.0696  decode.d8.loss_mask: 0.8934  decode.d8.loss_dice: 0.5596
06/01 13:41:47 - mmengine - INFO - Iter(train) [156600/160000]  base_lr: 3.1234e-06 lr: 3.1234e-07  eta: 1:44:50  time: 0.6432  data_time: 0.0107  memory: 10508  grad_norm: 303.3130  loss: 13.2279  decode.loss_cls: 0.0222  decode.loss_mask: 0.7162  decode.loss_dice: 0.5257  decode.d0.loss_cls: 0.4940  decode.d0.loss_mask: 0.7114  decode.d0.loss_dice: 0.5294  decode.d1.loss_cls: 0.0346  decode.d1.loss_mask: 0.7209  decode.d1.loss_dice: 0.5253  decode.d2.loss_cls: 0.0475  decode.d2.loss_mask: 0.7220  decode.d2.loss_dice: 0.5149  decode.d3.loss_cls: 0.0296  decode.d3.loss_mask: 0.7251  decode.d3.loss_dice: 0.5308  decode.d4.loss_cls: 0.0261  decode.d4.loss_mask: 0.7222  decode.d4.loss_dice: 0.5327  decode.d5.loss_cls: 0.0222  decode.d5.loss_mask: 0.7189  decode.d5.loss_dice: 0.5269  decode.d6.loss_cls: 0.0283  decode.d6.loss_mask: 0.7175  decode.d6.loss_dice: 0.5273  decode.d7.loss_cls: 0.0330  decode.d7.loss_mask: 0.7179  decode.d7.loss_dice: 0.5300  decode.d8.loss_cls: 0.0340  decode.d8.loss_mask: 0.7177  decode.d8.loss_dice: 0.5234
06/01 13:42:19 - mmengine - INFO - Iter(train) [156650/160000]  base_lr: 3.0820e-06 lr: 3.0820e-07  eta: 1:43:00  time: 0.6424  data_time: 0.0107  memory: 10500  grad_norm: 212.6019  loss: 15.4823  decode.loss_cls: 0.0785  decode.loss_mask: 0.8437  decode.loss_dice: 0.5697  decode.d0.loss_cls: 0.4977  decode.d0.loss_mask: 0.8254  decode.d0.loss_dice: 0.5746  decode.d1.loss_cls: 0.1010  decode.d1.loss_mask: 0.8443  decode.d1.loss_dice: 0.5779  decode.d2.loss_cls: 0.0949  decode.d2.loss_mask: 0.8414  decode.d2.loss_dice: 0.5744  decode.d3.loss_cls: 0.0864  decode.d3.loss_mask: 0.8399  decode.d3.loss_dice: 0.5916  decode.d4.loss_cls: 0.0710  decode.d4.loss_mask: 0.8424  decode.d4.loss_dice: 0.5838  decode.d5.loss_cls: 0.0818  decode.d5.loss_mask: 0.8497  decode.d5.loss_dice: 0.5851  decode.d6.loss_cls: 0.0795  decode.d6.loss_mask: 0.8431  decode.d6.loss_dice: 0.5830  decode.d7.loss_cls: 0.0933  decode.d7.loss_mask: 0.8492  decode.d7.loss_dice: 0.5799  decode.d8.loss_cls: 0.0761  decode.d8.loss_mask: 0.8443  decode.d8.loss_dice: 0.5786
06/01 13:42:51 - mmengine - INFO - Iter(train) [156700/160000]  base_lr: 3.0406e-06 lr: 3.0406e-07  eta: 1:41:11  time: 0.6435  data_time: 0.0107  memory: 10499  grad_norm: 291.6451  loss: 13.3615  decode.loss_cls: 0.0487  decode.loss_mask: 0.7602  decode.loss_dice: 0.4912  decode.d0.loss_cls: 0.4577  decode.d0.loss_mask: 0.7577  decode.d0.loss_dice: 0.4806  decode.d1.loss_cls: 0.0443  decode.d1.loss_mask: 0.7501  decode.d1.loss_dice: 0.4883  decode.d2.loss_cls: 0.0531  decode.d2.loss_mask: 0.7546  decode.d2.loss_dice: 0.4868  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.7565  decode.d3.loss_dice: 0.4873  decode.d4.loss_cls: 0.0823  decode.d4.loss_mask: 0.7526  decode.d4.loss_dice: 0.4820  decode.d5.loss_cls: 0.0567  decode.d5.loss_mask: 0.7531  decode.d5.loss_dice: 0.4844  decode.d6.loss_cls: 0.0569  decode.d6.loss_mask: 0.7520  decode.d6.loss_dice: 0.4872  decode.d7.loss_cls: 0.0518  decode.d7.loss_mask: 0.7589  decode.d7.loss_dice: 0.4882  decode.d8.loss_cls: 0.0478  decode.d8.loss_mask: 0.7560  decode.d8.loss_dice: 0.4854
06/01 13:43:24 - mmengine - INFO - Iter(train) [156750/160000]  base_lr: 2.9991e-06 lr: 2.9991e-07  eta: 1:39:23  time: 0.6431  data_time: 0.0107  memory: 10503  grad_norm: 267.5473  loss: 14.4095  decode.loss_cls: 0.0742  decode.loss_mask: 0.7956  decode.loss_dice: 0.5189  decode.d0.loss_cls: 0.5608  decode.d0.loss_mask: 0.7754  decode.d0.loss_dice: 0.5102  decode.d1.loss_cls: 0.0896  decode.d1.loss_mask: 0.7952  decode.d1.loss_dice: 0.5209  decode.d2.loss_cls: 0.0783  decode.d2.loss_mask: 0.7868  decode.d2.loss_dice: 0.5282  decode.d3.loss_cls: 0.0825  decode.d3.loss_mask: 0.7930  decode.d3.loss_dice: 0.5252  decode.d4.loss_cls: 0.0734  decode.d4.loss_mask: 0.7902  decode.d4.loss_dice: 0.5172  decode.d5.loss_cls: 0.0865  decode.d5.loss_mask: 0.7845  decode.d5.loss_dice: 0.5204  decode.d6.loss_cls: 0.0832  decode.d6.loss_mask: 0.8040  decode.d6.loss_dice: 0.5233  decode.d7.loss_cls: 0.0742  decode.d7.loss_mask: 0.8002  decode.d7.loss_dice: 0.5206  decode.d8.loss_cls: 0.0754  decode.d8.loss_mask: 0.7945  decode.d8.loss_dice: 0.5273
06/01 13:43:56 - mmengine - INFO - Iter(train) [156800/160000]  base_lr: 2.9575e-06 lr: 2.9575e-07  eta: 1:37:35  time: 0.6436  data_time: 0.0107  memory: 10498  grad_norm: 440.9539  loss: 15.0124  decode.loss_cls: 0.0870  decode.loss_mask: 0.7628  decode.loss_dice: 0.6013  decode.d0.loss_cls: 0.6409  decode.d0.loss_mask: 0.7084  decode.d0.loss_dice: 0.5764  decode.d1.loss_cls: 0.0539  decode.d1.loss_mask: 0.7641  decode.d1.loss_dice: 0.6185  decode.d2.loss_cls: 0.0660  decode.d2.loss_mask: 0.7683  decode.d2.loss_dice: 0.6154  decode.d3.loss_cls: 0.0926  decode.d3.loss_mask: 0.7495  decode.d3.loss_dice: 0.5749  decode.d4.loss_cls: 0.0971  decode.d4.loss_mask: 0.7598  decode.d4.loss_dice: 0.6012  decode.d5.loss_cls: 0.0355  decode.d5.loss_mask: 0.7932  decode.d5.loss_dice: 0.6387  decode.d6.loss_cls: 0.0669  decode.d6.loss_mask: 0.7710  decode.d6.loss_dice: 0.6235  decode.d7.loss_cls: 0.0731  decode.d7.loss_mask: 0.7749  decode.d7.loss_dice: 0.6303  decode.d8.loss_cls: 0.0660  decode.d8.loss_mask: 0.7780  decode.d8.loss_dice: 0.6233
06/01 13:44:28 - mmengine - INFO - Iter(train) [156850/160000]  base_lr: 2.9159e-06 lr: 2.9159e-07  eta: 1:35:47  time: 0.6435  data_time: 0.0106  memory: 10492  grad_norm: 423.8183  loss: 14.4044  decode.loss_cls: 0.1449  decode.loss_mask: 0.7357  decode.loss_dice: 0.5167  decode.d0.loss_cls: 0.5891  decode.d0.loss_mask: 0.7048  decode.d0.loss_dice: 0.5273  decode.d1.loss_cls: 0.1197  decode.d1.loss_mask: 0.7771  decode.d1.loss_dice: 0.5575  decode.d2.loss_cls: 0.1419  decode.d2.loss_mask: 0.7007  decode.d2.loss_dice: 0.5147  decode.d3.loss_cls: 0.1292  decode.d3.loss_mask: 0.7258  decode.d3.loss_dice: 0.5432  decode.d4.loss_cls: 0.1451  decode.d4.loss_mask: 0.7107  decode.d4.loss_dice: 0.5119  decode.d5.loss_cls: 0.1272  decode.d5.loss_mask: 0.7192  decode.d5.loss_dice: 0.5278  decode.d6.loss_cls: 0.1683  decode.d6.loss_mask: 0.7264  decode.d6.loss_dice: 0.5204  decode.d7.loss_cls: 0.1499  decode.d7.loss_mask: 0.7214  decode.d7.loss_dice: 0.5353  decode.d8.loss_cls: 0.1450  decode.d8.loss_mask: 0.7348  decode.d8.loss_dice: 0.5328
06/01 13:45:00 - mmengine - INFO - Iter(train) [156900/160000]  base_lr: 2.8742e-06 lr: 2.8742e-07  eta: 1:34:01  time: 0.6430  data_time: 0.0107  memory: 10504  grad_norm: 758.9612  loss: 16.4382  decode.loss_cls: 0.0917  decode.loss_mask: 0.9451  decode.loss_dice: 0.5617  decode.d0.loss_cls: 0.5285  decode.d0.loss_mask: 0.9122  decode.d0.loss_dice: 0.5571  decode.d1.loss_cls: 0.0989  decode.d1.loss_mask: 0.9532  decode.d1.loss_dice: 0.5688  decode.d2.loss_cls: 0.0893  decode.d2.loss_mask: 0.9524  decode.d2.loss_dice: 0.5710  decode.d3.loss_cls: 0.0915  decode.d3.loss_mask: 0.9481  decode.d3.loss_dice: 0.5669  decode.d4.loss_cls: 0.0867  decode.d4.loss_mask: 0.9532  decode.d4.loss_dice: 0.5651  decode.d5.loss_cls: 0.0892  decode.d5.loss_mask: 0.9448  decode.d5.loss_dice: 0.5617  decode.d6.loss_cls: 0.0882  decode.d6.loss_mask: 0.9389  decode.d6.loss_dice: 0.5612  decode.d7.loss_cls: 0.0844  decode.d7.loss_mask: 0.9537  decode.d7.loss_dice: 0.5642  decode.d8.loss_cls: 0.0985  decode.d8.loss_mask: 0.9458  decode.d8.loss_dice: 0.5663
06/01 13:45:32 - mmengine - INFO - Iter(train) [156950/160000]  base_lr: 2.8325e-06 lr: 2.8325e-07  eta: 1:32:15  time: 0.6446  data_time: 0.0107  memory: 10503  grad_norm: 1780.9220  loss: 14.6835  decode.loss_cls: 0.0598  decode.loss_mask: 0.7933  decode.loss_dice: 0.5670  decode.d0.loss_cls: 0.4917  decode.d0.loss_mask: 0.7817  decode.d0.loss_dice: 0.5547  decode.d1.loss_cls: 0.0872  decode.d1.loss_mask: 0.8051  decode.d1.loss_dice: 0.5614  decode.d2.loss_cls: 0.0611  decode.d2.loss_mask: 0.8047  decode.d2.loss_dice: 0.5575  decode.d3.loss_cls: 0.0609  decode.d3.loss_mask: 0.8002  decode.d3.loss_dice: 0.5665  decode.d4.loss_cls: 0.0612  decode.d4.loss_mask: 0.7963  decode.d4.loss_dice: 0.5646  decode.d5.loss_cls: 0.0543  decode.d5.loss_mask: 0.7952  decode.d5.loss_dice: 0.5669  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 0.7967  decode.d6.loss_dice: 0.5698  decode.d7.loss_cls: 0.0615  decode.d7.loss_mask: 0.8062  decode.d7.loss_dice: 0.5672  decode.d8.loss_cls: 0.0526  decode.d8.loss_mask: 0.8000  decode.d8.loss_dice: 0.5738
06/01 13:46:05 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 13:46:05 - mmengine - INFO - Iter(train) [157000/160000]  base_lr: 2.7906e-06 lr: 2.7906e-07  eta: 1:30:30  time: 0.6444  data_time: 0.0107  memory: 10492  grad_norm: 284.5199  loss: 13.1207  decode.loss_cls: 0.0368  decode.loss_mask: 0.7016  decode.loss_dice: 0.5208  decode.d0.loss_cls: 0.4676  decode.d0.loss_mask: 0.7164  decode.d0.loss_dice: 0.5221  decode.d1.loss_cls: 0.0458  decode.d1.loss_mask: 0.7068  decode.d1.loss_dice: 0.5191  decode.d2.loss_cls: 0.0456  decode.d2.loss_mask: 0.7014  decode.d2.loss_dice: 0.5097  decode.d3.loss_cls: 0.0456  decode.d3.loss_mask: 0.7028  decode.d3.loss_dice: 0.5312  decode.d4.loss_cls: 0.0440  decode.d4.loss_mask: 0.7053  decode.d4.loss_dice: 0.5187  decode.d5.loss_cls: 0.0374  decode.d5.loss_mask: 0.7044  decode.d5.loss_dice: 0.5244  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 0.7041  decode.d6.loss_dice: 0.5124  decode.d7.loss_cls: 0.0476  decode.d7.loss_mask: 0.7048  decode.d7.loss_dice: 0.5185  decode.d8.loss_cls: 0.0450  decode.d8.loss_mask: 0.7091  decode.d8.loss_dice: 0.5202
06/01 13:46:37 - mmengine - INFO - Iter(train) [157050/160000]  base_lr: 2.7487e-06 lr: 2.7487e-07  eta: 1:28:45  time: 0.6461  data_time: 0.0109  memory: 10508  grad_norm: 281.8498  loss: 14.3999  decode.loss_cls: 0.0683  decode.loss_mask: 0.8012  decode.loss_dice: 0.5268  decode.d0.loss_cls: 0.4946  decode.d0.loss_mask: 0.8039  decode.d0.loss_dice: 0.5488  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.7939  decode.d1.loss_dice: 0.5271  decode.d2.loss_cls: 0.0636  decode.d2.loss_mask: 0.8000  decode.d2.loss_dice: 0.5214  decode.d3.loss_cls: 0.0595  decode.d3.loss_mask: 0.8278  decode.d3.loss_dice: 0.5232  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.8045  decode.d4.loss_dice: 0.5296  decode.d5.loss_cls: 0.0673  decode.d5.loss_mask: 0.8057  decode.d5.loss_dice: 0.5132  decode.d6.loss_cls: 0.0613  decode.d6.loss_mask: 0.7978  decode.d6.loss_dice: 0.5363  decode.d7.loss_cls: 0.0573  decode.d7.loss_mask: 0.8035  decode.d7.loss_dice: 0.5240  decode.d8.loss_cls: 0.0694  decode.d8.loss_mask: 0.8066  decode.d8.loss_dice: 0.5193
06/01 13:47:09 - mmengine - INFO - Iter(train) [157100/160000]  base_lr: 2.7068e-06 lr: 2.7068e-07  eta: 1:27:01  time: 0.6434  data_time: 0.0106  memory: 10498  grad_norm: 683.9421  loss: 16.6814  decode.loss_cls: 0.1077  decode.loss_mask: 0.9410  decode.loss_dice: 0.6004  decode.d0.loss_cls: 0.6105  decode.d0.loss_mask: 0.9204  decode.d0.loss_dice: 0.5750  decode.d1.loss_cls: 0.1023  decode.d1.loss_mask: 0.9594  decode.d1.loss_dice: 0.5877  decode.d2.loss_cls: 0.0767  decode.d2.loss_mask: 0.9448  decode.d2.loss_dice: 0.5777  decode.d3.loss_cls: 0.0917  decode.d3.loss_mask: 0.9497  decode.d3.loss_dice: 0.5819  decode.d4.loss_cls: 0.0934  decode.d4.loss_mask: 0.9345  decode.d4.loss_dice: 0.5813  decode.d5.loss_cls: 0.0876  decode.d5.loss_mask: 0.9323  decode.d5.loss_dice: 0.5813  decode.d6.loss_cls: 0.1163  decode.d6.loss_mask: 0.9042  decode.d6.loss_dice: 0.5744  decode.d7.loss_cls: 0.0971  decode.d7.loss_mask: 0.9416  decode.d7.loss_dice: 0.5795  decode.d8.loss_cls: 0.0979  decode.d8.loss_mask: 0.9407  decode.d8.loss_dice: 0.5926
06/01 13:47:42 - mmengine - INFO - Iter(train) [157150/160000]  base_lr: 2.6647e-06 lr: 2.6647e-07  eta: 1:25:17  time: 0.6439  data_time: 0.0107  memory: 10501  grad_norm: 373.6261  loss: 17.2577  decode.loss_cls: 0.1402  decode.loss_mask: 0.9138  decode.loss_dice: 0.6484  decode.d0.loss_cls: 0.5061  decode.d0.loss_mask: 0.9112  decode.d0.loss_dice: 0.6454  decode.d1.loss_cls: 0.1246  decode.d1.loss_mask: 0.9163  decode.d1.loss_dice: 0.6537  decode.d2.loss_cls: 0.1354  decode.d2.loss_mask: 0.9173  decode.d2.loss_dice: 0.6514  decode.d3.loss_cls: 0.1264  decode.d3.loss_mask: 0.9113  decode.d3.loss_dice: 0.6496  decode.d4.loss_cls: 0.1278  decode.d4.loss_mask: 0.9140  decode.d4.loss_dice: 0.6474  decode.d5.loss_cls: 0.1270  decode.d5.loss_mask: 0.9176  decode.d5.loss_dice: 0.6490  decode.d6.loss_cls: 0.1174  decode.d6.loss_mask: 0.9070  decode.d6.loss_dice: 0.6418  decode.d7.loss_cls: 0.1039  decode.d7.loss_mask: 0.9246  decode.d7.loss_dice: 0.6459  decode.d8.loss_cls: 0.1367  decode.d8.loss_mask: 0.9061  decode.d8.loss_dice: 0.6406
06/01 13:48:14 - mmengine - INFO - Iter(train) [157200/160000]  base_lr: 2.6226e-06 lr: 2.6226e-07  eta: 1:23:34  time: 0.6438  data_time: 0.0107  memory: 10503  grad_norm: 561.2457  loss: 16.6376  decode.loss_cls: 0.1622  decode.loss_mask: 0.7831  decode.loss_dice: 0.6742  decode.d0.loss_cls: 0.6379  decode.d0.loss_mask: 0.7639  decode.d0.loss_dice: 0.6979  decode.d1.loss_cls: 0.1554  decode.d1.loss_mask: 0.7881  decode.d1.loss_dice: 0.6694  decode.d2.loss_cls: 0.1993  decode.d2.loss_mask: 0.7477  decode.d2.loss_dice: 0.6600  decode.d3.loss_cls: 0.1680  decode.d3.loss_mask: 0.7900  decode.d3.loss_dice: 0.6580  decode.d4.loss_cls: 0.1512  decode.d4.loss_mask: 0.7948  decode.d4.loss_dice: 0.6654  decode.d5.loss_cls: 0.1604  decode.d5.loss_mask: 0.7687  decode.d5.loss_dice: 0.6577  decode.d6.loss_cls: 0.1827  decode.d6.loss_mask: 0.7951  decode.d6.loss_dice: 0.6611  decode.d7.loss_cls: 0.1590  decode.d7.loss_mask: 0.7840  decode.d7.loss_dice: 0.6751  decode.d8.loss_cls: 0.2113  decode.d8.loss_mask: 0.7532  decode.d8.loss_dice: 0.6627
06/01 13:48:46 - mmengine - INFO - Iter(train) [157250/160000]  base_lr: 2.5804e-06 lr: 2.5804e-07  eta: 1:21:52  time: 0.6439  data_time: 0.0106  memory: 10504  grad_norm: 257.6881  loss: 15.1204  decode.loss_cls: 0.1108  decode.loss_mask: 0.8039  decode.loss_dice: 0.5403  decode.d0.loss_cls: 0.5854  decode.d0.loss_mask: 0.7906  decode.d0.loss_dice: 0.5436  decode.d1.loss_cls: 0.1471  decode.d1.loss_mask: 0.8067  decode.d1.loss_dice: 0.5349  decode.d2.loss_cls: 0.1235  decode.d2.loss_mask: 0.8164  decode.d2.loss_dice: 0.5442  decode.d3.loss_cls: 0.1076  decode.d3.loss_mask: 0.8068  decode.d3.loss_dice: 0.5423  decode.d4.loss_cls: 0.1089  decode.d4.loss_mask: 0.8077  decode.d4.loss_dice: 0.5394  decode.d5.loss_cls: 0.1065  decode.d5.loss_mask: 0.8028  decode.d5.loss_dice: 0.5371  decode.d6.loss_cls: 0.1129  decode.d6.loss_mask: 0.8108  decode.d6.loss_dice: 0.5489  decode.d7.loss_cls: 0.1316  decode.d7.loss_mask: 0.8042  decode.d7.loss_dice: 0.5404  decode.d8.loss_cls: 0.1138  decode.d8.loss_mask: 0.8096  decode.d8.loss_dice: 0.5419
06/01 13:49:18 - mmengine - INFO - Iter(train) [157300/160000]  base_lr: 2.5382e-06 lr: 2.5382e-07  eta: 1:20:10  time: 0.6429  data_time: 0.0106  memory: 10501  grad_norm: 272.5212  loss: 11.6365  decode.loss_cls: 0.0421  decode.loss_mask: 0.6492  decode.loss_dice: 0.4379  decode.d0.loss_cls: 0.4276  decode.d0.loss_mask: 0.6483  decode.d0.loss_dice: 0.4377  decode.d1.loss_cls: 0.0479  decode.d1.loss_mask: 0.6610  decode.d1.loss_dice: 0.4515  decode.d2.loss_cls: 0.0356  decode.d2.loss_mask: 0.6641  decode.d2.loss_dice: 0.4540  decode.d3.loss_cls: 0.0342  decode.d3.loss_mask: 0.6387  decode.d3.loss_dice: 0.4272  decode.d4.loss_cls: 0.0317  decode.d4.loss_mask: 0.6434  decode.d4.loss_dice: 0.4309  decode.d5.loss_cls: 0.0313  decode.d5.loss_mask: 0.6589  decode.d5.loss_dice: 0.4434  decode.d6.loss_cls: 0.0404  decode.d6.loss_mask: 0.6479  decode.d6.loss_dice: 0.4308  decode.d7.loss_cls: 0.0387  decode.d7.loss_mask: 0.6391  decode.d7.loss_dice: 0.4319  decode.d8.loss_cls: 0.0415  decode.d8.loss_mask: 0.6411  decode.d8.loss_dice: 0.4283
06/01 13:49:51 - mmengine - INFO - Iter(train) [157350/160000]  base_lr: 2.4958e-06 lr: 2.4958e-07  eta: 1:18:29  time: 0.6446  data_time: 0.0107  memory: 10492  grad_norm: 491.2201  loss: 15.5328  decode.loss_cls: 0.0524  decode.loss_mask: 0.8102  decode.loss_dice: 0.6290  decode.d0.loss_cls: 0.5947  decode.d0.loss_mask: 0.7953  decode.d0.loss_dice: 0.6183  decode.d1.loss_cls: 0.0739  decode.d1.loss_mask: 0.8149  decode.d1.loss_dice: 0.6236  decode.d2.loss_cls: 0.0667  decode.d2.loss_mask: 0.8045  decode.d2.loss_dice: 0.6263  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.8122  decode.d3.loss_dice: 0.6405  decode.d4.loss_cls: 0.0631  decode.d4.loss_mask: 0.8215  decode.d4.loss_dice: 0.6289  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.8044  decode.d5.loss_dice: 0.6319  decode.d6.loss_cls: 0.0615  decode.d6.loss_mask: 0.7965  decode.d6.loss_dice: 0.6342  decode.d7.loss_cls: 0.0721  decode.d7.loss_mask: 0.8140  decode.d7.loss_dice: 0.6281  decode.d8.loss_cls: 0.0585  decode.d8.loss_mask: 0.8124  decode.d8.loss_dice: 0.6273
06/01 13:50:23 - mmengine - INFO - Iter(train) [157400/160000]  base_lr: 2.4534e-06 lr: 2.4534e-07  eta: 1:16:48  time: 0.6449  data_time: 0.0106  memory: 10492  grad_norm: 442.0876  loss: 14.4456  decode.loss_cls: 0.1101  decode.loss_mask: 0.6770  decode.loss_dice: 0.6113  decode.d0.loss_cls: 0.6033  decode.d0.loss_mask: 0.6498  decode.d0.loss_dice: 0.6158  decode.d1.loss_cls: 0.1950  decode.d1.loss_mask: 0.6517  decode.d1.loss_dice: 0.5925  decode.d2.loss_cls: 0.1489  decode.d2.loss_mask: 0.6616  decode.d2.loss_dice: 0.5725  decode.d3.loss_cls: 0.1468  decode.d3.loss_mask: 0.6472  decode.d3.loss_dice: 0.5751  decode.d4.loss_cls: 0.1164  decode.d4.loss_mask: 0.6777  decode.d4.loss_dice: 0.5925  decode.d5.loss_cls: 0.1159  decode.d5.loss_mask: 0.6791  decode.d5.loss_dice: 0.6203  decode.d6.loss_cls: 0.1202  decode.d6.loss_mask: 0.6730  decode.d6.loss_dice: 0.5913  decode.d7.loss_cls: 0.1379  decode.d7.loss_mask: 0.6731  decode.d7.loss_dice: 0.6084  decode.d8.loss_cls: 0.1092  decode.d8.loss_mask: 0.6827  decode.d8.loss_dice: 0.5894
06/01 13:50:55 - mmengine - INFO - Iter(train) [157450/160000]  base_lr: 2.4109e-06 lr: 2.4109e-07  eta: 1:15:08  time: 0.6452  data_time: 0.0107  memory: 10494  grad_norm: 509.6094  loss: 14.0107  decode.loss_cls: 0.0558  decode.loss_mask: 0.7549  decode.loss_dice: 0.5312  decode.d0.loss_cls: 0.4969  decode.d0.loss_mask: 0.7591  decode.d0.loss_dice: 0.5571  decode.d1.loss_cls: 0.0797  decode.d1.loss_mask: 0.7538  decode.d1.loss_dice: 0.5414  decode.d2.loss_cls: 0.0646  decode.d2.loss_mask: 0.7405  decode.d2.loss_dice: 0.5460  decode.d3.loss_cls: 0.0664  decode.d3.loss_mask: 0.7468  decode.d3.loss_dice: 0.5346  decode.d4.loss_cls: 0.0660  decode.d4.loss_mask: 0.7547  decode.d4.loss_dice: 0.5310  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.7631  decode.d5.loss_dice: 0.5402  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.7542  decode.d6.loss_dice: 0.5292  decode.d7.loss_cls: 0.0944  decode.d7.loss_mask: 0.7345  decode.d7.loss_dice: 0.5403  decode.d8.loss_cls: 0.0929  decode.d8.loss_mask: 0.7298  decode.d8.loss_dice: 0.5286
06/01 13:51:27 - mmengine - INFO - Iter(train) [157500/160000]  base_lr: 2.3683e-06 lr: 2.3683e-07  eta: 1:13:28  time: 0.6440  data_time: 0.0106  memory: 10496  grad_norm: 916.4382  loss: 13.5700  decode.loss_cls: 0.0234  decode.loss_mask: 0.7906  decode.loss_dice: 0.4915  decode.d0.loss_cls: 0.3992  decode.d0.loss_mask: 0.8167  decode.d0.loss_dice: 0.5101  decode.d1.loss_cls: 0.0267  decode.d1.loss_mask: 0.8045  decode.d1.loss_dice: 0.4959  decode.d2.loss_cls: 0.0430  decode.d2.loss_mask: 0.7943  decode.d2.loss_dice: 0.4863  decode.d3.loss_cls: 0.0257  decode.d3.loss_mask: 0.7951  decode.d3.loss_dice: 0.4940  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 0.7980  decode.d4.loss_dice: 0.4919  decode.d5.loss_cls: 0.0235  decode.d5.loss_mask: 0.7987  decode.d5.loss_dice: 0.4936  decode.d6.loss_cls: 0.0249  decode.d6.loss_mask: 0.7992  decode.d6.loss_dice: 0.4937  decode.d7.loss_cls: 0.0235  decode.d7.loss_mask: 0.7939  decode.d7.loss_dice: 0.4975  decode.d8.loss_cls: 0.0245  decode.d8.loss_mask: 0.7905  decode.d8.loss_dice: 0.4907
06/01 13:52:00 - mmengine - INFO - Iter(train) [157550/160000]  base_lr: 2.3256e-06 lr: 2.3256e-07  eta: 1:11:49  time: 0.6438  data_time: 0.0107  memory: 10492  grad_norm: 273.0908  loss: 13.7367  decode.loss_cls: 0.0663  decode.loss_mask: 0.7566  decode.loss_dice: 0.5263  decode.d0.loss_cls: 0.4462  decode.d0.loss_mask: 0.7572  decode.d0.loss_dice: 0.5168  decode.d1.loss_cls: 0.0580  decode.d1.loss_mask: 0.7582  decode.d1.loss_dice: 0.5368  decode.d2.loss_cls: 0.0563  decode.d2.loss_mask: 0.7475  decode.d2.loss_dice: 0.5221  decode.d3.loss_cls: 0.0526  decode.d3.loss_mask: 0.7546  decode.d3.loss_dice: 0.5282  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 0.7509  decode.d4.loss_dice: 0.5246  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.7535  decode.d5.loss_dice: 0.5241  decode.d6.loss_cls: 0.0510  decode.d6.loss_mask: 0.7540  decode.d6.loss_dice: 0.5220  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.7474  decode.d7.loss_dice: 0.5256  decode.d8.loss_cls: 0.0628  decode.d8.loss_mask: 0.7502  decode.d8.loss_dice: 0.5217
06/01 13:52:32 - mmengine - INFO - Iter(train) [157600/160000]  base_lr: 2.2829e-06 lr: 2.2829e-07  eta: 1:10:10  time: 0.6457  data_time: 0.0107  memory: 10500  grad_norm: 346.4143  loss: 12.8037  decode.loss_cls: 0.0215  decode.loss_mask: 0.7318  decode.loss_dice: 0.5005  decode.d0.loss_cls: 0.4100  decode.d0.loss_mask: 0.6975  decode.d0.loss_dice: 0.4890  decode.d1.loss_cls: 0.0220  decode.d1.loss_mask: 0.7230  decode.d1.loss_dice: 0.4830  decode.d2.loss_cls: 0.0174  decode.d2.loss_mask: 0.7308  decode.d2.loss_dice: 0.4942  decode.d3.loss_cls: 0.0222  decode.d3.loss_mask: 0.7365  decode.d3.loss_dice: 0.5018  decode.d4.loss_cls: 0.0198  decode.d4.loss_mask: 0.7304  decode.d4.loss_dice: 0.4939  decode.d5.loss_cls: 0.0210  decode.d5.loss_mask: 0.7295  decode.d5.loss_dice: 0.4952  decode.d6.loss_cls: 0.0184  decode.d6.loss_mask: 0.7278  decode.d6.loss_dice: 0.4939  decode.d7.loss_cls: 0.0193  decode.d7.loss_mask: 0.7302  decode.d7.loss_dice: 0.4955  decode.d8.loss_cls: 0.0218  decode.d8.loss_mask: 0.7300  decode.d8.loss_dice: 0.4956
06/01 13:53:04 - mmengine - INFO - Iter(train) [157650/160000]  base_lr: 2.2400e-06 lr: 2.2400e-07  eta: 1:08:32  time: 0.6446  data_time: 0.0106  memory: 10495  grad_norm: 367.6428  loss: 14.1436  decode.loss_cls: 0.0748  decode.loss_mask: 0.8036  decode.loss_dice: 0.4891  decode.d0.loss_cls: 0.5902  decode.d0.loss_mask: 0.7644  decode.d0.loss_dice: 0.4731  decode.d1.loss_cls: 0.0835  decode.d1.loss_mask: 0.8021  decode.d1.loss_dice: 0.4954  decode.d2.loss_cls: 0.0937  decode.d2.loss_mask: 0.8023  decode.d2.loss_dice: 0.4892  decode.d3.loss_cls: 0.0713  decode.d3.loss_mask: 0.8008  decode.d3.loss_dice: 0.4924  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.8016  decode.d4.loss_dice: 0.4902  decode.d5.loss_cls: 0.0641  decode.d5.loss_mask: 0.8004  decode.d5.loss_dice: 0.4862  decode.d6.loss_cls: 0.0734  decode.d6.loss_mask: 0.8001  decode.d6.loss_dice: 0.4853  decode.d7.loss_cls: 0.0757  decode.d7.loss_mask: 0.8056  decode.d7.loss_dice: 0.4904  decode.d8.loss_cls: 0.0758  decode.d8.loss_mask: 0.8019  decode.d8.loss_dice: 0.4898
06/01 13:53:36 - mmengine - INFO - Iter(train) [157700/160000]  base_lr: 2.1971e-06 lr: 2.1971e-07  eta: 1:06:55  time: 0.6425  data_time: 0.0108  memory: 10522  grad_norm: 849.4779  loss: 13.7030  decode.loss_cls: 0.0897  decode.loss_mask: 0.7274  decode.loss_dice: 0.5086  decode.d0.loss_cls: 0.6165  decode.d0.loss_mask: 0.6901  decode.d0.loss_dice: 0.4950  decode.d1.loss_cls: 0.0928  decode.d1.loss_mask: 0.7234  decode.d1.loss_dice: 0.5130  decode.d2.loss_cls: 0.0887  decode.d2.loss_mask: 0.7218  decode.d2.loss_dice: 0.5186  decode.d3.loss_cls: 0.0923  decode.d3.loss_mask: 0.7164  decode.d3.loss_dice: 0.5111  decode.d4.loss_cls: 0.0783  decode.d4.loss_mask: 0.7254  decode.d4.loss_dice: 0.5168  decode.d5.loss_cls: 0.0726  decode.d5.loss_mask: 0.7235  decode.d5.loss_dice: 0.5120  decode.d6.loss_cls: 0.0840  decode.d6.loss_mask: 0.7176  decode.d6.loss_dice: 0.5087  decode.d7.loss_cls: 0.0835  decode.d7.loss_mask: 0.7250  decode.d7.loss_dice: 0.5191  decode.d8.loss_cls: 0.0683  decode.d8.loss_mask: 0.7387  decode.d8.loss_dice: 0.5242
06/01 13:54:09 - mmengine - INFO - Iter(train) [157750/160000]  base_lr: 2.1541e-06 lr: 2.1541e-07  eta: 1:05:18  time: 0.6437  data_time: 0.0109  memory: 10494  grad_norm: 206.4769  loss: 12.7397  decode.loss_cls: 0.0335  decode.loss_mask: 0.7326  decode.loss_dice: 0.4670  decode.d0.loss_cls: 0.4474  decode.d0.loss_mask: 0.7278  decode.d0.loss_dice: 0.4527  decode.d1.loss_cls: 0.0321  decode.d1.loss_mask: 0.7368  decode.d1.loss_dice: 0.4667  decode.d2.loss_cls: 0.0291  decode.d2.loss_mask: 0.7325  decode.d2.loss_dice: 0.4643  decode.d3.loss_cls: 0.0338  decode.d3.loss_mask: 0.7366  decode.d3.loss_dice: 0.4678  decode.d4.loss_cls: 0.0592  decode.d4.loss_mask: 0.7368  decode.d4.loss_dice: 0.4675  decode.d5.loss_cls: 0.0275  decode.d5.loss_mask: 0.7293  decode.d5.loss_dice: 0.4668  decode.d6.loss_cls: 0.0295  decode.d6.loss_mask: 0.7338  decode.d6.loss_dice: 0.4660  decode.d7.loss_cls: 0.0269  decode.d7.loss_mask: 0.7359  decode.d7.loss_dice: 0.4692  decode.d8.loss_cls: 0.0360  decode.d8.loss_mask: 0.7323  decode.d8.loss_dice: 0.4625
06/01 13:54:41 - mmengine - INFO - Iter(train) [157800/160000]  base_lr: 2.1109e-06 lr: 2.1109e-07  eta: 1:03:41  time: 0.6425  data_time: 0.0107  memory: 10512  grad_norm: 334.3157  loss: 15.9338  decode.loss_cls: 0.1383  decode.loss_mask: 0.8037  decode.loss_dice: 0.5788  decode.d0.loss_cls: 0.5546  decode.d0.loss_mask: 0.7843  decode.d0.loss_dice: 0.6030  decode.d1.loss_cls: 0.1875  decode.d1.loss_mask: 0.7916  decode.d1.loss_dice: 0.6178  decode.d2.loss_cls: 0.1186  decode.d2.loss_mask: 0.8605  decode.d2.loss_dice: 0.5926  decode.d3.loss_cls: 0.1739  decode.d3.loss_mask: 0.7887  decode.d3.loss_dice: 0.5907  decode.d4.loss_cls: 0.1857  decode.d4.loss_mask: 0.7997  decode.d4.loss_dice: 0.5719  decode.d5.loss_cls: 0.1491  decode.d5.loss_mask: 0.7950  decode.d5.loss_dice: 0.5551  decode.d6.loss_cls: 0.1717  decode.d6.loss_mask: 0.7843  decode.d6.loss_dice: 0.5842  decode.d7.loss_cls: 0.1822  decode.d7.loss_mask: 0.8122  decode.d7.loss_dice: 0.5969  decode.d8.loss_cls: 0.1511  decode.d8.loss_mask: 0.8156  decode.d8.loss_dice: 0.5945
06/01 13:55:13 - mmengine - INFO - Iter(train) [157850/160000]  base_lr: 2.0677e-06 lr: 2.0677e-07  eta: 1:02:05  time: 0.6432  data_time: 0.0107  memory: 10492  grad_norm: 432.5774  loss: 12.7138  decode.loss_cls: 0.0511  decode.loss_mask: 0.6840  decode.loss_dice: 0.4967  decode.d0.loss_cls: 0.4401  decode.d0.loss_mask: 0.6890  decode.d0.loss_dice: 0.5170  decode.d1.loss_cls: 0.0578  decode.d1.loss_mask: 0.6741  decode.d1.loss_dice: 0.4937  decode.d2.loss_cls: 0.0450  decode.d2.loss_mask: 0.6832  decode.d2.loss_dice: 0.4915  decode.d3.loss_cls: 0.0440  decode.d3.loss_mask: 0.6866  decode.d3.loss_dice: 0.4880  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.6819  decode.d4.loss_dice: 0.4851  decode.d5.loss_cls: 0.0562  decode.d5.loss_mask: 0.6866  decode.d5.loss_dice: 0.4944  decode.d6.loss_cls: 0.0507  decode.d6.loss_mask: 0.6859  decode.d6.loss_dice: 0.4987  decode.d7.loss_cls: 0.0557  decode.d7.loss_mask: 0.6827  decode.d7.loss_dice: 0.4989  decode.d8.loss_cls: 0.0552  decode.d8.loss_mask: 0.6886  decode.d8.loss_dice: 0.5028
06/01 13:55:45 - mmengine - INFO - Iter(train) [157900/160000]  base_lr: 2.0244e-06 lr: 2.0244e-07  eta: 1:00:30  time: 0.6438  data_time: 0.0108  memory: 10499  grad_norm: 638.9372  loss: 15.3812  decode.loss_cls: 0.1151  decode.loss_mask: 0.8276  decode.loss_dice: 0.5415  decode.d0.loss_cls: 0.6049  decode.d0.loss_mask: 0.8123  decode.d0.loss_dice: 0.5437  decode.d1.loss_cls: 0.1154  decode.d1.loss_mask: 0.8140  decode.d1.loss_dice: 0.5426  decode.d2.loss_cls: 0.1354  decode.d2.loss_mask: 0.8304  decode.d2.loss_dice: 0.5584  decode.d3.loss_cls: 0.1314  decode.d3.loss_mask: 0.8205  decode.d3.loss_dice: 0.5577  decode.d4.loss_cls: 0.1293  decode.d4.loss_mask: 0.8133  decode.d4.loss_dice: 0.5546  decode.d5.loss_cls: 0.0956  decode.d5.loss_mask: 0.8337  decode.d5.loss_dice: 0.5521  decode.d6.loss_cls: 0.1244  decode.d6.loss_mask: 0.8343  decode.d6.loss_dice: 0.5315  decode.d7.loss_cls: 0.1228  decode.d7.loss_mask: 0.8103  decode.d7.loss_dice: 0.5448  decode.d8.loss_cls: 0.1127  decode.d8.loss_mask: 0.8187  decode.d8.loss_dice: 0.5521
06/01 13:56:17 - mmengine - INFO - Iter(train) [157950/160000]  base_lr: 1.9809e-06 lr: 1.9809e-07  eta: 0:58:55  time: 0.6438  data_time: 0.0106  memory: 10512  grad_norm: 423.7778  loss: 14.2562  decode.loss_cls: 0.0622  decode.loss_mask: 0.8158  decode.loss_dice: 0.5264  decode.d0.loss_cls: 0.4904  decode.d0.loss_mask: 0.8227  decode.d0.loss_dice: 0.5217  decode.d1.loss_cls: 0.0330  decode.d1.loss_mask: 0.8100  decode.d1.loss_dice: 0.5226  decode.d2.loss_cls: 0.0389  decode.d2.loss_mask: 0.8155  decode.d2.loss_dice: 0.5233  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.8159  decode.d3.loss_dice: 0.5255  decode.d4.loss_cls: 0.0402  decode.d4.loss_mask: 0.8123  decode.d4.loss_dice: 0.5247  decode.d5.loss_cls: 0.0435  decode.d5.loss_mask: 0.8169  decode.d5.loss_dice: 0.5220  decode.d6.loss_cls: 0.0487  decode.d6.loss_mask: 0.8165  decode.d6.loss_dice: 0.5227  decode.d7.loss_cls: 0.0305  decode.d7.loss_mask: 0.8127  decode.d7.loss_dice: 0.5191  decode.d8.loss_cls: 0.0344  decode.d8.loss_mask: 0.8138  decode.d8.loss_dice: 0.5239
06/01 13:56:50 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 13:56:50 - mmengine - INFO - Iter(train) [158000/160000]  base_lr: 1.9374e-06 lr: 1.9374e-07  eta: 0:57:20  time: 0.6432  data_time: 0.0107  memory: 10499  grad_norm: 362.7813  loss: 15.5491  decode.loss_cls: 0.1265  decode.loss_mask: 0.8278  decode.loss_dice: 0.5569  decode.d0.loss_cls: 0.4801  decode.d0.loss_mask: 0.8131  decode.d0.loss_dice: 0.5457  decode.d1.loss_cls: 0.0971  decode.d1.loss_mask: 0.8394  decode.d1.loss_dice: 0.5469  decode.d2.loss_cls: 0.1103  decode.d2.loss_mask: 0.8475  decode.d2.loss_dice: 0.5727  decode.d3.loss_cls: 0.1173  decode.d3.loss_mask: 0.8623  decode.d3.loss_dice: 0.5614  decode.d4.loss_cls: 0.1169  decode.d4.loss_mask: 0.8398  decode.d4.loss_dice: 0.5608  decode.d5.loss_cls: 0.1238  decode.d5.loss_mask: 0.8437  decode.d5.loss_dice: 0.5663  decode.d6.loss_cls: 0.1379  decode.d6.loss_mask: 0.8416  decode.d6.loss_dice: 0.5440  decode.d7.loss_cls: 0.1248  decode.d7.loss_mask: 0.8258  decode.d7.loss_dice: 0.5612  decode.d8.loss_cls: 0.0919  decode.d8.loss_mask: 0.8901  decode.d8.loss_dice: 0.5753
06/01 13:57:22 - mmengine - INFO - Iter(train) [158050/160000]  base_lr: 1.8938e-06 lr: 1.8938e-07  eta: 0:55:46  time: 0.6443  data_time: 0.0107  memory: 10492  grad_norm: 802.1949  loss: 18.5114  decode.loss_cls: 0.0702  decode.loss_mask: 1.0034  decode.loss_dice: 0.7233  decode.d0.loss_cls: 0.5690  decode.d0.loss_mask: 0.9914  decode.d0.loss_dice: 0.6965  decode.d1.loss_cls: 0.1178  decode.d1.loss_mask: 1.0135  decode.d1.loss_dice: 0.7290  decode.d2.loss_cls: 0.0593  decode.d2.loss_mask: 1.0431  decode.d2.loss_dice: 0.7330  decode.d3.loss_cls: 0.0723  decode.d3.loss_mask: 1.0077  decode.d3.loss_dice: 0.7308  decode.d4.loss_cls: 0.0612  decode.d4.loss_mask: 1.0064  decode.d4.loss_dice: 0.7251  decode.d5.loss_cls: 0.0725  decode.d5.loss_mask: 1.0065  decode.d5.loss_dice: 0.7204  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 1.0144  decode.d6.loss_dice: 0.7185  decode.d7.loss_cls: 0.0614  decode.d7.loss_mask: 1.0135  decode.d7.loss_dice: 0.7186  decode.d8.loss_cls: 0.0626  decode.d8.loss_mask: 0.9934  decode.d8.loss_dice: 0.7121
06/01 13:57:54 - mmengine - INFO - Iter(train) [158100/160000]  base_lr: 1.8500e-06 lr: 1.8500e-07  eta: 0:54:13  time: 0.6432  data_time: 0.0107  memory: 10495  grad_norm: 545.8722  loss: 18.7849  decode.loss_cls: 0.1387  decode.loss_mask: 1.0445  decode.loss_dice: 0.6758  decode.d0.loss_cls: 0.6279  decode.d0.loss_mask: 0.9310  decode.d0.loss_dice: 0.6489  decode.d1.loss_cls: 0.1159  decode.d1.loss_mask: 1.0058  decode.d1.loss_dice: 0.6706  decode.d2.loss_cls: 0.1298  decode.d2.loss_mask: 1.0260  decode.d2.loss_dice: 0.6780  decode.d3.loss_cls: 0.1289  decode.d3.loss_mask: 1.0245  decode.d3.loss_dice: 0.6689  decode.d4.loss_cls: 0.1390  decode.d4.loss_mask: 1.0389  decode.d4.loss_dice: 0.6707  decode.d5.loss_cls: 0.1639  decode.d5.loss_mask: 1.0222  decode.d5.loss_dice: 0.6722  decode.d6.loss_cls: 0.1571  decode.d6.loss_mask: 1.0427  decode.d6.loss_dice: 0.6737  decode.d7.loss_cls: 0.1468  decode.d7.loss_mask: 1.0422  decode.d7.loss_dice: 0.6677  decode.d8.loss_cls: 0.1355  decode.d8.loss_mask: 1.0254  decode.d8.loss_dice: 0.6717
06/01 13:58:26 - mmengine - INFO - Iter(train) [158150/160000]  base_lr: 1.8061e-06 lr: 1.8061e-07  eta: 0:52:39  time: 0.6435  data_time: 0.0107  memory: 10505  grad_norm: 398.8199  loss: 15.6279  decode.loss_cls: 0.0855  decode.loss_mask: 0.8051  decode.loss_dice: 0.6448  decode.d0.loss_cls: 0.4663  decode.d0.loss_mask: 0.7862  decode.d0.loss_dice: 0.6155  decode.d1.loss_cls: 0.0817  decode.d1.loss_mask: 0.7868  decode.d1.loss_dice: 0.6196  decode.d2.loss_cls: 0.0863  decode.d2.loss_mask: 0.8056  decode.d2.loss_dice: 0.6462  decode.d3.loss_cls: 0.0805  decode.d3.loss_mask: 0.8104  decode.d3.loss_dice: 0.6514  decode.d4.loss_cls: 0.0803  decode.d4.loss_mask: 0.8083  decode.d4.loss_dice: 0.6446  decode.d5.loss_cls: 0.0909  decode.d5.loss_mask: 0.8104  decode.d5.loss_dice: 0.6581  decode.d6.loss_cls: 0.0893  decode.d6.loss_mask: 0.7984  decode.d6.loss_dice: 0.6463  decode.d7.loss_cls: 0.0684  decode.d7.loss_mask: 0.7979  decode.d7.loss_dice: 0.6447  decode.d8.loss_cls: 0.0828  decode.d8.loss_mask: 0.7942  decode.d8.loss_dice: 0.6415
06/01 13:58:58 - mmengine - INFO - Iter(train) [158200/160000]  base_lr: 1.7621e-06 lr: 1.7621e-07  eta: 0:51:07  time: 0.6437  data_time: 0.0106  memory: 10507  grad_norm: 486.2564  loss: 14.1604  decode.loss_cls: 0.0139  decode.loss_mask: 0.8128  decode.loss_dice: 0.5584  decode.d0.loss_cls: 0.3976  decode.d0.loss_mask: 0.8276  decode.d0.loss_dice: 0.5433  decode.d1.loss_cls: 0.0193  decode.d1.loss_mask: 0.8138  decode.d1.loss_dice: 0.5539  decode.d2.loss_cls: 0.0144  decode.d2.loss_mask: 0.8088  decode.d2.loss_dice: 0.5470  decode.d3.loss_cls: 0.0133  decode.d3.loss_mask: 0.8173  decode.d3.loss_dice: 0.5548  decode.d4.loss_cls: 0.0132  decode.d4.loss_mask: 0.8076  decode.d4.loss_dice: 0.5501  decode.d5.loss_cls: 0.0130  decode.d5.loss_mask: 0.8122  decode.d5.loss_dice: 0.5542  decode.d6.loss_cls: 0.0133  decode.d6.loss_mask: 0.8088  decode.d6.loss_dice: 0.5454  decode.d7.loss_cls: 0.0141  decode.d7.loss_mask: 0.8095  decode.d7.loss_dice: 0.5531  decode.d8.loss_cls: 0.0135  decode.d8.loss_mask: 0.8093  decode.d8.loss_dice: 0.5467
06/01 13:59:31 - mmengine - INFO - Iter(train) [158250/160000]  base_lr: 1.7180e-06 lr: 1.7180e-07  eta: 0:49:35  time: 0.6427  data_time: 0.0106  memory: 10492  grad_norm: 376.2658  loss: 11.8897  decode.loss_cls: 0.0884  decode.loss_mask: 0.6238  decode.loss_dice: 0.4427  decode.d0.loss_cls: 0.4520  decode.d0.loss_mask: 0.6355  decode.d0.loss_dice: 0.4599  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.6235  decode.d1.loss_dice: 0.4560  decode.d2.loss_cls: 0.0542  decode.d2.loss_mask: 0.6328  decode.d2.loss_dice: 0.4551  decode.d3.loss_cls: 0.1009  decode.d3.loss_mask: 0.6223  decode.d3.loss_dice: 0.4188  decode.d4.loss_cls: 0.0832  decode.d4.loss_mask: 0.6332  decode.d4.loss_dice: 0.4349  decode.d5.loss_cls: 0.0549  decode.d5.loss_mask: 0.6596  decode.d5.loss_dice: 0.4458  decode.d6.loss_cls: 0.0833  decode.d6.loss_mask: 0.6260  decode.d6.loss_dice: 0.4326  decode.d7.loss_cls: 0.0813  decode.d7.loss_mask: 0.6336  decode.d7.loss_dice: 0.4366  decode.d8.loss_cls: 0.0887  decode.d8.loss_mask: 0.6227  decode.d8.loss_dice: 0.4382
06/01 14:00:03 - mmengine - INFO - Iter(train) [158300/160000]  base_lr: 1.6738e-06 lr: 1.6738e-07  eta: 0:48:03  time: 0.6443  data_time: 0.0108  memory: 10500  grad_norm: 207.6082  loss: 12.0013  decode.loss_cls: 0.0112  decode.loss_mask: 0.7120  decode.loss_dice: 0.4394  decode.d0.loss_cls: 0.3796  decode.d0.loss_mask: 0.7089  decode.d0.loss_dice: 0.4371  decode.d1.loss_cls: 0.0114  decode.d1.loss_mask: 0.7137  decode.d1.loss_dice: 0.4373  decode.d2.loss_cls: 0.0097  decode.d2.loss_mask: 0.7174  decode.d2.loss_dice: 0.4432  decode.d3.loss_cls: 0.0101  decode.d3.loss_mask: 0.7139  decode.d3.loss_dice: 0.4469  decode.d4.loss_cls: 0.0085  decode.d4.loss_mask: 0.7111  decode.d4.loss_dice: 0.4370  decode.d5.loss_cls: 0.0100  decode.d5.loss_mask: 0.7103  decode.d5.loss_dice: 0.4409  decode.d6.loss_cls: 0.0320  decode.d6.loss_mask: 0.7090  decode.d6.loss_dice: 0.4369  decode.d7.loss_cls: 0.0105  decode.d7.loss_mask: 0.7120  decode.d7.loss_dice: 0.4355  decode.d8.loss_cls: 0.0101  decode.d8.loss_mask: 0.7097  decode.d8.loss_dice: 0.4360
06/01 14:00:35 - mmengine - INFO - Iter(train) [158350/160000]  base_lr: 1.6294e-06 lr: 1.6294e-07  eta: 0:46:32  time: 0.6423  data_time: 0.0106  memory: 10499  grad_norm: 147.7382  loss: 10.9896  decode.loss_cls: 0.0254  decode.loss_mask: 0.5764  decode.loss_dice: 0.4518  decode.d0.loss_cls: 0.4462  decode.d0.loss_mask: 0.5735  decode.d0.loss_dice: 0.4379  decode.d1.loss_cls: 0.0488  decode.d1.loss_mask: 0.5712  decode.d1.loss_dice: 0.4575  decode.d2.loss_cls: 0.0533  decode.d2.loss_mask: 0.5716  decode.d2.loss_dice: 0.4538  decode.d3.loss_cls: 0.0423  decode.d3.loss_mask: 0.5792  decode.d3.loss_dice: 0.4522  decode.d4.loss_cls: 0.0323  decode.d4.loss_mask: 0.5771  decode.d4.loss_dice: 0.4368  decode.d5.loss_cls: 0.0320  decode.d5.loss_mask: 0.5804  decode.d5.loss_dice: 0.4594  decode.d6.loss_cls: 0.0409  decode.d6.loss_mask: 0.5741  decode.d6.loss_dice: 0.4216  decode.d7.loss_cls: 0.0213  decode.d7.loss_mask: 0.5772  decode.d7.loss_dice: 0.4407  decode.d8.loss_cls: 0.0366  decode.d8.loss_mask: 0.5749  decode.d8.loss_dice: 0.4435
06/01 14:01:07 - mmengine - INFO - Iter(train) [158400/160000]  base_lr: 1.5849e-06 lr: 1.5849e-07  eta: 0:45:01  time: 0.6431  data_time: 0.0106  memory: 10496  grad_norm: 291.4941  loss: 13.6037  decode.loss_cls: 0.0604  decode.loss_mask: 0.7587  decode.loss_dice: 0.5004  decode.d0.loss_cls: 0.4840  decode.d0.loss_mask: 0.7470  decode.d0.loss_dice: 0.5171  decode.d1.loss_cls: 0.0655  decode.d1.loss_mask: 0.7525  decode.d1.loss_dice: 0.4891  decode.d2.loss_cls: 0.0534  decode.d2.loss_mask: 0.7531  decode.d2.loss_dice: 0.4929  decode.d3.loss_cls: 0.0606  decode.d3.loss_mask: 0.7613  decode.d3.loss_dice: 0.4975  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.7577  decode.d4.loss_dice: 0.4959  decode.d5.loss_cls: 0.0625  decode.d5.loss_mask: 0.7642  decode.d5.loss_dice: 0.5015  decode.d6.loss_cls: 0.0636  decode.d6.loss_mask: 0.7643  decode.d6.loss_dice: 0.4929  decode.d7.loss_cls: 0.0587  decode.d7.loss_mask: 0.7569  decode.d7.loss_dice: 0.5040  decode.d8.loss_cls: 0.0552  decode.d8.loss_mask: 0.7627  decode.d8.loss_dice: 0.5090
06/01 14:01:40 - mmengine - INFO - Iter(train) [158450/160000]  base_lr: 1.5403e-06 lr: 1.5403e-07  eta: 0:43:30  time: 0.6430  data_time: 0.0107  memory: 10513  grad_norm: 603.5029  loss: 12.8862  decode.loss_cls: 0.0783  decode.loss_mask: 0.6690  decode.loss_dice: 0.4956  decode.d0.loss_cls: 0.5673  decode.d0.loss_mask: 0.6135  decode.d0.loss_dice: 0.5057  decode.d1.loss_cls: 0.1363  decode.d1.loss_mask: 0.6139  decode.d1.loss_dice: 0.4879  decode.d2.loss_cls: 0.1230  decode.d2.loss_mask: 0.6177  decode.d2.loss_dice: 0.4999  decode.d3.loss_cls: 0.0882  decode.d3.loss_mask: 0.6776  decode.d3.loss_dice: 0.5016  decode.d4.loss_cls: 0.0827  decode.d4.loss_mask: 0.6682  decode.d4.loss_dice: 0.4938  decode.d5.loss_cls: 0.0829  decode.d5.loss_mask: 0.6724  decode.d5.loss_dice: 0.4856  decode.d6.loss_cls: 0.0862  decode.d6.loss_mask: 0.6757  decode.d6.loss_dice: 0.4917  decode.d7.loss_cls: 0.0929  decode.d7.loss_mask: 0.6707  decode.d7.loss_dice: 0.5010  decode.d8.loss_cls: 0.1111  decode.d8.loss_mask: 0.6043  decode.d8.loss_dice: 0.4915
06/01 14:02:12 - mmengine - INFO - Iter(train) [158500/160000]  base_lr: 1.4955e-06 lr: 1.4955e-07  eta: 0:42:00  time: 0.6441  data_time: 0.0106  memory: 10490  grad_norm: 850.4831  loss: 16.7415  decode.loss_cls: 0.1272  decode.loss_mask: 0.9346  decode.loss_dice: 0.5593  decode.d0.loss_cls: 0.5943  decode.d0.loss_mask: 0.8864  decode.d0.loss_dice: 0.5611  decode.d1.loss_cls: 0.1664  decode.d1.loss_mask: 0.9263  decode.d1.loss_dice: 0.5740  decode.d2.loss_cls: 0.1470  decode.d2.loss_mask: 0.9180  decode.d2.loss_dice: 0.5721  decode.d3.loss_cls: 0.1431  decode.d3.loss_mask: 0.9375  decode.d3.loss_dice: 0.5633  decode.d4.loss_cls: 0.1528  decode.d4.loss_mask: 0.9038  decode.d4.loss_dice: 0.5738  decode.d5.loss_cls: 0.1568  decode.d5.loss_mask: 0.9028  decode.d5.loss_dice: 0.5674  decode.d6.loss_cls: 0.1350  decode.d6.loss_mask: 0.9060  decode.d6.loss_dice: 0.5663  decode.d7.loss_cls: 0.1417  decode.d7.loss_mask: 0.9407  decode.d7.loss_dice: 0.5667  decode.d8.loss_cls: 0.1243  decode.d8.loss_mask: 0.9191  decode.d8.loss_dice: 0.5738
06/01 14:02:44 - mmengine - INFO - Iter(train) [158550/160000]  base_lr: 1.4505e-06 lr: 1.4505e-07  eta: 0:40:31  time: 0.6426  data_time: 0.0106  memory: 10510  grad_norm: 201.7783  loss: 11.6234  decode.loss_cls: 0.0493  decode.loss_mask: 0.6493  decode.loss_dice: 0.4392  decode.d0.loss_cls: 0.4053  decode.d0.loss_mask: 0.6497  decode.d0.loss_dice: 0.4291  decode.d1.loss_cls: 0.0219  decode.d1.loss_mask: 0.6491  decode.d1.loss_dice: 0.4327  decode.d2.loss_cls: 0.0546  decode.d2.loss_mask: 0.6490  decode.d2.loss_dice: 0.4369  decode.d3.loss_cls: 0.0585  decode.d3.loss_mask: 0.6479  decode.d3.loss_dice: 0.4355  decode.d4.loss_cls: 0.0269  decode.d4.loss_mask: 0.6440  decode.d4.loss_dice: 0.4278  decode.d5.loss_cls: 0.0527  decode.d5.loss_mask: 0.6503  decode.d5.loss_dice: 0.4334  decode.d6.loss_cls: 0.0527  decode.d6.loss_mask: 0.6516  decode.d6.loss_dice: 0.4331  decode.d7.loss_cls: 0.0256  decode.d7.loss_mask: 0.6532  decode.d7.loss_dice: 0.4344  decode.d8.loss_cls: 0.0466  decode.d8.loss_mask: 0.6466  decode.d8.loss_dice: 0.4363
06/01 14:03:16 - mmengine - INFO - Iter(train) [158600/160000]  base_lr: 1.4054e-06 lr: 1.4054e-07  eta: 0:39:01  time: 0.6429  data_time: 0.0107  memory: 10504  grad_norm: 285.6028  loss: 13.3077  decode.loss_cls: 0.1365  decode.loss_mask: 0.6575  decode.loss_dice: 0.5244  decode.d0.loss_cls: 0.5335  decode.d0.loss_mask: 0.6341  decode.d0.loss_dice: 0.4979  decode.d1.loss_cls: 0.1666  decode.d1.loss_mask: 0.6241  decode.d1.loss_dice: 0.5042  decode.d2.loss_cls: 0.1508  decode.d2.loss_mask: 0.6444  decode.d2.loss_dice: 0.5182  decode.d3.loss_cls: 0.1212  decode.d3.loss_mask: 0.6409  decode.d3.loss_dice: 0.5329  decode.d4.loss_cls: 0.1156  decode.d4.loss_mask: 0.6397  decode.d4.loss_dice: 0.5275  decode.d5.loss_cls: 0.1454  decode.d5.loss_mask: 0.6348  decode.d5.loss_dice: 0.4912  decode.d6.loss_cls: 0.1282  decode.d6.loss_mask: 0.6480  decode.d6.loss_dice: 0.5141  decode.d7.loss_cls: 0.1415  decode.d7.loss_mask: 0.6309  decode.d7.loss_dice: 0.5007  decode.d8.loss_cls: 0.1409  decode.d8.loss_mask: 0.6388  decode.d8.loss_dice: 0.5234
06/01 14:03:48 - mmengine - INFO - Iter(train) [158650/160000]  base_lr: 1.3602e-06 lr: 1.3602e-07  eta: 0:37:33  time: 0.6436  data_time: 0.0107  memory: 10518  grad_norm: 353.9350  loss: 17.7549  decode.loss_cls: 0.1765  decode.loss_mask: 0.9524  decode.loss_dice: 0.6362  decode.d0.loss_cls: 0.5581  decode.d0.loss_mask: 0.9488  decode.d0.loss_dice: 0.6316  decode.d1.loss_cls: 0.2009  decode.d1.loss_mask: 0.9391  decode.d1.loss_dice: 0.6334  decode.d2.loss_cls: 0.1556  decode.d2.loss_mask: 0.9346  decode.d2.loss_dice: 0.6183  decode.d3.loss_cls: 0.1567  decode.d3.loss_mask: 0.9510  decode.d3.loss_dice: 0.6239  decode.d4.loss_cls: 0.1596  decode.d4.loss_mask: 0.9369  decode.d4.loss_dice: 0.6415  decode.d5.loss_cls: 0.1838  decode.d5.loss_mask: 0.9372  decode.d5.loss_dice: 0.5871  decode.d6.loss_cls: 0.1804  decode.d6.loss_mask: 0.9424  decode.d6.loss_dice: 0.6274  decode.d7.loss_cls: 0.1481  decode.d7.loss_mask: 0.9480  decode.d7.loss_dice: 0.6177  decode.d8.loss_cls: 0.1866  decode.d8.loss_mask: 0.9334  decode.d8.loss_dice: 0.6078
06/01 14:04:20 - mmengine - INFO - Iter(train) [158700/160000]  base_lr: 1.3148e-06 lr: 1.3148e-07  eta: 0:36:04  time: 0.6426  data_time: 0.0106  memory: 10501  grad_norm: 203.8550  loss: 13.9922  decode.loss_cls: 0.0463  decode.loss_mask: 0.7313  decode.loss_dice: 0.5716  decode.d0.loss_cls: 0.4808  decode.d0.loss_mask: 0.7189  decode.d0.loss_dice: 0.5837  decode.d1.loss_cls: 0.0730  decode.d1.loss_mask: 0.7340  decode.d1.loss_dice: 0.5711  decode.d2.loss_cls: 0.0544  decode.d2.loss_mask: 0.7286  decode.d2.loss_dice: 0.5723  decode.d3.loss_cls: 0.0465  decode.d3.loss_mask: 0.7288  decode.d3.loss_dice: 0.5690  decode.d4.loss_cls: 0.0512  decode.d4.loss_mask: 0.7337  decode.d4.loss_dice: 0.5741  decode.d5.loss_cls: 0.0444  decode.d5.loss_mask: 0.7361  decode.d5.loss_dice: 0.5690  decode.d6.loss_cls: 0.0523  decode.d6.loss_mask: 0.7330  decode.d6.loss_dice: 0.5731  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.7300  decode.d7.loss_dice: 0.5706  decode.d8.loss_cls: 0.0472  decode.d8.loss_mask: 0.7361  decode.d8.loss_dice: 0.5709
06/01 14:04:53 - mmengine - INFO - Iter(train) [158750/160000]  base_lr: 1.2692e-06 lr: 1.2692e-07  eta: 0:34:37  time: 0.6421  data_time: 0.0107  memory: 10495  grad_norm: 249.4847  loss: 12.2469  decode.loss_cls: 0.0665  decode.loss_mask: 0.6902  decode.loss_dice: 0.4371  decode.d0.loss_cls: 0.4001  decode.d0.loss_mask: 0.6885  decode.d0.loss_dice: 0.4477  decode.d1.loss_cls: 0.0135  decode.d1.loss_mask: 0.7012  decode.d1.loss_dice: 0.4869  decode.d2.loss_cls: 0.0338  decode.d2.loss_mask: 0.6952  decode.d2.loss_dice: 0.4625  decode.d3.loss_cls: 0.0324  decode.d3.loss_mask: 0.6937  decode.d3.loss_dice: 0.4538  decode.d4.loss_cls: 0.0553  decode.d4.loss_mask: 0.6884  decode.d4.loss_dice: 0.4352  decode.d5.loss_cls: 0.0322  decode.d5.loss_mask: 0.6960  decode.d5.loss_dice: 0.4623  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.6911  decode.d6.loss_dice: 0.4327  decode.d7.loss_cls: 0.0357  decode.d7.loss_mask: 0.6998  decode.d7.loss_dice: 0.4651  decode.d8.loss_cls: 0.0656  decode.d8.loss_mask: 0.6910  decode.d8.loss_dice: 0.4378
06/01 14:05:25 - mmengine - INFO - Iter(train) [158800/160000]  base_lr: 1.2234e-06 lr: 1.2234e-07  eta: 0:33:09  time: 0.6426  data_time: 0.0106  memory: 10501  grad_norm: 308.7743  loss: 14.8593  decode.loss_cls: 0.0863  decode.loss_mask: 0.7807  decode.loss_dice: 0.5810  decode.d0.loss_cls: 0.4146  decode.d0.loss_mask: 0.7854  decode.d0.loss_dice: 0.5628  decode.d1.loss_cls: 0.1137  decode.d1.loss_mask: 0.7763  decode.d1.loss_dice: 0.5668  decode.d2.loss_cls: 0.1126  decode.d2.loss_mask: 0.7842  decode.d2.loss_dice: 0.5711  decode.d3.loss_cls: 0.1063  decode.d3.loss_mask: 0.7913  decode.d3.loss_dice: 0.5600  decode.d4.loss_cls: 0.1055  decode.d4.loss_mask: 0.7887  decode.d4.loss_dice: 0.5624  decode.d5.loss_cls: 0.1115  decode.d5.loss_mask: 0.7825  decode.d5.loss_dice: 0.5620  decode.d6.loss_cls: 0.1003  decode.d6.loss_mask: 0.7788  decode.d6.loss_dice: 0.5584  decode.d7.loss_cls: 0.1123  decode.d7.loss_mask: 0.7692  decode.d7.loss_dice: 0.5670  decode.d8.loss_cls: 0.1077  decode.d8.loss_mask: 0.7840  decode.d8.loss_dice: 0.5763
06/01 14:05:57 - mmengine - INFO - Iter(train) [158850/160000]  base_lr: 1.1774e-06 lr: 1.1774e-07  eta: 0:31:42  time: 0.6438  data_time: 0.0107  memory: 10496  grad_norm: 257.3091  loss: 12.7722  decode.loss_cls: 0.0288  decode.loss_mask: 0.7448  decode.loss_dice: 0.4570  decode.d0.loss_cls: 0.4498  decode.d0.loss_mask: 0.7556  decode.d0.loss_dice: 0.4429  decode.d1.loss_cls: 0.0546  decode.d1.loss_mask: 0.7438  decode.d1.loss_dice: 0.4563  decode.d2.loss_cls: 0.0330  decode.d2.loss_mask: 0.7421  decode.d2.loss_dice: 0.4574  decode.d3.loss_cls: 0.0347  decode.d3.loss_mask: 0.7395  decode.d3.loss_dice: 0.4537  decode.d4.loss_cls: 0.0351  decode.d4.loss_mask: 0.7373  decode.d4.loss_dice: 0.4523  decode.d5.loss_cls: 0.0389  decode.d5.loss_mask: 0.7423  decode.d5.loss_dice: 0.4516  decode.d6.loss_cls: 0.0419  decode.d6.loss_mask: 0.7430  decode.d6.loss_dice: 0.4532  decode.d7.loss_cls: 0.0439  decode.d7.loss_mask: 0.7415  decode.d7.loss_dice: 0.4551  decode.d8.loss_cls: 0.0473  decode.d8.loss_mask: 0.7415  decode.d8.loss_dice: 0.4531
06/01 14:06:29 - mmengine - INFO - Iter(train) [158900/160000]  base_lr: 1.1312e-06 lr: 1.1312e-07  eta: 0:30:15  time: 0.6419  data_time: 0.0106  memory: 10500  grad_norm: 677.1672  loss: 19.8643  decode.loss_cls: 0.1718  decode.loss_mask: 1.1068  decode.loss_dice: 0.6982  decode.d0.loss_cls: 0.6939  decode.d0.loss_mask: 0.9982  decode.d0.loss_dice: 0.6323  decode.d1.loss_cls: 0.2074  decode.d1.loss_mask: 1.0877  decode.d1.loss_dice: 0.6496  decode.d2.loss_cls: 0.2021  decode.d2.loss_mask: 1.0797  decode.d2.loss_dice: 0.6507  decode.d3.loss_cls: 0.1981  decode.d3.loss_mask: 1.0854  decode.d3.loss_dice: 0.6649  decode.d4.loss_cls: 0.1933  decode.d4.loss_mask: 1.0750  decode.d4.loss_dice: 0.6488  decode.d5.loss_cls: 0.1936  decode.d5.loss_mask: 1.0910  decode.d5.loss_dice: 0.6621  decode.d6.loss_cls: 0.1930  decode.d6.loss_mask: 1.1137  decode.d6.loss_dice: 0.6525  decode.d7.loss_cls: 0.2081  decode.d7.loss_mask: 1.0883  decode.d7.loss_dice: 0.6711  decode.d8.loss_cls: 0.2006  decode.d8.loss_mask: 1.0874  decode.d8.loss_dice: 0.6587
06/01 14:07:01 - mmengine - INFO - Iter(train) [158950/160000]  base_lr: 1.0848e-06 lr: 1.0848e-07  eta: 0:28:49  time: 0.6429  data_time: 0.0107  memory: 10504  grad_norm: 255.5610  loss: 14.7168  decode.loss_cls: 0.0967  decode.loss_mask: 0.7707  decode.loss_dice: 0.5968  decode.d0.loss_cls: 0.4834  decode.d0.loss_mask: 0.7373  decode.d0.loss_dice: 0.5785  decode.d1.loss_cls: 0.0854  decode.d1.loss_mask: 0.7777  decode.d1.loss_dice: 0.5870  decode.d2.loss_cls: 0.0830  decode.d2.loss_mask: 0.7687  decode.d2.loss_dice: 0.5815  decode.d3.loss_cls: 0.0846  decode.d3.loss_mask: 0.7665  decode.d3.loss_dice: 0.5838  decode.d4.loss_cls: 0.0889  decode.d4.loss_mask: 0.7664  decode.d4.loss_dice: 0.5769  decode.d5.loss_cls: 0.0798  decode.d5.loss_mask: 0.7620  decode.d5.loss_dice: 0.5777  decode.d6.loss_cls: 0.0835  decode.d6.loss_mask: 0.7743  decode.d6.loss_dice: 0.5814  decode.d7.loss_cls: 0.0841  decode.d7.loss_mask: 0.7608  decode.d7.loss_dice: 0.5758  decode.d8.loss_cls: 0.0761  decode.d8.loss_mask: 0.7587  decode.d8.loss_dice: 0.5886
06/01 14:07:33 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 14:07:33 - mmengine - INFO - Iter(train) [159000/160000]  base_lr: 1.0382e-06 lr: 1.0382e-07  eta: 0:27:23  time: 0.6421  data_time: 0.0106  memory: 10509  grad_norm: 384.0301  loss: 14.9113  decode.loss_cls: 0.0916  decode.loss_mask: 0.7411  decode.loss_dice: 0.6074  decode.d0.loss_cls: 0.6153  decode.d0.loss_mask: 0.7127  decode.d0.loss_dice: 0.5701  decode.d1.loss_cls: 0.1017  decode.d1.loss_mask: 0.7527  decode.d1.loss_dice: 0.5969  decode.d2.loss_cls: 0.1206  decode.d2.loss_mask: 0.7480  decode.d2.loss_dice: 0.5958  decode.d3.loss_cls: 0.1062  decode.d3.loss_mask: 0.7388  decode.d3.loss_dice: 0.5888  decode.d4.loss_cls: 0.1172  decode.d4.loss_mask: 0.7393  decode.d4.loss_dice: 0.5873  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.7456  decode.d5.loss_dice: 0.6024  decode.d6.loss_cls: 0.1099  decode.d6.loss_mask: 0.7381  decode.d6.loss_dice: 0.6004  decode.d7.loss_cls: 0.0958  decode.d7.loss_mask: 0.7490  decode.d7.loss_dice: 0.6040  decode.d8.loss_cls: 0.1159  decode.d8.loss_mask: 0.7448  decode.d8.loss_dice: 0.5962
06/01 14:08:06 - mmengine - INFO - Iter(train) [159050/160000]  base_lr: 9.9139e-07 lr: 9.9139e-08  eta: 0:25:57  time: 0.6428  data_time: 0.0106  memory: 10503  grad_norm: 367.6184  loss: 14.5485  decode.loss_cls: 0.0639  decode.loss_mask: 0.7757  decode.loss_dice: 0.5723  decode.d0.loss_cls: 0.5563  decode.d0.loss_mask: 0.7580  decode.d0.loss_dice: 0.5567  decode.d1.loss_cls: 0.0743  decode.d1.loss_mask: 0.7883  decode.d1.loss_dice: 0.6003  decode.d2.loss_cls: 0.1007  decode.d2.loss_mask: 0.7198  decode.d2.loss_dice: 0.5644  decode.d3.loss_cls: 0.1087  decode.d3.loss_mask: 0.7252  decode.d3.loss_dice: 0.5558  decode.d4.loss_cls: 0.0892  decode.d4.loss_mask: 0.7704  decode.d4.loss_dice: 0.5669  decode.d5.loss_cls: 0.0870  decode.d5.loss_mask: 0.7797  decode.d5.loss_dice: 0.5638  decode.d6.loss_cls: 0.0747  decode.d6.loss_mask: 0.7382  decode.d6.loss_dice: 0.5681  decode.d7.loss_cls: 0.0980  decode.d7.loss_mask: 0.7259  decode.d7.loss_dice: 0.5404  decode.d8.loss_cls: 0.0712  decode.d8.loss_mask: 0.7875  decode.d8.loss_dice: 0.5669
06/01 14:08:38 - mmengine - INFO - Iter(train) [159100/160000]  base_lr: 9.4431e-07 lr: 9.4431e-08  eta: 0:24:32  time: 0.6427  data_time: 0.0107  memory: 10492  grad_norm: 314.5346  loss: 15.6705  decode.loss_cls: 0.1195  decode.loss_mask: 0.8002  decode.loss_dice: 0.5715  decode.d0.loss_cls: 0.4984  decode.d0.loss_mask: 0.7830  decode.d0.loss_dice: 0.5734  decode.d1.loss_cls: 0.1134  decode.d1.loss_mask: 0.8391  decode.d1.loss_dice: 0.6031  decode.d2.loss_cls: 0.1450  decode.d2.loss_mask: 0.8066  decode.d2.loss_dice: 0.5716  decode.d3.loss_cls: 0.1446  decode.d3.loss_mask: 0.8053  decode.d3.loss_dice: 0.5683  decode.d4.loss_cls: 0.1142  decode.d4.loss_mask: 0.8506  decode.d4.loss_dice: 0.6067  decode.d5.loss_cls: 0.1152  decode.d5.loss_mask: 0.8468  decode.d5.loss_dice: 0.6103  decode.d6.loss_cls: 0.1500  decode.d6.loss_mask: 0.8162  decode.d6.loss_dice: 0.5726  decode.d7.loss_cls: 0.1339  decode.d7.loss_mask: 0.8078  decode.d7.loss_dice: 0.5748  decode.d8.loss_cls: 0.1408  decode.d8.loss_mask: 0.8121  decode.d8.loss_dice: 0.5757
06/01 14:09:10 - mmengine - INFO - Iter(train) [159150/160000]  base_lr: 8.9696e-07 lr: 8.9696e-08  eta: 0:23:07  time: 0.6430  data_time: 0.0106  memory: 10492  grad_norm: 213.3189  loss: 14.7435  decode.loss_cls: 0.1034  decode.loss_mask: 0.7634  decode.loss_dice: 0.5771  decode.d0.loss_cls: 0.5370  decode.d0.loss_mask: 0.7529  decode.d0.loss_dice: 0.5880  decode.d1.loss_cls: 0.1229  decode.d1.loss_mask: 0.7407  decode.d1.loss_dice: 0.5782  decode.d2.loss_cls: 0.1043  decode.d2.loss_mask: 0.7387  decode.d2.loss_dice: 0.5638  decode.d3.loss_cls: 0.1176  decode.d3.loss_mask: 0.7398  decode.d3.loss_dice: 0.5737  decode.d4.loss_cls: 0.1108  decode.d4.loss_mask: 0.7433  decode.d4.loss_dice: 0.5686  decode.d5.loss_cls: 0.1086  decode.d5.loss_mask: 0.7335  decode.d5.loss_dice: 0.5621  decode.d6.loss_cls: 0.1131  decode.d6.loss_mask: 0.7353  decode.d6.loss_dice: 0.5592  decode.d7.loss_cls: 0.1086  decode.d7.loss_mask: 0.7596  decode.d7.loss_dice: 0.5855  decode.d8.loss_cls: 0.1129  decode.d8.loss_mask: 0.7620  decode.d8.loss_dice: 0.5788
06/01 14:09:42 - mmengine - INFO - Iter(train) [159200/160000]  base_lr: 8.4933e-07 lr: 8.4933e-08  eta: 0:21:43  time: 0.6377  data_time: 0.0105  memory: 10494  grad_norm: 241.8511  loss: 13.5693  decode.loss_cls: 0.0084  decode.loss_mask: 0.8026  decode.loss_dice: 0.5103  decode.d0.loss_cls: 0.4098  decode.d0.loss_mask: 0.7770  decode.d0.loss_dice: 0.4940  decode.d1.loss_cls: 0.0120  decode.d1.loss_mask: 0.7996  decode.d1.loss_dice: 0.5111  decode.d2.loss_cls: 0.0094  decode.d2.loss_mask: 0.8009  decode.d2.loss_dice: 0.5061  decode.d3.loss_cls: 0.0089  decode.d3.loss_mask: 0.8002  decode.d3.loss_dice: 0.5099  decode.d4.loss_cls: 0.0100  decode.d4.loss_mask: 0.8024  decode.d4.loss_dice: 0.5088  decode.d5.loss_cls: 0.0101  decode.d5.loss_mask: 0.8077  decode.d5.loss_dice: 0.5106  decode.d6.loss_cls: 0.0098  decode.d6.loss_mask: 0.8005  decode.d6.loss_dice: 0.5068  decode.d7.loss_cls: 0.0090  decode.d7.loss_mask: 0.8007  decode.d7.loss_dice: 0.5076  decode.d8.loss_cls: 0.0086  decode.d8.loss_mask: 0.8053  decode.d8.loss_dice: 0.5112
06/01 14:10:14 - mmengine - INFO - Iter(train) [159250/160000]  base_lr: 8.0140e-07 lr: 8.0140e-08  eta: 0:20:19  time: 0.6426  data_time: 0.0107  memory: 10504  grad_norm: 361.6473  loss: 13.4316  decode.loss_cls: 0.0847  decode.loss_mask: 0.7555  decode.loss_dice: 0.4904  decode.d0.loss_cls: 0.4927  decode.d0.loss_mask: 0.7222  decode.d0.loss_dice: 0.4841  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 0.7627  decode.d1.loss_dice: 0.4920  decode.d2.loss_cls: 0.0489  decode.d2.loss_mask: 0.7628  decode.d2.loss_dice: 0.4896  decode.d3.loss_cls: 0.0476  decode.d3.loss_mask: 0.7541  decode.d3.loss_dice: 0.4873  decode.d4.loss_cls: 0.0425  decode.d4.loss_mask: 0.7601  decode.d4.loss_dice: 0.4990  decode.d5.loss_cls: 0.0534  decode.d5.loss_mask: 0.7596  decode.d5.loss_dice: 0.4914  decode.d6.loss_cls: 0.0504  decode.d6.loss_mask: 0.7509  decode.d6.loss_dice: 0.4878  decode.d7.loss_cls: 0.0494  decode.d7.loss_mask: 0.7557  decode.d7.loss_dice: 0.4838  decode.d8.loss_cls: 0.0496  decode.d8.loss_mask: 0.7567  decode.d8.loss_dice: 0.5014
06/01 14:10:46 - mmengine - INFO - Iter(train) [159300/160000]  base_lr: 7.5315e-07 lr: 7.5315e-08  eta: 0:18:55  time: 0.6415  data_time: 0.0106  memory: 10509  grad_norm: 245.0856  loss: 12.1744  decode.loss_cls: 0.0821  decode.loss_mask: 0.6602  decode.loss_dice: 0.4400  decode.d0.loss_cls: 0.4324  decode.d0.loss_mask: 0.6663  decode.d0.loss_dice: 0.4413  decode.d1.loss_cls: 0.0867  decode.d1.loss_mask: 0.6541  decode.d1.loss_dice: 0.4382  decode.d2.loss_cls: 0.0855  decode.d2.loss_mask: 0.6657  decode.d2.loss_dice: 0.4452  decode.d3.loss_cls: 0.0912  decode.d3.loss_mask: 0.6505  decode.d3.loss_dice: 0.4312  decode.d4.loss_cls: 0.0807  decode.d4.loss_mask: 0.6590  decode.d4.loss_dice: 0.4311  decode.d5.loss_cls: 0.0922  decode.d5.loss_mask: 0.6565  decode.d5.loss_dice: 0.4339  decode.d6.loss_cls: 0.0969  decode.d6.loss_mask: 0.6505  decode.d6.loss_dice: 0.4379  decode.d7.loss_cls: 0.0908  decode.d7.loss_mask: 0.6471  decode.d7.loss_dice: 0.4406  decode.d8.loss_cls: 0.1002  decode.d8.loss_mask: 0.6537  decode.d8.loss_dice: 0.4327
06/01 14:11:19 - mmengine - INFO - Iter(train) [159350/160000]  base_lr: 7.0456e-07 lr: 7.0456e-08  eta: 0:17:32  time: 0.6428  data_time: 0.0107  memory: 10495  grad_norm: 1267.4390  loss: 15.8086  decode.loss_cls: 0.1692  decode.loss_mask: 0.7762  decode.loss_dice: 0.5502  decode.d0.loss_cls: 0.6519  decode.d0.loss_mask: 0.7761  decode.d0.loss_dice: 0.5555  decode.d1.loss_cls: 0.2367  decode.d1.loss_mask: 0.7740  decode.d1.loss_dice: 0.5578  decode.d2.loss_cls: 0.2202  decode.d2.loss_mask: 0.7769  decode.d2.loss_dice: 0.5543  decode.d3.loss_cls: 0.2041  decode.d3.loss_mask: 0.7730  decode.d3.loss_dice: 0.5482  decode.d4.loss_cls: 0.1930  decode.d4.loss_mask: 0.7676  decode.d4.loss_dice: 0.5631  decode.d5.loss_cls: 0.1817  decode.d5.loss_mask: 0.7818  decode.d5.loss_dice: 0.5578  decode.d6.loss_cls: 0.2107  decode.d6.loss_mask: 0.7800  decode.d6.loss_dice: 0.5547  decode.d7.loss_cls: 0.1873  decode.d7.loss_mask: 0.7859  decode.d7.loss_dice: 0.5578  decode.d8.loss_cls: 0.2052  decode.d8.loss_mask: 0.7813  decode.d8.loss_dice: 0.5761
06/01 14:11:51 - mmengine - INFO - Iter(train) [159400/160000]  base_lr: 6.5559e-07 lr: 6.5559e-08  eta: 0:16:09  time: 0.6421  data_time: 0.0106  memory: 10495  grad_norm: 235.0891  loss: 11.5270  decode.loss_cls: 0.0233  decode.loss_mask: 0.6316  decode.loss_dice: 0.4515  decode.d0.loss_cls: 0.3969  decode.d0.loss_mask: 0.6291  decode.d0.loss_dice: 0.4539  decode.d1.loss_cls: 0.0389  decode.d1.loss_mask: 0.6306  decode.d1.loss_dice: 0.4460  decode.d2.loss_cls: 0.0428  decode.d2.loss_mask: 0.6361  decode.d2.loss_dice: 0.4511  decode.d3.loss_cls: 0.0281  decode.d3.loss_mask: 0.6287  decode.d3.loss_dice: 0.4416  decode.d4.loss_cls: 0.0374  decode.d4.loss_mask: 0.6327  decode.d4.loss_dice: 0.4556  decode.d5.loss_cls: 0.0327  decode.d5.loss_mask: 0.6309  decode.d5.loss_dice: 0.4533  decode.d6.loss_cls: 0.0228  decode.d6.loss_mask: 0.6332  decode.d6.loss_dice: 0.4526  decode.d7.loss_cls: 0.0369  decode.d7.loss_mask: 0.6293  decode.d7.loss_dice: 0.4529  decode.d8.loss_cls: 0.0343  decode.d8.loss_mask: 0.6366  decode.d8.loss_dice: 0.4558
06/01 14:12:23 - mmengine - INFO - Iter(train) [159450/160000]  base_lr: 6.0621e-07 lr: 6.0621e-08  eta: 0:14:46  time: 0.6422  data_time: 0.0110  memory: 10500  grad_norm: 239.3495  loss: 15.8479  decode.loss_cls: 0.1238  decode.loss_mask: 0.7887  decode.loss_dice: 0.5926  decode.d0.loss_cls: 0.6449  decode.d0.loss_mask: 0.7714  decode.d0.loss_dice: 0.5822  decode.d1.loss_cls: 0.1353  decode.d1.loss_mask: 0.7946  decode.d1.loss_dice: 0.6299  decode.d2.loss_cls: 0.1259  decode.d2.loss_mask: 0.8010  decode.d2.loss_dice: 0.5951  decode.d3.loss_cls: 0.1353  decode.d3.loss_mask: 0.7969  decode.d3.loss_dice: 0.5979  decode.d4.loss_cls: 0.1271  decode.d4.loss_mask: 0.7985  decode.d4.loss_dice: 0.5961  decode.d5.loss_cls: 0.1206  decode.d5.loss_mask: 0.8018  decode.d5.loss_dice: 0.5939  decode.d6.loss_cls: 0.1320  decode.d6.loss_mask: 0.8046  decode.d6.loss_dice: 0.6445  decode.d7.loss_cls: 0.1464  decode.d7.loss_mask: 0.7969  decode.d7.loss_dice: 0.6030  decode.d8.loss_cls: 0.1474  decode.d8.loss_mask: 0.8068  decode.d8.loss_dice: 0.6127
06/01 14:12:55 - mmengine - INFO - Iter(train) [159500/160000]  base_lr: 5.5637e-07 lr: 5.5637e-08  eta: 0:13:24  time: 0.6422  data_time: 0.0107  memory: 10491  grad_norm: 542.2446  loss: 17.4235  decode.loss_cls: 0.1250  decode.loss_mask: 0.9240  decode.loss_dice: 0.6283  decode.d0.loss_cls: 0.5713  decode.d0.loss_mask: 0.9070  decode.d0.loss_dice: 0.6197  decode.d1.loss_cls: 0.1767  decode.d1.loss_mask: 0.9353  decode.d1.loss_dice: 0.6197  decode.d2.loss_cls: 0.1376  decode.d2.loss_mask: 0.9273  decode.d2.loss_dice: 0.6200  decode.d3.loss_cls: 0.1663  decode.d3.loss_mask: 0.9274  decode.d3.loss_dice: 0.6227  decode.d4.loss_cls: 0.1771  decode.d4.loss_mask: 0.9122  decode.d4.loss_dice: 0.6077  decode.d5.loss_cls: 0.1493  decode.d5.loss_mask: 0.9354  decode.d5.loss_dice: 0.6340  decode.d6.loss_cls: 0.1414  decode.d6.loss_mask: 0.9404  decode.d6.loss_dice: 0.6365  decode.d7.loss_cls: 0.1577  decode.d7.loss_mask: 0.9305  decode.d7.loss_dice: 0.6170  decode.d8.loss_cls: 0.1210  decode.d8.loss_mask: 0.9249  decode.d8.loss_dice: 0.6300
06/01 14:13:27 - mmengine - INFO - Iter(train) [159550/160000]  base_lr: 5.0604e-07 lr: 5.0604e-08  eta: 0:12:02  time: 0.6455  data_time: 0.0109  memory: 10492  grad_norm: 682.4126  loss: 16.1839  decode.loss_cls: 0.1137  decode.loss_mask: 0.9346  decode.loss_dice: 0.5850  decode.d0.loss_cls: 0.6511  decode.d0.loss_mask: 0.7900  decode.d0.loss_dice: 0.5790  decode.d1.loss_cls: 0.0988  decode.d1.loss_mask: 0.8916  decode.d1.loss_dice: 0.6254  decode.d2.loss_cls: 0.1209  decode.d2.loss_mask: 0.8672  decode.d2.loss_dice: 0.5972  decode.d3.loss_cls: 0.1390  decode.d3.loss_mask: 0.8404  decode.d3.loss_dice: 0.5869  decode.d4.loss_cls: 0.1124  decode.d4.loss_mask: 0.8366  decode.d4.loss_dice: 0.5962  decode.d5.loss_cls: 0.1062  decode.d5.loss_mask: 0.8399  decode.d5.loss_dice: 0.5894  decode.d6.loss_cls: 0.0976  decode.d6.loss_mask: 0.8482  decode.d6.loss_dice: 0.5799  decode.d7.loss_cls: 0.1074  decode.d7.loss_mask: 0.8667  decode.d7.loss_dice: 0.5963  decode.d8.loss_cls: 0.1208  decode.d8.loss_mask: 0.8638  decode.d8.loss_dice: 0.6016
06/01 14:14:00 - mmengine - INFO - Iter(train) [159600/160000]  base_lr: 4.5514e-07 lr: 4.5514e-08  eta: 0:10:40  time: 0.6429  data_time: 0.0107  memory: 10501  grad_norm: 282.6031  loss: 14.5473  decode.loss_cls: 0.1166  decode.loss_mask: 0.7262  decode.loss_dice: 0.5409  decode.d0.loss_cls: 0.5099  decode.d0.loss_mask: 0.7182  decode.d0.loss_dice: 0.5744  decode.d1.loss_cls: 0.1147  decode.d1.loss_mask: 0.7395  decode.d1.loss_dice: 0.5621  decode.d2.loss_cls: 0.1533  decode.d2.loss_mask: 0.7367  decode.d2.loss_dice: 0.5515  decode.d3.loss_cls: 0.0991  decode.d3.loss_mask: 0.7355  decode.d3.loss_dice: 0.5541  decode.d4.loss_cls: 0.1177  decode.d4.loss_mask: 0.7393  decode.d4.loss_dice: 0.5608  decode.d5.loss_cls: 0.1271  decode.d5.loss_mask: 0.7394  decode.d5.loss_dice: 0.5580  decode.d6.loss_cls: 0.0964  decode.d6.loss_mask: 0.7427  decode.d6.loss_dice: 0.5546  decode.d7.loss_cls: 0.1534  decode.d7.loss_mask: 0.7288  decode.d7.loss_dice: 0.5683  decode.d8.loss_cls: 0.1337  decode.d8.loss_mask: 0.7360  decode.d8.loss_dice: 0.5584
06/01 14:14:32 - mmengine - INFO - Iter(train) [159650/160000]  base_lr: 4.0360e-07 lr: 4.0360e-08  eta: 0:09:19  time: 0.6449  data_time: 0.0115  memory: 10495  grad_norm: 433.8346  loss: 15.6597  decode.loss_cls: 0.1268  decode.loss_mask: 0.7852  decode.loss_dice: 0.6091  decode.d0.loss_cls: 0.5103  decode.d0.loss_mask: 0.7806  decode.d0.loss_dice: 0.6412  decode.d1.loss_cls: 0.1306  decode.d1.loss_mask: 0.7780  decode.d1.loss_dice: 0.6242  decode.d2.loss_cls: 0.1470  decode.d2.loss_mask: 0.7646  decode.d2.loss_dice: 0.6352  decode.d3.loss_cls: 0.1305  decode.d3.loss_mask: 0.7719  decode.d3.loss_dice: 0.6165  decode.d4.loss_cls: 0.1312  decode.d4.loss_mask: 0.7730  decode.d4.loss_dice: 0.6162  decode.d5.loss_cls: 0.1270  decode.d5.loss_mask: 0.7692  decode.d5.loss_dice: 0.6186  decode.d6.loss_cls: 0.1304  decode.d6.loss_mask: 0.7807  decode.d6.loss_dice: 0.6241  decode.d7.loss_cls: 0.1222  decode.d7.loss_mask: 0.7754  decode.d7.loss_dice: 0.6156  decode.d8.loss_cls: 0.1179  decode.d8.loss_mask: 0.7771  decode.d8.loss_dice: 0.6293
06/01 14:15:04 - mmengine - INFO - Iter(train) [159700/160000]  base_lr: 3.5132e-07 lr: 3.5132e-08  eta: 0:07:58  time: 0.6416  data_time: 0.0106  memory: 10496  grad_norm: 457.5817  loss: 16.3811  decode.loss_cls: 0.1114  decode.loss_mask: 0.8106  decode.loss_dice: 0.6390  decode.d0.loss_cls: 0.7001  decode.d0.loss_mask: 0.8286  decode.d0.loss_dice: 0.6452  decode.d1.loss_cls: 0.1520  decode.d1.loss_mask: 0.8184  decode.d1.loss_dice: 0.6389  decode.d2.loss_cls: 0.1141  decode.d2.loss_mask: 0.8188  decode.d2.loss_dice: 0.6505  decode.d3.loss_cls: 0.1224  decode.d3.loss_mask: 0.8254  decode.d3.loss_dice: 0.6410  decode.d4.loss_cls: 0.1270  decode.d4.loss_mask: 0.8155  decode.d4.loss_dice: 0.6413  decode.d5.loss_cls: 0.1097  decode.d5.loss_mask: 0.8147  decode.d5.loss_dice: 0.6460  decode.d6.loss_cls: 0.1145  decode.d6.loss_mask: 0.8100  decode.d6.loss_dice: 0.6340  decode.d7.loss_cls: 0.1193  decode.d7.loss_mask: 0.8120  decode.d7.loss_dice: 0.6422  decode.d8.loss_cls: 0.1285  decode.d8.loss_mask: 0.8126  decode.d8.loss_dice: 0.6375
06/01 14:15:36 - mmengine - INFO - Iter(train) [159750/160000]  base_lr: 2.9815e-07 lr: 2.9815e-08  eta: 0:06:38  time: 0.6444  data_time: 0.0107  memory: 10492  grad_norm: 268.2122  loss: 13.2615  decode.loss_cls: 0.0684  decode.loss_mask: 0.6635  decode.loss_dice: 0.5422  decode.d0.loss_cls: 0.4869  decode.d0.loss_mask: 0.6755  decode.d0.loss_dice: 0.5688  decode.d1.loss_cls: 0.1017  decode.d1.loss_mask: 0.6620  decode.d1.loss_dice: 0.5416  decode.d2.loss_cls: 0.0489  decode.d2.loss_mask: 0.6639  decode.d2.loss_dice: 0.5574  decode.d3.loss_cls: 0.0640  decode.d3.loss_mask: 0.6669  decode.d3.loss_dice: 0.5429  decode.d4.loss_cls: 0.0860  decode.d4.loss_mask: 0.6631  decode.d4.loss_dice: 0.5436  decode.d5.loss_cls: 0.0681  decode.d5.loss_mask: 0.6619  decode.d5.loss_dice: 0.5412  decode.d6.loss_cls: 0.0489  decode.d6.loss_mask: 0.6656  decode.d6.loss_dice: 0.5409  decode.d7.loss_cls: 0.0860  decode.d7.loss_mask: 0.6696  decode.d7.loss_dice: 0.5396  decode.d8.loss_cls: 0.0841  decode.d8.loss_mask: 0.6653  decode.d8.loss_dice: 0.5430
06/01 14:16:08 - mmengine - INFO - Iter(train) [159800/160000]  base_lr: 2.4391e-07 lr: 2.4391e-08  eta: 0:05:17  time: 0.6442  data_time: 0.0107  memory: 10509  grad_norm: 290.5451  loss: 13.7683  decode.loss_cls: 0.0997  decode.loss_mask: 0.7479  decode.loss_dice: 0.4734  decode.d0.loss_cls: 0.4903  decode.d0.loss_mask: 0.7570  decode.d0.loss_dice: 0.5076  decode.d1.loss_cls: 0.1021  decode.d1.loss_mask: 0.7531  decode.d1.loss_dice: 0.4974  decode.d2.loss_cls: 0.1011  decode.d2.loss_mask: 0.7441  decode.d2.loss_dice: 0.4909  decode.d3.loss_cls: 0.1082  decode.d3.loss_mask: 0.7428  decode.d3.loss_dice: 0.4824  decode.d4.loss_cls: 0.0965  decode.d4.loss_mask: 0.7458  decode.d4.loss_dice: 0.4858  decode.d5.loss_cls: 0.0954  decode.d5.loss_mask: 0.7535  decode.d5.loss_dice: 0.4931  decode.d6.loss_cls: 0.1006  decode.d6.loss_mask: 0.7458  decode.d6.loss_dice: 0.4741  decode.d7.loss_cls: 0.1040  decode.d7.loss_mask: 0.7471  decode.d7.loss_dice: 0.4853  decode.d8.loss_cls: 0.1070  decode.d8.loss_mask: 0.7492  decode.d8.loss_dice: 0.4872
06/01 14:16:41 - mmengine - INFO - Iter(train) [159850/160000]  base_lr: 1.8827e-07 lr: 1.8827e-08  eta: 0:03:57  time: 0.6429  data_time: 0.0106  memory: 10509  grad_norm: 246.1514  loss: 12.9802  decode.loss_cls: 0.0391  decode.loss_mask: 0.7069  decode.loss_dice: 0.5071  decode.d0.loss_cls: 0.4924  decode.d0.loss_mask: 0.7007  decode.d0.loss_dice: 0.5089  decode.d1.loss_cls: 0.0621  decode.d1.loss_mask: 0.6996  decode.d1.loss_dice: 0.4999  decode.d2.loss_cls: 0.0500  decode.d2.loss_mask: 0.7009  decode.d2.loss_dice: 0.5078  decode.d3.loss_cls: 0.0346  decode.d3.loss_mask: 0.7098  decode.d3.loss_dice: 0.5026  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 0.7034  decode.d4.loss_dice: 0.5007  decode.d5.loss_cls: 0.0351  decode.d5.loss_mask: 0.7020  decode.d5.loss_dice: 0.5043  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 0.7032  decode.d6.loss_dice: 0.5046  decode.d7.loss_cls: 0.0600  decode.d7.loss_mask: 0.7002  decode.d7.loss_dice: 0.4972  decode.d8.loss_cls: 0.0509  decode.d8.loss_mask: 0.7018  decode.d8.loss_dice: 0.5016
06/01 14:17:13 - mmengine - INFO - Iter(train) [159900/160000]  base_lr: 1.3071e-07 lr: 1.3071e-08  eta: 0:02:38  time: 0.6438  data_time: 0.0107  memory: 10495  grad_norm: 796.2570  loss: 16.8856  decode.loss_cls: 0.1659  decode.loss_mask: 0.8791  decode.loss_dice: 0.6553  decode.d0.loss_cls: 0.6829  decode.d0.loss_mask: 0.8007  decode.d0.loss_dice: 0.5916  decode.d1.loss_cls: 0.1735  decode.d1.loss_mask: 0.8540  decode.d1.loss_dice: 0.6264  decode.d2.loss_cls: 0.1511  decode.d2.loss_mask: 0.8268  decode.d2.loss_dice: 0.6143  decode.d3.loss_cls: 0.1707  decode.d3.loss_mask: 0.8397  decode.d3.loss_dice: 0.6114  decode.d4.loss_cls: 0.1606  decode.d4.loss_mask: 0.8495  decode.d4.loss_dice: 0.6613  decode.d5.loss_cls: 0.1600  decode.d5.loss_mask: 0.8539  decode.d5.loss_dice: 0.6282  decode.d6.loss_cls: 0.1841  decode.d6.loss_mask: 0.8408  decode.d6.loss_dice: 0.6110  decode.d7.loss_cls: 0.1656  decode.d7.loss_mask: 0.8599  decode.d7.loss_dice: 0.6006  decode.d8.loss_cls: 0.1953  decode.d8.loss_mask: 0.8486  decode.d8.loss_dice: 0.6227
06/01 14:17:45 - mmengine - INFO - Iter(train) [159950/160000]  base_lr: 7.0043e-08 lr: 7.0043e-09  eta: 0:01:18  time: 0.6447  data_time: 0.0107  memory: 10494  grad_norm: 214.9499  loss: 13.5242  decode.loss_cls: 0.0943  decode.loss_mask: 0.6861  decode.loss_dice: 0.5026  decode.d0.loss_cls: 0.5235  decode.d0.loss_mask: 0.6915  decode.d0.loss_dice: 0.5052  decode.d1.loss_cls: 0.1039  decode.d1.loss_mask: 0.6840  decode.d1.loss_dice: 0.5049  decode.d2.loss_cls: 0.0653  decode.d2.loss_mask: 0.7144  decode.d2.loss_dice: 0.5110  decode.d3.loss_cls: 0.0850  decode.d3.loss_mask: 0.7284  decode.d3.loss_dice: 0.5328  decode.d4.loss_cls: 0.0950  decode.d4.loss_mask: 0.7219  decode.d4.loss_dice: 0.5239  decode.d5.loss_cls: 0.0897  decode.d5.loss_mask: 0.7055  decode.d5.loss_dice: 0.5098  decode.d6.loss_cls: 0.0804  decode.d6.loss_mask: 0.7116  decode.d6.loss_dice: 0.5156  decode.d7.loss_cls: 0.1000  decode.d7.loss_mask: 0.7171  decode.d7.loss_dice: 0.5021  decode.d8.loss_cls: 0.1356  decode.d8.loss_mask: 0.6834  decode.d8.loss_dice: 0.4997
06/01 14:18:18 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-160k_voc12aug-512x512_20240601_073835
06/01 14:18:18 - mmengine - INFO - Iter(train) [160000/160000]  base_lr: 0.0000e+00 lr: 0.0000e+00  eta: 0:00:00  time: 0.6440  data_time: 0.0107  memory: 10509  grad_norm: 509.6676  loss: 17.2172  decode.loss_cls: 0.1121  decode.loss_mask: 0.8920  decode.loss_dice: 0.6711  decode.d0.loss_cls: 0.5636  decode.d0.loss_mask: 0.8593  decode.d0.loss_dice: 0.6356  decode.d1.loss_cls: 0.1271  decode.d1.loss_mask: 0.9091  decode.d1.loss_dice: 0.6650  decode.d2.loss_cls: 0.1029  decode.d2.loss_mask: 0.9272  decode.d2.loss_dice: 0.6808  decode.d3.loss_cls: 0.0964  decode.d3.loss_mask: 0.9054  decode.d3.loss_dice: 0.6722  decode.d4.loss_cls: 0.0909  decode.d4.loss_mask: 0.9004  decode.d4.loss_dice: 0.6674  decode.d5.loss_cls: 0.1015  decode.d5.loss_mask: 0.9046  decode.d5.loss_dice: 0.6711  decode.d6.loss_cls: 0.1038  decode.d6.loss_mask: 0.8969  decode.d6.loss_dice: 0.6801  decode.d7.loss_cls: 0.1131  decode.d7.loss_mask: 0.9086  decode.d7.loss_dice: 0.6770  decode.d8.loss_cls: 0.1188  decode.d8.loss_mask: 0.9048  decode.d8.loss_dice: 0.6582
06/01 14:18:18 - mmengine - INFO - Saving checkpoint at 160000 iterations
06/01 14:18:26 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:57  time: 0.0736  data_time: 0.0013  memory: 2320  
06/01 14:18:29 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:45  time: 0.0730  data_time: 0.0013  memory: 2133  
06/01 14:18:33 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:41  time: 0.0774  data_time: 0.0013  memory: 2529  
06/01 14:18:37 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:35  time: 0.0737  data_time: 0.0013  memory: 2230  
06/01 14:18:41 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:01:31  time: 0.0756  data_time: 0.0031  memory: 2230  
06/01 14:18:44 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:01:26  time: 0.0731  data_time: 0.0013  memory: 2215  
06/01 14:18:48 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:01:22  time: 0.0733  data_time: 0.0013  memory: 2152  
06/01 14:18:52 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:01:18  time: 0.0756  data_time: 0.0013  memory: 2231  
06/01 14:18:55 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:01:14  time: 0.0722  data_time: 0.0013  memory: 2230  
06/01 14:18:59 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:01:11  time: 0.0787  data_time: 0.0013  memory: 2662  
06/01 14:19:03 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:01:07  time: 0.0732  data_time: 0.0013  memory: 2264  
06/01 14:19:07 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:01:03  time: 0.0734  data_time: 0.0013  memory: 2230  
06/01 14:19:10 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:59  time: 0.0752  data_time: 0.0013  memory: 2133  
06/01 14:19:14 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:55  time: 0.0754  data_time: 0.0013  memory: 2245  
06/01 14:19:18 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:52  time: 0.0724  data_time: 0.0013  memory: 2215  
06/01 14:19:21 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:48  time: 0.0799  data_time: 0.0013  memory: 2339  
06/01 14:19:25 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:44  time: 0.0723  data_time: 0.0013  memory: 2215  
06/01 14:19:29 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:40  time: 0.0744  data_time: 0.0013  memory: 2133  
06/01 14:19:32 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:37  time: 0.0745  data_time: 0.0013  memory: 2133  
06/01 14:19:36 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:33  time: 0.0730  data_time: 0.0013  memory: 2264  
06/01 14:19:40 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:29  time: 0.0729  data_time: 0.0013  memory: 2171  
06/01 14:19:44 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:25  time: 0.0770  data_time: 0.0013  memory: 2433  
06/01 14:19:47 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:22  time: 0.0727  data_time: 0.0013  memory: 2190  
06/01 14:19:51 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:18  time: 0.0743  data_time: 0.0013  memory: 2230  
06/01 14:19:55 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:14  time: 0.0730  data_time: 0.0013  memory: 2379  
06/01 14:19:58 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:11  time: 0.0725  data_time: 0.0013  memory: 2230  
06/01 14:20:02 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:07  time: 0.0762  data_time: 0.0013  memory: 2215  
06/01 14:20:06 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:03  time: 0.0730  data_time: 0.0013  memory: 2133  
06/01 14:20:09 - mmengine - INFO - per class results:
06/01 14:20:09 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 96.32 | 98.01 |
|  aeroplane  |  93.9 |  99.1 |
|   bicycle   | 47.73 | 96.57 |
|     bird    | 96.43 |  98.5 |
|     boat    | 71.38 | 88.76 |
|    bottle   | 87.76 | 96.69 |
|     bus     | 96.84 | 98.42 |
|     car     | 91.38 | 95.85 |
|     cat     |  96.0 | 98.11 |
|    chair    |  44.6 | 62.81 |
|     cow     | 91.47 | 93.57 |
| diningtable | 65.09 | 69.41 |
|     dog     | 94.37 | 98.61 |
|    horse    | 88.18 | 95.74 |
|  motorbike  | 91.53 | 94.63 |
|    person   | 91.47 | 94.81 |
| pottedplant | 75.04 | 90.61 |
|    sheep    | 94.52 | 97.73 |
|     sofa    | 59.91 | 69.91 |
|    train    | 95.31 | 98.67 |
|  tvmonitor  | 85.61 | 93.99 |
+-------------+-------+-------+
06/01 14:20:09 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 96.5700  mIoU: 83.5600  mAcc: 91.9300  data_time: 0.0014  time: 0.0741
Runtime: 24269

============================= JOB FEEDBACK =============================

NodeName=uc2n485
Job ID: 23668253
Cluster: uc2
User/Group: ma_dschader/ma_ma
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 16
CPU Utilized: 11:21:42
CPU Efficiency: 10.52% of 4-11:59:12 core-walltime
Job Wall-clock time: 06:44:57
Memory Utilized: 8.27 GB
Memory Efficiency: 8.27% of 100.00 GB
