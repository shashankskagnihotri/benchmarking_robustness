Started at Tue Nov 19 21:39:49 CET 2024
Processing corruption type: gaussian_noise
11/19 21:41:15 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1293401171
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1293401171
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/19 21:41:17 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='gaussian_noise',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/gaussian_noise'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-19 21:42:07,049 - mmseg - INFO - using core type: DCNv3
2024-11-19 21:42:07,049 - mmseg - INFO - using activation layer: GELU
2024-11-19 21:42:07,049 - mmseg - INFO - using main norm layer: LN
2024-11-19 21:42:07,049 - mmseg - INFO - using dpr: linear, 0.3
2024-11-19 21:42:07,049 - mmseg - INFO - level2_post_norm: False
2024-11-19 21:42:07,049 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-19 21:42:07,049 - mmseg - INFO - res_post_norm: False
2024-11-19 21:42:07,049 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/19 21:42:12 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/19 21:42:12 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/19 21:42:14 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/19 21:42:19 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/19 21:44:14 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:53:43  time: 0.7683  data_time: 0.0015  memory: 21049  
11/19 21:44:49 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:33:41  time: 0.3394  data_time: 0.0016  memory: 21056  
11/19 21:45:22 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:26:25  time: 0.4114  data_time: 0.0016  memory: 21305  
11/19 21:45:52 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:22:06  time: 0.8152  data_time: 0.0015  memory: 21070  
11/19 21:46:17 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:19:02  time: 0.3556  data_time: 0.0015  memory: 21070  
11/19 21:46:39 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:16:34  time: 0.1245  data_time: 0.0016  memory: 21060  
11/19 21:47:02 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:14:47  time: 0.5582  data_time: 0.0016  memory: 21053  
11/19 21:47:21 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:13:11  time: 0.8318  data_time: 0.0020  memory: 21069  
11/19 21:47:35 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:11:42  time: 0.5368  data_time: 0.0016  memory: 21041  
11/19 21:48:03 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:10:52  time: 0.6652  data_time: 0.0016  memory: 21328  
11/19 21:48:21 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:09:51  time: 0.3492  data_time: 0.0016  memory: 21075  
11/19 21:48:33 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:08:49  time: 0.2810  data_time: 0.0016  memory: 21070  
11/19 21:48:53 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:08:03  time: 0.1221  data_time: 0.0016  memory: 21056  
11/19 21:49:08 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:07:17  time: 0.6548  data_time: 0.0015  memory: 21073  
11/19 21:49:24 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:06:35  time: 0.1214  data_time: 0.0016  memory: 21067  
11/19 21:49:38 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:05:55  time: 0.5733  data_time: 0.0015  memory: 21270  
11/19 21:49:52 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:05:18  time: 0.2832  data_time: 0.0015  memory: 21066  
11/19 21:50:05 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:04:43  time: 0.1277  data_time: 0.0016  memory: 21046  
11/19 21:50:11 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:04:07  time: 0.1275  data_time: 0.0016  memory: 776  
11/19 21:50:33 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:03:41  time: 0.5514  data_time: 0.0016  memory: 21075  
11/19 21:50:43 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:03:11  time: 0.1210  data_time: 0.0015  memory: 21050  
11/19 21:50:54 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:02:43  time: 0.5844  data_time: 0.0016  memory: 21288  
11/19 21:51:09 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:02:17  time: 0.3330  data_time: 0.0016  memory: 21064  
11/19 21:51:20 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:01:52  time: 0.3102  data_time: 0.0016  memory: 21069  
11/19 21:51:37 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:01:28  time: 0.3177  data_time: 0.0016  memory: 21275  
11/19 21:51:43 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:01:04  time: 0.1207  data_time: 0.0016  memory: 878  
11/19 21:51:49 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:00:41  time: 0.1232  data_time: 0.0021  memory: 861  
11/19 21:51:58 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:20  time: 0.1193  data_time: 0.0016  memory: 21036  
11/19 21:52:07 - mmengine - INFO - per class results:
11/19 21:52:07 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 83.96 | 89.61 |
|  aeroplane  | 58.41 | 70.91 |
|   bicycle   | 15.77 | 69.13 |
|     bird    | 37.81 | 41.61 |
|     boat    | 27.73 | 57.41 |
|    bottle   | 45.38 | 63.78 |
|     bus     | 62.59 | 74.04 |
|     car     | 62.84 | 87.43 |
|     cat     | 41.16 | 77.46 |
|    chair    | 11.59 | 13.47 |
|     cow     |  15.6 | 16.89 |
| diningtable | 33.96 | 65.07 |
|     dog     | 44.03 | 76.82 |
|    horse    | 36.11 |  60.3 |
|  motorbike  | 56.02 | 79.54 |
|    person   | 64.22 | 75.41 |
| pottedplant | 28.51 |  62.1 |
|    sheep    | 39.56 | 53.82 |
|     sofa    | 19.87 | 21.49 |
|    train    | 51.59 | 82.46 |
|  tvmonitor  | 39.12 | 41.83 |
+-------------+-------+-------+
11/19 21:52:07 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 82.8900  mIoU: 41.7100  mAcc: 60.9800  data_time: 0.0025  time: 0.4055
Finished processing corruption type: gaussian_noise
Processing corruption type: shot_noise
11/19 21:52:17 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 2018063216
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 2018063216
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/19 21:52:19 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='shot_noise',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/shot_noise'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-19 21:52:23,902 - mmseg - INFO - using core type: DCNv3
2024-11-19 21:52:23,902 - mmseg - INFO - using activation layer: GELU
2024-11-19 21:52:23,902 - mmseg - INFO - using main norm layer: LN
2024-11-19 21:52:23,902 - mmseg - INFO - using dpr: linear, 0.3
2024-11-19 21:52:23,902 - mmseg - INFO - level2_post_norm: False
2024-11-19 21:52:23,902 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-19 21:52:23,902 - mmseg - INFO - res_post_norm: False
2024-11-19 21:52:23,902 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/19 21:52:25 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/19 21:52:25 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/19 21:52:27 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/19 21:52:30 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/19 21:53:23 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:25:00  time: 0.8531  data_time: 0.0017  memory: 21049  
11/19 21:54:02 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:20:44  time: 0.4206  data_time: 0.0017  memory: 21056  
11/19 21:54:40 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:18:46  time: 0.5093  data_time: 0.0017  memory: 21305  
11/19 21:55:14 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:17:04  time: 0.9150  data_time: 0.0017  memory: 21070  
11/19 21:55:43 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:15:29  time: 0.4517  data_time: 0.0017  memory: 21070  
11/19 21:56:09 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:14:02  time: 0.2167  data_time: 0.0018  memory: 21060  
11/19 21:56:37 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:12:56  time: 0.6513  data_time: 0.0017  memory: 21053  
11/19 21:57:01 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:11:50  time: 0.9250  data_time: 0.0016  memory: 21069  
11/19 21:57:19 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:10:43  time: 0.6322  data_time: 0.0016  memory: 21041  
11/19 21:57:51 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:10:10  time: 0.7645  data_time: 0.0016  memory: 21328  
11/19 21:58:14 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:09:22  time: 0.4425  data_time: 0.0016  memory: 21075  
11/19 21:58:31 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:08:30  time: 0.3703  data_time: 0.0016  memory: 21070  
11/19 21:58:55 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:07:53  time: 0.2191  data_time: 0.0016  memory: 21056  
11/19 21:59:15 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:07:13  time: 0.7453  data_time: 0.0016  memory: 21073  
11/19 21:59:35 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:06:36  time: 0.2086  data_time: 0.0016  memory: 21067  
11/19 21:59:53 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:05:59  time: 0.6678  data_time: 0.0017  memory: 21270  
11/19 22:00:12 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:05:25  time: 0.3711  data_time: 0.0016  memory: 21066  
11/19 22:00:29 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:04:52  time: 0.2234  data_time: 0.0016  memory: 21046  
11/19 22:00:39 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:04:17  time: 0.2168  data_time: 0.0016  memory: 776  
11/19 22:01:06 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:03:51  time: 0.6398  data_time: 0.0016  memory: 21075  
11/19 22:01:20 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:03:21  time: 0.2193  data_time: 0.0016  memory: 21050  
11/19 22:01:36 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:02:53  time: 0.6803  data_time: 0.0016  memory: 21288  
11/19 22:01:56 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:02:27  time: 0.4177  data_time: 0.0017  memory: 21064  
11/19 22:02:10 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:02:00  time: 0.4069  data_time: 0.0018  memory: 21069  
11/19 22:02:32 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:01:35  time: 0.4120  data_time: 0.0017  memory: 21275  
11/19 22:02:42 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:01:10  time: 0.2066  data_time: 0.0017  memory: 878  
11/19 22:02:53 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:00:45  time: 0.2197  data_time: 0.0016  memory: 861  
11/19 22:03:07 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:22  time: 0.2088  data_time: 0.0017  memory: 21036  
11/19 22:03:20 - mmengine - INFO - per class results:
11/19 22:03:20 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 83.98 | 89.33 |
|  aeroplane  | 56.96 | 68.88 |
|   bicycle   | 14.66 | 69.47 |
|     bird    | 36.82 | 40.69 |
|     boat    | 27.31 |  54.3 |
|    bottle   | 46.54 | 63.83 |
|     bus     | 65.25 | 80.14 |
|     car     | 63.09 | 89.28 |
|     cat     | 44.54 | 77.37 |
|    chair    | 12.67 | 15.02 |
|     cow     | 15.74 | 16.96 |
| diningtable | 33.39 |  62.7 |
|     dog     | 43.26 | 79.42 |
|    horse    | 37.81 |  64.4 |
|  motorbike  |  55.4 | 84.43 |
|    person   | 65.04 | 77.04 |
| pottedplant | 28.26 | 60.97 |
|    sheep    | 39.98 | 52.56 |
|     sofa    |  20.1 |  21.6 |
|    train    | 52.11 | 82.88 |
|  tvmonitor  | 41.44 | 45.24 |
+-------------+-------+-------+
11/19 22:03:20 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 83.0200  mIoU: 42.1100  mAcc: 61.7400  data_time: 0.0020  time: 0.4488
Finished processing corruption type: shot_noise
Processing corruption type: impulse_noise
11/19 22:03:24 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 286131394
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 286131394
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/19 22:03:25 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='impulse_noise',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/impulse_noise'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-19 22:03:30,393 - mmseg - INFO - using core type: DCNv3
2024-11-19 22:03:30,393 - mmseg - INFO - using activation layer: GELU
2024-11-19 22:03:30,393 - mmseg - INFO - using main norm layer: LN
2024-11-19 22:03:30,393 - mmseg - INFO - using dpr: linear, 0.3
2024-11-19 22:03:30,393 - mmseg - INFO - level2_post_norm: False
2024-11-19 22:03:30,393 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-19 22:03:30,393 - mmseg - INFO - res_post_norm: False
2024-11-19 22:03:30,393 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/19 22:03:32 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/19 22:03:32 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/19 22:03:34 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/19 22:03:36 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/19 22:04:25 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:22:33  time: 0.7550  data_time: 0.0016  memory: 21049  
11/19 22:04:58 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:18:28  time: 0.3232  data_time: 0.0017  memory: 21056  
11/19 22:05:31 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:16:30  time: 0.3892  data_time: 0.0016  memory: 21305  
11/19 22:05:59 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:14:52  time: 0.7973  data_time: 0.0016  memory: 21070  
11/19 22:06:24 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:13:24  time: 0.3392  data_time: 0.0017  memory: 21070  
11/19 22:06:44 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:12:00  time: 0.1071  data_time: 0.0016  memory: 21060  
11/19 22:07:07 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:11:01  time: 0.5435  data_time: 0.0017  memory: 21053  
11/19 22:07:25 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:09:59  time: 0.8110  data_time: 0.0016  memory: 21069  
11/19 22:07:38 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:08:57  time: 0.5187  data_time: 0.0017  memory: 21041  
11/19 22:08:05 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:08:29  time: 0.6454  data_time: 0.0016  memory: 21328  
11/19 22:08:22 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:07:47  time: 0.3313  data_time: 0.0016  memory: 21075  
11/19 22:08:33 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:07:00  time: 0.2626  data_time: 0.0016  memory: 21070  
11/19 22:08:52 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:06:28  time: 0.1060  data_time: 0.0016  memory: 21056  
11/19 22:09:07 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:05:53  time: 0.6364  data_time: 0.0016  memory: 21073  
11/19 22:09:22 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:05:21  time: 0.1040  data_time: 0.0017  memory: 21067  
11/19 22:09:34 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:04:50  time: 0.5545  data_time: 0.0017  memory: 21270  
11/19 22:09:47 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:04:21  time: 0.2658  data_time: 0.0017  memory: 21066  
11/19 22:09:59 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:03:53  time: 0.1156  data_time: 0.0017  memory: 21046  
11/19 22:10:05 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:03:24  time: 0.1076  data_time: 0.0017  memory: 776  
11/19 22:10:26 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:03:03  time: 0.5368  data_time: 0.0017  memory: 21075  
11/19 22:10:35 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:02:39  time: 0.1063  data_time: 0.0017  memory: 21050  
11/19 22:10:45 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:02:16  time: 0.5682  data_time: 0.0017  memory: 21288  
11/19 22:11:00 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:01:55  time: 0.3142  data_time: 0.0016  memory: 21064  
11/19 22:11:09 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:01:33  time: 0.2906  data_time: 0.0017  memory: 21069  
11/19 22:11:25 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:01:14  time: 0.2914  data_time: 0.0015  memory: 21275  
11/19 22:11:30 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:00:54  time: 0.1009  data_time: 0.0016  memory: 878  
11/19 22:11:35 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:00:35  time: 0.1074  data_time: 0.0017  memory: 861  
11/19 22:11:44 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:17  time: 0.0999  data_time: 0.0017  memory: 21036  
11/19 22:11:51 - mmengine - INFO - per class results:
11/19 22:11:51 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 83.99 | 90.08 |
|  aeroplane  | 56.12 | 66.35 |
|   bicycle   | 15.55 | 66.86 |
|     bird    | 38.14 | 42.54 |
|     boat    | 26.86 | 60.94 |
|    bottle   | 43.74 | 64.45 |
|     bus     | 55.16 | 62.45 |
|     car     | 63.55 | 84.61 |
|     cat     | 42.25 | 75.71 |
|    chair    | 10.23 | 11.54 |
|     cow     | 14.17 | 15.34 |
| diningtable | 34.51 | 64.85 |
|     dog     | 44.41 | 72.81 |
|    horse    |  36.2 | 59.31 |
|  motorbike  | 55.03 | 82.79 |
|    person   | 63.81 | 73.34 |
| pottedplant | 29.08 |  63.9 |
|    sheep    | 40.07 | 55.09 |
|     sofa    | 17.74 | 19.34 |
|    train    | 46.11 | 84.87 |
|  tvmonitor  | 34.89 | 36.62 |
+-------------+-------+-------+
11/19 22:11:51 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 82.7200  mIoU: 40.5500  mAcc: 59.7000  data_time: 0.0022  time: 0.3417
Finished processing corruption type: impulse_noise
Processing corruption type: defocus_blur
11/19 22:11:55 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 673424571
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 673424571
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/19 22:11:57 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='defocus_blur',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/defocus_blur'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-19 22:12:07,549 - mmseg - INFO - using core type: DCNv3
2024-11-19 22:12:07,549 - mmseg - INFO - using activation layer: GELU
2024-11-19 22:12:07,549 - mmseg - INFO - using main norm layer: LN
2024-11-19 22:12:07,549 - mmseg - INFO - using dpr: linear, 0.3
2024-11-19 22:12:07,549 - mmseg - INFO - level2_post_norm: False
2024-11-19 22:12:07,549 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-19 22:12:07,549 - mmseg - INFO - res_post_norm: False
2024-11-19 22:12:07,549 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/19 22:12:11 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/19 22:12:11 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/19 22:12:13 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/19 22:12:15 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/19 22:13:05 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:23:18  time: 0.7657  data_time: 0.0018  memory: 21049  
11/19 22:13:39 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:18:55  time: 0.3308  data_time: 0.0029  memory: 21056  
11/19 22:14:12 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:16:51  time: 0.4019  data_time: 0.0016  memory: 21305  
11/19 22:14:41 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:15:11  time: 0.8098  data_time: 0.0026  memory: 21070  
11/19 22:15:06 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:13:40  time: 0.3474  data_time: 0.0017  memory: 21070  
11/19 22:15:27 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:12:15  time: 0.1135  data_time: 0.0016  memory: 21060  
11/19 22:15:50 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:11:14  time: 0.5509  data_time: 0.0017  memory: 21053  
11/19 22:16:08 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:10:12  time: 0.8201  data_time: 0.0017  memory: 21069  
11/19 22:16:22 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:09:08  time: 0.5297  data_time: 0.0017  memory: 21041  
11/19 22:16:49 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:08:40  time: 0.6535  data_time: 0.0016  memory: 21328  
11/19 22:17:07 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:07:56  time: 0.3391  data_time: 0.0017  memory: 21075  
11/19 22:17:18 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:07:09  time: 0.2712  data_time: 0.0016  memory: 21070  
11/19 22:17:38 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:06:36  time: 0.1143  data_time: 0.0016  memory: 21056  
11/19 22:17:53 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:06:01  time: 0.6475  data_time: 0.0017  memory: 21073  
11/19 22:18:08 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:05:29  time: 0.1109  data_time: 0.0016  memory: 21067  
11/19 22:18:21 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:04:57  time: 0.5671  data_time: 0.0017  memory: 21270  
11/19 22:18:35 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:04:27  time: 0.2694  data_time: 0.0016  memory: 21066  
11/19 22:18:47 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:03:59  time: 0.1140  data_time: 0.0016  memory: 21046  
11/19 22:18:53 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:03:28  time: 0.1149  data_time: 0.0016  memory: 776  
11/19 22:19:14 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:03:08  time: 0.5418  data_time: 0.0016  memory: 21075  
11/19 22:19:24 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:02:42  time: 0.1113  data_time: 0.0016  memory: 21050  
11/19 22:19:34 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:02:19  time: 0.5720  data_time: 0.0016  memory: 21288  
11/19 22:19:49 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:01:58  time: 0.3237  data_time: 0.0016  memory: 21064  
11/19 22:19:59 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:01:36  time: 0.2991  data_time: 0.0017  memory: 21069  
11/19 22:20:15 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:01:16  time: 0.3082  data_time: 0.0016  memory: 21275  
11/19 22:20:21 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:00:55  time: 0.1069  data_time: 0.0015  memory: 878  
11/19 22:20:26 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:00:36  time: 0.1125  data_time: 0.0015  memory: 861  
11/19 22:20:35 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:17  time: 0.1071  data_time: 0.0016  memory: 21036  
11/19 22:20:43 - mmengine - INFO - per class results:
11/19 22:20:43 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 79.83 | 83.11 |
|  aeroplane  | 44.14 | 89.69 |
|   bicycle   | 16.37 | 45.99 |
|     bird    | 46.14 | 61.99 |
|     boat    | 19.56 | 58.77 |
|    bottle   | 32.97 | 68.02 |
|     bus     | 54.15 | 84.35 |
|     car     | 44.91 | 90.84 |
|     cat     | 46.53 | 67.42 |
|    chair    |  10.4 | 11.72 |
|     cow     |  7.31 |  7.85 |
| diningtable | 26.18 | 77.83 |
|     dog     | 40.19 | 83.79 |
|    horse    | 34.95 | 64.96 |
|  motorbike  | 39.76 | 81.23 |
|    person   | 63.53 | 88.16 |
| pottedplant | 22.68 | 53.67 |
|    sheep    | 28.22 | 31.11 |
|     sofa    |  6.59 |  6.7  |
|    train    | 43.64 | 74.18 |
|  tvmonitor  | 46.16 | 57.98 |
+-------------+-------+-------+
11/19 22:20:43 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 78.8800  mIoU: 35.9100  mAcc: 61.4000  data_time: 0.0022  time: 0.3507
Finished processing corruption type: defocus_blur
Processing corruption type: glass_blur
11/19 22:20:54 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 873249533
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 873249533
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/19 22:20:55 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='glass_blur',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/glass_blur'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-19 22:20:59,777 - mmseg - INFO - using core type: DCNv3
2024-11-19 22:20:59,777 - mmseg - INFO - using activation layer: GELU
2024-11-19 22:20:59,777 - mmseg - INFO - using main norm layer: LN
2024-11-19 22:20:59,777 - mmseg - INFO - using dpr: linear, 0.3
2024-11-19 22:20:59,777 - mmseg - INFO - level2_post_norm: False
2024-11-19 22:20:59,777 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-19 22:20:59,777 - mmseg - INFO - res_post_norm: False
2024-11-19 22:20:59,777 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/19 22:21:01 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/19 22:21:01 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/19 22:21:03 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/19 22:21:05 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/19 22:28:18 - mmengine - INFO - Iter(test) [  50/1449]    eta: 3:21:39  time: 8.3993  data_time: 0.0018  memory: 21049  
11/19 22:35:12 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 3:10:14  time: 7.9831  data_time: 0.0017  memory: 21056  
11/19 22:42:30 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 3:05:22  time: 8.8617  data_time: 0.0057  memory: 21305  
11/19 22:49:32 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 2:57:35  time: 8.6922  data_time: 0.0017  memory: 21070  
11/19 22:56:03 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 2:47:38  time: 7.1310  data_time: 0.0017  memory: 21070  
11/19 23:02:07 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 2:37:08  time: 6.8704  data_time: 0.0016  memory: 21060  
11/19 23:08:04 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 2:27:28  time: 7.2651  data_time: 0.0016  memory: 21053  
11/19 23:14:05 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 2:18:57  time: 7.8562  data_time: 0.0017  memory: 21069  
11/19 23:19:49 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 2:10:22  time: 6.9790  data_time: 0.0016  memory: 21041  
11/19 23:26:12 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 2:03:33  time: 9.1934  data_time: 0.0118  memory: 21328  
11/19 23:31:57 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 1:55:49  time: 6.8572  data_time: 0.0015  memory: 21075  
11/19 23:37:34 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 1:48:13  time: 6.8567  data_time: 0.0016  memory: 21070  
11/19 23:43:20 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 1:41:05  time: 6.7176  data_time: 0.0016  memory: 21056  
11/19 23:49:07 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 1:34:11  time: 7.5950  data_time: 0.0016  memory: 21073  
11/19 23:54:53 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 1:27:25  time: 6.6485  data_time: 0.0016  memory: 21067  
11/20 00:00:50 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 1:20:54  time: 7.9334  data_time: 0.0016  memory: 21270  
11/20 00:06:26 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 1:14:14  time: 6.6486  data_time: 0.0015  memory: 21066  
11/20 00:12:04 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 1:07:41  time: 6.7223  data_time: 0.0015  memory: 21046  
11/20 00:17:28 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 1:01:07  time: 6.7092  data_time: 0.0015  memory: 776  
11/20 00:23:18 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:54:52  time: 6.9230  data_time: 0.0015  memory: 21075  
11/20 00:28:43 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:48:29  time: 6.4516  data_time: 0.0016  memory: 21050  
11/20 00:34:27 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:42:18  time: 7.6300  data_time: 0.0015  memory: 21288  
11/20 00:40:01 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:36:07  time: 6.6989  data_time: 0.0015  memory: 21064  
11/20 00:45:34 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:29:58  time: 6.9500  data_time: 0.0015  memory: 21069  
11/20 00:51:31 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:23:56  time: 8.1273  data_time: 0.0176  memory: 21275  
11/20 00:56:56 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:17:51  time: 6.3418  data_time: 0.0015  memory: 878  
11/20 01:02:21 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:11:49  time: 6.7108  data_time: 0.0015  memory: 861  
11/20 01:07:41 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:05:49  time: 6.4872  data_time: 0.0015  memory: 21036  
11/20 01:12:57 - mmengine - INFO - per class results:
11/20 01:12:57 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 81.33 | 84.62 |
|  aeroplane  | 48.79 | 89.69 |
|   bicycle   | 16.82 | 53.03 |
|     bird    | 48.27 | 61.39 |
|     boat    | 21.17 | 62.15 |
|    bottle   | 36.18 | 69.17 |
|     bus     | 58.37 | 83.07 |
|     car     | 52.39 | 90.87 |
|     cat     | 49.69 | 74.44 |
|    chair    | 10.72 |  12.1 |
|     cow     |  8.8  |  9.43 |
| diningtable | 28.56 | 76.95 |
|     dog     | 42.96 |  83.8 |
|    horse    | 36.73 | 69.85 |
|  motorbike  | 43.79 | 83.46 |
|    person   |  65.8 | 88.32 |
| pottedplant | 24.22 | 57.98 |
|    sheep    |  36.3 | 41.35 |
|     sofa    |  13.8 | 14.29 |
|    train    | 46.19 | 79.75 |
|  tvmonitor  | 47.56 | 58.54 |
+-------------+-------+-------+
11/20 01:12:57 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 80.5700  mIoU: 38.9700  mAcc: 64.0100  data_time: 0.0033  time: 7.1162
Finished processing corruption type: glass_blur
Processing corruption type: motion_blur
11/20 01:14:15 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1778095401
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1778095401
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/20 01:14:16 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='motion_blur',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/motion_blur'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-20 01:14:51,772 - mmseg - INFO - using core type: DCNv3
2024-11-20 01:14:51,772 - mmseg - INFO - using activation layer: GELU
2024-11-20 01:14:51,772 - mmseg - INFO - using main norm layer: LN
2024-11-20 01:14:51,773 - mmseg - INFO - using dpr: linear, 0.3
2024-11-20 01:14:51,773 - mmseg - INFO - level2_post_norm: False
2024-11-20 01:14:51,773 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-20 01:14:51,773 - mmseg - INFO - res_post_norm: False
2024-11-20 01:14:51,773 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/20 01:15:03 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/20 01:15:04 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/20 01:15:06 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 01:15:10 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 01:17:16 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:58:45  time: 1.5234  data_time: 0.0015  memory: 21049  
11/20 01:18:27 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:44:07  time: 1.0774  data_time: 0.0015  memory: 21056  
11/20 01:19:38 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:38:34  time: 1.2053  data_time: 0.0015  memory: 21305  
11/20 01:20:44 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:34:43  time: 1.5665  data_time: 0.0015  memory: 21070  
11/20 01:21:46 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:31:34  time: 1.0880  data_time: 0.0015  memory: 21070  
11/20 01:22:43 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:28:54  time: 0.7952  data_time: 0.0015  memory: 21060  
11/20 01:23:44 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:26:52  time: 1.2910  data_time: 0.0015  memory: 21053  
11/20 01:24:41 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:24:56  time: 1.6055  data_time: 0.0016  memory: 21069  
11/20 01:25:32 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:23:00  time: 1.2470  data_time: 0.0016  memory: 21041  
11/20 01:26:39 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:21:46  time: 1.5676  data_time: 0.0016  memory: 21328  
11/20 01:27:34 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:20:14  time: 1.1116  data_time: 0.0015  memory: 21075  
11/20 01:28:23 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:18:41  time: 1.0363  data_time: 0.0015  memory: 21070  
11/20 01:29:20 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:17:24  time: 0.9077  data_time: 0.0015  memory: 21056  
11/20 01:30:13 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:16:05  time: 1.4061  data_time: 0.0016  memory: 21073  
11/20 01:31:06 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:14:50  time: 0.8501  data_time: 0.0015  memory: 21067  
11/20 01:31:58 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:13:37  time: 1.4059  data_time: 0.0015  memory: 21270  
11/20 01:32:49 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:12:26  time: 1.0451  data_time: 0.0016  memory: 21066  
11/20 01:33:40 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:11:16  time: 0.9126  data_time: 0.0015  memory: 21046  
11/20 01:34:23 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:10:05  time: 0.9015  data_time: 0.0016  memory: 776  
11/20 01:35:23 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:09:04  time: 1.3069  data_time: 0.0016  memory: 21075  
11/20 01:36:09 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:07:58  time: 0.8512  data_time: 0.0015  memory: 21050  
11/20 01:36:57 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:06:54  time: 1.3911  data_time: 0.0016  memory: 21288  
11/20 01:37:49 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:05:53  time: 1.0717  data_time: 0.0026  memory: 21064  
11/20 01:38:38 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:04:51  time: 1.0865  data_time: 0.0015  memory: 21069  
11/20 01:39:31 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:03:52  time: 1.0737  data_time: 0.0016  memory: 21275  
11/20 01:40:14 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:02:52  time: 0.8398  data_time: 0.0015  memory: 878  
11/20 01:40:58 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:01:53  time: 0.9332  data_time: 0.0015  memory: 861  
11/20 01:41:45 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:55  time: 0.8887  data_time: 0.0015  memory: 21036  
11/20 01:42:31 - mmengine - INFO - per class results:
11/20 01:42:31 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 81.52 | 84.95 |
|  aeroplane  | 48.83 | 86.54 |
|   bicycle   | 16.83 | 51.73 |
|     bird    | 45.12 | 60.09 |
|     boat    | 21.66 | 69.59 |
|    bottle   | 39.68 | 67.75 |
|     bus     | 57.89 |  82.9 |
|     car     | 50.61 |  92.1 |
|     cat     | 47.61 | 73.85 |
|    chair    |  9.8  | 10.93 |
|     cow     | 11.49 | 12.21 |
| diningtable | 28.71 | 76.33 |
|     dog     | 40.45 | 85.88 |
|    horse    | 37.48 |  62.1 |
|  motorbike  | 45.04 | 81.18 |
|    person   | 64.55 | 87.23 |
| pottedplant | 24.12 | 50.42 |
|    sheep    | 33.33 |  37.5 |
|     sofa    | 10.04 | 10.36 |
|    train    | 48.68 | 80.14 |
|  tvmonitor  | 47.92 | 58.24 |
+-------------+-------+-------+
11/20 01:42:31 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 80.5800  mIoU: 38.6400  mAcc: 62.9500  data_time: 0.0023  time: 1.1319
Finished processing corruption type: motion_blur
Processing corruption type: zoom_blur
11/20 01:42:34 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 50260379
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 50260379
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/20 01:42:35 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='zoom_blur',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/zoom_blur'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-20 01:42:39,634 - mmseg - INFO - using core type: DCNv3
2024-11-20 01:42:39,634 - mmseg - INFO - using activation layer: GELU
2024-11-20 01:42:39,634 - mmseg - INFO - using main norm layer: LN
2024-11-20 01:42:39,634 - mmseg - INFO - using dpr: linear, 0.3
2024-11-20 01:42:39,634 - mmseg - INFO - level2_post_norm: False
2024-11-20 01:42:39,634 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-20 01:42:39,634 - mmseg - INFO - res_post_norm: False
2024-11-20 01:42:39,634 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/20 01:42:41 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/20 01:42:41 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/20 01:42:43 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 01:42:44 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 01:44:06 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:38:10  time: 1.4127  data_time: 0.0015  memory: 21049  
11/20 01:45:12 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:33:15  time: 0.9908  data_time: 0.0017  memory: 21056  
11/20 01:46:20 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:31:10  time: 1.1453  data_time: 0.0015  memory: 21305  
11/20 01:47:24 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:29:02  time: 1.5029  data_time: 0.0015  memory: 21070  
11/20 01:48:22 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:26:59  time: 1.0196  data_time: 0.0016  memory: 21070  
11/20 01:49:17 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:25:03  time: 0.7891  data_time: 0.0015  memory: 21060  
11/20 01:50:14 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:23:29  time: 1.2311  data_time: 0.0016  memory: 21053  
11/20 01:51:07 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:21:56  time: 1.5206  data_time: 0.0015  memory: 21069  
11/20 01:51:54 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:20:19  time: 1.1807  data_time: 0.0015  memory: 21041  
11/20 01:52:55 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:19:19  time: 1.4204  data_time: 0.0015  memory: 21328  
11/20 01:53:47 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:18:03  time: 1.0174  data_time: 0.0015  memory: 21075  
11/20 01:54:33 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:16:42  time: 0.9567  data_time: 0.0016  memory: 21070  
11/20 01:55:26 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:15:36  time: 0.8004  data_time: 0.0015  memory: 21056  
11/20 01:56:16 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:14:27  time: 1.3541  data_time: 0.0016  memory: 21073  
11/20 01:57:05 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:13:21  time: 0.7875  data_time: 0.0015  memory: 21067  
11/20 01:57:53 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:12:17  time: 1.3396  data_time: 0.0016  memory: 21270  
11/20 01:58:41 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:11:14  time: 0.9475  data_time: 0.0016  memory: 21066  
11/20 01:59:28 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:10:12  time: 0.8249  data_time: 0.0017  memory: 21046  
11/20 02:00:08 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:09:08  time: 0.8279  data_time: 0.0016  memory: 776  
11/20 02:01:04 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:08:13  time: 1.2142  data_time: 0.0016  memory: 21075  
11/20 02:01:48 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:07:14  time: 0.7955  data_time: 0.0016  memory: 21050  
11/20 02:02:32 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:06:16  time: 1.3203  data_time: 0.0016  memory: 21288  
11/20 02:03:22 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:05:21  time: 1.0254  data_time: 0.0017  memory: 21064  
11/20 02:04:09 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:04:26  time: 1.0358  data_time: 0.0017  memory: 21069  
11/20 02:05:01 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:03:32  time: 1.0197  data_time: 0.0016  memory: 21275  
11/20 02:05:43 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:02:38  time: 0.8073  data_time: 0.0015  memory: 878  
11/20 02:06:25 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:01:44  time: 0.8570  data_time: 0.0016  memory: 861  
11/20 02:07:08 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:51  time: 0.8037  data_time: 0.0016  memory: 21036  
11/20 02:07:50 - mmengine - INFO - per class results:
11/20 02:07:50 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 69.85 | 74.24 |
|  aeroplane  | 37.79 | 76.26 |
|   bicycle   | 17.51 | 37.77 |
|     bird    | 21.49 | 40.71 |
|     boat    | 17.43 | 29.22 |
|    bottle   | 19.41 |  50.0 |
|     bus     | 40.75 | 54.55 |
|     car     | 35.68 | 79.68 |
|     cat     | 10.89 | 86.26 |
|    chair    |  1.3  |  1.33 |
|     cow     |  0.01 |  0.01 |
| diningtable |  19.0 | 34.44 |
|     dog     | 23.03 | 55.09 |
|    horse    |  6.63 |  9.51 |
|  motorbike  |  18.8 | 29.57 |
|    person   | 43.64 |  50.9 |
| pottedplant | 25.04 | 40.87 |
|    sheep    |  0.45 |  0.45 |
|     sofa    |  1.25 |  1.25 |
|    train    | 34.91 | 52.01 |
|  tvmonitor  | 35.86 | 40.89 |
+-------------+-------+-------+
11/20 02:07:50 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 66.2300  mIoU: 22.8900  mAcc: 40.2400  data_time: 0.0020  time: 1.0386
Finished processing corruption type: zoom_blur
Processing corruption type: snow
11/20 02:07:53 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 641518280
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 641518280
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/20 02:07:55 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='snow',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/snow'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-20 02:08:00,052 - mmseg - INFO - using core type: DCNv3
2024-11-20 02:08:00,052 - mmseg - INFO - using activation layer: GELU
2024-11-20 02:08:00,052 - mmseg - INFO - using main norm layer: LN
2024-11-20 02:08:00,052 - mmseg - INFO - using dpr: linear, 0.3
2024-11-20 02:08:00,052 - mmseg - INFO - level2_post_norm: False
2024-11-20 02:08:00,052 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-20 02:08:00,052 - mmseg - INFO - res_post_norm: False
2024-11-20 02:08:00,052 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/20 02:08:04 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/20 02:08:04 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/20 02:08:06 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 02:08:09 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 02:09:08 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:27:37  time: 0.9576  data_time: 0.0015  memory: 21049  
11/20 02:09:52 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:23:10  time: 0.5368  data_time: 0.0015  memory: 21056  
11/20 02:10:36 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:21:10  time: 0.6285  data_time: 0.0014  memory: 21305  
11/20 02:11:15 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:19:22  time: 1.0241  data_time: 0.0015  memory: 21070  
11/20 02:11:50 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:17:41  time: 0.5537  data_time: 0.0015  memory: 21070  
11/20 02:12:22 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:16:07  time: 0.3178  data_time: 0.0015  memory: 21060  
11/20 02:12:54 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:14:56  time: 0.7577  data_time: 0.0015  memory: 21053  
11/20 02:13:24 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:13:45  time: 1.0371  data_time: 0.0014  memory: 21069  
11/20 02:13:47 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:12:31  time: 0.7276  data_time: 0.0015  memory: 21041  
11/20 02:14:25 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:11:54  time: 0.8926  data_time: 0.0016  memory: 21328  
11/20 02:14:53 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:11:00  time: 0.5484  data_time: 0.0015  memory: 21075  
11/20 02:15:15 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:10:03  time: 0.4868  data_time: 0.0015  memory: 21070  
11/20 02:15:45 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:09:20  time: 0.3285  data_time: 0.0015  memory: 21056  
11/20 02:16:11 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:08:35  time: 0.8644  data_time: 0.0016  memory: 21073  
11/20 02:16:36 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:07:52  time: 0.3144  data_time: 0.0015  memory: 21067  
11/20 02:17:00 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:07:10  time: 0.8019  data_time: 0.0015  memory: 21270  
11/20 02:17:24 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:06:31  time: 0.4768  data_time: 0.0015  memory: 21066  
11/20 02:17:47 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:05:52  time: 0.3304  data_time: 0.0015  memory: 21046  
11/20 02:18:03 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:05:12  time: 0.3933  data_time: 0.0015  memory: 776  
11/20 02:18:36 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:04:41  time: 0.7480  data_time: 0.0016  memory: 21075  
11/20 02:18:56 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:04:05  time: 0.3172  data_time: 0.0015  memory: 21050  
11/20 02:19:17 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:03:31  time: 0.8016  data_time: 0.0016  memory: 21288  
11/20 02:19:43 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:03:00  time: 0.5313  data_time: 0.0015  memory: 21064  
11/20 02:20:03 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:02:28  time: 0.5166  data_time: 0.0016  memory: 21069  
11/20 02:20:35 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:01:58  time: 0.5198  data_time: 0.0016  memory: 21275  
11/20 02:20:52 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:01:27  time: 0.3178  data_time: 0.0015  memory: 878  
11/20 02:21:08 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:00:57  time: 0.3347  data_time: 0.0015  memory: 861  
11/20 02:21:27 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:27  time: 0.3170  data_time: 0.0015  memory: 21036  
11/20 02:21:46 - mmengine - INFO - per class results:
11/20 02:21:46 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 81.62 | 87.35 |
|  aeroplane  |  39.1 | 42.75 |
|   bicycle   | 17.87 | 56.72 |
|     bird    | 33.44 | 38.01 |
|     boat    |  14.7 | 68.48 |
|    bottle   | 32.87 |  61.3 |
|     bus     | 37.17 | 40.05 |
|     car     | 56.55 | 75.32 |
|     cat     | 36.46 | 82.98 |
|    chair    |  4.57 |  4.77 |
|     cow     | 19.28 | 22.54 |
| diningtable | 33.32 | 58.54 |
|     dog     | 42.44 | 58.52 |
|    horse    | 32.31 |  73.1 |
|  motorbike  | 49.06 | 76.83 |
|    person   | 61.19 | 71.25 |
| pottedplant | 28.85 | 56.78 |
|    sheep    | 38.41 | 57.91 |
|     sofa    | 18.21 | 21.39 |
|    train    |  33.9 | 80.51 |
|  tvmonitor  | 16.06 | 16.34 |
+-------------+-------+-------+
11/20 02:21:46 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 79.5500  mIoU: 34.6400  mAcc: 54.8300  data_time: 0.0021  time: 0.5635
Finished processing corruption type: snow
Processing corruption type: frost
11/20 02:22:18 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 716216749
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 716216749
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/20 02:22:19 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='frost',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/frost'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-20 02:22:33,328 - mmseg - INFO - using core type: DCNv3
2024-11-20 02:22:33,328 - mmseg - INFO - using activation layer: GELU
2024-11-20 02:22:33,328 - mmseg - INFO - using main norm layer: LN
2024-11-20 02:22:33,328 - mmseg - INFO - using dpr: linear, 0.3
2024-11-20 02:22:33,328 - mmseg - INFO - level2_post_norm: False
2024-11-20 02:22:33,328 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-20 02:22:33,328 - mmseg - INFO - res_post_norm: False
2024-11-20 02:22:33,328 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/20 02:22:37 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/20 02:22:37 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/20 02:22:39 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 02:22:42 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 02:23:32 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:23:28  time: 0.7371  data_time: 0.0014  memory: 21049  
11/20 02:24:06 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:18:45  time: 0.3051  data_time: 0.0014  memory: 21056  
11/20 02:24:37 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:16:32  time: 0.3724  data_time: 0.0014  memory: 21305  
11/20 02:25:04 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:14:49  time: 0.7805  data_time: 0.0014  memory: 21070  
11/20 02:25:29 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:13:18  time: 0.3254  data_time: 0.0014  memory: 21070  
11/20 02:25:48 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:11:52  time: 0.0916  data_time: 0.0015  memory: 21060  
11/20 02:26:10 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:10:52  time: 0.5241  data_time: 0.0014  memory: 21053  
11/20 02:26:27 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:09:50  time: 0.7955  data_time: 0.0015  memory: 21069  
11/20 02:26:40 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:08:47  time: 0.5021  data_time: 0.0014  memory: 21041  
11/20 02:27:06 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:08:20  time: 0.6280  data_time: 0.0015  memory: 21328  
11/20 02:27:22 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:07:37  time: 0.3156  data_time: 0.0015  memory: 21075  
11/20 02:27:32 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:06:50  time: 0.2485  data_time: 0.0014  memory: 21070  
11/20 02:27:51 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:06:19  time: 0.0888  data_time: 0.0014  memory: 21056  
11/20 02:28:05 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:05:45  time: 0.6178  data_time: 0.0015  memory: 21073  
11/20 02:28:18 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:05:13  time: 0.0885  data_time: 0.0015  memory: 21067  
11/20 02:28:30 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:04:42  time: 0.5410  data_time: 0.0015  memory: 21270  
11/20 02:28:43 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:04:14  time: 0.2500  data_time: 0.0015  memory: 21066  
11/20 02:28:54 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:03:46  time: 0.0922  data_time: 0.0015  memory: 21046  
11/20 02:28:58 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:03:17  time: 0.0923  data_time: 0.0015  memory: 776  
11/20 02:29:19 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:02:58  time: 0.5164  data_time: 0.0015  memory: 21075  
11/20 02:29:27 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:02:33  time: 0.0869  data_time: 0.0015  memory: 21050  
11/20 02:29:36 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:02:11  time: 0.5458  data_time: 0.0015  memory: 21288  
11/20 02:29:50 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:01:51  time: 0.2991  data_time: 0.0015  memory: 21064  
11/20 02:29:59 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:01:30  time: 0.2752  data_time: 0.0015  memory: 21069  
11/20 02:30:14 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:01:11  time: 0.2862  data_time: 0.0015  memory: 21275  
11/20 02:30:18 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:00:52  time: 0.0862  data_time: 0.0015  memory: 878  
11/20 02:30:23 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:00:33  time: 0.0896  data_time: 0.0015  memory: 861  
11/20 02:30:31 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:16  time: 0.0861  data_time: 0.0015  memory: 21036  
11/20 02:30:37 - mmengine - INFO - per class results:
11/20 02:30:37 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background |  82.7 |  88.0 |
|  aeroplane  | 46.55 | 53.66 |
|   bicycle   |  19.3 | 58.98 |
|     bird    | 30.96 | 33.66 |
|     boat    | 23.12 | 67.39 |
|    bottle   | 40.91 | 65.29 |
|     bus     |  55.2 | 68.04 |
|     car     | 58.18 |  81.9 |
|     cat     | 46.22 | 76.09 |
|    chair    |  6.68 |  7.17 |
|     cow     | 18.47 | 21.79 |
| diningtable | 27.91 | 73.12 |
|     dog     | 43.15 | 78.86 |
|    horse    | 31.55 | 69.46 |
|  motorbike  | 51.18 | 68.74 |
|    person   | 62.02 | 78.41 |
| pottedplant | 25.25 | 52.01 |
|    sheep    | 38.85 |  53.2 |
|     sofa    | 25.67 | 28.97 |
|    train    | 48.38 | 77.41 |
|  tvmonitor  |  23.5 | 24.42 |
+-------------+-------+-------+
11/20 02:30:37 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 81.4400  mIoU: 38.3700  mAcc: 58.4100  data_time: 0.0019  time: 0.3280
Finished processing corruption type: frost
Processing corruption type: fog
11/20 02:30:41 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1529307506
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1529307506
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/20 02:30:42 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='fog',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/fog'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-20 02:30:46,437 - mmseg - INFO - using core type: DCNv3
2024-11-20 02:30:46,438 - mmseg - INFO - using activation layer: GELU
2024-11-20 02:30:46,438 - mmseg - INFO - using main norm layer: LN
2024-11-20 02:30:46,438 - mmseg - INFO - using dpr: linear, 0.3
2024-11-20 02:30:46,438 - mmseg - INFO - level2_post_norm: False
2024-11-20 02:30:46,438 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-20 02:30:46,438 - mmseg - INFO - res_post_norm: False
2024-11-20 02:30:46,438 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/20 02:30:48 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/20 02:30:48 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/20 02:30:49 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 02:30:51 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 02:31:45 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:24:55  time: 0.8502  data_time: 0.0015  memory: 21049  
11/20 02:32:24 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:20:44  time: 0.4324  data_time: 0.0014  memory: 21056  
11/20 02:33:01 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:18:42  time: 0.4968  data_time: 0.0015  memory: 21305  
11/20 02:33:35 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:17:01  time: 0.9092  data_time: 0.0015  memory: 21070  
11/20 02:34:05 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:15:28  time: 0.4493  data_time: 0.0015  memory: 21070  
11/20 02:34:31 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:14:00  time: 0.2145  data_time: 0.0015  memory: 21060  
11/20 02:34:59 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:12:55  time: 0.6479  data_time: 0.0014  memory: 21053  
11/20 02:35:22 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:11:49  time: 0.9169  data_time: 0.0014  memory: 21069  
11/20 02:35:41 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:10:42  time: 0.6258  data_time: 0.0015  memory: 21041  
11/20 02:36:12 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:10:09  time: 0.7421  data_time: 0.0015  memory: 21328  
11/20 02:36:35 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:09:21  time: 0.4368  data_time: 0.0014  memory: 21075  
11/20 02:36:51 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:08:29  time: 0.3681  data_time: 0.0014  memory: 21070  
11/20 02:37:15 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:07:51  time: 0.2136  data_time: 0.0014  memory: 21056  
11/20 02:37:35 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:07:12  time: 0.7428  data_time: 0.0015  memory: 21073  
11/20 02:37:56 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:06:35  time: 0.2127  data_time: 0.0015  memory: 21067  
11/20 02:38:13 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:05:58  time: 0.6567  data_time: 0.0014  memory: 21270  
11/20 02:38:32 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:05:24  time: 0.3707  data_time: 0.0014  memory: 21066  
11/20 02:38:49 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:04:51  time: 0.2202  data_time: 0.0036  memory: 21046  
11/20 02:39:00 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:04:16  time: 0.2203  data_time: 0.0015  memory: 776  
11/20 02:39:26 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:03:51  time: 0.6416  data_time: 0.0015  memory: 21075  
11/20 02:39:41 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:03:21  time: 0.2149  data_time: 0.0015  memory: 21050  
11/20 02:39:57 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:02:52  time: 0.6721  data_time: 0.0015  memory: 21288  
11/20 02:40:17 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:02:27  time: 0.4260  data_time: 0.0015  memory: 21064  
11/20 02:40:32 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:02:00  time: 0.4004  data_time: 0.0015  memory: 21069  
11/20 02:40:53 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:01:35  time: 0.4083  data_time: 0.0015  memory: 21275  
11/20 02:41:04 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:01:10  time: 0.2119  data_time: 0.0015  memory: 878  
11/20 02:41:15 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:00:45  time: 0.2178  data_time: 0.0015  memory: 861  
11/20 02:41:29 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:22  time: 0.2139  data_time: 0.0015  memory: 21036  
11/20 02:41:42 - mmengine - INFO - per class results:
11/20 02:41:42 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 82.81 | 87.11 |
|  aeroplane  | 46.48 | 83.66 |
|   bicycle   | 18.98 | 59.94 |
|     bird    | 43.86 | 50.67 |
|     boat    |  21.3 | 76.28 |
|    bottle   | 44.17 | 68.46 |
|     bus     | 58.53 | 86.46 |
|     car     | 46.39 |  92.5 |
|     cat     | 56.09 |  67.7 |
|    chair    | 14.33 |  18.6 |
|     cow     |  9.79 | 10.93 |
| diningtable | 29.37 | 76.26 |
|     dog     | 44.41 | 85.02 |
|    horse    | 35.28 | 66.38 |
|  motorbike  | 48.27 | 64.82 |
|    person   | 67.35 | 87.02 |
| pottedplant | 19.73 | 33.32 |
|    sheep    |  25.7 | 27.54 |
|     sofa    | 20.54 | 22.73 |
|    train    | 52.38 | 72.76 |
|  tvmonitor  | 45.67 | 52.15 |
+-------------+-------+-------+
11/20 02:41:42 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 81.7900  mIoU: 39.5900  mAcc: 61.4400  data_time: 0.0019  time: 0.4489
Finished processing corruption type: fog
Processing corruption type: brightness
11/20 02:41:45 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1322707327
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1322707327
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/20 02:41:47 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='brightness',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/brightness'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-20 02:41:50,941 - mmseg - INFO - using core type: DCNv3
2024-11-20 02:41:50,941 - mmseg - INFO - using activation layer: GELU
2024-11-20 02:41:50,941 - mmseg - INFO - using main norm layer: LN
2024-11-20 02:41:50,941 - mmseg - INFO - using dpr: linear, 0.3
2024-11-20 02:41:50,941 - mmseg - INFO - level2_post_norm: False
2024-11-20 02:41:50,941 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-20 02:41:50,941 - mmseg - INFO - res_post_norm: False
2024-11-20 02:41:50,941 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/20 02:41:52 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/20 02:41:52 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/20 02:41:54 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 02:41:56 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 02:42:50 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:25:24  time: 0.8700  data_time: 0.0014  memory: 21049  
11/20 02:43:30 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:21:07  time: 0.4485  data_time: 0.0014  memory: 21056  
11/20 02:44:09 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:19:09  time: 0.5286  data_time: 0.0015  memory: 21305  
11/20 02:44:43 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:17:26  time: 0.9252  data_time: 0.0014  memory: 21070  
11/20 02:45:14 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:15:51  time: 0.4614  data_time: 0.0014  memory: 21070  
11/20 02:45:41 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:14:22  time: 0.2333  data_time: 0.0015  memory: 21060  
11/20 02:46:10 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:13:16  time: 0.6693  data_time: 0.0015  memory: 21053  
11/20 02:46:34 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:12:09  time: 0.9407  data_time: 0.0014  memory: 21069  
11/20 02:46:54 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:11:01  time: 0.6387  data_time: 0.0015  memory: 21041  
11/20 02:47:27 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:10:27  time: 0.7839  data_time: 0.0014  memory: 21328  
11/20 02:47:50 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:09:39  time: 0.4587  data_time: 0.0014  memory: 21075  
11/20 02:48:08 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:08:46  time: 0.3916  data_time: 0.0014  memory: 21070  
11/20 02:48:33 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:08:08  time: 0.2371  data_time: 0.0015  memory: 21056  
11/20 02:48:54 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:07:27  time: 0.7692  data_time: 0.0016  memory: 21073  
11/20 02:49:15 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:06:49  time: 0.2266  data_time: 0.0014  memory: 21067  
11/20 02:49:35 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:06:12  time: 0.7106  data_time: 0.0015  memory: 21270  
11/20 02:49:54 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:05:37  time: 0.3920  data_time: 0.0015  memory: 21066  
11/20 02:50:13 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:05:03  time: 0.2433  data_time: 0.0015  memory: 21046  
11/20 02:50:25 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:04:27  time: 0.2415  data_time: 0.0015  memory: 776  
11/20 02:50:52 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:04:00  time: 0.6584  data_time: 0.0015  memory: 21075  
11/20 02:51:08 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:03:29  time: 0.2330  data_time: 0.0015  memory: 21050  
11/20 02:51:24 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:03:00  time: 0.7047  data_time: 0.0015  memory: 21288  
11/20 02:51:45 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:02:33  time: 0.4429  data_time: 0.0015  memory: 21064  
11/20 02:52:01 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:02:05  time: 0.4259  data_time: 0.0015  memory: 21069  
11/20 02:52:24 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:01:39  time: 0.4288  data_time: 0.0015  memory: 21275  
11/20 02:52:36 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:01:13  time: 0.2316  data_time: 0.0015  memory: 878  
11/20 02:52:48 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:00:47  time: 0.2438  data_time: 0.0015  memory: 861  
11/20 02:53:03 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:23  time: 0.2342  data_time: 0.0015  memory: 21036  
11/20 02:53:17 - mmengine - INFO - per class results:
11/20 02:53:17 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 81.97 | 85.23 |
|  aeroplane  | 51.53 | 82.42 |
|   bicycle   | 17.59 | 61.09 |
|     bird    | 49.51 | 60.38 |
|     boat    | 21.33 |  76.0 |
|    bottle   | 43.43 | 70.27 |
|     bus     | 60.28 | 87.28 |
|     car     | 54.41 | 91.85 |
|     cat     | 57.26 | 75.06 |
|    chair    | 14.03 | 16.91 |
|     cow     | 11.19 | 12.34 |
| diningtable | 29.82 | 78.26 |
|     dog     | 48.95 | 85.98 |
|    horse    | 36.07 | 76.21 |
|  motorbike  | 52.74 | 82.68 |
|    person   | 67.98 | 89.04 |
| pottedplant | 22.02 | 62.48 |
|    sheep    | 41.74 | 46.65 |
|     sofa    | 22.84 | 24.63 |
|    train    | 51.37 | 84.81 |
|  tvmonitor  | 48.69 | 57.01 |
+-------------+-------+-------+
11/20 02:53:17 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 81.6800  mIoU: 42.1300  mAcc: 66.9800  data_time: 0.0018  time: 0.4699
Finished processing corruption type: brightness
Processing corruption type: contrast
11/20 02:53:20 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1527801186
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1527801186
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/20 02:53:21 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='contrast',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/contrast'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-20 02:53:25,630 - mmseg - INFO - using core type: DCNv3
2024-11-20 02:53:25,630 - mmseg - INFO - using activation layer: GELU
2024-11-20 02:53:25,631 - mmseg - INFO - using main norm layer: LN
2024-11-20 02:53:25,631 - mmseg - INFO - using dpr: linear, 0.3
2024-11-20 02:53:25,631 - mmseg - INFO - level2_post_norm: False
2024-11-20 02:53:25,631 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-20 02:53:25,631 - mmseg - INFO - res_post_norm: False
2024-11-20 02:53:25,631 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/20 02:53:27 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/20 02:53:27 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/20 02:53:29 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 02:53:30 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 02:54:18 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:22:02  time: 0.7386  data_time: 0.0015  memory: 21049  
11/20 02:54:51 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:18:02  time: 0.3040  data_time: 0.0015  memory: 21056  
11/20 02:55:22 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:16:03  time: 0.3711  data_time: 0.0014  memory: 21305  
11/20 02:55:50 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:14:28  time: 0.7815  data_time: 0.0015  memory: 21070  
11/20 02:56:13 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:13:01  time: 0.3227  data_time: 0.0015  memory: 21070  
11/20 02:56:33 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:11:39  time: 0.0891  data_time: 0.0014  memory: 21060  
11/20 02:56:55 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:10:41  time: 0.5246  data_time: 0.0015  memory: 21053  
11/20 02:57:12 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:09:41  time: 0.7934  data_time: 0.0015  memory: 21069  
11/20 02:57:24 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:08:39  time: 0.5007  data_time: 0.0015  memory: 21041  
11/20 02:57:50 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:08:12  time: 0.6238  data_time: 0.0014  memory: 21328  
11/20 02:58:06 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:07:30  time: 0.3124  data_time: 0.0014  memory: 21075  
11/20 02:58:17 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:06:45  time: 0.2463  data_time: 0.0014  memory: 21070  
11/20 02:58:35 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:06:13  time: 0.0877  data_time: 0.0014  memory: 21056  
11/20 02:58:49 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:05:40  time: 0.6210  data_time: 0.0015  memory: 21073  
11/20 02:59:02 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:05:09  time: 0.0840  data_time: 0.0014  memory: 21067  
11/20 02:59:14 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:04:38  time: 0.5357  data_time: 0.0014  memory: 21270  
11/20 02:59:26 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:04:10  time: 0.2456  data_time: 0.0014  memory: 21066  
11/20 02:59:37 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:03:43  time: 0.0903  data_time: 0.0014  memory: 21046  
11/20 02:59:42 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:03:14  time: 0.0883  data_time: 0.0015  memory: 776  
11/20 03:00:02 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:02:55  time: 0.5135  data_time: 0.0014  memory: 21075  
11/20 03:00:10 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:02:31  time: 0.0851  data_time: 0.0014  memory: 21050  
11/20 03:00:19 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:02:09  time: 0.5454  data_time: 0.0023  memory: 21288  
11/20 03:00:33 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:01:49  time: 0.2952  data_time: 0.0014  memory: 21064  
11/20 03:00:41 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:01:29  time: 0.2702  data_time: 0.0015  memory: 21069  
11/20 03:00:56 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:01:10  time: 0.2840  data_time: 0.0015  memory: 21275  
11/20 03:01:01 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:00:51  time: 0.0842  data_time: 0.0015  memory: 878  
11/20 03:01:05 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:00:33  time: 0.0885  data_time: 0.0015  memory: 861  
11/20 03:01:13 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:16  time: 0.0836  data_time: 0.0014  memory: 21036  
11/20 03:01:20 - mmengine - INFO - per class results:
11/20 03:01:20 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 82.69 | 86.86 |
|  aeroplane  | 45.84 | 80.03 |
|   bicycle   | 19.29 | 60.92 |
|     bird    | 38.43 |  44.8 |
|     boat    | 20.28 | 72.99 |
|    bottle   | 49.17 | 70.12 |
|     bus     | 59.36 | 87.95 |
|     car     | 48.05 | 92.42 |
|     cat     | 55.83 | 69.38 |
|    chair    | 15.78 | 21.11 |
|     cow     | 10.96 |  12.4 |
| diningtable | 30.49 | 75.12 |
|     dog     | 44.74 | 84.97 |
|    horse    | 33.74 | 65.41 |
|  motorbike  | 47.12 | 67.03 |
|    person   | 67.57 | 87.28 |
| pottedplant | 19.18 | 39.35 |
|    sheep    | 26.13 | 28.24 |
|     sofa    |  20.9 | 23.18 |
|    train    | 51.85 | 75.24 |
|  tvmonitor  |  46.0 |  52.6 |
+-------------+-------+-------+
11/20 03:01:20 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 81.7300  mIoU: 39.6900  mAcc: 61.7800  data_time: 0.0019  time: 0.3237
Finished processing corruption type: contrast
Processing corruption type: elastic_transform
11/20 03:01:23 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1345311119
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1345311119
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/20 03:01:24 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='elastic_transform',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/elastic_transform'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-20 03:01:28,338 - mmseg - INFO - using core type: DCNv3
2024-11-20 03:01:28,338 - mmseg - INFO - using activation layer: GELU
2024-11-20 03:01:28,338 - mmseg - INFO - using main norm layer: LN
2024-11-20 03:01:28,338 - mmseg - INFO - using dpr: linear, 0.3
2024-11-20 03:01:28,338 - mmseg - INFO - level2_post_norm: False
2024-11-20 03:01:28,338 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-20 03:01:28,338 - mmseg - INFO - res_post_norm: False
2024-11-20 03:01:28,338 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/20 03:01:30 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/20 03:01:30 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/20 03:01:31 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 03:01:33 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 03:03:07 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:43:57  time: 1.6503  data_time: 0.0015  memory: 21049  
11/20 03:04:25 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:38:41  time: 1.2243  data_time: 0.0015  memory: 21056  
11/20 03:05:46 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:36:31  time: 1.4269  data_time: 0.0015  memory: 21305  
11/20 03:07:02 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:34:11  time: 1.7393  data_time: 0.0016  memory: 21070  
11/20 03:08:12 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:31:51  time: 1.2489  data_time: 0.0015  memory: 21070  
11/20 03:09:19 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:29:44  time: 1.0218  data_time: 0.0015  memory: 21060  
11/20 03:10:27 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:27:54  time: 1.4532  data_time: 0.0015  memory: 21053  
11/20 03:11:33 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:26:13  time: 1.8844  data_time: 0.0016  memory: 21069  
11/20 03:12:36 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:24:30  time: 1.4252  data_time: 0.0015  memory: 21041  
11/20 03:13:55 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:23:26  time: 1.6834  data_time: 0.0015  memory: 21328  
11/20 03:14:58 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:21:55  time: 1.2524  data_time: 0.0015  memory: 21075  
11/20 03:15:55 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:20:19  time: 1.1935  data_time: 0.0015  memory: 21070  
11/20 03:17:00 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:18:58  time: 1.0356  data_time: 0.0015  memory: 21056  
11/20 03:18:01 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:17:36  time: 1.5988  data_time: 0.0015  memory: 21073  
11/20 03:19:01 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:16:16  time: 1.0097  data_time: 0.0015  memory: 21067  
11/20 03:20:02 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:14:59  time: 1.6043  data_time: 0.0015  memory: 21270  
11/20 03:21:01 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:13:42  time: 1.1743  data_time: 0.0015  memory: 21066  
11/20 03:21:59 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:12:27  time: 1.0523  data_time: 0.0015  memory: 21046  
11/20 03:22:50 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:11:10  time: 1.0538  data_time: 0.0016  memory: 776  
11/20 03:23:58 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:10:03  time: 1.4399  data_time: 0.0015  memory: 21075  
11/20 03:24:52 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:08:51  time: 1.0140  data_time: 0.0014  memory: 21050  
11/20 03:25:48 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:07:41  time: 1.5433  data_time: 0.0015  memory: 21288  
11/20 03:26:48 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:06:33  time: 1.2190  data_time: 0.0015  memory: 21064  
11/20 03:27:43 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:05:25  time: 1.2352  data_time: 0.0015  memory: 21069  
11/20 03:28:46 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:04:19  time: 1.2119  data_time: 0.0015  memory: 21275  
11/20 03:29:37 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:03:13  time: 1.0111  data_time: 0.0015  memory: 878  
11/20 03:30:29 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:02:07  time: 1.0635  data_time: 0.0015  memory: 861  
11/20 03:31:23 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:01:02  time: 1.0182  data_time: 0.0015  memory: 21036  
11/20 03:32:15 - mmengine - INFO - per class results:
11/20 03:32:15 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 78.59 | 82.46 |
|  aeroplane  | 45.11 | 82.57 |
|   bicycle   | 14.59 | 55.05 |
|     bird    | 45.14 | 59.81 |
|     boat    | 18.79 | 74.72 |
|    bottle   | 42.73 | 65.78 |
|     bus     | 55.87 | 83.35 |
|     car     | 48.91 | 89.48 |
|     cat     | 52.24 | 76.32 |
|    chair    |  11.9 | 14.61 |
|     cow     |  8.44 |  9.23 |
| diningtable | 29.32 | 75.36 |
|     dog     | 46.71 | 82.46 |
|    horse    | 31.83 | 67.44 |
|  motorbike  | 42.19 | 83.25 |
|    person   | 61.01 | 84.37 |
| pottedplant | 19.06 | 53.15 |
|    sheep    | 34.85 | 40.64 |
|     sofa    | 18.25 | 19.34 |
|    train    | 46.93 | 83.45 |
|  tvmonitor  | 41.52 | 51.39 |
+-------------+-------+-------+
11/20 03:32:15 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 78.7800  mIoU: 37.8100  mAcc: 63.5400  data_time: 0.0021  time: 1.2711
Finished processing corruption type: elastic_transform
Processing corruption type: pixelate
11/20 03:32:39 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1130542717
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1130542717
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/20 03:32:41 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='pixelate',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/pixelate'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-20 03:32:50,775 - mmseg - INFO - using core type: DCNv3
2024-11-20 03:32:50,775 - mmseg - INFO - using activation layer: GELU
2024-11-20 03:32:50,775 - mmseg - INFO - using main norm layer: LN
2024-11-20 03:32:50,775 - mmseg - INFO - using dpr: linear, 0.3
2024-11-20 03:32:50,775 - mmseg - INFO - level2_post_norm: False
2024-11-20 03:32:50,775 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-20 03:32:50,775 - mmseg - INFO - res_post_norm: False
2024-11-20 03:32:50,776 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/20 03:32:56 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/20 03:32:56 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/20 03:32:57 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 03:33:01 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 03:34:03 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:29:02  time: 0.7209  data_time: 0.0014  memory: 21049  
11/20 03:34:36 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:21:17  time: 0.2911  data_time: 0.0014  memory: 21056  
11/20 03:35:06 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:18:03  time: 0.3553  data_time: 0.0013  memory: 21305  
11/20 03:35:33 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:15:48  time: 0.7669  data_time: 0.0014  memory: 21070  
11/20 03:36:00 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:14:18  time: 0.3099  data_time: 0.0015  memory: 21070  
11/20 03:36:19 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:12:38  time: 0.0769  data_time: 0.0014  memory: 21060  
11/20 03:36:40 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:11:27  time: 0.5117  data_time: 0.0015  memory: 21053  
11/20 03:36:56 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:10:17  time: 0.7826  data_time: 0.0014  memory: 21069  
11/20 03:37:08 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:09:09  time: 0.4880  data_time: 0.0014  memory: 21041  
11/20 03:37:33 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:08:36  time: 0.6145  data_time: 0.0014  memory: 21328  
11/20 03:37:49 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:07:50  time: 0.2989  data_time: 0.0014  memory: 21075  
11/20 03:37:58 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:07:01  time: 0.2328  data_time: 0.0014  memory: 21070  
11/20 03:38:16 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:06:27  time: 0.0742  data_time: 0.0014  memory: 21056  
11/20 03:38:29 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:05:51  time: 0.6064  data_time: 0.0015  memory: 21073  
11/20 03:38:42 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:05:18  time: 0.0715  data_time: 0.0015  memory: 21067  
11/20 03:38:53 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:04:45  time: 0.5222  data_time: 0.0015  memory: 21270  
11/20 03:39:05 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:04:16  time: 0.2349  data_time: 0.0014  memory: 21066  
11/20 03:39:15 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:03:48  time: 0.0747  data_time: 0.0014  memory: 21046  
11/20 03:39:19 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:03:18  time: 0.0745  data_time: 0.0014  memory: 776  
11/20 03:39:39 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:02:58  time: 0.5037  data_time: 0.0014  memory: 21075  
11/20 03:39:46 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:02:34  time: 0.0726  data_time: 0.0014  memory: 21050  
11/20 03:39:54 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:02:11  time: 0.5297  data_time: 0.0014  memory: 21288  
11/20 03:40:08 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:01:50  time: 0.2827  data_time: 0.0014  memory: 21064  
11/20 03:40:15 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:01:30  time: 0.2574  data_time: 0.0014  memory: 21069  
11/20 03:40:30 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:01:11  time: 0.2709  data_time: 0.0014  memory: 21275  
11/20 03:40:33 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:00:51  time: 0.0698  data_time: 0.0014  memory: 878  
11/20 03:40:37 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:00:33  time: 0.0730  data_time: 0.0014  memory: 861  
11/20 03:40:44 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:16  time: 0.0692  data_time: 0.0014  memory: 21036  
11/20 03:40:50 - mmengine - INFO - per class results:
11/20 03:40:50 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 81.55 | 84.68 |
|  aeroplane  | 50.54 | 85.26 |
|   bicycle   | 16.76 | 59.86 |
|     bird    | 50.64 | 62.95 |
|     boat    | 21.08 | 74.25 |
|    bottle   | 43.69 | 68.31 |
|     bus     | 59.38 | 86.76 |
|     car     | 52.76 | 91.27 |
|     cat     | 54.73 | 76.48 |
|    chair    | 13.47 | 16.05 |
|     cow     | 10.73 | 11.71 |
| diningtable | 30.74 | 77.28 |
|     dog     | 48.45 | 84.56 |
|    horse    | 36.83 | 75.38 |
|  motorbike  | 47.25 | 86.56 |
|    person   | 67.77 | 89.13 |
| pottedplant | 22.07 | 58.32 |
|    sheep    | 40.72 | 45.54 |
|     sofa    | 19.76 | 20.78 |
|    train    | 47.32 | 85.73 |
|  tvmonitor  | 48.93 | 58.81 |
+-------------+-------+-------+
11/20 03:40:50 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 81.2400  mIoU: 41.2000  mAcc: 66.6500  data_time: 0.0020  time: 0.3238
Finished processing corruption type: pixelate
Processing corruption type: jpeg_compression
11/20 03:41:01 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1694216517
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1694216517
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/20 03:41:02 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='jpeg_compression',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/jpeg_compression'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-20 03:41:09,624 - mmseg - INFO - using core type: DCNv3
2024-11-20 03:41:09,624 - mmseg - INFO - using activation layer: GELU
2024-11-20 03:41:09,624 - mmseg - INFO - using main norm layer: LN
2024-11-20 03:41:09,624 - mmseg - INFO - using dpr: linear, 0.3
2024-11-20 03:41:09,624 - mmseg - INFO - level2_post_norm: False
2024-11-20 03:41:09,624 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-20 03:41:09,624 - mmseg - INFO - res_post_norm: False
2024-11-20 03:41:09,624 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/20 03:41:15 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/20 03:41:15 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/20 03:41:16 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 03:41:18 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 03:42:06 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:22:18  time: 0.7300  data_time: 0.0014  memory: 21049  
11/20 03:42:39 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:18:06  time: 0.2980  data_time: 0.0014  memory: 21056  
11/20 03:43:09 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:16:03  time: 0.3624  data_time: 0.0013  memory: 21305  
11/20 03:43:37 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:14:25  time: 0.7726  data_time: 0.0014  memory: 21070  
11/20 03:44:00 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:12:58  time: 0.3140  data_time: 0.0013  memory: 21070  
11/20 03:44:20 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:11:35  time: 0.0816  data_time: 0.0013  memory: 21060  
11/20 03:44:41 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:10:36  time: 0.5169  data_time: 0.0013  memory: 21053  
11/20 03:44:58 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:09:35  time: 0.7873  data_time: 0.0013  memory: 21069  
11/20 03:45:10 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:08:34  time: 0.4940  data_time: 0.0013  memory: 21041  
11/20 03:45:35 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:08:07  time: 0.6164  data_time: 0.0014  memory: 21328  
11/20 03:45:51 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:07:25  time: 0.3035  data_time: 0.0013  memory: 21075  
11/20 03:46:01 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:06:39  time: 0.2396  data_time: 0.0013  memory: 21070  
11/20 03:46:18 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:06:08  time: 0.0782  data_time: 0.0013  memory: 21056  
11/20 03:46:32 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:05:35  time: 0.6125  data_time: 0.0014  memory: 21073  
11/20 03:46:45 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:05:04  time: 0.0753  data_time: 0.0013  memory: 21067  
11/20 03:46:56 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:04:34  time: 0.5271  data_time: 0.0014  memory: 21270  
11/20 03:47:08 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:04:06  time: 0.2395  data_time: 0.0013  memory: 21066  
11/20 03:47:19 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:03:40  time: 0.0817  data_time: 0.0015  memory: 21046  
11/20 03:47:23 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:03:11  time: 0.0802  data_time: 0.0013  memory: 776  
11/20 03:47:43 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:02:52  time: 0.5080  data_time: 0.0013  memory: 21075  
11/20 03:47:50 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:02:29  time: 0.0761  data_time: 0.0013  memory: 21050  
11/20 03:47:59 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:02:07  time: 0.5380  data_time: 0.0014  memory: 21288  
11/20 03:48:12 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:01:47  time: 0.2883  data_time: 0.0014  memory: 21064  
11/20 03:48:21 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:01:27  time: 0.2649  data_time: 0.0014  memory: 21069  
11/20 03:48:35 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:01:09  time: 0.2766  data_time: 0.0014  memory: 21275  
11/20 03:48:39 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:00:50  time: 0.0763  data_time: 0.0018  memory: 878  
11/20 03:48:43 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:00:32  time: 0.0785  data_time: 0.0013  memory: 861  
11/20 03:48:50 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:15  time: 0.0748  data_time: 0.0013  memory: 21036  
11/20 03:48:57 - mmengine - INFO - per class results:
11/20 03:48:57 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 81.33 | 84.92 |
|  aeroplane  | 50.89 | 82.96 |
|   bicycle   | 16.36 | 60.69 |
|     bird    | 51.38 | 62.78 |
|     boat    | 19.89 | 77.79 |
|    bottle   | 40.97 | 67.63 |
|     bus     | 55.88 | 82.05 |
|     car     | 52.52 | 89.58 |
|     cat     | 54.61 | 75.78 |
|    chair    | 11.22 | 12.83 |
|     cow     | 10.74 | 11.63 |
| diningtable | 31.62 | 76.73 |
|     dog     | 51.15 | 80.35 |
|    horse    | 37.22 | 75.13 |
|  motorbike  | 46.38 | 86.72 |
|    person   | 68.56 | 87.26 |
| pottedplant | 22.72 | 57.61 |
|    sheep    | 42.64 | 48.53 |
|     sofa    | 16.46 | 17.12 |
|    train    | 42.76 | 87.37 |
|  tvmonitor  | 47.47 |  55.3 |
+-------------+-------+-------+
11/20 03:48:57 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 81.0300  mIoU: 40.6100  mAcc: 65.7500  data_time: 0.0017  time: 0.3164
Finished processing corruption type: jpeg_compression
Processing corruption type: elastic_transform
11/20 03:49:00 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1089178709
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1089178709
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/20 03:49:01 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='elastic_transform',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/elastic_transform'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-20 03:49:05,524 - mmseg - INFO - using core type: DCNv3
2024-11-20 03:49:05,524 - mmseg - INFO - using activation layer: GELU
2024-11-20 03:49:05,524 - mmseg - INFO - using main norm layer: LN
2024-11-20 03:49:05,524 - mmseg - INFO - using dpr: linear, 0.3
2024-11-20 03:49:05,524 - mmseg - INFO - level2_post_norm: False
2024-11-20 03:49:05,524 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-20 03:49:05,524 - mmseg - INFO - res_post_norm: False
2024-11-20 03:49:05,524 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/20 03:49:07 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/20 03:49:07 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/20 03:49:08 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 03:49:10 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 03:50:42 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:42:58  time: 1.6095  data_time: 0.0016  memory: 21049  
11/20 03:51:58 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:37:44  time: 1.1810  data_time: 0.0016  memory: 21056  
11/20 03:53:16 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:35:29  time: 1.3487  data_time: 0.0015  memory: 21305  
11/20 03:54:29 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:33:08  time: 1.6933  data_time: 0.0015  memory: 21070  
11/20 03:55:37 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:30:52  time: 1.2022  data_time: 0.0015  memory: 21070  
11/20 03:56:41 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:28:45  time: 0.9635  data_time: 0.0015  memory: 21060  
11/20 03:57:46 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:26:59  time: 1.4074  data_time: 0.0015  memory: 21053  
11/20 03:58:49 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:25:16  time: 1.7188  data_time: 0.0015  memory: 21069  
11/20 03:59:45 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:23:28  time: 1.3624  data_time: 0.0015  memory: 21041  
11/20 04:00:56 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:22:20  time: 1.6277  data_time: 0.0016  memory: 21328  
11/20 04:01:57 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:20:53  time: 1.2068  data_time: 0.0015  memory: 21075  
11/20 04:02:52 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:19:23  time: 1.1462  data_time: 0.0015  memory: 21070  
11/20 04:03:54 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:18:06  time: 0.9839  data_time: 0.0015  memory: 21056  
11/20 04:04:53 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:16:48  time: 1.5495  data_time: 0.0028  memory: 21073  
11/20 04:05:51 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:15:32  time: 0.9614  data_time: 0.0015  memory: 21067  
11/20 04:06:56 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:14:24  time: 1.5556  data_time: 0.0015  memory: 21270  
11/20 04:07:53 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:13:11  time: 1.1267  data_time: 0.0016  memory: 21066  
11/20 04:08:49 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:11:58  time: 1.0026  data_time: 0.0015  memory: 21046  
11/20 04:09:37 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:10:44  time: 1.0036  data_time: 0.0015  memory: 776  
11/20 04:10:43 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:09:40  time: 1.3947  data_time: 0.0015  memory: 21075  
11/20 04:11:35 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:08:30  time: 0.9712  data_time: 0.0015  memory: 21050  
11/20 04:12:28 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:07:23  time: 1.4953  data_time: 0.0015  memory: 21288  
11/20 04:13:28 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:06:18  time: 1.2387  data_time: 0.0016  memory: 21064  
11/20 04:14:24 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:05:14  time: 1.2391  data_time: 0.0016  memory: 21069  
11/20 04:15:27 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:04:10  time: 1.2258  data_time: 0.0016  memory: 21275  
11/20 04:16:23 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:03:07  time: 1.1437  data_time: 0.0016  memory: 878  
11/20 04:17:22 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:02:04  time: 1.1968  data_time: 0.0015  memory: 861  
11/20 04:18:22 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:01:01  time: 1.1398  data_time: 0.0015  memory: 21036  
11/20 04:19:20 - mmengine - INFO - per class results:
11/20 04:19:20 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 78.74 | 82.58 |
|  aeroplane  | 45.27 | 82.17 |
|   bicycle   | 14.52 | 57.94 |
|     bird    | 45.56 | 59.18 |
|     boat    |  18.5 | 73.13 |
|    bottle   |  40.4 | 64.61 |
|     bus     | 54.13 | 79.38 |
|     car     |  46.4 | 87.72 |
|     cat     | 50.33 | 73.88 |
|    chair    | 11.79 | 14.53 |
|     cow     |  8.49 |  9.26 |
| diningtable | 29.61 | 74.55 |
|     dog     | 45.53 | 81.82 |
|    horse    | 31.54 | 67.98 |
|  motorbike  | 40.96 | 82.34 |
|    person   | 60.69 | 84.62 |
| pottedplant | 19.81 | 52.78 |
|    sheep    | 36.62 |  42.0 |
|     sofa    | 17.87 | 18.99 |
|    train    | 45.74 | 81.18 |
|  tvmonitor  | 46.39 | 53.97 |
+-------------+-------+-------+
11/20 04:19:20 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 78.6700  mIoU: 37.5700  mAcc: 63.0800  data_time: 0.0024  time: 1.2490
Finished processing corruption type: elastic_transform
Processing corruption type: pixelate
11/20 04:19:31 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 742774426
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 742774426
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/20 04:19:33 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='pixelate',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/pixelate'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-20 04:19:41,613 - mmseg - INFO - using core type: DCNv3
2024-11-20 04:19:41,613 - mmseg - INFO - using activation layer: GELU
2024-11-20 04:19:41,613 - mmseg - INFO - using main norm layer: LN
2024-11-20 04:19:41,613 - mmseg - INFO - using dpr: linear, 0.3
2024-11-20 04:19:41,613 - mmseg - INFO - level2_post_norm: False
2024-11-20 04:19:41,613 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-20 04:19:41,613 - mmseg - INFO - res_post_norm: False
2024-11-20 04:19:41,613 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/20 04:19:44 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/20 04:19:44 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/20 04:19:46 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 04:19:49 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 04:20:46 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:26:28  time: 0.7341  data_time: 0.0017  memory: 21049  
11/20 04:21:18 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:20:09  time: 0.2994  data_time: 0.0016  memory: 21056  
11/20 04:21:49 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:17:22  time: 0.3623  data_time: 0.0016  memory: 21305  
11/20 04:22:17 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:15:23  time: 0.7743  data_time: 0.0016  memory: 21070  
11/20 04:22:40 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:13:43  time: 0.3167  data_time: 0.0016  memory: 21070  
11/20 04:23:00 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:12:11  time: 0.0825  data_time: 0.0016  memory: 21060  
11/20 04:23:21 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:11:06  time: 0.5183  data_time: 0.0016  memory: 21053  
11/20 04:23:38 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:10:01  time: 0.7888  data_time: 0.0016  memory: 21069  
11/20 04:23:50 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:08:56  time: 0.4964  data_time: 0.0016  memory: 21041  
11/20 04:24:16 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:08:26  time: 0.6202  data_time: 0.0016  memory: 21328  
11/20 04:24:32 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:07:42  time: 0.3068  data_time: 0.0016  memory: 21075  
11/20 04:24:42 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:06:54  time: 0.2393  data_time: 0.0016  memory: 21070  
11/20 04:24:59 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:06:21  time: 0.0827  data_time: 0.0022  memory: 21056  
11/20 04:25:13 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:05:46  time: 0.6136  data_time: 0.0016  memory: 21073  
11/20 04:25:27 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:05:14  time: 0.0779  data_time: 0.0017  memory: 21067  
11/20 04:25:38 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:04:43  time: 0.5251  data_time: 0.0016  memory: 21270  
11/20 04:25:50 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:04:14  time: 0.2421  data_time: 0.0016  memory: 21066  
11/20 04:26:00 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:03:46  time: 0.0834  data_time: 0.0016  memory: 21046  
11/20 04:26:04 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:03:17  time: 0.0828  data_time: 0.0016  memory: 776  
11/20 04:26:25 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:02:57  time: 0.5106  data_time: 0.0016  memory: 21075  
11/20 04:26:33 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:02:33  time: 0.0802  data_time: 0.0016  memory: 21050  
11/20 04:26:41 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:02:10  time: 0.5375  data_time: 0.0016  memory: 21288  
11/20 04:26:55 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:01:50  time: 0.2905  data_time: 0.0016  memory: 21064  
11/20 04:27:03 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:01:30  time: 0.2645  data_time: 0.0017  memory: 21069  
11/20 04:27:18 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:01:11  time: 0.2776  data_time: 0.0016  memory: 21275  
11/20 04:27:22 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:00:51  time: 0.0796  data_time: 0.0016  memory: 878  
11/20 04:27:26 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:00:33  time: 0.0799  data_time: 0.0016  memory: 861  
11/20 04:27:33 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:16  time: 0.0786  data_time: 0.0016  memory: 21036  
11/20 04:27:40 - mmengine - INFO - per class results:
11/20 04:27:40 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 81.55 | 84.68 |
|  aeroplane  | 50.54 | 85.26 |
|   bicycle   | 16.76 | 59.86 |
|     bird    | 50.64 | 62.95 |
|     boat    | 21.08 | 74.25 |
|    bottle   | 43.69 | 68.31 |
|     bus     | 59.38 | 86.76 |
|     car     | 52.76 | 91.27 |
|     cat     | 54.73 | 76.48 |
|    chair    | 13.47 | 16.05 |
|     cow     | 10.73 | 11.71 |
| diningtable | 30.74 | 77.28 |
|     dog     | 48.45 | 84.56 |
|    horse    | 36.83 | 75.38 |
|  motorbike  | 47.25 | 86.56 |
|    person   | 67.77 | 89.13 |
| pottedplant | 22.07 | 58.32 |
|    sheep    | 40.72 | 45.54 |
|     sofa    | 19.76 | 20.78 |
|    train    | 47.32 | 85.73 |
|  tvmonitor  | 48.93 | 58.81 |
+-------------+-------+-------+
11/20 04:27:40 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 81.2400  mIoU: 41.2000  mAcc: 66.6500  data_time: 0.0020  time: 0.3248
Finished processing corruption type: pixelate
Processing corruption type: jpeg_compression
11/20 04:27:43 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.8.20 (default, Oct  3 2024, 15:24:27) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 790605440
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 790605440
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/20 04:27:45 - mmengine - INFO - Config:
checkpoint_config = dict(by_epoch=False, interval=1000, max_keep_ckpts=1)
crop_size = (
    512,
    512,
)
data = dict(
    samples_per_gpu=2,
    test=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]),
    val=dict(pipeline=[
        dict(type='LoadImageFromFile'),
        dict(
            flip=False,
            img_scale=(
                512,
                512,
            ),
            transforms=[
                dict(keep_ratio=True, type='Resize'),
                dict(size_divisor=32, type='ResizeToMultiple'),
                dict(type='RandomFlip'),
                dict(
                    mean=[
                        123.675,
                        116.28,
                        103.53,
                    ],
                    std=[
                        58.395,
                        57.12,
                        57.375,
                    ],
                    to_rgb=True,
                    type='Normalize'),
                dict(keys=[
                    'img',
                ], type='ImageToTensor'),
                dict(keys=[
                    'img',
                ], type='Collect'),
            ],
            type='MultiScaleFlipAug'),
    ]))
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=16000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
evaluation = dict(interval=16000, metric='mIoU', save_best='mIoU')
img_norm_cfg = dict(
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    std=[
        58.395,
        57.12,
        57.375,
    ],
    to_rgb=True)
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = '../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth'
log_level = 'INFO'
log_processor = dict(by_epoch=False)
lr_config = dict(
    _delete_=True,
    by_epoch=False,
    min_lr=0.0,
    policy='poly',
    power=1.0,
    warmup='linear',
    warmup_iters=1500,
    warmup_ratio=1e-06)
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=320,
        in_index=2,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        channels=80,
        core_op='DCNv3',
        depths=[
            4,
            4,
            21,
            4,
        ],
        drop_path_rate=0.3,
        groups=[
            5,
            10,
            20,
            40,
        ],
        init_cfg=dict(
            checkpoint=
            'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth',
            type='Pretrained'),
        layer_scale=1.0,
        mlp_ratio=4.0,
        norm_layer='LN',
        offset_scale=1.0,
        post_norm=True,
        type='InternImage',
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption='jpeg_compression',
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=512,
        dropout_ratio=0.1,
        in_channels=[
            80,
            160,
            320,
            640,
        ],
        in_index=[
            0,
            1,
            2,
            3,
        ],
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='UPerHead'),
    pretrained='open-mmlab://resnet50_v1c',
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=None,
    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    constructor='CustomLayerDecayOptimizerConstructor',
    lr=6e-05,
    paramwise_cfg=dict(
        depths=[
            4,
            4,
            21,
            4,
        ], layer_decay_rate=1.0, num_layers=33),
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0.0001,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://huggingface.co/OpenGVLab/InternImage/resolve/main/internimage_s_1k_224.pth'
resume = False
runner = dict(type='IterBasedRunner')
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        flip=False,
        img_scale=(
            512,
            512,
        ),
        transforms=[
            dict(keep_ratio=True, type='Resize'),
            dict(size_divisor=32, type='ResizeToMultiple'),
            dict(type='RandomFlip'),
            dict(
                mean=[
                    123.675,
                    116.28,
                    103.53,
                ],
                std=[
                    58.395,
                    57.12,
                    57.375,
                ],
                to_rgb=True,
                type='Normalize'),
            dict(keys=[
                'img',
            ], type='ImageToTensor'),
            dict(keys=[
                'img',
            ], type='Collect'),
        ],
        type='MultiScaleFlipAug'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=16000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../corruptions/work_dirs/pascalvoc/internimage/upernet_internimage_s_160k_voc12aug_512x512/jpeg_compression'

/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
/pfs/work7/workspace/scratch/ma_mkacar-team_project_fss2024/miniconda3/envs/py310/lib/python3.8/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers
  warnings.warn(f"Importing from {__name__} is deprecated, please import via timm.layers", FutureWarning)
2024-11-20 04:27:49,581 - mmseg - INFO - using core type: DCNv3
2024-11-20 04:27:49,581 - mmseg - INFO - using activation layer: GELU
2024-11-20 04:27:49,581 - mmseg - INFO - using main norm layer: LN
2024-11-20 04:27:49,581 - mmseg - INFO - using dpr: linear, 0.3
2024-11-20 04:27:49,582 - mmseg - INFO - level2_post_norm: False
2024-11-20 04:27:49,582 - mmseg - INFO - level2_post_norm_block_ids: None
2024-11-20 04:27:49,582 - mmseg - INFO - res_post_norm: False
2024-11-20 04:27:49,582 - mmseg - INFO - use_dcn_v4_op: False
Number of parameters:  79866956
11/20 04:27:51 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/20 04:27:51 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/20 04:27:53 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by local backend from path: ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 04:27:55 - mmengine - INFO - Load checkpoint from ../checkpoint_files/pascalvoc/internimage/Bestiter_internimage_s_512x512_160000.pth
11/20 04:28:43 - mmengine - INFO - Iter(test) [  50/1449]    eta: 0:22:11  time: 0.7412  data_time: 0.0016  memory: 21049  
11/20 04:29:16 - mmengine - INFO - Iter(test) [ 100/1449]    eta: 0:18:10  time: 0.3090  data_time: 0.0017  memory: 21056  
11/20 04:29:47 - mmengine - INFO - Iter(test) [ 150/1449]    eta: 0:16:09  time: 0.3716  data_time: 0.0015  memory: 21305  
11/20 04:30:15 - mmengine - INFO - Iter(test) [ 200/1449]    eta: 0:14:33  time: 0.7845  data_time: 0.0017  memory: 21070  
11/20 04:30:39 - mmengine - INFO - Iter(test) [ 250/1449]    eta: 0:13:06  time: 0.3241  data_time: 0.0016  memory: 21070  
11/20 04:30:59 - mmengine - INFO - Iter(test) [ 300/1449]    eta: 0:11:43  time: 0.0909  data_time: 0.0016  memory: 21060  
11/20 04:31:20 - mmengine - INFO - Iter(test) [ 350/1449]    eta: 0:10:44  time: 0.5263  data_time: 0.0017  memory: 21053  
11/20 04:31:38 - mmengine - INFO - Iter(test) [ 400/1449]    eta: 0:09:44  time: 0.7948  data_time: 0.0017  memory: 21069  
11/20 04:31:50 - mmengine - INFO - Iter(test) [ 450/1449]    eta: 0:08:42  time: 0.5050  data_time: 0.0017  memory: 21041  
11/20 04:32:16 - mmengine - INFO - Iter(test) [ 500/1449]    eta: 0:08:15  time: 0.6271  data_time: 0.0017  memory: 21328  
11/20 04:32:33 - mmengine - INFO - Iter(test) [ 550/1449]    eta: 0:07:33  time: 0.3135  data_time: 0.0016  memory: 21075  
11/20 04:32:43 - mmengine - INFO - Iter(test) [ 600/1449]    eta: 0:06:47  time: 0.2487  data_time: 0.0017  memory: 21070  
11/20 04:33:01 - mmengine - INFO - Iter(test) [ 650/1449]    eta: 0:06:15  time: 0.0883  data_time: 0.0017  memory: 21056  
11/20 04:33:15 - mmengine - INFO - Iter(test) [ 700/1449]    eta: 0:05:42  time: 0.6225  data_time: 0.0017  memory: 21073  
11/20 04:33:29 - mmengine - INFO - Iter(test) [ 750/1449]    eta: 0:05:11  time: 0.0862  data_time: 0.0017  memory: 21067  
11/20 04:33:41 - mmengine - INFO - Iter(test) [ 800/1449]    eta: 0:04:40  time: 0.5328  data_time: 0.0017  memory: 21270  
11/20 04:33:53 - mmengine - INFO - Iter(test) [ 850/1449]    eta: 0:04:12  time: 0.2497  data_time: 0.0017  memory: 21066  
11/20 04:34:04 - mmengine - INFO - Iter(test) [ 900/1449]    eta: 0:03:45  time: 0.0930  data_time: 0.0017  memory: 21046  
11/20 04:34:09 - mmengine - INFO - Iter(test) [ 950/1449]    eta: 0:03:16  time: 0.0902  data_time: 0.0017  memory: 776  
11/20 04:34:29 - mmengine - INFO - Iter(test) [1000/1449]    eta: 0:02:56  time: 0.5176  data_time: 0.0017  memory: 21075  
11/20 04:34:38 - mmengine - INFO - Iter(test) [1050/1449]    eta: 0:02:32  time: 0.0875  data_time: 0.0017  memory: 21050  
11/20 04:34:47 - mmengine - INFO - Iter(test) [1100/1449]    eta: 0:02:10  time: 0.5470  data_time: 0.0017  memory: 21288  
11/20 04:35:00 - mmengine - INFO - Iter(test) [1150/1449]    eta: 0:01:50  time: 0.2979  data_time: 0.0017  memory: 21064  
11/20 04:35:09 - mmengine - INFO - Iter(test) [1200/1449]    eta: 0:01:30  time: 0.2731  data_time: 0.0017  memory: 21069  
11/20 04:35:24 - mmengine - INFO - Iter(test) [1250/1449]    eta: 0:01:11  time: 0.2855  data_time: 0.0017  memory: 21275  
11/20 04:35:29 - mmengine - INFO - Iter(test) [1300/1449]    eta: 0:00:51  time: 0.0854  data_time: 0.0017  memory: 878  
11/20 04:35:33 - mmengine - INFO - Iter(test) [1350/1449]    eta: 0:00:33  time: 0.0877  data_time: 0.0017  memory: 861  
11/20 04:35:41 - mmengine - INFO - Iter(test) [1400/1449]    eta: 0:00:16  time: 0.0850  data_time: 0.0017  memory: 21036  
11/20 04:35:48 - mmengine - INFO - per class results:
11/20 04:35:48 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 81.33 | 84.92 |
|  aeroplane  | 50.89 | 82.96 |
|   bicycle   | 16.36 | 60.69 |
|     bird    | 51.38 | 62.78 |
|     boat    | 19.89 | 77.79 |
|    bottle   | 40.97 | 67.63 |
|     bus     | 55.88 | 82.05 |
|     car     | 52.52 | 89.58 |
|     cat     | 54.61 | 75.78 |
|    chair    | 11.22 | 12.83 |
|     cow     | 10.74 | 11.63 |
| diningtable | 31.62 | 76.73 |
|     dog     | 51.15 | 80.35 |
|    horse    | 37.22 | 75.13 |
|  motorbike  | 46.38 | 86.72 |
|    person   | 68.56 | 87.26 |
| pottedplant | 22.72 | 57.61 |
|    sheep    | 42.64 | 48.53 |
|     sofa    | 16.46 | 17.12 |
|    train    | 42.76 | 87.37 |
|  tvmonitor  | 47.47 |  55.3 |
+-------------+-------+-------+
11/20 04:35:48 - mmengine - INFO - Iter(test) [1449/1449]    aAcc: 81.0300  mIoU: 40.6100  mAcc: 65.7500  data_time: 0.0020  time: 0.3260
Finished processing corruption type: jpeg_compression
Runtime: 1732073748

============================= JOB FEEDBACK =============================

NodeName=uc2n488
Job ID: 24733600
Cluster: uc2
User/Group: ma_mkacar/ma_ma
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 6
CPU Utilized: 05:13:14
CPU Efficiency: 12.53% of 1-17:39:00 core-walltime
Job Wall-clock time: 06:56:30
Memory Utilized: 3.63 GB
Memory Efficiency: 36.31% of 10.00 GB
