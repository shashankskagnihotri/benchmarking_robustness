Started at Fri Nov 15 06:41:49 CET 2024
11/15 06:43:54 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.10.13 | packaged by conda-forge | (main, Dec 23 2023, 15:36:39) [GCC 12.3.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1338473935
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: None
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 3.4.18
    MMEngine: 0.10.4

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1338473935
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

11/15 06:43:54 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16, enable=False)
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
crop_size = (
    512,
    1024,
)
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.10.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.11.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.12.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.13.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.14.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.15.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.16.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.17.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.6.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.7.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.8.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.9.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    corruption=None,
    enable_normalization=False,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        1024,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = 'data/cityscapes/'
dataset_type = 'CityscapesDataset'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False, interval=5000, save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    18,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    attack_loss=dict(
        loss_weight=1.0,
        reduction='none',
        type='CrossEntropyLoss',
        use_sigmoid=False),
    backbone=dict(
        attn_drop_rate=0.0,
        depths=[
            2,
            2,
            18,
            2,
        ],
        drop_path_rate=0.3,
        drop_rate=0.0,
        embed_dims=128,
        frozen_stages=-1,
        init_cfg=dict(
            checkpoint=
            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_base_patch4_window12_384_20220317-55b0104a.pth',
            type='Pretrained'),
        mlp_ratio=4,
        num_heads=[
            4,
            8,
            16,
            32,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        pretrain_img_size=384,
        qk_scale=None,
        qkv_bias=True,
        type='SwinTransformer',
        window_size=12,
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        corruption=None,
        enable_normalization=False,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            1024,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            128,
            256,
            512,
            1024,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='none',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='none',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='none',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=19,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    normalize_mean_std=dict(
        mean=[
            123.675,
            116.28,
            103.53,
        ], std=[
            58.395,
            57.12,
            57.375,
        ]),
    perform_attack=False,
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 19
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.10.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.11.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.12.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.13.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.14.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.15.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.16.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.17.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.6.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.7.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.8.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.9.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=90000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_base_patch4_window12_384_20220317-55b0104a.pth'
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(
            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),
        data_root='data/cityscapes/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='CityscapesDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        1024,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(max_iters=90000, type='IterBasedTrainLoop', val_interval=5000)
train_dataloader = dict(
    batch_size=2,
    dataset=dict(
        data_prefix=dict(
            img_path='leftImg8bit/train', seg_map_path='gtFine/train'),
        data_root='data/cityscapes/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='LoadAnnotations'),
            dict(
                max_size=4096,
                resize_type='ResizeShortestEdge',
                scales=[
                    512,
                    614,
                    716,
                    819,
                    921,
                    1024,
                    1126,
                    1228,
                    1331,
                    1433,
                    1536,
                    1638,
                    1740,
                    1843,
                    1945,
                    2048,
                ],
                type='RandomChoiceResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    1024,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='CityscapesDataset'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        max_size=4096,
        resize_type='ResizeShortestEdge',
        scales=[
            512,
            614,
            716,
            819,
            921,
            1024,
            1126,
            1228,
            1331,
            1433,
            1536,
            1638,
            1740,
            1843,
            1945,
            2048,
        ],
        type='RandomChoiceResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        1024,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(
            img_path='leftImg8bit/val', seg_map_path='gtFine/val'),
        data_root='data/cityscapes/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                1024,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='CityscapesDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024'

/pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
Number of parameters:  106888524
11/15 06:45:14 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
11/15 06:45:14 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.6.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.7.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.8.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.9.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.10.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.11.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.12.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.13.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.14.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.15.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.16.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.17.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:decay_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
11/15 06:45:17 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
11/15 06:45:17 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
11/15 06:45:17 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_base_patch4_window12_384_20220317-55b0104a.pth
11/15 06:45:21 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
11/15 06:45:21 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
11/15 06:45:21 - mmengine - INFO - Checkpoints will be saved to /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024.
11/15 06:47:24 - mmengine - INFO - Iter(train) [   50/90000]  base_lr: 9.9951e-05 lr: 9.9951e-06  eta: 2 days, 13:13:21  time: 0.5903  data_time: 0.0104  memory: 24808  grad_norm: 115.6994  loss: 62.7585  decode.loss_cls: 0.6998  decode.loss_mask: 1.4292  decode.loss_dice: 4.2611  decode.d0.loss_cls: 0.9693  decode.d0.loss_mask: 1.5291  decode.d0.loss_dice: 3.8894  decode.d1.loss_cls: 0.6639  decode.d1.loss_mask: 1.5743  decode.d1.loss_dice: 3.8677  decode.d2.loss_cls: 0.6343  decode.d2.loss_mask: 1.5675  decode.d2.loss_dice: 3.9206  decode.d3.loss_cls: 0.6542  decode.d3.loss_mask: 1.5441  decode.d3.loss_dice: 3.9329  decode.d4.loss_cls: 0.7110  decode.d4.loss_mask: 1.5656  decode.d4.loss_dice: 4.0347  decode.d5.loss_cls: 0.6915  decode.d5.loss_mask: 1.5069  decode.d5.loss_dice: 4.0257  decode.d6.loss_cls: 0.6751  decode.d6.loss_mask: 1.5629  decode.d6.loss_dice: 4.0101  decode.d7.loss_cls: 0.6839  decode.d7.loss_mask: 1.5069  decode.d7.loss_dice: 4.0744  decode.d8.loss_cls: 0.6954  decode.d8.loss_mask: 1.5379  decode.d8.loss_dice: 4.3391
11/15 06:47:53 - mmengine - INFO - Iter(train) [  100/90000]  base_lr: 9.9901e-05 lr: 9.9901e-06  eta: 1 day, 13:57:50  time: 0.5909  data_time: 0.0104  memory: 10656  grad_norm: 117.0827  loss: 58.5693  decode.loss_cls: 0.6745  decode.loss_mask: 1.4679  decode.loss_dice: 3.7879  decode.d0.loss_cls: 0.9726  decode.d0.loss_mask: 1.4568  decode.d0.loss_dice: 3.7623  decode.d1.loss_cls: 0.6080  decode.d1.loss_mask: 1.4338  decode.d1.loss_dice: 3.6401  decode.d2.loss_cls: 0.5925  decode.d2.loss_mask: 1.4696  decode.d2.loss_dice: 3.6338  decode.d3.loss_cls: 0.6051  decode.d3.loss_mask: 1.4578  decode.d3.loss_dice: 3.6246  decode.d4.loss_cls: 0.6437  decode.d4.loss_mask: 1.4893  decode.d4.loss_dice: 3.7871  decode.d5.loss_cls: 0.6481  decode.d5.loss_mask: 1.5017  decode.d5.loss_dice: 3.7097  decode.d6.loss_cls: 0.6518  decode.d6.loss_mask: 1.4878  decode.d6.loss_dice: 3.7120  decode.d7.loss_cls: 0.6687  decode.d7.loss_mask: 1.4555  decode.d7.loss_dice: 3.7012  decode.d8.loss_cls: 0.6725  decode.d8.loss_mask: 1.4875  decode.d8.loss_dice: 3.7654
11/15 06:48:23 - mmengine - INFO - Iter(train) [  150/90000]  base_lr: 9.9851e-05 lr: 9.9851e-06  eta: 1 day, 6:12:49  time: 0.5907  data_time: 0.0096  memory: 10693  grad_norm: 183.5963  loss: 56.0247  decode.loss_cls: 0.6962  decode.loss_mask: 1.4328  decode.loss_dice: 3.6018  decode.d0.loss_cls: 0.9955  decode.d0.loss_mask: 1.3521  decode.d0.loss_dice: 3.6398  decode.d1.loss_cls: 0.5957  decode.d1.loss_mask: 1.3513  decode.d1.loss_dice: 3.5469  decode.d2.loss_cls: 0.5772  decode.d2.loss_mask: 1.4191  decode.d2.loss_dice: 3.5434  decode.d3.loss_cls: 0.5919  decode.d3.loss_mask: 1.4239  decode.d3.loss_dice: 3.4783  decode.d4.loss_cls: 0.6405  decode.d4.loss_mask: 1.3904  decode.d4.loss_dice: 3.4993  decode.d5.loss_cls: 0.6513  decode.d5.loss_mask: 1.3945  decode.d5.loss_dice: 3.5058  decode.d6.loss_cls: 0.6608  decode.d6.loss_mask: 1.4449  decode.d6.loss_dice: 3.5107  decode.d7.loss_cls: 0.6695  decode.d7.loss_mask: 1.3983  decode.d7.loss_dice: 3.4643  decode.d8.loss_cls: 0.6785  decode.d8.loss_mask: 1.3757  decode.d8.loss_dice: 3.4941
11/15 06:48:52 - mmengine - INFO - Iter(train) [  200/90000]  base_lr: 9.9801e-05 lr: 9.9801e-06  eta: 1 day, 2:20:17  time: 0.5939  data_time: 0.0110  memory: 10710  grad_norm: 189.8241  loss: 52.3762  decode.loss_cls: 0.6018  decode.loss_mask: 1.3919  decode.loss_dice: 3.2821  decode.d0.loss_cls: 0.9442  decode.d0.loss_mask: 1.3681  decode.d0.loss_dice: 3.4237  decode.d1.loss_cls: 0.4910  decode.d1.loss_mask: 1.3784  decode.d1.loss_dice: 3.3148  decode.d2.loss_cls: 0.4793  decode.d2.loss_mask: 1.3662  decode.d2.loss_dice: 3.2656  decode.d3.loss_cls: 0.4851  decode.d3.loss_mask: 1.3722  decode.d3.loss_dice: 3.2040  decode.d4.loss_cls: 0.5302  decode.d4.loss_mask: 1.4030  decode.d4.loss_dice: 3.2261  decode.d5.loss_cls: 0.5658  decode.d5.loss_mask: 1.4410  decode.d5.loss_dice: 3.1978  decode.d6.loss_cls: 0.5896  decode.d6.loss_mask: 1.3995  decode.d6.loss_dice: 3.2178  decode.d7.loss_cls: 0.5969  decode.d7.loss_mask: 1.3706  decode.d7.loss_dice: 3.1941  decode.d8.loss_cls: 0.5937  decode.d8.loss_mask: 1.4146  decode.d8.loss_dice: 3.2669
11/15 06:49:22 - mmengine - INFO - Iter(train) [  250/90000]  base_lr: 9.9751e-05 lr: 9.9751e-06  eta: 1 day, 0:00:25  time: 0.5915  data_time: 0.0100  memory: 10642  grad_norm: 303.6915  loss: 51.2759  decode.loss_cls: 0.5282  decode.loss_mask: 1.5311  decode.loss_dice: 3.0817  decode.d0.loss_cls: 0.9159  decode.d0.loss_mask: 1.5077  decode.d0.loss_dice: 3.2522  decode.d1.loss_cls: 0.4389  decode.d1.loss_mask: 1.5815  decode.d1.loss_dice: 3.0626  decode.d2.loss_cls: 0.4099  decode.d2.loss_mask: 1.5523  decode.d2.loss_dice: 3.0239  decode.d3.loss_cls: 0.4327  decode.d3.loss_mask: 1.5600  decode.d3.loss_dice: 3.0537  decode.d4.loss_cls: 0.4639  decode.d4.loss_mask: 1.4931  decode.d4.loss_dice: 2.9748  decode.d5.loss_cls: 0.4892  decode.d5.loss_mask: 1.5640  decode.d5.loss_dice: 2.9856  decode.d6.loss_cls: 0.5388  decode.d6.loss_mask: 1.4919  decode.d6.loss_dice: 3.0418  decode.d7.loss_cls: 0.5338  decode.d7.loss_mask: 1.5401  decode.d7.loss_dice: 3.0889  decode.d8.loss_cls: 0.5192  decode.d8.loss_mask: 1.5759  decode.d8.loss_dice: 3.0427
11/15 06:49:52 - mmengine - INFO - Iter(train) [  300/90000]  base_lr: 9.9701e-05 lr: 9.9701e-06  eta: 22:27:04  time: 0.5917  data_time: 0.0097  memory: 10673  grad_norm: 276.7968  loss: 49.3639  decode.loss_cls: 0.5709  decode.loss_mask: 1.3525  decode.loss_dice: 3.0039  decode.d0.loss_cls: 0.8836  decode.d0.loss_mask: 1.2520  decode.d0.loss_dice: 3.2915  decode.d1.loss_cls: 0.4255  decode.d1.loss_mask: 1.3304  decode.d1.loss_dice: 3.1219  decode.d2.loss_cls: 0.4086  decode.d2.loss_mask: 1.3564  decode.d2.loss_dice: 3.0803  decode.d3.loss_cls: 0.4068  decode.d3.loss_mask: 1.3448  decode.d3.loss_dice: 3.0866  decode.d4.loss_cls: 0.4580  decode.d4.loss_mask: 1.3235  decode.d4.loss_dice: 3.0568  decode.d5.loss_cls: 0.4898  decode.d5.loss_mask: 1.3397  decode.d5.loss_dice: 3.0563  decode.d6.loss_cls: 0.5358  decode.d6.loss_mask: 1.3674  decode.d6.loss_dice: 3.0141  decode.d7.loss_cls: 0.5572  decode.d7.loss_mask: 1.3772  decode.d7.loss_dice: 3.0072  decode.d8.loss_cls: 0.5704  decode.d8.loss_mask: 1.3235  decode.d8.loss_dice: 2.9711
11/15 06:50:21 - mmengine - INFO - Iter(train) [  350/90000]  base_lr: 9.9651e-05 lr: 9.9651e-06  eta: 21:20:18  time: 0.5926  data_time: 0.0097  memory: 10693  grad_norm: 497.1151  loss: 48.2837  decode.loss_cls: 0.5270  decode.loss_mask: 1.3085  decode.loss_dice: 2.9743  decode.d0.loss_cls: 0.8893  decode.d0.loss_mask: 1.2263  decode.d0.loss_dice: 3.2262  decode.d1.loss_cls: 0.3983  decode.d1.loss_mask: 1.2871  decode.d1.loss_dice: 3.0512  decode.d2.loss_cls: 0.3536  decode.d2.loss_mask: 1.3011  decode.d2.loss_dice: 3.0450  decode.d3.loss_cls: 0.3667  decode.d3.loss_mask: 1.2967  decode.d3.loss_dice: 3.0170  decode.d4.loss_cls: 0.4187  decode.d4.loss_mask: 1.3096  decode.d4.loss_dice: 2.9642  decode.d5.loss_cls: 0.4590  decode.d5.loss_mask: 1.3319  decode.d5.loss_dice: 2.9547  decode.d6.loss_cls: 0.4891  decode.d6.loss_mask: 1.3403  decode.d6.loss_dice: 2.9616  decode.d7.loss_cls: 0.5136  decode.d7.loss_mask: 1.3841  decode.d7.loss_dice: 3.0025  decode.d8.loss_cls: 0.5157  decode.d8.loss_mask: 1.3608  decode.d8.loss_dice: 3.0098
11/15 06:50:51 - mmengine - INFO - Iter(train) [  400/90000]  base_lr: 9.9601e-05 lr: 9.9601e-06  eta: 20:29:57  time: 0.5890  data_time: 0.0093  memory: 10693  grad_norm: 402.1720  loss: 46.6667  decode.loss_cls: 0.5124  decode.loss_mask: 1.3081  decode.loss_dice: 2.7573  decode.d0.loss_cls: 0.8945  decode.d0.loss_mask: 1.2614  decode.d0.loss_dice: 3.0302  decode.d1.loss_cls: 0.3646  decode.d1.loss_mask: 1.3640  decode.d1.loss_dice: 2.9217  decode.d2.loss_cls: 0.3577  decode.d2.loss_mask: 1.3754  decode.d2.loss_dice: 2.8838  decode.d3.loss_cls: 0.3640  decode.d3.loss_mask: 1.4157  decode.d3.loss_dice: 2.8707  decode.d4.loss_cls: 0.4098  decode.d4.loss_mask: 1.4094  decode.d4.loss_dice: 2.8242  decode.d5.loss_cls: 0.4230  decode.d5.loss_mask: 1.3627  decode.d5.loss_dice: 2.8031  decode.d6.loss_cls: 0.4630  decode.d6.loss_mask: 1.3477  decode.d6.loss_dice: 2.7526  decode.d7.loss_cls: 0.5056  decode.d7.loss_mask: 1.3338  decode.d7.loss_dice: 2.7397  decode.d8.loss_cls: 0.5077  decode.d8.loss_mask: 1.3331  decode.d8.loss_dice: 2.7696
11/15 06:51:20 - mmengine - INFO - Iter(train) [  450/90000]  base_lr: 9.9551e-05 lr: 9.9551e-06  eta: 19:50:35  time: 0.5922  data_time: 0.0098  memory: 10710  grad_norm: 368.6119  loss: 42.5387  decode.loss_cls: 0.4603  decode.loss_mask: 1.1550  decode.loss_dice: 2.6461  decode.d0.loss_cls: 0.8580  decode.d0.loss_mask: 1.1188  decode.d0.loss_dice: 2.9375  decode.d1.loss_cls: 0.3140  decode.d1.loss_mask: 1.1672  decode.d1.loss_dice: 2.7065  decode.d2.loss_cls: 0.2957  decode.d2.loss_mask: 1.1595  decode.d2.loss_dice: 2.6494  decode.d3.loss_cls: 0.2934  decode.d3.loss_mask: 1.1770  decode.d3.loss_dice: 2.6044  decode.d4.loss_cls: 0.3318  decode.d4.loss_mask: 1.1672  decode.d4.loss_dice: 2.6256  decode.d5.loss_cls: 0.3663  decode.d5.loss_mask: 1.1497  decode.d5.loss_dice: 2.6369  decode.d6.loss_cls: 0.4045  decode.d6.loss_mask: 1.1625  decode.d6.loss_dice: 2.6167  decode.d7.loss_cls: 0.4344  decode.d7.loss_mask: 1.1776  decode.d7.loss_dice: 2.6637  decode.d8.loss_cls: 0.4436  decode.d8.loss_mask: 1.1626  decode.d8.loss_dice: 2.6529
11/15 06:51:50 - mmengine - INFO - Iter(train) [  500/90000]  base_lr: 9.9501e-05 lr: 9.9501e-06  eta: 19:18:51  time: 0.5887  data_time: 0.0096  memory: 10673  grad_norm: 595.0211  loss: 40.2894  decode.loss_cls: 0.4123  decode.loss_mask: 1.0944  decode.loss_dice: 2.4573  decode.d0.loss_cls: 0.8144  decode.d0.loss_mask: 1.1174  decode.d0.loss_dice: 2.8175  decode.d1.loss_cls: 0.2694  decode.d1.loss_mask: 1.2024  decode.d1.loss_dice: 2.6061  decode.d2.loss_cls: 0.2452  decode.d2.loss_mask: 1.1373  decode.d2.loss_dice: 2.5424  decode.d3.loss_cls: 0.2486  decode.d3.loss_mask: 1.1452  decode.d3.loss_dice: 2.4714  decode.d4.loss_cls: 0.3025  decode.d4.loss_mask: 1.1739  decode.d4.loss_dice: 2.4657  decode.d5.loss_cls: 0.3239  decode.d5.loss_mask: 1.1621  decode.d5.loss_dice: 2.4650  decode.d6.loss_cls: 0.3502  decode.d6.loss_mask: 1.0904  decode.d6.loss_dice: 2.4671  decode.d7.loss_cls: 0.3746  decode.d7.loss_mask: 1.1402  decode.d7.loss_dice: 2.4677  decode.d8.loss_cls: 0.3884  decode.d8.loss_mask: 1.0928  decode.d8.loss_dice: 2.4438
11/15 06:52:19 - mmengine - INFO - Iter(train) [  550/90000]  base_lr: 9.9451e-05 lr: 9.9451e-06  eta: 18:53:02  time: 0.5918  data_time: 0.0098  memory: 10673  grad_norm: 554.7456  loss: 37.1743  decode.loss_cls: 0.3902  decode.loss_mask: 1.0721  decode.loss_dice: 2.2374  decode.d0.loss_cls: 0.7997  decode.d0.loss_mask: 1.0298  decode.d0.loss_dice: 2.5875  decode.d1.loss_cls: 0.2550  decode.d1.loss_mask: 1.0594  decode.d1.loss_dice: 2.3384  decode.d2.loss_cls: 0.2504  decode.d2.loss_mask: 1.0685  decode.d2.loss_dice: 2.2693  decode.d3.loss_cls: 0.2464  decode.d3.loss_mask: 1.0729  decode.d3.loss_dice: 2.2464  decode.d4.loss_cls: 0.2670  decode.d4.loss_mask: 1.0533  decode.d4.loss_dice: 2.2585  decode.d5.loss_cls: 0.3088  decode.d5.loss_mask: 1.0369  decode.d5.loss_dice: 2.2274  decode.d6.loss_cls: 0.3280  decode.d6.loss_mask: 1.0675  decode.d6.loss_dice: 2.2365  decode.d7.loss_cls: 0.3505  decode.d7.loss_mask: 1.0935  decode.d7.loss_dice: 2.3020  decode.d8.loss_cls: 0.3631  decode.d8.loss_mask: 1.0953  decode.d8.loss_dice: 2.2627
11/15 06:52:49 - mmengine - INFO - Iter(train) [  600/90000]  base_lr: 9.9401e-05 lr: 9.9401e-06  eta: 18:31:24  time: 0.5922  data_time: 0.0096  memory: 10656  grad_norm: 621.8897  loss: 39.2999  decode.loss_cls: 0.3740  decode.loss_mask: 1.1540  decode.loss_dice: 2.3658  decode.d0.loss_cls: 0.7701  decode.d0.loss_mask: 1.0997  decode.d0.loss_dice: 2.6709  decode.d1.loss_cls: 0.2383  decode.d1.loss_mask: 1.2095  decode.d1.loss_dice: 2.4405  decode.d2.loss_cls: 0.2271  decode.d2.loss_mask: 1.1948  decode.d2.loss_dice: 2.3496  decode.d3.loss_cls: 0.2278  decode.d3.loss_mask: 1.2053  decode.d3.loss_dice: 2.3546  decode.d4.loss_cls: 0.2598  decode.d4.loss_mask: 1.1881  decode.d4.loss_dice: 2.3464  decode.d5.loss_cls: 0.2766  decode.d5.loss_mask: 1.2073  decode.d5.loss_dice: 2.4017  decode.d6.loss_cls: 0.3010  decode.d6.loss_mask: 1.2186  decode.d6.loss_dice: 2.3995  decode.d7.loss_cls: 0.3386  decode.d7.loss_mask: 1.1847  decode.d7.loss_dice: 2.4071  decode.d8.loss_cls: 0.3613  decode.d8.loss_mask: 1.1543  decode.d8.loss_dice: 2.3730
11/15 06:53:19 - mmengine - INFO - Iter(train) [  650/90000]  base_lr: 9.9351e-05 lr: 9.9351e-06  eta: 18:13:19  time: 0.5930  data_time: 0.0097  memory: 10726  grad_norm: 396.8941  loss: 33.7222  decode.loss_cls: 0.3129  decode.loss_mask: 0.9226  decode.loss_dice: 2.0769  decode.d0.loss_cls: 0.7489  decode.d0.loss_mask: 0.8905  decode.d0.loss_dice: 2.3250  decode.d1.loss_cls: 0.1980  decode.d1.loss_mask: 0.9807  decode.d1.loss_dice: 2.1410  decode.d2.loss_cls: 0.1706  decode.d2.loss_mask: 0.9907  decode.d2.loss_dice: 2.1337  decode.d3.loss_cls: 0.1734  decode.d3.loss_mask: 0.9905  decode.d3.loss_dice: 2.1005  decode.d4.loss_cls: 0.1923  decode.d4.loss_mask: 0.9824  decode.d4.loss_dice: 2.1208  decode.d5.loss_cls: 0.2100  decode.d5.loss_mask: 0.9881  decode.d5.loss_dice: 2.1191  decode.d6.loss_cls: 0.2604  decode.d6.loss_mask: 0.9625  decode.d6.loss_dice: 2.0846  decode.d7.loss_cls: 0.2756  decode.d7.loss_mask: 0.9516  decode.d7.loss_dice: 2.0819  decode.d8.loss_cls: 0.2797  decode.d8.loss_mask: 0.9717  decode.d8.loss_dice: 2.0856
11/15 06:53:48 - mmengine - INFO - Iter(train) [  700/90000]  base_lr: 9.9301e-05 lr: 9.9301e-06  eta: 17:57:45  time: 0.5918  data_time: 0.0095  memory: 10673  grad_norm: 445.6083  loss: 34.8067  decode.loss_cls: 0.3041  decode.loss_mask: 1.0072  decode.loss_dice: 2.1446  decode.d0.loss_cls: 0.7411  decode.d0.loss_mask: 0.9250  decode.d0.loss_dice: 2.3638  decode.d1.loss_cls: 0.2166  decode.d1.loss_mask: 1.0447  decode.d1.loss_dice: 2.1826  decode.d2.loss_cls: 0.1923  decode.d2.loss_mask: 1.0443  decode.d2.loss_dice: 2.1592  decode.d3.loss_cls: 0.2009  decode.d3.loss_mask: 1.0626  decode.d3.loss_dice: 2.1518  decode.d4.loss_cls: 0.2131  decode.d4.loss_mask: 1.0889  decode.d4.loss_dice: 2.1475  decode.d5.loss_cls: 0.2355  decode.d5.loss_mask: 1.0398  decode.d5.loss_dice: 2.1567  decode.d6.loss_cls: 0.2556  decode.d6.loss_mask: 1.0445  decode.d6.loss_dice: 2.1269  decode.d7.loss_cls: 0.2708  decode.d7.loss_mask: 0.9599  decode.d7.loss_dice: 2.1502  decode.d8.loss_cls: 0.2904  decode.d8.loss_mask: 0.9706  decode.d8.loss_dice: 2.1154
11/15 06:54:18 - mmengine - INFO - Iter(train) [  750/90000]  base_lr: 9.9251e-05 lr: 9.9251e-06  eta: 17:44:09  time: 0.5930  data_time: 0.0095  memory: 10673  grad_norm: 818.4410  loss: 39.3005  decode.loss_cls: 0.3320  decode.loss_mask: 1.1092  decode.loss_dice: 2.4336  decode.d0.loss_cls: 0.7426  decode.d0.loss_mask: 1.0965  decode.d0.loss_dice: 2.5896  decode.d1.loss_cls: 0.2228  decode.d1.loss_mask: 1.2295  decode.d1.loss_dice: 2.4859  decode.d2.loss_cls: 0.2153  decode.d2.loss_mask: 1.1839  decode.d2.loss_dice: 2.4690  decode.d3.loss_cls: 0.2083  decode.d3.loss_mask: 1.2417  decode.d3.loss_dice: 2.4257  decode.d4.loss_cls: 0.2226  decode.d4.loss_mask: 1.2087  decode.d4.loss_dice: 2.4176  decode.d5.loss_cls: 0.2353  decode.d5.loss_mask: 1.1811  decode.d5.loss_dice: 2.4434  decode.d6.loss_cls: 0.2776  decode.d6.loss_mask: 1.1537  decode.d6.loss_dice: 2.4453  decode.d7.loss_cls: 0.2995  decode.d7.loss_mask: 1.1376  decode.d7.loss_dice: 2.4497  decode.d8.loss_cls: 0.3109  decode.d8.loss_mask: 1.1207  decode.d8.loss_dice: 2.4109
11/15 06:54:47 - mmengine - INFO - Iter(train) [  800/90000]  base_lr: 9.9201e-05 lr: 9.9201e-06  eta: 17:32:05  time: 0.5934  data_time: 0.0097  memory: 10673  grad_norm: 527.9416  loss: 36.3189  decode.loss_cls: 0.2843  decode.loss_mask: 1.0382  decode.loss_dice: 2.2905  decode.d0.loss_cls: 0.7240  decode.d0.loss_mask: 0.9910  decode.d0.loss_dice: 2.4656  decode.d1.loss_cls: 0.2059  decode.d1.loss_mask: 1.0532  decode.d1.loss_dice: 2.3879  decode.d2.loss_cls: 0.1761  decode.d2.loss_mask: 1.0710  decode.d2.loss_dice: 2.3258  decode.d3.loss_cls: 0.1834  decode.d3.loss_mask: 1.0407  decode.d3.loss_dice: 2.3031  decode.d4.loss_cls: 0.2175  decode.d4.loss_mask: 1.0279  decode.d4.loss_dice: 2.2803  decode.d5.loss_cls: 0.2237  decode.d5.loss_mask: 1.0438  decode.d5.loss_dice: 2.2731  decode.d6.loss_cls: 0.2456  decode.d6.loss_mask: 1.0363  decode.d6.loss_dice: 2.2755  decode.d7.loss_cls: 0.2546  decode.d7.loss_mask: 1.0333  decode.d7.loss_dice: 2.2767  decode.d8.loss_cls: 0.2600  decode.d8.loss_mask: 1.0516  decode.d8.loss_dice: 2.2786
11/15 06:55:17 - mmengine - INFO - Iter(train) [  850/90000]  base_lr: 9.9151e-05 lr: 9.9151e-06  eta: 17:21:25  time: 0.5932  data_time: 0.0099  memory: 10693  grad_norm: 366.3468  loss: 33.7837  decode.loss_cls: 0.2577  decode.loss_mask: 0.8671  decode.loss_dice: 2.2156  decode.d0.loss_cls: 0.7059  decode.d0.loss_mask: 0.7883  decode.d0.loss_dice: 2.4208  decode.d1.loss_cls: 0.1744  decode.d1.loss_mask: 0.8497  decode.d1.loss_dice: 2.2808  decode.d2.loss_cls: 0.1509  decode.d2.loss_mask: 0.8667  decode.d2.loss_dice: 2.2323  decode.d3.loss_cls: 0.1512  decode.d3.loss_mask: 0.8618  decode.d3.loss_dice: 2.2594  decode.d4.loss_cls: 0.1736  decode.d4.loss_mask: 0.8888  decode.d4.loss_dice: 2.2712  decode.d5.loss_cls: 0.1880  decode.d5.loss_mask: 0.8628  decode.d5.loss_dice: 2.2487  decode.d6.loss_cls: 0.2230  decode.d6.loss_mask: 0.8687  decode.d6.loss_dice: 2.2822  decode.d7.loss_cls: 0.2433  decode.d7.loss_mask: 0.8725  decode.d7.loss_dice: 2.2550  decode.d8.loss_cls: 0.2460  decode.d8.loss_mask: 0.8434  decode.d8.loss_dice: 2.2339
11/15 06:55:47 - mmengine - INFO - Iter(train) [  900/90000]  base_lr: 9.9101e-05 lr: 9.9101e-06  eta: 17:11:52  time: 0.5931  data_time: 0.0096  memory: 10693  grad_norm: 393.8424  loss: 34.4603  decode.loss_cls: 0.2453  decode.loss_mask: 1.0057  decode.loss_dice: 2.1255  decode.d0.loss_cls: 0.7129  decode.d0.loss_mask: 0.9489  decode.d0.loss_dice: 2.2967  decode.d1.loss_cls: 0.1976  decode.d1.loss_mask: 1.0165  decode.d1.loss_dice: 2.2225  decode.d2.loss_cls: 0.1747  decode.d2.loss_mask: 1.0340  decode.d2.loss_dice: 2.1796  decode.d3.loss_cls: 0.1770  decode.d3.loss_mask: 1.0260  decode.d3.loss_dice: 2.1798  decode.d4.loss_cls: 0.1927  decode.d4.loss_mask: 1.0093  decode.d4.loss_dice: 2.1526  decode.d5.loss_cls: 0.2015  decode.d5.loss_mask: 1.0429  decode.d5.loss_dice: 2.1840  decode.d6.loss_cls: 0.2259  decode.d6.loss_mask: 1.0085  decode.d6.loss_dice: 2.1281  decode.d7.loss_cls: 0.2202  decode.d7.loss_mask: 1.0349  decode.d7.loss_dice: 2.1530  decode.d8.loss_cls: 0.2319  decode.d8.loss_mask: 1.0162  decode.d8.loss_dice: 2.1160
11/15 06:56:16 - mmengine - INFO - Iter(train) [  950/90000]  base_lr: 9.9050e-05 lr: 9.9050e-06  eta: 17:03:25  time: 0.5896  data_time: 0.0093  memory: 10710  grad_norm: 573.3594  loss: 31.0854  decode.loss_cls: 0.2211  decode.loss_mask: 0.9363  decode.loss_dice: 1.8747  decode.d0.loss_cls: 0.6871  decode.d0.loss_mask: 0.8673  decode.d0.loss_dice: 2.0591  decode.d1.loss_cls: 0.1946  decode.d1.loss_mask: 0.9437  decode.d1.loss_dice: 1.9450  decode.d2.loss_cls: 0.1836  decode.d2.loss_mask: 0.9782  decode.d2.loss_dice: 1.8853  decode.d3.loss_cls: 0.1703  decode.d3.loss_mask: 0.9714  decode.d3.loss_dice: 1.9058  decode.d4.loss_cls: 0.1834  decode.d4.loss_mask: 0.9703  decode.d4.loss_dice: 1.8767  decode.d5.loss_cls: 0.1761  decode.d5.loss_mask: 0.9755  decode.d5.loss_dice: 1.9024  decode.d6.loss_cls: 0.1826  decode.d6.loss_mask: 0.9670  decode.d6.loss_dice: 1.8925  decode.d7.loss_cls: 0.1934  decode.d7.loss_mask: 0.9778  decode.d7.loss_dice: 1.9130  decode.d8.loss_cls: 0.2110  decode.d8.loss_mask: 0.9614  decode.d8.loss_dice: 1.8787
11/15 06:56:46 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 06:56:46 - mmengine - INFO - Iter(train) [ 1000/90000]  base_lr: 9.9000e-05 lr: 9.9000e-06  eta: 16:55:39  time: 0.5909  data_time: 0.0094  memory: 10673  grad_norm: 643.7023  loss: 33.4910  decode.loss_cls: 0.2053  decode.loss_mask: 1.0018  decode.loss_dice: 2.0724  decode.d0.loss_cls: 0.6606  decode.d0.loss_mask: 0.9401  decode.d0.loss_dice: 2.2489  decode.d1.loss_cls: 0.1510  decode.d1.loss_mask: 0.9906  decode.d1.loss_dice: 2.1534  decode.d2.loss_cls: 0.1346  decode.d2.loss_mask: 0.9753  decode.d2.loss_dice: 2.1631  decode.d3.loss_cls: 0.1459  decode.d3.loss_mask: 1.0023  decode.d3.loss_dice: 2.1671  decode.d4.loss_cls: 0.1592  decode.d4.loss_mask: 1.0053  decode.d4.loss_dice: 2.1190  decode.d5.loss_cls: 0.1722  decode.d5.loss_mask: 1.0054  decode.d5.loss_dice: 2.1255  decode.d6.loss_cls: 0.1797  decode.d6.loss_mask: 0.9833  decode.d6.loss_dice: 2.1190  decode.d7.loss_cls: 0.1938  decode.d7.loss_mask: 0.9899  decode.d7.loss_dice: 2.1245  decode.d8.loss_cls: 0.1985  decode.d8.loss_mask: 0.9989  decode.d8.loss_dice: 2.1042
11/15 06:57:16 - mmengine - INFO - Iter(train) [ 1050/90000]  base_lr: 9.8950e-05 lr: 9.8950e-06  eta: 16:48:31  time: 0.5913  data_time: 0.0095  memory: 10693  grad_norm: 435.0073  loss: 32.1292  decode.loss_cls: 0.1975  decode.loss_mask: 0.9691  decode.loss_dice: 1.9951  decode.d0.loss_cls: 0.6658  decode.d0.loss_mask: 0.9342  decode.d0.loss_dice: 2.1168  decode.d1.loss_cls: 0.1740  decode.d1.loss_mask: 0.9802  decode.d1.loss_dice: 2.0086  decode.d2.loss_cls: 0.1696  decode.d2.loss_mask: 0.9902  decode.d2.loss_dice: 1.9949  decode.d3.loss_cls: 0.1567  decode.d3.loss_mask: 1.0097  decode.d3.loss_dice: 2.0403  decode.d4.loss_cls: 0.1592  decode.d4.loss_mask: 1.0022  decode.d4.loss_dice: 2.0265  decode.d5.loss_cls: 0.1893  decode.d5.loss_mask: 0.9934  decode.d5.loss_dice: 1.9995  decode.d6.loss_cls: 0.1947  decode.d6.loss_mask: 0.9709  decode.d6.loss_dice: 1.9861  decode.d7.loss_cls: 0.1900  decode.d7.loss_mask: 0.9422  decode.d7.loss_dice: 1.9860  decode.d8.loss_cls: 0.1921  decode.d8.loss_mask: 0.9371  decode.d8.loss_dice: 1.9573
11/15 06:57:45 - mmengine - INFO - Iter(train) [ 1100/90000]  base_lr: 9.8900e-05 lr: 9.8900e-06  eta: 16:42:00  time: 0.5922  data_time: 0.0096  memory: 10673  grad_norm: 476.9850  loss: 33.4405  decode.loss_cls: 0.1881  decode.loss_mask: 1.0819  decode.loss_dice: 2.0416  decode.d0.loss_cls: 0.6415  decode.d0.loss_mask: 0.9781  decode.d0.loss_dice: 2.1872  decode.d1.loss_cls: 0.1354  decode.d1.loss_mask: 1.0742  decode.d1.loss_dice: 2.1094  decode.d2.loss_cls: 0.1186  decode.d2.loss_mask: 1.0739  decode.d2.loss_dice: 2.0918  decode.d3.loss_cls: 0.1111  decode.d3.loss_mask: 1.0930  decode.d3.loss_dice: 2.0999  decode.d4.loss_cls: 0.1309  decode.d4.loss_mask: 1.0730  decode.d4.loss_dice: 2.0875  decode.d5.loss_cls: 0.1339  decode.d5.loss_mask: 1.0890  decode.d5.loss_dice: 2.0453  decode.d6.loss_cls: 0.1536  decode.d6.loss_mask: 1.0857  decode.d6.loss_dice: 2.0466  decode.d7.loss_cls: 0.1762  decode.d7.loss_mask: 1.0454  decode.d7.loss_dice: 2.0470  decode.d8.loss_cls: 0.1741  decode.d8.loss_mask: 1.0872  decode.d8.loss_dice: 2.0396
11/15 06:58:15 - mmengine - INFO - Iter(train) [ 1150/90000]  base_lr: 9.8850e-05 lr: 9.8850e-06  eta: 16:35:59  time: 0.5911  data_time: 0.0094  memory: 10673  grad_norm: 539.1282  loss: 30.8711  decode.loss_cls: 0.1836  decode.loss_mask: 1.1267  decode.loss_dice: 1.7914  decode.d0.loss_cls: 0.6528  decode.d0.loss_mask: 0.9841  decode.d0.loss_dice: 1.8942  decode.d1.loss_cls: 0.1661  decode.d1.loss_mask: 1.0720  decode.d1.loss_dice: 1.7961  decode.d2.loss_cls: 0.1477  decode.d2.loss_mask: 1.0388  decode.d2.loss_dice: 1.7865  decode.d3.loss_cls: 0.1472  decode.d3.loss_mask: 1.0338  decode.d3.loss_dice: 1.7999  decode.d4.loss_cls: 0.1484  decode.d4.loss_mask: 1.0812  decode.d4.loss_dice: 1.7898  decode.d5.loss_cls: 0.1580  decode.d5.loss_mask: 1.0824  decode.d5.loss_dice: 1.7618  decode.d6.loss_cls: 0.1548  decode.d6.loss_mask: 1.1282  decode.d6.loss_dice: 1.7954  decode.d7.loss_cls: 0.1740  decode.d7.loss_mask: 1.1240  decode.d7.loss_dice: 1.7567  decode.d8.loss_cls: 0.1695  decode.d8.loss_mask: 1.1241  decode.d8.loss_dice: 1.8019
11/15 06:58:44 - mmengine - INFO - Iter(train) [ 1200/90000]  base_lr: 9.8800e-05 lr: 9.8800e-06  eta: 16:30:27  time: 0.5917  data_time: 0.0095  memory: 10710  grad_norm: 525.9510  loss: 31.5528  decode.loss_cls: 0.1872  decode.loss_mask: 0.8989  decode.loss_dice: 2.0241  decode.d0.loss_cls: 0.6299  decode.d0.loss_mask: 0.8342  decode.d0.loss_dice: 2.1910  decode.d1.loss_cls: 0.1348  decode.d1.loss_mask: 0.8824  decode.d1.loss_dice: 2.1130  decode.d2.loss_cls: 0.1292  decode.d2.loss_mask: 0.8835  decode.d2.loss_dice: 2.0759  decode.d3.loss_cls: 0.1327  decode.d3.loss_mask: 0.8829  decode.d3.loss_dice: 2.0672  decode.d4.loss_cls: 0.1353  decode.d4.loss_mask: 0.8835  decode.d4.loss_dice: 2.0605  decode.d5.loss_cls: 0.1528  decode.d5.loss_mask: 0.8560  decode.d5.loss_dice: 2.0736  decode.d6.loss_cls: 0.1639  decode.d6.loss_mask: 0.8792  decode.d6.loss_dice: 2.0655  decode.d7.loss_cls: 0.1794  decode.d7.loss_mask: 0.8773  decode.d7.loss_dice: 2.0586  decode.d8.loss_cls: 0.1859  decode.d8.loss_mask: 0.8856  decode.d8.loss_dice: 2.0286
11/15 06:59:14 - mmengine - INFO - Iter(train) [ 1250/90000]  base_lr: 9.8750e-05 lr: 9.8750e-06  eta: 16:25:22  time: 0.5920  data_time: 0.0097  memory: 10693  grad_norm: 493.4566  loss: 30.5699  decode.loss_cls: 0.1333  decode.loss_mask: 1.0200  decode.loss_dice: 1.8760  decode.d0.loss_cls: 0.6151  decode.d0.loss_mask: 0.9982  decode.d0.loss_dice: 1.9383  decode.d1.loss_cls: 0.1148  decode.d1.loss_mask: 1.0244  decode.d1.loss_dice: 1.8811  decode.d2.loss_cls: 0.0991  decode.d2.loss_mask: 1.0483  decode.d2.loss_dice: 1.8876  decode.d3.loss_cls: 0.0995  decode.d3.loss_mask: 1.0292  decode.d3.loss_dice: 1.8583  decode.d4.loss_cls: 0.0971  decode.d4.loss_mask: 1.0349  decode.d4.loss_dice: 1.8796  decode.d5.loss_cls: 0.1027  decode.d5.loss_mask: 1.0457  decode.d5.loss_dice: 1.8805  decode.d6.loss_cls: 0.1126  decode.d6.loss_mask: 1.0099  decode.d6.loss_dice: 1.8433  decode.d7.loss_cls: 0.1290  decode.d7.loss_mask: 1.0035  decode.d7.loss_dice: 1.8230  decode.d8.loss_cls: 0.1333  decode.d8.loss_mask: 1.0258  decode.d8.loss_dice: 1.8256
11/15 06:59:44 - mmengine - INFO - Iter(train) [ 1300/90000]  base_lr: 9.8700e-05 lr: 9.8700e-06  eta: 16:20:36  time: 0.5930  data_time: 0.0096  memory: 10710  grad_norm: 549.2832  loss: 30.6601  decode.loss_cls: 0.1772  decode.loss_mask: 0.8479  decode.loss_dice: 2.0586  decode.d0.loss_cls: 0.6444  decode.d0.loss_mask: 0.7853  decode.d0.loss_dice: 2.1547  decode.d1.loss_cls: 0.1535  decode.d1.loss_mask: 0.8438  decode.d1.loss_dice: 2.0691  decode.d2.loss_cls: 0.1360  decode.d2.loss_mask: 0.7857  decode.d2.loss_dice: 1.9957  decode.d3.loss_cls: 0.1332  decode.d3.loss_mask: 0.7664  decode.d3.loss_dice: 1.9876  decode.d4.loss_cls: 0.1264  decode.d4.loss_mask: 0.7610  decode.d4.loss_dice: 1.9879  decode.d5.loss_cls: 0.1347  decode.d5.loss_mask: 0.8530  decode.d5.loss_dice: 2.0483  decode.d6.loss_cls: 0.1655  decode.d6.loss_mask: 0.8429  decode.d6.loss_dice: 2.0394  decode.d7.loss_cls: 0.1710  decode.d7.loss_mask: 0.8500  decode.d7.loss_dice: 2.0525  decode.d8.loss_cls: 0.1785  decode.d8.loss_mask: 0.8483  decode.d8.loss_dice: 2.0617
11/15 07:00:13 - mmengine - INFO - Iter(train) [ 1350/90000]  base_lr: 9.8650e-05 lr: 9.8650e-06  eta: 16:16:11  time: 0.5931  data_time: 0.0097  memory: 10673  grad_norm: 769.9636  loss: 30.0989  decode.loss_cls: 0.1454  decode.loss_mask: 0.9348  decode.loss_dice: 1.8865  decode.d0.loss_cls: 0.6139  decode.d0.loss_mask: 0.8337  decode.d0.loss_dice: 1.9903  decode.d1.loss_cls: 0.1311  decode.d1.loss_mask: 0.9166  decode.d1.loss_dice: 1.8996  decode.d2.loss_cls: 0.1196  decode.d2.loss_mask: 0.9196  decode.d2.loss_dice: 1.8796  decode.d3.loss_cls: 0.1222  decode.d3.loss_mask: 0.9101  decode.d3.loss_dice: 1.8553  decode.d4.loss_cls: 0.1210  decode.d4.loss_mask: 0.9145  decode.d4.loss_dice: 1.9011  decode.d5.loss_cls: 0.1438  decode.d5.loss_mask: 0.9348  decode.d5.loss_dice: 1.9054  decode.d6.loss_cls: 0.1662  decode.d6.loss_mask: 0.9068  decode.d6.loss_dice: 1.8695  decode.d7.loss_cls: 0.1560  decode.d7.loss_mask: 0.9391  decode.d7.loss_dice: 1.9255  decode.d8.loss_cls: 0.1598  decode.d8.loss_mask: 0.9605  decode.d8.loss_dice: 1.9365
11/15 07:00:43 - mmengine - INFO - Iter(train) [ 1400/90000]  base_lr: 9.8600e-05 lr: 9.8600e-06  eta: 16:12:03  time: 0.5936  data_time: 0.0096  memory: 10673  grad_norm: 444.5088  loss: 30.5737  decode.loss_cls: 0.1605  decode.loss_mask: 0.9415  decode.loss_dice: 1.9530  decode.d0.loss_cls: 0.6201  decode.d0.loss_mask: 0.8247  decode.d0.loss_dice: 2.0334  decode.d1.loss_cls: 0.1370  decode.d1.loss_mask: 0.8920  decode.d1.loss_dice: 1.9667  decode.d2.loss_cls: 0.1041  decode.d2.loss_mask: 0.9366  decode.d2.loss_dice: 2.0129  decode.d3.loss_cls: 0.1207  decode.d3.loss_mask: 0.8830  decode.d3.loss_dice: 1.9740  decode.d4.loss_cls: 0.1251  decode.d4.loss_mask: 0.8839  decode.d4.loss_dice: 1.9640  decode.d5.loss_cls: 0.1438  decode.d5.loss_mask: 0.8498  decode.d5.loss_dice: 1.9269  decode.d6.loss_cls: 0.1442  decode.d6.loss_mask: 0.9486  decode.d6.loss_dice: 1.9469  decode.d7.loss_cls: 0.1589  decode.d7.loss_mask: 0.9257  decode.d7.loss_dice: 1.9641  decode.d8.loss_cls: 0.1519  decode.d8.loss_mask: 0.9262  decode.d8.loss_dice: 1.9534
11/15 07:01:13 - mmengine - INFO - Iter(train) [ 1450/90000]  base_lr: 9.8550e-05 lr: 9.8550e-06  eta: 16:08:13  time: 0.5928  data_time: 0.0094  memory: 10693  grad_norm: 578.9077  loss: 26.8637  decode.loss_cls: 0.1944  decode.loss_mask: 0.7311  decode.loss_dice: 1.6964  decode.d0.loss_cls: 0.6107  decode.d0.loss_mask: 0.7261  decode.d0.loss_dice: 1.8567  decode.d1.loss_cls: 0.1587  decode.d1.loss_mask: 0.7208  decode.d1.loss_dice: 1.7486  decode.d2.loss_cls: 0.1387  decode.d2.loss_mask: 0.7415  decode.d2.loss_dice: 1.7352  decode.d3.loss_cls: 0.1264  decode.d3.loss_mask: 0.7827  decode.d3.loss_dice: 1.7404  decode.d4.loss_cls: 0.1480  decode.d4.loss_mask: 0.7510  decode.d4.loss_dice: 1.6899  decode.d5.loss_cls: 0.1452  decode.d5.loss_mask: 0.7608  decode.d5.loss_dice: 1.7210  decode.d6.loss_cls: 0.1749  decode.d6.loss_mask: 0.7403  decode.d6.loss_dice: 1.6915  decode.d7.loss_cls: 0.1850  decode.d7.loss_mask: 0.7726  decode.d7.loss_dice: 1.7247  decode.d8.loss_cls: 0.1867  decode.d8.loss_mask: 0.7565  decode.d8.loss_dice: 1.7072
11/15 07:01:35 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 07:01:42 - mmengine - INFO - Iter(train) [ 1500/90000]  base_lr: 9.8500e-05 lr: 9.8500e-06  eta: 16:04:33  time: 0.5912  data_time: 0.0094  memory: 10693  grad_norm: 537.5551  loss: 30.9848  decode.loss_cls: 0.1248  decode.loss_mask: 1.0497  decode.loss_dice: 1.9045  decode.d0.loss_cls: 0.5775  decode.d0.loss_mask: 0.9073  decode.d0.loss_dice: 1.9762  decode.d1.loss_cls: 0.1084  decode.d1.loss_mask: 1.0555  decode.d1.loss_dice: 1.9396  decode.d2.loss_cls: 0.0941  decode.d2.loss_mask: 1.0270  decode.d2.loss_dice: 1.9351  decode.d3.loss_cls: 0.0980  decode.d3.loss_mask: 1.0333  decode.d3.loss_dice: 1.9147  decode.d4.loss_cls: 0.1086  decode.d4.loss_mask: 1.0125  decode.d4.loss_dice: 1.9256  decode.d5.loss_cls: 0.1293  decode.d5.loss_mask: 1.0042  decode.d5.loss_dice: 1.9059  decode.d6.loss_cls: 0.1226  decode.d6.loss_mask: 1.0090  decode.d6.loss_dice: 1.9123  decode.d7.loss_cls: 0.1325  decode.d7.loss_mask: 1.0112  decode.d7.loss_dice: 1.9125  decode.d8.loss_cls: 0.1313  decode.d8.loss_mask: 1.0139  decode.d8.loss_dice: 1.9079
11/15 07:02:12 - mmengine - INFO - Iter(train) [ 1550/90000]  base_lr: 9.8450e-05 lr: 9.8450e-06  eta: 16:01:04  time: 0.5915  data_time: 0.0096  memory: 10693  grad_norm: 902.0959  loss: 28.4621  decode.loss_cls: 0.1282  decode.loss_mask: 0.9052  decode.loss_dice: 1.7473  decode.d0.loss_cls: 0.5669  decode.d0.loss_mask: 0.8594  decode.d0.loss_dice: 1.8447  decode.d1.loss_cls: 0.1159  decode.d1.loss_mask: 0.9434  decode.d1.loss_dice: 1.8103  decode.d2.loss_cls: 0.1087  decode.d2.loss_mask: 0.9021  decode.d2.loss_dice: 1.7553  decode.d3.loss_cls: 0.1006  decode.d3.loss_mask: 0.8931  decode.d3.loss_dice: 1.7534  decode.d4.loss_cls: 0.1075  decode.d4.loss_mask: 0.9115  decode.d4.loss_dice: 1.7615  decode.d5.loss_cls: 0.1117  decode.d5.loss_mask: 0.9248  decode.d5.loss_dice: 1.7811  decode.d6.loss_cls: 0.1277  decode.d6.loss_mask: 0.9170  decode.d6.loss_dice: 1.7469  decode.d7.loss_cls: 0.1158  decode.d7.loss_mask: 0.9156  decode.d7.loss_dice: 1.7654  decode.d8.loss_cls: 0.1246  decode.d8.loss_mask: 0.9329  decode.d8.loss_dice: 1.7837
11/15 07:02:42 - mmengine - INFO - Iter(train) [ 1600/90000]  base_lr: 9.8400e-05 lr: 9.8400e-06  eta: 15:57:49  time: 0.5924  data_time: 0.0096  memory: 10656  grad_norm: 591.3768  loss: 29.7871  decode.loss_cls: 0.1523  decode.loss_mask: 0.9330  decode.loss_dice: 1.8394  decode.d0.loss_cls: 0.5681  decode.d0.loss_mask: 0.9216  decode.d0.loss_dice: 1.9287  decode.d1.loss_cls: 0.1257  decode.d1.loss_mask: 0.9344  decode.d1.loss_dice: 1.9093  decode.d2.loss_cls: 0.1063  decode.d2.loss_mask: 0.9624  decode.d2.loss_dice: 1.9023  decode.d3.loss_cls: 0.1140  decode.d3.loss_mask: 0.9562  decode.d3.loss_dice: 1.8927  decode.d4.loss_cls: 0.1195  decode.d4.loss_mask: 0.9644  decode.d4.loss_dice: 1.8911  decode.d5.loss_cls: 0.1305  decode.d5.loss_mask: 0.9127  decode.d5.loss_dice: 1.8543  decode.d6.loss_cls: 0.1421  decode.d6.loss_mask: 0.9196  decode.d6.loss_dice: 1.8224  decode.d7.loss_cls: 0.1512  decode.d7.loss_mask: 0.9173  decode.d7.loss_dice: 1.8378  decode.d8.loss_cls: 0.1523  decode.d8.loss_mask: 0.9008  decode.d8.loss_dice: 1.8249
11/15 07:03:11 - mmengine - INFO - Iter(train) [ 1650/90000]  base_lr: 9.8349e-05 lr: 9.8349e-06  eta: 15:54:41  time: 0.5918  data_time: 0.0098  memory: 10656  grad_norm: 622.7749  loss: 29.7172  decode.loss_cls: 0.1455  decode.loss_mask: 0.8996  decode.loss_dice: 1.9055  decode.d0.loss_cls: 0.5690  decode.d0.loss_mask: 0.8749  decode.d0.loss_dice: 1.9659  decode.d1.loss_cls: 0.1337  decode.d1.loss_mask: 0.8814  decode.d1.loss_dice: 1.9048  decode.d2.loss_cls: 0.1335  decode.d2.loss_mask: 0.9033  decode.d2.loss_dice: 1.8831  decode.d3.loss_cls: 0.1389  decode.d3.loss_mask: 0.8994  decode.d3.loss_dice: 1.8836  decode.d4.loss_cls: 0.1350  decode.d4.loss_mask: 0.9070  decode.d4.loss_dice: 1.8865  decode.d5.loss_cls: 0.1530  decode.d5.loss_mask: 0.8843  decode.d5.loss_dice: 1.8552  decode.d6.loss_cls: 0.1408  decode.d6.loss_mask: 0.9008  decode.d6.loss_dice: 1.8869  decode.d7.loss_cls: 0.1581  decode.d7.loss_mask: 0.8882  decode.d7.loss_dice: 1.8721  decode.d8.loss_cls: 0.1529  decode.d8.loss_mask: 0.8900  decode.d8.loss_dice: 1.8841
11/15 07:03:41 - mmengine - INFO - Iter(train) [ 1700/90000]  base_lr: 9.8299e-05 lr: 9.8299e-06  eta: 15:51:43  time: 0.5911  data_time: 0.0094  memory: 10740  grad_norm: 414.1232  loss: 31.3552  decode.loss_cls: 0.1637  decode.loss_mask: 0.9726  decode.loss_dice: 1.9153  decode.d0.loss_cls: 0.5544  decode.d0.loss_mask: 0.9287  decode.d0.loss_dice: 2.0330  decode.d1.loss_cls: 0.0993  decode.d1.loss_mask: 1.0124  decode.d1.loss_dice: 2.0117  decode.d2.loss_cls: 0.1077  decode.d2.loss_mask: 1.0172  decode.d2.loss_dice: 2.0099  decode.d3.loss_cls: 0.1158  decode.d3.loss_mask: 0.9966  decode.d3.loss_dice: 2.0223  decode.d4.loss_cls: 0.1204  decode.d4.loss_mask: 0.9941  decode.d4.loss_dice: 1.9511  decode.d5.loss_cls: 0.1278  decode.d5.loss_mask: 0.9919  decode.d5.loss_dice: 1.9811  decode.d6.loss_cls: 0.1493  decode.d6.loss_mask: 0.9618  decode.d6.loss_dice: 1.9627  decode.d7.loss_cls: 0.1577  decode.d7.loss_mask: 0.9753  decode.d7.loss_dice: 1.9330  decode.d8.loss_cls: 0.1465  decode.d8.loss_mask: 0.9981  decode.d8.loss_dice: 1.9439
11/15 07:04:10 - mmengine - INFO - Iter(train) [ 1750/90000]  base_lr: 9.8249e-05 lr: 9.8249e-06  eta: 15:48:52  time: 0.5913  data_time: 0.0097  memory: 10656  grad_norm: 1139.4895  loss: 30.5323  decode.loss_cls: 0.1556  decode.loss_mask: 1.0125  decode.loss_dice: 1.8480  decode.d0.loss_cls: 0.5467  decode.d0.loss_mask: 1.0522  decode.d0.loss_dice: 1.9645  decode.d1.loss_cls: 0.1311  decode.d1.loss_mask: 1.0026  decode.d1.loss_dice: 1.8681  decode.d2.loss_cls: 0.1194  decode.d2.loss_mask: 1.0622  decode.d2.loss_dice: 1.8907  decode.d3.loss_cls: 0.1238  decode.d3.loss_mask: 1.0507  decode.d3.loss_dice: 1.8532  decode.d4.loss_cls: 0.1325  decode.d4.loss_mask: 1.0003  decode.d4.loss_dice: 1.8296  decode.d5.loss_cls: 0.1230  decode.d5.loss_mask: 1.0247  decode.d5.loss_dice: 1.8416  decode.d6.loss_cls: 0.1191  decode.d6.loss_mask: 1.0013  decode.d6.loss_dice: 1.8291  decode.d7.loss_cls: 0.1464  decode.d7.loss_mask: 0.9826  decode.d7.loss_dice: 1.8236  decode.d8.loss_cls: 0.1427  decode.d8.loss_mask: 1.0005  decode.d8.loss_dice: 1.8542
11/15 07:04:40 - mmengine - INFO - Iter(train) [ 1800/90000]  base_lr: 9.8199e-05 lr: 9.8199e-06  eta: 15:46:10  time: 0.5923  data_time: 0.0097  memory: 10726  grad_norm: 595.0355  loss: 29.1743  decode.loss_cls: 0.1578  decode.loss_mask: 0.9105  decode.loss_dice: 1.8410  decode.d0.loss_cls: 0.5418  decode.d0.loss_mask: 0.8473  decode.d0.loss_dice: 1.9120  decode.d1.loss_cls: 0.1221  decode.d1.loss_mask: 0.9033  decode.d1.loss_dice: 1.8868  decode.d2.loss_cls: 0.1081  decode.d2.loss_mask: 0.8922  decode.d2.loss_dice: 1.8708  decode.d3.loss_cls: 0.1144  decode.d3.loss_mask: 0.8850  decode.d3.loss_dice: 1.8362  decode.d4.loss_cls: 0.1256  decode.d4.loss_mask: 0.9035  decode.d4.loss_dice: 1.8480  decode.d5.loss_cls: 0.1334  decode.d5.loss_mask: 0.8930  decode.d5.loss_dice: 1.8413  decode.d6.loss_cls: 0.1384  decode.d6.loss_mask: 0.8952  decode.d6.loss_dice: 1.7966  decode.d7.loss_cls: 0.1504  decode.d7.loss_mask: 0.8894  decode.d7.loss_dice: 1.8347  decode.d8.loss_cls: 0.1541  decode.d8.loss_mask: 0.8951  decode.d8.loss_dice: 1.8463
11/15 07:05:10 - mmengine - INFO - Iter(train) [ 1850/90000]  base_lr: 9.8149e-05 lr: 9.8149e-06  eta: 15:43:35  time: 0.5937  data_time: 0.0105  memory: 10693  grad_norm: 600.3261  loss: 28.3400  decode.loss_cls: 0.1399  decode.loss_mask: 0.8175  decode.loss_dice: 1.8274  decode.d0.loss_cls: 0.5301  decode.d0.loss_mask: 0.8016  decode.d0.loss_dice: 1.9437  decode.d1.loss_cls: 0.1162  decode.d1.loss_mask: 0.8152  decode.d1.loss_dice: 1.8594  decode.d2.loss_cls: 0.1027  decode.d2.loss_mask: 0.8327  decode.d2.loss_dice: 1.8661  decode.d3.loss_cls: 0.0977  decode.d3.loss_mask: 0.8058  decode.d3.loss_dice: 1.8717  decode.d4.loss_cls: 0.0910  decode.d4.loss_mask: 0.8237  decode.d4.loss_dice: 1.8829  decode.d5.loss_cls: 0.1067  decode.d5.loss_mask: 0.8117  decode.d5.loss_dice: 1.8841  decode.d6.loss_cls: 0.1133  decode.d6.loss_mask: 0.8276  decode.d6.loss_dice: 1.8510  decode.d7.loss_cls: 0.1238  decode.d7.loss_mask: 0.8109  decode.d7.loss_dice: 1.8277  decode.d8.loss_cls: 0.1296  decode.d8.loss_mask: 0.7943  decode.d8.loss_dice: 1.8344
11/15 07:05:39 - mmengine - INFO - Iter(train) [ 1900/90000]  base_lr: 9.8099e-05 lr: 9.8099e-06  eta: 15:41:07  time: 0.5933  data_time: 0.0100  memory: 10693  grad_norm: 281.9076  loss: 28.6559  decode.loss_cls: 0.1392  decode.loss_mask: 0.8045  decode.loss_dice: 1.8890  decode.d0.loss_cls: 0.5265  decode.d0.loss_mask: 0.7529  decode.d0.loss_dice: 1.9896  decode.d1.loss_cls: 0.1090  decode.d1.loss_mask: 0.8397  decode.d1.loss_dice: 1.9208  decode.d2.loss_cls: 0.0965  decode.d2.loss_mask: 0.8099  decode.d2.loss_dice: 1.9053  decode.d3.loss_cls: 0.0944  decode.d3.loss_mask: 0.8136  decode.d3.loss_dice: 1.9088  decode.d4.loss_cls: 0.1140  decode.d4.loss_mask: 0.8161  decode.d4.loss_dice: 1.8730  decode.d5.loss_cls: 0.0985  decode.d5.loss_mask: 0.8122  decode.d5.loss_dice: 1.9065  decode.d6.loss_cls: 0.0998  decode.d6.loss_mask: 0.7984  decode.d6.loss_dice: 1.8957  decode.d7.loss_cls: 0.1094  decode.d7.loss_mask: 0.8143  decode.d7.loss_dice: 1.8791  decode.d8.loss_cls: 0.1110  decode.d8.loss_mask: 0.8342  decode.d8.loss_dice: 1.8940
11/15 07:06:09 - mmengine - INFO - Iter(train) [ 1950/90000]  base_lr: 9.8049e-05 lr: 9.8049e-06  eta: 15:38:50  time: 0.5951  data_time: 0.0100  memory: 10710  grad_norm: 417.0193  loss: 27.3088  decode.loss_cls: 0.1448  decode.loss_mask: 0.8227  decode.loss_dice: 1.6877  decode.d0.loss_cls: 0.5021  decode.d0.loss_mask: 0.7561  decode.d0.loss_dice: 1.8378  decode.d1.loss_cls: 0.0961  decode.d1.loss_mask: 0.8244  decode.d1.loss_dice: 1.7806  decode.d2.loss_cls: 0.0824  decode.d2.loss_mask: 0.8397  decode.d2.loss_dice: 1.7901  decode.d3.loss_cls: 0.0879  decode.d3.loss_mask: 0.8316  decode.d3.loss_dice: 1.7711  decode.d4.loss_cls: 0.1104  decode.d4.loss_mask: 0.8191  decode.d4.loss_dice: 1.7666  decode.d5.loss_cls: 0.1136  decode.d5.loss_mask: 0.8304  decode.d5.loss_dice: 1.7346  decode.d6.loss_cls: 0.1337  decode.d6.loss_mask: 0.8539  decode.d6.loss_dice: 1.7229  decode.d7.loss_cls: 0.1280  decode.d7.loss_mask: 0.8511  decode.d7.loss_dice: 1.7156  decode.d8.loss_cls: 0.1315  decode.d8.loss_mask: 0.8384  decode.d8.loss_dice: 1.7035
11/15 07:06:39 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 07:06:39 - mmengine - INFO - Iter(train) [ 2000/90000]  base_lr: 9.7999e-05 lr: 9.7999e-06  eta: 15:36:37  time: 0.5912  data_time: 0.0095  memory: 10656  grad_norm: 432.9988  loss: 28.6071  decode.loss_cls: 0.1417  decode.loss_mask: 0.9181  decode.loss_dice: 1.7632  decode.d0.loss_cls: 0.5163  decode.d0.loss_mask: 0.8964  decode.d0.loss_dice: 1.8331  decode.d1.loss_cls: 0.1189  decode.d1.loss_mask: 0.9180  decode.d1.loss_dice: 1.8054  decode.d2.loss_cls: 0.1233  decode.d2.loss_mask: 0.8982  decode.d2.loss_dice: 1.7933  decode.d3.loss_cls: 0.1181  decode.d3.loss_mask: 0.8994  decode.d3.loss_dice: 1.7920  decode.d4.loss_cls: 0.1254  decode.d4.loss_mask: 0.9114  decode.d4.loss_dice: 1.7917  decode.d5.loss_cls: 0.1279  decode.d5.loss_mask: 0.9151  decode.d5.loss_dice: 1.7988  decode.d6.loss_cls: 0.1252  decode.d6.loss_mask: 0.9121  decode.d6.loss_dice: 1.7502  decode.d7.loss_cls: 0.1294  decode.d7.loss_mask: 0.9112  decode.d7.loss_dice: 1.7772  decode.d8.loss_cls: 0.1547  decode.d8.loss_mask: 0.9066  decode.d8.loss_dice: 1.7348
11/15 07:07:08 - mmengine - INFO - Iter(train) [ 2050/90000]  base_lr: 9.7949e-05 lr: 9.7949e-06  eta: 15:34:29  time: 0.5925  data_time: 0.0099  memory: 10693  grad_norm: 427.5608  loss: 24.8828  decode.loss_cls: 0.0785  decode.loss_mask: 0.7695  decode.loss_dice: 1.5765  decode.d0.loss_cls: 0.4823  decode.d0.loss_mask: 0.7557  decode.d0.loss_dice: 1.6154  decode.d1.loss_cls: 0.0748  decode.d1.loss_mask: 0.7685  decode.d1.loss_dice: 1.5564  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.7892  decode.d2.loss_dice: 1.5880  decode.d3.loss_cls: 0.0520  decode.d3.loss_mask: 0.8014  decode.d3.loss_dice: 1.5750  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.8163  decode.d4.loss_dice: 1.6045  decode.d5.loss_cls: 0.0653  decode.d5.loss_mask: 0.8118  decode.d5.loss_dice: 1.6096  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.8088  decode.d6.loss_dice: 1.5931  decode.d7.loss_cls: 0.0653  decode.d7.loss_mask: 0.7912  decode.d7.loss_dice: 1.6028  decode.d8.loss_cls: 0.0681  decode.d8.loss_mask: 0.7958  decode.d8.loss_dice: 1.5881
11/15 07:07:38 - mmengine - INFO - Iter(train) [ 2100/90000]  base_lr: 9.7899e-05 lr: 9.7899e-06  eta: 15:32:22  time: 0.5929  data_time: 0.0098  memory: 10642  grad_norm: 402.5003  loss: 29.0075  decode.loss_cls: 0.1452  decode.loss_mask: 0.9878  decode.loss_dice: 1.7755  decode.d0.loss_cls: 0.5015  decode.d0.loss_mask: 0.9143  decode.d0.loss_dice: 1.7646  decode.d1.loss_cls: 0.1315  decode.d1.loss_mask: 0.9452  decode.d1.loss_dice: 1.7468  decode.d2.loss_cls: 0.1222  decode.d2.loss_mask: 1.0017  decode.d2.loss_dice: 1.7357  decode.d3.loss_cls: 0.1165  decode.d3.loss_mask: 0.9734  decode.d3.loss_dice: 1.7704  decode.d4.loss_cls: 0.1344  decode.d4.loss_mask: 0.9588  decode.d4.loss_dice: 1.7574  decode.d5.loss_cls: 0.1256  decode.d5.loss_mask: 0.9896  decode.d5.loss_dice: 1.7846  decode.d6.loss_cls: 0.1201  decode.d6.loss_mask: 0.9851  decode.d6.loss_dice: 1.7399  decode.d7.loss_cls: 0.1211  decode.d7.loss_mask: 0.9977  decode.d7.loss_dice: 1.7898  decode.d8.loss_cls: 0.1317  decode.d8.loss_mask: 0.9854  decode.d8.loss_dice: 1.7540
11/15 07:08:08 - mmengine - INFO - Iter(train) [ 2150/90000]  base_lr: 9.7848e-05 lr: 9.7848e-06  eta: 15:30:25  time: 0.5919  data_time: 0.0098  memory: 10710  grad_norm: 622.0680  loss: 27.6425  decode.loss_cls: 0.1015  decode.loss_mask: 0.8577  decode.loss_dice: 1.7573  decode.d0.loss_cls: 0.4740  decode.d0.loss_mask: 0.8566  decode.d0.loss_dice: 1.8313  decode.d1.loss_cls: 0.0721  decode.d1.loss_mask: 0.8885  decode.d1.loss_dice: 1.7916  decode.d2.loss_cls: 0.0785  decode.d2.loss_mask: 0.8556  decode.d2.loss_dice: 1.7801  decode.d3.loss_cls: 0.0705  decode.d3.loss_mask: 0.8445  decode.d3.loss_dice: 1.7955  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.8820  decode.d4.loss_dice: 1.7827  decode.d5.loss_cls: 0.0752  decode.d5.loss_mask: 0.8877  decode.d5.loss_dice: 1.7739  decode.d6.loss_cls: 0.0897  decode.d6.loss_mask: 0.8548  decode.d6.loss_dice: 1.7640  decode.d7.loss_cls: 0.0896  decode.d7.loss_mask: 0.8395  decode.d7.loss_dice: 1.7815  decode.d8.loss_cls: 0.1014  decode.d8.loss_mask: 0.8507  decode.d8.loss_dice: 1.7464
11/15 07:08:37 - mmengine - INFO - Iter(train) [ 2200/90000]  base_lr: 9.7798e-05 lr: 9.7798e-06  eta: 15:28:28  time: 0.5930  data_time: 0.0102  memory: 10673  grad_norm: 754.0147  loss: 27.7859  decode.loss_cls: 0.1319  decode.loss_mask: 0.9119  decode.loss_dice: 1.7112  decode.d0.loss_cls: 0.4827  decode.d0.loss_mask: 0.9022  decode.d0.loss_dice: 1.8106  decode.d1.loss_cls: 0.0918  decode.d1.loss_mask: 0.8869  decode.d1.loss_dice: 1.7738  decode.d2.loss_cls: 0.0872  decode.d2.loss_mask: 0.9067  decode.d2.loss_dice: 1.7313  decode.d3.loss_cls: 0.0835  decode.d3.loss_mask: 0.9028  decode.d3.loss_dice: 1.7615  decode.d4.loss_cls: 0.0963  decode.d4.loss_mask: 0.8978  decode.d4.loss_dice: 1.7527  decode.d5.loss_cls: 0.1031  decode.d5.loss_mask: 0.8825  decode.d5.loss_dice: 1.7422  decode.d6.loss_cls: 0.1549  decode.d6.loss_mask: 0.8791  decode.d6.loss_dice: 1.6657  decode.d7.loss_cls: 0.1173  decode.d7.loss_mask: 0.9019  decode.d7.loss_dice: 1.7087  decode.d8.loss_cls: 0.1270  decode.d8.loss_mask: 0.8961  decode.d8.loss_dice: 1.6846
11/15 07:09:07 - mmengine - INFO - Iter(train) [ 2250/90000]  base_lr: 9.7748e-05 lr: 9.7748e-06  eta: 15:26:38  time: 0.5935  data_time: 0.0096  memory: 10673  grad_norm: 896.1455  loss: 25.9755  decode.loss_cls: 0.0799  decode.loss_mask: 0.7191  decode.loss_dice: 1.7504  decode.d0.loss_cls: 0.4621  decode.d0.loss_mask: 0.7242  decode.d0.loss_dice: 1.8112  decode.d1.loss_cls: 0.0846  decode.d1.loss_mask: 0.7398  decode.d1.loss_dice: 1.7541  decode.d2.loss_cls: 0.0829  decode.d2.loss_mask: 0.7233  decode.d2.loss_dice: 1.7384  decode.d3.loss_cls: 0.0783  decode.d3.loss_mask: 0.7306  decode.d3.loss_dice: 1.7359  decode.d4.loss_cls: 0.0891  decode.d4.loss_mask: 0.7364  decode.d4.loss_dice: 1.7246  decode.d5.loss_cls: 0.0861  decode.d5.loss_mask: 0.7319  decode.d5.loss_dice: 1.7354  decode.d6.loss_cls: 0.0883  decode.d6.loss_mask: 0.7255  decode.d6.loss_dice: 1.7251  decode.d7.loss_cls: 0.0859  decode.d7.loss_mask: 0.7507  decode.d7.loss_dice: 1.7370  decode.d8.loss_cls: 0.0890  decode.d8.loss_mask: 0.7223  decode.d8.loss_dice: 1.7337
11/15 07:09:37 - mmengine - INFO - Iter(train) [ 2300/90000]  base_lr: 9.7698e-05 lr: 9.7698e-06  eta: 15:24:52  time: 0.5941  data_time: 0.0099  memory: 10693  grad_norm: 825.7808  loss: 28.4345  decode.loss_cls: 0.0961  decode.loss_mask: 0.8772  decode.loss_dice: 1.8740  decode.d0.loss_cls: 0.4545  decode.d0.loss_mask: 0.8205  decode.d0.loss_dice: 1.9149  decode.d1.loss_cls: 0.0884  decode.d1.loss_mask: 0.8419  decode.d1.loss_dice: 1.8410  decode.d2.loss_cls: 0.0820  decode.d2.loss_mask: 0.8393  decode.d2.loss_dice: 1.8339  decode.d3.loss_cls: 0.0820  decode.d3.loss_mask: 0.8560  decode.d3.loss_dice: 1.8232  decode.d4.loss_cls: 0.0949  decode.d4.loss_mask: 0.8575  decode.d4.loss_dice: 1.8098  decode.d5.loss_cls: 0.0853  decode.d5.loss_mask: 0.8959  decode.d5.loss_dice: 1.8448  decode.d6.loss_cls: 0.0874  decode.d6.loss_mask: 0.8872  decode.d6.loss_dice: 1.8677  decode.d7.loss_cls: 0.1035  decode.d7.loss_mask: 0.9010  decode.d7.loss_dice: 1.8441  decode.d8.loss_cls: 0.1133  decode.d8.loss_mask: 0.8587  decode.d8.loss_dice: 1.8587
11/15 07:10:06 - mmengine - INFO - Iter(train) [ 2350/90000]  base_lr: 9.7648e-05 lr: 9.7648e-06  eta: 15:23:08  time: 0.5942  data_time: 0.0101  memory: 10628  grad_norm: 616.8892  loss: 26.0747  decode.loss_cls: 0.1196  decode.loss_mask: 0.7871  decode.loss_dice: 1.6854  decode.d0.loss_cls: 0.4669  decode.d0.loss_mask: 0.7599  decode.d0.loss_dice: 1.7795  decode.d1.loss_cls: 0.1019  decode.d1.loss_mask: 0.7753  decode.d1.loss_dice: 1.6960  decode.d2.loss_cls: 0.0947  decode.d2.loss_mask: 0.7686  decode.d2.loss_dice: 1.6809  decode.d3.loss_cls: 0.1085  decode.d3.loss_mask: 0.7538  decode.d3.loss_dice: 1.6570  decode.d4.loss_cls: 0.1135  decode.d4.loss_mask: 0.7651  decode.d4.loss_dice: 1.6412  decode.d5.loss_cls: 0.1119  decode.d5.loss_mask: 0.7727  decode.d5.loss_dice: 1.6973  decode.d6.loss_cls: 0.1311  decode.d6.loss_mask: 0.7740  decode.d6.loss_dice: 1.6578  decode.d7.loss_cls: 0.1093  decode.d7.loss_mask: 0.7821  decode.d7.loss_dice: 1.6902  decode.d8.loss_cls: 0.1169  decode.d8.loss_mask: 0.7931  decode.d8.loss_dice: 1.6831
11/15 07:10:36 - mmengine - INFO - Iter(train) [ 2400/90000]  base_lr: 9.7598e-05 lr: 9.7598e-06  eta: 15:21:36  time: 0.6028  data_time: 0.0103  memory: 10710  grad_norm: 390.8243  loss: 27.6187  decode.loss_cls: 0.1337  decode.loss_mask: 0.8314  decode.loss_dice: 1.7487  decode.d0.loss_cls: 0.4675  decode.d0.loss_mask: 0.8275  decode.d0.loss_dice: 1.8511  decode.d1.loss_cls: 0.1200  decode.d1.loss_mask: 0.8454  decode.d1.loss_dice: 1.7727  decode.d2.loss_cls: 0.1187  decode.d2.loss_mask: 0.8267  decode.d2.loss_dice: 1.7679  decode.d3.loss_cls: 0.1137  decode.d3.loss_mask: 0.8358  decode.d3.loss_dice: 1.7611  decode.d4.loss_cls: 0.1197  decode.d4.loss_mask: 0.8391  decode.d4.loss_dice: 1.7518  decode.d5.loss_cls: 0.1203  decode.d5.loss_mask: 0.8313  decode.d5.loss_dice: 1.7810  decode.d6.loss_cls: 0.1329  decode.d6.loss_mask: 0.8236  decode.d6.loss_dice: 1.7367  decode.d7.loss_cls: 0.1247  decode.d7.loss_mask: 0.8373  decode.d7.loss_dice: 1.7722  decode.d8.loss_cls: 0.1427  decode.d8.loss_mask: 0.8346  decode.d8.loss_dice: 1.7490
11/15 07:11:06 - mmengine - INFO - Iter(train) [ 2450/90000]  base_lr: 9.7548e-05 lr: 9.7548e-06  eta: 15:20:06  time: 0.5967  data_time: 0.0099  memory: 10693  grad_norm: 451.3556  loss: 28.0287  decode.loss_cls: 0.1312  decode.loss_mask: 0.7735  decode.loss_dice: 1.8659  decode.d0.loss_cls: 0.4535  decode.d0.loss_mask: 0.7852  decode.d0.loss_dice: 1.9119  decode.d1.loss_cls: 0.0976  decode.d1.loss_mask: 0.7983  decode.d1.loss_dice: 1.9187  decode.d2.loss_cls: 0.0957  decode.d2.loss_mask: 0.8053  decode.d2.loss_dice: 1.8782  decode.d3.loss_cls: 0.0926  decode.d3.loss_mask: 0.7907  decode.d3.loss_dice: 1.8730  decode.d4.loss_cls: 0.1270  decode.d4.loss_mask: 0.7743  decode.d4.loss_dice: 1.8531  decode.d5.loss_cls: 0.1205  decode.d5.loss_mask: 0.7696  decode.d5.loss_dice: 1.8099  decode.d6.loss_cls: 0.1225  decode.d6.loss_mask: 0.7956  decode.d6.loss_dice: 1.8501  decode.d7.loss_cls: 0.1225  decode.d7.loss_mask: 0.7689  decode.d7.loss_dice: 1.8396  decode.d8.loss_cls: 0.1080  decode.d8.loss_mask: 0.8139  decode.d8.loss_dice: 1.8821
11/15 07:11:36 - mmengine - INFO - Iter(train) [ 2500/90000]  base_lr: 9.7497e-05 lr: 9.7497e-06  eta: 15:18:36  time: 0.5959  data_time: 0.0097  memory: 10673  grad_norm: 809.6031  loss: 26.8646  decode.loss_cls: 0.1151  decode.loss_mask: 0.7991  decode.loss_dice: 1.7686  decode.d0.loss_cls: 0.4399  decode.d0.loss_mask: 0.7661  decode.d0.loss_dice: 1.7889  decode.d1.loss_cls: 0.0802  decode.d1.loss_mask: 0.8030  decode.d1.loss_dice: 1.7542  decode.d2.loss_cls: 0.0893  decode.d2.loss_mask: 0.8156  decode.d2.loss_dice: 1.7587  decode.d3.loss_cls: 0.0871  decode.d3.loss_mask: 0.8119  decode.d3.loss_dice: 1.7558  decode.d4.loss_cls: 0.0964  decode.d4.loss_mask: 0.7971  decode.d4.loss_dice: 1.7367  decode.d5.loss_cls: 0.1085  decode.d5.loss_mask: 0.7904  decode.d5.loss_dice: 1.7236  decode.d6.loss_cls: 0.1287  decode.d6.loss_mask: 0.7950  decode.d6.loss_dice: 1.7208  decode.d7.loss_cls: 0.1148  decode.d7.loss_mask: 0.8058  decode.d7.loss_dice: 1.7494  decode.d8.loss_cls: 0.1235  decode.d8.loss_mask: 0.8103  decode.d8.loss_dice: 1.7302
11/15 07:12:06 - mmengine - INFO - Iter(train) [ 2550/90000]  base_lr: 9.7447e-05 lr: 9.7447e-06  eta: 15:17:07  time: 0.5977  data_time: 0.0101  memory: 10642  grad_norm: 627.8543  loss: 29.4764  decode.loss_cls: 0.1399  decode.loss_mask: 0.9332  decode.loss_dice: 1.9149  decode.d0.loss_cls: 0.4497  decode.d0.loss_mask: 0.8361  decode.d0.loss_dice: 1.9484  decode.d1.loss_cls: 0.1344  decode.d1.loss_mask: 0.8818  decode.d1.loss_dice: 1.9134  decode.d2.loss_cls: 0.1181  decode.d2.loss_mask: 0.8678  decode.d2.loss_dice: 1.8969  decode.d3.loss_cls: 0.1317  decode.d3.loss_mask: 0.8530  decode.d3.loss_dice: 1.8812  decode.d4.loss_cls: 0.1286  decode.d4.loss_mask: 0.8451  decode.d4.loss_dice: 1.8731  decode.d5.loss_cls: 0.1314  decode.d5.loss_mask: 0.9104  decode.d5.loss_dice: 1.8766  decode.d6.loss_cls: 0.1340  decode.d6.loss_mask: 0.8853  decode.d6.loss_dice: 1.8742  decode.d7.loss_cls: 0.1477  decode.d7.loss_mask: 0.8670  decode.d7.loss_dice: 1.9216  decode.d8.loss_cls: 0.1455  decode.d8.loss_mask: 0.9249  decode.d8.loss_dice: 1.9105
11/15 07:12:36 - mmengine - INFO - Iter(train) [ 2600/90000]  base_lr: 9.7397e-05 lr: 9.7397e-06  eta: 15:15:42  time: 0.5964  data_time: 0.0100  memory: 10656  grad_norm: 400.8666  loss: 27.1485  decode.loss_cls: 0.1426  decode.loss_mask: 0.7739  decode.loss_dice: 1.7816  decode.d0.loss_cls: 0.4361  decode.d0.loss_mask: 0.8088  decode.d0.loss_dice: 1.8453  decode.d1.loss_cls: 0.0936  decode.d1.loss_mask: 0.8066  decode.d1.loss_dice: 1.7795  decode.d2.loss_cls: 0.1079  decode.d2.loss_mask: 0.8191  decode.d2.loss_dice: 1.7642  decode.d3.loss_cls: 0.1046  decode.d3.loss_mask: 0.8209  decode.d3.loss_dice: 1.7325  decode.d4.loss_cls: 0.1115  decode.d4.loss_mask: 0.8037  decode.d4.loss_dice: 1.7303  decode.d5.loss_cls: 0.1272  decode.d5.loss_mask: 0.7633  decode.d5.loss_dice: 1.7288  decode.d6.loss_cls: 0.1248  decode.d6.loss_mask: 0.7691  decode.d6.loss_dice: 1.7573  decode.d7.loss_cls: 0.1385  decode.d7.loss_mask: 0.7566  decode.d7.loss_dice: 1.7775  decode.d8.loss_cls: 0.1451  decode.d8.loss_mask: 0.7772  decode.d8.loss_dice: 1.8202
11/15 07:13:06 - mmengine - INFO - Iter(train) [ 2650/90000]  base_lr: 9.7347e-05 lr: 9.7347e-06  eta: 15:14:20  time: 0.5990  data_time: 0.0103  memory: 10673  grad_norm: 924.9182  loss: 27.7010  decode.loss_cls: 0.1385  decode.loss_mask: 0.8022  decode.loss_dice: 1.7991  decode.d0.loss_cls: 0.4248  decode.d0.loss_mask: 0.8337  decode.d0.loss_dice: 1.8775  decode.d1.loss_cls: 0.1028  decode.d1.loss_mask: 0.7764  decode.d1.loss_dice: 1.8437  decode.d2.loss_cls: 0.1063  decode.d2.loss_mask: 0.8040  decode.d2.loss_dice: 1.8072  decode.d3.loss_cls: 0.0901  decode.d3.loss_mask: 0.8207  decode.d3.loss_dice: 1.8149  decode.d4.loss_cls: 0.1053  decode.d4.loss_mask: 0.8180  decode.d4.loss_dice: 1.8041  decode.d5.loss_cls: 0.1071  decode.d5.loss_mask: 0.8205  decode.d5.loss_dice: 1.7937  decode.d6.loss_cls: 0.1144  decode.d6.loss_mask: 0.8115  decode.d6.loss_dice: 1.7786  decode.d7.loss_cls: 0.1238  decode.d7.loss_mask: 0.8444  decode.d7.loss_dice: 1.8097  decode.d8.loss_cls: 0.1226  decode.d8.loss_mask: 0.8127  decode.d8.loss_dice: 1.7925
11/15 07:13:36 - mmengine - INFO - Iter(train) [ 2700/90000]  base_lr: 9.7297e-05 lr: 9.7297e-06  eta: 15:13:02  time: 0.5984  data_time: 0.0102  memory: 10673  grad_norm: 497.8877  loss: 26.0014  decode.loss_cls: 0.0928  decode.loss_mask: 0.8980  decode.loss_dice: 1.5858  decode.d0.loss_cls: 0.4309  decode.d0.loss_mask: 0.8689  decode.d0.loss_dice: 1.6135  decode.d1.loss_cls: 0.1049  decode.d1.loss_mask: 0.8872  decode.d1.loss_dice: 1.5716  decode.d2.loss_cls: 0.0934  decode.d2.loss_mask: 0.8879  decode.d2.loss_dice: 1.5487  decode.d3.loss_cls: 0.0869  decode.d3.loss_mask: 0.9363  decode.d3.loss_dice: 1.5946  decode.d4.loss_cls: 0.0950  decode.d4.loss_mask: 0.9149  decode.d4.loss_dice: 1.5523  decode.d5.loss_cls: 0.0922  decode.d5.loss_mask: 0.9133  decode.d5.loss_dice: 1.5436  decode.d6.loss_cls: 0.0948  decode.d6.loss_mask: 0.9046  decode.d6.loss_dice: 1.5500  decode.d7.loss_cls: 0.1025  decode.d7.loss_mask: 0.9025  decode.d7.loss_dice: 1.5707  decode.d8.loss_cls: 0.1038  decode.d8.loss_mask: 0.8882  decode.d8.loss_dice: 1.5714
11/15 07:14:06 - mmengine - INFO - Iter(train) [ 2750/90000]  base_lr: 9.7247e-05 lr: 9.7247e-06  eta: 15:11:43  time: 0.5952  data_time: 0.0096  memory: 10693  grad_norm: 464.2214  loss: 24.3796  decode.loss_cls: 0.1300  decode.loss_mask: 0.8634  decode.loss_dice: 1.4642  decode.d0.loss_cls: 0.4196  decode.d0.loss_mask: 0.8237  decode.d0.loss_dice: 1.5362  decode.d1.loss_cls: 0.1207  decode.d1.loss_mask: 0.8275  decode.d1.loss_dice: 1.4966  decode.d2.loss_cls: 0.1133  decode.d2.loss_mask: 0.7899  decode.d2.loss_dice: 1.4420  decode.d3.loss_cls: 0.1224  decode.d3.loss_mask: 0.7749  decode.d3.loss_dice: 1.4456  decode.d4.loss_cls: 0.1123  decode.d4.loss_mask: 0.7879  decode.d4.loss_dice: 1.4477  decode.d5.loss_cls: 0.1345  decode.d5.loss_mask: 0.7948  decode.d5.loss_dice: 1.4388  decode.d6.loss_cls: 0.1231  decode.d6.loss_mask: 0.7979  decode.d6.loss_dice: 1.4607  decode.d7.loss_cls: 0.1288  decode.d7.loss_mask: 0.8782  decode.d7.loss_dice: 1.4518  decode.d8.loss_cls: 0.1158  decode.d8.loss_mask: 0.8874  decode.d8.loss_dice: 1.4500
11/15 07:14:35 - mmengine - INFO - Iter(train) [ 2800/90000]  base_lr: 9.7197e-05 lr: 9.7197e-06  eta: 15:10:25  time: 0.5957  data_time: 0.0099  memory: 10693  grad_norm: 434.4903  loss: 27.5355  decode.loss_cls: 0.1343  decode.loss_mask: 0.8304  decode.loss_dice: 1.7691  decode.d0.loss_cls: 0.4141  decode.d0.loss_mask: 0.8456  decode.d0.loss_dice: 1.8143  decode.d1.loss_cls: 0.0969  decode.d1.loss_mask: 0.8289  decode.d1.loss_dice: 1.7656  decode.d2.loss_cls: 0.0907  decode.d2.loss_mask: 0.8371  decode.d2.loss_dice: 1.7897  decode.d3.loss_cls: 0.1056  decode.d3.loss_mask: 0.8242  decode.d3.loss_dice: 1.7659  decode.d4.loss_cls: 0.1175  decode.d4.loss_mask: 0.8394  decode.d4.loss_dice: 1.7587  decode.d5.loss_cls: 0.1203  decode.d5.loss_mask: 0.8410  decode.d5.loss_dice: 1.7398  decode.d6.loss_cls: 0.1220  decode.d6.loss_mask: 0.8566  decode.d6.loss_dice: 1.7416  decode.d7.loss_cls: 0.1371  decode.d7.loss_mask: 0.8498  decode.d7.loss_dice: 1.7567  decode.d8.loss_cls: 0.1307  decode.d8.loss_mask: 0.8278  decode.d8.loss_dice: 1.7839
11/15 07:15:05 - mmengine - INFO - Iter(train) [ 2850/90000]  base_lr: 9.7146e-05 lr: 9.7146e-06  eta: 15:09:14  time: 0.5996  data_time: 0.0102  memory: 10693  grad_norm: 373.5807  loss: 25.7700  decode.loss_cls: 0.0994  decode.loss_mask: 0.8326  decode.loss_dice: 1.6415  decode.d0.loss_cls: 0.3975  decode.d0.loss_mask: 0.7685  decode.d0.loss_dice: 1.6700  decode.d1.loss_cls: 0.0825  decode.d1.loss_mask: 0.8132  decode.d1.loss_dice: 1.6492  decode.d2.loss_cls: 0.0860  decode.d2.loss_mask: 0.8242  decode.d2.loss_dice: 1.6330  decode.d3.loss_cls: 0.0992  decode.d3.loss_mask: 0.8172  decode.d3.loss_dice: 1.6235  decode.d4.loss_cls: 0.0943  decode.d4.loss_mask: 0.8157  decode.d4.loss_dice: 1.6516  decode.d5.loss_cls: 0.0912  decode.d5.loss_mask: 0.7953  decode.d5.loss_dice: 1.6473  decode.d6.loss_cls: 0.0955  decode.d6.loss_mask: 0.8144  decode.d6.loss_dice: 1.6496  decode.d7.loss_cls: 0.0987  decode.d7.loss_mask: 0.8237  decode.d7.loss_dice: 1.6238  decode.d8.loss_cls: 0.0980  decode.d8.loss_mask: 0.8179  decode.d8.loss_dice: 1.6155
11/15 07:15:35 - mmengine - INFO - Iter(train) [ 2900/90000]  base_lr: 9.7096e-05 lr: 9.7096e-06  eta: 15:08:00  time: 0.5975  data_time: 0.0101  memory: 10710  grad_norm: 430.5974  loss: 26.2732  decode.loss_cls: 0.0887  decode.loss_mask: 0.8364  decode.loss_dice: 1.6525  decode.d0.loss_cls: 0.3977  decode.d0.loss_mask: 0.8606  decode.d0.loss_dice: 1.6936  decode.d1.loss_cls: 0.0755  decode.d1.loss_mask: 0.8726  decode.d1.loss_dice: 1.6575  decode.d2.loss_cls: 0.0676  decode.d2.loss_mask: 0.8581  decode.d2.loss_dice: 1.6469  decode.d3.loss_cls: 0.0694  decode.d3.loss_mask: 0.8303  decode.d3.loss_dice: 1.6550  decode.d4.loss_cls: 0.0683  decode.d4.loss_mask: 0.8736  decode.d4.loss_dice: 1.6809  decode.d5.loss_cls: 0.0800  decode.d5.loss_mask: 0.8768  decode.d5.loss_dice: 1.6671  decode.d6.loss_cls: 0.0916  decode.d6.loss_mask: 0.8677  decode.d6.loss_dice: 1.6306  decode.d7.loss_cls: 0.0912  decode.d7.loss_mask: 0.8282  decode.d7.loss_dice: 1.6653  decode.d8.loss_cls: 0.0830  decode.d8.loss_mask: 0.8349  decode.d8.loss_dice: 1.6716
11/15 07:16:05 - mmengine - INFO - Iter(train) [ 2950/90000]  base_lr: 9.7046e-05 lr: 9.7046e-06  eta: 15:06:53  time: 0.6018  data_time: 0.0102  memory: 10693  grad_norm: 290.9397  loss: 24.6630  decode.loss_cls: 0.1416  decode.loss_mask: 0.6295  decode.loss_dice: 1.6717  decode.d0.loss_cls: 0.4040  decode.d0.loss_mask: 0.6351  decode.d0.loss_dice: 1.7895  decode.d1.loss_cls: 0.1267  decode.d1.loss_mask: 0.6103  decode.d1.loss_dice: 1.7158  decode.d2.loss_cls: 0.1056  decode.d2.loss_mask: 0.6290  decode.d2.loss_dice: 1.6935  decode.d3.loss_cls: 0.1130  decode.d3.loss_mask: 0.6325  decode.d3.loss_dice: 1.6701  decode.d4.loss_cls: 0.1215  decode.d4.loss_mask: 0.6285  decode.d4.loss_dice: 1.6627  decode.d5.loss_cls: 0.1235  decode.d5.loss_mask: 0.6362  decode.d5.loss_dice: 1.6614  decode.d6.loss_cls: 0.1294  decode.d6.loss_mask: 0.6395  decode.d6.loss_dice: 1.6351  decode.d7.loss_cls: 0.1319  decode.d7.loss_mask: 0.6290  decode.d7.loss_dice: 1.6707  decode.d8.loss_cls: 0.1412  decode.d8.loss_mask: 0.6260  decode.d8.loss_dice: 1.6585
11/15 07:16:35 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 07:16:35 - mmengine - INFO - Iter(train) [ 3000/90000]  base_lr: 9.6996e-05 lr: 9.6996e-06  eta: 15:05:45  time: 0.5981  data_time: 0.0102  memory: 10656  grad_norm: 359.0719  loss: 26.0492  decode.loss_cls: 0.1197  decode.loss_mask: 0.7818  decode.loss_dice: 1.6777  decode.d0.loss_cls: 0.3860  decode.d0.loss_mask: 0.7792  decode.d0.loss_dice: 1.7698  decode.d1.loss_cls: 0.0924  decode.d1.loss_mask: 0.7624  decode.d1.loss_dice: 1.7053  decode.d2.loss_cls: 0.0823  decode.d2.loss_mask: 0.7587  decode.d2.loss_dice: 1.7201  decode.d3.loss_cls: 0.0959  decode.d3.loss_mask: 0.7714  decode.d3.loss_dice: 1.7580  decode.d4.loss_cls: 0.1077  decode.d4.loss_mask: 0.7551  decode.d4.loss_dice: 1.7105  decode.d5.loss_cls: 0.1079  decode.d5.loss_mask: 0.7531  decode.d5.loss_dice: 1.6691  decode.d6.loss_cls: 0.1176  decode.d6.loss_mask: 0.7568  decode.d6.loss_dice: 1.6249  decode.d7.loss_cls: 0.0937  decode.d7.loss_mask: 0.7847  decode.d7.loss_dice: 1.7152  decode.d8.loss_cls: 0.1340  decode.d8.loss_mask: 0.7779  decode.d8.loss_dice: 1.6803
11/15 07:17:05 - mmengine - INFO - Iter(train) [ 3050/90000]  base_lr: 9.6946e-05 lr: 9.6946e-06  eta: 15:04:36  time: 0.5975  data_time: 0.0101  memory: 10710  grad_norm: 383.1484  loss: 25.9250  decode.loss_cls: 0.1169  decode.loss_mask: 0.8540  decode.loss_dice: 1.6069  decode.d0.loss_cls: 0.3711  decode.d0.loss_mask: 0.8023  decode.d0.loss_dice: 1.6723  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.8100  decode.d1.loss_dice: 1.6527  decode.d2.loss_cls: 0.0801  decode.d2.loss_mask: 0.8430  decode.d2.loss_dice: 1.6302  decode.d3.loss_cls: 0.0950  decode.d3.loss_mask: 0.8499  decode.d3.loss_dice: 1.5950  decode.d4.loss_cls: 0.0923  decode.d4.loss_mask: 0.8458  decode.d4.loss_dice: 1.5914  decode.d5.loss_cls: 0.0976  decode.d5.loss_mask: 0.8515  decode.d5.loss_dice: 1.6166  decode.d6.loss_cls: 0.1019  decode.d6.loss_mask: 0.8611  decode.d6.loss_dice: 1.6314  decode.d7.loss_cls: 0.1090  decode.d7.loss_mask: 0.8803  decode.d7.loss_dice: 1.6123  decode.d8.loss_cls: 0.1279  decode.d8.loss_mask: 0.8374  decode.d8.loss_dice: 1.5968
11/15 07:17:36 - mmengine - INFO - Iter(train) [ 3100/90000]  base_lr: 9.6896e-05 lr: 9.6896e-06  eta: 15:03:52  time: 0.5970  data_time: 0.0102  memory: 10693  grad_norm: 548.4371  loss: 26.9798  decode.loss_cls: 0.0822  decode.loss_mask: 0.9022  decode.loss_dice: 1.6749  decode.d0.loss_cls: 0.3726  decode.d0.loss_mask: 0.9259  decode.d0.loss_dice: 1.6793  decode.d1.loss_cls: 0.0968  decode.d1.loss_mask: 0.9043  decode.d1.loss_dice: 1.6939  decode.d2.loss_cls: 0.0757  decode.d2.loss_mask: 0.9121  decode.d2.loss_dice: 1.6974  decode.d3.loss_cls: 0.0805  decode.d3.loss_mask: 0.8950  decode.d3.loss_dice: 1.6909  decode.d4.loss_cls: 0.0936  decode.d4.loss_mask: 0.8917  decode.d4.loss_dice: 1.6687  decode.d5.loss_cls: 0.0944  decode.d5.loss_mask: 0.8999  decode.d5.loss_dice: 1.6617  decode.d6.loss_cls: 0.0974  decode.d6.loss_mask: 0.8906  decode.d6.loss_dice: 1.6607  decode.d7.loss_cls: 0.0959  decode.d7.loss_mask: 0.8714  decode.d7.loss_dice: 1.6952  decode.d8.loss_cls: 0.0933  decode.d8.loss_mask: 0.8824  decode.d8.loss_dice: 1.6993
11/15 07:18:06 - mmengine - INFO - Iter(train) [ 3150/90000]  base_lr: 9.6845e-05 lr: 9.6845e-06  eta: 15:02:44  time: 0.5973  data_time: 0.0101  memory: 10693  grad_norm: 685.0478  loss: 29.3691  decode.loss_cls: 0.1585  decode.loss_mask: 0.9157  decode.loss_dice: 1.8433  decode.d0.loss_cls: 0.3911  decode.d0.loss_mask: 0.8883  decode.d0.loss_dice: 1.8829  decode.d1.loss_cls: 0.1299  decode.d1.loss_mask: 0.9311  decode.d1.loss_dice: 1.8695  decode.d2.loss_cls: 0.1407  decode.d2.loss_mask: 0.9218  decode.d2.loss_dice: 1.8196  decode.d3.loss_cls: 0.1451  decode.d3.loss_mask: 0.9112  decode.d3.loss_dice: 1.7940  decode.d4.loss_cls: 0.1218  decode.d4.loss_mask: 0.9845  decode.d4.loss_dice: 1.8868  decode.d5.loss_cls: 0.1461  decode.d5.loss_mask: 0.9350  decode.d5.loss_dice: 1.8418  decode.d6.loss_cls: 0.1559  decode.d6.loss_mask: 0.8815  decode.d6.loss_dice: 1.8577  decode.d7.loss_cls: 0.1450  decode.d7.loss_mask: 0.9081  decode.d7.loss_dice: 1.8609  decode.d8.loss_cls: 0.1466  decode.d8.loss_mask: 0.9054  decode.d8.loss_dice: 1.8493
11/15 07:18:38 - mmengine - INFO - Iter(train) [ 3200/90000]  base_lr: 9.6795e-05 lr: 9.6795e-06  eta: 15:02:32  time: 0.5988  data_time: 0.0104  memory: 10673  grad_norm: 318.1034  loss: 25.8464  decode.loss_cls: 0.1127  decode.loss_mask: 0.7311  decode.loss_dice: 1.7131  decode.d0.loss_cls: 0.3405  decode.d0.loss_mask: 0.7549  decode.d0.loss_dice: 1.7843  decode.d1.loss_cls: 0.0995  decode.d1.loss_mask: 0.7387  decode.d1.loss_dice: 1.7528  decode.d2.loss_cls: 0.0911  decode.d2.loss_mask: 0.7275  decode.d2.loss_dice: 1.7209  decode.d3.loss_cls: 0.1046  decode.d3.loss_mask: 0.7298  decode.d3.loss_dice: 1.7114  decode.d4.loss_cls: 0.0976  decode.d4.loss_mask: 0.7294  decode.d4.loss_dice: 1.7066  decode.d5.loss_cls: 0.0926  decode.d5.loss_mask: 0.7299  decode.d5.loss_dice: 1.7172  decode.d6.loss_cls: 0.0962  decode.d6.loss_mask: 0.7290  decode.d6.loss_dice: 1.7003  decode.d7.loss_cls: 0.1104  decode.d7.loss_mask: 0.7307  decode.d7.loss_dice: 1.7162  decode.d8.loss_cls: 0.1051  decode.d8.loss_mask: 0.7381  decode.d8.loss_dice: 1.7343
11/15 07:19:08 - mmengine - INFO - Iter(train) [ 3250/90000]  base_lr: 9.6745e-05 lr: 9.6745e-06  eta: 15:01:26  time: 0.5959  data_time: 0.0097  memory: 10673  grad_norm: 574.3003  loss: 28.5053  decode.loss_cls: 0.1507  decode.loss_mask: 0.9696  decode.loss_dice: 1.7441  decode.d0.loss_cls: 0.3681  decode.d0.loss_mask: 0.8935  decode.d0.loss_dice: 1.7581  decode.d1.loss_cls: 0.0994  decode.d1.loss_mask: 0.9653  decode.d1.loss_dice: 1.7801  decode.d2.loss_cls: 0.1165  decode.d2.loss_mask: 0.9704  decode.d2.loss_dice: 1.7714  decode.d3.loss_cls: 0.1183  decode.d3.loss_mask: 0.9913  decode.d3.loss_dice: 1.7227  decode.d4.loss_cls: 0.1441  decode.d4.loss_mask: 0.9507  decode.d4.loss_dice: 1.6985  decode.d5.loss_cls: 0.1167  decode.d5.loss_mask: 0.9631  decode.d5.loss_dice: 1.7757  decode.d6.loss_cls: 0.1423  decode.d6.loss_mask: 0.9597  decode.d6.loss_dice: 1.6932  decode.d7.loss_cls: 0.1522  decode.d7.loss_mask: 0.9493  decode.d7.loss_dice: 1.7455  decode.d8.loss_cls: 0.1383  decode.d8.loss_mask: 0.9412  decode.d8.loss_dice: 1.7151
11/15 07:19:38 - mmengine - INFO - Iter(train) [ 3300/90000]  base_lr: 9.6695e-05 lr: 9.6695e-06  eta: 15:00:20  time: 0.5956  data_time: 0.0099  memory: 10656  grad_norm: 559.4686  loss: 26.5332  decode.loss_cls: 0.1121  decode.loss_mask: 0.8111  decode.loss_dice: 1.6985  decode.d0.loss_cls: 0.3311  decode.d0.loss_mask: 0.8332  decode.d0.loss_dice: 1.8039  decode.d1.loss_cls: 0.0800  decode.d1.loss_mask: 0.8141  decode.d1.loss_dice: 1.7461  decode.d2.loss_cls: 0.0899  decode.d2.loss_mask: 0.8174  decode.d2.loss_dice: 1.7154  decode.d3.loss_cls: 0.0887  decode.d3.loss_mask: 0.8196  decode.d3.loss_dice: 1.7099  decode.d4.loss_cls: 0.0814  decode.d4.loss_mask: 0.8071  decode.d4.loss_dice: 1.7178  decode.d5.loss_cls: 0.0964  decode.d5.loss_mask: 0.7967  decode.d5.loss_dice: 1.6988  decode.d6.loss_cls: 0.1025  decode.d6.loss_mask: 0.8235  decode.d6.loss_dice: 1.7157  decode.d7.loss_cls: 0.0818  decode.d7.loss_mask: 0.8071  decode.d7.loss_dice: 1.7241  decode.d8.loss_cls: 0.1004  decode.d8.loss_mask: 0.7866  decode.d8.loss_dice: 1.7225
11/15 07:20:08 - mmengine - INFO - Iter(train) [ 3350/90000]  base_lr: 9.6645e-05 lr: 9.6645e-06  eta: 14:59:30  time: 0.6001  data_time: 0.0100  memory: 10710  grad_norm: 443.0257  loss: 24.8080  decode.loss_cls: 0.1440  decode.loss_mask: 0.6110  decode.loss_dice: 1.6926  decode.d0.loss_cls: 0.3451  decode.d0.loss_mask: 0.6078  decode.d0.loss_dice: 1.8180  decode.d1.loss_cls: 0.0898  decode.d1.loss_mask: 0.6232  decode.d1.loss_dice: 1.7568  decode.d2.loss_cls: 0.1057  decode.d2.loss_mask: 0.6298  decode.d2.loss_dice: 1.7361  decode.d3.loss_cls: 0.1126  decode.d3.loss_mask: 0.6214  decode.d3.loss_dice: 1.7071  decode.d4.loss_cls: 0.1250  decode.d4.loss_mask: 0.6211  decode.d4.loss_dice: 1.7140  decode.d5.loss_cls: 0.1393  decode.d5.loss_mask: 0.6199  decode.d5.loss_dice: 1.6885  decode.d6.loss_cls: 0.1446  decode.d6.loss_mask: 0.6114  decode.d6.loss_dice: 1.6794  decode.d7.loss_cls: 0.1337  decode.d7.loss_mask: 0.6214  decode.d7.loss_dice: 1.6861  decode.d8.loss_cls: 0.1389  decode.d8.loss_mask: 0.6122  decode.d8.loss_dice: 1.6716
11/15 07:20:40 - mmengine - INFO - Iter(train) [ 3400/90000]  base_lr: 9.6594e-05 lr: 9.6594e-06  eta: 14:59:29  time: 0.5977  data_time: 0.0104  memory: 10710  grad_norm: 782.5824  loss: 28.5381  decode.loss_cls: 0.1413  decode.loss_mask: 0.8986  decode.loss_dice: 1.7521  decode.d0.loss_cls: 0.3410  decode.d0.loss_mask: 0.9374  decode.d0.loss_dice: 1.8808  decode.d1.loss_cls: 0.1438  decode.d1.loss_mask: 0.8866  decode.d1.loss_dice: 1.8140  decode.d2.loss_cls: 0.1303  decode.d2.loss_mask: 0.9245  decode.d2.loss_dice: 1.7970  decode.d3.loss_cls: 0.1357  decode.d3.loss_mask: 0.8849  decode.d3.loss_dice: 1.7796  decode.d4.loss_cls: 0.1503  decode.d4.loss_mask: 0.9128  decode.d4.loss_dice: 1.7657  decode.d5.loss_cls: 0.1334  decode.d5.loss_mask: 0.8970  decode.d5.loss_dice: 1.7481  decode.d6.loss_cls: 0.1307  decode.d6.loss_mask: 0.9746  decode.d6.loss_dice: 1.7362  decode.d7.loss_cls: 0.1427  decode.d7.loss_mask: 0.9442  decode.d7.loss_dice: 1.7510  decode.d8.loss_cls: 0.1601  decode.d8.loss_mask: 0.9248  decode.d8.loss_dice: 1.7192
11/15 07:21:11 - mmengine - INFO - Iter(train) [ 3450/90000]  base_lr: 9.6544e-05 lr: 9.6544e-06  eta: 14:58:40  time: 0.6043  data_time: 0.0105  memory: 10693  grad_norm: 693.2785  loss: 25.7161  decode.loss_cls: 0.0897  decode.loss_mask: 0.7998  decode.loss_dice: 1.6535  decode.d0.loss_cls: 0.3169  decode.d0.loss_mask: 0.8023  decode.d0.loss_dice: 1.7045  decode.d1.loss_cls: 0.0786  decode.d1.loss_mask: 0.7750  decode.d1.loss_dice: 1.7180  decode.d2.loss_cls: 0.0804  decode.d2.loss_mask: 0.7754  decode.d2.loss_dice: 1.6927  decode.d3.loss_cls: 0.0930  decode.d3.loss_mask: 0.7917  decode.d3.loss_dice: 1.6429  decode.d4.loss_cls: 0.0810  decode.d4.loss_mask: 0.8023  decode.d4.loss_dice: 1.6685  decode.d5.loss_cls: 0.0877  decode.d5.loss_mask: 0.7970  decode.d5.loss_dice: 1.6440  decode.d6.loss_cls: 0.0845  decode.d6.loss_mask: 0.8049  decode.d6.loss_dice: 1.6320  decode.d7.loss_cls: 0.0960  decode.d7.loss_mask: 0.7769  decode.d7.loss_dice: 1.6675  decode.d8.loss_cls: 0.0864  decode.d8.loss_mask: 0.7982  decode.d8.loss_dice: 1.6748
11/15 07:21:41 - mmengine - INFO - Iter(train) [ 3500/90000]  base_lr: 9.6494e-05 lr: 9.6494e-06  eta: 14:57:42  time: 0.6027  data_time: 0.0100  memory: 10693  grad_norm: 332.9051  loss: 24.0427  decode.loss_cls: 0.0995  decode.loss_mask: 0.7259  decode.loss_dice: 1.5669  decode.d0.loss_cls: 0.3078  decode.d0.loss_mask: 0.7280  decode.d0.loss_dice: 1.6066  decode.d1.loss_cls: 0.0770  decode.d1.loss_mask: 0.7106  decode.d1.loss_dice: 1.5718  decode.d2.loss_cls: 0.0815  decode.d2.loss_mask: 0.7077  decode.d2.loss_dice: 1.5698  decode.d3.loss_cls: 0.0791  decode.d3.loss_mask: 0.7485  decode.d3.loss_dice: 1.5692  decode.d4.loss_cls: 0.0756  decode.d4.loss_mask: 0.7319  decode.d4.loss_dice: 1.5631  decode.d5.loss_cls: 0.0811  decode.d5.loss_mask: 0.7651  decode.d5.loss_dice: 1.5560  decode.d6.loss_cls: 0.1010  decode.d6.loss_mask: 0.7204  decode.d6.loss_dice: 1.5441  decode.d7.loss_cls: 0.0814  decode.d7.loss_mask: 0.7094  decode.d7.loss_dice: 1.5750  decode.d8.loss_cls: 0.0984  decode.d8.loss_mask: 0.7419  decode.d8.loss_dice: 1.5484
11/15 07:22:11 - mmengine - INFO - Iter(train) [ 3550/90000]  base_lr: 9.6444e-05 lr: 9.6444e-06  eta: 14:56:48  time: 0.6054  data_time: 0.0104  memory: 10693  grad_norm: 609.7634  loss: 21.8752  decode.loss_cls: 0.0957  decode.loss_mask: 0.7562  decode.loss_dice: 1.3063  decode.d0.loss_cls: 0.3141  decode.d0.loss_mask: 0.8270  decode.d0.loss_dice: 1.3906  decode.d1.loss_cls: 0.0794  decode.d1.loss_mask: 0.7745  decode.d1.loss_dice: 1.3282  decode.d2.loss_cls: 0.0790  decode.d2.loss_mask: 0.7704  decode.d2.loss_dice: 1.3287  decode.d3.loss_cls: 0.0815  decode.d3.loss_mask: 0.7669  decode.d3.loss_dice: 1.2832  decode.d4.loss_cls: 0.0873  decode.d4.loss_mask: 0.7648  decode.d4.loss_dice: 1.3002  decode.d5.loss_cls: 0.0950  decode.d5.loss_mask: 0.7716  decode.d5.loss_dice: 1.2728  decode.d6.loss_cls: 0.0971  decode.d6.loss_mask: 0.7636  decode.d6.loss_dice: 1.2654  decode.d7.loss_cls: 0.0918  decode.d7.loss_mask: 0.7731  decode.d7.loss_dice: 1.2728  decode.d8.loss_cls: 0.1046  decode.d8.loss_mask: 0.7540  decode.d8.loss_dice: 1.2793
11/15 07:22:41 - mmengine - INFO - Iter(train) [ 3600/90000]  base_lr: 9.6394e-05 lr: 9.6394e-06  eta: 14:55:56  time: 0.6035  data_time: 0.0102  memory: 10693  grad_norm: 737.6294  loss: 26.8124  decode.loss_cls: 0.0891  decode.loss_mask: 0.8702  decode.loss_dice: 1.6799  decode.d0.loss_cls: 0.3004  decode.d0.loss_mask: 0.8833  decode.d0.loss_dice: 1.7559  decode.d1.loss_cls: 0.0730  decode.d1.loss_mask: 0.8627  decode.d1.loss_dice: 1.7119  decode.d2.loss_cls: 0.0950  decode.d2.loss_mask: 0.8751  decode.d2.loss_dice: 1.7016  decode.d3.loss_cls: 0.0980  decode.d3.loss_mask: 0.8794  decode.d3.loss_dice: 1.6943  decode.d4.loss_cls: 0.0805  decode.d4.loss_mask: 0.8686  decode.d4.loss_dice: 1.6949  decode.d5.loss_cls: 0.0969  decode.d5.loss_mask: 0.8751  decode.d5.loss_dice: 1.6727  decode.d6.loss_cls: 0.0974  decode.d6.loss_mask: 0.8774  decode.d6.loss_dice: 1.6626  decode.d7.loss_cls: 0.0991  decode.d7.loss_mask: 0.8691  decode.d7.loss_dice: 1.6830  decode.d8.loss_cls: 0.0930  decode.d8.loss_mask: 0.8665  decode.d8.loss_dice: 1.7058
11/15 07:23:11 - mmengine - INFO - Iter(train) [ 3650/90000]  base_lr: 9.6343e-05 lr: 9.6343e-06  eta: 14:55:03  time: 0.6068  data_time: 0.0106  memory: 10693  grad_norm: 677.0929  loss: 26.1557  decode.loss_cls: 0.1251  decode.loss_mask: 0.8486  decode.loss_dice: 1.6346  decode.d0.loss_cls: 0.3140  decode.d0.loss_mask: 0.8401  decode.d0.loss_dice: 1.6991  decode.d1.loss_cls: 0.1127  decode.d1.loss_mask: 0.8020  decode.d1.loss_dice: 1.6719  decode.d2.loss_cls: 0.1187  decode.d2.loss_mask: 0.8201  decode.d2.loss_dice: 1.6428  decode.d3.loss_cls: 0.1145  decode.d3.loss_mask: 0.8456  decode.d3.loss_dice: 1.6196  decode.d4.loss_cls: 0.1397  decode.d4.loss_mask: 0.8557  decode.d4.loss_dice: 1.6201  decode.d5.loss_cls: 0.1396  decode.d5.loss_mask: 0.8399  decode.d5.loss_dice: 1.5945  decode.d6.loss_cls: 0.1345  decode.d6.loss_mask: 0.8549  decode.d6.loss_dice: 1.5844  decode.d7.loss_cls: 0.1177  decode.d7.loss_mask: 0.8646  decode.d7.loss_dice: 1.6285  decode.d8.loss_cls: 0.1191  decode.d8.loss_mask: 0.8357  decode.d8.loss_dice: 1.6174
11/15 07:23:42 - mmengine - INFO - Iter(train) [ 3700/90000]  base_lr: 9.6293e-05 lr: 9.6293e-06  eta: 14:54:11  time: 0.6019  data_time: 0.0105  memory: 10693  grad_norm: 669.3760  loss: 22.8045  decode.loss_cls: 0.0685  decode.loss_mask: 0.7609  decode.loss_dice: 1.4511  decode.d0.loss_cls: 0.2889  decode.d0.loss_mask: 0.7500  decode.d0.loss_dice: 1.4760  decode.d1.loss_cls: 0.0656  decode.d1.loss_mask: 0.7560  decode.d1.loss_dice: 1.4721  decode.d2.loss_cls: 0.0602  decode.d2.loss_mask: 0.7494  decode.d2.loss_dice: 1.4373  decode.d3.loss_cls: 0.0643  decode.d3.loss_mask: 0.7476  decode.d3.loss_dice: 1.4166  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.7581  decode.d4.loss_dice: 1.4272  decode.d5.loss_cls: 0.0708  decode.d5.loss_mask: 0.7466  decode.d5.loss_dice: 1.4022  decode.d6.loss_cls: 0.0783  decode.d6.loss_mask: 0.7444  decode.d6.loss_dice: 1.4030  decode.d7.loss_cls: 0.0849  decode.d7.loss_mask: 0.7392  decode.d7.loss_dice: 1.4183  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.7705  decode.d8.loss_dice: 1.4644
11/15 07:24:12 - mmengine - INFO - Iter(train) [ 3750/90000]  base_lr: 9.6243e-05 lr: 9.6243e-06  eta: 14:53:18  time: 0.6015  data_time: 0.0100  memory: 10673  grad_norm: 312.3805  loss: 25.7878  decode.loss_cls: 0.1094  decode.loss_mask: 0.7928  decode.loss_dice: 1.6734  decode.d0.loss_cls: 0.2899  decode.d0.loss_mask: 0.7816  decode.d0.loss_dice: 1.7266  decode.d1.loss_cls: 0.0876  decode.d1.loss_mask: 0.7546  decode.d1.loss_dice: 1.7118  decode.d2.loss_cls: 0.0875  decode.d2.loss_mask: 0.7473  decode.d2.loss_dice: 1.7089  decode.d3.loss_cls: 0.0874  decode.d3.loss_mask: 0.7614  decode.d3.loss_dice: 1.6628  decode.d4.loss_cls: 0.1043  decode.d4.loss_mask: 0.7526  decode.d4.loss_dice: 1.6902  decode.d5.loss_cls: 0.1086  decode.d5.loss_mask: 0.7807  decode.d5.loss_dice: 1.6454  decode.d6.loss_cls: 0.0995  decode.d6.loss_mask: 0.8049  decode.d6.loss_dice: 1.6865  decode.d7.loss_cls: 0.1079  decode.d7.loss_mask: 0.7885  decode.d7.loss_dice: 1.6735  decode.d8.loss_cls: 0.1061  decode.d8.loss_mask: 0.7840  decode.d8.loss_dice: 1.6722
11/15 07:24:42 - mmengine - INFO - Iter(train) [ 3800/90000]  base_lr: 9.6193e-05 lr: 9.6193e-06  eta: 14:52:34  time: 0.5994  data_time: 0.0101  memory: 10693  grad_norm: 578.0761  loss: 26.8755  decode.loss_cls: 0.1235  decode.loss_mask: 0.9008  decode.loss_dice: 1.6716  decode.d0.loss_cls: 0.3009  decode.d0.loss_mask: 0.9017  decode.d0.loss_dice: 1.7045  decode.d1.loss_cls: 0.1100  decode.d1.loss_mask: 0.8946  decode.d1.loss_dice: 1.6728  decode.d2.loss_cls: 0.1172  decode.d2.loss_mask: 0.8642  decode.d2.loss_dice: 1.6555  decode.d3.loss_cls: 0.1176  decode.d3.loss_mask: 0.8444  decode.d3.loss_dice: 1.6468  decode.d4.loss_cls: 0.1270  decode.d4.loss_mask: 0.8518  decode.d4.loss_dice: 1.6622  decode.d5.loss_cls: 0.1304  decode.d5.loss_mask: 0.8395  decode.d5.loss_dice: 1.6736  decode.d6.loss_cls: 0.1278  decode.d6.loss_mask: 0.8760  decode.d6.loss_dice: 1.6425  decode.d7.loss_cls: 0.1025  decode.d7.loss_mask: 0.9116  decode.d7.loss_dice: 1.6838  decode.d8.loss_cls: 0.1026  decode.d8.loss_mask: 0.9219  decode.d8.loss_dice: 1.6960
11/15 07:25:12 - mmengine - INFO - Iter(train) [ 3850/90000]  base_lr: 9.6143e-05 lr: 9.6143e-06  eta: 14:51:40  time: 0.6005  data_time: 0.0100  memory: 10710  grad_norm: 372.7623  loss: 26.1924  decode.loss_cls: 0.1365  decode.loss_mask: 0.7003  decode.loss_dice: 1.7786  decode.d0.loss_cls: 0.2811  decode.d0.loss_mask: 0.7143  decode.d0.loss_dice: 1.8717  decode.d1.loss_cls: 0.1029  decode.d1.loss_mask: 0.6734  decode.d1.loss_dice: 1.8325  decode.d2.loss_cls: 0.1031  decode.d2.loss_mask: 0.6629  decode.d2.loss_dice: 1.7845  decode.d3.loss_cls: 0.1128  decode.d3.loss_mask: 0.6636  decode.d3.loss_dice: 1.7817  decode.d4.loss_cls: 0.1158  decode.d4.loss_mask: 0.7060  decode.d4.loss_dice: 1.7693  decode.d5.loss_cls: 0.1206  decode.d5.loss_mask: 0.6647  decode.d5.loss_dice: 1.7768  decode.d6.loss_cls: 0.1395  decode.d6.loss_mask: 0.7007  decode.d6.loss_dice: 1.7815  decode.d7.loss_cls: 0.1274  decode.d7.loss_mask: 0.6982  decode.d7.loss_dice: 1.7859  decode.d8.loss_cls: 0.1227  decode.d8.loss_mask: 0.7079  decode.d8.loss_dice: 1.7757
11/15 07:25:43 - mmengine - INFO - Iter(train) [ 3900/90000]  base_lr: 9.6092e-05 lr: 9.6092e-06  eta: 14:50:58  time: 0.5925  data_time: 0.0100  memory: 10656  grad_norm: 497.1638  loss: 24.9407  decode.loss_cls: 0.0845  decode.loss_mask: 0.8071  decode.loss_dice: 1.5442  decode.d0.loss_cls: 0.2696  decode.d0.loss_mask: 0.8196  decode.d0.loss_dice: 1.6561  decode.d1.loss_cls: 0.0731  decode.d1.loss_mask: 0.8065  decode.d1.loss_dice: 1.6045  decode.d2.loss_cls: 0.0933  decode.d2.loss_mask: 0.7270  decode.d2.loss_dice: 1.5632  decode.d3.loss_cls: 0.1007  decode.d3.loss_mask: 0.7300  decode.d3.loss_dice: 1.5511  decode.d4.loss_cls: 0.0843  decode.d4.loss_mask: 0.8050  decode.d4.loss_dice: 1.5952  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.8490  decode.d5.loss_dice: 1.6105  decode.d6.loss_cls: 0.0888  decode.d6.loss_mask: 0.7932  decode.d6.loss_dice: 1.5486  decode.d7.loss_cls: 0.0848  decode.d7.loss_mask: 0.8121  decode.d7.loss_dice: 1.6295  decode.d8.loss_cls: 0.0842  decode.d8.loss_mask: 0.8490  decode.d8.loss_dice: 1.5936
11/15 07:26:12 - mmengine - INFO - Iter(train) [ 3950/90000]  base_lr: 9.6042e-05 lr: 9.6042e-06  eta: 14:49:56  time: 0.5943  data_time: 0.0107  memory: 10693  grad_norm: 517.0695  loss: 26.9791  decode.loss_cls: 0.1534  decode.loss_mask: 0.8490  decode.loss_dice: 1.7246  decode.d0.loss_cls: 0.2858  decode.d0.loss_mask: 0.8173  decode.d0.loss_dice: 1.7709  decode.d1.loss_cls: 0.1016  decode.d1.loss_mask: 0.8014  decode.d1.loss_dice: 1.7562  decode.d2.loss_cls: 0.1166  decode.d2.loss_mask: 0.7785  decode.d2.loss_dice: 1.7535  decode.d3.loss_cls: 0.1304  decode.d3.loss_mask: 0.8220  decode.d3.loss_dice: 1.7195  decode.d4.loss_cls: 0.1565  decode.d4.loss_mask: 0.8070  decode.d4.loss_dice: 1.7306  decode.d5.loss_cls: 0.1418  decode.d5.loss_mask: 0.7980  decode.d5.loss_dice: 1.7352  decode.d6.loss_cls: 0.1398  decode.d6.loss_mask: 0.7896  decode.d6.loss_dice: 1.7356  decode.d7.loss_cls: 0.1376  decode.d7.loss_mask: 0.7865  decode.d7.loss_dice: 1.7733  decode.d8.loss_cls: 0.1300  decode.d8.loss_mask: 0.8071  decode.d8.loss_dice: 1.7301
11/15 07:26:42 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 07:26:42 - mmengine - INFO - Iter(train) [ 4000/90000]  base_lr: 9.5992e-05 lr: 9.5992e-06  eta: 14:48:55  time: 0.5912  data_time: 0.0095  memory: 10673  grad_norm: 1247.8299  loss: 27.8719  decode.loss_cls: 0.1301  decode.loss_mask: 0.8577  decode.loss_dice: 1.7961  decode.d0.loss_cls: 0.2669  decode.d0.loss_mask: 0.8800  decode.d0.loss_dice: 1.8721  decode.d1.loss_cls: 0.0918  decode.d1.loss_mask: 0.8360  decode.d1.loss_dice: 1.8335  decode.d2.loss_cls: 0.1275  decode.d2.loss_mask: 0.8474  decode.d2.loss_dice: 1.7959  decode.d3.loss_cls: 0.1043  decode.d3.loss_mask: 0.8867  decode.d3.loss_dice: 1.8047  decode.d4.loss_cls: 0.1429  decode.d4.loss_mask: 0.8539  decode.d4.loss_dice: 1.7765  decode.d5.loss_cls: 0.1218  decode.d5.loss_mask: 0.8243  decode.d5.loss_dice: 1.7695  decode.d6.loss_cls: 0.1175  decode.d6.loss_mask: 0.8182  decode.d6.loss_dice: 1.7709  decode.d7.loss_cls: 0.1295  decode.d7.loss_mask: 0.8310  decode.d7.loss_dice: 1.8176  decode.d8.loss_cls: 0.1364  decode.d8.loss_mask: 0.8310  decode.d8.loss_dice: 1.8002
11/15 07:27:12 - mmengine - INFO - Iter(train) [ 4050/90000]  base_lr: 9.5942e-05 lr: 9.5942e-06  eta: 14:47:54  time: 0.5922  data_time: 0.0097  memory: 10673  grad_norm: 505.7255  loss: 25.4803  decode.loss_cls: 0.1435  decode.loss_mask: 0.8231  decode.loss_dice: 1.5051  decode.d0.loss_cls: 0.2880  decode.d0.loss_mask: 0.7881  decode.d0.loss_dice: 1.6629  decode.d1.loss_cls: 0.1034  decode.d1.loss_mask: 0.8268  decode.d1.loss_dice: 1.6445  decode.d2.loss_cls: 0.1207  decode.d2.loss_mask: 0.8020  decode.d2.loss_dice: 1.5952  decode.d3.loss_cls: 0.1168  decode.d3.loss_mask: 0.8197  decode.d3.loss_dice: 1.5927  decode.d4.loss_cls: 0.1196  decode.d4.loss_mask: 0.8315  decode.d4.loss_dice: 1.5694  decode.d5.loss_cls: 0.1047  decode.d5.loss_mask: 0.8557  decode.d5.loss_dice: 1.5808  decode.d6.loss_cls: 0.1173  decode.d6.loss_mask: 0.8537  decode.d6.loss_dice: 1.5497  decode.d7.loss_cls: 0.1378  decode.d7.loss_mask: 0.8266  decode.d7.loss_dice: 1.5948  decode.d8.loss_cls: 0.1418  decode.d8.loss_mask: 0.8140  decode.d8.loss_dice: 1.5502
11/15 07:27:41 - mmengine - INFO - Iter(train) [ 4100/90000]  base_lr: 9.5891e-05 lr: 9.5891e-06  eta: 14:46:55  time: 0.5920  data_time: 0.0096  memory: 10673  grad_norm: 420.3646  loss: 23.2644  decode.loss_cls: 0.1142  decode.loss_mask: 0.5937  decode.loss_dice: 1.5655  decode.d0.loss_cls: 0.2557  decode.d0.loss_mask: 0.6827  decode.d0.loss_dice: 1.6394  decode.d1.loss_cls: 0.1019  decode.d1.loss_mask: 0.5831  decode.d1.loss_dice: 1.6277  decode.d2.loss_cls: 0.1050  decode.d2.loss_mask: 0.5974  decode.d2.loss_dice: 1.6100  decode.d3.loss_cls: 0.1076  decode.d3.loss_mask: 0.5967  decode.d3.loss_dice: 1.5748  decode.d4.loss_cls: 0.1168  decode.d4.loss_mask: 0.6118  decode.d4.loss_dice: 1.5724  decode.d5.loss_cls: 0.1370  decode.d5.loss_mask: 0.5977  decode.d5.loss_dice: 1.5819  decode.d6.loss_cls: 0.1268  decode.d6.loss_mask: 0.6070  decode.d6.loss_dice: 1.6097  decode.d7.loss_cls: 0.0996  decode.d7.loss_mask: 0.5971  decode.d7.loss_dice: 1.5813  decode.d8.loss_cls: 0.1124  decode.d8.loss_mask: 0.5866  decode.d8.loss_dice: 1.5709
11/15 07:28:11 - mmengine - INFO - Iter(train) [ 4150/90000]  base_lr: 9.5841e-05 lr: 9.5841e-06  eta: 14:45:56  time: 0.5931  data_time: 0.0099  memory: 10656  grad_norm: 331.7081  loss: 24.0242  decode.loss_cls: 0.0631  decode.loss_mask: 0.6908  decode.loss_dice: 1.6428  decode.d0.loss_cls: 0.2302  decode.d0.loss_mask: 0.7131  decode.d0.loss_dice: 1.6476  decode.d1.loss_cls: 0.0651  decode.d1.loss_mask: 0.6956  decode.d1.loss_dice: 1.6108  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.7080  decode.d2.loss_dice: 1.6044  decode.d3.loss_cls: 0.0775  decode.d3.loss_mask: 0.6838  decode.d3.loss_dice: 1.6012  decode.d4.loss_cls: 0.0661  decode.d4.loss_mask: 0.6968  decode.d4.loss_dice: 1.6418  decode.d5.loss_cls: 0.0733  decode.d5.loss_mask: 0.6946  decode.d5.loss_dice: 1.6191  decode.d6.loss_cls: 0.0739  decode.d6.loss_mask: 0.7011  decode.d6.loss_dice: 1.6019  decode.d7.loss_cls: 0.0650  decode.d7.loss_mask: 0.6869  decode.d7.loss_dice: 1.6337  decode.d8.loss_cls: 0.0714  decode.d8.loss_mask: 0.6851  decode.d8.loss_dice: 1.6245
11/15 07:28:41 - mmengine - INFO - Iter(train) [ 4200/90000]  base_lr: 9.5791e-05 lr: 9.5791e-06  eta: 14:44:57  time: 0.5916  data_time: 0.0098  memory: 10642  grad_norm: 398.1381  loss: 23.4915  decode.loss_cls: 0.1154  decode.loss_mask: 0.7524  decode.loss_dice: 1.4596  decode.d0.loss_cls: 0.2470  decode.d0.loss_mask: 0.8119  decode.d0.loss_dice: 1.5621  decode.d1.loss_cls: 0.1035  decode.d1.loss_mask: 0.7687  decode.d1.loss_dice: 1.4746  decode.d2.loss_cls: 0.0965  decode.d2.loss_mask: 0.7760  decode.d2.loss_dice: 1.4583  decode.d3.loss_cls: 0.1068  decode.d3.loss_mask: 0.7579  decode.d3.loss_dice: 1.4090  decode.d4.loss_cls: 0.1397  decode.d4.loss_mask: 0.7261  decode.d4.loss_dice: 1.4115  decode.d5.loss_cls: 0.1042  decode.d5.loss_mask: 0.7410  decode.d5.loss_dice: 1.4645  decode.d6.loss_cls: 0.1140  decode.d6.loss_mask: 0.7356  decode.d6.loss_dice: 1.4738  decode.d7.loss_cls: 0.1149  decode.d7.loss_mask: 0.7676  decode.d7.loss_dice: 1.4834  decode.d8.loss_cls: 0.1124  decode.d8.loss_mask: 0.7684  decode.d8.loss_dice: 1.4346
11/15 07:29:10 - mmengine - INFO - Iter(train) [ 4250/90000]  base_lr: 9.5741e-05 lr: 9.5741e-06  eta: 14:44:00  time: 0.5925  data_time: 0.0099  memory: 10710  grad_norm: 449.7335  loss: 23.6371  decode.loss_cls: 0.0933  decode.loss_mask: 0.7446  decode.loss_dice: 1.4773  decode.d0.loss_cls: 0.2290  decode.d0.loss_mask: 0.7607  decode.d0.loss_dice: 1.6196  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.7193  decode.d1.loss_dice: 1.5701  decode.d2.loss_cls: 0.0807  decode.d2.loss_mask: 0.7200  decode.d2.loss_dice: 1.5290  decode.d3.loss_cls: 0.0752  decode.d3.loss_mask: 0.7390  decode.d3.loss_dice: 1.5214  decode.d4.loss_cls: 0.0766  decode.d4.loss_mask: 0.7307  decode.d4.loss_dice: 1.5372  decode.d5.loss_cls: 0.0803  decode.d5.loss_mask: 0.7178  decode.d5.loss_dice: 1.5091  decode.d6.loss_cls: 0.0780  decode.d6.loss_mask: 0.7375  decode.d6.loss_dice: 1.5090  decode.d7.loss_cls: 0.0944  decode.d7.loss_mask: 0.7438  decode.d7.loss_dice: 1.5265  decode.d8.loss_cls: 0.1024  decode.d8.loss_mask: 0.7386  decode.d8.loss_dice: 1.4939
11/15 07:29:40 - mmengine - INFO - Iter(train) [ 4300/90000]  base_lr: 9.5691e-05 lr: 9.5691e-06  eta: 14:43:03  time: 0.5906  data_time: 0.0093  memory: 10693  grad_norm: 915.2593  loss: 25.4965  decode.loss_cls: 0.1364  decode.loss_mask: 0.9240  decode.loss_dice: 1.4938  decode.d0.loss_cls: 0.2437  decode.d0.loss_mask: 0.9662  decode.d0.loss_dice: 1.5587  decode.d1.loss_cls: 0.1120  decode.d1.loss_mask: 0.9343  decode.d1.loss_dice: 1.4779  decode.d2.loss_cls: 0.1069  decode.d2.loss_mask: 0.9285  decode.d2.loss_dice: 1.4579  decode.d3.loss_cls: 0.1089  decode.d3.loss_mask: 0.9885  decode.d3.loss_dice: 1.4777  decode.d4.loss_cls: 0.1287  decode.d4.loss_mask: 0.9256  decode.d4.loss_dice: 1.4596  decode.d5.loss_cls: 0.1173  decode.d5.loss_mask: 0.9377  decode.d5.loss_dice: 1.4434  decode.d6.loss_cls: 0.1189  decode.d6.loss_mask: 0.9295  decode.d6.loss_dice: 1.4616  decode.d7.loss_cls: 0.1367  decode.d7.loss_mask: 0.9203  decode.d7.loss_dice: 1.4475  decode.d8.loss_cls: 0.1289  decode.d8.loss_mask: 0.9350  decode.d8.loss_dice: 1.4904
11/15 07:30:09 - mmengine - INFO - Iter(train) [ 4350/90000]  base_lr: 9.5640e-05 lr: 9.5640e-06  eta: 14:42:05  time: 0.5914  data_time: 0.0096  memory: 10673  grad_norm: 510.0180  loss: 24.8928  decode.loss_cls: 0.1272  decode.loss_mask: 0.7418  decode.loss_dice: 1.6035  decode.d0.loss_cls: 0.2410  decode.d0.loss_mask: 0.7998  decode.d0.loss_dice: 1.7091  decode.d1.loss_cls: 0.1180  decode.d1.loss_mask: 0.7365  decode.d1.loss_dice: 1.6463  decode.d2.loss_cls: 0.1241  decode.d2.loss_mask: 0.7245  decode.d2.loss_dice: 1.6043  decode.d3.loss_cls: 0.1211  decode.d3.loss_mask: 0.7188  decode.d3.loss_dice: 1.5882  decode.d4.loss_cls: 0.1262  decode.d4.loss_mask: 0.7050  decode.d4.loss_dice: 1.6122  decode.d5.loss_cls: 0.1217  decode.d5.loss_mask: 0.7325  decode.d5.loss_dice: 1.6090  decode.d6.loss_cls: 0.1350  decode.d6.loss_mask: 0.7311  decode.d6.loss_dice: 1.5736  decode.d7.loss_cls: 0.1278  decode.d7.loss_mask: 0.7421  decode.d7.loss_dice: 1.6181  decode.d8.loss_cls: 0.1250  decode.d8.loss_mask: 0.7212  decode.d8.loss_dice: 1.6080
11/15 07:30:39 - mmengine - INFO - Iter(train) [ 4400/90000]  base_lr: 9.5590e-05 lr: 9.5590e-06  eta: 14:41:09  time: 0.5915  data_time: 0.0096  memory: 10656  grad_norm: 347.7489  loss: 24.8257  decode.loss_cls: 0.0993  decode.loss_mask: 0.7763  decode.loss_dice: 1.5923  decode.d0.loss_cls: 0.2171  decode.d0.loss_mask: 0.7503  decode.d0.loss_dice: 1.6583  decode.d1.loss_cls: 0.0902  decode.d1.loss_mask: 0.7664  decode.d1.loss_dice: 1.6445  decode.d2.loss_cls: 0.0848  decode.d2.loss_mask: 0.7657  decode.d2.loss_dice: 1.5850  decode.d3.loss_cls: 0.1052  decode.d3.loss_mask: 0.7581  decode.d3.loss_dice: 1.5867  decode.d4.loss_cls: 0.1000  decode.d4.loss_mask: 0.7762  decode.d4.loss_dice: 1.6127  decode.d5.loss_cls: 0.0985  decode.d5.loss_mask: 0.7699  decode.d5.loss_dice: 1.6027  decode.d6.loss_cls: 0.0964  decode.d6.loss_mask: 0.7732  decode.d6.loss_dice: 1.5977  decode.d7.loss_cls: 0.1141  decode.d7.loss_mask: 0.7653  decode.d7.loss_dice: 1.5805  decode.d8.loss_cls: 0.1038  decode.d8.loss_mask: 0.7777  decode.d8.loss_dice: 1.5771
11/15 07:31:09 - mmengine - INFO - Iter(train) [ 4450/90000]  base_lr: 9.5540e-05 lr: 9.5540e-06  eta: 14:40:14  time: 0.5927  data_time: 0.0097  memory: 10693  grad_norm: 504.7686  loss: 26.3100  decode.loss_cls: 0.1221  decode.loss_mask: 0.7942  decode.loss_dice: 1.6920  decode.d0.loss_cls: 0.2183  decode.d0.loss_mask: 0.8049  decode.d0.loss_dice: 1.7697  decode.d1.loss_cls: 0.1094  decode.d1.loss_mask: 0.7982  decode.d1.loss_dice: 1.7229  decode.d2.loss_cls: 0.1235  decode.d2.loss_mask: 0.7964  decode.d2.loss_dice: 1.7072  decode.d3.loss_cls: 0.1038  decode.d3.loss_mask: 0.8067  decode.d3.loss_dice: 1.6877  decode.d4.loss_cls: 0.1088  decode.d4.loss_mask: 0.7996  decode.d4.loss_dice: 1.6851  decode.d5.loss_cls: 0.1025  decode.d5.loss_mask: 0.8061  decode.d5.loss_dice: 1.7115  decode.d6.loss_cls: 0.1002  decode.d6.loss_mask: 0.8156  decode.d6.loss_dice: 1.6817  decode.d7.loss_cls: 0.1058  decode.d7.loss_mask: 0.8325  decode.d7.loss_dice: 1.6892  decode.d8.loss_cls: 0.1001  decode.d8.loss_mask: 0.8170  decode.d8.loss_dice: 1.6973
11/15 07:31:38 - mmengine - INFO - Iter(train) [ 4500/90000]  base_lr: 9.5489e-05 lr: 9.5489e-06  eta: 14:39:20  time: 0.5935  data_time: 0.0096  memory: 10710  grad_norm: 533.5876  loss: 27.0318  decode.loss_cls: 0.0963  decode.loss_mask: 0.8245  decode.loss_dice: 1.7732  decode.d0.loss_cls: 0.2274  decode.d0.loss_mask: 0.8053  decode.d0.loss_dice: 1.8244  decode.d1.loss_cls: 0.1014  decode.d1.loss_mask: 0.8139  decode.d1.loss_dice: 1.7752  decode.d2.loss_cls: 0.1085  decode.d2.loss_mask: 0.8053  decode.d2.loss_dice: 1.7380  decode.d3.loss_cls: 0.1003  decode.d3.loss_mask: 0.7947  decode.d3.loss_dice: 1.7638  decode.d4.loss_cls: 0.1051  decode.d4.loss_mask: 0.8250  decode.d4.loss_dice: 1.7698  decode.d5.loss_cls: 0.1018  decode.d5.loss_mask: 0.8306  decode.d5.loss_dice: 1.7592  decode.d6.loss_cls: 0.1030  decode.d6.loss_mask: 0.8238  decode.d6.loss_dice: 1.7545  decode.d7.loss_cls: 0.0891  decode.d7.loss_mask: 0.8272  decode.d7.loss_dice: 1.7930  decode.d8.loss_cls: 0.0877  decode.d8.loss_mask: 0.8185  decode.d8.loss_dice: 1.7909
11/15 07:32:09 - mmengine - INFO - Iter(train) [ 4550/90000]  base_lr: 9.5439e-05 lr: 9.5439e-06  eta: 14:38:37  time: 0.5943  data_time: 0.0093  memory: 10656  grad_norm: 1082.0360  loss: 24.5803  decode.loss_cls: 0.0771  decode.loss_mask: 0.8657  decode.loss_dice: 1.5267  decode.d0.loss_cls: 0.2057  decode.d0.loss_mask: 0.8960  decode.d0.loss_dice: 1.5870  decode.d1.loss_cls: 0.0746  decode.d1.loss_mask: 0.8370  decode.d1.loss_dice: 1.5058  decode.d2.loss_cls: 0.0616  decode.d2.loss_mask: 0.8941  decode.d2.loss_dice: 1.5083  decode.d3.loss_cls: 0.0829  decode.d3.loss_mask: 0.8373  decode.d3.loss_dice: 1.4820  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.8865  decode.d4.loss_dice: 1.4976  decode.d5.loss_cls: 0.0926  decode.d5.loss_mask: 0.8511  decode.d5.loss_dice: 1.4732  decode.d6.loss_cls: 0.0735  decode.d6.loss_mask: 0.8583  decode.d6.loss_dice: 1.4966  decode.d7.loss_cls: 0.0778  decode.d7.loss_mask: 0.8564  decode.d7.loss_dice: 1.4999  decode.d8.loss_cls: 0.0775  decode.d8.loss_mask: 0.8435  decode.d8.loss_dice: 1.4851
11/15 07:32:38 - mmengine - INFO - Iter(train) [ 4600/90000]  base_lr: 9.5389e-05 lr: 9.5389e-06  eta: 14:37:46  time: 0.5934  data_time: 0.0099  memory: 10673  grad_norm: 480.5193  loss: 23.3418  decode.loss_cls: 0.0837  decode.loss_mask: 0.7553  decode.loss_dice: 1.4902  decode.d0.loss_cls: 0.2137  decode.d0.loss_mask: 0.7768  decode.d0.loss_dice: 1.5261  decode.d1.loss_cls: 0.0868  decode.d1.loss_mask: 0.7789  decode.d1.loss_dice: 1.4823  decode.d2.loss_cls: 0.0936  decode.d2.loss_mask: 0.7319  decode.d2.loss_dice: 1.4829  decode.d3.loss_cls: 0.0870  decode.d3.loss_mask: 0.7399  decode.d3.loss_dice: 1.4845  decode.d4.loss_cls: 0.0859  decode.d4.loss_mask: 0.7194  decode.d4.loss_dice: 1.4771  decode.d5.loss_cls: 0.0948  decode.d5.loss_mask: 0.7233  decode.d5.loss_dice: 1.4685  decode.d6.loss_cls: 0.0916  decode.d6.loss_mask: 0.7122  decode.d6.loss_dice: 1.5019  decode.d7.loss_cls: 0.1019  decode.d7.loss_mask: 0.7212  decode.d7.loss_dice: 1.4952  decode.d8.loss_cls: 0.0911  decode.d8.loss_mask: 0.7497  decode.d8.loss_dice: 1.4943
11/15 07:33:08 - mmengine - INFO - Iter(train) [ 4650/90000]  base_lr: 9.5339e-05 lr: 9.5339e-06  eta: 14:36:55  time: 0.5931  data_time: 0.0098  memory: 10710  grad_norm: 620.9455  loss: 22.8942  decode.loss_cls: 0.1207  decode.loss_mask: 0.7617  decode.loss_dice: 1.3588  decode.d0.loss_cls: 0.2163  decode.d0.loss_mask: 0.8298  decode.d0.loss_dice: 1.4866  decode.d1.loss_cls: 0.0946  decode.d1.loss_mask: 0.8158  decode.d1.loss_dice: 1.4560  decode.d2.loss_cls: 0.0940  decode.d2.loss_mask: 0.7599  decode.d2.loss_dice: 1.4154  decode.d3.loss_cls: 0.1100  decode.d3.loss_mask: 0.7467  decode.d3.loss_dice: 1.3908  decode.d4.loss_cls: 0.1114  decode.d4.loss_mask: 0.7438  decode.d4.loss_dice: 1.3895  decode.d5.loss_cls: 0.1238  decode.d5.loss_mask: 0.7611  decode.d5.loss_dice: 1.3710  decode.d6.loss_cls: 0.1074  decode.d6.loss_mask: 0.7682  decode.d6.loss_dice: 1.3878  decode.d7.loss_cls: 0.1202  decode.d7.loss_mask: 0.7564  decode.d7.loss_dice: 1.3636  decode.d8.loss_cls: 0.1136  decode.d8.loss_mask: 0.7597  decode.d8.loss_dice: 1.3595
11/15 07:33:38 - mmengine - INFO - Iter(train) [ 4700/90000]  base_lr: 9.5288e-05 lr: 9.5288e-06  eta: 14:36:02  time: 0.5934  data_time: 0.0097  memory: 10673  grad_norm: 304.0635  loss: 22.1774  decode.loss_cls: 0.1024  decode.loss_mask: 0.6604  decode.loss_dice: 1.4374  decode.d0.loss_cls: 0.1939  decode.d0.loss_mask: 0.6896  decode.d0.loss_dice: 1.5524  decode.d1.loss_cls: 0.0906  decode.d1.loss_mask: 0.6457  decode.d1.loss_dice: 1.4886  decode.d2.loss_cls: 0.0859  decode.d2.loss_mask: 0.6370  decode.d2.loss_dice: 1.4461  decode.d3.loss_cls: 0.0864  decode.d3.loss_mask: 0.6488  decode.d3.loss_dice: 1.4419  decode.d4.loss_cls: 0.0929  decode.d4.loss_mask: 0.6467  decode.d4.loss_dice: 1.4378  decode.d5.loss_cls: 0.0957  decode.d5.loss_mask: 0.6496  decode.d5.loss_dice: 1.4392  decode.d6.loss_cls: 0.0990  decode.d6.loss_mask: 0.6473  decode.d6.loss_dice: 1.4532  decode.d7.loss_cls: 0.1063  decode.d7.loss_mask: 0.6600  decode.d7.loss_dice: 1.4189  decode.d8.loss_cls: 0.1039  decode.d8.loss_mask: 0.6610  decode.d8.loss_dice: 1.4585
11/15 07:34:07 - mmengine - INFO - Iter(train) [ 4750/90000]  base_lr: 9.5238e-05 lr: 9.5238e-06  eta: 14:35:10  time: 0.5915  data_time: 0.0096  memory: 10673  grad_norm: 376.5261  loss: 23.6216  decode.loss_cls: 0.0991  decode.loss_mask: 0.7476  decode.loss_dice: 1.4780  decode.d0.loss_cls: 0.1963  decode.d0.loss_mask: 0.7702  decode.d0.loss_dice: 1.5681  decode.d1.loss_cls: 0.0830  decode.d1.loss_mask: 0.7668  decode.d1.loss_dice: 1.5204  decode.d2.loss_cls: 0.0801  decode.d2.loss_mask: 0.7550  decode.d2.loss_dice: 1.4940  decode.d3.loss_cls: 0.0930  decode.d3.loss_mask: 0.7383  decode.d3.loss_dice: 1.4609  decode.d4.loss_cls: 0.0968  decode.d4.loss_mask: 0.7553  decode.d4.loss_dice: 1.5167  decode.d5.loss_cls: 0.0901  decode.d5.loss_mask: 0.7474  decode.d5.loss_dice: 1.4919  decode.d6.loss_cls: 0.0913  decode.d6.loss_mask: 0.7620  decode.d6.loss_dice: 1.4754  decode.d7.loss_cls: 0.0794  decode.d7.loss_mask: 0.7792  decode.d7.loss_dice: 1.5019  decode.d8.loss_cls: 0.0919  decode.d8.loss_mask: 0.8045  decode.d8.loss_dice: 1.4870
11/15 07:34:37 - mmengine - INFO - Iter(train) [ 4800/90000]  base_lr: 9.5188e-05 lr: 9.5188e-06  eta: 14:34:19  time: 0.5935  data_time: 0.0096  memory: 10693  grad_norm: 599.8730  loss: 25.8852  decode.loss_cls: 0.1067  decode.loss_mask: 0.7707  decode.loss_dice: 1.6780  decode.d0.loss_cls: 0.1982  decode.d0.loss_mask: 0.8472  decode.d0.loss_dice: 1.6914  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.8149  decode.d1.loss_dice: 1.7210  decode.d2.loss_cls: 0.0792  decode.d2.loss_mask: 0.8074  decode.d2.loss_dice: 1.6832  decode.d3.loss_cls: 0.0828  decode.d3.loss_mask: 0.7870  decode.d3.loss_dice: 1.6946  decode.d4.loss_cls: 0.0911  decode.d4.loss_mask: 0.7818  decode.d4.loss_dice: 1.6529  decode.d5.loss_cls: 0.1012  decode.d5.loss_mask: 0.7756  decode.d5.loss_dice: 1.6646  decode.d6.loss_cls: 0.0932  decode.d6.loss_mask: 0.8037  decode.d6.loss_dice: 1.6826  decode.d7.loss_cls: 0.0923  decode.d7.loss_mask: 0.8115  decode.d7.loss_dice: 1.7090  decode.d8.loss_cls: 0.1036  decode.d8.loss_mask: 0.8151  decode.d8.loss_dice: 1.6659
11/15 07:35:07 - mmengine - INFO - Iter(train) [ 4850/90000]  base_lr: 9.5138e-05 lr: 9.5138e-06  eta: 14:33:28  time: 0.5938  data_time: 0.0097  memory: 10673  grad_norm: 306.3160  loss: 23.5489  decode.loss_cls: 0.1117  decode.loss_mask: 0.7377  decode.loss_dice: 1.4646  decode.d0.loss_cls: 0.1790  decode.d0.loss_mask: 0.7629  decode.d0.loss_dice: 1.5747  decode.d1.loss_cls: 0.0900  decode.d1.loss_mask: 0.7296  decode.d1.loss_dice: 1.5144  decode.d2.loss_cls: 0.1033  decode.d2.loss_mask: 0.7473  decode.d2.loss_dice: 1.4941  decode.d3.loss_cls: 0.1028  decode.d3.loss_mask: 0.7484  decode.d3.loss_dice: 1.4940  decode.d4.loss_cls: 0.1076  decode.d4.loss_mask: 0.7475  decode.d4.loss_dice: 1.5194  decode.d5.loss_cls: 0.1178  decode.d5.loss_mask: 0.7423  decode.d5.loss_dice: 1.4831  decode.d6.loss_cls: 0.1074  decode.d6.loss_mask: 0.7378  decode.d6.loss_dice: 1.4930  decode.d7.loss_cls: 0.1063  decode.d7.loss_mask: 0.7479  decode.d7.loss_dice: 1.4678  decode.d8.loss_cls: 0.1116  decode.d8.loss_mask: 0.7534  decode.d8.loss_dice: 1.4515
11/15 07:35:36 - mmengine - INFO - Iter(train) [ 4900/90000]  base_lr: 9.5087e-05 lr: 9.5087e-06  eta: 14:32:38  time: 0.5927  data_time: 0.0099  memory: 10673  grad_norm: 307.4097  loss: 24.9700  decode.loss_cls: 0.0892  decode.loss_mask: 0.7257  decode.loss_dice: 1.6445  decode.d0.loss_cls: 0.1904  decode.d0.loss_mask: 0.7106  decode.d0.loss_dice: 1.7455  decode.d1.loss_cls: 0.0850  decode.d1.loss_mask: 0.6961  decode.d1.loss_dice: 1.6534  decode.d2.loss_cls: 0.0757  decode.d2.loss_mask: 0.7252  decode.d2.loss_dice: 1.7000  decode.d3.loss_cls: 0.0723  decode.d3.loss_mask: 0.7341  decode.d3.loss_dice: 1.6565  decode.d4.loss_cls: 0.0786  decode.d4.loss_mask: 0.7358  decode.d4.loss_dice: 1.6892  decode.d5.loss_cls: 0.0918  decode.d5.loss_mask: 0.7228  decode.d5.loss_dice: 1.6799  decode.d6.loss_cls: 0.1117  decode.d6.loss_mask: 0.7262  decode.d6.loss_dice: 1.6560  decode.d7.loss_cls: 0.1089  decode.d7.loss_mask: 0.7218  decode.d7.loss_dice: 1.6670  decode.d8.loss_cls: 0.1074  decode.d8.loss_mask: 0.7128  decode.d8.loss_dice: 1.6560
11/15 07:36:06 - mmengine - INFO - Iter(train) [ 4950/90000]  base_lr: 9.5037e-05 lr: 9.5037e-06  eta: 14:31:48  time: 0.5922  data_time: 0.0100  memory: 10673  grad_norm: 357.9797  loss: 25.7863  decode.loss_cls: 0.0886  decode.loss_mask: 0.8019  decode.loss_dice: 1.6611  decode.d0.loss_cls: 0.1825  decode.d0.loss_mask: 0.8455  decode.d0.loss_dice: 1.7403  decode.d1.loss_cls: 0.0878  decode.d1.loss_mask: 0.8172  decode.d1.loss_dice: 1.6783  decode.d2.loss_cls: 0.0893  decode.d2.loss_mask: 0.8111  decode.d2.loss_dice: 1.6283  decode.d3.loss_cls: 0.0821  decode.d3.loss_mask: 0.8043  decode.d3.loss_dice: 1.6901  decode.d4.loss_cls: 0.1053  decode.d4.loss_mask: 0.8037  decode.d4.loss_dice: 1.6665  decode.d5.loss_cls: 0.0997  decode.d5.loss_mask: 0.8056  decode.d5.loss_dice: 1.6282  decode.d6.loss_cls: 0.0835  decode.d6.loss_mask: 0.8032  decode.d6.loss_dice: 1.6697  decode.d7.loss_cls: 0.0839  decode.d7.loss_mask: 0.8087  decode.d7.loss_dice: 1.6681  decode.d8.loss_cls: 0.1073  decode.d8.loss_mask: 0.8047  decode.d8.loss_dice: 1.6399
11/15 07:36:35 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 07:36:35 - mmengine - INFO - Iter(train) [ 5000/90000]  base_lr: 9.4987e-05 lr: 9.4987e-06  eta: 14:30:57  time: 0.5909  data_time: 0.0095  memory: 10673  grad_norm: 681.3334  loss: 24.4185  decode.loss_cls: 0.0927  decode.loss_mask: 0.8938  decode.loss_dice: 1.4231  decode.d0.loss_cls: 0.1951  decode.d0.loss_mask: 0.9388  decode.d0.loss_dice: 1.5106  decode.d1.loss_cls: 0.0912  decode.d1.loss_mask: 0.8858  decode.d1.loss_dice: 1.4795  decode.d2.loss_cls: 0.0685  decode.d2.loss_mask: 0.8898  decode.d2.loss_dice: 1.4579  decode.d3.loss_cls: 0.0797  decode.d3.loss_mask: 0.8874  decode.d3.loss_dice: 1.4189  decode.d4.loss_cls: 0.0700  decode.d4.loss_mask: 0.8988  decode.d4.loss_dice: 1.4491  decode.d5.loss_cls: 0.0797  decode.d5.loss_mask: 0.9280  decode.d5.loss_dice: 1.4463  decode.d6.loss_cls: 0.0938  decode.d6.loss_mask: 0.8679  decode.d6.loss_dice: 1.4280  decode.d7.loss_cls: 0.0874  decode.d7.loss_mask: 0.9098  decode.d7.loss_dice: 1.4569  decode.d8.loss_cls: 0.1062  decode.d8.loss_mask: 0.8520  decode.d8.loss_dice: 1.4318
11/15 07:36:35 - mmengine - INFO - Saving checkpoint at 5000 iterations
11/15 07:37:01 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:03:17  time: 0.3078  data_time: 0.0040  memory: 11696  
11/15 07:37:16 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:29  time: 0.3074  data_time: 0.0038  memory: 4095  
11/15 07:37:32 - mmengine - INFO - Iter(val) [150/500]    eta: 0:02:03  time: 0.3085  data_time: 0.0040  memory: 4095  
11/15 07:37:47 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:42  time: 0.3085  data_time: 0.0041  memory: 4095  
11/15 07:38:02 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:23  time: 0.3090  data_time: 0.0041  memory: 4095  
11/15 07:38:18 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:06  time: 0.3084  data_time: 0.0041  memory: 4095  
11/15 07:38:33 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:49  time: 0.3087  data_time: 0.0039  memory: 4095  
11/15 07:38:49 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:32  time: 0.3085  data_time: 0.0040  memory: 4095  
11/15 07:39:04 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:16  time: 0.3085  data_time: 0.0039  memory: 4095  
11/15 07:39:20 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3089  data_time: 0.0036  memory: 4095  
11/15 07:39:20 - mmengine - INFO - per class results:
11/15 07:39:20 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 96.43 | 97.19 |
|    sidewalk   | 75.47 | 93.09 |
|    building   |  89.8 | 93.22 |
|      wall     | 37.24 |  59.2 |
|     fence     | 40.86 | 73.89 |
|      pole     | 54.93 |  68.0 |
| traffic light | 56.35 |  79.0 |
|  traffic sign | 71.49 | 77.44 |
|   vegetation  | 89.56 | 94.95 |
|    terrain    | 51.23 | 71.63 |
|      sky      | 88.63 | 91.35 |
|     person    | 76.91 | 88.02 |
|     rider     | 47.24 |  72.1 |
|      car      | 91.22 | 97.25 |
|     truck     |  1.13 |  1.16 |
|      bus      | 37.06 | 71.08 |
|     train     |  0.0  |  0.0  |
|   motorcycle  | 31.74 | 58.54 |
|    bicycle    | 66.26 |  70.5 |
+---------------+-------+-------+
11/15 07:39:20 - mmengine - INFO - Iter(val) [500/500]    aAcc: 93.3400  mIoU: 58.0800  mAcc: 71.4500  data_time: 0.0149  time: 0.3216
11/15 07:39:22 - mmengine - INFO - The best checkpoint with 58.0800 mIoU at 5000 iter is saved to best_mIoU_iter_5000.pth.
11/15 07:39:55 - mmengine - INFO - Iter(train) [ 5050/90000]  base_lr: 9.4936e-05 lr: 9.4936e-06  eta: 14:31:37  time: 0.5937  data_time: 0.0099  memory: 10656  grad_norm: 617.7912  loss: 24.9329  decode.loss_cls: 0.0949  decode.loss_mask: 0.7848  decode.loss_dice: 1.6334  decode.d0.loss_cls: 0.1663  decode.d0.loss_mask: 0.7685  decode.d0.loss_dice: 1.6859  decode.d1.loss_cls: 0.0755  decode.d1.loss_mask: 0.7601  decode.d1.loss_dice: 1.6573  decode.d2.loss_cls: 0.0974  decode.d2.loss_mask: 0.7673  decode.d2.loss_dice: 1.6078  decode.d3.loss_cls: 0.0989  decode.d3.loss_mask: 0.7434  decode.d3.loss_dice: 1.6162  decode.d4.loss_cls: 0.0971  decode.d4.loss_mask: 0.7394  decode.d4.loss_dice: 1.6165  decode.d5.loss_cls: 0.1007  decode.d5.loss_mask: 0.7719  decode.d5.loss_dice: 1.6269  decode.d6.loss_cls: 0.1005  decode.d6.loss_mask: 0.7795  decode.d6.loss_dice: 1.6140  decode.d7.loss_cls: 0.0893  decode.d7.loss_mask: 0.7766  decode.d7.loss_dice: 1.6194  decode.d8.loss_cls: 0.0969  decode.d8.loss_mask: 0.7526  decode.d8.loss_dice: 1.5938
11/15 07:40:24 - mmengine - INFO - Iter(train) [ 5100/90000]  base_lr: 9.4886e-05 lr: 9.4886e-06  eta: 14:30:48  time: 0.5932  data_time: 0.0098  memory: 10656  grad_norm: 273.6741  loss: 21.7202  decode.loss_cls: 0.0765  decode.loss_mask: 0.6125  decode.loss_dice: 1.4599  decode.d0.loss_cls: 0.1665  decode.d0.loss_mask: 0.6279  decode.d0.loss_dice: 1.5397  decode.d1.loss_cls: 0.0650  decode.d1.loss_mask: 0.6034  decode.d1.loss_dice: 1.5227  decode.d2.loss_cls: 0.0586  decode.d2.loss_mask: 0.6175  decode.d2.loss_dice: 1.4620  decode.d3.loss_cls: 0.0757  decode.d3.loss_mask: 0.6289  decode.d3.loss_dice: 1.4476  decode.d4.loss_cls: 0.0776  decode.d4.loss_mask: 0.6240  decode.d4.loss_dice: 1.4609  decode.d5.loss_cls: 0.0767  decode.d5.loss_mask: 0.6232  decode.d5.loss_dice: 1.4384  decode.d6.loss_cls: 0.0834  decode.d6.loss_mask: 0.6127  decode.d6.loss_dice: 1.4235  decode.d7.loss_cls: 0.0905  decode.d7.loss_mask: 0.6246  decode.d7.loss_dice: 1.4456  decode.d8.loss_cls: 0.0767  decode.d8.loss_mask: 0.6191  decode.d8.loss_dice: 1.4790
11/15 07:40:54 - mmengine - INFO - Iter(train) [ 5150/90000]  base_lr: 9.4836e-05 lr: 9.4836e-06  eta: 14:30:00  time: 0.5937  data_time: 0.0100  memory: 10713  grad_norm: 456.3834  loss: 23.6358  decode.loss_cls: 0.1246  decode.loss_mask: 0.7677  decode.loss_dice: 1.4666  decode.d0.loss_cls: 0.1950  decode.d0.loss_mask: 0.7592  decode.d0.loss_dice: 1.5054  decode.d1.loss_cls: 0.1208  decode.d1.loss_mask: 0.7424  decode.d1.loss_dice: 1.4515  decode.d2.loss_cls: 0.1097  decode.d2.loss_mask: 0.7641  decode.d2.loss_dice: 1.4497  decode.d3.loss_cls: 0.1281  decode.d3.loss_mask: 0.7707  decode.d3.loss_dice: 1.4245  decode.d4.loss_cls: 0.1354  decode.d4.loss_mask: 0.7742  decode.d4.loss_dice: 1.4471  decode.d5.loss_cls: 0.1182  decode.d5.loss_mask: 0.7983  decode.d5.loss_dice: 1.4606  decode.d6.loss_cls: 0.1149  decode.d6.loss_mask: 0.7970  decode.d6.loss_dice: 1.4632  decode.d7.loss_cls: 0.1090  decode.d7.loss_mask: 0.7828  decode.d7.loss_dice: 1.4717  decode.d8.loss_cls: 0.1133  decode.d8.loss_mask: 0.7860  decode.d8.loss_dice: 1.4843
11/15 07:41:24 - mmengine - INFO - Iter(train) [ 5200/90000]  base_lr: 9.4786e-05 lr: 9.4786e-06  eta: 14:29:11  time: 0.5933  data_time: 0.0097  memory: 10692  grad_norm: 531.0052  loss: 26.3067  decode.loss_cls: 0.1202  decode.loss_mask: 0.7860  decode.loss_dice: 1.7217  decode.d0.loss_cls: 0.1809  decode.d0.loss_mask: 0.7912  decode.d0.loss_dice: 1.7743  decode.d1.loss_cls: 0.1075  decode.d1.loss_mask: 0.7774  decode.d1.loss_dice: 1.7329  decode.d2.loss_cls: 0.1024  decode.d2.loss_mask: 0.7888  decode.d2.loss_dice: 1.7362  decode.d3.loss_cls: 0.0988  decode.d3.loss_mask: 0.7878  decode.d3.loss_dice: 1.7299  decode.d4.loss_cls: 0.1099  decode.d4.loss_mask: 0.7787  decode.d4.loss_dice: 1.7285  decode.d5.loss_cls: 0.1082  decode.d5.loss_mask: 0.7883  decode.d5.loss_dice: 1.7150  decode.d6.loss_cls: 0.1044  decode.d6.loss_mask: 0.7877  decode.d6.loss_dice: 1.7104  decode.d7.loss_cls: 0.0912  decode.d7.loss_mask: 0.8122  decode.d7.loss_dice: 1.7388  decode.d8.loss_cls: 0.1185  decode.d8.loss_mask: 0.7918  decode.d8.loss_dice: 1.6871
11/15 07:41:53 - mmengine - INFO - Iter(train) [ 5250/90000]  base_lr: 9.4735e-05 lr: 9.4735e-06  eta: 14:28:23  time: 0.5934  data_time: 0.0098  memory: 10692  grad_norm: 574.6940  loss: 24.1238  decode.loss_cls: 0.0951  decode.loss_mask: 0.6997  decode.loss_dice: 1.5949  decode.d0.loss_cls: 0.1773  decode.d0.loss_mask: 0.6771  decode.d0.loss_dice: 1.6811  decode.d1.loss_cls: 0.0960  decode.d1.loss_mask: 0.6903  decode.d1.loss_dice: 1.6087  decode.d2.loss_cls: 0.1018  decode.d2.loss_mask: 0.6839  decode.d2.loss_dice: 1.6077  decode.d3.loss_cls: 0.1020  decode.d3.loss_mask: 0.6980  decode.d3.loss_dice: 1.6035  decode.d4.loss_cls: 0.0985  decode.d4.loss_mask: 0.7103  decode.d4.loss_dice: 1.5973  decode.d5.loss_cls: 0.0967  decode.d5.loss_mask: 0.7058  decode.d5.loss_dice: 1.6002  decode.d6.loss_cls: 0.0986  decode.d6.loss_mask: 0.7020  decode.d6.loss_dice: 1.6237  decode.d7.loss_cls: 0.0851  decode.d7.loss_mask: 0.6944  decode.d7.loss_dice: 1.6101  decode.d8.loss_cls: 0.0896  decode.d8.loss_mask: 0.7138  decode.d8.loss_dice: 1.5804
11/15 07:42:23 - mmengine - INFO - Iter(train) [ 5300/90000]  base_lr: 9.4685e-05 lr: 9.4685e-06  eta: 14:27:36  time: 0.5981  data_time: 0.0101  memory: 10656  grad_norm: 429.5298  loss: 26.3989  decode.loss_cls: 0.1310  decode.loss_mask: 0.7694  decode.loss_dice: 1.7187  decode.d0.loss_cls: 0.1759  decode.d0.loss_mask: 0.7804  decode.d0.loss_dice: 1.8189  decode.d1.loss_cls: 0.0921  decode.d1.loss_mask: 0.7835  decode.d1.loss_dice: 1.7586  decode.d2.loss_cls: 0.1052  decode.d2.loss_mask: 0.7912  decode.d2.loss_dice: 1.6960  decode.d3.loss_cls: 0.1059  decode.d3.loss_mask: 0.7984  decode.d3.loss_dice: 1.7363  decode.d4.loss_cls: 0.1103  decode.d4.loss_mask: 0.7906  decode.d4.loss_dice: 1.7253  decode.d5.loss_cls: 0.1036  decode.d5.loss_mask: 0.8104  decode.d5.loss_dice: 1.7493  decode.d6.loss_cls: 0.1083  decode.d6.loss_mask: 0.7727  decode.d6.loss_dice: 1.6813  decode.d7.loss_cls: 0.1114  decode.d7.loss_mask: 0.7851  decode.d7.loss_dice: 1.7423  decode.d8.loss_cls: 0.1072  decode.d8.loss_mask: 0.7804  decode.d8.loss_dice: 1.7591
11/15 07:42:53 - mmengine - INFO - Iter(train) [ 5350/90000]  base_lr: 9.4635e-05 lr: 9.4635e-06  eta: 14:26:51  time: 0.5964  data_time: 0.0102  memory: 10656  grad_norm: 416.0045  loss: 25.3270  decode.loss_cls: 0.1298  decode.loss_mask: 0.8270  decode.loss_dice: 1.5393  decode.d0.loss_cls: 0.1605  decode.d0.loss_mask: 0.8713  decode.d0.loss_dice: 1.6148  decode.d1.loss_cls: 0.0900  decode.d1.loss_mask: 0.8315  decode.d1.loss_dice: 1.5856  decode.d2.loss_cls: 0.1010  decode.d2.loss_mask: 0.8681  decode.d2.loss_dice: 1.5723  decode.d3.loss_cls: 0.1183  decode.d3.loss_mask: 0.8338  decode.d3.loss_dice: 1.5158  decode.d4.loss_cls: 0.1353  decode.d4.loss_mask: 0.8410  decode.d4.loss_dice: 1.5596  decode.d5.loss_cls: 0.1361  decode.d5.loss_mask: 0.8476  decode.d5.loss_dice: 1.5468  decode.d6.loss_cls: 0.1340  decode.d6.loss_mask: 0.8660  decode.d6.loss_dice: 1.5404  decode.d7.loss_cls: 0.1152  decode.d7.loss_mask: 0.8774  decode.d7.loss_dice: 1.5706  decode.d8.loss_cls: 0.1386  decode.d8.loss_mask: 0.8368  decode.d8.loss_dice: 1.5225
11/15 07:43:23 - mmengine - INFO - Iter(train) [ 5400/90000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 14:26:06  time: 0.5944  data_time: 0.0097  memory: 10713  grad_norm: 850.5157  loss: 24.6025  decode.loss_cls: 0.1169  decode.loss_mask: 0.8428  decode.loss_dice: 1.5084  decode.d0.loss_cls: 0.1785  decode.d0.loss_mask: 0.8714  decode.d0.loss_dice: 1.5806  decode.d1.loss_cls: 0.0978  decode.d1.loss_mask: 0.8534  decode.d1.loss_dice: 1.5014  decode.d2.loss_cls: 0.1019  decode.d2.loss_mask: 0.8064  decode.d2.loss_dice: 1.5016  decode.d3.loss_cls: 0.1124  decode.d3.loss_mask: 0.8298  decode.d3.loss_dice: 1.4811  decode.d4.loss_cls: 0.0878  decode.d4.loss_mask: 0.8502  decode.d4.loss_dice: 1.5082  decode.d5.loss_cls: 0.1047  decode.d5.loss_mask: 0.8432  decode.d5.loss_dice: 1.4653  decode.d6.loss_cls: 0.1067  decode.d6.loss_mask: 0.8495  decode.d6.loss_dice: 1.4746  decode.d7.loss_cls: 0.1039  decode.d7.loss_mask: 0.8510  decode.d7.loss_dice: 1.5094  decode.d8.loss_cls: 0.1195  decode.d8.loss_mask: 0.8393  decode.d8.loss_dice: 1.5047
11/15 07:43:53 - mmengine - INFO - Iter(train) [ 5450/90000]  base_lr: 9.4534e-05 lr: 9.4534e-06  eta: 14:25:21  time: 0.5976  data_time: 0.0119  memory: 10675  grad_norm: 474.4433  loss: 25.4705  decode.loss_cls: 0.1096  decode.loss_mask: 0.9383  decode.loss_dice: 1.5285  decode.d0.loss_cls: 0.1664  decode.d0.loss_mask: 0.9521  decode.d0.loss_dice: 1.5959  decode.d1.loss_cls: 0.1138  decode.d1.loss_mask: 0.8951  decode.d1.loss_dice: 1.5301  decode.d2.loss_cls: 0.1203  decode.d2.loss_mask: 0.8880  decode.d2.loss_dice: 1.5061  decode.d3.loss_cls: 0.1030  decode.d3.loss_mask: 0.9041  decode.d3.loss_dice: 1.5015  decode.d4.loss_cls: 0.1192  decode.d4.loss_mask: 0.8978  decode.d4.loss_dice: 1.4701  decode.d5.loss_cls: 0.1248  decode.d5.loss_mask: 0.8966  decode.d5.loss_dice: 1.4760  decode.d6.loss_cls: 0.1034  decode.d6.loss_mask: 0.9408  decode.d6.loss_dice: 1.4989  decode.d7.loss_cls: 0.1106  decode.d7.loss_mask: 0.9204  decode.d7.loss_dice: 1.4921  decode.d8.loss_cls: 0.0998  decode.d8.loss_mask: 0.9471  decode.d8.loss_dice: 1.5201
11/15 07:44:22 - mmengine - INFO - Iter(train) [ 5500/90000]  base_lr: 9.4484e-05 lr: 9.4484e-06  eta: 14:24:36  time: 0.5947  data_time: 0.0099  memory: 10692  grad_norm: 398.3831  loss: 22.4668  decode.loss_cls: 0.1016  decode.loss_mask: 0.6627  decode.loss_dice: 1.4911  decode.d0.loss_cls: 0.1535  decode.d0.loss_mask: 0.6728  decode.d0.loss_dice: 1.5377  decode.d1.loss_cls: 0.1054  decode.d1.loss_mask: 0.6619  decode.d1.loss_dice: 1.4856  decode.d2.loss_cls: 0.1013  decode.d2.loss_mask: 0.6568  decode.d2.loss_dice: 1.4611  decode.d3.loss_cls: 0.1058  decode.d3.loss_mask: 0.6701  decode.d3.loss_dice: 1.4534  decode.d4.loss_cls: 0.1112  decode.d4.loss_mask: 0.6658  decode.d4.loss_dice: 1.4661  decode.d5.loss_cls: 0.1054  decode.d5.loss_mask: 0.6725  decode.d5.loss_dice: 1.4751  decode.d6.loss_cls: 0.1097  decode.d6.loss_mask: 0.6557  decode.d6.loss_dice: 1.4361  decode.d7.loss_cls: 0.1020  decode.d7.loss_mask: 0.6579  decode.d7.loss_dice: 1.4685  decode.d8.loss_cls: 0.0916  decode.d8.loss_mask: 0.6558  decode.d8.loss_dice: 1.4727
11/15 07:44:52 - mmengine - INFO - Iter(train) [ 5550/90000]  base_lr: 9.4433e-05 lr: 9.4433e-06  eta: 14:23:50  time: 0.5954  data_time: 0.0099  memory: 10692  grad_norm: 322.2900  loss: 22.8467  decode.loss_cls: 0.0873  decode.loss_mask: 0.6858  decode.loss_dice: 1.5072  decode.d0.loss_cls: 0.1654  decode.d0.loss_mask: 0.6802  decode.d0.loss_dice: 1.5305  decode.d1.loss_cls: 0.0589  decode.d1.loss_mask: 0.6876  decode.d1.loss_dice: 1.5379  decode.d2.loss_cls: 0.0737  decode.d2.loss_mask: 0.6790  decode.d2.loss_dice: 1.5292  decode.d3.loss_cls: 0.0682  decode.d3.loss_mask: 0.6769  decode.d3.loss_dice: 1.5454  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.6707  decode.d4.loss_dice: 1.4978  decode.d5.loss_cls: 0.0738  decode.d5.loss_mask: 0.6782  decode.d5.loss_dice: 1.5198  decode.d6.loss_cls: 0.0740  decode.d6.loss_mask: 0.6793  decode.d6.loss_dice: 1.5335  decode.d7.loss_cls: 0.0768  decode.d7.loss_mask: 0.6860  decode.d7.loss_dice: 1.5114  decode.d8.loss_cls: 0.0730  decode.d8.loss_mask: 0.6857  decode.d8.loss_dice: 1.4965
11/15 07:45:22 - mmengine - INFO - Iter(train) [ 5600/90000]  base_lr: 9.4383e-05 lr: 9.4383e-06  eta: 14:23:05  time: 0.5946  data_time: 0.0099  memory: 10675  grad_norm: 319.2855  loss: 21.1682  decode.loss_cls: 0.0961  decode.loss_mask: 0.6853  decode.loss_dice: 1.3188  decode.d0.loss_cls: 0.1586  decode.d0.loss_mask: 0.6831  decode.d0.loss_dice: 1.3686  decode.d1.loss_cls: 0.0792  decode.d1.loss_mask: 0.6677  decode.d1.loss_dice: 1.3256  decode.d2.loss_cls: 0.0750  decode.d2.loss_mask: 0.6899  decode.d2.loss_dice: 1.3210  decode.d3.loss_cls: 0.0897  decode.d3.loss_mask: 0.6888  decode.d3.loss_dice: 1.3045  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.7431  decode.d4.loss_dice: 1.3220  decode.d5.loss_cls: 0.0898  decode.d5.loss_mask: 0.7143  decode.d5.loss_dice: 1.3519  decode.d6.loss_cls: 0.0914  decode.d6.loss_mask: 0.7190  decode.d6.loss_dice: 1.3105  decode.d7.loss_cls: 0.0939  decode.d7.loss_mask: 0.7014  decode.d7.loss_dice: 1.2915  decode.d8.loss_cls: 0.0915  decode.d8.loss_mask: 0.7066  decode.d8.loss_dice: 1.3122
11/15 07:45:51 - mmengine - INFO - Iter(train) [ 5650/90000]  base_lr: 9.4333e-05 lr: 9.4333e-06  eta: 14:22:20  time: 0.5938  data_time: 0.0099  memory: 10692  grad_norm: 455.5741  loss: 24.2403  decode.loss_cls: 0.1160  decode.loss_mask: 0.7617  decode.loss_dice: 1.5635  decode.d0.loss_cls: 0.1489  decode.d0.loss_mask: 0.7182  decode.d0.loss_dice: 1.6673  decode.d1.loss_cls: 0.1198  decode.d1.loss_mask: 0.7237  decode.d1.loss_dice: 1.6291  decode.d2.loss_cls: 0.1097  decode.d2.loss_mask: 0.7386  decode.d2.loss_dice: 1.5994  decode.d3.loss_cls: 0.1262  decode.d3.loss_mask: 0.7439  decode.d3.loss_dice: 1.5496  decode.d4.loss_cls: 0.1443  decode.d4.loss_mask: 0.7187  decode.d4.loss_dice: 1.5540  decode.d5.loss_cls: 0.1204  decode.d5.loss_mask: 0.7020  decode.d5.loss_dice: 1.5605  decode.d6.loss_cls: 0.1027  decode.d6.loss_mask: 0.7137  decode.d6.loss_dice: 1.5548  decode.d7.loss_cls: 0.1297  decode.d7.loss_mask: 0.6978  decode.d7.loss_dice: 1.5549  decode.d8.loss_cls: 0.1272  decode.d8.loss_mask: 0.6870  decode.d8.loss_dice: 1.5572
11/15 07:46:21 - mmengine - INFO - Iter(train) [ 5700/90000]  base_lr: 9.4282e-05 lr: 9.4282e-06  eta: 14:21:37  time: 0.6088  data_time: 0.0099  memory: 10692  grad_norm: 336.0810  loss: 22.6788  decode.loss_cls: 0.1068  decode.loss_mask: 0.6462  decode.loss_dice: 1.5199  decode.d0.loss_cls: 0.1545  decode.d0.loss_mask: 0.6575  decode.d0.loss_dice: 1.5346  decode.d1.loss_cls: 0.0879  decode.d1.loss_mask: 0.6613  decode.d1.loss_dice: 1.5300  decode.d2.loss_cls: 0.0883  decode.d2.loss_mask: 0.6595  decode.d2.loss_dice: 1.5047  decode.d3.loss_cls: 0.0858  decode.d3.loss_mask: 0.6781  decode.d3.loss_dice: 1.4810  decode.d4.loss_cls: 0.0998  decode.d4.loss_mask: 0.6649  decode.d4.loss_dice: 1.5032  decode.d5.loss_cls: 0.0913  decode.d5.loss_mask: 0.6634  decode.d5.loss_dice: 1.5349  decode.d6.loss_cls: 0.0987  decode.d6.loss_mask: 0.6486  decode.d6.loss_dice: 1.4835  decode.d7.loss_cls: 0.0964  decode.d7.loss_mask: 0.6550  decode.d7.loss_dice: 1.4785  decode.d8.loss_cls: 0.1009  decode.d8.loss_mask: 0.6396  decode.d8.loss_dice: 1.5240
11/15 07:46:51 - mmengine - INFO - Iter(train) [ 5750/90000]  base_lr: 9.4232e-05 lr: 9.4232e-06  eta: 14:20:54  time: 0.5956  data_time: 0.0096  memory: 10713  grad_norm: 471.4377  loss: 22.0408  decode.loss_cls: 0.1281  decode.loss_mask: 0.6366  decode.loss_dice: 1.4253  decode.d0.loss_cls: 0.1610  decode.d0.loss_mask: 0.6542  decode.d0.loss_dice: 1.4991  decode.d1.loss_cls: 0.0927  decode.d1.loss_mask: 0.6330  decode.d1.loss_dice: 1.4956  decode.d2.loss_cls: 0.1152  decode.d2.loss_mask: 0.6176  decode.d2.loss_dice: 1.4171  decode.d3.loss_cls: 0.1107  decode.d3.loss_mask: 0.6463  decode.d3.loss_dice: 1.4220  decode.d4.loss_cls: 0.1341  decode.d4.loss_mask: 0.6598  decode.d4.loss_dice: 1.4352  decode.d5.loss_cls: 0.1356  decode.d5.loss_mask: 0.6334  decode.d5.loss_dice: 1.4400  decode.d6.loss_cls: 0.1238  decode.d6.loss_mask: 0.6100  decode.d6.loss_dice: 1.3908  decode.d7.loss_cls: 0.1134  decode.d7.loss_mask: 0.6585  decode.d7.loss_dice: 1.4450  decode.d8.loss_cls: 0.1262  decode.d8.loss_mask: 0.6478  decode.d8.loss_dice: 1.4327
11/15 07:47:21 - mmengine - INFO - Iter(train) [ 5800/90000]  base_lr: 9.4182e-05 lr: 9.4182e-06  eta: 14:20:12  time: 0.5976  data_time: 0.0101  memory: 10713  grad_norm: 769.7826  loss: 25.4953  decode.loss_cls: 0.0913  decode.loss_mask: 0.8979  decode.loss_dice: 1.5771  decode.d0.loss_cls: 0.1370  decode.d0.loss_mask: 0.8921  decode.d0.loss_dice: 1.6545  decode.d1.loss_cls: 0.1036  decode.d1.loss_mask: 0.8604  decode.d1.loss_dice: 1.5689  decode.d2.loss_cls: 0.0882  decode.d2.loss_mask: 0.8545  decode.d2.loss_dice: 1.5850  decode.d3.loss_cls: 0.0874  decode.d3.loss_mask: 0.8443  decode.d3.loss_dice: 1.5585  decode.d4.loss_cls: 0.0835  decode.d4.loss_mask: 0.8737  decode.d4.loss_dice: 1.6123  decode.d5.loss_cls: 0.0999  decode.d5.loss_mask: 0.8564  decode.d5.loss_dice: 1.5565  decode.d6.loss_cls: 0.0935  decode.d6.loss_mask: 0.8435  decode.d6.loss_dice: 1.5634  decode.d7.loss_cls: 0.0934  decode.d7.loss_mask: 0.8679  decode.d7.loss_dice: 1.5718  decode.d8.loss_cls: 0.0925  decode.d8.loss_mask: 0.9292  decode.d8.loss_dice: 1.5571
11/15 07:47:51 - mmengine - INFO - Iter(train) [ 5850/90000]  base_lr: 9.4131e-05 lr: 9.4131e-06  eta: 14:19:30  time: 0.5956  data_time: 0.0100  memory: 10675  grad_norm: 363.7292  loss: 23.5443  decode.loss_cls: 0.0964  decode.loss_mask: 0.8237  decode.loss_dice: 1.4262  decode.d0.loss_cls: 0.1466  decode.d0.loss_mask: 0.8523  decode.d0.loss_dice: 1.4842  decode.d1.loss_cls: 0.0992  decode.d1.loss_mask: 0.8321  decode.d1.loss_dice: 1.4448  decode.d2.loss_cls: 0.0954  decode.d2.loss_mask: 0.8313  decode.d2.loss_dice: 1.4341  decode.d3.loss_cls: 0.0863  decode.d3.loss_mask: 0.8242  decode.d3.loss_dice: 1.4116  decode.d4.loss_cls: 0.0889  decode.d4.loss_mask: 0.8236  decode.d4.loss_dice: 1.4118  decode.d5.loss_cls: 0.1006  decode.d5.loss_mask: 0.8287  decode.d5.loss_dice: 1.4151  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.8275  decode.d6.loss_dice: 1.4106  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.8277  decode.d7.loss_dice: 1.4134  decode.d8.loss_cls: 0.0871  decode.d8.loss_mask: 0.8303  decode.d8.loss_dice: 1.4091
11/15 07:48:21 - mmengine - INFO - Iter(train) [ 5900/90000]  base_lr: 9.4081e-05 lr: 9.4081e-06  eta: 14:18:49  time: 0.6027  data_time: 0.0118  memory: 10675  grad_norm: 393.5660  loss: 22.3848  decode.loss_cls: 0.0621  decode.loss_mask: 0.7397  decode.loss_dice: 1.4230  decode.d0.loss_cls: 0.1412  decode.d0.loss_mask: 0.7503  decode.d0.loss_dice: 1.4869  decode.d1.loss_cls: 0.0634  decode.d1.loss_mask: 0.7376  decode.d1.loss_dice: 1.4136  decode.d2.loss_cls: 0.0617  decode.d2.loss_mask: 0.7685  decode.d2.loss_dice: 1.4125  decode.d3.loss_cls: 0.0535  decode.d3.loss_mask: 0.7646  decode.d3.loss_dice: 1.4274  decode.d4.loss_cls: 0.0589  decode.d4.loss_mask: 0.7466  decode.d4.loss_dice: 1.4113  decode.d5.loss_cls: 0.0635  decode.d5.loss_mask: 0.7319  decode.d5.loss_dice: 1.4076  decode.d6.loss_cls: 0.0523  decode.d6.loss_mask: 0.7495  decode.d6.loss_dice: 1.4233  decode.d7.loss_cls: 0.0772  decode.d7.loss_mask: 0.7536  decode.d7.loss_dice: 1.3938  decode.d8.loss_cls: 0.0603  decode.d8.loss_mask: 0.7438  decode.d8.loss_dice: 1.4051
11/15 07:48:51 - mmengine - INFO - Iter(train) [ 5950/90000]  base_lr: 9.4031e-05 lr: 9.4031e-06  eta: 14:18:13  time: 0.6040  data_time: 0.0107  memory: 10728  grad_norm: 394.9826  loss: 23.7904  decode.loss_cls: 0.1234  decode.loss_mask: 0.6459  decode.loss_dice: 1.5832  decode.d0.loss_cls: 0.1620  decode.d0.loss_mask: 0.7530  decode.d0.loss_dice: 1.6684  decode.d1.loss_cls: 0.0855  decode.d1.loss_mask: 0.6940  decode.d1.loss_dice: 1.6269  decode.d2.loss_cls: 0.1034  decode.d2.loss_mask: 0.6402  decode.d2.loss_dice: 1.5585  decode.d3.loss_cls: 0.1103  decode.d3.loss_mask: 0.6838  decode.d3.loss_dice: 1.5785  decode.d4.loss_cls: 0.1148  decode.d4.loss_mask: 0.6612  decode.d4.loss_dice: 1.5651  decode.d5.loss_cls: 0.1357  decode.d5.loss_mask: 0.6297  decode.d5.loss_dice: 1.5743  decode.d6.loss_cls: 0.1329  decode.d6.loss_mask: 0.6374  decode.d6.loss_dice: 1.5483  decode.d7.loss_cls: 0.1349  decode.d7.loss_mask: 0.6637  decode.d7.loss_dice: 1.5848  decode.d8.loss_cls: 0.1148  decode.d8.loss_mask: 0.6701  decode.d8.loss_dice: 1.6058
11/15 07:49:21 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 07:49:21 - mmengine - INFO - Iter(train) [ 6000/90000]  base_lr: 9.3980e-05 lr: 9.3980e-06  eta: 14:17:35  time: 0.6013  data_time: 0.0106  memory: 10641  grad_norm: 748.0543  loss: 24.4051  decode.loss_cls: 0.0902  decode.loss_mask: 0.8374  decode.loss_dice: 1.4839  decode.d0.loss_cls: 0.1303  decode.d0.loss_mask: 0.8828  decode.d0.loss_dice: 1.5627  decode.d1.loss_cls: 0.0827  decode.d1.loss_mask: 0.8329  decode.d1.loss_dice: 1.4957  decode.d2.loss_cls: 0.0727  decode.d2.loss_mask: 0.8324  decode.d2.loss_dice: 1.4937  decode.d3.loss_cls: 0.0855  decode.d3.loss_mask: 0.8633  decode.d3.loss_dice: 1.4864  decode.d4.loss_cls: 0.0807  decode.d4.loss_mask: 0.8623  decode.d4.loss_dice: 1.4780  decode.d5.loss_cls: 0.0852  decode.d5.loss_mask: 0.8619  decode.d5.loss_dice: 1.4963  decode.d6.loss_cls: 0.0893  decode.d6.loss_mask: 0.8485  decode.d6.loss_dice: 1.4837  decode.d7.loss_cls: 0.0723  decode.d7.loss_mask: 0.8632  decode.d7.loss_dice: 1.5063  decode.d8.loss_cls: 0.0868  decode.d8.loss_mask: 0.8497  decode.d8.loss_dice: 1.5081
11/15 07:49:51 - mmengine - INFO - Iter(train) [ 6050/90000]  base_lr: 9.3930e-05 lr: 9.3930e-06  eta: 14:16:58  time: 0.6007  data_time: 0.0101  memory: 10692  grad_norm: 451.7194  loss: 23.1132  decode.loss_cls: 0.0968  decode.loss_mask: 0.7082  decode.loss_dice: 1.5053  decode.d0.loss_cls: 0.1374  decode.d0.loss_mask: 0.7053  decode.d0.loss_dice: 1.5722  decode.d1.loss_cls: 0.0896  decode.d1.loss_mask: 0.6991  decode.d1.loss_dice: 1.5301  decode.d2.loss_cls: 0.0989  decode.d2.loss_mask: 0.6943  decode.d2.loss_dice: 1.4972  decode.d3.loss_cls: 0.0859  decode.d3.loss_mask: 0.7049  decode.d3.loss_dice: 1.5168  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 0.6909  decode.d4.loss_dice: 1.5015  decode.d5.loss_cls: 0.0959  decode.d5.loss_mask: 0.6957  decode.d5.loss_dice: 1.4743  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.7047  decode.d6.loss_dice: 1.4975  decode.d7.loss_cls: 0.0992  decode.d7.loss_mask: 0.7089  decode.d7.loss_dice: 1.5009  decode.d8.loss_cls: 0.0969  decode.d8.loss_mask: 0.7091  decode.d8.loss_dice: 1.5113
11/15 07:50:22 - mmengine - INFO - Iter(train) [ 6100/90000]  base_lr: 9.3880e-05 lr: 9.3880e-06  eta: 14:16:29  time: 0.6357  data_time: 0.0102  memory: 10675  grad_norm: 436.3201  loss: 24.5394  decode.loss_cls: 0.1030  decode.loss_mask: 0.8257  decode.loss_dice: 1.5400  decode.d0.loss_cls: 0.1554  decode.d0.loss_mask: 0.8828  decode.d0.loss_dice: 1.6123  decode.d1.loss_cls: 0.0932  decode.d1.loss_mask: 0.8093  decode.d1.loss_dice: 1.5366  decode.d2.loss_cls: 0.0828  decode.d2.loss_mask: 0.8155  decode.d2.loss_dice: 1.4821  decode.d3.loss_cls: 0.1018  decode.d3.loss_mask: 0.8026  decode.d3.loss_dice: 1.4965  decode.d4.loss_cls: 0.1219  decode.d4.loss_mask: 0.7986  decode.d4.loss_dice: 1.5297  decode.d5.loss_cls: 0.1253  decode.d5.loss_mask: 0.7946  decode.d5.loss_dice: 1.4872  decode.d6.loss_cls: 0.1220  decode.d6.loss_mask: 0.8118  decode.d6.loss_dice: 1.5076  decode.d7.loss_cls: 0.1169  decode.d7.loss_mask: 0.8140  decode.d7.loss_dice: 1.5227  decode.d8.loss_cls: 0.1107  decode.d8.loss_mask: 0.8164  decode.d8.loss_dice: 1.5205
11/15 07:50:52 - mmengine - INFO - Iter(train) [ 6150/90000]  base_lr: 9.3829e-05 lr: 9.3829e-06  eta: 14:15:49  time: 0.6017  data_time: 0.0122  memory: 10675  grad_norm: 299.3781  loss: 22.7254  decode.loss_cls: 0.0877  decode.loss_mask: 0.6092  decode.loss_dice: 1.5740  decode.d0.loss_cls: 0.1305  decode.d0.loss_mask: 0.6135  decode.d0.loss_dice: 1.6183  decode.d1.loss_cls: 0.0763  decode.d1.loss_mask: 0.5955  decode.d1.loss_dice: 1.5684  decode.d2.loss_cls: 0.0667  decode.d2.loss_mask: 0.6269  decode.d2.loss_dice: 1.5491  decode.d3.loss_cls: 0.0737  decode.d3.loss_mask: 0.6257  decode.d3.loss_dice: 1.5569  decode.d4.loss_cls: 0.0861  decode.d4.loss_mask: 0.6242  decode.d4.loss_dice: 1.5461  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 0.6379  decode.d5.loss_dice: 1.5598  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.6306  decode.d6.loss_dice: 1.5726  decode.d7.loss_cls: 0.0735  decode.d7.loss_mask: 0.6326  decode.d7.loss_dice: 1.5667  decode.d8.loss_cls: 0.0748  decode.d8.loss_mask: 0.6148  decode.d8.loss_dice: 1.5844
11/15 07:51:22 - mmengine - INFO - Iter(train) [ 6200/90000]  base_lr: 9.3779e-05 lr: 9.3779e-06  eta: 14:15:08  time: 0.5975  data_time: 0.0099  memory: 10675  grad_norm: 576.4143  loss: 24.4699  decode.loss_cls: 0.1034  decode.loss_mask: 0.7523  decode.loss_dice: 1.6020  decode.d0.loss_cls: 0.1388  decode.d0.loss_mask: 0.7752  decode.d0.loss_dice: 1.6839  decode.d1.loss_cls: 0.1065  decode.d1.loss_mask: 0.7117  decode.d1.loss_dice: 1.5641  decode.d2.loss_cls: 0.0956  decode.d2.loss_mask: 0.7286  decode.d2.loss_dice: 1.5992  decode.d3.loss_cls: 0.0834  decode.d3.loss_mask: 0.7416  decode.d3.loss_dice: 1.5934  decode.d4.loss_cls: 0.1011  decode.d4.loss_mask: 0.7515  decode.d4.loss_dice: 1.5875  decode.d5.loss_cls: 0.0934  decode.d5.loss_mask: 0.7371  decode.d5.loss_dice: 1.6054  decode.d6.loss_cls: 0.1019  decode.d6.loss_mask: 0.7469  decode.d6.loss_dice: 1.5991  decode.d7.loss_cls: 0.1135  decode.d7.loss_mask: 0.7485  decode.d7.loss_dice: 1.5779  decode.d8.loss_cls: 0.1092  decode.d8.loss_mask: 0.7366  decode.d8.loss_dice: 1.5806
11/15 07:51:52 - mmengine - INFO - Iter(train) [ 6250/90000]  base_lr: 9.3729e-05 lr: 9.3729e-06  eta: 14:14:29  time: 0.6002  data_time: 0.0104  memory: 10656  grad_norm: 339.9316  loss: 23.0538  decode.loss_cls: 0.0880  decode.loss_mask: 0.6947  decode.loss_dice: 1.5184  decode.d0.loss_cls: 0.1350  decode.d0.loss_mask: 0.6879  decode.d0.loss_dice: 1.6007  decode.d1.loss_cls: 0.0864  decode.d1.loss_mask: 0.6664  decode.d1.loss_dice: 1.5247  decode.d2.loss_cls: 0.1055  decode.d2.loss_mask: 0.6545  decode.d2.loss_dice: 1.5228  decode.d3.loss_cls: 0.0962  decode.d3.loss_mask: 0.6509  decode.d3.loss_dice: 1.5214  decode.d4.loss_cls: 0.0748  decode.d4.loss_mask: 0.6976  decode.d4.loss_dice: 1.5329  decode.d5.loss_cls: 0.0785  decode.d5.loss_mask: 0.6896  decode.d5.loss_dice: 1.5167  decode.d6.loss_cls: 0.0806  decode.d6.loss_mask: 0.6804  decode.d6.loss_dice: 1.5267  decode.d7.loss_cls: 0.1007  decode.d7.loss_mask: 0.6988  decode.d7.loss_dice: 1.5245  decode.d8.loss_cls: 0.0929  decode.d8.loss_mask: 0.6858  decode.d8.loss_dice: 1.5198
11/15 07:52:22 - mmengine - INFO - Iter(train) [ 6300/90000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 14:13:50  time: 0.5978  data_time: 0.0102  memory: 10675  grad_norm: 501.7292  loss: 21.4640  decode.loss_cls: 0.0952  decode.loss_mask: 0.6913  decode.loss_dice: 1.3172  decode.d0.loss_cls: 0.1163  decode.d0.loss_mask: 0.7159  decode.d0.loss_dice: 1.4289  decode.d1.loss_cls: 0.0637  decode.d1.loss_mask: 0.7198  decode.d1.loss_dice: 1.3900  decode.d2.loss_cls: 0.0853  decode.d2.loss_mask: 0.7237  decode.d2.loss_dice: 1.3599  decode.d3.loss_cls: 0.0773  decode.d3.loss_mask: 0.6946  decode.d3.loss_dice: 1.3273  decode.d4.loss_cls: 0.0791  decode.d4.loss_mask: 0.6895  decode.d4.loss_dice: 1.3360  decode.d5.loss_cls: 0.0813  decode.d5.loss_mask: 0.7227  decode.d5.loss_dice: 1.3559  decode.d6.loss_cls: 0.0878  decode.d6.loss_mask: 0.6911  decode.d6.loss_dice: 1.3465  decode.d7.loss_cls: 0.0765  decode.d7.loss_mask: 0.6988  decode.d7.loss_dice: 1.3491  decode.d8.loss_cls: 0.0913  decode.d8.loss_mask: 0.6950  decode.d8.loss_dice: 1.3570
11/15 07:52:52 - mmengine - INFO - Iter(train) [ 6350/90000]  base_lr: 9.3628e-05 lr: 9.3628e-06  eta: 14:13:10  time: 0.5978  data_time: 0.0101  memory: 10675  grad_norm: 367.9335  loss: 20.1004  decode.loss_cls: 0.0651  decode.loss_mask: 0.6368  decode.loss_dice: 1.2908  decode.d0.loss_cls: 0.1265  decode.d0.loss_mask: 0.6489  decode.d0.loss_dice: 1.3611  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.6111  decode.d1.loss_dice: 1.3146  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.6203  decode.d2.loss_dice: 1.3040  decode.d3.loss_cls: 0.0741  decode.d3.loss_mask: 0.6358  decode.d3.loss_dice: 1.2831  decode.d4.loss_cls: 0.0682  decode.d4.loss_mask: 0.6321  decode.d4.loss_dice: 1.2892  decode.d5.loss_cls: 0.0731  decode.d5.loss_mask: 0.6240  decode.d5.loss_dice: 1.2639  decode.d6.loss_cls: 0.0751  decode.d6.loss_mask: 0.6374  decode.d6.loss_dice: 1.2829  decode.d7.loss_cls: 0.0715  decode.d7.loss_mask: 0.6340  decode.d7.loss_dice: 1.3123  decode.d8.loss_cls: 0.0627  decode.d8.loss_mask: 0.6617  decode.d8.loss_dice: 1.2906
11/15 07:53:22 - mmengine - INFO - Iter(train) [ 6400/90000]  base_lr: 9.3578e-05 lr: 9.3578e-06  eta: 14:12:32  time: 0.6023  data_time: 0.0105  memory: 10728  grad_norm: 383.9749  loss: 24.0185  decode.loss_cls: 0.0929  decode.loss_mask: 0.7241  decode.loss_dice: 1.5758  decode.d0.loss_cls: 0.1265  decode.d0.loss_mask: 0.7353  decode.d0.loss_dice: 1.6399  decode.d1.loss_cls: 0.0731  decode.d1.loss_mask: 0.7205  decode.d1.loss_dice: 1.6062  decode.d2.loss_cls: 0.0760  decode.d2.loss_mask: 0.7171  decode.d2.loss_dice: 1.5984  decode.d3.loss_cls: 0.0838  decode.d3.loss_mask: 0.7109  decode.d3.loss_dice: 1.5984  decode.d4.loss_cls: 0.0759  decode.d4.loss_mask: 0.7020  decode.d4.loss_dice: 1.6218  decode.d5.loss_cls: 0.0858  decode.d5.loss_mask: 0.7115  decode.d5.loss_dice: 1.5780  decode.d6.loss_cls: 0.0899  decode.d6.loss_mask: 0.7317  decode.d6.loss_dice: 1.5607  decode.d7.loss_cls: 0.0895  decode.d7.loss_mask: 0.7373  decode.d7.loss_dice: 1.5769  decode.d8.loss_cls: 0.0965  decode.d8.loss_mask: 0.7257  decode.d8.loss_dice: 1.5564
11/15 07:53:52 - mmengine - INFO - Iter(train) [ 6450/90000]  base_lr: 9.3527e-05 lr: 9.3527e-06  eta: 14:11:53  time: 0.5985  data_time: 0.0101  memory: 10713  grad_norm: 680.1064  loss: 22.1282  decode.loss_cls: 0.0506  decode.loss_mask: 0.7463  decode.loss_dice: 1.3982  decode.d0.loss_cls: 0.0926  decode.d0.loss_mask: 0.7548  decode.d0.loss_dice: 1.4668  decode.d1.loss_cls: 0.0464  decode.d1.loss_mask: 0.7604  decode.d1.loss_dice: 1.4170  decode.d2.loss_cls: 0.0405  decode.d2.loss_mask: 0.7486  decode.d2.loss_dice: 1.4022  decode.d3.loss_cls: 0.0451  decode.d3.loss_mask: 0.7561  decode.d3.loss_dice: 1.3998  decode.d4.loss_cls: 0.0426  decode.d4.loss_mask: 0.7524  decode.d4.loss_dice: 1.4005  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.7450  decode.d5.loss_dice: 1.3776  decode.d6.loss_cls: 0.0530  decode.d6.loss_mask: 0.7442  decode.d6.loss_dice: 1.3948  decode.d7.loss_cls: 0.0400  decode.d7.loss_mask: 0.7567  decode.d7.loss_dice: 1.4171  decode.d8.loss_cls: 0.0507  decode.d8.loss_mask: 0.7504  decode.d8.loss_dice: 1.4236
11/15 07:54:22 - mmengine - INFO - Iter(train) [ 6500/90000]  base_lr: 9.3477e-05 lr: 9.3477e-06  eta: 14:11:15  time: 0.5972  data_time: 0.0097  memory: 10692  grad_norm: 294.2168  loss: 21.9943  decode.loss_cls: 0.0869  decode.loss_mask: 0.6468  decode.loss_dice: 1.4744  decode.d0.loss_cls: 0.1177  decode.d0.loss_mask: 0.6692  decode.d0.loss_dice: 1.5119  decode.d1.loss_cls: 0.0903  decode.d1.loss_mask: 0.6508  decode.d1.loss_dice: 1.4921  decode.d2.loss_cls: 0.0778  decode.d2.loss_mask: 0.6472  decode.d2.loss_dice: 1.4725  decode.d3.loss_cls: 0.0781  decode.d3.loss_mask: 0.6329  decode.d3.loss_dice: 1.4569  decode.d4.loss_cls: 0.0859  decode.d4.loss_mask: 0.6326  decode.d4.loss_dice: 1.4519  decode.d5.loss_cls: 0.0834  decode.d5.loss_mask: 0.6328  decode.d5.loss_dice: 1.4432  decode.d6.loss_cls: 0.0904  decode.d6.loss_mask: 0.6471  decode.d6.loss_dice: 1.4389  decode.d7.loss_cls: 0.0903  decode.d7.loss_mask: 0.6433  decode.d7.loss_dice: 1.4426  decode.d8.loss_cls: 0.0820  decode.d8.loss_mask: 0.6522  decode.d8.loss_dice: 1.4722
11/15 07:54:52 - mmengine - INFO - Iter(train) [ 6550/90000]  base_lr: 9.3426e-05 lr: 9.3426e-06  eta: 14:10:35  time: 0.5984  data_time: 0.0104  memory: 10675  grad_norm: 470.1534  loss: 24.3352  decode.loss_cls: 0.1003  decode.loss_mask: 0.7013  decode.loss_dice: 1.6104  decode.d0.loss_cls: 0.1106  decode.d0.loss_mask: 0.7144  decode.d0.loss_dice: 1.6749  decode.d1.loss_cls: 0.0650  decode.d1.loss_mask: 0.7325  decode.d1.loss_dice: 1.6859  decode.d2.loss_cls: 0.1026  decode.d2.loss_mask: 0.7189  decode.d2.loss_dice: 1.6275  decode.d3.loss_cls: 0.0925  decode.d3.loss_mask: 0.7124  decode.d3.loss_dice: 1.6014  decode.d4.loss_cls: 0.0965  decode.d4.loss_mask: 0.7072  decode.d4.loss_dice: 1.6219  decode.d5.loss_cls: 0.0863  decode.d5.loss_mask: 0.7037  decode.d5.loss_dice: 1.6107  decode.d6.loss_cls: 0.0929  decode.d6.loss_mask: 0.7142  decode.d6.loss_dice: 1.6286  decode.d7.loss_cls: 0.1096  decode.d7.loss_mask: 0.6953  decode.d7.loss_dice: 1.6289  decode.d8.loss_cls: 0.1101  decode.d8.loss_mask: 0.7062  decode.d8.loss_dice: 1.5724
11/15 07:55:22 - mmengine - INFO - Iter(train) [ 6600/90000]  base_lr: 9.3376e-05 lr: 9.3376e-06  eta: 14:10:02  time: 0.6013  data_time: 0.0101  memory: 10692  grad_norm: 321.7192  loss: 23.5716  decode.loss_cls: 0.0669  decode.loss_mask: 0.6828  decode.loss_dice: 1.5850  decode.d0.loss_cls: 0.1079  decode.d0.loss_mask: 0.7393  decode.d0.loss_dice: 1.6374  decode.d1.loss_cls: 0.0721  decode.d1.loss_mask: 0.7238  decode.d1.loss_dice: 1.5934  decode.d2.loss_cls: 0.0611  decode.d2.loss_mask: 0.7072  decode.d2.loss_dice: 1.6077  decode.d3.loss_cls: 0.0487  decode.d3.loss_mask: 0.7118  decode.d3.loss_dice: 1.5774  decode.d4.loss_cls: 0.0711  decode.d4.loss_mask: 0.6825  decode.d4.loss_dice: 1.5795  decode.d5.loss_cls: 0.0526  decode.d5.loss_mask: 0.6878  decode.d5.loss_dice: 1.5530  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.6878  decode.d6.loss_dice: 1.5660  decode.d7.loss_cls: 0.0638  decode.d7.loss_mask: 0.6853  decode.d7.loss_dice: 1.5986  decode.d8.loss_cls: 0.0674  decode.d8.loss_mask: 0.7084  decode.d8.loss_dice: 1.5869
11/15 07:55:52 - mmengine - INFO - Iter(train) [ 6650/90000]  base_lr: 9.3326e-05 lr: 9.3326e-06  eta: 14:09:25  time: 0.6013  data_time: 0.0103  memory: 10692  grad_norm: 521.7998  loss: 25.7655  decode.loss_cls: 0.1102  decode.loss_mask: 0.7965  decode.loss_dice: 1.6794  decode.d0.loss_cls: 0.1304  decode.d0.loss_mask: 0.7898  decode.d0.loss_dice: 1.7754  decode.d1.loss_cls: 0.0948  decode.d1.loss_mask: 0.7614  decode.d1.loss_dice: 1.6848  decode.d2.loss_cls: 0.0861  decode.d2.loss_mask: 0.7992  decode.d2.loss_dice: 1.6757  decode.d3.loss_cls: 0.0846  decode.d3.loss_mask: 0.7857  decode.d3.loss_dice: 1.6788  decode.d4.loss_cls: 0.0947  decode.d4.loss_mask: 0.7952  decode.d4.loss_dice: 1.6886  decode.d5.loss_cls: 0.0814  decode.d5.loss_mask: 0.8061  decode.d5.loss_dice: 1.6816  decode.d6.loss_cls: 0.1031  decode.d6.loss_mask: 0.7914  decode.d6.loss_dice: 1.6772  decode.d7.loss_cls: 0.1069  decode.d7.loss_mask: 0.8032  decode.d7.loss_dice: 1.6863  decode.d8.loss_cls: 0.1220  decode.d8.loss_mask: 0.7875  decode.d8.loss_dice: 1.6075
11/15 07:56:22 - mmengine - INFO - Iter(train) [ 6700/90000]  base_lr: 9.3275e-05 lr: 9.3275e-06  eta: 14:08:48  time: 0.5996  data_time: 0.0101  memory: 10713  grad_norm: 337.5182  loss: 24.1011  decode.loss_cls: 0.0784  decode.loss_mask: 0.7361  decode.loss_dice: 1.6008  decode.d0.loss_cls: 0.1081  decode.d0.loss_mask: 0.7405  decode.d0.loss_dice: 1.6450  decode.d1.loss_cls: 0.0547  decode.d1.loss_mask: 0.7354  decode.d1.loss_dice: 1.6207  decode.d2.loss_cls: 0.0811  decode.d2.loss_mask: 0.7052  decode.d2.loss_dice: 1.6027  decode.d3.loss_cls: 0.0768  decode.d3.loss_mask: 0.7140  decode.d3.loss_dice: 1.6038  decode.d4.loss_cls: 0.0885  decode.d4.loss_mask: 0.7172  decode.d4.loss_dice: 1.5995  decode.d5.loss_cls: 0.0868  decode.d5.loss_mask: 0.7195  decode.d5.loss_dice: 1.5967  decode.d6.loss_cls: 0.0944  decode.d6.loss_mask: 0.7020  decode.d6.loss_dice: 1.5901  decode.d7.loss_cls: 0.0794  decode.d7.loss_mask: 0.7023  decode.d7.loss_dice: 1.6196  decode.d8.loss_cls: 0.0749  decode.d8.loss_mask: 0.7169  decode.d8.loss_dice: 1.6100
11/15 07:56:52 - mmengine - INFO - Iter(train) [ 6750/90000]  base_lr: 9.3225e-05 lr: 9.3225e-06  eta: 14:08:10  time: 0.6002  data_time: 0.0111  memory: 10713  grad_norm: 693.1676  loss: 21.3560  decode.loss_cls: 0.0834  decode.loss_mask: 0.7505  decode.loss_dice: 1.2814  decode.d0.loss_cls: 0.1191  decode.d0.loss_mask: 0.7516  decode.d0.loss_dice: 1.3781  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.7438  decode.d1.loss_dice: 1.3011  decode.d2.loss_cls: 0.0774  decode.d2.loss_mask: 0.7507  decode.d2.loss_dice: 1.2878  decode.d3.loss_cls: 0.0952  decode.d3.loss_mask: 0.7553  decode.d3.loss_dice: 1.2605  decode.d4.loss_cls: 0.1061  decode.d4.loss_mask: 0.7322  decode.d4.loss_dice: 1.3056  decode.d5.loss_cls: 0.1026  decode.d5.loss_mask: 0.7306  decode.d5.loss_dice: 1.2623  decode.d6.loss_cls: 0.0880  decode.d6.loss_mask: 0.7515  decode.d6.loss_dice: 1.3100  decode.d7.loss_cls: 0.0840  decode.d7.loss_mask: 0.7456  decode.d7.loss_dice: 1.2831  decode.d8.loss_cls: 0.0854  decode.d8.loss_mask: 0.7507  decode.d8.loss_dice: 1.2979
11/15 07:57:22 - mmengine - INFO - Iter(train) [ 6800/90000]  base_lr: 9.3175e-05 lr: 9.3175e-06  eta: 14:07:33  time: 0.6018  data_time: 0.0100  memory: 10656  grad_norm: 330.1134  loss: 23.1998  decode.loss_cls: 0.0797  decode.loss_mask: 0.6313  decode.loss_dice: 1.5856  decode.d0.loss_cls: 0.0959  decode.d0.loss_mask: 0.6440  decode.d0.loss_dice: 1.6447  decode.d1.loss_cls: 0.0786  decode.d1.loss_mask: 0.6204  decode.d1.loss_dice: 1.6206  decode.d2.loss_cls: 0.1152  decode.d2.loss_mask: 0.6264  decode.d2.loss_dice: 1.5836  decode.d3.loss_cls: 0.0928  decode.d3.loss_mask: 0.6206  decode.d3.loss_dice: 1.6084  decode.d4.loss_cls: 0.0889  decode.d4.loss_mask: 0.6192  decode.d4.loss_dice: 1.6035  decode.d5.loss_cls: 0.0958  decode.d5.loss_mask: 0.6161  decode.d5.loss_dice: 1.5899  decode.d6.loss_cls: 0.1032  decode.d6.loss_mask: 0.6173  decode.d6.loss_dice: 1.6064  decode.d7.loss_cls: 0.1012  decode.d7.loss_mask: 0.6177  decode.d7.loss_dice: 1.5797  decode.d8.loss_cls: 0.0969  decode.d8.loss_mask: 0.6214  decode.d8.loss_dice: 1.5949
11/15 07:57:52 - mmengine - INFO - Iter(train) [ 6850/90000]  base_lr: 9.3124e-05 lr: 9.3124e-06  eta: 14:06:55  time: 0.5988  data_time: 0.0098  memory: 10692  grad_norm: 686.8996  loss: 22.7205  decode.loss_cls: 0.0712  decode.loss_mask: 0.7275  decode.loss_dice: 1.4745  decode.d0.loss_cls: 0.1203  decode.d0.loss_mask: 0.7575  decode.d0.loss_dice: 1.5060  decode.d1.loss_cls: 0.0734  decode.d1.loss_mask: 0.7203  decode.d1.loss_dice: 1.4739  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.7532  decode.d2.loss_dice: 1.4677  decode.d3.loss_cls: 0.0766  decode.d3.loss_mask: 0.7303  decode.d3.loss_dice: 1.4316  decode.d4.loss_cls: 0.0656  decode.d4.loss_mask: 0.7718  decode.d4.loss_dice: 1.4819  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.7373  decode.d5.loss_dice: 1.4678  decode.d6.loss_cls: 0.0761  decode.d6.loss_mask: 0.7022  decode.d6.loss_dice: 1.4251  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.7261  decode.d7.loss_dice: 1.4599  decode.d8.loss_cls: 0.0694  decode.d8.loss_mask: 0.7221  decode.d8.loss_dice: 1.4450
11/15 07:58:22 - mmengine - INFO - Iter(train) [ 6900/90000]  base_lr: 9.3074e-05 lr: 9.3074e-06  eta: 14:06:23  time: 0.6415  data_time: 0.0103  memory: 10675  grad_norm: 370.4985  loss: 21.9866  decode.loss_cls: 0.0916  decode.loss_mask: 0.6736  decode.loss_dice: 1.4272  decode.d0.loss_cls: 0.1076  decode.d0.loss_mask: 0.6407  decode.d0.loss_dice: 1.4810  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.6450  decode.d1.loss_dice: 1.4667  decode.d2.loss_cls: 0.0810  decode.d2.loss_mask: 0.6653  decode.d2.loss_dice: 1.4237  decode.d3.loss_cls: 0.0810  decode.d3.loss_mask: 0.6862  decode.d3.loss_dice: 1.4084  decode.d4.loss_cls: 0.0785  decode.d4.loss_mask: 0.7169  decode.d4.loss_dice: 1.4427  decode.d5.loss_cls: 0.0928  decode.d5.loss_mask: 0.6951  decode.d5.loss_dice: 1.4224  decode.d6.loss_cls: 0.1013  decode.d6.loss_mask: 0.6837  decode.d6.loss_dice: 1.4260  decode.d7.loss_cls: 0.1112  decode.d7.loss_mask: 0.6598  decode.d7.loss_dice: 1.4181  decode.d8.loss_cls: 0.0984  decode.d8.loss_mask: 0.6684  decode.d8.loss_dice: 1.4148
11/15 07:58:52 - mmengine - INFO - Iter(train) [ 6950/90000]  base_lr: 9.3023e-05 lr: 9.3023e-06  eta: 14:05:44  time: 0.5963  data_time: 0.0098  memory: 10692  grad_norm: 433.8187  loss: 24.5615  decode.loss_cls: 0.0985  decode.loss_mask: 0.7387  decode.loss_dice: 1.6076  decode.d0.loss_cls: 0.1184  decode.d0.loss_mask: 0.7662  decode.d0.loss_dice: 1.7092  decode.d1.loss_cls: 0.0746  decode.d1.loss_mask: 0.7676  decode.d1.loss_dice: 1.6178  decode.d2.loss_cls: 0.0882  decode.d2.loss_mask: 0.7630  decode.d2.loss_dice: 1.5739  decode.d3.loss_cls: 0.1005  decode.d3.loss_mask: 0.7629  decode.d3.loss_dice: 1.5767  decode.d4.loss_cls: 0.1125  decode.d4.loss_mask: 0.7217  decode.d4.loss_dice: 1.5903  decode.d5.loss_cls: 0.0911  decode.d5.loss_mask: 0.7185  decode.d5.loss_dice: 1.6096  decode.d6.loss_cls: 0.0999  decode.d6.loss_mask: 0.7173  decode.d6.loss_dice: 1.5832  decode.d7.loss_cls: 0.1000  decode.d7.loss_mask: 0.7708  decode.d7.loss_dice: 1.6309  decode.d8.loss_cls: 0.0975  decode.d8.loss_mask: 0.7446  decode.d8.loss_dice: 1.6101
11/15 07:59:22 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 07:59:22 - mmengine - INFO - Iter(train) [ 7000/90000]  base_lr: 9.2973e-05 lr: 9.2973e-06  eta: 14:05:05  time: 0.5970  data_time: 0.0098  memory: 10656  grad_norm: 880.4171  loss: 22.9983  decode.loss_cls: 0.1018  decode.loss_mask: 0.8430  decode.loss_dice: 1.3409  decode.d0.loss_cls: 0.1200  decode.d0.loss_mask: 0.8919  decode.d0.loss_dice: 1.4757  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.7570  decode.d1.loss_dice: 1.4086  decode.d2.loss_cls: 0.0923  decode.d2.loss_mask: 0.7761  decode.d2.loss_dice: 1.4104  decode.d3.loss_cls: 0.1009  decode.d3.loss_mask: 0.7670  decode.d3.loss_dice: 1.3578  decode.d4.loss_cls: 0.1066  decode.d4.loss_mask: 0.7694  decode.d4.loss_dice: 1.3629  decode.d5.loss_cls: 0.0953  decode.d5.loss_mask: 0.8378  decode.d5.loss_dice: 1.3922  decode.d6.loss_cls: 0.0855  decode.d6.loss_mask: 0.8323  decode.d6.loss_dice: 1.3967  decode.d7.loss_cls: 0.0953  decode.d7.loss_mask: 0.8275  decode.d7.loss_dice: 1.3867  decode.d8.loss_cls: 0.0892  decode.d8.loss_mask: 0.8192  decode.d8.loss_dice: 1.3663
11/15 07:59:52 - mmengine - INFO - Iter(train) [ 7050/90000]  base_lr: 9.2922e-05 lr: 9.2922e-06  eta: 14:04:27  time: 0.5974  data_time: 0.0100  memory: 10656  grad_norm: 314.2959  loss: 21.1420  decode.loss_cls: 0.0927  decode.loss_mask: 0.5469  decode.loss_dice: 1.4716  decode.d0.loss_cls: 0.1076  decode.d0.loss_mask: 0.5446  decode.d0.loss_dice: 1.5368  decode.d1.loss_cls: 0.0669  decode.d1.loss_mask: 0.5517  decode.d1.loss_dice: 1.5160  decode.d2.loss_cls: 0.0912  decode.d2.loss_mask: 0.5496  decode.d2.loss_dice: 1.4373  decode.d3.loss_cls: 0.0819  decode.d3.loss_mask: 0.5551  decode.d3.loss_dice: 1.4725  decode.d4.loss_cls: 0.0865  decode.d4.loss_mask: 0.5549  decode.d4.loss_dice: 1.4630  decode.d5.loss_cls: 0.0989  decode.d5.loss_mask: 0.5484  decode.d5.loss_dice: 1.4488  decode.d6.loss_cls: 0.0956  decode.d6.loss_mask: 0.5500  decode.d6.loss_dice: 1.4712  decode.d7.loss_cls: 0.0975  decode.d7.loss_mask: 0.5560  decode.d7.loss_dice: 1.4443  decode.d8.loss_cls: 0.0886  decode.d8.loss_mask: 0.5513  decode.d8.loss_dice: 1.4646
11/15 08:00:22 - mmengine - INFO - Iter(train) [ 7100/90000]  base_lr: 9.2872e-05 lr: 9.2872e-06  eta: 14:03:48  time: 0.6007  data_time: 0.0101  memory: 10728  grad_norm: 467.9243  loss: 25.2034  decode.loss_cls: 0.1123  decode.loss_mask: 0.8281  decode.loss_dice: 1.6099  decode.d0.loss_cls: 0.1145  decode.d0.loss_mask: 0.8260  decode.d0.loss_dice: 1.6932  decode.d1.loss_cls: 0.1547  decode.d1.loss_mask: 0.8023  decode.d1.loss_dice: 1.5904  decode.d2.loss_cls: 0.1196  decode.d2.loss_mask: 0.7980  decode.d2.loss_dice: 1.5782  decode.d3.loss_cls: 0.1180  decode.d3.loss_mask: 0.7998  decode.d3.loss_dice: 1.5748  decode.d4.loss_cls: 0.1177  decode.d4.loss_mask: 0.8117  decode.d4.loss_dice: 1.5773  decode.d5.loss_cls: 0.1317  decode.d5.loss_mask: 0.7855  decode.d5.loss_dice: 1.5994  decode.d6.loss_cls: 0.1275  decode.d6.loss_mask: 0.7626  decode.d6.loss_dice: 1.5855  decode.d7.loss_cls: 0.1218  decode.d7.loss_mask: 0.7627  decode.d7.loss_dice: 1.5878  decode.d8.loss_cls: 0.1336  decode.d8.loss_mask: 0.7975  decode.d8.loss_dice: 1.5815
11/15 08:00:52 - mmengine - INFO - Iter(train) [ 7150/90000]  base_lr: 9.2822e-05 lr: 9.2822e-06  eta: 14:03:10  time: 0.5975  data_time: 0.0098  memory: 10692  grad_norm: 1409.9977  loss: 22.3816  decode.loss_cls: 0.1180  decode.loss_mask: 0.7373  decode.loss_dice: 1.3504  decode.d0.loss_cls: 0.1281  decode.d0.loss_mask: 0.7792  decode.d0.loss_dice: 1.4592  decode.d1.loss_cls: 0.0965  decode.d1.loss_mask: 0.7648  decode.d1.loss_dice: 1.3986  decode.d2.loss_cls: 0.1259  decode.d2.loss_mask: 0.7328  decode.d2.loss_dice: 1.3516  decode.d3.loss_cls: 0.1082  decode.d3.loss_mask: 0.7332  decode.d3.loss_dice: 1.3641  decode.d4.loss_cls: 0.1068  decode.d4.loss_mask: 0.7427  decode.d4.loss_dice: 1.3369  decode.d5.loss_cls: 0.1112  decode.d5.loss_mask: 0.7487  decode.d5.loss_dice: 1.3395  decode.d6.loss_cls: 0.1162  decode.d6.loss_mask: 0.7605  decode.d6.loss_dice: 1.3403  decode.d7.loss_cls: 0.1086  decode.d7.loss_mask: 0.7773  decode.d7.loss_dice: 1.3746  decode.d8.loss_cls: 0.1206  decode.d8.loss_mask: 0.7615  decode.d8.loss_dice: 1.3882
11/15 08:01:22 - mmengine - INFO - Iter(train) [ 7200/90000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 14:02:32  time: 0.5973  data_time: 0.0099  memory: 10656  grad_norm: 595.7881  loss: 22.1890  decode.loss_cls: 0.0867  decode.loss_mask: 0.7606  decode.loss_dice: 1.3964  decode.d0.loss_cls: 0.1032  decode.d0.loss_mask: 0.7103  decode.d0.loss_dice: 1.4537  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.7122  decode.d1.loss_dice: 1.4105  decode.d2.loss_cls: 0.0712  decode.d2.loss_mask: 0.7247  decode.d2.loss_dice: 1.4137  decode.d3.loss_cls: 0.0925  decode.d3.loss_mask: 0.7143  decode.d3.loss_dice: 1.3539  decode.d4.loss_cls: 0.0914  decode.d4.loss_mask: 0.7228  decode.d4.loss_dice: 1.3864  decode.d5.loss_cls: 0.0911  decode.d5.loss_mask: 0.7245  decode.d5.loss_dice: 1.4060  decode.d6.loss_cls: 0.0951  decode.d6.loss_mask: 0.7306  decode.d6.loss_dice: 1.3864  decode.d7.loss_cls: 0.0968  decode.d7.loss_mask: 0.7323  decode.d7.loss_dice: 1.4152  decode.d8.loss_cls: 0.0836  decode.d8.loss_mask: 0.7439  decode.d8.loss_dice: 1.4108
11/15 08:01:51 - mmengine - INFO - Iter(train) [ 7250/90000]  base_lr: 9.2721e-05 lr: 9.2721e-06  eta: 14:01:54  time: 0.5960  data_time: 0.0099  memory: 10675  grad_norm: 404.4270  loss: 22.5612  decode.loss_cls: 0.1123  decode.loss_mask: 0.7368  decode.loss_dice: 1.3822  decode.d0.loss_cls: 0.1348  decode.d0.loss_mask: 0.7656  decode.d0.loss_dice: 1.4865  decode.d1.loss_cls: 0.1254  decode.d1.loss_mask: 0.7302  decode.d1.loss_dice: 1.4206  decode.d2.loss_cls: 0.1003  decode.d2.loss_mask: 0.7454  decode.d2.loss_dice: 1.3993  decode.d3.loss_cls: 0.1133  decode.d3.loss_mask: 0.7261  decode.d3.loss_dice: 1.3594  decode.d4.loss_cls: 0.1129  decode.d4.loss_mask: 0.7641  decode.d4.loss_dice: 1.3595  decode.d5.loss_cls: 0.1079  decode.d5.loss_mask: 0.7782  decode.d5.loss_dice: 1.3736  decode.d6.loss_cls: 0.1201  decode.d6.loss_mask: 0.7664  decode.d6.loss_dice: 1.3500  decode.d7.loss_cls: 0.1080  decode.d7.loss_mask: 0.7582  decode.d7.loss_dice: 1.3983  decode.d8.loss_cls: 0.1164  decode.d8.loss_mask: 0.7330  decode.d8.loss_dice: 1.3763
11/15 08:02:21 - mmengine - INFO - Iter(train) [ 7300/90000]  base_lr: 9.2670e-05 lr: 9.2670e-06  eta: 14:01:17  time: 0.5992  data_time: 0.0100  memory: 10656  grad_norm: 259.1918  loss: 20.8459  decode.loss_cls: 0.0975  decode.loss_mask: 0.6468  decode.loss_dice: 1.2990  decode.d0.loss_cls: 0.1176  decode.d0.loss_mask: 0.6856  decode.d0.loss_dice: 1.4040  decode.d1.loss_cls: 0.1006  decode.d1.loss_mask: 0.6610  decode.d1.loss_dice: 1.3502  decode.d2.loss_cls: 0.1058  decode.d2.loss_mask: 0.6609  decode.d2.loss_dice: 1.3067  decode.d3.loss_cls: 0.0911  decode.d3.loss_mask: 0.6611  decode.d3.loss_dice: 1.2995  decode.d4.loss_cls: 0.0884  decode.d4.loss_mask: 0.6641  decode.d4.loss_dice: 1.3036  decode.d5.loss_cls: 0.0896  decode.d5.loss_mask: 0.6732  decode.d5.loss_dice: 1.3194  decode.d6.loss_cls: 0.1004  decode.d6.loss_mask: 0.6630  decode.d6.loss_dice: 1.2999  decode.d7.loss_cls: 0.1082  decode.d7.loss_mask: 0.6595  decode.d7.loss_dice: 1.3212  decode.d8.loss_cls: 0.0912  decode.d8.loss_mask: 0.6576  decode.d8.loss_dice: 1.3192
11/15 08:02:51 - mmengine - INFO - Iter(train) [ 7350/90000]  base_lr: 9.2620e-05 lr: 9.2620e-06  eta: 14:00:40  time: 0.6003  data_time: 0.0102  memory: 10675  grad_norm: 576.1386  loss: 21.8937  decode.loss_cls: 0.0854  decode.loss_mask: 0.8215  decode.loss_dice: 1.3258  decode.d0.loss_cls: 0.1241  decode.d0.loss_mask: 0.7639  decode.d0.loss_dice: 1.3446  decode.d1.loss_cls: 0.0726  decode.d1.loss_mask: 0.7673  decode.d1.loss_dice: 1.3044  decode.d2.loss_cls: 0.0725  decode.d2.loss_mask: 0.7975  decode.d2.loss_dice: 1.3301  decode.d3.loss_cls: 0.0862  decode.d3.loss_mask: 0.7697  decode.d3.loss_dice: 1.3095  decode.d4.loss_cls: 0.0847  decode.d4.loss_mask: 0.7664  decode.d4.loss_dice: 1.3219  decode.d5.loss_cls: 0.0901  decode.d5.loss_mask: 0.7877  decode.d5.loss_dice: 1.3366  decode.d6.loss_cls: 0.0637  decode.d6.loss_mask: 0.7795  decode.d6.loss_dice: 1.3260  decode.d7.loss_cls: 0.0739  decode.d7.loss_mask: 0.8011  decode.d7.loss_dice: 1.3022  decode.d8.loss_cls: 0.0790  decode.d8.loss_mask: 0.8142  decode.d8.loss_dice: 1.2915
11/15 08:03:21 - mmengine - INFO - Iter(train) [ 7400/90000]  base_lr: 9.2570e-05 lr: 9.2570e-06  eta: 14:00:03  time: 0.6002  data_time: 0.0100  memory: 10692  grad_norm: 326.7796  loss: 22.7624  decode.loss_cls: 0.1012  decode.loss_mask: 0.7388  decode.loss_dice: 1.4244  decode.d0.loss_cls: 0.1096  decode.d0.loss_mask: 0.7619  decode.d0.loss_dice: 1.4921  decode.d1.loss_cls: 0.0725  decode.d1.loss_mask: 0.7361  decode.d1.loss_dice: 1.4840  decode.d2.loss_cls: 0.1030  decode.d2.loss_mask: 0.7228  decode.d2.loss_dice: 1.4466  decode.d3.loss_cls: 0.1170  decode.d3.loss_mask: 0.7200  decode.d3.loss_dice: 1.4352  decode.d4.loss_cls: 0.0990  decode.d4.loss_mask: 0.7210  decode.d4.loss_dice: 1.4389  decode.d5.loss_cls: 0.1184  decode.d5.loss_mask: 0.7229  decode.d5.loss_dice: 1.4060  decode.d6.loss_cls: 0.0980  decode.d6.loss_mask: 0.7321  decode.d6.loss_dice: 1.4247  decode.d7.loss_cls: 0.0979  decode.d7.loss_mask: 0.7317  decode.d7.loss_dice: 1.4446  decode.d8.loss_cls: 0.1046  decode.d8.loss_mask: 0.7205  decode.d8.loss_dice: 1.4368
11/15 08:03:51 - mmengine - INFO - Iter(train) [ 7450/90000]  base_lr: 9.2519e-05 lr: 9.2519e-06  eta: 13:59:26  time: 0.5995  data_time: 0.0101  memory: 10728  grad_norm: 659.9988  loss: 24.2160  decode.loss_cls: 0.1092  decode.loss_mask: 0.7267  decode.loss_dice: 1.5729  decode.d0.loss_cls: 0.1192  decode.d0.loss_mask: 0.7681  decode.d0.loss_dice: 1.6368  decode.d1.loss_cls: 0.0901  decode.d1.loss_mask: 0.7576  decode.d1.loss_dice: 1.6135  decode.d2.loss_cls: 0.1062  decode.d2.loss_mask: 0.7615  decode.d2.loss_dice: 1.5544  decode.d3.loss_cls: 0.1013  decode.d3.loss_mask: 0.7453  decode.d3.loss_dice: 1.5328  decode.d4.loss_cls: 0.1003  decode.d4.loss_mask: 0.7417  decode.d4.loss_dice: 1.5688  decode.d5.loss_cls: 0.1087  decode.d5.loss_mask: 0.7364  decode.d5.loss_dice: 1.5217  decode.d6.loss_cls: 0.0992  decode.d6.loss_mask: 0.7470  decode.d6.loss_dice: 1.5528  decode.d7.loss_cls: 0.0983  decode.d7.loss_mask: 0.7457  decode.d7.loss_dice: 1.5802  decode.d8.loss_cls: 0.1051  decode.d8.loss_mask: 0.7431  decode.d8.loss_dice: 1.5713
11/15 08:04:21 - mmengine - INFO - Iter(train) [ 7500/90000]  base_lr: 9.2469e-05 lr: 9.2469e-06  eta: 13:58:50  time: 0.6002  data_time: 0.0104  memory: 10713  grad_norm: 445.2488  loss: 23.5613  decode.loss_cls: 0.0663  decode.loss_mask: 0.7356  decode.loss_dice: 1.5371  decode.d0.loss_cls: 0.0988  decode.d0.loss_mask: 0.7610  decode.d0.loss_dice: 1.6036  decode.d1.loss_cls: 0.0621  decode.d1.loss_mask: 0.7391  decode.d1.loss_dice: 1.5618  decode.d2.loss_cls: 0.0782  decode.d2.loss_mask: 0.7306  decode.d2.loss_dice: 1.5375  decode.d3.loss_cls: 0.0820  decode.d3.loss_mask: 0.7236  decode.d3.loss_dice: 1.5244  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.7265  decode.d4.loss_dice: 1.5543  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.7233  decode.d5.loss_dice: 1.5272  decode.d6.loss_cls: 0.0875  decode.d6.loss_mask: 0.7248  decode.d6.loss_dice: 1.5294  decode.d7.loss_cls: 0.0800  decode.d7.loss_mask: 0.7134  decode.d7.loss_dice: 1.5515  decode.d8.loss_cls: 0.0797  decode.d8.loss_mask: 0.7222  decode.d8.loss_dice: 1.5356
11/15 08:04:51 - mmengine - INFO - Iter(train) [ 7550/90000]  base_lr: 9.2418e-05 lr: 9.2418e-06  eta: 13:58:14  time: 0.6005  data_time: 0.0100  memory: 10692  grad_norm: 722.9252  loss: 21.7410  decode.loss_cls: 0.0764  decode.loss_mask: 0.6819  decode.loss_dice: 1.4178  decode.d0.loss_cls: 0.0972  decode.d0.loss_mask: 0.6790  decode.d0.loss_dice: 1.4591  decode.d1.loss_cls: 0.0806  decode.d1.loss_mask: 0.6659  decode.d1.loss_dice: 1.4312  decode.d2.loss_cls: 0.0966  decode.d2.loss_mask: 0.6706  decode.d2.loss_dice: 1.4032  decode.d3.loss_cls: 0.0891  decode.d3.loss_mask: 0.6749  decode.d3.loss_dice: 1.3852  decode.d4.loss_cls: 0.0854  decode.d4.loss_mask: 0.6827  decode.d4.loss_dice: 1.4076  decode.d5.loss_cls: 0.0936  decode.d5.loss_mask: 0.6765  decode.d5.loss_dice: 1.3804  decode.d6.loss_cls: 0.0897  decode.d6.loss_mask: 0.6741  decode.d6.loss_dice: 1.4050  decode.d7.loss_cls: 0.1000  decode.d7.loss_mask: 0.6776  decode.d7.loss_dice: 1.3909  decode.d8.loss_cls: 0.0920  decode.d8.loss_mask: 0.6799  decode.d8.loss_dice: 1.3968
11/15 08:05:24 - mmengine - INFO - Iter(train) [ 7600/90000]  base_lr: 9.2368e-05 lr: 9.2368e-06  eta: 13:58:04  time: 0.5982  data_time: 0.0099  memory: 10692  grad_norm: 499.2135  loss: 22.7053  decode.loss_cls: 0.0595  decode.loss_mask: 0.7433  decode.loss_dice: 1.4430  decode.d0.loss_cls: 0.0849  decode.d0.loss_mask: 0.7801  decode.d0.loss_dice: 1.4965  decode.d1.loss_cls: 0.0733  decode.d1.loss_mask: 0.7912  decode.d1.loss_dice: 1.4205  decode.d2.loss_cls: 0.0611  decode.d2.loss_mask: 0.7592  decode.d2.loss_dice: 1.4350  decode.d3.loss_cls: 0.0626  decode.d3.loss_mask: 0.7487  decode.d3.loss_dice: 1.4108  decode.d4.loss_cls: 0.0669  decode.d4.loss_mask: 0.7495  decode.d4.loss_dice: 1.4304  decode.d5.loss_cls: 0.0599  decode.d5.loss_mask: 0.7474  decode.d5.loss_dice: 1.4458  decode.d6.loss_cls: 0.0705  decode.d6.loss_mask: 0.7470  decode.d6.loss_dice: 1.4321  decode.d7.loss_cls: 0.0471  decode.d7.loss_mask: 0.7725  decode.d7.loss_dice: 1.4958  decode.d8.loss_cls: 0.0530  decode.d8.loss_mask: 0.7375  decode.d8.loss_dice: 1.4802
11/15 08:05:53 - mmengine - INFO - Iter(train) [ 7650/90000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 13:57:27  time: 0.5975  data_time: 0.0099  memory: 10656  grad_norm: 441.9616  loss: 21.0304  decode.loss_cls: 0.0759  decode.loss_mask: 0.7134  decode.loss_dice: 1.3155  decode.d0.loss_cls: 0.0921  decode.d0.loss_mask: 0.7512  decode.d0.loss_dice: 1.4059  decode.d1.loss_cls: 0.0483  decode.d1.loss_mask: 0.6959  decode.d1.loss_dice: 1.3518  decode.d2.loss_cls: 0.0548  decode.d2.loss_mask: 0.6947  decode.d2.loss_dice: 1.3083  decode.d3.loss_cls: 0.0627  decode.d3.loss_mask: 0.7214  decode.d3.loss_dice: 1.3048  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.7053  decode.d4.loss_dice: 1.3263  decode.d5.loss_cls: 0.0548  decode.d5.loss_mask: 0.6984  decode.d5.loss_dice: 1.3161  decode.d6.loss_cls: 0.0627  decode.d6.loss_mask: 0.6954  decode.d6.loss_dice: 1.3023  decode.d7.loss_cls: 0.0721  decode.d7.loss_mask: 0.7007  decode.d7.loss_dice: 1.3258  decode.d8.loss_cls: 0.0615  decode.d8.loss_mask: 0.7230  decode.d8.loss_dice: 1.3287
11/15 08:06:23 - mmengine - INFO - Iter(train) [ 7700/90000]  base_lr: 9.2267e-05 lr: 9.2267e-06  eta: 13:56:50  time: 0.5974  data_time: 0.0098  memory: 10713  grad_norm: 550.3236  loss: 20.8711  decode.loss_cls: 0.0757  decode.loss_mask: 0.6034  decode.loss_dice: 1.4083  decode.d0.loss_cls: 0.1100  decode.d0.loss_mask: 0.5889  decode.d0.loss_dice: 1.5188  decode.d1.loss_cls: 0.0826  decode.d1.loss_mask: 0.5810  decode.d1.loss_dice: 1.4297  decode.d2.loss_cls: 0.0795  decode.d2.loss_mask: 0.5817  decode.d2.loss_dice: 1.4139  decode.d3.loss_cls: 0.0831  decode.d3.loss_mask: 0.5873  decode.d3.loss_dice: 1.3861  decode.d4.loss_cls: 0.0764  decode.d4.loss_mask: 0.5885  decode.d4.loss_dice: 1.3977  decode.d5.loss_cls: 0.0817  decode.d5.loss_mask: 0.5909  decode.d5.loss_dice: 1.3885  decode.d6.loss_cls: 0.0795  decode.d6.loss_mask: 0.5924  decode.d6.loss_dice: 1.3907  decode.d7.loss_cls: 0.0695  decode.d7.loss_mask: 0.6021  decode.d7.loss_dice: 1.4082  decode.d8.loss_cls: 0.0792  decode.d8.loss_mask: 0.5898  decode.d8.loss_dice: 1.4062
11/15 08:06:53 - mmengine - INFO - Iter(train) [ 7750/90000]  base_lr: 9.2216e-05 lr: 9.2216e-06  eta: 13:56:13  time: 0.5968  data_time: 0.0098  memory: 10656  grad_norm: 580.4911  loss: 20.5659  decode.loss_cls: 0.0314  decode.loss_mask: 0.7320  decode.loss_dice: 1.2835  decode.d0.loss_cls: 0.0860  decode.d0.loss_mask: 0.7587  decode.d0.loss_dice: 1.2933  decode.d1.loss_cls: 0.0395  decode.d1.loss_mask: 0.7287  decode.d1.loss_dice: 1.2800  decode.d2.loss_cls: 0.0376  decode.d2.loss_mask: 0.7164  decode.d2.loss_dice: 1.2952  decode.d3.loss_cls: 0.0359  decode.d3.loss_mask: 0.7285  decode.d3.loss_dice: 1.2791  decode.d4.loss_cls: 0.0366  decode.d4.loss_mask: 0.7336  decode.d4.loss_dice: 1.2794  decode.d5.loss_cls: 0.0437  decode.d5.loss_mask: 0.7258  decode.d5.loss_dice: 1.2559  decode.d6.loss_cls: 0.0356  decode.d6.loss_mask: 0.7457  decode.d6.loss_dice: 1.2725  decode.d7.loss_cls: 0.0357  decode.d7.loss_mask: 0.7565  decode.d7.loss_dice: 1.2648  decode.d8.loss_cls: 0.0347  decode.d8.loss_mask: 0.7439  decode.d8.loss_dice: 1.2757
11/15 08:07:23 - mmengine - INFO - Iter(train) [ 7800/90000]  base_lr: 9.2166e-05 lr: 9.2166e-06  eta: 13:55:36  time: 0.5972  data_time: 0.0099  memory: 10692  grad_norm: 448.4747  loss: 22.5039  decode.loss_cls: 0.0700  decode.loss_mask: 0.6887  decode.loss_dice: 1.4787  decode.d0.loss_cls: 0.1047  decode.d0.loss_mask: 0.7132  decode.d0.loss_dice: 1.5881  decode.d1.loss_cls: 0.1142  decode.d1.loss_mask: 0.6634  decode.d1.loss_dice: 1.4629  decode.d2.loss_cls: 0.0923  decode.d2.loss_mask: 0.6747  decode.d2.loss_dice: 1.4783  decode.d3.loss_cls: 0.0938  decode.d3.loss_mask: 0.6825  decode.d3.loss_dice: 1.4502  decode.d4.loss_cls: 0.1044  decode.d4.loss_mask: 0.6545  decode.d4.loss_dice: 1.4688  decode.d5.loss_cls: 0.0816  decode.d5.loss_mask: 0.6744  decode.d5.loss_dice: 1.4838  decode.d6.loss_cls: 0.0821  decode.d6.loss_mask: 0.6911  decode.d6.loss_dice: 1.4337  decode.d7.loss_cls: 0.0892  decode.d7.loss_mask: 0.6827  decode.d7.loss_dice: 1.4592  decode.d8.loss_cls: 0.0884  decode.d8.loss_mask: 0.6870  decode.d8.loss_dice: 1.4673
11/15 08:07:53 - mmengine - INFO - Iter(train) [ 7850/90000]  base_lr: 9.2116e-05 lr: 9.2116e-06  eta: 13:54:59  time: 0.5977  data_time: 0.0099  memory: 10758  grad_norm: 624.6661  loss: 25.3468  decode.loss_cls: 0.1119  decode.loss_mask: 0.7797  decode.loss_dice: 1.6447  decode.d0.loss_cls: 0.1069  decode.d0.loss_mask: 0.7471  decode.d0.loss_dice: 1.6825  decode.d1.loss_cls: 0.0908  decode.d1.loss_mask: 0.7421  decode.d1.loss_dice: 1.6562  decode.d2.loss_cls: 0.0955  decode.d2.loss_mask: 0.7100  decode.d2.loss_dice: 1.6217  decode.d3.loss_cls: 0.0958  decode.d3.loss_mask: 0.7807  decode.d3.loss_dice: 1.6510  decode.d4.loss_cls: 0.1061  decode.d4.loss_mask: 0.7856  decode.d4.loss_dice: 1.6574  decode.d5.loss_cls: 0.0969  decode.d5.loss_mask: 0.7915  decode.d5.loss_dice: 1.6512  decode.d6.loss_cls: 0.1043  decode.d6.loss_mask: 0.8044  decode.d6.loss_dice: 1.6951  decode.d7.loss_cls: 0.1097  decode.d7.loss_mask: 0.8097  decode.d7.loss_dice: 1.6583  decode.d8.loss_cls: 0.1060  decode.d8.loss_mask: 0.8018  decode.d8.loss_dice: 1.6522
11/15 08:08:23 - mmengine - INFO - Iter(train) [ 7900/90000]  base_lr: 9.2065e-05 lr: 9.2065e-06  eta: 13:54:22  time: 0.5974  data_time: 0.0099  memory: 10675  grad_norm: 438.5854  loss: 21.4949  decode.loss_cls: 0.0710  decode.loss_mask: 0.6703  decode.loss_dice: 1.3898  decode.d0.loss_cls: 0.1116  decode.d0.loss_mask: 0.6827  decode.d0.loss_dice: 1.4872  decode.d1.loss_cls: 0.0783  decode.d1.loss_mask: 0.6566  decode.d1.loss_dice: 1.4033  decode.d2.loss_cls: 0.0775  decode.d2.loss_mask: 0.6613  decode.d2.loss_dice: 1.3738  decode.d3.loss_cls: 0.0705  decode.d3.loss_mask: 0.6591  decode.d3.loss_dice: 1.3872  decode.d4.loss_cls: 0.0765  decode.d4.loss_mask: 0.6486  decode.d4.loss_dice: 1.4160  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 0.6507  decode.d5.loss_dice: 1.4144  decode.d6.loss_cls: 0.0788  decode.d6.loss_mask: 0.6621  decode.d6.loss_dice: 1.4056  decode.d7.loss_cls: 0.0725  decode.d7.loss_mask: 0.6598  decode.d7.loss_dice: 1.4365  decode.d8.loss_cls: 0.0820  decode.d8.loss_mask: 0.6630  decode.d8.loss_dice: 1.3783
11/15 08:08:53 - mmengine - INFO - Iter(train) [ 7950/90000]  base_lr: 9.2015e-05 lr: 9.2015e-06  eta: 13:53:45  time: 0.5960  data_time: 0.0098  memory: 10692  grad_norm: 491.9407  loss: 23.6974  decode.loss_cls: 0.0846  decode.loss_mask: 0.7653  decode.loss_dice: 1.5516  decode.d0.loss_cls: 0.1044  decode.d0.loss_mask: 0.7638  decode.d0.loss_dice: 1.5745  decode.d1.loss_cls: 0.0913  decode.d1.loss_mask: 0.7294  decode.d1.loss_dice: 1.5144  decode.d2.loss_cls: 0.0925  decode.d2.loss_mask: 0.7349  decode.d2.loss_dice: 1.4910  decode.d3.loss_cls: 0.1108  decode.d3.loss_mask: 0.7260  decode.d3.loss_dice: 1.5086  decode.d4.loss_cls: 0.0975  decode.d4.loss_mask: 0.7529  decode.d4.loss_dice: 1.5376  decode.d5.loss_cls: 0.0963  decode.d5.loss_mask: 0.7430  decode.d5.loss_dice: 1.4983  decode.d6.loss_cls: 0.0951  decode.d6.loss_mask: 0.7580  decode.d6.loss_dice: 1.5024  decode.d7.loss_cls: 0.0909  decode.d7.loss_mask: 0.7426  decode.d7.loss_dice: 1.5278  decode.d8.loss_cls: 0.0901  decode.d8.loss_mask: 0.7752  decode.d8.loss_dice: 1.5463
11/15 08:09:23 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 08:09:23 - mmengine - INFO - Iter(train) [ 8000/90000]  base_lr: 9.1964e-05 lr: 9.1964e-06  eta: 13:53:09  time: 0.6001  data_time: 0.0100  memory: 10641  grad_norm: 976.9407  loss: 20.5728  decode.loss_cls: 0.0818  decode.loss_mask: 0.5873  decode.loss_dice: 1.3598  decode.d0.loss_cls: 0.0888  decode.d0.loss_mask: 0.5959  decode.d0.loss_dice: 1.4449  decode.d1.loss_cls: 0.0638  decode.d1.loss_mask: 0.5941  decode.d1.loss_dice: 1.3853  decode.d2.loss_cls: 0.0770  decode.d2.loss_mask: 0.5848  decode.d2.loss_dice: 1.3710  decode.d3.loss_cls: 0.0855  decode.d3.loss_mask: 0.5914  decode.d3.loss_dice: 1.3718  decode.d4.loss_cls: 0.0824  decode.d4.loss_mask: 0.6061  decode.d4.loss_dice: 1.3845  decode.d5.loss_cls: 0.0918  decode.d5.loss_mask: 0.5877  decode.d5.loss_dice: 1.3675  decode.d6.loss_cls: 0.1022  decode.d6.loss_mask: 0.5890  decode.d6.loss_dice: 1.3542  decode.d7.loss_cls: 0.0843  decode.d7.loss_mask: 0.5862  decode.d7.loss_dice: 1.3887  decode.d8.loss_cls: 0.0770  decode.d8.loss_mask: 0.5939  decode.d8.loss_dice: 1.3938
11/15 08:09:53 - mmengine - INFO - Iter(train) [ 8050/90000]  base_lr: 9.1914e-05 lr: 9.1914e-06  eta: 13:52:34  time: 0.6010  data_time: 0.0101  memory: 10713  grad_norm: 250.3167  loss: 20.6985  decode.loss_cls: 0.1007  decode.loss_mask: 0.6499  decode.loss_dice: 1.3433  decode.d0.loss_cls: 0.0935  decode.d0.loss_mask: 0.6446  decode.d0.loss_dice: 1.4369  decode.d1.loss_cls: 0.0781  decode.d1.loss_mask: 0.6273  decode.d1.loss_dice: 1.3693  decode.d2.loss_cls: 0.0832  decode.d2.loss_mask: 0.6317  decode.d2.loss_dice: 1.3448  decode.d3.loss_cls: 0.0824  decode.d3.loss_mask: 0.6358  decode.d3.loss_dice: 1.3350  decode.d4.loss_cls: 0.0913  decode.d4.loss_mask: 0.6233  decode.d4.loss_dice: 1.3001  decode.d5.loss_cls: 0.0819  decode.d5.loss_mask: 0.6318  decode.d5.loss_dice: 1.3309  decode.d6.loss_cls: 0.0930  decode.d6.loss_mask: 0.6383  decode.d6.loss_dice: 1.3454  decode.d7.loss_cls: 0.0805  decode.d7.loss_mask: 0.6262  decode.d7.loss_dice: 1.3379  decode.d8.loss_cls: 0.0949  decode.d8.loss_mask: 0.6241  decode.d8.loss_dice: 1.3424
11/15 08:10:23 - mmengine - INFO - Iter(train) [ 8100/90000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 13:52:00  time: 0.6165  data_time: 0.0098  memory: 10713  grad_norm: 311.8709  loss: 24.7744  decode.loss_cls: 0.1404  decode.loss_mask: 0.7326  decode.loss_dice: 1.6032  decode.d0.loss_cls: 0.1186  decode.d0.loss_mask: 0.7760  decode.d0.loss_dice: 1.6817  decode.d1.loss_cls: 0.1068  decode.d1.loss_mask: 0.7203  decode.d1.loss_dice: 1.6416  decode.d2.loss_cls: 0.1103  decode.d2.loss_mask: 0.7139  decode.d2.loss_dice: 1.6036  decode.d3.loss_cls: 0.1139  decode.d3.loss_mask: 0.7113  decode.d3.loss_dice: 1.5948  decode.d4.loss_cls: 0.1174  decode.d4.loss_mask: 0.7330  decode.d4.loss_dice: 1.6049  decode.d5.loss_cls: 0.1129  decode.d5.loss_mask: 0.7487  decode.d5.loss_dice: 1.6096  decode.d6.loss_cls: 0.1325  decode.d6.loss_mask: 0.7521  decode.d6.loss_dice: 1.6040  decode.d7.loss_cls: 0.1163  decode.d7.loss_mask: 0.7605  decode.d7.loss_dice: 1.6203  decode.d8.loss_cls: 0.1223  decode.d8.loss_mask: 0.7488  decode.d8.loss_dice: 1.6219
11/15 08:10:54 - mmengine - INFO - Iter(train) [ 8150/90000]  base_lr: 9.1813e-05 lr: 9.1813e-06  eta: 13:51:31  time: 0.6003  data_time: 0.0101  memory: 10692  grad_norm: 399.6376  loss: 22.0757  decode.loss_cls: 0.1134  decode.loss_mask: 0.6379  decode.loss_dice: 1.4501  decode.d0.loss_cls: 0.1031  decode.d0.loss_mask: 0.6339  decode.d0.loss_dice: 1.5372  decode.d1.loss_cls: 0.1001  decode.d1.loss_mask: 0.5943  decode.d1.loss_dice: 1.4557  decode.d2.loss_cls: 0.0984  decode.d2.loss_mask: 0.6082  decode.d2.loss_dice: 1.4488  decode.d3.loss_cls: 0.1062  decode.d3.loss_mask: 0.6295  decode.d3.loss_dice: 1.4524  decode.d4.loss_cls: 0.1039  decode.d4.loss_mask: 0.6272  decode.d4.loss_dice: 1.4499  decode.d5.loss_cls: 0.1105  decode.d5.loss_mask: 0.6366  decode.d5.loss_dice: 1.4664  decode.d6.loss_cls: 0.1168  decode.d6.loss_mask: 0.6300  decode.d6.loss_dice: 1.4514  decode.d7.loss_cls: 0.1224  decode.d7.loss_mask: 0.6644  decode.d7.loss_dice: 1.4775  decode.d8.loss_cls: 0.1229  decode.d8.loss_mask: 0.6526  decode.d8.loss_dice: 1.4739
11/15 08:11:23 - mmengine - INFO - Iter(train) [ 8200/90000]  base_lr: 9.1762e-05 lr: 9.1762e-06  eta: 13:50:55  time: 0.5970  data_time: 0.0098  memory: 10713  grad_norm: 375.9272  loss: 19.4742  decode.loss_cls: 0.0915  decode.loss_mask: 0.5842  decode.loss_dice: 1.2606  decode.d0.loss_cls: 0.1020  decode.d0.loss_mask: 0.6019  decode.d0.loss_dice: 1.3347  decode.d1.loss_cls: 0.0904  decode.d1.loss_mask: 0.5872  decode.d1.loss_dice: 1.2849  decode.d2.loss_cls: 0.0855  decode.d2.loss_mask: 0.5883  decode.d2.loss_dice: 1.2919  decode.d3.loss_cls: 0.1038  decode.d3.loss_mask: 0.5884  decode.d3.loss_dice: 1.2539  decode.d4.loss_cls: 0.0966  decode.d4.loss_mask: 0.5880  decode.d4.loss_dice: 1.2620  decode.d5.loss_cls: 0.0953  decode.d5.loss_mask: 0.5912  decode.d5.loss_dice: 1.2182  decode.d6.loss_cls: 0.0979  decode.d6.loss_mask: 0.5948  decode.d6.loss_dice: 1.2319  decode.d7.loss_cls: 0.0944  decode.d7.loss_mask: 0.5890  decode.d7.loss_dice: 1.2422  decode.d8.loss_cls: 0.0912  decode.d8.loss_mask: 0.5996  decode.d8.loss_dice: 1.2329
11/15 08:11:53 - mmengine - INFO - Iter(train) [ 8250/90000]  base_lr: 9.1712e-05 lr: 9.1712e-06  eta: 13:50:19  time: 0.5976  data_time: 0.0099  memory: 10713  grad_norm: 276.8870  loss: 20.6233  decode.loss_cls: 0.0954  decode.loss_mask: 0.5428  decode.loss_dice: 1.4056  decode.d0.loss_cls: 0.1279  decode.d0.loss_mask: 0.5551  decode.d0.loss_dice: 1.4932  decode.d1.loss_cls: 0.1042  decode.d1.loss_mask: 0.5445  decode.d1.loss_dice: 1.4332  decode.d2.loss_cls: 0.0953  decode.d2.loss_mask: 0.5494  decode.d2.loss_dice: 1.3946  decode.d3.loss_cls: 0.1112  decode.d3.loss_mask: 0.5568  decode.d3.loss_dice: 1.3977  decode.d4.loss_cls: 0.1096  decode.d4.loss_mask: 0.5513  decode.d4.loss_dice: 1.3973  decode.d5.loss_cls: 0.1056  decode.d5.loss_mask: 0.5513  decode.d5.loss_dice: 1.3934  decode.d6.loss_cls: 0.0854  decode.d6.loss_mask: 0.5548  decode.d6.loss_dice: 1.4255  decode.d7.loss_cls: 0.1044  decode.d7.loss_mask: 0.5394  decode.d7.loss_dice: 1.3975  decode.d8.loss_cls: 0.0914  decode.d8.loss_mask: 0.5387  decode.d8.loss_dice: 1.3707
11/15 08:12:23 - mmengine - INFO - Iter(train) [ 8300/90000]  base_lr: 9.1661e-05 lr: 9.1661e-06  eta: 13:49:43  time: 0.5977  data_time: 0.0102  memory: 10656  grad_norm: 457.5016  loss: 23.0462  decode.loss_cls: 0.0699  decode.loss_mask: 0.7037  decode.loss_dice: 1.5483  decode.d0.loss_cls: 0.1029  decode.d0.loss_mask: 0.6953  decode.d0.loss_dice: 1.6255  decode.d1.loss_cls: 0.0902  decode.d1.loss_mask: 0.6820  decode.d1.loss_dice: 1.5487  decode.d2.loss_cls: 0.0669  decode.d2.loss_mask: 0.6919  decode.d2.loss_dice: 1.5234  decode.d3.loss_cls: 0.0795  decode.d3.loss_mask: 0.6922  decode.d3.loss_dice: 1.4944  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 0.6660  decode.d4.loss_dice: 1.5316  decode.d5.loss_cls: 0.0646  decode.d5.loss_mask: 0.6804  decode.d5.loss_dice: 1.5306  decode.d6.loss_cls: 0.0786  decode.d6.loss_mask: 0.6627  decode.d6.loss_dice: 1.5174  decode.d7.loss_cls: 0.0749  decode.d7.loss_mask: 0.7037  decode.d7.loss_dice: 1.5332  decode.d8.loss_cls: 0.0706  decode.d8.loss_mask: 0.7006  decode.d8.loss_dice: 1.5367
11/15 08:12:56 - mmengine - INFO - Iter(train) [ 8350/90000]  base_lr: 9.1611e-05 lr: 9.1611e-06  eta: 13:49:30  time: 0.5981  data_time: 0.0102  memory: 10675  grad_norm: 268.1772  loss: 21.0459  decode.loss_cls: 0.0905  decode.loss_mask: 0.7275  decode.loss_dice: 1.3354  decode.d0.loss_cls: 0.1084  decode.d0.loss_mask: 0.7073  decode.d0.loss_dice: 1.3353  decode.d1.loss_cls: 0.0793  decode.d1.loss_mask: 0.6878  decode.d1.loss_dice: 1.2818  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.6953  decode.d2.loss_dice: 1.2865  decode.d3.loss_cls: 0.0887  decode.d3.loss_mask: 0.6906  decode.d3.loss_dice: 1.2899  decode.d4.loss_cls: 0.0968  decode.d4.loss_mask: 0.7174  decode.d4.loss_dice: 1.2955  decode.d5.loss_cls: 0.0915  decode.d5.loss_mask: 0.7165  decode.d5.loss_dice: 1.2980  decode.d6.loss_cls: 0.0965  decode.d6.loss_mask: 0.7031  decode.d6.loss_dice: 1.2861  decode.d7.loss_cls: 0.1009  decode.d7.loss_mask: 0.7494  decode.d7.loss_dice: 1.2962  decode.d8.loss_cls: 0.0896  decode.d8.loss_mask: 0.7453  decode.d8.loss_dice: 1.2775
11/15 08:13:26 - mmengine - INFO - Iter(train) [ 8400/90000]  base_lr: 9.1560e-05 lr: 9.1560e-06  eta: 13:48:55  time: 0.5996  data_time: 0.0101  memory: 10692  grad_norm: 415.8026  loss: 22.6683  decode.loss_cls: 0.0756  decode.loss_mask: 0.7069  decode.loss_dice: 1.4549  decode.d0.loss_cls: 0.1002  decode.d0.loss_mask: 0.7556  decode.d0.loss_dice: 1.5468  decode.d1.loss_cls: 0.0695  decode.d1.loss_mask: 0.7414  decode.d1.loss_dice: 1.4851  decode.d2.loss_cls: 0.0720  decode.d2.loss_mask: 0.7353  decode.d2.loss_dice: 1.4546  decode.d3.loss_cls: 0.0827  decode.d3.loss_mask: 0.7067  decode.d3.loss_dice: 1.4331  decode.d4.loss_cls: 0.0851  decode.d4.loss_mask: 0.7099  decode.d4.loss_dice: 1.4447  decode.d5.loss_cls: 0.0730  decode.d5.loss_mask: 0.7245  decode.d5.loss_dice: 1.4683  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.7329  decode.d6.loss_dice: 1.4623  decode.d7.loss_cls: 0.0791  decode.d7.loss_mask: 0.7155  decode.d7.loss_dice: 1.4496  decode.d8.loss_cls: 0.0785  decode.d8.loss_mask: 0.7169  decode.d8.loss_dice: 1.4378
11/15 08:13:56 - mmengine - INFO - Iter(train) [ 8450/90000]  base_lr: 9.1510e-05 lr: 9.1510e-06  eta: 13:48:19  time: 0.5983  data_time: 0.0101  memory: 10675  grad_norm: 575.4299  loss: 20.5137  decode.loss_cls: 0.0657  decode.loss_mask: 0.7364  decode.loss_dice: 1.2452  decode.d0.loss_cls: 0.1002  decode.d0.loss_mask: 0.7550  decode.d0.loss_dice: 1.2973  decode.d1.loss_cls: 0.0608  decode.d1.loss_mask: 0.7432  decode.d1.loss_dice: 1.2456  decode.d2.loss_cls: 0.0703  decode.d2.loss_mask: 0.7259  decode.d2.loss_dice: 1.2178  decode.d3.loss_cls: 0.0495  decode.d3.loss_mask: 0.7541  decode.d3.loss_dice: 1.2056  decode.d4.loss_cls: 0.0561  decode.d4.loss_mask: 0.7648  decode.d4.loss_dice: 1.2348  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.7473  decode.d5.loss_dice: 1.2233  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.7449  decode.d6.loss_dice: 1.2396  decode.d7.loss_cls: 0.0616  decode.d7.loss_mask: 0.7494  decode.d7.loss_dice: 1.2549  decode.d8.loss_cls: 0.0462  decode.d8.loss_mask: 0.7463  decode.d8.loss_dice: 1.2704
11/15 08:14:26 - mmengine - INFO - Iter(train) [ 8500/90000]  base_lr: 9.1459e-05 lr: 9.1459e-06  eta: 13:47:46  time: 0.5993  data_time: 0.0101  memory: 10692  grad_norm: 1399.0053  loss: 20.8122  decode.loss_cls: 0.0963  decode.loss_mask: 0.6897  decode.loss_dice: 1.2872  decode.d0.loss_cls: 0.1298  decode.d0.loss_mask: 0.6597  decode.d0.loss_dice: 1.3979  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.6953  decode.d1.loss_dice: 1.3138  decode.d2.loss_cls: 0.0741  decode.d2.loss_mask: 0.6888  decode.d2.loss_dice: 1.3134  decode.d3.loss_cls: 0.0837  decode.d3.loss_mask: 0.6796  decode.d3.loss_dice: 1.2903  decode.d4.loss_cls: 0.0639  decode.d4.loss_mask: 0.7016  decode.d4.loss_dice: 1.3059  decode.d5.loss_cls: 0.0899  decode.d5.loss_mask: 0.6967  decode.d5.loss_dice: 1.2667  decode.d6.loss_cls: 0.0746  decode.d6.loss_mask: 0.7029  decode.d6.loss_dice: 1.2789  decode.d7.loss_cls: 0.0800  decode.d7.loss_mask: 0.6879  decode.d7.loss_dice: 1.3123  decode.d8.loss_cls: 0.0917  decode.d8.loss_mask: 0.6964  decode.d8.loss_dice: 1.2840
11/15 08:14:56 - mmengine - INFO - Iter(train) [ 8550/90000]  base_lr: 9.1409e-05 lr: 9.1409e-06  eta: 13:47:10  time: 0.5977  data_time: 0.0096  memory: 10656  grad_norm: 605.7126  loss: 23.3686  decode.loss_cls: 0.1099  decode.loss_mask: 0.7334  decode.loss_dice: 1.5041  decode.d0.loss_cls: 0.1036  decode.d0.loss_mask: 0.7498  decode.d0.loss_dice: 1.5947  decode.d1.loss_cls: 0.1214  decode.d1.loss_mask: 0.6991  decode.d1.loss_dice: 1.5197  decode.d2.loss_cls: 0.1313  decode.d2.loss_mask: 0.6926  decode.d2.loss_dice: 1.4865  decode.d3.loss_cls: 0.1185  decode.d3.loss_mask: 0.7073  decode.d3.loss_dice: 1.4782  decode.d4.loss_cls: 0.1271  decode.d4.loss_mask: 0.7271  decode.d4.loss_dice: 1.4733  decode.d5.loss_cls: 0.1247  decode.d5.loss_mask: 0.7143  decode.d5.loss_dice: 1.4890  decode.d6.loss_cls: 0.1145  decode.d6.loss_mask: 0.7265  decode.d6.loss_dice: 1.4857  decode.d7.loss_cls: 0.1069  decode.d7.loss_mask: 0.7159  decode.d7.loss_dice: 1.4884  decode.d8.loss_cls: 0.1063  decode.d8.loss_mask: 0.7168  decode.d8.loss_dice: 1.5021
11/15 08:15:25 - mmengine - INFO - Iter(train) [ 8600/90000]  base_lr: 9.1358e-05 lr: 9.1358e-06  eta: 13:46:34  time: 0.5982  data_time: 0.0110  memory: 10692  grad_norm: 409.7848  loss: 23.3589  decode.loss_cls: 0.1007  decode.loss_mask: 0.6879  decode.loss_dice: 1.5358  decode.d0.loss_cls: 0.1034  decode.d0.loss_mask: 0.6894  decode.d0.loss_dice: 1.6021  decode.d1.loss_cls: 0.0946  decode.d1.loss_mask: 0.6918  decode.d1.loss_dice: 1.5432  decode.d2.loss_cls: 0.0996  decode.d2.loss_mask: 0.6706  decode.d2.loss_dice: 1.5511  decode.d3.loss_cls: 0.1039  decode.d3.loss_mask: 0.6867  decode.d3.loss_dice: 1.5435  decode.d4.loss_cls: 0.1009  decode.d4.loss_mask: 0.6886  decode.d4.loss_dice: 1.5621  decode.d5.loss_cls: 0.0955  decode.d5.loss_mask: 0.6878  decode.d5.loss_dice: 1.5213  decode.d6.loss_cls: 0.1082  decode.d6.loss_mask: 0.6934  decode.d6.loss_dice: 1.5386  decode.d7.loss_cls: 0.1046  decode.d7.loss_mask: 0.6809  decode.d7.loss_dice: 1.5380  decode.d8.loss_cls: 0.1012  decode.d8.loss_mask: 0.6881  decode.d8.loss_dice: 1.5455
11/15 08:15:55 - mmengine - INFO - Iter(train) [ 8650/90000]  base_lr: 9.1308e-05 lr: 9.1308e-06  eta: 13:45:58  time: 0.5960  data_time: 0.0100  memory: 10656  grad_norm: 412.3961  loss: 20.7431  decode.loss_cls: 0.0509  decode.loss_mask: 0.7237  decode.loss_dice: 1.2540  decode.d0.loss_cls: 0.0873  decode.d0.loss_mask: 0.7834  decode.d0.loss_dice: 1.3197  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.7310  decode.d1.loss_dice: 1.2880  decode.d2.loss_cls: 0.0390  decode.d2.loss_mask: 0.7344  decode.d2.loss_dice: 1.2910  decode.d3.loss_cls: 0.0464  decode.d3.loss_mask: 0.7124  decode.d3.loss_dice: 1.2613  decode.d4.loss_cls: 0.0448  decode.d4.loss_mask: 0.7122  decode.d4.loss_dice: 1.2924  decode.d5.loss_cls: 0.0634  decode.d5.loss_mask: 0.7364  decode.d5.loss_dice: 1.2752  decode.d6.loss_cls: 0.0483  decode.d6.loss_mask: 0.7409  decode.d6.loss_dice: 1.2903  decode.d7.loss_cls: 0.0358  decode.d7.loss_mask: 0.7460  decode.d7.loss_dice: 1.3187  decode.d8.loss_cls: 0.0532  decode.d8.loss_mask: 0.7200  decode.d8.loss_dice: 1.2909
11/15 08:16:25 - mmengine - INFO - Iter(train) [ 8700/90000]  base_lr: 9.1257e-05 lr: 9.1257e-06  eta: 13:45:24  time: 0.6012  data_time: 0.0099  memory: 10656  grad_norm: 403.6007  loss: 22.9393  decode.loss_cls: 0.0859  decode.loss_mask: 0.5615  decode.loss_dice: 1.6055  decode.d0.loss_cls: 0.0971  decode.d0.loss_mask: 0.5971  decode.d0.loss_dice: 1.6954  decode.d1.loss_cls: 0.1066  decode.d1.loss_mask: 0.5637  decode.d1.loss_dice: 1.6295  decode.d2.loss_cls: 0.0807  decode.d2.loss_mask: 0.5719  decode.d2.loss_dice: 1.6407  decode.d3.loss_cls: 0.1097  decode.d3.loss_mask: 0.5535  decode.d3.loss_dice: 1.5996  decode.d4.loss_cls: 0.0931  decode.d4.loss_mask: 0.5556  decode.d4.loss_dice: 1.6307  decode.d5.loss_cls: 0.1167  decode.d5.loss_mask: 0.5572  decode.d5.loss_dice: 1.6394  decode.d6.loss_cls: 0.1120  decode.d6.loss_mask: 0.5514  decode.d6.loss_dice: 1.6408  decode.d7.loss_cls: 0.0986  decode.d7.loss_mask: 0.5607  decode.d7.loss_dice: 1.6149  decode.d8.loss_cls: 0.0976  decode.d8.loss_mask: 0.5607  decode.d8.loss_dice: 1.6117
11/15 08:16:55 - mmengine - INFO - Iter(train) [ 8750/90000]  base_lr: 9.1207e-05 lr: 9.1207e-06  eta: 13:44:49  time: 0.5993  data_time: 0.0101  memory: 10656  grad_norm: 555.1888  loss: 22.8868  decode.loss_cls: 0.1241  decode.loss_mask: 0.6467  decode.loss_dice: 1.5195  decode.d0.loss_cls: 0.1047  decode.d0.loss_mask: 0.6764  decode.d0.loss_dice: 1.6030  decode.d1.loss_cls: 0.1357  decode.d1.loss_mask: 0.6515  decode.d1.loss_dice: 1.4976  decode.d2.loss_cls: 0.1418  decode.d2.loss_mask: 0.6613  decode.d2.loss_dice: 1.4661  decode.d3.loss_cls: 0.1207  decode.d3.loss_mask: 0.6746  decode.d3.loss_dice: 1.4906  decode.d4.loss_cls: 0.1219  decode.d4.loss_mask: 0.6658  decode.d4.loss_dice: 1.5024  decode.d5.loss_cls: 0.1121  decode.d5.loss_mask: 0.6499  decode.d5.loss_dice: 1.4933  decode.d6.loss_cls: 0.1263  decode.d6.loss_mask: 0.6523  decode.d6.loss_dice: 1.4761  decode.d7.loss_cls: 0.1282  decode.d7.loss_mask: 0.6600  decode.d7.loss_dice: 1.5067  decode.d8.loss_cls: 0.1185  decode.d8.loss_mask: 0.6496  decode.d8.loss_dice: 1.5096
11/15 08:17:25 - mmengine - INFO - Iter(train) [ 8800/90000]  base_lr: 9.1156e-05 lr: 9.1156e-06  eta: 13:44:14  time: 0.6004  data_time: 0.0102  memory: 10675  grad_norm: 363.1511  loss: 20.8100  decode.loss_cls: 0.0713  decode.loss_mask: 0.5968  decode.loss_dice: 1.3770  decode.d0.loss_cls: 0.0840  decode.d0.loss_mask: 0.6227  decode.d0.loss_dice: 1.4470  decode.d1.loss_cls: 0.0609  decode.d1.loss_mask: 0.6117  decode.d1.loss_dice: 1.4065  decode.d2.loss_cls: 0.0673  decode.d2.loss_mask: 0.6281  decode.d2.loss_dice: 1.3895  decode.d3.loss_cls: 0.0700  decode.d3.loss_mask: 0.6213  decode.d3.loss_dice: 1.4211  decode.d4.loss_cls: 0.0753  decode.d4.loss_mask: 0.6178  decode.d4.loss_dice: 1.3816  decode.d5.loss_cls: 0.0670  decode.d5.loss_mask: 0.6157  decode.d5.loss_dice: 1.3625  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 0.6136  decode.d6.loss_dice: 1.3743  decode.d7.loss_cls: 0.0672  decode.d7.loss_mask: 0.6135  decode.d7.loss_dice: 1.3701  decode.d8.loss_cls: 0.0781  decode.d8.loss_mask: 0.6220  decode.d8.loss_dice: 1.3925
11/15 08:17:55 - mmengine - INFO - Iter(train) [ 8850/90000]  base_lr: 9.1106e-05 lr: 9.1106e-06  eta: 13:43:40  time: 0.5990  data_time: 0.0097  memory: 10713  grad_norm: 387.8829  loss: 21.6614  decode.loss_cls: 0.0641  decode.loss_mask: 0.6631  decode.loss_dice: 1.4350  decode.d0.loss_cls: 0.0919  decode.d0.loss_mask: 0.6662  decode.d0.loss_dice: 1.4573  decode.d1.loss_cls: 0.0828  decode.d1.loss_mask: 0.6415  decode.d1.loss_dice: 1.4068  decode.d2.loss_cls: 0.0777  decode.d2.loss_mask: 0.6686  decode.d2.loss_dice: 1.4121  decode.d3.loss_cls: 0.0812  decode.d3.loss_mask: 0.6845  decode.d3.loss_dice: 1.4232  decode.d4.loss_cls: 0.0704  decode.d4.loss_mask: 0.6648  decode.d4.loss_dice: 1.3816  decode.d5.loss_cls: 0.0764  decode.d5.loss_mask: 0.6916  decode.d5.loss_dice: 1.4375  decode.d6.loss_cls: 0.0815  decode.d6.loss_mask: 0.6960  decode.d6.loss_dice: 1.4205  decode.d7.loss_cls: 0.0810  decode.d7.loss_mask: 0.6702  decode.d7.loss_dice: 1.4092  decode.d8.loss_cls: 0.0780  decode.d8.loss_mask: 0.6617  decode.d8.loss_dice: 1.3851
11/15 08:18:25 - mmengine - INFO - Iter(train) [ 8900/90000]  base_lr: 9.1055e-05 lr: 9.1055e-06  eta: 13:43:05  time: 0.6018  data_time: 0.0103  memory: 10675  grad_norm: 388.7645  loss: 21.9284  decode.loss_cls: 0.0925  decode.loss_mask: 0.6923  decode.loss_dice: 1.3871  decode.d0.loss_cls: 0.1099  decode.d0.loss_mask: 0.7245  decode.d0.loss_dice: 1.4549  decode.d1.loss_cls: 0.0732  decode.d1.loss_mask: 0.7319  decode.d1.loss_dice: 1.3957  decode.d2.loss_cls: 0.0993  decode.d2.loss_mask: 0.7264  decode.d2.loss_dice: 1.3851  decode.d3.loss_cls: 0.0845  decode.d3.loss_mask: 0.7022  decode.d3.loss_dice: 1.4109  decode.d4.loss_cls: 0.1022  decode.d4.loss_mask: 0.6911  decode.d4.loss_dice: 1.3696  decode.d5.loss_cls: 0.0969  decode.d5.loss_mask: 0.6925  decode.d5.loss_dice: 1.3858  decode.d6.loss_cls: 0.0873  decode.d6.loss_mask: 0.7074  decode.d6.loss_dice: 1.3842  decode.d7.loss_cls: 0.1025  decode.d7.loss_mask: 0.6994  decode.d7.loss_dice: 1.3889  decode.d8.loss_cls: 0.0834  decode.d8.loss_mask: 0.6941  decode.d8.loss_dice: 1.3726
11/15 08:18:55 - mmengine - INFO - Iter(train) [ 8950/90000]  base_lr: 9.1005e-05 lr: 9.1005e-06  eta: 13:42:31  time: 0.6008  data_time: 0.0099  memory: 10728  grad_norm: 454.7168  loss: 22.0266  decode.loss_cls: 0.1080  decode.loss_mask: 0.6400  decode.loss_dice: 1.4251  decode.d0.loss_cls: 0.0913  decode.d0.loss_mask: 0.6562  decode.d0.loss_dice: 1.6091  decode.d1.loss_cls: 0.0889  decode.d1.loss_mask: 0.6394  decode.d1.loss_dice: 1.4834  decode.d2.loss_cls: 0.1096  decode.d2.loss_mask: 0.6451  decode.d2.loss_dice: 1.4435  decode.d3.loss_cls: 0.1119  decode.d3.loss_mask: 0.6305  decode.d3.loss_dice: 1.4213  decode.d4.loss_cls: 0.1085  decode.d4.loss_mask: 0.6286  decode.d4.loss_dice: 1.4276  decode.d5.loss_cls: 0.0886  decode.d5.loss_mask: 0.6366  decode.d5.loss_dice: 1.4567  decode.d6.loss_cls: 0.0862  decode.d6.loss_mask: 0.6423  decode.d6.loss_dice: 1.4503  decode.d7.loss_cls: 0.0977  decode.d7.loss_mask: 0.6462  decode.d7.loss_dice: 1.4498  decode.d8.loss_cls: 0.1059  decode.d8.loss_mask: 0.6401  decode.d8.loss_dice: 1.4584
11/15 08:19:25 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 08:19:25 - mmengine - INFO - Iter(train) [ 9000/90000]  base_lr: 9.0954e-05 lr: 9.0954e-06  eta: 13:41:56  time: 0.5968  data_time: 0.0096  memory: 10641  grad_norm: 424.8665  loss: 20.4492  decode.loss_cls: 0.0714  decode.loss_mask: 0.6564  decode.loss_dice: 1.3094  decode.d0.loss_cls: 0.0908  decode.d0.loss_mask: 0.6514  decode.d0.loss_dice: 1.3697  decode.d1.loss_cls: 0.0711  decode.d1.loss_mask: 0.6481  decode.d1.loss_dice: 1.3168  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.6532  decode.d2.loss_dice: 1.2967  decode.d3.loss_cls: 0.0671  decode.d3.loss_mask: 0.6488  decode.d3.loss_dice: 1.2815  decode.d4.loss_cls: 0.0644  decode.d4.loss_mask: 0.6667  decode.d4.loss_dice: 1.3046  decode.d5.loss_cls: 0.0673  decode.d5.loss_mask: 0.6764  decode.d5.loss_dice: 1.3041  decode.d6.loss_cls: 0.0699  decode.d6.loss_mask: 0.6842  decode.d6.loss_dice: 1.3260  decode.d7.loss_cls: 0.0692  decode.d7.loss_mask: 0.6756  decode.d7.loss_dice: 1.3100  decode.d8.loss_cls: 0.0719  decode.d8.loss_mask: 0.6606  decode.d8.loss_dice: 1.2928
11/15 08:19:55 - mmengine - INFO - Iter(train) [ 9050/90000]  base_lr: 9.0904e-05 lr: 9.0904e-06  eta: 13:41:22  time: 0.5968  data_time: 0.0097  memory: 10675  grad_norm: 830.3955  loss: 21.5523  decode.loss_cls: 0.0595  decode.loss_mask: 0.7244  decode.loss_dice: 1.3657  decode.d0.loss_cls: 0.1004  decode.d0.loss_mask: 0.7408  decode.d0.loss_dice: 1.4111  decode.d1.loss_cls: 0.0655  decode.d1.loss_mask: 0.7142  decode.d1.loss_dice: 1.3193  decode.d2.loss_cls: 0.0588  decode.d2.loss_mask: 0.7264  decode.d2.loss_dice: 1.3453  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.7337  decode.d3.loss_dice: 1.3522  decode.d4.loss_cls: 0.0603  decode.d4.loss_mask: 0.7435  decode.d4.loss_dice: 1.3446  decode.d5.loss_cls: 0.0589  decode.d5.loss_mask: 0.7396  decode.d5.loss_dice: 1.3471  decode.d6.loss_cls: 0.0654  decode.d6.loss_mask: 0.7303  decode.d6.loss_dice: 1.3516  decode.d7.loss_cls: 0.0568  decode.d7.loss_mask: 0.7589  decode.d7.loss_dice: 1.3701  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 0.7381  decode.d8.loss_dice: 1.3638
11/15 08:20:25 - mmengine - INFO - Iter(train) [ 9100/90000]  base_lr: 9.0853e-05 lr: 9.0853e-06  eta: 13:40:46  time: 0.5976  data_time: 0.0098  memory: 10713  grad_norm: 639.6797  loss: 21.9552  decode.loss_cls: 0.0787  decode.loss_mask: 0.7568  decode.loss_dice: 1.3493  decode.d0.loss_cls: 0.0910  decode.d0.loss_mask: 0.7436  decode.d0.loss_dice: 1.4028  decode.d1.loss_cls: 0.0779  decode.d1.loss_mask: 0.7505  decode.d1.loss_dice: 1.3582  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.7866  decode.d2.loss_dice: 1.3861  decode.d3.loss_cls: 0.0802  decode.d3.loss_mask: 0.6895  decode.d3.loss_dice: 1.3417  decode.d4.loss_cls: 0.0912  decode.d4.loss_mask: 0.6592  decode.d4.loss_dice: 1.3312  decode.d5.loss_cls: 0.0717  decode.d5.loss_mask: 0.7941  decode.d5.loss_dice: 1.3617  decode.d6.loss_cls: 0.0726  decode.d6.loss_mask: 0.7836  decode.d6.loss_dice: 1.3699  decode.d7.loss_cls: 0.0800  decode.d7.loss_mask: 0.7981  decode.d7.loss_dice: 1.3767  decode.d8.loss_cls: 0.0870  decode.d8.loss_mask: 0.7732  decode.d8.loss_dice: 1.3518
11/15 08:20:55 - mmengine - INFO - Iter(train) [ 9150/90000]  base_lr: 9.0803e-05 lr: 9.0803e-06  eta: 13:40:11  time: 0.5964  data_time: 0.0100  memory: 10675  grad_norm: 690.7758  loss: 24.5787  decode.loss_cls: 0.0933  decode.loss_mask: 0.7828  decode.loss_dice: 1.5421  decode.d0.loss_cls: 0.1074  decode.d0.loss_mask: 0.8082  decode.d0.loss_dice: 1.6027  decode.d1.loss_cls: 0.0918  decode.d1.loss_mask: 0.8052  decode.d1.loss_dice: 1.5484  decode.d2.loss_cls: 0.0753  decode.d2.loss_mask: 0.7909  decode.d2.loss_dice: 1.5541  decode.d3.loss_cls: 0.0709  decode.d3.loss_mask: 0.8230  decode.d3.loss_dice: 1.5767  decode.d4.loss_cls: 0.0987  decode.d4.loss_mask: 0.8019  decode.d4.loss_dice: 1.5191  decode.d5.loss_cls: 0.0848  decode.d5.loss_mask: 0.8052  decode.d5.loss_dice: 1.5629  decode.d6.loss_cls: 0.0987  decode.d6.loss_mask: 0.8082  decode.d6.loss_dice: 1.5617  decode.d7.loss_cls: 0.0846  decode.d7.loss_mask: 0.8135  decode.d7.loss_dice: 1.5687  decode.d8.loss_cls: 0.0830  decode.d8.loss_mask: 0.8099  decode.d8.loss_dice: 1.6050
11/15 08:21:25 - mmengine - INFO - Iter(train) [ 9200/90000]  base_lr: 9.0752e-05 lr: 9.0752e-06  eta: 13:39:36  time: 0.5963  data_time: 0.0102  memory: 10675  grad_norm: 477.0545  loss: 20.9403  decode.loss_cls: 0.0598  decode.loss_mask: 0.6330  decode.loss_dice: 1.3853  decode.d0.loss_cls: 0.1006  decode.d0.loss_mask: 0.6624  decode.d0.loss_dice: 1.4163  decode.d1.loss_cls: 0.0848  decode.d1.loss_mask: 0.6636  decode.d1.loss_dice: 1.3892  decode.d2.loss_cls: 0.0642  decode.d2.loss_mask: 0.6697  decode.d2.loss_dice: 1.3813  decode.d3.loss_cls: 0.0881  decode.d3.loss_mask: 0.6716  decode.d3.loss_dice: 1.3108  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.6646  decode.d4.loss_dice: 1.3309  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.6518  decode.d5.loss_dice: 1.3404  decode.d6.loss_cls: 0.0651  decode.d6.loss_mask: 0.6431  decode.d6.loss_dice: 1.3664  decode.d7.loss_cls: 0.0787  decode.d7.loss_mask: 0.6588  decode.d7.loss_dice: 1.3339  decode.d8.loss_cls: 0.0690  decode.d8.loss_mask: 0.6397  decode.d8.loss_dice: 1.3838
11/15 08:21:55 - mmengine - INFO - Iter(train) [ 9250/90000]  base_lr: 9.0701e-05 lr: 9.0701e-06  eta: 13:39:02  time: 0.5991  data_time: 0.0102  memory: 10656  grad_norm: 474.7154  loss: 24.9292  decode.loss_cls: 0.0999  decode.loss_mask: 0.7927  decode.loss_dice: 1.5647  decode.d0.loss_cls: 0.1085  decode.d0.loss_mask: 0.8387  decode.d0.loss_dice: 1.7195  decode.d1.loss_cls: 0.1137  decode.d1.loss_mask: 0.8280  decode.d1.loss_dice: 1.6411  decode.d2.loss_cls: 0.1031  decode.d2.loss_mask: 0.8218  decode.d2.loss_dice: 1.5616  decode.d3.loss_cls: 0.1102  decode.d3.loss_mask: 0.7958  decode.d3.loss_dice: 1.5756  decode.d4.loss_cls: 0.1030  decode.d4.loss_mask: 0.7922  decode.d4.loss_dice: 1.5800  decode.d5.loss_cls: 0.1039  decode.d5.loss_mask: 0.7986  decode.d5.loss_dice: 1.5189  decode.d6.loss_cls: 0.1029  decode.d6.loss_mask: 0.7938  decode.d6.loss_dice: 1.5370  decode.d7.loss_cls: 0.1069  decode.d7.loss_mask: 0.7952  decode.d7.loss_dice: 1.5634  decode.d8.loss_cls: 0.1081  decode.d8.loss_mask: 0.7862  decode.d8.loss_dice: 1.5645
11/15 08:22:26 - mmengine - INFO - Iter(train) [ 9300/90000]  base_lr: 9.0651e-05 lr: 9.0651e-06  eta: 13:38:32  time: 0.6510  data_time: 0.0102  memory: 10656  grad_norm: 287.3820  loss: 20.3058  decode.loss_cls: 0.0915  decode.loss_mask: 0.5736  decode.loss_dice: 1.3599  decode.d0.loss_cls: 0.0933  decode.d0.loss_mask: 0.6164  decode.d0.loss_dice: 1.4222  decode.d1.loss_cls: 0.0916  decode.d1.loss_mask: 0.5760  decode.d1.loss_dice: 1.3728  decode.d2.loss_cls: 0.0906  decode.d2.loss_mask: 0.5567  decode.d2.loss_dice: 1.3379  decode.d3.loss_cls: 0.0767  decode.d3.loss_mask: 0.5779  decode.d3.loss_dice: 1.3408  decode.d4.loss_cls: 0.0891  decode.d4.loss_mask: 0.5689  decode.d4.loss_dice: 1.3568  decode.d5.loss_cls: 0.0849  decode.d5.loss_mask: 0.5737  decode.d5.loss_dice: 1.3748  decode.d6.loss_cls: 0.0989  decode.d6.loss_mask: 0.5806  decode.d6.loss_dice: 1.3603  decode.d7.loss_cls: 0.0802  decode.d7.loss_mask: 0.5787  decode.d7.loss_dice: 1.3869  decode.d8.loss_cls: 0.0979  decode.d8.loss_mask: 0.5598  decode.d8.loss_dice: 1.3364
11/15 08:22:56 - mmengine - INFO - Iter(train) [ 9350/90000]  base_lr: 9.0600e-05 lr: 9.0600e-06  eta: 13:37:58  time: 0.5989  data_time: 0.0099  memory: 10656  grad_norm: 517.2472  loss: 21.2226  decode.loss_cls: 0.0889  decode.loss_mask: 0.6183  decode.loss_dice: 1.4312  decode.d0.loss_cls: 0.0917  decode.d0.loss_mask: 0.6159  decode.d0.loss_dice: 1.4418  decode.d1.loss_cls: 0.0614  decode.d1.loss_mask: 0.6250  decode.d1.loss_dice: 1.4209  decode.d2.loss_cls: 0.0750  decode.d2.loss_mask: 0.6110  decode.d2.loss_dice: 1.4106  decode.d3.loss_cls: 0.0831  decode.d3.loss_mask: 0.5976  decode.d3.loss_dice: 1.4107  decode.d4.loss_cls: 0.0922  decode.d4.loss_mask: 0.6009  decode.d4.loss_dice: 1.4072  decode.d5.loss_cls: 0.0786  decode.d5.loss_mask: 0.6115  decode.d5.loss_dice: 1.4394  decode.d6.loss_cls: 0.0774  decode.d6.loss_mask: 0.6020  decode.d6.loss_dice: 1.4482  decode.d7.loss_cls: 0.0840  decode.d7.loss_mask: 0.6213  decode.d7.loss_dice: 1.4282  decode.d8.loss_cls: 0.0900  decode.d8.loss_mask: 0.6254  decode.d8.loss_dice: 1.4334
11/15 08:23:26 - mmengine - INFO - Iter(train) [ 9400/90000]  base_lr: 9.0550e-05 lr: 9.0550e-06  eta: 13:37:23  time: 0.5991  data_time: 0.0099  memory: 10692  grad_norm: 459.7957  loss: 21.7998  decode.loss_cls: 0.0694  decode.loss_mask: 0.7121  decode.loss_dice: 1.4111  decode.d0.loss_cls: 0.0895  decode.d0.loss_mask: 0.7290  decode.d0.loss_dice: 1.4143  decode.d1.loss_cls: 0.0679  decode.d1.loss_mask: 0.7226  decode.d1.loss_dice: 1.3954  decode.d2.loss_cls: 0.0631  decode.d2.loss_mask: 0.7251  decode.d2.loss_dice: 1.3921  decode.d3.loss_cls: 0.0680  decode.d3.loss_mask: 0.7280  decode.d3.loss_dice: 1.4001  decode.d4.loss_cls: 0.0678  decode.d4.loss_mask: 0.7094  decode.d4.loss_dice: 1.3726  decode.d5.loss_cls: 0.0775  decode.d5.loss_mask: 0.7001  decode.d5.loss_dice: 1.3580  decode.d6.loss_cls: 0.0737  decode.d6.loss_mask: 0.7151  decode.d6.loss_dice: 1.4064  decode.d7.loss_cls: 0.0689  decode.d7.loss_mask: 0.7079  decode.d7.loss_dice: 1.3808  decode.d8.loss_cls: 0.0673  decode.d8.loss_mask: 0.7190  decode.d8.loss_dice: 1.3875
11/15 08:23:57 - mmengine - INFO - Iter(train) [ 9450/90000]  base_lr: 9.0499e-05 lr: 9.0499e-06  eta: 13:36:59  time: 0.5961  data_time: 0.0099  memory: 10713  grad_norm: 226.5595  loss: 22.0346  decode.loss_cls: 0.1275  decode.loss_mask: 0.6481  decode.loss_dice: 1.4102  decode.d0.loss_cls: 0.1143  decode.d0.loss_mask: 0.6666  decode.d0.loss_dice: 1.5373  decode.d1.loss_cls: 0.1091  decode.d1.loss_mask: 0.6622  decode.d1.loss_dice: 1.4614  decode.d2.loss_cls: 0.1271  decode.d2.loss_mask: 0.6540  decode.d2.loss_dice: 1.4257  decode.d3.loss_cls: 0.1281  decode.d3.loss_mask: 0.6686  decode.d3.loss_dice: 1.4141  decode.d4.loss_cls: 0.1173  decode.d4.loss_mask: 0.6624  decode.d4.loss_dice: 1.4179  decode.d5.loss_cls: 0.1334  decode.d5.loss_mask: 0.6618  decode.d5.loss_dice: 1.3972  decode.d6.loss_cls: 0.1227  decode.d6.loss_mask: 0.6494  decode.d6.loss_dice: 1.3997  decode.d7.loss_cls: 0.1248  decode.d7.loss_mask: 0.6440  decode.d7.loss_dice: 1.3772  decode.d8.loss_cls: 0.1223  decode.d8.loss_mask: 0.6355  decode.d8.loss_dice: 1.4143
11/15 08:24:27 - mmengine - INFO - Iter(train) [ 9500/90000]  base_lr: 9.0449e-05 lr: 9.0449e-06  eta: 13:36:24  time: 0.6033  data_time: 0.0102  memory: 10692  grad_norm: 272.4453  loss: 19.7621  decode.loss_cls: 0.0683  decode.loss_mask: 0.5678  decode.loss_dice: 1.3461  decode.d0.loss_cls: 0.0916  decode.d0.loss_mask: 0.6003  decode.d0.loss_dice: 1.3929  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.5594  decode.d1.loss_dice: 1.3304  decode.d2.loss_cls: 0.0666  decode.d2.loss_mask: 0.5620  decode.d2.loss_dice: 1.3300  decode.d3.loss_cls: 0.0634  decode.d3.loss_mask: 0.5605  decode.d3.loss_dice: 1.3008  decode.d4.loss_cls: 0.0690  decode.d4.loss_mask: 0.5672  decode.d4.loss_dice: 1.3155  decode.d5.loss_cls: 0.0736  decode.d5.loss_mask: 0.5677  decode.d5.loss_dice: 1.3158  decode.d6.loss_cls: 0.0722  decode.d6.loss_mask: 0.5626  decode.d6.loss_dice: 1.3182  decode.d7.loss_cls: 0.0733  decode.d7.loss_mask: 0.5721  decode.d7.loss_dice: 1.3200  decode.d8.loss_cls: 0.0786  decode.d8.loss_mask: 0.5706  decode.d8.loss_dice: 1.3784
11/15 08:24:57 - mmengine - INFO - Iter(train) [ 9550/90000]  base_lr: 9.0398e-05 lr: 9.0398e-06  eta: 13:35:51  time: 0.6022  data_time: 0.0102  memory: 10656  grad_norm: 312.9812  loss: 21.4541  decode.loss_cls: 0.0840  decode.loss_mask: 0.6978  decode.loss_dice: 1.3596  decode.d0.loss_cls: 0.0894  decode.d0.loss_mask: 0.7037  decode.d0.loss_dice: 1.4365  decode.d1.loss_cls: 0.0787  decode.d1.loss_mask: 0.6907  decode.d1.loss_dice: 1.3707  decode.d2.loss_cls: 0.0839  decode.d2.loss_mask: 0.6767  decode.d2.loss_dice: 1.3757  decode.d3.loss_cls: 0.0802  decode.d3.loss_mask: 0.6894  decode.d3.loss_dice: 1.3558  decode.d4.loss_cls: 0.0767  decode.d4.loss_mask: 0.6909  decode.d4.loss_dice: 1.3670  decode.d5.loss_cls: 0.0847  decode.d5.loss_mask: 0.6955  decode.d5.loss_dice: 1.3432  decode.d6.loss_cls: 0.0774  decode.d6.loss_mask: 0.6915  decode.d6.loss_dice: 1.3722  decode.d7.loss_cls: 0.0733  decode.d7.loss_mask: 0.7003  decode.d7.loss_dice: 1.3635  decode.d8.loss_cls: 0.0829  decode.d8.loss_mask: 0.6947  decode.d8.loss_dice: 1.3676
11/15 08:25:27 - mmengine - INFO - Iter(train) [ 9600/90000]  base_lr: 9.0348e-05 lr: 9.0348e-06  eta: 13:35:19  time: 0.6029  data_time: 0.0103  memory: 10713  grad_norm: 765.9356  loss: 24.2214  decode.loss_cls: 0.1042  decode.loss_mask: 0.7430  decode.loss_dice: 1.5415  decode.d0.loss_cls: 0.0982  decode.d0.loss_mask: 0.7711  decode.d0.loss_dice: 1.6200  decode.d1.loss_cls: 0.0793  decode.d1.loss_mask: 0.7431  decode.d1.loss_dice: 1.5807  decode.d2.loss_cls: 0.0918  decode.d2.loss_mask: 0.7550  decode.d2.loss_dice: 1.5530  decode.d3.loss_cls: 0.0860  decode.d3.loss_mask: 0.7686  decode.d3.loss_dice: 1.5410  decode.d4.loss_cls: 0.0878  decode.d4.loss_mask: 0.7695  decode.d4.loss_dice: 1.5753  decode.d5.loss_cls: 0.0901  decode.d5.loss_mask: 0.7802  decode.d5.loss_dice: 1.5651  decode.d6.loss_cls: 0.0969  decode.d6.loss_mask: 0.7903  decode.d6.loss_dice: 1.5659  decode.d7.loss_cls: 0.1100  decode.d7.loss_mask: 0.7612  decode.d7.loss_dice: 1.5589  decode.d8.loss_cls: 0.1049  decode.d8.loss_mask: 0.7612  decode.d8.loss_dice: 1.5279
11/15 08:25:57 - mmengine - INFO - Iter(train) [ 9650/90000]  base_lr: 9.0297e-05 lr: 9.0297e-06  eta: 13:34:47  time: 0.6042  data_time: 0.0104  memory: 10675  grad_norm: 370.3646  loss: 21.4471  decode.loss_cls: 0.0753  decode.loss_mask: 0.6996  decode.loss_dice: 1.3418  decode.d0.loss_cls: 0.0955  decode.d0.loss_mask: 0.7399  decode.d0.loss_dice: 1.4162  decode.d1.loss_cls: 0.0810  decode.d1.loss_mask: 0.6842  decode.d1.loss_dice: 1.3552  decode.d2.loss_cls: 0.0612  decode.d2.loss_mask: 0.6817  decode.d2.loss_dice: 1.3397  decode.d3.loss_cls: 0.0622  decode.d3.loss_mask: 0.7057  decode.d3.loss_dice: 1.3571  decode.d4.loss_cls: 0.0711  decode.d4.loss_mask: 0.6909  decode.d4.loss_dice: 1.3577  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 0.6876  decode.d5.loss_dice: 1.3433  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.7163  decode.d6.loss_dice: 1.3787  decode.d7.loss_cls: 0.0711  decode.d7.loss_mask: 0.7191  decode.d7.loss_dice: 1.3737  decode.d8.loss_cls: 0.0824  decode.d8.loss_mask: 0.7387  decode.d8.loss_dice: 1.3744
11/15 08:26:27 - mmengine - INFO - Iter(train) [ 9700/90000]  base_lr: 9.0246e-05 lr: 9.0246e-06  eta: 13:34:15  time: 0.6086  data_time: 0.0104  memory: 10675  grad_norm: 510.4835  loss: 20.9765  decode.loss_cls: 0.0551  decode.loss_mask: 0.6991  decode.loss_dice: 1.3158  decode.d0.loss_cls: 0.0831  decode.d0.loss_mask: 0.7128  decode.d0.loss_dice: 1.3551  decode.d1.loss_cls: 0.0511  decode.d1.loss_mask: 0.7095  decode.d1.loss_dice: 1.3773  decode.d2.loss_cls: 0.0424  decode.d2.loss_mask: 0.7213  decode.d2.loss_dice: 1.3400  decode.d3.loss_cls: 0.0471  decode.d3.loss_mask: 0.6888  decode.d3.loss_dice: 1.3168  decode.d4.loss_cls: 0.0496  decode.d4.loss_mask: 0.7026  decode.d4.loss_dice: 1.3220  decode.d5.loss_cls: 0.0474  decode.d5.loss_mask: 0.7109  decode.d5.loss_dice: 1.3223  decode.d6.loss_cls: 0.0531  decode.d6.loss_mask: 0.7051  decode.d6.loss_dice: 1.3154  decode.d7.loss_cls: 0.0568  decode.d7.loss_mask: 0.7189  decode.d7.loss_dice: 1.3568  decode.d8.loss_cls: 0.0554  decode.d8.loss_mask: 0.7005  decode.d8.loss_dice: 1.3446
11/15 08:26:57 - mmengine - INFO - Iter(train) [ 9750/90000]  base_lr: 9.0196e-05 lr: 9.0196e-06  eta: 13:33:42  time: 0.6014  data_time: 0.0101  memory: 10641  grad_norm: 425.4244  loss: 22.0749  decode.loss_cls: 0.0893  decode.loss_mask: 0.6645  decode.loss_dice: 1.4833  decode.d0.loss_cls: 0.0964  decode.d0.loss_mask: 0.6758  decode.d0.loss_dice: 1.5226  decode.d1.loss_cls: 0.0834  decode.d1.loss_mask: 0.6612  decode.d1.loss_dice: 1.4799  decode.d2.loss_cls: 0.0900  decode.d2.loss_mask: 0.6777  decode.d2.loss_dice: 1.4550  decode.d3.loss_cls: 0.0953  decode.d3.loss_mask: 0.6474  decode.d3.loss_dice: 1.4510  decode.d4.loss_cls: 0.0996  decode.d4.loss_mask: 0.6496  decode.d4.loss_dice: 1.4428  decode.d5.loss_cls: 0.1069  decode.d5.loss_mask: 0.6522  decode.d5.loss_dice: 1.4100  decode.d6.loss_cls: 0.1032  decode.d6.loss_mask: 0.6477  decode.d6.loss_dice: 1.4405  decode.d7.loss_cls: 0.0969  decode.d7.loss_mask: 0.6447  decode.d7.loss_dice: 1.4164  decode.d8.loss_cls: 0.0921  decode.d8.loss_mask: 0.6413  decode.d8.loss_dice: 1.4583
11/15 08:27:28 - mmengine - INFO - Iter(train) [ 9800/90000]  base_lr: 9.0145e-05 lr: 9.0145e-06  eta: 13:33:09  time: 0.6029  data_time: 0.0105  memory: 10713  grad_norm: 442.9634  loss: 22.0829  decode.loss_cls: 0.1037  decode.loss_mask: 0.6659  decode.loss_dice: 1.4019  decode.d0.loss_cls: 0.1100  decode.d0.loss_mask: 0.7326  decode.d0.loss_dice: 1.4963  decode.d1.loss_cls: 0.0991  decode.d1.loss_mask: 0.6846  decode.d1.loss_dice: 1.4449  decode.d2.loss_cls: 0.0986  decode.d2.loss_mask: 0.6986  decode.d2.loss_dice: 1.4138  decode.d3.loss_cls: 0.1000  decode.d3.loss_mask: 0.7012  decode.d3.loss_dice: 1.4068  decode.d4.loss_cls: 0.0972  decode.d4.loss_mask: 0.6925  decode.d4.loss_dice: 1.3784  decode.d5.loss_cls: 0.0949  decode.d5.loss_mask: 0.6911  decode.d5.loss_dice: 1.4079  decode.d6.loss_cls: 0.1051  decode.d6.loss_mask: 0.6979  decode.d6.loss_dice: 1.3885  decode.d7.loss_cls: 0.1228  decode.d7.loss_mask: 0.6855  decode.d7.loss_dice: 1.3884  decode.d8.loss_cls: 0.1250  decode.d8.loss_mask: 0.6675  decode.d8.loss_dice: 1.3823
11/15 08:27:58 - mmengine - INFO - Iter(train) [ 9850/90000]  base_lr: 9.0095e-05 lr: 9.0095e-06  eta: 13:32:36  time: 0.6006  data_time: 0.0099  memory: 10728  grad_norm: 372.1220  loss: 21.3410  decode.loss_cls: 0.0768  decode.loss_mask: 0.7064  decode.loss_dice: 1.3648  decode.d0.loss_cls: 0.0900  decode.d0.loss_mask: 0.7021  decode.d0.loss_dice: 1.4597  decode.d1.loss_cls: 0.0962  decode.d1.loss_mask: 0.6605  decode.d1.loss_dice: 1.3779  decode.d2.loss_cls: 0.0933  decode.d2.loss_mask: 0.6842  decode.d2.loss_dice: 1.3302  decode.d3.loss_cls: 0.0815  decode.d3.loss_mask: 0.6674  decode.d3.loss_dice: 1.3559  decode.d4.loss_cls: 0.0875  decode.d4.loss_mask: 0.6701  decode.d4.loss_dice: 1.3399  decode.d5.loss_cls: 0.0919  decode.d5.loss_mask: 0.6573  decode.d5.loss_dice: 1.3479  decode.d6.loss_cls: 0.0845  decode.d6.loss_mask: 0.6656  decode.d6.loss_dice: 1.3418  decode.d7.loss_cls: 0.0868  decode.d7.loss_mask: 0.6936  decode.d7.loss_dice: 1.3780  decode.d8.loss_cls: 0.0903  decode.d8.loss_mask: 0.6934  decode.d8.loss_dice: 1.3657
11/15 08:28:28 - mmengine - INFO - Iter(train) [ 9900/90000]  base_lr: 9.0044e-05 lr: 9.0044e-06  eta: 13:32:03  time: 0.6008  data_time: 0.0101  memory: 10675  grad_norm: 1338.5688  loss: 22.0310  decode.loss_cls: 0.0914  decode.loss_mask: 0.6695  decode.loss_dice: 1.4199  decode.d0.loss_cls: 0.0942  decode.d0.loss_mask: 0.6944  decode.d0.loss_dice: 1.5288  decode.d1.loss_cls: 0.0692  decode.d1.loss_mask: 0.6654  decode.d1.loss_dice: 1.4634  decode.d2.loss_cls: 0.0755  decode.d2.loss_mask: 0.6489  decode.d2.loss_dice: 1.4538  decode.d3.loss_cls: 0.0828  decode.d3.loss_mask: 0.6551  decode.d3.loss_dice: 1.4249  decode.d4.loss_cls: 0.0788  decode.d4.loss_mask: 0.6751  decode.d4.loss_dice: 1.4539  decode.d5.loss_cls: 0.0855  decode.d5.loss_mask: 0.6732  decode.d5.loss_dice: 1.4373  decode.d6.loss_cls: 0.0839  decode.d6.loss_mask: 0.6657  decode.d6.loss_dice: 1.4539  decode.d7.loss_cls: 0.0776  decode.d7.loss_mask: 0.6765  decode.d7.loss_dice: 1.4475  decode.d8.loss_cls: 0.0963  decode.d8.loss_mask: 0.6673  decode.d8.loss_dice: 1.4212
11/15 08:28:58 - mmengine - INFO - Iter(train) [ 9950/90000]  base_lr: 8.9994e-05 lr: 8.9994e-06  eta: 13:31:30  time: 0.5991  data_time: 0.0098  memory: 10656  grad_norm: 425.8489  loss: 22.1190  decode.loss_cls: 0.1082  decode.loss_mask: 0.6777  decode.loss_dice: 1.4064  decode.d0.loss_cls: 0.1127  decode.d0.loss_mask: 0.6319  decode.d0.loss_dice: 1.5437  decode.d1.loss_cls: 0.1180  decode.d1.loss_mask: 0.6116  decode.d1.loss_dice: 1.4518  decode.d2.loss_cls: 0.1201  decode.d2.loss_mask: 0.6518  decode.d2.loss_dice: 1.4432  decode.d3.loss_cls: 0.1168  decode.d3.loss_mask: 0.6507  decode.d3.loss_dice: 1.4129  decode.d4.loss_cls: 0.1190  decode.d4.loss_mask: 0.6559  decode.d4.loss_dice: 1.4404  decode.d5.loss_cls: 0.1149  decode.d5.loss_mask: 0.6568  decode.d5.loss_dice: 1.4336  decode.d6.loss_cls: 0.1085  decode.d6.loss_mask: 0.6666  decode.d6.loss_dice: 1.4284  decode.d7.loss_cls: 0.1049  decode.d7.loss_mask: 0.6817  decode.d7.loss_dice: 1.4444  decode.d8.loss_cls: 0.1080  decode.d8.loss_mask: 0.6783  decode.d8.loss_dice: 1.4205
11/15 08:29:28 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 08:29:28 - mmengine - INFO - Iter(train) [10000/90000]  base_lr: 8.9943e-05 lr: 8.9943e-06  eta: 13:30:56  time: 0.6020  data_time: 0.0101  memory: 10675  grad_norm: 512.2830  loss: 22.1156  decode.loss_cls: 0.0905  decode.loss_mask: 0.6398  decode.loss_dice: 1.4585  decode.d0.loss_cls: 0.0838  decode.d0.loss_mask: 0.7023  decode.d0.loss_dice: 1.5741  decode.d1.loss_cls: 0.0928  decode.d1.loss_mask: 0.6285  decode.d1.loss_dice: 1.4402  decode.d2.loss_cls: 0.1029  decode.d2.loss_mask: 0.6408  decode.d2.loss_dice: 1.3833  decode.d3.loss_cls: 0.0835  decode.d3.loss_mask: 0.6724  decode.d3.loss_dice: 1.4337  decode.d4.loss_cls: 0.0958  decode.d4.loss_mask: 0.6695  decode.d4.loss_dice: 1.4344  decode.d5.loss_cls: 0.1028  decode.d5.loss_mask: 0.6706  decode.d5.loss_dice: 1.4521  decode.d6.loss_cls: 0.1084  decode.d6.loss_mask: 0.6672  decode.d6.loss_dice: 1.4297  decode.d7.loss_cls: 0.1143  decode.d7.loss_mask: 0.6781  decode.d7.loss_dice: 1.4384  decode.d8.loss_cls: 0.0857  decode.d8.loss_mask: 0.6733  decode.d8.loss_dice: 1.4681
11/15 08:29:28 - mmengine - INFO - Saving checkpoint at 10000 iterations
11/15 08:29:47 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:23  time: 0.3090  data_time: 0.0043  memory: 4095  
11/15 08:30:03 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:05  time: 0.3089  data_time: 0.0043  memory: 4095  
11/15 08:30:18 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:49  time: 0.3095  data_time: 0.0043  memory: 4095  
11/15 08:30:34 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3096  data_time: 0.0042  memory: 4095  
11/15 08:30:49 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3093  data_time: 0.0041  memory: 4095  
11/15 08:31:05 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:02  time: 0.3094  data_time: 0.0042  memory: 4095  
11/15 08:31:20 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3100  data_time: 0.0044  memory: 4095  
11/15 08:31:36 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:31  time: 0.3099  data_time: 0.0041  memory: 4095  
11/15 08:31:51 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3098  data_time: 0.0042  memory: 4095  
11/15 08:32:07 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3091  data_time: 0.0038  memory: 4095  
11/15 08:32:07 - mmengine - INFO - per class results:
11/15 08:32:07 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 97.17 |  98.0 |
|    sidewalk   | 79.91 | 92.61 |
|    building   | 91.46 | 96.12 |
|      wall     | 44.58 | 73.68 |
|     fence     | 49.23 | 64.12 |
|      pole     |  60.5 | 74.46 |
| traffic light |  62.8 | 71.49 |
|  traffic sign | 77.01 | 84.01 |
|   vegetation  | 91.61 | 95.46 |
|    terrain    | 58.27 | 69.14 |
|      sky      | 93.18 | 95.97 |
|     person    |  79.0 | 86.48 |
|     rider     | 55.23 | 78.31 |
|      car      | 94.04 | 96.62 |
|     truck     | 10.88 | 12.77 |
|      bus      | 45.14 | 55.97 |
|     train     | 23.76 |  62.2 |
|   motorcycle  | 53.29 | 64.26 |
|    bicycle    | 74.93 | 84.76 |
+---------------+-------+-------+
11/15 08:32:07 - mmengine - INFO - Iter(val) [500/500]    aAcc: 94.7300  mIoU: 65.3700  mAcc: 76.6500  data_time: 0.0050  time: 0.3105
11/15 08:32:07 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024/best_mIoU_iter_5000.pth is removed
11/15 08:32:09 - mmengine - INFO - The best checkpoint with 65.3700 mIoU at 10000 iter is saved to best_mIoU_iter_10000.pth.
11/15 08:32:43 - mmengine - INFO - Iter(train) [10050/90000]  base_lr: 8.9892e-05 lr: 8.9892e-06  eta: 13:31:10  time: 0.6067  data_time: 0.0103  memory: 10675  grad_norm: 338.4195  loss: 22.4494  decode.loss_cls: 0.0852  decode.loss_mask: 0.6743  decode.loss_dice: 1.4887  decode.d0.loss_cls: 0.0932  decode.d0.loss_mask: 0.6712  decode.d0.loss_dice: 1.5817  decode.d1.loss_cls: 0.0879  decode.d1.loss_mask: 0.6178  decode.d1.loss_dice: 1.4922  decode.d2.loss_cls: 0.0893  decode.d2.loss_mask: 0.6451  decode.d2.loss_dice: 1.4986  decode.d3.loss_cls: 0.0961  decode.d3.loss_mask: 0.6366  decode.d3.loss_dice: 1.4966  decode.d4.loss_cls: 0.0912  decode.d4.loss_mask: 0.6540  decode.d4.loss_dice: 1.4869  decode.d5.loss_cls: 0.0951  decode.d5.loss_mask: 0.6717  decode.d5.loss_dice: 1.4935  decode.d6.loss_cls: 0.0961  decode.d6.loss_mask: 0.6495  decode.d6.loss_dice: 1.4763  decode.d7.loss_cls: 0.0992  decode.d7.loss_mask: 0.6501  decode.d7.loss_dice: 1.4816  decode.d8.loss_cls: 0.0886  decode.d8.loss_mask: 0.6628  decode.d8.loss_dice: 1.4982
11/15 08:33:13 - mmengine - INFO - Iter(train) [10100/90000]  base_lr: 8.9842e-05 lr: 8.9842e-06  eta: 13:30:37  time: 0.6064  data_time: 0.0105  memory: 10675  grad_norm: 352.6401  loss: 21.8901  decode.loss_cls: 0.0803  decode.loss_mask: 0.7023  decode.loss_dice: 1.4114  decode.d0.loss_cls: 0.0896  decode.d0.loss_mask: 0.7223  decode.d0.loss_dice: 1.4476  decode.d1.loss_cls: 0.0925  decode.d1.loss_mask: 0.6949  decode.d1.loss_dice: 1.3844  decode.d2.loss_cls: 0.0830  decode.d2.loss_mask: 0.6848  decode.d2.loss_dice: 1.4036  decode.d3.loss_cls: 0.0949  decode.d3.loss_mask: 0.6776  decode.d3.loss_dice: 1.3879  decode.d4.loss_cls: 0.0864  decode.d4.loss_mask: 0.6849  decode.d4.loss_dice: 1.4278  decode.d5.loss_cls: 0.0824  decode.d5.loss_mask: 0.6865  decode.d5.loss_dice: 1.4136  decode.d6.loss_cls: 0.0892  decode.d6.loss_mask: 0.6942  decode.d6.loss_dice: 1.3999  decode.d7.loss_cls: 0.0877  decode.d7.loss_mask: 0.7116  decode.d7.loss_dice: 1.3852  decode.d8.loss_cls: 0.0822  decode.d8.loss_mask: 0.7030  decode.d8.loss_dice: 1.3982
11/15 08:33:43 - mmengine - INFO - Iter(train) [10150/90000]  base_lr: 8.9791e-05 lr: 8.9791e-06  eta: 13:30:05  time: 0.5994  data_time: 0.0102  memory: 10656  grad_norm: 904.5730  loss: 22.4909  decode.loss_cls: 0.0588  decode.loss_mask: 0.8126  decode.loss_dice: 1.3555  decode.d0.loss_cls: 0.0781  decode.d0.loss_mask: 0.8459  decode.d0.loss_dice: 1.4169  decode.d1.loss_cls: 0.0704  decode.d1.loss_mask: 0.8093  decode.d1.loss_dice: 1.3363  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.8285  decode.d2.loss_dice: 1.3657  decode.d3.loss_cls: 0.0567  decode.d3.loss_mask: 0.8300  decode.d3.loss_dice: 1.3494  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 0.7945  decode.d4.loss_dice: 1.3632  decode.d5.loss_cls: 0.0557  decode.d5.loss_mask: 0.8348  decode.d5.loss_dice: 1.4017  decode.d6.loss_cls: 0.0519  decode.d6.loss_mask: 0.8029  decode.d6.loss_dice: 1.3772  decode.d7.loss_cls: 0.0735  decode.d7.loss_mask: 0.7909  decode.d7.loss_dice: 1.3639  decode.d8.loss_cls: 0.0557  decode.d8.loss_mask: 0.8197  decode.d8.loss_dice: 1.3839
11/15 08:34:13 - mmengine - INFO - Iter(train) [10200/90000]  base_lr: 8.9741e-05 lr: 8.9741e-06  eta: 13:29:33  time: 0.6053  data_time: 0.0102  memory: 10675  grad_norm: 310.9852  loss: 18.4908  decode.loss_cls: 0.0643  decode.loss_mask: 0.6407  decode.loss_dice: 1.1141  decode.d0.loss_cls: 0.0818  decode.d0.loss_mask: 0.6398  decode.d0.loss_dice: 1.1894  decode.d1.loss_cls: 0.0460  decode.d1.loss_mask: 0.6764  decode.d1.loss_dice: 1.1334  decode.d2.loss_cls: 0.0547  decode.d2.loss_mask: 0.6874  decode.d2.loss_dice: 1.1206  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.6422  decode.d3.loss_dice: 1.1060  decode.d4.loss_cls: 0.0535  decode.d4.loss_mask: 0.6820  decode.d4.loss_dice: 1.1441  decode.d5.loss_cls: 0.0837  decode.d5.loss_mask: 0.6330  decode.d5.loss_dice: 1.1158  decode.d6.loss_cls: 0.0690  decode.d6.loss_mask: 0.6259  decode.d6.loss_dice: 1.1279  decode.d7.loss_cls: 0.0675  decode.d7.loss_mask: 0.6460  decode.d7.loss_dice: 1.1238  decode.d8.loss_cls: 0.0597  decode.d8.loss_mask: 0.6688  decode.d8.loss_dice: 1.1205
11/15 08:34:43 - mmengine - INFO - Iter(train) [10250/90000]  base_lr: 8.9690e-05 lr: 8.9690e-06  eta: 13:29:00  time: 0.6014  data_time: 0.0104  memory: 10692  grad_norm: 866.5960  loss: 22.6324  decode.loss_cls: 0.1265  decode.loss_mask: 0.6913  decode.loss_dice: 1.4513  decode.d0.loss_cls: 0.1060  decode.d0.loss_mask: 0.7189  decode.d0.loss_dice: 1.5559  decode.d1.loss_cls: 0.0956  decode.d1.loss_mask: 0.7332  decode.d1.loss_dice: 1.4437  decode.d2.loss_cls: 0.0883  decode.d2.loss_mask: 0.6965  decode.d2.loss_dice: 1.4532  decode.d3.loss_cls: 0.1111  decode.d3.loss_mask: 0.7311  decode.d3.loss_dice: 1.4014  decode.d4.loss_cls: 0.0950  decode.d4.loss_mask: 0.6891  decode.d4.loss_dice: 1.4235  decode.d5.loss_cls: 0.1008  decode.d5.loss_mask: 0.7212  decode.d5.loss_dice: 1.4434  decode.d6.loss_cls: 0.0935  decode.d6.loss_mask: 0.7010  decode.d6.loss_dice: 1.4239  decode.d7.loss_cls: 0.1066  decode.d7.loss_mask: 0.7227  decode.d7.loss_dice: 1.4699  decode.d8.loss_cls: 0.1070  decode.d8.loss_mask: 0.6895  decode.d8.loss_dice: 1.4410
11/15 08:35:13 - mmengine - INFO - Iter(train) [10300/90000]  base_lr: 8.9639e-05 lr: 8.9639e-06  eta: 13:28:27  time: 0.6014  data_time: 0.0103  memory: 10641  grad_norm: 490.2973  loss: 20.9185  decode.loss_cls: 0.0802  decode.loss_mask: 0.6202  decode.loss_dice: 1.4011  decode.d0.loss_cls: 0.0940  decode.d0.loss_mask: 0.6328  decode.d0.loss_dice: 1.4298  decode.d1.loss_cls: 0.0883  decode.d1.loss_mask: 0.6070  decode.d1.loss_dice: 1.4081  decode.d2.loss_cls: 0.0904  decode.d2.loss_mask: 0.6082  decode.d2.loss_dice: 1.3693  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 0.6153  decode.d3.loss_dice: 1.4128  decode.d4.loss_cls: 0.0883  decode.d4.loss_mask: 0.6049  decode.d4.loss_dice: 1.3528  decode.d5.loss_cls: 0.0839  decode.d5.loss_mask: 0.6018  decode.d5.loss_dice: 1.3805  decode.d6.loss_cls: 0.0811  decode.d6.loss_mask: 0.6188  decode.d6.loss_dice: 1.3919  decode.d7.loss_cls: 0.0866  decode.d7.loss_mask: 0.6072  decode.d7.loss_dice: 1.4118  decode.d8.loss_cls: 0.0781  decode.d8.loss_mask: 0.6067  decode.d8.loss_dice: 1.3957
11/15 08:35:43 - mmengine - INFO - Iter(train) [10350/90000]  base_lr: 8.9589e-05 lr: 8.9589e-06  eta: 13:27:53  time: 0.6011  data_time: 0.0103  memory: 10713  grad_norm: 703.5644  loss: 21.1075  decode.loss_cls: 0.0460  decode.loss_mask: 0.6866  decode.loss_dice: 1.3178  decode.d0.loss_cls: 0.0767  decode.d0.loss_mask: 0.7709  decode.d0.loss_dice: 1.3550  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.7322  decode.d1.loss_dice: 1.3223  decode.d2.loss_cls: 0.0515  decode.d2.loss_mask: 0.7371  decode.d2.loss_dice: 1.2937  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.7319  decode.d3.loss_dice: 1.3145  decode.d4.loss_cls: 0.0616  decode.d4.loss_mask: 0.7371  decode.d4.loss_dice: 1.3273  decode.d5.loss_cls: 0.0458  decode.d5.loss_mask: 0.7427  decode.d5.loss_dice: 1.3177  decode.d6.loss_cls: 0.0635  decode.d6.loss_mask: 0.7368  decode.d6.loss_dice: 1.3106  decode.d7.loss_cls: 0.0685  decode.d7.loss_mask: 0.7140  decode.d7.loss_dice: 1.3367  decode.d8.loss_cls: 0.0703  decode.d8.loss_mask: 0.7161  decode.d8.loss_dice: 1.3028
11/15 08:36:14 - mmengine - INFO - Iter(train) [10400/90000]  base_lr: 8.9538e-05 lr: 8.9538e-06  eta: 13:27:21  time: 0.6119  data_time: 0.0098  memory: 10692  grad_norm: 313.3795  loss: 21.3750  decode.loss_cls: 0.1034  decode.loss_mask: 0.6241  decode.loss_dice: 1.4231  decode.d0.loss_cls: 0.1122  decode.d0.loss_mask: 0.6519  decode.d0.loss_dice: 1.4694  decode.d1.loss_cls: 0.1173  decode.d1.loss_mask: 0.6514  decode.d1.loss_dice: 1.3901  decode.d2.loss_cls: 0.1130  decode.d2.loss_mask: 0.6081  decode.d2.loss_dice: 1.3919  decode.d3.loss_cls: 0.0952  decode.d3.loss_mask: 0.6221  decode.d3.loss_dice: 1.4171  decode.d4.loss_cls: 0.1040  decode.d4.loss_mask: 0.6274  decode.d4.loss_dice: 1.3901  decode.d5.loss_cls: 0.0979  decode.d5.loss_mask: 0.6415  decode.d5.loss_dice: 1.3884  decode.d6.loss_cls: 0.1122  decode.d6.loss_mask: 0.6226  decode.d6.loss_dice: 1.3856  decode.d7.loss_cls: 0.1160  decode.d7.loss_mask: 0.6267  decode.d7.loss_dice: 1.3685  decode.d8.loss_cls: 0.0987  decode.d8.loss_mask: 0.6218  decode.d8.loss_dice: 1.3835
11/15 08:36:44 - mmengine - INFO - Iter(train) [10450/90000]  base_lr: 8.9487e-05 lr: 8.9487e-06  eta: 13:26:48  time: 0.6106  data_time: 0.0105  memory: 10713  grad_norm: 283.1582  loss: 22.8868  decode.loss_cls: 0.1056  decode.loss_mask: 0.6410  decode.loss_dice: 1.5388  decode.d0.loss_cls: 0.1011  decode.d0.loss_mask: 0.6901  decode.d0.loss_dice: 1.5713  decode.d1.loss_cls: 0.0988  decode.d1.loss_mask: 0.6668  decode.d1.loss_dice: 1.5372  decode.d2.loss_cls: 0.1061  decode.d2.loss_mask: 0.6505  decode.d2.loss_dice: 1.5181  decode.d3.loss_cls: 0.1028  decode.d3.loss_mask: 0.6538  decode.d3.loss_dice: 1.5088  decode.d4.loss_cls: 0.0995  decode.d4.loss_mask: 0.6545  decode.d4.loss_dice: 1.5148  decode.d5.loss_cls: 0.1068  decode.d5.loss_mask: 0.6449  decode.d5.loss_dice: 1.5183  decode.d6.loss_cls: 0.0917  decode.d6.loss_mask: 0.6550  decode.d6.loss_dice: 1.5279  decode.d7.loss_cls: 0.1086  decode.d7.loss_mask: 0.6441  decode.d7.loss_dice: 1.5360  decode.d8.loss_cls: 0.1069  decode.d8.loss_mask: 0.6554  decode.d8.loss_dice: 1.5318
11/15 08:37:14 - mmengine - INFO - Iter(train) [10500/90000]  base_lr: 8.9437e-05 lr: 8.9437e-06  eta: 13:26:15  time: 0.6010  data_time: 0.0099  memory: 10641  grad_norm: 337.9739  loss: 21.9662  decode.loss_cls: 0.0774  decode.loss_mask: 0.6513  decode.loss_dice: 1.4833  decode.d0.loss_cls: 0.0919  decode.d0.loss_mask: 0.6784  decode.d0.loss_dice: 1.4991  decode.d1.loss_cls: 0.0705  decode.d1.loss_mask: 0.6079  decode.d1.loss_dice: 1.4766  decode.d2.loss_cls: 0.0818  decode.d2.loss_mask: 0.5999  decode.d2.loss_dice: 1.4784  decode.d3.loss_cls: 0.0763  decode.d3.loss_mask: 0.6286  decode.d3.loss_dice: 1.4533  decode.d4.loss_cls: 0.0731  decode.d4.loss_mask: 0.6443  decode.d4.loss_dice: 1.4769  decode.d5.loss_cls: 0.0780  decode.d5.loss_mask: 0.6562  decode.d5.loss_dice: 1.4982  decode.d6.loss_cls: 0.0825  decode.d6.loss_mask: 0.6485  decode.d6.loss_dice: 1.4864  decode.d7.loss_cls: 0.0947  decode.d7.loss_mask: 0.6267  decode.d7.loss_dice: 1.4551  decode.d8.loss_cls: 0.0943  decode.d8.loss_mask: 0.6424  decode.d8.loss_dice: 1.4543
11/15 08:37:47 - mmengine - INFO - Iter(train) [10550/90000]  base_lr: 8.9386e-05 lr: 8.9386e-06  eta: 13:26:03  time: 0.6011  data_time: 0.0103  memory: 10656  grad_norm: 795.9231  loss: 20.8812  decode.loss_cls: 0.0675  decode.loss_mask: 0.7495  decode.loss_dice: 1.2640  decode.d0.loss_cls: 0.0848  decode.d0.loss_mask: 0.8186  decode.d0.loss_dice: 1.2880  decode.d1.loss_cls: 0.0682  decode.d1.loss_mask: 0.7508  decode.d1.loss_dice: 1.2702  decode.d2.loss_cls: 0.0773  decode.d2.loss_mask: 0.7425  decode.d2.loss_dice: 1.2313  decode.d3.loss_cls: 0.0697  decode.d3.loss_mask: 0.7538  decode.d3.loss_dice: 1.2427  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.7587  decode.d4.loss_dice: 1.2413  decode.d5.loss_cls: 0.0599  decode.d5.loss_mask: 0.7776  decode.d5.loss_dice: 1.2623  decode.d6.loss_cls: 0.0742  decode.d6.loss_mask: 0.7556  decode.d6.loss_dice: 1.2376  decode.d7.loss_cls: 0.0842  decode.d7.loss_mask: 0.7596  decode.d7.loss_dice: 1.2481  decode.d8.loss_cls: 0.0733  decode.d8.loss_mask: 0.7534  decode.d8.loss_dice: 1.2491
11/15 08:38:17 - mmengine - INFO - Iter(train) [10600/90000]  base_lr: 8.9336e-05 lr: 8.9336e-06  eta: 13:25:30  time: 0.5999  data_time: 0.0101  memory: 10692  grad_norm: 424.0994  loss: 21.6880  decode.loss_cls: 0.1158  decode.loss_mask: 0.7232  decode.loss_dice: 1.3348  decode.d0.loss_cls: 0.0973  decode.d0.loss_mask: 0.7693  decode.d0.loss_dice: 1.3829  decode.d1.loss_cls: 0.0830  decode.d1.loss_mask: 0.6874  decode.d1.loss_dice: 1.3250  decode.d2.loss_cls: 0.0881  decode.d2.loss_mask: 0.7115  decode.d2.loss_dice: 1.3754  decode.d3.loss_cls: 0.0910  decode.d3.loss_mask: 0.7318  decode.d3.loss_dice: 1.3557  decode.d4.loss_cls: 0.0959  decode.d4.loss_mask: 0.6912  decode.d4.loss_dice: 1.3392  decode.d5.loss_cls: 0.1011  decode.d5.loss_mask: 0.6929  decode.d5.loss_dice: 1.3321  decode.d6.loss_cls: 0.0992  decode.d6.loss_mask: 0.7141  decode.d6.loss_dice: 1.3893  decode.d7.loss_cls: 0.1136  decode.d7.loss_mask: 0.7150  decode.d7.loss_dice: 1.3426  decode.d8.loss_cls: 0.1030  decode.d8.loss_mask: 0.7265  decode.d8.loss_dice: 1.3600
11/15 08:38:47 - mmengine - INFO - Iter(train) [10650/90000]  base_lr: 8.9285e-05 lr: 8.9285e-06  eta: 13:24:58  time: 0.6006  data_time: 0.0102  memory: 10713  grad_norm: 799.0564  loss: 23.8613  decode.loss_cls: 0.1172  decode.loss_mask: 0.8197  decode.loss_dice: 1.4348  decode.d0.loss_cls: 0.1028  decode.d0.loss_mask: 0.8200  decode.d0.loss_dice: 1.5948  decode.d1.loss_cls: 0.0974  decode.d1.loss_mask: 0.8262  decode.d1.loss_dice: 1.5146  decode.d2.loss_cls: 0.0975  decode.d2.loss_mask: 0.7608  decode.d2.loss_dice: 1.4858  decode.d3.loss_cls: 0.1043  decode.d3.loss_mask: 0.8121  decode.d3.loss_dice: 1.4577  decode.d4.loss_cls: 0.1013  decode.d4.loss_mask: 0.7918  decode.d4.loss_dice: 1.4895  decode.d5.loss_cls: 0.1036  decode.d5.loss_mask: 0.7951  decode.d5.loss_dice: 1.4563  decode.d6.loss_cls: 0.1086  decode.d6.loss_mask: 0.7607  decode.d6.loss_dice: 1.4539  decode.d7.loss_cls: 0.1137  decode.d7.loss_mask: 0.7607  decode.d7.loss_dice: 1.4746  decode.d8.loss_cls: 0.1041  decode.d8.loss_mask: 0.7888  decode.d8.loss_dice: 1.5127
11/15 08:39:17 - mmengine - INFO - Iter(train) [10700/90000]  base_lr: 8.9234e-05 lr: 8.9234e-06  eta: 13:24:25  time: 0.6003  data_time: 0.0101  memory: 10675  grad_norm: 324.1092  loss: 18.4401  decode.loss_cls: 0.0666  decode.loss_mask: 0.5313  decode.loss_dice: 1.2310  decode.d0.loss_cls: 0.0948  decode.d0.loss_mask: 0.5575  decode.d0.loss_dice: 1.3252  decode.d1.loss_cls: 0.0653  decode.d1.loss_mask: 0.5332  decode.d1.loss_dice: 1.2198  decode.d2.loss_cls: 0.0726  decode.d2.loss_mask: 0.5376  decode.d2.loss_dice: 1.2254  decode.d3.loss_cls: 0.0743  decode.d3.loss_mask: 0.5384  decode.d3.loss_dice: 1.1865  decode.d4.loss_cls: 0.0706  decode.d4.loss_mask: 0.5342  decode.d4.loss_dice: 1.2130  decode.d5.loss_cls: 0.0776  decode.d5.loss_mask: 0.5297  decode.d5.loss_dice: 1.1929  decode.d6.loss_cls: 0.0799  decode.d6.loss_mask: 0.5299  decode.d6.loss_dice: 1.2502  decode.d7.loss_cls: 0.0717  decode.d7.loss_mask: 0.5420  decode.d7.loss_dice: 1.2462  decode.d8.loss_cls: 0.0731  decode.d8.loss_mask: 0.5328  decode.d8.loss_dice: 1.2369
11/15 08:39:47 - mmengine - INFO - Iter(train) [10750/90000]  base_lr: 8.9184e-05 lr: 8.9184e-06  eta: 13:23:51  time: 0.6021  data_time: 0.0103  memory: 10692  grad_norm: 321.7421  loss: 20.1700  decode.loss_cls: 0.0582  decode.loss_mask: 0.6373  decode.loss_dice: 1.3223  decode.d0.loss_cls: 0.0764  decode.d0.loss_mask: 0.6415  decode.d0.loss_dice: 1.3826  decode.d1.loss_cls: 0.0678  decode.d1.loss_mask: 0.6318  decode.d1.loss_dice: 1.3254  decode.d2.loss_cls: 0.0697  decode.d2.loss_mask: 0.6173  decode.d2.loss_dice: 1.3311  decode.d3.loss_cls: 0.0652  decode.d3.loss_mask: 0.6198  decode.d3.loss_dice: 1.2850  decode.d4.loss_cls: 0.0638  decode.d4.loss_mask: 0.6312  decode.d4.loss_dice: 1.3066  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.6291  decode.d5.loss_dice: 1.2915  decode.d6.loss_cls: 0.0615  decode.d6.loss_mask: 0.6272  decode.d6.loss_dice: 1.3354  decode.d7.loss_cls: 0.0638  decode.d7.loss_mask: 0.6396  decode.d7.loss_dice: 1.3275  decode.d8.loss_cls: 0.0583  decode.d8.loss_mask: 0.6314  decode.d8.loss_dice: 1.3148
11/15 08:40:17 - mmengine - INFO - Iter(train) [10800/90000]  base_lr: 8.9133e-05 lr: 8.9133e-06  eta: 13:23:18  time: 0.6025  data_time: 0.0101  memory: 10728  grad_norm: 510.4770  loss: 22.1336  decode.loss_cls: 0.0877  decode.loss_mask: 0.6358  decode.loss_dice: 1.5211  decode.d0.loss_cls: 0.0864  decode.d0.loss_mask: 0.6178  decode.d0.loss_dice: 1.6218  decode.d1.loss_cls: 0.1128  decode.d1.loss_mask: 0.6073  decode.d1.loss_dice: 1.4864  decode.d2.loss_cls: 0.0938  decode.d2.loss_mask: 0.6046  decode.d2.loss_dice: 1.4715  decode.d3.loss_cls: 0.0905  decode.d3.loss_mask: 0.6151  decode.d3.loss_dice: 1.4458  decode.d4.loss_cls: 0.0840  decode.d4.loss_mask: 0.6441  decode.d4.loss_dice: 1.4642  decode.d5.loss_cls: 0.0985  decode.d5.loss_mask: 0.6195  decode.d5.loss_dice: 1.4800  decode.d6.loss_cls: 0.0945  decode.d6.loss_mask: 0.6167  decode.d6.loss_dice: 1.5141  decode.d7.loss_cls: 0.0970  decode.d7.loss_mask: 0.6157  decode.d7.loss_dice: 1.5013  decode.d8.loss_cls: 0.0870  decode.d8.loss_mask: 0.6261  decode.d8.loss_dice: 1.4926
11/15 08:40:47 - mmengine - INFO - Iter(train) [10850/90000]  base_lr: 8.9082e-05 lr: 8.9082e-06  eta: 13:22:46  time: 0.6010  data_time: 0.0103  memory: 10641  grad_norm: 1246.5011  loss: 22.2083  decode.loss_cls: 0.1544  decode.loss_mask: 0.7972  decode.loss_dice: 1.2492  decode.d0.loss_cls: 0.1445  decode.d0.loss_mask: 0.8244  decode.d0.loss_dice: 1.3422  decode.d1.loss_cls: 0.1233  decode.d1.loss_mask: 0.8380  decode.d1.loss_dice: 1.2851  decode.d2.loss_cls: 0.1550  decode.d2.loss_mask: 0.7895  decode.d2.loss_dice: 1.2704  decode.d3.loss_cls: 0.1360  decode.d3.loss_mask: 0.7998  decode.d3.loss_dice: 1.2441  decode.d4.loss_cls: 0.1308  decode.d4.loss_mask: 0.8121  decode.d4.loss_dice: 1.2643  decode.d5.loss_cls: 0.1387  decode.d5.loss_mask: 0.8059  decode.d5.loss_dice: 1.2680  decode.d6.loss_cls: 0.1248  decode.d6.loss_mask: 0.8239  decode.d6.loss_dice: 1.2774  decode.d7.loss_cls: 0.1331  decode.d7.loss_mask: 0.8385  decode.d7.loss_dice: 1.2643  decode.d8.loss_cls: 0.1332  decode.d8.loss_mask: 0.7929  decode.d8.loss_dice: 1.2470
11/15 08:41:19 - mmengine - INFO - Iter(train) [10900/90000]  base_lr: 8.9032e-05 lr: 8.9032e-06  eta: 13:22:27  time: 0.5983  data_time: 0.0100  memory: 10656  grad_norm: 334.1755  loss: 20.4273  decode.loss_cls: 0.0624  decode.loss_mask: 0.6481  decode.loss_dice: 1.3143  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.7182  decode.d0.loss_dice: 1.4018  decode.d1.loss_cls: 0.0749  decode.d1.loss_mask: 0.6571  decode.d1.loss_dice: 1.3334  decode.d2.loss_cls: 0.0692  decode.d2.loss_mask: 0.6705  decode.d2.loss_dice: 1.3128  decode.d3.loss_cls: 0.0666  decode.d3.loss_mask: 0.6449  decode.d3.loss_dice: 1.2978  decode.d4.loss_cls: 0.0697  decode.d4.loss_mask: 0.6611  decode.d4.loss_dice: 1.2981  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.6493  decode.d5.loss_dice: 1.2912  decode.d6.loss_cls: 0.0784  decode.d6.loss_mask: 0.6452  decode.d6.loss_dice: 1.3069  decode.d7.loss_cls: 0.0803  decode.d7.loss_mask: 0.6724  decode.d7.loss_dice: 1.2984  decode.d8.loss_cls: 0.0699  decode.d8.loss_mask: 0.6229  decode.d8.loss_dice: 1.2703
11/15 08:41:50 - mmengine - INFO - Iter(train) [10950/90000]  base_lr: 8.8981e-05 lr: 8.8981e-06  eta: 13:22:00  time: 0.6637  data_time: 0.0106  memory: 10675  grad_norm: 603.1168  loss: 19.7236  decode.loss_cls: 0.0688  decode.loss_mask: 0.6756  decode.loss_dice: 1.2202  decode.d0.loss_cls: 0.0896  decode.d0.loss_mask: 0.7274  decode.d0.loss_dice: 1.2807  decode.d1.loss_cls: 0.0723  decode.d1.loss_mask: 0.6719  decode.d1.loss_dice: 1.1981  decode.d2.loss_cls: 0.0784  decode.d2.loss_mask: 0.6722  decode.d2.loss_dice: 1.1798  decode.d3.loss_cls: 0.0782  decode.d3.loss_mask: 0.6939  decode.d3.loss_dice: 1.2078  decode.d4.loss_cls: 0.0777  decode.d4.loss_mask: 0.6852  decode.d4.loss_dice: 1.2022  decode.d5.loss_cls: 0.0747  decode.d5.loss_mask: 0.6824  decode.d5.loss_dice: 1.2013  decode.d6.loss_cls: 0.0782  decode.d6.loss_mask: 0.6853  decode.d6.loss_dice: 1.2015  decode.d7.loss_cls: 0.0818  decode.d7.loss_mask: 0.6883  decode.d7.loss_dice: 1.1904  decode.d8.loss_cls: 0.0858  decode.d8.loss_mask: 0.6956  decode.d8.loss_dice: 1.1783
11/15 08:42:20 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 08:42:20 - mmengine - INFO - Iter(train) [11000/90000]  base_lr: 8.8930e-05 lr: 8.8930e-06  eta: 13:21:23  time: 0.5906  data_time: 0.0096  memory: 10641  grad_norm: 743.5371  loss: 21.3546  decode.loss_cls: 0.1150  decode.loss_mask: 0.6670  decode.loss_dice: 1.3365  decode.d0.loss_cls: 0.1140  decode.d0.loss_mask: 0.7113  decode.d0.loss_dice: 1.4055  decode.d1.loss_cls: 0.1166  decode.d1.loss_mask: 0.6728  decode.d1.loss_dice: 1.3635  decode.d2.loss_cls: 0.1137  decode.d2.loss_mask: 0.6551  decode.d2.loss_dice: 1.3484  decode.d3.loss_cls: 0.1069  decode.d3.loss_mask: 0.6458  decode.d3.loss_dice: 1.3334  decode.d4.loss_cls: 0.1035  decode.d4.loss_mask: 0.6517  decode.d4.loss_dice: 1.3457  decode.d5.loss_cls: 0.1068  decode.d5.loss_mask: 0.6915  decode.d5.loss_dice: 1.3407  decode.d6.loss_cls: 0.1104  decode.d6.loss_mask: 0.6851  decode.d6.loss_dice: 1.3333  decode.d7.loss_cls: 0.0993  decode.d7.loss_mask: 0.6959  decode.d7.loss_dice: 1.3639  decode.d8.loss_cls: 0.0932  decode.d8.loss_mask: 0.6739  decode.d8.loss_dice: 1.3539
11/15 08:42:49 - mmengine - INFO - Iter(train) [11050/90000]  base_lr: 8.8880e-05 lr: 8.8880e-06  eta: 13:20:48  time: 0.6018  data_time: 0.0099  memory: 10758  grad_norm: 478.0207  loss: 22.9765  decode.loss_cls: 0.0994  decode.loss_mask: 0.6081  decode.loss_dice: 1.5638  decode.d0.loss_cls: 0.1013  decode.d0.loss_mask: 0.6151  decode.d0.loss_dice: 1.6542  decode.d1.loss_cls: 0.0881  decode.d1.loss_mask: 0.6118  decode.d1.loss_dice: 1.6170  decode.d2.loss_cls: 0.0959  decode.d2.loss_mask: 0.5886  decode.d2.loss_dice: 1.5800  decode.d3.loss_cls: 0.0951  decode.d3.loss_mask: 0.5966  decode.d3.loss_dice: 1.5833  decode.d4.loss_cls: 0.0985  decode.d4.loss_mask: 0.6057  decode.d4.loss_dice: 1.6014  decode.d5.loss_cls: 0.1039  decode.d5.loss_mask: 0.6049  decode.d5.loss_dice: 1.5668  decode.d6.loss_cls: 0.0897  decode.d6.loss_mask: 0.6109  decode.d6.loss_dice: 1.5846  decode.d7.loss_cls: 0.1085  decode.d7.loss_mask: 0.6114  decode.d7.loss_dice: 1.5904  decode.d8.loss_cls: 0.0908  decode.d8.loss_mask: 0.6074  decode.d8.loss_dice: 1.6032
11/15 08:43:19 - mmengine - INFO - Iter(train) [11100/90000]  base_lr: 8.8829e-05 lr: 8.8829e-06  eta: 13:20:12  time: 0.5917  data_time: 0.0096  memory: 10692  grad_norm: 297.0342  loss: 18.5286  decode.loss_cls: 0.0733  decode.loss_mask: 0.6419  decode.loss_dice: 1.0859  decode.d0.loss_cls: 0.0948  decode.d0.loss_mask: 0.6597  decode.d0.loss_dice: 1.2368  decode.d1.loss_cls: 0.0789  decode.d1.loss_mask: 0.6345  decode.d1.loss_dice: 1.1308  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.6354  decode.d2.loss_dice: 1.1230  decode.d3.loss_cls: 0.0776  decode.d3.loss_mask: 0.6301  decode.d3.loss_dice: 1.1336  decode.d4.loss_cls: 0.0754  decode.d4.loss_mask: 0.6370  decode.d4.loss_dice: 1.1176  decode.d5.loss_cls: 0.0875  decode.d5.loss_mask: 0.6411  decode.d5.loss_dice: 1.1108  decode.d6.loss_cls: 0.0832  decode.d6.loss_mask: 0.6400  decode.d6.loss_dice: 1.1090  decode.d7.loss_cls: 0.0918  decode.d7.loss_mask: 0.6499  decode.d7.loss_dice: 1.0969  decode.d8.loss_cls: 0.0817  decode.d8.loss_mask: 0.6525  decode.d8.loss_dice: 1.1447
11/15 08:43:49 - mmengine - INFO - Iter(train) [11150/90000]  base_lr: 8.8778e-05 lr: 8.8778e-06  eta: 13:19:36  time: 0.5929  data_time: 0.0094  memory: 10713  grad_norm: 393.7232  loss: 20.6543  decode.loss_cls: 0.0838  decode.loss_mask: 0.5670  decode.loss_dice: 1.3906  decode.d0.loss_cls: 0.1024  decode.d0.loss_mask: 0.6010  decode.d0.loss_dice: 1.4771  decode.d1.loss_cls: 0.0867  decode.d1.loss_mask: 0.5703  decode.d1.loss_dice: 1.3989  decode.d2.loss_cls: 0.0799  decode.d2.loss_mask: 0.5795  decode.d2.loss_dice: 1.4049  decode.d3.loss_cls: 0.0673  decode.d3.loss_mask: 0.5796  decode.d3.loss_dice: 1.4062  decode.d4.loss_cls: 0.0893  decode.d4.loss_mask: 0.5834  decode.d4.loss_dice: 1.4102  decode.d5.loss_cls: 0.0718  decode.d5.loss_mask: 0.5776  decode.d5.loss_dice: 1.4360  decode.d6.loss_cls: 0.0691  decode.d6.loss_mask: 0.5787  decode.d6.loss_dice: 1.3712  decode.d7.loss_cls: 0.0816  decode.d7.loss_mask: 0.5705  decode.d7.loss_dice: 1.3810  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.5699  decode.d8.loss_dice: 1.3946
11/15 08:44:18 - mmengine - INFO - Iter(train) [11200/90000]  base_lr: 8.8728e-05 lr: 8.8728e-06  eta: 13:19:00  time: 0.5926  data_time: 0.0098  memory: 10641  grad_norm: 534.9753  loss: 23.5066  decode.loss_cls: 0.1353  decode.loss_mask: 0.7250  decode.loss_dice: 1.5228  decode.d0.loss_cls: 0.1127  decode.d0.loss_mask: 0.7795  decode.d0.loss_dice: 1.6081  decode.d1.loss_cls: 0.1106  decode.d1.loss_mask: 0.7167  decode.d1.loss_dice: 1.5297  decode.d2.loss_cls: 0.1173  decode.d2.loss_mask: 0.7183  decode.d2.loss_dice: 1.5083  decode.d3.loss_cls: 0.1141  decode.d3.loss_mask: 0.7073  decode.d3.loss_dice: 1.4790  decode.d4.loss_cls: 0.1185  decode.d4.loss_mask: 0.7098  decode.d4.loss_dice: 1.4841  decode.d5.loss_cls: 0.1147  decode.d5.loss_mask: 0.7128  decode.d5.loss_dice: 1.4938  decode.d6.loss_cls: 0.1117  decode.d6.loss_mask: 0.7113  decode.d6.loss_dice: 1.4827  decode.d7.loss_cls: 0.1095  decode.d7.loss_mask: 0.7172  decode.d7.loss_dice: 1.4976  decode.d8.loss_cls: 0.1279  decode.d8.loss_mask: 0.7159  decode.d8.loss_dice: 1.5145
11/15 08:44:48 - mmengine - INFO - Iter(train) [11250/90000]  base_lr: 8.8677e-05 lr: 8.8677e-06  eta: 13:18:24  time: 0.5919  data_time: 0.0094  memory: 10675  grad_norm: 965.7633  loss: 23.4835  decode.loss_cls: 0.0882  decode.loss_mask: 0.7749  decode.loss_dice: 1.4467  decode.d0.loss_cls: 0.1033  decode.d0.loss_mask: 0.8429  decode.d0.loss_dice: 1.5312  decode.d1.loss_cls: 0.0755  decode.d1.loss_mask: 0.8170  decode.d1.loss_dice: 1.4600  decode.d2.loss_cls: 0.1093  decode.d2.loss_mask: 0.7804  decode.d2.loss_dice: 1.4512  decode.d3.loss_cls: 0.0957  decode.d3.loss_mask: 0.7581  decode.d3.loss_dice: 1.4563  decode.d4.loss_cls: 0.1116  decode.d4.loss_mask: 0.7514  decode.d4.loss_dice: 1.4479  decode.d5.loss_cls: 0.0857  decode.d5.loss_mask: 0.7734  decode.d5.loss_dice: 1.4365  decode.d6.loss_cls: 0.0941  decode.d6.loss_mask: 0.8150  decode.d6.loss_dice: 1.4598  decode.d7.loss_cls: 0.0983  decode.d7.loss_mask: 0.7814  decode.d7.loss_dice: 1.4775  decode.d8.loss_cls: 0.0984  decode.d8.loss_mask: 0.7985  decode.d8.loss_dice: 1.4632
11/15 08:45:18 - mmengine - INFO - Iter(train) [11300/90000]  base_lr: 8.8626e-05 lr: 8.8626e-06  eta: 13:17:48  time: 0.5921  data_time: 0.0096  memory: 10692  grad_norm: 362.3118  loss: 22.3547  decode.loss_cls: 0.1224  decode.loss_mask: 0.5812  decode.loss_dice: 1.4722  decode.d0.loss_cls: 0.1053  decode.d0.loss_mask: 0.6041  decode.d0.loss_dice: 1.6569  decode.d1.loss_cls: 0.1253  decode.d1.loss_mask: 0.5790  decode.d1.loss_dice: 1.5023  decode.d2.loss_cls: 0.1272  decode.d2.loss_mask: 0.6091  decode.d2.loss_dice: 1.4844  decode.d3.loss_cls: 0.1449  decode.d3.loss_mask: 0.6051  decode.d3.loss_dice: 1.4808  decode.d4.loss_cls: 0.1318  decode.d4.loss_mask: 0.5990  decode.d4.loss_dice: 1.4892  decode.d5.loss_cls: 0.1238  decode.d5.loss_mask: 0.5819  decode.d5.loss_dice: 1.5064  decode.d6.loss_cls: 0.1228  decode.d6.loss_mask: 0.5815  decode.d6.loss_dice: 1.5387  decode.d7.loss_cls: 0.1420  decode.d7.loss_mask: 0.5807  decode.d7.loss_dice: 1.5331  decode.d8.loss_cls: 0.1335  decode.d8.loss_mask: 0.5899  decode.d8.loss_dice: 1.5004
11/15 08:45:47 - mmengine - INFO - Iter(train) [11350/90000]  base_lr: 8.8576e-05 lr: 8.8576e-06  eta: 13:17:13  time: 0.5917  data_time: 0.0096  memory: 10656  grad_norm: 326.1586  loss: 20.8233  decode.loss_cls: 0.0945  decode.loss_mask: 0.6181  decode.loss_dice: 1.3200  decode.d0.loss_cls: 0.1078  decode.d0.loss_mask: 0.6479  decode.d0.loss_dice: 1.4830  decode.d1.loss_cls: 0.0943  decode.d1.loss_mask: 0.6211  decode.d1.loss_dice: 1.4109  decode.d2.loss_cls: 0.0806  decode.d2.loss_mask: 0.6164  decode.d2.loss_dice: 1.3794  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 0.6113  decode.d3.loss_dice: 1.3341  decode.d4.loss_cls: 0.1141  decode.d4.loss_mask: 0.5872  decode.d4.loss_dice: 1.3306  decode.d5.loss_cls: 0.1006  decode.d5.loss_mask: 0.5944  decode.d5.loss_dice: 1.3323  decode.d6.loss_cls: 0.1021  decode.d6.loss_mask: 0.6128  decode.d6.loss_dice: 1.3600  decode.d7.loss_cls: 0.0799  decode.d7.loss_mask: 0.6198  decode.d7.loss_dice: 1.3530  decode.d8.loss_cls: 0.0840  decode.d8.loss_mask: 0.6380  decode.d8.loss_dice: 1.3936
11/15 08:46:17 - mmengine - INFO - Iter(train) [11400/90000]  base_lr: 8.8525e-05 lr: 8.8525e-06  eta: 13:16:37  time: 0.5919  data_time: 0.0096  memory: 10728  grad_norm: 545.0850  loss: 20.9884  decode.loss_cls: 0.0990  decode.loss_mask: 0.6335  decode.loss_dice: 1.3933  decode.d0.loss_cls: 0.0971  decode.d0.loss_mask: 0.6461  decode.d0.loss_dice: 1.4647  decode.d1.loss_cls: 0.0883  decode.d1.loss_mask: 0.6199  decode.d1.loss_dice: 1.4053  decode.d2.loss_cls: 0.0923  decode.d2.loss_mask: 0.6408  decode.d2.loss_dice: 1.4116  decode.d3.loss_cls: 0.0802  decode.d3.loss_mask: 0.6151  decode.d3.loss_dice: 1.3522  decode.d4.loss_cls: 0.0977  decode.d4.loss_mask: 0.6083  decode.d4.loss_dice: 1.3546  decode.d5.loss_cls: 0.0829  decode.d5.loss_mask: 0.6209  decode.d5.loss_dice: 1.3853  decode.d6.loss_cls: 0.0909  decode.d6.loss_mask: 0.6323  decode.d6.loss_dice: 1.3271  decode.d7.loss_cls: 0.1032  decode.d7.loss_mask: 0.6255  decode.d7.loss_dice: 1.3448  decode.d8.loss_cls: 0.0980  decode.d8.loss_mask: 0.6192  decode.d8.loss_dice: 1.3582
11/15 08:46:47 - mmengine - INFO - Iter(train) [11450/90000]  base_lr: 8.8474e-05 lr: 8.8474e-06  eta: 13:16:01  time: 0.5943  data_time: 0.0096  memory: 10641  grad_norm: 327.4760  loss: 20.3750  decode.loss_cls: 0.0794  decode.loss_mask: 0.5922  decode.loss_dice: 1.3658  decode.d0.loss_cls: 0.0792  decode.d0.loss_mask: 0.6375  decode.d0.loss_dice: 1.3893  decode.d1.loss_cls: 0.0721  decode.d1.loss_mask: 0.6027  decode.d1.loss_dice: 1.3320  decode.d2.loss_cls: 0.0779  decode.d2.loss_mask: 0.5876  decode.d2.loss_dice: 1.3198  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.5930  decode.d3.loss_dice: 1.3535  decode.d4.loss_cls: 0.0815  decode.d4.loss_mask: 0.5960  decode.d4.loss_dice: 1.3333  decode.d5.loss_cls: 0.0649  decode.d5.loss_mask: 0.6197  decode.d5.loss_dice: 1.3464  decode.d6.loss_cls: 0.0776  decode.d6.loss_mask: 0.6065  decode.d6.loss_dice: 1.3721  decode.d7.loss_cls: 0.0870  decode.d7.loss_mask: 0.5977  decode.d7.loss_dice: 1.3637  decode.d8.loss_cls: 0.0808  decode.d8.loss_mask: 0.6045  decode.d8.loss_dice: 1.3821
11/15 08:47:16 - mmengine - INFO - Iter(train) [11500/90000]  base_lr: 8.8424e-05 lr: 8.8424e-06  eta: 13:15:25  time: 0.5920  data_time: 0.0093  memory: 10692  grad_norm: 482.1291  loss: 20.5123  decode.loss_cls: 0.1183  decode.loss_mask: 0.6042  decode.loss_dice: 1.3045  decode.d0.loss_cls: 0.1020  decode.d0.loss_mask: 0.6333  decode.d0.loss_dice: 1.4376  decode.d1.loss_cls: 0.0932  decode.d1.loss_mask: 0.6233  decode.d1.loss_dice: 1.3475  decode.d2.loss_cls: 0.1088  decode.d2.loss_mask: 0.6304  decode.d2.loss_dice: 1.3336  decode.d3.loss_cls: 0.1100  decode.d3.loss_mask: 0.6176  decode.d3.loss_dice: 1.3104  decode.d4.loss_cls: 0.1152  decode.d4.loss_mask: 0.6227  decode.d4.loss_dice: 1.3031  decode.d5.loss_cls: 0.1058  decode.d5.loss_mask: 0.6185  decode.d5.loss_dice: 1.3009  decode.d6.loss_cls: 0.1321  decode.d6.loss_mask: 0.6091  decode.d6.loss_dice: 1.2677  decode.d7.loss_cls: 0.1166  decode.d7.loss_mask: 0.6171  decode.d7.loss_dice: 1.2878  decode.d8.loss_cls: 0.1148  decode.d8.loss_mask: 0.6107  decode.d8.loss_dice: 1.3156
11/15 08:47:46 - mmengine - INFO - Iter(train) [11550/90000]  base_lr: 8.8373e-05 lr: 8.8373e-06  eta: 13:14:52  time: 0.5933  data_time: 0.0098  memory: 10641  grad_norm: 502.1904  loss: 22.2875  decode.loss_cls: 0.0644  decode.loss_mask: 0.7934  decode.loss_dice: 1.3436  decode.d0.loss_cls: 0.0810  decode.d0.loss_mask: 0.8342  decode.d0.loss_dice: 1.4240  decode.d1.loss_cls: 0.0650  decode.d1.loss_mask: 0.8405  decode.d1.loss_dice: 1.4066  decode.d2.loss_cls: 0.0747  decode.d2.loss_mask: 0.7971  decode.d2.loss_dice: 1.3390  decode.d3.loss_cls: 0.0726  decode.d3.loss_mask: 0.8073  decode.d3.loss_dice: 1.3403  decode.d4.loss_cls: 0.0637  decode.d4.loss_mask: 0.8035  decode.d4.loss_dice: 1.3346  decode.d5.loss_cls: 0.0760  decode.d5.loss_mask: 0.8073  decode.d5.loss_dice: 1.3305  decode.d6.loss_cls: 0.0760  decode.d6.loss_mask: 0.7903  decode.d6.loss_dice: 1.3093  decode.d7.loss_cls: 0.0670  decode.d7.loss_mask: 0.8065  decode.d7.loss_dice: 1.3479  decode.d8.loss_cls: 0.0953  decode.d8.loss_mask: 0.7801  decode.d8.loss_dice: 1.3157
11/15 08:48:16 - mmengine - INFO - Iter(train) [11600/90000]  base_lr: 8.8322e-05 lr: 8.8322e-06  eta: 13:14:18  time: 0.6206  data_time: 0.0096  memory: 10692  grad_norm: 380.6660  loss: 22.8023  decode.loss_cls: 0.1085  decode.loss_mask: 0.6074  decode.loss_dice: 1.4707  decode.d0.loss_cls: 0.1133  decode.d0.loss_mask: 0.6193  decode.d0.loss_dice: 1.6573  decode.d1.loss_cls: 0.1112  decode.d1.loss_mask: 0.5738  decode.d1.loss_dice: 1.5294  decode.d2.loss_cls: 0.0937  decode.d2.loss_mask: 0.7196  decode.d2.loss_dice: 1.5046  decode.d3.loss_cls: 0.1043  decode.d3.loss_mask: 0.7559  decode.d3.loss_dice: 1.5014  decode.d4.loss_cls: 0.1141  decode.d4.loss_mask: 0.6260  decode.d4.loss_dice: 1.4764  decode.d5.loss_cls: 0.1219  decode.d5.loss_mask: 0.6319  decode.d5.loss_dice: 1.4696  decode.d6.loss_cls: 0.1191  decode.d6.loss_mask: 0.7491  decode.d6.loss_dice: 1.4746  decode.d7.loss_cls: 0.1349  decode.d7.loss_mask: 0.6696  decode.d7.loss_dice: 1.4982  decode.d8.loss_cls: 0.1159  decode.d8.loss_mask: 0.6390  decode.d8.loss_dice: 1.4915
11/15 08:48:46 - mmengine - INFO - Iter(train) [11650/90000]  base_lr: 8.8272e-05 lr: 8.8272e-06  eta: 13:13:45  time: 0.5938  data_time: 0.0098  memory: 10675  grad_norm: 367.3734  loss: 23.7097  decode.loss_cls: 0.1055  decode.loss_mask: 0.7641  decode.loss_dice: 1.4611  decode.d0.loss_cls: 0.1139  decode.d0.loss_mask: 0.8006  decode.d0.loss_dice: 1.5226  decode.d1.loss_cls: 0.0933  decode.d1.loss_mask: 0.7765  decode.d1.loss_dice: 1.4904  decode.d2.loss_cls: 0.0972  decode.d2.loss_mask: 0.8061  decode.d2.loss_dice: 1.5111  decode.d3.loss_cls: 0.1045  decode.d3.loss_mask: 0.7691  decode.d3.loss_dice: 1.4493  decode.d4.loss_cls: 0.1048  decode.d4.loss_mask: 0.7754  decode.d4.loss_dice: 1.4822  decode.d5.loss_cls: 0.1074  decode.d5.loss_mask: 0.7559  decode.d5.loss_dice: 1.4618  decode.d6.loss_cls: 0.1073  decode.d6.loss_mask: 0.7622  decode.d6.loss_dice: 1.4981  decode.d7.loss_cls: 0.1145  decode.d7.loss_mask: 0.7737  decode.d7.loss_dice: 1.5171  decode.d8.loss_cls: 0.1083  decode.d8.loss_mask: 0.7806  decode.d8.loss_dice: 1.4953
11/15 08:49:16 - mmengine - INFO - Iter(train) [11700/90000]  base_lr: 8.8221e-05 lr: 8.8221e-06  eta: 13:13:09  time: 0.5922  data_time: 0.0098  memory: 10656  grad_norm: 623.3317  loss: 24.6814  decode.loss_cls: 0.1103  decode.loss_mask: 0.7355  decode.loss_dice: 1.6342  decode.d0.loss_cls: 0.0990  decode.d0.loss_mask: 0.7683  decode.d0.loss_dice: 1.6957  decode.d1.loss_cls: 0.1217  decode.d1.loss_mask: 0.7371  decode.d1.loss_dice: 1.6118  decode.d2.loss_cls: 0.1148  decode.d2.loss_mask: 0.7318  decode.d2.loss_dice: 1.5942  decode.d3.loss_cls: 0.1026  decode.d3.loss_mask: 0.7428  decode.d3.loss_dice: 1.5712  decode.d4.loss_cls: 0.1017  decode.d4.loss_mask: 0.7376  decode.d4.loss_dice: 1.6152  decode.d5.loss_cls: 0.1071  decode.d5.loss_mask: 0.7233  decode.d5.loss_dice: 1.6095  decode.d6.loss_cls: 0.1246  decode.d6.loss_mask: 0.7398  decode.d6.loss_dice: 1.6091  decode.d7.loss_cls: 0.1121  decode.d7.loss_mask: 0.7393  decode.d7.loss_dice: 1.6403  decode.d8.loss_cls: 0.1128  decode.d8.loss_mask: 0.7455  decode.d8.loss_dice: 1.5927
11/15 08:49:45 - mmengine - INFO - Iter(train) [11750/90000]  base_lr: 8.8170e-05 lr: 8.8170e-06  eta: 13:12:34  time: 0.5946  data_time: 0.0099  memory: 10675  grad_norm: 446.9646  loss: 20.3366  decode.loss_cls: 0.0769  decode.loss_mask: 0.6485  decode.loss_dice: 1.3027  decode.d0.loss_cls: 0.0835  decode.d0.loss_mask: 0.6588  decode.d0.loss_dice: 1.3629  decode.d1.loss_cls: 0.0782  decode.d1.loss_mask: 0.6627  decode.d1.loss_dice: 1.3343  decode.d2.loss_cls: 0.0848  decode.d2.loss_mask: 0.6368  decode.d2.loss_dice: 1.2809  decode.d3.loss_cls: 0.0820  decode.d3.loss_mask: 0.6543  decode.d3.loss_dice: 1.2870  decode.d4.loss_cls: 0.0668  decode.d4.loss_mask: 0.6545  decode.d4.loss_dice: 1.3018  decode.d5.loss_cls: 0.0654  decode.d5.loss_mask: 0.6491  decode.d5.loss_dice: 1.2933  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.6468  decode.d6.loss_dice: 1.3079  decode.d7.loss_cls: 0.0723  decode.d7.loss_mask: 0.6515  decode.d7.loss_dice: 1.3195  decode.d8.loss_cls: 0.0710  decode.d8.loss_mask: 0.6495  decode.d8.loss_dice: 1.2915
11/15 08:50:15 - mmengine - INFO - Iter(train) [11800/90000]  base_lr: 8.8120e-05 lr: 8.8120e-06  eta: 13:12:00  time: 0.5945  data_time: 0.0100  memory: 10656  grad_norm: 404.7476  loss: 22.4218  decode.loss_cls: 0.0705  decode.loss_mask: 0.7929  decode.loss_dice: 1.3669  decode.d0.loss_cls: 0.0932  decode.d0.loss_mask: 0.8130  decode.d0.loss_dice: 1.3890  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.7885  decode.d1.loss_dice: 1.3356  decode.d2.loss_cls: 0.0718  decode.d2.loss_mask: 0.8287  decode.d2.loss_dice: 1.3594  decode.d3.loss_cls: 0.0663  decode.d3.loss_mask: 0.8755  decode.d3.loss_dice: 1.3392  decode.d4.loss_cls: 0.0694  decode.d4.loss_mask: 0.8125  decode.d4.loss_dice: 1.3244  decode.d5.loss_cls: 0.0748  decode.d5.loss_mask: 0.8267  decode.d5.loss_dice: 1.3428  decode.d6.loss_cls: 0.0634  decode.d6.loss_mask: 0.8223  decode.d6.loss_dice: 1.3558  decode.d7.loss_cls: 0.0740  decode.d7.loss_mask: 0.8088  decode.d7.loss_dice: 1.3529  decode.d8.loss_cls: 0.0796  decode.d8.loss_mask: 0.7968  decode.d8.loss_dice: 1.3519
11/15 08:50:45 - mmengine - INFO - Iter(train) [11850/90000]  base_lr: 8.8069e-05 lr: 8.8069e-06  eta: 13:11:25  time: 0.5962  data_time: 0.0109  memory: 10626  grad_norm: 511.3901  loss: 17.9574  decode.loss_cls: 0.0507  decode.loss_mask: 0.5748  decode.loss_dice: 1.1548  decode.d0.loss_cls: 0.0802  decode.d0.loss_mask: 0.6078  decode.d0.loss_dice: 1.2366  decode.d1.loss_cls: 0.0713  decode.d1.loss_mask: 0.5926  decode.d1.loss_dice: 1.1533  decode.d2.loss_cls: 0.0544  decode.d2.loss_mask: 0.5832  decode.d2.loss_dice: 1.1386  decode.d3.loss_cls: 0.0526  decode.d3.loss_mask: 0.5861  decode.d3.loss_dice: 1.1466  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.5850  decode.d4.loss_dice: 1.1394  decode.d5.loss_cls: 0.0500  decode.d5.loss_mask: 0.5759  decode.d5.loss_dice: 1.1365  decode.d6.loss_cls: 0.0635  decode.d6.loss_mask: 0.5646  decode.d6.loss_dice: 1.1367  decode.d7.loss_cls: 0.0539  decode.d7.loss_mask: 0.6002  decode.d7.loss_dice: 1.1468  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.5822  decode.d8.loss_dice: 1.1364
11/15 08:51:15 - mmengine - INFO - Iter(train) [11900/90000]  base_lr: 8.8018e-05 lr: 8.8018e-06  eta: 13:10:50  time: 0.5928  data_time: 0.0097  memory: 10713  grad_norm: 579.0070  loss: 20.6640  decode.loss_cls: 0.0724  decode.loss_mask: 0.6540  decode.loss_dice: 1.2608  decode.d0.loss_cls: 0.0732  decode.d0.loss_mask: 0.7238  decode.d0.loss_dice: 1.4148  decode.d1.loss_cls: 0.0842  decode.d1.loss_mask: 0.7137  decode.d1.loss_dice: 1.3084  decode.d2.loss_cls: 0.1034  decode.d2.loss_mask: 0.6955  decode.d2.loss_dice: 1.2764  decode.d3.loss_cls: 0.0888  decode.d3.loss_mask: 0.6996  decode.d3.loss_dice: 1.2923  decode.d4.loss_cls: 0.0795  decode.d4.loss_mask: 0.7146  decode.d4.loss_dice: 1.2864  decode.d5.loss_cls: 0.0883  decode.d5.loss_mask: 0.6950  decode.d5.loss_dice: 1.2832  decode.d6.loss_cls: 0.0832  decode.d6.loss_mask: 0.6416  decode.d6.loss_dice: 1.2701  decode.d7.loss_cls: 0.0874  decode.d7.loss_mask: 0.6513  decode.d7.loss_dice: 1.2655  decode.d8.loss_cls: 0.0923  decode.d8.loss_mask: 0.6627  decode.d8.loss_dice: 1.3015
11/15 08:51:44 - mmengine - INFO - Iter(train) [11950/90000]  base_lr: 8.7967e-05 lr: 8.7967e-06  eta: 13:10:15  time: 0.5923  data_time: 0.0097  memory: 10656  grad_norm: 558.9885  loss: 18.6708  decode.loss_cls: 0.0774  decode.loss_mask: 0.6230  decode.loss_dice: 1.1542  decode.d0.loss_cls: 0.0946  decode.d0.loss_mask: 0.6452  decode.d0.loss_dice: 1.2300  decode.d1.loss_cls: 0.0706  decode.d1.loss_mask: 0.6102  decode.d1.loss_dice: 1.1917  decode.d2.loss_cls: 0.0658  decode.d2.loss_mask: 0.6110  decode.d2.loss_dice: 1.1399  decode.d3.loss_cls: 0.0600  decode.d3.loss_mask: 0.6228  decode.d3.loss_dice: 1.1554  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.6261  decode.d4.loss_dice: 1.1595  decode.d5.loss_cls: 0.0716  decode.d5.loss_mask: 0.6193  decode.d5.loss_dice: 1.1662  decode.d6.loss_cls: 0.0798  decode.d6.loss_mask: 0.6143  decode.d6.loss_dice: 1.1474  decode.d7.loss_cls: 0.0796  decode.d7.loss_mask: 0.6145  decode.d7.loss_dice: 1.1731  decode.d8.loss_cls: 0.0626  decode.d8.loss_mask: 0.6263  decode.d8.loss_dice: 1.2046
11/15 08:52:14 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 08:52:14 - mmengine - INFO - Iter(train) [12000/90000]  base_lr: 8.7917e-05 lr: 8.7917e-06  eta: 13:09:40  time: 0.5937  data_time: 0.0097  memory: 10692  grad_norm: 445.1723  loss: 22.5912  decode.loss_cls: 0.1365  decode.loss_mask: 0.6201  decode.loss_dice: 1.5150  decode.d0.loss_cls: 0.1191  decode.d0.loss_mask: 0.5721  decode.d0.loss_dice: 1.5293  decode.d1.loss_cls: 0.1071  decode.d1.loss_mask: 0.6092  decode.d1.loss_dice: 1.5008  decode.d2.loss_cls: 0.1109  decode.d2.loss_mask: 0.6392  decode.d2.loss_dice: 1.5053  decode.d3.loss_cls: 0.1021  decode.d3.loss_mask: 0.6299  decode.d3.loss_dice: 1.5000  decode.d4.loss_cls: 0.1276  decode.d4.loss_mask: 0.6454  decode.d4.loss_dice: 1.4966  decode.d5.loss_cls: 0.1290  decode.d5.loss_mask: 0.6275  decode.d5.loss_dice: 1.5245  decode.d6.loss_cls: 0.1377  decode.d6.loss_mask: 0.6406  decode.d6.loss_dice: 1.4896  decode.d7.loss_cls: 0.1121  decode.d7.loss_mask: 0.6455  decode.d7.loss_dice: 1.5467  decode.d8.loss_cls: 0.1199  decode.d8.loss_mask: 0.6258  decode.d8.loss_dice: 1.5261
11/15 08:52:44 - mmengine - INFO - Iter(train) [12050/90000]  base_lr: 8.7866e-05 lr: 8.7866e-06  eta: 13:09:05  time: 0.5940  data_time: 0.0096  memory: 10692  grad_norm: 556.5836  loss: 20.4566  decode.loss_cls: 0.0954  decode.loss_mask: 0.5793  decode.loss_dice: 1.3576  decode.d0.loss_cls: 0.0929  decode.d0.loss_mask: 0.5974  decode.d0.loss_dice: 1.4877  decode.d1.loss_cls: 0.0918  decode.d1.loss_mask: 0.5867  decode.d1.loss_dice: 1.3945  decode.d2.loss_cls: 0.0988  decode.d2.loss_mask: 0.5827  decode.d2.loss_dice: 1.3475  decode.d3.loss_cls: 0.1108  decode.d3.loss_mask: 0.5776  decode.d3.loss_dice: 1.3107  decode.d4.loss_cls: 0.1137  decode.d4.loss_mask: 0.5736  decode.d4.loss_dice: 1.3494  decode.d5.loss_cls: 0.1007  decode.d5.loss_mask: 0.5776  decode.d5.loss_dice: 1.3648  decode.d6.loss_cls: 0.0997  decode.d6.loss_mask: 0.5807  decode.d6.loss_dice: 1.3404  decode.d7.loss_cls: 0.0968  decode.d7.loss_mask: 0.5666  decode.d7.loss_dice: 1.3620  decode.d8.loss_cls: 0.0944  decode.d8.loss_mask: 0.5731  decode.d8.loss_dice: 1.3516
11/15 08:53:13 - mmengine - INFO - Iter(train) [12100/90000]  base_lr: 8.7815e-05 lr: 8.7815e-06  eta: 13:08:30  time: 0.5926  data_time: 0.0096  memory: 10692  grad_norm: 437.2241  loss: 20.3470  decode.loss_cls: 0.0625  decode.loss_mask: 0.7031  decode.loss_dice: 1.2709  decode.d0.loss_cls: 0.0719  decode.d0.loss_mask: 0.7375  decode.d0.loss_dice: 1.2988  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.7118  decode.d1.loss_dice: 1.2893  decode.d2.loss_cls: 0.0567  decode.d2.loss_mask: 0.7166  decode.d2.loss_dice: 1.2606  decode.d3.loss_cls: 0.0521  decode.d3.loss_mask: 0.7050  decode.d3.loss_dice: 1.2529  decode.d4.loss_cls: 0.0587  decode.d4.loss_mask: 0.7057  decode.d4.loss_dice: 1.2636  decode.d5.loss_cls: 0.0627  decode.d5.loss_mask: 0.7008  decode.d5.loss_dice: 1.2530  decode.d6.loss_cls: 0.0585  decode.d6.loss_mask: 0.6984  decode.d6.loss_dice: 1.2377  decode.d7.loss_cls: 0.0524  decode.d7.loss_mask: 0.7177  decode.d7.loss_dice: 1.2860  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 0.6978  decode.d8.loss_dice: 1.2614
11/15 08:53:43 - mmengine - INFO - Iter(train) [12150/90000]  base_lr: 8.7764e-05 lr: 8.7764e-06  eta: 13:07:56  time: 0.5929  data_time: 0.0097  memory: 10675  grad_norm: 351.4518  loss: 21.3593  decode.loss_cls: 0.0955  decode.loss_mask: 0.5877  decode.loss_dice: 1.4562  decode.d0.loss_cls: 0.0950  decode.d0.loss_mask: 0.6131  decode.d0.loss_dice: 1.5178  decode.d1.loss_cls: 0.0745  decode.d1.loss_mask: 0.5871  decode.d1.loss_dice: 1.4912  decode.d2.loss_cls: 0.1120  decode.d2.loss_mask: 0.5842  decode.d2.loss_dice: 1.4366  decode.d3.loss_cls: 0.0968  decode.d3.loss_mask: 0.5935  decode.d3.loss_dice: 1.4242  decode.d4.loss_cls: 0.1025  decode.d4.loss_mask: 0.5893  decode.d4.loss_dice: 1.4247  decode.d5.loss_cls: 0.1089  decode.d5.loss_mask: 0.5846  decode.d5.loss_dice: 1.4262  decode.d6.loss_cls: 0.1074  decode.d6.loss_mask: 0.5956  decode.d6.loss_dice: 1.4328  decode.d7.loss_cls: 0.0965  decode.d7.loss_mask: 0.5988  decode.d7.loss_dice: 1.4128  decode.d8.loss_cls: 0.1076  decode.d8.loss_mask: 0.5808  decode.d8.loss_dice: 1.4256
11/15 08:54:13 - mmengine - INFO - Iter(train) [12200/90000]  base_lr: 8.7714e-05 lr: 8.7714e-06  eta: 13:07:21  time: 0.5924  data_time: 0.0097  memory: 10692  grad_norm: 1450.8897  loss: 21.4365  decode.loss_cls: 0.0921  decode.loss_mask: 0.6573  decode.loss_dice: 1.3204  decode.d0.loss_cls: 0.0872  decode.d0.loss_mask: 0.7042  decode.d0.loss_dice: 1.4594  decode.d1.loss_cls: 0.0749  decode.d1.loss_mask: 0.6576  decode.d1.loss_dice: 1.4089  decode.d2.loss_cls: 0.0957  decode.d2.loss_mask: 0.6491  decode.d2.loss_dice: 1.4082  decode.d3.loss_cls: 0.0997  decode.d3.loss_mask: 0.6611  decode.d3.loss_dice: 1.3565  decode.d4.loss_cls: 0.0778  decode.d4.loss_mask: 0.7746  decode.d4.loss_dice: 1.3698  decode.d5.loss_cls: 0.0911  decode.d5.loss_mask: 0.6508  decode.d5.loss_dice: 1.3300  decode.d6.loss_cls: 0.0935  decode.d6.loss_mask: 0.6606  decode.d6.loss_dice: 1.3854  decode.d7.loss_cls: 0.0958  decode.d7.loss_mask: 0.6726  decode.d7.loss_dice: 1.3740  decode.d8.loss_cls: 0.0872  decode.d8.loss_mask: 0.6647  decode.d8.loss_dice: 1.3762
11/15 08:54:42 - mmengine - INFO - Iter(train) [12250/90000]  base_lr: 8.7663e-05 lr: 8.7663e-06  eta: 13:06:46  time: 0.5945  data_time: 0.0095  memory: 10675  grad_norm: 401.5764  loss: 18.7453  decode.loss_cls: 0.0715  decode.loss_mask: 0.5565  decode.loss_dice: 1.2499  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.5815  decode.d0.loss_dice: 1.3395  decode.d1.loss_cls: 0.0978  decode.d1.loss_mask: 0.5581  decode.d1.loss_dice: 1.2244  decode.d2.loss_cls: 0.0758  decode.d2.loss_mask: 0.5611  decode.d2.loss_dice: 1.2469  decode.d3.loss_cls: 0.0818  decode.d3.loss_mask: 0.5498  decode.d3.loss_dice: 1.2189  decode.d4.loss_cls: 0.0692  decode.d4.loss_mask: 0.5448  decode.d4.loss_dice: 1.2475  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.5341  decode.d5.loss_dice: 1.2312  decode.d6.loss_cls: 0.0641  decode.d6.loss_mask: 0.5616  decode.d6.loss_dice: 1.2283  decode.d7.loss_cls: 0.0615  decode.d7.loss_mask: 0.5575  decode.d7.loss_dice: 1.2391  decode.d8.loss_cls: 0.0648  decode.d8.loss_mask: 0.5451  decode.d8.loss_dice: 1.2210
11/15 08:55:12 - mmengine - INFO - Iter(train) [12300/90000]  base_lr: 8.7612e-05 lr: 8.7612e-06  eta: 13:06:11  time: 0.5931  data_time: 0.0098  memory: 10728  grad_norm: 330.4832  loss: 21.1245  decode.loss_cls: 0.0628  decode.loss_mask: 0.6469  decode.loss_dice: 1.3807  decode.d0.loss_cls: 0.0835  decode.d0.loss_mask: 0.6766  decode.d0.loss_dice: 1.4619  decode.d1.loss_cls: 0.0701  decode.d1.loss_mask: 0.6486  decode.d1.loss_dice: 1.4021  decode.d2.loss_cls: 0.0696  decode.d2.loss_mask: 0.6448  decode.d2.loss_dice: 1.3844  decode.d3.loss_cls: 0.0619  decode.d3.loss_mask: 0.6348  decode.d3.loss_dice: 1.3886  decode.d4.loss_cls: 0.0656  decode.d4.loss_mask: 0.6411  decode.d4.loss_dice: 1.4069  decode.d5.loss_cls: 0.0716  decode.d5.loss_mask: 0.6278  decode.d5.loss_dice: 1.3802  decode.d6.loss_cls: 0.0736  decode.d6.loss_mask: 0.6369  decode.d6.loss_dice: 1.3701  decode.d7.loss_cls: 0.0649  decode.d7.loss_mask: 0.6497  decode.d7.loss_dice: 1.3920  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 0.6498  decode.d8.loss_dice: 1.4153
11/15 08:55:43 - mmengine - INFO - Iter(train) [12350/90000]  base_lr: 8.7562e-05 lr: 8.7562e-06  eta: 13:05:46  time: 0.5926  data_time: 0.0097  memory: 10692  grad_norm: 332.2659  loss: 19.8134  decode.loss_cls: 0.0679  decode.loss_mask: 0.6366  decode.loss_dice: 1.2716  decode.d0.loss_cls: 0.0714  decode.d0.loss_mask: 0.6816  decode.d0.loss_dice: 1.3727  decode.d1.loss_cls: 0.0840  decode.d1.loss_mask: 0.6533  decode.d1.loss_dice: 1.2673  decode.d2.loss_cls: 0.0773  decode.d2.loss_mask: 0.6401  decode.d2.loss_dice: 1.2562  decode.d3.loss_cls: 0.0679  decode.d3.loss_mask: 0.6289  decode.d3.loss_dice: 1.2602  decode.d4.loss_cls: 0.0650  decode.d4.loss_mask: 0.6619  decode.d4.loss_dice: 1.2545  decode.d5.loss_cls: 0.0948  decode.d5.loss_mask: 0.6421  decode.d5.loss_dice: 1.2144  decode.d6.loss_cls: 0.0637  decode.d6.loss_mask: 0.6409  decode.d6.loss_dice: 1.2466  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.6411  decode.d7.loss_dice: 1.2629  decode.d8.loss_cls: 0.0630  decode.d8.loss_mask: 0.6305  decode.d8.loss_dice: 1.2244
11/15 08:56:13 - mmengine - INFO - Iter(train) [12400/90000]  base_lr: 8.7511e-05 lr: 8.7511e-06  eta: 13:05:11  time: 0.5936  data_time: 0.0098  memory: 10675  grad_norm: 441.3117  loss: 20.7924  decode.loss_cls: 0.1057  decode.loss_mask: 0.6562  decode.loss_dice: 1.3417  decode.d0.loss_cls: 0.1173  decode.d0.loss_mask: 0.6568  decode.d0.loss_dice: 1.4037  decode.d1.loss_cls: 0.0968  decode.d1.loss_mask: 0.6476  decode.d1.loss_dice: 1.3701  decode.d2.loss_cls: 0.1026  decode.d2.loss_mask: 0.6530  decode.d2.loss_dice: 1.3041  decode.d3.loss_cls: 0.1153  decode.d3.loss_mask: 0.6201  decode.d3.loss_dice: 1.2802  decode.d4.loss_cls: 0.1205  decode.d4.loss_mask: 0.6404  decode.d4.loss_dice: 1.2888  decode.d5.loss_cls: 0.1146  decode.d5.loss_mask: 0.6346  decode.d5.loss_dice: 1.2676  decode.d6.loss_cls: 0.1111  decode.d6.loss_mask: 0.6640  decode.d6.loss_dice: 1.2631  decode.d7.loss_cls: 0.1060  decode.d7.loss_mask: 0.6755  decode.d7.loss_dice: 1.2886  decode.d8.loss_cls: 0.0974  decode.d8.loss_mask: 0.6804  decode.d8.loss_dice: 1.3689
11/15 08:56:42 - mmengine - INFO - Iter(train) [12450/90000]  base_lr: 8.7460e-05 lr: 8.7460e-06  eta: 13:04:37  time: 0.5926  data_time: 0.0097  memory: 10675  grad_norm: 820.6563  loss: 21.7284  decode.loss_cls: 0.0534  decode.loss_mask: 0.7154  decode.loss_dice: 1.3714  decode.d0.loss_cls: 0.0763  decode.d0.loss_mask: 0.7424  decode.d0.loss_dice: 1.4186  decode.d1.loss_cls: 0.0543  decode.d1.loss_mask: 0.7305  decode.d1.loss_dice: 1.3922  decode.d2.loss_cls: 0.0386  decode.d2.loss_mask: 0.7214  decode.d2.loss_dice: 1.3985  decode.d3.loss_cls: 0.0463  decode.d3.loss_mask: 0.7255  decode.d3.loss_dice: 1.3856  decode.d4.loss_cls: 0.0546  decode.d4.loss_mask: 0.7131  decode.d4.loss_dice: 1.3679  decode.d5.loss_cls: 0.0528  decode.d5.loss_mask: 0.7291  decode.d5.loss_dice: 1.3856  decode.d6.loss_cls: 0.0523  decode.d6.loss_mask: 0.7633  decode.d6.loss_dice: 1.4019  decode.d7.loss_cls: 0.0567  decode.d7.loss_mask: 0.7279  decode.d7.loss_dice: 1.3949  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.7253  decode.d8.loss_dice: 1.3733
11/15 08:57:12 - mmengine - INFO - Iter(train) [12500/90000]  base_lr: 8.7409e-05 lr: 8.7409e-06  eta: 13:04:02  time: 0.5941  data_time: 0.0098  memory: 10692  grad_norm: 442.0305  loss: 18.4206  decode.loss_cls: 0.0598  decode.loss_mask: 0.4958  decode.loss_dice: 1.2545  decode.d0.loss_cls: 0.0727  decode.d0.loss_mask: 0.4976  decode.d0.loss_dice: 1.3272  decode.d1.loss_cls: 0.0697  decode.d1.loss_mask: 0.4896  decode.d1.loss_dice: 1.3030  decode.d2.loss_cls: 0.0824  decode.d2.loss_mask: 0.4884  decode.d2.loss_dice: 1.2823  decode.d3.loss_cls: 0.0768  decode.d3.loss_mask: 0.4882  decode.d3.loss_dice: 1.2825  decode.d4.loss_cls: 0.0697  decode.d4.loss_mask: 0.4970  decode.d4.loss_dice: 1.2589  decode.d5.loss_cls: 0.0639  decode.d5.loss_mask: 0.4943  decode.d5.loss_dice: 1.2629  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.4956  decode.d6.loss_dice: 1.2701  decode.d7.loss_cls: 0.0843  decode.d7.loss_mask: 0.5007  decode.d7.loss_dice: 1.2468  decode.d8.loss_cls: 0.0630  decode.d8.loss_mask: 0.4898  decode.d8.loss_dice: 1.2875
11/15 08:57:42 - mmengine - INFO - Iter(train) [12550/90000]  base_lr: 8.7359e-05 lr: 8.7359e-06  eta: 13:03:28  time: 0.5936  data_time: 0.0096  memory: 10692  grad_norm: 325.1606  loss: 19.2216  decode.loss_cls: 0.0614  decode.loss_mask: 0.5753  decode.loss_dice: 1.2706  decode.d0.loss_cls: 0.0846  decode.d0.loss_mask: 0.6069  decode.d0.loss_dice: 1.3195  decode.d1.loss_cls: 0.0653  decode.d1.loss_mask: 0.5776  decode.d1.loss_dice: 1.2707  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.5824  decode.d2.loss_dice: 1.2478  decode.d3.loss_cls: 0.0655  decode.d3.loss_mask: 0.5828  decode.d3.loss_dice: 1.2507  decode.d4.loss_cls: 0.0671  decode.d4.loss_mask: 0.5820  decode.d4.loss_dice: 1.2565  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.5897  decode.d5.loss_dice: 1.2926  decode.d6.loss_cls: 0.0560  decode.d6.loss_mask: 0.5929  decode.d6.loss_dice: 1.2725  decode.d7.loss_cls: 0.0506  decode.d7.loss_mask: 0.5946  decode.d7.loss_dice: 1.2525  decode.d8.loss_cls: 0.0539  decode.d8.loss_mask: 0.5882  decode.d8.loss_dice: 1.2911
11/15 08:58:12 - mmengine - INFO - Iter(train) [12600/90000]  base_lr: 8.7308e-05 lr: 8.7308e-06  eta: 13:02:54  time: 0.5953  data_time: 0.0096  memory: 10656  grad_norm: 515.4314  loss: 21.2280  decode.loss_cls: 0.0685  decode.loss_mask: 0.6862  decode.loss_dice: 1.4023  decode.d0.loss_cls: 0.0901  decode.d0.loss_mask: 0.6536  decode.d0.loss_dice: 1.4665  decode.d1.loss_cls: 0.0911  decode.d1.loss_mask: 0.6433  decode.d1.loss_dice: 1.3549  decode.d2.loss_cls: 0.0822  decode.d2.loss_mask: 0.6490  decode.d2.loss_dice: 1.3542  decode.d3.loss_cls: 0.0889  decode.d3.loss_mask: 0.6528  decode.d3.loss_dice: 1.3516  decode.d4.loss_cls: 0.0808  decode.d4.loss_mask: 0.6685  decode.d4.loss_dice: 1.3759  decode.d5.loss_cls: 0.0895  decode.d5.loss_mask: 0.6788  decode.d5.loss_dice: 1.3498  decode.d6.loss_cls: 0.0806  decode.d6.loss_mask: 0.6786  decode.d6.loss_dice: 1.3531  decode.d7.loss_cls: 0.0891  decode.d7.loss_mask: 0.6685  decode.d7.loss_dice: 1.3675  decode.d8.loss_cls: 0.0803  decode.d8.loss_mask: 0.6720  decode.d8.loss_dice: 1.3598
11/15 08:58:41 - mmengine - INFO - Iter(train) [12650/90000]  base_lr: 8.7257e-05 lr: 8.7257e-06  eta: 13:02:20  time: 0.5991  data_time: 0.0098  memory: 10742  grad_norm: 533.7609  loss: 22.6310  decode.loss_cls: 0.1032  decode.loss_mask: 0.7005  decode.loss_dice: 1.4672  decode.d0.loss_cls: 0.1043  decode.d0.loss_mask: 0.7460  decode.d0.loss_dice: 1.5313  decode.d1.loss_cls: 0.0983  decode.d1.loss_mask: 0.6695  decode.d1.loss_dice: 1.4936  decode.d2.loss_cls: 0.1209  decode.d2.loss_mask: 0.6609  decode.d2.loss_dice: 1.4526  decode.d3.loss_cls: 0.1232  decode.d3.loss_mask: 0.6515  decode.d3.loss_dice: 1.4581  decode.d4.loss_cls: 0.1090  decode.d4.loss_mask: 0.6733  decode.d4.loss_dice: 1.4686  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.6665  decode.d5.loss_dice: 1.4621  decode.d6.loss_cls: 0.1025  decode.d6.loss_mask: 0.6898  decode.d6.loss_dice: 1.4704  decode.d7.loss_cls: 0.1027  decode.d7.loss_mask: 0.6835  decode.d7.loss_dice: 1.4606  decode.d8.loss_cls: 0.1056  decode.d8.loss_mask: 0.6645  decode.d8.loss_dice: 1.4812
11/15 08:59:11 - mmengine - INFO - Iter(train) [12700/90000]  base_lr: 8.7206e-05 lr: 8.7206e-06  eta: 13:01:46  time: 0.5962  data_time: 0.0099  memory: 10692  grad_norm: 494.2508  loss: 20.6509  decode.loss_cls: 0.0763  decode.loss_mask: 0.6660  decode.loss_dice: 1.3544  decode.d0.loss_cls: 0.0896  decode.d0.loss_mask: 0.6582  decode.d0.loss_dice: 1.4068  decode.d1.loss_cls: 0.0743  decode.d1.loss_mask: 0.6181  decode.d1.loss_dice: 1.3536  decode.d2.loss_cls: 0.0809  decode.d2.loss_mask: 0.6425  decode.d2.loss_dice: 1.3749  decode.d3.loss_cls: 0.0863  decode.d3.loss_mask: 0.6466  decode.d3.loss_dice: 1.3059  decode.d4.loss_cls: 0.0943  decode.d4.loss_mask: 0.6325  decode.d4.loss_dice: 1.3249  decode.d5.loss_cls: 0.0855  decode.d5.loss_mask: 0.6219  decode.d5.loss_dice: 1.3078  decode.d6.loss_cls: 0.0808  decode.d6.loss_mask: 0.6321  decode.d6.loss_dice: 1.3185  decode.d7.loss_cls: 0.0712  decode.d7.loss_mask: 0.6341  decode.d7.loss_dice: 1.3286  decode.d8.loss_cls: 0.0610  decode.d8.loss_mask: 0.6563  decode.d8.loss_dice: 1.3670
11/15 08:59:41 - mmengine - INFO - Iter(train) [12750/90000]  base_lr: 8.7155e-05 lr: 8.7155e-06  eta: 13:01:13  time: 0.5947  data_time: 0.0099  memory: 10713  grad_norm: 735.5180  loss: 20.3187  decode.loss_cls: 0.0652  decode.loss_mask: 0.6607  decode.loss_dice: 1.3079  decode.d0.loss_cls: 0.0736  decode.d0.loss_mask: 0.7043  decode.d0.loss_dice: 1.3440  decode.d1.loss_cls: 0.0785  decode.d1.loss_mask: 0.6618  decode.d1.loss_dice: 1.2621  decode.d2.loss_cls: 0.0635  decode.d2.loss_mask: 0.6753  decode.d2.loss_dice: 1.2762  decode.d3.loss_cls: 0.0641  decode.d3.loss_mask: 0.6753  decode.d3.loss_dice: 1.2601  decode.d4.loss_cls: 0.0714  decode.d4.loss_mask: 0.6697  decode.d4.loss_dice: 1.2857  decode.d5.loss_cls: 0.0599  decode.d5.loss_mask: 0.6764  decode.d5.loss_dice: 1.2998  decode.d6.loss_cls: 0.0631  decode.d6.loss_mask: 0.6689  decode.d6.loss_dice: 1.3079  decode.d7.loss_cls: 0.0612  decode.d7.loss_mask: 0.6823  decode.d7.loss_dice: 1.2957  decode.d8.loss_cls: 0.0697  decode.d8.loss_mask: 0.6583  decode.d8.loss_dice: 1.2761
11/15 09:00:11 - mmengine - INFO - Iter(train) [12800/90000]  base_lr: 8.7105e-05 lr: 8.7105e-06  eta: 13:00:41  time: 0.6380  data_time: 0.0098  memory: 10713  grad_norm: 703.3554  loss: 22.7699  decode.loss_cls: 0.1069  decode.loss_mask: 0.6935  decode.loss_dice: 1.4863  decode.d0.loss_cls: 0.1141  decode.d0.loss_mask: 0.6859  decode.d0.loss_dice: 1.5332  decode.d1.loss_cls: 0.0989  decode.d1.loss_mask: 0.6915  decode.d1.loss_dice: 1.4745  decode.d2.loss_cls: 0.0993  decode.d2.loss_mask: 0.6926  decode.d2.loss_dice: 1.4832  decode.d3.loss_cls: 0.1021  decode.d3.loss_mask: 0.7077  decode.d3.loss_dice: 1.4460  decode.d4.loss_cls: 0.1078  decode.d4.loss_mask: 0.6932  decode.d4.loss_dice: 1.4487  decode.d5.loss_cls: 0.1015  decode.d5.loss_mask: 0.6877  decode.d5.loss_dice: 1.4518  decode.d6.loss_cls: 0.1001  decode.d6.loss_mask: 0.7069  decode.d6.loss_dice: 1.4452  decode.d7.loss_cls: 0.0924  decode.d7.loss_mask: 0.7144  decode.d7.loss_dice: 1.5071  decode.d8.loss_cls: 0.1011  decode.d8.loss_mask: 0.6857  decode.d8.loss_dice: 1.5107
11/15 09:00:41 - mmengine - INFO - Iter(train) [12850/90000]  base_lr: 8.7054e-05 lr: 8.7054e-06  eta: 13:00:07  time: 0.5948  data_time: 0.0096  memory: 10656  grad_norm: 617.1043  loss: 20.4517  decode.loss_cls: 0.0839  decode.loss_mask: 0.6260  decode.loss_dice: 1.3319  decode.d0.loss_cls: 0.0923  decode.d0.loss_mask: 0.6356  decode.d0.loss_dice: 1.3819  decode.d1.loss_cls: 0.0940  decode.d1.loss_mask: 0.6391  decode.d1.loss_dice: 1.3051  decode.d2.loss_cls: 0.0895  decode.d2.loss_mask: 0.6250  decode.d2.loss_dice: 1.3240  decode.d3.loss_cls: 0.0834  decode.d3.loss_mask: 0.6286  decode.d3.loss_dice: 1.3045  decode.d4.loss_cls: 0.0777  decode.d4.loss_mask: 0.6294  decode.d4.loss_dice: 1.3381  decode.d5.loss_cls: 0.0869  decode.d5.loss_mask: 0.6297  decode.d5.loss_dice: 1.3179  decode.d6.loss_cls: 0.1081  decode.d6.loss_mask: 0.6355  decode.d6.loss_dice: 1.3148  decode.d7.loss_cls: 0.0838  decode.d7.loss_mask: 0.6398  decode.d7.loss_dice: 1.2970  decode.d8.loss_cls: 0.0978  decode.d8.loss_mask: 0.6263  decode.d8.loss_dice: 1.3242
11/15 09:01:11 - mmengine - INFO - Iter(train) [12900/90000]  base_lr: 8.7003e-05 lr: 8.7003e-06  eta: 12:59:33  time: 0.5947  data_time: 0.0099  memory: 10692  grad_norm: 475.0394  loss: 20.7572  decode.loss_cls: 0.0785  decode.loss_mask: 0.7360  decode.loss_dice: 1.2634  decode.d0.loss_cls: 0.0913  decode.d0.loss_mask: 0.7883  decode.d0.loss_dice: 1.2943  decode.d1.loss_cls: 0.0846  decode.d1.loss_mask: 0.7354  decode.d1.loss_dice: 1.2913  decode.d2.loss_cls: 0.0688  decode.d2.loss_mask: 0.7296  decode.d2.loss_dice: 1.2643  decode.d3.loss_cls: 0.0759  decode.d3.loss_mask: 0.7031  decode.d3.loss_dice: 1.2459  decode.d4.loss_cls: 0.0757  decode.d4.loss_mask: 0.7045  decode.d4.loss_dice: 1.2617  decode.d5.loss_cls: 0.0694  decode.d5.loss_mask: 0.7105  decode.d5.loss_dice: 1.2516  decode.d6.loss_cls: 0.0644  decode.d6.loss_mask: 0.7031  decode.d6.loss_dice: 1.2655  decode.d7.loss_cls: 0.0746  decode.d7.loss_mask: 0.7445  decode.d7.loss_dice: 1.2691  decode.d8.loss_cls: 0.0649  decode.d8.loss_mask: 0.7428  decode.d8.loss_dice: 1.3041
11/15 09:01:40 - mmengine - INFO - Iter(train) [12950/90000]  base_lr: 8.6952e-05 lr: 8.6952e-06  eta: 12:58:59  time: 0.5937  data_time: 0.0099  memory: 10656  grad_norm: 417.4213  loss: 21.8759  decode.loss_cls: 0.0717  decode.loss_mask: 0.7343  decode.loss_dice: 1.3800  decode.d0.loss_cls: 0.0868  decode.d0.loss_mask: 0.7687  decode.d0.loss_dice: 1.4296  decode.d1.loss_cls: 0.0802  decode.d1.loss_mask: 0.7259  decode.d1.loss_dice: 1.3825  decode.d2.loss_cls: 0.0847  decode.d2.loss_mask: 0.7148  decode.d2.loss_dice: 1.3551  decode.d3.loss_cls: 0.0748  decode.d3.loss_mask: 0.7024  decode.d3.loss_dice: 1.3548  decode.d4.loss_cls: 0.0783  decode.d4.loss_mask: 0.7391  decode.d4.loss_dice: 1.3930  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 0.7464  decode.d5.loss_dice: 1.3665  decode.d6.loss_cls: 0.0764  decode.d6.loss_mask: 0.7228  decode.d6.loss_dice: 1.3656  decode.d7.loss_cls: 0.0794  decode.d7.loss_mask: 0.7237  decode.d7.loss_dice: 1.3578  decode.d8.loss_cls: 0.0699  decode.d8.loss_mask: 0.7550  decode.d8.loss_dice: 1.3801
11/15 09:02:10 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 09:02:10 - mmengine - INFO - Iter(train) [13000/90000]  base_lr: 8.6902e-05 lr: 8.6902e-06  eta: 12:58:25  time: 0.5922  data_time: 0.0095  memory: 10641  grad_norm: 935.4509  loss: 21.5989  decode.loss_cls: 0.0568  decode.loss_mask: 0.7153  decode.loss_dice: 1.3764  decode.d0.loss_cls: 0.0850  decode.d0.loss_mask: 0.7781  decode.d0.loss_dice: 1.4585  decode.d1.loss_cls: 0.0744  decode.d1.loss_mask: 0.7022  decode.d1.loss_dice: 1.3853  decode.d2.loss_cls: 0.0730  decode.d2.loss_mask: 0.6994  decode.d2.loss_dice: 1.3798  decode.d3.loss_cls: 0.0768  decode.d3.loss_mask: 0.6973  decode.d3.loss_dice: 1.3472  decode.d4.loss_cls: 0.0729  decode.d4.loss_mask: 0.6961  decode.d4.loss_dice: 1.3608  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 0.6960  decode.d5.loss_dice: 1.3717  decode.d6.loss_cls: 0.0708  decode.d6.loss_mask: 0.7015  decode.d6.loss_dice: 1.3599  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.7302  decode.d7.loss_dice: 1.3590  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.7157  decode.d8.loss_dice: 1.3678
11/15 09:02:40 - mmengine - INFO - Iter(train) [13050/90000]  base_lr: 8.6851e-05 lr: 8.6851e-06  eta: 12:57:51  time: 0.5939  data_time: 0.0100  memory: 10713  grad_norm: 447.4794  loss: 22.4697  decode.loss_cls: 0.1088  decode.loss_mask: 0.7227  decode.loss_dice: 1.4407  decode.d0.loss_cls: 0.0864  decode.d0.loss_mask: 0.7961  decode.d0.loss_dice: 1.5010  decode.d1.loss_cls: 0.0991  decode.d1.loss_mask: 0.7305  decode.d1.loss_dice: 1.4017  decode.d2.loss_cls: 0.0971  decode.d2.loss_mask: 0.7180  decode.d2.loss_dice: 1.3708  decode.d3.loss_cls: 0.0925  decode.d3.loss_mask: 0.7093  decode.d3.loss_dice: 1.3856  decode.d4.loss_cls: 0.0821  decode.d4.loss_mask: 0.7133  decode.d4.loss_dice: 1.4369  decode.d5.loss_cls: 0.1017  decode.d5.loss_mask: 0.7162  decode.d5.loss_dice: 1.4205  decode.d6.loss_cls: 0.1011  decode.d6.loss_mask: 0.7190  decode.d6.loss_dice: 1.3737  decode.d7.loss_cls: 0.1086  decode.d7.loss_mask: 0.7448  decode.d7.loss_dice: 1.4144  decode.d8.loss_cls: 0.1017  decode.d8.loss_mask: 0.7392  decode.d8.loss_dice: 1.4362
11/15 09:03:09 - mmengine - INFO - Iter(train) [13100/90000]  base_lr: 8.6800e-05 lr: 8.6800e-06  eta: 12:57:17  time: 0.5926  data_time: 0.0095  memory: 10728  grad_norm: 555.7439  loss: 19.2721  decode.loss_cls: 0.0607  decode.loss_mask: 0.6819  decode.loss_dice: 1.1780  decode.d0.loss_cls: 0.0897  decode.d0.loss_mask: 0.6892  decode.d0.loss_dice: 1.2210  decode.d1.loss_cls: 0.0630  decode.d1.loss_mask: 0.6850  decode.d1.loss_dice: 1.2155  decode.d2.loss_cls: 0.0732  decode.d2.loss_mask: 0.6573  decode.d2.loss_dice: 1.1703  decode.d3.loss_cls: 0.0540  decode.d3.loss_mask: 0.6847  decode.d3.loss_dice: 1.1845  decode.d4.loss_cls: 0.0632  decode.d4.loss_mask: 0.6771  decode.d4.loss_dice: 1.1750  decode.d5.loss_cls: 0.0704  decode.d5.loss_mask: 0.6460  decode.d5.loss_dice: 1.1653  decode.d6.loss_cls: 0.0675  decode.d6.loss_mask: 0.6846  decode.d6.loss_dice: 1.1627  decode.d7.loss_cls: 0.0652  decode.d7.loss_mask: 0.6803  decode.d7.loss_dice: 1.1952  decode.d8.loss_cls: 0.0727  decode.d8.loss_mask: 0.6721  decode.d8.loss_dice: 1.1668
11/15 09:03:39 - mmengine - INFO - Iter(train) [13150/90000]  base_lr: 8.6749e-05 lr: 8.6749e-06  eta: 12:56:44  time: 0.5935  data_time: 0.0097  memory: 10675  grad_norm: 367.9365  loss: 19.9875  decode.loss_cls: 0.0735  decode.loss_mask: 0.6153  decode.loss_dice: 1.3460  decode.d0.loss_cls: 0.0902  decode.d0.loss_mask: 0.6162  decode.d0.loss_dice: 1.3877  decode.d1.loss_cls: 0.0713  decode.d1.loss_mask: 0.5787  decode.d1.loss_dice: 1.3320  decode.d2.loss_cls: 0.0805  decode.d2.loss_mask: 0.5839  decode.d2.loss_dice: 1.3010  decode.d3.loss_cls: 0.0713  decode.d3.loss_mask: 0.5906  decode.d3.loss_dice: 1.3069  decode.d4.loss_cls: 0.0753  decode.d4.loss_mask: 0.5808  decode.d4.loss_dice: 1.2874  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.5970  decode.d5.loss_dice: 1.3186  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.6066  decode.d6.loss_dice: 1.3200  decode.d7.loss_cls: 0.0576  decode.d7.loss_mask: 0.6104  decode.d7.loss_dice: 1.3469  decode.d8.loss_cls: 0.0659  decode.d8.loss_mask: 0.6126  decode.d8.loss_dice: 1.3365
11/15 09:04:09 - mmengine - INFO - Iter(train) [13200/90000]  base_lr: 8.6698e-05 lr: 8.6698e-06  eta: 12:56:10  time: 0.5938  data_time: 0.0098  memory: 10675  grad_norm: 280.1283  loss: 20.3436  decode.loss_cls: 0.0773  decode.loss_mask: 0.5384  decode.loss_dice: 1.4308  decode.d0.loss_cls: 0.0699  decode.d0.loss_mask: 0.5250  decode.d0.loss_dice: 1.4914  decode.d1.loss_cls: 0.0749  decode.d1.loss_mask: 0.5354  decode.d1.loss_dice: 1.4354  decode.d2.loss_cls: 0.0846  decode.d2.loss_mask: 0.5151  decode.d2.loss_dice: 1.4033  decode.d3.loss_cls: 0.0809  decode.d3.loss_mask: 0.5153  decode.d3.loss_dice: 1.4231  decode.d4.loss_cls: 0.0728  decode.d4.loss_mask: 0.5046  decode.d4.loss_dice: 1.4176  decode.d5.loss_cls: 0.0723  decode.d5.loss_mask: 0.5162  decode.d5.loss_dice: 1.4323  decode.d6.loss_cls: 0.0760  decode.d6.loss_mask: 0.5448  decode.d6.loss_dice: 1.4632  decode.d7.loss_cls: 0.0705  decode.d7.loss_mask: 0.5185  decode.d7.loss_dice: 1.4193  decode.d8.loss_cls: 0.0591  decode.d8.loss_mask: 0.5272  decode.d8.loss_dice: 1.4485
11/15 09:04:39 - mmengine - INFO - Iter(train) [13250/90000]  base_lr: 8.6648e-05 lr: 8.6648e-06  eta: 12:55:36  time: 0.5964  data_time: 0.0100  memory: 10641  grad_norm: 362.9350  loss: 19.6322  decode.loss_cls: 0.0753  decode.loss_mask: 0.5892  decode.loss_dice: 1.3144  decode.d0.loss_cls: 0.0761  decode.d0.loss_mask: 0.6139  decode.d0.loss_dice: 1.3445  decode.d1.loss_cls: 0.0809  decode.d1.loss_mask: 0.5924  decode.d1.loss_dice: 1.3087  decode.d2.loss_cls: 0.0867  decode.d2.loss_mask: 0.5882  decode.d2.loss_dice: 1.2762  decode.d3.loss_cls: 0.0751  decode.d3.loss_mask: 0.5840  decode.d3.loss_dice: 1.2915  decode.d4.loss_cls: 0.0787  decode.d4.loss_mask: 0.5808  decode.d4.loss_dice: 1.2922  decode.d5.loss_cls: 0.0895  decode.d5.loss_mask: 0.5854  decode.d5.loss_dice: 1.2617  decode.d6.loss_cls: 0.0838  decode.d6.loss_mask: 0.5800  decode.d6.loss_dice: 1.2834  decode.d7.loss_cls: 0.0844  decode.d7.loss_mask: 0.5821  decode.d7.loss_dice: 1.2734  decode.d8.loss_cls: 0.0833  decode.d8.loss_mask: 0.5844  decode.d8.loss_dice: 1.2919
11/15 09:05:08 - mmengine - INFO - Iter(train) [13300/90000]  base_lr: 8.6597e-05 lr: 8.6597e-06  eta: 12:55:03  time: 0.5950  data_time: 0.0095  memory: 10692  grad_norm: 531.2858  loss: 22.5671  decode.loss_cls: 0.1102  decode.loss_mask: 0.6618  decode.loss_dice: 1.4787  decode.d0.loss_cls: 0.1178  decode.d0.loss_mask: 0.6408  decode.d0.loss_dice: 1.5842  decode.d1.loss_cls: 0.0993  decode.d1.loss_mask: 0.6373  decode.d1.loss_dice: 1.4889  decode.d2.loss_cls: 0.1172  decode.d2.loss_mask: 0.6396  decode.d2.loss_dice: 1.4938  decode.d3.loss_cls: 0.1235  decode.d3.loss_mask: 0.6417  decode.d3.loss_dice: 1.4590  decode.d4.loss_cls: 0.1171  decode.d4.loss_mask: 0.6470  decode.d4.loss_dice: 1.4181  decode.d5.loss_cls: 0.1050  decode.d5.loss_mask: 0.6554  decode.d5.loss_dice: 1.5317  decode.d6.loss_cls: 0.1181  decode.d6.loss_mask: 0.6552  decode.d6.loss_dice: 1.5177  decode.d7.loss_cls: 0.1017  decode.d7.loss_mask: 0.6445  decode.d7.loss_dice: 1.4966  decode.d8.loss_cls: 0.1043  decode.d8.loss_mask: 0.6541  decode.d8.loss_dice: 1.5066
11/15 09:05:38 - mmengine - INFO - Iter(train) [13350/90000]  base_lr: 8.6546e-05 lr: 8.6546e-06  eta: 12:54:30  time: 0.5959  data_time: 0.0096  memory: 10728  grad_norm: 871.2015  loss: 20.2612  decode.loss_cls: 0.0741  decode.loss_mask: 0.6468  decode.loss_dice: 1.2807  decode.d0.loss_cls: 0.0860  decode.d0.loss_mask: 0.6892  decode.d0.loss_dice: 1.3618  decode.d1.loss_cls: 0.0573  decode.d1.loss_mask: 0.6659  decode.d1.loss_dice: 1.3200  decode.d2.loss_cls: 0.0685  decode.d2.loss_mask: 0.6463  decode.d2.loss_dice: 1.3008  decode.d3.loss_cls: 0.0640  decode.d3.loss_mask: 0.6467  decode.d3.loss_dice: 1.2932  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 0.6385  decode.d4.loss_dice: 1.3111  decode.d5.loss_cls: 0.0641  decode.d5.loss_mask: 0.6507  decode.d5.loss_dice: 1.2996  decode.d6.loss_cls: 0.0627  decode.d6.loss_mask: 0.6519  decode.d6.loss_dice: 1.2681  decode.d7.loss_cls: 0.0713  decode.d7.loss_mask: 0.6519  decode.d7.loss_dice: 1.3106  decode.d8.loss_cls: 0.0641  decode.d8.loss_mask: 0.6506  decode.d8.loss_dice: 1.3083
11/15 09:06:08 - mmengine - INFO - Iter(train) [13400/90000]  base_lr: 8.6495e-05 lr: 8.6495e-06  eta: 12:53:56  time: 0.5937  data_time: 0.0096  memory: 10675  grad_norm: 406.2384  loss: 20.9395  decode.loss_cls: 0.0700  decode.loss_mask: 0.6809  decode.loss_dice: 1.3312  decode.d0.loss_cls: 0.0895  decode.d0.loss_mask: 0.7007  decode.d0.loss_dice: 1.4370  decode.d1.loss_cls: 0.0779  decode.d1.loss_mask: 0.6810  decode.d1.loss_dice: 1.3565  decode.d2.loss_cls: 0.0696  decode.d2.loss_mask: 0.6792  decode.d2.loss_dice: 1.3270  decode.d3.loss_cls: 0.0610  decode.d3.loss_mask: 0.6941  decode.d3.loss_dice: 1.2967  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.6935  decode.d4.loss_dice: 1.3068  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.6948  decode.d5.loss_dice: 1.3517  decode.d6.loss_cls: 0.0662  decode.d6.loss_mask: 0.6796  decode.d6.loss_dice: 1.3147  decode.d7.loss_cls: 0.0684  decode.d7.loss_mask: 0.6954  decode.d7.loss_dice: 1.3437  decode.d8.loss_cls: 0.0674  decode.d8.loss_mask: 0.6703  decode.d8.loss_dice: 1.3169
11/15 09:06:38 - mmengine - INFO - Iter(train) [13450/90000]  base_lr: 8.6444e-05 lr: 8.6444e-06  eta: 12:53:22  time: 0.5938  data_time: 0.0098  memory: 10692  grad_norm: 839.4013  loss: 21.5452  decode.loss_cls: 0.0622  decode.loss_mask: 0.7123  decode.loss_dice: 1.3660  decode.d0.loss_cls: 0.0805  decode.d0.loss_mask: 0.7504  decode.d0.loss_dice: 1.4086  decode.d1.loss_cls: 0.0656  decode.d1.loss_mask: 0.7255  decode.d1.loss_dice: 1.3738  decode.d2.loss_cls: 0.0810  decode.d2.loss_mask: 0.7106  decode.d2.loss_dice: 1.3311  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 0.7230  decode.d3.loss_dice: 1.3416  decode.d4.loss_cls: 0.0717  decode.d4.loss_mask: 0.7240  decode.d4.loss_dice: 1.3337  decode.d5.loss_cls: 0.0522  decode.d5.loss_mask: 0.7300  decode.d5.loss_dice: 1.3814  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.7435  decode.d6.loss_dice: 1.3488  decode.d7.loss_cls: 0.0553  decode.d7.loss_mask: 0.7184  decode.d7.loss_dice: 1.3680  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.7243  decode.d8.loss_dice: 1.3669
11/15 09:07:07 - mmengine - INFO - Iter(train) [13500/90000]  base_lr: 8.6394e-05 lr: 8.6394e-06  eta: 12:52:48  time: 0.5924  data_time: 0.0096  memory: 10692  grad_norm: 327.5147  loss: 18.9409  decode.loss_cls: 0.0869  decode.loss_mask: 0.5374  decode.loss_dice: 1.2428  decode.d0.loss_cls: 0.0915  decode.d0.loss_mask: 0.5685  decode.d0.loss_dice: 1.3474  decode.d1.loss_cls: 0.0768  decode.d1.loss_mask: 0.5347  decode.d1.loss_dice: 1.2923  decode.d2.loss_cls: 0.0929  decode.d2.loss_mask: 0.5369  decode.d2.loss_dice: 1.2743  decode.d3.loss_cls: 0.0820  decode.d3.loss_mask: 0.5360  decode.d3.loss_dice: 1.2438  decode.d4.loss_cls: 0.0798  decode.d4.loss_mask: 0.5361  decode.d4.loss_dice: 1.2740  decode.d5.loss_cls: 0.0896  decode.d5.loss_mask: 0.5386  decode.d5.loss_dice: 1.2697  decode.d6.loss_cls: 0.0854  decode.d6.loss_mask: 0.5332  decode.d6.loss_dice: 1.2515  decode.d7.loss_cls: 0.0759  decode.d7.loss_mask: 0.5310  decode.d7.loss_dice: 1.2663  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.5352  decode.d8.loss_dice: 1.2531
11/15 09:07:37 - mmengine - INFO - Iter(train) [13550/90000]  base_lr: 8.6343e-05 lr: 8.6343e-06  eta: 12:52:15  time: 0.5928  data_time: 0.0097  memory: 10713  grad_norm: 479.9534  loss: 18.7269  decode.loss_cls: 0.0306  decode.loss_mask: 0.6296  decode.loss_dice: 1.2044  decode.d0.loss_cls: 0.0586  decode.d0.loss_mask: 0.6313  decode.d0.loss_dice: 1.2760  decode.d1.loss_cls: 0.0478  decode.d1.loss_mask: 0.6246  decode.d1.loss_dice: 1.2006  decode.d2.loss_cls: 0.0408  decode.d2.loss_mask: 0.6251  decode.d2.loss_dice: 1.1821  decode.d3.loss_cls: 0.0371  decode.d3.loss_mask: 0.6280  decode.d3.loss_dice: 1.1902  decode.d4.loss_cls: 0.0339  decode.d4.loss_mask: 0.6262  decode.d4.loss_dice: 1.2005  decode.d5.loss_cls: 0.0343  decode.d5.loss_mask: 0.6304  decode.d5.loss_dice: 1.2125  decode.d6.loss_cls: 0.0407  decode.d6.loss_mask: 0.6120  decode.d6.loss_dice: 1.1901  decode.d7.loss_cls: 0.0428  decode.d7.loss_mask: 0.6226  decode.d7.loss_dice: 1.2017  decode.d8.loss_cls: 0.0337  decode.d8.loss_mask: 0.6353  decode.d8.loss_dice: 1.2036
11/15 09:08:07 - mmengine - INFO - Iter(train) [13600/90000]  base_lr: 8.6292e-05 lr: 8.6292e-06  eta: 12:51:41  time: 0.5967  data_time: 0.0099  memory: 10692  grad_norm: 262.4257  loss: 21.0737  decode.loss_cls: 0.0988  decode.loss_mask: 0.5620  decode.loss_dice: 1.4413  decode.d0.loss_cls: 0.0930  decode.d0.loss_mask: 0.5592  decode.d0.loss_dice: 1.5651  decode.d1.loss_cls: 0.1052  decode.d1.loss_mask: 0.5262  decode.d1.loss_dice: 1.4774  decode.d2.loss_cls: 0.1097  decode.d2.loss_mask: 0.5372  decode.d2.loss_dice: 1.4876  decode.d3.loss_cls: 0.1026  decode.d3.loss_mask: 0.5418  decode.d3.loss_dice: 1.4435  decode.d4.loss_cls: 0.1146  decode.d4.loss_mask: 0.5479  decode.d4.loss_dice: 1.4359  decode.d5.loss_cls: 0.1092  decode.d5.loss_mask: 0.5421  decode.d5.loss_dice: 1.4315  decode.d6.loss_cls: 0.1038  decode.d6.loss_mask: 0.5414  decode.d6.loss_dice: 1.4051  decode.d7.loss_cls: 0.0990  decode.d7.loss_mask: 0.5417  decode.d7.loss_dice: 1.4516  decode.d8.loss_cls: 0.1098  decode.d8.loss_mask: 0.5380  decode.d8.loss_dice: 1.4514
11/15 09:08:37 - mmengine - INFO - Iter(train) [13650/90000]  base_lr: 8.6241e-05 lr: 8.6241e-06  eta: 12:51:08  time: 0.5976  data_time: 0.0100  memory: 10675  grad_norm: 301.1164  loss: 20.5731  decode.loss_cls: 0.0654  decode.loss_mask: 0.6111  decode.loss_dice: 1.4009  decode.d0.loss_cls: 0.0786  decode.d0.loss_mask: 0.5800  decode.d0.loss_dice: 1.4339  decode.d1.loss_cls: 0.0882  decode.d1.loss_mask: 0.5819  decode.d1.loss_dice: 1.3933  decode.d2.loss_cls: 0.0926  decode.d2.loss_mask: 0.5832  decode.d2.loss_dice: 1.3677  decode.d3.loss_cls: 0.0795  decode.d3.loss_mask: 0.6024  decode.d3.loss_dice: 1.3706  decode.d4.loss_cls: 0.0645  decode.d4.loss_mask: 0.5923  decode.d4.loss_dice: 1.3855  decode.d5.loss_cls: 0.0688  decode.d5.loss_mask: 0.5876  decode.d5.loss_dice: 1.3825  decode.d6.loss_cls: 0.0640  decode.d6.loss_mask: 0.5934  decode.d6.loss_dice: 1.3906  decode.d7.loss_cls: 0.0726  decode.d7.loss_mask: 0.5894  decode.d7.loss_dice: 1.4041  decode.d8.loss_cls: 0.0731  decode.d8.loss_mask: 0.5740  decode.d8.loss_dice: 1.4013
11/15 09:09:07 - mmengine - INFO - Iter(train) [13700/90000]  base_lr: 8.6190e-05 lr: 8.6190e-06  eta: 12:50:35  time: 0.5986  data_time: 0.0100  memory: 10656  grad_norm: 427.3632  loss: 18.2751  decode.loss_cls: 0.0700  decode.loss_mask: 0.6022  decode.loss_dice: 1.1745  decode.d0.loss_cls: 0.0882  decode.d0.loss_mask: 0.6262  decode.d0.loss_dice: 1.2231  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.6065  decode.d1.loss_dice: 1.1820  decode.d2.loss_cls: 0.0846  decode.d2.loss_mask: 0.5931  decode.d2.loss_dice: 1.1662  decode.d3.loss_cls: 0.0653  decode.d3.loss_mask: 0.5926  decode.d3.loss_dice: 1.1253  decode.d4.loss_cls: 0.0620  decode.d4.loss_mask: 0.5878  decode.d4.loss_dice: 1.1559  decode.d5.loss_cls: 0.0647  decode.d5.loss_mask: 0.5913  decode.d5.loss_dice: 1.1338  decode.d6.loss_cls: 0.0708  decode.d6.loss_mask: 0.5863  decode.d6.loss_dice: 1.1349  decode.d7.loss_cls: 0.0699  decode.d7.loss_mask: 0.5937  decode.d7.loss_dice: 1.1393  decode.d8.loss_cls: 0.0780  decode.d8.loss_mask: 0.5865  decode.d8.loss_dice: 1.1360
11/15 09:09:36 - mmengine - INFO - Iter(train) [13750/90000]  base_lr: 8.6139e-05 lr: 8.6139e-06  eta: 12:50:03  time: 0.5969  data_time: 0.0099  memory: 10692  grad_norm: 373.7380  loss: 19.8633  decode.loss_cls: 0.0730  decode.loss_mask: 0.6241  decode.loss_dice: 1.2721  decode.d0.loss_cls: 0.0857  decode.d0.loss_mask: 0.6317  decode.d0.loss_dice: 1.3633  decode.d1.loss_cls: 0.0891  decode.d1.loss_mask: 0.6035  decode.d1.loss_dice: 1.2746  decode.d2.loss_cls: 0.0862  decode.d2.loss_mask: 0.6041  decode.d2.loss_dice: 1.2982  decode.d3.loss_cls: 0.0717  decode.d3.loss_mask: 0.6158  decode.d3.loss_dice: 1.3084  decode.d4.loss_cls: 0.0950  decode.d4.loss_mask: 0.6043  decode.d4.loss_dice: 1.2733  decode.d5.loss_cls: 0.1019  decode.d5.loss_mask: 0.6077  decode.d5.loss_dice: 1.2555  decode.d6.loss_cls: 0.0833  decode.d6.loss_mask: 0.6179  decode.d6.loss_dice: 1.2823  decode.d7.loss_cls: 0.0823  decode.d7.loss_mask: 0.6137  decode.d7.loss_dice: 1.2840  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.6211  decode.d8.loss_dice: 1.2730
11/15 09:10:06 - mmengine - INFO - Iter(train) [13800/90000]  base_lr: 8.6089e-05 lr: 8.6089e-06  eta: 12:49:31  time: 0.5986  data_time: 0.0101  memory: 10656  grad_norm: 418.8604  loss: 21.0451  decode.loss_cls: 0.0632  decode.loss_mask: 0.6976  decode.loss_dice: 1.3487  decode.d0.loss_cls: 0.0801  decode.d0.loss_mask: 0.6384  decode.d0.loss_dice: 1.4361  decode.d1.loss_cls: 0.0722  decode.d1.loss_mask: 0.6096  decode.d1.loss_dice: 1.3567  decode.d2.loss_cls: 0.0660  decode.d2.loss_mask: 0.6413  decode.d2.loss_dice: 1.3712  decode.d3.loss_cls: 0.0627  decode.d3.loss_mask: 0.6692  decode.d3.loss_dice: 1.3548  decode.d4.loss_cls: 0.0631  decode.d4.loss_mask: 0.6510  decode.d4.loss_dice: 1.3659  decode.d5.loss_cls: 0.0632  decode.d5.loss_mask: 0.6582  decode.d5.loss_dice: 1.3904  decode.d6.loss_cls: 0.0605  decode.d6.loss_mask: 0.6714  decode.d6.loss_dice: 1.3600  decode.d7.loss_cls: 0.0591  decode.d7.loss_mask: 0.7081  decode.d7.loss_dice: 1.4081  decode.d8.loss_cls: 0.0662  decode.d8.loss_mask: 0.6957  decode.d8.loss_dice: 1.3562
11/15 09:10:36 - mmengine - INFO - Iter(train) [13850/90000]  base_lr: 8.6038e-05 lr: 8.6038e-06  eta: 12:48:59  time: 0.6025  data_time: 0.0101  memory: 10692  grad_norm: 601.3745  loss: 19.7671  decode.loss_cls: 0.0742  decode.loss_mask: 0.6655  decode.loss_dice: 1.2249  decode.d0.loss_cls: 0.0956  decode.d0.loss_mask: 0.6928  decode.d0.loss_dice: 1.2857  decode.d1.loss_cls: 0.0837  decode.d1.loss_mask: 0.6590  decode.d1.loss_dice: 1.2398  decode.d2.loss_cls: 0.0748  decode.d2.loss_mask: 0.6578  decode.d2.loss_dice: 1.2336  decode.d3.loss_cls: 0.0850  decode.d3.loss_mask: 0.6598  decode.d3.loss_dice: 1.2162  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.6690  decode.d4.loss_dice: 1.2284  decode.d5.loss_cls: 0.0815  decode.d5.loss_mask: 0.6669  decode.d5.loss_dice: 1.2257  decode.d6.loss_cls: 0.0762  decode.d6.loss_mask: 0.6496  decode.d6.loss_dice: 1.2545  decode.d7.loss_cls: 0.0805  decode.d7.loss_mask: 0.6638  decode.d7.loss_dice: 1.2204  decode.d8.loss_cls: 0.0751  decode.d8.loss_mask: 0.6588  decode.d8.loss_dice: 1.2022
11/15 09:11:06 - mmengine - INFO - Iter(train) [13900/90000]  base_lr: 8.5987e-05 lr: 8.5987e-06  eta: 12:48:27  time: 0.5995  data_time: 0.0100  memory: 10713  grad_norm: 360.6181  loss: 20.2664  decode.loss_cls: 0.0709  decode.loss_mask: 0.6764  decode.loss_dice: 1.2970  decode.d0.loss_cls: 0.1084  decode.d0.loss_mask: 0.6788  decode.d0.loss_dice: 1.3136  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.6834  decode.d1.loss_dice: 1.2772  decode.d2.loss_cls: 0.0891  decode.d2.loss_mask: 0.6512  decode.d2.loss_dice: 1.2574  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.7042  decode.d3.loss_dice: 1.2467  decode.d4.loss_cls: 0.0752  decode.d4.loss_mask: 0.6831  decode.d4.loss_dice: 1.2464  decode.d5.loss_cls: 0.0746  decode.d5.loss_mask: 0.6621  decode.d5.loss_dice: 1.2631  decode.d6.loss_cls: 0.0693  decode.d6.loss_mask: 0.6709  decode.d6.loss_dice: 1.2714  decode.d7.loss_cls: 0.0845  decode.d7.loss_mask: 0.6637  decode.d7.loss_dice: 1.2834  decode.d8.loss_cls: 0.0853  decode.d8.loss_mask: 0.6694  decode.d8.loss_dice: 1.2696
11/15 09:11:36 - mmengine - INFO - Iter(train) [13950/90000]  base_lr: 8.5936e-05 lr: 8.5936e-06  eta: 12:47:55  time: 0.5996  data_time: 0.0101  memory: 10675  grad_norm: 359.6541  loss: 21.5263  decode.loss_cls: 0.1013  decode.loss_mask: 0.6222  decode.loss_dice: 1.4214  decode.d0.loss_cls: 0.1266  decode.d0.loss_mask: 0.6469  decode.d0.loss_dice: 1.5106  decode.d1.loss_cls: 0.1235  decode.d1.loss_mask: 0.6137  decode.d1.loss_dice: 1.4141  decode.d2.loss_cls: 0.1186  decode.d2.loss_mask: 0.5969  decode.d2.loss_dice: 1.3862  decode.d3.loss_cls: 0.1146  decode.d3.loss_mask: 0.5832  decode.d3.loss_dice: 1.3959  decode.d4.loss_cls: 0.1212  decode.d4.loss_mask: 0.6012  decode.d4.loss_dice: 1.4021  decode.d5.loss_cls: 0.1275  decode.d5.loss_mask: 0.6017  decode.d5.loss_dice: 1.3871  decode.d6.loss_cls: 0.1125  decode.d6.loss_mask: 0.6241  decode.d6.loss_dice: 1.3996  decode.d7.loss_cls: 0.1182  decode.d7.loss_mask: 0.6305  decode.d7.loss_dice: 1.4273  decode.d8.loss_cls: 0.1306  decode.d8.loss_mask: 0.6279  decode.d8.loss_dice: 1.4390
11/15 09:12:07 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 09:12:07 - mmengine - INFO - Iter(train) [14000/90000]  base_lr: 8.5885e-05 lr: 8.5885e-06  eta: 12:47:24  time: 0.6165  data_time: 0.0104  memory: 10742  grad_norm: 591.0385  loss: 20.1489  decode.loss_cls: 0.0952  decode.loss_mask: 0.5398  decode.loss_dice: 1.3361  decode.d0.loss_cls: 0.0942  decode.d0.loss_mask: 0.5785  decode.d0.loss_dice: 1.4495  decode.d1.loss_cls: 0.0957  decode.d1.loss_mask: 0.5749  decode.d1.loss_dice: 1.4050  decode.d2.loss_cls: 0.0870  decode.d2.loss_mask: 0.5677  decode.d2.loss_dice: 1.3680  decode.d3.loss_cls: 0.0875  decode.d3.loss_mask: 0.5692  decode.d3.loss_dice: 1.3473  decode.d4.loss_cls: 0.0985  decode.d4.loss_mask: 0.5751  decode.d4.loss_dice: 1.3514  decode.d5.loss_cls: 0.0808  decode.d5.loss_mask: 0.5684  decode.d5.loss_dice: 1.3390  decode.d6.loss_cls: 0.0806  decode.d6.loss_mask: 0.5575  decode.d6.loss_dice: 1.3496  decode.d7.loss_cls: 0.0957  decode.d7.loss_mask: 0.5548  decode.d7.loss_dice: 1.3341  decode.d8.loss_cls: 0.0876  decode.d8.loss_mask: 0.5533  decode.d8.loss_dice: 1.3268
11/15 09:12:37 - mmengine - INFO - Iter(train) [14050/90000]  base_lr: 8.5834e-05 lr: 8.5834e-06  eta: 12:46:52  time: 0.6004  data_time: 0.0099  memory: 10656  grad_norm: 353.4056  loss: 20.6408  decode.loss_cls: 0.0761  decode.loss_mask: 0.6692  decode.loss_dice: 1.3161  decode.d0.loss_cls: 0.0941  decode.d0.loss_mask: 0.6472  decode.d0.loss_dice: 1.4166  decode.d1.loss_cls: 0.0654  decode.d1.loss_mask: 0.6346  decode.d1.loss_dice: 1.3562  decode.d2.loss_cls: 0.0707  decode.d2.loss_mask: 0.6378  decode.d2.loss_dice: 1.3580  decode.d3.loss_cls: 0.0853  decode.d3.loss_mask: 0.6294  decode.d3.loss_dice: 1.3562  decode.d4.loss_cls: 0.0910  decode.d4.loss_mask: 0.6363  decode.d4.loss_dice: 1.3331  decode.d5.loss_cls: 0.0748  decode.d5.loss_mask: 0.6476  decode.d5.loss_dice: 1.3273  decode.d6.loss_cls: 0.0783  decode.d6.loss_mask: 0.6269  decode.d6.loss_dice: 1.3489  decode.d7.loss_cls: 0.0866  decode.d7.loss_mask: 0.6442  decode.d7.loss_dice: 1.3252  decode.d8.loss_cls: 0.0761  decode.d8.loss_mask: 0.6273  decode.d8.loss_dice: 1.3042
11/15 09:13:06 - mmengine - INFO - Iter(train) [14100/90000]  base_lr: 8.5783e-05 lr: 8.5783e-06  eta: 12:46:20  time: 0.5995  data_time: 0.0100  memory: 10758  grad_norm: 401.9980  loss: 20.3124  decode.loss_cls: 0.1005  decode.loss_mask: 0.5767  decode.loss_dice: 1.3423  decode.d0.loss_cls: 0.0904  decode.d0.loss_mask: 0.5929  decode.d0.loss_dice: 1.4174  decode.d1.loss_cls: 0.1135  decode.d1.loss_mask: 0.5823  decode.d1.loss_dice: 1.3640  decode.d2.loss_cls: 0.0878  decode.d2.loss_mask: 0.5862  decode.d2.loss_dice: 1.3420  decode.d3.loss_cls: 0.0916  decode.d3.loss_mask: 0.5863  decode.d3.loss_dice: 1.3501  decode.d4.loss_cls: 0.0923  decode.d4.loss_mask: 0.5908  decode.d4.loss_dice: 1.3621  decode.d5.loss_cls: 0.0939  decode.d5.loss_mask: 0.5747  decode.d5.loss_dice: 1.3437  decode.d6.loss_cls: 0.0989  decode.d6.loss_mask: 0.5818  decode.d6.loss_dice: 1.3320  decode.d7.loss_cls: 0.0904  decode.d7.loss_mask: 0.5713  decode.d7.loss_dice: 1.3486  decode.d8.loss_cls: 0.0932  decode.d8.loss_mask: 0.5649  decode.d8.loss_dice: 1.3497
11/15 09:13:37 - mmengine - INFO - Iter(train) [14150/90000]  base_lr: 8.5733e-05 lr: 8.5733e-06  eta: 12:45:48  time: 0.6043  data_time: 0.0135  memory: 10713  grad_norm: 458.7770  loss: 21.0438  decode.loss_cls: 0.0831  decode.loss_mask: 0.6518  decode.loss_dice: 1.4046  decode.d0.loss_cls: 0.1002  decode.d0.loss_mask: 0.6133  decode.d0.loss_dice: 1.4617  decode.d1.loss_cls: 0.0985  decode.d1.loss_mask: 0.6319  decode.d1.loss_dice: 1.4357  decode.d2.loss_cls: 0.0969  decode.d2.loss_mask: 0.5834  decode.d2.loss_dice: 1.3527  decode.d3.loss_cls: 0.0984  decode.d3.loss_mask: 0.6369  decode.d3.loss_dice: 1.3911  decode.d4.loss_cls: 0.0955  decode.d4.loss_mask: 0.6001  decode.d4.loss_dice: 1.3746  decode.d5.loss_cls: 0.0901  decode.d5.loss_mask: 0.5753  decode.d5.loss_dice: 1.3491  decode.d6.loss_cls: 0.0976  decode.d6.loss_mask: 0.5764  decode.d6.loss_dice: 1.3546  decode.d7.loss_cls: 0.0819  decode.d7.loss_mask: 0.6329  decode.d7.loss_dice: 1.3971  decode.d8.loss_cls: 0.0817  decode.d8.loss_mask: 0.6597  decode.d8.loss_dice: 1.4371
11/15 09:14:07 - mmengine - INFO - Iter(train) [14200/90000]  base_lr: 8.5682e-05 lr: 8.5682e-06  eta: 12:45:16  time: 0.5962  data_time: 0.0099  memory: 10692  grad_norm: 1322.7526  loss: 20.8555  decode.loss_cls: 0.0871  decode.loss_mask: 0.7297  decode.loss_dice: 1.2522  decode.d0.loss_cls: 0.0962  decode.d0.loss_mask: 0.7367  decode.d0.loss_dice: 1.2910  decode.d1.loss_cls: 0.0892  decode.d1.loss_mask: 0.7437  decode.d1.loss_dice: 1.2635  decode.d2.loss_cls: 0.0845  decode.d2.loss_mask: 0.7422  decode.d2.loss_dice: 1.2465  decode.d3.loss_cls: 0.0792  decode.d3.loss_mask: 0.7484  decode.d3.loss_dice: 1.2712  decode.d4.loss_cls: 0.0879  decode.d4.loss_mask: 0.7355  decode.d4.loss_dice: 1.2509  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.7400  decode.d5.loss_dice: 1.2535  decode.d6.loss_cls: 0.0768  decode.d6.loss_mask: 0.7376  decode.d6.loss_dice: 1.2803  decode.d7.loss_cls: 0.0899  decode.d7.loss_mask: 0.7212  decode.d7.loss_dice: 1.2546  decode.d8.loss_cls: 0.0819  decode.d8.loss_mask: 0.7322  decode.d8.loss_dice: 1.2660
11/15 09:14:37 - mmengine - INFO - Iter(train) [14250/90000]  base_lr: 8.5631e-05 lr: 8.5631e-06  eta: 12:44:45  time: 0.6006  data_time: 0.0101  memory: 10777  grad_norm: 495.4372  loss: 20.2402  decode.loss_cls: 0.0966  decode.loss_mask: 0.5446  decode.loss_dice: 1.3669  decode.d0.loss_cls: 0.1013  decode.d0.loss_mask: 0.5592  decode.d0.loss_dice: 1.4678  decode.d1.loss_cls: 0.1229  decode.d1.loss_mask: 0.5633  decode.d1.loss_dice: 1.3768  decode.d2.loss_cls: 0.0912  decode.d2.loss_mask: 0.5662  decode.d2.loss_dice: 1.3479  decode.d3.loss_cls: 0.0714  decode.d3.loss_mask: 0.5526  decode.d3.loss_dice: 1.3800  decode.d4.loss_cls: 0.0769  decode.d4.loss_mask: 0.5531  decode.d4.loss_dice: 1.3866  decode.d5.loss_cls: 0.1076  decode.d5.loss_mask: 0.5542  decode.d5.loss_dice: 1.3315  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 0.5635  decode.d6.loss_dice: 1.3540  decode.d7.loss_cls: 0.0947  decode.d7.loss_mask: 0.5485  decode.d7.loss_dice: 1.3866  decode.d8.loss_cls: 0.0941  decode.d8.loss_mask: 0.5402  decode.d8.loss_dice: 1.3476
11/15 09:15:07 - mmengine - INFO - Iter(train) [14300/90000]  base_lr: 8.5580e-05 lr: 8.5580e-06  eta: 12:44:13  time: 0.5977  data_time: 0.0098  memory: 10641  grad_norm: 1411.0379  loss: 18.5707  decode.loss_cls: 0.0682  decode.loss_mask: 0.5850  decode.loss_dice: 1.2314  decode.d0.loss_cls: 0.0863  decode.d0.loss_mask: 0.5694  decode.d0.loss_dice: 1.3066  decode.d1.loss_cls: 0.0707  decode.d1.loss_mask: 0.5633  decode.d1.loss_dice: 1.2093  decode.d2.loss_cls: 0.0762  decode.d2.loss_mask: 0.5696  decode.d2.loss_dice: 1.2124  decode.d3.loss_cls: 0.0696  decode.d3.loss_mask: 0.5621  decode.d3.loss_dice: 1.1801  decode.d4.loss_cls: 0.0727  decode.d4.loss_mask: 0.5686  decode.d4.loss_dice: 1.1877  decode.d5.loss_cls: 0.0795  decode.d5.loss_mask: 0.5719  decode.d5.loss_dice: 1.1822  decode.d6.loss_cls: 0.0669  decode.d6.loss_mask: 0.5659  decode.d6.loss_dice: 1.1988  decode.d7.loss_cls: 0.0656  decode.d7.loss_mask: 0.5737  decode.d7.loss_dice: 1.2219  decode.d8.loss_cls: 0.0848  decode.d8.loss_mask: 0.5606  decode.d8.loss_dice: 1.2097
11/15 09:15:37 - mmengine - INFO - Iter(train) [14350/90000]  base_lr: 8.5529e-05 lr: 8.5529e-06  eta: 12:43:41  time: 0.5990  data_time: 0.0103  memory: 10656  grad_norm: 1132.0314  loss: 22.1019  decode.loss_cls: 0.1167  decode.loss_mask: 0.6982  decode.loss_dice: 1.4053  decode.d0.loss_cls: 0.1024  decode.d0.loss_mask: 0.7218  decode.d0.loss_dice: 1.5089  decode.d1.loss_cls: 0.1072  decode.d1.loss_mask: 0.7017  decode.d1.loss_dice: 1.4376  decode.d2.loss_cls: 0.1279  decode.d2.loss_mask: 0.6636  decode.d2.loss_dice: 1.3825  decode.d3.loss_cls: 0.1259  decode.d3.loss_mask: 0.6783  decode.d3.loss_dice: 1.3814  decode.d4.loss_cls: 0.1233  decode.d4.loss_mask: 0.6708  decode.d4.loss_dice: 1.3267  decode.d5.loss_cls: 0.1194  decode.d5.loss_mask: 0.7003  decode.d5.loss_dice: 1.3723  decode.d6.loss_cls: 0.1287  decode.d6.loss_mask: 0.6785  decode.d6.loss_dice: 1.4070  decode.d7.loss_cls: 0.1199  decode.d7.loss_mask: 0.6867  decode.d7.loss_dice: 1.4020  decode.d8.loss_cls: 0.1243  decode.d8.loss_mask: 0.6694  decode.d8.loss_dice: 1.4131
11/15 09:16:07 - mmengine - INFO - Iter(train) [14400/90000]  base_lr: 8.5478e-05 lr: 8.5478e-06  eta: 12:43:09  time: 0.6008  data_time: 0.0103  memory: 10675  grad_norm: 381.3467  loss: 18.9023  decode.loss_cls: 0.0618  decode.loss_mask: 0.5478  decode.loss_dice: 1.2678  decode.d0.loss_cls: 0.0878  decode.d0.loss_mask: 0.5616  decode.d0.loss_dice: 1.2968  decode.d1.loss_cls: 0.0700  decode.d1.loss_mask: 0.5729  decode.d1.loss_dice: 1.3110  decode.d2.loss_cls: 0.0753  decode.d2.loss_mask: 0.5634  decode.d2.loss_dice: 1.2877  decode.d3.loss_cls: 0.0812  decode.d3.loss_mask: 0.5518  decode.d3.loss_dice: 1.2463  decode.d4.loss_cls: 0.0757  decode.d4.loss_mask: 0.5489  decode.d4.loss_dice: 1.2450  decode.d5.loss_cls: 0.0743  decode.d5.loss_mask: 0.5462  decode.d5.loss_dice: 1.2605  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.5395  decode.d6.loss_dice: 1.2540  decode.d7.loss_cls: 0.0674  decode.d7.loss_mask: 0.5385  decode.d7.loss_dice: 1.2441  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.5373  decode.d8.loss_dice: 1.2661
11/15 09:16:37 - mmengine - INFO - Iter(train) [14450/90000]  base_lr: 8.5427e-05 lr: 8.5427e-06  eta: 12:42:38  time: 0.6016  data_time: 0.0104  memory: 10656  grad_norm: 380.9136  loss: 22.3516  decode.loss_cls: 0.0948  decode.loss_mask: 0.6489  decode.loss_dice: 1.4958  decode.d0.loss_cls: 0.0842  decode.d0.loss_mask: 0.6739  decode.d0.loss_dice: 1.6370  decode.d1.loss_cls: 0.1003  decode.d1.loss_mask: 0.6252  decode.d1.loss_dice: 1.5551  decode.d2.loss_cls: 0.1109  decode.d2.loss_mask: 0.6321  decode.d2.loss_dice: 1.5105  decode.d3.loss_cls: 0.1099  decode.d3.loss_mask: 0.6295  decode.d3.loss_dice: 1.4830  decode.d4.loss_cls: 0.1114  decode.d4.loss_mask: 0.6171  decode.d4.loss_dice: 1.4692  decode.d5.loss_cls: 0.1284  decode.d5.loss_mask: 0.5899  decode.d5.loss_dice: 1.4668  decode.d6.loss_cls: 0.1234  decode.d6.loss_mask: 0.5945  decode.d6.loss_dice: 1.4304  decode.d7.loss_cls: 0.1145  decode.d7.loss_mask: 0.6050  decode.d7.loss_dice: 1.4726  decode.d8.loss_cls: 0.1102  decode.d8.loss_mask: 0.6296  decode.d8.loss_dice: 1.4975
11/15 09:17:07 - mmengine - INFO - Iter(train) [14500/90000]  base_lr: 8.5376e-05 lr: 8.5376e-06  eta: 12:42:06  time: 0.6011  data_time: 0.0103  memory: 10692  grad_norm: 431.1593  loss: 22.3486  decode.loss_cls: 0.0726  decode.loss_mask: 0.7686  decode.loss_dice: 1.3847  decode.d0.loss_cls: 0.0760  decode.d0.loss_mask: 0.7918  decode.d0.loss_dice: 1.4895  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.7547  decode.d1.loss_dice: 1.4322  decode.d2.loss_cls: 0.0950  decode.d2.loss_mask: 0.7702  decode.d2.loss_dice: 1.4339  decode.d3.loss_cls: 0.0707  decode.d3.loss_mask: 0.7541  decode.d3.loss_dice: 1.3933  decode.d4.loss_cls: 0.0729  decode.d4.loss_mask: 0.7214  decode.d4.loss_dice: 1.3733  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.7257  decode.d5.loss_dice: 1.3762  decode.d6.loss_cls: 0.0782  decode.d6.loss_mask: 0.7399  decode.d6.loss_dice: 1.3986  decode.d7.loss_cls: 0.0797  decode.d7.loss_mask: 0.7420  decode.d7.loss_dice: 1.3941  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.7474  decode.d8.loss_dice: 1.3950
11/15 09:17:37 - mmengine - INFO - Iter(train) [14550/90000]  base_lr: 8.5326e-05 lr: 8.5326e-06  eta: 12:41:34  time: 0.5988  data_time: 0.0101  memory: 10692  grad_norm: 480.1941  loss: 20.1014  decode.loss_cls: 0.0688  decode.loss_mask: 0.6385  decode.loss_dice: 1.3006  decode.d0.loss_cls: 0.0909  decode.d0.loss_mask: 0.6703  decode.d0.loss_dice: 1.3293  decode.d1.loss_cls: 0.0693  decode.d1.loss_mask: 0.6477  decode.d1.loss_dice: 1.2961  decode.d2.loss_cls: 0.0711  decode.d2.loss_mask: 0.6339  decode.d2.loss_dice: 1.2717  decode.d3.loss_cls: 0.0649  decode.d3.loss_mask: 0.6426  decode.d3.loss_dice: 1.2998  decode.d4.loss_cls: 0.0728  decode.d4.loss_mask: 0.6391  decode.d4.loss_dice: 1.2972  decode.d5.loss_cls: 0.0716  decode.d5.loss_mask: 0.6373  decode.d5.loss_dice: 1.2975  decode.d6.loss_cls: 0.0675  decode.d6.loss_mask: 0.6459  decode.d6.loss_dice: 1.2746  decode.d7.loss_cls: 0.0738  decode.d7.loss_mask: 0.6461  decode.d7.loss_dice: 1.2719  decode.d8.loss_cls: 0.0772  decode.d8.loss_mask: 0.6366  decode.d8.loss_dice: 1.2969
11/15 09:18:07 - mmengine - INFO - Iter(train) [14600/90000]  base_lr: 8.5275e-05 lr: 8.5275e-06  eta: 12:41:04  time: 0.6015  data_time: 0.0103  memory: 10656  grad_norm: 376.3859  loss: 20.0873  decode.loss_cls: 0.1338  decode.loss_mask: 0.5117  decode.loss_dice: 1.3210  decode.d0.loss_cls: 0.1312  decode.d0.loss_mask: 0.5525  decode.d0.loss_dice: 1.4856  decode.d1.loss_cls: 0.1406  decode.d1.loss_mask: 0.5417  decode.d1.loss_dice: 1.3733  decode.d2.loss_cls: 0.1400  decode.d2.loss_mask: 0.5233  decode.d2.loss_dice: 1.3487  decode.d3.loss_cls: 0.1267  decode.d3.loss_mask: 0.5181  decode.d3.loss_dice: 1.3355  decode.d4.loss_cls: 0.1375  decode.d4.loss_mask: 0.5188  decode.d4.loss_dice: 1.3278  decode.d5.loss_cls: 0.1348  decode.d5.loss_mask: 0.5132  decode.d5.loss_dice: 1.3280  decode.d6.loss_cls: 0.1414  decode.d6.loss_mask: 0.5073  decode.d6.loss_dice: 1.3199  decode.d7.loss_cls: 0.1246  decode.d7.loss_mask: 0.5122  decode.d7.loss_dice: 1.3588  decode.d8.loss_cls: 0.1323  decode.d8.loss_mask: 0.5084  decode.d8.loss_dice: 1.3386
11/15 09:18:37 - mmengine - INFO - Iter(train) [14650/90000]  base_lr: 8.5224e-05 lr: 8.5224e-06  eta: 12:40:32  time: 0.6007  data_time: 0.0103  memory: 10656  grad_norm: 420.1267  loss: 18.8429  decode.loss_cls: 0.0956  decode.loss_mask: 0.5989  decode.loss_dice: 1.2245  decode.d0.loss_cls: 0.0893  decode.d0.loss_mask: 0.5622  decode.d0.loss_dice: 1.2951  decode.d1.loss_cls: 0.1040  decode.d1.loss_mask: 0.5485  decode.d1.loss_dice: 1.2521  decode.d2.loss_cls: 0.0971  decode.d2.loss_mask: 0.5717  decode.d2.loss_dice: 1.2120  decode.d3.loss_cls: 0.0925  decode.d3.loss_mask: 0.5663  decode.d3.loss_dice: 1.2072  decode.d4.loss_cls: 0.0965  decode.d4.loss_mask: 0.5671  decode.d4.loss_dice: 1.2053  decode.d5.loss_cls: 0.0996  decode.d5.loss_mask: 0.5731  decode.d5.loss_dice: 1.1840  decode.d6.loss_cls: 0.1008  decode.d6.loss_mask: 0.5578  decode.d6.loss_dice: 1.1703  decode.d7.loss_cls: 0.0869  decode.d7.loss_mask: 0.5598  decode.d7.loss_dice: 1.2081  decode.d8.loss_cls: 0.0795  decode.d8.loss_mask: 0.6012  decode.d8.loss_dice: 1.2361
11/15 09:19:07 - mmengine - INFO - Iter(train) [14700/90000]  base_lr: 8.5173e-05 lr: 8.5173e-06  eta: 12:40:00  time: 0.5979  data_time: 0.0102  memory: 10675  grad_norm: 618.1982  loss: 22.0248  decode.loss_cls: 0.0919  decode.loss_mask: 0.6931  decode.loss_dice: 1.3909  decode.d0.loss_cls: 0.0936  decode.d0.loss_mask: 0.7099  decode.d0.loss_dice: 1.4937  decode.d1.loss_cls: 0.0995  decode.d1.loss_mask: 0.6769  decode.d1.loss_dice: 1.4347  decode.d2.loss_cls: 0.0868  decode.d2.loss_mask: 0.6940  decode.d2.loss_dice: 1.4313  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 0.6932  decode.d3.loss_dice: 1.4430  decode.d4.loss_cls: 0.0815  decode.d4.loss_mask: 0.6901  decode.d4.loss_dice: 1.3899  decode.d5.loss_cls: 0.0944  decode.d5.loss_mask: 0.6669  decode.d5.loss_dice: 1.4111  decode.d6.loss_cls: 0.0919  decode.d6.loss_mask: 0.6970  decode.d6.loss_dice: 1.3895  decode.d7.loss_cls: 0.0871  decode.d7.loss_mask: 0.6911  decode.d7.loss_dice: 1.4187  decode.d8.loss_cls: 0.0871  decode.d8.loss_mask: 0.6891  decode.d8.loss_dice: 1.4399
11/15 09:19:37 - mmengine - INFO - Iter(train) [14750/90000]  base_lr: 8.5122e-05 lr: 8.5122e-06  eta: 12:39:28  time: 0.6008  data_time: 0.0101  memory: 10728  grad_norm: 428.8930  loss: 22.3824  decode.loss_cls: 0.0790  decode.loss_mask: 0.7530  decode.loss_dice: 1.4040  decode.d0.loss_cls: 0.0968  decode.d0.loss_mask: 0.7923  decode.d0.loss_dice: 1.4915  decode.d1.loss_cls: 0.0992  decode.d1.loss_mask: 0.7425  decode.d1.loss_dice: 1.3780  decode.d2.loss_cls: 0.0864  decode.d2.loss_mask: 0.7307  decode.d2.loss_dice: 1.3903  decode.d3.loss_cls: 0.0948  decode.d3.loss_mask: 0.7325  decode.d3.loss_dice: 1.3887  decode.d4.loss_cls: 0.0844  decode.d4.loss_mask: 0.7343  decode.d4.loss_dice: 1.3796  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 0.7468  decode.d5.loss_dice: 1.3915  decode.d6.loss_cls: 0.0883  decode.d6.loss_mask: 0.7482  decode.d6.loss_dice: 1.3854  decode.d7.loss_cls: 0.0845  decode.d7.loss_mask: 0.7552  decode.d7.loss_dice: 1.4077  decode.d8.loss_cls: 0.0890  decode.d8.loss_mask: 0.7514  decode.d8.loss_dice: 1.4005
11/15 09:20:10 - mmengine - INFO - Iter(train) [14800/90000]  base_lr: 8.5071e-05 lr: 8.5071e-06  eta: 12:39:12  time: 0.5961  data_time: 0.0101  memory: 10692  grad_norm: 371.8414  loss: 19.4264  decode.loss_cls: 0.0896  decode.loss_mask: 0.5733  decode.loss_dice: 1.2680  decode.d0.loss_cls: 0.1111  decode.d0.loss_mask: 0.5795  decode.d0.loss_dice: 1.3199  decode.d1.loss_cls: 0.0940  decode.d1.loss_mask: 0.5630  decode.d1.loss_dice: 1.3284  decode.d2.loss_cls: 0.0933  decode.d2.loss_mask: 0.5744  decode.d2.loss_dice: 1.2819  decode.d3.loss_cls: 0.1013  decode.d3.loss_mask: 0.5739  decode.d3.loss_dice: 1.2304  decode.d4.loss_cls: 0.0977  decode.d4.loss_mask: 0.5904  decode.d4.loss_dice: 1.2350  decode.d5.loss_cls: 0.0945  decode.d5.loss_mask: 0.5705  decode.d5.loss_dice: 1.2790  decode.d6.loss_cls: 0.0873  decode.d6.loss_mask: 0.5678  decode.d6.loss_dice: 1.2785  decode.d7.loss_cls: 0.0953  decode.d7.loss_mask: 0.5711  decode.d7.loss_dice: 1.2682  decode.d8.loss_cls: 0.1068  decode.d8.loss_mask: 0.5667  decode.d8.loss_dice: 1.2358
11/15 09:20:40 - mmengine - INFO - Iter(train) [14850/90000]  base_lr: 8.5020e-05 lr: 8.5020e-06  eta: 12:38:41  time: 0.6008  data_time: 0.0104  memory: 10656  grad_norm: 817.9060  loss: 19.5224  decode.loss_cls: 0.0694  decode.loss_mask: 0.6595  decode.loss_dice: 1.2315  decode.d0.loss_cls: 0.0830  decode.d0.loss_mask: 0.6622  decode.d0.loss_dice: 1.3209  decode.d1.loss_cls: 0.0637  decode.d1.loss_mask: 0.6442  decode.d1.loss_dice: 1.2961  decode.d2.loss_cls: 0.0857  decode.d2.loss_mask: 0.6159  decode.d2.loss_dice: 1.2295  decode.d3.loss_cls: 0.0882  decode.d3.loss_mask: 0.6184  decode.d3.loss_dice: 1.2313  decode.d4.loss_cls: 0.0746  decode.d4.loss_mask: 0.6664  decode.d4.loss_dice: 1.2192  decode.d5.loss_cls: 0.0764  decode.d5.loss_mask: 0.6259  decode.d5.loss_dice: 1.1829  decode.d6.loss_cls: 0.0854  decode.d6.loss_mask: 0.6232  decode.d6.loss_dice: 1.2286  decode.d7.loss_cls: 0.0780  decode.d7.loss_mask: 0.6294  decode.d7.loss_dice: 1.2471  decode.d8.loss_cls: 0.0825  decode.d8.loss_mask: 0.6202  decode.d8.loss_dice: 1.1829
11/15 09:21:10 - mmengine - INFO - Iter(train) [14900/90000]  base_lr: 8.4969e-05 lr: 8.4969e-06  eta: 12:38:10  time: 0.6055  data_time: 0.0105  memory: 10656  grad_norm: 471.7274  loss: 19.1633  decode.loss_cls: 0.0693  decode.loss_mask: 0.6740  decode.loss_dice: 1.1902  decode.d0.loss_cls: 0.0978  decode.d0.loss_mask: 0.6768  decode.d0.loss_dice: 1.2698  decode.d1.loss_cls: 0.0847  decode.d1.loss_mask: 0.6419  decode.d1.loss_dice: 1.1798  decode.d2.loss_cls: 0.0714  decode.d2.loss_mask: 0.6633  decode.d2.loss_dice: 1.1714  decode.d3.loss_cls: 0.0718  decode.d3.loss_mask: 0.6773  decode.d3.loss_dice: 1.1741  decode.d4.loss_cls: 0.0693  decode.d4.loss_mask: 0.6675  decode.d4.loss_dice: 1.1852  decode.d5.loss_cls: 0.0782  decode.d5.loss_mask: 0.6533  decode.d5.loss_dice: 1.1674  decode.d6.loss_cls: 0.0743  decode.d6.loss_mask: 0.6639  decode.d6.loss_dice: 1.1694  decode.d7.loss_cls: 0.0848  decode.d7.loss_mask: 0.5571  decode.d7.loss_dice: 1.1523  decode.d8.loss_cls: 0.0770  decode.d8.loss_mask: 0.6738  decode.d8.loss_dice: 1.1762
11/15 09:21:40 - mmengine - INFO - Iter(train) [14950/90000]  base_lr: 8.4918e-05 lr: 8.4918e-06  eta: 12:37:39  time: 0.6036  data_time: 0.0107  memory: 10626  grad_norm: 315.6907  loss: 21.4622  decode.loss_cls: 0.1020  decode.loss_mask: 0.6480  decode.loss_dice: 1.3998  decode.d0.loss_cls: 0.0939  decode.d0.loss_mask: 0.6230  decode.d0.loss_dice: 1.4926  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.6198  decode.d1.loss_dice: 1.4465  decode.d2.loss_cls: 0.0937  decode.d2.loss_mask: 0.6238  decode.d2.loss_dice: 1.3884  decode.d3.loss_cls: 0.0957  decode.d3.loss_mask: 0.6191  decode.d3.loss_dice: 1.4337  decode.d4.loss_cls: 0.0931  decode.d4.loss_mask: 0.6285  decode.d4.loss_dice: 1.4244  decode.d5.loss_cls: 0.0914  decode.d5.loss_mask: 0.6293  decode.d5.loss_dice: 1.4103  decode.d6.loss_cls: 0.0995  decode.d6.loss_mask: 0.6345  decode.d6.loss_dice: 1.3962  decode.d7.loss_cls: 0.1008  decode.d7.loss_mask: 0.6415  decode.d7.loss_dice: 1.4150  decode.d8.loss_cls: 0.1019  decode.d8.loss_mask: 0.6163  decode.d8.loss_dice: 1.4072
11/15 09:22:11 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 09:22:11 - mmengine - INFO - Iter(train) [15000/90000]  base_lr: 8.4867e-05 lr: 8.4867e-06  eta: 12:37:09  time: 0.6052  data_time: 0.0106  memory: 10713  grad_norm: 465.6333  loss: 20.4467  decode.loss_cls: 0.0825  decode.loss_mask: 0.6866  decode.loss_dice: 1.2638  decode.d0.loss_cls: 0.0997  decode.d0.loss_mask: 0.6915  decode.d0.loss_dice: 1.3188  decode.d1.loss_cls: 0.0810  decode.d1.loss_mask: 0.6558  decode.d1.loss_dice: 1.2893  decode.d2.loss_cls: 0.0697  decode.d2.loss_mask: 0.6798  decode.d2.loss_dice: 1.2704  decode.d3.loss_cls: 0.0781  decode.d3.loss_mask: 0.6701  decode.d3.loss_dice: 1.2647  decode.d4.loss_cls: 0.0739  decode.d4.loss_mask: 0.6913  decode.d4.loss_dice: 1.2523  decode.d5.loss_cls: 0.0706  decode.d5.loss_mask: 0.7027  decode.d5.loss_dice: 1.2627  decode.d6.loss_cls: 0.0790  decode.d6.loss_mask: 0.6895  decode.d6.loss_dice: 1.2674  decode.d7.loss_cls: 0.0891  decode.d7.loss_mask: 0.7000  decode.d7.loss_dice: 1.2824  decode.d8.loss_cls: 0.0778  decode.d8.loss_mask: 0.7150  decode.d8.loss_dice: 1.2913
11/15 09:22:11 - mmengine - INFO - Saving checkpoint at 15000 iterations
11/15 09:22:31 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:23  time: 0.3091  data_time: 0.0043  memory: 4095  
11/15 09:22:46 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:05  time: 0.3090  data_time: 0.0042  memory: 4095  
11/15 09:23:02 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:49  time: 0.3093  data_time: 0.0043  memory: 4095  
11/15 09:23:17 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3095  data_time: 0.0043  memory: 4095  
11/15 09:23:33 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3096  data_time: 0.0043  memory: 4095  
11/15 09:23:48 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:02  time: 0.3093  data_time: 0.0044  memory: 4095  
11/15 09:24:04 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3100  data_time: 0.0043  memory: 4095  
11/15 09:24:19 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:31  time: 0.3090  data_time: 0.0042  memory: 4095  
11/15 09:24:35 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3097  data_time: 0.0041  memory: 4095  
11/15 09:24:50 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3093  data_time: 0.0041  memory: 4095  
11/15 09:24:50 - mmengine - INFO - per class results:
11/15 09:24:50 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     |  97.1 | 98.29 |
|    sidewalk   | 81.37 | 92.43 |
|    building   | 91.64 | 96.45 |
|      wall     | 46.82 | 59.77 |
|     fence     |  52.9 |  64.7 |
|      pole     | 62.48 | 76.22 |
| traffic light | 65.29 | 75.98 |
|  traffic sign | 77.17 | 84.44 |
|   vegetation  |  91.6 | 96.42 |
|    terrain    | 60.19 | 72.53 |
|      sky      | 92.51 | 94.87 |
|     person    | 77.93 | 82.36 |
|     rider     | 59.99 | 79.88 |
|      car      | 93.81 | 97.66 |
|     truck     | 20.51 | 44.57 |
|      bus      |  0.0  |  0.0  |
|     train     |  4.99 |  4.99 |
|   motorcycle  | 53.95 | 77.68 |
|    bicycle    | 73.32 | 79.51 |
+---------------+-------+-------+
11/15 09:24:50 - mmengine - INFO - Iter(val) [500/500]    aAcc: 94.8100  mIoU: 63.3500  mAcc: 72.5700  data_time: 0.0049  time: 0.3103
11/15 09:25:20 - mmengine - INFO - Iter(train) [15050/90000]  base_lr: 8.4817e-05 lr: 8.4817e-06  eta: 12:36:36  time: 0.5946  data_time: 0.0100  memory: 10675  grad_norm: 483.3366  loss: 18.6538  decode.loss_cls: 0.0663  decode.loss_mask: 0.5731  decode.loss_dice: 1.1989  decode.d0.loss_cls: 0.0896  decode.d0.loss_mask: 0.5980  decode.d0.loss_dice: 1.2719  decode.d1.loss_cls: 0.0660  decode.d1.loss_mask: 0.5841  decode.d1.loss_dice: 1.1971  decode.d2.loss_cls: 0.0610  decode.d2.loss_mask: 0.5779  decode.d2.loss_dice: 1.2083  decode.d3.loss_cls: 0.0676  decode.d3.loss_mask: 0.5721  decode.d3.loss_dice: 1.2451  decode.d4.loss_cls: 0.0569  decode.d4.loss_mask: 0.5759  decode.d4.loss_dice: 1.1981  decode.d5.loss_cls: 0.0669  decode.d5.loss_mask: 0.5614  decode.d5.loss_dice: 1.2233  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.5655  decode.d6.loss_dice: 1.2488  decode.d7.loss_cls: 0.0615  decode.d7.loss_mask: 0.5605  decode.d7.loss_dice: 1.2122  decode.d8.loss_cls: 0.0761  decode.d8.loss_mask: 0.5817  decode.d8.loss_dice: 1.2295
11/15 09:25:49 - mmengine - INFO - Iter(train) [15100/90000]  base_lr: 8.4766e-05 lr: 8.4766e-06  eta: 12:36:03  time: 0.5932  data_time: 0.0095  memory: 10692  grad_norm: 359.3133  loss: 20.8234  decode.loss_cls: 0.0707  decode.loss_mask: 0.5636  decode.loss_dice: 1.4226  decode.d0.loss_cls: 0.0926  decode.d0.loss_mask: 0.5847  decode.d0.loss_dice: 1.4883  decode.d1.loss_cls: 0.0826  decode.d1.loss_mask: 0.5776  decode.d1.loss_dice: 1.4684  decode.d2.loss_cls: 0.0694  decode.d2.loss_mask: 0.5650  decode.d2.loss_dice: 1.4140  decode.d3.loss_cls: 0.0745  decode.d3.loss_mask: 0.5689  decode.d3.loss_dice: 1.4146  decode.d4.loss_cls: 0.0862  decode.d4.loss_mask: 0.5700  decode.d4.loss_dice: 1.4440  decode.d5.loss_cls: 0.0852  decode.d5.loss_mask: 0.5606  decode.d5.loss_dice: 1.4044  decode.d6.loss_cls: 0.0708  decode.d6.loss_mask: 0.5719  decode.d6.loss_dice: 1.4037  decode.d7.loss_cls: 0.0569  decode.d7.loss_mask: 0.5689  decode.d7.loss_dice: 1.4859  decode.d8.loss_cls: 0.0662  decode.d8.loss_mask: 0.5649  decode.d8.loss_dice: 1.4260
11/15 09:26:19 - mmengine - INFO - Iter(train) [15150/90000]  base_lr: 8.4715e-05 lr: 8.4715e-06  eta: 12:35:29  time: 0.5927  data_time: 0.0097  memory: 10728  grad_norm: 396.5393  loss: 20.0486  decode.loss_cls: 0.0840  decode.loss_mask: 0.6233  decode.loss_dice: 1.3003  decode.d0.loss_cls: 0.1055  decode.d0.loss_mask: 0.6098  decode.d0.loss_dice: 1.3721  decode.d1.loss_cls: 0.0692  decode.d1.loss_mask: 0.6052  decode.d1.loss_dice: 1.3139  decode.d2.loss_cls: 0.0649  decode.d2.loss_mask: 0.6050  decode.d2.loss_dice: 1.3244  decode.d3.loss_cls: 0.0737  decode.d3.loss_mask: 0.6288  decode.d3.loss_dice: 1.2999  decode.d4.loss_cls: 0.0819  decode.d4.loss_mask: 0.6098  decode.d4.loss_dice: 1.2680  decode.d5.loss_cls: 0.0752  decode.d5.loss_mask: 0.6297  decode.d5.loss_dice: 1.2817  decode.d6.loss_cls: 0.0768  decode.d6.loss_mask: 0.6353  decode.d6.loss_dice: 1.3160  decode.d7.loss_cls: 0.0846  decode.d7.loss_mask: 0.5932  decode.d7.loss_dice: 1.2928  decode.d8.loss_cls: 0.0750  decode.d8.loss_mask: 0.6233  decode.d8.loss_dice: 1.3251
11/15 09:26:49 - mmengine - INFO - Iter(train) [15200/90000]  base_lr: 8.4664e-05 lr: 8.4664e-06  eta: 12:34:56  time: 0.5930  data_time: 0.0095  memory: 10641  grad_norm: 1103.5766  loss: 20.7492  decode.loss_cls: 0.0979  decode.loss_mask: 0.5549  decode.loss_dice: 1.4239  decode.d0.loss_cls: 0.1049  decode.d0.loss_mask: 0.5706  decode.d0.loss_dice: 1.5055  decode.d1.loss_cls: 0.1102  decode.d1.loss_mask: 0.5568  decode.d1.loss_dice: 1.4506  decode.d2.loss_cls: 0.1204  decode.d2.loss_mask: 0.5509  decode.d2.loss_dice: 1.3918  decode.d3.loss_cls: 0.1132  decode.d3.loss_mask: 0.5434  decode.d3.loss_dice: 1.3817  decode.d4.loss_cls: 0.1219  decode.d4.loss_mask: 0.5457  decode.d4.loss_dice: 1.3754  decode.d5.loss_cls: 0.1031  decode.d5.loss_mask: 0.5632  decode.d5.loss_dice: 1.3980  decode.d6.loss_cls: 0.1161  decode.d6.loss_mask: 0.5386  decode.d6.loss_dice: 1.3780  decode.d7.loss_cls: 0.1184  decode.d7.loss_mask: 0.5504  decode.d7.loss_dice: 1.3913  decode.d8.loss_cls: 0.1124  decode.d8.loss_mask: 0.5484  decode.d8.loss_dice: 1.4115
11/15 09:27:18 - mmengine - INFO - Iter(train) [15250/90000]  base_lr: 8.4613e-05 lr: 8.4613e-06  eta: 12:34:23  time: 0.5922  data_time: 0.0096  memory: 10656  grad_norm: 285.0599  loss: 18.8577  decode.loss_cls: 0.1092  decode.loss_mask: 0.5436  decode.loss_dice: 1.1965  decode.d0.loss_cls: 0.0894  decode.d0.loss_mask: 0.5953  decode.d0.loss_dice: 1.3211  decode.d1.loss_cls: 0.1019  decode.d1.loss_mask: 0.5406  decode.d1.loss_dice: 1.2390  decode.d2.loss_cls: 0.0956  decode.d2.loss_mask: 0.5412  decode.d2.loss_dice: 1.2199  decode.d3.loss_cls: 0.1002  decode.d3.loss_mask: 0.5493  decode.d3.loss_dice: 1.2209  decode.d4.loss_cls: 0.0963  decode.d4.loss_mask: 0.5523  decode.d4.loss_dice: 1.1895  decode.d5.loss_cls: 0.0939  decode.d5.loss_mask: 0.5514  decode.d5.loss_dice: 1.2517  decode.d6.loss_cls: 0.0880  decode.d6.loss_mask: 0.5529  decode.d6.loss_dice: 1.2360  decode.d7.loss_cls: 0.0921  decode.d7.loss_mask: 0.5680  decode.d7.loss_dice: 1.2473  decode.d8.loss_cls: 0.0974  decode.d8.loss_mask: 0.5625  decode.d8.loss_dice: 1.2146
11/15 09:27:48 - mmengine - INFO - Iter(train) [15300/90000]  base_lr: 8.4562e-05 lr: 8.4562e-06  eta: 12:33:51  time: 0.5924  data_time: 0.0095  memory: 10692  grad_norm: 421.8142  loss: 19.8646  decode.loss_cls: 0.1020  decode.loss_mask: 0.6226  decode.loss_dice: 1.2555  decode.d0.loss_cls: 0.1057  decode.d0.loss_mask: 0.6050  decode.d0.loss_dice: 1.3622  decode.d1.loss_cls: 0.1202  decode.d1.loss_mask: 0.5814  decode.d1.loss_dice: 1.3053  decode.d2.loss_cls: 0.1178  decode.d2.loss_mask: 0.5888  decode.d2.loss_dice: 1.2682  decode.d3.loss_cls: 0.1093  decode.d3.loss_mask: 0.6021  decode.d3.loss_dice: 1.2376  decode.d4.loss_cls: 0.1194  decode.d4.loss_mask: 0.5969  decode.d4.loss_dice: 1.2400  decode.d5.loss_cls: 0.1037  decode.d5.loss_mask: 0.5978  decode.d5.loss_dice: 1.3063  decode.d6.loss_cls: 0.1041  decode.d6.loss_mask: 0.5983  decode.d6.loss_dice: 1.2588  decode.d7.loss_cls: 0.1007  decode.d7.loss_mask: 0.6011  decode.d7.loss_dice: 1.2638  decode.d8.loss_cls: 0.1065  decode.d8.loss_mask: 0.6135  decode.d8.loss_dice: 1.2700
11/15 09:28:18 - mmengine - INFO - Iter(train) [15350/90000]  base_lr: 8.4511e-05 lr: 8.4511e-06  eta: 12:33:17  time: 0.5910  data_time: 0.0096  memory: 10692  grad_norm: 605.7449  loss: 18.3198  decode.loss_cls: 0.0508  decode.loss_mask: 0.6683  decode.loss_dice: 1.1774  decode.d0.loss_cls: 0.0912  decode.d0.loss_mask: 0.6180  decode.d0.loss_dice: 1.1777  decode.d1.loss_cls: 0.0778  decode.d1.loss_mask: 0.6106  decode.d1.loss_dice: 1.1284  decode.d2.loss_cls: 0.0573  decode.d2.loss_mask: 0.6246  decode.d2.loss_dice: 1.1373  decode.d3.loss_cls: 0.0560  decode.d3.loss_mask: 0.6247  decode.d3.loss_dice: 1.1332  decode.d4.loss_cls: 0.0680  decode.d4.loss_mask: 0.6063  decode.d4.loss_dice: 1.0902  decode.d5.loss_cls: 0.0624  decode.d5.loss_mask: 0.6142  decode.d5.loss_dice: 1.1351  decode.d6.loss_cls: 0.0611  decode.d6.loss_mask: 0.6314  decode.d6.loss_dice: 1.1232  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.6360  decode.d7.loss_dice: 1.1203  decode.d8.loss_cls: 0.0585  decode.d8.loss_mask: 0.6666  decode.d8.loss_dice: 1.1491
11/15 09:28:48 - mmengine - INFO - Iter(train) [15400/90000]  base_lr: 8.4460e-05 lr: 8.4460e-06  eta: 12:32:44  time: 0.5945  data_time: 0.0097  memory: 10675  grad_norm: 507.8187  loss: 19.8795  decode.loss_cls: 0.0688  decode.loss_mask: 0.6280  decode.loss_dice: 1.3213  decode.d0.loss_cls: 0.0846  decode.d0.loss_mask: 0.6436  decode.d0.loss_dice: 1.3111  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.6078  decode.d1.loss_dice: 1.2829  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 0.6220  decode.d2.loss_dice: 1.2799  decode.d3.loss_cls: 0.0679  decode.d3.loss_mask: 0.6179  decode.d3.loss_dice: 1.2697  decode.d4.loss_cls: 0.0662  decode.d4.loss_mask: 0.6183  decode.d4.loss_dice: 1.3029  decode.d5.loss_cls: 0.0621  decode.d5.loss_mask: 0.6334  decode.d5.loss_dice: 1.2886  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.6280  decode.d6.loss_dice: 1.3121  decode.d7.loss_cls: 0.0671  decode.d7.loss_mask: 0.6204  decode.d7.loss_dice: 1.2831  decode.d8.loss_cls: 0.0939  decode.d8.loss_mask: 0.6203  decode.d8.loss_dice: 1.2836
11/15 09:29:17 - mmengine - INFO - Iter(train) [15450/90000]  base_lr: 8.4409e-05 lr: 8.4409e-06  eta: 12:32:11  time: 0.5956  data_time: 0.0098  memory: 10675  grad_norm: 689.0575  loss: 21.8897  decode.loss_cls: 0.0633  decode.loss_mask: 0.7853  decode.loss_dice: 1.3466  decode.d0.loss_cls: 0.0839  decode.d0.loss_mask: 0.7877  decode.d0.loss_dice: 1.4116  decode.d1.loss_cls: 0.0953  decode.d1.loss_mask: 0.7441  decode.d1.loss_dice: 1.3669  decode.d2.loss_cls: 0.0753  decode.d2.loss_mask: 0.7615  decode.d2.loss_dice: 1.3489  decode.d3.loss_cls: 0.0709  decode.d3.loss_mask: 0.7421  decode.d3.loss_dice: 1.3327  decode.d4.loss_cls: 0.0617  decode.d4.loss_mask: 0.7559  decode.d4.loss_dice: 1.3818  decode.d5.loss_cls: 0.0726  decode.d5.loss_mask: 0.7543  decode.d5.loss_dice: 1.3509  decode.d6.loss_cls: 0.0697  decode.d6.loss_mask: 0.7636  decode.d6.loss_dice: 1.3532  decode.d7.loss_cls: 0.0645  decode.d7.loss_mask: 0.7387  decode.d7.loss_dice: 1.3462  decode.d8.loss_cls: 0.0626  decode.d8.loss_mask: 0.7501  decode.d8.loss_dice: 1.3479
11/15 09:29:50 - mmengine - INFO - Iter(train) [15500/90000]  base_lr: 8.4358e-05 lr: 8.4358e-06  eta: 12:31:52  time: 0.5937  data_time: 0.0095  memory: 10656  grad_norm: 585.2894  loss: 21.8344  decode.loss_cls: 0.0693  decode.loss_mask: 0.7296  decode.loss_dice: 1.3597  decode.d0.loss_cls: 0.0779  decode.d0.loss_mask: 0.7853  decode.d0.loss_dice: 1.4457  decode.d1.loss_cls: 0.0665  decode.d1.loss_mask: 0.7609  decode.d1.loss_dice: 1.3875  decode.d2.loss_cls: 0.0668  decode.d2.loss_mask: 0.7505  decode.d2.loss_dice: 1.3333  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.7665  decode.d3.loss_dice: 1.3363  decode.d4.loss_cls: 0.0616  decode.d4.loss_mask: 0.7639  decode.d4.loss_dice: 1.3468  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 0.7630  decode.d5.loss_dice: 1.3322  decode.d6.loss_cls: 0.0681  decode.d6.loss_mask: 0.7542  decode.d6.loss_dice: 1.3180  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.7407  decode.d7.loss_dice: 1.3723  decode.d8.loss_cls: 0.0659  decode.d8.loss_mask: 0.7665  decode.d8.loss_dice: 1.3642
11/15 09:30:20 - mmengine - INFO - Iter(train) [15550/90000]  base_lr: 8.4307e-05 lr: 8.4307e-06  eta: 12:31:19  time: 0.5924  data_time: 0.0097  memory: 10692  grad_norm: 836.0728  loss: 21.9629  decode.loss_cls: 0.0497  decode.loss_mask: 0.7908  decode.loss_dice: 1.3583  decode.d0.loss_cls: 0.0753  decode.d0.loss_mask: 0.8491  decode.d0.loss_dice: 1.4077  decode.d1.loss_cls: 0.0755  decode.d1.loss_mask: 0.7653  decode.d1.loss_dice: 1.3464  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 0.7670  decode.d2.loss_dice: 1.3410  decode.d3.loss_cls: 0.0621  decode.d3.loss_mask: 0.7756  decode.d3.loss_dice: 1.3064  decode.d4.loss_cls: 0.0473  decode.d4.loss_mask: 0.7755  decode.d4.loss_dice: 1.3522  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 0.7761  decode.d5.loss_dice: 1.3324  decode.d6.loss_cls: 0.0529  decode.d6.loss_mask: 0.7945  decode.d6.loss_dice: 1.3393  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 0.7846  decode.d7.loss_dice: 1.3582  decode.d8.loss_cls: 0.0690  decode.d8.loss_mask: 0.7745  decode.d8.loss_dice: 1.3501
11/15 09:30:49 - mmengine - INFO - Iter(train) [15600/90000]  base_lr: 8.4256e-05 lr: 8.4256e-06  eta: 12:30:46  time: 0.5950  data_time: 0.0096  memory: 10692  grad_norm: 327.0516  loss: 19.5333  decode.loss_cls: 0.0672  decode.loss_mask: 0.6097  decode.loss_dice: 1.2551  decode.d0.loss_cls: 0.0729  decode.d0.loss_mask: 0.6315  decode.d0.loss_dice: 1.3230  decode.d1.loss_cls: 0.0688  decode.d1.loss_mask: 0.6154  decode.d1.loss_dice: 1.2635  decode.d2.loss_cls: 0.0680  decode.d2.loss_mask: 0.6129  decode.d2.loss_dice: 1.2881  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.6137  decode.d3.loss_dice: 1.2579  decode.d4.loss_cls: 0.0776  decode.d4.loss_mask: 0.6280  decode.d4.loss_dice: 1.2560  decode.d5.loss_cls: 0.0737  decode.d5.loss_mask: 0.6020  decode.d5.loss_dice: 1.2331  decode.d6.loss_cls: 0.0660  decode.d6.loss_mask: 0.6222  decode.d6.loss_dice: 1.2703  decode.d7.loss_cls: 0.0727  decode.d7.loss_mask: 0.5949  decode.d7.loss_dice: 1.2672  decode.d8.loss_cls: 0.0750  decode.d8.loss_mask: 0.6138  decode.d8.loss_dice: 1.2692
11/15 09:31:19 - mmengine - INFO - Iter(train) [15650/90000]  base_lr: 8.4205e-05 lr: 8.4205e-06  eta: 12:30:12  time: 0.5923  data_time: 0.0096  memory: 10692  grad_norm: 370.8347  loss: 21.7511  decode.loss_cls: 0.0812  decode.loss_mask: 0.6251  decode.loss_dice: 1.4812  decode.d0.loss_cls: 0.0809  decode.d0.loss_mask: 0.6321  decode.d0.loss_dice: 1.5300  decode.d1.loss_cls: 0.0547  decode.d1.loss_mask: 0.6274  decode.d1.loss_dice: 1.4896  decode.d2.loss_cls: 0.0592  decode.d2.loss_mask: 0.6369  decode.d2.loss_dice: 1.4940  decode.d3.loss_cls: 0.0760  decode.d3.loss_mask: 0.6271  decode.d3.loss_dice: 1.4685  decode.d4.loss_cls: 0.0797  decode.d4.loss_mask: 0.6241  decode.d4.loss_dice: 1.4263  decode.d5.loss_cls: 0.0648  decode.d5.loss_mask: 0.6236  decode.d5.loss_dice: 1.4777  decode.d6.loss_cls: 0.0811  decode.d6.loss_mask: 0.6098  decode.d6.loss_dice: 1.4419  decode.d7.loss_cls: 0.0766  decode.d7.loss_mask: 0.6170  decode.d7.loss_dice: 1.4926  decode.d8.loss_cls: 0.0755  decode.d8.loss_mask: 0.6204  decode.d8.loss_dice: 1.4759
11/15 09:31:49 - mmengine - INFO - Iter(train) [15700/90000]  base_lr: 8.4154e-05 lr: 8.4154e-06  eta: 12:29:39  time: 0.5913  data_time: 0.0095  memory: 10656  grad_norm: 663.6960  loss: 20.6342  decode.loss_cls: 0.0531  decode.loss_mask: 0.7648  decode.loss_dice: 1.2010  decode.d0.loss_cls: 0.0900  decode.d0.loss_mask: 0.8022  decode.d0.loss_dice: 1.2776  decode.d1.loss_cls: 0.0577  decode.d1.loss_mask: 0.7670  decode.d1.loss_dice: 1.2208  decode.d2.loss_cls: 0.0585  decode.d2.loss_mask: 0.7862  decode.d2.loss_dice: 1.2450  decode.d3.loss_cls: 0.0592  decode.d3.loss_mask: 0.8102  decode.d3.loss_dice: 1.1967  decode.d4.loss_cls: 0.0493  decode.d4.loss_mask: 0.8096  decode.d4.loss_dice: 1.2191  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.8029  decode.d5.loss_dice: 1.2305  decode.d6.loss_cls: 0.0527  decode.d6.loss_mask: 0.7631  decode.d6.loss_dice: 1.1729  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.8020  decode.d7.loss_dice: 1.2124  decode.d8.loss_cls: 0.0486  decode.d8.loss_mask: 0.7679  decode.d8.loss_dice: 1.2111
11/15 09:32:18 - mmengine - INFO - Iter(train) [15750/90000]  base_lr: 8.4103e-05 lr: 8.4103e-06  eta: 12:29:06  time: 0.5940  data_time: 0.0095  memory: 10728  grad_norm: 325.1571  loss: 19.5835  decode.loss_cls: 0.1081  decode.loss_mask: 0.6216  decode.loss_dice: 1.2524  decode.d0.loss_cls: 0.1056  decode.d0.loss_mask: 0.6366  decode.d0.loss_dice: 1.3218  decode.d1.loss_cls: 0.0925  decode.d1.loss_mask: 0.6258  decode.d1.loss_dice: 1.2520  decode.d2.loss_cls: 0.1053  decode.d2.loss_mask: 0.6232  decode.d2.loss_dice: 1.2111  decode.d3.loss_cls: 0.1070  decode.d3.loss_mask: 0.6171  decode.d3.loss_dice: 1.2043  decode.d4.loss_cls: 0.0980  decode.d4.loss_mask: 0.6095  decode.d4.loss_dice: 1.2428  decode.d5.loss_cls: 0.0968  decode.d5.loss_mask: 0.6040  decode.d5.loss_dice: 1.2451  decode.d6.loss_cls: 0.1027  decode.d6.loss_mask: 0.6033  decode.d6.loss_dice: 1.2229  decode.d7.loss_cls: 0.1116  decode.d7.loss_mask: 0.5960  decode.d7.loss_dice: 1.2309  decode.d8.loss_cls: 0.1049  decode.d8.loss_mask: 0.6083  decode.d8.loss_dice: 1.2226
11/15 09:32:48 - mmengine - INFO - Iter(train) [15800/90000]  base_lr: 8.4052e-05 lr: 8.4052e-06  eta: 12:28:33  time: 0.5927  data_time: 0.0096  memory: 10692  grad_norm: 360.7473  loss: 20.3664  decode.loss_cls: 0.0638  decode.loss_mask: 0.6817  decode.loss_dice: 1.2818  decode.d0.loss_cls: 0.0903  decode.d0.loss_mask: 0.7108  decode.d0.loss_dice: 1.3217  decode.d1.loss_cls: 0.0710  decode.d1.loss_mask: 0.6595  decode.d1.loss_dice: 1.3147  decode.d2.loss_cls: 0.0660  decode.d2.loss_mask: 0.6728  decode.d2.loss_dice: 1.2873  decode.d3.loss_cls: 0.0574  decode.d3.loss_mask: 0.6904  decode.d3.loss_dice: 1.2840  decode.d4.loss_cls: 0.0760  decode.d4.loss_mask: 0.6658  decode.d4.loss_dice: 1.2864  decode.d5.loss_cls: 0.0670  decode.d5.loss_mask: 0.6832  decode.d5.loss_dice: 1.2732  decode.d6.loss_cls: 0.0637  decode.d6.loss_mask: 0.6797  decode.d6.loss_dice: 1.2819  decode.d7.loss_cls: 0.0604  decode.d7.loss_mask: 0.6522  decode.d7.loss_dice: 1.2992  decode.d8.loss_cls: 0.0722  decode.d8.loss_mask: 0.6577  decode.d8.loss_dice: 1.2945
11/15 09:33:18 - mmengine - INFO - Iter(train) [15850/90000]  base_lr: 8.4001e-05 lr: 8.4001e-06  eta: 12:28:01  time: 0.5942  data_time: 0.0095  memory: 10656  grad_norm: 420.5459  loss: 19.4372  decode.loss_cls: 0.0645  decode.loss_mask: 0.6828  decode.loss_dice: 1.2114  decode.d0.loss_cls: 0.1105  decode.d0.loss_mask: 0.6241  decode.d0.loss_dice: 1.2003  decode.d1.loss_cls: 0.0825  decode.d1.loss_mask: 0.6713  decode.d1.loss_dice: 1.2127  decode.d2.loss_cls: 0.0782  decode.d2.loss_mask: 0.6651  decode.d2.loss_dice: 1.1993  decode.d3.loss_cls: 0.0970  decode.d3.loss_mask: 0.6146  decode.d3.loss_dice: 1.1583  decode.d4.loss_cls: 0.0830  decode.d4.loss_mask: 0.6269  decode.d4.loss_dice: 1.1949  decode.d5.loss_cls: 0.0689  decode.d5.loss_mask: 0.6763  decode.d5.loss_dice: 1.2096  decode.d6.loss_cls: 0.0756  decode.d6.loss_mask: 0.6437  decode.d6.loss_dice: 1.2262  decode.d7.loss_cls: 0.0677  decode.d7.loss_mask: 0.6722  decode.d7.loss_dice: 1.2246  decode.d8.loss_cls: 0.0645  decode.d8.loss_mask: 0.6867  decode.d8.loss_dice: 1.2438
11/15 09:33:48 - mmengine - INFO - Iter(train) [15900/90000]  base_lr: 8.3950e-05 lr: 8.3950e-06  eta: 12:27:28  time: 0.5949  data_time: 0.0097  memory: 10675  grad_norm: 356.7747  loss: 22.5785  decode.loss_cls: 0.1096  decode.loss_mask: 0.6398  decode.loss_dice: 1.4619  decode.d0.loss_cls: 0.0945  decode.d0.loss_mask: 0.6699  decode.d0.loss_dice: 1.6190  decode.d1.loss_cls: 0.1237  decode.d1.loss_mask: 0.6568  decode.d1.loss_dice: 1.5259  decode.d2.loss_cls: 0.1168  decode.d2.loss_mask: 0.6260  decode.d2.loss_dice: 1.4703  decode.d3.loss_cls: 0.1078  decode.d3.loss_mask: 0.6371  decode.d3.loss_dice: 1.5118  decode.d4.loss_cls: 0.1217  decode.d4.loss_mask: 0.6288  decode.d4.loss_dice: 1.5093  decode.d5.loss_cls: 0.1041  decode.d5.loss_mask: 0.6306  decode.d5.loss_dice: 1.4809  decode.d6.loss_cls: 0.1163  decode.d6.loss_mask: 0.6424  decode.d6.loss_dice: 1.4602  decode.d7.loss_cls: 0.1136  decode.d7.loss_mask: 0.6413  decode.d7.loss_dice: 1.5042  decode.d8.loss_cls: 0.1172  decode.d8.loss_mask: 0.6408  decode.d8.loss_dice: 1.4964
11/15 09:34:17 - mmengine - INFO - Iter(train) [15950/90000]  base_lr: 8.3899e-05 lr: 8.3899e-06  eta: 12:26:56  time: 0.5952  data_time: 0.0096  memory: 10692  grad_norm: 297.6174  loss: 20.1918  decode.loss_cls: 0.0964  decode.loss_mask: 0.6211  decode.loss_dice: 1.3019  decode.d0.loss_cls: 0.1276  decode.d0.loss_mask: 0.6666  decode.d0.loss_dice: 1.3545  decode.d1.loss_cls: 0.1274  decode.d1.loss_mask: 0.6178  decode.d1.loss_dice: 1.2854  decode.d2.loss_cls: 0.1129  decode.d2.loss_mask: 0.6294  decode.d2.loss_dice: 1.2753  decode.d3.loss_cls: 0.0992  decode.d3.loss_mask: 0.6287  decode.d3.loss_dice: 1.2463  decode.d4.loss_cls: 0.1081  decode.d4.loss_mask: 0.6256  decode.d4.loss_dice: 1.2703  decode.d5.loss_cls: 0.1023  decode.d5.loss_mask: 0.6273  decode.d5.loss_dice: 1.2586  decode.d6.loss_cls: 0.1033  decode.d6.loss_mask: 0.6361  decode.d6.loss_dice: 1.2711  decode.d7.loss_cls: 0.1118  decode.d7.loss_mask: 0.6231  decode.d7.loss_dice: 1.2617  decode.d8.loss_cls: 0.1097  decode.d8.loss_mask: 0.6232  decode.d8.loss_dice: 1.2693
11/15 09:34:47 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 09:34:47 - mmengine - INFO - Iter(train) [16000/90000]  base_lr: 8.3848e-05 lr: 8.3848e-06  eta: 12:26:24  time: 0.5939  data_time: 0.0095  memory: 10641  grad_norm: 1245.4640  loss: 21.7614  decode.loss_cls: 0.0982  decode.loss_mask: 0.6568  decode.loss_dice: 1.4113  decode.d0.loss_cls: 0.0808  decode.d0.loss_mask: 0.7065  decode.d0.loss_dice: 1.5150  decode.d1.loss_cls: 0.0742  decode.d1.loss_mask: 0.6768  decode.d1.loss_dice: 1.4597  decode.d2.loss_cls: 0.0752  decode.d2.loss_mask: 0.6618  decode.d2.loss_dice: 1.4820  decode.d3.loss_cls: 0.0931  decode.d3.loss_mask: 0.6481  decode.d3.loss_dice: 1.4195  decode.d4.loss_cls: 0.0879  decode.d4.loss_mask: 0.6577  decode.d4.loss_dice: 1.3830  decode.d5.loss_cls: 0.0990  decode.d5.loss_mask: 0.6508  decode.d5.loss_dice: 1.4023  decode.d6.loss_cls: 0.1038  decode.d6.loss_mask: 0.6331  decode.d6.loss_dice: 1.3720  decode.d7.loss_cls: 0.0773  decode.d7.loss_mask: 0.6450  decode.d7.loss_dice: 1.4225  decode.d8.loss_cls: 0.1018  decode.d8.loss_mask: 0.6444  decode.d8.loss_dice: 1.4220
11/15 09:35:17 - mmengine - INFO - Iter(train) [16050/90000]  base_lr: 8.3797e-05 lr: 8.3797e-06  eta: 12:25:52  time: 0.5935  data_time: 0.0096  memory: 10675  grad_norm: 374.8769  loss: 21.5427  decode.loss_cls: 0.0867  decode.loss_mask: 0.6405  decode.loss_dice: 1.4105  decode.d0.loss_cls: 0.0713  decode.d0.loss_mask: 0.7243  decode.d0.loss_dice: 1.4693  decode.d1.loss_cls: 0.0962  decode.d1.loss_mask: 0.6462  decode.d1.loss_dice: 1.3778  decode.d2.loss_cls: 0.0832  decode.d2.loss_mask: 0.6356  decode.d2.loss_dice: 1.4035  decode.d3.loss_cls: 0.0936  decode.d3.loss_mask: 0.6294  decode.d3.loss_dice: 1.4021  decode.d4.loss_cls: 0.0852  decode.d4.loss_mask: 0.6476  decode.d4.loss_dice: 1.3884  decode.d5.loss_cls: 0.0704  decode.d5.loss_mask: 0.6554  decode.d5.loss_dice: 1.4252  decode.d6.loss_cls: 0.0868  decode.d6.loss_mask: 0.6379  decode.d6.loss_dice: 1.4401  decode.d7.loss_cls: 0.1001  decode.d7.loss_mask: 0.6474  decode.d7.loss_dice: 1.4304  decode.d8.loss_cls: 0.1001  decode.d8.loss_mask: 0.6274  decode.d8.loss_dice: 1.4303
11/15 09:35:47 - mmengine - INFO - Iter(train) [16100/90000]  base_lr: 8.3746e-05 lr: 8.3746e-06  eta: 12:25:19  time: 0.5943  data_time: 0.0097  memory: 10728  grad_norm: 474.5968  loss: 21.3971  decode.loss_cls: 0.0832  decode.loss_mask: 0.6614  decode.loss_dice: 1.4173  decode.d0.loss_cls: 0.0887  decode.d0.loss_mask: 0.6587  decode.d0.loss_dice: 1.4544  decode.d1.loss_cls: 0.0777  decode.d1.loss_mask: 0.6688  decode.d1.loss_dice: 1.3930  decode.d2.loss_cls: 0.0736  decode.d2.loss_mask: 0.6640  decode.d2.loss_dice: 1.4282  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.6492  decode.d3.loss_dice: 1.3773  decode.d4.loss_cls: 0.0730  decode.d4.loss_mask: 0.6557  decode.d4.loss_dice: 1.4059  decode.d5.loss_cls: 0.0842  decode.d5.loss_mask: 0.6519  decode.d5.loss_dice: 1.3930  decode.d6.loss_cls: 0.0737  decode.d6.loss_mask: 0.6533  decode.d6.loss_dice: 1.3965  decode.d7.loss_cls: 0.0750  decode.d7.loss_mask: 0.6521  decode.d7.loss_dice: 1.4021  decode.d8.loss_cls: 0.0694  decode.d8.loss_mask: 0.6462  decode.d8.loss_dice: 1.3954
11/15 09:36:17 - mmengine - INFO - Iter(train) [16150/90000]  base_lr: 8.3695e-05 lr: 8.3695e-06  eta: 12:24:46  time: 0.5930  data_time: 0.0096  memory: 10656  grad_norm: 347.8255  loss: 21.3791  decode.loss_cls: 0.0742  decode.loss_mask: 0.7015  decode.loss_dice: 1.3257  decode.d0.loss_cls: 0.0797  decode.d0.loss_mask: 0.7429  decode.d0.loss_dice: 1.4274  decode.d1.loss_cls: 0.0838  decode.d1.loss_mask: 0.7037  decode.d1.loss_dice: 1.3686  decode.d2.loss_cls: 0.0687  decode.d2.loss_mask: 0.7152  decode.d2.loss_dice: 1.3516  decode.d3.loss_cls: 0.0684  decode.d3.loss_mask: 0.7087  decode.d3.loss_dice: 1.3429  decode.d4.loss_cls: 0.0724  decode.d4.loss_mask: 0.7020  decode.d4.loss_dice: 1.3526  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 0.7147  decode.d5.loss_dice: 1.3523  decode.d6.loss_cls: 0.0714  decode.d6.loss_mask: 0.7046  decode.d6.loss_dice: 1.3391  decode.d7.loss_cls: 0.0777  decode.d7.loss_mask: 0.6953  decode.d7.loss_dice: 1.3644  decode.d8.loss_cls: 0.0793  decode.d8.loss_mask: 0.7016  decode.d8.loss_dice: 1.3209
11/15 09:36:46 - mmengine - INFO - Iter(train) [16200/90000]  base_lr: 8.3644e-05 lr: 8.3644e-06  eta: 12:24:13  time: 0.5917  data_time: 0.0095  memory: 10675  grad_norm: 653.7706  loss: 22.3506  decode.loss_cls: 0.1223  decode.loss_mask: 0.7444  decode.loss_dice: 1.3368  decode.d0.loss_cls: 0.1199  decode.d0.loss_mask: 0.8540  decode.d0.loss_dice: 1.4443  decode.d1.loss_cls: 0.1175  decode.d1.loss_mask: 0.7644  decode.d1.loss_dice: 1.3462  decode.d2.loss_cls: 0.1249  decode.d2.loss_mask: 0.7498  decode.d2.loss_dice: 1.3377  decode.d3.loss_cls: 0.1105  decode.d3.loss_mask: 0.7595  decode.d3.loss_dice: 1.3548  decode.d4.loss_cls: 0.1207  decode.d4.loss_mask: 0.7468  decode.d4.loss_dice: 1.3396  decode.d5.loss_cls: 0.1234  decode.d5.loss_mask: 0.7139  decode.d5.loss_dice: 1.3237  decode.d6.loss_cls: 0.1212  decode.d6.loss_mask: 0.7595  decode.d6.loss_dice: 1.3044  decode.d7.loss_cls: 0.1266  decode.d7.loss_mask: 0.7852  decode.d7.loss_dice: 1.3614  decode.d8.loss_cls: 0.1209  decode.d8.loss_mask: 0.7643  decode.d8.loss_dice: 1.3522
11/15 09:37:16 - mmengine - INFO - Iter(train) [16250/90000]  base_lr: 8.3593e-05 lr: 8.3593e-06  eta: 12:23:41  time: 0.5935  data_time: 0.0095  memory: 10692  grad_norm: 346.5978  loss: 19.5769  decode.loss_cls: 0.0760  decode.loss_mask: 0.6009  decode.loss_dice: 1.3337  decode.d0.loss_cls: 0.0898  decode.d0.loss_mask: 0.6309  decode.d0.loss_dice: 1.3741  decode.d1.loss_cls: 0.0727  decode.d1.loss_mask: 0.5944  decode.d1.loss_dice: 1.2761  decode.d2.loss_cls: 0.0873  decode.d2.loss_mask: 0.6004  decode.d2.loss_dice: 1.2680  decode.d3.loss_cls: 0.0869  decode.d3.loss_mask: 0.5773  decode.d3.loss_dice: 1.2297  decode.d4.loss_cls: 0.0849  decode.d4.loss_mask: 0.5761  decode.d4.loss_dice: 1.2874  decode.d5.loss_cls: 0.0835  decode.d5.loss_mask: 0.5805  decode.d5.loss_dice: 1.2480  decode.d6.loss_cls: 0.0727  decode.d6.loss_mask: 0.5815  decode.d6.loss_dice: 1.2842  decode.d7.loss_cls: 0.0781  decode.d7.loss_mask: 0.5836  decode.d7.loss_dice: 1.2759  decode.d8.loss_cls: 0.0846  decode.d8.loss_mask: 0.5790  decode.d8.loss_dice: 1.2786
11/15 09:37:46 - mmengine - INFO - Iter(train) [16300/90000]  base_lr: 8.3542e-05 lr: 8.3542e-06  eta: 12:23:10  time: 0.6481  data_time: 0.0111  memory: 10641  grad_norm: 535.1458  loss: 19.7231  decode.loss_cls: 0.0786  decode.loss_mask: 0.5762  decode.loss_dice: 1.2882  decode.d0.loss_cls: 0.0854  decode.d0.loss_mask: 0.5852  decode.d0.loss_dice: 1.3630  decode.d1.loss_cls: 0.0899  decode.d1.loss_mask: 0.5709  decode.d1.loss_dice: 1.3018  decode.d2.loss_cls: 0.0821  decode.d2.loss_mask: 0.5719  decode.d2.loss_dice: 1.2928  decode.d3.loss_cls: 0.0705  decode.d3.loss_mask: 0.5938  decode.d3.loss_dice: 1.3000  decode.d4.loss_cls: 0.0724  decode.d4.loss_mask: 0.5897  decode.d4.loss_dice: 1.3113  decode.d5.loss_cls: 0.0840  decode.d5.loss_mask: 0.5924  decode.d5.loss_dice: 1.2788  decode.d6.loss_cls: 0.0813  decode.d6.loss_mask: 0.5952  decode.d6.loss_dice: 1.2930  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.5941  decode.d7.loss_dice: 1.3254  decode.d8.loss_cls: 0.0757  decode.d8.loss_mask: 0.5848  decode.d8.loss_dice: 1.3267
11/15 09:38:16 - mmengine - INFO - Iter(train) [16350/90000]  base_lr: 8.3491e-05 lr: 8.3491e-06  eta: 12:22:37  time: 0.5928  data_time: 0.0094  memory: 10713  grad_norm: 2110.0929  loss: 18.6587  decode.loss_cls: 0.0769  decode.loss_mask: 0.5435  decode.loss_dice: 1.2255  decode.d0.loss_cls: 0.0958  decode.d0.loss_mask: 0.5626  decode.d0.loss_dice: 1.2670  decode.d1.loss_cls: 0.0921  decode.d1.loss_mask: 0.5389  decode.d1.loss_dice: 1.2238  decode.d2.loss_cls: 0.0883  decode.d2.loss_mask: 0.5629  decode.d2.loss_dice: 1.2113  decode.d3.loss_cls: 0.0909  decode.d3.loss_mask: 0.5644  decode.d3.loss_dice: 1.2296  decode.d4.loss_cls: 0.0821  decode.d4.loss_mask: 0.5496  decode.d4.loss_dice: 1.2198  decode.d5.loss_cls: 0.0848  decode.d5.loss_mask: 0.5494  decode.d5.loss_dice: 1.2214  decode.d6.loss_cls: 0.0829  decode.d6.loss_mask: 0.5457  decode.d6.loss_dice: 1.2104  decode.d7.loss_cls: 0.0948  decode.d7.loss_mask: 0.5378  decode.d7.loss_dice: 1.2444  decode.d8.loss_cls: 0.0767  decode.d8.loss_mask: 0.5598  decode.d8.loss_dice: 1.2260
11/15 09:38:46 - mmengine - INFO - Iter(train) [16400/90000]  base_lr: 8.3440e-05 lr: 8.3440e-06  eta: 12:22:04  time: 0.5922  data_time: 0.0096  memory: 10675  grad_norm: 381.3634  loss: 20.4624  decode.loss_cls: 0.0926  decode.loss_mask: 0.6212  decode.loss_dice: 1.2882  decode.d0.loss_cls: 0.0865  decode.d0.loss_mask: 0.6416  decode.d0.loss_dice: 1.4226  decode.d1.loss_cls: 0.0764  decode.d1.loss_mask: 0.6114  decode.d1.loss_dice: 1.3542  decode.d2.loss_cls: 0.0866  decode.d2.loss_mask: 0.6140  decode.d2.loss_dice: 1.3335  decode.d3.loss_cls: 0.0883  decode.d3.loss_mask: 0.6251  decode.d3.loss_dice: 1.3258  decode.d4.loss_cls: 0.1062  decode.d4.loss_mask: 0.6148  decode.d4.loss_dice: 1.3215  decode.d5.loss_cls: 0.0992  decode.d5.loss_mask: 0.6184  decode.d5.loss_dice: 1.3110  decode.d6.loss_cls: 0.1148  decode.d6.loss_mask: 0.6194  decode.d6.loss_dice: 1.3054  decode.d7.loss_cls: 0.0960  decode.d7.loss_mask: 0.6253  decode.d7.loss_dice: 1.3369  decode.d8.loss_cls: 0.0926  decode.d8.loss_mask: 0.6175  decode.d8.loss_dice: 1.3154
11/15 09:39:15 - mmengine - INFO - Iter(train) [16450/90000]  base_lr: 8.3389e-05 lr: 8.3389e-06  eta: 12:21:31  time: 0.5930  data_time: 0.0097  memory: 10675  grad_norm: 311.1128  loss: 21.0142  decode.loss_cls: 0.1103  decode.loss_mask: 0.5590  decode.loss_dice: 1.4202  decode.d0.loss_cls: 0.0988  decode.d0.loss_mask: 0.5849  decode.d0.loss_dice: 1.4837  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.5665  decode.d1.loss_dice: 1.4568  decode.d2.loss_cls: 0.0930  decode.d2.loss_mask: 0.5864  decode.d2.loss_dice: 1.4169  decode.d3.loss_cls: 0.0920  decode.d3.loss_mask: 0.5810  decode.d3.loss_dice: 1.4052  decode.d4.loss_cls: 0.0920  decode.d4.loss_mask: 0.5833  decode.d4.loss_dice: 1.4434  decode.d5.loss_cls: 0.0890  decode.d5.loss_mask: 0.5616  decode.d5.loss_dice: 1.4171  decode.d6.loss_cls: 0.0981  decode.d6.loss_mask: 0.5773  decode.d6.loss_dice: 1.4088  decode.d7.loss_cls: 0.0926  decode.d7.loss_mask: 0.5851  decode.d7.loss_dice: 1.4108  decode.d8.loss_cls: 0.1046  decode.d8.loss_mask: 0.5776  decode.d8.loss_dice: 1.4362
11/15 09:39:45 - mmengine - INFO - Iter(train) [16500/90000]  base_lr: 8.3338e-05 lr: 8.3338e-06  eta: 12:20:59  time: 0.5928  data_time: 0.0095  memory: 10692  grad_norm: 364.8781  loss: 19.6619  decode.loss_cls: 0.0551  decode.loss_mask: 0.6085  decode.loss_dice: 1.2949  decode.d0.loss_cls: 0.0750  decode.d0.loss_mask: 0.6317  decode.d0.loss_dice: 1.3182  decode.d1.loss_cls: 0.0710  decode.d1.loss_mask: 0.6072  decode.d1.loss_dice: 1.2647  decode.d2.loss_cls: 0.0618  decode.d2.loss_mask: 0.6232  decode.d2.loss_dice: 1.2899  decode.d3.loss_cls: 0.0543  decode.d3.loss_mask: 0.6197  decode.d3.loss_dice: 1.2718  decode.d4.loss_cls: 0.0623  decode.d4.loss_mask: 0.6166  decode.d4.loss_dice: 1.3039  decode.d5.loss_cls: 0.0513  decode.d5.loss_mask: 0.6191  decode.d5.loss_dice: 1.2804  decode.d6.loss_cls: 0.0478  decode.d6.loss_mask: 0.6111  decode.d6.loss_dice: 1.2882  decode.d7.loss_cls: 0.0616  decode.d7.loss_mask: 0.6036  decode.d7.loss_dice: 1.2919  decode.d8.loss_cls: 0.0663  decode.d8.loss_mask: 0.6123  decode.d8.loss_dice: 1.2983
11/15 09:40:15 - mmengine - INFO - Iter(train) [16550/90000]  base_lr: 8.3287e-05 lr: 8.3287e-06  eta: 12:20:26  time: 0.5931  data_time: 0.0095  memory: 10656  grad_norm: 692.3383  loss: 19.2675  decode.loss_cls: 0.0718  decode.loss_mask: 0.5464  decode.loss_dice: 1.2806  decode.d0.loss_cls: 0.0764  decode.d0.loss_mask: 0.5823  decode.d0.loss_dice: 1.3719  decode.d1.loss_cls: 0.0877  decode.d1.loss_mask: 0.5503  decode.d1.loss_dice: 1.2975  decode.d2.loss_cls: 0.0839  decode.d2.loss_mask: 0.5200  decode.d2.loss_dice: 1.2973  decode.d3.loss_cls: 0.0806  decode.d3.loss_mask: 0.5341  decode.d3.loss_dice: 1.2667  decode.d4.loss_cls: 0.0805  decode.d4.loss_mask: 0.5405  decode.d4.loss_dice: 1.2647  decode.d5.loss_cls: 0.0780  decode.d5.loss_mask: 0.5516  decode.d5.loss_dice: 1.2770  decode.d6.loss_cls: 0.0679  decode.d6.loss_mask: 0.5648  decode.d6.loss_dice: 1.3152  decode.d7.loss_cls: 0.0839  decode.d7.loss_mask: 0.5634  decode.d7.loss_dice: 1.2874  decode.d8.loss_cls: 0.0897  decode.d8.loss_mask: 0.5604  decode.d8.loss_dice: 1.2952
11/15 09:40:44 - mmengine - INFO - Iter(train) [16600/90000]  base_lr: 8.3236e-05 lr: 8.3236e-06  eta: 12:19:53  time: 0.5956  data_time: 0.0097  memory: 10656  grad_norm: 390.5578  loss: 19.7224  decode.loss_cls: 0.0821  decode.loss_mask: 0.6337  decode.loss_dice: 1.2393  decode.d0.loss_cls: 0.0924  decode.d0.loss_mask: 0.6458  decode.d0.loss_dice: 1.3342  decode.d1.loss_cls: 0.0875  decode.d1.loss_mask: 0.6377  decode.d1.loss_dice: 1.2209  decode.d2.loss_cls: 0.0792  decode.d2.loss_mask: 0.6394  decode.d2.loss_dice: 1.2437  decode.d3.loss_cls: 0.0818  decode.d3.loss_mask: 0.6385  decode.d3.loss_dice: 1.2347  decode.d4.loss_cls: 0.0773  decode.d4.loss_mask: 0.6319  decode.d4.loss_dice: 1.2419  decode.d5.loss_cls: 0.0774  decode.d5.loss_mask: 0.6229  decode.d5.loss_dice: 1.2680  decode.d6.loss_cls: 0.0770  decode.d6.loss_mask: 0.6297  decode.d6.loss_dice: 1.2588  decode.d7.loss_cls: 0.0859  decode.d7.loss_mask: 0.6231  decode.d7.loss_dice: 1.2693  decode.d8.loss_cls: 0.0945  decode.d8.loss_mask: 0.6294  decode.d8.loss_dice: 1.2445
11/15 09:41:14 - mmengine - INFO - Iter(train) [16650/90000]  base_lr: 8.3185e-05 lr: 8.3185e-06  eta: 12:19:22  time: 0.6227  data_time: 0.0098  memory: 10692  grad_norm: 351.9500  loss: 20.0498  decode.loss_cls: 0.0719  decode.loss_mask: 0.5978  decode.loss_dice: 1.3384  decode.d0.loss_cls: 0.0869  decode.d0.loss_mask: 0.5487  decode.d0.loss_dice: 1.4360  decode.d1.loss_cls: 0.0748  decode.d1.loss_mask: 0.5504  decode.d1.loss_dice: 1.3578  decode.d2.loss_cls: 0.0746  decode.d2.loss_mask: 0.5570  decode.d2.loss_dice: 1.3764  decode.d3.loss_cls: 0.0669  decode.d3.loss_mask: 0.5594  decode.d3.loss_dice: 1.3288  decode.d4.loss_cls: 0.0705  decode.d4.loss_mask: 0.5536  decode.d4.loss_dice: 1.3439  decode.d5.loss_cls: 0.0761  decode.d5.loss_mask: 0.5602  decode.d5.loss_dice: 1.3673  decode.d6.loss_cls: 0.0617  decode.d6.loss_mask: 0.5922  decode.d6.loss_dice: 1.3595  decode.d7.loss_cls: 0.0683  decode.d7.loss_mask: 0.5955  decode.d7.loss_dice: 1.3332  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.5968  decode.d8.loss_dice: 1.3678
11/15 09:41:44 - mmengine - INFO - Iter(train) [16700/90000]  base_lr: 8.3134e-05 lr: 8.3134e-06  eta: 12:18:49  time: 0.5981  data_time: 0.0099  memory: 10692  grad_norm: 880.9290  loss: 21.1348  decode.loss_cls: 0.0993  decode.loss_mask: 0.6247  decode.loss_dice: 1.3676  decode.d0.loss_cls: 0.0931  decode.d0.loss_mask: 0.6016  decode.d0.loss_dice: 1.4753  decode.d1.loss_cls: 0.0990  decode.d1.loss_mask: 0.6426  decode.d1.loss_dice: 1.4125  decode.d2.loss_cls: 0.1033  decode.d2.loss_mask: 0.6260  decode.d2.loss_dice: 1.3870  decode.d3.loss_cls: 0.1017  decode.d3.loss_mask: 0.6217  decode.d3.loss_dice: 1.3619  decode.d4.loss_cls: 0.1142  decode.d4.loss_mask: 0.6256  decode.d4.loss_dice: 1.3555  decode.d5.loss_cls: 0.0963  decode.d5.loss_mask: 0.6361  decode.d5.loss_dice: 1.3694  decode.d6.loss_cls: 0.0907  decode.d6.loss_mask: 0.6261  decode.d6.loss_dice: 1.3861  decode.d7.loss_cls: 0.1029  decode.d7.loss_mask: 0.6205  decode.d7.loss_dice: 1.3683  decode.d8.loss_cls: 0.0977  decode.d8.loss_mask: 0.6507  decode.d8.loss_dice: 1.3776
11/15 09:42:14 - mmengine - INFO - Iter(train) [16750/90000]  base_lr: 8.3083e-05 lr: 8.3083e-06  eta: 12:18:17  time: 0.5952  data_time: 0.0098  memory: 10675  grad_norm: 421.3186  loss: 20.6930  decode.loss_cls: 0.0905  decode.loss_mask: 0.6771  decode.loss_dice: 1.3029  decode.d0.loss_cls: 0.0899  decode.d0.loss_mask: 0.6885  decode.d0.loss_dice: 1.3755  decode.d1.loss_cls: 0.0923  decode.d1.loss_mask: 0.6672  decode.d1.loss_dice: 1.3200  decode.d2.loss_cls: 0.1042  decode.d2.loss_mask: 0.6385  decode.d2.loss_dice: 1.2996  decode.d3.loss_cls: 0.0941  decode.d3.loss_mask: 0.6630  decode.d3.loss_dice: 1.3042  decode.d4.loss_cls: 0.0977  decode.d4.loss_mask: 0.6525  decode.d4.loss_dice: 1.3152  decode.d5.loss_cls: 0.0993  decode.d5.loss_mask: 0.6482  decode.d5.loss_dice: 1.3221  decode.d6.loss_cls: 0.0927  decode.d6.loss_mask: 0.6336  decode.d6.loss_dice: 1.3029  decode.d7.loss_cls: 0.0885  decode.d7.loss_mask: 0.6583  decode.d7.loss_dice: 1.3096  decode.d8.loss_cls: 0.0974  decode.d8.loss_mask: 0.6595  decode.d8.loss_dice: 1.3079
11/15 09:42:44 - mmengine - INFO - Iter(train) [16800/90000]  base_lr: 8.3032e-05 lr: 8.3032e-06  eta: 12:17:45  time: 0.5982  data_time: 0.0099  memory: 10713  grad_norm: 343.9687  loss: 19.5337  decode.loss_cls: 0.0691  decode.loss_mask: 0.5679  decode.loss_dice: 1.2649  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.6101  decode.d0.loss_dice: 1.3734  decode.d1.loss_cls: 0.0731  decode.d1.loss_mask: 0.5888  decode.d1.loss_dice: 1.3299  decode.d2.loss_cls: 0.0782  decode.d2.loss_mask: 0.5785  decode.d2.loss_dice: 1.3012  decode.d3.loss_cls: 0.0677  decode.d3.loss_mask: 0.5967  decode.d3.loss_dice: 1.2747  decode.d4.loss_cls: 0.0824  decode.d4.loss_mask: 0.5730  decode.d4.loss_dice: 1.2523  decode.d5.loss_cls: 0.0812  decode.d5.loss_mask: 0.5729  decode.d5.loss_dice: 1.2755  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.5887  decode.d6.loss_dice: 1.2885  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.6108  decode.d7.loss_dice: 1.2805  decode.d8.loss_cls: 0.0634  decode.d8.loss_mask: 0.5993  decode.d8.loss_dice: 1.2702
11/15 09:43:13 - mmengine - INFO - Iter(train) [16850/90000]  base_lr: 8.2981e-05 lr: 8.2981e-06  eta: 12:17:13  time: 0.5950  data_time: 0.0098  memory: 10675  grad_norm: 305.6177  loss: 20.7743  decode.loss_cls: 0.0993  decode.loss_mask: 0.6012  decode.loss_dice: 1.3482  decode.d0.loss_cls: 0.0653  decode.d0.loss_mask: 0.6511  decode.d0.loss_dice: 1.4431  decode.d1.loss_cls: 0.0714  decode.d1.loss_mask: 0.6320  decode.d1.loss_dice: 1.3801  decode.d2.loss_cls: 0.0913  decode.d2.loss_mask: 0.6209  decode.d2.loss_dice: 1.3577  decode.d3.loss_cls: 0.0917  decode.d3.loss_mask: 0.6258  decode.d3.loss_dice: 1.3505  decode.d4.loss_cls: 0.0730  decode.d4.loss_mask: 0.6304  decode.d4.loss_dice: 1.3434  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.6317  decode.d5.loss_dice: 1.3723  decode.d6.loss_cls: 0.0844  decode.d6.loss_mask: 0.6491  decode.d6.loss_dice: 1.3498  decode.d7.loss_cls: 0.0763  decode.d7.loss_mask: 0.6453  decode.d7.loss_dice: 1.3610  decode.d8.loss_cls: 0.0790  decode.d8.loss_mask: 0.6161  decode.d8.loss_dice: 1.3500
11/15 09:43:43 - mmengine - INFO - Iter(train) [16900/90000]  base_lr: 8.2930e-05 lr: 8.2930e-06  eta: 12:16:41  time: 0.5944  data_time: 0.0096  memory: 10656  grad_norm: 332.4874  loss: 20.6690  decode.loss_cls: 0.0840  decode.loss_mask: 0.6253  decode.loss_dice: 1.3913  decode.d0.loss_cls: 0.0945  decode.d0.loss_mask: 0.5892  decode.d0.loss_dice: 1.4335  decode.d1.loss_cls: 0.0982  decode.d1.loss_mask: 0.5898  decode.d1.loss_dice: 1.3769  decode.d2.loss_cls: 0.0936  decode.d2.loss_mask: 0.5780  decode.d2.loss_dice: 1.3541  decode.d3.loss_cls: 0.0835  decode.d3.loss_mask: 0.5991  decode.d3.loss_dice: 1.3275  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 0.6127  decode.d4.loss_dice: 1.3639  decode.d5.loss_cls: 0.0857  decode.d5.loss_mask: 0.6105  decode.d5.loss_dice: 1.3405  decode.d6.loss_cls: 0.0739  decode.d6.loss_mask: 0.6336  decode.d6.loss_dice: 1.3821  decode.d7.loss_cls: 0.0808  decode.d7.loss_mask: 0.6277  decode.d7.loss_dice: 1.3713  decode.d8.loss_cls: 0.0862  decode.d8.loss_mask: 0.6121  decode.d8.loss_dice: 1.3823
11/15 09:44:13 - mmengine - INFO - Iter(train) [16950/90000]  base_lr: 8.2879e-05 lr: 8.2879e-06  eta: 12:16:08  time: 0.5931  data_time: 0.0097  memory: 10713  grad_norm: 408.5706  loss: 19.3583  decode.loss_cls: 0.0622  decode.loss_mask: 0.5304  decode.loss_dice: 1.3117  decode.d0.loss_cls: 0.0859  decode.d0.loss_mask: 0.5794  decode.d0.loss_dice: 1.3941  decode.d1.loss_cls: 0.0624  decode.d1.loss_mask: 0.5426  decode.d1.loss_dice: 1.3673  decode.d2.loss_cls: 0.0879  decode.d2.loss_mask: 0.5374  decode.d2.loss_dice: 1.3065  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.5411  decode.d3.loss_dice: 1.2979  decode.d4.loss_cls: 0.0759  decode.d4.loss_mask: 0.5448  decode.d4.loss_dice: 1.3004  decode.d5.loss_cls: 0.0751  decode.d5.loss_mask: 0.5443  decode.d5.loss_dice: 1.2984  decode.d6.loss_cls: 0.0690  decode.d6.loss_mask: 0.5344  decode.d6.loss_dice: 1.2822  decode.d7.loss_cls: 0.0633  decode.d7.loss_mask: 0.5373  decode.d7.loss_dice: 1.3288  decode.d8.loss_cls: 0.0743  decode.d8.loss_mask: 0.5398  decode.d8.loss_dice: 1.3093
11/15 09:44:43 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 09:44:43 - mmengine - INFO - Iter(train) [17000/90000]  base_lr: 8.2828e-05 lr: 8.2828e-06  eta: 12:15:36  time: 0.5944  data_time: 0.0097  memory: 10641  grad_norm: 400.8361  loss: 19.5983  decode.loss_cls: 0.0840  decode.loss_mask: 0.6949  decode.loss_dice: 1.1711  decode.d0.loss_cls: 0.0849  decode.d0.loss_mask: 0.7237  decode.d0.loss_dice: 1.2918  decode.d1.loss_cls: 0.0694  decode.d1.loss_mask: 0.6925  decode.d1.loss_dice: 1.2106  decode.d2.loss_cls: 0.0808  decode.d2.loss_mask: 0.6793  decode.d2.loss_dice: 1.1866  decode.d3.loss_cls: 0.0745  decode.d3.loss_mask: 0.6974  decode.d3.loss_dice: 1.1910  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.7007  decode.d4.loss_dice: 1.1880  decode.d5.loss_cls: 0.0825  decode.d5.loss_mask: 0.6877  decode.d5.loss_dice: 1.2016  decode.d6.loss_cls: 0.0752  decode.d6.loss_mask: 0.6683  decode.d6.loss_dice: 1.1923  decode.d7.loss_cls: 0.0821  decode.d7.loss_mask: 0.6640  decode.d7.loss_dice: 1.1500  decode.d8.loss_cls: 0.0847  decode.d8.loss_mask: 0.6541  decode.d8.loss_dice: 1.1571
11/15 09:45:12 - mmengine - INFO - Iter(train) [17050/90000]  base_lr: 8.2777e-05 lr: 8.2777e-06  eta: 12:15:03  time: 0.5934  data_time: 0.0095  memory: 10656  grad_norm: 424.2876  loss: 20.0231  decode.loss_cls: 0.0588  decode.loss_mask: 0.5904  decode.loss_dice: 1.3335  decode.d0.loss_cls: 0.0653  decode.d0.loss_mask: 0.6247  decode.d0.loss_dice: 1.3835  decode.d1.loss_cls: 0.0727  decode.d1.loss_mask: 0.5966  decode.d1.loss_dice: 1.3464  decode.d2.loss_cls: 0.0771  decode.d2.loss_mask: 0.5813  decode.d2.loss_dice: 1.3184  decode.d3.loss_cls: 0.0690  decode.d3.loss_mask: 0.6058  decode.d3.loss_dice: 1.3421  decode.d4.loss_cls: 0.0615  decode.d4.loss_mask: 0.5993  decode.d4.loss_dice: 1.3579  decode.d5.loss_cls: 0.0643  decode.d5.loss_mask: 0.5962  decode.d5.loss_dice: 1.3111  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 0.5949  decode.d6.loss_dice: 1.3070  decode.d7.loss_cls: 0.0466  decode.d7.loss_mask: 0.5947  decode.d7.loss_dice: 1.3339  decode.d8.loss_cls: 0.0522  decode.d8.loss_mask: 0.5958  decode.d8.loss_dice: 1.3587
11/15 09:45:42 - mmengine - INFO - Iter(train) [17100/90000]  base_lr: 8.2726e-05 lr: 8.2726e-06  eta: 12:14:31  time: 0.5944  data_time: 0.0099  memory: 10713  grad_norm: 439.5720  loss: 19.4119  decode.loss_cls: 0.0888  decode.loss_mask: 0.5572  decode.loss_dice: 1.2992  decode.d0.loss_cls: 0.0821  decode.d0.loss_mask: 0.5778  decode.d0.loss_dice: 1.3556  decode.d1.loss_cls: 0.1054  decode.d1.loss_mask: 0.5594  decode.d1.loss_dice: 1.2868  decode.d2.loss_cls: 0.0889  decode.d2.loss_mask: 0.5704  decode.d2.loss_dice: 1.2966  decode.d3.loss_cls: 0.0967  decode.d3.loss_mask: 0.5391  decode.d3.loss_dice: 1.2851  decode.d4.loss_cls: 0.0954  decode.d4.loss_mask: 0.5410  decode.d4.loss_dice: 1.2897  decode.d5.loss_cls: 0.0844  decode.d5.loss_mask: 0.5510  decode.d5.loss_dice: 1.3031  decode.d6.loss_cls: 0.0880  decode.d6.loss_mask: 0.5450  decode.d6.loss_dice: 1.2955  decode.d7.loss_cls: 0.0917  decode.d7.loss_mask: 0.5416  decode.d7.loss_dice: 1.2856  decode.d8.loss_cls: 0.0947  decode.d8.loss_mask: 0.5381  decode.d8.loss_dice: 1.2783
11/15 09:46:12 - mmengine - INFO - Iter(train) [17150/90000]  base_lr: 8.2675e-05 lr: 8.2675e-06  eta: 12:13:58  time: 0.5930  data_time: 0.0098  memory: 10641  grad_norm: 718.3292  loss: 21.0287  decode.loss_cls: 0.1011  decode.loss_mask: 0.6401  decode.loss_dice: 1.3172  decode.d0.loss_cls: 0.0798  decode.d0.loss_mask: 0.6799  decode.d0.loss_dice: 1.4125  decode.d1.loss_cls: 0.1031  decode.d1.loss_mask: 0.6588  decode.d1.loss_dice: 1.3422  decode.d2.loss_cls: 0.0963  decode.d2.loss_mask: 0.6752  decode.d2.loss_dice: 1.3265  decode.d3.loss_cls: 0.0897  decode.d3.loss_mask: 0.6414  decode.d3.loss_dice: 1.3330  decode.d4.loss_cls: 0.1152  decode.d4.loss_mask: 0.6387  decode.d4.loss_dice: 1.3208  decode.d5.loss_cls: 0.1244  decode.d5.loss_mask: 0.6546  decode.d5.loss_dice: 1.3507  decode.d6.loss_cls: 0.1021  decode.d6.loss_mask: 0.6654  decode.d6.loss_dice: 1.3292  decode.d7.loss_cls: 0.0981  decode.d7.loss_mask: 0.6897  decode.d7.loss_dice: 1.3181  decode.d8.loss_cls: 0.0929  decode.d8.loss_mask: 0.6734  decode.d8.loss_dice: 1.3584
11/15 09:46:41 - mmengine - INFO - Iter(train) [17200/90000]  base_lr: 8.2624e-05 lr: 8.2624e-06  eta: 12:13:25  time: 0.5930  data_time: 0.0095  memory: 10692  grad_norm: 355.1800  loss: 20.5781  decode.loss_cls: 0.0879  decode.loss_mask: 0.5637  decode.loss_dice: 1.4042  decode.d0.loss_cls: 0.0914  decode.d0.loss_mask: 0.5627  decode.d0.loss_dice: 1.5000  decode.d1.loss_cls: 0.0728  decode.d1.loss_mask: 0.5491  decode.d1.loss_dice: 1.4634  decode.d2.loss_cls: 0.0785  decode.d2.loss_mask: 0.5476  decode.d2.loss_dice: 1.4055  decode.d3.loss_cls: 0.0816  decode.d3.loss_mask: 0.5487  decode.d3.loss_dice: 1.4018  decode.d4.loss_cls: 0.0784  decode.d4.loss_mask: 0.5446  decode.d4.loss_dice: 1.4144  decode.d5.loss_cls: 0.0927  decode.d5.loss_mask: 0.5475  decode.d5.loss_dice: 1.3951  decode.d6.loss_cls: 0.0960  decode.d6.loss_mask: 0.5458  decode.d6.loss_dice: 1.4082  decode.d7.loss_cls: 0.0928  decode.d7.loss_mask: 0.5548  decode.d7.loss_dice: 1.3891  decode.d8.loss_cls: 0.0800  decode.d8.loss_mask: 0.5564  decode.d8.loss_dice: 1.4235
11/15 09:47:11 - mmengine - INFO - Iter(train) [17250/90000]  base_lr: 8.2573e-05 lr: 8.2573e-06  eta: 12:12:54  time: 0.5934  data_time: 0.0097  memory: 10675  grad_norm: 283.2514  loss: 18.0674  decode.loss_cls: 0.0591  decode.loss_mask: 0.5402  decode.loss_dice: 1.1968  decode.d0.loss_cls: 0.0734  decode.d0.loss_mask: 0.5602  decode.d0.loss_dice: 1.2605  decode.d1.loss_cls: 0.0639  decode.d1.loss_mask: 0.5327  decode.d1.loss_dice: 1.2138  decode.d2.loss_cls: 0.0735  decode.d2.loss_mask: 0.5289  decode.d2.loss_dice: 1.1851  decode.d3.loss_cls: 0.0597  decode.d3.loss_mask: 0.5356  decode.d3.loss_dice: 1.1972  decode.d4.loss_cls: 0.0654  decode.d4.loss_mask: 0.5428  decode.d4.loss_dice: 1.2053  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.5308  decode.d5.loss_dice: 1.1931  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.5373  decode.d6.loss_dice: 1.1862  decode.d7.loss_cls: 0.0673  decode.d7.loss_mask: 0.5357  decode.d7.loss_dice: 1.2022  decode.d8.loss_cls: 0.0632  decode.d8.loss_mask: 0.5390  decode.d8.loss_dice: 1.1954
11/15 09:47:41 - mmengine - INFO - Iter(train) [17300/90000]  base_lr: 8.2521e-05 lr: 8.2521e-06  eta: 12:12:22  time: 0.5953  data_time: 0.0098  memory: 10692  grad_norm: 324.5311  loss: 20.9066  decode.loss_cls: 0.0798  decode.loss_mask: 0.5550  decode.loss_dice: 1.4095  decode.d0.loss_cls: 0.0803  decode.d0.loss_mask: 0.5822  decode.d0.loss_dice: 1.5344  decode.d1.loss_cls: 0.0876  decode.d1.loss_mask: 0.5575  decode.d1.loss_dice: 1.4258  decode.d2.loss_cls: 0.0812  decode.d2.loss_mask: 0.5586  decode.d2.loss_dice: 1.4581  decode.d3.loss_cls: 0.0934  decode.d3.loss_mask: 0.5628  decode.d3.loss_dice: 1.3997  decode.d4.loss_cls: 0.0964  decode.d4.loss_mask: 0.5586  decode.d4.loss_dice: 1.4511  decode.d5.loss_cls: 0.0933  decode.d5.loss_mask: 0.5654  decode.d5.loss_dice: 1.4526  decode.d6.loss_cls: 0.0894  decode.d6.loss_mask: 0.5649  decode.d6.loss_dice: 1.4132  decode.d7.loss_cls: 0.0685  decode.d7.loss_mask: 0.5625  decode.d7.loss_dice: 1.4554  decode.d8.loss_cls: 0.0715  decode.d8.loss_mask: 0.5648  decode.d8.loss_dice: 1.4330
11/15 09:48:11 - mmengine - INFO - Iter(train) [17350/90000]  base_lr: 8.2470e-05 lr: 8.2470e-06  eta: 12:11:50  time: 0.5981  data_time: 0.0100  memory: 10675  grad_norm: 353.2048  loss: 16.7813  decode.loss_cls: 0.0566  decode.loss_mask: 0.5487  decode.loss_dice: 1.0477  decode.d0.loss_cls: 0.0778  decode.d0.loss_mask: 0.5799  decode.d0.loss_dice: 1.1180  decode.d1.loss_cls: 0.0714  decode.d1.loss_mask: 0.5442  decode.d1.loss_dice: 1.0705  decode.d2.loss_cls: 0.0766  decode.d2.loss_mask: 0.5469  decode.d2.loss_dice: 1.0438  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 0.5460  decode.d3.loss_dice: 1.0518  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.5366  decode.d4.loss_dice: 1.0721  decode.d5.loss_cls: 0.0667  decode.d5.loss_mask: 0.5549  decode.d5.loss_dice: 1.0598  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.5485  decode.d6.loss_dice: 1.0511  decode.d7.loss_cls: 0.0649  decode.d7.loss_mask: 0.5507  decode.d7.loss_dice: 1.0434  decode.d8.loss_cls: 0.0644  decode.d8.loss_mask: 0.5479  decode.d8.loss_dice: 1.0456
11/15 09:48:41 - mmengine - INFO - Iter(train) [17400/90000]  base_lr: 8.2419e-05 lr: 8.2419e-06  eta: 12:11:18  time: 0.5976  data_time: 0.0099  memory: 10675  grad_norm: 325.4968  loss: 20.6759  decode.loss_cls: 0.1005  decode.loss_mask: 0.6205  decode.loss_dice: 1.3573  decode.d0.loss_cls: 0.1087  decode.d0.loss_mask: 0.5905  decode.d0.loss_dice: 1.4599  decode.d1.loss_cls: 0.1178  decode.d1.loss_mask: 0.5975  decode.d1.loss_dice: 1.3992  decode.d2.loss_cls: 0.1036  decode.d2.loss_mask: 0.6083  decode.d2.loss_dice: 1.3282  decode.d3.loss_cls: 0.1014  decode.d3.loss_mask: 0.6064  decode.d3.loss_dice: 1.3266  decode.d4.loss_cls: 0.1027  decode.d4.loss_mask: 0.6050  decode.d4.loss_dice: 1.3259  decode.d5.loss_cls: 0.1053  decode.d5.loss_mask: 0.6152  decode.d5.loss_dice: 1.3360  decode.d6.loss_cls: 0.1003  decode.d6.loss_mask: 0.6146  decode.d6.loss_dice: 1.3349  decode.d7.loss_cls: 0.1114  decode.d7.loss_mask: 0.6005  decode.d7.loss_dice: 1.3365  decode.d8.loss_cls: 0.1007  decode.d8.loss_mask: 0.6057  decode.d8.loss_dice: 1.3548
11/15 09:49:11 - mmengine - INFO - Iter(train) [17450/90000]  base_lr: 8.2368e-05 lr: 8.2368e-06  eta: 12:10:47  time: 0.5945  data_time: 0.0099  memory: 10656  grad_norm: 274.6044  loss: 20.7801  decode.loss_cls: 0.0786  decode.loss_mask: 0.5501  decode.loss_dice: 1.4286  decode.d0.loss_cls: 0.0999  decode.d0.loss_mask: 0.5669  decode.d0.loss_dice: 1.5091  decode.d1.loss_cls: 0.0881  decode.d1.loss_mask: 0.5581  decode.d1.loss_dice: 1.4472  decode.d2.loss_cls: 0.0838  decode.d2.loss_mask: 0.5410  decode.d2.loss_dice: 1.4416  decode.d3.loss_cls: 0.0782  decode.d3.loss_mask: 0.5285  decode.d3.loss_dice: 1.4178  decode.d4.loss_cls: 0.0865  decode.d4.loss_mask: 0.5296  decode.d4.loss_dice: 1.4599  decode.d5.loss_cls: 0.0856  decode.d5.loss_mask: 0.5337  decode.d5.loss_dice: 1.4730  decode.d6.loss_cls: 0.0845  decode.d6.loss_mask: 0.5343  decode.d6.loss_dice: 1.4060  decode.d7.loss_cls: 0.0757  decode.d7.loss_mask: 0.5528  decode.d7.loss_dice: 1.4687  decode.d8.loss_cls: 0.0798  decode.d8.loss_mask: 0.5407  decode.d8.loss_dice: 1.4518
11/15 09:49:40 - mmengine - INFO - Iter(train) [17500/90000]  base_lr: 8.2317e-05 lr: 8.2317e-06  eta: 12:10:14  time: 0.5932  data_time: 0.0097  memory: 10656  grad_norm: 773.6799  loss: 20.3759  decode.loss_cls: 0.0773  decode.loss_mask: 0.7469  decode.loss_dice: 1.2373  decode.d0.loss_cls: 0.0971  decode.d0.loss_mask: 0.8074  decode.d0.loss_dice: 1.2538  decode.d1.loss_cls: 0.0883  decode.d1.loss_mask: 0.7409  decode.d1.loss_dice: 1.2256  decode.d2.loss_cls: 0.0935  decode.d2.loss_mask: 0.7264  decode.d2.loss_dice: 1.1648  decode.d3.loss_cls: 0.0923  decode.d3.loss_mask: 0.7297  decode.d3.loss_dice: 1.1826  decode.d4.loss_cls: 0.0753  decode.d4.loss_mask: 0.7297  decode.d4.loss_dice: 1.1754  decode.d5.loss_cls: 0.0672  decode.d5.loss_mask: 0.7335  decode.d5.loss_dice: 1.2135  decode.d6.loss_cls: 0.0753  decode.d6.loss_mask: 0.7396  decode.d6.loss_dice: 1.2197  decode.d7.loss_cls: 0.0924  decode.d7.loss_mask: 0.7379  decode.d7.loss_dice: 1.2089  decode.d8.loss_cls: 0.0760  decode.d8.loss_mask: 0.7655  decode.d8.loss_dice: 1.2021
11/15 09:50:10 - mmengine - INFO - Iter(train) [17550/90000]  base_lr: 8.2266e-05 lr: 8.2266e-06  eta: 12:09:42  time: 0.5942  data_time: 0.0097  memory: 10713  grad_norm: 357.8091  loss: 20.6091  decode.loss_cls: 0.0740  decode.loss_mask: 0.6080  decode.loss_dice: 1.3363  decode.d0.loss_cls: 0.0751  decode.d0.loss_mask: 0.6110  decode.d0.loss_dice: 1.4914  decode.d1.loss_cls: 0.0794  decode.d1.loss_mask: 0.6123  decode.d1.loss_dice: 1.4046  decode.d2.loss_cls: 0.0725  decode.d2.loss_mask: 0.5736  decode.d2.loss_dice: 1.3891  decode.d3.loss_cls: 0.0790  decode.d3.loss_mask: 0.5950  decode.d3.loss_dice: 1.3631  decode.d4.loss_cls: 0.0820  decode.d4.loss_mask: 0.5626  decode.d4.loss_dice: 1.3940  decode.d5.loss_cls: 0.0755  decode.d5.loss_mask: 0.6004  decode.d5.loss_dice: 1.3703  decode.d6.loss_cls: 0.0747  decode.d6.loss_mask: 0.5916  decode.d6.loss_dice: 1.3444  decode.d7.loss_cls: 0.0637  decode.d7.loss_mask: 0.6138  decode.d7.loss_dice: 1.3813  decode.d8.loss_cls: 0.0730  decode.d8.loss_mask: 0.6089  decode.d8.loss_dice: 1.4083
11/15 09:50:40 - mmengine - INFO - Iter(train) [17600/90000]  base_lr: 8.2215e-05 lr: 8.2215e-06  eta: 12:09:10  time: 0.5951  data_time: 0.0097  memory: 10692  grad_norm: 301.9148  loss: 21.4954  decode.loss_cls: 0.0836  decode.loss_mask: 0.6278  decode.loss_dice: 1.4476  decode.d0.loss_cls: 0.0784  decode.d0.loss_mask: 0.6144  decode.d0.loss_dice: 1.5216  decode.d1.loss_cls: 0.0958  decode.d1.loss_mask: 0.5989  decode.d1.loss_dice: 1.4241  decode.d2.loss_cls: 0.0987  decode.d2.loss_mask: 0.6011  decode.d2.loss_dice: 1.4294  decode.d3.loss_cls: 0.0925  decode.d3.loss_mask: 0.6038  decode.d3.loss_dice: 1.4353  decode.d4.loss_cls: 0.1039  decode.d4.loss_mask: 0.5985  decode.d4.loss_dice: 1.4050  decode.d5.loss_cls: 0.1022  decode.d5.loss_mask: 0.6287  decode.d5.loss_dice: 1.4358  decode.d6.loss_cls: 0.0913  decode.d6.loss_mask: 0.6177  decode.d6.loss_dice: 1.4236  decode.d7.loss_cls: 0.1064  decode.d7.loss_mask: 0.6164  decode.d7.loss_dice: 1.4411  decode.d8.loss_cls: 0.0939  decode.d8.loss_mask: 0.6153  decode.d8.loss_dice: 1.4626
11/15 09:51:09 - mmengine - INFO - Iter(train) [17650/90000]  base_lr: 8.2164e-05 lr: 8.2164e-06  eta: 12:08:38  time: 0.5940  data_time: 0.0098  memory: 10713  grad_norm: 320.8609  loss: 19.1117  decode.loss_cls: 0.1068  decode.loss_mask: 0.4925  decode.loss_dice: 1.2781  decode.d0.loss_cls: 0.0893  decode.d0.loss_mask: 0.4990  decode.d0.loss_dice: 1.4123  decode.d1.loss_cls: 0.0910  decode.d1.loss_mask: 0.5068  decode.d1.loss_dice: 1.3121  decode.d2.loss_cls: 0.0889  decode.d2.loss_mask: 0.4963  decode.d2.loss_dice: 1.3148  decode.d3.loss_cls: 0.0961  decode.d3.loss_mask: 0.4970  decode.d3.loss_dice: 1.3378  decode.d4.loss_cls: 0.0830  decode.d4.loss_mask: 0.5001  decode.d4.loss_dice: 1.3139  decode.d5.loss_cls: 0.0940  decode.d5.loss_mask: 0.4918  decode.d5.loss_dice: 1.3271  decode.d6.loss_cls: 0.0838  decode.d6.loss_mask: 0.4999  decode.d6.loss_dice: 1.3031  decode.d7.loss_cls: 0.1009  decode.d7.loss_mask: 0.4937  decode.d7.loss_dice: 1.3122  decode.d8.loss_cls: 0.1015  decode.d8.loss_mask: 0.4898  decode.d8.loss_dice: 1.2982
11/15 09:51:39 - mmengine - INFO - Iter(train) [17700/90000]  base_lr: 8.2113e-05 lr: 8.2113e-06  eta: 12:08:05  time: 0.5937  data_time: 0.0098  memory: 10692  grad_norm: 351.2376  loss: 18.0089  decode.loss_cls: 0.0652  decode.loss_mask: 0.5694  decode.loss_dice: 1.1509  decode.d0.loss_cls: 0.0860  decode.d0.loss_mask: 0.6212  decode.d0.loss_dice: 1.1882  decode.d1.loss_cls: 0.0785  decode.d1.loss_mask: 0.5805  decode.d1.loss_dice: 1.1771  decode.d2.loss_cls: 0.0745  decode.d2.loss_mask: 0.5905  decode.d2.loss_dice: 1.1456  decode.d3.loss_cls: 0.0579  decode.d3.loss_mask: 0.5874  decode.d3.loss_dice: 1.1295  decode.d4.loss_cls: 0.0580  decode.d4.loss_mask: 0.5862  decode.d4.loss_dice: 1.1460  decode.d5.loss_cls: 0.0535  decode.d5.loss_mask: 0.5993  decode.d5.loss_dice: 1.1490  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.5778  decode.d6.loss_dice: 1.1377  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.5688  decode.d7.loss_dice: 1.1433  decode.d8.loss_cls: 0.0627  decode.d8.loss_mask: 0.5674  decode.d8.loss_dice: 1.1405
11/15 09:52:09 - mmengine - INFO - Iter(train) [17750/90000]  base_lr: 8.2062e-05 lr: 8.2062e-06  eta: 12:07:33  time: 0.5930  data_time: 0.0097  memory: 10656  grad_norm: 427.3600  loss: 20.9961  decode.loss_cls: 0.0942  decode.loss_mask: 0.6366  decode.loss_dice: 1.3386  decode.d0.loss_cls: 0.1054  decode.d0.loss_mask: 0.6826  decode.d0.loss_dice: 1.3927  decode.d1.loss_cls: 0.0933  decode.d1.loss_mask: 0.6376  decode.d1.loss_dice: 1.3680  decode.d2.loss_cls: 0.1003  decode.d2.loss_mask: 0.6380  decode.d2.loss_dice: 1.3303  decode.d3.loss_cls: 0.0840  decode.d3.loss_mask: 0.6625  decode.d3.loss_dice: 1.3815  decode.d4.loss_cls: 0.0978  decode.d4.loss_mask: 0.6531  decode.d4.loss_dice: 1.3500  decode.d5.loss_cls: 0.0779  decode.d5.loss_mask: 0.6587  decode.d5.loss_dice: 1.3517  decode.d6.loss_cls: 0.0871  decode.d6.loss_mask: 0.6598  decode.d6.loss_dice: 1.3542  decode.d7.loss_cls: 0.0873  decode.d7.loss_mask: 0.6511  decode.d7.loss_dice: 1.3496  decode.d8.loss_cls: 0.0983  decode.d8.loss_mask: 0.6459  decode.d8.loss_dice: 1.3282
11/15 09:52:39 - mmengine - INFO - Iter(train) [17800/90000]  base_lr: 8.2011e-05 lr: 8.2011e-06  eta: 12:07:01  time: 0.5956  data_time: 0.0101  memory: 10728  grad_norm: 435.1813  loss: 19.0058  decode.loss_cls: 0.0957  decode.loss_mask: 0.6454  decode.loss_dice: 1.1664  decode.d0.loss_cls: 0.1047  decode.d0.loss_mask: 0.6840  decode.d0.loss_dice: 1.2080  decode.d1.loss_cls: 0.0742  decode.d1.loss_mask: 0.6711  decode.d1.loss_dice: 1.1904  decode.d2.loss_cls: 0.0832  decode.d2.loss_mask: 0.6622  decode.d2.loss_dice: 1.1072  decode.d3.loss_cls: 0.0872  decode.d3.loss_mask: 0.6420  decode.d3.loss_dice: 1.1293  decode.d4.loss_cls: 0.0918  decode.d4.loss_mask: 0.6476  decode.d4.loss_dice: 1.1699  decode.d5.loss_cls: 0.0873  decode.d5.loss_mask: 0.6580  decode.d5.loss_dice: 1.1399  decode.d6.loss_cls: 0.0824  decode.d6.loss_mask: 0.6465  decode.d6.loss_dice: 1.1457  decode.d7.loss_cls: 0.0941  decode.d7.loss_mask: 0.6409  decode.d7.loss_dice: 1.1456  decode.d8.loss_cls: 0.0884  decode.d8.loss_mask: 0.6439  decode.d8.loss_dice: 1.1727
11/15 09:53:09 - mmengine - INFO - Iter(train) [17850/90000]  base_lr: 8.1959e-05 lr: 8.1959e-06  eta: 12:06:30  time: 0.5965  data_time: 0.0100  memory: 10713  grad_norm: 728.2133  loss: 21.6178  decode.loss_cls: 0.1188  decode.loss_mask: 0.7012  decode.loss_dice: 1.3119  decode.d0.loss_cls: 0.0929  decode.d0.loss_mask: 0.7469  decode.d0.loss_dice: 1.4640  decode.d1.loss_cls: 0.1019  decode.d1.loss_mask: 0.7098  decode.d1.loss_dice: 1.3324  decode.d2.loss_cls: 0.1143  decode.d2.loss_mask: 0.7024  decode.d2.loss_dice: 1.3367  decode.d3.loss_cls: 0.0910  decode.d3.loss_mask: 0.7021  decode.d3.loss_dice: 1.3484  decode.d4.loss_cls: 0.0879  decode.d4.loss_mask: 0.7214  decode.d4.loss_dice: 1.3398  decode.d5.loss_cls: 0.0992  decode.d5.loss_mask: 0.6928  decode.d5.loss_dice: 1.3354  decode.d6.loss_cls: 0.0909  decode.d6.loss_mask: 0.7029  decode.d6.loss_dice: 1.3267  decode.d7.loss_cls: 0.0920  decode.d7.loss_mask: 0.7199  decode.d7.loss_dice: 1.3450  decode.d8.loss_cls: 0.0930  decode.d8.loss_mask: 0.7362  decode.d8.loss_dice: 1.3598
11/15 09:53:39 - mmengine - INFO - Iter(train) [17900/90000]  base_lr: 8.1908e-05 lr: 8.1908e-06  eta: 12:05:58  time: 0.5961  data_time: 0.0098  memory: 10656  grad_norm: 464.3609  loss: 18.3756  decode.loss_cls: 0.1025  decode.loss_mask: 0.4760  decode.loss_dice: 1.2595  decode.d0.loss_cls: 0.1007  decode.d0.loss_mask: 0.4761  decode.d0.loss_dice: 1.3277  decode.d1.loss_cls: 0.0966  decode.d1.loss_mask: 0.4768  decode.d1.loss_dice: 1.2152  decode.d2.loss_cls: 0.1136  decode.d2.loss_mask: 0.4702  decode.d2.loss_dice: 1.2359  decode.d3.loss_cls: 0.0960  decode.d3.loss_mask: 0.4727  decode.d3.loss_dice: 1.2686  decode.d4.loss_cls: 0.0920  decode.d4.loss_mask: 0.4647  decode.d4.loss_dice: 1.2702  decode.d5.loss_cls: 0.1067  decode.d5.loss_mask: 0.4831  decode.d5.loss_dice: 1.2762  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.5086  decode.d6.loss_dice: 1.2374  decode.d7.loss_cls: 0.0995  decode.d7.loss_mask: 0.4838  decode.d7.loss_dice: 1.2721  decode.d8.loss_cls: 0.0951  decode.d8.loss_mask: 0.4717  decode.d8.loss_dice: 1.2290
11/15 09:54:08 - mmengine - INFO - Iter(train) [17950/90000]  base_lr: 8.1857e-05 lr: 8.1857e-06  eta: 12:05:27  time: 0.5965  data_time: 0.0097  memory: 10675  grad_norm: 275.7149  loss: 19.1073  decode.loss_cls: 0.0860  decode.loss_mask: 0.5157  decode.loss_dice: 1.3044  decode.d0.loss_cls: 0.0842  decode.d0.loss_mask: 0.5278  decode.d0.loss_dice: 1.3532  decode.d1.loss_cls: 0.1007  decode.d1.loss_mask: 0.5165  decode.d1.loss_dice: 1.2787  decode.d2.loss_cls: 0.1016  decode.d2.loss_mask: 0.5087  decode.d2.loss_dice: 1.2984  decode.d3.loss_cls: 0.0939  decode.d3.loss_mask: 0.5201  decode.d3.loss_dice: 1.3186  decode.d4.loss_cls: 0.0880  decode.d4.loss_mask: 0.5273  decode.d4.loss_dice: 1.3142  decode.d5.loss_cls: 0.0894  decode.d5.loss_mask: 0.5138  decode.d5.loss_dice: 1.3275  decode.d6.loss_cls: 0.0841  decode.d6.loss_mask: 0.5190  decode.d6.loss_dice: 1.2900  decode.d7.loss_cls: 0.0791  decode.d7.loss_mask: 0.5196  decode.d7.loss_dice: 1.2884  decode.d8.loss_cls: 0.0797  decode.d8.loss_mask: 0.5089  decode.d8.loss_dice: 1.2696
11/15 09:54:38 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 09:54:38 - mmengine - INFO - Iter(train) [18000/90000]  base_lr: 8.1806e-05 lr: 8.1806e-06  eta: 12:04:55  time: 0.5950  data_time: 0.0099  memory: 10656  grad_norm: 1021.9483  loss: 19.7295  decode.loss_cls: 0.0886  decode.loss_mask: 0.6565  decode.loss_dice: 1.2448  decode.d0.loss_cls: 0.1103  decode.d0.loss_mask: 0.6730  decode.d0.loss_dice: 1.2765  decode.d1.loss_cls: 0.0708  decode.d1.loss_mask: 0.6438  decode.d1.loss_dice: 1.2254  decode.d2.loss_cls: 0.0845  decode.d2.loss_mask: 0.6604  decode.d2.loss_dice: 1.2206  decode.d3.loss_cls: 0.0978  decode.d3.loss_mask: 0.6351  decode.d3.loss_dice: 1.2156  decode.d4.loss_cls: 0.0996  decode.d4.loss_mask: 0.6660  decode.d4.loss_dice: 1.1958  decode.d5.loss_cls: 0.0933  decode.d5.loss_mask: 0.6600  decode.d5.loss_dice: 1.1916  decode.d6.loss_cls: 0.0940  decode.d6.loss_mask: 0.6526  decode.d6.loss_dice: 1.2305  decode.d7.loss_cls: 0.0898  decode.d7.loss_mask: 0.6451  decode.d7.loss_dice: 1.2365  decode.d8.loss_cls: 0.0893  decode.d8.loss_mask: 0.6465  decode.d8.loss_dice: 1.2353
11/15 09:55:08 - mmengine - INFO - Iter(train) [18050/90000]  base_lr: 8.1755e-05 lr: 8.1755e-06  eta: 12:04:25  time: 0.6058  data_time: 0.0106  memory: 10692  grad_norm: 569.2608  loss: 19.0961  decode.loss_cls: 0.0559  decode.loss_mask: 0.5860  decode.loss_dice: 1.2462  decode.d0.loss_cls: 0.0701  decode.d0.loss_mask: 0.6487  decode.d0.loss_dice: 1.3174  decode.d1.loss_cls: 0.0532  decode.d1.loss_mask: 0.5512  decode.d1.loss_dice: 1.2698  decode.d2.loss_cls: 0.0714  decode.d2.loss_mask: 0.5710  decode.d2.loss_dice: 1.2543  decode.d3.loss_cls: 0.0533  decode.d3.loss_mask: 0.5903  decode.d3.loss_dice: 1.2270  decode.d4.loss_cls: 0.0580  decode.d4.loss_mask: 0.5956  decode.d4.loss_dice: 1.2506  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.5955  decode.d5.loss_dice: 1.2322  decode.d6.loss_cls: 0.0588  decode.d6.loss_mask: 0.5838  decode.d6.loss_dice: 1.2369  decode.d7.loss_cls: 0.0617  decode.d7.loss_mask: 0.6238  decode.d7.loss_dice: 1.2592  decode.d8.loss_cls: 0.0552  decode.d8.loss_mask: 0.5984  decode.d8.loss_dice: 1.2567
11/15 09:55:39 - mmengine - INFO - Iter(train) [18100/90000]  base_lr: 8.1704e-05 lr: 8.1704e-06  eta: 12:03:55  time: 0.6057  data_time: 0.0105  memory: 10675  grad_norm: 436.9369  loss: 19.5058  decode.loss_cls: 0.0613  decode.loss_mask: 0.6741  decode.loss_dice: 1.1963  decode.d0.loss_cls: 0.0950  decode.d0.loss_mask: 0.6910  decode.d0.loss_dice: 1.2873  decode.d1.loss_cls: 0.0585  decode.d1.loss_mask: 0.6844  decode.d1.loss_dice: 1.2507  decode.d2.loss_cls: 0.0590  decode.d2.loss_mask: 0.6850  decode.d2.loss_dice: 1.2020  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.6618  decode.d3.loss_dice: 1.1824  decode.d4.loss_cls: 0.0557  decode.d4.loss_mask: 0.6724  decode.d4.loss_dice: 1.1905  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.6761  decode.d5.loss_dice: 1.1932  decode.d6.loss_cls: 0.0623  decode.d6.loss_mask: 0.7077  decode.d6.loss_dice: 1.1813  decode.d7.loss_cls: 0.0608  decode.d7.loss_mask: 0.6907  decode.d7.loss_dice: 1.1857  decode.d8.loss_cls: 0.0561  decode.d8.loss_mask: 0.6669  decode.d8.loss_dice: 1.1974
11/15 09:56:09 - mmengine - INFO - Iter(train) [18150/90000]  base_lr: 8.1653e-05 lr: 8.1653e-06  eta: 12:03:24  time: 0.6018  data_time: 0.0102  memory: 10675  grad_norm: 445.4997  loss: 20.3476  decode.loss_cls: 0.0563  decode.loss_mask: 0.6716  decode.loss_dice: 1.2705  decode.d0.loss_cls: 0.0657  decode.d0.loss_mask: 0.7254  decode.d0.loss_dice: 1.3729  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.6838  decode.d1.loss_dice: 1.2841  decode.d2.loss_cls: 0.0655  decode.d2.loss_mask: 0.6760  decode.d2.loss_dice: 1.2844  decode.d3.loss_cls: 0.0557  decode.d3.loss_mask: 0.6675  decode.d3.loss_dice: 1.2951  decode.d4.loss_cls: 0.0515  decode.d4.loss_mask: 0.6752  decode.d4.loss_dice: 1.3195  decode.d5.loss_cls: 0.0604  decode.d5.loss_mask: 0.6777  decode.d5.loss_dice: 1.3090  decode.d6.loss_cls: 0.0644  decode.d6.loss_mask: 0.6749  decode.d6.loss_dice: 1.2777  decode.d7.loss_cls: 0.0540  decode.d7.loss_mask: 0.6677  decode.d7.loss_dice: 1.2819  decode.d8.loss_cls: 0.0503  decode.d8.loss_mask: 0.6633  decode.d8.loss_dice: 1.2822
11/15 09:56:39 - mmengine - INFO - Iter(train) [18200/90000]  base_lr: 8.1601e-05 lr: 8.1601e-06  eta: 12:02:54  time: 0.6020  data_time: 0.0099  memory: 10692  grad_norm: 308.2936  loss: 20.9335  decode.loss_cls: 0.0886  decode.loss_mask: 0.6008  decode.loss_dice: 1.3712  decode.d0.loss_cls: 0.1189  decode.d0.loss_mask: 0.6325  decode.d0.loss_dice: 1.4456  decode.d1.loss_cls: 0.1104  decode.d1.loss_mask: 0.6114  decode.d1.loss_dice: 1.4255  decode.d2.loss_cls: 0.1014  decode.d2.loss_mask: 0.6056  decode.d2.loss_dice: 1.3973  decode.d3.loss_cls: 0.0890  decode.d3.loss_mask: 0.5973  decode.d3.loss_dice: 1.3913  decode.d4.loss_cls: 0.0995  decode.d4.loss_mask: 0.6056  decode.d4.loss_dice: 1.3535  decode.d5.loss_cls: 0.0978  decode.d5.loss_mask: 0.6100  decode.d5.loss_dice: 1.3712  decode.d6.loss_cls: 0.0876  decode.d6.loss_mask: 0.6018  decode.d6.loss_dice: 1.3957  decode.d7.loss_cls: 0.0840  decode.d7.loss_mask: 0.5872  decode.d7.loss_dice: 1.3719  decode.d8.loss_cls: 0.0946  decode.d8.loss_mask: 0.6040  decode.d8.loss_dice: 1.3822
11/15 09:57:09 - mmengine - INFO - Iter(train) [18250/90000]  base_lr: 8.1550e-05 lr: 8.1550e-06  eta: 12:02:23  time: 0.5987  data_time: 0.0099  memory: 10675  grad_norm: 341.0418  loss: 19.8270  decode.loss_cls: 0.0882  decode.loss_mask: 0.5891  decode.loss_dice: 1.2611  decode.d0.loss_cls: 0.0822  decode.d0.loss_mask: 0.6273  decode.d0.loss_dice: 1.3254  decode.d1.loss_cls: 0.0695  decode.d1.loss_mask: 0.6195  decode.d1.loss_dice: 1.3216  decode.d2.loss_cls: 0.0817  decode.d2.loss_mask: 0.6053  decode.d2.loss_dice: 1.2944  decode.d3.loss_cls: 0.0763  decode.d3.loss_mask: 0.6081  decode.d3.loss_dice: 1.2924  decode.d4.loss_cls: 0.0770  decode.d4.loss_mask: 0.6285  decode.d4.loss_dice: 1.3064  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.6116  decode.d5.loss_dice: 1.2625  decode.d6.loss_cls: 0.0752  decode.d6.loss_mask: 0.6327  decode.d6.loss_dice: 1.2780  decode.d7.loss_cls: 0.0820  decode.d7.loss_mask: 0.5962  decode.d7.loss_dice: 1.2942  decode.d8.loss_cls: 0.0800  decode.d8.loss_mask: 0.6105  decode.d8.loss_dice: 1.2640
11/15 09:57:39 - mmengine - INFO - Iter(train) [18300/90000]  base_lr: 8.1499e-05 lr: 8.1499e-06  eta: 12:01:51  time: 0.5969  data_time: 0.0100  memory: 10713  grad_norm: 423.2678  loss: 20.8004  decode.loss_cls: 0.0696  decode.loss_mask: 0.6379  decode.loss_dice: 1.3885  decode.d0.loss_cls: 0.0720  decode.d0.loss_mask: 0.6370  decode.d0.loss_dice: 1.4424  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.6337  decode.d1.loss_dice: 1.3952  decode.d2.loss_cls: 0.0586  decode.d2.loss_mask: 0.6197  decode.d2.loss_dice: 1.3646  decode.d3.loss_cls: 0.0551  decode.d3.loss_mask: 0.6212  decode.d3.loss_dice: 1.3914  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.6321  decode.d4.loss_dice: 1.3936  decode.d5.loss_cls: 0.0763  decode.d5.loss_mask: 0.6259  decode.d5.loss_dice: 1.3556  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.6293  decode.d6.loss_dice: 1.3686  decode.d7.loss_cls: 0.0772  decode.d7.loss_mask: 0.6310  decode.d7.loss_dice: 1.3696  decode.d8.loss_cls: 0.0720  decode.d8.loss_mask: 0.6230  decode.d8.loss_dice: 1.3721
11/15 09:58:09 - mmengine - INFO - Iter(train) [18350/90000]  base_lr: 8.1448e-05 lr: 8.1448e-06  eta: 12:01:20  time: 0.6004  data_time: 0.0101  memory: 10692  grad_norm: 511.8549  loss: 22.9046  decode.loss_cls: 0.1539  decode.loss_mask: 0.6715  decode.loss_dice: 1.4379  decode.d0.loss_cls: 0.1379  decode.d0.loss_mask: 0.7217  decode.d0.loss_dice: 1.5281  decode.d1.loss_cls: 0.1634  decode.d1.loss_mask: 0.6825  decode.d1.loss_dice: 1.4392  decode.d2.loss_cls: 0.1601  decode.d2.loss_mask: 0.7298  decode.d2.loss_dice: 1.3952  decode.d3.loss_cls: 0.1591  decode.d3.loss_mask: 0.6924  decode.d3.loss_dice: 1.3972  decode.d4.loss_cls: 0.1425  decode.d4.loss_mask: 0.7481  decode.d4.loss_dice: 1.4618  decode.d5.loss_cls: 0.1487  decode.d5.loss_mask: 0.7076  decode.d5.loss_dice: 1.4327  decode.d6.loss_cls: 0.1685  decode.d6.loss_mask: 0.6612  decode.d6.loss_dice: 1.4208  decode.d7.loss_cls: 0.1517  decode.d7.loss_mask: 0.6688  decode.d7.loss_dice: 1.4175  decode.d8.loss_cls: 0.1477  decode.d8.loss_mask: 0.6978  decode.d8.loss_dice: 1.4594
11/15 09:58:39 - mmengine - INFO - Iter(train) [18400/90000]  base_lr: 8.1397e-05 lr: 8.1397e-06  eta: 12:00:49  time: 0.5979  data_time: 0.0102  memory: 10641  grad_norm: 474.1246  loss: 18.9783  decode.loss_cls: 0.0712  decode.loss_mask: 0.6323  decode.loss_dice: 1.2051  decode.d0.loss_cls: 0.0963  decode.d0.loss_mask: 0.6271  decode.d0.loss_dice: 1.2563  decode.d1.loss_cls: 0.0766  decode.d1.loss_mask: 0.6058  decode.d1.loss_dice: 1.2066  decode.d2.loss_cls: 0.0782  decode.d2.loss_mask: 0.5876  decode.d2.loss_dice: 1.1664  decode.d3.loss_cls: 0.0669  decode.d3.loss_mask: 0.6101  decode.d3.loss_dice: 1.2106  decode.d4.loss_cls: 0.0892  decode.d4.loss_mask: 0.6000  decode.d4.loss_dice: 1.1795  decode.d5.loss_cls: 0.0693  decode.d5.loss_mask: 0.6299  decode.d5.loss_dice: 1.2055  decode.d6.loss_cls: 0.0787  decode.d6.loss_mask: 0.6158  decode.d6.loss_dice: 1.1685  decode.d7.loss_cls: 0.0707  decode.d7.loss_mask: 0.6453  decode.d7.loss_dice: 1.1955  decode.d8.loss_cls: 0.0538  decode.d8.loss_mask: 0.6488  decode.d8.loss_dice: 1.2306
11/15 09:59:09 - mmengine - INFO - Iter(train) [18450/90000]  base_lr: 8.1346e-05 lr: 8.1346e-06  eta: 12:00:18  time: 0.5969  data_time: 0.0102  memory: 10692  grad_norm: 813.0242  loss: 20.8132  decode.loss_cls: 0.0642  decode.loss_mask: 0.6815  decode.loss_dice: 1.3494  decode.d0.loss_cls: 0.0968  decode.d0.loss_mask: 0.6806  decode.d0.loss_dice: 1.4104  decode.d1.loss_cls: 0.0685  decode.d1.loss_mask: 0.6995  decode.d1.loss_dice: 1.4030  decode.d2.loss_cls: 0.0826  decode.d2.loss_mask: 0.7096  decode.d2.loss_dice: 1.2909  decode.d3.loss_cls: 0.0718  decode.d3.loss_mask: 0.6455  decode.d3.loss_dice: 1.3108  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 0.6618  decode.d4.loss_dice: 1.3456  decode.d5.loss_cls: 0.0677  decode.d5.loss_mask: 0.6894  decode.d5.loss_dice: 1.3322  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.6483  decode.d6.loss_dice: 1.2705  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.6728  decode.d7.loss_dice: 1.3065  decode.d8.loss_cls: 0.0724  decode.d8.loss_mask: 0.6606  decode.d8.loss_dice: 1.3150
11/15 09:59:39 - mmengine - INFO - Iter(train) [18500/90000]  base_lr: 8.1295e-05 lr: 8.1295e-06  eta: 11:59:47  time: 0.5998  data_time: 0.0099  memory: 10692  grad_norm: 641.4556  loss: 22.4247  decode.loss_cls: 0.0902  decode.loss_mask: 0.6700  decode.loss_dice: 1.4876  decode.d0.loss_cls: 0.0943  decode.d0.loss_mask: 0.7256  decode.d0.loss_dice: 1.4951  decode.d1.loss_cls: 0.0706  decode.d1.loss_mask: 0.6855  decode.d1.loss_dice: 1.4932  decode.d2.loss_cls: 0.0961  decode.d2.loss_mask: 0.6678  decode.d2.loss_dice: 1.4589  decode.d3.loss_cls: 0.0945  decode.d3.loss_mask: 0.6747  decode.d3.loss_dice: 1.4236  decode.d4.loss_cls: 0.0883  decode.d4.loss_mask: 0.6847  decode.d4.loss_dice: 1.4591  decode.d5.loss_cls: 0.0945  decode.d5.loss_mask: 0.6880  decode.d5.loss_dice: 1.4836  decode.d6.loss_cls: 0.0873  decode.d6.loss_mask: 0.6874  decode.d6.loss_dice: 1.4397  decode.d7.loss_cls: 0.0846  decode.d7.loss_mask: 0.6883  decode.d7.loss_dice: 1.4674  decode.d8.loss_cls: 0.0834  decode.d8.loss_mask: 0.6953  decode.d8.loss_dice: 1.4653
11/15 10:00:12 - mmengine - INFO - Iter(train) [18550/90000]  base_lr: 8.1243e-05 lr: 8.1243e-06  eta: 11:59:30  time: 0.9524  data_time: 0.0227  memory: 10656  grad_norm: 433.3519  loss: 21.0537  decode.loss_cls: 0.0490  decode.loss_mask: 0.6836  decode.loss_dice: 1.3661  decode.d0.loss_cls: 0.0586  decode.d0.loss_mask: 0.7145  decode.d0.loss_dice: 1.4109  decode.d1.loss_cls: 0.0606  decode.d1.loss_mask: 0.6754  decode.d1.loss_dice: 1.3825  decode.d2.loss_cls: 0.0525  decode.d2.loss_mask: 0.6694  decode.d2.loss_dice: 1.3530  decode.d3.loss_cls: 0.0424  decode.d3.loss_mask: 0.6917  decode.d3.loss_dice: 1.3390  decode.d4.loss_cls: 0.0423  decode.d4.loss_mask: 0.6821  decode.d4.loss_dice: 1.3764  decode.d5.loss_cls: 0.0439  decode.d5.loss_mask: 0.6846  decode.d5.loss_dice: 1.3620  decode.d6.loss_cls: 0.0354  decode.d6.loss_mask: 0.6881  decode.d6.loss_dice: 1.3710  decode.d7.loss_cls: 0.0497  decode.d7.loss_mask: 0.6810  decode.d7.loss_dice: 1.3785  decode.d8.loss_cls: 0.0540  decode.d8.loss_mask: 0.6807  decode.d8.loss_dice: 1.3746
11/15 10:00:43 - mmengine - INFO - Iter(train) [18600/90000]  base_lr: 8.1192e-05 lr: 8.1192e-06  eta: 11:59:00  time: 0.5987  data_time: 0.0102  memory: 10675  grad_norm: 509.9686  loss: 19.4854  decode.loss_cls: 0.0692  decode.loss_mask: 0.5496  decode.loss_dice: 1.3225  decode.d0.loss_cls: 0.0908  decode.d0.loss_mask: 0.5883  decode.d0.loss_dice: 1.4218  decode.d1.loss_cls: 0.0949  decode.d1.loss_mask: 0.5569  decode.d1.loss_dice: 1.3345  decode.d2.loss_cls: 0.0947  decode.d2.loss_mask: 0.5310  decode.d2.loss_dice: 1.2561  decode.d3.loss_cls: 0.0999  decode.d3.loss_mask: 0.5324  decode.d3.loss_dice: 1.2737  decode.d4.loss_cls: 0.0868  decode.d4.loss_mask: 0.5506  decode.d4.loss_dice: 1.2948  decode.d5.loss_cls: 0.0943  decode.d5.loss_mask: 0.5577  decode.d5.loss_dice: 1.2724  decode.d6.loss_cls: 0.0976  decode.d6.loss_mask: 0.5709  decode.d6.loss_dice: 1.2668  decode.d7.loss_cls: 0.0875  decode.d7.loss_mask: 0.5675  decode.d7.loss_dice: 1.2922  decode.d8.loss_cls: 0.0933  decode.d8.loss_mask: 0.5561  decode.d8.loss_dice: 1.2806
11/15 10:01:13 - mmengine - INFO - Iter(train) [18650/90000]  base_lr: 8.1141e-05 lr: 8.1141e-06  eta: 11:58:29  time: 0.5976  data_time: 0.0102  memory: 10641  grad_norm: 356.3990  loss: 17.8512  decode.loss_cls: 0.0493  decode.loss_mask: 0.5443  decode.loss_dice: 1.1755  decode.d0.loss_cls: 0.0730  decode.d0.loss_mask: 0.5498  decode.d0.loss_dice: 1.2466  decode.d1.loss_cls: 0.0603  decode.d1.loss_mask: 0.5503  decode.d1.loss_dice: 1.1758  decode.d2.loss_cls: 0.0582  decode.d2.loss_mask: 0.5474  decode.d2.loss_dice: 1.1639  decode.d3.loss_cls: 0.0539  decode.d3.loss_mask: 0.5621  decode.d3.loss_dice: 1.1898  decode.d4.loss_cls: 0.0686  decode.d4.loss_mask: 0.5403  decode.d4.loss_dice: 1.1574  decode.d5.loss_cls: 0.0548  decode.d5.loss_mask: 0.5457  decode.d5.loss_dice: 1.1765  decode.d6.loss_cls: 0.0565  decode.d6.loss_mask: 0.5542  decode.d6.loss_dice: 1.1658  decode.d7.loss_cls: 0.0528  decode.d7.loss_mask: 0.5457  decode.d7.loss_dice: 1.1508  decode.d8.loss_cls: 0.0558  decode.d8.loss_mask: 0.5520  decode.d8.loss_dice: 1.1742
11/15 10:01:43 - mmengine - INFO - Iter(train) [18700/90000]  base_lr: 8.1090e-05 lr: 8.1090e-06  eta: 11:57:58  time: 0.6002  data_time: 0.0101  memory: 10656  grad_norm: 306.9556  loss: 19.3079  decode.loss_cls: 0.0812  decode.loss_mask: 0.5983  decode.loss_dice: 1.2787  decode.d0.loss_cls: 0.0828  decode.d0.loss_mask: 0.6167  decode.d0.loss_dice: 1.2925  decode.d1.loss_cls: 0.0739  decode.d1.loss_mask: 0.6096  decode.d1.loss_dice: 1.2609  decode.d2.loss_cls: 0.0807  decode.d2.loss_mask: 0.5918  decode.d2.loss_dice: 1.2463  decode.d3.loss_cls: 0.0690  decode.d3.loss_mask: 0.5999  decode.d3.loss_dice: 1.2472  decode.d4.loss_cls: 0.0668  decode.d4.loss_mask: 0.5947  decode.d4.loss_dice: 1.2384  decode.d5.loss_cls: 0.0754  decode.d5.loss_mask: 0.5996  decode.d5.loss_dice: 1.2367  decode.d6.loss_cls: 0.0735  decode.d6.loss_mask: 0.6115  decode.d6.loss_dice: 1.2426  decode.d7.loss_cls: 0.0750  decode.d7.loss_mask: 0.6018  decode.d7.loss_dice: 1.2559  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.5875  decode.d8.loss_dice: 1.2481
11/15 10:02:13 - mmengine - INFO - Iter(train) [18750/90000]  base_lr: 8.1039e-05 lr: 8.1039e-06  eta: 11:57:27  time: 0.6016  data_time: 0.0102  memory: 10793  grad_norm: 233.1247  loss: 17.9137  decode.loss_cls: 0.0750  decode.loss_mask: 0.4992  decode.loss_dice: 1.1703  decode.d0.loss_cls: 0.0667  decode.d0.loss_mask: 0.5002  decode.d0.loss_dice: 1.2891  decode.d1.loss_cls: 0.0564  decode.d1.loss_mask: 0.5087  decode.d1.loss_dice: 1.2309  decode.d2.loss_cls: 0.0685  decode.d2.loss_mask: 0.5076  decode.d2.loss_dice: 1.2130  decode.d3.loss_cls: 0.0758  decode.d3.loss_mask: 0.5168  decode.d3.loss_dice: 1.1830  decode.d4.loss_cls: 0.0744  decode.d4.loss_mask: 0.5033  decode.d4.loss_dice: 1.2001  decode.d5.loss_cls: 0.0908  decode.d5.loss_mask: 0.5058  decode.d5.loss_dice: 1.1848  decode.d6.loss_cls: 0.0764  decode.d6.loss_mask: 0.5163  decode.d6.loss_dice: 1.2010  decode.d7.loss_cls: 0.0811  decode.d7.loss_mask: 0.5129  decode.d7.loss_dice: 1.2025  decode.d8.loss_cls: 0.0675  decode.d8.loss_mask: 0.5135  decode.d8.loss_dice: 1.2218
11/15 10:02:43 - mmengine - INFO - Iter(train) [18800/90000]  base_lr: 8.0988e-05 lr: 8.0988e-06  eta: 11:56:56  time: 0.5982  data_time: 0.0100  memory: 10641  grad_norm: 442.3728  loss: 21.0440  decode.loss_cls: 0.0809  decode.loss_mask: 0.7344  decode.loss_dice: 1.2564  decode.d0.loss_cls: 0.1246  decode.d0.loss_mask: 0.8016  decode.d0.loss_dice: 1.3077  decode.d1.loss_cls: 0.0988  decode.d1.loss_mask: 0.7630  decode.d1.loss_dice: 1.2697  decode.d2.loss_cls: 0.1121  decode.d2.loss_mask: 0.7224  decode.d2.loss_dice: 1.2484  decode.d3.loss_cls: 0.1097  decode.d3.loss_mask: 0.7286  decode.d3.loss_dice: 1.2696  decode.d4.loss_cls: 0.0983  decode.d4.loss_mask: 0.7274  decode.d4.loss_dice: 1.2835  decode.d5.loss_cls: 0.1070  decode.d5.loss_mask: 0.7191  decode.d5.loss_dice: 1.2513  decode.d6.loss_cls: 0.0992  decode.d6.loss_mask: 0.7386  decode.d6.loss_dice: 1.2604  decode.d7.loss_cls: 0.1076  decode.d7.loss_mask: 0.7254  decode.d7.loss_dice: 1.2380  decode.d8.loss_cls: 0.0909  decode.d8.loss_mask: 0.7299  decode.d8.loss_dice: 1.2393
11/15 10:03:13 - mmengine - INFO - Iter(train) [18850/90000]  base_lr: 8.0936e-05 lr: 8.0936e-06  eta: 11:56:25  time: 0.5966  data_time: 0.0099  memory: 10713  grad_norm: 418.4041  loss: 19.2465  decode.loss_cls: 0.0629  decode.loss_mask: 0.6104  decode.loss_dice: 1.2634  decode.d0.loss_cls: 0.1003  decode.d0.loss_mask: 0.5930  decode.d0.loss_dice: 1.3092  decode.d1.loss_cls: 0.0742  decode.d1.loss_mask: 0.5903  decode.d1.loss_dice: 1.2765  decode.d2.loss_cls: 0.0675  decode.d2.loss_mask: 0.5932  decode.d2.loss_dice: 1.2388  decode.d3.loss_cls: 0.0709  decode.d3.loss_mask: 0.5965  decode.d3.loss_dice: 1.2375  decode.d4.loss_cls: 0.0641  decode.d4.loss_mask: 0.5999  decode.d4.loss_dice: 1.2577  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.6004  decode.d5.loss_dice: 1.2542  decode.d6.loss_cls: 0.0605  decode.d6.loss_mask: 0.6103  decode.d6.loss_dice: 1.2447  decode.d7.loss_cls: 0.0687  decode.d7.loss_mask: 0.5987  decode.d7.loss_dice: 1.2281  decode.d8.loss_cls: 0.0722  decode.d8.loss_mask: 0.6062  decode.d8.loss_dice: 1.2323
11/15 10:03:43 - mmengine - INFO - Iter(train) [18900/90000]  base_lr: 8.0885e-05 lr: 8.0885e-06  eta: 11:55:54  time: 0.5993  data_time: 0.0102  memory: 10692  grad_norm: 1443.2367  loss: 20.0703  decode.loss_cls: 0.0729  decode.loss_mask: 0.6432  decode.loss_dice: 1.3234  decode.d0.loss_cls: 0.1082  decode.d0.loss_mask: 0.6452  decode.d0.loss_dice: 1.3349  decode.d1.loss_cls: 0.0737  decode.d1.loss_mask: 0.6407  decode.d1.loss_dice: 1.3525  decode.d2.loss_cls: 0.0719  decode.d2.loss_mask: 0.6282  decode.d2.loss_dice: 1.2980  decode.d3.loss_cls: 0.0656  decode.d3.loss_mask: 0.6258  decode.d3.loss_dice: 1.2752  decode.d4.loss_cls: 0.0841  decode.d4.loss_mask: 0.6211  decode.d4.loss_dice: 1.3016  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.6233  decode.d5.loss_dice: 1.2548  decode.d6.loss_cls: 0.0681  decode.d6.loss_mask: 0.6251  decode.d6.loss_dice: 1.3000  decode.d7.loss_cls: 0.0705  decode.d7.loss_mask: 0.6257  decode.d7.loss_dice: 1.2763  decode.d8.loss_cls: 0.0802  decode.d8.loss_mask: 0.6234  decode.d8.loss_dice: 1.2840
11/15 10:04:13 - mmengine - INFO - Iter(train) [18950/90000]  base_lr: 8.0834e-05 lr: 8.0834e-06  eta: 11:55:23  time: 0.6000  data_time: 0.0100  memory: 10656  grad_norm: 814.8261  loss: 19.2023  decode.loss_cls: 0.0717  decode.loss_mask: 0.6211  decode.loss_dice: 1.2227  decode.d0.loss_cls: 0.0743  decode.d0.loss_mask: 0.6482  decode.d0.loss_dice: 1.2601  decode.d1.loss_cls: 0.0826  decode.d1.loss_mask: 0.6198  decode.d1.loss_dice: 1.2196  decode.d2.loss_cls: 0.0699  decode.d2.loss_mask: 0.6415  decode.d2.loss_dice: 1.2095  decode.d3.loss_cls: 0.0777  decode.d3.loss_mask: 0.6327  decode.d3.loss_dice: 1.2314  decode.d4.loss_cls: 0.0775  decode.d4.loss_mask: 0.6255  decode.d4.loss_dice: 1.2034  decode.d5.loss_cls: 0.0736  decode.d5.loss_mask: 0.6306  decode.d5.loss_dice: 1.1965  decode.d6.loss_cls: 0.0744  decode.d6.loss_mask: 0.6256  decode.d6.loss_dice: 1.2032  decode.d7.loss_cls: 0.0708  decode.d7.loss_mask: 0.6246  decode.d7.loss_dice: 1.2168  decode.d8.loss_cls: 0.0674  decode.d8.loss_mask: 0.6264  decode.d8.loss_dice: 1.2034
11/15 10:04:43 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 10:04:43 - mmengine - INFO - Iter(train) [19000/90000]  base_lr: 8.0783e-05 lr: 8.0783e-06  eta: 11:54:52  time: 0.6004  data_time: 0.0103  memory: 10692  grad_norm: 319.2820  loss: 20.6252  decode.loss_cls: 0.0870  decode.loss_mask: 0.6381  decode.loss_dice: 1.3168  decode.d0.loss_cls: 0.0890  decode.d0.loss_mask: 0.6724  decode.d0.loss_dice: 1.4625  decode.d1.loss_cls: 0.1144  decode.d1.loss_mask: 0.6334  decode.d1.loss_dice: 1.3508  decode.d2.loss_cls: 0.1088  decode.d2.loss_mask: 0.6322  decode.d2.loss_dice: 1.3409  decode.d3.loss_cls: 0.1090  decode.d3.loss_mask: 0.6166  decode.d3.loss_dice: 1.2851  decode.d4.loss_cls: 0.1052  decode.d4.loss_mask: 0.6340  decode.d4.loss_dice: 1.2917  decode.d5.loss_cls: 0.1020  decode.d5.loss_mask: 0.6173  decode.d5.loss_dice: 1.3023  decode.d6.loss_cls: 0.1178  decode.d6.loss_mask: 0.6190  decode.d6.loss_dice: 1.2696  decode.d7.loss_cls: 0.1019  decode.d7.loss_mask: 0.6414  decode.d7.loss_dice: 1.3002  decode.d8.loss_cls: 0.1152  decode.d8.loss_mask: 0.6231  decode.d8.loss_dice: 1.3275
11/15 10:05:13 - mmengine - INFO - Iter(train) [19050/90000]  base_lr: 8.0732e-05 lr: 8.0732e-06  eta: 11:54:21  time: 0.6045  data_time: 0.0108  memory: 10692  grad_norm: 370.0629  loss: 20.5943  decode.loss_cls: 0.0911  decode.loss_mask: 0.6226  decode.loss_dice: 1.3474  decode.d0.loss_cls: 0.0849  decode.d0.loss_mask: 0.6582  decode.d0.loss_dice: 1.3869  decode.d1.loss_cls: 0.0782  decode.d1.loss_mask: 0.6229  decode.d1.loss_dice: 1.4001  decode.d2.loss_cls: 0.0715  decode.d2.loss_mask: 0.6232  decode.d2.loss_dice: 1.3444  decode.d3.loss_cls: 0.0736  decode.d3.loss_mask: 0.6095  decode.d3.loss_dice: 1.3733  decode.d4.loss_cls: 0.0730  decode.d4.loss_mask: 0.6244  decode.d4.loss_dice: 1.3500  decode.d5.loss_cls: 0.0694  decode.d5.loss_mask: 0.6163  decode.d5.loss_dice: 1.3630  decode.d6.loss_cls: 0.0797  decode.d6.loss_mask: 0.6115  decode.d6.loss_dice: 1.3394  decode.d7.loss_cls: 0.0743  decode.d7.loss_mask: 0.6306  decode.d7.loss_dice: 1.3427  decode.d8.loss_cls: 0.0731  decode.d8.loss_mask: 0.6200  decode.d8.loss_dice: 1.3393
11/15 10:05:43 - mmengine - INFO - Iter(train) [19100/90000]  base_lr: 8.0680e-05 lr: 8.0680e-06  eta: 11:53:52  time: 0.5978  data_time: 0.0100  memory: 10713  grad_norm: 913.4652  loss: 20.8377  decode.loss_cls: 0.0778  decode.loss_mask: 0.7963  decode.loss_dice: 1.2135  decode.d0.loss_cls: 0.0971  decode.d0.loss_mask: 0.7638  decode.d0.loss_dice: 1.2978  decode.d1.loss_cls: 0.0955  decode.d1.loss_mask: 0.7673  decode.d1.loss_dice: 1.2265  decode.d2.loss_cls: 0.0695  decode.d2.loss_mask: 0.7669  decode.d2.loss_dice: 1.2525  decode.d3.loss_cls: 0.0932  decode.d3.loss_mask: 0.7423  decode.d3.loss_dice: 1.2083  decode.d4.loss_cls: 0.0818  decode.d4.loss_mask: 0.7786  decode.d4.loss_dice: 1.1986  decode.d5.loss_cls: 0.0858  decode.d5.loss_mask: 0.7593  decode.d5.loss_dice: 1.2360  decode.d6.loss_cls: 0.0766  decode.d6.loss_mask: 0.7788  decode.d6.loss_dice: 1.2049  decode.d7.loss_cls: 0.0949  decode.d7.loss_mask: 0.7710  decode.d7.loss_dice: 1.2204  decode.d8.loss_cls: 0.0977  decode.d8.loss_mask: 0.7940  decode.d8.loss_dice: 1.1909
11/15 10:06:13 - mmengine - INFO - Iter(train) [19150/90000]  base_lr: 8.0629e-05 lr: 8.0629e-06  eta: 11:53:21  time: 0.6004  data_time: 0.0101  memory: 10675  grad_norm: 375.2695  loss: 18.8562  decode.loss_cls: 0.0803  decode.loss_mask: 0.5159  decode.loss_dice: 1.2445  decode.d0.loss_cls: 0.0826  decode.d0.loss_mask: 0.5395  decode.d0.loss_dice: 1.3749  decode.d1.loss_cls: 0.0802  decode.d1.loss_mask: 0.5078  decode.d1.loss_dice: 1.2766  decode.d2.loss_cls: 0.0920  decode.d2.loss_mask: 0.5037  decode.d2.loss_dice: 1.2699  decode.d3.loss_cls: 0.0889  decode.d3.loss_mask: 0.5073  decode.d3.loss_dice: 1.2697  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.5239  decode.d4.loss_dice: 1.2627  decode.d5.loss_cls: 0.0766  decode.d5.loss_mask: 0.5412  decode.d5.loss_dice: 1.2810  decode.d6.loss_cls: 0.0639  decode.d6.loss_mask: 0.5451  decode.d6.loss_dice: 1.2859  decode.d7.loss_cls: 0.0876  decode.d7.loss_mask: 0.5494  decode.d7.loss_dice: 1.2612  decode.d8.loss_cls: 0.0728  decode.d8.loss_mask: 0.5211  decode.d8.loss_dice: 1.2766
11/15 10:06:43 - mmengine - INFO - Iter(train) [19200/90000]  base_lr: 8.0578e-05 lr: 8.0578e-06  eta: 11:52:50  time: 0.5967  data_time: 0.0102  memory: 10692  grad_norm: 759.5104  loss: 20.4692  decode.loss_cls: 0.0792  decode.loss_mask: 0.7017  decode.loss_dice: 1.2659  decode.d0.loss_cls: 0.1050  decode.d0.loss_mask: 0.7169  decode.d0.loss_dice: 1.2867  decode.d1.loss_cls: 0.0985  decode.d1.loss_mask: 0.7134  decode.d1.loss_dice: 1.2492  decode.d2.loss_cls: 0.0886  decode.d2.loss_mask: 0.7163  decode.d2.loss_dice: 1.2446  decode.d3.loss_cls: 0.0960  decode.d3.loss_mask: 0.7063  decode.d3.loss_dice: 1.2070  decode.d4.loss_cls: 0.0924  decode.d4.loss_mask: 0.7117  decode.d4.loss_dice: 1.2348  decode.d5.loss_cls: 0.0957  decode.d5.loss_mask: 0.7089  decode.d5.loss_dice: 1.2423  decode.d6.loss_cls: 0.0823  decode.d6.loss_mask: 0.6911  decode.d6.loss_dice: 1.2570  decode.d7.loss_cls: 0.0892  decode.d7.loss_mask: 0.6932  decode.d7.loss_dice: 1.2515  decode.d8.loss_cls: 0.0856  decode.d8.loss_mask: 0.7137  decode.d8.loss_dice: 1.2445
11/15 10:07:13 - mmengine - INFO - Iter(train) [19250/90000]  base_lr: 8.0527e-05 lr: 8.0527e-06  eta: 11:52:19  time: 0.6092  data_time: 0.0103  memory: 10692  grad_norm: 688.7275  loss: 22.0543  decode.loss_cls: 0.0811  decode.loss_mask: 0.6720  decode.loss_dice: 1.3915  decode.d0.loss_cls: 0.0934  decode.d0.loss_mask: 0.7308  decode.d0.loss_dice: 1.5058  decode.d1.loss_cls: 0.0925  decode.d1.loss_mask: 0.7114  decode.d1.loss_dice: 1.4595  decode.d2.loss_cls: 0.1050  decode.d2.loss_mask: 0.6920  decode.d2.loss_dice: 1.4082  decode.d3.loss_cls: 0.0883  decode.d3.loss_mask: 0.6837  decode.d3.loss_dice: 1.4144  decode.d4.loss_cls: 0.0905  decode.d4.loss_mask: 0.6851  decode.d4.loss_dice: 1.4251  decode.d5.loss_cls: 0.1011  decode.d5.loss_mask: 0.6788  decode.d5.loss_dice: 1.3969  decode.d6.loss_cls: 0.1008  decode.d6.loss_mask: 0.6885  decode.d6.loss_dice: 1.4047  decode.d7.loss_cls: 0.1012  decode.d7.loss_mask: 0.6835  decode.d7.loss_dice: 1.4136  decode.d8.loss_cls: 0.0948  decode.d8.loss_mask: 0.6739  decode.d8.loss_dice: 1.3863
11/15 10:07:43 - mmengine - INFO - Iter(train) [19300/90000]  base_lr: 8.0475e-05 lr: 8.0475e-06  eta: 11:51:48  time: 0.6015  data_time: 0.0101  memory: 10675  grad_norm: 364.5012  loss: 19.3771  decode.loss_cls: 0.0741  decode.loss_mask: 0.5349  decode.loss_dice: 1.3244  decode.d0.loss_cls: 0.0828  decode.d0.loss_mask: 0.5542  decode.d0.loss_dice: 1.4249  decode.d1.loss_cls: 0.0802  decode.d1.loss_mask: 0.5218  decode.d1.loss_dice: 1.3205  decode.d2.loss_cls: 0.0985  decode.d2.loss_mask: 0.5295  decode.d2.loss_dice: 1.2887  decode.d3.loss_cls: 0.0812  decode.d3.loss_mask: 0.5322  decode.d3.loss_dice: 1.2901  decode.d4.loss_cls: 0.0879  decode.d4.loss_mask: 0.5318  decode.d4.loss_dice: 1.2912  decode.d5.loss_cls: 0.0895  decode.d5.loss_mask: 0.5453  decode.d5.loss_dice: 1.2986  decode.d6.loss_cls: 0.0917  decode.d6.loss_mask: 0.5359  decode.d6.loss_dice: 1.2801  decode.d7.loss_cls: 0.0862  decode.d7.loss_mask: 0.5381  decode.d7.loss_dice: 1.3279  decode.d8.loss_cls: 0.0732  decode.d8.loss_mask: 0.5373  decode.d8.loss_dice: 1.3245
11/15 10:08:13 - mmengine - INFO - Iter(train) [19350/90000]  base_lr: 8.0424e-05 lr: 8.0424e-06  eta: 11:51:17  time: 0.6019  data_time: 0.0102  memory: 10675  grad_norm: 509.4133  loss: 17.2793  decode.loss_cls: 0.0597  decode.loss_mask: 0.5471  decode.loss_dice: 1.1161  decode.d0.loss_cls: 0.0805  decode.d0.loss_mask: 0.5516  decode.d0.loss_dice: 1.1857  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.5490  decode.d1.loss_dice: 1.1438  decode.d2.loss_cls: 0.0701  decode.d2.loss_mask: 0.5469  decode.d2.loss_dice: 1.1211  decode.d3.loss_cls: 0.0674  decode.d3.loss_mask: 0.5475  decode.d3.loss_dice: 1.0884  decode.d4.loss_cls: 0.0707  decode.d4.loss_mask: 0.5425  decode.d4.loss_dice: 1.1040  decode.d5.loss_cls: 0.0546  decode.d5.loss_mask: 0.5505  decode.d5.loss_dice: 1.1132  decode.d6.loss_cls: 0.0622  decode.d6.loss_mask: 0.5463  decode.d6.loss_dice: 1.0971  decode.d7.loss_cls: 0.0553  decode.d7.loss_mask: 0.5511  decode.d7.loss_dice: 1.0984  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 0.5469  decode.d8.loss_dice: 1.0885
11/15 10:08:43 - mmengine - INFO - Iter(train) [19400/90000]  base_lr: 8.0373e-05 lr: 8.0373e-06  eta: 11:50:46  time: 0.5984  data_time: 0.0103  memory: 10656  grad_norm: 1029.5740  loss: 18.3494  decode.loss_cls: 0.0539  decode.loss_mask: 0.6316  decode.loss_dice: 1.1067  decode.d0.loss_cls: 0.0838  decode.d0.loss_mask: 0.6541  decode.d0.loss_dice: 1.1772  decode.d1.loss_cls: 0.0529  decode.d1.loss_mask: 0.6546  decode.d1.loss_dice: 1.1481  decode.d2.loss_cls: 0.0421  decode.d2.loss_mask: 0.6517  decode.d2.loss_dice: 1.1574  decode.d3.loss_cls: 0.0543  decode.d3.loss_mask: 0.6380  decode.d3.loss_dice: 1.1262  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.6658  decode.d4.loss_dice: 1.1174  decode.d5.loss_cls: 0.0507  decode.d5.loss_mask: 0.6645  decode.d5.loss_dice: 1.1423  decode.d6.loss_cls: 0.0552  decode.d6.loss_mask: 0.6309  decode.d6.loss_dice: 1.1200  decode.d7.loss_cls: 0.0606  decode.d7.loss_mask: 0.6292  decode.d7.loss_dice: 1.1354  decode.d8.loss_cls: 0.0530  decode.d8.loss_mask: 0.6288  decode.d8.loss_dice: 1.1129
11/15 10:09:13 - mmengine - INFO - Iter(train) [19450/90000]  base_lr: 8.0322e-05 lr: 8.0322e-06  eta: 11:50:15  time: 0.5996  data_time: 0.0099  memory: 10656  grad_norm: 348.8673  loss: 19.1545  decode.loss_cls: 0.0715  decode.loss_mask: 0.5690  decode.loss_dice: 1.2335  decode.d0.loss_cls: 0.0673  decode.d0.loss_mask: 0.6295  decode.d0.loss_dice: 1.3300  decode.d1.loss_cls: 0.0754  decode.d1.loss_mask: 0.5857  decode.d1.loss_dice: 1.2689  decode.d2.loss_cls: 0.0659  decode.d2.loss_mask: 0.5797  decode.d2.loss_dice: 1.2677  decode.d3.loss_cls: 0.0606  decode.d3.loss_mask: 0.5872  decode.d3.loss_dice: 1.2603  decode.d4.loss_cls: 0.0621  decode.d4.loss_mask: 0.5899  decode.d4.loss_dice: 1.2878  decode.d5.loss_cls: 0.0707  decode.d5.loss_mask: 0.5765  decode.d5.loss_dice: 1.2501  decode.d6.loss_cls: 0.0729  decode.d6.loss_mask: 0.5706  decode.d6.loss_dice: 1.2449  decode.d7.loss_cls: 0.0772  decode.d7.loss_mask: 0.5698  decode.d7.loss_dice: 1.2550  decode.d8.loss_cls: 0.0783  decode.d8.loss_mask: 0.5604  decode.d8.loss_dice: 1.2357
11/15 10:09:43 - mmengine - INFO - Iter(train) [19500/90000]  base_lr: 8.0271e-05 lr: 8.0271e-06  eta: 11:49:45  time: 0.5988  data_time: 0.0099  memory: 10675  grad_norm: 213.2751  loss: 18.1470  decode.loss_cls: 0.0976  decode.loss_mask: 0.4922  decode.loss_dice: 1.2430  decode.d0.loss_cls: 0.0959  decode.d0.loss_mask: 0.5061  decode.d0.loss_dice: 1.3256  decode.d1.loss_cls: 0.1103  decode.d1.loss_mask: 0.4934  decode.d1.loss_dice: 1.2530  decode.d2.loss_cls: 0.0903  decode.d2.loss_mask: 0.4873  decode.d2.loss_dice: 1.2405  decode.d3.loss_cls: 0.0823  decode.d3.loss_mask: 0.4865  decode.d3.loss_dice: 1.2261  decode.d4.loss_cls: 0.0952  decode.d4.loss_mask: 0.4861  decode.d4.loss_dice: 1.1874  decode.d5.loss_cls: 0.0954  decode.d5.loss_mask: 0.4744  decode.d5.loss_dice: 1.1993  decode.d6.loss_cls: 0.0994  decode.d6.loss_mask: 0.4931  decode.d6.loss_dice: 1.2075  decode.d7.loss_cls: 0.1015  decode.d7.loss_mask: 0.4993  decode.d7.loss_dice: 1.1880  decode.d8.loss_cls: 0.0903  decode.d8.loss_mask: 0.4854  decode.d8.loss_dice: 1.2145
11/15 10:10:13 - mmengine - INFO - Iter(train) [19550/90000]  base_lr: 8.0219e-05 lr: 8.0219e-06  eta: 11:49:13  time: 0.5972  data_time: 0.0099  memory: 10641  grad_norm: 425.1475  loss: 20.2529  decode.loss_cls: 0.0625  decode.loss_mask: 0.6397  decode.loss_dice: 1.3304  decode.d0.loss_cls: 0.0819  decode.d0.loss_mask: 0.5992  decode.d0.loss_dice: 1.3900  decode.d1.loss_cls: 0.0873  decode.d1.loss_mask: 0.5738  decode.d1.loss_dice: 1.3329  decode.d2.loss_cls: 0.0757  decode.d2.loss_mask: 0.5859  decode.d2.loss_dice: 1.3225  decode.d3.loss_cls: 0.0822  decode.d3.loss_mask: 0.5713  decode.d3.loss_dice: 1.3105  decode.d4.loss_cls: 0.0529  decode.d4.loss_mask: 0.6445  decode.d4.loss_dice: 1.3608  decode.d5.loss_cls: 0.0589  decode.d5.loss_mask: 0.6274  decode.d5.loss_dice: 1.3583  decode.d6.loss_cls: 0.0781  decode.d6.loss_mask: 0.5822  decode.d6.loss_dice: 1.3298  decode.d7.loss_cls: 0.0595  decode.d7.loss_mask: 0.6526  decode.d7.loss_dice: 1.3443  decode.d8.loss_cls: 0.0611  decode.d8.loss_mask: 0.6433  decode.d8.loss_dice: 1.3531
11/15 10:10:43 - mmengine - INFO - Iter(train) [19600/90000]  base_lr: 8.0168e-05 lr: 8.0168e-06  eta: 11:48:42  time: 0.5989  data_time: 0.0100  memory: 10675  grad_norm: 765.6669  loss: 17.6239  decode.loss_cls: 0.0805  decode.loss_mask: 0.5550  decode.loss_dice: 1.1199  decode.d0.loss_cls: 0.0939  decode.d0.loss_mask: 0.5618  decode.d0.loss_dice: 1.2213  decode.d1.loss_cls: 0.0846  decode.d1.loss_mask: 0.5458  decode.d1.loss_dice: 1.1365  decode.d2.loss_cls: 0.0810  decode.d2.loss_mask: 0.5548  decode.d2.loss_dice: 1.1186  decode.d3.loss_cls: 0.0744  decode.d3.loss_mask: 0.5537  decode.d3.loss_dice: 1.1450  decode.d4.loss_cls: 0.0713  decode.d4.loss_mask: 0.5557  decode.d4.loss_dice: 1.0860  decode.d5.loss_cls: 0.0784  decode.d5.loss_mask: 0.5557  decode.d5.loss_dice: 1.1252  decode.d6.loss_cls: 0.0795  decode.d6.loss_mask: 0.5532  decode.d6.loss_dice: 1.1083  decode.d7.loss_cls: 0.0762  decode.d7.loss_mask: 0.5450  decode.d7.loss_dice: 1.0974  decode.d8.loss_cls: 0.0811  decode.d8.loss_mask: 0.5449  decode.d8.loss_dice: 1.1390
11/15 10:11:13 - mmengine - INFO - Iter(train) [19650/90000]  base_lr: 8.0117e-05 lr: 8.0117e-06  eta: 11:48:12  time: 0.5990  data_time: 0.0101  memory: 10713  grad_norm: 432.9865  loss: 19.8354  decode.loss_cls: 0.0885  decode.loss_mask: 0.5873  decode.loss_dice: 1.3208  decode.d0.loss_cls: 0.0866  decode.d0.loss_mask: 0.5944  decode.d0.loss_dice: 1.3908  decode.d1.loss_cls: 0.0905  decode.d1.loss_mask: 0.5918  decode.d1.loss_dice: 1.2934  decode.d2.loss_cls: 0.1142  decode.d2.loss_mask: 0.5720  decode.d2.loss_dice: 1.2812  decode.d3.loss_cls: 0.1040  decode.d3.loss_mask: 0.5671  decode.d3.loss_dice: 1.2873  decode.d4.loss_cls: 0.0890  decode.d4.loss_mask: 0.5865  decode.d4.loss_dice: 1.2879  decode.d5.loss_cls: 0.1065  decode.d5.loss_mask: 0.5841  decode.d5.loss_dice: 1.2751  decode.d6.loss_cls: 0.1011  decode.d6.loss_mask: 0.5819  decode.d6.loss_dice: 1.3052  decode.d7.loss_cls: 0.0859  decode.d7.loss_mask: 0.5795  decode.d7.loss_dice: 1.3095  decode.d8.loss_cls: 0.0945  decode.d8.loss_mask: 0.5784  decode.d8.loss_dice: 1.3005
11/15 10:11:43 - mmengine - INFO - Iter(train) [19700/90000]  base_lr: 8.0066e-05 lr: 8.0066e-06  eta: 11:47:41  time: 0.5993  data_time: 0.0099  memory: 10675  grad_norm: 340.6881  loss: 18.3230  decode.loss_cls: 0.0721  decode.loss_mask: 0.5021  decode.loss_dice: 1.2435  decode.d0.loss_cls: 0.0852  decode.d0.loss_mask: 0.5049  decode.d0.loss_dice: 1.3241  decode.d1.loss_cls: 0.0882  decode.d1.loss_mask: 0.5148  decode.d1.loss_dice: 1.2444  decode.d2.loss_cls: 0.0729  decode.d2.loss_mask: 0.5102  decode.d2.loss_dice: 1.2399  decode.d3.loss_cls: 0.0847  decode.d3.loss_mask: 0.5023  decode.d3.loss_dice: 1.2179  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.5083  decode.d4.loss_dice: 1.2569  decode.d5.loss_cls: 0.0890  decode.d5.loss_mask: 0.5006  decode.d5.loss_dice: 1.2393  decode.d6.loss_cls: 0.0746  decode.d6.loss_mask: 0.5039  decode.d6.loss_dice: 1.2376  decode.d7.loss_cls: 0.0837  decode.d7.loss_mask: 0.5043  decode.d7.loss_dice: 1.2356  decode.d8.loss_cls: 0.0727  decode.d8.loss_mask: 0.5036  decode.d8.loss_dice: 1.2319
11/15 10:12:15 - mmengine - INFO - Iter(train) [19750/90000]  base_lr: 8.0014e-05 lr: 8.0014e-06  eta: 11:47:15  time: 0.7270  data_time: 0.0149  memory: 10728  grad_norm: 412.3661  loss: 19.2625  decode.loss_cls: 0.0826  decode.loss_mask: 0.5599  decode.loss_dice: 1.2658  decode.d0.loss_cls: 0.0725  decode.d0.loss_mask: 0.5737  decode.d0.loss_dice: 1.3797  decode.d1.loss_cls: 0.0888  decode.d1.loss_mask: 0.5647  decode.d1.loss_dice: 1.3016  decode.d2.loss_cls: 0.0781  decode.d2.loss_mask: 0.5608  decode.d2.loss_dice: 1.2522  decode.d3.loss_cls: 0.0852  decode.d3.loss_mask: 0.5673  decode.d3.loss_dice: 1.2564  decode.d4.loss_cls: 0.0795  decode.d4.loss_mask: 0.5640  decode.d4.loss_dice: 1.2526  decode.d5.loss_cls: 0.0982  decode.d5.loss_mask: 0.5710  decode.d5.loss_dice: 1.2520  decode.d6.loss_cls: 0.0977  decode.d6.loss_mask: 0.5644  decode.d6.loss_dice: 1.2596  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.5604  decode.d7.loss_dice: 1.2622  decode.d8.loss_cls: 0.0866  decode.d8.loss_mask: 0.5758  decode.d8.loss_dice: 1.2584
11/15 10:12:45 - mmengine - INFO - Iter(train) [19800/90000]  base_lr: 7.9963e-05 lr: 7.9963e-06  eta: 11:46:45  time: 0.6006  data_time: 0.0102  memory: 10656  grad_norm: 307.4165  loss: 19.9032  decode.loss_cls: 0.0714  decode.loss_mask: 0.5737  decode.loss_dice: 1.3010  decode.d0.loss_cls: 0.0780  decode.d0.loss_mask: 0.6134  decode.d0.loss_dice: 1.4044  decode.d1.loss_cls: 0.0752  decode.d1.loss_mask: 0.5682  decode.d1.loss_dice: 1.3264  decode.d2.loss_cls: 0.0818  decode.d2.loss_mask: 0.5727  decode.d2.loss_dice: 1.3165  decode.d3.loss_cls: 0.0812  decode.d3.loss_mask: 0.5797  decode.d3.loss_dice: 1.3058  decode.d4.loss_cls: 0.0799  decode.d4.loss_mask: 0.5763  decode.d4.loss_dice: 1.3284  decode.d5.loss_cls: 0.0865  decode.d5.loss_mask: 0.5780  decode.d5.loss_dice: 1.3421  decode.d6.loss_cls: 0.0792  decode.d6.loss_mask: 0.5778  decode.d6.loss_dice: 1.3230  decode.d7.loss_cls: 0.0793  decode.d7.loss_mask: 0.5761  decode.d7.loss_dice: 1.3425  decode.d8.loss_cls: 0.0741  decode.d8.loss_mask: 0.5816  decode.d8.loss_dice: 1.3291
11/15 10:13:15 - mmengine - INFO - Iter(train) [19850/90000]  base_lr: 7.9912e-05 lr: 7.9912e-06  eta: 11:46:15  time: 0.6012  data_time: 0.0101  memory: 10675  grad_norm: 392.4542  loss: 19.5743  decode.loss_cls: 0.1006  decode.loss_mask: 0.5455  decode.loss_dice: 1.2800  decode.d0.loss_cls: 0.0935  decode.d0.loss_mask: 0.5598  decode.d0.loss_dice: 1.4482  decode.d1.loss_cls: 0.1051  decode.d1.loss_mask: 0.5375  decode.d1.loss_dice: 1.3093  decode.d2.loss_cls: 0.1037  decode.d2.loss_mask: 0.5482  decode.d2.loss_dice: 1.3059  decode.d3.loss_cls: 0.1030  decode.d3.loss_mask: 0.5452  decode.d3.loss_dice: 1.3113  decode.d4.loss_cls: 0.0984  decode.d4.loss_mask: 0.5484  decode.d4.loss_dice: 1.3238  decode.d5.loss_cls: 0.1014  decode.d5.loss_mask: 0.5430  decode.d5.loss_dice: 1.2926  decode.d6.loss_cls: 0.1014  decode.d6.loss_mask: 0.5333  decode.d6.loss_dice: 1.2890  decode.d7.loss_cls: 0.0844  decode.d7.loss_mask: 0.5451  decode.d7.loss_dice: 1.3074  decode.d8.loss_cls: 0.0932  decode.d8.loss_mask: 0.5379  decode.d8.loss_dice: 1.2784
11/15 10:13:45 - mmengine - INFO - Iter(train) [19900/90000]  base_lr: 7.9861e-05 lr: 7.9861e-06  eta: 11:45:44  time: 0.6005  data_time: 0.0099  memory: 10713  grad_norm: 463.3702  loss: 19.4473  decode.loss_cls: 0.0698  decode.loss_mask: 0.6336  decode.loss_dice: 1.2290  decode.d0.loss_cls: 0.0703  decode.d0.loss_mask: 0.6775  decode.d0.loss_dice: 1.3417  decode.d1.loss_cls: 0.0753  decode.d1.loss_mask: 0.6132  decode.d1.loss_dice: 1.2442  decode.d2.loss_cls: 0.0586  decode.d2.loss_mask: 0.6230  decode.d2.loss_dice: 1.2434  decode.d3.loss_cls: 0.0563  decode.d3.loss_mask: 0.6171  decode.d3.loss_dice: 1.2587  decode.d4.loss_cls: 0.0590  decode.d4.loss_mask: 0.6076  decode.d4.loss_dice: 1.2619  decode.d5.loss_cls: 0.0603  decode.d5.loss_mask: 0.6164  decode.d5.loss_dice: 1.2609  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.6234  decode.d6.loss_dice: 1.2416  decode.d7.loss_cls: 0.0559  decode.d7.loss_mask: 0.6304  decode.d7.loss_dice: 1.2456  decode.d8.loss_cls: 0.0591  decode.d8.loss_mask: 0.6138  decode.d8.loss_dice: 1.2344
11/15 10:14:15 - mmengine - INFO - Iter(train) [19950/90000]  base_lr: 7.9809e-05 lr: 7.9809e-06  eta: 11:45:13  time: 0.5982  data_time: 0.0098  memory: 10692  grad_norm: 323.9010  loss: 18.9446  decode.loss_cls: 0.0768  decode.loss_mask: 0.4965  decode.loss_dice: 1.3077  decode.d0.loss_cls: 0.0910  decode.d0.loss_mask: 0.5067  decode.d0.loss_dice: 1.4190  decode.d1.loss_cls: 0.0917  decode.d1.loss_mask: 0.5001  decode.d1.loss_dice: 1.3242  decode.d2.loss_cls: 0.0744  decode.d2.loss_mask: 0.5021  decode.d2.loss_dice: 1.2925  decode.d3.loss_cls: 0.0860  decode.d3.loss_mask: 0.4931  decode.d3.loss_dice: 1.2734  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 0.4941  decode.d4.loss_dice: 1.3072  decode.d5.loss_cls: 0.0823  decode.d5.loss_mask: 0.4951  decode.d5.loss_dice: 1.3016  decode.d6.loss_cls: 0.0840  decode.d6.loss_mask: 0.4996  decode.d6.loss_dice: 1.3315  decode.d7.loss_cls: 0.0763  decode.d7.loss_mask: 0.5078  decode.d7.loss_dice: 1.3139  decode.d8.loss_cls: 0.0775  decode.d8.loss_mask: 0.4988  decode.d8.loss_dice: 1.2601
11/15 10:14:45 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 10:14:45 - mmengine - INFO - Iter(train) [20000/90000]  base_lr: 7.9758e-05 lr: 7.9758e-06  eta: 11:44:42  time: 0.5990  data_time: 0.0101  memory: 10713  grad_norm: 314.8711  loss: 20.6829  decode.loss_cls: 0.0710  decode.loss_mask: 0.7185  decode.loss_dice: 1.2861  decode.d0.loss_cls: 0.0781  decode.d0.loss_mask: 0.7200  decode.d0.loss_dice: 1.3438  decode.d1.loss_cls: 0.0861  decode.d1.loss_mask: 0.6670  decode.d1.loss_dice: 1.3118  decode.d2.loss_cls: 0.0692  decode.d2.loss_mask: 0.7008  decode.d2.loss_dice: 1.3057  decode.d3.loss_cls: 0.0727  decode.d3.loss_mask: 0.6967  decode.d3.loss_dice: 1.2872  decode.d4.loss_cls: 0.0763  decode.d4.loss_mask: 0.6910  decode.d4.loss_dice: 1.2730  decode.d5.loss_cls: 0.0705  decode.d5.loss_mask: 0.7335  decode.d5.loss_dice: 1.2730  decode.d6.loss_cls: 0.0706  decode.d6.loss_mask: 0.7084  decode.d6.loss_dice: 1.2785  decode.d7.loss_cls: 0.0734  decode.d7.loss_mask: 0.7258  decode.d7.loss_dice: 1.2786  decode.d8.loss_cls: 0.0734  decode.d8.loss_mask: 0.6841  decode.d8.loss_dice: 1.2581
11/15 10:14:45 - mmengine - INFO - Saving checkpoint at 20000 iterations
11/15 10:15:05 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:23  time: 0.3086  data_time: 0.0041  memory: 4095  
11/15 10:15:21 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:05  time: 0.3093  data_time: 0.0041  memory: 4095  
11/15 10:15:36 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:49  time: 0.3089  data_time: 0.0042  memory: 4095  
11/15 10:15:51 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3090  data_time: 0.0041  memory: 4095  
11/15 10:16:07 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3086  data_time: 0.0040  memory: 4095  
11/15 10:16:22 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:02  time: 0.3085  data_time: 0.0041  memory: 4095  
11/15 10:16:38 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3092  data_time: 0.0040  memory: 4095  
11/15 10:16:53 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:31  time: 0.3093  data_time: 0.0041  memory: 4095  
11/15 10:17:09 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3096  data_time: 0.0041  memory: 4095  
11/15 10:17:24 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3104  data_time: 0.0046  memory: 4095  
11/15 10:17:24 - mmengine - INFO - per class results:
11/15 10:17:24 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 97.61 | 98.26 |
|    sidewalk   | 82.43 | 93.36 |
|    building   | 92.12 | 95.94 |
|      wall     | 58.51 | 73.28 |
|     fence     | 54.92 | 71.55 |
|      pole     | 62.96 | 73.55 |
| traffic light | 66.61 | 80.44 |
|  traffic sign | 76.85 |  83.7 |
|   vegetation  | 91.32 |  95.7 |
|    terrain    | 58.81 |  81.7 |
|      sky      | 94.64 |  96.9 |
|     person    | 80.94 | 90.11 |
|     rider     | 61.77 | 76.73 |
|      car      | 94.48 | 97.19 |
|     truck     | 37.78 | 43.53 |
|      bus      | 55.01 | 90.47 |
|     train     |  2.56 |  2.65 |
|   motorcycle  | 60.43 | 73.09 |
|    bicycle    | 76.09 | 85.18 |
+---------------+-------+-------+
11/15 10:17:24 - mmengine - INFO - Iter(val) [500/500]    aAcc: 95.3200  mIoU: 68.7300  mAcc: 79.1200  data_time: 0.0048  time: 0.3103
11/15 10:17:24 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024/best_mIoU_iter_10000.pth is removed
11/15 10:17:26 - mmengine - INFO - The best checkpoint with 68.7300 mIoU at 20000 iter is saved to best_mIoU_iter_20000.pth.
11/15 10:18:00 - mmengine - INFO - Iter(train) [20050/90000]  base_lr: 7.9707e-05 lr: 7.9707e-06  eta: 11:44:30  time: 0.6016  data_time: 0.0100  memory: 10656  grad_norm: 498.5251  loss: 19.8491  decode.loss_cls: 0.0840  decode.loss_mask: 0.6452  decode.loss_dice: 1.2590  decode.d0.loss_cls: 0.1054  decode.d0.loss_mask: 0.6708  decode.d0.loss_dice: 1.3034  decode.d1.loss_cls: 0.0768  decode.d1.loss_mask: 0.6622  decode.d1.loss_dice: 1.2396  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 0.6367  decode.d2.loss_dice: 1.2582  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.6295  decode.d3.loss_dice: 1.2449  decode.d4.loss_cls: 0.0716  decode.d4.loss_mask: 0.6397  decode.d4.loss_dice: 1.2475  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.6534  decode.d5.loss_dice: 1.2306  decode.d6.loss_cls: 0.0657  decode.d6.loss_mask: 0.6565  decode.d6.loss_dice: 1.2636  decode.d7.loss_cls: 0.0744  decode.d7.loss_mask: 0.6565  decode.d7.loss_dice: 1.2716  decode.d8.loss_cls: 0.0715  decode.d8.loss_mask: 0.6534  decode.d8.loss_dice: 1.2573
11/15 10:18:30 - mmengine - INFO - Iter(train) [20100/90000]  base_lr: 7.9655e-05 lr: 7.9655e-06  eta: 11:43:59  time: 0.6001  data_time: 0.0101  memory: 10742  grad_norm: 651.0456  loss: 21.1639  decode.loss_cls: 0.0973  decode.loss_mask: 0.6488  decode.loss_dice: 1.3161  decode.d0.loss_cls: 0.1028  decode.d0.loss_mask: 0.6954  decode.d0.loss_dice: 1.4249  decode.d1.loss_cls: 0.1116  decode.d1.loss_mask: 0.6560  decode.d1.loss_dice: 1.3440  decode.d2.loss_cls: 0.0942  decode.d2.loss_mask: 0.6659  decode.d2.loss_dice: 1.3851  decode.d3.loss_cls: 0.0984  decode.d3.loss_mask: 0.6579  decode.d3.loss_dice: 1.3572  decode.d4.loss_cls: 0.1068  decode.d4.loss_mask: 0.6410  decode.d4.loss_dice: 1.3709  decode.d5.loss_cls: 0.1105  decode.d5.loss_mask: 0.6567  decode.d5.loss_dice: 1.3632  decode.d6.loss_cls: 0.1140  decode.d6.loss_mask: 0.6417  decode.d6.loss_dice: 1.3129  decode.d7.loss_cls: 0.0947  decode.d7.loss_mask: 0.6550  decode.d7.loss_dice: 1.3648  decode.d8.loss_cls: 0.0976  decode.d8.loss_mask: 0.6358  decode.d8.loss_dice: 1.3427
11/15 10:19:00 - mmengine - INFO - Iter(train) [20150/90000]  base_lr: 7.9604e-05 lr: 7.9604e-06  eta: 11:43:28  time: 0.6009  data_time: 0.0101  memory: 10692  grad_norm: 329.0145  loss: 18.0988  decode.loss_cls: 0.0642  decode.loss_mask: 0.5491  decode.loss_dice: 1.1905  decode.d0.loss_cls: 0.0832  decode.d0.loss_mask: 0.5693  decode.d0.loss_dice: 1.2743  decode.d1.loss_cls: 0.0713  decode.d1.loss_mask: 0.5519  decode.d1.loss_dice: 1.2011  decode.d2.loss_cls: 0.0826  decode.d2.loss_mask: 0.5514  decode.d2.loss_dice: 1.1608  decode.d3.loss_cls: 0.0734  decode.d3.loss_mask: 0.5557  decode.d3.loss_dice: 1.1676  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.5545  decode.d4.loss_dice: 1.1486  decode.d5.loss_cls: 0.0724  decode.d5.loss_mask: 0.5486  decode.d5.loss_dice: 1.1902  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.5529  decode.d6.loss_dice: 1.1752  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 0.5481  decode.d7.loss_dice: 1.1765  decode.d8.loss_cls: 0.0802  decode.d8.loss_mask: 0.5486  decode.d8.loss_dice: 1.1477
11/15 10:19:30 - mmengine - INFO - Iter(train) [20200/90000]  base_lr: 7.9553e-05 lr: 7.9553e-06  eta: 11:42:57  time: 0.5985  data_time: 0.0098  memory: 10656  grad_norm: 487.6468  loss: 18.6071  decode.loss_cls: 0.0737  decode.loss_mask: 0.5914  decode.loss_dice: 1.1656  decode.d0.loss_cls: 0.0920  decode.d0.loss_mask: 0.6117  decode.d0.loss_dice: 1.2619  decode.d1.loss_cls: 0.0793  decode.d1.loss_mask: 0.5778  decode.d1.loss_dice: 1.2005  decode.d2.loss_cls: 0.0829  decode.d2.loss_mask: 0.5735  decode.d2.loss_dice: 1.1893  decode.d3.loss_cls: 0.0821  decode.d3.loss_mask: 0.5877  decode.d3.loss_dice: 1.1681  decode.d4.loss_cls: 0.0757  decode.d4.loss_mask: 0.5854  decode.d4.loss_dice: 1.1690  decode.d5.loss_cls: 0.0861  decode.d5.loss_mask: 0.5881  decode.d5.loss_dice: 1.1690  decode.d6.loss_cls: 0.0662  decode.d6.loss_mask: 0.5963  decode.d6.loss_dice: 1.2211  decode.d7.loss_cls: 0.0740  decode.d7.loss_mask: 0.5972  decode.d7.loss_dice: 1.1786  decode.d8.loss_cls: 0.0770  decode.d8.loss_mask: 0.5936  decode.d8.loss_dice: 1.1924
11/15 10:20:00 - mmengine - INFO - Iter(train) [20250/90000]  base_lr: 7.9502e-05 lr: 7.9502e-06  eta: 11:42:26  time: 0.5997  data_time: 0.0101  memory: 10641  grad_norm: 550.8478  loss: 18.8990  decode.loss_cls: 0.0905  decode.loss_mask: 0.5361  decode.loss_dice: 1.2685  decode.d0.loss_cls: 0.1029  decode.d0.loss_mask: 0.5536  decode.d0.loss_dice: 1.2852  decode.d1.loss_cls: 0.0875  decode.d1.loss_mask: 0.5455  decode.d1.loss_dice: 1.2691  decode.d2.loss_cls: 0.0979  decode.d2.loss_mask: 0.5390  decode.d2.loss_dice: 1.2502  decode.d3.loss_cls: 0.0929  decode.d3.loss_mask: 0.5313  decode.d3.loss_dice: 1.2603  decode.d4.loss_cls: 0.0816  decode.d4.loss_mask: 0.5347  decode.d4.loss_dice: 1.2536  decode.d5.loss_cls: 0.0856  decode.d5.loss_mask: 0.5301  decode.d5.loss_dice: 1.2829  decode.d6.loss_cls: 0.0921  decode.d6.loss_mask: 0.5308  decode.d6.loss_dice: 1.2617  decode.d7.loss_cls: 0.0898  decode.d7.loss_mask: 0.5286  decode.d7.loss_dice: 1.2390  decode.d8.loss_cls: 0.0783  decode.d8.loss_mask: 0.5336  decode.d8.loss_dice: 1.2661
11/15 10:20:30 - mmengine - INFO - Iter(train) [20300/90000]  base_lr: 7.9450e-05 lr: 7.9450e-06  eta: 11:41:55  time: 0.5995  data_time: 0.0101  memory: 10656  grad_norm: 682.1809  loss: 20.3746  decode.loss_cls: 0.0721  decode.loss_mask: 0.6603  decode.loss_dice: 1.2735  decode.d0.loss_cls: 0.0947  decode.d0.loss_mask: 0.7092  decode.d0.loss_dice: 1.3573  decode.d1.loss_cls: 0.0734  decode.d1.loss_mask: 0.6756  decode.d1.loss_dice: 1.2900  decode.d2.loss_cls: 0.0683  decode.d2.loss_mask: 0.6825  decode.d2.loss_dice: 1.2815  decode.d3.loss_cls: 0.0672  decode.d3.loss_mask: 0.6559  decode.d3.loss_dice: 1.2643  decode.d4.loss_cls: 0.0721  decode.d4.loss_mask: 0.6696  decode.d4.loss_dice: 1.2974  decode.d5.loss_cls: 0.0674  decode.d5.loss_mask: 0.6772  decode.d5.loss_dice: 1.2901  decode.d6.loss_cls: 0.0667  decode.d6.loss_mask: 0.6705  decode.d6.loss_dice: 1.2867  decode.d7.loss_cls: 0.0679  decode.d7.loss_mask: 0.6754  decode.d7.loss_dice: 1.2780  decode.d8.loss_cls: 0.0651  decode.d8.loss_mask: 0.6857  decode.d8.loss_dice: 1.2791
11/15 10:21:00 - mmengine - INFO - Iter(train) [20350/90000]  base_lr: 7.9399e-05 lr: 7.9399e-06  eta: 11:41:24  time: 0.5995  data_time: 0.0100  memory: 10675  grad_norm: 341.0339  loss: 17.4274  decode.loss_cls: 0.0596  decode.loss_mask: 0.5155  decode.loss_dice: 1.1110  decode.d0.loss_cls: 0.0762  decode.d0.loss_mask: 0.5567  decode.d0.loss_dice: 1.2664  decode.d1.loss_cls: 0.0614  decode.d1.loss_mask: 0.5187  decode.d1.loss_dice: 1.1785  decode.d2.loss_cls: 0.0599  decode.d2.loss_mask: 0.5173  decode.d2.loss_dice: 1.1860  decode.d3.loss_cls: 0.0723  decode.d3.loss_mask: 0.5154  decode.d3.loss_dice: 1.1385  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.5113  decode.d4.loss_dice: 1.1478  decode.d5.loss_cls: 0.0634  decode.d5.loss_mask: 0.5212  decode.d5.loss_dice: 1.1526  decode.d6.loss_cls: 0.0667  decode.d6.loss_mask: 0.5164  decode.d6.loss_dice: 1.1322  decode.d7.loss_cls: 0.0573  decode.d7.loss_mask: 0.5193  decode.d7.loss_dice: 1.1279  decode.d8.loss_cls: 0.0589  decode.d8.loss_mask: 0.5175  decode.d8.loss_dice: 1.1417
11/15 10:21:30 - mmengine - INFO - Iter(train) [20400/90000]  base_lr: 7.9348e-05 lr: 7.9348e-06  eta: 11:40:53  time: 0.5998  data_time: 0.0100  memory: 10675  grad_norm: 446.8003  loss: 20.1510  decode.loss_cls: 0.1097  decode.loss_mask: 0.6332  decode.loss_dice: 1.2243  decode.d0.loss_cls: 0.1110  decode.d0.loss_mask: 0.6752  decode.d0.loss_dice: 1.3060  decode.d1.loss_cls: 0.1033  decode.d1.loss_mask: 0.6740  decode.d1.loss_dice: 1.2682  decode.d2.loss_cls: 0.1102  decode.d2.loss_mask: 0.6705  decode.d2.loss_dice: 1.2498  decode.d3.loss_cls: 0.1076  decode.d3.loss_mask: 0.6816  decode.d3.loss_dice: 1.2137  decode.d4.loss_cls: 0.1020  decode.d4.loss_mask: 0.6826  decode.d4.loss_dice: 1.2588  decode.d5.loss_cls: 0.0927  decode.d5.loss_mask: 0.6568  decode.d5.loss_dice: 1.2547  decode.d6.loss_cls: 0.0887  decode.d6.loss_mask: 0.6508  decode.d6.loss_dice: 1.2336  decode.d7.loss_cls: 0.0896  decode.d7.loss_mask: 0.6659  decode.d7.loss_dice: 1.2455  decode.d8.loss_cls: 0.0930  decode.d8.loss_mask: 0.6500  decode.d8.loss_dice: 1.2481
11/15 10:22:00 - mmengine - INFO - Iter(train) [20450/90000]  base_lr: 7.9296e-05 lr: 7.9296e-06  eta: 11:40:22  time: 0.6019  data_time: 0.0100  memory: 10692  grad_norm: 381.1299  loss: 19.1795  decode.loss_cls: 0.0709  decode.loss_mask: 0.5585  decode.loss_dice: 1.2901  decode.d0.loss_cls: 0.0915  decode.d0.loss_mask: 0.5830  decode.d0.loss_dice: 1.3257  decode.d1.loss_cls: 0.1003  decode.d1.loss_mask: 0.5279  decode.d1.loss_dice: 1.2733  decode.d2.loss_cls: 0.0669  decode.d2.loss_mask: 0.5561  decode.d2.loss_dice: 1.3080  decode.d3.loss_cls: 0.0733  decode.d3.loss_mask: 0.5495  decode.d3.loss_dice: 1.2619  decode.d4.loss_cls: 0.0678  decode.d4.loss_mask: 0.5597  decode.d4.loss_dice: 1.2917  decode.d5.loss_cls: 0.0796  decode.d5.loss_mask: 0.5345  decode.d5.loss_dice: 1.2833  decode.d6.loss_cls: 0.0931  decode.d6.loss_mask: 0.5416  decode.d6.loss_dice: 1.2622  decode.d7.loss_cls: 0.0838  decode.d7.loss_mask: 0.5522  decode.d7.loss_dice: 1.2594  decode.d8.loss_cls: 0.0619  decode.d8.loss_mask: 0.5603  decode.d8.loss_dice: 1.3116
11/15 10:22:30 - mmengine - INFO - Iter(train) [20500/90000]  base_lr: 7.9245e-05 lr: 7.9245e-06  eta: 11:39:52  time: 0.5965  data_time: 0.0099  memory: 10692  grad_norm: 287.2273  loss: 18.0485  decode.loss_cls: 0.0705  decode.loss_mask: 0.5568  decode.loss_dice: 1.1634  decode.d0.loss_cls: 0.0762  decode.d0.loss_mask: 0.5737  decode.d0.loss_dice: 1.2377  decode.d1.loss_cls: 0.0676  decode.d1.loss_mask: 0.5641  decode.d1.loss_dice: 1.1848  decode.d2.loss_cls: 0.0796  decode.d2.loss_mask: 0.5698  decode.d2.loss_dice: 1.1273  decode.d3.loss_cls: 0.0675  decode.d3.loss_mask: 0.5789  decode.d3.loss_dice: 1.1594  decode.d4.loss_cls: 0.0735  decode.d4.loss_mask: 0.5659  decode.d4.loss_dice: 1.1604  decode.d5.loss_cls: 0.0734  decode.d5.loss_mask: 0.5594  decode.d5.loss_dice: 1.1395  decode.d6.loss_cls: 0.0767  decode.d6.loss_mask: 0.5778  decode.d6.loss_dice: 1.1324  decode.d7.loss_cls: 0.0754  decode.d7.loss_mask: 0.5650  decode.d7.loss_dice: 1.1401  decode.d8.loss_cls: 0.0796  decode.d8.loss_mask: 0.5666  decode.d8.loss_dice: 1.1853
11/15 10:23:00 - mmengine - INFO - Iter(train) [20550/90000]  base_lr: 7.9194e-05 lr: 7.9194e-06  eta: 11:39:21  time: 0.5992  data_time: 0.0098  memory: 10713  grad_norm: 341.7414  loss: 19.7270  decode.loss_cls: 0.0868  decode.loss_mask: 0.5629  decode.loss_dice: 1.3275  decode.d0.loss_cls: 0.0995  decode.d0.loss_mask: 0.5476  decode.d0.loss_dice: 1.4258  decode.d1.loss_cls: 0.1050  decode.d1.loss_mask: 0.5455  decode.d1.loss_dice: 1.3271  decode.d2.loss_cls: 0.1107  decode.d2.loss_mask: 0.5397  decode.d2.loss_dice: 1.3039  decode.d3.loss_cls: 0.0824  decode.d3.loss_mask: 0.5659  decode.d3.loss_dice: 1.3103  decode.d4.loss_cls: 0.0838  decode.d4.loss_mask: 0.5507  decode.d4.loss_dice: 1.2944  decode.d5.loss_cls: 0.0917  decode.d5.loss_mask: 0.5642  decode.d5.loss_dice: 1.3113  decode.d6.loss_cls: 0.0850  decode.d6.loss_mask: 0.5609  decode.d6.loss_dice: 1.3117  decode.d7.loss_cls: 0.0894  decode.d7.loss_mask: 0.5620  decode.d7.loss_dice: 1.3169  decode.d8.loss_cls: 0.0937  decode.d8.loss_mask: 0.5532  decode.d8.loss_dice: 1.3173
11/15 10:23:30 - mmengine - INFO - Iter(train) [20600/90000]  base_lr: 7.9142e-05 lr: 7.9142e-06  eta: 11:38:50  time: 0.5988  data_time: 0.0100  memory: 10692  grad_norm: 430.3494  loss: 19.1356  decode.loss_cls: 0.0791  decode.loss_mask: 0.5560  decode.loss_dice: 1.2437  decode.d0.loss_cls: 0.0908  decode.d0.loss_mask: 0.5722  decode.d0.loss_dice: 1.3170  decode.d1.loss_cls: 0.0855  decode.d1.loss_mask: 0.5635  decode.d1.loss_dice: 1.2564  decode.d2.loss_cls: 0.0920  decode.d2.loss_mask: 0.5743  decode.d2.loss_dice: 1.2289  decode.d3.loss_cls: 0.0845  decode.d3.loss_mask: 0.5562  decode.d3.loss_dice: 1.2574  decode.d4.loss_cls: 0.0724  decode.d4.loss_mask: 0.5705  decode.d4.loss_dice: 1.2691  decode.d5.loss_cls: 0.0891  decode.d5.loss_mask: 0.5753  decode.d5.loss_dice: 1.2669  decode.d6.loss_cls: 0.0750  decode.d6.loss_mask: 0.5622  decode.d6.loss_dice: 1.2526  decode.d7.loss_cls: 0.0766  decode.d7.loss_mask: 0.5616  decode.d7.loss_dice: 1.2862  decode.d8.loss_cls: 0.0802  decode.d8.loss_mask: 0.5730  decode.d8.loss_dice: 1.2676
11/15 10:24:00 - mmengine - INFO - Iter(train) [20650/90000]  base_lr: 7.9091e-05 lr: 7.9091e-06  eta: 11:38:19  time: 0.5999  data_time: 0.0099  memory: 10641  grad_norm: 517.3506  loss: 21.7089  decode.loss_cls: 0.0934  decode.loss_mask: 0.8026  decode.loss_dice: 1.3241  decode.d0.loss_cls: 0.0920  decode.d0.loss_mask: 0.8519  decode.d0.loss_dice: 1.4012  decode.d1.loss_cls: 0.0986  decode.d1.loss_mask: 0.7516  decode.d1.loss_dice: 1.3001  decode.d2.loss_cls: 0.0954  decode.d2.loss_mask: 0.7411  decode.d2.loss_dice: 1.3019  decode.d3.loss_cls: 0.0926  decode.d3.loss_mask: 0.7711  decode.d3.loss_dice: 1.2813  decode.d4.loss_cls: 0.0913  decode.d4.loss_mask: 0.7426  decode.d4.loss_dice: 1.2764  decode.d5.loss_cls: 0.0975  decode.d5.loss_mask: 0.7437  decode.d5.loss_dice: 1.2617  decode.d6.loss_cls: 0.0920  decode.d6.loss_mask: 0.7643  decode.d6.loss_dice: 1.2702  decode.d7.loss_cls: 0.0961  decode.d7.loss_mask: 0.7500  decode.d7.loss_dice: 1.2993  decode.d8.loss_cls: 0.0953  decode.d8.loss_mask: 0.7965  decode.d8.loss_dice: 1.3331
11/15 10:24:30 - mmengine - INFO - Iter(train) [20700/90000]  base_lr: 7.9040e-05 lr: 7.9040e-06  eta: 11:37:48  time: 0.5988  data_time: 0.0099  memory: 10656  grad_norm: 719.9609  loss: 21.2689  decode.loss_cls: 0.0894  decode.loss_mask: 0.6770  decode.loss_dice: 1.3519  decode.d0.loss_cls: 0.1156  decode.d0.loss_mask: 0.6810  decode.d0.loss_dice: 1.4164  decode.d1.loss_cls: 0.1041  decode.d1.loss_mask: 0.6529  decode.d1.loss_dice: 1.3392  decode.d2.loss_cls: 0.0886  decode.d2.loss_mask: 0.6489  decode.d2.loss_dice: 1.3721  decode.d3.loss_cls: 0.0927  decode.d3.loss_mask: 0.6956  decode.d3.loss_dice: 1.3403  decode.d4.loss_cls: 0.0969  decode.d4.loss_mask: 0.6602  decode.d4.loss_dice: 1.3393  decode.d5.loss_cls: 0.0808  decode.d5.loss_mask: 0.6929  decode.d5.loss_dice: 1.3886  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.6830  decode.d6.loss_dice: 1.3505  decode.d7.loss_cls: 0.0899  decode.d7.loss_mask: 0.6767  decode.d7.loss_dice: 1.3592  decode.d8.loss_cls: 0.1097  decode.d8.loss_mask: 0.6445  decode.d8.loss_dice: 1.3404
11/15 10:25:00 - mmengine - INFO - Iter(train) [20750/90000]  base_lr: 7.8989e-05 lr: 7.8989e-06  eta: 11:37:17  time: 0.6004  data_time: 0.0099  memory: 10675  grad_norm: 281.0900  loss: 16.4790  decode.loss_cls: 0.0671  decode.loss_mask: 0.4821  decode.loss_dice: 1.0803  decode.d0.loss_cls: 0.0897  decode.d0.loss_mask: 0.5021  decode.d0.loss_dice: 1.1395  decode.d1.loss_cls: 0.0603  decode.d1.loss_mask: 0.4923  decode.d1.loss_dice: 1.1196  decode.d2.loss_cls: 0.0695  decode.d2.loss_mask: 0.4852  decode.d2.loss_dice: 1.0828  decode.d3.loss_cls: 0.0717  decode.d3.loss_mask: 0.4864  decode.d3.loss_dice: 1.0762  decode.d4.loss_cls: 0.0734  decode.d4.loss_mask: 0.4832  decode.d4.loss_dice: 1.0554  decode.d5.loss_cls: 0.0674  decode.d5.loss_mask: 0.4901  decode.d5.loss_dice: 1.0966  decode.d6.loss_cls: 0.0730  decode.d6.loss_mask: 0.4807  decode.d6.loss_dice: 1.0540  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.4828  decode.d7.loss_dice: 1.0996  decode.d8.loss_cls: 0.0708  decode.d8.loss_mask: 0.4851  decode.d8.loss_dice: 1.0940
11/15 10:25:30 - mmengine - INFO - Iter(train) [20800/90000]  base_lr: 7.8937e-05 lr: 7.8937e-06  eta: 11:36:47  time: 0.6021  data_time: 0.0099  memory: 10728  grad_norm: 753.7500  loss: 20.0103  decode.loss_cls: 0.1182  decode.loss_mask: 0.5230  decode.loss_dice: 1.3515  decode.d0.loss_cls: 0.1081  decode.d0.loss_mask: 0.5559  decode.d0.loss_dice: 1.4582  decode.d1.loss_cls: 0.1267  decode.d1.loss_mask: 0.5115  decode.d1.loss_dice: 1.3805  decode.d2.loss_cls: 0.1211  decode.d2.loss_mask: 0.5057  decode.d2.loss_dice: 1.3281  decode.d3.loss_cls: 0.1217  decode.d3.loss_mask: 0.5250  decode.d3.loss_dice: 1.3290  decode.d4.loss_cls: 0.1228  decode.d4.loss_mask: 0.5295  decode.d4.loss_dice: 1.3307  decode.d5.loss_cls: 0.1123  decode.d5.loss_mask: 0.5269  decode.d5.loss_dice: 1.3215  decode.d6.loss_cls: 0.1066  decode.d6.loss_mask: 0.5327  decode.d6.loss_dice: 1.3274  decode.d7.loss_cls: 0.0864  decode.d7.loss_mask: 0.5353  decode.d7.loss_dice: 1.3878  decode.d8.loss_cls: 0.1071  decode.d8.loss_mask: 0.5558  decode.d8.loss_dice: 1.3633
11/15 10:26:00 - mmengine - INFO - Iter(train) [20850/90000]  base_lr: 7.8886e-05 lr: 7.8886e-06  eta: 11:36:16  time: 0.6006  data_time: 0.0099  memory: 10713  grad_norm: 305.7076  loss: 19.5757  decode.loss_cls: 0.0734  decode.loss_mask: 0.5903  decode.loss_dice: 1.2925  decode.d0.loss_cls: 0.0971  decode.d0.loss_mask: 0.5851  decode.d0.loss_dice: 1.3491  decode.d1.loss_cls: 0.0971  decode.d1.loss_mask: 0.5721  decode.d1.loss_dice: 1.2737  decode.d2.loss_cls: 0.0990  decode.d2.loss_mask: 0.5635  decode.d2.loss_dice: 1.2682  decode.d3.loss_cls: 0.0899  decode.d3.loss_mask: 0.5671  decode.d3.loss_dice: 1.2752  decode.d4.loss_cls: 0.0878  decode.d4.loss_mask: 0.5789  decode.d4.loss_dice: 1.2980  decode.d5.loss_cls: 0.0902  decode.d5.loss_mask: 0.5788  decode.d5.loss_dice: 1.2910  decode.d6.loss_cls: 0.0889  decode.d6.loss_mask: 0.5813  decode.d6.loss_dice: 1.2758  decode.d7.loss_cls: 0.0970  decode.d7.loss_mask: 0.5842  decode.d7.loss_dice: 1.2675  decode.d8.loss_cls: 0.0871  decode.d8.loss_mask: 0.5877  decode.d8.loss_dice: 1.2882
11/15 10:26:30 - mmengine - INFO - Iter(train) [20900/90000]  base_lr: 7.8835e-05 lr: 7.8835e-06  eta: 11:35:45  time: 0.6012  data_time: 0.0102  memory: 10692  grad_norm: 470.3982  loss: 19.8485  decode.loss_cls: 0.0731  decode.loss_mask: 0.6379  decode.loss_dice: 1.2612  decode.d0.loss_cls: 0.0826  decode.d0.loss_mask: 0.6567  decode.d0.loss_dice: 1.3280  decode.d1.loss_cls: 0.0805  decode.d1.loss_mask: 0.6316  decode.d1.loss_dice: 1.2665  decode.d2.loss_cls: 0.0819  decode.d2.loss_mask: 0.6307  decode.d2.loss_dice: 1.2776  decode.d3.loss_cls: 0.0695  decode.d3.loss_mask: 0.6446  decode.d3.loss_dice: 1.2458  decode.d4.loss_cls: 0.0685  decode.d4.loss_mask: 0.6475  decode.d4.loss_dice: 1.2667  decode.d5.loss_cls: 0.0687  decode.d5.loss_mask: 0.6560  decode.d5.loss_dice: 1.2755  decode.d6.loss_cls: 0.0755  decode.d6.loss_mask: 0.6471  decode.d6.loss_dice: 1.2559  decode.d7.loss_cls: 0.0825  decode.d7.loss_mask: 0.6213  decode.d7.loss_dice: 1.2552  decode.d8.loss_cls: 0.0691  decode.d8.loss_mask: 0.6354  decode.d8.loss_dice: 1.2558
11/15 10:27:00 - mmengine - INFO - Iter(train) [20950/90000]  base_lr: 7.8783e-05 lr: 7.8783e-06  eta: 11:35:14  time: 0.5996  data_time: 0.0109  memory: 10675  grad_norm: 426.9501  loss: 18.3278  decode.loss_cls: 0.0646  decode.loss_mask: 0.6106  decode.loss_dice: 1.1250  decode.d0.loss_cls: 0.0947  decode.d0.loss_mask: 0.6320  decode.d0.loss_dice: 1.1984  decode.d1.loss_cls: 0.0666  decode.d1.loss_mask: 0.6294  decode.d1.loss_dice: 1.1455  decode.d2.loss_cls: 0.0920  decode.d2.loss_mask: 0.6209  decode.d2.loss_dice: 1.1016  decode.d3.loss_cls: 0.0743  decode.d3.loss_mask: 0.6142  decode.d3.loss_dice: 1.1272  decode.d4.loss_cls: 0.0679  decode.d4.loss_mask: 0.6402  decode.d4.loss_dice: 1.1312  decode.d5.loss_cls: 0.0677  decode.d5.loss_mask: 0.6250  decode.d5.loss_dice: 1.1171  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.6349  decode.d6.loss_dice: 1.1341  decode.d7.loss_cls: 0.0719  decode.d7.loss_mask: 0.6159  decode.d7.loss_dice: 1.1517  decode.d8.loss_cls: 0.0626  decode.d8.loss_mask: 0.6108  decode.d8.loss_dice: 1.1414
11/15 10:27:31 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 10:27:31 - mmengine - INFO - Iter(train) [21000/90000]  base_lr: 7.8732e-05 lr: 7.8732e-06  eta: 11:34:45  time: 0.6016  data_time: 0.0101  memory: 10656  grad_norm: 424.3030  loss: 20.9225  decode.loss_cls: 0.0829  decode.loss_mask: 0.5850  decode.loss_dice: 1.4067  decode.d0.loss_cls: 0.0788  decode.d0.loss_mask: 0.6078  decode.d0.loss_dice: 1.4871  decode.d1.loss_cls: 0.0803  decode.d1.loss_mask: 0.5815  decode.d1.loss_dice: 1.4511  decode.d2.loss_cls: 0.0923  decode.d2.loss_mask: 0.5818  decode.d2.loss_dice: 1.4526  decode.d3.loss_cls: 0.0763  decode.d3.loss_mask: 0.5736  decode.d3.loss_dice: 1.4021  decode.d4.loss_cls: 0.0722  decode.d4.loss_mask: 0.5814  decode.d4.loss_dice: 1.4279  decode.d5.loss_cls: 0.0651  decode.d5.loss_mask: 0.5807  decode.d5.loss_dice: 1.4309  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.5796  decode.d6.loss_dice: 1.4345  decode.d7.loss_cls: 0.0780  decode.d7.loss_mask: 0.5731  decode.d7.loss_dice: 1.4180  decode.d8.loss_cls: 0.0727  decode.d8.loss_mask: 0.5775  decode.d8.loss_dice: 1.4261
11/15 10:28:01 - mmengine - INFO - Iter(train) [21050/90000]  base_lr: 7.8680e-05 lr: 7.8680e-06  eta: 11:34:14  time: 0.5971  data_time: 0.0097  memory: 10656  grad_norm: 415.7073  loss: 16.4458  decode.loss_cls: 0.0520  decode.loss_mask: 0.4825  decode.loss_dice: 1.0940  decode.d0.loss_cls: 0.0687  decode.d0.loss_mask: 0.4898  decode.d0.loss_dice: 1.1884  decode.d1.loss_cls: 0.0654  decode.d1.loss_mask: 0.4970  decode.d1.loss_dice: 1.0883  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.4777  decode.d2.loss_dice: 1.1189  decode.d3.loss_cls: 0.0603  decode.d3.loss_mask: 0.4788  decode.d3.loss_dice: 1.0902  decode.d4.loss_cls: 0.0596  decode.d4.loss_mask: 0.4716  decode.d4.loss_dice: 1.0688  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 0.4736  decode.d5.loss_dice: 1.0811  decode.d6.loss_cls: 0.0540  decode.d6.loss_mask: 0.4878  decode.d6.loss_dice: 1.0887  decode.d7.loss_cls: 0.0587  decode.d7.loss_mask: 0.4950  decode.d7.loss_dice: 1.0864  decode.d8.loss_cls: 0.0536  decode.d8.loss_mask: 0.4884  decode.d8.loss_dice: 1.1094
11/15 10:28:31 - mmengine - INFO - Iter(train) [21100/90000]  base_lr: 7.8629e-05 lr: 7.8629e-06  eta: 11:33:43  time: 0.5999  data_time: 0.0099  memory: 10713  grad_norm: 648.0220  loss: 18.6117  decode.loss_cls: 0.0698  decode.loss_mask: 0.5299  decode.loss_dice: 1.2442  decode.d0.loss_cls: 0.0672  decode.d0.loss_mask: 0.5496  decode.d0.loss_dice: 1.3214  decode.d1.loss_cls: 0.0901  decode.d1.loss_mask: 0.5186  decode.d1.loss_dice: 1.2248  decode.d2.loss_cls: 0.0891  decode.d2.loss_mask: 0.5284  decode.d2.loss_dice: 1.2381  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.5284  decode.d3.loss_dice: 1.2589  decode.d4.loss_cls: 0.0766  decode.d4.loss_mask: 0.5222  decode.d4.loss_dice: 1.2652  decode.d5.loss_cls: 0.0691  decode.d5.loss_mask: 0.5260  decode.d5.loss_dice: 1.2586  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.5280  decode.d6.loss_dice: 1.2530  decode.d7.loss_cls: 0.0632  decode.d7.loss_mask: 0.5258  decode.d7.loss_dice: 1.2829  decode.d8.loss_cls: 0.0730  decode.d8.loss_mask: 0.5292  decode.d8.loss_dice: 1.2468
11/15 10:29:02 - mmengine - INFO - Iter(train) [21150/90000]  base_lr: 7.8578e-05 lr: 7.8578e-06  eta: 11:33:15  time: 0.6006  data_time: 0.0100  memory: 10692  grad_norm: 488.3002  loss: 18.2282  decode.loss_cls: 0.0728  decode.loss_mask: 0.5787  decode.loss_dice: 1.1307  decode.d0.loss_cls: 0.0764  decode.d0.loss_mask: 0.6110  decode.d0.loss_dice: 1.2549  decode.d1.loss_cls: 0.0708  decode.d1.loss_mask: 0.5895  decode.d1.loss_dice: 1.2025  decode.d2.loss_cls: 0.0786  decode.d2.loss_mask: 0.5673  decode.d2.loss_dice: 1.1814  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.5680  decode.d3.loss_dice: 1.1816  decode.d4.loss_cls: 0.0736  decode.d4.loss_mask: 0.5596  decode.d4.loss_dice: 1.1704  decode.d5.loss_cls: 0.0799  decode.d5.loss_mask: 0.5649  decode.d5.loss_dice: 1.1512  decode.d6.loss_cls: 0.0599  decode.d6.loss_mask: 0.5916  decode.d6.loss_dice: 1.1526  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.5705  decode.d7.loss_dice: 1.1757  decode.d8.loss_cls: 0.0758  decode.d8.loss_mask: 0.5738  decode.d8.loss_dice: 1.1373
11/15 10:29:37 - mmengine - INFO - Iter(train) [21200/90000]  base_lr: 7.8526e-05 lr: 7.8526e-06  eta: 11:33:04  time: 0.6059  data_time: 0.0104  memory: 10692  grad_norm: 542.3255  loss: 22.2056  decode.loss_cls: 0.1257  decode.loss_mask: 0.7371  decode.loss_dice: 1.4092  decode.d0.loss_cls: 0.1180  decode.d0.loss_mask: 0.7071  decode.d0.loss_dice: 1.4400  decode.d1.loss_cls: 0.1238  decode.d1.loss_mask: 0.6871  decode.d1.loss_dice: 1.3903  decode.d2.loss_cls: 0.1223  decode.d2.loss_mask: 0.6675  decode.d2.loss_dice: 1.3729  decode.d3.loss_cls: 0.1301  decode.d3.loss_mask: 0.6922  decode.d3.loss_dice: 1.3529  decode.d4.loss_cls: 0.1374  decode.d4.loss_mask: 0.7101  decode.d4.loss_dice: 1.3655  decode.d5.loss_cls: 0.1197  decode.d5.loss_mask: 0.7334  decode.d5.loss_dice: 1.3908  decode.d6.loss_cls: 0.1297  decode.d6.loss_mask: 0.7277  decode.d6.loss_dice: 1.3753  decode.d7.loss_cls: 0.1293  decode.d7.loss_mask: 0.6738  decode.d7.loss_dice: 1.3943  decode.d8.loss_cls: 0.1339  decode.d8.loss_mask: 0.7175  decode.d8.loss_dice: 1.3906
11/15 10:30:08 - mmengine - INFO - Iter(train) [21250/90000]  base_lr: 7.8475e-05 lr: 7.8475e-06  eta: 11:32:36  time: 0.6048  data_time: 0.0102  memory: 10713  grad_norm: 313.5096  loss: 20.0599  decode.loss_cls: 0.0919  decode.loss_mask: 0.5846  decode.loss_dice: 1.3252  decode.d0.loss_cls: 0.0802  decode.d0.loss_mask: 0.6082  decode.d0.loss_dice: 1.3849  decode.d1.loss_cls: 0.0925  decode.d1.loss_mask: 0.5686  decode.d1.loss_dice: 1.3339  decode.d2.loss_cls: 0.0847  decode.d2.loss_mask: 0.5686  decode.d2.loss_dice: 1.3204  decode.d3.loss_cls: 0.0901  decode.d3.loss_mask: 0.5740  decode.d3.loss_dice: 1.3383  decode.d4.loss_cls: 0.0923  decode.d4.loss_mask: 0.5772  decode.d4.loss_dice: 1.3150  decode.d5.loss_cls: 0.0882  decode.d5.loss_mask: 0.5850  decode.d5.loss_dice: 1.3473  decode.d6.loss_cls: 0.0787  decode.d6.loss_mask: 0.5831  decode.d6.loss_dice: 1.3580  decode.d7.loss_cls: 0.0886  decode.d7.loss_mask: 0.5653  decode.d7.loss_dice: 1.3355  decode.d8.loss_cls: 0.0836  decode.d8.loss_mask: 0.5686  decode.d8.loss_dice: 1.3474
11/15 10:30:39 - mmengine - INFO - Iter(train) [21300/90000]  base_lr: 7.8424e-05 lr: 7.8424e-06  eta: 11:32:06  time: 0.6043  data_time: 0.0103  memory: 10692  grad_norm: 413.2306  loss: 18.5092  decode.loss_cls: 0.1016  decode.loss_mask: 0.5985  decode.loss_dice: 1.1416  decode.d0.loss_cls: 0.1230  decode.d0.loss_mask: 0.6209  decode.d0.loss_dice: 1.2684  decode.d1.loss_cls: 0.1133  decode.d1.loss_mask: 0.5988  decode.d1.loss_dice: 1.1256  decode.d2.loss_cls: 0.1114  decode.d2.loss_mask: 0.5995  decode.d2.loss_dice: 1.1149  decode.d3.loss_cls: 0.0971  decode.d3.loss_mask: 0.6005  decode.d3.loss_dice: 1.1455  decode.d4.loss_cls: 0.0951  decode.d4.loss_mask: 0.5972  decode.d4.loss_dice: 1.1264  decode.d5.loss_cls: 0.0943  decode.d5.loss_mask: 0.5974  decode.d5.loss_dice: 1.1338  decode.d6.loss_cls: 0.1028  decode.d6.loss_mask: 0.5989  decode.d6.loss_dice: 1.1149  decode.d7.loss_cls: 0.1007  decode.d7.loss_mask: 0.5919  decode.d7.loss_dice: 1.1381  decode.d8.loss_cls: 0.0971  decode.d8.loss_mask: 0.6125  decode.d8.loss_dice: 1.1474
11/15 10:31:09 - mmengine - INFO - Iter(train) [21350/90000]  base_lr: 7.8372e-05 lr: 7.8372e-06  eta: 11:31:37  time: 0.6173  data_time: 0.0111  memory: 10713  grad_norm: 340.9003  loss: 17.4657  decode.loss_cls: 0.0733  decode.loss_mask: 0.4912  decode.loss_dice: 1.1671  decode.d0.loss_cls: 0.0752  decode.d0.loss_mask: 0.4911  decode.d0.loss_dice: 1.2530  decode.d1.loss_cls: 0.0971  decode.d1.loss_mask: 0.4692  decode.d1.loss_dice: 1.1994  decode.d2.loss_cls: 0.0816  decode.d2.loss_mask: 0.4651  decode.d2.loss_dice: 1.1855  decode.d3.loss_cls: 0.0811  decode.d3.loss_mask: 0.4681  decode.d3.loss_dice: 1.1859  decode.d4.loss_cls: 0.0750  decode.d4.loss_mask: 0.4648  decode.d4.loss_dice: 1.1850  decode.d5.loss_cls: 0.0712  decode.d5.loss_mask: 0.4831  decode.d5.loss_dice: 1.2014  decode.d6.loss_cls: 0.0659  decode.d6.loss_mask: 0.4904  decode.d6.loss_dice: 1.1708  decode.d7.loss_cls: 0.0669  decode.d7.loss_mask: 0.4890  decode.d7.loss_dice: 1.1780  decode.d8.loss_cls: 0.0765  decode.d8.loss_mask: 0.4829  decode.d8.loss_dice: 1.1810
11/15 10:31:40 - mmengine - INFO - Iter(train) [21400/90000]  base_lr: 7.8321e-05 lr: 7.8321e-06  eta: 11:31:08  time: 0.6109  data_time: 0.0106  memory: 10675  grad_norm: 372.9609  loss: 18.7052  decode.loss_cls: 0.0858  decode.loss_mask: 0.5478  decode.loss_dice: 1.2494  decode.d0.loss_cls: 0.0812  decode.d0.loss_mask: 0.5672  decode.d0.loss_dice: 1.3914  decode.d1.loss_cls: 0.0902  decode.d1.loss_mask: 0.5510  decode.d1.loss_dice: 1.2465  decode.d2.loss_cls: 0.0963  decode.d2.loss_mask: 0.5516  decode.d2.loss_dice: 1.1878  decode.d3.loss_cls: 0.0819  decode.d3.loss_mask: 0.5587  decode.d3.loss_dice: 1.1908  decode.d4.loss_cls: 0.0895  decode.d4.loss_mask: 0.5539  decode.d4.loss_dice: 1.2031  decode.d5.loss_cls: 0.0840  decode.d5.loss_mask: 0.5482  decode.d5.loss_dice: 1.2516  decode.d6.loss_cls: 0.0758  decode.d6.loss_mask: 0.5457  decode.d6.loss_dice: 1.2102  decode.d7.loss_cls: 0.0710  decode.d7.loss_mask: 0.5544  decode.d7.loss_dice: 1.1931  decode.d8.loss_cls: 0.0843  decode.d8.loss_mask: 0.5516  decode.d8.loss_dice: 1.2109
11/15 10:32:11 - mmengine - INFO - Iter(train) [21450/90000]  base_lr: 7.8270e-05 lr: 7.8270e-06  eta: 11:30:39  time: 0.6078  data_time: 0.0102  memory: 10656  grad_norm: 492.3633  loss: 19.7173  decode.loss_cls: 0.0740  decode.loss_mask: 0.6141  decode.loss_dice: 1.2820  decode.d0.loss_cls: 0.0756  decode.d0.loss_mask: 0.6482  decode.d0.loss_dice: 1.3391  decode.d1.loss_cls: 0.0666  decode.d1.loss_mask: 0.6083  decode.d1.loss_dice: 1.3099  decode.d2.loss_cls: 0.0681  decode.d2.loss_mask: 0.5792  decode.d2.loss_dice: 1.2962  decode.d3.loss_cls: 0.0594  decode.d3.loss_mask: 0.5947  decode.d3.loss_dice: 1.2964  decode.d4.loss_cls: 0.0640  decode.d4.loss_mask: 0.6031  decode.d4.loss_dice: 1.2966  decode.d5.loss_cls: 0.0740  decode.d5.loss_mask: 0.6049  decode.d5.loss_dice: 1.3110  decode.d6.loss_cls: 0.0599  decode.d6.loss_mask: 0.6004  decode.d6.loss_dice: 1.2863  decode.d7.loss_cls: 0.0679  decode.d7.loss_mask: 0.6070  decode.d7.loss_dice: 1.2780  decode.d8.loss_cls: 0.0669  decode.d8.loss_mask: 0.6022  decode.d8.loss_dice: 1.2834
11/15 10:32:41 - mmengine - INFO - Iter(train) [21500/90000]  base_lr: 7.8218e-05 lr: 7.8218e-06  eta: 11:30:09  time: 0.6079  data_time: 0.0106  memory: 10692  grad_norm: 290.9387  loss: 18.2625  decode.loss_cls: 0.0991  decode.loss_mask: 0.6217  decode.loss_dice: 1.0733  decode.d0.loss_cls: 0.1033  decode.d0.loss_mask: 0.6405  decode.d0.loss_dice: 1.1732  decode.d1.loss_cls: 0.0973  decode.d1.loss_mask: 0.6558  decode.d1.loss_dice: 1.1162  decode.d2.loss_cls: 0.0910  decode.d2.loss_mask: 0.6523  decode.d2.loss_dice: 1.1001  decode.d3.loss_cls: 0.0791  decode.d3.loss_mask: 0.6349  decode.d3.loss_dice: 1.0637  decode.d4.loss_cls: 0.0820  decode.d4.loss_mask: 0.6476  decode.d4.loss_dice: 1.0903  decode.d5.loss_cls: 0.0830  decode.d5.loss_mask: 0.6404  decode.d5.loss_dice: 1.0585  decode.d6.loss_cls: 0.0845  decode.d6.loss_mask: 0.6337  decode.d6.loss_dice: 1.0959  decode.d7.loss_cls: 0.0857  decode.d7.loss_mask: 0.6382  decode.d7.loss_dice: 1.1077  decode.d8.loss_cls: 0.0928  decode.d8.loss_mask: 0.6295  decode.d8.loss_dice: 1.0914
11/15 10:33:11 - mmengine - INFO - Iter(train) [21550/90000]  base_lr: 7.8167e-05 lr: 7.8167e-06  eta: 11:29:39  time: 0.6070  data_time: 0.0101  memory: 10692  grad_norm: 285.3182  loss: 18.3297  decode.loss_cls: 0.0516  decode.loss_mask: 0.5580  decode.loss_dice: 1.2143  decode.d0.loss_cls: 0.0758  decode.d0.loss_mask: 0.5723  decode.d0.loss_dice: 1.2768  decode.d1.loss_cls: 0.0653  decode.d1.loss_mask: 0.5548  decode.d1.loss_dice: 1.2263  decode.d2.loss_cls: 0.0671  decode.d2.loss_mask: 0.5600  decode.d2.loss_dice: 1.2027  decode.d3.loss_cls: 0.0638  decode.d3.loss_mask: 0.5356  decode.d3.loss_dice: 1.2029  decode.d4.loss_cls: 0.0692  decode.d4.loss_mask: 0.5399  decode.d4.loss_dice: 1.2106  decode.d5.loss_cls: 0.0727  decode.d5.loss_mask: 0.5404  decode.d5.loss_dice: 1.1928  decode.d6.loss_cls: 0.0680  decode.d6.loss_mask: 0.5595  decode.d6.loss_dice: 1.1938  decode.d7.loss_cls: 0.0584  decode.d7.loss_mask: 0.5590  decode.d7.loss_dice: 1.2225  decode.d8.loss_cls: 0.0550  decode.d8.loss_mask: 0.5408  decode.d8.loss_dice: 1.2197
11/15 10:33:42 - mmengine - INFO - Iter(train) [21600/90000]  base_lr: 7.8115e-05 lr: 7.8115e-06  eta: 11:29:12  time: 0.6357  data_time: 0.0121  memory: 10692  grad_norm: 651.2463  loss: 19.5417  decode.loss_cls: 0.0754  decode.loss_mask: 0.6578  decode.loss_dice: 1.2271  decode.d0.loss_cls: 0.0894  decode.d0.loss_mask: 0.6843  decode.d0.loss_dice: 1.2969  decode.d1.loss_cls: 0.0795  decode.d1.loss_mask: 0.6304  decode.d1.loss_dice: 1.2404  decode.d2.loss_cls: 0.0716  decode.d2.loss_mask: 0.6553  decode.d2.loss_dice: 1.2385  decode.d3.loss_cls: 0.0791  decode.d3.loss_mask: 0.6526  decode.d3.loss_dice: 1.2201  decode.d4.loss_cls: 0.0787  decode.d4.loss_mask: 0.6518  decode.d4.loss_dice: 1.2059  decode.d5.loss_cls: 0.0798  decode.d5.loss_mask: 0.6334  decode.d5.loss_dice: 1.2267  decode.d6.loss_cls: 0.0777  decode.d6.loss_mask: 0.6208  decode.d6.loss_dice: 1.2097  decode.d7.loss_cls: 0.0955  decode.d7.loss_mask: 0.6105  decode.d7.loss_dice: 1.2065  decode.d8.loss_cls: 0.0769  decode.d8.loss_mask: 0.6425  decode.d8.loss_dice: 1.2266
11/15 10:34:14 - mmengine - INFO - Iter(train) [21650/90000]  base_lr: 7.8064e-05 lr: 7.8064e-06  eta: 11:28:47  time: 0.6410  data_time: 0.0118  memory: 10692  grad_norm: 1109.2619  loss: 19.2352  decode.loss_cls: 0.0827  decode.loss_mask: 0.6570  decode.loss_dice: 1.2122  decode.d0.loss_cls: 0.0989  decode.d0.loss_mask: 0.6504  decode.d0.loss_dice: 1.2825  decode.d1.loss_cls: 0.0837  decode.d1.loss_mask: 0.5962  decode.d1.loss_dice: 1.2527  decode.d2.loss_cls: 0.1011  decode.d2.loss_mask: 0.5672  decode.d2.loss_dice: 1.1986  decode.d3.loss_cls: 0.0946  decode.d3.loss_mask: 0.5638  decode.d3.loss_dice: 1.2118  decode.d4.loss_cls: 0.1033  decode.d4.loss_mask: 0.6070  decode.d4.loss_dice: 1.1968  decode.d5.loss_cls: 0.0891  decode.d5.loss_mask: 0.6065  decode.d5.loss_dice: 1.1988  decode.d6.loss_cls: 0.0901  decode.d6.loss_mask: 0.6097  decode.d6.loss_dice: 1.1873  decode.d7.loss_cls: 0.0908  decode.d7.loss_mask: 0.6695  decode.d7.loss_dice: 1.2189  decode.d8.loss_cls: 0.0860  decode.d8.loss_mask: 0.6598  decode.d8.loss_dice: 1.1683
11/15 10:34:46 - mmengine - INFO - Iter(train) [21700/90000]  base_lr: 7.8013e-05 lr: 7.8013e-06  eta: 11:28:22  time: 0.6444  data_time: 0.0118  memory: 10656  grad_norm: 462.0048  loss: 18.7442  decode.loss_cls: 0.0823  decode.loss_mask: 0.5775  decode.loss_dice: 1.1850  decode.d0.loss_cls: 0.0698  decode.d0.loss_mask: 0.6235  decode.d0.loss_dice: 1.3236  decode.d1.loss_cls: 0.0778  decode.d1.loss_mask: 0.5870  decode.d1.loss_dice: 1.1911  decode.d2.loss_cls: 0.0720  decode.d2.loss_mask: 0.5929  decode.d2.loss_dice: 1.1997  decode.d3.loss_cls: 0.0677  decode.d3.loss_mask: 0.5873  decode.d3.loss_dice: 1.2129  decode.d4.loss_cls: 0.0640  decode.d4.loss_mask: 0.5728  decode.d4.loss_dice: 1.2191  decode.d5.loss_cls: 0.0725  decode.d5.loss_mask: 0.5778  decode.d5.loss_dice: 1.2123  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.5759  decode.d6.loss_dice: 1.2293  decode.d7.loss_cls: 0.0715  decode.d7.loss_mask: 0.5757  decode.d7.loss_dice: 1.2234  decode.d8.loss_cls: 0.0662  decode.d8.loss_mask: 0.5724  decode.d8.loss_dice: 1.1891
11/15 10:35:18 - mmengine - INFO - Iter(train) [21750/90000]  base_lr: 7.7961e-05 lr: 7.7961e-06  eta: 11:27:57  time: 0.6323  data_time: 0.0116  memory: 10728  grad_norm: 643.8296  loss: 18.0886  decode.loss_cls: 0.0607  decode.loss_mask: 0.6237  decode.loss_dice: 1.1152  decode.d0.loss_cls: 0.1072  decode.d0.loss_mask: 0.6456  decode.d0.loss_dice: 1.1811  decode.d1.loss_cls: 0.0954  decode.d1.loss_mask: 0.6236  decode.d1.loss_dice: 1.1065  decode.d2.loss_cls: 0.0808  decode.d2.loss_mask: 0.6131  decode.d2.loss_dice: 1.1104  decode.d3.loss_cls: 0.0753  decode.d3.loss_mask: 0.6203  decode.d3.loss_dice: 1.0820  decode.d4.loss_cls: 0.0638  decode.d4.loss_mask: 0.6190  decode.d4.loss_dice: 1.0859  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.6307  decode.d5.loss_dice: 1.0932  decode.d6.loss_cls: 0.0728  decode.d6.loss_mask: 0.6246  decode.d6.loss_dice: 1.1003  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.6215  decode.d7.loss_dice: 1.0940  decode.d8.loss_cls: 0.0753  decode.d8.loss_mask: 0.6343  decode.d8.loss_dice: 1.0945
11/15 10:35:49 - mmengine - INFO - Iter(train) [21800/90000]  base_lr: 7.7910e-05 lr: 7.7910e-06  eta: 11:27:28  time: 0.6036  data_time: 0.0097  memory: 10728  grad_norm: 442.1829  loss: 17.9501  decode.loss_cls: 0.0701  decode.loss_mask: 0.5184  decode.loss_dice: 1.2100  decode.d0.loss_cls: 0.0797  decode.d0.loss_mask: 0.5174  decode.d0.loss_dice: 1.2778  decode.d1.loss_cls: 0.0759  decode.d1.loss_mask: 0.5136  decode.d1.loss_dice: 1.2075  decode.d2.loss_cls: 0.0670  decode.d2.loss_mask: 0.5243  decode.d2.loss_dice: 1.1766  decode.d3.loss_cls: 0.0547  decode.d3.loss_mask: 0.5010  decode.d3.loss_dice: 1.2036  decode.d4.loss_cls: 0.0541  decode.d4.loss_mask: 0.5167  decode.d4.loss_dice: 1.2376  decode.d5.loss_cls: 0.0607  decode.d5.loss_mask: 0.5105  decode.d5.loss_dice: 1.2289  decode.d6.loss_cls: 0.0556  decode.d6.loss_mask: 0.4999  decode.d6.loss_dice: 1.2148  decode.d7.loss_cls: 0.0658  decode.d7.loss_mask: 0.5001  decode.d7.loss_dice: 1.2078  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 0.5068  decode.d8.loss_dice: 1.2375
11/15 10:36:19 - mmengine - INFO - Iter(train) [21850/90000]  base_lr: 7.7858e-05 lr: 7.7858e-06  eta: 11:26:59  time: 0.6014  data_time: 0.0097  memory: 10675  grad_norm: 365.1879  loss: 16.7311  decode.loss_cls: 0.0587  decode.loss_mask: 0.5526  decode.loss_dice: 1.0707  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.5958  decode.d0.loss_dice: 1.1049  decode.d1.loss_cls: 0.0438  decode.d1.loss_mask: 0.5576  decode.d1.loss_dice: 1.0992  decode.d2.loss_cls: 0.0557  decode.d2.loss_mask: 0.5443  decode.d2.loss_dice: 1.0571  decode.d3.loss_cls: 0.0468  decode.d3.loss_mask: 0.5602  decode.d3.loss_dice: 1.0619  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.5476  decode.d4.loss_dice: 1.0151  decode.d5.loss_cls: 0.0634  decode.d5.loss_mask: 0.5301  decode.d5.loss_dice: 1.0533  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.5512  decode.d6.loss_dice: 1.0425  decode.d7.loss_cls: 0.0538  decode.d7.loss_mask: 0.5519  decode.d7.loss_dice: 1.0591  decode.d8.loss_cls: 0.0584  decode.d8.loss_mask: 0.5438  decode.d8.loss_dice: 1.0678
11/15 10:36:50 - mmengine - INFO - Iter(train) [21900/90000]  base_lr: 7.7807e-05 lr: 7.7807e-06  eta: 11:26:29  time: 0.6053  data_time: 0.0099  memory: 10656  grad_norm: 347.2755  loss: 20.0256  decode.loss_cls: 0.0729  decode.loss_mask: 0.5620  decode.loss_dice: 1.3590  decode.d0.loss_cls: 0.0881  decode.d0.loss_mask: 0.5561  decode.d0.loss_dice: 1.4047  decode.d1.loss_cls: 0.0879  decode.d1.loss_mask: 0.5370  decode.d1.loss_dice: 1.3772  decode.d2.loss_cls: 0.0780  decode.d2.loss_mask: 0.5620  decode.d2.loss_dice: 1.3673  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 0.5535  decode.d3.loss_dice: 1.3767  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.5629  decode.d4.loss_dice: 1.3828  decode.d5.loss_cls: 0.0683  decode.d5.loss_mask: 0.5534  decode.d5.loss_dice: 1.3781  decode.d6.loss_cls: 0.0809  decode.d6.loss_mask: 0.5472  decode.d6.loss_dice: 1.3732  decode.d7.loss_cls: 0.0899  decode.d7.loss_mask: 0.5440  decode.d7.loss_dice: 1.3605  decode.d8.loss_cls: 0.0752  decode.d8.loss_mask: 0.5429  decode.d8.loss_dice: 1.3630
11/15 10:37:20 - mmengine - INFO - Iter(train) [21950/90000]  base_lr: 7.7756e-05 lr: 7.7756e-06  eta: 11:25:58  time: 0.6031  data_time: 0.0097  memory: 10656  grad_norm: 303.2400  loss: 18.7324  decode.loss_cls: 0.0780  decode.loss_mask: 0.5775  decode.loss_dice: 1.2016  decode.d0.loss_cls: 0.0922  decode.d0.loss_mask: 0.5937  decode.d0.loss_dice: 1.3158  decode.d1.loss_cls: 0.0857  decode.d1.loss_mask: 0.5580  decode.d1.loss_dice: 1.2167  decode.d2.loss_cls: 0.0881  decode.d2.loss_mask: 0.5523  decode.d2.loss_dice: 1.2240  decode.d3.loss_cls: 0.0791  decode.d3.loss_mask: 0.5616  decode.d3.loss_dice: 1.1871  decode.d4.loss_cls: 0.0896  decode.d4.loss_mask: 0.5700  decode.d4.loss_dice: 1.2037  decode.d5.loss_cls: 0.0851  decode.d5.loss_mask: 0.5667  decode.d5.loss_dice: 1.2120  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.5830  decode.d6.loss_dice: 1.1968  decode.d7.loss_cls: 0.0864  decode.d7.loss_mask: 0.5837  decode.d7.loss_dice: 1.2163  decode.d8.loss_cls: 0.0892  decode.d8.loss_mask: 0.5613  decode.d8.loss_dice: 1.1868
11/15 10:37:51 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 10:37:51 - mmengine - INFO - Iter(train) [22000/90000]  base_lr: 7.7704e-05 lr: 7.7704e-06  eta: 11:25:30  time: 0.6051  data_time: 0.0097  memory: 10692  grad_norm: 517.0530  loss: 19.5221  decode.loss_cls: 0.0600  decode.loss_mask: 0.6638  decode.loss_dice: 1.2156  decode.d0.loss_cls: 0.0706  decode.d0.loss_mask: 0.6866  decode.d0.loss_dice: 1.2884  decode.d1.loss_cls: 0.0630  decode.d1.loss_mask: 0.6816  decode.d1.loss_dice: 1.2072  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.6851  decode.d2.loss_dice: 1.2183  decode.d3.loss_cls: 0.0546  decode.d3.loss_mask: 0.6800  decode.d3.loss_dice: 1.1903  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.6734  decode.d4.loss_dice: 1.2273  decode.d5.loss_cls: 0.0719  decode.d5.loss_mask: 0.6654  decode.d5.loss_dice: 1.1967  decode.d6.loss_cls: 0.0545  decode.d6.loss_mask: 0.6823  decode.d6.loss_dice: 1.1916  decode.d7.loss_cls: 0.0485  decode.d7.loss_mask: 0.6719  decode.d7.loss_dice: 1.2237  decode.d8.loss_cls: 0.0600  decode.d8.loss_mask: 0.6672  decode.d8.loss_dice: 1.2144
11/15 10:38:21 - mmengine - INFO - Iter(train) [22050/90000]  base_lr: 7.7653e-05 lr: 7.7653e-06  eta: 11:25:00  time: 0.6052  data_time: 0.0098  memory: 10713  grad_norm: 295.2328  loss: 19.4210  decode.loss_cls: 0.0608  decode.loss_mask: 0.6095  decode.loss_dice: 1.2727  decode.d0.loss_cls: 0.0945  decode.d0.loss_mask: 0.5965  decode.d0.loss_dice: 1.3399  decode.d1.loss_cls: 0.0655  decode.d1.loss_mask: 0.5994  decode.d1.loss_dice: 1.2844  decode.d2.loss_cls: 0.0688  decode.d2.loss_mask: 0.5899  decode.d2.loss_dice: 1.2579  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.5969  decode.d3.loss_dice: 1.2560  decode.d4.loss_cls: 0.0665  decode.d4.loss_mask: 0.5967  decode.d4.loss_dice: 1.2457  decode.d5.loss_cls: 0.0613  decode.d5.loss_mask: 0.5973  decode.d5.loss_dice: 1.2541  decode.d6.loss_cls: 0.0675  decode.d6.loss_mask: 0.6080  decode.d6.loss_dice: 1.2723  decode.d7.loss_cls: 0.0727  decode.d7.loss_mask: 0.6177  decode.d7.loss_dice: 1.2545  decode.d8.loss_cls: 0.0770  decode.d8.loss_mask: 0.6099  decode.d8.loss_dice: 1.2624
11/15 10:38:51 - mmengine - INFO - Iter(train) [22100/90000]  base_lr: 7.7601e-05 lr: 7.7601e-06  eta: 11:24:29  time: 0.6032  data_time: 0.0097  memory: 10692  grad_norm: 476.4995  loss: 19.1552  decode.loss_cls: 0.0707  decode.loss_mask: 0.6039  decode.loss_dice: 1.2224  decode.d0.loss_cls: 0.0823  decode.d0.loss_mask: 0.6216  decode.d0.loss_dice: 1.2982  decode.d1.loss_cls: 0.0708  decode.d1.loss_mask: 0.5985  decode.d1.loss_dice: 1.2494  decode.d2.loss_cls: 0.0661  decode.d2.loss_mask: 0.6052  decode.d2.loss_dice: 1.2467  decode.d3.loss_cls: 0.0854  decode.d3.loss_mask: 0.6062  decode.d3.loss_dice: 1.2115  decode.d4.loss_cls: 0.0859  decode.d4.loss_mask: 0.6051  decode.d4.loss_dice: 1.1873  decode.d5.loss_cls: 0.0701  decode.d5.loss_mask: 0.6086  decode.d5.loss_dice: 1.2493  decode.d6.loss_cls: 0.0738  decode.d6.loss_mask: 0.6011  decode.d6.loss_dice: 1.2186  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.5986  decode.d7.loss_dice: 1.2517  decode.d8.loss_cls: 0.0718  decode.d8.loss_mask: 0.6018  decode.d8.loss_dice: 1.2298
11/15 10:39:21 - mmengine - INFO - Iter(train) [22150/90000]  base_lr: 7.7550e-05 lr: 7.7550e-06  eta: 11:23:59  time: 0.6086  data_time: 0.0100  memory: 10675  grad_norm: 591.7607  loss: 20.4549  decode.loss_cls: 0.0808  decode.loss_mask: 0.7189  decode.loss_dice: 1.2104  decode.d0.loss_cls: 0.0931  decode.d0.loss_mask: 0.7391  decode.d0.loss_dice: 1.3049  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.7141  decode.d1.loss_dice: 1.2785  decode.d2.loss_cls: 0.0697  decode.d2.loss_mask: 0.7165  decode.d2.loss_dice: 1.2292  decode.d3.loss_cls: 0.0876  decode.d3.loss_mask: 0.7143  decode.d3.loss_dice: 1.1981  decode.d4.loss_cls: 0.0765  decode.d4.loss_mask: 0.7255  decode.d4.loss_dice: 1.2716  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 0.7354  decode.d5.loss_dice: 1.2502  decode.d6.loss_cls: 0.0900  decode.d6.loss_mask: 0.6969  decode.d6.loss_dice: 1.2088  decode.d7.loss_cls: 0.0777  decode.d7.loss_mask: 0.7203  decode.d7.loss_dice: 1.2686  decode.d8.loss_cls: 0.0845  decode.d8.loss_mask: 0.7183  decode.d8.loss_dice: 1.2294
11/15 10:39:52 - mmengine - INFO - Iter(train) [22200/90000]  base_lr: 7.7498e-05 lr: 7.7498e-06  eta: 11:23:29  time: 0.6049  data_time: 0.0098  memory: 10713  grad_norm: 317.2276  loss: 20.5370  decode.loss_cls: 0.1029  decode.loss_mask: 0.6405  decode.loss_dice: 1.3566  decode.d0.loss_cls: 0.1031  decode.d0.loss_mask: 0.5658  decode.d0.loss_dice: 1.4463  decode.d1.loss_cls: 0.0978  decode.d1.loss_mask: 0.5615  decode.d1.loss_dice: 1.3829  decode.d2.loss_cls: 0.1096  decode.d2.loss_mask: 0.5619  decode.d2.loss_dice: 1.3653  decode.d3.loss_cls: 0.1073  decode.d3.loss_mask: 0.6099  decode.d3.loss_dice: 1.3250  decode.d4.loss_cls: 0.1153  decode.d4.loss_mask: 0.5788  decode.d4.loss_dice: 1.3666  decode.d5.loss_cls: 0.0915  decode.d5.loss_mask: 0.5916  decode.d5.loss_dice: 1.3625  decode.d6.loss_cls: 0.0937  decode.d6.loss_mask: 0.5875  decode.d6.loss_dice: 1.3475  decode.d7.loss_cls: 0.1022  decode.d7.loss_mask: 0.5707  decode.d7.loss_dice: 1.3758  decode.d8.loss_cls: 0.0979  decode.d8.loss_mask: 0.5681  decode.d8.loss_dice: 1.3511
11/15 10:40:22 - mmengine - INFO - Iter(train) [22250/90000]  base_lr: 7.7447e-05 lr: 7.7447e-06  eta: 11:22:59  time: 0.6031  data_time: 0.0098  memory: 10692  grad_norm: 360.2696  loss: 16.2530  decode.loss_cls: 0.0695  decode.loss_mask: 0.4667  decode.loss_dice: 1.1035  decode.d0.loss_cls: 0.0923  decode.d0.loss_mask: 0.4678  decode.d0.loss_dice: 1.1523  decode.d1.loss_cls: 0.0716  decode.d1.loss_mask: 0.4333  decode.d1.loss_dice: 1.0683  decode.d2.loss_cls: 0.0767  decode.d2.loss_mask: 0.4386  decode.d2.loss_dice: 1.0613  decode.d3.loss_cls: 0.0820  decode.d3.loss_mask: 0.4494  decode.d3.loss_dice: 1.0593  decode.d4.loss_cls: 0.0708  decode.d4.loss_mask: 0.4712  decode.d4.loss_dice: 1.0737  decode.d5.loss_cls: 0.0686  decode.d5.loss_mask: 0.4712  decode.d5.loss_dice: 1.0888  decode.d6.loss_cls: 0.0605  decode.d6.loss_mask: 0.4681  decode.d6.loss_dice: 1.1110  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.4714  decode.d7.loss_dice: 1.1036  decode.d8.loss_cls: 0.0702  decode.d8.loss_mask: 0.4723  decode.d8.loss_dice: 1.0883
11/15 10:40:52 - mmengine - INFO - Iter(train) [22300/90000]  base_lr: 7.7396e-05 lr: 7.7396e-06  eta: 11:22:29  time: 0.6078  data_time: 0.0098  memory: 10675  grad_norm: 574.8921  loss: 20.3504  decode.loss_cls: 0.1088  decode.loss_mask: 0.5554  decode.loss_dice: 1.3874  decode.d0.loss_cls: 0.1161  decode.d0.loss_mask: 0.5589  decode.d0.loss_dice: 1.4809  decode.d1.loss_cls: 0.1327  decode.d1.loss_mask: 0.5463  decode.d1.loss_dice: 1.3535  decode.d2.loss_cls: 0.1133  decode.d2.loss_mask: 0.5591  decode.d2.loss_dice: 1.3858  decode.d3.loss_cls: 0.1124  decode.d3.loss_mask: 0.5630  decode.d3.loss_dice: 1.3395  decode.d4.loss_cls: 0.1107  decode.d4.loss_mask: 0.5547  decode.d4.loss_dice: 1.3559  decode.d5.loss_cls: 0.1100  decode.d5.loss_mask: 0.5509  decode.d5.loss_dice: 1.3414  decode.d6.loss_cls: 0.1247  decode.d6.loss_mask: 0.5605  decode.d6.loss_dice: 1.2942  decode.d7.loss_cls: 0.1194  decode.d7.loss_mask: 0.5513  decode.d7.loss_dice: 1.3523  decode.d8.loss_cls: 0.1139  decode.d8.loss_mask: 0.5644  decode.d8.loss_dice: 1.3329
11/15 10:41:23 - mmengine - INFO - Iter(train) [22350/90000]  base_lr: 7.7344e-05 lr: 7.7344e-06  eta: 11:21:59  time: 0.6067  data_time: 0.0097  memory: 10675  grad_norm: 275.8487  loss: 19.9902  decode.loss_cls: 0.1029  decode.loss_mask: 0.5440  decode.loss_dice: 1.3650  decode.d0.loss_cls: 0.1011  decode.d0.loss_mask: 0.5342  decode.d0.loss_dice: 1.4294  decode.d1.loss_cls: 0.1007  decode.d1.loss_mask: 0.5139  decode.d1.loss_dice: 1.3675  decode.d2.loss_cls: 0.1239  decode.d2.loss_mask: 0.5299  decode.d2.loss_dice: 1.3714  decode.d3.loss_cls: 0.0907  decode.d3.loss_mask: 0.5334  decode.d3.loss_dice: 1.3592  decode.d4.loss_cls: 0.0929  decode.d4.loss_mask: 0.5409  decode.d4.loss_dice: 1.3635  decode.d5.loss_cls: 0.1174  decode.d5.loss_mask: 0.5409  decode.d5.loss_dice: 1.3392  decode.d6.loss_cls: 0.0890  decode.d6.loss_mask: 0.5333  decode.d6.loss_dice: 1.3562  decode.d7.loss_cls: 0.1182  decode.d7.loss_mask: 0.5248  decode.d7.loss_dice: 1.3242  decode.d8.loss_cls: 0.1006  decode.d8.loss_mask: 0.5395  decode.d8.loss_dice: 1.3426
11/15 10:41:53 - mmengine - INFO - Iter(train) [22400/90000]  base_lr: 7.7293e-05 lr: 7.7293e-06  eta: 11:21:29  time: 0.6066  data_time: 0.0097  memory: 10692  grad_norm: 527.9461  loss: 19.3100  decode.loss_cls: 0.0793  decode.loss_mask: 0.6436  decode.loss_dice: 1.2028  decode.d0.loss_cls: 0.0787  decode.d0.loss_mask: 0.6625  decode.d0.loss_dice: 1.2575  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.6733  decode.d1.loss_dice: 1.2161  decode.d2.loss_cls: 0.0831  decode.d2.loss_mask: 0.6536  decode.d2.loss_dice: 1.1661  decode.d3.loss_cls: 0.0661  decode.d3.loss_mask: 0.6414  decode.d3.loss_dice: 1.1786  decode.d4.loss_cls: 0.0698  decode.d4.loss_mask: 0.6462  decode.d4.loss_dice: 1.1819  decode.d5.loss_cls: 0.0721  decode.d5.loss_mask: 0.6666  decode.d5.loss_dice: 1.1889  decode.d6.loss_cls: 0.0594  decode.d6.loss_mask: 0.6404  decode.d6.loss_dice: 1.2119  decode.d7.loss_cls: 0.0768  decode.d7.loss_mask: 0.6961  decode.d7.loss_dice: 1.1760  decode.d8.loss_cls: 0.0826  decode.d8.loss_mask: 0.6922  decode.d8.loss_dice: 1.1878
11/15 10:42:23 - mmengine - INFO - Iter(train) [22450/90000]  base_lr: 7.7241e-05 lr: 7.7241e-06  eta: 11:20:59  time: 0.6077  data_time: 0.0099  memory: 10675  grad_norm: 609.6785  loss: 22.4340  decode.loss_cls: 0.0992  decode.loss_mask: 0.7638  decode.loss_dice: 1.3472  decode.d0.loss_cls: 0.1203  decode.d0.loss_mask: 0.7870  decode.d0.loss_dice: 1.4386  decode.d1.loss_cls: 0.0834  decode.d1.loss_mask: 0.7398  decode.d1.loss_dice: 1.4125  decode.d2.loss_cls: 0.0885  decode.d2.loss_mask: 0.7685  decode.d2.loss_dice: 1.4011  decode.d3.loss_cls: 0.0866  decode.d3.loss_mask: 0.7717  decode.d3.loss_dice: 1.3763  decode.d4.loss_cls: 0.0938  decode.d4.loss_mask: 0.7661  decode.d4.loss_dice: 1.3690  decode.d5.loss_cls: 0.0955  decode.d5.loss_mask: 0.7885  decode.d5.loss_dice: 1.3677  decode.d6.loss_cls: 0.0999  decode.d6.loss_mask: 0.7407  decode.d6.loss_dice: 1.3655  decode.d7.loss_cls: 0.0919  decode.d7.loss_mask: 0.7559  decode.d7.loss_dice: 1.3932  decode.d8.loss_cls: 0.0934  decode.d8.loss_mask: 0.7577  decode.d8.loss_dice: 1.3707
11/15 10:42:54 - mmengine - INFO - Iter(train) [22500/90000]  base_lr: 7.7190e-05 lr: 7.7190e-06  eta: 11:20:29  time: 0.6047  data_time: 0.0098  memory: 10656  grad_norm: 319.2621  loss: 20.8297  decode.loss_cls: 0.0774  decode.loss_mask: 0.6865  decode.loss_dice: 1.2807  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.7497  decode.d0.loss_dice: 1.3605  decode.d1.loss_cls: 0.0823  decode.d1.loss_mask: 0.7026  decode.d1.loss_dice: 1.3136  decode.d2.loss_cls: 0.0691  decode.d2.loss_mask: 0.7049  decode.d2.loss_dice: 1.3180  decode.d3.loss_cls: 0.0767  decode.d3.loss_mask: 0.6940  decode.d3.loss_dice: 1.2795  decode.d4.loss_cls: 0.0680  decode.d4.loss_mask: 0.6941  decode.d4.loss_dice: 1.3016  decode.d5.loss_cls: 0.0696  decode.d5.loss_mask: 0.6940  decode.d5.loss_dice: 1.2981  decode.d6.loss_cls: 0.0846  decode.d6.loss_mask: 0.6842  decode.d6.loss_dice: 1.2819  decode.d7.loss_cls: 0.0767  decode.d7.loss_mask: 0.7059  decode.d7.loss_dice: 1.3142  decode.d8.loss_cls: 0.0795  decode.d8.loss_mask: 0.7097  decode.d8.loss_dice: 1.2982
11/15 10:43:24 - mmengine - INFO - Iter(train) [22550/90000]  base_lr: 7.7138e-05 lr: 7.7138e-06  eta: 11:19:59  time: 0.6070  data_time: 0.0099  memory: 10675  grad_norm: 465.1155  loss: 17.0701  decode.loss_cls: 0.0584  decode.loss_mask: 0.5286  decode.loss_dice: 1.1073  decode.d0.loss_cls: 0.0876  decode.d0.loss_mask: 0.5345  decode.d0.loss_dice: 1.1619  decode.d1.loss_cls: 0.0736  decode.d1.loss_mask: 0.5162  decode.d1.loss_dice: 1.1388  decode.d2.loss_cls: 0.0620  decode.d2.loss_mask: 0.5314  decode.d2.loss_dice: 1.1253  decode.d3.loss_cls: 0.0677  decode.d3.loss_mask: 0.5246  decode.d3.loss_dice: 1.1224  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.5199  decode.d4.loss_dice: 1.0826  decode.d5.loss_cls: 0.0735  decode.d5.loss_mask: 0.5192  decode.d5.loss_dice: 1.0875  decode.d6.loss_cls: 0.0635  decode.d6.loss_mask: 0.5327  decode.d6.loss_dice: 1.0961  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.5292  decode.d7.loss_dice: 1.0743  decode.d8.loss_cls: 0.0724  decode.d8.loss_mask: 0.5225  decode.d8.loss_dice: 1.1209
11/15 10:43:54 - mmengine - INFO - Iter(train) [22600/90000]  base_lr: 7.7087e-05 lr: 7.7087e-06  eta: 11:19:29  time: 0.6055  data_time: 0.0098  memory: 10675  grad_norm: 517.4989  loss: 19.3551  decode.loss_cls: 0.0462  decode.loss_mask: 0.6290  decode.loss_dice: 1.2791  decode.d0.loss_cls: 0.0840  decode.d0.loss_mask: 0.6035  decode.d0.loss_dice: 1.3285  decode.d1.loss_cls: 0.0696  decode.d1.loss_mask: 0.6088  decode.d1.loss_dice: 1.2767  decode.d2.loss_cls: 0.0728  decode.d2.loss_mask: 0.6008  decode.d2.loss_dice: 1.2467  decode.d3.loss_cls: 0.0525  decode.d3.loss_mask: 0.6066  decode.d3.loss_dice: 1.2704  decode.d4.loss_cls: 0.0554  decode.d4.loss_mask: 0.6050  decode.d4.loss_dice: 1.2526  decode.d5.loss_cls: 0.0519  decode.d5.loss_mask: 0.5998  decode.d5.loss_dice: 1.2707  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.6011  decode.d6.loss_dice: 1.2478  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.6074  decode.d7.loss_dice: 1.2605  decode.d8.loss_cls: 0.0627  decode.d8.loss_mask: 0.6033  decode.d8.loss_dice: 1.2459
11/15 10:44:25 - mmengine - INFO - Iter(train) [22650/90000]  base_lr: 7.7035e-05 lr: 7.7035e-06  eta: 11:18:59  time: 0.6061  data_time: 0.0097  memory: 10675  grad_norm: 284.3551  loss: 18.9578  decode.loss_cls: 0.0454  decode.loss_mask: 0.5637  decode.loss_dice: 1.2886  decode.d0.loss_cls: 0.0733  decode.d0.loss_mask: 0.5808  decode.d0.loss_dice: 1.3120  decode.d1.loss_cls: 0.0632  decode.d1.loss_mask: 0.5592  decode.d1.loss_dice: 1.2900  decode.d2.loss_cls: 0.0575  decode.d2.loss_mask: 0.5624  decode.d2.loss_dice: 1.2581  decode.d3.loss_cls: 0.0446  decode.d3.loss_mask: 0.5580  decode.d3.loss_dice: 1.2483  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.5584  decode.d4.loss_dice: 1.2844  decode.d5.loss_cls: 0.0561  decode.d5.loss_mask: 0.5637  decode.d5.loss_dice: 1.2799  decode.d6.loss_cls: 0.0444  decode.d6.loss_mask: 0.5672  decode.d6.loss_dice: 1.2792  decode.d7.loss_cls: 0.0426  decode.d7.loss_mask: 0.5623  decode.d7.loss_dice: 1.2810  decode.d8.loss_cls: 0.0473  decode.d8.loss_mask: 0.5629  decode.d8.loss_dice: 1.2815
11/15 10:44:55 - mmengine - INFO - Iter(train) [22700/90000]  base_lr: 7.6984e-05 lr: 7.6984e-06  eta: 11:18:29  time: 0.6060  data_time: 0.0096  memory: 10641  grad_norm: 337.7918  loss: 19.7408  decode.loss_cls: 0.0917  decode.loss_mask: 0.6913  decode.loss_dice: 1.2047  decode.d0.loss_cls: 0.1095  decode.d0.loss_mask: 0.6757  decode.d0.loss_dice: 1.3015  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.6745  decode.d1.loss_dice: 1.2571  decode.d2.loss_cls: 0.0836  decode.d2.loss_mask: 0.6469  decode.d2.loss_dice: 1.2180  decode.d3.loss_cls: 0.0830  decode.d3.loss_mask: 0.6408  decode.d3.loss_dice: 1.2124  decode.d4.loss_cls: 0.0879  decode.d4.loss_mask: 0.6451  decode.d4.loss_dice: 1.2129  decode.d5.loss_cls: 0.0984  decode.d5.loss_mask: 0.6437  decode.d5.loss_dice: 1.2139  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 0.6381  decode.d6.loss_dice: 1.2033  decode.d7.loss_cls: 0.0989  decode.d7.loss_mask: 0.6479  decode.d7.loss_dice: 1.2150  decode.d8.loss_cls: 0.0908  decode.d8.loss_mask: 0.6518  decode.d8.loss_dice: 1.2255
11/15 10:45:25 - mmengine - INFO - Iter(train) [22750/90000]  base_lr: 7.6932e-05 lr: 7.6932e-06  eta: 11:17:59  time: 0.6086  data_time: 0.0099  memory: 10675  grad_norm: 1000.7161  loss: 20.5946  decode.loss_cls: 0.0727  decode.loss_mask: 0.6212  decode.loss_dice: 1.3432  decode.d0.loss_cls: 0.0866  decode.d0.loss_mask: 0.6698  decode.d0.loss_dice: 1.4295  decode.d1.loss_cls: 0.0913  decode.d1.loss_mask: 0.6112  decode.d1.loss_dice: 1.3801  decode.d2.loss_cls: 0.0757  decode.d2.loss_mask: 0.6095  decode.d2.loss_dice: 1.3309  decode.d3.loss_cls: 0.0818  decode.d3.loss_mask: 0.6082  decode.d3.loss_dice: 1.3418  decode.d4.loss_cls: 0.0766  decode.d4.loss_mask: 0.6164  decode.d4.loss_dice: 1.3549  decode.d5.loss_cls: 0.0792  decode.d5.loss_mask: 0.5989  decode.d5.loss_dice: 1.3509  decode.d6.loss_cls: 0.0782  decode.d6.loss_mask: 0.6260  decode.d6.loss_dice: 1.3560  decode.d7.loss_cls: 0.0791  decode.d7.loss_mask: 0.6224  decode.d7.loss_dice: 1.3444  decode.d8.loss_cls: 0.0780  decode.d8.loss_mask: 0.6249  decode.d8.loss_dice: 1.3550
11/15 10:45:56 - mmengine - INFO - Iter(train) [22800/90000]  base_lr: 7.6881e-05 lr: 7.6881e-06  eta: 11:17:29  time: 0.6060  data_time: 0.0099  memory: 10656  grad_norm: 354.4870  loss: 19.8009  decode.loss_cls: 0.0856  decode.loss_mask: 0.6500  decode.loss_dice: 1.2565  decode.d0.loss_cls: 0.0973  decode.d0.loss_mask: 0.6318  decode.d0.loss_dice: 1.3473  decode.d1.loss_cls: 0.0854  decode.d1.loss_mask: 0.6378  decode.d1.loss_dice: 1.2337  decode.d2.loss_cls: 0.1036  decode.d2.loss_mask: 0.6245  decode.d2.loss_dice: 1.2491  decode.d3.loss_cls: 0.0987  decode.d3.loss_mask: 0.6314  decode.d3.loss_dice: 1.2388  decode.d4.loss_cls: 0.1027  decode.d4.loss_mask: 0.6152  decode.d4.loss_dice: 1.2368  decode.d5.loss_cls: 0.0942  decode.d5.loss_mask: 0.6281  decode.d5.loss_dice: 1.2473  decode.d6.loss_cls: 0.0837  decode.d6.loss_mask: 0.6319  decode.d6.loss_dice: 1.2357  decode.d7.loss_cls: 0.0902  decode.d7.loss_mask: 0.6314  decode.d7.loss_dice: 1.2500  decode.d8.loss_cls: 0.1079  decode.d8.loss_mask: 0.6190  decode.d8.loss_dice: 1.2550
11/15 10:46:26 - mmengine - INFO - Iter(train) [22850/90000]  base_lr: 7.6829e-05 lr: 7.6829e-06  eta: 11:16:59  time: 0.6058  data_time: 0.0099  memory: 10675  grad_norm: 688.1082  loss: 17.8864  decode.loss_cls: 0.0715  decode.loss_mask: 0.6337  decode.loss_dice: 1.0648  decode.d0.loss_cls: 0.1042  decode.d0.loss_mask: 0.5827  decode.d0.loss_dice: 1.1497  decode.d1.loss_cls: 0.0684  decode.d1.loss_mask: 0.6242  decode.d1.loss_dice: 1.1007  decode.d2.loss_cls: 0.0736  decode.d2.loss_mask: 0.6136  decode.d2.loss_dice: 1.0867  decode.d3.loss_cls: 0.0762  decode.d3.loss_mask: 0.6366  decode.d3.loss_dice: 1.0877  decode.d4.loss_cls: 0.0705  decode.d4.loss_mask: 0.6266  decode.d4.loss_dice: 1.0883  decode.d5.loss_cls: 0.0742  decode.d5.loss_mask: 0.6280  decode.d5.loss_dice: 1.0910  decode.d6.loss_cls: 0.0709  decode.d6.loss_mask: 0.6108  decode.d6.loss_dice: 1.0757  decode.d7.loss_cls: 0.0660  decode.d7.loss_mask: 0.6341  decode.d7.loss_dice: 1.0910  decode.d8.loss_cls: 0.0778  decode.d8.loss_mask: 0.6373  decode.d8.loss_dice: 1.0701
11/15 10:46:56 - mmengine - INFO - Iter(train) [22900/90000]  base_lr: 7.6778e-05 lr: 7.6778e-06  eta: 11:16:29  time: 0.6048  data_time: 0.0099  memory: 10675  grad_norm: 299.7535  loss: 15.7816  decode.loss_cls: 0.0401  decode.loss_mask: 0.4562  decode.loss_dice: 1.0639  decode.d0.loss_cls: 0.0635  decode.d0.loss_mask: 0.5054  decode.d0.loss_dice: 1.1677  decode.d1.loss_cls: 0.0589  decode.d1.loss_mask: 0.4678  decode.d1.loss_dice: 1.0824  decode.d2.loss_cls: 0.0464  decode.d2.loss_mask: 0.4657  decode.d2.loss_dice: 1.0198  decode.d3.loss_cls: 0.0464  decode.d3.loss_mask: 0.4598  decode.d3.loss_dice: 1.0329  decode.d4.loss_cls: 0.0377  decode.d4.loss_mask: 0.4658  decode.d4.loss_dice: 1.0585  decode.d5.loss_cls: 0.0384  decode.d5.loss_mask: 0.4630  decode.d5.loss_dice: 1.0790  decode.d6.loss_cls: 0.0488  decode.d6.loss_mask: 0.4686  decode.d6.loss_dice: 1.0386  decode.d7.loss_cls: 0.0484  decode.d7.loss_mask: 0.4549  decode.d7.loss_dice: 1.0368  decode.d8.loss_cls: 0.0395  decode.d8.loss_mask: 0.4636  decode.d8.loss_dice: 1.0630
11/15 10:47:27 - mmengine - INFO - Iter(train) [22950/90000]  base_lr: 7.6726e-05 lr: 7.6726e-06  eta: 11:15:59  time: 0.6085  data_time: 0.0100  memory: 10692  grad_norm: 491.7880  loss: 19.1119  decode.loss_cls: 0.0827  decode.loss_mask: 0.5332  decode.loss_dice: 1.2829  decode.d0.loss_cls: 0.0909  decode.d0.loss_mask: 0.5541  decode.d0.loss_dice: 1.4007  decode.d1.loss_cls: 0.0708  decode.d1.loss_mask: 0.5294  decode.d1.loss_dice: 1.3470  decode.d2.loss_cls: 0.0770  decode.d2.loss_mask: 0.5283  decode.d2.loss_dice: 1.2926  decode.d3.loss_cls: 0.0733  decode.d3.loss_mask: 0.5173  decode.d3.loss_dice: 1.2655  decode.d4.loss_cls: 0.0740  decode.d4.loss_mask: 0.5303  decode.d4.loss_dice: 1.2782  decode.d5.loss_cls: 0.0714  decode.d5.loss_mask: 0.5289  decode.d5.loss_dice: 1.2965  decode.d6.loss_cls: 0.0781  decode.d6.loss_mask: 0.5249  decode.d6.loss_dice: 1.2926  decode.d7.loss_cls: 0.0759  decode.d7.loss_mask: 0.5319  decode.d7.loss_dice: 1.2692  decode.d8.loss_cls: 0.0718  decode.d8.loss_mask: 0.5556  decode.d8.loss_dice: 1.2871
11/15 10:47:57 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 10:47:57 - mmengine - INFO - Iter(train) [23000/90000]  base_lr: 7.6675e-05 lr: 7.6675e-06  eta: 11:15:28  time: 0.6056  data_time: 0.0098  memory: 10728  grad_norm: 297.6627  loss: 19.9855  decode.loss_cls: 0.1169  decode.loss_mask: 0.5937  decode.loss_dice: 1.2765  decode.d0.loss_cls: 0.0854  decode.d0.loss_mask: 0.6338  decode.d0.loss_dice: 1.3792  decode.d1.loss_cls: 0.1044  decode.d1.loss_mask: 0.6151  decode.d1.loss_dice: 1.3261  decode.d2.loss_cls: 0.0889  decode.d2.loss_mask: 0.6055  decode.d2.loss_dice: 1.3055  decode.d3.loss_cls: 0.1144  decode.d3.loss_mask: 0.5896  decode.d3.loss_dice: 1.2533  decode.d4.loss_cls: 0.1171  decode.d4.loss_mask: 0.6081  decode.d4.loss_dice: 1.2803  decode.d5.loss_cls: 0.1113  decode.d5.loss_mask: 0.5941  decode.d5.loss_dice: 1.2781  decode.d6.loss_cls: 0.0969  decode.d6.loss_mask: 0.6131  decode.d6.loss_dice: 1.2759  decode.d7.loss_cls: 0.1145  decode.d7.loss_mask: 0.5423  decode.d7.loss_dice: 1.2708  decode.d8.loss_cls: 0.1052  decode.d8.loss_mask: 0.5914  decode.d8.loss_dice: 1.2981
11/15 10:48:27 - mmengine - INFO - Iter(train) [23050/90000]  base_lr: 7.6623e-05 lr: 7.6623e-06  eta: 11:14:58  time: 0.5971  data_time: 0.0096  memory: 10656  grad_norm: 268.8128  loss: 18.4497  decode.loss_cls: 0.0382  decode.loss_mask: 0.6957  decode.loss_dice: 1.1981  decode.d0.loss_cls: 0.0578  decode.d0.loss_mask: 0.6042  decode.d0.loss_dice: 1.2357  decode.d1.loss_cls: 0.0482  decode.d1.loss_mask: 0.5877  decode.d1.loss_dice: 1.1778  decode.d2.loss_cls: 0.0516  decode.d2.loss_mask: 0.5821  decode.d2.loss_dice: 1.1883  decode.d3.loss_cls: 0.0479  decode.d3.loss_mask: 0.5873  decode.d3.loss_dice: 1.1830  decode.d4.loss_cls: 0.0405  decode.d4.loss_mask: 0.5943  decode.d4.loss_dice: 1.1950  decode.d5.loss_cls: 0.0403  decode.d5.loss_mask: 0.5919  decode.d5.loss_dice: 1.1791  decode.d6.loss_cls: 0.0420  decode.d6.loss_mask: 0.5883  decode.d6.loss_dice: 1.2127  decode.d7.loss_cls: 0.0483  decode.d7.loss_mask: 0.5932  decode.d7.loss_dice: 1.2031  decode.d8.loss_cls: 0.0377  decode.d8.loss_mask: 0.5908  decode.d8.loss_dice: 1.2090
11/15 10:48:57 - mmengine - INFO - Iter(train) [23100/90000]  base_lr: 7.6572e-05 lr: 7.6572e-06  eta: 11:14:27  time: 0.5976  data_time: 0.0097  memory: 10656  grad_norm: 262.2668  loss: 17.0770  decode.loss_cls: 0.0504  decode.loss_mask: 0.5298  decode.loss_dice: 1.1143  decode.d0.loss_cls: 0.0805  decode.d0.loss_mask: 0.5650  decode.d0.loss_dice: 1.1382  decode.d1.loss_cls: 0.0559  decode.d1.loss_mask: 0.5314  decode.d1.loss_dice: 1.1156  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 0.5228  decode.d2.loss_dice: 1.1015  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.5376  decode.d3.loss_dice: 1.0876  decode.d4.loss_cls: 0.0451  decode.d4.loss_mask: 0.5439  decode.d4.loss_dice: 1.1230  decode.d5.loss_cls: 0.0519  decode.d5.loss_mask: 0.5278  decode.d5.loss_dice: 1.1053  decode.d6.loss_cls: 0.0416  decode.d6.loss_mask: 0.5503  decode.d6.loss_dice: 1.1489  decode.d7.loss_cls: 0.0482  decode.d7.loss_mask: 0.5416  decode.d7.loss_dice: 1.1250  decode.d8.loss_cls: 0.0499  decode.d8.loss_mask: 0.5233  decode.d8.loss_dice: 1.0984
11/15 10:49:29 - mmengine - INFO - Iter(train) [23150/90000]  base_lr: 7.6520e-05 lr: 7.6520e-06  eta: 11:14:03  time: 0.5977  data_time: 0.0095  memory: 10713  grad_norm: 390.2792  loss: 18.8368  decode.loss_cls: 0.0568  decode.loss_mask: 0.6090  decode.loss_dice: 1.1972  decode.d0.loss_cls: 0.0870  decode.d0.loss_mask: 0.6532  decode.d0.loss_dice: 1.2695  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.6040  decode.d1.loss_dice: 1.2127  decode.d2.loss_cls: 0.0599  decode.d2.loss_mask: 0.6229  decode.d2.loss_dice: 1.2097  decode.d3.loss_cls: 0.0656  decode.d3.loss_mask: 0.6023  decode.d3.loss_dice: 1.1783  decode.d4.loss_cls: 0.0650  decode.d4.loss_mask: 0.6013  decode.d4.loss_dice: 1.2049  decode.d5.loss_cls: 0.0638  decode.d5.loss_mask: 0.5886  decode.d5.loss_dice: 1.1930  decode.d6.loss_cls: 0.0623  decode.d6.loss_mask: 0.5973  decode.d6.loss_dice: 1.1819  decode.d7.loss_cls: 0.0588  decode.d7.loss_mask: 0.6062  decode.d7.loss_dice: 1.2314  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 0.5995  decode.d8.loss_dice: 1.2259
11/15 10:49:59 - mmengine - INFO - Iter(train) [23200/90000]  base_lr: 7.6469e-05 lr: 7.6469e-06  eta: 11:13:32  time: 0.5975  data_time: 0.0096  memory: 10713  grad_norm: 609.4513  loss: 18.0916  decode.loss_cls: 0.0808  decode.loss_mask: 0.6076  decode.loss_dice: 1.1124  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 0.5990  decode.d0.loss_dice: 1.2112  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.5976  decode.d1.loss_dice: 1.1327  decode.d2.loss_cls: 0.0832  decode.d2.loss_mask: 0.5830  decode.d2.loss_dice: 1.1210  decode.d3.loss_cls: 0.0848  decode.d3.loss_mask: 0.5990  decode.d3.loss_dice: 1.1020  decode.d4.loss_cls: 0.0818  decode.d4.loss_mask: 0.5965  decode.d4.loss_dice: 1.1360  decode.d5.loss_cls: 0.0840  decode.d5.loss_mask: 0.6071  decode.d5.loss_dice: 1.1312  decode.d6.loss_cls: 0.0683  decode.d6.loss_mask: 0.5949  decode.d6.loss_dice: 1.1271  decode.d7.loss_cls: 0.0886  decode.d7.loss_mask: 0.5860  decode.d7.loss_dice: 1.1200  decode.d8.loss_cls: 0.0782  decode.d8.loss_mask: 0.6009  decode.d8.loss_dice: 1.1224
11/15 10:50:29 - mmengine - INFO - Iter(train) [23250/90000]  base_lr: 7.6417e-05 lr: 7.6417e-06  eta: 11:13:01  time: 0.5967  data_time: 0.0094  memory: 10692  grad_norm: 505.4201  loss: 20.3796  decode.loss_cls: 0.0793  decode.loss_mask: 0.5927  decode.loss_dice: 1.3809  decode.d0.loss_cls: 0.0837  decode.d0.loss_mask: 0.6230  decode.d0.loss_dice: 1.4050  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.6024  decode.d1.loss_dice: 1.3784  decode.d2.loss_cls: 0.0857  decode.d2.loss_mask: 0.5807  decode.d2.loss_dice: 1.3670  decode.d3.loss_cls: 0.0874  decode.d3.loss_mask: 0.5856  decode.d3.loss_dice: 1.3467  decode.d4.loss_cls: 0.0748  decode.d4.loss_mask: 0.5944  decode.d4.loss_dice: 1.3730  decode.d5.loss_cls: 0.0825  decode.d5.loss_mask: 0.5857  decode.d5.loss_dice: 1.3543  decode.d6.loss_cls: 0.0805  decode.d6.loss_mask: 0.5756  decode.d6.loss_dice: 1.3407  decode.d7.loss_cls: 0.0867  decode.d7.loss_mask: 0.5742  decode.d7.loss_dice: 1.3669  decode.d8.loss_cls: 0.0795  decode.d8.loss_mask: 0.5762  decode.d8.loss_dice: 1.3544
11/15 10:50:59 - mmengine - INFO - Iter(train) [23300/90000]  base_lr: 7.6366e-05 lr: 7.6366e-06  eta: 11:12:29  time: 0.5975  data_time: 0.0095  memory: 10692  grad_norm: 320.0877  loss: 18.4499  decode.loss_cls: 0.0886  decode.loss_mask: 0.5802  decode.loss_dice: 1.1573  decode.d0.loss_cls: 0.0940  decode.d0.loss_mask: 0.6226  decode.d0.loss_dice: 1.2071  decode.d1.loss_cls: 0.0857  decode.d1.loss_mask: 0.5928  decode.d1.loss_dice: 1.1751  decode.d2.loss_cls: 0.0960  decode.d2.loss_mask: 0.5975  decode.d2.loss_dice: 1.1479  decode.d3.loss_cls: 0.0912  decode.d3.loss_mask: 0.5847  decode.d3.loss_dice: 1.1773  decode.d4.loss_cls: 0.0950  decode.d4.loss_mask: 0.5753  decode.d4.loss_dice: 1.1618  decode.d5.loss_cls: 0.0931  decode.d5.loss_mask: 0.5814  decode.d5.loss_dice: 1.1684  decode.d6.loss_cls: 0.0931  decode.d6.loss_mask: 0.5809  decode.d6.loss_dice: 1.1543  decode.d7.loss_cls: 0.0898  decode.d7.loss_mask: 0.5845  decode.d7.loss_dice: 1.1556  decode.d8.loss_cls: 0.0818  decode.d8.loss_mask: 0.5932  decode.d8.loss_dice: 1.1438
11/15 10:51:29 - mmengine - INFO - Iter(train) [23350/90000]  base_lr: 7.6314e-05 lr: 7.6314e-06  eta: 11:11:58  time: 0.5974  data_time: 0.0095  memory: 10713  grad_norm: 377.9522  loss: 19.3260  decode.loss_cls: 0.0749  decode.loss_mask: 0.6060  decode.loss_dice: 1.2481  decode.d0.loss_cls: 0.0802  decode.d0.loss_mask: 0.6081  decode.d0.loss_dice: 1.3562  decode.d1.loss_cls: 0.0681  decode.d1.loss_mask: 0.6029  decode.d1.loss_dice: 1.2941  decode.d2.loss_cls: 0.0887  decode.d2.loss_mask: 0.5862  decode.d2.loss_dice: 1.2444  decode.d3.loss_cls: 0.0886  decode.d3.loss_mask: 0.5786  decode.d3.loss_dice: 1.2390  decode.d4.loss_cls: 0.0879  decode.d4.loss_mask: 0.5945  decode.d4.loss_dice: 1.2630  decode.d5.loss_cls: 0.0813  decode.d5.loss_mask: 0.5983  decode.d5.loss_dice: 1.2482  decode.d6.loss_cls: 0.0779  decode.d6.loss_mask: 0.5840  decode.d6.loss_dice: 1.2323  decode.d7.loss_cls: 0.0776  decode.d7.loss_mask: 0.5768  decode.d7.loss_dice: 1.2359  decode.d8.loss_cls: 0.0622  decode.d8.loss_mask: 0.5916  decode.d8.loss_dice: 1.2501
11/15 10:51:59 - mmengine - INFO - Iter(train) [23400/90000]  base_lr: 7.6263e-05 lr: 7.6263e-06  eta: 11:11:27  time: 0.5960  data_time: 0.0095  memory: 10692  grad_norm: 5698.8234  loss: 18.5992  decode.loss_cls: 0.0644  decode.loss_mask: 0.5850  decode.loss_dice: 1.1895  decode.d0.loss_cls: 0.0838  decode.d0.loss_mask: 0.6120  decode.d0.loss_dice: 1.2970  decode.d1.loss_cls: 0.0678  decode.d1.loss_mask: 0.6061  decode.d1.loss_dice: 1.2190  decode.d2.loss_cls: 0.0649  decode.d2.loss_mask: 0.5914  decode.d2.loss_dice: 1.2149  decode.d3.loss_cls: 0.0833  decode.d3.loss_mask: 0.5819  decode.d3.loss_dice: 1.1765  decode.d4.loss_cls: 0.0890  decode.d4.loss_mask: 0.5872  decode.d4.loss_dice: 1.1456  decode.d5.loss_cls: 0.0731  decode.d5.loss_mask: 0.5828  decode.d5.loss_dice: 1.1827  decode.d6.loss_cls: 0.0567  decode.d6.loss_mask: 0.5868  decode.d6.loss_dice: 1.2072  decode.d7.loss_cls: 0.0553  decode.d7.loss_mask: 0.5848  decode.d7.loss_dice: 1.1852  decode.d8.loss_cls: 0.0790  decode.d8.loss_mask: 0.5761  decode.d8.loss_dice: 1.1703
11/15 10:52:29 - mmengine - INFO - Iter(train) [23450/90000]  base_lr: 7.6211e-05 lr: 7.6211e-06  eta: 11:10:56  time: 0.5971  data_time: 0.0095  memory: 10713  grad_norm: 398.3751  loss: 18.7686  decode.loss_cls: 0.0866  decode.loss_mask: 0.5789  decode.loss_dice: 1.2106  decode.d0.loss_cls: 0.0899  decode.d0.loss_mask: 0.5902  decode.d0.loss_dice: 1.2536  decode.d1.loss_cls: 0.0914  decode.d1.loss_mask: 0.5905  decode.d1.loss_dice: 1.2188  decode.d2.loss_cls: 0.0842  decode.d2.loss_mask: 0.5846  decode.d2.loss_dice: 1.2258  decode.d3.loss_cls: 0.0816  decode.d3.loss_mask: 0.5811  decode.d3.loss_dice: 1.2019  decode.d4.loss_cls: 0.0865  decode.d4.loss_mask: 0.5698  decode.d4.loss_dice: 1.1886  decode.d5.loss_cls: 0.0874  decode.d5.loss_mask: 0.5818  decode.d5.loss_dice: 1.1969  decode.d6.loss_cls: 0.0787  decode.d6.loss_mask: 0.5746  decode.d6.loss_dice: 1.1993  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.5925  decode.d7.loss_dice: 1.2057  decode.d8.loss_cls: 0.0760  decode.d8.loss_mask: 0.5755  decode.d8.loss_dice: 1.2173
11/15 10:52:59 - mmengine - INFO - Iter(train) [23500/90000]  base_lr: 7.6160e-05 lr: 7.6160e-06  eta: 11:10:25  time: 0.5984  data_time: 0.0095  memory: 10742  grad_norm: 519.2227  loss: 19.4675  decode.loss_cls: 0.0606  decode.loss_mask: 0.6758  decode.loss_dice: 1.2289  decode.d0.loss_cls: 0.0795  decode.d0.loss_mask: 0.6682  decode.d0.loss_dice: 1.2716  decode.d1.loss_cls: 0.0699  decode.d1.loss_mask: 0.6613  decode.d1.loss_dice: 1.2254  decode.d2.loss_cls: 0.0735  decode.d2.loss_mask: 0.6438  decode.d2.loss_dice: 1.2136  decode.d3.loss_cls: 0.0737  decode.d3.loss_mask: 0.6528  decode.d3.loss_dice: 1.2163  decode.d4.loss_cls: 0.0812  decode.d4.loss_mask: 0.6670  decode.d4.loss_dice: 1.2092  decode.d5.loss_cls: 0.0819  decode.d5.loss_mask: 0.6496  decode.d5.loss_dice: 1.2028  decode.d6.loss_cls: 0.0681  decode.d6.loss_mask: 0.6170  decode.d6.loss_dice: 1.2219  decode.d7.loss_cls: 0.0691  decode.d7.loss_mask: 0.6262  decode.d7.loss_dice: 1.1954  decode.d8.loss_cls: 0.0736  decode.d8.loss_mask: 0.6520  decode.d8.loss_dice: 1.2377
11/15 10:53:29 - mmengine - INFO - Iter(train) [23550/90000]  base_lr: 7.6108e-05 lr: 7.6108e-06  eta: 11:09:53  time: 0.5958  data_time: 0.0095  memory: 10656  grad_norm: 379.0005  loss: 18.6751  decode.loss_cls: 0.0602  decode.loss_mask: 0.6437  decode.loss_dice: 1.1281  decode.d0.loss_cls: 0.0831  decode.d0.loss_mask: 0.7449  decode.d0.loss_dice: 1.2069  decode.d1.loss_cls: 0.0661  decode.d1.loss_mask: 0.6702  decode.d1.loss_dice: 1.1515  decode.d2.loss_cls: 0.0629  decode.d2.loss_mask: 0.6583  decode.d2.loss_dice: 1.1263  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.6488  decode.d3.loss_dice: 1.1232  decode.d4.loss_cls: 0.0532  decode.d4.loss_mask: 0.6688  decode.d4.loss_dice: 1.1255  decode.d5.loss_cls: 0.0536  decode.d5.loss_mask: 0.6562  decode.d5.loss_dice: 1.1431  decode.d6.loss_cls: 0.0562  decode.d6.loss_mask: 0.6627  decode.d6.loss_dice: 1.1367  decode.d7.loss_cls: 0.0551  decode.d7.loss_mask: 0.6605  decode.d7.loss_dice: 1.1269  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.6479  decode.d8.loss_dice: 1.1332
11/15 10:53:58 - mmengine - INFO - Iter(train) [23600/90000]  base_lr: 7.6057e-05 lr: 7.6057e-06  eta: 11:09:22  time: 0.5967  data_time: 0.0095  memory: 10713  grad_norm: 1005.4255  loss: 21.9538  decode.loss_cls: 0.0857  decode.loss_mask: 0.7843  decode.loss_dice: 1.3451  decode.d0.loss_cls: 0.1200  decode.d0.loss_mask: 0.7898  decode.d0.loss_dice: 1.3715  decode.d1.loss_cls: 0.1070  decode.d1.loss_mask: 0.7569  decode.d1.loss_dice: 1.3298  decode.d2.loss_cls: 0.0992  decode.d2.loss_mask: 0.7820  decode.d2.loss_dice: 1.3082  decode.d3.loss_cls: 0.1183  decode.d3.loss_mask: 0.7409  decode.d3.loss_dice: 1.2780  decode.d4.loss_cls: 0.1039  decode.d4.loss_mask: 0.7463  decode.d4.loss_dice: 1.2979  decode.d5.loss_cls: 0.1088  decode.d5.loss_mask: 0.7771  decode.d5.loss_dice: 1.3116  decode.d6.loss_cls: 0.1009  decode.d6.loss_mask: 0.7575  decode.d6.loss_dice: 1.3195  decode.d7.loss_cls: 0.0973  decode.d7.loss_mask: 0.7636  decode.d7.loss_dice: 1.3322  decode.d8.loss_cls: 0.0841  decode.d8.loss_mask: 0.7937  decode.d8.loss_dice: 1.3429
11/15 10:54:28 - mmengine - INFO - Iter(train) [23650/90000]  base_lr: 7.6005e-05 lr: 7.6005e-06  eta: 11:08:50  time: 0.5966  data_time: 0.0095  memory: 10692  grad_norm: 504.9343  loss: 22.0355  decode.loss_cls: 0.1116  decode.loss_mask: 0.7560  decode.loss_dice: 1.3294  decode.d0.loss_cls: 0.1052  decode.d0.loss_mask: 0.7454  decode.d0.loss_dice: 1.4283  decode.d1.loss_cls: 0.1167  decode.d1.loss_mask: 0.7554  decode.d1.loss_dice: 1.3346  decode.d2.loss_cls: 0.1123  decode.d2.loss_mask: 0.7449  decode.d2.loss_dice: 1.3634  decode.d3.loss_cls: 0.1086  decode.d3.loss_mask: 0.7617  decode.d3.loss_dice: 1.3100  decode.d4.loss_cls: 0.0997  decode.d4.loss_mask: 0.7432  decode.d4.loss_dice: 1.3329  decode.d5.loss_cls: 0.0924  decode.d5.loss_mask: 0.7400  decode.d5.loss_dice: 1.3625  decode.d6.loss_cls: 0.0962  decode.d6.loss_mask: 0.7425  decode.d6.loss_dice: 1.3272  decode.d7.loss_cls: 0.0951  decode.d7.loss_mask: 0.7674  decode.d7.loss_dice: 1.3664  decode.d8.loss_cls: 0.0997  decode.d8.loss_mask: 0.7655  decode.d8.loss_dice: 1.3212
11/15 10:54:58 - mmengine - INFO - Iter(train) [23700/90000]  base_lr: 7.5954e-05 lr: 7.5954e-06  eta: 11:08:19  time: 0.5967  data_time: 0.0094  memory: 10713  grad_norm: 225.9502  loss: 17.9456  decode.loss_cls: 0.0369  decode.loss_mask: 0.5801  decode.loss_dice: 1.1800  decode.d0.loss_cls: 0.0630  decode.d0.loss_mask: 0.5748  decode.d0.loss_dice: 1.1998  decode.d1.loss_cls: 0.0575  decode.d1.loss_mask: 0.5599  decode.d1.loss_dice: 1.1696  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.5782  decode.d2.loss_dice: 1.1727  decode.d3.loss_cls: 0.0713  decode.d3.loss_mask: 0.5669  decode.d3.loss_dice: 1.1344  decode.d4.loss_cls: 0.0512  decode.d4.loss_mask: 0.5921  decode.d4.loss_dice: 1.1592  decode.d5.loss_cls: 0.0499  decode.d5.loss_mask: 0.5821  decode.d5.loss_dice: 1.1555  decode.d6.loss_cls: 0.0403  decode.d6.loss_mask: 0.5831  decode.d6.loss_dice: 1.1418  decode.d7.loss_cls: 0.0444  decode.d7.loss_mask: 0.5689  decode.d7.loss_dice: 1.1618  decode.d8.loss_cls: 0.0453  decode.d8.loss_mask: 0.5897  decode.d8.loss_dice: 1.1749
11/15 10:55:28 - mmengine - INFO - Iter(train) [23750/90000]  base_lr: 7.5902e-05 lr: 7.5902e-06  eta: 11:07:48  time: 0.5965  data_time: 0.0095  memory: 10656  grad_norm: 660.7972  loss: 20.3312  decode.loss_cls: 0.0853  decode.loss_mask: 0.6082  decode.loss_dice: 1.2979  decode.d0.loss_cls: 0.1103  decode.d0.loss_mask: 0.6164  decode.d0.loss_dice: 1.3670  decode.d1.loss_cls: 0.0906  decode.d1.loss_mask: 0.6033  decode.d1.loss_dice: 1.3251  decode.d2.loss_cls: 0.0923  decode.d2.loss_mask: 0.5906  decode.d2.loss_dice: 1.3321  decode.d3.loss_cls: 0.0876  decode.d3.loss_mask: 0.6149  decode.d3.loss_dice: 1.3170  decode.d4.loss_cls: 0.0972  decode.d4.loss_mask: 0.6347  decode.d4.loss_dice: 1.3305  decode.d5.loss_cls: 0.0922  decode.d5.loss_mask: 0.6396  decode.d5.loss_dice: 1.3336  decode.d6.loss_cls: 0.0909  decode.d6.loss_mask: 0.6184  decode.d6.loss_dice: 1.3172  decode.d7.loss_cls: 0.0894  decode.d7.loss_mask: 0.6162  decode.d7.loss_dice: 1.3104  decode.d8.loss_cls: 0.0872  decode.d8.loss_mask: 0.6047  decode.d8.loss_dice: 1.3301
11/15 10:55:58 - mmengine - INFO - Iter(train) [23800/90000]  base_lr: 7.5850e-05 lr: 7.5850e-06  eta: 11:07:16  time: 0.5957  data_time: 0.0095  memory: 10626  grad_norm: 321.1791  loss: 17.2372  decode.loss_cls: 0.0488  decode.loss_mask: 0.5942  decode.loss_dice: 1.0440  decode.d0.loss_cls: 0.0944  decode.d0.loss_mask: 0.6186  decode.d0.loss_dice: 1.0906  decode.d1.loss_cls: 0.0490  decode.d1.loss_mask: 0.6153  decode.d1.loss_dice: 1.0942  decode.d2.loss_cls: 0.0471  decode.d2.loss_mask: 0.6215  decode.d2.loss_dice: 1.0723  decode.d3.loss_cls: 0.0534  decode.d3.loss_mask: 0.5962  decode.d3.loss_dice: 1.0551  decode.d4.loss_cls: 0.0451  decode.d4.loss_mask: 0.5940  decode.d4.loss_dice: 1.0661  decode.d5.loss_cls: 0.0400  decode.d5.loss_mask: 0.5937  decode.d5.loss_dice: 1.0602  decode.d6.loss_cls: 0.0431  decode.d6.loss_mask: 0.5945  decode.d6.loss_dice: 1.0595  decode.d7.loss_cls: 0.0428  decode.d7.loss_mask: 0.5959  decode.d7.loss_dice: 1.0807  decode.d8.loss_cls: 0.0496  decode.d8.loss_mask: 0.5906  decode.d8.loss_dice: 1.0867
11/15 10:56:28 - mmengine - INFO - Iter(train) [23850/90000]  base_lr: 7.5799e-05 lr: 7.5799e-06  eta: 11:06:45  time: 0.5961  data_time: 0.0093  memory: 10656  grad_norm: 372.2546  loss: 18.2126  decode.loss_cls: 0.0448  decode.loss_mask: 0.5976  decode.loss_dice: 1.2315  decode.d0.loss_cls: 0.0931  decode.d0.loss_mask: 0.5653  decode.d0.loss_dice: 1.2783  decode.d1.loss_cls: 0.0817  decode.d1.loss_mask: 0.5087  decode.d1.loss_dice: 1.1640  decode.d2.loss_cls: 0.0667  decode.d2.loss_mask: 0.5243  decode.d2.loss_dice: 1.2133  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 0.5332  decode.d3.loss_dice: 1.1746  decode.d4.loss_cls: 0.0556  decode.d4.loss_mask: 0.5855  decode.d4.loss_dice: 1.1543  decode.d5.loss_cls: 0.0558  decode.d5.loss_mask: 0.5745  decode.d5.loss_dice: 1.1793  decode.d6.loss_cls: 0.0502  decode.d6.loss_mask: 0.5701  decode.d6.loss_dice: 1.1814  decode.d7.loss_cls: 0.0495  decode.d7.loss_mask: 0.5786  decode.d7.loss_dice: 1.2151  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.5985  decode.d8.loss_dice: 1.1743
11/15 10:56:57 - mmengine - INFO - Iter(train) [23900/90000]  base_lr: 7.5747e-05 lr: 7.5747e-06  eta: 11:06:14  time: 0.5979  data_time: 0.0094  memory: 10728  grad_norm: 304.8027  loss: 19.7158  decode.loss_cls: 0.0538  decode.loss_mask: 0.6372  decode.loss_dice: 1.2699  decode.d0.loss_cls: 0.0863  decode.d0.loss_mask: 0.6281  decode.d0.loss_dice: 1.3693  decode.d1.loss_cls: 0.0617  decode.d1.loss_mask: 0.6197  decode.d1.loss_dice: 1.3215  decode.d2.loss_cls: 0.0561  decode.d2.loss_mask: 0.5944  decode.d2.loss_dice: 1.3013  decode.d3.loss_cls: 0.0591  decode.d3.loss_mask: 0.6028  decode.d3.loss_dice: 1.2956  decode.d4.loss_cls: 0.0519  decode.d4.loss_mask: 0.6130  decode.d4.loss_dice: 1.2864  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 0.6054  decode.d5.loss_dice: 1.2970  decode.d6.loss_cls: 0.0623  decode.d6.loss_mask: 0.6065  decode.d6.loss_dice: 1.2869  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.6190  decode.d7.loss_dice: 1.2871  decode.d8.loss_cls: 0.0700  decode.d8.loss_mask: 0.6216  decode.d8.loss_dice: 1.2388
11/15 10:57:27 - mmengine - INFO - Iter(train) [23950/90000]  base_lr: 7.5696e-05 lr: 7.5696e-06  eta: 11:05:42  time: 0.5969  data_time: 0.0095  memory: 10675  grad_norm: 567.0367  loss: 20.1600  decode.loss_cls: 0.0703  decode.loss_mask: 0.5977  decode.loss_dice: 1.3845  decode.d0.loss_cls: 0.0816  decode.d0.loss_mask: 0.5882  decode.d0.loss_dice: 1.4349  decode.d1.loss_cls: 0.0934  decode.d1.loss_mask: 0.5900  decode.d1.loss_dice: 1.3534  decode.d2.loss_cls: 0.0689  decode.d2.loss_mask: 0.5883  decode.d2.loss_dice: 1.3596  decode.d3.loss_cls: 0.0725  decode.d3.loss_mask: 0.5791  decode.d3.loss_dice: 1.3276  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.5901  decode.d4.loss_dice: 1.3346  decode.d5.loss_cls: 0.0705  decode.d5.loss_mask: 0.5858  decode.d5.loss_dice: 1.3250  decode.d6.loss_cls: 0.0769  decode.d6.loss_mask: 0.5922  decode.d6.loss_dice: 1.3429  decode.d7.loss_cls: 0.0666  decode.d7.loss_mask: 0.5892  decode.d7.loss_dice: 1.3370  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.5798  decode.d8.loss_dice: 1.3519
11/15 10:57:57 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 10:57:57 - mmengine - INFO - Iter(train) [24000/90000]  base_lr: 7.5644e-05 lr: 7.5644e-06  eta: 11:05:11  time: 0.5963  data_time: 0.0094  memory: 10656  grad_norm: 732.2358  loss: 19.5422  decode.loss_cls: 0.0738  decode.loss_mask: 0.5640  decode.loss_dice: 1.2954  decode.d0.loss_cls: 0.0785  decode.d0.loss_mask: 0.6181  decode.d0.loss_dice: 1.4015  decode.d1.loss_cls: 0.0733  decode.d1.loss_mask: 0.5841  decode.d1.loss_dice: 1.3108  decode.d2.loss_cls: 0.0741  decode.d2.loss_mask: 0.5711  decode.d2.loss_dice: 1.3141  decode.d3.loss_cls: 0.0720  decode.d3.loss_mask: 0.5638  decode.d3.loss_dice: 1.2827  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.5712  decode.d4.loss_dice: 1.3023  decode.d5.loss_cls: 0.0784  decode.d5.loss_mask: 0.5697  decode.d5.loss_dice: 1.3089  decode.d6.loss_cls: 0.0809  decode.d6.loss_mask: 0.5634  decode.d6.loss_dice: 1.2773  decode.d7.loss_cls: 0.0713  decode.d7.loss_mask: 0.5722  decode.d7.loss_dice: 1.2854  decode.d8.loss_cls: 0.0631  decode.d8.loss_mask: 0.5653  decode.d8.loss_dice: 1.2879
11/15 10:58:27 - mmengine - INFO - Iter(train) [24050/90000]  base_lr: 7.5593e-05 lr: 7.5593e-06  eta: 11:04:40  time: 0.5970  data_time: 0.0096  memory: 10675  grad_norm: 356.7934  loss: 19.8868  decode.loss_cls: 0.0643  decode.loss_mask: 0.6052  decode.loss_dice: 1.2425  decode.d0.loss_cls: 0.0924  decode.d0.loss_mask: 0.6379  decode.d0.loss_dice: 1.3214  decode.d1.loss_cls: 0.0654  decode.d1.loss_mask: 0.6596  decode.d1.loss_dice: 1.2923  decode.d2.loss_cls: 0.0732  decode.d2.loss_mask: 0.6430  decode.d2.loss_dice: 1.2855  decode.d3.loss_cls: 0.0734  decode.d3.loss_mask: 0.6592  decode.d3.loss_dice: 1.3024  decode.d4.loss_cls: 0.0679  decode.d4.loss_mask: 0.6299  decode.d4.loss_dice: 1.2818  decode.d5.loss_cls: 0.0759  decode.d5.loss_mask: 0.6440  decode.d5.loss_dice: 1.2674  decode.d6.loss_cls: 0.0728  decode.d6.loss_mask: 0.6092  decode.d6.loss_dice: 1.2720  decode.d7.loss_cls: 0.0639  decode.d7.loss_mask: 0.6512  decode.d7.loss_dice: 1.2630  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.6278  decode.d8.loss_dice: 1.2772
11/15 10:58:57 - mmengine - INFO - Iter(train) [24100/90000]  base_lr: 7.5541e-05 lr: 7.5541e-06  eta: 11:04:08  time: 0.5974  data_time: 0.0096  memory: 10656  grad_norm: 315.3930  loss: 18.7643  decode.loss_cls: 0.0744  decode.loss_mask: 0.6823  decode.loss_dice: 1.0911  decode.d0.loss_cls: 0.0985  decode.d0.loss_mask: 0.7001  decode.d0.loss_dice: 1.1741  decode.d1.loss_cls: 0.0784  decode.d1.loss_mask: 0.6769  decode.d1.loss_dice: 1.0868  decode.d2.loss_cls: 0.0984  decode.d2.loss_mask: 0.6720  decode.d2.loss_dice: 1.1162  decode.d3.loss_cls: 0.0854  decode.d3.loss_mask: 0.6703  decode.d3.loss_dice: 1.1143  decode.d4.loss_cls: 0.0832  decode.d4.loss_mask: 0.6804  decode.d4.loss_dice: 1.1182  decode.d5.loss_cls: 0.0889  decode.d5.loss_mask: 0.7156  decode.d5.loss_dice: 1.0973  decode.d6.loss_cls: 0.0837  decode.d6.loss_mask: 0.6683  decode.d6.loss_dice: 1.0957  decode.d7.loss_cls: 0.0839  decode.d7.loss_mask: 0.6763  decode.d7.loss_dice: 1.0914  decode.d8.loss_cls: 0.0871  decode.d8.loss_mask: 0.6815  decode.d8.loss_dice: 1.0937
11/15 10:59:27 - mmengine - INFO - Iter(train) [24150/90000]  base_lr: 7.5489e-05 lr: 7.5489e-06  eta: 11:03:37  time: 0.5977  data_time: 0.0096  memory: 10713  grad_norm: 791.7116  loss: 20.2683  decode.loss_cls: 0.0998  decode.loss_mask: 0.6690  decode.loss_dice: 1.2816  decode.d0.loss_cls: 0.1367  decode.d0.loss_mask: 0.6858  decode.d0.loss_dice: 1.3130  decode.d1.loss_cls: 0.1303  decode.d1.loss_mask: 0.6416  decode.d1.loss_dice: 1.1951  decode.d2.loss_cls: 0.1130  decode.d2.loss_mask: 0.6559  decode.d2.loss_dice: 1.2301  decode.d3.loss_cls: 0.1133  decode.d3.loss_mask: 0.6543  decode.d3.loss_dice: 1.2297  decode.d4.loss_cls: 0.1181  decode.d4.loss_mask: 0.6596  decode.d4.loss_dice: 1.2347  decode.d5.loss_cls: 0.1139  decode.d5.loss_mask: 0.6519  decode.d5.loss_dice: 1.2291  decode.d6.loss_cls: 0.1144  decode.d6.loss_mask: 0.6704  decode.d6.loss_dice: 1.2406  decode.d7.loss_cls: 0.1229  decode.d7.loss_mask: 0.6591  decode.d7.loss_dice: 1.2484  decode.d8.loss_cls: 0.1032  decode.d8.loss_mask: 0.6823  decode.d8.loss_dice: 1.2707
11/15 10:59:57 - mmengine - INFO - Iter(train) [24200/90000]  base_lr: 7.5438e-05 lr: 7.5438e-06  eta: 11:03:06  time: 0.5979  data_time: 0.0095  memory: 10656  grad_norm: 573.5558  loss: 20.1197  decode.loss_cls: 0.1048  decode.loss_mask: 0.6185  decode.loss_dice: 1.2491  decode.d0.loss_cls: 0.0892  decode.d0.loss_mask: 0.6581  decode.d0.loss_dice: 1.3173  decode.d1.loss_cls: 0.1023  decode.d1.loss_mask: 0.6258  decode.d1.loss_dice: 1.2703  decode.d2.loss_cls: 0.0979  decode.d2.loss_mask: 0.6309  decode.d2.loss_dice: 1.3001  decode.d3.loss_cls: 0.0886  decode.d3.loss_mask: 0.6283  decode.d3.loss_dice: 1.2824  decode.d4.loss_cls: 0.0851  decode.d4.loss_mask: 0.6328  decode.d4.loss_dice: 1.2920  decode.d5.loss_cls: 0.0892  decode.d5.loss_mask: 0.6105  decode.d5.loss_dice: 1.2916  decode.d6.loss_cls: 0.0878  decode.d6.loss_mask: 0.6239  decode.d6.loss_dice: 1.2927  decode.d7.loss_cls: 0.0851  decode.d7.loss_mask: 0.6329  decode.d7.loss_dice: 1.3101  decode.d8.loss_cls: 0.0996  decode.d8.loss_mask: 0.6291  decode.d8.loss_dice: 1.2937
11/15 11:00:27 - mmengine - INFO - Iter(train) [24250/90000]  base_lr: 7.5386e-05 lr: 7.5386e-06  eta: 11:02:35  time: 0.5971  data_time: 0.0096  memory: 10692  grad_norm: 408.2452  loss: 14.7165  decode.loss_cls: 0.0481  decode.loss_mask: 0.4466  decode.loss_dice: 0.9715  decode.d0.loss_cls: 0.0712  decode.d0.loss_mask: 0.4836  decode.d0.loss_dice: 1.0048  decode.d1.loss_cls: 0.0578  decode.d1.loss_mask: 0.4576  decode.d1.loss_dice: 0.9719  decode.d2.loss_cls: 0.0520  decode.d2.loss_mask: 0.4564  decode.d2.loss_dice: 0.9475  decode.d3.loss_cls: 0.0414  decode.d3.loss_mask: 0.4568  decode.d3.loss_dice: 0.9501  decode.d4.loss_cls: 0.0452  decode.d4.loss_mask: 0.4608  decode.d4.loss_dice: 0.9647  decode.d5.loss_cls: 0.0487  decode.d5.loss_mask: 0.4575  decode.d5.loss_dice: 0.9698  decode.d6.loss_cls: 0.0523  decode.d6.loss_mask: 0.4437  decode.d6.loss_dice: 0.9588  decode.d7.loss_cls: 0.0527  decode.d7.loss_mask: 0.4376  decode.d7.loss_dice: 0.9515  decode.d8.loss_cls: 0.0481  decode.d8.loss_mask: 0.4473  decode.d8.loss_dice: 0.9606
11/15 11:00:57 - mmengine - INFO - Iter(train) [24300/90000]  base_lr: 7.5335e-05 lr: 7.5335e-06  eta: 11:02:04  time: 0.5958  data_time: 0.0094  memory: 10656  grad_norm: 432.5525  loss: 16.3212  decode.loss_cls: 0.0586  decode.loss_mask: 0.5356  decode.loss_dice: 1.0426  decode.d0.loss_cls: 0.0887  decode.d0.loss_mask: 0.5393  decode.d0.loss_dice: 1.1181  decode.d1.loss_cls: 0.0793  decode.d1.loss_mask: 0.5011  decode.d1.loss_dice: 1.0473  decode.d2.loss_cls: 0.0846  decode.d2.loss_mask: 0.4870  decode.d2.loss_dice: 1.0250  decode.d3.loss_cls: 0.0675  decode.d3.loss_mask: 0.5134  decode.d3.loss_dice: 1.0452  decode.d4.loss_cls: 0.0745  decode.d4.loss_mask: 0.5039  decode.d4.loss_dice: 1.0552  decode.d5.loss_cls: 0.0727  decode.d5.loss_mask: 0.5015  decode.d5.loss_dice: 1.0568  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.5094  decode.d6.loss_dice: 1.0400  decode.d7.loss_cls: 0.0798  decode.d7.loss_mask: 0.4842  decode.d7.loss_dice: 1.0257  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.5044  decode.d8.loss_dice: 1.0451
11/15 11:01:26 - mmengine - INFO - Iter(train) [24350/90000]  base_lr: 7.5283e-05 lr: 7.5283e-06  eta: 11:01:33  time: 0.5980  data_time: 0.0095  memory: 10675  grad_norm: 444.8188  loss: 19.2420  decode.loss_cls: 0.0779  decode.loss_mask: 0.6197  decode.loss_dice: 1.1823  decode.d0.loss_cls: 0.0825  decode.d0.loss_mask: 0.6231  decode.d0.loss_dice: 1.2962  decode.d1.loss_cls: 0.0752  decode.d1.loss_mask: 0.5988  decode.d1.loss_dice: 1.2177  decode.d2.loss_cls: 0.0913  decode.d2.loss_mask: 0.6040  decode.d2.loss_dice: 1.1835  decode.d3.loss_cls: 0.0740  decode.d3.loss_mask: 0.6146  decode.d3.loss_dice: 1.1781  decode.d4.loss_cls: 0.0711  decode.d4.loss_mask: 0.6752  decode.d4.loss_dice: 1.2172  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.6287  decode.d5.loss_dice: 1.2178  decode.d6.loss_cls: 0.0658  decode.d6.loss_mask: 0.7122  decode.d6.loss_dice: 1.2488  decode.d7.loss_cls: 0.0755  decode.d7.loss_mask: 0.6296  decode.d7.loss_dice: 1.2254  decode.d8.loss_cls: 0.0873  decode.d8.loss_mask: 0.6078  decode.d8.loss_dice: 1.1813
11/15 11:01:57 - mmengine - INFO - Iter(train) [24400/90000]  base_lr: 7.5231e-05 lr: 7.5231e-06  eta: 11:01:02  time: 0.6247  data_time: 0.0094  memory: 10675  grad_norm: 752.0054  loss: 21.0313  decode.loss_cls: 0.0772  decode.loss_mask: 0.6650  decode.loss_dice: 1.3262  decode.d0.loss_cls: 0.0798  decode.d0.loss_mask: 0.7089  decode.d0.loss_dice: 1.4541  decode.d1.loss_cls: 0.0862  decode.d1.loss_mask: 0.6797  decode.d1.loss_dice: 1.3277  decode.d2.loss_cls: 0.0739  decode.d2.loss_mask: 0.6925  decode.d2.loss_dice: 1.3329  decode.d3.loss_cls: 0.0683  decode.d3.loss_mask: 0.6803  decode.d3.loss_dice: 1.3504  decode.d4.loss_cls: 0.0790  decode.d4.loss_mask: 0.6633  decode.d4.loss_dice: 1.3045  decode.d5.loss_cls: 0.0673  decode.d5.loss_mask: 0.6724  decode.d5.loss_dice: 1.3405  decode.d6.loss_cls: 0.0676  decode.d6.loss_mask: 0.6696  decode.d6.loss_dice: 1.3584  decode.d7.loss_cls: 0.0734  decode.d7.loss_mask: 0.6656  decode.d7.loss_dice: 1.3585  decode.d8.loss_cls: 0.0706  decode.d8.loss_mask: 0.6765  decode.d8.loss_dice: 1.3611
11/15 11:02:27 - mmengine - INFO - Iter(train) [24450/90000]  base_lr: 7.5180e-05 lr: 7.5180e-06  eta: 11:00:31  time: 0.5980  data_time: 0.0095  memory: 10692  grad_norm: 325.1058  loss: 18.1957  decode.loss_cls: 0.0509  decode.loss_mask: 0.5474  decode.loss_dice: 1.2135  decode.d0.loss_cls: 0.0484  decode.d0.loss_mask: 0.5539  decode.d0.loss_dice: 1.2998  decode.d1.loss_cls: 0.0553  decode.d1.loss_mask: 0.5358  decode.d1.loss_dice: 1.2606  decode.d2.loss_cls: 0.0458  decode.d2.loss_mask: 0.5425  decode.d2.loss_dice: 1.2159  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 0.5544  decode.d3.loss_dice: 1.1907  decode.d4.loss_cls: 0.0672  decode.d4.loss_mask: 0.5464  decode.d4.loss_dice: 1.1990  decode.d5.loss_cls: 0.0512  decode.d5.loss_mask: 0.5430  decode.d5.loss_dice: 1.2085  decode.d6.loss_cls: 0.0511  decode.d6.loss_mask: 0.5478  decode.d6.loss_dice: 1.2205  decode.d7.loss_cls: 0.0439  decode.d7.loss_mask: 0.5475  decode.d7.loss_dice: 1.2225  decode.d8.loss_cls: 0.0445  decode.d8.loss_mask: 0.5406  decode.d8.loss_dice: 1.1862
11/15 11:02:56 - mmengine - INFO - Iter(train) [24500/90000]  base_lr: 7.5128e-05 lr: 7.5128e-06  eta: 11:00:00  time: 0.5971  data_time: 0.0095  memory: 10692  grad_norm: 563.9691  loss: 16.8219  decode.loss_cls: 0.0642  decode.loss_mask: 0.5418  decode.loss_dice: 1.0360  decode.d0.loss_cls: 0.0758  decode.d0.loss_mask: 0.5978  decode.d0.loss_dice: 1.1053  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.5513  decode.d1.loss_dice: 1.0719  decode.d2.loss_cls: 0.0785  decode.d2.loss_mask: 0.5551  decode.d2.loss_dice: 1.0624  decode.d3.loss_cls: 0.0692  decode.d3.loss_mask: 0.5505  decode.d3.loss_dice: 1.0286  decode.d4.loss_cls: 0.0675  decode.d4.loss_mask: 0.5542  decode.d4.loss_dice: 1.0655  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.5521  decode.d5.loss_dice: 1.0603  decode.d6.loss_cls: 0.0782  decode.d6.loss_mask: 0.5492  decode.d6.loss_dice: 1.0347  decode.d7.loss_cls: 0.0669  decode.d7.loss_mask: 0.5520  decode.d7.loss_dice: 1.0615  decode.d8.loss_cls: 0.0716  decode.d8.loss_mask: 0.5453  decode.d8.loss_dice: 1.0377
11/15 11:03:26 - mmengine - INFO - Iter(train) [24550/90000]  base_lr: 7.5077e-05 lr: 7.5077e-06  eta: 10:59:29  time: 0.5968  data_time: 0.0095  memory: 10675  grad_norm: 203.7158  loss: 18.3500  decode.loss_cls: 0.0538  decode.loss_mask: 0.4895  decode.loss_dice: 1.2889  decode.d0.loss_cls: 0.0826  decode.d0.loss_mask: 0.4820  decode.d0.loss_dice: 1.3103  decode.d1.loss_cls: 0.0533  decode.d1.loss_mask: 0.4860  decode.d1.loss_dice: 1.2893  decode.d2.loss_cls: 0.0615  decode.d2.loss_mask: 0.4809  decode.d2.loss_dice: 1.2811  decode.d3.loss_cls: 0.0722  decode.d3.loss_mask: 0.4742  decode.d3.loss_dice: 1.2766  decode.d4.loss_cls: 0.0612  decode.d4.loss_mask: 0.4804  decode.d4.loss_dice: 1.2915  decode.d5.loss_cls: 0.0692  decode.d5.loss_mask: 0.4748  decode.d5.loss_dice: 1.2642  decode.d6.loss_cls: 0.0668  decode.d6.loss_mask: 0.5024  decode.d6.loss_dice: 1.2617  decode.d7.loss_cls: 0.0605  decode.d7.loss_mask: 0.5012  decode.d7.loss_dice: 1.2908  decode.d8.loss_cls: 0.0536  decode.d8.loss_mask: 0.4992  decode.d8.loss_dice: 1.2905
11/15 11:03:56 - mmengine - INFO - Iter(train) [24600/90000]  base_lr: 7.5025e-05 lr: 7.5025e-06  eta: 10:58:58  time: 0.5977  data_time: 0.0096  memory: 10675  grad_norm: 389.5254  loss: 19.0367  decode.loss_cls: 0.0720  decode.loss_mask: 0.5027  decode.loss_dice: 1.2812  decode.d0.loss_cls: 0.0807  decode.d0.loss_mask: 0.5283  decode.d0.loss_dice: 1.4512  decode.d1.loss_cls: 0.0676  decode.d1.loss_mask: 0.5360  decode.d1.loss_dice: 1.3477  decode.d2.loss_cls: 0.0610  decode.d2.loss_mask: 0.5335  decode.d2.loss_dice: 1.3332  decode.d3.loss_cls: 0.0717  decode.d3.loss_mask: 0.5047  decode.d3.loss_dice: 1.2892  decode.d4.loss_cls: 0.0713  decode.d4.loss_mask: 0.5232  decode.d4.loss_dice: 1.3075  decode.d5.loss_cls: 0.0657  decode.d5.loss_mask: 0.5092  decode.d5.loss_dice: 1.3009  decode.d6.loss_cls: 0.0651  decode.d6.loss_mask: 0.5161  decode.d6.loss_dice: 1.2859  decode.d7.loss_cls: 0.0690  decode.d7.loss_mask: 0.5074  decode.d7.loss_dice: 1.2985  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.4986  decode.d8.loss_dice: 1.2912
11/15 11:04:26 - mmengine - INFO - Iter(train) [24650/90000]  base_lr: 7.4973e-05 lr: 7.4973e-06  eta: 10:58:27  time: 0.5969  data_time: 0.0095  memory: 10675  grad_norm: 246.8659  loss: 18.7403  decode.loss_cls: 0.0623  decode.loss_mask: 0.5206  decode.loss_dice: 1.2623  decode.d0.loss_cls: 0.0838  decode.d0.loss_mask: 0.5550  decode.d0.loss_dice: 1.3310  decode.d1.loss_cls: 0.0536  decode.d1.loss_mask: 0.5482  decode.d1.loss_dice: 1.3125  decode.d2.loss_cls: 0.0538  decode.d2.loss_mask: 0.5310  decode.d2.loss_dice: 1.2871  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.5204  decode.d3.loss_dice: 1.2570  decode.d4.loss_cls: 0.0621  decode.d4.loss_mask: 0.5136  decode.d4.loss_dice: 1.2754  decode.d5.loss_cls: 0.0763  decode.d5.loss_mask: 0.5117  decode.d5.loss_dice: 1.2539  decode.d6.loss_cls: 0.0566  decode.d6.loss_mask: 0.5245  decode.d6.loss_dice: 1.2744  decode.d7.loss_cls: 0.0736  decode.d7.loss_mask: 0.5311  decode.d7.loss_dice: 1.2724  decode.d8.loss_cls: 0.0656  decode.d8.loss_mask: 0.5242  decode.d8.loss_dice: 1.2771
11/15 11:04:56 - mmengine - INFO - Iter(train) [24700/90000]  base_lr: 7.4922e-05 lr: 7.4922e-06  eta: 10:57:55  time: 0.5970  data_time: 0.0096  memory: 10713  grad_norm: 362.3577  loss: 20.4977  decode.loss_cls: 0.0856  decode.loss_mask: 0.6521  decode.loss_dice: 1.2864  decode.d0.loss_cls: 0.1007  decode.d0.loss_mask: 0.7080  decode.d0.loss_dice: 1.3520  decode.d1.loss_cls: 0.0838  decode.d1.loss_mask: 0.6663  decode.d1.loss_dice: 1.2819  decode.d2.loss_cls: 0.0718  decode.d2.loss_mask: 0.6671  decode.d2.loss_dice: 1.3503  decode.d3.loss_cls: 0.0799  decode.d3.loss_mask: 0.6530  decode.d3.loss_dice: 1.2799  decode.d4.loss_cls: 0.0730  decode.d4.loss_mask: 0.6554  decode.d4.loss_dice: 1.2900  decode.d5.loss_cls: 0.0816  decode.d5.loss_mask: 0.6561  decode.d5.loss_dice: 1.3066  decode.d6.loss_cls: 0.0781  decode.d6.loss_mask: 0.6735  decode.d6.loss_dice: 1.2798  decode.d7.loss_cls: 0.0851  decode.d7.loss_mask: 0.6607  decode.d7.loss_dice: 1.3056  decode.d8.loss_cls: 0.0821  decode.d8.loss_mask: 0.6671  decode.d8.loss_dice: 1.2842
11/15 11:05:27 - mmengine - INFO - Iter(train) [24750/90000]  base_lr: 7.4870e-05 lr: 7.4870e-06  eta: 10:57:27  time: 0.5971  data_time: 0.0094  memory: 10675  grad_norm: 452.7749  loss: 21.7048  decode.loss_cls: 0.0876  decode.loss_mask: 0.6954  decode.loss_dice: 1.3929  decode.d0.loss_cls: 0.0958  decode.d0.loss_mask: 0.7247  decode.d0.loss_dice: 1.4298  decode.d1.loss_cls: 0.0952  decode.d1.loss_mask: 0.7090  decode.d1.loss_dice: 1.3548  decode.d2.loss_cls: 0.0977  decode.d2.loss_mask: 0.7096  decode.d2.loss_dice: 1.3616  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 0.6941  decode.d3.loss_dice: 1.3487  decode.d4.loss_cls: 0.0906  decode.d4.loss_mask: 0.7031  decode.d4.loss_dice: 1.3670  decode.d5.loss_cls: 0.0941  decode.d5.loss_mask: 0.7003  decode.d5.loss_dice: 1.3619  decode.d6.loss_cls: 0.0884  decode.d6.loss_mask: 0.7059  decode.d6.loss_dice: 1.3985  decode.d7.loss_cls: 0.0807  decode.d7.loss_mask: 0.7057  decode.d7.loss_dice: 1.3758  decode.d8.loss_cls: 0.0964  decode.d8.loss_mask: 0.6873  decode.d8.loss_dice: 1.3629
11/15 11:05:57 - mmengine - INFO - Iter(train) [24800/90000]  base_lr: 7.4818e-05 lr: 7.4818e-06  eta: 10:56:56  time: 0.5971  data_time: 0.0094  memory: 10713  grad_norm: 635.5418  loss: 20.1991  decode.loss_cls: 0.0896  decode.loss_mask: 0.5464  decode.loss_dice: 1.3666  decode.d0.loss_cls: 0.0803  decode.d0.loss_mask: 0.5493  decode.d0.loss_dice: 1.4844  decode.d1.loss_cls: 0.0805  decode.d1.loss_mask: 0.5478  decode.d1.loss_dice: 1.4298  decode.d2.loss_cls: 0.0862  decode.d2.loss_mask: 0.5416  decode.d2.loss_dice: 1.3873  decode.d3.loss_cls: 0.0959  decode.d3.loss_mask: 0.5394  decode.d3.loss_dice: 1.3673  decode.d4.loss_cls: 0.1129  decode.d4.loss_mask: 0.5250  decode.d4.loss_dice: 1.3572  decode.d5.loss_cls: 0.0990  decode.d5.loss_mask: 0.5307  decode.d5.loss_dice: 1.3892  decode.d6.loss_cls: 0.0909  decode.d6.loss_mask: 0.5428  decode.d6.loss_dice: 1.3454  decode.d7.loss_cls: 0.0889  decode.d7.loss_mask: 0.5416  decode.d7.loss_dice: 1.3734  decode.d8.loss_cls: 0.0891  decode.d8.loss_mask: 0.5388  decode.d8.loss_dice: 1.3819
11/15 11:06:27 - mmengine - INFO - Iter(train) [24850/90000]  base_lr: 7.4767e-05 lr: 7.4767e-06  eta: 10:56:25  time: 0.5978  data_time: 0.0094  memory: 10713  grad_norm: 459.6049  loss: 18.7591  decode.loss_cls: 0.0861  decode.loss_mask: 0.5394  decode.loss_dice: 1.2196  decode.d0.loss_cls: 0.1028  decode.d0.loss_mask: 0.5409  decode.d0.loss_dice: 1.2864  decode.d1.loss_cls: 0.0999  decode.d1.loss_mask: 0.5468  decode.d1.loss_dice: 1.2112  decode.d2.loss_cls: 0.0981  decode.d2.loss_mask: 0.5474  decode.d2.loss_dice: 1.2300  decode.d3.loss_cls: 0.0992  decode.d3.loss_mask: 0.5433  decode.d3.loss_dice: 1.2423  decode.d4.loss_cls: 0.0879  decode.d4.loss_mask: 0.5539  decode.d4.loss_dice: 1.2338  decode.d5.loss_cls: 0.0958  decode.d5.loss_mask: 0.5489  decode.d5.loss_dice: 1.2573  decode.d6.loss_cls: 0.0920  decode.d6.loss_mask: 0.5450  decode.d6.loss_dice: 1.2335  decode.d7.loss_cls: 0.0872  decode.d7.loss_mask: 0.5302  decode.d7.loss_dice: 1.2404  decode.d8.loss_cls: 0.0889  decode.d8.loss_mask: 0.5320  decode.d8.loss_dice: 1.2390
11/15 11:06:57 - mmengine - INFO - Iter(train) [24900/90000]  base_lr: 7.4715e-05 lr: 7.4715e-06  eta: 10:55:54  time: 0.5970  data_time: 0.0093  memory: 10675  grad_norm: 412.7005  loss: 18.0276  decode.loss_cls: 0.0564  decode.loss_mask: 0.5675  decode.loss_dice: 1.1684  decode.d0.loss_cls: 0.0640  decode.d0.loss_mask: 0.5842  decode.d0.loss_dice: 1.2182  decode.d1.loss_cls: 0.0619  decode.d1.loss_mask: 0.5734  decode.d1.loss_dice: 1.1562  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 0.5682  decode.d2.loss_dice: 1.1698  decode.d3.loss_cls: 0.0591  decode.d3.loss_mask: 0.5699  decode.d3.loss_dice: 1.1448  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.5728  decode.d4.loss_dice: 1.1632  decode.d5.loss_cls: 0.0587  decode.d5.loss_mask: 0.5632  decode.d5.loss_dice: 1.1700  decode.d6.loss_cls: 0.0613  decode.d6.loss_mask: 0.5700  decode.d6.loss_dice: 1.1712  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.5774  decode.d7.loss_dice: 1.1686  decode.d8.loss_cls: 0.0613  decode.d8.loss_mask: 0.5764  decode.d8.loss_dice: 1.1641
11/15 11:07:27 - mmengine - INFO - Iter(train) [24950/90000]  base_lr: 7.4664e-05 lr: 7.4664e-06  eta: 10:55:23  time: 0.5994  data_time: 0.0097  memory: 10692  grad_norm: 484.0018  loss: 18.2865  decode.loss_cls: 0.0845  decode.loss_mask: 0.4501  decode.loss_dice: 1.2774  decode.d0.loss_cls: 0.0756  decode.d0.loss_mask: 0.4581  decode.d0.loss_dice: 1.3937  decode.d1.loss_cls: 0.0881  decode.d1.loss_mask: 0.4507  decode.d1.loss_dice: 1.3070  decode.d2.loss_cls: 0.0851  decode.d2.loss_mask: 0.4529  decode.d2.loss_dice: 1.3035  decode.d3.loss_cls: 0.0835  decode.d3.loss_mask: 0.4481  decode.d3.loss_dice: 1.2449  decode.d4.loss_cls: 0.0810  decode.d4.loss_mask: 0.4560  decode.d4.loss_dice: 1.2908  decode.d5.loss_cls: 0.0904  decode.d5.loss_mask: 0.4511  decode.d5.loss_dice: 1.2607  decode.d6.loss_cls: 0.0984  decode.d6.loss_mask: 0.4444  decode.d6.loss_dice: 1.2714  decode.d7.loss_cls: 0.0923  decode.d7.loss_mask: 0.4541  decode.d7.loss_dice: 1.2874  decode.d8.loss_cls: 0.0822  decode.d8.loss_mask: 0.4503  decode.d8.loss_dice: 1.2730
11/15 11:07:57 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 11:07:57 - mmengine - INFO - Iter(train) [25000/90000]  base_lr: 7.4612e-05 lr: 7.4612e-06  eta: 10:54:52  time: 0.5991  data_time: 0.0098  memory: 10692  grad_norm: 306.1797  loss: 20.4102  decode.loss_cls: 0.0774  decode.loss_mask: 0.6326  decode.loss_dice: 1.3129  decode.d0.loss_cls: 0.1041  decode.d0.loss_mask: 0.6448  decode.d0.loss_dice: 1.3511  decode.d1.loss_cls: 0.0823  decode.d1.loss_mask: 0.6263  decode.d1.loss_dice: 1.3193  decode.d2.loss_cls: 0.0749  decode.d2.loss_mask: 0.6235  decode.d2.loss_dice: 1.3115  decode.d3.loss_cls: 0.0733  decode.d3.loss_mask: 0.6377  decode.d3.loss_dice: 1.3425  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.6470  decode.d4.loss_dice: 1.3418  decode.d5.loss_cls: 0.0806  decode.d5.loss_mask: 0.6393  decode.d5.loss_dice: 1.3314  decode.d6.loss_cls: 0.0782  decode.d6.loss_mask: 0.6261  decode.d6.loss_dice: 1.3165  decode.d7.loss_cls: 0.0844  decode.d7.loss_mask: 0.6308  decode.d7.loss_dice: 1.3236  decode.d8.loss_cls: 0.0856  decode.d8.loss_mask: 0.6256  decode.d8.loss_dice: 1.3170
11/15 11:07:57 - mmengine - INFO - Saving checkpoint at 25000 iterations
11/15 11:08:16 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:25  time: 0.3071  data_time: 0.0037  memory: 4095  
11/15 11:08:32 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:06  time: 0.3079  data_time: 0.0036  memory: 4095  
11/15 11:08:47 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:49  time: 0.3083  data_time: 0.0037  memory: 4095  
11/15 11:09:03 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3081  data_time: 0.0038  memory: 4095  
11/15 11:09:18 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3087  data_time: 0.0038  memory: 4095  
11/15 11:09:33 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:02  time: 0.3088  data_time: 0.0038  memory: 4095  
11/15 11:09:49 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3089  data_time: 0.0041  memory: 4095  
11/15 11:10:04 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:31  time: 0.3093  data_time: 0.0038  memory: 4095  
11/15 11:10:20 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3087  data_time: 0.0038  memory: 4095  
11/15 11:10:35 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3088  data_time: 0.0036  memory: 4095  
11/15 11:10:35 - mmengine - INFO - per class results:
11/15 11:10:35 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     |  97.9 | 98.37 |
|    sidewalk   | 84.56 | 93.23 |
|    building   | 92.52 | 96.65 |
|      wall     | 51.62 | 78.93 |
|     fence     | 53.65 | 70.63 |
|      pole     | 64.55 | 74.63 |
| traffic light | 68.83 | 80.99 |
|  traffic sign | 79.58 | 88.35 |
|   vegetation  | 91.78 | 94.98 |
|    terrain    | 59.57 | 79.75 |
|      sky      | 94.77 | 96.84 |
|     person    | 81.38 | 89.68 |
|     rider     | 61.11 | 75.16 |
|      car      | 94.59 | 97.96 |
|     truck     | 47.53 | 89.21 |
|      bus      | 49.55 |  57.0 |
|     train     |  3.2  |  3.31 |
|   motorcycle  | 62.33 | 84.26 |
|    bicycle    | 75.76 | 83.53 |
+---------------+-------+-------+
11/15 11:10:35 - mmengine - INFO - Iter(val) [500/500]    aAcc: 95.5000  mIoU: 69.2000  mAcc: 80.7100  data_time: 0.0045  time: 0.3100
11/15 11:10:35 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024/best_mIoU_iter_20000.pth is removed
11/15 11:10:37 - mmengine - INFO - The best checkpoint with 69.2000 mIoU at 25000 iter is saved to best_mIoU_iter_25000.pth.
11/15 11:11:10 - mmengine - INFO - Iter(train) [25050/90000]  base_lr: 7.4560e-05 lr: 7.4560e-06  eta: 10:54:35  time: 0.5990  data_time: 0.0101  memory: 10675  grad_norm: 655.5474  loss: 20.4742  decode.loss_cls: 0.0677  decode.loss_mask: 0.7035  decode.loss_dice: 1.2526  decode.d0.loss_cls: 0.0688  decode.d0.loss_mask: 0.7627  decode.d0.loss_dice: 1.3553  decode.d1.loss_cls: 0.0841  decode.d1.loss_mask: 0.6981  decode.d1.loss_dice: 1.2377  decode.d2.loss_cls: 0.0632  decode.d2.loss_mask: 0.7075  decode.d2.loss_dice: 1.2653  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.7084  decode.d3.loss_dice: 1.2670  decode.d4.loss_cls: 0.0596  decode.d4.loss_mask: 0.7030  decode.d4.loss_dice: 1.2767  decode.d5.loss_cls: 0.0632  decode.d5.loss_mask: 0.6913  decode.d5.loss_dice: 1.2511  decode.d6.loss_cls: 0.0635  decode.d6.loss_mask: 0.6881  decode.d6.loss_dice: 1.2394  decode.d7.loss_cls: 0.0644  decode.d7.loss_mask: 0.7317  decode.d7.loss_dice: 1.2653  decode.d8.loss_cls: 0.0704  decode.d8.loss_mask: 0.7217  decode.d8.loss_dice: 1.2705
11/15 11:11:40 - mmengine - INFO - Iter(train) [25100/90000]  base_lr: 7.4509e-05 lr: 7.4509e-06  eta: 10:54:04  time: 0.5968  data_time: 0.0098  memory: 10675  grad_norm: 968.5406  loss: 19.4849  decode.loss_cls: 0.0840  decode.loss_mask: 0.6591  decode.loss_dice: 1.1933  decode.d0.loss_cls: 0.0932  decode.d0.loss_mask: 0.7415  decode.d0.loss_dice: 1.2516  decode.d1.loss_cls: 0.0897  decode.d1.loss_mask: 0.6748  decode.d1.loss_dice: 1.1968  decode.d2.loss_cls: 0.0805  decode.d2.loss_mask: 0.7103  decode.d2.loss_dice: 1.1688  decode.d3.loss_cls: 0.0778  decode.d3.loss_mask: 0.6603  decode.d3.loss_dice: 1.1527  decode.d4.loss_cls: 0.0895  decode.d4.loss_mask: 0.6615  decode.d4.loss_dice: 1.1679  decode.d5.loss_cls: 0.0876  decode.d5.loss_mask: 0.6585  decode.d5.loss_dice: 1.1468  decode.d6.loss_cls: 0.0901  decode.d6.loss_mask: 0.6555  decode.d6.loss_dice: 1.1516  decode.d7.loss_cls: 0.0827  decode.d7.loss_mask: 0.7037  decode.d7.loss_dice: 1.1935  decode.d8.loss_cls: 0.0767  decode.d8.loss_mask: 0.6979  decode.d8.loss_dice: 1.1871
11/15 11:12:10 - mmengine - INFO - Iter(train) [25150/90000]  base_lr: 7.4457e-05 lr: 7.4457e-06  eta: 10:53:33  time: 0.5978  data_time: 0.0098  memory: 10656  grad_norm: 256.1825  loss: 15.7097  decode.loss_cls: 0.0486  decode.loss_mask: 0.4927  decode.loss_dice: 1.0012  decode.d0.loss_cls: 0.0687  decode.d0.loss_mask: 0.4999  decode.d0.loss_dice: 1.0670  decode.d1.loss_cls: 0.0546  decode.d1.loss_mask: 0.4874  decode.d1.loss_dice: 1.0163  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.4856  decode.d2.loss_dice: 1.0187  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.4889  decode.d3.loss_dice: 1.0351  decode.d4.loss_cls: 0.0495  decode.d4.loss_mask: 0.4947  decode.d4.loss_dice: 1.0183  decode.d5.loss_cls: 0.0503  decode.d5.loss_mask: 0.4835  decode.d5.loss_dice: 1.0264  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.4832  decode.d6.loss_dice: 1.0186  decode.d7.loss_cls: 0.0464  decode.d7.loss_mask: 0.4857  decode.d7.loss_dice: 1.0222  decode.d8.loss_cls: 0.0505  decode.d8.loss_mask: 0.4935  decode.d8.loss_dice: 1.0637
11/15 11:12:40 - mmengine - INFO - Iter(train) [25200/90000]  base_lr: 7.4405e-05 lr: 7.4405e-06  eta: 10:53:02  time: 0.5976  data_time: 0.0098  memory: 10675  grad_norm: 431.4210  loss: 20.3185  decode.loss_cls: 0.1026  decode.loss_mask: 0.6471  decode.loss_dice: 1.3185  decode.d0.loss_cls: 0.0998  decode.d0.loss_mask: 0.6682  decode.d0.loss_dice: 1.3570  decode.d1.loss_cls: 0.1138  decode.d1.loss_mask: 0.6540  decode.d1.loss_dice: 1.3203  decode.d2.loss_cls: 0.0988  decode.d2.loss_mask: 0.6218  decode.d2.loss_dice: 1.3215  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 0.6105  decode.d3.loss_dice: 1.3121  decode.d4.loss_cls: 0.0990  decode.d4.loss_mask: 0.6073  decode.d4.loss_dice: 1.3043  decode.d5.loss_cls: 0.1039  decode.d5.loss_mask: 0.6129  decode.d5.loss_dice: 1.2813  decode.d6.loss_cls: 0.0983  decode.d6.loss_mask: 0.6117  decode.d6.loss_dice: 1.2538  decode.d7.loss_cls: 0.1058  decode.d7.loss_mask: 0.6117  decode.d7.loss_dice: 1.2466  decode.d8.loss_cls: 0.1042  decode.d8.loss_mask: 0.6281  decode.d8.loss_dice: 1.3019
11/15 11:13:10 - mmengine - INFO - Iter(train) [25250/90000]  base_lr: 7.4354e-05 lr: 7.4354e-06  eta: 10:52:31  time: 0.5986  data_time: 0.0099  memory: 10728  grad_norm: 686.8960  loss: 20.6284  decode.loss_cls: 0.0898  decode.loss_mask: 0.5718  decode.loss_dice: 1.3813  decode.d0.loss_cls: 0.0894  decode.d0.loss_mask: 0.5982  decode.d0.loss_dice: 1.4541  decode.d1.loss_cls: 0.0886  decode.d1.loss_mask: 0.5872  decode.d1.loss_dice: 1.4060  decode.d2.loss_cls: 0.0790  decode.d2.loss_mask: 0.5815  decode.d2.loss_dice: 1.3924  decode.d3.loss_cls: 0.0849  decode.d3.loss_mask: 0.5847  decode.d3.loss_dice: 1.3781  decode.d4.loss_cls: 0.0766  decode.d4.loss_mask: 0.5791  decode.d4.loss_dice: 1.4080  decode.d5.loss_cls: 0.0887  decode.d5.loss_mask: 0.5698  decode.d5.loss_dice: 1.3902  decode.d6.loss_cls: 0.0895  decode.d6.loss_mask: 0.5729  decode.d6.loss_dice: 1.3760  decode.d7.loss_cls: 0.0772  decode.d7.loss_mask: 0.5774  decode.d7.loss_dice: 1.3915  decode.d8.loss_cls: 0.0930  decode.d8.loss_mask: 0.5845  decode.d8.loss_dice: 1.3873
11/15 11:13:40 - mmengine - INFO - Iter(train) [25300/90000]  base_lr: 7.4302e-05 lr: 7.4302e-06  eta: 10:51:59  time: 0.5966  data_time: 0.0098  memory: 10713  grad_norm: 276.4738  loss: 17.7353  decode.loss_cls: 0.0837  decode.loss_mask: 0.5315  decode.loss_dice: 1.1211  decode.d0.loss_cls: 0.0936  decode.d0.loss_mask: 0.5605  decode.d0.loss_dice: 1.2852  decode.d1.loss_cls: 0.0944  decode.d1.loss_mask: 0.5523  decode.d1.loss_dice: 1.1634  decode.d2.loss_cls: 0.0885  decode.d2.loss_mask: 0.5440  decode.d2.loss_dice: 1.1554  decode.d3.loss_cls: 0.0764  decode.d3.loss_mask: 0.5437  decode.d3.loss_dice: 1.1400  decode.d4.loss_cls: 0.0886  decode.d4.loss_mask: 0.5326  decode.d4.loss_dice: 1.1105  decode.d5.loss_cls: 0.0831  decode.d5.loss_mask: 0.5376  decode.d5.loss_dice: 1.1483  decode.d6.loss_cls: 0.0788  decode.d6.loss_mask: 0.5491  decode.d6.loss_dice: 1.1325  decode.d7.loss_cls: 0.0833  decode.d7.loss_mask: 0.5384  decode.d7.loss_dice: 1.0930  decode.d8.loss_cls: 0.0950  decode.d8.loss_mask: 0.5362  decode.d8.loss_dice: 1.0943
11/15 11:14:10 - mmengine - INFO - Iter(train) [25350/90000]  base_lr: 7.4250e-05 lr: 7.4250e-06  eta: 10:51:28  time: 0.5988  data_time: 0.0098  memory: 10656  grad_norm: 247.7838  loss: 17.9186  decode.loss_cls: 0.0707  decode.loss_mask: 0.5192  decode.loss_dice: 1.2051  decode.d0.loss_cls: 0.0912  decode.d0.loss_mask: 0.5240  decode.d0.loss_dice: 1.2560  decode.d1.loss_cls: 0.0737  decode.d1.loss_mask: 0.5099  decode.d1.loss_dice: 1.1862  decode.d2.loss_cls: 0.0773  decode.d2.loss_mask: 0.5100  decode.d2.loss_dice: 1.1847  decode.d3.loss_cls: 0.0806  decode.d3.loss_mask: 0.4993  decode.d3.loss_dice: 1.1834  decode.d4.loss_cls: 0.0783  decode.d4.loss_mask: 0.5110  decode.d4.loss_dice: 1.1717  decode.d5.loss_cls: 0.0878  decode.d5.loss_mask: 0.5102  decode.d5.loss_dice: 1.1961  decode.d6.loss_cls: 0.0845  decode.d6.loss_mask: 0.5232  decode.d6.loss_dice: 1.1813  decode.d7.loss_cls: 0.0833  decode.d7.loss_mask: 0.5208  decode.d7.loss_dice: 1.2065  decode.d8.loss_cls: 0.0765  decode.d8.loss_mask: 0.5269  decode.d8.loss_dice: 1.1894
11/15 11:14:40 - mmengine - INFO - Iter(train) [25400/90000]  base_lr: 7.4199e-05 lr: 7.4199e-06  eta: 10:50:57  time: 0.5990  data_time: 0.0098  memory: 10692  grad_norm: 583.9532  loss: 19.4860  decode.loss_cls: 0.0996  decode.loss_mask: 0.5244  decode.loss_dice: 1.2963  decode.d0.loss_cls: 0.1160  decode.d0.loss_mask: 0.5415  decode.d0.loss_dice: 1.3943  decode.d1.loss_cls: 0.1124  decode.d1.loss_mask: 0.5321  decode.d1.loss_dice: 1.2957  decode.d2.loss_cls: 0.1129  decode.d2.loss_mask: 0.5279  decode.d2.loss_dice: 1.3154  decode.d3.loss_cls: 0.1061  decode.d3.loss_mask: 0.5274  decode.d3.loss_dice: 1.2909  decode.d4.loss_cls: 0.0869  decode.d4.loss_mask: 0.5300  decode.d4.loss_dice: 1.3194  decode.d5.loss_cls: 0.0940  decode.d5.loss_mask: 0.5200  decode.d5.loss_dice: 1.3370  decode.d6.loss_cls: 0.1052  decode.d6.loss_mask: 0.5236  decode.d6.loss_dice: 1.3114  decode.d7.loss_cls: 0.1001  decode.d7.loss_mask: 0.5082  decode.d7.loss_dice: 1.3327  decode.d8.loss_cls: 0.0968  decode.d8.loss_mask: 0.5144  decode.d8.loss_dice: 1.3135
11/15 11:15:10 - mmengine - INFO - Iter(train) [25450/90000]  base_lr: 7.4147e-05 lr: 7.4147e-06  eta: 10:50:26  time: 0.6015  data_time: 0.0100  memory: 10692  grad_norm: 1263.1703  loss: 19.3340  decode.loss_cls: 0.0641  decode.loss_mask: 0.6409  decode.loss_dice: 1.2252  decode.d0.loss_cls: 0.0798  decode.d0.loss_mask: 0.6125  decode.d0.loss_dice: 1.2587  decode.d1.loss_cls: 0.0662  decode.d1.loss_mask: 0.6303  decode.d1.loss_dice: 1.2471  decode.d2.loss_cls: 0.0644  decode.d2.loss_mask: 0.6317  decode.d2.loss_dice: 1.2366  decode.d3.loss_cls: 0.0682  decode.d3.loss_mask: 0.6428  decode.d3.loss_dice: 1.2426  decode.d4.loss_cls: 0.0733  decode.d4.loss_mask: 0.6348  decode.d4.loss_dice: 1.2126  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.6122  decode.d5.loss_dice: 1.2227  decode.d6.loss_cls: 0.0704  decode.d6.loss_mask: 0.6423  decode.d6.loss_dice: 1.2050  decode.d7.loss_cls: 0.0691  decode.d7.loss_mask: 0.6494  decode.d7.loss_dice: 1.2317  decode.d8.loss_cls: 0.0772  decode.d8.loss_mask: 0.6340  decode.d8.loss_dice: 1.2216
11/15 11:15:40 - mmengine - INFO - Iter(train) [25500/90000]  base_lr: 7.4095e-05 lr: 7.4095e-06  eta: 10:49:56  time: 0.6007  data_time: 0.0100  memory: 10656  grad_norm: 425.7268  loss: 19.2449  decode.loss_cls: 0.0936  decode.loss_mask: 0.5945  decode.loss_dice: 1.2230  decode.d0.loss_cls: 0.1031  decode.d0.loss_mask: 0.5972  decode.d0.loss_dice: 1.3116  decode.d1.loss_cls: 0.1038  decode.d1.loss_mask: 0.5884  decode.d1.loss_dice: 1.2419  decode.d2.loss_cls: 0.1093  decode.d2.loss_mask: 0.5823  decode.d2.loss_dice: 1.2251  decode.d3.loss_cls: 0.1018  decode.d3.loss_mask: 0.5946  decode.d3.loss_dice: 1.2280  decode.d4.loss_cls: 0.1021  decode.d4.loss_mask: 0.5833  decode.d4.loss_dice: 1.2096  decode.d5.loss_cls: 0.0971  decode.d5.loss_mask: 0.5958  decode.d5.loss_dice: 1.2338  decode.d6.loss_cls: 0.0775  decode.d6.loss_mask: 0.6088  decode.d6.loss_dice: 1.2306  decode.d7.loss_cls: 0.0828  decode.d7.loss_mask: 0.5971  decode.d7.loss_dice: 1.2058  decode.d8.loss_cls: 0.0988  decode.d8.loss_mask: 0.6034  decode.d8.loss_dice: 1.2205
11/15 11:16:10 - mmengine - INFO - Iter(train) [25550/90000]  base_lr: 7.4043e-05 lr: 7.4043e-06  eta: 10:49:25  time: 0.6009  data_time: 0.0100  memory: 10675  grad_norm: 499.9568  loss: 18.7475  decode.loss_cls: 0.0628  decode.loss_mask: 0.5351  decode.loss_dice: 1.2740  decode.d0.loss_cls: 0.0855  decode.d0.loss_mask: 0.5433  decode.d0.loss_dice: 1.2982  decode.d1.loss_cls: 0.0673  decode.d1.loss_mask: 0.5339  decode.d1.loss_dice: 1.3244  decode.d2.loss_cls: 0.0599  decode.d2.loss_mask: 0.5374  decode.d2.loss_dice: 1.2856  decode.d3.loss_cls: 0.0632  decode.d3.loss_mask: 0.5293  decode.d3.loss_dice: 1.2486  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.5291  decode.d4.loss_dice: 1.2888  decode.d5.loss_cls: 0.0699  decode.d5.loss_mask: 0.5268  decode.d5.loss_dice: 1.2641  decode.d6.loss_cls: 0.0632  decode.d6.loss_mask: 0.5239  decode.d6.loss_dice: 1.2784  decode.d7.loss_cls: 0.0648  decode.d7.loss_mask: 0.5223  decode.d7.loss_dice: 1.2488  decode.d8.loss_cls: 0.0576  decode.d8.loss_mask: 0.5380  decode.d8.loss_dice: 1.2582
11/15 11:16:40 - mmengine - INFO - Iter(train) [25600/90000]  base_lr: 7.3992e-05 lr: 7.3992e-06  eta: 10:48:55  time: 0.5989  data_time: 0.0101  memory: 10713  grad_norm: 525.1745  loss: 18.5086  decode.loss_cls: 0.0606  decode.loss_mask: 0.6032  decode.loss_dice: 1.1631  decode.d0.loss_cls: 0.0809  decode.d0.loss_mask: 0.6121  decode.d0.loss_dice: 1.2835  decode.d1.loss_cls: 0.0636  decode.d1.loss_mask: 0.5878  decode.d1.loss_dice: 1.2237  decode.d2.loss_cls: 0.0566  decode.d2.loss_mask: 0.6101  decode.d2.loss_dice: 1.2155  decode.d3.loss_cls: 0.0545  decode.d3.loss_mask: 0.6130  decode.d3.loss_dice: 1.1630  decode.d4.loss_cls: 0.0593  decode.d4.loss_mask: 0.6127  decode.d4.loss_dice: 1.1542  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.6045  decode.d5.loss_dice: 1.1414  decode.d6.loss_cls: 0.0493  decode.d6.loss_mask: 0.6110  decode.d6.loss_dice: 1.1689  decode.d7.loss_cls: 0.0497  decode.d7.loss_mask: 0.6107  decode.d7.loss_dice: 1.1855  decode.d8.loss_cls: 0.0510  decode.d8.loss_mask: 0.5983  decode.d8.loss_dice: 1.1667
11/15 11:17:10 - mmengine - INFO - Iter(train) [25650/90000]  base_lr: 7.3940e-05 lr: 7.3940e-06  eta: 10:48:24  time: 0.6003  data_time: 0.0100  memory: 10675  grad_norm: 410.5166  loss: 18.2952  decode.loss_cls: 0.0911  decode.loss_mask: 0.5249  decode.loss_dice: 1.2157  decode.d0.loss_cls: 0.0887  decode.d0.loss_mask: 0.5420  decode.d0.loss_dice: 1.2824  decode.d1.loss_cls: 0.0882  decode.d1.loss_mask: 0.5301  decode.d1.loss_dice: 1.2243  decode.d2.loss_cls: 0.0960  decode.d2.loss_mask: 0.5281  decode.d2.loss_dice: 1.2046  decode.d3.loss_cls: 0.0928  decode.d3.loss_mask: 0.5273  decode.d3.loss_dice: 1.1931  decode.d4.loss_cls: 0.0943  decode.d4.loss_mask: 0.5177  decode.d4.loss_dice: 1.2129  decode.d5.loss_cls: 0.0839  decode.d5.loss_mask: 0.5227  decode.d5.loss_dice: 1.2062  decode.d6.loss_cls: 0.0793  decode.d6.loss_mask: 0.5223  decode.d6.loss_dice: 1.2070  decode.d7.loss_cls: 0.0852  decode.d7.loss_mask: 0.5288  decode.d7.loss_dice: 1.2040  decode.d8.loss_cls: 0.0674  decode.d8.loss_mask: 0.5261  decode.d8.loss_dice: 1.2079
11/15 11:17:40 - mmengine - INFO - Iter(train) [25700/90000]  base_lr: 7.3888e-05 lr: 7.3888e-06  eta: 10:47:53  time: 0.6127  data_time: 0.0110  memory: 10692  grad_norm: 642.4623  loss: 20.8755  decode.loss_cls: 0.1440  decode.loss_mask: 0.5301  decode.loss_dice: 1.4082  decode.d0.loss_cls: 0.0861  decode.d0.loss_mask: 0.5629  decode.d0.loss_dice: 1.5859  decode.d1.loss_cls: 0.1165  decode.d1.loss_mask: 0.5470  decode.d1.loss_dice: 1.4557  decode.d2.loss_cls: 0.1140  decode.d2.loss_mask: 0.5518  decode.d2.loss_dice: 1.4043  decode.d3.loss_cls: 0.1339  decode.d3.loss_mask: 0.5423  decode.d3.loss_dice: 1.3550  decode.d4.loss_cls: 0.1201  decode.d4.loss_mask: 0.5381  decode.d4.loss_dice: 1.4284  decode.d5.loss_cls: 0.1249  decode.d5.loss_mask: 0.5353  decode.d5.loss_dice: 1.4074  decode.d6.loss_cls: 0.1183  decode.d6.loss_mask: 0.5426  decode.d6.loss_dice: 1.3911  decode.d7.loss_cls: 0.1371  decode.d7.loss_mask: 0.5362  decode.d7.loss_dice: 1.3863  decode.d8.loss_cls: 0.1212  decode.d8.loss_mask: 0.5390  decode.d8.loss_dice: 1.4118
11/15 11:18:10 - mmengine - INFO - Iter(train) [25750/90000]  base_lr: 7.3837e-05 lr: 7.3837e-06  eta: 10:47:22  time: 0.5986  data_time: 0.0100  memory: 10656  grad_norm: 395.3984  loss: 19.6018  decode.loss_cls: 0.0510  decode.loss_mask: 0.7080  decode.loss_dice: 1.1877  decode.d0.loss_cls: 0.0882  decode.d0.loss_mask: 0.7460  decode.d0.loss_dice: 1.2471  decode.d1.loss_cls: 0.0628  decode.d1.loss_mask: 0.6958  decode.d1.loss_dice: 1.2230  decode.d2.loss_cls: 0.0574  decode.d2.loss_mask: 0.6916  decode.d2.loss_dice: 1.2048  decode.d3.loss_cls: 0.0512  decode.d3.loss_mask: 0.6773  decode.d3.loss_dice: 1.1923  decode.d4.loss_cls: 0.0590  decode.d4.loss_mask: 0.6706  decode.d4.loss_dice: 1.1794  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.6780  decode.d5.loss_dice: 1.1795  decode.d6.loss_cls: 0.0632  decode.d6.loss_mask: 0.7068  decode.d6.loss_dice: 1.2368  decode.d7.loss_cls: 0.0561  decode.d7.loss_mask: 0.7022  decode.d7.loss_dice: 1.1809  decode.d8.loss_cls: 0.0445  decode.d8.loss_mask: 0.7043  decode.d8.loss_dice: 1.2011
11/15 11:18:40 - mmengine - INFO - Iter(train) [25800/90000]  base_lr: 7.3785e-05 lr: 7.3785e-06  eta: 10:46:51  time: 0.5987  data_time: 0.0099  memory: 10675  grad_norm: 232.7071  loss: 16.4398  decode.loss_cls: 0.0512  decode.loss_mask: 0.4992  decode.loss_dice: 1.0789  decode.d0.loss_cls: 0.0856  decode.d0.loss_mask: 0.5102  decode.d0.loss_dice: 1.1333  decode.d1.loss_cls: 0.0640  decode.d1.loss_mask: 0.4895  decode.d1.loss_dice: 1.1259  decode.d2.loss_cls: 0.0629  decode.d2.loss_mask: 0.4945  decode.d2.loss_dice: 1.0889  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.5013  decode.d3.loss_dice: 1.0843  decode.d4.loss_cls: 0.0620  decode.d4.loss_mask: 0.4959  decode.d4.loss_dice: 1.0684  decode.d5.loss_cls: 0.0585  decode.d5.loss_mask: 0.4968  decode.d5.loss_dice: 1.0604  decode.d6.loss_cls: 0.0544  decode.d6.loss_mask: 0.4942  decode.d6.loss_dice: 1.0699  decode.d7.loss_cls: 0.0524  decode.d7.loss_mask: 0.4922  decode.d7.loss_dice: 1.0861  decode.d8.loss_cls: 0.0484  decode.d8.loss_mask: 0.5027  decode.d8.loss_dice: 1.0713
11/15 11:19:10 - mmengine - INFO - Iter(train) [25850/90000]  base_lr: 7.3733e-05 lr: 7.3733e-06  eta: 10:46:20  time: 0.5970  data_time: 0.0097  memory: 10713  grad_norm: 404.4803  loss: 18.3297  decode.loss_cls: 0.0582  decode.loss_mask: 0.5410  decode.loss_dice: 1.2126  decode.d0.loss_cls: 0.0704  decode.d0.loss_mask: 0.5419  decode.d0.loss_dice: 1.2950  decode.d1.loss_cls: 0.0566  decode.d1.loss_mask: 0.5505  decode.d1.loss_dice: 1.2447  decode.d2.loss_cls: 0.0534  decode.d2.loss_mask: 0.5461  decode.d2.loss_dice: 1.2183  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.5495  decode.d3.loss_dice: 1.2248  decode.d4.loss_cls: 0.0542  decode.d4.loss_mask: 0.5336  decode.d4.loss_dice: 1.2418  decode.d5.loss_cls: 0.0622  decode.d5.loss_mask: 0.5281  decode.d5.loss_dice: 1.2083  decode.d6.loss_cls: 0.0464  decode.d6.loss_mask: 0.5304  decode.d6.loss_dice: 1.2516  decode.d7.loss_cls: 0.0573  decode.d7.loss_mask: 0.5520  decode.d7.loss_dice: 1.2351  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.5335  decode.d8.loss_dice: 1.2130
11/15 11:19:40 - mmengine - INFO - Iter(train) [25900/90000]  base_lr: 7.3681e-05 lr: 7.3681e-06  eta: 10:45:49  time: 0.5973  data_time: 0.0100  memory: 10713  grad_norm: 696.9876  loss: 18.3286  decode.loss_cls: 0.0734  decode.loss_mask: 0.7145  decode.loss_dice: 1.0968  decode.d0.loss_cls: 0.0934  decode.d0.loss_mask: 0.7033  decode.d0.loss_dice: 1.1044  decode.d1.loss_cls: 0.0773  decode.d1.loss_mask: 0.6692  decode.d1.loss_dice: 1.0686  decode.d2.loss_cls: 0.0746  decode.d2.loss_mask: 0.6723  decode.d2.loss_dice: 1.0376  decode.d3.loss_cls: 0.0752  decode.d3.loss_mask: 0.6741  decode.d3.loss_dice: 1.0538  decode.d4.loss_cls: 0.0793  decode.d4.loss_mask: 0.6580  decode.d4.loss_dice: 1.0121  decode.d5.loss_cls: 0.0724  decode.d5.loss_mask: 0.7292  decode.d5.loss_dice: 1.0472  decode.d6.loss_cls: 0.0800  decode.d6.loss_mask: 0.6994  decode.d6.loss_dice: 1.0557  decode.d7.loss_cls: 0.0789  decode.d7.loss_mask: 0.6964  decode.d7.loss_dice: 1.0545  decode.d8.loss_cls: 0.0693  decode.d8.loss_mask: 0.7288  decode.d8.loss_dice: 1.0790
11/15 11:20:10 - mmengine - INFO - Iter(train) [25950/90000]  base_lr: 7.3630e-05 lr: 7.3630e-06  eta: 10:45:19  time: 0.5996  data_time: 0.0100  memory: 10692  grad_norm: 411.4077  loss: 18.5236  decode.loss_cls: 0.0595  decode.loss_mask: 0.5850  decode.loss_dice: 1.1744  decode.d0.loss_cls: 0.0727  decode.d0.loss_mask: 0.6113  decode.d0.loss_dice: 1.2510  decode.d1.loss_cls: 0.0672  decode.d1.loss_mask: 0.5980  decode.d1.loss_dice: 1.2225  decode.d2.loss_cls: 0.0534  decode.d2.loss_mask: 0.5802  decode.d2.loss_dice: 1.1911  decode.d3.loss_cls: 0.0491  decode.d3.loss_mask: 0.5919  decode.d3.loss_dice: 1.2254  decode.d4.loss_cls: 0.0538  decode.d4.loss_mask: 0.5875  decode.d4.loss_dice: 1.2017  decode.d5.loss_cls: 0.0448  decode.d5.loss_mask: 0.5892  decode.d5.loss_dice: 1.2187  decode.d6.loss_cls: 0.0604  decode.d6.loss_mask: 0.5866  decode.d6.loss_dice: 1.1868  decode.d7.loss_cls: 0.0564  decode.d7.loss_mask: 0.5792  decode.d7.loss_dice: 1.2074  decode.d8.loss_cls: 0.0517  decode.d8.loss_mask: 0.5795  decode.d8.loss_dice: 1.1872
11/15 11:20:40 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 11:20:40 - mmengine - INFO - Iter(train) [26000/90000]  base_lr: 7.3578e-05 lr: 7.3578e-06  eta: 10:44:48  time: 0.6007  data_time: 0.0101  memory: 10713  grad_norm: 444.1201  loss: 16.6504  decode.loss_cls: 0.0668  decode.loss_mask: 0.4774  decode.loss_dice: 1.0976  decode.d0.loss_cls: 0.0902  decode.d0.loss_mask: 0.5024  decode.d0.loss_dice: 1.1792  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.4788  decode.d1.loss_dice: 1.1551  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.4886  decode.d2.loss_dice: 1.1475  decode.d3.loss_cls: 0.0656  decode.d3.loss_mask: 0.4764  decode.d3.loss_dice: 1.1211  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.4893  decode.d4.loss_dice: 1.1090  decode.d5.loss_cls: 0.0575  decode.d5.loss_mask: 0.4742  decode.d5.loss_dice: 1.0744  decode.d6.loss_cls: 0.0596  decode.d6.loss_mask: 0.4708  decode.d6.loss_dice: 1.1085  decode.d7.loss_cls: 0.0715  decode.d7.loss_mask: 0.4744  decode.d7.loss_dice: 1.0980  decode.d8.loss_cls: 0.0584  decode.d8.loss_mask: 0.4781  decode.d8.loss_dice: 1.0866
11/15 11:21:10 - mmengine - INFO - Iter(train) [26050/90000]  base_lr: 7.3526e-05 lr: 7.3526e-06  eta: 10:44:17  time: 0.5987  data_time: 0.0098  memory: 10728  grad_norm: 350.5337  loss: 19.1800  decode.loss_cls: 0.0919  decode.loss_mask: 0.5823  decode.loss_dice: 1.2126  decode.d0.loss_cls: 0.1041  decode.d0.loss_mask: 0.5940  decode.d0.loss_dice: 1.3074  decode.d1.loss_cls: 0.0972  decode.d1.loss_mask: 0.5877  decode.d1.loss_dice: 1.2283  decode.d2.loss_cls: 0.1011  decode.d2.loss_mask: 0.6001  decode.d2.loss_dice: 1.2317  decode.d3.loss_cls: 0.1065  decode.d3.loss_mask: 0.5876  decode.d3.loss_dice: 1.1933  decode.d4.loss_cls: 0.0987  decode.d4.loss_mask: 0.5940  decode.d4.loss_dice: 1.2254  decode.d5.loss_cls: 0.1000  decode.d5.loss_mask: 0.5836  decode.d5.loss_dice: 1.2136  decode.d6.loss_cls: 0.0880  decode.d6.loss_mask: 0.5813  decode.d6.loss_dice: 1.2601  decode.d7.loss_cls: 0.0869  decode.d7.loss_mask: 0.5757  decode.d7.loss_dice: 1.2363  decode.d8.loss_cls: 0.0911  decode.d8.loss_mask: 0.5965  decode.d8.loss_dice: 1.2230
11/15 11:21:40 - mmengine - INFO - Iter(train) [26100/90000]  base_lr: 7.3475e-05 lr: 7.3475e-06  eta: 10:43:47  time: 0.6054  data_time: 0.0101  memory: 10692  grad_norm: 294.5201  loss: 18.9819  decode.loss_cls: 0.0567  decode.loss_mask: 0.5513  decode.loss_dice: 1.2837  decode.d0.loss_cls: 0.0631  decode.d0.loss_mask: 0.5618  decode.d0.loss_dice: 1.3119  decode.d1.loss_cls: 0.0631  decode.d1.loss_mask: 0.5347  decode.d1.loss_dice: 1.2912  decode.d2.loss_cls: 0.0499  decode.d2.loss_mask: 0.5459  decode.d2.loss_dice: 1.2862  decode.d3.loss_cls: 0.0519  decode.d3.loss_mask: 0.5522  decode.d3.loss_dice: 1.2817  decode.d4.loss_cls: 0.0547  decode.d4.loss_mask: 0.5459  decode.d4.loss_dice: 1.2885  decode.d5.loss_cls: 0.0621  decode.d5.loss_mask: 0.5466  decode.d5.loss_dice: 1.2716  decode.d6.loss_cls: 0.0527  decode.d6.loss_mask: 0.5496  decode.d6.loss_dice: 1.2822  decode.d7.loss_cls: 0.0368  decode.d7.loss_mask: 0.5802  decode.d7.loss_dice: 1.2909  decode.d8.loss_cls: 0.0440  decode.d8.loss_mask: 0.5811  decode.d8.loss_dice: 1.3099
11/15 11:22:10 - mmengine - INFO - Iter(train) [26150/90000]  base_lr: 7.3423e-05 lr: 7.3423e-06  eta: 10:43:17  time: 0.6028  data_time: 0.0102  memory: 10641  grad_norm: 441.2694  loss: 17.3086  decode.loss_cls: 0.0683  decode.loss_mask: 0.5057  decode.loss_dice: 1.1266  decode.d0.loss_cls: 0.0971  decode.d0.loss_mask: 0.5514  decode.d0.loss_dice: 1.1650  decode.d1.loss_cls: 0.0636  decode.d1.loss_mask: 0.5084  decode.d1.loss_dice: 1.1717  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.5182  decode.d2.loss_dice: 1.1698  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.5166  decode.d3.loss_dice: 1.1378  decode.d4.loss_cls: 0.0735  decode.d4.loss_mask: 0.5128  decode.d4.loss_dice: 1.1141  decode.d5.loss_cls: 0.0626  decode.d5.loss_mask: 0.5024  decode.d5.loss_dice: 1.1371  decode.d6.loss_cls: 0.0725  decode.d6.loss_mask: 0.5129  decode.d6.loss_dice: 1.1237  decode.d7.loss_cls: 0.0594  decode.d7.loss_mask: 0.5225  decode.d7.loss_dice: 1.1598  decode.d8.loss_cls: 0.0694  decode.d8.loss_mask: 0.5113  decode.d8.loss_dice: 1.1548
11/15 11:22:41 - mmengine - INFO - Iter(train) [26200/90000]  base_lr: 7.3371e-05 lr: 7.3371e-06  eta: 10:42:47  time: 0.6059  data_time: 0.0107  memory: 10728  grad_norm: 326.1494  loss: 20.0986  decode.loss_cls: 0.0761  decode.loss_mask: 0.5953  decode.loss_dice: 1.3406  decode.d0.loss_cls: 0.0871  decode.d0.loss_mask: 0.5792  decode.d0.loss_dice: 1.4090  decode.d1.loss_cls: 0.0978  decode.d1.loss_mask: 0.5671  decode.d1.loss_dice: 1.3729  decode.d2.loss_cls: 0.0872  decode.d2.loss_mask: 0.5702  decode.d2.loss_dice: 1.3317  decode.d3.loss_cls: 0.0845  decode.d3.loss_mask: 0.5660  decode.d3.loss_dice: 1.3127  decode.d4.loss_cls: 0.0907  decode.d4.loss_mask: 0.5741  decode.d4.loss_dice: 1.3319  decode.d5.loss_cls: 0.0804  decode.d5.loss_mask: 0.5821  decode.d5.loss_dice: 1.3328  decode.d6.loss_cls: 0.0881  decode.d6.loss_mask: 0.5748  decode.d6.loss_dice: 1.3307  decode.d7.loss_cls: 0.0867  decode.d7.loss_mask: 0.5809  decode.d7.loss_dice: 1.3386  decode.d8.loss_cls: 0.0770  decode.d8.loss_mask: 0.6016  decode.d8.loss_dice: 1.3509
11/15 11:23:13 - mmengine - INFO - Iter(train) [26250/90000]  base_lr: 7.3319e-05 lr: 7.3319e-06  eta: 10:42:22  time: 0.6011  data_time: 0.0100  memory: 10675  grad_norm: 544.5659  loss: 19.9725  decode.loss_cls: 0.1003  decode.loss_mask: 0.6565  decode.loss_dice: 1.2193  decode.d0.loss_cls: 0.1247  decode.d0.loss_mask: 0.6457  decode.d0.loss_dice: 1.3139  decode.d1.loss_cls: 0.1045  decode.d1.loss_mask: 0.6679  decode.d1.loss_dice: 1.1937  decode.d2.loss_cls: 0.0972  decode.d2.loss_mask: 0.6754  decode.d2.loss_dice: 1.2358  decode.d3.loss_cls: 0.1118  decode.d3.loss_mask: 0.6525  decode.d3.loss_dice: 1.2209  decode.d4.loss_cls: 0.1044  decode.d4.loss_mask: 0.6522  decode.d4.loss_dice: 1.2320  decode.d5.loss_cls: 0.1014  decode.d5.loss_mask: 0.6712  decode.d5.loss_dice: 1.2096  decode.d6.loss_cls: 0.0900  decode.d6.loss_mask: 0.6607  decode.d6.loss_dice: 1.2437  decode.d7.loss_cls: 0.1008  decode.d7.loss_mask: 0.6654  decode.d7.loss_dice: 1.2423  decode.d8.loss_cls: 0.0944  decode.d8.loss_mask: 0.6674  decode.d8.loss_dice: 1.2167
11/15 11:23:43 - mmengine - INFO - Iter(train) [26300/90000]  base_lr: 7.3268e-05 lr: 7.3268e-06  eta: 10:41:51  time: 0.6024  data_time: 0.0103  memory: 10656  grad_norm: 320.7748  loss: 17.2460  decode.loss_cls: 0.0498  decode.loss_mask: 0.6333  decode.loss_dice: 1.0689  decode.d0.loss_cls: 0.0777  decode.d0.loss_mask: 0.6410  decode.d0.loss_dice: 1.0954  decode.d1.loss_cls: 0.0489  decode.d1.loss_mask: 0.6230  decode.d1.loss_dice: 1.0210  decode.d2.loss_cls: 0.0528  decode.d2.loss_mask: 0.6043  decode.d2.loss_dice: 1.0176  decode.d3.loss_cls: 0.0485  decode.d3.loss_mask: 0.6066  decode.d3.loss_dice: 1.0471  decode.d4.loss_cls: 0.0423  decode.d4.loss_mask: 0.6099  decode.d4.loss_dice: 1.0561  decode.d5.loss_cls: 0.0396  decode.d5.loss_mask: 0.6253  decode.d5.loss_dice: 1.0504  decode.d6.loss_cls: 0.0444  decode.d6.loss_mask: 0.6180  decode.d6.loss_dice: 1.0508  decode.d7.loss_cls: 0.0421  decode.d7.loss_mask: 0.6224  decode.d7.loss_dice: 1.0687  decode.d8.loss_cls: 0.0452  decode.d8.loss_mask: 0.6289  decode.d8.loss_dice: 1.0661
11/15 11:24:13 - mmengine - INFO - Iter(train) [26350/90000]  base_lr: 7.3216e-05 lr: 7.3216e-06  eta: 10:41:21  time: 0.6038  data_time: 0.0104  memory: 10675  grad_norm: 376.4651  loss: 17.7867  decode.loss_cls: 0.0679  decode.loss_mask: 0.5457  decode.loss_dice: 1.1523  decode.d0.loss_cls: 0.0767  decode.d0.loss_mask: 0.5621  decode.d0.loss_dice: 1.2513  decode.d1.loss_cls: 0.0716  decode.d1.loss_mask: 0.5402  decode.d1.loss_dice: 1.2052  decode.d2.loss_cls: 0.0646  decode.d2.loss_mask: 0.5400  decode.d2.loss_dice: 1.1643  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.5409  decode.d3.loss_dice: 1.1937  decode.d4.loss_cls: 0.0562  decode.d4.loss_mask: 0.5454  decode.d4.loss_dice: 1.1712  decode.d5.loss_cls: 0.0561  decode.d5.loss_mask: 0.5442  decode.d5.loss_dice: 1.1431  decode.d6.loss_cls: 0.0608  decode.d6.loss_mask: 0.5314  decode.d6.loss_dice: 1.1381  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.5359  decode.d7.loss_dice: 1.1495  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.5375  decode.d8.loss_dice: 1.1602
11/15 11:24:44 - mmengine - INFO - Iter(train) [26400/90000]  base_lr: 7.3164e-05 lr: 7.3164e-06  eta: 10:40:51  time: 0.6043  data_time: 0.0104  memory: 10641  grad_norm: 338.9824  loss: 17.8580  decode.loss_cls: 0.0525  decode.loss_mask: 0.5206  decode.loss_dice: 1.2298  decode.d0.loss_cls: 0.0806  decode.d0.loss_mask: 0.5319  decode.d0.loss_dice: 1.2544  decode.d1.loss_cls: 0.0520  decode.d1.loss_mask: 0.5308  decode.d1.loss_dice: 1.2189  decode.d2.loss_cls: 0.0588  decode.d2.loss_mask: 0.5192  decode.d2.loss_dice: 1.2239  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.5115  decode.d3.loss_dice: 1.2126  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 0.5234  decode.d4.loss_dice: 1.1887  decode.d5.loss_cls: 0.0600  decode.d5.loss_mask: 0.5065  decode.d5.loss_dice: 1.1772  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.5146  decode.d6.loss_dice: 1.1928  decode.d7.loss_cls: 0.0525  decode.d7.loss_mask: 0.5119  decode.d7.loss_dice: 1.1984  decode.d8.loss_cls: 0.0637  decode.d8.loss_mask: 0.5161  decode.d8.loss_dice: 1.1918
11/15 11:25:14 - mmengine - INFO - Iter(train) [26450/90000]  base_lr: 7.3112e-05 lr: 7.3112e-06  eta: 10:40:20  time: 0.6034  data_time: 0.0101  memory: 10656  grad_norm: 490.3714  loss: 19.7768  decode.loss_cls: 0.0836  decode.loss_mask: 0.5741  decode.loss_dice: 1.2812  decode.d0.loss_cls: 0.0964  decode.d0.loss_mask: 0.5982  decode.d0.loss_dice: 1.3777  decode.d1.loss_cls: 0.1067  decode.d1.loss_mask: 0.5968  decode.d1.loss_dice: 1.3055  decode.d2.loss_cls: 0.0889  decode.d2.loss_mask: 0.6071  decode.d2.loss_dice: 1.2986  decode.d3.loss_cls: 0.0978  decode.d3.loss_mask: 0.5900  decode.d3.loss_dice: 1.2730  decode.d4.loss_cls: 0.0790  decode.d4.loss_mask: 0.5954  decode.d4.loss_dice: 1.3006  decode.d5.loss_cls: 0.0769  decode.d5.loss_mask: 0.5790  decode.d5.loss_dice: 1.2744  decode.d6.loss_cls: 0.0724  decode.d6.loss_mask: 0.5972  decode.d6.loss_dice: 1.2909  decode.d7.loss_cls: 0.0746  decode.d7.loss_mask: 0.5920  decode.d7.loss_dice: 1.3053  decode.d8.loss_cls: 0.0628  decode.d8.loss_mask: 0.5929  decode.d8.loss_dice: 1.3079
11/15 11:25:44 - mmengine - INFO - Iter(train) [26500/90000]  base_lr: 7.3060e-05 lr: 7.3060e-06  eta: 10:39:50  time: 0.6029  data_time: 0.0103  memory: 10675  grad_norm: 185.8226  loss: 16.8657  decode.loss_cls: 0.0989  decode.loss_mask: 0.3963  decode.loss_dice: 1.1860  decode.d0.loss_cls: 0.0907  decode.d0.loss_mask: 0.4206  decode.d0.loss_dice: 1.2808  decode.d1.loss_cls: 0.0857  decode.d1.loss_mask: 0.3893  decode.d1.loss_dice: 1.1693  decode.d2.loss_cls: 0.1081  decode.d2.loss_mask: 0.3988  decode.d2.loss_dice: 1.1144  decode.d3.loss_cls: 0.1147  decode.d3.loss_mask: 0.3965  decode.d3.loss_dice: 1.1459  decode.d4.loss_cls: 0.1082  decode.d4.loss_mask: 0.3999  decode.d4.loss_dice: 1.1680  decode.d5.loss_cls: 0.1036  decode.d5.loss_mask: 0.3945  decode.d5.loss_dice: 1.1976  decode.d6.loss_cls: 0.1012  decode.d6.loss_mask: 0.4015  decode.d6.loss_dice: 1.2155  decode.d7.loss_cls: 0.1039  decode.d7.loss_mask: 0.4053  decode.d7.loss_dice: 1.1488  decode.d8.loss_cls: 0.1056  decode.d8.loss_mask: 0.4024  decode.d8.loss_dice: 1.2136
11/15 11:26:14 - mmengine - INFO - Iter(train) [26550/90000]  base_lr: 7.3009e-05 lr: 7.3009e-06  eta: 10:39:20  time: 0.6020  data_time: 0.0099  memory: 10641  grad_norm: 242.6110  loss: 18.8015  decode.loss_cls: 0.1077  decode.loss_mask: 0.4603  decode.loss_dice: 1.3162  decode.d0.loss_cls: 0.0759  decode.d0.loss_mask: 0.4918  decode.d0.loss_dice: 1.3585  decode.d1.loss_cls: 0.0895  decode.d1.loss_mask: 0.4705  decode.d1.loss_dice: 1.3433  decode.d2.loss_cls: 0.0806  decode.d2.loss_mask: 0.4735  decode.d2.loss_dice: 1.3412  decode.d3.loss_cls: 0.1026  decode.d3.loss_mask: 0.4659  decode.d3.loss_dice: 1.2731  decode.d4.loss_cls: 0.1018  decode.d4.loss_mask: 0.4683  decode.d4.loss_dice: 1.2804  decode.d5.loss_cls: 0.1067  decode.d5.loss_mask: 0.4676  decode.d5.loss_dice: 1.2895  decode.d6.loss_cls: 0.1025  decode.d6.loss_mask: 0.4695  decode.d6.loss_dice: 1.3017  decode.d7.loss_cls: 0.1011  decode.d7.loss_mask: 0.4541  decode.d7.loss_dice: 1.3113  decode.d8.loss_cls: 0.0958  decode.d8.loss_mask: 0.4596  decode.d8.loss_dice: 1.3407
11/15 11:26:44 - mmengine - INFO - Iter(train) [26600/90000]  base_lr: 7.2957e-05 lr: 7.2957e-06  eta: 10:38:49  time: 0.6063  data_time: 0.0101  memory: 10656  grad_norm: 526.4737  loss: 18.1465  decode.loss_cls: 0.0591  decode.loss_mask: 0.5279  decode.loss_dice: 1.2046  decode.d0.loss_cls: 0.0833  decode.d0.loss_mask: 0.5515  decode.d0.loss_dice: 1.2693  decode.d1.loss_cls: 0.0799  decode.d1.loss_mask: 0.5255  decode.d1.loss_dice: 1.2329  decode.d2.loss_cls: 0.0726  decode.d2.loss_mask: 0.5207  decode.d2.loss_dice: 1.2118  decode.d3.loss_cls: 0.0701  decode.d3.loss_mask: 0.5251  decode.d3.loss_dice: 1.2018  decode.d4.loss_cls: 0.0624  decode.d4.loss_mask: 0.5301  decode.d4.loss_dice: 1.2162  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.5291  decode.d5.loss_dice: 1.2053  decode.d6.loss_cls: 0.0759  decode.d6.loss_mask: 0.5319  decode.d6.loss_dice: 1.1913  decode.d7.loss_cls: 0.0687  decode.d7.loss_mask: 0.5340  decode.d7.loss_dice: 1.2022  decode.d8.loss_cls: 0.0625  decode.d8.loss_mask: 0.5295  decode.d8.loss_dice: 1.2083
11/15 11:27:15 - mmengine - INFO - Iter(train) [26650/90000]  base_lr: 7.2905e-05 lr: 7.2905e-06  eta: 10:38:19  time: 0.6042  data_time: 0.0103  memory: 10692  grad_norm: 345.8653  loss: 16.9422  decode.loss_cls: 0.0681  decode.loss_mask: 0.4762  decode.loss_dice: 1.1111  decode.d0.loss_cls: 0.0746  decode.d0.loss_mask: 0.5596  decode.d0.loss_dice: 1.1677  decode.d1.loss_cls: 0.0666  decode.d1.loss_mask: 0.5365  decode.d1.loss_dice: 1.1801  decode.d2.loss_cls: 0.0600  decode.d2.loss_mask: 0.5366  decode.d2.loss_dice: 1.1182  decode.d3.loss_cls: 0.0693  decode.d3.loss_mask: 0.4887  decode.d3.loss_dice: 1.1077  decode.d4.loss_cls: 0.0666  decode.d4.loss_mask: 0.4895  decode.d4.loss_dice: 1.1060  decode.d5.loss_cls: 0.0622  decode.d5.loss_mask: 0.4925  decode.d5.loss_dice: 1.1213  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.4947  decode.d6.loss_dice: 1.1255  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 0.4836  decode.d7.loss_dice: 1.0931  decode.d8.loss_cls: 0.0630  decode.d8.loss_mask: 0.4883  decode.d8.loss_dice: 1.1143
11/15 11:27:45 - mmengine - INFO - Iter(train) [26700/90000]  base_lr: 7.2853e-05 lr: 7.2853e-06  eta: 10:37:49  time: 0.6025  data_time: 0.0101  memory: 10675  grad_norm: 430.4509  loss: 18.7111  decode.loss_cls: 0.0970  decode.loss_mask: 0.5050  decode.loss_dice: 1.2381  decode.d0.loss_cls: 0.0857  decode.d0.loss_mask: 0.5527  decode.d0.loss_dice: 1.3843  decode.d1.loss_cls: 0.0951  decode.d1.loss_mask: 0.5403  decode.d1.loss_dice: 1.2902  decode.d2.loss_cls: 0.0882  decode.d2.loss_mask: 0.5212  decode.d2.loss_dice: 1.2326  decode.d3.loss_cls: 0.0875  decode.d3.loss_mask: 0.5170  decode.d3.loss_dice: 1.2162  decode.d4.loss_cls: 0.0982  decode.d4.loss_mask: 0.5103  decode.d4.loss_dice: 1.2473  decode.d5.loss_cls: 0.0956  decode.d5.loss_mask: 0.4986  decode.d5.loss_dice: 1.2282  decode.d6.loss_cls: 0.1008  decode.d6.loss_mask: 0.5179  decode.d6.loss_dice: 1.2210  decode.d7.loss_cls: 0.1027  decode.d7.loss_mask: 0.5067  decode.d7.loss_dice: 1.2563  decode.d8.loss_cls: 0.1050  decode.d8.loss_mask: 0.5120  decode.d8.loss_dice: 1.2595
11/15 11:28:15 - mmengine - INFO - Iter(train) [26750/90000]  base_lr: 7.2802e-05 lr: 7.2802e-06  eta: 10:37:19  time: 0.6044  data_time: 0.0102  memory: 10656  grad_norm: 671.4799  loss: 17.3639  decode.loss_cls: 0.0615  decode.loss_mask: 0.5295  decode.loss_dice: 1.1174  decode.d0.loss_cls: 0.0948  decode.d0.loss_mask: 0.5235  decode.d0.loss_dice: 1.2307  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.5368  decode.d1.loss_dice: 1.1449  decode.d2.loss_cls: 0.0685  decode.d2.loss_mask: 0.5307  decode.d2.loss_dice: 1.1029  decode.d3.loss_cls: 0.0754  decode.d3.loss_mask: 0.5355  decode.d3.loss_dice: 1.1115  decode.d4.loss_cls: 0.0744  decode.d4.loss_mask: 0.5421  decode.d4.loss_dice: 1.1366  decode.d5.loss_cls: 0.0783  decode.d5.loss_mask: 0.5298  decode.d5.loss_dice: 1.1094  decode.d6.loss_cls: 0.0710  decode.d6.loss_mask: 0.5403  decode.d6.loss_dice: 1.1242  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.5212  decode.d7.loss_dice: 1.1284  decode.d8.loss_cls: 0.0632  decode.d8.loss_mask: 0.5327  decode.d8.loss_dice: 1.1016
11/15 11:28:46 - mmengine - INFO - Iter(train) [26800/90000]  base_lr: 7.2750e-05 lr: 7.2750e-06  eta: 10:36:50  time: 0.6027  data_time: 0.0099  memory: 10728  grad_norm: 373.8252  loss: 17.9760  decode.loss_cls: 0.0451  decode.loss_mask: 0.5311  decode.loss_dice: 1.1860  decode.d0.loss_cls: 0.0706  decode.d0.loss_mask: 0.5554  decode.d0.loss_dice: 1.2515  decode.d1.loss_cls: 0.0529  decode.d1.loss_mask: 0.5376  decode.d1.loss_dice: 1.2214  decode.d2.loss_cls: 0.0605  decode.d2.loss_mask: 0.5397  decode.d2.loss_dice: 1.1755  decode.d3.loss_cls: 0.0544  decode.d3.loss_mask: 0.5334  decode.d3.loss_dice: 1.1979  decode.d4.loss_cls: 0.0468  decode.d4.loss_mask: 0.5352  decode.d4.loss_dice: 1.2024  decode.d5.loss_cls: 0.0489  decode.d5.loss_mask: 0.5355  decode.d5.loss_dice: 1.2010  decode.d6.loss_cls: 0.0505  decode.d6.loss_mask: 0.5284  decode.d6.loss_dice: 1.2164  decode.d7.loss_cls: 0.0517  decode.d7.loss_mask: 0.5362  decode.d7.loss_dice: 1.2132  decode.d8.loss_cls: 0.0452  decode.d8.loss_mask: 0.5365  decode.d8.loss_dice: 1.2150
11/15 11:29:16 - mmengine - INFO - Iter(train) [26850/90000]  base_lr: 7.2698e-05 lr: 7.2698e-06  eta: 10:36:19  time: 0.6018  data_time: 0.0100  memory: 10641  grad_norm: 326.2519  loss: 17.2656  decode.loss_cls: 0.0882  decode.loss_mask: 0.4681  decode.loss_dice: 1.1641  decode.d0.loss_cls: 0.0950  decode.d0.loss_mask: 0.4657  decode.d0.loss_dice: 1.2248  decode.d1.loss_cls: 0.0983  decode.d1.loss_mask: 0.4533  decode.d1.loss_dice: 1.1617  decode.d2.loss_cls: 0.0841  decode.d2.loss_mask: 0.4673  decode.d2.loss_dice: 1.1715  decode.d3.loss_cls: 0.0769  decode.d3.loss_mask: 0.4499  decode.d3.loss_dice: 1.1776  decode.d4.loss_cls: 0.0858  decode.d4.loss_mask: 0.4574  decode.d4.loss_dice: 1.1738  decode.d5.loss_cls: 0.0743  decode.d5.loss_mask: 0.4642  decode.d5.loss_dice: 1.1853  decode.d6.loss_cls: 0.0728  decode.d6.loss_mask: 0.4612  decode.d6.loss_dice: 1.1903  decode.d7.loss_cls: 0.0921  decode.d7.loss_mask: 0.4677  decode.d7.loss_dice: 1.1603  decode.d8.loss_cls: 0.0857  decode.d8.loss_mask: 0.4597  decode.d8.loss_dice: 1.1885
11/15 11:29:46 - mmengine - INFO - Iter(train) [26900/90000]  base_lr: 7.2646e-05 lr: 7.2646e-06  eta: 10:35:49  time: 0.6036  data_time: 0.0102  memory: 10728  grad_norm: 252.5656  loss: 17.7179  decode.loss_cls: 0.0565  decode.loss_mask: 0.4962  decode.loss_dice: 1.1940  decode.d0.loss_cls: 0.0677  decode.d0.loss_mask: 0.5036  decode.d0.loss_dice: 1.2849  decode.d1.loss_cls: 0.0601  decode.d1.loss_mask: 0.4977  decode.d1.loss_dice: 1.2135  decode.d2.loss_cls: 0.0498  decode.d2.loss_mask: 0.4958  decode.d2.loss_dice: 1.2235  decode.d3.loss_cls: 0.0575  decode.d3.loss_mask: 0.4896  decode.d3.loss_dice: 1.2279  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.4947  decode.d4.loss_dice: 1.2127  decode.d5.loss_cls: 0.0510  decode.d5.loss_mask: 0.4913  decode.d5.loss_dice: 1.2250  decode.d6.loss_cls: 0.0486  decode.d6.loss_mask: 0.4952  decode.d6.loss_dice: 1.2251  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.4946  decode.d7.loss_dice: 1.2211  decode.d8.loss_cls: 0.0491  decode.d8.loss_mask: 0.4922  decode.d8.loss_dice: 1.1933
11/15 11:30:20 - mmengine - INFO - Iter(train) [26950/90000]  base_lr: 7.2594e-05 lr: 7.2594e-06  eta: 10:35:26  time: 0.9116  data_time: 0.0114  memory: 10713  grad_norm: 256.5205  loss: 17.7246  decode.loss_cls: 0.1008  decode.loss_mask: 0.4799  decode.loss_dice: 1.1551  decode.d0.loss_cls: 0.0761  decode.d0.loss_mask: 0.5288  decode.d0.loss_dice: 1.2705  decode.d1.loss_cls: 0.1191  decode.d1.loss_mask: 0.5007  decode.d1.loss_dice: 1.1839  decode.d2.loss_cls: 0.1063  decode.d2.loss_mask: 0.4890  decode.d2.loss_dice: 1.1842  decode.d3.loss_cls: 0.0952  decode.d3.loss_mask: 0.5056  decode.d3.loss_dice: 1.1807  decode.d4.loss_cls: 0.0950  decode.d4.loss_mask: 0.4901  decode.d4.loss_dice: 1.1737  decode.d5.loss_cls: 0.0906  decode.d5.loss_mask: 0.5179  decode.d5.loss_dice: 1.1687  decode.d6.loss_cls: 0.1008  decode.d6.loss_mask: 0.4880  decode.d6.loss_dice: 1.1464  decode.d7.loss_cls: 0.0917  decode.d7.loss_mask: 0.4820  decode.d7.loss_dice: 1.1602  decode.d8.loss_cls: 0.0971  decode.d8.loss_mask: 0.4806  decode.d8.loss_dice: 1.1658
11/15 11:30:50 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 11:30:50 - mmengine - INFO - Iter(train) [27000/90000]  base_lr: 7.2543e-05 lr: 7.2543e-06  eta: 10:34:56  time: 0.6026  data_time: 0.0102  memory: 10728  grad_norm: 540.6554  loss: 16.8965  decode.loss_cls: 0.0572  decode.loss_mask: 0.5325  decode.loss_dice: 1.0764  decode.d0.loss_cls: 0.0805  decode.d0.loss_mask: 0.5557  decode.d0.loss_dice: 1.1448  decode.d1.loss_cls: 0.0649  decode.d1.loss_mask: 0.5305  decode.d1.loss_dice: 1.1033  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.5286  decode.d2.loss_dice: 1.0833  decode.d3.loss_cls: 0.0659  decode.d3.loss_mask: 0.5228  decode.d3.loss_dice: 1.0548  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.5324  decode.d4.loss_dice: 1.0967  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.5388  decode.d5.loss_dice: 1.0780  decode.d6.loss_cls: 0.0615  decode.d6.loss_mask: 0.5383  decode.d6.loss_dice: 1.0755  decode.d7.loss_cls: 0.0691  decode.d7.loss_mask: 0.5269  decode.d7.loss_dice: 1.0925  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.5315  decode.d8.loss_dice: 1.1051
11/15 11:31:20 - mmengine - INFO - Iter(train) [27050/90000]  base_lr: 7.2491e-05 lr: 7.2491e-06  eta: 10:34:25  time: 0.6041  data_time: 0.0104  memory: 10728  grad_norm: 450.0289  loss: 17.8374  decode.loss_cls: 0.0555  decode.loss_mask: 0.5453  decode.loss_dice: 1.1329  decode.d0.loss_cls: 0.0967  decode.d0.loss_mask: 0.5554  decode.d0.loss_dice: 1.1907  decode.d1.loss_cls: 0.0577  decode.d1.loss_mask: 0.5450  decode.d1.loss_dice: 1.2235  decode.d2.loss_cls: 0.0622  decode.d2.loss_mask: 0.5363  decode.d2.loss_dice: 1.1683  decode.d3.loss_cls: 0.0521  decode.d3.loss_mask: 0.5399  decode.d3.loss_dice: 1.1801  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.5398  decode.d4.loss_dice: 1.1649  decode.d5.loss_cls: 0.0506  decode.d5.loss_mask: 0.5435  decode.d5.loss_dice: 1.1864  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.5424  decode.d6.loss_dice: 1.1591  decode.d7.loss_cls: 0.0489  decode.d7.loss_mask: 0.5431  decode.d7.loss_dice: 1.2083  decode.d8.loss_cls: 0.0535  decode.d8.loss_mask: 0.5379  decode.d8.loss_dice: 1.2088
11/15 11:31:51 - mmengine - INFO - Iter(train) [27100/90000]  base_lr: 7.2439e-05 lr: 7.2439e-06  eta: 10:33:56  time: 0.6016  data_time: 0.0103  memory: 10728  grad_norm: 282.0672  loss: 19.8620  decode.loss_cls: 0.1183  decode.loss_mask: 0.5933  decode.loss_dice: 1.2739  decode.d0.loss_cls: 0.1049  decode.d0.loss_mask: 0.6420  decode.d0.loss_dice: 1.3336  decode.d1.loss_cls: 0.1041  decode.d1.loss_mask: 0.6047  decode.d1.loss_dice: 1.2707  decode.d2.loss_cls: 0.1058  decode.d2.loss_mask: 0.5979  decode.d2.loss_dice: 1.2409  decode.d3.loss_cls: 0.1224  decode.d3.loss_mask: 0.5896  decode.d3.loss_dice: 1.2166  decode.d4.loss_cls: 0.1064  decode.d4.loss_mask: 0.6327  decode.d4.loss_dice: 1.2705  decode.d5.loss_cls: 0.1078  decode.d5.loss_mask: 0.6025  decode.d5.loss_dice: 1.2664  decode.d6.loss_cls: 0.1012  decode.d6.loss_mask: 0.6039  decode.d6.loss_dice: 1.2890  decode.d7.loss_cls: 0.1107  decode.d7.loss_mask: 0.5937  decode.d7.loss_dice: 1.2819  decode.d8.loss_cls: 0.1059  decode.d8.loss_mask: 0.6000  decode.d8.loss_dice: 1.2708
11/15 11:32:21 - mmengine - INFO - Iter(train) [27150/90000]  base_lr: 7.2387e-05 lr: 7.2387e-06  eta: 10:33:26  time: 0.6055  data_time: 0.0103  memory: 10713  grad_norm: 1007.9644  loss: 20.0459  decode.loss_cls: 0.0790  decode.loss_mask: 0.6430  decode.loss_dice: 1.2609  decode.d0.loss_cls: 0.1040  decode.d0.loss_mask: 0.5918  decode.d0.loss_dice: 1.3351  decode.d1.loss_cls: 0.0736  decode.d1.loss_mask: 0.6194  decode.d1.loss_dice: 1.2834  decode.d2.loss_cls: 0.0991  decode.d2.loss_mask: 0.6329  decode.d2.loss_dice: 1.2329  decode.d3.loss_cls: 0.0829  decode.d3.loss_mask: 0.6455  decode.d3.loss_dice: 1.2428  decode.d4.loss_cls: 0.0795  decode.d4.loss_mask: 0.6889  decode.d4.loss_dice: 1.2635  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.6878  decode.d5.loss_dice: 1.2872  decode.d6.loss_cls: 0.0762  decode.d6.loss_mask: 0.6628  decode.d6.loss_dice: 1.2748  decode.d7.loss_cls: 0.0715  decode.d7.loss_mask: 0.6748  decode.d7.loss_dice: 1.2937  decode.d8.loss_cls: 0.0923  decode.d8.loss_mask: 0.6409  decode.d8.loss_dice: 1.2467
11/15 11:32:52 - mmengine - INFO - Iter(train) [27200/90000]  base_lr: 7.2335e-05 lr: 7.2335e-06  eta: 10:32:57  time: 0.6413  data_time: 0.0223  memory: 10692  grad_norm: 433.4515  loss: 20.1151  decode.loss_cls: 0.0614  decode.loss_mask: 0.5993  decode.loss_dice: 1.3312  decode.d0.loss_cls: 0.0704  decode.d0.loss_mask: 0.6279  decode.d0.loss_dice: 1.3711  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.6064  decode.d1.loss_dice: 1.3603  decode.d2.loss_cls: 0.0548  decode.d2.loss_mask: 0.6034  decode.d2.loss_dice: 1.3550  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.5932  decode.d3.loss_dice: 1.3214  decode.d4.loss_cls: 0.0645  decode.d4.loss_mask: 0.6088  decode.d4.loss_dice: 1.3242  decode.d5.loss_cls: 0.0690  decode.d5.loss_mask: 0.6137  decode.d5.loss_dice: 1.3222  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.6196  decode.d6.loss_dice: 1.3232  decode.d7.loss_cls: 0.0582  decode.d7.loss_mask: 0.6132  decode.d7.loss_dice: 1.3355  decode.d8.loss_cls: 0.0579  decode.d8.loss_mask: 0.6089  decode.d8.loss_dice: 1.3517
11/15 11:33:22 - mmengine - INFO - Iter(train) [27250/90000]  base_lr: 7.2283e-05 lr: 7.2283e-06  eta: 10:32:27  time: 0.6066  data_time: 0.0104  memory: 10675  grad_norm: 406.3337  loss: 18.1358  decode.loss_cls: 0.0581  decode.loss_mask: 0.6321  decode.loss_dice: 1.1546  decode.d0.loss_cls: 0.0850  decode.d0.loss_mask: 0.6376  decode.d0.loss_dice: 1.1486  decode.d1.loss_cls: 0.0704  decode.d1.loss_mask: 0.6095  decode.d1.loss_dice: 1.1451  decode.d2.loss_cls: 0.0604  decode.d2.loss_mask: 0.6223  decode.d2.loss_dice: 1.1114  decode.d3.loss_cls: 0.0565  decode.d3.loss_mask: 0.6223  decode.d3.loss_dice: 1.1206  decode.d4.loss_cls: 0.0694  decode.d4.loss_mask: 0.6180  decode.d4.loss_dice: 1.1090  decode.d5.loss_cls: 0.0693  decode.d5.loss_mask: 0.6202  decode.d5.loss_dice: 1.0867  decode.d6.loss_cls: 0.0653  decode.d6.loss_mask: 0.6341  decode.d6.loss_dice: 1.1077  decode.d7.loss_cls: 0.0613  decode.d7.loss_mask: 0.6316  decode.d7.loss_dice: 1.1247  decode.d8.loss_cls: 0.0599  decode.d8.loss_mask: 0.6343  decode.d8.loss_dice: 1.1098
11/15 11:33:52 - mmengine - INFO - Iter(train) [27300/90000]  base_lr: 7.2232e-05 lr: 7.2232e-06  eta: 10:31:57  time: 0.6060  data_time: 0.0103  memory: 10742  grad_norm: 330.6514  loss: 16.0977  decode.loss_cls: 0.0438  decode.loss_mask: 0.4579  decode.loss_dice: 1.0739  decode.d0.loss_cls: 0.0756  decode.d0.loss_mask: 0.4931  decode.d0.loss_dice: 1.1449  decode.d1.loss_cls: 0.0549  decode.d1.loss_mask: 0.4612  decode.d1.loss_dice: 1.0614  decode.d2.loss_cls: 0.0510  decode.d2.loss_mask: 0.4702  decode.d2.loss_dice: 1.0801  decode.d3.loss_cls: 0.0509  decode.d3.loss_mask: 0.4665  decode.d3.loss_dice: 1.0885  decode.d4.loss_cls: 0.0507  decode.d4.loss_mask: 0.4673  decode.d4.loss_dice: 1.0914  decode.d5.loss_cls: 0.0501  decode.d5.loss_mask: 0.4715  decode.d5.loss_dice: 1.0972  decode.d6.loss_cls: 0.0579  decode.d6.loss_mask: 0.4712  decode.d6.loss_dice: 1.0641  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 0.4675  decode.d7.loss_dice: 1.0826  decode.d8.loss_cls: 0.0531  decode.d8.loss_mask: 0.4618  decode.d8.loss_dice: 1.0729
11/15 11:34:23 - mmengine - INFO - Iter(train) [27350/90000]  base_lr: 7.2180e-05 lr: 7.2180e-06  eta: 10:31:27  time: 0.6086  data_time: 0.0106  memory: 10675  grad_norm: 228.6787  loss: 18.3872  decode.loss_cls: 0.0754  decode.loss_mask: 0.5493  decode.loss_dice: 1.1929  decode.d0.loss_cls: 0.0781  decode.d0.loss_mask: 0.5572  decode.d0.loss_dice: 1.2974  decode.d1.loss_cls: 0.0702  decode.d1.loss_mask: 0.5450  decode.d1.loss_dice: 1.2469  decode.d2.loss_cls: 0.0694  decode.d2.loss_mask: 0.5371  decode.d2.loss_dice: 1.1978  decode.d3.loss_cls: 0.0713  decode.d3.loss_mask: 0.5418  decode.d3.loss_dice: 1.2043  decode.d4.loss_cls: 0.0609  decode.d4.loss_mask: 0.5503  decode.d4.loss_dice: 1.2175  decode.d5.loss_cls: 0.0645  decode.d5.loss_mask: 0.5454  decode.d5.loss_dice: 1.2243  decode.d6.loss_cls: 0.0599  decode.d6.loss_mask: 0.5487  decode.d6.loss_dice: 1.2295  decode.d7.loss_cls: 0.0557  decode.d7.loss_mask: 0.5494  decode.d7.loss_dice: 1.2365  decode.d8.loss_cls: 0.0507  decode.d8.loss_mask: 0.5450  decode.d8.loss_dice: 1.2147
11/15 11:34:53 - mmengine - INFO - Iter(train) [27400/90000]  base_lr: 7.2128e-05 lr: 7.2128e-06  eta: 10:30:57  time: 0.6068  data_time: 0.0102  memory: 10692  grad_norm: 474.0813  loss: 18.9029  decode.loss_cls: 0.0596  decode.loss_mask: 0.6403  decode.loss_dice: 1.1731  decode.d0.loss_cls: 0.0560  decode.d0.loss_mask: 0.6496  decode.d0.loss_dice: 1.2550  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.6484  decode.d1.loss_dice: 1.2364  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.6652  decode.d2.loss_dice: 1.1991  decode.d3.loss_cls: 0.0578  decode.d3.loss_mask: 0.6243  decode.d3.loss_dice: 1.1684  decode.d4.loss_cls: 0.0605  decode.d4.loss_mask: 0.6411  decode.d4.loss_dice: 1.1685  decode.d5.loss_cls: 0.0496  decode.d5.loss_mask: 0.6543  decode.d5.loss_dice: 1.1701  decode.d6.loss_cls: 0.0557  decode.d6.loss_mask: 0.6538  decode.d6.loss_dice: 1.1861  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.6411  decode.d7.loss_dice: 1.1484  decode.d8.loss_cls: 0.0638  decode.d8.loss_mask: 0.6356  decode.d8.loss_dice: 1.1475
11/15 11:35:23 - mmengine - INFO - Iter(train) [27450/90000]  base_lr: 7.2076e-05 lr: 7.2076e-06  eta: 10:30:27  time: 0.6097  data_time: 0.0103  memory: 10713  grad_norm: 386.6684  loss: 17.0286  decode.loss_cls: 0.0728  decode.loss_mask: 0.5094  decode.loss_dice: 1.1037  decode.d0.loss_cls: 0.0817  decode.d0.loss_mask: 0.5331  decode.d0.loss_dice: 1.2044  decode.d1.loss_cls: 0.0737  decode.d1.loss_mask: 0.5281  decode.d1.loss_dice: 1.1234  decode.d2.loss_cls: 0.0796  decode.d2.loss_mask: 0.5170  decode.d2.loss_dice: 1.0932  decode.d3.loss_cls: 0.0574  decode.d3.loss_mask: 0.5158  decode.d3.loss_dice: 1.1090  decode.d4.loss_cls: 0.0600  decode.d4.loss_mask: 0.5067  decode.d4.loss_dice: 1.1425  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.5075  decode.d5.loss_dice: 1.1315  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.5026  decode.d6.loss_dice: 1.1094  decode.d7.loss_cls: 0.0763  decode.d7.loss_mask: 0.5151  decode.d7.loss_dice: 1.1027  decode.d8.loss_cls: 0.0741  decode.d8.loss_mask: 0.4994  decode.d8.loss_dice: 1.0858
11/15 11:35:54 - mmengine - INFO - Iter(train) [27500/90000]  base_lr: 7.2024e-05 lr: 7.2024e-06  eta: 10:29:57  time: 0.6067  data_time: 0.0102  memory: 10713  grad_norm: 541.4423  loss: 18.9541  decode.loss_cls: 0.0695  decode.loss_mask: 0.6418  decode.loss_dice: 1.1971  decode.d0.loss_cls: 0.0949  decode.d0.loss_mask: 0.6158  decode.d0.loss_dice: 1.3087  decode.d1.loss_cls: 0.0880  decode.d1.loss_mask: 0.6051  decode.d1.loss_dice: 1.1927  decode.d2.loss_cls: 0.0709  decode.d2.loss_mask: 0.6057  decode.d2.loss_dice: 1.2249  decode.d3.loss_cls: 0.0752  decode.d3.loss_mask: 0.5858  decode.d3.loss_dice: 1.1617  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.5943  decode.d4.loss_dice: 1.1815  decode.d5.loss_cls: 0.0682  decode.d5.loss_mask: 0.6283  decode.d5.loss_dice: 1.2191  decode.d6.loss_cls: 0.0637  decode.d6.loss_mask: 0.6274  decode.d6.loss_dice: 1.2134  decode.d7.loss_cls: 0.0738  decode.d7.loss_mask: 0.5830  decode.d7.loss_dice: 1.1863  decode.d8.loss_cls: 0.0825  decode.d8.loss_mask: 0.6259  decode.d8.loss_dice: 1.1909
11/15 11:36:24 - mmengine - INFO - Iter(train) [27550/90000]  base_lr: 7.1972e-05 lr: 7.1972e-06  eta: 10:29:27  time: 0.6062  data_time: 0.0102  memory: 10692  grad_norm: 383.3608  loss: 18.6606  decode.loss_cls: 0.0645  decode.loss_mask: 0.5614  decode.loss_dice: 1.2535  decode.d0.loss_cls: 0.0815  decode.d0.loss_mask: 0.5986  decode.d0.loss_dice: 1.3306  decode.d1.loss_cls: 0.0727  decode.d1.loss_mask: 0.5607  decode.d1.loss_dice: 1.2785  decode.d2.loss_cls: 0.0622  decode.d2.loss_mask: 0.5576  decode.d2.loss_dice: 1.2031  decode.d3.loss_cls: 0.0655  decode.d3.loss_mask: 0.5645  decode.d3.loss_dice: 1.2114  decode.d4.loss_cls: 0.0613  decode.d4.loss_mask: 0.5566  decode.d4.loss_dice: 1.2253  decode.d5.loss_cls: 0.0587  decode.d5.loss_mask: 0.5555  decode.d5.loss_dice: 1.2282  decode.d6.loss_cls: 0.0647  decode.d6.loss_mask: 0.5644  decode.d6.loss_dice: 1.2162  decode.d7.loss_cls: 0.0662  decode.d7.loss_mask: 0.5609  decode.d7.loss_dice: 1.1993  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 0.5602  decode.d8.loss_dice: 1.2170
11/15 11:36:54 - mmengine - INFO - Iter(train) [27600/90000]  base_lr: 7.1920e-05 lr: 7.1920e-06  eta: 10:28:56  time: 0.5998  data_time: 0.0099  memory: 10793  grad_norm: 495.3408  loss: 18.6060  decode.loss_cls: 0.0661  decode.loss_mask: 0.5368  decode.loss_dice: 1.2540  decode.d0.loss_cls: 0.0671  decode.d0.loss_mask: 0.5655  decode.d0.loss_dice: 1.3423  decode.d1.loss_cls: 0.0613  decode.d1.loss_mask: 0.5430  decode.d1.loss_dice: 1.2748  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 0.5447  decode.d2.loss_dice: 1.2799  decode.d3.loss_cls: 0.0527  decode.d3.loss_mask: 0.5382  decode.d3.loss_dice: 1.2639  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 0.5305  decode.d4.loss_dice: 1.2552  decode.d5.loss_cls: 0.0543  decode.d5.loss_mask: 0.5321  decode.d5.loss_dice: 1.2375  decode.d6.loss_cls: 0.0496  decode.d6.loss_mask: 0.5288  decode.d6.loss_dice: 1.2347  decode.d7.loss_cls: 0.0501  decode.d7.loss_mask: 0.5306  decode.d7.loss_dice: 1.2594  decode.d8.loss_cls: 0.0587  decode.d8.loss_mask: 0.5299  decode.d8.loss_dice: 1.2474
11/15 11:37:24 - mmengine - INFO - Iter(train) [27650/90000]  base_lr: 7.1869e-05 lr: 7.1869e-06  eta: 10:28:25  time: 0.5977  data_time: 0.0100  memory: 10675  grad_norm: 640.8671  loss: 19.3452  decode.loss_cls: 0.0710  decode.loss_mask: 0.5234  decode.loss_dice: 1.3639  decode.d0.loss_cls: 0.0834  decode.d0.loss_mask: 0.4842  decode.d0.loss_dice: 1.4200  decode.d1.loss_cls: 0.0914  decode.d1.loss_mask: 0.4842  decode.d1.loss_dice: 1.3523  decode.d2.loss_cls: 0.0755  decode.d2.loss_mask: 0.5257  decode.d2.loss_dice: 1.3447  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.4973  decode.d3.loss_dice: 1.3230  decode.d4.loss_cls: 0.0743  decode.d4.loss_mask: 0.4870  decode.d4.loss_dice: 1.3378  decode.d5.loss_cls: 0.0806  decode.d5.loss_mask: 0.4889  decode.d5.loss_dice: 1.3069  decode.d6.loss_cls: 0.0734  decode.d6.loss_mask: 0.5112  decode.d6.loss_dice: 1.3524  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.5182  decode.d7.loss_dice: 1.3643  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.5412  decode.d8.loss_dice: 1.3524
11/15 11:37:54 - mmengine - INFO - Iter(train) [27700/90000]  base_lr: 7.1817e-05 lr: 7.1817e-06  eta: 10:27:54  time: 0.5995  data_time: 0.0099  memory: 10728  grad_norm: 385.6623  loss: 16.1679  decode.loss_cls: 0.0679  decode.loss_mask: 0.4564  decode.loss_dice: 1.1014  decode.d0.loss_cls: 0.0808  decode.d0.loss_mask: 0.4474  decode.d0.loss_dice: 1.1502  decode.d1.loss_cls: 0.0718  decode.d1.loss_mask: 0.4491  decode.d1.loss_dice: 1.1113  decode.d2.loss_cls: 0.0542  decode.d2.loss_mask: 0.4544  decode.d2.loss_dice: 1.1162  decode.d3.loss_cls: 0.0684  decode.d3.loss_mask: 0.4523  decode.d3.loss_dice: 1.0710  decode.d4.loss_cls: 0.0728  decode.d4.loss_mask: 0.4503  decode.d4.loss_dice: 1.0680  decode.d5.loss_cls: 0.0643  decode.d5.loss_mask: 0.4507  decode.d5.loss_dice: 1.0796  decode.d6.loss_cls: 0.0750  decode.d6.loss_mask: 0.4434  decode.d6.loss_dice: 1.0815  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.4510  decode.d7.loss_dice: 1.0876  decode.d8.loss_cls: 0.0651  decode.d8.loss_mask: 0.4553  decode.d8.loss_dice: 1.1040
11/15 11:38:24 - mmengine - INFO - Iter(train) [27750/90000]  base_lr: 7.1765e-05 lr: 7.1765e-06  eta: 10:27:23  time: 0.5983  data_time: 0.0099  memory: 10713  grad_norm: 293.6601  loss: 17.6227  decode.loss_cls: 0.0619  decode.loss_mask: 0.5074  decode.loss_dice: 1.1853  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.5486  decode.d0.loss_dice: 1.2246  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.5180  decode.d1.loss_dice: 1.1872  decode.d2.loss_cls: 0.0775  decode.d2.loss_mask: 0.5128  decode.d2.loss_dice: 1.1805  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.5071  decode.d3.loss_dice: 1.1766  decode.d4.loss_cls: 0.0697  decode.d4.loss_mask: 0.5143  decode.d4.loss_dice: 1.1807  decode.d5.loss_cls: 0.0682  decode.d5.loss_mask: 0.5043  decode.d5.loss_dice: 1.1512  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.5075  decode.d6.loss_dice: 1.1502  decode.d7.loss_cls: 0.0753  decode.d7.loss_mask: 0.5046  decode.d7.loss_dice: 1.1520  decode.d8.loss_cls: 0.0691  decode.d8.loss_mask: 0.5152  decode.d8.loss_dice: 1.2024
11/15 11:38:54 - mmengine - INFO - Iter(train) [27800/90000]  base_lr: 7.1713e-05 lr: 7.1713e-06  eta: 10:26:52  time: 0.5993  data_time: 0.0100  memory: 10675  grad_norm: 275.9714  loss: 16.8251  decode.loss_cls: 0.0551  decode.loss_mask: 0.4986  decode.loss_dice: 1.1257  decode.d0.loss_cls: 0.0900  decode.d0.loss_mask: 0.5096  decode.d0.loss_dice: 1.1747  decode.d1.loss_cls: 0.0727  decode.d1.loss_mask: 0.4925  decode.d1.loss_dice: 1.1356  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.4927  decode.d2.loss_dice: 1.1344  decode.d3.loss_cls: 0.0554  decode.d3.loss_mask: 0.4825  decode.d3.loss_dice: 1.1182  decode.d4.loss_cls: 0.0584  decode.d4.loss_mask: 0.4873  decode.d4.loss_dice: 1.1041  decode.d5.loss_cls: 0.0673  decode.d5.loss_mask: 0.4851  decode.d5.loss_dice: 1.1027  decode.d6.loss_cls: 0.0647  decode.d6.loss_mask: 0.4817  decode.d6.loss_dice: 1.1137  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.4864  decode.d7.loss_dice: 1.1302  decode.d8.loss_cls: 0.0621  decode.d8.loss_mask: 0.4890  decode.d8.loss_dice: 1.1287
11/15 11:39:24 - mmengine - INFO - Iter(train) [27850/90000]  base_lr: 7.1661e-05 lr: 7.1661e-06  eta: 10:26:21  time: 0.6002  data_time: 0.0100  memory: 10675  grad_norm: 226.3263  loss: 19.5245  decode.loss_cls: 0.0828  decode.loss_mask: 0.5417  decode.loss_dice: 1.3253  decode.d0.loss_cls: 0.0793  decode.d0.loss_mask: 0.5848  decode.d0.loss_dice: 1.4352  decode.d1.loss_cls: 0.0899  decode.d1.loss_mask: 0.5459  decode.d1.loss_dice: 1.3606  decode.d2.loss_cls: 0.0815  decode.d2.loss_mask: 0.5333  decode.d2.loss_dice: 1.3305  decode.d3.loss_cls: 0.0713  decode.d3.loss_mask: 0.5265  decode.d3.loss_dice: 1.3273  decode.d4.loss_cls: 0.0686  decode.d4.loss_mask: 0.5297  decode.d4.loss_dice: 1.3245  decode.d5.loss_cls: 0.0763  decode.d5.loss_mask: 0.5282  decode.d5.loss_dice: 1.3381  decode.d6.loss_cls: 0.0634  decode.d6.loss_mask: 0.5288  decode.d6.loss_dice: 1.3111  decode.d7.loss_cls: 0.0739  decode.d7.loss_mask: 0.5223  decode.d7.loss_dice: 1.2975  decode.d8.loss_cls: 0.0815  decode.d8.loss_mask: 0.5315  decode.d8.loss_dice: 1.3333
11/15 11:39:54 - mmengine - INFO - Iter(train) [27900/90000]  base_lr: 7.1609e-05 lr: 7.1609e-06  eta: 10:25:51  time: 0.5991  data_time: 0.0098  memory: 10692  grad_norm: 414.3938  loss: 20.4957  decode.loss_cls: 0.1012  decode.loss_mask: 0.6127  decode.loss_dice: 1.2825  decode.d0.loss_cls: 0.0950  decode.d0.loss_mask: 0.6094  decode.d0.loss_dice: 1.4325  decode.d1.loss_cls: 0.0990  decode.d1.loss_mask: 0.5914  decode.d1.loss_dice: 1.3740  decode.d2.loss_cls: 0.0937  decode.d2.loss_mask: 0.6201  decode.d2.loss_dice: 1.3568  decode.d3.loss_cls: 0.1011  decode.d3.loss_mask: 0.6143  decode.d3.loss_dice: 1.2993  decode.d4.loss_cls: 0.0944  decode.d4.loss_mask: 0.6111  decode.d4.loss_dice: 1.3257  decode.d5.loss_cls: 0.0926  decode.d5.loss_mask: 0.6377  decode.d5.loss_dice: 1.3421  decode.d6.loss_cls: 0.0995  decode.d6.loss_mask: 0.6064  decode.d6.loss_dice: 1.3044  decode.d7.loss_cls: 0.1016  decode.d7.loss_mask: 0.5827  decode.d7.loss_dice: 1.3515  decode.d8.loss_cls: 0.0934  decode.d8.loss_mask: 0.6490  decode.d8.loss_dice: 1.3206
11/15 11:40:24 - mmengine - INFO - Iter(train) [27950/90000]  base_lr: 7.1557e-05 lr: 7.1557e-06  eta: 10:25:20  time: 0.5979  data_time: 0.0098  memory: 10692  grad_norm: 444.4071  loss: 20.2139  decode.loss_cls: 0.0697  decode.loss_mask: 0.7812  decode.loss_dice: 1.1910  decode.d0.loss_cls: 0.1052  decode.d0.loss_mask: 0.7528  decode.d0.loss_dice: 1.2562  decode.d1.loss_cls: 0.0822  decode.d1.loss_mask: 0.7117  decode.d1.loss_dice: 1.2233  decode.d2.loss_cls: 0.0914  decode.d2.loss_mask: 0.7553  decode.d2.loss_dice: 1.1808  decode.d3.loss_cls: 0.0680  decode.d3.loss_mask: 0.7486  decode.d3.loss_dice: 1.2032  decode.d4.loss_cls: 0.0673  decode.d4.loss_mask: 0.7402  decode.d4.loss_dice: 1.2029  decode.d5.loss_cls: 0.0776  decode.d5.loss_mask: 0.7477  decode.d5.loss_dice: 1.1823  decode.d6.loss_cls: 0.0827  decode.d6.loss_mask: 0.7358  decode.d6.loss_dice: 1.1420  decode.d7.loss_cls: 0.0757  decode.d7.loss_mask: 0.7525  decode.d7.loss_dice: 1.1690  decode.d8.loss_cls: 0.0677  decode.d8.loss_mask: 0.7589  decode.d8.loss_dice: 1.1910
11/15 11:40:54 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 11:40:54 - mmengine - INFO - Iter(train) [28000/90000]  base_lr: 7.1505e-05 lr: 7.1505e-06  eta: 10:24:49  time: 0.5980  data_time: 0.0100  memory: 10656  grad_norm: 299.8436  loss: 18.6400  decode.loss_cls: 0.0546  decode.loss_mask: 0.6705  decode.loss_dice: 1.1001  decode.d0.loss_cls: 0.0769  decode.d0.loss_mask: 0.7582  decode.d0.loss_dice: 1.1635  decode.d1.loss_cls: 0.0683  decode.d1.loss_mask: 0.6802  decode.d1.loss_dice: 1.1171  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 0.6767  decode.d2.loss_dice: 1.1206  decode.d3.loss_cls: 0.0662  decode.d3.loss_mask: 0.6751  decode.d3.loss_dice: 1.0968  decode.d4.loss_cls: 0.0659  decode.d4.loss_mask: 0.6841  decode.d4.loss_dice: 1.1169  decode.d5.loss_cls: 0.0707  decode.d5.loss_mask: 0.6803  decode.d5.loss_dice: 1.0883  decode.d6.loss_cls: 0.0633  decode.d6.loss_mask: 0.6814  decode.d6.loss_dice: 1.0909  decode.d7.loss_cls: 0.0581  decode.d7.loss_mask: 0.6883  decode.d7.loss_dice: 1.1094  decode.d8.loss_cls: 0.0559  decode.d8.loss_mask: 0.6820  decode.d8.loss_dice: 1.1171
11/15 11:41:24 - mmengine - INFO - Iter(train) [28050/90000]  base_lr: 7.1453e-05 lr: 7.1453e-06  eta: 10:24:20  time: 0.5973  data_time: 0.0098  memory: 10713  grad_norm: 940.0545  loss: 19.4357  decode.loss_cls: 0.0660  decode.loss_mask: 0.7176  decode.loss_dice: 1.1371  decode.d0.loss_cls: 0.1051  decode.d0.loss_mask: 0.7158  decode.d0.loss_dice: 1.1933  decode.d1.loss_cls: 0.0759  decode.d1.loss_mask: 0.7206  decode.d1.loss_dice: 1.1749  decode.d2.loss_cls: 0.0761  decode.d2.loss_mask: 0.6997  decode.d2.loss_dice: 1.1448  decode.d3.loss_cls: 0.0643  decode.d3.loss_mask: 0.7095  decode.d3.loss_dice: 1.1443  decode.d4.loss_cls: 0.0753  decode.d4.loss_mask: 0.7204  decode.d4.loss_dice: 1.1849  decode.d5.loss_cls: 0.0852  decode.d5.loss_mask: 0.7039  decode.d5.loss_dice: 1.1224  decode.d6.loss_cls: 0.0754  decode.d6.loss_mask: 0.7183  decode.d6.loss_dice: 1.1325  decode.d7.loss_cls: 0.0741  decode.d7.loss_mask: 0.7338  decode.d7.loss_dice: 1.1466  decode.d8.loss_cls: 0.0685  decode.d8.loss_mask: 0.7097  decode.d8.loss_dice: 1.1398
11/15 11:41:54 - mmengine - INFO - Iter(train) [28100/90000]  base_lr: 7.1402e-05 lr: 7.1402e-06  eta: 10:23:49  time: 0.6054  data_time: 0.0110  memory: 10692  grad_norm: 343.3445  loss: 19.6666  decode.loss_cls: 0.1289  decode.loss_mask: 0.5130  decode.loss_dice: 1.3203  decode.d0.loss_cls: 0.0954  decode.d0.loss_mask: 0.5050  decode.d0.loss_dice: 1.4395  decode.d1.loss_cls: 0.1050  decode.d1.loss_mask: 0.5159  decode.d1.loss_dice: 1.3467  decode.d2.loss_cls: 0.1124  decode.d2.loss_mask: 0.4889  decode.d2.loss_dice: 1.3563  decode.d3.loss_cls: 0.1286  decode.d3.loss_mask: 0.4843  decode.d3.loss_dice: 1.3268  decode.d4.loss_cls: 0.1218  decode.d4.loss_mask: 0.4989  decode.d4.loss_dice: 1.3272  decode.d5.loss_cls: 0.1109  decode.d5.loss_mask: 0.5037  decode.d5.loss_dice: 1.3569  decode.d6.loss_cls: 0.1134  decode.d6.loss_mask: 0.4995  decode.d6.loss_dice: 1.3216  decode.d7.loss_cls: 0.1074  decode.d7.loss_mask: 0.5043  decode.d7.loss_dice: 1.3566  decode.d8.loss_cls: 0.1026  decode.d8.loss_mask: 0.5182  decode.d8.loss_dice: 1.3564
11/15 11:42:24 - mmengine - INFO - Iter(train) [28150/90000]  base_lr: 7.1350e-05 lr: 7.1350e-06  eta: 10:23:18  time: 0.5978  data_time: 0.0100  memory: 10728  grad_norm: 581.6732  loss: 19.4987  decode.loss_cls: 0.1115  decode.loss_mask: 0.5687  decode.loss_dice: 1.2451  decode.d0.loss_cls: 0.0996  decode.d0.loss_mask: 0.6817  decode.d0.loss_dice: 1.3319  decode.d1.loss_cls: 0.1002  decode.d1.loss_mask: 0.6066  decode.d1.loss_dice: 1.2831  decode.d2.loss_cls: 0.1083  decode.d2.loss_mask: 0.5939  decode.d2.loss_dice: 1.2200  decode.d3.loss_cls: 0.1061  decode.d3.loss_mask: 0.5958  decode.d3.loss_dice: 1.1871  decode.d4.loss_cls: 0.0871  decode.d4.loss_mask: 0.6119  decode.d4.loss_dice: 1.2160  decode.d5.loss_cls: 0.0981  decode.d5.loss_mask: 0.6029  decode.d5.loss_dice: 1.2411  decode.d6.loss_cls: 0.0940  decode.d6.loss_mask: 0.6008  decode.d6.loss_dice: 1.2309  decode.d7.loss_cls: 0.0866  decode.d7.loss_mask: 0.6044  decode.d7.loss_dice: 1.2187  decode.d8.loss_cls: 0.0956  decode.d8.loss_mask: 0.5966  decode.d8.loss_dice: 1.2744
11/15 11:42:54 - mmengine - INFO - Iter(train) [28200/90000]  base_lr: 7.1298e-05 lr: 7.1298e-06  eta: 10:22:48  time: 0.6015  data_time: 0.0116  memory: 10713  grad_norm: 437.6211  loss: 18.7360  decode.loss_cls: 0.0727  decode.loss_mask: 0.5913  decode.loss_dice: 1.1795  decode.d0.loss_cls: 0.0825  decode.d0.loss_mask: 0.6216  decode.d0.loss_dice: 1.2391  decode.d1.loss_cls: 0.0554  decode.d1.loss_mask: 0.6111  decode.d1.loss_dice: 1.2295  decode.d2.loss_cls: 0.0562  decode.d2.loss_mask: 0.6169  decode.d2.loss_dice: 1.2063  decode.d3.loss_cls: 0.0651  decode.d3.loss_mask: 0.6058  decode.d3.loss_dice: 1.1932  decode.d4.loss_cls: 0.0562  decode.d4.loss_mask: 0.6061  decode.d4.loss_dice: 1.1998  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.6058  decode.d5.loss_dice: 1.2147  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.6109  decode.d6.loss_dice: 1.1815  decode.d7.loss_cls: 0.0505  decode.d7.loss_mask: 0.6159  decode.d7.loss_dice: 1.2076  decode.d8.loss_cls: 0.0651  decode.d8.loss_mask: 0.5938  decode.d8.loss_dice: 1.1926
11/15 11:43:24 - mmengine - INFO - Iter(train) [28250/90000]  base_lr: 7.1246e-05 lr: 7.1246e-06  eta: 10:22:17  time: 0.6014  data_time: 0.0115  memory: 10728  grad_norm: 309.0869  loss: 19.4748  decode.loss_cls: 0.0838  decode.loss_mask: 0.5025  decode.loss_dice: 1.3581  decode.d0.loss_cls: 0.0831  decode.d0.loss_mask: 0.4949  decode.d0.loss_dice: 1.4453  decode.d1.loss_cls: 0.0778  decode.d1.loss_mask: 0.4875  decode.d1.loss_dice: 1.3871  decode.d2.loss_cls: 0.0796  decode.d2.loss_mask: 0.4886  decode.d2.loss_dice: 1.3645  decode.d3.loss_cls: 0.0987  decode.d3.loss_mask: 0.4879  decode.d3.loss_dice: 1.3175  decode.d4.loss_cls: 0.0774  decode.d4.loss_mask: 0.4909  decode.d4.loss_dice: 1.3628  decode.d5.loss_cls: 0.0837  decode.d5.loss_mask: 0.4919  decode.d5.loss_dice: 1.3522  decode.d6.loss_cls: 0.0779  decode.d6.loss_mask: 0.5026  decode.d6.loss_dice: 1.3700  decode.d7.loss_cls: 0.1035  decode.d7.loss_mask: 0.4910  decode.d7.loss_dice: 1.3561  decode.d8.loss_cls: 0.0802  decode.d8.loss_mask: 0.4967  decode.d8.loss_dice: 1.3808
11/15 11:43:54 - mmengine - INFO - Iter(train) [28300/90000]  base_lr: 7.1194e-05 lr: 7.1194e-06  eta: 10:21:46  time: 0.5984  data_time: 0.0098  memory: 10675  grad_norm: 354.7052  loss: 18.7681  decode.loss_cls: 0.0991  decode.loss_mask: 0.5905  decode.loss_dice: 1.1603  decode.d0.loss_cls: 0.0963  decode.d0.loss_mask: 0.5907  decode.d0.loss_dice: 1.2534  decode.d1.loss_cls: 0.1061  decode.d1.loss_mask: 0.5709  decode.d1.loss_dice: 1.2348  decode.d2.loss_cls: 0.0996  decode.d2.loss_mask: 0.5792  decode.d2.loss_dice: 1.1918  decode.d3.loss_cls: 0.1070  decode.d3.loss_mask: 0.5653  decode.d3.loss_dice: 1.1696  decode.d4.loss_cls: 0.0983  decode.d4.loss_mask: 0.5906  decode.d4.loss_dice: 1.1815  decode.d5.loss_cls: 0.1037  decode.d5.loss_mask: 0.5896  decode.d5.loss_dice: 1.1844  decode.d6.loss_cls: 0.1051  decode.d6.loss_mask: 0.5686  decode.d6.loss_dice: 1.1783  decode.d7.loss_cls: 0.1040  decode.d7.loss_mask: 0.5764  decode.d7.loss_dice: 1.1984  decode.d8.loss_cls: 0.0951  decode.d8.loss_mask: 0.5817  decode.d8.loss_dice: 1.1980
11/15 11:44:24 - mmengine - INFO - Iter(train) [28350/90000]  base_lr: 7.1142e-05 lr: 7.1142e-06  eta: 10:21:15  time: 0.5983  data_time: 0.0097  memory: 10728  grad_norm: 274.1482  loss: 17.3440  decode.loss_cls: 0.0505  decode.loss_mask: 0.5434  decode.loss_dice: 1.1271  decode.d0.loss_cls: 0.0792  decode.d0.loss_mask: 0.5676  decode.d0.loss_dice: 1.2150  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.5454  decode.d1.loss_dice: 1.1287  decode.d2.loss_cls: 0.0652  decode.d2.loss_mask: 0.5404  decode.d2.loss_dice: 1.0938  decode.d3.loss_cls: 0.0543  decode.d3.loss_mask: 0.5394  decode.d3.loss_dice: 1.1197  decode.d4.loss_cls: 0.0599  decode.d4.loss_mask: 0.5388  decode.d4.loss_dice: 1.1330  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 0.5340  decode.d5.loss_dice: 1.1187  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.5416  decode.d6.loss_dice: 1.1045  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.5375  decode.d7.loss_dice: 1.1155  decode.d8.loss_cls: 0.0602  decode.d8.loss_mask: 0.5384  decode.d8.loss_dice: 1.1383
11/15 11:44:54 - mmengine - INFO - Iter(train) [28400/90000]  base_lr: 7.1090e-05 lr: 7.1090e-06  eta: 10:20:44  time: 0.5980  data_time: 0.0100  memory: 10692  grad_norm: 405.9222  loss: 19.6530  decode.loss_cls: 0.0742  decode.loss_mask: 0.5946  decode.loss_dice: 1.3083  decode.d0.loss_cls: 0.0796  decode.d0.loss_mask: 0.6568  decode.d0.loss_dice: 1.3237  decode.d1.loss_cls: 0.0707  decode.d1.loss_mask: 0.6107  decode.d1.loss_dice: 1.3079  decode.d2.loss_cls: 0.0841  decode.d2.loss_mask: 0.5981  decode.d2.loss_dice: 1.2780  decode.d3.loss_cls: 0.0908  decode.d3.loss_mask: 0.5771  decode.d3.loss_dice: 1.2845  decode.d4.loss_cls: 0.0817  decode.d4.loss_mask: 0.5988  decode.d4.loss_dice: 1.2757  decode.d5.loss_cls: 0.0801  decode.d5.loss_mask: 0.5845  decode.d5.loss_dice: 1.2653  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 0.5873  decode.d6.loss_dice: 1.2772  decode.d7.loss_cls: 0.0756  decode.d7.loss_mask: 0.5804  decode.d7.loss_dice: 1.2664  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.5916  decode.d8.loss_dice: 1.2797
11/15 11:45:24 - mmengine - INFO - Iter(train) [28450/90000]  base_lr: 7.1038e-05 lr: 7.1038e-06  eta: 10:20:13  time: 0.5981  data_time: 0.0100  memory: 10656  grad_norm: 686.7912  loss: 17.1593  decode.loss_cls: 0.0521  decode.loss_mask: 0.5547  decode.loss_dice: 1.0631  decode.d0.loss_cls: 0.0733  decode.d0.loss_mask: 0.6109  decode.d0.loss_dice: 1.1574  decode.d1.loss_cls: 0.0471  decode.d1.loss_mask: 0.5605  decode.d1.loss_dice: 1.1163  decode.d2.loss_cls: 0.0558  decode.d2.loss_mask: 0.5693  decode.d2.loss_dice: 1.1157  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.5583  decode.d3.loss_dice: 1.0869  decode.d4.loss_cls: 0.0454  decode.d4.loss_mask: 0.5639  decode.d4.loss_dice: 1.0942  decode.d5.loss_cls: 0.0471  decode.d5.loss_mask: 0.5559  decode.d5.loss_dice: 1.0762  decode.d6.loss_cls: 0.0434  decode.d6.loss_mask: 0.5659  decode.d6.loss_dice: 1.0938  decode.d7.loss_cls: 0.0437  decode.d7.loss_mask: 0.5607  decode.d7.loss_dice: 1.0906  decode.d8.loss_cls: 0.0488  decode.d8.loss_mask: 0.5641  decode.d8.loss_dice: 1.0875
11/15 11:45:54 - mmengine - INFO - Iter(train) [28500/90000]  base_lr: 7.0986e-05 lr: 7.0986e-06  eta: 10:19:42  time: 0.5981  data_time: 0.0096  memory: 10675  grad_norm: 477.1049  loss: 19.7058  decode.loss_cls: 0.1046  decode.loss_mask: 0.6706  decode.loss_dice: 1.2370  decode.d0.loss_cls: 0.1256  decode.d0.loss_mask: 0.6285  decode.d0.loss_dice: 1.3191  decode.d1.loss_cls: 0.1103  decode.d1.loss_mask: 0.6268  decode.d1.loss_dice: 1.2415  decode.d2.loss_cls: 0.1042  decode.d2.loss_mask: 0.6267  decode.d2.loss_dice: 1.2256  decode.d3.loss_cls: 0.1137  decode.d3.loss_mask: 0.6120  decode.d3.loss_dice: 1.1956  decode.d4.loss_cls: 0.0997  decode.d4.loss_mask: 0.6346  decode.d4.loss_dice: 1.2017  decode.d5.loss_cls: 0.1092  decode.d5.loss_mask: 0.6329  decode.d5.loss_dice: 1.2087  decode.d6.loss_cls: 0.1090  decode.d6.loss_mask: 0.6085  decode.d6.loss_dice: 1.1796  decode.d7.loss_cls: 0.1068  decode.d7.loss_mask: 0.6628  decode.d7.loss_dice: 1.2229  decode.d8.loss_cls: 0.1127  decode.d8.loss_mask: 0.6691  decode.d8.loss_dice: 1.2058
11/15 11:46:24 - mmengine - INFO - Iter(train) [28550/90000]  base_lr: 7.0934e-05 lr: 7.0934e-06  eta: 10:19:12  time: 0.5979  data_time: 0.0100  memory: 10692  grad_norm: 608.0702  loss: 17.3974  decode.loss_cls: 0.0828  decode.loss_mask: 0.4687  decode.loss_dice: 1.1655  decode.d0.loss_cls: 0.0851  decode.d0.loss_mask: 0.5040  decode.d0.loss_dice: 1.2600  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.4891  decode.d1.loss_dice: 1.2149  decode.d2.loss_cls: 0.0535  decode.d2.loss_mask: 0.4733  decode.d2.loss_dice: 1.1797  decode.d3.loss_cls: 0.0642  decode.d3.loss_mask: 0.4708  decode.d3.loss_dice: 1.1923  decode.d4.loss_cls: 0.0739  decode.d4.loss_mask: 0.4761  decode.d4.loss_dice: 1.1626  decode.d5.loss_cls: 0.0686  decode.d5.loss_mask: 0.4910  decode.d5.loss_dice: 1.1448  decode.d6.loss_cls: 0.0563  decode.d6.loss_mask: 0.4870  decode.d6.loss_dice: 1.2095  decode.d7.loss_cls: 0.0633  decode.d7.loss_mask: 0.4802  decode.d7.loss_dice: 1.2137  decode.d8.loss_cls: 0.0697  decode.d8.loss_mask: 0.4764  decode.d8.loss_dice: 1.1536
11/15 11:46:54 - mmengine - INFO - Iter(train) [28600/90000]  base_lr: 7.0882e-05 lr: 7.0882e-06  eta: 10:18:41  time: 0.5984  data_time: 0.0099  memory: 10641  grad_norm: 579.2307  loss: 17.8987  decode.loss_cls: 0.0892  decode.loss_mask: 0.4923  decode.loss_dice: 1.2233  decode.d0.loss_cls: 0.0981  decode.d0.loss_mask: 0.5194  decode.d0.loss_dice: 1.2758  decode.d1.loss_cls: 0.0956  decode.d1.loss_mask: 0.4873  decode.d1.loss_dice: 1.2163  decode.d2.loss_cls: 0.0833  decode.d2.loss_mask: 0.4938  decode.d2.loss_dice: 1.1920  decode.d3.loss_cls: 0.0746  decode.d3.loss_mask: 0.4902  decode.d3.loss_dice: 1.1870  decode.d4.loss_cls: 0.0634  decode.d4.loss_mask: 0.4918  decode.d4.loss_dice: 1.1910  decode.d5.loss_cls: 0.0823  decode.d5.loss_mask: 0.4962  decode.d5.loss_dice: 1.1898  decode.d6.loss_cls: 0.0959  decode.d6.loss_mask: 0.4834  decode.d6.loss_dice: 1.2382  decode.d7.loss_cls: 0.0849  decode.d7.loss_mask: 0.4832  decode.d7.loss_dice: 1.2080  decode.d8.loss_cls: 0.0859  decode.d8.loss_mask: 0.4847  decode.d8.loss_dice: 1.2019
11/15 11:47:24 - mmengine - INFO - Iter(train) [28650/90000]  base_lr: 7.0830e-05 lr: 7.0830e-06  eta: 10:18:10  time: 0.6029  data_time: 0.0101  memory: 10656  grad_norm: 577.9983  loss: 21.0718  decode.loss_cls: 0.1035  decode.loss_mask: 0.6241  decode.loss_dice: 1.3465  decode.d0.loss_cls: 0.0980  decode.d0.loss_mask: 0.6541  decode.d0.loss_dice: 1.4390  decode.d1.loss_cls: 0.0952  decode.d1.loss_mask: 0.6277  decode.d1.loss_dice: 1.3929  decode.d2.loss_cls: 0.1007  decode.d2.loss_mask: 0.6064  decode.d2.loss_dice: 1.3797  decode.d3.loss_cls: 0.0946  decode.d3.loss_mask: 0.6204  decode.d3.loss_dice: 1.3680  decode.d4.loss_cls: 0.1119  decode.d4.loss_mask: 0.6210  decode.d4.loss_dice: 1.3650  decode.d5.loss_cls: 0.1053  decode.d5.loss_mask: 0.6309  decode.d5.loss_dice: 1.3854  decode.d6.loss_cls: 0.1142  decode.d6.loss_mask: 0.6300  decode.d6.loss_dice: 1.3336  decode.d7.loss_cls: 0.1121  decode.d7.loss_mask: 0.6352  decode.d7.loss_dice: 1.3784  decode.d8.loss_cls: 0.1199  decode.d8.loss_mask: 0.6363  decode.d8.loss_dice: 1.3418
11/15 11:47:54 - mmengine - INFO - Iter(train) [28700/90000]  base_lr: 7.0778e-05 lr: 7.0778e-06  eta: 10:17:40  time: 0.6032  data_time: 0.0099  memory: 10713  grad_norm: 1112.9491  loss: 20.2721  decode.loss_cls: 0.0919  decode.loss_mask: 0.5841  decode.loss_dice: 1.3060  decode.d0.loss_cls: 0.0986  decode.d0.loss_mask: 0.6223  decode.d0.loss_dice: 1.4312  decode.d1.loss_cls: 0.1111  decode.d1.loss_mask: 0.5756  decode.d1.loss_dice: 1.3400  decode.d2.loss_cls: 0.1113  decode.d2.loss_mask: 0.6041  decode.d2.loss_dice: 1.3369  decode.d3.loss_cls: 0.0984  decode.d3.loss_mask: 0.6086  decode.d3.loss_dice: 1.3122  decode.d4.loss_cls: 0.0932  decode.d4.loss_mask: 0.5860  decode.d4.loss_dice: 1.3295  decode.d5.loss_cls: 0.0998  decode.d5.loss_mask: 0.5988  decode.d5.loss_dice: 1.3437  decode.d6.loss_cls: 0.0896  decode.d6.loss_mask: 0.6039  decode.d6.loss_dice: 1.3028  decode.d7.loss_cls: 0.0987  decode.d7.loss_mask: 0.5971  decode.d7.loss_dice: 1.2951  decode.d8.loss_cls: 0.0917  decode.d8.loss_mask: 0.5885  decode.d8.loss_dice: 1.3215
11/15 11:48:24 - mmengine - INFO - Iter(train) [28750/90000]  base_lr: 7.0726e-05 lr: 7.0726e-06  eta: 10:17:09  time: 0.6030  data_time: 0.0099  memory: 10656  grad_norm: 606.0310  loss: 19.1314  decode.loss_cls: 0.0633  decode.loss_mask: 0.6129  decode.loss_dice: 1.2285  decode.d0.loss_cls: 0.0821  decode.d0.loss_mask: 0.6059  decode.d0.loss_dice: 1.3053  decode.d1.loss_cls: 0.0635  decode.d1.loss_mask: 0.6031  decode.d1.loss_dice: 1.2275  decode.d2.loss_cls: 0.0730  decode.d2.loss_mask: 0.6050  decode.d2.loss_dice: 1.2250  decode.d3.loss_cls: 0.0714  decode.d3.loss_mask: 0.6020  decode.d3.loss_dice: 1.2209  decode.d4.loss_cls: 0.0753  decode.d4.loss_mask: 0.6046  decode.d4.loss_dice: 1.2407  decode.d5.loss_cls: 0.0908  decode.d5.loss_mask: 0.6050  decode.d5.loss_dice: 1.2155  decode.d6.loss_cls: 0.0576  decode.d6.loss_mask: 0.6079  decode.d6.loss_dice: 1.2413  decode.d7.loss_cls: 0.0772  decode.d7.loss_mask: 0.6086  decode.d7.loss_dice: 1.2255  decode.d8.loss_cls: 0.0689  decode.d8.loss_mask: 0.6019  decode.d8.loss_dice: 1.2212
11/15 11:48:54 - mmengine - INFO - Iter(train) [28800/90000]  base_lr: 7.0674e-05 lr: 7.0674e-06  eta: 10:16:39  time: 0.6028  data_time: 0.0103  memory: 10692  grad_norm: 470.0719  loss: 17.4432  decode.loss_cls: 0.0755  decode.loss_mask: 0.5532  decode.loss_dice: 1.1093  decode.d0.loss_cls: 0.0787  decode.d0.loss_mask: 0.5889  decode.d0.loss_dice: 1.1588  decode.d1.loss_cls: 0.0815  decode.d1.loss_mask: 0.5448  decode.d1.loss_dice: 1.1343  decode.d2.loss_cls: 0.0820  decode.d2.loss_mask: 0.5318  decode.d2.loss_dice: 1.0954  decode.d3.loss_cls: 0.0776  decode.d3.loss_mask: 0.5503  decode.d3.loss_dice: 1.1174  decode.d4.loss_cls: 0.0880  decode.d4.loss_mask: 0.5431  decode.d4.loss_dice: 1.1092  decode.d5.loss_cls: 0.0997  decode.d5.loss_mask: 0.5321  decode.d5.loss_dice: 1.0696  decode.d6.loss_cls: 0.0722  decode.d6.loss_mask: 0.5524  decode.d6.loss_dice: 1.1234  decode.d7.loss_cls: 0.0667  decode.d7.loss_mask: 0.5449  decode.d7.loss_dice: 1.1217  decode.d8.loss_cls: 0.0826  decode.d8.loss_mask: 0.5420  decode.d8.loss_dice: 1.1162
11/15 11:49:25 - mmengine - INFO - Iter(train) [28850/90000]  base_lr: 7.0622e-05 lr: 7.0622e-06  eta: 10:16:08  time: 0.6019  data_time: 0.0104  memory: 10692  grad_norm: 416.6351  loss: 19.3418  decode.loss_cls: 0.0810  decode.loss_mask: 0.6040  decode.loss_dice: 1.2353  decode.d0.loss_cls: 0.0970  decode.d0.loss_mask: 0.6688  decode.d0.loss_dice: 1.3132  decode.d1.loss_cls: 0.0688  decode.d1.loss_mask: 0.6274  decode.d1.loss_dice: 1.2802  decode.d2.loss_cls: 0.0562  decode.d2.loss_mask: 0.6601  decode.d2.loss_dice: 1.2693  decode.d3.loss_cls: 0.0710  decode.d3.loss_mask: 0.6294  decode.d3.loss_dice: 1.2133  decode.d4.loss_cls: 0.0683  decode.d4.loss_mask: 0.6319  decode.d4.loss_dice: 1.2122  decode.d5.loss_cls: 0.0821  decode.d5.loss_mask: 0.6121  decode.d5.loss_dice: 1.2166  decode.d6.loss_cls: 0.0860  decode.d6.loss_mask: 0.5927  decode.d6.loss_dice: 1.1972  decode.d7.loss_cls: 0.0707  decode.d7.loss_mask: 0.6125  decode.d7.loss_dice: 1.2097  decode.d8.loss_cls: 0.0801  decode.d8.loss_mask: 0.6011  decode.d8.loss_dice: 1.1939
11/15 11:49:55 - mmengine - INFO - Iter(train) [28900/90000]  base_lr: 7.0570e-05 lr: 7.0570e-06  eta: 10:15:38  time: 0.6007  data_time: 0.0099  memory: 10675  grad_norm: 303.3171  loss: 17.5466  decode.loss_cls: 0.0329  decode.loss_mask: 0.5927  decode.loss_dice: 1.1341  decode.d0.loss_cls: 0.0741  decode.d0.loss_mask: 0.6055  decode.d0.loss_dice: 1.1549  decode.d1.loss_cls: 0.0580  decode.d1.loss_mask: 0.5897  decode.d1.loss_dice: 1.1079  decode.d2.loss_cls: 0.0469  decode.d2.loss_mask: 0.5842  decode.d2.loss_dice: 1.1116  decode.d3.loss_cls: 0.0511  decode.d3.loss_mask: 0.5890  decode.d3.loss_dice: 1.1036  decode.d4.loss_cls: 0.0397  decode.d4.loss_mask: 0.6015  decode.d4.loss_dice: 1.1085  decode.d5.loss_cls: 0.0560  decode.d5.loss_mask: 0.5964  decode.d5.loss_dice: 1.0921  decode.d6.loss_cls: 0.0509  decode.d6.loss_mask: 0.5976  decode.d6.loss_dice: 1.0992  decode.d7.loss_cls: 0.0454  decode.d7.loss_mask: 0.5873  decode.d7.loss_dice: 1.0966  decode.d8.loss_cls: 0.0455  decode.d8.loss_mask: 0.5882  decode.d8.loss_dice: 1.1055
11/15 11:50:25 - mmengine - INFO - Iter(train) [28950/90000]  base_lr: 7.0519e-05 lr: 7.0519e-06  eta: 10:15:07  time: 0.6002  data_time: 0.0102  memory: 10675  grad_norm: 820.3382  loss: 18.3816  decode.loss_cls: 0.0753  decode.loss_mask: 0.5375  decode.loss_dice: 1.1625  decode.d0.loss_cls: 0.0801  decode.d0.loss_mask: 0.6215  decode.d0.loss_dice: 1.3085  decode.d1.loss_cls: 0.0874  decode.d1.loss_mask: 0.6034  decode.d1.loss_dice: 1.1883  decode.d2.loss_cls: 0.0671  decode.d2.loss_mask: 0.5518  decode.d2.loss_dice: 1.2013  decode.d3.loss_cls: 0.0715  decode.d3.loss_mask: 0.5632  decode.d3.loss_dice: 1.1667  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.5961  decode.d4.loss_dice: 1.1851  decode.d5.loss_cls: 0.0773  decode.d5.loss_mask: 0.6114  decode.d5.loss_dice: 1.1756  decode.d6.loss_cls: 0.0695  decode.d6.loss_mask: 0.5214  decode.d6.loss_dice: 1.1883  decode.d7.loss_cls: 0.0669  decode.d7.loss_mask: 0.5326  decode.d7.loss_dice: 1.2156  decode.d8.loss_cls: 0.0741  decode.d8.loss_mask: 0.5374  decode.d8.loss_dice: 1.1776
11/15 11:50:55 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 11:50:55 - mmengine - INFO - Iter(train) [29000/90000]  base_lr: 7.0467e-05 lr: 7.0467e-06  eta: 10:14:37  time: 0.6013  data_time: 0.0101  memory: 10675  grad_norm: 301.4378  loss: 17.1708  decode.loss_cls: 0.0525  decode.loss_mask: 0.4588  decode.loss_dice: 1.2086  decode.d0.loss_cls: 0.0614  decode.d0.loss_mask: 0.4716  decode.d0.loss_dice: 1.2413  decode.d1.loss_cls: 0.0612  decode.d1.loss_mask: 0.4562  decode.d1.loss_dice: 1.2121  decode.d2.loss_cls: 0.0456  decode.d2.loss_mask: 0.4591  decode.d2.loss_dice: 1.2255  decode.d3.loss_cls: 0.0532  decode.d3.loss_mask: 0.4608  decode.d3.loss_dice: 1.1892  decode.d4.loss_cls: 0.0614  decode.d4.loss_mask: 0.4577  decode.d4.loss_dice: 1.1626  decode.d5.loss_cls: 0.0543  decode.d5.loss_mask: 0.4627  decode.d5.loss_dice: 1.1999  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.4626  decode.d6.loss_dice: 1.1690  decode.d7.loss_cls: 0.0493  decode.d7.loss_mask: 0.4547  decode.d7.loss_dice: 1.2003  decode.d8.loss_cls: 0.0563  decode.d8.loss_mask: 0.4571  decode.d8.loss_dice: 1.2101
11/15 11:51:25 - mmengine - INFO - Iter(train) [29050/90000]  base_lr: 7.0415e-05 lr: 7.0415e-06  eta: 10:14:06  time: 0.5989  data_time: 0.0104  memory: 10692  grad_norm: 339.6837  loss: 19.6866  decode.loss_cls: 0.0867  decode.loss_mask: 0.5943  decode.loss_dice: 1.2897  decode.d0.loss_cls: 0.0972  decode.d0.loss_mask: 0.6338  decode.d0.loss_dice: 1.3380  decode.d1.loss_cls: 0.0815  decode.d1.loss_mask: 0.6086  decode.d1.loss_dice: 1.3022  decode.d2.loss_cls: 0.0873  decode.d2.loss_mask: 0.6171  decode.d2.loss_dice: 1.2662  decode.d3.loss_cls: 0.0754  decode.d3.loss_mask: 0.6226  decode.d3.loss_dice: 1.2147  decode.d4.loss_cls: 0.0828  decode.d4.loss_mask: 0.6103  decode.d4.loss_dice: 1.2791  decode.d5.loss_cls: 0.0971  decode.d5.loss_mask: 0.6043  decode.d5.loss_dice: 1.2529  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 0.5935  decode.d6.loss_dice: 1.2734  decode.d7.loss_cls: 0.0805  decode.d7.loss_mask: 0.5960  decode.d7.loss_dice: 1.2696  decode.d8.loss_cls: 0.0772  decode.d8.loss_mask: 0.5882  decode.d8.loss_dice: 1.2829
11/15 11:51:55 - mmengine - INFO - Iter(train) [29100/90000]  base_lr: 7.0363e-05 lr: 7.0363e-06  eta: 10:13:35  time: 0.5981  data_time: 0.0100  memory: 10675  grad_norm: 370.8145  loss: 18.5504  decode.loss_cls: 0.0632  decode.loss_mask: 0.6912  decode.loss_dice: 1.0961  decode.d0.loss_cls: 0.0871  decode.d0.loss_mask: 0.6860  decode.d0.loss_dice: 1.1838  decode.d1.loss_cls: 0.0598  decode.d1.loss_mask: 0.6782  decode.d1.loss_dice: 1.1316  decode.d2.loss_cls: 0.0715  decode.d2.loss_mask: 0.6736  decode.d2.loss_dice: 1.0981  decode.d3.loss_cls: 0.0640  decode.d3.loss_mask: 0.6450  decode.d3.loss_dice: 1.0827  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 0.6467  decode.d4.loss_dice: 1.0620  decode.d5.loss_cls: 0.0609  decode.d5.loss_mask: 0.6770  decode.d5.loss_dice: 1.1178  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.6872  decode.d6.loss_dice: 1.1126  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.6792  decode.d7.loss_dice: 1.1175  decode.d8.loss_cls: 0.0725  decode.d8.loss_mask: 0.7012  decode.d8.loss_dice: 1.1134
11/15 11:52:25 - mmengine - INFO - Iter(train) [29150/90000]  base_lr: 7.0311e-05 lr: 7.0311e-06  eta: 10:13:04  time: 0.5996  data_time: 0.0101  memory: 10675  grad_norm: 299.3112  loss: 18.2956  decode.loss_cls: 0.0638  decode.loss_mask: 0.5534  decode.loss_dice: 1.2195  decode.d0.loss_cls: 0.0707  decode.d0.loss_mask: 0.5633  decode.d0.loss_dice: 1.3256  decode.d1.loss_cls: 0.0736  decode.d1.loss_mask: 0.5454  decode.d1.loss_dice: 1.1920  decode.d2.loss_cls: 0.0632  decode.d2.loss_mask: 0.5411  decode.d2.loss_dice: 1.2108  decode.d3.loss_cls: 0.0768  decode.d3.loss_mask: 0.5333  decode.d3.loss_dice: 1.1919  decode.d4.loss_cls: 0.0581  decode.d4.loss_mask: 0.5393  decode.d4.loss_dice: 1.1973  decode.d5.loss_cls: 0.0744  decode.d5.loss_mask: 0.5346  decode.d5.loss_dice: 1.2027  decode.d6.loss_cls: 0.0784  decode.d6.loss_mask: 0.5385  decode.d6.loss_dice: 1.2009  decode.d7.loss_cls: 0.0586  decode.d7.loss_mask: 0.5378  decode.d7.loss_dice: 1.2162  decode.d8.loss_cls: 0.0652  decode.d8.loss_mask: 0.5460  decode.d8.loss_dice: 1.2235
11/15 11:52:55 - mmengine - INFO - Iter(train) [29200/90000]  base_lr: 7.0259e-05 lr: 7.0259e-06  eta: 10:12:34  time: 0.6005  data_time: 0.0100  memory: 10692  grad_norm: 908.4376  loss: 17.6057  decode.loss_cls: 0.0495  decode.loss_mask: 0.5462  decode.loss_dice: 1.1621  decode.d0.loss_cls: 0.0783  decode.d0.loss_mask: 0.5547  decode.d0.loss_dice: 1.2005  decode.d1.loss_cls: 0.0556  decode.d1.loss_mask: 0.5388  decode.d1.loss_dice: 1.1798  decode.d2.loss_cls: 0.0692  decode.d2.loss_mask: 0.5410  decode.d2.loss_dice: 1.1860  decode.d3.loss_cls: 0.0456  decode.d3.loss_mask: 0.5481  decode.d3.loss_dice: 1.1580  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.5456  decode.d4.loss_dice: 1.1750  decode.d5.loss_cls: 0.0476  decode.d5.loss_mask: 0.5364  decode.d5.loss_dice: 1.1517  decode.d6.loss_cls: 0.0457  decode.d6.loss_mask: 0.5424  decode.d6.loss_dice: 1.1464  decode.d7.loss_cls: 0.0465  decode.d7.loss_mask: 0.5440  decode.d7.loss_dice: 1.1263  decode.d8.loss_cls: 0.0477  decode.d8.loss_mask: 0.5457  decode.d8.loss_dice: 1.1497
11/15 11:53:25 - mmengine - INFO - Iter(train) [29250/90000]  base_lr: 7.0207e-05 lr: 7.0207e-06  eta: 10:12:03  time: 0.5987  data_time: 0.0099  memory: 10713  grad_norm: 320.1386  loss: 17.7208  decode.loss_cls: 0.0712  decode.loss_mask: 0.4324  decode.loss_dice: 1.2740  decode.d0.loss_cls: 0.1088  decode.d0.loss_mask: 0.4471  decode.d0.loss_dice: 1.3206  decode.d1.loss_cls: 0.1021  decode.d1.loss_mask: 0.4166  decode.d1.loss_dice: 1.2324  decode.d2.loss_cls: 0.1007  decode.d2.loss_mask: 0.4196  decode.d2.loss_dice: 1.2428  decode.d3.loss_cls: 0.1043  decode.d3.loss_mask: 0.4128  decode.d3.loss_dice: 1.2211  decode.d4.loss_cls: 0.1088  decode.d4.loss_mask: 0.4227  decode.d4.loss_dice: 1.2444  decode.d5.loss_cls: 0.1015  decode.d5.loss_mask: 0.4082  decode.d5.loss_dice: 1.2365  decode.d6.loss_cls: 0.1134  decode.d6.loss_mask: 0.4127  decode.d6.loss_dice: 1.1979  decode.d7.loss_cls: 0.1052  decode.d7.loss_mask: 0.4242  decode.d7.loss_dice: 1.2527  decode.d8.loss_cls: 0.0917  decode.d8.loss_mask: 0.4300  decode.d8.loss_dice: 1.2647
11/15 11:53:55 - mmengine - INFO - Iter(train) [29300/90000]  base_lr: 7.0155e-05 lr: 7.0155e-06  eta: 10:11:33  time: 0.5994  data_time: 0.0101  memory: 10742  grad_norm: 542.1747  loss: 16.3953  decode.loss_cls: 0.0610  decode.loss_mask: 0.5776  decode.loss_dice: 0.9799  decode.d0.loss_cls: 0.0769  decode.d0.loss_mask: 0.5972  decode.d0.loss_dice: 1.0453  decode.d1.loss_cls: 0.0705  decode.d1.loss_mask: 0.5775  decode.d1.loss_dice: 0.9651  decode.d2.loss_cls: 0.0582  decode.d2.loss_mask: 0.5927  decode.d2.loss_dice: 0.9919  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.5892  decode.d3.loss_dice: 0.9922  decode.d4.loss_cls: 0.0666  decode.d4.loss_mask: 0.5895  decode.d4.loss_dice: 0.9943  decode.d5.loss_cls: 0.0713  decode.d5.loss_mask: 0.5756  decode.d5.loss_dice: 0.9714  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.5799  decode.d6.loss_dice: 0.9935  decode.d7.loss_cls: 0.0588  decode.d7.loss_mask: 0.5775  decode.d7.loss_dice: 0.9882  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.5749  decode.d8.loss_dice: 0.9984
11/15 11:54:25 - mmengine - INFO - Iter(train) [29350/90000]  base_lr: 7.0103e-05 lr: 7.0103e-06  eta: 10:11:02  time: 0.6011  data_time: 0.0100  memory: 10675  grad_norm: 402.7601  loss: 18.8945  decode.loss_cls: 0.0578  decode.loss_mask: 0.5963  decode.loss_dice: 1.2184  decode.d0.loss_cls: 0.0910  decode.d0.loss_mask: 0.6221  decode.d0.loss_dice: 1.2993  decode.d1.loss_cls: 0.0736  decode.d1.loss_mask: 0.5952  decode.d1.loss_dice: 1.2248  decode.d2.loss_cls: 0.0683  decode.d2.loss_mask: 0.5956  decode.d2.loss_dice: 1.1956  decode.d3.loss_cls: 0.0712  decode.d3.loss_mask: 0.5980  decode.d3.loss_dice: 1.2036  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.6055  decode.d4.loss_dice: 1.2087  decode.d5.loss_cls: 0.0690  decode.d5.loss_mask: 0.5874  decode.d5.loss_dice: 1.2149  decode.d6.loss_cls: 0.0574  decode.d6.loss_mask: 0.6028  decode.d6.loss_dice: 1.2132  decode.d7.loss_cls: 0.0609  decode.d7.loss_mask: 0.5960  decode.d7.loss_dice: 1.2154  decode.d8.loss_cls: 0.0754  decode.d8.loss_mask: 0.6010  decode.d8.loss_dice: 1.2164
11/15 11:54:55 - mmengine - INFO - Iter(train) [29400/90000]  base_lr: 7.0051e-05 lr: 7.0051e-06  eta: 10:10:31  time: 0.5989  data_time: 0.0100  memory: 10675  grad_norm: 787.4228  loss: 18.8151  decode.loss_cls: 0.0766  decode.loss_mask: 0.5496  decode.loss_dice: 1.2575  decode.d0.loss_cls: 0.0986  decode.d0.loss_mask: 0.5766  decode.d0.loss_dice: 1.2546  decode.d1.loss_cls: 0.0937  decode.d1.loss_mask: 0.5506  decode.d1.loss_dice: 1.2591  decode.d2.loss_cls: 0.0590  decode.d2.loss_mask: 0.5761  decode.d2.loss_dice: 1.2593  decode.d3.loss_cls: 0.0824  decode.d3.loss_mask: 0.5441  decode.d3.loss_dice: 1.2342  decode.d4.loss_cls: 0.0802  decode.d4.loss_mask: 0.5423  decode.d4.loss_dice: 1.2439  decode.d5.loss_cls: 0.0765  decode.d5.loss_mask: 0.5407  decode.d5.loss_dice: 1.2407  decode.d6.loss_cls: 0.0825  decode.d6.loss_mask: 0.5333  decode.d6.loss_dice: 1.2349  decode.d7.loss_cls: 0.0748  decode.d7.loss_mask: 0.5540  decode.d7.loss_dice: 1.2268  decode.d8.loss_cls: 0.0708  decode.d8.loss_mask: 0.5755  decode.d8.loss_dice: 1.2660
11/15 11:55:25 - mmengine - INFO - Iter(train) [29450/90000]  base_lr: 6.9999e-05 lr: 6.9999e-06  eta: 10:10:01  time: 0.5987  data_time: 0.0100  memory: 10675  grad_norm: 405.5314  loss: 18.8980  decode.loss_cls: 0.0729  decode.loss_mask: 0.6040  decode.loss_dice: 1.2021  decode.d0.loss_cls: 0.0692  decode.d0.loss_mask: 0.6357  decode.d0.loss_dice: 1.3002  decode.d1.loss_cls: 0.0654  decode.d1.loss_mask: 0.5998  decode.d1.loss_dice: 1.2379  decode.d2.loss_cls: 0.0623  decode.d2.loss_mask: 0.6030  decode.d2.loss_dice: 1.1869  decode.d3.loss_cls: 0.0645  decode.d3.loss_mask: 0.6015  decode.d3.loss_dice: 1.1994  decode.d4.loss_cls: 0.0697  decode.d4.loss_mask: 0.6182  decode.d4.loss_dice: 1.2038  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 0.6134  decode.d5.loss_dice: 1.2037  decode.d6.loss_cls: 0.0682  decode.d6.loss_mask: 0.6017  decode.d6.loss_dice: 1.1820  decode.d7.loss_cls: 0.0669  decode.d7.loss_mask: 0.6048  decode.d7.loss_dice: 1.1999  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.6114  decode.d8.loss_dice: 1.2273
11/15 11:55:55 - mmengine - INFO - Iter(train) [29500/90000]  base_lr: 6.9946e-05 lr: 6.9946e-06  eta: 10:09:30  time: 0.6007  data_time: 0.0099  memory: 10675  grad_norm: 262.9391  loss: 17.3827  decode.loss_cls: 0.0623  decode.loss_mask: 0.4936  decode.loss_dice: 1.1832  decode.d0.loss_cls: 0.0672  decode.d0.loss_mask: 0.5119  decode.d0.loss_dice: 1.2620  decode.d1.loss_cls: 0.0572  decode.d1.loss_mask: 0.4949  decode.d1.loss_dice: 1.1662  decode.d2.loss_cls: 0.0683  decode.d2.loss_mask: 0.4949  decode.d2.loss_dice: 1.1397  decode.d3.loss_cls: 0.0649  decode.d3.loss_mask: 0.4985  decode.d3.loss_dice: 1.1866  decode.d4.loss_cls: 0.0618  decode.d4.loss_mask: 0.4930  decode.d4.loss_dice: 1.1643  decode.d5.loss_cls: 0.0684  decode.d5.loss_mask: 0.4935  decode.d5.loss_dice: 1.1871  decode.d6.loss_cls: 0.0798  decode.d6.loss_mask: 0.4872  decode.d6.loss_dice: 1.1650  decode.d7.loss_cls: 0.0605  decode.d7.loss_mask: 0.4918  decode.d7.loss_dice: 1.1672  decode.d8.loss_cls: 0.0655  decode.d8.loss_mask: 0.4855  decode.d8.loss_dice: 1.1608
11/15 11:56:25 - mmengine - INFO - Iter(train) [29550/90000]  base_lr: 6.9894e-05 lr: 6.9894e-06  eta: 10:08:59  time: 0.6064  data_time: 0.0102  memory: 10641  grad_norm: 506.3995  loss: 17.2091  decode.loss_cls: 0.0583  decode.loss_mask: 0.5588  decode.loss_dice: 1.0495  decode.d0.loss_cls: 0.1061  decode.d0.loss_mask: 0.6012  decode.d0.loss_dice: 1.1983  decode.d1.loss_cls: 0.0772  decode.d1.loss_mask: 0.5952  decode.d1.loss_dice: 1.0470  decode.d2.loss_cls: 0.0648  decode.d2.loss_mask: 0.5703  decode.d2.loss_dice: 1.0494  decode.d3.loss_cls: 0.0575  decode.d3.loss_mask: 0.5802  decode.d3.loss_dice: 1.0832  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.5586  decode.d4.loss_dice: 1.0834  decode.d5.loss_cls: 0.0620  decode.d5.loss_mask: 0.5750  decode.d5.loss_dice: 1.0738  decode.d6.loss_cls: 0.0552  decode.d6.loss_mask: 0.5656  decode.d6.loss_dice: 1.0442  decode.d7.loss_cls: 0.0677  decode.d7.loss_mask: 0.6176  decode.d7.loss_dice: 1.0789  decode.d8.loss_cls: 0.0623  decode.d8.loss_mask: 0.5719  decode.d8.loss_dice: 1.0370
11/15 11:56:55 - mmengine - INFO - Iter(train) [29600/90000]  base_lr: 6.9842e-05 lr: 6.9842e-06  eta: 10:08:29  time: 0.5988  data_time: 0.0100  memory: 10692  grad_norm: 340.2798  loss: 19.9468  decode.loss_cls: 0.0650  decode.loss_mask: 0.6275  decode.loss_dice: 1.3032  decode.d0.loss_cls: 0.0752  decode.d0.loss_mask: 0.6712  decode.d0.loss_dice: 1.3646  decode.d1.loss_cls: 0.0766  decode.d1.loss_mask: 0.6516  decode.d1.loss_dice: 1.3159  decode.d2.loss_cls: 0.0722  decode.d2.loss_mask: 0.6362  decode.d2.loss_dice: 1.3112  decode.d3.loss_cls: 0.0685  decode.d3.loss_mask: 0.6238  decode.d3.loss_dice: 1.2672  decode.d4.loss_cls: 0.0760  decode.d4.loss_mask: 0.6182  decode.d4.loss_dice: 1.2591  decode.d5.loss_cls: 0.0718  decode.d5.loss_mask: 0.6264  decode.d5.loss_dice: 1.2757  decode.d6.loss_cls: 0.0852  decode.d6.loss_mask: 0.6084  decode.d6.loss_dice: 1.2391  decode.d7.loss_cls: 0.0836  decode.d7.loss_mask: 0.6147  decode.d7.loss_dice: 1.2842  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.6133  decode.d8.loss_dice: 1.2837
11/15 11:57:25 - mmengine - INFO - Iter(train) [29650/90000]  base_lr: 6.9790e-05 lr: 6.9790e-06  eta: 10:07:58  time: 0.6038  data_time: 0.0104  memory: 10692  grad_norm: 404.5747  loss: 17.7183  decode.loss_cls: 0.0728  decode.loss_mask: 0.5070  decode.loss_dice: 1.1714  decode.d0.loss_cls: 0.0952  decode.d0.loss_mask: 0.5160  decode.d0.loss_dice: 1.2513  decode.d1.loss_cls: 0.0803  decode.d1.loss_mask: 0.5092  decode.d1.loss_dice: 1.2049  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.5048  decode.d2.loss_dice: 1.1803  decode.d3.loss_cls: 0.0762  decode.d3.loss_mask: 0.5081  decode.d3.loss_dice: 1.1776  decode.d4.loss_cls: 0.0872  decode.d4.loss_mask: 0.5066  decode.d4.loss_dice: 1.1730  decode.d5.loss_cls: 0.0850  decode.d5.loss_mask: 0.5083  decode.d5.loss_dice: 1.1571  decode.d6.loss_cls: 0.0786  decode.d6.loss_mask: 0.5088  decode.d6.loss_dice: 1.1701  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.5191  decode.d7.loss_dice: 1.1796  decode.d8.loss_cls: 0.0707  decode.d8.loss_mask: 0.5053  decode.d8.loss_dice: 1.1734
11/15 11:57:55 - mmengine - INFO - Iter(train) [29700/90000]  base_lr: 6.9738e-05 lr: 6.9738e-06  eta: 10:07:27  time: 0.5987  data_time: 0.0101  memory: 10656  grad_norm: 334.4411  loss: 18.2687  decode.loss_cls: 0.0677  decode.loss_mask: 0.7315  decode.loss_dice: 1.0680  decode.d0.loss_cls: 0.0859  decode.d0.loss_mask: 0.7475  decode.d0.loss_dice: 1.0912  decode.d1.loss_cls: 0.0776  decode.d1.loss_mask: 0.6831  decode.d1.loss_dice: 1.0425  decode.d2.loss_cls: 0.0570  decode.d2.loss_mask: 0.6757  decode.d2.loss_dice: 1.0567  decode.d3.loss_cls: 0.0657  decode.d3.loss_mask: 0.6945  decode.d3.loss_dice: 1.0512  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.6946  decode.d4.loss_dice: 1.0541  decode.d5.loss_cls: 0.0578  decode.d5.loss_mask: 0.7009  decode.d5.loss_dice: 1.0685  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.6965  decode.d6.loss_dice: 1.0499  decode.d7.loss_cls: 0.0701  decode.d7.loss_mask: 0.6859  decode.d7.loss_dice: 1.0348  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.7066  decode.d8.loss_dice: 1.0787
11/15 11:58:25 - mmengine - INFO - Iter(train) [29750/90000]  base_lr: 6.9686e-05 lr: 6.9686e-06  eta: 10:06:57  time: 0.5990  data_time: 0.0100  memory: 10675  grad_norm: 307.7172  loss: 19.8206  decode.loss_cls: 0.0525  decode.loss_mask: 0.6286  decode.loss_dice: 1.2901  decode.d0.loss_cls: 0.0897  decode.d0.loss_mask: 0.6593  decode.d0.loss_dice: 1.3496  decode.d1.loss_cls: 0.0696  decode.d1.loss_mask: 0.6480  decode.d1.loss_dice: 1.3116  decode.d2.loss_cls: 0.0542  decode.d2.loss_mask: 0.6271  decode.d2.loss_dice: 1.2567  decode.d3.loss_cls: 0.0545  decode.d3.loss_mask: 0.6312  decode.d3.loss_dice: 1.2924  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 0.6279  decode.d4.loss_dice: 1.2829  decode.d5.loss_cls: 0.0518  decode.d5.loss_mask: 0.6256  decode.d5.loss_dice: 1.2789  decode.d6.loss_cls: 0.0673  decode.d6.loss_mask: 0.6174  decode.d6.loss_dice: 1.2979  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.6163  decode.d7.loss_dice: 1.2897  decode.d8.loss_cls: 0.0553  decode.d8.loss_mask: 0.6145  decode.d8.loss_dice: 1.2736
11/15 11:58:55 - mmengine - INFO - Iter(train) [29800/90000]  base_lr: 6.9634e-05 lr: 6.9634e-06  eta: 10:06:26  time: 0.5987  data_time: 0.0101  memory: 10713  grad_norm: 812.6145  loss: 19.7255  decode.loss_cls: 0.0975  decode.loss_mask: 0.6139  decode.loss_dice: 1.2286  decode.d0.loss_cls: 0.0975  decode.d0.loss_mask: 0.6436  decode.d0.loss_dice: 1.3531  decode.d1.loss_cls: 0.0977  decode.d1.loss_mask: 0.6125  decode.d1.loss_dice: 1.2850  decode.d2.loss_cls: 0.0952  decode.d2.loss_mask: 0.6171  decode.d2.loss_dice: 1.2680  decode.d3.loss_cls: 0.1004  decode.d3.loss_mask: 0.5996  decode.d3.loss_dice: 1.2394  decode.d4.loss_cls: 0.0942  decode.d4.loss_mask: 0.6170  decode.d4.loss_dice: 1.2893  decode.d5.loss_cls: 0.1195  decode.d5.loss_mask: 0.6124  decode.d5.loss_dice: 1.2395  decode.d6.loss_cls: 0.1049  decode.d6.loss_mask: 0.6147  decode.d6.loss_dice: 1.2058  decode.d7.loss_cls: 0.0989  decode.d7.loss_mask: 0.6218  decode.d7.loss_dice: 1.2100  decode.d8.loss_cls: 0.0900  decode.d8.loss_mask: 0.6261  decode.d8.loss_dice: 1.2324
11/15 11:59:25 - mmengine - INFO - Iter(train) [29850/90000]  base_lr: 6.9582e-05 lr: 6.9582e-06  eta: 10:05:55  time: 0.5980  data_time: 0.0098  memory: 10728  grad_norm: 477.5782  loss: 15.1020  decode.loss_cls: 0.0402  decode.loss_mask: 0.4696  decode.loss_dice: 0.9621  decode.d0.loss_cls: 0.0899  decode.d0.loss_mask: 0.5249  decode.d0.loss_dice: 1.0078  decode.d1.loss_cls: 0.0623  decode.d1.loss_mask: 0.4925  decode.d1.loss_dice: 0.9834  decode.d2.loss_cls: 0.0489  decode.d2.loss_mask: 0.4805  decode.d2.loss_dice: 0.9476  decode.d3.loss_cls: 0.0541  decode.d3.loss_mask: 0.4880  decode.d3.loss_dice: 0.9771  decode.d4.loss_cls: 0.0472  decode.d4.loss_mask: 0.4855  decode.d4.loss_dice: 0.9579  decode.d5.loss_cls: 0.0543  decode.d5.loss_mask: 0.4713  decode.d5.loss_dice: 0.9726  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.4696  decode.d6.loss_dice: 0.9658  decode.d7.loss_cls: 0.0562  decode.d7.loss_mask: 0.4731  decode.d7.loss_dice: 0.9775  decode.d8.loss_cls: 0.0560  decode.d8.loss_mask: 0.4713  decode.d8.loss_dice: 0.9566
11/15 11:59:55 - mmengine - INFO - Iter(train) [29900/90000]  base_lr: 6.9530e-05 lr: 6.9530e-06  eta: 10:05:24  time: 0.5994  data_time: 0.0099  memory: 10675  grad_norm: 338.6737  loss: 17.2472  decode.loss_cls: 0.0983  decode.loss_mask: 0.4991  decode.loss_dice: 1.0968  decode.d0.loss_cls: 0.0859  decode.d0.loss_mask: 0.5245  decode.d0.loss_dice: 1.2189  decode.d1.loss_cls: 0.1015  decode.d1.loss_mask: 0.4982  decode.d1.loss_dice: 1.1086  decode.d2.loss_cls: 0.0918  decode.d2.loss_mask: 0.5173  decode.d2.loss_dice: 1.1211  decode.d3.loss_cls: 0.0874  decode.d3.loss_mask: 0.5276  decode.d3.loss_dice: 1.0716  decode.d4.loss_cls: 0.0925  decode.d4.loss_mask: 0.5324  decode.d4.loss_dice: 1.1079  decode.d5.loss_cls: 0.0979  decode.d5.loss_mask: 0.5238  decode.d5.loss_dice: 1.0879  decode.d6.loss_cls: 0.0977  decode.d6.loss_mask: 0.5179  decode.d6.loss_dice: 1.1110  decode.d7.loss_cls: 0.0919  decode.d7.loss_mask: 0.5186  decode.d7.loss_dice: 1.1229  decode.d8.loss_cls: 0.0967  decode.d8.loss_mask: 0.5038  decode.d8.loss_dice: 1.0958
11/15 12:00:25 - mmengine - INFO - Iter(train) [29950/90000]  base_lr: 6.9478e-05 lr: 6.9478e-06  eta: 10:04:54  time: 0.5990  data_time: 0.0102  memory: 10692  grad_norm: 351.0553  loss: 18.1571  decode.loss_cls: 0.0625  decode.loss_mask: 0.5426  decode.loss_dice: 1.2116  decode.d0.loss_cls: 0.0920  decode.d0.loss_mask: 0.5640  decode.d0.loss_dice: 1.2619  decode.d1.loss_cls: 0.0675  decode.d1.loss_mask: 0.5414  decode.d1.loss_dice: 1.2161  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 0.5495  decode.d2.loss_dice: 1.2048  decode.d3.loss_cls: 0.0609  decode.d3.loss_mask: 0.5558  decode.d3.loss_dice: 1.2128  decode.d4.loss_cls: 0.0648  decode.d4.loss_mask: 0.5455  decode.d4.loss_dice: 1.1864  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.5330  decode.d5.loss_dice: 1.1921  decode.d6.loss_cls: 0.0606  decode.d6.loss_mask: 0.5391  decode.d6.loss_dice: 1.1924  decode.d7.loss_cls: 0.0648  decode.d7.loss_mask: 0.5371  decode.d7.loss_dice: 1.1903  decode.d8.loss_cls: 0.0728  decode.d8.loss_mask: 0.5410  decode.d8.loss_dice: 1.1713
11/15 12:00:55 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 12:00:55 - mmengine - INFO - Iter(train) [30000/90000]  base_lr: 6.9426e-05 lr: 6.9426e-06  eta: 10:04:23  time: 0.6079  data_time: 0.0104  memory: 10656  grad_norm: 250.3446  loss: 15.8780  decode.loss_cls: 0.0441  decode.loss_mask: 0.4540  decode.loss_dice: 1.0867  decode.d0.loss_cls: 0.0695  decode.d0.loss_mask: 0.4592  decode.d0.loss_dice: 1.1342  decode.d1.loss_cls: 0.0477  decode.d1.loss_mask: 0.4628  decode.d1.loss_dice: 1.0943  decode.d2.loss_cls: 0.0547  decode.d2.loss_mask: 0.4594  decode.d2.loss_dice: 1.0800  decode.d3.loss_cls: 0.0432  decode.d3.loss_mask: 0.4615  decode.d3.loss_dice: 1.0695  decode.d4.loss_cls: 0.0480  decode.d4.loss_mask: 0.4620  decode.d4.loss_dice: 1.0757  decode.d5.loss_cls: 0.0592  decode.d5.loss_mask: 0.4583  decode.d5.loss_dice: 1.0458  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.4564  decode.d6.loss_dice: 1.0481  decode.d7.loss_cls: 0.0525  decode.d7.loss_mask: 0.4570  decode.d7.loss_dice: 1.0463  decode.d8.loss_cls: 0.0506  decode.d8.loss_mask: 0.4592  decode.d8.loss_dice: 1.0838
11/15 12:00:55 - mmengine - INFO - Saving checkpoint at 30000 iterations
11/15 12:01:14 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:22  time: 0.3088  data_time: 0.0040  memory: 4095  
11/15 12:01:30 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:04  time: 0.3091  data_time: 0.0039  memory: 4095  
11/15 12:01:45 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:48  time: 0.3103  data_time: 0.0041  memory: 4095  
11/15 12:02:01 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3097  data_time: 0.0043  memory: 4095  
11/15 12:02:16 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3091  data_time: 0.0039  memory: 4095  
11/15 12:02:32 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:02  time: 0.3098  data_time: 0.0041  memory: 4095  
11/15 12:02:47 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3100  data_time: 0.0041  memory: 4095  
11/15 12:03:03 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:31  time: 0.3092  data_time: 0.0039  memory: 4095  
11/15 12:03:18 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3098  data_time: 0.0041  memory: 4095  
11/15 12:03:34 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3098  data_time: 0.0037  memory: 4095  
11/15 12:03:34 - mmengine - INFO - per class results:
11/15 12:03:34 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 98.19 |  98.9 |
|    sidewalk   | 85.25 | 92.56 |
|    building   | 92.51 | 96.93 |
|      wall     | 45.25 | 82.55 |
|     fence     | 36.68 | 38.94 |
|      pole     | 64.83 | 76.52 |
| traffic light | 68.94 | 81.73 |
|  traffic sign | 78.67 |  86.1 |
|   vegetation  | 91.97 | 95.14 |
|    terrain    | 60.41 | 76.44 |
|      sky      |  95.0 |  97.7 |
|     person    | 81.49 | 88.01 |
|     rider     |  62.4 | 75.31 |
|      car      | 94.47 | 97.67 |
|     truck     | 76.63 |  85.9 |
|      bus      | 63.73 | 77.81 |
|     train     |  27.8 | 46.67 |
|   motorcycle  | 58.01 | 80.63 |
|    bicycle    | 76.66 | 84.31 |
+---------------+-------+-------+
11/15 12:03:34 - mmengine - INFO - Iter(val) [500/500]    aAcc: 95.6100  mIoU: 71.5200  mAcc: 82.1000  data_time: 0.0046  time: 0.3102
11/15 12:03:34 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024/best_mIoU_iter_25000.pth is removed
11/15 12:03:35 - mmengine - INFO - The best checkpoint with 71.5200 mIoU at 30000 iter is saved to best_mIoU_iter_30000.pth.
11/15 12:04:09 - mmengine - INFO - Iter(train) [30050/90000]  base_lr: 6.9374e-05 lr: 6.9374e-06  eta: 10:04:03  time: 0.6001  data_time: 0.0100  memory: 10713  grad_norm: 382.6351  loss: 17.3468  decode.loss_cls: 0.0530  decode.loss_mask: 0.5056  decode.loss_dice: 1.1445  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.5725  decode.d0.loss_dice: 1.2215  decode.d1.loss_cls: 0.0372  decode.d1.loss_mask: 0.5465  decode.d1.loss_dice: 1.2007  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.5362  decode.d2.loss_dice: 1.1551  decode.d3.loss_cls: 0.0439  decode.d3.loss_mask: 0.5066  decode.d3.loss_dice: 1.1522  decode.d4.loss_cls: 0.0463  decode.d4.loss_mask: 0.5082  decode.d4.loss_dice: 1.1681  decode.d5.loss_cls: 0.0517  decode.d5.loss_mask: 0.5056  decode.d5.loss_dice: 1.1435  decode.d6.loss_cls: 0.0553  decode.d6.loss_mask: 0.5024  decode.d6.loss_dice: 1.1514  decode.d7.loss_cls: 0.0522  decode.d7.loss_mask: 0.5075  decode.d7.loss_dice: 1.1476  decode.d8.loss_cls: 0.0610  decode.d8.loss_mask: 0.5101  decode.d8.loss_dice: 1.1392
11/15 12:04:39 - mmengine - INFO - Iter(train) [30100/90000]  base_lr: 6.9322e-05 lr: 6.9322e-06  eta: 10:03:32  time: 0.6056  data_time: 0.0114  memory: 10713  grad_norm: 324.7823  loss: 18.4519  decode.loss_cls: 0.0678  decode.loss_mask: 0.5444  decode.loss_dice: 1.2268  decode.d0.loss_cls: 0.0770  decode.d0.loss_mask: 0.5860  decode.d0.loss_dice: 1.3049  decode.d1.loss_cls: 0.0879  decode.d1.loss_mask: 0.5501  decode.d1.loss_dice: 1.2510  decode.d2.loss_cls: 0.0774  decode.d2.loss_mask: 0.5453  decode.d2.loss_dice: 1.2275  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.5474  decode.d3.loss_dice: 1.2086  decode.d4.loss_cls: 0.0697  decode.d4.loss_mask: 0.5488  decode.d4.loss_dice: 1.1832  decode.d5.loss_cls: 0.0713  decode.d5.loss_mask: 0.5418  decode.d5.loss_dice: 1.2079  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.5480  decode.d6.loss_dice: 1.1963  decode.d7.loss_cls: 0.0607  decode.d7.loss_mask: 0.5441  decode.d7.loss_dice: 1.2186  decode.d8.loss_cls: 0.0645  decode.d8.loss_mask: 0.5472  decode.d8.loss_dice: 1.2182
11/15 12:05:12 - mmengine - INFO - Iter(train) [30150/90000]  base_lr: 6.9270e-05 lr: 6.9270e-06  eta: 10:03:09  time: 0.6004  data_time: 0.0101  memory: 10692  grad_norm: 428.9348  loss: 18.9828  decode.loss_cls: 0.0909  decode.loss_mask: 0.6041  decode.loss_dice: 1.2088  decode.d0.loss_cls: 0.1198  decode.d0.loss_mask: 0.6227  decode.d0.loss_dice: 1.2408  decode.d1.loss_cls: 0.1287  decode.d1.loss_mask: 0.5911  decode.d1.loss_dice: 1.1763  decode.d2.loss_cls: 0.1234  decode.d2.loss_mask: 0.5981  decode.d2.loss_dice: 1.1788  decode.d3.loss_cls: 0.1178  decode.d3.loss_mask: 0.5958  decode.d3.loss_dice: 1.1469  decode.d4.loss_cls: 0.1308  decode.d4.loss_mask: 0.5942  decode.d4.loss_dice: 1.1686  decode.d5.loss_cls: 0.1170  decode.d5.loss_mask: 0.5904  decode.d5.loss_dice: 1.1514  decode.d6.loss_cls: 0.1282  decode.d6.loss_mask: 0.5883  decode.d6.loss_dice: 1.1446  decode.d7.loss_cls: 0.1082  decode.d7.loss_mask: 0.6007  decode.d7.loss_dice: 1.2373  decode.d8.loss_cls: 0.0980  decode.d8.loss_mask: 0.5864  decode.d8.loss_dice: 1.1946
11/15 12:05:45 - mmengine - INFO - Iter(train) [30200/90000]  base_lr: 6.9218e-05 lr: 6.9218e-06  eta: 10:02:42  time: 0.7989  data_time: 0.0102  memory: 10692  grad_norm: 663.1280  loss: 19.3772  decode.loss_cls: 0.0785  decode.loss_mask: 0.6088  decode.loss_dice: 1.2259  decode.d0.loss_cls: 0.0996  decode.d0.loss_mask: 0.6927  decode.d0.loss_dice: 1.2380  decode.d1.loss_cls: 0.0772  decode.d1.loss_mask: 0.6306  decode.d1.loss_dice: 1.2433  decode.d2.loss_cls: 0.0835  decode.d2.loss_mask: 0.6618  decode.d2.loss_dice: 1.2707  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.6496  decode.d3.loss_dice: 1.2239  decode.d4.loss_cls: 0.0916  decode.d4.loss_mask: 0.6146  decode.d4.loss_dice: 1.2195  decode.d5.loss_cls: 0.0905  decode.d5.loss_mask: 0.6096  decode.d5.loss_dice: 1.1977  decode.d6.loss_cls: 0.0870  decode.d6.loss_mask: 0.6281  decode.d6.loss_dice: 1.1778  decode.d7.loss_cls: 0.0699  decode.d7.loss_mask: 0.6223  decode.d7.loss_dice: 1.2122  decode.d8.loss_cls: 0.0884  decode.d8.loss_mask: 0.6156  decode.d8.loss_dice: 1.1934
11/15 12:06:14 - mmengine - INFO - Iter(train) [30250/90000]  base_lr: 6.9166e-05 lr: 6.9166e-06  eta: 10:02:11  time: 0.5991  data_time: 0.0101  memory: 10692  grad_norm: 356.7159  loss: 16.2339  decode.loss_cls: 0.1008  decode.loss_mask: 0.4322  decode.loss_dice: 1.0581  decode.d0.loss_cls: 0.0898  decode.d0.loss_mask: 0.4387  decode.d0.loss_dice: 1.2093  decode.d1.loss_cls: 0.0768  decode.d1.loss_mask: 0.4389  decode.d1.loss_dice: 1.1644  decode.d2.loss_cls: 0.0991  decode.d2.loss_mask: 0.4254  decode.d2.loss_dice: 1.1106  decode.d3.loss_cls: 0.1013  decode.d3.loss_mask: 0.4216  decode.d3.loss_dice: 1.0793  decode.d4.loss_cls: 0.0899  decode.d4.loss_mask: 0.4336  decode.d4.loss_dice: 1.0854  decode.d5.loss_cls: 0.0891  decode.d5.loss_mask: 0.4284  decode.d5.loss_dice: 1.0942  decode.d6.loss_cls: 0.0860  decode.d6.loss_mask: 0.4376  decode.d6.loss_dice: 1.0628  decode.d7.loss_cls: 0.0978  decode.d7.loss_mask: 0.4389  decode.d7.loss_dice: 1.0745  decode.d8.loss_cls: 0.0909  decode.d8.loss_mask: 0.4307  decode.d8.loss_dice: 1.0478
11/15 12:06:44 - mmengine - INFO - Iter(train) [30300/90000]  base_lr: 6.9114e-05 lr: 6.9114e-06  eta: 10:01:40  time: 0.5993  data_time: 0.0117  memory: 10675  grad_norm: 261.4392  loss: 17.2337  decode.loss_cls: 0.0665  decode.loss_mask: 0.5299  decode.loss_dice: 1.1044  decode.d0.loss_cls: 0.0750  decode.d0.loss_mask: 0.5499  decode.d0.loss_dice: 1.1700  decode.d1.loss_cls: 0.0696  decode.d1.loss_mask: 0.5370  decode.d1.loss_dice: 1.1156  decode.d2.loss_cls: 0.0609  decode.d2.loss_mask: 0.5435  decode.d2.loss_dice: 1.1309  decode.d3.loss_cls: 0.0599  decode.d3.loss_mask: 0.5410  decode.d3.loss_dice: 1.0878  decode.d4.loss_cls: 0.0600  decode.d4.loss_mask: 0.5383  decode.d4.loss_dice: 1.1222  decode.d5.loss_cls: 0.0604  decode.d5.loss_mask: 0.5308  decode.d5.loss_dice: 1.1297  decode.d6.loss_cls: 0.0643  decode.d6.loss_mask: 0.5357  decode.d6.loss_dice: 1.1134  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.5372  decode.d7.loss_dice: 1.1255  decode.d8.loss_cls: 0.0780  decode.d8.loss_mask: 0.5330  decode.d8.loss_dice: 1.0950
11/15 12:07:14 - mmengine - INFO - Iter(train) [30350/90000]  base_lr: 6.9061e-05 lr: 6.9061e-06  eta: 10:01:09  time: 0.5985  data_time: 0.0101  memory: 10675  grad_norm: 463.2093  loss: 16.9489  decode.loss_cls: 0.0695  decode.loss_mask: 0.5434  decode.loss_dice: 1.0699  decode.d0.loss_cls: 0.0824  decode.d0.loss_mask: 0.5846  decode.d0.loss_dice: 1.0928  decode.d1.loss_cls: 0.0645  decode.d1.loss_mask: 0.5493  decode.d1.loss_dice: 1.0811  decode.d2.loss_cls: 0.0693  decode.d2.loss_mask: 0.5145  decode.d2.loss_dice: 1.0624  decode.d3.loss_cls: 0.0704  decode.d3.loss_mask: 0.5442  decode.d3.loss_dice: 1.0709  decode.d4.loss_cls: 0.0818  decode.d4.loss_mask: 0.5326  decode.d4.loss_dice: 1.0726  decode.d5.loss_cls: 0.0726  decode.d5.loss_mask: 0.5410  decode.d5.loss_dice: 1.0642  decode.d6.loss_cls: 0.0723  decode.d6.loss_mask: 0.5455  decode.d6.loss_dice: 1.0674  decode.d7.loss_cls: 0.0840  decode.d7.loss_mask: 0.5485  decode.d7.loss_dice: 1.1058  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.5503  decode.d8.loss_dice: 1.0747
11/15 12:07:44 - mmengine - INFO - Iter(train) [30400/90000]  base_lr: 6.9009e-05 lr: 6.9009e-06  eta: 10:00:38  time: 0.5972  data_time: 0.0100  memory: 10713  grad_norm: 318.2619  loss: 16.3462  decode.loss_cls: 0.0675  decode.loss_mask: 0.4994  decode.loss_dice: 1.0532  decode.d0.loss_cls: 0.1061  decode.d0.loss_mask: 0.5223  decode.d0.loss_dice: 1.0890  decode.d1.loss_cls: 0.0773  decode.d1.loss_mask: 0.5096  decode.d1.loss_dice: 1.0727  decode.d2.loss_cls: 0.0674  decode.d2.loss_mask: 0.5024  decode.d2.loss_dice: 1.0568  decode.d3.loss_cls: 0.0624  decode.d3.loss_mask: 0.5053  decode.d3.loss_dice: 1.0514  decode.d4.loss_cls: 0.0572  decode.d4.loss_mask: 0.5058  decode.d4.loss_dice: 1.0422  decode.d5.loss_cls: 0.0568  decode.d5.loss_mask: 0.5119  decode.d5.loss_dice: 1.0496  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.5182  decode.d6.loss_dice: 1.0651  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 0.5034  decode.d7.loss_dice: 1.0418  decode.d8.loss_cls: 0.0701  decode.d8.loss_mask: 0.4960  decode.d8.loss_dice: 1.0624
11/15 12:08:14 - mmengine - INFO - Iter(train) [30450/90000]  base_lr: 6.8957e-05 lr: 6.8957e-06  eta: 10:00:07  time: 0.5975  data_time: 0.0100  memory: 10641  grad_norm: 359.3972  loss: 17.0710  decode.loss_cls: 0.0795  decode.loss_mask: 0.4962  decode.loss_dice: 1.1176  decode.d0.loss_cls: 0.0853  decode.d0.loss_mask: 0.5102  decode.d0.loss_dice: 1.2361  decode.d1.loss_cls: 0.0925  decode.d1.loss_mask: 0.5063  decode.d1.loss_dice: 1.1067  decode.d2.loss_cls: 0.0804  decode.d2.loss_mask: 0.4942  decode.d2.loss_dice: 1.1082  decode.d3.loss_cls: 0.0709  decode.d3.loss_mask: 0.4971  decode.d3.loss_dice: 1.1162  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.4918  decode.d4.loss_dice: 1.0977  decode.d5.loss_cls: 0.0775  decode.d5.loss_mask: 0.4866  decode.d5.loss_dice: 1.1528  decode.d6.loss_cls: 0.0824  decode.d6.loss_mask: 0.4851  decode.d6.loss_dice: 1.1014  decode.d7.loss_cls: 0.0730  decode.d7.loss_mask: 0.4919  decode.d7.loss_dice: 1.1636  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.4791  decode.d8.loss_dice: 1.1352
11/15 12:08:44 - mmengine - INFO - Iter(train) [30500/90000]  base_lr: 6.8905e-05 lr: 6.8905e-06  eta: 9:59:37  time: 0.5972  data_time: 0.0101  memory: 10656  grad_norm: 390.9883  loss: 19.1733  decode.loss_cls: 0.0912  decode.loss_mask: 0.6324  decode.loss_dice: 1.1615  decode.d0.loss_cls: 0.1028  decode.d0.loss_mask: 0.6669  decode.d0.loss_dice: 1.2933  decode.d1.loss_cls: 0.0814  decode.d1.loss_mask: 0.6414  decode.d1.loss_dice: 1.2543  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 0.6277  decode.d2.loss_dice: 1.2114  decode.d3.loss_cls: 0.0898  decode.d3.loss_mask: 0.6324  decode.d3.loss_dice: 1.1648  decode.d4.loss_cls: 0.0834  decode.d4.loss_mask: 0.6425  decode.d4.loss_dice: 1.1769  decode.d5.loss_cls: 0.0734  decode.d5.loss_mask: 0.6313  decode.d5.loss_dice: 1.1911  decode.d6.loss_cls: 0.0835  decode.d6.loss_mask: 0.6469  decode.d6.loss_dice: 1.1445  decode.d7.loss_cls: 0.0737  decode.d7.loss_mask: 0.6303  decode.d7.loss_dice: 1.1638  decode.d8.loss_cls: 0.0943  decode.d8.loss_mask: 0.6331  decode.d8.loss_dice: 1.1880
11/15 12:09:14 - mmengine - INFO - Iter(train) [30550/90000]  base_lr: 6.8853e-05 lr: 6.8853e-06  eta: 9:59:06  time: 0.5988  data_time: 0.0101  memory: 10692  grad_norm: 398.5196  loss: 19.5523  decode.loss_cls: 0.0784  decode.loss_mask: 0.5758  decode.loss_dice: 1.2902  decode.d0.loss_cls: 0.0806  decode.d0.loss_mask: 0.6004  decode.d0.loss_dice: 1.3586  decode.d1.loss_cls: 0.0720  decode.d1.loss_mask: 0.5850  decode.d1.loss_dice: 1.2914  decode.d2.loss_cls: 0.0689  decode.d2.loss_mask: 0.5822  decode.d2.loss_dice: 1.3087  decode.d3.loss_cls: 0.0693  decode.d3.loss_mask: 0.5823  decode.d3.loss_dice: 1.2760  decode.d4.loss_cls: 0.0668  decode.d4.loss_mask: 0.5837  decode.d4.loss_dice: 1.2806  decode.d5.loss_cls: 0.0811  decode.d5.loss_mask: 0.5832  decode.d5.loss_dice: 1.3017  decode.d6.loss_cls: 0.0738  decode.d6.loss_mask: 0.5770  decode.d6.loss_dice: 1.2946  decode.d7.loss_cls: 0.0823  decode.d7.loss_mask: 0.5791  decode.d7.loss_dice: 1.2830  decode.d8.loss_cls: 0.0831  decode.d8.loss_mask: 0.5740  decode.d8.loss_dice: 1.2885
11/15 12:09:44 - mmengine - INFO - Iter(train) [30600/90000]  base_lr: 6.8801e-05 lr: 6.8801e-06  eta: 9:58:35  time: 0.5973  data_time: 0.0101  memory: 10675  grad_norm: 289.3568  loss: 20.8694  decode.loss_cls: 0.0968  decode.loss_mask: 0.5922  decode.loss_dice: 1.3926  decode.d0.loss_cls: 0.1108  decode.d0.loss_mask: 0.6042  decode.d0.loss_dice: 1.4640  decode.d1.loss_cls: 0.0992  decode.d1.loss_mask: 0.6115  decode.d1.loss_dice: 1.3949  decode.d2.loss_cls: 0.0846  decode.d2.loss_mask: 0.6154  decode.d2.loss_dice: 1.3747  decode.d3.loss_cls: 0.0904  decode.d3.loss_mask: 0.6175  decode.d3.loss_dice: 1.3902  decode.d4.loss_cls: 0.0882  decode.d4.loss_mask: 0.5962  decode.d4.loss_dice: 1.3867  decode.d5.loss_cls: 0.0942  decode.d5.loss_mask: 0.5800  decode.d5.loss_dice: 1.3966  decode.d6.loss_cls: 0.0861  decode.d6.loss_mask: 0.5919  decode.d6.loss_dice: 1.4000  decode.d7.loss_cls: 0.0957  decode.d7.loss_mask: 0.5766  decode.d7.loss_dice: 1.3678  decode.d8.loss_cls: 0.1008  decode.d8.loss_mask: 0.5943  decode.d8.loss_dice: 1.3754
11/15 12:10:14 - mmengine - INFO - Iter(train) [30650/90000]  base_lr: 6.8749e-05 lr: 6.8749e-06  eta: 9:58:04  time: 0.6090  data_time: 0.0101  memory: 10656  grad_norm: 407.3634  loss: 18.7906  decode.loss_cls: 0.0579  decode.loss_mask: 0.6202  decode.loss_dice: 1.1583  decode.d0.loss_cls: 0.0800  decode.d0.loss_mask: 0.6415  decode.d0.loss_dice: 1.2458  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.6760  decode.d1.loss_dice: 1.1891  decode.d2.loss_cls: 0.0688  decode.d2.loss_mask: 0.6466  decode.d2.loss_dice: 1.1597  decode.d3.loss_cls: 0.0574  decode.d3.loss_mask: 0.6364  decode.d3.loss_dice: 1.1431  decode.d4.loss_cls: 0.0572  decode.d4.loss_mask: 0.6750  decode.d4.loss_dice: 1.1639  decode.d5.loss_cls: 0.0603  decode.d5.loss_mask: 0.6640  decode.d5.loss_dice: 1.1581  decode.d6.loss_cls: 0.0679  decode.d6.loss_mask: 0.6023  decode.d6.loss_dice: 1.1754  decode.d7.loss_cls: 0.0569  decode.d7.loss_mask: 0.6150  decode.d7.loss_dice: 1.1724  decode.d8.loss_cls: 0.0592  decode.d8.loss_mask: 0.6303  decode.d8.loss_dice: 1.1830
11/15 12:10:44 - mmengine - INFO - Iter(train) [30700/90000]  base_lr: 6.8697e-05 lr: 6.8697e-06  eta: 9:57:33  time: 0.5967  data_time: 0.0100  memory: 10713  grad_norm: 567.2760  loss: 18.9951  decode.loss_cls: 0.0759  decode.loss_mask: 0.5871  decode.loss_dice: 1.2438  decode.d0.loss_cls: 0.0802  decode.d0.loss_mask: 0.6039  decode.d0.loss_dice: 1.2982  decode.d1.loss_cls: 0.0732  decode.d1.loss_mask: 0.5808  decode.d1.loss_dice: 1.2784  decode.d2.loss_cls: 0.0906  decode.d2.loss_mask: 0.5783  decode.d2.loss_dice: 1.2135  decode.d3.loss_cls: 0.0719  decode.d3.loss_mask: 0.5903  decode.d3.loss_dice: 1.2167  decode.d4.loss_cls: 0.0773  decode.d4.loss_mask: 0.5768  decode.d4.loss_dice: 1.2140  decode.d5.loss_cls: 0.0724  decode.d5.loss_mask: 0.5915  decode.d5.loss_dice: 1.2188  decode.d6.loss_cls: 0.0785  decode.d6.loss_mask: 0.5871  decode.d6.loss_dice: 1.1898  decode.d7.loss_cls: 0.0671  decode.d7.loss_mask: 0.5985  decode.d7.loss_dice: 1.2306  decode.d8.loss_cls: 0.0640  decode.d8.loss_mask: 0.5921  decode.d8.loss_dice: 1.2536
11/15 12:11:14 - mmengine - INFO - Iter(train) [30750/90000]  base_lr: 6.8644e-05 lr: 6.8644e-06  eta: 9:57:02  time: 0.5984  data_time: 0.0102  memory: 10656  grad_norm: 285.1265  loss: 16.9592  decode.loss_cls: 0.0802  decode.loss_mask: 0.4816  decode.loss_dice: 1.1248  decode.d0.loss_cls: 0.1011  decode.d0.loss_mask: 0.4942  decode.d0.loss_dice: 1.1303  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.4851  decode.d1.loss_dice: 1.1229  decode.d2.loss_cls: 0.0826  decode.d2.loss_mask: 0.4871  decode.d2.loss_dice: 1.1116  decode.d3.loss_cls: 0.0797  decode.d3.loss_mask: 0.4849  decode.d3.loss_dice: 1.1171  decode.d4.loss_cls: 0.0867  decode.d4.loss_mask: 0.5005  decode.d4.loss_dice: 1.1209  decode.d5.loss_cls: 0.0804  decode.d5.loss_mask: 0.4881  decode.d5.loss_dice: 1.1136  decode.d6.loss_cls: 0.0828  decode.d6.loss_mask: 0.4929  decode.d6.loss_dice: 1.1125  decode.d7.loss_cls: 0.1009  decode.d7.loss_mask: 0.4849  decode.d7.loss_dice: 1.1268  decode.d8.loss_cls: 0.0934  decode.d8.loss_mask: 0.4844  decode.d8.loss_dice: 1.1250
11/15 12:11:44 - mmengine - INFO - Iter(train) [30800/90000]  base_lr: 6.8592e-05 lr: 6.8592e-06  eta: 9:56:32  time: 0.6039  data_time: 0.0104  memory: 10656  grad_norm: 403.1326  loss: 18.9436  decode.loss_cls: 0.0646  decode.loss_mask: 0.5625  decode.loss_dice: 1.2686  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.5908  decode.d0.loss_dice: 1.3671  decode.d1.loss_cls: 0.0762  decode.d1.loss_mask: 0.5298  decode.d1.loss_dice: 1.2719  decode.d2.loss_cls: 0.0571  decode.d2.loss_mask: 0.5461  decode.d2.loss_dice: 1.2648  decode.d3.loss_cls: 0.0739  decode.d3.loss_mask: 0.5427  decode.d3.loss_dice: 1.2323  decode.d4.loss_cls: 0.0661  decode.d4.loss_mask: 0.5540  decode.d4.loss_dice: 1.2521  decode.d5.loss_cls: 0.0673  decode.d5.loss_mask: 0.5355  decode.d5.loss_dice: 1.2545  decode.d6.loss_cls: 0.0625  decode.d6.loss_mask: 0.5500  decode.d6.loss_dice: 1.2705  decode.d7.loss_cls: 0.0563  decode.d7.loss_mask: 0.5555  decode.d7.loss_dice: 1.3022  decode.d8.loss_cls: 0.0626  decode.d8.loss_mask: 0.5450  decode.d8.loss_dice: 1.2827
11/15 12:12:14 - mmengine - INFO - Iter(train) [30850/90000]  base_lr: 6.8540e-05 lr: 6.8540e-06  eta: 9:56:01  time: 0.6042  data_time: 0.0105  memory: 10692  grad_norm: 309.9812  loss: 17.7860  decode.loss_cls: 0.0543  decode.loss_mask: 0.5857  decode.loss_dice: 1.1208  decode.d0.loss_cls: 0.0731  decode.d0.loss_mask: 0.6079  decode.d0.loss_dice: 1.1952  decode.d1.loss_cls: 0.0614  decode.d1.loss_mask: 0.5805  decode.d1.loss_dice: 1.1392  decode.d2.loss_cls: 0.0570  decode.d2.loss_mask: 0.5944  decode.d2.loss_dice: 1.1388  decode.d3.loss_cls: 0.0539  decode.d3.loss_mask: 0.5952  decode.d3.loss_dice: 1.1092  decode.d4.loss_cls: 0.0588  decode.d4.loss_mask: 0.5967  decode.d4.loss_dice: 1.1126  decode.d5.loss_cls: 0.0635  decode.d5.loss_mask: 0.5970  decode.d5.loss_dice: 1.1195  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.5852  decode.d6.loss_dice: 1.1197  decode.d7.loss_cls: 0.0600  decode.d7.loss_mask: 0.5855  decode.d7.loss_dice: 1.1064  decode.d8.loss_cls: 0.0534  decode.d8.loss_mask: 0.5876  decode.d8.loss_dice: 1.1189
11/15 12:12:44 - mmengine - INFO - Iter(train) [30900/90000]  base_lr: 6.8488e-05 lr: 6.8488e-06  eta: 9:55:31  time: 0.6020  data_time: 0.0105  memory: 10675  grad_norm: 462.5235  loss: 18.0624  decode.loss_cls: 0.0551  decode.loss_mask: 0.5153  decode.loss_dice: 1.2229  decode.d0.loss_cls: 0.0925  decode.d0.loss_mask: 0.5255  decode.d0.loss_dice: 1.2537  decode.d1.loss_cls: 0.0489  decode.d1.loss_mask: 0.5181  decode.d1.loss_dice: 1.2385  decode.d2.loss_cls: 0.0536  decode.d2.loss_mask: 0.5218  decode.d2.loss_dice: 1.2439  decode.d3.loss_cls: 0.0551  decode.d3.loss_mask: 0.5194  decode.d3.loss_dice: 1.2313  decode.d4.loss_cls: 0.0470  decode.d4.loss_mask: 0.5086  decode.d4.loss_dice: 1.2295  decode.d5.loss_cls: 0.0431  decode.d5.loss_mask: 0.5180  decode.d5.loss_dice: 1.2394  decode.d6.loss_cls: 0.0507  decode.d6.loss_mask: 0.5200  decode.d6.loss_dice: 1.2319  decode.d7.loss_cls: 0.0586  decode.d7.loss_mask: 0.5086  decode.d7.loss_dice: 1.2168  decode.d8.loss_cls: 0.0658  decode.d8.loss_mask: 0.5107  decode.d8.loss_dice: 1.2181
11/15 12:13:14 - mmengine - INFO - Iter(train) [30950/90000]  base_lr: 6.8436e-05 lr: 6.8436e-06  eta: 9:55:01  time: 0.6012  data_time: 0.0102  memory: 10656  grad_norm: 350.5281  loss: 19.4774  decode.loss_cls: 0.0601  decode.loss_mask: 0.6159  decode.loss_dice: 1.2459  decode.d0.loss_cls: 0.0673  decode.d0.loss_mask: 0.6272  decode.d0.loss_dice: 1.3353  decode.d1.loss_cls: 0.0454  decode.d1.loss_mask: 0.6081  decode.d1.loss_dice: 1.2858  decode.d2.loss_cls: 0.0803  decode.d2.loss_mask: 0.6120  decode.d2.loss_dice: 1.2492  decode.d3.loss_cls: 0.0730  decode.d3.loss_mask: 0.6096  decode.d3.loss_dice: 1.2744  decode.d4.loss_cls: 0.0816  decode.d4.loss_mask: 0.6070  decode.d4.loss_dice: 1.2500  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.6133  decode.d5.loss_dice: 1.2734  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.6044  decode.d6.loss_dice: 1.2562  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.6167  decode.d7.loss_dice: 1.2588  decode.d8.loss_cls: 0.0613  decode.d8.loss_mask: 0.6175  decode.d8.loss_dice: 1.2652
11/15 12:13:44 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 12:13:44 - mmengine - INFO - Iter(train) [31000/90000]  base_lr: 6.8384e-05 lr: 6.8384e-06  eta: 9:54:30  time: 0.6015  data_time: 0.0104  memory: 10692  grad_norm: 376.6660  loss: 17.6405  decode.loss_cls: 0.0426  decode.loss_mask: 0.5484  decode.loss_dice: 1.1774  decode.d0.loss_cls: 0.0681  decode.d0.loss_mask: 0.5327  decode.d0.loss_dice: 1.1915  decode.d1.loss_cls: 0.0525  decode.d1.loss_mask: 0.5451  decode.d1.loss_dice: 1.1872  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.5402  decode.d2.loss_dice: 1.1821  decode.d3.loss_cls: 0.0464  decode.d3.loss_mask: 0.5461  decode.d3.loss_dice: 1.1703  decode.d4.loss_cls: 0.0590  decode.d4.loss_mask: 0.5426  decode.d4.loss_dice: 1.1319  decode.d5.loss_cls: 0.0571  decode.d5.loss_mask: 0.5363  decode.d5.loss_dice: 1.1432  decode.d6.loss_cls: 0.0442  decode.d6.loss_mask: 0.5440  decode.d6.loss_dice: 1.1765  decode.d7.loss_cls: 0.0446  decode.d7.loss_mask: 0.5500  decode.d7.loss_dice: 1.1720  decode.d8.loss_cls: 0.0467  decode.d8.loss_mask: 0.5516  decode.d8.loss_dice: 1.1655
11/15 12:14:15 - mmengine - INFO - Iter(train) [31050/90000]  base_lr: 6.8332e-05 lr: 6.8332e-06  eta: 9:54:00  time: 0.6003  data_time: 0.0104  memory: 10641  grad_norm: 335.7853  loss: 17.8091  decode.loss_cls: 0.0577  decode.loss_mask: 0.5587  decode.loss_dice: 1.1347  decode.d0.loss_cls: 0.0821  decode.d0.loss_mask: 0.5563  decode.d0.loss_dice: 1.2180  decode.d1.loss_cls: 0.0541  decode.d1.loss_mask: 0.5552  decode.d1.loss_dice: 1.1894  decode.d2.loss_cls: 0.0633  decode.d2.loss_mask: 0.5565  decode.d2.loss_dice: 1.1491  decode.d3.loss_cls: 0.0508  decode.d3.loss_mask: 0.5682  decode.d3.loss_dice: 1.1477  decode.d4.loss_cls: 0.0528  decode.d4.loss_mask: 0.5550  decode.d4.loss_dice: 1.1618  decode.d5.loss_cls: 0.0386  decode.d5.loss_mask: 0.5798  decode.d5.loss_dice: 1.1824  decode.d6.loss_cls: 0.0540  decode.d6.loss_mask: 0.5525  decode.d6.loss_dice: 1.1438  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.5601  decode.d7.loss_dice: 1.1613  decode.d8.loss_cls: 0.0573  decode.d8.loss_mask: 0.5650  decode.d8.loss_dice: 1.1401
11/15 12:14:45 - mmengine - INFO - Iter(train) [31100/90000]  base_lr: 6.8279e-05 lr: 6.8279e-06  eta: 9:53:30  time: 0.6018  data_time: 0.0104  memory: 10641  grad_norm: 327.0445  loss: 19.4983  decode.loss_cls: 0.1003  decode.loss_mask: 0.5227  decode.loss_dice: 1.2979  decode.d0.loss_cls: 0.1003  decode.d0.loss_mask: 0.4968  decode.d0.loss_dice: 1.4427  decode.d1.loss_cls: 0.1041  decode.d1.loss_mask: 0.5054  decode.d1.loss_dice: 1.3341  decode.d2.loss_cls: 0.1059  decode.d2.loss_mask: 0.5291  decode.d2.loss_dice: 1.3452  decode.d3.loss_cls: 0.0810  decode.d3.loss_mask: 0.5248  decode.d3.loss_dice: 1.3555  decode.d4.loss_cls: 0.0892  decode.d4.loss_mask: 0.4998  decode.d4.loss_dice: 1.3037  decode.d5.loss_cls: 0.1084  decode.d5.loss_mask: 0.4942  decode.d5.loss_dice: 1.2893  decode.d6.loss_cls: 0.0920  decode.d6.loss_mask: 0.5367  decode.d6.loss_dice: 1.3276  decode.d7.loss_cls: 0.0984  decode.d7.loss_mask: 0.5323  decode.d7.loss_dice: 1.3319  decode.d8.loss_cls: 0.0837  decode.d8.loss_mask: 0.5204  decode.d8.loss_dice: 1.3448
11/15 12:15:15 - mmengine - INFO - Iter(train) [31150/90000]  base_lr: 6.8227e-05 lr: 6.8227e-06  eta: 9:52:59  time: 0.5982  data_time: 0.0099  memory: 10713  grad_norm: 296.1882  loss: 18.8441  decode.loss_cls: 0.0834  decode.loss_mask: 0.5222  decode.loss_dice: 1.2688  decode.d0.loss_cls: 0.0729  decode.d0.loss_mask: 0.5290  decode.d0.loss_dice: 1.3460  decode.d1.loss_cls: 0.0812  decode.d1.loss_mask: 0.5179  decode.d1.loss_dice: 1.2881  decode.d2.loss_cls: 0.0931  decode.d2.loss_mask: 0.5132  decode.d2.loss_dice: 1.2934  decode.d3.loss_cls: 0.0758  decode.d3.loss_mask: 0.5270  decode.d3.loss_dice: 1.2667  decode.d4.loss_cls: 0.0833  decode.d4.loss_mask: 0.5232  decode.d4.loss_dice: 1.2752  decode.d5.loss_cls: 0.0828  decode.d5.loss_mask: 0.5259  decode.d5.loss_dice: 1.2561  decode.d6.loss_cls: 0.0845  decode.d6.loss_mask: 0.5204  decode.d6.loss_dice: 1.2784  decode.d7.loss_cls: 0.0812  decode.d7.loss_mask: 0.5245  decode.d7.loss_dice: 1.2677  decode.d8.loss_cls: 0.0823  decode.d8.loss_mask: 0.5168  decode.d8.loss_dice: 1.2632
11/15 12:15:45 - mmengine - INFO - Iter(train) [31200/90000]  base_lr: 6.8175e-05 lr: 6.8175e-06  eta: 9:52:29  time: 0.5991  data_time: 0.0102  memory: 10692  grad_norm: 336.3132  loss: 20.0418  decode.loss_cls: 0.0700  decode.loss_mask: 0.5178  decode.loss_dice: 1.3908  decode.d0.loss_cls: 0.0809  decode.d0.loss_mask: 0.5394  decode.d0.loss_dice: 1.4757  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.5412  decode.d1.loss_dice: 1.4261  decode.d2.loss_cls: 0.0748  decode.d2.loss_mask: 0.5307  decode.d2.loss_dice: 1.3708  decode.d3.loss_cls: 0.0734  decode.d3.loss_mask: 0.5132  decode.d3.loss_dice: 1.3705  decode.d4.loss_cls: 0.0710  decode.d4.loss_mask: 0.5248  decode.d4.loss_dice: 1.3992  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.5236  decode.d5.loss_dice: 1.4129  decode.d6.loss_cls: 0.0674  decode.d6.loss_mask: 0.5239  decode.d6.loss_dice: 1.3820  decode.d7.loss_cls: 0.0695  decode.d7.loss_mask: 0.5285  decode.d7.loss_dice: 1.4185  decode.d8.loss_cls: 0.0793  decode.d8.loss_mask: 0.5146  decode.d8.loss_dice: 1.4284
11/15 12:16:15 - mmengine - INFO - Iter(train) [31250/90000]  base_lr: 6.8123e-05 lr: 6.8123e-06  eta: 9:51:58  time: 0.6013  data_time: 0.0102  memory: 10692  grad_norm: 1690.4973  loss: 18.0481  decode.loss_cls: 0.0819  decode.loss_mask: 0.6127  decode.loss_dice: 1.1274  decode.d0.loss_cls: 0.0916  decode.d0.loss_mask: 0.6135  decode.d0.loss_dice: 1.1789  decode.d1.loss_cls: 0.0993  decode.d1.loss_mask: 0.5830  decode.d1.loss_dice: 1.1079  decode.d2.loss_cls: 0.0993  decode.d2.loss_mask: 0.5744  decode.d2.loss_dice: 1.0952  decode.d3.loss_cls: 0.0860  decode.d3.loss_mask: 0.5989  decode.d3.loss_dice: 1.1297  decode.d4.loss_cls: 0.0884  decode.d4.loss_mask: 0.6080  decode.d4.loss_dice: 1.1007  decode.d5.loss_cls: 0.0907  decode.d5.loss_mask: 0.6000  decode.d5.loss_dice: 1.1089  decode.d6.loss_cls: 0.0937  decode.d6.loss_mask: 0.6004  decode.d6.loss_dice: 1.1254  decode.d7.loss_cls: 0.0831  decode.d7.loss_mask: 0.5829  decode.d7.loss_dice: 1.0848  decode.d8.loss_cls: 0.0910  decode.d8.loss_mask: 0.5869  decode.d8.loss_dice: 1.1235
11/15 12:16:45 - mmengine - INFO - Iter(train) [31300/90000]  base_lr: 6.8071e-05 lr: 6.8071e-06  eta: 9:51:28  time: 0.6015  data_time: 0.0104  memory: 10656  grad_norm: 545.8465  loss: 18.7704  decode.loss_cls: 0.0734  decode.loss_mask: 0.6012  decode.loss_dice: 1.1809  decode.d0.loss_cls: 0.0844  decode.d0.loss_mask: 0.6391  decode.d0.loss_dice: 1.3320  decode.d1.loss_cls: 0.0728  decode.d1.loss_mask: 0.6062  decode.d1.loss_dice: 1.2324  decode.d2.loss_cls: 0.0613  decode.d2.loss_mask: 0.6017  decode.d2.loss_dice: 1.2097  decode.d3.loss_cls: 0.0795  decode.d3.loss_mask: 0.5880  decode.d3.loss_dice: 1.1923  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.5812  decode.d4.loss_dice: 1.2209  decode.d5.loss_cls: 0.0766  decode.d5.loss_mask: 0.5785  decode.d5.loss_dice: 1.1670  decode.d6.loss_cls: 0.0681  decode.d6.loss_mask: 0.5790  decode.d6.loss_dice: 1.1629  decode.d7.loss_cls: 0.0658  decode.d7.loss_mask: 0.6028  decode.d7.loss_dice: 1.1896  decode.d8.loss_cls: 0.0705  decode.d8.loss_mask: 0.6021  decode.d8.loss_dice: 1.1899
11/15 12:17:15 - mmengine - INFO - Iter(train) [31350/90000]  base_lr: 6.8019e-05 lr: 6.8019e-06  eta: 9:50:57  time: 0.5994  data_time: 0.0100  memory: 10641  grad_norm: 400.0596  loss: 18.9624  decode.loss_cls: 0.0729  decode.loss_mask: 0.6795  decode.loss_dice: 1.1767  decode.d0.loss_cls: 0.0771  decode.d0.loss_mask: 0.7168  decode.d0.loss_dice: 1.2013  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.6327  decode.d1.loss_dice: 1.1579  decode.d2.loss_cls: 0.0649  decode.d2.loss_mask: 0.6356  decode.d2.loss_dice: 1.1697  decode.d3.loss_cls: 0.0618  decode.d3.loss_mask: 0.6542  decode.d3.loss_dice: 1.1593  decode.d4.loss_cls: 0.0586  decode.d4.loss_mask: 0.6907  decode.d4.loss_dice: 1.1555  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 0.6927  decode.d5.loss_dice: 1.1763  decode.d6.loss_cls: 0.0611  decode.d6.loss_mask: 0.6710  decode.d6.loss_dice: 1.1418  decode.d7.loss_cls: 0.0686  decode.d7.loss_mask: 0.6374  decode.d7.loss_dice: 1.1240  decode.d8.loss_cls: 0.0666  decode.d8.loss_mask: 0.6674  decode.d8.loss_dice: 1.1434
11/15 12:17:45 - mmengine - INFO - Iter(train) [31400/90000]  base_lr: 6.7966e-05 lr: 6.7966e-06  eta: 9:50:26  time: 0.5963  data_time: 0.0100  memory: 10692  grad_norm: 474.2208  loss: 17.5192  decode.loss_cls: 0.0617  decode.loss_mask: 0.5670  decode.loss_dice: 1.1026  decode.d0.loss_cls: 0.0857  decode.d0.loss_mask: 0.5899  decode.d0.loss_dice: 1.1453  decode.d1.loss_cls: 0.0661  decode.d1.loss_mask: 0.5522  decode.d1.loss_dice: 1.1399  decode.d2.loss_cls: 0.0671  decode.d2.loss_mask: 0.5670  decode.d2.loss_dice: 1.1397  decode.d3.loss_cls: 0.0630  decode.d3.loss_mask: 0.5556  decode.d3.loss_dice: 1.1093  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 0.5638  decode.d4.loss_dice: 1.1160  decode.d5.loss_cls: 0.0689  decode.d5.loss_mask: 0.5587  decode.d5.loss_dice: 1.1053  decode.d6.loss_cls: 0.0620  decode.d6.loss_mask: 0.5620  decode.d6.loss_dice: 1.1023  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 0.5609  decode.d7.loss_dice: 1.1339  decode.d8.loss_cls: 0.0679  decode.d8.loss_mask: 0.5585  decode.d8.loss_dice: 1.1308
11/15 12:18:15 - mmengine - INFO - Iter(train) [31450/90000]  base_lr: 6.7914e-05 lr: 6.7914e-06  eta: 9:49:55  time: 0.5966  data_time: 0.0100  memory: 10675  grad_norm: 317.5191  loss: 17.5627  decode.loss_cls: 0.0688  decode.loss_mask: 0.5843  decode.loss_dice: 1.1018  decode.d0.loss_cls: 0.0913  decode.d0.loss_mask: 0.5939  decode.d0.loss_dice: 1.1747  decode.d1.loss_cls: 0.0734  decode.d1.loss_mask: 0.5845  decode.d1.loss_dice: 1.1333  decode.d2.loss_cls: 0.0632  decode.d2.loss_mask: 0.5775  decode.d2.loss_dice: 1.1223  decode.d3.loss_cls: 0.0579  decode.d3.loss_mask: 0.5702  decode.d3.loss_dice: 1.1012  decode.d4.loss_cls: 0.0664  decode.d4.loss_mask: 0.5608  decode.d4.loss_dice: 1.1110  decode.d5.loss_cls: 0.0580  decode.d5.loss_mask: 0.5721  decode.d5.loss_dice: 1.1164  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.5822  decode.d6.loss_dice: 1.0938  decode.d7.loss_cls: 0.0675  decode.d7.loss_mask: 0.5664  decode.d7.loss_dice: 1.0871  decode.d8.loss_cls: 0.0542  decode.d8.loss_mask: 0.5684  decode.d8.loss_dice: 1.0974
11/15 12:18:44 - mmengine - INFO - Iter(train) [31500/90000]  base_lr: 6.7862e-05 lr: 6.7862e-06  eta: 9:49:24  time: 0.5961  data_time: 0.0099  memory: 10656  grad_norm: 1209.1241  loss: 16.8183  decode.loss_cls: 0.0489  decode.loss_mask: 0.5840  decode.loss_dice: 1.0570  decode.d0.loss_cls: 0.0839  decode.d0.loss_mask: 0.5813  decode.d0.loss_dice: 1.0821  decode.d1.loss_cls: 0.0531  decode.d1.loss_mask: 0.5815  decode.d1.loss_dice: 1.0530  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.5792  decode.d2.loss_dice: 1.0362  decode.d3.loss_cls: 0.0440  decode.d3.loss_mask: 0.5936  decode.d3.loss_dice: 1.0362  decode.d4.loss_cls: 0.0490  decode.d4.loss_mask: 0.5892  decode.d4.loss_dice: 1.0328  decode.d5.loss_cls: 0.0422  decode.d5.loss_mask: 0.5949  decode.d5.loss_dice: 1.0464  decode.d6.loss_cls: 0.0393  decode.d6.loss_mask: 0.5901  decode.d6.loss_dice: 1.0488  decode.d7.loss_cls: 0.0438  decode.d7.loss_mask: 0.5740  decode.d7.loss_dice: 1.0401  decode.d8.loss_cls: 0.0468  decode.d8.loss_mask: 0.5758  decode.d8.loss_dice: 1.0368
11/15 12:19:14 - mmengine - INFO - Iter(train) [31550/90000]  base_lr: 6.7810e-05 lr: 6.7810e-06  eta: 9:48:53  time: 0.6012  data_time: 0.0103  memory: 10692  grad_norm: 537.5202  loss: 18.6950  decode.loss_cls: 0.0652  decode.loss_mask: 0.6459  decode.loss_dice: 1.1596  decode.d0.loss_cls: 0.0954  decode.d0.loss_mask: 0.6665  decode.d0.loss_dice: 1.1901  decode.d1.loss_cls: 0.0745  decode.d1.loss_mask: 0.6548  decode.d1.loss_dice: 1.1507  decode.d2.loss_cls: 0.0781  decode.d2.loss_mask: 0.6229  decode.d2.loss_dice: 1.1388  decode.d3.loss_cls: 0.0626  decode.d3.loss_mask: 0.6395  decode.d3.loss_dice: 1.1596  decode.d4.loss_cls: 0.0636  decode.d4.loss_mask: 0.6255  decode.d4.loss_dice: 1.1539  decode.d5.loss_cls: 0.0611  decode.d5.loss_mask: 0.6377  decode.d5.loss_dice: 1.1521  decode.d6.loss_cls: 0.0595  decode.d6.loss_mask: 0.6602  decode.d6.loss_dice: 1.1552  decode.d7.loss_cls: 0.0572  decode.d7.loss_mask: 0.6474  decode.d7.loss_dice: 1.1531  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 0.6600  decode.d8.loss_dice: 1.1424
11/15 12:19:45 - mmengine - INFO - Iter(train) [31600/90000]  base_lr: 6.7758e-05 lr: 6.7758e-06  eta: 9:48:23  time: 0.6024  data_time: 0.0101  memory: 10713  grad_norm: 770.1192  loss: 19.4908  decode.loss_cls: 0.0471  decode.loss_mask: 0.6682  decode.loss_dice: 1.1894  decode.d0.loss_cls: 0.0904  decode.d0.loss_mask: 0.7327  decode.d0.loss_dice: 1.2840  decode.d1.loss_cls: 0.0781  decode.d1.loss_mask: 0.6593  decode.d1.loss_dice: 1.2289  decode.d2.loss_cls: 0.0571  decode.d2.loss_mask: 0.6677  decode.d2.loss_dice: 1.2303  decode.d3.loss_cls: 0.0585  decode.d3.loss_mask: 0.6749  decode.d3.loss_dice: 1.1960  decode.d4.loss_cls: 0.0768  decode.d4.loss_mask: 0.6613  decode.d4.loss_dice: 1.1917  decode.d5.loss_cls: 0.0659  decode.d5.loss_mask: 0.6760  decode.d5.loss_dice: 1.1756  decode.d6.loss_cls: 0.0577  decode.d6.loss_mask: 0.6555  decode.d6.loss_dice: 1.1847  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.6609  decode.d7.loss_dice: 1.1995  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.6796  decode.d8.loss_dice: 1.2191
11/15 12:20:15 - mmengine - INFO - Iter(train) [31650/90000]  base_lr: 6.7705e-05 lr: 6.7705e-06  eta: 9:47:53  time: 0.6014  data_time: 0.0102  memory: 10692  grad_norm: 335.8523  loss: 15.4625  decode.loss_cls: 0.0311  decode.loss_mask: 0.5499  decode.loss_dice: 0.9548  decode.d0.loss_cls: 0.0586  decode.d0.loss_mask: 0.5631  decode.d0.loss_dice: 0.9850  decode.d1.loss_cls: 0.0340  decode.d1.loss_mask: 0.5554  decode.d1.loss_dice: 0.9722  decode.d2.loss_cls: 0.0310  decode.d2.loss_mask: 0.5500  decode.d2.loss_dice: 0.9563  decode.d3.loss_cls: 0.0231  decode.d3.loss_mask: 0.5525  decode.d3.loss_dice: 0.9718  decode.d4.loss_cls: 0.0293  decode.d4.loss_mask: 0.5544  decode.d4.loss_dice: 0.9787  decode.d5.loss_cls: 0.0360  decode.d5.loss_mask: 0.5363  decode.d5.loss_dice: 0.9504  decode.d6.loss_cls: 0.0338  decode.d6.loss_mask: 0.5475  decode.d6.loss_dice: 0.9380  decode.d7.loss_cls: 0.0307  decode.d7.loss_mask: 0.5478  decode.d7.loss_dice: 0.9630  decode.d8.loss_cls: 0.0278  decode.d8.loss_mask: 0.5463  decode.d8.loss_dice: 0.9537
11/15 12:20:45 - mmengine - INFO - Iter(train) [31700/90000]  base_lr: 6.7653e-05 lr: 6.7653e-06  eta: 9:47:23  time: 0.6023  data_time: 0.0103  memory: 10713  grad_norm: 358.8542  loss: 17.4689  decode.loss_cls: 0.0728  decode.loss_mask: 0.4972  decode.loss_dice: 1.1041  decode.d0.loss_cls: 0.0826  decode.d0.loss_mask: 0.5657  decode.d0.loss_dice: 1.2024  decode.d1.loss_cls: 0.0653  decode.d1.loss_mask: 0.5212  decode.d1.loss_dice: 1.1813  decode.d2.loss_cls: 0.0747  decode.d2.loss_mask: 0.5199  decode.d2.loss_dice: 1.1531  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.5246  decode.d3.loss_dice: 1.1325  decode.d4.loss_cls: 0.0580  decode.d4.loss_mask: 0.5264  decode.d4.loss_dice: 1.1616  decode.d5.loss_cls: 0.0604  decode.d5.loss_mask: 0.5323  decode.d5.loss_dice: 1.1719  decode.d6.loss_cls: 0.0762  decode.d6.loss_mask: 0.5098  decode.d6.loss_dice: 1.1463  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 0.5274  decode.d7.loss_dice: 1.1514  decode.d8.loss_cls: 0.0632  decode.d8.loss_mask: 0.5236  decode.d8.loss_dice: 1.1431
11/15 12:21:15 - mmengine - INFO - Iter(train) [31750/90000]  base_lr: 6.7601e-05 lr: 6.7601e-06  eta: 9:46:52  time: 0.5979  data_time: 0.0099  memory: 10728  grad_norm: 350.6730  loss: 17.0025  decode.loss_cls: 0.0666  decode.loss_mask: 0.4203  decode.loss_dice: 1.1762  decode.d0.loss_cls: 0.0996  decode.d0.loss_mask: 0.4424  decode.d0.loss_dice: 1.2634  decode.d1.loss_cls: 0.0993  decode.d1.loss_mask: 0.4240  decode.d1.loss_dice: 1.2120  decode.d2.loss_cls: 0.0804  decode.d2.loss_mask: 0.4180  decode.d2.loss_dice: 1.1833  decode.d3.loss_cls: 0.0645  decode.d3.loss_mask: 0.4276  decode.d3.loss_dice: 1.1868  decode.d4.loss_cls: 0.0831  decode.d4.loss_mask: 0.4207  decode.d4.loss_dice: 1.1933  decode.d5.loss_cls: 0.0850  decode.d5.loss_mask: 0.4134  decode.d5.loss_dice: 1.1855  decode.d6.loss_cls: 0.0639  decode.d6.loss_mask: 0.4255  decode.d6.loss_dice: 1.2151  decode.d7.loss_cls: 0.0694  decode.d7.loss_mask: 0.4173  decode.d7.loss_dice: 1.2000  decode.d8.loss_cls: 0.0653  decode.d8.loss_mask: 0.4254  decode.d8.loss_dice: 1.1754
11/15 12:21:45 - mmengine - INFO - Iter(train) [31800/90000]  base_lr: 6.7549e-05 lr: 6.7549e-06  eta: 9:46:22  time: 0.6047  data_time: 0.0103  memory: 10675  grad_norm: 472.4069  loss: 18.5517  decode.loss_cls: 0.0798  decode.loss_mask: 0.5987  decode.loss_dice: 1.1777  decode.d0.loss_cls: 0.0777  decode.d0.loss_mask: 0.5847  decode.d0.loss_dice: 1.3012  decode.d1.loss_cls: 0.0841  decode.d1.loss_mask: 0.5793  decode.d1.loss_dice: 1.1949  decode.d2.loss_cls: 0.0784  decode.d2.loss_mask: 0.5660  decode.d2.loss_dice: 1.1779  decode.d3.loss_cls: 0.0684  decode.d3.loss_mask: 0.6025  decode.d3.loss_dice: 1.2246  decode.d4.loss_cls: 0.0765  decode.d4.loss_mask: 0.5609  decode.d4.loss_dice: 1.1648  decode.d5.loss_cls: 0.0772  decode.d5.loss_mask: 0.5689  decode.d5.loss_dice: 1.1768  decode.d6.loss_cls: 0.0745  decode.d6.loss_mask: 0.5714  decode.d6.loss_dice: 1.1931  decode.d7.loss_cls: 0.0717  decode.d7.loss_mask: 0.6043  decode.d7.loss_dice: 1.1861  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.5729  decode.d8.loss_dice: 1.1792
11/15 12:22:16 - mmengine - INFO - Iter(train) [31850/90000]  base_lr: 6.7496e-05 lr: 6.7496e-06  eta: 9:45:52  time: 0.6059  data_time: 0.0106  memory: 10692  grad_norm: 509.2209  loss: 16.1477  decode.loss_cls: 0.0548  decode.loss_mask: 0.5498  decode.loss_dice: 0.9741  decode.d0.loss_cls: 0.0813  decode.d0.loss_mask: 0.5941  decode.d0.loss_dice: 1.0443  decode.d1.loss_cls: 0.0601  decode.d1.loss_mask: 0.5594  decode.d1.loss_dice: 1.0314  decode.d2.loss_cls: 0.0576  decode.d2.loss_mask: 0.5510  decode.d2.loss_dice: 0.9887  decode.d3.loss_cls: 0.0557  decode.d3.loss_mask: 0.5593  decode.d3.loss_dice: 1.0044  decode.d4.loss_cls: 0.0539  decode.d4.loss_mask: 0.5440  decode.d4.loss_dice: 0.9793  decode.d5.loss_cls: 0.0513  decode.d5.loss_mask: 0.5543  decode.d5.loss_dice: 0.9949  decode.d6.loss_cls: 0.0482  decode.d6.loss_mask: 0.5553  decode.d6.loss_dice: 1.0080  decode.d7.loss_cls: 0.0546  decode.d7.loss_mask: 0.5578  decode.d7.loss_dice: 0.9869  decode.d8.loss_cls: 0.0549  decode.d8.loss_mask: 0.5516  decode.d8.loss_dice: 0.9867
11/15 12:22:46 - mmengine - INFO - Iter(train) [31900/90000]  base_lr: 6.7444e-05 lr: 6.7444e-06  eta: 9:45:22  time: 0.6047  data_time: 0.0103  memory: 10641  grad_norm: 775.1576  loss: 17.7966  decode.loss_cls: 0.0471  decode.loss_mask: 0.6083  decode.loss_dice: 1.1034  decode.d0.loss_cls: 0.0915  decode.d0.loss_mask: 0.6570  decode.d0.loss_dice: 1.1708  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.6188  decode.d1.loss_dice: 1.1308  decode.d2.loss_cls: 0.0615  decode.d2.loss_mask: 0.6042  decode.d2.loss_dice: 1.0958  decode.d3.loss_cls: 0.0574  decode.d3.loss_mask: 0.5992  decode.d3.loss_dice: 1.0799  decode.d4.loss_cls: 0.0505  decode.d4.loss_mask: 0.6041  decode.d4.loss_dice: 1.0876  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.6116  decode.d5.loss_dice: 1.0909  decode.d6.loss_cls: 0.0516  decode.d6.loss_mask: 0.5993  decode.d6.loss_dice: 1.0929  decode.d7.loss_cls: 0.0456  decode.d7.loss_mask: 0.6165  decode.d7.loss_dice: 1.1245  decode.d8.loss_cls: 0.0487  decode.d8.loss_mask: 0.6152  decode.d8.loss_dice: 1.1156
11/15 12:23:16 - mmengine - INFO - Iter(train) [31950/90000]  base_lr: 6.7392e-05 lr: 6.7392e-06  eta: 9:44:51  time: 0.5945  data_time: 0.0098  memory: 10675  grad_norm: 529.1228  loss: 15.6302  decode.loss_cls: 0.0704  decode.loss_mask: 0.5098  decode.loss_dice: 0.9670  decode.d0.loss_cls: 0.1025  decode.d0.loss_mask: 0.5272  decode.d0.loss_dice: 1.0212  decode.d1.loss_cls: 0.0663  decode.d1.loss_mask: 0.5161  decode.d1.loss_dice: 1.0178  decode.d2.loss_cls: 0.0653  decode.d2.loss_mask: 0.5016  decode.d2.loss_dice: 0.9885  decode.d3.loss_cls: 0.0695  decode.d3.loss_mask: 0.5020  decode.d3.loss_dice: 0.9769  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.4998  decode.d4.loss_dice: 0.9815  decode.d5.loss_cls: 0.0711  decode.d5.loss_mask: 0.4921  decode.d5.loss_dice: 0.9887  decode.d6.loss_cls: 0.0828  decode.d6.loss_mask: 0.4869  decode.d6.loss_dice: 0.9771  decode.d7.loss_cls: 0.0749  decode.d7.loss_mask: 0.4945  decode.d7.loss_dice: 0.9866  decode.d8.loss_cls: 0.0788  decode.d8.loss_mask: 0.4889  decode.d8.loss_dice: 0.9565
11/15 12:23:47 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 12:23:47 - mmengine - INFO - Iter(train) [32000/90000]  base_lr: 6.7340e-05 lr: 6.7340e-06  eta: 9:44:22  time: 0.6044  data_time: 0.0104  memory: 10656  grad_norm: 289.5241  loss: 18.2411  decode.loss_cls: 0.0582  decode.loss_mask: 0.4923  decode.loss_dice: 1.2392  decode.d0.loss_cls: 0.0901  decode.d0.loss_mask: 0.4966  decode.d0.loss_dice: 1.3104  decode.d1.loss_cls: 0.0639  decode.d1.loss_mask: 0.4983  decode.d1.loss_dice: 1.2621  decode.d2.loss_cls: 0.0734  decode.d2.loss_mask: 0.4987  decode.d2.loss_dice: 1.2625  decode.d3.loss_cls: 0.0612  decode.d3.loss_mask: 0.5014  decode.d3.loss_dice: 1.2436  decode.d4.loss_cls: 0.0539  decode.d4.loss_mask: 0.4971  decode.d4.loss_dice: 1.2733  decode.d5.loss_cls: 0.0571  decode.d5.loss_mask: 0.4901  decode.d5.loss_dice: 1.2532  decode.d6.loss_cls: 0.0708  decode.d6.loss_mask: 0.4972  decode.d6.loss_dice: 1.2502  decode.d7.loss_cls: 0.0603  decode.d7.loss_mask: 0.5001  decode.d7.loss_dice: 1.2782  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.5030  decode.d8.loss_dice: 1.2462
11/15 12:24:17 - mmengine - INFO - Iter(train) [32050/90000]  base_lr: 6.7287e-05 lr: 6.7287e-06  eta: 9:43:52  time: 0.6041  data_time: 0.0102  memory: 10728  grad_norm: 312.5004  loss: 18.9547  decode.loss_cls: 0.0669  decode.loss_mask: 0.5445  decode.loss_dice: 1.2716  decode.d0.loss_cls: 0.0813  decode.d0.loss_mask: 0.5588  decode.d0.loss_dice: 1.3589  decode.d1.loss_cls: 0.0750  decode.d1.loss_mask: 0.5457  decode.d1.loss_dice: 1.2853  decode.d2.loss_cls: 0.0614  decode.d2.loss_mask: 0.5722  decode.d2.loss_dice: 1.2711  decode.d3.loss_cls: 0.0857  decode.d3.loss_mask: 0.5601  decode.d3.loss_dice: 1.2246  decode.d4.loss_cls: 0.0702  decode.d4.loss_mask: 0.5601  decode.d4.loss_dice: 1.2164  decode.d5.loss_cls: 0.0579  decode.d5.loss_mask: 0.5735  decode.d5.loss_dice: 1.2653  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.5542  decode.d6.loss_dice: 1.2720  decode.d7.loss_cls: 0.0687  decode.d7.loss_mask: 0.5407  decode.d7.loss_dice: 1.2616  decode.d8.loss_cls: 0.0698  decode.d8.loss_mask: 0.5475  decode.d8.loss_dice: 1.2648
11/15 12:24:47 - mmengine - INFO - Iter(train) [32100/90000]  base_lr: 6.7235e-05 lr: 6.7235e-06  eta: 9:43:22  time: 0.6017  data_time: 0.0103  memory: 10675  grad_norm: 300.1744  loss: 18.3372  decode.loss_cls: 0.1095  decode.loss_mask: 0.5248  decode.loss_dice: 1.1588  decode.d0.loss_cls: 0.1336  decode.d0.loss_mask: 0.5474  decode.d0.loss_dice: 1.2802  decode.d1.loss_cls: 0.1116  decode.d1.loss_mask: 0.5429  decode.d1.loss_dice: 1.2234  decode.d2.loss_cls: 0.1031  decode.d2.loss_mask: 0.5398  decode.d2.loss_dice: 1.1885  decode.d3.loss_cls: 0.1079  decode.d3.loss_mask: 0.5391  decode.d3.loss_dice: 1.1968  decode.d4.loss_cls: 0.0955  decode.d4.loss_mask: 0.5410  decode.d4.loss_dice: 1.1986  decode.d5.loss_cls: 0.0969  decode.d5.loss_mask: 0.5366  decode.d5.loss_dice: 1.1763  decode.d6.loss_cls: 0.1017  decode.d6.loss_mask: 0.5299  decode.d6.loss_dice: 1.1580  decode.d7.loss_cls: 0.1026  decode.d7.loss_mask: 0.5297  decode.d7.loss_dice: 1.1637  decode.d8.loss_cls: 0.1151  decode.d8.loss_mask: 0.5281  decode.d8.loss_dice: 1.1559
11/15 12:25:17 - mmengine - INFO - Iter(train) [32150/90000]  base_lr: 6.7183e-05 lr: 6.7183e-06  eta: 9:42:51  time: 0.6018  data_time: 0.0102  memory: 10675  grad_norm: 603.0268  loss: 19.7515  decode.loss_cls: 0.0768  decode.loss_mask: 0.6494  decode.loss_dice: 1.2190  decode.d0.loss_cls: 0.1002  decode.d0.loss_mask: 0.6627  decode.d0.loss_dice: 1.3450  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.6469  decode.d1.loss_dice: 1.2578  decode.d2.loss_cls: 0.0850  decode.d2.loss_mask: 0.6484  decode.d2.loss_dice: 1.2372  decode.d3.loss_cls: 0.0773  decode.d3.loss_mask: 0.6350  decode.d3.loss_dice: 1.2283  decode.d4.loss_cls: 0.0808  decode.d4.loss_mask: 0.6441  decode.d4.loss_dice: 1.2391  decode.d5.loss_cls: 0.0882  decode.d5.loss_mask: 0.6367  decode.d5.loss_dice: 1.2165  decode.d6.loss_cls: 0.0838  decode.d6.loss_mask: 0.6560  decode.d6.loss_dice: 1.2232  decode.d7.loss_cls: 0.0790  decode.d7.loss_mask: 0.6582  decode.d7.loss_dice: 1.2404  decode.d8.loss_cls: 0.0720  decode.d8.loss_mask: 0.6553  decode.d8.loss_dice: 1.2322
11/15 12:25:48 - mmengine - INFO - Iter(train) [32200/90000]  base_lr: 6.7131e-05 lr: 6.7131e-06  eta: 9:42:21  time: 0.6043  data_time: 0.0102  memory: 10641  grad_norm: 580.5276  loss: 17.2160  decode.loss_cls: 0.0795  decode.loss_mask: 0.5518  decode.loss_dice: 1.0692  decode.d0.loss_cls: 0.0985  decode.d0.loss_mask: 0.5611  decode.d0.loss_dice: 1.1377  decode.d1.loss_cls: 0.1034  decode.d1.loss_mask: 0.5474  decode.d1.loss_dice: 1.0868  decode.d2.loss_cls: 0.0737  decode.d2.loss_mask: 0.5637  decode.d2.loss_dice: 1.1070  decode.d3.loss_cls: 0.0879  decode.d3.loss_mask: 0.5477  decode.d3.loss_dice: 1.0679  decode.d4.loss_cls: 0.0849  decode.d4.loss_mask: 0.5472  decode.d4.loss_dice: 1.0858  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 0.5493  decode.d5.loss_dice: 1.0499  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 0.5583  decode.d6.loss_dice: 1.0729  decode.d7.loss_cls: 0.0839  decode.d7.loss_mask: 0.5543  decode.d7.loss_dice: 1.0728  decode.d8.loss_cls: 0.0822  decode.d8.loss_mask: 0.5569  decode.d8.loss_dice: 1.0717
11/15 12:26:18 - mmengine - INFO - Iter(train) [32250/90000]  base_lr: 6.7078e-05 lr: 6.7078e-06  eta: 9:41:50  time: 0.6007  data_time: 0.0102  memory: 10656  grad_norm: 392.0178  loss: 17.7309  decode.loss_cls: 0.0476  decode.loss_mask: 0.5411  decode.loss_dice: 1.1575  decode.d0.loss_cls: 0.0639  decode.d0.loss_mask: 0.5639  decode.d0.loss_dice: 1.2593  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.5366  decode.d1.loss_dice: 1.1857  decode.d2.loss_cls: 0.0586  decode.d2.loss_mask: 0.5358  decode.d2.loss_dice: 1.1910  decode.d3.loss_cls: 0.0486  decode.d3.loss_mask: 0.5392  decode.d3.loss_dice: 1.1820  decode.d4.loss_cls: 0.0464  decode.d4.loss_mask: 0.5350  decode.d4.loss_dice: 1.1808  decode.d5.loss_cls: 0.0450  decode.d5.loss_mask: 0.5332  decode.d5.loss_dice: 1.1665  decode.d6.loss_cls: 0.0468  decode.d6.loss_mask: 0.5349  decode.d6.loss_dice: 1.1762  decode.d7.loss_cls: 0.0512  decode.d7.loss_mask: 0.5347  decode.d7.loss_dice: 1.1664  decode.d8.loss_cls: 0.0575  decode.d8.loss_mask: 0.5337  decode.d8.loss_dice: 1.1485
11/15 12:26:48 - mmengine - INFO - Iter(train) [32300/90000]  base_lr: 6.7026e-05 lr: 6.7026e-06  eta: 9:41:20  time: 0.6038  data_time: 0.0104  memory: 10675  grad_norm: 423.7984  loss: 18.1763  decode.loss_cls: 0.0545  decode.loss_mask: 0.5348  decode.loss_dice: 1.2215  decode.d0.loss_cls: 0.0762  decode.d0.loss_mask: 0.5383  decode.d0.loss_dice: 1.2531  decode.d1.loss_cls: 0.0586  decode.d1.loss_mask: 0.5290  decode.d1.loss_dice: 1.2200  decode.d2.loss_cls: 0.0512  decode.d2.loss_mask: 0.5234  decode.d2.loss_dice: 1.2288  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 0.5420  decode.d3.loss_dice: 1.2256  decode.d4.loss_cls: 0.0554  decode.d4.loss_mask: 0.5301  decode.d4.loss_dice: 1.2327  decode.d5.loss_cls: 0.0517  decode.d5.loss_mask: 0.5442  decode.d5.loss_dice: 1.2214  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.5334  decode.d6.loss_dice: 1.2394  decode.d7.loss_cls: 0.0491  decode.d7.loss_mask: 0.5440  decode.d7.loss_dice: 1.2235  decode.d8.loss_cls: 0.0470  decode.d8.loss_mask: 0.5338  decode.d8.loss_dice: 1.2069
11/15 12:27:18 - mmengine - INFO - Iter(train) [32350/90000]  base_lr: 6.6974e-05 lr: 6.6974e-06  eta: 9:40:50  time: 0.6038  data_time: 0.0105  memory: 10692  grad_norm: 374.1935  loss: 19.3949  decode.loss_cls: 0.0548  decode.loss_mask: 0.6249  decode.loss_dice: 1.2553  decode.d0.loss_cls: 0.0809  decode.d0.loss_mask: 0.6729  decode.d0.loss_dice: 1.2798  decode.d1.loss_cls: 0.0656  decode.d1.loss_mask: 0.6331  decode.d1.loss_dice: 1.2323  decode.d2.loss_cls: 0.0462  decode.d2.loss_mask: 0.6345  decode.d2.loss_dice: 1.2531  decode.d3.loss_cls: 0.0461  decode.d3.loss_mask: 0.6378  decode.d3.loss_dice: 1.2487  decode.d4.loss_cls: 0.0432  decode.d4.loss_mask: 0.6374  decode.d4.loss_dice: 1.2411  decode.d5.loss_cls: 0.0462  decode.d5.loss_mask: 0.6306  decode.d5.loss_dice: 1.2470  decode.d6.loss_cls: 0.0538  decode.d6.loss_mask: 0.6310  decode.d6.loss_dice: 1.2248  decode.d7.loss_cls: 0.0462  decode.d7.loss_mask: 0.6404  decode.d7.loss_dice: 1.2413  decode.d8.loss_cls: 0.0456  decode.d8.loss_mask: 0.6324  decode.d8.loss_dice: 1.2678
11/15 12:27:48 - mmengine - INFO - Iter(train) [32400/90000]  base_lr: 6.6922e-05 lr: 6.6922e-06  eta: 9:40:19  time: 0.6019  data_time: 0.0103  memory: 10728  grad_norm: 401.6572  loss: 15.7236  decode.loss_cls: 0.0536  decode.loss_mask: 0.4475  decode.loss_dice: 1.0658  decode.d0.loss_cls: 0.0755  decode.d0.loss_mask: 0.4612  decode.d0.loss_dice: 1.1494  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.4408  decode.d1.loss_dice: 1.0926  decode.d2.loss_cls: 0.0596  decode.d2.loss_mask: 0.4456  decode.d2.loss_dice: 1.0569  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.4424  decode.d3.loss_dice: 1.0368  decode.d4.loss_cls: 0.0627  decode.d4.loss_mask: 0.4435  decode.d4.loss_dice: 1.0410  decode.d5.loss_cls: 0.0648  decode.d5.loss_mask: 0.4425  decode.d5.loss_dice: 1.0405  decode.d6.loss_cls: 0.0545  decode.d6.loss_mask: 0.4506  decode.d6.loss_dice: 1.0481  decode.d7.loss_cls: 0.0633  decode.d7.loss_mask: 0.4483  decode.d7.loss_dice: 1.0549  decode.d8.loss_cls: 0.0664  decode.d8.loss_mask: 0.4447  decode.d8.loss_dice: 1.0449
11/15 12:28:19 - mmengine - INFO - Iter(train) [32450/90000]  base_lr: 6.6869e-05 lr: 6.6869e-06  eta: 9:39:49  time: 0.6024  data_time: 0.0105  memory: 10641  grad_norm: 383.9127  loss: 18.7774  decode.loss_cls: 0.0814  decode.loss_mask: 0.5853  decode.loss_dice: 1.1939  decode.d0.loss_cls: 0.1211  decode.d0.loss_mask: 0.6128  decode.d0.loss_dice: 1.2497  decode.d1.loss_cls: 0.0932  decode.d1.loss_mask: 0.5921  decode.d1.loss_dice: 1.2204  decode.d2.loss_cls: 0.0934  decode.d2.loss_mask: 0.5857  decode.d2.loss_dice: 1.1837  decode.d3.loss_cls: 0.0810  decode.d3.loss_mask: 0.5853  decode.d3.loss_dice: 1.1964  decode.d4.loss_cls: 0.0893  decode.d4.loss_mask: 0.5864  decode.d4.loss_dice: 1.1910  decode.d5.loss_cls: 0.0931  decode.d5.loss_mask: 0.5847  decode.d5.loss_dice: 1.1893  decode.d6.loss_cls: 0.0905  decode.d6.loss_mask: 0.5813  decode.d6.loss_dice: 1.1831  decode.d7.loss_cls: 0.0981  decode.d7.loss_mask: 0.5796  decode.d7.loss_dice: 1.1755  decode.d8.loss_cls: 0.0959  decode.d8.loss_mask: 0.5863  decode.d8.loss_dice: 1.1778
11/15 12:28:49 - mmengine - INFO - Iter(train) [32500/90000]  base_lr: 6.6817e-05 lr: 6.6817e-06  eta: 9:39:19  time: 0.5957  data_time: 0.0101  memory: 10692  grad_norm: 1312.1833  loss: 21.0971  decode.loss_cls: 0.1114  decode.loss_mask: 0.7405  decode.loss_dice: 1.2117  decode.d0.loss_cls: 0.1169  decode.d0.loss_mask: 0.7908  decode.d0.loss_dice: 1.3484  decode.d1.loss_cls: 0.1341  decode.d1.loss_mask: 0.7339  decode.d1.loss_dice: 1.2509  decode.d2.loss_cls: 0.1152  decode.d2.loss_mask: 0.7215  decode.d2.loss_dice: 1.2617  decode.d3.loss_cls: 0.1019  decode.d3.loss_mask: 0.7563  decode.d3.loss_dice: 1.2389  decode.d4.loss_cls: 0.1216  decode.d4.loss_mask: 0.7188  decode.d4.loss_dice: 1.2005  decode.d5.loss_cls: 0.1223  decode.d5.loss_mask: 0.7307  decode.d5.loss_dice: 1.2401  decode.d6.loss_cls: 0.1079  decode.d6.loss_mask: 0.7693  decode.d6.loss_dice: 1.2228  decode.d7.loss_cls: 0.1180  decode.d7.loss_mask: 0.7469  decode.d7.loss_dice: 1.2339  decode.d8.loss_cls: 0.1142  decode.d8.loss_mask: 0.7634  decode.d8.loss_dice: 1.2525
11/15 12:29:19 - mmengine - INFO - Iter(train) [32550/90000]  base_lr: 6.6765e-05 lr: 6.6765e-06  eta: 9:38:48  time: 0.6041  data_time: 0.0104  memory: 10675  grad_norm: 540.5655  loss: 16.6552  decode.loss_cls: 0.0716  decode.loss_mask: 0.5847  decode.loss_dice: 1.0190  decode.d0.loss_cls: 0.1039  decode.d0.loss_mask: 0.5999  decode.d0.loss_dice: 1.0717  decode.d1.loss_cls: 0.0787  decode.d1.loss_mask: 0.6198  decode.d1.loss_dice: 1.0230  decode.d2.loss_cls: 0.0787  decode.d2.loss_mask: 0.5877  decode.d2.loss_dice: 0.9728  decode.d3.loss_cls: 0.0710  decode.d3.loss_mask: 0.5884  decode.d3.loss_dice: 0.9791  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.5816  decode.d4.loss_dice: 0.9754  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 0.5889  decode.d5.loss_dice: 0.9879  decode.d6.loss_cls: 0.0669  decode.d6.loss_mask: 0.5891  decode.d6.loss_dice: 0.9778  decode.d7.loss_cls: 0.0642  decode.d7.loss_mask: 0.5923  decode.d7.loss_dice: 0.9945  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.5913  decode.d8.loss_dice: 0.9975
11/15 12:29:49 - mmengine - INFO - Iter(train) [32600/90000]  base_lr: 6.6712e-05 lr: 6.6712e-06  eta: 9:38:18  time: 0.6012  data_time: 0.0104  memory: 10656  grad_norm: 509.7151  loss: 20.1327  decode.loss_cls: 0.0918  decode.loss_mask: 0.6298  decode.loss_dice: 1.2624  decode.d0.loss_cls: 0.0757  decode.d0.loss_mask: 0.6565  decode.d0.loss_dice: 1.4127  decode.d1.loss_cls: 0.0936  decode.d1.loss_mask: 0.6041  decode.d1.loss_dice: 1.3140  decode.d2.loss_cls: 0.0974  decode.d2.loss_mask: 0.6125  decode.d2.loss_dice: 1.2772  decode.d3.loss_cls: 0.0878  decode.d3.loss_mask: 0.6401  decode.d3.loss_dice: 1.2510  decode.d4.loss_cls: 0.0885  decode.d4.loss_mask: 0.6342  decode.d4.loss_dice: 1.2885  decode.d5.loss_cls: 0.0799  decode.d5.loss_mask: 0.6373  decode.d5.loss_dice: 1.2970  decode.d6.loss_cls: 0.0919  decode.d6.loss_mask: 0.6378  decode.d6.loss_dice: 1.2669  decode.d7.loss_cls: 0.0810  decode.d7.loss_mask: 0.6298  decode.d7.loss_dice: 1.3038  decode.d8.loss_cls: 0.0798  decode.d8.loss_mask: 0.6341  decode.d8.loss_dice: 1.2755
11/15 12:30:19 - mmengine - INFO - Iter(train) [32650/90000]  base_lr: 6.6660e-05 lr: 6.6660e-06  eta: 9:37:48  time: 0.6025  data_time: 0.0104  memory: 10656  grad_norm: 781.7090  loss: 16.3298  decode.loss_cls: 0.0524  decode.loss_mask: 0.4553  decode.loss_dice: 1.0976  decode.d0.loss_cls: 0.0774  decode.d0.loss_mask: 0.4934  decode.d0.loss_dice: 1.1875  decode.d1.loss_cls: 0.0619  decode.d1.loss_mask: 0.4695  decode.d1.loss_dice: 1.1238  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 0.4624  decode.d2.loss_dice: 1.0912  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 0.4647  decode.d3.loss_dice: 1.0815  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.4623  decode.d4.loss_dice: 1.0949  decode.d5.loss_cls: 0.0588  decode.d5.loss_mask: 0.4611  decode.d5.loss_dice: 1.0856  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.4595  decode.d6.loss_dice: 1.0996  decode.d7.loss_cls: 0.0501  decode.d7.loss_mask: 0.4770  decode.d7.loss_dice: 1.1247  decode.d8.loss_cls: 0.0507  decode.d8.loss_mask: 0.4565  decode.d8.loss_dice: 1.0927
11/15 12:30:49 - mmengine - INFO - Iter(train) [32700/90000]  base_lr: 6.6608e-05 lr: 6.6608e-06  eta: 9:37:17  time: 0.6012  data_time: 0.0104  memory: 10728  grad_norm: 238.3893  loss: 18.2381  decode.loss_cls: 0.0820  decode.loss_mask: 0.5551  decode.loss_dice: 1.1670  decode.d0.loss_cls: 0.0907  decode.d0.loss_mask: 0.5890  decode.d0.loss_dice: 1.2597  decode.d1.loss_cls: 0.0868  decode.d1.loss_mask: 0.5614  decode.d1.loss_dice: 1.2030  decode.d2.loss_cls: 0.0794  decode.d2.loss_mask: 0.5585  decode.d2.loss_dice: 1.1702  decode.d3.loss_cls: 0.0694  decode.d3.loss_mask: 0.5607  decode.d3.loss_dice: 1.1800  decode.d4.loss_cls: 0.0709  decode.d4.loss_mask: 0.5560  decode.d4.loss_dice: 1.1770  decode.d5.loss_cls: 0.0719  decode.d5.loss_mask: 0.5532  decode.d5.loss_dice: 1.1777  decode.d6.loss_cls: 0.0800  decode.d6.loss_mask: 0.5596  decode.d6.loss_dice: 1.1527  decode.d7.loss_cls: 0.0757  decode.d7.loss_mask: 0.5585  decode.d7.loss_dice: 1.1958  decode.d8.loss_cls: 0.0770  decode.d8.loss_mask: 0.5587  decode.d8.loss_dice: 1.1606
11/15 12:31:19 - mmengine - INFO - Iter(train) [32750/90000]  base_lr: 6.6556e-05 lr: 6.6556e-06  eta: 9:36:47  time: 0.6068  data_time: 0.0108  memory: 10656  grad_norm: 450.9419  loss: 16.7326  decode.loss_cls: 0.0628  decode.loss_mask: 0.5090  decode.loss_dice: 1.0991  decode.d0.loss_cls: 0.1159  decode.d0.loss_mask: 0.5249  decode.d0.loss_dice: 1.1383  decode.d1.loss_cls: 0.0917  decode.d1.loss_mask: 0.5113  decode.d1.loss_dice: 1.0595  decode.d2.loss_cls: 0.0942  decode.d2.loss_mask: 0.5093  decode.d2.loss_dice: 1.0488  decode.d3.loss_cls: 0.0761  decode.d3.loss_mask: 0.5229  decode.d3.loss_dice: 1.0670  decode.d4.loss_cls: 0.0817  decode.d4.loss_mask: 0.5213  decode.d4.loss_dice: 1.0668  decode.d5.loss_cls: 0.0832  decode.d5.loss_mask: 0.4971  decode.d5.loss_dice: 1.0839  decode.d6.loss_cls: 0.0705  decode.d6.loss_mask: 0.5122  decode.d6.loss_dice: 1.0661  decode.d7.loss_cls: 0.0719  decode.d7.loss_mask: 0.5151  decode.d7.loss_dice: 1.0771  decode.d8.loss_cls: 0.0570  decode.d8.loss_mask: 0.5015  decode.d8.loss_dice: 1.0964
11/15 12:31:49 - mmengine - INFO - Iter(train) [32800/90000]  base_lr: 6.6503e-05 lr: 6.6503e-06  eta: 9:36:16  time: 0.6005  data_time: 0.0102  memory: 10692  grad_norm: 475.9546  loss: 18.4321  decode.loss_cls: 0.0662  decode.loss_mask: 0.5818  decode.loss_dice: 1.1700  decode.d0.loss_cls: 0.0814  decode.d0.loss_mask: 0.6291  decode.d0.loss_dice: 1.2801  decode.d1.loss_cls: 0.0792  decode.d1.loss_mask: 0.5893  decode.d1.loss_dice: 1.1904  decode.d2.loss_cls: 0.0572  decode.d2.loss_mask: 0.6174  decode.d2.loss_dice: 1.1696  decode.d3.loss_cls: 0.0573  decode.d3.loss_mask: 0.5873  decode.d3.loss_dice: 1.1533  decode.d4.loss_cls: 0.0546  decode.d4.loss_mask: 0.5913  decode.d4.loss_dice: 1.1766  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.5771  decode.d5.loss_dice: 1.1725  decode.d6.loss_cls: 0.0531  decode.d6.loss_mask: 0.5741  decode.d6.loss_dice: 1.1650  decode.d7.loss_cls: 0.0608  decode.d7.loss_mask: 0.5994  decode.d7.loss_dice: 1.1749  decode.d8.loss_cls: 0.0492  decode.d8.loss_mask: 0.6078  decode.d8.loss_dice: 1.1997
11/15 12:32:19 - mmengine - INFO - Iter(train) [32850/90000]  base_lr: 6.6451e-05 lr: 6.6451e-06  eta: 9:35:46  time: 0.6027  data_time: 0.0105  memory: 10675  grad_norm: 402.1107  loss: 19.1441  decode.loss_cls: 0.0632  decode.loss_mask: 0.6295  decode.loss_dice: 1.2106  decode.d0.loss_cls: 0.0844  decode.d0.loss_mask: 0.6633  decode.d0.loss_dice: 1.2929  decode.d1.loss_cls: 0.0706  decode.d1.loss_mask: 0.6362  decode.d1.loss_dice: 1.2488  decode.d2.loss_cls: 0.0647  decode.d2.loss_mask: 0.6470  decode.d2.loss_dice: 1.2272  decode.d3.loss_cls: 0.0561  decode.d3.loss_mask: 0.6456  decode.d3.loss_dice: 1.1910  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.6340  decode.d4.loss_dice: 1.1928  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.6321  decode.d5.loss_dice: 1.1862  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.6274  decode.d6.loss_dice: 1.1664  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.6273  decode.d7.loss_dice: 1.1965  decode.d8.loss_cls: 0.0731  decode.d8.loss_mask: 0.6328  decode.d8.loss_dice: 1.1851
11/15 12:32:50 - mmengine - INFO - Iter(train) [32900/90000]  base_lr: 6.6399e-05 lr: 6.6399e-06  eta: 9:35:16  time: 0.6007  data_time: 0.0103  memory: 10675  grad_norm: 454.2418  loss: 18.7607  decode.loss_cls: 0.0734  decode.loss_mask: 0.5702  decode.loss_dice: 1.2041  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.6169  decode.d0.loss_dice: 1.3657  decode.d1.loss_cls: 0.1020  decode.d1.loss_mask: 0.5802  decode.d1.loss_dice: 1.2013  decode.d2.loss_cls: 0.0963  decode.d2.loss_mask: 0.5812  decode.d2.loss_dice: 1.1838  decode.d3.loss_cls: 0.0772  decode.d3.loss_mask: 0.5789  decode.d3.loss_dice: 1.2138  decode.d4.loss_cls: 0.0807  decode.d4.loss_mask: 0.5807  decode.d4.loss_dice: 1.2051  decode.d5.loss_cls: 0.0797  decode.d5.loss_mask: 0.5770  decode.d5.loss_dice: 1.1854  decode.d6.loss_cls: 0.0817  decode.d6.loss_mask: 0.5718  decode.d6.loss_dice: 1.1758  decode.d7.loss_cls: 0.0804  decode.d7.loss_mask: 0.5722  decode.d7.loss_dice: 1.2150  decode.d8.loss_cls: 0.0813  decode.d8.loss_mask: 0.5656  decode.d8.loss_dice: 1.1787
11/15 12:33:20 - mmengine - INFO - Iter(train) [32950/90000]  base_lr: 6.6346e-05 lr: 6.6346e-06  eta: 9:34:45  time: 0.6016  data_time: 0.0103  memory: 10728  grad_norm: 845.0296  loss: 19.5624  decode.loss_cls: 0.0589  decode.loss_mask: 0.5464  decode.loss_dice: 1.3447  decode.d0.loss_cls: 0.0999  decode.d0.loss_mask: 0.5371  decode.d0.loss_dice: 1.4201  decode.d1.loss_cls: 0.0779  decode.d1.loss_mask: 0.5319  decode.d1.loss_dice: 1.3445  decode.d2.loss_cls: 0.0774  decode.d2.loss_mask: 0.5288  decode.d2.loss_dice: 1.3350  decode.d3.loss_cls: 0.0773  decode.d3.loss_mask: 0.5289  decode.d3.loss_dice: 1.3265  decode.d4.loss_cls: 0.0735  decode.d4.loss_mask: 0.5436  decode.d4.loss_dice: 1.3367  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.5410  decode.d5.loss_dice: 1.3525  decode.d6.loss_cls: 0.0669  decode.d6.loss_mask: 0.5424  decode.d6.loss_dice: 1.3288  decode.d7.loss_cls: 0.0766  decode.d7.loss_mask: 0.5264  decode.d7.loss_dice: 1.3224  decode.d8.loss_cls: 0.0684  decode.d8.loss_mask: 0.5318  decode.d8.loss_dice: 1.3544
11/15 12:33:50 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 12:33:50 - mmengine - INFO - Iter(train) [33000/90000]  base_lr: 6.6294e-05 lr: 6.6294e-06  eta: 9:34:15  time: 0.6095  data_time: 0.0108  memory: 10675  grad_norm: 311.3593  loss: 17.9314  decode.loss_cls: 0.0588  decode.loss_mask: 0.5407  decode.loss_dice: 1.1304  decode.d0.loss_cls: 0.0890  decode.d0.loss_mask: 0.5408  decode.d0.loss_dice: 1.2572  decode.d1.loss_cls: 0.0920  decode.d1.loss_mask: 0.5520  decode.d1.loss_dice: 1.1695  decode.d2.loss_cls: 0.0824  decode.d2.loss_mask: 0.5471  decode.d2.loss_dice: 1.1838  decode.d3.loss_cls: 0.0614  decode.d3.loss_mask: 0.5668  decode.d3.loss_dice: 1.1688  decode.d4.loss_cls: 0.0643  decode.d4.loss_mask: 0.5523  decode.d4.loss_dice: 1.1669  decode.d5.loss_cls: 0.0558  decode.d5.loss_mask: 0.5454  decode.d5.loss_dice: 1.1727  decode.d6.loss_cls: 0.0545  decode.d6.loss_mask: 0.5419  decode.d6.loss_dice: 1.1592  decode.d7.loss_cls: 0.0669  decode.d7.loss_mask: 0.5460  decode.d7.loss_dice: 1.1480  decode.d8.loss_cls: 0.0654  decode.d8.loss_mask: 0.5626  decode.d8.loss_dice: 1.1891
11/15 12:34:20 - mmengine - INFO - Iter(train) [33050/90000]  base_lr: 6.6242e-05 lr: 6.6242e-06  eta: 9:33:45  time: 0.6007  data_time: 0.0103  memory: 10728  grad_norm: 302.7426  loss: 17.1226  decode.loss_cls: 0.0873  decode.loss_mask: 0.4714  decode.loss_dice: 1.1246  decode.d0.loss_cls: 0.0896  decode.d0.loss_mask: 0.4949  decode.d0.loss_dice: 1.2761  decode.d1.loss_cls: 0.0918  decode.d1.loss_mask: 0.4792  decode.d1.loss_dice: 1.1356  decode.d2.loss_cls: 0.0856  decode.d2.loss_mask: 0.4826  decode.d2.loss_dice: 1.1408  decode.d3.loss_cls: 0.1023  decode.d3.loss_mask: 0.4731  decode.d3.loss_dice: 1.1223  decode.d4.loss_cls: 0.0842  decode.d4.loss_mask: 0.4744  decode.d4.loss_dice: 1.1385  decode.d5.loss_cls: 0.0857  decode.d5.loss_mask: 0.4732  decode.d5.loss_dice: 1.1396  decode.d6.loss_cls: 0.0915  decode.d6.loss_mask: 0.4728  decode.d6.loss_dice: 1.1379  decode.d7.loss_cls: 0.0930  decode.d7.loss_mask: 0.4730  decode.d7.loss_dice: 1.1309  decode.d8.loss_cls: 0.0869  decode.d8.loss_mask: 0.4684  decode.d8.loss_dice: 1.1154
11/15 12:34:50 - mmengine - INFO - Iter(train) [33100/90000]  base_lr: 6.6189e-05 lr: 6.6189e-06  eta: 9:33:14  time: 0.6036  data_time: 0.0104  memory: 10675  grad_norm: 444.2031  loss: 17.8705  decode.loss_cls: 0.0505  decode.loss_mask: 0.5537  decode.loss_dice: 1.1737  decode.d0.loss_cls: 0.0772  decode.d0.loss_mask: 0.5843  decode.d0.loss_dice: 1.2224  decode.d1.loss_cls: 0.0581  decode.d1.loss_mask: 0.5753  decode.d1.loss_dice: 1.1484  decode.d2.loss_cls: 0.0481  decode.d2.loss_mask: 0.5661  decode.d2.loss_dice: 1.1758  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.5648  decode.d3.loss_dice: 1.1410  decode.d4.loss_cls: 0.0618  decode.d4.loss_mask: 0.5649  decode.d4.loss_dice: 1.1364  decode.d5.loss_cls: 0.0515  decode.d5.loss_mask: 0.5716  decode.d5.loss_dice: 1.1636  decode.d6.loss_cls: 0.0609  decode.d6.loss_mask: 0.5742  decode.d6.loss_dice: 1.1338  decode.d7.loss_cls: 0.0558  decode.d7.loss_mask: 0.5739  decode.d7.loss_dice: 1.1622  decode.d8.loss_cls: 0.0589  decode.d8.loss_mask: 0.5460  decode.d8.loss_dice: 1.1576
11/15 12:35:21 - mmengine - INFO - Iter(train) [33150/90000]  base_lr: 6.6137e-05 lr: 6.6137e-06  eta: 9:32:44  time: 0.6031  data_time: 0.0105  memory: 10742  grad_norm: 283.8155  loss: 18.0086  decode.loss_cls: 0.0624  decode.loss_mask: 0.5705  decode.loss_dice: 1.1580  decode.d0.loss_cls: 0.0899  decode.d0.loss_mask: 0.5945  decode.d0.loss_dice: 1.2049  decode.d1.loss_cls: 0.0664  decode.d1.loss_mask: 0.5994  decode.d1.loss_dice: 1.1608  decode.d2.loss_cls: 0.0675  decode.d2.loss_mask: 0.5822  decode.d2.loss_dice: 1.1513  decode.d3.loss_cls: 0.0731  decode.d3.loss_mask: 0.5733  decode.d3.loss_dice: 1.1257  decode.d4.loss_cls: 0.0568  decode.d4.loss_mask: 0.5744  decode.d4.loss_dice: 1.1344  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.5701  decode.d5.loss_dice: 1.1588  decode.d6.loss_cls: 0.0662  decode.d6.loss_mask: 0.5704  decode.d6.loss_dice: 1.1374  decode.d7.loss_cls: 0.0578  decode.d7.loss_mask: 0.5801  decode.d7.loss_dice: 1.1675  decode.d8.loss_cls: 0.0651  decode.d8.loss_mask: 0.5741  decode.d8.loss_dice: 1.1616
11/15 12:35:51 - mmengine - INFO - Iter(train) [33200/90000]  base_lr: 6.6084e-05 lr: 6.6084e-06  eta: 9:32:14  time: 0.6043  data_time: 0.0104  memory: 10641  grad_norm: 423.5347  loss: 19.9234  decode.loss_cls: 0.0738  decode.loss_mask: 0.6273  decode.loss_dice: 1.2578  decode.d0.loss_cls: 0.0866  decode.d0.loss_mask: 0.6642  decode.d0.loss_dice: 1.3750  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.6441  decode.d1.loss_dice: 1.2953  decode.d2.loss_cls: 0.0779  decode.d2.loss_mask: 0.6321  decode.d2.loss_dice: 1.2749  decode.d3.loss_cls: 0.1056  decode.d3.loss_mask: 0.6131  decode.d3.loss_dice: 1.2363  decode.d4.loss_cls: 0.0863  decode.d4.loss_mask: 0.6352  decode.d4.loss_dice: 1.2628  decode.d5.loss_cls: 0.1030  decode.d5.loss_mask: 0.6152  decode.d5.loss_dice: 1.2597  decode.d6.loss_cls: 0.0770  decode.d6.loss_mask: 0.6362  decode.d6.loss_dice: 1.2674  decode.d7.loss_cls: 0.0810  decode.d7.loss_mask: 0.6242  decode.d7.loss_dice: 1.2916  decode.d8.loss_cls: 0.0858  decode.d8.loss_mask: 0.6191  decode.d8.loss_dice: 1.2458
11/15 12:36:21 - mmengine - INFO - Iter(train) [33250/90000]  base_lr: 6.6032e-05 lr: 6.6032e-06  eta: 9:31:43  time: 0.5997  data_time: 0.0104  memory: 10656  grad_norm: 345.7717  loss: 15.0905  decode.loss_cls: 0.0508  decode.loss_mask: 0.4869  decode.loss_dice: 0.9469  decode.d0.loss_cls: 0.0745  decode.d0.loss_mask: 0.4770  decode.d0.loss_dice: 1.0631  decode.d1.loss_cls: 0.0791  decode.d1.loss_mask: 0.4521  decode.d1.loss_dice: 0.9707  decode.d2.loss_cls: 0.0666  decode.d2.loss_mask: 0.4828  decode.d2.loss_dice: 0.9679  decode.d3.loss_cls: 0.0636  decode.d3.loss_mask: 0.4842  decode.d3.loss_dice: 0.9638  decode.d4.loss_cls: 0.0650  decode.d4.loss_mask: 0.4769  decode.d4.loss_dice: 0.9681  decode.d5.loss_cls: 0.0694  decode.d5.loss_mask: 0.4748  decode.d5.loss_dice: 0.9559  decode.d6.loss_cls: 0.0597  decode.d6.loss_mask: 0.4740  decode.d6.loss_dice: 0.9534  decode.d7.loss_cls: 0.0506  decode.d7.loss_mask: 0.4951  decode.d7.loss_dice: 0.9428  decode.d8.loss_cls: 0.0557  decode.d8.loss_mask: 0.4755  decode.d8.loss_dice: 0.9435
11/15 12:36:51 - mmengine - INFO - Iter(train) [33300/90000]  base_lr: 6.5980e-05 lr: 6.5980e-06  eta: 9:31:13  time: 0.6029  data_time: 0.0106  memory: 10692  grad_norm: 1227.2095  loss: 17.4510  decode.loss_cls: 0.0488  decode.loss_mask: 0.5853  decode.loss_dice: 1.0702  decode.d0.loss_cls: 0.0715  decode.d0.loss_mask: 0.6280  decode.d0.loss_dice: 1.1315  decode.d1.loss_cls: 0.0579  decode.d1.loss_mask: 0.6022  decode.d1.loss_dice: 1.1235  decode.d2.loss_cls: 0.0396  decode.d2.loss_mask: 0.6122  decode.d2.loss_dice: 1.0767  decode.d3.loss_cls: 0.0362  decode.d3.loss_mask: 0.5973  decode.d3.loss_dice: 1.1070  decode.d4.loss_cls: 0.0389  decode.d4.loss_mask: 0.6052  decode.d4.loss_dice: 1.0995  decode.d5.loss_cls: 0.0379  decode.d5.loss_mask: 0.5955  decode.d5.loss_dice: 1.0946  decode.d6.loss_cls: 0.0370  decode.d6.loss_mask: 0.5879  decode.d6.loss_dice: 1.1097  decode.d7.loss_cls: 0.0370  decode.d7.loss_mask: 0.5965  decode.d7.loss_dice: 1.0997  decode.d8.loss_cls: 0.0430  decode.d8.loss_mask: 0.5959  decode.d8.loss_dice: 1.0848
11/15 12:37:25 - mmengine - INFO - Iter(train) [33350/90000]  base_lr: 6.5927e-05 lr: 6.5927e-06  eta: 9:30:49  time: 0.6033  data_time: 0.0107  memory: 10641  grad_norm: 417.9042  loss: 16.1120  decode.loss_cls: 0.0544  decode.loss_mask: 0.4814  decode.loss_dice: 1.0406  decode.d0.loss_cls: 0.0834  decode.d0.loss_mask: 0.5074  decode.d0.loss_dice: 1.1035  decode.d1.loss_cls: 0.0636  decode.d1.loss_mask: 0.5093  decode.d1.loss_dice: 1.0868  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.4958  decode.d2.loss_dice: 1.0562  decode.d3.loss_cls: 0.0540  decode.d3.loss_mask: 0.4808  decode.d3.loss_dice: 1.0457  decode.d4.loss_cls: 0.0505  decode.d4.loss_mask: 0.4934  decode.d4.loss_dice: 1.0401  decode.d5.loss_cls: 0.0543  decode.d5.loss_mask: 0.4951  decode.d5.loss_dice: 1.0488  decode.d6.loss_cls: 0.0469  decode.d6.loss_mask: 0.4998  decode.d6.loss_dice: 1.0395  decode.d7.loss_cls: 0.0435  decode.d7.loss_mask: 0.4937  decode.d7.loss_dice: 1.0733  decode.d8.loss_cls: 0.0507  decode.d8.loss_mask: 0.4936  decode.d8.loss_dice: 1.0621
11/15 12:37:56 - mmengine - INFO - Iter(train) [33400/90000]  base_lr: 6.5875e-05 lr: 6.5875e-06  eta: 9:30:19  time: 0.6441  data_time: 0.0107  memory: 10675  grad_norm: 602.9170  loss: 16.9942  decode.loss_cls: 0.0493  decode.loss_mask: 0.5328  decode.loss_dice: 1.0907  decode.d0.loss_cls: 0.0720  decode.d0.loss_mask: 0.5728  decode.d0.loss_dice: 1.1353  decode.d1.loss_cls: 0.0591  decode.d1.loss_mask: 0.5388  decode.d1.loss_dice: 1.1345  decode.d2.loss_cls: 0.0511  decode.d2.loss_mask: 0.5397  decode.d2.loss_dice: 1.1070  decode.d3.loss_cls: 0.0510  decode.d3.loss_mask: 0.5364  decode.d3.loss_dice: 1.0918  decode.d4.loss_cls: 0.0445  decode.d4.loss_mask: 0.5376  decode.d4.loss_dice: 1.1147  decode.d5.loss_cls: 0.0450  decode.d5.loss_mask: 0.5404  decode.d5.loss_dice: 1.0950  decode.d6.loss_cls: 0.0450  decode.d6.loss_mask: 0.5468  decode.d6.loss_dice: 1.0985  decode.d7.loss_cls: 0.0523  decode.d7.loss_mask: 0.5369  decode.d7.loss_dice: 1.0881  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.5379  decode.d8.loss_dice: 1.1031
11/15 12:38:27 - mmengine - INFO - Iter(train) [33450/90000]  base_lr: 6.5823e-05 lr: 6.5823e-06  eta: 9:29:51  time: 0.6010  data_time: 0.0104  memory: 10641  grad_norm: 593.0372  loss: 17.1608  decode.loss_cls: 0.0425  decode.loss_mask: 0.5373  decode.loss_dice: 1.1254  decode.d0.loss_cls: 0.0718  decode.d0.loss_mask: 0.5650  decode.d0.loss_dice: 1.1718  decode.d1.loss_cls: 0.0495  decode.d1.loss_mask: 0.5487  decode.d1.loss_dice: 1.1297  decode.d2.loss_cls: 0.0500  decode.d2.loss_mask: 0.5324  decode.d2.loss_dice: 1.1202  decode.d3.loss_cls: 0.0497  decode.d3.loss_mask: 0.5384  decode.d3.loss_dice: 1.1210  decode.d4.loss_cls: 0.0535  decode.d4.loss_mask: 0.5387  decode.d4.loss_dice: 1.1051  decode.d5.loss_cls: 0.0508  decode.d5.loss_mask: 0.5405  decode.d5.loss_dice: 1.1114  decode.d6.loss_cls: 0.0442  decode.d6.loss_mask: 0.5494  decode.d6.loss_dice: 1.1104  decode.d7.loss_cls: 0.0515  decode.d7.loss_mask: 0.5407  decode.d7.loss_dice: 1.1139  decode.d8.loss_cls: 0.0470  decode.d8.loss_mask: 0.5373  decode.d8.loss_dice: 1.1128
11/15 12:38:57 - mmengine - INFO - Iter(train) [33500/90000]  base_lr: 6.5770e-05 lr: 6.5770e-06  eta: 9:29:20  time: 0.6019  data_time: 0.0105  memory: 10713  grad_norm: 385.7848  loss: 17.1331  decode.loss_cls: 0.0767  decode.loss_mask: 0.5160  decode.loss_dice: 1.0884  decode.d0.loss_cls: 0.1025  decode.d0.loss_mask: 0.5170  decode.d0.loss_dice: 1.2384  decode.d1.loss_cls: 0.0764  decode.d1.loss_mask: 0.5229  decode.d1.loss_dice: 1.1425  decode.d2.loss_cls: 0.0770  decode.d2.loss_mask: 0.5342  decode.d2.loss_dice: 1.1255  decode.d3.loss_cls: 0.0604  decode.d3.loss_mask: 0.5434  decode.d3.loss_dice: 1.1023  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.5227  decode.d4.loss_dice: 1.1130  decode.d5.loss_cls: 0.0685  decode.d5.loss_mask: 0.5113  decode.d5.loss_dice: 1.0969  decode.d6.loss_cls: 0.0724  decode.d6.loss_mask: 0.5124  decode.d6.loss_dice: 1.0802  decode.d7.loss_cls: 0.0694  decode.d7.loss_mask: 0.5225  decode.d7.loss_dice: 1.1032  decode.d8.loss_cls: 0.0758  decode.d8.loss_mask: 0.5139  decode.d8.loss_dice: 1.0794
11/15 12:39:27 - mmengine - INFO - Iter(train) [33550/90000]  base_lr: 6.5718e-05 lr: 6.5718e-06  eta: 9:28:50  time: 0.6003  data_time: 0.0104  memory: 10675  grad_norm: 926.7350  loss: 17.4520  decode.loss_cls: 0.0899  decode.loss_mask: 0.5195  decode.loss_dice: 1.0925  decode.d0.loss_cls: 0.0940  decode.d0.loss_mask: 0.5345  decode.d0.loss_dice: 1.2038  decode.d1.loss_cls: 0.0736  decode.d1.loss_mask: 0.5510  decode.d1.loss_dice: 1.1467  decode.d2.loss_cls: 0.0658  decode.d2.loss_mask: 0.5761  decode.d2.loss_dice: 1.1650  decode.d3.loss_cls: 0.0954  decode.d3.loss_mask: 0.5361  decode.d3.loss_dice: 1.1063  decode.d4.loss_cls: 0.0743  decode.d4.loss_mask: 0.5427  decode.d4.loss_dice: 1.1216  decode.d5.loss_cls: 0.0792  decode.d5.loss_mask: 0.5338  decode.d5.loss_dice: 1.0892  decode.d6.loss_cls: 0.0898  decode.d6.loss_mask: 0.5280  decode.d6.loss_dice: 1.0843  decode.d7.loss_cls: 0.0874  decode.d7.loss_mask: 0.5310  decode.d7.loss_dice: 1.1086  decode.d8.loss_cls: 0.0764  decode.d8.loss_mask: 0.5373  decode.d8.loss_dice: 1.1185
11/15 12:39:57 - mmengine - INFO - Iter(train) [33600/90000]  base_lr: 6.5666e-05 lr: 6.5666e-06  eta: 9:28:20  time: 0.5991  data_time: 0.0105  memory: 10728  grad_norm: 446.1273  loss: 18.8114  decode.loss_cls: 0.0710  decode.loss_mask: 0.6316  decode.loss_dice: 1.1668  decode.d0.loss_cls: 0.0784  decode.d0.loss_mask: 0.6437  decode.d0.loss_dice: 1.2307  decode.d1.loss_cls: 0.0586  decode.d1.loss_mask: 0.6296  decode.d1.loss_dice: 1.2199  decode.d2.loss_cls: 0.0763  decode.d2.loss_mask: 0.6166  decode.d2.loss_dice: 1.1739  decode.d3.loss_cls: 0.0718  decode.d3.loss_mask: 0.6198  decode.d3.loss_dice: 1.1849  decode.d4.loss_cls: 0.0695  decode.d4.loss_mask: 0.6224  decode.d4.loss_dice: 1.1593  decode.d5.loss_cls: 0.0697  decode.d5.loss_mask: 0.6203  decode.d5.loss_dice: 1.1635  decode.d6.loss_cls: 0.0684  decode.d6.loss_mask: 0.6360  decode.d6.loss_dice: 1.1718  decode.d7.loss_cls: 0.0701  decode.d7.loss_mask: 0.6330  decode.d7.loss_dice: 1.1795  decode.d8.loss_cls: 0.0731  decode.d8.loss_mask: 0.6204  decode.d8.loss_dice: 1.1807
11/15 12:40:27 - mmengine - INFO - Iter(train) [33650/90000]  base_lr: 6.5613e-05 lr: 6.5613e-06  eta: 9:27:49  time: 0.6032  data_time: 0.0105  memory: 10713  grad_norm: 288.0484  loss: 16.5301  decode.loss_cls: 0.0671  decode.loss_mask: 0.4674  decode.loss_dice: 1.1061  decode.d0.loss_cls: 0.0955  decode.d0.loss_mask: 0.4841  decode.d0.loss_dice: 1.1632  decode.d1.loss_cls: 0.0658  decode.d1.loss_mask: 0.4692  decode.d1.loss_dice: 1.1387  decode.d2.loss_cls: 0.0702  decode.d2.loss_mask: 0.4553  decode.d2.loss_dice: 1.1014  decode.d3.loss_cls: 0.0661  decode.d3.loss_mask: 0.4610  decode.d3.loss_dice: 1.1236  decode.d4.loss_cls: 0.0579  decode.d4.loss_mask: 0.4698  decode.d4.loss_dice: 1.0974  decode.d5.loss_cls: 0.0651  decode.d5.loss_mask: 0.4633  decode.d5.loss_dice: 1.1240  decode.d6.loss_cls: 0.0594  decode.d6.loss_mask: 0.4693  decode.d6.loss_dice: 1.0824  decode.d7.loss_cls: 0.0713  decode.d7.loss_mask: 0.4765  decode.d7.loss_dice: 1.1094  decode.d8.loss_cls: 0.0688  decode.d8.loss_mask: 0.4723  decode.d8.loss_dice: 1.1084
11/15 12:40:58 - mmengine - INFO - Iter(train) [33700/90000]  base_lr: 6.5561e-05 lr: 6.5561e-06  eta: 9:27:19  time: 0.6045  data_time: 0.0104  memory: 10656  grad_norm: 539.7660  loss: 16.9926  decode.loss_cls: 0.0877  decode.loss_mask: 0.4099  decode.loss_dice: 1.1840  decode.d0.loss_cls: 0.0814  decode.d0.loss_mask: 0.4191  decode.d0.loss_dice: 1.2832  decode.d1.loss_cls: 0.0632  decode.d1.loss_mask: 0.4226  decode.d1.loss_dice: 1.2200  decode.d2.loss_cls: 0.0689  decode.d2.loss_mask: 0.4199  decode.d2.loss_dice: 1.2103  decode.d3.loss_cls: 0.0770  decode.d3.loss_mask: 0.4124  decode.d3.loss_dice: 1.1835  decode.d4.loss_cls: 0.1090  decode.d4.loss_mask: 0.4194  decode.d4.loss_dice: 1.1893  decode.d5.loss_cls: 0.0832  decode.d5.loss_mask: 0.4163  decode.d5.loss_dice: 1.2108  decode.d6.loss_cls: 0.0824  decode.d6.loss_mask: 0.4120  decode.d6.loss_dice: 1.1869  decode.d7.loss_cls: 0.0865  decode.d7.loss_mask: 0.4158  decode.d7.loss_dice: 1.1577  decode.d8.loss_cls: 0.0732  decode.d8.loss_mask: 0.4138  decode.d8.loss_dice: 1.1931
11/15 12:41:28 - mmengine - INFO - Iter(train) [33750/90000]  base_lr: 6.5508e-05 lr: 6.5508e-06  eta: 9:26:49  time: 0.6010  data_time: 0.0106  memory: 10641  grad_norm: 632.8397  loss: 17.5032  decode.loss_cls: 0.0813  decode.loss_mask: 0.4722  decode.loss_dice: 1.2021  decode.d0.loss_cls: 0.1132  decode.d0.loss_mask: 0.4766  decode.d0.loss_dice: 1.2552  decode.d1.loss_cls: 0.0939  decode.d1.loss_mask: 0.4651  decode.d1.loss_dice: 1.1456  decode.d2.loss_cls: 0.0893  decode.d2.loss_mask: 0.4642  decode.d2.loss_dice: 1.1913  decode.d3.loss_cls: 0.0857  decode.d3.loss_mask: 0.4657  decode.d3.loss_dice: 1.1860  decode.d4.loss_cls: 0.0802  decode.d4.loss_mask: 0.4704  decode.d4.loss_dice: 1.1666  decode.d5.loss_cls: 0.0908  decode.d5.loss_mask: 0.4771  decode.d5.loss_dice: 1.1943  decode.d6.loss_cls: 0.0811  decode.d6.loss_mask: 0.4777  decode.d6.loss_dice: 1.2067  decode.d7.loss_cls: 0.0827  decode.d7.loss_mask: 0.4734  decode.d7.loss_dice: 1.1715  decode.d8.loss_cls: 0.0788  decode.d8.loss_mask: 0.4703  decode.d8.loss_dice: 1.1943
11/15 12:41:58 - mmengine - INFO - Iter(train) [33800/90000]  base_lr: 6.5456e-05 lr: 6.5456e-06  eta: 9:26:18  time: 0.6008  data_time: 0.0103  memory: 10675  grad_norm: 222.0505  loss: 15.8996  decode.loss_cls: 0.0862  decode.loss_mask: 0.5162  decode.loss_dice: 0.9577  decode.d0.loss_cls: 0.1121  decode.d0.loss_mask: 0.5502  decode.d0.loss_dice: 1.0301  decode.d1.loss_cls: 0.1070  decode.d1.loss_mask: 0.5305  decode.d1.loss_dice: 1.0062  decode.d2.loss_cls: 0.0907  decode.d2.loss_mask: 0.5234  decode.d2.loss_dice: 0.9800  decode.d3.loss_cls: 0.0889  decode.d3.loss_mask: 0.4929  decode.d3.loss_dice: 0.9473  decode.d4.loss_cls: 0.0898  decode.d4.loss_mask: 0.5150  decode.d4.loss_dice: 0.9624  decode.d5.loss_cls: 0.0849  decode.d5.loss_mask: 0.5171  decode.d5.loss_dice: 0.9729  decode.d6.loss_cls: 0.0880  decode.d6.loss_mask: 0.5188  decode.d6.loss_dice: 0.9752  decode.d7.loss_cls: 0.0800  decode.d7.loss_mask: 0.5198  decode.d7.loss_dice: 0.9779  decode.d8.loss_cls: 0.0889  decode.d8.loss_mask: 0.5141  decode.d8.loss_dice: 0.9755
11/15 12:42:28 - mmengine - INFO - Iter(train) [33850/90000]  base_lr: 6.5403e-05 lr: 6.5403e-06  eta: 9:25:48  time: 0.6035  data_time: 0.0105  memory: 10692  grad_norm: 381.2530  loss: 19.1053  decode.loss_cls: 0.0998  decode.loss_mask: 0.4364  decode.loss_dice: 1.3314  decode.d0.loss_cls: 0.0734  decode.d0.loss_mask: 0.4375  decode.d0.loss_dice: 1.4859  decode.d1.loss_cls: 0.0942  decode.d1.loss_mask: 0.4409  decode.d1.loss_dice: 1.4037  decode.d2.loss_cls: 0.1186  decode.d2.loss_mask: 0.4355  decode.d2.loss_dice: 1.3635  decode.d3.loss_cls: 0.1081  decode.d3.loss_mask: 0.4275  decode.d3.loss_dice: 1.3267  decode.d4.loss_cls: 0.1071  decode.d4.loss_mask: 0.4332  decode.d4.loss_dice: 1.3383  decode.d5.loss_cls: 0.0921  decode.d5.loss_mask: 0.4414  decode.d5.loss_dice: 1.3855  decode.d6.loss_cls: 0.0980  decode.d6.loss_mask: 0.4573  decode.d6.loss_dice: 1.3587  decode.d7.loss_cls: 0.0927  decode.d7.loss_mask: 0.4516  decode.d7.loss_dice: 1.3775  decode.d8.loss_cls: 0.1064  decode.d8.loss_mask: 0.4391  decode.d8.loss_dice: 1.3434
11/15 12:42:58 - mmengine - INFO - Iter(train) [33900/90000]  base_lr: 6.5351e-05 lr: 6.5351e-06  eta: 9:25:17  time: 0.6007  data_time: 0.0101  memory: 10713  grad_norm: 541.5766  loss: 16.3015  decode.loss_cls: 0.0547  decode.loss_mask: 0.4884  decode.loss_dice: 1.0494  decode.d0.loss_cls: 0.0722  decode.d0.loss_mask: 0.5299  decode.d0.loss_dice: 1.1549  decode.d1.loss_cls: 0.0648  decode.d1.loss_mask: 0.5209  decode.d1.loss_dice: 1.0897  decode.d2.loss_cls: 0.0624  decode.d2.loss_mask: 0.4962  decode.d2.loss_dice: 1.0449  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.4905  decode.d3.loss_dice: 1.0429  decode.d4.loss_cls: 0.0528  decode.d4.loss_mask: 0.4936  decode.d4.loss_dice: 1.0610  decode.d5.loss_cls: 0.0578  decode.d5.loss_mask: 0.4930  decode.d5.loss_dice: 1.0745  decode.d6.loss_cls: 0.0625  decode.d6.loss_mask: 0.4921  decode.d6.loss_dice: 1.0653  decode.d7.loss_cls: 0.0594  decode.d7.loss_mask: 0.4918  decode.d7.loss_dice: 1.0366  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.4946  decode.d8.loss_dice: 1.0861
11/15 12:43:28 - mmengine - INFO - Iter(train) [33950/90000]  base_lr: 6.5299e-05 lr: 6.5299e-06  eta: 9:24:47  time: 0.5998  data_time: 0.0103  memory: 10692  grad_norm: 374.4484  loss: 16.6511  decode.loss_cls: 0.0716  decode.loss_mask: 0.4728  decode.loss_dice: 1.1240  decode.d0.loss_cls: 0.1130  decode.d0.loss_mask: 0.4520  decode.d0.loss_dice: 1.2192  decode.d1.loss_cls: 0.0963  decode.d1.loss_mask: 0.4487  decode.d1.loss_dice: 1.1207  decode.d2.loss_cls: 0.1034  decode.d2.loss_mask: 0.4433  decode.d2.loss_dice: 1.1095  decode.d3.loss_cls: 0.0866  decode.d3.loss_mask: 0.4596  decode.d3.loss_dice: 1.0726  decode.d4.loss_cls: 0.0876  decode.d4.loss_mask: 0.4569  decode.d4.loss_dice: 1.1356  decode.d5.loss_cls: 0.0787  decode.d5.loss_mask: 0.4590  decode.d5.loss_dice: 1.1159  decode.d6.loss_cls: 0.0766  decode.d6.loss_mask: 0.4581  decode.d6.loss_dice: 1.0911  decode.d7.loss_cls: 0.0898  decode.d7.loss_mask: 0.4584  decode.d7.loss_dice: 1.1034  decode.d8.loss_cls: 0.0888  decode.d8.loss_mask: 0.4581  decode.d8.loss_dice: 1.0997
11/15 12:43:58 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 12:43:58 - mmengine - INFO - Iter(train) [34000/90000]  base_lr: 6.5246e-05 lr: 6.5246e-06  eta: 9:24:17  time: 0.6034  data_time: 0.0106  memory: 10675  grad_norm: 343.3407  loss: 16.6480  decode.loss_cls: 0.0644  decode.loss_mask: 0.4620  decode.loss_dice: 1.1285  decode.d0.loss_cls: 0.0821  decode.d0.loss_mask: 0.4763  decode.d0.loss_dice: 1.1829  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.4579  decode.d1.loss_dice: 1.1110  decode.d2.loss_cls: 0.0668  decode.d2.loss_mask: 0.4558  decode.d2.loss_dice: 1.1178  decode.d3.loss_cls: 0.0563  decode.d3.loss_mask: 0.4633  decode.d3.loss_dice: 1.1143  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 0.4712  decode.d4.loss_dice: 1.1396  decode.d5.loss_cls: 0.0492  decode.d5.loss_mask: 0.4715  decode.d5.loss_dice: 1.1292  decode.d6.loss_cls: 0.0467  decode.d6.loss_mask: 0.4832  decode.d6.loss_dice: 1.1464  decode.d7.loss_cls: 0.0505  decode.d7.loss_mask: 0.4773  decode.d7.loss_dice: 1.1345  decode.d8.loss_cls: 0.0503  decode.d8.loss_mask: 0.4715  decode.d8.loss_dice: 1.1639
11/15 12:44:29 - mmengine - INFO - Iter(train) [34050/90000]  base_lr: 6.5194e-05 lr: 6.5194e-06  eta: 9:23:46  time: 0.6059  data_time: 0.0106  memory: 10692  grad_norm: 525.3410  loss: 19.8924  decode.loss_cls: 0.0828  decode.loss_mask: 0.6528  decode.loss_dice: 1.2624  decode.d0.loss_cls: 0.1036  decode.d0.loss_mask: 0.6630  decode.d0.loss_dice: 1.3040  decode.d1.loss_cls: 0.0840  decode.d1.loss_mask: 0.6393  decode.d1.loss_dice: 1.2616  decode.d2.loss_cls: 0.0790  decode.d2.loss_mask: 0.6325  decode.d2.loss_dice: 1.2771  decode.d3.loss_cls: 0.0813  decode.d3.loss_mask: 0.6148  decode.d3.loss_dice: 1.2724  decode.d4.loss_cls: 0.0946  decode.d4.loss_mask: 0.6136  decode.d4.loss_dice: 1.2516  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 0.6091  decode.d5.loss_dice: 1.2731  decode.d6.loss_cls: 0.1034  decode.d6.loss_mask: 0.6201  decode.d6.loss_dice: 1.2529  decode.d7.loss_cls: 0.0843  decode.d7.loss_mask: 0.6425  decode.d7.loss_dice: 1.2843  decode.d8.loss_cls: 0.0831  decode.d8.loss_mask: 0.6243  decode.d8.loss_dice: 1.2586
11/15 12:44:59 - mmengine - INFO - Iter(train) [34100/90000]  base_lr: 6.5141e-05 lr: 6.5141e-06  eta: 9:23:16  time: 0.6028  data_time: 0.0104  memory: 10713  grad_norm: 700.2473  loss: 19.1357  decode.loss_cls: 0.0983  decode.loss_mask: 0.5983  decode.loss_dice: 1.1919  decode.d0.loss_cls: 0.0995  decode.d0.loss_mask: 0.6470  decode.d0.loss_dice: 1.2360  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.6262  decode.d1.loss_dice: 1.2363  decode.d2.loss_cls: 0.0709  decode.d2.loss_mask: 0.6064  decode.d2.loss_dice: 1.2070  decode.d3.loss_cls: 0.0834  decode.d3.loss_mask: 0.5938  decode.d3.loss_dice: 1.2092  decode.d4.loss_cls: 0.0811  decode.d4.loss_mask: 0.6292  decode.d4.loss_dice: 1.2048  decode.d5.loss_cls: 0.0816  decode.d5.loss_mask: 0.6206  decode.d5.loss_dice: 1.2284  decode.d6.loss_cls: 0.0716  decode.d6.loss_mask: 0.6218  decode.d6.loss_dice: 1.2212  decode.d7.loss_cls: 0.0825  decode.d7.loss_mask: 0.6050  decode.d7.loss_dice: 1.2158  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.6119  decode.d8.loss_dice: 1.2147
11/15 12:45:29 - mmengine - INFO - Iter(train) [34150/90000]  base_lr: 6.5089e-05 lr: 6.5089e-06  eta: 9:22:46  time: 0.6021  data_time: 0.0102  memory: 10675  grad_norm: 526.2435  loss: 18.2920  decode.loss_cls: 0.0621  decode.loss_mask: 0.6049  decode.loss_dice: 1.1737  decode.d0.loss_cls: 0.0891  decode.d0.loss_mask: 0.6236  decode.d0.loss_dice: 1.2044  decode.d1.loss_cls: 0.0893  decode.d1.loss_mask: 0.6010  decode.d1.loss_dice: 1.1636  decode.d2.loss_cls: 0.0613  decode.d2.loss_mask: 0.5956  decode.d2.loss_dice: 1.1666  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.5832  decode.d3.loss_dice: 1.1425  decode.d4.loss_cls: 0.0586  decode.d4.loss_mask: 0.5860  decode.d4.loss_dice: 1.1824  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.5826  decode.d5.loss_dice: 1.1377  decode.d6.loss_cls: 0.0609  decode.d6.loss_mask: 0.5988  decode.d6.loss_dice: 1.1551  decode.d7.loss_cls: 0.0688  decode.d7.loss_mask: 0.5838  decode.d7.loss_dice: 1.1891  decode.d8.loss_cls: 0.0670  decode.d8.loss_mask: 0.5827  decode.d8.loss_dice: 1.1567
11/15 12:45:59 - mmengine - INFO - Iter(train) [34200/90000]  base_lr: 6.5036e-05 lr: 6.5036e-06  eta: 9:22:15  time: 0.6035  data_time: 0.0105  memory: 10713  grad_norm: 309.9155  loss: 18.5963  decode.loss_cls: 0.1039  decode.loss_mask: 0.4773  decode.loss_dice: 1.2392  decode.d0.loss_cls: 0.1098  decode.d0.loss_mask: 0.4868  decode.d0.loss_dice: 1.3726  decode.d1.loss_cls: 0.1097  decode.d1.loss_mask: 0.4700  decode.d1.loss_dice: 1.3329  decode.d2.loss_cls: 0.1000  decode.d2.loss_mask: 0.4734  decode.d2.loss_dice: 1.2791  decode.d3.loss_cls: 0.0923  decode.d3.loss_mask: 0.4795  decode.d3.loss_dice: 1.2635  decode.d4.loss_cls: 0.0912  decode.d4.loss_mask: 0.4780  decode.d4.loss_dice: 1.2738  decode.d5.loss_cls: 0.1043  decode.d5.loss_mask: 0.4736  decode.d5.loss_dice: 1.2834  decode.d6.loss_cls: 0.1009  decode.d6.loss_mask: 0.4819  decode.d6.loss_dice: 1.2519  decode.d7.loss_cls: 0.0999  decode.d7.loss_mask: 0.4740  decode.d7.loss_dice: 1.2739  decode.d8.loss_cls: 0.0979  decode.d8.loss_mask: 0.4708  decode.d8.loss_dice: 1.2510
11/15 12:46:29 - mmengine - INFO - Iter(train) [34250/90000]  base_lr: 6.4984e-05 lr: 6.4984e-06  eta: 9:21:45  time: 0.6026  data_time: 0.0102  memory: 10656  grad_norm: 289.1787  loss: 18.2286  decode.loss_cls: 0.0853  decode.loss_mask: 0.5131  decode.loss_dice: 1.2199  decode.d0.loss_cls: 0.0875  decode.d0.loss_mask: 0.5242  decode.d0.loss_dice: 1.3152  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.4923  decode.d1.loss_dice: 1.2439  decode.d2.loss_cls: 0.0788  decode.d2.loss_mask: 0.5054  decode.d2.loss_dice: 1.2295  decode.d3.loss_cls: 0.0808  decode.d3.loss_mask: 0.4989  decode.d3.loss_dice: 1.2207  decode.d4.loss_cls: 0.0769  decode.d4.loss_mask: 0.4965  decode.d4.loss_dice: 1.2166  decode.d5.loss_cls: 0.0726  decode.d5.loss_mask: 0.4980  decode.d5.loss_dice: 1.2370  decode.d6.loss_cls: 0.0771  decode.d6.loss_mask: 0.5038  decode.d6.loss_dice: 1.2265  decode.d7.loss_cls: 0.0830  decode.d7.loss_mask: 0.5197  decode.d7.loss_dice: 1.2264  decode.d8.loss_cls: 0.0977  decode.d8.loss_mask: 0.5083  decode.d8.loss_dice: 1.2171
11/15 12:46:59 - mmengine - INFO - Iter(train) [34300/90000]  base_lr: 6.4932e-05 lr: 6.4932e-06  eta: 9:21:15  time: 0.6008  data_time: 0.0102  memory: 10692  grad_norm: 228.0797  loss: 19.1025  decode.loss_cls: 0.0842  decode.loss_mask: 0.6100  decode.loss_dice: 1.2380  decode.d0.loss_cls: 0.1113  decode.d0.loss_mask: 0.6196  decode.d0.loss_dice: 1.3030  decode.d1.loss_cls: 0.0951  decode.d1.loss_mask: 0.5737  decode.d1.loss_dice: 1.2305  decode.d2.loss_cls: 0.0752  decode.d2.loss_mask: 0.5888  decode.d2.loss_dice: 1.2396  decode.d3.loss_cls: 0.0829  decode.d3.loss_mask: 0.5726  decode.d3.loss_dice: 1.2332  decode.d4.loss_cls: 0.0827  decode.d4.loss_mask: 0.5918  decode.d4.loss_dice: 1.2389  decode.d5.loss_cls: 0.0771  decode.d5.loss_mask: 0.5733  decode.d5.loss_dice: 1.1935  decode.d6.loss_cls: 0.0828  decode.d6.loss_mask: 0.5801  decode.d6.loss_dice: 1.2445  decode.d7.loss_cls: 0.0778  decode.d7.loss_mask: 0.5780  decode.d7.loss_dice: 1.2171  decode.d8.loss_cls: 0.0796  decode.d8.loss_mask: 0.5869  decode.d8.loss_dice: 1.2407
11/15 12:47:30 - mmengine - INFO - Iter(train) [34350/90000]  base_lr: 6.4879e-05 lr: 6.4879e-06  eta: 9:20:44  time: 0.6032  data_time: 0.0114  memory: 10713  grad_norm: 318.7492  loss: 19.6583  decode.loss_cls: 0.0769  decode.loss_mask: 0.6383  decode.loss_dice: 1.2709  decode.d0.loss_cls: 0.0967  decode.d0.loss_mask: 0.6594  decode.d0.loss_dice: 1.3350  decode.d1.loss_cls: 0.0802  decode.d1.loss_mask: 0.6209  decode.d1.loss_dice: 1.2896  decode.d2.loss_cls: 0.0666  decode.d2.loss_mask: 0.6054  decode.d2.loss_dice: 1.2508  decode.d3.loss_cls: 0.0853  decode.d3.loss_mask: 0.6071  decode.d3.loss_dice: 1.2408  decode.d4.loss_cls: 0.0834  decode.d4.loss_mask: 0.6108  decode.d4.loss_dice: 1.2433  decode.d5.loss_cls: 0.0814  decode.d5.loss_mask: 0.6181  decode.d5.loss_dice: 1.2481  decode.d6.loss_cls: 0.0844  decode.d6.loss_mask: 0.6111  decode.d6.loss_dice: 1.2198  decode.d7.loss_cls: 0.0839  decode.d7.loss_mask: 0.6085  decode.d7.loss_dice: 1.2518  decode.d8.loss_cls: 0.0813  decode.d8.loss_mask: 0.6328  decode.d8.loss_dice: 1.2756
11/15 12:48:00 - mmengine - INFO - Iter(train) [34400/90000]  base_lr: 6.4827e-05 lr: 6.4827e-06  eta: 9:20:14  time: 0.6019  data_time: 0.0104  memory: 10675  grad_norm: 369.5311  loss: 18.5588  decode.loss_cls: 0.0652  decode.loss_mask: 0.5556  decode.loss_dice: 1.1947  decode.d0.loss_cls: 0.0916  decode.d0.loss_mask: 0.5838  decode.d0.loss_dice: 1.2652  decode.d1.loss_cls: 0.0603  decode.d1.loss_mask: 0.5733  decode.d1.loss_dice: 1.2313  decode.d2.loss_cls: 0.0776  decode.d2.loss_mask: 0.5793  decode.d2.loss_dice: 1.1817  decode.d3.loss_cls: 0.0683  decode.d3.loss_mask: 0.5984  decode.d3.loss_dice: 1.1794  decode.d4.loss_cls: 0.0750  decode.d4.loss_mask: 0.5982  decode.d4.loss_dice: 1.2080  decode.d5.loss_cls: 0.0674  decode.d5.loss_mask: 0.6055  decode.d5.loss_dice: 1.1932  decode.d6.loss_cls: 0.0642  decode.d6.loss_mask: 0.5910  decode.d6.loss_dice: 1.1899  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.5795  decode.d7.loss_dice: 1.1817  decode.d8.loss_cls: 0.0633  decode.d8.loss_mask: 0.5601  decode.d8.loss_dice: 1.2102
11/15 12:48:30 - mmengine - INFO - Iter(train) [34450/90000]  base_lr: 6.4774e-05 lr: 6.4774e-06  eta: 9:19:43  time: 0.6018  data_time: 0.0103  memory: 10713  grad_norm: 507.8184  loss: 17.0967  decode.loss_cls: 0.0838  decode.loss_mask: 0.5290  decode.loss_dice: 1.0809  decode.d0.loss_cls: 0.0960  decode.d0.loss_mask: 0.5320  decode.d0.loss_dice: 1.1627  decode.d1.loss_cls: 0.0530  decode.d1.loss_mask: 0.5663  decode.d1.loss_dice: 1.1406  decode.d2.loss_cls: 0.0647  decode.d2.loss_mask: 0.5461  decode.d2.loss_dice: 1.1050  decode.d3.loss_cls: 0.0786  decode.d3.loss_mask: 0.5206  decode.d3.loss_dice: 1.0445  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.5449  decode.d4.loss_dice: 1.0866  decode.d5.loss_cls: 0.0592  decode.d5.loss_mask: 0.5447  decode.d5.loss_dice: 1.0892  decode.d6.loss_cls: 0.0593  decode.d6.loss_mask: 0.5443  decode.d6.loss_dice: 1.0920  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.5414  decode.d7.loss_dice: 1.0984  decode.d8.loss_cls: 0.0740  decode.d8.loss_mask: 0.5395  decode.d8.loss_dice: 1.0982
11/15 12:49:00 - mmengine - INFO - Iter(train) [34500/90000]  base_lr: 6.4722e-05 lr: 6.4722e-06  eta: 9:19:13  time: 0.5999  data_time: 0.0105  memory: 10713  grad_norm: 520.5160  loss: 16.8876  decode.loss_cls: 0.0702  decode.loss_mask: 0.5015  decode.loss_dice: 1.1156  decode.d0.loss_cls: 0.1077  decode.d0.loss_mask: 0.5303  decode.d0.loss_dice: 1.1556  decode.d1.loss_cls: 0.0768  decode.d1.loss_mask: 0.5067  decode.d1.loss_dice: 1.1172  decode.d2.loss_cls: 0.0652  decode.d2.loss_mask: 0.4983  decode.d2.loss_dice: 1.0601  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.5079  decode.d3.loss_dice: 1.1002  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.5017  decode.d4.loss_dice: 1.1372  decode.d5.loss_cls: 0.0661  decode.d5.loss_mask: 0.5032  decode.d5.loss_dice: 1.0918  decode.d6.loss_cls: 0.0602  decode.d6.loss_mask: 0.5050  decode.d6.loss_dice: 1.1291  decode.d7.loss_cls: 0.0554  decode.d7.loss_mask: 0.5029  decode.d7.loss_dice: 1.1476  decode.d8.loss_cls: 0.0529  decode.d8.loss_mask: 0.4999  decode.d8.loss_dice: 1.0999
11/15 12:49:30 - mmengine - INFO - Iter(train) [34550/90000]  base_lr: 6.4669e-05 lr: 6.4669e-06  eta: 9:18:42  time: 0.6006  data_time: 0.0102  memory: 10675  grad_norm: 283.5524  loss: 16.8658  decode.loss_cls: 0.0694  decode.loss_mask: 0.4923  decode.loss_dice: 1.0931  decode.d0.loss_cls: 0.0835  decode.d0.loss_mask: 0.5321  decode.d0.loss_dice: 1.1665  decode.d1.loss_cls: 0.0896  decode.d1.loss_mask: 0.4972  decode.d1.loss_dice: 1.1275  decode.d2.loss_cls: 0.0809  decode.d2.loss_mask: 0.5066  decode.d2.loss_dice: 1.1096  decode.d3.loss_cls: 0.0929  decode.d3.loss_mask: 0.5059  decode.d3.loss_dice: 1.1043  decode.d4.loss_cls: 0.0853  decode.d4.loss_mask: 0.5036  decode.d4.loss_dice: 1.0750  decode.d5.loss_cls: 0.0827  decode.d5.loss_mask: 0.5038  decode.d5.loss_dice: 1.0784  decode.d6.loss_cls: 0.0864  decode.d6.loss_mask: 0.4892  decode.d6.loss_dice: 1.0797  decode.d7.loss_cls: 0.0830  decode.d7.loss_mask: 0.4851  decode.d7.loss_dice: 1.0965  decode.d8.loss_cls: 0.0689  decode.d8.loss_mask: 0.4908  decode.d8.loss_dice: 1.1059
11/15 12:50:00 - mmengine - INFO - Iter(train) [34600/90000]  base_lr: 6.4617e-05 lr: 6.4617e-06  eta: 9:18:12  time: 0.6009  data_time: 0.0103  memory: 10675  grad_norm: 446.3097  loss: 16.1258  decode.loss_cls: 0.0629  decode.loss_mask: 0.5330  decode.loss_dice: 1.0174  decode.d0.loss_cls: 0.0728  decode.d0.loss_mask: 0.5406  decode.d0.loss_dice: 1.0186  decode.d1.loss_cls: 0.0552  decode.d1.loss_mask: 0.5239  decode.d1.loss_dice: 1.0175  decode.d2.loss_cls: 0.0531  decode.d2.loss_mask: 0.5426  decode.d2.loss_dice: 1.0417  decode.d3.loss_cls: 0.0549  decode.d3.loss_mask: 0.5376  decode.d3.loss_dice: 1.0088  decode.d4.loss_cls: 0.0547  decode.d4.loss_mask: 0.5365  decode.d4.loss_dice: 1.0158  decode.d5.loss_cls: 0.0515  decode.d5.loss_mask: 0.5342  decode.d5.loss_dice: 1.0302  decode.d6.loss_cls: 0.0556  decode.d6.loss_mask: 0.5296  decode.d6.loss_dice: 1.0147  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.5286  decode.d7.loss_dice: 1.0338  decode.d8.loss_cls: 0.0607  decode.d8.loss_mask: 0.5282  decode.d8.loss_dice: 1.0175
11/15 12:50:30 - mmengine - INFO - Iter(train) [34650/90000]  base_lr: 6.4564e-05 lr: 6.4564e-06  eta: 9:17:42  time: 0.6077  data_time: 0.0126  memory: 10728  grad_norm: 735.3601  loss: 19.2507  decode.loss_cls: 0.0818  decode.loss_mask: 0.5603  decode.loss_dice: 1.2572  decode.d0.loss_cls: 0.0926  decode.d0.loss_mask: 0.5489  decode.d0.loss_dice: 1.3966  decode.d1.loss_cls: 0.0639  decode.d1.loss_mask: 0.5641  decode.d1.loss_dice: 1.3249  decode.d2.loss_cls: 0.0755  decode.d2.loss_mask: 0.5626  decode.d2.loss_dice: 1.2944  decode.d3.loss_cls: 0.1031  decode.d3.loss_mask: 0.5284  decode.d3.loss_dice: 1.2384  decode.d4.loss_cls: 0.0745  decode.d4.loss_mask: 0.5391  decode.d4.loss_dice: 1.3037  decode.d5.loss_cls: 0.0861  decode.d5.loss_mask: 0.5367  decode.d5.loss_dice: 1.3081  decode.d6.loss_cls: 0.0849  decode.d6.loss_mask: 0.5374  decode.d6.loss_dice: 1.2780  decode.d7.loss_cls: 0.0701  decode.d7.loss_mask: 0.5451  decode.d7.loss_dice: 1.2706  decode.d8.loss_cls: 0.0818  decode.d8.loss_mask: 0.5550  decode.d8.loss_dice: 1.2868
11/15 12:51:00 - mmengine - INFO - Iter(train) [34700/90000]  base_lr: 6.4512e-05 lr: 6.4512e-06  eta: 9:17:11  time: 0.6063  data_time: 0.0106  memory: 10728  grad_norm: 380.2375  loss: 14.9438  decode.loss_cls: 0.0704  decode.loss_mask: 0.4271  decode.loss_dice: 0.9651  decode.d0.loss_cls: 0.0999  decode.d0.loss_mask: 0.4238  decode.d0.loss_dice: 1.0595  decode.d1.loss_cls: 0.0904  decode.d1.loss_mask: 0.4216  decode.d1.loss_dice: 0.9886  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.4505  decode.d2.loss_dice: 1.0089  decode.d3.loss_cls: 0.0737  decode.d3.loss_mask: 0.4515  decode.d3.loss_dice: 0.9738  decode.d4.loss_cls: 0.0748  decode.d4.loss_mask: 0.4364  decode.d4.loss_dice: 0.9848  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.4289  decode.d5.loss_dice: 0.9638  decode.d6.loss_cls: 0.0780  decode.d6.loss_mask: 0.4199  decode.d6.loss_dice: 0.9685  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.4198  decode.d7.loss_dice: 0.9643  decode.d8.loss_cls: 0.0693  decode.d8.loss_mask: 0.4242  decode.d8.loss_dice: 0.9750
11/15 12:51:30 - mmengine - INFO - Iter(train) [34750/90000]  base_lr: 6.4459e-05 lr: 6.4459e-06  eta: 9:16:41  time: 0.5988  data_time: 0.0103  memory: 10675  grad_norm: 340.1471  loss: 16.8508  decode.loss_cls: 0.0922  decode.loss_mask: 0.4768  decode.loss_dice: 1.1139  decode.d0.loss_cls: 0.1025  decode.d0.loss_mask: 0.4953  decode.d0.loss_dice: 1.1713  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.4895  decode.d1.loss_dice: 1.1457  decode.d2.loss_cls: 0.0853  decode.d2.loss_mask: 0.5000  decode.d2.loss_dice: 1.1574  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.4907  decode.d3.loss_dice: 1.1004  decode.d4.loss_cls: 0.0843  decode.d4.loss_mask: 0.4863  decode.d4.loss_dice: 1.1031  decode.d5.loss_cls: 0.0934  decode.d5.loss_mask: 0.4805  decode.d5.loss_dice: 1.0580  decode.d6.loss_cls: 0.0841  decode.d6.loss_mask: 0.4822  decode.d6.loss_dice: 1.0837  decode.d7.loss_cls: 0.0885  decode.d7.loss_mask: 0.4775  decode.d7.loss_dice: 1.0941  decode.d8.loss_cls: 0.0737  decode.d8.loss_mask: 0.4849  decode.d8.loss_dice: 1.0975
11/15 12:52:01 - mmengine - INFO - Iter(train) [34800/90000]  base_lr: 6.4407e-05 lr: 6.4407e-06  eta: 9:16:11  time: 0.6070  data_time: 0.0106  memory: 10675  grad_norm: 321.4981  loss: 17.9789  decode.loss_cls: 0.0590  decode.loss_mask: 0.5640  decode.loss_dice: 1.1733  decode.d0.loss_cls: 0.0732  decode.d0.loss_mask: 0.5715  decode.d0.loss_dice: 1.2320  decode.d1.loss_cls: 0.0530  decode.d1.loss_mask: 0.5603  decode.d1.loss_dice: 1.2096  decode.d2.loss_cls: 0.0567  decode.d2.loss_mask: 0.5530  decode.d2.loss_dice: 1.1618  decode.d3.loss_cls: 0.0556  decode.d3.loss_mask: 0.5655  decode.d3.loss_dice: 1.1555  decode.d4.loss_cls: 0.0577  decode.d4.loss_mask: 0.5612  decode.d4.loss_dice: 1.1764  decode.d5.loss_cls: 0.0556  decode.d5.loss_mask: 0.5678  decode.d5.loss_dice: 1.1592  decode.d6.loss_cls: 0.0606  decode.d6.loss_mask: 0.5633  decode.d6.loss_dice: 1.1457  decode.d7.loss_cls: 0.0491  decode.d7.loss_mask: 0.5691  decode.d7.loss_dice: 1.1904  decode.d8.loss_cls: 0.0548  decode.d8.loss_mask: 0.5644  decode.d8.loss_dice: 1.1597
11/15 12:52:31 - mmengine - INFO - Iter(train) [34850/90000]  base_lr: 6.4354e-05 lr: 6.4354e-06  eta: 9:15:40  time: 0.6006  data_time: 0.0105  memory: 10675  grad_norm: 544.9166  loss: 16.8494  decode.loss_cls: 0.0561  decode.loss_mask: 0.5257  decode.loss_dice: 1.0681  decode.d0.loss_cls: 0.0662  decode.d0.loss_mask: 0.5411  decode.d0.loss_dice: 1.1524  decode.d1.loss_cls: 0.0365  decode.d1.loss_mask: 0.5209  decode.d1.loss_dice: 1.1243  decode.d2.loss_cls: 0.0422  decode.d2.loss_mask: 0.5211  decode.d2.loss_dice: 1.1185  decode.d3.loss_cls: 0.0273  decode.d3.loss_mask: 0.5337  decode.d3.loss_dice: 1.1377  decode.d4.loss_cls: 0.0475  decode.d4.loss_mask: 0.5246  decode.d4.loss_dice: 1.1283  decode.d5.loss_cls: 0.0488  decode.d5.loss_mask: 0.5209  decode.d5.loss_dice: 1.1150  decode.d6.loss_cls: 0.0496  decode.d6.loss_mask: 0.5237  decode.d6.loss_dice: 1.1044  decode.d7.loss_cls: 0.0411  decode.d7.loss_mask: 0.5238  decode.d7.loss_dice: 1.0946  decode.d8.loss_cls: 0.0503  decode.d8.loss_mask: 0.5261  decode.d8.loss_dice: 1.0790
11/15 12:53:01 - mmengine - INFO - Iter(train) [34900/90000]  base_lr: 6.4302e-05 lr: 6.4302e-06  eta: 9:15:10  time: 0.6033  data_time: 0.0106  memory: 10692  grad_norm: 539.1164  loss: 17.1440  decode.loss_cls: 0.0531  decode.loss_mask: 0.5794  decode.loss_dice: 1.0459  decode.d0.loss_cls: 0.0827  decode.d0.loss_mask: 0.6082  decode.d0.loss_dice: 1.1643  decode.d1.loss_cls: 0.0651  decode.d1.loss_mask: 0.5841  decode.d1.loss_dice: 1.0899  decode.d2.loss_cls: 0.0542  decode.d2.loss_mask: 0.5895  decode.d2.loss_dice: 1.0717  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.5679  decode.d3.loss_dice: 1.0198  decode.d4.loss_cls: 0.0586  decode.d4.loss_mask: 0.5788  decode.d4.loss_dice: 1.0522  decode.d5.loss_cls: 0.0683  decode.d5.loss_mask: 0.5713  decode.d5.loss_dice: 1.0716  decode.d6.loss_cls: 0.0664  decode.d6.loss_mask: 0.5788  decode.d6.loss_dice: 1.0602  decode.d7.loss_cls: 0.0627  decode.d7.loss_mask: 0.5769  decode.d7.loss_dice: 1.0644  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.5769  decode.d8.loss_dice: 1.0642
11/15 12:53:31 - mmengine - INFO - Iter(train) [34950/90000]  base_lr: 6.4249e-05 lr: 6.4249e-06  eta: 9:14:40  time: 0.6087  data_time: 0.0120  memory: 10713  grad_norm: 503.2294  loss: 16.1268  decode.loss_cls: 0.0607  decode.loss_mask: 0.5460  decode.loss_dice: 1.0012  decode.d0.loss_cls: 0.0897  decode.d0.loss_mask: 0.5519  decode.d0.loss_dice: 1.1008  decode.d1.loss_cls: 0.0573  decode.d1.loss_mask: 0.5477  decode.d1.loss_dice: 1.0513  decode.d2.loss_cls: 0.0572  decode.d2.loss_mask: 0.5317  decode.d2.loss_dice: 1.0108  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.5351  decode.d3.loss_dice: 0.9942  decode.d4.loss_cls: 0.0483  decode.d4.loss_mask: 0.5304  decode.d4.loss_dice: 1.0006  decode.d5.loss_cls: 0.0535  decode.d5.loss_mask: 0.5273  decode.d5.loss_dice: 1.0078  decode.d6.loss_cls: 0.0505  decode.d6.loss_mask: 0.5325  decode.d6.loss_dice: 0.9713  decode.d7.loss_cls: 0.0377  decode.d7.loss_mask: 0.5495  decode.d7.loss_dice: 1.0171  decode.d8.loss_cls: 0.0460  decode.d8.loss_mask: 0.5440  decode.d8.loss_dice: 1.0170
11/15 12:54:02 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 12:54:02 - mmengine - INFO - Iter(train) [35000/90000]  base_lr: 6.4197e-05 lr: 6.4197e-06  eta: 9:14:10  time: 0.6052  data_time: 0.0106  memory: 10728  grad_norm: 438.2213  loss: 16.2623  decode.loss_cls: 0.0561  decode.loss_mask: 0.5228  decode.loss_dice: 1.0297  decode.d0.loss_cls: 0.0928  decode.d0.loss_mask: 0.5770  decode.d0.loss_dice: 1.0719  decode.d1.loss_cls: 0.0598  decode.d1.loss_mask: 0.5665  decode.d1.loss_dice: 1.0488  decode.d2.loss_cls: 0.0593  decode.d2.loss_mask: 0.5314  decode.d2.loss_dice: 1.0159  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.5290  decode.d3.loss_dice: 1.0138  decode.d4.loss_cls: 0.0615  decode.d4.loss_mask: 0.5280  decode.d4.loss_dice: 1.0043  decode.d5.loss_cls: 0.0506  decode.d5.loss_mask: 0.5327  decode.d5.loss_dice: 1.0191  decode.d6.loss_cls: 0.0477  decode.d6.loss_mask: 0.5289  decode.d6.loss_dice: 1.0429  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.5257  decode.d7.loss_dice: 1.0281  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.5362  decode.d8.loss_dice: 1.0192
11/15 12:54:02 - mmengine - INFO - Saving checkpoint at 35000 iterations
11/15 12:54:21 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:22  time: 0.3086  data_time: 0.0040  memory: 4095  
11/15 12:54:36 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:05  time: 0.3089  data_time: 0.0039  memory: 4095  
11/15 12:54:52 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:49  time: 0.3095  data_time: 0.0040  memory: 4095  
11/15 12:55:07 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3091  data_time: 0.0039  memory: 4095  
11/15 12:55:23 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3096  data_time: 0.0042  memory: 4095  
11/15 12:55:38 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:02  time: 0.3092  data_time: 0.0042  memory: 4095  
11/15 12:55:54 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3092  data_time: 0.0040  memory: 4095  
11/15 12:56:09 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:31  time: 0.3096  data_time: 0.0040  memory: 4095  
11/15 12:56:25 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3095  data_time: 0.0041  memory: 4095  
11/15 12:56:40 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3093  data_time: 0.0038  memory: 4095  
11/15 12:56:40 - mmengine - INFO - per class results:
11/15 12:56:40 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 98.21 | 98.75 |
|    sidewalk   | 85.17 | 94.22 |
|    building   | 92.64 | 96.27 |
|      wall     | 58.72 |  75.3 |
|     fence     | 59.27 | 71.62 |
|      pole     |  66.2 | 77.96 |
| traffic light |  70.5 | 82.45 |
|  traffic sign | 80.52 | 86.35 |
|   vegetation  | 92.38 | 96.89 |
|    terrain    | 60.87 | 67.79 |
|      sky      | 93.89 | 95.41 |
|     person    | 81.88 | 89.22 |
|     rider     | 61.64 | 80.37 |
|      car      | 95.16 | 97.59 |
|     truck     | 80.55 | 91.99 |
|      bus      | 76.31 | 79.28 |
|     train     | 51.73 | 85.66 |
|   motorcycle  | 61.35 | 85.43 |
|    bicycle    | 77.42 | 89.52 |
+---------------+-------+-------+
11/15 12:56:40 - mmengine - INFO - Iter(val) [500/500]    aAcc: 96.0200  mIoU: 76.0200  mAcc: 86.4200  data_time: 0.0046  time: 0.3103
11/15 12:56:40 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024/best_mIoU_iter_30000.pth is removed
11/15 12:56:42 - mmengine - INFO - The best checkpoint with 76.0200 mIoU at 35000 iter is saved to best_mIoU_iter_35000.pth.
11/15 12:57:15 - mmengine - INFO - Iter(train) [35050/90000]  base_lr: 6.4144e-05 lr: 6.4144e-06  eta: 9:13:47  time: 0.6017  data_time: 0.0102  memory: 10692  grad_norm: 433.2608  loss: 17.3632  decode.loss_cls: 0.0616  decode.loss_mask: 0.4988  decode.loss_dice: 1.1574  decode.d0.loss_cls: 0.0859  decode.d0.loss_mask: 0.5201  decode.d0.loss_dice: 1.2452  decode.d1.loss_cls: 0.0617  decode.d1.loss_mask: 0.4873  decode.d1.loss_dice: 1.2204  decode.d2.loss_cls: 0.0548  decode.d2.loss_mask: 0.4877  decode.d2.loss_dice: 1.1741  decode.d3.loss_cls: 0.0568  decode.d3.loss_mask: 0.4901  decode.d3.loss_dice: 1.1679  decode.d4.loss_cls: 0.0564  decode.d4.loss_mask: 0.4916  decode.d4.loss_dice: 1.1891  decode.d5.loss_cls: 0.0601  decode.d5.loss_mask: 0.4944  decode.d5.loss_dice: 1.1426  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.4975  decode.d6.loss_dice: 1.1402  decode.d7.loss_cls: 0.0675  decode.d7.loss_mask: 0.5050  decode.d7.loss_dice: 1.1646  decode.d8.loss_cls: 0.0581  decode.d8.loss_mask: 0.4944  decode.d8.loss_dice: 1.1747
11/15 12:57:45 - mmengine - INFO - Iter(train) [35100/90000]  base_lr: 6.4092e-05 lr: 6.4092e-06  eta: 9:13:17  time: 0.6030  data_time: 0.0105  memory: 10692  grad_norm: 296.8858  loss: 16.9878  decode.loss_cls: 0.0586  decode.loss_mask: 0.6000  decode.loss_dice: 1.0494  decode.d0.loss_cls: 0.0766  decode.d0.loss_mask: 0.5978  decode.d0.loss_dice: 1.0859  decode.d1.loss_cls: 0.0575  decode.d1.loss_mask: 0.5756  decode.d1.loss_dice: 1.0495  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.5773  decode.d2.loss_dice: 1.0314  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.5782  decode.d3.loss_dice: 1.0426  decode.d4.loss_cls: 0.0666  decode.d4.loss_mask: 0.5793  decode.d4.loss_dice: 1.0310  decode.d5.loss_cls: 0.0598  decode.d5.loss_mask: 0.5856  decode.d5.loss_dice: 1.0409  decode.d6.loss_cls: 0.0593  decode.d6.loss_mask: 0.5865  decode.d6.loss_dice: 1.0638  decode.d7.loss_cls: 0.0774  decode.d7.loss_mask: 0.5862  decode.d7.loss_dice: 1.0186  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.5957  decode.d8.loss_dice: 1.0696
11/15 12:58:16 - mmengine - INFO - Iter(train) [35150/90000]  base_lr: 6.4039e-05 lr: 6.4039e-06  eta: 9:12:46  time: 0.5993  data_time: 0.0101  memory: 10713  grad_norm: 1406.5822  loss: 17.8939  decode.loss_cls: 0.0723  decode.loss_mask: 0.6980  decode.loss_dice: 0.9960  decode.d0.loss_cls: 0.0904  decode.d0.loss_mask: 0.7866  decode.d0.loss_dice: 1.0779  decode.d1.loss_cls: 0.0791  decode.d1.loss_mask: 0.7047  decode.d1.loss_dice: 1.0113  decode.d2.loss_cls: 0.0617  decode.d2.loss_mask: 0.7303  decode.d2.loss_dice: 1.0030  decode.d3.loss_cls: 0.0594  decode.d3.loss_mask: 0.7268  decode.d3.loss_dice: 0.9897  decode.d4.loss_cls: 0.0643  decode.d4.loss_mask: 0.7080  decode.d4.loss_dice: 0.9915  decode.d5.loss_cls: 0.0680  decode.d5.loss_mask: 0.7038  decode.d5.loss_dice: 1.0034  decode.d6.loss_cls: 0.0705  decode.d6.loss_mask: 0.7011  decode.d6.loss_dice: 0.9867  decode.d7.loss_cls: 0.0739  decode.d7.loss_mask: 0.6991  decode.d7.loss_dice: 0.9924  decode.d8.loss_cls: 0.0729  decode.d8.loss_mask: 0.6884  decode.d8.loss_dice: 0.9827
11/15 12:58:46 - mmengine - INFO - Iter(train) [35200/90000]  base_lr: 6.3987e-05 lr: 6.3987e-06  eta: 9:12:16  time: 0.6016  data_time: 0.0103  memory: 10692  grad_norm: 334.4600  loss: 17.4078  decode.loss_cls: 0.0847  decode.loss_mask: 0.5061  decode.loss_dice: 1.1331  decode.d0.loss_cls: 0.1005  decode.d0.loss_mask: 0.5360  decode.d0.loss_dice: 1.2787  decode.d1.loss_cls: 0.0887  decode.d1.loss_mask: 0.4979  decode.d1.loss_dice: 1.1715  decode.d2.loss_cls: 0.0973  decode.d2.loss_mask: 0.5083  decode.d2.loss_dice: 1.0920  decode.d3.loss_cls: 0.0888  decode.d3.loss_mask: 0.5044  decode.d3.loss_dice: 1.1533  decode.d4.loss_cls: 0.0982  decode.d4.loss_mask: 0.4955  decode.d4.loss_dice: 1.1101  decode.d5.loss_cls: 0.0871  decode.d5.loss_mask: 0.4948  decode.d5.loss_dice: 1.1048  decode.d6.loss_cls: 0.0880  decode.d6.loss_mask: 0.5019  decode.d6.loss_dice: 1.1206  decode.d7.loss_cls: 0.0941  decode.d7.loss_mask: 0.5032  decode.d7.loss_dice: 1.1263  decode.d8.loss_cls: 0.0936  decode.d8.loss_mask: 0.5184  decode.d8.loss_dice: 1.1297
11/15 12:59:16 - mmengine - INFO - Iter(train) [35250/90000]  base_lr: 6.3934e-05 lr: 6.3934e-06  eta: 9:11:46  time: 0.6094  data_time: 0.0105  memory: 10656  grad_norm: 566.1841  loss: 19.3947  decode.loss_cls: 0.0586  decode.loss_mask: 0.6407  decode.loss_dice: 1.2655  decode.d0.loss_cls: 0.0637  decode.d0.loss_mask: 0.6860  decode.d0.loss_dice: 1.2761  decode.d1.loss_cls: 0.0621  decode.d1.loss_mask: 0.6360  decode.d1.loss_dice: 1.2262  decode.d2.loss_cls: 0.0548  decode.d2.loss_mask: 0.6367  decode.d2.loss_dice: 1.2169  decode.d3.loss_cls: 0.0653  decode.d3.loss_mask: 0.6226  decode.d3.loss_dice: 1.2169  decode.d4.loss_cls: 0.0555  decode.d4.loss_mask: 0.6428  decode.d4.loss_dice: 1.2289  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.6354  decode.d5.loss_dice: 1.2218  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.6392  decode.d6.loss_dice: 1.2332  decode.d7.loss_cls: 0.0579  decode.d7.loss_mask: 0.6463  decode.d7.loss_dice: 1.2286  decode.d8.loss_cls: 0.0478  decode.d8.loss_mask: 0.6449  decode.d8.loss_dice: 1.2623
11/15 12:59:46 - mmengine - INFO - Iter(train) [35300/90000]  base_lr: 6.3881e-05 lr: 6.3881e-06  eta: 9:11:16  time: 0.6070  data_time: 0.0105  memory: 10656  grad_norm: 326.5558  loss: 17.4521  decode.loss_cls: 0.0816  decode.loss_mask: 0.5145  decode.loss_dice: 1.1354  decode.d0.loss_cls: 0.0868  decode.d0.loss_mask: 0.5451  decode.d0.loss_dice: 1.2283  decode.d1.loss_cls: 0.0833  decode.d1.loss_mask: 0.5243  decode.d1.loss_dice: 1.1462  decode.d2.loss_cls: 0.0822  decode.d2.loss_mask: 0.5170  decode.d2.loss_dice: 1.1610  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.5083  decode.d3.loss_dice: 1.1287  decode.d4.loss_cls: 0.0762  decode.d4.loss_mask: 0.5032  decode.d4.loss_dice: 1.1280  decode.d5.loss_cls: 0.0719  decode.d5.loss_mask: 0.5228  decode.d5.loss_dice: 1.1741  decode.d6.loss_cls: 0.0719  decode.d6.loss_mask: 0.5181  decode.d6.loss_dice: 1.1220  decode.d7.loss_cls: 0.0768  decode.d7.loss_mask: 0.5229  decode.d7.loss_dice: 1.1273  decode.d8.loss_cls: 0.0714  decode.d8.loss_mask: 0.5106  decode.d8.loss_dice: 1.1383
11/15 13:00:17 - mmengine - INFO - Iter(train) [35350/90000]  base_lr: 6.3829e-05 lr: 6.3829e-06  eta: 9:10:46  time: 0.6068  data_time: 0.0107  memory: 10728  grad_norm: 344.0840  loss: 18.0851  decode.loss_cls: 0.0635  decode.loss_mask: 0.5029  decode.loss_dice: 1.2006  decode.d0.loss_cls: 0.0955  decode.d0.loss_mask: 0.5164  decode.d0.loss_dice: 1.3056  decode.d1.loss_cls: 0.0929  decode.d1.loss_mask: 0.5044  decode.d1.loss_dice: 1.2581  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.4966  decode.d2.loss_dice: 1.2125  decode.d3.loss_cls: 0.0720  decode.d3.loss_mask: 0.4991  decode.d3.loss_dice: 1.2115  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.4988  decode.d4.loss_dice: 1.2074  decode.d5.loss_cls: 0.0880  decode.d5.loss_mask: 0.4906  decode.d5.loss_dice: 1.2067  decode.d6.loss_cls: 0.0662  decode.d6.loss_mask: 0.4999  decode.d6.loss_dice: 1.2384  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.5035  decode.d7.loss_dice: 1.2260  decode.d8.loss_cls: 0.0654  decode.d8.loss_mask: 0.5087  decode.d8.loss_dice: 1.2510
11/15 13:00:47 - mmengine - INFO - Iter(train) [35400/90000]  base_lr: 6.3776e-05 lr: 6.3776e-06  eta: 9:10:16  time: 0.6082  data_time: 0.0105  memory: 10675  grad_norm: 356.1345  loss: 17.9289  decode.loss_cls: 0.0531  decode.loss_mask: 0.5692  decode.loss_dice: 1.1643  decode.d0.loss_cls: 0.0740  decode.d0.loss_mask: 0.5861  decode.d0.loss_dice: 1.2447  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.5622  decode.d1.loss_dice: 1.1886  decode.d2.loss_cls: 0.0653  decode.d2.loss_mask: 0.5556  decode.d2.loss_dice: 1.1602  decode.d3.loss_cls: 0.0639  decode.d3.loss_mask: 0.5535  decode.d3.loss_dice: 1.1479  decode.d4.loss_cls: 0.0503  decode.d4.loss_mask: 0.5600  decode.d4.loss_dice: 1.1675  decode.d5.loss_cls: 0.0565  decode.d5.loss_mask: 0.5577  decode.d5.loss_dice: 1.1425  decode.d6.loss_cls: 0.0594  decode.d6.loss_mask: 0.5557  decode.d6.loss_dice: 1.1378  decode.d7.loss_cls: 0.0676  decode.d7.loss_mask: 0.5538  decode.d7.loss_dice: 1.1589  decode.d8.loss_cls: 0.0601  decode.d8.loss_mask: 0.5651  decode.d8.loss_dice: 1.1850
11/15 13:01:18 - mmengine - INFO - Iter(train) [35450/90000]  base_lr: 6.3724e-05 lr: 6.3724e-06  eta: 9:09:46  time: 0.6132  data_time: 0.0108  memory: 10675  grad_norm: 463.6128  loss: 16.6943  decode.loss_cls: 0.0621  decode.loss_mask: 0.5373  decode.loss_dice: 1.0687  decode.d0.loss_cls: 0.0941  decode.d0.loss_mask: 0.5488  decode.d0.loss_dice: 1.1091  decode.d1.loss_cls: 0.0515  decode.d1.loss_mask: 0.5358  decode.d1.loss_dice: 1.0967  decode.d2.loss_cls: 0.0508  decode.d2.loss_mask: 0.5296  decode.d2.loss_dice: 1.0915  decode.d3.loss_cls: 0.0475  decode.d3.loss_mask: 0.5345  decode.d3.loss_dice: 1.0528  decode.d4.loss_cls: 0.0520  decode.d4.loss_mask: 0.5392  decode.d4.loss_dice: 1.0577  decode.d5.loss_cls: 0.0449  decode.d5.loss_mask: 0.5442  decode.d5.loss_dice: 1.0801  decode.d6.loss_cls: 0.0438  decode.d6.loss_mask: 0.5457  decode.d6.loss_dice: 1.0667  decode.d7.loss_cls: 0.0426  decode.d7.loss_mask: 0.5413  decode.d7.loss_dice: 1.0785  decode.d8.loss_cls: 0.0533  decode.d8.loss_mask: 0.5418  decode.d8.loss_dice: 1.0517
11/15 13:01:49 - mmengine - INFO - Iter(train) [35500/90000]  base_lr: 6.3671e-05 lr: 6.3671e-06  eta: 9:09:17  time: 0.6115  data_time: 0.0109  memory: 10728  grad_norm: 382.6891  loss: 16.7639  decode.loss_cls: 0.0312  decode.loss_mask: 0.6135  decode.loss_dice: 1.0201  decode.d0.loss_cls: 0.0743  decode.d0.loss_mask: 0.6111  decode.d0.loss_dice: 1.0555  decode.d1.loss_cls: 0.0503  decode.d1.loss_mask: 0.6231  decode.d1.loss_dice: 1.0310  decode.d2.loss_cls: 0.0399  decode.d2.loss_mask: 0.6099  decode.d2.loss_dice: 1.0068  decode.d3.loss_cls: 0.0321  decode.d3.loss_mask: 0.6259  decode.d3.loss_dice: 1.0050  decode.d4.loss_cls: 0.0372  decode.d4.loss_mask: 0.6275  decode.d4.loss_dice: 1.0025  decode.d5.loss_cls: 0.0392  decode.d5.loss_mask: 0.6232  decode.d5.loss_dice: 0.9874  decode.d6.loss_cls: 0.0390  decode.d6.loss_mask: 0.6163  decode.d6.loss_dice: 1.0009  decode.d7.loss_cls: 0.0326  decode.d7.loss_mask: 0.6294  decode.d7.loss_dice: 1.0079  decode.d8.loss_cls: 0.0319  decode.d8.loss_mask: 0.6355  decode.d8.loss_dice: 1.0238
11/15 13:02:19 - mmengine - INFO - Iter(train) [35550/90000]  base_lr: 6.3619e-05 lr: 6.3619e-06  eta: 9:08:47  time: 0.6122  data_time: 0.0108  memory: 10656  grad_norm: 789.5232  loss: 18.9240  decode.loss_cls: 0.0835  decode.loss_mask: 0.6014  decode.loss_dice: 1.2004  decode.d0.loss_cls: 0.0939  decode.d0.loss_mask: 0.6580  decode.d0.loss_dice: 1.2506  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.6212  decode.d1.loss_dice: 1.2077  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.6223  decode.d2.loss_dice: 1.2068  decode.d3.loss_cls: 0.0884  decode.d3.loss_mask: 0.6063  decode.d3.loss_dice: 1.1912  decode.d4.loss_cls: 0.0888  decode.d4.loss_mask: 0.6075  decode.d4.loss_dice: 1.1710  decode.d5.loss_cls: 0.0854  decode.d5.loss_mask: 0.5981  decode.d5.loss_dice: 1.2234  decode.d6.loss_cls: 0.0807  decode.d6.loss_mask: 0.6016  decode.d6.loss_dice: 1.1708  decode.d7.loss_cls: 0.0885  decode.d7.loss_mask: 0.6030  decode.d7.loss_dice: 1.1719  decode.d8.loss_cls: 0.0867  decode.d8.loss_mask: 0.5969  decode.d8.loss_dice: 1.1842
11/15 13:02:50 - mmengine - INFO - Iter(train) [35600/90000]  base_lr: 6.3566e-05 lr: 6.3566e-06  eta: 9:08:17  time: 0.6128  data_time: 0.0108  memory: 10728  grad_norm: 295.3014  loss: 16.5787  decode.loss_cls: 0.0649  decode.loss_mask: 0.4522  decode.loss_dice: 1.1433  decode.d0.loss_cls: 0.0815  decode.d0.loss_mask: 0.4673  decode.d0.loss_dice: 1.1362  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.4557  decode.d1.loss_dice: 1.0993  decode.d2.loss_cls: 0.0641  decode.d2.loss_mask: 0.4519  decode.d2.loss_dice: 1.1372  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.4579  decode.d3.loss_dice: 1.1318  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 0.4559  decode.d4.loss_dice: 1.1376  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 0.4574  decode.d5.loss_dice: 1.1554  decode.d6.loss_cls: 0.0772  decode.d6.loss_mask: 0.4561  decode.d6.loss_dice: 1.1236  decode.d7.loss_cls: 0.0687  decode.d7.loss_mask: 0.4559  decode.d7.loss_dice: 1.1437  decode.d8.loss_cls: 0.0687  decode.d8.loss_mask: 0.4526  decode.d8.loss_dice: 1.1254
11/15 13:03:20 - mmengine - INFO - Iter(train) [35650/90000]  base_lr: 6.3513e-05 lr: 6.3513e-06  eta: 9:07:47  time: 0.6110  data_time: 0.0112  memory: 10656  grad_norm: 593.2859  loss: 16.6877  decode.loss_cls: 0.0592  decode.loss_mask: 0.4986  decode.loss_dice: 1.0909  decode.d0.loss_cls: 0.0710  decode.d0.loss_mask: 0.5314  decode.d0.loss_dice: 1.1846  decode.d1.loss_cls: 0.0583  decode.d1.loss_mask: 0.5061  decode.d1.loss_dice: 1.1406  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.4938  decode.d2.loss_dice: 1.1113  decode.d3.loss_cls: 0.0470  decode.d3.loss_mask: 0.4967  decode.d3.loss_dice: 1.1253  decode.d4.loss_cls: 0.0603  decode.d4.loss_mask: 0.5010  decode.d4.loss_dice: 1.0893  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.4955  decode.d5.loss_dice: 1.1078  decode.d6.loss_cls: 0.0477  decode.d6.loss_mask: 0.4975  decode.d6.loss_dice: 1.0888  decode.d7.loss_cls: 0.0494  decode.d7.loss_mask: 0.5015  decode.d7.loss_dice: 1.1031  decode.d8.loss_cls: 0.0511  decode.d8.loss_mask: 0.4915  decode.d8.loss_dice: 1.0830
11/15 13:03:51 - mmengine - INFO - Iter(train) [35700/90000]  base_lr: 6.3461e-05 lr: 6.3461e-06  eta: 9:07:17  time: 0.6046  data_time: 0.0103  memory: 10728  grad_norm: 461.1619  loss: 20.4200  decode.loss_cls: 0.0768  decode.loss_mask: 0.6726  decode.loss_dice: 1.2697  decode.d0.loss_cls: 0.0869  decode.d0.loss_mask: 0.6860  decode.d0.loss_dice: 1.3390  decode.d1.loss_cls: 0.0964  decode.d1.loss_mask: 0.6811  decode.d1.loss_dice: 1.2985  decode.d2.loss_cls: 0.0837  decode.d2.loss_mask: 0.6771  decode.d2.loss_dice: 1.2892  decode.d3.loss_cls: 0.0739  decode.d3.loss_mask: 0.6784  decode.d3.loss_dice: 1.2592  decode.d4.loss_cls: 0.0683  decode.d4.loss_mask: 0.6800  decode.d4.loss_dice: 1.3062  decode.d5.loss_cls: 0.0736  decode.d5.loss_mask: 0.6813  decode.d5.loss_dice: 1.2547  decode.d6.loss_cls: 0.0791  decode.d6.loss_mask: 0.6714  decode.d6.loss_dice: 1.2840  decode.d7.loss_cls: 0.0769  decode.d7.loss_mask: 0.6806  decode.d7.loss_dice: 1.2717  decode.d8.loss_cls: 0.0869  decode.d8.loss_mask: 0.6785  decode.d8.loss_dice: 1.2583
11/15 13:04:21 - mmengine - INFO - Iter(train) [35750/90000]  base_lr: 6.3408e-05 lr: 6.3408e-06  eta: 9:06:47  time: 0.6047  data_time: 0.0104  memory: 10692  grad_norm: 683.7967  loss: 17.6482  decode.loss_cls: 0.0926  decode.loss_mask: 0.6304  decode.loss_dice: 1.0504  decode.d0.loss_cls: 0.0901  decode.d0.loss_mask: 0.6701  decode.d0.loss_dice: 1.1477  decode.d1.loss_cls: 0.0898  decode.d1.loss_mask: 0.6187  decode.d1.loss_dice: 1.0926  decode.d2.loss_cls: 0.0860  decode.d2.loss_mask: 0.6136  decode.d2.loss_dice: 1.0457  decode.d3.loss_cls: 0.0897  decode.d3.loss_mask: 0.6115  decode.d3.loss_dice: 1.0203  decode.d4.loss_cls: 0.0831  decode.d4.loss_mask: 0.6077  decode.d4.loss_dice: 1.0556  decode.d5.loss_cls: 0.0877  decode.d5.loss_mask: 0.5998  decode.d5.loss_dice: 1.0168  decode.d6.loss_cls: 0.1012  decode.d6.loss_mask: 0.6035  decode.d6.loss_dice: 1.0352  decode.d7.loss_cls: 0.0919  decode.d7.loss_mask: 0.6134  decode.d7.loss_dice: 1.0346  decode.d8.loss_cls: 0.0926  decode.d8.loss_mask: 0.6227  decode.d8.loss_dice: 1.0535
11/15 13:04:51 - mmengine - INFO - Iter(train) [35800/90000]  base_lr: 6.3356e-05 lr: 6.3356e-06  eta: 9:06:17  time: 0.6061  data_time: 0.0105  memory: 10656  grad_norm: 771.1505  loss: 15.9518  decode.loss_cls: 0.0647  decode.loss_mask: 0.5275  decode.loss_dice: 0.9991  decode.d0.loss_cls: 0.0883  decode.d0.loss_mask: 0.5283  decode.d0.loss_dice: 1.0132  decode.d1.loss_cls: 0.0683  decode.d1.loss_mask: 0.5375  decode.d1.loss_dice: 1.0127  decode.d2.loss_cls: 0.0759  decode.d2.loss_mask: 0.5242  decode.d2.loss_dice: 0.9909  decode.d3.loss_cls: 0.0656  decode.d3.loss_mask: 0.5274  decode.d3.loss_dice: 0.9917  decode.d4.loss_cls: 0.0730  decode.d4.loss_mask: 0.5123  decode.d4.loss_dice: 0.9684  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.5366  decode.d5.loss_dice: 0.9710  decode.d6.loss_cls: 0.0668  decode.d6.loss_mask: 0.5346  decode.d6.loss_dice: 0.9784  decode.d7.loss_cls: 0.0675  decode.d7.loss_mask: 0.5360  decode.d7.loss_dice: 1.0011  decode.d8.loss_cls: 0.0611  decode.d8.loss_mask: 0.5277  decode.d8.loss_dice: 1.0232
11/15 13:05:22 - mmengine - INFO - Iter(train) [35850/90000]  base_lr: 6.3303e-05 lr: 6.3303e-06  eta: 9:05:47  time: 0.6075  data_time: 0.0107  memory: 10742  grad_norm: 257.9421  loss: 15.3039  decode.loss_cls: 0.0537  decode.loss_mask: 0.4421  decode.loss_dice: 1.0348  decode.d0.loss_cls: 0.0858  decode.d0.loss_mask: 0.4401  decode.d0.loss_dice: 1.0965  decode.d1.loss_cls: 0.0703  decode.d1.loss_mask: 0.4400  decode.d1.loss_dice: 1.0544  decode.d2.loss_cls: 0.0592  decode.d2.loss_mask: 0.4196  decode.d2.loss_dice: 1.0378  decode.d3.loss_cls: 0.0652  decode.d3.loss_mask: 0.4191  decode.d3.loss_dice: 1.0374  decode.d4.loss_cls: 0.0679  decode.d4.loss_mask: 0.4151  decode.d4.loss_dice: 1.0294  decode.d5.loss_cls: 0.0655  decode.d5.loss_mask: 0.4097  decode.d5.loss_dice: 0.9993  decode.d6.loss_cls: 0.0680  decode.d6.loss_mask: 0.4185  decode.d6.loss_dice: 1.0307  decode.d7.loss_cls: 0.0570  decode.d7.loss_mask: 0.4166  decode.d7.loss_dice: 1.0448  decode.d8.loss_cls: 0.0609  decode.d8.loss_mask: 0.4267  decode.d8.loss_dice: 1.0381
11/15 13:05:52 - mmengine - INFO - Iter(train) [35900/90000]  base_lr: 6.3250e-05 lr: 6.3250e-06  eta: 9:05:17  time: 0.6049  data_time: 0.0102  memory: 10675  grad_norm: 406.6288  loss: 17.4853  decode.loss_cls: 0.0723  decode.loss_mask: 0.4618  decode.loss_dice: 1.2100  decode.d0.loss_cls: 0.0797  decode.d0.loss_mask: 0.4792  decode.d0.loss_dice: 1.2696  decode.d1.loss_cls: 0.0646  decode.d1.loss_mask: 0.4583  decode.d1.loss_dice: 1.2209  decode.d2.loss_cls: 0.0723  decode.d2.loss_mask: 0.4644  decode.d2.loss_dice: 1.2112  decode.d3.loss_cls: 0.0671  decode.d3.loss_mask: 0.4631  decode.d3.loss_dice: 1.1946  decode.d4.loss_cls: 0.0644  decode.d4.loss_mask: 0.4679  decode.d4.loss_dice: 1.1936  decode.d5.loss_cls: 0.0669  decode.d5.loss_mask: 0.4630  decode.d5.loss_dice: 1.2158  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.4590  decode.d6.loss_dice: 1.2240  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 0.4557  decode.d7.loss_dice: 1.2127  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.4664  decode.d8.loss_dice: 1.2244
11/15 13:06:23 - mmengine - INFO - Iter(train) [35950/90000]  base_lr: 6.3198e-05 lr: 6.3198e-06  eta: 9:04:48  time: 0.6091  data_time: 0.0109  memory: 10692  grad_norm: 234.7803  loss: 17.3331  decode.loss_cls: 0.0559  decode.loss_mask: 0.5024  decode.loss_dice: 1.1751  decode.d0.loss_cls: 0.0945  decode.d0.loss_mask: 0.4729  decode.d0.loss_dice: 1.2286  decode.d1.loss_cls: 0.0595  decode.d1.loss_mask: 0.4936  decode.d1.loss_dice: 1.1855  decode.d2.loss_cls: 0.0632  decode.d2.loss_mask: 0.4970  decode.d2.loss_dice: 1.1600  decode.d3.loss_cls: 0.0532  decode.d3.loss_mask: 0.5033  decode.d3.loss_dice: 1.1529  decode.d4.loss_cls: 0.0561  decode.d4.loss_mask: 0.5022  decode.d4.loss_dice: 1.1689  decode.d5.loss_cls: 0.0559  decode.d5.loss_mask: 0.4985  decode.d5.loss_dice: 1.1590  decode.d6.loss_cls: 0.0505  decode.d6.loss_mask: 0.5005  decode.d6.loss_dice: 1.1704  decode.d7.loss_cls: 0.0569  decode.d7.loss_mask: 0.4999  decode.d7.loss_dice: 1.1718  decode.d8.loss_cls: 0.0662  decode.d8.loss_mask: 0.5083  decode.d8.loss_dice: 1.1703
11/15 13:06:54 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 13:06:54 - mmengine - INFO - Iter(train) [36000/90000]  base_lr: 6.3145e-05 lr: 6.3145e-06  eta: 9:04:19  time: 0.6071  data_time: 0.0109  memory: 10675  grad_norm: 359.9023  loss: 18.2753  decode.loss_cls: 0.0576  decode.loss_mask: 0.6092  decode.loss_dice: 1.1383  decode.d0.loss_cls: 0.0626  decode.d0.loss_mask: 0.6122  decode.d0.loss_dice: 1.2385  decode.d1.loss_cls: 0.0539  decode.d1.loss_mask: 0.6011  decode.d1.loss_dice: 1.1847  decode.d2.loss_cls: 0.0567  decode.d2.loss_mask: 0.6025  decode.d2.loss_dice: 1.1452  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.6003  decode.d3.loss_dice: 1.1414  decode.d4.loss_cls: 0.0580  decode.d4.loss_mask: 0.6117  decode.d4.loss_dice: 1.1660  decode.d5.loss_cls: 0.0645  decode.d5.loss_mask: 0.6168  decode.d5.loss_dice: 1.1443  decode.d6.loss_cls: 0.0560  decode.d6.loss_mask: 0.6144  decode.d6.loss_dice: 1.1467  decode.d7.loss_cls: 0.0573  decode.d7.loss_mask: 0.6082  decode.d7.loss_dice: 1.1530  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 0.6021  decode.d8.loss_dice: 1.1521
11/15 13:07:24 - mmengine - INFO - Iter(train) [36050/90000]  base_lr: 6.3093e-05 lr: 6.3093e-06  eta: 9:03:49  time: 0.6068  data_time: 0.0108  memory: 10713  grad_norm: 224.1288  loss: 16.0575  decode.loss_cls: 0.0618  decode.loss_mask: 0.4411  decode.loss_dice: 1.0942  decode.d0.loss_cls: 0.0664  decode.d0.loss_mask: 0.4279  decode.d0.loss_dice: 1.1653  decode.d1.loss_cls: 0.0697  decode.d1.loss_mask: 0.4167  decode.d1.loss_dice: 1.0999  decode.d2.loss_cls: 0.0635  decode.d2.loss_mask: 0.4175  decode.d2.loss_dice: 1.1288  decode.d3.loss_cls: 0.0666  decode.d3.loss_mask: 0.4166  decode.d3.loss_dice: 1.1057  decode.d4.loss_cls: 0.0743  decode.d4.loss_mask: 0.4170  decode.d4.loss_dice: 1.0964  decode.d5.loss_cls: 0.0702  decode.d5.loss_mask: 0.4286  decode.d5.loss_dice: 1.1268  decode.d6.loss_cls: 0.0628  decode.d6.loss_mask: 0.4304  decode.d6.loss_dice: 1.1023  decode.d7.loss_cls: 0.0619  decode.d7.loss_mask: 0.4406  decode.d7.loss_dice: 1.1065  decode.d8.loss_cls: 0.0604  decode.d8.loss_mask: 0.4337  decode.d8.loss_dice: 1.1040
11/15 13:07:55 - mmengine - INFO - Iter(train) [36100/90000]  base_lr: 6.3040e-05 lr: 6.3040e-06  eta: 9:03:18  time: 0.6056  data_time: 0.0106  memory: 10675  grad_norm: 352.7894  loss: 19.2597  decode.loss_cls: 0.0824  decode.loss_mask: 0.6058  decode.loss_dice: 1.2104  decode.d0.loss_cls: 0.1033  decode.d0.loss_mask: 0.6287  decode.d0.loss_dice: 1.3145  decode.d1.loss_cls: 0.1089  decode.d1.loss_mask: 0.6047  decode.d1.loss_dice: 1.2301  decode.d2.loss_cls: 0.0884  decode.d2.loss_mask: 0.5967  decode.d2.loss_dice: 1.2333  decode.d3.loss_cls: 0.0898  decode.d3.loss_mask: 0.5824  decode.d3.loss_dice: 1.2178  decode.d4.loss_cls: 0.0950  decode.d4.loss_mask: 0.5805  decode.d4.loss_dice: 1.2074  decode.d5.loss_cls: 0.0964  decode.d5.loss_mask: 0.5939  decode.d5.loss_dice: 1.2294  decode.d6.loss_cls: 0.0874  decode.d6.loss_mask: 0.5963  decode.d6.loss_dice: 1.2297  decode.d7.loss_cls: 0.0857  decode.d7.loss_mask: 0.6039  decode.d7.loss_dice: 1.2246  decode.d8.loss_cls: 0.0992  decode.d8.loss_mask: 0.6006  decode.d8.loss_dice: 1.2325
11/15 13:08:25 - mmengine - INFO - Iter(train) [36150/90000]  base_lr: 6.2987e-05 lr: 6.2987e-06  eta: 9:02:48  time: 0.6044  data_time: 0.0108  memory: 10656  grad_norm: 670.1809  loss: 18.0590  decode.loss_cls: 0.0629  decode.loss_mask: 0.6103  decode.loss_dice: 1.1020  decode.d0.loss_cls: 0.0869  decode.d0.loss_mask: 0.6388  decode.d0.loss_dice: 1.1760  decode.d1.loss_cls: 0.0606  decode.d1.loss_mask: 0.6106  decode.d1.loss_dice: 1.1568  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 0.6070  decode.d2.loss_dice: 1.1298  decode.d3.loss_cls: 0.0607  decode.d3.loss_mask: 0.6041  decode.d3.loss_dice: 1.1344  decode.d4.loss_cls: 0.0575  decode.d4.loss_mask: 0.6112  decode.d4.loss_dice: 1.1288  decode.d5.loss_cls: 0.0639  decode.d5.loss_mask: 0.6095  decode.d5.loss_dice: 1.1283  decode.d6.loss_cls: 0.0615  decode.d6.loss_mask: 0.6151  decode.d6.loss_dice: 1.1156  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.6056  decode.d7.loss_dice: 1.1044  decode.d8.loss_cls: 0.0653  decode.d8.loss_mask: 0.6086  decode.d8.loss_dice: 1.1138
11/15 13:08:55 - mmengine - INFO - Iter(train) [36200/90000]  base_lr: 6.2935e-05 lr: 6.2935e-06  eta: 9:02:18  time: 0.6055  data_time: 0.0108  memory: 10641  grad_norm: 545.5882  loss: 19.0002  decode.loss_cls: 0.0790  decode.loss_mask: 0.5755  decode.loss_dice: 1.2166  decode.d0.loss_cls: 0.1156  decode.d0.loss_mask: 0.5695  decode.d0.loss_dice: 1.3246  decode.d1.loss_cls: 0.1218  decode.d1.loss_mask: 0.6111  decode.d1.loss_dice: 1.2472  decode.d2.loss_cls: 0.0841  decode.d2.loss_mask: 0.5798  decode.d2.loss_dice: 1.2463  decode.d3.loss_cls: 0.0865  decode.d3.loss_mask: 0.5609  decode.d3.loss_dice: 1.2267  decode.d4.loss_cls: 0.0802  decode.d4.loss_mask: 0.5788  decode.d4.loss_dice: 1.2278  decode.d5.loss_cls: 0.0767  decode.d5.loss_mask: 0.5630  decode.d5.loss_dice: 1.2527  decode.d6.loss_cls: 0.0873  decode.d6.loss_mask: 0.5644  decode.d6.loss_dice: 1.1903  decode.d7.loss_cls: 0.0865  decode.d7.loss_mask: 0.5523  decode.d7.loss_dice: 1.2199  decode.d8.loss_cls: 0.0726  decode.d8.loss_mask: 0.5680  decode.d8.loss_dice: 1.2346
11/15 13:09:26 - mmengine - INFO - Iter(train) [36250/90000]  base_lr: 6.2882e-05 lr: 6.2882e-06  eta: 9:01:48  time: 0.6061  data_time: 0.0104  memory: 10675  grad_norm: 357.8650  loss: 16.4026  decode.loss_cls: 0.0519  decode.loss_mask: 0.5783  decode.loss_dice: 0.9849  decode.d0.loss_cls: 0.0890  decode.d0.loss_mask: 0.6254  decode.d0.loss_dice: 1.0493  decode.d1.loss_cls: 0.0508  decode.d1.loss_mask: 0.5941  decode.d1.loss_dice: 1.0201  decode.d2.loss_cls: 0.0504  decode.d2.loss_mask: 0.6167  decode.d2.loss_dice: 1.0026  decode.d3.loss_cls: 0.0604  decode.d3.loss_mask: 0.5653  decode.d3.loss_dice: 0.9908  decode.d4.loss_cls: 0.0545  decode.d4.loss_mask: 0.5613  decode.d4.loss_dice: 1.0163  decode.d5.loss_cls: 0.0554  decode.d5.loss_mask: 0.5624  decode.d5.loss_dice: 0.9909  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.5730  decode.d6.loss_dice: 0.9741  decode.d7.loss_cls: 0.0454  decode.d7.loss_mask: 0.5732  decode.d7.loss_dice: 1.0027  decode.d8.loss_cls: 0.0547  decode.d8.loss_mask: 0.5778  decode.d8.loss_dice: 0.9773
11/15 13:09:56 - mmengine - INFO - Iter(train) [36300/90000]  base_lr: 6.2829e-05 lr: 6.2829e-06  eta: 9:01:19  time: 0.6091  data_time: 0.0108  memory: 10692  grad_norm: 385.9541  loss: 18.8866  decode.loss_cls: 0.0658  decode.loss_mask: 0.5295  decode.loss_dice: 1.2992  decode.d0.loss_cls: 0.0907  decode.d0.loss_mask: 0.5322  decode.d0.loss_dice: 1.3454  decode.d1.loss_cls: 0.0725  decode.d1.loss_mask: 0.5154  decode.d1.loss_dice: 1.2974  decode.d2.loss_cls: 0.0708  decode.d2.loss_mask: 0.5156  decode.d2.loss_dice: 1.2969  decode.d3.loss_cls: 0.0602  decode.d3.loss_mask: 0.5177  decode.d3.loss_dice: 1.2865  decode.d4.loss_cls: 0.0633  decode.d4.loss_mask: 0.5093  decode.d4.loss_dice: 1.2761  decode.d5.loss_cls: 0.0754  decode.d5.loss_mask: 0.5107  decode.d5.loss_dice: 1.2663  decode.d6.loss_cls: 0.0681  decode.d6.loss_mask: 0.5233  decode.d6.loss_dice: 1.3230  decode.d7.loss_cls: 0.0668  decode.d7.loss_mask: 0.5126  decode.d7.loss_dice: 1.2828  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.5399  decode.d8.loss_dice: 1.3073
11/15 13:10:27 - mmengine - INFO - Iter(train) [36350/90000]  base_lr: 6.2777e-05 lr: 6.2777e-06  eta: 9:00:49  time: 0.6113  data_time: 0.0107  memory: 10713  grad_norm: 328.9912  loss: 16.2121  decode.loss_cls: 0.0536  decode.loss_mask: 0.4850  decode.loss_dice: 1.0538  decode.d0.loss_cls: 0.0676  decode.d0.loss_mask: 0.4920  decode.d0.loss_dice: 1.1702  decode.d1.loss_cls: 0.0580  decode.d1.loss_mask: 0.4814  decode.d1.loss_dice: 1.1112  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.4800  decode.d2.loss_dice: 1.0894  decode.d3.loss_cls: 0.0626  decode.d3.loss_mask: 0.4747  decode.d3.loss_dice: 1.0884  decode.d4.loss_cls: 0.0505  decode.d4.loss_mask: 0.4827  decode.d4.loss_dice: 1.0882  decode.d5.loss_cls: 0.0610  decode.d5.loss_mask: 0.4697  decode.d5.loss_dice: 1.0386  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.4671  decode.d6.loss_dice: 1.0579  decode.d7.loss_cls: 0.0623  decode.d7.loss_mask: 0.4630  decode.d7.loss_dice: 1.0434  decode.d8.loss_cls: 0.0475  decode.d8.loss_mask: 0.4920  decode.d8.loss_dice: 1.1044
11/15 13:10:57 - mmengine - INFO - Iter(train) [36400/90000]  base_lr: 6.2724e-05 lr: 6.2724e-06  eta: 9:00:19  time: 0.6076  data_time: 0.0107  memory: 10675  grad_norm: 261.9769  loss: 14.4790  decode.loss_cls: 0.0361  decode.loss_mask: 0.4514  decode.loss_dice: 0.9446  decode.d0.loss_cls: 0.0729  decode.d0.loss_mask: 0.4756  decode.d0.loss_dice: 1.0021  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.4615  decode.d1.loss_dice: 0.9645  decode.d2.loss_cls: 0.0348  decode.d2.loss_mask: 0.4529  decode.d2.loss_dice: 0.9416  decode.d3.loss_cls: 0.0306  decode.d3.loss_mask: 0.4497  decode.d3.loss_dice: 0.9674  decode.d4.loss_cls: 0.0328  decode.d4.loss_mask: 0.4511  decode.d4.loss_dice: 0.9391  decode.d5.loss_cls: 0.0330  decode.d5.loss_mask: 0.4565  decode.d5.loss_dice: 0.9533  decode.d6.loss_cls: 0.0391  decode.d6.loss_mask: 0.4570  decode.d6.loss_dice: 0.9509  decode.d7.loss_cls: 0.0448  decode.d7.loss_mask: 0.4564  decode.d7.loss_dice: 0.9195  decode.d8.loss_cls: 0.0353  decode.d8.loss_mask: 0.4546  decode.d8.loss_dice: 0.9357
11/15 13:11:28 - mmengine - INFO - Iter(train) [36450/90000]  base_lr: 6.2671e-05 lr: 6.2671e-06  eta: 8:59:49  time: 0.6066  data_time: 0.0107  memory: 10728  grad_norm: 307.3050  loss: 19.3561  decode.loss_cls: 0.0606  decode.loss_mask: 0.5676  decode.loss_dice: 1.2905  decode.d0.loss_cls: 0.0822  decode.d0.loss_mask: 0.5919  decode.d0.loss_dice: 1.3506  decode.d1.loss_cls: 0.0677  decode.d1.loss_mask: 0.5758  decode.d1.loss_dice: 1.3276  decode.d2.loss_cls: 0.0745  decode.d2.loss_mask: 0.5768  decode.d2.loss_dice: 1.2651  decode.d3.loss_cls: 0.0741  decode.d3.loss_mask: 0.5557  decode.d3.loss_dice: 1.2493  decode.d4.loss_cls: 0.0730  decode.d4.loss_mask: 0.5630  decode.d4.loss_dice: 1.2902  decode.d5.loss_cls: 0.0677  decode.d5.loss_mask: 0.5636  decode.d5.loss_dice: 1.3060  decode.d6.loss_cls: 0.0710  decode.d6.loss_mask: 0.5609  decode.d6.loss_dice: 1.2857  decode.d7.loss_cls: 0.0624  decode.d7.loss_mask: 0.5570  decode.d7.loss_dice: 1.2953  decode.d8.loss_cls: 0.0565  decode.d8.loss_mask: 0.5767  decode.d8.loss_dice: 1.3168
11/15 13:11:58 - mmengine - INFO - Iter(train) [36500/90000]  base_lr: 6.2619e-05 lr: 6.2619e-06  eta: 8:59:19  time: 0.6104  data_time: 0.0109  memory: 10675  grad_norm: 385.4817  loss: 17.7680  decode.loss_cls: 0.0563  decode.loss_mask: 0.5943  decode.loss_dice: 1.1166  decode.d0.loss_cls: 0.0914  decode.d0.loss_mask: 0.6141  decode.d0.loss_dice: 1.1308  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.5990  decode.d1.loss_dice: 1.1394  decode.d2.loss_cls: 0.0602  decode.d2.loss_mask: 0.6028  decode.d2.loss_dice: 1.1213  decode.d3.loss_cls: 0.0599  decode.d3.loss_mask: 0.6031  decode.d3.loss_dice: 1.0953  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.6046  decode.d4.loss_dice: 1.0994  decode.d5.loss_cls: 0.0537  decode.d5.loss_mask: 0.6050  decode.d5.loss_dice: 1.1102  decode.d6.loss_cls: 0.0554  decode.d6.loss_mask: 0.5953  decode.d6.loss_dice: 1.1001  decode.d7.loss_cls: 0.0531  decode.d7.loss_mask: 0.5923  decode.d7.loss_dice: 1.1181  decode.d8.loss_cls: 0.0530  decode.d8.loss_mask: 0.5861  decode.d8.loss_dice: 1.1394
11/15 13:12:29 - mmengine - INFO - Iter(train) [36550/90000]  base_lr: 6.2566e-05 lr: 6.2566e-06  eta: 8:58:49  time: 0.6092  data_time: 0.0107  memory: 10641  grad_norm: 314.0347  loss: 19.2748  decode.loss_cls: 0.0805  decode.loss_mask: 0.5511  decode.loss_dice: 1.2723  decode.d0.loss_cls: 0.0845  decode.d0.loss_mask: 0.5564  decode.d0.loss_dice: 1.3746  decode.d1.loss_cls: 0.0844  decode.d1.loss_mask: 0.5427  decode.d1.loss_dice: 1.3265  decode.d2.loss_cls: 0.0754  decode.d2.loss_mask: 0.5468  decode.d2.loss_dice: 1.2971  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.5413  decode.d3.loss_dice: 1.2721  decode.d4.loss_cls: 0.0805  decode.d4.loss_mask: 0.5422  decode.d4.loss_dice: 1.2994  decode.d5.loss_cls: 0.0925  decode.d5.loss_mask: 0.5485  decode.d5.loss_dice: 1.2751  decode.d6.loss_cls: 0.0998  decode.d6.loss_mask: 0.5481  decode.d6.loss_dice: 1.2842  decode.d7.loss_cls: 0.0960  decode.d7.loss_mask: 0.5410  decode.d7.loss_dice: 1.2857  decode.d8.loss_cls: 0.0897  decode.d8.loss_mask: 0.5398  decode.d8.loss_dice: 1.2678
11/15 13:13:00 - mmengine - INFO - Iter(train) [36600/90000]  base_lr: 6.2513e-05 lr: 6.2513e-06  eta: 8:58:20  time: 0.6134  data_time: 0.0116  memory: 10692  grad_norm: 348.4701  loss: 17.8952  decode.loss_cls: 0.0572  decode.loss_mask: 0.5397  decode.loss_dice: 1.1979  decode.d0.loss_cls: 0.0740  decode.d0.loss_mask: 0.5581  decode.d0.loss_dice: 1.2041  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.5397  decode.d1.loss_dice: 1.1985  decode.d2.loss_cls: 0.0590  decode.d2.loss_mask: 0.5420  decode.d2.loss_dice: 1.2122  decode.d3.loss_cls: 0.0673  decode.d3.loss_mask: 0.5354  decode.d3.loss_dice: 1.1979  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 0.5348  decode.d4.loss_dice: 1.1644  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.5285  decode.d5.loss_dice: 1.1807  decode.d6.loss_cls: 0.0582  decode.d6.loss_mask: 0.5345  decode.d6.loss_dice: 1.1951  decode.d7.loss_cls: 0.0651  decode.d7.loss_mask: 0.5313  decode.d7.loss_dice: 1.1858  decode.d8.loss_cls: 0.0611  decode.d8.loss_mask: 0.5333  decode.d8.loss_dice: 1.1620
11/15 13:13:30 - mmengine - INFO - Iter(train) [36650/90000]  base_lr: 6.2461e-05 lr: 6.2461e-06  eta: 8:57:50  time: 0.6062  data_time: 0.0107  memory: 10675  grad_norm: 977.6467  loss: 18.7741  decode.loss_cls: 0.0566  decode.loss_mask: 0.6591  decode.loss_dice: 1.1845  decode.d0.loss_cls: 0.0810  decode.d0.loss_mask: 0.6327  decode.d0.loss_dice: 1.2451  decode.d1.loss_cls: 0.0758  decode.d1.loss_mask: 0.6156  decode.d1.loss_dice: 1.1710  decode.d2.loss_cls: 0.0689  decode.d2.loss_mask: 0.6322  decode.d2.loss_dice: 1.1679  decode.d3.loss_cls: 0.0645  decode.d3.loss_mask: 0.6081  decode.d3.loss_dice: 1.1519  decode.d4.loss_cls: 0.0647  decode.d4.loss_mask: 0.6331  decode.d4.loss_dice: 1.1486  decode.d5.loss_cls: 0.0572  decode.d5.loss_mask: 0.6580  decode.d5.loss_dice: 1.1576  decode.d6.loss_cls: 0.0637  decode.d6.loss_mask: 0.6527  decode.d6.loss_dice: 1.1465  decode.d7.loss_cls: 0.0576  decode.d7.loss_mask: 0.6568  decode.d7.loss_dice: 1.1583  decode.d8.loss_cls: 0.0607  decode.d8.loss_mask: 0.6685  decode.d8.loss_dice: 1.1750
11/15 13:14:01 - mmengine - INFO - Iter(train) [36700/90000]  base_lr: 6.2408e-05 lr: 6.2408e-06  eta: 8:57:20  time: 0.6069  data_time: 0.0107  memory: 10692  grad_norm: 593.8180  loss: 17.5266  decode.loss_cls: 0.0565  decode.loss_mask: 0.5792  decode.loss_dice: 1.0993  decode.d0.loss_cls: 0.1056  decode.d0.loss_mask: 0.6196  decode.d0.loss_dice: 1.1506  decode.d1.loss_cls: 0.0508  decode.d1.loss_mask: 0.6277  decode.d1.loss_dice: 1.1450  decode.d2.loss_cls: 0.0517  decode.d2.loss_mask: 0.6082  decode.d2.loss_dice: 1.1180  decode.d3.loss_cls: 0.0650  decode.d3.loss_mask: 0.5798  decode.d3.loss_dice: 1.0603  decode.d4.loss_cls: 0.0656  decode.d4.loss_mask: 0.5719  decode.d4.loss_dice: 1.0425  decode.d5.loss_cls: 0.0602  decode.d5.loss_mask: 0.5829  decode.d5.loss_dice: 1.0876  decode.d6.loss_cls: 0.0625  decode.d6.loss_mask: 0.5647  decode.d6.loss_dice: 1.0661  decode.d7.loss_cls: 0.0546  decode.d7.loss_mask: 0.5750  decode.d7.loss_dice: 1.1099  decode.d8.loss_cls: 0.0492  decode.d8.loss_mask: 0.5792  decode.d8.loss_dice: 1.1376
11/15 13:14:31 - mmengine - INFO - Iter(train) [36750/90000]  base_lr: 6.2355e-05 lr: 6.2355e-06  eta: 8:56:50  time: 0.6069  data_time: 0.0109  memory: 10656  grad_norm: 422.3122  loss: 14.9728  decode.loss_cls: 0.0622  decode.loss_mask: 0.4784  decode.loss_dice: 0.9256  decode.d0.loss_cls: 0.0818  decode.d0.loss_mask: 0.5022  decode.d0.loss_dice: 0.9874  decode.d1.loss_cls: 0.0516  decode.d1.loss_mask: 0.4875  decode.d1.loss_dice: 0.9911  decode.d2.loss_cls: 0.0466  decode.d2.loss_mask: 0.4945  decode.d2.loss_dice: 0.9630  decode.d3.loss_cls: 0.0500  decode.d3.loss_mask: 0.4954  decode.d3.loss_dice: 0.9395  decode.d4.loss_cls: 0.0564  decode.d4.loss_mask: 0.4993  decode.d4.loss_dice: 0.9253  decode.d5.loss_cls: 0.0625  decode.d5.loss_mask: 0.4873  decode.d5.loss_dice: 0.9543  decode.d6.loss_cls: 0.0579  decode.d6.loss_mask: 0.4863  decode.d6.loss_dice: 0.9266  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.4885  decode.d7.loss_dice: 0.9419  decode.d8.loss_cls: 0.0516  decode.d8.loss_mask: 0.4834  decode.d8.loss_dice: 0.9414
11/15 13:15:02 - mmengine - INFO - Iter(train) [36800/90000]  base_lr: 6.2303e-05 lr: 6.2303e-06  eta: 8:56:20  time: 0.6071  data_time: 0.0105  memory: 10692  grad_norm: 222.4888  loss: 17.5669  decode.loss_cls: 0.0640  decode.loss_mask: 0.4946  decode.loss_dice: 1.1750  decode.d0.loss_cls: 0.0822  decode.d0.loss_mask: 0.5102  decode.d0.loss_dice: 1.2336  decode.d1.loss_cls: 0.0657  decode.d1.loss_mask: 0.4899  decode.d1.loss_dice: 1.2241  decode.d2.loss_cls: 0.0672  decode.d2.loss_mask: 0.4974  decode.d2.loss_dice: 1.1958  decode.d3.loss_cls: 0.0635  decode.d3.loss_mask: 0.4942  decode.d3.loss_dice: 1.1863  decode.d4.loss_cls: 0.0704  decode.d4.loss_mask: 0.4968  decode.d4.loss_dice: 1.1904  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.4972  decode.d5.loss_dice: 1.2074  decode.d6.loss_cls: 0.0600  decode.d6.loss_mask: 0.4939  decode.d6.loss_dice: 1.1764  decode.d7.loss_cls: 0.0662  decode.d7.loss_mask: 0.4922  decode.d7.loss_dice: 1.1646  decode.d8.loss_cls: 0.0632  decode.d8.loss_mask: 0.4951  decode.d8.loss_dice: 1.1876
11/15 13:15:32 - mmengine - INFO - Iter(train) [36850/90000]  base_lr: 6.2250e-05 lr: 6.2250e-06  eta: 8:55:51  time: 0.6118  data_time: 0.0109  memory: 10692  grad_norm: 326.8575  loss: 17.0397  decode.loss_cls: 0.0645  decode.loss_mask: 0.4752  decode.loss_dice: 1.1316  decode.d0.loss_cls: 0.0671  decode.d0.loss_mask: 0.4782  decode.d0.loss_dice: 1.2055  decode.d1.loss_cls: 0.0496  decode.d1.loss_mask: 0.4788  decode.d1.loss_dice: 1.1725  decode.d2.loss_cls: 0.0584  decode.d2.loss_mask: 0.4794  decode.d2.loss_dice: 1.1754  decode.d3.loss_cls: 0.0631  decode.d3.loss_mask: 0.4775  decode.d3.loss_dice: 1.1802  decode.d4.loss_cls: 0.0704  decode.d4.loss_mask: 0.4674  decode.d4.loss_dice: 1.1632  decode.d5.loss_cls: 0.0579  decode.d5.loss_mask: 0.4809  decode.d5.loss_dice: 1.1667  decode.d6.loss_cls: 0.0661  decode.d6.loss_mask: 0.4796  decode.d6.loss_dice: 1.1408  decode.d7.loss_cls: 0.0677  decode.d7.loss_mask: 0.4765  decode.d7.loss_dice: 1.1623  decode.d8.loss_cls: 0.0685  decode.d8.loss_mask: 0.4758  decode.d8.loss_dice: 1.1390
11/15 13:16:03 - mmengine - INFO - Iter(train) [36900/90000]  base_lr: 6.2197e-05 lr: 6.2197e-06  eta: 8:55:21  time: 0.6065  data_time: 0.0107  memory: 10692  grad_norm: 329.1409  loss: 15.9999  decode.loss_cls: 0.0557  decode.loss_mask: 0.4890  decode.loss_dice: 1.0411  decode.d0.loss_cls: 0.0637  decode.d0.loss_mask: 0.4965  decode.d0.loss_dice: 1.1160  decode.d1.loss_cls: 0.0682  decode.d1.loss_mask: 0.4728  decode.d1.loss_dice: 1.0731  decode.d2.loss_cls: 0.0691  decode.d2.loss_mask: 0.4792  decode.d2.loss_dice: 1.0592  decode.d3.loss_cls: 0.0610  decode.d3.loss_mask: 0.4781  decode.d3.loss_dice: 1.0388  decode.d4.loss_cls: 0.0625  decode.d4.loss_mask: 0.4805  decode.d4.loss_dice: 1.0436  decode.d5.loss_cls: 0.0627  decode.d5.loss_mask: 0.4832  decode.d5.loss_dice: 1.0565  decode.d6.loss_cls: 0.0521  decode.d6.loss_mask: 0.4867  decode.d6.loss_dice: 1.0374  decode.d7.loss_cls: 0.0449  decode.d7.loss_mask: 0.4867  decode.d7.loss_dice: 1.0436  decode.d8.loss_cls: 0.0471  decode.d8.loss_mask: 0.4895  decode.d8.loss_dice: 1.0616
11/15 13:16:33 - mmengine - INFO - Iter(train) [36950/90000]  base_lr: 6.2145e-05 lr: 6.2145e-06  eta: 8:54:50  time: 0.5985  data_time: 0.0104  memory: 10675  grad_norm: 437.9365  loss: 17.2092  decode.loss_cls: 0.0680  decode.loss_mask: 0.5389  decode.loss_dice: 1.0630  decode.d0.loss_cls: 0.0911  decode.d0.loss_mask: 0.5542  decode.d0.loss_dice: 1.2057  decode.d1.loss_cls: 0.0665  decode.d1.loss_mask: 0.5293  decode.d1.loss_dice: 1.1460  decode.d2.loss_cls: 0.0756  decode.d2.loss_mask: 0.5230  decode.d2.loss_dice: 1.0676  decode.d3.loss_cls: 0.0746  decode.d3.loss_mask: 0.5272  decode.d3.loss_dice: 1.0720  decode.d4.loss_cls: 0.0711  decode.d4.loss_mask: 0.5553  decode.d4.loss_dice: 1.1014  decode.d5.loss_cls: 0.0731  decode.d5.loss_mask: 0.5586  decode.d5.loss_dice: 1.1022  decode.d6.loss_cls: 0.0755  decode.d6.loss_mask: 0.5265  decode.d6.loss_dice: 1.0904  decode.d7.loss_cls: 0.0674  decode.d7.loss_mask: 0.5487  decode.d7.loss_dice: 1.1065  decode.d8.loss_cls: 0.0728  decode.d8.loss_mask: 0.5269  decode.d8.loss_dice: 1.1301
11/15 13:17:03 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 13:17:03 - mmengine - INFO - Iter(train) [37000/90000]  base_lr: 6.2092e-05 lr: 6.2092e-06  eta: 8:54:20  time: 0.5973  data_time: 0.0103  memory: 10728  grad_norm: 514.4290  loss: 15.4075  decode.loss_cls: 0.0400  decode.loss_mask: 0.5384  decode.loss_dice: 0.9367  decode.d0.loss_cls: 0.0930  decode.d0.loss_mask: 0.5301  decode.d0.loss_dice: 0.9450  decode.d1.loss_cls: 0.0468  decode.d1.loss_mask: 0.5446  decode.d1.loss_dice: 0.9590  decode.d2.loss_cls: 0.0392  decode.d2.loss_mask: 0.5368  decode.d2.loss_dice: 0.9782  decode.d3.loss_cls: 0.0446  decode.d3.loss_mask: 0.5392  decode.d3.loss_dice: 0.9503  decode.d4.loss_cls: 0.0430  decode.d4.loss_mask: 0.5500  decode.d4.loss_dice: 0.9498  decode.d5.loss_cls: 0.0482  decode.d5.loss_mask: 0.5498  decode.d5.loss_dice: 0.9360  decode.d6.loss_cls: 0.0399  decode.d6.loss_mask: 0.5314  decode.d6.loss_dice: 0.9536  decode.d7.loss_cls: 0.0403  decode.d7.loss_mask: 0.5320  decode.d7.loss_dice: 0.9714  decode.d8.loss_cls: 0.0483  decode.d8.loss_mask: 0.5303  decode.d8.loss_dice: 0.9615
11/15 13:17:33 - mmengine - INFO - Iter(train) [37050/90000]  base_lr: 6.2039e-05 lr: 6.2039e-06  eta: 8:53:49  time: 0.5994  data_time: 0.0105  memory: 10656  grad_norm: 343.3614  loss: 17.7267  decode.loss_cls: 0.0549  decode.loss_mask: 0.5740  decode.loss_dice: 1.1791  decode.d0.loss_cls: 0.0773  decode.d0.loss_mask: 0.5194  decode.d0.loss_dice: 1.2297  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.5132  decode.d1.loss_dice: 1.2045  decode.d2.loss_cls: 0.0584  decode.d2.loss_mask: 0.5116  decode.d2.loss_dice: 1.1568  decode.d3.loss_cls: 0.0597  decode.d3.loss_mask: 0.5141  decode.d3.loss_dice: 1.1509  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.5147  decode.d4.loss_dice: 1.1521  decode.d5.loss_cls: 0.0699  decode.d5.loss_mask: 0.5286  decode.d5.loss_dice: 1.1441  decode.d6.loss_cls: 0.0573  decode.d6.loss_mask: 0.5962  decode.d6.loss_dice: 1.1702  decode.d7.loss_cls: 0.0718  decode.d7.loss_mask: 0.5780  decode.d7.loss_dice: 1.1422  decode.d8.loss_cls: 0.0637  decode.d8.loss_mask: 0.5574  decode.d8.loss_dice: 1.1587
11/15 13:18:03 - mmengine - INFO - Iter(train) [37100/90000]  base_lr: 6.1986e-05 lr: 6.1986e-06  eta: 8:53:18  time: 0.5982  data_time: 0.0103  memory: 10675  grad_norm: 275.0075  loss: 17.1135  decode.loss_cls: 0.1226  decode.loss_mask: 0.4323  decode.loss_dice: 1.1481  decode.d0.loss_cls: 0.1315  decode.d0.loss_mask: 0.4379  decode.d0.loss_dice: 1.2379  decode.d1.loss_cls: 0.1409  decode.d1.loss_mask: 0.4430  decode.d1.loss_dice: 1.1272  decode.d2.loss_cls: 0.1242  decode.d2.loss_mask: 0.4467  decode.d2.loss_dice: 1.1546  decode.d3.loss_cls: 0.1205  decode.d3.loss_mask: 0.4357  decode.d3.loss_dice: 1.1103  decode.d4.loss_cls: 0.1138  decode.d4.loss_mask: 0.4347  decode.d4.loss_dice: 1.1538  decode.d5.loss_cls: 0.1321  decode.d5.loss_mask: 0.4319  decode.d5.loss_dice: 1.1738  decode.d6.loss_cls: 0.1206  decode.d6.loss_mask: 0.4360  decode.d6.loss_dice: 1.1313  decode.d7.loss_cls: 0.1265  decode.d7.loss_mask: 0.4421  decode.d7.loss_dice: 1.1206  decode.d8.loss_cls: 0.1176  decode.d8.loss_mask: 0.4391  decode.d8.loss_dice: 1.1260
11/15 13:18:33 - mmengine - INFO - Iter(train) [37150/90000]  base_lr: 6.1934e-05 lr: 6.1934e-06  eta: 8:52:48  time: 0.5979  data_time: 0.0104  memory: 10675  grad_norm: 735.7901  loss: 18.6976  decode.loss_cls: 0.0699  decode.loss_mask: 0.5848  decode.loss_dice: 1.2056  decode.d0.loss_cls: 0.0942  decode.d0.loss_mask: 0.6315  decode.d0.loss_dice: 1.2686  decode.d1.loss_cls: 0.0672  decode.d1.loss_mask: 0.6248  decode.d1.loss_dice: 1.2486  decode.d2.loss_cls: 0.0576  decode.d2.loss_mask: 0.6064  decode.d2.loss_dice: 1.2236  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.5756  decode.d3.loss_dice: 1.1812  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.5821  decode.d4.loss_dice: 1.1796  decode.d5.loss_cls: 0.0742  decode.d5.loss_mask: 0.5726  decode.d5.loss_dice: 1.1694  decode.d6.loss_cls: 0.0654  decode.d6.loss_mask: 0.5695  decode.d6.loss_dice: 1.1776  decode.d7.loss_cls: 0.0693  decode.d7.loss_mask: 0.5750  decode.d7.loss_dice: 1.1951  decode.d8.loss_cls: 0.0662  decode.d8.loss_mask: 0.5954  decode.d8.loss_dice: 1.2276
11/15 13:19:03 - mmengine - INFO - Iter(train) [37200/90000]  base_lr: 6.1881e-05 lr: 6.1881e-06  eta: 8:52:17  time: 0.5993  data_time: 0.0102  memory: 10713  grad_norm: 385.4699  loss: 19.9687  decode.loss_cls: 0.0747  decode.loss_mask: 0.5896  decode.loss_dice: 1.3532  decode.d0.loss_cls: 0.0812  decode.d0.loss_mask: 0.6290  decode.d0.loss_dice: 1.4135  decode.d1.loss_cls: 0.0796  decode.d1.loss_mask: 0.5769  decode.d1.loss_dice: 1.3191  decode.d2.loss_cls: 0.0785  decode.d2.loss_mask: 0.5968  decode.d2.loss_dice: 1.3274  decode.d3.loss_cls: 0.0779  decode.d3.loss_mask: 0.5853  decode.d3.loss_dice: 1.3179  decode.d4.loss_cls: 0.0830  decode.d4.loss_mask: 0.5702  decode.d4.loss_dice: 1.3101  decode.d5.loss_cls: 0.0821  decode.d5.loss_mask: 0.5789  decode.d5.loss_dice: 1.3282  decode.d6.loss_cls: 0.0894  decode.d6.loss_mask: 0.5692  decode.d6.loss_dice: 1.2898  decode.d7.loss_cls: 0.0575  decode.d7.loss_mask: 0.5841  decode.d7.loss_dice: 1.3431  decode.d8.loss_cls: 0.0615  decode.d8.loss_mask: 0.5894  decode.d8.loss_dice: 1.3316
11/15 13:19:33 - mmengine - INFO - Iter(train) [37250/90000]  base_lr: 6.1828e-05 lr: 6.1828e-06  eta: 8:51:46  time: 0.5983  data_time: 0.0103  memory: 10676  grad_norm: 342.1913  loss: 19.2575  decode.loss_cls: 0.0810  decode.loss_mask: 0.5313  decode.loss_dice: 1.3097  decode.d0.loss_cls: 0.0736  decode.d0.loss_mask: 0.5435  decode.d0.loss_dice: 1.3922  decode.d1.loss_cls: 0.0656  decode.d1.loss_mask: 0.5328  decode.d1.loss_dice: 1.3694  decode.d2.loss_cls: 0.0662  decode.d2.loss_mask: 0.5250  decode.d2.loss_dice: 1.3215  decode.d3.loss_cls: 0.0633  decode.d3.loss_mask: 0.5349  decode.d3.loss_dice: 1.2887  decode.d4.loss_cls: 0.0763  decode.d4.loss_mask: 0.5298  decode.d4.loss_dice: 1.2849  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.5325  decode.d5.loss_dice: 1.3150  decode.d6.loss_cls: 0.0685  decode.d6.loss_mask: 0.5362  decode.d6.loss_dice: 1.2858  decode.d7.loss_cls: 0.0671  decode.d7.loss_mask: 0.5363  decode.d7.loss_dice: 1.3280  decode.d8.loss_cls: 0.0785  decode.d8.loss_mask: 0.5378  decode.d8.loss_dice: 1.3160
11/15 13:20:03 - mmengine - INFO - Iter(train) [37300/90000]  base_lr: 6.1775e-05 lr: 6.1775e-06  eta: 8:51:16  time: 0.5987  data_time: 0.0103  memory: 10656  grad_norm: 422.9332  loss: 18.2780  decode.loss_cls: 0.0882  decode.loss_mask: 0.5494  decode.loss_dice: 1.1561  decode.d0.loss_cls: 0.1193  decode.d0.loss_mask: 0.5854  decode.d0.loss_dice: 1.2481  decode.d1.loss_cls: 0.1093  decode.d1.loss_mask: 0.5406  decode.d1.loss_dice: 1.2085  decode.d2.loss_cls: 0.0864  decode.d2.loss_mask: 0.5681  decode.d2.loss_dice: 1.2230  decode.d3.loss_cls: 0.0986  decode.d3.loss_mask: 0.5556  decode.d3.loss_dice: 1.1434  decode.d4.loss_cls: 0.1115  decode.d4.loss_mask: 0.5514  decode.d4.loss_dice: 1.1614  decode.d5.loss_cls: 0.1092  decode.d5.loss_mask: 0.5492  decode.d5.loss_dice: 1.1313  decode.d6.loss_cls: 0.0918  decode.d6.loss_mask: 0.5530  decode.d6.loss_dice: 1.1444  decode.d7.loss_cls: 0.0947  decode.d7.loss_mask: 0.5542  decode.d7.loss_dice: 1.1514  decode.d8.loss_cls: 0.1102  decode.d8.loss_mask: 0.5456  decode.d8.loss_dice: 1.1389
11/15 13:20:33 - mmengine - INFO - Iter(train) [37350/90000]  base_lr: 6.1723e-05 lr: 6.1723e-06  eta: 8:50:45  time: 0.5985  data_time: 0.0103  memory: 10692  grad_norm: 400.1762  loss: 17.7079  decode.loss_cls: 0.0837  decode.loss_mask: 0.5156  decode.loss_dice: 1.1335  decode.d0.loss_cls: 0.1417  decode.d0.loss_mask: 0.5247  decode.d0.loss_dice: 1.1850  decode.d1.loss_cls: 0.0974  decode.d1.loss_mask: 0.5149  decode.d1.loss_dice: 1.1689  decode.d2.loss_cls: 0.0914  decode.d2.loss_mask: 0.5225  decode.d2.loss_dice: 1.1694  decode.d3.loss_cls: 0.0886  decode.d3.loss_mask: 0.5252  decode.d3.loss_dice: 1.1549  decode.d4.loss_cls: 0.0892  decode.d4.loss_mask: 0.5218  decode.d4.loss_dice: 1.1636  decode.d5.loss_cls: 0.0934  decode.d5.loss_mask: 0.5115  decode.d5.loss_dice: 1.1453  decode.d6.loss_cls: 0.0853  decode.d6.loss_mask: 0.5362  decode.d6.loss_dice: 1.1455  decode.d7.loss_cls: 0.0858  decode.d7.loss_mask: 0.5263  decode.d7.loss_dice: 1.1379  decode.d8.loss_cls: 0.0879  decode.d8.loss_mask: 0.5210  decode.d8.loss_dice: 1.1397
11/15 13:21:03 - mmengine - INFO - Iter(train) [37400/90000]  base_lr: 6.1670e-05 lr: 6.1670e-06  eta: 8:50:14  time: 0.6004  data_time: 0.0115  memory: 10713  grad_norm: 314.6020  loss: 17.4629  decode.loss_cls: 0.0825  decode.loss_mask: 0.5018  decode.loss_dice: 1.1585  decode.d0.loss_cls: 0.0823  decode.d0.loss_mask: 0.5104  decode.d0.loss_dice: 1.2204  decode.d1.loss_cls: 0.1040  decode.d1.loss_mask: 0.5061  decode.d1.loss_dice: 1.1715  decode.d2.loss_cls: 0.0937  decode.d2.loss_mask: 0.5013  decode.d2.loss_dice: 1.1778  decode.d3.loss_cls: 0.0794  decode.d3.loss_mask: 0.5016  decode.d3.loss_dice: 1.1493  decode.d4.loss_cls: 0.0835  decode.d4.loss_mask: 0.5009  decode.d4.loss_dice: 1.1373  decode.d5.loss_cls: 0.0686  decode.d5.loss_mask: 0.5015  decode.d5.loss_dice: 1.1162  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.5112  decode.d6.loss_dice: 1.1417  decode.d7.loss_cls: 0.0800  decode.d7.loss_mask: 0.5171  decode.d7.loss_dice: 1.1512  decode.d8.loss_cls: 0.0777  decode.d8.loss_mask: 0.5072  decode.d8.loss_dice: 1.1640
11/15 13:21:33 - mmengine - INFO - Iter(train) [37450/90000]  base_lr: 6.1617e-05 lr: 6.1617e-06  eta: 8:49:44  time: 0.5998  data_time: 0.0105  memory: 10692  grad_norm: 360.6726  loss: 14.6671  decode.loss_cls: 0.0568  decode.loss_mask: 0.4985  decode.loss_dice: 0.8604  decode.d0.loss_cls: 0.0759  decode.d0.loss_mask: 0.5357  decode.d0.loss_dice: 0.9843  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.5022  decode.d1.loss_dice: 0.9211  decode.d2.loss_cls: 0.0555  decode.d2.loss_mask: 0.5048  decode.d2.loss_dice: 0.8995  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.4871  decode.d3.loss_dice: 0.8982  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 0.5036  decode.d4.loss_dice: 0.8990  decode.d5.loss_cls: 0.0548  decode.d5.loss_mask: 0.4964  decode.d5.loss_dice: 0.9088  decode.d6.loss_cls: 0.0489  decode.d6.loss_mask: 0.5046  decode.d6.loss_dice: 0.9011  decode.d7.loss_cls: 0.0525  decode.d7.loss_mask: 0.5187  decode.d7.loss_dice: 0.8799  decode.d8.loss_cls: 0.0518  decode.d8.loss_mask: 0.5134  decode.d8.loss_dice: 0.8886
11/15 13:22:02 - mmengine - INFO - Iter(train) [37500/90000]  base_lr: 6.1564e-05 lr: 6.1564e-06  eta: 8:49:13  time: 0.6002  data_time: 0.0105  memory: 10641  grad_norm: 297.8395  loss: 16.7185  decode.loss_cls: 0.0501  decode.loss_mask: 0.5378  decode.loss_dice: 1.0540  decode.d0.loss_cls: 0.0585  decode.d0.loss_mask: 0.5650  decode.d0.loss_dice: 1.1361  decode.d1.loss_cls: 0.0554  decode.d1.loss_mask: 0.5378  decode.d1.loss_dice: 1.0970  decode.d2.loss_cls: 0.0415  decode.d2.loss_mask: 0.5314  decode.d2.loss_dice: 1.0887  decode.d3.loss_cls: 0.0422  decode.d3.loss_mask: 0.5305  decode.d3.loss_dice: 1.0795  decode.d4.loss_cls: 0.0510  decode.d4.loss_mask: 0.5321  decode.d4.loss_dice: 1.0804  decode.d5.loss_cls: 0.0435  decode.d5.loss_mask: 0.5324  decode.d5.loss_dice: 1.0766  decode.d6.loss_cls: 0.0481  decode.d6.loss_mask: 0.5281  decode.d6.loss_dice: 1.0590  decode.d7.loss_cls: 0.0473  decode.d7.loss_mask: 0.5315  decode.d7.loss_dice: 1.0924  decode.d8.loss_cls: 0.0381  decode.d8.loss_mask: 0.5384  decode.d8.loss_dice: 1.1143
11/15 13:22:32 - mmengine - INFO - Iter(train) [37550/90000]  base_lr: 6.1512e-05 lr: 6.1512e-06  eta: 8:48:42  time: 0.5982  data_time: 0.0103  memory: 10692  grad_norm: 320.9575  loss: 17.5511  decode.loss_cls: 0.0717  decode.loss_mask: 0.5644  decode.loss_dice: 1.1318  decode.d0.loss_cls: 0.0862  decode.d0.loss_mask: 0.5948  decode.d0.loss_dice: 1.2333  decode.d1.loss_cls: 0.0600  decode.d1.loss_mask: 0.5548  decode.d1.loss_dice: 1.1537  decode.d2.loss_cls: 0.0605  decode.d2.loss_mask: 0.5658  decode.d2.loss_dice: 1.1465  decode.d3.loss_cls: 0.0651  decode.d3.loss_mask: 0.5545  decode.d3.loss_dice: 1.0911  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.5583  decode.d4.loss_dice: 1.0895  decode.d5.loss_cls: 0.0657  decode.d5.loss_mask: 0.5544  decode.d5.loss_dice: 1.1276  decode.d6.loss_cls: 0.0659  decode.d6.loss_mask: 0.5491  decode.d6.loss_dice: 1.1015  decode.d7.loss_cls: 0.0660  decode.d7.loss_mask: 0.5535  decode.d7.loss_dice: 1.0817  decode.d8.loss_cls: 0.0757  decode.d8.loss_mask: 0.5572  decode.d8.loss_dice: 1.1098
11/15 13:23:02 - mmengine - INFO - Iter(train) [37600/90000]  base_lr: 6.1459e-05 lr: 6.1459e-06  eta: 8:48:12  time: 0.5995  data_time: 0.0103  memory: 10713  grad_norm: 773.1960  loss: 16.1543  decode.loss_cls: 0.0884  decode.loss_mask: 0.4078  decode.loss_dice: 1.1085  decode.d0.loss_cls: 0.0889  decode.d0.loss_mask: 0.4214  decode.d0.loss_dice: 1.1999  decode.d1.loss_cls: 0.1098  decode.d1.loss_mask: 0.4094  decode.d1.loss_dice: 1.1365  decode.d2.loss_cls: 0.1023  decode.d2.loss_mask: 0.4022  decode.d2.loss_dice: 1.1021  decode.d3.loss_cls: 0.0822  decode.d3.loss_mask: 0.4077  decode.d3.loss_dice: 1.1093  decode.d4.loss_cls: 0.1019  decode.d4.loss_mask: 0.4029  decode.d4.loss_dice: 1.0898  decode.d5.loss_cls: 0.0985  decode.d5.loss_mask: 0.4016  decode.d5.loss_dice: 1.0807  decode.d6.loss_cls: 0.1008  decode.d6.loss_mask: 0.4020  decode.d6.loss_dice: 1.0919  decode.d7.loss_cls: 0.1119  decode.d7.loss_mask: 0.4047  decode.d7.loss_dice: 1.1036  decode.d8.loss_cls: 0.0874  decode.d8.loss_mask: 0.4087  decode.d8.loss_dice: 1.0914
11/15 13:23:33 - mmengine - INFO - Iter(train) [37650/90000]  base_lr: 6.1406e-05 lr: 6.1406e-06  eta: 8:47:42  time: 0.5981  data_time: 0.0104  memory: 10713  grad_norm: 367.6626  loss: 17.9478  decode.loss_cls: 0.0655  decode.loss_mask: 0.6065  decode.loss_dice: 1.1209  decode.d0.loss_cls: 0.0821  decode.d0.loss_mask: 0.6312  decode.d0.loss_dice: 1.1936  decode.d1.loss_cls: 0.0743  decode.d1.loss_mask: 0.6266  decode.d1.loss_dice: 1.0980  decode.d2.loss_cls: 0.0754  decode.d2.loss_mask: 0.6210  decode.d2.loss_dice: 1.0906  decode.d3.loss_cls: 0.0689  decode.d3.loss_mask: 0.6163  decode.d3.loss_dice: 1.0811  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.6182  decode.d4.loss_dice: 1.0735  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 0.6055  decode.d5.loss_dice: 1.1325  decode.d6.loss_cls: 0.0597  decode.d6.loss_mask: 0.6070  decode.d6.loss_dice: 1.0914  decode.d7.loss_cls: 0.0685  decode.d7.loss_mask: 0.6197  decode.d7.loss_dice: 1.0963  decode.d8.loss_cls: 0.0634  decode.d8.loss_mask: 0.6178  decode.d8.loss_dice: 1.1113
11/15 13:24:03 - mmengine - INFO - Iter(train) [37700/90000]  base_lr: 6.1353e-05 lr: 6.1353e-06  eta: 8:47:11  time: 0.5995  data_time: 0.0103  memory: 10656  grad_norm: 323.9016  loss: 16.7196  decode.loss_cls: 0.0595  decode.loss_mask: 0.4906  decode.loss_dice: 1.1088  decode.d0.loss_cls: 0.0877  decode.d0.loss_mask: 0.4862  decode.d0.loss_dice: 1.1677  decode.d1.loss_cls: 0.0600  decode.d1.loss_mask: 0.5003  decode.d1.loss_dice: 1.1291  decode.d2.loss_cls: 0.0586  decode.d2.loss_mask: 0.4924  decode.d2.loss_dice: 1.1033  decode.d3.loss_cls: 0.0523  decode.d3.loss_mask: 0.4848  decode.d3.loss_dice: 1.1114  decode.d4.loss_cls: 0.0639  decode.d4.loss_mask: 0.4813  decode.d4.loss_dice: 1.0997  decode.d5.loss_cls: 0.0519  decode.d5.loss_mask: 0.4942  decode.d5.loss_dice: 1.1268  decode.d6.loss_cls: 0.0491  decode.d6.loss_mask: 0.5087  decode.d6.loss_dice: 1.1232  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.4936  decode.d7.loss_dice: 1.0975  decode.d8.loss_cls: 0.0493  decode.d8.loss_mask: 0.4945  decode.d8.loss_dice: 1.1332
11/15 13:24:33 - mmengine - INFO - Iter(train) [37750/90000]  base_lr: 6.1300e-05 lr: 6.1300e-06  eta: 8:46:40  time: 0.5975  data_time: 0.0105  memory: 10713  grad_norm: 347.3352  loss: 17.7979  decode.loss_cls: 0.0840  decode.loss_mask: 0.5569  decode.loss_dice: 1.0868  decode.d0.loss_cls: 0.0964  decode.d0.loss_mask: 0.5885  decode.d0.loss_dice: 1.2181  decode.d1.loss_cls: 0.0765  decode.d1.loss_mask: 0.5924  decode.d1.loss_dice: 1.1661  decode.d2.loss_cls: 0.0814  decode.d2.loss_mask: 0.5687  decode.d2.loss_dice: 1.1177  decode.d3.loss_cls: 0.0844  decode.d3.loss_mask: 0.5707  decode.d3.loss_dice: 1.0684  decode.d4.loss_cls: 0.0736  decode.d4.loss_mask: 0.5832  decode.d4.loss_dice: 1.0978  decode.d5.loss_cls: 0.0767  decode.d5.loss_mask: 0.5799  decode.d5.loss_dice: 1.1066  decode.d6.loss_cls: 0.0764  decode.d6.loss_mask: 0.5954  decode.d6.loss_dice: 1.0976  decode.d7.loss_cls: 0.0816  decode.d7.loss_mask: 0.5966  decode.d7.loss_dice: 1.1390  decode.d8.loss_cls: 0.0876  decode.d8.loss_mask: 0.5688  decode.d8.loss_dice: 1.0802
11/15 13:25:03 - mmengine - INFO - Iter(train) [37800/90000]  base_lr: 6.1248e-05 lr: 6.1248e-06  eta: 8:46:10  time: 0.6014  data_time: 0.0106  memory: 10675  grad_norm: 279.3028  loss: 16.0648  decode.loss_cls: 0.0543  decode.loss_mask: 0.4746  decode.loss_dice: 1.0664  decode.d0.loss_cls: 0.0726  decode.d0.loss_mask: 0.4866  decode.d0.loss_dice: 1.1349  decode.d1.loss_cls: 0.0546  decode.d1.loss_mask: 0.4723  decode.d1.loss_dice: 1.0866  decode.d2.loss_cls: 0.0482  decode.d2.loss_mask: 0.4714  decode.d2.loss_dice: 1.0647  decode.d3.loss_cls: 0.0476  decode.d3.loss_mask: 0.4695  decode.d3.loss_dice: 1.0714  decode.d4.loss_cls: 0.0478  decode.d4.loss_mask: 0.4701  decode.d4.loss_dice: 1.0737  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.4679  decode.d5.loss_dice: 1.0728  decode.d6.loss_cls: 0.0496  decode.d6.loss_mask: 0.4725  decode.d6.loss_dice: 1.0720  decode.d7.loss_cls: 0.0528  decode.d7.loss_mask: 0.4770  decode.d7.loss_dice: 1.0791  decode.d8.loss_cls: 0.0552  decode.d8.loss_mask: 0.4778  decode.d8.loss_dice: 1.0666
11/15 13:25:33 - mmengine - INFO - Iter(train) [37850/90000]  base_lr: 6.1195e-05 lr: 6.1195e-06  eta: 8:45:39  time: 0.5990  data_time: 0.0120  memory: 10692  grad_norm: 460.1965  loss: 18.0301  decode.loss_cls: 0.0556  decode.loss_mask: 0.6248  decode.loss_dice: 1.1381  decode.d0.loss_cls: 0.0711  decode.d0.loss_mask: 0.6531  decode.d0.loss_dice: 1.2159  decode.d1.loss_cls: 0.0632  decode.d1.loss_mask: 0.6133  decode.d1.loss_dice: 1.1291  decode.d2.loss_cls: 0.0574  decode.d2.loss_mask: 0.6209  decode.d2.loss_dice: 1.0918  decode.d3.loss_cls: 0.0572  decode.d3.loss_mask: 0.6136  decode.d3.loss_dice: 1.1072  decode.d4.loss_cls: 0.0596  decode.d4.loss_mask: 0.6139  decode.d4.loss_dice: 1.1175  decode.d5.loss_cls: 0.0623  decode.d5.loss_mask: 0.6182  decode.d5.loss_dice: 1.0668  decode.d6.loss_cls: 0.0561  decode.d6.loss_mask: 0.6286  decode.d6.loss_dice: 1.1078  decode.d7.loss_cls: 0.0562  decode.d7.loss_mask: 0.6242  decode.d7.loss_dice: 1.1084  decode.d8.loss_cls: 0.0606  decode.d8.loss_mask: 0.6297  decode.d8.loss_dice: 1.1081
11/15 13:26:02 - mmengine - INFO - Iter(train) [37900/90000]  base_lr: 6.1142e-05 lr: 6.1142e-06  eta: 8:45:08  time: 0.5983  data_time: 0.0105  memory: 10675  grad_norm: 2770.2111  loss: 15.5337  decode.loss_cls: 0.0513  decode.loss_mask: 0.4430  decode.loss_dice: 1.0464  decode.d0.loss_cls: 0.0769  decode.d0.loss_mask: 0.4465  decode.d0.loss_dice: 1.1104  decode.d1.loss_cls: 0.0471  decode.d1.loss_mask: 0.4344  decode.d1.loss_dice: 1.0760  decode.d2.loss_cls: 0.0611  decode.d2.loss_mask: 0.4402  decode.d2.loss_dice: 1.0534  decode.d3.loss_cls: 0.0472  decode.d3.loss_mask: 0.4420  decode.d3.loss_dice: 1.0449  decode.d4.loss_cls: 0.0486  decode.d4.loss_mask: 0.4398  decode.d4.loss_dice: 1.0510  decode.d5.loss_cls: 0.0520  decode.d5.loss_mask: 0.4452  decode.d5.loss_dice: 1.0608  decode.d6.loss_cls: 0.0505  decode.d6.loss_mask: 0.4443  decode.d6.loss_dice: 1.0380  decode.d7.loss_cls: 0.0532  decode.d7.loss_mask: 0.4418  decode.d7.loss_dice: 1.0389  decode.d8.loss_cls: 0.0460  decode.d8.loss_mask: 0.4512  decode.d8.loss_dice: 1.0515
11/15 13:26:32 - mmengine - INFO - Iter(train) [37950/90000]  base_lr: 6.1089e-05 lr: 6.1089e-06  eta: 8:44:38  time: 0.6010  data_time: 0.0105  memory: 10656  grad_norm: 363.3232  loss: 16.7395  decode.loss_cls: 0.0614  decode.loss_mask: 0.5621  decode.loss_dice: 1.0386  decode.d0.loss_cls: 0.0997  decode.d0.loss_mask: 0.5719  decode.d0.loss_dice: 1.0736  decode.d1.loss_cls: 0.0679  decode.d1.loss_mask: 0.5717  decode.d1.loss_dice: 1.0736  decode.d2.loss_cls: 0.0722  decode.d2.loss_mask: 0.5534  decode.d2.loss_dice: 1.0449  decode.d3.loss_cls: 0.0655  decode.d3.loss_mask: 0.5650  decode.d3.loss_dice: 1.0415  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 0.5621  decode.d4.loss_dice: 1.0588  decode.d5.loss_cls: 0.0721  decode.d5.loss_mask: 0.5521  decode.d5.loss_dice: 1.0291  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.5674  decode.d6.loss_dice: 1.0186  decode.d7.loss_cls: 0.0644  decode.d7.loss_mask: 0.5464  decode.d7.loss_dice: 1.0100  decode.d8.loss_cls: 0.0582  decode.d8.loss_mask: 0.5723  decode.d8.loss_dice: 1.0396
11/15 13:27:02 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 13:27:02 - mmengine - INFO - Iter(train) [38000/90000]  base_lr: 6.1036e-05 lr: 6.1036e-06  eta: 8:44:07  time: 0.6007  data_time: 0.0104  memory: 10675  grad_norm: 375.8712  loss: 15.6620  decode.loss_cls: 0.0512  decode.loss_mask: 0.5279  decode.loss_dice: 0.9512  decode.d0.loss_cls: 0.0681  decode.d0.loss_mask: 0.5637  decode.d0.loss_dice: 0.9971  decode.d1.loss_cls: 0.0477  decode.d1.loss_mask: 0.5469  decode.d1.loss_dice: 1.0132  decode.d2.loss_cls: 0.0503  decode.d2.loss_mask: 0.5412  decode.d2.loss_dice: 1.0046  decode.d3.loss_cls: 0.0524  decode.d3.loss_mask: 0.5311  decode.d3.loss_dice: 0.9391  decode.d4.loss_cls: 0.0548  decode.d4.loss_mask: 0.5338  decode.d4.loss_dice: 0.9532  decode.d5.loss_cls: 0.0520  decode.d5.loss_mask: 0.5384  decode.d5.loss_dice: 0.9466  decode.d6.loss_cls: 0.0493  decode.d6.loss_mask: 0.5503  decode.d6.loss_dice: 0.9576  decode.d7.loss_cls: 0.0504  decode.d7.loss_mask: 0.5513  decode.d7.loss_dice: 0.9615  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 0.5454  decode.d8.loss_dice: 0.9726
11/15 13:27:32 - mmengine - INFO - Iter(train) [38050/90000]  base_lr: 6.0984e-05 lr: 6.0984e-06  eta: 8:43:37  time: 0.5983  data_time: 0.0102  memory: 10675  grad_norm: 507.6924  loss: 16.9461  decode.loss_cls: 0.0607  decode.loss_mask: 0.5279  decode.loss_dice: 1.1136  decode.d0.loss_cls: 0.0954  decode.d0.loss_mask: 0.5129  decode.d0.loss_dice: 1.1599  decode.d1.loss_cls: 0.0706  decode.d1.loss_mask: 0.5171  decode.d1.loss_dice: 1.1300  decode.d2.loss_cls: 0.0594  decode.d2.loss_mask: 0.5111  decode.d2.loss_dice: 1.1239  decode.d3.loss_cls: 0.0658  decode.d3.loss_mask: 0.5031  decode.d3.loss_dice: 1.0889  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.5073  decode.d4.loss_dice: 1.0874  decode.d5.loss_cls: 0.0569  decode.d5.loss_mask: 0.5313  decode.d5.loss_dice: 1.0965  decode.d6.loss_cls: 0.0538  decode.d6.loss_mask: 0.5287  decode.d6.loss_dice: 1.0923  decode.d7.loss_cls: 0.0517  decode.d7.loss_mask: 0.5333  decode.d7.loss_dice: 1.1050  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.5292  decode.d8.loss_dice: 1.1049
11/15 13:28:02 - mmengine - INFO - Iter(train) [38100/90000]  base_lr: 6.0931e-05 lr: 6.0931e-06  eta: 8:43:06  time: 0.5974  data_time: 0.0102  memory: 10675  grad_norm: 353.6296  loss: 16.3677  decode.loss_cls: 0.0597  decode.loss_mask: 0.5246  decode.loss_dice: 1.0388  decode.d0.loss_cls: 0.0771  decode.d0.loss_mask: 0.5238  decode.d0.loss_dice: 1.1326  decode.d1.loss_cls: 0.0564  decode.d1.loss_mask: 0.5198  decode.d1.loss_dice: 1.1147  decode.d2.loss_cls: 0.0537  decode.d2.loss_mask: 0.5039  decode.d2.loss_dice: 1.0689  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.5077  decode.d3.loss_dice: 1.0574  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.4943  decode.d4.loss_dice: 1.0694  decode.d5.loss_cls: 0.0572  decode.d5.loss_mask: 0.4985  decode.d5.loss_dice: 1.0600  decode.d6.loss_cls: 0.0632  decode.d6.loss_mask: 0.4869  decode.d6.loss_dice: 1.0447  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 0.4882  decode.d7.loss_dice: 1.0720  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.4885  decode.d8.loss_dice: 1.0604
11/15 13:28:32 - mmengine - INFO - Iter(train) [38150/90000]  base_lr: 6.0878e-05 lr: 6.0878e-06  eta: 8:42:35  time: 0.6152  data_time: 0.0106  memory: 10713  grad_norm: 355.8725  loss: 17.5506  decode.loss_cls: 0.0821  decode.loss_mask: 0.4849  decode.loss_dice: 1.1486  decode.d0.loss_cls: 0.1046  decode.d0.loss_mask: 0.4996  decode.d0.loss_dice: 1.2645  decode.d1.loss_cls: 0.0915  decode.d1.loss_mask: 0.4871  decode.d1.loss_dice: 1.1625  decode.d2.loss_cls: 0.0780  decode.d2.loss_mask: 0.4947  decode.d2.loss_dice: 1.1351  decode.d3.loss_cls: 0.0856  decode.d3.loss_mask: 0.5071  decode.d3.loss_dice: 1.1514  decode.d4.loss_cls: 0.0761  decode.d4.loss_mask: 0.5095  decode.d4.loss_dice: 1.1692  decode.d5.loss_cls: 0.0851  decode.d5.loss_mask: 0.4924  decode.d5.loss_dice: 1.1252  decode.d6.loss_cls: 0.0774  decode.d6.loss_mask: 0.5043  decode.d6.loss_dice: 1.2195  decode.d7.loss_cls: 0.0860  decode.d7.loss_mask: 0.4950  decode.d7.loss_dice: 1.1608  decode.d8.loss_cls: 0.0786  decode.d8.loss_mask: 0.5040  decode.d8.loss_dice: 1.1903
11/15 13:29:02 - mmengine - INFO - Iter(train) [38200/90000]  base_lr: 6.0825e-05 lr: 6.0825e-06  eta: 8:42:05  time: 0.5979  data_time: 0.0102  memory: 10758  grad_norm: 467.9959  loss: 19.1348  decode.loss_cls: 0.1022  decode.loss_mask: 0.5229  decode.loss_dice: 1.2598  decode.d0.loss_cls: 0.0904  decode.d0.loss_mask: 0.5610  decode.d0.loss_dice: 1.3920  decode.d1.loss_cls: 0.0916  decode.d1.loss_mask: 0.5366  decode.d1.loss_dice: 1.3347  decode.d2.loss_cls: 0.0910  decode.d2.loss_mask: 0.5354  decode.d2.loss_dice: 1.2914  decode.d3.loss_cls: 0.0935  decode.d3.loss_mask: 0.5369  decode.d3.loss_dice: 1.2604  decode.d4.loss_cls: 0.0945  decode.d4.loss_mask: 0.5411  decode.d4.loss_dice: 1.2532  decode.d5.loss_cls: 0.1018  decode.d5.loss_mask: 0.5301  decode.d5.loss_dice: 1.2998  decode.d6.loss_cls: 0.1007  decode.d6.loss_mask: 0.5254  decode.d6.loss_dice: 1.2663  decode.d7.loss_cls: 0.0908  decode.d7.loss_mask: 0.5210  decode.d7.loss_dice: 1.2584  decode.d8.loss_cls: 0.0967  decode.d8.loss_mask: 0.5210  decode.d8.loss_dice: 1.2344
11/15 13:29:32 - mmengine - INFO - Iter(train) [38250/90000]  base_lr: 6.0772e-05 lr: 6.0772e-06  eta: 8:41:34  time: 0.6033  data_time: 0.0106  memory: 10692  grad_norm: 430.4908  loss: 16.7452  decode.loss_cls: 0.0546  decode.loss_mask: 0.5122  decode.loss_dice: 1.0980  decode.d0.loss_cls: 0.0776  decode.d0.loss_mask: 0.5304  decode.d0.loss_dice: 1.1502  decode.d1.loss_cls: 0.0575  decode.d1.loss_mask: 0.5117  decode.d1.loss_dice: 1.1339  decode.d2.loss_cls: 0.0642  decode.d2.loss_mask: 0.5094  decode.d2.loss_dice: 1.1049  decode.d3.loss_cls: 0.0518  decode.d3.loss_mask: 0.5097  decode.d3.loss_dice: 1.0920  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.5085  decode.d4.loss_dice: 1.0900  decode.d5.loss_cls: 0.0514  decode.d5.loss_mask: 0.5057  decode.d5.loss_dice: 1.0966  decode.d6.loss_cls: 0.0519  decode.d6.loss_mask: 0.5042  decode.d6.loss_dice: 1.1021  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.5019  decode.d7.loss_dice: 1.1042  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.5057  decode.d8.loss_dice: 1.0949
11/15 13:30:02 - mmengine - INFO - Iter(train) [38300/90000]  base_lr: 6.0719e-05 lr: 6.0719e-06  eta: 8:41:03  time: 0.6016  data_time: 0.0104  memory: 10713  grad_norm: 668.6630  loss: 18.4238  decode.loss_cls: 0.0863  decode.loss_mask: 0.5648  decode.loss_dice: 1.2141  decode.d0.loss_cls: 0.1033  decode.d0.loss_mask: 0.5307  decode.d0.loss_dice: 1.2652  decode.d1.loss_cls: 0.0701  decode.d1.loss_mask: 0.5133  decode.d1.loss_dice: 1.2280  decode.d2.loss_cls: 0.0695  decode.d2.loss_mask: 0.5559  decode.d2.loss_dice: 1.2222  decode.d3.loss_cls: 0.0666  decode.d3.loss_mask: 0.5296  decode.d3.loss_dice: 1.2095  decode.d4.loss_cls: 0.0783  decode.d4.loss_mask: 0.5286  decode.d4.loss_dice: 1.1804  decode.d5.loss_cls: 0.0799  decode.d5.loss_mask: 0.5754  decode.d5.loss_dice: 1.2168  decode.d6.loss_cls: 0.0894  decode.d6.loss_mask: 0.5657  decode.d6.loss_dice: 1.2017  decode.d7.loss_cls: 0.0798  decode.d7.loss_mask: 0.5626  decode.d7.loss_dice: 1.2124  decode.d8.loss_cls: 0.0778  decode.d8.loss_mask: 0.5513  decode.d8.loss_dice: 1.1947
11/15 13:30:32 - mmengine - INFO - Iter(train) [38350/90000]  base_lr: 6.0667e-05 lr: 6.0667e-06  eta: 8:40:33  time: 0.5967  data_time: 0.0102  memory: 10675  grad_norm: 453.5670  loss: 17.4908  decode.loss_cls: 0.0593  decode.loss_mask: 0.6400  decode.loss_dice: 1.0364  decode.d0.loss_cls: 0.0905  decode.d0.loss_mask: 0.6496  decode.d0.loss_dice: 1.0948  decode.d1.loss_cls: 0.0547  decode.d1.loss_mask: 0.6214  decode.d1.loss_dice: 1.0655  decode.d2.loss_cls: 0.0567  decode.d2.loss_mask: 0.6238  decode.d2.loss_dice: 1.0453  decode.d3.loss_cls: 0.0547  decode.d3.loss_mask: 0.6333  decode.d3.loss_dice: 1.0510  decode.d4.loss_cls: 0.0555  decode.d4.loss_mask: 0.6467  decode.d4.loss_dice: 1.0425  decode.d5.loss_cls: 0.0598  decode.d5.loss_mask: 0.6269  decode.d5.loss_dice: 1.0518  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.6350  decode.d6.loss_dice: 1.0413  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.6377  decode.d7.loss_dice: 1.0472  decode.d8.loss_cls: 0.0531  decode.d8.loss_mask: 0.6403  decode.d8.loss_dice: 1.0670
11/15 13:31:02 - mmengine - INFO - Iter(train) [38400/90000]  base_lr: 6.0614e-05 lr: 6.0614e-06  eta: 8:40:02  time: 0.5978  data_time: 0.0104  memory: 10675  grad_norm: 306.9555  loss: 18.2157  decode.loss_cls: 0.0821  decode.loss_mask: 0.5444  decode.loss_dice: 1.2117  decode.d0.loss_cls: 0.0879  decode.d0.loss_mask: 0.5595  decode.d0.loss_dice: 1.2112  decode.d1.loss_cls: 0.0707  decode.d1.loss_mask: 0.5558  decode.d1.loss_dice: 1.1825  decode.d2.loss_cls: 0.0732  decode.d2.loss_mask: 0.5370  decode.d2.loss_dice: 1.1963  decode.d3.loss_cls: 0.0726  decode.d3.loss_mask: 0.5474  decode.d3.loss_dice: 1.2076  decode.d4.loss_cls: 0.0902  decode.d4.loss_mask: 0.5422  decode.d4.loss_dice: 1.1963  decode.d5.loss_cls: 0.0828  decode.d5.loss_mask: 0.5416  decode.d5.loss_dice: 1.1948  decode.d6.loss_cls: 0.0784  decode.d6.loss_mask: 0.5312  decode.d6.loss_dice: 1.1793  decode.d7.loss_cls: 0.0841  decode.d7.loss_mask: 0.5390  decode.d7.loss_dice: 1.2025  decode.d8.loss_cls: 0.0834  decode.d8.loss_mask: 0.5402  decode.d8.loss_dice: 1.1897
11/15 13:31:32 - mmengine - INFO - Iter(train) [38450/90000]  base_lr: 6.0561e-05 lr: 6.0561e-06  eta: 8:39:31  time: 0.5983  data_time: 0.0103  memory: 10692  grad_norm: 364.3676  loss: 16.8731  decode.loss_cls: 0.0618  decode.loss_mask: 0.5913  decode.loss_dice: 1.0499  decode.d0.loss_cls: 0.1032  decode.d0.loss_mask: 0.5736  decode.d0.loss_dice: 1.0593  decode.d1.loss_cls: 0.0558  decode.d1.loss_mask: 0.5877  decode.d1.loss_dice: 1.0451  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.5841  decode.d2.loss_dice: 1.0720  decode.d3.loss_cls: 0.0532  decode.d3.loss_mask: 0.5796  decode.d3.loss_dice: 1.0273  decode.d4.loss_cls: 0.0577  decode.d4.loss_mask: 0.5789  decode.d4.loss_dice: 1.0465  decode.d5.loss_cls: 0.0685  decode.d5.loss_mask: 0.5723  decode.d5.loss_dice: 1.0135  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.5836  decode.d6.loss_dice: 1.0402  decode.d7.loss_cls: 0.0519  decode.d7.loss_mask: 0.5952  decode.d7.loss_dice: 1.0463  decode.d8.loss_cls: 0.0517  decode.d8.loss_mask: 0.5816  decode.d8.loss_dice: 1.0365
11/15 13:32:02 - mmengine - INFO - Iter(train) [38500/90000]  base_lr: 6.0508e-05 lr: 6.0508e-06  eta: 8:39:01  time: 0.5969  data_time: 0.0102  memory: 10656  grad_norm: 771.2707  loss: 16.4717  decode.loss_cls: 0.0564  decode.loss_mask: 0.4823  decode.loss_dice: 1.0813  decode.d0.loss_cls: 0.0991  decode.d0.loss_mask: 0.5087  decode.d0.loss_dice: 1.1490  decode.d1.loss_cls: 0.0575  decode.d1.loss_mask: 0.4957  decode.d1.loss_dice: 1.1480  decode.d2.loss_cls: 0.0595  decode.d2.loss_mask: 0.4925  decode.d2.loss_dice: 1.0930  decode.d3.loss_cls: 0.0540  decode.d3.loss_mask: 0.4858  decode.d3.loss_dice: 1.0976  decode.d4.loss_cls: 0.0542  decode.d4.loss_mask: 0.4868  decode.d4.loss_dice: 1.0884  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.4847  decode.d5.loss_dice: 1.0922  decode.d6.loss_cls: 0.0522  decode.d6.loss_mask: 0.4757  decode.d6.loss_dice: 1.0836  decode.d7.loss_cls: 0.0527  decode.d7.loss_mask: 0.4736  decode.d7.loss_dice: 1.0823  decode.d8.loss_cls: 0.0492  decode.d8.loss_mask: 0.4739  decode.d8.loss_dice: 1.1123
11/15 13:32:32 - mmengine - INFO - Iter(train) [38550/90000]  base_lr: 6.0455e-05 lr: 6.0455e-06  eta: 8:38:30  time: 0.5974  data_time: 0.0102  memory: 10641  grad_norm: 301.6422  loss: 19.2318  decode.loss_cls: 0.0777  decode.loss_mask: 0.5555  decode.loss_dice: 1.2485  decode.d0.loss_cls: 0.0989  decode.d0.loss_mask: 0.5817  decode.d0.loss_dice: 1.3510  decode.d1.loss_cls: 0.0636  decode.d1.loss_mask: 0.5901  decode.d1.loss_dice: 1.3320  decode.d2.loss_cls: 0.0788  decode.d2.loss_mask: 0.5592  decode.d2.loss_dice: 1.2803  decode.d3.loss_cls: 0.0675  decode.d3.loss_mask: 0.5590  decode.d3.loss_dice: 1.2679  decode.d4.loss_cls: 0.0716  decode.d4.loss_mask: 0.5534  decode.d4.loss_dice: 1.2794  decode.d5.loss_cls: 0.0518  decode.d5.loss_mask: 0.5793  decode.d5.loss_dice: 1.3118  decode.d6.loss_cls: 0.0605  decode.d6.loss_mask: 0.5630  decode.d6.loss_dice: 1.2613  decode.d7.loss_cls: 0.0568  decode.d7.loss_mask: 0.5576  decode.d7.loss_dice: 1.2764  decode.d8.loss_cls: 0.0832  decode.d8.loss_mask: 0.5611  decode.d8.loss_dice: 1.2528
11/15 13:33:01 - mmengine - INFO - Iter(train) [38600/90000]  base_lr: 6.0402e-05 lr: 6.0402e-06  eta: 8:37:59  time: 0.5976  data_time: 0.0103  memory: 10675  grad_norm: 284.5937  loss: 16.3517  decode.loss_cls: 0.0648  decode.loss_mask: 0.4180  decode.loss_dice: 1.1089  decode.d0.loss_cls: 0.0705  decode.d0.loss_mask: 0.4550  decode.d0.loss_dice: 1.2362  decode.d1.loss_cls: 0.0696  decode.d1.loss_mask: 0.4490  decode.d1.loss_dice: 1.1548  decode.d2.loss_cls: 0.0734  decode.d2.loss_mask: 0.4362  decode.d2.loss_dice: 1.1593  decode.d3.loss_cls: 0.0775  decode.d3.loss_mask: 0.4222  decode.d3.loss_dice: 1.1075  decode.d4.loss_cls: 0.0695  decode.d4.loss_mask: 0.4235  decode.d4.loss_dice: 1.1229  decode.d5.loss_cls: 0.0750  decode.d5.loss_mask: 0.4289  decode.d5.loss_dice: 1.1023  decode.d6.loss_cls: 0.0715  decode.d6.loss_mask: 0.4295  decode.d6.loss_dice: 1.0989  decode.d7.loss_cls: 0.0694  decode.d7.loss_mask: 0.4246  decode.d7.loss_dice: 1.1213  decode.d8.loss_cls: 0.0558  decode.d8.loss_mask: 0.4248  decode.d8.loss_dice: 1.1309
11/15 13:33:32 - mmengine - INFO - Iter(train) [38650/90000]  base_lr: 6.0349e-05 lr: 6.0349e-06  eta: 8:37:29  time: 0.5994  data_time: 0.0105  memory: 10675  grad_norm: 384.8278  loss: 16.7922  decode.loss_cls: 0.0424  decode.loss_mask: 0.5382  decode.loss_dice: 1.0711  decode.d0.loss_cls: 0.0863  decode.d0.loss_mask: 0.5748  decode.d0.loss_dice: 1.1183  decode.d1.loss_cls: 0.0610  decode.d1.loss_mask: 0.5406  decode.d1.loss_dice: 1.0728  decode.d2.loss_cls: 0.0497  decode.d2.loss_mask: 0.5350  decode.d2.loss_dice: 1.1030  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.5352  decode.d3.loss_dice: 1.0918  decode.d4.loss_cls: 0.0590  decode.d4.loss_mask: 0.5375  decode.d4.loss_dice: 1.0526  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.5352  decode.d5.loss_dice: 1.1063  decode.d6.loss_cls: 0.0439  decode.d6.loss_mask: 0.5369  decode.d6.loss_dice: 1.0680  decode.d7.loss_cls: 0.0494  decode.d7.loss_mask: 0.5356  decode.d7.loss_dice: 1.0614  decode.d8.loss_cls: 0.0389  decode.d8.loss_mask: 0.5403  decode.d8.loss_dice: 1.0921
11/15 13:34:02 - mmengine - INFO - Iter(train) [38700/90000]  base_lr: 6.0296e-05 lr: 6.0296e-06  eta: 8:36:58  time: 0.5976  data_time: 0.0102  memory: 10675  grad_norm: 426.2033  loss: 16.9510  decode.loss_cls: 0.0640  decode.loss_mask: 0.5308  decode.loss_dice: 1.1067  decode.d0.loss_cls: 0.0879  decode.d0.loss_mask: 0.5230  decode.d0.loss_dice: 1.1708  decode.d1.loss_cls: 0.0617  decode.d1.loss_mask: 0.5217  decode.d1.loss_dice: 1.1483  decode.d2.loss_cls: 0.0624  decode.d2.loss_mask: 0.5218  decode.d2.loss_dice: 1.1039  decode.d3.loss_cls: 0.0793  decode.d3.loss_mask: 0.5043  decode.d3.loss_dice: 1.0885  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.5032  decode.d4.loss_dice: 1.0822  decode.d5.loss_cls: 0.0805  decode.d5.loss_mask: 0.5097  decode.d5.loss_dice: 1.0696  decode.d6.loss_cls: 0.0818  decode.d6.loss_mask: 0.5138  decode.d6.loss_dice: 1.0842  decode.d7.loss_cls: 0.0851  decode.d7.loss_mask: 0.5147  decode.d7.loss_dice: 1.0952  decode.d8.loss_cls: 0.0762  decode.d8.loss_mask: 0.5173  decode.d8.loss_dice: 1.0853
11/15 13:34:32 - mmengine - INFO - Iter(train) [38750/90000]  base_lr: 6.0244e-05 lr: 6.0244e-06  eta: 8:36:28  time: 0.5977  data_time: 0.0103  memory: 10656  grad_norm: 361.7127  loss: 15.8249  decode.loss_cls: 0.0472  decode.loss_mask: 0.4756  decode.loss_dice: 1.0491  decode.d0.loss_cls: 0.0647  decode.d0.loss_mask: 0.5090  decode.d0.loss_dice: 1.0984  decode.d1.loss_cls: 0.0417  decode.d1.loss_mask: 0.4929  decode.d1.loss_dice: 1.0817  decode.d2.loss_cls: 0.0502  decode.d2.loss_mask: 0.4884  decode.d2.loss_dice: 1.0048  decode.d3.loss_cls: 0.0563  decode.d3.loss_mask: 0.4821  decode.d3.loss_dice: 1.0263  decode.d4.loss_cls: 0.0464  decode.d4.loss_mask: 0.4790  decode.d4.loss_dice: 1.0618  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.4742  decode.d5.loss_dice: 1.0208  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.4815  decode.d6.loss_dice: 1.0296  decode.d7.loss_cls: 0.0516  decode.d7.loss_mask: 0.4806  decode.d7.loss_dice: 1.0403  decode.d8.loss_cls: 0.0528  decode.d8.loss_mask: 0.4764  decode.d8.loss_dice: 1.0455
11/15 13:35:01 - mmengine - INFO - Iter(train) [38800/90000]  base_lr: 6.0191e-05 lr: 6.0191e-06  eta: 8:35:57  time: 0.5973  data_time: 0.0101  memory: 10758  grad_norm: 438.1780  loss: 16.1313  decode.loss_cls: 0.0772  decode.loss_mask: 0.4240  decode.loss_dice: 1.0722  decode.d0.loss_cls: 0.0883  decode.d0.loss_mask: 0.4505  decode.d0.loss_dice: 1.1708  decode.d1.loss_cls: 0.0738  decode.d1.loss_mask: 0.4334  decode.d1.loss_dice: 1.1272  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.4365  decode.d2.loss_dice: 1.1304  decode.d3.loss_cls: 0.0759  decode.d3.loss_mask: 0.4283  decode.d3.loss_dice: 1.0998  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.4240  decode.d4.loss_dice: 1.0906  decode.d5.loss_cls: 0.0802  decode.d5.loss_mask: 0.4310  decode.d5.loss_dice: 1.1096  decode.d6.loss_cls: 0.0808  decode.d6.loss_mask: 0.4247  decode.d6.loss_dice: 1.0745  decode.d7.loss_cls: 0.0784  decode.d7.loss_mask: 0.4312  decode.d7.loss_dice: 1.0925  decode.d8.loss_cls: 0.0763  decode.d8.loss_mask: 0.4316  decode.d8.loss_dice: 1.0847
11/15 13:35:31 - mmengine - INFO - Iter(train) [38850/90000]  base_lr: 6.0138e-05 lr: 6.0138e-06  eta: 8:35:26  time: 0.5973  data_time: 0.0103  memory: 10675  grad_norm: 444.1506  loss: 16.7108  decode.loss_cls: 0.0539  decode.loss_mask: 0.4755  decode.loss_dice: 1.1360  decode.d0.loss_cls: 0.0824  decode.d0.loss_mask: 0.5091  decode.d0.loss_dice: 1.1839  decode.d1.loss_cls: 0.0654  decode.d1.loss_mask: 0.4808  decode.d1.loss_dice: 1.1444  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 0.4796  decode.d2.loss_dice: 1.1095  decode.d3.loss_cls: 0.0561  decode.d3.loss_mask: 0.4820  decode.d3.loss_dice: 1.0905  decode.d4.loss_cls: 0.0584  decode.d4.loss_mask: 0.4814  decode.d4.loss_dice: 1.1088  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.4816  decode.d5.loss_dice: 1.1117  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.4749  decode.d6.loss_dice: 1.1281  decode.d7.loss_cls: 0.0591  decode.d7.loss_mask: 0.4904  decode.d7.loss_dice: 1.1102  decode.d8.loss_cls: 0.0560  decode.d8.loss_mask: 0.4787  decode.d8.loss_dice: 1.1370
11/15 13:36:01 - mmengine - INFO - Iter(train) [38900/90000]  base_lr: 6.0085e-05 lr: 6.0085e-06  eta: 8:34:56  time: 0.5979  data_time: 0.0103  memory: 10675  grad_norm: 241.7708  loss: 15.7841  decode.loss_cls: 0.0602  decode.loss_mask: 0.4750  decode.loss_dice: 1.0253  decode.d0.loss_cls: 0.0562  decode.d0.loss_mask: 0.5228  decode.d0.loss_dice: 1.0933  decode.d1.loss_cls: 0.0634  decode.d1.loss_mask: 0.4748  decode.d1.loss_dice: 1.0502  decode.d2.loss_cls: 0.0519  decode.d2.loss_mask: 0.4731  decode.d2.loss_dice: 1.0421  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.4764  decode.d3.loss_dice: 1.0281  decode.d4.loss_cls: 0.0622  decode.d4.loss_mask: 0.4739  decode.d4.loss_dice: 1.0188  decode.d5.loss_cls: 0.0553  decode.d5.loss_mask: 0.4714  decode.d5.loss_dice: 1.0527  decode.d6.loss_cls: 0.0585  decode.d6.loss_mask: 0.4739  decode.d6.loss_dice: 1.0310  decode.d7.loss_cls: 0.0579  decode.d7.loss_mask: 0.4731  decode.d7.loss_dice: 1.0182  decode.d8.loss_cls: 0.0542  decode.d8.loss_mask: 0.4788  decode.d8.loss_dice: 1.0491
11/15 13:36:31 - mmengine - INFO - Iter(train) [38950/90000]  base_lr: 6.0032e-05 lr: 6.0032e-06  eta: 8:34:25  time: 0.5973  data_time: 0.0103  memory: 10675  grad_norm: 229.6236  loss: 18.3293  decode.loss_cls: 0.1130  decode.loss_mask: 0.4939  decode.loss_dice: 1.1924  decode.d0.loss_cls: 0.0956  decode.d0.loss_mask: 0.5170  decode.d0.loss_dice: 1.3296  decode.d1.loss_cls: 0.1002  decode.d1.loss_mask: 0.4987  decode.d1.loss_dice: 1.2524  decode.d2.loss_cls: 0.1032  decode.d2.loss_mask: 0.5049  decode.d2.loss_dice: 1.2507  decode.d3.loss_cls: 0.1098  decode.d3.loss_mask: 0.5000  decode.d3.loss_dice: 1.2460  decode.d4.loss_cls: 0.1000  decode.d4.loss_mask: 0.4939  decode.d4.loss_dice: 1.2139  decode.d5.loss_cls: 0.1048  decode.d5.loss_mask: 0.5087  decode.d5.loss_dice: 1.2078  decode.d6.loss_cls: 0.0988  decode.d6.loss_mask: 0.5090  decode.d6.loss_dice: 1.1792  decode.d7.loss_cls: 0.1054  decode.d7.loss_mask: 0.5018  decode.d7.loss_dice: 1.1927  decode.d8.loss_cls: 0.1114  decode.d8.loss_mask: 0.5093  decode.d8.loss_dice: 1.1855
11/15 13:37:01 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 13:37:01 - mmengine - INFO - Iter(train) [39000/90000]  base_lr: 5.9979e-05 lr: 5.9979e-06  eta: 8:33:54  time: 0.5989  data_time: 0.0101  memory: 10692  grad_norm: 439.7369  loss: 19.3763  decode.loss_cls: 0.0597  decode.loss_mask: 0.5443  decode.loss_dice: 1.3149  decode.d0.loss_cls: 0.0804  decode.d0.loss_mask: 0.5761  decode.d0.loss_dice: 1.3890  decode.d1.loss_cls: 0.0759  decode.d1.loss_mask: 0.5650  decode.d1.loss_dice: 1.3285  decode.d2.loss_cls: 0.0656  decode.d2.loss_mask: 0.5587  decode.d2.loss_dice: 1.3055  decode.d3.loss_cls: 0.0646  decode.d3.loss_mask: 0.5612  decode.d3.loss_dice: 1.2964  decode.d4.loss_cls: 0.0669  decode.d4.loss_mask: 0.5533  decode.d4.loss_dice: 1.3124  decode.d5.loss_cls: 0.0731  decode.d5.loss_mask: 0.5433  decode.d5.loss_dice: 1.2995  decode.d6.loss_cls: 0.0770  decode.d6.loss_mask: 0.5399  decode.d6.loss_dice: 1.3007  decode.d7.loss_cls: 0.0779  decode.d7.loss_mask: 0.5278  decode.d7.loss_dice: 1.2975  decode.d8.loss_cls: 0.0668  decode.d8.loss_mask: 0.5481  decode.d8.loss_dice: 1.3061
11/15 13:37:31 - mmengine - INFO - Iter(train) [39050/90000]  base_lr: 5.9926e-05 lr: 5.9926e-06  eta: 8:33:24  time: 0.6075  data_time: 0.0103  memory: 10675  grad_norm: 323.8375  loss: 18.3695  decode.loss_cls: 0.0675  decode.loss_mask: 0.5547  decode.loss_dice: 1.1985  decode.d0.loss_cls: 0.0686  decode.d0.loss_mask: 0.6050  decode.d0.loss_dice: 1.2876  decode.d1.loss_cls: 0.0826  decode.d1.loss_mask: 0.5724  decode.d1.loss_dice: 1.1886  decode.d2.loss_cls: 0.0807  decode.d2.loss_mask: 0.5635  decode.d2.loss_dice: 1.1834  decode.d3.loss_cls: 0.0730  decode.d3.loss_mask: 0.5617  decode.d3.loss_dice: 1.1633  decode.d4.loss_cls: 0.0660  decode.d4.loss_mask: 0.5614  decode.d4.loss_dice: 1.1889  decode.d5.loss_cls: 0.0642  decode.d5.loss_mask: 0.5611  decode.d5.loss_dice: 1.1825  decode.d6.loss_cls: 0.0735  decode.d6.loss_mask: 0.5574  decode.d6.loss_dice: 1.1837  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.5623  decode.d7.loss_dice: 1.2326  decode.d8.loss_cls: 0.0633  decode.d8.loss_mask: 0.5521  decode.d8.loss_dice: 1.2061
11/15 13:38:01 - mmengine - INFO - Iter(train) [39100/90000]  base_lr: 5.9873e-05 lr: 5.9873e-06  eta: 8:32:53  time: 0.5973  data_time: 0.0102  memory: 10728  grad_norm: 294.8865  loss: 17.0893  decode.loss_cls: 0.0530  decode.loss_mask: 0.5009  decode.loss_dice: 1.1504  decode.d0.loss_cls: 0.0926  decode.d0.loss_mask: 0.5003  decode.d0.loss_dice: 1.2368  decode.d1.loss_cls: 0.0631  decode.d1.loss_mask: 0.4933  decode.d1.loss_dice: 1.1708  decode.d2.loss_cls: 0.0610  decode.d2.loss_mask: 0.4895  decode.d2.loss_dice: 1.1342  decode.d3.loss_cls: 0.0621  decode.d3.loss_mask: 0.4846  decode.d3.loss_dice: 1.1203  decode.d4.loss_cls: 0.0539  decode.d4.loss_mask: 0.4938  decode.d4.loss_dice: 1.1394  decode.d5.loss_cls: 0.0651  decode.d5.loss_mask: 0.4775  decode.d5.loss_dice: 1.1508  decode.d6.loss_cls: 0.0695  decode.d6.loss_mask: 0.5003  decode.d6.loss_dice: 1.1187  decode.d7.loss_cls: 0.0798  decode.d7.loss_mask: 0.4931  decode.d7.loss_dice: 1.1046  decode.d8.loss_cls: 0.0653  decode.d8.loss_mask: 0.4970  decode.d8.loss_dice: 1.1677
11/15 13:38:31 - mmengine - INFO - Iter(train) [39150/90000]  base_lr: 5.9820e-05 lr: 5.9820e-06  eta: 8:32:23  time: 0.5967  data_time: 0.0103  memory: 10692  grad_norm: 600.4874  loss: 18.2218  decode.loss_cls: 0.0443  decode.loss_mask: 0.5854  decode.loss_dice: 1.1748  decode.d0.loss_cls: 0.0804  decode.d0.loss_mask: 0.5903  decode.d0.loss_dice: 1.2322  decode.d1.loss_cls: 0.0577  decode.d1.loss_mask: 0.5874  decode.d1.loss_dice: 1.1951  decode.d2.loss_cls: 0.0507  decode.d2.loss_mask: 0.5817  decode.d2.loss_dice: 1.1719  decode.d3.loss_cls: 0.0518  decode.d3.loss_mask: 0.5812  decode.d3.loss_dice: 1.1843  decode.d4.loss_cls: 0.0624  decode.d4.loss_mask: 0.5943  decode.d4.loss_dice: 1.1614  decode.d5.loss_cls: 0.0592  decode.d5.loss_mask: 0.5892  decode.d5.loss_dice: 1.1558  decode.d6.loss_cls: 0.0532  decode.d6.loss_mask: 0.6063  decode.d6.loss_dice: 1.1408  decode.d7.loss_cls: 0.0459  decode.d7.loss_mask: 0.5989  decode.d7.loss_dice: 1.1790  decode.d8.loss_cls: 0.0468  decode.d8.loss_mask: 0.5931  decode.d8.loss_dice: 1.1661
11/15 13:39:01 - mmengine - INFO - Iter(train) [39200/90000]  base_lr: 5.9767e-05 lr: 5.9767e-06  eta: 8:31:52  time: 0.5972  data_time: 0.0102  memory: 10692  grad_norm: 863.2091  loss: 16.2165  decode.loss_cls: 0.0504  decode.loss_mask: 0.4755  decode.loss_dice: 1.0671  decode.d0.loss_cls: 0.0832  decode.d0.loss_mask: 0.4931  decode.d0.loss_dice: 1.1382  decode.d1.loss_cls: 0.0577  decode.d1.loss_mask: 0.4843  decode.d1.loss_dice: 1.0746  decode.d2.loss_cls: 0.0639  decode.d2.loss_mask: 0.4770  decode.d2.loss_dice: 1.0939  decode.d3.loss_cls: 0.0596  decode.d3.loss_mask: 0.4774  decode.d3.loss_dice: 1.0916  decode.d4.loss_cls: 0.0640  decode.d4.loss_mask: 0.4729  decode.d4.loss_dice: 1.0654  decode.d5.loss_cls: 0.0525  decode.d5.loss_mask: 0.4771  decode.d5.loss_dice: 1.0872  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.4759  decode.d6.loss_dice: 1.0656  decode.d7.loss_cls: 0.0576  decode.d7.loss_mask: 0.4684  decode.d7.loss_dice: 1.0647  decode.d8.loss_cls: 0.0506  decode.d8.loss_mask: 0.4749  decode.d8.loss_dice: 1.0932
11/15 13:39:31 - mmengine - INFO - Iter(train) [39250/90000]  base_lr: 5.9714e-05 lr: 5.9714e-06  eta: 8:31:21  time: 0.5989  data_time: 0.0105  memory: 10713  grad_norm: 267.6007  loss: 19.3289  decode.loss_cls: 0.0896  decode.loss_mask: 0.5665  decode.loss_dice: 1.2698  decode.d0.loss_cls: 0.1113  decode.d0.loss_mask: 0.6025  decode.d0.loss_dice: 1.3468  decode.d1.loss_cls: 0.1015  decode.d1.loss_mask: 0.5778  decode.d1.loss_dice: 1.2967  decode.d2.loss_cls: 0.0876  decode.d2.loss_mask: 0.5613  decode.d2.loss_dice: 1.2781  decode.d3.loss_cls: 0.1113  decode.d3.loss_mask: 0.5548  decode.d3.loss_dice: 1.2471  decode.d4.loss_cls: 0.0949  decode.d4.loss_mask: 0.5569  decode.d4.loss_dice: 1.2558  decode.d5.loss_cls: 0.0936  decode.d5.loss_mask: 0.5630  decode.d5.loss_dice: 1.2761  decode.d6.loss_cls: 0.1005  decode.d6.loss_mask: 0.5616  decode.d6.loss_dice: 1.2342  decode.d7.loss_cls: 0.0884  decode.d7.loss_mask: 0.5588  decode.d7.loss_dice: 1.2432  decode.d8.loss_cls: 0.0850  decode.d8.loss_mask: 0.5630  decode.d8.loss_dice: 1.2510
11/15 13:40:01 - mmengine - INFO - Iter(train) [39300/90000]  base_lr: 5.9661e-05 lr: 5.9661e-06  eta: 8:30:51  time: 0.5983  data_time: 0.0103  memory: 10713  grad_norm: 262.1507  loss: 15.0537  decode.loss_cls: 0.0555  decode.loss_mask: 0.3820  decode.loss_dice: 1.0724  decode.d0.loss_cls: 0.0854  decode.d0.loss_mask: 0.3841  decode.d0.loss_dice: 1.1001  decode.d1.loss_cls: 0.0859  decode.d1.loss_mask: 0.3947  decode.d1.loss_dice: 1.0577  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.3872  decode.d2.loss_dice: 1.0631  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.3800  decode.d3.loss_dice: 1.0496  decode.d4.loss_cls: 0.0571  decode.d4.loss_mask: 0.3781  decode.d4.loss_dice: 1.0349  decode.d5.loss_cls: 0.0510  decode.d5.loss_mask: 0.3812  decode.d5.loss_dice: 1.0606  decode.d6.loss_cls: 0.0526  decode.d6.loss_mask: 0.3854  decode.d6.loss_dice: 1.0334  decode.d7.loss_cls: 0.0537  decode.d7.loss_mask: 0.3801  decode.d7.loss_dice: 1.0738  decode.d8.loss_cls: 0.0583  decode.d8.loss_mask: 0.3856  decode.d8.loss_dice: 1.0590
11/15 13:40:31 - mmengine - INFO - Iter(train) [39350/90000]  base_lr: 5.9608e-05 lr: 5.9608e-06  eta: 8:30:20  time: 0.5980  data_time: 0.0103  memory: 10728  grad_norm: 1010.2305  loss: 19.2818  decode.loss_cls: 0.0729  decode.loss_mask: 0.5525  decode.loss_dice: 1.2972  decode.d0.loss_cls: 0.0987  decode.d0.loss_mask: 0.5872  decode.d0.loss_dice: 1.3096  decode.d1.loss_cls: 0.0987  decode.d1.loss_mask: 0.5486  decode.d1.loss_dice: 1.3075  decode.d2.loss_cls: 0.0997  decode.d2.loss_mask: 0.5549  decode.d2.loss_dice: 1.2904  decode.d3.loss_cls: 0.0872  decode.d3.loss_mask: 0.5421  decode.d3.loss_dice: 1.3015  decode.d4.loss_cls: 0.0841  decode.d4.loss_mask: 0.5413  decode.d4.loss_dice: 1.2950  decode.d5.loss_cls: 0.0772  decode.d5.loss_mask: 0.5433  decode.d5.loss_dice: 1.2792  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.5453  decode.d6.loss_dice: 1.2757  decode.d7.loss_cls: 0.0739  decode.d7.loss_mask: 0.5441  decode.d7.loss_dice: 1.2803  decode.d8.loss_cls: 0.0824  decode.d8.loss_mask: 0.5476  decode.d8.loss_dice: 1.2936
11/15 13:41:01 - mmengine - INFO - Iter(train) [39400/90000]  base_lr: 5.9555e-05 lr: 5.9555e-06  eta: 8:29:49  time: 0.5981  data_time: 0.0102  memory: 10728  grad_norm: 291.0537  loss: 16.7892  decode.loss_cls: 0.0755  decode.loss_mask: 0.4599  decode.loss_dice: 1.1032  decode.d0.loss_cls: 0.0833  decode.d0.loss_mask: 0.4766  decode.d0.loss_dice: 1.2160  decode.d1.loss_cls: 0.0697  decode.d1.loss_mask: 0.4807  decode.d1.loss_dice: 1.1776  decode.d2.loss_cls: 0.0793  decode.d2.loss_mask: 0.4631  decode.d2.loss_dice: 1.1784  decode.d3.loss_cls: 0.0872  decode.d3.loss_mask: 0.4467  decode.d3.loss_dice: 1.1198  decode.d4.loss_cls: 0.0820  decode.d4.loss_mask: 0.4609  decode.d4.loss_dice: 1.1092  decode.d5.loss_cls: 0.0733  decode.d5.loss_mask: 0.4528  decode.d5.loss_dice: 1.1270  decode.d6.loss_cls: 0.0764  decode.d6.loss_mask: 0.4586  decode.d6.loss_dice: 1.0978  decode.d7.loss_cls: 0.0803  decode.d7.loss_mask: 0.4581  decode.d7.loss_dice: 1.1247  decode.d8.loss_cls: 0.0794  decode.d8.loss_mask: 0.4655  decode.d8.loss_dice: 1.1265
11/15 13:41:30 - mmengine - INFO - Iter(train) [39450/90000]  base_lr: 5.9502e-05 lr: 5.9502e-06  eta: 8:29:19  time: 0.5974  data_time: 0.0103  memory: 10641  grad_norm: 391.1008  loss: 17.3046  decode.loss_cls: 0.0692  decode.loss_mask: 0.5456  decode.loss_dice: 1.0995  decode.d0.loss_cls: 0.0927  decode.d0.loss_mask: 0.5878  decode.d0.loss_dice: 1.1402  decode.d1.loss_cls: 0.0910  decode.d1.loss_mask: 0.5420  decode.d1.loss_dice: 1.0803  decode.d2.loss_cls: 0.0770  decode.d2.loss_mask: 0.5714  decode.d2.loss_dice: 1.0533  decode.d3.loss_cls: 0.0770  decode.d3.loss_mask: 0.5776  decode.d3.loss_dice: 1.0780  decode.d4.loss_cls: 0.0723  decode.d4.loss_mask: 0.5743  decode.d4.loss_dice: 1.0761  decode.d5.loss_cls: 0.0658  decode.d5.loss_mask: 0.5760  decode.d5.loss_dice: 1.1083  decode.d6.loss_cls: 0.0662  decode.d6.loss_mask: 0.5720  decode.d6.loss_dice: 1.0924  decode.d7.loss_cls: 0.0669  decode.d7.loss_mask: 0.5714  decode.d7.loss_dice: 1.0914  decode.d8.loss_cls: 0.0825  decode.d8.loss_mask: 0.5351  decode.d8.loss_dice: 1.0714
11/15 13:42:00 - mmengine - INFO - Iter(train) [39500/90000]  base_lr: 5.9450e-05 lr: 5.9450e-06  eta: 8:28:48  time: 0.5970  data_time: 0.0103  memory: 10713  grad_norm: 291.3594  loss: 18.4379  decode.loss_cls: 0.0533  decode.loss_mask: 0.5287  decode.loss_dice: 1.2212  decode.d0.loss_cls: 0.0693  decode.d0.loss_mask: 0.5539  decode.d0.loss_dice: 1.3172  decode.d1.loss_cls: 0.0832  decode.d1.loss_mask: 0.5257  decode.d1.loss_dice: 1.2236  decode.d2.loss_cls: 0.0831  decode.d2.loss_mask: 0.5247  decode.d2.loss_dice: 1.2223  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.5391  decode.d3.loss_dice: 1.2107  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.5304  decode.d4.loss_dice: 1.2210  decode.d5.loss_cls: 0.0667  decode.d5.loss_mask: 0.5392  decode.d5.loss_dice: 1.2465  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.5355  decode.d6.loss_dice: 1.2475  decode.d7.loss_cls: 0.0670  decode.d7.loss_mask: 0.5516  decode.d7.loss_dice: 1.2384  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.5479  decode.d8.loss_dice: 1.2286
11/15 13:42:30 - mmengine - INFO - Iter(train) [39550/90000]  base_lr: 5.9397e-05 lr: 5.9397e-06  eta: 8:28:17  time: 0.5979  data_time: 0.0103  memory: 10656  grad_norm: 409.1593  loss: 15.7526  decode.loss_cls: 0.0550  decode.loss_mask: 0.4814  decode.loss_dice: 1.0276  decode.d0.loss_cls: 0.0871  decode.d0.loss_mask: 0.4999  decode.d0.loss_dice: 1.0805  decode.d1.loss_cls: 0.0479  decode.d1.loss_mask: 0.4962  decode.d1.loss_dice: 1.0493  decode.d2.loss_cls: 0.0554  decode.d2.loss_mask: 0.4809  decode.d2.loss_dice: 1.0040  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.4808  decode.d3.loss_dice: 1.0276  decode.d4.loss_cls: 0.0525  decode.d4.loss_mask: 0.4845  decode.d4.loss_dice: 1.0471  decode.d5.loss_cls: 0.0609  decode.d5.loss_mask: 0.4810  decode.d5.loss_dice: 1.0405  decode.d6.loss_cls: 0.0537  decode.d6.loss_mask: 0.4820  decode.d6.loss_dice: 1.0237  decode.d7.loss_cls: 0.0482  decode.d7.loss_mask: 0.4831  decode.d7.loss_dice: 1.0264  decode.d8.loss_cls: 0.0599  decode.d8.loss_mask: 0.4694  decode.d8.loss_dice: 1.0098
11/15 13:43:01 - mmengine - INFO - Iter(train) [39600/90000]  base_lr: 5.9344e-05 lr: 5.9344e-06  eta: 8:27:48  time: 0.5973  data_time: 0.0103  memory: 10692  grad_norm: 232.0925  loss: 15.1679  decode.loss_cls: 0.0677  decode.loss_mask: 0.4563  decode.loss_dice: 0.9810  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 0.4733  decode.d0.loss_dice: 1.0698  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.4602  decode.d1.loss_dice: 0.9995  decode.d2.loss_cls: 0.0613  decode.d2.loss_mask: 0.4570  decode.d2.loss_dice: 0.9990  decode.d3.loss_cls: 0.0696  decode.d3.loss_mask: 0.4585  decode.d3.loss_dice: 0.9933  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 0.4592  decode.d4.loss_dice: 0.9977  decode.d5.loss_cls: 0.0581  decode.d5.loss_mask: 0.4575  decode.d5.loss_dice: 0.9871  decode.d6.loss_cls: 0.0644  decode.d6.loss_mask: 0.4579  decode.d6.loss_dice: 0.9384  decode.d7.loss_cls: 0.0759  decode.d7.loss_mask: 0.4607  decode.d7.loss_dice: 0.9843  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.4546  decode.d8.loss_dice: 0.9680
11/15 13:43:31 - mmengine - INFO - Iter(train) [39650/90000]  base_lr: 5.9291e-05 lr: 5.9291e-06  eta: 8:27:17  time: 0.5990  data_time: 0.0108  memory: 10728  grad_norm: 380.4419  loss: 20.2185  decode.loss_cls: 0.0863  decode.loss_mask: 0.6492  decode.loss_dice: 1.2689  decode.d0.loss_cls: 0.1067  decode.d0.loss_mask: 0.6919  decode.d0.loss_dice: 1.3567  decode.d1.loss_cls: 0.0756  decode.d1.loss_mask: 0.6584  decode.d1.loss_dice: 1.2870  decode.d2.loss_cls: 0.0876  decode.d2.loss_mask: 0.6484  decode.d2.loss_dice: 1.2476  decode.d3.loss_cls: 0.0811  decode.d3.loss_mask: 0.6633  decode.d3.loss_dice: 1.2524  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 0.6721  decode.d4.loss_dice: 1.2712  decode.d5.loss_cls: 0.0805  decode.d5.loss_mask: 0.6610  decode.d5.loss_dice: 1.2745  decode.d6.loss_cls: 0.0812  decode.d6.loss_mask: 0.6621  decode.d6.loss_dice: 1.2592  decode.d7.loss_cls: 0.0839  decode.d7.loss_mask: 0.6571  decode.d7.loss_dice: 1.2712  decode.d8.loss_cls: 0.0785  decode.d8.loss_mask: 0.6491  decode.d8.loss_dice: 1.2761
11/15 13:44:01 - mmengine - INFO - Iter(train) [39700/90000]  base_lr: 5.9238e-05 lr: 5.9238e-06  eta: 8:26:47  time: 0.5991  data_time: 0.0106  memory: 10713  grad_norm: 477.4981  loss: 18.5582  decode.loss_cls: 0.0468  decode.loss_mask: 0.5219  decode.loss_dice: 1.2832  decode.d0.loss_cls: 0.0854  decode.d0.loss_mask: 0.5098  decode.d0.loss_dice: 1.3475  decode.d1.loss_cls: 0.0691  decode.d1.loss_mask: 0.5131  decode.d1.loss_dice: 1.3058  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.5167  decode.d2.loss_dice: 1.2777  decode.d3.loss_cls: 0.0437  decode.d3.loss_mask: 0.5099  decode.d3.loss_dice: 1.2798  decode.d4.loss_cls: 0.0464  decode.d4.loss_mask: 0.5269  decode.d4.loss_dice: 1.2840  decode.d5.loss_cls: 0.0559  decode.d5.loss_mask: 0.5054  decode.d5.loss_dice: 1.2697  decode.d6.loss_cls: 0.0518  decode.d6.loss_mask: 0.5099  decode.d6.loss_dice: 1.2742  decode.d7.loss_cls: 0.0534  decode.d7.loss_mask: 0.5074  decode.d7.loss_dice: 1.2900  decode.d8.loss_cls: 0.0482  decode.d8.loss_mask: 0.5065  decode.d8.loss_dice: 1.2732
11/15 13:44:31 - mmengine - INFO - Iter(train) [39750/90000]  base_lr: 5.9185e-05 lr: 5.9185e-06  eta: 8:26:16  time: 0.5977  data_time: 0.0103  memory: 10675  grad_norm: 340.7406  loss: 16.4267  decode.loss_cls: 0.0717  decode.loss_mask: 0.5233  decode.loss_dice: 1.0385  decode.d0.loss_cls: 0.0831  decode.d0.loss_mask: 0.5369  decode.d0.loss_dice: 1.1571  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.5261  decode.d1.loss_dice: 1.0674  decode.d2.loss_cls: 0.0668  decode.d2.loss_mask: 0.5213  decode.d2.loss_dice: 1.0445  decode.d3.loss_cls: 0.0765  decode.d3.loss_mask: 0.5197  decode.d3.loss_dice: 1.0088  decode.d4.loss_cls: 0.0677  decode.d4.loss_mask: 0.5154  decode.d4.loss_dice: 1.0403  decode.d5.loss_cls: 0.0660  decode.d5.loss_mask: 0.5226  decode.d5.loss_dice: 1.0025  decode.d6.loss_cls: 0.0704  decode.d6.loss_mask: 0.5253  decode.d6.loss_dice: 1.0348  decode.d7.loss_cls: 0.0724  decode.d7.loss_mask: 0.5284  decode.d7.loss_dice: 1.0575  decode.d8.loss_cls: 0.0762  decode.d8.loss_mask: 0.5213  decode.d8.loss_dice: 1.0178
11/15 13:45:01 - mmengine - INFO - Iter(train) [39800/90000]  base_lr: 5.9132e-05 lr: 5.9132e-06  eta: 8:25:45  time: 0.5985  data_time: 0.0105  memory: 10656  grad_norm: 459.6474  loss: 17.1341  decode.loss_cls: 0.0958  decode.loss_mask: 0.4330  decode.loss_dice: 1.1805  decode.d0.loss_cls: 0.0929  decode.d0.loss_mask: 0.4661  decode.d0.loss_dice: 1.2387  decode.d1.loss_cls: 0.0990  decode.d1.loss_mask: 0.4535  decode.d1.loss_dice: 1.1859  decode.d2.loss_cls: 0.1175  decode.d2.loss_mask: 0.4318  decode.d2.loss_dice: 1.1385  decode.d3.loss_cls: 0.1135  decode.d3.loss_mask: 0.4295  decode.d3.loss_dice: 1.1319  decode.d4.loss_cls: 0.1039  decode.d4.loss_mask: 0.4511  decode.d4.loss_dice: 1.1643  decode.d5.loss_cls: 0.1159  decode.d5.loss_mask: 0.4470  decode.d5.loss_dice: 1.1562  decode.d6.loss_cls: 0.1042  decode.d6.loss_mask: 0.4464  decode.d6.loss_dice: 1.1440  decode.d7.loss_cls: 0.0987  decode.d7.loss_mask: 0.4432  decode.d7.loss_dice: 1.1606  decode.d8.loss_cls: 0.1065  decode.d8.loss_mask: 0.4439  decode.d8.loss_dice: 1.1402
11/15 13:45:31 - mmengine - INFO - Iter(train) [39850/90000]  base_lr: 5.9079e-05 lr: 5.9079e-06  eta: 8:25:15  time: 0.5981  data_time: 0.0104  memory: 10675  grad_norm: 333.3812  loss: 18.5268  decode.loss_cls: 0.0884  decode.loss_mask: 0.5550  decode.loss_dice: 1.1716  decode.d0.loss_cls: 0.0984  decode.d0.loss_mask: 0.5796  decode.d0.loss_dice: 1.2615  decode.d1.loss_cls: 0.1058  decode.d1.loss_mask: 0.5622  decode.d1.loss_dice: 1.1707  decode.d2.loss_cls: 0.1111  decode.d2.loss_mask: 0.5680  decode.d2.loss_dice: 1.1762  decode.d3.loss_cls: 0.1055  decode.d3.loss_mask: 0.5617  decode.d3.loss_dice: 1.1663  decode.d4.loss_cls: 0.0954  decode.d4.loss_mask: 0.5834  decode.d4.loss_dice: 1.2018  decode.d5.loss_cls: 0.0855  decode.d5.loss_mask: 0.5688  decode.d5.loss_dice: 1.1768  decode.d6.loss_cls: 0.0742  decode.d6.loss_mask: 0.5665  decode.d6.loss_dice: 1.1759  decode.d7.loss_cls: 0.0808  decode.d7.loss_mask: 0.5865  decode.d7.loss_dice: 1.1984  decode.d8.loss_cls: 0.0985  decode.d8.loss_mask: 0.5634  decode.d8.loss_dice: 1.1890
11/15 13:46:01 - mmengine - INFO - Iter(train) [39900/90000]  base_lr: 5.9026e-05 lr: 5.9026e-06  eta: 8:24:44  time: 0.5990  data_time: 0.0104  memory: 10728  grad_norm: 409.0803  loss: 19.3663  decode.loss_cls: 0.1117  decode.loss_mask: 0.5179  decode.loss_dice: 1.2434  decode.d0.loss_cls: 0.1207  decode.d0.loss_mask: 0.5369  decode.d0.loss_dice: 1.3802  decode.d1.loss_cls: 0.0962  decode.d1.loss_mask: 0.5321  decode.d1.loss_dice: 1.3469  decode.d2.loss_cls: 0.1084  decode.d2.loss_mask: 0.5358  decode.d2.loss_dice: 1.2685  decode.d3.loss_cls: 0.1046  decode.d3.loss_mask: 0.5375  decode.d3.loss_dice: 1.3059  decode.d4.loss_cls: 0.1060  decode.d4.loss_mask: 0.5400  decode.d4.loss_dice: 1.2871  decode.d5.loss_cls: 0.1079  decode.d5.loss_mask: 0.5251  decode.d5.loss_dice: 1.3054  decode.d6.loss_cls: 0.1058  decode.d6.loss_mask: 0.5314  decode.d6.loss_dice: 1.2779  decode.d7.loss_cls: 0.0981  decode.d7.loss_mask: 0.5299  decode.d7.loss_dice: 1.2798  decode.d8.loss_cls: 0.1039  decode.d8.loss_mask: 0.5346  decode.d8.loss_dice: 1.2869
11/15 13:46:30 - mmengine - INFO - Iter(train) [39950/90000]  base_lr: 5.8973e-05 lr: 5.8973e-06  eta: 8:24:13  time: 0.5977  data_time: 0.0104  memory: 10675  grad_norm: 217.4802  loss: 18.5662  decode.loss_cls: 0.0735  decode.loss_mask: 0.5613  decode.loss_dice: 1.2238  decode.d0.loss_cls: 0.0982  decode.d0.loss_mask: 0.5762  decode.d0.loss_dice: 1.2710  decode.d1.loss_cls: 0.0863  decode.d1.loss_mask: 0.5554  decode.d1.loss_dice: 1.2204  decode.d2.loss_cls: 0.0716  decode.d2.loss_mask: 0.5532  decode.d2.loss_dice: 1.2458  decode.d3.loss_cls: 0.0770  decode.d3.loss_mask: 0.5454  decode.d3.loss_dice: 1.2290  decode.d4.loss_cls: 0.0853  decode.d4.loss_mask: 0.5429  decode.d4.loss_dice: 1.2096  decode.d5.loss_cls: 0.0899  decode.d5.loss_mask: 0.5387  decode.d5.loss_dice: 1.2130  decode.d6.loss_cls: 0.0807  decode.d6.loss_mask: 0.5399  decode.d6.loss_dice: 1.2028  decode.d7.loss_cls: 0.0866  decode.d7.loss_mask: 0.5484  decode.d7.loss_dice: 1.2212  decode.d8.loss_cls: 0.0840  decode.d8.loss_mask: 0.5471  decode.d8.loss_dice: 1.1879
11/15 13:47:00 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 13:47:00 - mmengine - INFO - Iter(train) [40000/90000]  base_lr: 5.8920e-05 lr: 5.8920e-06  eta: 8:23:43  time: 0.5958  data_time: 0.0103  memory: 10713  grad_norm: 610.5261  loss: 17.8169  decode.loss_cls: 0.0394  decode.loss_mask: 0.5625  decode.loss_dice: 1.1537  decode.d0.loss_cls: 0.0757  decode.d0.loss_mask: 0.6140  decode.d0.loss_dice: 1.2080  decode.d1.loss_cls: 0.0493  decode.d1.loss_mask: 0.5657  decode.d1.loss_dice: 1.1819  decode.d2.loss_cls: 0.0438  decode.d2.loss_mask: 0.5673  decode.d2.loss_dice: 1.1859  decode.d3.loss_cls: 0.0498  decode.d3.loss_mask: 0.5751  decode.d3.loss_dice: 1.1487  decode.d4.loss_cls: 0.0440  decode.d4.loss_mask: 0.5595  decode.d4.loss_dice: 1.1698  decode.d5.loss_cls: 0.0482  decode.d5.loss_mask: 0.5665  decode.d5.loss_dice: 1.1335  decode.d6.loss_cls: 0.0468  decode.d6.loss_mask: 0.5747  decode.d6.loss_dice: 1.1296  decode.d7.loss_cls: 0.0416  decode.d7.loss_mask: 0.5621  decode.d7.loss_dice: 1.1423  decode.d8.loss_cls: 0.0432  decode.d8.loss_mask: 0.5648  decode.d8.loss_dice: 1.1692
11/15 13:47:00 - mmengine - INFO - Saving checkpoint at 40000 iterations
11/15 13:47:19 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:21  time: 0.3095  data_time: 0.0044  memory: 4095  
11/15 13:47:35 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:04  time: 0.3090  data_time: 0.0041  memory: 4095  
11/15 13:47:50 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:48  time: 0.3092  data_time: 0.0042  memory: 4095  
11/15 13:48:06 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3096  data_time: 0.0044  memory: 4095  
11/15 13:48:21 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3095  data_time: 0.0044  memory: 4095  
11/15 13:48:37 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:02  time: 0.3093  data_time: 0.0041  memory: 4095  
11/15 13:48:52 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3094  data_time: 0.0042  memory: 4095  
11/15 13:49:08 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:31  time: 0.3096  data_time: 0.0043  memory: 4095  
11/15 13:49:23 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3097  data_time: 0.0043  memory: 4095  
11/15 13:49:39 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3092  data_time: 0.0039  memory: 4095  
11/15 13:49:39 - mmengine - INFO - per class results:
11/15 13:49:39 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 97.89 | 98.35 |
|    sidewalk   | 83.35 |  93.6 |
|    building   | 92.87 | 95.69 |
|      wall     | 55.55 | 78.78 |
|     fence     |  58.9 | 74.81 |
|      pole     | 65.86 |  80.2 |
| traffic light | 69.75 | 79.33 |
|  traffic sign | 80.67 |  86.6 |
|   vegetation  |  92.3 | 96.75 |
|    terrain    | 58.16 | 68.53 |
|      sky      | 94.88 | 96.65 |
|     person    | 81.77 | 92.07 |
|     rider     | 63.54 | 75.27 |
|      car      | 94.43 | 98.43 |
|     truck     | 79.95 | 90.29 |
|      bus      | 72.19 | 91.26 |
|     train     | 17.52 | 18.48 |
|   motorcycle  | 57.69 | 77.09 |
|    bicycle    | 75.67 |  82.0 |
+---------------+-------+-------+
11/15 13:49:39 - mmengine - INFO - Iter(val) [500/500]    aAcc: 95.8100  mIoU: 73.3100  mAcc: 82.8500  data_time: 0.0047  time: 0.3100
11/15 13:50:09 - mmengine - INFO - Iter(train) [40050/90000]  base_lr: 5.8866e-05 lr: 5.8866e-06  eta: 8:23:12  time: 0.5986  data_time: 0.0105  memory: 10656  grad_norm: 766.8017  loss: 17.7629  decode.loss_cls: 0.0618  decode.loss_mask: 0.5909  decode.loss_dice: 1.1308  decode.d0.loss_cls: 0.0832  decode.d0.loss_mask: 0.6110  decode.d0.loss_dice: 1.1814  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.5852  decode.d1.loss_dice: 1.1599  decode.d2.loss_cls: 0.0721  decode.d2.loss_mask: 0.5636  decode.d2.loss_dice: 1.0948  decode.d3.loss_cls: 0.0650  decode.d3.loss_mask: 0.5870  decode.d3.loss_dice: 1.1073  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.5825  decode.d4.loss_dice: 1.1012  decode.d5.loss_cls: 0.0730  decode.d5.loss_mask: 0.5817  decode.d5.loss_dice: 1.1113  decode.d6.loss_cls: 0.0638  decode.d6.loss_mask: 0.5752  decode.d6.loss_dice: 1.1062  decode.d7.loss_cls: 0.0671  decode.d7.loss_mask: 0.5751  decode.d7.loss_dice: 1.1086  decode.d8.loss_cls: 0.0718  decode.d8.loss_mask: 0.5795  decode.d8.loss_dice: 1.1331
11/15 13:50:39 - mmengine - INFO - Iter(train) [40100/90000]  base_lr: 5.8813e-05 lr: 5.8813e-06  eta: 8:22:42  time: 0.6052  data_time: 0.0107  memory: 10713  grad_norm: 389.2807  loss: 18.4863  decode.loss_cls: 0.0634  decode.loss_mask: 0.5533  decode.loss_dice: 1.2221  decode.d0.loss_cls: 0.0778  decode.d0.loss_mask: 0.5695  decode.d0.loss_dice: 1.2302  decode.d1.loss_cls: 0.0484  decode.d1.loss_mask: 0.5424  decode.d1.loss_dice: 1.2236  decode.d2.loss_cls: 0.0417  decode.d2.loss_mask: 0.5662  decode.d2.loss_dice: 1.2235  decode.d3.loss_cls: 0.0520  decode.d3.loss_mask: 0.5734  decode.d3.loss_dice: 1.2300  decode.d4.loss_cls: 0.0406  decode.d4.loss_mask: 0.5853  decode.d4.loss_dice: 1.2382  decode.d5.loss_cls: 0.0393  decode.d5.loss_mask: 0.5940  decode.d5.loss_dice: 1.2389  decode.d6.loss_cls: 0.0510  decode.d6.loss_mask: 0.5645  decode.d6.loss_dice: 1.2332  decode.d7.loss_cls: 0.0551  decode.d7.loss_mask: 0.5445  decode.d7.loss_dice: 1.2265  decode.d8.loss_cls: 0.0488  decode.d8.loss_mask: 0.5483  decode.d8.loss_dice: 1.2605
11/15 13:51:09 - mmengine - INFO - Iter(train) [40150/90000]  base_lr: 5.8760e-05 lr: 5.8760e-06  eta: 8:22:11  time: 0.5967  data_time: 0.0101  memory: 10656  grad_norm: 198.6584  loss: 15.4419  decode.loss_cls: 0.0533  decode.loss_mask: 0.4880  decode.loss_dice: 0.9590  decode.d0.loss_cls: 0.0760  decode.d0.loss_mask: 0.5198  decode.d0.loss_dice: 1.0501  decode.d1.loss_cls: 0.0730  decode.d1.loss_mask: 0.4961  decode.d1.loss_dice: 0.9944  decode.d2.loss_cls: 0.0644  decode.d2.loss_mask: 0.4945  decode.d2.loss_dice: 1.0145  decode.d3.loss_cls: 0.0646  decode.d3.loss_mask: 0.4905  decode.d3.loss_dice: 0.9766  decode.d4.loss_cls: 0.0551  decode.d4.loss_mask: 0.4954  decode.d4.loss_dice: 0.9816  decode.d5.loss_cls: 0.0580  decode.d5.loss_mask: 0.4884  decode.d5.loss_dice: 0.9744  decode.d6.loss_cls: 0.0604  decode.d6.loss_mask: 0.4828  decode.d6.loss_dice: 0.9640  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.4868  decode.d7.loss_dice: 0.9788  decode.d8.loss_cls: 0.0577  decode.d8.loss_mask: 0.4862  decode.d8.loss_dice: 0.9939
11/15 13:51:38 - mmengine - INFO - Iter(train) [40200/90000]  base_lr: 5.8707e-05 lr: 5.8707e-06  eta: 8:21:40  time: 0.5958  data_time: 0.0102  memory: 10713  grad_norm: 555.7870  loss: 19.3234  decode.loss_cls: 0.0593  decode.loss_mask: 0.6680  decode.loss_dice: 1.2050  decode.d0.loss_cls: 0.0827  decode.d0.loss_mask: 0.6823  decode.d0.loss_dice: 1.2685  decode.d1.loss_cls: 0.0604  decode.d1.loss_mask: 0.6734  decode.d1.loss_dice: 1.2150  decode.d2.loss_cls: 0.0646  decode.d2.loss_mask: 0.6645  decode.d2.loss_dice: 1.1869  decode.d3.loss_cls: 0.0687  decode.d3.loss_mask: 0.6637  decode.d3.loss_dice: 1.1647  decode.d4.loss_cls: 0.0697  decode.d4.loss_mask: 0.6590  decode.d4.loss_dice: 1.1638  decode.d5.loss_cls: 0.0706  decode.d5.loss_mask: 0.6669  decode.d5.loss_dice: 1.1464  decode.d6.loss_cls: 0.0578  decode.d6.loss_mask: 0.6629  decode.d6.loss_dice: 1.2279  decode.d7.loss_cls: 0.0625  decode.d7.loss_mask: 0.6706  decode.d7.loss_dice: 1.2075  decode.d8.loss_cls: 0.0671  decode.d8.loss_mask: 0.6622  decode.d8.loss_dice: 1.2010
11/15 13:52:08 - mmengine - INFO - Iter(train) [40250/90000]  base_lr: 5.8654e-05 lr: 5.8654e-06  eta: 8:21:10  time: 0.6009  data_time: 0.0103  memory: 10713  grad_norm: 220.2326  loss: 18.5248  decode.loss_cls: 0.0762  decode.loss_mask: 0.4952  decode.loss_dice: 1.2647  decode.d0.loss_cls: 0.0693  decode.d0.loss_mask: 0.5282  decode.d0.loss_dice: 1.3847  decode.d1.loss_cls: 0.0874  decode.d1.loss_mask: 0.4865  decode.d1.loss_dice: 1.2569  decode.d2.loss_cls: 0.0778  decode.d2.loss_mask: 0.4895  decode.d2.loss_dice: 1.2873  decode.d3.loss_cls: 0.0739  decode.d3.loss_mask: 0.5105  decode.d3.loss_dice: 1.2818  decode.d4.loss_cls: 0.0774  decode.d4.loss_mask: 0.4982  decode.d4.loss_dice: 1.2545  decode.d5.loss_cls: 0.0817  decode.d5.loss_mask: 0.4974  decode.d5.loss_dice: 1.2906  decode.d6.loss_cls: 0.0758  decode.d6.loss_mask: 0.4701  decode.d6.loss_dice: 1.2585  decode.d7.loss_cls: 0.0716  decode.d7.loss_mask: 0.4843  decode.d7.loss_dice: 1.2709  decode.d8.loss_cls: 0.0708  decode.d8.loss_mask: 0.4742  decode.d8.loss_dice: 1.2790
11/15 13:52:38 - mmengine - INFO - Iter(train) [40300/90000]  base_lr: 5.8601e-05 lr: 5.8601e-06  eta: 8:20:39  time: 0.5964  data_time: 0.0100  memory: 10641  grad_norm: 692.1899  loss: 18.8469  decode.loss_cls: 0.0676  decode.loss_mask: 0.6008  decode.loss_dice: 1.1759  decode.d0.loss_cls: 0.0973  decode.d0.loss_mask: 0.6897  decode.d0.loss_dice: 1.2168  decode.d1.loss_cls: 0.1169  decode.d1.loss_mask: 0.6004  decode.d1.loss_dice: 1.1774  decode.d2.loss_cls: 0.0846  decode.d2.loss_mask: 0.6140  decode.d2.loss_dice: 1.1928  decode.d3.loss_cls: 0.0776  decode.d3.loss_mask: 0.6150  decode.d3.loss_dice: 1.2015  decode.d4.loss_cls: 0.0860  decode.d4.loss_mask: 0.5993  decode.d4.loss_dice: 1.1840  decode.d5.loss_cls: 0.0733  decode.d5.loss_mask: 0.6045  decode.d5.loss_dice: 1.1816  decode.d6.loss_cls: 0.0863  decode.d6.loss_mask: 0.5955  decode.d6.loss_dice: 1.1442  decode.d7.loss_cls: 0.0674  decode.d7.loss_mask: 0.6024  decode.d7.loss_dice: 1.1830  decode.d8.loss_cls: 0.0732  decode.d8.loss_mask: 0.6274  decode.d8.loss_dice: 1.2104
11/15 13:53:08 - mmengine - INFO - Iter(train) [40350/90000]  base_lr: 5.8548e-05 lr: 5.8548e-06  eta: 8:20:08  time: 0.5967  data_time: 0.0103  memory: 10742  grad_norm: 342.1270  loss: 16.9401  decode.loss_cls: 0.0805  decode.loss_mask: 0.4306  decode.loss_dice: 1.1463  decode.d0.loss_cls: 0.1030  decode.d0.loss_mask: 0.4406  decode.d0.loss_dice: 1.2622  decode.d1.loss_cls: 0.1017  decode.d1.loss_mask: 0.4404  decode.d1.loss_dice: 1.1990  decode.d2.loss_cls: 0.1015  decode.d2.loss_mask: 0.4313  decode.d2.loss_dice: 1.1426  decode.d3.loss_cls: 0.0966  decode.d3.loss_mask: 0.4317  decode.d3.loss_dice: 1.1525  decode.d4.loss_cls: 0.0853  decode.d4.loss_mask: 0.4330  decode.d4.loss_dice: 1.1496  decode.d5.loss_cls: 0.0859  decode.d5.loss_mask: 0.4283  decode.d5.loss_dice: 1.1667  decode.d6.loss_cls: 0.0942  decode.d6.loss_mask: 0.4336  decode.d6.loss_dice: 1.1593  decode.d7.loss_cls: 0.0917  decode.d7.loss_mask: 0.4303  decode.d7.loss_dice: 1.1571  decode.d8.loss_cls: 0.0905  decode.d8.loss_mask: 0.4280  decode.d8.loss_dice: 1.1457
11/15 13:53:38 - mmengine - INFO - Iter(train) [40400/90000]  base_lr: 5.8495e-05 lr: 5.8495e-06  eta: 8:19:38  time: 0.5971  data_time: 0.0101  memory: 10713  grad_norm: 367.7662  loss: 16.7135  decode.loss_cls: 0.0546  decode.loss_mask: 0.5287  decode.loss_dice: 1.0819  decode.d0.loss_cls: 0.0694  decode.d0.loss_mask: 0.5562  decode.d0.loss_dice: 1.1609  decode.d1.loss_cls: 0.0646  decode.d1.loss_mask: 0.5258  decode.d1.loss_dice: 1.1053  decode.d2.loss_cls: 0.0499  decode.d2.loss_mask: 0.5238  decode.d2.loss_dice: 1.0865  decode.d3.loss_cls: 0.0568  decode.d3.loss_mask: 0.5255  decode.d3.loss_dice: 1.0892  decode.d4.loss_cls: 0.0581  decode.d4.loss_mask: 0.5245  decode.d4.loss_dice: 1.0455  decode.d5.loss_cls: 0.0623  decode.d5.loss_mask: 0.5204  decode.d5.loss_dice: 1.0313  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.5170  decode.d6.loss_dice: 1.0848  decode.d7.loss_cls: 0.0557  decode.d7.loss_mask: 0.5412  decode.d7.loss_dice: 1.0786  decode.d8.loss_cls: 0.0455  decode.d8.loss_mask: 0.5390  decode.d8.loss_dice: 1.0716
11/15 13:54:08 - mmengine - INFO - Iter(train) [40450/90000]  base_lr: 5.8442e-05 lr: 5.8442e-06  eta: 8:19:07  time: 0.5964  data_time: 0.0102  memory: 10713  grad_norm: 413.1437  loss: 16.2681  decode.loss_cls: 0.0576  decode.loss_mask: 0.4631  decode.loss_dice: 1.0769  decode.d0.loss_cls: 0.0812  decode.d0.loss_mask: 0.5019  decode.d0.loss_dice: 1.1432  decode.d1.loss_cls: 0.0710  decode.d1.loss_mask: 0.4731  decode.d1.loss_dice: 1.1037  decode.d2.loss_cls: 0.0591  decode.d2.loss_mask: 0.4707  decode.d2.loss_dice: 1.0915  decode.d3.loss_cls: 0.0597  decode.d3.loss_mask: 0.4688  decode.d3.loss_dice: 1.0811  decode.d4.loss_cls: 0.0622  decode.d4.loss_mask: 0.4655  decode.d4.loss_dice: 1.0770  decode.d5.loss_cls: 0.0650  decode.d5.loss_mask: 0.4667  decode.d5.loss_dice: 1.0783  decode.d6.loss_cls: 0.0618  decode.d6.loss_mask: 0.4681  decode.d6.loss_dice: 1.0807  decode.d7.loss_cls: 0.0555  decode.d7.loss_mask: 0.4768  decode.d7.loss_dice: 1.0990  decode.d8.loss_cls: 0.0600  decode.d8.loss_mask: 0.4655  decode.d8.loss_dice: 1.0838
11/15 13:54:38 - mmengine - INFO - Iter(train) [40500/90000]  base_lr: 5.8389e-05 lr: 5.8389e-06  eta: 8:18:37  time: 0.5969  data_time: 0.0099  memory: 10656  grad_norm: 353.1027  loss: 17.5618  decode.loss_cls: 0.0988  decode.loss_mask: 0.5986  decode.loss_dice: 1.0772  decode.d0.loss_cls: 0.1101  decode.d0.loss_mask: 0.5919  decode.d0.loss_dice: 1.1501  decode.d1.loss_cls: 0.1177  decode.d1.loss_mask: 0.5846  decode.d1.loss_dice: 1.0516  decode.d2.loss_cls: 0.1017  decode.d2.loss_mask: 0.5871  decode.d2.loss_dice: 1.0625  decode.d3.loss_cls: 0.1018  decode.d3.loss_mask: 0.5802  decode.d3.loss_dice: 1.0507  decode.d4.loss_cls: 0.1069  decode.d4.loss_mask: 0.5833  decode.d4.loss_dice: 1.0556  decode.d5.loss_cls: 0.0984  decode.d5.loss_mask: 0.5770  decode.d5.loss_dice: 1.0472  decode.d6.loss_cls: 0.0995  decode.d6.loss_mask: 0.5774  decode.d6.loss_dice: 1.0590  decode.d7.loss_cls: 0.1000  decode.d7.loss_mask: 0.5805  decode.d7.loss_dice: 1.0633  decode.d8.loss_cls: 0.0909  decode.d8.loss_mask: 0.5927  decode.d8.loss_dice: 1.0655
11/15 13:55:08 - mmengine - INFO - Iter(train) [40550/90000]  base_lr: 5.8336e-05 lr: 5.8336e-06  eta: 8:18:06  time: 0.5969  data_time: 0.0101  memory: 10656  grad_norm: 180.9907  loss: 16.1776  decode.loss_cls: 0.0483  decode.loss_mask: 0.4537  decode.loss_dice: 1.1366  decode.d0.loss_cls: 0.0604  decode.d0.loss_mask: 0.4735  decode.d0.loss_dice: 1.1909  decode.d1.loss_cls: 0.0514  decode.d1.loss_mask: 0.4544  decode.d1.loss_dice: 1.1024  decode.d2.loss_cls: 0.0585  decode.d2.loss_mask: 0.4546  decode.d2.loss_dice: 1.0858  decode.d3.loss_cls: 0.0530  decode.d3.loss_mask: 0.4514  decode.d3.loss_dice: 1.0808  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.4489  decode.d4.loss_dice: 1.0660  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 0.4437  decode.d5.loss_dice: 1.0832  decode.d6.loss_cls: 0.0534  decode.d6.loss_mask: 0.4490  decode.d6.loss_dice: 1.0865  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.4543  decode.d7.loss_dice: 1.1225  decode.d8.loss_cls: 0.0426  decode.d8.loss_mask: 0.4575  decode.d8.loss_dice: 1.1326
11/15 13:55:38 - mmengine - INFO - Iter(train) [40600/90000]  base_lr: 5.8283e-05 lr: 5.8283e-06  eta: 8:17:35  time: 0.6009  data_time: 0.0107  memory: 10713  grad_norm: 448.1821  loss: 17.8264  decode.loss_cls: 0.0537  decode.loss_mask: 0.6114  decode.loss_dice: 1.1421  decode.d0.loss_cls: 0.0861  decode.d0.loss_mask: 0.6050  decode.d0.loss_dice: 1.1365  decode.d1.loss_cls: 0.0669  decode.d1.loss_mask: 0.6035  decode.d1.loss_dice: 1.1471  decode.d2.loss_cls: 0.0561  decode.d2.loss_mask: 0.6112  decode.d2.loss_dice: 1.1171  decode.d3.loss_cls: 0.0524  decode.d3.loss_mask: 0.6039  decode.d3.loss_dice: 1.0783  decode.d4.loss_cls: 0.0546  decode.d4.loss_mask: 0.6059  decode.d4.loss_dice: 1.0837  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.5996  decode.d5.loss_dice: 1.0935  decode.d6.loss_cls: 0.0592  decode.d6.loss_mask: 0.6251  decode.d6.loss_dice: 1.1254  decode.d7.loss_cls: 0.0511  decode.d7.loss_mask: 0.5955  decode.d7.loss_dice: 1.1249  decode.d8.loss_cls: 0.0538  decode.d8.loss_mask: 0.6022  decode.d8.loss_dice: 1.1255
11/15 13:56:07 - mmengine - INFO - Iter(train) [40650/90000]  base_lr: 5.8230e-05 lr: 5.8230e-06  eta: 8:17:05  time: 0.5970  data_time: 0.0102  memory: 10692  grad_norm: 442.2962  loss: 17.5961  decode.loss_cls: 0.0632  decode.loss_mask: 0.4932  decode.loss_dice: 1.1853  decode.d0.loss_cls: 0.0907  decode.d0.loss_mask: 0.5297  decode.d0.loss_dice: 1.2633  decode.d1.loss_cls: 0.0870  decode.d1.loss_mask: 0.4999  decode.d1.loss_dice: 1.2008  decode.d2.loss_cls: 0.0887  decode.d2.loss_mask: 0.4825  decode.d2.loss_dice: 1.1766  decode.d3.loss_cls: 0.0772  decode.d3.loss_mask: 0.4768  decode.d3.loss_dice: 1.1711  decode.d4.loss_cls: 0.0769  decode.d4.loss_mask: 0.4757  decode.d4.loss_dice: 1.1823  decode.d5.loss_cls: 0.0819  decode.d5.loss_mask: 0.4722  decode.d5.loss_dice: 1.1678  decode.d6.loss_cls: 0.0735  decode.d6.loss_mask: 0.4713  decode.d6.loss_dice: 1.1737  decode.d7.loss_cls: 0.0894  decode.d7.loss_mask: 0.4846  decode.d7.loss_dice: 1.2124  decode.d8.loss_cls: 0.0708  decode.d8.loss_mask: 0.4871  decode.d8.loss_dice: 1.1905
11/15 13:56:37 - mmengine - INFO - Iter(train) [40700/90000]  base_lr: 5.8177e-05 lr: 5.8177e-06  eta: 8:16:34  time: 0.5997  data_time: 0.0105  memory: 10675  grad_norm: 323.6410  loss: 15.6385  decode.loss_cls: 0.0454  decode.loss_mask: 0.4819  decode.loss_dice: 1.0302  decode.d0.loss_cls: 0.0733  decode.d0.loss_mask: 0.5001  decode.d0.loss_dice: 1.0969  decode.d1.loss_cls: 0.0561  decode.d1.loss_mask: 0.4868  decode.d1.loss_dice: 1.0424  decode.d2.loss_cls: 0.0464  decode.d2.loss_mask: 0.4817  decode.d2.loss_dice: 1.0246  decode.d3.loss_cls: 0.0511  decode.d3.loss_mask: 0.4808  decode.d3.loss_dice: 1.0366  decode.d4.loss_cls: 0.0486  decode.d4.loss_mask: 0.4668  decode.d4.loss_dice: 1.0144  decode.d5.loss_cls: 0.0530  decode.d5.loss_mask: 0.4712  decode.d5.loss_dice: 1.0049  decode.d6.loss_cls: 0.0530  decode.d6.loss_mask: 0.4729  decode.d6.loss_dice: 1.0138  decode.d7.loss_cls: 0.0473  decode.d7.loss_mask: 0.4844  decode.d7.loss_dice: 1.0319  decode.d8.loss_cls: 0.0443  decode.d8.loss_mask: 0.4806  decode.d8.loss_dice: 1.0172
11/15 13:57:07 - mmengine - INFO - Iter(train) [40750/90000]  base_lr: 5.8123e-05 lr: 5.8123e-06  eta: 8:16:03  time: 0.5961  data_time: 0.0102  memory: 10692  grad_norm: 662.3542  loss: 17.8783  decode.loss_cls: 0.0974  decode.loss_mask: 0.6469  decode.loss_dice: 1.0428  decode.d0.loss_cls: 0.1031  decode.d0.loss_mask: 0.6335  decode.d0.loss_dice: 1.1404  decode.d1.loss_cls: 0.0903  decode.d1.loss_mask: 0.6365  decode.d1.loss_dice: 1.1029  decode.d2.loss_cls: 0.0851  decode.d2.loss_mask: 0.6220  decode.d2.loss_dice: 1.0719  decode.d3.loss_cls: 0.0775  decode.d3.loss_mask: 0.6154  decode.d3.loss_dice: 1.0680  decode.d4.loss_cls: 0.0816  decode.d4.loss_mask: 0.5976  decode.d4.loss_dice: 1.0681  decode.d5.loss_cls: 0.0867  decode.d5.loss_mask: 0.6068  decode.d5.loss_dice: 1.0586  decode.d6.loss_cls: 0.0857  decode.d6.loss_mask: 0.6151  decode.d6.loss_dice: 1.0497  decode.d7.loss_cls: 0.0869  decode.d7.loss_mask: 0.6159  decode.d7.loss_dice: 1.1090  decode.d8.loss_cls: 0.0743  decode.d8.loss_mask: 0.6234  decode.d8.loss_dice: 1.0849
11/15 13:57:37 - mmengine - INFO - Iter(train) [40800/90000]  base_lr: 5.8070e-05 lr: 5.8070e-06  eta: 8:15:33  time: 0.5981  data_time: 0.0100  memory: 10713  grad_norm: 1925.3562  loss: 18.8180  decode.loss_cls: 0.0717  decode.loss_mask: 0.4744  decode.loss_dice: 1.3224  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.4681  decode.d0.loss_dice: 1.4067  decode.d1.loss_cls: 0.0888  decode.d1.loss_mask: 0.4743  decode.d1.loss_dice: 1.3463  decode.d2.loss_cls: 0.0719  decode.d2.loss_mask: 0.4791  decode.d2.loss_dice: 1.3285  decode.d3.loss_cls: 0.0760  decode.d3.loss_mask: 0.4749  decode.d3.loss_dice: 1.3281  decode.d4.loss_cls: 0.0736  decode.d4.loss_mask: 0.4723  decode.d4.loss_dice: 1.3338  decode.d5.loss_cls: 0.0712  decode.d5.loss_mask: 0.4779  decode.d5.loss_dice: 1.3421  decode.d6.loss_cls: 0.0803  decode.d6.loss_mask: 0.4709  decode.d6.loss_dice: 1.3087  decode.d7.loss_cls: 0.0756  decode.d7.loss_mask: 0.4687  decode.d7.loss_dice: 1.3076  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.4717  decode.d8.loss_dice: 1.3201
11/15 13:58:07 - mmengine - INFO - Iter(train) [40850/90000]  base_lr: 5.8017e-05 lr: 5.8017e-06  eta: 8:15:02  time: 0.5969  data_time: 0.0102  memory: 10675  grad_norm: 592.7640  loss: 15.5695  decode.loss_cls: 0.0551  decode.loss_mask: 0.4877  decode.loss_dice: 1.0100  decode.d0.loss_cls: 0.0873  decode.d0.loss_mask: 0.5027  decode.d0.loss_dice: 1.0301  decode.d1.loss_cls: 0.0738  decode.d1.loss_mask: 0.4746  decode.d1.loss_dice: 1.0230  decode.d2.loss_cls: 0.0654  decode.d2.loss_mask: 0.4852  decode.d2.loss_dice: 1.0265  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.4819  decode.d3.loss_dice: 0.9906  decode.d4.loss_cls: 0.0633  decode.d4.loss_mask: 0.4824  decode.d4.loss_dice: 0.9969  decode.d5.loss_cls: 0.0609  decode.d5.loss_mask: 0.4871  decode.d5.loss_dice: 1.0152  decode.d6.loss_cls: 0.0619  decode.d6.loss_mask: 0.4710  decode.d6.loss_dice: 0.9845  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.4798  decode.d7.loss_dice: 1.0135  decode.d8.loss_cls: 0.0604  decode.d8.loss_mask: 0.4748  decode.d8.loss_dice: 1.0116
11/15 13:58:37 - mmengine - INFO - Iter(train) [40900/90000]  base_lr: 5.7964e-05 lr: 5.7964e-06  eta: 8:14:31  time: 0.5962  data_time: 0.0101  memory: 10675  grad_norm: 430.4400  loss: 14.9879  decode.loss_cls: 0.0532  decode.loss_mask: 0.4395  decode.loss_dice: 0.9704  decode.d0.loss_cls: 0.0722  decode.d0.loss_mask: 0.4694  decode.d0.loss_dice: 1.0423  decode.d1.loss_cls: 0.0566  decode.d1.loss_mask: 0.4486  decode.d1.loss_dice: 0.9959  decode.d2.loss_cls: 0.0602  decode.d2.loss_mask: 0.4479  decode.d2.loss_dice: 0.9827  decode.d3.loss_cls: 0.0586  decode.d3.loss_mask: 0.4559  decode.d3.loss_dice: 0.9794  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 0.4449  decode.d4.loss_dice: 0.9773  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.4449  decode.d5.loss_dice: 0.9832  decode.d6.loss_cls: 0.0497  decode.d6.loss_mask: 0.4676  decode.d6.loss_dice: 0.9790  decode.d7.loss_cls: 0.0561  decode.d7.loss_mask: 0.4639  decode.d7.loss_dice: 0.9889  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.4640  decode.d8.loss_dice: 0.9627
11/15 13:59:07 - mmengine - INFO - Iter(train) [40950/90000]  base_lr: 5.7911e-05 lr: 5.7911e-06  eta: 8:14:01  time: 0.5963  data_time: 0.0101  memory: 10692  grad_norm: 322.6935  loss: 18.2301  decode.loss_cls: 0.0665  decode.loss_mask: 0.6031  decode.loss_dice: 1.1363  decode.d0.loss_cls: 0.0915  decode.d0.loss_mask: 0.6354  decode.d0.loss_dice: 1.1896  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.5919  decode.d1.loss_dice: 1.1578  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 0.6057  decode.d2.loss_dice: 1.1585  decode.d3.loss_cls: 0.0615  decode.d3.loss_mask: 0.6065  decode.d3.loss_dice: 1.1476  decode.d4.loss_cls: 0.0544  decode.d4.loss_mask: 0.6423  decode.d4.loss_dice: 1.1432  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 0.6277  decode.d5.loss_dice: 1.1493  decode.d6.loss_cls: 0.0643  decode.d6.loss_mask: 0.5958  decode.d6.loss_dice: 1.1225  decode.d7.loss_cls: 0.0551  decode.d7.loss_mask: 0.5854  decode.d7.loss_dice: 1.1549  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.5985  decode.d8.loss_dice: 1.1215
11/15 13:59:39 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 13:59:39 - mmengine - INFO - Iter(train) [41000/90000]  base_lr: 5.7858e-05 lr: 5.7858e-06  eta: 8:13:33  time: 0.5971  data_time: 0.0102  memory: 10656  grad_norm: 532.0696  loss: 17.3118  decode.loss_cls: 0.0726  decode.loss_mask: 0.5478  decode.loss_dice: 1.0842  decode.d0.loss_cls: 0.1135  decode.d0.loss_mask: 0.5731  decode.d0.loss_dice: 1.1070  decode.d1.loss_cls: 0.0763  decode.d1.loss_mask: 0.5744  decode.d1.loss_dice: 1.1139  decode.d2.loss_cls: 0.0763  decode.d2.loss_mask: 0.5512  decode.d2.loss_dice: 1.0861  decode.d3.loss_cls: 0.0808  decode.d3.loss_mask: 0.5525  decode.d3.loss_dice: 1.1255  decode.d4.loss_cls: 0.0674  decode.d4.loss_mask: 0.5504  decode.d4.loss_dice: 1.0810  decode.d5.loss_cls: 0.0772  decode.d5.loss_mask: 0.5442  decode.d5.loss_dice: 1.0734  decode.d6.loss_cls: 0.0782  decode.d6.loss_mask: 0.5527  decode.d6.loss_dice: 1.1066  decode.d7.loss_cls: 0.0806  decode.d7.loss_mask: 0.5438  decode.d7.loss_dice: 1.1424  decode.d8.loss_cls: 0.0801  decode.d8.loss_mask: 0.5288  decode.d8.loss_dice: 1.0700
11/15 14:00:09 - mmengine - INFO - Iter(train) [41050/90000]  base_lr: 5.7805e-05 lr: 5.7805e-06  eta: 8:13:02  time: 0.5966  data_time: 0.0101  memory: 10728  grad_norm: 285.5162  loss: 16.7813  decode.loss_cls: 0.0682  decode.loss_mask: 0.4925  decode.loss_dice: 1.0874  decode.d0.loss_cls: 0.0847  decode.d0.loss_mask: 0.5280  decode.d0.loss_dice: 1.1945  decode.d1.loss_cls: 0.0523  decode.d1.loss_mask: 0.5044  decode.d1.loss_dice: 1.1505  decode.d2.loss_cls: 0.0585  decode.d2.loss_mask: 0.4968  decode.d2.loss_dice: 1.1178  decode.d3.loss_cls: 0.0632  decode.d3.loss_mask: 0.4998  decode.d3.loss_dice: 1.0964  decode.d4.loss_cls: 0.0640  decode.d4.loss_mask: 0.5001  decode.d4.loss_dice: 1.0835  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.5055  decode.d5.loss_dice: 1.1076  decode.d6.loss_cls: 0.0697  decode.d6.loss_mask: 0.4874  decode.d6.loss_dice: 1.0937  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.4891  decode.d7.loss_dice: 1.0975  decode.d8.loss_cls: 0.0672  decode.d8.loss_mask: 0.4973  decode.d8.loss_dice: 1.0961
11/15 14:00:38 - mmengine - INFO - Iter(train) [41100/90000]  base_lr: 5.7752e-05 lr: 5.7752e-06  eta: 8:12:32  time: 0.5978  data_time: 0.0105  memory: 10656  grad_norm: 683.6248  loss: 16.8916  decode.loss_cls: 0.0478  decode.loss_mask: 0.5533  decode.loss_dice: 1.0760  decode.d0.loss_cls: 0.0931  decode.d0.loss_mask: 0.5795  decode.d0.loss_dice: 1.1052  decode.d1.loss_cls: 0.0528  decode.d1.loss_mask: 0.5565  decode.d1.loss_dice: 1.0992  decode.d2.loss_cls: 0.0540  decode.d2.loss_mask: 0.5452  decode.d2.loss_dice: 1.0793  decode.d3.loss_cls: 0.0438  decode.d3.loss_mask: 0.5537  decode.d3.loss_dice: 1.0995  decode.d4.loss_cls: 0.0448  decode.d4.loss_mask: 0.5508  decode.d4.loss_dice: 1.0818  decode.d5.loss_cls: 0.0429  decode.d5.loss_mask: 0.5475  decode.d5.loss_dice: 1.0801  decode.d6.loss_cls: 0.0524  decode.d6.loss_mask: 0.5493  decode.d6.loss_dice: 1.0576  decode.d7.loss_cls: 0.0550  decode.d7.loss_mask: 0.5509  decode.d7.loss_dice: 1.0761  decode.d8.loss_cls: 0.0542  decode.d8.loss_mask: 0.5490  decode.d8.loss_dice: 1.0605
11/15 14:01:08 - mmengine - INFO - Iter(train) [41150/90000]  base_lr: 5.7698e-05 lr: 5.7698e-06  eta: 8:12:01  time: 0.5972  data_time: 0.0103  memory: 10713  grad_norm: 247.7838  loss: 18.5659  decode.loss_cls: 0.0758  decode.loss_mask: 0.5390  decode.loss_dice: 1.2260  decode.d0.loss_cls: 0.0831  decode.d0.loss_mask: 0.5557  decode.d0.loss_dice: 1.2470  decode.d1.loss_cls: 0.0638  decode.d1.loss_mask: 0.5609  decode.d1.loss_dice: 1.2435  decode.d2.loss_cls: 0.0726  decode.d2.loss_mask: 0.5441  decode.d2.loss_dice: 1.2566  decode.d3.loss_cls: 0.0805  decode.d3.loss_mask: 0.5524  decode.d3.loss_dice: 1.2414  decode.d4.loss_cls: 0.0752  decode.d4.loss_mask: 0.5423  decode.d4.loss_dice: 1.2284  decode.d5.loss_cls: 0.0771  decode.d5.loss_mask: 0.5353  decode.d5.loss_dice: 1.2443  decode.d6.loss_cls: 0.0816  decode.d6.loss_mask: 0.5389  decode.d6.loss_dice: 1.2299  decode.d7.loss_cls: 0.0728  decode.d7.loss_mask: 0.5345  decode.d7.loss_dice: 1.2325  decode.d8.loss_cls: 0.0761  decode.d8.loss_mask: 0.5403  decode.d8.loss_dice: 1.2144
11/15 14:01:38 - mmengine - INFO - Iter(train) [41200/90000]  base_lr: 5.7645e-05 lr: 5.7645e-06  eta: 8:11:30  time: 0.5961  data_time: 0.0100  memory: 10656  grad_norm: 310.5570  loss: 17.2220  decode.loss_cls: 0.0802  decode.loss_mask: 0.5026  decode.loss_dice: 1.1732  decode.d0.loss_cls: 0.0932  decode.d0.loss_mask: 0.5091  decode.d0.loss_dice: 1.1988  decode.d1.loss_cls: 0.0950  decode.d1.loss_mask: 0.4965  decode.d1.loss_dice: 1.1638  decode.d2.loss_cls: 0.0948  decode.d2.loss_mask: 0.4829  decode.d2.loss_dice: 1.1248  decode.d3.loss_cls: 0.0884  decode.d3.loss_mask: 0.4779  decode.d3.loss_dice: 1.1067  decode.d4.loss_cls: 0.0863  decode.d4.loss_mask: 0.4846  decode.d4.loss_dice: 1.1536  decode.d5.loss_cls: 0.0976  decode.d5.loss_mask: 0.4827  decode.d5.loss_dice: 1.1431  decode.d6.loss_cls: 0.0751  decode.d6.loss_mask: 0.4754  decode.d6.loss_dice: 1.1285  decode.d7.loss_cls: 0.0851  decode.d7.loss_mask: 0.4821  decode.d7.loss_dice: 1.1437  decode.d8.loss_cls: 0.0920  decode.d8.loss_mask: 0.4744  decode.d8.loss_dice: 1.1298
11/15 14:02:09 - mmengine - INFO - Iter(train) [41250/90000]  base_lr: 5.7592e-05 lr: 5.7592e-06  eta: 8:11:01  time: 0.5978  data_time: 0.0102  memory: 10713  grad_norm: 392.2177  loss: 20.3256  decode.loss_cls: 0.1067  decode.loss_mask: 0.6007  decode.loss_dice: 1.3446  decode.d0.loss_cls: 0.1285  decode.d0.loss_mask: 0.5969  decode.d0.loss_dice: 1.3578  decode.d1.loss_cls: 0.1186  decode.d1.loss_mask: 0.6131  decode.d1.loss_dice: 1.3445  decode.d2.loss_cls: 0.1063  decode.d2.loss_mask: 0.5920  decode.d2.loss_dice: 1.3133  decode.d3.loss_cls: 0.1216  decode.d3.loss_mask: 0.5712  decode.d3.loss_dice: 1.2962  decode.d4.loss_cls: 0.1059  decode.d4.loss_mask: 0.5796  decode.d4.loss_dice: 1.3269  decode.d5.loss_cls: 0.1068  decode.d5.loss_mask: 0.5937  decode.d5.loss_dice: 1.3113  decode.d6.loss_cls: 0.1034  decode.d6.loss_mask: 0.6050  decode.d6.loss_dice: 1.3263  decode.d7.loss_cls: 0.1087  decode.d7.loss_mask: 0.5907  decode.d7.loss_dice: 1.3075  decode.d8.loss_cls: 0.1092  decode.d8.loss_mask: 0.6042  decode.d8.loss_dice: 1.3343
11/15 14:02:40 - mmengine - INFO - Iter(train) [41300/90000]  base_lr: 5.7539e-05 lr: 5.7539e-06  eta: 8:10:31  time: 0.5959  data_time: 0.0103  memory: 10656  grad_norm: 436.5089  loss: 18.3224  decode.loss_cls: 0.0784  decode.loss_mask: 0.6135  decode.loss_dice: 1.1168  decode.d0.loss_cls: 0.1062  decode.d0.loss_mask: 0.6418  decode.d0.loss_dice: 1.2161  decode.d1.loss_cls: 0.0822  decode.d1.loss_mask: 0.6297  decode.d1.loss_dice: 1.1592  decode.d2.loss_cls: 0.0829  decode.d2.loss_mask: 0.6314  decode.d2.loss_dice: 1.1104  decode.d3.loss_cls: 0.0850  decode.d3.loss_mask: 0.6225  decode.d3.loss_dice: 1.1079  decode.d4.loss_cls: 0.0804  decode.d4.loss_mask: 0.6161  decode.d4.loss_dice: 1.1186  decode.d5.loss_cls: 0.0798  decode.d5.loss_mask: 0.6168  decode.d5.loss_dice: 1.0926  decode.d6.loss_cls: 0.0683  decode.d6.loss_mask: 0.6194  decode.d6.loss_dice: 1.1008  decode.d7.loss_cls: 0.0784  decode.d7.loss_mask: 0.6097  decode.d7.loss_dice: 1.1121  decode.d8.loss_cls: 0.0625  decode.d8.loss_mask: 0.6350  decode.d8.loss_dice: 1.1480
11/15 14:03:10 - mmengine - INFO - Iter(train) [41350/90000]  base_lr: 5.7486e-05 lr: 5.7486e-06  eta: 8:10:01  time: 0.5962  data_time: 0.0104  memory: 10675  grad_norm: 287.9549  loss: 14.7134  decode.loss_cls: 0.0710  decode.loss_mask: 0.4582  decode.loss_dice: 0.9125  decode.d0.loss_cls: 0.0787  decode.d0.loss_mask: 0.4981  decode.d0.loss_dice: 1.0190  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.4771  decode.d1.loss_dice: 0.9303  decode.d2.loss_cls: 0.0686  decode.d2.loss_mask: 0.4628  decode.d2.loss_dice: 0.9485  decode.d3.loss_cls: 0.0544  decode.d3.loss_mask: 0.4662  decode.d3.loss_dice: 0.9252  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 0.4684  decode.d4.loss_dice: 0.9542  decode.d5.loss_cls: 0.0693  decode.d5.loss_mask: 0.4567  decode.d5.loss_dice: 0.9347  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.4560  decode.d6.loss_dice: 0.8937  decode.d7.loss_cls: 0.0675  decode.d7.loss_mask: 0.4659  decode.d7.loss_dice: 0.9344  decode.d8.loss_cls: 0.0621  decode.d8.loss_mask: 0.4573  decode.d8.loss_dice: 0.9321
11/15 14:03:40 - mmengine - INFO - Iter(train) [41400/90000]  base_lr: 5.7433e-05 lr: 5.7433e-06  eta: 8:09:30  time: 0.5967  data_time: 0.0103  memory: 10692  grad_norm: 335.0039  loss: 16.5586  decode.loss_cls: 0.0713  decode.loss_mask: 0.5131  decode.loss_dice: 1.0690  decode.d0.loss_cls: 0.0693  decode.d0.loss_mask: 0.5036  decode.d0.loss_dice: 1.1824  decode.d1.loss_cls: 0.0686  decode.d1.loss_mask: 0.4951  decode.d1.loss_dice: 1.1042  decode.d2.loss_cls: 0.0701  decode.d2.loss_mask: 0.4851  decode.d2.loss_dice: 1.0934  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.4970  decode.d3.loss_dice: 1.0624  decode.d4.loss_cls: 0.0662  decode.d4.loss_mask: 0.5022  decode.d4.loss_dice: 1.0688  decode.d5.loss_cls: 0.0811  decode.d5.loss_mask: 0.4841  decode.d5.loss_dice: 1.0869  decode.d6.loss_cls: 0.0784  decode.d6.loss_mask: 0.4871  decode.d6.loss_dice: 1.0606  decode.d7.loss_cls: 0.0772  decode.d7.loss_mask: 0.5060  decode.d7.loss_dice: 1.0786  decode.d8.loss_cls: 0.0841  decode.d8.loss_mask: 0.4802  decode.d8.loss_dice: 1.0637
11/15 14:04:10 - mmengine - INFO - Iter(train) [41450/90000]  base_lr: 5.7379e-05 lr: 5.7379e-06  eta: 8:08:59  time: 0.6005  data_time: 0.0122  memory: 10713  grad_norm: 252.1070  loss: 17.1479  decode.loss_cls: 0.0967  decode.loss_mask: 0.4310  decode.loss_dice: 1.1675  decode.d0.loss_cls: 0.1081  decode.d0.loss_mask: 0.4358  decode.d0.loss_dice: 1.2590  decode.d1.loss_cls: 0.0994  decode.d1.loss_mask: 0.4414  decode.d1.loss_dice: 1.1980  decode.d2.loss_cls: 0.1030  decode.d2.loss_mask: 0.4385  decode.d2.loss_dice: 1.1719  decode.d3.loss_cls: 0.0920  decode.d3.loss_mask: 0.4371  decode.d3.loss_dice: 1.1659  decode.d4.loss_cls: 0.0909  decode.d4.loss_mask: 0.4382  decode.d4.loss_dice: 1.1703  decode.d5.loss_cls: 0.0877  decode.d5.loss_mask: 0.4347  decode.d5.loss_dice: 1.1565  decode.d6.loss_cls: 0.0905  decode.d6.loss_mask: 0.4381  decode.d6.loss_dice: 1.1659  decode.d7.loss_cls: 0.0858  decode.d7.loss_mask: 0.4450  decode.d7.loss_dice: 1.1948  decode.d8.loss_cls: 0.0947  decode.d8.loss_mask: 0.4399  decode.d8.loss_dice: 1.1695
11/15 14:04:39 - mmengine - INFO - Iter(train) [41500/90000]  base_lr: 5.7326e-05 lr: 5.7326e-06  eta: 8:08:29  time: 0.5961  data_time: 0.0102  memory: 10656  grad_norm: 685.1052  loss: 16.2525  decode.loss_cls: 0.0411  decode.loss_mask: 0.4965  decode.loss_dice: 1.0782  decode.d0.loss_cls: 0.0701  decode.d0.loss_mask: 0.5210  decode.d0.loss_dice: 1.1191  decode.d1.loss_cls: 0.0503  decode.d1.loss_mask: 0.4991  decode.d1.loss_dice: 1.0964  decode.d2.loss_cls: 0.0421  decode.d2.loss_mask: 0.4989  decode.d2.loss_dice: 1.0492  decode.d3.loss_cls: 0.0518  decode.d3.loss_mask: 0.4977  decode.d3.loss_dice: 1.0735  decode.d4.loss_cls: 0.0509  decode.d4.loss_mask: 0.4925  decode.d4.loss_dice: 1.0491  decode.d5.loss_cls: 0.0467  decode.d5.loss_mask: 0.4967  decode.d5.loss_dice: 1.0675  decode.d6.loss_cls: 0.0493  decode.d6.loss_mask: 0.4897  decode.d6.loss_dice: 1.0672  decode.d7.loss_cls: 0.0452  decode.d7.loss_mask: 0.4963  decode.d7.loss_dice: 1.0888  decode.d8.loss_cls: 0.0411  decode.d8.loss_mask: 0.4941  decode.d8.loss_dice: 1.0925
11/15 14:05:09 - mmengine - INFO - Iter(train) [41550/90000]  base_lr: 5.7273e-05 lr: 5.7273e-06  eta: 8:07:58  time: 0.5972  data_time: 0.0102  memory: 10656  grad_norm: 300.8394  loss: 17.3037  decode.loss_cls: 0.0858  decode.loss_mask: 0.5031  decode.loss_dice: 1.1098  decode.d0.loss_cls: 0.1167  decode.d0.loss_mask: 0.5346  decode.d0.loss_dice: 1.2012  decode.d1.loss_cls: 0.0703  decode.d1.loss_mask: 0.5261  decode.d1.loss_dice: 1.1652  decode.d2.loss_cls: 0.0881  decode.d2.loss_mask: 0.5213  decode.d2.loss_dice: 1.1816  decode.d3.loss_cls: 0.0892  decode.d3.loss_mask: 0.5245  decode.d3.loss_dice: 1.0993  decode.d4.loss_cls: 0.0845  decode.d4.loss_mask: 0.5096  decode.d4.loss_dice: 1.0973  decode.d5.loss_cls: 0.0897  decode.d5.loss_mask: 0.5105  decode.d5.loss_dice: 1.1029  decode.d6.loss_cls: 0.0851  decode.d6.loss_mask: 0.5078  decode.d6.loss_dice: 1.1254  decode.d7.loss_cls: 0.0849  decode.d7.loss_mask: 0.5059  decode.d7.loss_dice: 1.0928  decode.d8.loss_cls: 0.0899  decode.d8.loss_mask: 0.5053  decode.d8.loss_dice: 1.0952
11/15 14:05:39 - mmengine - INFO - Iter(train) [41600/90000]  base_lr: 5.7220e-05 lr: 5.7220e-06  eta: 8:07:28  time: 0.5967  data_time: 0.0103  memory: 10656  grad_norm: 432.4216  loss: 17.2069  decode.loss_cls: 0.0483  decode.loss_mask: 0.6140  decode.loss_dice: 1.0525  decode.d0.loss_cls: 0.0711  decode.d0.loss_mask: 0.6408  decode.d0.loss_dice: 1.1234  decode.d1.loss_cls: 0.0572  decode.d1.loss_mask: 0.6237  decode.d1.loss_dice: 1.0706  decode.d2.loss_cls: 0.0666  decode.d2.loss_mask: 0.6075  decode.d2.loss_dice: 1.0355  decode.d3.loss_cls: 0.0538  decode.d3.loss_mask: 0.5990  decode.d3.loss_dice: 1.0392  decode.d4.loss_cls: 0.0498  decode.d4.loss_mask: 0.5936  decode.d4.loss_dice: 1.0545  decode.d5.loss_cls: 0.0426  decode.d5.loss_mask: 0.6026  decode.d5.loss_dice: 1.0579  decode.d6.loss_cls: 0.0462  decode.d6.loss_mask: 0.6147  decode.d6.loss_dice: 1.0381  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.6203  decode.d7.loss_dice: 1.0411  decode.d8.loss_cls: 0.0484  decode.d8.loss_mask: 0.6111  decode.d8.loss_dice: 1.0311
11/15 14:06:09 - mmengine - INFO - Iter(train) [41650/90000]  base_lr: 5.7167e-05 lr: 5.7167e-06  eta: 8:06:57  time: 0.5999  data_time: 0.0126  memory: 10692  grad_norm: 455.9588  loss: 17.6212  decode.loss_cls: 0.0830  decode.loss_mask: 0.4780  decode.loss_dice: 1.1349  decode.d0.loss_cls: 0.1360  decode.d0.loss_mask: 0.4724  decode.d0.loss_dice: 1.2338  decode.d1.loss_cls: 0.1058  decode.d1.loss_mask: 0.4889  decode.d1.loss_dice: 1.1844  decode.d2.loss_cls: 0.0835  decode.d2.loss_mask: 0.4935  decode.d2.loss_dice: 1.1790  decode.d3.loss_cls: 0.0760  decode.d3.loss_mask: 0.5083  decode.d3.loss_dice: 1.1570  decode.d4.loss_cls: 0.0791  decode.d4.loss_mask: 0.5159  decode.d4.loss_dice: 1.1784  decode.d5.loss_cls: 0.0770  decode.d5.loss_mask: 0.5250  decode.d5.loss_dice: 1.1508  decode.d6.loss_cls: 0.0808  decode.d6.loss_mask: 0.5129  decode.d6.loss_dice: 1.1281  decode.d7.loss_cls: 0.0780  decode.d7.loss_mask: 0.5147  decode.d7.loss_dice: 1.2092  decode.d8.loss_cls: 0.0809  decode.d8.loss_mask: 0.5224  decode.d8.loss_dice: 1.1534
11/15 14:06:39 - mmengine - INFO - Iter(train) [41700/90000]  base_lr: 5.7113e-05 lr: 5.7113e-06  eta: 8:06:26  time: 0.5972  data_time: 0.0102  memory: 10713  grad_norm: 334.0061  loss: 16.7467  decode.loss_cls: 0.0743  decode.loss_mask: 0.4599  decode.loss_dice: 1.1357  decode.d0.loss_cls: 0.0852  decode.d0.loss_mask: 0.4899  decode.d0.loss_dice: 1.2315  decode.d1.loss_cls: 0.0770  decode.d1.loss_mask: 0.4613  decode.d1.loss_dice: 1.1317  decode.d2.loss_cls: 0.0837  decode.d2.loss_mask: 0.4525  decode.d2.loss_dice: 1.1333  decode.d3.loss_cls: 0.0909  decode.d3.loss_mask: 0.4396  decode.d3.loss_dice: 1.1225  decode.d4.loss_cls: 0.0892  decode.d4.loss_mask: 0.4443  decode.d4.loss_dice: 1.1052  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.4634  decode.d5.loss_dice: 1.1363  decode.d6.loss_cls: 0.0737  decode.d6.loss_mask: 0.4579  decode.d6.loss_dice: 1.1228  decode.d7.loss_cls: 0.0763  decode.d7.loss_mask: 0.4586  decode.d7.loss_dice: 1.1192  decode.d8.loss_cls: 0.0755  decode.d8.loss_mask: 0.4591  decode.d8.loss_dice: 1.1331
11/15 14:07:09 - mmengine - INFO - Iter(train) [41750/90000]  base_lr: 5.7060e-05 lr: 5.7060e-06  eta: 8:05:56  time: 0.5974  data_time: 0.0103  memory: 10713  grad_norm: 317.6219  loss: 15.5742  decode.loss_cls: 0.0615  decode.loss_mask: 0.4231  decode.loss_dice: 1.0756  decode.d0.loss_cls: 0.0646  decode.d0.loss_mask: 0.4228  decode.d0.loss_dice: 1.1228  decode.d1.loss_cls: 0.0546  decode.d1.loss_mask: 0.4175  decode.d1.loss_dice: 1.0983  decode.d2.loss_cls: 0.0510  decode.d2.loss_mask: 0.4163  decode.d2.loss_dice: 1.0953  decode.d3.loss_cls: 0.0650  decode.d3.loss_mask: 0.4059  decode.d3.loss_dice: 1.0796  decode.d4.loss_cls: 0.0622  decode.d4.loss_mask: 0.4097  decode.d4.loss_dice: 1.0701  decode.d5.loss_cls: 0.0541  decode.d5.loss_mask: 0.4167  decode.d5.loss_dice: 1.0476  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.4172  decode.d6.loss_dice: 1.0675  decode.d7.loss_cls: 0.0580  decode.d7.loss_mask: 0.4151  decode.d7.loss_dice: 1.0719  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.4183  decode.d8.loss_dice: 1.0999
11/15 14:07:39 - mmengine - INFO - Iter(train) [41800/90000]  base_lr: 5.7007e-05 lr: 5.7007e-06  eta: 8:05:25  time: 0.6005  data_time: 0.0103  memory: 10713  grad_norm: 267.8081  loss: 16.9724  decode.loss_cls: 0.0675  decode.loss_mask: 0.4909  decode.loss_dice: 1.0992  decode.d0.loss_cls: 0.0760  decode.d0.loss_mask: 0.5438  decode.d0.loss_dice: 1.1983  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.5092  decode.d1.loss_dice: 1.1357  decode.d2.loss_cls: 0.0546  decode.d2.loss_mask: 0.5081  decode.d2.loss_dice: 1.1198  decode.d3.loss_cls: 0.0530  decode.d3.loss_mask: 0.5148  decode.d3.loss_dice: 1.1271  decode.d4.loss_cls: 0.0582  decode.d4.loss_mask: 0.4993  decode.d4.loss_dice: 1.1308  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.5106  decode.d5.loss_dice: 1.1274  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.4904  decode.d6.loss_dice: 1.1134  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 0.4967  decode.d7.loss_dice: 1.1137  decode.d8.loss_cls: 0.0685  decode.d8.loss_mask: 0.4975  decode.d8.loss_dice: 1.1272
11/15 14:08:09 - mmengine - INFO - Iter(train) [41850/90000]  base_lr: 5.6954e-05 lr: 5.6954e-06  eta: 8:04:55  time: 0.6008  data_time: 0.0105  memory: 10742  grad_norm: 281.6808  loss: 16.3497  decode.loss_cls: 0.0789  decode.loss_mask: 0.4734  decode.loss_dice: 1.0371  decode.d0.loss_cls: 0.0947  decode.d0.loss_mask: 0.4945  decode.d0.loss_dice: 1.1435  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.4857  decode.d1.loss_dice: 1.1050  decode.d2.loss_cls: 0.0801  decode.d2.loss_mask: 0.4790  decode.d2.loss_dice: 1.0937  decode.d3.loss_cls: 0.0651  decode.d3.loss_mask: 0.4853  decode.d3.loss_dice: 1.0589  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.4859  decode.d4.loss_dice: 1.0697  decode.d5.loss_cls: 0.0658  decode.d5.loss_mask: 0.4879  decode.d5.loss_dice: 1.0842  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.4857  decode.d6.loss_dice: 1.0778  decode.d7.loss_cls: 0.0604  decode.d7.loss_mask: 0.4808  decode.d7.loss_dice: 1.0716  decode.d8.loss_cls: 0.0781  decode.d8.loss_mask: 0.4793  decode.d8.loss_dice: 1.0493
11/15 14:08:38 - mmengine - INFO - Iter(train) [41900/90000]  base_lr: 5.6901e-05 lr: 5.6901e-06  eta: 8:04:24  time: 0.5968  data_time: 0.0101  memory: 10641  grad_norm: 394.8321  loss: 18.1475  decode.loss_cls: 0.0885  decode.loss_mask: 0.5389  decode.loss_dice: 1.1654  decode.d0.loss_cls: 0.0938  decode.d0.loss_mask: 0.5785  decode.d0.loss_dice: 1.2762  decode.d1.loss_cls: 0.0782  decode.d1.loss_mask: 0.5555  decode.d1.loss_dice: 1.1957  decode.d2.loss_cls: 0.0606  decode.d2.loss_mask: 0.5552  decode.d2.loss_dice: 1.1818  decode.d3.loss_cls: 0.0562  decode.d3.loss_mask: 0.5578  decode.d3.loss_dice: 1.1858  decode.d4.loss_cls: 0.0672  decode.d4.loss_mask: 0.5519  decode.d4.loss_dice: 1.1660  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.5496  decode.d5.loss_dice: 1.1888  decode.d6.loss_cls: 0.0705  decode.d6.loss_mask: 0.5560  decode.d6.loss_dice: 1.1698  decode.d7.loss_cls: 0.0668  decode.d7.loss_mask: 0.5543  decode.d7.loss_dice: 1.1959  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.5448  decode.d8.loss_dice: 1.1604
11/15 14:09:11 - mmengine - INFO - Iter(train) [41950/90000]  base_lr: 5.6847e-05 lr: 5.6847e-06  eta: 8:03:56  time: 0.5969  data_time: 0.0107  memory: 10692  grad_norm: 384.5165  loss: 18.3328  decode.loss_cls: 0.0894  decode.loss_mask: 0.5416  decode.loss_dice: 1.1322  decode.d0.loss_cls: 0.0770  decode.d0.loss_mask: 0.5708  decode.d0.loss_dice: 1.2207  decode.d1.loss_cls: 0.0811  decode.d1.loss_mask: 0.6079  decode.d1.loss_dice: 1.1995  decode.d2.loss_cls: 0.0925  decode.d2.loss_mask: 0.6100  decode.d2.loss_dice: 1.1849  decode.d3.loss_cls: 0.0686  decode.d3.loss_mask: 0.5819  decode.d3.loss_dice: 1.1733  decode.d4.loss_cls: 0.0949  decode.d4.loss_mask: 0.5662  decode.d4.loss_dice: 1.1355  decode.d5.loss_cls: 0.0735  decode.d5.loss_mask: 0.5523  decode.d5.loss_dice: 1.1701  decode.d6.loss_cls: 0.0900  decode.d6.loss_mask: 0.5794  decode.d6.loss_dice: 1.1665  decode.d7.loss_cls: 0.0739  decode.d7.loss_mask: 0.5964  decode.d7.loss_dice: 1.1980  decode.d8.loss_cls: 0.0886  decode.d8.loss_mask: 0.5676  decode.d8.loss_dice: 1.1483
11/15 14:09:40 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 14:09:40 - mmengine - INFO - Iter(train) [42000/90000]  base_lr: 5.6794e-05 lr: 5.6794e-06  eta: 8:03:25  time: 0.5985  data_time: 0.0105  memory: 10713  grad_norm: 281.9381  loss: 15.3830  decode.loss_cls: 0.0463  decode.loss_mask: 0.4661  decode.loss_dice: 1.0100  decode.d0.loss_cls: 0.0649  decode.d0.loss_mask: 0.4749  decode.d0.loss_dice: 1.0714  decode.d1.loss_cls: 0.0464  decode.d1.loss_mask: 0.4527  decode.d1.loss_dice: 1.0264  decode.d2.loss_cls: 0.0483  decode.d2.loss_mask: 0.4631  decode.d2.loss_dice: 1.0261  decode.d3.loss_cls: 0.0497  decode.d3.loss_mask: 0.4600  decode.d3.loss_dice: 1.0216  decode.d4.loss_cls: 0.0402  decode.d4.loss_mask: 0.4653  decode.d4.loss_dice: 1.0174  decode.d5.loss_cls: 0.0420  decode.d5.loss_mask: 0.4650  decode.d5.loss_dice: 1.0174  decode.d6.loss_cls: 0.0437  decode.d6.loss_mask: 0.4620  decode.d6.loss_dice: 1.0354  decode.d7.loss_cls: 0.0504  decode.d7.loss_mask: 0.4611  decode.d7.loss_dice: 1.0148  decode.d8.loss_cls: 0.0387  decode.d8.loss_mask: 0.4650  decode.d8.loss_dice: 1.0363
11/15 14:10:10 - mmengine - INFO - Iter(train) [42050/90000]  base_lr: 5.6741e-05 lr: 5.6741e-06  eta: 8:02:55  time: 0.5959  data_time: 0.0102  memory: 10656  grad_norm: 257.1053  loss: 15.2788  decode.loss_cls: 0.0508  decode.loss_mask: 0.5040  decode.loss_dice: 0.9461  decode.d0.loss_cls: 0.0933  decode.d0.loss_mask: 0.5361  decode.d0.loss_dice: 1.0274  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.4960  decode.d1.loss_dice: 0.9884  decode.d2.loss_cls: 0.0497  decode.d2.loss_mask: 0.5113  decode.d2.loss_dice: 0.9686  decode.d3.loss_cls: 0.0400  decode.d3.loss_mask: 0.5083  decode.d3.loss_dice: 0.9671  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.5053  decode.d4.loss_dice: 0.9454  decode.d5.loss_cls: 0.0531  decode.d5.loss_mask: 0.5138  decode.d5.loss_dice: 0.9693  decode.d6.loss_cls: 0.0534  decode.d6.loss_mask: 0.4893  decode.d6.loss_dice: 0.9466  decode.d7.loss_cls: 0.0440  decode.d7.loss_mask: 0.4874  decode.d7.loss_dice: 0.9648  decode.d8.loss_cls: 0.0465  decode.d8.loss_mask: 0.5077  decode.d8.loss_dice: 0.9479
11/15 14:10:40 - mmengine - INFO - Iter(train) [42100/90000]  base_lr: 5.6688e-05 lr: 5.6688e-06  eta: 8:02:24  time: 0.5966  data_time: 0.0102  memory: 10692  grad_norm: 247.5815  loss: 14.2360  decode.loss_cls: 0.0418  decode.loss_mask: 0.4079  decode.loss_dice: 0.9815  decode.d0.loss_cls: 0.0587  decode.d0.loss_mask: 0.4120  decode.d0.loss_dice: 1.0228  decode.d1.loss_cls: 0.0483  decode.d1.loss_mask: 0.3937  decode.d1.loss_dice: 0.9880  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.3914  decode.d2.loss_dice: 0.9586  decode.d3.loss_cls: 0.0374  decode.d3.loss_mask: 0.4061  decode.d3.loss_dice: 0.9804  decode.d4.loss_cls: 0.0457  decode.d4.loss_mask: 0.3956  decode.d4.loss_dice: 0.9438  decode.d5.loss_cls: 0.0413  decode.d5.loss_mask: 0.3989  decode.d5.loss_dice: 0.9729  decode.d6.loss_cls: 0.0318  decode.d6.loss_mask: 0.4071  decode.d6.loss_dice: 0.9849  decode.d7.loss_cls: 0.0305  decode.d7.loss_mask: 0.4067  decode.d7.loss_dice: 0.9784  decode.d8.loss_cls: 0.0369  decode.d8.loss_mask: 0.4041  decode.d8.loss_dice: 0.9774
11/15 14:11:10 - mmengine - INFO - Iter(train) [42150/90000]  base_lr: 5.6634e-05 lr: 5.6634e-06  eta: 8:01:53  time: 0.6004  data_time: 0.0106  memory: 10656  grad_norm: 431.6745  loss: 16.7114  decode.loss_cls: 0.0686  decode.loss_mask: 0.5276  decode.loss_dice: 1.0543  decode.d0.loss_cls: 0.0725  decode.d0.loss_mask: 0.5315  decode.d0.loss_dice: 1.1841  decode.d1.loss_cls: 0.0635  decode.d1.loss_mask: 0.5207  decode.d1.loss_dice: 1.1064  decode.d2.loss_cls: 0.0647  decode.d2.loss_mask: 0.5229  decode.d2.loss_dice: 1.0505  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.5291  decode.d3.loss_dice: 1.0461  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.5335  decode.d4.loss_dice: 1.0660  decode.d5.loss_cls: 0.0645  decode.d5.loss_mask: 0.5344  decode.d5.loss_dice: 1.0746  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.5308  decode.d6.loss_dice: 1.0567  decode.d7.loss_cls: 0.0673  decode.d7.loss_mask: 0.5305  decode.d7.loss_dice: 1.0676  decode.d8.loss_cls: 0.0649  decode.d8.loss_mask: 0.5221  decode.d8.loss_dice: 1.0707
11/15 14:11:41 - mmengine - INFO - Iter(train) [42200/90000]  base_lr: 5.6581e-05 lr: 5.6581e-06  eta: 8:01:24  time: 0.5980  data_time: 0.0105  memory: 10728  grad_norm: 423.1603  loss: 19.4175  decode.loss_cls: 0.1127  decode.loss_mask: 0.5471  decode.loss_dice: 1.2320  decode.d0.loss_cls: 0.1138  decode.d0.loss_mask: 0.6206  decode.d0.loss_dice: 1.3265  decode.d1.loss_cls: 0.1129  decode.d1.loss_mask: 0.5552  decode.d1.loss_dice: 1.2797  decode.d2.loss_cls: 0.1050  decode.d2.loss_mask: 0.5536  decode.d2.loss_dice: 1.2492  decode.d3.loss_cls: 0.1097  decode.d3.loss_mask: 0.5668  decode.d3.loss_dice: 1.2752  decode.d4.loss_cls: 0.1099  decode.d4.loss_mask: 0.5647  decode.d4.loss_dice: 1.2689  decode.d5.loss_cls: 0.1047  decode.d5.loss_mask: 0.5537  decode.d5.loss_dice: 1.2494  decode.d6.loss_cls: 0.1059  decode.d6.loss_mask: 0.5607  decode.d6.loss_dice: 1.2561  decode.d7.loss_cls: 0.1021  decode.d7.loss_mask: 0.5612  decode.d7.loss_dice: 1.2727  decode.d8.loss_cls: 0.1099  decode.d8.loss_mask: 0.5706  decode.d8.loss_dice: 1.2672
11/15 14:12:10 - mmengine - INFO - Iter(train) [42250/90000]  base_lr: 5.6528e-05 lr: 5.6528e-06  eta: 8:00:53  time: 0.5951  data_time: 0.0104  memory: 10692  grad_norm: 394.8977  loss: 15.5041  decode.loss_cls: 0.0768  decode.loss_mask: 0.3871  decode.loss_dice: 1.0459  decode.d0.loss_cls: 0.0781  decode.d0.loss_mask: 0.4148  decode.d0.loss_dice: 1.1819  decode.d1.loss_cls: 0.0558  decode.d1.loss_mask: 0.4014  decode.d1.loss_dice: 1.1012  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.3957  decode.d2.loss_dice: 1.0952  decode.d3.loss_cls: 0.0485  decode.d3.loss_mask: 0.3951  decode.d3.loss_dice: 1.0954  decode.d4.loss_cls: 0.0520  decode.d4.loss_mask: 0.3941  decode.d4.loss_dice: 1.0749  decode.d5.loss_cls: 0.0561  decode.d5.loss_mask: 0.3908  decode.d5.loss_dice: 1.0968  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 0.3921  decode.d6.loss_dice: 1.0930  decode.d7.loss_cls: 0.0676  decode.d7.loss_mask: 0.3958  decode.d7.loss_dice: 1.0639  decode.d8.loss_cls: 0.0505  decode.d8.loss_mask: 0.4032  decode.d8.loss_dice: 1.0877
11/15 14:12:40 - mmengine - INFO - Iter(train) [42300/90000]  base_lr: 5.6475e-05 lr: 5.6475e-06  eta: 8:00:22  time: 0.5997  data_time: 0.0105  memory: 10692  grad_norm: 385.8969  loss: 17.0327  decode.loss_cls: 0.0778  decode.loss_mask: 0.4516  decode.loss_dice: 1.1669  decode.d0.loss_cls: 0.1010  decode.d0.loss_mask: 0.4690  decode.d0.loss_dice: 1.2342  decode.d1.loss_cls: 0.0843  decode.d1.loss_mask: 0.4741  decode.d1.loss_dice: 1.2108  decode.d2.loss_cls: 0.0730  decode.d2.loss_mask: 0.4640  decode.d2.loss_dice: 1.1372  decode.d3.loss_cls: 0.0779  decode.d3.loss_mask: 0.4568  decode.d3.loss_dice: 1.1332  decode.d4.loss_cls: 0.0763  decode.d4.loss_mask: 0.4567  decode.d4.loss_dice: 1.1232  decode.d5.loss_cls: 0.0661  decode.d5.loss_mask: 0.4598  decode.d5.loss_dice: 1.1618  decode.d6.loss_cls: 0.0657  decode.d6.loss_mask: 0.4667  decode.d6.loss_dice: 1.1520  decode.d7.loss_cls: 0.0735  decode.d7.loss_mask: 0.4640  decode.d7.loss_dice: 1.1424  decode.d8.loss_cls: 0.0711  decode.d8.loss_mask: 0.4620  decode.d8.loss_dice: 1.1798
11/15 14:13:10 - mmengine - INFO - Iter(train) [42350/90000]  base_lr: 5.6421e-05 lr: 5.6421e-06  eta: 7:59:52  time: 0.5983  data_time: 0.0105  memory: 10692  grad_norm: 365.5605  loss: 16.3930  decode.loss_cls: 0.0651  decode.loss_mask: 0.5013  decode.loss_dice: 1.0605  decode.d0.loss_cls: 0.0845  decode.d0.loss_mask: 0.5276  decode.d0.loss_dice: 1.1850  decode.d1.loss_cls: 0.0847  decode.d1.loss_mask: 0.5062  decode.d1.loss_dice: 1.1013  decode.d2.loss_cls: 0.0668  decode.d2.loss_mask: 0.5091  decode.d2.loss_dice: 1.0941  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.4940  decode.d3.loss_dice: 1.0308  decode.d4.loss_cls: 0.0604  decode.d4.loss_mask: 0.4940  decode.d4.loss_dice: 1.0482  decode.d5.loss_cls: 0.0627  decode.d5.loss_mask: 0.4982  decode.d5.loss_dice: 1.0372  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.4958  decode.d6.loss_dice: 1.0312  decode.d7.loss_cls: 0.0667  decode.d7.loss_mask: 0.4981  decode.d7.loss_dice: 1.0578  decode.d8.loss_cls: 0.0677  decode.d8.loss_mask: 0.5010  decode.d8.loss_dice: 1.0423
11/15 14:13:40 - mmengine - INFO - Iter(train) [42400/90000]  base_lr: 5.6368e-05 lr: 5.6368e-06  eta: 7:59:21  time: 0.6019  data_time: 0.0109  memory: 10641  grad_norm: 565.2487  loss: 18.2344  decode.loss_cls: 0.0829  decode.loss_mask: 0.5443  decode.loss_dice: 1.1694  decode.d0.loss_cls: 0.1133  decode.d0.loss_mask: 0.5962  decode.d0.loss_dice: 1.1936  decode.d1.loss_cls: 0.1039  decode.d1.loss_mask: 0.5657  decode.d1.loss_dice: 1.1542  decode.d2.loss_cls: 0.0787  decode.d2.loss_mask: 0.5570  decode.d2.loss_dice: 1.2023  decode.d3.loss_cls: 0.0985  decode.d3.loss_mask: 0.5646  decode.d3.loss_dice: 1.1230  decode.d4.loss_cls: 0.0876  decode.d4.loss_mask: 0.5729  decode.d4.loss_dice: 1.1675  decode.d5.loss_cls: 0.0703  decode.d5.loss_mask: 0.5790  decode.d5.loss_dice: 1.1568  decode.d6.loss_cls: 0.0783  decode.d6.loss_mask: 0.5805  decode.d6.loss_dice: 1.1765  decode.d7.loss_cls: 0.0713  decode.d7.loss_mask: 0.5752  decode.d7.loss_dice: 1.1807  decode.d8.loss_cls: 0.0736  decode.d8.loss_mask: 0.5687  decode.d8.loss_dice: 1.1481
11/15 14:14:10 - mmengine - INFO - Iter(train) [42450/90000]  base_lr: 5.6315e-05 lr: 5.6315e-06  eta: 7:58:51  time: 0.5978  data_time: 0.0103  memory: 10675  grad_norm: 293.1916  loss: 17.6944  decode.loss_cls: 0.0624  decode.loss_mask: 0.4646  decode.loss_dice: 1.2195  decode.d0.loss_cls: 0.0890  decode.d0.loss_mask: 0.4853  decode.d0.loss_dice: 1.2885  decode.d1.loss_cls: 0.0639  decode.d1.loss_mask: 0.4714  decode.d1.loss_dice: 1.2688  decode.d2.loss_cls: 0.0677  decode.d2.loss_mask: 0.4680  decode.d2.loss_dice: 1.2416  decode.d3.loss_cls: 0.0674  decode.d3.loss_mask: 0.4612  decode.d3.loss_dice: 1.2216  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.4614  decode.d4.loss_dice: 1.2233  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.4575  decode.d5.loss_dice: 1.2272  decode.d6.loss_cls: 0.0632  decode.d6.loss_mask: 0.4581  decode.d6.loss_dice: 1.2449  decode.d7.loss_cls: 0.0637  decode.d7.loss_mask: 0.4629  decode.d7.loss_dice: 1.2197  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.4647  decode.d8.loss_dice: 1.2254
11/15 14:14:40 - mmengine - INFO - Iter(train) [42500/90000]  base_lr: 5.6261e-05 lr: 5.6261e-06  eta: 7:58:20  time: 0.5960  data_time: 0.0102  memory: 10675  grad_norm: 249.8765  loss: 16.3430  decode.loss_cls: 0.0618  decode.loss_mask: 0.4644  decode.loss_dice: 1.0877  decode.d0.loss_cls: 0.0841  decode.d0.loss_mask: 0.4953  decode.d0.loss_dice: 1.1130  decode.d1.loss_cls: 0.0725  decode.d1.loss_mask: 0.4749  decode.d1.loss_dice: 1.0955  decode.d2.loss_cls: 0.0570  decode.d2.loss_mask: 0.4799  decode.d2.loss_dice: 1.1114  decode.d3.loss_cls: 0.0700  decode.d3.loss_mask: 0.4748  decode.d3.loss_dice: 1.0619  decode.d4.loss_cls: 0.0587  decode.d4.loss_mask: 0.4799  decode.d4.loss_dice: 1.0986  decode.d5.loss_cls: 0.0623  decode.d5.loss_mask: 0.4732  decode.d5.loss_dice: 1.0690  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.4863  decode.d6.loss_dice: 1.0656  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.4833  decode.d7.loss_dice: 1.1135  decode.d8.loss_cls: 0.0667  decode.d8.loss_mask: 0.4676  decode.d8.loss_dice: 1.0851
11/15 14:15:10 - mmengine - INFO - Iter(train) [42550/90000]  base_lr: 5.6208e-05 lr: 5.6208e-06  eta: 7:57:49  time: 0.5959  data_time: 0.0103  memory: 10656  grad_norm: 339.7175  loss: 16.2941  decode.loss_cls: 0.0732  decode.loss_mask: 0.4182  decode.loss_dice: 1.1381  decode.d0.loss_cls: 0.0754  decode.d0.loss_mask: 0.4181  decode.d0.loss_dice: 1.2143  decode.d1.loss_cls: 0.0765  decode.d1.loss_mask: 0.4045  decode.d1.loss_dice: 1.1275  decode.d2.loss_cls: 0.0746  decode.d2.loss_mask: 0.4154  decode.d2.loss_dice: 1.1128  decode.d3.loss_cls: 0.0744  decode.d3.loss_mask: 0.4135  decode.d3.loss_dice: 1.1307  decode.d4.loss_cls: 0.0873  decode.d4.loss_mask: 0.4136  decode.d4.loss_dice: 1.0943  decode.d5.loss_cls: 0.0795  decode.d5.loss_mask: 0.4143  decode.d5.loss_dice: 1.1221  decode.d6.loss_cls: 0.0696  decode.d6.loss_mask: 0.4171  decode.d6.loss_dice: 1.1424  decode.d7.loss_cls: 0.0715  decode.d7.loss_mask: 0.4184  decode.d7.loss_dice: 1.1601  decode.d8.loss_cls: 0.0694  decode.d8.loss_mask: 0.4183  decode.d8.loss_dice: 1.1488
11/15 14:15:40 - mmengine - INFO - Iter(train) [42600/90000]  base_lr: 5.6155e-05 lr: 5.6155e-06  eta: 7:57:19  time: 0.5954  data_time: 0.0102  memory: 10675  grad_norm: 458.3027  loss: 17.4445  decode.loss_cls: 0.0674  decode.loss_mask: 0.5178  decode.loss_dice: 1.1681  decode.d0.loss_cls: 0.0771  decode.d0.loss_mask: 0.5271  decode.d0.loss_dice: 1.2390  decode.d1.loss_cls: 0.0747  decode.d1.loss_mask: 0.5190  decode.d1.loss_dice: 1.1713  decode.d2.loss_cls: 0.0717  decode.d2.loss_mask: 0.5025  decode.d2.loss_dice: 1.1531  decode.d3.loss_cls: 0.0741  decode.d3.loss_mask: 0.5110  decode.d3.loss_dice: 1.1436  decode.d4.loss_cls: 0.0725  decode.d4.loss_mask: 0.5149  decode.d4.loss_dice: 1.1366  decode.d5.loss_cls: 0.0646  decode.d5.loss_mask: 0.5298  decode.d5.loss_dice: 1.1384  decode.d6.loss_cls: 0.0789  decode.d6.loss_mask: 0.5310  decode.d6.loss_dice: 1.1266  decode.d7.loss_cls: 0.0896  decode.d7.loss_mask: 0.5185  decode.d7.loss_dice: 1.1353  decode.d8.loss_cls: 0.0867  decode.d8.loss_mask: 0.4930  decode.d8.loss_dice: 1.1107
11/15 14:16:10 - mmengine - INFO - Iter(train) [42650/90000]  base_lr: 5.6101e-05 lr: 5.6101e-06  eta: 7:56:48  time: 0.5964  data_time: 0.0102  memory: 10728  grad_norm: 330.6701  loss: 15.9015  decode.loss_cls: 0.0387  decode.loss_mask: 0.5260  decode.loss_dice: 1.0186  decode.d0.loss_cls: 0.0664  decode.d0.loss_mask: 0.5416  decode.d0.loss_dice: 1.0691  decode.d1.loss_cls: 0.0321  decode.d1.loss_mask: 0.5212  decode.d1.loss_dice: 1.0565  decode.d2.loss_cls: 0.0491  decode.d2.loss_mask: 0.5018  decode.d2.loss_dice: 1.0293  decode.d3.loss_cls: 0.0412  decode.d3.loss_mask: 0.5058  decode.d3.loss_dice: 1.0162  decode.d4.loss_cls: 0.0503  decode.d4.loss_mask: 0.4999  decode.d4.loss_dice: 1.0272  decode.d5.loss_cls: 0.0365  decode.d5.loss_mask: 0.5197  decode.d5.loss_dice: 1.0264  decode.d6.loss_cls: 0.0368  decode.d6.loss_mask: 0.5196  decode.d6.loss_dice: 1.0166  decode.d7.loss_cls: 0.0307  decode.d7.loss_mask: 0.5246  decode.d7.loss_dice: 1.0313  decode.d8.loss_cls: 0.0407  decode.d8.loss_mask: 0.5153  decode.d8.loss_dice: 1.0121
11/15 14:16:39 - mmengine - INFO - Iter(train) [42700/90000]  base_lr: 5.6048e-05 lr: 5.6048e-06  eta: 7:56:18  time: 0.5959  data_time: 0.0102  memory: 10675  grad_norm: 381.6343  loss: 17.7075  decode.loss_cls: 0.0688  decode.loss_mask: 0.6009  decode.loss_dice: 1.0994  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.6623  decode.d0.loss_dice: 1.1455  decode.d1.loss_cls: 0.0657  decode.d1.loss_mask: 0.6267  decode.d1.loss_dice: 1.1380  decode.d2.loss_cls: 0.0642  decode.d2.loss_mask: 0.6064  decode.d2.loss_dice: 1.0963  decode.d3.loss_cls: 0.0627  decode.d3.loss_mask: 0.6054  decode.d3.loss_dice: 1.0904  decode.d4.loss_cls: 0.0664  decode.d4.loss_mask: 0.6108  decode.d4.loss_dice: 1.1041  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.5985  decode.d5.loss_dice: 1.0586  decode.d6.loss_cls: 0.0645  decode.d6.loss_mask: 0.6100  decode.d6.loss_dice: 1.0727  decode.d7.loss_cls: 0.0593  decode.d7.loss_mask: 0.6024  decode.d7.loss_dice: 1.0658  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.6002  decode.d8.loss_dice: 1.0588
11/15 14:17:09 - mmengine - INFO - Iter(train) [42750/90000]  base_lr: 5.5995e-05 lr: 5.5995e-06  eta: 7:55:47  time: 0.5950  data_time: 0.0104  memory: 10656  grad_norm: 531.2347  loss: 17.2475  decode.loss_cls: 0.0504  decode.loss_mask: 0.5477  decode.loss_dice: 1.1054  decode.d0.loss_cls: 0.1095  decode.d0.loss_mask: 0.5808  decode.d0.loss_dice: 1.1981  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.5599  decode.d1.loss_dice: 1.1632  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 0.5487  decode.d2.loss_dice: 1.1261  decode.d3.loss_cls: 0.0636  decode.d3.loss_mask: 0.5232  decode.d3.loss_dice: 1.0902  decode.d4.loss_cls: 0.0531  decode.d4.loss_mask: 0.5215  decode.d4.loss_dice: 1.0908  decode.d5.loss_cls: 0.0635  decode.d5.loss_mask: 0.5294  decode.d5.loss_dice: 1.0995  decode.d6.loss_cls: 0.0592  decode.d6.loss_mask: 0.5206  decode.d6.loss_dice: 1.1060  decode.d7.loss_cls: 0.0512  decode.d7.loss_mask: 0.5438  decode.d7.loss_dice: 1.1053  decode.d8.loss_cls: 0.0491  decode.d8.loss_mask: 0.5443  decode.d8.loss_dice: 1.1264
11/15 14:17:39 - mmengine - INFO - Iter(train) [42800/90000]  base_lr: 5.5941e-05 lr: 5.5941e-06  eta: 7:55:16  time: 0.5949  data_time: 0.0100  memory: 10675  grad_norm: 862.0644  loss: 17.4615  decode.loss_cls: 0.0677  decode.loss_mask: 0.4898  decode.loss_dice: 1.1643  decode.d0.loss_cls: 0.0933  decode.d0.loss_mask: 0.4824  decode.d0.loss_dice: 1.2658  decode.d1.loss_cls: 0.0897  decode.d1.loss_mask: 0.4947  decode.d1.loss_dice: 1.2047  decode.d2.loss_cls: 0.0790  decode.d2.loss_mask: 0.4987  decode.d2.loss_dice: 1.1914  decode.d3.loss_cls: 0.0699  decode.d3.loss_mask: 0.4922  decode.d3.loss_dice: 1.1764  decode.d4.loss_cls: 0.0766  decode.d4.loss_mask: 0.4851  decode.d4.loss_dice: 1.1588  decode.d5.loss_cls: 0.0721  decode.d5.loss_mask: 0.4779  decode.d5.loss_dice: 1.1418  decode.d6.loss_cls: 0.0731  decode.d6.loss_mask: 0.4875  decode.d6.loss_dice: 1.1676  decode.d7.loss_cls: 0.0689  decode.d7.loss_mask: 0.4913  decode.d7.loss_dice: 1.1595  decode.d8.loss_cls: 0.0714  decode.d8.loss_mask: 0.4902  decode.d8.loss_dice: 1.1795
11/15 14:18:09 - mmengine - INFO - Iter(train) [42850/90000]  base_lr: 5.5888e-05 lr: 5.5888e-06  eta: 7:54:46  time: 0.5948  data_time: 0.0101  memory: 10692  grad_norm: 373.2751  loss: 17.5922  decode.loss_cls: 0.0562  decode.loss_mask: 0.5701  decode.loss_dice: 1.1291  decode.d0.loss_cls: 0.0778  decode.d0.loss_mask: 0.6114  decode.d0.loss_dice: 1.1656  decode.d1.loss_cls: 0.0617  decode.d1.loss_mask: 0.5774  decode.d1.loss_dice: 1.1375  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.5648  decode.d2.loss_dice: 1.1605  decode.d3.loss_cls: 0.0531  decode.d3.loss_mask: 0.5636  decode.d3.loss_dice: 1.1106  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.5612  decode.d4.loss_dice: 1.1432  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.5548  decode.d5.loss_dice: 1.1133  decode.d6.loss_cls: 0.0613  decode.d6.loss_mask: 0.5598  decode.d6.loss_dice: 1.0909  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 0.5588  decode.d7.loss_dice: 1.1341  decode.d8.loss_cls: 0.0606  decode.d8.loss_mask: 0.5618  decode.d8.loss_dice: 1.1041
11/15 14:18:39 - mmengine - INFO - Iter(train) [42900/90000]  base_lr: 5.5835e-05 lr: 5.5835e-06  eta: 7:54:15  time: 0.5975  data_time: 0.0100  memory: 10728  grad_norm: 182.4021  loss: 17.0662  decode.loss_cls: 0.0898  decode.loss_mask: 0.4287  decode.loss_dice: 1.1969  decode.d0.loss_cls: 0.0820  decode.d0.loss_mask: 0.4313  decode.d0.loss_dice: 1.2888  decode.d1.loss_cls: 0.1054  decode.d1.loss_mask: 0.4244  decode.d1.loss_dice: 1.1634  decode.d2.loss_cls: 0.0916  decode.d2.loss_mask: 0.4211  decode.d2.loss_dice: 1.1688  decode.d3.loss_cls: 0.0931  decode.d3.loss_mask: 0.4305  decode.d3.loss_dice: 1.1678  decode.d4.loss_cls: 0.1045  decode.d4.loss_mask: 0.4282  decode.d4.loss_dice: 1.1716  decode.d5.loss_cls: 0.0901  decode.d5.loss_mask: 0.4243  decode.d5.loss_dice: 1.1966  decode.d6.loss_cls: 0.0997  decode.d6.loss_mask: 0.4245  decode.d6.loss_dice: 1.1563  decode.d7.loss_cls: 0.1078  decode.d7.loss_mask: 0.4251  decode.d7.loss_dice: 1.1543  decode.d8.loss_cls: 0.0926  decode.d8.loss_mask: 0.4249  decode.d8.loss_dice: 1.1818
11/15 14:19:08 - mmengine - INFO - Iter(train) [42950/90000]  base_lr: 5.5781e-05 lr: 5.5781e-06  eta: 7:53:44  time: 0.5944  data_time: 0.0103  memory: 10742  grad_norm: 423.8061  loss: 15.9063  decode.loss_cls: 0.0628  decode.loss_mask: 0.4932  decode.loss_dice: 1.0438  decode.d0.loss_cls: 0.0969  decode.d0.loss_mask: 0.4956  decode.d0.loss_dice: 1.0648  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 0.4899  decode.d1.loss_dice: 1.0661  decode.d2.loss_cls: 0.0874  decode.d2.loss_mask: 0.4798  decode.d2.loss_dice: 1.0277  decode.d3.loss_cls: 0.0671  decode.d3.loss_mask: 0.4871  decode.d3.loss_dice: 0.9858  decode.d4.loss_cls: 0.0660  decode.d4.loss_mask: 0.4852  decode.d4.loss_dice: 1.0190  decode.d5.loss_cls: 0.0817  decode.d5.loss_mask: 0.4814  decode.d5.loss_dice: 0.9759  decode.d6.loss_cls: 0.0615  decode.d6.loss_mask: 0.4907  decode.d6.loss_dice: 1.0420  decode.d7.loss_cls: 0.0738  decode.d7.loss_mask: 0.4826  decode.d7.loss_dice: 1.0240  decode.d8.loss_cls: 0.0766  decode.d8.loss_mask: 0.4843  decode.d8.loss_dice: 1.0484
11/15 14:19:38 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 14:19:38 - mmengine - INFO - Iter(train) [43000/90000]  base_lr: 5.5728e-05 lr: 5.5728e-06  eta: 7:53:14  time: 0.5955  data_time: 0.0102  memory: 10656  grad_norm: 404.0506  loss: 16.4762  decode.loss_cls: 0.0678  decode.loss_mask: 0.4963  decode.loss_dice: 1.0935  decode.d0.loss_cls: 0.0971  decode.d0.loss_mask: 0.4798  decode.d0.loss_dice: 1.1406  decode.d1.loss_cls: 0.0659  decode.d1.loss_mask: 0.4847  decode.d1.loss_dice: 1.1338  decode.d2.loss_cls: 0.0625  decode.d2.loss_mask: 0.4714  decode.d2.loss_dice: 1.1188  decode.d3.loss_cls: 0.0696  decode.d3.loss_mask: 0.4647  decode.d3.loss_dice: 1.0488  decode.d4.loss_cls: 0.0734  decode.d4.loss_mask: 0.4667  decode.d4.loss_dice: 1.0825  decode.d5.loss_cls: 0.0708  decode.d5.loss_mask: 0.4589  decode.d5.loss_dice: 1.1077  decode.d6.loss_cls: 0.0758  decode.d6.loss_mask: 0.4605  decode.d6.loss_dice: 1.1053  decode.d7.loss_cls: 0.0723  decode.d7.loss_mask: 0.4636  decode.d7.loss_dice: 1.0681  decode.d8.loss_cls: 0.0747  decode.d8.loss_mask: 0.4875  decode.d8.loss_dice: 1.1132
11/15 14:20:08 - mmengine - INFO - Iter(train) [43050/90000]  base_lr: 5.5675e-05 lr: 5.5675e-06  eta: 7:52:43  time: 0.5952  data_time: 0.0102  memory: 10713  grad_norm: 398.0437  loss: 17.3745  decode.loss_cls: 0.0622  decode.loss_mask: 0.4898  decode.loss_dice: 1.1561  decode.d0.loss_cls: 0.0796  decode.d0.loss_mask: 0.4924  decode.d0.loss_dice: 1.2538  decode.d1.loss_cls: 0.0839  decode.d1.loss_mask: 0.5142  decode.d1.loss_dice: 1.1757  decode.d2.loss_cls: 0.0744  decode.d2.loss_mask: 0.4936  decode.d2.loss_dice: 1.1776  decode.d3.loss_cls: 0.0480  decode.d3.loss_mask: 0.5094  decode.d3.loss_dice: 1.1566  decode.d4.loss_cls: 0.0468  decode.d4.loss_mask: 0.5017  decode.d4.loss_dice: 1.1635  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.4988  decode.d5.loss_dice: 1.1811  decode.d6.loss_cls: 0.0750  decode.d6.loss_mask: 0.4902  decode.d6.loss_dice: 1.1539  decode.d7.loss_cls: 0.0531  decode.d7.loss_mask: 0.5197  decode.d7.loss_dice: 1.1495  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.5076  decode.d8.loss_dice: 1.1472
11/15 14:20:38 - mmengine - INFO - Iter(train) [43100/90000]  base_lr: 5.5621e-05 lr: 5.5621e-06  eta: 7:52:12  time: 0.5956  data_time: 0.0099  memory: 10656  grad_norm: 325.7012  loss: 20.6198  decode.loss_cls: 0.0819  decode.loss_mask: 0.7382  decode.loss_dice: 1.2302  decode.d0.loss_cls: 0.1064  decode.d0.loss_mask: 0.7840  decode.d0.loss_dice: 1.2763  decode.d1.loss_cls: 0.0898  decode.d1.loss_mask: 0.7554  decode.d1.loss_dice: 1.2693  decode.d2.loss_cls: 0.0929  decode.d2.loss_mask: 0.7336  decode.d2.loss_dice: 1.2242  decode.d3.loss_cls: 0.0882  decode.d3.loss_mask: 0.7156  decode.d3.loss_dice: 1.1933  decode.d4.loss_cls: 0.0823  decode.d4.loss_mask: 0.7415  decode.d4.loss_dice: 1.2507  decode.d5.loss_cls: 0.0899  decode.d5.loss_mask: 0.7058  decode.d5.loss_dice: 1.2186  decode.d6.loss_cls: 0.0793  decode.d6.loss_mask: 0.7284  decode.d6.loss_dice: 1.2302  decode.d7.loss_cls: 0.0880  decode.d7.loss_mask: 0.7272  decode.d7.loss_dice: 1.2260  decode.d8.loss_cls: 0.0735  decode.d8.loss_mask: 0.7408  decode.d8.loss_dice: 1.2584
11/15 14:21:08 - mmengine - INFO - Iter(train) [43150/90000]  base_lr: 5.5568e-05 lr: 5.5568e-06  eta: 7:51:42  time: 0.5952  data_time: 0.0100  memory: 10692  grad_norm: 472.3079  loss: 15.6644  decode.loss_cls: 0.0413  decode.loss_mask: 0.4864  decode.loss_dice: 1.0242  decode.d0.loss_cls: 0.0797  decode.d0.loss_mask: 0.4824  decode.d0.loss_dice: 1.0849  decode.d1.loss_cls: 0.0503  decode.d1.loss_mask: 0.4888  decode.d1.loss_dice: 1.0745  decode.d2.loss_cls: 0.0530  decode.d2.loss_mask: 0.4744  decode.d2.loss_dice: 1.0036  decode.d3.loss_cls: 0.0472  decode.d3.loss_mask: 0.4857  decode.d3.loss_dice: 1.0097  decode.d4.loss_cls: 0.0432  decode.d4.loss_mask: 0.4835  decode.d4.loss_dice: 1.0313  decode.d5.loss_cls: 0.0424  decode.d5.loss_mask: 0.4835  decode.d5.loss_dice: 1.0283  decode.d6.loss_cls: 0.0374  decode.d6.loss_mask: 0.4871  decode.d6.loss_dice: 1.0371  decode.d7.loss_cls: 0.0498  decode.d7.loss_mask: 0.4851  decode.d7.loss_dice: 1.0257  decode.d8.loss_cls: 0.0466  decode.d8.loss_mask: 0.4814  decode.d8.loss_dice: 1.0161
11/15 14:21:37 - mmengine - INFO - Iter(train) [43200/90000]  base_lr: 5.5515e-05 lr: 5.5515e-06  eta: 7:51:11  time: 0.5941  data_time: 0.0102  memory: 10713  grad_norm: 319.5682  loss: 18.1241  decode.loss_cls: 0.0738  decode.loss_mask: 0.5052  decode.loss_dice: 1.1946  decode.d0.loss_cls: 0.1024  decode.d0.loss_mask: 0.5247  decode.d0.loss_dice: 1.3428  decode.d1.loss_cls: 0.0806  decode.d1.loss_mask: 0.5072  decode.d1.loss_dice: 1.2232  decode.d2.loss_cls: 0.0825  decode.d2.loss_mask: 0.5035  decode.d2.loss_dice: 1.2121  decode.d3.loss_cls: 0.0674  decode.d3.loss_mask: 0.5131  decode.d3.loss_dice: 1.2639  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.5224  decode.d4.loss_dice: 1.2419  decode.d5.loss_cls: 0.0800  decode.d5.loss_mask: 0.4982  decode.d5.loss_dice: 1.1750  decode.d6.loss_cls: 0.0775  decode.d6.loss_mask: 0.5023  decode.d6.loss_dice: 1.2150  decode.d7.loss_cls: 0.0788  decode.d7.loss_mask: 0.4989  decode.d7.loss_dice: 1.1891  decode.d8.loss_cls: 0.0785  decode.d8.loss_mask: 0.4951  decode.d8.loss_dice: 1.2167
11/15 14:22:07 - mmengine - INFO - Iter(train) [43250/90000]  base_lr: 5.5461e-05 lr: 5.5461e-06  eta: 7:50:41  time: 0.5987  data_time: 0.0104  memory: 10641  grad_norm: 209.1799  loss: 16.4324  decode.loss_cls: 0.0672  decode.loss_mask: 0.4373  decode.loss_dice: 1.1009  decode.d0.loss_cls: 0.0762  decode.d0.loss_mask: 0.4578  decode.d0.loss_dice: 1.1934  decode.d1.loss_cls: 0.0619  decode.d1.loss_mask: 0.4432  decode.d1.loss_dice: 1.1692  decode.d2.loss_cls: 0.0696  decode.d2.loss_mask: 0.4365  decode.d2.loss_dice: 1.1170  decode.d3.loss_cls: 0.0674  decode.d3.loss_mask: 0.4410  decode.d3.loss_dice: 1.1137  decode.d4.loss_cls: 0.0721  decode.d4.loss_mask: 0.4380  decode.d4.loss_dice: 1.1146  decode.d5.loss_cls: 0.0760  decode.d5.loss_mask: 0.4378  decode.d5.loss_dice: 1.1221  decode.d6.loss_cls: 0.0619  decode.d6.loss_mask: 0.4379  decode.d6.loss_dice: 1.1454  decode.d7.loss_cls: 0.0656  decode.d7.loss_mask: 0.4442  decode.d7.loss_dice: 1.1350  decode.d8.loss_cls: 0.0749  decode.d8.loss_mask: 0.4398  decode.d8.loss_dice: 1.1149
11/15 14:22:37 - mmengine - INFO - Iter(train) [43300/90000]  base_lr: 5.5408e-05 lr: 5.5408e-06  eta: 7:50:10  time: 0.5966  data_time: 0.0104  memory: 10656  grad_norm: 446.0711  loss: 18.1759  decode.loss_cls: 0.1138  decode.loss_mask: 0.5025  decode.loss_dice: 1.1481  decode.d0.loss_cls: 0.1384  decode.d0.loss_mask: 0.4927  decode.d0.loss_dice: 1.3477  decode.d1.loss_cls: 0.1449  decode.d1.loss_mask: 0.5167  decode.d1.loss_dice: 1.2420  decode.d2.loss_cls: 0.1245  decode.d2.loss_mask: 0.4945  decode.d2.loss_dice: 1.1806  decode.d3.loss_cls: 0.1142  decode.d3.loss_mask: 0.5096  decode.d3.loss_dice: 1.1561  decode.d4.loss_cls: 0.1240  decode.d4.loss_mask: 0.4811  decode.d4.loss_dice: 1.2043  decode.d5.loss_cls: 0.1074  decode.d5.loss_mask: 0.4813  decode.d5.loss_dice: 1.1872  decode.d6.loss_cls: 0.1254  decode.d6.loss_mask: 0.4726  decode.d6.loss_dice: 1.1845  decode.d7.loss_cls: 0.1169  decode.d7.loss_mask: 0.4924  decode.d7.loss_dice: 1.1946  decode.d8.loss_cls: 0.1199  decode.d8.loss_mask: 0.4871  decode.d8.loss_dice: 1.1711
11/15 14:23:07 - mmengine - INFO - Iter(train) [43350/90000]  base_lr: 5.5354e-05 lr: 5.5354e-06  eta: 7:49:39  time: 0.5953  data_time: 0.0101  memory: 10641  grad_norm: 392.3679  loss: 17.1299  decode.loss_cls: 0.0586  decode.loss_mask: 0.5719  decode.loss_dice: 1.0760  decode.d0.loss_cls: 0.0933  decode.d0.loss_mask: 0.5853  decode.d0.loss_dice: 1.1363  decode.d1.loss_cls: 0.0515  decode.d1.loss_mask: 0.5562  decode.d1.loss_dice: 1.1459  decode.d2.loss_cls: 0.0632  decode.d2.loss_mask: 0.5440  decode.d2.loss_dice: 1.1057  decode.d3.loss_cls: 0.0541  decode.d3.loss_mask: 0.5528  decode.d3.loss_dice: 1.0796  decode.d4.loss_cls: 0.0574  decode.d4.loss_mask: 0.5232  decode.d4.loss_dice: 1.0942  decode.d5.loss_cls: 0.0512  decode.d5.loss_mask: 0.5585  decode.d5.loss_dice: 1.0879  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.5562  decode.d6.loss_dice: 1.0889  decode.d7.loss_cls: 0.0447  decode.d7.loss_mask: 0.5526  decode.d7.loss_dice: 1.1109  decode.d8.loss_cls: 0.0558  decode.d8.loss_mask: 0.5446  decode.d8.loss_dice: 1.0799
11/15 14:23:37 - mmengine - INFO - Iter(train) [43400/90000]  base_lr: 5.5301e-05 lr: 5.5301e-06  eta: 7:49:09  time: 0.5977  data_time: 0.0103  memory: 10692  grad_norm: 452.3663  loss: 17.4840  decode.loss_cls: 0.0842  decode.loss_mask: 0.4932  decode.loss_dice: 1.1483  decode.d0.loss_cls: 0.1112  decode.d0.loss_mask: 0.5106  decode.d0.loss_dice: 1.2334  decode.d1.loss_cls: 0.0927  decode.d1.loss_mask: 0.4755  decode.d1.loss_dice: 1.1790  decode.d2.loss_cls: 0.0812  decode.d2.loss_mask: 0.4795  decode.d2.loss_dice: 1.2066  decode.d3.loss_cls: 0.0859  decode.d3.loss_mask: 0.4833  decode.d3.loss_dice: 1.1634  decode.d4.loss_cls: 0.0873  decode.d4.loss_mask: 0.4863  decode.d4.loss_dice: 1.1453  decode.d5.loss_cls: 0.0722  decode.d5.loss_mask: 0.4908  decode.d5.loss_dice: 1.1708  decode.d6.loss_cls: 0.0792  decode.d6.loss_mask: 0.4978  decode.d6.loss_dice: 1.1835  decode.d7.loss_cls: 0.0839  decode.d7.loss_mask: 0.4860  decode.d7.loss_dice: 1.1805  decode.d8.loss_cls: 0.0797  decode.d8.loss_mask: 0.4797  decode.d8.loss_dice: 1.1330
11/15 14:24:07 - mmengine - INFO - Iter(train) [43450/90000]  base_lr: 5.5248e-05 lr: 5.5248e-06  eta: 7:48:38  time: 0.5960  data_time: 0.0102  memory: 10758  grad_norm: 426.1016  loss: 16.1668  decode.loss_cls: 0.0723  decode.loss_mask: 0.4694  decode.loss_dice: 1.0678  decode.d0.loss_cls: 0.0823  decode.d0.loss_mask: 0.4660  decode.d0.loss_dice: 1.1798  decode.d1.loss_cls: 0.0808  decode.d1.loss_mask: 0.4585  decode.d1.loss_dice: 1.0953  decode.d2.loss_cls: 0.0766  decode.d2.loss_mask: 0.4655  decode.d2.loss_dice: 1.0613  decode.d3.loss_cls: 0.0599  decode.d3.loss_mask: 0.4631  decode.d3.loss_dice: 1.0646  decode.d4.loss_cls: 0.0621  decode.d4.loss_mask: 0.4659  decode.d4.loss_dice: 1.0737  decode.d5.loss_cls: 0.0651  decode.d5.loss_mask: 0.4640  decode.d5.loss_dice: 1.0533  decode.d6.loss_cls: 0.0717  decode.d6.loss_mask: 0.4678  decode.d6.loss_dice: 1.0640  decode.d7.loss_cls: 0.0758  decode.d7.loss_mask: 0.4665  decode.d7.loss_dice: 1.0639  decode.d8.loss_cls: 0.0692  decode.d8.loss_mask: 0.4733  decode.d8.loss_dice: 1.0672
11/15 14:24:37 - mmengine - INFO - Iter(train) [43500/90000]  base_lr: 5.5194e-05 lr: 5.5194e-06  eta: 7:48:08  time: 0.5947  data_time: 0.0101  memory: 10728  grad_norm: 534.4264  loss: 17.0171  decode.loss_cls: 0.0876  decode.loss_mask: 0.5464  decode.loss_dice: 1.0775  decode.d0.loss_cls: 0.0963  decode.d0.loss_mask: 0.5343  decode.d0.loss_dice: 1.1510  decode.d1.loss_cls: 0.0927  decode.d1.loss_mask: 0.5207  decode.d1.loss_dice: 1.1209  decode.d2.loss_cls: 0.0724  decode.d2.loss_mask: 0.5085  decode.d2.loss_dice: 1.1092  decode.d3.loss_cls: 0.0807  decode.d3.loss_mask: 0.5024  decode.d3.loss_dice: 1.0601  decode.d4.loss_cls: 0.0743  decode.d4.loss_mask: 0.5061  decode.d4.loss_dice: 1.1201  decode.d5.loss_cls: 0.0798  decode.d5.loss_mask: 0.5119  decode.d5.loss_dice: 1.0819  decode.d6.loss_cls: 0.0927  decode.d6.loss_mask: 0.5176  decode.d6.loss_dice: 1.0657  decode.d7.loss_cls: 0.0812  decode.d7.loss_mask: 0.5127  decode.d7.loss_dice: 1.0930  decode.d8.loss_cls: 0.0847  decode.d8.loss_mask: 0.5292  decode.d8.loss_dice: 1.1053
11/15 14:25:06 - mmengine - INFO - Iter(train) [43550/90000]  base_lr: 5.5141e-05 lr: 5.5141e-06  eta: 7:47:37  time: 0.5950  data_time: 0.0100  memory: 10641  grad_norm: 305.2190  loss: 17.1187  decode.loss_cls: 0.0411  decode.loss_mask: 0.5898  decode.loss_dice: 1.0498  decode.d0.loss_cls: 0.0781  decode.d0.loss_mask: 0.6279  decode.d0.loss_dice: 1.1102  decode.d1.loss_cls: 0.0498  decode.d1.loss_mask: 0.5966  decode.d1.loss_dice: 1.0787  decode.d2.loss_cls: 0.0438  decode.d2.loss_mask: 0.5996  decode.d2.loss_dice: 1.0606  decode.d3.loss_cls: 0.0401  decode.d3.loss_mask: 0.5953  decode.d3.loss_dice: 1.0708  decode.d4.loss_cls: 0.0425  decode.d4.loss_mask: 0.5961  decode.d4.loss_dice: 1.0640  decode.d5.loss_cls: 0.0386  decode.d5.loss_mask: 0.6087  decode.d5.loss_dice: 1.0716  decode.d6.loss_cls: 0.0423  decode.d6.loss_mask: 0.5925  decode.d6.loss_dice: 1.0485  decode.d7.loss_cls: 0.0431  decode.d7.loss_mask: 0.5907  decode.d7.loss_dice: 1.0537  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.5901  decode.d8.loss_dice: 1.0628
11/15 14:25:36 - mmengine - INFO - Iter(train) [43600/90000]  base_lr: 5.5087e-05 lr: 5.5087e-06  eta: 7:47:06  time: 0.5968  data_time: 0.0104  memory: 10692  grad_norm: 365.2568  loss: 16.3924  decode.loss_cls: 0.0529  decode.loss_mask: 0.5607  decode.loss_dice: 0.9823  decode.d0.loss_cls: 0.0821  decode.d0.loss_mask: 0.6154  decode.d0.loss_dice: 1.0641  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.5704  decode.d1.loss_dice: 1.0298  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.5818  decode.d2.loss_dice: 1.0166  decode.d3.loss_cls: 0.0528  decode.d3.loss_mask: 0.5691  decode.d3.loss_dice: 1.0257  decode.d4.loss_cls: 0.0554  decode.d4.loss_mask: 0.5831  decode.d4.loss_dice: 1.0022  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.5700  decode.d5.loss_dice: 0.9759  decode.d6.loss_cls: 0.0574  decode.d6.loss_mask: 0.5754  decode.d6.loss_dice: 0.9814  decode.d7.loss_cls: 0.0531  decode.d7.loss_mask: 0.5696  decode.d7.loss_dice: 0.9912  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.5601  decode.d8.loss_dice: 0.9738
11/15 14:26:06 - mmengine - INFO - Iter(train) [43650/90000]  base_lr: 5.5034e-05 lr: 5.5034e-06  eta: 7:46:36  time: 0.5950  data_time: 0.0103  memory: 10641  grad_norm: 706.4643  loss: 17.2262  decode.loss_cls: 0.0740  decode.loss_mask: 0.4772  decode.loss_dice: 1.1269  decode.d0.loss_cls: 0.0764  decode.d0.loss_mask: 0.5035  decode.d0.loss_dice: 1.2372  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.4873  decode.d1.loss_dice: 1.1767  decode.d2.loss_cls: 0.0726  decode.d2.loss_mask: 0.4710  decode.d2.loss_dice: 1.1555  decode.d3.loss_cls: 0.0584  decode.d3.loss_mask: 0.4795  decode.d3.loss_dice: 1.1617  decode.d4.loss_cls: 0.0729  decode.d4.loss_mask: 0.4790  decode.d4.loss_dice: 1.1503  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.4781  decode.d5.loss_dice: 1.1797  decode.d6.loss_cls: 0.0802  decode.d6.loss_mask: 0.4848  decode.d6.loss_dice: 1.1267  decode.d7.loss_cls: 0.0720  decode.d7.loss_mask: 0.4896  decode.d7.loss_dice: 1.1493  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 0.4835  decode.d8.loss_dice: 1.1987
11/15 14:26:36 - mmengine - INFO - Iter(train) [43700/90000]  base_lr: 5.4981e-05 lr: 5.4981e-06  eta: 7:46:05  time: 0.5962  data_time: 0.0102  memory: 10675  grad_norm: 290.7494  loss: 17.2245  decode.loss_cls: 0.0814  decode.loss_mask: 0.4527  decode.loss_dice: 1.1756  decode.d0.loss_cls: 0.0931  decode.d0.loss_mask: 0.4645  decode.d0.loss_dice: 1.2590  decode.d1.loss_cls: 0.0773  decode.d1.loss_mask: 0.4525  decode.d1.loss_dice: 1.2032  decode.d2.loss_cls: 0.0865  decode.d2.loss_mask: 0.4457  decode.d2.loss_dice: 1.1763  decode.d3.loss_cls: 0.0746  decode.d3.loss_mask: 0.4469  decode.d3.loss_dice: 1.1667  decode.d4.loss_cls: 0.0751  decode.d4.loss_mask: 0.4428  decode.d4.loss_dice: 1.1703  decode.d5.loss_cls: 0.0856  decode.d5.loss_mask: 0.4516  decode.d5.loss_dice: 1.1893  decode.d6.loss_cls: 0.0912  decode.d6.loss_mask: 0.4485  decode.d6.loss_dice: 1.1670  decode.d7.loss_cls: 0.0777  decode.d7.loss_mask: 0.4556  decode.d7.loss_dice: 1.1904  decode.d8.loss_cls: 0.0898  decode.d8.loss_mask: 0.4555  decode.d8.loss_dice: 1.1781
11/15 14:27:05 - mmengine - INFO - Iter(train) [43750/90000]  base_lr: 5.4927e-05 lr: 5.4927e-06  eta: 7:45:34  time: 0.5952  data_time: 0.0101  memory: 10656  grad_norm: 259.0573  loss: 16.7470  decode.loss_cls: 0.0541  decode.loss_mask: 0.4906  decode.loss_dice: 1.0967  decode.d0.loss_cls: 0.0735  decode.d0.loss_mask: 0.5314  decode.d0.loss_dice: 1.1853  decode.d1.loss_cls: 0.0679  decode.d1.loss_mask: 0.4863  decode.d1.loss_dice: 1.1318  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.5148  decode.d2.loss_dice: 1.1085  decode.d3.loss_cls: 0.0540  decode.d3.loss_mask: 0.4917  decode.d3.loss_dice: 1.0866  decode.d4.loss_cls: 0.0451  decode.d4.loss_mask: 0.5145  decode.d4.loss_dice: 1.1233  decode.d5.loss_cls: 0.0455  decode.d5.loss_mask: 0.5059  decode.d5.loss_dice: 1.1194  decode.d6.loss_cls: 0.0456  decode.d6.loss_mask: 0.5007  decode.d6.loss_dice: 1.1161  decode.d7.loss_cls: 0.0502  decode.d7.loss_mask: 0.4935  decode.d7.loss_dice: 1.1111  decode.d8.loss_cls: 0.0532  decode.d8.loss_mask: 0.4886  decode.d8.loss_dice: 1.1068
11/15 14:27:35 - mmengine - INFO - Iter(train) [43800/90000]  base_lr: 5.4874e-05 lr: 5.4874e-06  eta: 7:45:04  time: 0.5939  data_time: 0.0101  memory: 10675  grad_norm: 496.6338  loss: 16.9415  decode.loss_cls: 0.0462  decode.loss_mask: 0.5594  decode.loss_dice: 1.0642  decode.d0.loss_cls: 0.0781  decode.d0.loss_mask: 0.5792  decode.d0.loss_dice: 1.1662  decode.d1.loss_cls: 0.0590  decode.d1.loss_mask: 0.5757  decode.d1.loss_dice: 1.1041  decode.d2.loss_cls: 0.0697  decode.d2.loss_mask: 0.5642  decode.d2.loss_dice: 1.0608  decode.d3.loss_cls: 0.0574  decode.d3.loss_mask: 0.5662  decode.d3.loss_dice: 1.0704  decode.d4.loss_cls: 0.0678  decode.d4.loss_mask: 0.5517  decode.d4.loss_dice: 1.0463  decode.d5.loss_cls: 0.0577  decode.d5.loss_mask: 0.5517  decode.d5.loss_dice: 1.0448  decode.d6.loss_cls: 0.0564  decode.d6.loss_mask: 0.5531  decode.d6.loss_dice: 1.0696  decode.d7.loss_cls: 0.0576  decode.d7.loss_mask: 0.5557  decode.d7.loss_dice: 1.0482  decode.d8.loss_cls: 0.0577  decode.d8.loss_mask: 0.5562  decode.d8.loss_dice: 1.0463
11/15 14:28:05 - mmengine - INFO - Iter(train) [43850/90000]  base_lr: 5.4820e-05 lr: 5.4820e-06  eta: 7:44:33  time: 0.5976  data_time: 0.0105  memory: 10713  grad_norm: 390.7541  loss: 17.6310  decode.loss_cls: 0.0876  decode.loss_mask: 0.5086  decode.loss_dice: 1.1524  decode.d0.loss_cls: 0.0911  decode.d0.loss_mask: 0.5070  decode.d0.loss_dice: 1.2640  decode.d1.loss_cls: 0.0598  decode.d1.loss_mask: 0.5373  decode.d1.loss_dice: 1.1857  decode.d2.loss_cls: 0.0889  decode.d2.loss_mask: 0.5271  decode.d2.loss_dice: 1.1698  decode.d3.loss_cls: 0.0766  decode.d3.loss_mask: 0.5041  decode.d3.loss_dice: 1.1622  decode.d4.loss_cls: 0.0863  decode.d4.loss_mask: 0.4976  decode.d4.loss_dice: 1.1508  decode.d5.loss_cls: 0.0795  decode.d5.loss_mask: 0.5051  decode.d5.loss_dice: 1.1635  decode.d6.loss_cls: 0.0910  decode.d6.loss_mask: 0.5070  decode.d6.loss_dice: 1.1508  decode.d7.loss_cls: 0.0857  decode.d7.loss_mask: 0.5030  decode.d7.loss_dice: 1.1520  decode.d8.loss_cls: 0.0825  decode.d8.loss_mask: 0.4977  decode.d8.loss_dice: 1.1562
11/15 14:28:35 - mmengine - INFO - Iter(train) [43900/90000]  base_lr: 5.4767e-05 lr: 5.4767e-06  eta: 7:44:03  time: 0.5958  data_time: 0.0103  memory: 10675  grad_norm: 302.8965  loss: 17.7860  decode.loss_cls: 0.0688  decode.loss_mask: 0.4701  decode.loss_dice: 1.2085  decode.d0.loss_cls: 0.0946  decode.d0.loss_mask: 0.4601  decode.d0.loss_dice: 1.2793  decode.d1.loss_cls: 0.0583  decode.d1.loss_mask: 0.4690  decode.d1.loss_dice: 1.2910  decode.d2.loss_cls: 0.0620  decode.d2.loss_mask: 0.4653  decode.d2.loss_dice: 1.2622  decode.d3.loss_cls: 0.0587  decode.d3.loss_mask: 0.4685  decode.d3.loss_dice: 1.2488  decode.d4.loss_cls: 0.0677  decode.d4.loss_mask: 0.4720  decode.d4.loss_dice: 1.2430  decode.d5.loss_cls: 0.0577  decode.d5.loss_mask: 0.4685  decode.d5.loss_dice: 1.2227  decode.d6.loss_cls: 0.0624  decode.d6.loss_mask: 0.4763  decode.d6.loss_dice: 1.2235  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.4719  decode.d7.loss_dice: 1.2136  decode.d8.loss_cls: 0.0667  decode.d8.loss_mask: 0.4751  decode.d8.loss_dice: 1.2358
11/15 14:29:05 - mmengine - INFO - Iter(train) [43950/90000]  base_lr: 5.4713e-05 lr: 5.4713e-06  eta: 7:43:32  time: 0.5967  data_time: 0.0104  memory: 10692  grad_norm: 445.2925  loss: 16.4486  decode.loss_cls: 0.0679  decode.loss_mask: 0.4904  decode.loss_dice: 1.0927  decode.d0.loss_cls: 0.0969  decode.d0.loss_mask: 0.5027  decode.d0.loss_dice: 1.1695  decode.d1.loss_cls: 0.0744  decode.d1.loss_mask: 0.4905  decode.d1.loss_dice: 1.0755  decode.d2.loss_cls: 0.0660  decode.d2.loss_mask: 0.4891  decode.d2.loss_dice: 1.0662  decode.d3.loss_cls: 0.0662  decode.d3.loss_mask: 0.4799  decode.d3.loss_dice: 1.0719  decode.d4.loss_cls: 0.0731  decode.d4.loss_mask: 0.4828  decode.d4.loss_dice: 1.0883  decode.d5.loss_cls: 0.0733  decode.d5.loss_mask: 0.4783  decode.d5.loss_dice: 1.0947  decode.d6.loss_cls: 0.0742  decode.d6.loss_mask: 0.4746  decode.d6.loss_dice: 1.0742  decode.d7.loss_cls: 0.0684  decode.d7.loss_mask: 0.4837  decode.d7.loss_dice: 1.0714  decode.d8.loss_cls: 0.0684  decode.d8.loss_mask: 0.4853  decode.d8.loss_dice: 1.0577
11/15 14:29:35 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 14:29:35 - mmengine - INFO - Iter(train) [44000/90000]  base_lr: 5.4660e-05 lr: 5.4660e-06  eta: 7:43:01  time: 0.5966  data_time: 0.0102  memory: 10675  grad_norm: 693.6686  loss: 17.1745  decode.loss_cls: 0.0519  decode.loss_mask: 0.5592  decode.loss_dice: 1.0565  decode.d0.loss_cls: 0.0950  decode.d0.loss_mask: 0.7176  decode.d0.loss_dice: 1.1693  decode.d1.loss_cls: 0.0476  decode.d1.loss_mask: 0.5911  decode.d1.loss_dice: 1.1356  decode.d2.loss_cls: 0.0600  decode.d2.loss_mask: 0.5847  decode.d2.loss_dice: 1.0700  decode.d3.loss_cls: 0.0468  decode.d3.loss_mask: 0.5651  decode.d3.loss_dice: 1.0519  decode.d4.loss_cls: 0.0477  decode.d4.loss_mask: 0.5487  decode.d4.loss_dice: 1.0666  decode.d5.loss_cls: 0.0467  decode.d5.loss_mask: 0.5542  decode.d5.loss_dice: 1.0653  decode.d6.loss_cls: 0.0544  decode.d6.loss_mask: 0.5610  decode.d6.loss_dice: 1.0466  decode.d7.loss_cls: 0.0539  decode.d7.loss_mask: 0.5761  decode.d7.loss_dice: 1.0628  decode.d8.loss_cls: 0.0550  decode.d8.loss_mask: 0.5631  decode.d8.loss_dice: 1.0703
11/15 14:30:04 - mmengine - INFO - Iter(train) [44050/90000]  base_lr: 5.4606e-05 lr: 5.4606e-06  eta: 7:42:31  time: 0.5941  data_time: 0.0101  memory: 10656  grad_norm: 295.9043  loss: 17.6747  decode.loss_cls: 0.1056  decode.loss_mask: 0.5733  decode.loss_dice: 1.1401  decode.d0.loss_cls: 0.1052  decode.d0.loss_mask: 0.6099  decode.d0.loss_dice: 1.1817  decode.d1.loss_cls: 0.1136  decode.d1.loss_mask: 0.5688  decode.d1.loss_dice: 1.0728  decode.d2.loss_cls: 0.1201  decode.d2.loss_mask: 0.5658  decode.d2.loss_dice: 1.0914  decode.d3.loss_cls: 0.1160  decode.d3.loss_mask: 0.5521  decode.d3.loss_dice: 1.0580  decode.d4.loss_cls: 0.1018  decode.d4.loss_mask: 0.5503  decode.d4.loss_dice: 1.0788  decode.d5.loss_cls: 0.0959  decode.d5.loss_mask: 0.5729  decode.d5.loss_dice: 1.1022  decode.d6.loss_cls: 0.0994  decode.d6.loss_mask: 0.5389  decode.d6.loss_dice: 1.0918  decode.d7.loss_cls: 0.1077  decode.d7.loss_mask: 0.5559  decode.d7.loss_dice: 1.0608  decode.d8.loss_cls: 0.1117  decode.d8.loss_mask: 0.5428  decode.d8.loss_dice: 1.0894
11/15 14:30:34 - mmengine - INFO - Iter(train) [44100/90000]  base_lr: 5.4553e-05 lr: 5.4553e-06  eta: 7:42:00  time: 0.5969  data_time: 0.0104  memory: 10713  grad_norm: 264.8534  loss: 16.5361  decode.loss_cls: 0.0709  decode.loss_mask: 0.5046  decode.loss_dice: 1.0704  decode.d0.loss_cls: 0.0930  decode.d0.loss_mask: 0.5358  decode.d0.loss_dice: 1.1604  decode.d1.loss_cls: 0.0548  decode.d1.loss_mask: 0.5092  decode.d1.loss_dice: 1.1221  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.5057  decode.d2.loss_dice: 1.0553  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 0.5057  decode.d3.loss_dice: 1.0666  decode.d4.loss_cls: 0.0682  decode.d4.loss_mask: 0.5076  decode.d4.loss_dice: 1.0707  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.5118  decode.d5.loss_dice: 1.0637  decode.d6.loss_cls: 0.0708  decode.d6.loss_mask: 0.4949  decode.d6.loss_dice: 1.0321  decode.d7.loss_cls: 0.0686  decode.d7.loss_mask: 0.5040  decode.d7.loss_dice: 1.0583  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.5061  decode.d8.loss_dice: 1.0504
11/15 14:31:04 - mmengine - INFO - Iter(train) [44150/90000]  base_lr: 5.4499e-05 lr: 5.4499e-06  eta: 7:41:30  time: 0.5944  data_time: 0.0102  memory: 10656  grad_norm: 1068.2747  loss: 17.4405  decode.loss_cls: 0.0748  decode.loss_mask: 0.5998  decode.loss_dice: 1.0387  decode.d0.loss_cls: 0.1030  decode.d0.loss_mask: 0.5648  decode.d0.loss_dice: 1.1662  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.5358  decode.d1.loss_dice: 1.1024  decode.d2.loss_cls: 0.0824  decode.d2.loss_mask: 0.5276  decode.d2.loss_dice: 1.0294  decode.d3.loss_cls: 0.0757  decode.d3.loss_mask: 0.5363  decode.d3.loss_dice: 1.0628  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.5371  decode.d4.loss_dice: 1.0416  decode.d5.loss_cls: 0.0782  decode.d5.loss_mask: 0.6013  decode.d5.loss_dice: 1.0732  decode.d6.loss_cls: 0.0904  decode.d6.loss_mask: 0.6915  decode.d6.loss_dice: 1.0485  decode.d7.loss_cls: 0.0834  decode.d7.loss_mask: 0.6419  decode.d7.loss_dice: 1.0921  decode.d8.loss_cls: 0.0774  decode.d8.loss_mask: 0.6354  decode.d8.loss_dice: 1.0902
11/15 14:31:34 - mmengine - INFO - Iter(train) [44200/90000]  base_lr: 5.4446e-05 lr: 5.4446e-06  eta: 7:40:59  time: 0.5954  data_time: 0.0103  memory: 10742  grad_norm: 515.4748  loss: 18.2525  decode.loss_cls: 0.0437  decode.loss_mask: 0.6234  decode.loss_dice: 1.1426  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 0.6596  decode.d0.loss_dice: 1.1623  decode.d1.loss_cls: 0.0492  decode.d1.loss_mask: 0.6516  decode.d1.loss_dice: 1.1666  decode.d2.loss_cls: 0.0456  decode.d2.loss_mask: 0.6585  decode.d2.loss_dice: 1.1323  decode.d3.loss_cls: 0.0449  decode.d3.loss_mask: 0.6246  decode.d3.loss_dice: 1.1536  decode.d4.loss_cls: 0.0453  decode.d4.loss_mask: 0.6210  decode.d4.loss_dice: 1.1505  decode.d5.loss_cls: 0.0472  decode.d5.loss_mask: 0.6145  decode.d5.loss_dice: 1.1502  decode.d6.loss_cls: 0.0463  decode.d6.loss_mask: 0.6208  decode.d6.loss_dice: 1.1246  decode.d7.loss_cls: 0.0477  decode.d7.loss_mask: 0.6146  decode.d7.loss_dice: 1.1266  decode.d8.loss_cls: 0.0464  decode.d8.loss_mask: 0.6537  decode.d8.loss_dice: 1.1206
11/15 14:32:04 - mmengine - INFO - Iter(train) [44250/90000]  base_lr: 5.4392e-05 lr: 5.4392e-06  eta: 7:40:29  time: 0.5965  data_time: 0.0101  memory: 10656  grad_norm: 309.6041  loss: 16.9243  decode.loss_cls: 0.0486  decode.loss_mask: 0.5312  decode.loss_dice: 1.1056  decode.d0.loss_cls: 0.0831  decode.d0.loss_mask: 0.5461  decode.d0.loss_dice: 1.1554  decode.d1.loss_cls: 0.0524  decode.d1.loss_mask: 0.5293  decode.d1.loss_dice: 1.1359  decode.d2.loss_cls: 0.0594  decode.d2.loss_mask: 0.5272  decode.d2.loss_dice: 1.1043  decode.d3.loss_cls: 0.0588  decode.d3.loss_mask: 0.5223  decode.d3.loss_dice: 1.0813  decode.d4.loss_cls: 0.0527  decode.d4.loss_mask: 0.5288  decode.d4.loss_dice: 1.0765  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.5233  decode.d5.loss_dice: 1.0934  decode.d6.loss_cls: 0.0504  decode.d6.loss_mask: 0.5277  decode.d6.loss_dice: 1.0974  decode.d7.loss_cls: 0.0545  decode.d7.loss_mask: 0.5300  decode.d7.loss_dice: 1.1063  decode.d8.loss_cls: 0.0561  decode.d8.loss_mask: 0.5252  decode.d8.loss_dice: 1.1036
11/15 14:32:34 - mmengine - INFO - Iter(train) [44300/90000]  base_lr: 5.4339e-05 lr: 5.4339e-06  eta: 7:39:58  time: 0.5955  data_time: 0.0100  memory: 10713  grad_norm: 730.0524  loss: 18.5818  decode.loss_cls: 0.0662  decode.loss_mask: 0.5861  decode.loss_dice: 1.1425  decode.d0.loss_cls: 0.0853  decode.d0.loss_mask: 0.6200  decode.d0.loss_dice: 1.2860  decode.d1.loss_cls: 0.0702  decode.d1.loss_mask: 0.6022  decode.d1.loss_dice: 1.2058  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.5900  decode.d2.loss_dice: 1.2066  decode.d3.loss_cls: 0.0794  decode.d3.loss_mask: 0.5920  decode.d3.loss_dice: 1.1772  decode.d4.loss_cls: 0.0678  decode.d4.loss_mask: 0.6006  decode.d4.loss_dice: 1.2115  decode.d5.loss_cls: 0.0701  decode.d5.loss_mask: 0.5833  decode.d5.loss_dice: 1.1930  decode.d6.loss_cls: 0.0725  decode.d6.loss_mask: 0.5871  decode.d6.loss_dice: 1.1899  decode.d7.loss_cls: 0.0731  decode.d7.loss_mask: 0.5866  decode.d7.loss_dice: 1.1631  decode.d8.loss_cls: 0.0663  decode.d8.loss_mask: 0.5845  decode.d8.loss_dice: 1.1496
11/15 14:33:03 - mmengine - INFO - Iter(train) [44350/90000]  base_lr: 5.4285e-05 lr: 5.4285e-06  eta: 7:39:27  time: 0.5950  data_time: 0.0100  memory: 10656  grad_norm: 551.2195  loss: 18.3464  decode.loss_cls: 0.0774  decode.loss_mask: 0.5483  decode.loss_dice: 1.1920  decode.d0.loss_cls: 0.0786  decode.d0.loss_mask: 0.5535  decode.d0.loss_dice: 1.2790  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.5570  decode.d1.loss_dice: 1.2425  decode.d2.loss_cls: 0.0773  decode.d2.loss_mask: 0.5601  decode.d2.loss_dice: 1.2220  decode.d3.loss_cls: 0.0696  decode.d3.loss_mask: 0.5549  decode.d3.loss_dice: 1.1991  decode.d4.loss_cls: 0.0800  decode.d4.loss_mask: 0.5532  decode.d4.loss_dice: 1.2159  decode.d5.loss_cls: 0.0633  decode.d5.loss_mask: 0.5366  decode.d5.loss_dice: 1.1805  decode.d6.loss_cls: 0.0705  decode.d6.loss_mask: 0.5467  decode.d6.loss_dice: 1.2142  decode.d7.loss_cls: 0.0882  decode.d7.loss_mask: 0.5455  decode.d7.loss_dice: 1.1786  decode.d8.loss_cls: 0.0828  decode.d8.loss_mask: 0.5413  decode.d8.loss_dice: 1.1749
11/15 14:33:33 - mmengine - INFO - Iter(train) [44400/90000]  base_lr: 5.4232e-05 lr: 5.4232e-06  eta: 7:38:57  time: 0.5952  data_time: 0.0104  memory: 10728  grad_norm: 353.0942  loss: 16.0056  decode.loss_cls: 0.0582  decode.loss_mask: 0.5067  decode.loss_dice: 0.9983  decode.d0.loss_cls: 0.0936  decode.d0.loss_mask: 0.5313  decode.d0.loss_dice: 1.0954  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.5229  decode.d1.loss_dice: 1.0554  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 0.5167  decode.d2.loss_dice: 1.0258  decode.d3.loss_cls: 0.0617  decode.d3.loss_mask: 0.5094  decode.d3.loss_dice: 1.0189  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.5093  decode.d4.loss_dice: 1.0216  decode.d5.loss_cls: 0.0650  decode.d5.loss_mask: 0.5009  decode.d5.loss_dice: 1.0032  decode.d6.loss_cls: 0.0603  decode.d6.loss_mask: 0.5099  decode.d6.loss_dice: 1.0022  decode.d7.loss_cls: 0.0767  decode.d7.loss_mask: 0.5118  decode.d7.loss_dice: 0.9931  decode.d8.loss_cls: 0.0538  decode.d8.loss_mask: 0.5016  decode.d8.loss_dice: 1.0110
11/15 14:34:03 - mmengine - INFO - Iter(train) [44450/90000]  base_lr: 5.4178e-05 lr: 5.4178e-06  eta: 7:38:26  time: 0.5985  data_time: 0.0102  memory: 10692  grad_norm: 486.3754  loss: 18.8792  decode.loss_cls: 0.0660  decode.loss_mask: 0.6448  decode.loss_dice: 1.1721  decode.d0.loss_cls: 0.0748  decode.d0.loss_mask: 0.6671  decode.d0.loss_dice: 1.2624  decode.d1.loss_cls: 0.0756  decode.d1.loss_mask: 0.6332  decode.d1.loss_dice: 1.2077  decode.d2.loss_cls: 0.0762  decode.d2.loss_mask: 0.6182  decode.d2.loss_dice: 1.1745  decode.d3.loss_cls: 0.0780  decode.d3.loss_mask: 0.6149  decode.d3.loss_dice: 1.1714  decode.d4.loss_cls: 0.0714  decode.d4.loss_mask: 0.6206  decode.d4.loss_dice: 1.1873  decode.d5.loss_cls: 0.0800  decode.d5.loss_mask: 0.6216  decode.d5.loss_dice: 1.1831  decode.d6.loss_cls: 0.0827  decode.d6.loss_mask: 0.6134  decode.d6.loss_dice: 1.1288  decode.d7.loss_cls: 0.0645  decode.d7.loss_mask: 0.6331  decode.d7.loss_dice: 1.1858  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.6429  decode.d8.loss_dice: 1.1677
11/15 14:34:33 - mmengine - INFO - Iter(train) [44500/90000]  base_lr: 5.4125e-05 lr: 5.4125e-06  eta: 7:37:56  time: 0.5965  data_time: 0.0102  memory: 10692  grad_norm: 301.1801  loss: 15.9230  decode.loss_cls: 0.0486  decode.loss_mask: 0.4942  decode.loss_dice: 1.0154  decode.d0.loss_cls: 0.0784  decode.d0.loss_mask: 0.5125  decode.d0.loss_dice: 1.0870  decode.d1.loss_cls: 0.0604  decode.d1.loss_mask: 0.5006  decode.d1.loss_dice: 1.0824  decode.d2.loss_cls: 0.0546  decode.d2.loss_mask: 0.4865  decode.d2.loss_dice: 0.9988  decode.d3.loss_cls: 0.0521  decode.d3.loss_mask: 0.4943  decode.d3.loss_dice: 1.0193  decode.d4.loss_cls: 0.0554  decode.d4.loss_mask: 0.4890  decode.d4.loss_dice: 1.0318  decode.d5.loss_cls: 0.0531  decode.d5.loss_mask: 0.4932  decode.d5.loss_dice: 1.0517  decode.d6.loss_cls: 0.0512  decode.d6.loss_mask: 0.4982  decode.d6.loss_dice: 1.0445  decode.d7.loss_cls: 0.0525  decode.d7.loss_mask: 0.4941  decode.d7.loss_dice: 1.0323  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.4947  decode.d8.loss_dice: 1.0448
11/15 14:35:03 - mmengine - INFO - Iter(train) [44550/90000]  base_lr: 5.4071e-05 lr: 5.4071e-06  eta: 7:37:25  time: 0.5949  data_time: 0.0101  memory: 10656  grad_norm: 368.2833  loss: 16.0217  decode.loss_cls: 0.0457  decode.loss_mask: 0.5329  decode.loss_dice: 1.0090  decode.d0.loss_cls: 0.0940  decode.d0.loss_mask: 0.5521  decode.d0.loss_dice: 1.0337  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.5451  decode.d1.loss_dice: 1.0374  decode.d2.loss_cls: 0.0449  decode.d2.loss_mask: 0.5454  decode.d2.loss_dice: 0.9957  decode.d3.loss_cls: 0.0428  decode.d3.loss_mask: 0.5614  decode.d3.loss_dice: 0.9841  decode.d4.loss_cls: 0.0545  decode.d4.loss_mask: 0.5501  decode.d4.loss_dice: 0.9960  decode.d5.loss_cls: 0.0370  decode.d5.loss_mask: 0.5471  decode.d5.loss_dice: 1.0211  decode.d6.loss_cls: 0.0477  decode.d6.loss_mask: 0.5273  decode.d6.loss_dice: 0.9784  decode.d7.loss_cls: 0.0474  decode.d7.loss_mask: 0.5452  decode.d7.loss_dice: 0.9884  decode.d8.loss_cls: 0.0501  decode.d8.loss_mask: 0.5371  decode.d8.loss_dice: 1.0060
11/15 14:35:33 - mmengine - INFO - Iter(train) [44600/90000]  base_lr: 5.4018e-05 lr: 5.4018e-06  eta: 7:36:55  time: 0.5965  data_time: 0.0103  memory: 10656  grad_norm: 272.9920  loss: 17.8522  decode.loss_cls: 0.0633  decode.loss_mask: 0.5004  decode.loss_dice: 1.2048  decode.d0.loss_cls: 0.0909  decode.d0.loss_mask: 0.4983  decode.d0.loss_dice: 1.2666  decode.d1.loss_cls: 0.0658  decode.d1.loss_mask: 0.4948  decode.d1.loss_dice: 1.2253  decode.d2.loss_cls: 0.0853  decode.d2.loss_mask: 0.5090  decode.d2.loss_dice: 1.1898  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.5251  decode.d3.loss_dice: 1.1940  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.5219  decode.d4.loss_dice: 1.2177  decode.d5.loss_cls: 0.0686  decode.d5.loss_mask: 0.5097  decode.d5.loss_dice: 1.1855  decode.d6.loss_cls: 0.0715  decode.d6.loss_mask: 0.5140  decode.d6.loss_dice: 1.1818  decode.d7.loss_cls: 0.0828  decode.d7.loss_mask: 0.5098  decode.d7.loss_dice: 1.2103  decode.d8.loss_cls: 0.0726  decode.d8.loss_mask: 0.4981  decode.d8.loss_dice: 1.1697
11/15 14:36:03 - mmengine - INFO - Iter(train) [44650/90000]  base_lr: 5.3964e-05 lr: 5.3964e-06  eta: 7:36:24  time: 0.5967  data_time: 0.0103  memory: 10656  grad_norm: 474.3619  loss: 17.5006  decode.loss_cls: 0.0834  decode.loss_mask: 0.4757  decode.loss_dice: 1.1896  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 0.4894  decode.d0.loss_dice: 1.2431  decode.d1.loss_cls: 0.1033  decode.d1.loss_mask: 0.4746  decode.d1.loss_dice: 1.2119  decode.d2.loss_cls: 0.0881  decode.d2.loss_mask: 0.4655  decode.d2.loss_dice: 1.1820  decode.d3.loss_cls: 0.0706  decode.d3.loss_mask: 0.4630  decode.d3.loss_dice: 1.1966  decode.d4.loss_cls: 0.0719  decode.d4.loss_mask: 0.4725  decode.d4.loss_dice: 1.1974  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 0.4851  decode.d5.loss_dice: 1.1908  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.4807  decode.d6.loss_dice: 1.1959  decode.d7.loss_cls: 0.0663  decode.d7.loss_mask: 0.4647  decode.d7.loss_dice: 1.1950  decode.d8.loss_cls: 0.0743  decode.d8.loss_mask: 0.4622  decode.d8.loss_dice: 1.1771
11/15 14:36:32 - mmengine - INFO - Iter(train) [44700/90000]  base_lr: 5.3911e-05 lr: 5.3911e-06  eta: 7:35:54  time: 0.5980  data_time: 0.0103  memory: 10675  grad_norm: 716.8940  loss: 16.5293  decode.loss_cls: 0.0806  decode.loss_mask: 0.4522  decode.loss_dice: 1.0948  decode.d0.loss_cls: 0.1108  decode.d0.loss_mask: 0.4689  decode.d0.loss_dice: 1.2158  decode.d1.loss_cls: 0.0770  decode.d1.loss_mask: 0.4598  decode.d1.loss_dice: 1.1534  decode.d2.loss_cls: 0.0846  decode.d2.loss_mask: 0.4586  decode.d2.loss_dice: 1.1163  decode.d3.loss_cls: 0.0797  decode.d3.loss_mask: 0.4492  decode.d3.loss_dice: 1.0736  decode.d4.loss_cls: 0.0864  decode.d4.loss_mask: 0.4540  decode.d4.loss_dice: 1.0830  decode.d5.loss_cls: 0.0834  decode.d5.loss_mask: 0.4526  decode.d5.loss_dice: 1.1074  decode.d6.loss_cls: 0.0724  decode.d6.loss_mask: 0.4475  decode.d6.loss_dice: 1.1033  decode.d7.loss_cls: 0.0767  decode.d7.loss_mask: 0.4439  decode.d7.loss_dice: 1.0840  decode.d8.loss_cls: 0.0769  decode.d8.loss_mask: 0.4508  decode.d8.loss_dice: 1.1315
11/15 14:37:02 - mmengine - INFO - Iter(train) [44750/90000]  base_lr: 5.3857e-05 lr: 5.3857e-06  eta: 7:35:23  time: 0.5966  data_time: 0.0100  memory: 10728  grad_norm: 217.6592  loss: 17.4164  decode.loss_cls: 0.0724  decode.loss_mask: 0.4817  decode.loss_dice: 1.1421  decode.d0.loss_cls: 0.0996  decode.d0.loss_mask: 0.5242  decode.d0.loss_dice: 1.2302  decode.d1.loss_cls: 0.0825  decode.d1.loss_mask: 0.4973  decode.d1.loss_dice: 1.1860  decode.d2.loss_cls: 0.0792  decode.d2.loss_mask: 0.4904  decode.d2.loss_dice: 1.1792  decode.d3.loss_cls: 0.0851  decode.d3.loss_mask: 0.4982  decode.d3.loss_dice: 1.1569  decode.d4.loss_cls: 0.0845  decode.d4.loss_mask: 0.4972  decode.d4.loss_dice: 1.1376  decode.d5.loss_cls: 0.0724  decode.d5.loss_mask: 0.5021  decode.d5.loss_dice: 1.1818  decode.d6.loss_cls: 0.0843  decode.d6.loss_mask: 0.4985  decode.d6.loss_dice: 1.1451  decode.d7.loss_cls: 0.0823  decode.d7.loss_mask: 0.4836  decode.d7.loss_dice: 1.1402  decode.d8.loss_cls: 0.0790  decode.d8.loss_mask: 0.4762  decode.d8.loss_dice: 1.1467
11/15 14:37:32 - mmengine - INFO - Iter(train) [44800/90000]  base_lr: 5.3804e-05 lr: 5.3804e-06  eta: 7:34:52  time: 0.5966  data_time: 0.0105  memory: 10692  grad_norm: 794.6824  loss: 17.4945  decode.loss_cls: 0.0832  decode.loss_mask: 0.5265  decode.loss_dice: 1.1167  decode.d0.loss_cls: 0.1091  decode.d0.loss_mask: 0.5391  decode.d0.loss_dice: 1.1810  decode.d1.loss_cls: 0.1184  decode.d1.loss_mask: 0.5035  decode.d1.loss_dice: 1.1712  decode.d2.loss_cls: 0.0990  decode.d2.loss_mask: 0.5043  decode.d2.loss_dice: 1.1270  decode.d3.loss_cls: 0.0950  decode.d3.loss_mask: 0.5063  decode.d3.loss_dice: 1.1364  decode.d4.loss_cls: 0.0869  decode.d4.loss_mask: 0.5190  decode.d4.loss_dice: 1.1491  decode.d5.loss_cls: 0.0873  decode.d5.loss_mask: 0.5075  decode.d5.loss_dice: 1.1446  decode.d6.loss_cls: 0.0754  decode.d6.loss_mask: 0.5198  decode.d6.loss_dice: 1.1278  decode.d7.loss_cls: 0.0883  decode.d7.loss_mask: 0.5251  decode.d7.loss_dice: 1.1210  decode.d8.loss_cls: 0.0836  decode.d8.loss_mask: 0.5294  decode.d8.loss_dice: 1.1132
11/15 14:38:02 - mmengine - INFO - Iter(train) [44850/90000]  base_lr: 5.3750e-05 lr: 5.3750e-06  eta: 7:34:22  time: 0.5969  data_time: 0.0104  memory: 10692  grad_norm: 334.6340  loss: 18.6416  decode.loss_cls: 0.0593  decode.loss_mask: 0.5165  decode.loss_dice: 1.2524  decode.d0.loss_cls: 0.0772  decode.d0.loss_mask: 0.5495  decode.d0.loss_dice: 1.3459  decode.d1.loss_cls: 0.0526  decode.d1.loss_mask: 0.5281  decode.d1.loss_dice: 1.3134  decode.d2.loss_cls: 0.0571  decode.d2.loss_mask: 0.5215  decode.d2.loss_dice: 1.2768  decode.d3.loss_cls: 0.0582  decode.d3.loss_mask: 0.5207  decode.d3.loss_dice: 1.2646  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.5216  decode.d4.loss_dice: 1.2595  decode.d5.loss_cls: 0.0520  decode.d5.loss_mask: 0.5188  decode.d5.loss_dice: 1.2981  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.5187  decode.d6.loss_dice: 1.2724  decode.d7.loss_cls: 0.0643  decode.d7.loss_mask: 0.5193  decode.d7.loss_dice: 1.2687  decode.d8.loss_cls: 0.0549  decode.d8.loss_mask: 0.5158  decode.d8.loss_dice: 1.2670
11/15 14:38:32 - mmengine - INFO - Iter(train) [44900/90000]  base_lr: 5.3696e-05 lr: 5.3696e-06  eta: 7:33:52  time: 0.5982  data_time: 0.0103  memory: 10692  grad_norm: 383.4636  loss: 16.9699  decode.loss_cls: 0.0648  decode.loss_mask: 0.5449  decode.loss_dice: 1.0826  decode.d0.loss_cls: 0.0886  decode.d0.loss_mask: 0.5935  decode.d0.loss_dice: 1.1423  decode.d1.loss_cls: 0.0929  decode.d1.loss_mask: 0.5531  decode.d1.loss_dice: 1.1014  decode.d2.loss_cls: 0.0648  decode.d2.loss_mask: 0.5479  decode.d2.loss_dice: 1.0850  decode.d3.loss_cls: 0.0745  decode.d3.loss_mask: 0.5454  decode.d3.loss_dice: 1.0525  decode.d4.loss_cls: 0.0678  decode.d4.loss_mask: 0.5308  decode.d4.loss_dice: 1.0636  decode.d5.loss_cls: 0.0669  decode.d5.loss_mask: 0.5442  decode.d5.loss_dice: 1.0389  decode.d6.loss_cls: 0.0683  decode.d6.loss_mask: 0.5480  decode.d6.loss_dice: 1.0542  decode.d7.loss_cls: 0.0685  decode.d7.loss_mask: 0.5481  decode.d7.loss_dice: 1.0561  decode.d8.loss_cls: 0.0768  decode.d8.loss_mask: 0.5431  decode.d8.loss_dice: 1.0602
11/15 14:39:02 - mmengine - INFO - Iter(train) [44950/90000]  base_lr: 5.3643e-05 lr: 5.3643e-06  eta: 7:33:21  time: 0.5943  data_time: 0.0099  memory: 10675  grad_norm: 597.5022  loss: 17.7999  decode.loss_cls: 0.0566  decode.loss_mask: 0.6478  decode.loss_dice: 1.0496  decode.d0.loss_cls: 0.0803  decode.d0.loss_mask: 0.6749  decode.d0.loss_dice: 1.1316  decode.d1.loss_cls: 0.0559  decode.d1.loss_mask: 0.6589  decode.d1.loss_dice: 1.0766  decode.d2.loss_cls: 0.0564  decode.d2.loss_mask: 0.6733  decode.d2.loss_dice: 1.0725  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.6727  decode.d3.loss_dice: 1.0534  decode.d4.loss_cls: 0.0668  decode.d4.loss_mask: 0.6448  decode.d4.loss_dice: 1.0261  decode.d5.loss_cls: 0.0569  decode.d5.loss_mask: 0.6589  decode.d5.loss_dice: 1.0229  decode.d6.loss_cls: 0.0562  decode.d6.loss_mask: 0.6559  decode.d6.loss_dice: 1.0265  decode.d7.loss_cls: 0.0559  decode.d7.loss_mask: 0.6738  decode.d7.loss_dice: 1.0692  decode.d8.loss_cls: 0.0560  decode.d8.loss_mask: 0.6608  decode.d8.loss_dice: 1.0464
11/15 14:39:32 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 14:39:32 - mmengine - INFO - Iter(train) [45000/90000]  base_lr: 5.3589e-05 lr: 5.3589e-06  eta: 7:32:50  time: 0.5963  data_time: 0.0102  memory: 10675  grad_norm: 229.2769  loss: 15.9953  decode.loss_cls: 0.0605  decode.loss_mask: 0.4410  decode.loss_dice: 1.0732  decode.d0.loss_cls: 0.0770  decode.d0.loss_mask: 0.4707  decode.d0.loss_dice: 1.1617  decode.d1.loss_cls: 0.0569  decode.d1.loss_mask: 0.4470  decode.d1.loss_dice: 1.1034  decode.d2.loss_cls: 0.0723  decode.d2.loss_mask: 0.4433  decode.d2.loss_dice: 1.0894  decode.d3.loss_cls: 0.0510  decode.d3.loss_mask: 0.4491  decode.d3.loss_dice: 1.0955  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.4384  decode.d4.loss_dice: 1.0696  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.4456  decode.d5.loss_dice: 1.0760  decode.d6.loss_cls: 0.0619  decode.d6.loss_mask: 0.4432  decode.d6.loss_dice: 1.0853  decode.d7.loss_cls: 0.0531  decode.d7.loss_mask: 0.4342  decode.d7.loss_dice: 1.0825  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.4310  decode.d8.loss_dice: 1.0942
11/15 14:39:32 - mmengine - INFO - Saving checkpoint at 45000 iterations
11/15 14:39:51 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:21  time: 0.3083  data_time: 0.0039  memory: 4095  
11/15 14:40:06 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:04  time: 0.3083  data_time: 0.0039  memory: 4095  
11/15 14:40:22 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:48  time: 0.3091  data_time: 0.0044  memory: 4095  
11/15 14:40:37 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3085  data_time: 0.0040  memory: 4095  
11/15 14:40:53 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3093  data_time: 0.0041  memory: 4095  
11/15 14:41:08 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:01  time: 0.3098  data_time: 0.0041  memory: 4095  
11/15 14:41:24 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3091  data_time: 0.0039  memory: 4095  
11/15 14:41:39 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:30  time: 0.3090  data_time: 0.0038  memory: 4095  
11/15 14:41:55 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3084  data_time: 0.0037  memory: 4095  
11/15 14:42:10 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3090  data_time: 0.0037  memory: 4095  
11/15 14:42:10 - mmengine - INFO - per class results:
11/15 14:42:10 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 98.17 | 98.67 |
|    sidewalk   | 85.43 | 93.31 |
|    building   | 92.85 | 96.56 |
|      wall     | 59.24 | 80.59 |
|     fence     | 58.81 | 67.41 |
|      pole     | 66.79 | 80.71 |
| traffic light | 70.26 | 79.06 |
|  traffic sign | 80.75 | 88.17 |
|   vegetation  | 92.23 | 96.01 |
|    terrain    | 62.28 | 77.47 |
|      sky      | 94.54 | 96.61 |
|     person    | 81.37 | 89.65 |
|     rider     | 60.37 | 85.14 |
|      car      | 95.23 | 97.73 |
|     truck     | 83.72 | 92.31 |
|      bus      | 79.75 |  89.9 |
|     train     | 52.69 | 68.97 |
|   motorcycle  | 56.16 | 87.27 |
|    bicycle    | 76.17 |  84.3 |
+---------------+-------+-------+
11/15 14:42:10 - mmengine - INFO - Iter(val) [500/500]    aAcc: 96.0400  mIoU: 76.1500  mAcc: 86.8300  data_time: 0.0044  time: 0.3095
11/15 14:42:10 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024/best_mIoU_iter_35000.pth is removed
11/15 14:42:12 - mmengine - INFO - The best checkpoint with 76.1500 mIoU at 45000 iter is saved to best_mIoU_iter_45000.pth.
11/15 14:42:45 - mmengine - INFO - Iter(train) [45050/90000]  base_lr: 5.3536e-05 lr: 5.3536e-06  eta: 7:32:25  time: 0.5974  data_time: 0.0104  memory: 10692  grad_norm: 308.2741  loss: 16.4523  decode.loss_cls: 0.0429  decode.loss_mask: 0.5388  decode.loss_dice: 1.0277  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.5654  decode.d0.loss_dice: 1.0919  decode.d1.loss_cls: 0.0469  decode.d1.loss_mask: 0.5358  decode.d1.loss_dice: 1.0731  decode.d2.loss_cls: 0.0391  decode.d2.loss_mask: 0.5429  decode.d2.loss_dice: 1.0526  decode.d3.loss_cls: 0.0354  decode.d3.loss_mask: 0.5363  decode.d3.loss_dice: 1.0559  decode.d4.loss_cls: 0.0475  decode.d4.loss_mask: 0.5367  decode.d4.loss_dice: 1.0498  decode.d5.loss_cls: 0.0424  decode.d5.loss_mask: 0.5352  decode.d5.loss_dice: 1.0485  decode.d6.loss_cls: 0.0416  decode.d6.loss_mask: 0.5459  decode.d6.loss_dice: 1.0643  decode.d7.loss_cls: 0.0404  decode.d7.loss_mask: 0.5443  decode.d7.loss_dice: 1.0727  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.5456  decode.d8.loss_dice: 1.0399
11/15 14:43:16 - mmengine - INFO - Iter(train) [45100/90000]  base_lr: 5.3482e-05 lr: 5.3482e-06  eta: 7:31:55  time: 0.5985  data_time: 0.0105  memory: 10713  grad_norm: 264.2089  loss: 18.1352  decode.loss_cls: 0.0867  decode.loss_mask: 0.4954  decode.loss_dice: 1.2205  decode.d0.loss_cls: 0.1012  decode.d0.loss_mask: 0.5157  decode.d0.loss_dice: 1.3269  decode.d1.loss_cls: 0.1169  decode.d1.loss_mask: 0.4908  decode.d1.loss_dice: 1.2294  decode.d2.loss_cls: 0.0892  decode.d2.loss_mask: 0.4955  decode.d2.loss_dice: 1.2473  decode.d3.loss_cls: 0.0744  decode.d3.loss_mask: 0.4838  decode.d3.loss_dice: 1.2137  decode.d4.loss_cls: 0.0915  decode.d4.loss_mask: 0.4844  decode.d4.loss_dice: 1.2179  decode.d5.loss_cls: 0.0844  decode.d5.loss_mask: 0.4841  decode.d5.loss_dice: 1.2215  decode.d6.loss_cls: 0.0852  decode.d6.loss_mask: 0.4889  decode.d6.loss_dice: 1.2118  decode.d7.loss_cls: 0.0890  decode.d7.loss_mask: 0.4909  decode.d7.loss_dice: 1.2086  decode.d8.loss_cls: 0.0932  decode.d8.loss_mask: 0.4963  decode.d8.loss_dice: 1.2001
11/15 14:43:45 - mmengine - INFO - Iter(train) [45150/90000]  base_lr: 5.3428e-05 lr: 5.3428e-06  eta: 7:31:25  time: 0.5969  data_time: 0.0105  memory: 10692  grad_norm: 610.4165  loss: 15.6490  decode.loss_cls: 0.0468  decode.loss_mask: 0.4395  decode.loss_dice: 1.0663  decode.d0.loss_cls: 0.0744  decode.d0.loss_mask: 0.4340  decode.d0.loss_dice: 1.1404  decode.d1.loss_cls: 0.0631  decode.d1.loss_mask: 0.4340  decode.d1.loss_dice: 1.0879  decode.d2.loss_cls: 0.0574  decode.d2.loss_mask: 0.4379  decode.d2.loss_dice: 1.0714  decode.d3.loss_cls: 0.0518  decode.d3.loss_mask: 0.4401  decode.d3.loss_dice: 1.0541  decode.d4.loss_cls: 0.0530  decode.d4.loss_mask: 0.4403  decode.d4.loss_dice: 1.0628  decode.d5.loss_cls: 0.0572  decode.d5.loss_mask: 0.4373  decode.d5.loss_dice: 1.0571  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.4374  decode.d6.loss_dice: 1.0563  decode.d7.loss_cls: 0.0655  decode.d7.loss_mask: 0.4285  decode.d7.loss_dice: 1.0514  decode.d8.loss_cls: 0.0526  decode.d8.loss_mask: 0.4373  decode.d8.loss_dice: 1.0506
11/15 14:44:15 - mmengine - INFO - Iter(train) [45200/90000]  base_lr: 5.3375e-05 lr: 5.3375e-06  eta: 7:30:54  time: 0.5978  data_time: 0.0104  memory: 10675  grad_norm: 244.8324  loss: 17.0555  decode.loss_cls: 0.0779  decode.loss_mask: 0.5309  decode.loss_dice: 1.0674  decode.d0.loss_cls: 0.0887  decode.d0.loss_mask: 0.5828  decode.d0.loss_dice: 1.1355  decode.d1.loss_cls: 0.0740  decode.d1.loss_mask: 0.5572  decode.d1.loss_dice: 1.0955  decode.d2.loss_cls: 0.0698  decode.d2.loss_mask: 0.5431  decode.d2.loss_dice: 1.0980  decode.d3.loss_cls: 0.0688  decode.d3.loss_mask: 0.5403  decode.d3.loss_dice: 1.0828  decode.d4.loss_cls: 0.0695  decode.d4.loss_mask: 0.5336  decode.d4.loss_dice: 1.0845  decode.d5.loss_cls: 0.0696  decode.d5.loss_mask: 0.5325  decode.d5.loss_dice: 1.0905  decode.d6.loss_cls: 0.0710  decode.d6.loss_mask: 0.5378  decode.d6.loss_dice: 1.0720  decode.d7.loss_cls: 0.0822  decode.d7.loss_mask: 0.5382  decode.d7.loss_dice: 1.0648  decode.d8.loss_cls: 0.0796  decode.d8.loss_mask: 0.5419  decode.d8.loss_dice: 1.0751
11/15 14:44:45 - mmengine - INFO - Iter(train) [45250/90000]  base_lr: 5.3321e-05 lr: 5.3321e-06  eta: 7:30:24  time: 0.5982  data_time: 0.0106  memory: 10692  grad_norm: 200.4929  loss: 16.4971  decode.loss_cls: 0.0668  decode.loss_mask: 0.4042  decode.loss_dice: 1.1805  decode.d0.loss_cls: 0.0750  decode.d0.loss_mask: 0.3983  decode.d0.loss_dice: 1.2662  decode.d1.loss_cls: 0.0649  decode.d1.loss_mask: 0.4016  decode.d1.loss_dice: 1.1570  decode.d2.loss_cls: 0.0743  decode.d2.loss_mask: 0.4003  decode.d2.loss_dice: 1.1500  decode.d3.loss_cls: 0.0719  decode.d3.loss_mask: 0.3947  decode.d3.loss_dice: 1.1859  decode.d4.loss_cls: 0.0682  decode.d4.loss_mask: 0.4026  decode.d4.loss_dice: 1.1602  decode.d5.loss_cls: 0.0705  decode.d5.loss_mask: 0.4047  decode.d5.loss_dice: 1.1703  decode.d6.loss_cls: 0.0681  decode.d6.loss_mask: 0.4030  decode.d6.loss_dice: 1.1687  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.4068  decode.d7.loss_dice: 1.1651  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 0.4099  decode.d8.loss_dice: 1.1654
11/15 14:45:15 - mmengine - INFO - Iter(train) [45300/90000]  base_lr: 5.3268e-05 lr: 5.3268e-06  eta: 7:29:53  time: 0.5969  data_time: 0.0105  memory: 10692  grad_norm: 332.7264  loss: 16.4743  decode.loss_cls: 0.0437  decode.loss_mask: 0.4663  decode.loss_dice: 1.1239  decode.d0.loss_cls: 0.0733  decode.d0.loss_mask: 0.4906  decode.d0.loss_dice: 1.1796  decode.d1.loss_cls: 0.0749  decode.d1.loss_mask: 0.4774  decode.d1.loss_dice: 1.1415  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.4730  decode.d2.loss_dice: 1.1109  decode.d3.loss_cls: 0.0562  decode.d3.loss_mask: 0.4683  decode.d3.loss_dice: 1.1048  decode.d4.loss_cls: 0.0632  decode.d4.loss_mask: 0.4668  decode.d4.loss_dice: 1.0988  decode.d5.loss_cls: 0.0500  decode.d5.loss_mask: 0.4676  decode.d5.loss_dice: 1.1076  decode.d6.loss_cls: 0.0466  decode.d6.loss_mask: 0.4720  decode.d6.loss_dice: 1.1127  decode.d7.loss_cls: 0.0447  decode.d7.loss_mask: 0.4656  decode.d7.loss_dice: 1.1090  decode.d8.loss_cls: 0.0526  decode.d8.loss_mask: 0.4695  decode.d8.loss_dice: 1.1014
11/15 14:45:45 - mmengine - INFO - Iter(train) [45350/90000]  base_lr: 5.3214e-05 lr: 5.3214e-06  eta: 7:29:23  time: 0.5969  data_time: 0.0109  memory: 10692  grad_norm: 345.0708  loss: 15.8804  decode.loss_cls: 0.0794  decode.loss_mask: 0.4678  decode.loss_dice: 1.0133  decode.d0.loss_cls: 0.1038  decode.d0.loss_mask: 0.4899  decode.d0.loss_dice: 1.0935  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.4674  decode.d1.loss_dice: 1.0727  decode.d2.loss_cls: 0.0853  decode.d2.loss_mask: 0.4674  decode.d2.loss_dice: 1.0460  decode.d3.loss_cls: 0.0718  decode.d3.loss_mask: 0.4727  decode.d3.loss_dice: 1.0335  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 0.4686  decode.d4.loss_dice: 1.0236  decode.d5.loss_cls: 0.0808  decode.d5.loss_mask: 0.4636  decode.d5.loss_dice: 1.0225  decode.d6.loss_cls: 0.0813  decode.d6.loss_mask: 0.4666  decode.d6.loss_dice: 1.0304  decode.d7.loss_cls: 0.0761  decode.d7.loss_mask: 0.4623  decode.d7.loss_dice: 1.0346  decode.d8.loss_cls: 0.0822  decode.d8.loss_mask: 0.4557  decode.d8.loss_dice: 1.0174
11/15 14:46:15 - mmengine - INFO - Iter(train) [45400/90000]  base_lr: 5.3160e-05 lr: 5.3160e-06  eta: 7:28:52  time: 0.5997  data_time: 0.0105  memory: 10713  grad_norm: 320.2392  loss: 17.4577  decode.loss_cls: 0.0759  decode.loss_mask: 0.5412  decode.loss_dice: 1.0983  decode.d0.loss_cls: 0.0881  decode.d0.loss_mask: 0.5919  decode.d0.loss_dice: 1.1887  decode.d1.loss_cls: 0.0655  decode.d1.loss_mask: 0.5545  decode.d1.loss_dice: 1.1311  decode.d2.loss_cls: 0.0805  decode.d2.loss_mask: 0.5587  decode.d2.loss_dice: 1.1193  decode.d3.loss_cls: 0.0676  decode.d3.loss_mask: 0.5533  decode.d3.loss_dice: 1.1190  decode.d4.loss_cls: 0.0677  decode.d4.loss_mask: 0.5559  decode.d4.loss_dice: 1.0949  decode.d5.loss_cls: 0.0798  decode.d5.loss_mask: 0.5494  decode.d5.loss_dice: 1.0880  decode.d6.loss_cls: 0.0746  decode.d6.loss_mask: 0.5513  decode.d6.loss_dice: 1.1049  decode.d7.loss_cls: 0.0763  decode.d7.loss_mask: 0.5513  decode.d7.loss_dice: 1.1042  decode.d8.loss_cls: 0.0876  decode.d8.loss_mask: 0.5460  decode.d8.loss_dice: 1.0921
11/15 14:46:45 - mmengine - INFO - Iter(train) [45450/90000]  base_lr: 5.3107e-05 lr: 5.3107e-06  eta: 7:28:22  time: 0.5980  data_time: 0.0105  memory: 10692  grad_norm: 299.4448  loss: 15.2947  decode.loss_cls: 0.0774  decode.loss_mask: 0.4728  decode.loss_dice: 0.9701  decode.d0.loss_cls: 0.0991  decode.d0.loss_mask: 0.4856  decode.d0.loss_dice: 1.0163  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.4759  decode.d1.loss_dice: 1.0107  decode.d2.loss_cls: 0.0810  decode.d2.loss_mask: 0.4752  decode.d2.loss_dice: 0.9708  decode.d3.loss_cls: 0.0830  decode.d3.loss_mask: 0.4665  decode.d3.loss_dice: 0.9577  decode.d4.loss_cls: 0.0867  decode.d4.loss_mask: 0.4690  decode.d4.loss_dice: 0.9623  decode.d5.loss_cls: 0.0763  decode.d5.loss_mask: 0.4678  decode.d5.loss_dice: 0.9625  decode.d6.loss_cls: 0.0788  decode.d6.loss_mask: 0.4664  decode.d6.loss_dice: 0.9688  decode.d7.loss_cls: 0.0755  decode.d7.loss_mask: 0.4754  decode.d7.loss_dice: 0.9807  decode.d8.loss_cls: 0.0843  decode.d8.loss_mask: 0.4723  decode.d8.loss_dice: 0.9506
11/15 14:47:15 - mmengine - INFO - Iter(train) [45500/90000]  base_lr: 5.3053e-05 lr: 5.3053e-06  eta: 7:27:51  time: 0.6030  data_time: 0.0109  memory: 10692  grad_norm: 187.7311  loss: 14.9712  decode.loss_cls: 0.0527  decode.loss_mask: 0.4144  decode.loss_dice: 1.0237  decode.d0.loss_cls: 0.0721  decode.d0.loss_mask: 0.4212  decode.d0.loss_dice: 1.0762  decode.d1.loss_cls: 0.0524  decode.d1.loss_mask: 0.4153  decode.d1.loss_dice: 1.0465  decode.d2.loss_cls: 0.0528  decode.d2.loss_mask: 0.4125  decode.d2.loss_dice: 1.0367  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.4141  decode.d3.loss_dice: 1.0207  decode.d4.loss_cls: 0.0466  decode.d4.loss_mask: 0.4166  decode.d4.loss_dice: 1.0017  decode.d5.loss_cls: 0.0490  decode.d5.loss_mask: 0.4145  decode.d5.loss_dice: 0.9913  decode.d6.loss_cls: 0.0489  decode.d6.loss_mask: 0.4088  decode.d6.loss_dice: 1.0113  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.4097  decode.d7.loss_dice: 1.0336  decode.d8.loss_cls: 0.0562  decode.d8.loss_mask: 0.4132  decode.d8.loss_dice: 1.0558
11/15 14:47:45 - mmengine - INFO - Iter(train) [45550/90000]  base_lr: 5.2999e-05 lr: 5.2999e-06  eta: 7:27:21  time: 0.5964  data_time: 0.0106  memory: 10728  grad_norm: 452.0831  loss: 18.1092  decode.loss_cls: 0.0596  decode.loss_mask: 0.6048  decode.loss_dice: 1.1286  decode.d0.loss_cls: 0.0821  decode.d0.loss_mask: 0.6411  decode.d0.loss_dice: 1.1418  decode.d1.loss_cls: 0.0554  decode.d1.loss_mask: 0.6170  decode.d1.loss_dice: 1.1525  decode.d2.loss_cls: 0.0511  decode.d2.loss_mask: 0.6287  decode.d2.loss_dice: 1.1226  decode.d3.loss_cls: 0.0516  decode.d3.loss_mask: 0.6199  decode.d3.loss_dice: 1.1334  decode.d4.loss_cls: 0.0577  decode.d4.loss_mask: 0.6241  decode.d4.loss_dice: 1.1297  decode.d5.loss_cls: 0.0519  decode.d5.loss_mask: 0.6275  decode.d5.loss_dice: 1.1233  decode.d6.loss_cls: 0.0575  decode.d6.loss_mask: 0.6148  decode.d6.loss_dice: 1.1281  decode.d7.loss_cls: 0.0555  decode.d7.loss_mask: 0.6222  decode.d7.loss_dice: 1.1327  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.6102  decode.d8.loss_dice: 1.1221
11/15 14:48:17 - mmengine - INFO - Iter(train) [45600/90000]  base_lr: 5.2946e-05 lr: 5.2946e-06  eta: 7:26:53  time: 0.5984  data_time: 0.0108  memory: 10692  grad_norm: 406.2223  loss: 18.2613  decode.loss_cls: 0.0624  decode.loss_mask: 0.6169  decode.loss_dice: 1.1335  decode.d0.loss_cls: 0.0696  decode.d0.loss_mask: 0.6598  decode.d0.loss_dice: 1.1974  decode.d1.loss_cls: 0.0662  decode.d1.loss_mask: 0.6218  decode.d1.loss_dice: 1.1238  decode.d2.loss_cls: 0.0780  decode.d2.loss_mask: 0.6085  decode.d2.loss_dice: 1.1026  decode.d3.loss_cls: 0.0580  decode.d3.loss_mask: 0.6124  decode.d3.loss_dice: 1.1288  decode.d4.loss_cls: 0.0473  decode.d4.loss_mask: 0.6170  decode.d4.loss_dice: 1.1523  decode.d5.loss_cls: 0.0685  decode.d5.loss_mask: 0.6229  decode.d5.loss_dice: 1.1525  decode.d6.loss_cls: 0.0687  decode.d6.loss_mask: 0.6163  decode.d6.loss_dice: 1.1384  decode.d7.loss_cls: 0.0690  decode.d7.loss_mask: 0.6155  decode.d7.loss_dice: 1.1388  decode.d8.loss_cls: 0.0568  decode.d8.loss_mask: 0.6176  decode.d8.loss_dice: 1.1399
11/15 14:48:47 - mmengine - INFO - Iter(train) [45650/90000]  base_lr: 5.2892e-05 lr: 5.2892e-06  eta: 7:26:23  time: 0.5979  data_time: 0.0104  memory: 10692  grad_norm: 231.8396  loss: 16.6919  decode.loss_cls: 0.0267  decode.loss_mask: 0.5220  decode.loss_dice: 1.1070  decode.d0.loss_cls: 0.0545  decode.d0.loss_mask: 0.5504  decode.d0.loss_dice: 1.1394  decode.d1.loss_cls: 0.0417  decode.d1.loss_mask: 0.5236  decode.d1.loss_dice: 1.1081  decode.d2.loss_cls: 0.0370  decode.d2.loss_mask: 0.5180  decode.d2.loss_dice: 1.0876  decode.d3.loss_cls: 0.0285  decode.d3.loss_mask: 0.5302  decode.d3.loss_dice: 1.1105  decode.d4.loss_cls: 0.0334  decode.d4.loss_mask: 0.5267  decode.d4.loss_dice: 1.1163  decode.d5.loss_cls: 0.0349  decode.d5.loss_mask: 0.5244  decode.d5.loss_dice: 1.1089  decode.d6.loss_cls: 0.0387  decode.d6.loss_mask: 0.5244  decode.d6.loss_dice: 1.1028  decode.d7.loss_cls: 0.0320  decode.d7.loss_mask: 0.5159  decode.d7.loss_dice: 1.1047  decode.d8.loss_cls: 0.0550  decode.d8.loss_mask: 0.5200  decode.d8.loss_dice: 1.0689
11/15 14:49:17 - mmengine - INFO - Iter(train) [45700/90000]  base_lr: 5.2838e-05 lr: 5.2838e-06  eta: 7:25:52  time: 0.5968  data_time: 0.0106  memory: 10675  grad_norm: 564.5326  loss: 20.0965  decode.loss_cls: 0.0948  decode.loss_mask: 0.5878  decode.loss_dice: 1.3137  decode.d0.loss_cls: 0.1093  decode.d0.loss_mask: 0.6246  decode.d0.loss_dice: 1.3940  decode.d1.loss_cls: 0.1166  decode.d1.loss_mask: 0.5881  decode.d1.loss_dice: 1.3523  decode.d2.loss_cls: 0.1030  decode.d2.loss_mask: 0.5905  decode.d2.loss_dice: 1.3416  decode.d3.loss_cls: 0.0916  decode.d3.loss_mask: 0.5848  decode.d3.loss_dice: 1.2956  decode.d4.loss_cls: 0.0954  decode.d4.loss_mask: 0.5914  decode.d4.loss_dice: 1.3083  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 0.5837  decode.d5.loss_dice: 1.3035  decode.d6.loss_cls: 0.0929  decode.d6.loss_mask: 0.5788  decode.d6.loss_dice: 1.3272  decode.d7.loss_cls: 0.0903  decode.d7.loss_mask: 0.5800  decode.d7.loss_dice: 1.3213  decode.d8.loss_cls: 0.0787  decode.d8.loss_mask: 0.5801  decode.d8.loss_dice: 1.2904
11/15 14:49:47 - mmengine - INFO - Iter(train) [45750/90000]  base_lr: 5.2785e-05 lr: 5.2785e-06  eta: 7:25:22  time: 0.5983  data_time: 0.0106  memory: 10713  grad_norm: 309.9332  loss: 16.6306  decode.loss_cls: 0.0548  decode.loss_mask: 0.4427  decode.loss_dice: 1.1764  decode.d0.loss_cls: 0.0752  decode.d0.loss_mask: 0.4431  decode.d0.loss_dice: 1.1971  decode.d1.loss_cls: 0.0505  decode.d1.loss_mask: 0.4282  decode.d1.loss_dice: 1.1856  decode.d2.loss_cls: 0.0632  decode.d2.loss_mask: 0.4303  decode.d2.loss_dice: 1.1591  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 0.4309  decode.d3.loss_dice: 1.1714  decode.d4.loss_cls: 0.0660  decode.d4.loss_mask: 0.4335  decode.d4.loss_dice: 1.1517  decode.d5.loss_cls: 0.0600  decode.d5.loss_mask: 0.4339  decode.d5.loss_dice: 1.1583  decode.d6.loss_cls: 0.0600  decode.d6.loss_mask: 0.4321  decode.d6.loss_dice: 1.1358  decode.d7.loss_cls: 0.0644  decode.d7.loss_mask: 0.4375  decode.d7.loss_dice: 1.1418  decode.d8.loss_cls: 0.0733  decode.d8.loss_mask: 0.4504  decode.d8.loss_dice: 1.1620
11/15 14:50:17 - mmengine - INFO - Iter(train) [45800/90000]  base_lr: 5.2731e-05 lr: 5.2731e-06  eta: 7:24:51  time: 0.5972  data_time: 0.0104  memory: 10675  grad_norm: 493.4542  loss: 19.2362  decode.loss_cls: 0.0826  decode.loss_mask: 0.6459  decode.loss_dice: 1.1984  decode.d0.loss_cls: 0.0679  decode.d0.loss_mask: 0.6986  decode.d0.loss_dice: 1.2861  decode.d1.loss_cls: 0.0990  decode.d1.loss_mask: 0.6641  decode.d1.loss_dice: 1.1993  decode.d2.loss_cls: 0.0982  decode.d2.loss_mask: 0.6485  decode.d2.loss_dice: 1.2057  decode.d3.loss_cls: 0.0869  decode.d3.loss_mask: 0.6370  decode.d3.loss_dice: 1.1573  decode.d4.loss_cls: 0.0895  decode.d4.loss_mask: 0.6415  decode.d4.loss_dice: 1.1791  decode.d5.loss_cls: 0.0925  decode.d5.loss_mask: 0.6470  decode.d5.loss_dice: 1.1520  decode.d6.loss_cls: 0.1028  decode.d6.loss_mask: 0.6378  decode.d6.loss_dice: 1.1393  decode.d7.loss_cls: 0.0977  decode.d7.loss_mask: 0.6416  decode.d7.loss_dice: 1.1452  decode.d8.loss_cls: 0.0877  decode.d8.loss_mask: 0.6521  decode.d8.loss_dice: 1.1550
11/15 14:50:47 - mmengine - INFO - Iter(train) [45850/90000]  base_lr: 5.2677e-05 lr: 5.2677e-06  eta: 7:24:21  time: 0.5966  data_time: 0.0104  memory: 10641  grad_norm: 442.5128  loss: 16.5270  decode.loss_cls: 0.0621  decode.loss_mask: 0.4849  decode.loss_dice: 1.0930  decode.d0.loss_cls: 0.0734  decode.d0.loss_mask: 0.4853  decode.d0.loss_dice: 1.1585  decode.d1.loss_cls: 0.0784  decode.d1.loss_mask: 0.4847  decode.d1.loss_dice: 1.1286  decode.d2.loss_cls: 0.0615  decode.d2.loss_mask: 0.4790  decode.d2.loss_dice: 1.1064  decode.d3.loss_cls: 0.0702  decode.d3.loss_mask: 0.4835  decode.d3.loss_dice: 1.0819  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.4870  decode.d4.loss_dice: 1.0900  decode.d5.loss_cls: 0.0598  decode.d5.loss_mask: 0.4897  decode.d5.loss_dice: 1.1004  decode.d6.loss_cls: 0.0619  decode.d6.loss_mask: 0.4892  decode.d6.loss_dice: 1.0768  decode.d7.loss_cls: 0.0529  decode.d7.loss_mask: 0.4871  decode.d7.loss_dice: 1.0829  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.4875  decode.d8.loss_dice: 1.1088
11/15 14:51:17 - mmengine - INFO - Iter(train) [45900/90000]  base_lr: 5.2624e-05 lr: 5.2624e-06  eta: 7:23:51  time: 0.6016  data_time: 0.0107  memory: 10675  grad_norm: 280.1805  loss: 16.9256  decode.loss_cls: 0.0640  decode.loss_mask: 0.5638  decode.loss_dice: 1.0439  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.5930  decode.d0.loss_dice: 1.1065  decode.d1.loss_cls: 0.0528  decode.d1.loss_mask: 0.5715  decode.d1.loss_dice: 1.0754  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.5798  decode.d2.loss_dice: 1.0702  decode.d3.loss_cls: 0.0649  decode.d3.loss_mask: 0.5631  decode.d3.loss_dice: 1.0541  decode.d4.loss_cls: 0.0674  decode.d4.loss_mask: 0.5587  decode.d4.loss_dice: 1.0338  decode.d5.loss_cls: 0.0684  decode.d5.loss_mask: 0.5726  decode.d5.loss_dice: 1.0274  decode.d6.loss_cls: 0.0617  decode.d6.loss_mask: 0.5750  decode.d6.loss_dice: 1.0491  decode.d7.loss_cls: 0.0642  decode.d7.loss_mask: 0.5618  decode.d7.loss_dice: 1.0481  decode.d8.loss_cls: 0.0661  decode.d8.loss_mask: 0.5716  decode.d8.loss_dice: 1.0535
11/15 14:51:47 - mmengine - INFO - Iter(train) [45950/90000]  base_lr: 5.2570e-05 lr: 5.2570e-06  eta: 7:23:20  time: 0.5979  data_time: 0.0106  memory: 10713  grad_norm: 500.7540  loss: 15.9321  decode.loss_cls: 0.0535  decode.loss_mask: 0.4790  decode.loss_dice: 1.0506  decode.d0.loss_cls: 0.0717  decode.d0.loss_mask: 0.5172  decode.d0.loss_dice: 1.0903  decode.d1.loss_cls: 0.0683  decode.d1.loss_mask: 0.4879  decode.d1.loss_dice: 1.0563  decode.d2.loss_cls: 0.0593  decode.d2.loss_mask: 0.4748  decode.d2.loss_dice: 1.0491  decode.d3.loss_cls: 0.0674  decode.d3.loss_mask: 0.4762  decode.d3.loss_dice: 1.0433  decode.d4.loss_cls: 0.0564  decode.d4.loss_mask: 0.4762  decode.d4.loss_dice: 1.0491  decode.d5.loss_cls: 0.0516  decode.d5.loss_mask: 0.4756  decode.d5.loss_dice: 1.0381  decode.d6.loss_cls: 0.0554  decode.d6.loss_mask: 0.4764  decode.d6.loss_dice: 1.0487  decode.d7.loss_cls: 0.0467  decode.d7.loss_mask: 0.4799  decode.d7.loss_dice: 1.0401  decode.d8.loss_cls: 0.0488  decode.d8.loss_mask: 0.4753  decode.d8.loss_dice: 1.0689
11/15 14:52:18 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 14:52:18 - mmengine - INFO - Iter(train) [46000/90000]  base_lr: 5.2516e-05 lr: 5.2516e-06  eta: 7:22:50  time: 0.5985  data_time: 0.0107  memory: 10675  grad_norm: 627.7228  loss: 15.3779  decode.loss_cls: 0.0570  decode.loss_mask: 0.4220  decode.loss_dice: 1.0267  decode.d0.loss_cls: 0.0754  decode.d0.loss_mask: 0.4468  decode.d0.loss_dice: 1.1434  decode.d1.loss_cls: 0.0679  decode.d1.loss_mask: 0.4248  decode.d1.loss_dice: 1.0776  decode.d2.loss_cls: 0.0644  decode.d2.loss_mask: 0.4208  decode.d2.loss_dice: 1.0477  decode.d3.loss_cls: 0.0649  decode.d3.loss_mask: 0.4206  decode.d3.loss_dice: 1.0313  decode.d4.loss_cls: 0.0720  decode.d4.loss_mask: 0.4200  decode.d4.loss_dice: 1.0404  decode.d5.loss_cls: 0.0624  decode.d5.loss_mask: 0.4137  decode.d5.loss_dice: 1.0458  decode.d6.loss_cls: 0.0619  decode.d6.loss_mask: 0.4161  decode.d6.loss_dice: 1.0478  decode.d7.loss_cls: 0.0723  decode.d7.loss_mask: 0.4176  decode.d7.loss_dice: 1.0249  decode.d8.loss_cls: 0.0671  decode.d8.loss_mask: 0.4150  decode.d8.loss_dice: 1.0095
11/15 14:52:48 - mmengine - INFO - Iter(train) [46050/90000]  base_lr: 5.2463e-05 lr: 5.2463e-06  eta: 7:22:20  time: 0.5974  data_time: 0.0106  memory: 10742  grad_norm: 303.0092  loss: 16.1560  decode.loss_cls: 0.0787  decode.loss_mask: 0.4213  decode.loss_dice: 1.1044  decode.d0.loss_cls: 0.0733  decode.d0.loss_mask: 0.4592  decode.d0.loss_dice: 1.2189  decode.d1.loss_cls: 0.0850  decode.d1.loss_mask: 0.4235  decode.d1.loss_dice: 1.1328  decode.d2.loss_cls: 0.0854  decode.d2.loss_mask: 0.4212  decode.d2.loss_dice: 1.1154  decode.d3.loss_cls: 0.0698  decode.d3.loss_mask: 0.4275  decode.d3.loss_dice: 1.0993  decode.d4.loss_cls: 0.0641  decode.d4.loss_mask: 0.4235  decode.d4.loss_dice: 1.1098  decode.d5.loss_cls: 0.0774  decode.d5.loss_mask: 0.4253  decode.d5.loss_dice: 1.1129  decode.d6.loss_cls: 0.0837  decode.d6.loss_mask: 0.4225  decode.d6.loss_dice: 1.0825  decode.d7.loss_cls: 0.0778  decode.d7.loss_mask: 0.4199  decode.d7.loss_dice: 1.0606  decode.d8.loss_cls: 0.0786  decode.d8.loss_mask: 0.4241  decode.d8.loss_dice: 1.0777
11/15 14:53:18 - mmengine - INFO - Iter(train) [46100/90000]  base_lr: 5.2409e-05 lr: 5.2409e-06  eta: 7:21:49  time: 0.5973  data_time: 0.0107  memory: 10692  grad_norm: 421.9464  loss: 17.3718  decode.loss_cls: 0.0852  decode.loss_mask: 0.5166  decode.loss_dice: 1.1129  decode.d0.loss_cls: 0.0849  decode.d0.loss_mask: 0.5439  decode.d0.loss_dice: 1.3054  decode.d1.loss_cls: 0.0886  decode.d1.loss_mask: 0.5086  decode.d1.loss_dice: 1.1656  decode.d2.loss_cls: 0.0779  decode.d2.loss_mask: 0.5104  decode.d2.loss_dice: 1.1057  decode.d3.loss_cls: 0.0802  decode.d3.loss_mask: 0.5087  decode.d3.loss_dice: 1.0834  decode.d4.loss_cls: 0.0802  decode.d4.loss_mask: 0.5107  decode.d4.loss_dice: 1.1066  decode.d5.loss_cls: 0.0905  decode.d5.loss_mask: 0.5101  decode.d5.loss_dice: 1.1190  decode.d6.loss_cls: 0.0903  decode.d6.loss_mask: 0.5149  decode.d6.loss_dice: 1.1210  decode.d7.loss_cls: 0.0806  decode.d7.loss_mask: 0.5153  decode.d7.loss_dice: 1.1118  decode.d8.loss_cls: 0.0826  decode.d8.loss_mask: 0.5190  decode.d8.loss_dice: 1.1413
11/15 14:53:47 - mmengine - INFO - Iter(train) [46150/90000]  base_lr: 5.2355e-05 lr: 5.2355e-06  eta: 7:21:19  time: 0.5971  data_time: 0.0105  memory: 10675  grad_norm: 304.2917  loss: 13.6756  decode.loss_cls: 0.0613  decode.loss_mask: 0.4343  decode.loss_dice: 0.8662  decode.d0.loss_cls: 0.0810  decode.d0.loss_mask: 0.4565  decode.d0.loss_dice: 0.9316  decode.d1.loss_cls: 0.0699  decode.d1.loss_mask: 0.4414  decode.d1.loss_dice: 0.8694  decode.d2.loss_cls: 0.0611  decode.d2.loss_mask: 0.4374  decode.d2.loss_dice: 0.8605  decode.d3.loss_cls: 0.0675  decode.d3.loss_mask: 0.4346  decode.d3.loss_dice: 0.8636  decode.d4.loss_cls: 0.0604  decode.d4.loss_mask: 0.4351  decode.d4.loss_dice: 0.8407  decode.d5.loss_cls: 0.0588  decode.d5.loss_mask: 0.4310  decode.d5.loss_dice: 0.8773  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.4308  decode.d6.loss_dice: 0.8829  decode.d7.loss_cls: 0.0548  decode.d7.loss_mask: 0.4414  decode.d7.loss_dice: 0.8387  decode.d8.loss_cls: 0.0542  decode.d8.loss_mask: 0.4368  decode.d8.loss_dice: 0.8421
11/15 14:54:17 - mmengine - INFO - Iter(train) [46200/90000]  base_lr: 5.2301e-05 lr: 5.2301e-06  eta: 7:20:48  time: 0.5976  data_time: 0.0106  memory: 10675  grad_norm: 237.6947  loss: 16.6620  decode.loss_cls: 0.0561  decode.loss_mask: 0.4676  decode.loss_dice: 1.1352  decode.d0.loss_cls: 0.0887  decode.d0.loss_mask: 0.4912  decode.d0.loss_dice: 1.1610  decode.d1.loss_cls: 0.0617  decode.d1.loss_mask: 0.4699  decode.d1.loss_dice: 1.1346  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.4740  decode.d2.loss_dice: 1.1364  decode.d3.loss_cls: 0.0502  decode.d3.loss_mask: 0.4713  decode.d3.loss_dice: 1.1545  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 0.4762  decode.d4.loss_dice: 1.1379  decode.d5.loss_cls: 0.0626  decode.d5.loss_mask: 0.4655  decode.d5.loss_dice: 1.1279  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.4617  decode.d6.loss_dice: 1.1294  decode.d7.loss_cls: 0.0546  decode.d7.loss_mask: 0.4704  decode.d7.loss_dice: 1.1092  decode.d8.loss_cls: 0.0424  decode.d8.loss_mask: 0.4772  decode.d8.loss_dice: 1.1270
11/15 14:54:47 - mmengine - INFO - Iter(train) [46250/90000]  base_lr: 5.2248e-05 lr: 5.2248e-06  eta: 7:20:18  time: 0.5984  data_time: 0.0105  memory: 10713  grad_norm: 245.5820  loss: 17.3797  decode.loss_cls: 0.0775  decode.loss_mask: 0.5792  decode.loss_dice: 1.0573  decode.d0.loss_cls: 0.0837  decode.d0.loss_mask: 0.6173  decode.d0.loss_dice: 1.1639  decode.d1.loss_cls: 0.0524  decode.d1.loss_mask: 0.5971  decode.d1.loss_dice: 1.0952  decode.d2.loss_cls: 0.0742  decode.d2.loss_mask: 0.5916  decode.d2.loss_dice: 1.0736  decode.d3.loss_cls: 0.0820  decode.d3.loss_mask: 0.5831  decode.d3.loss_dice: 1.0555  decode.d4.loss_cls: 0.0840  decode.d4.loss_mask: 0.5833  decode.d4.loss_dice: 1.0434  decode.d5.loss_cls: 0.0590  decode.d5.loss_mask: 0.5906  decode.d5.loss_dice: 1.0860  decode.d6.loss_cls: 0.0811  decode.d6.loss_mask: 0.5796  decode.d6.loss_dice: 1.0571  decode.d7.loss_cls: 0.0737  decode.d7.loss_mask: 0.5828  decode.d7.loss_dice: 1.0516  decode.d8.loss_cls: 0.0587  decode.d8.loss_mask: 0.5868  decode.d8.loss_dice: 1.0785
11/15 14:55:17 - mmengine - INFO - Iter(train) [46300/90000]  base_lr: 5.2194e-05 lr: 5.2194e-06  eta: 7:19:47  time: 0.5972  data_time: 0.0108  memory: 10641  grad_norm: 345.6888  loss: 16.3779  decode.loss_cls: 0.0468  decode.loss_mask: 0.5025  decode.loss_dice: 1.0340  decode.d0.loss_cls: 0.0693  decode.d0.loss_mask: 0.5739  decode.d0.loss_dice: 1.1628  decode.d1.loss_cls: 0.0654  decode.d1.loss_mask: 0.5141  decode.d1.loss_dice: 1.0926  decode.d2.loss_cls: 0.0513  decode.d2.loss_mask: 0.5115  decode.d2.loss_dice: 1.0800  decode.d3.loss_cls: 0.0452  decode.d3.loss_mask: 0.5089  decode.d3.loss_dice: 1.0469  decode.d4.loss_cls: 0.0474  decode.d4.loss_mask: 0.5048  decode.d4.loss_dice: 1.0394  decode.d5.loss_cls: 0.0450  decode.d5.loss_mask: 0.5061  decode.d5.loss_dice: 1.0692  decode.d6.loss_cls: 0.0484  decode.d6.loss_mask: 0.5100  decode.d6.loss_dice: 1.0449  decode.d7.loss_cls: 0.0431  decode.d7.loss_mask: 0.5123  decode.d7.loss_dice: 1.0964  decode.d8.loss_cls: 0.0477  decode.d8.loss_mask: 0.5057  decode.d8.loss_dice: 1.0522
11/15 14:55:47 - mmengine - INFO - Iter(train) [46350/90000]  base_lr: 5.2140e-05 lr: 5.2140e-06  eta: 7:19:17  time: 0.5974  data_time: 0.0105  memory: 10675  grad_norm: 635.5831  loss: 16.9195  decode.loss_cls: 0.1061  decode.loss_mask: 0.5471  decode.loss_dice: 1.0557  decode.d0.loss_cls: 0.0997  decode.d0.loss_mask: 0.5325  decode.d0.loss_dice: 1.1506  decode.d1.loss_cls: 0.0906  decode.d1.loss_mask: 0.5249  decode.d1.loss_dice: 1.0735  decode.d2.loss_cls: 0.1047  decode.d2.loss_mask: 0.5192  decode.d2.loss_dice: 1.0358  decode.d3.loss_cls: 0.1102  decode.d3.loss_mask: 0.5211  decode.d3.loss_dice: 1.0296  decode.d4.loss_cls: 0.1127  decode.d4.loss_mask: 0.5075  decode.d4.loss_dice: 1.0455  decode.d5.loss_cls: 0.1038  decode.d5.loss_mask: 0.5267  decode.d5.loss_dice: 1.0255  decode.d6.loss_cls: 0.1109  decode.d6.loss_mask: 0.5226  decode.d6.loss_dice: 1.0566  decode.d7.loss_cls: 0.1108  decode.d7.loss_mask: 0.5510  decode.d7.loss_dice: 1.0732  decode.d8.loss_cls: 0.1015  decode.d8.loss_mask: 0.5459  decode.d8.loss_dice: 1.0241
11/15 14:56:17 - mmengine - INFO - Iter(train) [46400/90000]  base_lr: 5.2086e-05 lr: 5.2086e-06  eta: 7:18:46  time: 0.5977  data_time: 0.0104  memory: 10675  grad_norm: 335.1642  loss: 15.3941  decode.loss_cls: 0.0431  decode.loss_mask: 0.3920  decode.loss_dice: 1.0752  decode.d0.loss_cls: 0.0683  decode.d0.loss_mask: 0.4024  decode.d0.loss_dice: 1.1456  decode.d1.loss_cls: 0.0533  decode.d1.loss_mask: 0.3978  decode.d1.loss_dice: 1.1212  decode.d2.loss_cls: 0.0422  decode.d2.loss_mask: 0.3900  decode.d2.loss_dice: 1.1090  decode.d3.loss_cls: 0.0416  decode.d3.loss_mask: 0.3910  decode.d3.loss_dice: 1.0750  decode.d4.loss_cls: 0.0458  decode.d4.loss_mask: 0.3900  decode.d4.loss_dice: 1.0861  decode.d5.loss_cls: 0.0464  decode.d5.loss_mask: 0.3876  decode.d5.loss_dice: 1.0979  decode.d6.loss_cls: 0.0421  decode.d6.loss_mask: 0.3915  decode.d6.loss_dice: 1.0909  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.3959  decode.d7.loss_dice: 1.0921  decode.d8.loss_cls: 0.0496  decode.d8.loss_mask: 0.3925  decode.d8.loss_dice: 1.0876
11/15 14:56:47 - mmengine - INFO - Iter(train) [46450/90000]  base_lr: 5.2033e-05 lr: 5.2033e-06  eta: 7:18:16  time: 0.5984  data_time: 0.0106  memory: 10675  grad_norm: 284.4578  loss: 17.0370  decode.loss_cls: 0.0396  decode.loss_mask: 0.5271  decode.loss_dice: 1.1234  decode.d0.loss_cls: 0.0878  decode.d0.loss_mask: 0.5624  decode.d0.loss_dice: 1.1416  decode.d1.loss_cls: 0.0597  decode.d1.loss_mask: 0.5325  decode.d1.loss_dice: 1.1158  decode.d2.loss_cls: 0.0507  decode.d2.loss_mask: 0.5269  decode.d2.loss_dice: 1.1220  decode.d3.loss_cls: 0.0452  decode.d3.loss_mask: 0.5265  decode.d3.loss_dice: 1.1226  decode.d4.loss_cls: 0.0546  decode.d4.loss_mask: 0.5266  decode.d4.loss_dice: 1.1338  decode.d5.loss_cls: 0.0661  decode.d5.loss_mask: 0.5299  decode.d5.loss_dice: 1.1046  decode.d6.loss_cls: 0.0481  decode.d6.loss_mask: 0.5225  decode.d6.loss_dice: 1.0961  decode.d7.loss_cls: 0.0449  decode.d7.loss_mask: 0.5312  decode.d7.loss_dice: 1.1125  decode.d8.loss_cls: 0.0437  decode.d8.loss_mask: 0.5323  decode.d8.loss_dice: 1.1061
11/15 14:57:17 - mmengine - INFO - Iter(train) [46500/90000]  base_lr: 5.1979e-05 lr: 5.1979e-06  eta: 7:17:45  time: 0.6001  data_time: 0.0107  memory: 10675  grad_norm: 354.4374  loss: 17.3731  decode.loss_cls: 0.0601  decode.loss_mask: 0.4879  decode.loss_dice: 1.1875  decode.d0.loss_cls: 0.0873  decode.d0.loss_mask: 0.4870  decode.d0.loss_dice: 1.2398  decode.d1.loss_cls: 0.0678  decode.d1.loss_mask: 0.4659  decode.d1.loss_dice: 1.1896  decode.d2.loss_cls: 0.0670  decode.d2.loss_mask: 0.4873  decode.d2.loss_dice: 1.1920  decode.d3.loss_cls: 0.0688  decode.d3.loss_mask: 0.5028  decode.d3.loss_dice: 1.1722  decode.d4.loss_cls: 0.0576  decode.d4.loss_mask: 0.5117  decode.d4.loss_dice: 1.1899  decode.d5.loss_cls: 0.0639  decode.d5.loss_mask: 0.5173  decode.d5.loss_dice: 1.1383  decode.d6.loss_cls: 0.0635  decode.d6.loss_mask: 0.4571  decode.d6.loss_dice: 1.1313  decode.d7.loss_cls: 0.0559  decode.d7.loss_mask: 0.5018  decode.d7.loss_dice: 1.1817  decode.d8.loss_cls: 0.0678  decode.d8.loss_mask: 0.4859  decode.d8.loss_dice: 1.1864
11/15 14:57:47 - mmengine - INFO - Iter(train) [46550/90000]  base_lr: 5.1925e-05 lr: 5.1925e-06  eta: 7:17:15  time: 0.6000  data_time: 0.0106  memory: 10675  grad_norm: 375.8994  loss: 17.2501  decode.loss_cls: 0.0356  decode.loss_mask: 0.5455  decode.loss_dice: 1.1089  decode.d0.loss_cls: 0.0708  decode.d0.loss_mask: 0.5765  decode.d0.loss_dice: 1.1747  decode.d1.loss_cls: 0.0486  decode.d1.loss_mask: 0.5525  decode.d1.loss_dice: 1.1259  decode.d2.loss_cls: 0.0466  decode.d2.loss_mask: 0.5493  decode.d2.loss_dice: 1.1321  decode.d3.loss_cls: 0.0481  decode.d3.loss_mask: 0.5454  decode.d3.loss_dice: 1.1415  decode.d4.loss_cls: 0.0451  decode.d4.loss_mask: 0.5393  decode.d4.loss_dice: 1.1263  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.5455  decode.d5.loss_dice: 1.1352  decode.d6.loss_cls: 0.0431  decode.d6.loss_mask: 0.5501  decode.d6.loss_dice: 1.1243  decode.d7.loss_cls: 0.0391  decode.d7.loss_mask: 0.5434  decode.d7.loss_dice: 1.1067  decode.d8.loss_cls: 0.0471  decode.d8.loss_mask: 0.5486  decode.d8.loss_dice: 1.1064
11/15 14:58:17 - mmengine - INFO - Iter(train) [46600/90000]  base_lr: 5.1871e-05 lr: 5.1871e-06  eta: 7:16:45  time: 0.5974  data_time: 0.0105  memory: 10713  grad_norm: 326.0036  loss: 16.6525  decode.loss_cls: 0.0685  decode.loss_mask: 0.5466  decode.loss_dice: 1.0379  decode.d0.loss_cls: 0.0942  decode.d0.loss_mask: 0.5725  decode.d0.loss_dice: 1.1247  decode.d1.loss_cls: 0.0663  decode.d1.loss_mask: 0.5451  decode.d1.loss_dice: 1.0915  decode.d2.loss_cls: 0.0826  decode.d2.loss_mask: 0.5383  decode.d2.loss_dice: 1.0114  decode.d3.loss_cls: 0.0773  decode.d3.loss_mask: 0.5360  decode.d3.loss_dice: 1.0191  decode.d4.loss_cls: 0.0720  decode.d4.loss_mask: 0.5409  decode.d4.loss_dice: 1.0636  decode.d5.loss_cls: 0.0730  decode.d5.loss_mask: 0.5340  decode.d5.loss_dice: 1.0215  decode.d6.loss_cls: 0.0613  decode.d6.loss_mask: 0.5393  decode.d6.loss_dice: 1.0166  decode.d7.loss_cls: 0.0709  decode.d7.loss_mask: 0.5379  decode.d7.loss_dice: 1.0460  decode.d8.loss_cls: 0.0768  decode.d8.loss_mask: 0.5453  decode.d8.loss_dice: 1.0415
11/15 14:58:46 - mmengine - INFO - Iter(train) [46650/90000]  base_lr: 5.1817e-05 lr: 5.1817e-06  eta: 7:16:14  time: 0.5974  data_time: 0.0103  memory: 10713  grad_norm: 479.0330  loss: 16.6287  decode.loss_cls: 0.0471  decode.loss_mask: 0.4943  decode.loss_dice: 1.0817  decode.d0.loss_cls: 0.0695  decode.d0.loss_mask: 0.5541  decode.d0.loss_dice: 1.1477  decode.d1.loss_cls: 0.0525  decode.d1.loss_mask: 0.5192  decode.d1.loss_dice: 1.1252  decode.d2.loss_cls: 0.0584  decode.d2.loss_mask: 0.5307  decode.d2.loss_dice: 1.1083  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.5195  decode.d3.loss_dice: 1.0806  decode.d4.loss_cls: 0.0453  decode.d4.loss_mask: 0.5187  decode.d4.loss_dice: 1.0752  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.5240  decode.d5.loss_dice: 1.1035  decode.d6.loss_cls: 0.0523  decode.d6.loss_mask: 0.4930  decode.d6.loss_dice: 1.0753  decode.d7.loss_cls: 0.0409  decode.d7.loss_mask: 0.4925  decode.d7.loss_dice: 1.0787  decode.d8.loss_cls: 0.0425  decode.d8.loss_mask: 0.4959  decode.d8.loss_dice: 1.0946
11/15 14:59:16 - mmengine - INFO - Iter(train) [46700/90000]  base_lr: 5.1764e-05 lr: 5.1764e-06  eta: 7:15:44  time: 0.5969  data_time: 0.0104  memory: 10675  grad_norm: 344.2287  loss: 17.8750  decode.loss_cls: 0.0384  decode.loss_mask: 0.5630  decode.loss_dice: 1.1549  decode.d0.loss_cls: 0.0630  decode.d0.loss_mask: 0.6165  decode.d0.loss_dice: 1.2085  decode.d1.loss_cls: 0.0486  decode.d1.loss_mask: 0.5759  decode.d1.loss_dice: 1.1962  decode.d2.loss_cls: 0.0461  decode.d2.loss_mask: 0.5658  decode.d2.loss_dice: 1.1760  decode.d3.loss_cls: 0.0431  decode.d3.loss_mask: 0.5675  decode.d3.loss_dice: 1.1492  decode.d4.loss_cls: 0.0424  decode.d4.loss_mask: 0.5704  decode.d4.loss_dice: 1.1593  decode.d5.loss_cls: 0.0348  decode.d5.loss_mask: 0.5781  decode.d5.loss_dice: 1.1669  decode.d6.loss_cls: 0.0366  decode.d6.loss_mask: 0.5778  decode.d6.loss_dice: 1.1586  decode.d7.loss_cls: 0.0405  decode.d7.loss_mask: 0.5763  decode.d7.loss_dice: 1.1524  decode.d8.loss_cls: 0.0432  decode.d8.loss_mask: 0.5607  decode.d8.loss_dice: 1.1643
11/15 14:59:46 - mmengine - INFO - Iter(train) [46750/90000]  base_lr: 5.1710e-05 lr: 5.1710e-06  eta: 7:15:13  time: 0.5976  data_time: 0.0106  memory: 10656  grad_norm: 240.7267  loss: 16.2074  decode.loss_cls: 0.1015  decode.loss_mask: 0.4153  decode.loss_dice: 1.0257  decode.d0.loss_cls: 0.0956  decode.d0.loss_mask: 0.4517  decode.d0.loss_dice: 1.2695  decode.d1.loss_cls: 0.0932  decode.d1.loss_mask: 0.4385  decode.d1.loss_dice: 1.1564  decode.d2.loss_cls: 0.0875  decode.d2.loss_mask: 0.4262  decode.d2.loss_dice: 1.0992  decode.d3.loss_cls: 0.0887  decode.d3.loss_mask: 0.4173  decode.d3.loss_dice: 1.0817  decode.d4.loss_cls: 0.0956  decode.d4.loss_mask: 0.4228  decode.d4.loss_dice: 1.0617  decode.d5.loss_cls: 0.1020  decode.d5.loss_mask: 0.4277  decode.d5.loss_dice: 1.0561  decode.d6.loss_cls: 0.0932  decode.d6.loss_mask: 0.4260  decode.d6.loss_dice: 1.0781  decode.d7.loss_cls: 0.0880  decode.d7.loss_mask: 0.4212  decode.d7.loss_dice: 1.0715  decode.d8.loss_cls: 0.0824  decode.d8.loss_mask: 0.4325  decode.d8.loss_dice: 1.1006
11/15 15:00:16 - mmengine - INFO - Iter(train) [46800/90000]  base_lr: 5.1656e-05 lr: 5.1656e-06  eta: 7:14:43  time: 0.5984  data_time: 0.0106  memory: 10728  grad_norm: 399.4495  loss: 16.1697  decode.loss_cls: 0.0379  decode.loss_mask: 0.5173  decode.loss_dice: 1.0753  decode.d0.loss_cls: 0.0764  decode.d0.loss_mask: 0.5392  decode.d0.loss_dice: 1.0900  decode.d1.loss_cls: 0.0562  decode.d1.loss_mask: 0.5494  decode.d1.loss_dice: 1.0666  decode.d2.loss_cls: 0.0506  decode.d2.loss_mask: 0.5023  decode.d2.loss_dice: 1.0443  decode.d3.loss_cls: 0.0619  decode.d3.loss_mask: 0.4672  decode.d3.loss_dice: 1.0166  decode.d4.loss_cls: 0.0642  decode.d4.loss_mask: 0.4958  decode.d4.loss_dice: 1.0478  decode.d5.loss_cls: 0.0526  decode.d5.loss_mask: 0.5014  decode.d5.loss_dice: 1.0452  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.4789  decode.d6.loss_dice: 1.0257  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.5172  decode.d7.loss_dice: 1.0670  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.5162  decode.d8.loss_dice: 1.0500
11/15 15:00:46 - mmengine - INFO - Iter(train) [46850/90000]  base_lr: 5.1602e-05 lr: 5.1602e-06  eta: 7:14:12  time: 0.5979  data_time: 0.0106  memory: 10641  grad_norm: 375.5131  loss: 17.1934  decode.loss_cls: 0.0713  decode.loss_mask: 0.4562  decode.loss_dice: 1.1500  decode.d0.loss_cls: 0.0714  decode.d0.loss_mask: 0.4952  decode.d0.loss_dice: 1.2539  decode.d1.loss_cls: 0.0492  decode.d1.loss_mask: 0.4847  decode.d1.loss_dice: 1.2227  decode.d2.loss_cls: 0.0557  decode.d2.loss_mask: 0.4747  decode.d2.loss_dice: 1.1917  decode.d3.loss_cls: 0.0441  decode.d3.loss_mask: 0.4746  decode.d3.loss_dice: 1.1865  decode.d4.loss_cls: 0.0502  decode.d4.loss_mask: 0.4779  decode.d4.loss_dice: 1.2062  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 0.4712  decode.d5.loss_dice: 1.1530  decode.d6.loss_cls: 0.0637  decode.d6.loss_mask: 0.4609  decode.d6.loss_dice: 1.1666  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 0.4636  decode.d7.loss_dice: 1.1876  decode.d8.loss_cls: 0.0641  decode.d8.loss_mask: 0.4596  decode.d8.loss_dice: 1.1627
11/15 15:01:16 - mmengine - INFO - Iter(train) [46900/90000]  base_lr: 5.1548e-05 lr: 5.1548e-06  eta: 7:13:42  time: 0.5987  data_time: 0.0104  memory: 10641  grad_norm: 409.5218  loss: 15.9492  decode.loss_cls: 0.0514  decode.loss_mask: 0.5117  decode.loss_dice: 1.0243  decode.d0.loss_cls: 0.0744  decode.d0.loss_mask: 0.4855  decode.d0.loss_dice: 1.1067  decode.d1.loss_cls: 0.0560  decode.d1.loss_mask: 0.4870  decode.d1.loss_dice: 1.0562  decode.d2.loss_cls: 0.0475  decode.d2.loss_mask: 0.5000  decode.d2.loss_dice: 1.0316  decode.d3.loss_cls: 0.0527  decode.d3.loss_mask: 0.5057  decode.d3.loss_dice: 1.0205  decode.d4.loss_cls: 0.0467  decode.d4.loss_mask: 0.5181  decode.d4.loss_dice: 1.0410  decode.d5.loss_cls: 0.0466  decode.d5.loss_mask: 0.5154  decode.d5.loss_dice: 1.0213  decode.d6.loss_cls: 0.0518  decode.d6.loss_mask: 0.5137  decode.d6.loss_dice: 1.0154  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.5161  decode.d7.loss_dice: 1.0287  decode.d8.loss_cls: 0.0508  decode.d8.loss_mask: 0.5032  decode.d8.loss_dice: 1.0186
11/15 15:01:46 - mmengine - INFO - Iter(train) [46950/90000]  base_lr: 5.1495e-05 lr: 5.1495e-06  eta: 7:13:11  time: 0.5957  data_time: 0.0106  memory: 10675  grad_norm: 528.7134  loss: 16.1982  decode.loss_cls: 0.0534  decode.loss_mask: 0.5727  decode.loss_dice: 0.9853  decode.d0.loss_cls: 0.0883  decode.d0.loss_mask: 0.6002  decode.d0.loss_dice: 1.0605  decode.d1.loss_cls: 0.0522  decode.d1.loss_mask: 0.5700  decode.d1.loss_dice: 1.0421  decode.d2.loss_cls: 0.0510  decode.d2.loss_mask: 0.5717  decode.d2.loss_dice: 0.9865  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.5732  decode.d3.loss_dice: 0.9474  decode.d4.loss_cls: 0.0531  decode.d4.loss_mask: 0.5425  decode.d4.loss_dice: 0.9929  decode.d5.loss_cls: 0.0521  decode.d5.loss_mask: 0.5524  decode.d5.loss_dice: 0.9956  decode.d6.loss_cls: 0.0529  decode.d6.loss_mask: 0.5560  decode.d6.loss_dice: 0.9944  decode.d7.loss_cls: 0.0547  decode.d7.loss_mask: 0.5632  decode.d7.loss_dice: 0.9918  decode.d8.loss_cls: 0.0643  decode.d8.loss_mask: 0.5553  decode.d8.loss_dice: 0.9736
11/15 15:02:16 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 15:02:16 - mmengine - INFO - Iter(train) [47000/90000]  base_lr: 5.1441e-05 lr: 5.1441e-06  eta: 7:12:41  time: 0.5974  data_time: 0.0104  memory: 10656  grad_norm: 356.1213  loss: 16.2086  decode.loss_cls: 0.0539  decode.loss_mask: 0.5119  decode.loss_dice: 1.0268  decode.d0.loss_cls: 0.0689  decode.d0.loss_mask: 0.5783  decode.d0.loss_dice: 1.1265  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.5478  decode.d1.loss_dice: 1.0371  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 0.5424  decode.d2.loss_dice: 1.0372  decode.d3.loss_cls: 0.0445  decode.d3.loss_mask: 0.5343  decode.d3.loss_dice: 1.0322  decode.d4.loss_cls: 0.0502  decode.d4.loss_mask: 0.5319  decode.d4.loss_dice: 1.0220  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.5165  decode.d5.loss_dice: 1.0106  decode.d6.loss_cls: 0.0506  decode.d6.loss_mask: 0.5121  decode.d6.loss_dice: 1.0223  decode.d7.loss_cls: 0.0635  decode.d7.loss_mask: 0.5149  decode.d7.loss_dice: 1.0053  decode.d8.loss_cls: 0.0432  decode.d8.loss_mask: 0.5297  decode.d8.loss_dice: 1.0330
11/15 15:02:46 - mmengine - INFO - Iter(train) [47050/90000]  base_lr: 5.1387e-05 lr: 5.1387e-06  eta: 7:12:11  time: 0.5974  data_time: 0.0105  memory: 10675  grad_norm: 298.6648  loss: 16.4350  decode.loss_cls: 0.0553  decode.loss_mask: 0.4362  decode.loss_dice: 1.1100  decode.d0.loss_cls: 0.0632  decode.d0.loss_mask: 0.4556  decode.d0.loss_dice: 1.1852  decode.d1.loss_cls: 0.0640  decode.d1.loss_mask: 0.4504  decode.d1.loss_dice: 1.1406  decode.d2.loss_cls: 0.0527  decode.d2.loss_mask: 0.4463  decode.d2.loss_dice: 1.1482  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 0.4426  decode.d3.loss_dice: 1.1323  decode.d4.loss_cls: 0.0682  decode.d4.loss_mask: 0.4393  decode.d4.loss_dice: 1.1245  decode.d5.loss_cls: 0.0621  decode.d5.loss_mask: 0.4369  decode.d5.loss_dice: 1.1383  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 0.4387  decode.d6.loss_dice: 1.1526  decode.d7.loss_cls: 0.0663  decode.d7.loss_mask: 0.4361  decode.d7.loss_dice: 1.1278  decode.d8.loss_cls: 0.0524  decode.d8.loss_mask: 0.4341  decode.d8.loss_dice: 1.1495
11/15 15:03:16 - mmengine - INFO - Iter(train) [47100/90000]  base_lr: 5.1333e-05 lr: 5.1333e-06  eta: 7:11:40  time: 0.5981  data_time: 0.0105  memory: 10675  grad_norm: 889.4136  loss: 17.2724  decode.loss_cls: 0.0717  decode.loss_mask: 0.4976  decode.loss_dice: 1.1628  decode.d0.loss_cls: 0.1100  decode.d0.loss_mask: 0.4778  decode.d0.loss_dice: 1.1886  decode.d1.loss_cls: 0.0836  decode.d1.loss_mask: 0.4814  decode.d1.loss_dice: 1.1702  decode.d2.loss_cls: 0.0729  decode.d2.loss_mask: 0.5025  decode.d2.loss_dice: 1.1755  decode.d3.loss_cls: 0.0874  decode.d3.loss_mask: 0.4768  decode.d3.loss_dice: 1.1447  decode.d4.loss_cls: 0.1040  decode.d4.loss_mask: 0.4899  decode.d4.loss_dice: 1.1440  decode.d5.loss_cls: 0.0800  decode.d5.loss_mask: 0.4735  decode.d5.loss_dice: 1.1406  decode.d6.loss_cls: 0.0824  decode.d6.loss_mask: 0.4844  decode.d6.loss_dice: 1.1447  decode.d7.loss_cls: 0.0735  decode.d7.loss_mask: 0.4911  decode.d7.loss_dice: 1.1283  decode.d8.loss_cls: 0.0717  decode.d8.loss_mask: 0.5072  decode.d8.loss_dice: 1.1537
11/15 15:03:46 - mmengine - INFO - Iter(train) [47150/90000]  base_lr: 5.1279e-05 lr: 5.1279e-06  eta: 7:11:10  time: 0.5980  data_time: 0.0106  memory: 10692  grad_norm: 488.5088  loss: 18.8995  decode.loss_cls: 0.0774  decode.loss_mask: 0.6222  decode.loss_dice: 1.1572  decode.d0.loss_cls: 0.0993  decode.d0.loss_mask: 0.6620  decode.d0.loss_dice: 1.2679  decode.d1.loss_cls: 0.0761  decode.d1.loss_mask: 0.6344  decode.d1.loss_dice: 1.2011  decode.d2.loss_cls: 0.0686  decode.d2.loss_mask: 0.6344  decode.d2.loss_dice: 1.1692  decode.d3.loss_cls: 0.0748  decode.d3.loss_mask: 0.6380  decode.d3.loss_dice: 1.1589  decode.d4.loss_cls: 0.0661  decode.d4.loss_mask: 0.6538  decode.d4.loss_dice: 1.1635  decode.d5.loss_cls: 0.0685  decode.d5.loss_mask: 0.6262  decode.d5.loss_dice: 1.1669  decode.d6.loss_cls: 0.0679  decode.d6.loss_mask: 0.6384  decode.d6.loss_dice: 1.1848  decode.d7.loss_cls: 0.0697  decode.d7.loss_mask: 0.6246  decode.d7.loss_dice: 1.1666  decode.d8.loss_cls: 0.0701  decode.d8.loss_mask: 0.6182  decode.d8.loss_dice: 1.1725
11/15 15:04:16 - mmengine - INFO - Iter(train) [47200/90000]  base_lr: 5.1225e-05 lr: 5.1225e-06  eta: 7:10:40  time: 0.5987  data_time: 0.0107  memory: 10675  grad_norm: 375.9164  loss: 15.9769  decode.loss_cls: 0.0800  decode.loss_mask: 0.4279  decode.loss_dice: 1.0451  decode.d0.loss_cls: 0.1012  decode.d0.loss_mask: 0.4648  decode.d0.loss_dice: 1.1472  decode.d1.loss_cls: 0.0881  decode.d1.loss_mask: 0.4350  decode.d1.loss_dice: 1.0639  decode.d2.loss_cls: 0.0756  decode.d2.loss_mask: 0.4500  decode.d2.loss_dice: 1.0923  decode.d3.loss_cls: 0.0751  decode.d3.loss_mask: 0.4333  decode.d3.loss_dice: 1.0813  decode.d4.loss_cls: 0.0870  decode.d4.loss_mask: 0.4324  decode.d4.loss_dice: 1.0729  decode.d5.loss_cls: 0.0873  decode.d5.loss_mask: 0.4330  decode.d5.loss_dice: 1.0653  decode.d6.loss_cls: 0.0887  decode.d6.loss_mask: 0.4217  decode.d6.loss_dice: 1.0712  decode.d7.loss_cls: 0.0903  decode.d7.loss_mask: 0.4261  decode.d7.loss_dice: 1.0689  decode.d8.loss_cls: 0.0758  decode.d8.loss_mask: 0.4340  decode.d8.loss_dice: 1.0616
11/15 15:04:46 - mmengine - INFO - Iter(train) [47250/90000]  base_lr: 5.1172e-05 lr: 5.1172e-06  eta: 7:10:09  time: 0.5960  data_time: 0.0105  memory: 10656  grad_norm: 314.6075  loss: 16.5029  decode.loss_cls: 0.0624  decode.loss_mask: 0.5094  decode.loss_dice: 0.9916  decode.d0.loss_cls: 0.0814  decode.d0.loss_mask: 0.6036  decode.d0.loss_dice: 1.0822  decode.d1.loss_cls: 0.0560  decode.d1.loss_mask: 0.7078  decode.d1.loss_dice: 1.0503  decode.d2.loss_cls: 0.0564  decode.d2.loss_mask: 0.7012  decode.d2.loss_dice: 1.0307  decode.d3.loss_cls: 0.0615  decode.d3.loss_mask: 0.6941  decode.d3.loss_dice: 0.9758  decode.d4.loss_cls: 0.0745  decode.d4.loss_mask: 0.5090  decode.d4.loss_dice: 0.9601  decode.d5.loss_cls: 0.0701  decode.d5.loss_mask: 0.5117  decode.d5.loss_dice: 0.9715  decode.d6.loss_cls: 0.0772  decode.d6.loss_mask: 0.5038  decode.d6.loss_dice: 0.9958  decode.d7.loss_cls: 0.0658  decode.d7.loss_mask: 0.5153  decode.d7.loss_dice: 0.9715  decode.d8.loss_cls: 0.0571  decode.d8.loss_mask: 0.5775  decode.d8.loss_dice: 0.9776
11/15 15:05:16 - mmengine - INFO - Iter(train) [47300/90000]  base_lr: 5.1118e-05 lr: 5.1118e-06  eta: 7:09:39  time: 0.5970  data_time: 0.0103  memory: 10641  grad_norm: 223.4207  loss: 17.3599  decode.loss_cls: 0.1079  decode.loss_mask: 0.5272  decode.loss_dice: 1.0858  decode.d0.loss_cls: 0.1161  decode.d0.loss_mask: 0.5336  decode.d0.loss_dice: 1.1707  decode.d1.loss_cls: 0.1283  decode.d1.loss_mask: 0.5169  decode.d1.loss_dice: 1.0912  decode.d2.loss_cls: 0.0873  decode.d2.loss_mask: 0.5377  decode.d2.loss_dice: 1.0991  decode.d3.loss_cls: 0.0897  decode.d3.loss_mask: 0.5219  decode.d3.loss_dice: 1.1399  decode.d4.loss_cls: 0.1027  decode.d4.loss_mask: 0.5198  decode.d4.loss_dice: 1.0837  decode.d5.loss_cls: 0.0970  decode.d5.loss_mask: 0.5189  decode.d5.loss_dice: 1.0893  decode.d6.loss_cls: 0.1035  decode.d6.loss_mask: 0.5199  decode.d6.loss_dice: 1.1005  decode.d7.loss_cls: 0.1015  decode.d7.loss_mask: 0.5232  decode.d7.loss_dice: 1.1039  decode.d8.loss_cls: 0.1038  decode.d8.loss_mask: 0.5322  decode.d8.loss_dice: 1.1071
11/15 15:05:46 - mmengine - INFO - Iter(train) [47350/90000]  base_lr: 5.1064e-05 lr: 5.1064e-06  eta: 7:09:08  time: 0.5960  data_time: 0.0105  memory: 10675  grad_norm: 523.3066  loss: 15.3511  decode.loss_cls: 0.0267  decode.loss_mask: 0.5416  decode.loss_dice: 0.9463  decode.d0.loss_cls: 0.0575  decode.d0.loss_mask: 0.5532  decode.d0.loss_dice: 0.9655  decode.d1.loss_cls: 0.0356  decode.d1.loss_mask: 0.5481  decode.d1.loss_dice: 0.9668  decode.d2.loss_cls: 0.0320  decode.d2.loss_mask: 0.5454  decode.d2.loss_dice: 0.9484  decode.d3.loss_cls: 0.0281  decode.d3.loss_mask: 0.5455  decode.d3.loss_dice: 0.9594  decode.d4.loss_cls: 0.0287  decode.d4.loss_mask: 0.5431  decode.d4.loss_dice: 0.9601  decode.d5.loss_cls: 0.0337  decode.d5.loss_mask: 0.5407  decode.d5.loss_dice: 0.9524  decode.d6.loss_cls: 0.0282  decode.d6.loss_mask: 0.5421  decode.d6.loss_dice: 0.9662  decode.d7.loss_cls: 0.0363  decode.d7.loss_mask: 0.5415  decode.d7.loss_dice: 0.9378  decode.d8.loss_cls: 0.0274  decode.d8.loss_mask: 0.5471  decode.d8.loss_dice: 0.9656
11/15 15:06:16 - mmengine - INFO - Iter(train) [47400/90000]  base_lr: 5.1010e-05 lr: 5.1010e-06  eta: 7:08:38  time: 0.5971  data_time: 0.0106  memory: 10656  grad_norm: 627.9793  loss: 15.0355  decode.loss_cls: 0.0400  decode.loss_mask: 0.5277  decode.loss_dice: 0.9194  decode.d0.loss_cls: 0.0785  decode.d0.loss_mask: 0.5464  decode.d0.loss_dice: 0.9572  decode.d1.loss_cls: 0.0379  decode.d1.loss_mask: 0.5256  decode.d1.loss_dice: 0.9501  decode.d2.loss_cls: 0.0366  decode.d2.loss_mask: 0.5191  decode.d2.loss_dice: 0.9357  decode.d3.loss_cls: 0.0420  decode.d3.loss_mask: 0.5238  decode.d3.loss_dice: 0.9298  decode.d4.loss_cls: 0.0389  decode.d4.loss_mask: 0.5257  decode.d4.loss_dice: 0.9224  decode.d5.loss_cls: 0.0425  decode.d5.loss_mask: 0.5214  decode.d5.loss_dice: 0.9191  decode.d6.loss_cls: 0.0397  decode.d6.loss_mask: 0.5197  decode.d6.loss_dice: 0.9323  decode.d7.loss_cls: 0.0429  decode.d7.loss_mask: 0.5264  decode.d7.loss_dice: 0.9355  decode.d8.loss_cls: 0.0395  decode.d8.loss_mask: 0.5289  decode.d8.loss_dice: 0.9305
11/15 15:06:46 - mmengine - INFO - Iter(train) [47450/90000]  base_lr: 5.0956e-05 lr: 5.0956e-06  eta: 7:08:07  time: 0.5975  data_time: 0.0106  memory: 10656  grad_norm: 328.1911  loss: 15.6548  decode.loss_cls: 0.0739  decode.loss_mask: 0.4223  decode.loss_dice: 1.0463  decode.d0.loss_cls: 0.0933  decode.d0.loss_mask: 0.4323  decode.d0.loss_dice: 1.1199  decode.d1.loss_cls: 0.0685  decode.d1.loss_mask: 0.4377  decode.d1.loss_dice: 1.0739  decode.d2.loss_cls: 0.0710  decode.d2.loss_mask: 0.4361  decode.d2.loss_dice: 1.0532  decode.d3.loss_cls: 0.0789  decode.d3.loss_mask: 0.4327  decode.d3.loss_dice: 1.0634  decode.d4.loss_cls: 0.0617  decode.d4.loss_mask: 0.4376  decode.d4.loss_dice: 1.0363  decode.d5.loss_cls: 0.0648  decode.d5.loss_mask: 0.4369  decode.d5.loss_dice: 1.0625  decode.d6.loss_cls: 0.0660  decode.d6.loss_mask: 0.4322  decode.d6.loss_dice: 1.0488  decode.d7.loss_cls: 0.0766  decode.d7.loss_mask: 0.4296  decode.d7.loss_dice: 1.0383  decode.d8.loss_cls: 0.0633  decode.d8.loss_mask: 0.4338  decode.d8.loss_dice: 1.0629
11/15 15:07:16 - mmengine - INFO - Iter(train) [47500/90000]  base_lr: 5.0902e-05 lr: 5.0902e-06  eta: 7:07:37  time: 0.5962  data_time: 0.0105  memory: 10675  grad_norm: 699.7353  loss: 17.4684  decode.loss_cls: 0.0801  decode.loss_mask: 0.5397  decode.loss_dice: 1.1260  decode.d0.loss_cls: 0.0839  decode.d0.loss_mask: 0.5485  decode.d0.loss_dice: 1.1957  decode.d1.loss_cls: 0.0753  decode.d1.loss_mask: 0.5366  decode.d1.loss_dice: 1.1662  decode.d2.loss_cls: 0.0686  decode.d2.loss_mask: 0.5322  decode.d2.loss_dice: 1.1342  decode.d3.loss_cls: 0.0712  decode.d3.loss_mask: 0.5302  decode.d3.loss_dice: 1.1404  decode.d4.loss_cls: 0.0645  decode.d4.loss_mask: 0.5221  decode.d4.loss_dice: 1.1084  decode.d5.loss_cls: 0.0718  decode.d5.loss_mask: 0.5363  decode.d5.loss_dice: 1.1409  decode.d6.loss_cls: 0.0775  decode.d6.loss_mask: 0.5145  decode.d6.loss_dice: 1.1265  decode.d7.loss_cls: 0.0764  decode.d7.loss_mask: 0.5183  decode.d7.loss_dice: 1.1530  decode.d8.loss_cls: 0.0653  decode.d8.loss_mask: 0.5300  decode.d8.loss_dice: 1.1340
11/15 15:07:45 - mmengine - INFO - Iter(train) [47550/90000]  base_lr: 5.0848e-05 lr: 5.0848e-06  eta: 7:07:07  time: 0.5976  data_time: 0.0105  memory: 10713  grad_norm: 234.1161  loss: 15.2943  decode.loss_cls: 0.0534  decode.loss_mask: 0.4458  decode.loss_dice: 1.0223  decode.d0.loss_cls: 0.0806  decode.d0.loss_mask: 0.4498  decode.d0.loss_dice: 1.0515  decode.d1.loss_cls: 0.0621  decode.d1.loss_mask: 0.4360  decode.d1.loss_dice: 1.0374  decode.d2.loss_cls: 0.0638  decode.d2.loss_mask: 0.4412  decode.d2.loss_dice: 1.0182  decode.d3.loss_cls: 0.0507  decode.d3.loss_mask: 0.4561  decode.d3.loss_dice: 1.0194  decode.d4.loss_cls: 0.0638  decode.d4.loss_mask: 0.4409  decode.d4.loss_dice: 1.0235  decode.d5.loss_cls: 0.0516  decode.d5.loss_mask: 0.4559  decode.d5.loss_dice: 1.0056  decode.d6.loss_cls: 0.0569  decode.d6.loss_mask: 0.4493  decode.d6.loss_dice: 1.0222  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.4374  decode.d7.loss_dice: 1.0115  decode.d8.loss_cls: 0.0555  decode.d8.loss_mask: 0.4489  decode.d8.loss_dice: 1.0230
11/15 15:08:15 - mmengine - INFO - Iter(train) [47600/90000]  base_lr: 5.0794e-05 lr: 5.0794e-06  eta: 7:06:36  time: 0.5978  data_time: 0.0105  memory: 10656  grad_norm: 163.4040  loss: 15.2315  decode.loss_cls: 0.0617  decode.loss_mask: 0.4136  decode.loss_dice: 1.0201  decode.d0.loss_cls: 0.0687  decode.d0.loss_mask: 0.4252  decode.d0.loss_dice: 1.1017  decode.d1.loss_cls: 0.0621  decode.d1.loss_mask: 0.4094  decode.d1.loss_dice: 1.0700  decode.d2.loss_cls: 0.0534  decode.d2.loss_mask: 0.4195  decode.d2.loss_dice: 1.0813  decode.d3.loss_cls: 0.0553  decode.d3.loss_mask: 0.4144  decode.d3.loss_dice: 1.0458  decode.d4.loss_cls: 0.0569  decode.d4.loss_mask: 0.4103  decode.d4.loss_dice: 1.0464  decode.d5.loss_cls: 0.0545  decode.d5.loss_mask: 0.4138  decode.d5.loss_dice: 1.0365  decode.d6.loss_cls: 0.0566  decode.d6.loss_mask: 0.4155  decode.d6.loss_dice: 1.0295  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.4110  decode.d7.loss_dice: 1.0404  decode.d8.loss_cls: 0.0571  decode.d8.loss_mask: 0.4144  decode.d8.loss_dice: 1.0263
11/15 15:08:45 - mmengine - INFO - Iter(train) [47650/90000]  base_lr: 5.0740e-05 lr: 5.0740e-06  eta: 7:06:06  time: 0.5973  data_time: 0.0105  memory: 10656  grad_norm: 312.3389  loss: 15.4437  decode.loss_cls: 0.0421  decode.loss_mask: 0.4745  decode.loss_dice: 0.9968  decode.d0.loss_cls: 0.0720  decode.d0.loss_mask: 0.4880  decode.d0.loss_dice: 1.0956  decode.d1.loss_cls: 0.0433  decode.d1.loss_mask: 0.4850  decode.d1.loss_dice: 1.0368  decode.d2.loss_cls: 0.0415  decode.d2.loss_mask: 0.4789  decode.d2.loss_dice: 1.0023  decode.d3.loss_cls: 0.0444  decode.d3.loss_mask: 0.4801  decode.d3.loss_dice: 1.0060  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.4748  decode.d4.loss_dice: 0.9720  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.4783  decode.d5.loss_dice: 1.0042  decode.d6.loss_cls: 0.0449  decode.d6.loss_mask: 0.4828  decode.d6.loss_dice: 1.0158  decode.d7.loss_cls: 0.0390  decode.d7.loss_mask: 0.4791  decode.d7.loss_dice: 1.0269  decode.d8.loss_cls: 0.0379  decode.d8.loss_mask: 0.4757  decode.d8.loss_dice: 1.0285
11/15 15:09:15 - mmengine - INFO - Iter(train) [47700/90000]  base_lr: 5.0687e-05 lr: 5.0687e-06  eta: 7:05:35  time: 0.5982  data_time: 0.0106  memory: 10675  grad_norm: 405.1845  loss: 14.2279  decode.loss_cls: 0.0610  decode.loss_mask: 0.4512  decode.loss_dice: 0.9064  decode.d0.loss_cls: 0.0819  decode.d0.loss_mask: 0.4808  decode.d0.loss_dice: 0.9906  decode.d1.loss_cls: 0.0557  decode.d1.loss_mask: 0.4644  decode.d1.loss_dice: 0.9106  decode.d2.loss_cls: 0.0639  decode.d2.loss_mask: 0.4528  decode.d2.loss_dice: 0.9136  decode.d3.loss_cls: 0.0643  decode.d3.loss_mask: 0.4485  decode.d3.loss_dice: 0.8705  decode.d4.loss_cls: 0.0625  decode.d4.loss_mask: 0.4443  decode.d4.loss_dice: 0.8715  decode.d5.loss_cls: 0.0697  decode.d5.loss_mask: 0.4460  decode.d5.loss_dice: 0.8846  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.4585  decode.d6.loss_dice: 0.8933  decode.d7.loss_cls: 0.0585  decode.d7.loss_mask: 0.4511  decode.d7.loss_dice: 0.8965  decode.d8.loss_cls: 0.0559  decode.d8.loss_mask: 0.4497  decode.d8.loss_dice: 0.9009
11/15 15:09:45 - mmengine - INFO - Iter(train) [47750/90000]  base_lr: 5.0633e-05 lr: 5.0633e-06  eta: 7:05:05  time: 0.5964  data_time: 0.0105  memory: 10692  grad_norm: 320.5375  loss: 13.4011  decode.loss_cls: 0.0381  decode.loss_mask: 0.4263  decode.loss_dice: 0.8480  decode.d0.loss_cls: 0.0624  decode.d0.loss_mask: 0.4373  decode.d0.loss_dice: 0.9024  decode.d1.loss_cls: 0.0481  decode.d1.loss_mask: 0.4322  decode.d1.loss_dice: 0.8873  decode.d2.loss_cls: 0.0457  decode.d2.loss_mask: 0.4324  decode.d2.loss_dice: 0.8915  decode.d3.loss_cls: 0.0367  decode.d3.loss_mask: 0.4248  decode.d3.loss_dice: 0.8609  decode.d4.loss_cls: 0.0416  decode.d4.loss_mask: 0.4262  decode.d4.loss_dice: 0.8646  decode.d5.loss_cls: 0.0461  decode.d5.loss_mask: 0.4247  decode.d5.loss_dice: 0.8623  decode.d6.loss_cls: 0.0371  decode.d6.loss_mask: 0.4228  decode.d6.loss_dice: 0.8679  decode.d7.loss_cls: 0.0496  decode.d7.loss_mask: 0.4237  decode.d7.loss_dice: 0.8330  decode.d8.loss_cls: 0.0466  decode.d8.loss_mask: 0.4213  decode.d8.loss_dice: 0.8594
11/15 15:10:15 - mmengine - INFO - Iter(train) [47800/90000]  base_lr: 5.0579e-05 lr: 5.0579e-06  eta: 7:04:34  time: 0.5984  data_time: 0.0107  memory: 10713  grad_norm: 501.0040  loss: 18.3862  decode.loss_cls: 0.0857  decode.loss_mask: 0.6084  decode.loss_dice: 1.1043  decode.d0.loss_cls: 0.0833  decode.d0.loss_mask: 0.6502  decode.d0.loss_dice: 1.1854  decode.d1.loss_cls: 0.0758  decode.d1.loss_mask: 0.6332  decode.d1.loss_dice: 1.1431  decode.d2.loss_cls: 0.0904  decode.d2.loss_mask: 0.6290  decode.d2.loss_dice: 1.1296  decode.d3.loss_cls: 0.0885  decode.d3.loss_mask: 0.6253  decode.d3.loss_dice: 1.1245  decode.d4.loss_cls: 0.0844  decode.d4.loss_mask: 0.6322  decode.d4.loss_dice: 1.1387  decode.d5.loss_cls: 0.0845  decode.d5.loss_mask: 0.6221  decode.d5.loss_dice: 1.1300  decode.d6.loss_cls: 0.0940  decode.d6.loss_mask: 0.6048  decode.d6.loss_dice: 1.1153  decode.d7.loss_cls: 0.0904  decode.d7.loss_mask: 0.6128  decode.d7.loss_dice: 1.1092  decode.d8.loss_cls: 0.0850  decode.d8.loss_mask: 0.6096  decode.d8.loss_dice: 1.1167
11/15 15:10:45 - mmengine - INFO - Iter(train) [47850/90000]  base_lr: 5.0525e-05 lr: 5.0525e-06  eta: 7:04:04  time: 0.5977  data_time: 0.0105  memory: 10675  grad_norm: 384.9182  loss: 15.8437  decode.loss_cls: 0.0486  decode.loss_mask: 0.4909  decode.loss_dice: 1.0250  decode.d0.loss_cls: 0.0711  decode.d0.loss_mask: 0.5193  decode.d0.loss_dice: 1.1170  decode.d1.loss_cls: 0.0520  decode.d1.loss_mask: 0.5061  decode.d1.loss_dice: 1.0580  decode.d2.loss_cls: 0.0573  decode.d2.loss_mask: 0.4965  decode.d2.loss_dice: 1.0047  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.4946  decode.d3.loss_dice: 1.0206  decode.d4.loss_cls: 0.0568  decode.d4.loss_mask: 0.4937  decode.d4.loss_dice: 1.0234  decode.d5.loss_cls: 0.0523  decode.d5.loss_mask: 0.4953  decode.d5.loss_dice: 1.0125  decode.d6.loss_cls: 0.0476  decode.d6.loss_mask: 0.4956  decode.d6.loss_dice: 1.0235  decode.d7.loss_cls: 0.0495  decode.d7.loss_mask: 0.4980  decode.d7.loss_dice: 1.0360  decode.d8.loss_cls: 0.0423  decode.d8.loss_mask: 0.4907  decode.d8.loss_dice: 1.0143
11/15 15:11:15 - mmengine - INFO - Iter(train) [47900/90000]  base_lr: 5.0471e-05 lr: 5.0471e-06  eta: 7:03:33  time: 0.5987  data_time: 0.0107  memory: 10692  grad_norm: 361.1842  loss: 16.0781  decode.loss_cls: 0.0522  decode.loss_mask: 0.4507  decode.loss_dice: 1.0863  decode.d0.loss_cls: 0.0736  decode.d0.loss_mask: 0.4851  decode.d0.loss_dice: 1.1479  decode.d1.loss_cls: 0.0432  decode.d1.loss_mask: 0.4572  decode.d1.loss_dice: 1.1240  decode.d2.loss_cls: 0.0483  decode.d2.loss_mask: 0.4584  decode.d2.loss_dice: 1.1194  decode.d3.loss_cls: 0.0398  decode.d3.loss_mask: 0.4571  decode.d3.loss_dice: 1.1049  decode.d4.loss_cls: 0.0481  decode.d4.loss_mask: 0.4577  decode.d4.loss_dice: 1.0931  decode.d5.loss_cls: 0.0464  decode.d5.loss_mask: 0.4535  decode.d5.loss_dice: 1.0909  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.4480  decode.d6.loss_dice: 1.0872  decode.d7.loss_cls: 0.0531  decode.d7.loss_mask: 0.4472  decode.d7.loss_dice: 1.0536  decode.d8.loss_cls: 0.0561  decode.d8.loss_mask: 0.4504  decode.d8.loss_dice: 1.0962
11/15 15:11:45 - mmengine - INFO - Iter(train) [47950/90000]  base_lr: 5.0417e-05 lr: 5.0417e-06  eta: 7:03:03  time: 0.5987  data_time: 0.0106  memory: 10656  grad_norm: 495.5932  loss: 17.0339  decode.loss_cls: 0.0749  decode.loss_mask: 0.4993  decode.loss_dice: 1.1179  decode.d0.loss_cls: 0.0850  decode.d0.loss_mask: 0.5416  decode.d0.loss_dice: 1.1505  decode.d1.loss_cls: 0.0657  decode.d1.loss_mask: 0.5234  decode.d1.loss_dice: 1.1336  decode.d2.loss_cls: 0.0630  decode.d2.loss_mask: 0.5138  decode.d2.loss_dice: 1.1317  decode.d3.loss_cls: 0.0631  decode.d3.loss_mask: 0.5205  decode.d3.loss_dice: 1.1071  decode.d4.loss_cls: 0.0644  decode.d4.loss_mask: 0.5220  decode.d4.loss_dice: 1.1217  decode.d5.loss_cls: 0.0708  decode.d5.loss_mask: 0.5043  decode.d5.loss_dice: 1.1226  decode.d6.loss_cls: 0.0666  decode.d6.loss_mask: 0.5027  decode.d6.loss_dice: 1.0957  decode.d7.loss_cls: 0.0731  decode.d7.loss_mask: 0.5099  decode.d7.loss_dice: 1.1032  decode.d8.loss_cls: 0.0703  decode.d8.loss_mask: 0.5090  decode.d8.loss_dice: 1.1065
11/15 15:12:15 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 15:12:15 - mmengine - INFO - Iter(train) [48000/90000]  base_lr: 5.0363e-05 lr: 5.0363e-06  eta: 7:02:33  time: 0.5986  data_time: 0.0106  memory: 10609  grad_norm: 1012.8266  loss: 19.6313  decode.loss_cls: 0.0717  decode.loss_mask: 0.6295  decode.loss_dice: 1.2179  decode.d0.loss_cls: 0.0847  decode.d0.loss_mask: 0.6582  decode.d0.loss_dice: 1.3626  decode.d1.loss_cls: 0.0839  decode.d1.loss_mask: 0.6433  decode.d1.loss_dice: 1.2313  decode.d2.loss_cls: 0.0827  decode.d2.loss_mask: 0.6386  decode.d2.loss_dice: 1.2413  decode.d3.loss_cls: 0.0698  decode.d3.loss_mask: 0.6387  decode.d3.loss_dice: 1.2320  decode.d4.loss_cls: 0.0902  decode.d4.loss_mask: 0.6318  decode.d4.loss_dice: 1.2213  decode.d5.loss_cls: 0.0712  decode.d5.loss_mask: 0.6438  decode.d5.loss_dice: 1.2469  decode.d6.loss_cls: 0.0813  decode.d6.loss_mask: 0.6213  decode.d6.loss_dice: 1.2305  decode.d7.loss_cls: 0.0852  decode.d7.loss_mask: 0.6440  decode.d7.loss_dice: 1.2261  decode.d8.loss_cls: 0.0773  decode.d8.loss_mask: 0.6445  decode.d8.loss_dice: 1.2295
11/15 15:12:45 - mmengine - INFO - Iter(train) [48050/90000]  base_lr: 5.0309e-05 lr: 5.0309e-06  eta: 7:02:02  time: 0.5983  data_time: 0.0105  memory: 10675  grad_norm: 513.5396  loss: 16.6784  decode.loss_cls: 0.0754  decode.loss_mask: 0.4982  decode.loss_dice: 1.0818  decode.d0.loss_cls: 0.0911  decode.d0.loss_mask: 0.5372  decode.d0.loss_dice: 1.1217  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.5045  decode.d1.loss_dice: 1.0944  decode.d2.loss_cls: 0.0748  decode.d2.loss_mask: 0.5023  decode.d2.loss_dice: 1.1013  decode.d3.loss_cls: 0.0687  decode.d3.loss_mask: 0.5062  decode.d3.loss_dice: 1.0888  decode.d4.loss_cls: 0.0763  decode.d4.loss_mask: 0.5007  decode.d4.loss_dice: 1.0606  decode.d5.loss_cls: 0.0783  decode.d5.loss_mask: 0.5006  decode.d5.loss_dice: 1.0698  decode.d6.loss_cls: 0.0695  decode.d6.loss_mask: 0.5012  decode.d6.loss_dice: 1.1037  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.4952  decode.d7.loss_dice: 1.0504  decode.d8.loss_cls: 0.0770  decode.d8.loss_mask: 0.5019  decode.d8.loss_dice: 1.0988
11/15 15:13:14 - mmengine - INFO - Iter(train) [48100/90000]  base_lr: 5.0255e-05 lr: 5.0255e-06  eta: 7:01:32  time: 0.5969  data_time: 0.0106  memory: 10675  grad_norm: 292.9257  loss: 17.8822  decode.loss_cls: 0.0465  decode.loss_mask: 0.5870  decode.loss_dice: 1.1429  decode.d0.loss_cls: 0.0760  decode.d0.loss_mask: 0.6302  decode.d0.loss_dice: 1.1934  decode.d1.loss_cls: 0.0648  decode.d1.loss_mask: 0.5873  decode.d1.loss_dice: 1.1565  decode.d2.loss_cls: 0.0529  decode.d2.loss_mask: 0.5869  decode.d2.loss_dice: 1.1460  decode.d3.loss_cls: 0.0441  decode.d3.loss_mask: 0.5896  decode.d3.loss_dice: 1.1510  decode.d4.loss_cls: 0.0595  decode.d4.loss_mask: 0.5766  decode.d4.loss_dice: 1.1250  decode.d5.loss_cls: 0.0475  decode.d5.loss_mask: 0.5739  decode.d5.loss_dice: 1.1574  decode.d6.loss_cls: 0.0486  decode.d6.loss_mask: 0.5733  decode.d6.loss_dice: 1.1429  decode.d7.loss_cls: 0.0587  decode.d7.loss_mask: 0.5775  decode.d7.loss_dice: 1.1138  decode.d8.loss_cls: 0.0589  decode.d8.loss_mask: 0.5825  decode.d8.loss_dice: 1.1309
11/15 15:13:44 - mmengine - INFO - Iter(train) [48150/90000]  base_lr: 5.0201e-05 lr: 5.0201e-06  eta: 7:01:01  time: 0.5980  data_time: 0.0105  memory: 10675  grad_norm: 324.8185  loss: 16.4064  decode.loss_cls: 0.0475  decode.loss_mask: 0.4966  decode.loss_dice: 1.1133  decode.d0.loss_cls: 0.0764  decode.d0.loss_mask: 0.5023  decode.d0.loss_dice: 1.1150  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.4972  decode.d1.loss_dice: 1.0956  decode.d2.loss_cls: 0.0402  decode.d2.loss_mask: 0.4954  decode.d2.loss_dice: 1.0782  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.5044  decode.d3.loss_dice: 1.0774  decode.d4.loss_cls: 0.0369  decode.d4.loss_mask: 0.5043  decode.d4.loss_dice: 1.1009  decode.d5.loss_cls: 0.0430  decode.d5.loss_mask: 0.5082  decode.d5.loss_dice: 1.0935  decode.d6.loss_cls: 0.0462  decode.d6.loss_mask: 0.4957  decode.d6.loss_dice: 1.0907  decode.d7.loss_cls: 0.0466  decode.d7.loss_mask: 0.4947  decode.d7.loss_dice: 1.0840  decode.d8.loss_cls: 0.0424  decode.d8.loss_mask: 0.4901  decode.d8.loss_dice: 1.0934
11/15 15:14:16 - mmengine - INFO - Iter(train) [48200/90000]  base_lr: 5.0147e-05 lr: 5.0147e-06  eta: 7:00:33  time: 0.5964  data_time: 0.0106  memory: 10626  grad_norm: 303.7582  loss: 17.7027  decode.loss_cls: 0.0473  decode.loss_mask: 0.6128  decode.loss_dice: 1.0933  decode.d0.loss_cls: 0.0957  decode.d0.loss_mask: 0.6450  decode.d0.loss_dice: 1.1824  decode.d1.loss_cls: 0.0534  decode.d1.loss_mask: 0.6119  decode.d1.loss_dice: 1.0970  decode.d2.loss_cls: 0.0648  decode.d2.loss_mask: 0.6230  decode.d2.loss_dice: 1.1310  decode.d3.loss_cls: 0.0554  decode.d3.loss_mask: 0.5924  decode.d3.loss_dice: 1.0794  decode.d4.loss_cls: 0.0525  decode.d4.loss_mask: 0.5905  decode.d4.loss_dice: 1.0755  decode.d5.loss_cls: 0.0501  decode.d5.loss_mask: 0.6089  decode.d5.loss_dice: 1.0820  decode.d6.loss_cls: 0.0552  decode.d6.loss_mask: 0.5857  decode.d6.loss_dice: 1.0813  decode.d7.loss_cls: 0.0516  decode.d7.loss_mask: 0.6030  decode.d7.loss_dice: 1.1380  decode.d8.loss_cls: 0.0497  decode.d8.loss_mask: 0.6052  decode.d8.loss_dice: 1.0891
11/15 15:14:46 - mmengine - INFO - Iter(train) [48250/90000]  base_lr: 5.0093e-05 lr: 5.0093e-06  eta: 7:00:02  time: 0.5980  data_time: 0.0105  memory: 10692  grad_norm: 399.2263  loss: 17.2007  decode.loss_cls: 0.0999  decode.loss_mask: 0.5065  decode.loss_dice: 1.0661  decode.d0.loss_cls: 0.1122  decode.d0.loss_mask: 0.5247  decode.d0.loss_dice: 1.2001  decode.d1.loss_cls: 0.1142  decode.d1.loss_mask: 0.5117  decode.d1.loss_dice: 1.1186  decode.d2.loss_cls: 0.0837  decode.d2.loss_mask: 0.5209  decode.d2.loss_dice: 1.1429  decode.d3.loss_cls: 0.0928  decode.d3.loss_mask: 0.5072  decode.d3.loss_dice: 1.1062  decode.d4.loss_cls: 0.0908  decode.d4.loss_mask: 0.5069  decode.d4.loss_dice: 1.0857  decode.d5.loss_cls: 0.0925  decode.d5.loss_mask: 0.5245  decode.d5.loss_dice: 1.0598  decode.d6.loss_cls: 0.0919  decode.d6.loss_mask: 0.5092  decode.d6.loss_dice: 1.1115  decode.d7.loss_cls: 0.0949  decode.d7.loss_mask: 0.5222  decode.d7.loss_dice: 1.0945  decode.d8.loss_cls: 0.1011  decode.d8.loss_mask: 0.5124  decode.d8.loss_dice: 1.0953
11/15 15:15:16 - mmengine - INFO - Iter(train) [48300/90000]  base_lr: 5.0039e-05 lr: 5.0039e-06  eta: 6:59:32  time: 0.5975  data_time: 0.0107  memory: 10656  grad_norm: 315.2692  loss: 17.0636  decode.loss_cls: 0.0666  decode.loss_mask: 0.5087  decode.loss_dice: 1.1464  decode.d0.loss_cls: 0.0805  decode.d0.loss_mask: 0.5456  decode.d0.loss_dice: 1.1890  decode.d1.loss_cls: 0.0698  decode.d1.loss_mask: 0.5305  decode.d1.loss_dice: 1.1360  decode.d2.loss_cls: 0.0787  decode.d2.loss_mask: 0.5128  decode.d2.loss_dice: 1.1114  decode.d3.loss_cls: 0.0797  decode.d3.loss_mask: 0.5062  decode.d3.loss_dice: 1.0940  decode.d4.loss_cls: 0.0732  decode.d4.loss_mask: 0.5052  decode.d4.loss_dice: 1.1151  decode.d5.loss_cls: 0.0646  decode.d5.loss_mask: 0.5115  decode.d5.loss_dice: 1.1130  decode.d6.loss_cls: 0.0627  decode.d6.loss_mask: 0.5069  decode.d6.loss_dice: 1.0870  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.5080  decode.d7.loss_dice: 1.0906  decode.d8.loss_cls: 0.0677  decode.d8.loss_mask: 0.5096  decode.d8.loss_dice: 1.1297
11/15 15:15:46 - mmengine - INFO - Iter(train) [48350/90000]  base_lr: 4.9985e-05 lr: 4.9985e-06  eta: 6:59:01  time: 0.5970  data_time: 0.0106  memory: 10656  grad_norm: 205.8251  loss: 16.6952  decode.loss_cls: 0.0570  decode.loss_mask: 0.5210  decode.loss_dice: 1.0702  decode.d0.loss_cls: 0.0733  decode.d0.loss_mask: 0.5291  decode.d0.loss_dice: 1.1522  decode.d1.loss_cls: 0.0738  decode.d1.loss_mask: 0.5130  decode.d1.loss_dice: 1.0820  decode.d2.loss_cls: 0.0539  decode.d2.loss_mask: 0.5258  decode.d2.loss_dice: 1.1037  decode.d3.loss_cls: 0.0642  decode.d3.loss_mask: 0.5276  decode.d3.loss_dice: 1.0552  decode.d4.loss_cls: 0.0692  decode.d4.loss_mask: 0.5249  decode.d4.loss_dice: 1.0716  decode.d5.loss_cls: 0.0601  decode.d5.loss_mask: 0.5233  decode.d5.loss_dice: 1.0931  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.5188  decode.d6.loss_dice: 1.0747  decode.d7.loss_cls: 0.0731  decode.d7.loss_mask: 0.5101  decode.d7.loss_dice: 1.0464  decode.d8.loss_cls: 0.0484  decode.d8.loss_mask: 0.5184  decode.d8.loss_dice: 1.0952
11/15 15:16:16 - mmengine - INFO - Iter(train) [48400/90000]  base_lr: 4.9931e-05 lr: 4.9931e-06  eta: 6:58:31  time: 0.5960  data_time: 0.0107  memory: 10692  grad_norm: 337.3985  loss: 17.6727  decode.loss_cls: 0.0796  decode.loss_mask: 0.6443  decode.loss_dice: 1.0099  decode.d0.loss_cls: 0.1010  decode.d0.loss_mask: 0.6662  decode.d0.loss_dice: 1.0992  decode.d1.loss_cls: 0.0776  decode.d1.loss_mask: 0.6530  decode.d1.loss_dice: 1.0429  decode.d2.loss_cls: 0.0744  decode.d2.loss_mask: 0.6476  decode.d2.loss_dice: 1.0193  decode.d3.loss_cls: 0.0673  decode.d3.loss_mask: 0.6604  decode.d3.loss_dice: 1.0385  decode.d4.loss_cls: 0.0620  decode.d4.loss_mask: 0.6575  decode.d4.loss_dice: 1.0401  decode.d5.loss_cls: 0.0702  decode.d5.loss_mask: 0.6554  decode.d5.loss_dice: 1.0386  decode.d6.loss_cls: 0.0661  decode.d6.loss_mask: 0.6460  decode.d6.loss_dice: 1.0327  decode.d7.loss_cls: 0.0701  decode.d7.loss_mask: 0.6402  decode.d7.loss_dice: 1.0293  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.6494  decode.d8.loss_dice: 1.0600
11/15 15:16:46 - mmengine - INFO - Iter(train) [48450/90000]  base_lr: 4.9877e-05 lr: 4.9877e-06  eta: 6:58:01  time: 0.5965  data_time: 0.0106  memory: 10675  grad_norm: 270.6562  loss: 16.5260  decode.loss_cls: 0.0827  decode.loss_mask: 0.4435  decode.loss_dice: 1.0949  decode.d0.loss_cls: 0.0945  decode.d0.loss_mask: 0.4754  decode.d0.loss_dice: 1.2213  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.4524  decode.d1.loss_dice: 1.1478  decode.d2.loss_cls: 0.0793  decode.d2.loss_mask: 0.4521  decode.d2.loss_dice: 1.1283  decode.d3.loss_cls: 0.0826  decode.d3.loss_mask: 0.4439  decode.d3.loss_dice: 1.0802  decode.d4.loss_cls: 0.0719  decode.d4.loss_mask: 0.4516  decode.d4.loss_dice: 1.1062  decode.d5.loss_cls: 0.0850  decode.d5.loss_mask: 0.4404  decode.d5.loss_dice: 1.0652  decode.d6.loss_cls: 0.0696  decode.d6.loss_mask: 0.4419  decode.d6.loss_dice: 1.1268  decode.d7.loss_cls: 0.0668  decode.d7.loss_mask: 0.4593  decode.d7.loss_dice: 1.1446  decode.d8.loss_cls: 0.0639  decode.d8.loss_mask: 0.4546  decode.d8.loss_dice: 1.1177
11/15 15:17:16 - mmengine - INFO - Iter(train) [48500/90000]  base_lr: 4.9823e-05 lr: 4.9823e-06  eta: 6:57:30  time: 0.5980  data_time: 0.0106  memory: 10656  grad_norm: 254.4101  loss: 15.6651  decode.loss_cls: 0.0522  decode.loss_mask: 0.4722  decode.loss_dice: 1.0281  decode.d0.loss_cls: 0.0732  decode.d0.loss_mask: 0.4801  decode.d0.loss_dice: 1.1438  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.4666  decode.d1.loss_dice: 1.0488  decode.d2.loss_cls: 0.0556  decode.d2.loss_mask: 0.4679  decode.d2.loss_dice: 1.0328  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.4653  decode.d3.loss_dice: 0.9982  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 0.4686  decode.d4.loss_dice: 1.0035  decode.d5.loss_cls: 0.0594  decode.d5.loss_mask: 0.4691  decode.d5.loss_dice: 1.0273  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.4693  decode.d6.loss_dice: 1.0161  decode.d7.loss_cls: 0.0608  decode.d7.loss_mask: 0.4726  decode.d7.loss_dice: 1.0304  decode.d8.loss_cls: 0.0535  decode.d8.loss_mask: 0.4635  decode.d8.loss_dice: 1.0286
11/15 15:17:46 - mmengine - INFO - Iter(train) [48550/90000]  base_lr: 4.9769e-05 lr: 4.9769e-06  eta: 6:57:00  time: 0.5975  data_time: 0.0106  memory: 10675  grad_norm: 261.7422  loss: 15.8862  decode.loss_cls: 0.0727  decode.loss_mask: 0.4605  decode.loss_dice: 0.9918  decode.d0.loss_cls: 0.0777  decode.d0.loss_mask: 0.4908  decode.d0.loss_dice: 1.1088  decode.d1.loss_cls: 0.0807  decode.d1.loss_mask: 0.4716  decode.d1.loss_dice: 1.0203  decode.d2.loss_cls: 0.0736  decode.d2.loss_mask: 0.4943  decode.d2.loss_dice: 1.0472  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.4763  decode.d3.loss_dice: 1.0319  decode.d4.loss_cls: 0.0665  decode.d4.loss_mask: 0.4880  decode.d4.loss_dice: 1.0243  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.4798  decode.d5.loss_dice: 1.0281  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.4856  decode.d6.loss_dice: 1.0144  decode.d7.loss_cls: 0.0739  decode.d7.loss_mask: 0.4888  decode.d7.loss_dice: 1.0484  decode.d8.loss_cls: 0.0658  decode.d8.loss_mask: 0.4804  decode.d8.loss_dice: 1.0341
11/15 15:18:16 - mmengine - INFO - Iter(train) [48600/90000]  base_lr: 4.9715e-05 lr: 4.9715e-06  eta: 6:56:29  time: 0.5978  data_time: 0.0109  memory: 10641  grad_norm: 313.0342  loss: 17.6193  decode.loss_cls: 0.0778  decode.loss_mask: 0.5523  decode.loss_dice: 1.1129  decode.d0.loss_cls: 0.0808  decode.d0.loss_mask: 0.5719  decode.d0.loss_dice: 1.2331  decode.d1.loss_cls: 0.0731  decode.d1.loss_mask: 0.5617  decode.d1.loss_dice: 1.1461  decode.d2.loss_cls: 0.0620  decode.d2.loss_mask: 0.5536  decode.d2.loss_dice: 1.1485  decode.d3.loss_cls: 0.0743  decode.d3.loss_mask: 0.5488  decode.d3.loss_dice: 1.1101  decode.d4.loss_cls: 0.0770  decode.d4.loss_mask: 0.5563  decode.d4.loss_dice: 1.1026  decode.d5.loss_cls: 0.0671  decode.d5.loss_mask: 0.5833  decode.d5.loss_dice: 1.1230  decode.d6.loss_cls: 0.0669  decode.d6.loss_mask: 0.5707  decode.d6.loss_dice: 1.1004  decode.d7.loss_cls: 0.0682  decode.d7.loss_mask: 0.5494  decode.d7.loss_dice: 1.1122  decode.d8.loss_cls: 0.0711  decode.d8.loss_mask: 0.5408  decode.d8.loss_dice: 1.1231
11/15 15:18:46 - mmengine - INFO - Iter(train) [48650/90000]  base_lr: 4.9661e-05 lr: 4.9661e-06  eta: 6:55:59  time: 0.5975  data_time: 0.0107  memory: 10713  grad_norm: 338.7087  loss: 17.3601  decode.loss_cls: 0.0615  decode.loss_mask: 0.4824  decode.loss_dice: 1.1884  decode.d0.loss_cls: 0.0923  decode.d0.loss_mask: 0.5078  decode.d0.loss_dice: 1.2021  decode.d1.loss_cls: 0.0856  decode.d1.loss_mask: 0.4749  decode.d1.loss_dice: 1.1506  decode.d2.loss_cls: 0.0716  decode.d2.loss_mask: 0.4832  decode.d2.loss_dice: 1.1956  decode.d3.loss_cls: 0.0584  decode.d3.loss_mask: 0.4859  decode.d3.loss_dice: 1.1742  decode.d4.loss_cls: 0.0737  decode.d4.loss_mask: 0.4825  decode.d4.loss_dice: 1.1489  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.4819  decode.d5.loss_dice: 1.1496  decode.d6.loss_cls: 0.0538  decode.d6.loss_mask: 0.4957  decode.d6.loss_dice: 1.1881  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.4948  decode.d7.loss_dice: 1.2088  decode.d8.loss_cls: 0.0565  decode.d8.loss_mask: 0.5001  decode.d8.loss_dice: 1.1783
11/15 15:19:15 - mmengine - INFO - Iter(train) [48700/90000]  base_lr: 4.9607e-05 lr: 4.9607e-06  eta: 6:55:29  time: 0.5973  data_time: 0.0106  memory: 10675  grad_norm: 530.7712  loss: 21.2029  decode.loss_cls: 0.0843  decode.loss_mask: 0.8006  decode.loss_dice: 1.2331  decode.d0.loss_cls: 0.0919  decode.d0.loss_mask: 0.8893  decode.d0.loss_dice: 1.3006  decode.d1.loss_cls: 0.1030  decode.d1.loss_mask: 0.7702  decode.d1.loss_dice: 1.2632  decode.d2.loss_cls: 0.0808  decode.d2.loss_mask: 0.7892  decode.d2.loss_dice: 1.2313  decode.d3.loss_cls: 0.0862  decode.d3.loss_mask: 0.7861  decode.d3.loss_dice: 1.2324  decode.d4.loss_cls: 0.0840  decode.d4.loss_mask: 0.8222  decode.d4.loss_dice: 1.2270  decode.d5.loss_cls: 0.0778  decode.d5.loss_mask: 0.7674  decode.d5.loss_dice: 1.2196  decode.d6.loss_cls: 0.0801  decode.d6.loss_mask: 0.7991  decode.d6.loss_dice: 1.2234  decode.d7.loss_cls: 0.0871  decode.d7.loss_mask: 0.7746  decode.d7.loss_dice: 1.2171  decode.d8.loss_cls: 0.0950  decode.d8.loss_mask: 0.7731  decode.d8.loss_dice: 1.2132
11/15 15:19:45 - mmengine - INFO - Iter(train) [48750/90000]  base_lr: 4.9553e-05 lr: 4.9553e-06  eta: 6:54:58  time: 0.5976  data_time: 0.0106  memory: 10675  grad_norm: 384.7067  loss: 18.1037  decode.loss_cls: 0.0996  decode.loss_mask: 0.4985  decode.loss_dice: 1.1869  decode.d0.loss_cls: 0.1203  decode.d0.loss_mask: 0.5784  decode.d0.loss_dice: 1.2863  decode.d1.loss_cls: 0.1013  decode.d1.loss_mask: 0.5679  decode.d1.loss_dice: 1.2553  decode.d2.loss_cls: 0.1132  decode.d2.loss_mask: 0.5209  decode.d2.loss_dice: 1.1853  decode.d3.loss_cls: 0.0990  decode.d3.loss_mask: 0.5180  decode.d3.loss_dice: 1.1521  decode.d4.loss_cls: 0.0992  decode.d4.loss_mask: 0.4989  decode.d4.loss_dice: 1.1414  decode.d5.loss_cls: 0.0968  decode.d5.loss_mask: 0.5036  decode.d5.loss_dice: 1.1674  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.4946  decode.d6.loss_dice: 1.1393  decode.d7.loss_cls: 0.0820  decode.d7.loss_mask: 0.5467  decode.d7.loss_dice: 1.1769  decode.d8.loss_cls: 0.1048  decode.d8.loss_mask: 0.5101  decode.d8.loss_dice: 1.1685
11/15 15:20:15 - mmengine - INFO - Iter(train) [48800/90000]  base_lr: 4.9499e-05 lr: 4.9499e-06  eta: 6:54:28  time: 0.5979  data_time: 0.0106  memory: 10692  grad_norm: 515.5138  loss: 16.0640  decode.loss_cls: 0.0638  decode.loss_mask: 0.4670  decode.loss_dice: 1.0709  decode.d0.loss_cls: 0.1000  decode.d0.loss_mask: 0.4807  decode.d0.loss_dice: 1.1081  decode.d1.loss_cls: 0.0552  decode.d1.loss_mask: 0.4892  decode.d1.loss_dice: 1.1194  decode.d2.loss_cls: 0.0554  decode.d2.loss_mask: 0.4819  decode.d2.loss_dice: 1.0617  decode.d3.loss_cls: 0.0657  decode.d3.loss_mask: 0.4746  decode.d3.loss_dice: 1.0539  decode.d4.loss_cls: 0.0617  decode.d4.loss_mask: 0.4714  decode.d4.loss_dice: 1.0642  decode.d5.loss_cls: 0.0624  decode.d5.loss_mask: 0.4836  decode.d5.loss_dice: 1.0764  decode.d6.loss_cls: 0.0746  decode.d6.loss_mask: 0.4491  decode.d6.loss_dice: 1.0402  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.4676  decode.d7.loss_dice: 1.0408  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.4509  decode.d8.loss_dice: 1.0318
11/15 15:20:45 - mmengine - INFO - Iter(train) [48850/90000]  base_lr: 4.9445e-05 lr: 4.9445e-06  eta: 6:53:57  time: 0.6076  data_time: 0.0106  memory: 10728  grad_norm: 262.3911  loss: 16.4152  decode.loss_cls: 0.0610  decode.loss_mask: 0.4702  decode.loss_dice: 1.0959  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.4970  decode.d0.loss_dice: 1.1852  decode.d1.loss_cls: 0.0706  decode.d1.loss_mask: 0.4830  decode.d1.loss_dice: 1.1477  decode.d2.loss_cls: 0.0770  decode.d2.loss_mask: 0.4599  decode.d2.loss_dice: 1.1187  decode.d3.loss_cls: 0.0563  decode.d3.loss_mask: 0.4709  decode.d3.loss_dice: 1.0906  decode.d4.loss_cls: 0.0490  decode.d4.loss_mask: 0.4753  decode.d4.loss_dice: 1.0816  decode.d5.loss_cls: 0.0619  decode.d5.loss_mask: 0.4747  decode.d5.loss_dice: 1.0828  decode.d6.loss_cls: 0.0565  decode.d6.loss_mask: 0.4711  decode.d6.loss_dice: 1.0757  decode.d7.loss_cls: 0.0678  decode.d7.loss_mask: 0.4776  decode.d7.loss_dice: 1.0785  decode.d8.loss_cls: 0.0560  decode.d8.loss_mask: 0.4721  decode.d8.loss_dice: 1.0767
11/15 15:21:15 - mmengine - INFO - Iter(train) [48900/90000]  base_lr: 4.9391e-05 lr: 4.9391e-06  eta: 6:53:27  time: 0.5987  data_time: 0.0108  memory: 10675  grad_norm: 233.2572  loss: 16.3906  decode.loss_cls: 0.0667  decode.loss_mask: 0.4097  decode.loss_dice: 1.1351  decode.d0.loss_cls: 0.0990  decode.d0.loss_mask: 0.4347  decode.d0.loss_dice: 1.2313  decode.d1.loss_cls: 0.0770  decode.d1.loss_mask: 0.4287  decode.d1.loss_dice: 1.1684  decode.d2.loss_cls: 0.0881  decode.d2.loss_mask: 0.4112  decode.d2.loss_dice: 1.1574  decode.d3.loss_cls: 0.0809  decode.d3.loss_mask: 0.4039  decode.d3.loss_dice: 1.1261  decode.d4.loss_cls: 0.0771  decode.d4.loss_mask: 0.4094  decode.d4.loss_dice: 1.1498  decode.d5.loss_cls: 0.0692  decode.d5.loss_mask: 0.4125  decode.d5.loss_dice: 1.1487  decode.d6.loss_cls: 0.0745  decode.d6.loss_mask: 0.4051  decode.d6.loss_dice: 1.0915  decode.d7.loss_cls: 0.0741  decode.d7.loss_mask: 0.4122  decode.d7.loss_dice: 1.1149  decode.d8.loss_cls: 0.0626  decode.d8.loss_mask: 0.4133  decode.d8.loss_dice: 1.1575
11/15 15:21:45 - mmengine - INFO - Iter(train) [48950/90000]  base_lr: 4.9336e-05 lr: 4.9336e-06  eta: 6:52:57  time: 0.5981  data_time: 0.0108  memory: 10692  grad_norm: 356.8043  loss: 17.2946  decode.loss_cls: 0.0499  decode.loss_mask: 0.5882  decode.loss_dice: 1.0790  decode.d0.loss_cls: 0.0665  decode.d0.loss_mask: 0.5949  decode.d0.loss_dice: 1.1543  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.5870  decode.d1.loss_dice: 1.0686  decode.d2.loss_cls: 0.0535  decode.d2.loss_mask: 0.5908  decode.d2.loss_dice: 1.1001  decode.d3.loss_cls: 0.0513  decode.d3.loss_mask: 0.5813  decode.d3.loss_dice: 1.0667  decode.d4.loss_cls: 0.0553  decode.d4.loss_mask: 0.5877  decode.d4.loss_dice: 1.0674  decode.d5.loss_cls: 0.0439  decode.d5.loss_mask: 0.5892  decode.d5.loss_dice: 1.0816  decode.d6.loss_cls: 0.0454  decode.d6.loss_mask: 0.5834  decode.d6.loss_dice: 1.1023  decode.d7.loss_cls: 0.0488  decode.d7.loss_mask: 0.5799  decode.d7.loss_dice: 1.0937  decode.d8.loss_cls: 0.0620  decode.d8.loss_mask: 0.5906  decode.d8.loss_dice: 1.0679
11/15 15:22:15 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 15:22:15 - mmengine - INFO - Iter(train) [49000/90000]  base_lr: 4.9282e-05 lr: 4.9282e-06  eta: 6:52:26  time: 0.5973  data_time: 0.0105  memory: 10656  grad_norm: 1170.6503  loss: 15.6482  decode.loss_cls: 0.0650  decode.loss_mask: 0.4420  decode.loss_dice: 1.0504  decode.d0.loss_cls: 0.0910  decode.d0.loss_mask: 0.4663  decode.d0.loss_dice: 1.1553  decode.d1.loss_cls: 0.0700  decode.d1.loss_mask: 0.4509  decode.d1.loss_dice: 1.0839  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.4452  decode.d2.loss_dice: 1.0271  decode.d3.loss_cls: 0.0586  decode.d3.loss_mask: 0.4474  decode.d3.loss_dice: 1.0324  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.4482  decode.d4.loss_dice: 1.0417  decode.d5.loss_cls: 0.0659  decode.d5.loss_mask: 0.4459  decode.d5.loss_dice: 1.0142  decode.d6.loss_cls: 0.0643  decode.d6.loss_mask: 0.4472  decode.d6.loss_dice: 1.0051  decode.d7.loss_cls: 0.0599  decode.d7.loss_mask: 0.4493  decode.d7.loss_dice: 1.0461  decode.d8.loss_cls: 0.0741  decode.d8.loss_mask: 0.4462  decode.d8.loss_dice: 1.0151
11/15 15:22:45 - mmengine - INFO - Iter(train) [49050/90000]  base_lr: 4.9228e-05 lr: 4.9228e-06  eta: 6:51:56  time: 0.6006  data_time: 0.0127  memory: 10656  grad_norm: 233.3361  loss: 15.5134  decode.loss_cls: 0.0578  decode.loss_mask: 0.4640  decode.loss_dice: 1.0007  decode.d0.loss_cls: 0.0735  decode.d0.loss_mask: 0.4876  decode.d0.loss_dice: 1.0862  decode.d1.loss_cls: 0.0469  decode.d1.loss_mask: 0.4896  decode.d1.loss_dice: 1.0633  decode.d2.loss_cls: 0.0582  decode.d2.loss_mask: 0.4719  decode.d2.loss_dice: 1.0365  decode.d3.loss_cls: 0.0389  decode.d3.loss_mask: 0.4758  decode.d3.loss_dice: 1.0313  decode.d4.loss_cls: 0.0515  decode.d4.loss_mask: 0.4596  decode.d4.loss_dice: 1.0231  decode.d5.loss_cls: 0.0682  decode.d5.loss_mask: 0.4582  decode.d5.loss_dice: 1.0126  decode.d6.loss_cls: 0.0563  decode.d6.loss_mask: 0.4581  decode.d6.loss_dice: 1.0067  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.4504  decode.d7.loss_dice: 0.9923  decode.d8.loss_cls: 0.0459  decode.d8.loss_mask: 0.4674  decode.d8.loss_dice: 1.0212
11/15 15:23:15 - mmengine - INFO - Iter(train) [49100/90000]  base_lr: 4.9174e-05 lr: 4.9174e-06  eta: 6:51:25  time: 0.5987  data_time: 0.0106  memory: 10713  grad_norm: 445.9538  loss: 17.1069  decode.loss_cls: 0.0764  decode.loss_mask: 0.5170  decode.loss_dice: 1.1051  decode.d0.loss_cls: 0.0812  decode.d0.loss_mask: 0.4970  decode.d0.loss_dice: 1.1951  decode.d1.loss_cls: 0.0730  decode.d1.loss_mask: 0.4929  decode.d1.loss_dice: 1.1475  decode.d2.loss_cls: 0.0854  decode.d2.loss_mask: 0.4979  decode.d2.loss_dice: 1.1135  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.5124  decode.d3.loss_dice: 1.0953  decode.d4.loss_cls: 0.0799  decode.d4.loss_mask: 0.5138  decode.d4.loss_dice: 1.1263  decode.d5.loss_cls: 0.0810  decode.d5.loss_mask: 0.5182  decode.d5.loss_dice: 1.1172  decode.d6.loss_cls: 0.0755  decode.d6.loss_mask: 0.5182  decode.d6.loss_dice: 1.1292  decode.d7.loss_cls: 0.0904  decode.d7.loss_mask: 0.5053  decode.d7.loss_dice: 1.0671  decode.d8.loss_cls: 0.0732  decode.d8.loss_mask: 0.5180  decode.d8.loss_dice: 1.1235
11/15 15:23:45 - mmengine - INFO - Iter(train) [49150/90000]  base_lr: 4.9120e-05 lr: 4.9120e-06  eta: 6:50:55  time: 0.6013  data_time: 0.0106  memory: 10675  grad_norm: 339.0883  loss: 17.8222  decode.loss_cls: 0.0927  decode.loss_mask: 0.5071  decode.loss_dice: 1.1561  decode.d0.loss_cls: 0.1214  decode.d0.loss_mask: 0.5298  decode.d0.loss_dice: 1.2314  decode.d1.loss_cls: 0.0873  decode.d1.loss_mask: 0.5322  decode.d1.loss_dice: 1.2065  decode.d2.loss_cls: 0.0855  decode.d2.loss_mask: 0.5135  decode.d2.loss_dice: 1.1626  decode.d3.loss_cls: 0.0968  decode.d3.loss_mask: 0.5067  decode.d3.loss_dice: 1.1604  decode.d4.loss_cls: 0.0973  decode.d4.loss_mask: 0.5093  decode.d4.loss_dice: 1.1802  decode.d5.loss_cls: 0.0947  decode.d5.loss_mask: 0.5089  decode.d5.loss_dice: 1.1524  decode.d6.loss_cls: 0.0823  decode.d6.loss_mask: 0.5161  decode.d6.loss_dice: 1.1656  decode.d7.loss_cls: 0.0882  decode.d7.loss_mask: 0.5119  decode.d7.loss_dice: 1.1816  decode.d8.loss_cls: 0.0780  decode.d8.loss_mask: 0.5094  decode.d8.loss_dice: 1.1564
11/15 15:24:15 - mmengine - INFO - Iter(train) [49200/90000]  base_lr: 4.9066e-05 lr: 4.9066e-06  eta: 6:50:25  time: 0.5970  data_time: 0.0106  memory: 10675  grad_norm: 263.0905  loss: 14.9292  decode.loss_cls: 0.0675  decode.loss_mask: 0.4800  decode.loss_dice: 0.9395  decode.d0.loss_cls: 0.0724  decode.d0.loss_mask: 0.5195  decode.d0.loss_dice: 0.9962  decode.d1.loss_cls: 0.0842  decode.d1.loss_mask: 0.4856  decode.d1.loss_dice: 0.9317  decode.d2.loss_cls: 0.0759  decode.d2.loss_mask: 0.4708  decode.d2.loss_dice: 0.9347  decode.d3.loss_cls: 0.0627  decode.d3.loss_mask: 0.4731  decode.d3.loss_dice: 0.9507  decode.d4.loss_cls: 0.0673  decode.d4.loss_mask: 0.4761  decode.d4.loss_dice: 0.9552  decode.d5.loss_cls: 0.0762  decode.d5.loss_mask: 0.4735  decode.d5.loss_dice: 0.9258  decode.d6.loss_cls: 0.0722  decode.d6.loss_mask: 0.4772  decode.d6.loss_dice: 0.9155  decode.d7.loss_cls: 0.0615  decode.d7.loss_mask: 0.4860  decode.d7.loss_dice: 0.9404  decode.d8.loss_cls: 0.0714  decode.d8.loss_mask: 0.4782  decode.d8.loss_dice: 0.9081
11/15 15:24:45 - mmengine - INFO - Iter(train) [49250/90000]  base_lr: 4.9012e-05 lr: 4.9012e-06  eta: 6:49:54  time: 0.6006  data_time: 0.0107  memory: 10656  grad_norm: 312.3427  loss: 17.3049  decode.loss_cls: 0.0630  decode.loss_mask: 0.5746  decode.loss_dice: 1.0516  decode.d0.loss_cls: 0.0930  decode.d0.loss_mask: 0.6035  decode.d0.loss_dice: 1.1635  decode.d1.loss_cls: 0.0662  decode.d1.loss_mask: 0.5865  decode.d1.loss_dice: 1.0810  decode.d2.loss_cls: 0.0595  decode.d2.loss_mask: 0.5921  decode.d2.loss_dice: 1.1181  decode.d3.loss_cls: 0.0536  decode.d3.loss_mask: 0.5722  decode.d3.loss_dice: 1.0571  decode.d4.loss_cls: 0.0661  decode.d4.loss_mask: 0.5753  decode.d4.loss_dice: 1.0513  decode.d5.loss_cls: 0.0663  decode.d5.loss_mask: 0.5727  decode.d5.loss_dice: 1.0808  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.5740  decode.d6.loss_dice: 1.0607  decode.d7.loss_cls: 0.0573  decode.d7.loss_mask: 0.6019  decode.d7.loss_dice: 1.0658  decode.d8.loss_cls: 0.0831  decode.d8.loss_mask: 0.5955  decode.d8.loss_dice: 1.0558
11/15 15:25:15 - mmengine - INFO - Iter(train) [49300/90000]  base_lr: 4.8958e-05 lr: 4.8958e-06  eta: 6:49:24  time: 0.5986  data_time: 0.0106  memory: 10692  grad_norm: 299.2310  loss: 15.8860  decode.loss_cls: 0.0825  decode.loss_mask: 0.5011  decode.loss_dice: 1.0305  decode.d0.loss_cls: 0.1090  decode.d0.loss_mask: 0.4474  decode.d0.loss_dice: 1.0840  decode.d1.loss_cls: 0.0831  decode.d1.loss_mask: 0.4358  decode.d1.loss_dice: 1.0478  decode.d2.loss_cls: 0.0698  decode.d2.loss_mask: 0.4490  decode.d2.loss_dice: 1.0389  decode.d3.loss_cls: 0.0766  decode.d3.loss_mask: 0.4464  decode.d3.loss_dice: 1.0132  decode.d4.loss_cls: 0.0775  decode.d4.loss_mask: 0.4612  decode.d4.loss_dice: 1.0389  decode.d5.loss_cls: 0.0638  decode.d5.loss_mask: 0.4927  decode.d5.loss_dice: 1.0509  decode.d6.loss_cls: 0.0877  decode.d6.loss_mask: 0.4888  decode.d6.loss_dice: 1.0310  decode.d7.loss_cls: 0.0765  decode.d7.loss_mask: 0.4528  decode.d7.loss_dice: 1.0644  decode.d8.loss_cls: 0.0844  decode.d8.loss_mask: 0.4960  decode.d8.loss_dice: 1.0042
11/15 15:25:45 - mmengine - INFO - Iter(train) [49350/90000]  base_lr: 4.8904e-05 lr: 4.8904e-06  eta: 6:48:53  time: 0.5978  data_time: 0.0108  memory: 10692  grad_norm: 417.6003  loss: 17.7762  decode.loss_cls: 0.0670  decode.loss_mask: 0.5489  decode.loss_dice: 1.1377  decode.d0.loss_cls: 0.0699  decode.d0.loss_mask: 0.5486  decode.d0.loss_dice: 1.2323  decode.d1.loss_cls: 0.0805  decode.d1.loss_mask: 0.5385  decode.d1.loss_dice: 1.1999  decode.d2.loss_cls: 0.0616  decode.d2.loss_mask: 0.5374  decode.d2.loss_dice: 1.1719  decode.d3.loss_cls: 0.0653  decode.d3.loss_mask: 0.5344  decode.d3.loss_dice: 1.1561  decode.d4.loss_cls: 0.0719  decode.d4.loss_mask: 0.5413  decode.d4.loss_dice: 1.1501  decode.d5.loss_cls: 0.0651  decode.d5.loss_mask: 0.5438  decode.d5.loss_dice: 1.1759  decode.d6.loss_cls: 0.0642  decode.d6.loss_mask: 0.5490  decode.d6.loss_dice: 1.1427  decode.d7.loss_cls: 0.0670  decode.d7.loss_mask: 0.5505  decode.d7.loss_dice: 1.1467  decode.d8.loss_cls: 0.0775  decode.d8.loss_mask: 0.5479  decode.d8.loss_dice: 1.1326
11/15 15:26:15 - mmengine - INFO - Iter(train) [49400/90000]  base_lr: 4.8849e-05 lr: 4.8849e-06  eta: 6:48:23  time: 0.5964  data_time: 0.0106  memory: 10692  grad_norm: 639.7442  loss: 18.1278  decode.loss_cls: 0.0872  decode.loss_mask: 0.6146  decode.loss_dice: 1.0706  decode.d0.loss_cls: 0.1007  decode.d0.loss_mask: 0.6529  decode.d0.loss_dice: 1.2148  decode.d1.loss_cls: 0.0985  decode.d1.loss_mask: 0.6331  decode.d1.loss_dice: 1.1213  decode.d2.loss_cls: 0.1027  decode.d2.loss_mask: 0.6189  decode.d2.loss_dice: 1.0626  decode.d3.loss_cls: 0.1134  decode.d3.loss_mask: 0.6117  decode.d3.loss_dice: 1.0658  decode.d4.loss_cls: 0.1004  decode.d4.loss_mask: 0.6097  decode.d4.loss_dice: 1.1202  decode.d5.loss_cls: 0.0970  decode.d5.loss_mask: 0.6036  decode.d5.loss_dice: 1.0928  decode.d6.loss_cls: 0.1033  decode.d6.loss_mask: 0.6052  decode.d6.loss_dice: 1.0609  decode.d7.loss_cls: 0.1037  decode.d7.loss_mask: 0.6059  decode.d7.loss_dice: 1.0774  decode.d8.loss_cls: 0.0789  decode.d8.loss_mask: 0.6145  decode.d8.loss_dice: 1.0858
11/15 15:26:45 - mmengine - INFO - Iter(train) [49450/90000]  base_lr: 4.8795e-05 lr: 4.8795e-06  eta: 6:47:53  time: 0.5969  data_time: 0.0108  memory: 10675  grad_norm: 457.8027  loss: 17.1884  decode.loss_cls: 0.0309  decode.loss_mask: 0.5343  decode.loss_dice: 1.1552  decode.d0.loss_cls: 0.0668  decode.d0.loss_mask: 0.5449  decode.d0.loss_dice: 1.2286  decode.d1.loss_cls: 0.0313  decode.d1.loss_mask: 0.5375  decode.d1.loss_dice: 1.1536  decode.d2.loss_cls: 0.0332  decode.d2.loss_mask: 0.5369  decode.d2.loss_dice: 1.1373  decode.d3.loss_cls: 0.0351  decode.d3.loss_mask: 0.5323  decode.d3.loss_dice: 1.1296  decode.d4.loss_cls: 0.0295  decode.d4.loss_mask: 0.5397  decode.d4.loss_dice: 1.1368  decode.d5.loss_cls: 0.0296  decode.d5.loss_mask: 0.5377  decode.d5.loss_dice: 1.1415  decode.d6.loss_cls: 0.0336  decode.d6.loss_mask: 0.5253  decode.d6.loss_dice: 1.1149  decode.d7.loss_cls: 0.0345  decode.d7.loss_mask: 0.5265  decode.d7.loss_dice: 1.1463  decode.d8.loss_cls: 0.0336  decode.d8.loss_mask: 0.5331  decode.d8.loss_dice: 1.1383
11/15 15:27:14 - mmengine - INFO - Iter(train) [49500/90000]  base_lr: 4.8741e-05 lr: 4.8741e-06  eta: 6:47:22  time: 0.5978  data_time: 0.0107  memory: 10692  grad_norm: 225.8878  loss: 16.2493  decode.loss_cls: 0.0610  decode.loss_mask: 0.4686  decode.loss_dice: 1.0994  decode.d0.loss_cls: 0.1003  decode.d0.loss_mask: 0.4868  decode.d0.loss_dice: 1.1795  decode.d1.loss_cls: 0.0835  decode.d1.loss_mask: 0.4778  decode.d1.loss_dice: 1.1166  decode.d2.loss_cls: 0.0734  decode.d2.loss_mask: 0.4643  decode.d2.loss_dice: 1.0720  decode.d3.loss_cls: 0.0688  decode.d3.loss_mask: 0.4675  decode.d3.loss_dice: 1.0517  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 0.4656  decode.d4.loss_dice: 1.0631  decode.d5.loss_cls: 0.0592  decode.d5.loss_mask: 0.4643  decode.d5.loss_dice: 1.0707  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.4652  decode.d6.loss_dice: 1.0869  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.4692  decode.d7.loss_dice: 1.0892  decode.d8.loss_cls: 0.0545  decode.d8.loss_mask: 0.4659  decode.d8.loss_dice: 1.0366
11/15 15:27:44 - mmengine - INFO - Iter(train) [49550/90000]  base_lr: 4.8687e-05 lr: 4.8687e-06  eta: 6:46:52  time: 0.6003  data_time: 0.0109  memory: 10641  grad_norm: 562.6407  loss: 18.0630  decode.loss_cls: 0.0671  decode.loss_mask: 0.5411  decode.loss_dice: 1.1808  decode.d0.loss_cls: 0.0951  decode.d0.loss_mask: 0.5291  decode.d0.loss_dice: 1.2742  decode.d1.loss_cls: 0.0627  decode.d1.loss_mask: 0.5261  decode.d1.loss_dice: 1.2482  decode.d2.loss_cls: 0.0817  decode.d2.loss_mask: 0.5248  decode.d2.loss_dice: 1.2050  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.5330  decode.d3.loss_dice: 1.1927  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.5365  decode.d4.loss_dice: 1.1705  decode.d5.loss_cls: 0.0723  decode.d5.loss_mask: 0.5344  decode.d5.loss_dice: 1.1894  decode.d6.loss_cls: 0.0807  decode.d6.loss_mask: 0.5347  decode.d6.loss_dice: 1.1751  decode.d7.loss_cls: 0.0791  decode.d7.loss_mask: 0.5364  decode.d7.loss_dice: 1.1714  decode.d8.loss_cls: 0.0853  decode.d8.loss_mask: 0.5398  decode.d8.loss_dice: 1.1601
11/15 15:28:14 - mmengine - INFO - Iter(train) [49600/90000]  base_lr: 4.8633e-05 lr: 4.8633e-06  eta: 6:46:22  time: 0.5976  data_time: 0.0104  memory: 10692  grad_norm: 333.4255  loss: 16.4791  decode.loss_cls: 0.0736  decode.loss_mask: 0.4560  decode.loss_dice: 1.0852  decode.d0.loss_cls: 0.0775  decode.d0.loss_mask: 0.4812  decode.d0.loss_dice: 1.2215  decode.d1.loss_cls: 0.0885  decode.d1.loss_mask: 0.4601  decode.d1.loss_dice: 1.1218  decode.d2.loss_cls: 0.0729  decode.d2.loss_mask: 0.4637  decode.d2.loss_dice: 1.1259  decode.d3.loss_cls: 0.0685  decode.d3.loss_mask: 0.4545  decode.d3.loss_dice: 1.1017  decode.d4.loss_cls: 0.0711  decode.d4.loss_mask: 0.4545  decode.d4.loss_dice: 1.1170  decode.d5.loss_cls: 0.0716  decode.d5.loss_mask: 0.4556  decode.d5.loss_dice: 1.1033  decode.d6.loss_cls: 0.0770  decode.d6.loss_mask: 0.4559  decode.d6.loss_dice: 1.0871  decode.d7.loss_cls: 0.0845  decode.d7.loss_mask: 0.4509  decode.d7.loss_dice: 1.0802  decode.d8.loss_cls: 0.0851  decode.d8.loss_mask: 0.4514  decode.d8.loss_dice: 1.0811
11/15 15:28:44 - mmengine - INFO - Iter(train) [49650/90000]  base_lr: 4.8579e-05 lr: 4.8579e-06  eta: 6:45:51  time: 0.5984  data_time: 0.0106  memory: 10692  grad_norm: 396.2140  loss: 16.4577  decode.loss_cls: 0.0729  decode.loss_mask: 0.4326  decode.loss_dice: 1.1313  decode.d0.loss_cls: 0.0746  decode.d0.loss_mask: 0.4414  decode.d0.loss_dice: 1.2457  decode.d1.loss_cls: 0.0847  decode.d1.loss_mask: 0.4316  decode.d1.loss_dice: 1.1460  decode.d2.loss_cls: 0.0669  decode.d2.loss_mask: 0.4252  decode.d2.loss_dice: 1.1483  decode.d3.loss_cls: 0.0716  decode.d3.loss_mask: 0.4208  decode.d3.loss_dice: 1.1321  decode.d4.loss_cls: 0.0837  decode.d4.loss_mask: 0.4182  decode.d4.loss_dice: 1.1039  decode.d5.loss_cls: 0.0676  decode.d5.loss_mask: 0.4259  decode.d5.loss_dice: 1.1367  decode.d6.loss_cls: 0.0754  decode.d6.loss_mask: 0.4230  decode.d6.loss_dice: 1.1177  decode.d7.loss_cls: 0.0641  decode.d7.loss_mask: 0.4346  decode.d7.loss_dice: 1.1313  decode.d8.loss_cls: 0.0736  decode.d8.loss_mask: 0.4214  decode.d8.loss_dice: 1.1551
11/15 15:29:14 - mmengine - INFO - Iter(train) [49700/90000]  base_lr: 4.8524e-05 lr: 4.8524e-06  eta: 6:45:21  time: 0.5971  data_time: 0.0104  memory: 10675  grad_norm: 424.5341  loss: 16.2051  decode.loss_cls: 0.0510  decode.loss_mask: 0.5452  decode.loss_dice: 1.0387  decode.d0.loss_cls: 0.0691  decode.d0.loss_mask: 0.5675  decode.d0.loss_dice: 1.0400  decode.d1.loss_cls: 0.0447  decode.d1.loss_mask: 0.5402  decode.d1.loss_dice: 1.0339  decode.d2.loss_cls: 0.0437  decode.d2.loss_mask: 0.5433  decode.d2.loss_dice: 1.0303  decode.d3.loss_cls: 0.0478  decode.d3.loss_mask: 0.5410  decode.d3.loss_dice: 1.0300  decode.d4.loss_cls: 0.0493  decode.d4.loss_mask: 0.5356  decode.d4.loss_dice: 1.0024  decode.d5.loss_cls: 0.0401  decode.d5.loss_mask: 0.5370  decode.d5.loss_dice: 1.0183  decode.d6.loss_cls: 0.0552  decode.d6.loss_mask: 0.5507  decode.d6.loss_dice: 1.0296  decode.d7.loss_cls: 0.0643  decode.d7.loss_mask: 0.5390  decode.d7.loss_dice: 1.0078  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.5444  decode.d8.loss_dice: 1.0044
11/15 15:29:44 - mmengine - INFO - Iter(train) [49750/90000]  base_lr: 4.8470e-05 lr: 4.8470e-06  eta: 6:44:50  time: 0.5970  data_time: 0.0106  memory: 10713  grad_norm: 467.6317  loss: 18.1830  decode.loss_cls: 0.0442  decode.loss_mask: 0.5843  decode.loss_dice: 1.1383  decode.d0.loss_cls: 0.0837  decode.d0.loss_mask: 0.6153  decode.d0.loss_dice: 1.2144  decode.d1.loss_cls: 0.0435  decode.d1.loss_mask: 0.6096  decode.d1.loss_dice: 1.1844  decode.d2.loss_cls: 0.0522  decode.d2.loss_mask: 0.5898  decode.d2.loss_dice: 1.1701  decode.d3.loss_cls: 0.0345  decode.d3.loss_mask: 0.5915  decode.d3.loss_dice: 1.2214  decode.d4.loss_cls: 0.0389  decode.d4.loss_mask: 0.5852  decode.d4.loss_dice: 1.1926  decode.d5.loss_cls: 0.0384  decode.d5.loss_mask: 0.5837  decode.d5.loss_dice: 1.1889  decode.d6.loss_cls: 0.0434  decode.d6.loss_mask: 0.5861  decode.d6.loss_dice: 1.1552  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 0.5858  decode.d7.loss_dice: 1.1716  decode.d8.loss_cls: 0.0479  decode.d8.loss_mask: 0.5711  decode.d8.loss_dice: 1.1784
11/15 15:30:14 - mmengine - INFO - Iter(train) [49800/90000]  base_lr: 4.8416e-05 lr: 4.8416e-06  eta: 6:44:20  time: 0.5975  data_time: 0.0104  memory: 10675  grad_norm: 357.8503  loss: 17.6818  decode.loss_cls: 0.0858  decode.loss_mask: 0.4920  decode.loss_dice: 1.1800  decode.d0.loss_cls: 0.0831  decode.d0.loss_mask: 0.5200  decode.d0.loss_dice: 1.2808  decode.d1.loss_cls: 0.1000  decode.d1.loss_mask: 0.4895  decode.d1.loss_dice: 1.1969  decode.d2.loss_cls: 0.0876  decode.d2.loss_mask: 0.4820  decode.d2.loss_dice: 1.2036  decode.d3.loss_cls: 0.0888  decode.d3.loss_mask: 0.4834  decode.d3.loss_dice: 1.1665  decode.d4.loss_cls: 0.0900  decode.d4.loss_mask: 0.4873  decode.d4.loss_dice: 1.1681  decode.d5.loss_cls: 0.0910  decode.d5.loss_mask: 0.4861  decode.d5.loss_dice: 1.1774  decode.d6.loss_cls: 0.0883  decode.d6.loss_mask: 0.4876  decode.d6.loss_dice: 1.1714  decode.d7.loss_cls: 0.0954  decode.d7.loss_mask: 0.4822  decode.d7.loss_dice: 1.1672  decode.d8.loss_cls: 0.0878  decode.d8.loss_mask: 0.4875  decode.d8.loss_dice: 1.1744
11/15 15:30:44 - mmengine - INFO - Iter(train) [49850/90000]  base_lr: 4.8362e-05 lr: 4.8362e-06  eta: 6:43:49  time: 0.5997  data_time: 0.0106  memory: 10692  grad_norm: 487.8795  loss: 18.3246  decode.loss_cls: 0.0727  decode.loss_mask: 0.5396  decode.loss_dice: 1.1792  decode.d0.loss_cls: 0.0973  decode.d0.loss_mask: 0.5910  decode.d0.loss_dice: 1.3239  decode.d1.loss_cls: 0.0986  decode.d1.loss_mask: 0.5754  decode.d1.loss_dice: 1.1883  decode.d2.loss_cls: 0.0877  decode.d2.loss_mask: 0.5404  decode.d2.loss_dice: 1.1732  decode.d3.loss_cls: 0.0911  decode.d3.loss_mask: 0.5610  decode.d3.loss_dice: 1.1901  decode.d4.loss_cls: 0.0877  decode.d4.loss_mask: 0.5559  decode.d4.loss_dice: 1.1588  decode.d5.loss_cls: 0.0884  decode.d5.loss_mask: 0.5424  decode.d5.loss_dice: 1.1744  decode.d6.loss_cls: 0.0826  decode.d6.loss_mask: 0.5499  decode.d6.loss_dice: 1.1783  decode.d7.loss_cls: 0.0963  decode.d7.loss_mask: 0.5403  decode.d7.loss_dice: 1.1740  decode.d8.loss_cls: 0.0746  decode.d8.loss_mask: 0.5393  decode.d8.loss_dice: 1.1724
11/15 15:31:14 - mmengine - INFO - Iter(train) [49900/90000]  base_lr: 4.8308e-05 lr: 4.8308e-06  eta: 6:43:19  time: 0.5974  data_time: 0.0104  memory: 10713  grad_norm: 383.8941  loss: 18.0391  decode.loss_cls: 0.0671  decode.loss_mask: 0.5976  decode.loss_dice: 1.1381  decode.d0.loss_cls: 0.0914  decode.d0.loss_mask: 0.5878  decode.d0.loss_dice: 1.1937  decode.d1.loss_cls: 0.0824  decode.d1.loss_mask: 0.5961  decode.d1.loss_dice: 1.1486  decode.d2.loss_cls: 0.0763  decode.d2.loss_mask: 0.5968  decode.d2.loss_dice: 1.1278  decode.d3.loss_cls: 0.0689  decode.d3.loss_mask: 0.5908  decode.d3.loss_dice: 1.1480  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 0.5905  decode.d4.loss_dice: 1.0997  decode.d5.loss_cls: 0.0778  decode.d5.loss_mask: 0.5952  decode.d5.loss_dice: 1.1168  decode.d6.loss_cls: 0.0617  decode.d6.loss_mask: 0.5966  decode.d6.loss_dice: 1.1542  decode.d7.loss_cls: 0.0712  decode.d7.loss_mask: 0.5948  decode.d7.loss_dice: 1.1163  decode.d8.loss_cls: 0.0726  decode.d8.loss_mask: 0.5943  decode.d8.loss_dice: 1.1163
11/15 15:31:43 - mmengine - INFO - Iter(train) [49950/90000]  base_lr: 4.8253e-05 lr: 4.8253e-06  eta: 6:42:49  time: 0.5987  data_time: 0.0107  memory: 10656  grad_norm: 382.9988  loss: 16.7238  decode.loss_cls: 0.0586  decode.loss_mask: 0.5025  decode.loss_dice: 1.0701  decode.d0.loss_cls: 0.0805  decode.d0.loss_mask: 0.5396  decode.d0.loss_dice: 1.1471  decode.d1.loss_cls: 0.0570  decode.d1.loss_mask: 0.5137  decode.d1.loss_dice: 1.1330  decode.d2.loss_cls: 0.0644  decode.d2.loss_mask: 0.5056  decode.d2.loss_dice: 1.1055  decode.d3.loss_cls: 0.0634  decode.d3.loss_mask: 0.5058  decode.d3.loss_dice: 1.0610  decode.d4.loss_cls: 0.0590  decode.d4.loss_mask: 0.5078  decode.d4.loss_dice: 1.0814  decode.d5.loss_cls: 0.0572  decode.d5.loss_mask: 0.5168  decode.d5.loss_dice: 1.1059  decode.d6.loss_cls: 0.0654  decode.d6.loss_mask: 0.5036  decode.d6.loss_dice: 1.1036  decode.d7.loss_cls: 0.0580  decode.d7.loss_mask: 0.5164  decode.d7.loss_dice: 1.0846  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.5044  decode.d8.loss_dice: 1.0870
11/15 15:32:13 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 15:32:13 - mmengine - INFO - Iter(train) [50000/90000]  base_lr: 4.8199e-05 lr: 4.8199e-06  eta: 6:42:18  time: 0.5971  data_time: 0.0104  memory: 10656  grad_norm: 230.2230  loss: 17.4674  decode.loss_cls: 0.0638  decode.loss_mask: 0.5437  decode.loss_dice: 1.1613  decode.d0.loss_cls: 0.1035  decode.d0.loss_mask: 0.5395  decode.d0.loss_dice: 1.1856  decode.d1.loss_cls: 0.0899  decode.d1.loss_mask: 0.5156  decode.d1.loss_dice: 1.1354  decode.d2.loss_cls: 0.0966  decode.d2.loss_mask: 0.5063  decode.d2.loss_dice: 1.1095  decode.d3.loss_cls: 0.0716  decode.d3.loss_mask: 0.5081  decode.d3.loss_dice: 1.1570  decode.d4.loss_cls: 0.0820  decode.d4.loss_mask: 0.5099  decode.d4.loss_dice: 1.1434  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.5185  decode.d5.loss_dice: 1.1691  decode.d6.loss_cls: 0.0745  decode.d6.loss_mask: 0.5162  decode.d6.loss_dice: 1.1334  decode.d7.loss_cls: 0.0788  decode.d7.loss_mask: 0.5129  decode.d7.loss_dice: 1.1514  decode.d8.loss_cls: 0.0836  decode.d8.loss_mask: 0.5145  decode.d8.loss_dice: 1.1244
11/15 15:32:13 - mmengine - INFO - Saving checkpoint at 50000 iterations
11/15 15:32:32 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:22  time: 0.3083  data_time: 0.0043  memory: 4095  
11/15 15:32:48 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:05  time: 0.3087  data_time: 0.0043  memory: 4095  
11/15 15:33:03 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:48  time: 0.3083  data_time: 0.0039  memory: 4095  
11/15 15:33:19 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3094  data_time: 0.0040  memory: 4095  
11/15 15:33:34 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3084  data_time: 0.0039  memory: 4095  
11/15 15:33:50 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:02  time: 0.3086  data_time: 0.0040  memory: 4095  
11/15 15:34:05 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3088  data_time: 0.0039  memory: 4095  
11/15 15:34:20 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:30  time: 0.3089  data_time: 0.0039  memory: 4095  
11/15 15:34:36 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3088  data_time: 0.0040  memory: 4095  
11/15 15:34:51 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3083  data_time: 0.0036  memory: 4095  
11/15 15:34:51 - mmengine - INFO - per class results:
11/15 15:34:51 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 98.28 | 98.78 |
|    sidewalk   | 86.02 | 94.42 |
|    building   | 92.65 | 96.98 |
|      wall     | 60.59 | 73.72 |
|     fence     | 59.16 | 66.63 |
|      pole     | 67.15 | 78.92 |
| traffic light |  70.9 | 81.34 |
|  traffic sign | 80.68 |  85.4 |
|   vegetation  | 92.24 | 96.37 |
|    terrain    | 63.31 | 76.22 |
|      sky      | 94.44 |  96.0 |
|     person    | 82.13 | 89.48 |
|     rider     | 62.22 | 81.93 |
|      car      | 95.22 | 97.45 |
|     truck     | 84.45 |  91.7 |
|      bus      | 81.93 | 86.36 |
|     train     |  68.8 | 79.92 |
|   motorcycle  | 65.91 | 83.58 |
|    bicycle    | 78.29 | 87.73 |
+---------------+-------+-------+
11/15 15:34:51 - mmengine - INFO - Iter(val) [500/500]    aAcc: 96.1600  mIoU: 78.1200  mAcc: 86.4700  data_time: 0.0045  time: 0.3096
11/15 15:34:51 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024/best_mIoU_iter_45000.pth is removed
11/15 15:34:53 - mmengine - INFO - The best checkpoint with 78.1200 mIoU at 50000 iter is saved to best_mIoU_iter_50000.pth.
11/15 15:35:26 - mmengine - INFO - Iter(train) [50050/90000]  base_lr: 4.8145e-05 lr: 4.8145e-06  eta: 6:41:52  time: 0.5987  data_time: 0.0106  memory: 10656  grad_norm: 326.1054  loss: 16.9740  decode.loss_cls: 0.0507  decode.loss_mask: 0.5685  decode.loss_dice: 1.0703  decode.d0.loss_cls: 0.0883  decode.d0.loss_mask: 0.5489  decode.d0.loss_dice: 1.1379  decode.d1.loss_cls: 0.0705  decode.d1.loss_mask: 0.5655  decode.d1.loss_dice: 1.0935  decode.d2.loss_cls: 0.0497  decode.d2.loss_mask: 0.5699  decode.d2.loss_dice: 1.0697  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.5643  decode.d3.loss_dice: 1.0631  decode.d4.loss_cls: 0.0492  decode.d4.loss_mask: 0.5654  decode.d4.loss_dice: 1.0719  decode.d5.loss_cls: 0.0486  decode.d5.loss_mask: 0.5672  decode.d5.loss_dice: 1.0730  decode.d6.loss_cls: 0.0506  decode.d6.loss_mask: 0.5439  decode.d6.loss_dice: 1.0963  decode.d7.loss_cls: 0.0488  decode.d7.loss_mask: 0.5666  decode.d7.loss_dice: 1.0767  decode.d8.loss_cls: 0.0511  decode.d8.loss_mask: 0.5328  decode.d8.loss_dice: 1.0721
11/15 15:35:56 - mmengine - INFO - Iter(train) [50100/90000]  base_lr: 4.8091e-05 lr: 4.8091e-06  eta: 6:41:21  time: 0.5946  data_time: 0.0104  memory: 10656  grad_norm: 291.2327  loss: 15.4318  decode.loss_cls: 0.0495  decode.loss_mask: 0.5119  decode.loss_dice: 0.9634  decode.d0.loss_cls: 0.0872  decode.d0.loss_mask: 0.5355  decode.d0.loss_dice: 1.0480  decode.d1.loss_cls: 0.0592  decode.d1.loss_mask: 0.5117  decode.d1.loss_dice: 0.9978  decode.d2.loss_cls: 0.0459  decode.d2.loss_mask: 0.5200  decode.d2.loss_dice: 0.9802  decode.d3.loss_cls: 0.0499  decode.d3.loss_mask: 0.5100  decode.d3.loss_dice: 0.9558  decode.d4.loss_cls: 0.0494  decode.d4.loss_mask: 0.5081  decode.d4.loss_dice: 0.9628  decode.d5.loss_cls: 0.0516  decode.d5.loss_mask: 0.5051  decode.d5.loss_dice: 0.9546  decode.d6.loss_cls: 0.0554  decode.d6.loss_mask: 0.5003  decode.d6.loss_dice: 0.9504  decode.d7.loss_cls: 0.0495  decode.d7.loss_mask: 0.5187  decode.d7.loss_dice: 0.9561  decode.d8.loss_cls: 0.0463  decode.d8.loss_mask: 0.5153  decode.d8.loss_dice: 0.9819
11/15 15:36:26 - mmengine - INFO - Iter(train) [50150/90000]  base_lr: 4.8037e-05 lr: 4.8037e-06  eta: 6:40:51  time: 0.5955  data_time: 0.0105  memory: 10675  grad_norm: 504.5444  loss: 15.8420  decode.loss_cls: 0.0533  decode.loss_mask: 0.5298  decode.loss_dice: 1.0065  decode.d0.loss_cls: 0.0847  decode.d0.loss_mask: 0.5477  decode.d0.loss_dice: 1.0760  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.5218  decode.d1.loss_dice: 1.0108  decode.d2.loss_cls: 0.0709  decode.d2.loss_mask: 0.5133  decode.d2.loss_dice: 0.9989  decode.d3.loss_cls: 0.0633  decode.d3.loss_mask: 0.5074  decode.d3.loss_dice: 0.9924  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.5143  decode.d4.loss_dice: 1.0080  decode.d5.loss_cls: 0.0526  decode.d5.loss_mask: 0.5103  decode.d5.loss_dice: 0.9859  decode.d6.loss_cls: 0.0520  decode.d6.loss_mask: 0.5178  decode.d6.loss_dice: 0.9956  decode.d7.loss_cls: 0.0578  decode.d7.loss_mask: 0.5284  decode.d7.loss_dice: 0.9873  decode.d8.loss_cls: 0.0587  decode.d8.loss_mask: 0.5066  decode.d8.loss_dice: 0.9661
11/15 15:36:56 - mmengine - INFO - Iter(train) [50200/90000]  base_lr: 4.7982e-05 lr: 4.7982e-06  eta: 6:40:20  time: 0.5967  data_time: 0.0106  memory: 10641  grad_norm: 277.4095  loss: 17.5100  decode.loss_cls: 0.0535  decode.loss_mask: 0.5231  decode.loss_dice: 1.1678  decode.d0.loss_cls: 0.0562  decode.d0.loss_mask: 0.5662  decode.d0.loss_dice: 1.2225  decode.d1.loss_cls: 0.0600  decode.d1.loss_mask: 0.5305  decode.d1.loss_dice: 1.1802  decode.d2.loss_cls: 0.0732  decode.d2.loss_mask: 0.5307  decode.d2.loss_dice: 1.1478  decode.d3.loss_cls: 0.0497  decode.d3.loss_mask: 0.5237  decode.d3.loss_dice: 1.1564  decode.d4.loss_cls: 0.0538  decode.d4.loss_mask: 0.5255  decode.d4.loss_dice: 1.1381  decode.d5.loss_cls: 0.0499  decode.d5.loss_mask: 0.5273  decode.d5.loss_dice: 1.1657  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.5228  decode.d6.loss_dice: 1.1495  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.5197  decode.d7.loss_dice: 1.1691  decode.d8.loss_cls: 0.0622  decode.d8.loss_mask: 0.5230  decode.d8.loss_dice: 1.1562
11/15 15:37:26 - mmengine - INFO - Iter(train) [50250/90000]  base_lr: 4.7928e-05 lr: 4.7928e-06  eta: 6:39:50  time: 0.5969  data_time: 0.0104  memory: 10641  grad_norm: 469.1222  loss: 17.9046  decode.loss_cls: 0.0612  decode.loss_mask: 0.5813  decode.loss_dice: 1.1250  decode.d0.loss_cls: 0.0790  decode.d0.loss_mask: 0.6071  decode.d0.loss_dice: 1.2080  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.6015  decode.d1.loss_dice: 1.1507  decode.d2.loss_cls: 0.0658  decode.d2.loss_mask: 0.5752  decode.d2.loss_dice: 1.1405  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.5810  decode.d3.loss_dice: 1.1328  decode.d4.loss_cls: 0.0619  decode.d4.loss_mask: 0.5806  decode.d4.loss_dice: 1.1235  decode.d5.loss_cls: 0.0572  decode.d5.loss_mask: 0.5761  decode.d5.loss_dice: 1.1264  decode.d6.loss_cls: 0.0624  decode.d6.loss_mask: 0.5760  decode.d6.loss_dice: 1.1288  decode.d7.loss_cls: 0.0597  decode.d7.loss_mask: 0.5863  decode.d7.loss_dice: 1.1325  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.5861  decode.d8.loss_dice: 1.1464
11/15 15:37:56 - mmengine - INFO - Iter(train) [50300/90000]  base_lr: 4.7874e-05 lr: 4.7874e-06  eta: 6:39:20  time: 0.5974  data_time: 0.0108  memory: 10692  grad_norm: 504.9879  loss: 16.6657  decode.loss_cls: 0.0625  decode.loss_mask: 0.5408  decode.loss_dice: 1.0369  decode.d0.loss_cls: 0.0757  decode.d0.loss_mask: 0.5792  decode.d0.loss_dice: 1.1428  decode.d1.loss_cls: 0.0524  decode.d1.loss_mask: 0.5509  decode.d1.loss_dice: 1.1131  decode.d2.loss_cls: 0.0605  decode.d2.loss_mask: 0.5426  decode.d2.loss_dice: 1.0733  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.5380  decode.d3.loss_dice: 1.0592  decode.d4.loss_cls: 0.0525  decode.d4.loss_mask: 0.5392  decode.d4.loss_dice: 1.0581  decode.d5.loss_cls: 0.0584  decode.d5.loss_mask: 0.5369  decode.d5.loss_dice: 1.0390  decode.d6.loss_cls: 0.0538  decode.d6.loss_mask: 0.5347  decode.d6.loss_dice: 1.0209  decode.d7.loss_cls: 0.0579  decode.d7.loss_mask: 0.5400  decode.d7.loss_dice: 1.0439  decode.d8.loss_cls: 0.0561  decode.d8.loss_mask: 0.5409  decode.d8.loss_dice: 1.0534
11/15 15:38:25 - mmengine - INFO - Iter(train) [50350/90000]  base_lr: 4.7819e-05 lr: 4.7819e-06  eta: 6:38:49  time: 0.5977  data_time: 0.0107  memory: 10675  grad_norm: 571.8826  loss: 17.8004  decode.loss_cls: 0.0416  decode.loss_mask: 0.6357  decode.loss_dice: 1.0953  decode.d0.loss_cls: 0.0803  decode.d0.loss_mask: 0.6799  decode.d0.loss_dice: 1.0968  decode.d1.loss_cls: 0.0643  decode.d1.loss_mask: 0.6430  decode.d1.loss_dice: 1.0949  decode.d2.loss_cls: 0.0557  decode.d2.loss_mask: 0.6476  decode.d2.loss_dice: 1.0911  decode.d3.loss_cls: 0.0507  decode.d3.loss_mask: 0.6352  decode.d3.loss_dice: 1.0875  decode.d4.loss_cls: 0.0531  decode.d4.loss_mask: 0.6365  decode.d4.loss_dice: 1.0920  decode.d5.loss_cls: 0.0415  decode.d5.loss_mask: 0.6292  decode.d5.loss_dice: 1.0872  decode.d6.loss_cls: 0.0508  decode.d6.loss_mask: 0.6236  decode.d6.loss_dice: 1.0730  decode.d7.loss_cls: 0.0492  decode.d7.loss_mask: 0.6290  decode.d7.loss_dice: 1.0657  decode.d8.loss_cls: 0.0459  decode.d8.loss_mask: 0.6370  decode.d8.loss_dice: 1.0868
11/15 15:38:55 - mmengine - INFO - Iter(train) [50400/90000]  base_lr: 4.7765e-05 lr: 4.7765e-06  eta: 6:38:19  time: 0.5991  data_time: 0.0108  memory: 10641  grad_norm: 281.1869  loss: 15.7446  decode.loss_cls: 0.0624  decode.loss_mask: 0.4044  decode.loss_dice: 1.0955  decode.d0.loss_cls: 0.0811  decode.d0.loss_mask: 0.4151  decode.d0.loss_dice: 1.1557  decode.d1.loss_cls: 0.0598  decode.d1.loss_mask: 0.4122  decode.d1.loss_dice: 1.1375  decode.d2.loss_cls: 0.0778  decode.d2.loss_mask: 0.4080  decode.d2.loss_dice: 1.0956  decode.d3.loss_cls: 0.0682  decode.d3.loss_mask: 0.4055  decode.d3.loss_dice: 1.0869  decode.d4.loss_cls: 0.0707  decode.d4.loss_mask: 0.4080  decode.d4.loss_dice: 1.0830  decode.d5.loss_cls: 0.0714  decode.d5.loss_mask: 0.4046  decode.d5.loss_dice: 1.0634  decode.d6.loss_cls: 0.0713  decode.d6.loss_mask: 0.3989  decode.d6.loss_dice: 1.0929  decode.d7.loss_cls: 0.0677  decode.d7.loss_mask: 0.4044  decode.d7.loss_dice: 1.0959  decode.d8.loss_cls: 0.0679  decode.d8.loss_mask: 0.4056  decode.d8.loss_dice: 1.0731
11/15 15:39:25 - mmengine - INFO - Iter(train) [50450/90000]  base_lr: 4.7711e-05 lr: 4.7711e-06  eta: 6:37:48  time: 0.5977  data_time: 0.0105  memory: 10675  grad_norm: 506.1425  loss: 18.6529  decode.loss_cls: 0.0490  decode.loss_mask: 0.6509  decode.loss_dice: 1.1398  decode.d0.loss_cls: 0.0758  decode.d0.loss_mask: 0.6812  decode.d0.loss_dice: 1.1907  decode.d1.loss_cls: 0.0661  decode.d1.loss_mask: 0.6599  decode.d1.loss_dice: 1.1512  decode.d2.loss_cls: 0.0483  decode.d2.loss_mask: 0.6625  decode.d2.loss_dice: 1.1806  decode.d3.loss_cls: 0.0544  decode.d3.loss_mask: 0.6636  decode.d3.loss_dice: 1.1344  decode.d4.loss_cls: 0.0583  decode.d4.loss_mask: 0.6602  decode.d4.loss_dice: 1.1383  decode.d5.loss_cls: 0.0600  decode.d5.loss_mask: 0.6635  decode.d5.loss_dice: 1.1048  decode.d6.loss_cls: 0.0560  decode.d6.loss_mask: 0.6642  decode.d6.loss_dice: 1.1231  decode.d7.loss_cls: 0.0563  decode.d7.loss_mask: 0.6711  decode.d7.loss_dice: 1.1277  decode.d8.loss_cls: 0.0535  decode.d8.loss_mask: 0.6729  decode.d8.loss_dice: 1.1350
11/15 15:39:55 - mmengine - INFO - Iter(train) [50500/90000]  base_lr: 4.7657e-05 lr: 4.7657e-06  eta: 6:37:18  time: 0.5957  data_time: 0.0105  memory: 10675  grad_norm: 542.0549  loss: 16.2141  decode.loss_cls: 0.0818  decode.loss_mask: 0.4065  decode.loss_dice: 1.1236  decode.d0.loss_cls: 0.1106  decode.d0.loss_mask: 0.4091  decode.d0.loss_dice: 1.1861  decode.d1.loss_cls: 0.0833  decode.d1.loss_mask: 0.4002  decode.d1.loss_dice: 1.1450  decode.d2.loss_cls: 0.0900  decode.d2.loss_mask: 0.3916  decode.d2.loss_dice: 1.1442  decode.d3.loss_cls: 0.0834  decode.d3.loss_mask: 0.3948  decode.d3.loss_dice: 1.1256  decode.d4.loss_cls: 0.0752  decode.d4.loss_mask: 0.3993  decode.d4.loss_dice: 1.1086  decode.d5.loss_cls: 0.0772  decode.d5.loss_mask: 0.3983  decode.d5.loss_dice: 1.1401  decode.d6.loss_cls: 0.0926  decode.d6.loss_mask: 0.3963  decode.d6.loss_dice: 1.1273  decode.d7.loss_cls: 0.0764  decode.d7.loss_mask: 0.3998  decode.d7.loss_dice: 1.1287  decode.d8.loss_cls: 0.0859  decode.d8.loss_mask: 0.3934  decode.d8.loss_dice: 1.1392
11/15 15:40:25 - mmengine - INFO - Iter(train) [50550/90000]  base_lr: 4.7602e-05 lr: 4.7602e-06  eta: 6:36:48  time: 0.5972  data_time: 0.0105  memory: 10675  grad_norm: 422.9447  loss: 15.5764  decode.loss_cls: 0.0595  decode.loss_mask: 0.4755  decode.loss_dice: 1.0307  decode.d0.loss_cls: 0.0792  decode.d0.loss_mask: 0.4375  decode.d0.loss_dice: 1.0690  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.4351  decode.d1.loss_dice: 1.0016  decode.d2.loss_cls: 0.0611  decode.d2.loss_mask: 0.4415  decode.d2.loss_dice: 1.0291  decode.d3.loss_cls: 0.0654  decode.d3.loss_mask: 0.4438  decode.d3.loss_dice: 1.0107  decode.d4.loss_cls: 0.0600  decode.d4.loss_mask: 0.4711  decode.d4.loss_dice: 1.0266  decode.d5.loss_cls: 0.0548  decode.d5.loss_mask: 0.4722  decode.d5.loss_dice: 1.0508  decode.d6.loss_cls: 0.0616  decode.d6.loss_mask: 0.4649  decode.d6.loss_dice: 1.0591  decode.d7.loss_cls: 0.0542  decode.d7.loss_mask: 0.4708  decode.d7.loss_dice: 1.0400  decode.d8.loss_cls: 0.0516  decode.d8.loss_mask: 0.4777  decode.d8.loss_dice: 1.0437
11/15 15:40:55 - mmengine - INFO - Iter(train) [50600/90000]  base_lr: 4.7548e-05 lr: 4.7548e-06  eta: 6:36:17  time: 0.5948  data_time: 0.0103  memory: 10656  grad_norm: 387.5382  loss: 12.9254  decode.loss_cls: 0.0409  decode.loss_mask: 0.4058  decode.loss_dice: 0.8303  decode.d0.loss_cls: 0.0743  decode.d0.loss_mask: 0.4261  decode.d0.loss_dice: 0.9058  decode.d1.loss_cls: 0.0506  decode.d1.loss_mask: 0.4168  decode.d1.loss_dice: 0.8210  decode.d2.loss_cls: 0.0456  decode.d2.loss_mask: 0.4089  decode.d2.loss_dice: 0.8402  decode.d3.loss_cls: 0.0384  decode.d3.loss_mask: 0.4044  decode.d3.loss_dice: 0.8365  decode.d4.loss_cls: 0.0466  decode.d4.loss_mask: 0.4029  decode.d4.loss_dice: 0.8319  decode.d5.loss_cls: 0.0474  decode.d5.loss_mask: 0.4015  decode.d5.loss_dice: 0.8367  decode.d6.loss_cls: 0.0497  decode.d6.loss_mask: 0.4044  decode.d6.loss_dice: 0.8147  decode.d7.loss_cls: 0.0419  decode.d7.loss_mask: 0.4041  decode.d7.loss_dice: 0.8333  decode.d8.loss_cls: 0.0401  decode.d8.loss_mask: 0.4014  decode.d8.loss_dice: 0.8232
11/15 15:41:25 - mmengine - INFO - Iter(train) [50650/90000]  base_lr: 4.7494e-05 lr: 4.7494e-06  eta: 6:35:47  time: 0.5973  data_time: 0.0105  memory: 10675  grad_norm: 1140.6285  loss: 19.0148  decode.loss_cls: 0.0924  decode.loss_mask: 0.5261  decode.loss_dice: 1.2668  decode.d0.loss_cls: 0.0947  decode.d0.loss_mask: 0.5224  decode.d0.loss_dice: 1.4087  decode.d1.loss_cls: 0.1036  decode.d1.loss_mask: 0.5270  decode.d1.loss_dice: 1.3092  decode.d2.loss_cls: 0.1074  decode.d2.loss_mask: 0.4862  decode.d2.loss_dice: 1.2988  decode.d3.loss_cls: 0.1005  decode.d3.loss_mask: 0.4897  decode.d3.loss_dice: 1.2460  decode.d4.loss_cls: 0.0916  decode.d4.loss_mask: 0.5225  decode.d4.loss_dice: 1.2440  decode.d5.loss_cls: 0.0832  decode.d5.loss_mask: 0.4947  decode.d5.loss_dice: 1.2901  decode.d6.loss_cls: 0.0876  decode.d6.loss_mask: 0.5586  decode.d6.loss_dice: 1.2858  decode.d7.loss_cls: 0.0765  decode.d7.loss_mask: 0.5499  decode.d7.loss_dice: 1.2650  decode.d8.loss_cls: 0.0918  decode.d8.loss_mask: 0.5326  decode.d8.loss_dice: 1.2614
11/15 15:41:55 - mmengine - INFO - Iter(train) [50700/90000]  base_lr: 4.7439e-05 lr: 4.7439e-06  eta: 6:35:16  time: 0.5958  data_time: 0.0102  memory: 10656  grad_norm: 639.6736  loss: 18.0767  decode.loss_cls: 0.0782  decode.loss_mask: 0.5368  decode.loss_dice: 1.1982  decode.d0.loss_cls: 0.0918  decode.d0.loss_mask: 0.5437  decode.d0.loss_dice: 1.2718  decode.d1.loss_cls: 0.0879  decode.d1.loss_mask: 0.5464  decode.d1.loss_dice: 1.1572  decode.d2.loss_cls: 0.0926  decode.d2.loss_mask: 0.5276  decode.d2.loss_dice: 1.1740  decode.d3.loss_cls: 0.0954  decode.d3.loss_mask: 0.5316  decode.d3.loss_dice: 1.1432  decode.d4.loss_cls: 0.0884  decode.d4.loss_mask: 0.5300  decode.d4.loss_dice: 1.1628  decode.d5.loss_cls: 0.0766  decode.d5.loss_mask: 0.5381  decode.d5.loss_dice: 1.1829  decode.d6.loss_cls: 0.0750  decode.d6.loss_mask: 0.5434  decode.d6.loss_dice: 1.1800  decode.d7.loss_cls: 0.0732  decode.d7.loss_mask: 0.5410  decode.d7.loss_dice: 1.1855  decode.d8.loss_cls: 0.0658  decode.d8.loss_mask: 0.5448  decode.d8.loss_dice: 1.2129
11/15 15:42:24 - mmengine - INFO - Iter(train) [50750/90000]  base_lr: 4.7385e-05 lr: 4.7385e-06  eta: 6:34:46  time: 0.5959  data_time: 0.0100  memory: 10692  grad_norm: 393.2868  loss: 16.2359  decode.loss_cls: 0.0464  decode.loss_mask: 0.4963  decode.loss_dice: 1.0486  decode.d0.loss_cls: 0.0659  decode.d0.loss_mask: 0.5299  decode.d0.loss_dice: 1.1043  decode.d1.loss_cls: 0.0582  decode.d1.loss_mask: 0.5143  decode.d1.loss_dice: 1.0759  decode.d2.loss_cls: 0.0577  decode.d2.loss_mask: 0.5095  decode.d2.loss_dice: 1.0666  decode.d3.loss_cls: 0.0492  decode.d3.loss_mask: 0.5100  decode.d3.loss_dice: 1.0569  decode.d4.loss_cls: 0.0491  decode.d4.loss_mask: 0.5070  decode.d4.loss_dice: 1.0589  decode.d5.loss_cls: 0.0590  decode.d5.loss_mask: 0.5077  decode.d5.loss_dice: 1.0433  decode.d6.loss_cls: 0.0593  decode.d6.loss_mask: 0.5050  decode.d6.loss_dice: 1.0431  decode.d7.loss_cls: 0.0524  decode.d7.loss_mask: 0.5088  decode.d7.loss_dice: 1.0668  decode.d8.loss_cls: 0.0507  decode.d8.loss_mask: 0.4884  decode.d8.loss_dice: 1.0470
11/15 15:42:54 - mmengine - INFO - Iter(train) [50800/90000]  base_lr: 4.7331e-05 lr: 4.7331e-06  eta: 6:34:16  time: 0.6044  data_time: 0.0106  memory: 10656  grad_norm: 334.0773  loss: 17.3386  decode.loss_cls: 0.0564  decode.loss_mask: 0.5408  decode.loss_dice: 1.1195  decode.d0.loss_cls: 0.1028  decode.d0.loss_mask: 0.5499  decode.d0.loss_dice: 1.1955  decode.d1.loss_cls: 0.0696  decode.d1.loss_mask: 0.5164  decode.d1.loss_dice: 1.1310  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.5258  decode.d2.loss_dice: 1.1394  decode.d3.loss_cls: 0.0584  decode.d3.loss_mask: 0.5275  decode.d3.loss_dice: 1.1165  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.5286  decode.d4.loss_dice: 1.1472  decode.d5.loss_cls: 0.0720  decode.d5.loss_mask: 0.5176  decode.d5.loss_dice: 1.1192  decode.d6.loss_cls: 0.0518  decode.d6.loss_mask: 0.5269  decode.d6.loss_dice: 1.1297  decode.d7.loss_cls: 0.0480  decode.d7.loss_mask: 0.5563  decode.d7.loss_dice: 1.1422  decode.d8.loss_cls: 0.0567  decode.d8.loss_mask: 0.5447  decode.d8.loss_dice: 1.1415
11/15 15:43:24 - mmengine - INFO - Iter(train) [50850/90000]  base_lr: 4.7276e-05 lr: 4.7276e-06  eta: 6:33:45  time: 0.5969  data_time: 0.0104  memory: 10713  grad_norm: 597.5297  loss: 17.7933  decode.loss_cls: 0.0879  decode.loss_mask: 0.5026  decode.loss_dice: 1.1338  decode.d0.loss_cls: 0.1134  decode.d0.loss_mask: 0.5178  decode.d0.loss_dice: 1.2206  decode.d1.loss_cls: 0.0987  decode.d1.loss_mask: 0.5189  decode.d1.loss_dice: 1.2082  decode.d2.loss_cls: 0.1000  decode.d2.loss_mask: 0.5194  decode.d2.loss_dice: 1.1859  decode.d3.loss_cls: 0.0779  decode.d3.loss_mask: 0.5232  decode.d3.loss_dice: 1.1577  decode.d4.loss_cls: 0.0857  decode.d4.loss_mask: 0.5274  decode.d4.loss_dice: 1.1706  decode.d5.loss_cls: 0.0874  decode.d5.loss_mask: 0.5275  decode.d5.loss_dice: 1.1802  decode.d6.loss_cls: 0.0850  decode.d6.loss_mask: 0.5079  decode.d6.loss_dice: 1.1741  decode.d7.loss_cls: 0.0972  decode.d7.loss_mask: 0.5059  decode.d7.loss_dice: 1.1394  decode.d8.loss_cls: 0.0849  decode.d8.loss_mask: 0.5017  decode.d8.loss_dice: 1.1521
11/15 15:43:54 - mmengine - INFO - Iter(train) [50900/90000]  base_lr: 4.7222e-05 lr: 4.7222e-06  eta: 6:33:15  time: 0.5977  data_time: 0.0105  memory: 10641  grad_norm: 436.7406  loss: 17.0308  decode.loss_cls: 0.0550  decode.loss_mask: 0.5056  decode.loss_dice: 1.1063  decode.d0.loss_cls: 0.0815  decode.d0.loss_mask: 0.5320  decode.d0.loss_dice: 1.1738  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.5121  decode.d1.loss_dice: 1.1264  decode.d2.loss_cls: 0.0536  decode.d2.loss_mask: 0.5144  decode.d2.loss_dice: 1.1228  decode.d3.loss_cls: 0.0553  decode.d3.loss_mask: 0.5171  decode.d3.loss_dice: 1.1228  decode.d4.loss_cls: 0.0621  decode.d4.loss_mask: 0.5204  decode.d4.loss_dice: 1.1285  decode.d5.loss_cls: 0.0543  decode.d5.loss_mask: 0.5242  decode.d5.loss_dice: 1.1340  decode.d6.loss_cls: 0.0563  decode.d6.loss_mask: 0.5174  decode.d6.loss_dice: 1.1055  decode.d7.loss_cls: 0.0563  decode.d7.loss_mask: 0.5293  decode.d7.loss_dice: 1.1153  decode.d8.loss_cls: 0.0682  decode.d8.loss_mask: 0.5095  decode.d8.loss_dice: 1.1066
11/15 15:44:24 - mmengine - INFO - Iter(train) [50950/90000]  base_lr: 4.7168e-05 lr: 4.7168e-06  eta: 6:32:44  time: 0.5970  data_time: 0.0105  memory: 10692  grad_norm: 447.6259  loss: 17.3726  decode.loss_cls: 0.0610  decode.loss_mask: 0.5331  decode.loss_dice: 1.1034  decode.d0.loss_cls: 0.0769  decode.d0.loss_mask: 0.5588  decode.d0.loss_dice: 1.2076  decode.d1.loss_cls: 0.0611  decode.d1.loss_mask: 0.5476  decode.d1.loss_dice: 1.1424  decode.d2.loss_cls: 0.0611  decode.d2.loss_mask: 0.5398  decode.d2.loss_dice: 1.1285  decode.d3.loss_cls: 0.0661  decode.d3.loss_mask: 0.5178  decode.d3.loss_dice: 1.1377  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.5491  decode.d4.loss_dice: 1.1201  decode.d5.loss_cls: 0.0661  decode.d5.loss_mask: 0.5431  decode.d5.loss_dice: 1.1273  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.5320  decode.d6.loss_dice: 1.1236  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.5381  decode.d7.loss_dice: 1.1183  decode.d8.loss_cls: 0.0654  decode.d8.loss_mask: 0.5321  decode.d8.loss_dice: 1.1156
11/15 15:44:56 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 15:44:56 - mmengine - INFO - Iter(train) [51000/90000]  base_lr: 4.7113e-05 lr: 4.7113e-06  eta: 6:32:15  time: 0.5944  data_time: 0.0101  memory: 10656  grad_norm: 605.4650  loss: 18.6655  decode.loss_cls: 0.0766  decode.loss_mask: 0.5895  decode.loss_dice: 1.2104  decode.d0.loss_cls: 0.1050  decode.d0.loss_mask: 0.5681  decode.d0.loss_dice: 1.2665  decode.d1.loss_cls: 0.0908  decode.d1.loss_mask: 0.5704  decode.d1.loss_dice: 1.2491  decode.d2.loss_cls: 0.0976  decode.d2.loss_mask: 0.5743  decode.d2.loss_dice: 1.1921  decode.d3.loss_cls: 0.0738  decode.d3.loss_mask: 0.5646  decode.d3.loss_dice: 1.1962  decode.d4.loss_cls: 0.0813  decode.d4.loss_mask: 0.5824  decode.d4.loss_dice: 1.2013  decode.d5.loss_cls: 0.0873  decode.d5.loss_mask: 0.5633  decode.d5.loss_dice: 1.1940  decode.d6.loss_cls: 0.0857  decode.d6.loss_mask: 0.5601  decode.d6.loss_dice: 1.1934  decode.d7.loss_cls: 0.0853  decode.d7.loss_mask: 0.5639  decode.d7.loss_dice: 1.1808  decode.d8.loss_cls: 0.0823  decode.d8.loss_mask: 0.5735  decode.d8.loss_dice: 1.2059
11/15 15:45:26 - mmengine - INFO - Iter(train) [51050/90000]  base_lr: 4.7059e-05 lr: 4.7059e-06  eta: 6:31:45  time: 0.5953  data_time: 0.0104  memory: 10675  grad_norm: 289.6365  loss: 19.3988  decode.loss_cls: 0.0844  decode.loss_mask: 0.5776  decode.loss_dice: 1.2837  decode.d0.loss_cls: 0.1465  decode.d0.loss_mask: 0.5569  decode.d0.loss_dice: 1.3038  decode.d1.loss_cls: 0.1081  decode.d1.loss_mask: 0.5482  decode.d1.loss_dice: 1.2941  decode.d2.loss_cls: 0.1022  decode.d2.loss_mask: 0.5760  decode.d2.loss_dice: 1.3046  decode.d3.loss_cls: 0.0968  decode.d3.loss_mask: 0.5581  decode.d3.loss_dice: 1.2521  decode.d4.loss_cls: 0.0893  decode.d4.loss_mask: 0.5690  decode.d4.loss_dice: 1.2453  decode.d5.loss_cls: 0.0904  decode.d5.loss_mask: 0.5616  decode.d5.loss_dice: 1.2539  decode.d6.loss_cls: 0.0936  decode.d6.loss_mask: 0.5568  decode.d6.loss_dice: 1.2554  decode.d7.loss_cls: 0.0934  decode.d7.loss_mask: 0.5672  decode.d7.loss_dice: 1.2772  decode.d8.loss_cls: 0.0982  decode.d8.loss_mask: 0.5595  decode.d8.loss_dice: 1.2951
11/15 15:45:55 - mmengine - INFO - Iter(train) [51100/90000]  base_lr: 4.7005e-05 lr: 4.7005e-06  eta: 6:31:14  time: 0.5941  data_time: 0.0102  memory: 10656  grad_norm: 385.7215  loss: 16.9800  decode.loss_cls: 0.0585  decode.loss_mask: 0.5617  decode.loss_dice: 1.0873  decode.d0.loss_cls: 0.0834  decode.d0.loss_mask: 0.5488  decode.d0.loss_dice: 1.1465  decode.d1.loss_cls: 0.0608  decode.d1.loss_mask: 0.5403  decode.d1.loss_dice: 1.1046  decode.d2.loss_cls: 0.0611  decode.d2.loss_mask: 0.5395  decode.d2.loss_dice: 1.1019  decode.d3.loss_cls: 0.0538  decode.d3.loss_mask: 0.5286  decode.d3.loss_dice: 1.0468  decode.d4.loss_cls: 0.0506  decode.d4.loss_mask: 0.5377  decode.d4.loss_dice: 1.0976  decode.d5.loss_cls: 0.0493  decode.d5.loss_mask: 0.5410  decode.d5.loss_dice: 1.0999  decode.d6.loss_cls: 0.0510  decode.d6.loss_mask: 0.5529  decode.d6.loss_dice: 1.0896  decode.d7.loss_cls: 0.0492  decode.d7.loss_mask: 0.5604  decode.d7.loss_dice: 1.0916  decode.d8.loss_cls: 0.0489  decode.d8.loss_mask: 0.5577  decode.d8.loss_dice: 1.0791
11/15 15:46:25 - mmengine - INFO - Iter(train) [51150/90000]  base_lr: 4.6950e-05 lr: 4.6950e-06  eta: 6:30:44  time: 0.5949  data_time: 0.0102  memory: 10692  grad_norm: 245.5627  loss: 14.9195  decode.loss_cls: 0.0706  decode.loss_mask: 0.4414  decode.loss_dice: 0.9528  decode.d0.loss_cls: 0.0948  decode.d0.loss_mask: 0.4889  decode.d0.loss_dice: 1.0804  decode.d1.loss_cls: 0.0797  decode.d1.loss_mask: 0.4604  decode.d1.loss_dice: 1.0122  decode.d2.loss_cls: 0.0737  decode.d2.loss_mask: 0.4417  decode.d2.loss_dice: 0.9609  decode.d3.loss_cls: 0.0848  decode.d3.loss_mask: 0.4332  decode.d3.loss_dice: 0.9342  decode.d4.loss_cls: 0.0807  decode.d4.loss_mask: 0.4436  decode.d4.loss_dice: 0.9636  decode.d5.loss_cls: 0.0805  decode.d5.loss_mask: 0.4449  decode.d5.loss_dice: 0.9349  decode.d6.loss_cls: 0.0799  decode.d6.loss_mask: 0.4399  decode.d6.loss_dice: 0.9336  decode.d7.loss_cls: 0.0714  decode.d7.loss_mask: 0.4396  decode.d7.loss_dice: 0.9253  decode.d8.loss_cls: 0.0822  decode.d8.loss_mask: 0.4454  decode.d8.loss_dice: 0.9444
11/15 15:46:55 - mmengine - INFO - Iter(train) [51200/90000]  base_lr: 4.6896e-05 lr: 4.6896e-06  eta: 6:30:13  time: 0.5960  data_time: 0.0105  memory: 10675  grad_norm: 263.5024  loss: 15.1615  decode.loss_cls: 0.0637  decode.loss_mask: 0.3877  decode.loss_dice: 1.0635  decode.d0.loss_cls: 0.0878  decode.d0.loss_mask: 0.3947  decode.d0.loss_dice: 1.1379  decode.d1.loss_cls: 0.0766  decode.d1.loss_mask: 0.3885  decode.d1.loss_dice: 1.0896  decode.d2.loss_cls: 0.0749  decode.d2.loss_mask: 0.3816  decode.d2.loss_dice: 1.0479  decode.d3.loss_cls: 0.0630  decode.d3.loss_mask: 0.3791  decode.d3.loss_dice: 1.0320  decode.d4.loss_cls: 0.0653  decode.d4.loss_mask: 0.3829  decode.d4.loss_dice: 1.0465  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.3832  decode.d5.loss_dice: 1.0095  decode.d6.loss_cls: 0.0664  decode.d6.loss_mask: 0.3870  decode.d6.loss_dice: 1.0541  decode.d7.loss_cls: 0.0559  decode.d7.loss_mask: 0.4085  decode.d7.loss_dice: 1.0730  decode.d8.loss_cls: 0.0656  decode.d8.loss_mask: 0.3873  decode.d8.loss_dice: 1.0398
11/15 15:47:29 - mmengine - INFO - Iter(train) [51250/90000]  base_lr: 4.6841e-05 lr: 4.6841e-06  eta: 6:29:46  time: 0.5991  data_time: 0.0107  memory: 10692  grad_norm: 549.2718  loss: 15.7190  decode.loss_cls: 0.0563  decode.loss_mask: 0.5439  decode.loss_dice: 0.9415  decode.d0.loss_cls: 0.0803  decode.d0.loss_mask: 0.5959  decode.d0.loss_dice: 1.0261  decode.d1.loss_cls: 0.0507  decode.d1.loss_mask: 0.5683  decode.d1.loss_dice: 0.9728  decode.d2.loss_cls: 0.0446  decode.d2.loss_mask: 0.5527  decode.d2.loss_dice: 0.9517  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.5584  decode.d3.loss_dice: 0.9277  decode.d4.loss_cls: 0.0437  decode.d4.loss_mask: 0.5514  decode.d4.loss_dice: 0.9453  decode.d5.loss_cls: 0.0436  decode.d5.loss_mask: 0.5553  decode.d5.loss_dice: 0.9536  decode.d6.loss_cls: 0.0508  decode.d6.loss_mask: 0.5652  decode.d6.loss_dice: 0.9683  decode.d7.loss_cls: 0.0528  decode.d7.loss_mask: 0.5578  decode.d7.loss_dice: 0.9506  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.5629  decode.d8.loss_dice: 0.9520
11/15 15:48:00 - mmengine - INFO - Iter(train) [51300/90000]  base_lr: 4.6787e-05 lr: 4.6787e-06  eta: 6:29:16  time: 0.5949  data_time: 0.0115  memory: 10656  grad_norm: 318.5053  loss: 16.4682  decode.loss_cls: 0.0607  decode.loss_mask: 0.5313  decode.loss_dice: 0.9995  decode.d0.loss_cls: 0.0791  decode.d0.loss_mask: 0.5627  decode.d0.loss_dice: 1.1099  decode.d1.loss_cls: 0.0746  decode.d1.loss_mask: 0.5544  decode.d1.loss_dice: 1.0155  decode.d2.loss_cls: 0.0644  decode.d2.loss_mask: 0.5465  decode.d2.loss_dice: 1.0316  decode.d3.loss_cls: 0.0590  decode.d3.loss_mask: 0.5531  decode.d3.loss_dice: 1.0261  decode.d4.loss_cls: 0.0580  decode.d4.loss_mask: 0.5502  decode.d4.loss_dice: 1.0186  decode.d5.loss_cls: 0.0555  decode.d5.loss_mask: 0.5622  decode.d5.loss_dice: 1.0327  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.5525  decode.d6.loss_dice: 1.0390  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.5563  decode.d7.loss_dice: 1.0175  decode.d8.loss_cls: 0.0604  decode.d8.loss_mask: 0.5526  decode.d8.loss_dice: 1.0232
11/15 15:48:29 - mmengine - INFO - Iter(train) [51350/90000]  base_lr: 4.6733e-05 lr: 4.6733e-06  eta: 6:28:46  time: 0.5960  data_time: 0.0105  memory: 10692  grad_norm: 491.2101  loss: 17.5155  decode.loss_cls: 0.0930  decode.loss_mask: 0.5189  decode.loss_dice: 1.1251  decode.d0.loss_cls: 0.1052  decode.d0.loss_mask: 0.5370  decode.d0.loss_dice: 1.2142  decode.d1.loss_cls: 0.1005  decode.d1.loss_mask: 0.5189  decode.d1.loss_dice: 1.1460  decode.d2.loss_cls: 0.1010  decode.d2.loss_mask: 0.5211  decode.d2.loss_dice: 1.1257  decode.d3.loss_cls: 0.0822  decode.d3.loss_mask: 0.5209  decode.d3.loss_dice: 1.1420  decode.d4.loss_cls: 0.0848  decode.d4.loss_mask: 0.5219  decode.d4.loss_dice: 1.1471  decode.d5.loss_cls: 0.0885  decode.d5.loss_mask: 0.5154  decode.d5.loss_dice: 1.1169  decode.d6.loss_cls: 0.0835  decode.d6.loss_mask: 0.5183  decode.d6.loss_dice: 1.1121  decode.d7.loss_cls: 0.0799  decode.d7.loss_mask: 0.5097  decode.d7.loss_dice: 1.1603  decode.d8.loss_cls: 0.0744  decode.d8.loss_mask: 0.5174  decode.d8.loss_dice: 1.1337
11/15 15:48:59 - mmengine - INFO - Iter(train) [51400/90000]  base_lr: 4.6678e-05 lr: 4.6678e-06  eta: 6:28:15  time: 0.5954  data_time: 0.0106  memory: 10656  grad_norm: 309.8750  loss: 16.0064  decode.loss_cls: 0.0668  decode.loss_mask: 0.4551  decode.loss_dice: 1.0521  decode.d0.loss_cls: 0.0868  decode.d0.loss_mask: 0.4590  decode.d0.loss_dice: 1.0935  decode.d1.loss_cls: 0.0703  decode.d1.loss_mask: 0.4571  decode.d1.loss_dice: 1.0839  decode.d2.loss_cls: 0.0636  decode.d2.loss_mask: 0.4595  decode.d2.loss_dice: 1.0850  decode.d3.loss_cls: 0.0717  decode.d3.loss_mask: 0.4640  decode.d3.loss_dice: 1.0378  decode.d4.loss_cls: 0.0662  decode.d4.loss_mask: 0.4576  decode.d4.loss_dice: 1.0686  decode.d5.loss_cls: 0.0682  decode.d5.loss_mask: 0.4606  decode.d5.loss_dice: 1.0863  decode.d6.loss_cls: 0.0709  decode.d6.loss_mask: 0.4548  decode.d6.loss_dice: 1.0727  decode.d7.loss_cls: 0.0580  decode.d7.loss_mask: 0.4522  decode.d7.loss_dice: 1.0912  decode.d8.loss_cls: 0.0562  decode.d8.loss_mask: 0.4544  decode.d8.loss_dice: 1.0824
11/15 15:49:29 - mmengine - INFO - Iter(train) [51450/90000]  base_lr: 4.6624e-05 lr: 4.6624e-06  eta: 6:27:45  time: 0.5948  data_time: 0.0105  memory: 10742  grad_norm: 325.8005  loss: 17.3986  decode.loss_cls: 0.1271  decode.loss_mask: 0.4759  decode.loss_dice: 1.0985  decode.d0.loss_cls: 0.1086  decode.d0.loss_mask: 0.5068  decode.d0.loss_dice: 1.2230  decode.d1.loss_cls: 0.1170  decode.d1.loss_mask: 0.4737  decode.d1.loss_dice: 1.1699  decode.d2.loss_cls: 0.1214  decode.d2.loss_mask: 0.4766  decode.d2.loss_dice: 1.1500  decode.d3.loss_cls: 0.1242  decode.d3.loss_mask: 0.4575  decode.d3.loss_dice: 1.1177  decode.d4.loss_cls: 0.1220  decode.d4.loss_mask: 0.4657  decode.d4.loss_dice: 1.1316  decode.d5.loss_cls: 0.1255  decode.d5.loss_mask: 0.4717  decode.d5.loss_dice: 1.1479  decode.d6.loss_cls: 0.1299  decode.d6.loss_mask: 0.4954  decode.d6.loss_dice: 1.1047  decode.d7.loss_cls: 0.1267  decode.d7.loss_mask: 0.4806  decode.d7.loss_dice: 1.1175  decode.d8.loss_cls: 0.1247  decode.d8.loss_mask: 0.4589  decode.d8.loss_dice: 1.1479
11/15 15:49:59 - mmengine - INFO - Iter(train) [51500/90000]  base_lr: 4.6569e-05 lr: 4.6569e-06  eta: 6:27:14  time: 0.6009  data_time: 0.0104  memory: 10675  grad_norm: 300.2400  loss: 16.5869  decode.loss_cls: 0.0546  decode.loss_mask: 0.5427  decode.loss_dice: 1.0495  decode.d0.loss_cls: 0.0876  decode.d0.loss_mask: 0.5817  decode.d0.loss_dice: 1.0605  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.5521  decode.d1.loss_dice: 1.0353  decode.d2.loss_cls: 0.0448  decode.d2.loss_mask: 0.5543  decode.d2.loss_dice: 1.0698  decode.d3.loss_cls: 0.0502  decode.d3.loss_mask: 0.5472  decode.d3.loss_dice: 1.0346  decode.d4.loss_cls: 0.0539  decode.d4.loss_mask: 0.5548  decode.d4.loss_dice: 1.0503  decode.d5.loss_cls: 0.0441  decode.d5.loss_mask: 0.5764  decode.d5.loss_dice: 1.0618  decode.d6.loss_cls: 0.0607  decode.d6.loss_mask: 0.5544  decode.d6.loss_dice: 1.0247  decode.d7.loss_cls: 0.0564  decode.d7.loss_mask: 0.5410  decode.d7.loss_dice: 1.0321  decode.d8.loss_cls: 0.0547  decode.d8.loss_mask: 0.5492  decode.d8.loss_dice: 1.0385
11/15 15:50:28 - mmengine - INFO - Iter(train) [51550/90000]  base_lr: 4.6515e-05 lr: 4.6515e-06  eta: 6:26:44  time: 0.5941  data_time: 0.0104  memory: 10675  grad_norm: 384.4609  loss: 15.9275  decode.loss_cls: 0.0526  decode.loss_mask: 0.4879  decode.loss_dice: 1.0113  decode.d0.loss_cls: 0.0925  decode.d0.loss_mask: 0.5186  decode.d0.loss_dice: 1.1000  decode.d1.loss_cls: 0.0574  decode.d1.loss_mask: 0.5009  decode.d1.loss_dice: 1.0443  decode.d2.loss_cls: 0.0713  decode.d2.loss_mask: 0.4987  decode.d2.loss_dice: 1.0233  decode.d3.loss_cls: 0.0576  decode.d3.loss_mask: 0.4963  decode.d3.loss_dice: 1.0272  decode.d4.loss_cls: 0.0544  decode.d4.loss_mask: 0.4992  decode.d4.loss_dice: 1.0347  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.4959  decode.d5.loss_dice: 1.0262  decode.d6.loss_cls: 0.0658  decode.d6.loss_mask: 0.4935  decode.d6.loss_dice: 1.0171  decode.d7.loss_cls: 0.0603  decode.d7.loss_mask: 0.4930  decode.d7.loss_dice: 1.0136  decode.d8.loss_cls: 0.0505  decode.d8.loss_mask: 0.4897  decode.d8.loss_dice: 1.0364
11/15 15:50:58 - mmengine - INFO - Iter(train) [51600/90000]  base_lr: 4.6461e-05 lr: 4.6461e-06  eta: 6:26:13  time: 0.5961  data_time: 0.0105  memory: 10713  grad_norm: 397.6157  loss: 16.3081  decode.loss_cls: 0.0504  decode.loss_mask: 0.5019  decode.loss_dice: 1.0706  decode.d0.loss_cls: 0.0893  decode.d0.loss_mask: 0.5035  decode.d0.loss_dice: 1.1141  decode.d1.loss_cls: 0.0560  decode.d1.loss_mask: 0.5054  decode.d1.loss_dice: 1.0703  decode.d2.loss_cls: 0.0511  decode.d2.loss_mask: 0.4977  decode.d2.loss_dice: 1.0868  decode.d3.loss_cls: 0.0561  decode.d3.loss_mask: 0.4960  decode.d3.loss_dice: 1.0460  decode.d4.loss_cls: 0.0541  decode.d4.loss_mask: 0.5026  decode.d4.loss_dice: 1.0725  decode.d5.loss_cls: 0.0562  decode.d5.loss_mask: 0.5029  decode.d5.loss_dice: 1.0407  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.4957  decode.d6.loss_dice: 1.0545  decode.d7.loss_cls: 0.0489  decode.d7.loss_mask: 0.4983  decode.d7.loss_dice: 1.0754  decode.d8.loss_cls: 0.0429  decode.d8.loss_mask: 0.5113  decode.d8.loss_dice: 1.1014
11/15 15:51:28 - mmengine - INFO - Iter(train) [51650/90000]  base_lr: 4.6406e-05 lr: 4.6406e-06  eta: 6:25:43  time: 0.5949  data_time: 0.0102  memory: 10692  grad_norm: 392.4518  loss: 18.9037  decode.loss_cls: 0.0842  decode.loss_mask: 0.5565  decode.loss_dice: 1.2620  decode.d0.loss_cls: 0.0910  decode.d0.loss_mask: 0.5774  decode.d0.loss_dice: 1.2869  decode.d1.loss_cls: 0.0807  decode.d1.loss_mask: 0.5592  decode.d1.loss_dice: 1.2904  decode.d2.loss_cls: 0.0958  decode.d2.loss_mask: 0.5590  decode.d2.loss_dice: 1.2368  decode.d3.loss_cls: 0.0787  decode.d3.loss_mask: 0.5566  decode.d3.loss_dice: 1.2394  decode.d4.loss_cls: 0.0908  decode.d4.loss_mask: 0.5411  decode.d4.loss_dice: 1.2355  decode.d5.loss_cls: 0.0899  decode.d5.loss_mask: 0.5327  decode.d5.loss_dice: 1.2368  decode.d6.loss_cls: 0.0854  decode.d6.loss_mask: 0.5449  decode.d6.loss_dice: 1.2460  decode.d7.loss_cls: 0.0792  decode.d7.loss_mask: 0.5507  decode.d7.loss_dice: 1.2623  decode.d8.loss_cls: 0.0839  decode.d8.loss_mask: 0.5453  decode.d8.loss_dice: 1.2249
11/15 15:51:58 - mmengine - INFO - Iter(train) [51700/90000]  base_lr: 4.6352e-05 lr: 4.6352e-06  eta: 6:25:12  time: 0.5934  data_time: 0.0103  memory: 10692  grad_norm: 551.2355  loss: 17.3764  decode.loss_cls: 0.0476  decode.loss_mask: 0.5379  decode.loss_dice: 1.1174  decode.d0.loss_cls: 0.0664  decode.d0.loss_mask: 0.5780  decode.d0.loss_dice: 1.1782  decode.d1.loss_cls: 0.0511  decode.d1.loss_mask: 0.5545  decode.d1.loss_dice: 1.1819  decode.d2.loss_cls: 0.0575  decode.d2.loss_mask: 0.5526  decode.d2.loss_dice: 1.1146  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.5523  decode.d3.loss_dice: 1.1297  decode.d4.loss_cls: 0.0554  decode.d4.loss_mask: 0.5469  decode.d4.loss_dice: 1.1064  decode.d5.loss_cls: 0.0504  decode.d5.loss_mask: 0.5435  decode.d5.loss_dice: 1.1369  decode.d6.loss_cls: 0.0519  decode.d6.loss_mask: 0.5386  decode.d6.loss_dice: 1.1108  decode.d7.loss_cls: 0.0441  decode.d7.loss_mask: 0.5517  decode.d7.loss_dice: 1.1366  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.5459  decode.d8.loss_dice: 1.1290
11/15 15:52:27 - mmengine - INFO - Iter(train) [51750/90000]  base_lr: 4.6297e-05 lr: 4.6297e-06  eta: 6:24:42  time: 0.5932  data_time: 0.0103  memory: 10692  grad_norm: 347.2585  loss: 13.6523  decode.loss_cls: 0.0414  decode.loss_mask: 0.4480  decode.loss_dice: 0.8867  decode.d0.loss_cls: 0.0905  decode.d0.loss_mask: 0.4853  decode.d0.loss_dice: 0.9315  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.4179  decode.d1.loss_dice: 0.8742  decode.d2.loss_cls: 0.0536  decode.d2.loss_mask: 0.4186  decode.d2.loss_dice: 0.8431  decode.d3.loss_cls: 0.0516  decode.d3.loss_mask: 0.4229  decode.d3.loss_dice: 0.8475  decode.d4.loss_cls: 0.0548  decode.d4.loss_mask: 0.4316  decode.d4.loss_dice: 0.8696  decode.d5.loss_cls: 0.0525  decode.d5.loss_mask: 0.4205  decode.d5.loss_dice: 0.8512  decode.d6.loss_cls: 0.0531  decode.d6.loss_mask: 0.4227  decode.d6.loss_dice: 0.8559  decode.d7.loss_cls: 0.0472  decode.d7.loss_mask: 0.4478  decode.d7.loss_dice: 0.8946  decode.d8.loss_cls: 0.0466  decode.d8.loss_mask: 0.4452  decode.d8.loss_dice: 0.8873
11/15 15:52:57 - mmengine - INFO - Iter(train) [51800/90000]  base_lr: 4.6243e-05 lr: 4.6243e-06  eta: 6:24:11  time: 0.5940  data_time: 0.0105  memory: 10675  grad_norm: 446.3646  loss: 15.2693  decode.loss_cls: 0.0533  decode.loss_mask: 0.4521  decode.loss_dice: 0.9899  decode.d0.loss_cls: 0.0762  decode.d0.loss_mask: 0.4667  decode.d0.loss_dice: 1.0369  decode.d1.loss_cls: 0.0578  decode.d1.loss_mask: 0.4666  decode.d1.loss_dice: 1.0288  decode.d2.loss_cls: 0.0625  decode.d2.loss_mask: 0.4568  decode.d2.loss_dice: 1.0087  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.4674  decode.d3.loss_dice: 1.0126  decode.d4.loss_cls: 0.0416  decode.d4.loss_mask: 0.4662  decode.d4.loss_dice: 1.0001  decode.d5.loss_cls: 0.0516  decode.d5.loss_mask: 0.4663  decode.d5.loss_dice: 1.0023  decode.d6.loss_cls: 0.0469  decode.d6.loss_mask: 0.4690  decode.d6.loss_dice: 0.9973  decode.d7.loss_cls: 0.0397  decode.d7.loss_mask: 0.4655  decode.d7.loss_dice: 1.0176  decode.d8.loss_cls: 0.0417  decode.d8.loss_mask: 0.4714  decode.d8.loss_dice: 1.0123
11/15 15:53:27 - mmengine - INFO - Iter(train) [51850/90000]  base_lr: 4.6188e-05 lr: 4.6188e-06  eta: 6:23:41  time: 0.5955  data_time: 0.0104  memory: 10641  grad_norm: 311.2109  loss: 16.1691  decode.loss_cls: 0.0752  decode.loss_mask: 0.5387  decode.loss_dice: 0.9857  decode.d0.loss_cls: 0.0774  decode.d0.loss_mask: 0.5594  decode.d0.loss_dice: 1.0389  decode.d1.loss_cls: 0.0664  decode.d1.loss_mask: 0.5288  decode.d1.loss_dice: 1.0112  decode.d2.loss_cls: 0.0519  decode.d2.loss_mask: 0.5305  decode.d2.loss_dice: 1.0027  decode.d3.loss_cls: 0.0550  decode.d3.loss_mask: 0.5565  decode.d3.loss_dice: 1.0099  decode.d4.loss_cls: 0.0493  decode.d4.loss_mask: 0.5604  decode.d4.loss_dice: 1.0130  decode.d5.loss_cls: 0.0704  decode.d5.loss_mask: 0.5417  decode.d5.loss_dice: 0.9832  decode.d6.loss_cls: 0.0640  decode.d6.loss_mask: 0.5379  decode.d6.loss_dice: 1.0086  decode.d7.loss_cls: 0.0536  decode.d7.loss_mask: 0.5550  decode.d7.loss_dice: 1.0252  decode.d8.loss_cls: 0.0634  decode.d8.loss_mask: 0.5385  decode.d8.loss_dice: 1.0168
11/15 15:53:57 - mmengine - INFO - Iter(train) [51900/90000]  base_lr: 4.6134e-05 lr: 4.6134e-06  eta: 6:23:11  time: 0.5959  data_time: 0.0107  memory: 10675  grad_norm: 507.4304  loss: 18.0978  decode.loss_cls: 0.0690  decode.loss_mask: 0.5735  decode.loss_dice: 1.1507  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.6166  decode.d0.loss_dice: 1.2198  decode.d1.loss_cls: 0.0948  decode.d1.loss_mask: 0.5630  decode.d1.loss_dice: 1.1424  decode.d2.loss_cls: 0.0774  decode.d2.loss_mask: 0.5667  decode.d2.loss_dice: 1.1269  decode.d3.loss_cls: 0.0747  decode.d3.loss_mask: 0.5793  decode.d3.loss_dice: 1.1646  decode.d4.loss_cls: 0.0794  decode.d4.loss_mask: 0.5744  decode.d4.loss_dice: 1.1599  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.5607  decode.d5.loss_dice: 1.1314  decode.d6.loss_cls: 0.0732  decode.d6.loss_mask: 0.5614  decode.d6.loss_dice: 1.1590  decode.d7.loss_cls: 0.0851  decode.d7.loss_mask: 0.5798  decode.d7.loss_dice: 1.1434  decode.d8.loss_cls: 0.0693  decode.d8.loss_mask: 0.5790  decode.d8.loss_dice: 1.1719
11/15 15:54:27 - mmengine - INFO - Iter(train) [51950/90000]  base_lr: 4.6079e-05 lr: 4.6079e-06  eta: 6:22:41  time: 0.5948  data_time: 0.0104  memory: 10656  grad_norm: 560.7960  loss: 15.2454  decode.loss_cls: 0.0598  decode.loss_mask: 0.4812  decode.loss_dice: 0.9786  decode.d0.loss_cls: 0.0701  decode.d0.loss_mask: 0.4867  decode.d0.loss_dice: 1.0362  decode.d1.loss_cls: 0.0577  decode.d1.loss_mask: 0.4723  decode.d1.loss_dice: 1.0127  decode.d2.loss_cls: 0.0687  decode.d2.loss_mask: 0.4637  decode.d2.loss_dice: 0.9861  decode.d3.loss_cls: 0.0556  decode.d3.loss_mask: 0.4690  decode.d3.loss_dice: 0.9770  decode.d4.loss_cls: 0.0560  decode.d4.loss_mask: 0.4702  decode.d4.loss_dice: 0.9794  decode.d5.loss_cls: 0.0490  decode.d5.loss_mask: 0.4687  decode.d5.loss_dice: 0.9744  decode.d6.loss_cls: 0.0693  decode.d6.loss_mask: 0.4689  decode.d6.loss_dice: 0.9860  decode.d7.loss_cls: 0.0610  decode.d7.loss_mask: 0.4832  decode.d7.loss_dice: 1.0005  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.4690  decode.d8.loss_dice: 0.9759
11/15 15:54:57 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 15:54:57 - mmengine - INFO - Iter(train) [52000/90000]  base_lr: 4.6025e-05 lr: 4.6025e-06  eta: 6:22:10  time: 0.5949  data_time: 0.0102  memory: 10692  grad_norm: 274.3865  loss: 15.3248  decode.loss_cls: 0.0421  decode.loss_mask: 0.5396  decode.loss_dice: 0.9202  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 0.5708  decode.d0.loss_dice: 0.9920  decode.d1.loss_cls: 0.0501  decode.d1.loss_mask: 0.5486  decode.d1.loss_dice: 0.9355  decode.d2.loss_cls: 0.0425  decode.d2.loss_mask: 0.5435  decode.d2.loss_dice: 0.9537  decode.d3.loss_cls: 0.0434  decode.d3.loss_mask: 0.5409  decode.d3.loss_dice: 0.9118  decode.d4.loss_cls: 0.0436  decode.d4.loss_mask: 0.5418  decode.d4.loss_dice: 0.9304  decode.d5.loss_cls: 0.0433  decode.d5.loss_mask: 0.5416  decode.d5.loss_dice: 0.9418  decode.d6.loss_cls: 0.0430  decode.d6.loss_mask: 0.5424  decode.d6.loss_dice: 0.9443  decode.d7.loss_cls: 0.0393  decode.d7.loss_mask: 0.5436  decode.d7.loss_dice: 0.9528  decode.d8.loss_cls: 0.0389  decode.d8.loss_mask: 0.5405  decode.d8.loss_dice: 0.9386
11/15 15:55:27 - mmengine - INFO - Iter(train) [52050/90000]  base_lr: 4.5970e-05 lr: 4.5970e-06  eta: 6:21:40  time: 0.5937  data_time: 0.0103  memory: 10758  grad_norm: 563.4165  loss: 18.0911  decode.loss_cls: 0.0546  decode.loss_mask: 0.5888  decode.loss_dice: 1.1275  decode.d0.loss_cls: 0.0972  decode.d0.loss_mask: 0.6194  decode.d0.loss_dice: 1.1726  decode.d1.loss_cls: 0.0571  decode.d1.loss_mask: 0.6052  decode.d1.loss_dice: 1.1753  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 0.5978  decode.d2.loss_dice: 1.1403  decode.d3.loss_cls: 0.0590  decode.d3.loss_mask: 0.5949  decode.d3.loss_dice: 1.1422  decode.d4.loss_cls: 0.0576  decode.d4.loss_mask: 0.5868  decode.d4.loss_dice: 1.1541  decode.d5.loss_cls: 0.0514  decode.d5.loss_mask: 0.6054  decode.d5.loss_dice: 1.1613  decode.d6.loss_cls: 0.0519  decode.d6.loss_mask: 0.6046  decode.d6.loss_dice: 1.1550  decode.d7.loss_cls: 0.0550  decode.d7.loss_mask: 0.6059  decode.d7.loss_dice: 1.1324  decode.d8.loss_cls: 0.0560  decode.d8.loss_mask: 0.5864  decode.d8.loss_dice: 1.1488
11/15 15:55:57 - mmengine - INFO - Iter(train) [52100/90000]  base_lr: 4.5916e-05 lr: 4.5916e-06  eta: 6:21:09  time: 0.5937  data_time: 0.0103  memory: 10713  grad_norm: 297.8567  loss: 17.1912  decode.loss_cls: 0.0643  decode.loss_mask: 0.5636  decode.loss_dice: 1.0791  decode.d0.loss_cls: 0.0707  decode.d0.loss_mask: 0.6132  decode.d0.loss_dice: 1.1857  decode.d1.loss_cls: 0.0724  decode.d1.loss_mask: 0.5375  decode.d1.loss_dice: 1.0967  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.5358  decode.d2.loss_dice: 1.0882  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 0.5400  decode.d3.loss_dice: 1.0811  decode.d4.loss_cls: 0.0680  decode.d4.loss_mask: 0.5404  decode.d4.loss_dice: 1.1088  decode.d5.loss_cls: 0.0601  decode.d5.loss_mask: 0.5344  decode.d5.loss_dice: 1.0846  decode.d6.loss_cls: 0.0616  decode.d6.loss_mask: 0.5451  decode.d6.loss_dice: 1.0891  decode.d7.loss_cls: 0.0568  decode.d7.loss_mask: 0.5600  decode.d7.loss_dice: 1.1147  decode.d8.loss_cls: 0.0564  decode.d8.loss_mask: 0.5508  decode.d8.loss_dice: 1.0948
11/15 15:56:26 - mmengine - INFO - Iter(train) [52150/90000]  base_lr: 4.5861e-05 lr: 4.5861e-06  eta: 6:20:39  time: 0.5938  data_time: 0.0103  memory: 10675  grad_norm: 350.7286  loss: 17.5301  decode.loss_cls: 0.0525  decode.loss_mask: 0.5837  decode.loss_dice: 1.1022  decode.d0.loss_cls: 0.0617  decode.d0.loss_mask: 0.6129  decode.d0.loss_dice: 1.2380  decode.d1.loss_cls: 0.0553  decode.d1.loss_mask: 0.5831  decode.d1.loss_dice: 1.1436  decode.d2.loss_cls: 0.0526  decode.d2.loss_mask: 0.5731  decode.d2.loss_dice: 1.1170  decode.d3.loss_cls: 0.0441  decode.d3.loss_mask: 0.5764  decode.d3.loss_dice: 1.1041  decode.d4.loss_cls: 0.0563  decode.d4.loss_mask: 0.5831  decode.d4.loss_dice: 1.0792  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.5785  decode.d5.loss_dice: 1.0902  decode.d6.loss_cls: 0.0562  decode.d6.loss_mask: 0.5722  decode.d6.loss_dice: 1.0939  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.5903  decode.d7.loss_dice: 1.0793  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 0.5893  decode.d8.loss_dice: 1.1015
11/15 15:56:56 - mmengine - INFO - Iter(train) [52200/90000]  base_lr: 4.5807e-05 lr: 4.5807e-06  eta: 6:20:08  time: 0.5942  data_time: 0.0102  memory: 10713  grad_norm: 335.4934  loss: 17.7570  decode.loss_cls: 0.0672  decode.loss_mask: 0.4737  decode.loss_dice: 1.2092  decode.d0.loss_cls: 0.1018  decode.d0.loss_mask: 0.4880  decode.d0.loss_dice: 1.2882  decode.d1.loss_cls: 0.0862  decode.d1.loss_mask: 0.4779  decode.d1.loss_dice: 1.2102  decode.d2.loss_cls: 0.0745  decode.d2.loss_mask: 0.4755  decode.d2.loss_dice: 1.2224  decode.d3.loss_cls: 0.0824  decode.d3.loss_mask: 0.4780  decode.d3.loss_dice: 1.2315  decode.d4.loss_cls: 0.0721  decode.d4.loss_mask: 0.4774  decode.d4.loss_dice: 1.2089  decode.d5.loss_cls: 0.0717  decode.d5.loss_mask: 0.4774  decode.d5.loss_dice: 1.2218  decode.d6.loss_cls: 0.0724  decode.d6.loss_mask: 0.4728  decode.d6.loss_dice: 1.2153  decode.d7.loss_cls: 0.0714  decode.d7.loss_mask: 0.4757  decode.d7.loss_dice: 1.2209  decode.d8.loss_cls: 0.0677  decode.d8.loss_mask: 0.4768  decode.d8.loss_dice: 1.1881
11/15 15:57:27 - mmengine - INFO - Iter(train) [52250/90000]  base_lr: 4.5752e-05 lr: 4.5752e-06  eta: 6:19:38  time: 0.5946  data_time: 0.0104  memory: 10675  grad_norm: 329.8548  loss: 16.0693  decode.loss_cls: 0.0777  decode.loss_mask: 0.5096  decode.loss_dice: 1.0039  decode.d0.loss_cls: 0.0975  decode.d0.loss_mask: 0.5447  decode.d0.loss_dice: 1.1162  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.5209  decode.d1.loss_dice: 1.0328  decode.d2.loss_cls: 0.0931  decode.d2.loss_mask: 0.5072  decode.d2.loss_dice: 0.9994  decode.d3.loss_cls: 0.0810  decode.d3.loss_mask: 0.5193  decode.d3.loss_dice: 0.9887  decode.d4.loss_cls: 0.0746  decode.d4.loss_mask: 0.5152  decode.d4.loss_dice: 1.0093  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.5108  decode.d5.loss_dice: 0.9833  decode.d6.loss_cls: 0.0860  decode.d6.loss_mask: 0.5113  decode.d6.loss_dice: 0.9942  decode.d7.loss_cls: 0.0916  decode.d7.loss_mask: 0.5084  decode.d7.loss_dice: 0.9674  decode.d8.loss_cls: 0.0914  decode.d8.loss_mask: 0.5098  decode.d8.loss_dice: 0.9631
11/15 15:57:58 - mmengine - INFO - Iter(train) [52300/90000]  base_lr: 4.5698e-05 lr: 4.5698e-06  eta: 6:19:09  time: 0.5949  data_time: 0.0104  memory: 10692  grad_norm: 304.5795  loss: 15.2396  decode.loss_cls: 0.0501  decode.loss_mask: 0.4620  decode.loss_dice: 0.9987  decode.d0.loss_cls: 0.0668  decode.d0.loss_mask: 0.4864  decode.d0.loss_dice: 1.0575  decode.d1.loss_cls: 0.0561  decode.d1.loss_mask: 0.4751  decode.d1.loss_dice: 1.0198  decode.d2.loss_cls: 0.0493  decode.d2.loss_mask: 0.4716  decode.d2.loss_dice: 0.9960  decode.d3.loss_cls: 0.0584  decode.d3.loss_mask: 0.4698  decode.d3.loss_dice: 0.9767  decode.d4.loss_cls: 0.0518  decode.d4.loss_mask: 0.4691  decode.d4.loss_dice: 0.9915  decode.d5.loss_cls: 0.0518  decode.d5.loss_mask: 0.4680  decode.d5.loss_dice: 1.0212  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.4645  decode.d6.loss_dice: 0.9800  decode.d7.loss_cls: 0.0521  decode.d7.loss_mask: 0.4553  decode.d7.loss_dice: 0.9722  decode.d8.loss_cls: 0.0513  decode.d8.loss_mask: 0.4602  decode.d8.loss_dice: 1.0005
11/15 15:58:28 - mmengine - INFO - Iter(train) [52350/90000]  base_lr: 4.5643e-05 lr: 4.5643e-06  eta: 6:18:39  time: 0.5941  data_time: 0.0102  memory: 10713  grad_norm: 518.7257  loss: 17.7690  decode.loss_cls: 0.0531  decode.loss_mask: 0.5397  decode.loss_dice: 1.1576  decode.d0.loss_cls: 0.0650  decode.d0.loss_mask: 0.5566  decode.d0.loss_dice: 1.2804  decode.d1.loss_cls: 0.0656  decode.d1.loss_mask: 0.5402  decode.d1.loss_dice: 1.2179  decode.d2.loss_cls: 0.0722  decode.d2.loss_mask: 0.5648  decode.d2.loss_dice: 1.1772  decode.d3.loss_cls: 0.0572  decode.d3.loss_mask: 0.5552  decode.d3.loss_dice: 1.1617  decode.d4.loss_cls: 0.0587  decode.d4.loss_mask: 0.5523  decode.d4.loss_dice: 1.1596  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.5224  decode.d5.loss_dice: 1.1537  decode.d6.loss_cls: 0.0566  decode.d6.loss_mask: 0.5151  decode.d6.loss_dice: 1.1385  decode.d7.loss_cls: 0.0516  decode.d7.loss_mask: 0.5210  decode.d7.loss_dice: 1.1562  decode.d8.loss_cls: 0.0490  decode.d8.loss_mask: 0.5357  decode.d8.loss_dice: 1.1716
11/15 15:58:58 - mmengine - INFO - Iter(train) [52400/90000]  base_lr: 4.5588e-05 lr: 4.5588e-06  eta: 6:18:08  time: 0.5942  data_time: 0.0102  memory: 10728  grad_norm: 195.1139  loss: 17.2778  decode.loss_cls: 0.0653  decode.loss_mask: 0.5341  decode.loss_dice: 1.0873  decode.d0.loss_cls: 0.0814  decode.d0.loss_mask: 0.5532  decode.d0.loss_dice: 1.1848  decode.d1.loss_cls: 0.0709  decode.d1.loss_mask: 0.5376  decode.d1.loss_dice: 1.1305  decode.d2.loss_cls: 0.0533  decode.d2.loss_mask: 0.5551  decode.d2.loss_dice: 1.1502  decode.d3.loss_cls: 0.0624  decode.d3.loss_mask: 0.5270  decode.d3.loss_dice: 1.1174  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.5450  decode.d4.loss_dice: 1.1096  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.5431  decode.d5.loss_dice: 1.1194  decode.d6.loss_cls: 0.0564  decode.d6.loss_mask: 0.5266  decode.d6.loss_dice: 1.1078  decode.d7.loss_cls: 0.0650  decode.d7.loss_mask: 0.5216  decode.d7.loss_dice: 1.1295  decode.d8.loss_cls: 0.0578  decode.d8.loss_mask: 0.5341  decode.d8.loss_dice: 1.1322
11/15 15:59:27 - mmengine - INFO - Iter(train) [52450/90000]  base_lr: 4.5534e-05 lr: 4.5534e-06  eta: 6:17:38  time: 0.5932  data_time: 0.0104  memory: 10713  grad_norm: 388.2685  loss: 17.5969  decode.loss_cls: 0.0615  decode.loss_mask: 0.5487  decode.loss_dice: 1.1337  decode.d0.loss_cls: 0.0924  decode.d0.loss_mask: 0.5693  decode.d0.loss_dice: 1.1469  decode.d1.loss_cls: 0.0740  decode.d1.loss_mask: 0.5599  decode.d1.loss_dice: 1.1285  decode.d2.loss_cls: 0.0775  decode.d2.loss_mask: 0.5496  decode.d2.loss_dice: 1.1130  decode.d3.loss_cls: 0.0520  decode.d3.loss_mask: 0.5657  decode.d3.loss_dice: 1.1406  decode.d4.loss_cls: 0.0645  decode.d4.loss_mask: 0.5600  decode.d4.loss_dice: 1.1325  decode.d5.loss_cls: 0.0697  decode.d5.loss_mask: 0.5582  decode.d5.loss_dice: 1.1374  decode.d6.loss_cls: 0.0561  decode.d6.loss_mask: 0.5608  decode.d6.loss_dice: 1.1511  decode.d7.loss_cls: 0.0509  decode.d7.loss_mask: 0.5596  decode.d7.loss_dice: 1.1565  decode.d8.loss_cls: 0.0569  decode.d8.loss_mask: 0.5587  decode.d8.loss_dice: 1.1110
11/15 15:59:57 - mmengine - INFO - Iter(train) [52500/90000]  base_lr: 4.5479e-05 lr: 4.5479e-06  eta: 6:17:07  time: 0.5943  data_time: 0.0104  memory: 10675  grad_norm: 339.5052  loss: 18.1037  decode.loss_cls: 0.0907  decode.loss_mask: 0.5744  decode.loss_dice: 1.1331  decode.d0.loss_cls: 0.0897  decode.d0.loss_mask: 0.6179  decode.d0.loss_dice: 1.2529  decode.d1.loss_cls: 0.0946  decode.d1.loss_mask: 0.5931  decode.d1.loss_dice: 1.1761  decode.d2.loss_cls: 0.0680  decode.d2.loss_mask: 0.5871  decode.d2.loss_dice: 1.1747  decode.d3.loss_cls: 0.0762  decode.d3.loss_mask: 0.5704  decode.d3.loss_dice: 1.1179  decode.d4.loss_cls: 0.0757  decode.d4.loss_mask: 0.5671  decode.d4.loss_dice: 1.1317  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.5766  decode.d5.loss_dice: 1.1567  decode.d6.loss_cls: 0.0725  decode.d6.loss_mask: 0.5650  decode.d6.loss_dice: 1.1270  decode.d7.loss_cls: 0.0687  decode.d7.loss_mask: 0.5775  decode.d7.loss_dice: 1.1159  decode.d8.loss_cls: 0.0702  decode.d8.loss_mask: 0.5802  decode.d8.loss_dice: 1.1360
11/15 16:00:27 - mmengine - INFO - Iter(train) [52550/90000]  base_lr: 4.5425e-05 lr: 4.5425e-06  eta: 6:16:37  time: 0.5938  data_time: 0.0103  memory: 10692  grad_norm: 257.8017  loss: 17.2203  decode.loss_cls: 0.0731  decode.loss_mask: 0.4971  decode.loss_dice: 1.1450  decode.d0.loss_cls: 0.0834  decode.d0.loss_mask: 0.5023  decode.d0.loss_dice: 1.2408  decode.d1.loss_cls: 0.0900  decode.d1.loss_mask: 0.4985  decode.d1.loss_dice: 1.1466  decode.d2.loss_cls: 0.0909  decode.d2.loss_mask: 0.4964  decode.d2.loss_dice: 1.1736  decode.d3.loss_cls: 0.0923  decode.d3.loss_mask: 0.4846  decode.d3.loss_dice: 1.1402  decode.d4.loss_cls: 0.0815  decode.d4.loss_mask: 0.4979  decode.d4.loss_dice: 1.1370  decode.d5.loss_cls: 0.0955  decode.d5.loss_mask: 0.4923  decode.d5.loss_dice: 1.0891  decode.d6.loss_cls: 0.0803  decode.d6.loss_mask: 0.4898  decode.d6.loss_dice: 1.1249  decode.d7.loss_cls: 0.0735  decode.d7.loss_mask: 0.4871  decode.d7.loss_dice: 1.1299  decode.d8.loss_cls: 0.0867  decode.d8.loss_mask: 0.4891  decode.d8.loss_dice: 1.1110
11/15 16:00:56 - mmengine - INFO - Iter(train) [52600/90000]  base_lr: 4.5370e-05 lr: 4.5370e-06  eta: 6:16:06  time: 0.5938  data_time: 0.0101  memory: 10692  grad_norm: 292.5116  loss: 16.8331  decode.loss_cls: 0.0686  decode.loss_mask: 0.4744  decode.loss_dice: 1.1102  decode.d0.loss_cls: 0.0967  decode.d0.loss_mask: 0.5358  decode.d0.loss_dice: 1.2060  decode.d1.loss_cls: 0.0773  decode.d1.loss_mask: 0.4883  decode.d1.loss_dice: 1.1559  decode.d2.loss_cls: 0.0765  decode.d2.loss_mask: 0.4969  decode.d2.loss_dice: 1.1089  decode.d3.loss_cls: 0.0765  decode.d3.loss_mask: 0.4898  decode.d3.loss_dice: 1.1241  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.4931  decode.d4.loss_dice: 1.0982  decode.d5.loss_cls: 0.0764  decode.d5.loss_mask: 0.4790  decode.d5.loss_dice: 1.0926  decode.d6.loss_cls: 0.0749  decode.d6.loss_mask: 0.4739  decode.d6.loss_dice: 1.1005  decode.d7.loss_cls: 0.0731  decode.d7.loss_mask: 0.4697  decode.d7.loss_dice: 1.1022  decode.d8.loss_cls: 0.0722  decode.d8.loss_mask: 0.4699  decode.d8.loss_dice: 1.1035
11/15 16:01:26 - mmengine - INFO - Iter(train) [52650/90000]  base_lr: 4.5316e-05 lr: 4.5316e-06  eta: 6:15:36  time: 0.5983  data_time: 0.0106  memory: 10728  grad_norm: 439.1104  loss: 16.6306  decode.loss_cls: 0.0518  decode.loss_mask: 0.5816  decode.loss_dice: 1.0037  decode.d0.loss_cls: 0.0773  decode.d0.loss_mask: 0.6603  decode.d0.loss_dice: 1.0417  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.6006  decode.d1.loss_dice: 0.9867  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.5895  decode.d2.loss_dice: 1.0030  decode.d3.loss_cls: 0.0514  decode.d3.loss_mask: 0.5915  decode.d3.loss_dice: 0.9882  decode.d4.loss_cls: 0.0550  decode.d4.loss_mask: 0.5976  decode.d4.loss_dice: 1.0101  decode.d5.loss_cls: 0.0597  decode.d5.loss_mask: 0.6088  decode.d5.loss_dice: 0.9758  decode.d6.loss_cls: 0.0512  decode.d6.loss_mask: 0.6020  decode.d6.loss_dice: 0.9965  decode.d7.loss_cls: 0.0538  decode.d7.loss_mask: 0.6020  decode.d7.loss_dice: 1.0072  decode.d8.loss_cls: 0.0486  decode.d8.loss_mask: 0.6024  decode.d8.loss_dice: 1.0160
11/15 16:01:56 - mmengine - INFO - Iter(train) [52700/90000]  base_lr: 4.5261e-05 lr: 4.5261e-06  eta: 6:15:05  time: 0.5944  data_time: 0.0102  memory: 10692  grad_norm: 363.4160  loss: 17.1899  decode.loss_cls: 0.0925  decode.loss_mask: 0.4955  decode.loss_dice: 1.1675  decode.d0.loss_cls: 0.0985  decode.d0.loss_mask: 0.5064  decode.d0.loss_dice: 1.1938  decode.d1.loss_cls: 0.0924  decode.d1.loss_mask: 0.5048  decode.d1.loss_dice: 1.1539  decode.d2.loss_cls: 0.0862  decode.d2.loss_mask: 0.4852  decode.d2.loss_dice: 1.1327  decode.d3.loss_cls: 0.0762  decode.d3.loss_mask: 0.4949  decode.d3.loss_dice: 1.1261  decode.d4.loss_cls: 0.0932  decode.d4.loss_mask: 0.4901  decode.d4.loss_dice: 1.1280  decode.d5.loss_cls: 0.0776  decode.d5.loss_mask: 0.4862  decode.d5.loss_dice: 1.1126  decode.d6.loss_cls: 0.0736  decode.d6.loss_mask: 0.4917  decode.d6.loss_dice: 1.1611  decode.d7.loss_cls: 0.0882  decode.d7.loss_mask: 0.4921  decode.d7.loss_dice: 1.0852  decode.d8.loss_cls: 0.0954  decode.d8.loss_mask: 0.4887  decode.d8.loss_dice: 1.1196
11/15 16:02:26 - mmengine - INFO - Iter(train) [52750/90000]  base_lr: 4.5206e-05 lr: 4.5206e-06  eta: 6:14:35  time: 0.5945  data_time: 0.0103  memory: 10675  grad_norm: 366.8141  loss: 17.2236  decode.loss_cls: 0.0614  decode.loss_mask: 0.5226  decode.loss_dice: 1.1385  decode.d0.loss_cls: 0.0759  decode.d0.loss_mask: 0.5520  decode.d0.loss_dice: 1.1999  decode.d1.loss_cls: 0.0710  decode.d1.loss_mask: 0.5316  decode.d1.loss_dice: 1.1244  decode.d2.loss_cls: 0.0544  decode.d2.loss_mask: 0.5431  decode.d2.loss_dice: 1.1281  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.5236  decode.d3.loss_dice: 1.1245  decode.d4.loss_cls: 0.0541  decode.d4.loss_mask: 0.5208  decode.d4.loss_dice: 1.1285  decode.d5.loss_cls: 0.0565  decode.d5.loss_mask: 0.5288  decode.d5.loss_dice: 1.1148  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.5271  decode.d6.loss_dice: 1.1106  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 0.5163  decode.d7.loss_dice: 1.1159  decode.d8.loss_cls: 0.0649  decode.d8.loss_mask: 0.5277  decode.d8.loss_dice: 1.1365
11/15 16:02:55 - mmengine - INFO - Iter(train) [52800/90000]  base_lr: 4.5152e-05 lr: 4.5152e-06  eta: 6:14:04  time: 0.5938  data_time: 0.0102  memory: 10656  grad_norm: 196.4237  loss: 14.4971  decode.loss_cls: 0.0403  decode.loss_mask: 0.4504  decode.loss_dice: 0.9501  decode.d0.loss_cls: 0.0614  decode.d0.loss_mask: 0.4637  decode.d0.loss_dice: 1.0088  decode.d1.loss_cls: 0.0413  decode.d1.loss_mask: 0.4531  decode.d1.loss_dice: 0.9740  decode.d2.loss_cls: 0.0310  decode.d2.loss_mask: 0.4576  decode.d2.loss_dice: 0.9544  decode.d3.loss_cls: 0.0326  decode.d3.loss_mask: 0.4557  decode.d3.loss_dice: 0.9535  decode.d4.loss_cls: 0.0402  decode.d4.loss_mask: 0.4541  decode.d4.loss_dice: 0.9647  decode.d5.loss_cls: 0.0343  decode.d5.loss_mask: 0.4495  decode.d5.loss_dice: 0.9672  decode.d6.loss_cls: 0.0336  decode.d6.loss_mask: 0.4465  decode.d6.loss_dice: 0.9506  decode.d7.loss_cls: 0.0298  decode.d7.loss_mask: 0.4483  decode.d7.loss_dice: 0.9313  decode.d8.loss_cls: 0.0320  decode.d8.loss_mask: 0.4542  decode.d8.loss_dice: 0.9328
11/15 16:03:25 - mmengine - INFO - Iter(train) [52850/90000]  base_lr: 4.5097e-05 lr: 4.5097e-06  eta: 6:13:34  time: 0.5932  data_time: 0.0101  memory: 10692  grad_norm: 207.5042  loss: 14.4485  decode.loss_cls: 0.0376  decode.loss_mask: 0.4618  decode.loss_dice: 0.9284  decode.d0.loss_cls: 0.0884  decode.d0.loss_mask: 0.4856  decode.d0.loss_dice: 0.9698  decode.d1.loss_cls: 0.0501  decode.d1.loss_mask: 0.4698  decode.d1.loss_dice: 0.9454  decode.d2.loss_cls: 0.0494  decode.d2.loss_mask: 0.4581  decode.d2.loss_dice: 0.9346  decode.d3.loss_cls: 0.0450  decode.d3.loss_mask: 0.4507  decode.d3.loss_dice: 0.9265  decode.d4.loss_cls: 0.0424  decode.d4.loss_mask: 0.4541  decode.d4.loss_dice: 0.9326  decode.d5.loss_cls: 0.0460  decode.d5.loss_mask: 0.4547  decode.d5.loss_dice: 0.9006  decode.d6.loss_cls: 0.0380  decode.d6.loss_mask: 0.4607  decode.d6.loss_dice: 0.9116  decode.d7.loss_cls: 0.0386  decode.d7.loss_mask: 0.4672  decode.d7.loss_dice: 0.9408  decode.d8.loss_cls: 0.0405  decode.d8.loss_mask: 0.4705  decode.d8.loss_dice: 0.9490
11/15 16:03:55 - mmengine - INFO - Iter(train) [52900/90000]  base_lr: 4.5043e-05 lr: 4.5043e-06  eta: 6:13:03  time: 0.5930  data_time: 0.0102  memory: 10742  grad_norm: 530.0514  loss: 15.8241  decode.loss_cls: 0.0443  decode.loss_mask: 0.4977  decode.loss_dice: 1.0011  decode.d0.loss_cls: 0.0649  decode.d0.loss_mask: 0.5286  decode.d0.loss_dice: 1.0967  decode.d1.loss_cls: 0.0558  decode.d1.loss_mask: 0.4891  decode.d1.loss_dice: 1.0537  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.5068  decode.d2.loss_dice: 1.0421  decode.d3.loss_cls: 0.0449  decode.d3.loss_mask: 0.5083  decode.d3.loss_dice: 1.0124  decode.d4.loss_cls: 0.0454  decode.d4.loss_mask: 0.5050  decode.d4.loss_dice: 1.0246  decode.d5.loss_cls: 0.0433  decode.d5.loss_mask: 0.5086  decode.d5.loss_dice: 1.0196  decode.d6.loss_cls: 0.0415  decode.d6.loss_mask: 0.5096  decode.d6.loss_dice: 1.0169  decode.d7.loss_cls: 0.0464  decode.d7.loss_mask: 0.4920  decode.d7.loss_dice: 1.0192  decode.d8.loss_cls: 0.0482  decode.d8.loss_mask: 0.4918  decode.d8.loss_dice: 1.0147
11/15 16:04:25 - mmengine - INFO - Iter(train) [52950/90000]  base_lr: 4.4988e-05 lr: 4.4988e-06  eta: 6:12:33  time: 0.5947  data_time: 0.0102  memory: 10675  grad_norm: 1319.5809  loss: 17.9850  decode.loss_cls: 0.0843  decode.loss_mask: 0.5469  decode.loss_dice: 1.1673  decode.d0.loss_cls: 0.1111  decode.d0.loss_mask: 0.5714  decode.d0.loss_dice: 1.2650  decode.d1.loss_cls: 0.0905  decode.d1.loss_mask: 0.5707  decode.d1.loss_dice: 1.2402  decode.d2.loss_cls: 0.1005  decode.d2.loss_mask: 0.5249  decode.d2.loss_dice: 1.1617  decode.d3.loss_cls: 0.0871  decode.d3.loss_mask: 0.5278  decode.d3.loss_dice: 1.1704  decode.d4.loss_cls: 0.0970  decode.d4.loss_mask: 0.5147  decode.d4.loss_dice: 1.1585  decode.d5.loss_cls: 0.0912  decode.d5.loss_mask: 0.5108  decode.d5.loss_dice: 1.1371  decode.d6.loss_cls: 0.0859  decode.d6.loss_mask: 0.5048  decode.d6.loss_dice: 1.1493  decode.d7.loss_cls: 0.1027  decode.d7.loss_mask: 0.5055  decode.d7.loss_dice: 1.1292  decode.d8.loss_cls: 0.0839  decode.d8.loss_mask: 0.5426  decode.d8.loss_dice: 1.1523
11/15 16:04:54 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 16:04:54 - mmengine - INFO - Iter(train) [53000/90000]  base_lr: 4.4933e-05 lr: 4.4933e-06  eta: 6:12:02  time: 0.5949  data_time: 0.0102  memory: 10675  grad_norm: 378.5288  loss: 17.1318  decode.loss_cls: 0.0729  decode.loss_mask: 0.4982  decode.loss_dice: 1.1410  decode.d0.loss_cls: 0.0781  decode.d0.loss_mask: 0.5492  decode.d0.loss_dice: 1.2657  decode.d1.loss_cls: 0.0897  decode.d1.loss_mask: 0.5184  decode.d1.loss_dice: 1.1462  decode.d2.loss_cls: 0.0894  decode.d2.loss_mask: 0.4934  decode.d2.loss_dice: 1.1292  decode.d3.loss_cls: 0.0790  decode.d3.loss_mask: 0.4854  decode.d3.loss_dice: 1.1049  decode.d4.loss_cls: 0.0839  decode.d4.loss_mask: 0.4903  decode.d4.loss_dice: 1.1180  decode.d5.loss_cls: 0.0782  decode.d5.loss_mask: 0.4828  decode.d5.loss_dice: 1.0984  decode.d6.loss_cls: 0.0742  decode.d6.loss_mask: 0.4877  decode.d6.loss_dice: 1.1351  decode.d7.loss_cls: 0.0732  decode.d7.loss_mask: 0.4931  decode.d7.loss_dice: 1.1125  decode.d8.loss_cls: 0.0641  decode.d8.loss_mask: 0.4952  decode.d8.loss_dice: 1.1044
11/15 16:05:24 - mmengine - INFO - Iter(train) [53050/90000]  base_lr: 4.4879e-05 lr: 4.4879e-06  eta: 6:11:32  time: 0.5955  data_time: 0.0104  memory: 10692  grad_norm: 354.7778  loss: 15.2814  decode.loss_cls: 0.0593  decode.loss_mask: 0.4365  decode.loss_dice: 1.0189  decode.d0.loss_cls: 0.0866  decode.d0.loss_mask: 0.4421  decode.d0.loss_dice: 1.0725  decode.d1.loss_cls: 0.0664  decode.d1.loss_mask: 0.4306  decode.d1.loss_dice: 1.0291  decode.d2.loss_cls: 0.0683  decode.d2.loss_mask: 0.4324  decode.d2.loss_dice: 1.0376  decode.d3.loss_cls: 0.0519  decode.d3.loss_mask: 0.4378  decode.d3.loss_dice: 1.0322  decode.d4.loss_cls: 0.0612  decode.d4.loss_mask: 0.4362  decode.d4.loss_dice: 1.0241  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.4364  decode.d5.loss_dice: 1.0100  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.4405  decode.d6.loss_dice: 1.0417  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.4342  decode.d7.loss_dice: 1.0049  decode.d8.loss_cls: 0.0570  decode.d8.loss_mask: 0.4346  decode.d8.loss_dice: 1.0147
11/15 16:05:54 - mmengine - INFO - Iter(train) [53100/90000]  base_lr: 4.4824e-05 lr: 4.4824e-06  eta: 6:11:02  time: 0.5954  data_time: 0.0104  memory: 10692  grad_norm: 282.2051  loss: 18.0820  decode.loss_cls: 0.0703  decode.loss_mask: 0.5288  decode.loss_dice: 1.1774  decode.d0.loss_cls: 0.0779  decode.d0.loss_mask: 0.5380  decode.d0.loss_dice: 1.2939  decode.d1.loss_cls: 0.0698  decode.d1.loss_mask: 0.5370  decode.d1.loss_dice: 1.2644  decode.d2.loss_cls: 0.0617  decode.d2.loss_mask: 0.5381  decode.d2.loss_dice: 1.2248  decode.d3.loss_cls: 0.0517  decode.d3.loss_mask: 0.5352  decode.d3.loss_dice: 1.1986  decode.d4.loss_cls: 0.0605  decode.d4.loss_mask: 0.5369  decode.d4.loss_dice: 1.1727  decode.d5.loss_cls: 0.0547  decode.d5.loss_mask: 0.5315  decode.d5.loss_dice: 1.1951  decode.d6.loss_cls: 0.0527  decode.d6.loss_mask: 0.5300  decode.d6.loss_dice: 1.2017  decode.d7.loss_cls: 0.0697  decode.d7.loss_mask: 0.5328  decode.d7.loss_dice: 1.1837  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.5256  decode.d8.loss_dice: 1.2063
11/15 16:06:24 - mmengine - INFO - Iter(train) [53150/90000]  base_lr: 4.4769e-05 lr: 4.4769e-06  eta: 6:10:31  time: 0.5951  data_time: 0.0103  memory: 10675  grad_norm: 432.0923  loss: 18.2618  decode.loss_cls: 0.0654  decode.loss_mask: 0.5153  decode.loss_dice: 1.2508  decode.d0.loss_cls: 0.0893  decode.d0.loss_mask: 0.5576  decode.d0.loss_dice: 1.3186  decode.d1.loss_cls: 0.0678  decode.d1.loss_mask: 0.5268  decode.d1.loss_dice: 1.2752  decode.d2.loss_cls: 0.0710  decode.d2.loss_mask: 0.5269  decode.d2.loss_dice: 1.2461  decode.d3.loss_cls: 0.0792  decode.d3.loss_mask: 0.5155  decode.d3.loss_dice: 1.2208  decode.d4.loss_cls: 0.0656  decode.d4.loss_mask: 0.5216  decode.d4.loss_dice: 1.2447  decode.d5.loss_cls: 0.0709  decode.d5.loss_mask: 0.4843  decode.d5.loss_dice: 1.2361  decode.d6.loss_cls: 0.0806  decode.d6.loss_mask: 0.4835  decode.d6.loss_dice: 1.1958  decode.d7.loss_cls: 0.0747  decode.d7.loss_mask: 0.4887  decode.d7.loss_dice: 1.2145  decode.d8.loss_cls: 0.0668  decode.d8.loss_mask: 0.4873  decode.d8.loss_dice: 1.2204
11/15 16:06:54 - mmengine - INFO - Iter(train) [53200/90000]  base_lr: 4.4715e-05 lr: 4.4715e-06  eta: 6:10:01  time: 0.5956  data_time: 0.0102  memory: 10692  grad_norm: 381.8173  loss: 19.0753  decode.loss_cls: 0.0912  decode.loss_mask: 0.5634  decode.loss_dice: 1.2264  decode.d0.loss_cls: 0.1088  decode.d0.loss_mask: 0.5877  decode.d0.loss_dice: 1.3125  decode.d1.loss_cls: 0.0806  decode.d1.loss_mask: 0.5609  decode.d1.loss_dice: 1.2791  decode.d2.loss_cls: 0.1038  decode.d2.loss_mask: 0.5640  decode.d2.loss_dice: 1.2501  decode.d3.loss_cls: 0.0868  decode.d3.loss_mask: 0.5648  decode.d3.loss_dice: 1.2174  decode.d4.loss_cls: 0.0977  decode.d4.loss_mask: 0.5754  decode.d4.loss_dice: 1.2396  decode.d5.loss_cls: 0.0946  decode.d5.loss_mask: 0.5647  decode.d5.loss_dice: 1.2248  decode.d6.loss_cls: 0.0866  decode.d6.loss_mask: 0.5760  decode.d6.loss_dice: 1.2572  decode.d7.loss_cls: 0.0749  decode.d7.loss_mask: 0.5707  decode.d7.loss_dice: 1.2358  decode.d8.loss_cls: 0.0901  decode.d8.loss_mask: 0.5652  decode.d8.loss_dice: 1.2243
11/15 16:07:24 - mmengine - INFO - Iter(train) [53250/90000]  base_lr: 4.4660e-05 lr: 4.4660e-06  eta: 6:09:30  time: 0.5948  data_time: 0.0102  memory: 10675  grad_norm: 604.1585  loss: 17.1492  decode.loss_cls: 0.0937  decode.loss_mask: 0.5095  decode.loss_dice: 1.1237  decode.d0.loss_cls: 0.1083  decode.d0.loss_mask: 0.5105  decode.d0.loss_dice: 1.1785  decode.d1.loss_cls: 0.0756  decode.d1.loss_mask: 0.5238  decode.d1.loss_dice: 1.1427  decode.d2.loss_cls: 0.1018  decode.d2.loss_mask: 0.4973  decode.d2.loss_dice: 1.0905  decode.d3.loss_cls: 0.0902  decode.d3.loss_mask: 0.5043  decode.d3.loss_dice: 1.1270  decode.d4.loss_cls: 0.0991  decode.d4.loss_mask: 0.4907  decode.d4.loss_dice: 1.1102  decode.d5.loss_cls: 0.0883  decode.d5.loss_mask: 0.5022  decode.d5.loss_dice: 1.0952  decode.d6.loss_cls: 0.0906  decode.d6.loss_mask: 0.5024  decode.d6.loss_dice: 1.0970  decode.d7.loss_cls: 0.0938  decode.d7.loss_mask: 0.5024  decode.d7.loss_dice: 1.0917  decode.d8.loss_cls: 0.0848  decode.d8.loss_mask: 0.5076  decode.d8.loss_dice: 1.1158
11/15 16:07:53 - mmengine - INFO - Iter(train) [53300/90000]  base_lr: 4.4605e-05 lr: 4.4605e-06  eta: 6:09:00  time: 0.5944  data_time: 0.0102  memory: 10656  grad_norm: 264.0541  loss: 16.6891  decode.loss_cls: 0.0495  decode.loss_mask: 0.4780  decode.loss_dice: 1.1464  decode.d0.loss_cls: 0.0617  decode.d0.loss_mask: 0.4901  decode.d0.loss_dice: 1.1880  decode.d1.loss_cls: 0.0440  decode.d1.loss_mask: 0.4660  decode.d1.loss_dice: 1.1705  decode.d2.loss_cls: 0.0461  decode.d2.loss_mask: 0.4588  decode.d2.loss_dice: 1.1453  decode.d3.loss_cls: 0.0475  decode.d3.loss_mask: 0.4646  decode.d3.loss_dice: 1.1331  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.4574  decode.d4.loss_dice: 1.1540  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.4674  decode.d5.loss_dice: 1.1487  decode.d6.loss_cls: 0.0519  decode.d6.loss_mask: 0.4668  decode.d6.loss_dice: 1.1606  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.4670  decode.d7.loss_dice: 1.1397  decode.d8.loss_cls: 0.0513  decode.d8.loss_mask: 0.4588  decode.d8.loss_dice: 1.1276
11/15 16:08:23 - mmengine - INFO - Iter(train) [53350/90000]  base_lr: 4.4551e-05 lr: 4.4551e-06  eta: 6:08:29  time: 0.5947  data_time: 0.0105  memory: 10656  grad_norm: 290.0995  loss: 15.9860  decode.loss_cls: 0.0495  decode.loss_mask: 0.4984  decode.loss_dice: 1.0040  decode.d0.loss_cls: 0.0797  decode.d0.loss_mask: 0.5159  decode.d0.loss_dice: 1.0917  decode.d1.loss_cls: 0.0683  decode.d1.loss_mask: 0.4976  decode.d1.loss_dice: 1.0270  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.4984  decode.d2.loss_dice: 1.0270  decode.d3.loss_cls: 0.0525  decode.d3.loss_mask: 0.4989  decode.d3.loss_dice: 1.0244  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.4996  decode.d4.loss_dice: 1.0710  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 0.4966  decode.d5.loss_dice: 1.0195  decode.d6.loss_cls: 0.0651  decode.d6.loss_mask: 0.4980  decode.d6.loss_dice: 1.0279  decode.d7.loss_cls: 0.0517  decode.d7.loss_mask: 0.4927  decode.d7.loss_dice: 1.0404  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 0.5024  decode.d8.loss_dice: 1.0514
11/15 16:08:53 - mmengine - INFO - Iter(train) [53400/90000]  base_lr: 4.4496e-05 lr: 4.4496e-06  eta: 6:07:59  time: 0.5946  data_time: 0.0105  memory: 10656  grad_norm: 570.2322  loss: 18.6679  decode.loss_cls: 0.0662  decode.loss_mask: 0.6010  decode.loss_dice: 1.1873  decode.d0.loss_cls: 0.0684  decode.d0.loss_mask: 0.6493  decode.d0.loss_dice: 1.3110  decode.d1.loss_cls: 0.0704  decode.d1.loss_mask: 0.6350  decode.d1.loss_dice: 1.2428  decode.d2.loss_cls: 0.0679  decode.d2.loss_mask: 0.5870  decode.d2.loss_dice: 1.1972  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.5742  decode.d3.loss_dice: 1.1977  decode.d4.loss_cls: 0.0710  decode.d4.loss_mask: 0.5812  decode.d4.loss_dice: 1.1804  decode.d5.loss_cls: 0.0702  decode.d5.loss_mask: 0.5732  decode.d5.loss_dice: 1.1624  decode.d6.loss_cls: 0.0779  decode.d6.loss_mask: 0.5621  decode.d6.loss_dice: 1.1582  decode.d7.loss_cls: 0.0595  decode.d7.loss_mask: 0.6031  decode.d7.loss_dice: 1.2218  decode.d8.loss_cls: 0.0718  decode.d8.loss_mask: 0.5974  decode.d8.loss_dice: 1.1618
11/15 16:09:23 - mmengine - INFO - Iter(train) [53450/90000]  base_lr: 4.4441e-05 lr: 4.4441e-06  eta: 6:07:29  time: 0.5949  data_time: 0.0102  memory: 10694  grad_norm: 392.7631  loss: 17.5044  decode.loss_cls: 0.0575  decode.loss_mask: 0.5207  decode.loss_dice: 1.1653  decode.d0.loss_cls: 0.0896  decode.d0.loss_mask: 0.5707  decode.d0.loss_dice: 1.2433  decode.d1.loss_cls: 0.0661  decode.d1.loss_mask: 0.5183  decode.d1.loss_dice: 1.2026  decode.d2.loss_cls: 0.0651  decode.d2.loss_mask: 0.5138  decode.d2.loss_dice: 1.1708  decode.d3.loss_cls: 0.0687  decode.d3.loss_mask: 0.5039  decode.d3.loss_dice: 1.1288  decode.d4.loss_cls: 0.0751  decode.d4.loss_mask: 0.5193  decode.d4.loss_dice: 1.0973  decode.d5.loss_cls: 0.0629  decode.d5.loss_mask: 0.5490  decode.d5.loss_dice: 1.1218  decode.d6.loss_cls: 0.0631  decode.d6.loss_mask: 0.5261  decode.d6.loss_dice: 1.1400  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.5197  decode.d7.loss_dice: 1.1527  decode.d8.loss_cls: 0.0626  decode.d8.loss_mask: 0.5099  decode.d8.loss_dice: 1.1498
11/15 16:09:52 - mmengine - INFO - Iter(train) [53500/90000]  base_lr: 4.4386e-05 lr: 4.4386e-06  eta: 6:06:58  time: 0.5936  data_time: 0.0101  memory: 10656  grad_norm: 515.2005  loss: 18.5994  decode.loss_cls: 0.0521  decode.loss_mask: 0.6393  decode.loss_dice: 1.1243  decode.d0.loss_cls: 0.0764  decode.d0.loss_mask: 0.7033  decode.d0.loss_dice: 1.2288  decode.d1.loss_cls: 0.0604  decode.d1.loss_mask: 0.6866  decode.d1.loss_dice: 1.1759  decode.d2.loss_cls: 0.0709  decode.d2.loss_mask: 0.6374  decode.d2.loss_dice: 1.1493  decode.d3.loss_cls: 0.0594  decode.d3.loss_mask: 0.6482  decode.d3.loss_dice: 1.1290  decode.d4.loss_cls: 0.0518  decode.d4.loss_mask: 0.6585  decode.d4.loss_dice: 1.1292  decode.d5.loss_cls: 0.0543  decode.d5.loss_mask: 0.6492  decode.d5.loss_dice: 1.1304  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.6326  decode.d6.loss_dice: 1.1296  decode.d7.loss_cls: 0.0520  decode.d7.loss_mask: 0.6493  decode.d7.loss_dice: 1.1414  decode.d8.loss_cls: 0.0485  decode.d8.loss_mask: 0.6450  decode.d8.loss_dice: 1.1313
11/15 16:10:22 - mmengine - INFO - Iter(train) [53550/90000]  base_lr: 4.4332e-05 lr: 4.4332e-06  eta: 6:06:28  time: 0.5998  data_time: 0.0105  memory: 10656  grad_norm: 204.3559  loss: 16.3875  decode.loss_cls: 0.0646  decode.loss_mask: 0.4675  decode.loss_dice: 1.1006  decode.d0.loss_cls: 0.0911  decode.d0.loss_mask: 0.4726  decode.d0.loss_dice: 1.1483  decode.d1.loss_cls: 0.0665  decode.d1.loss_mask: 0.4650  decode.d1.loss_dice: 1.1230  decode.d2.loss_cls: 0.0850  decode.d2.loss_mask: 0.4688  decode.d2.loss_dice: 1.0799  decode.d3.loss_cls: 0.0538  decode.d3.loss_mask: 0.4731  decode.d3.loss_dice: 1.1065  decode.d4.loss_cls: 0.0653  decode.d4.loss_mask: 0.4604  decode.d4.loss_dice: 1.0944  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.4661  decode.d5.loss_dice: 1.1048  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.4654  decode.d6.loss_dice: 1.1025  decode.d7.loss_cls: 0.0700  decode.d7.loss_mask: 0.4640  decode.d7.loss_dice: 1.0987  decode.d8.loss_cls: 0.0596  decode.d8.loss_mask: 0.4673  decode.d8.loss_dice: 1.0940
11/15 16:10:52 - mmengine - INFO - Iter(train) [53600/90000]  base_lr: 4.4277e-05 lr: 4.4277e-06  eta: 6:05:57  time: 0.5949  data_time: 0.0102  memory: 10692  grad_norm: 187.1427  loss: 16.5908  decode.loss_cls: 0.0741  decode.loss_mask: 0.4671  decode.loss_dice: 1.1181  decode.d0.loss_cls: 0.0749  decode.d0.loss_mask: 0.4843  decode.d0.loss_dice: 1.2133  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.4656  decode.d1.loss_dice: 1.1180  decode.d2.loss_cls: 0.0694  decode.d2.loss_mask: 0.4659  decode.d2.loss_dice: 1.1268  decode.d3.loss_cls: 0.0688  decode.d3.loss_mask: 0.4704  decode.d3.loss_dice: 1.1000  decode.d4.loss_cls: 0.0851  decode.d4.loss_mask: 0.4637  decode.d4.loss_dice: 1.0980  decode.d5.loss_cls: 0.0717  decode.d5.loss_mask: 0.4654  decode.d5.loss_dice: 1.0904  decode.d6.loss_cls: 0.0686  decode.d6.loss_mask: 0.4643  decode.d6.loss_dice: 1.1067  decode.d7.loss_cls: 0.0561  decode.d7.loss_mask: 0.4644  decode.d7.loss_dice: 1.1105  decode.d8.loss_cls: 0.0634  decode.d8.loss_mask: 0.4611  decode.d8.loss_dice: 1.1223
11/15 16:11:22 - mmengine - INFO - Iter(train) [53650/90000]  base_lr: 4.4222e-05 lr: 4.4222e-06  eta: 6:05:27  time: 0.5942  data_time: 0.0102  memory: 10656  grad_norm: 1169.9709  loss: 17.6227  decode.loss_cls: 0.0839  decode.loss_mask: 0.5586  decode.loss_dice: 1.0775  decode.d0.loss_cls: 0.0871  decode.d0.loss_mask: 0.6027  decode.d0.loss_dice: 1.1585  decode.d1.loss_cls: 0.0828  decode.d1.loss_mask: 0.5689  decode.d1.loss_dice: 1.1165  decode.d2.loss_cls: 0.0700  decode.d2.loss_mask: 0.5667  decode.d2.loss_dice: 1.1211  decode.d3.loss_cls: 0.0795  decode.d3.loss_mask: 0.5837  decode.d3.loss_dice: 1.1096  decode.d4.loss_cls: 0.0980  decode.d4.loss_mask: 0.5526  decode.d4.loss_dice: 1.0556  decode.d5.loss_cls: 0.0841  decode.d5.loss_mask: 0.5590  decode.d5.loss_dice: 1.1279  decode.d6.loss_cls: 0.0808  decode.d6.loss_mask: 0.5461  decode.d6.loss_dice: 1.1135  decode.d7.loss_cls: 0.0821  decode.d7.loss_mask: 0.5742  decode.d7.loss_dice: 1.1104  decode.d8.loss_cls: 0.0857  decode.d8.loss_mask: 0.5742  decode.d8.loss_dice: 1.1113
11/15 16:11:51 - mmengine - INFO - Iter(train) [53700/90000]  base_lr: 4.4167e-05 lr: 4.4167e-06  eta: 6:04:56  time: 0.5957  data_time: 0.0102  memory: 10675  grad_norm: 494.8944  loss: 14.4792  decode.loss_cls: 0.0366  decode.loss_mask: 0.4662  decode.loss_dice: 0.9321  decode.d0.loss_cls: 0.0716  decode.d0.loss_mask: 0.4830  decode.d0.loss_dice: 0.9967  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.4749  decode.d1.loss_dice: 0.9429  decode.d2.loss_cls: 0.0431  decode.d2.loss_mask: 0.4523  decode.d2.loss_dice: 0.9208  decode.d3.loss_cls: 0.0327  decode.d3.loss_mask: 0.4649  decode.d3.loss_dice: 0.9238  decode.d4.loss_cls: 0.0326  decode.d4.loss_mask: 0.4631  decode.d4.loss_dice: 0.9398  decode.d5.loss_cls: 0.0378  decode.d5.loss_mask: 0.4697  decode.d5.loss_dice: 0.9340  decode.d6.loss_cls: 0.0332  decode.d6.loss_mask: 0.4698  decode.d6.loss_dice: 0.9278  decode.d7.loss_cls: 0.0431  decode.d7.loss_mask: 0.4721  decode.d7.loss_dice: 0.9147  decode.d8.loss_cls: 0.0324  decode.d8.loss_mask: 0.4707  decode.d8.loss_dice: 0.9382
11/15 16:12:21 - mmengine - INFO - Iter(train) [53750/90000]  base_lr: 4.4113e-05 lr: 4.4113e-06  eta: 6:04:26  time: 0.5931  data_time: 0.0103  memory: 10742  grad_norm: 245.9762  loss: 14.5580  decode.loss_cls: 0.0524  decode.loss_mask: 0.4552  decode.loss_dice: 0.9154  decode.d0.loss_cls: 0.0730  decode.d0.loss_mask: 0.4741  decode.d0.loss_dice: 0.9935  decode.d1.loss_cls: 0.0363  decode.d1.loss_mask: 0.4521  decode.d1.loss_dice: 0.9789  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.4549  decode.d2.loss_dice: 0.9445  decode.d3.loss_cls: 0.0448  decode.d3.loss_mask: 0.4520  decode.d3.loss_dice: 0.9531  decode.d4.loss_cls: 0.0374  decode.d4.loss_mask: 0.4527  decode.d4.loss_dice: 0.9508  decode.d5.loss_cls: 0.0281  decode.d5.loss_mask: 0.4577  decode.d5.loss_dice: 0.9724  decode.d6.loss_cls: 0.0471  decode.d6.loss_mask: 0.4577  decode.d6.loss_dice: 0.9573  decode.d7.loss_cls: 0.0372  decode.d7.loss_mask: 0.4492  decode.d7.loss_dice: 0.9417  decode.d8.loss_cls: 0.0456  decode.d8.loss_mask: 0.4546  decode.d8.loss_dice: 0.9395
11/15 16:12:51 - mmengine - INFO - Iter(train) [53800/90000]  base_lr: 4.4058e-05 lr: 4.4058e-06  eta: 6:03:55  time: 0.5945  data_time: 0.0103  memory: 10656  grad_norm: 410.4023  loss: 16.7325  decode.loss_cls: 0.0535  decode.loss_mask: 0.5317  decode.loss_dice: 1.0759  decode.d0.loss_cls: 0.0826  decode.d0.loss_mask: 0.5504  decode.d0.loss_dice: 1.1565  decode.d1.loss_cls: 0.0555  decode.d1.loss_mask: 0.5281  decode.d1.loss_dice: 1.0921  decode.d2.loss_cls: 0.0489  decode.d2.loss_mask: 0.5259  decode.d2.loss_dice: 1.0802  decode.d3.loss_cls: 0.0559  decode.d3.loss_mask: 0.5221  decode.d3.loss_dice: 1.0927  decode.d4.loss_cls: 0.0590  decode.d4.loss_mask: 0.5281  decode.d4.loss_dice: 1.0443  decode.d5.loss_cls: 0.0548  decode.d5.loss_mask: 0.5347  decode.d5.loss_dice: 1.0825  decode.d6.loss_cls: 0.0516  decode.d6.loss_mask: 0.5344  decode.d6.loss_dice: 1.0880  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.5250  decode.d7.loss_dice: 1.0647  decode.d8.loss_cls: 0.0568  decode.d8.loss_mask: 0.5306  decode.d8.loss_dice: 1.0753
11/15 16:13:21 - mmengine - INFO - Iter(train) [53850/90000]  base_lr: 4.4003e-05 lr: 4.4003e-06  eta: 6:03:25  time: 0.5945  data_time: 0.0103  memory: 10692  grad_norm: 333.3784  loss: 16.9191  decode.loss_cls: 0.0605  decode.loss_mask: 0.5087  decode.loss_dice: 1.0706  decode.d0.loss_cls: 0.0863  decode.d0.loss_mask: 0.5484  decode.d0.loss_dice: 1.1436  decode.d1.loss_cls: 0.0745  decode.d1.loss_mask: 0.5365  decode.d1.loss_dice: 1.1349  decode.d2.loss_cls: 0.0651  decode.d2.loss_mask: 0.5240  decode.d2.loss_dice: 1.1470  decode.d3.loss_cls: 0.0597  decode.d3.loss_mask: 0.5139  decode.d3.loss_dice: 1.0886  decode.d4.loss_cls: 0.0757  decode.d4.loss_mask: 0.5097  decode.d4.loss_dice: 1.0906  decode.d5.loss_cls: 0.0795  decode.d5.loss_mask: 0.5310  decode.d5.loss_dice: 1.1099  decode.d6.loss_cls: 0.0672  decode.d6.loss_mask: 0.5411  decode.d6.loss_dice: 1.0702  decode.d7.loss_cls: 0.0760  decode.d7.loss_mask: 0.4969  decode.d7.loss_dice: 1.0648  decode.d8.loss_cls: 0.0562  decode.d8.loss_mask: 0.5160  decode.d8.loss_dice: 1.0722
11/15 16:13:50 - mmengine - INFO - Iter(train) [53900/90000]  base_lr: 4.3948e-05 lr: 4.3948e-06  eta: 6:02:54  time: 0.5951  data_time: 0.0102  memory: 10692  grad_norm: 473.3568  loss: 17.1238  decode.loss_cls: 0.0656  decode.loss_mask: 0.6050  decode.loss_dice: 1.0361  decode.d0.loss_cls: 0.0967  decode.d0.loss_mask: 0.6682  decode.d0.loss_dice: 1.0851  decode.d1.loss_cls: 0.0767  decode.d1.loss_mask: 0.6325  decode.d1.loss_dice: 1.0376  decode.d2.loss_cls: 0.0722  decode.d2.loss_mask: 0.6163  decode.d2.loss_dice: 1.0157  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.5983  decode.d3.loss_dice: 1.0057  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.6030  decode.d4.loss_dice: 1.0351  decode.d5.loss_cls: 0.0653  decode.d5.loss_mask: 0.6024  decode.d5.loss_dice: 1.0147  decode.d6.loss_cls: 0.0710  decode.d6.loss_mask: 0.6108  decode.d6.loss_dice: 1.0022  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.6024  decode.d7.loss_dice: 1.0084  decode.d8.loss_cls: 0.0707  decode.d8.loss_mask: 0.6061  decode.d8.loss_dice: 1.0127
11/15 16:14:20 - mmengine - INFO - Iter(train) [53950/90000]  base_lr: 4.3894e-05 lr: 4.3894e-06  eta: 6:02:24  time: 0.5972  data_time: 0.0104  memory: 10692  grad_norm: 360.4853  loss: 17.7605  decode.loss_cls: 0.0737  decode.loss_mask: 0.5449  decode.loss_dice: 1.1392  decode.d0.loss_cls: 0.0919  decode.d0.loss_mask: 0.5555  decode.d0.loss_dice: 1.2143  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.5448  decode.d1.loss_dice: 1.1377  decode.d2.loss_cls: 0.0659  decode.d2.loss_mask: 0.5499  decode.d2.loss_dice: 1.1465  decode.d3.loss_cls: 0.0602  decode.d3.loss_mask: 0.5446  decode.d3.loss_dice: 1.1656  decode.d4.loss_cls: 0.0716  decode.d4.loss_mask: 0.5419  decode.d4.loss_dice: 1.1527  decode.d5.loss_cls: 0.0610  decode.d5.loss_mask: 0.5534  decode.d5.loss_dice: 1.1486  decode.d6.loss_cls: 0.0649  decode.d6.loss_mask: 0.5504  decode.d6.loss_dice: 1.1490  decode.d7.loss_cls: 0.0666  decode.d7.loss_mask: 0.5477  decode.d7.loss_dice: 1.1644  decode.d8.loss_cls: 0.0678  decode.d8.loss_mask: 0.5500  decode.d8.loss_dice: 1.1568
11/15 16:14:50 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 16:14:50 - mmengine - INFO - Iter(train) [54000/90000]  base_lr: 4.3839e-05 lr: 4.3839e-06  eta: 6:01:54  time: 0.5948  data_time: 0.0104  memory: 10675  grad_norm: 293.6221  loss: 15.6782  decode.loss_cls: 0.0749  decode.loss_mask: 0.4998  decode.loss_dice: 0.9718  decode.d0.loss_cls: 0.1035  decode.d0.loss_mask: 0.5181  decode.d0.loss_dice: 1.0114  decode.d1.loss_cls: 0.0839  decode.d1.loss_mask: 0.5042  decode.d1.loss_dice: 0.9857  decode.d2.loss_cls: 0.0845  decode.d2.loss_mask: 0.5000  decode.d2.loss_dice: 0.9776  decode.d3.loss_cls: 0.0688  decode.d3.loss_mask: 0.5118  decode.d3.loss_dice: 0.9841  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.5005  decode.d4.loss_dice: 0.9931  decode.d5.loss_cls: 0.0782  decode.d5.loss_mask: 0.5073  decode.d5.loss_dice: 0.9829  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.5099  decode.d6.loss_dice: 0.9758  decode.d7.loss_cls: 0.0726  decode.d7.loss_mask: 0.5042  decode.d7.loss_dice: 0.9851  decode.d8.loss_cls: 0.0671  decode.d8.loss_mask: 0.5026  decode.d8.loss_dice: 0.9638
11/15 16:15:20 - mmengine - INFO - Iter(train) [54050/90000]  base_lr: 4.3784e-05 lr: 4.3784e-06  eta: 6:01:23  time: 0.5951  data_time: 0.0103  memory: 10656  grad_norm: 267.7777  loss: 16.0244  decode.loss_cls: 0.0762  decode.loss_mask: 0.4586  decode.loss_dice: 1.0693  decode.d0.loss_cls: 0.0822  decode.d0.loss_mask: 0.4728  decode.d0.loss_dice: 1.1534  decode.d1.loss_cls: 0.0634  decode.d1.loss_mask: 0.4711  decode.d1.loss_dice: 1.0565  decode.d2.loss_cls: 0.0773  decode.d2.loss_mask: 0.4571  decode.d2.loss_dice: 1.0625  decode.d3.loss_cls: 0.0651  decode.d3.loss_mask: 0.4540  decode.d3.loss_dice: 1.0594  decode.d4.loss_cls: 0.0630  decode.d4.loss_mask: 0.4543  decode.d4.loss_dice: 1.0498  decode.d5.loss_cls: 0.0636  decode.d5.loss_mask: 0.4507  decode.d5.loss_dice: 1.0494  decode.d6.loss_cls: 0.0628  decode.d6.loss_mask: 0.4596  decode.d6.loss_dice: 1.0707  decode.d7.loss_cls: 0.0645  decode.d7.loss_mask: 0.4611  decode.d7.loss_dice: 1.0905  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 0.4612  decode.d8.loss_dice: 1.0853
11/15 16:15:49 - mmengine - INFO - Iter(train) [54100/90000]  base_lr: 4.3729e-05 lr: 4.3729e-06  eta: 6:00:53  time: 0.5945  data_time: 0.0104  memory: 10656  grad_norm: 344.5921  loss: 16.8561  decode.loss_cls: 0.0772  decode.loss_mask: 0.4763  decode.loss_dice: 1.1185  decode.d0.loss_cls: 0.1096  decode.d0.loss_mask: 0.4834  decode.d0.loss_dice: 1.1442  decode.d1.loss_cls: 0.0819  decode.d1.loss_mask: 0.4803  decode.d1.loss_dice: 1.1447  decode.d2.loss_cls: 0.0796  decode.d2.loss_mask: 0.4763  decode.d2.loss_dice: 1.1126  decode.d3.loss_cls: 0.0744  decode.d3.loss_mask: 0.4822  decode.d3.loss_dice: 1.1215  decode.d4.loss_cls: 0.0753  decode.d4.loss_mask: 0.4805  decode.d4.loss_dice: 1.1300  decode.d5.loss_cls: 0.0764  decode.d5.loss_mask: 0.4745  decode.d5.loss_dice: 1.1336  decode.d6.loss_cls: 0.0897  decode.d6.loss_mask: 0.4838  decode.d6.loss_dice: 1.1228  decode.d7.loss_cls: 0.0784  decode.d7.loss_mask: 0.4795  decode.d7.loss_dice: 1.1047  decode.d8.loss_cls: 0.0715  decode.d8.loss_mask: 0.4806  decode.d8.loss_dice: 1.1120
11/15 16:16:19 - mmengine - INFO - Iter(train) [54150/90000]  base_lr: 4.3674e-05 lr: 4.3674e-06  eta: 6:00:22  time: 0.5945  data_time: 0.0103  memory: 10713  grad_norm: 316.8220  loss: 16.3354  decode.loss_cls: 0.0661  decode.loss_mask: 0.5158  decode.loss_dice: 1.0187  decode.d0.loss_cls: 0.1059  decode.d0.loss_mask: 0.5276  decode.d0.loss_dice: 1.1193  decode.d1.loss_cls: 0.0631  decode.d1.loss_mask: 0.5149  decode.d1.loss_dice: 1.0358  decode.d2.loss_cls: 0.0738  decode.d2.loss_mask: 0.5153  decode.d2.loss_dice: 1.0242  decode.d3.loss_cls: 0.0781  decode.d3.loss_mask: 0.5202  decode.d3.loss_dice: 1.0331  decode.d4.loss_cls: 0.0745  decode.d4.loss_mask: 0.5048  decode.d4.loss_dice: 1.0103  decode.d5.loss_cls: 0.0759  decode.d5.loss_mask: 0.5194  decode.d5.loss_dice: 1.0421  decode.d6.loss_cls: 0.0658  decode.d6.loss_mask: 0.5231  decode.d6.loss_dice: 1.0606  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.5173  decode.d7.loss_dice: 1.0384  decode.d8.loss_cls: 0.0644  decode.d8.loss_mask: 0.5217  decode.d8.loss_dice: 1.0409
11/15 16:16:49 - mmengine - INFO - Iter(train) [54200/90000]  base_lr: 4.3620e-05 lr: 4.3620e-06  eta: 5:59:52  time: 0.5953  data_time: 0.0105  memory: 10675  grad_norm: 386.6370  loss: 17.1525  decode.loss_cls: 0.0968  decode.loss_mask: 0.5131  decode.loss_dice: 1.0728  decode.d0.loss_cls: 0.1247  decode.d0.loss_mask: 0.5187  decode.d0.loss_dice: 1.1800  decode.d1.loss_cls: 0.1159  decode.d1.loss_mask: 0.5250  decode.d1.loss_dice: 1.1588  decode.d2.loss_cls: 0.1050  decode.d2.loss_mask: 0.4877  decode.d2.loss_dice: 1.1015  decode.d3.loss_cls: 0.1004  decode.d3.loss_mask: 0.5003  decode.d3.loss_dice: 1.0785  decode.d4.loss_cls: 0.1016  decode.d4.loss_mask: 0.4910  decode.d4.loss_dice: 1.1091  decode.d5.loss_cls: 0.1021  decode.d5.loss_mask: 0.4844  decode.d5.loss_dice: 1.0570  decode.d6.loss_cls: 0.0962  decode.d6.loss_mask: 0.5269  decode.d6.loss_dice: 1.1173  decode.d7.loss_cls: 0.0965  decode.d7.loss_mask: 0.5084  decode.d7.loss_dice: 1.1014  decode.d8.loss_cls: 0.0893  decode.d8.loss_mask: 0.5047  decode.d8.loss_dice: 1.0871
11/15 16:17:19 - mmengine - INFO - Iter(train) [54250/90000]  base_lr: 4.3565e-05 lr: 4.3565e-06  eta: 5:59:22  time: 0.5950  data_time: 0.0105  memory: 10641  grad_norm: 706.3238  loss: 15.7156  decode.loss_cls: 0.0627  decode.loss_mask: 0.4555  decode.loss_dice: 1.0177  decode.d0.loss_cls: 0.0849  decode.d0.loss_mask: 0.4816  decode.d0.loss_dice: 1.1181  decode.d1.loss_cls: 0.0651  decode.d1.loss_mask: 0.4864  decode.d1.loss_dice: 1.0732  decode.d2.loss_cls: 0.0606  decode.d2.loss_mask: 0.4737  decode.d2.loss_dice: 1.0577  decode.d3.loss_cls: 0.0653  decode.d3.loss_mask: 0.4535  decode.d3.loss_dice: 1.0199  decode.d4.loss_cls: 0.0604  decode.d4.loss_mask: 0.4604  decode.d4.loss_dice: 1.0383  decode.d5.loss_cls: 0.0701  decode.d5.loss_mask: 0.4545  decode.d5.loss_dice: 1.0251  decode.d6.loss_cls: 0.0687  decode.d6.loss_mask: 0.4547  decode.d6.loss_dice: 1.0231  decode.d7.loss_cls: 0.0638  decode.d7.loss_mask: 0.4527  decode.d7.loss_dice: 1.0309  decode.d8.loss_cls: 0.0638  decode.d8.loss_mask: 0.4515  decode.d8.loss_dice: 1.0218
11/15 16:17:49 - mmengine - INFO - Iter(train) [54300/90000]  base_lr: 4.3510e-05 lr: 4.3510e-06  eta: 5:58:51  time: 0.5938  data_time: 0.0102  memory: 10692  grad_norm: 638.5390  loss: 16.9007  decode.loss_cls: 0.0423  decode.loss_mask: 0.5650  decode.loss_dice: 1.0732  decode.d0.loss_cls: 0.0770  decode.d0.loss_mask: 0.5879  decode.d0.loss_dice: 1.1014  decode.d1.loss_cls: 0.0528  decode.d1.loss_mask: 0.5676  decode.d1.loss_dice: 1.0843  decode.d2.loss_cls: 0.0477  decode.d2.loss_mask: 0.5581  decode.d2.loss_dice: 1.0914  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.5565  decode.d3.loss_dice: 1.0600  decode.d4.loss_cls: 0.0428  decode.d4.loss_mask: 0.5565  decode.d4.loss_dice: 1.0726  decode.d5.loss_cls: 0.0401  decode.d5.loss_mask: 0.5482  decode.d5.loss_dice: 1.0720  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.5569  decode.d6.loss_dice: 1.0558  decode.d7.loss_cls: 0.0522  decode.d7.loss_mask: 0.5616  decode.d7.loss_dice: 1.0943  decode.d8.loss_cls: 0.0443  decode.d8.loss_mask: 0.5620  decode.d8.loss_dice: 1.0719
11/15 16:18:18 - mmengine - INFO - Iter(train) [54350/90000]  base_lr: 4.3455e-05 lr: 4.3455e-06  eta: 5:58:21  time: 0.5936  data_time: 0.0102  memory: 10675  grad_norm: 310.5570  loss: 16.0776  decode.loss_cls: 0.0578  decode.loss_mask: 0.5108  decode.loss_dice: 1.0236  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.5456  decode.d0.loss_dice: 1.0763  decode.d1.loss_cls: 0.0591  decode.d1.loss_mask: 0.5218  decode.d1.loss_dice: 1.0790  decode.d2.loss_cls: 0.0575  decode.d2.loss_mask: 0.5105  decode.d2.loss_dice: 1.0421  decode.d3.loss_cls: 0.0606  decode.d3.loss_mask: 0.5100  decode.d3.loss_dice: 1.0251  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.5119  decode.d4.loss_dice: 1.0111  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 0.5130  decode.d5.loss_dice: 1.0330  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.5064  decode.d6.loss_dice: 1.0210  decode.d7.loss_cls: 0.0506  decode.d7.loss_mask: 0.5003  decode.d7.loss_dice: 1.0090  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.5122  decode.d8.loss_dice: 1.0054
11/15 16:18:48 - mmengine - INFO - Iter(train) [54400/90000]  base_lr: 4.3400e-05 lr: 4.3400e-06  eta: 5:57:50  time: 0.5954  data_time: 0.0103  memory: 10713  grad_norm: 198.2800  loss: 16.1551  decode.loss_cls: 0.0603  decode.loss_mask: 0.4643  decode.loss_dice: 1.0989  decode.d0.loss_cls: 0.0790  decode.d0.loss_mask: 0.4769  decode.d0.loss_dice: 1.1431  decode.d1.loss_cls: 0.0640  decode.d1.loss_mask: 0.4813  decode.d1.loss_dice: 1.0936  decode.d2.loss_cls: 0.0572  decode.d2.loss_mask: 0.4586  decode.d2.loss_dice: 1.0658  decode.d3.loss_cls: 0.0569  decode.d3.loss_mask: 0.4658  decode.d3.loss_dice: 1.0871  decode.d4.loss_cls: 0.0529  decode.d4.loss_mask: 0.4678  decode.d4.loss_dice: 1.0847  decode.d5.loss_cls: 0.0723  decode.d5.loss_mask: 0.4620  decode.d5.loss_dice: 1.0695  decode.d6.loss_cls: 0.0547  decode.d6.loss_mask: 0.4626  decode.d6.loss_dice: 1.0702  decode.d7.loss_cls: 0.0663  decode.d7.loss_mask: 0.4481  decode.d7.loss_dice: 1.0761  decode.d8.loss_cls: 0.0609  decode.d8.loss_mask: 0.4773  decode.d8.loss_dice: 1.0770
11/15 16:19:18 - mmengine - INFO - Iter(train) [54450/90000]  base_lr: 4.3345e-05 lr: 4.3345e-06  eta: 5:57:20  time: 0.5935  data_time: 0.0103  memory: 10713  grad_norm: 424.7202  loss: 15.8234  decode.loss_cls: 0.0528  decode.loss_mask: 0.4712  decode.loss_dice: 1.0363  decode.d0.loss_cls: 0.0704  decode.d0.loss_mask: 0.4710  decode.d0.loss_dice: 1.1611  decode.d1.loss_cls: 0.0616  decode.d1.loss_mask: 0.4657  decode.d1.loss_dice: 1.0475  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.4732  decode.d2.loss_dice: 1.0380  decode.d3.loss_cls: 0.0514  decode.d3.loss_mask: 0.4719  decode.d3.loss_dice: 1.0507  decode.d4.loss_cls: 0.0614  decode.d4.loss_mask: 0.4607  decode.d4.loss_dice: 1.0246  decode.d5.loss_cls: 0.0451  decode.d5.loss_mask: 0.4692  decode.d5.loss_dice: 1.0685  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.4731  decode.d6.loss_dice: 1.0251  decode.d7.loss_cls: 0.0597  decode.d7.loss_mask: 0.4742  decode.d7.loss_dice: 1.0383  decode.d8.loss_cls: 0.0495  decode.d8.loss_mask: 0.4756  decode.d8.loss_dice: 1.0651
11/15 16:19:48 - mmengine - INFO - Iter(train) [54500/90000]  base_lr: 4.3290e-05 lr: 4.3290e-06  eta: 5:56:50  time: 0.5941  data_time: 0.0104  memory: 10742  grad_norm: 363.7787  loss: 15.5185  decode.loss_cls: 0.0794  decode.loss_mask: 0.5145  decode.loss_dice: 0.9730  decode.d0.loss_cls: 0.0925  decode.d0.loss_mask: 0.5396  decode.d0.loss_dice: 1.0120  decode.d1.loss_cls: 0.0785  decode.d1.loss_mask: 0.5159  decode.d1.loss_dice: 0.9577  decode.d2.loss_cls: 0.0824  decode.d2.loss_mask: 0.5116  decode.d2.loss_dice: 0.9793  decode.d3.loss_cls: 0.0856  decode.d3.loss_mask: 0.5085  decode.d3.loss_dice: 0.9470  decode.d4.loss_cls: 0.0846  decode.d4.loss_mask: 0.5174  decode.d4.loss_dice: 0.9254  decode.d5.loss_cls: 0.0695  decode.d5.loss_mask: 0.5109  decode.d5.loss_dice: 0.9804  decode.d6.loss_cls: 0.0895  decode.d6.loss_mask: 0.5056  decode.d6.loss_dice: 0.9353  decode.d7.loss_cls: 0.0825  decode.d7.loss_mask: 0.5012  decode.d7.loss_dice: 0.9256  decode.d8.loss_cls: 0.0842  decode.d8.loss_mask: 0.5035  decode.d8.loss_dice: 0.9252
11/15 16:20:18 - mmengine - INFO - Iter(train) [54550/90000]  base_lr: 4.3236e-05 lr: 4.3236e-06  eta: 5:56:20  time: 0.5938  data_time: 0.0103  memory: 10713  grad_norm: 307.5934  loss: 15.6109  decode.loss_cls: 0.0469  decode.loss_mask: 0.4821  decode.loss_dice: 1.0100  decode.d0.loss_cls: 0.0749  decode.d0.loss_mask: 0.5185  decode.d0.loss_dice: 1.0424  decode.d1.loss_cls: 0.0437  decode.d1.loss_mask: 0.4971  decode.d1.loss_dice: 1.0553  decode.d2.loss_cls: 0.0429  decode.d2.loss_mask: 0.4920  decode.d2.loss_dice: 1.0467  decode.d3.loss_cls: 0.0410  decode.d3.loss_mask: 0.4873  decode.d3.loss_dice: 1.0391  decode.d4.loss_cls: 0.0365  decode.d4.loss_mask: 0.4891  decode.d4.loss_dice: 1.0203  decode.d5.loss_cls: 0.0422  decode.d5.loss_mask: 0.4860  decode.d5.loss_dice: 0.9945  decode.d6.loss_cls: 0.0404  decode.d6.loss_mask: 0.4856  decode.d6.loss_dice: 0.9922  decode.d7.loss_cls: 0.0342  decode.d7.loss_mask: 0.4883  decode.d7.loss_dice: 1.0339  decode.d8.loss_cls: 0.0305  decode.d8.loss_mask: 0.4878  decode.d8.loss_dice: 1.0294
11/15 16:20:48 - mmengine - INFO - Iter(train) [54600/90000]  base_lr: 4.3181e-05 lr: 4.3181e-06  eta: 5:55:49  time: 0.5940  data_time: 0.0101  memory: 10675  grad_norm: 778.0444  loss: 18.3641  decode.loss_cls: 0.0805  decode.loss_mask: 0.5602  decode.loss_dice: 1.1723  decode.d0.loss_cls: 0.1061  decode.d0.loss_mask: 0.5735  decode.d0.loss_dice: 1.3064  decode.d1.loss_cls: 0.0996  decode.d1.loss_mask: 0.5728  decode.d1.loss_dice: 1.2398  decode.d2.loss_cls: 0.0878  decode.d2.loss_mask: 0.5803  decode.d2.loss_dice: 1.2217  decode.d3.loss_cls: 0.0886  decode.d3.loss_mask: 0.5605  decode.d3.loss_dice: 1.1786  decode.d4.loss_cls: 0.0877  decode.d4.loss_mask: 0.5589  decode.d4.loss_dice: 1.1436  decode.d5.loss_cls: 0.0812  decode.d5.loss_mask: 0.5520  decode.d5.loss_dice: 1.1690  decode.d6.loss_cls: 0.0859  decode.d6.loss_mask: 0.5474  decode.d6.loss_dice: 1.1599  decode.d7.loss_cls: 0.0897  decode.d7.loss_mask: 0.5366  decode.d7.loss_dice: 1.1461  decode.d8.loss_cls: 0.0863  decode.d8.loss_mask: 0.5475  decode.d8.loss_dice: 1.1434
11/15 16:21:18 - mmengine - INFO - Iter(train) [54650/90000]  base_lr: 4.3126e-05 lr: 4.3126e-06  eta: 5:55:19  time: 0.5945  data_time: 0.0103  memory: 10692  grad_norm: 222.1285  loss: 15.2158  decode.loss_cls: 0.0516  decode.loss_mask: 0.3997  decode.loss_dice: 1.0134  decode.d0.loss_cls: 0.0762  decode.d0.loss_mask: 0.4539  decode.d0.loss_dice: 1.0909  decode.d1.loss_cls: 0.0570  decode.d1.loss_mask: 0.4475  decode.d1.loss_dice: 1.0482  decode.d2.loss_cls: 0.0638  decode.d2.loss_mask: 0.4350  decode.d2.loss_dice: 1.0181  decode.d3.loss_cls: 0.0632  decode.d3.loss_mask: 0.4288  decode.d3.loss_dice: 1.0272  decode.d4.loss_cls: 0.0723  decode.d4.loss_mask: 0.4329  decode.d4.loss_dice: 1.0104  decode.d5.loss_cls: 0.0642  decode.d5.loss_mask: 0.4309  decode.d5.loss_dice: 0.9914  decode.d6.loss_cls: 0.0588  decode.d6.loss_mask: 0.4307  decode.d6.loss_dice: 1.0193  decode.d7.loss_cls: 0.0603  decode.d7.loss_mask: 0.4406  decode.d7.loss_dice: 1.0550  decode.d8.loss_cls: 0.0513  decode.d8.loss_mask: 0.3977  decode.d8.loss_dice: 1.0255
11/15 16:21:47 - mmengine - INFO - Iter(train) [54700/90000]  base_lr: 4.3071e-05 lr: 4.3071e-06  eta: 5:54:48  time: 0.5937  data_time: 0.0106  memory: 10692  grad_norm: 688.2256  loss: 15.5852  decode.loss_cls: 0.0749  decode.loss_mask: 0.4151  decode.loss_dice: 1.0417  decode.d0.loss_cls: 0.0734  decode.d0.loss_mask: 0.4315  decode.d0.loss_dice: 1.1177  decode.d1.loss_cls: 0.0717  decode.d1.loss_mask: 0.4142  decode.d1.loss_dice: 1.1220  decode.d2.loss_cls: 0.0743  decode.d2.loss_mask: 0.4034  decode.d2.loss_dice: 1.0510  decode.d3.loss_cls: 0.0755  decode.d3.loss_mask: 0.4095  decode.d3.loss_dice: 1.0482  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.4141  decode.d4.loss_dice: 1.1036  decode.d5.loss_cls: 0.0688  decode.d5.loss_mask: 0.4078  decode.d5.loss_dice: 1.0438  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.4162  decode.d6.loss_dice: 1.0537  decode.d7.loss_cls: 0.0703  decode.d7.loss_mask: 0.4131  decode.d7.loss_dice: 1.0606  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 0.4252  decode.d8.loss_dice: 1.0958
11/15 16:22:17 - mmengine - INFO - Iter(train) [54750/90000]  base_lr: 4.3016e-05 lr: 4.3016e-06  eta: 5:54:18  time: 0.5937  data_time: 0.0102  memory: 10692  grad_norm: 349.2580  loss: 15.3215  decode.loss_cls: 0.0532  decode.loss_mask: 0.4724  decode.loss_dice: 0.9860  decode.d0.loss_cls: 0.0775  decode.d0.loss_mask: 0.5164  decode.d0.loss_dice: 1.1399  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.4860  decode.d1.loss_dice: 0.9729  decode.d2.loss_cls: 0.0715  decode.d2.loss_mask: 0.4830  decode.d2.loss_dice: 0.9604  decode.d3.loss_cls: 0.0568  decode.d3.loss_mask: 0.4767  decode.d3.loss_dice: 0.9902  decode.d4.loss_cls: 0.0618  decode.d4.loss_mask: 0.4710  decode.d4.loss_dice: 0.9908  decode.d5.loss_cls: 0.0518  decode.d5.loss_mask: 0.4681  decode.d5.loss_dice: 0.9732  decode.d6.loss_cls: 0.0540  decode.d6.loss_mask: 0.4740  decode.d6.loss_dice: 0.9875  decode.d7.loss_cls: 0.0511  decode.d7.loss_mask: 0.4737  decode.d7.loss_dice: 0.9607  decode.d8.loss_cls: 0.0576  decode.d8.loss_mask: 0.4764  decode.d8.loss_dice: 0.9589
11/15 16:22:47 - mmengine - INFO - Iter(train) [54800/90000]  base_lr: 4.2961e-05 lr: 4.2961e-06  eta: 5:53:47  time: 0.5948  data_time: 0.0103  memory: 10675  grad_norm: 378.6645  loss: 16.4254  decode.loss_cls: 0.0738  decode.loss_mask: 0.4427  decode.loss_dice: 1.1018  decode.d0.loss_cls: 0.1001  decode.d0.loss_mask: 0.4560  decode.d0.loss_dice: 1.1984  decode.d1.loss_cls: 0.0673  decode.d1.loss_mask: 0.4401  decode.d1.loss_dice: 1.1383  decode.d2.loss_cls: 0.0720  decode.d2.loss_mask: 0.4470  decode.d2.loss_dice: 1.0946  decode.d3.loss_cls: 0.0744  decode.d3.loss_mask: 0.4513  decode.d3.loss_dice: 1.0881  decode.d4.loss_cls: 0.0765  decode.d4.loss_mask: 0.4520  decode.d4.loss_dice: 1.1052  decode.d5.loss_cls: 0.0748  decode.d5.loss_mask: 0.4488  decode.d5.loss_dice: 1.1051  decode.d6.loss_cls: 0.0701  decode.d6.loss_mask: 0.4446  decode.d6.loss_dice: 1.1222  decode.d7.loss_cls: 0.0827  decode.d7.loss_mask: 0.4418  decode.d7.loss_dice: 1.1188  decode.d8.loss_cls: 0.0766  decode.d8.loss_mask: 0.4445  decode.d8.loss_dice: 1.1159
11/15 16:23:17 - mmengine - INFO - Iter(train) [54850/90000]  base_lr: 4.2906e-05 lr: 4.2906e-06  eta: 5:53:17  time: 0.5941  data_time: 0.0103  memory: 10692  grad_norm: 219.3206  loss: 15.3238  decode.loss_cls: 0.0662  decode.loss_mask: 0.4575  decode.loss_dice: 1.0183  decode.d0.loss_cls: 0.0783  decode.d0.loss_mask: 0.4436  decode.d0.loss_dice: 1.0825  decode.d1.loss_cls: 0.0754  decode.d1.loss_mask: 0.4418  decode.d1.loss_dice: 1.0210  decode.d2.loss_cls: 0.0757  decode.d2.loss_mask: 0.4479  decode.d2.loss_dice: 1.0303  decode.d3.loss_cls: 0.0668  decode.d3.loss_mask: 0.4422  decode.d3.loss_dice: 0.9990  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 0.4381  decode.d4.loss_dice: 0.9887  decode.d5.loss_cls: 0.0660  decode.d5.loss_mask: 0.4431  decode.d5.loss_dice: 1.0106  decode.d6.loss_cls: 0.0736  decode.d6.loss_mask: 0.4392  decode.d6.loss_dice: 0.9968  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.4617  decode.d7.loss_dice: 1.0172  decode.d8.loss_cls: 0.0708  decode.d8.loss_mask: 0.4561  decode.d8.loss_dice: 0.9922
11/15 16:23:46 - mmengine - INFO - Iter(train) [54900/90000]  base_lr: 4.2851e-05 lr: 4.2851e-06  eta: 5:52:47  time: 0.5959  data_time: 0.0102  memory: 10713  grad_norm: 297.9465  loss: 17.3761  decode.loss_cls: 0.0489  decode.loss_mask: 0.5001  decode.loss_dice: 1.1819  decode.d0.loss_cls: 0.0898  decode.d0.loss_mask: 0.4575  decode.d0.loss_dice: 1.2510  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.4942  decode.d1.loss_dice: 1.2042  decode.d2.loss_cls: 0.0666  decode.d2.loss_mask: 0.4873  decode.d2.loss_dice: 1.1987  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.4707  decode.d3.loss_dice: 1.1536  decode.d4.loss_cls: 0.0834  decode.d4.loss_mask: 0.4630  decode.d4.loss_dice: 1.1702  decode.d5.loss_cls: 0.0556  decode.d5.loss_mask: 0.4988  decode.d5.loss_dice: 1.1709  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.4854  decode.d6.loss_dice: 1.1649  decode.d7.loss_cls: 0.0790  decode.d7.loss_mask: 0.4847  decode.d7.loss_dice: 1.1895  decode.d8.loss_cls: 0.0584  decode.d8.loss_mask: 0.4830  decode.d8.loss_dice: 1.2029
11/15 16:24:16 - mmengine - INFO - Iter(train) [54950/90000]  base_lr: 4.2796e-05 lr: 4.2796e-06  eta: 5:52:16  time: 0.5934  data_time: 0.0103  memory: 10713  grad_norm: 531.7819  loss: 15.8923  decode.loss_cls: 0.0628  decode.loss_mask: 0.4540  decode.loss_dice: 1.0443  decode.d0.loss_cls: 0.0769  decode.d0.loss_mask: 0.4593  decode.d0.loss_dice: 1.0915  decode.d1.loss_cls: 0.0488  decode.d1.loss_mask: 0.5559  decode.d1.loss_dice: 1.0954  decode.d2.loss_cls: 0.0504  decode.d2.loss_mask: 0.5533  decode.d2.loss_dice: 1.0731  decode.d3.loss_cls: 0.0475  decode.d3.loss_mask: 0.4590  decode.d3.loss_dice: 1.0501  decode.d4.loss_cls: 0.0588  decode.d4.loss_mask: 0.4681  decode.d4.loss_dice: 1.0426  decode.d5.loss_cls: 0.0468  decode.d5.loss_mask: 0.4560  decode.d5.loss_dice: 1.0519  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.4510  decode.d6.loss_dice: 1.0493  decode.d7.loss_cls: 0.0536  decode.d7.loss_mask: 0.4406  decode.d7.loss_dice: 1.0273  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 0.4568  decode.d8.loss_dice: 1.0525
11/15 16:24:46 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 16:24:46 - mmengine - INFO - Iter(train) [55000/90000]  base_lr: 4.2741e-05 lr: 4.2741e-06  eta: 5:51:46  time: 0.5972  data_time: 0.0107  memory: 10692  grad_norm: 447.6968  loss: 16.9985  decode.loss_cls: 0.0714  decode.loss_mask: 0.4524  decode.loss_dice: 1.1057  decode.d0.loss_cls: 0.1009  decode.d0.loss_mask: 0.4842  decode.d0.loss_dice: 1.2404  decode.d1.loss_cls: 0.0743  decode.d1.loss_mask: 0.4671  decode.d1.loss_dice: 1.2086  decode.d2.loss_cls: 0.0810  decode.d2.loss_mask: 0.4616  decode.d2.loss_dice: 1.1925  decode.d3.loss_cls: 0.0856  decode.d3.loss_mask: 0.4553  decode.d3.loss_dice: 1.1347  decode.d4.loss_cls: 0.0765  decode.d4.loss_mask: 0.4612  decode.d4.loss_dice: 1.1507  decode.d5.loss_cls: 0.0792  decode.d5.loss_mask: 0.4549  decode.d5.loss_dice: 1.1439  decode.d6.loss_cls: 0.0815  decode.d6.loss_mask: 0.4533  decode.d6.loss_dice: 1.1191  decode.d7.loss_cls: 0.0776  decode.d7.loss_mask: 0.4557  decode.d7.loss_dice: 1.1394  decode.d8.loss_cls: 0.0694  decode.d8.loss_mask: 0.4568  decode.d8.loss_dice: 1.1636
11/15 16:24:46 - mmengine - INFO - Saving checkpoint at 55000 iterations
11/15 16:25:06 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:26  time: 0.3083  data_time: 0.0043  memory: 4095  
11/15 16:25:21 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:07  time: 0.3082  data_time: 0.0041  memory: 4095  
11/15 16:25:37 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:50  time: 0.3080  data_time: 0.0040  memory: 4095  
11/15 16:25:52 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3085  data_time: 0.0042  memory: 4095  
11/15 16:26:08 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:18  time: 0.3082  data_time: 0.0039  memory: 4095  
11/15 16:26:23 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:02  time: 0.3085  data_time: 0.0042  memory: 4095  
11/15 16:26:38 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3085  data_time: 0.0040  memory: 4095  
11/15 16:26:54 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:31  time: 0.3088  data_time: 0.0039  memory: 4095  
11/15 16:27:09 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3092  data_time: 0.0043  memory: 4095  
11/15 16:27:25 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3084  data_time: 0.0038  memory: 4095  
11/15 16:27:25 - mmengine - INFO - per class results:
11/15 16:27:25 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     |  98.1 | 98.57 |
|    sidewalk   |  85.1 | 93.92 |
|    building   | 92.65 | 97.36 |
|      wall     | 62.37 | 77.48 |
|     fence     |  57.6 | 70.57 |
|      pole     |  66.8 | 78.09 |
| traffic light | 69.91 | 77.32 |
|  traffic sign | 81.41 | 87.28 |
|   vegetation  | 92.38 | 95.64 |
|    terrain    | 63.58 | 73.99 |
|      sky      | 94.97 | 97.86 |
|     person    |  82.2 | 89.13 |
|     rider     | 65.34 |  78.1 |
|      car      |  94.8 | 96.83 |
|     truck     |  68.9 | 92.74 |
|      bus      | 72.57 | 91.43 |
|     train     | 20.46 | 24.38 |
|   motorcycle  |  67.1 | 82.05 |
|    bicycle    | 77.99 | 86.13 |
+---------------+-------+-------+
11/15 16:27:25 - mmengine - INFO - Iter(val) [500/500]    aAcc: 96.0000  mIoU: 74.4300  mAcc: 83.6200  data_time: 0.0050  time: 0.3104
11/15 16:27:55 - mmengine - INFO - Iter(train) [55050/90000]  base_lr: 4.2686e-05 lr: 4.2686e-06  eta: 5:51:15  time: 0.5948  data_time: 0.0104  memory: 10675  grad_norm: 301.7859  loss: 15.3490  decode.loss_cls: 0.0950  decode.loss_mask: 0.4386  decode.loss_dice: 1.0001  decode.d0.loss_cls: 0.1007  decode.d0.loss_mask: 0.4616  decode.d0.loss_dice: 1.0949  decode.d1.loss_cls: 0.0905  decode.d1.loss_mask: 0.4424  decode.d1.loss_dice: 1.0220  decode.d2.loss_cls: 0.0900  decode.d2.loss_mask: 0.4324  decode.d2.loss_dice: 0.9879  decode.d3.loss_cls: 0.0874  decode.d3.loss_mask: 0.4370  decode.d3.loss_dice: 0.9819  decode.d4.loss_cls: 0.0875  decode.d4.loss_mask: 0.4393  decode.d4.loss_dice: 0.9978  decode.d5.loss_cls: 0.0830  decode.d5.loss_mask: 0.4367  decode.d5.loss_dice: 1.0026  decode.d6.loss_cls: 0.0799  decode.d6.loss_mask: 0.4335  decode.d6.loss_dice: 0.9931  decode.d7.loss_cls: 0.0918  decode.d7.loss_mask: 0.4336  decode.d7.loss_dice: 0.9994  decode.d8.loss_cls: 0.0894  decode.d8.loss_mask: 0.4343  decode.d8.loss_dice: 0.9852
11/15 16:28:24 - mmengine - INFO - Iter(train) [55100/90000]  base_lr: 4.2631e-05 lr: 4.2631e-06  eta: 5:50:45  time: 0.5952  data_time: 0.0104  memory: 10641  grad_norm: 255.9621  loss: 16.6290  decode.loss_cls: 0.0409  decode.loss_mask: 0.5223  decode.loss_dice: 1.0939  decode.d0.loss_cls: 0.0766  decode.d0.loss_mask: 0.5311  decode.d0.loss_dice: 1.1409  decode.d1.loss_cls: 0.0580  decode.d1.loss_mask: 0.5148  decode.d1.loss_dice: 1.0845  decode.d2.loss_cls: 0.0595  decode.d2.loss_mask: 0.5154  decode.d2.loss_dice: 1.0738  decode.d3.loss_cls: 0.0463  decode.d3.loss_mask: 0.5224  decode.d3.loss_dice: 1.0822  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.5280  decode.d4.loss_dice: 1.0883  decode.d5.loss_cls: 0.0412  decode.d5.loss_mask: 0.5185  decode.d5.loss_dice: 1.1068  decode.d6.loss_cls: 0.0567  decode.d6.loss_mask: 0.5243  decode.d6.loss_dice: 1.0747  decode.d7.loss_cls: 0.0383  decode.d7.loss_mask: 0.5223  decode.d7.loss_dice: 1.1007  decode.d8.loss_cls: 0.0477  decode.d8.loss_mask: 0.5137  decode.d8.loss_dice: 1.0554
11/15 16:28:54 - mmengine - INFO - Iter(train) [55150/90000]  base_lr: 4.2576e-05 lr: 4.2576e-06  eta: 5:50:15  time: 0.5938  data_time: 0.0102  memory: 10713  grad_norm: 291.9947  loss: 15.4508  decode.loss_cls: 0.0538  decode.loss_mask: 0.5250  decode.loss_dice: 0.9516  decode.d0.loss_cls: 0.0810  decode.d0.loss_mask: 0.5695  decode.d0.loss_dice: 1.0415  decode.d1.loss_cls: 0.0571  decode.d1.loss_mask: 0.5285  decode.d1.loss_dice: 0.9700  decode.d2.loss_cls: 0.0513  decode.d2.loss_mask: 0.5237  decode.d2.loss_dice: 0.9349  decode.d3.loss_cls: 0.0532  decode.d3.loss_mask: 0.5293  decode.d3.loss_dice: 0.9388  decode.d4.loss_cls: 0.0504  decode.d4.loss_mask: 0.5300  decode.d4.loss_dice: 0.9809  decode.d5.loss_cls: 0.0578  decode.d5.loss_mask: 0.5420  decode.d5.loss_dice: 0.9463  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.5279  decode.d6.loss_dice: 0.9397  decode.d7.loss_cls: 0.0551  decode.d7.loss_mask: 0.5250  decode.d7.loss_dice: 0.9493  decode.d8.loss_cls: 0.0581  decode.d8.loss_mask: 0.5250  decode.d8.loss_dice: 0.8990
11/15 16:29:24 - mmengine - INFO - Iter(train) [55200/90000]  base_lr: 4.2521e-05 lr: 4.2521e-06  eta: 5:49:44  time: 0.5943  data_time: 0.0103  memory: 10641  grad_norm: 589.1623  loss: 14.9175  decode.loss_cls: 0.0513  decode.loss_mask: 0.5058  decode.loss_dice: 0.9094  decode.d0.loss_cls: 0.0925  decode.d0.loss_mask: 0.5226  decode.d0.loss_dice: 1.0006  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.5106  decode.d1.loss_dice: 0.9446  decode.d2.loss_cls: 0.0519  decode.d2.loss_mask: 0.5169  decode.d2.loss_dice: 0.9355  decode.d3.loss_cls: 0.0429  decode.d3.loss_mask: 0.5205  decode.d3.loss_dice: 0.9106  decode.d4.loss_cls: 0.0569  decode.d4.loss_mask: 0.5038  decode.d4.loss_dice: 0.8853  decode.d5.loss_cls: 0.0471  decode.d5.loss_mask: 0.5136  decode.d5.loss_dice: 0.9168  decode.d6.loss_cls: 0.0437  decode.d6.loss_mask: 0.5172  decode.d6.loss_dice: 0.9063  decode.d7.loss_cls: 0.0563  decode.d7.loss_mask: 0.5208  decode.d7.loss_dice: 0.9151  decode.d8.loss_cls: 0.0564  decode.d8.loss_mask: 0.5148  decode.d8.loss_dice: 0.8957
11/15 16:29:54 - mmengine - INFO - Iter(train) [55250/90000]  base_lr: 4.2466e-05 lr: 4.2466e-06  eta: 5:49:14  time: 0.5964  data_time: 0.0113  memory: 10641  grad_norm: 252.7708  loss: 15.8136  decode.loss_cls: 0.0428  decode.loss_mask: 0.4596  decode.loss_dice: 1.0689  decode.d0.loss_cls: 0.0755  decode.d0.loss_mask: 0.4682  decode.d0.loss_dice: 1.1146  decode.d1.loss_cls: 0.0487  decode.d1.loss_mask: 0.4576  decode.d1.loss_dice: 1.0781  decode.d2.loss_cls: 0.0466  decode.d2.loss_mask: 0.4669  decode.d2.loss_dice: 1.0637  decode.d3.loss_cls: 0.0456  decode.d3.loss_mask: 0.4583  decode.d3.loss_dice: 1.0655  decode.d4.loss_cls: 0.0675  decode.d4.loss_mask: 0.4562  decode.d4.loss_dice: 1.0441  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.4594  decode.d5.loss_dice: 1.0530  decode.d6.loss_cls: 0.0473  decode.d6.loss_mask: 0.4537  decode.d6.loss_dice: 1.0746  decode.d7.loss_cls: 0.0465  decode.d7.loss_mask: 0.4516  decode.d7.loss_dice: 1.0711  decode.d8.loss_cls: 0.0422  decode.d8.loss_mask: 0.4603  decode.d8.loss_dice: 1.0755
11/15 16:30:23 - mmengine - INFO - Iter(train) [55300/90000]  base_lr: 4.2411e-05 lr: 4.2411e-06  eta: 5:48:43  time: 0.5962  data_time: 0.0104  memory: 10692  grad_norm: 285.0524  loss: 16.7155  decode.loss_cls: 0.0905  decode.loss_mask: 0.4583  decode.loss_dice: 1.0806  decode.d0.loss_cls: 0.0976  decode.d0.loss_mask: 0.4954  decode.d0.loss_dice: 1.2133  decode.d1.loss_cls: 0.1002  decode.d1.loss_mask: 0.4763  decode.d1.loss_dice: 1.1259  decode.d2.loss_cls: 0.0750  decode.d2.loss_mask: 0.4759  decode.d2.loss_dice: 1.1192  decode.d3.loss_cls: 0.0833  decode.d3.loss_mask: 0.4759  decode.d3.loss_dice: 1.1191  decode.d4.loss_cls: 0.0836  decode.d4.loss_mask: 0.4619  decode.d4.loss_dice: 1.0946  decode.d5.loss_cls: 0.0866  decode.d5.loss_mask: 0.4749  decode.d5.loss_dice: 1.1013  decode.d6.loss_cls: 0.0723  decode.d6.loss_mask: 0.4718  decode.d6.loss_dice: 1.0994  decode.d7.loss_cls: 0.0804  decode.d7.loss_mask: 0.4627  decode.d7.loss_dice: 1.0873  decode.d8.loss_cls: 0.0842  decode.d8.loss_mask: 0.4593  decode.d8.loss_dice: 1.1090
11/15 16:30:53 - mmengine - INFO - Iter(train) [55350/90000]  base_lr: 4.2356e-05 lr: 4.2356e-06  eta: 5:48:13  time: 0.5949  data_time: 0.0104  memory: 10742  grad_norm: 307.6429  loss: 18.1861  decode.loss_cls: 0.0856  decode.loss_mask: 0.5517  decode.loss_dice: 1.1733  decode.d0.loss_cls: 0.1115  decode.d0.loss_mask: 0.5778  decode.d0.loss_dice: 1.2928  decode.d1.loss_cls: 0.0931  decode.d1.loss_mask: 0.5398  decode.d1.loss_dice: 1.2118  decode.d2.loss_cls: 0.0960  decode.d2.loss_mask: 0.5475  decode.d2.loss_dice: 1.2121  decode.d3.loss_cls: 0.0912  decode.d3.loss_mask: 0.5346  decode.d3.loss_dice: 1.1407  decode.d4.loss_cls: 0.0968  decode.d4.loss_mask: 0.5283  decode.d4.loss_dice: 1.1540  decode.d5.loss_cls: 0.0910  decode.d5.loss_mask: 0.5431  decode.d5.loss_dice: 1.1533  decode.d6.loss_cls: 0.1016  decode.d6.loss_mask: 0.5311  decode.d6.loss_dice: 1.1469  decode.d7.loss_cls: 0.0782  decode.d7.loss_mask: 0.5409  decode.d7.loss_dice: 1.1546  decode.d8.loss_cls: 0.1050  decode.d8.loss_mask: 0.5338  decode.d8.loss_dice: 1.1682
11/15 16:31:23 - mmengine - INFO - Iter(train) [55400/90000]  base_lr: 4.2301e-05 lr: 4.2301e-06  eta: 5:47:43  time: 0.5955  data_time: 0.0102  memory: 10641  grad_norm: 299.7888  loss: 16.5364  decode.loss_cls: 0.0522  decode.loss_mask: 0.4765  decode.loss_dice: 1.1236  decode.d0.loss_cls: 0.0626  decode.d0.loss_mask: 0.4806  decode.d0.loss_dice: 1.1669  decode.d1.loss_cls: 0.0505  decode.d1.loss_mask: 0.4744  decode.d1.loss_dice: 1.1274  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 0.4709  decode.d2.loss_dice: 1.1205  decode.d3.loss_cls: 0.0560  decode.d3.loss_mask: 0.4695  decode.d3.loss_dice: 1.1196  decode.d4.loss_cls: 0.0553  decode.d4.loss_mask: 0.4710  decode.d4.loss_dice: 1.1472  decode.d5.loss_cls: 0.0654  decode.d5.loss_mask: 0.4674  decode.d5.loss_dice: 1.0949  decode.d6.loss_cls: 0.0622  decode.d6.loss_mask: 0.4734  decode.d6.loss_dice: 1.1057  decode.d7.loss_cls: 0.0616  decode.d7.loss_mask: 0.4763  decode.d7.loss_dice: 1.0993  decode.d8.loss_cls: 0.0591  decode.d8.loss_mask: 0.4734  decode.d8.loss_dice: 1.1193
11/15 16:31:53 - mmengine - INFO - Iter(train) [55450/90000]  base_lr: 4.2246e-05 lr: 4.2246e-06  eta: 5:47:12  time: 0.5941  data_time: 0.0102  memory: 10675  grad_norm: 577.7129  loss: 18.8203  decode.loss_cls: 0.0530  decode.loss_mask: 0.6580  decode.loss_dice: 1.1782  decode.d0.loss_cls: 0.0655  decode.d0.loss_mask: 0.6827  decode.d0.loss_dice: 1.2343  decode.d1.loss_cls: 0.0710  decode.d1.loss_mask: 0.6058  decode.d1.loss_dice: 1.1641  decode.d2.loss_cls: 0.0554  decode.d2.loss_mask: 0.6674  decode.d2.loss_dice: 1.1724  decode.d3.loss_cls: 0.0656  decode.d3.loss_mask: 0.6584  decode.d3.loss_dice: 1.1693  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.6549  decode.d4.loss_dice: 1.1641  decode.d5.loss_cls: 0.0660  decode.d5.loss_mask: 0.6068  decode.d5.loss_dice: 1.1876  decode.d6.loss_cls: 0.0516  decode.d6.loss_mask: 0.6301  decode.d6.loss_dice: 1.1778  decode.d7.loss_cls: 0.0666  decode.d7.loss_mask: 0.6035  decode.d7.loss_dice: 1.1778  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.6007  decode.d8.loss_dice: 1.1989
11/15 16:32:23 - mmengine - INFO - Iter(train) [55500/90000]  base_lr: 4.2191e-05 lr: 4.2191e-06  eta: 5:46:42  time: 0.5938  data_time: 0.0101  memory: 10675  grad_norm: 935.4508  loss: 17.7524  decode.loss_cls: 0.0824  decode.loss_mask: 0.5386  decode.loss_dice: 1.1175  decode.d0.loss_cls: 0.0964  decode.d0.loss_mask: 0.5760  decode.d0.loss_dice: 1.2586  decode.d1.loss_cls: 0.0842  decode.d1.loss_mask: 0.5514  decode.d1.loss_dice: 1.1359  decode.d2.loss_cls: 0.0740  decode.d2.loss_mask: 0.5692  decode.d2.loss_dice: 1.1257  decode.d3.loss_cls: 0.0833  decode.d3.loss_mask: 0.5589  decode.d3.loss_dice: 1.1291  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.5893  decode.d4.loss_dice: 1.1279  decode.d5.loss_cls: 0.0866  decode.d5.loss_mask: 0.5343  decode.d5.loss_dice: 1.1056  decode.d6.loss_cls: 0.0686  decode.d6.loss_mask: 0.5622  decode.d6.loss_dice: 1.0850  decode.d7.loss_cls: 0.0677  decode.d7.loss_mask: 0.5725  decode.d7.loss_dice: 1.1234  decode.d8.loss_cls: 0.0687  decode.d8.loss_mask: 0.5808  decode.d8.loss_dice: 1.1251
11/15 16:32:52 - mmengine - INFO - Iter(train) [55550/90000]  base_lr: 4.2136e-05 lr: 4.2136e-06  eta: 5:46:12  time: 0.5955  data_time: 0.0103  memory: 10713  grad_norm: 532.7067  loss: 17.6022  decode.loss_cls: 0.0661  decode.loss_mask: 0.5514  decode.loss_dice: 1.0890  decode.d0.loss_cls: 0.0962  decode.d0.loss_mask: 0.5661  decode.d0.loss_dice: 1.1734  decode.d1.loss_cls: 0.0804  decode.d1.loss_mask: 0.5563  decode.d1.loss_dice: 1.1523  decode.d2.loss_cls: 0.0660  decode.d2.loss_mask: 0.5813  decode.d2.loss_dice: 1.1351  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.6007  decode.d3.loss_dice: 1.1220  decode.d4.loss_cls: 0.0702  decode.d4.loss_mask: 0.5889  decode.d4.loss_dice: 1.1188  decode.d5.loss_cls: 0.0571  decode.d5.loss_mask: 0.5808  decode.d5.loss_dice: 1.1206  decode.d6.loss_cls: 0.0776  decode.d6.loss_mask: 0.5462  decode.d6.loss_dice: 1.0845  decode.d7.loss_cls: 0.0638  decode.d7.loss_mask: 0.5741  decode.d7.loss_dice: 1.0896  decode.d8.loss_cls: 0.0680  decode.d8.loss_mask: 0.5620  decode.d8.loss_dice: 1.0992
11/15 16:33:22 - mmengine - INFO - Iter(train) [55600/90000]  base_lr: 4.2081e-05 lr: 4.2081e-06  eta: 5:45:41  time: 0.5955  data_time: 0.0103  memory: 10728  grad_norm: 242.9347  loss: 15.8331  decode.loss_cls: 0.0614  decode.loss_mask: 0.4880  decode.loss_dice: 1.0212  decode.d0.loss_cls: 0.0844  decode.d0.loss_mask: 0.4907  decode.d0.loss_dice: 1.1214  decode.d1.loss_cls: 0.0701  decode.d1.loss_mask: 0.4811  decode.d1.loss_dice: 1.0504  decode.d2.loss_cls: 0.0742  decode.d2.loss_mask: 0.4794  decode.d2.loss_dice: 1.0203  decode.d3.loss_cls: 0.0737  decode.d3.loss_mask: 0.4835  decode.d3.loss_dice: 0.9792  decode.d4.loss_cls: 0.0614  decode.d4.loss_mask: 0.4843  decode.d4.loss_dice: 0.9981  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.5041  decode.d5.loss_dice: 1.0316  decode.d6.loss_cls: 0.0739  decode.d6.loss_mask: 0.4931  decode.d6.loss_dice: 1.0137  decode.d7.loss_cls: 0.0680  decode.d7.loss_mask: 0.4851  decode.d7.loss_dice: 1.0029  decode.d8.loss_cls: 0.0638  decode.d8.loss_mask: 0.4869  decode.d8.loss_dice: 1.0220
11/15 16:33:52 - mmengine - INFO - Iter(train) [55650/90000]  base_lr: 4.2026e-05 lr: 4.2026e-06  eta: 5:45:11  time: 0.5949  data_time: 0.0108  memory: 10692  grad_norm: 351.2573  loss: 16.3858  decode.loss_cls: 0.0372  decode.loss_mask: 0.5240  decode.loss_dice: 1.0637  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.5507  decode.d0.loss_dice: 1.1408  decode.d1.loss_cls: 0.0524  decode.d1.loss_mask: 0.5313  decode.d1.loss_dice: 1.0663  decode.d2.loss_cls: 0.0643  decode.d2.loss_mask: 0.5093  decode.d2.loss_dice: 1.0389  decode.d3.loss_cls: 0.0422  decode.d3.loss_mask: 0.5120  decode.d3.loss_dice: 1.0740  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.5082  decode.d4.loss_dice: 1.0633  decode.d5.loss_cls: 0.0613  decode.d5.loss_mask: 0.5111  decode.d5.loss_dice: 1.0194  decode.d6.loss_cls: 0.0654  decode.d6.loss_mask: 0.5149  decode.d6.loss_dice: 1.0266  decode.d7.loss_cls: 0.0522  decode.d7.loss_mask: 0.5271  decode.d7.loss_dice: 1.0333  decode.d8.loss_cls: 0.0470  decode.d8.loss_mask: 0.5269  decode.d8.loss_dice: 1.0729
11/15 16:34:22 - mmengine - INFO - Iter(train) [55700/90000]  base_lr: 4.1971e-05 lr: 4.1971e-06  eta: 5:44:40  time: 0.5967  data_time: 0.0106  memory: 10656  grad_norm: 473.5904  loss: 15.7639  decode.loss_cls: 0.0382  decode.loss_mask: 0.4861  decode.loss_dice: 1.0342  decode.d0.loss_cls: 0.1099  decode.d0.loss_mask: 0.4868  decode.d0.loss_dice: 1.0208  decode.d1.loss_cls: 0.0607  decode.d1.loss_mask: 0.4748  decode.d1.loss_dice: 1.0465  decode.d2.loss_cls: 0.0427  decode.d2.loss_mask: 0.4693  decode.d2.loss_dice: 1.0733  decode.d3.loss_cls: 0.0492  decode.d3.loss_mask: 0.4774  decode.d3.loss_dice: 1.0458  decode.d4.loss_cls: 0.0460  decode.d4.loss_mask: 0.4826  decode.d4.loss_dice: 1.0409  decode.d5.loss_cls: 0.0437  decode.d5.loss_mask: 0.4788  decode.d5.loss_dice: 1.0484  decode.d6.loss_cls: 0.0423  decode.d6.loss_mask: 0.4791  decode.d6.loss_dice: 1.0269  decode.d7.loss_cls: 0.0421  decode.d7.loss_mask: 0.4804  decode.d7.loss_dice: 1.0505  decode.d8.loss_cls: 0.0508  decode.d8.loss_mask: 0.4773  decode.d8.loss_dice: 1.0583
11/15 16:34:51 - mmengine - INFO - Iter(train) [55750/90000]  base_lr: 4.1916e-05 lr: 4.1916e-06  eta: 5:44:10  time: 0.5944  data_time: 0.0102  memory: 10641  grad_norm: 294.6296  loss: 16.8735  decode.loss_cls: 0.0787  decode.loss_mask: 0.4910  decode.loss_dice: 1.0983  decode.d0.loss_cls: 0.0980  decode.d0.loss_mask: 0.5221  decode.d0.loss_dice: 1.1628  decode.d1.loss_cls: 0.0831  decode.d1.loss_mask: 0.5089  decode.d1.loss_dice: 1.1305  decode.d2.loss_cls: 0.0942  decode.d2.loss_mask: 0.4890  decode.d2.loss_dice: 1.1189  decode.d3.loss_cls: 0.0802  decode.d3.loss_mask: 0.4957  decode.d3.loss_dice: 1.0973  decode.d4.loss_cls: 0.0848  decode.d4.loss_mask: 0.4909  decode.d4.loss_dice: 1.0958  decode.d5.loss_cls: 0.0858  decode.d5.loss_mask: 0.4876  decode.d5.loss_dice: 1.0812  decode.d6.loss_cls: 0.0770  decode.d6.loss_mask: 0.4885  decode.d6.loss_dice: 1.0941  decode.d7.loss_cls: 0.0829  decode.d7.loss_mask: 0.4906  decode.d7.loss_dice: 1.0882  decode.d8.loss_cls: 0.0823  decode.d8.loss_mask: 0.4803  decode.d8.loss_dice: 1.1147
11/15 16:35:21 - mmengine - INFO - Iter(train) [55800/90000]  base_lr: 4.1861e-05 lr: 4.1861e-06  eta: 5:43:40  time: 0.5965  data_time: 0.0104  memory: 10675  grad_norm: 337.9837  loss: 15.4149  decode.loss_cls: 0.0731  decode.loss_mask: 0.4647  decode.loss_dice: 0.9677  decode.d0.loss_cls: 0.0834  decode.d0.loss_mask: 0.5116  decode.d0.loss_dice: 1.1160  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.4644  decode.d1.loss_dice: 1.0352  decode.d2.loss_cls: 0.0846  decode.d2.loss_mask: 0.4676  decode.d2.loss_dice: 1.0095  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.4652  decode.d3.loss_dice: 0.9641  decode.d4.loss_cls: 0.0673  decode.d4.loss_mask: 0.4663  decode.d4.loss_dice: 0.9850  decode.d5.loss_cls: 0.0824  decode.d5.loss_mask: 0.4628  decode.d5.loss_dice: 0.9769  decode.d6.loss_cls: 0.0784  decode.d6.loss_mask: 0.4591  decode.d6.loss_dice: 0.9717  decode.d7.loss_cls: 0.0790  decode.d7.loss_mask: 0.4595  decode.d7.loss_dice: 0.9739  decode.d8.loss_cls: 0.0722  decode.d8.loss_mask: 0.4615  decode.d8.loss_dice: 0.9523
11/15 16:35:51 - mmengine - INFO - Iter(train) [55850/90000]  base_lr: 4.1806e-05 lr: 4.1806e-06  eta: 5:43:09  time: 0.5940  data_time: 0.0104  memory: 10692  grad_norm: 348.0985  loss: 15.0725  decode.loss_cls: 0.0653  decode.loss_mask: 0.4283  decode.loss_dice: 0.9585  decode.d0.loss_cls: 0.0944  decode.d0.loss_mask: 0.4561  decode.d0.loss_dice: 1.0645  decode.d1.loss_cls: 0.0883  decode.d1.loss_mask: 0.4437  decode.d1.loss_dice: 1.0176  decode.d2.loss_cls: 0.0839  decode.d2.loss_mask: 0.4347  decode.d2.loss_dice: 0.9857  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.4507  decode.d3.loss_dice: 0.9915  decode.d4.loss_cls: 0.0788  decode.d4.loss_mask: 0.4393  decode.d4.loss_dice: 0.9650  decode.d5.loss_cls: 0.0727  decode.d5.loss_mask: 0.4404  decode.d5.loss_dice: 0.9704  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.4376  decode.d6.loss_dice: 0.9922  decode.d7.loss_cls: 0.0797  decode.d7.loss_mask: 0.4397  decode.d7.loss_dice: 0.9688  decode.d8.loss_cls: 0.0720  decode.d8.loss_mask: 0.4376  decode.d8.loss_dice: 0.9761
11/15 16:36:21 - mmengine - INFO - Iter(train) [55900/90000]  base_lr: 4.1751e-05 lr: 4.1751e-06  eta: 5:42:39  time: 0.5964  data_time: 0.0104  memory: 10656  grad_norm: 416.5494  loss: 17.9382  decode.loss_cls: 0.0774  decode.loss_mask: 0.5541  decode.loss_dice: 1.1224  decode.d0.loss_cls: 0.0925  decode.d0.loss_mask: 0.6532  decode.d0.loss_dice: 1.2367  decode.d1.loss_cls: 0.0754  decode.d1.loss_mask: 0.5974  decode.d1.loss_dice: 1.1805  decode.d2.loss_cls: 0.0732  decode.d2.loss_mask: 0.5980  decode.d2.loss_dice: 1.1389  decode.d3.loss_cls: 0.0633  decode.d3.loss_mask: 0.5870  decode.d3.loss_dice: 1.1708  decode.d4.loss_cls: 0.0677  decode.d4.loss_mask: 0.5694  decode.d4.loss_dice: 1.1142  decode.d5.loss_cls: 0.0625  decode.d5.loss_mask: 0.5674  decode.d5.loss_dice: 1.1420  decode.d6.loss_cls: 0.0649  decode.d6.loss_mask: 0.5588  decode.d6.loss_dice: 1.0885  decode.d7.loss_cls: 0.0655  decode.d7.loss_mask: 0.5554  decode.d7.loss_dice: 1.1139  decode.d8.loss_cls: 0.0642  decode.d8.loss_mask: 0.5592  decode.d8.loss_dice: 1.1239
11/15 16:36:50 - mmengine - INFO - Iter(train) [55950/90000]  base_lr: 4.1696e-05 lr: 4.1696e-06  eta: 5:42:08  time: 0.5936  data_time: 0.0101  memory: 10713  grad_norm: 506.1400  loss: 16.5535  decode.loss_cls: 0.0414  decode.loss_mask: 0.5756  decode.loss_dice: 1.0095  decode.d0.loss_cls: 0.0781  decode.d0.loss_mask: 0.6008  decode.d0.loss_dice: 1.0947  decode.d1.loss_cls: 0.0449  decode.d1.loss_mask: 0.5684  decode.d1.loss_dice: 1.0536  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 0.5632  decode.d2.loss_dice: 1.0080  decode.d3.loss_cls: 0.0440  decode.d3.loss_mask: 0.5756  decode.d3.loss_dice: 0.9963  decode.d4.loss_cls: 0.0426  decode.d4.loss_mask: 0.5754  decode.d4.loss_dice: 1.0267  decode.d5.loss_cls: 0.0448  decode.d5.loss_mask: 0.5695  decode.d5.loss_dice: 1.0374  decode.d6.loss_cls: 0.0390  decode.d6.loss_mask: 0.5770  decode.d6.loss_dice: 1.0377  decode.d7.loss_cls: 0.0489  decode.d7.loss_mask: 0.5880  decode.d7.loss_dice: 1.0275  decode.d8.loss_cls: 0.0421  decode.d8.loss_mask: 0.5841  decode.d8.loss_dice: 1.0146
11/15 16:37:24 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 16:37:24 - mmengine - INFO - Iter(train) [56000/90000]  base_lr: 4.1641e-05 lr: 4.1641e-06  eta: 5:41:40  time: 0.9778  data_time: 0.0272  memory: 10675  grad_norm: 399.6323  loss: 15.2843  decode.loss_cls: 0.0562  decode.loss_mask: 0.4839  decode.loss_dice: 0.9310  decode.d0.loss_cls: 0.1089  decode.d0.loss_mask: 0.5195  decode.d0.loss_dice: 1.0133  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.5407  decode.d1.loss_dice: 1.0016  decode.d2.loss_cls: 0.0678  decode.d2.loss_mask: 0.4990  decode.d2.loss_dice: 0.9184  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 0.4979  decode.d3.loss_dice: 0.9175  decode.d4.loss_cls: 0.0732  decode.d4.loss_mask: 0.5062  decode.d4.loss_dice: 0.9342  decode.d5.loss_cls: 0.0740  decode.d5.loss_mask: 0.4981  decode.d5.loss_dice: 0.9221  decode.d6.loss_cls: 0.0653  decode.d6.loss_mask: 0.5124  decode.d6.loss_dice: 0.9378  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.5208  decode.d7.loss_dice: 0.9278  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.5150  decode.d8.loss_dice: 0.9654
11/15 16:37:54 - mmengine - INFO - Iter(train) [56050/90000]  base_lr: 4.1585e-05 lr: 4.1585e-06  eta: 5:41:10  time: 0.5948  data_time: 0.0107  memory: 10713  grad_norm: 400.1584  loss: 14.9637  decode.loss_cls: 0.0585  decode.loss_mask: 0.3820  decode.loss_dice: 1.0525  decode.d0.loss_cls: 0.0907  decode.d0.loss_mask: 0.3869  decode.d0.loss_dice: 1.0952  decode.d1.loss_cls: 0.0577  decode.d1.loss_mask: 0.3803  decode.d1.loss_dice: 1.0544  decode.d2.loss_cls: 0.0581  decode.d2.loss_mask: 0.3790  decode.d2.loss_dice: 1.0400  decode.d3.loss_cls: 0.0602  decode.d3.loss_mask: 0.3840  decode.d3.loss_dice: 1.0365  decode.d4.loss_cls: 0.0580  decode.d4.loss_mask: 0.3808  decode.d4.loss_dice: 1.0640  decode.d5.loss_cls: 0.0625  decode.d5.loss_mask: 0.3810  decode.d5.loss_dice: 1.0466  decode.d6.loss_cls: 0.0638  decode.d6.loss_mask: 0.3775  decode.d6.loss_dice: 1.0439  decode.d7.loss_cls: 0.0611  decode.d7.loss_mask: 0.3819  decode.d7.loss_dice: 1.0561  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.3771  decode.d8.loss_dice: 1.0328
11/15 16:38:24 - mmengine - INFO - Iter(train) [56100/90000]  base_lr: 4.1530e-05 lr: 4.1530e-06  eta: 5:40:40  time: 0.5944  data_time: 0.0103  memory: 10713  grad_norm: 775.0191  loss: 15.4938  decode.loss_cls: 0.0667  decode.loss_mask: 0.4909  decode.loss_dice: 0.9997  decode.d0.loss_cls: 0.0845  decode.d0.loss_mask: 0.4914  decode.d0.loss_dice: 1.0628  decode.d1.loss_cls: 0.0573  decode.d1.loss_mask: 0.4955  decode.d1.loss_dice: 0.9981  decode.d2.loss_cls: 0.0575  decode.d2.loss_mask: 0.4865  decode.d2.loss_dice: 0.9901  decode.d3.loss_cls: 0.0605  decode.d3.loss_mask: 0.4718  decode.d3.loss_dice: 0.9894  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.4887  decode.d4.loss_dice: 0.9760  decode.d5.loss_cls: 0.0594  decode.d5.loss_mask: 0.4836  decode.d5.loss_dice: 1.0059  decode.d6.loss_cls: 0.0599  decode.d6.loss_mask: 0.4871  decode.d6.loss_dice: 1.0292  decode.d7.loss_cls: 0.0746  decode.d7.loss_mask: 0.4831  decode.d7.loss_dice: 0.9625  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.4867  decode.d8.loss_dice: 0.9772
11/15 16:38:53 - mmengine - INFO - Iter(train) [56150/90000]  base_lr: 4.1475e-05 lr: 4.1475e-06  eta: 5:40:09  time: 0.5969  data_time: 0.0104  memory: 10692  grad_norm: 347.4295  loss: 17.3389  decode.loss_cls: 0.0529  decode.loss_mask: 0.5644  decode.loss_dice: 1.1171  decode.d0.loss_cls: 0.0803  decode.d0.loss_mask: 0.5953  decode.d0.loss_dice: 1.1532  decode.d1.loss_cls: 0.0543  decode.d1.loss_mask: 0.5456  decode.d1.loss_dice: 1.1260  decode.d2.loss_cls: 0.0610  decode.d2.loss_mask: 0.5600  decode.d2.loss_dice: 1.1028  decode.d3.loss_cls: 0.0511  decode.d3.loss_mask: 0.5712  decode.d3.loss_dice: 1.0926  decode.d4.loss_cls: 0.0506  decode.d4.loss_mask: 0.5665  decode.d4.loss_dice: 1.1028  decode.d5.loss_cls: 0.0506  decode.d5.loss_mask: 0.5694  decode.d5.loss_dice: 1.1111  decode.d6.loss_cls: 0.0526  decode.d6.loss_mask: 0.5668  decode.d6.loss_dice: 1.0978  decode.d7.loss_cls: 0.0561  decode.d7.loss_mask: 0.5603  decode.d7.loss_dice: 1.0965  decode.d8.loss_cls: 0.0470  decode.d8.loss_mask: 0.5681  decode.d8.loss_dice: 1.1150
11/15 16:39:23 - mmengine - INFO - Iter(train) [56200/90000]  base_lr: 4.1420e-05 lr: 4.1420e-06  eta: 5:39:39  time: 0.5940  data_time: 0.0103  memory: 10675  grad_norm: 712.5253  loss: 15.0893  decode.loss_cls: 0.0543  decode.loss_mask: 0.5677  decode.loss_dice: 0.8753  decode.d0.loss_cls: 0.0864  decode.d0.loss_mask: 0.5993  decode.d0.loss_dice: 0.9480  decode.d1.loss_cls: 0.0533  decode.d1.loss_mask: 0.5848  decode.d1.loss_dice: 0.9115  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.5670  decode.d2.loss_dice: 0.8967  decode.d3.loss_cls: 0.0487  decode.d3.loss_mask: 0.5615  decode.d3.loss_dice: 0.8849  decode.d4.loss_cls: 0.0507  decode.d4.loss_mask: 0.5642  decode.d4.loss_dice: 0.8891  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.5617  decode.d5.loss_dice: 0.8684  decode.d6.loss_cls: 0.0557  decode.d6.loss_mask: 0.5544  decode.d6.loss_dice: 0.8699  decode.d7.loss_cls: 0.0507  decode.d7.loss_mask: 0.5662  decode.d7.loss_dice: 0.8589  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 0.5581  decode.d8.loss_dice: 0.8566
11/15 16:39:53 - mmengine - INFO - Iter(train) [56250/90000]  base_lr: 4.1365e-05 lr: 4.1365e-06  eta: 5:39:09  time: 0.5941  data_time: 0.0102  memory: 10692  grad_norm: 371.7586  loss: 15.3186  decode.loss_cls: 0.0515  decode.loss_mask: 0.4362  decode.loss_dice: 1.0307  decode.d0.loss_cls: 0.0739  decode.d0.loss_mask: 0.4650  decode.d0.loss_dice: 1.0630  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.4405  decode.d1.loss_dice: 1.0545  decode.d2.loss_cls: 0.0668  decode.d2.loss_mask: 0.4406  decode.d2.loss_dice: 1.0406  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.4409  decode.d3.loss_dice: 1.0146  decode.d4.loss_cls: 0.0587  decode.d4.loss_mask: 0.4404  decode.d4.loss_dice: 1.0076  decode.d5.loss_cls: 0.0530  decode.d5.loss_mask: 0.4369  decode.d5.loss_dice: 1.0326  decode.d6.loss_cls: 0.0577  decode.d6.loss_mask: 0.4336  decode.d6.loss_dice: 1.0132  decode.d7.loss_cls: 0.0520  decode.d7.loss_mask: 0.4388  decode.d7.loss_dice: 1.0286  decode.d8.loss_cls: 0.0542  decode.d8.loss_mask: 0.4367  decode.d8.loss_dice: 1.0358
11/15 16:40:23 - mmengine - INFO - Iter(train) [56300/90000]  base_lr: 4.1310e-05 lr: 4.1310e-06  eta: 5:38:39  time: 0.5944  data_time: 0.0102  memory: 10692  grad_norm: 276.6782  loss: 16.4426  decode.loss_cls: 0.0553  decode.loss_mask: 0.4865  decode.loss_dice: 1.0843  decode.d0.loss_cls: 0.0764  decode.d0.loss_mask: 0.5173  decode.d0.loss_dice: 1.1549  decode.d1.loss_cls: 0.0599  decode.d1.loss_mask: 0.4899  decode.d1.loss_dice: 1.0738  decode.d2.loss_cls: 0.0588  decode.d2.loss_mask: 0.4889  decode.d2.loss_dice: 1.0998  decode.d3.loss_cls: 0.0700  decode.d3.loss_mask: 0.4898  decode.d3.loss_dice: 1.0931  decode.d4.loss_cls: 0.0707  decode.d4.loss_mask: 0.4898  decode.d4.loss_dice: 1.0834  decode.d5.loss_cls: 0.0582  decode.d5.loss_mask: 0.4893  decode.d5.loss_dice: 1.1004  decode.d6.loss_cls: 0.0567  decode.d6.loss_mask: 0.4865  decode.d6.loss_dice: 1.0671  decode.d7.loss_cls: 0.0577  decode.d7.loss_mask: 0.4898  decode.d7.loss_dice: 1.0670  decode.d8.loss_cls: 0.0562  decode.d8.loss_mask: 0.4883  decode.d8.loss_dice: 1.0827
11/15 16:40:53 - mmengine - INFO - Iter(train) [56350/90000]  base_lr: 4.1255e-05 lr: 4.1255e-06  eta: 5:38:08  time: 0.5946  data_time: 0.0104  memory: 10728  grad_norm: 466.0107  loss: 18.4561  decode.loss_cls: 0.0563  decode.loss_mask: 0.6200  decode.loss_dice: 1.1282  decode.d0.loss_cls: 0.0712  decode.d0.loss_mask: 0.6756  decode.d0.loss_dice: 1.2134  decode.d1.loss_cls: 0.0499  decode.d1.loss_mask: 0.6336  decode.d1.loss_dice: 1.1976  decode.d2.loss_cls: 0.0639  decode.d2.loss_mask: 0.6217  decode.d2.loss_dice: 1.1509  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.6282  decode.d3.loss_dice: 1.1417  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.6233  decode.d4.loss_dice: 1.1432  decode.d5.loss_cls: 0.0514  decode.d5.loss_mask: 0.6283  decode.d5.loss_dice: 1.1720  decode.d6.loss_cls: 0.0597  decode.d6.loss_mask: 0.6273  decode.d6.loss_dice: 1.1334  decode.d7.loss_cls: 0.0619  decode.d7.loss_mask: 0.6229  decode.d7.loss_dice: 1.1494  decode.d8.loss_cls: 0.0585  decode.d8.loss_mask: 0.6258  decode.d8.loss_dice: 1.1383
11/15 16:41:23 - mmengine - INFO - Iter(train) [56400/90000]  base_lr: 4.1199e-05 lr: 4.1199e-06  eta: 5:37:38  time: 0.5976  data_time: 0.0105  memory: 10713  grad_norm: 340.5788  loss: 15.7087  decode.loss_cls: 0.0415  decode.loss_mask: 0.5136  decode.loss_dice: 1.0026  decode.d0.loss_cls: 0.0715  decode.d0.loss_mask: 0.5222  decode.d0.loss_dice: 1.0542  decode.d1.loss_cls: 0.0590  decode.d1.loss_mask: 0.5163  decode.d1.loss_dice: 1.0417  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.5022  decode.d2.loss_dice: 0.9948  decode.d3.loss_cls: 0.0550  decode.d3.loss_mask: 0.5018  decode.d3.loss_dice: 0.9916  decode.d4.loss_cls: 0.0511  decode.d4.loss_mask: 0.5055  decode.d4.loss_dice: 1.0186  decode.d5.loss_cls: 0.0505  decode.d5.loss_mask: 0.5113  decode.d5.loss_dice: 0.9828  decode.d6.loss_cls: 0.0501  decode.d6.loss_mask: 0.5070  decode.d6.loss_dice: 1.0008  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 0.5083  decode.d7.loss_dice: 0.9832  decode.d8.loss_cls: 0.0516  decode.d8.loss_mask: 0.5046  decode.d8.loss_dice: 0.9939
11/15 16:41:53 - mmengine - INFO - Iter(train) [56450/90000]  base_lr: 4.1144e-05 lr: 4.1144e-06  eta: 5:37:08  time: 0.5952  data_time: 0.0104  memory: 10713  grad_norm: 557.4769  loss: 15.8191  decode.loss_cls: 0.0633  decode.loss_mask: 0.4708  decode.loss_dice: 1.0323  decode.d0.loss_cls: 0.0894  decode.d0.loss_mask: 0.4998  decode.d0.loss_dice: 1.1079  decode.d1.loss_cls: 0.0799  decode.d1.loss_mask: 0.4840  decode.d1.loss_dice: 1.0557  decode.d2.loss_cls: 0.0766  decode.d2.loss_mask: 0.4788  decode.d2.loss_dice: 1.0149  decode.d3.loss_cls: 0.0735  decode.d3.loss_mask: 0.4746  decode.d3.loss_dice: 0.9913  decode.d4.loss_cls: 0.0807  decode.d4.loss_mask: 0.4725  decode.d4.loss_dice: 1.0113  decode.d5.loss_cls: 0.0757  decode.d5.loss_mask: 0.4728  decode.d5.loss_dice: 1.0218  decode.d6.loss_cls: 0.0772  decode.d6.loss_mask: 0.4756  decode.d6.loss_dice: 1.0051  decode.d7.loss_cls: 0.0738  decode.d7.loss_mask: 0.4724  decode.d7.loss_dice: 1.0244  decode.d8.loss_cls: 0.0694  decode.d8.loss_mask: 0.4715  decode.d8.loss_dice: 1.0222
11/15 16:42:23 - mmengine - INFO - Iter(train) [56500/90000]  base_lr: 4.1089e-05 lr: 4.1089e-06  eta: 5:36:37  time: 0.5938  data_time: 0.0101  memory: 10675  grad_norm: 605.5678  loss: 16.8793  decode.loss_cls: 0.0565  decode.loss_mask: 0.5448  decode.loss_dice: 1.0532  decode.d0.loss_cls: 0.0912  decode.d0.loss_mask: 0.6009  decode.d0.loss_dice: 1.1732  decode.d1.loss_cls: 0.0849  decode.d1.loss_mask: 0.5562  decode.d1.loss_dice: 1.0785  decode.d2.loss_cls: 0.0638  decode.d2.loss_mask: 0.5493  decode.d2.loss_dice: 1.0503  decode.d3.loss_cls: 0.0512  decode.d3.loss_mask: 0.5462  decode.d3.loss_dice: 1.0707  decode.d4.loss_cls: 0.0636  decode.d4.loss_mask: 0.5454  decode.d4.loss_dice: 1.0418  decode.d5.loss_cls: 0.0815  decode.d5.loss_mask: 0.5509  decode.d5.loss_dice: 1.0421  decode.d6.loss_cls: 0.0692  decode.d6.loss_mask: 0.5445  decode.d6.loss_dice: 1.0415  decode.d7.loss_cls: 0.0657  decode.d7.loss_mask: 0.5523  decode.d7.loss_dice: 1.0516  decode.d8.loss_cls: 0.0521  decode.d8.loss_mask: 0.5456  decode.d8.loss_dice: 1.0606
11/15 16:42:52 - mmengine - INFO - Iter(train) [56550/90000]  base_lr: 4.1034e-05 lr: 4.1034e-06  eta: 5:36:07  time: 0.5949  data_time: 0.0105  memory: 10742  grad_norm: 370.4358  loss: 18.1370  decode.loss_cls: 0.0827  decode.loss_mask: 0.5252  decode.loss_dice: 1.2097  decode.d0.loss_cls: 0.1136  decode.d0.loss_mask: 0.5385  decode.d0.loss_dice: 1.2386  decode.d1.loss_cls: 0.1179  decode.d1.loss_mask: 0.5334  decode.d1.loss_dice: 1.2072  decode.d2.loss_cls: 0.1100  decode.d2.loss_mask: 0.5282  decode.d2.loss_dice: 1.1879  decode.d3.loss_cls: 0.0989  decode.d3.loss_mask: 0.5252  decode.d3.loss_dice: 1.1360  decode.d4.loss_cls: 0.0896  decode.d4.loss_mask: 0.5249  decode.d4.loss_dice: 1.1796  decode.d5.loss_cls: 0.0961  decode.d5.loss_mask: 0.5223  decode.d5.loss_dice: 1.1949  decode.d6.loss_cls: 0.0930  decode.d6.loss_mask: 0.5321  decode.d6.loss_dice: 1.1636  decode.d7.loss_cls: 0.0866  decode.d7.loss_mask: 0.5238  decode.d7.loss_dice: 1.1751  decode.d8.loss_cls: 0.0873  decode.d8.loss_mask: 0.5167  decode.d8.loss_dice: 1.1984
11/15 16:43:22 - mmengine - INFO - Iter(train) [56600/90000]  base_lr: 4.0979e-05 lr: 4.0979e-06  eta: 5:35:36  time: 0.5956  data_time: 0.0103  memory: 10692  grad_norm: 288.4420  loss: 16.5843  decode.loss_cls: 0.0696  decode.loss_mask: 0.4285  decode.loss_dice: 1.1424  decode.d0.loss_cls: 0.0878  decode.d0.loss_mask: 0.4356  decode.d0.loss_dice: 1.2669  decode.d1.loss_cls: 0.1029  decode.d1.loss_mask: 0.4245  decode.d1.loss_dice: 1.1512  decode.d2.loss_cls: 0.0911  decode.d2.loss_mask: 0.4205  decode.d2.loss_dice: 1.1548  decode.d3.loss_cls: 0.0731  decode.d3.loss_mask: 0.4243  decode.d3.loss_dice: 1.1475  decode.d4.loss_cls: 0.0750  decode.d4.loss_mask: 0.4283  decode.d4.loss_dice: 1.1086  decode.d5.loss_cls: 0.0900  decode.d5.loss_mask: 0.4315  decode.d5.loss_dice: 1.1480  decode.d6.loss_cls: 0.0824  decode.d6.loss_mask: 0.4248  decode.d6.loss_dice: 1.1084  decode.d7.loss_cls: 0.0880  decode.d7.loss_mask: 0.4300  decode.d7.loss_dice: 1.1114  decode.d8.loss_cls: 0.0804  decode.d8.loss_mask: 0.4246  decode.d8.loss_dice: 1.1322
11/15 16:43:52 - mmengine - INFO - Iter(train) [56650/90000]  base_lr: 4.0923e-05 lr: 4.0923e-06  eta: 5:35:06  time: 0.5958  data_time: 0.0104  memory: 10713  grad_norm: 309.9095  loss: 13.9307  decode.loss_cls: 0.0546  decode.loss_mask: 0.3993  decode.loss_dice: 0.9009  decode.d0.loss_cls: 0.0864  decode.d0.loss_mask: 0.4155  decode.d0.loss_dice: 1.0025  decode.d1.loss_cls: 0.0648  decode.d1.loss_mask: 0.4085  decode.d1.loss_dice: 0.9541  decode.d2.loss_cls: 0.0585  decode.d2.loss_mask: 0.4108  decode.d2.loss_dice: 0.9092  decode.d3.loss_cls: 0.0569  decode.d3.loss_mask: 0.4102  decode.d3.loss_dice: 0.9388  decode.d4.loss_cls: 0.0632  decode.d4.loss_mask: 0.4065  decode.d4.loss_dice: 0.9207  decode.d5.loss_cls: 0.0611  decode.d5.loss_mask: 0.4072  decode.d5.loss_dice: 0.9074  decode.d6.loss_cls: 0.0570  decode.d6.loss_mask: 0.4012  decode.d6.loss_dice: 0.8976  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.4093  decode.d7.loss_dice: 0.9185  decode.d8.loss_cls: 0.0549  decode.d8.loss_mask: 0.3988  decode.d8.loss_dice: 0.8940
11/15 16:44:22 - mmengine - INFO - Iter(train) [56700/90000]  base_lr: 4.0868e-05 lr: 4.0868e-06  eta: 5:34:36  time: 0.5955  data_time: 0.0105  memory: 10713  grad_norm: 244.7748  loss: 17.0834  decode.loss_cls: 0.0684  decode.loss_mask: 0.4976  decode.loss_dice: 1.1251  decode.d0.loss_cls: 0.0876  decode.d0.loss_mask: 0.5224  decode.d0.loss_dice: 1.1887  decode.d1.loss_cls: 0.0810  decode.d1.loss_mask: 0.5054  decode.d1.loss_dice: 1.1719  decode.d2.loss_cls: 0.0783  decode.d2.loss_mask: 0.4950  decode.d2.loss_dice: 1.1433  decode.d3.loss_cls: 0.0781  decode.d3.loss_mask: 0.4922  decode.d3.loss_dice: 1.1338  decode.d4.loss_cls: 0.0780  decode.d4.loss_mask: 0.4879  decode.d4.loss_dice: 1.0994  decode.d5.loss_cls: 0.0737  decode.d5.loss_mask: 0.5020  decode.d5.loss_dice: 1.1081  decode.d6.loss_cls: 0.0746  decode.d6.loss_mask: 0.4989  decode.d6.loss_dice: 1.1000  decode.d7.loss_cls: 0.0675  decode.d7.loss_mask: 0.5033  decode.d7.loss_dice: 1.1238  decode.d8.loss_cls: 0.0798  decode.d8.loss_mask: 0.5031  decode.d8.loss_dice: 1.1145
11/15 16:44:52 - mmengine - INFO - Iter(train) [56750/90000]  base_lr: 4.0813e-05 lr: 4.0813e-06  eta: 5:34:05  time: 0.5941  data_time: 0.0104  memory: 10713  grad_norm: 357.4261  loss: 17.2361  decode.loss_cls: 0.0492  decode.loss_mask: 0.5705  decode.loss_dice: 1.0229  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.6297  decode.d0.loss_dice: 1.0980  decode.d1.loss_cls: 0.0422  decode.d1.loss_mask: 0.6691  decode.d1.loss_dice: 1.0914  decode.d2.loss_cls: 0.0372  decode.d2.loss_mask: 0.6374  decode.d2.loss_dice: 1.0787  decode.d3.loss_cls: 0.0413  decode.d3.loss_mask: 0.5955  decode.d3.loss_dice: 1.0494  decode.d4.loss_cls: 0.0431  decode.d4.loss_mask: 0.6452  decode.d4.loss_dice: 1.0581  decode.d5.loss_cls: 0.0388  decode.d5.loss_mask: 0.6461  decode.d5.loss_dice: 1.0544  decode.d6.loss_cls: 0.0363  decode.d6.loss_mask: 0.6482  decode.d6.loss_dice: 1.0367  decode.d7.loss_cls: 0.0464  decode.d7.loss_mask: 0.5895  decode.d7.loss_dice: 1.0401  decode.d8.loss_cls: 0.0487  decode.d8.loss_mask: 0.5771  decode.d8.loss_dice: 1.0366
11/15 16:45:21 - mmengine - INFO - Iter(train) [56800/90000]  base_lr: 4.0758e-05 lr: 4.0758e-06  eta: 5:33:35  time: 0.5956  data_time: 0.0106  memory: 10692  grad_norm: 252.5554  loss: 15.5482  decode.loss_cls: 0.0749  decode.loss_mask: 0.3988  decode.loss_dice: 1.0894  decode.d0.loss_cls: 0.0886  decode.d0.loss_mask: 0.3902  decode.d0.loss_dice: 1.1484  decode.d1.loss_cls: 0.0686  decode.d1.loss_mask: 0.4039  decode.d1.loss_dice: 1.1061  decode.d2.loss_cls: 0.0667  decode.d2.loss_mask: 0.3906  decode.d2.loss_dice: 1.1064  decode.d3.loss_cls: 0.0795  decode.d3.loss_mask: 0.3852  decode.d3.loss_dice: 1.0519  decode.d4.loss_cls: 0.0637  decode.d4.loss_mask: 0.3945  decode.d4.loss_dice: 1.1027  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.3880  decode.d5.loss_dice: 1.0744  decode.d6.loss_cls: 0.0671  decode.d6.loss_mask: 0.3914  decode.d6.loss_dice: 1.0815  decode.d7.loss_cls: 0.0617  decode.d7.loss_mask: 0.4039  decode.d7.loss_dice: 1.0873  decode.d8.loss_cls: 0.0670  decode.d8.loss_mask: 0.3924  decode.d8.loss_dice: 1.0509
11/15 16:45:51 - mmengine - INFO - Iter(train) [56850/90000]  base_lr: 4.0703e-05 lr: 4.0703e-06  eta: 5:33:05  time: 0.5954  data_time: 0.0102  memory: 10675  grad_norm: 998.0970  loss: 17.8576  decode.loss_cls: 0.0653  decode.loss_mask: 0.4855  decode.loss_dice: 1.2316  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 0.4751  decode.d0.loss_dice: 1.3006  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 0.4977  decode.d1.loss_dice: 1.2484  decode.d2.loss_cls: 0.0718  decode.d2.loss_mask: 0.4946  decode.d2.loss_dice: 1.2097  decode.d3.loss_cls: 0.0641  decode.d3.loss_mask: 0.5018  decode.d3.loss_dice: 1.2224  decode.d4.loss_cls: 0.0568  decode.d4.loss_mask: 0.5087  decode.d4.loss_dice: 1.2308  decode.d5.loss_cls: 0.0745  decode.d5.loss_mask: 0.4778  decode.d5.loss_dice: 1.1945  decode.d6.loss_cls: 0.0682  decode.d6.loss_mask: 0.4847  decode.d6.loss_dice: 1.2304  decode.d7.loss_cls: 0.0803  decode.d7.loss_mask: 0.4777  decode.d7.loss_dice: 1.2147  decode.d8.loss_cls: 0.0782  decode.d8.loss_mask: 0.4767  decode.d8.loss_dice: 1.1911
11/15 16:46:21 - mmengine - INFO - Iter(train) [56900/90000]  base_lr: 4.0647e-05 lr: 4.0647e-06  eta: 5:32:34  time: 0.5973  data_time: 0.0108  memory: 10656  grad_norm: 238.7872  loss: 14.0354  decode.loss_cls: 0.0610  decode.loss_mask: 0.4102  decode.loss_dice: 0.9133  decode.d0.loss_cls: 0.0889  decode.d0.loss_mask: 0.4207  decode.d0.loss_dice: 0.9721  decode.d1.loss_cls: 0.0694  decode.d1.loss_mask: 0.4213  decode.d1.loss_dice: 0.9174  decode.d2.loss_cls: 0.0661  decode.d2.loss_mask: 0.4155  decode.d2.loss_dice: 0.9250  decode.d3.loss_cls: 0.0534  decode.d3.loss_mask: 0.4135  decode.d3.loss_dice: 0.9330  decode.d4.loss_cls: 0.0674  decode.d4.loss_mask: 0.4109  decode.d4.loss_dice: 0.9389  decode.d5.loss_cls: 0.0682  decode.d5.loss_mask: 0.4130  decode.d5.loss_dice: 0.9119  decode.d6.loss_cls: 0.0560  decode.d6.loss_mask: 0.4132  decode.d6.loss_dice: 0.9126  decode.d7.loss_cls: 0.0684  decode.d7.loss_mask: 0.4041  decode.d7.loss_dice: 0.9110  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.4125  decode.d8.loss_dice: 0.9047
11/15 16:46:51 - mmengine - INFO - Iter(train) [56950/90000]  base_lr: 4.0592e-05 lr: 4.0592e-06  eta: 5:32:04  time: 0.5953  data_time: 0.0106  memory: 10656  grad_norm: 296.0806  loss: 15.7536  decode.loss_cls: 0.0712  decode.loss_mask: 0.4230  decode.loss_dice: 1.0592  decode.d0.loss_cls: 0.0624  decode.d0.loss_mask: 0.4326  decode.d0.loss_dice: 1.1771  decode.d1.loss_cls: 0.0645  decode.d1.loss_mask: 0.4299  decode.d1.loss_dice: 1.1086  decode.d2.loss_cls: 0.0711  decode.d2.loss_mask: 0.4188  decode.d2.loss_dice: 1.0687  decode.d3.loss_cls: 0.0829  decode.d3.loss_mask: 0.4115  decode.d3.loss_dice: 1.0597  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.4229  decode.d4.loss_dice: 1.0974  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.4179  decode.d5.loss_dice: 1.1053  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.4177  decode.d6.loss_dice: 1.0741  decode.d7.loss_cls: 0.0694  decode.d7.loss_mask: 0.4191  decode.d7.loss_dice: 1.0553  decode.d8.loss_cls: 0.0682  decode.d8.loss_mask: 0.4227  decode.d8.loss_dice: 1.0534
11/15 16:47:20 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 16:47:20 - mmengine - INFO - Iter(train) [57000/90000]  base_lr: 4.0537e-05 lr: 4.0537e-06  eta: 5:31:34  time: 0.5949  data_time: 0.0103  memory: 10692  grad_norm: 271.0912  loss: 17.2112  decode.loss_cls: 0.0851  decode.loss_mask: 0.4670  decode.loss_dice: 1.1558  decode.d0.loss_cls: 0.0904  decode.d0.loss_mask: 0.4873  decode.d0.loss_dice: 1.2511  decode.d1.loss_cls: 0.0905  decode.d1.loss_mask: 0.4756  decode.d1.loss_dice: 1.1653  decode.d2.loss_cls: 0.0911  decode.d2.loss_mask: 0.4955  decode.d2.loss_dice: 1.1792  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 0.4802  decode.d3.loss_dice: 1.1530  decode.d4.loss_cls: 0.0934  decode.d4.loss_mask: 0.4703  decode.d4.loss_dice: 1.1324  decode.d5.loss_cls: 0.0887  decode.d5.loss_mask: 0.4680  decode.d5.loss_dice: 1.1390  decode.d6.loss_cls: 0.0822  decode.d6.loss_mask: 0.4781  decode.d6.loss_dice: 1.1441  decode.d7.loss_cls: 0.0739  decode.d7.loss_mask: 0.4793  decode.d7.loss_dice: 1.1340  decode.d8.loss_cls: 0.0768  decode.d8.loss_mask: 0.4701  decode.d8.loss_dice: 1.1242
11/15 16:47:50 - mmengine - INFO - Iter(train) [57050/90000]  base_lr: 4.0481e-05 lr: 4.0481e-06  eta: 5:31:03  time: 0.5947  data_time: 0.0104  memory: 10692  grad_norm: 324.3689  loss: 16.0298  decode.loss_cls: 0.0650  decode.loss_mask: 0.5458  decode.loss_dice: 0.9849  decode.d0.loss_cls: 0.0936  decode.d0.loss_mask: 0.5766  decode.d0.loss_dice: 1.0280  decode.d1.loss_cls: 0.0732  decode.d1.loss_mask: 0.5512  decode.d1.loss_dice: 0.9765  decode.d2.loss_cls: 0.0645  decode.d2.loss_mask: 0.5444  decode.d2.loss_dice: 1.0210  decode.d3.loss_cls: 0.0762  decode.d3.loss_mask: 0.5379  decode.d3.loss_dice: 0.9773  decode.d4.loss_cls: 0.0753  decode.d4.loss_mask: 0.5368  decode.d4.loss_dice: 0.9662  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.5401  decode.d5.loss_dice: 0.9870  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.5352  decode.d6.loss_dice: 0.9721  decode.d7.loss_cls: 0.0654  decode.d7.loss_mask: 0.5491  decode.d7.loss_dice: 0.9645  decode.d8.loss_cls: 0.0634  decode.d8.loss_mask: 0.5503  decode.d8.loss_dice: 0.9694
11/15 16:48:20 - mmengine - INFO - Iter(train) [57100/90000]  base_lr: 4.0426e-05 lr: 4.0426e-06  eta: 5:30:33  time: 0.5958  data_time: 0.0105  memory: 10692  grad_norm: 341.0967  loss: 17.3305  decode.loss_cls: 0.0783  decode.loss_mask: 0.5194  decode.loss_dice: 1.1386  decode.d0.loss_cls: 0.0768  decode.d0.loss_mask: 0.5628  decode.d0.loss_dice: 1.2295  decode.d1.loss_cls: 0.0944  decode.d1.loss_mask: 0.5340  decode.d1.loss_dice: 1.1326  decode.d2.loss_cls: 0.0838  decode.d2.loss_mask: 0.5169  decode.d2.loss_dice: 1.1007  decode.d3.loss_cls: 0.0767  decode.d3.loss_mask: 0.5214  decode.d3.loss_dice: 1.1069  decode.d4.loss_cls: 0.0832  decode.d4.loss_mask: 0.5196  decode.d4.loss_dice: 1.1185  decode.d5.loss_cls: 0.0825  decode.d5.loss_mask: 0.5141  decode.d5.loss_dice: 1.1031  decode.d6.loss_cls: 0.0890  decode.d6.loss_mask: 0.5249  decode.d6.loss_dice: 1.0878  decode.d7.loss_cls: 0.0833  decode.d7.loss_mask: 0.5227  decode.d7.loss_dice: 1.1104  decode.d8.loss_cls: 0.0843  decode.d8.loss_mask: 0.5210  decode.d8.loss_dice: 1.1133
11/15 16:48:50 - mmengine - INFO - Iter(train) [57150/90000]  base_lr: 4.0371e-05 lr: 4.0371e-06  eta: 5:30:03  time: 0.5954  data_time: 0.0102  memory: 10675  grad_norm: 543.2057  loss: 18.5242  decode.loss_cls: 0.0690  decode.loss_mask: 0.6346  decode.loss_dice: 1.1302  decode.d0.loss_cls: 0.0810  decode.d0.loss_mask: 0.6861  decode.d0.loss_dice: 1.1862  decode.d1.loss_cls: 0.0431  decode.d1.loss_mask: 0.6468  decode.d1.loss_dice: 1.1710  decode.d2.loss_cls: 0.0511  decode.d2.loss_mask: 0.6528  decode.d2.loss_dice: 1.1465  decode.d3.loss_cls: 0.0544  decode.d3.loss_mask: 0.6505  decode.d3.loss_dice: 1.1192  decode.d4.loss_cls: 0.0463  decode.d4.loss_mask: 0.6523  decode.d4.loss_dice: 1.1530  decode.d5.loss_cls: 0.0363  decode.d5.loss_mask: 0.6683  decode.d5.loss_dice: 1.1528  decode.d6.loss_cls: 0.0442  decode.d6.loss_mask: 0.6494  decode.d6.loss_dice: 1.1426  decode.d7.loss_cls: 0.0456  decode.d7.loss_mask: 0.6433  decode.d7.loss_dice: 1.1505  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.6387  decode.d8.loss_dice: 1.1268
11/15 16:49:20 - mmengine - INFO - Iter(train) [57200/90000]  base_lr: 4.0316e-05 lr: 4.0316e-06  eta: 5:29:32  time: 0.5942  data_time: 0.0103  memory: 10713  grad_norm: 610.7927  loss: 20.7986  decode.loss_cls: 0.0740  decode.loss_mask: 0.7148  decode.loss_dice: 1.2422  decode.d0.loss_cls: 0.1026  decode.d0.loss_mask: 0.7733  decode.d0.loss_dice: 1.3287  decode.d1.loss_cls: 0.0867  decode.d1.loss_mask: 0.7352  decode.d1.loss_dice: 1.2703  decode.d2.loss_cls: 0.0811  decode.d2.loss_mask: 0.7054  decode.d2.loss_dice: 1.2756  decode.d3.loss_cls: 0.0767  decode.d3.loss_mask: 0.6886  decode.d3.loss_dice: 1.2751  decode.d4.loss_cls: 0.0808  decode.d4.loss_mask: 0.7182  decode.d4.loss_dice: 1.2609  decode.d5.loss_cls: 0.0774  decode.d5.loss_mask: 0.7174  decode.d5.loss_dice: 1.2505  decode.d6.loss_cls: 0.0761  decode.d6.loss_mask: 0.7217  decode.d6.loss_dice: 1.2865  decode.d7.loss_cls: 0.0766  decode.d7.loss_mask: 0.7399  decode.d7.loss_dice: 1.2851  decode.d8.loss_cls: 0.0735  decode.d8.loss_mask: 0.7313  decode.d8.loss_dice: 1.2725
11/15 16:49:50 - mmengine - INFO - Iter(train) [57250/90000]  base_lr: 4.0260e-05 lr: 4.0260e-06  eta: 5:29:02  time: 0.5959  data_time: 0.0104  memory: 10675  grad_norm: 316.7411  loss: 16.8312  decode.loss_cls: 0.0650  decode.loss_mask: 0.4807  decode.loss_dice: 1.1148  decode.d0.loss_cls: 0.0676  decode.d0.loss_mask: 0.4929  decode.d0.loss_dice: 1.2338  decode.d1.loss_cls: 0.0627  decode.d1.loss_mask: 0.4786  decode.d1.loss_dice: 1.1514  decode.d2.loss_cls: 0.0633  decode.d2.loss_mask: 0.4751  decode.d2.loss_dice: 1.1257  decode.d3.loss_cls: 0.0709  decode.d3.loss_mask: 0.4702  decode.d3.loss_dice: 1.1443  decode.d4.loss_cls: 0.0596  decode.d4.loss_mask: 0.4763  decode.d4.loss_dice: 1.1487  decode.d5.loss_cls: 0.0567  decode.d5.loss_mask: 0.4741  decode.d5.loss_dice: 1.1351  decode.d6.loss_cls: 0.0520  decode.d6.loss_mask: 0.4788  decode.d6.loss_dice: 1.1192  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.4795  decode.d7.loss_dice: 1.1076  decode.d8.loss_cls: 0.0577  decode.d8.loss_mask: 0.4770  decode.d8.loss_dice: 1.1460
11/15 16:50:19 - mmengine - INFO - Iter(train) [57300/90000]  base_lr: 4.0205e-05 lr: 4.0205e-06  eta: 5:28:32  time: 0.5952  data_time: 0.0105  memory: 10675  grad_norm: 269.9501  loss: 16.7362  decode.loss_cls: 0.0550  decode.loss_mask: 0.4899  decode.loss_dice: 1.0946  decode.d0.loss_cls: 0.0793  decode.d0.loss_mask: 0.5010  decode.d0.loss_dice: 1.1799  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 0.4940  decode.d1.loss_dice: 1.1466  decode.d2.loss_cls: 0.0512  decode.d2.loss_mask: 0.4914  decode.d2.loss_dice: 1.1211  decode.d3.loss_cls: 0.0419  decode.d3.loss_mask: 0.4820  decode.d3.loss_dice: 1.1303  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.4874  decode.d4.loss_dice: 1.1146  decode.d5.loss_cls: 0.0522  decode.d5.loss_mask: 0.4888  decode.d5.loss_dice: 1.1211  decode.d6.loss_cls: 0.0530  decode.d6.loss_mask: 0.4897  decode.d6.loss_dice: 1.1273  decode.d7.loss_cls: 0.0580  decode.d7.loss_mask: 0.4890  decode.d7.loss_dice: 1.1126  decode.d8.loss_cls: 0.0602  decode.d8.loss_mask: 0.4898  decode.d8.loss_dice: 1.1114
11/15 16:50:49 - mmengine - INFO - Iter(train) [57350/90000]  base_lr: 4.0150e-05 lr: 4.0150e-06  eta: 5:28:01  time: 0.5945  data_time: 0.0104  memory: 10713  grad_norm: 358.8848  loss: 16.2772  decode.loss_cls: 0.0446  decode.loss_mask: 0.4858  decode.loss_dice: 1.0606  decode.d0.loss_cls: 0.0685  decode.d0.loss_mask: 0.4982  decode.d0.loss_dice: 1.1998  decode.d1.loss_cls: 0.0560  decode.d1.loss_mask: 0.4912  decode.d1.loss_dice: 1.1347  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 0.4822  decode.d2.loss_dice: 1.0949  decode.d3.loss_cls: 0.0421  decode.d3.loss_mask: 0.4834  decode.d3.loss_dice: 1.0627  decode.d4.loss_cls: 0.0398  decode.d4.loss_mask: 0.4863  decode.d4.loss_dice: 1.1063  decode.d5.loss_cls: 0.0393  decode.d5.loss_mask: 0.4880  decode.d5.loss_dice: 1.0754  decode.d6.loss_cls: 0.0540  decode.d6.loss_mask: 0.4864  decode.d6.loss_dice: 1.0751  decode.d7.loss_cls: 0.0460  decode.d7.loss_mask: 0.4868  decode.d7.loss_dice: 1.0659  decode.d8.loss_cls: 0.0543  decode.d8.loss_mask: 0.4829  decode.d8.loss_dice: 1.0418
11/15 16:51:19 - mmengine - INFO - Iter(train) [57400/90000]  base_lr: 4.0094e-05 lr: 4.0094e-06  eta: 5:27:31  time: 0.5963  data_time: 0.0104  memory: 10713  grad_norm: 370.2112  loss: 16.7626  decode.loss_cls: 0.0547  decode.loss_mask: 0.4898  decode.loss_dice: 1.1005  decode.d0.loss_cls: 0.1043  decode.d0.loss_mask: 0.5161  decode.d0.loss_dice: 1.1617  decode.d1.loss_cls: 0.0723  decode.d1.loss_mask: 0.4971  decode.d1.loss_dice: 1.1387  decode.d2.loss_cls: 0.0574  decode.d2.loss_mask: 0.5021  decode.d2.loss_dice: 1.1143  decode.d3.loss_cls: 0.0493  decode.d3.loss_mask: 0.4991  decode.d3.loss_dice: 1.1202  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.5108  decode.d4.loss_dice: 1.1042  decode.d5.loss_cls: 0.0574  decode.d5.loss_mask: 0.5036  decode.d5.loss_dice: 1.0994  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.4888  decode.d6.loss_dice: 1.0895  decode.d7.loss_cls: 0.0607  decode.d7.loss_mask: 0.4985  decode.d7.loss_dice: 1.1030  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 0.4854  decode.d8.loss_dice: 1.1021
11/15 16:51:49 - mmengine - INFO - Iter(train) [57450/90000]  base_lr: 4.0039e-05 lr: 4.0039e-06  eta: 5:27:01  time: 0.5954  data_time: 0.0105  memory: 10713  grad_norm: 770.9516  loss: 18.1440  decode.loss_cls: 0.0624  decode.loss_mask: 0.5906  decode.loss_dice: 1.1158  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.6344  decode.d0.loss_dice: 1.2199  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.5947  decode.d1.loss_dice: 1.1554  decode.d2.loss_cls: 0.0661  decode.d2.loss_mask: 0.6066  decode.d2.loss_dice: 1.1485  decode.d3.loss_cls: 0.0651  decode.d3.loss_mask: 0.6091  decode.d3.loss_dice: 1.1597  decode.d4.loss_cls: 0.0636  decode.d4.loss_mask: 0.6044  decode.d4.loss_dice: 1.1288  decode.d5.loss_cls: 0.0658  decode.d5.loss_mask: 0.5956  decode.d5.loss_dice: 1.1392  decode.d6.loss_cls: 0.0608  decode.d6.loss_mask: 0.6007  decode.d6.loss_dice: 1.1187  decode.d7.loss_cls: 0.0581  decode.d7.loss_mask: 0.5908  decode.d7.loss_dice: 1.1543  decode.d8.loss_cls: 0.0672  decode.d8.loss_mask: 0.5851  decode.d8.loss_dice: 1.1359
11/15 16:52:19 - mmengine - INFO - Iter(train) [57500/90000]  base_lr: 3.9984e-05 lr: 3.9984e-06  eta: 5:26:30  time: 0.5943  data_time: 0.0103  memory: 10692  grad_norm: 252.6752  loss: 16.1135  decode.loss_cls: 0.0720  decode.loss_mask: 0.5120  decode.loss_dice: 0.9977  decode.d0.loss_cls: 0.0790  decode.d0.loss_mask: 0.5333  decode.d0.loss_dice: 1.0941  decode.d1.loss_cls: 0.0617  decode.d1.loss_mask: 0.5278  decode.d1.loss_dice: 1.0624  decode.d2.loss_cls: 0.0580  decode.d2.loss_mask: 0.5327  decode.d2.loss_dice: 1.0458  decode.d3.loss_cls: 0.0626  decode.d3.loss_mask: 0.5220  decode.d3.loss_dice: 1.0151  decode.d4.loss_cls: 0.0482  decode.d4.loss_mask: 0.5199  decode.d4.loss_dice: 1.0130  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.5117  decode.d5.loss_dice: 1.0233  decode.d6.loss_cls: 0.0604  decode.d6.loss_mask: 0.5178  decode.d6.loss_dice: 0.9996  decode.d7.loss_cls: 0.0587  decode.d7.loss_mask: 0.5187  decode.d7.loss_dice: 1.0336  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.5140  decode.d8.loss_dice: 1.0019
11/15 16:52:49 - mmengine - INFO - Iter(train) [57550/90000]  base_lr: 3.9928e-05 lr: 3.9928e-06  eta: 5:26:00  time: 0.5964  data_time: 0.0106  memory: 10656  grad_norm: 366.6999  loss: 17.6190  decode.loss_cls: 0.0672  decode.loss_mask: 0.4888  decode.loss_dice: 1.1889  decode.d0.loss_cls: 0.0757  decode.d0.loss_mask: 0.4957  decode.d0.loss_dice: 1.2843  decode.d1.loss_cls: 0.0728  decode.d1.loss_mask: 0.4905  decode.d1.loss_dice: 1.2398  decode.d2.loss_cls: 0.0715  decode.d2.loss_mask: 0.4930  decode.d2.loss_dice: 1.2266  decode.d3.loss_cls: 0.0894  decode.d3.loss_mask: 0.4873  decode.d3.loss_dice: 1.2311  decode.d4.loss_cls: 0.0741  decode.d4.loss_mask: 0.4821  decode.d4.loss_dice: 1.2034  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 0.4801  decode.d5.loss_dice: 1.1608  decode.d6.loss_cls: 0.0697  decode.d6.loss_mask: 0.4817  decode.d6.loss_dice: 1.1439  decode.d7.loss_cls: 0.0737  decode.d7.loss_mask: 0.4838  decode.d7.loss_dice: 1.1703  decode.d8.loss_cls: 0.0740  decode.d8.loss_mask: 0.4844  decode.d8.loss_dice: 1.1662
11/15 16:53:19 - mmengine - INFO - Iter(train) [57600/90000]  base_lr: 3.9873e-05 lr: 3.9873e-06  eta: 5:25:30  time: 0.5952  data_time: 0.0105  memory: 10675  grad_norm: 752.2959  loss: 16.1449  decode.loss_cls: 0.0654  decode.loss_mask: 0.5074  decode.loss_dice: 1.0361  decode.d0.loss_cls: 0.1143  decode.d0.loss_mask: 0.5307  decode.d0.loss_dice: 1.0837  decode.d1.loss_cls: 0.0872  decode.d1.loss_mask: 0.5007  decode.d1.loss_dice: 1.0480  decode.d2.loss_cls: 0.0760  decode.d2.loss_mask: 0.5029  decode.d2.loss_dice: 1.0179  decode.d3.loss_cls: 0.0771  decode.d3.loss_mask: 0.4939  decode.d3.loss_dice: 1.0169  decode.d4.loss_cls: 0.0762  decode.d4.loss_mask: 0.4963  decode.d4.loss_dice: 0.9962  decode.d5.loss_cls: 0.0735  decode.d5.loss_mask: 0.5082  decode.d5.loss_dice: 1.0389  decode.d6.loss_cls: 0.0662  decode.d6.loss_mask: 0.5160  decode.d6.loss_dice: 1.0401  decode.d7.loss_cls: 0.0600  decode.d7.loss_mask: 0.5120  decode.d7.loss_dice: 1.0121  decode.d8.loss_cls: 0.0641  decode.d8.loss_mask: 0.5068  decode.d8.loss_dice: 1.0202
11/15 16:53:49 - mmengine - INFO - Iter(train) [57650/90000]  base_lr: 3.9817e-05 lr: 3.9817e-06  eta: 5:24:59  time: 0.5962  data_time: 0.0104  memory: 10692  grad_norm: 245.4741  loss: 15.8405  decode.loss_cls: 0.0591  decode.loss_mask: 0.4276  decode.loss_dice: 1.0617  decode.d0.loss_cls: 0.0942  decode.d0.loss_mask: 0.4397  decode.d0.loss_dice: 1.1371  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.4260  decode.d1.loss_dice: 1.0899  decode.d2.loss_cls: 0.0864  decode.d2.loss_mask: 0.4217  decode.d2.loss_dice: 1.0856  decode.d3.loss_cls: 0.0657  decode.d3.loss_mask: 0.4243  decode.d3.loss_dice: 1.0592  decode.d4.loss_cls: 0.0638  decode.d4.loss_mask: 0.4308  decode.d4.loss_dice: 1.0940  decode.d5.loss_cls: 0.0660  decode.d5.loss_mask: 0.4245  decode.d5.loss_dice: 1.0643  decode.d6.loss_cls: 0.0714  decode.d6.loss_mask: 0.4292  decode.d6.loss_dice: 1.0735  decode.d7.loss_cls: 0.0675  decode.d7.loss_mask: 0.4300  decode.d7.loss_dice: 1.0771  decode.d8.loss_cls: 0.0583  decode.d8.loss_mask: 0.4322  decode.d8.loss_dice: 1.0973
11/15 16:54:18 - mmengine - INFO - Iter(train) [57700/90000]  base_lr: 3.9762e-05 lr: 3.9762e-06  eta: 5:24:29  time: 0.5948  data_time: 0.0104  memory: 10675  grad_norm: 364.0616  loss: 15.3169  decode.loss_cls: 0.0537  decode.loss_mask: 0.4387  decode.loss_dice: 1.0289  decode.d0.loss_cls: 0.0980  decode.d0.loss_mask: 0.4362  decode.d0.loss_dice: 1.0784  decode.d1.loss_cls: 0.0627  decode.d1.loss_mask: 0.4278  decode.d1.loss_dice: 1.0522  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.4351  decode.d2.loss_dice: 1.0628  decode.d3.loss_cls: 0.0473  decode.d3.loss_mask: 0.4344  decode.d3.loss_dice: 1.0302  decode.d4.loss_cls: 0.0535  decode.d4.loss_mask: 0.4362  decode.d4.loss_dice: 1.0237  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.4393  decode.d5.loss_dice: 1.0252  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.4344  decode.d6.loss_dice: 1.0312  decode.d7.loss_cls: 0.0521  decode.d7.loss_mask: 0.4364  decode.d7.loss_dice: 1.0319  decode.d8.loss_cls: 0.0523  decode.d8.loss_mask: 0.4379  decode.d8.loss_dice: 1.0164
11/15 16:54:48 - mmengine - INFO - Iter(train) [57750/90000]  base_lr: 3.9707e-05 lr: 3.9707e-06  eta: 5:23:59  time: 0.5949  data_time: 0.0106  memory: 10692  grad_norm: 291.7306  loss: 15.9003  decode.loss_cls: 0.0522  decode.loss_mask: 0.5149  decode.loss_dice: 1.0482  decode.d0.loss_cls: 0.0755  decode.d0.loss_mask: 0.5509  decode.d0.loss_dice: 1.0699  decode.d1.loss_cls: 0.0481  decode.d1.loss_mask: 0.5068  decode.d1.loss_dice: 1.0261  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.5097  decode.d2.loss_dice: 1.0099  decode.d3.loss_cls: 0.0516  decode.d3.loss_mask: 0.5112  decode.d3.loss_dice: 1.0138  decode.d4.loss_cls: 0.0509  decode.d4.loss_mask: 0.5091  decode.d4.loss_dice: 1.0252  decode.d5.loss_cls: 0.0500  decode.d5.loss_mask: 0.5047  decode.d5.loss_dice: 1.0116  decode.d6.loss_cls: 0.0537  decode.d6.loss_mask: 0.5114  decode.d6.loss_dice: 1.0056  decode.d7.loss_cls: 0.0575  decode.d7.loss_mask: 0.5137  decode.d7.loss_dice: 0.9940  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.5113  decode.d8.loss_dice: 0.9967
11/15 16:55:18 - mmengine - INFO - Iter(train) [57800/90000]  base_lr: 3.9651e-05 lr: 3.9651e-06  eta: 5:23:28  time: 0.5949  data_time: 0.0105  memory: 10675  grad_norm: 606.7563  loss: 15.1590  decode.loss_cls: 0.0437  decode.loss_mask: 0.4709  decode.loss_dice: 0.9976  decode.d0.loss_cls: 0.1001  decode.d0.loss_mask: 0.4602  decode.d0.loss_dice: 1.0486  decode.d1.loss_cls: 0.0707  decode.d1.loss_mask: 0.4397  decode.d1.loss_dice: 0.9921  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.4450  decode.d2.loss_dice: 0.9810  decode.d3.loss_cls: 0.0402  decode.d3.loss_mask: 0.4763  decode.d3.loss_dice: 1.0071  decode.d4.loss_cls: 0.0453  decode.d4.loss_mask: 0.4683  decode.d4.loss_dice: 1.0013  decode.d5.loss_cls: 0.0423  decode.d5.loss_mask: 0.4733  decode.d5.loss_dice: 0.9774  decode.d6.loss_cls: 0.0483  decode.d6.loss_mask: 0.4692  decode.d6.loss_dice: 0.9656  decode.d7.loss_cls: 0.0446  decode.d7.loss_mask: 0.4698  decode.d7.loss_dice: 1.0097  decode.d8.loss_cls: 0.0420  decode.d8.loss_mask: 0.4655  decode.d8.loss_dice: 1.0033
11/15 16:55:48 - mmengine - INFO - Iter(train) [57850/90000]  base_lr: 3.9596e-05 lr: 3.9596e-06  eta: 5:22:58  time: 0.5944  data_time: 0.0105  memory: 10692  grad_norm: 602.8203  loss: 15.7907  decode.loss_cls: 0.0574  decode.loss_mask: 0.4887  decode.loss_dice: 1.0073  decode.d0.loss_cls: 0.0916  decode.d0.loss_mask: 0.5124  decode.d0.loss_dice: 1.0750  decode.d1.loss_cls: 0.0666  decode.d1.loss_mask: 0.4995  decode.d1.loss_dice: 1.0462  decode.d2.loss_cls: 0.0583  decode.d2.loss_mask: 0.4922  decode.d2.loss_dice: 1.0283  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.4883  decode.d3.loss_dice: 1.0264  decode.d4.loss_cls: 0.0550  decode.d4.loss_mask: 0.4914  decode.d4.loss_dice: 1.0597  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.4889  decode.d5.loss_dice: 1.0180  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.4887  decode.d6.loss_dice: 0.9765  decode.d7.loss_cls: 0.0578  decode.d7.loss_mask: 0.4954  decode.d7.loss_dice: 0.9987  decode.d8.loss_cls: 0.0611  decode.d8.loss_mask: 0.4939  decode.d8.loss_dice: 0.9977
11/15 16:56:17 - mmengine - INFO - Iter(train) [57900/90000]  base_lr: 3.9540e-05 lr: 3.9540e-06  eta: 5:22:28  time: 0.5946  data_time: 0.0102  memory: 10728  grad_norm: 753.9831  loss: 14.7548  decode.loss_cls: 0.0294  decode.loss_mask: 0.5301  decode.loss_dice: 0.9183  decode.d0.loss_cls: 0.0758  decode.d0.loss_mask: 0.5185  decode.d0.loss_dice: 0.9214  decode.d1.loss_cls: 0.0365  decode.d1.loss_mask: 0.5232  decode.d1.loss_dice: 0.9213  decode.d2.loss_cls: 0.0265  decode.d2.loss_mask: 0.5337  decode.d2.loss_dice: 0.9453  decode.d3.loss_cls: 0.0359  decode.d3.loss_mask: 0.5170  decode.d3.loss_dice: 0.8897  decode.d4.loss_cls: 0.0350  decode.d4.loss_mask: 0.5284  decode.d4.loss_dice: 0.8980  decode.d5.loss_cls: 0.0323  decode.d5.loss_mask: 0.5248  decode.d5.loss_dice: 0.9141  decode.d6.loss_cls: 0.0362  decode.d6.loss_mask: 0.5307  decode.d6.loss_dice: 0.9060  decode.d7.loss_cls: 0.0345  decode.d7.loss_mask: 0.5273  decode.d7.loss_dice: 0.8991  decode.d8.loss_cls: 0.0308  decode.d8.loss_mask: 0.5265  decode.d8.loss_dice: 0.9084
11/15 16:56:47 - mmengine - INFO - Iter(train) [57950/90000]  base_lr: 3.9485e-05 lr: 3.9485e-06  eta: 5:21:57  time: 0.5963  data_time: 0.0107  memory: 10692  grad_norm: 418.0681  loss: 16.7842  decode.loss_cls: 0.0716  decode.loss_mask: 0.4990  decode.loss_dice: 1.0585  decode.d0.loss_cls: 0.0902  decode.d0.loss_mask: 0.5686  decode.d0.loss_dice: 1.1456  decode.d1.loss_cls: 0.0998  decode.d1.loss_mask: 0.5106  decode.d1.loss_dice: 1.0970  decode.d2.loss_cls: 0.0947  decode.d2.loss_mask: 0.4877  decode.d2.loss_dice: 1.0626  decode.d3.loss_cls: 0.0750  decode.d3.loss_mask: 0.4981  decode.d3.loss_dice: 1.0814  decode.d4.loss_cls: 0.0686  decode.d4.loss_mask: 0.5116  decode.d4.loss_dice: 1.0801  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 0.5187  decode.d5.loss_dice: 1.0906  decode.d6.loss_cls: 0.0686  decode.d6.loss_mask: 0.5111  decode.d6.loss_dice: 1.0703  decode.d7.loss_cls: 0.0679  decode.d7.loss_mask: 0.5166  decode.d7.loss_dice: 1.0861  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 0.5273  decode.d8.loss_dice: 1.0855
11/15 16:57:17 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 16:57:17 - mmengine - INFO - Iter(train) [58000/90000]  base_lr: 3.9429e-05 lr: 3.9429e-06  eta: 5:21:27  time: 0.5943  data_time: 0.0104  memory: 10692  grad_norm: 679.8262  loss: 15.6454  decode.loss_cls: 0.0567  decode.loss_mask: 0.5205  decode.loss_dice: 0.9730  decode.d0.loss_cls: 0.1001  decode.d0.loss_mask: 0.5209  decode.d0.loss_dice: 1.0761  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.5139  decode.d1.loss_dice: 1.0007  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.5253  decode.d2.loss_dice: 1.0140  decode.d3.loss_cls: 0.0544  decode.d3.loss_mask: 0.5205  decode.d3.loss_dice: 0.9619  decode.d4.loss_cls: 0.0596  decode.d4.loss_mask: 0.5180  decode.d4.loss_dice: 0.9617  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 0.5206  decode.d5.loss_dice: 0.9838  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.5222  decode.d6.loss_dice: 0.9581  decode.d7.loss_cls: 0.0581  decode.d7.loss_mask: 0.5240  decode.d7.loss_dice: 0.9489  decode.d8.loss_cls: 0.0624  decode.d8.loss_mask: 0.5196  decode.d8.loss_dice: 0.9296
11/15 16:57:47 - mmengine - INFO - Iter(train) [58050/90000]  base_lr: 3.9374e-05 lr: 3.9374e-06  eta: 5:20:57  time: 0.5961  data_time: 0.0108  memory: 10656  grad_norm: 268.5671  loss: 16.2288  decode.loss_cls: 0.0745  decode.loss_mask: 0.4897  decode.loss_dice: 1.0340  decode.d0.loss_cls: 0.0836  decode.d0.loss_mask: 0.5190  decode.d0.loss_dice: 1.1430  decode.d1.loss_cls: 0.0814  decode.d1.loss_mask: 0.4939  decode.d1.loss_dice: 1.0847  decode.d2.loss_cls: 0.0773  decode.d2.loss_mask: 0.4960  decode.d2.loss_dice: 1.0341  decode.d3.loss_cls: 0.0765  decode.d3.loss_mask: 0.4957  decode.d3.loss_dice: 1.0316  decode.d4.loss_cls: 0.0800  decode.d4.loss_mask: 0.4926  decode.d4.loss_dice: 1.0390  decode.d5.loss_cls: 0.0722  decode.d5.loss_mask: 0.4942  decode.d5.loss_dice: 1.0245  decode.d6.loss_cls: 0.0753  decode.d6.loss_mask: 0.4904  decode.d6.loss_dice: 1.0211  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.4896  decode.d7.loss_dice: 1.0391  decode.d8.loss_cls: 0.0753  decode.d8.loss_mask: 0.4895  decode.d8.loss_dice: 1.0643
11/15 16:58:17 - mmengine - INFO - Iter(train) [58100/90000]  base_lr: 3.9319e-05 lr: 3.9319e-06  eta: 5:20:26  time: 0.5949  data_time: 0.0105  memory: 10713  grad_norm: 370.7394  loss: 15.8729  decode.loss_cls: 0.0501  decode.loss_mask: 0.4886  decode.loss_dice: 1.0464  decode.d0.loss_cls: 0.0851  decode.d0.loss_mask: 0.5085  decode.d0.loss_dice: 1.1220  decode.d1.loss_cls: 0.0507  decode.d1.loss_mask: 0.4847  decode.d1.loss_dice: 1.0750  decode.d2.loss_cls: 0.0451  decode.d2.loss_mask: 0.4853  decode.d2.loss_dice: 1.0643  decode.d3.loss_cls: 0.0582  decode.d3.loss_mask: 0.4829  decode.d3.loss_dice: 1.0090  decode.d4.loss_cls: 0.0433  decode.d4.loss_mask: 0.4822  decode.d4.loss_dice: 1.0353  decode.d5.loss_cls: 0.0534  decode.d5.loss_mask: 0.4865  decode.d5.loss_dice: 1.0124  decode.d6.loss_cls: 0.0449  decode.d6.loss_mask: 0.4842  decode.d6.loss_dice: 1.0242  decode.d7.loss_cls: 0.0409  decode.d7.loss_mask: 0.4869  decode.d7.loss_dice: 1.0679  decode.d8.loss_cls: 0.0470  decode.d8.loss_mask: 0.4806  decode.d8.loss_dice: 1.0273
11/15 16:58:46 - mmengine - INFO - Iter(train) [58150/90000]  base_lr: 3.9263e-05 lr: 3.9263e-06  eta: 5:19:56  time: 0.5959  data_time: 0.0104  memory: 10692  grad_norm: 515.9434  loss: 16.3205  decode.loss_cls: 0.0588  decode.loss_mask: 0.5435  decode.loss_dice: 1.0091  decode.d0.loss_cls: 0.0779  decode.d0.loss_mask: 0.5659  decode.d0.loss_dice: 1.0964  decode.d1.loss_cls: 0.0706  decode.d1.loss_mask: 0.5387  decode.d1.loss_dice: 1.0407  decode.d2.loss_cls: 0.0537  decode.d2.loss_mask: 0.5462  decode.d2.loss_dice: 1.0330  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.5417  decode.d3.loss_dice: 1.0172  decode.d4.loss_cls: 0.0531  decode.d4.loss_mask: 0.5427  decode.d4.loss_dice: 1.0076  decode.d5.loss_cls: 0.0692  decode.d5.loss_mask: 0.5409  decode.d5.loss_dice: 1.0207  decode.d6.loss_cls: 0.0503  decode.d6.loss_mask: 0.5411  decode.d6.loss_dice: 1.0100  decode.d7.loss_cls: 0.0580  decode.d7.loss_mask: 0.5399  decode.d7.loss_dice: 1.0054  decode.d8.loss_cls: 0.0596  decode.d8.loss_mask: 0.5453  decode.d8.loss_dice: 1.0254
11/15 16:59:16 - mmengine - INFO - Iter(train) [58200/90000]  base_lr: 3.9208e-05 lr: 3.9208e-06  eta: 5:19:26  time: 0.5955  data_time: 0.0104  memory: 10692  grad_norm: 353.3846  loss: 18.5802  decode.loss_cls: 0.0867  decode.loss_mask: 0.5902  decode.loss_dice: 1.1899  decode.d0.loss_cls: 0.0943  decode.d0.loss_mask: 0.6150  decode.d0.loss_dice: 1.3215  decode.d1.loss_cls: 0.0729  decode.d1.loss_mask: 0.5848  decode.d1.loss_dice: 1.2229  decode.d2.loss_cls: 0.0826  decode.d2.loss_mask: 0.5455  decode.d2.loss_dice: 1.1579  decode.d3.loss_cls: 0.0774  decode.d3.loss_mask: 0.5440  decode.d3.loss_dice: 1.2053  decode.d4.loss_cls: 0.0802  decode.d4.loss_mask: 0.5835  decode.d4.loss_dice: 1.2054  decode.d5.loss_cls: 0.0816  decode.d5.loss_mask: 0.5878  decode.d5.loss_dice: 1.1869  decode.d6.loss_cls: 0.0999  decode.d6.loss_mask: 0.5440  decode.d6.loss_dice: 1.1566  decode.d7.loss_cls: 0.0922  decode.d7.loss_mask: 0.5908  decode.d7.loss_dice: 1.1640  decode.d8.loss_cls: 0.0820  decode.d8.loss_mask: 0.5877  decode.d8.loss_dice: 1.1466
11/15 16:59:46 - mmengine - INFO - Iter(train) [58250/90000]  base_lr: 3.9152e-05 lr: 3.9152e-06  eta: 5:18:55  time: 0.5945  data_time: 0.0103  memory: 10641  grad_norm: 243.1143  loss: 15.2563  decode.loss_cls: 0.0567  decode.loss_mask: 0.4777  decode.loss_dice: 0.9786  decode.d0.loss_cls: 0.0819  decode.d0.loss_mask: 0.5144  decode.d0.loss_dice: 1.0465  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.4771  decode.d1.loss_dice: 0.9983  decode.d2.loss_cls: 0.0727  decode.d2.loss_mask: 0.4709  decode.d2.loss_dice: 0.9733  decode.d3.loss_cls: 0.0597  decode.d3.loss_mask: 0.4715  decode.d3.loss_dice: 0.9687  decode.d4.loss_cls: 0.0740  decode.d4.loss_mask: 0.4666  decode.d4.loss_dice: 0.9637  decode.d5.loss_cls: 0.0687  decode.d5.loss_mask: 0.4697  decode.d5.loss_dice: 0.9869  decode.d6.loss_cls: 0.0600  decode.d6.loss_mask: 0.4715  decode.d6.loss_dice: 0.9624  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.4733  decode.d7.loss_dice: 0.9668  decode.d8.loss_cls: 0.0545  decode.d8.loss_mask: 0.4802  decode.d8.loss_dice: 0.9865
11/15 17:00:16 - mmengine - INFO - Iter(train) [58300/90000]  base_lr: 3.9097e-05 lr: 3.9097e-06  eta: 5:18:25  time: 0.5951  data_time: 0.0104  memory: 10641  grad_norm: 361.2030  loss: 19.4399  decode.loss_cls: 0.0563  decode.loss_mask: 0.6137  decode.loss_dice: 1.2342  decode.d0.loss_cls: 0.1001  decode.d0.loss_mask: 0.6657  decode.d0.loss_dice: 1.3534  decode.d1.loss_cls: 0.0861  decode.d1.loss_mask: 0.6081  decode.d1.loss_dice: 1.3128  decode.d2.loss_cls: 0.0633  decode.d2.loss_mask: 0.6109  decode.d2.loss_dice: 1.2849  decode.d3.loss_cls: 0.0745  decode.d3.loss_mask: 0.6158  decode.d3.loss_dice: 1.2192  decode.d4.loss_cls: 0.0574  decode.d4.loss_mask: 0.6035  decode.d4.loss_dice: 1.2542  decode.d5.loss_cls: 0.0642  decode.d5.loss_mask: 0.6034  decode.d5.loss_dice: 1.2366  decode.d6.loss_cls: 0.0810  decode.d6.loss_mask: 0.6001  decode.d6.loss_dice: 1.2631  decode.d7.loss_cls: 0.0719  decode.d7.loss_mask: 0.6043  decode.d7.loss_dice: 1.2162  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 0.6061  decode.d8.loss_dice: 1.2092
11/15 17:00:45 - mmengine - INFO - Iter(train) [58350/90000]  base_lr: 3.9041e-05 lr: 3.9041e-06  eta: 5:17:55  time: 0.5972  data_time: 0.0107  memory: 10675  grad_norm: 538.2135  loss: 15.6947  decode.loss_cls: 0.0534  decode.loss_mask: 0.4970  decode.loss_dice: 1.0254  decode.d0.loss_cls: 0.0687  decode.d0.loss_mask: 0.5348  decode.d0.loss_dice: 1.0574  decode.d1.loss_cls: 0.0776  decode.d1.loss_mask: 0.4958  decode.d1.loss_dice: 0.9883  decode.d2.loss_cls: 0.0610  decode.d2.loss_mask: 0.4976  decode.d2.loss_dice: 0.9875  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.4949  decode.d3.loss_dice: 0.9729  decode.d4.loss_cls: 0.0470  decode.d4.loss_mask: 0.4963  decode.d4.loss_dice: 1.0114  decode.d5.loss_cls: 0.0591  decode.d5.loss_mask: 0.4984  decode.d5.loss_dice: 1.0127  decode.d6.loss_cls: 0.0502  decode.d6.loss_mask: 0.4965  decode.d6.loss_dice: 0.9950  decode.d7.loss_cls: 0.0477  decode.d7.loss_mask: 0.4994  decode.d7.loss_dice: 1.0579  decode.d8.loss_cls: 0.0443  decode.d8.loss_mask: 0.4957  decode.d8.loss_dice: 1.0139
11/15 17:01:15 - mmengine - INFO - Iter(train) [58400/90000]  base_lr: 3.8986e-05 lr: 3.8986e-06  eta: 5:17:24  time: 0.5952  data_time: 0.0101  memory: 10692  grad_norm: 212.6080  loss: 16.3268  decode.loss_cls: 0.0505  decode.loss_mask: 0.4452  decode.loss_dice: 1.1103  decode.d0.loss_cls: 0.0658  decode.d0.loss_mask: 0.4668  decode.d0.loss_dice: 1.1885  decode.d1.loss_cls: 0.0616  decode.d1.loss_mask: 0.4488  decode.d1.loss_dice: 1.1291  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.4469  decode.d2.loss_dice: 1.1421  decode.d3.loss_cls: 0.0496  decode.d3.loss_mask: 0.4446  decode.d3.loss_dice: 1.1230  decode.d4.loss_cls: 0.0604  decode.d4.loss_mask: 0.4454  decode.d4.loss_dice: 1.1145  decode.d5.loss_cls: 0.0541  decode.d5.loss_mask: 0.4483  decode.d5.loss_dice: 1.1455  decode.d6.loss_cls: 0.0517  decode.d6.loss_mask: 0.4419  decode.d6.loss_dice: 1.1120  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.4440  decode.d7.loss_dice: 1.1231  decode.d8.loss_cls: 0.0537  decode.d8.loss_mask: 0.4449  decode.d8.loss_dice: 1.1056
11/15 17:01:45 - mmengine - INFO - Iter(train) [58450/90000]  base_lr: 3.8930e-05 lr: 3.8930e-06  eta: 5:16:54  time: 0.5952  data_time: 0.0105  memory: 10742  grad_norm: 348.3935  loss: 15.0103  decode.loss_cls: 0.0744  decode.loss_mask: 0.4090  decode.loss_dice: 0.9776  decode.d0.loss_cls: 0.0845  decode.d0.loss_mask: 0.4108  decode.d0.loss_dice: 1.1412  decode.d1.loss_cls: 0.0878  decode.d1.loss_mask: 0.3945  decode.d1.loss_dice: 1.0261  decode.d2.loss_cls: 0.0718  decode.d2.loss_mask: 0.3877  decode.d2.loss_dice: 1.0243  decode.d3.loss_cls: 0.0719  decode.d3.loss_mask: 0.3942  decode.d3.loss_dice: 1.0339  decode.d4.loss_cls: 0.0634  decode.d4.loss_mask: 0.3915  decode.d4.loss_dice: 1.0465  decode.d5.loss_cls: 0.0718  decode.d5.loss_mask: 0.3965  decode.d5.loss_dice: 1.0242  decode.d6.loss_cls: 0.0669  decode.d6.loss_mask: 0.3933  decode.d6.loss_dice: 0.9994  decode.d7.loss_cls: 0.0761  decode.d7.loss_mask: 0.4054  decode.d7.loss_dice: 1.0101  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.4032  decode.d8.loss_dice: 1.0047
11/15 17:02:15 - mmengine - INFO - Iter(train) [58500/90000]  base_lr: 3.8875e-05 lr: 3.8875e-06  eta: 5:16:24  time: 0.5959  data_time: 0.0105  memory: 10692  grad_norm: 222.5754  loss: 16.7273  decode.loss_cls: 0.0766  decode.loss_mask: 0.4661  decode.loss_dice: 1.1129  decode.d0.loss_cls: 0.0868  decode.d0.loss_mask: 0.4849  decode.d0.loss_dice: 1.1756  decode.d1.loss_cls: 0.0686  decode.d1.loss_mask: 0.4829  decode.d1.loss_dice: 1.1478  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.4776  decode.d2.loss_dice: 1.1235  decode.d3.loss_cls: 0.0782  decode.d3.loss_mask: 0.4684  decode.d3.loss_dice: 1.1270  decode.d4.loss_cls: 0.0769  decode.d4.loss_mask: 0.4610  decode.d4.loss_dice: 1.1005  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.4771  decode.d5.loss_dice: 1.1408  decode.d6.loss_cls: 0.0737  decode.d6.loss_mask: 0.4645  decode.d6.loss_dice: 1.1112  decode.d7.loss_cls: 0.0747  decode.d7.loss_mask: 0.4657  decode.d7.loss_dice: 1.0924  decode.d8.loss_cls: 0.0623  decode.d8.loss_mask: 0.4792  decode.d8.loss_dice: 1.1221
11/15 17:02:45 - mmengine - INFO - Iter(train) [58550/90000]  base_lr: 3.8819e-05 lr: 3.8819e-06  eta: 5:15:53  time: 0.5951  data_time: 0.0106  memory: 10713  grad_norm: 271.4066  loss: 14.7221  decode.loss_cls: 0.0433  decode.loss_mask: 0.4738  decode.loss_dice: 0.9448  decode.d0.loss_cls: 0.0745  decode.d0.loss_mask: 0.4965  decode.d0.loss_dice: 1.0035  decode.d1.loss_cls: 0.0479  decode.d1.loss_mask: 0.4796  decode.d1.loss_dice: 0.9924  decode.d2.loss_cls: 0.0525  decode.d2.loss_mask: 0.4688  decode.d2.loss_dice: 0.9460  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.4751  decode.d3.loss_dice: 0.9372  decode.d4.loss_cls: 0.0477  decode.d4.loss_mask: 0.4720  decode.d4.loss_dice: 0.9368  decode.d5.loss_cls: 0.0517  decode.d5.loss_mask: 0.4717  decode.d5.loss_dice: 0.9290  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.4677  decode.d6.loss_dice: 0.9140  decode.d7.loss_cls: 0.0366  decode.d7.loss_mask: 0.4695  decode.d7.loss_dice: 0.9480  decode.d8.loss_cls: 0.0425  decode.d8.loss_mask: 0.4734  decode.d8.loss_dice: 0.9281
11/15 17:03:14 - mmengine - INFO - Iter(train) [58600/90000]  base_lr: 3.8763e-05 lr: 3.8763e-06  eta: 5:15:23  time: 0.5949  data_time: 0.0104  memory: 10692  grad_norm: 244.0652  loss: 15.3702  decode.loss_cls: 0.0679  decode.loss_mask: 0.4076  decode.loss_dice: 1.0476  decode.d0.loss_cls: 0.0933  decode.d0.loss_mask: 0.4277  decode.d0.loss_dice: 1.1396  decode.d1.loss_cls: 0.0836  decode.d1.loss_mask: 0.4151  decode.d1.loss_dice: 1.0832  decode.d2.loss_cls: 0.0896  decode.d2.loss_mask: 0.4100  decode.d2.loss_dice: 1.0359  decode.d3.loss_cls: 0.0740  decode.d3.loss_mask: 0.4130  decode.d3.loss_dice: 1.0227  decode.d4.loss_cls: 0.0866  decode.d4.loss_mask: 0.4115  decode.d4.loss_dice: 1.0286  decode.d5.loss_cls: 0.0733  decode.d5.loss_mask: 0.4102  decode.d5.loss_dice: 1.0173  decode.d6.loss_cls: 0.0749  decode.d6.loss_mask: 0.4162  decode.d6.loss_dice: 1.0104  decode.d7.loss_cls: 0.0747  decode.d7.loss_mask: 0.4090  decode.d7.loss_dice: 1.0275  decode.d8.loss_cls: 0.0710  decode.d8.loss_mask: 0.4098  decode.d8.loss_dice: 1.0385
11/15 17:03:45 - mmengine - INFO - Iter(train) [58650/90000]  base_lr: 3.8708e-05 lr: 3.8708e-06  eta: 5:14:53  time: 0.5954  data_time: 0.0106  memory: 10675  grad_norm: 756.2354  loss: 16.2513  decode.loss_cls: 0.0586  decode.loss_mask: 0.5192  decode.loss_dice: 1.0350  decode.d0.loss_cls: 0.0813  decode.d0.loss_mask: 0.5132  decode.d0.loss_dice: 1.1096  decode.d1.loss_cls: 0.0686  decode.d1.loss_mask: 0.5359  decode.d1.loss_dice: 1.0686  decode.d2.loss_cls: 0.0596  decode.d2.loss_mask: 0.5152  decode.d2.loss_dice: 1.0483  decode.d3.loss_cls: 0.0534  decode.d3.loss_mask: 0.5152  decode.d3.loss_dice: 1.0538  decode.d4.loss_cls: 0.0585  decode.d4.loss_mask: 0.5171  decode.d4.loss_dice: 1.0290  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.5190  decode.d5.loss_dice: 1.0155  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.5202  decode.d6.loss_dice: 1.0343  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.5247  decode.d7.loss_dice: 1.0274  decode.d8.loss_cls: 0.0638  decode.d8.loss_mask: 0.5138  decode.d8.loss_dice: 1.0229
11/15 17:04:14 - mmengine - INFO - Iter(train) [58700/90000]  base_lr: 3.8652e-05 lr: 3.8652e-06  eta: 5:14:23  time: 0.5944  data_time: 0.0105  memory: 10692  grad_norm: 326.0722  loss: 16.7260  decode.loss_cls: 0.0570  decode.loss_mask: 0.5468  decode.loss_dice: 1.0616  decode.d0.loss_cls: 0.0838  decode.d0.loss_mask: 0.5705  decode.d0.loss_dice: 1.1647  decode.d1.loss_cls: 0.0620  decode.d1.loss_mask: 0.5588  decode.d1.loss_dice: 1.0803  decode.d2.loss_cls: 0.0573  decode.d2.loss_mask: 0.5436  decode.d2.loss_dice: 1.0697  decode.d3.loss_cls: 0.0542  decode.d3.loss_mask: 0.5464  decode.d3.loss_dice: 1.0646  decode.d4.loss_cls: 0.0584  decode.d4.loss_mask: 0.5375  decode.d4.loss_dice: 1.0442  decode.d5.loss_cls: 0.0627  decode.d5.loss_mask: 0.5339  decode.d5.loss_dice: 1.0248  decode.d6.loss_cls: 0.0611  decode.d6.loss_mask: 0.5427  decode.d6.loss_dice: 1.0420  decode.d7.loss_cls: 0.0619  decode.d7.loss_mask: 0.5422  decode.d7.loss_dice: 1.0255  decode.d8.loss_cls: 0.0503  decode.d8.loss_mask: 0.5443  decode.d8.loss_dice: 1.0734
11/15 17:04:44 - mmengine - INFO - Iter(train) [58750/90000]  base_lr: 3.8597e-05 lr: 3.8597e-06  eta: 5:13:52  time: 0.5959  data_time: 0.0105  memory: 10675  grad_norm: 931.2115  loss: 16.4469  decode.loss_cls: 0.0804  decode.loss_mask: 0.4814  decode.loss_dice: 1.0462  decode.d0.loss_cls: 0.0800  decode.d0.loss_mask: 0.4994  decode.d0.loss_dice: 1.1969  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 0.4835  decode.d1.loss_dice: 1.1062  decode.d2.loss_cls: 0.0701  decode.d2.loss_mask: 0.4804  decode.d2.loss_dice: 1.0622  decode.d3.loss_cls: 0.0734  decode.d3.loss_mask: 0.4788  decode.d3.loss_dice: 1.0732  decode.d4.loss_cls: 0.0693  decode.d4.loss_mask: 0.4761  decode.d4.loss_dice: 1.0847  decode.d5.loss_cls: 0.0586  decode.d5.loss_mask: 0.4755  decode.d5.loss_dice: 1.0580  decode.d6.loss_cls: 0.0723  decode.d6.loss_mask: 0.4771  decode.d6.loss_dice: 1.0865  decode.d7.loss_cls: 0.0732  decode.d7.loss_mask: 0.4779  decode.d7.loss_dice: 1.0560  decode.d8.loss_cls: 0.0703  decode.d8.loss_mask: 0.4884  decode.d8.loss_dice: 1.1508
11/15 17:05:14 - mmengine - INFO - Iter(train) [58800/90000]  base_lr: 3.8541e-05 lr: 3.8541e-06  eta: 5:13:22  time: 0.5962  data_time: 0.0105  memory: 10675  grad_norm: 363.8141  loss: 17.2357  decode.loss_cls: 0.0631  decode.loss_mask: 0.5505  decode.loss_dice: 1.1028  decode.d0.loss_cls: 0.0764  decode.d0.loss_mask: 0.5993  decode.d0.loss_dice: 1.1476  decode.d1.loss_cls: 0.0678  decode.d1.loss_mask: 0.5637  decode.d1.loss_dice: 1.1041  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 0.5630  decode.d2.loss_dice: 1.0856  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.5470  decode.d3.loss_dice: 1.0836  decode.d4.loss_cls: 0.0571  decode.d4.loss_mask: 0.5465  decode.d4.loss_dice: 1.0969  decode.d5.loss_cls: 0.0519  decode.d5.loss_mask: 0.5577  decode.d5.loss_dice: 1.1058  decode.d6.loss_cls: 0.0642  decode.d6.loss_mask: 0.5555  decode.d6.loss_dice: 1.0714  decode.d7.loss_cls: 0.0683  decode.d7.loss_mask: 0.5554  decode.d7.loss_dice: 1.0861  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.5645  decode.d8.loss_dice: 1.1107
11/15 17:05:44 - mmengine - INFO - Iter(train) [58850/90000]  base_lr: 3.8486e-05 lr: 3.8486e-06  eta: 5:12:52  time: 0.5954  data_time: 0.0105  memory: 10713  grad_norm: 404.0083  loss: 16.7610  decode.loss_cls: 0.0516  decode.loss_mask: 0.5391  decode.loss_dice: 1.0737  decode.d0.loss_cls: 0.0812  decode.d0.loss_mask: 0.5690  decode.d0.loss_dice: 1.1447  decode.d1.loss_cls: 0.0810  decode.d1.loss_mask: 0.5503  decode.d1.loss_dice: 1.0679  decode.d2.loss_cls: 0.0616  decode.d2.loss_mask: 0.5492  decode.d2.loss_dice: 1.0566  decode.d3.loss_cls: 0.0752  decode.d3.loss_mask: 0.5442  decode.d3.loss_dice: 1.0435  decode.d4.loss_cls: 0.0631  decode.d4.loss_mask: 0.5459  decode.d4.loss_dice: 1.0639  decode.d5.loss_cls: 0.0715  decode.d5.loss_mask: 0.5449  decode.d5.loss_dice: 1.0364  decode.d6.loss_cls: 0.0727  decode.d6.loss_mask: 0.5365  decode.d6.loss_dice: 1.0314  decode.d7.loss_cls: 0.0576  decode.d7.loss_mask: 0.5424  decode.d7.loss_dice: 1.0474  decode.d8.loss_cls: 0.0621  decode.d8.loss_mask: 0.5403  decode.d8.loss_dice: 1.0560
11/15 17:06:13 - mmengine - INFO - Iter(train) [58900/90000]  base_lr: 3.8430e-05 lr: 3.8430e-06  eta: 5:12:21  time: 0.5948  data_time: 0.0103  memory: 10675  grad_norm: 439.8028  loss: 16.8481  decode.loss_cls: 0.0526  decode.loss_mask: 0.5491  decode.loss_dice: 1.0515  decode.d0.loss_cls: 0.0798  decode.d0.loss_mask: 0.6047  decode.d0.loss_dice: 1.1526  decode.d1.loss_cls: 0.0685  decode.d1.loss_mask: 0.5387  decode.d1.loss_dice: 1.0956  decode.d2.loss_cls: 0.0650  decode.d2.loss_mask: 0.5565  decode.d2.loss_dice: 1.0685  decode.d3.loss_cls: 0.0714  decode.d3.loss_mask: 0.5424  decode.d3.loss_dice: 1.0446  decode.d4.loss_cls: 0.0670  decode.d4.loss_mask: 0.5416  decode.d4.loss_dice: 1.0155  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.5415  decode.d5.loss_dice: 1.0671  decode.d6.loss_cls: 0.0529  decode.d6.loss_mask: 0.5472  decode.d6.loss_dice: 1.0720  decode.d7.loss_cls: 0.0672  decode.d7.loss_mask: 0.5380  decode.d7.loss_dice: 1.0539  decode.d8.loss_cls: 0.0583  decode.d8.loss_mask: 0.5476  decode.d8.loss_dice: 1.0785
11/15 17:06:43 - mmengine - INFO - Iter(train) [58950/90000]  base_lr: 3.8374e-05 lr: 3.8374e-06  eta: 5:11:51  time: 0.5949  data_time: 0.0104  memory: 10713  grad_norm: 523.3407  loss: 16.6288  decode.loss_cls: 0.0701  decode.loss_mask: 0.5336  decode.loss_dice: 1.0828  decode.d0.loss_cls: 0.0853  decode.d0.loss_mask: 0.5201  decode.d0.loss_dice: 1.1736  decode.d1.loss_cls: 0.0826  decode.d1.loss_mask: 0.4980  decode.d1.loss_dice: 1.1137  decode.d2.loss_cls: 0.0794  decode.d2.loss_mask: 0.4938  decode.d2.loss_dice: 1.0745  decode.d3.loss_cls: 0.0735  decode.d3.loss_mask: 0.4953  decode.d3.loss_dice: 1.0581  decode.d4.loss_cls: 0.0741  decode.d4.loss_mask: 0.4946  decode.d4.loss_dice: 1.0796  decode.d5.loss_cls: 0.0740  decode.d5.loss_mask: 0.4944  decode.d5.loss_dice: 1.0618  decode.d6.loss_cls: 0.0716  decode.d6.loss_mask: 0.4963  decode.d6.loss_dice: 1.0622  decode.d7.loss_cls: 0.0712  decode.d7.loss_mask: 0.4898  decode.d7.loss_dice: 1.0710  decode.d8.loss_cls: 0.0714  decode.d8.loss_mask: 0.4947  decode.d8.loss_dice: 1.0875
11/15 17:07:13 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 17:07:13 - mmengine - INFO - Iter(train) [59000/90000]  base_lr: 3.8319e-05 lr: 3.8319e-06  eta: 5:11:21  time: 0.5951  data_time: 0.0104  memory: 10692  grad_norm: 492.0498  loss: 18.0575  decode.loss_cls: 0.0603  decode.loss_mask: 0.6354  decode.loss_dice: 1.0649  decode.d0.loss_cls: 0.0887  decode.d0.loss_mask: 0.6786  decode.d0.loss_dice: 1.1729  decode.d1.loss_cls: 0.0995  decode.d1.loss_mask: 0.6640  decode.d1.loss_dice: 1.0928  decode.d2.loss_cls: 0.0622  decode.d2.loss_mask: 0.6644  decode.d2.loss_dice: 1.0969  decode.d3.loss_cls: 0.0672  decode.d3.loss_mask: 0.6415  decode.d3.loss_dice: 1.0880  decode.d4.loss_cls: 0.0510  decode.d4.loss_mask: 0.6454  decode.d4.loss_dice: 1.1003  decode.d5.loss_cls: 0.0629  decode.d5.loss_mask: 0.6340  decode.d5.loss_dice: 1.0863  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 0.6314  decode.d6.loss_dice: 1.0658  decode.d7.loss_cls: 0.0768  decode.d7.loss_mask: 0.6362  decode.d7.loss_dice: 1.0628  decode.d8.loss_cls: 0.0664  decode.d8.loss_mask: 0.6283  decode.d8.loss_dice: 1.0680
11/15 17:07:43 - mmengine - INFO - Iter(train) [59050/90000]  base_lr: 3.8263e-05 lr: 3.8263e-06  eta: 5:10:50  time: 0.5951  data_time: 0.0104  memory: 10713  grad_norm: 636.5266  loss: 19.0568  decode.loss_cls: 0.0790  decode.loss_mask: 0.6165  decode.loss_dice: 1.1975  decode.d0.loss_cls: 0.0813  decode.d0.loss_mask: 0.6235  decode.d0.loss_dice: 1.2767  decode.d1.loss_cls: 0.0796  decode.d1.loss_mask: 0.6076  decode.d1.loss_dice: 1.2139  decode.d2.loss_cls: 0.0570  decode.d2.loss_mask: 0.6298  decode.d2.loss_dice: 1.2341  decode.d3.loss_cls: 0.0773  decode.d3.loss_mask: 0.6089  decode.d3.loss_dice: 1.1755  decode.d4.loss_cls: 0.0608  decode.d4.loss_mask: 0.6172  decode.d4.loss_dice: 1.2370  decode.d5.loss_cls: 0.0744  decode.d5.loss_mask: 0.6071  decode.d5.loss_dice: 1.1948  decode.d6.loss_cls: 0.0687  decode.d6.loss_mask: 0.6145  decode.d6.loss_dice: 1.2140  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.6216  decode.d7.loss_dice: 1.1996  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.6204  decode.d8.loss_dice: 1.2431
11/15 17:08:13 - mmengine - INFO - Iter(train) [59100/90000]  base_lr: 3.8208e-05 lr: 3.8208e-06  eta: 5:10:20  time: 0.5963  data_time: 0.0104  memory: 10713  grad_norm: 687.0475  loss: 18.0847  decode.loss_cls: 0.0797  decode.loss_mask: 0.5027  decode.loss_dice: 1.1941  decode.d0.loss_cls: 0.0861  decode.d0.loss_mask: 0.5494  decode.d0.loss_dice: 1.2738  decode.d1.loss_cls: 0.0959  decode.d1.loss_mask: 0.5137  decode.d1.loss_dice: 1.2283  decode.d2.loss_cls: 0.1062  decode.d2.loss_mask: 0.5151  decode.d2.loss_dice: 1.1956  decode.d3.loss_cls: 0.0882  decode.d3.loss_mask: 0.5052  decode.d3.loss_dice: 1.1938  decode.d4.loss_cls: 0.0888  decode.d4.loss_mask: 0.5053  decode.d4.loss_dice: 1.1776  decode.d5.loss_cls: 0.0852  decode.d5.loss_mask: 0.5120  decode.d5.loss_dice: 1.1642  decode.d6.loss_cls: 0.0798  decode.d6.loss_mask: 0.5139  decode.d6.loss_dice: 1.1966  decode.d7.loss_cls: 0.0841  decode.d7.loss_mask: 0.5189  decode.d7.loss_dice: 1.2240  decode.d8.loss_cls: 0.0914  decode.d8.loss_mask: 0.5115  decode.d8.loss_dice: 1.2038
11/15 17:08:42 - mmengine - INFO - Iter(train) [59150/90000]  base_lr: 3.8152e-05 lr: 3.8152e-06  eta: 5:09:50  time: 0.5952  data_time: 0.0104  memory: 10675  grad_norm: 538.4225  loss: 19.4163  decode.loss_cls: 0.0778  decode.loss_mask: 0.6426  decode.loss_dice: 1.2184  decode.d0.loss_cls: 0.0936  decode.d0.loss_mask: 0.6325  decode.d0.loss_dice: 1.2559  decode.d1.loss_cls: 0.0778  decode.d1.loss_mask: 0.6367  decode.d1.loss_dice: 1.2267  decode.d2.loss_cls: 0.0815  decode.d2.loss_mask: 0.6504  decode.d2.loss_dice: 1.2242  decode.d3.loss_cls: 0.0747  decode.d3.loss_mask: 0.6106  decode.d3.loss_dice: 1.1925  decode.d4.loss_cls: 0.0713  decode.d4.loss_mask: 0.6474  decode.d4.loss_dice: 1.1917  decode.d5.loss_cls: 0.0746  decode.d5.loss_mask: 0.6469  decode.d5.loss_dice: 1.2165  decode.d6.loss_cls: 0.0725  decode.d6.loss_mask: 0.7065  decode.d6.loss_dice: 1.2190  decode.d7.loss_cls: 0.0766  decode.d7.loss_mask: 0.6278  decode.d7.loss_dice: 1.2090  decode.d8.loss_cls: 0.0717  decode.d8.loss_mask: 0.6447  decode.d8.loss_dice: 1.2441
11/15 17:09:12 - mmengine - INFO - Iter(train) [59200/90000]  base_lr: 3.8096e-05 lr: 3.8096e-06  eta: 5:09:19  time: 0.5958  data_time: 0.0104  memory: 10692  grad_norm: 236.3344  loss: 15.1581  decode.loss_cls: 0.0871  decode.loss_mask: 0.4466  decode.loss_dice: 0.9366  decode.d0.loss_cls: 0.1041  decode.d0.loss_mask: 0.4723  decode.d0.loss_dice: 1.0423  decode.d1.loss_cls: 0.1069  decode.d1.loss_mask: 0.4700  decode.d1.loss_dice: 0.9853  decode.d2.loss_cls: 0.0873  decode.d2.loss_mask: 0.4569  decode.d2.loss_dice: 0.9893  decode.d3.loss_cls: 0.0823  decode.d3.loss_mask: 0.4570  decode.d3.loss_dice: 0.9505  decode.d4.loss_cls: 0.0786  decode.d4.loss_mask: 0.4449  decode.d4.loss_dice: 0.9662  decode.d5.loss_cls: 0.0769  decode.d5.loss_mask: 0.4437  decode.d5.loss_dice: 0.9589  decode.d6.loss_cls: 0.0798  decode.d6.loss_mask: 0.4534  decode.d6.loss_dice: 0.9934  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.4416  decode.d7.loss_dice: 0.9540  decode.d8.loss_cls: 0.0800  decode.d8.loss_mask: 0.4406  decode.d8.loss_dice: 0.9811
11/15 17:09:42 - mmengine - INFO - Iter(train) [59250/90000]  base_lr: 3.8041e-05 lr: 3.8041e-06  eta: 5:08:49  time: 0.5949  data_time: 0.0105  memory: 10641  grad_norm: 327.0837  loss: 16.2406  decode.loss_cls: 0.0534  decode.loss_mask: 0.4597  decode.loss_dice: 1.1116  decode.d0.loss_cls: 0.0802  decode.d0.loss_mask: 0.4822  decode.d0.loss_dice: 1.1651  decode.d1.loss_cls: 0.0660  decode.d1.loss_mask: 0.4506  decode.d1.loss_dice: 1.1221  decode.d2.loss_cls: 0.0574  decode.d2.loss_mask: 0.4591  decode.d2.loss_dice: 1.0939  decode.d3.loss_cls: 0.0587  decode.d3.loss_mask: 0.4595  decode.d3.loss_dice: 1.0901  decode.d4.loss_cls: 0.0489  decode.d4.loss_mask: 0.4711  decode.d4.loss_dice: 1.0745  decode.d5.loss_cls: 0.0592  decode.d5.loss_mask: 0.4631  decode.d5.loss_dice: 1.0880  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.4536  decode.d6.loss_dice: 1.1056  decode.d7.loss_cls: 0.0593  decode.d7.loss_mask: 0.4480  decode.d7.loss_dice: 1.0800  decode.d8.loss_cls: 0.0555  decode.d8.loss_mask: 0.4589  decode.d8.loss_dice: 1.1041
11/15 17:10:12 - mmengine - INFO - Iter(train) [59300/90000]  base_lr: 3.7985e-05 lr: 3.7985e-06  eta: 5:08:19  time: 0.5960  data_time: 0.0105  memory: 10675  grad_norm: 302.6677  loss: 15.2905  decode.loss_cls: 0.0570  decode.loss_mask: 0.5041  decode.loss_dice: 0.9628  decode.d0.loss_cls: 0.0753  decode.d0.loss_mask: 0.5348  decode.d0.loss_dice: 1.0029  decode.d1.loss_cls: 0.0639  decode.d1.loss_mask: 0.5153  decode.d1.loss_dice: 0.9677  decode.d2.loss_cls: 0.0545  decode.d2.loss_mask: 0.5086  decode.d2.loss_dice: 0.9506  decode.d3.loss_cls: 0.0500  decode.d3.loss_mask: 0.5062  decode.d3.loss_dice: 0.9465  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.5130  decode.d4.loss_dice: 0.9469  decode.d5.loss_cls: 0.0528  decode.d5.loss_mask: 0.5170  decode.d5.loss_dice: 0.9684  decode.d6.loss_cls: 0.0592  decode.d6.loss_mask: 0.5084  decode.d6.loss_dice: 0.9700  decode.d7.loss_cls: 0.0500  decode.d7.loss_mask: 0.5068  decode.d7.loss_dice: 0.9517  decode.d8.loss_cls: 0.0545  decode.d8.loss_mask: 0.5046  decode.d8.loss_dice: 0.9344
11/15 17:10:41 - mmengine - INFO - Iter(train) [59350/90000]  base_lr: 3.7929e-05 lr: 3.7929e-06  eta: 5:07:48  time: 0.5957  data_time: 0.0103  memory: 10641  grad_norm: 370.6347  loss: 15.4351  decode.loss_cls: 0.0592  decode.loss_mask: 0.4109  decode.loss_dice: 1.0720  decode.d0.loss_cls: 0.0791  decode.d0.loss_mask: 0.4070  decode.d0.loss_dice: 1.1368  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.4069  decode.d1.loss_dice: 1.0591  decode.d2.loss_cls: 0.0582  decode.d2.loss_mask: 0.3993  decode.d2.loss_dice: 1.0725  decode.d3.loss_cls: 0.0748  decode.d3.loss_mask: 0.4098  decode.d3.loss_dice: 1.0660  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.4100  decode.d4.loss_dice: 1.0537  decode.d5.loss_cls: 0.0527  decode.d5.loss_mask: 0.4104  decode.d5.loss_dice: 1.0709  decode.d6.loss_cls: 0.0685  decode.d6.loss_mask: 0.4095  decode.d6.loss_dice: 1.0571  decode.d7.loss_cls: 0.0721  decode.d7.loss_mask: 0.4109  decode.d7.loss_dice: 1.0609  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.4092  decode.d8.loss_dice: 1.0531
11/15 17:11:11 - mmengine - INFO - Iter(train) [59400/90000]  base_lr: 3.7873e-05 lr: 3.7873e-06  eta: 5:07:18  time: 0.5952  data_time: 0.0106  memory: 10692  grad_norm: 372.5979  loss: 18.0628  decode.loss_cls: 0.0744  decode.loss_mask: 0.5482  decode.loss_dice: 1.1803  decode.d0.loss_cls: 0.1069  decode.d0.loss_mask: 0.5323  decode.d0.loss_dice: 1.2221  decode.d1.loss_cls: 0.0781  decode.d1.loss_mask: 0.5540  decode.d1.loss_dice: 1.2008  decode.d2.loss_cls: 0.0682  decode.d2.loss_mask: 0.5427  decode.d2.loss_dice: 1.2015  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.5493  decode.d3.loss_dice: 1.1594  decode.d4.loss_cls: 0.0815  decode.d4.loss_mask: 0.5334  decode.d4.loss_dice: 1.1642  decode.d5.loss_cls: 0.0961  decode.d5.loss_mask: 0.5243  decode.d5.loss_dice: 1.1508  decode.d6.loss_cls: 0.0914  decode.d6.loss_mask: 0.5354  decode.d6.loss_dice: 1.1742  decode.d7.loss_cls: 0.0837  decode.d7.loss_mask: 0.5368  decode.d7.loss_dice: 1.1620  decode.d8.loss_cls: 0.0794  decode.d8.loss_mask: 0.5647  decode.d8.loss_dice: 1.1867
11/15 17:11:41 - mmengine - INFO - Iter(train) [59450/90000]  base_lr: 3.7818e-05 lr: 3.7818e-06  eta: 5:06:48  time: 0.5954  data_time: 0.0103  memory: 10728  grad_norm: 736.1388  loss: 18.4552  decode.loss_cls: 0.1032  decode.loss_mask: 0.5341  decode.loss_dice: 1.1861  decode.d0.loss_cls: 0.1120  decode.d0.loss_mask: 0.5857  decode.d0.loss_dice: 1.2951  decode.d1.loss_cls: 0.1106  decode.d1.loss_mask: 0.5440  decode.d1.loss_dice: 1.2000  decode.d2.loss_cls: 0.1084  decode.d2.loss_mask: 0.5354  decode.d2.loss_dice: 1.1971  decode.d3.loss_cls: 0.1055  decode.d3.loss_mask: 0.5315  decode.d3.loss_dice: 1.1633  decode.d4.loss_cls: 0.1058  decode.d4.loss_mask: 0.5348  decode.d4.loss_dice: 1.1949  decode.d5.loss_cls: 0.1048  decode.d5.loss_mask: 0.5385  decode.d5.loss_dice: 1.1942  decode.d6.loss_cls: 0.1041  decode.d6.loss_mask: 0.5381  decode.d6.loss_dice: 1.1975  decode.d7.loss_cls: 0.1054  decode.d7.loss_mask: 0.5335  decode.d7.loss_dice: 1.1824  decode.d8.loss_cls: 0.1005  decode.d8.loss_mask: 0.5376  decode.d8.loss_dice: 1.1710
11/15 17:12:11 - mmengine - INFO - Iter(train) [59500/90000]  base_lr: 3.7762e-05 lr: 3.7762e-06  eta: 5:06:18  time: 0.5960  data_time: 0.0105  memory: 10675  grad_norm: 318.3399  loss: 17.2534  decode.loss_cls: 0.0581  decode.loss_mask: 0.4641  decode.loss_dice: 1.2028  decode.d0.loss_cls: 0.0933  decode.d0.loss_mask: 0.4788  decode.d0.loss_dice: 1.2655  decode.d1.loss_cls: 0.0862  decode.d1.loss_mask: 0.4693  decode.d1.loss_dice: 1.1857  decode.d2.loss_cls: 0.0735  decode.d2.loss_mask: 0.4783  decode.d2.loss_dice: 1.1573  decode.d3.loss_cls: 0.0599  decode.d3.loss_mask: 0.4723  decode.d3.loss_dice: 1.1750  decode.d4.loss_cls: 0.0593  decode.d4.loss_mask: 0.4694  decode.d4.loss_dice: 1.1882  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.4756  decode.d5.loss_dice: 1.2105  decode.d6.loss_cls: 0.0513  decode.d6.loss_mask: 0.4659  decode.d6.loss_dice: 1.1744  decode.d7.loss_cls: 0.0632  decode.d7.loss_mask: 0.4575  decode.d7.loss_dice: 1.1786  decode.d8.loss_cls: 0.0504  decode.d8.loss_mask: 0.4631  decode.d8.loss_dice: 1.1722
11/15 17:12:41 - mmengine - INFO - Iter(train) [59550/90000]  base_lr: 3.7706e-05 lr: 3.7706e-06  eta: 5:05:47  time: 0.5957  data_time: 0.0103  memory: 10641  grad_norm: 354.4339  loss: 16.0023  decode.loss_cls: 0.0828  decode.loss_mask: 0.4679  decode.loss_dice: 1.0066  decode.d0.loss_cls: 0.0870  decode.d0.loss_mask: 0.5022  decode.d0.loss_dice: 1.1434  decode.d1.loss_cls: 0.0909  decode.d1.loss_mask: 0.4825  decode.d1.loss_dice: 1.0618  decode.d2.loss_cls: 0.0812  decode.d2.loss_mask: 0.4863  decode.d2.loss_dice: 1.0290  decode.d3.loss_cls: 0.0753  decode.d3.loss_mask: 0.4770  decode.d3.loss_dice: 0.9995  decode.d4.loss_cls: 0.0819  decode.d4.loss_mask: 0.4760  decode.d4.loss_dice: 1.0151  decode.d5.loss_cls: 0.0753  decode.d5.loss_mask: 0.4737  decode.d5.loss_dice: 1.0448  decode.d6.loss_cls: 0.0853  decode.d6.loss_mask: 0.4713  decode.d6.loss_dice: 1.0210  decode.d7.loss_cls: 0.0812  decode.d7.loss_mask: 0.4766  decode.d7.loss_dice: 1.0309  decode.d8.loss_cls: 0.0895  decode.d8.loss_mask: 0.4752  decode.d8.loss_dice: 1.0310
11/15 17:13:10 - mmengine - INFO - Iter(train) [59600/90000]  base_lr: 3.7651e-05 lr: 3.7651e-06  eta: 5:05:17  time: 0.5950  data_time: 0.0102  memory: 10675  grad_norm: 387.0964  loss: 17.0866  decode.loss_cls: 0.0505  decode.loss_mask: 0.5523  decode.loss_dice: 1.0641  decode.d0.loss_cls: 0.0827  decode.d0.loss_mask: 0.5690  decode.d0.loss_dice: 1.1356  decode.d1.loss_cls: 0.0437  decode.d1.loss_mask: 0.5696  decode.d1.loss_dice: 1.1410  decode.d2.loss_cls: 0.0455  decode.d2.loss_mask: 0.5441  decode.d2.loss_dice: 1.0907  decode.d3.loss_cls: 0.0421  decode.d3.loss_mask: 0.5390  decode.d3.loss_dice: 1.0784  decode.d4.loss_cls: 0.0445  decode.d4.loss_mask: 0.5453  decode.d4.loss_dice: 1.1076  decode.d5.loss_cls: 0.0430  decode.d5.loss_mask: 0.5483  decode.d5.loss_dice: 1.1051  decode.d6.loss_cls: 0.0424  decode.d6.loss_mask: 0.5721  decode.d6.loss_dice: 1.0903  decode.d7.loss_cls: 0.0402  decode.d7.loss_mask: 0.5700  decode.d7.loss_dice: 1.1011  decode.d8.loss_cls: 0.0382  decode.d8.loss_mask: 0.5662  decode.d8.loss_dice: 1.1240
11/15 17:13:40 - mmengine - INFO - Iter(train) [59650/90000]  base_lr: 3.7595e-05 lr: 3.7595e-06  eta: 5:04:47  time: 0.5955  data_time: 0.0104  memory: 10656  grad_norm: 201.4481  loss: 14.2410  decode.loss_cls: 0.0685  decode.loss_mask: 0.3682  decode.loss_dice: 0.9628  decode.d0.loss_cls: 0.0973  decode.d0.loss_mask: 0.3852  decode.d0.loss_dice: 1.0697  decode.d1.loss_cls: 0.0795  decode.d1.loss_mask: 0.3746  decode.d1.loss_dice: 1.0018  decode.d2.loss_cls: 0.0723  decode.d2.loss_mask: 0.3682  decode.d2.loss_dice: 0.9616  decode.d3.loss_cls: 0.0759  decode.d3.loss_mask: 0.3713  decode.d3.loss_dice: 0.9624  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.3677  decode.d4.loss_dice: 0.9584  decode.d5.loss_cls: 0.0671  decode.d5.loss_mask: 0.3689  decode.d5.loss_dice: 0.9775  decode.d6.loss_cls: 0.0628  decode.d6.loss_mask: 0.3671  decode.d6.loss_dice: 0.9795  decode.d7.loss_cls: 0.0747  decode.d7.loss_mask: 0.3685  decode.d7.loss_dice: 0.9608  decode.d8.loss_cls: 0.0652  decode.d8.loss_mask: 0.3720  decode.d8.loss_dice: 0.9684
11/15 17:14:10 - mmengine - INFO - Iter(train) [59700/90000]  base_lr: 3.7539e-05 lr: 3.7539e-06  eta: 5:04:16  time: 0.5951  data_time: 0.0103  memory: 10692  grad_norm: 255.2926  loss: 14.1926  decode.loss_cls: 0.0407  decode.loss_mask: 0.4447  decode.loss_dice: 0.9280  decode.d0.loss_cls: 0.0712  decode.d0.loss_mask: 0.4528  decode.d0.loss_dice: 0.9422  decode.d1.loss_cls: 0.0451  decode.d1.loss_mask: 0.4486  decode.d1.loss_dice: 0.9286  decode.d2.loss_cls: 0.0475  decode.d2.loss_mask: 0.4409  decode.d2.loss_dice: 0.9375  decode.d3.loss_cls: 0.0402  decode.d3.loss_mask: 0.4467  decode.d3.loss_dice: 0.9142  decode.d4.loss_cls: 0.0447  decode.d4.loss_mask: 0.4255  decode.d4.loss_dice: 0.9329  decode.d5.loss_cls: 0.0414  decode.d5.loss_mask: 0.4437  decode.d5.loss_dice: 0.9130  decode.d6.loss_cls: 0.0448  decode.d6.loss_mask: 0.4496  decode.d6.loss_dice: 0.9402  decode.d7.loss_cls: 0.0446  decode.d7.loss_mask: 0.4456  decode.d7.loss_dice: 0.9124  decode.d8.loss_cls: 0.0401  decode.d8.loss_mask: 0.4470  decode.d8.loss_dice: 0.9383
11/15 17:14:40 - mmengine - INFO - Iter(train) [59750/90000]  base_lr: 3.7483e-05 lr: 3.7483e-06  eta: 5:03:46  time: 0.5953  data_time: 0.0106  memory: 10675  grad_norm: 601.1947  loss: 16.9150  decode.loss_cls: 0.0764  decode.loss_mask: 0.4716  decode.loss_dice: 1.0935  decode.d0.loss_cls: 0.1236  decode.d0.loss_mask: 0.5304  decode.d0.loss_dice: 1.2152  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.4945  decode.d1.loss_dice: 1.1441  decode.d2.loss_cls: 0.0776  decode.d2.loss_mask: 0.4878  decode.d2.loss_dice: 1.1102  decode.d3.loss_cls: 0.0813  decode.d3.loss_mask: 0.4804  decode.d3.loss_dice: 1.1197  decode.d4.loss_cls: 0.0844  decode.d4.loss_mask: 0.4814  decode.d4.loss_dice: 1.1216  decode.d5.loss_cls: 0.0614  decode.d5.loss_mask: 0.4812  decode.d5.loss_dice: 1.1043  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.4821  decode.d6.loss_dice: 1.0998  decode.d7.loss_cls: 0.0789  decode.d7.loss_mask: 0.4813  decode.d7.loss_dice: 1.1266  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.4727  decode.d8.loss_dice: 1.1150
11/15 17:15:10 - mmengine - INFO - Iter(train) [59800/90000]  base_lr: 3.7428e-05 lr: 3.7428e-06  eta: 5:03:16  time: 0.5962  data_time: 0.0105  memory: 10675  grad_norm: 739.7057  loss: 17.0219  decode.loss_cls: 0.0676  decode.loss_mask: 0.5994  decode.loss_dice: 1.0504  decode.d0.loss_cls: 0.0808  decode.d0.loss_mask: 0.6760  decode.d0.loss_dice: 1.1148  decode.d1.loss_cls: 0.0673  decode.d1.loss_mask: 0.6032  decode.d1.loss_dice: 1.0431  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 0.6011  decode.d2.loss_dice: 1.0366  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.5865  decode.d3.loss_dice: 0.9970  decode.d4.loss_cls: 0.0657  decode.d4.loss_mask: 0.5915  decode.d4.loss_dice: 1.0114  decode.d5.loss_cls: 0.0623  decode.d5.loss_mask: 0.5778  decode.d5.loss_dice: 1.0248  decode.d6.loss_cls: 0.0670  decode.d6.loss_mask: 0.5836  decode.d6.loss_dice: 1.0356  decode.d7.loss_cls: 0.0647  decode.d7.loss_mask: 0.5891  decode.d7.loss_dice: 1.0334  decode.d8.loss_cls: 0.0638  decode.d8.loss_mask: 0.5924  decode.d8.loss_dice: 1.0132
11/15 17:15:39 - mmengine - INFO - Iter(train) [59850/90000]  base_lr: 3.7372e-05 lr: 3.7372e-06  eta: 5:02:46  time: 0.5959  data_time: 0.0104  memory: 10692  grad_norm: 461.3256  loss: 16.5577  decode.loss_cls: 0.0718  decode.loss_mask: 0.5539  decode.loss_dice: 1.0549  decode.d0.loss_cls: 0.0993  decode.d0.loss_mask: 0.5724  decode.d0.loss_dice: 1.1690  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.5816  decode.d1.loss_dice: 1.0865  decode.d2.loss_cls: 0.0707  decode.d2.loss_mask: 0.5038  decode.d2.loss_dice: 1.0378  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 0.5003  decode.d3.loss_dice: 1.0248  decode.d4.loss_cls: 0.0648  decode.d4.loss_mask: 0.5072  decode.d4.loss_dice: 1.0278  decode.d5.loss_cls: 0.0766  decode.d5.loss_mask: 0.4943  decode.d5.loss_dice: 1.0245  decode.d6.loss_cls: 0.0658  decode.d6.loss_mask: 0.5157  decode.d6.loss_dice: 1.0285  decode.d7.loss_cls: 0.0733  decode.d7.loss_mask: 0.5413  decode.d7.loss_dice: 1.0223  decode.d8.loss_cls: 0.0688  decode.d8.loss_mask: 0.5508  decode.d8.loss_dice: 1.0400
11/15 17:16:09 - mmengine - INFO - Iter(train) [59900/90000]  base_lr: 3.7316e-05 lr: 3.7316e-06  eta: 5:02:15  time: 0.5949  data_time: 0.0104  memory: 10656  grad_norm: 296.9780  loss: 16.7287  decode.loss_cls: 0.0573  decode.loss_mask: 0.5102  decode.loss_dice: 1.0895  decode.d0.loss_cls: 0.0920  decode.d0.loss_mask: 0.5391  decode.d0.loss_dice: 1.1263  decode.d1.loss_cls: 0.0658  decode.d1.loss_mask: 0.5121  decode.d1.loss_dice: 1.1039  decode.d2.loss_cls: 0.0550  decode.d2.loss_mask: 0.5160  decode.d2.loss_dice: 1.0978  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 0.5116  decode.d3.loss_dice: 1.0860  decode.d4.loss_cls: 0.0743  decode.d4.loss_mask: 0.5061  decode.d4.loss_dice: 1.0864  decode.d5.loss_cls: 0.0638  decode.d5.loss_mask: 0.5158  decode.d5.loss_dice: 1.0438  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.5107  decode.d6.loss_dice: 1.1068  decode.d7.loss_cls: 0.0708  decode.d7.loss_mask: 0.5079  decode.d7.loss_dice: 1.0749  decode.d8.loss_cls: 0.0647  decode.d8.loss_mask: 0.5081  decode.d8.loss_dice: 1.1068
11/15 17:16:39 - mmengine - INFO - Iter(train) [59950/90000]  base_lr: 3.7260e-05 lr: 3.7260e-06  eta: 5:01:45  time: 0.5947  data_time: 0.0106  memory: 10675  grad_norm: 399.5302  loss: 16.2149  decode.loss_cls: 0.0638  decode.loss_mask: 0.5249  decode.loss_dice: 1.0053  decode.d0.loss_cls: 0.0666  decode.d0.loss_mask: 0.5631  decode.d0.loss_dice: 1.1107  decode.d1.loss_cls: 0.0504  decode.d1.loss_mask: 0.5534  decode.d1.loss_dice: 1.0524  decode.d2.loss_cls: 0.0592  decode.d2.loss_mask: 0.5568  decode.d2.loss_dice: 1.0180  decode.d3.loss_cls: 0.0543  decode.d3.loss_mask: 0.5462  decode.d3.loss_dice: 1.0043  decode.d4.loss_cls: 0.0500  decode.d4.loss_mask: 0.5424  decode.d4.loss_dice: 1.0045  decode.d5.loss_cls: 0.0565  decode.d5.loss_mask: 0.5343  decode.d5.loss_dice: 1.0134  decode.d6.loss_cls: 0.0545  decode.d6.loss_mask: 0.5452  decode.d6.loss_dice: 1.0165  decode.d7.loss_cls: 0.0614  decode.d7.loss_mask: 0.5310  decode.d7.loss_dice: 1.0030  decode.d8.loss_cls: 0.0581  decode.d8.loss_mask: 0.5181  decode.d8.loss_dice: 0.9962
11/15 17:17:09 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 17:17:09 - mmengine - INFO - Iter(train) [60000/90000]  base_lr: 3.7204e-05 lr: 3.7204e-06  eta: 5:01:15  time: 0.5946  data_time: 0.0105  memory: 10641  grad_norm: 346.6237  loss: 14.8893  decode.loss_cls: 0.0824  decode.loss_mask: 0.4531  decode.loss_dice: 0.9263  decode.d0.loss_cls: 0.1072  decode.d0.loss_mask: 0.4580  decode.d0.loss_dice: 1.0279  decode.d1.loss_cls: 0.0831  decode.d1.loss_mask: 0.4331  decode.d1.loss_dice: 0.9671  decode.d2.loss_cls: 0.0692  decode.d2.loss_mask: 0.4490  decode.d2.loss_dice: 0.9657  decode.d3.loss_cls: 0.0775  decode.d3.loss_mask: 0.4552  decode.d3.loss_dice: 0.9369  decode.d4.loss_cls: 0.0725  decode.d4.loss_mask: 0.4595  decode.d4.loss_dice: 0.9504  decode.d5.loss_cls: 0.0716  decode.d5.loss_mask: 0.4506  decode.d5.loss_dice: 0.9548  decode.d6.loss_cls: 0.0685  decode.d6.loss_mask: 0.4513  decode.d6.loss_dice: 0.9527  decode.d7.loss_cls: 0.0782  decode.d7.loss_mask: 0.4556  decode.d7.loss_dice: 0.9599  decode.d8.loss_cls: 0.0730  decode.d8.loss_mask: 0.4500  decode.d8.loss_dice: 0.9490
11/15 17:17:09 - mmengine - INFO - Saving checkpoint at 60000 iterations
11/15 17:17:28 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:26  time: 0.3090  data_time: 0.0050  memory: 4095  
11/15 17:17:43 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:06  time: 0.3080  data_time: 0.0039  memory: 4095  
11/15 17:17:59 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:49  time: 0.3082  data_time: 0.0041  memory: 4095  
11/15 17:18:14 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3089  data_time: 0.0041  memory: 4095  
11/15 17:18:30 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3084  data_time: 0.0039  memory: 4095  
11/15 17:18:45 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:02  time: 0.3082  data_time: 0.0038  memory: 4095  
11/15 17:19:01 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3084  data_time: 0.0040  memory: 4095  
11/15 17:19:16 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:31  time: 0.3099  data_time: 0.0038  memory: 4095  
11/15 17:19:31 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3083  data_time: 0.0039  memory: 4095  
11/15 17:19:47 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3080  data_time: 0.0036  memory: 4095  
11/15 17:19:47 - mmengine - INFO - per class results:
11/15 17:19:47 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 98.16 | 98.62 |
|    sidewalk   | 86.15 | 93.35 |
|    building   |  92.7 | 95.82 |
|      wall     | 59.78 | 78.47 |
|     fence     | 61.04 | 70.59 |
|      pole     | 67.37 | 80.19 |
| traffic light | 71.26 | 79.11 |
|  traffic sign | 81.53 |  87.1 |
|   vegetation  | 92.18 | 97.24 |
|    terrain    | 67.58 | 80.18 |
|      sky      |  94.8 | 97.05 |
|     person    |  82.7 | 91.54 |
|     rider     | 65.49 | 78.43 |
|      car      | 95.04 | 97.94 |
|     truck     | 81.06 |  89.7 |
|      bus      |  86.4 | 89.22 |
|     train     | 69.63 |  90.9 |
|   motorcycle  | 64.24 | 82.43 |
|    bicycle    | 78.87 | 88.13 |
+---------------+-------+-------+
11/15 17:19:47 - mmengine - INFO - Iter(val) [500/500]    aAcc: 96.1700  mIoU: 78.7400  mAcc: 87.6800  data_time: 0.0047  time: 0.3101
11/15 17:19:47 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024/best_mIoU_iter_50000.pth is removed
11/15 17:19:49 - mmengine - INFO - The best checkpoint with 78.7400 mIoU at 60000 iter is saved to best_mIoU_iter_60000.pth.
11/15 17:20:22 - mmengine - INFO - Iter(train) [60050/90000]  base_lr: 3.7149e-05 lr: 3.7149e-06  eta: 5:00:47  time: 0.5962  data_time: 0.0104  memory: 10656  grad_norm: 370.8566  loss: 16.2450  decode.loss_cls: 0.0767  decode.loss_mask: 0.4442  decode.loss_dice: 1.0823  decode.d0.loss_cls: 0.0932  decode.d0.loss_mask: 0.4678  decode.d0.loss_dice: 1.1909  decode.d1.loss_cls: 0.0925  decode.d1.loss_mask: 0.4315  decode.d1.loss_dice: 1.1139  decode.d2.loss_cls: 0.0819  decode.d2.loss_mask: 0.4469  decode.d2.loss_dice: 1.1128  decode.d3.loss_cls: 0.0768  decode.d3.loss_mask: 0.4473  decode.d3.loss_dice: 1.0598  decode.d4.loss_cls: 0.0775  decode.d4.loss_mask: 0.4413  decode.d4.loss_dice: 1.0940  decode.d5.loss_cls: 0.0773  decode.d5.loss_mask: 0.4439  decode.d5.loss_dice: 1.0646  decode.d6.loss_cls: 0.0762  decode.d6.loss_mask: 0.4447  decode.d6.loss_dice: 1.1131  decode.d7.loss_cls: 0.0791  decode.d7.loss_mask: 0.4389  decode.d7.loss_dice: 1.0791  decode.d8.loss_cls: 0.0790  decode.d8.loss_mask: 0.4433  decode.d8.loss_dice: 1.0744
11/15 17:20:51 - mmengine - INFO - Iter(train) [60100/90000]  base_lr: 3.7093e-05 lr: 3.7093e-06  eta: 5:00:16  time: 0.5967  data_time: 0.0105  memory: 10656  grad_norm: 306.8105  loss: 16.1377  decode.loss_cls: 0.0449  decode.loss_mask: 0.5087  decode.loss_dice: 1.0311  decode.d0.loss_cls: 0.0746  decode.d0.loss_mask: 0.5163  decode.d0.loss_dice: 1.0929  decode.d1.loss_cls: 0.0481  decode.d1.loss_mask: 0.5049  decode.d1.loss_dice: 1.0797  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.5042  decode.d2.loss_dice: 1.0473  decode.d3.loss_cls: 0.0474  decode.d3.loss_mask: 0.5121  decode.d3.loss_dice: 1.0372  decode.d4.loss_cls: 0.0550  decode.d4.loss_mask: 0.5081  decode.d4.loss_dice: 1.0373  decode.d5.loss_cls: 0.0516  decode.d5.loss_mask: 0.5060  decode.d5.loss_dice: 1.0670  decode.d6.loss_cls: 0.0483  decode.d6.loss_mask: 0.5065  decode.d6.loss_dice: 1.0380  decode.d7.loss_cls: 0.0452  decode.d7.loss_mask: 0.5101  decode.d7.loss_dice: 1.0698  decode.d8.loss_cls: 0.0469  decode.d8.loss_mask: 0.5024  decode.d8.loss_dice: 1.0402
11/15 17:21:21 - mmengine - INFO - Iter(train) [60150/90000]  base_lr: 3.7037e-05 lr: 3.7037e-06  eta: 4:59:46  time: 0.5967  data_time: 0.0104  memory: 10728  grad_norm: 1216.0348  loss: 17.4548  decode.loss_cls: 0.0690  decode.loss_mask: 0.4752  decode.loss_dice: 1.1621  decode.d0.loss_cls: 0.0581  decode.d0.loss_mask: 0.5248  decode.d0.loss_dice: 1.2988  decode.d1.loss_cls: 0.0590  decode.d1.loss_mask: 0.5045  decode.d1.loss_dice: 1.1889  decode.d2.loss_cls: 0.0700  decode.d2.loss_mask: 0.4929  decode.d2.loss_dice: 1.2027  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 0.4898  decode.d3.loss_dice: 1.2031  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.4729  decode.d4.loss_dice: 1.1876  decode.d5.loss_cls: 0.0621  decode.d5.loss_mask: 0.4753  decode.d5.loss_dice: 1.1771  decode.d6.loss_cls: 0.0715  decode.d6.loss_mask: 0.4864  decode.d6.loss_dice: 1.1555  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.4836  decode.d7.loss_dice: 1.1640  decode.d8.loss_cls: 0.0681  decode.d8.loss_mask: 0.4940  decode.d8.loss_dice: 1.1641
11/15 17:21:51 - mmengine - INFO - Iter(train) [60200/90000]  base_lr: 3.6981e-05 lr: 3.6981e-06  eta: 4:59:16  time: 0.5960  data_time: 0.0105  memory: 10675  grad_norm: 357.2723  loss: 16.5822  decode.loss_cls: 0.0903  decode.loss_mask: 0.4653  decode.loss_dice: 1.0833  decode.d0.loss_cls: 0.0913  decode.d0.loss_mask: 0.4886  decode.d0.loss_dice: 1.1852  decode.d1.loss_cls: 0.0905  decode.d1.loss_mask: 0.4715  decode.d1.loss_dice: 1.1479  decode.d2.loss_cls: 0.0894  decode.d2.loss_mask: 0.4752  decode.d2.loss_dice: 1.1323  decode.d3.loss_cls: 0.0794  decode.d3.loss_mask: 0.4674  decode.d3.loss_dice: 1.0923  decode.d4.loss_cls: 0.0865  decode.d4.loss_mask: 0.4624  decode.d4.loss_dice: 1.0969  decode.d5.loss_cls: 0.0765  decode.d5.loss_mask: 0.4609  decode.d5.loss_dice: 1.0772  decode.d6.loss_cls: 0.0812  decode.d6.loss_mask: 0.4618  decode.d6.loss_dice: 1.0725  decode.d7.loss_cls: 0.0774  decode.d7.loss_mask: 0.4600  decode.d7.loss_dice: 1.0759  decode.d8.loss_cls: 0.0839  decode.d8.loss_mask: 0.4611  decode.d8.loss_dice: 1.0978
11/15 17:22:21 - mmengine - INFO - Iter(train) [60250/90000]  base_lr: 3.6925e-05 lr: 3.6925e-06  eta: 4:58:46  time: 0.5951  data_time: 0.0103  memory: 10675  grad_norm: 1166.6984  loss: 15.9898  decode.loss_cls: 0.0478  decode.loss_mask: 0.4887  decode.loss_dice: 1.0612  decode.d0.loss_cls: 0.0721  decode.d0.loss_mask: 0.5274  decode.d0.loss_dice: 1.1079  decode.d1.loss_cls: 0.0462  decode.d1.loss_mask: 0.5061  decode.d1.loss_dice: 1.0968  decode.d2.loss_cls: 0.0502  decode.d2.loss_mask: 0.4920  decode.d2.loss_dice: 1.0470  decode.d3.loss_cls: 0.0504  decode.d3.loss_mask: 0.4714  decode.d3.loss_dice: 1.0324  decode.d4.loss_cls: 0.0539  decode.d4.loss_mask: 0.4778  decode.d4.loss_dice: 1.0215  decode.d5.loss_cls: 0.0445  decode.d5.loss_mask: 0.4914  decode.d5.loss_dice: 1.0609  decode.d6.loss_cls: 0.0501  decode.d6.loss_mask: 0.4852  decode.d6.loss_dice: 1.0453  decode.d7.loss_cls: 0.0516  decode.d7.loss_mask: 0.4912  decode.d7.loss_dice: 1.0261  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.4911  decode.d8.loss_dice: 1.0558
11/15 17:22:51 - mmengine - INFO - Iter(train) [60300/90000]  base_lr: 3.6869e-05 lr: 3.6869e-06  eta: 4:58:15  time: 0.5975  data_time: 0.0105  memory: 10713  grad_norm: 210.7476  loss: 15.9773  decode.loss_cls: 0.0683  decode.loss_mask: 0.4608  decode.loss_dice: 1.0332  decode.d0.loss_cls: 0.0937  decode.d0.loss_mask: 0.4816  decode.d0.loss_dice: 1.1490  decode.d1.loss_cls: 0.0802  decode.d1.loss_mask: 0.4605  decode.d1.loss_dice: 1.0873  decode.d2.loss_cls: 0.0688  decode.d2.loss_mask: 0.4652  decode.d2.loss_dice: 1.0750  decode.d3.loss_cls: 0.0582  decode.d3.loss_mask: 0.4610  decode.d3.loss_dice: 1.0320  decode.d4.loss_cls: 0.0587  decode.d4.loss_mask: 0.4558  decode.d4.loss_dice: 1.0785  decode.d5.loss_cls: 0.0672  decode.d5.loss_mask: 0.4614  decode.d5.loss_dice: 1.0570  decode.d6.loss_cls: 0.0578  decode.d6.loss_mask: 0.4593  decode.d6.loss_dice: 1.0505  decode.d7.loss_cls: 0.0634  decode.d7.loss_mask: 0.4609  decode.d7.loss_dice: 1.0644  decode.d8.loss_cls: 0.0595  decode.d8.loss_mask: 0.4583  decode.d8.loss_dice: 1.0497
11/15 17:23:20 - mmengine - INFO - Iter(train) [60350/90000]  base_lr: 3.6814e-05 lr: 3.6814e-06  eta: 4:57:45  time: 0.5974  data_time: 0.0106  memory: 10692  grad_norm: 236.4023  loss: 15.7635  decode.loss_cls: 0.0539  decode.loss_mask: 0.4858  decode.loss_dice: 1.0145  decode.d0.loss_cls: 0.0863  decode.d0.loss_mask: 0.5086  decode.d0.loss_dice: 1.0754  decode.d1.loss_cls: 0.0758  decode.d1.loss_mask: 0.4885  decode.d1.loss_dice: 1.0470  decode.d2.loss_cls: 0.0578  decode.d2.loss_mask: 0.5024  decode.d2.loss_dice: 1.0192  decode.d3.loss_cls: 0.0678  decode.d3.loss_mask: 0.4783  decode.d3.loss_dice: 1.0205  decode.d4.loss_cls: 0.0682  decode.d4.loss_mask: 0.4794  decode.d4.loss_dice: 1.0142  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.4728  decode.d5.loss_dice: 1.0294  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.4863  decode.d6.loss_dice: 1.0039  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.4830  decode.d7.loss_dice: 1.0074  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 0.4832  decode.d8.loss_dice: 1.0152
11/15 17:23:50 - mmengine - INFO - Iter(train) [60400/90000]  base_lr: 3.6758e-05 lr: 3.6758e-06  eta: 4:57:15  time: 0.5955  data_time: 0.0104  memory: 10692  grad_norm: 352.8168  loss: 16.4507  decode.loss_cls: 0.0836  decode.loss_mask: 0.4630  decode.loss_dice: 1.0713  decode.d0.loss_cls: 0.1012  decode.d0.loss_mask: 0.4862  decode.d0.loss_dice: 1.1339  decode.d1.loss_cls: 0.0966  decode.d1.loss_mask: 0.4764  decode.d1.loss_dice: 1.0886  decode.d2.loss_cls: 0.0876  decode.d2.loss_mask: 0.4647  decode.d2.loss_dice: 1.0730  decode.d3.loss_cls: 0.0784  decode.d3.loss_mask: 0.4659  decode.d3.loss_dice: 1.0792  decode.d4.loss_cls: 0.0857  decode.d4.loss_mask: 0.4692  decode.d4.loss_dice: 1.0826  decode.d5.loss_cls: 0.0888  decode.d5.loss_mask: 0.4710  decode.d5.loss_dice: 1.0987  decode.d6.loss_cls: 0.0930  decode.d6.loss_mask: 0.4644  decode.d6.loss_dice: 1.0755  decode.d7.loss_cls: 0.0812  decode.d7.loss_mask: 0.4677  decode.d7.loss_dice: 1.0775  decode.d8.loss_cls: 0.0854  decode.d8.loss_mask: 0.4652  decode.d8.loss_dice: 1.0953
11/15 17:24:22 - mmengine - INFO - Iter(train) [60450/90000]  base_lr: 3.6702e-05 lr: 3.6702e-06  eta: 4:56:45  time: 0.5962  data_time: 0.0106  memory: 10692  grad_norm: 465.2106  loss: 15.2174  decode.loss_cls: 0.0641  decode.loss_mask: 0.4614  decode.loss_dice: 0.9950  decode.d0.loss_cls: 0.0858  decode.d0.loss_mask: 0.4783  decode.d0.loss_dice: 1.0759  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.4724  decode.d1.loss_dice: 1.0474  decode.d2.loss_cls: 0.0576  decode.d2.loss_mask: 0.4732  decode.d2.loss_dice: 1.0027  decode.d3.loss_cls: 0.0585  decode.d3.loss_mask: 0.4690  decode.d3.loss_dice: 0.9813  decode.d4.loss_cls: 0.0538  decode.d4.loss_mask: 0.4678  decode.d4.loss_dice: 0.9730  decode.d5.loss_cls: 0.0645  decode.d5.loss_mask: 0.4554  decode.d5.loss_dice: 0.9613  decode.d6.loss_cls: 0.0699  decode.d6.loss_mask: 0.4581  decode.d6.loss_dice: 0.9522  decode.d7.loss_cls: 0.0770  decode.d7.loss_mask: 0.4582  decode.d7.loss_dice: 0.9757  decode.d8.loss_cls: 0.0700  decode.d8.loss_mask: 0.4535  decode.d8.loss_dice: 0.9402
11/15 17:24:51 - mmengine - INFO - Iter(train) [60500/90000]  base_lr: 3.6646e-05 lr: 3.6646e-06  eta: 4:56:15  time: 0.5962  data_time: 0.0106  memory: 10641  grad_norm: 326.4548  loss: 15.6028  decode.loss_cls: 0.0707  decode.loss_mask: 0.4236  decode.loss_dice: 1.0371  decode.d0.loss_cls: 0.0748  decode.d0.loss_mask: 0.4420  decode.d0.loss_dice: 1.1796  decode.d1.loss_cls: 0.0668  decode.d1.loss_mask: 0.4213  decode.d1.loss_dice: 1.0681  decode.d2.loss_cls: 0.0610  decode.d2.loss_mask: 0.4234  decode.d2.loss_dice: 1.0466  decode.d3.loss_cls: 0.0641  decode.d3.loss_mask: 0.4259  decode.d3.loss_dice: 1.0730  decode.d4.loss_cls: 0.0675  decode.d4.loss_mask: 0.4244  decode.d4.loss_dice: 1.0600  decode.d5.loss_cls: 0.0610  decode.d5.loss_mask: 0.4234  decode.d5.loss_dice: 1.0584  decode.d6.loss_cls: 0.0622  decode.d6.loss_mask: 0.4244  decode.d6.loss_dice: 1.0578  decode.d7.loss_cls: 0.0668  decode.d7.loss_mask: 0.4241  decode.d7.loss_dice: 1.0672  decode.d8.loss_cls: 0.0654  decode.d8.loss_mask: 0.4258  decode.d8.loss_dice: 1.0366
11/15 17:25:21 - mmengine - INFO - Iter(train) [60550/90000]  base_lr: 3.6590e-05 lr: 3.6590e-06  eta: 4:55:45  time: 0.5959  data_time: 0.0106  memory: 10675  grad_norm: 282.0636  loss: 15.0958  decode.loss_cls: 0.0557  decode.loss_mask: 0.4509  decode.loss_dice: 0.9873  decode.d0.loss_cls: 0.0688  decode.d0.loss_mask: 0.4767  decode.d0.loss_dice: 1.0672  decode.d1.loss_cls: 0.0563  decode.d1.loss_mask: 0.4504  decode.d1.loss_dice: 1.0291  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 0.4377  decode.d2.loss_dice: 0.9946  decode.d3.loss_cls: 0.0574  decode.d3.loss_mask: 0.4357  decode.d3.loss_dice: 0.9993  decode.d4.loss_cls: 0.0486  decode.d4.loss_mask: 0.4368  decode.d4.loss_dice: 0.9791  decode.d5.loss_cls: 0.0533  decode.d5.loss_mask: 0.4367  decode.d5.loss_dice: 0.9968  decode.d6.loss_cls: 0.0575  decode.d6.loss_mask: 0.4454  decode.d6.loss_dice: 0.9870  decode.d7.loss_cls: 0.0529  decode.d7.loss_mask: 0.4533  decode.d7.loss_dice: 1.0020  decode.d8.loss_cls: 0.0551  decode.d8.loss_mask: 0.4499  decode.d8.loss_dice: 1.0242
11/15 17:25:51 - mmengine - INFO - Iter(train) [60600/90000]  base_lr: 3.6534e-05 lr: 3.6534e-06  eta: 4:55:14  time: 0.5935  data_time: 0.0105  memory: 10641  grad_norm: 609.2922  loss: 15.5754  decode.loss_cls: 0.0638  decode.loss_mask: 0.5036  decode.loss_dice: 0.9900  decode.d0.loss_cls: 0.0934  decode.d0.loss_mask: 0.5283  decode.d0.loss_dice: 1.0181  decode.d1.loss_cls: 0.0801  decode.d1.loss_mask: 0.5013  decode.d1.loss_dice: 0.9505  decode.d2.loss_cls: 0.0625  decode.d2.loss_mask: 0.5057  decode.d2.loss_dice: 0.9772  decode.d3.loss_cls: 0.0582  decode.d3.loss_mask: 0.5186  decode.d3.loss_dice: 0.9823  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.5092  decode.d4.loss_dice: 0.9743  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.5125  decode.d5.loss_dice: 0.9881  decode.d6.loss_cls: 0.0718  decode.d6.loss_mask: 0.4912  decode.d6.loss_dice: 0.9594  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.5090  decode.d7.loss_dice: 0.9857  decode.d8.loss_cls: 0.0654  decode.d8.loss_mask: 0.5093  decode.d8.loss_dice: 0.9960
11/15 17:26:21 - mmengine - INFO - Iter(train) [60650/90000]  base_lr: 3.6478e-05 lr: 3.6478e-06  eta: 4:54:44  time: 0.5989  data_time: 0.0107  memory: 10713  grad_norm: 315.0240  loss: 17.2086  decode.loss_cls: 0.0713  decode.loss_mask: 0.5259  decode.loss_dice: 1.1054  decode.d0.loss_cls: 0.0880  decode.d0.loss_mask: 0.5620  decode.d0.loss_dice: 1.1929  decode.d1.loss_cls: 0.0779  decode.d1.loss_mask: 0.5279  decode.d1.loss_dice: 1.1618  decode.d2.loss_cls: 0.0681  decode.d2.loss_mask: 0.5211  decode.d2.loss_dice: 1.0863  decode.d3.loss_cls: 0.0672  decode.d3.loss_mask: 0.5211  decode.d3.loss_dice: 1.0855  decode.d4.loss_cls: 0.0622  decode.d4.loss_mask: 0.5226  decode.d4.loss_dice: 1.1202  decode.d5.loss_cls: 0.0741  decode.d5.loss_mask: 0.5165  decode.d5.loss_dice: 1.1170  decode.d6.loss_cls: 0.0623  decode.d6.loss_mask: 0.5143  decode.d6.loss_dice: 1.1235  decode.d7.loss_cls: 0.0734  decode.d7.loss_mask: 0.5193  decode.d7.loss_dice: 1.1151  decode.d8.loss_cls: 0.0633  decode.d8.loss_mask: 0.5208  decode.d8.loss_dice: 1.1416
11/15 17:26:51 - mmengine - INFO - Iter(train) [60700/90000]  base_lr: 3.6422e-05 lr: 3.6422e-06  eta: 4:54:14  time: 0.5954  data_time: 0.0106  memory: 10713  grad_norm: 818.7215  loss: 15.9988  decode.loss_cls: 0.0485  decode.loss_mask: 0.5082  decode.loss_dice: 0.9954  decode.d0.loss_cls: 0.0703  decode.d0.loss_mask: 0.5418  decode.d0.loss_dice: 1.0692  decode.d1.loss_cls: 0.0444  decode.d1.loss_mask: 0.5167  decode.d1.loss_dice: 1.0548  decode.d2.loss_cls: 0.0380  decode.d2.loss_mask: 0.5221  decode.d2.loss_dice: 1.0218  decode.d3.loss_cls: 0.0457  decode.d3.loss_mask: 0.5259  decode.d3.loss_dice: 1.0205  decode.d4.loss_cls: 0.0384  decode.d4.loss_mask: 0.5256  decode.d4.loss_dice: 1.0172  decode.d5.loss_cls: 0.0439  decode.d5.loss_mask: 0.5263  decode.d5.loss_dice: 1.0130  decode.d6.loss_cls: 0.0487  decode.d6.loss_mask: 0.5261  decode.d6.loss_dice: 1.0622  decode.d7.loss_cls: 0.0421  decode.d7.loss_mask: 0.5314  decode.d7.loss_dice: 1.0153  decode.d8.loss_cls: 0.0524  decode.d8.loss_mask: 0.5133  decode.d8.loss_dice: 1.0196
11/15 17:27:21 - mmengine - INFO - Iter(train) [60750/90000]  base_lr: 3.6366e-05 lr: 3.6366e-06  eta: 4:53:43  time: 0.5953  data_time: 0.0106  memory: 10656  grad_norm: 328.9081  loss: 14.8362  decode.loss_cls: 0.0586  decode.loss_mask: 0.3982  decode.loss_dice: 0.9861  decode.d0.loss_cls: 0.0913  decode.d0.loss_mask: 0.4080  decode.d0.loss_dice: 1.0637  decode.d1.loss_cls: 0.0654  decode.d1.loss_mask: 0.4271  decode.d1.loss_dice: 1.0734  decode.d2.loss_cls: 0.0583  decode.d2.loss_mask: 0.4114  decode.d2.loss_dice: 1.0164  decode.d3.loss_cls: 0.0668  decode.d3.loss_mask: 0.3995  decode.d3.loss_dice: 1.0019  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.4064  decode.d4.loss_dice: 0.9801  decode.d5.loss_cls: 0.0605  decode.d5.loss_mask: 0.4275  decode.d5.loss_dice: 1.0098  decode.d6.loss_cls: 0.0603  decode.d6.loss_mask: 0.4043  decode.d6.loss_dice: 0.9880  decode.d7.loss_cls: 0.0604  decode.d7.loss_mask: 0.4061  decode.d7.loss_dice: 0.9964  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.4071  decode.d8.loss_dice: 0.9810
11/15 17:27:50 - mmengine - INFO - Iter(train) [60800/90000]  base_lr: 3.6310e-05 lr: 3.6310e-06  eta: 4:53:13  time: 0.5958  data_time: 0.0104  memory: 10656  grad_norm: 1248.2301  loss: 15.0228  decode.loss_cls: 0.0477  decode.loss_mask: 0.4920  decode.loss_dice: 0.9228  decode.d0.loss_cls: 0.0735  decode.d0.loss_mask: 0.5317  decode.d0.loss_dice: 1.0132  decode.d1.loss_cls: 0.0454  decode.d1.loss_mask: 0.4979  decode.d1.loss_dice: 0.9715  decode.d2.loss_cls: 0.0403  decode.d2.loss_mask: 0.5033  decode.d2.loss_dice: 0.9728  decode.d3.loss_cls: 0.0516  decode.d3.loss_mask: 0.5027  decode.d3.loss_dice: 0.9364  decode.d4.loss_cls: 0.0492  decode.d4.loss_mask: 0.5145  decode.d4.loss_dice: 0.9314  decode.d5.loss_cls: 0.0520  decode.d5.loss_mask: 0.5056  decode.d5.loss_dice: 0.9264  decode.d6.loss_cls: 0.0450  decode.d6.loss_mask: 0.5034  decode.d6.loss_dice: 0.9225  decode.d7.loss_cls: 0.0424  decode.d7.loss_mask: 0.5059  decode.d7.loss_dice: 0.9404  decode.d8.loss_cls: 0.0418  decode.d8.loss_mask: 0.5047  decode.d8.loss_dice: 0.9348
11/15 17:28:20 - mmengine - INFO - Iter(train) [60850/90000]  base_lr: 3.6254e-05 lr: 3.6254e-06  eta: 4:52:43  time: 0.5954  data_time: 0.0105  memory: 10656  grad_norm: 252.6863  loss: 14.3109  decode.loss_cls: 0.0561  decode.loss_mask: 0.3893  decode.loss_dice: 0.9844  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.4139  decode.d0.loss_dice: 1.0466  decode.d1.loss_cls: 0.0575  decode.d1.loss_mask: 0.3852  decode.d1.loss_dice: 0.9817  decode.d2.loss_cls: 0.0601  decode.d2.loss_mask: 0.4116  decode.d2.loss_dice: 0.9371  decode.d3.loss_cls: 0.0672  decode.d3.loss_mask: 0.3892  decode.d3.loss_dice: 0.9565  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.3849  decode.d4.loss_dice: 0.9516  decode.d5.loss_cls: 0.0589  decode.d5.loss_mask: 0.3870  decode.d5.loss_dice: 0.9732  decode.d6.loss_cls: 0.0575  decode.d6.loss_mask: 0.3858  decode.d6.loss_dice: 0.9662  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 0.3890  decode.d7.loss_dice: 0.9863  decode.d8.loss_cls: 0.0762  decode.d8.loss_mask: 0.3872  decode.d8.loss_dice: 0.9699
11/15 17:28:50 - mmengine - INFO - Iter(train) [60900/90000]  base_lr: 3.6198e-05 lr: 3.6198e-06  eta: 4:52:13  time: 0.5989  data_time: 0.0107  memory: 10675  grad_norm: 258.3818  loss: 14.6095  decode.loss_cls: 0.0528  decode.loss_mask: 0.3900  decode.loss_dice: 0.9868  decode.d0.loss_cls: 0.0649  decode.d0.loss_mask: 0.4157  decode.d0.loss_dice: 1.0723  decode.d1.loss_cls: 0.0620  decode.d1.loss_mask: 0.3956  decode.d1.loss_dice: 1.0319  decode.d2.loss_cls: 0.0538  decode.d2.loss_mask: 0.3941  decode.d2.loss_dice: 1.0107  decode.d3.loss_cls: 0.0567  decode.d3.loss_mask: 0.3930  decode.d3.loss_dice: 0.9913  decode.d4.loss_cls: 0.0590  decode.d4.loss_mask: 0.3943  decode.d4.loss_dice: 0.9871  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 0.3924  decode.d5.loss_dice: 1.0134  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.3928  decode.d6.loss_dice: 1.0102  decode.d7.loss_cls: 0.0493  decode.d7.loss_mask: 0.3868  decode.d7.loss_dice: 1.0124  decode.d8.loss_cls: 0.0536  decode.d8.loss_mask: 0.3858  decode.d8.loss_dice: 0.9942
11/15 17:29:20 - mmengine - INFO - Iter(train) [60950/90000]  base_lr: 3.6142e-05 lr: 3.6142e-06  eta: 4:51:42  time: 0.5948  data_time: 0.0103  memory: 10656  grad_norm: 484.3288  loss: 14.8718  decode.loss_cls: 0.0494  decode.loss_mask: 0.4125  decode.loss_dice: 1.0274  decode.d0.loss_cls: 0.0700  decode.d0.loss_mask: 0.4548  decode.d0.loss_dice: 1.0927  decode.d1.loss_cls: 0.0369  decode.d1.loss_mask: 0.4264  decode.d1.loss_dice: 1.0434  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 0.4150  decode.d2.loss_dice: 1.0056  decode.d3.loss_cls: 0.0412  decode.d3.loss_mask: 0.4198  decode.d3.loss_dice: 0.9918  decode.d4.loss_cls: 0.0391  decode.d4.loss_mask: 0.4214  decode.d4.loss_dice: 1.0174  decode.d5.loss_cls: 0.0429  decode.d5.loss_mask: 0.4207  decode.d5.loss_dice: 1.0169  decode.d6.loss_cls: 0.0403  decode.d6.loss_mask: 0.4179  decode.d6.loss_dice: 1.0039  decode.d7.loss_cls: 0.0399  decode.d7.loss_mask: 0.4075  decode.d7.loss_dice: 1.0001  decode.d8.loss_cls: 0.0414  decode.d8.loss_mask: 0.4129  decode.d8.loss_dice: 1.0140
11/15 17:29:50 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 17:29:50 - mmengine - INFO - Iter(train) [61000/90000]  base_lr: 3.6086e-05 lr: 3.6086e-06  eta: 4:51:12  time: 0.5952  data_time: 0.0104  memory: 10656  grad_norm: 428.1830  loss: 16.5511  decode.loss_cls: 0.0624  decode.loss_mask: 0.4289  decode.loss_dice: 1.1309  decode.d0.loss_cls: 0.0721  decode.d0.loss_mask: 0.4564  decode.d0.loss_dice: 1.2480  decode.d1.loss_cls: 0.0673  decode.d1.loss_mask: 0.4318  decode.d1.loss_dice: 1.1618  decode.d2.loss_cls: 0.0715  decode.d2.loss_mask: 0.4363  decode.d2.loss_dice: 1.1646  decode.d3.loss_cls: 0.0663  decode.d3.loss_mask: 0.4316  decode.d3.loss_dice: 1.1396  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.4316  decode.d4.loss_dice: 1.1602  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.4348  decode.d5.loss_dice: 1.1349  decode.d6.loss_cls: 0.0677  decode.d6.loss_mask: 0.4298  decode.d6.loss_dice: 1.1391  decode.d7.loss_cls: 0.0606  decode.d7.loss_mask: 0.4276  decode.d7.loss_dice: 1.1440  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.4265  decode.d8.loss_dice: 1.1235
11/15 17:30:23 - mmengine - INFO - Iter(train) [61050/90000]  base_lr: 3.6030e-05 lr: 3.6030e-06  eta: 4:50:44  time: 0.6244  data_time: 0.0108  memory: 10713  grad_norm: 327.9646  loss: 15.5287  decode.loss_cls: 0.0635  decode.loss_mask: 0.5032  decode.loss_dice: 0.9748  decode.d0.loss_cls: 0.1051  decode.d0.loss_mask: 0.5435  decode.d0.loss_dice: 1.0076  decode.d1.loss_cls: 0.0770  decode.d1.loss_mask: 0.4877  decode.d1.loss_dice: 0.9631  decode.d2.loss_cls: 0.0810  decode.d2.loss_mask: 0.4940  decode.d2.loss_dice: 0.9834  decode.d3.loss_cls: 0.0692  decode.d3.loss_mask: 0.4814  decode.d3.loss_dice: 0.9726  decode.d4.loss_cls: 0.0638  decode.d4.loss_mask: 0.4870  decode.d4.loss_dice: 1.0010  decode.d5.loss_cls: 0.0788  decode.d5.loss_mask: 0.4940  decode.d5.loss_dice: 0.9689  decode.d6.loss_cls: 0.0610  decode.d6.loss_mask: 0.4893  decode.d6.loss_dice: 0.9732  decode.d7.loss_cls: 0.0691  decode.d7.loss_mask: 0.5075  decode.d7.loss_dice: 0.9729  decode.d8.loss_cls: 0.0611  decode.d8.loss_mask: 0.5054  decode.d8.loss_dice: 0.9886
11/15 17:30:54 - mmengine - INFO - Iter(train) [61100/90000]  base_lr: 3.5974e-05 lr: 3.5974e-06  eta: 4:50:14  time: 0.5958  data_time: 0.0112  memory: 10675  grad_norm: 393.6516  loss: 17.8711  decode.loss_cls: 0.0423  decode.loss_mask: 0.5267  decode.loss_dice: 1.1699  decode.d0.loss_cls: 0.0698  decode.d0.loss_mask: 0.5837  decode.d0.loss_dice: 1.2900  decode.d1.loss_cls: 0.0381  decode.d1.loss_mask: 0.5524  decode.d1.loss_dice: 1.2462  decode.d2.loss_cls: 0.0506  decode.d2.loss_mask: 0.5490  decode.d2.loss_dice: 1.1882  decode.d3.loss_cls: 0.0347  decode.d3.loss_mask: 0.5454  decode.d3.loss_dice: 1.1915  decode.d4.loss_cls: 0.0335  decode.d4.loss_mask: 0.5391  decode.d4.loss_dice: 1.1782  decode.d5.loss_cls: 0.0351  decode.d5.loss_mask: 0.5335  decode.d5.loss_dice: 1.1562  decode.d6.loss_cls: 0.0367  decode.d6.loss_mask: 0.5342  decode.d6.loss_dice: 1.1923  decode.d7.loss_cls: 0.0326  decode.d7.loss_mask: 0.5355  decode.d7.loss_dice: 1.2104  decode.d8.loss_cls: 0.0321  decode.d8.loss_mask: 0.5431  decode.d8.loss_dice: 1.2000
11/15 17:31:24 - mmengine - INFO - Iter(train) [61150/90000]  base_lr: 3.5918e-05 lr: 3.5918e-06  eta: 4:49:43  time: 0.5994  data_time: 0.0106  memory: 10641  grad_norm: 384.0117  loss: 17.0513  decode.loss_cls: 0.0636  decode.loss_mask: 0.4561  decode.loss_dice: 1.1462  decode.d0.loss_cls: 0.0918  decode.d0.loss_mask: 0.5024  decode.d0.loss_dice: 1.2273  decode.d1.loss_cls: 0.0691  decode.d1.loss_mask: 0.4989  decode.d1.loss_dice: 1.2221  decode.d2.loss_cls: 0.0647  decode.d2.loss_mask: 0.4629  decode.d2.loss_dice: 1.1498  decode.d3.loss_cls: 0.0650  decode.d3.loss_mask: 0.4684  decode.d3.loss_dice: 1.1597  decode.d4.loss_cls: 0.0638  decode.d4.loss_mask: 0.4691  decode.d4.loss_dice: 1.1558  decode.d5.loss_cls: 0.0671  decode.d5.loss_mask: 0.4611  decode.d5.loss_dice: 1.1459  decode.d6.loss_cls: 0.0667  decode.d6.loss_mask: 0.4578  decode.d6.loss_dice: 1.1552  decode.d7.loss_cls: 0.0691  decode.d7.loss_mask: 0.4553  decode.d7.loss_dice: 1.1648  decode.d8.loss_cls: 0.0638  decode.d8.loss_mask: 0.4578  decode.d8.loss_dice: 1.1498
11/15 17:31:53 - mmengine - INFO - Iter(train) [61200/90000]  base_lr: 3.5862e-05 lr: 3.5862e-06  eta: 4:49:13  time: 0.5956  data_time: 0.0105  memory: 10675  grad_norm: 291.2743  loss: 15.8227  decode.loss_cls: 0.0556  decode.loss_mask: 0.4260  decode.loss_dice: 1.0572  decode.d0.loss_cls: 0.0865  decode.d0.loss_mask: 0.4405  decode.d0.loss_dice: 1.1396  decode.d1.loss_cls: 0.0828  decode.d1.loss_mask: 0.4390  decode.d1.loss_dice: 1.0861  decode.d2.loss_cls: 0.0598  decode.d2.loss_mask: 0.4661  decode.d2.loss_dice: 1.0987  decode.d3.loss_cls: 0.0468  decode.d3.loss_mask: 0.4677  decode.d3.loss_dice: 1.0553  decode.d4.loss_cls: 0.0481  decode.d4.loss_mask: 0.4628  decode.d4.loss_dice: 1.0797  decode.d5.loss_cls: 0.0513  decode.d5.loss_mask: 0.4656  decode.d5.loss_dice: 1.0760  decode.d6.loss_cls: 0.0478  decode.d6.loss_mask: 0.4337  decode.d6.loss_dice: 1.0641  decode.d7.loss_cls: 0.0540  decode.d7.loss_mask: 0.4298  decode.d7.loss_dice: 1.0675  decode.d8.loss_cls: 0.0554  decode.d8.loss_mask: 0.4290  decode.d8.loss_dice: 1.0501
11/15 17:32:23 - mmengine - INFO - Iter(train) [61250/90000]  base_lr: 3.5806e-05 lr: 3.5806e-06  eta: 4:48:43  time: 0.5958  data_time: 0.0108  memory: 10713  grad_norm: 605.0223  loss: 17.2485  decode.loss_cls: 0.0567  decode.loss_mask: 0.5858  decode.loss_dice: 1.0856  decode.d0.loss_cls: 0.0868  decode.d0.loss_mask: 0.5972  decode.d0.loss_dice: 1.1332  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.5847  decode.d1.loss_dice: 1.1022  decode.d2.loss_cls: 0.0644  decode.d2.loss_mask: 0.5721  decode.d2.loss_dice: 1.0912  decode.d3.loss_cls: 0.0614  decode.d3.loss_mask: 0.5752  decode.d3.loss_dice: 1.0737  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.5599  decode.d4.loss_dice: 1.0725  decode.d5.loss_cls: 0.0647  decode.d5.loss_mask: 0.5717  decode.d5.loss_dice: 1.0760  decode.d6.loss_cls: 0.0726  decode.d6.loss_mask: 0.5588  decode.d6.loss_dice: 1.0542  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 0.5732  decode.d7.loss_dice: 1.0602  decode.d8.loss_cls: 0.0504  decode.d8.loss_mask: 0.5881  decode.d8.loss_dice: 1.0830
11/15 17:32:53 - mmengine - INFO - Iter(train) [61300/90000]  base_lr: 3.5750e-05 lr: 3.5750e-06  eta: 4:48:13  time: 0.5951  data_time: 0.0106  memory: 10713  grad_norm: 375.2771  loss: 16.0882  decode.loss_cls: 0.0675  decode.loss_mask: 0.4635  decode.loss_dice: 1.0537  decode.d0.loss_cls: 0.0794  decode.d0.loss_mask: 0.4639  decode.d0.loss_dice: 1.1444  decode.d1.loss_cls: 0.0723  decode.d1.loss_mask: 0.4675  decode.d1.loss_dice: 1.0494  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.4706  decode.d2.loss_dice: 1.0745  decode.d3.loss_cls: 0.0779  decode.d3.loss_mask: 0.4669  decode.d3.loss_dice: 1.0574  decode.d4.loss_cls: 0.0782  decode.d4.loss_mask: 0.4683  decode.d4.loss_dice: 1.0857  decode.d5.loss_cls: 0.0780  decode.d5.loss_mask: 0.4697  decode.d5.loss_dice: 1.0680  decode.d6.loss_cls: 0.0731  decode.d6.loss_mask: 0.4628  decode.d6.loss_dice: 1.0591  decode.d7.loss_cls: 0.0808  decode.d7.loss_mask: 0.4623  decode.d7.loss_dice: 1.0489  decode.d8.loss_cls: 0.0723  decode.d8.loss_mask: 0.4669  decode.d8.loss_dice: 1.0321
11/15 17:33:23 - mmengine - INFO - Iter(train) [61350/90000]  base_lr: 3.5694e-05 lr: 3.5694e-06  eta: 4:47:42  time: 0.5950  data_time: 0.0106  memory: 10675  grad_norm: 639.8306  loss: 17.2811  decode.loss_cls: 0.0633  decode.loss_mask: 0.6608  decode.loss_dice: 0.9694  decode.d0.loss_cls: 0.1134  decode.d0.loss_mask: 0.7674  decode.d0.loss_dice: 1.0529  decode.d1.loss_cls: 0.0677  decode.d1.loss_mask: 0.7475  decode.d1.loss_dice: 1.0412  decode.d2.loss_cls: 0.0655  decode.d2.loss_mask: 0.6671  decode.d2.loss_dice: 0.9670  decode.d3.loss_cls: 0.0753  decode.d3.loss_mask: 0.6497  decode.d3.loss_dice: 0.9401  decode.d4.loss_cls: 0.0700  decode.d4.loss_mask: 0.6607  decode.d4.loss_dice: 0.9604  decode.d5.loss_cls: 0.0682  decode.d5.loss_mask: 0.6542  decode.d5.loss_dice: 0.9544  decode.d6.loss_cls: 0.0597  decode.d6.loss_mask: 0.6598  decode.d6.loss_dice: 0.9778  decode.d7.loss_cls: 0.0655  decode.d7.loss_mask: 0.6586  decode.d7.loss_dice: 0.9573  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 0.6603  decode.d8.loss_dice: 0.9661
11/15 17:33:53 - mmengine - INFO - Iter(train) [61400/90000]  base_lr: 3.5638e-05 lr: 3.5638e-06  eta: 4:47:12  time: 0.5959  data_time: 0.0106  memory: 10692  grad_norm: 405.7214  loss: 15.7497  decode.loss_cls: 0.0351  decode.loss_mask: 0.5569  decode.loss_dice: 0.9671  decode.d0.loss_cls: 0.0659  decode.d0.loss_mask: 0.5977  decode.d0.loss_dice: 1.0150  decode.d1.loss_cls: 0.0390  decode.d1.loss_mask: 0.5756  decode.d1.loss_dice: 0.9904  decode.d2.loss_cls: 0.0285  decode.d2.loss_mask: 0.5610  decode.d2.loss_dice: 0.9846  decode.d3.loss_cls: 0.0273  decode.d3.loss_mask: 0.5609  decode.d3.loss_dice: 0.9890  decode.d4.loss_cls: 0.0232  decode.d4.loss_mask: 0.5624  decode.d4.loss_dice: 0.9765  decode.d5.loss_cls: 0.0352  decode.d5.loss_mask: 0.5483  decode.d5.loss_dice: 0.9697  decode.d6.loss_cls: 0.0356  decode.d6.loss_mask: 0.5517  decode.d6.loss_dice: 0.9579  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.5412  decode.d7.loss_dice: 0.9592  decode.d8.loss_cls: 0.0345  decode.d8.loss_mask: 0.5578  decode.d8.loss_dice: 0.9642
11/15 17:34:23 - mmengine - INFO - Iter(train) [61450/90000]  base_lr: 3.5582e-05 lr: 3.5582e-06  eta: 4:46:42  time: 0.5958  data_time: 0.0107  memory: 10656  grad_norm: 321.2633  loss: 14.8715  decode.loss_cls: 0.0624  decode.loss_mask: 0.4163  decode.loss_dice: 0.9853  decode.d0.loss_cls: 0.0739  decode.d0.loss_mask: 0.4335  decode.d0.loss_dice: 1.1358  decode.d1.loss_cls: 0.0503  decode.d1.loss_mask: 0.4119  decode.d1.loss_dice: 1.0438  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.4069  decode.d2.loss_dice: 0.9966  decode.d3.loss_cls: 0.0610  decode.d3.loss_mask: 0.4104  decode.d3.loss_dice: 0.9944  decode.d4.loss_cls: 0.0670  decode.d4.loss_mask: 0.4131  decode.d4.loss_dice: 0.9778  decode.d5.loss_cls: 0.0636  decode.d5.loss_mask: 0.4107  decode.d5.loss_dice: 1.0143  decode.d6.loss_cls: 0.0713  decode.d6.loss_mask: 0.4073  decode.d6.loss_dice: 0.9916  decode.d7.loss_cls: 0.0590  decode.d7.loss_mask: 0.4089  decode.d7.loss_dice: 0.9708  decode.d8.loss_cls: 0.0661  decode.d8.loss_mask: 0.4084  decode.d8.loss_dice: 0.9886
11/15 17:34:53 - mmengine - INFO - Iter(train) [61500/90000]  base_lr: 3.5526e-05 lr: 3.5526e-06  eta: 4:46:12  time: 0.5966  data_time: 0.0107  memory: 10742  grad_norm: 282.4232  loss: 14.5344  decode.loss_cls: 0.0576  decode.loss_mask: 0.4015  decode.loss_dice: 0.9660  decode.d0.loss_cls: 0.0649  decode.d0.loss_mask: 0.4342  decode.d0.loss_dice: 1.0679  decode.d1.loss_cls: 0.0605  decode.d1.loss_mask: 0.4079  decode.d1.loss_dice: 0.9856  decode.d2.loss_cls: 0.0711  decode.d2.loss_mask: 0.4095  decode.d2.loss_dice: 1.0079  decode.d3.loss_cls: 0.0499  decode.d3.loss_mask: 0.4056  decode.d3.loss_dice: 0.9985  decode.d4.loss_cls: 0.0499  decode.d4.loss_mask: 0.4060  decode.d4.loss_dice: 0.9724  decode.d5.loss_cls: 0.0600  decode.d5.loss_mask: 0.4055  decode.d5.loss_dice: 0.9763  decode.d6.loss_cls: 0.0489  decode.d6.loss_mask: 0.4077  decode.d6.loss_dice: 0.9727  decode.d7.loss_cls: 0.0542  decode.d7.loss_mask: 0.4065  decode.d7.loss_dice: 0.9668  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.4042  decode.d8.loss_dice: 0.9544
11/15 17:35:22 - mmengine - INFO - Iter(train) [61550/90000]  base_lr: 3.5470e-05 lr: 3.5470e-06  eta: 4:45:41  time: 0.5954  data_time: 0.0106  memory: 10675  grad_norm: 532.8726  loss: 15.0063  decode.loss_cls: 0.0451  decode.loss_mask: 0.4327  decode.loss_dice: 0.9972  decode.d0.loss_cls: 0.0790  decode.d0.loss_mask: 0.4715  decode.d0.loss_dice: 1.0829  decode.d1.loss_cls: 0.0534  decode.d1.loss_mask: 0.4404  decode.d1.loss_dice: 1.0494  decode.d2.loss_cls: 0.0465  decode.d2.loss_mask: 0.4321  decode.d2.loss_dice: 1.0061  decode.d3.loss_cls: 0.0382  decode.d3.loss_mask: 0.4323  decode.d3.loss_dice: 1.0114  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.4358  decode.d4.loss_dice: 0.9958  decode.d5.loss_cls: 0.0466  decode.d5.loss_mask: 0.4299  decode.d5.loss_dice: 0.9851  decode.d6.loss_cls: 0.0428  decode.d6.loss_mask: 0.4293  decode.d6.loss_dice: 0.9887  decode.d7.loss_cls: 0.0447  decode.d7.loss_mask: 0.4330  decode.d7.loss_dice: 1.0126  decode.d8.loss_cls: 0.0409  decode.d8.loss_mask: 0.4307  decode.d8.loss_dice: 1.0334
11/15 17:35:52 - mmengine - INFO - Iter(train) [61600/90000]  base_lr: 3.5414e-05 lr: 3.5414e-06  eta: 4:45:11  time: 0.5961  data_time: 0.0103  memory: 10713  grad_norm: 582.0927  loss: 17.7453  decode.loss_cls: 0.0694  decode.loss_mask: 0.5410  decode.loss_dice: 1.1365  decode.d0.loss_cls: 0.1082  decode.d0.loss_mask: 0.5768  decode.d0.loss_dice: 1.2080  decode.d1.loss_cls: 0.0862  decode.d1.loss_mask: 0.5588  decode.d1.loss_dice: 1.1654  decode.d2.loss_cls: 0.0764  decode.d2.loss_mask: 0.5407  decode.d2.loss_dice: 1.1386  decode.d3.loss_cls: 0.0839  decode.d3.loss_mask: 0.5407  decode.d3.loss_dice: 1.1368  decode.d4.loss_cls: 0.0727  decode.d4.loss_mask: 0.5478  decode.d4.loss_dice: 1.1485  decode.d5.loss_cls: 0.0752  decode.d5.loss_mask: 0.5391  decode.d5.loss_dice: 1.1374  decode.d6.loss_cls: 0.0737  decode.d6.loss_mask: 0.5298  decode.d6.loss_dice: 1.1396  decode.d7.loss_cls: 0.0697  decode.d7.loss_mask: 0.5450  decode.d7.loss_dice: 1.1405  decode.d8.loss_cls: 0.0732  decode.d8.loss_mask: 0.5381  decode.d8.loss_dice: 1.1475
11/15 17:36:22 - mmengine - INFO - Iter(train) [61650/90000]  base_lr: 3.5358e-05 lr: 3.5358e-06  eta: 4:44:41  time: 0.5998  data_time: 0.0107  memory: 10675  grad_norm: 298.4248  loss: 15.6359  decode.loss_cls: 0.0674  decode.loss_mask: 0.4284  decode.loss_dice: 1.0525  decode.d0.loss_cls: 0.0823  decode.d0.loss_mask: 0.4436  decode.d0.loss_dice: 1.1320  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.4329  decode.d1.loss_dice: 1.0843  decode.d2.loss_cls: 0.0715  decode.d2.loss_mask: 0.4374  decode.d2.loss_dice: 1.0500  decode.d3.loss_cls: 0.0675  decode.d3.loss_mask: 0.4292  decode.d3.loss_dice: 1.0619  decode.d4.loss_cls: 0.0738  decode.d4.loss_mask: 0.4318  decode.d4.loss_dice: 1.0278  decode.d5.loss_cls: 0.0731  decode.d5.loss_mask: 0.4290  decode.d5.loss_dice: 1.0419  decode.d6.loss_cls: 0.0638  decode.d6.loss_mask: 0.4271  decode.d6.loss_dice: 1.0630  decode.d7.loss_cls: 0.0633  decode.d7.loss_mask: 0.4268  decode.d7.loss_dice: 1.0507  decode.d8.loss_cls: 0.0703  decode.d8.loss_mask: 0.4270  decode.d8.loss_dice: 1.0513
11/15 17:36:52 - mmengine - INFO - Iter(train) [61700/90000]  base_lr: 3.5302e-05 lr: 3.5302e-06  eta: 4:44:11  time: 0.5955  data_time: 0.0103  memory: 10675  grad_norm: 513.3495  loss: 15.9813  decode.loss_cls: 0.0530  decode.loss_mask: 0.4933  decode.loss_dice: 1.0011  decode.d0.loss_cls: 0.0775  decode.d0.loss_mask: 0.5287  decode.d0.loss_dice: 1.1207  decode.d1.loss_cls: 0.0635  decode.d1.loss_mask: 0.5049  decode.d1.loss_dice: 1.0672  decode.d2.loss_cls: 0.0648  decode.d2.loss_mask: 0.4952  decode.d2.loss_dice: 1.0357  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.4947  decode.d3.loss_dice: 1.0377  decode.d4.loss_cls: 0.0606  decode.d4.loss_mask: 0.4923  decode.d4.loss_dice: 1.0292  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.4912  decode.d5.loss_dice: 1.0349  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.4972  decode.d6.loss_dice: 1.0363  decode.d7.loss_cls: 0.0540  decode.d7.loss_mask: 0.4897  decode.d7.loss_dice: 1.0090  decode.d8.loss_cls: 0.0545  decode.d8.loss_mask: 0.4908  decode.d8.loss_dice: 1.0381
11/15 17:37:22 - mmengine - INFO - Iter(train) [61750/90000]  base_lr: 3.5245e-05 lr: 3.5245e-06  eta: 4:43:40  time: 0.5981  data_time: 0.0107  memory: 10675  grad_norm: 312.7473  loss: 17.4220  decode.loss_cls: 0.0580  decode.loss_mask: 0.5617  decode.loss_dice: 1.1318  decode.d0.loss_cls: 0.0692  decode.d0.loss_mask: 0.5416  decode.d0.loss_dice: 1.1697  decode.d1.loss_cls: 0.0454  decode.d1.loss_mask: 0.5358  decode.d1.loss_dice: 1.1567  decode.d2.loss_cls: 0.0340  decode.d2.loss_mask: 0.5460  decode.d2.loss_dice: 1.1712  decode.d3.loss_cls: 0.0502  decode.d3.loss_mask: 0.5475  decode.d3.loss_dice: 1.1460  decode.d4.loss_cls: 0.0526  decode.d4.loss_mask: 0.5427  decode.d4.loss_dice: 1.1435  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.5414  decode.d5.loss_dice: 1.1056  decode.d6.loss_cls: 0.0437  decode.d6.loss_mask: 0.5417  decode.d6.loss_dice: 1.1408  decode.d7.loss_cls: 0.0503  decode.d7.loss_mask: 0.5490  decode.d7.loss_dice: 1.1416  decode.d8.loss_cls: 0.0557  decode.d8.loss_mask: 0.5466  decode.d8.loss_dice: 1.1526
11/15 17:37:51 - mmengine - INFO - Iter(train) [61800/90000]  base_lr: 3.5189e-05 lr: 3.5189e-06  eta: 4:43:10  time: 0.5968  data_time: 0.0104  memory: 10626  grad_norm: 322.0425  loss: 16.4662  decode.loss_cls: 0.0761  decode.loss_mask: 0.5039  decode.loss_dice: 1.0364  decode.d0.loss_cls: 0.0814  decode.d0.loss_mask: 0.5374  decode.d0.loss_dice: 1.1704  decode.d1.loss_cls: 0.0515  decode.d1.loss_mask: 0.5187  decode.d1.loss_dice: 1.0836  decode.d2.loss_cls: 0.0694  decode.d2.loss_mask: 0.5149  decode.d2.loss_dice: 1.0837  decode.d3.loss_cls: 0.0723  decode.d3.loss_mask: 0.5075  decode.d3.loss_dice: 1.0449  decode.d4.loss_cls: 0.0727  decode.d4.loss_mask: 0.5045  decode.d4.loss_dice: 1.0279  decode.d5.loss_cls: 0.0750  decode.d5.loss_mask: 0.4945  decode.d5.loss_dice: 1.0250  decode.d6.loss_cls: 0.0758  decode.d6.loss_mask: 0.5056  decode.d6.loss_dice: 1.0446  decode.d7.loss_cls: 0.0648  decode.d7.loss_mask: 0.5068  decode.d7.loss_dice: 1.0649  decode.d8.loss_cls: 0.0740  decode.d8.loss_mask: 0.5091  decode.d8.loss_dice: 1.0689
11/15 17:38:21 - mmengine - INFO - Iter(train) [61850/90000]  base_lr: 3.5133e-05 lr: 3.5133e-06  eta: 4:42:40  time: 0.5965  data_time: 0.0104  memory: 10713  grad_norm: 279.9074  loss: 15.2186  decode.loss_cls: 0.0943  decode.loss_mask: 0.4169  decode.loss_dice: 1.0045  decode.d0.loss_cls: 0.1029  decode.d0.loss_mask: 0.4262  decode.d0.loss_dice: 1.0906  decode.d1.loss_cls: 0.0813  decode.d1.loss_mask: 0.4411  decode.d1.loss_dice: 1.0449  decode.d2.loss_cls: 0.0835  decode.d2.loss_mask: 0.4166  decode.d2.loss_dice: 1.0296  decode.d3.loss_cls: 0.0874  decode.d3.loss_mask: 0.3958  decode.d3.loss_dice: 0.9999  decode.d4.loss_cls: 0.0852  decode.d4.loss_mask: 0.4088  decode.d4.loss_dice: 1.0089  decode.d5.loss_cls: 0.0917  decode.d5.loss_mask: 0.3957  decode.d5.loss_dice: 1.0202  decode.d6.loss_cls: 0.0882  decode.d6.loss_mask: 0.3875  decode.d6.loss_dice: 0.9967  decode.d7.loss_cls: 0.0856  decode.d7.loss_mask: 0.4057  decode.d7.loss_dice: 1.0353  decode.d8.loss_cls: 0.0938  decode.d8.loss_mask: 0.4004  decode.d8.loss_dice: 0.9995
11/15 17:38:51 - mmengine - INFO - Iter(train) [61900/90000]  base_lr: 3.5077e-05 lr: 3.5077e-06  eta: 4:42:09  time: 0.5948  data_time: 0.0103  memory: 10656  grad_norm: 644.7106  loss: 16.2518  decode.loss_cls: 0.0816  decode.loss_mask: 0.5567  decode.loss_dice: 0.9663  decode.d0.loss_cls: 0.0915  decode.d0.loss_mask: 0.5784  decode.d0.loss_dice: 1.0787  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.5575  decode.d1.loss_dice: 1.0132  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.5709  decode.d2.loss_dice: 0.9820  decode.d3.loss_cls: 0.0766  decode.d3.loss_mask: 0.5601  decode.d3.loss_dice: 0.9706  decode.d4.loss_cls: 0.0669  decode.d4.loss_mask: 0.5594  decode.d4.loss_dice: 0.9843  decode.d5.loss_cls: 0.0781  decode.d5.loss_mask: 0.5629  decode.d5.loss_dice: 0.9612  decode.d6.loss_cls: 0.0799  decode.d6.loss_mask: 0.5541  decode.d6.loss_dice: 0.9650  decode.d7.loss_cls: 0.0737  decode.d7.loss_mask: 0.5495  decode.d7.loss_dice: 0.9712  decode.d8.loss_cls: 0.0741  decode.d8.loss_mask: 0.5633  decode.d8.loss_dice: 0.9764
11/15 17:39:21 - mmengine - INFO - Iter(train) [61950/90000]  base_lr: 3.5021e-05 lr: 3.5021e-06  eta: 4:41:39  time: 0.5962  data_time: 0.0106  memory: 10728  grad_norm: 438.1393  loss: 15.8195  decode.loss_cls: 0.0427  decode.loss_mask: 0.4692  decode.loss_dice: 1.0489  decode.d0.loss_cls: 0.0845  decode.d0.loss_mask: 0.4913  decode.d0.loss_dice: 1.0833  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 0.4843  decode.d1.loss_dice: 1.0894  decode.d2.loss_cls: 0.0601  decode.d2.loss_mask: 0.4766  decode.d2.loss_dice: 1.0610  decode.d3.loss_cls: 0.0430  decode.d3.loss_mask: 0.4773  decode.d3.loss_dice: 1.0528  decode.d4.loss_cls: 0.0425  decode.d4.loss_mask: 0.4682  decode.d4.loss_dice: 1.0376  decode.d5.loss_cls: 0.0549  decode.d5.loss_mask: 0.4685  decode.d5.loss_dice: 1.0608  decode.d6.loss_cls: 0.0476  decode.d6.loss_mask: 0.4670  decode.d6.loss_dice: 1.0366  decode.d7.loss_cls: 0.0427  decode.d7.loss_mask: 0.4669  decode.d7.loss_dice: 1.0421  decode.d8.loss_cls: 0.0491  decode.d8.loss_mask: 0.4696  decode.d8.loss_dice: 1.0407
11/15 17:39:51 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 17:39:51 - mmengine - INFO - Iter(train) [62000/90000]  base_lr: 3.4965e-05 lr: 3.4965e-06  eta: 4:41:09  time: 0.5952  data_time: 0.0104  memory: 10728  grad_norm: 304.9686  loss: 17.5836  decode.loss_cls: 0.0762  decode.loss_mask: 0.5934  decode.loss_dice: 1.0737  decode.d0.loss_cls: 0.0913  decode.d0.loss_mask: 0.6180  decode.d0.loss_dice: 1.1655  decode.d1.loss_cls: 0.0840  decode.d1.loss_mask: 0.5960  decode.d1.loss_dice: 1.0882  decode.d2.loss_cls: 0.0828  decode.d2.loss_mask: 0.5814  decode.d2.loss_dice: 1.1000  decode.d3.loss_cls: 0.0863  decode.d3.loss_mask: 0.5778  decode.d3.loss_dice: 1.0769  decode.d4.loss_cls: 0.0806  decode.d4.loss_mask: 0.5800  decode.d4.loss_dice: 1.0741  decode.d5.loss_cls: 0.0825  decode.d5.loss_mask: 0.5808  decode.d5.loss_dice: 1.0835  decode.d6.loss_cls: 0.0781  decode.d6.loss_mask: 0.5890  decode.d6.loss_dice: 1.0661  decode.d7.loss_cls: 0.0744  decode.d7.loss_mask: 0.5888  decode.d7.loss_dice: 1.0787  decode.d8.loss_cls: 0.0707  decode.d8.loss_mask: 0.5904  decode.d8.loss_dice: 1.0745
11/15 17:40:20 - mmengine - INFO - Iter(train) [62050/90000]  base_lr: 3.4908e-05 lr: 3.4908e-06  eta: 4:40:39  time: 0.5956  data_time: 0.0105  memory: 10675  grad_norm: 412.5406  loss: 16.4248  decode.loss_cls: 0.0406  decode.loss_mask: 0.4614  decode.loss_dice: 1.1129  decode.d0.loss_cls: 0.0725  decode.d0.loss_mask: 0.4946  decode.d0.loss_dice: 1.2030  decode.d1.loss_cls: 0.0427  decode.d1.loss_mask: 0.4986  decode.d1.loss_dice: 1.1358  decode.d2.loss_cls: 0.0428  decode.d2.loss_mask: 0.4687  decode.d2.loss_dice: 1.0914  decode.d3.loss_cls: 0.0458  decode.d3.loss_mask: 0.4561  decode.d3.loss_dice: 1.1135  decode.d4.loss_cls: 0.0408  decode.d4.loss_mask: 0.4668  decode.d4.loss_dice: 1.1461  decode.d5.loss_cls: 0.0420  decode.d5.loss_mask: 0.4604  decode.d5.loss_dice: 1.1151  decode.d6.loss_cls: 0.0382  decode.d6.loss_mask: 0.4795  decode.d6.loss_dice: 1.1178  decode.d7.loss_cls: 0.0361  decode.d7.loss_mask: 0.4749  decode.d7.loss_dice: 1.1198  decode.d8.loss_cls: 0.0399  decode.d8.loss_mask: 0.4698  decode.d8.loss_dice: 1.0972
11/15 17:40:50 - mmengine - INFO - Iter(train) [62100/90000]  base_lr: 3.4852e-05 lr: 3.4852e-06  eta: 4:40:08  time: 0.5955  data_time: 0.0106  memory: 10692  grad_norm: 552.5704  loss: 15.2525  decode.loss_cls: 0.0424  decode.loss_mask: 0.4780  decode.loss_dice: 0.9930  decode.d0.loss_cls: 0.0894  decode.d0.loss_mask: 0.4866  decode.d0.loss_dice: 1.0453  decode.d1.loss_cls: 0.0452  decode.d1.loss_mask: 0.4932  decode.d1.loss_dice: 1.0162  decode.d2.loss_cls: 0.0495  decode.d2.loss_mask: 0.4841  decode.d2.loss_dice: 1.0175  decode.d3.loss_cls: 0.0395  decode.d3.loss_mask: 0.4856  decode.d3.loss_dice: 0.9994  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.4760  decode.d4.loss_dice: 0.9985  decode.d5.loss_cls: 0.0559  decode.d5.loss_mask: 0.4706  decode.d5.loss_dice: 0.9755  decode.d6.loss_cls: 0.0436  decode.d6.loss_mask: 0.4666  decode.d6.loss_dice: 0.9832  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.4630  decode.d7.loss_dice: 0.9586  decode.d8.loss_cls: 0.0464  decode.d8.loss_mask: 0.4668  decode.d8.loss_dice: 0.9929
11/15 17:41:20 - mmengine - INFO - Iter(train) [62150/90000]  base_lr: 3.4796e-05 lr: 3.4796e-06  eta: 4:39:38  time: 0.5949  data_time: 0.0103  memory: 10713  grad_norm: 468.1844  loss: 14.4917  decode.loss_cls: 0.0512  decode.loss_mask: 0.4873  decode.loss_dice: 0.9135  decode.d0.loss_cls: 0.0811  decode.d0.loss_mask: 0.5115  decode.d0.loss_dice: 0.9682  decode.d1.loss_cls: 0.0688  decode.d1.loss_mask: 0.4934  decode.d1.loss_dice: 0.9050  decode.d2.loss_cls: 0.0540  decode.d2.loss_mask: 0.4854  decode.d2.loss_dice: 0.9367  decode.d3.loss_cls: 0.0449  decode.d3.loss_mask: 0.4876  decode.d3.loss_dice: 0.8777  decode.d4.loss_cls: 0.0440  decode.d4.loss_mask: 0.4867  decode.d4.loss_dice: 0.8845  decode.d5.loss_cls: 0.0497  decode.d5.loss_mask: 0.4843  decode.d5.loss_dice: 0.9100  decode.d6.loss_cls: 0.0525  decode.d6.loss_mask: 0.4856  decode.d6.loss_dice: 0.8970  decode.d7.loss_cls: 0.0509  decode.d7.loss_mask: 0.4859  decode.d7.loss_dice: 0.8872  decode.d8.loss_cls: 0.0536  decode.d8.loss_mask: 0.4916  decode.d8.loss_dice: 0.8617
11/15 17:41:50 - mmengine - INFO - Iter(train) [62200/90000]  base_lr: 3.4740e-05 lr: 3.4740e-06  eta: 4:39:08  time: 0.5953  data_time: 0.0103  memory: 10713  grad_norm: 328.8843  loss: 17.3533  decode.loss_cls: 0.0703  decode.loss_mask: 0.5072  decode.loss_dice: 1.1442  decode.d0.loss_cls: 0.0726  decode.d0.loss_mask: 0.5167  decode.d0.loss_dice: 1.2431  decode.d1.loss_cls: 0.0694  decode.d1.loss_mask: 0.5196  decode.d1.loss_dice: 1.1707  decode.d2.loss_cls: 0.0624  decode.d2.loss_mask: 0.5195  decode.d2.loss_dice: 1.1671  decode.d3.loss_cls: 0.0757  decode.d3.loss_mask: 0.5117  decode.d3.loss_dice: 1.1424  decode.d4.loss_cls: 0.0665  decode.d4.loss_mask: 0.5152  decode.d4.loss_dice: 1.1312  decode.d5.loss_cls: 0.0701  decode.d5.loss_mask: 0.5123  decode.d5.loss_dice: 1.1364  decode.d6.loss_cls: 0.0638  decode.d6.loss_mask: 0.5086  decode.d6.loss_dice: 1.1395  decode.d7.loss_cls: 0.0708  decode.d7.loss_mask: 0.5075  decode.d7.loss_dice: 1.1135  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.5164  decode.d8.loss_dice: 1.1487
11/15 17:42:20 - mmengine - INFO - Iter(train) [62250/90000]  base_lr: 3.4683e-05 lr: 3.4683e-06  eta: 4:38:38  time: 0.6187  data_time: 0.0236  memory: 10713  grad_norm: 529.3390  loss: 17.9775  decode.loss_cls: 0.0763  decode.loss_mask: 0.5708  decode.loss_dice: 1.1456  decode.d0.loss_cls: 0.1193  decode.d0.loss_mask: 0.5894  decode.d0.loss_dice: 1.1796  decode.d1.loss_cls: 0.0974  decode.d1.loss_mask: 0.5846  decode.d1.loss_dice: 1.1299  decode.d2.loss_cls: 0.0891  decode.d2.loss_mask: 0.5633  decode.d2.loss_dice: 1.1343  decode.d3.loss_cls: 0.0786  decode.d3.loss_mask: 0.5848  decode.d3.loss_dice: 1.1244  decode.d4.loss_cls: 0.0779  decode.d4.loss_mask: 0.5817  decode.d4.loss_dice: 1.1366  decode.d5.loss_cls: 0.0860  decode.d5.loss_mask: 0.5772  decode.d5.loss_dice: 1.1404  decode.d6.loss_cls: 0.0865  decode.d6.loss_mask: 0.5714  decode.d6.loss_dice: 1.1171  decode.d7.loss_cls: 0.0943  decode.d7.loss_mask: 0.5502  decode.d7.loss_dice: 1.1043  decode.d8.loss_cls: 0.0955  decode.d8.loss_mask: 0.5687  decode.d8.loss_dice: 1.1224
11/15 17:42:50 - mmengine - INFO - Iter(train) [62300/90000]  base_lr: 3.4627e-05 lr: 3.4627e-06  eta: 4:38:07  time: 0.5958  data_time: 0.0103  memory: 10713  grad_norm: 409.3207  loss: 17.5030  decode.loss_cls: 0.0586  decode.loss_mask: 0.5564  decode.loss_dice: 1.1040  decode.d0.loss_cls: 0.0791  decode.d0.loss_mask: 0.5863  decode.d0.loss_dice: 1.2506  decode.d1.loss_cls: 0.0649  decode.d1.loss_mask: 0.5612  decode.d1.loss_dice: 1.1428  decode.d2.loss_cls: 0.0714  decode.d2.loss_mask: 0.5599  decode.d2.loss_dice: 1.1277  decode.d3.loss_cls: 0.0813  decode.d3.loss_mask: 0.5471  decode.d3.loss_dice: 1.0952  decode.d4.loss_cls: 0.0732  decode.d4.loss_mask: 0.5530  decode.d4.loss_dice: 1.1067  decode.d5.loss_cls: 0.0726  decode.d5.loss_mask: 0.5523  decode.d5.loss_dice: 1.1144  decode.d6.loss_cls: 0.0677  decode.d6.loss_mask: 0.5517  decode.d6.loss_dice: 1.0892  decode.d7.loss_cls: 0.0704  decode.d7.loss_mask: 0.5485  decode.d7.loss_dice: 1.1020  decode.d8.loss_cls: 0.0832  decode.d8.loss_mask: 0.5458  decode.d8.loss_dice: 1.0856
11/15 17:43:20 - mmengine - INFO - Iter(train) [62350/90000]  base_lr: 3.4571e-05 lr: 3.4571e-06  eta: 4:37:37  time: 0.5955  data_time: 0.0104  memory: 10728  grad_norm: 229.0213  loss: 17.6035  decode.loss_cls: 0.0820  decode.loss_mask: 0.4982  decode.loss_dice: 1.1745  decode.d0.loss_cls: 0.0825  decode.d0.loss_mask: 0.5007  decode.d0.loss_dice: 1.2535  decode.d1.loss_cls: 0.0910  decode.d1.loss_mask: 0.4837  decode.d1.loss_dice: 1.1938  decode.d2.loss_cls: 0.0942  decode.d2.loss_mask: 0.4898  decode.d2.loss_dice: 1.2026  decode.d3.loss_cls: 0.0923  decode.d3.loss_mask: 0.4966  decode.d3.loss_dice: 1.1603  decode.d4.loss_cls: 0.0751  decode.d4.loss_mask: 0.5038  decode.d4.loss_dice: 1.1742  decode.d5.loss_cls: 0.0824  decode.d5.loss_mask: 0.5055  decode.d5.loss_dice: 1.1555  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 0.4982  decode.d6.loss_dice: 1.1403  decode.d7.loss_cls: 0.0856  decode.d7.loss_mask: 0.4945  decode.d7.loss_dice: 1.1573  decode.d8.loss_cls: 0.0954  decode.d8.loss_mask: 0.4984  decode.d8.loss_dice: 1.1491
11/15 17:43:49 - mmengine - INFO - Iter(train) [62400/90000]  base_lr: 3.4515e-05 lr: 3.4515e-06  eta: 4:37:07  time: 0.5966  data_time: 0.0105  memory: 10675  grad_norm: 389.2790  loss: 15.1263  decode.loss_cls: 0.0718  decode.loss_mask: 0.4473  decode.loss_dice: 0.9704  decode.d0.loss_cls: 0.1049  decode.d0.loss_mask: 0.4597  decode.d0.loss_dice: 1.0545  decode.d1.loss_cls: 0.0727  decode.d1.loss_mask: 0.4695  decode.d1.loss_dice: 1.0308  decode.d2.loss_cls: 0.0769  decode.d2.loss_mask: 0.4481  decode.d2.loss_dice: 1.0013  decode.d3.loss_cls: 0.0716  decode.d3.loss_mask: 0.4634  decode.d3.loss_dice: 0.9554  decode.d4.loss_cls: 0.0689  decode.d4.loss_mask: 0.4658  decode.d4.loss_dice: 0.9762  decode.d5.loss_cls: 0.0686  decode.d5.loss_mask: 0.4619  decode.d5.loss_dice: 0.9601  decode.d6.loss_cls: 0.0709  decode.d6.loss_mask: 0.4405  decode.d6.loss_dice: 0.9813  decode.d7.loss_cls: 0.0808  decode.d7.loss_mask: 0.4293  decode.d7.loss_dice: 0.9639  decode.d8.loss_cls: 0.0784  decode.d8.loss_mask: 0.4319  decode.d8.loss_dice: 0.9495
11/15 17:44:19 - mmengine - INFO - Iter(train) [62450/90000]  base_lr: 3.4458e-05 lr: 3.4458e-06  eta: 4:36:37  time: 0.5953  data_time: 0.0105  memory: 10656  grad_norm: 482.2539  loss: 16.8977  decode.loss_cls: 0.0649  decode.loss_mask: 0.5310  decode.loss_dice: 1.0407  decode.d0.loss_cls: 0.0944  decode.d0.loss_mask: 0.5502  decode.d0.loss_dice: 1.1381  decode.d1.loss_cls: 0.0739  decode.d1.loss_mask: 0.5374  decode.d1.loss_dice: 1.0594  decode.d2.loss_cls: 0.0742  decode.d2.loss_mask: 0.5418  decode.d2.loss_dice: 1.1176  decode.d3.loss_cls: 0.0723  decode.d3.loss_mask: 0.5372  decode.d3.loss_dice: 1.1001  decode.d4.loss_cls: 0.0764  decode.d4.loss_mask: 0.5407  decode.d4.loss_dice: 1.0719  decode.d5.loss_cls: 0.0661  decode.d5.loss_mask: 0.5463  decode.d5.loss_dice: 1.0794  decode.d6.loss_cls: 0.0740  decode.d6.loss_mask: 0.5447  decode.d6.loss_dice: 1.0501  decode.d7.loss_cls: 0.0734  decode.d7.loss_mask: 0.5358  decode.d7.loss_dice: 1.0435  decode.d8.loss_cls: 0.0663  decode.d8.loss_mask: 0.5409  decode.d8.loss_dice: 1.0550
11/15 17:44:49 - mmengine - INFO - Iter(train) [62500/90000]  base_lr: 3.4402e-05 lr: 3.4402e-06  eta: 4:36:06  time: 0.5943  data_time: 0.0105  memory: 10675  grad_norm: 383.0927  loss: 16.2629  decode.loss_cls: 0.0529  decode.loss_mask: 0.5971  decode.loss_dice: 0.9629  decode.d0.loss_cls: 0.0823  decode.d0.loss_mask: 0.6155  decode.d0.loss_dice: 1.0294  decode.d1.loss_cls: 0.0566  decode.d1.loss_mask: 0.5956  decode.d1.loss_dice: 1.0059  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 0.5998  decode.d2.loss_dice: 1.0187  decode.d3.loss_cls: 0.0475  decode.d3.loss_mask: 0.5890  decode.d3.loss_dice: 0.9594  decode.d4.loss_cls: 0.0464  decode.d4.loss_mask: 0.5930  decode.d4.loss_dice: 0.9482  decode.d5.loss_cls: 0.0511  decode.d5.loss_mask: 0.5867  decode.d5.loss_dice: 0.9689  decode.d6.loss_cls: 0.0445  decode.d6.loss_mask: 0.5880  decode.d6.loss_dice: 0.9584  decode.d7.loss_cls: 0.0487  decode.d7.loss_mask: 0.5873  decode.d7.loss_dice: 0.9726  decode.d8.loss_cls: 0.0554  decode.d8.loss_mask: 0.5942  decode.d8.loss_dice: 0.9604
11/15 17:45:19 - mmengine - INFO - Iter(train) [62550/90000]  base_lr: 3.4346e-05 lr: 3.4346e-06  eta: 4:35:36  time: 0.5938  data_time: 0.0103  memory: 10692  grad_norm: 569.8532  loss: 14.0230  decode.loss_cls: 0.0392  decode.loss_mask: 0.4665  decode.loss_dice: 0.8999  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 0.4934  decode.d0.loss_dice: 0.8982  decode.d1.loss_cls: 0.0460  decode.d1.loss_mask: 0.4746  decode.d1.loss_dice: 0.8809  decode.d2.loss_cls: 0.0433  decode.d2.loss_mask: 0.4644  decode.d2.loss_dice: 0.8778  decode.d3.loss_cls: 0.0465  decode.d3.loss_mask: 0.4620  decode.d3.loss_dice: 0.8923  decode.d4.loss_cls: 0.0385  decode.d4.loss_mask: 0.4714  decode.d4.loss_dice: 0.8753  decode.d5.loss_cls: 0.0427  decode.d5.loss_mask: 0.4643  decode.d5.loss_dice: 0.8993  decode.d6.loss_cls: 0.0429  decode.d6.loss_mask: 0.4640  decode.d6.loss_dice: 0.8977  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.4637  decode.d7.loss_dice: 0.8884  decode.d8.loss_cls: 0.0402  decode.d8.loss_mask: 0.4623  decode.d8.loss_dice: 0.8703
11/15 17:45:49 - mmengine - INFO - Iter(train) [62600/90000]  base_lr: 3.4290e-05 lr: 3.4290e-06  eta: 4:35:06  time: 0.5957  data_time: 0.0102  memory: 10656  grad_norm: 320.4611  loss: 17.1927  decode.loss_cls: 0.0764  decode.loss_mask: 0.5492  decode.loss_dice: 1.0734  decode.d0.loss_cls: 0.0968  decode.d0.loss_mask: 0.6307  decode.d0.loss_dice: 1.1442  decode.d1.loss_cls: 0.0774  decode.d1.loss_mask: 0.5659  decode.d1.loss_dice: 1.1005  decode.d2.loss_cls: 0.0801  decode.d2.loss_mask: 0.5648  decode.d2.loss_dice: 1.1116  decode.d3.loss_cls: 0.0796  decode.d3.loss_mask: 0.5561  decode.d3.loss_dice: 1.0665  decode.d4.loss_cls: 0.0776  decode.d4.loss_mask: 0.5258  decode.d4.loss_dice: 1.0690  decode.d5.loss_cls: 0.0870  decode.d5.loss_mask: 0.5611  decode.d5.loss_dice: 1.0651  decode.d6.loss_cls: 0.0817  decode.d6.loss_mask: 0.5241  decode.d6.loss_dice: 1.0683  decode.d7.loss_cls: 0.0690  decode.d7.loss_mask: 0.5281  decode.d7.loss_dice: 1.0753  decode.d8.loss_cls: 0.0684  decode.d8.loss_mask: 0.5523  decode.d8.loss_dice: 1.0667
11/15 17:46:19 - mmengine - INFO - Iter(train) [62650/90000]  base_lr: 3.4233e-05 lr: 3.4233e-06  eta: 4:34:36  time: 0.5956  data_time: 0.0104  memory: 10713  grad_norm: 298.3671  loss: 16.4358  decode.loss_cls: 0.0767  decode.loss_mask: 0.4692  decode.loss_dice: 1.0899  decode.d0.loss_cls: 0.0947  decode.d0.loss_mask: 0.4524  decode.d0.loss_dice: 1.1638  decode.d1.loss_cls: 0.0752  decode.d1.loss_mask: 0.4397  decode.d1.loss_dice: 1.1465  decode.d2.loss_cls: 0.0659  decode.d2.loss_mask: 0.4454  decode.d2.loss_dice: 1.1280  decode.d3.loss_cls: 0.0650  decode.d3.loss_mask: 0.4470  decode.d3.loss_dice: 1.1152  decode.d4.loss_cls: 0.0647  decode.d4.loss_mask: 0.4603  decode.d4.loss_dice: 1.1190  decode.d5.loss_cls: 0.0658  decode.d5.loss_mask: 0.4726  decode.d5.loss_dice: 1.1075  decode.d6.loss_cls: 0.0756  decode.d6.loss_mask: 0.4600  decode.d6.loss_dice: 1.0827  decode.d7.loss_cls: 0.0759  decode.d7.loss_mask: 0.4581  decode.d7.loss_dice: 1.1101  decode.d8.loss_cls: 0.0779  decode.d8.loss_mask: 0.4398  decode.d8.loss_dice: 1.0911
11/15 17:46:48 - mmengine - INFO - Iter(train) [62700/90000]  base_lr: 3.4177e-05 lr: 3.4177e-06  eta: 4:34:05  time: 0.5961  data_time: 0.0105  memory: 10675  grad_norm: 482.8388  loss: 16.4946  decode.loss_cls: 0.0568  decode.loss_mask: 0.4881  decode.loss_dice: 1.0983  decode.d0.loss_cls: 0.0739  decode.d0.loss_mask: 0.5009  decode.d0.loss_dice: 1.1482  decode.d1.loss_cls: 0.0502  decode.d1.loss_mask: 0.4943  decode.d1.loss_dice: 1.1058  decode.d2.loss_cls: 0.0592  decode.d2.loss_mask: 0.4952  decode.d2.loss_dice: 1.1204  decode.d3.loss_cls: 0.0584  decode.d3.loss_mask: 0.4860  decode.d3.loss_dice: 1.0919  decode.d4.loss_cls: 0.0653  decode.d4.loss_mask: 0.4864  decode.d4.loss_dice: 1.0935  decode.d5.loss_cls: 0.0681  decode.d5.loss_mask: 0.4911  decode.d5.loss_dice: 1.0894  decode.d6.loss_cls: 0.0696  decode.d6.loss_mask: 0.4824  decode.d6.loss_dice: 1.0561  decode.d7.loss_cls: 0.0641  decode.d7.loss_mask: 0.4862  decode.d7.loss_dice: 1.0802  decode.d8.loss_cls: 0.0596  decode.d8.loss_mask: 0.4896  decode.d8.loss_dice: 1.0855
11/15 17:47:18 - mmengine - INFO - Iter(train) [62750/90000]  base_lr: 3.4121e-05 lr: 3.4121e-06  eta: 4:33:35  time: 0.5952  data_time: 0.0104  memory: 10675  grad_norm: 355.9874  loss: 17.1165  decode.loss_cls: 0.0678  decode.loss_mask: 0.4844  decode.loss_dice: 1.1243  decode.d0.loss_cls: 0.0953  decode.d0.loss_mask: 0.5133  decode.d0.loss_dice: 1.2178  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.5040  decode.d1.loss_dice: 1.2001  decode.d2.loss_cls: 0.0595  decode.d2.loss_mask: 0.5080  decode.d2.loss_dice: 1.1838  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.4951  decode.d3.loss_dice: 1.1266  decode.d4.loss_cls: 0.0681  decode.d4.loss_mask: 0.4969  decode.d4.loss_dice: 1.1330  decode.d5.loss_cls: 0.0652  decode.d5.loss_mask: 0.4936  decode.d5.loss_dice: 1.1343  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.4915  decode.d6.loss_dice: 1.1289  decode.d7.loss_cls: 0.0518  decode.d7.loss_mask: 0.4891  decode.d7.loss_dice: 1.1229  decode.d8.loss_cls: 0.0706  decode.d8.loss_mask: 0.4926  decode.d8.loss_dice: 1.1172
11/15 17:47:48 - mmengine - INFO - Iter(train) [62800/90000]  base_lr: 3.4064e-05 lr: 3.4064e-06  eta: 4:33:05  time: 0.5953  data_time: 0.0105  memory: 10728  grad_norm: 343.8844  loss: 16.4049  decode.loss_cls: 0.0470  decode.loss_mask: 0.4857  decode.loss_dice: 1.0759  decode.d0.loss_cls: 0.0728  decode.d0.loss_mask: 0.5293  decode.d0.loss_dice: 1.1271  decode.d1.loss_cls: 0.0740  decode.d1.loss_mask: 0.5042  decode.d1.loss_dice: 1.0974  decode.d2.loss_cls: 0.0593  decode.d2.loss_mask: 0.4996  decode.d2.loss_dice: 1.1065  decode.d3.loss_cls: 0.0505  decode.d3.loss_mask: 0.4918  decode.d3.loss_dice: 1.0854  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.4939  decode.d4.loss_dice: 1.0871  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.4982  decode.d5.loss_dice: 1.0537  decode.d6.loss_cls: 0.0466  decode.d6.loss_mask: 0.4930  decode.d6.loss_dice: 1.0915  decode.d7.loss_cls: 0.0485  decode.d7.loss_mask: 0.4974  decode.d7.loss_dice: 1.0792  decode.d8.loss_cls: 0.0551  decode.d8.loss_mask: 0.4922  decode.d8.loss_dice: 1.0474
11/15 17:48:18 - mmengine - INFO - Iter(train) [62850/90000]  base_lr: 3.4008e-05 lr: 3.4008e-06  eta: 4:32:35  time: 0.5956  data_time: 0.0103  memory: 10713  grad_norm: 330.0548  loss: 15.1423  decode.loss_cls: 0.0680  decode.loss_mask: 0.4045  decode.loss_dice: 1.0202  decode.d0.loss_cls: 0.1038  decode.d0.loss_mask: 0.4171  decode.d0.loss_dice: 1.1054  decode.d1.loss_cls: 0.0733  decode.d1.loss_mask: 0.4068  decode.d1.loss_dice: 1.0844  decode.d2.loss_cls: 0.0956  decode.d2.loss_mask: 0.4081  decode.d2.loss_dice: 1.0453  decode.d3.loss_cls: 0.0734  decode.d3.loss_mask: 0.4065  decode.d3.loss_dice: 1.0103  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.4054  decode.d4.loss_dice: 1.0325  decode.d5.loss_cls: 0.0757  decode.d5.loss_mask: 0.4086  decode.d5.loss_dice: 1.0060  decode.d6.loss_cls: 0.0776  decode.d6.loss_mask: 0.4008  decode.d6.loss_dice: 1.0007  decode.d7.loss_cls: 0.0737  decode.d7.loss_mask: 0.4029  decode.d7.loss_dice: 1.0007  decode.d8.loss_cls: 0.0664  decode.d8.loss_mask: 0.4013  decode.d8.loss_dice: 1.0010
11/15 17:48:48 - mmengine - INFO - Iter(train) [62900/90000]  base_lr: 3.3951e-05 lr: 3.3951e-06  eta: 4:32:04  time: 0.5962  data_time: 0.0103  memory: 10675  grad_norm: 1802.3696  loss: 16.0556  decode.loss_cls: 0.0481  decode.loss_mask: 0.5186  decode.loss_dice: 1.0178  decode.d0.loss_cls: 0.0736  decode.d0.loss_mask: 0.5290  decode.d0.loss_dice: 1.0919  decode.d1.loss_cls: 0.0648  decode.d1.loss_mask: 0.5342  decode.d1.loss_dice: 1.0753  decode.d2.loss_cls: 0.0641  decode.d2.loss_mask: 0.5225  decode.d2.loss_dice: 1.0114  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.5101  decode.d3.loss_dice: 1.0074  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.5133  decode.d4.loss_dice: 1.0289  decode.d5.loss_cls: 0.0517  decode.d5.loss_mask: 0.5210  decode.d5.loss_dice: 1.0103  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.5131  decode.d6.loss_dice: 1.0084  decode.d7.loss_cls: 0.0472  decode.d7.loss_mask: 0.5177  decode.d7.loss_dice: 1.0147  decode.d8.loss_cls: 0.0432  decode.d8.loss_mask: 0.5209  decode.d8.loss_dice: 1.0264
11/15 17:49:17 - mmengine - INFO - Iter(train) [62950/90000]  base_lr: 3.3895e-05 lr: 3.3895e-06  eta: 4:31:34  time: 0.5945  data_time: 0.0103  memory: 10675  grad_norm: 291.9457  loss: 17.4511  decode.loss_cls: 0.0614  decode.loss_mask: 0.5637  decode.loss_dice: 1.1178  decode.d0.loss_cls: 0.0871  decode.d0.loss_mask: 0.5974  decode.d0.loss_dice: 1.1246  decode.d1.loss_cls: 0.0742  decode.d1.loss_mask: 0.5759  decode.d1.loss_dice: 1.1346  decode.d2.loss_cls: 0.0808  decode.d2.loss_mask: 0.5610  decode.d2.loss_dice: 1.0826  decode.d3.loss_cls: 0.0749  decode.d3.loss_mask: 0.5586  decode.d3.loss_dice: 1.0892  decode.d4.loss_cls: 0.0659  decode.d4.loss_mask: 0.5655  decode.d4.loss_dice: 1.0911  decode.d5.loss_cls: 0.0621  decode.d5.loss_mask: 0.5646  decode.d5.loss_dice: 1.1046  decode.d6.loss_cls: 0.0620  decode.d6.loss_mask: 0.5656  decode.d6.loss_dice: 1.1204  decode.d7.loss_cls: 0.0569  decode.d7.loss_mask: 0.5841  decode.d7.loss_dice: 1.1060  decode.d8.loss_cls: 0.0631  decode.d8.loss_mask: 0.5561  decode.d8.loss_dice: 1.0992
11/15 17:49:47 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 17:49:47 - mmengine - INFO - Iter(train) [63000/90000]  base_lr: 3.3839e-05 lr: 3.3839e-06  eta: 4:31:04  time: 0.5948  data_time: 0.0104  memory: 10675  grad_norm: 397.8269  loss: 14.6627  decode.loss_cls: 0.0744  decode.loss_mask: 0.4167  decode.loss_dice: 0.9889  decode.d0.loss_cls: 0.1190  decode.d0.loss_mask: 0.4160  decode.d0.loss_dice: 1.0445  decode.d1.loss_cls: 0.0830  decode.d1.loss_mask: 0.4090  decode.d1.loss_dice: 0.9975  decode.d2.loss_cls: 0.0774  decode.d2.loss_mask: 0.4042  decode.d2.loss_dice: 0.9870  decode.d3.loss_cls: 0.0771  decode.d3.loss_mask: 0.4075  decode.d3.loss_dice: 0.9551  decode.d4.loss_cls: 0.0793  decode.d4.loss_mask: 0.4010  decode.d4.loss_dice: 0.9579  decode.d5.loss_cls: 0.0739  decode.d5.loss_mask: 0.4085  decode.d5.loss_dice: 0.9753  decode.d6.loss_cls: 0.0686  decode.d6.loss_mask: 0.4098  decode.d6.loss_dice: 0.9875  decode.d7.loss_cls: 0.0805  decode.d7.loss_mask: 0.3985  decode.d7.loss_dice: 0.9255  decode.d8.loss_cls: 0.0870  decode.d8.loss_mask: 0.3949  decode.d8.loss_dice: 0.9572
11/15 17:50:17 - mmengine - INFO - Iter(train) [63050/90000]  base_lr: 3.3782e-05 lr: 3.3782e-06  eta: 4:30:33  time: 0.5959  data_time: 0.0103  memory: 10713  grad_norm: 688.8991  loss: 14.9621  decode.loss_cls: 0.0682  decode.loss_mask: 0.4400  decode.loss_dice: 0.9731  decode.d0.loss_cls: 0.0985  decode.d0.loss_mask: 0.4351  decode.d0.loss_dice: 1.0382  decode.d1.loss_cls: 0.0800  decode.d1.loss_mask: 0.4323  decode.d1.loss_dice: 0.9560  decode.d2.loss_cls: 0.0618  decode.d2.loss_mask: 0.4413  decode.d2.loss_dice: 0.9916  decode.d3.loss_cls: 0.0610  decode.d3.loss_mask: 0.4405  decode.d3.loss_dice: 1.0073  decode.d4.loss_cls: 0.0579  decode.d4.loss_mask: 0.4416  decode.d4.loss_dice: 1.0113  decode.d5.loss_cls: 0.0638  decode.d5.loss_mask: 0.4386  decode.d5.loss_dice: 0.9840  decode.d6.loss_cls: 0.0635  decode.d6.loss_mask: 0.4374  decode.d6.loss_dice: 0.9686  decode.d7.loss_cls: 0.0589  decode.d7.loss_mask: 0.4425  decode.d7.loss_dice: 0.9950  decode.d8.loss_cls: 0.0662  decode.d8.loss_mask: 0.4333  decode.d8.loss_dice: 0.9749
11/15 17:50:47 - mmengine - INFO - Iter(train) [63100/90000]  base_lr: 3.3726e-05 lr: 3.3726e-06  eta: 4:30:03  time: 0.5956  data_time: 0.0105  memory: 10641  grad_norm: 356.1307  loss: 14.9605  decode.loss_cls: 0.0511  decode.loss_mask: 0.4337  decode.loss_dice: 1.0112  decode.d0.loss_cls: 0.0926  decode.d0.loss_mask: 0.4462  decode.d0.loss_dice: 1.0374  decode.d1.loss_cls: 0.0713  decode.d1.loss_mask: 0.4368  decode.d1.loss_dice: 0.9950  decode.d2.loss_cls: 0.0595  decode.d2.loss_mask: 0.4326  decode.d2.loss_dice: 0.9879  decode.d3.loss_cls: 0.0562  decode.d3.loss_mask: 0.4239  decode.d3.loss_dice: 1.0028  decode.d4.loss_cls: 0.0504  decode.d4.loss_mask: 0.4267  decode.d4.loss_dice: 0.9794  decode.d5.loss_cls: 0.0592  decode.d5.loss_mask: 0.4362  decode.d5.loss_dice: 0.9920  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.4281  decode.d6.loss_dice: 1.0195  decode.d7.loss_cls: 0.0519  decode.d7.loss_mask: 0.4257  decode.d7.loss_dice: 0.9941  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.4359  decode.d8.loss_dice: 1.0099
11/15 17:51:17 - mmengine - INFO - Iter(train) [63150/90000]  base_lr: 3.3669e-05 lr: 3.3669e-06  eta: 4:29:33  time: 0.5954  data_time: 0.0104  memory: 10713  grad_norm: 275.8165  loss: 15.7556  decode.loss_cls: 0.0413  decode.loss_mask: 0.4837  decode.loss_dice: 1.0335  decode.d0.loss_cls: 0.0665  decode.d0.loss_mask: 0.5061  decode.d0.loss_dice: 1.0348  decode.d1.loss_cls: 0.0517  decode.d1.loss_mask: 0.4907  decode.d1.loss_dice: 1.0583  decode.d2.loss_cls: 0.0439  decode.d2.loss_mask: 0.4831  decode.d2.loss_dice: 1.0464  decode.d3.loss_cls: 0.0492  decode.d3.loss_mask: 0.4880  decode.d3.loss_dice: 1.0317  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 0.4840  decode.d4.loss_dice: 1.0291  decode.d5.loss_cls: 0.0534  decode.d5.loss_mask: 0.4870  decode.d5.loss_dice: 1.0320  decode.d6.loss_cls: 0.0390  decode.d6.loss_mask: 0.4875  decode.d6.loss_dice: 1.0415  decode.d7.loss_cls: 0.0450  decode.d7.loss_mask: 0.4866  decode.d7.loss_dice: 1.0421  decode.d8.loss_cls: 0.0313  decode.d8.loss_mask: 0.4878  decode.d8.loss_dice: 1.0541
11/15 17:51:46 - mmengine - INFO - Iter(train) [63200/90000]  base_lr: 3.3613e-05 lr: 3.3613e-06  eta: 4:29:03  time: 0.5964  data_time: 0.0105  memory: 10656  grad_norm: 354.8629  loss: 17.0617  decode.loss_cls: 0.0782  decode.loss_mask: 0.5004  decode.loss_dice: 1.0618  decode.d0.loss_cls: 0.0853  decode.d0.loss_mask: 0.5706  decode.d0.loss_dice: 1.2237  decode.d1.loss_cls: 0.0850  decode.d1.loss_mask: 0.5134  decode.d1.loss_dice: 1.1294  decode.d2.loss_cls: 0.0679  decode.d2.loss_mask: 0.5164  decode.d2.loss_dice: 1.1379  decode.d3.loss_cls: 0.0778  decode.d3.loss_mask: 0.5185  decode.d3.loss_dice: 1.0862  decode.d4.loss_cls: 0.0674  decode.d4.loss_mask: 0.5093  decode.d4.loss_dice: 1.1137  decode.d5.loss_cls: 0.0732  decode.d5.loss_mask: 0.5076  decode.d5.loss_dice: 1.1040  decode.d6.loss_cls: 0.0747  decode.d6.loss_mask: 0.5091  decode.d6.loss_dice: 1.1008  decode.d7.loss_cls: 0.0682  decode.d7.loss_mask: 0.5124  decode.d7.loss_dice: 1.0871  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.5019  decode.d8.loss_dice: 1.1057
11/15 17:52:16 - mmengine - INFO - Iter(train) [63250/90000]  base_lr: 3.3557e-05 lr: 3.3557e-06  eta: 4:28:32  time: 0.5945  data_time: 0.0104  memory: 10713  grad_norm: 274.9307  loss: 13.9669  decode.loss_cls: 0.0506  decode.loss_mask: 0.4122  decode.loss_dice: 0.8963  decode.d0.loss_cls: 0.0838  decode.d0.loss_mask: 0.4493  decode.d0.loss_dice: 0.9967  decode.d1.loss_cls: 0.0534  decode.d1.loss_mask: 0.4384  decode.d1.loss_dice: 0.9316  decode.d2.loss_cls: 0.0534  decode.d2.loss_mask: 0.4288  decode.d2.loss_dice: 0.9176  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.4323  decode.d3.loss_dice: 0.9093  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.4317  decode.d4.loss_dice: 0.8899  decode.d5.loss_cls: 0.0538  decode.d5.loss_mask: 0.4188  decode.d5.loss_dice: 0.9041  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.4117  decode.d6.loss_dice: 0.8987  decode.d7.loss_cls: 0.0529  decode.d7.loss_mask: 0.4124  decode.d7.loss_dice: 0.9065  decode.d8.loss_cls: 0.0451  decode.d8.loss_mask: 0.4307  decode.d8.loss_dice: 0.9008
11/15 17:52:46 - mmengine - INFO - Iter(train) [63300/90000]  base_lr: 3.3500e-05 lr: 3.3500e-06  eta: 4:28:02  time: 0.5946  data_time: 0.0104  memory: 10656  grad_norm: 336.7640  loss: 14.7565  decode.loss_cls: 0.0530  decode.loss_mask: 0.4539  decode.loss_dice: 0.9480  decode.d0.loss_cls: 0.0835  decode.d0.loss_mask: 0.5153  decode.d0.loss_dice: 1.0359  decode.d1.loss_cls: 0.0627  decode.d1.loss_mask: 0.4542  decode.d1.loss_dice: 0.9878  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.4494  decode.d2.loss_dice: 0.9700  decode.d3.loss_cls: 0.0500  decode.d3.loss_mask: 0.4554  decode.d3.loss_dice: 0.9179  decode.d4.loss_cls: 0.0498  decode.d4.loss_mask: 0.4907  decode.d4.loss_dice: 0.9355  decode.d5.loss_cls: 0.0491  decode.d5.loss_mask: 0.4623  decode.d5.loss_dice: 0.9513  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.4535  decode.d6.loss_dice: 0.9384  decode.d7.loss_cls: 0.0581  decode.d7.loss_mask: 0.4579  decode.d7.loss_dice: 0.9318  decode.d8.loss_cls: 0.0747  decode.d8.loss_mask: 0.4443  decode.d8.loss_dice: 0.9123
11/15 17:53:16 - mmengine - INFO - Iter(train) [63350/90000]  base_lr: 3.3444e-05 lr: 3.3444e-06  eta: 4:27:32  time: 0.5947  data_time: 0.0103  memory: 10692  grad_norm: 344.1447  loss: 17.0608  decode.loss_cls: 0.0740  decode.loss_mask: 0.4513  decode.loss_dice: 1.1367  decode.d0.loss_cls: 0.0957  decode.d0.loss_mask: 0.4632  decode.d0.loss_dice: 1.2779  decode.d1.loss_cls: 0.0868  decode.d1.loss_mask: 0.4526  decode.d1.loss_dice: 1.2050  decode.d2.loss_cls: 0.0861  decode.d2.loss_mask: 0.4469  decode.d2.loss_dice: 1.1675  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.4575  decode.d3.loss_dice: 1.1447  decode.d4.loss_cls: 0.0749  decode.d4.loss_mask: 0.4788  decode.d4.loss_dice: 1.1484  decode.d5.loss_cls: 0.0809  decode.d5.loss_mask: 0.4847  decode.d5.loss_dice: 1.1539  decode.d6.loss_cls: 0.0736  decode.d6.loss_mask: 0.4731  decode.d6.loss_dice: 1.1527  decode.d7.loss_cls: 0.0761  decode.d7.loss_mask: 0.4694  decode.d7.loss_dice: 1.1309  decode.d8.loss_cls: 0.0739  decode.d8.loss_mask: 0.4438  decode.d8.loss_dice: 1.1192
11/15 17:53:46 - mmengine - INFO - Iter(train) [63400/90000]  base_lr: 3.3387e-05 lr: 3.3387e-06  eta: 4:27:02  time: 0.5955  data_time: 0.0103  memory: 10675  grad_norm: 702.5428  loss: 15.3352  decode.loss_cls: 0.0602  decode.loss_mask: 0.4623  decode.loss_dice: 0.9803  decode.d0.loss_cls: 0.0812  decode.d0.loss_mask: 0.4890  decode.d0.loss_dice: 1.0510  decode.d1.loss_cls: 0.0536  decode.d1.loss_mask: 0.4653  decode.d1.loss_dice: 0.9950  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.4614  decode.d2.loss_dice: 1.0004  decode.d3.loss_cls: 0.0487  decode.d3.loss_mask: 0.4774  decode.d3.loss_dice: 0.9894  decode.d4.loss_cls: 0.0524  decode.d4.loss_mask: 0.4778  decode.d4.loss_dice: 1.0015  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.4747  decode.d5.loss_dice: 0.9970  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.4668  decode.d6.loss_dice: 1.0050  decode.d7.loss_cls: 0.0558  decode.d7.loss_mask: 0.4784  decode.d7.loss_dice: 1.0107  decode.d8.loss_cls: 0.0527  decode.d8.loss_mask: 0.4822  decode.d8.loss_dice: 1.0044
11/15 17:54:15 - mmengine - INFO - Iter(train) [63450/90000]  base_lr: 3.3331e-05 lr: 3.3331e-06  eta: 4:26:31  time: 0.5951  data_time: 0.0105  memory: 10692  grad_norm: 861.1828  loss: 15.6125  decode.loss_cls: 0.0556  decode.loss_mask: 0.4698  decode.loss_dice: 0.9976  decode.d0.loss_cls: 0.0733  decode.d0.loss_mask: 0.4832  decode.d0.loss_dice: 1.1442  decode.d1.loss_cls: 0.0640  decode.d1.loss_mask: 0.4868  decode.d1.loss_dice: 1.0480  decode.d2.loss_cls: 0.0630  decode.d2.loss_mask: 0.4707  decode.d2.loss_dice: 1.0466  decode.d3.loss_cls: 0.0578  decode.d3.loss_mask: 0.4753  decode.d3.loss_dice: 1.0217  decode.d4.loss_cls: 0.0599  decode.d4.loss_mask: 0.4781  decode.d4.loss_dice: 0.9943  decode.d5.loss_cls: 0.0519  decode.d5.loss_mask: 0.4744  decode.d5.loss_dice: 1.0203  decode.d6.loss_cls: 0.0544  decode.d6.loss_mask: 0.4669  decode.d6.loss_dice: 1.0016  decode.d7.loss_cls: 0.0569  decode.d7.loss_mask: 0.4714  decode.d7.loss_dice: 1.0047  decode.d8.loss_cls: 0.0477  decode.d8.loss_mask: 0.4752  decode.d8.loss_dice: 0.9972
11/15 17:54:45 - mmengine - INFO - Iter(train) [63500/90000]  base_lr: 3.3274e-05 lr: 3.3274e-06  eta: 4:26:01  time: 0.5973  data_time: 0.0106  memory: 10656  grad_norm: 231.6677  loss: 15.8576  decode.loss_cls: 0.0655  decode.loss_mask: 0.4554  decode.loss_dice: 1.0557  decode.d0.loss_cls: 0.0916  decode.d0.loss_mask: 0.4716  decode.d0.loss_dice: 1.1209  decode.d1.loss_cls: 0.0598  decode.d1.loss_mask: 0.4703  decode.d1.loss_dice: 1.0733  decode.d2.loss_cls: 0.0513  decode.d2.loss_mask: 0.4633  decode.d2.loss_dice: 1.0889  decode.d3.loss_cls: 0.0588  decode.d3.loss_mask: 0.4613  decode.d3.loss_dice: 1.0561  decode.d4.loss_cls: 0.0633  decode.d4.loss_mask: 0.4599  decode.d4.loss_dice: 1.0570  decode.d5.loss_cls: 0.0521  decode.d5.loss_mask: 0.4569  decode.d5.loss_dice: 1.0549  decode.d6.loss_cls: 0.0679  decode.d6.loss_mask: 0.4484  decode.d6.loss_dice: 1.0456  decode.d7.loss_cls: 0.0673  decode.d7.loss_mask: 0.4429  decode.d7.loss_dice: 1.0402  decode.d8.loss_cls: 0.0707  decode.d8.loss_mask: 0.4463  decode.d8.loss_dice: 1.0404
11/15 17:55:15 - mmengine - INFO - Iter(train) [63550/90000]  base_lr: 3.3218e-05 lr: 3.3218e-06  eta: 4:25:31  time: 0.5967  data_time: 0.0106  memory: 10656  grad_norm: 527.5018  loss: 16.0686  decode.loss_cls: 0.0611  decode.loss_mask: 0.5105  decode.loss_dice: 1.0416  decode.d0.loss_cls: 0.0821  decode.d0.loss_mask: 0.5289  decode.d0.loss_dice: 1.1178  decode.d1.loss_cls: 0.0601  decode.d1.loss_mask: 0.5036  decode.d1.loss_dice: 1.0467  decode.d2.loss_cls: 0.0535  decode.d2.loss_mask: 0.5011  decode.d2.loss_dice: 1.0272  decode.d3.loss_cls: 0.0592  decode.d3.loss_mask: 0.4998  decode.d3.loss_dice: 1.0080  decode.d4.loss_cls: 0.0532  decode.d4.loss_mask: 0.5034  decode.d4.loss_dice: 1.0227  decode.d5.loss_cls: 0.0528  decode.d5.loss_mask: 0.5084  decode.d5.loss_dice: 1.0392  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.5079  decode.d6.loss_dice: 1.0385  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.4996  decode.d7.loss_dice: 1.0145  decode.d8.loss_cls: 0.0627  decode.d8.loss_mask: 0.5049  decode.d8.loss_dice: 1.0423
11/15 17:55:45 - mmengine - INFO - Iter(train) [63600/90000]  base_lr: 3.3161e-05 lr: 3.3161e-06  eta: 4:25:01  time: 0.5948  data_time: 0.0106  memory: 10692  grad_norm: 430.6559  loss: 14.9985  decode.loss_cls: 0.0611  decode.loss_mask: 0.4960  decode.loss_dice: 0.9561  decode.d0.loss_cls: 0.0997  decode.d0.loss_mask: 0.4645  decode.d0.loss_dice: 0.9739  decode.d1.loss_cls: 0.0659  decode.d1.loss_mask: 0.4926  decode.d1.loss_dice: 1.0006  decode.d2.loss_cls: 0.0646  decode.d2.loss_mask: 0.4746  decode.d2.loss_dice: 0.9822  decode.d3.loss_cls: 0.0575  decode.d3.loss_mask: 0.4823  decode.d3.loss_dice: 0.9563  decode.d4.loss_cls: 0.0618  decode.d4.loss_mask: 0.4553  decode.d4.loss_dice: 0.9229  decode.d5.loss_cls: 0.0602  decode.d5.loss_mask: 0.4806  decode.d5.loss_dice: 0.9205  decode.d6.loss_cls: 0.0578  decode.d6.loss_mask: 0.4825  decode.d6.loss_dice: 0.9285  decode.d7.loss_cls: 0.0734  decode.d7.loss_mask: 0.4780  decode.d7.loss_dice: 0.9359  decode.d8.loss_cls: 0.0635  decode.d8.loss_mask: 0.4897  decode.d8.loss_dice: 0.9600
11/15 17:56:15 - mmengine - INFO - Iter(train) [63650/90000]  base_lr: 3.3105e-05 lr: 3.3105e-06  eta: 4:24:31  time: 0.5963  data_time: 0.0103  memory: 10675  grad_norm: 376.0081  loss: 17.0884  decode.loss_cls: 0.0830  decode.loss_mask: 0.4576  decode.loss_dice: 1.1539  decode.d0.loss_cls: 0.1078  decode.d0.loss_mask: 0.4858  decode.d0.loss_dice: 1.2606  decode.d1.loss_cls: 0.0739  decode.d1.loss_mask: 0.4651  decode.d1.loss_dice: 1.1658  decode.d2.loss_cls: 0.0877  decode.d2.loss_mask: 0.4547  decode.d2.loss_dice: 1.1662  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 0.4484  decode.d3.loss_dice: 1.1507  decode.d4.loss_cls: 0.0671  decode.d4.loss_mask: 0.4503  decode.d4.loss_dice: 1.1669  decode.d5.loss_cls: 0.0673  decode.d5.loss_mask: 0.4469  decode.d5.loss_dice: 1.1774  decode.d6.loss_cls: 0.0766  decode.d6.loss_mask: 0.4467  decode.d6.loss_dice: 1.1645  decode.d7.loss_cls: 0.0832  decode.d7.loss_mask: 0.4529  decode.d7.loss_dice: 1.1390  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.4567  decode.d8.loss_dice: 1.1869
11/15 17:56:45 - mmengine - INFO - Iter(train) [63700/90000]  base_lr: 3.3048e-05 lr: 3.3048e-06  eta: 4:24:00  time: 0.5956  data_time: 0.0104  memory: 10692  grad_norm: 494.0075  loss: 18.1274  decode.loss_cls: 0.0815  decode.loss_mask: 0.5602  decode.loss_dice: 1.1496  decode.d0.loss_cls: 0.0972  decode.d0.loss_mask: 0.5911  decode.d0.loss_dice: 1.2150  decode.d1.loss_cls: 0.0865  decode.d1.loss_mask: 0.5545  decode.d1.loss_dice: 1.2113  decode.d2.loss_cls: 0.0900  decode.d2.loss_mask: 0.5572  decode.d2.loss_dice: 1.1710  decode.d3.loss_cls: 0.0809  decode.d3.loss_mask: 0.5707  decode.d3.loss_dice: 1.1562  decode.d4.loss_cls: 0.0864  decode.d4.loss_mask: 0.5574  decode.d4.loss_dice: 1.1585  decode.d5.loss_cls: 0.0964  decode.d5.loss_mask: 0.5531  decode.d5.loss_dice: 1.1484  decode.d6.loss_cls: 0.0861  decode.d6.loss_mask: 0.5605  decode.d6.loss_dice: 1.1459  decode.d7.loss_cls: 0.1031  decode.d7.loss_mask: 0.5562  decode.d7.loss_dice: 1.1060  decode.d8.loss_cls: 0.0952  decode.d8.loss_mask: 0.5477  decode.d8.loss_dice: 1.1536
11/15 17:57:14 - mmengine - INFO - Iter(train) [63750/90000]  base_lr: 3.2992e-05 lr: 3.2992e-06  eta: 4:23:30  time: 0.5969  data_time: 0.0103  memory: 10675  grad_norm: 322.5432  loss: 14.9946  decode.loss_cls: 0.0647  decode.loss_mask: 0.4393  decode.loss_dice: 0.9999  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.4624  decode.d0.loss_dice: 1.0266  decode.d1.loss_cls: 0.0622  decode.d1.loss_mask: 0.4447  decode.d1.loss_dice: 0.9898  decode.d2.loss_cls: 0.0759  decode.d2.loss_mask: 0.4347  decode.d2.loss_dice: 0.9882  decode.d3.loss_cls: 0.0632  decode.d3.loss_mask: 0.4374  decode.d3.loss_dice: 1.0045  decode.d4.loss_cls: 0.0708  decode.d4.loss_mask: 0.4346  decode.d4.loss_dice: 0.9816  decode.d5.loss_cls: 0.0600  decode.d5.loss_mask: 0.4368  decode.d5.loss_dice: 0.9823  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.4313  decode.d6.loss_dice: 0.9672  decode.d7.loss_cls: 0.0623  decode.d7.loss_mask: 0.4358  decode.d7.loss_dice: 1.0023  decode.d8.loss_cls: 0.0668  decode.d8.loss_mask: 0.4381  decode.d8.loss_dice: 0.9884
11/15 17:57:44 - mmengine - INFO - Iter(train) [63800/90000]  base_lr: 3.2935e-05 lr: 3.2935e-06  eta: 4:23:00  time: 0.5969  data_time: 0.0114  memory: 10675  grad_norm: 294.9232  loss: 16.4076  decode.loss_cls: 0.0622  decode.loss_mask: 0.4671  decode.loss_dice: 1.1023  decode.d0.loss_cls: 0.0790  decode.d0.loss_mask: 0.4691  decode.d0.loss_dice: 1.1426  decode.d1.loss_cls: 0.0716  decode.d1.loss_mask: 0.4818  decode.d1.loss_dice: 1.1118  decode.d2.loss_cls: 0.0561  decode.d2.loss_mask: 0.4746  decode.d2.loss_dice: 1.1142  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.4717  decode.d3.loss_dice: 1.0842  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.4766  decode.d4.loss_dice: 1.1164  decode.d5.loss_cls: 0.0600  decode.d5.loss_mask: 0.4700  decode.d5.loss_dice: 1.1233  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.4534  decode.d6.loss_dice: 1.1001  decode.d7.loss_cls: 0.0568  decode.d7.loss_mask: 0.4705  decode.d7.loss_dice: 1.1068  decode.d8.loss_cls: 0.0634  decode.d8.loss_mask: 0.4633  decode.d8.loss_dice: 1.0917
11/15 17:58:14 - mmengine - INFO - Iter(train) [63850/90000]  base_lr: 3.2878e-05 lr: 3.2878e-06  eta: 4:22:30  time: 0.5982  data_time: 0.0105  memory: 10713  grad_norm: 351.8733  loss: 16.6526  decode.loss_cls: 0.0552  decode.loss_mask: 0.4564  decode.loss_dice: 1.1327  decode.d0.loss_cls: 0.0773  decode.d0.loss_mask: 0.4799  decode.d0.loss_dice: 1.2013  decode.d1.loss_cls: 0.0775  decode.d1.loss_mask: 0.4646  decode.d1.loss_dice: 1.1546  decode.d2.loss_cls: 0.0681  decode.d2.loss_mask: 0.4715  decode.d2.loss_dice: 1.1134  decode.d3.loss_cls: 0.0680  decode.d3.loss_mask: 0.4678  decode.d3.loss_dice: 1.1257  decode.d4.loss_cls: 0.0773  decode.d4.loss_mask: 0.4712  decode.d4.loss_dice: 1.1075  decode.d5.loss_cls: 0.0695  decode.d5.loss_mask: 0.4757  decode.d5.loss_dice: 1.1027  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.4711  decode.d6.loss_dice: 1.1182  decode.d7.loss_cls: 0.0641  decode.d7.loss_mask: 0.4733  decode.d7.loss_dice: 1.1019  decode.d8.loss_cls: 0.0659  decode.d8.loss_mask: 0.4630  decode.d8.loss_dice: 1.1147
11/15 17:58:44 - mmengine - INFO - Iter(train) [63900/90000]  base_lr: 3.2822e-05 lr: 3.2822e-06  eta: 4:21:59  time: 0.5966  data_time: 0.0107  memory: 10675  grad_norm: 477.6320  loss: 17.0064  decode.loss_cls: 0.0483  decode.loss_mask: 0.5432  decode.loss_dice: 1.0996  decode.d0.loss_cls: 0.0734  decode.d0.loss_mask: 0.5608  decode.d0.loss_dice: 1.1373  decode.d1.loss_cls: 0.0429  decode.d1.loss_mask: 0.5496  decode.d1.loss_dice: 1.1215  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.5578  decode.d2.loss_dice: 1.0792  decode.d3.loss_cls: 0.0496  decode.d3.loss_mask: 0.5515  decode.d3.loss_dice: 1.0963  decode.d4.loss_cls: 0.0373  decode.d4.loss_mask: 0.5455  decode.d4.loss_dice: 1.0769  decode.d5.loss_cls: 0.0533  decode.d5.loss_mask: 0.5603  decode.d5.loss_dice: 1.0967  decode.d6.loss_cls: 0.0419  decode.d6.loss_mask: 0.5459  decode.d6.loss_dice: 1.0955  decode.d7.loss_cls: 0.0346  decode.d7.loss_mask: 0.5710  decode.d7.loss_dice: 1.0858  decode.d8.loss_cls: 0.0393  decode.d8.loss_mask: 0.5585  decode.d8.loss_dice: 1.1041
11/15 17:59:14 - mmengine - INFO - Iter(train) [63950/90000]  base_lr: 3.2765e-05 lr: 3.2765e-06  eta: 4:21:29  time: 0.5957  data_time: 0.0105  memory: 10692  grad_norm: 313.8194  loss: 16.9962  decode.loss_cls: 0.0498  decode.loss_mask: 0.5494  decode.loss_dice: 1.0913  decode.d0.loss_cls: 0.0836  decode.d0.loss_mask: 0.5796  decode.d0.loss_dice: 1.1613  decode.d1.loss_cls: 0.0700  decode.d1.loss_mask: 0.5557  decode.d1.loss_dice: 1.0764  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.5506  decode.d2.loss_dice: 1.0628  decode.d3.loss_cls: 0.0675  decode.d3.loss_mask: 0.5527  decode.d3.loss_dice: 1.0817  decode.d4.loss_cls: 0.0788  decode.d4.loss_mask: 0.5448  decode.d4.loss_dice: 1.0616  decode.d5.loss_cls: 0.0707  decode.d5.loss_mask: 0.5447  decode.d5.loss_dice: 1.0696  decode.d6.loss_cls: 0.0725  decode.d6.loss_mask: 0.5472  decode.d6.loss_dice: 1.0478  decode.d7.loss_cls: 0.0609  decode.d7.loss_mask: 0.5524  decode.d7.loss_dice: 1.0573  decode.d8.loss_cls: 0.0691  decode.d8.loss_mask: 0.5530  decode.d8.loss_dice: 1.0600
11/15 17:59:44 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 17:59:44 - mmengine - INFO - Iter(train) [64000/90000]  base_lr: 3.2709e-05 lr: 3.2709e-06  eta: 4:20:59  time: 0.5954  data_time: 0.0103  memory: 10692  grad_norm: 323.4898  loss: 15.1777  decode.loss_cls: 0.0348  decode.loss_mask: 0.4862  decode.loss_dice: 0.9470  decode.d0.loss_cls: 0.0730  decode.d0.loss_mask: 0.5191  decode.d0.loss_dice: 1.0269  decode.d1.loss_cls: 0.0344  decode.d1.loss_mask: 0.4968  decode.d1.loss_dice: 1.0311  decode.d2.loss_cls: 0.0361  decode.d2.loss_mask: 0.4953  decode.d2.loss_dice: 0.9840  decode.d3.loss_cls: 0.0405  decode.d3.loss_mask: 0.5010  decode.d3.loss_dice: 0.9547  decode.d4.loss_cls: 0.0366  decode.d4.loss_mask: 0.4934  decode.d4.loss_dice: 0.9757  decode.d5.loss_cls: 0.0298  decode.d5.loss_mask: 0.4983  decode.d5.loss_dice: 0.9802  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.4990  decode.d6.loss_dice: 0.9519  decode.d7.loss_cls: 0.0418  decode.d7.loss_mask: 0.4952  decode.d7.loss_dice: 0.9751  decode.d8.loss_cls: 0.0350  decode.d8.loss_mask: 0.4866  decode.d8.loss_dice: 0.9755
11/15 18:00:13 - mmengine - INFO - Iter(train) [64050/90000]  base_lr: 3.2652e-05 lr: 3.2652e-06  eta: 4:20:29  time: 0.5962  data_time: 0.0104  memory: 10675  grad_norm: 559.6328  loss: 15.0856  decode.loss_cls: 0.0488  decode.loss_mask: 0.5139  decode.loss_dice: 0.9627  decode.d0.loss_cls: 0.0752  decode.d0.loss_mask: 0.5145  decode.d0.loss_dice: 0.9983  decode.d1.loss_cls: 0.0600  decode.d1.loss_mask: 0.5034  decode.d1.loss_dice: 0.9502  decode.d2.loss_cls: 0.0544  decode.d2.loss_mask: 0.5049  decode.d2.loss_dice: 0.9295  decode.d3.loss_cls: 0.0483  decode.d3.loss_mask: 0.5001  decode.d3.loss_dice: 0.9145  decode.d4.loss_cls: 0.0510  decode.d4.loss_mask: 0.5045  decode.d4.loss_dice: 0.9363  decode.d5.loss_cls: 0.0496  decode.d5.loss_mask: 0.5107  decode.d5.loss_dice: 0.9569  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.5074  decode.d6.loss_dice: 0.9192  decode.d7.loss_cls: 0.0531  decode.d7.loss_mask: 0.5063  decode.d7.loss_dice: 0.9497  decode.d8.loss_cls: 0.0520  decode.d8.loss_mask: 0.5099  decode.d8.loss_dice: 0.9413
11/15 18:00:43 - mmengine - INFO - Iter(train) [64100/90000]  base_lr: 3.2595e-05 lr: 3.2595e-06  eta: 4:19:58  time: 0.5954  data_time: 0.0104  memory: 10692  grad_norm: 261.1981  loss: 15.2964  decode.loss_cls: 0.0439  decode.loss_mask: 0.5351  decode.loss_dice: 0.9130  decode.d0.loss_cls: 0.0756  decode.d0.loss_mask: 0.5897  decode.d0.loss_dice: 0.9733  decode.d1.loss_cls: 0.0616  decode.d1.loss_mask: 0.5233  decode.d1.loss_dice: 0.9488  decode.d2.loss_cls: 0.0485  decode.d2.loss_mask: 0.5397  decode.d2.loss_dice: 0.9245  decode.d3.loss_cls: 0.0570  decode.d3.loss_mask: 0.5364  decode.d3.loss_dice: 0.9278  decode.d4.loss_cls: 0.0412  decode.d4.loss_mask: 0.5460  decode.d4.loss_dice: 0.9296  decode.d5.loss_cls: 0.0454  decode.d5.loss_mask: 0.5450  decode.d5.loss_dice: 0.9372  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.5335  decode.d6.loss_dice: 0.9477  decode.d7.loss_cls: 0.0471  decode.d7.loss_mask: 0.5391  decode.d7.loss_dice: 0.9306  decode.d8.loss_cls: 0.0486  decode.d8.loss_mask: 0.5345  decode.d8.loss_dice: 0.9241
11/15 18:01:13 - mmengine - INFO - Iter(train) [64150/90000]  base_lr: 3.2539e-05 lr: 3.2539e-06  eta: 4:19:28  time: 0.5973  data_time: 0.0105  memory: 10692  grad_norm: 298.6518  loss: 15.3819  decode.loss_cls: 0.0745  decode.loss_mask: 0.4398  decode.loss_dice: 1.0238  decode.d0.loss_cls: 0.0915  decode.d0.loss_mask: 0.4522  decode.d0.loss_dice: 1.1000  decode.d1.loss_cls: 0.0746  decode.d1.loss_mask: 0.4455  decode.d1.loss_dice: 1.0414  decode.d2.loss_cls: 0.0760  decode.d2.loss_mask: 0.4384  decode.d2.loss_dice: 1.0205  decode.d3.loss_cls: 0.0688  decode.d3.loss_mask: 0.4346  decode.d3.loss_dice: 0.9965  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 0.4340  decode.d4.loss_dice: 1.0160  decode.d5.loss_cls: 0.0743  decode.d5.loss_mask: 0.4380  decode.d5.loss_dice: 1.0102  decode.d6.loss_cls: 0.0738  decode.d6.loss_mask: 0.4292  decode.d6.loss_dice: 1.0048  decode.d7.loss_cls: 0.0775  decode.d7.loss_mask: 0.4323  decode.d7.loss_dice: 1.0092  decode.d8.loss_cls: 0.0789  decode.d8.loss_mask: 0.4323  decode.d8.loss_dice: 1.0230
11/15 18:01:43 - mmengine - INFO - Iter(train) [64200/90000]  base_lr: 3.2482e-05 lr: 3.2482e-06  eta: 4:18:58  time: 0.5980  data_time: 0.0108  memory: 10675  grad_norm: 618.8307  loss: 18.8410  decode.loss_cls: 0.0727  decode.loss_mask: 0.5993  decode.loss_dice: 1.1898  decode.d0.loss_cls: 0.0901  decode.d0.loss_mask: 0.6401  decode.d0.loss_dice: 1.2985  decode.d1.loss_cls: 0.0791  decode.d1.loss_mask: 0.6012  decode.d1.loss_dice: 1.2077  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.6140  decode.d2.loss_dice: 1.2293  decode.d3.loss_cls: 0.0519  decode.d3.loss_mask: 0.6141  decode.d3.loss_dice: 1.2094  decode.d4.loss_cls: 0.0558  decode.d4.loss_mask: 0.5962  decode.d4.loss_dice: 1.2088  decode.d5.loss_cls: 0.0563  decode.d5.loss_mask: 0.6037  decode.d5.loss_dice: 1.2168  decode.d6.loss_cls: 0.0627  decode.d6.loss_mask: 0.5959  decode.d6.loss_dice: 1.1865  decode.d7.loss_cls: 0.0542  decode.d7.loss_mask: 0.6032  decode.d7.loss_dice: 1.2119  decode.d8.loss_cls: 0.0652  decode.d8.loss_mask: 0.6082  decode.d8.loss_dice: 1.1614
11/15 18:02:13 - mmengine - INFO - Iter(train) [64250/90000]  base_lr: 3.2425e-05 lr: 3.2425e-06  eta: 4:18:28  time: 0.5968  data_time: 0.0105  memory: 10728  grad_norm: 428.0948  loss: 16.5430  decode.loss_cls: 0.0489  decode.loss_mask: 0.5821  decode.loss_dice: 1.0193  decode.d0.loss_cls: 0.0706  decode.d0.loss_mask: 0.6104  decode.d0.loss_dice: 1.0855  decode.d1.loss_cls: 0.0582  decode.d1.loss_mask: 0.5881  decode.d1.loss_dice: 1.0493  decode.d2.loss_cls: 0.0532  decode.d2.loss_mask: 0.5886  decode.d2.loss_dice: 1.0160  decode.d3.loss_cls: 0.0464  decode.d3.loss_mask: 0.5767  decode.d3.loss_dice: 0.9982  decode.d4.loss_cls: 0.0469  decode.d4.loss_mask: 0.5759  decode.d4.loss_dice: 1.0023  decode.d5.loss_cls: 0.0490  decode.d5.loss_mask: 0.5696  decode.d5.loss_dice: 0.9999  decode.d6.loss_cls: 0.0502  decode.d6.loss_mask: 0.5783  decode.d6.loss_dice: 1.0014  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.5810  decode.d7.loss_dice: 0.9989  decode.d8.loss_cls: 0.0558  decode.d8.loss_mask: 0.5742  decode.d8.loss_dice: 1.0170
11/15 18:02:43 - mmengine - INFO - Iter(train) [64300/90000]  base_lr: 3.2369e-05 lr: 3.2369e-06  eta: 4:17:57  time: 0.5972  data_time: 0.0108  memory: 10656  grad_norm: 316.8420  loss: 15.1974  decode.loss_cls: 0.0758  decode.loss_mask: 0.4356  decode.loss_dice: 0.9861  decode.d0.loss_cls: 0.1078  decode.d0.loss_mask: 0.4381  decode.d0.loss_dice: 1.0432  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.4539  decode.d1.loss_dice: 1.0243  decode.d2.loss_cls: 0.0696  decode.d2.loss_mask: 0.4338  decode.d2.loss_dice: 0.9913  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.4321  decode.d3.loss_dice: 0.9996  decode.d4.loss_cls: 0.0748  decode.d4.loss_mask: 0.4513  decode.d4.loss_dice: 1.0003  decode.d5.loss_cls: 0.0772  decode.d5.loss_mask: 0.4474  decode.d5.loss_dice: 1.0137  decode.d6.loss_cls: 0.0733  decode.d6.loss_mask: 0.4350  decode.d6.loss_dice: 0.9759  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.4506  decode.d7.loss_dice: 0.9755  decode.d8.loss_cls: 0.0653  decode.d8.loss_mask: 0.4386  decode.d8.loss_dice: 1.0100
11/15 18:03:12 - mmengine - INFO - Iter(train) [64350/90000]  base_lr: 3.2312e-05 lr: 3.2312e-06  eta: 4:17:27  time: 0.5963  data_time: 0.0107  memory: 10675  grad_norm: 335.5138  loss: 15.8699  decode.loss_cls: 0.0732  decode.loss_mask: 0.4473  decode.loss_dice: 1.0171  decode.d0.loss_cls: 0.0881  decode.d0.loss_mask: 0.4657  decode.d0.loss_dice: 1.1760  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.4454  decode.d1.loss_dice: 1.1069  decode.d2.loss_cls: 0.0739  decode.d2.loss_mask: 0.4495  decode.d2.loss_dice: 1.0268  decode.d3.loss_cls: 0.0728  decode.d3.loss_mask: 0.4478  decode.d3.loss_dice: 1.0249  decode.d4.loss_cls: 0.0729  decode.d4.loss_mask: 0.4453  decode.d4.loss_dice: 1.0334  decode.d5.loss_cls: 0.0841  decode.d5.loss_mask: 0.4405  decode.d5.loss_dice: 1.0139  decode.d6.loss_cls: 0.0673  decode.d6.loss_mask: 0.4510  decode.d6.loss_dice: 1.0827  decode.d7.loss_cls: 0.0619  decode.d7.loss_mask: 0.4492  decode.d7.loss_dice: 1.0896  decode.d8.loss_cls: 0.0699  decode.d8.loss_mask: 0.4447  decode.d8.loss_dice: 1.0849
11/15 18:03:42 - mmengine - INFO - Iter(train) [64400/90000]  base_lr: 3.2255e-05 lr: 3.2255e-06  eta: 4:16:57  time: 0.5966  data_time: 0.0106  memory: 10656  grad_norm: 479.5018  loss: 17.8239  decode.loss_cls: 0.0727  decode.loss_mask: 0.5457  decode.loss_dice: 1.1997  decode.d0.loss_cls: 0.0699  decode.d0.loss_mask: 0.5637  decode.d0.loss_dice: 1.2324  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.5401  decode.d1.loss_dice: 1.1939  decode.d2.loss_cls: 0.0665  decode.d2.loss_mask: 0.5454  decode.d2.loss_dice: 1.1970  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 0.5212  decode.d3.loss_dice: 1.1234  decode.d4.loss_cls: 0.0665  decode.d4.loss_mask: 0.5236  decode.d4.loss_dice: 1.1512  decode.d5.loss_cls: 0.0653  decode.d5.loss_mask: 0.5235  decode.d5.loss_dice: 1.1504  decode.d6.loss_cls: 0.0600  decode.d6.loss_mask: 0.5340  decode.d6.loss_dice: 1.1666  decode.d7.loss_cls: 0.0643  decode.d7.loss_mask: 0.5254  decode.d7.loss_dice: 1.1635  decode.d8.loss_cls: 0.0566  decode.d8.loss_mask: 0.5544  decode.d8.loss_dice: 1.2131
11/15 18:04:12 - mmengine - INFO - Iter(train) [64450/90000]  base_lr: 3.2199e-05 lr: 3.2199e-06  eta: 4:16:27  time: 0.5985  data_time: 0.0106  memory: 10675  grad_norm: 366.5758  loss: 14.3938  decode.loss_cls: 0.0527  decode.loss_mask: 0.4304  decode.loss_dice: 0.9371  decode.d0.loss_cls: 0.0795  decode.d0.loss_mask: 0.4521  decode.d0.loss_dice: 0.9819  decode.d1.loss_cls: 0.0500  decode.d1.loss_mask: 0.4344  decode.d1.loss_dice: 0.9564  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.4303  decode.d2.loss_dice: 0.9466  decode.d3.loss_cls: 0.0482  decode.d3.loss_mask: 0.4266  decode.d3.loss_dice: 0.9471  decode.d4.loss_cls: 0.0480  decode.d4.loss_mask: 0.4307  decode.d4.loss_dice: 0.9534  decode.d5.loss_cls: 0.0547  decode.d5.loss_mask: 0.4301  decode.d5.loss_dice: 0.9472  decode.d6.loss_cls: 0.0522  decode.d6.loss_mask: 0.4281  decode.d6.loss_dice: 0.9462  decode.d7.loss_cls: 0.0470  decode.d7.loss_mask: 0.4323  decode.d7.loss_dice: 0.9744  decode.d8.loss_cls: 0.0459  decode.d8.loss_mask: 0.4345  decode.d8.loss_dice: 0.9510
11/15 18:04:42 - mmengine - INFO - Iter(train) [64500/90000]  base_lr: 3.2142e-05 lr: 3.2142e-06  eta: 4:15:57  time: 0.5964  data_time: 0.0108  memory: 10656  grad_norm: 381.8941  loss: 17.3454  decode.loss_cls: 0.0377  decode.loss_mask: 0.5761  decode.loss_dice: 1.1278  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.6104  decode.d0.loss_dice: 1.1661  decode.d1.loss_cls: 0.0436  decode.d1.loss_mask: 0.5720  decode.d1.loss_dice: 1.1168  decode.d2.loss_cls: 0.0518  decode.d2.loss_mask: 0.5521  decode.d2.loss_dice: 1.1195  decode.d3.loss_cls: 0.0454  decode.d3.loss_mask: 0.5481  decode.d3.loss_dice: 1.1253  decode.d4.loss_cls: 0.0452  decode.d4.loss_mask: 0.5433  decode.d4.loss_dice: 1.1184  decode.d5.loss_cls: 0.0483  decode.d5.loss_mask: 0.5462  decode.d5.loss_dice: 1.1407  decode.d6.loss_cls: 0.0467  decode.d6.loss_mask: 0.5447  decode.d6.loss_dice: 1.1163  decode.d7.loss_cls: 0.0422  decode.d7.loss_mask: 0.5401  decode.d7.loss_dice: 1.1110  decode.d8.loss_cls: 0.0374  decode.d8.loss_mask: 0.5790  decode.d8.loss_dice: 1.1152
11/15 18:05:12 - mmengine - INFO - Iter(train) [64550/90000]  base_lr: 3.2085e-05 lr: 3.2085e-06  eta: 4:15:26  time: 0.5967  data_time: 0.0107  memory: 10713  grad_norm: 283.2651  loss: 14.4949  decode.loss_cls: 0.0539  decode.loss_mask: 0.4728  decode.loss_dice: 0.9182  decode.d0.loss_cls: 0.0791  decode.d0.loss_mask: 0.4761  decode.d0.loss_dice: 0.9843  decode.d1.loss_cls: 0.0532  decode.d1.loss_mask: 0.4694  decode.d1.loss_dice: 0.9513  decode.d2.loss_cls: 0.0434  decode.d2.loss_mask: 0.4650  decode.d2.loss_dice: 0.9319  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.4510  decode.d3.loss_dice: 0.9166  decode.d4.loss_cls: 0.0486  decode.d4.loss_mask: 0.4556  decode.d4.loss_dice: 0.9174  decode.d5.loss_cls: 0.0466  decode.d5.loss_mask: 0.4593  decode.d5.loss_dice: 0.9138  decode.d6.loss_cls: 0.0472  decode.d6.loss_mask: 0.4691  decode.d6.loss_dice: 0.9270  decode.d7.loss_cls: 0.0433  decode.d7.loss_mask: 0.4716  decode.d7.loss_dice: 0.9356  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.4699  decode.d8.loss_dice: 0.9337
11/15 18:05:42 - mmengine - INFO - Iter(train) [64600/90000]  base_lr: 3.2028e-05 lr: 3.2028e-06  eta: 4:14:56  time: 0.5959  data_time: 0.0105  memory: 10713  grad_norm: 316.5009  loss: 15.2037  decode.loss_cls: 0.0525  decode.loss_mask: 0.4411  decode.loss_dice: 1.0184  decode.d0.loss_cls: 0.0990  decode.d0.loss_mask: 0.4458  decode.d0.loss_dice: 1.0707  decode.d1.loss_cls: 0.0733  decode.d1.loss_mask: 0.4381  decode.d1.loss_dice: 1.0283  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.4360  decode.d2.loss_dice: 0.9942  decode.d3.loss_cls: 0.0655  decode.d3.loss_mask: 0.4409  decode.d3.loss_dice: 0.9975  decode.d4.loss_cls: 0.0637  decode.d4.loss_mask: 0.4429  decode.d4.loss_dice: 1.0178  decode.d5.loss_cls: 0.0670  decode.d5.loss_mask: 0.4398  decode.d5.loss_dice: 0.9990  decode.d6.loss_cls: 0.0560  decode.d6.loss_mask: 0.4403  decode.d6.loss_dice: 1.0060  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.4391  decode.d7.loss_dice: 1.0007  decode.d8.loss_cls: 0.0593  decode.d8.loss_mask: 0.4402  decode.d8.loss_dice: 1.0100
11/15 18:06:12 - mmengine - INFO - Iter(train) [64650/90000]  base_lr: 3.1972e-05 lr: 3.1972e-06  eta: 4:14:26  time: 0.5970  data_time: 0.0105  memory: 10675  grad_norm: 322.0460  loss: 15.5998  decode.loss_cls: 0.0368  decode.loss_mask: 0.5030  decode.loss_dice: 1.0399  decode.d0.loss_cls: 0.0847  decode.d0.loss_mask: 0.4755  decode.d0.loss_dice: 1.0511  decode.d1.loss_cls: 0.0560  decode.d1.loss_mask: 0.4680  decode.d1.loss_dice: 1.0355  decode.d2.loss_cls: 0.0503  decode.d2.loss_mask: 0.4954  decode.d2.loss_dice: 1.0097  decode.d3.loss_cls: 0.0312  decode.d3.loss_mask: 0.5134  decode.d3.loss_dice: 1.0205  decode.d4.loss_cls: 0.0442  decode.d4.loss_mask: 0.4665  decode.d4.loss_dice: 1.0073  decode.d5.loss_cls: 0.0410  decode.d5.loss_mask: 0.4693  decode.d5.loss_dice: 1.0398  decode.d6.loss_cls: 0.0383  decode.d6.loss_mask: 0.4645  decode.d6.loss_dice: 1.0231  decode.d7.loss_cls: 0.0324  decode.d7.loss_mask: 0.4973  decode.d7.loss_dice: 1.0283  decode.d8.loss_cls: 0.0326  decode.d8.loss_mask: 0.5043  decode.d8.loss_dice: 1.0399
11/15 18:06:41 - mmengine - INFO - Iter(train) [64700/90000]  base_lr: 3.1915e-05 lr: 3.1915e-06  eta: 4:13:56  time: 0.5959  data_time: 0.0104  memory: 10713  grad_norm: 310.1426  loss: 17.0430  decode.loss_cls: 0.0700  decode.loss_mask: 0.5900  decode.loss_dice: 1.0497  decode.d0.loss_cls: 0.1043  decode.d0.loss_mask: 0.6517  decode.d0.loss_dice: 1.0993  decode.d1.loss_cls: 0.0687  decode.d1.loss_mask: 0.6080  decode.d1.loss_dice: 1.0312  decode.d2.loss_cls: 0.0672  decode.d2.loss_mask: 0.5885  decode.d2.loss_dice: 1.0129  decode.d3.loss_cls: 0.0643  decode.d3.loss_mask: 0.5890  decode.d3.loss_dice: 1.0213  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.5925  decode.d4.loss_dice: 0.9927  decode.d5.loss_cls: 0.0821  decode.d5.loss_mask: 0.5843  decode.d5.loss_dice: 1.0093  decode.d6.loss_cls: 0.0778  decode.d6.loss_mask: 0.5955  decode.d6.loss_dice: 1.0378  decode.d7.loss_cls: 0.0624  decode.d7.loss_mask: 0.5924  decode.d7.loss_dice: 1.0436  decode.d8.loss_cls: 0.0817  decode.d8.loss_mask: 0.5816  decode.d8.loss_dice: 1.0152
11/15 18:07:11 - mmengine - INFO - Iter(train) [64750/90000]  base_lr: 3.1858e-05 lr: 3.1858e-06  eta: 4:13:26  time: 0.5959  data_time: 0.0105  memory: 10675  grad_norm: 356.3930  loss: 16.5481  decode.loss_cls: 0.0500  decode.loss_mask: 0.4363  decode.loss_dice: 1.1394  decode.d0.loss_cls: 0.0696  decode.d0.loss_mask: 0.4589  decode.d0.loss_dice: 1.2313  decode.d1.loss_cls: 0.0381  decode.d1.loss_mask: 0.4525  decode.d1.loss_dice: 1.2093  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 0.4326  decode.d2.loss_dice: 1.1821  decode.d3.loss_cls: 0.0416  decode.d3.loss_mask: 0.4318  decode.d3.loss_dice: 1.1417  decode.d4.loss_cls: 0.0452  decode.d4.loss_mask: 0.4317  decode.d4.loss_dice: 1.1602  decode.d5.loss_cls: 0.0424  decode.d5.loss_mask: 0.4365  decode.d5.loss_dice: 1.1466  decode.d6.loss_cls: 0.0477  decode.d6.loss_mask: 0.4372  decode.d6.loss_dice: 1.1314  decode.d7.loss_cls: 0.0435  decode.d7.loss_mask: 0.4413  decode.d7.loss_dice: 1.1643  decode.d8.loss_cls: 0.0429  decode.d8.loss_mask: 0.4335  decode.d8.loss_dice: 1.1786
11/15 18:07:42 - mmengine - INFO - Iter(train) [64800/90000]  base_lr: 3.1801e-05 lr: 3.1801e-06  eta: 4:12:56  time: 0.5957  data_time: 0.0109  memory: 10656  grad_norm: 334.1809  loss: 15.5826  decode.loss_cls: 0.0253  decode.loss_mask: 0.5153  decode.loss_dice: 0.9777  decode.d0.loss_cls: 0.0615  decode.d0.loss_mask: 0.5174  decode.d0.loss_dice: 1.0870  decode.d1.loss_cls: 0.0370  decode.d1.loss_mask: 0.5185  decode.d1.loss_dice: 1.0256  decode.d2.loss_cls: 0.0363  decode.d2.loss_mask: 0.5146  decode.d2.loss_dice: 1.0224  decode.d3.loss_cls: 0.0306  decode.d3.loss_mask: 0.5100  decode.d3.loss_dice: 1.0026  decode.d4.loss_cls: 0.0291  decode.d4.loss_mask: 0.5131  decode.d4.loss_dice: 1.0015  decode.d5.loss_cls: 0.0255  decode.d5.loss_mask: 0.5146  decode.d5.loss_dice: 1.0010  decode.d6.loss_cls: 0.0310  decode.d6.loss_mask: 0.5186  decode.d6.loss_dice: 1.0005  decode.d7.loss_cls: 0.0263  decode.d7.loss_mask: 0.5135  decode.d7.loss_dice: 0.9853  decode.d8.loss_cls: 0.0274  decode.d8.loss_mask: 0.5126  decode.d8.loss_dice: 1.0007
11/15 18:08:12 - mmengine - INFO - Iter(train) [64850/90000]  base_lr: 3.1745e-05 lr: 3.1745e-06  eta: 4:12:25  time: 0.5956  data_time: 0.0105  memory: 10675  grad_norm: 422.4375  loss: 16.7233  decode.loss_cls: 0.0823  decode.loss_mask: 0.4990  decode.loss_dice: 1.0691  decode.d0.loss_cls: 0.0909  decode.d0.loss_mask: 0.5452  decode.d0.loss_dice: 1.1429  decode.d1.loss_cls: 0.1054  decode.d1.loss_mask: 0.5359  decode.d1.loss_dice: 1.0965  decode.d2.loss_cls: 0.0842  decode.d2.loss_mask: 0.5019  decode.d2.loss_dice: 1.0815  decode.d3.loss_cls: 0.0940  decode.d3.loss_mask: 0.5059  decode.d3.loss_dice: 1.0778  decode.d4.loss_cls: 0.0937  decode.d4.loss_mask: 0.4998  decode.d4.loss_dice: 1.0506  decode.d5.loss_cls: 0.0881  decode.d5.loss_mask: 0.5004  decode.d5.loss_dice: 1.0579  decode.d6.loss_cls: 0.0846  decode.d6.loss_mask: 0.5031  decode.d6.loss_dice: 1.0653  decode.d7.loss_cls: 0.0790  decode.d7.loss_mask: 0.5042  decode.d7.loss_dice: 1.0496  decode.d8.loss_cls: 0.0772  decode.d8.loss_mask: 0.4970  decode.d8.loss_dice: 1.0601
11/15 18:08:42 - mmengine - INFO - Iter(train) [64900/90000]  base_lr: 3.1688e-05 lr: 3.1688e-06  eta: 4:11:55  time: 0.5962  data_time: 0.0106  memory: 10675  grad_norm: 333.9229  loss: 14.2207  decode.loss_cls: 0.0541  decode.loss_mask: 0.3563  decode.loss_dice: 0.9795  decode.d0.loss_cls: 0.0778  decode.d0.loss_mask: 0.3720  decode.d0.loss_dice: 1.0842  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.3688  decode.d1.loss_dice: 1.0510  decode.d2.loss_cls: 0.0675  decode.d2.loss_mask: 0.3617  decode.d2.loss_dice: 0.9814  decode.d3.loss_cls: 0.0556  decode.d3.loss_mask: 0.3645  decode.d3.loss_dice: 0.9803  decode.d4.loss_cls: 0.0571  decode.d4.loss_mask: 0.3603  decode.d4.loss_dice: 0.9675  decode.d5.loss_cls: 0.0591  decode.d5.loss_mask: 0.3632  decode.d5.loss_dice: 0.9869  decode.d6.loss_cls: 0.0608  decode.d6.loss_mask: 0.3540  decode.d6.loss_dice: 0.9603  decode.d7.loss_cls: 0.0644  decode.d7.loss_mask: 0.3569  decode.d7.loss_dice: 0.9832  decode.d8.loss_cls: 0.0592  decode.d8.loss_mask: 0.3557  decode.d8.loss_dice: 1.0151
11/15 18:09:12 - mmengine - INFO - Iter(train) [64950/90000]  base_lr: 3.1631e-05 lr: 3.1631e-06  eta: 4:11:25  time: 0.5958  data_time: 0.0106  memory: 10692  grad_norm: 250.3222  loss: 14.8506  decode.loss_cls: 0.0459  decode.loss_mask: 0.3975  decode.loss_dice: 1.0039  decode.d0.loss_cls: 0.0825  decode.d0.loss_mask: 0.4102  decode.d0.loss_dice: 1.1129  decode.d1.loss_cls: 0.0711  decode.d1.loss_mask: 0.4004  decode.d1.loss_dice: 1.0182  decode.d2.loss_cls: 0.0433  decode.d2.loss_mask: 0.3967  decode.d2.loss_dice: 1.0197  decode.d3.loss_cls: 0.0453  decode.d3.loss_mask: 0.3962  decode.d3.loss_dice: 1.0386  decode.d4.loss_cls: 0.0483  decode.d4.loss_mask: 0.4056  decode.d4.loss_dice: 1.0258  decode.d5.loss_cls: 0.0380  decode.d5.loss_mask: 0.4057  decode.d5.loss_dice: 1.0294  decode.d6.loss_cls: 0.0498  decode.d6.loss_mask: 0.3965  decode.d6.loss_dice: 1.0207  decode.d7.loss_cls: 0.0552  decode.d7.loss_mask: 0.3942  decode.d7.loss_dice: 1.0100  decode.d8.loss_cls: 0.0476  decode.d8.loss_mask: 0.3972  decode.d8.loss_dice: 1.0440
11/15 18:09:41 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 18:09:41 - mmengine - INFO - Iter(train) [65000/90000]  base_lr: 3.1574e-05 lr: 3.1574e-06  eta: 4:10:55  time: 0.5973  data_time: 0.0107  memory: 10675  grad_norm: 274.4111  loss: 16.9998  decode.loss_cls: 0.0731  decode.loss_mask: 0.5183  decode.loss_dice: 1.0984  decode.d0.loss_cls: 0.1130  decode.d0.loss_mask: 0.5239  decode.d0.loss_dice: 1.1474  decode.d1.loss_cls: 0.0669  decode.d1.loss_mask: 0.5113  decode.d1.loss_dice: 1.1144  decode.d2.loss_cls: 0.0759  decode.d2.loss_mask: 0.5107  decode.d2.loss_dice: 1.0948  decode.d3.loss_cls: 0.0705  decode.d3.loss_mask: 0.5045  decode.d3.loss_dice: 1.1143  decode.d4.loss_cls: 0.0745  decode.d4.loss_mask: 0.5054  decode.d4.loss_dice: 1.1013  decode.d5.loss_cls: 0.0733  decode.d5.loss_mask: 0.5228  decode.d5.loss_dice: 1.1004  decode.d6.loss_cls: 0.0725  decode.d6.loss_mask: 0.5240  decode.d6.loss_dice: 1.1075  decode.d7.loss_cls: 0.0806  decode.d7.loss_mask: 0.5237  decode.d7.loss_dice: 1.1002  decode.d8.loss_cls: 0.0792  decode.d8.loss_mask: 0.5079  decode.d8.loss_dice: 1.0891
11/15 18:09:41 - mmengine - INFO - Saving checkpoint at 65000 iterations
11/15 18:10:00 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:21  time: 0.3087  data_time: 0.0043  memory: 4095  
11/15 18:10:16 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:04  time: 0.3084  data_time: 0.0041  memory: 4095  
11/15 18:10:31 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:48  time: 0.3088  data_time: 0.0041  memory: 4095  
11/15 18:10:47 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3085  data_time: 0.0041  memory: 4095  
11/15 18:11:02 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3091  data_time: 0.0044  memory: 4095  
11/15 18:11:18 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:01  time: 0.3091  data_time: 0.0042  memory: 4095  
11/15 18:11:33 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3091  data_time: 0.0040  memory: 4095  
11/15 18:11:49 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:30  time: 0.3089  data_time: 0.0040  memory: 4095  
11/15 18:12:04 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3094  data_time: 0.0043  memory: 4095  
11/15 18:12:19 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3085  data_time: 0.0039  memory: 4095  
11/15 18:12:20 - mmengine - INFO - per class results:
11/15 18:12:20 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 98.09 | 98.47 |
|    sidewalk   | 85.12 | 94.64 |
|    building   | 92.51 | 96.96 |
|      wall     | 51.28 | 59.51 |
|     fence     | 60.47 | 72.01 |
|      pole     | 67.94 | 80.66 |
| traffic light | 71.06 | 78.73 |
|  traffic sign | 81.21 | 87.29 |
|   vegetation  | 92.56 | 96.31 |
|    terrain    | 64.35 | 75.04 |
|      sky      | 95.11 | 97.39 |
|     person    | 81.73 | 88.63 |
|     rider     | 62.03 | 80.15 |
|      car      | 95.15 | 97.96 |
|     truck     | 81.32 | 94.08 |
|      bus      | 83.27 | 90.87 |
|     train     | 59.64 | 69.54 |
|   motorcycle  | 64.86 | 79.24 |
|    bicycle    | 78.81 | 88.49 |
+---------------+-------+-------+
11/15 18:12:20 - mmengine - INFO - Iter(val) [500/500]    aAcc: 96.0800  mIoU: 77.1800  mAcc: 85.5800  data_time: 0.0047  time: 0.3096
11/15 18:12:49 - mmengine - INFO - Iter(train) [65050/90000]  base_lr: 3.1517e-05 lr: 3.1517e-06  eta: 4:10:25  time: 0.5967  data_time: 0.0105  memory: 10692  grad_norm: 203.7628  loss: 15.0572  decode.loss_cls: 0.0784  decode.loss_mask: 0.4597  decode.loss_dice: 0.9513  decode.d0.loss_cls: 0.1046  decode.d0.loss_mask: 0.4849  decode.d0.loss_dice: 1.0145  decode.d1.loss_cls: 0.0919  decode.d1.loss_mask: 0.4654  decode.d1.loss_dice: 0.9648  decode.d2.loss_cls: 0.0830  decode.d2.loss_mask: 0.4587  decode.d2.loss_dice: 0.9188  decode.d3.loss_cls: 0.0818  decode.d3.loss_mask: 0.4628  decode.d3.loss_dice: 0.9693  decode.d4.loss_cls: 0.0837  decode.d4.loss_mask: 0.4725  decode.d4.loss_dice: 0.9404  decode.d5.loss_cls: 0.0908  decode.d5.loss_mask: 0.4702  decode.d5.loss_dice: 0.9307  decode.d6.loss_cls: 0.0826  decode.d6.loss_mask: 0.4627  decode.d6.loss_dice: 0.9460  decode.d7.loss_cls: 0.0855  decode.d7.loss_mask: 0.4665  decode.d7.loss_dice: 0.9352  decode.d8.loss_cls: 0.0808  decode.d8.loss_mask: 0.4704  decode.d8.loss_dice: 0.9493
11/15 18:13:19 - mmengine - INFO - Iter(train) [65100/90000]  base_lr: 3.1460e-05 lr: 3.1460e-06  eta: 4:09:54  time: 0.5968  data_time: 0.0106  memory: 10641  grad_norm: 221.5367  loss: 16.5524  decode.loss_cls: 0.0481  decode.loss_mask: 0.5344  decode.loss_dice: 1.0784  decode.d0.loss_cls: 0.0822  decode.d0.loss_mask: 0.5635  decode.d0.loss_dice: 1.1116  decode.d1.loss_cls: 0.0717  decode.d1.loss_mask: 0.5384  decode.d1.loss_dice: 1.0716  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 0.5324  decode.d2.loss_dice: 1.0530  decode.d3.loss_cls: 0.0575  decode.d3.loss_mask: 0.5331  decode.d3.loss_dice: 1.0596  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.5325  decode.d4.loss_dice: 1.0545  decode.d5.loss_cls: 0.0481  decode.d5.loss_mask: 0.5321  decode.d5.loss_dice: 1.0514  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.4984  decode.d6.loss_dice: 1.0445  decode.d7.loss_cls: 0.0520  decode.d7.loss_mask: 0.5287  decode.d7.loss_dice: 1.0694  decode.d8.loss_cls: 0.0531  decode.d8.loss_mask: 0.5280  decode.d8.loss_dice: 1.0572
11/15 18:13:49 - mmengine - INFO - Iter(train) [65150/90000]  base_lr: 3.1404e-05 lr: 3.1404e-06  eta: 4:09:24  time: 0.5957  data_time: 0.0104  memory: 10656  grad_norm: 622.1018  loss: 15.6690  decode.loss_cls: 0.0619  decode.loss_mask: 0.5107  decode.loss_dice: 0.9674  decode.d0.loss_cls: 0.0765  decode.d0.loss_mask: 0.5516  decode.d0.loss_dice: 1.0539  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.5213  decode.d1.loss_dice: 1.0026  decode.d2.loss_cls: 0.0555  decode.d2.loss_mask: 0.5110  decode.d2.loss_dice: 0.9820  decode.d3.loss_cls: 0.0497  decode.d3.loss_mask: 0.5075  decode.d3.loss_dice: 0.9630  decode.d4.loss_cls: 0.0400  decode.d4.loss_mask: 0.5126  decode.d4.loss_dice: 0.9878  decode.d5.loss_cls: 0.0541  decode.d5.loss_mask: 0.5373  decode.d5.loss_dice: 0.9881  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.5285  decode.d6.loss_dice: 0.9738  decode.d7.loss_cls: 0.0550  decode.d7.loss_mask: 0.5238  decode.d7.loss_dice: 0.9890  decode.d8.loss_cls: 0.0404  decode.d8.loss_mask: 0.5166  decode.d8.loss_dice: 0.9933
11/15 18:14:19 - mmengine - INFO - Iter(train) [65200/90000]  base_lr: 3.1347e-05 lr: 3.1347e-06  eta: 4:08:54  time: 0.5968  data_time: 0.0105  memory: 10656  grad_norm: 352.2579  loss: 16.2123  decode.loss_cls: 0.0721  decode.loss_mask: 0.5334  decode.loss_dice: 1.0051  decode.d0.loss_cls: 0.1072  decode.d0.loss_mask: 0.5557  decode.d0.loss_dice: 1.0421  decode.d1.loss_cls: 0.0829  decode.d1.loss_mask: 0.5394  decode.d1.loss_dice: 1.0142  decode.d2.loss_cls: 0.0798  decode.d2.loss_mask: 0.5357  decode.d2.loss_dice: 1.0044  decode.d3.loss_cls: 0.0851  decode.d3.loss_mask: 0.5333  decode.d3.loss_dice: 0.9877  decode.d4.loss_cls: 0.0857  decode.d4.loss_mask: 0.5274  decode.d4.loss_dice: 1.0054  decode.d5.loss_cls: 0.0775  decode.d5.loss_mask: 0.5335  decode.d5.loss_dice: 1.0219  decode.d6.loss_cls: 0.0908  decode.d6.loss_mask: 0.5331  decode.d6.loss_dice: 1.0011  decode.d7.loss_cls: 0.0812  decode.d7.loss_mask: 0.5308  decode.d7.loss_dice: 0.9490  decode.d8.loss_cls: 0.0775  decode.d8.loss_mask: 0.5275  decode.d8.loss_dice: 0.9918
11/15 18:14:49 - mmengine - INFO - Iter(train) [65250/90000]  base_lr: 3.1290e-05 lr: 3.1290e-06  eta: 4:08:24  time: 0.5957  data_time: 0.0104  memory: 10692  grad_norm: 568.1097  loss: 17.6932  decode.loss_cls: 0.0872  decode.loss_mask: 0.5271  decode.loss_dice: 1.1522  decode.d0.loss_cls: 0.1050  decode.d0.loss_mask: 0.5535  decode.d0.loss_dice: 1.1816  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.5410  decode.d1.loss_dice: 1.1970  decode.d2.loss_cls: 0.0822  decode.d2.loss_mask: 0.5433  decode.d2.loss_dice: 1.1892  decode.d3.loss_cls: 0.0913  decode.d3.loss_mask: 0.5185  decode.d3.loss_dice: 1.1284  decode.d4.loss_cls: 0.0865  decode.d4.loss_mask: 0.5231  decode.d4.loss_dice: 1.1365  decode.d5.loss_cls: 0.0864  decode.d5.loss_mask: 0.5192  decode.d5.loss_dice: 1.1316  decode.d6.loss_cls: 0.0833  decode.d6.loss_mask: 0.5247  decode.d6.loss_dice: 1.1501  decode.d7.loss_cls: 0.0861  decode.d7.loss_mask: 0.5177  decode.d7.loss_dice: 1.1184  decode.d8.loss_cls: 0.0821  decode.d8.loss_mask: 0.5251  decode.d8.loss_dice: 1.1461
11/15 18:15:19 - mmengine - INFO - Iter(train) [65300/90000]  base_lr: 3.1233e-05 lr: 3.1233e-06  eta: 4:07:54  time: 0.5965  data_time: 0.0105  memory: 10675  grad_norm: 445.0700  loss: 14.6233  decode.loss_cls: 0.0435  decode.loss_mask: 0.4741  decode.loss_dice: 0.9303  decode.d0.loss_cls: 0.0834  decode.d0.loss_mask: 0.4578  decode.d0.loss_dice: 0.9957  decode.d1.loss_cls: 0.0590  decode.d1.loss_mask: 0.4766  decode.d1.loss_dice: 0.9336  decode.d2.loss_cls: 0.0441  decode.d2.loss_mask: 0.4742  decode.d2.loss_dice: 0.9339  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.4627  decode.d3.loss_dice: 0.9072  decode.d4.loss_cls: 0.0428  decode.d4.loss_mask: 0.4753  decode.d4.loss_dice: 0.9339  decode.d5.loss_cls: 0.0469  decode.d5.loss_mask: 0.4776  decode.d5.loss_dice: 0.9233  decode.d6.loss_cls: 0.0397  decode.d6.loss_mask: 0.4816  decode.d6.loss_dice: 0.9444  decode.d7.loss_cls: 0.0422  decode.d7.loss_mask: 0.4860  decode.d7.loss_dice: 0.9394  decode.d8.loss_cls: 0.0408  decode.d8.loss_mask: 0.4766  decode.d8.loss_dice: 0.9459
11/15 18:15:49 - mmengine - INFO - Iter(train) [65350/90000]  base_lr: 3.1176e-05 lr: 3.1176e-06  eta: 4:07:23  time: 0.5965  data_time: 0.0106  memory: 10641  grad_norm: 292.3131  loss: 16.2903  decode.loss_cls: 0.0884  decode.loss_mask: 0.4415  decode.loss_dice: 1.0603  decode.d0.loss_cls: 0.1238  decode.d0.loss_mask: 0.4956  decode.d0.loss_dice: 1.1563  decode.d1.loss_cls: 0.1023  decode.d1.loss_mask: 0.4506  decode.d1.loss_dice: 1.0727  decode.d2.loss_cls: 0.0888  decode.d2.loss_mask: 0.4573  decode.d2.loss_dice: 1.1080  decode.d3.loss_cls: 0.1003  decode.d3.loss_mask: 0.4492  decode.d3.loss_dice: 1.0498  decode.d4.loss_cls: 0.0964  decode.d4.loss_mask: 0.4494  decode.d4.loss_dice: 1.0899  decode.d5.loss_cls: 0.0736  decode.d5.loss_mask: 0.4468  decode.d5.loss_dice: 1.1202  decode.d6.loss_cls: 0.0750  decode.d6.loss_mask: 0.4511  decode.d6.loss_dice: 1.0799  decode.d7.loss_cls: 0.0822  decode.d7.loss_mask: 0.4523  decode.d7.loss_dice: 1.0548  decode.d8.loss_cls: 0.0776  decode.d8.loss_mask: 0.4495  decode.d8.loss_dice: 1.0467
11/15 18:16:18 - mmengine - INFO - Iter(train) [65400/90000]  base_lr: 3.1119e-05 lr: 3.1119e-06  eta: 4:06:53  time: 0.5958  data_time: 0.0103  memory: 10692  grad_norm: 227.4097  loss: 14.4265  decode.loss_cls: 0.0753  decode.loss_mask: 0.3612  decode.loss_dice: 0.9840  decode.d0.loss_cls: 0.0938  decode.d0.loss_mask: 0.3890  decode.d0.loss_dice: 1.0835  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.3821  decode.d1.loss_dice: 0.9718  decode.d2.loss_cls: 0.0835  decode.d2.loss_mask: 0.3689  decode.d2.loss_dice: 1.0139  decode.d3.loss_cls: 0.0663  decode.d3.loss_mask: 0.3795  decode.d3.loss_dice: 0.9891  decode.d4.loss_cls: 0.0678  decode.d4.loss_mask: 0.3757  decode.d4.loss_dice: 0.9569  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.3747  decode.d5.loss_dice: 0.9782  decode.d6.loss_cls: 0.0736  decode.d6.loss_mask: 0.3769  decode.d6.loss_dice: 0.9931  decode.d7.loss_cls: 0.0752  decode.d7.loss_mask: 0.3809  decode.d7.loss_dice: 0.9524  decode.d8.loss_cls: 0.0822  decode.d8.loss_mask: 0.3591  decode.d8.loss_dice: 0.9880
11/15 18:16:48 - mmengine - INFO - Iter(train) [65450/90000]  base_lr: 3.1062e-05 lr: 3.1062e-06  eta: 4:06:23  time: 0.5954  data_time: 0.0104  memory: 10675  grad_norm: 502.3423  loss: 16.5988  decode.loss_cls: 0.0465  decode.loss_mask: 0.4941  decode.loss_dice: 1.0492  decode.d0.loss_cls: 0.0865  decode.d0.loss_mask: 0.5416  decode.d0.loss_dice: 1.1537  decode.d1.loss_cls: 0.0534  decode.d1.loss_mask: 0.5242  decode.d1.loss_dice: 1.1364  decode.d2.loss_cls: 0.0448  decode.d2.loss_mask: 0.5097  decode.d2.loss_dice: 1.1099  decode.d3.loss_cls: 0.0414  decode.d3.loss_mask: 0.5083  decode.d3.loss_dice: 1.1049  decode.d4.loss_cls: 0.0464  decode.d4.loss_mask: 0.5145  decode.d4.loss_dice: 1.0898  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.5116  decode.d5.loss_dice: 1.0895  decode.d6.loss_cls: 0.0375  decode.d6.loss_mask: 0.5133  decode.d6.loss_dice: 1.0976  decode.d7.loss_cls: 0.0515  decode.d7.loss_mask: 0.4999  decode.d7.loss_dice: 1.0685  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.4998  decode.d8.loss_dice: 1.0793
11/15 18:17:18 - mmengine - INFO - Iter(train) [65500/90000]  base_lr: 3.1005e-05 lr: 3.1005e-06  eta: 4:05:53  time: 0.5958  data_time: 0.0105  memory: 10713  grad_norm: 446.3865  loss: 16.2304  decode.loss_cls: 0.0669  decode.loss_mask: 0.6011  decode.loss_dice: 0.9613  decode.d0.loss_cls: 0.0819  decode.d0.loss_mask: 0.6139  decode.d0.loss_dice: 1.0319  decode.d1.loss_cls: 0.0537  decode.d1.loss_mask: 0.5735  decode.d1.loss_dice: 1.0068  decode.d2.loss_cls: 0.0588  decode.d2.loss_mask: 0.5837  decode.d2.loss_dice: 0.9749  decode.d3.loss_cls: 0.0568  decode.d3.loss_mask: 0.5785  decode.d3.loss_dice: 0.9796  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.5769  decode.d4.loss_dice: 0.9659  decode.d5.loss_cls: 0.0567  decode.d5.loss_mask: 0.5824  decode.d5.loss_dice: 0.9582  decode.d6.loss_cls: 0.0584  decode.d6.loss_mask: 0.5921  decode.d6.loss_dice: 0.9565  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 0.5865  decode.d7.loss_dice: 0.9437  decode.d8.loss_cls: 0.0545  decode.d8.loss_mask: 0.5948  decode.d8.loss_dice: 0.9636
11/15 18:17:48 - mmengine - INFO - Iter(train) [65550/90000]  base_lr: 3.0948e-05 lr: 3.0948e-06  eta: 4:05:23  time: 0.5969  data_time: 0.0104  memory: 10742  grad_norm: 428.1831  loss: 18.0238  decode.loss_cls: 0.0542  decode.loss_mask: 0.5189  decode.loss_dice: 1.2202  decode.d0.loss_cls: 0.0824  decode.d0.loss_mask: 0.5334  decode.d0.loss_dice: 1.2558  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.5359  decode.d1.loss_dice: 1.2389  decode.d2.loss_cls: 0.0618  decode.d2.loss_mask: 0.5177  decode.d2.loss_dice: 1.2112  decode.d3.loss_cls: 0.0685  decode.d3.loss_mask: 0.5262  decode.d3.loss_dice: 1.1917  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.5250  decode.d4.loss_dice: 1.2034  decode.d5.loss_cls: 0.0591  decode.d5.loss_mask: 0.5288  decode.d5.loss_dice: 1.2207  decode.d6.loss_cls: 0.0616  decode.d6.loss_mask: 0.5255  decode.d6.loss_dice: 1.1996  decode.d7.loss_cls: 0.0572  decode.d7.loss_mask: 0.5237  decode.d7.loss_dice: 1.2031  decode.d8.loss_cls: 0.0546  decode.d8.loss_mask: 0.5217  decode.d8.loss_dice: 1.2098
11/15 18:18:18 - mmengine - INFO - Iter(train) [65600/90000]  base_lr: 3.0891e-05 lr: 3.0891e-06  eta: 4:04:52  time: 0.5953  data_time: 0.0104  memory: 10713  grad_norm: 376.5731  loss: 14.2308  decode.loss_cls: 0.0668  decode.loss_mask: 0.4297  decode.loss_dice: 0.9286  decode.d0.loss_cls: 0.0899  decode.d0.loss_mask: 0.4577  decode.d0.loss_dice: 0.9737  decode.d1.loss_cls: 0.0780  decode.d1.loss_mask: 0.4243  decode.d1.loss_dice: 0.9109  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.4217  decode.d2.loss_dice: 0.9135  decode.d3.loss_cls: 0.0608  decode.d3.loss_mask: 0.4291  decode.d3.loss_dice: 0.9242  decode.d4.loss_cls: 0.0741  decode.d4.loss_mask: 0.4226  decode.d4.loss_dice: 0.8770  decode.d5.loss_cls: 0.0731  decode.d5.loss_mask: 0.4313  decode.d5.loss_dice: 0.9412  decode.d6.loss_cls: 0.0585  decode.d6.loss_mask: 0.4291  decode.d6.loss_dice: 0.8980  decode.d7.loss_cls: 0.0674  decode.d7.loss_mask: 0.4280  decode.d7.loss_dice: 0.9380  decode.d8.loss_cls: 0.0662  decode.d8.loss_mask: 0.4288  decode.d8.loss_dice: 0.9181
11/15 18:18:48 - mmengine - INFO - Iter(train) [65650/90000]  base_lr: 3.0834e-05 lr: 3.0834e-06  eta: 4:04:22  time: 0.5953  data_time: 0.0104  memory: 10656  grad_norm: 552.1939  loss: 18.3755  decode.loss_cls: 0.0772  decode.loss_mask: 0.5451  decode.loss_dice: 1.2003  decode.d0.loss_cls: 0.0888  decode.d0.loss_mask: 0.5833  decode.d0.loss_dice: 1.2668  decode.d1.loss_cls: 0.0759  decode.d1.loss_mask: 0.5549  decode.d1.loss_dice: 1.2268  decode.d2.loss_cls: 0.0763  decode.d2.loss_mask: 0.5537  decode.d2.loss_dice: 1.1950  decode.d3.loss_cls: 0.0833  decode.d3.loss_mask: 0.5450  decode.d3.loss_dice: 1.1771  decode.d4.loss_cls: 0.0741  decode.d4.loss_mask: 0.5443  decode.d4.loss_dice: 1.2101  decode.d5.loss_cls: 0.0750  decode.d5.loss_mask: 0.5510  decode.d5.loss_dice: 1.2341  decode.d6.loss_cls: 0.0822  decode.d6.loss_mask: 0.5505  decode.d6.loss_dice: 1.1824  decode.d7.loss_cls: 0.0744  decode.d7.loss_mask: 0.5543  decode.d7.loss_dice: 1.1809  decode.d8.loss_cls: 0.0754  decode.d8.loss_mask: 0.5509  decode.d8.loss_dice: 1.1866
11/15 18:19:18 - mmengine - INFO - Iter(train) [65700/90000]  base_lr: 3.0777e-05 lr: 3.0777e-06  eta: 4:03:52  time: 0.5961  data_time: 0.0104  memory: 10692  grad_norm: 364.7307  loss: 15.0873  decode.loss_cls: 0.0588  decode.loss_mask: 0.4364  decode.loss_dice: 0.9814  decode.d0.loss_cls: 0.0619  decode.d0.loss_mask: 0.4444  decode.d0.loss_dice: 1.1168  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.4314  decode.d1.loss_dice: 1.0252  decode.d2.loss_cls: 0.0453  decode.d2.loss_mask: 0.4354  decode.d2.loss_dice: 1.0177  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.4357  decode.d3.loss_dice: 1.0191  decode.d4.loss_cls: 0.0569  decode.d4.loss_mask: 0.4427  decode.d4.loss_dice: 1.0159  decode.d5.loss_cls: 0.0594  decode.d5.loss_mask: 0.4388  decode.d5.loss_dice: 0.9811  decode.d6.loss_cls: 0.0552  decode.d6.loss_mask: 0.4368  decode.d6.loss_dice: 0.9920  decode.d7.loss_cls: 0.0528  decode.d7.loss_mask: 0.4365  decode.d7.loss_dice: 0.9932  decode.d8.loss_cls: 0.0480  decode.d8.loss_mask: 0.4428  decode.d8.loss_dice: 1.0237
11/15 18:19:47 - mmengine - INFO - Iter(train) [65750/90000]  base_lr: 3.0720e-05 lr: 3.0720e-06  eta: 4:03:22  time: 0.5961  data_time: 0.0106  memory: 10641  grad_norm: 324.8374  loss: 13.8139  decode.loss_cls: 0.0479  decode.loss_mask: 0.4360  decode.loss_dice: 0.8953  decode.d0.loss_cls: 0.1017  decode.d0.loss_mask: 0.4564  decode.d0.loss_dice: 0.9284  decode.d1.loss_cls: 0.0693  decode.d1.loss_mask: 0.4375  decode.d1.loss_dice: 0.8849  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.4283  decode.d2.loss_dice: 0.9008  decode.d3.loss_cls: 0.0601  decode.d3.loss_mask: 0.4319  decode.d3.loss_dice: 0.8913  decode.d4.loss_cls: 0.0546  decode.d4.loss_mask: 0.4286  decode.d4.loss_dice: 0.8794  decode.d5.loss_cls: 0.0498  decode.d5.loss_mask: 0.4261  decode.d5.loss_dice: 0.8759  decode.d6.loss_cls: 0.0487  decode.d6.loss_mask: 0.4284  decode.d6.loss_dice: 0.8571  decode.d7.loss_cls: 0.0516  decode.d7.loss_mask: 0.4310  decode.d7.loss_dice: 0.8752  decode.d8.loss_cls: 0.0465  decode.d8.loss_mask: 0.4291  decode.d8.loss_dice: 0.9134
11/15 18:20:17 - mmengine - INFO - Iter(train) [65800/90000]  base_lr: 3.0663e-05 lr: 3.0663e-06  eta: 4:02:51  time: 0.5962  data_time: 0.0105  memory: 10692  grad_norm: 263.8033  loss: 16.4347  decode.loss_cls: 0.0608  decode.loss_mask: 0.3996  decode.loss_dice: 1.1848  decode.d0.loss_cls: 0.0755  decode.d0.loss_mask: 0.4105  decode.d0.loss_dice: 1.2286  decode.d1.loss_cls: 0.0593  decode.d1.loss_mask: 0.4049  decode.d1.loss_dice: 1.1976  decode.d2.loss_cls: 0.0447  decode.d2.loss_mask: 0.4087  decode.d2.loss_dice: 1.1982  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.4105  decode.d3.loss_dice: 1.1397  decode.d4.loss_cls: 0.0576  decode.d4.loss_mask: 0.4045  decode.d4.loss_dice: 1.1523  decode.d5.loss_cls: 0.0460  decode.d5.loss_mask: 0.4043  decode.d5.loss_dice: 1.1884  decode.d6.loss_cls: 0.0459  decode.d6.loss_mask: 0.4029  decode.d6.loss_dice: 1.1818  decode.d7.loss_cls: 0.0515  decode.d7.loss_mask: 0.4019  decode.d7.loss_dice: 1.1684  decode.d8.loss_cls: 0.0577  decode.d8.loss_mask: 0.4035  decode.d8.loss_dice: 1.1817
11/15 18:20:47 - mmengine - INFO - Iter(train) [65850/90000]  base_lr: 3.0606e-05 lr: 3.0606e-06  eta: 4:02:21  time: 0.5961  data_time: 0.0104  memory: 10692  grad_norm: 302.5122  loss: 15.4881  decode.loss_cls: 0.0864  decode.loss_mask: 0.4295  decode.loss_dice: 0.9905  decode.d0.loss_cls: 0.0983  decode.d0.loss_mask: 0.4221  decode.d0.loss_dice: 1.0969  decode.d1.loss_cls: 0.0916  decode.d1.loss_mask: 0.4293  decode.d1.loss_dice: 1.0847  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.4309  decode.d2.loss_dice: 1.0809  decode.d3.loss_cls: 0.0871  decode.d3.loss_mask: 0.4272  decode.d3.loss_dice: 0.9808  decode.d4.loss_cls: 0.0763  decode.d4.loss_mask: 0.4257  decode.d4.loss_dice: 1.0172  decode.d5.loss_cls: 0.0773  decode.d5.loss_mask: 0.4303  decode.d5.loss_dice: 1.0216  decode.d6.loss_cls: 0.0962  decode.d6.loss_mask: 0.4288  decode.d6.loss_dice: 1.0213  decode.d7.loss_cls: 0.0833  decode.d7.loss_mask: 0.4373  decode.d7.loss_dice: 1.0263  decode.d8.loss_cls: 0.0814  decode.d8.loss_mask: 0.4383  decode.d8.loss_dice: 1.0178
11/15 18:21:17 - mmengine - INFO - Iter(train) [65900/90000]  base_lr: 3.0549e-05 lr: 3.0549e-06  eta: 4:01:51  time: 0.5970  data_time: 0.0104  memory: 10758  grad_norm: 596.6004  loss: 16.5712  decode.loss_cls: 0.0619  decode.loss_mask: 0.5617  decode.loss_dice: 1.0223  decode.d0.loss_cls: 0.0776  decode.d0.loss_mask: 0.5943  decode.d0.loss_dice: 1.0882  decode.d1.loss_cls: 0.0627  decode.d1.loss_mask: 0.5264  decode.d1.loss_dice: 1.0498  decode.d2.loss_cls: 0.0614  decode.d2.loss_mask: 0.5187  decode.d2.loss_dice: 1.0510  decode.d3.loss_cls: 0.0600  decode.d3.loss_mask: 0.5352  decode.d3.loss_dice: 1.0573  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.5337  decode.d4.loss_dice: 1.0410  decode.d5.loss_cls: 0.0538  decode.d5.loss_mask: 0.5607  decode.d5.loss_dice: 1.0340  decode.d6.loss_cls: 0.0563  decode.d6.loss_mask: 0.5645  decode.d6.loss_dice: 1.0367  decode.d7.loss_cls: 0.0704  decode.d7.loss_mask: 0.5639  decode.d7.loss_dice: 1.0170  decode.d8.loss_cls: 0.0667  decode.d8.loss_mask: 0.5597  decode.d8.loss_dice: 1.0217
11/15 18:21:47 - mmengine - INFO - Iter(train) [65950/90000]  base_lr: 3.0492e-05 lr: 3.0492e-06  eta: 4:01:21  time: 0.5963  data_time: 0.0103  memory: 10656  grad_norm: 418.5020  loss: 16.2014  decode.loss_cls: 0.0455  decode.loss_mask: 0.5090  decode.loss_dice: 1.0600  decode.d0.loss_cls: 0.0820  decode.d0.loss_mask: 0.5167  decode.d0.loss_dice: 1.1350  decode.d1.loss_cls: 0.0572  decode.d1.loss_mask: 0.4930  decode.d1.loss_dice: 1.0866  decode.d2.loss_cls: 0.0540  decode.d2.loss_mask: 0.4858  decode.d2.loss_dice: 1.0498  decode.d3.loss_cls: 0.0505  decode.d3.loss_mask: 0.4881  decode.d3.loss_dice: 1.0546  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.4833  decode.d4.loss_dice: 1.0374  decode.d5.loss_cls: 0.0467  decode.d5.loss_mask: 0.5020  decode.d5.loss_dice: 1.0222  decode.d6.loss_cls: 0.0547  decode.d6.loss_mask: 0.5084  decode.d6.loss_dice: 1.0832  decode.d7.loss_cls: 0.0502  decode.d7.loss_mask: 0.5150  decode.d7.loss_dice: 1.0410  decode.d8.loss_cls: 0.0570  decode.d8.loss_mask: 0.5079  decode.d8.loss_dice: 1.0654
11/15 18:22:20 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 18:22:20 - mmengine - INFO - Iter(train) [66000/90000]  base_lr: 3.0435e-05 lr: 3.0435e-06  eta: 4:00:52  time: 0.8991  data_time: 0.0275  memory: 10692  grad_norm: 315.1686  loss: 14.8107  decode.loss_cls: 0.0370  decode.loss_mask: 0.4648  decode.loss_dice: 0.9496  decode.d0.loss_cls: 0.0837  decode.d0.loss_mask: 0.4719  decode.d0.loss_dice: 1.0030  decode.d1.loss_cls: 0.0645  decode.d1.loss_mask: 0.4982  decode.d1.loss_dice: 0.9603  decode.d2.loss_cls: 0.0436  decode.d2.loss_mask: 0.4908  decode.d2.loss_dice: 0.9673  decode.d3.loss_cls: 0.0400  decode.d3.loss_mask: 0.4773  decode.d3.loss_dice: 0.9535  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.4734  decode.d4.loss_dice: 0.9814  decode.d5.loss_cls: 0.0401  decode.d5.loss_mask: 0.4693  decode.d5.loss_dice: 0.9541  decode.d6.loss_cls: 0.0394  decode.d6.loss_mask: 0.4663  decode.d6.loss_dice: 0.9483  decode.d7.loss_cls: 0.0439  decode.d7.loss_mask: 0.4560  decode.d7.loss_dice: 0.9618  decode.d8.loss_cls: 0.0512  decode.d8.loss_mask: 0.4410  decode.d8.loss_dice: 0.9306
11/15 18:22:50 - mmengine - INFO - Iter(train) [66050/90000]  base_lr: 3.0378e-05 lr: 3.0378e-06  eta: 4:00:22  time: 0.5965  data_time: 0.0106  memory: 10656  grad_norm: 265.1543  loss: 14.4931  decode.loss_cls: 0.0653  decode.loss_mask: 0.4072  decode.loss_dice: 0.9606  decode.d0.loss_cls: 0.0878  decode.d0.loss_mask: 0.4276  decode.d0.loss_dice: 1.1257  decode.d1.loss_cls: 0.0646  decode.d1.loss_mask: 0.4186  decode.d1.loss_dice: 0.9883  decode.d2.loss_cls: 0.0769  decode.d2.loss_mask: 0.4090  decode.d2.loss_dice: 0.9683  decode.d3.loss_cls: 0.0556  decode.d3.loss_mask: 0.4010  decode.d3.loss_dice: 0.9698  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.4025  decode.d4.loss_dice: 0.9340  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.4066  decode.d5.loss_dice: 0.9477  decode.d6.loss_cls: 0.0644  decode.d6.loss_mask: 0.4074  decode.d6.loss_dice: 0.9452  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.4114  decode.d7.loss_dice: 0.9426  decode.d8.loss_cls: 0.0653  decode.d8.loss_mask: 0.4074  decode.d8.loss_dice: 0.9382
11/15 18:23:20 - mmengine - INFO - Iter(train) [66100/90000]  base_lr: 3.0321e-05 lr: 3.0321e-06  eta: 3:59:52  time: 0.5976  data_time: 0.0107  memory: 10641  grad_norm: 353.2578  loss: 17.1910  decode.loss_cls: 0.0745  decode.loss_mask: 0.4840  decode.loss_dice: 1.1305  decode.d0.loss_cls: 0.1037  decode.d0.loss_mask: 0.5035  decode.d0.loss_dice: 1.2297  decode.d1.loss_cls: 0.0917  decode.d1.loss_mask: 0.4827  decode.d1.loss_dice: 1.1781  decode.d2.loss_cls: 0.0921  decode.d2.loss_mask: 0.4742  decode.d2.loss_dice: 1.1550  decode.d3.loss_cls: 0.0721  decode.d3.loss_mask: 0.4801  decode.d3.loss_dice: 1.1397  decode.d4.loss_cls: 0.0660  decode.d4.loss_mask: 0.4790  decode.d4.loss_dice: 1.1626  decode.d5.loss_cls: 0.0725  decode.d5.loss_mask: 0.4868  decode.d5.loss_dice: 1.1462  decode.d6.loss_cls: 0.0815  decode.d6.loss_mask: 0.4754  decode.d6.loss_dice: 1.1470  decode.d7.loss_cls: 0.0675  decode.d7.loss_mask: 0.4850  decode.d7.loss_dice: 1.1335  decode.d8.loss_cls: 0.0734  decode.d8.loss_mask: 0.4855  decode.d8.loss_dice: 1.1373
11/15 18:23:50 - mmengine - INFO - Iter(train) [66150/90000]  base_lr: 3.0264e-05 lr: 3.0264e-06  eta: 3:59:21  time: 0.5969  data_time: 0.0106  memory: 10641  grad_norm: 450.8433  loss: 17.0439  decode.loss_cls: 0.0689  decode.loss_mask: 0.4936  decode.loss_dice: 1.0990  decode.d0.loss_cls: 0.0763  decode.d0.loss_mask: 0.5084  decode.d0.loss_dice: 1.2259  decode.d1.loss_cls: 0.0759  decode.d1.loss_mask: 0.4875  decode.d1.loss_dice: 1.1574  decode.d2.loss_cls: 0.0710  decode.d2.loss_mask: 0.4907  decode.d2.loss_dice: 1.1255  decode.d3.loss_cls: 0.0745  decode.d3.loss_mask: 0.4921  decode.d3.loss_dice: 1.1055  decode.d4.loss_cls: 0.0715  decode.d4.loss_mask: 0.4835  decode.d4.loss_dice: 1.1377  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.4886  decode.d5.loss_dice: 1.1250  decode.d6.loss_cls: 0.0672  decode.d6.loss_mask: 0.4961  decode.d6.loss_dice: 1.1351  decode.d7.loss_cls: 0.0684  decode.d7.loss_mask: 0.4952  decode.d7.loss_dice: 1.1337  decode.d8.loss_cls: 0.0689  decode.d8.loss_mask: 0.5073  decode.d8.loss_dice: 1.1505
11/15 18:24:20 - mmengine - INFO - Iter(train) [66200/90000]  base_lr: 3.0207e-05 lr: 3.0207e-06  eta: 3:58:51  time: 0.5960  data_time: 0.0106  memory: 10675  grad_norm: 406.4118  loss: 15.9562  decode.loss_cls: 0.0634  decode.loss_mask: 0.4917  decode.loss_dice: 1.0094  decode.d0.loss_cls: 0.0807  decode.d0.loss_mask: 0.5254  decode.d0.loss_dice: 1.1231  decode.d1.loss_cls: 0.0810  decode.d1.loss_mask: 0.4962  decode.d1.loss_dice: 1.0332  decode.d2.loss_cls: 0.0709  decode.d2.loss_mask: 0.4953  decode.d2.loss_dice: 1.0454  decode.d3.loss_cls: 0.0709  decode.d3.loss_mask: 0.4828  decode.d3.loss_dice: 1.0091  decode.d4.loss_cls: 0.0739  decode.d4.loss_mask: 0.4903  decode.d4.loss_dice: 0.9953  decode.d5.loss_cls: 0.0697  decode.d5.loss_mask: 0.4894  decode.d5.loss_dice: 1.0189  decode.d6.loss_cls: 0.0754  decode.d6.loss_mask: 0.4873  decode.d6.loss_dice: 1.0022  decode.d7.loss_cls: 0.0738  decode.d7.loss_mask: 0.4946  decode.d7.loss_dice: 1.0177  decode.d8.loss_cls: 0.0649  decode.d8.loss_mask: 0.4929  decode.d8.loss_dice: 1.0312
11/15 18:24:51 - mmengine - INFO - Iter(train) [66250/90000]  base_lr: 3.0150e-05 lr: 3.0150e-06  eta: 3:58:21  time: 0.7079  data_time: 0.0105  memory: 10692  grad_norm: 538.9762  loss: 17.7042  decode.loss_cls: 0.0615  decode.loss_mask: 0.5899  decode.loss_dice: 1.1109  decode.d0.loss_cls: 0.0921  decode.d0.loss_mask: 0.6091  decode.d0.loss_dice: 1.1936  decode.d1.loss_cls: 0.0638  decode.d1.loss_mask: 0.5909  decode.d1.loss_dice: 1.1038  decode.d2.loss_cls: 0.0670  decode.d2.loss_mask: 0.6093  decode.d2.loss_dice: 1.1181  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.5936  decode.d3.loss_dice: 1.0989  decode.d4.loss_cls: 0.0654  decode.d4.loss_mask: 0.5852  decode.d4.loss_dice: 1.1053  decode.d5.loss_cls: 0.0624  decode.d5.loss_mask: 0.5879  decode.d5.loss_dice: 1.1109  decode.d6.loss_cls: 0.0613  decode.d6.loss_mask: 0.6011  decode.d6.loss_dice: 1.0820  decode.d7.loss_cls: 0.0664  decode.d7.loss_mask: 0.5946  decode.d7.loss_dice: 1.0696  decode.d8.loss_cls: 0.0610  decode.d8.loss_mask: 0.5938  decode.d8.loss_dice: 1.0949
11/15 18:25:21 - mmengine - INFO - Iter(train) [66300/90000]  base_lr: 3.0093e-05 lr: 3.0093e-06  eta: 3:57:51  time: 0.6138  data_time: 0.0107  memory: 10641  grad_norm: 388.2401  loss: 16.1533  decode.loss_cls: 0.0663  decode.loss_mask: 0.4931  decode.loss_dice: 1.0738  decode.d0.loss_cls: 0.0892  decode.d0.loss_mask: 0.5005  decode.d0.loss_dice: 1.0968  decode.d1.loss_cls: 0.0552  decode.d1.loss_mask: 0.4954  decode.d1.loss_dice: 1.0839  decode.d2.loss_cls: 0.0627  decode.d2.loss_mask: 0.4830  decode.d2.loss_dice: 1.0367  decode.d3.loss_cls: 0.0540  decode.d3.loss_mask: 0.4832  decode.d3.loss_dice: 1.0516  decode.d4.loss_cls: 0.0519  decode.d4.loss_mask: 0.4877  decode.d4.loss_dice: 1.0801  decode.d5.loss_cls: 0.0602  decode.d5.loss_mask: 0.4741  decode.d5.loss_dice: 1.0548  decode.d6.loss_cls: 0.0700  decode.d6.loss_mask: 0.4846  decode.d6.loss_dice: 1.0649  decode.d7.loss_cls: 0.0737  decode.d7.loss_mask: 0.4812  decode.d7.loss_dice: 1.0511  decode.d8.loss_cls: 0.0577  decode.d8.loss_mask: 0.4838  decode.d8.loss_dice: 1.0522
11/15 18:25:51 - mmengine - INFO - Iter(train) [66350/90000]  base_lr: 3.0035e-05 lr: 3.0035e-06  eta: 3:57:21  time: 0.5980  data_time: 0.0105  memory: 10692  grad_norm: 474.7805  loss: 16.0743  decode.loss_cls: 0.0520  decode.loss_mask: 0.5170  decode.loss_dice: 1.0243  decode.d0.loss_cls: 0.0706  decode.d0.loss_mask: 0.5467  decode.d0.loss_dice: 1.0492  decode.d1.loss_cls: 0.0373  decode.d1.loss_mask: 0.5268  decode.d1.loss_dice: 1.0492  decode.d2.loss_cls: 0.0370  decode.d2.loss_mask: 0.5242  decode.d2.loss_dice: 1.0269  decode.d3.loss_cls: 0.0415  decode.d3.loss_mask: 0.5193  decode.d3.loss_dice: 1.0265  decode.d4.loss_cls: 0.0394  decode.d4.loss_mask: 0.5213  decode.d4.loss_dice: 1.0248  decode.d5.loss_cls: 0.0455  decode.d5.loss_mask: 0.5199  decode.d5.loss_dice: 1.0448  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 0.5159  decode.d6.loss_dice: 1.0569  decode.d7.loss_cls: 0.0390  decode.d7.loss_mask: 0.5200  decode.d7.loss_dice: 1.0379  decode.d8.loss_cls: 0.0511  decode.d8.loss_mask: 0.5201  decode.d8.loss_dice: 1.0480
11/15 18:26:20 - mmengine - INFO - Iter(train) [66400/90000]  base_lr: 2.9978e-05 lr: 2.9978e-06  eta: 3:56:51  time: 0.5968  data_time: 0.0106  memory: 10675  grad_norm: 622.7528  loss: 18.0843  decode.loss_cls: 0.0721  decode.loss_mask: 0.5483  decode.loss_dice: 1.1597  decode.d0.loss_cls: 0.0998  decode.d0.loss_mask: 0.5790  decode.d0.loss_dice: 1.2583  decode.d1.loss_cls: 0.0765  decode.d1.loss_mask: 0.5521  decode.d1.loss_dice: 1.1904  decode.d2.loss_cls: 0.0775  decode.d2.loss_mask: 0.5578  decode.d2.loss_dice: 1.1870  decode.d3.loss_cls: 0.0769  decode.d3.loss_mask: 0.5482  decode.d3.loss_dice: 1.1604  decode.d4.loss_cls: 0.0840  decode.d4.loss_mask: 0.5488  decode.d4.loss_dice: 1.1518  decode.d5.loss_cls: 0.0714  decode.d5.loss_mask: 0.5472  decode.d5.loss_dice: 1.1629  decode.d6.loss_cls: 0.0680  decode.d6.loss_mask: 0.5519  decode.d6.loss_dice: 1.1750  decode.d7.loss_cls: 0.0710  decode.d7.loss_mask: 0.5506  decode.d7.loss_dice: 1.1615  decode.d8.loss_cls: 0.0698  decode.d8.loss_mask: 0.5529  decode.d8.loss_dice: 1.1735
11/15 18:26:50 - mmengine - INFO - Iter(train) [66450/90000]  base_lr: 2.9921e-05 lr: 2.9921e-06  eta: 3:56:21  time: 0.5976  data_time: 0.0106  memory: 10728  grad_norm: 275.7214  loss: 16.2819  decode.loss_cls: 0.0550  decode.loss_mask: 0.4667  decode.loss_dice: 1.0766  decode.d0.loss_cls: 0.0963  decode.d0.loss_mask: 0.4777  decode.d0.loss_dice: 1.1477  decode.d1.loss_cls: 0.0676  decode.d1.loss_mask: 0.4618  decode.d1.loss_dice: 1.1227  decode.d2.loss_cls: 0.0758  decode.d2.loss_mask: 0.4625  decode.d2.loss_dice: 1.1004  decode.d3.loss_cls: 0.0618  decode.d3.loss_mask: 0.4642  decode.d3.loss_dice: 1.0943  decode.d4.loss_cls: 0.0633  decode.d4.loss_mask: 0.4589  decode.d4.loss_dice: 1.0955  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.4592  decode.d5.loss_dice: 1.0873  decode.d6.loss_cls: 0.0643  decode.d6.loss_mask: 0.4605  decode.d6.loss_dice: 1.0797  decode.d7.loss_cls: 0.0575  decode.d7.loss_mask: 0.4585  decode.d7.loss_dice: 1.0841  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.4609  decode.d8.loss_dice: 1.1010
11/15 18:27:20 - mmengine - INFO - Iter(train) [66500/90000]  base_lr: 2.9864e-05 lr: 2.9864e-06  eta: 3:55:50  time: 0.5958  data_time: 0.0106  memory: 10675  grad_norm: 484.5139  loss: 18.5812  decode.loss_cls: 0.0602  decode.loss_mask: 0.5296  decode.loss_dice: 1.2131  decode.d0.loss_cls: 0.0860  decode.d0.loss_mask: 0.5774  decode.d0.loss_dice: 1.3583  decode.d1.loss_cls: 0.0822  decode.d1.loss_mask: 0.5366  decode.d1.loss_dice: 1.2595  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.5445  decode.d2.loss_dice: 1.2061  decode.d3.loss_cls: 0.0553  decode.d3.loss_mask: 0.5421  decode.d3.loss_dice: 1.2183  decode.d4.loss_cls: 0.0560  decode.d4.loss_mask: 0.5449  decode.d4.loss_dice: 1.2635  decode.d5.loss_cls: 0.0572  decode.d5.loss_mask: 0.5420  decode.d5.loss_dice: 1.2688  decode.d6.loss_cls: 0.0633  decode.d6.loss_mask: 0.5397  decode.d6.loss_dice: 1.2473  decode.d7.loss_cls: 0.0592  decode.d7.loss_mask: 0.5307  decode.d7.loss_dice: 1.2284  decode.d8.loss_cls: 0.0700  decode.d8.loss_mask: 0.5348  decode.d8.loss_dice: 1.2422
11/15 18:27:50 - mmengine - INFO - Iter(train) [66550/90000]  base_lr: 2.9807e-05 lr: 2.9807e-06  eta: 3:55:20  time: 0.5984  data_time: 0.0107  memory: 10692  grad_norm: 244.7628  loss: 14.9027  decode.loss_cls: 0.0502  decode.loss_mask: 0.4396  decode.loss_dice: 0.9640  decode.d0.loss_cls: 0.0845  decode.d0.loss_mask: 0.4548  decode.d0.loss_dice: 1.0265  decode.d1.loss_cls: 0.0554  decode.d1.loss_mask: 0.4465  decode.d1.loss_dice: 1.0295  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.4493  decode.d2.loss_dice: 0.9896  decode.d3.loss_cls: 0.0462  decode.d3.loss_mask: 0.4462  decode.d3.loss_dice: 0.9779  decode.d4.loss_cls: 0.0434  decode.d4.loss_mask: 0.4413  decode.d4.loss_dice: 0.9765  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.4410  decode.d5.loss_dice: 0.9674  decode.d6.loss_cls: 0.0439  decode.d6.loss_mask: 0.4447  decode.d6.loss_dice: 1.0098  decode.d7.loss_cls: 0.0434  decode.d7.loss_mask: 0.4378  decode.d7.loss_dice: 1.0059  decode.d8.loss_cls: 0.0511  decode.d8.loss_mask: 0.4404  decode.d8.loss_dice: 0.9876
11/15 18:28:20 - mmengine - INFO - Iter(train) [66600/90000]  base_lr: 2.9750e-05 lr: 2.9750e-06  eta: 3:54:50  time: 0.5994  data_time: 0.0109  memory: 10692  grad_norm: 299.6484  loss: 15.2064  decode.loss_cls: 0.0685  decode.loss_mask: 0.4529  decode.loss_dice: 0.9553  decode.d0.loss_cls: 0.0909  decode.d0.loss_mask: 0.4847  decode.d0.loss_dice: 1.0776  decode.d1.loss_cls: 0.0837  decode.d1.loss_mask: 0.4698  decode.d1.loss_dice: 0.9992  decode.d2.loss_cls: 0.0742  decode.d2.loss_mask: 0.4662  decode.d2.loss_dice: 0.9820  decode.d3.loss_cls: 0.0624  decode.d3.loss_mask: 0.4657  decode.d3.loss_dice: 0.9727  decode.d4.loss_cls: 0.0842  decode.d4.loss_mask: 0.4581  decode.d4.loss_dice: 0.9413  decode.d5.loss_cls: 0.0757  decode.d5.loss_mask: 0.4666  decode.d5.loss_dice: 0.9759  decode.d6.loss_cls: 0.0672  decode.d6.loss_mask: 0.4658  decode.d6.loss_dice: 0.9824  decode.d7.loss_cls: 0.0717  decode.d7.loss_mask: 0.4621  decode.d7.loss_dice: 0.9603  decode.d8.loss_cls: 0.0682  decode.d8.loss_mask: 0.4590  decode.d8.loss_dice: 0.9622
11/15 18:28:50 - mmengine - INFO - Iter(train) [66650/90000]  base_lr: 2.9692e-05 lr: 2.9692e-06  eta: 3:54:20  time: 0.5956  data_time: 0.0107  memory: 10713  grad_norm: 411.2560  loss: 14.9300  decode.loss_cls: 0.0478  decode.loss_mask: 0.5138  decode.loss_dice: 0.9410  decode.d0.loss_cls: 0.0864  decode.d0.loss_mask: 0.5835  decode.d0.loss_dice: 0.9391  decode.d1.loss_cls: 0.0565  decode.d1.loss_mask: 0.5268  decode.d1.loss_dice: 0.9021  decode.d2.loss_cls: 0.0453  decode.d2.loss_mask: 0.5242  decode.d2.loss_dice: 0.9244  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.5068  decode.d3.loss_dice: 0.9110  decode.d4.loss_cls: 0.0479  decode.d4.loss_mask: 0.5102  decode.d4.loss_dice: 0.9060  decode.d5.loss_cls: 0.0353  decode.d5.loss_mask: 0.5209  decode.d5.loss_dice: 0.9401  decode.d6.loss_cls: 0.0492  decode.d6.loss_mask: 0.5125  decode.d6.loss_dice: 0.9049  decode.d7.loss_cls: 0.0440  decode.d7.loss_mask: 0.5206  decode.d7.loss_dice: 0.8922  decode.d8.loss_cls: 0.0501  decode.d8.loss_mask: 0.5270  decode.d8.loss_dice: 0.9114
11/15 18:29:20 - mmengine - INFO - Iter(train) [66700/90000]  base_lr: 2.9635e-05 lr: 2.9635e-06  eta: 3:53:50  time: 0.5989  data_time: 0.0106  memory: 10641  grad_norm: 241.9104  loss: 16.3565  decode.loss_cls: 0.0804  decode.loss_mask: 0.4737  decode.loss_dice: 1.0783  decode.d0.loss_cls: 0.0676  decode.d0.loss_mask: 0.4791  decode.d0.loss_dice: 1.1712  decode.d1.loss_cls: 0.0768  decode.d1.loss_mask: 0.4649  decode.d1.loss_dice: 1.1122  decode.d2.loss_cls: 0.0624  decode.d2.loss_mask: 0.4605  decode.d2.loss_dice: 1.1096  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.4639  decode.d3.loss_dice: 1.0784  decode.d4.loss_cls: 0.0655  decode.d4.loss_mask: 0.4793  decode.d4.loss_dice: 1.1252  decode.d5.loss_cls: 0.0938  decode.d5.loss_mask: 0.4513  decode.d5.loss_dice: 1.0537  decode.d6.loss_cls: 0.0835  decode.d6.loss_mask: 0.4626  decode.d6.loss_dice: 1.0616  decode.d7.loss_cls: 0.0813  decode.d7.loss_mask: 0.4574  decode.d7.loss_dice: 1.0695  decode.d8.loss_cls: 0.0784  decode.d8.loss_mask: 0.4825  decode.d8.loss_dice: 1.0586
11/15 18:29:50 - mmengine - INFO - Iter(train) [66750/90000]  base_lr: 2.9578e-05 lr: 2.9578e-06  eta: 3:53:20  time: 0.5973  data_time: 0.0106  memory: 10656  grad_norm: 376.0105  loss: 16.5245  decode.loss_cls: 0.0813  decode.loss_mask: 0.4696  decode.loss_dice: 1.0881  decode.d0.loss_cls: 0.1242  decode.d0.loss_mask: 0.4704  decode.d0.loss_dice: 1.1556  decode.d1.loss_cls: 0.0916  decode.d1.loss_mask: 0.4659  decode.d1.loss_dice: 1.1292  decode.d2.loss_cls: 0.0928  decode.d2.loss_mask: 0.4644  decode.d2.loss_dice: 1.0812  decode.d3.loss_cls: 0.0881  decode.d3.loss_mask: 0.4638  decode.d3.loss_dice: 1.1027  decode.d4.loss_cls: 0.0906  decode.d4.loss_mask: 0.4650  decode.d4.loss_dice: 1.0781  decode.d5.loss_cls: 0.0816  decode.d5.loss_mask: 0.4602  decode.d5.loss_dice: 1.0896  decode.d6.loss_cls: 0.0840  decode.d6.loss_mask: 0.4614  decode.d6.loss_dice: 1.0629  decode.d7.loss_cls: 0.0761  decode.d7.loss_mask: 0.4649  decode.d7.loss_dice: 1.1023  decode.d8.loss_cls: 0.0882  decode.d8.loss_mask: 0.4735  decode.d8.loss_dice: 1.0772
11/15 18:30:20 - mmengine - INFO - Iter(train) [66800/90000]  base_lr: 2.9521e-05 lr: 2.9521e-06  eta: 3:52:49  time: 0.5961  data_time: 0.0104  memory: 10675  grad_norm: 289.9192  loss: 16.2223  decode.loss_cls: 0.0587  decode.loss_mask: 0.4783  decode.loss_dice: 1.0413  decode.d0.loss_cls: 0.0662  decode.d0.loss_mask: 0.4924  decode.d0.loss_dice: 1.1672  decode.d1.loss_cls: 0.0646  decode.d1.loss_mask: 0.4835  decode.d1.loss_dice: 1.1283  decode.d2.loss_cls: 0.0612  decode.d2.loss_mask: 0.4757  decode.d2.loss_dice: 1.0818  decode.d3.loss_cls: 0.0696  decode.d3.loss_mask: 0.4706  decode.d3.loss_dice: 1.0860  decode.d4.loss_cls: 0.0574  decode.d4.loss_mask: 0.4744  decode.d4.loss_dice: 1.0903  decode.d5.loss_cls: 0.0532  decode.d5.loss_mask: 0.4693  decode.d5.loss_dice: 1.0488  decode.d6.loss_cls: 0.0741  decode.d6.loss_mask: 0.4686  decode.d6.loss_dice: 1.0538  decode.d7.loss_cls: 0.0650  decode.d7.loss_mask: 0.4746  decode.d7.loss_dice: 1.0743  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.4694  decode.d8.loss_dice: 1.0499
11/15 18:30:50 - mmengine - INFO - Iter(train) [66850/90000]  base_lr: 2.9463e-05 lr: 2.9463e-06  eta: 3:52:19  time: 0.5973  data_time: 0.0105  memory: 10713  grad_norm: 422.0416  loss: 14.6320  decode.loss_cls: 0.0494  decode.loss_mask: 0.3669  decode.loss_dice: 1.0472  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 0.3713  decode.d0.loss_dice: 1.0891  decode.d1.loss_cls: 0.0604  decode.d1.loss_mask: 0.3702  decode.d1.loss_dice: 1.0595  decode.d2.loss_cls: 0.0532  decode.d2.loss_mask: 0.3768  decode.d2.loss_dice: 1.0502  decode.d3.loss_cls: 0.0466  decode.d3.loss_mask: 0.3732  decode.d3.loss_dice: 1.0354  decode.d4.loss_cls: 0.0461  decode.d4.loss_mask: 0.3712  decode.d4.loss_dice: 1.0206  decode.d5.loss_cls: 0.0535  decode.d5.loss_mask: 0.3675  decode.d5.loss_dice: 1.0358  decode.d6.loss_cls: 0.0496  decode.d6.loss_mask: 0.3669  decode.d6.loss_dice: 1.0286  decode.d7.loss_cls: 0.0439  decode.d7.loss_mask: 0.3645  decode.d7.loss_dice: 1.0214  decode.d8.loss_cls: 0.0446  decode.d8.loss_mask: 0.3645  decode.d8.loss_dice: 1.0249
11/15 18:31:19 - mmengine - INFO - Iter(train) [66900/90000]  base_lr: 2.9406e-05 lr: 2.9406e-06  eta: 3:51:49  time: 0.5969  data_time: 0.0106  memory: 10675  grad_norm: 370.1880  loss: 15.9628  decode.loss_cls: 0.0680  decode.loss_mask: 0.4373  decode.loss_dice: 1.0599  decode.d0.loss_cls: 0.0787  decode.d0.loss_mask: 0.4852  decode.d0.loss_dice: 1.1718  decode.d1.loss_cls: 0.0623  decode.d1.loss_mask: 0.4563  decode.d1.loss_dice: 1.1162  decode.d2.loss_cls: 0.0785  decode.d2.loss_mask: 0.4332  decode.d2.loss_dice: 1.0666  decode.d3.loss_cls: 0.0725  decode.d3.loss_mask: 0.4331  decode.d3.loss_dice: 1.0595  decode.d4.loss_cls: 0.0596  decode.d4.loss_mask: 0.4393  decode.d4.loss_dice: 1.0836  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.4375  decode.d5.loss_dice: 1.0831  decode.d6.loss_cls: 0.0686  decode.d6.loss_mask: 0.4331  decode.d6.loss_dice: 1.0703  decode.d7.loss_cls: 0.0807  decode.d7.loss_mask: 0.4369  decode.d7.loss_dice: 1.0586  decode.d8.loss_cls: 0.0687  decode.d8.loss_mask: 0.4350  decode.d8.loss_dice: 1.0662
11/15 18:31:49 - mmengine - INFO - Iter(train) [66950/90000]  base_lr: 2.9349e-05 lr: 2.9349e-06  eta: 3:51:19  time: 0.5972  data_time: 0.0105  memory: 10675  grad_norm: 254.6031  loss: 13.0529  decode.loss_cls: 0.0412  decode.loss_mask: 0.3597  decode.loss_dice: 0.9062  decode.d0.loss_cls: 0.0578  decode.d0.loss_mask: 0.3600  decode.d0.loss_dice: 0.9739  decode.d1.loss_cls: 0.0341  decode.d1.loss_mask: 0.3561  decode.d1.loss_dice: 0.9300  decode.d2.loss_cls: 0.0437  decode.d2.loss_mask: 0.3611  decode.d2.loss_dice: 0.9073  decode.d3.loss_cls: 0.0395  decode.d3.loss_mask: 0.3604  decode.d3.loss_dice: 0.8780  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.3614  decode.d4.loss_dice: 0.8899  decode.d5.loss_cls: 0.0404  decode.d5.loss_mask: 0.3587  decode.d5.loss_dice: 0.8822  decode.d6.loss_cls: 0.0394  decode.d6.loss_mask: 0.3618  decode.d6.loss_dice: 0.8945  decode.d7.loss_cls: 0.0424  decode.d7.loss_mask: 0.3570  decode.d7.loss_dice: 0.8727  decode.d8.loss_cls: 0.0403  decode.d8.loss_mask: 0.3613  decode.d8.loss_dice: 0.9002
11/15 18:32:19 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 18:32:19 - mmengine - INFO - Iter(train) [67000/90000]  base_lr: 2.9291e-05 lr: 2.9291e-06  eta: 3:50:49  time: 0.5960  data_time: 0.0106  memory: 10675  grad_norm: 232.6451  loss: 15.8076  decode.loss_cls: 0.0516  decode.loss_mask: 0.4522  decode.loss_dice: 1.0671  decode.d0.loss_cls: 0.0743  decode.d0.loss_mask: 0.4625  decode.d0.loss_dice: 1.1188  decode.d1.loss_cls: 0.0811  decode.d1.loss_mask: 0.4452  decode.d1.loss_dice: 1.0626  decode.d2.loss_cls: 0.0682  decode.d2.loss_mask: 0.4425  decode.d2.loss_dice: 1.0479  decode.d3.loss_cls: 0.0648  decode.d3.loss_mask: 0.4424  decode.d3.loss_dice: 1.0500  decode.d4.loss_cls: 0.0575  decode.d4.loss_mask: 0.4645  decode.d4.loss_dice: 1.0792  decode.d5.loss_cls: 0.0639  decode.d5.loss_mask: 0.4589  decode.d5.loss_dice: 1.0628  decode.d6.loss_cls: 0.0590  decode.d6.loss_mask: 0.4578  decode.d6.loss_dice: 1.0581  decode.d7.loss_cls: 0.0530  decode.d7.loss_mask: 0.4550  decode.d7.loss_dice: 1.0536  decode.d8.loss_cls: 0.0602  decode.d8.loss_mask: 0.4516  decode.d8.loss_dice: 1.0416
11/15 18:32:49 - mmengine - INFO - Iter(train) [67050/90000]  base_lr: 2.9234e-05 lr: 2.9234e-06  eta: 3:50:18  time: 0.5952  data_time: 0.0103  memory: 10728  grad_norm: 387.3377  loss: 17.1231  decode.loss_cls: 0.0734  decode.loss_mask: 0.5691  decode.loss_dice: 1.0068  decode.d0.loss_cls: 0.1186  decode.d0.loss_mask: 0.6042  decode.d0.loss_dice: 1.1082  decode.d1.loss_cls: 0.0837  decode.d1.loss_mask: 0.6114  decode.d1.loss_dice: 1.0828  decode.d2.loss_cls: 0.0744  decode.d2.loss_mask: 0.5918  decode.d2.loss_dice: 1.0512  decode.d3.loss_cls: 0.0790  decode.d3.loss_mask: 0.5760  decode.d3.loss_dice: 1.0454  decode.d4.loss_cls: 0.0740  decode.d4.loss_mask: 0.5740  decode.d4.loss_dice: 1.0499  decode.d5.loss_cls: 0.0760  decode.d5.loss_mask: 0.5696  decode.d5.loss_dice: 1.0379  decode.d6.loss_cls: 0.0751  decode.d6.loss_mask: 0.5723  decode.d6.loss_dice: 1.0540  decode.d7.loss_cls: 0.0773  decode.d7.loss_mask: 0.5748  decode.d7.loss_dice: 1.0405  decode.d8.loss_cls: 0.0784  decode.d8.loss_mask: 0.5764  decode.d8.loss_dice: 1.0170
11/15 18:33:19 - mmengine - INFO - Iter(train) [67100/90000]  base_lr: 2.9177e-05 lr: 2.9177e-06  eta: 3:49:48  time: 0.5959  data_time: 0.0105  memory: 10713  grad_norm: 277.5443  loss: 16.0239  decode.loss_cls: 0.0587  decode.loss_mask: 0.4404  decode.loss_dice: 1.1092  decode.d0.loss_cls: 0.0869  decode.d0.loss_mask: 0.4618  decode.d0.loss_dice: 1.1435  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.4383  decode.d1.loss_dice: 1.1055  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 0.4421  decode.d2.loss_dice: 1.1215  decode.d3.loss_cls: 0.0572  decode.d3.loss_mask: 0.4367  decode.d3.loss_dice: 1.0984  decode.d4.loss_cls: 0.0537  decode.d4.loss_mask: 0.4383  decode.d4.loss_dice: 1.0972  decode.d5.loss_cls: 0.0568  decode.d5.loss_mask: 0.4410  decode.d5.loss_dice: 1.0876  decode.d6.loss_cls: 0.0488  decode.d6.loss_mask: 0.4330  decode.d6.loss_dice: 1.0979  decode.d7.loss_cls: 0.0517  decode.d7.loss_mask: 0.4366  decode.d7.loss_dice: 1.0852  decode.d8.loss_cls: 0.0547  decode.d8.loss_mask: 0.4354  decode.d8.loss_dice: 1.0888
11/15 18:33:49 - mmengine - INFO - Iter(train) [67150/90000]  base_lr: 2.9119e-05 lr: 2.9119e-06  eta: 3:49:18  time: 0.5953  data_time: 0.0104  memory: 10713  grad_norm: 237.2524  loss: 14.6084  decode.loss_cls: 0.0562  decode.loss_mask: 0.4728  decode.loss_dice: 0.9095  decode.d0.loss_cls: 0.0885  decode.d0.loss_mask: 0.4752  decode.d0.loss_dice: 0.9804  decode.d1.loss_cls: 0.0601  decode.d1.loss_mask: 0.4930  decode.d1.loss_dice: 0.9543  decode.d2.loss_cls: 0.0705  decode.d2.loss_mask: 0.4789  decode.d2.loss_dice: 0.9246  decode.d3.loss_cls: 0.0597  decode.d3.loss_mask: 0.4727  decode.d3.loss_dice: 0.9192  decode.d4.loss_cls: 0.0637  decode.d4.loss_mask: 0.4697  decode.d4.loss_dice: 0.8942  decode.d5.loss_cls: 0.0591  decode.d5.loss_mask: 0.4749  decode.d5.loss_dice: 0.9175  decode.d6.loss_cls: 0.0576  decode.d6.loss_mask: 0.4711  decode.d6.loss_dice: 0.8943  decode.d7.loss_cls: 0.0638  decode.d7.loss_mask: 0.4704  decode.d7.loss_dice: 0.9034  decode.d8.loss_cls: 0.0681  decode.d8.loss_mask: 0.4728  decode.d8.loss_dice: 0.9123
11/15 18:34:19 - mmengine - INFO - Iter(train) [67200/90000]  base_lr: 2.9062e-05 lr: 2.9062e-06  eta: 3:48:48  time: 0.5963  data_time: 0.0103  memory: 10675  grad_norm: 220.0856  loss: 16.8928  decode.loss_cls: 0.0416  decode.loss_mask: 0.5673  decode.loss_dice: 1.0440  decode.d0.loss_cls: 0.0760  decode.d0.loss_mask: 0.5854  decode.d0.loss_dice: 1.1664  decode.d1.loss_cls: 0.0463  decode.d1.loss_mask: 0.5723  decode.d1.loss_dice: 1.1115  decode.d2.loss_cls: 0.0459  decode.d2.loss_mask: 0.5634  decode.d2.loss_dice: 1.0798  decode.d3.loss_cls: 0.0386  decode.d3.loss_mask: 0.5604  decode.d3.loss_dice: 1.0820  decode.d4.loss_cls: 0.0425  decode.d4.loss_mask: 0.5567  decode.d4.loss_dice: 1.0540  decode.d5.loss_cls: 0.0383  decode.d5.loss_mask: 0.5636  decode.d5.loss_dice: 1.0523  decode.d6.loss_cls: 0.0393  decode.d6.loss_mask: 0.5551  decode.d6.loss_dice: 1.0662  decode.d7.loss_cls: 0.0391  decode.d7.loss_mask: 0.5673  decode.d7.loss_dice: 1.0781  decode.d8.loss_cls: 0.0396  decode.d8.loss_mask: 0.5637  decode.d8.loss_dice: 1.0561
11/15 18:34:48 - mmengine - INFO - Iter(train) [67250/90000]  base_lr: 2.9005e-05 lr: 2.9005e-06  eta: 3:48:18  time: 0.5972  data_time: 0.0106  memory: 10656  grad_norm: 214.7053  loss: 16.0402  decode.loss_cls: 0.0555  decode.loss_mask: 0.4677  decode.loss_dice: 1.0740  decode.d0.loss_cls: 0.0864  decode.d0.loss_mask: 0.4803  decode.d0.loss_dice: 1.1093  decode.d1.loss_cls: 0.0736  decode.d1.loss_mask: 0.4773  decode.d1.loss_dice: 1.0571  decode.d2.loss_cls: 0.0708  decode.d2.loss_mask: 0.4743  decode.d2.loss_dice: 1.0627  decode.d3.loss_cls: 0.0562  decode.d3.loss_mask: 0.4695  decode.d3.loss_dice: 1.0789  decode.d4.loss_cls: 0.0480  decode.d4.loss_mask: 0.4702  decode.d4.loss_dice: 1.0756  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.4692  decode.d5.loss_dice: 1.0448  decode.d6.loss_cls: 0.0554  decode.d6.loss_mask: 0.4695  decode.d6.loss_dice: 1.0567  decode.d7.loss_cls: 0.0662  decode.d7.loss_mask: 0.4686  decode.d7.loss_dice: 1.0769  decode.d8.loss_cls: 0.0571  decode.d8.loss_mask: 0.4670  decode.d8.loss_dice: 1.0586
11/15 18:35:19 - mmengine - INFO - Iter(train) [67300/90000]  base_lr: 2.8947e-05 lr: 2.8947e-06  eta: 3:47:48  time: 0.5962  data_time: 0.0106  memory: 10728  grad_norm: 303.3920  loss: 16.7784  decode.loss_cls: 0.0701  decode.loss_mask: 0.5426  decode.loss_dice: 1.0439  decode.d0.loss_cls: 0.0801  decode.d0.loss_mask: 0.5571  decode.d0.loss_dice: 1.1164  decode.d1.loss_cls: 0.0614  decode.d1.loss_mask: 0.5421  decode.d1.loss_dice: 1.0934  decode.d2.loss_cls: 0.0554  decode.d2.loss_mask: 0.5404  decode.d2.loss_dice: 1.0856  decode.d3.loss_cls: 0.0532  decode.d3.loss_mask: 0.5482  decode.d3.loss_dice: 1.0932  decode.d4.loss_cls: 0.0553  decode.d4.loss_mask: 0.5373  decode.d4.loss_dice: 1.0599  decode.d5.loss_cls: 0.0606  decode.d5.loss_mask: 0.5373  decode.d5.loss_dice: 1.0520  decode.d6.loss_cls: 0.0719  decode.d6.loss_mask: 0.5416  decode.d6.loss_dice: 1.0436  decode.d7.loss_cls: 0.0607  decode.d7.loss_mask: 0.5435  decode.d7.loss_dice: 1.0489  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.5398  decode.d8.loss_dice: 1.0719
11/15 18:35:49 - mmengine - INFO - Iter(train) [67350/90000]  base_lr: 2.8890e-05 lr: 2.8890e-06  eta: 3:47:18  time: 0.5971  data_time: 0.0106  memory: 10675  grad_norm: 330.6910  loss: 15.9515  decode.loss_cls: 0.0553  decode.loss_mask: 0.4885  decode.loss_dice: 1.0329  decode.d0.loss_cls: 0.0880  decode.d0.loss_mask: 0.4975  decode.d0.loss_dice: 1.1525  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 0.5069  decode.d1.loss_dice: 1.0735  decode.d2.loss_cls: 0.0676  decode.d2.loss_mask: 0.5034  decode.d2.loss_dice: 1.0252  decode.d3.loss_cls: 0.0426  decode.d3.loss_mask: 0.4916  decode.d3.loss_dice: 1.0165  decode.d4.loss_cls: 0.0435  decode.d4.loss_mask: 0.4924  decode.d4.loss_dice: 1.0267  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.4924  decode.d5.loss_dice: 1.0421  decode.d6.loss_cls: 0.0661  decode.d6.loss_mask: 0.4868  decode.d6.loss_dice: 1.0092  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.4975  decode.d7.loss_dice: 1.0191  decode.d8.loss_cls: 0.0536  decode.d8.loss_mask: 0.4927  decode.d8.loss_dice: 1.0186
11/15 18:36:19 - mmengine - INFO - Iter(train) [67400/90000]  base_lr: 2.8833e-05 lr: 2.8833e-06  eta: 3:46:47  time: 0.5960  data_time: 0.0105  memory: 10692  grad_norm: 380.0903  loss: 15.6463  decode.loss_cls: 0.0639  decode.loss_mask: 0.4321  decode.loss_dice: 1.0493  decode.d0.loss_cls: 0.1027  decode.d0.loss_mask: 0.4456  decode.d0.loss_dice: 1.1167  decode.d1.loss_cls: 0.0900  decode.d1.loss_mask: 0.4395  decode.d1.loss_dice: 1.0881  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.4325  decode.d2.loss_dice: 1.0434  decode.d3.loss_cls: 0.0801  decode.d3.loss_mask: 0.4316  decode.d3.loss_dice: 1.0562  decode.d4.loss_cls: 0.0849  decode.d4.loss_mask: 0.4278  decode.d4.loss_dice: 1.0220  decode.d5.loss_cls: 0.0767  decode.d5.loss_mask: 0.4275  decode.d5.loss_dice: 1.0307  decode.d6.loss_cls: 0.0790  decode.d6.loss_mask: 0.4294  decode.d6.loss_dice: 1.0508  decode.d7.loss_cls: 0.0933  decode.d7.loss_mask: 0.4300  decode.d7.loss_dice: 1.0002  decode.d8.loss_cls: 0.0914  decode.d8.loss_mask: 0.4320  decode.d8.loss_dice: 1.0177
11/15 18:36:49 - mmengine - INFO - Iter(train) [67450/90000]  base_lr: 2.8775e-05 lr: 2.8775e-06  eta: 3:46:17  time: 0.5979  data_time: 0.0107  memory: 10675  grad_norm: 264.3402  loss: 14.0243  decode.loss_cls: 0.0580  decode.loss_mask: 0.3743  decode.loss_dice: 0.9465  decode.d0.loss_cls: 0.0587  decode.d0.loss_mask: 0.3778  decode.d0.loss_dice: 1.0610  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.3706  decode.d1.loss_dice: 0.9852  decode.d2.loss_cls: 0.0646  decode.d2.loss_mask: 0.3763  decode.d2.loss_dice: 0.9863  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 0.3776  decode.d3.loss_dice: 0.9786  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.3738  decode.d4.loss_dice: 0.9334  decode.d5.loss_cls: 0.0635  decode.d5.loss_mask: 0.3708  decode.d5.loss_dice: 0.9398  decode.d6.loss_cls: 0.0627  decode.d6.loss_mask: 0.3669  decode.d6.loss_dice: 0.9669  decode.d7.loss_cls: 0.0715  decode.d7.loss_mask: 0.3635  decode.d7.loss_dice: 0.9321  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.3594  decode.d8.loss_dice: 0.9422
11/15 18:37:19 - mmengine - INFO - Iter(train) [67500/90000]  base_lr: 2.8718e-05 lr: 2.8718e-06  eta: 3:45:47  time: 0.5985  data_time: 0.0108  memory: 10713  grad_norm: 319.3872  loss: 16.6895  decode.loss_cls: 0.0811  decode.loss_mask: 0.4676  decode.loss_dice: 1.1033  decode.d0.loss_cls: 0.0655  decode.d0.loss_mask: 0.4825  decode.d0.loss_dice: 1.2118  decode.d1.loss_cls: 0.0727  decode.d1.loss_mask: 0.4693  decode.d1.loss_dice: 1.1314  decode.d2.loss_cls: 0.0702  decode.d2.loss_mask: 0.4800  decode.d2.loss_dice: 1.1472  decode.d3.loss_cls: 0.0739  decode.d3.loss_mask: 0.4708  decode.d3.loss_dice: 1.0977  decode.d4.loss_cls: 0.0776  decode.d4.loss_mask: 0.4659  decode.d4.loss_dice: 1.1138  decode.d5.loss_cls: 0.0803  decode.d5.loss_mask: 0.4664  decode.d5.loss_dice: 1.0952  decode.d6.loss_cls: 0.0700  decode.d6.loss_mask: 0.4673  decode.d6.loss_dice: 1.1038  decode.d7.loss_cls: 0.0716  decode.d7.loss_mask: 0.4667  decode.d7.loss_dice: 1.1111  decode.d8.loss_cls: 0.0702  decode.d8.loss_mask: 0.4708  decode.d8.loss_dice: 1.1336
11/15 18:37:48 - mmengine - INFO - Iter(train) [67550/90000]  base_lr: 2.8660e-05 lr: 2.8660e-06  eta: 3:45:17  time: 0.5973  data_time: 0.0106  memory: 10675  grad_norm: 334.0490  loss: 17.4758  decode.loss_cls: 0.0575  decode.loss_mask: 0.5781  decode.loss_dice: 1.1018  decode.d0.loss_cls: 0.0986  decode.d0.loss_mask: 0.6048  decode.d0.loss_dice: 1.1452  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.5780  decode.d1.loss_dice: 1.1135  decode.d2.loss_cls: 0.0633  decode.d2.loss_mask: 0.5761  decode.d2.loss_dice: 1.0990  decode.d3.loss_cls: 0.0599  decode.d3.loss_mask: 0.5734  decode.d3.loss_dice: 1.0900  decode.d4.loss_cls: 0.0668  decode.d4.loss_mask: 0.5701  decode.d4.loss_dice: 1.1056  decode.d5.loss_cls: 0.0604  decode.d5.loss_mask: 0.5730  decode.d5.loss_dice: 1.0948  decode.d6.loss_cls: 0.0592  decode.d6.loss_mask: 0.5756  decode.d6.loss_dice: 1.0885  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 0.5766  decode.d7.loss_dice: 1.1149  decode.d8.loss_cls: 0.0601  decode.d8.loss_mask: 0.5669  decode.d8.loss_dice: 1.0948
11/15 18:38:18 - mmengine - INFO - Iter(train) [67600/90000]  base_lr: 2.8603e-05 lr: 2.8603e-06  eta: 3:44:47  time: 0.5978  data_time: 0.0106  memory: 10692  grad_norm: 275.3772  loss: 17.8933  decode.loss_cls: 0.0580  decode.loss_mask: 0.6019  decode.loss_dice: 1.1377  decode.d0.loss_cls: 0.0852  decode.d0.loss_mask: 0.6148  decode.d0.loss_dice: 1.1609  decode.d1.loss_cls: 0.0695  decode.d1.loss_mask: 0.6038  decode.d1.loss_dice: 1.1166  decode.d2.loss_cls: 0.0580  decode.d2.loss_mask: 0.6046  decode.d2.loss_dice: 1.1396  decode.d3.loss_cls: 0.0528  decode.d3.loss_mask: 0.6013  decode.d3.loss_dice: 1.1317  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.5963  decode.d4.loss_dice: 1.1166  decode.d5.loss_cls: 0.0639  decode.d5.loss_mask: 0.5997  decode.d5.loss_dice: 1.1204  decode.d6.loss_cls: 0.0681  decode.d6.loss_mask: 0.5994  decode.d6.loss_dice: 1.1098  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.6013  decode.d7.loss_dice: 1.1047  decode.d8.loss_cls: 0.0606  decode.d8.loss_mask: 0.5954  decode.d8.loss_dice: 1.1051
11/15 18:38:48 - mmengine - INFO - Iter(train) [67650/90000]  base_lr: 2.8545e-05 lr: 2.8545e-06  eta: 3:44:16  time: 0.5945  data_time: 0.0105  memory: 10675  grad_norm: 414.2542  loss: 15.0145  decode.loss_cls: 0.0576  decode.loss_mask: 0.5306  decode.loss_dice: 0.8779  decode.d0.loss_cls: 0.0934  decode.d0.loss_mask: 0.5591  decode.d0.loss_dice: 0.9783  decode.d1.loss_cls: 0.0763  decode.d1.loss_mask: 0.5400  decode.d1.loss_dice: 0.9028  decode.d2.loss_cls: 0.0670  decode.d2.loss_mask: 0.5461  decode.d2.loss_dice: 0.8991  decode.d3.loss_cls: 0.0635  decode.d3.loss_mask: 0.5398  decode.d3.loss_dice: 0.8929  decode.d4.loss_cls: 0.0554  decode.d4.loss_mask: 0.5320  decode.d4.loss_dice: 0.9024  decode.d5.loss_cls: 0.0492  decode.d5.loss_mask: 0.5423  decode.d5.loss_dice: 0.8808  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.5414  decode.d6.loss_dice: 0.9015  decode.d7.loss_cls: 0.0613  decode.d7.loss_mask: 0.5355  decode.d7.loss_dice: 0.8739  decode.d8.loss_cls: 0.0532  decode.d8.loss_mask: 0.5352  decode.d8.loss_dice: 0.8676
11/15 18:39:18 - mmengine - INFO - Iter(train) [67700/90000]  base_lr: 2.8488e-05 lr: 2.8488e-06  eta: 3:43:46  time: 0.5971  data_time: 0.0107  memory: 10692  grad_norm: 305.7216  loss: 16.1862  decode.loss_cls: 0.0690  decode.loss_mask: 0.5506  decode.loss_dice: 1.0065  decode.d0.loss_cls: 0.0744  decode.d0.loss_mask: 0.5659  decode.d0.loss_dice: 1.0709  decode.d1.loss_cls: 0.0707  decode.d1.loss_mask: 0.5411  decode.d1.loss_dice: 1.0165  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.5491  decode.d2.loss_dice: 0.9950  decode.d3.loss_cls: 0.0616  decode.d3.loss_mask: 0.5451  decode.d3.loss_dice: 0.9982  decode.d4.loss_cls: 0.0616  decode.d4.loss_mask: 0.5420  decode.d4.loss_dice: 1.0148  decode.d5.loss_cls: 0.0657  decode.d5.loss_mask: 0.5412  decode.d5.loss_dice: 1.0000  decode.d6.loss_cls: 0.0701  decode.d6.loss_mask: 0.5406  decode.d6.loss_dice: 0.9930  decode.d7.loss_cls: 0.0700  decode.d7.loss_mask: 0.5453  decode.d7.loss_dice: 0.9659  decode.d8.loss_cls: 0.0685  decode.d8.loss_mask: 0.5439  decode.d8.loss_dice: 0.9916
11/15 18:39:48 - mmengine - INFO - Iter(train) [67750/90000]  base_lr: 2.8430e-05 lr: 2.8430e-06  eta: 3:43:16  time: 0.5974  data_time: 0.0106  memory: 10656  grad_norm: 256.9631  loss: 14.3296  decode.loss_cls: 0.0531  decode.loss_mask: 0.4143  decode.loss_dice: 0.9421  decode.d0.loss_cls: 0.0737  decode.d0.loss_mask: 0.4217  decode.d0.loss_dice: 1.0029  decode.d1.loss_cls: 0.0697  decode.d1.loss_mask: 0.4168  decode.d1.loss_dice: 0.9860  decode.d2.loss_cls: 0.0642  decode.d2.loss_mask: 0.4175  decode.d2.loss_dice: 0.9568  decode.d3.loss_cls: 0.0685  decode.d3.loss_mask: 0.4117  decode.d3.loss_dice: 0.9557  decode.d4.loss_cls: 0.0659  decode.d4.loss_mask: 0.4146  decode.d4.loss_dice: 0.9303  decode.d5.loss_cls: 0.0634  decode.d5.loss_mask: 0.4103  decode.d5.loss_dice: 0.9531  decode.d6.loss_cls: 0.0649  decode.d6.loss_mask: 0.4112  decode.d6.loss_dice: 0.9452  decode.d7.loss_cls: 0.0642  decode.d7.loss_mask: 0.4082  decode.d7.loss_dice: 0.9246  decode.d8.loss_cls: 0.0557  decode.d8.loss_mask: 0.4145  decode.d8.loss_dice: 0.9488
11/15 18:40:18 - mmengine - INFO - Iter(train) [67800/90000]  base_lr: 2.8373e-05 lr: 2.8373e-06  eta: 3:42:46  time: 0.5970  data_time: 0.0105  memory: 10675  grad_norm: 285.5541  loss: 15.7763  decode.loss_cls: 0.0744  decode.loss_mask: 0.4690  decode.loss_dice: 1.0345  decode.d0.loss_cls: 0.1063  decode.d0.loss_mask: 0.4689  decode.d0.loss_dice: 1.1046  decode.d1.loss_cls: 0.0658  decode.d1.loss_mask: 0.4625  decode.d1.loss_dice: 1.0758  decode.d2.loss_cls: 0.0610  decode.d2.loss_mask: 0.4610  decode.d2.loss_dice: 1.0290  decode.d3.loss_cls: 0.0583  decode.d3.loss_mask: 0.4628  decode.d3.loss_dice: 1.0135  decode.d4.loss_cls: 0.0669  decode.d4.loss_mask: 0.4621  decode.d4.loss_dice: 1.0154  decode.d5.loss_cls: 0.0689  decode.d5.loss_mask: 0.4658  decode.d5.loss_dice: 1.0453  decode.d6.loss_cls: 0.0708  decode.d6.loss_mask: 0.4660  decode.d6.loss_dice: 1.0385  decode.d7.loss_cls: 0.0729  decode.d7.loss_mask: 0.4616  decode.d7.loss_dice: 1.0309  decode.d8.loss_cls: 0.0716  decode.d8.loss_mask: 0.4653  decode.d8.loss_dice: 1.0269
11/15 18:40:48 - mmengine - INFO - Iter(train) [67850/90000]  base_lr: 2.8315e-05 lr: 2.8315e-06  eta: 3:42:16  time: 0.5976  data_time: 0.0106  memory: 10692  grad_norm: 339.9768  loss: 15.9938  decode.loss_cls: 0.0607  decode.loss_mask: 0.5062  decode.loss_dice: 0.9897  decode.d0.loss_cls: 0.0946  decode.d0.loss_mask: 0.5324  decode.d0.loss_dice: 1.0639  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.5202  decode.d1.loss_dice: 1.0504  decode.d2.loss_cls: 0.0703  decode.d2.loss_mask: 0.5389  decode.d2.loss_dice: 1.0145  decode.d3.loss_cls: 0.0587  decode.d3.loss_mask: 0.5217  decode.d3.loss_dice: 1.0058  decode.d4.loss_cls: 0.0555  decode.d4.loss_mask: 0.5170  decode.d4.loss_dice: 1.0299  decode.d5.loss_cls: 0.0572  decode.d5.loss_mask: 0.5151  decode.d5.loss_dice: 1.0121  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.5068  decode.d6.loss_dice: 0.9837  decode.d7.loss_cls: 0.0584  decode.d7.loss_mask: 0.5159  decode.d7.loss_dice: 1.0069  decode.d8.loss_cls: 0.0551  decode.d8.loss_mask: 0.5058  decode.d8.loss_dice: 1.0163
11/15 18:41:18 - mmengine - INFO - Iter(train) [67900/90000]  base_lr: 2.8258e-05 lr: 2.8258e-06  eta: 3:41:46  time: 0.5965  data_time: 0.0105  memory: 10675  grad_norm: 268.2078  loss: 14.7946  decode.loss_cls: 0.0376  decode.loss_mask: 0.4733  decode.loss_dice: 0.9376  decode.d0.loss_cls: 0.0784  decode.d0.loss_mask: 0.5077  decode.d0.loss_dice: 1.0051  decode.d1.loss_cls: 0.0358  decode.d1.loss_mask: 0.4818  decode.d1.loss_dice: 0.9957  decode.d2.loss_cls: 0.0383  decode.d2.loss_mask: 0.4753  decode.d2.loss_dice: 0.9697  decode.d3.loss_cls: 0.0349  decode.d3.loss_mask: 0.4720  decode.d3.loss_dice: 0.9527  decode.d4.loss_cls: 0.0341  decode.d4.loss_mask: 0.4720  decode.d4.loss_dice: 0.9386  decode.d5.loss_cls: 0.0374  decode.d5.loss_mask: 0.4695  decode.d5.loss_dice: 0.9390  decode.d6.loss_cls: 0.0341  decode.d6.loss_mask: 0.4740  decode.d6.loss_dice: 0.9726  decode.d7.loss_cls: 0.0363  decode.d7.loss_mask: 0.4727  decode.d7.loss_dice: 0.9560  decode.d8.loss_cls: 0.0364  decode.d8.loss_mask: 0.4743  decode.d8.loss_dice: 0.9517
11/15 18:41:48 - mmengine - INFO - Iter(train) [67950/90000]  base_lr: 2.8200e-05 lr: 2.8200e-06  eta: 3:41:15  time: 0.5963  data_time: 0.0106  memory: 10713  grad_norm: 245.7980  loss: 15.4433  decode.loss_cls: 0.0469  decode.loss_mask: 0.4218  decode.loss_dice: 1.0372  decode.d0.loss_cls: 0.0638  decode.d0.loss_mask: 0.4332  decode.d0.loss_dice: 1.1342  decode.d1.loss_cls: 0.0653  decode.d1.loss_mask: 0.4162  decode.d1.loss_dice: 1.0858  decode.d2.loss_cls: 0.0588  decode.d2.loss_mask: 0.4212  decode.d2.loss_dice: 1.0755  decode.d3.loss_cls: 0.0498  decode.d3.loss_mask: 0.4202  decode.d3.loss_dice: 1.0437  decode.d4.loss_cls: 0.0555  decode.d4.loss_mask: 0.4184  decode.d4.loss_dice: 1.0894  decode.d5.loss_cls: 0.0481  decode.d5.loss_mask: 0.4175  decode.d5.loss_dice: 1.0689  decode.d6.loss_cls: 0.0461  decode.d6.loss_mask: 0.4179  decode.d6.loss_dice: 1.0655  decode.d7.loss_cls: 0.0592  decode.d7.loss_mask: 0.4166  decode.d7.loss_dice: 1.0482  decode.d8.loss_cls: 0.0476  decode.d8.loss_mask: 0.4162  decode.d8.loss_dice: 1.0544
11/15 18:42:18 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 18:42:18 - mmengine - INFO - Iter(train) [68000/90000]  base_lr: 2.8143e-05 lr: 2.8143e-06  eta: 3:40:45  time: 0.5982  data_time: 0.0107  memory: 10758  grad_norm: 406.7416  loss: 14.1646  decode.loss_cls: 0.0760  decode.loss_mask: 0.4212  decode.loss_dice: 0.8916  decode.d0.loss_cls: 0.0943  decode.d0.loss_mask: 0.4589  decode.d0.loss_dice: 1.0001  decode.d1.loss_cls: 0.0734  decode.d1.loss_mask: 0.4355  decode.d1.loss_dice: 0.9337  decode.d2.loss_cls: 0.0687  decode.d2.loss_mask: 0.4290  decode.d2.loss_dice: 0.9168  decode.d3.loss_cls: 0.0716  decode.d3.loss_mask: 0.4231  decode.d3.loss_dice: 0.8966  decode.d4.loss_cls: 0.0669  decode.d4.loss_mask: 0.4181  decode.d4.loss_dice: 0.9188  decode.d5.loss_cls: 0.0733  decode.d5.loss_mask: 0.4223  decode.d5.loss_dice: 0.9343  decode.d6.loss_cls: 0.0777  decode.d6.loss_mask: 0.4177  decode.d6.loss_dice: 0.8669  decode.d7.loss_cls: 0.0781  decode.d7.loss_mask: 0.4191  decode.d7.loss_dice: 0.8831  decode.d8.loss_cls: 0.0760  decode.d8.loss_mask: 0.4217  decode.d8.loss_dice: 0.8999
11/15 18:42:48 - mmengine - INFO - Iter(train) [68050/90000]  base_lr: 2.8085e-05 lr: 2.8085e-06  eta: 3:40:15  time: 0.5968  data_time: 0.0104  memory: 10728  grad_norm: 589.4130  loss: 14.7319  decode.loss_cls: 0.0418  decode.loss_mask: 0.4480  decode.loss_dice: 0.9714  decode.d0.loss_cls: 0.0648  decode.d0.loss_mask: 0.4636  decode.d0.loss_dice: 0.9961  decode.d1.loss_cls: 0.0516  decode.d1.loss_mask: 0.4500  decode.d1.loss_dice: 0.9781  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 0.4507  decode.d2.loss_dice: 0.9718  decode.d3.loss_cls: 0.0400  decode.d3.loss_mask: 0.4574  decode.d3.loss_dice: 0.9926  decode.d4.loss_cls: 0.0414  decode.d4.loss_mask: 0.4470  decode.d4.loss_dice: 0.9709  decode.d5.loss_cls: 0.0323  decode.d5.loss_mask: 0.4532  decode.d5.loss_dice: 0.9987  decode.d6.loss_cls: 0.0432  decode.d6.loss_mask: 0.4511  decode.d6.loss_dice: 0.9554  decode.d7.loss_cls: 0.0440  decode.d7.loss_mask: 0.4518  decode.d7.loss_dice: 0.9617  decode.d8.loss_cls: 0.0473  decode.d8.loss_mask: 0.4488  decode.d8.loss_dice: 0.9586
11/15 18:43:17 - mmengine - INFO - Iter(train) [68100/90000]  base_lr: 2.8028e-05 lr: 2.8028e-06  eta: 3:39:45  time: 0.5956  data_time: 0.0104  memory: 10692  grad_norm: 355.6650  loss: 15.8504  decode.loss_cls: 0.0708  decode.loss_mask: 0.4833  decode.loss_dice: 1.0083  decode.d0.loss_cls: 0.0900  decode.d0.loss_mask: 0.5265  decode.d0.loss_dice: 1.0684  decode.d1.loss_cls: 0.0756  decode.d1.loss_mask: 0.4880  decode.d1.loss_dice: 1.0170  decode.d2.loss_cls: 0.0710  decode.d2.loss_mask: 0.4828  decode.d2.loss_dice: 1.0123  decode.d3.loss_cls: 0.0646  decode.d3.loss_mask: 0.5043  decode.d3.loss_dice: 1.0079  decode.d4.loss_cls: 0.0642  decode.d4.loss_mask: 0.4969  decode.d4.loss_dice: 1.0034  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.4987  decode.d5.loss_dice: 1.0316  decode.d6.loss_cls: 0.0676  decode.d6.loss_mask: 0.5099  decode.d6.loss_dice: 1.0323  decode.d7.loss_cls: 0.0679  decode.d7.loss_mask: 0.4994  decode.d7.loss_dice: 0.9914  decode.d8.loss_cls: 0.0622  decode.d8.loss_mask: 0.4991  decode.d8.loss_dice: 0.9922
11/15 18:43:47 - mmengine - INFO - Iter(train) [68150/90000]  base_lr: 2.7970e-05 lr: 2.7970e-06  eta: 3:39:15  time: 0.5964  data_time: 0.0104  memory: 10713  grad_norm: 301.7400  loss: 13.9047  decode.loss_cls: 0.0615  decode.loss_mask: 0.4417  decode.loss_dice: 0.8712  decode.d0.loss_cls: 0.0808  decode.d0.loss_mask: 0.4716  decode.d0.loss_dice: 0.9426  decode.d1.loss_cls: 0.0678  decode.d1.loss_mask: 0.4454  decode.d1.loss_dice: 0.8955  decode.d2.loss_cls: 0.0583  decode.d2.loss_mask: 0.4450  decode.d2.loss_dice: 0.8894  decode.d3.loss_cls: 0.0636  decode.d3.loss_mask: 0.4394  decode.d3.loss_dice: 0.8443  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 0.4362  decode.d4.loss_dice: 0.8798  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 0.4501  decode.d5.loss_dice: 0.8864  decode.d6.loss_cls: 0.0521  decode.d6.loss_mask: 0.4510  decode.d6.loss_dice: 0.8730  decode.d7.loss_cls: 0.0617  decode.d7.loss_mask: 0.4394  decode.d7.loss_dice: 0.8699  decode.d8.loss_cls: 0.0531  decode.d8.loss_mask: 0.4476  decode.d8.loss_dice: 0.8745
11/15 18:44:17 - mmengine - INFO - Iter(train) [68200/90000]  base_lr: 2.7912e-05 lr: 2.7912e-06  eta: 3:38:44  time: 0.5958  data_time: 0.0105  memory: 10656  grad_norm: 365.6787  loss: 14.6718  decode.loss_cls: 0.0489  decode.loss_mask: 0.4390  decode.loss_dice: 0.9503  decode.d0.loss_cls: 0.0937  decode.d0.loss_mask: 0.4502  decode.d0.loss_dice: 0.9961  decode.d1.loss_cls: 0.0622  decode.d1.loss_mask: 0.4751  decode.d1.loss_dice: 0.9597  decode.d2.loss_cls: 0.0528  decode.d2.loss_mask: 0.4536  decode.d2.loss_dice: 0.9398  decode.d3.loss_cls: 0.0454  decode.d3.loss_mask: 0.4537  decode.d3.loss_dice: 0.9624  decode.d4.loss_cls: 0.0453  decode.d4.loss_mask: 0.4458  decode.d4.loss_dice: 0.9637  decode.d5.loss_cls: 0.0538  decode.d5.loss_mask: 0.4488  decode.d5.loss_dice: 0.9664  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.4515  decode.d6.loss_dice: 0.9625  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.4459  decode.d7.loss_dice: 0.9603  decode.d8.loss_cls: 0.0629  decode.d8.loss_mask: 0.4446  decode.d8.loss_dice: 0.9314
11/15 18:44:47 - mmengine - INFO - Iter(train) [68250/90000]  base_lr: 2.7855e-05 lr: 2.7855e-06  eta: 3:38:14  time: 0.5955  data_time: 0.0105  memory: 10692  grad_norm: 579.7714  loss: 15.9210  decode.loss_cls: 0.0494  decode.loss_mask: 0.5463  decode.loss_dice: 0.9938  decode.d0.loss_cls: 0.1062  decode.d0.loss_mask: 0.5807  decode.d0.loss_dice: 1.0537  decode.d1.loss_cls: 0.0700  decode.d1.loss_mask: 0.5515  decode.d1.loss_dice: 1.0154  decode.d2.loss_cls: 0.0612  decode.d2.loss_mask: 0.5312  decode.d2.loss_dice: 1.0012  decode.d3.loss_cls: 0.0499  decode.d3.loss_mask: 0.5321  decode.d3.loss_dice: 0.9790  decode.d4.loss_cls: 0.0486  decode.d4.loss_mask: 0.5298  decode.d4.loss_dice: 0.9859  decode.d5.loss_cls: 0.0443  decode.d5.loss_mask: 0.5274  decode.d5.loss_dice: 0.9576  decode.d6.loss_cls: 0.0497  decode.d6.loss_mask: 0.5334  decode.d6.loss_dice: 0.9918  decode.d7.loss_cls: 0.0423  decode.d7.loss_mask: 0.5383  decode.d7.loss_dice: 0.9945  decode.d8.loss_cls: 0.0549  decode.d8.loss_mask: 0.5329  decode.d8.loss_dice: 0.9680
11/15 18:45:17 - mmengine - INFO - Iter(train) [68300/90000]  base_lr: 2.7797e-05 lr: 2.7797e-06  eta: 3:37:44  time: 0.5969  data_time: 0.0105  memory: 10656  grad_norm: 238.3651  loss: 14.6866  decode.loss_cls: 0.0602  decode.loss_mask: 0.4183  decode.loss_dice: 0.9641  decode.d0.loss_cls: 0.0808  decode.d0.loss_mask: 0.4265  decode.d0.loss_dice: 1.0598  decode.d1.loss_cls: 0.0537  decode.d1.loss_mask: 0.4246  decode.d1.loss_dice: 0.9877  decode.d2.loss_cls: 0.0606  decode.d2.loss_mask: 0.4281  decode.d2.loss_dice: 0.9778  decode.d3.loss_cls: 0.0526  decode.d3.loss_mask: 0.4215  decode.d3.loss_dice: 0.9792  decode.d4.loss_cls: 0.0442  decode.d4.loss_mask: 0.4273  decode.d4.loss_dice: 1.0014  decode.d5.loss_cls: 0.0620  decode.d5.loss_mask: 0.4168  decode.d5.loss_dice: 0.9714  decode.d6.loss_cls: 0.0580  decode.d6.loss_mask: 0.4235  decode.d6.loss_dice: 0.9898  decode.d7.loss_cls: 0.0674  decode.d7.loss_mask: 0.4134  decode.d7.loss_dice: 0.9580  decode.d8.loss_cls: 0.0698  decode.d8.loss_mask: 0.4148  decode.d8.loss_dice: 0.9735
11/15 18:45:47 - mmengine - INFO - Iter(train) [68350/90000]  base_lr: 2.7739e-05 lr: 2.7739e-06  eta: 3:37:14  time: 0.5972  data_time: 0.0104  memory: 10713  grad_norm: 478.8305  loss: 16.1006  decode.loss_cls: 0.0656  decode.loss_mask: 0.4585  decode.loss_dice: 1.0901  decode.d0.loss_cls: 0.0819  decode.d0.loss_mask: 0.4551  decode.d0.loss_dice: 1.1428  decode.d1.loss_cls: 0.0772  decode.d1.loss_mask: 0.4739  decode.d1.loss_dice: 1.0983  decode.d2.loss_cls: 0.0689  decode.d2.loss_mask: 0.4663  decode.d2.loss_dice: 1.0639  decode.d3.loss_cls: 0.0666  decode.d3.loss_mask: 0.4542  decode.d3.loss_dice: 1.0530  decode.d4.loss_cls: 0.0631  decode.d4.loss_mask: 0.4583  decode.d4.loss_dice: 1.0665  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.4593  decode.d5.loss_dice: 1.0844  decode.d6.loss_cls: 0.0641  decode.d6.loss_mask: 0.5000  decode.d6.loss_dice: 1.0618  decode.d7.loss_cls: 0.0630  decode.d7.loss_mask: 0.4570  decode.d7.loss_dice: 1.0612  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 0.4620  decode.d8.loss_dice: 1.0540
11/15 18:46:17 - mmengine - INFO - Iter(train) [68400/90000]  base_lr: 2.7682e-05 lr: 2.7682e-06  eta: 3:36:44  time: 0.5955  data_time: 0.0103  memory: 10656  grad_norm: 278.7456  loss: 14.1183  decode.loss_cls: 0.0563  decode.loss_mask: 0.4241  decode.loss_dice: 0.9171  decode.d0.loss_cls: 0.0764  decode.d0.loss_mask: 0.4672  decode.d0.loss_dice: 1.0122  decode.d1.loss_cls: 0.0582  decode.d1.loss_mask: 0.4310  decode.d1.loss_dice: 0.9174  decode.d2.loss_cls: 0.0554  decode.d2.loss_mask: 0.4279  decode.d2.loss_dice: 0.9118  decode.d3.loss_cls: 0.0569  decode.d3.loss_mask: 0.4241  decode.d3.loss_dice: 0.8826  decode.d4.loss_cls: 0.0586  decode.d4.loss_mask: 0.4252  decode.d4.loss_dice: 0.9131  decode.d5.loss_cls: 0.0581  decode.d5.loss_mask: 0.4257  decode.d5.loss_dice: 0.9301  decode.d6.loss_cls: 0.0593  decode.d6.loss_mask: 0.4251  decode.d6.loss_dice: 0.9197  decode.d7.loss_cls: 0.0583  decode.d7.loss_mask: 0.4299  decode.d7.loss_dice: 0.9059  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.4269  decode.d8.loss_dice: 0.9065
11/15 18:46:46 - mmengine - INFO - Iter(train) [68450/90000]  base_lr: 2.7624e-05 lr: 2.7624e-06  eta: 3:36:14  time: 0.5964  data_time: 0.0103  memory: 10713  grad_norm: 307.2994  loss: 17.7968  decode.loss_cls: 0.0546  decode.loss_mask: 0.4820  decode.loss_dice: 1.2141  decode.d0.loss_cls: 0.0761  decode.d0.loss_mask: 0.5324  decode.d0.loss_dice: 1.2947  decode.d1.loss_cls: 0.0759  decode.d1.loss_mask: 0.5133  decode.d1.loss_dice: 1.2409  decode.d2.loss_cls: 0.0775  decode.d2.loss_mask: 0.4845  decode.d2.loss_dice: 1.2173  decode.d3.loss_cls: 0.0600  decode.d3.loss_mask: 0.4837  decode.d3.loss_dice: 1.1991  decode.d4.loss_cls: 0.0638  decode.d4.loss_mask: 0.4830  decode.d4.loss_dice: 1.2055  decode.d5.loss_cls: 0.0600  decode.d5.loss_mask: 0.4846  decode.d5.loss_dice: 1.2335  decode.d6.loss_cls: 0.0515  decode.d6.loss_mask: 0.4879  decode.d6.loss_dice: 1.2049  decode.d7.loss_cls: 0.0779  decode.d7.loss_mask: 0.4834  decode.d7.loss_dice: 1.2095  decode.d8.loss_cls: 0.0673  decode.d8.loss_mask: 0.4852  decode.d8.loss_dice: 1.1927
11/15 18:47:16 - mmengine - INFO - Iter(train) [68500/90000]  base_lr: 2.7566e-05 lr: 2.7566e-06  eta: 3:35:43  time: 0.5959  data_time: 0.0103  memory: 10692  grad_norm: 321.1538  loss: 13.9603  decode.loss_cls: 0.0395  decode.loss_mask: 0.4461  decode.loss_dice: 0.8661  decode.d0.loss_cls: 0.0707  decode.d0.loss_mask: 0.4825  decode.d0.loss_dice: 0.9707  decode.d1.loss_cls: 0.0537  decode.d1.loss_mask: 0.4568  decode.d1.loss_dice: 0.9039  decode.d2.loss_cls: 0.0369  decode.d2.loss_mask: 0.4579  decode.d2.loss_dice: 0.9020  decode.d3.loss_cls: 0.0360  decode.d3.loss_mask: 0.4470  decode.d3.loss_dice: 0.8881  decode.d4.loss_cls: 0.0391  decode.d4.loss_mask: 0.4531  decode.d4.loss_dice: 0.9158  decode.d5.loss_cls: 0.0438  decode.d5.loss_mask: 0.4444  decode.d5.loss_dice: 0.8950  decode.d6.loss_cls: 0.0468  decode.d6.loss_mask: 0.4495  decode.d6.loss_dice: 0.8655  decode.d7.loss_cls: 0.0376  decode.d7.loss_mask: 0.4477  decode.d7.loss_dice: 0.8961  decode.d8.loss_cls: 0.0419  decode.d8.loss_mask: 0.4556  decode.d8.loss_dice: 0.8703
11/15 18:47:46 - mmengine - INFO - Iter(train) [68550/90000]  base_lr: 2.7509e-05 lr: 2.7509e-06  eta: 3:35:13  time: 0.5963  data_time: 0.0106  memory: 10675  grad_norm: 267.3833  loss: 15.9719  decode.loss_cls: 0.0500  decode.loss_mask: 0.5118  decode.loss_dice: 1.0280  decode.d0.loss_cls: 0.0965  decode.d0.loss_mask: 0.5257  decode.d0.loss_dice: 1.0641  decode.d1.loss_cls: 0.0648  decode.d1.loss_mask: 0.5302  decode.d1.loss_dice: 1.0243  decode.d2.loss_cls: 0.0564  decode.d2.loss_mask: 0.5270  decode.d2.loss_dice: 1.0000  decode.d3.loss_cls: 0.0569  decode.d3.loss_mask: 0.5145  decode.d3.loss_dice: 1.0233  decode.d4.loss_cls: 0.0587  decode.d4.loss_mask: 0.5230  decode.d4.loss_dice: 1.0014  decode.d5.loss_cls: 0.0590  decode.d5.loss_mask: 0.5183  decode.d5.loss_dice: 1.0159  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.5100  decode.d6.loss_dice: 1.0023  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.5064  decode.d7.loss_dice: 1.0174  decode.d8.loss_cls: 0.0538  decode.d8.loss_mask: 0.5132  decode.d8.loss_dice: 0.9994
11/15 18:48:16 - mmengine - INFO - Iter(train) [68600/90000]  base_lr: 2.7451e-05 lr: 2.7451e-06  eta: 3:34:43  time: 0.5969  data_time: 0.0106  memory: 10675  grad_norm: 282.1563  loss: 14.2198  decode.loss_cls: 0.0654  decode.loss_mask: 0.3624  decode.loss_dice: 0.9738  decode.d0.loss_cls: 0.0775  decode.d0.loss_mask: 0.3718  decode.d0.loss_dice: 1.0741  decode.d1.loss_cls: 0.0635  decode.d1.loss_mask: 0.3717  decode.d1.loss_dice: 1.0141  decode.d2.loss_cls: 0.0703  decode.d2.loss_mask: 0.3667  decode.d2.loss_dice: 0.9895  decode.d3.loss_cls: 0.0549  decode.d3.loss_mask: 0.3609  decode.d3.loss_dice: 0.9891  decode.d4.loss_cls: 0.0518  decode.d4.loss_mask: 0.3599  decode.d4.loss_dice: 0.9959  decode.d5.loss_cls: 0.0551  decode.d5.loss_mask: 0.3601  decode.d5.loss_dice: 0.9901  decode.d6.loss_cls: 0.0572  decode.d6.loss_mask: 0.3627  decode.d6.loss_dice: 0.9806  decode.d7.loss_cls: 0.0597  decode.d7.loss_mask: 0.3582  decode.d7.loss_dice: 0.9795  decode.d8.loss_cls: 0.0540  decode.d8.loss_mask: 0.3610  decode.d8.loss_dice: 0.9883
11/15 18:48:46 - mmengine - INFO - Iter(train) [68650/90000]  base_lr: 2.7393e-05 lr: 2.7393e-06  eta: 3:34:13  time: 0.5961  data_time: 0.0106  memory: 10713  grad_norm: 236.7581  loss: 15.0926  decode.loss_cls: 0.0497  decode.loss_mask: 0.4425  decode.loss_dice: 1.0310  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.4589  decode.d0.loss_dice: 1.0632  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.4368  decode.d1.loss_dice: 1.0165  decode.d2.loss_cls: 0.0614  decode.d2.loss_mask: 0.4338  decode.d2.loss_dice: 0.9889  decode.d3.loss_cls: 0.0547  decode.d3.loss_mask: 0.4402  decode.d3.loss_dice: 0.9991  decode.d4.loss_cls: 0.0594  decode.d4.loss_mask: 0.4398  decode.d4.loss_dice: 1.0166  decode.d5.loss_cls: 0.0523  decode.d5.loss_mask: 0.4350  decode.d5.loss_dice: 0.9977  decode.d6.loss_cls: 0.0396  decode.d6.loss_mask: 0.4410  decode.d6.loss_dice: 1.0248  decode.d7.loss_cls: 0.0442  decode.d7.loss_mask: 0.4359  decode.d7.loss_dice: 0.9981  decode.d8.loss_cls: 0.0430  decode.d8.loss_mask: 0.4347  decode.d8.loss_dice: 1.0226
11/15 18:49:16 - mmengine - INFO - Iter(train) [68700/90000]  base_lr: 2.7336e-05 lr: 2.7336e-06  eta: 3:33:43  time: 0.5975  data_time: 0.0107  memory: 10656  grad_norm: 271.9600  loss: 15.0757  decode.loss_cls: 0.0577  decode.loss_mask: 0.4165  decode.loss_dice: 1.0147  decode.d0.loss_cls: 0.0889  decode.d0.loss_mask: 0.4195  decode.d0.loss_dice: 1.0758  decode.d1.loss_cls: 0.0505  decode.d1.loss_mask: 0.4173  decode.d1.loss_dice: 1.0730  decode.d2.loss_cls: 0.0661  decode.d2.loss_mask: 0.4099  decode.d2.loss_dice: 1.0215  decode.d3.loss_cls: 0.0641  decode.d3.loss_mask: 0.4159  decode.d3.loss_dice: 1.0149  decode.d4.loss_cls: 0.0645  decode.d4.loss_mask: 0.4098  decode.d4.loss_dice: 0.9975  decode.d5.loss_cls: 0.0593  decode.d5.loss_mask: 0.4140  decode.d5.loss_dice: 1.0003  decode.d6.loss_cls: 0.0484  decode.d6.loss_mask: 0.4123  decode.d6.loss_dice: 1.0445  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.4167  decode.d7.loss_dice: 1.0526  decode.d8.loss_cls: 0.0587  decode.d8.loss_mask: 0.4087  decode.d8.loss_dice: 1.0139
11/15 18:49:46 - mmengine - INFO - Iter(train) [68750/90000]  base_lr: 2.7278e-05 lr: 2.7278e-06  eta: 3:33:13  time: 0.5963  data_time: 0.0105  memory: 10742  grad_norm: 282.3947  loss: 17.0810  decode.loss_cls: 0.0517  decode.loss_mask: 0.5973  decode.loss_dice: 1.0422  decode.d0.loss_cls: 0.1008  decode.d0.loss_mask: 0.6048  decode.d0.loss_dice: 1.1168  decode.d1.loss_cls: 0.0709  decode.d1.loss_mask: 0.5934  decode.d1.loss_dice: 1.0812  decode.d2.loss_cls: 0.0779  decode.d2.loss_mask: 0.5807  decode.d2.loss_dice: 1.0243  decode.d3.loss_cls: 0.0535  decode.d3.loss_mask: 0.6037  decode.d3.loss_dice: 1.0422  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 0.5969  decode.d4.loss_dice: 1.0629  decode.d5.loss_cls: 0.0501  decode.d5.loss_mask: 0.5960  decode.d5.loss_dice: 1.0587  decode.d6.loss_cls: 0.0494  decode.d6.loss_mask: 0.5934  decode.d6.loss_dice: 1.0395  decode.d7.loss_cls: 0.0530  decode.d7.loss_mask: 0.5881  decode.d7.loss_dice: 1.0284  decode.d8.loss_cls: 0.0512  decode.d8.loss_mask: 0.5891  decode.d8.loss_dice: 1.0365
11/15 18:50:16 - mmengine - INFO - Iter(train) [68800/90000]  base_lr: 2.7220e-05 lr: 2.7220e-06  eta: 3:32:42  time: 0.5977  data_time: 0.0107  memory: 10675  grad_norm: 264.4245  loss: 15.5713  decode.loss_cls: 0.0418  decode.loss_mask: 0.3909  decode.loss_dice: 1.1014  decode.d0.loss_cls: 0.0584  decode.d0.loss_mask: 0.3828  decode.d0.loss_dice: 1.1951  decode.d1.loss_cls: 0.0549  decode.d1.loss_mask: 0.3868  decode.d1.loss_dice: 1.1306  decode.d2.loss_cls: 0.0484  decode.d2.loss_mask: 0.3881  decode.d2.loss_dice: 1.1097  decode.d3.loss_cls: 0.0448  decode.d3.loss_mask: 0.3930  decode.d3.loss_dice: 1.1167  decode.d4.loss_cls: 0.0551  decode.d4.loss_mask: 0.3860  decode.d4.loss_dice: 1.1205  decode.d5.loss_cls: 0.0427  decode.d5.loss_mask: 0.3917  decode.d5.loss_dice: 1.1261  decode.d6.loss_cls: 0.0459  decode.d6.loss_mask: 0.3829  decode.d6.loss_dice: 1.1049  decode.d7.loss_cls: 0.0477  decode.d7.loss_mask: 0.3827  decode.d7.loss_dice: 1.1027  decode.d8.loss_cls: 0.0423  decode.d8.loss_mask: 0.3846  decode.d8.loss_dice: 1.1122
11/15 18:50:45 - mmengine - INFO - Iter(train) [68850/90000]  base_lr: 2.7162e-05 lr: 2.7162e-06  eta: 3:32:12  time: 0.5969  data_time: 0.0104  memory: 10656  grad_norm: 377.2157  loss: 15.6772  decode.loss_cls: 0.0346  decode.loss_mask: 0.5121  decode.loss_dice: 1.0388  decode.d0.loss_cls: 0.0711  decode.d0.loss_mask: 0.5489  decode.d0.loss_dice: 1.0879  decode.d1.loss_cls: 0.0449  decode.d1.loss_mask: 0.5002  decode.d1.loss_dice: 1.0431  decode.d2.loss_cls: 0.0468  decode.d2.loss_mask: 0.4843  decode.d2.loss_dice: 0.9843  decode.d3.loss_cls: 0.0477  decode.d3.loss_mask: 0.4809  decode.d3.loss_dice: 0.9973  decode.d4.loss_cls: 0.0479  decode.d4.loss_mask: 0.4888  decode.d4.loss_dice: 1.0034  decode.d5.loss_cls: 0.0504  decode.d5.loss_mask: 0.4821  decode.d5.loss_dice: 1.0160  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.4962  decode.d6.loss_dice: 1.0094  decode.d7.loss_cls: 0.0418  decode.d7.loss_mask: 0.5054  decode.d7.loss_dice: 1.0031  decode.d8.loss_cls: 0.0409  decode.d8.loss_mask: 0.5030  decode.d8.loss_dice: 1.0232
11/15 18:51:15 - mmengine - INFO - Iter(train) [68900/90000]  base_lr: 2.7104e-05 lr: 2.7104e-06  eta: 3:31:42  time: 0.5985  data_time: 0.0108  memory: 10641  grad_norm: 304.1821  loss: 16.2683  decode.loss_cls: 0.0466  decode.loss_mask: 0.5311  decode.loss_dice: 1.0222  decode.d0.loss_cls: 0.0737  decode.d0.loss_mask: 0.5602  decode.d0.loss_dice: 1.0918  decode.d1.loss_cls: 0.0596  decode.d1.loss_mask: 0.5371  decode.d1.loss_dice: 1.0379  decode.d2.loss_cls: 0.0563  decode.d2.loss_mask: 0.5360  decode.d2.loss_dice: 1.0243  decode.d3.loss_cls: 0.0504  decode.d3.loss_mask: 0.5311  decode.d3.loss_dice: 1.0205  decode.d4.loss_cls: 0.0480  decode.d4.loss_mask: 0.5306  decode.d4.loss_dice: 1.0036  decode.d5.loss_cls: 0.0481  decode.d5.loss_mask: 0.5410  decode.d5.loss_dice: 1.0420  decode.d6.loss_cls: 0.0457  decode.d6.loss_mask: 0.5691  decode.d6.loss_dice: 1.0490  decode.d7.loss_cls: 0.0492  decode.d7.loss_mask: 0.5605  decode.d7.loss_dice: 1.0086  decode.d8.loss_cls: 0.0485  decode.d8.loss_mask: 0.5313  decode.d8.loss_dice: 1.0143
11/15 18:51:45 - mmengine - INFO - Iter(train) [68950/90000]  base_lr: 2.7047e-05 lr: 2.7047e-06  eta: 3:31:12  time: 0.5956  data_time: 0.0106  memory: 10692  grad_norm: 260.8713  loss: 14.5678  decode.loss_cls: 0.0434  decode.loss_mask: 0.4925  decode.loss_dice: 0.9181  decode.d0.loss_cls: 0.0924  decode.d0.loss_mask: 0.4990  decode.d0.loss_dice: 0.9393  decode.d1.loss_cls: 0.0464  decode.d1.loss_mask: 0.4929  decode.d1.loss_dice: 0.9410  decode.d2.loss_cls: 0.0566  decode.d2.loss_mask: 0.4892  decode.d2.loss_dice: 0.8891  decode.d3.loss_cls: 0.0447  decode.d3.loss_mask: 0.4843  decode.d3.loss_dice: 0.8872  decode.d4.loss_cls: 0.0473  decode.d4.loss_mask: 0.4866  decode.d4.loss_dice: 0.9127  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.4832  decode.d5.loss_dice: 0.9128  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.4913  decode.d6.loss_dice: 0.9011  decode.d7.loss_cls: 0.0498  decode.d7.loss_mask: 0.4920  decode.d7.loss_dice: 0.9083  decode.d8.loss_cls: 0.0432  decode.d8.loss_mask: 0.4877  decode.d8.loss_dice: 0.9308
11/15 18:52:15 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 18:52:15 - mmengine - INFO - Iter(train) [69000/90000]  base_lr: 2.6989e-05 lr: 2.6989e-06  eta: 3:30:42  time: 0.5967  data_time: 0.0106  memory: 10692  grad_norm: 733.8677  loss: 16.6591  decode.loss_cls: 0.0694  decode.loss_mask: 0.5992  decode.loss_dice: 0.9602  decode.d0.loss_cls: 0.1030  decode.d0.loss_mask: 0.6532  decode.d0.loss_dice: 1.0516  decode.d1.loss_cls: 0.0642  decode.d1.loss_mask: 0.6163  decode.d1.loss_dice: 1.0551  decode.d2.loss_cls: 0.0748  decode.d2.loss_mask: 0.5937  decode.d2.loss_dice: 0.9620  decode.d3.loss_cls: 0.0694  decode.d3.loss_mask: 0.5997  decode.d3.loss_dice: 0.9751  decode.d4.loss_cls: 0.0774  decode.d4.loss_mask: 0.5912  decode.d4.loss_dice: 0.9732  decode.d5.loss_cls: 0.0688  decode.d5.loss_mask: 0.5963  decode.d5.loss_dice: 0.9794  decode.d6.loss_cls: 0.0663  decode.d6.loss_mask: 0.5980  decode.d6.loss_dice: 0.9841  decode.d7.loss_cls: 0.0656  decode.d7.loss_mask: 0.5959  decode.d7.loss_dice: 0.9681  decode.d8.loss_cls: 0.0755  decode.d8.loss_mask: 0.5964  decode.d8.loss_dice: 0.9760
11/15 18:52:45 - mmengine - INFO - Iter(train) [69050/90000]  base_lr: 2.6931e-05 lr: 2.6931e-06  eta: 3:30:11  time: 0.5965  data_time: 0.0106  memory: 10728  grad_norm: 381.0155  loss: 15.6018  decode.loss_cls: 0.0651  decode.loss_mask: 0.4899  decode.loss_dice: 0.9915  decode.d0.loss_cls: 0.0857  decode.d0.loss_mask: 0.5342  decode.d0.loss_dice: 1.0614  decode.d1.loss_cls: 0.0687  decode.d1.loss_mask: 0.5050  decode.d1.loss_dice: 1.0026  decode.d2.loss_cls: 0.0758  decode.d2.loss_mask: 0.5072  decode.d2.loss_dice: 0.9625  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.5153  decode.d3.loss_dice: 0.9686  decode.d4.loss_cls: 0.0702  decode.d4.loss_mask: 0.5032  decode.d4.loss_dice: 0.9732  decode.d5.loss_cls: 0.0740  decode.d5.loss_mask: 0.4932  decode.d5.loss_dice: 0.9777  decode.d6.loss_cls: 0.0664  decode.d6.loss_mask: 0.4955  decode.d6.loss_dice: 0.9640  decode.d7.loss_cls: 0.0656  decode.d7.loss_mask: 0.4893  decode.d7.loss_dice: 0.9819  decode.d8.loss_cls: 0.0669  decode.d8.loss_mask: 0.4901  decode.d8.loss_dice: 0.9979
11/15 18:53:15 - mmengine - INFO - Iter(train) [69100/90000]  base_lr: 2.6873e-05 lr: 2.6873e-06  eta: 3:29:41  time: 0.5963  data_time: 0.0106  memory: 10656  grad_norm: 539.5848  loss: 16.6404  decode.loss_cls: 0.0394  decode.loss_mask: 0.5546  decode.loss_dice: 1.0289  decode.d0.loss_cls: 0.0842  decode.d0.loss_mask: 0.6162  decode.d0.loss_dice: 1.1246  decode.d1.loss_cls: 0.0627  decode.d1.loss_mask: 0.5672  decode.d1.loss_dice: 1.0509  decode.d2.loss_cls: 0.0575  decode.d2.loss_mask: 0.5594  decode.d2.loss_dice: 1.0477  decode.d3.loss_cls: 0.0533  decode.d3.loss_mask: 0.5486  decode.d3.loss_dice: 1.0423  decode.d4.loss_cls: 0.0582  decode.d4.loss_mask: 0.5447  decode.d4.loss_dice: 1.0515  decode.d5.loss_cls: 0.0571  decode.d5.loss_mask: 0.5425  decode.d5.loss_dice: 1.0408  decode.d6.loss_cls: 0.0425  decode.d6.loss_mask: 0.5514  decode.d6.loss_dice: 1.0503  decode.d7.loss_cls: 0.0531  decode.d7.loss_mask: 0.5488  decode.d7.loss_dice: 1.0343  decode.d8.loss_cls: 0.0489  decode.d8.loss_mask: 0.5503  decode.d8.loss_dice: 1.0285
11/15 18:53:45 - mmengine - INFO - Iter(train) [69150/90000]  base_lr: 2.6815e-05 lr: 2.6815e-06  eta: 3:29:11  time: 0.5965  data_time: 0.0103  memory: 10692  grad_norm: 377.0026  loss: 14.8605  decode.loss_cls: 0.0788  decode.loss_mask: 0.4015  decode.loss_dice: 0.9956  decode.d0.loss_cls: 0.1031  decode.d0.loss_mask: 0.3988  decode.d0.loss_dice: 1.0676  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.3913  decode.d1.loss_dice: 1.0313  decode.d2.loss_cls: 0.0699  decode.d2.loss_mask: 0.3894  decode.d2.loss_dice: 1.0252  decode.d3.loss_cls: 0.0780  decode.d3.loss_mask: 0.3850  decode.d3.loss_dice: 0.9533  decode.d4.loss_cls: 0.0754  decode.d4.loss_mask: 0.3896  decode.d4.loss_dice: 1.0095  decode.d5.loss_cls: 0.0785  decode.d5.loss_mask: 0.3878  decode.d5.loss_dice: 0.9946  decode.d6.loss_cls: 0.0760  decode.d6.loss_mask: 0.3873  decode.d6.loss_dice: 1.0137  decode.d7.loss_cls: 0.0779  decode.d7.loss_mask: 0.4038  decode.d7.loss_dice: 1.0129  decode.d8.loss_cls: 0.0599  decode.d8.loss_mask: 0.3955  decode.d8.loss_dice: 1.0448
11/15 18:54:15 - mmengine - INFO - Iter(train) [69200/90000]  base_lr: 2.6757e-05 lr: 2.6757e-06  eta: 3:28:41  time: 0.5970  data_time: 0.0106  memory: 10713  grad_norm: 303.1237  loss: 13.1728  decode.loss_cls: 0.0583  decode.loss_mask: 0.3855  decode.loss_dice: 0.8470  decode.d0.loss_cls: 0.0894  decode.d0.loss_mask: 0.4141  decode.d0.loss_dice: 0.9354  decode.d1.loss_cls: 0.0561  decode.d1.loss_mask: 0.3773  decode.d1.loss_dice: 0.8878  decode.d2.loss_cls: 0.0554  decode.d2.loss_mask: 0.3835  decode.d2.loss_dice: 0.8741  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.3816  decode.d3.loss_dice: 0.8619  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 0.3875  decode.d4.loss_dice: 0.8550  decode.d5.loss_cls: 0.0580  decode.d5.loss_mask: 0.3833  decode.d5.loss_dice: 0.8653  decode.d6.loss_cls: 0.0572  decode.d6.loss_mask: 0.3890  decode.d6.loss_dice: 0.8645  decode.d7.loss_cls: 0.0643  decode.d7.loss_mask: 0.3866  decode.d7.loss_dice: 0.8349  decode.d8.loss_cls: 0.0575  decode.d8.loss_mask: 0.3887  decode.d8.loss_dice: 0.8645
11/15 18:54:44 - mmengine - INFO - Iter(train) [69250/90000]  base_lr: 2.6699e-05 lr: 2.6699e-06  eta: 3:28:11  time: 0.5971  data_time: 0.0105  memory: 10656  grad_norm: 366.3608  loss: 16.9783  decode.loss_cls: 0.0643  decode.loss_mask: 0.4720  decode.loss_dice: 1.1546  decode.d0.loss_cls: 0.0696  decode.d0.loss_mask: 0.4590  decode.d0.loss_dice: 1.2546  decode.d1.loss_cls: 0.0843  decode.d1.loss_mask: 0.4746  decode.d1.loss_dice: 1.1812  decode.d2.loss_cls: 0.0712  decode.d2.loss_mask: 0.4790  decode.d2.loss_dice: 1.1484  decode.d3.loss_cls: 0.0729  decode.d3.loss_mask: 0.4685  decode.d3.loss_dice: 1.1449  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.4730  decode.d4.loss_dice: 1.1357  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 0.4740  decode.d5.loss_dice: 1.1572  decode.d6.loss_cls: 0.0773  decode.d6.loss_mask: 0.4672  decode.d6.loss_dice: 1.1169  decode.d7.loss_cls: 0.0652  decode.d7.loss_mask: 0.4690  decode.d7.loss_dice: 1.1163  decode.d8.loss_cls: 0.0810  decode.d8.loss_mask: 0.4735  decode.d8.loss_dice: 1.1409
11/15 18:55:14 - mmengine - INFO - Iter(train) [69300/90000]  base_lr: 2.6642e-05 lr: 2.6642e-06  eta: 3:27:41  time: 0.5978  data_time: 0.0105  memory: 10675  grad_norm: 280.7905  loss: 16.9740  decode.loss_cls: 0.0555  decode.loss_mask: 0.4896  decode.loss_dice: 1.1474  decode.d0.loss_cls: 0.0693  decode.d0.loss_mask: 0.5186  decode.d0.loss_dice: 1.2453  decode.d1.loss_cls: 0.0513  decode.d1.loss_mask: 0.5048  decode.d1.loss_dice: 1.1867  decode.d2.loss_cls: 0.0673  decode.d2.loss_mask: 0.4857  decode.d2.loss_dice: 1.1299  decode.d3.loss_cls: 0.0448  decode.d3.loss_mask: 0.4796  decode.d3.loss_dice: 1.1362  decode.d4.loss_cls: 0.0582  decode.d4.loss_mask: 0.4821  decode.d4.loss_dice: 1.1431  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.4887  decode.d5.loss_dice: 1.1240  decode.d6.loss_cls: 0.0600  decode.d6.loss_mask: 0.4795  decode.d6.loss_dice: 1.1239  decode.d7.loss_cls: 0.0567  decode.d7.loss_mask: 0.4924  decode.d7.loss_dice: 1.1307  decode.d8.loss_cls: 0.0570  decode.d8.loss_mask: 0.4843  decode.d8.loss_dice: 1.1219
11/15 18:55:44 - mmengine - INFO - Iter(train) [69350/90000]  base_lr: 2.6584e-05 lr: 2.6584e-06  eta: 3:27:10  time: 0.5962  data_time: 0.0104  memory: 10692  grad_norm: 571.9805  loss: 15.3308  decode.loss_cls: 0.0421  decode.loss_mask: 0.5057  decode.loss_dice: 0.9779  decode.d0.loss_cls: 0.0889  decode.d0.loss_mask: 0.5534  decode.d0.loss_dice: 0.9887  decode.d1.loss_cls: 0.0492  decode.d1.loss_mask: 0.5142  decode.d1.loss_dice: 0.9829  decode.d2.loss_cls: 0.0478  decode.d2.loss_mask: 0.5129  decode.d2.loss_dice: 0.9774  decode.d3.loss_cls: 0.0431  decode.d3.loss_mask: 0.5199  decode.d3.loss_dice: 0.9582  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.5056  decode.d4.loss_dice: 0.9622  decode.d5.loss_cls: 0.0562  decode.d5.loss_mask: 0.4990  decode.d5.loss_dice: 0.9590  decode.d6.loss_cls: 0.0482  decode.d6.loss_mask: 0.5042  decode.d6.loss_dice: 0.9518  decode.d7.loss_cls: 0.0447  decode.d7.loss_mask: 0.5088  decode.d7.loss_dice: 0.9590  decode.d8.loss_cls: 0.0473  decode.d8.loss_mask: 0.5064  decode.d8.loss_dice: 0.9741
11/15 18:56:14 - mmengine - INFO - Iter(train) [69400/90000]  base_lr: 2.6526e-05 lr: 2.6526e-06  eta: 3:26:40  time: 0.5957  data_time: 0.0106  memory: 10728  grad_norm: 292.4135  loss: 14.1254  decode.loss_cls: 0.0455  decode.loss_mask: 0.4695  decode.loss_dice: 0.8880  decode.d0.loss_cls: 0.0796  decode.d0.loss_mask: 0.4953  decode.d0.loss_dice: 0.9212  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.4775  decode.d1.loss_dice: 0.8958  decode.d2.loss_cls: 0.0539  decode.d2.loss_mask: 0.4806  decode.d2.loss_dice: 0.8662  decode.d3.loss_cls: 0.0444  decode.d3.loss_mask: 0.4757  decode.d3.loss_dice: 0.8823  decode.d4.loss_cls: 0.0446  decode.d4.loss_mask: 0.4776  decode.d4.loss_dice: 0.8744  decode.d5.loss_cls: 0.0444  decode.d5.loss_mask: 0.4838  decode.d5.loss_dice: 0.8822  decode.d6.loss_cls: 0.0482  decode.d6.loss_mask: 0.4809  decode.d6.loss_dice: 0.8780  decode.d7.loss_cls: 0.0435  decode.d7.loss_mask: 0.4785  decode.d7.loss_dice: 0.8818  decode.d8.loss_cls: 0.0471  decode.d8.loss_mask: 0.4700  decode.d8.loss_dice: 0.8627
11/15 18:56:44 - mmengine - INFO - Iter(train) [69450/90000]  base_lr: 2.6468e-05 lr: 2.6468e-06  eta: 3:26:10  time: 0.5969  data_time: 0.0105  memory: 10675  grad_norm: 408.6610  loss: 14.3871  decode.loss_cls: 0.0622  decode.loss_mask: 0.4486  decode.loss_dice: 0.9076  decode.d0.loss_cls: 0.0912  decode.d0.loss_mask: 0.4897  decode.d0.loss_dice: 0.9757  decode.d1.loss_cls: 0.0600  decode.d1.loss_mask: 0.4625  decode.d1.loss_dice: 0.9309  decode.d2.loss_cls: 0.0641  decode.d2.loss_mask: 0.4482  decode.d2.loss_dice: 0.9147  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 0.4510  decode.d3.loss_dice: 0.8907  decode.d4.loss_cls: 0.0599  decode.d4.loss_mask: 0.4487  decode.d4.loss_dice: 0.9200  decode.d5.loss_cls: 0.0650  decode.d5.loss_mask: 0.4447  decode.d5.loss_dice: 0.8991  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.4527  decode.d6.loss_dice: 0.9094  decode.d7.loss_cls: 0.0480  decode.d7.loss_mask: 0.4610  decode.d7.loss_dice: 0.9293  decode.d8.loss_cls: 0.0599  decode.d8.loss_mask: 0.4541  decode.d8.loss_dice: 0.9187
11/15 18:57:14 - mmengine - INFO - Iter(train) [69500/90000]  base_lr: 2.6410e-05 lr: 2.6410e-06  eta: 3:25:40  time: 0.5960  data_time: 0.0106  memory: 10692  grad_norm: 850.0568  loss: 15.3828  decode.loss_cls: 0.0577  decode.loss_mask: 0.4632  decode.loss_dice: 1.0314  decode.d0.loss_cls: 0.0863  decode.d0.loss_mask: 0.4782  decode.d0.loss_dice: 1.0555  decode.d1.loss_cls: 0.0689  decode.d1.loss_mask: 0.4796  decode.d1.loss_dice: 1.0094  decode.d2.loss_cls: 0.0623  decode.d2.loss_mask: 0.4729  decode.d2.loss_dice: 0.9939  decode.d3.loss_cls: 0.0665  decode.d3.loss_mask: 0.4665  decode.d3.loss_dice: 1.0019  decode.d4.loss_cls: 0.0565  decode.d4.loss_mask: 0.4641  decode.d4.loss_dice: 1.0017  decode.d5.loss_cls: 0.0621  decode.d5.loss_mask: 0.4627  decode.d5.loss_dice: 0.9889  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.4612  decode.d6.loss_dice: 0.9997  decode.d7.loss_cls: 0.0703  decode.d7.loss_mask: 0.4662  decode.d7.loss_dice: 0.9762  decode.d8.loss_cls: 0.0623  decode.d8.loss_mask: 0.4617  decode.d8.loss_dice: 0.9845
11/15 18:57:44 - mmengine - INFO - Iter(train) [69550/90000]  base_lr: 2.6352e-05 lr: 2.6352e-06  eta: 3:25:10  time: 0.5963  data_time: 0.0106  memory: 10713  grad_norm: 458.1246  loss: 15.2110  decode.loss_cls: 0.0764  decode.loss_mask: 0.4659  decode.loss_dice: 0.9296  decode.d0.loss_cls: 0.0828  decode.d0.loss_mask: 0.5732  decode.d0.loss_dice: 1.0985  decode.d1.loss_cls: 0.0784  decode.d1.loss_mask: 0.5046  decode.d1.loss_dice: 1.0081  decode.d2.loss_cls: 0.0681  decode.d2.loss_mask: 0.4778  decode.d2.loss_dice: 0.9552  decode.d3.loss_cls: 0.0764  decode.d3.loss_mask: 0.4659  decode.d3.loss_dice: 0.9404  decode.d4.loss_cls: 0.0633  decode.d4.loss_mask: 0.4742  decode.d4.loss_dice: 0.9531  decode.d5.loss_cls: 0.0804  decode.d5.loss_mask: 0.4761  decode.d5.loss_dice: 0.9237  decode.d6.loss_cls: 0.0748  decode.d6.loss_mask: 0.4647  decode.d6.loss_dice: 0.9478  decode.d7.loss_cls: 0.0649  decode.d7.loss_mask: 0.4787  decode.d7.loss_dice: 0.9530  decode.d8.loss_cls: 0.0763  decode.d8.loss_mask: 0.4577  decode.d8.loss_dice: 0.9211
11/15 18:58:13 - mmengine - INFO - Iter(train) [69600/90000]  base_lr: 2.6294e-05 lr: 2.6294e-06  eta: 3:24:40  time: 0.5962  data_time: 0.0104  memory: 10641  grad_norm: 592.7735  loss: 14.9100  decode.loss_cls: 0.0314  decode.loss_mask: 0.5119  decode.loss_dice: 0.9095  decode.d0.loss_cls: 0.0871  decode.d0.loss_mask: 0.5190  decode.d0.loss_dice: 0.9868  decode.d1.loss_cls: 0.0397  decode.d1.loss_mask: 0.5541  decode.d1.loss_dice: 0.9331  decode.d2.loss_cls: 0.0412  decode.d2.loss_mask: 0.5232  decode.d2.loss_dice: 0.9156  decode.d3.loss_cls: 0.0385  decode.d3.loss_mask: 0.5059  decode.d3.loss_dice: 0.8914  decode.d4.loss_cls: 0.0421  decode.d4.loss_mask: 0.5105  decode.d4.loss_dice: 0.8932  decode.d5.loss_cls: 0.0340  decode.d5.loss_mask: 0.5385  decode.d5.loss_dice: 0.9185  decode.d6.loss_cls: 0.0409  decode.d6.loss_mask: 0.5006  decode.d6.loss_dice: 0.9281  decode.d7.loss_cls: 0.0318  decode.d7.loss_mask: 0.5493  decode.d7.loss_dice: 0.9265  decode.d8.loss_cls: 0.0349  decode.d8.loss_mask: 0.5445  decode.d8.loss_dice: 0.9283
11/15 18:58:43 - mmengine - INFO - Iter(train) [69650/90000]  base_lr: 2.6236e-05 lr: 2.6236e-06  eta: 3:24:09  time: 0.5965  data_time: 0.0104  memory: 10656  grad_norm: 438.6464  loss: 15.6007  decode.loss_cls: 0.0578  decode.loss_mask: 0.5301  decode.loss_dice: 0.9359  decode.d0.loss_cls: 0.0763  decode.d0.loss_mask: 0.5609  decode.d0.loss_dice: 1.0566  decode.d1.loss_cls: 0.0672  decode.d1.loss_mask: 0.5288  decode.d1.loss_dice: 1.0029  decode.d2.loss_cls: 0.0622  decode.d2.loss_mask: 0.5218  decode.d2.loss_dice: 0.9641  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.5285  decode.d3.loss_dice: 0.9570  decode.d4.loss_cls: 0.0582  decode.d4.loss_mask: 0.5274  decode.d4.loss_dice: 0.9625  decode.d5.loss_cls: 0.0639  decode.d5.loss_mask: 0.5303  decode.d5.loss_dice: 0.9518  decode.d6.loss_cls: 0.0582  decode.d6.loss_mask: 0.5298  decode.d6.loss_dice: 0.9403  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.5278  decode.d7.loss_dice: 0.9479  decode.d8.loss_cls: 0.0609  decode.d8.loss_mask: 0.5290  decode.d8.loss_dice: 0.9532
11/15 18:59:13 - mmengine - INFO - Iter(train) [69700/90000]  base_lr: 2.6178e-05 lr: 2.6178e-06  eta: 3:23:39  time: 0.5978  data_time: 0.0107  memory: 10692  grad_norm: 312.6628  loss: 16.3281  decode.loss_cls: 0.0671  decode.loss_mask: 0.4497  decode.loss_dice: 1.0934  decode.d0.loss_cls: 0.0622  decode.d0.loss_mask: 0.4595  decode.d0.loss_dice: 1.2027  decode.d1.loss_cls: 0.0663  decode.d1.loss_mask: 0.4482  decode.d1.loss_dice: 1.1303  decode.d2.loss_cls: 0.0734  decode.d2.loss_mask: 0.4475  decode.d2.loss_dice: 1.1133  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.4532  decode.d3.loss_dice: 1.0809  decode.d4.loss_cls: 0.0496  decode.d4.loss_mask: 0.4478  decode.d4.loss_dice: 1.1232  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.4489  decode.d5.loss_dice: 1.1165  decode.d6.loss_cls: 0.0700  decode.d6.loss_mask: 0.4465  decode.d6.loss_dice: 1.1141  decode.d7.loss_cls: 0.0636  decode.d7.loss_mask: 0.4514  decode.d7.loss_dice: 1.1082  decode.d8.loss_cls: 0.0640  decode.d8.loss_mask: 0.4481  decode.d8.loss_dice: 1.1000
11/15 18:59:43 - mmengine - INFO - Iter(train) [69750/90000]  base_lr: 2.6120e-05 lr: 2.6120e-06  eta: 3:23:09  time: 0.5993  data_time: 0.0108  memory: 10675  grad_norm: 254.6407  loss: 15.1671  decode.loss_cls: 0.0489  decode.loss_mask: 0.4425  decode.loss_dice: 1.0253  decode.d0.loss_cls: 0.0831  decode.d0.loss_mask: 0.4569  decode.d0.loss_dice: 1.0888  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.4400  decode.d1.loss_dice: 1.0232  decode.d2.loss_cls: 0.0558  decode.d2.loss_mask: 0.4382  decode.d2.loss_dice: 1.0016  decode.d3.loss_cls: 0.0623  decode.d3.loss_mask: 0.4392  decode.d3.loss_dice: 0.9808  decode.d4.loss_cls: 0.0605  decode.d4.loss_mask: 0.4370  decode.d4.loss_dice: 1.0133  decode.d5.loss_cls: 0.0600  decode.d5.loss_mask: 0.4361  decode.d5.loss_dice: 0.9877  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.4372  decode.d6.loss_dice: 1.0085  decode.d7.loss_cls: 0.0561  decode.d7.loss_mask: 0.4360  decode.d7.loss_dice: 1.0108  decode.d8.loss_cls: 0.0475  decode.d8.loss_mask: 0.4396  decode.d8.loss_dice: 1.0314
11/15 19:00:13 - mmengine - INFO - Iter(train) [69800/90000]  base_lr: 2.6062e-05 lr: 2.6062e-06  eta: 3:22:39  time: 0.5965  data_time: 0.0104  memory: 10692  grad_norm: 362.1106  loss: 17.0279  decode.loss_cls: 0.0513  decode.loss_mask: 0.5329  decode.loss_dice: 1.0777  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.5381  decode.d0.loss_dice: 1.1750  decode.d1.loss_cls: 0.0610  decode.d1.loss_mask: 0.5292  decode.d1.loss_dice: 1.1077  decode.d2.loss_cls: 0.0604  decode.d2.loss_mask: 0.5357  decode.d2.loss_dice: 1.1066  decode.d3.loss_cls: 0.0470  decode.d3.loss_mask: 0.5375  decode.d3.loss_dice: 1.1030  decode.d4.loss_cls: 0.0434  decode.d4.loss_mask: 0.5559  decode.d4.loss_dice: 1.1079  decode.d5.loss_cls: 0.0451  decode.d5.loss_mask: 0.5528  decode.d5.loss_dice: 1.1170  decode.d6.loss_cls: 0.0496  decode.d6.loss_mask: 0.5356  decode.d6.loss_dice: 1.1117  decode.d7.loss_cls: 0.0463  decode.d7.loss_mask: 0.5345  decode.d7.loss_dice: 1.1000  decode.d8.loss_cls: 0.0538  decode.d8.loss_mask: 0.5320  decode.d8.loss_dice: 1.0949
11/15 19:00:43 - mmengine - INFO - Iter(train) [69850/90000]  base_lr: 2.6004e-05 lr: 2.6004e-06  eta: 3:22:09  time: 0.5958  data_time: 0.0104  memory: 10692  grad_norm: 531.8228  loss: 16.9146  decode.loss_cls: 0.0422  decode.loss_mask: 0.5922  decode.loss_dice: 1.0413  decode.d0.loss_cls: 0.0774  decode.d0.loss_mask: 0.6207  decode.d0.loss_dice: 1.0786  decode.d1.loss_cls: 0.0437  decode.d1.loss_mask: 0.5919  decode.d1.loss_dice: 1.0463  decode.d2.loss_cls: 0.0484  decode.d2.loss_mask: 0.5725  decode.d2.loss_dice: 1.0511  decode.d3.loss_cls: 0.0476  decode.d3.loss_mask: 0.5852  decode.d3.loss_dice: 1.0888  decode.d4.loss_cls: 0.0430  decode.d4.loss_mask: 0.5867  decode.d4.loss_dice: 1.0610  decode.d5.loss_cls: 0.0472  decode.d5.loss_mask: 0.5876  decode.d5.loss_dice: 1.0565  decode.d6.loss_cls: 0.0476  decode.d6.loss_mask: 0.5858  decode.d6.loss_dice: 1.0255  decode.d7.loss_cls: 0.0518  decode.d7.loss_mask: 0.5862  decode.d7.loss_dice: 1.0417  decode.d8.loss_cls: 0.0432  decode.d8.loss_mask: 0.5916  decode.d8.loss_dice: 1.0313
11/15 19:01:13 - mmengine - INFO - Iter(train) [69900/90000]  base_lr: 2.5946e-05 lr: 2.5946e-06  eta: 3:21:39  time: 0.5963  data_time: 0.0106  memory: 10692  grad_norm: 613.6281  loss: 17.7124  decode.loss_cls: 0.0454  decode.loss_mask: 0.6722  decode.loss_dice: 1.0368  decode.d0.loss_cls: 0.0842  decode.d0.loss_mask: 0.7360  decode.d0.loss_dice: 1.0763  decode.d1.loss_cls: 0.0491  decode.d1.loss_mask: 0.6823  decode.d1.loss_dice: 1.0578  decode.d2.loss_cls: 0.0471  decode.d2.loss_mask: 0.6821  decode.d2.loss_dice: 1.0260  decode.d3.loss_cls: 0.0325  decode.d3.loss_mask: 0.6789  decode.d3.loss_dice: 1.0422  decode.d4.loss_cls: 0.0457  decode.d4.loss_mask: 0.6816  decode.d4.loss_dice: 1.0445  decode.d5.loss_cls: 0.0456  decode.d5.loss_mask: 0.6784  decode.d5.loss_dice: 1.0462  decode.d6.loss_cls: 0.0485  decode.d6.loss_mask: 0.6692  decode.d6.loss_dice: 1.0163  decode.d7.loss_cls: 0.0402  decode.d7.loss_mask: 0.6734  decode.d7.loss_dice: 1.0324  decode.d8.loss_cls: 0.0517  decode.d8.loss_mask: 0.6714  decode.d8.loss_dice: 1.0185
11/15 19:01:43 - mmengine - INFO - Iter(train) [69950/90000]  base_lr: 2.5887e-05 lr: 2.5887e-06  eta: 3:21:08  time: 0.5974  data_time: 0.0106  memory: 10656  grad_norm: 332.8032  loss: 15.5731  decode.loss_cls: 0.0538  decode.loss_mask: 0.4821  decode.loss_dice: 1.0074  decode.d0.loss_cls: 0.0711  decode.d0.loss_mask: 0.5066  decode.d0.loss_dice: 1.0967  decode.d1.loss_cls: 0.0527  decode.d1.loss_mask: 0.4866  decode.d1.loss_dice: 0.9897  decode.d2.loss_cls: 0.0604  decode.d2.loss_mask: 0.4836  decode.d2.loss_dice: 0.9819  decode.d3.loss_cls: 0.0563  decode.d3.loss_mask: 0.4881  decode.d3.loss_dice: 0.9953  decode.d4.loss_cls: 0.0580  decode.d4.loss_mask: 0.4874  decode.d4.loss_dice: 1.0072  decode.d5.loss_cls: 0.0507  decode.d5.loss_mask: 0.4869  decode.d5.loss_dice: 1.0249  decode.d6.loss_cls: 0.0537  decode.d6.loss_mask: 0.4865  decode.d6.loss_dice: 0.9830  decode.d7.loss_cls: 0.0583  decode.d7.loss_mask: 0.4808  decode.d7.loss_dice: 1.0275  decode.d8.loss_cls: 0.0460  decode.d8.loss_mask: 0.4832  decode.d8.loss_dice: 1.0268
11/15 19:02:12 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 19:02:12 - mmengine - INFO - Iter(train) [70000/90000]  base_lr: 2.5829e-05 lr: 2.5829e-06  eta: 3:20:38  time: 0.5963  data_time: 0.0103  memory: 10713  grad_norm: 236.3913  loss: 15.9158  decode.loss_cls: 0.0611  decode.loss_mask: 0.4452  decode.loss_dice: 1.0672  decode.d0.loss_cls: 0.0812  decode.d0.loss_mask: 0.4696  decode.d0.loss_dice: 1.1410  decode.d1.loss_cls: 0.0592  decode.d1.loss_mask: 0.4628  decode.d1.loss_dice: 1.1274  decode.d2.loss_cls: 0.0593  decode.d2.loss_mask: 0.4560  decode.d2.loss_dice: 1.0766  decode.d3.loss_cls: 0.0587  decode.d3.loss_mask: 0.4576  decode.d3.loss_dice: 1.0908  decode.d4.loss_cls: 0.0609  decode.d4.loss_mask: 0.4478  decode.d4.loss_dice: 1.0736  decode.d5.loss_cls: 0.0615  decode.d5.loss_mask: 0.4449  decode.d5.loss_dice: 1.0607  decode.d6.loss_cls: 0.0610  decode.d6.loss_mask: 0.4435  decode.d6.loss_dice: 1.0416  decode.d7.loss_cls: 0.0649  decode.d7.loss_mask: 0.4446  decode.d7.loss_dice: 1.0238  decode.d8.loss_cls: 0.0688  decode.d8.loss_mask: 0.4452  decode.d8.loss_dice: 1.0593
11/15 19:02:12 - mmengine - INFO - Saving checkpoint at 70000 iterations
11/15 19:02:31 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:21  time: 0.3085  data_time: 0.0039  memory: 4095  
11/15 19:02:47 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:04  time: 0.3082  data_time: 0.0038  memory: 4095  
11/15 19:03:02 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:48  time: 0.3086  data_time: 0.0038  memory: 4095  
11/15 19:03:17 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:32  time: 0.3082  data_time: 0.0039  memory: 4095  
11/15 19:03:33 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3086  data_time: 0.0039  memory: 4095  
11/15 19:03:48 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:01  time: 0.3084  data_time: 0.0038  memory: 4095  
11/15 19:04:04 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3085  data_time: 0.0039  memory: 4095  
11/15 19:04:19 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:30  time: 0.3085  data_time: 0.0038  memory: 4095  
11/15 19:04:35 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3089  data_time: 0.0040  memory: 4095  
11/15 19:04:50 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3086  data_time: 0.0037  memory: 4095  
11/15 19:04:50 - mmengine - INFO - per class results:
11/15 19:04:50 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 98.17 | 98.63 |
|    sidewalk   | 86.31 | 93.83 |
|    building   | 93.12 | 96.24 |
|      wall     | 65.81 | 78.81 |
|     fence     | 62.71 | 74.02 |
|      pole     | 68.35 | 83.25 |
| traffic light |  72.0 | 82.74 |
|  traffic sign | 81.47 | 86.67 |
|   vegetation  | 92.54 | 96.27 |
|    terrain    | 65.55 |  84.8 |
|      sky      | 94.93 | 97.71 |
|     person    | 82.66 | 90.78 |
|     rider     | 64.55 | 83.09 |
|      car      | 95.32 | 98.04 |
|     truck     | 83.49 | 93.18 |
|      bus      |  87.3 | 90.92 |
|     train     | 68.32 | 93.87 |
|   motorcycle  | 68.71 | 82.13 |
|    bicycle    | 78.96 | 89.81 |
+---------------+-------+-------+
11/15 19:04:50 - mmengine - INFO - Iter(val) [500/500]    aAcc: 96.3100  mIoU: 79.4900  mAcc: 89.2000  data_time: 0.0044  time: 0.3091
11/15 19:04:50 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024/best_mIoU_iter_60000.pth is removed
11/15 19:04:52 - mmengine - INFO - The best checkpoint with 79.4900 mIoU at 70000 iter is saved to best_mIoU_iter_70000.pth.
11/15 19:05:25 - mmengine - INFO - Iter(train) [70050/90000]  base_lr: 2.5771e-05 lr: 2.5771e-06  eta: 3:20:09  time: 0.5970  data_time: 0.0105  memory: 10641  grad_norm: 266.9257  loss: 14.3366  decode.loss_cls: 0.0710  decode.loss_mask: 0.4030  decode.loss_dice: 0.9420  decode.d0.loss_cls: 0.0794  decode.d0.loss_mask: 0.4203  decode.d0.loss_dice: 1.0480  decode.d1.loss_cls: 0.0935  decode.d1.loss_mask: 0.3946  decode.d1.loss_dice: 0.9571  decode.d2.loss_cls: 0.0904  decode.d2.loss_mask: 0.4056  decode.d2.loss_dice: 0.9275  decode.d3.loss_cls: 0.0834  decode.d3.loss_mask: 0.4117  decode.d3.loss_dice: 0.9105  decode.d4.loss_cls: 0.0829  decode.d4.loss_mask: 0.4008  decode.d4.loss_dice: 0.9364  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.4148  decode.d5.loss_dice: 0.9360  decode.d6.loss_cls: 0.0764  decode.d6.loss_mask: 0.4011  decode.d6.loss_dice: 0.9345  decode.d7.loss_cls: 0.0796  decode.d7.loss_mask: 0.4090  decode.d7.loss_dice: 0.9210  decode.d8.loss_cls: 0.0697  decode.d8.loss_mask: 0.4048  decode.d8.loss_dice: 0.9587
11/15 19:05:54 - mmengine - INFO - Iter(train) [70100/90000]  base_lr: 2.5713e-05 lr: 2.5713e-06  eta: 3:19:39  time: 0.5966  data_time: 0.0106  memory: 10692  grad_norm: 395.8955  loss: 15.9155  decode.loss_cls: 0.0734  decode.loss_mask: 0.4992  decode.loss_dice: 0.9872  decode.d0.loss_cls: 0.0915  decode.d0.loss_mask: 0.5145  decode.d0.loss_dice: 1.0491  decode.d1.loss_cls: 0.0721  decode.d1.loss_mask: 0.5563  decode.d1.loss_dice: 1.0060  decode.d2.loss_cls: 0.0754  decode.d2.loss_mask: 0.5697  decode.d2.loss_dice: 0.9803  decode.d3.loss_cls: 0.0714  decode.d3.loss_mask: 0.5636  decode.d3.loss_dice: 1.0005  decode.d4.loss_cls: 0.0689  decode.d4.loss_mask: 0.4954  decode.d4.loss_dice: 0.9671  decode.d5.loss_cls: 0.0729  decode.d5.loss_mask: 0.5304  decode.d5.loss_dice: 1.0046  decode.d6.loss_cls: 0.0744  decode.d6.loss_mask: 0.5074  decode.d6.loss_dice: 1.0000  decode.d7.loss_cls: 0.0735  decode.d7.loss_mask: 0.4879  decode.d7.loss_dice: 0.9897  decode.d8.loss_cls: 0.0748  decode.d8.loss_mask: 0.4907  decode.d8.loss_dice: 0.9676
11/15 19:06:24 - mmengine - INFO - Iter(train) [70150/90000]  base_lr: 2.5655e-05 lr: 2.5655e-06  eta: 3:19:09  time: 0.5977  data_time: 0.0106  memory: 10692  grad_norm: 443.5636  loss: 18.1219  decode.loss_cls: 0.0676  decode.loss_mask: 0.6003  decode.loss_dice: 1.1062  decode.d0.loss_cls: 0.0952  decode.d0.loss_mask: 0.6517  decode.d0.loss_dice: 1.1691  decode.d1.loss_cls: 0.0623  decode.d1.loss_mask: 0.6152  decode.d1.loss_dice: 1.1304  decode.d2.loss_cls: 0.0515  decode.d2.loss_mask: 0.6217  decode.d2.loss_dice: 1.1605  decode.d3.loss_cls: 0.0507  decode.d3.loss_mask: 0.6119  decode.d3.loss_dice: 1.1303  decode.d4.loss_cls: 0.0625  decode.d4.loss_mask: 0.5981  decode.d4.loss_dice: 1.1191  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.6041  decode.d5.loss_dice: 1.1300  decode.d6.loss_cls: 0.0662  decode.d6.loss_mask: 0.6082  decode.d6.loss_dice: 1.1363  decode.d7.loss_cls: 0.0619  decode.d7.loss_mask: 0.6134  decode.d7.loss_dice: 1.1338  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 0.6086  decode.d8.loss_dice: 1.1260
11/15 19:06:54 - mmengine - INFO - Iter(train) [70200/90000]  base_lr: 2.5597e-05 lr: 2.5597e-06  eta: 3:18:39  time: 0.5961  data_time: 0.0106  memory: 10692  grad_norm: 256.2891  loss: 16.7626  decode.loss_cls: 0.0780  decode.loss_mask: 0.4487  decode.loss_dice: 1.1414  decode.d0.loss_cls: 0.1000  decode.d0.loss_mask: 0.4640  decode.d0.loss_dice: 1.2391  decode.d1.loss_cls: 0.0936  decode.d1.loss_mask: 0.4509  decode.d1.loss_dice: 1.1599  decode.d2.loss_cls: 0.0893  decode.d2.loss_mask: 0.4542  decode.d2.loss_dice: 1.1413  decode.d3.loss_cls: 0.0861  decode.d3.loss_mask: 0.4499  decode.d3.loss_dice: 1.1367  decode.d4.loss_cls: 0.0925  decode.d4.loss_mask: 0.4459  decode.d4.loss_dice: 1.1044  decode.d5.loss_cls: 0.0987  decode.d5.loss_mask: 0.4418  decode.d5.loss_dice: 1.1015  decode.d6.loss_cls: 0.0823  decode.d6.loss_mask: 0.4471  decode.d6.loss_dice: 1.1034  decode.d7.loss_cls: 0.0748  decode.d7.loss_mask: 0.4519  decode.d7.loss_dice: 1.1119  decode.d8.loss_cls: 0.0775  decode.d8.loss_mask: 0.4415  decode.d8.loss_dice: 1.1543
11/15 19:07:24 - mmengine - INFO - Iter(train) [70250/90000]  base_lr: 2.5539e-05 lr: 2.5539e-06  eta: 3:18:09  time: 0.6028  data_time: 0.0109  memory: 10656  grad_norm: 414.5350  loss: 16.6615  decode.loss_cls: 0.0623  decode.loss_mask: 0.5008  decode.loss_dice: 1.0986  decode.d0.loss_cls: 0.0871  decode.d0.loss_mask: 0.5298  decode.d0.loss_dice: 1.1165  decode.d1.loss_cls: 0.0551  decode.d1.loss_mask: 0.5026  decode.d1.loss_dice: 1.1117  decode.d2.loss_cls: 0.0590  decode.d2.loss_mask: 0.4957  decode.d2.loss_dice: 1.0812  decode.d3.loss_cls: 0.0640  decode.d3.loss_mask: 0.5048  decode.d3.loss_dice: 1.1126  decode.d4.loss_cls: 0.0562  decode.d4.loss_mask: 0.5077  decode.d4.loss_dice: 1.0988  decode.d5.loss_cls: 0.0600  decode.d5.loss_mask: 0.5009  decode.d5.loss_dice: 1.0761  decode.d6.loss_cls: 0.0541  decode.d6.loss_mask: 0.5081  decode.d6.loss_dice: 1.1157  decode.d7.loss_cls: 0.0656  decode.d7.loss_mask: 0.5045  decode.d7.loss_dice: 1.0592  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.5135  decode.d8.loss_dice: 1.0946
11/15 19:07:54 - mmengine - INFO - Iter(train) [70300/90000]  base_lr: 2.5480e-05 lr: 2.5480e-06  eta: 3:17:39  time: 0.5961  data_time: 0.0108  memory: 10713  grad_norm: 455.8273  loss: 15.7941  decode.loss_cls: 0.0373  decode.loss_mask: 0.6005  decode.loss_dice: 0.9314  decode.d0.loss_cls: 0.0706  decode.d0.loss_mask: 0.6477  decode.d0.loss_dice: 0.9949  decode.d1.loss_cls: 0.0418  decode.d1.loss_mask: 0.6011  decode.d1.loss_dice: 0.9398  decode.d2.loss_cls: 0.0407  decode.d2.loss_mask: 0.6004  decode.d2.loss_dice: 0.9328  decode.d3.loss_cls: 0.0329  decode.d3.loss_mask: 0.5883  decode.d3.loss_dice: 0.9367  decode.d4.loss_cls: 0.0360  decode.d4.loss_mask: 0.5946  decode.d4.loss_dice: 0.9333  decode.d5.loss_cls: 0.0376  decode.d5.loss_mask: 0.5964  decode.d5.loss_dice: 0.9138  decode.d6.loss_cls: 0.0304  decode.d6.loss_mask: 0.5998  decode.d6.loss_dice: 0.9308  decode.d7.loss_cls: 0.0345  decode.d7.loss_mask: 0.5950  decode.d7.loss_dice: 0.9221  decode.d8.loss_cls: 0.0362  decode.d8.loss_mask: 0.6056  decode.d8.loss_dice: 0.9312
11/15 19:08:24 - mmengine - INFO - Iter(train) [70350/90000]  base_lr: 2.5422e-05 lr: 2.5422e-06  eta: 3:17:08  time: 0.6068  data_time: 0.0105  memory: 10656  grad_norm: 180.5757  loss: 14.6022  decode.loss_cls: 0.0451  decode.loss_mask: 0.3946  decode.loss_dice: 1.0016  decode.d0.loss_cls: 0.0633  decode.d0.loss_mask: 0.4116  decode.d0.loss_dice: 1.0637  decode.d1.loss_cls: 0.0491  decode.d1.loss_mask: 0.3924  decode.d1.loss_dice: 1.0004  decode.d2.loss_cls: 0.0433  decode.d2.loss_mask: 0.3954  decode.d2.loss_dice: 1.0040  decode.d3.loss_cls: 0.0502  decode.d3.loss_mask: 0.3999  decode.d3.loss_dice: 1.0066  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.4097  decode.d4.loss_dice: 1.0044  decode.d5.loss_cls: 0.0487  decode.d5.loss_mask: 0.4010  decode.d5.loss_dice: 1.0137  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.4053  decode.d6.loss_dice: 1.0139  decode.d7.loss_cls: 0.0488  decode.d7.loss_mask: 0.4004  decode.d7.loss_dice: 0.9946  decode.d8.loss_cls: 0.0468  decode.d8.loss_mask: 0.3959  decode.d8.loss_dice: 1.0041
11/15 19:08:54 - mmengine - INFO - Iter(train) [70400/90000]  base_lr: 2.5364e-05 lr: 2.5364e-06  eta: 3:16:38  time: 0.6039  data_time: 0.0109  memory: 10675  grad_norm: 456.8596  loss: 15.4669  decode.loss_cls: 0.0508  decode.loss_mask: 0.4257  decode.loss_dice: 1.0282  decode.d0.loss_cls: 0.1026  decode.d0.loss_mask: 0.4302  decode.d0.loss_dice: 1.1180  decode.d1.loss_cls: 0.0747  decode.d1.loss_mask: 0.4543  decode.d1.loss_dice: 1.1040  decode.d2.loss_cls: 0.0601  decode.d2.loss_mask: 0.4421  decode.d2.loss_dice: 1.0614  decode.d3.loss_cls: 0.0569  decode.d3.loss_mask: 0.4318  decode.d3.loss_dice: 1.0035  decode.d4.loss_cls: 0.0653  decode.d4.loss_mask: 0.4199  decode.d4.loss_dice: 1.0355  decode.d5.loss_cls: 0.0634  decode.d5.loss_mask: 0.4203  decode.d5.loss_dice: 1.0352  decode.d6.loss_cls: 0.0690  decode.d6.loss_mask: 0.4219  decode.d6.loss_dice: 1.0260  decode.d7.loss_cls: 0.0509  decode.d7.loss_mask: 0.4485  decode.d7.loss_dice: 1.0321  decode.d8.loss_cls: 0.0592  decode.d8.loss_mask: 0.4283  decode.d8.loss_dice: 1.0470
11/15 19:09:24 - mmengine - INFO - Iter(train) [70450/90000]  base_lr: 2.5306e-05 lr: 2.5306e-06  eta: 3:16:08  time: 0.5966  data_time: 0.0107  memory: 10656  grad_norm: 227.3134  loss: 15.6963  decode.loss_cls: 0.0775  decode.loss_mask: 0.3520  decode.loss_dice: 1.1132  decode.d0.loss_cls: 0.0905  decode.d0.loss_mask: 0.3626  decode.d0.loss_dice: 1.2172  decode.d1.loss_cls: 0.1036  decode.d1.loss_mask: 0.3594  decode.d1.loss_dice: 1.1345  decode.d2.loss_cls: 0.0882  decode.d2.loss_mask: 0.3567  decode.d2.loss_dice: 1.1105  decode.d3.loss_cls: 0.0837  decode.d3.loss_mask: 0.3600  decode.d3.loss_dice: 1.1323  decode.d4.loss_cls: 0.0870  decode.d4.loss_mask: 0.3567  decode.d4.loss_dice: 1.1055  decode.d5.loss_cls: 0.0923  decode.d5.loss_mask: 0.3529  decode.d5.loss_dice: 1.1045  decode.d6.loss_cls: 0.0735  decode.d6.loss_mask: 0.3563  decode.d6.loss_dice: 1.1253  decode.d7.loss_cls: 0.0899  decode.d7.loss_mask: 0.3549  decode.d7.loss_dice: 1.0974  decode.d8.loss_cls: 0.0923  decode.d8.loss_mask: 0.3553  decode.d8.loss_dice: 1.1108
11/15 19:09:53 - mmengine - INFO - Iter(train) [70500/90000]  base_lr: 2.5247e-05 lr: 2.5247e-06  eta: 3:15:38  time: 0.5957  data_time: 0.0105  memory: 10656  grad_norm: 401.3563  loss: 15.7050  decode.loss_cls: 0.0644  decode.loss_mask: 0.5119  decode.loss_dice: 0.9680  decode.d0.loss_cls: 0.0803  decode.d0.loss_mask: 0.5795  decode.d0.loss_dice: 1.0963  decode.d1.loss_cls: 0.0742  decode.d1.loss_mask: 0.5215  decode.d1.loss_dice: 1.0235  decode.d2.loss_cls: 0.0655  decode.d2.loss_mask: 0.5238  decode.d2.loss_dice: 0.9882  decode.d3.loss_cls: 0.0652  decode.d3.loss_mask: 0.5143  decode.d3.loss_dice: 0.9535  decode.d4.loss_cls: 0.0792  decode.d4.loss_mask: 0.4912  decode.d4.loss_dice: 0.9747  decode.d5.loss_cls: 0.0779  decode.d5.loss_mask: 0.4985  decode.d5.loss_dice: 0.9314  decode.d6.loss_cls: 0.0755  decode.d6.loss_mask: 0.4976  decode.d6.loss_dice: 0.9405  decode.d7.loss_cls: 0.0632  decode.d7.loss_mask: 0.5039  decode.d7.loss_dice: 0.9854  decode.d8.loss_cls: 0.0681  decode.d8.loss_mask: 0.5087  decode.d8.loss_dice: 0.9791
11/15 19:10:23 - mmengine - INFO - Iter(train) [70550/90000]  base_lr: 2.5189e-05 lr: 2.5189e-06  eta: 3:15:08  time: 0.5955  data_time: 0.0103  memory: 10692  grad_norm: 483.7709  loss: 12.7346  decode.loss_cls: 0.0364  decode.loss_mask: 0.4206  decode.loss_dice: 0.7925  decode.d0.loss_cls: 0.0889  decode.d0.loss_mask: 0.4511  decode.d0.loss_dice: 0.8704  decode.d1.loss_cls: 0.0525  decode.d1.loss_mask: 0.4266  decode.d1.loss_dice: 0.8616  decode.d2.loss_cls: 0.0490  decode.d2.loss_mask: 0.4142  decode.d2.loss_dice: 0.7963  decode.d3.loss_cls: 0.0396  decode.d3.loss_mask: 0.4150  decode.d3.loss_dice: 0.7882  decode.d4.loss_cls: 0.0321  decode.d4.loss_mask: 0.4163  decode.d4.loss_dice: 0.7745  decode.d5.loss_cls: 0.0358  decode.d5.loss_mask: 0.4150  decode.d5.loss_dice: 0.7846  decode.d6.loss_cls: 0.0371  decode.d6.loss_mask: 0.4191  decode.d6.loss_dice: 0.7952  decode.d7.loss_cls: 0.0370  decode.d7.loss_mask: 0.4194  decode.d7.loss_dice: 0.8080  decode.d8.loss_cls: 0.0337  decode.d8.loss_mask: 0.4165  decode.d8.loss_dice: 0.8074
11/15 19:10:53 - mmengine - INFO - Iter(train) [70600/90000]  base_lr: 2.5131e-05 lr: 2.5131e-06  eta: 3:14:38  time: 0.5969  data_time: 0.0106  memory: 10692  grad_norm: 388.0793  loss: 14.4902  decode.loss_cls: 0.0375  decode.loss_mask: 0.4718  decode.loss_dice: 0.9294  decode.d0.loss_cls: 0.0889  decode.d0.loss_mask: 0.4888  decode.d0.loss_dice: 0.9373  decode.d1.loss_cls: 0.0590  decode.d1.loss_mask: 0.4588  decode.d1.loss_dice: 0.9251  decode.d2.loss_cls: 0.0547  decode.d2.loss_mask: 0.4712  decode.d2.loss_dice: 0.9279  decode.d3.loss_cls: 0.0450  decode.d3.loss_mask: 0.4793  decode.d3.loss_dice: 0.9038  decode.d4.loss_cls: 0.0451  decode.d4.loss_mask: 0.4765  decode.d4.loss_dice: 0.9112  decode.d5.loss_cls: 0.0408  decode.d5.loss_mask: 0.4745  decode.d5.loss_dice: 0.9340  decode.d6.loss_cls: 0.0412  decode.d6.loss_mask: 0.4729  decode.d6.loss_dice: 0.9238  decode.d7.loss_cls: 0.0406  decode.d7.loss_mask: 0.4736  decode.d7.loss_dice: 0.9299  decode.d8.loss_cls: 0.0429  decode.d8.loss_mask: 0.4721  decode.d8.loss_dice: 0.9324
11/15 19:11:23 - mmengine - INFO - Iter(train) [70650/90000]  base_lr: 2.5073e-05 lr: 2.5073e-06  eta: 3:14:07  time: 0.5964  data_time: 0.0107  memory: 10675  grad_norm: 287.9817  loss: 14.9106  decode.loss_cls: 0.0336  decode.loss_mask: 0.4195  decode.loss_dice: 1.0245  decode.d0.loss_cls: 0.0764  decode.d0.loss_mask: 0.4306  decode.d0.loss_dice: 1.0456  decode.d1.loss_cls: 0.0503  decode.d1.loss_mask: 0.4275  decode.d1.loss_dice: 1.0364  decode.d2.loss_cls: 0.0352  decode.d2.loss_mask: 0.4238  decode.d2.loss_dice: 1.0432  decode.d3.loss_cls: 0.0427  decode.d3.loss_mask: 0.4175  decode.d3.loss_dice: 1.0190  decode.d4.loss_cls: 0.0365  decode.d4.loss_mask: 0.4232  decode.d4.loss_dice: 1.0268  decode.d5.loss_cls: 0.0446  decode.d5.loss_mask: 0.4199  decode.d5.loss_dice: 1.0044  decode.d6.loss_cls: 0.0277  decode.d6.loss_mask: 0.4219  decode.d6.loss_dice: 1.0368  decode.d7.loss_cls: 0.0368  decode.d7.loss_mask: 0.4215  decode.d7.loss_dice: 1.0074  decode.d8.loss_cls: 0.0373  decode.d8.loss_mask: 0.4245  decode.d8.loss_dice: 1.0154
11/15 19:11:53 - mmengine - INFO - Iter(train) [70700/90000]  base_lr: 2.5014e-05 lr: 2.5014e-06  eta: 3:13:37  time: 0.5967  data_time: 0.0106  memory: 10656  grad_norm: 455.6916  loss: 16.5666  decode.loss_cls: 0.0701  decode.loss_mask: 0.5479  decode.loss_dice: 1.0229  decode.d0.loss_cls: 0.0901  decode.d0.loss_mask: 0.5845  decode.d0.loss_dice: 1.1037  decode.d1.loss_cls: 0.0653  decode.d1.loss_mask: 0.5539  decode.d1.loss_dice: 1.0421  decode.d2.loss_cls: 0.0635  decode.d2.loss_mask: 0.5460  decode.d2.loss_dice: 1.0291  decode.d3.loss_cls: 0.0672  decode.d3.loss_mask: 0.5435  decode.d3.loss_dice: 1.0327  decode.d4.loss_cls: 0.0611  decode.d4.loss_mask: 0.5473  decode.d4.loss_dice: 1.0223  decode.d5.loss_cls: 0.0682  decode.d5.loss_mask: 0.5460  decode.d5.loss_dice: 1.0331  decode.d6.loss_cls: 0.0731  decode.d6.loss_mask: 0.5456  decode.d6.loss_dice: 1.0026  decode.d7.loss_cls: 0.0547  decode.d7.loss_mask: 0.5889  decode.d7.loss_dice: 1.0297  decode.d8.loss_cls: 0.0629  decode.d8.loss_mask: 0.5427  decode.d8.loss_dice: 1.0257
11/15 19:12:23 - mmengine - INFO - Iter(train) [70750/90000]  base_lr: 2.4956e-05 lr: 2.4956e-06  eta: 3:13:07  time: 0.5966  data_time: 0.0106  memory: 10692  grad_norm: 268.6080  loss: 15.9500  decode.loss_cls: 0.0377  decode.loss_mask: 0.4745  decode.loss_dice: 1.0669  decode.d0.loss_cls: 0.0760  decode.d0.loss_mask: 0.4991  decode.d0.loss_dice: 1.1470  decode.d1.loss_cls: 0.0469  decode.d1.loss_mask: 0.4805  decode.d1.loss_dice: 1.0663  decode.d2.loss_cls: 0.0329  decode.d2.loss_mask: 0.4797  decode.d2.loss_dice: 1.0969  decode.d3.loss_cls: 0.0404  decode.d3.loss_mask: 0.4791  decode.d3.loss_dice: 1.0626  decode.d4.loss_cls: 0.0411  decode.d4.loss_mask: 0.4777  decode.d4.loss_dice: 1.0734  decode.d5.loss_cls: 0.0393  decode.d5.loss_mask: 0.4759  decode.d5.loss_dice: 1.0619  decode.d6.loss_cls: 0.0430  decode.d6.loss_mask: 0.4805  decode.d6.loss_dice: 1.0283  decode.d7.loss_cls: 0.0393  decode.d7.loss_mask: 0.4765  decode.d7.loss_dice: 1.0551  decode.d8.loss_cls: 0.0410  decode.d8.loss_mask: 0.4788  decode.d8.loss_dice: 1.0517
11/15 19:12:53 - mmengine - INFO - Iter(train) [70800/90000]  base_lr: 2.4898e-05 lr: 2.4898e-06  eta: 3:12:37  time: 0.5983  data_time: 0.0107  memory: 10713  grad_norm: 362.2243  loss: 17.5775  decode.loss_cls: 0.0807  decode.loss_mask: 0.5299  decode.loss_dice: 1.1182  decode.d0.loss_cls: 0.0949  decode.d0.loss_mask: 0.5562  decode.d0.loss_dice: 1.2234  decode.d1.loss_cls: 0.0737  decode.d1.loss_mask: 0.5391  decode.d1.loss_dice: 1.1871  decode.d2.loss_cls: 0.0810  decode.d2.loss_mask: 0.5117  decode.d2.loss_dice: 1.1388  decode.d3.loss_cls: 0.0812  decode.d3.loss_mask: 0.5142  decode.d3.loss_dice: 1.1332  decode.d4.loss_cls: 0.0826  decode.d4.loss_mask: 0.5265  decode.d4.loss_dice: 1.1352  decode.d5.loss_cls: 0.0812  decode.d5.loss_mask: 0.5262  decode.d5.loss_dice: 1.1417  decode.d6.loss_cls: 0.0940  decode.d6.loss_mask: 0.5293  decode.d6.loss_dice: 1.1296  decode.d7.loss_cls: 0.0817  decode.d7.loss_mask: 0.5289  decode.d7.loss_dice: 1.1518  decode.d8.loss_cls: 0.0842  decode.d8.loss_mask: 0.5283  decode.d8.loss_dice: 1.0930
11/15 19:13:23 - mmengine - INFO - Iter(train) [70850/90000]  base_lr: 2.4839e-05 lr: 2.4839e-06  eta: 3:12:07  time: 0.5970  data_time: 0.0108  memory: 10656  grad_norm: 703.1506  loss: 15.9938  decode.loss_cls: 0.0619  decode.loss_mask: 0.4742  decode.loss_dice: 0.9962  decode.d0.loss_cls: 0.1117  decode.d0.loss_mask: 0.4913  decode.d0.loss_dice: 1.0726  decode.d1.loss_cls: 0.0746  decode.d1.loss_mask: 0.5199  decode.d1.loss_dice: 1.0378  decode.d2.loss_cls: 0.0671  decode.d2.loss_mask: 0.5022  decode.d2.loss_dice: 0.9923  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.4930  decode.d3.loss_dice: 1.0085  decode.d4.loss_cls: 0.0609  decode.d4.loss_mask: 0.5212  decode.d4.loss_dice: 1.0284  decode.d5.loss_cls: 0.0592  decode.d5.loss_mask: 0.5703  decode.d5.loss_dice: 1.0424  decode.d6.loss_cls: 0.0669  decode.d6.loss_mask: 0.5184  decode.d6.loss_dice: 1.0187  decode.d7.loss_cls: 0.0684  decode.d7.loss_mask: 0.5129  decode.d7.loss_dice: 1.0256  decode.d8.loss_cls: 0.0654  decode.d8.loss_mask: 0.4853  decode.d8.loss_dice: 0.9868
11/15 19:13:53 - mmengine - INFO - Iter(train) [70900/90000]  base_lr: 2.4781e-05 lr: 2.4781e-06  eta: 3:11:37  time: 0.5990  data_time: 0.0107  memory: 10692  grad_norm: 258.4876  loss: 16.0707  decode.loss_cls: 0.0532  decode.loss_mask: 0.4582  decode.loss_dice: 1.0579  decode.d0.loss_cls: 0.0779  decode.d0.loss_mask: 0.4900  decode.d0.loss_dice: 1.1826  decode.d1.loss_cls: 0.0718  decode.d1.loss_mask: 0.4533  decode.d1.loss_dice: 1.0847  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.4534  decode.d2.loss_dice: 1.0768  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.4538  decode.d3.loss_dice: 1.0892  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.4475  decode.d4.loss_dice: 1.0762  decode.d5.loss_cls: 0.0581  decode.d5.loss_mask: 0.4467  decode.d5.loss_dice: 1.0887  decode.d6.loss_cls: 0.0585  decode.d6.loss_mask: 0.4486  decode.d6.loss_dice: 1.0871  decode.d7.loss_cls: 0.0505  decode.d7.loss_mask: 0.4499  decode.d7.loss_dice: 1.0812  decode.d8.loss_cls: 0.0539  decode.d8.loss_mask: 0.4570  decode.d8.loss_dice: 1.0899
11/15 19:14:23 - mmengine - INFO - Iter(train) [70950/90000]  base_lr: 2.4722e-05 lr: 2.4722e-06  eta: 3:11:07  time: 0.6024  data_time: 0.0109  memory: 10656  grad_norm: 247.6485  loss: 14.3273  decode.loss_cls: 0.0623  decode.loss_mask: 0.4137  decode.loss_dice: 0.9190  decode.d0.loss_cls: 0.1030  decode.d0.loss_mask: 0.4260  decode.d0.loss_dice: 1.0127  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.4312  decode.d1.loss_dice: 0.9939  decode.d2.loss_cls: 0.0645  decode.d2.loss_mask: 0.4105  decode.d2.loss_dice: 0.9551  decode.d3.loss_cls: 0.0599  decode.d3.loss_mask: 0.4106  decode.d3.loss_dice: 0.9352  decode.d4.loss_cls: 0.0593  decode.d4.loss_mask: 0.4122  decode.d4.loss_dice: 0.9389  decode.d5.loss_cls: 0.0585  decode.d5.loss_mask: 0.4155  decode.d5.loss_dice: 0.9399  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.4122  decode.d6.loss_dice: 0.9275  decode.d7.loss_cls: 0.0645  decode.d7.loss_mask: 0.4112  decode.d7.loss_dice: 0.9420  decode.d8.loss_cls: 0.0562  decode.d8.loss_mask: 0.4161  decode.d8.loss_dice: 0.9433
11/15 19:14:56 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 19:14:56 - mmengine - INFO - Iter(train) [71000/90000]  base_lr: 2.4664e-05 lr: 2.4664e-06  eta: 3:10:37  time: 0.6511  data_time: 0.0109  memory: 10713  grad_norm: 439.8473  loss: 15.1776  decode.loss_cls: 0.0634  decode.loss_mask: 0.4179  decode.loss_dice: 1.0058  decode.d0.loss_cls: 0.0850  decode.d0.loss_mask: 0.4112  decode.d0.loss_dice: 1.1414  decode.d1.loss_cls: 0.0901  decode.d1.loss_mask: 0.4037  decode.d1.loss_dice: 1.0529  decode.d2.loss_cls: 0.0782  decode.d2.loss_mask: 0.4074  decode.d2.loss_dice: 1.0169  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.4156  decode.d3.loss_dice: 1.0026  decode.d4.loss_cls: 0.0692  decode.d4.loss_mask: 0.4145  decode.d4.loss_dice: 1.0076  decode.d5.loss_cls: 0.0661  decode.d5.loss_mask: 0.4194  decode.d5.loss_dice: 1.0356  decode.d6.loss_cls: 0.0687  decode.d6.loss_mask: 0.3948  decode.d6.loss_dice: 1.0089  decode.d7.loss_cls: 0.0660  decode.d7.loss_mask: 0.4155  decode.d7.loss_dice: 1.0144  decode.d8.loss_cls: 0.0648  decode.d8.loss_mask: 0.4191  decode.d8.loss_dice: 1.0520
11/15 19:15:30 - mmengine - INFO - Iter(train) [71050/90000]  base_lr: 2.4606e-05 lr: 2.4606e-06  eta: 3:10:08  time: 0.5985  data_time: 0.0106  memory: 10692  grad_norm: 530.1781  loss: 15.9161  decode.loss_cls: 0.0371  decode.loss_mask: 0.5685  decode.loss_dice: 0.9670  decode.d0.loss_cls: 0.0701  decode.d0.loss_mask: 0.5996  decode.d0.loss_dice: 1.0692  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.5683  decode.d1.loss_dice: 1.0130  decode.d2.loss_cls: 0.0416  decode.d2.loss_mask: 0.5611  decode.d2.loss_dice: 0.9919  decode.d3.loss_cls: 0.0398  decode.d3.loss_mask: 0.5630  decode.d3.loss_dice: 0.9440  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.5540  decode.d4.loss_dice: 0.9672  decode.d5.loss_cls: 0.0445  decode.d5.loss_mask: 0.5592  decode.d5.loss_dice: 0.9664  decode.d6.loss_cls: 0.0372  decode.d6.loss_mask: 0.5650  decode.d6.loss_dice: 0.9758  decode.d7.loss_cls: 0.0464  decode.d7.loss_mask: 0.5664  decode.d7.loss_dice: 0.9657  decode.d8.loss_cls: 0.0434  decode.d8.loss_mask: 0.5638  decode.d8.loss_dice: 0.9396
11/15 19:16:00 - mmengine - INFO - Iter(train) [71100/90000]  base_lr: 2.4547e-05 lr: 2.4547e-06  eta: 3:09:38  time: 0.6000  data_time: 0.0106  memory: 10728  grad_norm: 261.9277  loss: 14.0704  decode.loss_cls: 0.0694  decode.loss_mask: 0.3354  decode.loss_dice: 0.9798  decode.d0.loss_cls: 0.0826  decode.d0.loss_mask: 0.3462  decode.d0.loss_dice: 1.0920  decode.d1.loss_cls: 0.0866  decode.d1.loss_mask: 0.3536  decode.d1.loss_dice: 1.0007  decode.d2.loss_cls: 0.0816  decode.d2.loss_mask: 0.3499  decode.d2.loss_dice: 0.9891  decode.d3.loss_cls: 0.0584  decode.d3.loss_mask: 0.3486  decode.d3.loss_dice: 1.0069  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.3436  decode.d4.loss_dice: 0.9820  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.3399  decode.d5.loss_dice: 0.9701  decode.d6.loss_cls: 0.0504  decode.d6.loss_mask: 0.3348  decode.d6.loss_dice: 0.9857  decode.d7.loss_cls: 0.0682  decode.d7.loss_mask: 0.3352  decode.d7.loss_dice: 0.9839  decode.d8.loss_cls: 0.0562  decode.d8.loss_mask: 0.3355  decode.d8.loss_dice: 0.9753
11/15 19:16:30 - mmengine - INFO - Iter(train) [71150/90000]  base_lr: 2.4489e-05 lr: 2.4489e-06  eta: 3:09:08  time: 0.5991  data_time: 0.0107  memory: 10641  grad_norm: 445.0680  loss: 14.9462  decode.loss_cls: 0.0521  decode.loss_mask: 0.4730  decode.loss_dice: 0.9676  decode.d0.loss_cls: 0.0775  decode.d0.loss_mask: 0.4752  decode.d0.loss_dice: 0.9894  decode.d1.loss_cls: 0.0631  decode.d1.loss_mask: 0.4673  decode.d1.loss_dice: 0.9743  decode.d2.loss_cls: 0.0529  decode.d2.loss_mask: 0.4639  decode.d2.loss_dice: 0.9659  decode.d3.loss_cls: 0.0495  decode.d3.loss_mask: 0.4688  decode.d3.loss_dice: 0.9686  decode.d4.loss_cls: 0.0474  decode.d4.loss_mask: 0.4718  decode.d4.loss_dice: 0.9612  decode.d5.loss_cls: 0.0510  decode.d5.loss_mask: 0.4747  decode.d5.loss_dice: 0.9803  decode.d6.loss_cls: 0.0558  decode.d6.loss_mask: 0.4730  decode.d6.loss_dice: 0.9467  decode.d7.loss_cls: 0.0583  decode.d7.loss_mask: 0.4719  decode.d7.loss_dice: 0.9597  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.4712  decode.d8.loss_dice: 0.9570
11/15 19:17:00 - mmengine - INFO - Iter(train) [71200/90000]  base_lr: 2.4430e-05 lr: 2.4430e-06  eta: 3:08:38  time: 0.6014  data_time: 0.0108  memory: 10728  grad_norm: 386.5624  loss: 15.7298  decode.loss_cls: 0.0534  decode.loss_mask: 0.5449  decode.loss_dice: 0.9404  decode.d0.loss_cls: 0.0898  decode.d0.loss_mask: 0.6155  decode.d0.loss_dice: 1.0077  decode.d1.loss_cls: 0.0539  decode.d1.loss_mask: 0.5550  decode.d1.loss_dice: 0.9955  decode.d2.loss_cls: 0.0518  decode.d2.loss_mask: 0.5530  decode.d2.loss_dice: 0.9760  decode.d3.loss_cls: 0.0506  decode.d3.loss_mask: 0.5451  decode.d3.loss_dice: 0.9677  decode.d4.loss_cls: 0.0443  decode.d4.loss_mask: 0.5403  decode.d4.loss_dice: 0.9657  decode.d5.loss_cls: 0.0488  decode.d5.loss_mask: 0.5434  decode.d5.loss_dice: 0.9744  decode.d6.loss_cls: 0.0448  decode.d6.loss_mask: 0.5447  decode.d6.loss_dice: 0.9486  decode.d7.loss_cls: 0.0447  decode.d7.loss_mask: 0.5425  decode.d7.loss_dice: 0.9599  decode.d8.loss_cls: 0.0459  decode.d8.loss_mask: 0.5402  decode.d8.loss_dice: 0.9414
11/15 19:17:30 - mmengine - INFO - Iter(train) [71250/90000]  base_lr: 2.4372e-05 lr: 2.4372e-06  eta: 3:08:08  time: 0.6006  data_time: 0.0111  memory: 10728  grad_norm: 483.2569  loss: 17.0782  decode.loss_cls: 0.0433  decode.loss_mask: 0.4930  decode.loss_dice: 1.1563  decode.d0.loss_cls: 0.0721  decode.d0.loss_mask: 0.4986  decode.d0.loss_dice: 1.2552  decode.d1.loss_cls: 0.0560  decode.d1.loss_mask: 0.4703  decode.d1.loss_dice: 1.1635  decode.d2.loss_cls: 0.0606  decode.d2.loss_mask: 0.4673  decode.d2.loss_dice: 1.1469  decode.d3.loss_cls: 0.0448  decode.d3.loss_mask: 0.4771  decode.d3.loss_dice: 1.1614  decode.d4.loss_cls: 0.0553  decode.d4.loss_mask: 0.4783  decode.d4.loss_dice: 1.1637  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 0.4759  decode.d5.loss_dice: 1.1387  decode.d6.loss_cls: 0.0537  decode.d6.loss_mask: 0.5006  decode.d6.loss_dice: 1.1696  decode.d7.loss_cls: 0.0471  decode.d7.loss_mask: 0.4896  decode.d7.loss_dice: 1.1708  decode.d8.loss_cls: 0.0586  decode.d8.loss_mask: 0.4907  decode.d8.loss_dice: 1.1577
11/15 19:18:00 - mmengine - INFO - Iter(train) [71300/90000]  base_lr: 2.4313e-05 lr: 2.4313e-06  eta: 3:07:38  time: 0.6008  data_time: 0.0116  memory: 10692  grad_norm: 415.6233  loss: 15.5145  decode.loss_cls: 0.0495  decode.loss_mask: 0.4512  decode.loss_dice: 1.0228  decode.d0.loss_cls: 0.0732  decode.d0.loss_mask: 0.4760  decode.d0.loss_dice: 1.0973  decode.d1.loss_cls: 0.0590  decode.d1.loss_mask: 0.4549  decode.d1.loss_dice: 1.0392  decode.d2.loss_cls: 0.0413  decode.d2.loss_mask: 0.4571  decode.d2.loss_dice: 1.0345  decode.d3.loss_cls: 0.0364  decode.d3.loss_mask: 0.4714  decode.d3.loss_dice: 1.0340  decode.d4.loss_cls: 0.0467  decode.d4.loss_mask: 0.4679  decode.d4.loss_dice: 1.0414  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.4669  decode.d5.loss_dice: 1.0346  decode.d6.loss_cls: 0.0504  decode.d6.loss_mask: 0.4608  decode.d6.loss_dice: 1.0283  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.4657  decode.d7.loss_dice: 1.0512  decode.d8.loss_cls: 0.0471  decode.d8.loss_mask: 0.4523  decode.d8.loss_dice: 1.0113
11/15 19:18:30 - mmengine - INFO - Iter(train) [71350/90000]  base_lr: 2.4255e-05 lr: 2.4255e-06  eta: 3:07:08  time: 0.5986  data_time: 0.0105  memory: 10656  grad_norm: 445.0683  loss: 18.5219  decode.loss_cls: 0.0656  decode.loss_mask: 0.6104  decode.loss_dice: 1.1574  decode.d0.loss_cls: 0.0744  decode.d0.loss_mask: 0.6664  decode.d0.loss_dice: 1.2935  decode.d1.loss_cls: 0.0815  decode.d1.loss_mask: 0.6272  decode.d1.loss_dice: 1.1770  decode.d2.loss_cls: 0.0808  decode.d2.loss_mask: 0.6204  decode.d2.loss_dice: 1.1667  decode.d3.loss_cls: 0.0585  decode.d3.loss_mask: 0.6167  decode.d3.loss_dice: 1.1402  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.6142  decode.d4.loss_dice: 1.1608  decode.d5.loss_cls: 0.0659  decode.d5.loss_mask: 0.6147  decode.d5.loss_dice: 1.1184  decode.d6.loss_cls: 0.0708  decode.d6.loss_mask: 0.6113  decode.d6.loss_dice: 1.1006  decode.d7.loss_cls: 0.0609  decode.d7.loss_mask: 0.6126  decode.d7.loss_dice: 1.1709  decode.d8.loss_cls: 0.0699  decode.d8.loss_mask: 0.6143  decode.d8.loss_dice: 1.1371
11/15 19:19:00 - mmengine - INFO - Iter(train) [71400/90000]  base_lr: 2.4196e-05 lr: 2.4196e-06  eta: 3:06:37  time: 0.6163  data_time: 0.0282  memory: 10656  grad_norm: 843.3011  loss: 14.0763  decode.loss_cls: 0.0620  decode.loss_mask: 0.4465  decode.loss_dice: 0.8767  decode.d0.loss_cls: 0.0803  decode.d0.loss_mask: 0.4976  decode.d0.loss_dice: 0.9341  decode.d1.loss_cls: 0.0739  decode.d1.loss_mask: 0.4777  decode.d1.loss_dice: 0.8823  decode.d2.loss_cls: 0.0697  decode.d2.loss_mask: 0.4756  decode.d2.loss_dice: 0.8811  decode.d3.loss_cls: 0.0602  decode.d3.loss_mask: 0.4574  decode.d3.loss_dice: 0.8781  decode.d4.loss_cls: 0.0744  decode.d4.loss_mask: 0.4708  decode.d4.loss_dice: 0.8565  decode.d5.loss_cls: 0.0682  decode.d5.loss_mask: 0.4565  decode.d5.loss_dice: 0.8641  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.4510  decode.d6.loss_dice: 0.8651  decode.d7.loss_cls: 0.0678  decode.d7.loss_mask: 0.4533  decode.d7.loss_dice: 0.8555  decode.d8.loss_cls: 0.0664  decode.d8.loss_mask: 0.4502  decode.d8.loss_dice: 0.8514
11/15 19:19:30 - mmengine - INFO - Iter(train) [71450/90000]  base_lr: 2.4138e-05 lr: 2.4138e-06  eta: 3:06:07  time: 0.5995  data_time: 0.0107  memory: 10692  grad_norm: 235.4797  loss: 15.7272  decode.loss_cls: 0.0505  decode.loss_mask: 0.4961  decode.loss_dice: 1.0259  decode.d0.loss_cls: 0.0866  decode.d0.loss_mask: 0.5173  decode.d0.loss_dice: 1.1068  decode.d1.loss_cls: 0.0674  decode.d1.loss_mask: 0.4934  decode.d1.loss_dice: 1.0236  decode.d2.loss_cls: 0.0523  decode.d2.loss_mask: 0.4879  decode.d2.loss_dice: 1.0006  decode.d3.loss_cls: 0.0467  decode.d3.loss_mask: 0.4904  decode.d3.loss_dice: 1.0051  decode.d4.loss_cls: 0.0494  decode.d4.loss_mask: 0.4895  decode.d4.loss_dice: 1.0163  decode.d5.loss_cls: 0.0492  decode.d5.loss_mask: 0.4914  decode.d5.loss_dice: 1.0057  decode.d6.loss_cls: 0.0420  decode.d6.loss_mask: 0.4874  decode.d6.loss_dice: 1.0319  decode.d7.loss_cls: 0.0444  decode.d7.loss_mask: 0.4902  decode.d7.loss_dice: 1.0107  decode.d8.loss_cls: 0.0445  decode.d8.loss_mask: 0.4949  decode.d8.loss_dice: 1.0288
11/15 19:20:00 - mmengine - INFO - Iter(train) [71500/90000]  base_lr: 2.4079e-05 lr: 2.4079e-06  eta: 3:05:37  time: 0.5992  data_time: 0.0106  memory: 10728  grad_norm: 229.3955  loss: 14.0336  decode.loss_cls: 0.0483  decode.loss_mask: 0.4362  decode.loss_dice: 0.8920  decode.d0.loss_cls: 0.0693  decode.d0.loss_mask: 0.4701  decode.d0.loss_dice: 1.0185  decode.d1.loss_cls: 0.0617  decode.d1.loss_mask: 0.4372  decode.d1.loss_dice: 0.9216  decode.d2.loss_cls: 0.0597  decode.d2.loss_mask: 0.4321  decode.d2.loss_dice: 0.8875  decode.d3.loss_cls: 0.0532  decode.d3.loss_mask: 0.4326  decode.d3.loss_dice: 0.8972  decode.d4.loss_cls: 0.0457  decode.d4.loss_mask: 0.4319  decode.d4.loss_dice: 0.9075  decode.d5.loss_cls: 0.0528  decode.d5.loss_mask: 0.4406  decode.d5.loss_dice: 0.9034  decode.d6.loss_cls: 0.0539  decode.d6.loss_mask: 0.4421  decode.d6.loss_dice: 0.8842  decode.d7.loss_cls: 0.0516  decode.d7.loss_mask: 0.4384  decode.d7.loss_dice: 0.8958  decode.d8.loss_cls: 0.0506  decode.d8.loss_mask: 0.4364  decode.d8.loss_dice: 0.8816
11/15 19:20:31 - mmengine - INFO - Iter(train) [71550/90000]  base_lr: 2.4021e-05 lr: 2.4021e-06  eta: 3:05:07  time: 0.6702  data_time: 0.0108  memory: 10675  grad_norm: 562.0115  loss: 15.7463  decode.loss_cls: 0.0348  decode.loss_mask: 0.4686  decode.loss_dice: 1.0415  decode.d0.loss_cls: 0.0704  decode.d0.loss_mask: 0.4961  decode.d0.loss_dice: 1.1040  decode.d1.loss_cls: 0.0427  decode.d1.loss_mask: 0.4680  decode.d1.loss_dice: 1.0676  decode.d2.loss_cls: 0.0369  decode.d2.loss_mask: 0.4716  decode.d2.loss_dice: 1.0633  decode.d3.loss_cls: 0.0343  decode.d3.loss_mask: 0.4699  decode.d3.loss_dice: 1.0522  decode.d4.loss_cls: 0.0464  decode.d4.loss_mask: 0.4721  decode.d4.loss_dice: 1.0627  decode.d5.loss_cls: 0.0369  decode.d5.loss_mask: 0.4714  decode.d5.loss_dice: 1.0580  decode.d6.loss_cls: 0.0339  decode.d6.loss_mask: 0.4716  decode.d6.loss_dice: 1.0638  decode.d7.loss_cls: 0.0406  decode.d7.loss_mask: 0.4706  decode.d7.loss_dice: 1.0504  decode.d8.loss_cls: 0.0273  decode.d8.loss_mask: 0.4716  decode.d8.loss_dice: 1.0470
11/15 19:21:01 - mmengine - INFO - Iter(train) [71600/90000]  base_lr: 2.3962e-05 lr: 2.3962e-06  eta: 3:04:37  time: 0.5992  data_time: 0.0107  memory: 10692  grad_norm: 354.8259  loss: 15.0276  decode.loss_cls: 0.0687  decode.loss_mask: 0.4055  decode.loss_dice: 1.0358  decode.d0.loss_cls: 0.0840  decode.d0.loss_mask: 0.4451  decode.d0.loss_dice: 1.1488  decode.d1.loss_cls: 0.0756  decode.d1.loss_mask: 0.4060  decode.d1.loss_dice: 1.0430  decode.d2.loss_cls: 0.0750  decode.d2.loss_mask: 0.4064  decode.d2.loss_dice: 1.0205  decode.d3.loss_cls: 0.0710  decode.d3.loss_mask: 0.3963  decode.d3.loss_dice: 1.0178  decode.d4.loss_cls: 0.0699  decode.d4.loss_mask: 0.4017  decode.d4.loss_dice: 0.9781  decode.d5.loss_cls: 0.0655  decode.d5.loss_mask: 0.4036  decode.d5.loss_dice: 1.0095  decode.d6.loss_cls: 0.0770  decode.d6.loss_mask: 0.3967  decode.d6.loss_dice: 0.9779  decode.d7.loss_cls: 0.0842  decode.d7.loss_mask: 0.3989  decode.d7.loss_dice: 0.9990  decode.d8.loss_cls: 0.0722  decode.d8.loss_mask: 0.3984  decode.d8.loss_dice: 0.9954
11/15 19:21:31 - mmengine - INFO - Iter(train) [71650/90000]  base_lr: 2.3903e-05 lr: 2.3903e-06  eta: 3:04:07  time: 0.6008  data_time: 0.0109  memory: 10728  grad_norm: 343.7085  loss: 15.3866  decode.loss_cls: 0.0460  decode.loss_mask: 0.4741  decode.loss_dice: 0.9682  decode.d0.loss_cls: 0.0735  decode.d0.loss_mask: 0.5033  decode.d0.loss_dice: 1.0882  decode.d1.loss_cls: 0.0477  decode.d1.loss_mask: 0.4858  decode.d1.loss_dice: 1.0318  decode.d2.loss_cls: 0.0434  decode.d2.loss_mask: 0.4818  decode.d2.loss_dice: 1.0207  decode.d3.loss_cls: 0.0384  decode.d3.loss_mask: 0.4874  decode.d3.loss_dice: 0.9778  decode.d4.loss_cls: 0.0472  decode.d4.loss_mask: 0.4869  decode.d4.loss_dice: 1.0033  decode.d5.loss_cls: 0.0485  decode.d5.loss_mask: 0.4804  decode.d5.loss_dice: 1.0054  decode.d6.loss_cls: 0.0425  decode.d6.loss_mask: 0.4767  decode.d6.loss_dice: 0.9959  decode.d7.loss_cls: 0.0387  decode.d7.loss_mask: 0.4854  decode.d7.loss_dice: 0.9916  decode.d8.loss_cls: 0.0363  decode.d8.loss_mask: 0.4850  decode.d8.loss_dice: 0.9947
11/15 19:22:01 - mmengine - INFO - Iter(train) [71700/90000]  base_lr: 2.3845e-05 lr: 2.3845e-06  eta: 3:03:37  time: 0.5990  data_time: 0.0109  memory: 10692  grad_norm: 317.4701  loss: 14.0144  decode.loss_cls: 0.0686  decode.loss_mask: 0.4321  decode.loss_dice: 0.8762  decode.d0.loss_cls: 0.1098  decode.d0.loss_mask: 0.4535  decode.d0.loss_dice: 0.9552  decode.d1.loss_cls: 0.0606  decode.d1.loss_mask: 0.4539  decode.d1.loss_dice: 0.9145  decode.d2.loss_cls: 0.0680  decode.d2.loss_mask: 0.4503  decode.d2.loss_dice: 0.8957  decode.d3.loss_cls: 0.0767  decode.d3.loss_mask: 0.4343  decode.d3.loss_dice: 0.8799  decode.d4.loss_cls: 0.0726  decode.d4.loss_mask: 0.4362  decode.d4.loss_dice: 0.8746  decode.d5.loss_cls: 0.0717  decode.d5.loss_mask: 0.4328  decode.d5.loss_dice: 0.8726  decode.d6.loss_cls: 0.0720  decode.d6.loss_mask: 0.4256  decode.d6.loss_dice: 0.8970  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.4245  decode.d7.loss_dice: 0.8666  decode.d8.loss_cls: 0.0720  decode.d8.loss_mask: 0.4308  decode.d8.loss_dice: 0.8662
11/15 19:22:31 - mmengine - INFO - Iter(train) [71750/90000]  base_lr: 2.3786e-05 lr: 2.3786e-06  eta: 3:03:07  time: 0.5995  data_time: 0.0104  memory: 10713  grad_norm: 254.1977  loss: 15.6148  decode.loss_cls: 0.0759  decode.loss_mask: 0.4107  decode.loss_dice: 1.0299  decode.d0.loss_cls: 0.0995  decode.d0.loss_mask: 0.4225  decode.d0.loss_dice: 1.1269  decode.d1.loss_cls: 0.0793  decode.d1.loss_mask: 0.4107  decode.d1.loss_dice: 1.1163  decode.d2.loss_cls: 0.0843  decode.d2.loss_mask: 0.4080  decode.d2.loss_dice: 1.0707  decode.d3.loss_cls: 0.0699  decode.d3.loss_mask: 0.4148  decode.d3.loss_dice: 1.0549  decode.d4.loss_cls: 0.0860  decode.d4.loss_mask: 0.4101  decode.d4.loss_dice: 1.0589  decode.d5.loss_cls: 0.0725  decode.d5.loss_mask: 0.4078  decode.d5.loss_dice: 1.0662  decode.d6.loss_cls: 0.0748  decode.d6.loss_mask: 0.4102  decode.d6.loss_dice: 1.0335  decode.d7.loss_cls: 0.0687  decode.d7.loss_mask: 0.4138  decode.d7.loss_dice: 1.0825  decode.d8.loss_cls: 0.0832  decode.d8.loss_mask: 0.4122  decode.d8.loss_dice: 1.0601
11/15 19:23:01 - mmengine - INFO - Iter(train) [71800/90000]  base_lr: 2.3727e-05 lr: 2.3727e-06  eta: 3:02:37  time: 0.6022  data_time: 0.0108  memory: 10713  grad_norm: 307.1487  loss: 16.3622  decode.loss_cls: 0.0495  decode.loss_mask: 0.5692  decode.loss_dice: 1.0307  decode.d0.loss_cls: 0.0805  decode.d0.loss_mask: 0.5798  decode.d0.loss_dice: 1.0695  decode.d1.loss_cls: 0.0584  decode.d1.loss_mask: 0.5577  decode.d1.loss_dice: 1.0479  decode.d2.loss_cls: 0.0542  decode.d2.loss_mask: 0.5507  decode.d2.loss_dice: 1.0253  decode.d3.loss_cls: 0.0487  decode.d3.loss_mask: 0.5467  decode.d3.loss_dice: 1.0093  decode.d4.loss_cls: 0.0474  decode.d4.loss_mask: 0.5481  decode.d4.loss_dice: 1.0421  decode.d5.loss_cls: 0.0578  decode.d5.loss_mask: 0.5513  decode.d5.loss_dice: 1.0171  decode.d6.loss_cls: 0.0533  decode.d6.loss_mask: 0.5434  decode.d6.loss_dice: 0.9966  decode.d7.loss_cls: 0.0580  decode.d7.loss_mask: 0.5380  decode.d7.loss_dice: 1.0025  decode.d8.loss_cls: 0.0474  decode.d8.loss_mask: 0.5502  decode.d8.loss_dice: 1.0309
11/15 19:23:31 - mmengine - INFO - Iter(train) [71850/90000]  base_lr: 2.3669e-05 lr: 2.3669e-06  eta: 3:02:06  time: 0.5981  data_time: 0.0105  memory: 10675  grad_norm: 727.6592  loss: 16.4271  decode.loss_cls: 0.0475  decode.loss_mask: 0.5619  decode.loss_dice: 1.0199  decode.d0.loss_cls: 0.0702  decode.d0.loss_mask: 0.5809  decode.d0.loss_dice: 1.0854  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.5729  decode.d1.loss_dice: 1.0637  decode.d2.loss_cls: 0.0431  decode.d2.loss_mask: 0.5632  decode.d2.loss_dice: 1.0184  decode.d3.loss_cls: 0.0445  decode.d3.loss_mask: 0.5515  decode.d3.loss_dice: 0.9984  decode.d4.loss_cls: 0.0454  decode.d4.loss_mask: 0.5497  decode.d4.loss_dice: 1.0260  decode.d5.loss_cls: 0.0441  decode.d5.loss_mask: 0.5648  decode.d5.loss_dice: 1.0381  decode.d6.loss_cls: 0.0484  decode.d6.loss_mask: 0.5397  decode.d6.loss_dice: 1.0202  decode.d7.loss_cls: 0.0527  decode.d7.loss_mask: 0.5608  decode.d7.loss_dice: 1.0426  decode.d8.loss_cls: 0.0527  decode.d8.loss_mask: 0.5592  decode.d8.loss_dice: 1.0067
11/15 19:24:01 - mmengine - INFO - Iter(train) [71900/90000]  base_lr: 2.3610e-05 lr: 2.3610e-06  eta: 3:01:36  time: 0.5974  data_time: 0.0105  memory: 10692  grad_norm: 374.0609  loss: 15.8736  decode.loss_cls: 0.0443  decode.loss_mask: 0.4682  decode.loss_dice: 1.0730  decode.d0.loss_cls: 0.0696  decode.d0.loss_mask: 0.4682  decode.d0.loss_dice: 1.1158  decode.d1.loss_cls: 0.0480  decode.d1.loss_mask: 0.4583  decode.d1.loss_dice: 1.0937  decode.d2.loss_cls: 0.0357  decode.d2.loss_mask: 0.4597  decode.d2.loss_dice: 1.0810  decode.d3.loss_cls: 0.0350  decode.d3.loss_mask: 0.4621  decode.d3.loss_dice: 1.0654  decode.d4.loss_cls: 0.0489  decode.d4.loss_mask: 0.4653  decode.d4.loss_dice: 1.0813  decode.d5.loss_cls: 0.0385  decode.d5.loss_mask: 0.4653  decode.d5.loss_dice: 1.0626  decode.d6.loss_cls: 0.0391  decode.d6.loss_mask: 0.4683  decode.d6.loss_dice: 1.0815  decode.d7.loss_cls: 0.0409  decode.d7.loss_mask: 0.4678  decode.d7.loss_dice: 1.0694  decode.d8.loss_cls: 0.0365  decode.d8.loss_mask: 0.4687  decode.d8.loss_dice: 1.0616
11/15 19:24:31 - mmengine - INFO - Iter(train) [71950/90000]  base_lr: 2.3551e-05 lr: 2.3551e-06  eta: 3:01:06  time: 0.5981  data_time: 0.0106  memory: 10692  grad_norm: 429.7399  loss: 16.1928  decode.loss_cls: 0.0550  decode.loss_mask: 0.5062  decode.loss_dice: 1.0374  decode.d0.loss_cls: 0.0852  decode.d0.loss_mask: 0.5441  decode.d0.loss_dice: 1.0854  decode.d1.loss_cls: 0.0702  decode.d1.loss_mask: 0.5232  decode.d1.loss_dice: 1.0407  decode.d2.loss_cls: 0.0531  decode.d2.loss_mask: 0.5302  decode.d2.loss_dice: 1.0517  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 0.5147  decode.d3.loss_dice: 1.0206  decode.d4.loss_cls: 0.0655  decode.d4.loss_mask: 0.5041  decode.d4.loss_dice: 1.0091  decode.d5.loss_cls: 0.0582  decode.d5.loss_mask: 0.5299  decode.d5.loss_dice: 1.0189  decode.d6.loss_cls: 0.0601  decode.d6.loss_mask: 0.5068  decode.d6.loss_dice: 1.0403  decode.d7.loss_cls: 0.0516  decode.d7.loss_mask: 0.5224  decode.d7.loss_dice: 1.0397  decode.d8.loss_cls: 0.0615  decode.d8.loss_mask: 0.5181  decode.d8.loss_dice: 1.0278
11/15 19:25:01 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 19:25:01 - mmengine - INFO - Iter(train) [72000/90000]  base_lr: 2.3493e-05 lr: 2.3493e-06  eta: 3:00:36  time: 0.5991  data_time: 0.0105  memory: 10713  grad_norm: 653.4957  loss: 17.4288  decode.loss_cls: 0.0564  decode.loss_mask: 0.5245  decode.loss_dice: 1.1329  decode.d0.loss_cls: 0.0857  decode.d0.loss_mask: 0.5376  decode.d0.loss_dice: 1.1893  decode.d1.loss_cls: 0.0654  decode.d1.loss_mask: 0.5409  decode.d1.loss_dice: 1.1826  decode.d2.loss_cls: 0.0689  decode.d2.loss_mask: 0.5388  decode.d2.loss_dice: 1.1436  decode.d3.loss_cls: 0.0626  decode.d3.loss_mask: 0.4968  decode.d3.loss_dice: 1.1161  decode.d4.loss_cls: 0.0655  decode.d4.loss_mask: 0.5275  decode.d4.loss_dice: 1.1333  decode.d5.loss_cls: 0.0798  decode.d5.loss_mask: 0.5393  decode.d5.loss_dice: 1.1455  decode.d6.loss_cls: 0.0591  decode.d6.loss_mask: 0.5323  decode.d6.loss_dice: 1.1198  decode.d7.loss_cls: 0.0635  decode.d7.loss_mask: 0.5269  decode.d7.loss_dice: 1.1710  decode.d8.loss_cls: 0.0641  decode.d8.loss_mask: 0.5262  decode.d8.loss_dice: 1.1330
11/15 19:25:31 - mmengine - INFO - Iter(train) [72050/90000]  base_lr: 2.3434e-05 lr: 2.3434e-06  eta: 3:00:06  time: 0.5988  data_time: 0.0109  memory: 10692  grad_norm: 242.7468  loss: 15.5723  decode.loss_cls: 0.0568  decode.loss_mask: 0.5161  decode.loss_dice: 0.9724  decode.d0.loss_cls: 0.0811  decode.d0.loss_mask: 0.5212  decode.d0.loss_dice: 1.0524  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.5103  decode.d1.loss_dice: 1.0075  decode.d2.loss_cls: 0.0601  decode.d2.loss_mask: 0.5046  decode.d2.loss_dice: 0.9930  decode.d3.loss_cls: 0.0575  decode.d3.loss_mask: 0.5070  decode.d3.loss_dice: 0.9645  decode.d4.loss_cls: 0.0560  decode.d4.loss_mask: 0.5068  decode.d4.loss_dice: 0.9591  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.5105  decode.d5.loss_dice: 0.9885  decode.d6.loss_cls: 0.0531  decode.d6.loss_mask: 0.5077  decode.d6.loss_dice: 0.9825  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 0.5088  decode.d7.loss_dice: 0.9653  decode.d8.loss_cls: 0.0637  decode.d8.loss_mask: 0.5075  decode.d8.loss_dice: 0.9769
11/15 19:26:01 - mmengine - INFO - Iter(train) [72100/90000]  base_lr: 2.3375e-05 lr: 2.3375e-06  eta: 2:59:36  time: 0.5984  data_time: 0.0107  memory: 10656  grad_norm: 396.4257  loss: 15.3520  decode.loss_cls: 0.0522  decode.loss_mask: 0.4683  decode.loss_dice: 0.9775  decode.d0.loss_cls: 0.0779  decode.d0.loss_mask: 0.5188  decode.d0.loss_dice: 1.0344  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.5147  decode.d1.loss_dice: 0.9983  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.4951  decode.d2.loss_dice: 1.0055  decode.d3.loss_cls: 0.0583  decode.d3.loss_mask: 0.4852  decode.d3.loss_dice: 1.0003  decode.d4.loss_cls: 0.0629  decode.d4.loss_mask: 0.4892  decode.d4.loss_dice: 0.9809  decode.d5.loss_cls: 0.0442  decode.d5.loss_mask: 0.4875  decode.d5.loss_dice: 0.9943  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.4756  decode.d6.loss_dice: 0.9846  decode.d7.loss_cls: 0.0538  decode.d7.loss_mask: 0.4638  decode.d7.loss_dice: 0.9808  decode.d8.loss_cls: 0.0531  decode.d8.loss_mask: 0.4797  decode.d8.loss_dice: 0.9717
11/15 19:26:31 - mmengine - INFO - Iter(train) [72150/90000]  base_lr: 2.3316e-05 lr: 2.3316e-06  eta: 2:59:06  time: 0.6015  data_time: 0.0107  memory: 10692  grad_norm: 614.0811  loss: 15.5955  decode.loss_cls: 0.0447  decode.loss_mask: 0.5153  decode.loss_dice: 0.9764  decode.d0.loss_cls: 0.0720  decode.d0.loss_mask: 0.5248  decode.d0.loss_dice: 1.0305  decode.d1.loss_cls: 0.0399  decode.d1.loss_mask: 0.5187  decode.d1.loss_dice: 1.0460  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.5175  decode.d2.loss_dice: 0.9994  decode.d3.loss_cls: 0.0392  decode.d3.loss_mask: 0.5208  decode.d3.loss_dice: 0.9921  decode.d4.loss_cls: 0.0499  decode.d4.loss_mask: 0.5075  decode.d4.loss_dice: 0.9716  decode.d5.loss_cls: 0.0432  decode.d5.loss_mask: 0.5134  decode.d5.loss_dice: 0.9757  decode.d6.loss_cls: 0.0460  decode.d6.loss_mask: 0.5123  decode.d6.loss_dice: 0.9664  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.5129  decode.d7.loss_dice: 0.9924  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.5242  decode.d8.loss_dice: 1.0080
11/15 19:27:01 - mmengine - INFO - Iter(train) [72200/90000]  base_lr: 2.3258e-05 lr: 2.3258e-06  eta: 2:58:36  time: 0.5985  data_time: 0.0105  memory: 10656  grad_norm: 444.2655  loss: 16.5114  decode.loss_cls: 0.0792  decode.loss_mask: 0.5322  decode.loss_dice: 1.0059  decode.d0.loss_cls: 0.1029  decode.d0.loss_mask: 0.5848  decode.d0.loss_dice: 1.1260  decode.d1.loss_cls: 0.0688  decode.d1.loss_mask: 0.5480  decode.d1.loss_dice: 1.0611  decode.d2.loss_cls: 0.0941  decode.d2.loss_mask: 0.5337  decode.d2.loss_dice: 1.0048  decode.d3.loss_cls: 0.0781  decode.d3.loss_mask: 0.5476  decode.d3.loss_dice: 0.9926  decode.d4.loss_cls: 0.0950  decode.d4.loss_mask: 0.5371  decode.d4.loss_dice: 0.9989  decode.d5.loss_cls: 0.0773  decode.d5.loss_mask: 0.5411  decode.d5.loss_dice: 1.0116  decode.d6.loss_cls: 0.0808  decode.d6.loss_mask: 0.5359  decode.d6.loss_dice: 0.9998  decode.d7.loss_cls: 0.0854  decode.d7.loss_mask: 0.5346  decode.d7.loss_dice: 1.0164  decode.d8.loss_cls: 0.0804  decode.d8.loss_mask: 0.5386  decode.d8.loss_dice: 1.0190
11/15 19:27:32 - mmengine - INFO - Iter(train) [72250/90000]  base_lr: 2.3199e-05 lr: 2.3199e-06  eta: 2:58:06  time: 0.6040  data_time: 0.0106  memory: 10758  grad_norm: 529.6180  loss: 15.0890  decode.loss_cls: 0.0617  decode.loss_mask: 0.4444  decode.loss_dice: 0.9637  decode.d0.loss_cls: 0.0978  decode.d0.loss_mask: 0.4971  decode.d0.loss_dice: 1.1104  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.4775  decode.d1.loss_dice: 1.0261  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.4605  decode.d2.loss_dice: 0.9912  decode.d3.loss_cls: 0.0549  decode.d3.loss_mask: 0.4472  decode.d3.loss_dice: 0.9608  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.4481  decode.d4.loss_dice: 0.9280  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.4438  decode.d5.loss_dice: 0.9887  decode.d6.loss_cls: 0.0596  decode.d6.loss_mask: 0.4425  decode.d6.loss_dice: 0.9815  decode.d7.loss_cls: 0.0682  decode.d7.loss_mask: 0.4485  decode.d7.loss_dice: 0.9534  decode.d8.loss_cls: 0.0590  decode.d8.loss_mask: 0.4465  decode.d8.loss_dice: 0.9720
11/15 19:28:02 - mmengine - INFO - Iter(train) [72300/90000]  base_lr: 2.3140e-05 lr: 2.3140e-06  eta: 2:57:35  time: 0.5993  data_time: 0.0108  memory: 10728  grad_norm: 353.3158  loss: 16.5071  decode.loss_cls: 0.0847  decode.loss_mask: 0.4543  decode.loss_dice: 1.0525  decode.d0.loss_cls: 0.1171  decode.d0.loss_mask: 0.4774  decode.d0.loss_dice: 1.1584  decode.d1.loss_cls: 0.1161  decode.d1.loss_mask: 0.4465  decode.d1.loss_dice: 1.0813  decode.d2.loss_cls: 0.0883  decode.d2.loss_mask: 0.4517  decode.d2.loss_dice: 1.1180  decode.d3.loss_cls: 0.0970  decode.d3.loss_mask: 0.4632  decode.d3.loss_dice: 1.0592  decode.d4.loss_cls: 0.0785  decode.d4.loss_mask: 0.4862  decode.d4.loss_dice: 1.0933  decode.d5.loss_cls: 0.0803  decode.d5.loss_mask: 0.4905  decode.d5.loss_dice: 1.0911  decode.d6.loss_cls: 0.0776  decode.d6.loss_mask: 0.4660  decode.d6.loss_dice: 1.0927  decode.d7.loss_cls: 0.0785  decode.d7.loss_mask: 0.4559  decode.d7.loss_dice: 1.1219  decode.d8.loss_cls: 0.0888  decode.d8.loss_mask: 0.4535  decode.d8.loss_dice: 1.0866
11/15 19:28:32 - mmengine - INFO - Iter(train) [72350/90000]  base_lr: 2.3081e-05 lr: 2.3081e-06  eta: 2:57:05  time: 0.6007  data_time: 0.0107  memory: 10656  grad_norm: 273.4261  loss: 15.9724  decode.loss_cls: 0.0596  decode.loss_mask: 0.4201  decode.loss_dice: 1.0954  decode.d0.loss_cls: 0.0871  decode.d0.loss_mask: 0.4386  decode.d0.loss_dice: 1.1760  decode.d1.loss_cls: 0.0582  decode.d1.loss_mask: 0.4247  decode.d1.loss_dice: 1.1467  decode.d2.loss_cls: 0.0613  decode.d2.loss_mask: 0.4208  decode.d2.loss_dice: 1.1144  decode.d3.loss_cls: 0.0757  decode.d3.loss_mask: 0.4186  decode.d3.loss_dice: 1.0768  decode.d4.loss_cls: 0.0694  decode.d4.loss_mask: 0.4156  decode.d4.loss_dice: 1.0888  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.4167  decode.d5.loss_dice: 1.0770  decode.d6.loss_cls: 0.0672  decode.d6.loss_mask: 0.4186  decode.d6.loss_dice: 1.0929  decode.d7.loss_cls: 0.0575  decode.d7.loss_mask: 0.4186  decode.d7.loss_dice: 1.1246  decode.d8.loss_cls: 0.0622  decode.d8.loss_mask: 0.4202  decode.d8.loss_dice: 1.1074
11/15 19:29:02 - mmengine - INFO - Iter(train) [72400/90000]  base_lr: 2.3022e-05 lr: 2.3022e-06  eta: 2:56:35  time: 0.6030  data_time: 0.0108  memory: 10728  grad_norm: 258.0633  loss: 16.6257  decode.loss_cls: 0.0717  decode.loss_mask: 0.4811  decode.loss_dice: 1.1067  decode.d0.loss_cls: 0.1118  decode.d0.loss_mask: 0.5085  decode.d0.loss_dice: 1.1667  decode.d1.loss_cls: 0.0897  decode.d1.loss_mask: 0.4632  decode.d1.loss_dice: 1.1401  decode.d2.loss_cls: 0.0811  decode.d2.loss_mask: 0.4698  decode.d2.loss_dice: 1.1150  decode.d3.loss_cls: 0.0796  decode.d3.loss_mask: 0.4634  decode.d3.loss_dice: 1.1040  decode.d4.loss_cls: 0.0755  decode.d4.loss_mask: 0.4690  decode.d4.loss_dice: 1.1266  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.4588  decode.d5.loss_dice: 1.0911  decode.d6.loss_cls: 0.0729  decode.d6.loss_mask: 0.4567  decode.d6.loss_dice: 1.0912  decode.d7.loss_cls: 0.0751  decode.d7.loss_mask: 0.4492  decode.d7.loss_dice: 1.1157  decode.d8.loss_cls: 0.0766  decode.d8.loss_mask: 0.4514  decode.d8.loss_dice: 1.0844
11/15 19:29:32 - mmengine - INFO - Iter(train) [72450/90000]  base_lr: 2.2963e-05 lr: 2.2963e-06  eta: 2:56:05  time: 0.5979  data_time: 0.0106  memory: 10692  grad_norm: 751.2320  loss: 15.3610  decode.loss_cls: 0.0365  decode.loss_mask: 0.4845  decode.loss_dice: 0.9825  decode.d0.loss_cls: 0.0624  decode.d0.loss_mask: 0.5479  decode.d0.loss_dice: 1.0856  decode.d1.loss_cls: 0.0388  decode.d1.loss_mask: 0.4904  decode.d1.loss_dice: 1.0348  decode.d2.loss_cls: 0.0362  decode.d2.loss_mask: 0.4765  decode.d2.loss_dice: 1.0050  decode.d3.loss_cls: 0.0275  decode.d3.loss_mask: 0.5004  decode.d3.loss_dice: 1.0088  decode.d4.loss_cls: 0.0308  decode.d4.loss_mask: 0.4898  decode.d4.loss_dice: 1.0069  decode.d5.loss_cls: 0.0261  decode.d5.loss_mask: 0.4896  decode.d5.loss_dice: 1.0002  decode.d6.loss_cls: 0.0309  decode.d6.loss_mask: 0.4842  decode.d6.loss_dice: 1.0021  decode.d7.loss_cls: 0.0317  decode.d7.loss_mask: 0.4807  decode.d7.loss_dice: 0.9964  decode.d8.loss_cls: 0.0345  decode.d8.loss_mask: 0.4645  decode.d8.loss_dice: 0.9749
11/15 19:30:02 - mmengine - INFO - Iter(train) [72500/90000]  base_lr: 2.2904e-05 lr: 2.2904e-06  eta: 2:55:35  time: 0.5993  data_time: 0.0108  memory: 10656  grad_norm: 237.5728  loss: 14.6809  decode.loss_cls: 0.0402  decode.loss_mask: 0.4229  decode.loss_dice: 1.0015  decode.d0.loss_cls: 0.0837  decode.d0.loss_mask: 0.4356  decode.d0.loss_dice: 1.0427  decode.d1.loss_cls: 0.0473  decode.d1.loss_mask: 0.4276  decode.d1.loss_dice: 1.0107  decode.d2.loss_cls: 0.0468  decode.d2.loss_mask: 0.4207  decode.d2.loss_dice: 0.9921  decode.d3.loss_cls: 0.0427  decode.d3.loss_mask: 0.4237  decode.d3.loss_dice: 0.9753  decode.d4.loss_cls: 0.0455  decode.d4.loss_mask: 0.4183  decode.d4.loss_dice: 0.9674  decode.d5.loss_cls: 0.0453  decode.d5.loss_mask: 0.4207  decode.d5.loss_dice: 1.0016  decode.d6.loss_cls: 0.0406  decode.d6.loss_mask: 0.4172  decode.d6.loss_dice: 0.9841  decode.d7.loss_cls: 0.0416  decode.d7.loss_mask: 0.4236  decode.d7.loss_dice: 1.0074  decode.d8.loss_cls: 0.0467  decode.d8.loss_mask: 0.4243  decode.d8.loss_dice: 0.9831
11/15 19:30:32 - mmengine - INFO - Iter(train) [72550/90000]  base_lr: 2.2846e-05 lr: 2.2846e-06  eta: 2:55:05  time: 0.6019  data_time: 0.0110  memory: 10675  grad_norm: 277.4745  loss: 14.5450  decode.loss_cls: 0.0423  decode.loss_mask: 0.4396  decode.loss_dice: 0.9347  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.4465  decode.d0.loss_dice: 1.0142  decode.d1.loss_cls: 0.0555  decode.d1.loss_mask: 0.4385  decode.d1.loss_dice: 0.9881  decode.d2.loss_cls: 0.0481  decode.d2.loss_mask: 0.4295  decode.d2.loss_dice: 0.9679  decode.d3.loss_cls: 0.0471  decode.d3.loss_mask: 0.4362  decode.d3.loss_dice: 0.9558  decode.d4.loss_cls: 0.0492  decode.d4.loss_mask: 0.4379  decode.d4.loss_dice: 0.9685  decode.d5.loss_cls: 0.0575  decode.d5.loss_mask: 0.4425  decode.d5.loss_dice: 0.9635  decode.d6.loss_cls: 0.0438  decode.d6.loss_mask: 0.4424  decode.d6.loss_dice: 0.9499  decode.d7.loss_cls: 0.0432  decode.d7.loss_mask: 0.4430  decode.d7.loss_dice: 0.9517  decode.d8.loss_cls: 0.0468  decode.d8.loss_mask: 0.4424  decode.d8.loss_dice: 0.9407
11/15 19:31:01 - mmengine - INFO - Iter(train) [72600/90000]  base_lr: 2.2787e-05 lr: 2.2787e-06  eta: 2:54:35  time: 0.5988  data_time: 0.0105  memory: 10676  grad_norm: 381.9226  loss: 14.9844  decode.loss_cls: 0.0283  decode.loss_mask: 0.4676  decode.loss_dice: 0.9783  decode.d0.loss_cls: 0.0718  decode.d0.loss_mask: 0.5013  decode.d0.loss_dice: 1.0124  decode.d1.loss_cls: 0.0293  decode.d1.loss_mask: 0.4758  decode.d1.loss_dice: 1.0091  decode.d2.loss_cls: 0.0333  decode.d2.loss_mask: 0.4783  decode.d2.loss_dice: 0.9917  decode.d3.loss_cls: 0.0361  decode.d3.loss_mask: 0.4703  decode.d3.loss_dice: 0.9745  decode.d4.loss_cls: 0.0362  decode.d4.loss_mask: 0.4698  decode.d4.loss_dice: 0.9880  decode.d5.loss_cls: 0.0344  decode.d5.loss_mask: 0.4694  decode.d5.loss_dice: 0.9851  decode.d6.loss_cls: 0.0280  decode.d6.loss_mask: 0.4713  decode.d6.loss_dice: 0.9978  decode.d7.loss_cls: 0.0330  decode.d7.loss_mask: 0.4684  decode.d7.loss_dice: 0.9740  decode.d8.loss_cls: 0.0316  decode.d8.loss_mask: 0.4720  decode.d8.loss_dice: 0.9674
11/15 19:31:31 - mmengine - INFO - Iter(train) [72650/90000]  base_lr: 2.2728e-05 lr: 2.2728e-06  eta: 2:54:04  time: 0.5987  data_time: 0.0108  memory: 10692  grad_norm: 335.7850  loss: 15.3266  decode.loss_cls: 0.0469  decode.loss_mask: 0.4648  decode.loss_dice: 1.0180  decode.d0.loss_cls: 0.0876  decode.d0.loss_mask: 0.4858  decode.d0.loss_dice: 1.0672  decode.d1.loss_cls: 0.0558  decode.d1.loss_mask: 0.4785  decode.d1.loss_dice: 1.0034  decode.d2.loss_cls: 0.0516  decode.d2.loss_mask: 0.4791  decode.d2.loss_dice: 1.0015  decode.d3.loss_cls: 0.0481  decode.d3.loss_mask: 0.4771  decode.d3.loss_dice: 1.0055  decode.d4.loss_cls: 0.0479  decode.d4.loss_mask: 0.4709  decode.d4.loss_dice: 0.9782  decode.d5.loss_cls: 0.0474  decode.d5.loss_mask: 0.4691  decode.d5.loss_dice: 0.9925  decode.d6.loss_cls: 0.0454  decode.d6.loss_mask: 0.4643  decode.d6.loss_dice: 0.9931  decode.d7.loss_cls: 0.0518  decode.d7.loss_mask: 0.4708  decode.d7.loss_dice: 1.0244  decode.d8.loss_cls: 0.0546  decode.d8.loss_mask: 0.4656  decode.d8.loss_dice: 0.9797
11/15 19:32:01 - mmengine - INFO - Iter(train) [72700/90000]  base_lr: 2.2669e-05 lr: 2.2669e-06  eta: 2:53:34  time: 0.5983  data_time: 0.0104  memory: 10692  grad_norm: 290.9647  loss: 17.1816  decode.loss_cls: 0.0907  decode.loss_mask: 0.5139  decode.loss_dice: 1.0857  decode.d0.loss_cls: 0.0971  decode.d0.loss_mask: 0.5508  decode.d0.loss_dice: 1.2193  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.5365  decode.d1.loss_dice: 1.1387  decode.d2.loss_cls: 0.0856  decode.d2.loss_mask: 0.5340  decode.d2.loss_dice: 1.1060  decode.d3.loss_cls: 0.0850  decode.d3.loss_mask: 0.5179  decode.d3.loss_dice: 1.0804  decode.d4.loss_cls: 0.0854  decode.d4.loss_mask: 0.5136  decode.d4.loss_dice: 1.0974  decode.d5.loss_cls: 0.0718  decode.d5.loss_mask: 0.5117  decode.d5.loss_dice: 1.1058  decode.d6.loss_cls: 0.0775  decode.d6.loss_mask: 0.5057  decode.d6.loss_dice: 1.1103  decode.d7.loss_cls: 0.0834  decode.d7.loss_mask: 0.5120  decode.d7.loss_dice: 1.0993  decode.d8.loss_cls: 0.0782  decode.d8.loss_mask: 0.5202  decode.d8.loss_dice: 1.0831
11/15 19:32:32 - mmengine - INFO - Iter(train) [72750/90000]  base_lr: 2.2610e-05 lr: 2.2610e-06  eta: 2:53:04  time: 0.6266  data_time: 0.0106  memory: 10675  grad_norm: 185.5645  loss: 14.7796  decode.loss_cls: 0.0629  decode.loss_mask: 0.3713  decode.loss_dice: 1.0510  decode.d0.loss_cls: 0.0753  decode.d0.loss_mask: 0.3784  decode.d0.loss_dice: 1.1256  decode.d1.loss_cls: 0.0653  decode.d1.loss_mask: 0.3700  decode.d1.loss_dice: 1.0658  decode.d2.loss_cls: 0.0661  decode.d2.loss_mask: 0.3687  decode.d2.loss_dice: 1.0558  decode.d3.loss_cls: 0.0705  decode.d3.loss_mask: 0.3693  decode.d3.loss_dice: 1.0089  decode.d4.loss_cls: 0.0766  decode.d4.loss_mask: 0.3723  decode.d4.loss_dice: 1.0237  decode.d5.loss_cls: 0.0729  decode.d5.loss_mask: 0.3692  decode.d5.loss_dice: 0.9945  decode.d6.loss_cls: 0.0712  decode.d6.loss_mask: 0.3732  decode.d6.loss_dice: 1.0284  decode.d7.loss_cls: 0.0723  decode.d7.loss_mask: 0.3725  decode.d7.loss_dice: 1.0211  decode.d8.loss_cls: 0.0674  decode.d8.loss_mask: 0.3670  decode.d8.loss_dice: 0.9925
11/15 19:33:02 - mmengine - INFO - Iter(train) [72800/90000]  base_lr: 2.2551e-05 lr: 2.2551e-06  eta: 2:52:34  time: 0.5982  data_time: 0.0105  memory: 10675  grad_norm: 393.4247  loss: 14.8383  decode.loss_cls: 0.0574  decode.loss_mask: 0.4348  decode.loss_dice: 0.9606  decode.d0.loss_cls: 0.0824  decode.d0.loss_mask: 0.4614  decode.d0.loss_dice: 1.0755  decode.d1.loss_cls: 0.0611  decode.d1.loss_mask: 0.4410  decode.d1.loss_dice: 0.9912  decode.d2.loss_cls: 0.0620  decode.d2.loss_mask: 0.4474  decode.d2.loss_dice: 0.9761  decode.d3.loss_cls: 0.0693  decode.d3.loss_mask: 0.4486  decode.d3.loss_dice: 0.9570  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.4397  decode.d4.loss_dice: 0.9573  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.4351  decode.d5.loss_dice: 0.9637  decode.d6.loss_cls: 0.0648  decode.d6.loss_mask: 0.4370  decode.d6.loss_dice: 0.9683  decode.d7.loss_cls: 0.0615  decode.d7.loss_mask: 0.4324  decode.d7.loss_dice: 0.9578  decode.d8.loss_cls: 0.0581  decode.d8.loss_mask: 0.4360  decode.d8.loss_dice: 0.9658
11/15 19:33:31 - mmengine - INFO - Iter(train) [72850/90000]  base_lr: 2.2492e-05 lr: 2.2492e-06  eta: 2:52:04  time: 0.5983  data_time: 0.0105  memory: 10675  grad_norm: 188.1465  loss: 15.1930  decode.loss_cls: 0.0697  decode.loss_mask: 0.4912  decode.loss_dice: 0.9622  decode.d0.loss_cls: 0.0907  decode.d0.loss_mask: 0.5068  decode.d0.loss_dice: 1.0291  decode.d1.loss_cls: 0.0716  decode.d1.loss_mask: 0.4936  decode.d1.loss_dice: 0.9748  decode.d2.loss_cls: 0.0698  decode.d2.loss_mask: 0.4871  decode.d2.loss_dice: 0.9785  decode.d3.loss_cls: 0.0632  decode.d3.loss_mask: 0.4788  decode.d3.loss_dice: 0.9365  decode.d4.loss_cls: 0.0717  decode.d4.loss_mask: 0.4845  decode.d4.loss_dice: 0.9386  decode.d5.loss_cls: 0.0712  decode.d5.loss_mask: 0.4788  decode.d5.loss_dice: 0.9481  decode.d6.loss_cls: 0.0712  decode.d6.loss_mask: 0.4883  decode.d6.loss_dice: 0.9376  decode.d7.loss_cls: 0.0694  decode.d7.loss_mask: 0.4935  decode.d7.loss_dice: 0.9267  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.4868  decode.d8.loss_dice: 0.9579
11/15 19:34:01 - mmengine - INFO - Iter(train) [72900/90000]  base_lr: 2.2433e-05 lr: 2.2433e-06  eta: 2:51:34  time: 0.6012  data_time: 0.0109  memory: 10742  grad_norm: 186.2888  loss: 13.8366  decode.loss_cls: 0.0331  decode.loss_mask: 0.3819  decode.loss_dice: 0.9393  decode.d0.loss_cls: 0.0770  decode.d0.loss_mask: 0.3794  decode.d0.loss_dice: 0.9931  decode.d1.loss_cls: 0.0507  decode.d1.loss_mask: 0.3834  decode.d1.loss_dice: 0.9777  decode.d2.loss_cls: 0.0411  decode.d2.loss_mask: 0.3818  decode.d2.loss_dice: 0.9680  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.3852  decode.d3.loss_dice: 0.9489  decode.d4.loss_cls: 0.0388  decode.d4.loss_mask: 0.3872  decode.d4.loss_dice: 0.9521  decode.d5.loss_cls: 0.0370  decode.d5.loss_mask: 0.3838  decode.d5.loss_dice: 0.9467  decode.d6.loss_cls: 0.0352  decode.d6.loss_mask: 0.3837  decode.d6.loss_dice: 0.9555  decode.d7.loss_cls: 0.0357  decode.d7.loss_mask: 0.3793  decode.d7.loss_dice: 0.9396  decode.d8.loss_cls: 0.0356  decode.d8.loss_mask: 0.3824  decode.d8.loss_dice: 0.9600
11/15 19:34:31 - mmengine - INFO - Iter(train) [72950/90000]  base_lr: 2.2374e-05 lr: 2.2374e-06  eta: 2:51:04  time: 0.5984  data_time: 0.0108  memory: 10692  grad_norm: 559.7026  loss: 16.3808  decode.loss_cls: 0.0330  decode.loss_mask: 0.5494  decode.loss_dice: 1.0219  decode.d0.loss_cls: 0.0761  decode.d0.loss_mask: 0.5844  decode.d0.loss_dice: 1.0705  decode.d1.loss_cls: 0.0519  decode.d1.loss_mask: 0.5396  decode.d1.loss_dice: 1.0444  decode.d2.loss_cls: 0.0441  decode.d2.loss_mask: 0.5450  decode.d2.loss_dice: 1.0537  decode.d3.loss_cls: 0.0420  decode.d3.loss_mask: 0.5434  decode.d3.loss_dice: 1.0332  decode.d4.loss_cls: 0.0435  decode.d4.loss_mask: 0.5484  decode.d4.loss_dice: 1.0238  decode.d5.loss_cls: 0.0362  decode.d5.loss_mask: 0.5487  decode.d5.loss_dice: 1.0479  decode.d6.loss_cls: 0.0433  decode.d6.loss_mask: 0.5529  decode.d6.loss_dice: 1.0346  decode.d7.loss_cls: 0.0343  decode.d7.loss_mask: 0.5560  decode.d7.loss_dice: 1.0549  decode.d8.loss_cls: 0.0375  decode.d8.loss_mask: 0.5481  decode.d8.loss_dice: 1.0381
11/15 19:35:01 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 19:35:01 - mmengine - INFO - Iter(train) [73000/90000]  base_lr: 2.2315e-05 lr: 2.2315e-06  eta: 2:50:34  time: 0.6018  data_time: 0.0108  memory: 10656  grad_norm: 616.1330  loss: 14.3430  decode.loss_cls: 0.0387  decode.loss_mask: 0.5060  decode.loss_dice: 0.8864  decode.d0.loss_cls: 0.0725  decode.d0.loss_mask: 0.5075  decode.d0.loss_dice: 0.9007  decode.d1.loss_cls: 0.0341  decode.d1.loss_mask: 0.5091  decode.d1.loss_dice: 0.9086  decode.d2.loss_cls: 0.0373  decode.d2.loss_mask: 0.4897  decode.d2.loss_dice: 0.8610  decode.d3.loss_cls: 0.0379  decode.d3.loss_mask: 0.5048  decode.d3.loss_dice: 0.8680  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.5186  decode.d4.loss_dice: 0.8789  decode.d5.loss_cls: 0.0365  decode.d5.loss_mask: 0.5178  decode.d5.loss_dice: 0.8815  decode.d6.loss_cls: 0.0509  decode.d6.loss_mask: 0.5095  decode.d6.loss_dice: 0.8763  decode.d7.loss_cls: 0.0472  decode.d7.loss_mask: 0.5111  decode.d7.loss_dice: 0.8793  decode.d8.loss_cls: 0.0463  decode.d8.loss_mask: 0.5038  decode.d8.loss_dice: 0.8832
11/15 19:35:31 - mmengine - INFO - Iter(train) [73050/90000]  base_lr: 2.2256e-05 lr: 2.2256e-06  eta: 2:50:03  time: 0.5989  data_time: 0.0106  memory: 10656  grad_norm: 252.4261  loss: 16.1869  decode.loss_cls: 0.0498  decode.loss_mask: 0.4960  decode.loss_dice: 1.0491  decode.d0.loss_cls: 0.0959  decode.d0.loss_mask: 0.4997  decode.d0.loss_dice: 1.1104  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.5029  decode.d1.loss_dice: 1.0797  decode.d2.loss_cls: 0.0574  decode.d2.loss_mask: 0.4940  decode.d2.loss_dice: 1.0826  decode.d3.loss_cls: 0.0486  decode.d3.loss_mask: 0.4980  decode.d3.loss_dice: 1.0489  decode.d4.loss_cls: 0.0422  decode.d4.loss_mask: 0.4977  decode.d4.loss_dice: 1.0660  decode.d5.loss_cls: 0.0555  decode.d5.loss_mask: 0.4901  decode.d5.loss_dice: 1.0686  decode.d6.loss_cls: 0.0509  decode.d6.loss_mask: 0.4967  decode.d6.loss_dice: 1.0334  decode.d7.loss_cls: 0.0530  decode.d7.loss_mask: 0.4941  decode.d7.loss_dice: 1.0658  decode.d8.loss_cls: 0.0536  decode.d8.loss_mask: 0.4918  decode.d8.loss_dice: 1.0624
11/15 19:36:01 - mmengine - INFO - Iter(train) [73100/90000]  base_lr: 2.2196e-05 lr: 2.2196e-06  eta: 2:49:33  time: 0.5985  data_time: 0.0105  memory: 10692  grad_norm: 237.2244  loss: 12.1688  decode.loss_cls: 0.0336  decode.loss_mask: 0.3446  decode.loss_dice: 0.8167  decode.d0.loss_cls: 0.0738  decode.d0.loss_mask: 0.3631  decode.d0.loss_dice: 0.9218  decode.d1.loss_cls: 0.0466  decode.d1.loss_mask: 0.3553  decode.d1.loss_dice: 0.8240  decode.d2.loss_cls: 0.0395  decode.d2.loss_mask: 0.3485  decode.d2.loss_dice: 0.8135  decode.d3.loss_cls: 0.0368  decode.d3.loss_mask: 0.3484  decode.d3.loss_dice: 0.8112  decode.d4.loss_cls: 0.0413  decode.d4.loss_mask: 0.3520  decode.d4.loss_dice: 0.8099  decode.d5.loss_cls: 0.0355  decode.d5.loss_mask: 0.3490  decode.d5.loss_dice: 0.8210  decode.d6.loss_cls: 0.0366  decode.d6.loss_mask: 0.3466  decode.d6.loss_dice: 0.8088  decode.d7.loss_cls: 0.0352  decode.d7.loss_mask: 0.3488  decode.d7.loss_dice: 0.8042  decode.d8.loss_cls: 0.0348  decode.d8.loss_mask: 0.3448  decode.d8.loss_dice: 0.8227
11/15 19:36:31 - mmengine - INFO - Iter(train) [73150/90000]  base_lr: 2.2137e-05 lr: 2.2137e-06  eta: 2:49:03  time: 0.5998  data_time: 0.0107  memory: 10675  grad_norm: 406.2085  loss: 15.3734  decode.loss_cls: 0.0580  decode.loss_mask: 0.4136  decode.loss_dice: 1.0359  decode.d0.loss_cls: 0.0867  decode.d0.loss_mask: 0.4497  decode.d0.loss_dice: 1.1212  decode.d1.loss_cls: 0.0767  decode.d1.loss_mask: 0.4224  decode.d1.loss_dice: 1.0973  decode.d2.loss_cls: 0.0563  decode.d2.loss_mask: 0.4262  decode.d2.loss_dice: 1.0669  decode.d3.loss_cls: 0.0567  decode.d3.loss_mask: 0.4183  decode.d3.loss_dice: 1.0383  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.4227  decode.d4.loss_dice: 1.0560  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.4121  decode.d5.loss_dice: 1.0202  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 0.4079  decode.d6.loss_dice: 1.0278  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 0.4103  decode.d7.loss_dice: 1.0511  decode.d8.loss_cls: 0.0573  decode.d8.loss_mask: 0.4154  decode.d8.loss_dice: 1.0240
11/15 19:37:01 - mmengine - INFO - Iter(train) [73200/90000]  base_lr: 2.2078e-05 lr: 2.2078e-06  eta: 2:48:33  time: 0.5982  data_time: 0.0107  memory: 10675  grad_norm: 229.4965  loss: 15.0348  decode.loss_cls: 0.0703  decode.loss_mask: 0.4546  decode.loss_dice: 0.9767  decode.d0.loss_cls: 0.0935  decode.d0.loss_mask: 0.4870  decode.d0.loss_dice: 1.0117  decode.d1.loss_cls: 0.0783  decode.d1.loss_mask: 0.4537  decode.d1.loss_dice: 0.9945  decode.d2.loss_cls: 0.0788  decode.d2.loss_mask: 0.4479  decode.d2.loss_dice: 0.9893  decode.d3.loss_cls: 0.0773  decode.d3.loss_mask: 0.4593  decode.d3.loss_dice: 0.9778  decode.d4.loss_cls: 0.0789  decode.d4.loss_mask: 0.4524  decode.d4.loss_dice: 0.9522  decode.d5.loss_cls: 0.0709  decode.d5.loss_mask: 0.4558  decode.d5.loss_dice: 0.9447  decode.d6.loss_cls: 0.0714  decode.d6.loss_mask: 0.4539  decode.d6.loss_dice: 0.9644  decode.d7.loss_cls: 0.0752  decode.d7.loss_mask: 0.4515  decode.d7.loss_dice: 0.9519  decode.d8.loss_cls: 0.0740  decode.d8.loss_mask: 0.4529  decode.d8.loss_dice: 0.9341
11/15 19:37:31 - mmengine - INFO - Iter(train) [73250/90000]  base_lr: 2.2019e-05 lr: 2.2019e-06  eta: 2:48:03  time: 0.6002  data_time: 0.0106  memory: 10742  grad_norm: 399.1103  loss: 14.3395  decode.loss_cls: 0.0544  decode.loss_mask: 0.3956  decode.loss_dice: 0.9498  decode.d0.loss_cls: 0.0742  decode.d0.loss_mask: 0.4112  decode.d0.loss_dice: 1.0325  decode.d1.loss_cls: 0.0502  decode.d1.loss_mask: 0.4015  decode.d1.loss_dice: 1.0442  decode.d2.loss_cls: 0.0526  decode.d2.loss_mask: 0.3957  decode.d2.loss_dice: 0.9783  decode.d3.loss_cls: 0.0490  decode.d3.loss_mask: 0.3923  decode.d3.loss_dice: 0.9614  decode.d4.loss_cls: 0.0562  decode.d4.loss_mask: 0.3982  decode.d4.loss_dice: 0.9777  decode.d5.loss_cls: 0.0562  decode.d5.loss_mask: 0.3971  decode.d5.loss_dice: 0.9510  decode.d6.loss_cls: 0.0496  decode.d6.loss_mask: 0.3973  decode.d6.loss_dice: 0.9457  decode.d7.loss_cls: 0.0547  decode.d7.loss_mask: 0.3977  decode.d7.loss_dice: 0.9752  decode.d8.loss_cls: 0.0557  decode.d8.loss_mask: 0.3978  decode.d8.loss_dice: 0.9865
11/15 19:38:01 - mmengine - INFO - Iter(train) [73300/90000]  base_lr: 2.1960e-05 lr: 2.1960e-06  eta: 2:47:33  time: 0.6029  data_time: 0.0109  memory: 10675  grad_norm: 309.0939  loss: 15.1048  decode.loss_cls: 0.0597  decode.loss_mask: 0.4937  decode.loss_dice: 0.9234  decode.d0.loss_cls: 0.1004  decode.d0.loss_mask: 0.5349  decode.d0.loss_dice: 1.0479  decode.d1.loss_cls: 0.0679  decode.d1.loss_mask: 0.5039  decode.d1.loss_dice: 0.9515  decode.d2.loss_cls: 0.0645  decode.d2.loss_mask: 0.4923  decode.d2.loss_dice: 0.9415  decode.d3.loss_cls: 0.0590  decode.d3.loss_mask: 0.4926  decode.d3.loss_dice: 0.9401  decode.d4.loss_cls: 0.0592  decode.d4.loss_mask: 0.4964  decode.d4.loss_dice: 0.9461  decode.d5.loss_cls: 0.0543  decode.d5.loss_mask: 0.4979  decode.d5.loss_dice: 0.9523  decode.d6.loss_cls: 0.0601  decode.d6.loss_mask: 0.4933  decode.d6.loss_dice: 0.9058  decode.d7.loss_cls: 0.0570  decode.d7.loss_mask: 0.4952  decode.d7.loss_dice: 0.9394  decode.d8.loss_cls: 0.0618  decode.d8.loss_mask: 0.4983  decode.d8.loss_dice: 0.9143
11/15 19:38:32 - mmengine - INFO - Iter(train) [73350/90000]  base_lr: 2.1901e-05 lr: 2.1901e-06  eta: 2:47:03  time: 0.6008  data_time: 0.0107  memory: 10713  grad_norm: 334.7347  loss: 15.2009  decode.loss_cls: 0.0303  decode.loss_mask: 0.4712  decode.loss_dice: 1.0237  decode.d0.loss_cls: 0.0710  decode.d0.loss_mask: 0.4732  decode.d0.loss_dice: 1.0571  decode.d1.loss_cls: 0.0239  decode.d1.loss_mask: 0.4749  decode.d1.loss_dice: 1.0614  decode.d2.loss_cls: 0.0428  decode.d2.loss_mask: 0.4719  decode.d2.loss_dice: 0.9930  decode.d3.loss_cls: 0.0342  decode.d3.loss_mask: 0.4670  decode.d3.loss_dice: 0.9917  decode.d4.loss_cls: 0.0351  decode.d4.loss_mask: 0.4748  decode.d4.loss_dice: 1.0133  decode.d5.loss_cls: 0.0327  decode.d5.loss_mask: 0.4719  decode.d5.loss_dice: 1.0044  decode.d6.loss_cls: 0.0326  decode.d6.loss_mask: 0.4660  decode.d6.loss_dice: 1.0117  decode.d7.loss_cls: 0.0349  decode.d7.loss_mask: 0.4645  decode.d7.loss_dice: 0.9811  decode.d8.loss_cls: 0.0351  decode.d8.loss_mask: 0.4636  decode.d8.loss_dice: 0.9917
11/15 19:39:02 - mmengine - INFO - Iter(train) [73400/90000]  base_lr: 2.1842e-05 lr: 2.1842e-06  eta: 2:46:33  time: 0.5980  data_time: 0.0104  memory: 10675  grad_norm: 434.2865  loss: 13.8309  decode.loss_cls: 0.0432  decode.loss_mask: 0.4155  decode.loss_dice: 0.9255  decode.d0.loss_cls: 0.0740  decode.d0.loss_mask: 0.4236  decode.d0.loss_dice: 0.9621  decode.d1.loss_cls: 0.0438  decode.d1.loss_mask: 0.4166  decode.d1.loss_dice: 0.9336  decode.d2.loss_cls: 0.0563  decode.d2.loss_mask: 0.4043  decode.d2.loss_dice: 0.9142  decode.d3.loss_cls: 0.0358  decode.d3.loss_mask: 0.4096  decode.d3.loss_dice: 0.9321  decode.d4.loss_cls: 0.0404  decode.d4.loss_mask: 0.4103  decode.d4.loss_dice: 0.9192  decode.d5.loss_cls: 0.0397  decode.d5.loss_mask: 0.4081  decode.d5.loss_dice: 0.9059  decode.d6.loss_cls: 0.0383  decode.d6.loss_mask: 0.4088  decode.d6.loss_dice: 0.9351  decode.d7.loss_cls: 0.0489  decode.d7.loss_mask: 0.4126  decode.d7.loss_dice: 0.9110  decode.d8.loss_cls: 0.0559  decode.d8.loss_mask: 0.4107  decode.d8.loss_dice: 0.8957
11/15 19:39:31 - mmengine - INFO - Iter(train) [73450/90000]  base_lr: 2.1782e-05 lr: 2.1782e-06  eta: 2:46:02  time: 0.5992  data_time: 0.0107  memory: 10675  grad_norm: 203.1507  loss: 13.5116  decode.loss_cls: 0.0658  decode.loss_mask: 0.4287  decode.loss_dice: 0.8597  decode.d0.loss_cls: 0.0786  decode.d0.loss_mask: 0.4255  decode.d0.loss_dice: 0.9271  decode.d1.loss_cls: 0.0660  decode.d1.loss_mask: 0.4216  decode.d1.loss_dice: 0.8560  decode.d2.loss_cls: 0.0692  decode.d2.loss_mask: 0.4144  decode.d2.loss_dice: 0.8602  decode.d3.loss_cls: 0.0642  decode.d3.loss_mask: 0.4263  decode.d3.loss_dice: 0.8483  decode.d4.loss_cls: 0.0680  decode.d4.loss_mask: 0.4232  decode.d4.loss_dice: 0.8443  decode.d5.loss_cls: 0.0667  decode.d5.loss_mask: 0.4208  decode.d5.loss_dice: 0.8466  decode.d6.loss_cls: 0.0639  decode.d6.loss_mask: 0.4266  decode.d6.loss_dice: 0.8449  decode.d7.loss_cls: 0.0635  decode.d7.loss_mask: 0.4214  decode.d7.loss_dice: 0.8661  decode.d8.loss_cls: 0.0750  decode.d8.loss_mask: 0.4184  decode.d8.loss_dice: 0.8506
11/15 19:40:02 - mmengine - INFO - Iter(train) [73500/90000]  base_lr: 2.1723e-05 lr: 2.1723e-06  eta: 2:45:33  time: 0.5989  data_time: 0.0104  memory: 10692  grad_norm: 468.4683  loss: 14.5088  decode.loss_cls: 0.0484  decode.loss_mask: 0.4599  decode.loss_dice: 0.9262  decode.d0.loss_cls: 0.0780  decode.d0.loss_mask: 0.4723  decode.d0.loss_dice: 0.9948  decode.d1.loss_cls: 0.0760  decode.d1.loss_mask: 0.4643  decode.d1.loss_dice: 0.9563  decode.d2.loss_cls: 0.0445  decode.d2.loss_mask: 0.4587  decode.d2.loss_dice: 0.9530  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.4534  decode.d3.loss_dice: 0.9381  decode.d4.loss_cls: 0.0570  decode.d4.loss_mask: 0.4534  decode.d4.loss_dice: 0.9308  decode.d5.loss_cls: 0.0437  decode.d5.loss_mask: 0.4558  decode.d5.loss_dice: 0.9370  decode.d6.loss_cls: 0.0502  decode.d6.loss_mask: 0.4539  decode.d6.loss_dice: 0.8987  decode.d7.loss_cls: 0.0467  decode.d7.loss_mask: 0.4579  decode.d7.loss_dice: 0.9041  decode.d8.loss_cls: 0.0485  decode.d8.loss_mask: 0.4598  decode.d8.loss_dice: 0.9315
11/15 19:40:32 - mmengine - INFO - Iter(train) [73550/90000]  base_lr: 2.1664e-05 lr: 2.1664e-06  eta: 2:45:02  time: 0.5988  data_time: 0.0106  memory: 10728  grad_norm: 316.9284  loss: 18.0520  decode.loss_cls: 0.0818  decode.loss_mask: 0.5448  decode.loss_dice: 1.1280  decode.d0.loss_cls: 0.1088  decode.d0.loss_mask: 0.5722  decode.d0.loss_dice: 1.2521  decode.d1.loss_cls: 0.0884  decode.d1.loss_mask: 0.5558  decode.d1.loss_dice: 1.2074  decode.d2.loss_cls: 0.0878  decode.d2.loss_mask: 0.5592  decode.d2.loss_dice: 1.2165  decode.d3.loss_cls: 0.0796  decode.d3.loss_mask: 0.5501  decode.d3.loss_dice: 1.1375  decode.d4.loss_cls: 0.0820  decode.d4.loss_mask: 0.5460  decode.d4.loss_dice: 1.1410  decode.d5.loss_cls: 0.0891  decode.d5.loss_mask: 0.5475  decode.d5.loss_dice: 1.1539  decode.d6.loss_cls: 0.0755  decode.d6.loss_mask: 0.5481  decode.d6.loss_dice: 1.1600  decode.d7.loss_cls: 0.0767  decode.d7.loss_mask: 0.5479  decode.d7.loss_dice: 1.1433  decode.d8.loss_cls: 0.0772  decode.d8.loss_mask: 0.5423  decode.d8.loss_dice: 1.1514
11/15 19:41:02 - mmengine - INFO - Iter(train) [73600/90000]  base_lr: 2.1605e-05 lr: 2.1605e-06  eta: 2:44:32  time: 0.5992  data_time: 0.0106  memory: 10692  grad_norm: 415.2228  loss: 17.0887  decode.loss_cls: 0.0420  decode.loss_mask: 0.5650  decode.loss_dice: 1.0948  decode.d0.loss_cls: 0.0642  decode.d0.loss_mask: 0.6008  decode.d0.loss_dice: 1.1740  decode.d1.loss_cls: 0.0671  decode.d1.loss_mask: 0.5771  decode.d1.loss_dice: 1.0770  decode.d2.loss_cls: 0.0523  decode.d2.loss_mask: 0.5692  decode.d2.loss_dice: 1.0985  decode.d3.loss_cls: 0.0601  decode.d3.loss_mask: 0.5688  decode.d3.loss_dice: 1.0442  decode.d4.loss_cls: 0.0529  decode.d4.loss_mask: 0.5649  decode.d4.loss_dice: 1.0801  decode.d5.loss_cls: 0.0578  decode.d5.loss_mask: 0.5668  decode.d5.loss_dice: 1.0710  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.5652  decode.d6.loss_dice: 1.0486  decode.d7.loss_cls: 0.0535  decode.d7.loss_mask: 0.5688  decode.d7.loss_dice: 1.0621  decode.d8.loss_cls: 0.0554  decode.d8.loss_mask: 0.5653  decode.d8.loss_dice: 1.0718
11/15 19:41:32 - mmengine - INFO - Iter(train) [73650/90000]  base_lr: 2.1545e-05 lr: 2.1545e-06  eta: 2:44:02  time: 0.6065  data_time: 0.0108  memory: 10728  grad_norm: 248.2192  loss: 15.4542  decode.loss_cls: 0.0763  decode.loss_mask: 0.4535  decode.loss_dice: 1.0148  decode.d0.loss_cls: 0.0688  decode.d0.loss_mask: 0.4631  decode.d0.loss_dice: 1.0957  decode.d1.loss_cls: 0.0911  decode.d1.loss_mask: 0.4519  decode.d1.loss_dice: 1.0113  decode.d2.loss_cls: 0.0813  decode.d2.loss_mask: 0.4448  decode.d2.loss_dice: 1.0193  decode.d3.loss_cls: 0.0797  decode.d3.loss_mask: 0.4438  decode.d3.loss_dice: 1.0018  decode.d4.loss_cls: 0.0687  decode.d4.loss_mask: 0.4452  decode.d4.loss_dice: 1.0018  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.4497  decode.d5.loss_dice: 1.0242  decode.d6.loss_cls: 0.0790  decode.d6.loss_mask: 0.4541  decode.d6.loss_dice: 0.9918  decode.d7.loss_cls: 0.0855  decode.d7.loss_mask: 0.4495  decode.d7.loss_dice: 1.0089  decode.d8.loss_cls: 0.0768  decode.d8.loss_mask: 0.4431  decode.d8.loss_dice: 0.9997
11/15 19:42:02 - mmengine - INFO - Iter(train) [73700/90000]  base_lr: 2.1486e-05 lr: 2.1486e-06  eta: 2:43:32  time: 0.5994  data_time: 0.0106  memory: 10675  grad_norm: 197.3869  loss: 14.2548  decode.loss_cls: 0.0297  decode.loss_mask: 0.4756  decode.loss_dice: 0.9073  decode.d0.loss_cls: 0.0553  decode.d0.loss_mask: 0.4924  decode.d0.loss_dice: 0.9427  decode.d1.loss_cls: 0.0291  decode.d1.loss_mask: 0.4761  decode.d1.loss_dice: 0.9433  decode.d2.loss_cls: 0.0272  decode.d2.loss_mask: 0.4685  decode.d2.loss_dice: 0.9119  decode.d3.loss_cls: 0.0313  decode.d3.loss_mask: 0.4662  decode.d3.loss_dice: 0.9191  decode.d4.loss_cls: 0.0308  decode.d4.loss_mask: 0.4704  decode.d4.loss_dice: 0.9083  decode.d5.loss_cls: 0.0290  decode.d5.loss_mask: 0.4715  decode.d5.loss_dice: 0.9349  decode.d6.loss_cls: 0.0276  decode.d6.loss_mask: 0.4726  decode.d6.loss_dice: 0.9039  decode.d7.loss_cls: 0.0282  decode.d7.loss_mask: 0.4752  decode.d7.loss_dice: 0.9116  decode.d8.loss_cls: 0.0256  decode.d8.loss_mask: 0.4770  decode.d8.loss_dice: 0.9123
11/15 19:42:32 - mmengine - INFO - Iter(train) [73750/90000]  base_lr: 2.1427e-05 lr: 2.1427e-06  eta: 2:43:02  time: 0.5984  data_time: 0.0105  memory: 10675  grad_norm: 354.3162  loss: 14.8474  decode.loss_cls: 0.0490  decode.loss_mask: 0.5163  decode.loss_dice: 0.9043  decode.d0.loss_cls: 0.0999  decode.d0.loss_mask: 0.5237  decode.d0.loss_dice: 0.9359  decode.d1.loss_cls: 0.0534  decode.d1.loss_mask: 0.5248  decode.d1.loss_dice: 0.9430  decode.d2.loss_cls: 0.0472  decode.d2.loss_mask: 0.5105  decode.d2.loss_dice: 0.9359  decode.d3.loss_cls: 0.0386  decode.d3.loss_mask: 0.5282  decode.d3.loss_dice: 0.9081  decode.d4.loss_cls: 0.0447  decode.d4.loss_mask: 0.5271  decode.d4.loss_dice: 0.9032  decode.d5.loss_cls: 0.0456  decode.d5.loss_mask: 0.5157  decode.d5.loss_dice: 0.9187  decode.d6.loss_cls: 0.0535  decode.d6.loss_mask: 0.5074  decode.d6.loss_dice: 0.8984  decode.d7.loss_cls: 0.0551  decode.d7.loss_mask: 0.5100  decode.d7.loss_dice: 0.8753  decode.d8.loss_cls: 0.0444  decode.d8.loss_mask: 0.5221  decode.d8.loss_dice: 0.9075
11/15 19:43:02 - mmengine - INFO - Iter(train) [73800/90000]  base_lr: 2.1367e-05 lr: 2.1367e-06  eta: 2:42:32  time: 0.5993  data_time: 0.0105  memory: 10675  grad_norm: 220.4096  loss: 15.6444  decode.loss_cls: 0.0646  decode.loss_mask: 0.4264  decode.loss_dice: 1.0678  decode.d0.loss_cls: 0.0693  decode.d0.loss_mask: 0.4464  decode.d0.loss_dice: 1.1687  decode.d1.loss_cls: 0.0536  decode.d1.loss_mask: 0.4279  decode.d1.loss_dice: 1.0852  decode.d2.loss_cls: 0.0683  decode.d2.loss_mask: 0.4280  decode.d2.loss_dice: 1.0860  decode.d3.loss_cls: 0.0743  decode.d3.loss_mask: 0.4264  decode.d3.loss_dice: 1.0596  decode.d4.loss_cls: 0.0789  decode.d4.loss_mask: 0.4259  decode.d4.loss_dice: 1.0391  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.4271  decode.d5.loss_dice: 1.0763  decode.d6.loss_cls: 0.0775  decode.d6.loss_mask: 0.4206  decode.d6.loss_dice: 1.0248  decode.d7.loss_cls: 0.0671  decode.d7.loss_mask: 0.4243  decode.d7.loss_dice: 1.0388  decode.d8.loss_cls: 0.0611  decode.d8.loss_mask: 0.4265  decode.d8.loss_dice: 1.0456
11/15 19:43:32 - mmengine - INFO - Iter(train) [73850/90000]  base_lr: 2.1308e-05 lr: 2.1308e-06  eta: 2:42:02  time: 0.5982  data_time: 0.0108  memory: 10713  grad_norm: 463.2960  loss: 13.8125  decode.loss_cls: 0.0379  decode.loss_mask: 0.4659  decode.loss_dice: 0.8628  decode.d0.loss_cls: 0.0695  decode.d0.loss_mask: 0.4973  decode.d0.loss_dice: 0.8998  decode.d1.loss_cls: 0.0420  decode.d1.loss_mask: 0.4807  decode.d1.loss_dice: 0.8801  decode.d2.loss_cls: 0.0350  decode.d2.loss_mask: 0.4751  decode.d2.loss_dice: 0.8664  decode.d3.loss_cls: 0.0387  decode.d3.loss_mask: 0.4727  decode.d3.loss_dice: 0.8709  decode.d4.loss_cls: 0.0325  decode.d4.loss_mask: 0.4723  decode.d4.loss_dice: 0.8454  decode.d5.loss_cls: 0.0380  decode.d5.loss_mask: 0.4756  decode.d5.loss_dice: 0.8650  decode.d6.loss_cls: 0.0358  decode.d6.loss_mask: 0.4695  decode.d6.loss_dice: 0.8661  decode.d7.loss_cls: 0.0327  decode.d7.loss_mask: 0.4714  decode.d7.loss_dice: 0.8536  decode.d8.loss_cls: 0.0324  decode.d8.loss_mask: 0.4693  decode.d8.loss_dice: 0.8582
11/15 19:44:02 - mmengine - INFO - Iter(train) [73900/90000]  base_lr: 2.1249e-05 lr: 2.1249e-06  eta: 2:41:32  time: 0.5999  data_time: 0.0106  memory: 10713  grad_norm: 319.6272  loss: 18.4450  decode.loss_cls: 0.0896  decode.loss_mask: 0.4929  decode.loss_dice: 1.2102  decode.d0.loss_cls: 0.1011  decode.d0.loss_mask: 0.5191  decode.d0.loss_dice: 1.3430  decode.d1.loss_cls: 0.0846  decode.d1.loss_mask: 0.5059  decode.d1.loss_dice: 1.2667  decode.d2.loss_cls: 0.0786  decode.d2.loss_mask: 0.4945  decode.d2.loss_dice: 1.2747  decode.d3.loss_cls: 0.0865  decode.d3.loss_mask: 0.5081  decode.d3.loss_dice: 1.2641  decode.d4.loss_cls: 0.0816  decode.d4.loss_mask: 0.5018  decode.d4.loss_dice: 1.2281  decode.d5.loss_cls: 0.0797  decode.d5.loss_mask: 0.4978  decode.d5.loss_dice: 1.2489  decode.d6.loss_cls: 0.0892  decode.d6.loss_mask: 0.5042  decode.d6.loss_dice: 1.2503  decode.d7.loss_cls: 0.0939  decode.d7.loss_mask: 0.5025  decode.d7.loss_dice: 1.2402  decode.d8.loss_cls: 0.0885  decode.d8.loss_mask: 0.4983  decode.d8.loss_dice: 1.2202
11/15 19:44:33 - mmengine - INFO - Iter(train) [73950/90000]  base_lr: 2.1189e-05 lr: 2.1189e-06  eta: 2:41:01  time: 0.6315  data_time: 0.0108  memory: 10675  grad_norm: 389.4210  loss: 14.6581  decode.loss_cls: 0.0533  decode.loss_mask: 0.4491  decode.loss_dice: 0.9296  decode.d0.loss_cls: 0.1095  decode.d0.loss_mask: 0.4839  decode.d0.loss_dice: 1.0610  decode.d1.loss_cls: 0.0638  decode.d1.loss_mask: 0.4428  decode.d1.loss_dice: 0.9620  decode.d2.loss_cls: 0.0466  decode.d2.loss_mask: 0.4488  decode.d2.loss_dice: 0.9586  decode.d3.loss_cls: 0.0582  decode.d3.loss_mask: 0.4389  decode.d3.loss_dice: 0.9298  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.4442  decode.d4.loss_dice: 0.9592  decode.d5.loss_cls: 0.0567  decode.d5.loss_mask: 0.4452  decode.d5.loss_dice: 0.9254  decode.d6.loss_cls: 0.0559  decode.d6.loss_mask: 0.4460  decode.d6.loss_dice: 0.9502  decode.d7.loss_cls: 0.0517  decode.d7.loss_mask: 0.4465  decode.d7.loss_dice: 0.9454  decode.d8.loss_cls: 0.0596  decode.d8.loss_mask: 0.4532  decode.d8.loss_dice: 0.9280
11/15 19:45:03 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 19:45:03 - mmengine - INFO - Iter(train) [74000/90000]  base_lr: 2.1130e-05 lr: 2.1130e-06  eta: 2:40:31  time: 0.6060  data_time: 0.0120  memory: 10675  grad_norm: 422.9018  loss: 14.7672  decode.loss_cls: 0.0639  decode.loss_mask: 0.4470  decode.loss_dice: 0.9742  decode.d0.loss_cls: 0.0805  decode.d0.loss_mask: 0.4964  decode.d0.loss_dice: 1.0658  decode.d1.loss_cls: 0.0797  decode.d1.loss_mask: 0.4542  decode.d1.loss_dice: 0.9678  decode.d2.loss_cls: 0.0666  decode.d2.loss_mask: 0.4394  decode.d2.loss_dice: 0.9387  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.4406  decode.d3.loss_dice: 0.9365  decode.d4.loss_cls: 0.0675  decode.d4.loss_mask: 0.4416  decode.d4.loss_dice: 0.9348  decode.d5.loss_cls: 0.0619  decode.d5.loss_mask: 0.4427  decode.d5.loss_dice: 0.9395  decode.d6.loss_cls: 0.0661  decode.d6.loss_mask: 0.4428  decode.d6.loss_dice: 0.9601  decode.d7.loss_cls: 0.0651  decode.d7.loss_mask: 0.4420  decode.d7.loss_dice: 0.9409  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 0.4453  decode.d8.loss_dice: 0.9400
11/15 19:45:33 - mmengine - INFO - Iter(train) [74050/90000]  base_lr: 2.1070e-05 lr: 2.1070e-06  eta: 2:40:01  time: 0.5985  data_time: 0.0116  memory: 10692  grad_norm: 323.3607  loss: 14.3039  decode.loss_cls: 0.0539  decode.loss_mask: 0.4688  decode.loss_dice: 0.8988  decode.d0.loss_cls: 0.0922  decode.d0.loss_mask: 0.4843  decode.d0.loss_dice: 0.9571  decode.d1.loss_cls: 0.0526  decode.d1.loss_mask: 0.4883  decode.d1.loss_dice: 0.9404  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.4660  decode.d2.loss_dice: 0.9033  decode.d3.loss_cls: 0.0645  decode.d3.loss_mask: 0.4675  decode.d3.loss_dice: 0.8748  decode.d4.loss_cls: 0.0587  decode.d4.loss_mask: 0.4596  decode.d4.loss_dice: 0.8573  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 0.4692  decode.d5.loss_dice: 0.8859  decode.d6.loss_cls: 0.0516  decode.d6.loss_mask: 0.4704  decode.d6.loss_dice: 0.8722  decode.d7.loss_cls: 0.0552  decode.d7.loss_mask: 0.4670  decode.d7.loss_dice: 0.9039  decode.d8.loss_cls: 0.0540  decode.d8.loss_mask: 0.4746  decode.d8.loss_dice: 0.8950
11/15 19:46:02 - mmengine - INFO - Iter(train) [74100/90000]  base_lr: 2.1011e-05 lr: 2.1011e-06  eta: 2:39:31  time: 0.5990  data_time: 0.0107  memory: 10692  grad_norm: 343.3440  loss: 15.3570  decode.loss_cls: 0.0459  decode.loss_mask: 0.4729  decode.loss_dice: 1.0057  decode.d0.loss_cls: 0.0663  decode.d0.loss_mask: 0.4922  decode.d0.loss_dice: 1.0882  decode.d1.loss_cls: 0.0523  decode.d1.loss_mask: 0.4779  decode.d1.loss_dice: 1.0395  decode.d2.loss_cls: 0.0572  decode.d2.loss_mask: 0.4728  decode.d2.loss_dice: 0.9992  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.4689  decode.d3.loss_dice: 0.9743  decode.d4.loss_cls: 0.0549  decode.d4.loss_mask: 0.4671  decode.d4.loss_dice: 0.9988  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.4719  decode.d5.loss_dice: 1.0119  decode.d6.loss_cls: 0.0570  decode.d6.loss_mask: 0.4643  decode.d6.loss_dice: 0.9799  decode.d7.loss_cls: 0.0472  decode.d7.loss_mask: 0.4680  decode.d7.loss_dice: 0.9975  decode.d8.loss_cls: 0.0502  decode.d8.loss_mask: 0.4701  decode.d8.loss_dice: 0.9951
11/15 19:46:32 - mmengine - INFO - Iter(train) [74150/90000]  base_lr: 2.0951e-05 lr: 2.0951e-06  eta: 2:39:01  time: 0.5989  data_time: 0.0104  memory: 10692  grad_norm: 361.2997  loss: 15.9309  decode.loss_cls: 0.0732  decode.loss_mask: 0.4447  decode.loss_dice: 1.0420  decode.d0.loss_cls: 0.0882  decode.d0.loss_mask: 0.4765  decode.d0.loss_dice: 1.1907  decode.d1.loss_cls: 0.0818  decode.d1.loss_mask: 0.4608  decode.d1.loss_dice: 1.0852  decode.d2.loss_cls: 0.0797  decode.d2.loss_mask: 0.4553  decode.d2.loss_dice: 1.0806  decode.d3.loss_cls: 0.0674  decode.d3.loss_mask: 0.4342  decode.d3.loss_dice: 1.0471  decode.d4.loss_cls: 0.0660  decode.d4.loss_mask: 0.4381  decode.d4.loss_dice: 1.0506  decode.d5.loss_cls: 0.0738  decode.d5.loss_mask: 0.4419  decode.d5.loss_dice: 1.0322  decode.d6.loss_cls: 0.0665  decode.d6.loss_mask: 0.4504  decode.d6.loss_dice: 1.0529  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.4529  decode.d7.loss_dice: 1.0666  decode.d8.loss_cls: 0.0748  decode.d8.loss_mask: 0.4383  decode.d8.loss_dice: 1.0461
11/15 19:47:02 - mmengine - INFO - Iter(train) [74200/90000]  base_lr: 2.0892e-05 lr: 2.0892e-06  eta: 2:38:31  time: 0.5988  data_time: 0.0106  memory: 10675  grad_norm: 292.9628  loss: 15.2782  decode.loss_cls: 0.0690  decode.loss_mask: 0.4290  decode.loss_dice: 0.9988  decode.d0.loss_cls: 0.0825  decode.d0.loss_mask: 0.4608  decode.d0.loss_dice: 1.0949  decode.d1.loss_cls: 0.0709  decode.d1.loss_mask: 0.4271  decode.d1.loss_dice: 1.0453  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.4378  decode.d2.loss_dice: 1.0129  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 0.4236  decode.d3.loss_dice: 1.0143  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.4291  decode.d4.loss_dice: 1.0236  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.4295  decode.d5.loss_dice: 1.0255  decode.d6.loss_cls: 0.0730  decode.d6.loss_mask: 0.4340  decode.d6.loss_dice: 1.0036  decode.d7.loss_cls: 0.0772  decode.d7.loss_mask: 0.4320  decode.d7.loss_dice: 1.0197  decode.d8.loss_cls: 0.0684  decode.d8.loss_mask: 0.4325  decode.d8.loss_dice: 1.0091
11/15 19:47:32 - mmengine - INFO - Iter(train) [74250/90000]  base_lr: 2.0832e-05 lr: 2.0832e-06  eta: 2:38:01  time: 0.5976  data_time: 0.0103  memory: 10641  grad_norm: 498.4063  loss: 15.2577  decode.loss_cls: 0.0394  decode.loss_mask: 0.4898  decode.loss_dice: 0.9519  decode.d0.loss_cls: 0.0914  decode.d0.loss_mask: 0.5209  decode.d0.loss_dice: 1.0354  decode.d1.loss_cls: 0.0590  decode.d1.loss_mask: 0.4969  decode.d1.loss_dice: 0.9768  decode.d2.loss_cls: 0.0513  decode.d2.loss_mask: 0.4951  decode.d2.loss_dice: 0.9555  decode.d3.loss_cls: 0.0438  decode.d3.loss_mask: 0.4861  decode.d3.loss_dice: 0.9682  decode.d4.loss_cls: 0.0603  decode.d4.loss_mask: 0.4947  decode.d4.loss_dice: 0.9731  decode.d5.loss_cls: 0.0440  decode.d5.loss_mask: 0.4905  decode.d5.loss_dice: 0.9680  decode.d6.loss_cls: 0.0463  decode.d6.loss_mask: 0.4904  decode.d6.loss_dice: 0.9710  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.4927  decode.d7.loss_dice: 1.0156  decode.d8.loss_cls: 0.0436  decode.d8.loss_mask: 0.4861  decode.d8.loss_dice: 0.9844
11/15 19:48:02 - mmengine - INFO - Iter(train) [74300/90000]  base_lr: 2.0773e-05 lr: 2.0773e-06  eta: 2:37:31  time: 0.5978  data_time: 0.0107  memory: 10675  grad_norm: 307.4466  loss: 17.5867  decode.loss_cls: 0.0616  decode.loss_mask: 0.5130  decode.loss_dice: 1.1427  decode.d0.loss_cls: 0.0894  decode.d0.loss_mask: 0.5833  decode.d0.loss_dice: 1.2405  decode.d1.loss_cls: 0.0539  decode.d1.loss_mask: 0.5175  decode.d1.loss_dice: 1.1929  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.5166  decode.d2.loss_dice: 1.1726  decode.d3.loss_cls: 0.0488  decode.d3.loss_mask: 0.5132  decode.d3.loss_dice: 1.1778  decode.d4.loss_cls: 0.0395  decode.d4.loss_mask: 0.5168  decode.d4.loss_dice: 1.1969  decode.d5.loss_cls: 0.0511  decode.d5.loss_mask: 0.5130  decode.d5.loss_dice: 1.1744  decode.d6.loss_cls: 0.0520  decode.d6.loss_mask: 0.5073  decode.d6.loss_dice: 1.1844  decode.d7.loss_cls: 0.0445  decode.d7.loss_mask: 0.5080  decode.d7.loss_dice: 1.1651  decode.d8.loss_cls: 0.0514  decode.d8.loss_mask: 0.5080  decode.d8.loss_dice: 1.1981
11/15 19:48:32 - mmengine - INFO - Iter(train) [74350/90000]  base_lr: 2.0713e-05 lr: 2.0713e-06  eta: 2:37:00  time: 0.5981  data_time: 0.0105  memory: 10656  grad_norm: 222.1050  loss: 13.7956  decode.loss_cls: 0.0413  decode.loss_mask: 0.4165  decode.loss_dice: 0.8864  decode.d0.loss_cls: 0.0603  decode.d0.loss_mask: 0.4459  decode.d0.loss_dice: 0.9424  decode.d1.loss_cls: 0.0572  decode.d1.loss_mask: 0.4280  decode.d1.loss_dice: 0.9209  decode.d2.loss_cls: 0.0445  decode.d2.loss_mask: 0.4239  decode.d2.loss_dice: 0.9185  decode.d3.loss_cls: 0.0436  decode.d3.loss_mask: 0.4252  decode.d3.loss_dice: 0.9095  decode.d4.loss_cls: 0.0539  decode.d4.loss_mask: 0.4227  decode.d4.loss_dice: 0.9060  decode.d5.loss_cls: 0.0485  decode.d5.loss_mask: 0.4143  decode.d5.loss_dice: 0.8925  decode.d6.loss_cls: 0.0443  decode.d6.loss_mask: 0.4245  decode.d6.loss_dice: 0.9049  decode.d7.loss_cls: 0.0415  decode.d7.loss_mask: 0.4185  decode.d7.loss_dice: 0.8907  decode.d8.loss_cls: 0.0420  decode.d8.loss_mask: 0.4155  decode.d8.loss_dice: 0.9118
11/15 19:49:02 - mmengine - INFO - Iter(train) [74400/90000]  base_lr: 2.0654e-05 lr: 2.0654e-06  eta: 2:36:30  time: 0.5989  data_time: 0.0106  memory: 10675  grad_norm: 370.2561  loss: 14.3176  decode.loss_cls: 0.0531  decode.loss_mask: 0.4326  decode.loss_dice: 0.9346  decode.d0.loss_cls: 0.0942  decode.d0.loss_mask: 0.4459  decode.d0.loss_dice: 0.9704  decode.d1.loss_cls: 0.0686  decode.d1.loss_mask: 0.4327  decode.d1.loss_dice: 0.9692  decode.d2.loss_cls: 0.0473  decode.d2.loss_mask: 0.4286  decode.d2.loss_dice: 0.9496  decode.d3.loss_cls: 0.0528  decode.d3.loss_mask: 0.4307  decode.d3.loss_dice: 0.9310  decode.d4.loss_cls: 0.0456  decode.d4.loss_mask: 0.4340  decode.d4.loss_dice: 0.9372  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.4337  decode.d5.loss_dice: 0.9103  decode.d6.loss_cls: 0.0551  decode.d6.loss_mask: 0.4375  decode.d6.loss_dice: 0.9360  decode.d7.loss_cls: 0.0492  decode.d7.loss_mask: 0.4368  decode.d7.loss_dice: 0.9420  decode.d8.loss_cls: 0.0481  decode.d8.loss_mask: 0.4296  decode.d8.loss_dice: 0.9330
11/15 19:49:32 - mmengine - INFO - Iter(train) [74450/90000]  base_lr: 2.0594e-05 lr: 2.0594e-06  eta: 2:36:00  time: 0.5990  data_time: 0.0106  memory: 10692  grad_norm: 267.8605  loss: 15.6965  decode.loss_cls: 0.0397  decode.loss_mask: 0.4465  decode.loss_dice: 1.0561  decode.d0.loss_cls: 0.0581  decode.d0.loss_mask: 0.4730  decode.d0.loss_dice: 1.1159  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.4532  decode.d1.loss_dice: 1.1118  decode.d2.loss_cls: 0.0473  decode.d2.loss_mask: 0.4430  decode.d2.loss_dice: 1.0773  decode.d3.loss_cls: 0.0401  decode.d3.loss_mask: 0.4411  decode.d3.loss_dice: 1.0575  decode.d4.loss_cls: 0.0396  decode.d4.loss_mask: 0.4427  decode.d4.loss_dice: 1.0709  decode.d5.loss_cls: 0.0376  decode.d5.loss_mask: 0.4459  decode.d5.loss_dice: 1.0817  decode.d6.loss_cls: 0.0376  decode.d6.loss_mask: 0.4464  decode.d6.loss_dice: 1.0364  decode.d7.loss_cls: 0.0397  decode.d7.loss_mask: 0.4497  decode.d7.loss_dice: 1.0812  decode.d8.loss_cls: 0.0352  decode.d8.loss_mask: 0.4495  decode.d8.loss_dice: 1.1023
11/15 19:50:02 - mmengine - INFO - Iter(train) [74500/90000]  base_lr: 2.0535e-05 lr: 2.0535e-06  eta: 2:35:30  time: 0.5991  data_time: 0.0107  memory: 10692  grad_norm: 297.1433  loss: 14.1046  decode.loss_cls: 0.0535  decode.loss_mask: 0.4208  decode.loss_dice: 0.9092  decode.d0.loss_cls: 0.0795  decode.d0.loss_mask: 0.4451  decode.d0.loss_dice: 0.9912  decode.d1.loss_cls: 0.0563  decode.d1.loss_mask: 0.4290  decode.d1.loss_dice: 0.9349  decode.d2.loss_cls: 0.0528  decode.d2.loss_mask: 0.4262  decode.d2.loss_dice: 0.9217  decode.d3.loss_cls: 0.0618  decode.d3.loss_mask: 0.4279  decode.d3.loss_dice: 0.9178  decode.d4.loss_cls: 0.0596  decode.d4.loss_mask: 0.4276  decode.d4.loss_dice: 0.9087  decode.d5.loss_cls: 0.0535  decode.d5.loss_mask: 0.4271  decode.d5.loss_dice: 0.9203  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.4263  decode.d6.loss_dice: 0.9131  decode.d7.loss_cls: 0.0616  decode.d7.loss_mask: 0.4256  decode.d7.loss_dice: 0.9141  decode.d8.loss_cls: 0.0638  decode.d8.loss_mask: 0.4234  decode.d8.loss_dice: 0.8951
11/15 19:50:32 - mmengine - INFO - Iter(train) [74550/90000]  base_lr: 2.0475e-05 lr: 2.0475e-06  eta: 2:35:00  time: 0.6023  data_time: 0.0107  memory: 10713  grad_norm: 373.3893  loss: 12.8654  decode.loss_cls: 0.0447  decode.loss_mask: 0.3785  decode.loss_dice: 0.8318  decode.d0.loss_cls: 0.0710  decode.d0.loss_mask: 0.3918  decode.d0.loss_dice: 0.9198  decode.d1.loss_cls: 0.0546  decode.d1.loss_mask: 0.3887  decode.d1.loss_dice: 0.8355  decode.d2.loss_cls: 0.0492  decode.d2.loss_mask: 0.3846  decode.d2.loss_dice: 0.8643  decode.d3.loss_cls: 0.0556  decode.d3.loss_mask: 0.3863  decode.d3.loss_dice: 0.8309  decode.d4.loss_cls: 0.0468  decode.d4.loss_mask: 0.3873  decode.d4.loss_dice: 0.8324  decode.d5.loss_cls: 0.0504  decode.d5.loss_mask: 0.3862  decode.d5.loss_dice: 0.8878  decode.d6.loss_cls: 0.0441  decode.d6.loss_mask: 0.3857  decode.d6.loss_dice: 0.8426  decode.d7.loss_cls: 0.0438  decode.d7.loss_mask: 0.3828  decode.d7.loss_dice: 0.8329  decode.d8.loss_cls: 0.0522  decode.d8.loss_mask: 0.3774  decode.d8.loss_dice: 0.8259
11/15 19:51:02 - mmengine - INFO - Iter(train) [74600/90000]  base_lr: 2.0415e-05 lr: 2.0415e-06  eta: 2:34:30  time: 0.5983  data_time: 0.0105  memory: 10641  grad_norm: 342.0160  loss: 15.4484  decode.loss_cls: 0.0536  decode.loss_mask: 0.4768  decode.loss_dice: 0.9969  decode.d0.loss_cls: 0.0815  decode.d0.loss_mask: 0.4959  decode.d0.loss_dice: 1.0626  decode.d1.loss_cls: 0.0646  decode.d1.loss_mask: 0.4802  decode.d1.loss_dice: 1.0383  decode.d2.loss_cls: 0.0635  decode.d2.loss_mask: 0.4716  decode.d2.loss_dice: 1.0042  decode.d3.loss_cls: 0.0655  decode.d3.loss_mask: 0.4704  decode.d3.loss_dice: 0.9901  decode.d4.loss_cls: 0.0559  decode.d4.loss_mask: 0.4729  decode.d4.loss_dice: 1.0186  decode.d5.loss_cls: 0.0631  decode.d5.loss_mask: 0.4748  decode.d5.loss_dice: 0.9865  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.4760  decode.d6.loss_dice: 1.0003  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.4775  decode.d7.loss_dice: 0.9732  decode.d8.loss_cls: 0.0583  decode.d8.loss_mask: 0.4758  decode.d8.loss_dice: 0.9855
11/15 19:51:32 - mmengine - INFO - Iter(train) [74650/90000]  base_lr: 2.0356e-05 lr: 2.0356e-06  eta: 2:34:00  time: 0.6003  data_time: 0.0107  memory: 10728  grad_norm: 325.0809  loss: 17.7155  decode.loss_cls: 0.0833  decode.loss_mask: 0.4683  decode.loss_dice: 1.1895  decode.d0.loss_cls: 0.1221  decode.d0.loss_mask: 0.4954  decode.d0.loss_dice: 1.3290  decode.d1.loss_cls: 0.0934  decode.d1.loss_mask: 0.4715  decode.d1.loss_dice: 1.2182  decode.d2.loss_cls: 0.0901  decode.d2.loss_mask: 0.4698  decode.d2.loss_dice: 1.2251  decode.d3.loss_cls: 0.0853  decode.d3.loss_mask: 0.4544  decode.d3.loss_dice: 1.1894  decode.d4.loss_cls: 0.0800  decode.d4.loss_mask: 0.4678  decode.d4.loss_dice: 1.1927  decode.d5.loss_cls: 0.0888  decode.d5.loss_mask: 0.4547  decode.d5.loss_dice: 1.1878  decode.d6.loss_cls: 0.0841  decode.d6.loss_mask: 0.4676  decode.d6.loss_dice: 1.1982  decode.d7.loss_cls: 0.0803  decode.d7.loss_mask: 0.4739  decode.d7.loss_dice: 1.2072  decode.d8.loss_cls: 0.0817  decode.d8.loss_mask: 0.4714  decode.d8.loss_dice: 1.1948
11/15 19:52:02 - mmengine - INFO - Iter(train) [74700/90000]  base_lr: 2.0296e-05 lr: 2.0296e-06  eta: 2:33:30  time: 0.5986  data_time: 0.0105  memory: 10675  grad_norm: 383.9427  loss: 15.7798  decode.loss_cls: 0.0612  decode.loss_mask: 0.4372  decode.loss_dice: 1.0639  decode.d0.loss_cls: 0.0943  decode.d0.loss_mask: 0.4553  decode.d0.loss_dice: 1.1628  decode.d1.loss_cls: 0.0734  decode.d1.loss_mask: 0.4415  decode.d1.loss_dice: 1.1125  decode.d2.loss_cls: 0.0757  decode.d2.loss_mask: 0.4355  decode.d2.loss_dice: 1.0468  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.4279  decode.d3.loss_dice: 1.0669  decode.d4.loss_cls: 0.0802  decode.d4.loss_mask: 0.4186  decode.d4.loss_dice: 1.0198  decode.d5.loss_cls: 0.0661  decode.d5.loss_mask: 0.4358  decode.d5.loss_dice: 1.0342  decode.d6.loss_cls: 0.0745  decode.d6.loss_mask: 0.4377  decode.d6.loss_dice: 1.0508  decode.d7.loss_cls: 0.0658  decode.d7.loss_mask: 0.4380  decode.d7.loss_dice: 1.0700  decode.d8.loss_cls: 0.0703  decode.d8.loss_mask: 0.4441  decode.d8.loss_dice: 1.0573
11/15 19:52:32 - mmengine - INFO - Iter(train) [74750/90000]  base_lr: 2.0236e-05 lr: 2.0236e-06  eta: 2:32:59  time: 0.5996  data_time: 0.0107  memory: 10713  grad_norm: 296.1066  loss: 14.1027  decode.loss_cls: 0.0607  decode.loss_mask: 0.4106  decode.loss_dice: 0.9300  decode.d0.loss_cls: 0.0909  decode.d0.loss_mask: 0.4338  decode.d0.loss_dice: 1.0098  decode.d1.loss_cls: 0.0730  decode.d1.loss_mask: 0.4110  decode.d1.loss_dice: 0.9480  decode.d2.loss_cls: 0.0690  decode.d2.loss_mask: 0.4085  decode.d2.loss_dice: 0.9277  decode.d3.loss_cls: 0.0635  decode.d3.loss_mask: 0.4135  decode.d3.loss_dice: 0.9160  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.4095  decode.d4.loss_dice: 0.9043  decode.d5.loss_cls: 0.0659  decode.d5.loss_mask: 0.4082  decode.d5.loss_dice: 0.9071  decode.d6.loss_cls: 0.0625  decode.d6.loss_mask: 0.4154  decode.d6.loss_dice: 0.9072  decode.d7.loss_cls: 0.0636  decode.d7.loss_mask: 0.4132  decode.d7.loss_dice: 0.9382  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 0.4126  decode.d8.loss_dice: 0.9008
11/15 19:53:02 - mmengine - INFO - Iter(train) [74800/90000]  base_lr: 2.0176e-05 lr: 2.0176e-06  eta: 2:32:29  time: 0.5993  data_time: 0.0108  memory: 10675  grad_norm: 568.7896  loss: 15.3974  decode.loss_cls: 0.0744  decode.loss_mask: 0.4155  decode.loss_dice: 1.0450  decode.d0.loss_cls: 0.1052  decode.d0.loss_mask: 0.4327  decode.d0.loss_dice: 1.0805  decode.d1.loss_cls: 0.0752  decode.d1.loss_mask: 0.4377  decode.d1.loss_dice: 1.0774  decode.d2.loss_cls: 0.0781  decode.d2.loss_mask: 0.4197  decode.d2.loss_dice: 1.0440  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.4184  decode.d3.loss_dice: 1.0421  decode.d4.loss_cls: 0.0708  decode.d4.loss_mask: 0.4168  decode.d4.loss_dice: 1.0642  decode.d5.loss_cls: 0.0731  decode.d5.loss_mask: 0.4146  decode.d5.loss_dice: 1.0231  decode.d6.loss_cls: 0.0640  decode.d6.loss_mask: 0.4087  decode.d6.loss_dice: 1.0294  decode.d7.loss_cls: 0.0674  decode.d7.loss_mask: 0.4094  decode.d7.loss_dice: 1.0328  decode.d8.loss_cls: 0.0630  decode.d8.loss_mask: 0.4131  decode.d8.loss_dice: 1.0364
11/15 19:53:32 - mmengine - INFO - Iter(train) [74850/90000]  base_lr: 2.0117e-05 lr: 2.0117e-06  eta: 2:31:59  time: 0.5993  data_time: 0.0106  memory: 10692  grad_norm: 449.4493  loss: 16.6387  decode.loss_cls: 0.0607  decode.loss_mask: 0.5534  decode.loss_dice: 1.0591  decode.d0.loss_cls: 0.1017  decode.d0.loss_mask: 0.5565  decode.d0.loss_dice: 1.0914  decode.d1.loss_cls: 0.0731  decode.d1.loss_mask: 0.5489  decode.d1.loss_dice: 1.0631  decode.d2.loss_cls: 0.0631  decode.d2.loss_mask: 0.5509  decode.d2.loss_dice: 1.0546  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.5502  decode.d3.loss_dice: 1.0135  decode.d4.loss_cls: 0.0567  decode.d4.loss_mask: 0.5505  decode.d4.loss_dice: 1.0379  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 0.5517  decode.d5.loss_dice: 1.0230  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.5540  decode.d6.loss_dice: 1.0376  decode.d7.loss_cls: 0.0658  decode.d7.loss_mask: 0.5525  decode.d7.loss_dice: 1.0358  decode.d8.loss_cls: 0.0629  decode.d8.loss_mask: 0.5506  decode.d8.loss_dice: 1.0326
11/15 19:54:02 - mmengine - INFO - Iter(train) [74900/90000]  base_lr: 2.0057e-05 lr: 2.0057e-06  eta: 2:31:29  time: 0.5989  data_time: 0.0108  memory: 10713  grad_norm: 419.4692  loss: 14.0057  decode.loss_cls: 0.0439  decode.loss_mask: 0.4917  decode.loss_dice: 0.8651  decode.d0.loss_cls: 0.0857  decode.d0.loss_mask: 0.4688  decode.d0.loss_dice: 0.9077  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.4590  decode.d1.loss_dice: 0.8646  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.4502  decode.d2.loss_dice: 0.8519  decode.d3.loss_cls: 0.0544  decode.d3.loss_mask: 0.4826  decode.d3.loss_dice: 0.8353  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.4846  decode.d4.loss_dice: 0.8303  decode.d5.loss_cls: 0.0508  decode.d5.loss_mask: 0.4870  decode.d5.loss_dice: 0.8594  decode.d6.loss_cls: 0.0490  decode.d6.loss_mask: 0.5085  decode.d6.loss_dice: 0.8761  decode.d7.loss_cls: 0.0522  decode.d7.loss_mask: 0.4872  decode.d7.loss_dice: 0.8741  decode.d8.loss_cls: 0.0415  decode.d8.loss_mask: 0.4931  decode.d8.loss_dice: 0.8739
11/15 19:54:32 - mmengine - INFO - Iter(train) [74950/90000]  base_lr: 1.9997e-05 lr: 1.9997e-06  eta: 2:30:59  time: 0.5993  data_time: 0.0106  memory: 10692  grad_norm: 236.7123  loss: 14.2845  decode.loss_cls: 0.0943  decode.loss_mask: 0.3815  decode.loss_dice: 0.9335  decode.d0.loss_cls: 0.1079  decode.d0.loss_mask: 0.3802  decode.d0.loss_dice: 1.0688  decode.d1.loss_cls: 0.1080  decode.d1.loss_mask: 0.3679  decode.d1.loss_dice: 1.0030  decode.d2.loss_cls: 0.1067  decode.d2.loss_mask: 0.3633  decode.d2.loss_dice: 0.9646  decode.d3.loss_cls: 0.0985  decode.d3.loss_mask: 0.3606  decode.d3.loss_dice: 0.9123  decode.d4.loss_cls: 0.1063  decode.d4.loss_mask: 0.3619  decode.d4.loss_dice: 0.9414  decode.d5.loss_cls: 0.0947  decode.d5.loss_mask: 0.3636  decode.d5.loss_dice: 0.9662  decode.d6.loss_cls: 0.0898  decode.d6.loss_mask: 0.3762  decode.d6.loss_dice: 0.9541  decode.d7.loss_cls: 0.0884  decode.d7.loss_mask: 0.3756  decode.d7.loss_dice: 0.9286  decode.d8.loss_cls: 0.0936  decode.d8.loss_mask: 0.3696  decode.d8.loss_dice: 0.9234
11/15 19:55:02 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 19:55:02 - mmengine - INFO - Iter(train) [75000/90000]  base_lr: 1.9937e-05 lr: 1.9937e-06  eta: 2:30:29  time: 0.5981  data_time: 0.0107  memory: 10713  grad_norm: 504.7931  loss: 15.9541  decode.loss_cls: 0.0738  decode.loss_mask: 0.5020  decode.loss_dice: 1.0197  decode.d0.loss_cls: 0.1070  decode.d0.loss_mask: 0.5200  decode.d0.loss_dice: 1.1150  decode.d1.loss_cls: 0.0970  decode.d1.loss_mask: 0.4902  decode.d1.loss_dice: 1.0291  decode.d2.loss_cls: 0.0847  decode.d2.loss_mask: 0.4756  decode.d2.loss_dice: 0.9965  decode.d3.loss_cls: 0.0826  decode.d3.loss_mask: 0.4799  decode.d3.loss_dice: 0.9812  decode.d4.loss_cls: 0.0789  decode.d4.loss_mask: 0.4838  decode.d4.loss_dice: 0.9810  decode.d5.loss_cls: 0.0840  decode.d5.loss_mask: 0.4867  decode.d5.loss_dice: 0.9967  decode.d6.loss_cls: 0.0776  decode.d6.loss_mask: 0.5011  decode.d6.loss_dice: 1.0254  decode.d7.loss_cls: 0.0586  decode.d7.loss_mask: 0.4965  decode.d7.loss_dice: 1.0452  decode.d8.loss_cls: 0.0711  decode.d8.loss_mask: 0.4964  decode.d8.loss_dice: 1.0167
11/15 19:55:02 - mmengine - INFO - Saving checkpoint at 75000 iterations
11/15 19:55:21 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:24  time: 0.3086  data_time: 0.0042  memory: 4095  
11/15 19:55:36 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:06  time: 0.3084  data_time: 0.0041  memory: 4095  
11/15 19:55:52 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:49  time: 0.3084  data_time: 0.0042  memory: 4095  
11/15 19:56:07 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3089  data_time: 0.0043  memory: 4095  
11/15 19:56:23 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3092  data_time: 0.0043  memory: 4095  
11/15 19:56:38 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:02  time: 0.3092  data_time: 0.0041  memory: 4095  
11/15 19:56:54 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3090  data_time: 0.0041  memory: 4095  
11/15 19:57:09 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:31  time: 0.3087  data_time: 0.0040  memory: 4095  
11/15 19:57:25 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3093  data_time: 0.0042  memory: 4095  
11/15 19:57:40 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3087  data_time: 0.0037  memory: 4095  
11/15 19:57:40 - mmengine - INFO - per class results:
11/15 19:57:40 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 97.84 | 98.21 |
|    sidewalk   | 84.78 | 94.31 |
|    building   | 93.07 | 96.12 |
|      wall     | 62.87 | 81.42 |
|     fence     | 61.07 | 74.05 |
|      pole     | 68.19 | 80.93 |
| traffic light | 72.05 | 82.79 |
|  traffic sign | 82.11 | 89.08 |
|   vegetation  | 92.48 | 96.89 |
|    terrain    | 67.47 | 80.82 |
|      sky      | 94.89 | 96.83 |
|     person    | 82.83 | 90.24 |
|     rider     | 65.51 | 81.16 |
|      car      | 95.16 | 98.08 |
|     truck     | 84.49 | 92.65 |
|      bus      |  86.8 | 90.07 |
|     train     |  71.5 | 91.96 |
|   motorcycle  | 66.49 | 79.04 |
|    bicycle    | 79.32 | 89.53 |
+---------------+-------+-------+
11/15 19:57:40 - mmengine - INFO - Iter(val) [500/500]    aAcc: 96.1700  mIoU: 79.4200  mAcc: 88.6400  data_time: 0.0049  time: 0.3102
11/15 19:58:10 - mmengine - INFO - Iter(train) [75050/90000]  base_lr: 1.9878e-05 lr: 1.9878e-06  eta: 2:29:59  time: 0.5998  data_time: 0.0108  memory: 10692  grad_norm: 287.2368  loss: 16.6124  decode.loss_cls: 0.0444  decode.loss_mask: 0.5077  decode.loss_dice: 1.0946  decode.d0.loss_cls: 0.0866  decode.d0.loss_mask: 0.5144  decode.d0.loss_dice: 1.1081  decode.d1.loss_cls: 0.0598  decode.d1.loss_mask: 0.5129  decode.d1.loss_dice: 1.1094  decode.d2.loss_cls: 0.0465  decode.d2.loss_mask: 0.5156  decode.d2.loss_dice: 1.0980  decode.d3.loss_cls: 0.0431  decode.d3.loss_mask: 0.5082  decode.d3.loss_dice: 1.1117  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.5142  decode.d4.loss_dice: 1.1124  decode.d5.loss_cls: 0.0436  decode.d5.loss_mask: 0.5094  decode.d5.loss_dice: 1.0861  decode.d6.loss_cls: 0.0497  decode.d6.loss_mask: 0.5072  decode.d6.loss_dice: 1.1003  decode.d7.loss_cls: 0.0481  decode.d7.loss_mask: 0.5067  decode.d7.loss_dice: 1.0858  decode.d8.loss_cls: 0.0579  decode.d8.loss_mask: 0.4887  decode.d8.loss_dice: 1.0925
11/15 19:58:40 - mmengine - INFO - Iter(train) [75100/90000]  base_lr: 1.9818e-05 lr: 1.9818e-06  eta: 2:29:29  time: 0.5988  data_time: 0.0106  memory: 10692  grad_norm: 577.1176  loss: 14.7336  decode.loss_cls: 0.0620  decode.loss_mask: 0.4674  decode.loss_dice: 0.9349  decode.d0.loss_cls: 0.0661  decode.d0.loss_mask: 0.4818  decode.d0.loss_dice: 1.0023  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.4751  decode.d1.loss_dice: 0.9782  decode.d2.loss_cls: 0.0514  decode.d2.loss_mask: 0.4714  decode.d2.loss_dice: 0.9708  decode.d3.loss_cls: 0.0587  decode.d3.loss_mask: 0.4619  decode.d3.loss_dice: 0.9181  decode.d4.loss_cls: 0.0555  decode.d4.loss_mask: 0.4756  decode.d4.loss_dice: 0.9314  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.4631  decode.d5.loss_dice: 0.9053  decode.d6.loss_cls: 0.0598  decode.d6.loss_mask: 0.4676  decode.d6.loss_dice: 0.9421  decode.d7.loss_cls: 0.0564  decode.d7.loss_mask: 0.4715  decode.d7.loss_dice: 0.9386  decode.d8.loss_cls: 0.0615  decode.d8.loss_mask: 0.4643  decode.d8.loss_dice: 0.9101
11/15 19:59:10 - mmengine - INFO - Iter(train) [75150/90000]  base_lr: 1.9758e-05 lr: 1.9758e-06  eta: 2:28:58  time: 0.5999  data_time: 0.0106  memory: 10692  grad_norm: 320.7365  loss: 14.1524  decode.loss_cls: 0.0538  decode.loss_mask: 0.4041  decode.loss_dice: 0.9191  decode.d0.loss_cls: 0.1011  decode.d0.loss_mask: 0.4212  decode.d0.loss_dice: 0.9996  decode.d1.loss_cls: 0.0682  decode.d1.loss_mask: 0.4102  decode.d1.loss_dice: 0.9349  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.4092  decode.d2.loss_dice: 0.9411  decode.d3.loss_cls: 0.0646  decode.d3.loss_mask: 0.4074  decode.d3.loss_dice: 0.9236  decode.d4.loss_cls: 0.0513  decode.d4.loss_mask: 0.4053  decode.d4.loss_dice: 0.9283  decode.d5.loss_cls: 0.0594  decode.d5.loss_mask: 0.4084  decode.d5.loss_dice: 0.9457  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.4067  decode.d6.loss_dice: 0.9325  decode.d7.loss_cls: 0.0585  decode.d7.loss_mask: 0.4083  decode.d7.loss_dice: 0.9627  decode.d8.loss_cls: 0.0520  decode.d8.loss_mask: 0.4083  decode.d8.loss_dice: 0.9383
11/15 19:59:40 - mmengine - INFO - Iter(train) [75200/90000]  base_lr: 1.9698e-05 lr: 1.9698e-06  eta: 2:28:28  time: 0.5983  data_time: 0.0106  memory: 10728  grad_norm: 363.4300  loss: 13.6718  decode.loss_cls: 0.0455  decode.loss_mask: 0.4218  decode.loss_dice: 0.8954  decode.d0.loss_cls: 0.0753  decode.d0.loss_mask: 0.4647  decode.d0.loss_dice: 0.9497  decode.d1.loss_cls: 0.0507  decode.d1.loss_mask: 0.4505  decode.d1.loss_dice: 0.9019  decode.d2.loss_cls: 0.0460  decode.d2.loss_mask: 0.4306  decode.d2.loss_dice: 0.8863  decode.d3.loss_cls: 0.0437  decode.d3.loss_mask: 0.4270  decode.d3.loss_dice: 0.8741  decode.d4.loss_cls: 0.0457  decode.d4.loss_mask: 0.4162  decode.d4.loss_dice: 0.8501  decode.d5.loss_cls: 0.0449  decode.d5.loss_mask: 0.4217  decode.d5.loss_dice: 0.8785  decode.d6.loss_cls: 0.0482  decode.d6.loss_mask: 0.4189  decode.d6.loss_dice: 0.8889  decode.d7.loss_cls: 0.0430  decode.d7.loss_mask: 0.4169  decode.d7.loss_dice: 0.8899  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.4212  decode.d8.loss_dice: 0.8788
11/15 20:00:10 - mmengine - INFO - Iter(train) [75250/90000]  base_lr: 1.9638e-05 lr: 1.9638e-06  eta: 2:27:58  time: 0.5988  data_time: 0.0105  memory: 10692  grad_norm: 772.2696  loss: 14.1745  decode.loss_cls: 0.0659  decode.loss_mask: 0.4333  decode.loss_dice: 0.8978  decode.d0.loss_cls: 0.1020  decode.d0.loss_mask: 0.4550  decode.d0.loss_dice: 1.0021  decode.d1.loss_cls: 0.0833  decode.d1.loss_mask: 0.4386  decode.d1.loss_dice: 0.9565  decode.d2.loss_cls: 0.0801  decode.d2.loss_mask: 0.4456  decode.d2.loss_dice: 0.9023  decode.d3.loss_cls: 0.0643  decode.d3.loss_mask: 0.4490  decode.d3.loss_dice: 0.8947  decode.d4.loss_cls: 0.0630  decode.d4.loss_mask: 0.4413  decode.d4.loss_dice: 0.9003  decode.d5.loss_cls: 0.0751  decode.d5.loss_mask: 0.4400  decode.d5.loss_dice: 0.8788  decode.d6.loss_cls: 0.0629  decode.d6.loss_mask: 0.4364  decode.d6.loss_dice: 0.8825  decode.d7.loss_cls: 0.0714  decode.d7.loss_mask: 0.4344  decode.d7.loss_dice: 0.8594  decode.d8.loss_cls: 0.0772  decode.d8.loss_mask: 0.4315  decode.d8.loss_dice: 0.8498
11/15 20:00:40 - mmengine - INFO - Iter(train) [75300/90000]  base_lr: 1.9578e-05 lr: 1.9578e-06  eta: 2:27:28  time: 0.5996  data_time: 0.0108  memory: 10656  grad_norm: 384.9138  loss: 14.3531  decode.loss_cls: 0.0436  decode.loss_mask: 0.4180  decode.loss_dice: 0.9784  decode.d0.loss_cls: 0.0637  decode.d0.loss_mask: 0.4215  decode.d0.loss_dice: 1.0226  decode.d1.loss_cls: 0.0462  decode.d1.loss_mask: 0.4200  decode.d1.loss_dice: 0.9962  decode.d2.loss_cls: 0.0466  decode.d2.loss_mask: 0.4176  decode.d2.loss_dice: 0.9850  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.4151  decode.d3.loss_dice: 0.9323  decode.d4.loss_cls: 0.0485  decode.d4.loss_mask: 0.4200  decode.d4.loss_dice: 0.9729  decode.d5.loss_cls: 0.0495  decode.d5.loss_mask: 0.4166  decode.d5.loss_dice: 0.9376  decode.d6.loss_cls: 0.0436  decode.d6.loss_mask: 0.4151  decode.d6.loss_dice: 0.9762  decode.d7.loss_cls: 0.0451  decode.d7.loss_mask: 0.4145  decode.d7.loss_dice: 0.9639  decode.d8.loss_cls: 0.0450  decode.d8.loss_mask: 0.4141  decode.d8.loss_dice: 0.9340
11/15 20:01:10 - mmengine - INFO - Iter(train) [75350/90000]  base_lr: 1.9518e-05 lr: 1.9518e-06  eta: 2:26:58  time: 0.5995  data_time: 0.0105  memory: 10675  grad_norm: 423.7794  loss: 15.5433  decode.loss_cls: 0.0591  decode.loss_mask: 0.4014  decode.loss_dice: 1.0492  decode.d0.loss_cls: 0.0978  decode.d0.loss_mask: 0.4374  decode.d0.loss_dice: 1.1872  decode.d1.loss_cls: 0.0628  decode.d1.loss_mask: 0.4124  decode.d1.loss_dice: 1.1260  decode.d2.loss_cls: 0.0615  decode.d2.loss_mask: 0.4049  decode.d2.loss_dice: 1.0880  decode.d3.loss_cls: 0.0586  decode.d3.loss_mask: 0.4032  decode.d3.loss_dice: 1.0671  decode.d4.loss_cls: 0.0632  decode.d4.loss_mask: 0.4024  decode.d4.loss_dice: 1.0580  decode.d5.loss_cls: 0.0591  decode.d5.loss_mask: 0.4005  decode.d5.loss_dice: 1.0628  decode.d6.loss_cls: 0.0653  decode.d6.loss_mask: 0.3986  decode.d6.loss_dice: 1.0580  decode.d7.loss_cls: 0.0580  decode.d7.loss_mask: 0.4006  decode.d7.loss_dice: 1.0724  decode.d8.loss_cls: 0.0545  decode.d8.loss_mask: 0.4035  decode.d8.loss_dice: 1.0697
11/15 20:01:40 - mmengine - INFO - Iter(train) [75400/90000]  base_lr: 1.9458e-05 lr: 1.9458e-06  eta: 2:26:28  time: 0.6021  data_time: 0.0107  memory: 10692  grad_norm: 221.1988  loss: 14.1548  decode.loss_cls: 0.0466  decode.loss_mask: 0.4023  decode.loss_dice: 0.9587  decode.d0.loss_cls: 0.0792  decode.d0.loss_mask: 0.4183  decode.d0.loss_dice: 1.0236  decode.d1.loss_cls: 0.0559  decode.d1.loss_mask: 0.4011  decode.d1.loss_dice: 0.9925  decode.d2.loss_cls: 0.0586  decode.d2.loss_mask: 0.3989  decode.d2.loss_dice: 0.9475  decode.d3.loss_cls: 0.0491  decode.d3.loss_mask: 0.4008  decode.d3.loss_dice: 0.9430  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.3978  decode.d4.loss_dice: 0.9473  decode.d5.loss_cls: 0.0517  decode.d5.loss_mask: 0.3977  decode.d5.loss_dice: 0.9328  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.3989  decode.d6.loss_dice: 0.9558  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.3976  decode.d7.loss_dice: 0.9495  decode.d8.loss_cls: 0.0463  decode.d8.loss_mask: 0.3998  decode.d8.loss_dice: 0.9459
11/15 20:02:10 - mmengine - INFO - Iter(train) [75450/90000]  base_lr: 1.9398e-05 lr: 1.9398e-06  eta: 2:25:58  time: 0.6025  data_time: 0.0109  memory: 10675  grad_norm: 348.1861  loss: 16.6756  decode.loss_cls: 0.0457  decode.loss_mask: 0.4967  decode.loss_dice: 1.0721  decode.d0.loss_cls: 0.0897  decode.d0.loss_mask: 0.5607  decode.d0.loss_dice: 1.1568  decode.d1.loss_cls: 0.0432  decode.d1.loss_mask: 0.5209  decode.d1.loss_dice: 1.1518  decode.d2.loss_cls: 0.0492  decode.d2.loss_mask: 0.5105  decode.d2.loss_dice: 1.1239  decode.d3.loss_cls: 0.0540  decode.d3.loss_mask: 0.5022  decode.d3.loss_dice: 1.0909  decode.d4.loss_cls: 0.0467  decode.d4.loss_mask: 0.4993  decode.d4.loss_dice: 1.0903  decode.d5.loss_cls: 0.0489  decode.d5.loss_mask: 0.4968  decode.d5.loss_dice: 1.0832  decode.d6.loss_cls: 0.0611  decode.d6.loss_mask: 0.5024  decode.d6.loss_dice: 1.0849  decode.d7.loss_cls: 0.0467  decode.d7.loss_mask: 0.5051  decode.d7.loss_dice: 1.1027  decode.d8.loss_cls: 0.0689  decode.d8.loss_mask: 0.4972  decode.d8.loss_dice: 1.0730
11/15 20:02:40 - mmengine - INFO - Iter(train) [75500/90000]  base_lr: 1.9338e-05 lr: 1.9338e-06  eta: 2:25:28  time: 0.6008  data_time: 0.0110  memory: 10692  grad_norm: 297.9371  loss: 15.8781  decode.loss_cls: 0.0701  decode.loss_mask: 0.4495  decode.loss_dice: 1.0748  decode.d0.loss_cls: 0.0771  decode.d0.loss_mask: 0.4601  decode.d0.loss_dice: 1.1459  decode.d1.loss_cls: 0.0618  decode.d1.loss_mask: 0.4401  decode.d1.loss_dice: 1.0944  decode.d2.loss_cls: 0.0655  decode.d2.loss_mask: 0.4463  decode.d2.loss_dice: 1.0614  decode.d3.loss_cls: 0.0627  decode.d3.loss_mask: 0.4399  decode.d3.loss_dice: 1.0524  decode.d4.loss_cls: 0.0612  decode.d4.loss_mask: 0.4428  decode.d4.loss_dice: 1.0588  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.4480  decode.d5.loss_dice: 1.0729  decode.d6.loss_cls: 0.0728  decode.d6.loss_mask: 0.4442  decode.d6.loss_dice: 1.0630  decode.d7.loss_cls: 0.0681  decode.d7.loss_mask: 0.4434  decode.d7.loss_dice: 1.0671  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.4465  decode.d8.loss_dice: 1.0625
11/15 20:03:10 - mmengine - INFO - Iter(train) [75550/90000]  base_lr: 1.9278e-05 lr: 1.9278e-06  eta: 2:24:57  time: 0.6020  data_time: 0.0108  memory: 10692  grad_norm: 293.3096  loss: 16.4533  decode.loss_cls: 0.0781  decode.loss_mask: 0.4173  decode.loss_dice: 1.0981  decode.d0.loss_cls: 0.0942  decode.d0.loss_mask: 0.4695  decode.d0.loss_dice: 1.2464  decode.d1.loss_cls: 0.0773  decode.d1.loss_mask: 0.4288  decode.d1.loss_dice: 1.1424  decode.d2.loss_cls: 0.0762  decode.d2.loss_mask: 0.4279  decode.d2.loss_dice: 1.1596  decode.d3.loss_cls: 0.0766  decode.d3.loss_mask: 0.4183  decode.d3.loss_dice: 1.1440  decode.d4.loss_cls: 0.0702  decode.d4.loss_mask: 0.4222  decode.d4.loss_dice: 1.1198  decode.d5.loss_cls: 0.0784  decode.d5.loss_mask: 0.4204  decode.d5.loss_dice: 1.1303  decode.d6.loss_cls: 0.0907  decode.d6.loss_mask: 0.4121  decode.d6.loss_dice: 1.0900  decode.d7.loss_cls: 0.0817  decode.d7.loss_mask: 0.4164  decode.d7.loss_dice: 1.1257  decode.d8.loss_cls: 0.0751  decode.d8.loss_mask: 0.4216  decode.d8.loss_dice: 1.1440
11/15 20:03:40 - mmengine - INFO - Iter(train) [75600/90000]  base_lr: 1.9218e-05 lr: 1.9218e-06  eta: 2:24:27  time: 0.5996  data_time: 0.0107  memory: 10758  grad_norm: 236.8372  loss: 14.1948  decode.loss_cls: 0.0271  decode.loss_mask: 0.4328  decode.loss_dice: 0.9618  decode.d0.loss_cls: 0.0632  decode.d0.loss_mask: 0.4442  decode.d0.loss_dice: 0.9903  decode.d1.loss_cls: 0.0490  decode.d1.loss_mask: 0.4281  decode.d1.loss_dice: 0.9382  decode.d2.loss_cls: 0.0339  decode.d2.loss_mask: 0.4278  decode.d2.loss_dice: 0.9766  decode.d3.loss_cls: 0.0306  decode.d3.loss_mask: 0.4309  decode.d3.loss_dice: 0.9251  decode.d4.loss_cls: 0.0303  decode.d4.loss_mask: 0.4319  decode.d4.loss_dice: 0.9603  decode.d5.loss_cls: 0.0276  decode.d5.loss_mask: 0.4337  decode.d5.loss_dice: 0.9517  decode.d6.loss_cls: 0.0293  decode.d6.loss_mask: 0.4312  decode.d6.loss_dice: 0.9458  decode.d7.loss_cls: 0.0294  decode.d7.loss_mask: 0.4277  decode.d7.loss_dice: 0.9391  decode.d8.loss_cls: 0.0259  decode.d8.loss_mask: 0.4315  decode.d8.loss_dice: 0.9398
11/15 20:04:10 - mmengine - INFO - Iter(train) [75650/90000]  base_lr: 1.9158e-05 lr: 1.9158e-06  eta: 2:23:57  time: 0.5993  data_time: 0.0107  memory: 10692  grad_norm: 262.3223  loss: 13.2120  decode.loss_cls: 0.0567  decode.loss_mask: 0.4152  decode.loss_dice: 0.8341  decode.d0.loss_cls: 0.0982  decode.d0.loss_mask: 0.4228  decode.d0.loss_dice: 0.8977  decode.d1.loss_cls: 0.0626  decode.d1.loss_mask: 0.4286  decode.d1.loss_dice: 0.8528  decode.d2.loss_cls: 0.0568  decode.d2.loss_mask: 0.4153  decode.d2.loss_dice: 0.8546  decode.d3.loss_cls: 0.0599  decode.d3.loss_mask: 0.4184  decode.d3.loss_dice: 0.8299  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.4217  decode.d4.loss_dice: 0.8098  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.4197  decode.d5.loss_dice: 0.8304  decode.d6.loss_cls: 0.0536  decode.d6.loss_mask: 0.4173  decode.d6.loss_dice: 0.8276  decode.d7.loss_cls: 0.0577  decode.d7.loss_mask: 0.4112  decode.d7.loss_dice: 0.8342  decode.d8.loss_cls: 0.0628  decode.d8.loss_mask: 0.4155  decode.d8.loss_dice: 0.8284
11/15 20:04:40 - mmengine - INFO - Iter(train) [75700/90000]  base_lr: 1.9098e-05 lr: 1.9098e-06  eta: 2:23:27  time: 0.5978  data_time: 0.0105  memory: 10626  grad_norm: 768.2359  loss: 15.7610  decode.loss_cls: 0.0687  decode.loss_mask: 0.5112  decode.loss_dice: 0.9716  decode.d0.loss_cls: 0.0958  decode.d0.loss_mask: 0.5522  decode.d0.loss_dice: 1.0288  decode.d1.loss_cls: 0.0757  decode.d1.loss_mask: 0.5078  decode.d1.loss_dice: 0.9917  decode.d2.loss_cls: 0.0724  decode.d2.loss_mask: 0.5113  decode.d2.loss_dice: 0.9691  decode.d3.loss_cls: 0.0844  decode.d3.loss_mask: 0.5243  decode.d3.loss_dice: 1.0028  decode.d4.loss_cls: 0.0568  decode.d4.loss_mask: 0.5465  decode.d4.loss_dice: 1.0113  decode.d5.loss_cls: 0.0686  decode.d5.loss_mask: 0.5189  decode.d5.loss_dice: 0.9631  decode.d6.loss_cls: 0.0751  decode.d6.loss_mask: 0.5090  decode.d6.loss_dice: 0.9633  decode.d7.loss_cls: 0.0648  decode.d7.loss_mask: 0.5119  decode.d7.loss_dice: 0.9666  decode.d8.loss_cls: 0.0752  decode.d8.loss_mask: 0.5092  decode.d8.loss_dice: 0.9529
11/15 20:05:10 - mmengine - INFO - Iter(train) [75750/90000]  base_lr: 1.9038e-05 lr: 1.9038e-06  eta: 2:22:57  time: 0.5990  data_time: 0.0108  memory: 10692  grad_norm: 274.2192  loss: 16.0363  decode.loss_cls: 0.0584  decode.loss_mask: 0.4924  decode.loss_dice: 1.0246  decode.d0.loss_cls: 0.1062  decode.d0.loss_mask: 0.5036  decode.d0.loss_dice: 1.1041  decode.d1.loss_cls: 0.0666  decode.d1.loss_mask: 0.4953  decode.d1.loss_dice: 1.0545  decode.d2.loss_cls: 0.0662  decode.d2.loss_mask: 0.4798  decode.d2.loss_dice: 1.0474  decode.d3.loss_cls: 0.0497  decode.d3.loss_mask: 0.4993  decode.d3.loss_dice: 1.0437  decode.d4.loss_cls: 0.0518  decode.d4.loss_mask: 0.4909  decode.d4.loss_dice: 1.0421  decode.d5.loss_cls: 0.0561  decode.d5.loss_mask: 0.4876  decode.d5.loss_dice: 1.0351  decode.d6.loss_cls: 0.0508  decode.d6.loss_mask: 0.4977  decode.d6.loss_dice: 1.0492  decode.d7.loss_cls: 0.0564  decode.d7.loss_mask: 0.4906  decode.d7.loss_dice: 1.0369  decode.d8.loss_cls: 0.0567  decode.d8.loss_mask: 0.4902  decode.d8.loss_dice: 1.0524
11/15 20:05:40 - mmengine - INFO - Iter(train) [75800/90000]  base_lr: 1.8978e-05 lr: 1.8978e-06  eta: 2:22:27  time: 0.5984  data_time: 0.0106  memory: 10692  grad_norm: 247.0504  loss: 17.6749  decode.loss_cls: 0.0757  decode.loss_mask: 0.5379  decode.loss_dice: 1.1320  decode.d0.loss_cls: 0.0875  decode.d0.loss_mask: 0.5620  decode.d0.loss_dice: 1.1560  decode.d1.loss_cls: 0.0798  decode.d1.loss_mask: 0.5442  decode.d1.loss_dice: 1.1577  decode.d2.loss_cls: 0.0784  decode.d2.loss_mask: 0.5507  decode.d2.loss_dice: 1.1590  decode.d3.loss_cls: 0.0782  decode.d3.loss_mask: 0.5441  decode.d3.loss_dice: 1.1366  decode.d4.loss_cls: 0.0957  decode.d4.loss_mask: 0.5367  decode.d4.loss_dice: 1.1382  decode.d5.loss_cls: 0.0802  decode.d5.loss_mask: 0.5390  decode.d5.loss_dice: 1.1597  decode.d6.loss_cls: 0.0745  decode.d6.loss_mask: 0.5388  decode.d6.loss_dice: 1.1258  decode.d7.loss_cls: 0.0754  decode.d7.loss_mask: 0.5398  decode.d7.loss_dice: 1.1189  decode.d8.loss_cls: 0.0800  decode.d8.loss_mask: 0.5402  decode.d8.loss_dice: 1.1522
11/15 20:06:10 - mmengine - INFO - Iter(train) [75850/90000]  base_lr: 1.8918e-05 lr: 1.8918e-06  eta: 2:21:57  time: 0.5991  data_time: 0.0106  memory: 10656  grad_norm: 395.0275  loss: 15.4564  decode.loss_cls: 0.0702  decode.loss_mask: 0.4887  decode.loss_dice: 1.0036  decode.d0.loss_cls: 0.0971  decode.d0.loss_mask: 0.4862  decode.d0.loss_dice: 1.0428  decode.d1.loss_cls: 0.0693  decode.d1.loss_mask: 0.4869  decode.d1.loss_dice: 1.0298  decode.d2.loss_cls: 0.0620  decode.d2.loss_mask: 0.4951  decode.d2.loss_dice: 0.9847  decode.d3.loss_cls: 0.0697  decode.d3.loss_mask: 0.4890  decode.d3.loss_dice: 0.9709  decode.d4.loss_cls: 0.0747  decode.d4.loss_mask: 0.4867  decode.d4.loss_dice: 0.9803  decode.d5.loss_cls: 0.0691  decode.d5.loss_mask: 0.4911  decode.d5.loss_dice: 0.9466  decode.d6.loss_cls: 0.0579  decode.d6.loss_mask: 0.4980  decode.d6.loss_dice: 0.9805  decode.d7.loss_cls: 0.0637  decode.d7.loss_mask: 0.4956  decode.d7.loss_dice: 0.9650  decode.d8.loss_cls: 0.0653  decode.d8.loss_mask: 0.4930  decode.d8.loss_dice: 0.9427
11/15 20:06:40 - mmengine - INFO - Iter(train) [75900/90000]  base_lr: 1.8857e-05 lr: 1.8857e-06  eta: 2:21:27  time: 0.5988  data_time: 0.0107  memory: 10692  grad_norm: 366.6274  loss: 15.7243  decode.loss_cls: 0.0797  decode.loss_mask: 0.5056  decode.loss_dice: 0.9577  decode.d0.loss_cls: 0.1128  decode.d0.loss_mask: 0.5236  decode.d0.loss_dice: 1.0508  decode.d1.loss_cls: 0.0945  decode.d1.loss_mask: 0.5327  decode.d1.loss_dice: 0.9903  decode.d2.loss_cls: 0.0872  decode.d2.loss_mask: 0.5283  decode.d2.loss_dice: 0.9649  decode.d3.loss_cls: 0.0866  decode.d3.loss_mask: 0.5131  decode.d3.loss_dice: 0.9385  decode.d4.loss_cls: 0.0708  decode.d4.loss_mask: 0.5098  decode.d4.loss_dice: 0.9837  decode.d5.loss_cls: 0.0790  decode.d5.loss_mask: 0.5160  decode.d5.loss_dice: 0.9493  decode.d6.loss_cls: 0.0865  decode.d6.loss_mask: 0.5099  decode.d6.loss_dice: 0.9535  decode.d7.loss_cls: 0.0784  decode.d7.loss_mask: 0.5100  decode.d7.loss_dice: 0.9536  decode.d8.loss_cls: 0.0822  decode.d8.loss_mask: 0.5055  decode.d8.loss_dice: 0.9698
11/15 20:07:10 - mmengine - INFO - Iter(train) [75950/90000]  base_lr: 1.8797e-05 lr: 1.8797e-06  eta: 2:20:56  time: 0.5991  data_time: 0.0105  memory: 10713  grad_norm: 322.4681  loss: 14.0018  decode.loss_cls: 0.0425  decode.loss_mask: 0.4316  decode.loss_dice: 0.9065  decode.d0.loss_cls: 0.0715  decode.d0.loss_mask: 0.4802  decode.d0.loss_dice: 0.9695  decode.d1.loss_cls: 0.0457  decode.d1.loss_mask: 0.4609  decode.d1.loss_dice: 0.9341  decode.d2.loss_cls: 0.0406  decode.d2.loss_mask: 0.4422  decode.d2.loss_dice: 0.9144  decode.d3.loss_cls: 0.0363  decode.d3.loss_mask: 0.4488  decode.d3.loss_dice: 0.8925  decode.d4.loss_cls: 0.0416  decode.d4.loss_mask: 0.4265  decode.d4.loss_dice: 0.8932  decode.d5.loss_cls: 0.0409  decode.d5.loss_mask: 0.4294  decode.d5.loss_dice: 0.9039  decode.d6.loss_cls: 0.0410  decode.d6.loss_mask: 0.4282  decode.d6.loss_dice: 0.9089  decode.d7.loss_cls: 0.0378  decode.d7.loss_mask: 0.4447  decode.d7.loss_dice: 0.9043  decode.d8.loss_cls: 0.0406  decode.d8.loss_mask: 0.4476  decode.d8.loss_dice: 0.8960
11/15 20:07:44 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 20:07:44 - mmengine - INFO - Iter(train) [76000/90000]  base_lr: 1.8737e-05 lr: 1.8737e-06  eta: 2:20:27  time: 0.6016  data_time: 0.0108  memory: 10675  grad_norm: 294.5404  loss: 13.7839  decode.loss_cls: 0.0507  decode.loss_mask: 0.3771  decode.loss_dice: 0.9329  decode.d0.loss_cls: 0.0712  decode.d0.loss_mask: 0.4000  decode.d0.loss_dice: 1.0064  decode.d1.loss_cls: 0.0610  decode.d1.loss_mask: 0.3824  decode.d1.loss_dice: 0.9721  decode.d2.loss_cls: 0.0582  decode.d2.loss_mask: 0.3830  decode.d2.loss_dice: 0.9615  decode.d3.loss_cls: 0.0607  decode.d3.loss_mask: 0.3741  decode.d3.loss_dice: 0.9213  decode.d4.loss_cls: 0.0514  decode.d4.loss_mask: 0.3735  decode.d4.loss_dice: 0.9285  decode.d5.loss_cls: 0.0531  decode.d5.loss_mask: 0.3760  decode.d5.loss_dice: 0.9343  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.3762  decode.d6.loss_dice: 0.9211  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.3762  decode.d7.loss_dice: 0.9280  decode.d8.loss_cls: 0.0540  decode.d8.loss_mask: 0.3770  decode.d8.loss_dice: 0.9102
11/15 20:08:14 - mmengine - INFO - Iter(train) [76050/90000]  base_lr: 1.8677e-05 lr: 1.8677e-06  eta: 2:19:57  time: 0.5989  data_time: 0.0110  memory: 10656  grad_norm: 365.7490  loss: 17.0590  decode.loss_cls: 0.0591  decode.loss_mask: 0.5929  decode.loss_dice: 1.0345  decode.d0.loss_cls: 0.0857  decode.d0.loss_mask: 0.6023  decode.d0.loss_dice: 1.1306  decode.d1.loss_cls: 0.0859  decode.d1.loss_mask: 0.5688  decode.d1.loss_dice: 1.0772  decode.d2.loss_cls: 0.0597  decode.d2.loss_mask: 0.5961  decode.d2.loss_dice: 1.0526  decode.d3.loss_cls: 0.0584  decode.d3.loss_mask: 0.5885  decode.d3.loss_dice: 1.0363  decode.d4.loss_cls: 0.0571  decode.d4.loss_mask: 0.5573  decode.d4.loss_dice: 1.0668  decode.d5.loss_cls: 0.0545  decode.d5.loss_mask: 0.5976  decode.d5.loss_dice: 1.0383  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.6043  decode.d6.loss_dice: 1.0686  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 0.5604  decode.d7.loss_dice: 1.0320  decode.d8.loss_cls: 0.0579  decode.d8.loss_mask: 0.5899  decode.d8.loss_dice: 1.0306
11/15 20:08:44 - mmengine - INFO - Iter(train) [76100/90000]  base_lr: 1.8617e-05 lr: 1.8617e-06  eta: 2:19:27  time: 0.5984  data_time: 0.0109  memory: 10675  grad_norm: 440.6295  loss: 14.9473  decode.loss_cls: 0.0393  decode.loss_mask: 0.4442  decode.loss_dice: 0.9900  decode.d0.loss_cls: 0.0755  decode.d0.loss_mask: 0.4621  decode.d0.loss_dice: 1.0633  decode.d1.loss_cls: 0.0430  decode.d1.loss_mask: 0.4571  decode.d1.loss_dice: 1.0188  decode.d2.loss_cls: 0.0390  decode.d2.loss_mask: 0.4542  decode.d2.loss_dice: 1.0121  decode.d3.loss_cls: 0.0438  decode.d3.loss_mask: 0.4527  decode.d3.loss_dice: 1.0079  decode.d4.loss_cls: 0.0497  decode.d4.loss_mask: 0.4487  decode.d4.loss_dice: 0.9901  decode.d5.loss_cls: 0.0468  decode.d5.loss_mask: 0.4407  decode.d5.loss_dice: 0.9905  decode.d6.loss_cls: 0.0453  decode.d6.loss_mask: 0.4388  decode.d6.loss_dice: 0.9615  decode.d7.loss_cls: 0.0527  decode.d7.loss_mask: 0.4411  decode.d7.loss_dice: 0.9713  decode.d8.loss_cls: 0.0472  decode.d8.loss_mask: 0.4449  decode.d8.loss_dice: 0.9750
11/15 20:09:14 - mmengine - INFO - Iter(train) [76150/90000]  base_lr: 1.8556e-05 lr: 1.8556e-06  eta: 2:18:57  time: 0.5996  data_time: 0.0106  memory: 10713  grad_norm: 300.9196  loss: 15.3587  decode.loss_cls: 0.0580  decode.loss_mask: 0.4619  decode.loss_dice: 1.0097  decode.d0.loss_cls: 0.0934  decode.d0.loss_mask: 0.4664  decode.d0.loss_dice: 1.0736  decode.d1.loss_cls: 0.0613  decode.d1.loss_mask: 0.4601  decode.d1.loss_dice: 1.0265  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.4549  decode.d2.loss_dice: 1.0053  decode.d3.loss_cls: 0.0627  decode.d3.loss_mask: 0.4588  decode.d3.loss_dice: 0.9806  decode.d4.loss_cls: 0.0616  decode.d4.loss_mask: 0.4593  decode.d4.loss_dice: 1.0041  decode.d5.loss_cls: 0.0635  decode.d5.loss_mask: 0.4599  decode.d5.loss_dice: 1.0009  decode.d6.loss_cls: 0.0582  decode.d6.loss_mask: 0.4586  decode.d6.loss_dice: 1.0132  decode.d7.loss_cls: 0.0550  decode.d7.loss_mask: 0.4589  decode.d7.loss_dice: 1.0051  decode.d8.loss_cls: 0.0609  decode.d8.loss_mask: 0.4625  decode.d8.loss_dice: 1.0049
11/15 20:09:44 - mmengine - INFO - Iter(train) [76200/90000]  base_lr: 1.8496e-05 lr: 1.8496e-06  eta: 2:18:27  time: 0.6013  data_time: 0.0107  memory: 10713  grad_norm: 285.9696  loss: 15.3536  decode.loss_cls: 0.0587  decode.loss_mask: 0.4666  decode.loss_dice: 0.9830  decode.d0.loss_cls: 0.0920  decode.d0.loss_mask: 0.4805  decode.d0.loss_dice: 1.0790  decode.d1.loss_cls: 0.0720  decode.d1.loss_mask: 0.4714  decode.d1.loss_dice: 1.0275  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 0.4688  decode.d2.loss_dice: 1.0064  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.4632  decode.d3.loss_dice: 0.9762  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.4661  decode.d4.loss_dice: 0.9934  decode.d5.loss_cls: 0.0579  decode.d5.loss_mask: 0.4711  decode.d5.loss_dice: 1.0047  decode.d6.loss_cls: 0.0592  decode.d6.loss_mask: 0.4662  decode.d6.loss_dice: 0.9838  decode.d7.loss_cls: 0.0606  decode.d7.loss_mask: 0.4666  decode.d7.loss_dice: 0.9743  decode.d8.loss_cls: 0.0541  decode.d8.loss_mask: 0.4640  decode.d8.loss_dice: 0.9988
11/15 20:10:17 - mmengine - INFO - Iter(train) [76250/90000]  base_lr: 1.8436e-05 lr: 1.8436e-06  eta: 2:17:57  time: 0.5992  data_time: 0.0108  memory: 10675  grad_norm: 315.8343  loss: 17.0332  decode.loss_cls: 0.0522  decode.loss_mask: 0.5008  decode.loss_dice: 1.1237  decode.d0.loss_cls: 0.0908  decode.d0.loss_mask: 0.5294  decode.d0.loss_dice: 1.2057  decode.d1.loss_cls: 0.0570  decode.d1.loss_mask: 0.5057  decode.d1.loss_dice: 1.1387  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.5076  decode.d2.loss_dice: 1.1357  decode.d3.loss_cls: 0.0481  decode.d3.loss_mask: 0.5138  decode.d3.loss_dice: 1.1194  decode.d4.loss_cls: 0.0466  decode.d4.loss_mask: 0.5123  decode.d4.loss_dice: 1.1318  decode.d5.loss_cls: 0.0574  decode.d5.loss_mask: 0.5157  decode.d5.loss_dice: 1.1282  decode.d6.loss_cls: 0.0550  decode.d6.loss_mask: 0.5086  decode.d6.loss_dice: 1.1494  decode.d7.loss_cls: 0.0548  decode.d7.loss_mask: 0.4954  decode.d7.loss_dice: 1.1213  decode.d8.loss_cls: 0.0563  decode.d8.loss_mask: 0.4988  decode.d8.loss_dice: 1.1170
11/15 20:10:48 - mmengine - INFO - Iter(train) [76300/90000]  base_lr: 1.8375e-05 lr: 1.8375e-06  eta: 2:17:27  time: 0.6049  data_time: 0.0110  memory: 10675  grad_norm: 515.2815  loss: 15.9870  decode.loss_cls: 0.0751  decode.loss_mask: 0.4321  decode.loss_dice: 1.1023  decode.d0.loss_cls: 0.1067  decode.d0.loss_mask: 0.4298  decode.d0.loss_dice: 1.1906  decode.d1.loss_cls: 0.0877  decode.d1.loss_mask: 0.4411  decode.d1.loss_dice: 1.1368  decode.d2.loss_cls: 0.0895  decode.d2.loss_mask: 0.4193  decode.d2.loss_dice: 1.0663  decode.d3.loss_cls: 0.0830  decode.d3.loss_mask: 0.4109  decode.d3.loss_dice: 1.0377  decode.d4.loss_cls: 0.0811  decode.d4.loss_mask: 0.4138  decode.d4.loss_dice: 1.0721  decode.d5.loss_cls: 0.0850  decode.d5.loss_mask: 0.4116  decode.d5.loss_dice: 1.0720  decode.d6.loss_cls: 0.0787  decode.d6.loss_mask: 0.4212  decode.d6.loss_dice: 1.0723  decode.d7.loss_cls: 0.0827  decode.d7.loss_mask: 0.4355  decode.d7.loss_dice: 1.0733  decode.d8.loss_cls: 0.0788  decode.d8.loss_mask: 0.4236  decode.d8.loss_dice: 1.0763
11/15 20:11:18 - mmengine - INFO - Iter(train) [76350/90000]  base_lr: 1.8315e-05 lr: 1.8315e-06  eta: 2:16:57  time: 0.5989  data_time: 0.0107  memory: 10713  grad_norm: 279.7535  loss: 15.9838  decode.loss_cls: 0.0643  decode.loss_mask: 0.4225  decode.loss_dice: 1.0919  decode.d0.loss_cls: 0.0677  decode.d0.loss_mask: 0.4665  decode.d0.loss_dice: 1.2013  decode.d1.loss_cls: 0.0577  decode.d1.loss_mask: 0.4289  decode.d1.loss_dice: 1.1551  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 0.4205  decode.d2.loss_dice: 1.1275  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.4174  decode.d3.loss_dice: 1.0865  decode.d4.loss_cls: 0.0608  decode.d4.loss_mask: 0.4187  decode.d4.loss_dice: 1.0770  decode.d5.loss_cls: 0.0606  decode.d5.loss_mask: 0.4208  decode.d5.loss_dice: 1.0961  decode.d6.loss_cls: 0.0618  decode.d6.loss_mask: 0.4153  decode.d6.loss_dice: 1.0706  decode.d7.loss_cls: 0.0636  decode.d7.loss_mask: 0.4259  decode.d7.loss_dice: 1.0929  decode.d8.loss_cls: 0.0603  decode.d8.loss_mask: 0.4181  decode.d8.loss_dice: 1.1033
11/15 20:11:48 - mmengine - INFO - Iter(train) [76400/90000]  base_lr: 1.8255e-05 lr: 1.8255e-06  eta: 2:16:27  time: 0.5983  data_time: 0.0106  memory: 10713  grad_norm: 490.3598  loss: 13.5042  decode.loss_cls: 0.0623  decode.loss_mask: 0.3805  decode.loss_dice: 0.8811  decode.d0.loss_cls: 0.0641  decode.d0.loss_mask: 0.3952  decode.d0.loss_dice: 1.0235  decode.d1.loss_cls: 0.0417  decode.d1.loss_mask: 0.3877  decode.d1.loss_dice: 0.9625  decode.d2.loss_cls: 0.0526  decode.d2.loss_mask: 0.3765  decode.d2.loss_dice: 0.9100  decode.d3.loss_cls: 0.0451  decode.d3.loss_mask: 0.3754  decode.d3.loss_dice: 0.8998  decode.d4.loss_cls: 0.0504  decode.d4.loss_mask: 0.3804  decode.d4.loss_dice: 0.9112  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.3801  decode.d5.loss_dice: 0.9006  decode.d6.loss_cls: 0.0553  decode.d6.loss_mask: 0.3758  decode.d6.loss_dice: 0.8809  decode.d7.loss_cls: 0.0565  decode.d7.loss_mask: 0.3770  decode.d7.loss_dice: 0.8892  decode.d8.loss_cls: 0.0473  decode.d8.loss_mask: 0.3788  decode.d8.loss_dice: 0.9085
11/15 20:12:18 - mmengine - INFO - Iter(train) [76450/90000]  base_lr: 1.8194e-05 lr: 1.8194e-06  eta: 2:15:57  time: 0.5990  data_time: 0.0106  memory: 10675  grad_norm: 629.8922  loss: 16.8936  decode.loss_cls: 0.0622  decode.loss_mask: 0.5285  decode.loss_dice: 1.0841  decode.d0.loss_cls: 0.0747  decode.d0.loss_mask: 0.5596  decode.d0.loss_dice: 1.1802  decode.d1.loss_cls: 0.0543  decode.d1.loss_mask: 0.5255  decode.d1.loss_dice: 1.1122  decode.d2.loss_cls: 0.0461  decode.d2.loss_mask: 0.5238  decode.d2.loss_dice: 1.1050  decode.d3.loss_cls: 0.0560  decode.d3.loss_mask: 0.5195  decode.d3.loss_dice: 1.1070  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 0.5197  decode.d4.loss_dice: 1.0963  decode.d5.loss_cls: 0.0491  decode.d5.loss_mask: 0.5284  decode.d5.loss_dice: 1.0992  decode.d6.loss_cls: 0.0551  decode.d6.loss_mask: 0.5152  decode.d6.loss_dice: 1.0830  decode.d7.loss_cls: 0.0687  decode.d7.loss_mask: 0.5237  decode.d7.loss_dice: 1.0770  decode.d8.loss_cls: 0.0548  decode.d8.loss_mask: 0.5356  decode.d8.loss_dice: 1.0949
11/15 20:12:48 - mmengine - INFO - Iter(train) [76500/90000]  base_lr: 1.8134e-05 lr: 1.8134e-06  eta: 2:15:27  time: 0.5984  data_time: 0.0107  memory: 10656  grad_norm: 476.7564  loss: 13.8850  decode.loss_cls: 0.0375  decode.loss_mask: 0.4411  decode.loss_dice: 0.8842  decode.d0.loss_cls: 0.0689  decode.d0.loss_mask: 0.4805  decode.d0.loss_dice: 0.9484  decode.d1.loss_cls: 0.0562  decode.d1.loss_mask: 0.4498  decode.d1.loss_dice: 0.9314  decode.d2.loss_cls: 0.0555  decode.d2.loss_mask: 0.4556  decode.d2.loss_dice: 0.9012  decode.d3.loss_cls: 0.0424  decode.d3.loss_mask: 0.4421  decode.d3.loss_dice: 0.8845  decode.d4.loss_cls: 0.0534  decode.d4.loss_mask: 0.4443  decode.d4.loss_dice: 0.8567  decode.d5.loss_cls: 0.0462  decode.d5.loss_mask: 0.4498  decode.d5.loss_dice: 0.8516  decode.d6.loss_cls: 0.0316  decode.d6.loss_mask: 0.4653  decode.d6.loss_dice: 0.8860  decode.d7.loss_cls: 0.0338  decode.d7.loss_mask: 0.4627  decode.d7.loss_dice: 0.8570  decode.d8.loss_cls: 0.0391  decode.d8.loss_mask: 0.4575  decode.d8.loss_dice: 0.8704
11/15 20:13:18 - mmengine - INFO - Iter(train) [76550/90000]  base_lr: 1.8073e-05 lr: 1.8073e-06  eta: 2:14:57  time: 0.5994  data_time: 0.0105  memory: 10742  grad_norm: 265.7049  loss: 16.2142  decode.loss_cls: 0.0626  decode.loss_mask: 0.4384  decode.loss_dice: 1.1040  decode.d0.loss_cls: 0.0925  decode.d0.loss_mask: 0.4575  decode.d0.loss_dice: 1.1821  decode.d1.loss_cls: 0.0655  decode.d1.loss_mask: 0.4457  decode.d1.loss_dice: 1.1570  decode.d2.loss_cls: 0.0811  decode.d2.loss_mask: 0.4378  decode.d2.loss_dice: 1.1043  decode.d3.loss_cls: 0.0647  decode.d3.loss_mask: 0.4371  decode.d3.loss_dice: 1.1001  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.4297  decode.d4.loss_dice: 1.0918  decode.d5.loss_cls: 0.0636  decode.d5.loss_mask: 0.4361  decode.d5.loss_dice: 1.0891  decode.d6.loss_cls: 0.0673  decode.d6.loss_mask: 0.4356  decode.d6.loss_dice: 1.1045  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.4346  decode.d7.loss_dice: 1.1124  decode.d8.loss_cls: 0.0628  decode.d8.loss_mask: 0.4334  decode.d8.loss_dice: 1.0973
11/15 20:13:48 - mmengine - INFO - Iter(train) [76600/90000]  base_lr: 1.8013e-05 lr: 1.8013e-06  eta: 2:14:26  time: 0.5987  data_time: 0.0105  memory: 10728  grad_norm: 489.4402  loss: 14.9355  decode.loss_cls: 0.0529  decode.loss_mask: 0.5269  decode.loss_dice: 0.9254  decode.d0.loss_cls: 0.1002  decode.d0.loss_mask: 0.5548  decode.d0.loss_dice: 0.9353  decode.d1.loss_cls: 0.0601  decode.d1.loss_mask: 0.5417  decode.d1.loss_dice: 0.8969  decode.d2.loss_cls: 0.0490  decode.d2.loss_mask: 0.5508  decode.d2.loss_dice: 0.8991  decode.d3.loss_cls: 0.0542  decode.d3.loss_mask: 0.5332  decode.d3.loss_dice: 0.8927  decode.d4.loss_cls: 0.0505  decode.d4.loss_mask: 0.5274  decode.d4.loss_dice: 0.8773  decode.d5.loss_cls: 0.0591  decode.d5.loss_mask: 0.5386  decode.d5.loss_dice: 0.8892  decode.d6.loss_cls: 0.0449  decode.d6.loss_mask: 0.5377  decode.d6.loss_dice: 0.8926  decode.d7.loss_cls: 0.0477  decode.d7.loss_mask: 0.5293  decode.d7.loss_dice: 0.8906  decode.d8.loss_cls: 0.0511  decode.d8.loss_mask: 0.5322  decode.d8.loss_dice: 0.8941
11/15 20:14:18 - mmengine - INFO - Iter(train) [76650/90000]  base_lr: 1.7952e-05 lr: 1.7952e-06  eta: 2:13:56  time: 0.6069  data_time: 0.0111  memory: 10656  grad_norm: 348.3895  loss: 15.0436  decode.loss_cls: 0.0740  decode.loss_mask: 0.4636  decode.loss_dice: 0.9439  decode.d0.loss_cls: 0.0847  decode.d0.loss_mask: 0.4813  decode.d0.loss_dice: 1.0236  decode.d1.loss_cls: 0.0652  decode.d1.loss_mask: 0.4737  decode.d1.loss_dice: 0.9875  decode.d2.loss_cls: 0.0618  decode.d2.loss_mask: 0.4740  decode.d2.loss_dice: 1.0017  decode.d3.loss_cls: 0.0675  decode.d3.loss_mask: 0.4718  decode.d3.loss_dice: 0.9487  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.4694  decode.d4.loss_dice: 0.9487  decode.d5.loss_cls: 0.0589  decode.d5.loss_mask: 0.4709  decode.d5.loss_dice: 0.9412  decode.d6.loss_cls: 0.0647  decode.d6.loss_mask: 0.4715  decode.d6.loss_dice: 0.9624  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 0.4695  decode.d7.loss_dice: 0.9672  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.4654  decode.d8.loss_dice: 0.9501
11/15 20:14:48 - mmengine - INFO - Iter(train) [76700/90000]  base_lr: 1.7892e-05 lr: 1.7892e-06  eta: 2:13:26  time: 0.5990  data_time: 0.0107  memory: 10675  grad_norm: 227.2971  loss: 15.0706  decode.loss_cls: 0.0570  decode.loss_mask: 0.4337  decode.loss_dice: 1.0010  decode.d0.loss_cls: 0.0890  decode.d0.loss_mask: 0.4355  decode.d0.loss_dice: 1.0714  decode.d1.loss_cls: 0.0658  decode.d1.loss_mask: 0.4342  decode.d1.loss_dice: 1.0207  decode.d2.loss_cls: 0.0650  decode.d2.loss_mask: 0.4368  decode.d2.loss_dice: 1.0277  decode.d3.loss_cls: 0.0615  decode.d3.loss_mask: 0.4283  decode.d3.loss_dice: 0.9788  decode.d4.loss_cls: 0.0633  decode.d4.loss_mask: 0.4320  decode.d4.loss_dice: 1.0042  decode.d5.loss_cls: 0.0607  decode.d5.loss_mask: 0.4264  decode.d5.loss_dice: 1.0046  decode.d6.loss_cls: 0.0616  decode.d6.loss_mask: 0.4275  decode.d6.loss_dice: 1.0049  decode.d7.loss_cls: 0.0672  decode.d7.loss_mask: 0.4298  decode.d7.loss_dice: 0.9881  decode.d8.loss_cls: 0.0610  decode.d8.loss_mask: 0.4270  decode.d8.loss_dice: 1.0060
11/15 20:15:18 - mmengine - INFO - Iter(train) [76750/90000]  base_lr: 1.7831e-05 lr: 1.7831e-06  eta: 2:12:56  time: 0.5991  data_time: 0.0106  memory: 10692  grad_norm: 374.7000  loss: 17.8146  decode.loss_cls: 0.0549  decode.loss_mask: 0.5195  decode.loss_dice: 1.1471  decode.d0.loss_cls: 0.0653  decode.d0.loss_mask: 0.5666  decode.d0.loss_dice: 1.3250  decode.d1.loss_cls: 0.0590  decode.d1.loss_mask: 0.5203  decode.d1.loss_dice: 1.2114  decode.d2.loss_cls: 0.0532  decode.d2.loss_mask: 0.5444  decode.d2.loss_dice: 1.2011  decode.d3.loss_cls: 0.0535  decode.d3.loss_mask: 0.5349  decode.d3.loss_dice: 1.1739  decode.d4.loss_cls: 0.0542  decode.d4.loss_mask: 0.5350  decode.d4.loss_dice: 1.1737  decode.d5.loss_cls: 0.0504  decode.d5.loss_mask: 0.5444  decode.d5.loss_dice: 1.1740  decode.d6.loss_cls: 0.0520  decode.d6.loss_mask: 0.5429  decode.d6.loss_dice: 1.1707  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.5240  decode.d7.loss_dice: 1.1669  decode.d8.loss_cls: 0.0520  decode.d8.loss_mask: 0.5269  decode.d8.loss_dice: 1.1572
11/15 20:15:48 - mmengine - INFO - Iter(train) [76800/90000]  base_lr: 1.7771e-05 lr: 1.7771e-06  eta: 2:12:26  time: 0.6015  data_time: 0.0109  memory: 10692  grad_norm: 452.3789  loss: 13.7417  decode.loss_cls: 0.0304  decode.loss_mask: 0.4459  decode.loss_dice: 0.8674  decode.d0.loss_cls: 0.0630  decode.d0.loss_mask: 0.4628  decode.d0.loss_dice: 0.9837  decode.d1.loss_cls: 0.0367  decode.d1.loss_mask: 0.4482  decode.d1.loss_dice: 0.8837  decode.d2.loss_cls: 0.0396  decode.d2.loss_mask: 0.4479  decode.d2.loss_dice: 0.8795  decode.d3.loss_cls: 0.0316  decode.d3.loss_mask: 0.4430  decode.d3.loss_dice: 0.8656  decode.d4.loss_cls: 0.0310  decode.d4.loss_mask: 0.4456  decode.d4.loss_dice: 0.8931  decode.d5.loss_cls: 0.0350  decode.d5.loss_mask: 0.4459  decode.d5.loss_dice: 0.8766  decode.d6.loss_cls: 0.0360  decode.d6.loss_mask: 0.4482  decode.d6.loss_dice: 0.8857  decode.d7.loss_cls: 0.0330  decode.d7.loss_mask: 0.4460  decode.d7.loss_dice: 0.8869  decode.d8.loss_cls: 0.0345  decode.d8.loss_mask: 0.4481  decode.d8.loss_dice: 0.8672
11/15 20:16:18 - mmengine - INFO - Iter(train) [76850/90000]  base_lr: 1.7710e-05 lr: 1.7710e-06  eta: 2:11:56  time: 0.5981  data_time: 0.0106  memory: 10641  grad_norm: 304.3697  loss: 16.3696  decode.loss_cls: 0.0853  decode.loss_mask: 0.4045  decode.loss_dice: 1.1061  decode.d0.loss_cls: 0.1124  decode.d0.loss_mask: 0.4277  decode.d0.loss_dice: 1.2429  decode.d1.loss_cls: 0.0963  decode.d1.loss_mask: 0.4225  decode.d1.loss_dice: 1.1540  decode.d2.loss_cls: 0.0947  decode.d2.loss_mask: 0.4132  decode.d2.loss_dice: 1.2078  decode.d3.loss_cls: 0.0667  decode.d3.loss_mask: 0.4186  decode.d3.loss_dice: 1.1430  decode.d4.loss_cls: 0.0824  decode.d4.loss_mask: 0.4187  decode.d4.loss_dice: 1.0992  decode.d5.loss_cls: 0.0913  decode.d5.loss_mask: 0.4087  decode.d5.loss_dice: 1.0791  decode.d6.loss_cls: 0.0710  decode.d6.loss_mask: 0.4176  decode.d6.loss_dice: 1.1246  decode.d7.loss_cls: 0.0745  decode.d7.loss_mask: 0.4190  decode.d7.loss_dice: 1.0893  decode.d8.loss_cls: 0.0793  decode.d8.loss_mask: 0.4183  decode.d8.loss_dice: 1.1008
11/15 20:16:48 - mmengine - INFO - Iter(train) [76900/90000]  base_lr: 1.7649e-05 lr: 1.7649e-06  eta: 2:11:26  time: 0.5990  data_time: 0.0106  memory: 10713  grad_norm: 279.8227  loss: 15.9712  decode.loss_cls: 0.0431  decode.loss_mask: 0.4639  decode.loss_dice: 1.0843  decode.d0.loss_cls: 0.0869  decode.d0.loss_mask: 0.4924  decode.d0.loss_dice: 1.1353  decode.d1.loss_cls: 0.0507  decode.d1.loss_mask: 0.4624  decode.d1.loss_dice: 1.1029  decode.d2.loss_cls: 0.0539  decode.d2.loss_mask: 0.4653  decode.d2.loss_dice: 1.0845  decode.d3.loss_cls: 0.0535  decode.d3.loss_mask: 0.4633  decode.d3.loss_dice: 1.0691  decode.d4.loss_cls: 0.0503  decode.d4.loss_mask: 0.4635  decode.d4.loss_dice: 1.0694  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.4569  decode.d5.loss_dice: 1.0655  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.4617  decode.d6.loss_dice: 1.0577  decode.d7.loss_cls: 0.0561  decode.d7.loss_mask: 0.4557  decode.d7.loss_dice: 1.0458  decode.d8.loss_cls: 0.0458  decode.d8.loss_mask: 0.4632  decode.d8.loss_dice: 1.0593
11/15 20:17:18 - mmengine - INFO - Iter(train) [76950/90000]  base_lr: 1.7589e-05 lr: 1.7589e-06  eta: 2:10:56  time: 0.5997  data_time: 0.0106  memory: 10656  grad_norm: 565.7244  loss: 15.8115  decode.loss_cls: 0.0781  decode.loss_mask: 0.4417  decode.loss_dice: 1.0248  decode.d0.loss_cls: 0.1024  decode.d0.loss_mask: 0.4270  decode.d0.loss_dice: 1.1557  decode.d1.loss_cls: 0.1073  decode.d1.loss_mask: 0.4608  decode.d1.loss_dice: 1.0826  decode.d2.loss_cls: 0.0880  decode.d2.loss_mask: 0.4574  decode.d2.loss_dice: 1.0397  decode.d3.loss_cls: 0.0991  decode.d3.loss_mask: 0.4310  decode.d3.loss_dice: 0.9991  decode.d4.loss_cls: 0.0927  decode.d4.loss_mask: 0.4420  decode.d4.loss_dice: 1.0294  decode.d5.loss_cls: 0.0889  decode.d5.loss_mask: 0.4437  decode.d5.loss_dice: 1.0403  decode.d6.loss_cls: 0.0912  decode.d6.loss_mask: 0.4419  decode.d6.loss_dice: 1.0328  decode.d7.loss_cls: 0.0988  decode.d7.loss_mask: 0.4202  decode.d7.loss_dice: 1.0208  decode.d8.loss_cls: 0.0864  decode.d8.loss_mask: 0.4455  decode.d8.loss_dice: 1.0422
11/15 20:17:48 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 20:17:48 - mmengine - INFO - Iter(train) [77000/90000]  base_lr: 1.7528e-05 lr: 1.7528e-06  eta: 2:10:25  time: 0.6000  data_time: 0.0107  memory: 10675  grad_norm: 475.3921  loss: 14.9930  decode.loss_cls: 0.0445  decode.loss_mask: 0.5332  decode.loss_dice: 0.9026  decode.d0.loss_cls: 0.0873  decode.d0.loss_mask: 0.5779  decode.d0.loss_dice: 0.9244  decode.d1.loss_cls: 0.0535  decode.d1.loss_mask: 0.5415  decode.d1.loss_dice: 0.9396  decode.d2.loss_cls: 0.0562  decode.d2.loss_mask: 0.5300  decode.d2.loss_dice: 0.9083  decode.d3.loss_cls: 0.0548  decode.d3.loss_mask: 0.5254  decode.d3.loss_dice: 0.8846  decode.d4.loss_cls: 0.0478  decode.d4.loss_mask: 0.5253  decode.d4.loss_dice: 0.9236  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.5247  decode.d5.loss_dice: 0.9115  decode.d6.loss_cls: 0.0497  decode.d6.loss_mask: 0.5294  decode.d6.loss_dice: 0.9025  decode.d7.loss_cls: 0.0466  decode.d7.loss_mask: 0.5278  decode.d7.loss_dice: 0.9100  decode.d8.loss_cls: 0.0442  decode.d8.loss_mask: 0.5252  decode.d8.loss_dice: 0.9107
11/15 20:18:18 - mmengine - INFO - Iter(train) [77050/90000]  base_lr: 1.7467e-05 lr: 1.7467e-06  eta: 2:09:55  time: 0.6000  data_time: 0.0107  memory: 10675  grad_norm: 342.9774  loss: 15.7029  decode.loss_cls: 0.0685  decode.loss_mask: 0.4446  decode.loss_dice: 1.0228  decode.d0.loss_cls: 0.0883  decode.d0.loss_mask: 0.4645  decode.d0.loss_dice: 1.1320  decode.d1.loss_cls: 0.0677  decode.d1.loss_mask: 0.4462  decode.d1.loss_dice: 1.0521  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 0.4582  decode.d2.loss_dice: 1.0698  decode.d3.loss_cls: 0.0680  decode.d3.loss_mask: 0.4565  decode.d3.loss_dice: 1.0450  decode.d4.loss_cls: 0.0687  decode.d4.loss_mask: 0.4554  decode.d4.loss_dice: 1.0637  decode.d5.loss_cls: 0.0721  decode.d5.loss_mask: 0.4418  decode.d5.loss_dice: 1.0498  decode.d6.loss_cls: 0.0700  decode.d6.loss_mask: 0.4305  decode.d6.loss_dice: 1.0056  decode.d7.loss_cls: 0.0592  decode.d7.loss_mask: 0.4445  decode.d7.loss_dice: 1.0583  decode.d8.loss_cls: 0.0730  decode.d8.loss_mask: 0.4328  decode.d8.loss_dice: 1.0279
11/15 20:18:48 - mmengine - INFO - Iter(train) [77100/90000]  base_lr: 1.7407e-05 lr: 1.7407e-06  eta: 2:09:25  time: 0.6000  data_time: 0.0106  memory: 10728  grad_norm: 273.6553  loss: 14.2580  decode.loss_cls: 0.0666  decode.loss_mask: 0.3811  decode.loss_dice: 0.9697  decode.d0.loss_cls: 0.0748  decode.d0.loss_mask: 0.4191  decode.d0.loss_dice: 1.0677  decode.d1.loss_cls: 0.0647  decode.d1.loss_mask: 0.3847  decode.d1.loss_dice: 0.9913  decode.d2.loss_cls: 0.0773  decode.d2.loss_mask: 0.3781  decode.d2.loss_dice: 0.9568  decode.d3.loss_cls: 0.0761  decode.d3.loss_mask: 0.3742  decode.d3.loss_dice: 0.9525  decode.d4.loss_cls: 0.0806  decode.d4.loss_mask: 0.3768  decode.d4.loss_dice: 0.9417  decode.d5.loss_cls: 0.0758  decode.d5.loss_mask: 0.3894  decode.d5.loss_dice: 0.9469  decode.d6.loss_cls: 0.0752  decode.d6.loss_mask: 0.3857  decode.d6.loss_dice: 0.9634  decode.d7.loss_cls: 0.0729  decode.d7.loss_mask: 0.3833  decode.d7.loss_dice: 0.9267  decode.d8.loss_cls: 0.0688  decode.d8.loss_mask: 0.3834  decode.d8.loss_dice: 0.9528
11/15 20:19:18 - mmengine - INFO - Iter(train) [77150/90000]  base_lr: 1.7346e-05 lr: 1.7346e-06  eta: 2:08:55  time: 0.5979  data_time: 0.0108  memory: 10656  grad_norm: 786.4639  loss: 15.6453  decode.loss_cls: 0.0540  decode.loss_mask: 0.5354  decode.loss_dice: 0.9555  decode.d0.loss_cls: 0.0929  decode.d0.loss_mask: 0.5722  decode.d0.loss_dice: 1.0009  decode.d1.loss_cls: 0.0500  decode.d1.loss_mask: 0.5597  decode.d1.loss_dice: 0.9982  decode.d2.loss_cls: 0.0615  decode.d2.loss_mask: 0.5425  decode.d2.loss_dice: 0.9627  decode.d3.loss_cls: 0.0523  decode.d3.loss_mask: 0.5428  decode.d3.loss_dice: 0.9619  decode.d4.loss_cls: 0.0557  decode.d4.loss_mask: 0.5387  decode.d4.loss_dice: 0.9722  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.5296  decode.d5.loss_dice: 0.9494  decode.d6.loss_cls: 0.0596  decode.d6.loss_mask: 0.5300  decode.d6.loss_dice: 0.9504  decode.d7.loss_cls: 0.0541  decode.d7.loss_mask: 0.5339  decode.d7.loss_dice: 0.9527  decode.d8.loss_cls: 0.0516  decode.d8.loss_mask: 0.5351  decode.d8.loss_dice: 0.9358
11/15 20:19:49 - mmengine - INFO - Iter(train) [77200/90000]  base_lr: 1.7285e-05 lr: 1.7285e-06  eta: 2:08:25  time: 0.5993  data_time: 0.0105  memory: 10692  grad_norm: 668.3510  loss: 13.5424  decode.loss_cls: 0.0514  decode.loss_mask: 0.3413  decode.loss_dice: 0.9122  decode.d0.loss_cls: 0.0926  decode.d0.loss_mask: 0.3590  decode.d0.loss_dice: 1.0293  decode.d1.loss_cls: 0.0466  decode.d1.loss_mask: 0.3541  decode.d1.loss_dice: 0.9772  decode.d2.loss_cls: 0.0541  decode.d2.loss_mask: 0.3436  decode.d2.loss_dice: 0.9511  decode.d3.loss_cls: 0.0525  decode.d3.loss_mask: 0.3409  decode.d3.loss_dice: 0.9457  decode.d4.loss_cls: 0.0475  decode.d4.loss_mask: 0.3436  decode.d4.loss_dice: 0.9264  decode.d5.loss_cls: 0.0487  decode.d5.loss_mask: 0.3420  decode.d5.loss_dice: 0.9464  decode.d6.loss_cls: 0.0446  decode.d6.loss_mask: 0.3452  decode.d6.loss_dice: 0.9794  decode.d7.loss_cls: 0.0452  decode.d7.loss_mask: 0.3416  decode.d7.loss_dice: 0.9347  decode.d8.loss_cls: 0.0546  decode.d8.loss_mask: 0.3444  decode.d8.loss_dice: 0.9465
11/15 20:20:19 - mmengine - INFO - Iter(train) [77250/90000]  base_lr: 1.7224e-05 lr: 1.7224e-06  eta: 2:07:55  time: 0.5984  data_time: 0.0106  memory: 10692  grad_norm: 673.0925  loss: 15.4668  decode.loss_cls: 0.0467  decode.loss_mask: 0.5340  decode.loss_dice: 0.9432  decode.d0.loss_cls: 0.1046  decode.d0.loss_mask: 0.6002  decode.d0.loss_dice: 1.0074  decode.d1.loss_cls: 0.0752  decode.d1.loss_mask: 0.5494  decode.d1.loss_dice: 0.9439  decode.d2.loss_cls: 0.0519  decode.d2.loss_mask: 0.5574  decode.d2.loss_dice: 0.9511  decode.d3.loss_cls: 0.0502  decode.d3.loss_mask: 0.5440  decode.d3.loss_dice: 0.9319  decode.d4.loss_cls: 0.0506  decode.d4.loss_mask: 0.5442  decode.d4.loss_dice: 0.9267  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.5446  decode.d5.loss_dice: 0.9411  decode.d6.loss_cls: 0.0413  decode.d6.loss_mask: 0.5446  decode.d6.loss_dice: 0.9190  decode.d7.loss_cls: 0.0481  decode.d7.loss_mask: 0.5327  decode.d7.loss_dice: 0.9170  decode.d8.loss_cls: 0.0477  decode.d8.loss_mask: 0.5365  decode.d8.loss_dice: 0.9341
11/15 20:20:49 - mmengine - INFO - Iter(train) [77300/90000]  base_lr: 1.7164e-05 lr: 1.7164e-06  eta: 2:07:25  time: 0.6012  data_time: 0.0107  memory: 10713  grad_norm: 263.5833  loss: 14.8304  decode.loss_cls: 0.0586  decode.loss_mask: 0.4035  decode.loss_dice: 1.0256  decode.d0.loss_cls: 0.0815  decode.d0.loss_mask: 0.4092  decode.d0.loss_dice: 1.0885  decode.d1.loss_cls: 0.0737  decode.d1.loss_mask: 0.4043  decode.d1.loss_dice: 1.0150  decode.d2.loss_cls: 0.0585  decode.d2.loss_mask: 0.4074  decode.d2.loss_dice: 1.0023  decode.d3.loss_cls: 0.0573  decode.d3.loss_mask: 0.4054  decode.d3.loss_dice: 1.0214  decode.d4.loss_cls: 0.0550  decode.d4.loss_mask: 0.4019  decode.d4.loss_dice: 0.9869  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 0.4011  decode.d5.loss_dice: 1.0107  decode.d6.loss_cls: 0.0631  decode.d6.loss_mask: 0.4011  decode.d6.loss_dice: 1.0033  decode.d7.loss_cls: 0.0521  decode.d7.loss_mask: 0.4148  decode.d7.loss_dice: 0.9907  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.4110  decode.d8.loss_dice: 1.0138
11/15 20:21:19 - mmengine - INFO - Iter(train) [77350/90000]  base_lr: 1.7103e-05 lr: 1.7103e-06  eta: 2:06:55  time: 0.6000  data_time: 0.0111  memory: 10675  grad_norm: 242.8070  loss: 14.3839  decode.loss_cls: 0.0438  decode.loss_mask: 0.4045  decode.loss_dice: 0.9655  decode.d0.loss_cls: 0.0898  decode.d0.loss_mask: 0.4185  decode.d0.loss_dice: 1.0315  decode.d1.loss_cls: 0.0568  decode.d1.loss_mask: 0.4130  decode.d1.loss_dice: 0.9959  decode.d2.loss_cls: 0.0609  decode.d2.loss_mask: 0.4047  decode.d2.loss_dice: 0.9857  decode.d3.loss_cls: 0.0494  decode.d3.loss_mask: 0.4046  decode.d3.loss_dice: 0.9790  decode.d4.loss_cls: 0.0556  decode.d4.loss_mask: 0.4059  decode.d4.loss_dice: 0.9790  decode.d5.loss_cls: 0.0567  decode.d5.loss_mask: 0.4048  decode.d5.loss_dice: 0.9613  decode.d6.loss_cls: 0.0567  decode.d6.loss_mask: 0.4024  decode.d6.loss_dice: 0.9374  decode.d7.loss_cls: 0.0523  decode.d7.loss_mask: 0.4007  decode.d7.loss_dice: 0.9501  decode.d8.loss_cls: 0.0537  decode.d8.loss_mask: 0.4045  decode.d8.loss_dice: 0.9594
11/15 20:21:49 - mmengine - INFO - Iter(train) [77400/90000]  base_lr: 1.7042e-05 lr: 1.7042e-06  eta: 2:06:25  time: 0.5993  data_time: 0.0105  memory: 10675  grad_norm: 497.9424  loss: 15.0992  decode.loss_cls: 0.0486  decode.loss_mask: 0.4576  decode.loss_dice: 1.0101  decode.d0.loss_cls: 0.0754  decode.d0.loss_mask: 0.4744  decode.d0.loss_dice: 1.0510  decode.d1.loss_cls: 0.0530  decode.d1.loss_mask: 0.4558  decode.d1.loss_dice: 0.9964  decode.d2.loss_cls: 0.0509  decode.d2.loss_mask: 0.4551  decode.d2.loss_dice: 0.9778  decode.d3.loss_cls: 0.0502  decode.d3.loss_mask: 0.4481  decode.d3.loss_dice: 1.0069  decode.d4.loss_cls: 0.0423  decode.d4.loss_mask: 0.4528  decode.d4.loss_dice: 1.0139  decode.d5.loss_cls: 0.0503  decode.d5.loss_mask: 0.4542  decode.d5.loss_dice: 0.9942  decode.d6.loss_cls: 0.0356  decode.d6.loss_mask: 0.4498  decode.d6.loss_dice: 0.9905  decode.d7.loss_cls: 0.0465  decode.d7.loss_mask: 0.4550  decode.d7.loss_dice: 1.0073  decode.d8.loss_cls: 0.0425  decode.d8.loss_mask: 0.4522  decode.d8.loss_dice: 1.0009
11/15 20:22:19 - mmengine - INFO - Iter(train) [77450/90000]  base_lr: 1.6981e-05 lr: 1.6981e-06  eta: 2:05:55  time: 0.5987  data_time: 0.0106  memory: 10692  grad_norm: 388.2250  loss: 16.0849  decode.loss_cls: 0.0608  decode.loss_mask: 0.4731  decode.loss_dice: 1.0447  decode.d0.loss_cls: 0.0863  decode.d0.loss_mask: 0.4830  decode.d0.loss_dice: 1.1114  decode.d1.loss_cls: 0.0638  decode.d1.loss_mask: 0.4764  decode.d1.loss_dice: 1.0954  decode.d2.loss_cls: 0.0667  decode.d2.loss_mask: 0.4729  decode.d2.loss_dice: 1.0613  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 0.4720  decode.d3.loss_dice: 1.0485  decode.d4.loss_cls: 0.0640  decode.d4.loss_mask: 0.4740  decode.d4.loss_dice: 1.0757  decode.d5.loss_cls: 0.0566  decode.d5.loss_mask: 0.4737  decode.d5.loss_dice: 1.0324  decode.d6.loss_cls: 0.0576  decode.d6.loss_mask: 0.4797  decode.d6.loss_dice: 1.0703  decode.d7.loss_cls: 0.0671  decode.d7.loss_mask: 0.4795  decode.d7.loss_dice: 1.0815  decode.d8.loss_cls: 0.0674  decode.d8.loss_mask: 0.4728  decode.d8.loss_dice: 1.0503
11/15 20:22:49 - mmengine - INFO - Iter(train) [77500/90000]  base_lr: 1.6920e-05 lr: 1.6920e-06  eta: 2:05:24  time: 0.5997  data_time: 0.0106  memory: 10713  grad_norm: 190.3464  loss: 14.4303  decode.loss_cls: 0.0486  decode.loss_mask: 0.3806  decode.loss_dice: 0.9833  decode.d0.loss_cls: 0.0786  decode.d0.loss_mask: 0.3933  decode.d0.loss_dice: 1.0676  decode.d1.loss_cls: 0.0581  decode.d1.loss_mask: 0.3830  decode.d1.loss_dice: 1.0247  decode.d2.loss_cls: 0.0537  decode.d2.loss_mask: 0.3801  decode.d2.loss_dice: 0.9945  decode.d3.loss_cls: 0.0542  decode.d3.loss_mask: 0.3784  decode.d3.loss_dice: 1.0130  decode.d4.loss_cls: 0.0522  decode.d4.loss_mask: 0.3777  decode.d4.loss_dice: 1.0053  decode.d5.loss_cls: 0.0513  decode.d5.loss_mask: 0.3804  decode.d5.loss_dice: 1.0043  decode.d6.loss_cls: 0.0486  decode.d6.loss_mask: 0.3787  decode.d6.loss_dice: 0.9968  decode.d7.loss_cls: 0.0502  decode.d7.loss_mask: 0.3764  decode.d7.loss_dice: 0.9764  decode.d8.loss_cls: 0.0538  decode.d8.loss_mask: 0.3783  decode.d8.loss_dice: 1.0083
11/15 20:23:19 - mmengine - INFO - Iter(train) [77550/90000]  base_lr: 1.6859e-05 lr: 1.6859e-06  eta: 2:04:54  time: 0.5986  data_time: 0.0106  memory: 10742  grad_norm: 489.0451  loss: 15.7216  decode.loss_cls: 0.0652  decode.loss_mask: 0.5258  decode.loss_dice: 0.9694  decode.d0.loss_cls: 0.0739  decode.d0.loss_mask: 0.6395  decode.d0.loss_dice: 1.0481  decode.d1.loss_cls: 0.0589  decode.d1.loss_mask: 0.5352  decode.d1.loss_dice: 0.9884  decode.d2.loss_cls: 0.0709  decode.d2.loss_mask: 0.5353  decode.d2.loss_dice: 0.9707  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.5306  decode.d3.loss_dice: 0.9558  decode.d4.loss_cls: 0.0564  decode.d4.loss_mask: 0.5300  decode.d4.loss_dice: 0.9764  decode.d5.loss_cls: 0.0561  decode.d5.loss_mask: 0.5233  decode.d5.loss_dice: 0.9482  decode.d6.loss_cls: 0.0557  decode.d6.loss_mask: 0.5316  decode.d6.loss_dice: 0.9333  decode.d7.loss_cls: 0.0674  decode.d7.loss_mask: 0.5299  decode.d7.loss_dice: 0.9456  decode.d8.loss_cls: 0.0611  decode.d8.loss_mask: 0.5276  decode.d8.loss_dice: 0.9534
11/15 20:23:49 - mmengine - INFO - Iter(train) [77600/90000]  base_lr: 1.6798e-05 lr: 1.6798e-06  eta: 2:04:24  time: 0.5982  data_time: 0.0103  memory: 10692  grad_norm: 664.8985  loss: 16.7004  decode.loss_cls: 0.0821  decode.loss_mask: 0.5401  decode.loss_dice: 1.0250  decode.d0.loss_cls: 0.0958  decode.d0.loss_mask: 0.5791  decode.d0.loss_dice: 1.0933  decode.d1.loss_cls: 0.0825  decode.d1.loss_mask: 0.5468  decode.d1.loss_dice: 1.0924  decode.d2.loss_cls: 0.0948  decode.d2.loss_mask: 0.5362  decode.d2.loss_dice: 1.0443  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.5445  decode.d3.loss_dice: 1.0534  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 0.5400  decode.d4.loss_dice: 1.0163  decode.d5.loss_cls: 0.0772  decode.d5.loss_mask: 0.5381  decode.d5.loss_dice: 1.0376  decode.d6.loss_cls: 0.0744  decode.d6.loss_mask: 0.5402  decode.d6.loss_dice: 1.0357  decode.d7.loss_cls: 0.0815  decode.d7.loss_mask: 0.5391  decode.d7.loss_dice: 1.0299  decode.d8.loss_cls: 0.0808  decode.d8.loss_mask: 0.5340  decode.d8.loss_dice: 1.0165
11/15 20:24:19 - mmengine - INFO - Iter(train) [77650/90000]  base_lr: 1.6737e-05 lr: 1.6737e-06  eta: 2:03:54  time: 0.5980  data_time: 0.0106  memory: 10742  grad_norm: 311.2588  loss: 14.7480  decode.loss_cls: 0.0460  decode.loss_mask: 0.5085  decode.loss_dice: 0.9131  decode.d0.loss_cls: 0.0652  decode.d0.loss_mask: 0.5512  decode.d0.loss_dice: 0.9755  decode.d1.loss_cls: 0.0373  decode.d1.loss_mask: 0.5361  decode.d1.loss_dice: 0.9572  decode.d2.loss_cls: 0.0467  decode.d2.loss_mask: 0.5290  decode.d2.loss_dice: 0.9190  decode.d3.loss_cls: 0.0487  decode.d3.loss_mask: 0.4902  decode.d3.loss_dice: 0.8856  decode.d4.loss_cls: 0.0485  decode.d4.loss_mask: 0.4972  decode.d4.loss_dice: 0.9082  decode.d5.loss_cls: 0.0529  decode.d5.loss_mask: 0.4922  decode.d5.loss_dice: 0.8853  decode.d6.loss_cls: 0.0487  decode.d6.loss_mask: 0.4923  decode.d6.loss_dice: 0.8899  decode.d7.loss_cls: 0.0469  decode.d7.loss_mask: 0.5023  decode.d7.loss_dice: 0.9019  decode.d8.loss_cls: 0.0469  decode.d8.loss_mask: 0.5094  decode.d8.loss_dice: 0.9157
11/15 20:24:49 - mmengine - INFO - Iter(train) [77700/90000]  base_lr: 1.6676e-05 lr: 1.6676e-06  eta: 2:03:24  time: 0.5996  data_time: 0.0108  memory: 10692  grad_norm: 379.7310  loss: 15.8300  decode.loss_cls: 0.0867  decode.loss_mask: 0.4557  decode.loss_dice: 1.0047  decode.d0.loss_cls: 0.0829  decode.d0.loss_mask: 0.4948  decode.d0.loss_dice: 1.1852  decode.d1.loss_cls: 0.1000  decode.d1.loss_mask: 0.4538  decode.d1.loss_dice: 1.0646  decode.d2.loss_cls: 0.1070  decode.d2.loss_mask: 0.4449  decode.d2.loss_dice: 1.0161  decode.d3.loss_cls: 0.0937  decode.d3.loss_mask: 0.4488  decode.d3.loss_dice: 0.9887  decode.d4.loss_cls: 0.0890  decode.d4.loss_mask: 0.4455  decode.d4.loss_dice: 1.0310  decode.d5.loss_cls: 0.0771  decode.d5.loss_mask: 0.4520  decode.d5.loss_dice: 1.0246  decode.d6.loss_cls: 0.0848  decode.d6.loss_mask: 0.4544  decode.d6.loss_dice: 1.0111  decode.d7.loss_cls: 0.0893  decode.d7.loss_mask: 0.4577  decode.d7.loss_dice: 1.0301  decode.d8.loss_cls: 0.0928  decode.d8.loss_mask: 0.4621  decode.d8.loss_dice: 1.0011
11/15 20:25:19 - mmengine - INFO - Iter(train) [77750/90000]  base_lr: 1.6615e-05 lr: 1.6615e-06  eta: 2:02:54  time: 0.5989  data_time: 0.0107  memory: 10656  grad_norm: 362.7631  loss: 15.1131  decode.loss_cls: 0.0599  decode.loss_mask: 0.4396  decode.loss_dice: 0.9873  decode.d0.loss_cls: 0.0920  decode.d0.loss_mask: 0.4694  decode.d0.loss_dice: 1.0431  decode.d1.loss_cls: 0.0612  decode.d1.loss_mask: 0.4859  decode.d1.loss_dice: 1.0297  decode.d2.loss_cls: 0.0550  decode.d2.loss_mask: 0.4434  decode.d2.loss_dice: 1.0056  decode.d3.loss_cls: 0.0466  decode.d3.loss_mask: 0.4447  decode.d3.loss_dice: 1.0012  decode.d4.loss_cls: 0.0507  decode.d4.loss_mask: 0.4452  decode.d4.loss_dice: 0.9967  decode.d5.loss_cls: 0.0571  decode.d5.loss_mask: 0.4416  decode.d5.loss_dice: 0.9761  decode.d6.loss_cls: 0.0549  decode.d6.loss_mask: 0.4429  decode.d6.loss_dice: 1.0106  decode.d7.loss_cls: 0.0538  decode.d7.loss_mask: 0.4520  decode.d7.loss_dice: 1.0051  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.4367  decode.d8.loss_dice: 0.9733
11/15 20:25:49 - mmengine - INFO - Iter(train) [77800/90000]  base_lr: 1.6554e-05 lr: 1.6554e-06  eta: 2:02:24  time: 0.5992  data_time: 0.0106  memory: 10713  grad_norm: 221.6550  loss: 13.8328  decode.loss_cls: 0.0583  decode.loss_mask: 0.3605  decode.loss_dice: 0.9392  decode.d0.loss_cls: 0.0786  decode.d0.loss_mask: 0.3748  decode.d0.loss_dice: 1.0626  decode.d1.loss_cls: 0.0524  decode.d1.loss_mask: 0.3686  decode.d1.loss_dice: 0.9718  decode.d2.loss_cls: 0.0587  decode.d2.loss_mask: 0.3675  decode.d2.loss_dice: 0.9464  decode.d3.loss_cls: 0.0669  decode.d3.loss_mask: 0.3627  decode.d3.loss_dice: 0.9341  decode.d4.loss_cls: 0.0579  decode.d4.loss_mask: 0.3684  decode.d4.loss_dice: 0.9349  decode.d5.loss_cls: 0.0612  decode.d5.loss_mask: 0.3701  decode.d5.loss_dice: 0.9624  decode.d6.loss_cls: 0.0555  decode.d6.loss_mask: 0.3605  decode.d6.loss_dice: 0.9405  decode.d7.loss_cls: 0.0613  decode.d7.loss_mask: 0.3628  decode.d7.loss_dice: 0.9422  decode.d8.loss_cls: 0.0621  decode.d8.loss_mask: 0.3653  decode.d8.loss_dice: 0.9246
11/15 20:26:19 - mmengine - INFO - Iter(train) [77850/90000]  base_lr: 1.6493e-05 lr: 1.6493e-06  eta: 2:01:54  time: 0.5996  data_time: 0.0107  memory: 10692  grad_norm: 296.0746  loss: 15.7923  decode.loss_cls: 0.0800  decode.loss_mask: 0.4269  decode.loss_dice: 1.0157  decode.d0.loss_cls: 0.0918  decode.d0.loss_mask: 0.4445  decode.d0.loss_dice: 1.0989  decode.d1.loss_cls: 0.0626  decode.d1.loss_mask: 0.4373  decode.d1.loss_dice: 1.1221  decode.d2.loss_cls: 0.0757  decode.d2.loss_mask: 0.4358  decode.d2.loss_dice: 1.1010  decode.d3.loss_cls: 0.0737  decode.d3.loss_mask: 0.4281  decode.d3.loss_dice: 1.0472  decode.d4.loss_cls: 0.0756  decode.d4.loss_mask: 0.4283  decode.d4.loss_dice: 1.0494  decode.d5.loss_cls: 0.0830  decode.d5.loss_mask: 0.4314  decode.d5.loss_dice: 1.0834  decode.d6.loss_cls: 0.0775  decode.d6.loss_mask: 0.4294  decode.d6.loss_dice: 1.0721  decode.d7.loss_cls: 0.0688  decode.d7.loss_mask: 0.4265  decode.d7.loss_dice: 1.0492  decode.d8.loss_cls: 0.0669  decode.d8.loss_mask: 0.4296  decode.d8.loss_dice: 1.0798
11/15 20:26:49 - mmengine - INFO - Iter(train) [77900/90000]  base_lr: 1.6432e-05 lr: 1.6432e-06  eta: 2:01:23  time: 0.5987  data_time: 0.0105  memory: 10713  grad_norm: 284.9494  loss: 13.9660  decode.loss_cls: 0.0857  decode.loss_mask: 0.4226  decode.loss_dice: 0.8819  decode.d0.loss_cls: 0.0966  decode.d0.loss_mask: 0.4283  decode.d0.loss_dice: 0.9592  decode.d1.loss_cls: 0.0919  decode.d1.loss_mask: 0.4280  decode.d1.loss_dice: 0.8899  decode.d2.loss_cls: 0.0914  decode.d2.loss_mask: 0.4334  decode.d2.loss_dice: 0.8812  decode.d3.loss_cls: 0.0736  decode.d3.loss_mask: 0.4353  decode.d3.loss_dice: 0.8870  decode.d4.loss_cls: 0.0885  decode.d4.loss_mask: 0.4212  decode.d4.loss_dice: 0.8322  decode.d5.loss_cls: 0.0836  decode.d5.loss_mask: 0.4308  decode.d5.loss_dice: 0.8644  decode.d6.loss_cls: 0.0959  decode.d6.loss_mask: 0.4328  decode.d6.loss_dice: 0.8441  decode.d7.loss_cls: 0.0834  decode.d7.loss_mask: 0.4269  decode.d7.loss_dice: 0.8712  decode.d8.loss_cls: 0.0869  decode.d8.loss_mask: 0.4287  decode.d8.loss_dice: 0.8897
11/15 20:27:19 - mmengine - INFO - Iter(train) [77950/90000]  base_lr: 1.6371e-05 lr: 1.6371e-06  eta: 2:00:53  time: 0.5996  data_time: 0.0106  memory: 10692  grad_norm: 547.7316  loss: 17.3683  decode.loss_cls: 0.0502  decode.loss_mask: 0.5543  decode.loss_dice: 1.1201  decode.d0.loss_cls: 0.0714  decode.d0.loss_mask: 0.5593  decode.d0.loss_dice: 1.1810  decode.d1.loss_cls: 0.0717  decode.d1.loss_mask: 0.5653  decode.d1.loss_dice: 1.1710  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.5612  decode.d2.loss_dice: 1.1314  decode.d3.loss_cls: 0.0478  decode.d3.loss_mask: 0.5613  decode.d3.loss_dice: 1.1193  decode.d4.loss_cls: 0.0483  decode.d4.loss_mask: 0.5570  decode.d4.loss_dice: 1.1009  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.5570  decode.d5.loss_dice: 1.1004  decode.d6.loss_cls: 0.0477  decode.d6.loss_mask: 0.5615  decode.d6.loss_dice: 1.1150  decode.d7.loss_cls: 0.0480  decode.d7.loss_mask: 0.5525  decode.d7.loss_dice: 1.1018  decode.d8.loss_cls: 0.0544  decode.d8.loss_mask: 0.5543  decode.d8.loss_dice: 1.0996
11/15 20:27:49 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 20:27:49 - mmengine - INFO - Iter(train) [78000/90000]  base_lr: 1.6310e-05 lr: 1.6310e-06  eta: 2:00:23  time: 0.5995  data_time: 0.0108  memory: 10675  grad_norm: 528.7946  loss: 15.2087  decode.loss_cls: 0.0861  decode.loss_mask: 0.4397  decode.loss_dice: 1.0000  decode.d0.loss_cls: 0.0942  decode.d0.loss_mask: 0.4647  decode.d0.loss_dice: 1.1170  decode.d1.loss_cls: 0.0688  decode.d1.loss_mask: 0.4455  decode.d1.loss_dice: 1.0314  decode.d2.loss_cls: 0.0777  decode.d2.loss_mask: 0.4250  decode.d2.loss_dice: 1.0046  decode.d3.loss_cls: 0.0761  decode.d3.loss_mask: 0.4465  decode.d3.loss_dice: 0.9800  decode.d4.loss_cls: 0.0762  decode.d4.loss_mask: 0.4394  decode.d4.loss_dice: 0.9878  decode.d5.loss_cls: 0.0648  decode.d5.loss_mask: 0.4417  decode.d5.loss_dice: 1.0032  decode.d6.loss_cls: 0.0747  decode.d6.loss_mask: 0.4382  decode.d6.loss_dice: 0.9899  decode.d7.loss_cls: 0.0756  decode.d7.loss_mask: 0.4250  decode.d7.loss_dice: 0.9646  decode.d8.loss_cls: 0.0825  decode.d8.loss_mask: 0.4060  decode.d8.loss_dice: 0.9818
11/15 20:28:19 - mmengine - INFO - Iter(train) [78050/90000]  base_lr: 1.6249e-05 lr: 1.6249e-06  eta: 1:59:53  time: 0.5986  data_time: 0.0105  memory: 10641  grad_norm: 500.8717  loss: 14.2125  decode.loss_cls: 0.0468  decode.loss_mask: 0.4497  decode.loss_dice: 0.8825  decode.d0.loss_cls: 0.0931  decode.d0.loss_mask: 0.4842  decode.d0.loss_dice: 0.9619  decode.d1.loss_cls: 0.0621  decode.d1.loss_mask: 0.4595  decode.d1.loss_dice: 0.9289  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 0.4568  decode.d2.loss_dice: 0.9189  decode.d3.loss_cls: 0.0599  decode.d3.loss_mask: 0.4560  decode.d3.loss_dice: 0.9051  decode.d4.loss_cls: 0.0520  decode.d4.loss_mask: 0.4527  decode.d4.loss_dice: 0.8996  decode.d5.loss_cls: 0.0478  decode.d5.loss_mask: 0.4525  decode.d5.loss_dice: 0.9096  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.4524  decode.d6.loss_dice: 0.8952  decode.d7.loss_cls: 0.0462  decode.d7.loss_mask: 0.4506  decode.d7.loss_dice: 0.9087  decode.d8.loss_cls: 0.0533  decode.d8.loss_mask: 0.4450  decode.d8.loss_dice: 0.8741
11/15 20:28:49 - mmengine - INFO - Iter(train) [78100/90000]  base_lr: 1.6187e-05 lr: 1.6187e-06  eta: 1:59:23  time: 0.5978  data_time: 0.0104  memory: 10675  grad_norm: 315.6544  loss: 15.2725  decode.loss_cls: 0.0478  decode.loss_mask: 0.4942  decode.loss_dice: 0.9460  decode.d0.loss_cls: 0.0885  decode.d0.loss_mask: 0.4800  decode.d0.loss_dice: 1.0167  decode.d1.loss_cls: 0.0539  decode.d1.loss_mask: 0.5114  decode.d1.loss_dice: 0.9802  decode.d2.loss_cls: 0.0535  decode.d2.loss_mask: 0.5143  decode.d2.loss_dice: 0.9872  decode.d3.loss_cls: 0.0421  decode.d3.loss_mask: 0.5063  decode.d3.loss_dice: 0.9477  decode.d4.loss_cls: 0.0430  decode.d4.loss_mask: 0.5216  decode.d4.loss_dice: 0.9568  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.5523  decode.d5.loss_dice: 0.9633  decode.d6.loss_cls: 0.0448  decode.d6.loss_mask: 0.4840  decode.d6.loss_dice: 0.9627  decode.d7.loss_cls: 0.0414  decode.d7.loss_mask: 0.4954  decode.d7.loss_dice: 0.9691  decode.d8.loss_cls: 0.0594  decode.d8.loss_mask: 0.4766  decode.d8.loss_dice: 0.9823
11/15 20:29:19 - mmengine - INFO - Iter(train) [78150/90000]  base_lr: 1.6126e-05 lr: 1.6126e-06  eta: 1:58:53  time: 0.6014  data_time: 0.0108  memory: 10675  grad_norm: 464.1027  loss: 16.4158  decode.loss_cls: 0.0591  decode.loss_mask: 0.5355  decode.loss_dice: 1.0395  decode.d0.loss_cls: 0.0845  decode.d0.loss_mask: 0.5676  decode.d0.loss_dice: 1.0681  decode.d1.loss_cls: 0.0432  decode.d1.loss_mask: 0.5519  decode.d1.loss_dice: 1.0699  decode.d2.loss_cls: 0.0542  decode.d2.loss_mask: 0.5377  decode.d2.loss_dice: 1.0547  decode.d3.loss_cls: 0.0467  decode.d3.loss_mask: 0.5374  decode.d3.loss_dice: 1.0388  decode.d4.loss_cls: 0.0456  decode.d4.loss_mask: 0.5345  decode.d4.loss_dice: 1.0337  decode.d5.loss_cls: 0.0508  decode.d5.loss_mask: 0.5323  decode.d5.loss_dice: 1.0509  decode.d6.loss_cls: 0.0526  decode.d6.loss_mask: 0.5328  decode.d6.loss_dice: 1.0237  decode.d7.loss_cls: 0.0499  decode.d7.loss_mask: 0.5320  decode.d7.loss_dice: 1.0595  decode.d8.loss_cls: 0.0507  decode.d8.loss_mask: 0.5372  decode.d8.loss_dice: 1.0406
11/15 20:29:49 - mmengine - INFO - Iter(train) [78200/90000]  base_lr: 1.6065e-05 lr: 1.6065e-06  eta: 1:58:23  time: 0.5979  data_time: 0.0104  memory: 10692  grad_norm: 333.9957  loss: 15.7204  decode.loss_cls: 0.0613  decode.loss_mask: 0.5038  decode.loss_dice: 0.9914  decode.d0.loss_cls: 0.0700  decode.d0.loss_mask: 0.5432  decode.d0.loss_dice: 1.0557  decode.d1.loss_cls: 0.0511  decode.d1.loss_mask: 0.5088  decode.d1.loss_dice: 1.0087  decode.d2.loss_cls: 0.0646  decode.d2.loss_mask: 0.4981  decode.d2.loss_dice: 0.9883  decode.d3.loss_cls: 0.0701  decode.d3.loss_mask: 0.5038  decode.d3.loss_dice: 1.0098  decode.d4.loss_cls: 0.0703  decode.d4.loss_mask: 0.5028  decode.d4.loss_dice: 0.9769  decode.d5.loss_cls: 0.0626  decode.d5.loss_mask: 0.5035  decode.d5.loss_dice: 1.0017  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.5071  decode.d6.loss_dice: 0.9882  decode.d7.loss_cls: 0.0579  decode.d7.loss_mask: 0.5018  decode.d7.loss_dice: 1.0148  decode.d8.loss_cls: 0.0532  decode.d8.loss_mask: 0.4968  decode.d8.loss_dice: 0.9970
11/15 20:30:19 - mmengine - INFO - Iter(train) [78250/90000]  base_lr: 1.6004e-05 lr: 1.6004e-06  eta: 1:57:53  time: 0.5986  data_time: 0.0105  memory: 10692  grad_norm: 482.7937  loss: 14.5415  decode.loss_cls: 0.0371  decode.loss_mask: 0.4703  decode.loss_dice: 0.9425  decode.d0.loss_cls: 0.0635  decode.d0.loss_mask: 0.4910  decode.d0.loss_dice: 0.9956  decode.d1.loss_cls: 0.0467  decode.d1.loss_mask: 0.4741  decode.d1.loss_dice: 0.9523  decode.d2.loss_cls: 0.0387  decode.d2.loss_mask: 0.4714  decode.d2.loss_dice: 0.9474  decode.d3.loss_cls: 0.0402  decode.d3.loss_mask: 0.4686  decode.d3.loss_dice: 0.9394  decode.d4.loss_cls: 0.0375  decode.d4.loss_mask: 0.4686  decode.d4.loss_dice: 0.9331  decode.d5.loss_cls: 0.0387  decode.d5.loss_mask: 0.4700  decode.d5.loss_dice: 0.9376  decode.d6.loss_cls: 0.0360  decode.d6.loss_mask: 0.4685  decode.d6.loss_dice: 0.9189  decode.d7.loss_cls: 0.0421  decode.d7.loss_mask: 0.4680  decode.d7.loss_dice: 0.9238  decode.d8.loss_cls: 0.0349  decode.d8.loss_mask: 0.4648  decode.d8.loss_dice: 0.9201
11/15 20:30:49 - mmengine - INFO - Iter(train) [78300/90000]  base_lr: 1.5942e-05 lr: 1.5942e-06  eta: 1:57:23  time: 0.6020  data_time: 0.0107  memory: 10675  grad_norm: 297.9062  loss: 14.1214  decode.loss_cls: 0.0394  decode.loss_mask: 0.3942  decode.loss_dice: 0.9507  decode.d0.loss_cls: 0.0771  decode.d0.loss_mask: 0.4188  decode.d0.loss_dice: 1.0291  decode.d1.loss_cls: 0.0490  decode.d1.loss_mask: 0.4068  decode.d1.loss_dice: 0.9509  decode.d2.loss_cls: 0.0427  decode.d2.loss_mask: 0.4044  decode.d2.loss_dice: 0.9656  decode.d3.loss_cls: 0.0393  decode.d3.loss_mask: 0.4066  decode.d3.loss_dice: 0.9527  decode.d4.loss_cls: 0.0419  decode.d4.loss_mask: 0.4054  decode.d4.loss_dice: 0.9514  decode.d5.loss_cls: 0.0446  decode.d5.loss_mask: 0.4035  decode.d5.loss_dice: 0.9348  decode.d6.loss_cls: 0.0510  decode.d6.loss_mask: 0.4100  decode.d6.loss_dice: 0.9756  decode.d7.loss_cls: 0.0407  decode.d7.loss_mask: 0.3989  decode.d7.loss_dice: 0.9645  decode.d8.loss_cls: 0.0382  decode.d8.loss_mask: 0.3948  decode.d8.loss_dice: 0.9386
11/15 20:31:19 - mmengine - INFO - Iter(train) [78350/90000]  base_lr: 1.5881e-05 lr: 1.5881e-06  eta: 1:56:52  time: 0.6002  data_time: 0.0107  memory: 10656  grad_norm: 253.9801  loss: 15.5216  decode.loss_cls: 0.0642  decode.loss_mask: 0.4367  decode.loss_dice: 1.0328  decode.d0.loss_cls: 0.1077  decode.d0.loss_mask: 0.4643  decode.d0.loss_dice: 1.1187  decode.d1.loss_cls: 0.0732  decode.d1.loss_mask: 0.4371  decode.d1.loss_dice: 1.0658  decode.d2.loss_cls: 0.0820  decode.d2.loss_mask: 0.4365  decode.d2.loss_dice: 1.0249  decode.d3.loss_cls: 0.0760  decode.d3.loss_mask: 0.4346  decode.d3.loss_dice: 0.9976  decode.d4.loss_cls: 0.0674  decode.d4.loss_mask: 0.4417  decode.d4.loss_dice: 1.0263  decode.d5.loss_cls: 0.0812  decode.d5.loss_mask: 0.4487  decode.d5.loss_dice: 1.0123  decode.d6.loss_cls: 0.0828  decode.d6.loss_mask: 0.4451  decode.d6.loss_dice: 1.0324  decode.d7.loss_cls: 0.0715  decode.d7.loss_mask: 0.4354  decode.d7.loss_dice: 1.0038  decode.d8.loss_cls: 0.0711  decode.d8.loss_mask: 0.4346  decode.d8.loss_dice: 1.0155
11/15 20:31:49 - mmengine - INFO - Iter(train) [78400/90000]  base_lr: 1.5820e-05 lr: 1.5820e-06  eta: 1:56:22  time: 0.6080  data_time: 0.0111  memory: 10692  grad_norm: 326.1444  loss: 18.0824  decode.loss_cls: 0.0652  decode.loss_mask: 0.6087  decode.loss_dice: 1.1283  decode.d0.loss_cls: 0.0927  decode.d0.loss_mask: 0.6342  decode.d0.loss_dice: 1.2287  decode.d1.loss_cls: 0.0813  decode.d1.loss_mask: 0.6040  decode.d1.loss_dice: 1.1168  decode.d2.loss_cls: 0.0710  decode.d2.loss_mask: 0.6117  decode.d2.loss_dice: 1.0826  decode.d3.loss_cls: 0.0715  decode.d3.loss_mask: 0.6044  decode.d3.loss_dice: 1.1266  decode.d4.loss_cls: 0.0716  decode.d4.loss_mask: 0.6078  decode.d4.loss_dice: 1.0796  decode.d5.loss_cls: 0.0720  decode.d5.loss_mask: 0.6086  decode.d5.loss_dice: 1.1122  decode.d6.loss_cls: 0.0696  decode.d6.loss_mask: 0.6096  decode.d6.loss_dice: 1.1155  decode.d7.loss_cls: 0.0696  decode.d7.loss_mask: 0.6114  decode.d7.loss_dice: 1.1217  decode.d8.loss_cls: 0.0726  decode.d8.loss_mask: 0.6029  decode.d8.loss_dice: 1.1300
11/15 20:32:19 - mmengine - INFO - Iter(train) [78450/90000]  base_lr: 1.5758e-05 lr: 1.5758e-06  eta: 1:55:52  time: 0.6399  data_time: 0.0106  memory: 10656  grad_norm: 362.5562  loss: 15.5853  decode.loss_cls: 0.0659  decode.loss_mask: 0.5029  decode.loss_dice: 0.9761  decode.d0.loss_cls: 0.0914  decode.d0.loss_mask: 0.5437  decode.d0.loss_dice: 1.0486  decode.d1.loss_cls: 0.0635  decode.d1.loss_mask: 0.5069  decode.d1.loss_dice: 1.0021  decode.d2.loss_cls: 0.0561  decode.d2.loss_mask: 0.5126  decode.d2.loss_dice: 0.9966  decode.d3.loss_cls: 0.0607  decode.d3.loss_mask: 0.5038  decode.d3.loss_dice: 0.9616  decode.d4.loss_cls: 0.0579  decode.d4.loss_mask: 0.4999  decode.d4.loss_dice: 0.9506  decode.d5.loss_cls: 0.0638  decode.d5.loss_mask: 0.5008  decode.d5.loss_dice: 0.9617  decode.d6.loss_cls: 0.0643  decode.d6.loss_mask: 0.5071  decode.d6.loss_dice: 1.0039  decode.d7.loss_cls: 0.0525  decode.d7.loss_mask: 0.5059  decode.d7.loss_dice: 0.9910  decode.d8.loss_cls: 0.0622  decode.d8.loss_mask: 0.5082  decode.d8.loss_dice: 0.9628
11/15 20:32:49 - mmengine - INFO - Iter(train) [78500/90000]  base_lr: 1.5697e-05 lr: 1.5697e-06  eta: 1:55:22  time: 0.5999  data_time: 0.0106  memory: 10692  grad_norm: 228.0947  loss: 16.8357  decode.loss_cls: 0.0766  decode.loss_mask: 0.4799  decode.loss_dice: 1.1105  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 0.5412  decode.d0.loss_dice: 1.1668  decode.d1.loss_cls: 0.0739  decode.d1.loss_mask: 0.4884  decode.d1.loss_dice: 1.1492  decode.d2.loss_cls: 0.0682  decode.d2.loss_mask: 0.4982  decode.d2.loss_dice: 1.1216  decode.d3.loss_cls: 0.0860  decode.d3.loss_mask: 0.4814  decode.d3.loss_dice: 1.0683  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.4990  decode.d4.loss_dice: 1.0928  decode.d5.loss_cls: 0.0740  decode.d5.loss_mask: 0.4794  decode.d5.loss_dice: 1.0985  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.5040  decode.d6.loss_dice: 1.0980  decode.d7.loss_cls: 0.0644  decode.d7.loss_mask: 0.5082  decode.d7.loss_dice: 1.1031  decode.d8.loss_cls: 0.0791  decode.d8.loss_mask: 0.4948  decode.d8.loss_dice: 1.1234
11/15 20:33:19 - mmengine - INFO - Iter(train) [78550/90000]  base_lr: 1.5635e-05 lr: 1.5635e-06  eta: 1:54:52  time: 0.6042  data_time: 0.0111  memory: 10692  grad_norm: 225.8538  loss: 14.0030  decode.loss_cls: 0.0746  decode.loss_mask: 0.4125  decode.loss_dice: 0.8829  decode.d0.loss_cls: 0.0833  decode.d0.loss_mask: 0.4654  decode.d0.loss_dice: 0.9777  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.4257  decode.d1.loss_dice: 0.9144  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 0.4411  decode.d2.loss_dice: 0.9134  decode.d3.loss_cls: 0.0725  decode.d3.loss_mask: 0.4254  decode.d3.loss_dice: 0.8823  decode.d4.loss_cls: 0.0667  decode.d4.loss_mask: 0.4209  decode.d4.loss_dice: 0.9161  decode.d5.loss_cls: 0.0755  decode.d5.loss_mask: 0.4184  decode.d5.loss_dice: 0.8774  decode.d6.loss_cls: 0.0763  decode.d6.loss_mask: 0.4186  decode.d6.loss_dice: 0.8764  decode.d7.loss_cls: 0.0752  decode.d7.loss_mask: 0.4128  decode.d7.loss_dice: 0.8911  decode.d8.loss_cls: 0.0737  decode.d8.loss_mask: 0.4132  decode.d8.loss_dice: 0.8900
11/15 20:33:50 - mmengine - INFO - Iter(train) [78600/90000]  base_lr: 1.5574e-05 lr: 1.5574e-06  eta: 1:54:22  time: 0.6017  data_time: 0.0108  memory: 10713  grad_norm: 181.7156  loss: 13.2264  decode.loss_cls: 0.0563  decode.loss_mask: 0.3857  decode.loss_dice: 0.8728  decode.d0.loss_cls: 0.0709  decode.d0.loss_mask: 0.4263  decode.d0.loss_dice: 0.9725  decode.d1.loss_cls: 0.0641  decode.d1.loss_mask: 0.3877  decode.d1.loss_dice: 0.8819  decode.d2.loss_cls: 0.0620  decode.d2.loss_mask: 0.3910  decode.d2.loss_dice: 0.8750  decode.d3.loss_cls: 0.0634  decode.d3.loss_mask: 0.3863  decode.d3.loss_dice: 0.8456  decode.d4.loss_cls: 0.0618  decode.d4.loss_mask: 0.3839  decode.d4.loss_dice: 0.8485  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.3834  decode.d5.loss_dice: 0.8518  decode.d6.loss_cls: 0.0567  decode.d6.loss_mask: 0.3846  decode.d6.loss_dice: 0.8707  decode.d7.loss_cls: 0.0668  decode.d7.loss_mask: 0.3821  decode.d7.loss_dice: 0.8363  decode.d8.loss_cls: 0.0654  decode.d8.loss_mask: 0.3863  decode.d8.loss_dice: 0.8440
11/15 20:34:20 - mmengine - INFO - Iter(train) [78650/90000]  base_lr: 1.5513e-05 lr: 1.5513e-06  eta: 1:53:52  time: 0.6044  data_time: 0.0111  memory: 10742  grad_norm: 271.4057  loss: 15.4379  decode.loss_cls: 0.0365  decode.loss_mask: 0.4718  decode.loss_dice: 1.0145  decode.d0.loss_cls: 0.0676  decode.d0.loss_mask: 0.5118  decode.d0.loss_dice: 1.0437  decode.d1.loss_cls: 0.0344  decode.d1.loss_mask: 0.4866  decode.d1.loss_dice: 1.0417  decode.d2.loss_cls: 0.0404  decode.d2.loss_mask: 0.4806  decode.d2.loss_dice: 1.0262  decode.d3.loss_cls: 0.0352  decode.d3.loss_mask: 0.4863  decode.d3.loss_dice: 1.0142  decode.d4.loss_cls: 0.0381  decode.d4.loss_mask: 0.4874  decode.d4.loss_dice: 1.0165  decode.d5.loss_cls: 0.0329  decode.d5.loss_mask: 0.4784  decode.d5.loss_dice: 1.0324  decode.d6.loss_cls: 0.0314  decode.d6.loss_mask: 0.4717  decode.d6.loss_dice: 1.0211  decode.d7.loss_cls: 0.0303  decode.d7.loss_mask: 0.4735  decode.d7.loss_dice: 1.0301  decode.d8.loss_cls: 0.0347  decode.d8.loss_mask: 0.4719  decode.d8.loss_dice: 0.9963
11/15 20:34:50 - mmengine - INFO - Iter(train) [78700/90000]  base_lr: 1.5451e-05 lr: 1.5451e-06  eta: 1:53:22  time: 0.5993  data_time: 0.0105  memory: 10728  grad_norm: 364.6642  loss: 12.4267  decode.loss_cls: 0.0292  decode.loss_mask: 0.3892  decode.loss_dice: 0.8127  decode.d0.loss_cls: 0.0765  decode.d0.loss_mask: 0.3982  decode.d0.loss_dice: 0.8578  decode.d1.loss_cls: 0.0528  decode.d1.loss_mask: 0.3915  decode.d1.loss_dice: 0.8169  decode.d2.loss_cls: 0.0365  decode.d2.loss_mask: 0.3914  decode.d2.loss_dice: 0.8211  decode.d3.loss_cls: 0.0381  decode.d3.loss_mask: 0.3869  decode.d3.loss_dice: 0.8045  decode.d4.loss_cls: 0.0337  decode.d4.loss_mask: 0.3861  decode.d4.loss_dice: 0.8080  decode.d5.loss_cls: 0.0297  decode.d5.loss_mask: 0.3880  decode.d5.loss_dice: 0.8043  decode.d6.loss_cls: 0.0311  decode.d6.loss_mask: 0.3864  decode.d6.loss_dice: 0.8006  decode.d7.loss_cls: 0.0272  decode.d7.loss_mask: 0.3888  decode.d7.loss_dice: 0.8145  decode.d8.loss_cls: 0.0305  decode.d8.loss_mask: 0.3852  decode.d8.loss_dice: 0.8094
11/15 20:35:20 - mmengine - INFO - Iter(train) [78750/90000]  base_lr: 1.5389e-05 lr: 1.5389e-06  eta: 1:52:52  time: 0.5990  data_time: 0.0108  memory: 10692  grad_norm: 354.2686  loss: 14.9444  decode.loss_cls: 0.0508  decode.loss_mask: 0.4643  decode.loss_dice: 0.9610  decode.d0.loss_cls: 0.0867  decode.d0.loss_mask: 0.4880  decode.d0.loss_dice: 0.9902  decode.d1.loss_cls: 0.0634  decode.d1.loss_mask: 0.4677  decode.d1.loss_dice: 0.9701  decode.d2.loss_cls: 0.0504  decode.d2.loss_mask: 0.4774  decode.d2.loss_dice: 0.9922  decode.d3.loss_cls: 0.0496  decode.d3.loss_mask: 0.4605  decode.d3.loss_dice: 0.9579  decode.d4.loss_cls: 0.0469  decode.d4.loss_mask: 0.4557  decode.d4.loss_dice: 1.0242  decode.d5.loss_cls: 0.0515  decode.d5.loss_mask: 0.4656  decode.d5.loss_dice: 0.9846  decode.d6.loss_cls: 0.0557  decode.d6.loss_mask: 0.4464  decode.d6.loss_dice: 0.9301  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.4659  decode.d7.loss_dice: 0.9638  decode.d8.loss_cls: 0.0527  decode.d8.loss_mask: 0.4631  decode.d8.loss_dice: 0.9533
11/15 20:35:50 - mmengine - INFO - Iter(train) [78800/90000]  base_lr: 1.5328e-05 lr: 1.5328e-06  eta: 1:52:22  time: 0.5996  data_time: 0.0106  memory: 10675  grad_norm: 747.6205  loss: 14.2247  decode.loss_cls: 0.0660  decode.loss_mask: 0.3508  decode.loss_dice: 0.9527  decode.d0.loss_cls: 0.0881  decode.d0.loss_mask: 0.4042  decode.d0.loss_dice: 1.0925  decode.d1.loss_cls: 0.0715  decode.d1.loss_mask: 0.3840  decode.d1.loss_dice: 1.0290  decode.d2.loss_cls: 0.0606  decode.d2.loss_mask: 0.3701  decode.d2.loss_dice: 1.0118  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 0.3479  decode.d3.loss_dice: 0.9494  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.3606  decode.d4.loss_dice: 0.9972  decode.d5.loss_cls: 0.0582  decode.d5.loss_mask: 0.3559  decode.d5.loss_dice: 1.0015  decode.d6.loss_cls: 0.0583  decode.d6.loss_mask: 0.3523  decode.d6.loss_dice: 0.9651  decode.d7.loss_cls: 0.0655  decode.d7.loss_mask: 0.3551  decode.d7.loss_dice: 0.9787  decode.d8.loss_cls: 0.0647  decode.d8.loss_mask: 0.3523  decode.d8.loss_dice: 0.9654
11/15 20:36:20 - mmengine - INFO - Iter(train) [78850/90000]  base_lr: 1.5266e-05 lr: 1.5266e-06  eta: 1:51:51  time: 0.6002  data_time: 0.0108  memory: 10692  grad_norm: 408.6112  loss: 13.4496  decode.loss_cls: 0.0535  decode.loss_mask: 0.3873  decode.loss_dice: 0.8939  decode.d0.loss_cls: 0.0747  decode.d0.loss_mask: 0.3985  decode.d0.loss_dice: 0.9685  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.3821  decode.d1.loss_dice: 0.9401  decode.d2.loss_cls: 0.0610  decode.d2.loss_mask: 0.3796  decode.d2.loss_dice: 0.8956  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.3797  decode.d3.loss_dice: 0.8819  decode.d4.loss_cls: 0.0582  decode.d4.loss_mask: 0.3729  decode.d4.loss_dice: 0.8755  decode.d5.loss_cls: 0.0577  decode.d5.loss_mask: 0.3829  decode.d5.loss_dice: 0.8732  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.3831  decode.d6.loss_dice: 0.8917  decode.d7.loss_cls: 0.0552  decode.d7.loss_mask: 0.3820  decode.d7.loss_dice: 0.8926  decode.d8.loss_cls: 0.0515  decode.d8.loss_mask: 0.3836  decode.d8.loss_dice: 0.9164
11/15 20:36:50 - mmengine - INFO - Iter(train) [78900/90000]  base_lr: 1.5205e-05 lr: 1.5205e-06  eta: 1:51:21  time: 0.5988  data_time: 0.0107  memory: 10675  grad_norm: 472.7693  loss: 14.6763  decode.loss_cls: 0.0421  decode.loss_mask: 0.4563  decode.loss_dice: 0.9622  decode.d0.loss_cls: 0.0873  decode.d0.loss_mask: 0.4766  decode.d0.loss_dice: 1.0131  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.4634  decode.d1.loss_dice: 0.9590  decode.d2.loss_cls: 0.0424  decode.d2.loss_mask: 0.4626  decode.d2.loss_dice: 0.9475  decode.d3.loss_cls: 0.0524  decode.d3.loss_mask: 0.4616  decode.d3.loss_dice: 0.9524  decode.d4.loss_cls: 0.0551  decode.d4.loss_mask: 0.4611  decode.d4.loss_dice: 0.9694  decode.d5.loss_cls: 0.0396  decode.d5.loss_mask: 0.4597  decode.d5.loss_dice: 0.9537  decode.d6.loss_cls: 0.0463  decode.d6.loss_mask: 0.4572  decode.d6.loss_dice: 0.9382  decode.d7.loss_cls: 0.0518  decode.d7.loss_mask: 0.4536  decode.d7.loss_dice: 0.9258  decode.d8.loss_cls: 0.0501  decode.d8.loss_mask: 0.4554  decode.d8.loss_dice: 0.9284
11/15 20:37:20 - mmengine - INFO - Iter(train) [78950/90000]  base_lr: 1.5143e-05 lr: 1.5143e-06  eta: 1:50:51  time: 0.5998  data_time: 0.0107  memory: 10675  grad_norm: 374.9307  loss: 14.8245  decode.loss_cls: 0.0927  decode.loss_mask: 0.3636  decode.loss_dice: 0.9696  decode.d0.loss_cls: 0.0901  decode.d0.loss_mask: 0.4104  decode.d0.loss_dice: 1.1405  decode.d1.loss_cls: 0.0753  decode.d1.loss_mask: 0.3778  decode.d1.loss_dice: 1.0501  decode.d2.loss_cls: 0.0693  decode.d2.loss_mask: 0.3907  decode.d2.loss_dice: 1.0702  decode.d3.loss_cls: 0.0928  decode.d3.loss_mask: 0.3813  decode.d3.loss_dice: 0.9946  decode.d4.loss_cls: 0.0830  decode.d4.loss_mask: 0.3650  decode.d4.loss_dice: 0.9850  decode.d5.loss_cls: 0.0806  decode.d5.loss_mask: 0.3800  decode.d5.loss_dice: 0.9736  decode.d6.loss_cls: 0.0804  decode.d6.loss_mask: 0.3653  decode.d6.loss_dice: 0.9964  decode.d7.loss_cls: 0.0776  decode.d7.loss_mask: 0.3688  decode.d7.loss_dice: 1.0279  decode.d8.loss_cls: 0.0832  decode.d8.loss_mask: 0.3666  decode.d8.loss_dice: 1.0223
11/15 20:37:50 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 20:37:50 - mmengine - INFO - Iter(train) [79000/90000]  base_lr: 1.5081e-05 lr: 1.5081e-06  eta: 1:50:21  time: 0.6004  data_time: 0.0107  memory: 10713  grad_norm: 307.6721  loss: 16.6242  decode.loss_cls: 0.0881  decode.loss_mask: 0.4474  decode.loss_dice: 1.0919  decode.d0.loss_cls: 0.0800  decode.d0.loss_mask: 0.4678  decode.d0.loss_dice: 1.2246  decode.d1.loss_cls: 0.0674  decode.d1.loss_mask: 0.4570  decode.d1.loss_dice: 1.1335  decode.d2.loss_cls: 0.0809  decode.d2.loss_mask: 0.4491  decode.d2.loss_dice: 1.1341  decode.d3.loss_cls: 0.0863  decode.d3.loss_mask: 0.4476  decode.d3.loss_dice: 1.0962  decode.d4.loss_cls: 0.0889  decode.d4.loss_mask: 0.4484  decode.d4.loss_dice: 1.1409  decode.d5.loss_cls: 0.0861  decode.d5.loss_mask: 0.4523  decode.d5.loss_dice: 1.1232  decode.d6.loss_cls: 0.1126  decode.d6.loss_mask: 0.4533  decode.d6.loss_dice: 1.0984  decode.d7.loss_cls: 0.0919  decode.d7.loss_mask: 0.4513  decode.d7.loss_dice: 1.1044  decode.d8.loss_cls: 0.0798  decode.d8.loss_mask: 0.4515  decode.d8.loss_dice: 1.0892
11/15 20:38:20 - mmengine - INFO - Iter(train) [79050/90000]  base_lr: 1.5020e-05 lr: 1.5020e-06  eta: 1:49:51  time: 0.5990  data_time: 0.0109  memory: 10692  grad_norm: 286.8865  loss: 16.1012  decode.loss_cls: 0.0426  decode.loss_mask: 0.5380  decode.loss_dice: 1.0339  decode.d0.loss_cls: 0.0865  decode.d0.loss_mask: 0.5430  decode.d0.loss_dice: 1.0522  decode.d1.loss_cls: 0.0650  decode.d1.loss_mask: 0.5317  decode.d1.loss_dice: 1.0232  decode.d2.loss_cls: 0.0526  decode.d2.loss_mask: 0.5373  decode.d2.loss_dice: 1.0345  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.5296  decode.d3.loss_dice: 0.9918  decode.d4.loss_cls: 0.0471  decode.d4.loss_mask: 0.5326  decode.d4.loss_dice: 1.0259  decode.d5.loss_cls: 0.0500  decode.d5.loss_mask: 0.5282  decode.d5.loss_dice: 0.9983  decode.d6.loss_cls: 0.0431  decode.d6.loss_mask: 0.5270  decode.d6.loss_dice: 1.0329  decode.d7.loss_cls: 0.0442  decode.d7.loss_mask: 0.5330  decode.d7.loss_dice: 1.0298  decode.d8.loss_cls: 0.0494  decode.d8.loss_mask: 0.5307  decode.d8.loss_dice: 1.0095
11/15 20:38:50 - mmengine - INFO - Iter(train) [79100/90000]  base_lr: 1.4958e-05 lr: 1.4958e-06  eta: 1:49:21  time: 0.5990  data_time: 0.0107  memory: 10713  grad_norm: 571.0149  loss: 14.2954  decode.loss_cls: 0.0557  decode.loss_mask: 0.5448  decode.loss_dice: 0.7872  decode.d0.loss_cls: 0.0931  decode.d0.loss_mask: 0.5930  decode.d0.loss_dice: 0.8953  decode.d1.loss_cls: 0.0520  decode.d1.loss_mask: 0.5568  decode.d1.loss_dice: 0.8862  decode.d2.loss_cls: 0.0543  decode.d2.loss_mask: 0.5616  decode.d2.loss_dice: 0.8541  decode.d3.loss_cls: 0.0486  decode.d3.loss_mask: 0.5395  decode.d3.loss_dice: 0.8005  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.5367  decode.d4.loss_dice: 0.8094  decode.d5.loss_cls: 0.0467  decode.d5.loss_mask: 0.5376  decode.d5.loss_dice: 0.8108  decode.d6.loss_cls: 0.0447  decode.d6.loss_mask: 0.5342  decode.d6.loss_dice: 0.7898  decode.d7.loss_cls: 0.0568  decode.d7.loss_mask: 0.5283  decode.d7.loss_dice: 0.8167  decode.d8.loss_cls: 0.0478  decode.d8.loss_mask: 0.5478  decode.d8.loss_dice: 0.8135
11/15 20:39:20 - mmengine - INFO - Iter(train) [79150/90000]  base_lr: 1.4896e-05 lr: 1.4896e-06  eta: 1:48:51  time: 0.5991  data_time: 0.0108  memory: 10641  grad_norm: 292.1859  loss: 16.4308  decode.loss_cls: 0.0577  decode.loss_mask: 0.5061  decode.loss_dice: 1.0659  decode.d0.loss_cls: 0.1113  decode.d0.loss_mask: 0.5641  decode.d0.loss_dice: 1.1750  decode.d1.loss_cls: 0.0717  decode.d1.loss_mask: 0.4941  decode.d1.loss_dice: 1.0670  decode.d2.loss_cls: 0.0721  decode.d2.loss_mask: 0.4900  decode.d2.loss_dice: 1.0312  decode.d3.loss_cls: 0.0724  decode.d3.loss_mask: 0.4888  decode.d3.loss_dice: 1.0566  decode.d4.loss_cls: 0.0600  decode.d4.loss_mask: 0.5177  decode.d4.loss_dice: 1.0538  decode.d5.loss_cls: 0.0719  decode.d5.loss_mask: 0.4848  decode.d5.loss_dice: 1.0195  decode.d6.loss_cls: 0.0753  decode.d6.loss_mask: 0.4839  decode.d6.loss_dice: 1.0649  decode.d7.loss_cls: 0.0770  decode.d7.loss_mask: 0.4913  decode.d7.loss_dice: 1.0433  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.5085  decode.d8.loss_dice: 1.0903
11/15 20:39:50 - mmengine - INFO - Iter(train) [79200/90000]  base_lr: 1.4834e-05 lr: 1.4834e-06  eta: 1:48:21  time: 0.6005  data_time: 0.0107  memory: 10675  grad_norm: 363.5700  loss: 16.7438  decode.loss_cls: 0.0680  decode.loss_mask: 0.4761  decode.loss_dice: 1.1033  decode.d0.loss_cls: 0.1086  decode.d0.loss_mask: 0.5129  decode.d0.loss_dice: 1.2046  decode.d1.loss_cls: 0.0731  decode.d1.loss_mask: 0.4958  decode.d1.loss_dice: 1.1346  decode.d2.loss_cls: 0.0681  decode.d2.loss_mask: 0.4864  decode.d2.loss_dice: 1.1403  decode.d3.loss_cls: 0.0691  decode.d3.loss_mask: 0.4822  decode.d3.loss_dice: 1.0892  decode.d4.loss_cls: 0.0797  decode.d4.loss_mask: 0.4748  decode.d4.loss_dice: 1.0814  decode.d5.loss_cls: 0.0678  decode.d5.loss_mask: 0.4799  decode.d5.loss_dice: 1.1202  decode.d6.loss_cls: 0.0690  decode.d6.loss_mask: 0.4807  decode.d6.loss_dice: 1.0955  decode.d7.loss_cls: 0.0700  decode.d7.loss_mask: 0.4733  decode.d7.loss_dice: 1.0831  decode.d8.loss_cls: 0.0651  decode.d8.loss_mask: 0.4788  decode.d8.loss_dice: 1.1123
11/15 20:40:20 - mmengine - INFO - Iter(train) [79250/90000]  base_lr: 1.4772e-05 lr: 1.4772e-06  eta: 1:47:50  time: 0.6000  data_time: 0.0110  memory: 10758  grad_norm: 372.4547  loss: 15.9680  decode.loss_cls: 0.0593  decode.loss_mask: 0.4281  decode.loss_dice: 1.1012  decode.d0.loss_cls: 0.0950  decode.d0.loss_mask: 0.4431  decode.d0.loss_dice: 1.1876  decode.d1.loss_cls: 0.0547  decode.d1.loss_mask: 0.4262  decode.d1.loss_dice: 1.1282  decode.d2.loss_cls: 0.0554  decode.d2.loss_mask: 0.4316  decode.d2.loss_dice: 1.1235  decode.d3.loss_cls: 0.0530  decode.d3.loss_mask: 0.4292  decode.d3.loss_dice: 1.0757  decode.d4.loss_cls: 0.0604  decode.d4.loss_mask: 0.4271  decode.d4.loss_dice: 1.0782  decode.d5.loss_cls: 0.0698  decode.d5.loss_mask: 0.4294  decode.d5.loss_dice: 1.0743  decode.d6.loss_cls: 0.0698  decode.d6.loss_mask: 0.4259  decode.d6.loss_dice: 1.0810  decode.d7.loss_cls: 0.0629  decode.d7.loss_mask: 0.4319  decode.d7.loss_dice: 1.0782  decode.d8.loss_cls: 0.0643  decode.d8.loss_mask: 0.4323  decode.d8.loss_dice: 1.0907
11/15 20:40:50 - mmengine - INFO - Iter(train) [79300/90000]  base_lr: 1.4711e-05 lr: 1.4711e-06  eta: 1:47:20  time: 0.5990  data_time: 0.0105  memory: 10626  grad_norm: 575.9254  loss: 14.5429  decode.loss_cls: 0.0438  decode.loss_mask: 0.4841  decode.loss_dice: 0.9030  decode.d0.loss_cls: 0.0827  decode.d0.loss_mask: 0.5231  decode.d0.loss_dice: 0.9428  decode.d1.loss_cls: 0.0474  decode.d1.loss_mask: 0.5002  decode.d1.loss_dice: 0.9516  decode.d2.loss_cls: 0.0489  decode.d2.loss_mask: 0.4925  decode.d2.loss_dice: 0.9423  decode.d3.loss_cls: 0.0399  decode.d3.loss_mask: 0.5063  decode.d3.loss_dice: 0.9251  decode.d4.loss_cls: 0.0450  decode.d4.loss_mask: 0.5157  decode.d4.loss_dice: 0.9294  decode.d5.loss_cls: 0.0395  decode.d5.loss_mask: 0.5194  decode.d5.loss_dice: 0.9238  decode.d6.loss_cls: 0.0441  decode.d6.loss_mask: 0.4862  decode.d6.loss_dice: 0.8782  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.4478  decode.d7.loss_dice: 0.8506  decode.d8.loss_cls: 0.0492  decode.d8.loss_mask: 0.4510  decode.d8.loss_dice: 0.8777
11/15 20:41:20 - mmengine - INFO - Iter(train) [79350/90000]  base_lr: 1.4649e-05 lr: 1.4649e-06  eta: 1:46:50  time: 0.5990  data_time: 0.0106  memory: 10728  grad_norm: 351.2532  loss: 13.2075  decode.loss_cls: 0.0357  decode.loss_mask: 0.4600  decode.loss_dice: 0.8020  decode.d0.loss_cls: 0.0799  decode.d0.loss_mask: 0.4793  decode.d0.loss_dice: 0.8379  decode.d1.loss_cls: 0.0342  decode.d1.loss_mask: 0.4642  decode.d1.loss_dice: 0.8400  decode.d2.loss_cls: 0.0345  decode.d2.loss_mask: 0.4587  decode.d2.loss_dice: 0.8334  decode.d3.loss_cls: 0.0357  decode.d3.loss_mask: 0.4579  decode.d3.loss_dice: 0.8110  decode.d4.loss_cls: 0.0367  decode.d4.loss_mask: 0.4614  decode.d4.loss_dice: 0.8142  decode.d5.loss_cls: 0.0389  decode.d5.loss_mask: 0.4608  decode.d5.loss_dice: 0.8117  decode.d6.loss_cls: 0.0381  decode.d6.loss_mask: 0.4591  decode.d6.loss_dice: 0.8026  decode.d7.loss_cls: 0.0413  decode.d7.loss_mask: 0.4578  decode.d7.loss_dice: 0.8059  decode.d8.loss_cls: 0.0391  decode.d8.loss_mask: 0.4578  decode.d8.loss_dice: 0.8175
11/15 20:41:50 - mmengine - INFO - Iter(train) [79400/90000]  base_lr: 1.4587e-05 lr: 1.4587e-06  eta: 1:46:20  time: 0.6011  data_time: 0.0107  memory: 10675  grad_norm: 460.0587  loss: 16.6983  decode.loss_cls: 0.0674  decode.loss_mask: 0.5372  decode.loss_dice: 1.0595  decode.d0.loss_cls: 0.0794  decode.d0.loss_mask: 0.5720  decode.d0.loss_dice: 1.1454  decode.d1.loss_cls: 0.0709  decode.d1.loss_mask: 0.5277  decode.d1.loss_dice: 1.0712  decode.d2.loss_cls: 0.0608  decode.d2.loss_mask: 0.5291  decode.d2.loss_dice: 1.0459  decode.d3.loss_cls: 0.0635  decode.d3.loss_mask: 0.5240  decode.d3.loss_dice: 1.0605  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.5235  decode.d4.loss_dice: 1.0882  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.5295  decode.d5.loss_dice: 1.0789  decode.d6.loss_cls: 0.0643  decode.d6.loss_mask: 0.5253  decode.d6.loss_dice: 1.0702  decode.d7.loss_cls: 0.0481  decode.d7.loss_mask: 0.5291  decode.d7.loss_dice: 1.0878  decode.d8.loss_cls: 0.0591  decode.d8.loss_mask: 0.5304  decode.d8.loss_dice: 1.0454
11/15 20:42:20 - mmengine - INFO - Iter(train) [79450/90000]  base_lr: 1.4525e-05 lr: 1.4525e-06  eta: 1:45:50  time: 0.5991  data_time: 0.0106  memory: 10656  grad_norm: 290.9593  loss: 16.0450  decode.loss_cls: 0.0724  decode.loss_mask: 0.4582  decode.loss_dice: 1.0333  decode.d0.loss_cls: 0.0863  decode.d0.loss_mask: 0.4770  decode.d0.loss_dice: 1.1844  decode.d1.loss_cls: 0.0713  decode.d1.loss_mask: 0.4612  decode.d1.loss_dice: 1.0774  decode.d2.loss_cls: 0.0879  decode.d2.loss_mask: 0.4622  decode.d2.loss_dice: 1.0466  decode.d3.loss_cls: 0.0677  decode.d3.loss_mask: 0.4625  decode.d3.loss_dice: 1.1015  decode.d4.loss_cls: 0.0700  decode.d4.loss_mask: 0.4587  decode.d4.loss_dice: 1.0421  decode.d5.loss_cls: 0.0711  decode.d5.loss_mask: 0.4593  decode.d5.loss_dice: 1.0635  decode.d6.loss_cls: 0.0720  decode.d6.loss_mask: 0.4582  decode.d6.loss_dice: 1.0168  decode.d7.loss_cls: 0.0716  decode.d7.loss_mask: 0.4570  decode.d7.loss_dice: 1.0547  decode.d8.loss_cls: 0.0816  decode.d8.loss_mask: 0.4582  decode.d8.loss_dice: 1.0603
11/15 20:42:50 - mmengine - INFO - Iter(train) [79500/90000]  base_lr: 1.4463e-05 lr: 1.4463e-06  eta: 1:45:20  time: 0.5990  data_time: 0.0105  memory: 10656  grad_norm: 469.8431  loss: 16.3046  decode.loss_cls: 0.0528  decode.loss_mask: 0.5909  decode.loss_dice: 0.9733  decode.d0.loss_cls: 0.0800  decode.d0.loss_mask: 0.6115  decode.d0.loss_dice: 1.0404  decode.d1.loss_cls: 0.0538  decode.d1.loss_mask: 0.5841  decode.d1.loss_dice: 0.9887  decode.d2.loss_cls: 0.0515  decode.d2.loss_mask: 0.5795  decode.d2.loss_dice: 0.9897  decode.d3.loss_cls: 0.0472  decode.d3.loss_mask: 0.5795  decode.d3.loss_dice: 0.9858  decode.d4.loss_cls: 0.0479  decode.d4.loss_mask: 0.5828  decode.d4.loss_dice: 0.9827  decode.d5.loss_cls: 0.0473  decode.d5.loss_mask: 0.5859  decode.d5.loss_dice: 0.9922  decode.d6.loss_cls: 0.0541  decode.d6.loss_mask: 0.5926  decode.d6.loss_dice: 0.9727  decode.d7.loss_cls: 0.0542  decode.d7.loss_mask: 0.5938  decode.d7.loss_dice: 0.9739  decode.d8.loss_cls: 0.0523  decode.d8.loss_mask: 0.5865  decode.d8.loss_dice: 0.9768
11/15 20:43:20 - mmengine - INFO - Iter(train) [79550/90000]  base_lr: 1.4401e-05 lr: 1.4401e-06  eta: 1:44:50  time: 0.6000  data_time: 0.0107  memory: 10675  grad_norm: 261.2377  loss: 14.5822  decode.loss_cls: 0.0358  decode.loss_mask: 0.4685  decode.loss_dice: 0.9236  decode.d0.loss_cls: 0.0680  decode.d0.loss_mask: 0.4919  decode.d0.loss_dice: 0.9928  decode.d1.loss_cls: 0.0457  decode.d1.loss_mask: 0.4708  decode.d1.loss_dice: 0.9489  decode.d2.loss_cls: 0.0410  decode.d2.loss_mask: 0.4656  decode.d2.loss_dice: 0.9441  decode.d3.loss_cls: 0.0374  decode.d3.loss_mask: 0.4645  decode.d3.loss_dice: 0.9327  decode.d4.loss_cls: 0.0397  decode.d4.loss_mask: 0.4677  decode.d4.loss_dice: 0.9401  decode.d5.loss_cls: 0.0378  decode.d5.loss_mask: 0.4682  decode.d5.loss_dice: 0.9610  decode.d6.loss_cls: 0.0328  decode.d6.loss_mask: 0.4701  decode.d6.loss_dice: 0.9355  decode.d7.loss_cls: 0.0330  decode.d7.loss_mask: 0.4706  decode.d7.loss_dice: 0.9509  decode.d8.loss_cls: 0.0393  decode.d8.loss_mask: 0.4705  decode.d8.loss_dice: 0.9338
11/15 20:43:50 - mmengine - INFO - Iter(train) [79600/90000]  base_lr: 1.4339e-05 lr: 1.4339e-06  eta: 1:44:20  time: 0.6154  data_time: 0.0109  memory: 10675  grad_norm: 419.4349  loss: 17.8632  decode.loss_cls: 0.0638  decode.loss_mask: 0.5224  decode.loss_dice: 1.1979  decode.d0.loss_cls: 0.0929  decode.d0.loss_mask: 0.5390  decode.d0.loss_dice: 1.2547  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.4981  decode.d1.loss_dice: 1.1775  decode.d2.loss_cls: 0.0610  decode.d2.loss_mask: 0.5248  decode.d2.loss_dice: 1.1957  decode.d3.loss_cls: 0.0661  decode.d3.loss_mask: 0.5330  decode.d3.loss_dice: 1.2043  decode.d4.loss_cls: 0.0604  decode.d4.loss_mask: 0.5251  decode.d4.loss_dice: 1.1934  decode.d5.loss_cls: 0.0675  decode.d5.loss_mask: 0.5082  decode.d5.loss_dice: 1.1783  decode.d6.loss_cls: 0.0657  decode.d6.loss_mask: 0.5190  decode.d6.loss_dice: 1.2095  decode.d7.loss_cls: 0.0751  decode.d7.loss_mask: 0.5109  decode.d7.loss_dice: 1.1893  decode.d8.loss_cls: 0.0695  decode.d8.loss_mask: 0.5054  decode.d8.loss_dice: 1.1878
11/15 20:44:20 - mmengine - INFO - Iter(train) [79650/90000]  base_lr: 1.4277e-05 lr: 1.4277e-06  eta: 1:43:50  time: 0.6007  data_time: 0.0109  memory: 10675  grad_norm: 415.1032  loss: 16.2694  decode.loss_cls: 0.0515  decode.loss_mask: 0.4524  decode.loss_dice: 1.1182  decode.d0.loss_cls: 0.0810  decode.d0.loss_mask: 0.4626  decode.d0.loss_dice: 1.1306  decode.d1.loss_cls: 0.0696  decode.d1.loss_mask: 0.4521  decode.d1.loss_dice: 1.1187  decode.d2.loss_cls: 0.0539  decode.d2.loss_mask: 0.4524  decode.d2.loss_dice: 1.1151  decode.d3.loss_cls: 0.0544  decode.d3.loss_mask: 0.4564  decode.d3.loss_dice: 1.0993  decode.d4.loss_cls: 0.0493  decode.d4.loss_mask: 0.4516  decode.d4.loss_dice: 1.1241  decode.d5.loss_cls: 0.0562  decode.d5.loss_mask: 0.4529  decode.d5.loss_dice: 1.1131  decode.d6.loss_cls: 0.0528  decode.d6.loss_mask: 0.4532  decode.d6.loss_dice: 1.1272  decode.d7.loss_cls: 0.0592  decode.d7.loss_mask: 0.4511  decode.d7.loss_dice: 1.1035  decode.d8.loss_cls: 0.0495  decode.d8.loss_mask: 0.4480  decode.d8.loss_dice: 1.1092
11/15 20:44:50 - mmengine - INFO - Iter(train) [79700/90000]  base_lr: 1.4215e-05 lr: 1.4215e-06  eta: 1:43:20  time: 0.5996  data_time: 0.0108  memory: 10742  grad_norm: 407.9388  loss: 16.1210  decode.loss_cls: 0.0636  decode.loss_mask: 0.4513  decode.loss_dice: 1.0951  decode.d0.loss_cls: 0.0818  decode.d0.loss_mask: 0.4773  decode.d0.loss_dice: 1.1334  decode.d1.loss_cls: 0.0637  decode.d1.loss_mask: 0.4625  decode.d1.loss_dice: 1.1063  decode.d2.loss_cls: 0.0706  decode.d2.loss_mask: 0.4488  decode.d2.loss_dice: 1.0717  decode.d3.loss_cls: 0.0618  decode.d3.loss_mask: 0.4542  decode.d3.loss_dice: 1.0924  decode.d4.loss_cls: 0.0622  decode.d4.loss_mask: 0.4509  decode.d4.loss_dice: 1.0831  decode.d5.loss_cls: 0.0689  decode.d5.loss_mask: 0.4463  decode.d5.loss_dice: 1.0889  decode.d6.loss_cls: 0.0681  decode.d6.loss_mask: 0.4471  decode.d6.loss_dice: 1.0492  decode.d7.loss_cls: 0.0662  decode.d7.loss_mask: 0.4528  decode.d7.loss_dice: 1.0876  decode.d8.loss_cls: 0.0726  decode.d8.loss_mask: 0.4527  decode.d8.loss_dice: 1.0899
11/15 20:45:20 - mmengine - INFO - Iter(train) [79750/90000]  base_lr: 1.4153e-05 lr: 1.4153e-06  eta: 1:42:49  time: 0.6016  data_time: 0.0107  memory: 10675  grad_norm: 457.0706  loss: 15.6502  decode.loss_cls: 0.0584  decode.loss_mask: 0.4645  decode.loss_dice: 0.9918  decode.d0.loss_cls: 0.0760  decode.d0.loss_mask: 0.4993  decode.d0.loss_dice: 1.0727  decode.d1.loss_cls: 0.0529  decode.d1.loss_mask: 0.4939  decode.d1.loss_dice: 1.0477  decode.d2.loss_cls: 0.0605  decode.d2.loss_mask: 0.4972  decode.d2.loss_dice: 1.0111  decode.d3.loss_cls: 0.0630  decode.d3.loss_mask: 0.4937  decode.d3.loss_dice: 1.0029  decode.d4.loss_cls: 0.0504  decode.d4.loss_mask: 0.4960  decode.d4.loss_dice: 1.0116  decode.d5.loss_cls: 0.0604  decode.d5.loss_mask: 0.4989  decode.d5.loss_dice: 0.9986  decode.d6.loss_cls: 0.0623  decode.d6.loss_mask: 0.4972  decode.d6.loss_dice: 0.9877  decode.d7.loss_cls: 0.0664  decode.d7.loss_mask: 0.4935  decode.d7.loss_dice: 0.9858  decode.d8.loss_cls: 0.0685  decode.d8.loss_mask: 0.4899  decode.d8.loss_dice: 0.9975
11/15 20:45:50 - mmengine - INFO - Iter(train) [79800/90000]  base_lr: 1.4090e-05 lr: 1.4090e-06  eta: 1:42:19  time: 0.6000  data_time: 0.0106  memory: 10675  grad_norm: 242.1786  loss: 15.2197  decode.loss_cls: 0.0604  decode.loss_mask: 0.4342  decode.loss_dice: 1.0095  decode.d0.loss_cls: 0.0836  decode.d0.loss_mask: 0.4611  decode.d0.loss_dice: 1.0896  decode.d1.loss_cls: 0.0697  decode.d1.loss_mask: 0.4365  decode.d1.loss_dice: 1.0170  decode.d2.loss_cls: 0.0547  decode.d2.loss_mask: 0.4668  decode.d2.loss_dice: 1.0083  decode.d3.loss_cls: 0.0684  decode.d3.loss_mask: 0.4460  decode.d3.loss_dice: 0.9985  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.4409  decode.d4.loss_dice: 0.9846  decode.d5.loss_cls: 0.0640  decode.d5.loss_mask: 0.4384  decode.d5.loss_dice: 1.0003  decode.d6.loss_cls: 0.0600  decode.d6.loss_mask: 0.4381  decode.d6.loss_dice: 1.0121  decode.d7.loss_cls: 0.0669  decode.d7.loss_mask: 0.4343  decode.d7.loss_dice: 1.0008  decode.d8.loss_cls: 0.0638  decode.d8.loss_mask: 0.4338  decode.d8.loss_dice: 1.0123
11/15 20:46:20 - mmengine - INFO - Iter(train) [79850/90000]  base_lr: 1.4028e-05 lr: 1.4028e-06  eta: 1:41:49  time: 0.5982  data_time: 0.0105  memory: 10692  grad_norm: 327.7901  loss: 12.2996  decode.loss_cls: 0.0510  decode.loss_mask: 0.3463  decode.loss_dice: 0.7934  decode.d0.loss_cls: 0.1003  decode.d0.loss_mask: 0.3618  decode.d0.loss_dice: 0.8764  decode.d1.loss_cls: 0.0668  decode.d1.loss_mask: 0.3552  decode.d1.loss_dice: 0.8551  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.3523  decode.d2.loss_dice: 0.8318  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.3473  decode.d3.loss_dice: 0.8114  decode.d4.loss_cls: 0.0550  decode.d4.loss_mask: 0.3469  decode.d4.loss_dice: 0.7834  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.3503  decode.d5.loss_dice: 0.7998  decode.d6.loss_cls: 0.0529  decode.d6.loss_mask: 0.3491  decode.d6.loss_dice: 0.8137  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.3479  decode.d7.loss_dice: 0.8148  decode.d8.loss_cls: 0.0517  decode.d8.loss_mask: 0.3486  decode.d8.loss_dice: 0.8111
11/15 20:46:50 - mmengine - INFO - Iter(train) [79900/90000]  base_lr: 1.3966e-05 lr: 1.3966e-06  eta: 1:41:19  time: 0.6000  data_time: 0.0106  memory: 10675  grad_norm: 552.7990  loss: 14.1924  decode.loss_cls: 0.0444  decode.loss_mask: 0.3769  decode.loss_dice: 0.9964  decode.d0.loss_cls: 0.0646  decode.d0.loss_mask: 0.3740  decode.d0.loss_dice: 1.0631  decode.d1.loss_cls: 0.0498  decode.d1.loss_mask: 0.3731  decode.d1.loss_dice: 0.9938  decode.d2.loss_cls: 0.0343  decode.d2.loss_mask: 0.3826  decode.d2.loss_dice: 0.9939  decode.d3.loss_cls: 0.0374  decode.d3.loss_mask: 0.3814  decode.d3.loss_dice: 1.0110  decode.d4.loss_cls: 0.0444  decode.d4.loss_mask: 0.3763  decode.d4.loss_dice: 1.0010  decode.d5.loss_cls: 0.0354  decode.d5.loss_mask: 0.3795  decode.d5.loss_dice: 0.9772  decode.d6.loss_cls: 0.0331  decode.d6.loss_mask: 0.3745  decode.d6.loss_dice: 0.9817  decode.d7.loss_cls: 0.0353  decode.d7.loss_mask: 0.3773  decode.d7.loss_dice: 1.0021  decode.d8.loss_cls: 0.0451  decode.d8.loss_mask: 0.3755  decode.d8.loss_dice: 0.9775
11/15 20:47:20 - mmengine - INFO - Iter(train) [79950/90000]  base_lr: 1.3904e-05 lr: 1.3904e-06  eta: 1:40:49  time: 0.6000  data_time: 0.0106  memory: 10675  grad_norm: 439.4244  loss: 16.3488  decode.loss_cls: 0.0619  decode.loss_mask: 0.4379  decode.loss_dice: 1.1124  decode.d0.loss_cls: 0.0894  decode.d0.loss_mask: 0.4523  decode.d0.loss_dice: 1.1851  decode.d1.loss_cls: 0.0661  decode.d1.loss_mask: 0.4529  decode.d1.loss_dice: 1.1338  decode.d2.loss_cls: 0.0712  decode.d2.loss_mask: 0.4500  decode.d2.loss_dice: 1.1140  decode.d3.loss_cls: 0.0603  decode.d3.loss_mask: 0.4385  decode.d3.loss_dice: 1.1269  decode.d4.loss_cls: 0.0608  decode.d4.loss_mask: 0.4336  decode.d4.loss_dice: 1.0881  decode.d5.loss_cls: 0.0697  decode.d5.loss_mask: 0.4458  decode.d5.loss_dice: 1.1212  decode.d6.loss_cls: 0.0588  decode.d6.loss_mask: 0.4450  decode.d6.loss_dice: 1.1116  decode.d7.loss_cls: 0.0673  decode.d7.loss_mask: 0.4386  decode.d7.loss_dice: 1.1395  decode.d8.loss_cls: 0.0678  decode.d8.loss_mask: 0.4364  decode.d8.loss_dice: 1.1118
11/15 20:47:50 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 20:47:50 - mmengine - INFO - Iter(train) [80000/90000]  base_lr: 1.3842e-05 lr: 1.3842e-06  eta: 1:40:19  time: 0.5995  data_time: 0.0105  memory: 10656  grad_norm: 314.1753  loss: 14.8210  decode.loss_cls: 0.0624  decode.loss_mask: 0.4176  decode.loss_dice: 0.9876  decode.d0.loss_cls: 0.0923  decode.d0.loss_mask: 0.4345  decode.d0.loss_dice: 1.0654  decode.d1.loss_cls: 0.0592  decode.d1.loss_mask: 0.4155  decode.d1.loss_dice: 1.0249  decode.d2.loss_cls: 0.0643  decode.d2.loss_mask: 0.4227  decode.d2.loss_dice: 0.9841  decode.d3.loss_cls: 0.0598  decode.d3.loss_mask: 0.4291  decode.d3.loss_dice: 0.9808  decode.d4.loss_cls: 0.0612  decode.d4.loss_mask: 0.4344  decode.d4.loss_dice: 0.9874  decode.d5.loss_cls: 0.0578  decode.d5.loss_mask: 0.4223  decode.d5.loss_dice: 1.0127  decode.d6.loss_cls: 0.0570  decode.d6.loss_mask: 0.4119  decode.d6.loss_dice: 0.9581  decode.d7.loss_cls: 0.0622  decode.d7.loss_mask: 0.4163  decode.d7.loss_dice: 0.9820  decode.d8.loss_cls: 0.0615  decode.d8.loss_mask: 0.4156  decode.d8.loss_dice: 0.9805
11/15 20:47:50 - mmengine - INFO - Saving checkpoint at 80000 iterations
11/15 20:48:09 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:22  time: 0.3079  data_time: 0.0041  memory: 4095  
11/15 20:48:24 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:04  time: 0.3080  data_time: 0.0039  memory: 4095  
11/15 20:48:40 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:48  time: 0.3082  data_time: 0.0039  memory: 4095  
11/15 20:48:55 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3085  data_time: 0.0040  memory: 4095  
11/15 20:49:11 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3088  data_time: 0.0041  memory: 4095  
11/15 20:49:26 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:01  time: 0.3083  data_time: 0.0039  memory: 4095  
11/15 20:49:42 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3085  data_time: 0.0039  memory: 4095  
11/15 20:49:57 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:30  time: 0.3083  data_time: 0.0039  memory: 4095  
11/15 20:50:13 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3088  data_time: 0.0040  memory: 4095  
11/15 20:50:28 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3079  data_time: 0.0036  memory: 4095  
11/15 20:50:28 - mmengine - INFO - per class results:
11/15 20:50:28 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 97.93 | 98.34 |
|    sidewalk   | 84.77 |  94.4 |
|    building   | 92.88 | 96.58 |
|      wall     | 60.34 | 70.65 |
|     fence     |  61.7 | 75.69 |
|      pole     | 67.85 | 78.76 |
| traffic light | 72.25 | 81.35 |
|  traffic sign | 81.36 | 88.98 |
|   vegetation  | 92.42 | 96.62 |
|    terrain    | 66.57 | 81.31 |
|      sky      | 94.89 | 96.66 |
|     person    | 82.88 | 91.46 |
|     rider     | 66.14 | 81.04 |
|      car      |  95.4 | 97.88 |
|     truck     | 85.07 | 92.85 |
|      bus      | 87.28 | 90.46 |
|     train     | 71.93 | 92.46 |
|   motorcycle  |  67.2 | 80.99 |
|    bicycle    | 79.13 | 87.49 |
+---------------+-------+-------+
11/15 20:50:28 - mmengine - INFO - Iter(val) [500/500]    aAcc: 96.1700  mIoU: 79.3700  mAcc: 88.1000  data_time: 0.0045  time: 0.3092
11/15 20:50:58 - mmengine - INFO - Iter(train) [80050/90000]  base_lr: 1.3779e-05 lr: 1.3779e-06  eta: 1:39:49  time: 0.5993  data_time: 0.0106  memory: 10692  grad_norm: 320.2646  loss: 15.6279  decode.loss_cls: 0.0599  decode.loss_mask: 0.5048  decode.loss_dice: 0.9925  decode.d0.loss_cls: 0.0773  decode.d0.loss_mask: 0.5240  decode.d0.loss_dice: 1.0565  decode.d1.loss_cls: 0.0561  decode.d1.loss_mask: 0.5130  decode.d1.loss_dice: 0.9977  decode.d2.loss_cls: 0.0730  decode.d2.loss_mask: 0.5038  decode.d2.loss_dice: 0.9718  decode.d3.loss_cls: 0.0515  decode.d3.loss_mask: 0.5179  decode.d3.loss_dice: 0.9707  decode.d4.loss_cls: 0.0504  decode.d4.loss_mask: 0.5172  decode.d4.loss_dice: 0.9737  decode.d5.loss_cls: 0.0572  decode.d5.loss_mask: 0.5036  decode.d5.loss_dice: 0.9889  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.4970  decode.d6.loss_dice: 1.0050  decode.d7.loss_cls: 0.0548  decode.d7.loss_mask: 0.4984  decode.d7.loss_dice: 0.9862  decode.d8.loss_cls: 0.0574  decode.d8.loss_mask: 0.5110  decode.d8.loss_dice: 0.9938
11/15 20:51:28 - mmengine - INFO - Iter(train) [80100/90000]  base_lr: 1.3717e-05 lr: 1.3717e-06  eta: 1:39:19  time: 0.6003  data_time: 0.0109  memory: 10692  grad_norm: 285.7887  loss: 14.3496  decode.loss_cls: 0.0441  decode.loss_mask: 0.3911  decode.loss_dice: 0.9895  decode.d0.loss_cls: 0.0750  decode.d0.loss_mask: 0.3953  decode.d0.loss_dice: 1.0605  decode.d1.loss_cls: 0.0457  decode.d1.loss_mask: 0.3945  decode.d1.loss_dice: 1.0105  decode.d2.loss_cls: 0.0389  decode.d2.loss_mask: 0.3967  decode.d2.loss_dice: 0.9807  decode.d3.loss_cls: 0.0375  decode.d3.loss_mask: 0.3896  decode.d3.loss_dice: 0.9748  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 0.3962  decode.d4.loss_dice: 0.9858  decode.d5.loss_cls: 0.0426  decode.d5.loss_mask: 0.3917  decode.d5.loss_dice: 1.0021  decode.d6.loss_cls: 0.0406  decode.d6.loss_mask: 0.3929  decode.d6.loss_dice: 0.9870  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.3919  decode.d7.loss_dice: 1.0035  decode.d8.loss_cls: 0.0448  decode.d8.loss_mask: 0.3899  decode.d8.loss_dice: 0.9720
11/15 20:51:58 - mmengine - INFO - Iter(train) [80150/90000]  base_lr: 1.3655e-05 lr: 1.3655e-06  eta: 1:38:49  time: 0.6013  data_time: 0.0108  memory: 10656  grad_norm: 372.7408  loss: 16.2400  decode.loss_cls: 0.0779  decode.loss_mask: 0.4608  decode.loss_dice: 1.0528  decode.d0.loss_cls: 0.1183  decode.d0.loss_mask: 0.4872  decode.d0.loss_dice: 1.1401  decode.d1.loss_cls: 0.0844  decode.d1.loss_mask: 0.4682  decode.d1.loss_dice: 1.1021  decode.d2.loss_cls: 0.0871  decode.d2.loss_mask: 0.4627  decode.d2.loss_dice: 1.0826  decode.d3.loss_cls: 0.0865  decode.d3.loss_mask: 0.4605  decode.d3.loss_dice: 1.0295  decode.d4.loss_cls: 0.0789  decode.d4.loss_mask: 0.4696  decode.d4.loss_dice: 1.0802  decode.d5.loss_cls: 0.0659  decode.d5.loss_mask: 0.4655  decode.d5.loss_dice: 1.0748  decode.d6.loss_cls: 0.0748  decode.d6.loss_mask: 0.4607  decode.d6.loss_dice: 1.0718  decode.d7.loss_cls: 0.0828  decode.d7.loss_mask: 0.4651  decode.d7.loss_dice: 1.0702  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.4663  decode.d8.loss_dice: 1.0389
11/15 20:52:28 - mmengine - INFO - Iter(train) [80200/90000]  base_lr: 1.3592e-05 lr: 1.3592e-06  eta: 1:38:18  time: 0.5991  data_time: 0.0107  memory: 10692  grad_norm: 483.3032  loss: 15.8793  decode.loss_cls: 0.0456  decode.loss_mask: 0.5548  decode.loss_dice: 0.9697  decode.d0.loss_cls: 0.0886  decode.d0.loss_mask: 0.5855  decode.d0.loss_dice: 1.0340  decode.d1.loss_cls: 0.0452  decode.d1.loss_mask: 0.5621  decode.d1.loss_dice: 1.0277  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.5482  decode.d2.loss_dice: 0.9686  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.5450  decode.d3.loss_dice: 0.9770  decode.d4.loss_cls: 0.0548  decode.d4.loss_mask: 0.5453  decode.d4.loss_dice: 0.9613  decode.d5.loss_cls: 0.0561  decode.d5.loss_mask: 0.5402  decode.d5.loss_dice: 0.9654  decode.d6.loss_cls: 0.0517  decode.d6.loss_mask: 0.5485  decode.d6.loss_dice: 0.9662  decode.d7.loss_cls: 0.0458  decode.d7.loss_mask: 0.5544  decode.d7.loss_dice: 0.9593  decode.d8.loss_cls: 0.0495  decode.d8.loss_mask: 0.5609  decode.d8.loss_dice: 0.9569
11/15 20:52:58 - mmengine - INFO - Iter(train) [80250/90000]  base_lr: 1.3530e-05 lr: 1.3530e-06  eta: 1:37:48  time: 0.5999  data_time: 0.0105  memory: 10692  grad_norm: 253.9539  loss: 14.0829  decode.loss_cls: 0.0749  decode.loss_mask: 0.3532  decode.loss_dice: 0.9308  decode.d0.loss_cls: 0.0803  decode.d0.loss_mask: 0.3733  decode.d0.loss_dice: 1.0677  decode.d1.loss_cls: 0.0750  decode.d1.loss_mask: 0.3641  decode.d1.loss_dice: 1.0153  decode.d2.loss_cls: 0.0643  decode.d2.loss_mask: 0.3578  decode.d2.loss_dice: 0.9815  decode.d3.loss_cls: 0.0688  decode.d3.loss_mask: 0.3573  decode.d3.loss_dice: 0.9717  decode.d4.loss_cls: 0.0732  decode.d4.loss_mask: 0.3568  decode.d4.loss_dice: 0.9650  decode.d5.loss_cls: 0.0695  decode.d5.loss_mask: 0.3579  decode.d5.loss_dice: 0.9739  decode.d6.loss_cls: 0.0792  decode.d6.loss_mask: 0.3570  decode.d6.loss_dice: 0.9417  decode.d7.loss_cls: 0.0789  decode.d7.loss_mask: 0.3529  decode.d7.loss_dice: 0.9420  decode.d8.loss_cls: 0.0739  decode.d8.loss_mask: 0.3550  decode.d8.loss_dice: 0.9698
11/15 20:53:28 - mmengine - INFO - Iter(train) [80300/90000]  base_lr: 1.3467e-05 lr: 1.3467e-06  eta: 1:37:18  time: 0.5988  data_time: 0.0106  memory: 10758  grad_norm: 314.3965  loss: 15.0107  decode.loss_cls: 0.0645  decode.loss_mask: 0.4371  decode.loss_dice: 0.9802  decode.d0.loss_cls: 0.0826  decode.d0.loss_mask: 0.4642  decode.d0.loss_dice: 1.1184  decode.d1.loss_cls: 0.0740  decode.d1.loss_mask: 0.4472  decode.d1.loss_dice: 1.0011  decode.d2.loss_cls: 0.0687  decode.d2.loss_mask: 0.4379  decode.d2.loss_dice: 0.9955  decode.d3.loss_cls: 0.0646  decode.d3.loss_mask: 0.4394  decode.d3.loss_dice: 0.9783  decode.d4.loss_cls: 0.0671  decode.d4.loss_mask: 0.4334  decode.d4.loss_dice: 0.9898  decode.d5.loss_cls: 0.0683  decode.d5.loss_mask: 0.4284  decode.d5.loss_dice: 0.9679  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.4308  decode.d6.loss_dice: 0.9417  decode.d7.loss_cls: 0.0628  decode.d7.loss_mask: 0.4384  decode.d7.loss_dice: 0.9844  decode.d8.loss_cls: 0.0708  decode.d8.loss_mask: 0.4397  decode.d8.loss_dice: 0.9632
11/15 20:53:58 - mmengine - INFO - Iter(train) [80350/90000]  base_lr: 1.3405e-05 lr: 1.3405e-06  eta: 1:36:48  time: 0.5990  data_time: 0.0107  memory: 10656  grad_norm: 285.8737  loss: 14.0550  decode.loss_cls: 0.0377  decode.loss_mask: 0.4448  decode.loss_dice: 0.9162  decode.d0.loss_cls: 0.0645  decode.d0.loss_mask: 0.4653  decode.d0.loss_dice: 0.9694  decode.d1.loss_cls: 0.0519  decode.d1.loss_mask: 0.4463  decode.d1.loss_dice: 0.9078  decode.d2.loss_cls: 0.0396  decode.d2.loss_mask: 0.4582  decode.d2.loss_dice: 0.9275  decode.d3.loss_cls: 0.0340  decode.d3.loss_mask: 0.4476  decode.d3.loss_dice: 0.9150  decode.d4.loss_cls: 0.0418  decode.d4.loss_mask: 0.4407  decode.d4.loss_dice: 0.9219  decode.d5.loss_cls: 0.0362  decode.d5.loss_mask: 0.4380  decode.d5.loss_dice: 0.8878  decode.d6.loss_cls: 0.0367  decode.d6.loss_mask: 0.4406  decode.d6.loss_dice: 0.9085  decode.d7.loss_cls: 0.0385  decode.d7.loss_mask: 0.4401  decode.d7.loss_dice: 0.9093  decode.d8.loss_cls: 0.0418  decode.d8.loss_mask: 0.4414  decode.d8.loss_dice: 0.9058
11/15 20:54:28 - mmengine - INFO - Iter(train) [80400/90000]  base_lr: 1.3342e-05 lr: 1.3342e-06  eta: 1:36:18  time: 0.5996  data_time: 0.0105  memory: 10656  grad_norm: 218.6076  loss: 13.2149  decode.loss_cls: 0.0307  decode.loss_mask: 0.3302  decode.loss_dice: 0.9439  decode.d0.loss_cls: 0.0527  decode.d0.loss_mask: 0.3456  decode.d0.loss_dice: 1.0022  decode.d1.loss_cls: 0.0432  decode.d1.loss_mask: 0.3349  decode.d1.loss_dice: 0.9349  decode.d2.loss_cls: 0.0474  decode.d2.loss_mask: 0.3331  decode.d2.loss_dice: 0.9305  decode.d3.loss_cls: 0.0428  decode.d3.loss_mask: 0.3304  decode.d3.loss_dice: 0.9472  decode.d4.loss_cls: 0.0515  decode.d4.loss_mask: 0.3314  decode.d4.loss_dice: 0.9495  decode.d5.loss_cls: 0.0394  decode.d5.loss_mask: 0.3328  decode.d5.loss_dice: 0.9527  decode.d6.loss_cls: 0.0377  decode.d6.loss_mask: 0.3295  decode.d6.loss_dice: 0.9249  decode.d7.loss_cls: 0.0460  decode.d7.loss_mask: 0.3330  decode.d7.loss_dice: 0.9489  decode.d8.loss_cls: 0.0358  decode.d8.loss_mask: 0.3330  decode.d8.loss_dice: 0.9187
11/15 20:54:58 - mmengine - INFO - Iter(train) [80450/90000]  base_lr: 1.3280e-05 lr: 1.3280e-06  eta: 1:35:48  time: 0.6001  data_time: 0.0108  memory: 10692  grad_norm: 386.8501  loss: 13.5957  decode.loss_cls: 0.0557  decode.loss_mask: 0.4542  decode.loss_dice: 0.8382  decode.d0.loss_cls: 0.0985  decode.d0.loss_mask: 0.4631  decode.d0.loss_dice: 0.9123  decode.d1.loss_cls: 0.0517  decode.d1.loss_mask: 0.4494  decode.d1.loss_dice: 0.8824  decode.d2.loss_cls: 0.0529  decode.d2.loss_mask: 0.4535  decode.d2.loss_dice: 0.8863  decode.d3.loss_cls: 0.0443  decode.d3.loss_mask: 0.4522  decode.d3.loss_dice: 0.8551  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 0.4514  decode.d4.loss_dice: 0.8566  decode.d5.loss_cls: 0.0524  decode.d5.loss_mask: 0.4492  decode.d5.loss_dice: 0.8368  decode.d6.loss_cls: 0.0562  decode.d6.loss_mask: 0.4431  decode.d6.loss_dice: 0.8060  decode.d7.loss_cls: 0.0515  decode.d7.loss_mask: 0.4473  decode.d7.loss_dice: 0.8264  decode.d8.loss_cls: 0.0545  decode.d8.loss_mask: 0.4448  decode.d8.loss_dice: 0.8237
11/15 20:55:28 - mmengine - INFO - Iter(train) [80500/90000]  base_lr: 1.3217e-05 lr: 1.3217e-06  eta: 1:35:18  time: 0.5999  data_time: 0.0106  memory: 10641  grad_norm: 201.6072  loss: 15.4255  decode.loss_cls: 0.0519  decode.loss_mask: 0.4779  decode.loss_dice: 1.0066  decode.d0.loss_cls: 0.0923  decode.d0.loss_mask: 0.4880  decode.d0.loss_dice: 1.0421  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.4721  decode.d1.loss_dice: 1.0065  decode.d2.loss_cls: 0.0574  decode.d2.loss_mask: 0.4766  decode.d2.loss_dice: 0.9960  decode.d3.loss_cls: 0.0619  decode.d3.loss_mask: 0.4776  decode.d3.loss_dice: 0.9993  decode.d4.loss_cls: 0.0555  decode.d4.loss_mask: 0.4760  decode.d4.loss_dice: 1.0152  decode.d5.loss_cls: 0.0673  decode.d5.loss_mask: 0.4771  decode.d5.loss_dice: 0.9868  decode.d6.loss_cls: 0.0630  decode.d6.loss_mask: 0.4692  decode.d6.loss_dice: 0.9860  decode.d7.loss_cls: 0.0656  decode.d7.loss_mask: 0.4676  decode.d7.loss_dice: 0.9969  decode.d8.loss_cls: 0.0508  decode.d8.loss_mask: 0.4733  decode.d8.loss_dice: 1.0057
11/15 20:55:58 - mmengine - INFO - Iter(train) [80550/90000]  base_lr: 1.3155e-05 lr: 1.3155e-06  eta: 1:34:48  time: 0.5994  data_time: 0.0104  memory: 10641  grad_norm: 312.2556  loss: 15.2471  decode.loss_cls: 0.0648  decode.loss_mask: 0.4632  decode.loss_dice: 0.9651  decode.d0.loss_cls: 0.0820  decode.d0.loss_mask: 0.4796  decode.d0.loss_dice: 1.0556  decode.d1.loss_cls: 0.0673  decode.d1.loss_mask: 0.4675  decode.d1.loss_dice: 0.9957  decode.d2.loss_cls: 0.0460  decode.d2.loss_mask: 0.4566  decode.d2.loss_dice: 1.0165  decode.d3.loss_cls: 0.0637  decode.d3.loss_mask: 0.4644  decode.d3.loss_dice: 0.9832  decode.d4.loss_cls: 0.0546  decode.d4.loss_mask: 0.4666  decode.d4.loss_dice: 0.9794  decode.d5.loss_cls: 0.0490  decode.d5.loss_mask: 0.4606  decode.d5.loss_dice: 0.9845  decode.d6.loss_cls: 0.0688  decode.d6.loss_mask: 0.4709  decode.d6.loss_dice: 0.9828  decode.d7.loss_cls: 0.0612  decode.d7.loss_mask: 0.4666  decode.d7.loss_dice: 1.0112  decode.d8.loss_cls: 0.0611  decode.d8.loss_mask: 0.4708  decode.d8.loss_dice: 0.9879
11/15 20:56:28 - mmengine - INFO - Iter(train) [80600/90000]  base_lr: 1.3092e-05 lr: 1.3092e-06  eta: 1:34:18  time: 0.5999  data_time: 0.0106  memory: 10656  grad_norm: 224.5989  loss: 14.8527  decode.loss_cls: 0.0586  decode.loss_mask: 0.4495  decode.loss_dice: 0.9739  decode.d0.loss_cls: 0.0674  decode.d0.loss_mask: 0.4559  decode.d0.loss_dice: 1.0280  decode.d1.loss_cls: 0.0733  decode.d1.loss_mask: 0.4429  decode.d1.loss_dice: 0.9927  decode.d2.loss_cls: 0.0615  decode.d2.loss_mask: 0.4496  decode.d2.loss_dice: 0.9521  decode.d3.loss_cls: 0.0547  decode.d3.loss_mask: 0.4552  decode.d3.loss_dice: 0.9766  decode.d4.loss_cls: 0.0592  decode.d4.loss_mask: 0.4528  decode.d4.loss_dice: 0.9557  decode.d5.loss_cls: 0.0403  decode.d5.loss_mask: 0.4541  decode.d5.loss_dice: 0.9820  decode.d6.loss_cls: 0.0586  decode.d6.loss_mask: 0.4486  decode.d6.loss_dice: 0.9475  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.4492  decode.d7.loss_dice: 0.9720  decode.d8.loss_cls: 0.0531  decode.d8.loss_mask: 0.4529  decode.d8.loss_dice: 0.9838
11/15 20:56:58 - mmengine - INFO - Iter(train) [80650/90000]  base_lr: 1.3029e-05 lr: 1.3029e-06  eta: 1:33:47  time: 0.6025  data_time: 0.0112  memory: 10675  grad_norm: 334.2238  loss: 16.0289  decode.loss_cls: 0.0623  decode.loss_mask: 0.4893  decode.loss_dice: 1.0206  decode.d0.loss_cls: 0.0645  decode.d0.loss_mask: 0.5322  decode.d0.loss_dice: 1.1276  decode.d1.loss_cls: 0.0660  decode.d1.loss_mask: 0.5049  decode.d1.loss_dice: 1.0647  decode.d2.loss_cls: 0.0465  decode.d2.loss_mask: 0.5056  decode.d2.loss_dice: 1.0849  decode.d3.loss_cls: 0.0567  decode.d3.loss_mask: 0.4983  decode.d3.loss_dice: 1.0438  decode.d4.loss_cls: 0.0544  decode.d4.loss_mask: 0.4968  decode.d4.loss_dice: 1.0334  decode.d5.loss_cls: 0.0442  decode.d5.loss_mask: 0.4950  decode.d5.loss_dice: 1.0463  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.4926  decode.d6.loss_dice: 1.0138  decode.d7.loss_cls: 0.0468  decode.d7.loss_mask: 0.4945  decode.d7.loss_dice: 1.0272  decode.d8.loss_cls: 0.0461  decode.d8.loss_mask: 0.4907  decode.d8.loss_dice: 1.0252
11/15 20:57:28 - mmengine - INFO - Iter(train) [80700/90000]  base_lr: 1.2966e-05 lr: 1.2966e-06  eta: 1:33:17  time: 0.5996  data_time: 0.0110  memory: 10656  grad_norm: 279.9127  loss: 14.9690  decode.loss_cls: 0.0644  decode.loss_mask: 0.3806  decode.loss_dice: 1.0243  decode.d0.loss_cls: 0.0762  decode.d0.loss_mask: 0.3982  decode.d0.loss_dice: 1.1987  decode.d1.loss_cls: 0.0672  decode.d1.loss_mask: 0.3851  decode.d1.loss_dice: 1.0747  decode.d2.loss_cls: 0.0740  decode.d2.loss_mask: 0.3823  decode.d2.loss_dice: 1.0396  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 0.3818  decode.d3.loss_dice: 1.0221  decode.d4.loss_cls: 0.0771  decode.d4.loss_mask: 0.3794  decode.d4.loss_dice: 1.0278  decode.d5.loss_cls: 0.0725  decode.d5.loss_mask: 0.3779  decode.d5.loss_dice: 1.0002  decode.d6.loss_cls: 0.0524  decode.d6.loss_mask: 0.3845  decode.d6.loss_dice: 1.0602  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.3766  decode.d7.loss_dice: 1.0071  decode.d8.loss_cls: 0.0646  decode.d8.loss_mask: 0.3798  decode.d8.loss_dice: 1.0055
11/15 20:57:58 - mmengine - INFO - Iter(train) [80750/90000]  base_lr: 1.2904e-05 lr: 1.2904e-06  eta: 1:32:47  time: 0.5992  data_time: 0.0106  memory: 10675  grad_norm: 898.7376  loss: 15.1609  decode.loss_cls: 0.0828  decode.loss_mask: 0.4445  decode.loss_dice: 0.9698  decode.d0.loss_cls: 0.0943  decode.d0.loss_mask: 0.4987  decode.d0.loss_dice: 1.0530  decode.d1.loss_cls: 0.1089  decode.d1.loss_mask: 0.4900  decode.d1.loss_dice: 0.9656  decode.d2.loss_cls: 0.0747  decode.d2.loss_mask: 0.4473  decode.d2.loss_dice: 0.9668  decode.d3.loss_cls: 0.0688  decode.d3.loss_mask: 0.4537  decode.d3.loss_dice: 0.9710  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 0.4523  decode.d4.loss_dice: 0.9628  decode.d5.loss_cls: 0.0786  decode.d5.loss_mask: 0.4439  decode.d5.loss_dice: 0.9791  decode.d6.loss_cls: 0.0712  decode.d6.loss_mask: 0.4513  decode.d6.loss_dice: 0.9354  decode.d7.loss_cls: 0.0715  decode.d7.loss_mask: 0.5042  decode.d7.loss_dice: 0.9452  decode.d8.loss_cls: 0.0697  decode.d8.loss_mask: 0.4593  decode.d8.loss_dice: 0.9750
11/15 20:58:28 - mmengine - INFO - Iter(train) [80800/90000]  base_lr: 1.2841e-05 lr: 1.2841e-06  eta: 1:32:17  time: 0.5981  data_time: 0.0106  memory: 10713  grad_norm: 457.6692  loss: 16.7047  decode.loss_cls: 0.0676  decode.loss_mask: 0.6130  decode.loss_dice: 0.9917  decode.d0.loss_cls: 0.0958  decode.d0.loss_mask: 0.6092  decode.d0.loss_dice: 1.0125  decode.d1.loss_cls: 0.0667  decode.d1.loss_mask: 0.5979  decode.d1.loss_dice: 1.0620  decode.d2.loss_cls: 0.0652  decode.d2.loss_mask: 0.5844  decode.d2.loss_dice: 1.0235  decode.d3.loss_cls: 0.0664  decode.d3.loss_mask: 0.5787  decode.d3.loss_dice: 0.9690  decode.d4.loss_cls: 0.0619  decode.d4.loss_mask: 0.6166  decode.d4.loss_dice: 0.9822  decode.d5.loss_cls: 0.0577  decode.d5.loss_mask: 0.5901  decode.d5.loss_dice: 1.0013  decode.d6.loss_cls: 0.0661  decode.d6.loss_mask: 0.5826  decode.d6.loss_dice: 0.9968  decode.d7.loss_cls: 0.0582  decode.d7.loss_mask: 0.6350  decode.d7.loss_dice: 1.0111  decode.d8.loss_cls: 0.0668  decode.d8.loss_mask: 0.5965  decode.d8.loss_dice: 0.9782
11/15 20:58:58 - mmengine - INFO - Iter(train) [80850/90000]  base_lr: 1.2778e-05 lr: 1.2778e-06  eta: 1:31:47  time: 0.6014  data_time: 0.0108  memory: 10713  grad_norm: 439.7800  loss: 14.7065  decode.loss_cls: 0.0618  decode.loss_mask: 0.4314  decode.loss_dice: 0.9479  decode.d0.loss_cls: 0.0999  decode.d0.loss_mask: 0.4582  decode.d0.loss_dice: 1.0164  decode.d1.loss_cls: 0.0634  decode.d1.loss_mask: 0.4396  decode.d1.loss_dice: 0.9908  decode.d2.loss_cls: 0.0745  decode.d2.loss_mask: 0.4266  decode.d2.loss_dice: 0.9476  decode.d3.loss_cls: 0.0698  decode.d3.loss_mask: 0.4378  decode.d3.loss_dice: 0.9621  decode.d4.loss_cls: 0.0692  decode.d4.loss_mask: 0.4336  decode.d4.loss_dice: 0.9623  decode.d5.loss_cls: 0.0707  decode.d5.loss_mask: 0.4243  decode.d5.loss_dice: 0.9391  decode.d6.loss_cls: 0.0738  decode.d6.loss_mask: 0.4391  decode.d6.loss_dice: 0.9508  decode.d7.loss_cls: 0.0608  decode.d7.loss_mask: 0.4301  decode.d7.loss_dice: 0.9665  decode.d8.loss_cls: 0.0631  decode.d8.loss_mask: 0.4335  decode.d8.loss_dice: 0.9618
11/15 20:59:28 - mmengine - INFO - Iter(train) [80900/90000]  base_lr: 1.2715e-05 lr: 1.2715e-06  eta: 1:31:17  time: 0.5998  data_time: 0.0106  memory: 10656  grad_norm: 380.2290  loss: 14.4737  decode.loss_cls: 0.0662  decode.loss_mask: 0.4144  decode.loss_dice: 0.9491  decode.d0.loss_cls: 0.0906  decode.d0.loss_mask: 0.4325  decode.d0.loss_dice: 1.0258  decode.d1.loss_cls: 0.0730  decode.d1.loss_mask: 0.4221  decode.d1.loss_dice: 0.9574  decode.d2.loss_cls: 0.0783  decode.d2.loss_mask: 0.4152  decode.d2.loss_dice: 0.9657  decode.d3.loss_cls: 0.0693  decode.d3.loss_mask: 0.4179  decode.d3.loss_dice: 0.9352  decode.d4.loss_cls: 0.0729  decode.d4.loss_mask: 0.4171  decode.d4.loss_dice: 0.9336  decode.d5.loss_cls: 0.0661  decode.d5.loss_mask: 0.4147  decode.d5.loss_dice: 0.9370  decode.d6.loss_cls: 0.0706  decode.d6.loss_mask: 0.4144  decode.d6.loss_dice: 0.9350  decode.d7.loss_cls: 0.0625  decode.d7.loss_mask: 0.4173  decode.d7.loss_dice: 0.9583  decode.d8.loss_cls: 0.0748  decode.d8.loss_mask: 0.4149  decode.d8.loss_dice: 0.9717
11/15 20:59:58 - mmengine - INFO - Iter(train) [80950/90000]  base_lr: 1.2652e-05 lr: 1.2652e-06  eta: 1:30:47  time: 0.5990  data_time: 0.0109  memory: 10675  grad_norm: 209.3176  loss: 15.0907  decode.loss_cls: 0.0475  decode.loss_mask: 0.5130  decode.loss_dice: 0.9197  decode.d0.loss_cls: 0.0818  decode.d0.loss_mask: 0.5246  decode.d0.loss_dice: 0.9915  decode.d1.loss_cls: 0.0468  decode.d1.loss_mask: 0.5232  decode.d1.loss_dice: 0.9674  decode.d2.loss_cls: 0.0405  decode.d2.loss_mask: 0.5137  decode.d2.loss_dice: 0.9607  decode.d3.loss_cls: 0.0507  decode.d3.loss_mask: 0.5122  decode.d3.loss_dice: 0.9289  decode.d4.loss_cls: 0.0425  decode.d4.loss_mask: 0.5135  decode.d4.loss_dice: 0.9530  decode.d5.loss_cls: 0.0517  decode.d5.loss_mask: 0.5082  decode.d5.loss_dice: 0.9361  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.5116  decode.d6.loss_dice: 0.9283  decode.d7.loss_cls: 0.0497  decode.d7.loss_mask: 0.5103  decode.d7.loss_dice: 0.9167  decode.d8.loss_cls: 0.0414  decode.d8.loss_mask: 0.5137  decode.d8.loss_dice: 0.9424
11/15 21:00:33 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 21:00:33 - mmengine - INFO - Iter(train) [81000/90000]  base_lr: 1.2589e-05 lr: 1.2589e-06  eta: 1:30:17  time: 0.5989  data_time: 0.0106  memory: 10675  grad_norm: 344.5640  loss: 14.1981  decode.loss_cls: 0.0615  decode.loss_mask: 0.4293  decode.loss_dice: 0.9126  decode.d0.loss_cls: 0.0932  decode.d0.loss_mask: 0.4399  decode.d0.loss_dice: 0.9740  decode.d1.loss_cls: 0.0973  decode.d1.loss_mask: 0.4246  decode.d1.loss_dice: 0.9200  decode.d2.loss_cls: 0.0833  decode.d2.loss_mask: 0.4219  decode.d2.loss_dice: 0.9553  decode.d3.loss_cls: 0.0839  decode.d3.loss_mask: 0.4226  decode.d3.loss_dice: 0.8988  decode.d4.loss_cls: 0.0726  decode.d4.loss_mask: 0.4269  decode.d4.loss_dice: 0.8892  decode.d5.loss_cls: 0.0809  decode.d5.loss_mask: 0.4230  decode.d5.loss_dice: 0.8716  decode.d6.loss_cls: 0.0666  decode.d6.loss_mask: 0.4260  decode.d6.loss_dice: 0.9106  decode.d7.loss_cls: 0.0735  decode.d7.loss_mask: 0.4267  decode.d7.loss_dice: 0.8993  decode.d8.loss_cls: 0.0666  decode.d8.loss_mask: 0.4305  decode.d8.loss_dice: 0.9158
11/15 21:01:03 - mmengine - INFO - Iter(train) [81050/90000]  base_lr: 1.2526e-05 lr: 1.2526e-06  eta: 1:29:47  time: 0.6009  data_time: 0.0107  memory: 10692  grad_norm: 385.0876  loss: 15.9719  decode.loss_cls: 0.0619  decode.loss_mask: 0.4394  decode.loss_dice: 1.0553  decode.d0.loss_cls: 0.0837  decode.d0.loss_mask: 0.4404  decode.d0.loss_dice: 1.1667  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.4429  decode.d1.loss_dice: 1.1112  decode.d2.loss_cls: 0.0757  decode.d2.loss_mask: 0.4450  decode.d2.loss_dice: 1.0937  decode.d3.loss_cls: 0.0677  decode.d3.loss_mask: 0.4451  decode.d3.loss_dice: 1.0454  decode.d4.loss_cls: 0.0616  decode.d4.loss_mask: 0.4477  decode.d4.loss_dice: 1.0785  decode.d5.loss_cls: 0.0754  decode.d5.loss_mask: 0.4416  decode.d5.loss_dice: 1.0777  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.4466  decode.d6.loss_dice: 1.0876  decode.d7.loss_cls: 0.0664  decode.d7.loss_mask: 0.4387  decode.d7.loss_dice: 1.0635  decode.d8.loss_cls: 0.0555  decode.d8.loss_mask: 0.4356  decode.d8.loss_dice: 1.0820
11/15 21:01:33 - mmengine - INFO - Iter(train) [81100/90000]  base_lr: 1.2463e-05 lr: 1.2463e-06  eta: 1:29:17  time: 0.6034  data_time: 0.0112  memory: 10675  grad_norm: 322.0473  loss: 13.7004  decode.loss_cls: 0.0602  decode.loss_mask: 0.3761  decode.loss_dice: 0.9207  decode.d0.loss_cls: 0.0819  decode.d0.loss_mask: 0.3900  decode.d0.loss_dice: 1.0003  decode.d1.loss_cls: 0.0714  decode.d1.loss_mask: 0.3703  decode.d1.loss_dice: 0.9350  decode.d2.loss_cls: 0.0539  decode.d2.loss_mask: 0.3709  decode.d2.loss_dice: 0.9286  decode.d3.loss_cls: 0.0468  decode.d3.loss_mask: 0.3740  decode.d3.loss_dice: 0.9334  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.3726  decode.d4.loss_dice: 0.9292  decode.d5.loss_cls: 0.0549  decode.d5.loss_mask: 0.3720  decode.d5.loss_dice: 0.8950  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.3736  decode.d6.loss_dice: 0.9281  decode.d7.loss_cls: 0.0572  decode.d7.loss_mask: 0.3758  decode.d7.loss_dice: 0.9416  decode.d8.loss_cls: 0.0537  decode.d8.loss_mask: 0.3811  decode.d8.loss_dice: 0.9389
11/15 21:02:03 - mmengine - INFO - Iter(train) [81150/90000]  base_lr: 1.2400e-05 lr: 1.2400e-06  eta: 1:28:47  time: 0.6009  data_time: 0.0107  memory: 10675  grad_norm: 317.0826  loss: 14.3261  decode.loss_cls: 0.0571  decode.loss_mask: 0.4208  decode.loss_dice: 0.9252  decode.d0.loss_cls: 0.0881  decode.d0.loss_mask: 0.4736  decode.d0.loss_dice: 0.9800  decode.d1.loss_cls: 0.0517  decode.d1.loss_mask: 0.4595  decode.d1.loss_dice: 0.9441  decode.d2.loss_cls: 0.0478  decode.d2.loss_mask: 0.4344  decode.d2.loss_dice: 0.9412  decode.d3.loss_cls: 0.0496  decode.d3.loss_mask: 0.4272  decode.d3.loss_dice: 0.9352  decode.d4.loss_cls: 0.0410  decode.d4.loss_mask: 0.4455  decode.d4.loss_dice: 0.9377  decode.d5.loss_cls: 0.0525  decode.d5.loss_mask: 0.4300  decode.d5.loss_dice: 0.9260  decode.d6.loss_cls: 0.0531  decode.d6.loss_mask: 0.4153  decode.d6.loss_dice: 0.9213  decode.d7.loss_cls: 0.0456  decode.d7.loss_mask: 0.4334  decode.d7.loss_dice: 0.9559  decode.d8.loss_cls: 0.0498  decode.d8.loss_mask: 0.4307  decode.d8.loss_dice: 0.9528
11/15 21:02:34 - mmengine - INFO - Iter(train) [81200/90000]  base_lr: 1.2337e-05 lr: 1.2337e-06  eta: 1:28:17  time: 0.6004  data_time: 0.0107  memory: 10692  grad_norm: 255.8667  loss: 15.1261  decode.loss_cls: 0.0847  decode.loss_mask: 0.3537  decode.loss_dice: 1.0551  decode.d0.loss_cls: 0.0826  decode.d0.loss_mask: 0.3723  decode.d0.loss_dice: 1.1458  decode.d1.loss_cls: 0.0917  decode.d1.loss_mask: 0.3614  decode.d1.loss_dice: 1.0768  decode.d2.loss_cls: 0.0942  decode.d2.loss_mask: 0.3578  decode.d2.loss_dice: 1.0764  decode.d3.loss_cls: 0.0788  decode.d3.loss_mask: 0.3552  decode.d3.loss_dice: 1.0472  decode.d4.loss_cls: 0.0935  decode.d4.loss_mask: 0.3518  decode.d4.loss_dice: 1.0336  decode.d5.loss_cls: 0.0734  decode.d5.loss_mask: 0.3557  decode.d5.loss_dice: 1.0780  decode.d6.loss_cls: 0.0931  decode.d6.loss_mask: 0.3538  decode.d6.loss_dice: 1.0452  decode.d7.loss_cls: 0.0779  decode.d7.loss_mask: 0.3536  decode.d7.loss_dice: 1.0807  decode.d8.loss_cls: 0.0779  decode.d8.loss_mask: 0.3530  decode.d8.loss_dice: 1.0711
11/15 21:03:04 - mmengine - INFO - Iter(train) [81250/90000]  base_lr: 1.2274e-05 lr: 1.2274e-06  eta: 1:27:47  time: 0.6021  data_time: 0.0110  memory: 10728  grad_norm: 478.6509  loss: 15.9391  decode.loss_cls: 0.0470  decode.loss_mask: 0.4581  decode.loss_dice: 1.0710  decode.d0.loss_cls: 0.0922  decode.d0.loss_mask: 0.4700  decode.d0.loss_dice: 1.0874  decode.d1.loss_cls: 0.0733  decode.d1.loss_mask: 0.4544  decode.d1.loss_dice: 1.0807  decode.d2.loss_cls: 0.0585  decode.d2.loss_mask: 0.4572  decode.d2.loss_dice: 1.0728  decode.d3.loss_cls: 0.0531  decode.d3.loss_mask: 0.4622  decode.d3.loss_dice: 1.1017  decode.d4.loss_cls: 0.0480  decode.d4.loss_mask: 0.4605  decode.d4.loss_dice: 1.0955  decode.d5.loss_cls: 0.0525  decode.d5.loss_mask: 0.4550  decode.d5.loss_dice: 1.0658  decode.d6.loss_cls: 0.0426  decode.d6.loss_mask: 0.4602  decode.d6.loss_dice: 1.0792  decode.d7.loss_cls: 0.0523  decode.d7.loss_mask: 0.4577  decode.d7.loss_dice: 1.0655  decode.d8.loss_cls: 0.0530  decode.d8.loss_mask: 0.4558  decode.d8.loss_dice: 1.0559
11/15 21:03:34 - mmengine - INFO - Iter(train) [81300/90000]  base_lr: 1.2211e-05 lr: 1.2211e-06  eta: 1:27:17  time: 0.6007  data_time: 0.0107  memory: 10713  grad_norm: 269.6930  loss: 14.3550  decode.loss_cls: 0.0408  decode.loss_mask: 0.4712  decode.loss_dice: 0.9171  decode.d0.loss_cls: 0.0594  decode.d0.loss_mask: 0.5025  decode.d0.loss_dice: 0.9399  decode.d1.loss_cls: 0.0372  decode.d1.loss_mask: 0.4709  decode.d1.loss_dice: 0.9099  decode.d2.loss_cls: 0.0331  decode.d2.loss_mask: 0.4761  decode.d2.loss_dice: 0.9038  decode.d3.loss_cls: 0.0303  decode.d3.loss_mask: 0.4762  decode.d3.loss_dice: 0.9197  decode.d4.loss_cls: 0.0289  decode.d4.loss_mask: 0.4762  decode.d4.loss_dice: 0.9291  decode.d5.loss_cls: 0.0323  decode.d5.loss_mask: 0.4759  decode.d5.loss_dice: 0.9076  decode.d6.loss_cls: 0.0361  decode.d6.loss_mask: 0.4779  decode.d6.loss_dice: 0.9262  decode.d7.loss_cls: 0.0279  decode.d7.loss_mask: 0.4765  decode.d7.loss_dice: 0.9235  decode.d8.loss_cls: 0.0375  decode.d8.loss_mask: 0.4767  decode.d8.loss_dice: 0.9346
11/15 21:04:04 - mmengine - INFO - Iter(train) [81350/90000]  base_lr: 1.2148e-05 lr: 1.2148e-06  eta: 1:26:47  time: 0.6087  data_time: 0.0113  memory: 10713  grad_norm: 453.1364  loss: 13.9319  decode.loss_cls: 0.0486  decode.loss_mask: 0.4157  decode.loss_dice: 0.9262  decode.d0.loss_cls: 0.0898  decode.d0.loss_mask: 0.4476  decode.d0.loss_dice: 0.9796  decode.d1.loss_cls: 0.0560  decode.d1.loss_mask: 0.4207  decode.d1.loss_dice: 0.9492  decode.d2.loss_cls: 0.0560  decode.d2.loss_mask: 0.4175  decode.d2.loss_dice: 0.9098  decode.d3.loss_cls: 0.0514  decode.d3.loss_mask: 0.4145  decode.d3.loss_dice: 0.9188  decode.d4.loss_cls: 0.0473  decode.d4.loss_mask: 0.4126  decode.d4.loss_dice: 0.8863  decode.d5.loss_cls: 0.0456  decode.d5.loss_mask: 0.4136  decode.d5.loss_dice: 0.9043  decode.d6.loss_cls: 0.0470  decode.d6.loss_mask: 0.4156  decode.d6.loss_dice: 0.9091  decode.d7.loss_cls: 0.0480  decode.d7.loss_mask: 0.4166  decode.d7.loss_dice: 0.9130  decode.d8.loss_cls: 0.0481  decode.d8.loss_mask: 0.4120  decode.d8.loss_dice: 0.9115
11/15 21:04:34 - mmengine - INFO - Iter(train) [81400/90000]  base_lr: 1.2085e-05 lr: 1.2085e-06  eta: 1:26:16  time: 0.5994  data_time: 0.0107  memory: 10675  grad_norm: 486.6183  loss: 15.2448  decode.loss_cls: 0.0575  decode.loss_mask: 0.4531  decode.loss_dice: 0.9897  decode.d0.loss_cls: 0.0946  decode.d0.loss_mask: 0.4741  decode.d0.loss_dice: 1.0514  decode.d1.loss_cls: 0.0730  decode.d1.loss_mask: 0.4677  decode.d1.loss_dice: 1.0154  decode.d2.loss_cls: 0.0579  decode.d2.loss_mask: 0.4589  decode.d2.loss_dice: 1.0022  decode.d3.loss_cls: 0.0503  decode.d3.loss_mask: 0.4593  decode.d3.loss_dice: 1.0164  decode.d4.loss_cls: 0.0539  decode.d4.loss_mask: 0.4598  decode.d4.loss_dice: 0.9895  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.4517  decode.d5.loss_dice: 1.0081  decode.d6.loss_cls: 0.0622  decode.d6.loss_mask: 0.4567  decode.d6.loss_dice: 0.9785  decode.d7.loss_cls: 0.0559  decode.d7.loss_mask: 0.4529  decode.d7.loss_dice: 0.9918  decode.d8.loss_cls: 0.0479  decode.d8.loss_mask: 0.4512  decode.d8.loss_dice: 1.0146
11/15 21:05:04 - mmengine - INFO - Iter(train) [81450/90000]  base_lr: 1.2021e-05 lr: 1.2021e-06  eta: 1:25:46  time: 0.6024  data_time: 0.0111  memory: 10713  grad_norm: 227.9242  loss: 15.1527  decode.loss_cls: 0.0746  decode.loss_mask: 0.4709  decode.loss_dice: 0.9258  decode.d0.loss_cls: 0.0906  decode.d0.loss_mask: 0.5278  decode.d0.loss_dice: 1.0416  decode.d1.loss_cls: 0.0795  decode.d1.loss_mask: 0.4811  decode.d1.loss_dice: 0.9672  decode.d2.loss_cls: 0.0790  decode.d2.loss_mask: 0.4866  decode.d2.loss_dice: 0.9895  decode.d3.loss_cls: 0.0718  decode.d3.loss_mask: 0.4802  decode.d3.loss_dice: 0.9401  decode.d4.loss_cls: 0.0668  decode.d4.loss_mask: 0.4805  decode.d4.loss_dice: 0.9477  decode.d5.loss_cls: 0.0689  decode.d5.loss_mask: 0.4773  decode.d5.loss_dice: 0.9505  decode.d6.loss_cls: 0.0739  decode.d6.loss_mask: 0.4679  decode.d6.loss_dice: 0.9556  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 0.4761  decode.d7.loss_dice: 0.9379  decode.d8.loss_cls: 0.0615  decode.d8.loss_mask: 0.4690  decode.d8.loss_dice: 0.9425
11/15 21:05:35 - mmengine - INFO - Iter(train) [81500/90000]  base_lr: 1.1958e-05 lr: 1.1958e-06  eta: 1:25:16  time: 0.5998  data_time: 0.0107  memory: 10675  grad_norm: 369.0376  loss: 15.5811  decode.loss_cls: 0.0507  decode.loss_mask: 0.4467  decode.loss_dice: 1.0363  decode.d0.loss_cls: 0.0625  decode.d0.loss_mask: 0.4784  decode.d0.loss_dice: 1.1417  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 0.4538  decode.d1.loss_dice: 1.0600  decode.d2.loss_cls: 0.0595  decode.d2.loss_mask: 0.4510  decode.d2.loss_dice: 1.0508  decode.d3.loss_cls: 0.0595  decode.d3.loss_mask: 0.4494  decode.d3.loss_dice: 1.0206  decode.d4.loss_cls: 0.0569  decode.d4.loss_mask: 0.4499  decode.d4.loss_dice: 1.0272  decode.d5.loss_cls: 0.0519  decode.d5.loss_mask: 0.4500  decode.d5.loss_dice: 1.0291  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.4573  decode.d6.loss_dice: 1.0269  decode.d7.loss_cls: 0.0531  decode.d7.loss_mask: 0.4570  decode.d7.loss_dice: 1.0318  decode.d8.loss_cls: 0.0441  decode.d8.loss_mask: 0.4570  decode.d8.loss_dice: 1.0564
11/15 21:06:05 - mmengine - INFO - Iter(train) [81550/90000]  base_lr: 1.1895e-05 lr: 1.1895e-06  eta: 1:24:46  time: 0.6009  data_time: 0.0107  memory: 10728  grad_norm: 368.9936  loss: 14.9053  decode.loss_cls: 0.0555  decode.loss_mask: 0.4124  decode.loss_dice: 0.9912  decode.d0.loss_cls: 0.0765  decode.d0.loss_mask: 0.4328  decode.d0.loss_dice: 1.1132  decode.d1.loss_cls: 0.0604  decode.d1.loss_mask: 0.4111  decode.d1.loss_dice: 1.0308  decode.d2.loss_cls: 0.0550  decode.d2.loss_mask: 0.4057  decode.d2.loss_dice: 1.0249  decode.d3.loss_cls: 0.0572  decode.d3.loss_mask: 0.4043  decode.d3.loss_dice: 1.0289  decode.d4.loss_cls: 0.0503  decode.d4.loss_mask: 0.4082  decode.d4.loss_dice: 1.0170  decode.d5.loss_cls: 0.0503  decode.d5.loss_mask: 0.4057  decode.d5.loss_dice: 1.0001  decode.d6.loss_cls: 0.0457  decode.d6.loss_mask: 0.4039  decode.d6.loss_dice: 1.0189  decode.d7.loss_cls: 0.0567  decode.d7.loss_mask: 0.4155  decode.d7.loss_dice: 1.0046  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 0.4127  decode.d8.loss_dice: 0.9951
11/15 21:06:35 - mmengine - INFO - Iter(train) [81600/90000]  base_lr: 1.1831e-05 lr: 1.1831e-06  eta: 1:24:16  time: 0.6009  data_time: 0.0107  memory: 10742  grad_norm: 239.6832  loss: 13.5816  decode.loss_cls: 0.0488  decode.loss_mask: 0.4458  decode.loss_dice: 0.8476  decode.d0.loss_cls: 0.0625  decode.d0.loss_mask: 0.4553  decode.d0.loss_dice: 0.9387  decode.d1.loss_cls: 0.0532  decode.d1.loss_mask: 0.4382  decode.d1.loss_dice: 0.8876  decode.d2.loss_cls: 0.0444  decode.d2.loss_mask: 0.4366  decode.d2.loss_dice: 0.8895  decode.d3.loss_cls: 0.0446  decode.d3.loss_mask: 0.4284  decode.d3.loss_dice: 0.8441  decode.d4.loss_cls: 0.0434  decode.d4.loss_mask: 0.4359  decode.d4.loss_dice: 0.8720  decode.d5.loss_cls: 0.0473  decode.d5.loss_mask: 0.4365  decode.d5.loss_dice: 0.8494  decode.d6.loss_cls: 0.0459  decode.d6.loss_mask: 0.4433  decode.d6.loss_dice: 0.8484  decode.d7.loss_cls: 0.0473  decode.d7.loss_mask: 0.4458  decode.d7.loss_dice: 0.8549  decode.d8.loss_cls: 0.0477  decode.d8.loss_mask: 0.4363  decode.d8.loss_dice: 0.8623
11/15 21:07:05 - mmengine - INFO - Iter(train) [81650/90000]  base_lr: 1.1768e-05 lr: 1.1768e-06  eta: 1:23:46  time: 0.5999  data_time: 0.0108  memory: 10656  grad_norm: 257.8985  loss: 16.3761  decode.loss_cls: 0.0581  decode.loss_mask: 0.5028  decode.loss_dice: 1.0512  decode.d0.loss_cls: 0.0985  decode.d0.loss_mask: 0.5211  decode.d0.loss_dice: 1.1350  decode.d1.loss_cls: 0.0721  decode.d1.loss_mask: 0.4964  decode.d1.loss_dice: 1.0887  decode.d2.loss_cls: 0.0824  decode.d2.loss_mask: 0.4903  decode.d2.loss_dice: 1.0514  decode.d3.loss_cls: 0.0720  decode.d3.loss_mask: 0.4953  decode.d3.loss_dice: 1.0561  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 0.5059  decode.d4.loss_dice: 1.0659  decode.d5.loss_cls: 0.0782  decode.d5.loss_mask: 0.5004  decode.d5.loss_dice: 1.0370  decode.d6.loss_cls: 0.0806  decode.d6.loss_mask: 0.5063  decode.d6.loss_dice: 1.0287  decode.d7.loss_cls: 0.0732  decode.d7.loss_mask: 0.5037  decode.d7.loss_dice: 1.0361  decode.d8.loss_cls: 0.0684  decode.d8.loss_mask: 0.4959  decode.d8.loss_dice: 1.0546
11/15 21:07:35 - mmengine - INFO - Iter(train) [81700/90000]  base_lr: 1.1705e-05 lr: 1.1705e-06  eta: 1:23:16  time: 0.6016  data_time: 0.0108  memory: 10692  grad_norm: 344.7005  loss: 15.5246  decode.loss_cls: 0.0654  decode.loss_mask: 0.4483  decode.loss_dice: 1.0237  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 0.4583  decode.d0.loss_dice: 1.1332  decode.d1.loss_cls: 0.0761  decode.d1.loss_mask: 0.4507  decode.d1.loss_dice: 1.0345  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.4528  decode.d2.loss_dice: 1.0462  decode.d3.loss_cls: 0.0627  decode.d3.loss_mask: 0.4469  decode.d3.loss_dice: 1.0141  decode.d4.loss_cls: 0.0564  decode.d4.loss_mask: 0.4607  decode.d4.loss_dice: 1.0270  decode.d5.loss_cls: 0.0613  decode.d5.loss_mask: 0.4551  decode.d5.loss_dice: 1.0119  decode.d6.loss_cls: 0.0617  decode.d6.loss_mask: 0.4400  decode.d6.loss_dice: 1.0256  decode.d7.loss_cls: 0.0697  decode.d7.loss_mask: 0.4406  decode.d7.loss_dice: 1.0340  decode.d8.loss_cls: 0.0587  decode.d8.loss_mask: 0.4483  decode.d8.loss_dice: 1.0270
11/15 21:08:05 - mmengine - INFO - Iter(train) [81750/90000]  base_lr: 1.1641e-05 lr: 1.1641e-06  eta: 1:22:46  time: 0.6006  data_time: 0.0108  memory: 10692  grad_norm: 477.6603  loss: 14.8364  decode.loss_cls: 0.0441  decode.loss_mask: 0.4295  decode.loss_dice: 0.9731  decode.d0.loss_cls: 0.0769  decode.d0.loss_mask: 0.4689  decode.d0.loss_dice: 1.0364  decode.d1.loss_cls: 0.0551  decode.d1.loss_mask: 0.4446  decode.d1.loss_dice: 0.9945  decode.d2.loss_cls: 0.0605  decode.d2.loss_mask: 0.4371  decode.d2.loss_dice: 0.9732  decode.d3.loss_cls: 0.0558  decode.d3.loss_mask: 0.4362  decode.d3.loss_dice: 0.9822  decode.d4.loss_cls: 0.0454  decode.d4.loss_mask: 0.4335  decode.d4.loss_dice: 1.0028  decode.d5.loss_cls: 0.0460  decode.d5.loss_mask: 0.4393  decode.d5.loss_dice: 0.9992  decode.d6.loss_cls: 0.0419  decode.d6.loss_mask: 0.4381  decode.d6.loss_dice: 0.9777  decode.d7.loss_cls: 0.0416  decode.d7.loss_mask: 0.4378  decode.d7.loss_dice: 1.0063  decode.d8.loss_cls: 0.0385  decode.d8.loss_mask: 0.4318  decode.d8.loss_dice: 0.9881
11/15 21:08:35 - mmengine - INFO - Iter(train) [81800/90000]  base_lr: 1.1578e-05 lr: 1.1578e-06  eta: 1:22:16  time: 0.5993  data_time: 0.0107  memory: 10675  grad_norm: 269.0414  loss: 16.5622  decode.loss_cls: 0.0399  decode.loss_mask: 0.5380  decode.loss_dice: 1.0781  decode.d0.loss_cls: 0.0670  decode.d0.loss_mask: 0.5360  decode.d0.loss_dice: 1.1267  decode.d1.loss_cls: 0.0362  decode.d1.loss_mask: 0.5333  decode.d1.loss_dice: 1.0903  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 0.5319  decode.d2.loss_dice: 1.0594  decode.d3.loss_cls: 0.0327  decode.d3.loss_mask: 0.5363  decode.d3.loss_dice: 1.0713  decode.d4.loss_cls: 0.0419  decode.d4.loss_mask: 0.5391  decode.d4.loss_dice: 1.0696  decode.d5.loss_cls: 0.0413  decode.d5.loss_mask: 0.5416  decode.d5.loss_dice: 1.0703  decode.d6.loss_cls: 0.0404  decode.d6.loss_mask: 0.5361  decode.d6.loss_dice: 1.0800  decode.d7.loss_cls: 0.0384  decode.d7.loss_mask: 0.5247  decode.d7.loss_dice: 1.0499  decode.d8.loss_cls: 0.0468  decode.d8.loss_mask: 0.5363  decode.d8.loss_dice: 1.0800
11/15 21:09:05 - mmengine - INFO - Iter(train) [81850/90000]  base_lr: 1.1514e-05 lr: 1.1514e-06  eta: 1:21:46  time: 0.6030  data_time: 0.0108  memory: 10692  grad_norm: 228.8153  loss: 15.0342  decode.loss_cls: 0.0528  decode.loss_mask: 0.4419  decode.loss_dice: 0.9889  decode.d0.loss_cls: 0.0847  decode.d0.loss_mask: 0.4563  decode.d0.loss_dice: 1.0376  decode.d1.loss_cls: 0.0649  decode.d1.loss_mask: 0.4472  decode.d1.loss_dice: 1.0102  decode.d2.loss_cls: 0.0620  decode.d2.loss_mask: 0.4474  decode.d2.loss_dice: 0.9845  decode.d3.loss_cls: 0.0537  decode.d3.loss_mask: 0.4472  decode.d3.loss_dice: 0.9850  decode.d4.loss_cls: 0.0540  decode.d4.loss_mask: 0.4487  decode.d4.loss_dice: 0.9914  decode.d5.loss_cls: 0.0521  decode.d5.loss_mask: 0.4482  decode.d5.loss_dice: 0.9926  decode.d6.loss_cls: 0.0523  decode.d6.loss_mask: 0.4428  decode.d6.loss_dice: 0.9936  decode.d7.loss_cls: 0.0486  decode.d7.loss_mask: 0.4443  decode.d7.loss_dice: 1.0006  decode.d8.loss_cls: 0.0519  decode.d8.loss_mask: 0.4471  decode.d8.loss_dice: 1.0015
11/15 21:09:35 - mmengine - INFO - Iter(train) [81900/90000]  base_lr: 1.1450e-05 lr: 1.1450e-06  eta: 1:21:16  time: 0.5992  data_time: 0.0105  memory: 10675  grad_norm: 364.2822  loss: 15.6457  decode.loss_cls: 0.0657  decode.loss_mask: 0.4546  decode.loss_dice: 1.0258  decode.d0.loss_cls: 0.0942  decode.d0.loss_mask: 0.4788  decode.d0.loss_dice: 1.1035  decode.d1.loss_cls: 0.0746  decode.d1.loss_mask: 0.4638  decode.d1.loss_dice: 1.0715  decode.d2.loss_cls: 0.0656  decode.d2.loss_mask: 0.4628  decode.d2.loss_dice: 1.0505  decode.d3.loss_cls: 0.0695  decode.d3.loss_mask: 0.4541  decode.d3.loss_dice: 1.0125  decode.d4.loss_cls: 0.0664  decode.d4.loss_mask: 0.4570  decode.d4.loss_dice: 1.0231  decode.d5.loss_cls: 0.0705  decode.d5.loss_mask: 0.4558  decode.d5.loss_dice: 1.0059  decode.d6.loss_cls: 0.0674  decode.d6.loss_mask: 0.4544  decode.d6.loss_dice: 1.0166  decode.d7.loss_cls: 0.0644  decode.d7.loss_mask: 0.4555  decode.d7.loss_dice: 1.0205  decode.d8.loss_cls: 0.0666  decode.d8.loss_mask: 0.4613  decode.d8.loss_dice: 1.0130
11/15 21:10:05 - mmengine - INFO - Iter(train) [81950/90000]  base_lr: 1.1387e-05 lr: 1.1387e-06  eta: 1:20:45  time: 0.6008  data_time: 0.0108  memory: 10692  grad_norm: 431.3930  loss: 14.2831  decode.loss_cls: 0.0498  decode.loss_mask: 0.4379  decode.loss_dice: 0.9237  decode.d0.loss_cls: 0.0799  decode.d0.loss_mask: 0.4782  decode.d0.loss_dice: 1.0197  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.4438  decode.d1.loss_dice: 0.9597  decode.d2.loss_cls: 0.0485  decode.d2.loss_mask: 0.4423  decode.d2.loss_dice: 0.9669  decode.d3.loss_cls: 0.0523  decode.d3.loss_mask: 0.4398  decode.d3.loss_dice: 0.9051  decode.d4.loss_cls: 0.0444  decode.d4.loss_mask: 0.4407  decode.d4.loss_dice: 0.8983  decode.d5.loss_cls: 0.0468  decode.d5.loss_mask: 0.4380  decode.d5.loss_dice: 0.9103  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.4387  decode.d6.loss_dice: 0.9023  decode.d7.loss_cls: 0.0432  decode.d7.loss_mask: 0.4412  decode.d7.loss_dice: 0.9317  decode.d8.loss_cls: 0.0506  decode.d8.loss_mask: 0.4359  decode.d8.loss_dice: 0.9109
11/15 21:10:35 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 21:10:35 - mmengine - INFO - Iter(train) [82000/90000]  base_lr: 1.1323e-05 lr: 1.1323e-06  eta: 1:20:15  time: 0.5993  data_time: 0.0106  memory: 10641  grad_norm: 263.8730  loss: 14.7610  decode.loss_cls: 0.0488  decode.loss_mask: 0.4488  decode.loss_dice: 0.9646  decode.d0.loss_cls: 0.0878  decode.d0.loss_mask: 0.4630  decode.d0.loss_dice: 1.0386  decode.d1.loss_cls: 0.0630  decode.d1.loss_mask: 0.4376  decode.d1.loss_dice: 0.9752  decode.d2.loss_cls: 0.0524  decode.d2.loss_mask: 0.4484  decode.d2.loss_dice: 0.9804  decode.d3.loss_cls: 0.0543  decode.d3.loss_mask: 0.4351  decode.d3.loss_dice: 0.9552  decode.d4.loss_cls: 0.0552  decode.d4.loss_mask: 0.4330  decode.d4.loss_dice: 0.9522  decode.d5.loss_cls: 0.0554  decode.d5.loss_mask: 0.4446  decode.d5.loss_dice: 0.9751  decode.d6.loss_cls: 0.0520  decode.d6.loss_mask: 0.4335  decode.d6.loss_dice: 0.9602  decode.d7.loss_cls: 0.0525  decode.d7.loss_mask: 0.4488  decode.d7.loss_dice: 0.9802  decode.d8.loss_cls: 0.0564  decode.d8.loss_mask: 0.4340  decode.d8.loss_dice: 0.9749
11/15 21:11:05 - mmengine - INFO - Iter(train) [82050/90000]  base_lr: 1.1259e-05 lr: 1.1259e-06  eta: 1:19:45  time: 0.5992  data_time: 0.0107  memory: 10728  grad_norm: 299.4008  loss: 15.0838  decode.loss_cls: 0.0522  decode.loss_mask: 0.4091  decode.loss_dice: 1.0398  decode.d0.loss_cls: 0.0928  decode.d0.loss_mask: 0.4204  decode.d0.loss_dice: 1.1299  decode.d1.loss_cls: 0.0754  decode.d1.loss_mask: 0.4156  decode.d1.loss_dice: 1.0285  decode.d2.loss_cls: 0.0668  decode.d2.loss_mask: 0.4090  decode.d2.loss_dice: 1.0385  decode.d3.loss_cls: 0.0674  decode.d3.loss_mask: 0.4052  decode.d3.loss_dice: 0.9930  decode.d4.loss_cls: 0.0557  decode.d4.loss_mask: 0.4140  decode.d4.loss_dice: 1.0161  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.4101  decode.d5.loss_dice: 1.0279  decode.d6.loss_cls: 0.0567  decode.d6.loss_mask: 0.4133  decode.d6.loss_dice: 1.0255  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.4069  decode.d7.loss_dice: 1.0357  decode.d8.loss_cls: 0.0563  decode.d8.loss_mask: 0.4053  decode.d8.loss_dice: 1.0011
11/15 21:11:36 - mmengine - INFO - Iter(train) [82100/90000]  base_lr: 1.1196e-05 lr: 1.1196e-06  eta: 1:19:15  time: 0.5992  data_time: 0.0105  memory: 10713  grad_norm: 604.7933  loss: 16.1396  decode.loss_cls: 0.0900  decode.loss_mask: 0.4678  decode.loss_dice: 1.0456  decode.d0.loss_cls: 0.1056  decode.d0.loss_mask: 0.5306  decode.d0.loss_dice: 1.1570  decode.d1.loss_cls: 0.0923  decode.d1.loss_mask: 0.4678  decode.d1.loss_dice: 1.0687  decode.d2.loss_cls: 0.0919  decode.d2.loss_mask: 0.4731  decode.d2.loss_dice: 1.0584  decode.d3.loss_cls: 0.0840  decode.d3.loss_mask: 0.4697  decode.d3.loss_dice: 1.0259  decode.d4.loss_cls: 0.0781  decode.d4.loss_mask: 0.4739  decode.d4.loss_dice: 1.0351  decode.d5.loss_cls: 0.0797  decode.d5.loss_mask: 0.4726  decode.d5.loss_dice: 1.0175  decode.d6.loss_cls: 0.0957  decode.d6.loss_mask: 0.4648  decode.d6.loss_dice: 1.0257  decode.d7.loss_cls: 0.0872  decode.d7.loss_mask: 0.4698  decode.d7.loss_dice: 1.0337  decode.d8.loss_cls: 0.0829  decode.d8.loss_mask: 0.4673  decode.d8.loss_dice: 1.0271
11/15 21:12:06 - mmengine - INFO - Iter(train) [82150/90000]  base_lr: 1.1132e-05 lr: 1.1132e-06  eta: 1:18:45  time: 0.6013  data_time: 0.0107  memory: 10713  grad_norm: 272.1556  loss: 16.1472  decode.loss_cls: 0.0614  decode.loss_mask: 0.5129  decode.loss_dice: 1.0280  decode.d0.loss_cls: 0.0784  decode.d0.loss_mask: 0.5357  decode.d0.loss_dice: 1.0891  decode.d1.loss_cls: 0.0504  decode.d1.loss_mask: 0.5264  decode.d1.loss_dice: 1.0742  decode.d2.loss_cls: 0.0533  decode.d2.loss_mask: 0.5267  decode.d2.loss_dice: 1.0209  decode.d3.loss_cls: 0.0606  decode.d3.loss_mask: 0.5222  decode.d3.loss_dice: 1.0043  decode.d4.loss_cls: 0.0676  decode.d4.loss_mask: 0.5220  decode.d4.loss_dice: 1.0127  decode.d5.loss_cls: 0.0606  decode.d5.loss_mask: 0.5261  decode.d5.loss_dice: 1.0132  decode.d6.loss_cls: 0.0495  decode.d6.loss_mask: 0.5157  decode.d6.loss_dice: 1.0481  decode.d7.loss_cls: 0.0683  decode.d7.loss_mask: 0.5109  decode.d7.loss_dice: 1.0114  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.5179  decode.d8.loss_dice: 1.0078
11/15 21:12:36 - mmengine - INFO - Iter(train) [82200/90000]  base_lr: 1.1068e-05 lr: 1.1068e-06  eta: 1:18:15  time: 0.6002  data_time: 0.0107  memory: 10656  grad_norm: 509.6851  loss: 17.7441  decode.loss_cls: 0.0455  decode.loss_mask: 0.5772  decode.loss_dice: 1.1395  decode.d0.loss_cls: 0.0875  decode.d0.loss_mask: 0.5991  decode.d0.loss_dice: 1.1982  decode.d1.loss_cls: 0.0581  decode.d1.loss_mask: 0.5700  decode.d1.loss_dice: 1.1628  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.5680  decode.d2.loss_dice: 1.1319  decode.d3.loss_cls: 0.0645  decode.d3.loss_mask: 0.5665  decode.d3.loss_dice: 1.1417  decode.d4.loss_cls: 0.0520  decode.d4.loss_mask: 0.5769  decode.d4.loss_dice: 1.1258  decode.d5.loss_cls: 0.0473  decode.d5.loss_mask: 0.5766  decode.d5.loss_dice: 1.1411  decode.d6.loss_cls: 0.0626  decode.d6.loss_mask: 0.5641  decode.d6.loss_dice: 1.1185  decode.d7.loss_cls: 0.0483  decode.d7.loss_mask: 0.5784  decode.d7.loss_dice: 1.1348  decode.d8.loss_cls: 0.0455  decode.d8.loss_mask: 0.5768  decode.d8.loss_dice: 1.1300
11/15 21:13:06 - mmengine - INFO - Iter(train) [82250/90000]  base_lr: 1.1004e-05 lr: 1.1004e-06  eta: 1:17:45  time: 0.5989  data_time: 0.0104  memory: 10656  grad_norm: 754.5208  loss: 14.2399  decode.loss_cls: 0.0531  decode.loss_mask: 0.4521  decode.loss_dice: 0.9086  decode.d0.loss_cls: 0.0735  decode.d0.loss_mask: 0.4865  decode.d0.loss_dice: 1.0404  decode.d1.loss_cls: 0.0485  decode.d1.loss_mask: 0.4465  decode.d1.loss_dice: 0.9433  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 0.4432  decode.d2.loss_dice: 0.9152  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.4255  decode.d3.loss_dice: 0.8799  decode.d4.loss_cls: 0.0481  decode.d4.loss_mask: 0.4481  decode.d4.loss_dice: 0.9080  decode.d5.loss_cls: 0.0544  decode.d5.loss_mask: 0.4262  decode.d5.loss_dice: 0.9133  decode.d6.loss_cls: 0.0560  decode.d6.loss_mask: 0.4341  decode.d6.loss_dice: 0.8973  decode.d7.loss_cls: 0.0598  decode.d7.loss_mask: 0.4485  decode.d7.loss_dice: 0.9129  decode.d8.loss_cls: 0.0457  decode.d8.loss_mask: 0.4629  decode.d8.loss_dice: 0.9020
11/15 21:13:36 - mmengine - INFO - Iter(train) [82300/90000]  base_lr: 1.0940e-05 lr: 1.0940e-06  eta: 1:17:15  time: 0.5997  data_time: 0.0106  memory: 10675  grad_norm: 261.2321  loss: 15.3444  decode.loss_cls: 0.0406  decode.loss_mask: 0.5242  decode.loss_dice: 0.9625  decode.d0.loss_cls: 0.0717  decode.d0.loss_mask: 0.5421  decode.d0.loss_dice: 1.0076  decode.d1.loss_cls: 0.0411  decode.d1.loss_mask: 0.5219  decode.d1.loss_dice: 0.9767  decode.d2.loss_cls: 0.0424  decode.d2.loss_mask: 0.5161  decode.d2.loss_dice: 0.9767  decode.d3.loss_cls: 0.0427  decode.d3.loss_mask: 0.5195  decode.d3.loss_dice: 0.9610  decode.d4.loss_cls: 0.0415  decode.d4.loss_mask: 0.5205  decode.d4.loss_dice: 0.9614  decode.d5.loss_cls: 0.0444  decode.d5.loss_mask: 0.5210  decode.d5.loss_dice: 0.9642  decode.d6.loss_cls: 0.0439  decode.d6.loss_mask: 0.5210  decode.d6.loss_dice: 0.9464  decode.d7.loss_cls: 0.0372  decode.d7.loss_mask: 0.5208  decode.d7.loss_dice: 0.9665  decode.d8.loss_cls: 0.0425  decode.d8.loss_mask: 0.5206  decode.d8.loss_dice: 0.9458
11/15 21:14:06 - mmengine - INFO - Iter(train) [82350/90000]  base_lr: 1.0876e-05 lr: 1.0876e-06  eta: 1:16:45  time: 0.6001  data_time: 0.0109  memory: 10728  grad_norm: 432.2863  loss: 14.7209  decode.loss_cls: 0.0570  decode.loss_mask: 0.4412  decode.loss_dice: 0.9584  decode.d0.loss_cls: 0.1065  decode.d0.loss_mask: 0.4803  decode.d0.loss_dice: 1.0485  decode.d1.loss_cls: 0.0759  decode.d1.loss_mask: 0.4504  decode.d1.loss_dice: 0.9580  decode.d2.loss_cls: 0.0564  decode.d2.loss_mask: 0.4540  decode.d2.loss_dice: 0.9849  decode.d3.loss_cls: 0.0615  decode.d3.loss_mask: 0.4437  decode.d3.loss_dice: 0.9367  decode.d4.loss_cls: 0.0585  decode.d4.loss_mask: 0.4390  decode.d4.loss_dice: 0.9505  decode.d5.loss_cls: 0.0554  decode.d5.loss_mask: 0.4401  decode.d5.loss_dice: 0.9462  decode.d6.loss_cls: 0.0552  decode.d6.loss_mask: 0.4362  decode.d6.loss_dice: 0.9392  decode.d7.loss_cls: 0.0596  decode.d7.loss_mask: 0.4386  decode.d7.loss_dice: 0.9494  decode.d8.loss_cls: 0.0534  decode.d8.loss_mask: 0.4401  decode.d8.loss_dice: 0.9462
11/15 21:14:36 - mmengine - INFO - Iter(train) [82400/90000]  base_lr: 1.0812e-05 lr: 1.0812e-06  eta: 1:16:14  time: 0.6010  data_time: 0.0106  memory: 10713  grad_norm: 279.6197  loss: 14.8161  decode.loss_cls: 0.0611  decode.loss_mask: 0.4291  decode.loss_dice: 1.0007  decode.d0.loss_cls: 0.1078  decode.d0.loss_mask: 0.4466  decode.d0.loss_dice: 1.0008  decode.d1.loss_cls: 0.0706  decode.d1.loss_mask: 0.4447  decode.d1.loss_dice: 0.9718  decode.d2.loss_cls: 0.0549  decode.d2.loss_mask: 0.4309  decode.d2.loss_dice: 0.9687  decode.d3.loss_cls: 0.0602  decode.d3.loss_mask: 0.4285  decode.d3.loss_dice: 0.9636  decode.d4.loss_cls: 0.0697  decode.d4.loss_mask: 0.4245  decode.d4.loss_dice: 0.9735  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.4267  decode.d5.loss_dice: 0.9769  decode.d6.loss_cls: 0.0607  decode.d6.loss_mask: 0.4304  decode.d6.loss_dice: 0.9862  decode.d7.loss_cls: 0.0648  decode.d7.loss_mask: 0.4302  decode.d7.loss_dice: 0.9871  decode.d8.loss_cls: 0.0634  decode.d8.loss_mask: 0.4333  decode.d8.loss_dice: 0.9946
11/15 21:15:07 - mmengine - INFO - Iter(train) [82450/90000]  base_lr: 1.0748e-05 lr: 1.0748e-06  eta: 1:15:44  time: 0.6420  data_time: 0.0107  memory: 10675  grad_norm: 565.4660  loss: 16.3864  decode.loss_cls: 0.0757  decode.loss_mask: 0.4667  decode.loss_dice: 1.0557  decode.d0.loss_cls: 0.0924  decode.d0.loss_mask: 0.5059  decode.d0.loss_dice: 1.1720  decode.d1.loss_cls: 0.0754  decode.d1.loss_mask: 0.4845  decode.d1.loss_dice: 1.0903  decode.d2.loss_cls: 0.0691  decode.d2.loss_mask: 0.4812  decode.d2.loss_dice: 1.0938  decode.d3.loss_cls: 0.0677  decode.d3.loss_mask: 0.4771  decode.d3.loss_dice: 1.0651  decode.d4.loss_cls: 0.0687  decode.d4.loss_mask: 0.4770  decode.d4.loss_dice: 1.0710  decode.d5.loss_cls: 0.0800  decode.d5.loss_mask: 0.4727  decode.d5.loss_dice: 1.0772  decode.d6.loss_cls: 0.0722  decode.d6.loss_mask: 0.4752  decode.d6.loss_dice: 1.0593  decode.d7.loss_cls: 0.0882  decode.d7.loss_mask: 0.4718  decode.d7.loss_dice: 1.0488  decode.d8.loss_cls: 0.0760  decode.d8.loss_mask: 0.4700  decode.d8.loss_dice: 1.1059
11/15 21:15:38 - mmengine - INFO - Iter(train) [82500/90000]  base_lr: 1.0684e-05 lr: 1.0684e-06  eta: 1:15:14  time: 0.5992  data_time: 0.0106  memory: 10742  grad_norm: 279.0203  loss: 14.0817  decode.loss_cls: 0.0333  decode.loss_mask: 0.5241  decode.loss_dice: 0.8270  decode.d0.loss_cls: 0.0829  decode.d0.loss_mask: 0.5256  decode.d0.loss_dice: 0.9144  decode.d1.loss_cls: 0.0471  decode.d1.loss_mask: 0.5161  decode.d1.loss_dice: 0.8471  decode.d2.loss_cls: 0.0505  decode.d2.loss_mask: 0.5134  decode.d2.loss_dice: 0.8103  decode.d3.loss_cls: 0.0357  decode.d3.loss_mask: 0.5152  decode.d3.loss_dice: 0.8777  decode.d4.loss_cls: 0.0409  decode.d4.loss_mask: 0.5087  decode.d4.loss_dice: 0.8095  decode.d5.loss_cls: 0.0403  decode.d5.loss_mask: 0.5064  decode.d5.loss_dice: 0.8363  decode.d6.loss_cls: 0.0326  decode.d6.loss_mask: 0.5201  decode.d6.loss_dice: 0.8636  decode.d7.loss_cls: 0.0352  decode.d7.loss_mask: 0.5126  decode.d7.loss_dice: 0.8556  decode.d8.loss_cls: 0.0355  decode.d8.loss_mask: 0.5160  decode.d8.loss_dice: 0.8477
11/15 21:16:08 - mmengine - INFO - Iter(train) [82550/90000]  base_lr: 1.0620e-05 lr: 1.0620e-06  eta: 1:14:44  time: 0.6000  data_time: 0.0108  memory: 10742  grad_norm: 233.1591  loss: 14.7735  decode.loss_cls: 0.0401  decode.loss_mask: 0.4784  decode.loss_dice: 0.9526  decode.d0.loss_cls: 0.0903  decode.d0.loss_mask: 0.4765  decode.d0.loss_dice: 0.9604  decode.d1.loss_cls: 0.0457  decode.d1.loss_mask: 0.4952  decode.d1.loss_dice: 0.9648  decode.d2.loss_cls: 0.0465  decode.d2.loss_mask: 0.4886  decode.d2.loss_dice: 0.9422  decode.d3.loss_cls: 0.0466  decode.d3.loss_mask: 0.4803  decode.d3.loss_dice: 0.9277  decode.d4.loss_cls: 0.0438  decode.d4.loss_mask: 0.4909  decode.d4.loss_dice: 0.9562  decode.d5.loss_cls: 0.0422  decode.d5.loss_mask: 0.4689  decode.d5.loss_dice: 0.9492  decode.d6.loss_cls: 0.0415  decode.d6.loss_mask: 0.4671  decode.d6.loss_dice: 0.9503  decode.d7.loss_cls: 0.0417  decode.d7.loss_mask: 0.4736  decode.d7.loss_dice: 0.9613  decode.d8.loss_cls: 0.0441  decode.d8.loss_mask: 0.4726  decode.d8.loss_dice: 0.9344
11/15 21:16:38 - mmengine - INFO - Iter(train) [82600/90000]  base_lr: 1.0556e-05 lr: 1.0556e-06  eta: 1:14:14  time: 0.6002  data_time: 0.0109  memory: 10692  grad_norm: 272.2445  loss: 15.5744  decode.loss_cls: 0.0852  decode.loss_mask: 0.3763  decode.loss_dice: 1.0814  decode.d0.loss_cls: 0.1150  decode.d0.loss_mask: 0.4019  decode.d0.loss_dice: 1.2200  decode.d1.loss_cls: 0.0942  decode.d1.loss_mask: 0.3848  decode.d1.loss_dice: 1.1007  decode.d2.loss_cls: 0.0863  decode.d2.loss_mask: 0.3744  decode.d2.loss_dice: 1.0886  decode.d3.loss_cls: 0.0922  decode.d3.loss_mask: 0.3813  decode.d3.loss_dice: 1.0669  decode.d4.loss_cls: 0.0989  decode.d4.loss_mask: 0.3807  decode.d4.loss_dice: 1.0581  decode.d5.loss_cls: 0.0898  decode.d5.loss_mask: 0.3810  decode.d5.loss_dice: 1.0361  decode.d6.loss_cls: 0.0927  decode.d6.loss_mask: 0.3745  decode.d6.loss_dice: 1.0736  decode.d7.loss_cls: 0.0948  decode.d7.loss_mask: 0.3794  decode.d7.loss_dice: 1.0425  decode.d8.loss_cls: 0.0886  decode.d8.loss_mask: 0.3781  decode.d8.loss_dice: 1.0565
11/15 21:17:08 - mmengine - INFO - Iter(train) [82650/90000]  base_lr: 1.0492e-05 lr: 1.0492e-06  eta: 1:13:44  time: 0.6005  data_time: 0.0106  memory: 10692  grad_norm: 482.0670  loss: 17.2393  decode.loss_cls: 0.0637  decode.loss_mask: 0.4918  decode.loss_dice: 1.1648  decode.d0.loss_cls: 0.0770  decode.d0.loss_mask: 0.5277  decode.d0.loss_dice: 1.2335  decode.d1.loss_cls: 0.0796  decode.d1.loss_mask: 0.4751  decode.d1.loss_dice: 1.1225  decode.d2.loss_cls: 0.0872  decode.d2.loss_mask: 0.4799  decode.d2.loss_dice: 1.1799  decode.d3.loss_cls: 0.0615  decode.d3.loss_mask: 0.4947  decode.d3.loss_dice: 1.1636  decode.d4.loss_cls: 0.0755  decode.d4.loss_mask: 0.4951  decode.d4.loss_dice: 1.1571  decode.d5.loss_cls: 0.0648  decode.d5.loss_mask: 0.4992  decode.d5.loss_dice: 1.1470  decode.d6.loss_cls: 0.0573  decode.d6.loss_mask: 0.4876  decode.d6.loss_dice: 1.1717  decode.d7.loss_cls: 0.0574  decode.d7.loss_mask: 0.4881  decode.d7.loss_dice: 1.1722  decode.d8.loss_cls: 0.0665  decode.d8.loss_mask: 0.4873  decode.d8.loss_dice: 1.1098
11/15 21:17:38 - mmengine - INFO - Iter(train) [82700/90000]  base_lr: 1.0427e-05 lr: 1.0427e-06  eta: 1:13:14  time: 0.5996  data_time: 0.0107  memory: 10675  grad_norm: 592.0943  loss: 14.1297  decode.loss_cls: 0.0488  decode.loss_mask: 0.4725  decode.loss_dice: 0.8671  decode.d0.loss_cls: 0.0927  decode.d0.loss_mask: 0.4946  decode.d0.loss_dice: 0.9370  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.4945  decode.d1.loss_dice: 0.9076  decode.d2.loss_cls: 0.0558  decode.d2.loss_mask: 0.4694  decode.d2.loss_dice: 0.8737  decode.d3.loss_cls: 0.0453  decode.d3.loss_mask: 0.4690  decode.d3.loss_dice: 0.9038  decode.d4.loss_cls: 0.0411  decode.d4.loss_mask: 0.4734  decode.d4.loss_dice: 0.8831  decode.d5.loss_cls: 0.0466  decode.d5.loss_mask: 0.4658  decode.d5.loss_dice: 0.8524  decode.d6.loss_cls: 0.0490  decode.d6.loss_mask: 0.4706  decode.d6.loss_dice: 0.8651  decode.d7.loss_cls: 0.0410  decode.d7.loss_mask: 0.4870  decode.d7.loss_dice: 0.8742  decode.d8.loss_cls: 0.0466  decode.d8.loss_mask: 0.4754  decode.d8.loss_dice: 0.8744
11/15 21:18:08 - mmengine - INFO - Iter(train) [82750/90000]  base_lr: 1.0363e-05 lr: 1.0363e-06  eta: 1:12:44  time: 0.6040  data_time: 0.0111  memory: 10728  grad_norm: 258.3249  loss: 14.9235  decode.loss_cls: 0.0548  decode.loss_mask: 0.4813  decode.loss_dice: 0.9401  decode.d0.loss_cls: 0.0830  decode.d0.loss_mask: 0.5001  decode.d0.loss_dice: 1.0339  decode.d1.loss_cls: 0.0643  decode.d1.loss_mask: 0.4746  decode.d1.loss_dice: 0.9652  decode.d2.loss_cls: 0.0604  decode.d2.loss_mask: 0.4704  decode.d2.loss_dice: 0.9446  decode.d3.loss_cls: 0.0500  decode.d3.loss_mask: 0.4843  decode.d3.loss_dice: 0.9673  decode.d4.loss_cls: 0.0481  decode.d4.loss_mask: 0.4852  decode.d4.loss_dice: 0.9585  decode.d5.loss_cls: 0.0498  decode.d5.loss_mask: 0.4844  decode.d5.loss_dice: 0.9397  decode.d6.loss_cls: 0.0561  decode.d6.loss_mask: 0.4735  decode.d6.loss_dice: 0.9472  decode.d7.loss_cls: 0.0533  decode.d7.loss_mask: 0.4728  decode.d7.loss_dice: 0.9336  decode.d8.loss_cls: 0.0568  decode.d8.loss_mask: 0.4771  decode.d8.loss_dice: 0.9128
11/15 21:18:38 - mmengine - INFO - Iter(train) [82800/90000]  base_lr: 1.0299e-05 lr: 1.0299e-06  eta: 1:12:14  time: 0.6008  data_time: 0.0109  memory: 10656  grad_norm: 354.6736  loss: 15.8210  decode.loss_cls: 0.0342  decode.loss_mask: 0.5589  decode.loss_dice: 0.9546  decode.d0.loss_cls: 0.0972  decode.d0.loss_mask: 0.5955  decode.d0.loss_dice: 0.9966  decode.d1.loss_cls: 0.0393  decode.d1.loss_mask: 0.5893  decode.d1.loss_dice: 1.0068  decode.d2.loss_cls: 0.0565  decode.d2.loss_mask: 0.5756  decode.d2.loss_dice: 0.9686  decode.d3.loss_cls: 0.0499  decode.d3.loss_mask: 0.5554  decode.d3.loss_dice: 0.9539  decode.d4.loss_cls: 0.0399  decode.d4.loss_mask: 0.5596  decode.d4.loss_dice: 0.9552  decode.d5.loss_cls: 0.0346  decode.d5.loss_mask: 0.5613  decode.d5.loss_dice: 0.9498  decode.d6.loss_cls: 0.0427  decode.d6.loss_mask: 0.5557  decode.d6.loss_dice: 0.9607  decode.d7.loss_cls: 0.0346  decode.d7.loss_mask: 0.5482  decode.d7.loss_dice: 0.9686  decode.d8.loss_cls: 0.0396  decode.d8.loss_mask: 0.5607  decode.d8.loss_dice: 0.9775
11/15 21:19:08 - mmengine - INFO - Iter(train) [82850/90000]  base_lr: 1.0234e-05 lr: 1.0234e-06  eta: 1:11:44  time: 0.6026  data_time: 0.0111  memory: 10692  grad_norm: 419.6798  loss: 13.5925  decode.loss_cls: 0.0438  decode.loss_mask: 0.3627  decode.loss_dice: 0.9383  decode.d0.loss_cls: 0.0746  decode.d0.loss_mask: 0.3796  decode.d0.loss_dice: 0.9848  decode.d1.loss_cls: 0.0508  decode.d1.loss_mask: 0.3697  decode.d1.loss_dice: 0.9669  decode.d2.loss_cls: 0.0348  decode.d2.loss_mask: 0.3679  decode.d2.loss_dice: 0.9545  decode.d3.loss_cls: 0.0440  decode.d3.loss_mask: 0.3673  decode.d3.loss_dice: 0.9371  decode.d4.loss_cls: 0.0409  decode.d4.loss_mask: 0.3694  decode.d4.loss_dice: 0.9307  decode.d5.loss_cls: 0.0467  decode.d5.loss_mask: 0.3658  decode.d5.loss_dice: 0.9316  decode.d6.loss_cls: 0.0355  decode.d6.loss_mask: 0.3621  decode.d6.loss_dice: 0.9485  decode.d7.loss_cls: 0.0437  decode.d7.loss_mask: 0.3613  decode.d7.loss_dice: 0.9345  decode.d8.loss_cls: 0.0423  decode.d8.loss_mask: 0.3637  decode.d8.loss_dice: 0.9390
11/15 21:19:38 - mmengine - INFO - Iter(train) [82900/90000]  base_lr: 1.0170e-05 lr: 1.0170e-06  eta: 1:11:14  time: 0.5999  data_time: 0.0109  memory: 10675  grad_norm: 284.0653  loss: 16.1040  decode.loss_cls: 0.0761  decode.loss_mask: 0.5240  decode.loss_dice: 0.9790  decode.d0.loss_cls: 0.0970  decode.d0.loss_mask: 0.5803  decode.d0.loss_dice: 1.1182  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.5318  decode.d1.loss_dice: 1.0330  decode.d2.loss_cls: 0.0631  decode.d2.loss_mask: 0.5344  decode.d2.loss_dice: 1.0333  decode.d3.loss_cls: 0.0698  decode.d3.loss_mask: 0.5058  decode.d3.loss_dice: 1.0004  decode.d4.loss_cls: 0.0722  decode.d4.loss_mask: 0.5092  decode.d4.loss_dice: 0.9766  decode.d5.loss_cls: 0.0704  decode.d5.loss_mask: 0.5088  decode.d5.loss_dice: 1.0271  decode.d6.loss_cls: 0.0748  decode.d6.loss_mask: 0.5207  decode.d6.loss_dice: 0.9672  decode.d7.loss_cls: 0.0820  decode.d7.loss_mask: 0.5144  decode.d7.loss_dice: 0.9690  decode.d8.loss_cls: 0.0810  decode.d8.loss_mask: 0.5185  decode.d8.loss_dice: 0.9918
11/15 21:20:08 - mmengine - INFO - Iter(train) [82950/90000]  base_lr: 1.0105e-05 lr: 1.0105e-06  eta: 1:10:44  time: 0.6006  data_time: 0.0109  memory: 10675  grad_norm: 325.3909  loss: 15.6103  decode.loss_cls: 0.0530  decode.loss_mask: 0.4399  decode.loss_dice: 1.0415  decode.d0.loss_cls: 0.0735  decode.d0.loss_mask: 0.4453  decode.d0.loss_dice: 1.1732  decode.d1.loss_cls: 0.0768  decode.d1.loss_mask: 0.4365  decode.d1.loss_dice: 1.0653  decode.d2.loss_cls: 0.0649  decode.d2.loss_mask: 0.4397  decode.d2.loss_dice: 1.0526  decode.d3.loss_cls: 0.0714  decode.d3.loss_mask: 0.4345  decode.d3.loss_dice: 1.0392  decode.d4.loss_cls: 0.0659  decode.d4.loss_mask: 0.4370  decode.d4.loss_dice: 1.0347  decode.d5.loss_cls: 0.0643  decode.d5.loss_mask: 0.4364  decode.d5.loss_dice: 1.0699  decode.d6.loss_cls: 0.0605  decode.d6.loss_mask: 0.4321  decode.d6.loss_dice: 1.0256  decode.d7.loss_cls: 0.0571  decode.d7.loss_mask: 0.4390  decode.d7.loss_dice: 1.0390  decode.d8.loss_cls: 0.0519  decode.d8.loss_mask: 0.4378  decode.d8.loss_dice: 1.0520
11/15 21:20:38 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 21:20:38 - mmengine - INFO - Iter(train) [83000/90000]  base_lr: 1.0041e-05 lr: 1.0041e-06  eta: 1:10:13  time: 0.5992  data_time: 0.0109  memory: 10675  grad_norm: 298.7697  loss: 14.4363  decode.loss_cls: 0.0575  decode.loss_mask: 0.4985  decode.loss_dice: 0.8740  decode.d0.loss_cls: 0.0887  decode.d0.loss_mask: 0.5028  decode.d0.loss_dice: 0.9440  decode.d1.loss_cls: 0.0531  decode.d1.loss_mask: 0.5129  decode.d1.loss_dice: 0.8808  decode.d2.loss_cls: 0.0569  decode.d2.loss_mask: 0.5067  decode.d2.loss_dice: 0.8740  decode.d3.loss_cls: 0.0554  decode.d3.loss_mask: 0.5082  decode.d3.loss_dice: 0.8765  decode.d4.loss_cls: 0.0505  decode.d4.loss_mask: 0.5113  decode.d4.loss_dice: 0.8686  decode.d5.loss_cls: 0.0546  decode.d5.loss_mask: 0.5032  decode.d5.loss_dice: 0.8558  decode.d6.loss_cls: 0.0553  decode.d6.loss_mask: 0.5103  decode.d6.loss_dice: 0.8791  decode.d7.loss_cls: 0.0541  decode.d7.loss_mask: 0.5057  decode.d7.loss_dice: 0.8689  decode.d8.loss_cls: 0.0592  decode.d8.loss_mask: 0.5065  decode.d8.loss_dice: 0.8633
11/15 21:21:09 - mmengine - INFO - Iter(train) [83050/90000]  base_lr: 9.9764e-06 lr: 9.9764e-07  eta: 1:09:43  time: 0.5993  data_time: 0.0106  memory: 10713  grad_norm: 428.5203  loss: 13.8379  decode.loss_cls: 0.0317  decode.loss_mask: 0.4155  decode.loss_dice: 0.9414  decode.d0.loss_cls: 0.0660  decode.d0.loss_mask: 0.4362  decode.d0.loss_dice: 0.9960  decode.d1.loss_cls: 0.0506  decode.d1.loss_mask: 0.4134  decode.d1.loss_dice: 0.9438  decode.d2.loss_cls: 0.0400  decode.d2.loss_mask: 0.4152  decode.d2.loss_dice: 0.9364  decode.d3.loss_cls: 0.0482  decode.d3.loss_mask: 0.4165  decode.d3.loss_dice: 0.9220  decode.d4.loss_cls: 0.0449  decode.d4.loss_mask: 0.4094  decode.d4.loss_dice: 0.9108  decode.d5.loss_cls: 0.0390  decode.d5.loss_mask: 0.4084  decode.d5.loss_dice: 0.8985  decode.d6.loss_cls: 0.0417  decode.d6.loss_mask: 0.4112  decode.d6.loss_dice: 0.9132  decode.d7.loss_cls: 0.0375  decode.d7.loss_mask: 0.4089  decode.d7.loss_dice: 0.8898  decode.d8.loss_cls: 0.0401  decode.d8.loss_mask: 0.4121  decode.d8.loss_dice: 0.8998
11/15 21:21:39 - mmengine - INFO - Iter(train) [83100/90000]  base_lr: 9.9117e-06 lr: 9.9117e-07  eta: 1:09:13  time: 0.6014  data_time: 0.0111  memory: 10692  grad_norm: 460.9162  loss: 14.9930  decode.loss_cls: 0.0578  decode.loss_mask: 0.4413  decode.loss_dice: 0.9764  decode.d0.loss_cls: 0.0751  decode.d0.loss_mask: 0.4735  decode.d0.loss_dice: 1.0724  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.4560  decode.d1.loss_dice: 1.0035  decode.d2.loss_cls: 0.0587  decode.d2.loss_mask: 0.4459  decode.d2.loss_dice: 0.9795  decode.d3.loss_cls: 0.0500  decode.d3.loss_mask: 0.4512  decode.d3.loss_dice: 0.9643  decode.d4.loss_cls: 0.0573  decode.d4.loss_mask: 0.4512  decode.d4.loss_dice: 0.9816  decode.d5.loss_cls: 0.0552  decode.d5.loss_mask: 0.4483  decode.d5.loss_dice: 0.9785  decode.d6.loss_cls: 0.0557  decode.d6.loss_mask: 0.4475  decode.d6.loss_dice: 0.9887  decode.d7.loss_cls: 0.0671  decode.d7.loss_mask: 0.4441  decode.d7.loss_dice: 0.9661  decode.d8.loss_cls: 0.0596  decode.d8.loss_mask: 0.4496  decode.d8.loss_dice: 0.9741
11/15 21:22:09 - mmengine - INFO - Iter(train) [83150/90000]  base_lr: 9.8471e-06 lr: 9.8471e-07  eta: 1:08:43  time: 0.5990  data_time: 0.0106  memory: 10713  grad_norm: 831.8886  loss: 14.4336  decode.loss_cls: 0.0659  decode.loss_mask: 0.4932  decode.loss_dice: 0.8503  decode.d0.loss_cls: 0.0979  decode.d0.loss_mask: 0.5354  decode.d0.loss_dice: 0.9711  decode.d1.loss_cls: 0.0699  decode.d1.loss_mask: 0.5045  decode.d1.loss_dice: 0.9378  decode.d2.loss_cls: 0.0641  decode.d2.loss_mask: 0.4969  decode.d2.loss_dice: 0.8850  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.4904  decode.d3.loss_dice: 0.8750  decode.d4.loss_cls: 0.0521  decode.d4.loss_mask: 0.4895  decode.d4.loss_dice: 0.8856  decode.d5.loss_cls: 0.0669  decode.d5.loss_mask: 0.4899  decode.d5.loss_dice: 0.8539  decode.d6.loss_cls: 0.0603  decode.d6.loss_mask: 0.4882  decode.d6.loss_dice: 0.8468  decode.d7.loss_cls: 0.0595  decode.d7.loss_mask: 0.4934  decode.d7.loss_dice: 0.8482  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.4927  decode.d8.loss_dice: 0.8476
11/15 21:22:39 - mmengine - INFO - Iter(train) [83200/90000]  base_lr: 9.7824e-06 lr: 9.7824e-07  eta: 1:08:13  time: 0.5989  data_time: 0.0106  memory: 10728  grad_norm: 305.9809  loss: 14.6019  decode.loss_cls: 0.0559  decode.loss_mask: 0.4619  decode.loss_dice: 0.9311  decode.d0.loss_cls: 0.0876  decode.d0.loss_mask: 0.4526  decode.d0.loss_dice: 1.0128  decode.d1.loss_cls: 0.0644  decode.d1.loss_mask: 0.4473  decode.d1.loss_dice: 0.9379  decode.d2.loss_cls: 0.0670  decode.d2.loss_mask: 0.4399  decode.d2.loss_dice: 0.9147  decode.d3.loss_cls: 0.0511  decode.d3.loss_mask: 0.4704  decode.d3.loss_dice: 0.9299  decode.d4.loss_cls: 0.0601  decode.d4.loss_mask: 0.4496  decode.d4.loss_dice: 0.9747  decode.d5.loss_cls: 0.0637  decode.d5.loss_mask: 0.4426  decode.d5.loss_dice: 0.9298  decode.d6.loss_cls: 0.0599  decode.d6.loss_mask: 0.4514  decode.d6.loss_dice: 0.9644  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.4459  decode.d7.loss_dice: 0.9439  decode.d8.loss_cls: 0.0630  decode.d8.loss_mask: 0.4391  decode.d8.loss_dice: 0.9261
11/15 21:23:09 - mmengine - INFO - Iter(train) [83250/90000]  base_lr: 9.7176e-06 lr: 9.7176e-07  eta: 1:07:43  time: 0.5992  data_time: 0.0107  memory: 10675  grad_norm: 304.6218  loss: 15.1815  decode.loss_cls: 0.0691  decode.loss_mask: 0.4870  decode.loss_dice: 0.9448  decode.d0.loss_cls: 0.1007  decode.d0.loss_mask: 0.5111  decode.d0.loss_dice: 1.0281  decode.d1.loss_cls: 0.0828  decode.d1.loss_mask: 0.4961  decode.d1.loss_dice: 0.9619  decode.d2.loss_cls: 0.0866  decode.d2.loss_mask: 0.4902  decode.d2.loss_dice: 0.9241  decode.d3.loss_cls: 0.0848  decode.d3.loss_mask: 0.4877  decode.d3.loss_dice: 0.9306  decode.d4.loss_cls: 0.0862  decode.d4.loss_mask: 0.4876  decode.d4.loss_dice: 0.9335  decode.d5.loss_cls: 0.0912  decode.d5.loss_mask: 0.4877  decode.d5.loss_dice: 0.9274  decode.d6.loss_cls: 0.0777  decode.d6.loss_mask: 0.4901  decode.d6.loss_dice: 0.9424  decode.d7.loss_cls: 0.0768  decode.d7.loss_mask: 0.4821  decode.d7.loss_dice: 0.9239  decode.d8.loss_cls: 0.0786  decode.d8.loss_mask: 0.4811  decode.d8.loss_dice: 0.9296
11/15 21:23:39 - mmengine - INFO - Iter(train) [83300/90000]  base_lr: 9.6528e-06 lr: 9.6528e-07  eta: 1:07:13  time: 0.5998  data_time: 0.0106  memory: 10656  grad_norm: 663.3468  loss: 17.1513  decode.loss_cls: 0.0618  decode.loss_mask: 0.5208  decode.loss_dice: 1.1135  decode.d0.loss_cls: 0.0869  decode.d0.loss_mask: 0.5491  decode.d0.loss_dice: 1.2141  decode.d1.loss_cls: 0.0745  decode.d1.loss_mask: 0.5258  decode.d1.loss_dice: 1.1369  decode.d2.loss_cls: 0.0647  decode.d2.loss_mask: 0.5577  decode.d2.loss_dice: 1.1171  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.5328  decode.d3.loss_dice: 1.1117  decode.d4.loss_cls: 0.0607  decode.d4.loss_mask: 0.5338  decode.d4.loss_dice: 1.1324  decode.d5.loss_cls: 0.0658  decode.d5.loss_mask: 0.5252  decode.d5.loss_dice: 1.1028  decode.d6.loss_cls: 0.0640  decode.d6.loss_mask: 0.5262  decode.d6.loss_dice: 1.0630  decode.d7.loss_cls: 0.0634  decode.d7.loss_mask: 0.5252  decode.d7.loss_dice: 1.0936  decode.d8.loss_cls: 0.0666  decode.d8.loss_mask: 0.5189  decode.d8.loss_dice: 1.0780
11/15 21:24:09 - mmengine - INFO - Iter(train) [83350/90000]  base_lr: 9.5879e-06 lr: 9.5879e-07  eta: 1:06:43  time: 0.6012  data_time: 0.0110  memory: 10713  grad_norm: 413.1631  loss: 15.7289  decode.loss_cls: 0.0586  decode.loss_mask: 0.4885  decode.loss_dice: 1.0263  decode.d0.loss_cls: 0.0936  decode.d0.loss_mask: 0.5162  decode.d0.loss_dice: 1.0726  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.4980  decode.d1.loss_dice: 1.0496  decode.d2.loss_cls: 0.0624  decode.d2.loss_mask: 0.4937  decode.d2.loss_dice: 1.0118  decode.d3.loss_cls: 0.0585  decode.d3.loss_mask: 0.4896  decode.d3.loss_dice: 0.9863  decode.d4.loss_cls: 0.0652  decode.d4.loss_mask: 0.4849  decode.d4.loss_dice: 0.9795  decode.d5.loss_cls: 0.0633  decode.d5.loss_mask: 0.4823  decode.d5.loss_dice: 1.0149  decode.d6.loss_cls: 0.0533  decode.d6.loss_mask: 0.4889  decode.d6.loss_dice: 1.0211  decode.d7.loss_cls: 0.0654  decode.d7.loss_mask: 0.4852  decode.d7.loss_dice: 0.9923  decode.d8.loss_cls: 0.0624  decode.d8.loss_mask: 0.4857  decode.d8.loss_dice: 1.0244
11/15 21:24:39 - mmengine - INFO - Iter(train) [83400/90000]  base_lr: 9.5230e-06 lr: 9.5230e-07  eta: 1:06:13  time: 0.5997  data_time: 0.0109  memory: 10713  grad_norm: 231.5851  loss: 13.4854  decode.loss_cls: 0.0388  decode.loss_mask: 0.4307  decode.loss_dice: 0.8593  decode.d0.loss_cls: 0.0648  decode.d0.loss_mask: 0.4538  decode.d0.loss_dice: 0.9147  decode.d1.loss_cls: 0.0325  decode.d1.loss_mask: 0.4309  decode.d1.loss_dice: 0.8835  decode.d2.loss_cls: 0.0333  decode.d2.loss_mask: 0.4292  decode.d2.loss_dice: 0.8860  decode.d3.loss_cls: 0.0427  decode.d3.loss_mask: 0.4268  decode.d3.loss_dice: 0.8673  decode.d4.loss_cls: 0.0348  decode.d4.loss_mask: 0.4273  decode.d4.loss_dice: 0.8664  decode.d5.loss_cls: 0.0361  decode.d5.loss_mask: 0.4282  decode.d5.loss_dice: 0.8790  decode.d6.loss_cls: 0.0389  decode.d6.loss_mask: 0.4272  decode.d6.loss_dice: 0.8652  decode.d7.loss_cls: 0.0337  decode.d7.loss_mask: 0.4295  decode.d7.loss_dice: 0.8827  decode.d8.loss_cls: 0.0374  decode.d8.loss_mask: 0.4298  decode.d8.loss_dice: 0.8748
11/15 21:25:09 - mmengine - INFO - Iter(train) [83450/90000]  base_lr: 9.4581e-06 lr: 9.4581e-07  eta: 1:05:42  time: 0.6002  data_time: 0.0107  memory: 10641  grad_norm: 211.9756  loss: 13.9701  decode.loss_cls: 0.0613  decode.loss_mask: 0.3741  decode.loss_dice: 0.9011  decode.d0.loss_cls: 0.0845  decode.d0.loss_mask: 0.4413  decode.d0.loss_dice: 0.9952  decode.d1.loss_cls: 0.0493  decode.d1.loss_mask: 0.4279  decode.d1.loss_dice: 0.9837  decode.d2.loss_cls: 0.0479  decode.d2.loss_mask: 0.4059  decode.d2.loss_dice: 0.9550  decode.d3.loss_cls: 0.0565  decode.d3.loss_mask: 0.4176  decode.d3.loss_dice: 0.9621  decode.d4.loss_cls: 0.0534  decode.d4.loss_mask: 0.3960  decode.d4.loss_dice: 0.9146  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.3983  decode.d5.loss_dice: 0.9325  decode.d6.loss_cls: 0.0602  decode.d6.loss_mask: 0.3767  decode.d6.loss_dice: 0.9144  decode.d7.loss_cls: 0.0501  decode.d7.loss_mask: 0.3932  decode.d7.loss_dice: 0.8963  decode.d8.loss_cls: 0.0525  decode.d8.loss_mask: 0.3986  decode.d8.loss_dice: 0.9160
11/15 21:25:39 - mmengine - INFO - Iter(train) [83500/90000]  base_lr: 9.3931e-06 lr: 9.3931e-07  eta: 1:05:12  time: 0.6002  data_time: 0.0107  memory: 10641  grad_norm: 245.1013  loss: 13.4000  decode.loss_cls: 0.0592  decode.loss_mask: 0.3611  decode.loss_dice: 0.8903  decode.d0.loss_cls: 0.0882  decode.d0.loss_mask: 0.3839  decode.d0.loss_dice: 0.9543  decode.d1.loss_cls: 0.0643  decode.d1.loss_mask: 0.3673  decode.d1.loss_dice: 0.9192  decode.d2.loss_cls: 0.0632  decode.d2.loss_mask: 0.3698  decode.d2.loss_dice: 0.9031  decode.d3.loss_cls: 0.0531  decode.d3.loss_mask: 0.3678  decode.d3.loss_dice: 0.8965  decode.d4.loss_cls: 0.0566  decode.d4.loss_mask: 0.3683  decode.d4.loss_dice: 0.8986  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.3728  decode.d5.loss_dice: 0.9176  decode.d6.loss_cls: 0.0566  decode.d6.loss_mask: 0.3576  decode.d6.loss_dice: 0.9000  decode.d7.loss_cls: 0.0496  decode.d7.loss_mask: 0.3625  decode.d7.loss_dice: 0.9217  decode.d8.loss_cls: 0.0531  decode.d8.loss_mask: 0.3646  decode.d8.loss_dice: 0.9197
11/15 21:26:09 - mmengine - INFO - Iter(train) [83550/90000]  base_lr: 9.3280e-06 lr: 9.3280e-07  eta: 1:04:42  time: 0.6007  data_time: 0.0108  memory: 10675  grad_norm: 257.3250  loss: 15.1998  decode.loss_cls: 0.0677  decode.loss_mask: 0.4261  decode.loss_dice: 1.0052  decode.d0.loss_cls: 0.1003  decode.d0.loss_mask: 0.4374  decode.d0.loss_dice: 1.1030  decode.d1.loss_cls: 0.0761  decode.d1.loss_mask: 0.4294  decode.d1.loss_dice: 1.0750  decode.d2.loss_cls: 0.0689  decode.d2.loss_mask: 0.4222  decode.d2.loss_dice: 1.0311  decode.d3.loss_cls: 0.0651  decode.d3.loss_mask: 0.4328  decode.d3.loss_dice: 0.9997  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.4269  decode.d4.loss_dice: 1.0048  decode.d5.loss_cls: 0.0808  decode.d5.loss_mask: 0.4218  decode.d5.loss_dice: 0.9815  decode.d6.loss_cls: 0.0717  decode.d6.loss_mask: 0.4238  decode.d6.loss_dice: 0.9970  decode.d7.loss_cls: 0.0676  decode.d7.loss_mask: 0.4245  decode.d7.loss_dice: 0.9996  decode.d8.loss_cls: 0.0672  decode.d8.loss_mask: 0.4238  decode.d8.loss_dice: 0.9998
11/15 21:26:39 - mmengine - INFO - Iter(train) [83600/90000]  base_lr: 9.2629e-06 lr: 9.2629e-07  eta: 1:04:12  time: 0.6011  data_time: 0.0107  memory: 10692  grad_norm: 149.1251  loss: 14.1788  decode.loss_cls: 0.0528  decode.loss_mask: 0.3576  decode.loss_dice: 0.9831  decode.d0.loss_cls: 0.0845  decode.d0.loss_mask: 0.3656  decode.d0.loss_dice: 1.0361  decode.d1.loss_cls: 0.0543  decode.d1.loss_mask: 0.3633  decode.d1.loss_dice: 1.0184  decode.d2.loss_cls: 0.0491  decode.d2.loss_mask: 0.3549  decode.d2.loss_dice: 0.9940  decode.d3.loss_cls: 0.0585  decode.d3.loss_mask: 0.3624  decode.d3.loss_dice: 0.9891  decode.d4.loss_cls: 0.0548  decode.d4.loss_mask: 0.3599  decode.d4.loss_dice: 1.0104  decode.d5.loss_cls: 0.0693  decode.d5.loss_mask: 0.3554  decode.d5.loss_dice: 1.0144  decode.d6.loss_cls: 0.0575  decode.d6.loss_mask: 0.3546  decode.d6.loss_dice: 0.9891  decode.d7.loss_cls: 0.0642  decode.d7.loss_mask: 0.3526  decode.d7.loss_dice: 0.9694  decode.d8.loss_cls: 0.0569  decode.d8.loss_mask: 0.3545  decode.d8.loss_dice: 0.9920
11/15 21:27:09 - mmengine - INFO - Iter(train) [83650/90000]  base_lr: 9.1978e-06 lr: 9.1978e-07  eta: 1:03:42  time: 0.6038  data_time: 0.0108  memory: 10692  grad_norm: 334.1962  loss: 14.6690  decode.loss_cls: 0.0622  decode.loss_mask: 0.3722  decode.loss_dice: 1.0174  decode.d0.loss_cls: 0.0830  decode.d0.loss_mask: 0.3832  decode.d0.loss_dice: 1.0812  decode.d1.loss_cls: 0.0605  decode.d1.loss_mask: 0.3787  decode.d1.loss_dice: 1.0553  decode.d2.loss_cls: 0.0534  decode.d2.loss_mask: 0.3769  decode.d2.loss_dice: 1.0590  decode.d3.loss_cls: 0.0524  decode.d3.loss_mask: 0.3719  decode.d3.loss_dice: 0.9985  decode.d4.loss_cls: 0.0451  decode.d4.loss_mask: 0.3803  decode.d4.loss_dice: 1.0218  decode.d5.loss_cls: 0.0484  decode.d5.loss_mask: 0.3783  decode.d5.loss_dice: 1.0302  decode.d6.loss_cls: 0.0512  decode.d6.loss_mask: 0.3753  decode.d6.loss_dice: 1.0157  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.3785  decode.d7.loss_dice: 1.0297  decode.d8.loss_cls: 0.0587  decode.d8.loss_mask: 0.3810  decode.d8.loss_dice: 1.0174
11/15 21:27:39 - mmengine - INFO - Iter(train) [83700/90000]  base_lr: 9.1326e-06 lr: 9.1326e-07  eta: 1:03:12  time: 0.6005  data_time: 0.0109  memory: 10675  grad_norm: 322.7969  loss: 16.3938  decode.loss_cls: 0.0801  decode.loss_mask: 0.4970  decode.loss_dice: 1.0243  decode.d0.loss_cls: 0.0961  decode.d0.loss_mask: 0.5442  decode.d0.loss_dice: 1.1470  decode.d1.loss_cls: 0.0924  decode.d1.loss_mask: 0.5015  decode.d1.loss_dice: 1.0655  decode.d2.loss_cls: 0.0865  decode.d2.loss_mask: 0.5018  decode.d2.loss_dice: 1.0287  decode.d3.loss_cls: 0.0840  decode.d3.loss_mask: 0.5014  decode.d3.loss_dice: 1.0222  decode.d4.loss_cls: 0.0722  decode.d4.loss_mask: 0.5110  decode.d4.loss_dice: 1.0590  decode.d5.loss_cls: 0.0873  decode.d5.loss_mask: 0.5063  decode.d5.loss_dice: 1.0482  decode.d6.loss_cls: 0.0929  decode.d6.loss_mask: 0.4958  decode.d6.loss_dice: 1.0141  decode.d7.loss_cls: 0.0770  decode.d7.loss_mask: 0.5028  decode.d7.loss_dice: 1.0439  decode.d8.loss_cls: 0.0829  decode.d8.loss_mask: 0.5032  decode.d8.loss_dice: 1.0243
11/15 21:28:09 - mmengine - INFO - Iter(train) [83750/90000]  base_lr: 9.0673e-06 lr: 9.0673e-07  eta: 1:02:42  time: 0.6003  data_time: 0.0108  memory: 10728  grad_norm: 343.7051  loss: 14.3356  decode.loss_cls: 0.0571  decode.loss_mask: 0.4222  decode.loss_dice: 0.9141  decode.d0.loss_cls: 0.0966  decode.d0.loss_mask: 0.4517  decode.d0.loss_dice: 0.9596  decode.d1.loss_cls: 0.0605  decode.d1.loss_mask: 0.4301  decode.d1.loss_dice: 0.9834  decode.d2.loss_cls: 0.0573  decode.d2.loss_mask: 0.4289  decode.d2.loss_dice: 0.9563  decode.d3.loss_cls: 0.0643  decode.d3.loss_mask: 0.4234  decode.d3.loss_dice: 0.9316  decode.d4.loss_cls: 0.0566  decode.d4.loss_mask: 0.4227  decode.d4.loss_dice: 0.9322  decode.d5.loss_cls: 0.0535  decode.d5.loss_mask: 0.4242  decode.d5.loss_dice: 0.9240  decode.d6.loss_cls: 0.0535  decode.d6.loss_mask: 0.4264  decode.d6.loss_dice: 0.9210  decode.d7.loss_cls: 0.0621  decode.d7.loss_mask: 0.4253  decode.d7.loss_dice: 0.9603  decode.d8.loss_cls: 0.0619  decode.d8.loss_mask: 0.4255  decode.d8.loss_dice: 0.9494
11/15 21:28:39 - mmengine - INFO - Iter(train) [83800/90000]  base_lr: 9.0020e-06 lr: 9.0020e-07  eta: 1:02:12  time: 0.6001  data_time: 0.0107  memory: 10713  grad_norm: 320.4012  loss: 13.8509  decode.loss_cls: 0.0520  decode.loss_mask: 0.4449  decode.loss_dice: 0.8717  decode.d0.loss_cls: 0.0765  decode.d0.loss_mask: 0.4675  decode.d0.loss_dice: 0.9384  decode.d1.loss_cls: 0.0541  decode.d1.loss_mask: 0.4496  decode.d1.loss_dice: 0.9016  decode.d2.loss_cls: 0.0490  decode.d2.loss_mask: 0.4506  decode.d2.loss_dice: 0.8826  decode.d3.loss_cls: 0.0468  decode.d3.loss_mask: 0.4440  decode.d3.loss_dice: 0.8833  decode.d4.loss_cls: 0.0544  decode.d4.loss_mask: 0.4398  decode.d4.loss_dice: 0.8646  decode.d5.loss_cls: 0.0591  decode.d5.loss_mask: 0.4430  decode.d5.loss_dice: 0.8449  decode.d6.loss_cls: 0.0489  decode.d6.loss_mask: 0.4438  decode.d6.loss_dice: 0.8883  decode.d7.loss_cls: 0.0474  decode.d7.loss_mask: 0.4380  decode.d7.loss_dice: 0.8950  decode.d8.loss_cls: 0.0466  decode.d8.loss_mask: 0.4463  decode.d8.loss_dice: 0.8782
11/15 21:29:09 - mmengine - INFO - Iter(train) [83850/90000]  base_lr: 8.9366e-06 lr: 8.9366e-07  eta: 1:01:42  time: 0.6015  data_time: 0.0107  memory: 10742  grad_norm: 352.4672  loss: 13.6013  decode.loss_cls: 0.0500  decode.loss_mask: 0.4138  decode.loss_dice: 0.9019  decode.d0.loss_cls: 0.0777  decode.d0.loss_mask: 0.4351  decode.d0.loss_dice: 0.9953  decode.d1.loss_cls: 0.0700  decode.d1.loss_mask: 0.4022  decode.d1.loss_dice: 0.8837  decode.d2.loss_cls: 0.0584  decode.d2.loss_mask: 0.4025  decode.d2.loss_dice: 0.8929  decode.d3.loss_cls: 0.0552  decode.d3.loss_mask: 0.4031  decode.d3.loss_dice: 0.8767  decode.d4.loss_cls: 0.0593  decode.d4.loss_mask: 0.4021  decode.d4.loss_dice: 0.8782  decode.d5.loss_cls: 0.0632  decode.d5.loss_mask: 0.3986  decode.d5.loss_dice: 0.8700  decode.d6.loss_cls: 0.0611  decode.d6.loss_mask: 0.3997  decode.d6.loss_dice: 0.8644  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.4037  decode.d7.loss_dice: 0.8823  decode.d8.loss_cls: 0.0548  decode.d8.loss_mask: 0.4020  decode.d8.loss_dice: 0.8927
11/15 21:29:39 - mmengine - INFO - Iter(train) [83900/90000]  base_lr: 8.8712e-06 lr: 8.8712e-07  eta: 1:01:12  time: 0.5999  data_time: 0.0107  memory: 10656  grad_norm: 367.4079  loss: 15.0085  decode.loss_cls: 0.0458  decode.loss_mask: 0.5108  decode.loss_dice: 0.9178  decode.d0.loss_cls: 0.0700  decode.d0.loss_mask: 0.5616  decode.d0.loss_dice: 0.9994  decode.d1.loss_cls: 0.0509  decode.d1.loss_mask: 0.5284  decode.d1.loss_dice: 0.9294  decode.d2.loss_cls: 0.0502  decode.d2.loss_mask: 0.5218  decode.d2.loss_dice: 0.9277  decode.d3.loss_cls: 0.0447  decode.d3.loss_mask: 0.5137  decode.d3.loss_dice: 0.9281  decode.d4.loss_cls: 0.0470  decode.d4.loss_mask: 0.5178  decode.d4.loss_dice: 0.9259  decode.d5.loss_cls: 0.0493  decode.d5.loss_mask: 0.5148  decode.d5.loss_dice: 0.9203  decode.d6.loss_cls: 0.0510  decode.d6.loss_mask: 0.5135  decode.d6.loss_dice: 0.9099  decode.d7.loss_cls: 0.0471  decode.d7.loss_mask: 0.5117  decode.d7.loss_dice: 0.9111  decode.d8.loss_cls: 0.0540  decode.d8.loss_mask: 0.5086  decode.d8.loss_dice: 0.9260
11/15 21:30:10 - mmengine - INFO - Iter(train) [83950/90000]  base_lr: 8.8057e-06 lr: 8.8057e-07  eta: 1:00:41  time: 0.6008  data_time: 0.0110  memory: 10692  grad_norm: 255.3690  loss: 14.7655  decode.loss_cls: 0.0475  decode.loss_mask: 0.4418  decode.loss_dice: 0.9879  decode.d0.loss_cls: 0.0717  decode.d0.loss_mask: 0.4652  decode.d0.loss_dice: 1.0522  decode.d1.loss_cls: 0.0509  decode.d1.loss_mask: 0.4512  decode.d1.loss_dice: 0.9905  decode.d2.loss_cls: 0.0532  decode.d2.loss_mask: 0.4394  decode.d2.loss_dice: 0.9971  decode.d3.loss_cls: 0.0518  decode.d3.loss_mask: 0.4353  decode.d3.loss_dice: 0.9785  decode.d4.loss_cls: 0.0511  decode.d4.loss_mask: 0.4422  decode.d4.loss_dice: 0.9833  decode.d5.loss_cls: 0.0583  decode.d5.loss_mask: 0.4403  decode.d5.loss_dice: 0.9384  decode.d6.loss_cls: 0.0469  decode.d6.loss_mask: 0.4365  decode.d6.loss_dice: 0.9652  decode.d7.loss_cls: 0.0457  decode.d7.loss_mask: 0.4403  decode.d7.loss_dice: 0.9677  decode.d8.loss_cls: 0.0516  decode.d8.loss_mask: 0.4384  decode.d8.loss_dice: 0.9455
11/15 21:30:40 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 21:30:40 - mmengine - INFO - Iter(train) [84000/90000]  base_lr: 8.7402e-06 lr: 8.7402e-07  eta: 1:00:11  time: 0.5994  data_time: 0.0106  memory: 10626  grad_norm: 456.3180  loss: 16.7006  decode.loss_cls: 0.0613  decode.loss_mask: 0.4985  decode.loss_dice: 1.1063  decode.d0.loss_cls: 0.0946  decode.d0.loss_mask: 0.4979  decode.d0.loss_dice: 1.1946  decode.d1.loss_cls: 0.0750  decode.d1.loss_mask: 0.4963  decode.d1.loss_dice: 1.1082  decode.d2.loss_cls: 0.0745  decode.d2.loss_mask: 0.4947  decode.d2.loss_dice: 1.0867  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.4971  decode.d3.loss_dice: 1.1161  decode.d4.loss_cls: 0.0691  decode.d4.loss_mask: 0.4912  decode.d4.loss_dice: 1.0998  decode.d5.loss_cls: 0.0592  decode.d5.loss_mask: 0.4938  decode.d5.loss_dice: 1.1086  decode.d6.loss_cls: 0.0653  decode.d6.loss_mask: 0.4915  decode.d6.loss_dice: 1.0720  decode.d7.loss_cls: 0.0578  decode.d7.loss_mask: 0.4894  decode.d7.loss_dice: 1.0999  decode.d8.loss_cls: 0.0657  decode.d8.loss_mask: 0.4877  decode.d8.loss_dice: 1.0949
11/15 21:31:10 - mmengine - INFO - Iter(train) [84050/90000]  base_lr: 8.6746e-06 lr: 8.6746e-07  eta: 0:59:41  time: 0.6001  data_time: 0.0107  memory: 10656  grad_norm: 337.8415  loss: 14.0065  decode.loss_cls: 0.0257  decode.loss_mask: 0.4819  decode.loss_dice: 0.8869  decode.d0.loss_cls: 0.0664  decode.d0.loss_mask: 0.5067  decode.d0.loss_dice: 0.9173  decode.d1.loss_cls: 0.0328  decode.d1.loss_mask: 0.4909  decode.d1.loss_dice: 0.8971  decode.d2.loss_cls: 0.0374  decode.d2.loss_mask: 0.4764  decode.d2.loss_dice: 0.8841  decode.d3.loss_cls: 0.0308  decode.d3.loss_mask: 0.4779  decode.d3.loss_dice: 0.8848  decode.d4.loss_cls: 0.0290  decode.d4.loss_mask: 0.4711  decode.d4.loss_dice: 0.8816  decode.d5.loss_cls: 0.0328  decode.d5.loss_mask: 0.4772  decode.d5.loss_dice: 0.8756  decode.d6.loss_cls: 0.0261  decode.d6.loss_mask: 0.4714  decode.d6.loss_dice: 0.8890  decode.d7.loss_cls: 0.0309  decode.d7.loss_mask: 0.4743  decode.d7.loss_dice: 0.8768  decode.d8.loss_cls: 0.0354  decode.d8.loss_mask: 0.4768  decode.d8.loss_dice: 0.8617
11/15 21:31:40 - mmengine - INFO - Iter(train) [84100/90000]  base_lr: 8.6090e-06 lr: 8.6090e-07  eta: 0:59:11  time: 0.6002  data_time: 0.0107  memory: 10656  grad_norm: 483.4442  loss: 15.8263  decode.loss_cls: 0.0788  decode.loss_mask: 0.4361  decode.loss_dice: 1.0437  decode.d0.loss_cls: 0.0798  decode.d0.loss_mask: 0.4700  decode.d0.loss_dice: 1.1501  decode.d1.loss_cls: 0.0703  decode.d1.loss_mask: 0.4554  decode.d1.loss_dice: 1.0922  decode.d2.loss_cls: 0.0754  decode.d2.loss_mask: 0.4402  decode.d2.loss_dice: 1.0672  decode.d3.loss_cls: 0.0900  decode.d3.loss_mask: 0.4329  decode.d3.loss_dice: 1.0319  decode.d4.loss_cls: 0.0791  decode.d4.loss_mask: 0.4331  decode.d4.loss_dice: 1.0252  decode.d5.loss_cls: 0.0770  decode.d5.loss_mask: 0.4362  decode.d5.loss_dice: 1.0734  decode.d6.loss_cls: 0.0801  decode.d6.loss_mask: 0.4415  decode.d6.loss_dice: 1.0208  decode.d7.loss_cls: 0.0722  decode.d7.loss_mask: 0.4418  decode.d7.loss_dice: 1.0437  decode.d8.loss_cls: 0.0795  decode.d8.loss_mask: 0.4393  decode.d8.loss_dice: 1.0692
11/15 21:32:10 - mmengine - INFO - Iter(train) [84150/90000]  base_lr: 8.5433e-06 lr: 8.5433e-07  eta: 0:58:41  time: 0.6002  data_time: 0.0104  memory: 10675  grad_norm: 1160.7145  loss: 14.4664  decode.loss_cls: 0.0410  decode.loss_mask: 0.4825  decode.loss_dice: 0.9174  decode.d0.loss_cls: 0.0883  decode.d0.loss_mask: 0.5228  decode.d0.loss_dice: 1.0126  decode.d1.loss_cls: 0.0540  decode.d1.loss_mask: 0.4973  decode.d1.loss_dice: 0.9437  decode.d2.loss_cls: 0.0405  decode.d2.loss_mask: 0.4960  decode.d2.loss_dice: 0.9338  decode.d3.loss_cls: 0.0486  decode.d3.loss_mask: 0.5001  decode.d3.loss_dice: 0.8925  decode.d4.loss_cls: 0.0489  decode.d4.loss_mask: 0.4710  decode.d4.loss_dice: 0.8790  decode.d5.loss_cls: 0.0492  decode.d5.loss_mask: 0.4737  decode.d5.loss_dice: 0.8804  decode.d6.loss_cls: 0.0472  decode.d6.loss_mask: 0.4746  decode.d6.loss_dice: 0.8755  decode.d7.loss_cls: 0.0500  decode.d7.loss_mask: 0.4658  decode.d7.loss_dice: 0.8658  decode.d8.loss_cls: 0.0419  decode.d8.loss_mask: 0.4776  decode.d8.loss_dice: 0.8945
11/15 21:32:40 - mmengine - INFO - Iter(train) [84200/90000]  base_lr: 8.4776e-06 lr: 8.4776e-07  eta: 0:58:11  time: 0.6041  data_time: 0.0108  memory: 10656  grad_norm: 373.0280  loss: 13.4278  decode.loss_cls: 0.0584  decode.loss_mask: 0.4045  decode.loss_dice: 0.8551  decode.d0.loss_cls: 0.0888  decode.d0.loss_mask: 0.4469  decode.d0.loss_dice: 0.9389  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.4159  decode.d1.loss_dice: 0.9028  decode.d2.loss_cls: 0.0525  decode.d2.loss_mask: 0.4037  decode.d2.loss_dice: 0.8874  decode.d3.loss_cls: 0.0599  decode.d3.loss_mask: 0.4106  decode.d3.loss_dice: 0.8499  decode.d4.loss_cls: 0.0542  decode.d4.loss_mask: 0.4054  decode.d4.loss_dice: 0.9017  decode.d5.loss_cls: 0.0575  decode.d5.loss_mask: 0.4032  decode.d5.loss_dice: 0.8361  decode.d6.loss_cls: 0.0564  decode.d6.loss_mask: 0.4024  decode.d6.loss_dice: 0.8269  decode.d7.loss_cls: 0.0552  decode.d7.loss_mask: 0.4079  decode.d7.loss_dice: 0.8641  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.4062  decode.d8.loss_dice: 0.8627
11/15 21:33:10 - mmengine - INFO - Iter(train) [84250/90000]  base_lr: 8.4118e-06 lr: 8.4118e-07  eta: 0:57:41  time: 0.6010  data_time: 0.0107  memory: 10641  grad_norm: 355.5689  loss: 14.7108  decode.loss_cls: 0.0345  decode.loss_mask: 0.4817  decode.loss_dice: 0.9246  decode.d0.loss_cls: 0.0762  decode.d0.loss_mask: 0.5122  decode.d0.loss_dice: 0.9505  decode.d1.loss_cls: 0.0512  decode.d1.loss_mask: 0.4902  decode.d1.loss_dice: 0.9464  decode.d2.loss_cls: 0.0324  decode.d2.loss_mask: 0.4812  decode.d2.loss_dice: 0.9532  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 0.4805  decode.d3.loss_dice: 0.9352  decode.d4.loss_cls: 0.0419  decode.d4.loss_mask: 0.4839  decode.d4.loss_dice: 0.9507  decode.d5.loss_cls: 0.0380  decode.d5.loss_mask: 0.4826  decode.d5.loss_dice: 0.9397  decode.d6.loss_cls: 0.0346  decode.d6.loss_mask: 0.4840  decode.d6.loss_dice: 0.9387  decode.d7.loss_cls: 0.0326  decode.d7.loss_mask: 0.4832  decode.d7.loss_dice: 0.9285  decode.d8.loss_cls: 0.0344  decode.d8.loss_mask: 0.4858  decode.d8.loss_dice: 0.9654
11/15 21:33:40 - mmengine - INFO - Iter(train) [84300/90000]  base_lr: 8.3459e-06 lr: 8.3459e-07  eta: 0:57:11  time: 0.6000  data_time: 0.0108  memory: 10656  grad_norm: 362.2512  loss: 15.0288  decode.loss_cls: 0.0430  decode.loss_mask: 0.4090  decode.loss_dice: 1.0186  decode.d0.loss_cls: 0.0656  decode.d0.loss_mask: 0.4212  decode.d0.loss_dice: 1.1187  decode.d1.loss_cls: 0.0401  decode.d1.loss_mask: 0.4169  decode.d1.loss_dice: 1.0916  decode.d2.loss_cls: 0.0411  decode.d2.loss_mask: 0.4155  decode.d2.loss_dice: 1.0587  decode.d3.loss_cls: 0.0352  decode.d3.loss_mask: 0.4079  decode.d3.loss_dice: 1.0280  decode.d4.loss_cls: 0.0400  decode.d4.loss_mask: 0.4054  decode.d4.loss_dice: 1.0525  decode.d5.loss_cls: 0.0369  decode.d5.loss_mask: 0.4106  decode.d5.loss_dice: 1.0472  decode.d6.loss_cls: 0.0377  decode.d6.loss_mask: 0.4069  decode.d6.loss_dice: 0.9997  decode.d7.loss_cls: 0.0340  decode.d7.loss_mask: 0.4056  decode.d7.loss_dice: 1.0934  decode.d8.loss_cls: 0.0481  decode.d8.loss_mask: 0.4076  decode.d8.loss_dice: 0.9921
11/15 21:34:10 - mmengine - INFO - Iter(train) [84350/90000]  base_lr: 8.2800e-06 lr: 8.2800e-07  eta: 0:56:41  time: 0.6013  data_time: 0.0107  memory: 10713  grad_norm: 279.3600  loss: 16.3714  decode.loss_cls: 0.0713  decode.loss_mask: 0.4465  decode.loss_dice: 1.1015  decode.d0.loss_cls: 0.0832  decode.d0.loss_mask: 0.4599  decode.d0.loss_dice: 1.1767  decode.d1.loss_cls: 0.0665  decode.d1.loss_mask: 0.4499  decode.d1.loss_dice: 1.1555  decode.d2.loss_cls: 0.0759  decode.d2.loss_mask: 0.4484  decode.d2.loss_dice: 1.0918  decode.d3.loss_cls: 0.0682  decode.d3.loss_mask: 0.4360  decode.d3.loss_dice: 1.1190  decode.d4.loss_cls: 0.0666  decode.d4.loss_mask: 0.4359  decode.d4.loss_dice: 1.1022  decode.d5.loss_cls: 0.0716  decode.d5.loss_mask: 0.4576  decode.d5.loss_dice: 1.1197  decode.d6.loss_cls: 0.0620  decode.d6.loss_mask: 0.4551  decode.d6.loss_dice: 1.1183  decode.d7.loss_cls: 0.0664  decode.d7.loss_mask: 0.4516  decode.d7.loss_dice: 1.1246  decode.d8.loss_cls: 0.0631  decode.d8.loss_mask: 0.4470  decode.d8.loss_dice: 1.0793
11/15 21:34:40 - mmengine - INFO - Iter(train) [84400/90000]  base_lr: 8.2140e-06 lr: 8.2140e-07  eta: 0:56:11  time: 0.6009  data_time: 0.0105  memory: 10656  grad_norm: 243.6305  loss: 14.7107  decode.loss_cls: 0.0359  decode.loss_mask: 0.4408  decode.loss_dice: 0.9871  decode.d0.loss_cls: 0.0657  decode.d0.loss_mask: 0.4598  decode.d0.loss_dice: 1.0714  decode.d1.loss_cls: 0.0565  decode.d1.loss_mask: 0.4268  decode.d1.loss_dice: 0.9789  decode.d2.loss_cls: 0.0503  decode.d2.loss_mask: 0.4314  decode.d2.loss_dice: 0.9753  decode.d3.loss_cls: 0.0421  decode.d3.loss_mask: 0.4482  decode.d3.loss_dice: 0.9678  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.4325  decode.d4.loss_dice: 0.9592  decode.d5.loss_cls: 0.0364  decode.d5.loss_mask: 0.4468  decode.d5.loss_dice: 0.9902  decode.d6.loss_cls: 0.0398  decode.d6.loss_mask: 0.4473  decode.d6.loss_dice: 1.0046  decode.d7.loss_cls: 0.0453  decode.d7.loss_mask: 0.4267  decode.d7.loss_dice: 0.9572  decode.d8.loss_cls: 0.0508  decode.d8.loss_mask: 0.4265  decode.d8.loss_dice: 0.9570
11/15 21:35:10 - mmengine - INFO - Iter(train) [84450/90000]  base_lr: 8.1480e-06 lr: 8.1480e-07  eta: 0:55:40  time: 0.5995  data_time: 0.0105  memory: 10656  grad_norm: 380.2525  loss: 14.6035  decode.loss_cls: 0.0581  decode.loss_mask: 0.4671  decode.loss_dice: 0.9247  decode.d0.loss_cls: 0.0784  decode.d0.loss_mask: 0.4560  decode.d0.loss_dice: 1.0129  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.4600  decode.d1.loss_dice: 0.9732  decode.d2.loss_cls: 0.0584  decode.d2.loss_mask: 0.4551  decode.d2.loss_dice: 0.9728  decode.d3.loss_cls: 0.0530  decode.d3.loss_mask: 0.4499  decode.d3.loss_dice: 0.9243  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.4549  decode.d4.loss_dice: 0.9030  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.4699  decode.d5.loss_dice: 0.9289  decode.d6.loss_cls: 0.0496  decode.d6.loss_mask: 0.4754  decode.d6.loss_dice: 0.9278  decode.d7.loss_cls: 0.0525  decode.d7.loss_mask: 0.4667  decode.d7.loss_dice: 0.9132  decode.d8.loss_cls: 0.0555  decode.d8.loss_mask: 0.4669  decode.d8.loss_dice: 0.9152
11/15 21:35:40 - mmengine - INFO - Iter(train) [84500/90000]  base_lr: 8.0819e-06 lr: 8.0819e-07  eta: 0:55:10  time: 0.6000  data_time: 0.0106  memory: 10675  grad_norm: 301.6573  loss: 13.7605  decode.loss_cls: 0.0377  decode.loss_mask: 0.4168  decode.loss_dice: 0.9165  decode.d0.loss_cls: 0.0674  decode.d0.loss_mask: 0.4352  decode.d0.loss_dice: 0.9883  decode.d1.loss_cls: 0.0425  decode.d1.loss_mask: 0.4187  decode.d1.loss_dice: 0.9225  decode.d2.loss_cls: 0.0347  decode.d2.loss_mask: 0.4201  decode.d2.loss_dice: 0.9354  decode.d3.loss_cls: 0.0409  decode.d3.loss_mask: 0.4089  decode.d3.loss_dice: 0.8933  decode.d4.loss_cls: 0.0415  decode.d4.loss_mask: 0.4098  decode.d4.loss_dice: 0.8920  decode.d5.loss_cls: 0.0427  decode.d5.loss_mask: 0.4080  decode.d5.loss_dice: 0.9381  decode.d6.loss_cls: 0.0418  decode.d6.loss_mask: 0.4078  decode.d6.loss_dice: 0.8954  decode.d7.loss_cls: 0.0450  decode.d7.loss_mask: 0.4067  decode.d7.loss_dice: 0.9038  decode.d8.loss_cls: 0.0366  decode.d8.loss_mask: 0.4137  decode.d8.loss_dice: 0.8988
11/15 21:36:10 - mmengine - INFO - Iter(train) [84550/90000]  base_lr: 8.0157e-06 lr: 8.0157e-07  eta: 0:54:40  time: 0.6032  data_time: 0.0109  memory: 10675  grad_norm: 253.9574  loss: 13.5420  decode.loss_cls: 0.0394  decode.loss_mask: 0.3692  decode.loss_dice: 0.9362  decode.d0.loss_cls: 0.0511  decode.d0.loss_mask: 0.3833  decode.d0.loss_dice: 1.0097  decode.d1.loss_cls: 0.0487  decode.d1.loss_mask: 0.3702  decode.d1.loss_dice: 0.9474  decode.d2.loss_cls: 0.0399  decode.d2.loss_mask: 0.3734  decode.d2.loss_dice: 0.9396  decode.d3.loss_cls: 0.0395  decode.d3.loss_mask: 0.3714  decode.d3.loss_dice: 0.9360  decode.d4.loss_cls: 0.0435  decode.d4.loss_mask: 0.3680  decode.d4.loss_dice: 0.9323  decode.d5.loss_cls: 0.0503  decode.d5.loss_mask: 0.3678  decode.d5.loss_dice: 0.9172  decode.d6.loss_cls: 0.0448  decode.d6.loss_mask: 0.3665  decode.d6.loss_dice: 0.9130  decode.d7.loss_cls: 0.0435  decode.d7.loss_mask: 0.3681  decode.d7.loss_dice: 0.9247  decode.d8.loss_cls: 0.0387  decode.d8.loss_mask: 0.3680  decode.d8.loss_dice: 0.9407
11/15 21:36:40 - mmengine - INFO - Iter(train) [84600/90000]  base_lr: 7.9495e-06 lr: 7.9495e-07  eta: 0:54:10  time: 0.6013  data_time: 0.0116  memory: 10656  grad_norm: 391.5063  loss: 14.7352  decode.loss_cls: 0.0594  decode.loss_mask: 0.4783  decode.loss_dice: 0.9071  decode.d0.loss_cls: 0.0947  decode.d0.loss_mask: 0.5360  decode.d0.loss_dice: 0.9812  decode.d1.loss_cls: 0.0785  decode.d1.loss_mask: 0.4974  decode.d1.loss_dice: 0.9514  decode.d2.loss_cls: 0.0715  decode.d2.loss_mask: 0.4909  decode.d2.loss_dice: 0.9301  decode.d3.loss_cls: 0.0696  decode.d3.loss_mask: 0.4786  decode.d3.loss_dice: 0.8941  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.4777  decode.d4.loss_dice: 0.9113  decode.d5.loss_cls: 0.0649  decode.d5.loss_mask: 0.4803  decode.d5.loss_dice: 0.9019  decode.d6.loss_cls: 0.0618  decode.d6.loss_mask: 0.4759  decode.d6.loss_dice: 0.8962  decode.d7.loss_cls: 0.0651  decode.d7.loss_mask: 0.4783  decode.d7.loss_dice: 0.9001  decode.d8.loss_cls: 0.0614  decode.d8.loss_mask: 0.4752  decode.d8.loss_dice: 0.9002
11/15 21:37:10 - mmengine - INFO - Iter(train) [84650/90000]  base_lr: 7.8832e-06 lr: 7.8832e-07  eta: 0:53:40  time: 0.6004  data_time: 0.0108  memory: 10675  grad_norm: 278.8260  loss: 11.5713  decode.loss_cls: 0.0315  decode.loss_mask: 0.3772  decode.loss_dice: 0.7291  decode.d0.loss_cls: 0.0843  decode.d0.loss_mask: 0.4046  decode.d0.loss_dice: 0.7587  decode.d1.loss_cls: 0.0486  decode.d1.loss_mask: 0.3802  decode.d1.loss_dice: 0.7597  decode.d2.loss_cls: 0.0385  decode.d2.loss_mask: 0.3784  decode.d2.loss_dice: 0.7446  decode.d3.loss_cls: 0.0365  decode.d3.loss_mask: 0.3779  decode.d3.loss_dice: 0.7323  decode.d4.loss_cls: 0.0336  decode.d4.loss_mask: 0.3765  decode.d4.loss_dice: 0.7338  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.3777  decode.d5.loss_dice: 0.7294  decode.d6.loss_cls: 0.0377  decode.d6.loss_mask: 0.3786  decode.d6.loss_dice: 0.7194  decode.d7.loss_cls: 0.0369  decode.d7.loss_mask: 0.3779  decode.d7.loss_dice: 0.7186  decode.d8.loss_cls: 0.0331  decode.d8.loss_mask: 0.3789  decode.d8.loss_dice: 0.7198
11/15 21:37:40 - mmengine - INFO - Iter(train) [84700/90000]  base_lr: 7.8169e-06 lr: 7.8169e-07  eta: 0:53:10  time: 0.6006  data_time: 0.0106  memory: 10692  grad_norm: 307.9569  loss: 15.4774  decode.loss_cls: 0.0641  decode.loss_mask: 0.4315  decode.loss_dice: 1.0246  decode.d0.loss_cls: 0.0854  decode.d0.loss_mask: 0.4442  decode.d0.loss_dice: 1.1572  decode.d1.loss_cls: 0.0745  decode.d1.loss_mask: 0.4181  decode.d1.loss_dice: 1.0648  decode.d2.loss_cls: 0.0791  decode.d2.loss_mask: 0.4225  decode.d2.loss_dice: 1.0371  decode.d3.loss_cls: 0.0612  decode.d3.loss_mask: 0.4193  decode.d3.loss_dice: 1.0569  decode.d4.loss_cls: 0.0648  decode.d4.loss_mask: 0.4255  decode.d4.loss_dice: 1.0570  decode.d5.loss_cls: 0.0646  decode.d5.loss_mask: 0.4207  decode.d5.loss_dice: 1.0189  decode.d6.loss_cls: 0.0628  decode.d6.loss_mask: 0.4255  decode.d6.loss_dice: 1.0407  decode.d7.loss_cls: 0.0694  decode.d7.loss_mask: 0.4254  decode.d7.loss_dice: 1.0320  decode.d8.loss_cls: 0.0592  decode.d8.loss_mask: 0.4239  decode.d8.loss_dice: 1.0465
11/15 21:38:10 - mmengine - INFO - Iter(train) [84750/90000]  base_lr: 7.7505e-06 lr: 7.7505e-07  eta: 0:52:40  time: 0.6004  data_time: 0.0108  memory: 10656  grad_norm: 331.5660  loss: 14.0441  decode.loss_cls: 0.0508  decode.loss_mask: 0.3946  decode.loss_dice: 0.9622  decode.d0.loss_cls: 0.0827  decode.d0.loss_mask: 0.4037  decode.d0.loss_dice: 1.0074  decode.d1.loss_cls: 0.0557  decode.d1.loss_mask: 0.4046  decode.d1.loss_dice: 0.9810  decode.d2.loss_cls: 0.0594  decode.d2.loss_mask: 0.3963  decode.d2.loss_dice: 0.9524  decode.d3.loss_cls: 0.0500  decode.d3.loss_mask: 0.3964  decode.d3.loss_dice: 0.9397  decode.d4.loss_cls: 0.0493  decode.d4.loss_mask: 0.3955  decode.d4.loss_dice: 0.9282  decode.d5.loss_cls: 0.0410  decode.d5.loss_mask: 0.3956  decode.d5.loss_dice: 0.9389  decode.d6.loss_cls: 0.0447  decode.d6.loss_mask: 0.4025  decode.d6.loss_dice: 0.9790  decode.d7.loss_cls: 0.0426  decode.d7.loss_mask: 0.4000  decode.d7.loss_dice: 0.9397  decode.d8.loss_cls: 0.0427  decode.d8.loss_mask: 0.3983  decode.d8.loss_dice: 0.9093
11/15 21:38:40 - mmengine - INFO - Iter(train) [84800/90000]  base_lr: 7.6840e-06 lr: 7.6840e-07  eta: 0:52:10  time: 0.6009  data_time: 0.0105  memory: 10692  grad_norm: 508.1055  loss: 15.1260  decode.loss_cls: 0.0412  decode.loss_mask: 0.4670  decode.loss_dice: 0.9888  decode.d0.loss_cls: 0.0964  decode.d0.loss_mask: 0.4755  decode.d0.loss_dice: 1.0673  decode.d1.loss_cls: 0.0431  decode.d1.loss_mask: 0.4797  decode.d1.loss_dice: 1.0285  decode.d2.loss_cls: 0.0463  decode.d2.loss_mask: 0.4659  decode.d2.loss_dice: 1.0179  decode.d3.loss_cls: 0.0500  decode.d3.loss_mask: 0.4605  decode.d3.loss_dice: 0.9856  decode.d4.loss_cls: 0.0411  decode.d4.loss_mask: 0.4588  decode.d4.loss_dice: 0.9860  decode.d5.loss_cls: 0.0419  decode.d5.loss_mask: 0.4516  decode.d5.loss_dice: 0.9740  decode.d6.loss_cls: 0.0374  decode.d6.loss_mask: 0.4658  decode.d6.loss_dice: 0.9843  decode.d7.loss_cls: 0.0514  decode.d7.loss_mask: 0.4584  decode.d7.loss_dice: 0.9800  decode.d8.loss_cls: 0.0416  decode.d8.loss_mask: 0.4616  decode.d8.loss_dice: 0.9785
11/15 21:39:10 - mmengine - INFO - Iter(train) [84850/90000]  base_lr: 7.6175e-06 lr: 7.6175e-07  eta: 0:51:40  time: 0.6009  data_time: 0.0108  memory: 10728  grad_norm: 367.7476  loss: 13.9292  decode.loss_cls: 0.0403  decode.loss_mask: 0.3858  decode.loss_dice: 0.9731  decode.d0.loss_cls: 0.0804  decode.d0.loss_mask: 0.4030  decode.d0.loss_dice: 1.0119  decode.d1.loss_cls: 0.0473  decode.d1.loss_mask: 0.3911  decode.d1.loss_dice: 0.9807  decode.d2.loss_cls: 0.0390  decode.d2.loss_mask: 0.3871  decode.d2.loss_dice: 0.9570  decode.d3.loss_cls: 0.0399  decode.d3.loss_mask: 0.3863  decode.d3.loss_dice: 0.9448  decode.d4.loss_cls: 0.0408  decode.d4.loss_mask: 0.3838  decode.d4.loss_dice: 0.9341  decode.d5.loss_cls: 0.0411  decode.d5.loss_mask: 0.3881  decode.d5.loss_dice: 0.9559  decode.d6.loss_cls: 0.0413  decode.d6.loss_mask: 0.3795  decode.d6.loss_dice: 0.9568  decode.d7.loss_cls: 0.0367  decode.d7.loss_mask: 0.3828  decode.d7.loss_dice: 0.9581  decode.d8.loss_cls: 0.0375  decode.d8.loss_mask: 0.3845  decode.d8.loss_dice: 0.9401
11/15 21:39:40 - mmengine - INFO - Iter(train) [84900/90000]  base_lr: 7.5509e-06 lr: 7.5509e-07  eta: 0:51:09  time: 0.6013  data_time: 0.0105  memory: 10692  grad_norm: 181.8045  loss: 13.7878  decode.loss_cls: 0.0552  decode.loss_mask: 0.3206  decode.loss_dice: 0.9984  decode.d0.loss_cls: 0.0841  decode.d0.loss_mask: 0.3312  decode.d0.loss_dice: 1.0954  decode.d1.loss_cls: 0.0885  decode.d1.loss_mask: 0.3259  decode.d1.loss_dice: 1.0032  decode.d2.loss_cls: 0.0766  decode.d2.loss_mask: 0.3204  decode.d2.loss_dice: 0.9822  decode.d3.loss_cls: 0.0709  decode.d3.loss_mask: 0.3190  decode.d3.loss_dice: 0.9588  decode.d4.loss_cls: 0.0658  decode.d4.loss_mask: 0.3209  decode.d4.loss_dice: 0.9987  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.3183  decode.d5.loss_dice: 0.9589  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.3235  decode.d6.loss_dice: 0.9508  decode.d7.loss_cls: 0.0667  decode.d7.loss_mask: 0.3240  decode.d7.loss_dice: 0.9327  decode.d8.loss_cls: 0.0670  decode.d8.loss_mask: 0.3249  decode.d8.loss_dice: 0.9658
11/15 21:40:11 - mmengine - INFO - Iter(train) [84950/90000]  base_lr: 7.4843e-06 lr: 7.4843e-07  eta: 0:50:39  time: 0.6000  data_time: 0.0106  memory: 10692  grad_norm: 357.1863  loss: 14.7519  decode.loss_cls: 0.0535  decode.loss_mask: 0.5301  decode.loss_dice: 0.8852  decode.d0.loss_cls: 0.0842  decode.d0.loss_mask: 0.5673  decode.d0.loss_dice: 0.9440  decode.d1.loss_cls: 0.0576  decode.d1.loss_mask: 0.5420  decode.d1.loss_dice: 0.9244  decode.d2.loss_cls: 0.0486  decode.d2.loss_mask: 0.5097  decode.d2.loss_dice: 0.9043  decode.d3.loss_cls: 0.0471  decode.d3.loss_mask: 0.5129  decode.d3.loss_dice: 0.8848  decode.d4.loss_cls: 0.0461  decode.d4.loss_mask: 0.5092  decode.d4.loss_dice: 0.8660  decode.d5.loss_cls: 0.0475  decode.d5.loss_mask: 0.5139  decode.d5.loss_dice: 0.8896  decode.d6.loss_cls: 0.0512  decode.d6.loss_mask: 0.5165  decode.d6.loss_dice: 0.8878  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.5204  decode.d7.loss_dice: 0.9059  decode.d8.loss_cls: 0.0551  decode.d8.loss_mask: 0.5184  decode.d8.loss_dice: 0.8744
11/15 21:40:41 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 21:40:41 - mmengine - INFO - Iter(train) [85000/90000]  base_lr: 7.4175e-06 lr: 7.4175e-07  eta: 0:50:09  time: 0.6007  data_time: 0.0106  memory: 10713  grad_norm: 392.0587  loss: 14.2167  decode.loss_cls: 0.0695  decode.loss_mask: 0.3891  decode.loss_dice: 0.9275  decode.d0.loss_cls: 0.1034  decode.d0.loss_mask: 0.4052  decode.d0.loss_dice: 1.0303  decode.d1.loss_cls: 0.0714  decode.d1.loss_mask: 0.3916  decode.d1.loss_dice: 0.9785  decode.d2.loss_cls: 0.0695  decode.d2.loss_mask: 0.3873  decode.d2.loss_dice: 0.9537  decode.d3.loss_cls: 0.0681  decode.d3.loss_mask: 0.3917  decode.d3.loss_dice: 0.9458  decode.d4.loss_cls: 0.0729  decode.d4.loss_mask: 0.3901  decode.d4.loss_dice: 0.9407  decode.d5.loss_cls: 0.0754  decode.d5.loss_mask: 0.3915  decode.d5.loss_dice: 0.9470  decode.d6.loss_cls: 0.0736  decode.d6.loss_mask: 0.3887  decode.d6.loss_dice: 0.9543  decode.d7.loss_cls: 0.0656  decode.d7.loss_mask: 0.3925  decode.d7.loss_dice: 0.9446  decode.d8.loss_cls: 0.0752  decode.d8.loss_mask: 0.3906  decode.d8.loss_dice: 0.9314
11/15 21:40:41 - mmengine - INFO - Saving checkpoint at 85000 iterations
11/15 21:41:00 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:22  time: 0.3080  data_time: 0.0040  memory: 4095  
11/15 21:41:15 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:04  time: 0.3082  data_time: 0.0039  memory: 4095  
11/15 21:41:31 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:48  time: 0.3092  data_time: 0.0041  memory: 4095  
11/15 21:41:46 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:33  time: 0.3087  data_time: 0.0039  memory: 4095  
11/15 21:42:02 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3095  data_time: 0.0042  memory: 4095  
11/15 21:42:17 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:01  time: 0.3095  data_time: 0.0048  memory: 4095  
11/15 21:42:32 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3094  data_time: 0.0041  memory: 4095  
11/15 21:42:48 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:30  time: 0.3099  data_time: 0.0039  memory: 4095  
11/15 21:43:03 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3086  data_time: 0.0038  memory: 4095  
11/15 21:43:19 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3082  data_time: 0.0036  memory: 4095  
11/15 21:43:19 - mmengine - INFO - per class results:
11/15 21:43:19 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 98.14 | 98.52 |
|    sidewalk   | 86.05 | 94.87 |
|    building   | 93.24 | 96.56 |
|      wall     | 65.45 | 79.02 |
|     fence     | 62.38 | 74.19 |
|      pole     | 69.03 | 81.92 |
| traffic light | 73.25 | 83.15 |
|  traffic sign | 81.78 |  88.8 |
|   vegetation  |  92.7 | 96.48 |
|    terrain    | 67.39 | 81.05 |
|      sky      | 95.01 | 97.36 |
|     person    | 83.22 | 90.77 |
|     rider     | 66.59 | 80.94 |
|      car      | 95.42 | 97.99 |
|     truck     | 84.35 | 93.35 |
|      bus      | 86.83 | 90.81 |
|     train     | 72.73 | 92.75 |
|   motorcycle  | 67.51 | 82.78 |
|    bicycle    | 79.53 |  89.1 |
+---------------+-------+-------+
11/15 21:43:19 - mmengine - INFO - Iter(val) [500/500]    aAcc: 96.3700  mIoU: 80.0300  mAcc: 88.9700  data_time: 0.0047  time: 0.3094
11/15 21:43:19 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024/best_mIoU_iter_70000.pth is removed
11/15 21:43:20 - mmengine - INFO - The best checkpoint with 80.0300 mIoU at 85000 iter is saved to best_mIoU_iter_85000.pth.
11/15 21:43:54 - mmengine - INFO - Iter(train) [85050/90000]  base_lr: 7.3507e-06 lr: 7.3507e-07  eta: 0:49:39  time: 0.6028  data_time: 0.0110  memory: 10728  grad_norm: 298.4527  loss: 14.7428  decode.loss_cls: 0.0685  decode.loss_mask: 0.4124  decode.loss_dice: 0.9728  decode.d0.loss_cls: 0.0919  decode.d0.loss_mask: 0.4278  decode.d0.loss_dice: 1.0578  decode.d1.loss_cls: 0.0772  decode.d1.loss_mask: 0.4108  decode.d1.loss_dice: 0.9739  decode.d2.loss_cls: 0.0703  decode.d2.loss_mask: 0.4158  decode.d2.loss_dice: 0.9936  decode.d3.loss_cls: 0.0842  decode.d3.loss_mask: 0.4105  decode.d3.loss_dice: 0.9800  decode.d4.loss_cls: 0.0735  decode.d4.loss_mask: 0.4117  decode.d4.loss_dice: 0.9735  decode.d5.loss_cls: 0.0834  decode.d5.loss_mask: 0.4085  decode.d5.loss_dice: 0.9787  decode.d6.loss_cls: 0.0750  decode.d6.loss_mask: 0.4083  decode.d6.loss_dice: 0.9530  decode.d7.loss_cls: 0.0809  decode.d7.loss_mask: 0.4095  decode.d7.loss_dice: 0.9775  decode.d8.loss_cls: 0.0706  decode.d8.loss_mask: 0.4143  decode.d8.loss_dice: 0.9773
11/15 21:44:24 - mmengine - INFO - Iter(train) [85100/90000]  base_lr: 7.2839e-06 lr: 7.2839e-07  eta: 0:49:09  time: 0.6073  data_time: 0.0112  memory: 10675  grad_norm: 293.8661  loss: 12.6554  decode.loss_cls: 0.0423  decode.loss_mask: 0.3345  decode.loss_dice: 0.8580  decode.d0.loss_cls: 0.0755  decode.d0.loss_mask: 0.3677  decode.d0.loss_dice: 0.9603  decode.d1.loss_cls: 0.0480  decode.d1.loss_mask: 0.3420  decode.d1.loss_dice: 0.8905  decode.d2.loss_cls: 0.0516  decode.d2.loss_mask: 0.3421  decode.d2.loss_dice: 0.8819  decode.d3.loss_cls: 0.0467  decode.d3.loss_mask: 0.3382  decode.d3.loss_dice: 0.8645  decode.d4.loss_cls: 0.0372  decode.d4.loss_mask: 0.3377  decode.d4.loss_dice: 0.8643  decode.d5.loss_cls: 0.0387  decode.d5.loss_mask: 0.3368  decode.d5.loss_dice: 0.8719  decode.d6.loss_cls: 0.0352  decode.d6.loss_mask: 0.3382  decode.d6.loss_dice: 0.8756  decode.d7.loss_cls: 0.0443  decode.d7.loss_mask: 0.3370  decode.d7.loss_dice: 0.8604  decode.d8.loss_cls: 0.0344  decode.d8.loss_mask: 0.3390  decode.d8.loss_dice: 0.8609
11/15 21:44:54 - mmengine - INFO - Iter(train) [85150/90000]  base_lr: 7.2169e-06 lr: 7.2169e-07  eta: 0:48:39  time: 0.6008  data_time: 0.0106  memory: 10675  grad_norm: 395.6318  loss: 14.2481  decode.loss_cls: 0.0588  decode.loss_mask: 0.4112  decode.loss_dice: 0.9366  decode.d0.loss_cls: 0.0702  decode.d0.loss_mask: 0.4359  decode.d0.loss_dice: 0.9815  decode.d1.loss_cls: 0.0749  decode.d1.loss_mask: 0.4254  decode.d1.loss_dice: 0.9761  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.4255  decode.d2.loss_dice: 0.9396  decode.d3.loss_cls: 0.0594  decode.d3.loss_mask: 0.4198  decode.d3.loss_dice: 0.9241  decode.d4.loss_cls: 0.0698  decode.d4.loss_mask: 0.4194  decode.d4.loss_dice: 0.9456  decode.d5.loss_cls: 0.0628  decode.d5.loss_mask: 0.4157  decode.d5.loss_dice: 0.9153  decode.d6.loss_cls: 0.0570  decode.d6.loss_mask: 0.4145  decode.d6.loss_dice: 0.9114  decode.d7.loss_cls: 0.0701  decode.d7.loss_mask: 0.4145  decode.d7.loss_dice: 0.9512  decode.d8.loss_cls: 0.0631  decode.d8.loss_mask: 0.4157  decode.d8.loss_dice: 0.9241
11/15 21:45:24 - mmengine - INFO - Iter(train) [85200/90000]  base_lr: 7.1500e-06 lr: 7.1500e-07  eta: 0:48:09  time: 0.5991  data_time: 0.0106  memory: 10675  grad_norm: 443.5751  loss: 15.4690  decode.loss_cls: 0.0564  decode.loss_mask: 0.4917  decode.loss_dice: 0.9835  decode.d0.loss_cls: 0.0855  decode.d0.loss_mask: 0.5075  decode.d0.loss_dice: 1.0156  decode.d1.loss_cls: 0.0436  decode.d1.loss_mask: 0.4937  decode.d1.loss_dice: 1.0426  decode.d2.loss_cls: 0.0466  decode.d2.loss_mask: 0.4970  decode.d2.loss_dice: 1.0358  decode.d3.loss_cls: 0.0501  decode.d3.loss_mask: 0.4832  decode.d3.loss_dice: 0.9781  decode.d4.loss_cls: 0.0566  decode.d4.loss_mask: 0.4916  decode.d4.loss_dice: 0.9841  decode.d5.loss_cls: 0.0490  decode.d5.loss_mask: 0.4942  decode.d5.loss_dice: 1.0021  decode.d6.loss_cls: 0.0472  decode.d6.loss_mask: 0.4944  decode.d6.loss_dice: 0.9911  decode.d7.loss_cls: 0.0496  decode.d7.loss_mask: 0.4839  decode.d7.loss_dice: 0.9795  decode.d8.loss_cls: 0.0505  decode.d8.loss_mask: 0.4876  decode.d8.loss_dice: 0.9965
11/15 21:45:54 - mmengine - INFO - Iter(train) [85250/90000]  base_lr: 7.0829e-06 lr: 7.0829e-07  eta: 0:47:39  time: 0.5997  data_time: 0.0107  memory: 10656  grad_norm: 374.3787  loss: 16.2351  decode.loss_cls: 0.0404  decode.loss_mask: 0.5840  decode.loss_dice: 0.9694  decode.d0.loss_cls: 0.0799  decode.d0.loss_mask: 0.6336  decode.d0.loss_dice: 1.0020  decode.d1.loss_cls: 0.0367  decode.d1.loss_mask: 0.5934  decode.d1.loss_dice: 0.9979  decode.d2.loss_cls: 0.0339  decode.d2.loss_mask: 0.5919  decode.d2.loss_dice: 0.9925  decode.d3.loss_cls: 0.0298  decode.d3.loss_mask: 0.5931  decode.d3.loss_dice: 0.9817  decode.d4.loss_cls: 0.0458  decode.d4.loss_mask: 0.5921  decode.d4.loss_dice: 0.9714  decode.d5.loss_cls: 0.0367  decode.d5.loss_mask: 0.5901  decode.d5.loss_dice: 1.0147  decode.d6.loss_cls: 0.0422  decode.d6.loss_mask: 0.5909  decode.d6.loss_dice: 0.9632  decode.d7.loss_cls: 0.0334  decode.d7.loss_mask: 0.5919  decode.d7.loss_dice: 0.9919  decode.d8.loss_cls: 0.0322  decode.d8.loss_mask: 0.5954  decode.d8.loss_dice: 0.9832
11/15 21:46:24 - mmengine - INFO - Iter(train) [85300/90000]  base_lr: 7.0158e-06 lr: 7.0158e-07  eta: 0:47:09  time: 0.6020  data_time: 0.0109  memory: 10713  grad_norm: 262.3689  loss: 14.5439  decode.loss_cls: 0.0516  decode.loss_mask: 0.4262  decode.loss_dice: 0.9673  decode.d0.loss_cls: 0.0602  decode.d0.loss_mask: 0.4634  decode.d0.loss_dice: 1.0814  decode.d1.loss_cls: 0.0540  decode.d1.loss_mask: 0.4287  decode.d1.loss_dice: 0.9585  decode.d2.loss_cls: 0.0441  decode.d2.loss_mask: 0.4356  decode.d2.loss_dice: 1.0073  decode.d3.loss_cls: 0.0620  decode.d3.loss_mask: 0.4297  decode.d3.loss_dice: 0.9274  decode.d4.loss_cls: 0.0443  decode.d4.loss_mask: 0.4261  decode.d4.loss_dice: 0.9434  decode.d5.loss_cls: 0.0548  decode.d5.loss_mask: 0.4335  decode.d5.loss_dice: 0.9551  decode.d6.loss_cls: 0.0542  decode.d6.loss_mask: 0.4236  decode.d6.loss_dice: 0.9483  decode.d7.loss_cls: 0.0478  decode.d7.loss_mask: 0.4309  decode.d7.loss_dice: 0.9589  decode.d8.loss_cls: 0.0535  decode.d8.loss_mask: 0.4278  decode.d8.loss_dice: 0.9441
11/15 21:46:54 - mmengine - INFO - Iter(train) [85350/90000]  base_lr: 6.9485e-06 lr: 6.9485e-07  eta: 0:46:39  time: 0.6047  data_time: 0.0108  memory: 10656  grad_norm: 412.0439  loss: 16.0740  decode.loss_cls: 0.0450  decode.loss_mask: 0.4980  decode.loss_dice: 0.9938  decode.d0.loss_cls: 0.0612  decode.d0.loss_mask: 0.6065  decode.d0.loss_dice: 1.0884  decode.d1.loss_cls: 0.0527  decode.d1.loss_mask: 0.5370  decode.d1.loss_dice: 1.0411  decode.d2.loss_cls: 0.0401  decode.d2.loss_mask: 0.5629  decode.d2.loss_dice: 1.0222  decode.d3.loss_cls: 0.0399  decode.d3.loss_mask: 0.5683  decode.d3.loss_dice: 1.0045  decode.d4.loss_cls: 0.0345  decode.d4.loss_mask: 0.5635  decode.d4.loss_dice: 1.0032  decode.d5.loss_cls: 0.0441  decode.d5.loss_mask: 0.5506  decode.d5.loss_dice: 0.9855  decode.d6.loss_cls: 0.0424  decode.d6.loss_mask: 0.5464  decode.d6.loss_dice: 0.9913  decode.d7.loss_cls: 0.0384  decode.d7.loss_mask: 0.5440  decode.d7.loss_dice: 1.0166  decode.d8.loss_cls: 0.0436  decode.d8.loss_mask: 0.5083  decode.d8.loss_dice: 0.9999
11/15 21:47:24 - mmengine - INFO - Iter(train) [85400/90000]  base_lr: 6.8813e-06 lr: 6.8813e-07  eta: 0:46:09  time: 0.6010  data_time: 0.0111  memory: 10692  grad_norm: 496.2449  loss: 16.0460  decode.loss_cls: 0.0527  decode.loss_mask: 0.5376  decode.loss_dice: 0.9958  decode.d0.loss_cls: 0.0950  decode.d0.loss_mask: 0.5434  decode.d0.loss_dice: 1.0570  decode.d1.loss_cls: 0.0627  decode.d1.loss_mask: 0.5449  decode.d1.loss_dice: 1.0536  decode.d2.loss_cls: 0.0572  decode.d2.loss_mask: 0.5458  decode.d2.loss_dice: 1.0261  decode.d3.loss_cls: 0.0473  decode.d3.loss_mask: 0.5384  decode.d3.loss_dice: 1.0127  decode.d4.loss_cls: 0.0535  decode.d4.loss_mask: 0.5410  decode.d4.loss_dice: 1.0231  decode.d5.loss_cls: 0.0473  decode.d5.loss_mask: 0.5274  decode.d5.loss_dice: 0.9864  decode.d6.loss_cls: 0.0464  decode.d6.loss_mask: 0.5302  decode.d6.loss_dice: 0.9850  decode.d7.loss_cls: 0.0611  decode.d7.loss_mask: 0.5280  decode.d7.loss_dice: 0.9772  decode.d8.loss_cls: 0.0499  decode.d8.loss_mask: 0.5341  decode.d8.loss_dice: 0.9851
11/15 21:47:54 - mmengine - INFO - Iter(train) [85450/90000]  base_lr: 6.8139e-06 lr: 6.8139e-07  eta: 0:45:39  time: 0.6009  data_time: 0.0105  memory: 10692  grad_norm: 293.9484  loss: 15.2655  decode.loss_cls: 0.0449  decode.loss_mask: 0.4400  decode.loss_dice: 1.0005  decode.d0.loss_cls: 0.0964  decode.d0.loss_mask: 0.4731  decode.d0.loss_dice: 1.1029  decode.d1.loss_cls: 0.0517  decode.d1.loss_mask: 0.4601  decode.d1.loss_dice: 1.0534  decode.d2.loss_cls: 0.0510  decode.d2.loss_mask: 0.4505  decode.d2.loss_dice: 1.0259  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.4484  decode.d3.loss_dice: 1.0352  decode.d4.loss_cls: 0.0477  decode.d4.loss_mask: 0.4454  decode.d4.loss_dice: 1.0217  decode.d5.loss_cls: 0.0469  decode.d5.loss_mask: 0.4429  decode.d5.loss_dice: 1.0080  decode.d6.loss_cls: 0.0479  decode.d6.loss_mask: 0.4423  decode.d6.loss_dice: 1.0021  decode.d7.loss_cls: 0.0489  decode.d7.loss_mask: 0.4443  decode.d7.loss_dice: 0.9879  decode.d8.loss_cls: 0.0460  decode.d8.loss_mask: 0.4464  decode.d8.loss_dice: 1.0007
11/15 21:48:24 - mmengine - INFO - Iter(train) [85500/90000]  base_lr: 6.7465e-06 lr: 6.7465e-07  eta: 0:45:09  time: 0.6006  data_time: 0.0108  memory: 10713  grad_norm: 689.1952  loss: 14.1101  decode.loss_cls: 0.0454  decode.loss_mask: 0.4253  decode.loss_dice: 0.8851  decode.d0.loss_cls: 0.0631  decode.d0.loss_mask: 0.4796  decode.d0.loss_dice: 0.9839  decode.d1.loss_cls: 0.0493  decode.d1.loss_mask: 0.4526  decode.d1.loss_dice: 0.9080  decode.d2.loss_cls: 0.0530  decode.d2.loss_mask: 0.4561  decode.d2.loss_dice: 0.9250  decode.d3.loss_cls: 0.0406  decode.d3.loss_mask: 0.4535  decode.d3.loss_dice: 0.9048  decode.d4.loss_cls: 0.0608  decode.d4.loss_mask: 0.4561  decode.d4.loss_dice: 0.8881  decode.d5.loss_cls: 0.0422  decode.d5.loss_mask: 0.4548  decode.d5.loss_dice: 0.9037  decode.d6.loss_cls: 0.0491  decode.d6.loss_mask: 0.4565  decode.d6.loss_dice: 0.8936  decode.d7.loss_cls: 0.0496  decode.d7.loss_mask: 0.4534  decode.d7.loss_dice: 0.9105  decode.d8.loss_cls: 0.0447  decode.d8.loss_mask: 0.4338  decode.d8.loss_dice: 0.8881
11/15 21:48:54 - mmengine - INFO - Iter(train) [85550/90000]  base_lr: 6.6790e-06 lr: 6.6790e-07  eta: 0:44:38  time: 0.6007  data_time: 0.0107  memory: 10656  grad_norm: 299.4817  loss: 15.3748  decode.loss_cls: 0.0635  decode.loss_mask: 0.4535  decode.loss_dice: 1.0014  decode.d0.loss_cls: 0.0872  decode.d0.loss_mask: 0.5003  decode.d0.loss_dice: 1.1000  decode.d1.loss_cls: 0.0794  decode.d1.loss_mask: 0.4634  decode.d1.loss_dice: 0.9827  decode.d2.loss_cls: 0.0719  decode.d2.loss_mask: 0.4587  decode.d2.loss_dice: 0.9756  decode.d3.loss_cls: 0.0573  decode.d3.loss_mask: 0.4689  decode.d3.loss_dice: 0.9908  decode.d4.loss_cls: 0.0654  decode.d4.loss_mask: 0.4655  decode.d4.loss_dice: 1.0055  decode.d5.loss_cls: 0.0697  decode.d5.loss_mask: 0.4708  decode.d5.loss_dice: 1.0032  decode.d6.loss_cls: 0.0635  decode.d6.loss_mask: 0.4588  decode.d6.loss_dice: 0.9824  decode.d7.loss_cls: 0.0708  decode.d7.loss_mask: 0.4561  decode.d7.loss_dice: 0.9892  decode.d8.loss_cls: 0.0688  decode.d8.loss_mask: 0.4596  decode.d8.loss_dice: 0.9911
11/15 21:49:25 - mmengine - INFO - Iter(train) [85600/90000]  base_lr: 6.6114e-06 lr: 6.6114e-07  eta: 0:44:08  time: 0.6018  data_time: 0.0109  memory: 10656  grad_norm: 302.8907  loss: 15.5594  decode.loss_cls: 0.0513  decode.loss_mask: 0.4646  decode.loss_dice: 1.0302  decode.d0.loss_cls: 0.0804  decode.d0.loss_mask: 0.4913  decode.d0.loss_dice: 1.1126  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.4683  decode.d1.loss_dice: 1.0384  decode.d2.loss_cls: 0.0746  decode.d2.loss_mask: 0.4583  decode.d2.loss_dice: 1.0240  decode.d3.loss_cls: 0.0618  decode.d3.loss_mask: 0.4670  decode.d3.loss_dice: 1.0176  decode.d4.loss_cls: 0.0504  decode.d4.loss_mask: 0.4654  decode.d4.loss_dice: 1.0267  decode.d5.loss_cls: 0.0537  decode.d5.loss_mask: 0.4614  decode.d5.loss_dice: 0.9989  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.4609  decode.d6.loss_dice: 1.0240  decode.d7.loss_cls: 0.0597  decode.d7.loss_mask: 0.4654  decode.d7.loss_dice: 0.9803  decode.d8.loss_cls: 0.0600  decode.d8.loss_mask: 0.4606  decode.d8.loss_dice: 1.0215
11/15 21:49:55 - mmengine - INFO - Iter(train) [85650/90000]  base_lr: 6.5437e-06 lr: 6.5437e-07  eta: 0:43:38  time: 0.5992  data_time: 0.0106  memory: 10656  grad_norm: 236.3791  loss: 15.6532  decode.loss_cls: 0.0528  decode.loss_mask: 0.4302  decode.loss_dice: 1.0697  decode.d0.loss_cls: 0.0917  decode.d0.loss_mask: 0.4402  decode.d0.loss_dice: 1.1110  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.4395  decode.d1.loss_dice: 1.0876  decode.d2.loss_cls: 0.0595  decode.d2.loss_mask: 0.4397  decode.d2.loss_dice: 1.0916  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.4302  decode.d3.loss_dice: 1.0472  decode.d4.loss_cls: 0.0473  decode.d4.loss_mask: 0.4371  decode.d4.loss_dice: 1.0790  decode.d5.loss_cls: 0.0592  decode.d5.loss_mask: 0.4298  decode.d5.loss_dice: 1.0536  decode.d6.loss_cls: 0.0704  decode.d6.loss_mask: 0.4294  decode.d6.loss_dice: 1.0379  decode.d7.loss_cls: 0.0631  decode.d7.loss_mask: 0.4280  decode.d7.loss_dice: 1.0515  decode.d8.loss_cls: 0.0501  decode.d8.loss_mask: 0.4316  decode.d8.loss_dice: 1.0467
11/15 21:50:25 - mmengine - INFO - Iter(train) [85700/90000]  base_lr: 6.4760e-06 lr: 6.4760e-07  eta: 0:43:08  time: 0.5998  data_time: 0.0104  memory: 10656  grad_norm: 232.0752  loss: 13.3320  decode.loss_cls: 0.0438  decode.loss_mask: 0.3874  decode.loss_dice: 0.8707  decode.d0.loss_cls: 0.0820  decode.d0.loss_mask: 0.4167  decode.d0.loss_dice: 0.9608  decode.d1.loss_cls: 0.0538  decode.d1.loss_mask: 0.3964  decode.d1.loss_dice: 0.9177  decode.d2.loss_cls: 0.0476  decode.d2.loss_mask: 0.3956  decode.d2.loss_dice: 0.9026  decode.d3.loss_cls: 0.0507  decode.d3.loss_mask: 0.3841  decode.d3.loss_dice: 0.8794  decode.d4.loss_cls: 0.0466  decode.d4.loss_mask: 0.3845  decode.d4.loss_dice: 0.8619  decode.d5.loss_cls: 0.0427  decode.d5.loss_mask: 0.3854  decode.d5.loss_dice: 0.8968  decode.d6.loss_cls: 0.0458  decode.d6.loss_mask: 0.3818  decode.d6.loss_dice: 0.8695  decode.d7.loss_cls: 0.0446  decode.d7.loss_mask: 0.3846  decode.d7.loss_dice: 0.8841  decode.d8.loss_cls: 0.0435  decode.d8.loss_mask: 0.3879  decode.d8.loss_dice: 0.8827
11/15 21:50:55 - mmengine - INFO - Iter(train) [85750/90000]  base_lr: 6.4082e-06 lr: 6.4082e-07  eta: 0:42:38  time: 0.6009  data_time: 0.0106  memory: 10728  grad_norm: 304.8722  loss: 18.1370  decode.loss_cls: 0.0587  decode.loss_mask: 0.5024  decode.loss_dice: 1.2617  decode.d0.loss_cls: 0.0726  decode.d0.loss_mask: 0.5036  decode.d0.loss_dice: 1.3075  decode.d1.loss_cls: 0.0567  decode.d1.loss_mask: 0.4899  decode.d1.loss_dice: 1.2783  decode.d2.loss_cls: 0.0624  decode.d2.loss_mask: 0.4790  decode.d2.loss_dice: 1.2638  decode.d3.loss_cls: 0.0593  decode.d3.loss_mask: 0.4863  decode.d3.loss_dice: 1.2537  decode.d4.loss_cls: 0.0725  decode.d4.loss_mask: 0.4895  decode.d4.loss_dice: 1.2416  decode.d5.loss_cls: 0.0789  decode.d5.loss_mask: 0.4947  decode.d5.loss_dice: 1.2238  decode.d6.loss_cls: 0.0693  decode.d6.loss_mask: 0.4981  decode.d6.loss_dice: 1.2316  decode.d7.loss_cls: 0.0800  decode.d7.loss_mask: 0.4966  decode.d7.loss_dice: 1.2319  decode.d8.loss_cls: 0.0644  decode.d8.loss_mask: 0.4951  decode.d8.loss_dice: 1.2333
11/15 21:51:25 - mmengine - INFO - Iter(train) [85800/90000]  base_lr: 6.3403e-06 lr: 6.3403e-07  eta: 0:42:08  time: 0.5999  data_time: 0.0106  memory: 10675  grad_norm: 411.3228  loss: 15.7676  decode.loss_cls: 0.0602  decode.loss_mask: 0.4355  decode.loss_dice: 1.0572  decode.d0.loss_cls: 0.0799  decode.d0.loss_mask: 0.4818  decode.d0.loss_dice: 1.1657  decode.d1.loss_cls: 0.0553  decode.d1.loss_mask: 0.4356  decode.d1.loss_dice: 1.1071  decode.d2.loss_cls: 0.0712  decode.d2.loss_mask: 0.4386  decode.d2.loss_dice: 1.0774  decode.d3.loss_cls: 0.0613  decode.d3.loss_mask: 0.4367  decode.d3.loss_dice: 1.0441  decode.d4.loss_cls: 0.0543  decode.d4.loss_mask: 0.4410  decode.d4.loss_dice: 1.0663  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.4326  decode.d5.loss_dice: 1.0480  decode.d6.loss_cls: 0.0656  decode.d6.loss_mask: 0.4341  decode.d6.loss_dice: 1.0501  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.4349  decode.d7.loss_dice: 1.0607  decode.d8.loss_cls: 0.0620  decode.d8.loss_mask: 0.4370  decode.d8.loss_dice: 1.0490
11/15 21:51:55 - mmengine - INFO - Iter(train) [85850/90000]  base_lr: 6.2723e-06 lr: 6.2723e-07  eta: 0:41:38  time: 0.6072  data_time: 0.0111  memory: 10675  grad_norm: 553.3369  loss: 14.6463  decode.loss_cls: 0.0273  decode.loss_mask: 0.5205  decode.loss_dice: 0.8959  decode.d0.loss_cls: 0.0758  decode.d0.loss_mask: 0.5443  decode.d0.loss_dice: 0.9625  decode.d1.loss_cls: 0.0354  decode.d1.loss_mask: 0.5282  decode.d1.loss_dice: 0.9599  decode.d2.loss_cls: 0.0261  decode.d2.loss_mask: 0.5161  decode.d2.loss_dice: 0.8898  decode.d3.loss_cls: 0.0299  decode.d3.loss_mask: 0.5223  decode.d3.loss_dice: 0.8962  decode.d4.loss_cls: 0.0254  decode.d4.loss_mask: 0.5176  decode.d4.loss_dice: 0.8839  decode.d5.loss_cls: 0.0280  decode.d5.loss_mask: 0.5194  decode.d5.loss_dice: 0.8946  decode.d6.loss_cls: 0.0256  decode.d6.loss_mask: 0.5234  decode.d6.loss_dice: 0.9039  decode.d7.loss_cls: 0.0252  decode.d7.loss_mask: 0.5236  decode.d7.loss_dice: 0.9237  decode.d8.loss_cls: 0.0282  decode.d8.loss_mask: 0.5175  decode.d8.loss_dice: 0.8761
11/15 21:52:25 - mmengine - INFO - Iter(train) [85900/90000]  base_lr: 6.2043e-06 lr: 6.2043e-07  eta: 0:41:08  time: 0.5996  data_time: 0.0106  memory: 10656  grad_norm: 513.4323  loss: 15.3533  decode.loss_cls: 0.0259  decode.loss_mask: 0.5552  decode.loss_dice: 0.9210  decode.d0.loss_cls: 0.0719  decode.d0.loss_mask: 0.5989  decode.d0.loss_dice: 0.9666  decode.d1.loss_cls: 0.0405  decode.d1.loss_mask: 0.5612  decode.d1.loss_dice: 0.9629  decode.d2.loss_cls: 0.0399  decode.d2.loss_mask: 0.5564  decode.d2.loss_dice: 0.9365  decode.d3.loss_cls: 0.0270  decode.d3.loss_mask: 0.5545  decode.d3.loss_dice: 0.9182  decode.d4.loss_cls: 0.0321  decode.d4.loss_mask: 0.5557  decode.d4.loss_dice: 0.9356  decode.d5.loss_cls: 0.0297  decode.d5.loss_mask: 0.5550  decode.d5.loss_dice: 0.9271  decode.d6.loss_cls: 0.0348  decode.d6.loss_mask: 0.5571  decode.d6.loss_dice: 0.9351  decode.d7.loss_cls: 0.0261  decode.d7.loss_mask: 0.5587  decode.d7.loss_dice: 0.9356  decode.d8.loss_cls: 0.0290  decode.d8.loss_mask: 0.5585  decode.d8.loss_dice: 0.9469
11/15 21:52:56 - mmengine - INFO - Iter(train) [85950/90000]  base_lr: 6.1361e-06 lr: 6.1361e-07  eta: 0:40:38  time: 0.7033  data_time: 0.0198  memory: 10675  grad_norm: 1029.9159  loss: 15.7016  decode.loss_cls: 0.0388  decode.loss_mask: 0.4493  decode.loss_dice: 1.0668  decode.d0.loss_cls: 0.0688  decode.d0.loss_mask: 0.4723  decode.d0.loss_dice: 1.1505  decode.d1.loss_cls: 0.0433  decode.d1.loss_mask: 0.4629  decode.d1.loss_dice: 1.0844  decode.d2.loss_cls: 0.0420  decode.d2.loss_mask: 0.4492  decode.d2.loss_dice: 1.0526  decode.d3.loss_cls: 0.0452  decode.d3.loss_mask: 0.4508  decode.d3.loss_dice: 1.0522  decode.d4.loss_cls: 0.0487  decode.d4.loss_mask: 0.4647  decode.d4.loss_dice: 1.0323  decode.d5.loss_cls: 0.0456  decode.d5.loss_mask: 0.4638  decode.d5.loss_dice: 1.0515  decode.d6.loss_cls: 0.0350  decode.d6.loss_mask: 0.4633  decode.d6.loss_dice: 1.0611  decode.d7.loss_cls: 0.0408  decode.d7.loss_mask: 0.4625  decode.d7.loss_dice: 1.0391  decode.d8.loss_cls: 0.0390  decode.d8.loss_mask: 0.4685  decode.d8.loss_dice: 1.0568
11/15 21:53:31 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 21:53:31 - mmengine - INFO - Iter(train) [86000/90000]  base_lr: 6.0679e-06 lr: 6.0679e-07  eta: 0:40:08  time: 0.6011  data_time: 0.0107  memory: 10641  grad_norm: 568.5205  loss: 13.7515  decode.loss_cls: 0.0250  decode.loss_mask: 0.4682  decode.loss_dice: 0.8648  decode.d0.loss_cls: 0.0720  decode.d0.loss_mask: 0.4916  decode.d0.loss_dice: 0.9259  decode.d1.loss_cls: 0.0306  decode.d1.loss_mask: 0.4740  decode.d1.loss_dice: 0.9042  decode.d2.loss_cls: 0.0255  decode.d2.loss_mask: 0.4669  decode.d2.loss_dice: 0.8733  decode.d3.loss_cls: 0.0179  decode.d3.loss_mask: 0.4755  decode.d3.loss_dice: 0.8649  decode.d4.loss_cls: 0.0181  decode.d4.loss_mask: 0.4745  decode.d4.loss_dice: 0.8639  decode.d5.loss_cls: 0.0190  decode.d5.loss_mask: 0.4740  decode.d5.loss_dice: 0.8686  decode.d6.loss_cls: 0.0212  decode.d6.loss_mask: 0.4698  decode.d6.loss_dice: 0.8523  decode.d7.loss_cls: 0.0247  decode.d7.loss_mask: 0.4780  decode.d7.loss_dice: 0.8609  decode.d8.loss_cls: 0.0249  decode.d8.loss_mask: 0.4699  decode.d8.loss_dice: 0.8514
11/15 21:54:01 - mmengine - INFO - Iter(train) [86050/90000]  base_lr: 5.9996e-06 lr: 5.9996e-07  eta: 0:39:38  time: 0.5981  data_time: 0.0109  memory: 10692  grad_norm: 317.9535  loss: 16.4345  decode.loss_cls: 0.0588  decode.loss_mask: 0.4974  decode.loss_dice: 1.0418  decode.d0.loss_cls: 0.0683  decode.d0.loss_mask: 0.5455  decode.d0.loss_dice: 1.1501  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.5091  decode.d1.loss_dice: 1.1045  decode.d2.loss_cls: 0.0460  decode.d2.loss_mask: 0.5202  decode.d2.loss_dice: 1.0958  decode.d3.loss_cls: 0.0562  decode.d3.loss_mask: 0.5022  decode.d3.loss_dice: 1.0665  decode.d4.loss_cls: 0.0612  decode.d4.loss_mask: 0.5020  decode.d4.loss_dice: 1.0897  decode.d5.loss_cls: 0.0568  decode.d5.loss_mask: 0.4998  decode.d5.loss_dice: 1.0640  decode.d6.loss_cls: 0.0651  decode.d6.loss_mask: 0.4986  decode.d6.loss_dice: 1.0418  decode.d7.loss_cls: 0.0600  decode.d7.loss_mask: 0.4992  decode.d7.loss_dice: 1.0507  decode.d8.loss_cls: 0.0529  decode.d8.loss_mask: 0.4966  decode.d8.loss_dice: 1.0669
11/15 21:54:31 - mmengine - INFO - Iter(train) [86100/90000]  base_lr: 5.9312e-06 lr: 5.9312e-07  eta: 0:39:08  time: 0.5995  data_time: 0.0108  memory: 10692  grad_norm: 309.2431  loss: 14.8328  decode.loss_cls: 0.0494  decode.loss_mask: 0.4179  decode.loss_dice: 0.9980  decode.d0.loss_cls: 0.0835  decode.d0.loss_mask: 0.4285  decode.d0.loss_dice: 1.0586  decode.d1.loss_cls: 0.0699  decode.d1.loss_mask: 0.4184  decode.d1.loss_dice: 1.0043  decode.d2.loss_cls: 0.0615  decode.d2.loss_mask: 0.4170  decode.d2.loss_dice: 0.9905  decode.d3.loss_cls: 0.0618  decode.d3.loss_mask: 0.4200  decode.d3.loss_dice: 0.9893  decode.d4.loss_cls: 0.0615  decode.d4.loss_mask: 0.4201  decode.d4.loss_dice: 0.9984  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 0.4196  decode.d5.loss_dice: 1.0054  decode.d6.loss_cls: 0.0658  decode.d6.loss_mask: 0.4175  decode.d6.loss_dice: 0.9901  decode.d7.loss_cls: 0.0625  decode.d7.loss_mask: 0.4203  decode.d7.loss_dice: 0.9920  decode.d8.loss_cls: 0.0582  decode.d8.loss_mask: 0.4186  decode.d8.loss_dice: 0.9689
11/15 21:55:01 - mmengine - INFO - Iter(train) [86150/90000]  base_lr: 5.8627e-06 lr: 5.8627e-07  eta: 0:38:37  time: 0.6018  data_time: 0.0112  memory: 10626  grad_norm: 460.4248  loss: 16.9401  decode.loss_cls: 0.0652  decode.loss_mask: 0.4900  decode.loss_dice: 1.1022  decode.d0.loss_cls: 0.0753  decode.d0.loss_mask: 0.5582  decode.d0.loss_dice: 1.2070  decode.d1.loss_cls: 0.0800  decode.d1.loss_mask: 0.5054  decode.d1.loss_dice: 1.1078  decode.d2.loss_cls: 0.0673  decode.d2.loss_mask: 0.5299  decode.d2.loss_dice: 1.1059  decode.d3.loss_cls: 0.0785  decode.d3.loss_mask: 0.5001  decode.d3.loss_dice: 1.0782  decode.d4.loss_cls: 0.0741  decode.d4.loss_mask: 0.4995  decode.d4.loss_dice: 1.0827  decode.d5.loss_cls: 0.0732  decode.d5.loss_mask: 0.5141  decode.d5.loss_dice: 1.1126  decode.d6.loss_cls: 0.0725  decode.d6.loss_mask: 0.5154  decode.d6.loss_dice: 1.0989  decode.d7.loss_cls: 0.0727  decode.d7.loss_mask: 0.5093  decode.d7.loss_dice: 1.1103  decode.d8.loss_cls: 0.0721  decode.d8.loss_mask: 0.4938  decode.d8.loss_dice: 1.0879
11/15 21:55:31 - mmengine - INFO - Iter(train) [86200/90000]  base_lr: 5.7942e-06 lr: 5.7942e-07  eta: 0:38:07  time: 0.5970  data_time: 0.0108  memory: 10692  grad_norm: 314.4230  loss: 15.4153  decode.loss_cls: 0.0473  decode.loss_mask: 0.5093  decode.loss_dice: 0.9661  decode.d0.loss_cls: 0.0834  decode.d0.loss_mask: 0.5341  decode.d0.loss_dice: 1.0265  decode.d1.loss_cls: 0.0553  decode.d1.loss_mask: 0.5106  decode.d1.loss_dice: 0.9965  decode.d2.loss_cls: 0.0474  decode.d2.loss_mask: 0.5045  decode.d2.loss_dice: 1.0139  decode.d3.loss_cls: 0.0483  decode.d3.loss_mask: 0.5054  decode.d3.loss_dice: 0.9502  decode.d4.loss_cls: 0.0517  decode.d4.loss_mask: 0.5052  decode.d4.loss_dice: 0.9546  decode.d5.loss_cls: 0.0508  decode.d5.loss_mask: 0.5039  decode.d5.loss_dice: 0.9808  decode.d6.loss_cls: 0.0474  decode.d6.loss_mask: 0.5054  decode.d6.loss_dice: 0.9622  decode.d7.loss_cls: 0.0474  decode.d7.loss_mask: 0.5084  decode.d7.loss_dice: 0.9631  decode.d8.loss_cls: 0.0480  decode.d8.loss_mask: 0.5078  decode.d8.loss_dice: 0.9798
11/15 21:56:01 - mmengine - INFO - Iter(train) [86250/90000]  base_lr: 5.7255e-06 lr: 5.7255e-07  eta: 0:37:37  time: 0.5981  data_time: 0.0108  memory: 10742  grad_norm: 269.9940  loss: 15.1498  decode.loss_cls: 0.0622  decode.loss_mask: 0.4511  decode.loss_dice: 0.9462  decode.d0.loss_cls: 0.0933  decode.d0.loss_mask: 0.4654  decode.d0.loss_dice: 1.0383  decode.d1.loss_cls: 0.0753  decode.d1.loss_mask: 0.4499  decode.d1.loss_dice: 1.0086  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.4531  decode.d2.loss_dice: 0.9854  decode.d3.loss_cls: 0.0625  decode.d3.loss_mask: 0.4506  decode.d3.loss_dice: 0.9843  decode.d4.loss_cls: 0.0666  decode.d4.loss_mask: 0.4491  decode.d4.loss_dice: 1.0029  decode.d5.loss_cls: 0.0573  decode.d5.loss_mask: 0.4495  decode.d5.loss_dice: 0.9892  decode.d6.loss_cls: 0.0634  decode.d6.loss_mask: 0.4495  decode.d6.loss_dice: 1.0142  decode.d7.loss_cls: 0.0564  decode.d7.loss_mask: 0.4529  decode.d7.loss_dice: 1.0026  decode.d8.loss_cls: 0.0601  decode.d8.loss_mask: 0.4517  decode.d8.loss_dice: 0.9980
11/15 21:56:31 - mmengine - INFO - Iter(train) [86300/90000]  base_lr: 5.6568e-06 lr: 5.6568e-07  eta: 0:37:07  time: 0.5974  data_time: 0.0106  memory: 10692  grad_norm: 414.3195  loss: 15.8879  decode.loss_cls: 0.0761  decode.loss_mask: 0.5124  decode.loss_dice: 0.9860  decode.d0.loss_cls: 0.1013  decode.d0.loss_mask: 0.5553  decode.d0.loss_dice: 1.0674  decode.d1.loss_cls: 0.0893  decode.d1.loss_mask: 0.5066  decode.d1.loss_dice: 1.0173  decode.d2.loss_cls: 0.0795  decode.d2.loss_mask: 0.5119  decode.d2.loss_dice: 1.0052  decode.d3.loss_cls: 0.0765  decode.d3.loss_mask: 0.5175  decode.d3.loss_dice: 0.9679  decode.d4.loss_cls: 0.0741  decode.d4.loss_mask: 0.5092  decode.d4.loss_dice: 0.9550  decode.d5.loss_cls: 0.0714  decode.d5.loss_mask: 0.5170  decode.d5.loss_dice: 0.9976  decode.d6.loss_cls: 0.0708  decode.d6.loss_mask: 0.5124  decode.d6.loss_dice: 0.9750  decode.d7.loss_cls: 0.0699  decode.d7.loss_mask: 0.5128  decode.d7.loss_dice: 0.9874  decode.d8.loss_cls: 0.0733  decode.d8.loss_mask: 0.5065  decode.d8.loss_dice: 0.9852
11/15 21:57:01 - mmengine - INFO - Iter(train) [86350/90000]  base_lr: 5.5879e-06 lr: 5.5879e-07  eta: 0:36:37  time: 0.6000  data_time: 0.0108  memory: 10692  grad_norm: 311.5944  loss: 15.2401  decode.loss_cls: 0.0336  decode.loss_mask: 0.4957  decode.loss_dice: 0.9794  decode.d0.loss_cls: 0.0575  decode.d0.loss_mask: 0.5127  decode.d0.loss_dice: 1.0444  decode.d1.loss_cls: 0.0479  decode.d1.loss_mask: 0.4915  decode.d1.loss_dice: 1.0132  decode.d2.loss_cls: 0.0296  decode.d2.loss_mask: 0.4922  decode.d2.loss_dice: 1.0173  decode.d3.loss_cls: 0.0366  decode.d3.loss_mask: 0.4895  decode.d3.loss_dice: 0.9684  decode.d4.loss_cls: 0.0385  decode.d4.loss_mask: 0.4845  decode.d4.loss_dice: 0.9726  decode.d5.loss_cls: 0.0383  decode.d5.loss_mask: 0.4847  decode.d5.loss_dice: 0.9712  decode.d6.loss_cls: 0.0406  decode.d6.loss_mask: 0.4874  decode.d6.loss_dice: 0.9858  decode.d7.loss_cls: 0.0384  decode.d7.loss_mask: 0.4977  decode.d7.loss_dice: 0.9783  decode.d8.loss_cls: 0.0386  decode.d8.loss_mask: 0.4913  decode.d8.loss_dice: 0.9829
11/15 21:57:31 - mmengine - INFO - Iter(train) [86400/90000]  base_lr: 5.5190e-06 lr: 5.5190e-07  eta: 0:36:07  time: 0.5973  data_time: 0.0107  memory: 10758  grad_norm: 336.0884  loss: 14.5339  decode.loss_cls: 0.0727  decode.loss_mask: 0.4509  decode.loss_dice: 0.8806  decode.d0.loss_cls: 0.1007  decode.d0.loss_mask: 0.4862  decode.d0.loss_dice: 1.0325  decode.d1.loss_cls: 0.0847  decode.d1.loss_mask: 0.4557  decode.d1.loss_dice: 0.9575  decode.d2.loss_cls: 0.0903  decode.d2.loss_mask: 0.4456  decode.d2.loss_dice: 0.8940  decode.d3.loss_cls: 0.0657  decode.d3.loss_mask: 0.4459  decode.d3.loss_dice: 0.9087  decode.d4.loss_cls: 0.0726  decode.d4.loss_mask: 0.4526  decode.d4.loss_dice: 0.9188  decode.d5.loss_cls: 0.0668  decode.d5.loss_mask: 0.4513  decode.d5.loss_dice: 0.9053  decode.d6.loss_cls: 0.0699  decode.d6.loss_mask: 0.4531  decode.d6.loss_dice: 0.8863  decode.d7.loss_cls: 0.0713  decode.d7.loss_mask: 0.4533  decode.d7.loss_dice: 0.9099  decode.d8.loss_cls: 0.0710  decode.d8.loss_mask: 0.4562  decode.d8.loss_dice: 0.9240
11/15 21:58:01 - mmengine - INFO - Iter(train) [86450/90000]  base_lr: 5.4499e-06 lr: 5.4499e-07  eta: 0:35:37  time: 0.5983  data_time: 0.0108  memory: 10675  grad_norm: 197.7539  loss: 15.3885  decode.loss_cls: 0.0621  decode.loss_mask: 0.3835  decode.loss_dice: 1.0894  decode.d0.loss_cls: 0.0644  decode.d0.loss_mask: 0.4025  decode.d0.loss_dice: 1.1871  decode.d1.loss_cls: 0.0536  decode.d1.loss_mask: 0.3880  decode.d1.loss_dice: 1.1275  decode.d2.loss_cls: 0.0479  decode.d2.loss_mask: 0.3895  decode.d2.loss_dice: 1.1122  decode.d3.loss_cls: 0.0568  decode.d3.loss_mask: 0.3829  decode.d3.loss_dice: 1.0709  decode.d4.loss_cls: 0.0637  decode.d4.loss_mask: 0.3727  decode.d4.loss_dice: 1.0540  decode.d5.loss_cls: 0.0630  decode.d5.loss_mask: 0.3835  decode.d5.loss_dice: 1.0780  decode.d6.loss_cls: 0.0607  decode.d6.loss_mask: 0.3840  decode.d6.loss_dice: 1.0727  decode.d7.loss_cls: 0.0592  decode.d7.loss_mask: 0.3854  decode.d7.loss_dice: 1.0644  decode.d8.loss_cls: 0.0602  decode.d8.loss_mask: 0.3893  decode.d8.loss_dice: 1.0793
11/15 21:58:31 - mmengine - INFO - Iter(train) [86500/90000]  base_lr: 5.3808e-06 lr: 5.3808e-07  eta: 0:35:07  time: 0.5981  data_time: 0.0106  memory: 10675  grad_norm: 289.6545  loss: 15.1963  decode.loss_cls: 0.0569  decode.loss_mask: 0.3926  decode.loss_dice: 1.0305  decode.d0.loss_cls: 0.0899  decode.d0.loss_mask: 0.4182  decode.d0.loss_dice: 1.1600  decode.d1.loss_cls: 0.0802  decode.d1.loss_mask: 0.4100  decode.d1.loss_dice: 1.0865  decode.d2.loss_cls: 0.0675  decode.d2.loss_mask: 0.3975  decode.d2.loss_dice: 1.0589  decode.d3.loss_cls: 0.0611  decode.d3.loss_mask: 0.3911  decode.d3.loss_dice: 1.0437  decode.d4.loss_cls: 0.0647  decode.d4.loss_mask: 0.3930  decode.d4.loss_dice: 1.0193  decode.d5.loss_cls: 0.0653  decode.d5.loss_mask: 0.3915  decode.d5.loss_dice: 1.0351  decode.d6.loss_cls: 0.0655  decode.d6.loss_mask: 0.3938  decode.d6.loss_dice: 1.0479  decode.d7.loss_cls: 0.0639  decode.d7.loss_mask: 0.3903  decode.d7.loss_dice: 1.0420  decode.d8.loss_cls: 0.0676  decode.d8.loss_mask: 0.3892  decode.d8.loss_dice: 1.0225
11/15 21:59:01 - mmengine - INFO - Iter(train) [86550/90000]  base_lr: 5.3116e-06 lr: 5.3116e-07  eta: 0:34:37  time: 0.5976  data_time: 0.0109  memory: 10675  grad_norm: 441.7712  loss: 13.7374  decode.loss_cls: 0.0574  decode.loss_mask: 0.4535  decode.loss_dice: 0.8207  decode.d0.loss_cls: 0.0882  decode.d0.loss_mask: 0.5005  decode.d0.loss_dice: 0.9166  decode.d1.loss_cls: 0.0650  decode.d1.loss_mask: 0.4589  decode.d1.loss_dice: 0.8776  decode.d2.loss_cls: 0.0734  decode.d2.loss_mask: 0.4522  decode.d2.loss_dice: 0.8363  decode.d3.loss_cls: 0.0577  decode.d3.loss_mask: 0.4478  decode.d3.loss_dice: 0.8326  decode.d4.loss_cls: 0.0598  decode.d4.loss_mask: 0.4582  decode.d4.loss_dice: 0.8563  decode.d5.loss_cls: 0.0549  decode.d5.loss_mask: 0.4541  decode.d5.loss_dice: 0.8357  decode.d6.loss_cls: 0.0522  decode.d6.loss_mask: 0.4584  decode.d6.loss_dice: 0.8379  decode.d7.loss_cls: 0.0553  decode.d7.loss_mask: 0.4561  decode.d7.loss_dice: 0.8457  decode.d8.loss_cls: 0.0473  decode.d8.loss_mask: 0.4558  decode.d8.loss_dice: 0.8711
11/15 21:59:31 - mmengine - INFO - Iter(train) [86600/90000]  base_lr: 5.2422e-06 lr: 5.2422e-07  eta: 0:34:06  time: 0.6020  data_time: 0.0121  memory: 10692  grad_norm: 368.9231  loss: 15.7651  decode.loss_cls: 0.0667  decode.loss_mask: 0.4784  decode.loss_dice: 1.0279  decode.d0.loss_cls: 0.0926  decode.d0.loss_mask: 0.5056  decode.d0.loss_dice: 1.0928  decode.d1.loss_cls: 0.0874  decode.d1.loss_mask: 0.4846  decode.d1.loss_dice: 1.0473  decode.d2.loss_cls: 0.0730  decode.d2.loss_mask: 0.4778  decode.d2.loss_dice: 1.0350  decode.d3.loss_cls: 0.0688  decode.d3.loss_mask: 0.4711  decode.d3.loss_dice: 1.0003  decode.d4.loss_cls: 0.0741  decode.d4.loss_mask: 0.4728  decode.d4.loss_dice: 0.9961  decode.d5.loss_cls: 0.0705  decode.d5.loss_mask: 0.4753  decode.d5.loss_dice: 0.9866  decode.d6.loss_cls: 0.0671  decode.d6.loss_mask: 0.4747  decode.d6.loss_dice: 1.0070  decode.d7.loss_cls: 0.0678  decode.d7.loss_mask: 0.4753  decode.d7.loss_dice: 1.0085  decode.d8.loss_cls: 0.0799  decode.d8.loss_mask: 0.4729  decode.d8.loss_dice: 1.0273
11/15 22:00:01 - mmengine - INFO - Iter(train) [86650/90000]  base_lr: 5.1728e-06 lr: 5.1728e-07  eta: 0:33:36  time: 0.5986  data_time: 0.0108  memory: 10675  grad_norm: 260.7013  loss: 16.0865  decode.loss_cls: 0.0736  decode.loss_mask: 0.4174  decode.loss_dice: 1.0994  decode.d0.loss_cls: 0.0865  decode.d0.loss_mask: 0.4360  decode.d0.loss_dice: 1.1815  decode.d1.loss_cls: 0.0620  decode.d1.loss_mask: 0.4291  decode.d1.loss_dice: 1.1249  decode.d2.loss_cls: 0.0634  decode.d2.loss_mask: 0.4250  decode.d2.loss_dice: 1.1474  decode.d3.loss_cls: 0.0540  decode.d3.loss_mask: 0.4307  decode.d3.loss_dice: 1.1224  decode.d4.loss_cls: 0.0573  decode.d4.loss_mask: 0.4271  decode.d4.loss_dice: 1.1083  decode.d5.loss_cls: 0.0587  decode.d5.loss_mask: 0.4250  decode.d5.loss_dice: 1.1048  decode.d6.loss_cls: 0.0692  decode.d6.loss_mask: 0.4231  decode.d6.loss_dice: 1.1025  decode.d7.loss_cls: 0.0682  decode.d7.loss_mask: 0.4170  decode.d7.loss_dice: 1.0872  decode.d8.loss_cls: 0.0556  decode.d8.loss_mask: 0.4236  decode.d8.loss_dice: 1.1057
11/15 22:00:31 - mmengine - INFO - Iter(train) [86700/90000]  base_lr: 5.1033e-06 lr: 5.1033e-07  eta: 0:33:06  time: 0.5984  data_time: 0.0107  memory: 10656  grad_norm: 802.1336  loss: 16.9780  decode.loss_cls: 0.0704  decode.loss_mask: 0.5085  decode.loss_dice: 1.0940  decode.d0.loss_cls: 0.0748  decode.d0.loss_mask: 0.5549  decode.d0.loss_dice: 1.2344  decode.d1.loss_cls: 0.0833  decode.d1.loss_mask: 0.5143  decode.d1.loss_dice: 1.1110  decode.d2.loss_cls: 0.0649  decode.d2.loss_mask: 0.5193  decode.d2.loss_dice: 1.1207  decode.d3.loss_cls: 0.0743  decode.d3.loss_mask: 0.5134  decode.d3.loss_dice: 1.0788  decode.d4.loss_cls: 0.0784  decode.d4.loss_mask: 0.5123  decode.d4.loss_dice: 1.0924  decode.d5.loss_cls: 0.0717  decode.d5.loss_mask: 0.5115  decode.d5.loss_dice: 1.0884  decode.d6.loss_cls: 0.0745  decode.d6.loss_mask: 0.5072  decode.d6.loss_dice: 1.0713  decode.d7.loss_cls: 0.0714  decode.d7.loss_mask: 0.5086  decode.d7.loss_dice: 1.0845  decode.d8.loss_cls: 0.0674  decode.d8.loss_mask: 0.5088  decode.d8.loss_dice: 1.1126
11/15 22:01:01 - mmengine - INFO - Iter(train) [86750/90000]  base_lr: 5.0336e-06 lr: 5.0336e-07  eta: 0:32:36  time: 0.5982  data_time: 0.0109  memory: 10692  grad_norm: 376.1714  loss: 14.6654  decode.loss_cls: 0.0530  decode.loss_mask: 0.4226  decode.loss_dice: 0.9392  decode.d0.loss_cls: 0.0733  decode.d0.loss_mask: 0.4557  decode.d0.loss_dice: 1.0826  decode.d1.loss_cls: 0.0581  decode.d1.loss_mask: 0.4345  decode.d1.loss_dice: 1.0216  decode.d2.loss_cls: 0.0577  decode.d2.loss_mask: 0.4249  decode.d2.loss_dice: 0.9844  decode.d3.loss_cls: 0.0553  decode.d3.loss_mask: 0.4259  decode.d3.loss_dice: 0.9756  decode.d4.loss_cls: 0.0605  decode.d4.loss_mask: 0.4233  decode.d4.loss_dice: 0.9692  decode.d5.loss_cls: 0.0565  decode.d5.loss_mask: 0.4252  decode.d5.loss_dice: 0.9601  decode.d6.loss_cls: 0.0533  decode.d6.loss_mask: 0.4261  decode.d6.loss_dice: 0.9640  decode.d7.loss_cls: 0.0527  decode.d7.loss_mask: 0.4232  decode.d7.loss_dice: 0.9691  decode.d8.loss_cls: 0.0517  decode.d8.loss_mask: 0.4237  decode.d8.loss_dice: 0.9425
11/15 22:01:31 - mmengine - INFO - Iter(train) [86800/90000]  base_lr: 4.9639e-06 lr: 4.9639e-07  eta: 0:32:06  time: 0.5987  data_time: 0.0109  memory: 10675  grad_norm: 462.0940  loss: 15.5936  decode.loss_cls: 0.0472  decode.loss_mask: 0.5693  decode.loss_dice: 0.9189  decode.d0.loss_cls: 0.0639  decode.d0.loss_mask: 0.6130  decode.d0.loss_dice: 1.0010  decode.d1.loss_cls: 0.0440  decode.d1.loss_mask: 0.5836  decode.d1.loss_dice: 0.9844  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 0.5748  decode.d2.loss_dice: 0.9353  decode.d3.loss_cls: 0.0539  decode.d3.loss_mask: 0.5557  decode.d3.loss_dice: 0.8996  decode.d4.loss_cls: 0.0507  decode.d4.loss_mask: 0.5542  decode.d4.loss_dice: 0.9165  decode.d5.loss_cls: 0.0474  decode.d5.loss_mask: 0.5665  decode.d5.loss_dice: 0.9124  decode.d6.loss_cls: 0.0480  decode.d6.loss_mask: 0.5696  decode.d6.loss_dice: 0.9273  decode.d7.loss_cls: 0.0447  decode.d7.loss_mask: 0.5750  decode.d7.loss_dice: 0.9300  decode.d8.loss_cls: 0.0448  decode.d8.loss_mask: 0.5667  decode.d8.loss_dice: 0.9449
11/15 22:02:01 - mmengine - INFO - Iter(train) [86850/90000]  base_lr: 4.8940e-06 lr: 4.8940e-07  eta: 0:31:36  time: 0.5988  data_time: 0.0106  memory: 10728  grad_norm: 337.1000  loss: 14.8360  decode.loss_cls: 0.0620  decode.loss_mask: 0.4689  decode.loss_dice: 0.9309  decode.d0.loss_cls: 0.0937  decode.d0.loss_mask: 0.4794  decode.d0.loss_dice: 0.9945  decode.d1.loss_cls: 0.0610  decode.d1.loss_mask: 0.4663  decode.d1.loss_dice: 0.9543  decode.d2.loss_cls: 0.0515  decode.d2.loss_mask: 0.4742  decode.d2.loss_dice: 0.9863  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.4593  decode.d3.loss_dice: 0.9594  decode.d4.loss_cls: 0.0508  decode.d4.loss_mask: 0.4639  decode.d4.loss_dice: 0.9529  decode.d5.loss_cls: 0.0577  decode.d5.loss_mask: 0.4627  decode.d5.loss_dice: 0.9442  decode.d6.loss_cls: 0.0471  decode.d6.loss_mask: 0.4710  decode.d6.loss_dice: 0.9570  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.4714  decode.d7.loss_dice: 0.9489  decode.d8.loss_cls: 0.0444  decode.d8.loss_mask: 0.4648  decode.d8.loss_dice: 0.9489
11/15 22:02:30 - mmengine - INFO - Iter(train) [86900/90000]  base_lr: 4.8240e-06 lr: 4.8240e-07  eta: 0:31:06  time: 0.5975  data_time: 0.0105  memory: 10692  grad_norm: 380.2950  loss: 14.4720  decode.loss_cls: 0.0585  decode.loss_mask: 0.3923  decode.loss_dice: 0.9594  decode.d0.loss_cls: 0.0784  decode.d0.loss_mask: 0.4191  decode.d0.loss_dice: 1.1023  decode.d1.loss_cls: 0.0527  decode.d1.loss_mask: 0.4031  decode.d1.loss_dice: 1.0279  decode.d2.loss_cls: 0.0633  decode.d2.loss_mask: 0.4018  decode.d2.loss_dice: 0.9828  decode.d3.loss_cls: 0.0502  decode.d3.loss_mask: 0.4054  decode.d3.loss_dice: 0.9572  decode.d4.loss_cls: 0.0611  decode.d4.loss_mask: 0.3971  decode.d4.loss_dice: 0.9454  decode.d5.loss_cls: 0.0505  decode.d5.loss_mask: 0.3982  decode.d5.loss_dice: 0.9792  decode.d6.loss_cls: 0.0570  decode.d6.loss_mask: 0.4033  decode.d6.loss_dice: 0.9707  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.4013  decode.d7.loss_dice: 0.9967  decode.d8.loss_cls: 0.0510  decode.d8.loss_mask: 0.3983  decode.d8.loss_dice: 0.9562
11/15 22:03:00 - mmengine - INFO - Iter(train) [86950/90000]  base_lr: 4.7540e-06 lr: 4.7540e-07  eta: 0:30:36  time: 0.6015  data_time: 0.0110  memory: 10675  grad_norm: 288.4200  loss: 13.8640  decode.loss_cls: 0.0536  decode.loss_mask: 0.4402  decode.loss_dice: 0.8795  decode.d0.loss_cls: 0.0794  decode.d0.loss_mask: 0.4541  decode.d0.loss_dice: 0.9662  decode.d1.loss_cls: 0.0658  decode.d1.loss_mask: 0.4442  decode.d1.loss_dice: 0.9035  decode.d2.loss_cls: 0.0617  decode.d2.loss_mask: 0.4382  decode.d2.loss_dice: 0.8633  decode.d3.loss_cls: 0.0564  decode.d3.loss_mask: 0.4397  decode.d3.loss_dice: 0.8588  decode.d4.loss_cls: 0.0501  decode.d4.loss_mask: 0.4438  decode.d4.loss_dice: 0.8989  decode.d5.loss_cls: 0.0540  decode.d5.loss_mask: 0.4411  decode.d5.loss_dice: 0.8677  decode.d6.loss_cls: 0.0573  decode.d6.loss_mask: 0.4431  decode.d6.loss_dice: 0.8812  decode.d7.loss_cls: 0.0656  decode.d7.loss_mask: 0.4249  decode.d7.loss_dice: 0.8453  decode.d8.loss_cls: 0.0569  decode.d8.loss_mask: 0.4416  decode.d8.loss_dice: 0.8880
11/15 22:03:30 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 22:03:30 - mmengine - INFO - Iter(train) [87000/90000]  base_lr: 4.6838e-06 lr: 4.6838e-07  eta: 0:30:06  time: 0.5979  data_time: 0.0108  memory: 10692  grad_norm: 320.3772  loss: 14.5244  decode.loss_cls: 0.0435  decode.loss_mask: 0.4403  decode.loss_dice: 0.9551  decode.d0.loss_cls: 0.0811  decode.d0.loss_mask: 0.4644  decode.d0.loss_dice: 1.0189  decode.d1.loss_cls: 0.0630  decode.d1.loss_mask: 0.4454  decode.d1.loss_dice: 0.9554  decode.d2.loss_cls: 0.0499  decode.d2.loss_mask: 0.4447  decode.d2.loss_dice: 0.9620  decode.d3.loss_cls: 0.0438  decode.d3.loss_mask: 0.4382  decode.d3.loss_dice: 0.9478  decode.d4.loss_cls: 0.0393  decode.d4.loss_mask: 0.4414  decode.d4.loss_dice: 0.9474  decode.d5.loss_cls: 0.0433  decode.d5.loss_mask: 0.4341  decode.d5.loss_dice: 0.9421  decode.d6.loss_cls: 0.0391  decode.d6.loss_mask: 0.4431  decode.d6.loss_dice: 0.9597  decode.d7.loss_cls: 0.0438  decode.d7.loss_mask: 0.4404  decode.d7.loss_dice: 0.9491  decode.d8.loss_cls: 0.0397  decode.d8.loss_mask: 0.4479  decode.d8.loss_dice: 0.9605
11/15 22:04:00 - mmengine - INFO - Iter(train) [87050/90000]  base_lr: 4.6135e-06 lr: 4.6135e-07  eta: 0:29:36  time: 0.5980  data_time: 0.0107  memory: 10713  grad_norm: 234.6558  loss: 14.8672  decode.loss_cls: 0.0716  decode.loss_mask: 0.4343  decode.loss_dice: 0.9861  decode.d0.loss_cls: 0.0862  decode.d0.loss_mask: 0.4531  decode.d0.loss_dice: 1.0808  decode.d1.loss_cls: 0.0761  decode.d1.loss_mask: 0.4314  decode.d1.loss_dice: 0.9714  decode.d2.loss_cls: 0.0762  decode.d2.loss_mask: 0.4398  decode.d2.loss_dice: 0.9251  decode.d3.loss_cls: 0.0674  decode.d3.loss_mask: 0.4346  decode.d3.loss_dice: 0.9627  decode.d4.loss_cls: 0.0725  decode.d4.loss_mask: 0.4350  decode.d4.loss_dice: 0.9912  decode.d5.loss_cls: 0.0685  decode.d5.loss_mask: 0.4426  decode.d5.loss_dice: 0.9630  decode.d6.loss_cls: 0.0722  decode.d6.loss_mask: 0.4379  decode.d6.loss_dice: 0.9515  decode.d7.loss_cls: 0.0714  decode.d7.loss_mask: 0.4393  decode.d7.loss_dice: 0.9663  decode.d8.loss_cls: 0.0753  decode.d8.loss_mask: 0.4390  decode.d8.loss_dice: 0.9446
11/15 22:04:30 - mmengine - INFO - Iter(train) [87100/90000]  base_lr: 4.5430e-06 lr: 4.5430e-07  eta: 0:29:05  time: 0.5984  data_time: 0.0107  memory: 10675  grad_norm: 302.9136  loss: 14.6681  decode.loss_cls: 0.0552  decode.loss_mask: 0.4475  decode.loss_dice: 0.9470  decode.d0.loss_cls: 0.0802  decode.d0.loss_mask: 0.4665  decode.d0.loss_dice: 1.0089  decode.d1.loss_cls: 0.0588  decode.d1.loss_mask: 0.4544  decode.d1.loss_dice: 0.9540  decode.d2.loss_cls: 0.0525  decode.d2.loss_mask: 0.4477  decode.d2.loss_dice: 0.9830  decode.d3.loss_cls: 0.0657  decode.d3.loss_mask: 0.4428  decode.d3.loss_dice: 0.9460  decode.d4.loss_cls: 0.0524  decode.d4.loss_mask: 0.4503  decode.d4.loss_dice: 0.9617  decode.d5.loss_cls: 0.0560  decode.d5.loss_mask: 0.4499  decode.d5.loss_dice: 0.9639  decode.d6.loss_cls: 0.0630  decode.d6.loss_mask: 0.4455  decode.d6.loss_dice: 0.9578  decode.d7.loss_cls: 0.0593  decode.d7.loss_mask: 0.4496  decode.d7.loss_dice: 0.9202  decode.d8.loss_cls: 0.0688  decode.d8.loss_mask: 0.4439  decode.d8.loss_dice: 0.9160
11/15 22:05:00 - mmengine - INFO - Iter(train) [87150/90000]  base_lr: 4.4725e-06 lr: 4.4725e-07  eta: 0:28:35  time: 0.6013  data_time: 0.0108  memory: 10713  grad_norm: 263.8845  loss: 14.0722  decode.loss_cls: 0.0508  decode.loss_mask: 0.3647  decode.loss_dice: 0.9696  decode.d0.loss_cls: 0.0852  decode.d0.loss_mask: 0.3663  decode.d0.loss_dice: 1.0523  decode.d1.loss_cls: 0.0723  decode.d1.loss_mask: 0.3642  decode.d1.loss_dice: 1.0007  decode.d2.loss_cls: 0.0654  decode.d2.loss_mask: 0.3615  decode.d2.loss_dice: 1.0011  decode.d3.loss_cls: 0.0574  decode.d3.loss_mask: 0.3596  decode.d3.loss_dice: 0.9573  decode.d4.loss_cls: 0.0429  decode.d4.loss_mask: 0.3671  decode.d4.loss_dice: 0.9546  decode.d5.loss_cls: 0.0454  decode.d5.loss_mask: 0.3656  decode.d5.loss_dice: 0.9745  decode.d6.loss_cls: 0.0534  decode.d6.loss_mask: 0.3661  decode.d6.loss_dice: 0.9981  decode.d7.loss_cls: 0.0429  decode.d7.loss_mask: 0.3674  decode.d7.loss_dice: 0.9810  decode.d8.loss_cls: 0.0459  decode.d8.loss_mask: 0.3620  decode.d8.loss_dice: 0.9769
11/15 22:05:31 - mmengine - INFO - Iter(train) [87200/90000]  base_lr: 4.4018e-06 lr: 4.4018e-07  eta: 0:28:05  time: 0.5975  data_time: 0.0105  memory: 10692  grad_norm: 2114.7910  loss: 14.8634  decode.loss_cls: 0.0492  decode.loss_mask: 0.4542  decode.loss_dice: 0.9867  decode.d0.loss_cls: 0.0929  decode.d0.loss_mask: 0.4780  decode.d0.loss_dice: 1.0424  decode.d1.loss_cls: 0.0504  decode.d1.loss_mask: 0.4588  decode.d1.loss_dice: 0.9850  decode.d2.loss_cls: 0.0501  decode.d2.loss_mask: 0.4603  decode.d2.loss_dice: 0.9577  decode.d3.loss_cls: 0.0502  decode.d3.loss_mask: 0.4574  decode.d3.loss_dice: 0.9721  decode.d4.loss_cls: 0.0536  decode.d4.loss_mask: 0.4530  decode.d4.loss_dice: 0.9577  decode.d5.loss_cls: 0.0539  decode.d5.loss_mask: 0.4530  decode.d5.loss_dice: 0.9495  decode.d6.loss_cls: 0.0473  decode.d6.loss_mask: 0.4583  decode.d6.loss_dice: 0.9505  decode.d7.loss_cls: 0.0384  decode.d7.loss_mask: 0.4579  decode.d7.loss_dice: 0.9706  decode.d8.loss_cls: 0.0480  decode.d8.loss_mask: 0.4552  decode.d8.loss_dice: 0.9712
11/15 22:06:01 - mmengine - INFO - Iter(train) [87250/90000]  base_lr: 4.3310e-06 lr: 4.3310e-07  eta: 0:27:35  time: 0.6003  data_time: 0.0115  memory: 10675  grad_norm: 231.7993  loss: 14.3543  decode.loss_cls: 0.0651  decode.loss_mask: 0.4207  decode.loss_dice: 0.9368  decode.d0.loss_cls: 0.1056  decode.d0.loss_mask: 0.4452  decode.d0.loss_dice: 1.0066  decode.d1.loss_cls: 0.0737  decode.d1.loss_mask: 0.4250  decode.d1.loss_dice: 0.9320  decode.d2.loss_cls: 0.0673  decode.d2.loss_mask: 0.4229  decode.d2.loss_dice: 0.9456  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 0.4227  decode.d3.loss_dice: 0.9380  decode.d4.loss_cls: 0.0597  decode.d4.loss_mask: 0.4205  decode.d4.loss_dice: 0.9072  decode.d5.loss_cls: 0.0662  decode.d5.loss_mask: 0.4236  decode.d5.loss_dice: 0.9393  decode.d6.loss_cls: 0.0566  decode.d6.loss_mask: 0.4185  decode.d6.loss_dice: 0.9282  decode.d7.loss_cls: 0.0793  decode.d7.loss_mask: 0.4211  decode.d7.loss_dice: 0.9511  decode.d8.loss_cls: 0.0548  decode.d8.loss_mask: 0.4238  decode.d8.loss_dice: 0.9302
11/15 22:06:31 - mmengine - INFO - Iter(train) [87300/90000]  base_lr: 4.2600e-06 lr: 4.2600e-07  eta: 0:27:05  time: 0.5980  data_time: 0.0106  memory: 10692  grad_norm: 271.3941  loss: 13.8889  decode.loss_cls: 0.0725  decode.loss_mask: 0.4326  decode.loss_dice: 0.8672  decode.d0.loss_cls: 0.0914  decode.d0.loss_mask: 0.4661  decode.d0.loss_dice: 0.9638  decode.d1.loss_cls: 0.0729  decode.d1.loss_mask: 0.4579  decode.d1.loss_dice: 0.8839  decode.d2.loss_cls: 0.0716  decode.d2.loss_mask: 0.4437  decode.d2.loss_dice: 0.8923  decode.d3.loss_cls: 0.0770  decode.d3.loss_mask: 0.4377  decode.d3.loss_dice: 0.8562  decode.d4.loss_cls: 0.0699  decode.d4.loss_mask: 0.4364  decode.d4.loss_dice: 0.8631  decode.d5.loss_cls: 0.0694  decode.d5.loss_mask: 0.4331  decode.d5.loss_dice: 0.8596  decode.d6.loss_cls: 0.0654  decode.d6.loss_mask: 0.4342  decode.d6.loss_dice: 0.8748  decode.d7.loss_cls: 0.0692  decode.d7.loss_mask: 0.4323  decode.d7.loss_dice: 0.8375  decode.d8.loss_cls: 0.0696  decode.d8.loss_mask: 0.4334  decode.d8.loss_dice: 0.8542
11/15 22:07:01 - mmengine - INFO - Iter(train) [87350/90000]  base_lr: 4.1890e-06 lr: 4.1890e-07  eta: 0:26:35  time: 0.5995  data_time: 0.0105  memory: 10675  grad_norm: 292.8096  loss: 15.3574  decode.loss_cls: 0.1014  decode.loss_mask: 0.3793  decode.loss_dice: 1.0334  decode.d0.loss_cls: 0.1316  decode.d0.loss_mask: 0.3904  decode.d0.loss_dice: 1.1518  decode.d1.loss_cls: 0.0972  decode.d1.loss_mask: 0.3866  decode.d1.loss_dice: 1.0895  decode.d2.loss_cls: 0.0943  decode.d2.loss_mask: 0.3783  decode.d2.loss_dice: 1.0342  decode.d3.loss_cls: 0.0953  decode.d3.loss_mask: 0.3772  decode.d3.loss_dice: 1.0404  decode.d4.loss_cls: 0.0882  decode.d4.loss_mask: 0.3824  decode.d4.loss_dice: 1.0604  decode.d5.loss_cls: 0.0890  decode.d5.loss_mask: 0.3773  decode.d5.loss_dice: 1.0424  decode.d6.loss_cls: 0.0937  decode.d6.loss_mask: 0.3769  decode.d6.loss_dice: 1.0490  decode.d7.loss_cls: 0.0965  decode.d7.loss_mask: 0.3838  decode.d7.loss_dice: 1.0422  decode.d8.loss_cls: 0.0965  decode.d8.loss_mask: 0.3782  decode.d8.loss_dice: 1.0199
11/15 22:07:31 - mmengine - INFO - Iter(train) [87400/90000]  base_lr: 4.1178e-06 lr: 4.1178e-07  eta: 0:26:05  time: 0.5981  data_time: 0.0107  memory: 10641  grad_norm: 313.7244  loss: 14.1812  decode.loss_cls: 0.0636  decode.loss_mask: 0.3902  decode.loss_dice: 0.9426  decode.d0.loss_cls: 0.0816  decode.d0.loss_mask: 0.4067  decode.d0.loss_dice: 1.0397  decode.d1.loss_cls: 0.0750  decode.d1.loss_mask: 0.4057  decode.d1.loss_dice: 0.9553  decode.d2.loss_cls: 0.0650  decode.d2.loss_mask: 0.3911  decode.d2.loss_dice: 0.9449  decode.d3.loss_cls: 0.0667  decode.d3.loss_mask: 0.3869  decode.d3.loss_dice: 0.9616  decode.d4.loss_cls: 0.0702  decode.d4.loss_mask: 0.3855  decode.d4.loss_dice: 0.9288  decode.d5.loss_cls: 0.0726  decode.d5.loss_mask: 0.3891  decode.d5.loss_dice: 0.9559  decode.d6.loss_cls: 0.0667  decode.d6.loss_mask: 0.3875  decode.d6.loss_dice: 0.9453  decode.d7.loss_cls: 0.0664  decode.d7.loss_mask: 0.3912  decode.d7.loss_dice: 0.9529  decode.d8.loss_cls: 0.0598  decode.d8.loss_mask: 0.3906  decode.d8.loss_dice: 0.9421
11/15 22:08:01 - mmengine - INFO - Iter(train) [87450/90000]  base_lr: 4.0464e-06 lr: 4.0464e-07  eta: 0:25:35  time: 0.5972  data_time: 0.0108  memory: 10692  grad_norm: 578.0489  loss: 14.2343  decode.loss_cls: 0.0530  decode.loss_mask: 0.4719  decode.loss_dice: 0.8502  decode.d0.loss_cls: 0.0853  decode.d0.loss_mask: 0.4788  decode.d0.loss_dice: 0.9367  decode.d1.loss_cls: 0.0722  decode.d1.loss_mask: 0.5095  decode.d1.loss_dice: 0.8792  decode.d2.loss_cls: 0.0671  decode.d2.loss_mask: 0.5063  decode.d2.loss_dice: 0.8771  decode.d3.loss_cls: 0.0488  decode.d3.loss_mask: 0.4927  decode.d3.loss_dice: 0.8840  decode.d4.loss_cls: 0.0548  decode.d4.loss_mask: 0.4992  decode.d4.loss_dice: 0.8408  decode.d5.loss_cls: 0.0410  decode.d5.loss_mask: 0.5022  decode.d5.loss_dice: 0.8563  decode.d6.loss_cls: 0.0428  decode.d6.loss_mask: 0.5010  decode.d6.loss_dice: 0.8706  decode.d7.loss_cls: 0.0462  decode.d7.loss_mask: 0.5049  decode.d7.loss_dice: 0.8551  decode.d8.loss_cls: 0.0491  decode.d8.loss_mask: 0.5002  decode.d8.loss_dice: 0.8575
11/15 22:08:31 - mmengine - INFO - Iter(train) [87500/90000]  base_lr: 3.9750e-06 lr: 3.9750e-07  eta: 0:25:05  time: 0.5990  data_time: 0.0107  memory: 10692  grad_norm: 448.8185  loss: 15.0410  decode.loss_cls: 0.0798  decode.loss_mask: 0.4254  decode.loss_dice: 0.9806  decode.d0.loss_cls: 0.1115  decode.d0.loss_mask: 0.4486  decode.d0.loss_dice: 1.0621  decode.d1.loss_cls: 0.0983  decode.d1.loss_mask: 0.4282  decode.d1.loss_dice: 0.9952  decode.d2.loss_cls: 0.0839  decode.d2.loss_mask: 0.4283  decode.d2.loss_dice: 0.9856  decode.d3.loss_cls: 0.0831  decode.d3.loss_mask: 0.4278  decode.d3.loss_dice: 0.9703  decode.d4.loss_cls: 0.0899  decode.d4.loss_mask: 0.4293  decode.d4.loss_dice: 0.9745  decode.d5.loss_cls: 0.0824  decode.d5.loss_mask: 0.4273  decode.d5.loss_dice: 0.9615  decode.d6.loss_cls: 0.0817  decode.d6.loss_mask: 0.4236  decode.d6.loss_dice: 0.9851  decode.d7.loss_cls: 0.0867  decode.d7.loss_mask: 0.4266  decode.d7.loss_dice: 0.9840  decode.d8.loss_cls: 0.0821  decode.d8.loss_mask: 0.4251  decode.d8.loss_dice: 0.9726
11/15 22:09:01 - mmengine - INFO - Iter(train) [87550/90000]  base_lr: 3.9033e-06 lr: 3.9033e-07  eta: 0:24:34  time: 0.6013  data_time: 0.0108  memory: 10713  grad_norm: 455.3380  loss: 14.0655  decode.loss_cls: 0.0587  decode.loss_mask: 0.4017  decode.loss_dice: 0.9470  decode.d0.loss_cls: 0.0978  decode.d0.loss_mask: 0.4219  decode.d0.loss_dice: 0.9663  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.3976  decode.d1.loss_dice: 0.9598  decode.d2.loss_cls: 0.0456  decode.d2.loss_mask: 0.3982  decode.d2.loss_dice: 0.9572  decode.d3.loss_cls: 0.0369  decode.d3.loss_mask: 0.3989  decode.d3.loss_dice: 0.9258  decode.d4.loss_cls: 0.0429  decode.d4.loss_mask: 0.3985  decode.d4.loss_dice: 0.9646  decode.d5.loss_cls: 0.0396  decode.d5.loss_mask: 0.4009  decode.d5.loss_dice: 0.9715  decode.d6.loss_cls: 0.0383  decode.d6.loss_mask: 0.4047  decode.d6.loss_dice: 0.9633  decode.d7.loss_cls: 0.0449  decode.d7.loss_mask: 0.3993  decode.d7.loss_dice: 0.9321  decode.d8.loss_cls: 0.0430  decode.d8.loss_mask: 0.4012  decode.d8.loss_dice: 0.9443
11/15 22:09:31 - mmengine - INFO - Iter(train) [87600/90000]  base_lr: 3.8316e-06 lr: 3.8316e-07  eta: 0:24:04  time: 0.5976  data_time: 0.0106  memory: 10675  grad_norm: 376.3194  loss: 12.5634  decode.loss_cls: 0.0442  decode.loss_mask: 0.3913  decode.loss_dice: 0.7966  decode.d0.loss_cls: 0.0782  decode.d0.loss_mask: 0.4394  decode.d0.loss_dice: 0.8461  decode.d1.loss_cls: 0.0595  decode.d1.loss_mask: 0.3961  decode.d1.loss_dice: 0.8286  decode.d2.loss_cls: 0.0440  decode.d2.loss_mask: 0.3875  decode.d2.loss_dice: 0.7975  decode.d3.loss_cls: 0.0354  decode.d3.loss_mask: 0.3930  decode.d3.loss_dice: 0.8019  decode.d4.loss_cls: 0.0465  decode.d4.loss_mask: 0.3912  decode.d4.loss_dice: 0.8073  decode.d5.loss_cls: 0.0426  decode.d5.loss_mask: 0.3927  decode.d5.loss_dice: 0.8091  decode.d6.loss_cls: 0.0434  decode.d6.loss_mask: 0.3980  decode.d6.loss_dice: 0.8080  decode.d7.loss_cls: 0.0479  decode.d7.loss_mask: 0.3905  decode.d7.loss_dice: 0.8098  decode.d8.loss_cls: 0.0415  decode.d8.loss_mask: 0.3890  decode.d8.loss_dice: 0.8064
11/15 22:10:00 - mmengine - INFO - Iter(train) [87650/90000]  base_lr: 3.7596e-06 lr: 3.7596e-07  eta: 0:23:34  time: 0.5969  data_time: 0.0105  memory: 10675  grad_norm: 741.4063  loss: 16.0430  decode.loss_cls: 0.0495  decode.loss_mask: 0.5201  decode.loss_dice: 1.0045  decode.d0.loss_cls: 0.0880  decode.d0.loss_mask: 0.5635  decode.d0.loss_dice: 1.1086  decode.d1.loss_cls: 0.0644  decode.d1.loss_mask: 0.5467  decode.d1.loss_dice: 1.0252  decode.d2.loss_cls: 0.0528  decode.d2.loss_mask: 0.5415  decode.d2.loss_dice: 1.0305  decode.d3.loss_cls: 0.0565  decode.d3.loss_mask: 0.5247  decode.d3.loss_dice: 1.0091  decode.d4.loss_cls: 0.0459  decode.d4.loss_mask: 0.5300  decode.d4.loss_dice: 1.0187  decode.d5.loss_cls: 0.0532  decode.d5.loss_mask: 0.5317  decode.d5.loss_dice: 0.9958  decode.d6.loss_cls: 0.0493  decode.d6.loss_mask: 0.5297  decode.d6.loss_dice: 1.0010  decode.d7.loss_cls: 0.0495  decode.d7.loss_mask: 0.5263  decode.d7.loss_dice: 0.9867  decode.d8.loss_cls: 0.0604  decode.d8.loss_mask: 0.5276  decode.d8.loss_dice: 0.9518
11/15 22:10:30 - mmengine - INFO - Iter(train) [87700/90000]  base_lr: 3.6876e-06 lr: 3.6876e-07  eta: 0:23:04  time: 0.6015  data_time: 0.0108  memory: 10656  grad_norm: 400.3454  loss: 16.3823  decode.loss_cls: 0.0795  decode.loss_mask: 0.4506  decode.loss_dice: 1.0727  decode.d0.loss_cls: 0.1261  decode.d0.loss_mask: 0.4676  decode.d0.loss_dice: 1.1601  decode.d1.loss_cls: 0.0844  decode.d1.loss_mask: 0.4750  decode.d1.loss_dice: 1.1286  decode.d2.loss_cls: 0.0833  decode.d2.loss_mask: 0.4494  decode.d2.loss_dice: 1.0997  decode.d3.loss_cls: 0.0892  decode.d3.loss_mask: 0.4482  decode.d3.loss_dice: 1.0861  decode.d4.loss_cls: 0.0874  decode.d4.loss_mask: 0.4541  decode.d4.loss_dice: 1.0811  decode.d5.loss_cls: 0.0737  decode.d5.loss_mask: 0.4566  decode.d5.loss_dice: 1.0764  decode.d6.loss_cls: 0.0750  decode.d6.loss_mask: 0.4581  decode.d6.loss_dice: 1.0697  decode.d7.loss_cls: 0.0812  decode.d7.loss_mask: 0.4566  decode.d7.loss_dice: 1.0638  decode.d8.loss_cls: 0.0710  decode.d8.loss_mask: 0.4568  decode.d8.loss_dice: 1.1201
11/15 22:11:00 - mmengine - INFO - Iter(train) [87750/90000]  base_lr: 3.6154e-06 lr: 3.6154e-07  eta: 0:22:34  time: 0.5984  data_time: 0.0107  memory: 10713  grad_norm: 332.6759  loss: 15.9717  decode.loss_cls: 0.0687  decode.loss_mask: 0.4166  decode.loss_dice: 1.0736  decode.d0.loss_cls: 0.0896  decode.d0.loss_mask: 0.4354  decode.d0.loss_dice: 1.1641  decode.d1.loss_cls: 0.1010  decode.d1.loss_mask: 0.4200  decode.d1.loss_dice: 1.1298  decode.d2.loss_cls: 0.0765  decode.d2.loss_mask: 0.4180  decode.d2.loss_dice: 1.1093  decode.d3.loss_cls: 0.0663  decode.d3.loss_mask: 0.4119  decode.d3.loss_dice: 1.1128  decode.d4.loss_cls: 0.0707  decode.d4.loss_mask: 0.4143  decode.d4.loss_dice: 1.0841  decode.d5.loss_cls: 0.0707  decode.d5.loss_mask: 0.4158  decode.d5.loss_dice: 1.0831  decode.d6.loss_cls: 0.0622  decode.d6.loss_mask: 0.4160  decode.d6.loss_dice: 1.1165  decode.d7.loss_cls: 0.0651  decode.d7.loss_mask: 0.4182  decode.d7.loss_dice: 1.0840  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.4197  decode.d8.loss_dice: 1.1005
11/15 22:11:30 - mmengine - INFO - Iter(train) [87800/90000]  base_lr: 3.5430e-06 lr: 3.5430e-07  eta: 0:22:04  time: 0.5982  data_time: 0.0105  memory: 10713  grad_norm: 318.6317  loss: 15.5560  decode.loss_cls: 0.0443  decode.loss_mask: 0.4195  decode.loss_dice: 1.0563  decode.d0.loss_cls: 0.0874  decode.d0.loss_mask: 0.4497  decode.d0.loss_dice: 1.1208  decode.d1.loss_cls: 0.0714  decode.d1.loss_mask: 0.4233  decode.d1.loss_dice: 1.0649  decode.d2.loss_cls: 0.0617  decode.d2.loss_mask: 0.4215  decode.d2.loss_dice: 1.0452  decode.d3.loss_cls: 0.0595  decode.d3.loss_mask: 0.4232  decode.d3.loss_dice: 1.0476  decode.d4.loss_cls: 0.0538  decode.d4.loss_mask: 0.4232  decode.d4.loss_dice: 1.0812  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.4229  decode.d5.loss_dice: 1.0525  decode.d6.loss_cls: 0.0589  decode.d6.loss_mask: 0.4199  decode.d6.loss_dice: 1.0614  decode.d7.loss_cls: 0.0583  decode.d7.loss_mask: 0.4239  decode.d7.loss_dice: 1.1120  decode.d8.loss_cls: 0.0554  decode.d8.loss_mask: 0.4243  decode.d8.loss_dice: 1.0524
11/15 22:12:00 - mmengine - INFO - Iter(train) [87850/90000]  base_lr: 3.4704e-06 lr: 3.4704e-07  eta: 0:21:34  time: 0.5982  data_time: 0.0109  memory: 10692  grad_norm: 239.7671  loss: 13.3586  decode.loss_cls: 0.0512  decode.loss_mask: 0.4691  decode.loss_dice: 0.7836  decode.d0.loss_cls: 0.0961  decode.d0.loss_mask: 0.4633  decode.d0.loss_dice: 0.8683  decode.d1.loss_cls: 0.0568  decode.d1.loss_mask: 0.4624  decode.d1.loss_dice: 0.8467  decode.d2.loss_cls: 0.0552  decode.d2.loss_mask: 0.4685  decode.d2.loss_dice: 0.8381  decode.d3.loss_cls: 0.0579  decode.d3.loss_mask: 0.4632  decode.d3.loss_dice: 0.8194  decode.d4.loss_cls: 0.0523  decode.d4.loss_mask: 0.4618  decode.d4.loss_dice: 0.7857  decode.d5.loss_cls: 0.0569  decode.d5.loss_mask: 0.4474  decode.d5.loss_dice: 0.8054  decode.d6.loss_cls: 0.0465  decode.d6.loss_mask: 0.4727  decode.d6.loss_dice: 0.8136  decode.d7.loss_cls: 0.0496  decode.d7.loss_mask: 0.4690  decode.d7.loss_dice: 0.7895  decode.d8.loss_cls: 0.0539  decode.d8.loss_mask: 0.4461  decode.d8.loss_dice: 0.8084
11/15 22:12:30 - mmengine - INFO - Iter(train) [87900/90000]  base_lr: 3.3977e-06 lr: 3.3977e-07  eta: 0:21:04  time: 0.5980  data_time: 0.0112  memory: 10675  grad_norm: 255.9796  loss: 15.3784  decode.loss_cls: 0.0381  decode.loss_mask: 0.4689  decode.loss_dice: 0.9960  decode.d0.loss_cls: 0.0737  decode.d0.loss_mask: 0.4816  decode.d0.loss_dice: 1.0679  decode.d1.loss_cls: 0.0492  decode.d1.loss_mask: 0.4743  decode.d1.loss_dice: 1.0340  decode.d2.loss_cls: 0.0494  decode.d2.loss_mask: 0.4735  decode.d2.loss_dice: 1.0369  decode.d3.loss_cls: 0.0461  decode.d3.loss_mask: 0.4719  decode.d3.loss_dice: 1.0053  decode.d4.loss_cls: 0.0529  decode.d4.loss_mask: 0.4732  decode.d4.loss_dice: 1.0101  decode.d5.loss_cls: 0.0427  decode.d5.loss_mask: 0.4702  decode.d5.loss_dice: 1.0119  decode.d6.loss_cls: 0.0374  decode.d6.loss_mask: 0.4688  decode.d6.loss_dice: 1.0229  decode.d7.loss_cls: 0.0380  decode.d7.loss_mask: 0.4705  decode.d7.loss_dice: 1.0029  decode.d8.loss_cls: 0.0380  decode.d8.loss_mask: 0.4626  decode.d8.loss_dice: 1.0097
11/15 22:13:00 - mmengine - INFO - Iter(train) [87950/90000]  base_lr: 3.3248e-06 lr: 3.3248e-07  eta: 0:20:34  time: 0.5979  data_time: 0.0106  memory: 10675  grad_norm: 459.5939  loss: 16.8536  decode.loss_cls: 0.0701  decode.loss_mask: 0.4756  decode.loss_dice: 1.1293  decode.d0.loss_cls: 0.0795  decode.d0.loss_mask: 0.5119  decode.d0.loss_dice: 1.2180  decode.d1.loss_cls: 0.0694  decode.d1.loss_mask: 0.4718  decode.d1.loss_dice: 1.1299  decode.d2.loss_cls: 0.0564  decode.d2.loss_mask: 0.4710  decode.d2.loss_dice: 1.1315  decode.d3.loss_cls: 0.0623  decode.d3.loss_mask: 0.4753  decode.d3.loss_dice: 1.1352  decode.d4.loss_cls: 0.0708  decode.d4.loss_mask: 0.4775  decode.d4.loss_dice: 1.1246  decode.d5.loss_cls: 0.0582  decode.d5.loss_mask: 0.4786  decode.d5.loss_dice: 1.1244  decode.d6.loss_cls: 0.0620  decode.d6.loss_mask: 0.4791  decode.d6.loss_dice: 1.1292  decode.d7.loss_cls: 0.0633  decode.d7.loss_mask: 0.4781  decode.d7.loss_dice: 1.1253  decode.d8.loss_cls: 0.0700  decode.d8.loss_mask: 0.4776  decode.d8.loss_dice: 1.1480
11/15 22:13:30 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 22:13:30 - mmengine - INFO - Iter(train) [88000/90000]  base_lr: 3.2517e-06 lr: 3.2517e-07  eta: 0:20:04  time: 0.5985  data_time: 0.0107  memory: 10692  grad_norm: 312.4055  loss: 14.0493  decode.loss_cls: 0.0750  decode.loss_mask: 0.3735  decode.loss_dice: 0.9455  decode.d0.loss_cls: 0.1067  decode.d0.loss_mask: 0.3939  decode.d0.loss_dice: 1.0406  decode.d1.loss_cls: 0.0835  decode.d1.loss_mask: 0.3858  decode.d1.loss_dice: 0.9694  decode.d2.loss_cls: 0.0778  decode.d2.loss_mask: 0.3814  decode.d2.loss_dice: 0.9452  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.3789  decode.d3.loss_dice: 0.9240  decode.d4.loss_cls: 0.0707  decode.d4.loss_mask: 0.3776  decode.d4.loss_dice: 0.9365  decode.d5.loss_cls: 0.0719  decode.d5.loss_mask: 0.3758  decode.d5.loss_dice: 0.9384  decode.d6.loss_cls: 0.0683  decode.d6.loss_mask: 0.3731  decode.d6.loss_dice: 0.9234  decode.d7.loss_cls: 0.0758  decode.d7.loss_mask: 0.3705  decode.d7.loss_dice: 0.9360  decode.d8.loss_cls: 0.0776  decode.d8.loss_mask: 0.3698  decode.d8.loss_dice: 0.9226
11/15 22:14:00 - mmengine - INFO - Iter(train) [88050/90000]  base_lr: 3.1785e-06 lr: 3.1785e-07  eta: 0:19:33  time: 0.5984  data_time: 0.0106  memory: 10692  grad_norm: 278.5947  loss: 14.3133  decode.loss_cls: 0.0580  decode.loss_mask: 0.4531  decode.loss_dice: 0.9010  decode.d0.loss_cls: 0.0936  decode.d0.loss_mask: 0.4879  decode.d0.loss_dice: 0.9784  decode.d1.loss_cls: 0.0592  decode.d1.loss_mask: 0.4700  decode.d1.loss_dice: 0.9235  decode.d2.loss_cls: 0.0506  decode.d2.loss_mask: 0.4622  decode.d2.loss_dice: 0.8984  decode.d3.loss_cls: 0.0478  decode.d3.loss_mask: 0.4638  decode.d3.loss_dice: 0.9092  decode.d4.loss_cls: 0.0465  decode.d4.loss_mask: 0.4603  decode.d4.loss_dice: 0.9209  decode.d5.loss_cls: 0.0568  decode.d5.loss_mask: 0.4572  decode.d5.loss_dice: 0.8999  decode.d6.loss_cls: 0.0561  decode.d6.loss_mask: 0.4549  decode.d6.loss_dice: 0.8743  decode.d7.loss_cls: 0.0630  decode.d7.loss_mask: 0.4599  decode.d7.loss_dice: 0.8952  decode.d8.loss_cls: 0.0588  decode.d8.loss_mask: 0.4571  decode.d8.loss_dice: 0.8959
11/15 22:14:30 - mmengine - INFO - Iter(train) [88100/90000]  base_lr: 3.1050e-06 lr: 3.1050e-07  eta: 0:19:03  time: 0.5991  data_time: 0.0108  memory: 10641  grad_norm: 322.1276  loss: 17.1928  decode.loss_cls: 0.0634  decode.loss_mask: 0.5184  decode.loss_dice: 1.1026  decode.d0.loss_cls: 0.0789  decode.d0.loss_mask: 0.5810  decode.d0.loss_dice: 1.2034  decode.d1.loss_cls: 0.0712  decode.d1.loss_mask: 0.5251  decode.d1.loss_dice: 1.1266  decode.d2.loss_cls: 0.0645  decode.d2.loss_mask: 0.5301  decode.d2.loss_dice: 1.1099  decode.d3.loss_cls: 0.0604  decode.d3.loss_mask: 0.5338  decode.d3.loss_dice: 1.1042  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.5383  decode.d4.loss_dice: 1.1008  decode.d5.loss_cls: 0.0559  decode.d5.loss_mask: 0.5412  decode.d5.loss_dice: 1.1138  decode.d6.loss_cls: 0.0578  decode.d6.loss_mask: 0.5391  decode.d6.loss_dice: 1.0874  decode.d7.loss_cls: 0.0662  decode.d7.loss_mask: 0.5300  decode.d7.loss_dice: 1.1072  decode.d8.loss_cls: 0.0660  decode.d8.loss_mask: 0.5297  decode.d8.loss_dice: 1.1249
11/15 22:15:00 - mmengine - INFO - Iter(train) [88150/90000]  base_lr: 3.0314e-06 lr: 3.0314e-07  eta: 0:18:33  time: 0.5984  data_time: 0.0106  memory: 10713  grad_norm: 256.4614  loss: 15.7698  decode.loss_cls: 0.0647  decode.loss_mask: 0.4947  decode.loss_dice: 0.9929  decode.d0.loss_cls: 0.0710  decode.d0.loss_mask: 0.5178  decode.d0.loss_dice: 1.1476  decode.d1.loss_cls: 0.0647  decode.d1.loss_mask: 0.4990  decode.d1.loss_dice: 1.0333  decode.d2.loss_cls: 0.0581  decode.d2.loss_mask: 0.4962  decode.d2.loss_dice: 1.0077  decode.d3.loss_cls: 0.0508  decode.d3.loss_mask: 0.4992  decode.d3.loss_dice: 1.0059  decode.d4.loss_cls: 0.0535  decode.d4.loss_mask: 0.4966  decode.d4.loss_dice: 1.0113  decode.d5.loss_cls: 0.0641  decode.d5.loss_mask: 0.4936  decode.d5.loss_dice: 0.9959  decode.d6.loss_cls: 0.0636  decode.d6.loss_mask: 0.4986  decode.d6.loss_dice: 1.0111  decode.d7.loss_cls: 0.0508  decode.d7.loss_mask: 0.4966  decode.d7.loss_dice: 1.0019  decode.d8.loss_cls: 0.0537  decode.d8.loss_mask: 0.4908  decode.d8.loss_dice: 0.9840
11/15 22:15:30 - mmengine - INFO - Iter(train) [88200/90000]  base_lr: 2.9575e-06 lr: 2.9575e-07  eta: 0:18:03  time: 0.5982  data_time: 0.0108  memory: 10656  grad_norm: 260.9020  loss: 14.0445  decode.loss_cls: 0.0482  decode.loss_mask: 0.3586  decode.loss_dice: 0.9788  decode.d0.loss_cls: 0.0916  decode.d0.loss_mask: 0.3633  decode.d0.loss_dice: 1.0652  decode.d1.loss_cls: 0.0599  decode.d1.loss_mask: 0.3609  decode.d1.loss_dice: 0.9914  decode.d2.loss_cls: 0.0589  decode.d2.loss_mask: 0.3615  decode.d2.loss_dice: 0.9734  decode.d3.loss_cls: 0.0572  decode.d3.loss_mask: 0.3605  decode.d3.loss_dice: 0.9686  decode.d4.loss_cls: 0.0524  decode.d4.loss_mask: 0.3632  decode.d4.loss_dice: 0.9967  decode.d5.loss_cls: 0.0524  decode.d5.loss_mask: 0.3549  decode.d5.loss_dice: 0.9733  decode.d6.loss_cls: 0.0518  decode.d6.loss_mask: 0.3571  decode.d6.loss_dice: 0.9780  decode.d7.loss_cls: 0.0577  decode.d7.loss_mask: 0.3562  decode.d7.loss_dice: 0.9778  decode.d8.loss_cls: 0.0560  decode.d8.loss_mask: 0.3585  decode.d8.loss_dice: 0.9605
11/15 22:16:00 - mmengine - INFO - Iter(train) [88250/90000]  base_lr: 2.8835e-06 lr: 2.8835e-07  eta: 0:17:33  time: 0.5973  data_time: 0.0108  memory: 10713  grad_norm: 392.5503  loss: 14.8921  decode.loss_cls: 0.0687  decode.loss_mask: 0.3779  decode.loss_dice: 1.0197  decode.d0.loss_cls: 0.1006  decode.d0.loss_mask: 0.3910  decode.d0.loss_dice: 1.1278  decode.d1.loss_cls: 0.0878  decode.d1.loss_mask: 0.3879  decode.d1.loss_dice: 1.0469  decode.d2.loss_cls: 0.0829  decode.d2.loss_mask: 0.3803  decode.d2.loss_dice: 1.0442  decode.d3.loss_cls: 0.0779  decode.d3.loss_mask: 0.3755  decode.d3.loss_dice: 0.9988  decode.d4.loss_cls: 0.0748  decode.d4.loss_mask: 0.3784  decode.d4.loss_dice: 1.0129  decode.d5.loss_cls: 0.0764  decode.d5.loss_mask: 0.3729  decode.d5.loss_dice: 0.9971  decode.d6.loss_cls: 0.0735  decode.d6.loss_mask: 0.3783  decode.d6.loss_dice: 1.0215  decode.d7.loss_cls: 0.0654  decode.d7.loss_mask: 0.3761  decode.d7.loss_dice: 1.0186  decode.d8.loss_cls: 0.0777  decode.d8.loss_mask: 0.3798  decode.d8.loss_dice: 1.0206
11/15 22:16:29 - mmengine - INFO - Iter(train) [88300/90000]  base_lr: 2.8092e-06 lr: 2.8092e-07  eta: 0:17:03  time: 0.5988  data_time: 0.0105  memory: 10692  grad_norm: 291.9886  loss: 14.3710  decode.loss_cls: 0.0590  decode.loss_mask: 0.3900  decode.loss_dice: 0.9354  decode.d0.loss_cls: 0.1063  decode.d0.loss_mask: 0.4072  decode.d0.loss_dice: 1.0592  decode.d1.loss_cls: 0.0559  decode.d1.loss_mask: 0.4168  decode.d1.loss_dice: 1.0097  decode.d2.loss_cls: 0.0628  decode.d2.loss_mask: 0.3931  decode.d2.loss_dice: 0.9857  decode.d3.loss_cls: 0.0623  decode.d3.loss_mask: 0.3925  decode.d3.loss_dice: 0.9840  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.3929  decode.d4.loss_dice: 0.9549  decode.d5.loss_cls: 0.0586  decode.d5.loss_mask: 0.3921  decode.d5.loss_dice: 0.9645  decode.d6.loss_cls: 0.0557  decode.d6.loss_mask: 0.3902  decode.d6.loss_dice: 0.9770  decode.d7.loss_cls: 0.0541  decode.d7.loss_mask: 0.3932  decode.d7.loss_dice: 0.9517  decode.d8.loss_cls: 0.0616  decode.d8.loss_mask: 0.3914  decode.d8.loss_dice: 0.9520
11/15 22:16:59 - mmengine - INFO - Iter(train) [88350/90000]  base_lr: 2.7348e-06 lr: 2.7348e-07  eta: 0:16:33  time: 0.5978  data_time: 0.0108  memory: 10692  grad_norm: 203.8383  loss: 13.1346  decode.loss_cls: 0.0565  decode.loss_mask: 0.3364  decode.loss_dice: 0.9020  decode.d0.loss_cls: 0.0983  decode.d0.loss_mask: 0.3422  decode.d0.loss_dice: 0.9698  decode.d1.loss_cls: 0.0699  decode.d1.loss_mask: 0.3442  decode.d1.loss_dice: 0.9451  decode.d2.loss_cls: 0.0566  decode.d2.loss_mask: 0.3469  decode.d2.loss_dice: 0.9384  decode.d3.loss_cls: 0.0544  decode.d3.loss_mask: 0.3448  decode.d3.loss_dice: 0.8867  decode.d4.loss_cls: 0.0578  decode.d4.loss_mask: 0.3377  decode.d4.loss_dice: 0.8723  decode.d5.loss_cls: 0.0591  decode.d5.loss_mask: 0.3352  decode.d5.loss_dice: 0.8876  decode.d6.loss_cls: 0.0663  decode.d6.loss_mask: 0.3398  decode.d6.loss_dice: 0.9093  decode.d7.loss_cls: 0.0665  decode.d7.loss_mask: 0.3323  decode.d7.loss_dice: 0.9045  decode.d8.loss_cls: 0.0682  decode.d8.loss_mask: 0.3367  decode.d8.loss_dice: 0.8689
11/15 22:17:29 - mmengine - INFO - Iter(train) [88400/90000]  base_lr: 2.6601e-06 lr: 2.6601e-07  eta: 0:16:03  time: 0.5988  data_time: 0.0110  memory: 10713  grad_norm: 271.2284  loss: 14.5677  decode.loss_cls: 0.0559  decode.loss_mask: 0.3940  decode.loss_dice: 0.9791  decode.d0.loss_cls: 0.0747  decode.d0.loss_mask: 0.4023  decode.d0.loss_dice: 1.0597  decode.d1.loss_cls: 0.0540  decode.d1.loss_mask: 0.4020  decode.d1.loss_dice: 1.0169  decode.d2.loss_cls: 0.0655  decode.d2.loss_mask: 0.3972  decode.d2.loss_dice: 1.0062  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 0.3942  decode.d3.loss_dice: 0.9932  decode.d4.loss_cls: 0.0570  decode.d4.loss_mask: 0.3963  decode.d4.loss_dice: 0.9880  decode.d5.loss_cls: 0.0511  decode.d5.loss_mask: 0.3996  decode.d5.loss_dice: 0.9863  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.3940  decode.d6.loss_dice: 0.9762  decode.d7.loss_cls: 0.0572  decode.d7.loss_mask: 0.4024  decode.d7.loss_dice: 0.9821  decode.d8.loss_cls: 0.0507  decode.d8.loss_mask: 0.4030  decode.d8.loss_dice: 1.0010
11/15 22:17:59 - mmengine - INFO - Iter(train) [88450/90000]  base_lr: 2.5851e-06 lr: 2.5851e-07  eta: 0:15:33  time: 0.5986  data_time: 0.0109  memory: 10692  grad_norm: 561.8369  loss: 13.9791  decode.loss_cls: 0.0433  decode.loss_mask: 0.3976  decode.loss_dice: 0.9333  decode.d0.loss_cls: 0.0790  decode.d0.loss_mask: 0.4269  decode.d0.loss_dice: 1.0123  decode.d1.loss_cls: 0.0531  decode.d1.loss_mask: 0.4041  decode.d1.loss_dice: 0.9517  decode.d2.loss_cls: 0.0482  decode.d2.loss_mask: 0.3961  decode.d2.loss_dice: 0.9227  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.3910  decode.d3.loss_dice: 0.9251  decode.d4.loss_cls: 0.0444  decode.d4.loss_mask: 0.3977  decode.d4.loss_dice: 0.9455  decode.d5.loss_cls: 0.0390  decode.d5.loss_mask: 0.4009  decode.d5.loss_dice: 0.9691  decode.d6.loss_cls: 0.0462  decode.d6.loss_mask: 0.3936  decode.d6.loss_dice: 0.9415  decode.d7.loss_cls: 0.0458  decode.d7.loss_mask: 0.3960  decode.d7.loss_dice: 0.9283  decode.d8.loss_cls: 0.0345  decode.d8.loss_mask: 0.4031  decode.d8.loss_dice: 0.9569
11/15 22:18:29 - mmengine - INFO - Iter(train) [88500/90000]  base_lr: 2.5100e-06 lr: 2.5100e-07  eta: 0:15:02  time: 0.5978  data_time: 0.0107  memory: 10675  grad_norm: 345.2224  loss: 15.5364  decode.loss_cls: 0.0530  decode.loss_mask: 0.4774  decode.loss_dice: 0.9806  decode.d0.loss_cls: 0.0854  decode.d0.loss_mask: 0.5256  decode.d0.loss_dice: 1.0776  decode.d1.loss_cls: 0.0626  decode.d1.loss_mask: 0.4944  decode.d1.loss_dice: 0.9826  decode.d2.loss_cls: 0.0567  decode.d2.loss_mask: 0.4875  decode.d2.loss_dice: 1.0297  decode.d3.loss_cls: 0.0533  decode.d3.loss_mask: 0.4950  decode.d3.loss_dice: 1.0022  decode.d4.loss_cls: 0.0608  decode.d4.loss_mask: 0.4829  decode.d4.loss_dice: 0.9681  decode.d5.loss_cls: 0.0596  decode.d5.loss_mask: 0.4868  decode.d5.loss_dice: 0.9825  decode.d6.loss_cls: 0.0504  decode.d6.loss_mask: 0.4858  decode.d6.loss_dice: 1.0125  decode.d7.loss_cls: 0.0551  decode.d7.loss_mask: 0.4864  decode.d7.loss_dice: 1.0165  decode.d8.loss_cls: 0.0485  decode.d8.loss_mask: 0.4804  decode.d8.loss_dice: 0.9965
11/15 22:18:59 - mmengine - INFO - Iter(train) [88550/90000]  base_lr: 2.4345e-06 lr: 2.4345e-07  eta: 0:14:32  time: 0.5986  data_time: 0.0107  memory: 10656  grad_norm: 927.3832  loss: 17.7481  decode.loss_cls: 0.0781  decode.loss_mask: 0.5605  decode.loss_dice: 1.0607  decode.d0.loss_cls: 0.0898  decode.d0.loss_mask: 0.6348  decode.d0.loss_dice: 1.1916  decode.d1.loss_cls: 0.0879  decode.d1.loss_mask: 0.6221  decode.d1.loss_dice: 1.1366  decode.d2.loss_cls: 0.0907  decode.d2.loss_mask: 0.5854  decode.d2.loss_dice: 1.1209  decode.d3.loss_cls: 0.0833  decode.d3.loss_mask: 0.5881  decode.d3.loss_dice: 1.0794  decode.d4.loss_cls: 0.0905  decode.d4.loss_mask: 0.5926  decode.d4.loss_dice: 1.0755  decode.d5.loss_cls: 0.0807  decode.d5.loss_mask: 0.5917  decode.d5.loss_dice: 1.0876  decode.d6.loss_cls: 0.0751  decode.d6.loss_mask: 0.5958  decode.d6.loss_dice: 1.0530  decode.d7.loss_cls: 0.0792  decode.d7.loss_mask: 0.5930  decode.d7.loss_dice: 1.0727  decode.d8.loss_cls: 0.0748  decode.d8.loss_mask: 0.5974  decode.d8.loss_dice: 1.0788
11/15 22:19:29 - mmengine - INFO - Iter(train) [88600/90000]  base_lr: 2.3589e-06 lr: 2.3589e-07  eta: 0:14:02  time: 0.5983  data_time: 0.0107  memory: 10713  grad_norm: 377.3830  loss: 14.5361  decode.loss_cls: 0.0458  decode.loss_mask: 0.4369  decode.loss_dice: 0.9386  decode.d0.loss_cls: 0.0703  decode.d0.loss_mask: 0.4707  decode.d0.loss_dice: 0.9988  decode.d1.loss_cls: 0.0670  decode.d1.loss_mask: 0.4380  decode.d1.loss_dice: 0.9540  decode.d2.loss_cls: 0.0594  decode.d2.loss_mask: 0.4423  decode.d2.loss_dice: 0.9532  decode.d3.loss_cls: 0.0418  decode.d3.loss_mask: 0.4348  decode.d3.loss_dice: 0.9394  decode.d4.loss_cls: 0.0494  decode.d4.loss_mask: 0.4422  decode.d4.loss_dice: 0.9560  decode.d5.loss_cls: 0.0458  decode.d5.loss_mask: 0.4399  decode.d5.loss_dice: 0.9528  decode.d6.loss_cls: 0.0378  decode.d6.loss_mask: 0.4515  decode.d6.loss_dice: 0.9487  decode.d7.loss_cls: 0.0466  decode.d7.loss_mask: 0.4552  decode.d7.loss_dice: 0.9686  decode.d8.loss_cls: 0.0516  decode.d8.loss_mask: 0.4525  decode.d8.loss_dice: 0.9468
11/15 22:19:59 - mmengine - INFO - Iter(train) [88650/90000]  base_lr: 2.2829e-06 lr: 2.2829e-07  eta: 0:13:32  time: 0.5988  data_time: 0.0110  memory: 10675  grad_norm: 253.9853  loss: 13.2956  decode.loss_cls: 0.0621  decode.loss_mask: 0.3576  decode.loss_dice: 0.8663  decode.d0.loss_cls: 0.0878  decode.d0.loss_mask: 0.3812  decode.d0.loss_dice: 0.9966  decode.d1.loss_cls: 0.0893  decode.d1.loss_mask: 0.3672  decode.d1.loss_dice: 0.9103  decode.d2.loss_cls: 0.0702  decode.d2.loss_mask: 0.3568  decode.d2.loss_dice: 0.8732  decode.d3.loss_cls: 0.0629  decode.d3.loss_mask: 0.3585  decode.d3.loss_dice: 0.8884  decode.d4.loss_cls: 0.0674  decode.d4.loss_mask: 0.3613  decode.d4.loss_dice: 0.8772  decode.d5.loss_cls: 0.0576  decode.d5.loss_mask: 0.3614  decode.d5.loss_dice: 0.8983  decode.d6.loss_cls: 0.0633  decode.d6.loss_mask: 0.3644  decode.d6.loss_dice: 0.8915  decode.d7.loss_cls: 0.0597  decode.d7.loss_mask: 0.3604  decode.d7.loss_dice: 0.9108  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.3591  decode.d8.loss_dice: 0.8776
11/15 22:20:30 - mmengine - INFO - Iter(train) [88700/90000]  base_lr: 2.2067e-06 lr: 2.2067e-07  eta: 0:13:02  time: 0.6231  data_time: 0.0108  memory: 10728  grad_norm: 300.0071  loss: 15.3581  decode.loss_cls: 0.0651  decode.loss_mask: 0.3721  decode.loss_dice: 1.0718  decode.d0.loss_cls: 0.0697  decode.d0.loss_mask: 0.3900  decode.d0.loss_dice: 1.1432  decode.d1.loss_cls: 0.0396  decode.d1.loss_mask: 0.4644  decode.d1.loss_dice: 1.0946  decode.d2.loss_cls: 0.0478  decode.d2.loss_mask: 0.4411  decode.d2.loss_dice: 1.0569  decode.d3.loss_cls: 0.0465  decode.d3.loss_mask: 0.4386  decode.d3.loss_dice: 1.0258  decode.d4.loss_cls: 0.0504  decode.d4.loss_mask: 0.4511  decode.d4.loss_dice: 1.0150  decode.d5.loss_cls: 0.0386  decode.d5.loss_mask: 0.4543  decode.d5.loss_dice: 1.0268  decode.d6.loss_cls: 0.0401  decode.d6.loss_mask: 0.4450  decode.d6.loss_dice: 1.0422  decode.d7.loss_cls: 0.0604  decode.d7.loss_mask: 0.3896  decode.d7.loss_dice: 1.0892  decode.d8.loss_cls: 0.0605  decode.d8.loss_mask: 0.3700  decode.d8.loss_dice: 1.0579
11/15 22:21:00 - mmengine - INFO - Iter(train) [88750/90000]  base_lr: 2.1301e-06 lr: 2.1301e-07  eta: 0:12:32  time: 0.6011  data_time: 0.0110  memory: 10758  grad_norm: 329.0202  loss: 14.1932  decode.loss_cls: 0.0567  decode.loss_mask: 0.4226  decode.loss_dice: 0.9165  decode.d0.loss_cls: 0.0680  decode.d0.loss_mask: 0.4406  decode.d0.loss_dice: 1.0076  decode.d1.loss_cls: 0.0713  decode.d1.loss_mask: 0.4250  decode.d1.loss_dice: 0.9535  decode.d2.loss_cls: 0.0587  decode.d2.loss_mask: 0.4298  decode.d2.loss_dice: 0.9586  decode.d3.loss_cls: 0.0630  decode.d3.loss_mask: 0.4171  decode.d3.loss_dice: 0.9317  decode.d4.loss_cls: 0.0619  decode.d4.loss_mask: 0.4135  decode.d4.loss_dice: 0.9249  decode.d5.loss_cls: 0.0629  decode.d5.loss_mask: 0.4199  decode.d5.loss_dice: 0.9200  decode.d6.loss_cls: 0.0646  decode.d6.loss_mask: 0.4140  decode.d6.loss_dice: 0.9032  decode.d7.loss_cls: 0.0554  decode.d7.loss_mask: 0.4174  decode.d7.loss_dice: 0.8947  decode.d8.loss_cls: 0.0522  decode.d8.loss_mask: 0.4225  decode.d8.loss_dice: 0.9451
11/15 22:21:30 - mmengine - INFO - Iter(train) [88800/90000]  base_lr: 2.0533e-06 lr: 2.0533e-07  eta: 0:12:02  time: 0.5987  data_time: 0.0107  memory: 10692  grad_norm: 338.1057  loss: 14.6710  decode.loss_cls: 0.0705  decode.loss_mask: 0.4209  decode.loss_dice: 0.9354  decode.d0.loss_cls: 0.0903  decode.d0.loss_mask: 0.4490  decode.d0.loss_dice: 1.0546  decode.d1.loss_cls: 0.0690  decode.d1.loss_mask: 0.4298  decode.d1.loss_dice: 0.9989  decode.d2.loss_cls: 0.0752  decode.d2.loss_mask: 0.4292  decode.d2.loss_dice: 0.9486  decode.d3.loss_cls: 0.0724  decode.d3.loss_mask: 0.4178  decode.d3.loss_dice: 0.9806  decode.d4.loss_cls: 0.0744  decode.d4.loss_mask: 0.4268  decode.d4.loss_dice: 0.9551  decode.d5.loss_cls: 0.0738  decode.d5.loss_mask: 0.4216  decode.d5.loss_dice: 0.9598  decode.d6.loss_cls: 0.0734  decode.d6.loss_mask: 0.4240  decode.d6.loss_dice: 0.9605  decode.d7.loss_cls: 0.0721  decode.d7.loss_mask: 0.4206  decode.d7.loss_dice: 0.9277  decode.d8.loss_cls: 0.0710  decode.d8.loss_mask: 0.4234  decode.d8.loss_dice: 0.9448
11/15 22:22:00 - mmengine - INFO - Iter(train) [88850/90000]  base_lr: 1.9761e-06 lr: 1.9761e-07  eta: 0:11:32  time: 0.5993  data_time: 0.0109  memory: 10675  grad_norm: 322.6407  loss: 15.9772  decode.loss_cls: 0.0579  decode.loss_mask: 0.4685  decode.loss_dice: 1.0518  decode.d0.loss_cls: 0.0873  decode.d0.loss_mask: 0.4814  decode.d0.loss_dice: 1.1329  decode.d1.loss_cls: 0.0664  decode.d1.loss_mask: 0.4648  decode.d1.loss_dice: 1.0834  decode.d2.loss_cls: 0.0692  decode.d2.loss_mask: 0.4643  decode.d2.loss_dice: 1.0669  decode.d3.loss_cls: 0.0529  decode.d3.loss_mask: 0.4666  decode.d3.loss_dice: 1.0670  decode.d4.loss_cls: 0.0431  decode.d4.loss_mask: 0.4645  decode.d4.loss_dice: 1.0747  decode.d5.loss_cls: 0.0592  decode.d5.loss_mask: 0.4652  decode.d5.loss_dice: 1.0576  decode.d6.loss_cls: 0.0552  decode.d6.loss_mask: 0.4665  decode.d6.loss_dice: 1.0443  decode.d7.loss_cls: 0.0530  decode.d7.loss_mask: 0.4652  decode.d7.loss_dice: 1.0692  decode.d8.loss_cls: 0.0584  decode.d8.loss_mask: 0.4673  decode.d8.loss_dice: 1.0525
11/15 22:22:30 - mmengine - INFO - Iter(train) [88900/90000]  base_lr: 1.8986e-06 lr: 1.8986e-07  eta: 0:11:02  time: 0.5970  data_time: 0.0109  memory: 10641  grad_norm: 328.1336  loss: 15.0884  decode.loss_cls: 0.0671  decode.loss_mask: 0.4405  decode.loss_dice: 0.9764  decode.d0.loss_cls: 0.1043  decode.d0.loss_mask: 0.4482  decode.d0.loss_dice: 1.0986  decode.d1.loss_cls: 0.0604  decode.d1.loss_mask: 0.4548  decode.d1.loss_dice: 1.0267  decode.d2.loss_cls: 0.0602  decode.d2.loss_mask: 0.4467  decode.d2.loss_dice: 0.9929  decode.d3.loss_cls: 0.0704  decode.d3.loss_mask: 0.4536  decode.d3.loss_dice: 0.9697  decode.d4.loss_cls: 0.0610  decode.d4.loss_mask: 0.4559  decode.d4.loss_dice: 0.9678  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.4517  decode.d5.loss_dice: 0.9852  decode.d6.loss_cls: 0.0604  decode.d6.loss_mask: 0.4479  decode.d6.loss_dice: 0.9670  decode.d7.loss_cls: 0.0618  decode.d7.loss_mask: 0.4462  decode.d7.loss_dice: 0.9580  decode.d8.loss_cls: 0.0738  decode.d8.loss_mask: 0.4491  decode.d8.loss_dice: 0.9642
11/15 22:23:00 - mmengine - INFO - Iter(train) [88950/90000]  base_lr: 1.8208e-06 lr: 1.8208e-07  eta: 0:10:32  time: 0.6002  data_time: 0.0108  memory: 10713  grad_norm: 384.0535  loss: 13.0330  decode.loss_cls: 0.0306  decode.loss_mask: 0.4336  decode.loss_dice: 0.8177  decode.d0.loss_cls: 0.0637  decode.d0.loss_mask: 0.4650  decode.d0.loss_dice: 0.8898  decode.d1.loss_cls: 0.0483  decode.d1.loss_mask: 0.4362  decode.d1.loss_dice: 0.8583  decode.d2.loss_cls: 0.0474  decode.d2.loss_mask: 0.4345  decode.d2.loss_dice: 0.8179  decode.d3.loss_cls: 0.0459  decode.d3.loss_mask: 0.4378  decode.d3.loss_dice: 0.8284  decode.d4.loss_cls: 0.0387  decode.d4.loss_mask: 0.4372  decode.d4.loss_dice: 0.7883  decode.d5.loss_cls: 0.0386  decode.d5.loss_mask: 0.4328  decode.d5.loss_dice: 0.8171  decode.d6.loss_cls: 0.0448  decode.d6.loss_mask: 0.4321  decode.d6.loss_dice: 0.7926  decode.d7.loss_cls: 0.0444  decode.d7.loss_mask: 0.4325  decode.d7.loss_dice: 0.7916  decode.d8.loss_cls: 0.0380  decode.d8.loss_mask: 0.4359  decode.d8.loss_dice: 0.8132
11/15 22:23:30 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 22:23:30 - mmengine - INFO - Iter(train) [89000/90000]  base_lr: 1.7426e-06 lr: 1.7426e-07  eta: 0:10:01  time: 0.5979  data_time: 0.0111  memory: 10713  grad_norm: 514.8639  loss: 14.5219  decode.loss_cls: 0.0527  decode.loss_mask: 0.4301  decode.loss_dice: 0.9516  decode.d0.loss_cls: 0.0801  decode.d0.loss_mask: 0.4642  decode.d0.loss_dice: 1.0107  decode.d1.loss_cls: 0.0466  decode.d1.loss_mask: 0.4492  decode.d1.loss_dice: 0.9997  decode.d2.loss_cls: 0.0637  decode.d2.loss_mask: 0.4378  decode.d2.loss_dice: 0.9786  decode.d3.loss_cls: 0.0576  decode.d3.loss_mask: 0.4210  decode.d3.loss_dice: 0.9482  decode.d4.loss_cls: 0.0499  decode.d4.loss_mask: 0.4186  decode.d4.loss_dice: 0.9317  decode.d5.loss_cls: 0.0494  decode.d5.loss_mask: 0.4163  decode.d5.loss_dice: 0.9575  decode.d6.loss_cls: 0.0514  decode.d6.loss_mask: 0.4173  decode.d6.loss_dice: 0.9564  decode.d7.loss_cls: 0.0689  decode.d7.loss_mask: 0.4182  decode.d7.loss_dice: 0.9570  decode.d8.loss_cls: 0.0502  decode.d8.loss_mask: 0.4289  decode.d8.loss_dice: 0.9582
11/15 22:24:00 - mmengine - INFO - Iter(train) [89050/90000]  base_lr: 1.6639e-06 lr: 1.6639e-07  eta: 0:09:31  time: 0.5981  data_time: 0.0108  memory: 10675  grad_norm: 209.5443  loss: 13.3251  decode.loss_cls: 0.0724  decode.loss_mask: 0.3600  decode.loss_dice: 0.8661  decode.d0.loss_cls: 0.0895  decode.d0.loss_mask: 0.3785  decode.d0.loss_dice: 0.9826  decode.d1.loss_cls: 0.0730  decode.d1.loss_mask: 0.3675  decode.d1.loss_dice: 0.9240  decode.d2.loss_cls: 0.0557  decode.d2.loss_mask: 0.3580  decode.d2.loss_dice: 0.9306  decode.d3.loss_cls: 0.0623  decode.d3.loss_mask: 0.3628  decode.d3.loss_dice: 0.8901  decode.d4.loss_cls: 0.0744  decode.d4.loss_mask: 0.3591  decode.d4.loss_dice: 0.8593  decode.d5.loss_cls: 0.0615  decode.d5.loss_mask: 0.3616  decode.d5.loss_dice: 0.8905  decode.d6.loss_cls: 0.0718  decode.d6.loss_mask: 0.3630  decode.d6.loss_dice: 0.8831  decode.d7.loss_cls: 0.0676  decode.d7.loss_mask: 0.3689  decode.d7.loss_dice: 0.8905  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.3621  decode.d8.loss_dice: 0.8736
11/15 22:24:30 - mmengine - INFO - Iter(train) [89100/90000]  base_lr: 1.5849e-06 lr: 1.5849e-07  eta: 0:09:01  time: 0.5967  data_time: 0.0106  memory: 10656  grad_norm: 571.8194  loss: 13.8043  decode.loss_cls: 0.0366  decode.loss_mask: 0.4330  decode.loss_dice: 0.8834  decode.d0.loss_cls: 0.0724  decode.d0.loss_mask: 0.4576  decode.d0.loss_dice: 0.9614  decode.d1.loss_cls: 0.0449  decode.d1.loss_mask: 0.4521  decode.d1.loss_dice: 0.9241  decode.d2.loss_cls: 0.0419  decode.d2.loss_mask: 0.4458  decode.d2.loss_dice: 0.9028  decode.d3.loss_cls: 0.0446  decode.d3.loss_mask: 0.4348  decode.d3.loss_dice: 0.8796  decode.d4.loss_cls: 0.0383  decode.d4.loss_mask: 0.4285  decode.d4.loss_dice: 0.8912  decode.d5.loss_cls: 0.0410  decode.d5.loss_mask: 0.4362  decode.d5.loss_dice: 0.8830  decode.d6.loss_cls: 0.0355  decode.d6.loss_mask: 0.4366  decode.d6.loss_dice: 0.8854  decode.d7.loss_cls: 0.0382  decode.d7.loss_mask: 0.4361  decode.d7.loss_dice: 0.8822  decode.d8.loss_cls: 0.0365  decode.d8.loss_mask: 0.4345  decode.d8.loss_dice: 0.8860
11/15 22:25:00 - mmengine - INFO - Iter(train) [89150/90000]  base_lr: 1.5054e-06 lr: 1.5054e-07  eta: 0:08:31  time: 0.5985  data_time: 0.0110  memory: 10692  grad_norm: 301.2654  loss: 16.7882  decode.loss_cls: 0.0589  decode.loss_mask: 0.5073  decode.loss_dice: 1.1233  decode.d0.loss_cls: 0.0854  decode.d0.loss_mask: 0.5167  decode.d0.loss_dice: 1.1794  decode.d1.loss_cls: 0.0625  decode.d1.loss_mask: 0.5013  decode.d1.loss_dice: 1.1165  decode.d2.loss_cls: 0.0576  decode.d2.loss_mask: 0.5032  decode.d2.loss_dice: 1.0936  decode.d3.loss_cls: 0.0656  decode.d3.loss_mask: 0.5011  decode.d3.loss_dice: 1.0900  decode.d4.loss_cls: 0.0582  decode.d4.loss_mask: 0.5035  decode.d4.loss_dice: 1.1049  decode.d5.loss_cls: 0.0535  decode.d5.loss_mask: 0.5032  decode.d5.loss_dice: 1.1135  decode.d6.loss_cls: 0.0594  decode.d6.loss_mask: 0.5097  decode.d6.loss_dice: 1.1188  decode.d7.loss_cls: 0.0548  decode.d7.loss_mask: 0.5059  decode.d7.loss_dice: 1.0955  decode.d8.loss_cls: 0.0729  decode.d8.loss_mask: 0.5016  decode.d8.loss_dice: 1.0702
11/15 22:25:30 - mmengine - INFO - Iter(train) [89200/90000]  base_lr: 1.4255e-06 lr: 1.4255e-07  eta: 0:08:01  time: 0.5980  data_time: 0.0109  memory: 10692  grad_norm: 227.4439  loss: 14.0409  decode.loss_cls: 0.0589  decode.loss_mask: 0.3678  decode.loss_dice: 0.9341  decode.d0.loss_cls: 0.0965  decode.d0.loss_mask: 0.4107  decode.d0.loss_dice: 1.0499  decode.d1.loss_cls: 0.0753  decode.d1.loss_mask: 0.3841  decode.d1.loss_dice: 1.0078  decode.d2.loss_cls: 0.0735  decode.d2.loss_mask: 0.3844  decode.d2.loss_dice: 0.9649  decode.d3.loss_cls: 0.0648  decode.d3.loss_mask: 0.3658  decode.d3.loss_dice: 0.9134  decode.d4.loss_cls: 0.0641  decode.d4.loss_mask: 0.3719  decode.d4.loss_dice: 0.9261  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.3739  decode.d5.loss_dice: 0.9722  decode.d6.loss_cls: 0.0681  decode.d6.loss_mask: 0.3688  decode.d6.loss_dice: 0.9249  decode.d7.loss_cls: 0.0613  decode.d7.loss_mask: 0.3704  decode.d7.loss_dice: 0.9500  decode.d8.loss_cls: 0.0643  decode.d8.loss_mask: 0.3715  decode.d8.loss_dice: 0.9372
11/15 22:26:00 - mmengine - INFO - Iter(train) [89250/90000]  base_lr: 1.3451e-06 lr: 1.3451e-07  eta: 0:07:31  time: 0.5973  data_time: 0.0106  memory: 10692  grad_norm: 466.2978  loss: 14.2985  decode.loss_cls: 0.0501  decode.loss_mask: 0.4301  decode.loss_dice: 0.9334  decode.d0.loss_cls: 0.0676  decode.d0.loss_mask: 0.4505  decode.d0.loss_dice: 1.0370  decode.d1.loss_cls: 0.0506  decode.d1.loss_mask: 0.4370  decode.d1.loss_dice: 0.9882  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.4303  decode.d2.loss_dice: 0.9555  decode.d3.loss_cls: 0.0517  decode.d3.loss_mask: 0.4300  decode.d3.loss_dice: 0.9397  decode.d4.loss_cls: 0.0515  decode.d4.loss_mask: 0.4299  decode.d4.loss_dice: 0.9546  decode.d5.loss_cls: 0.0507  decode.d5.loss_mask: 0.4114  decode.d5.loss_dice: 0.9225  decode.d6.loss_cls: 0.0460  decode.d6.loss_mask: 0.4105  decode.d6.loss_dice: 0.9323  decode.d7.loss_cls: 0.0453  decode.d7.loss_mask: 0.4112  decode.d7.loss_dice: 0.9391  decode.d8.loss_cls: 0.0563  decode.d8.loss_mask: 0.4087  decode.d8.loss_dice: 0.9210
11/15 22:26:30 - mmengine - INFO - Iter(train) [89300/90000]  base_lr: 1.2641e-06 lr: 1.2641e-07  eta: 0:07:01  time: 0.5990  data_time: 0.0106  memory: 10692  grad_norm: 203.8105  loss: 15.0544  decode.loss_cls: 0.0686  decode.loss_mask: 0.3959  decode.loss_dice: 1.0048  decode.d0.loss_cls: 0.0828  decode.d0.loss_mask: 0.4015  decode.d0.loss_dice: 1.1076  decode.d1.loss_cls: 0.0587  decode.d1.loss_mask: 0.4003  decode.d1.loss_dice: 1.0757  decode.d2.loss_cls: 0.0559  decode.d2.loss_mask: 0.3925  decode.d2.loss_dice: 1.0453  decode.d3.loss_cls: 0.0594  decode.d3.loss_mask: 0.3984  decode.d3.loss_dice: 1.0524  decode.d4.loss_cls: 0.0537  decode.d4.loss_mask: 0.3963  decode.d4.loss_dice: 1.0059  decode.d5.loss_cls: 0.0613  decode.d5.loss_mask: 0.4005  decode.d5.loss_dice: 1.0780  decode.d6.loss_cls: 0.0627  decode.d6.loss_mask: 0.3963  decode.d6.loss_dice: 1.0224  decode.d7.loss_cls: 0.0658  decode.d7.loss_mask: 0.4010  decode.d7.loss_dice: 1.0399  decode.d8.loss_cls: 0.0636  decode.d8.loss_mask: 0.3974  decode.d8.loss_dice: 1.0095
11/15 22:27:00 - mmengine - INFO - Iter(train) [89350/90000]  base_lr: 1.1825e-06 lr: 1.1825e-07  eta: 0:06:31  time: 0.5979  data_time: 0.0108  memory: 10742  grad_norm: 438.9564  loss: 15.9258  decode.loss_cls: 0.0426  decode.loss_mask: 0.5548  decode.loss_dice: 0.9669  decode.d0.loss_cls: 0.0776  decode.d0.loss_mask: 0.5959  decode.d0.loss_dice: 1.0521  decode.d1.loss_cls: 0.0433  decode.d1.loss_mask: 0.5625  decode.d1.loss_dice: 1.0045  decode.d2.loss_cls: 0.0495  decode.d2.loss_mask: 0.5632  decode.d2.loss_dice: 0.9824  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.5614  decode.d3.loss_dice: 0.9751  decode.d4.loss_cls: 0.0406  decode.d4.loss_mask: 0.5604  decode.d4.loss_dice: 0.9805  decode.d5.loss_cls: 0.0402  decode.d5.loss_mask: 0.5557  decode.d5.loss_dice: 0.9729  decode.d6.loss_cls: 0.0467  decode.d6.loss_mask: 0.5564  decode.d6.loss_dice: 0.9628  decode.d7.loss_cls: 0.0471  decode.d7.loss_mask: 0.5564  decode.d7.loss_dice: 0.9568  decode.d8.loss_cls: 0.0497  decode.d8.loss_mask: 0.5558  decode.d8.loss_dice: 0.9556
11/15 22:27:30 - mmengine - INFO - Iter(train) [89400/90000]  base_lr: 1.1003e-06 lr: 1.1003e-07  eta: 0:06:01  time: 0.5982  data_time: 0.0110  memory: 10675  grad_norm: 338.3949  loss: 13.4772  decode.loss_cls: 0.0598  decode.loss_mask: 0.4187  decode.loss_dice: 0.8467  decode.d0.loss_cls: 0.1106  decode.d0.loss_mask: 0.4414  decode.d0.loss_dice: 0.9005  decode.d1.loss_cls: 0.0705  decode.d1.loss_mask: 0.4289  decode.d1.loss_dice: 0.8836  decode.d2.loss_cls: 0.0650  decode.d2.loss_mask: 0.4284  decode.d2.loss_dice: 0.8397  decode.d3.loss_cls: 0.0732  decode.d3.loss_mask: 0.4252  decode.d3.loss_dice: 0.8264  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.4287  decode.d4.loss_dice: 0.8715  decode.d5.loss_cls: 0.0608  decode.d5.loss_mask: 0.4262  decode.d5.loss_dice: 0.8566  decode.d6.loss_cls: 0.0637  decode.d6.loss_mask: 0.4174  decode.d6.loss_dice: 0.8242  decode.d7.loss_cls: 0.0626  decode.d7.loss_mask: 0.4120  decode.d7.loss_dice: 0.8307  decode.d8.loss_cls: 0.0559  decode.d8.loss_mask: 0.4151  decode.d8.loss_dice: 0.8686
11/15 22:28:00 - mmengine - INFO - Iter(train) [89450/90000]  base_lr: 1.0174e-06 lr: 1.0174e-07  eta: 0:05:31  time: 0.5984  data_time: 0.0108  memory: 10713  grad_norm: 264.1390  loss: 14.6400  decode.loss_cls: 0.0568  decode.loss_mask: 0.4144  decode.loss_dice: 0.9687  decode.d0.loss_cls: 0.0832  decode.d0.loss_mask: 0.4306  decode.d0.loss_dice: 1.1036  decode.d1.loss_cls: 0.0673  decode.d1.loss_mask: 0.4093  decode.d1.loss_dice: 1.0247  decode.d2.loss_cls: 0.0685  decode.d2.loss_mask: 0.4102  decode.d2.loss_dice: 0.9931  decode.d3.loss_cls: 0.0610  decode.d3.loss_mask: 0.4116  decode.d3.loss_dice: 0.9883  decode.d4.loss_cls: 0.0614  decode.d4.loss_mask: 0.4111  decode.d4.loss_dice: 0.9774  decode.d5.loss_cls: 0.0542  decode.d5.loss_mask: 0.4161  decode.d5.loss_dice: 0.9812  decode.d6.loss_cls: 0.0587  decode.d6.loss_mask: 0.4119  decode.d6.loss_dice: 0.9363  decode.d7.loss_cls: 0.0570  decode.d7.loss_mask: 0.4129  decode.d7.loss_dice: 0.9641  decode.d8.loss_cls: 0.0679  decode.d8.loss_mask: 0.4045  decode.d8.loss_dice: 0.9340
11/15 22:28:30 - mmengine - INFO - Iter(train) [89500/90000]  base_lr: 9.3381e-07 lr: 9.3381e-08  eta: 0:05:00  time: 0.5996  data_time: 0.0109  memory: 10656  grad_norm: 270.7571  loss: 13.8456  decode.loss_cls: 0.0469  decode.loss_mask: 0.4105  decode.loss_dice: 0.9127  decode.d0.loss_cls: 0.0702  decode.d0.loss_mask: 0.4216  decode.d0.loss_dice: 0.9768  decode.d1.loss_cls: 0.0528  decode.d1.loss_mask: 0.4069  decode.d1.loss_dice: 0.9344  decode.d2.loss_cls: 0.0492  decode.d2.loss_mask: 0.4113  decode.d2.loss_dice: 0.9242  decode.d3.loss_cls: 0.0495  decode.d3.loss_mask: 0.4037  decode.d3.loss_dice: 0.9226  decode.d4.loss_cls: 0.0588  decode.d4.loss_mask: 0.4088  decode.d4.loss_dice: 0.9332  decode.d5.loss_cls: 0.0428  decode.d5.loss_mask: 0.4102  decode.d5.loss_dice: 0.9083  decode.d6.loss_cls: 0.0440  decode.d6.loss_mask: 0.4097  decode.d6.loss_dice: 0.9011  decode.d7.loss_cls: 0.0448  decode.d7.loss_mask: 0.4110  decode.d7.loss_dice: 0.9122  decode.d8.loss_cls: 0.0503  decode.d8.loss_mask: 0.4045  decode.d8.loss_dice: 0.9127
11/15 22:28:59 - mmengine - INFO - Iter(train) [89550/90000]  base_lr: 8.4933e-07 lr: 8.4933e-08  eta: 0:04:30  time: 0.5991  data_time: 0.0105  memory: 10777  grad_norm: 281.8417  loss: 13.8192  decode.loss_cls: 0.0547  decode.loss_mask: 0.4287  decode.loss_dice: 0.8868  decode.d0.loss_cls: 0.0633  decode.d0.loss_mask: 0.4492  decode.d0.loss_dice: 0.9361  decode.d1.loss_cls: 0.0487  decode.d1.loss_mask: 0.4381  decode.d1.loss_dice: 0.8997  decode.d2.loss_cls: 0.0512  decode.d2.loss_mask: 0.4338  decode.d2.loss_dice: 0.8828  decode.d3.loss_cls: 0.0571  decode.d3.loss_mask: 0.4300  decode.d3.loss_dice: 0.8905  decode.d4.loss_cls: 0.0542  decode.d4.loss_mask: 0.4330  decode.d4.loss_dice: 0.8513  decode.d5.loss_cls: 0.0480  decode.d5.loss_mask: 0.4397  decode.d5.loss_dice: 0.9004  decode.d6.loss_cls: 0.0563  decode.d6.loss_mask: 0.4300  decode.d6.loss_dice: 0.8819  decode.d7.loss_cls: 0.0640  decode.d7.loss_mask: 0.4321  decode.d7.loss_dice: 0.9072  decode.d8.loss_cls: 0.0587  decode.d8.loss_mask: 0.4352  decode.d8.loss_dice: 0.8763
11/15 22:29:29 - mmengine - INFO - Iter(train) [89600/90000]  base_lr: 7.6391e-07 lr: 7.6391e-08  eta: 0:04:00  time: 0.6015  data_time: 0.0108  memory: 10713  grad_norm: 366.9636  loss: 16.2986  decode.loss_cls: 0.0752  decode.loss_mask: 0.4817  decode.loss_dice: 1.0371  decode.d0.loss_cls: 0.0969  decode.d0.loss_mask: 0.5032  decode.d0.loss_dice: 1.1770  decode.d1.loss_cls: 0.0805  decode.d1.loss_mask: 0.5001  decode.d1.loss_dice: 1.0787  decode.d2.loss_cls: 0.0891  decode.d2.loss_mask: 0.4857  decode.d2.loss_dice: 1.0770  decode.d3.loss_cls: 0.0769  decode.d3.loss_mask: 0.4776  decode.d3.loss_dice: 1.0399  decode.d4.loss_cls: 0.0858  decode.d4.loss_mask: 0.4691  decode.d4.loss_dice: 1.0251  decode.d5.loss_cls: 0.0888  decode.d5.loss_mask: 0.4648  decode.d5.loss_dice: 1.0443  decode.d6.loss_cls: 0.0756  decode.d6.loss_mask: 0.4786  decode.d6.loss_dice: 1.0741  decode.d7.loss_cls: 0.0773  decode.d7.loss_mask: 0.4881  decode.d7.loss_dice: 1.0621  decode.d8.loss_cls: 0.0788  decode.d8.loss_mask: 0.4823  decode.d8.loss_dice: 1.0271
11/15 22:29:59 - mmengine - INFO - Iter(train) [89650/90000]  base_lr: 6.7740e-07 lr: 6.7740e-08  eta: 0:03:30  time: 0.5993  data_time: 0.0111  memory: 10675  grad_norm: 297.3116  loss: 15.8096  decode.loss_cls: 0.0763  decode.loss_mask: 0.4609  decode.loss_dice: 1.0297  decode.d0.loss_cls: 0.1123  decode.d0.loss_mask: 0.4780  decode.d0.loss_dice: 1.1226  decode.d1.loss_cls: 0.0813  decode.d1.loss_mask: 0.4428  decode.d1.loss_dice: 1.0312  decode.d2.loss_cls: 0.0774  decode.d2.loss_mask: 0.4464  decode.d2.loss_dice: 1.0619  decode.d3.loss_cls: 0.0792  decode.d3.loss_mask: 0.4480  decode.d3.loss_dice: 1.0454  decode.d4.loss_cls: 0.0752  decode.d4.loss_mask: 0.4423  decode.d4.loss_dice: 1.0456  decode.d5.loss_cls: 0.0768  decode.d5.loss_mask: 0.4434  decode.d5.loss_dice: 1.0417  decode.d6.loss_cls: 0.0787  decode.d6.loss_mask: 0.4404  decode.d6.loss_dice: 1.0333  decode.d7.loss_cls: 0.0822  decode.d7.loss_mask: 0.4455  decode.d7.loss_dice: 1.0472  decode.d8.loss_cls: 0.0836  decode.d8.loss_mask: 0.4435  decode.d8.loss_dice: 1.0368
11/15 22:30:29 - mmengine - INFO - Iter(train) [89700/90000]  base_lr: 5.8965e-07 lr: 5.8965e-08  eta: 0:03:00  time: 0.5989  data_time: 0.0107  memory: 10713  grad_norm: 542.6002  loss: 15.6568  decode.loss_cls: 0.0596  decode.loss_mask: 0.4359  decode.loss_dice: 1.0124  decode.d0.loss_cls: 0.1074  decode.d0.loss_mask: 0.4488  decode.d0.loss_dice: 1.1137  decode.d1.loss_cls: 0.0773  decode.d1.loss_mask: 0.4447  decode.d1.loss_dice: 1.0585  decode.d2.loss_cls: 0.0874  decode.d2.loss_mask: 0.4357  decode.d2.loss_dice: 1.0414  decode.d3.loss_cls: 0.0836  decode.d3.loss_mask: 0.4360  decode.d3.loss_dice: 1.0167  decode.d4.loss_cls: 0.0777  decode.d4.loss_mask: 0.4394  decode.d4.loss_dice: 1.0884  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.4391  decode.d5.loss_dice: 1.0604  decode.d6.loss_cls: 0.0718  decode.d6.loss_mask: 0.4204  decode.d6.loss_dice: 1.0469  decode.d7.loss_cls: 0.0781  decode.d7.loss_mask: 0.4259  decode.d7.loss_dice: 1.0351  decode.d8.loss_cls: 0.0726  decode.d8.loss_mask: 0.4367  decode.d8.loss_dice: 1.0388
11/15 22:30:59 - mmengine - INFO - Iter(train) [89750/90000]  base_lr: 5.0042e-07 lr: 5.0042e-08  eta: 0:02:30  time: 0.5983  data_time: 0.0106  memory: 10692  grad_norm: 280.3053  loss: 14.1524  decode.loss_cls: 0.0495  decode.loss_mask: 0.4448  decode.loss_dice: 0.8941  decode.d0.loss_cls: 0.0766  decode.d0.loss_mask: 0.4581  decode.d0.loss_dice: 0.9744  decode.d1.loss_cls: 0.0574  decode.d1.loss_mask: 0.4456  decode.d1.loss_dice: 0.9281  decode.d2.loss_cls: 0.0603  decode.d2.loss_mask: 0.4325  decode.d2.loss_dice: 0.9203  decode.d3.loss_cls: 0.0412  decode.d3.loss_mask: 0.4534  decode.d3.loss_dice: 0.9044  decode.d4.loss_cls: 0.0484  decode.d4.loss_mask: 0.4522  decode.d4.loss_dice: 0.9299  decode.d5.loss_cls: 0.0405  decode.d5.loss_mask: 0.4512  decode.d5.loss_dice: 0.9079  decode.d6.loss_cls: 0.0521  decode.d6.loss_mask: 0.4428  decode.d6.loss_dice: 0.8997  decode.d7.loss_cls: 0.0513  decode.d7.loss_mask: 0.4443  decode.d7.loss_dice: 0.8945  decode.d8.loss_cls: 0.0506  decode.d8.loss_mask: 0.4447  decode.d8.loss_dice: 0.9017
11/15 22:31:30 - mmengine - INFO - Iter(train) [89800/90000]  base_lr: 4.0937e-07 lr: 4.0937e-08  eta: 0:02:00  time: 0.6014  data_time: 0.0108  memory: 10692  grad_norm: 248.8395  loss: 13.7077  decode.loss_cls: 0.0676  decode.loss_mask: 0.3692  decode.loss_dice: 0.9209  decode.d0.loss_cls: 0.0816  decode.d0.loss_mask: 0.3851  decode.d0.loss_dice: 1.0291  decode.d1.loss_cls: 0.0544  decode.d1.loss_mask: 0.3748  decode.d1.loss_dice: 0.9592  decode.d2.loss_cls: 0.0533  decode.d2.loss_mask: 0.3713  decode.d2.loss_dice: 0.9519  decode.d3.loss_cls: 0.0510  decode.d3.loss_mask: 0.3693  decode.d3.loss_dice: 0.9394  decode.d4.loss_cls: 0.0527  decode.d4.loss_mask: 0.3678  decode.d4.loss_dice: 0.9146  decode.d5.loss_cls: 0.0541  decode.d5.loss_mask: 0.3727  decode.d5.loss_dice: 0.8938  decode.d6.loss_cls: 0.0515  decode.d6.loss_mask: 0.3743  decode.d6.loss_dice: 0.9375  decode.d7.loss_cls: 0.0650  decode.d7.loss_mask: 0.3747  decode.d7.loss_dice: 0.9246  decode.d8.loss_cls: 0.0508  decode.d8.loss_mask: 0.3732  decode.d8.loss_dice: 0.9223
11/15 22:32:00 - mmengine - INFO - Iter(train) [89850/90000]  base_lr: 3.1599e-07 lr: 3.1599e-08  eta: 0:01:30  time: 0.5995  data_time: 0.0108  memory: 10692  grad_norm: 371.4790  loss: 14.1195  decode.loss_cls: 0.0450  decode.loss_mask: 0.3589  decode.loss_dice: 0.9841  decode.d0.loss_cls: 0.0788  decode.d0.loss_mask: 0.3753  decode.d0.loss_dice: 1.0910  decode.d1.loss_cls: 0.0412  decode.d1.loss_mask: 0.3691  decode.d1.loss_dice: 1.0200  decode.d2.loss_cls: 0.0437  decode.d2.loss_mask: 0.3583  decode.d2.loss_dice: 0.9970  decode.d3.loss_cls: 0.0461  decode.d3.loss_mask: 0.3596  decode.d3.loss_dice: 1.0152  decode.d4.loss_cls: 0.0474  decode.d4.loss_mask: 0.3572  decode.d4.loss_dice: 0.9969  decode.d5.loss_cls: 0.0448  decode.d5.loss_mask: 0.3576  decode.d5.loss_dice: 0.9809  decode.d6.loss_cls: 0.0425  decode.d6.loss_mask: 0.3563  decode.d6.loss_dice: 0.9843  decode.d7.loss_cls: 0.0364  decode.d7.loss_mask: 0.3601  decode.d7.loss_dice: 0.9832  decode.d8.loss_cls: 0.0474  decode.d8.loss_mask: 0.3576  decode.d8.loss_dice: 0.9834
11/15 22:32:30 - mmengine - INFO - Iter(train) [89900/90000]  base_lr: 2.1937e-07 lr: 2.1937e-08  eta: 0:01:00  time: 0.6030  data_time: 0.0110  memory: 10675  grad_norm: 358.8224  loss: 15.0198  decode.loss_cls: 0.0507  decode.loss_mask: 0.4836  decode.loss_dice: 0.9482  decode.d0.loss_cls: 0.0715  decode.d0.loss_mask: 0.5332  decode.d0.loss_dice: 1.0145  decode.d1.loss_cls: 0.0456  decode.d1.loss_mask: 0.4886  decode.d1.loss_dice: 0.9729  decode.d2.loss_cls: 0.0436  decode.d2.loss_mask: 0.4837  decode.d2.loss_dice: 0.9494  decode.d3.loss_cls: 0.0343  decode.d3.loss_mask: 0.4859  decode.d3.loss_dice: 0.9702  decode.d4.loss_cls: 0.0426  decode.d4.loss_mask: 0.4821  decode.d4.loss_dice: 0.9525  decode.d5.loss_cls: 0.0395  decode.d5.loss_mask: 0.4867  decode.d5.loss_dice: 0.9570  decode.d6.loss_cls: 0.0345  decode.d6.loss_mask: 0.4821  decode.d6.loss_dice: 0.9737  decode.d7.loss_cls: 0.0334  decode.d7.loss_mask: 0.4859  decode.d7.loss_dice: 0.9794  decode.d8.loss_cls: 0.0388  decode.d8.loss_mask: 0.4869  decode.d8.loss_dice: 0.9688
11/15 22:33:00 - mmengine - INFO - Iter(train) [89950/90000]  base_lr: 1.1756e-07 lr: 1.1756e-08  eta: 0:00:30  time: 0.6048  data_time: 0.0111  memory: 10692  grad_norm: 517.1727  loss: 15.4863  decode.loss_cls: 0.0677  decode.loss_mask: 0.4484  decode.loss_dice: 1.0071  decode.d0.loss_cls: 0.0761  decode.d0.loss_mask: 0.4872  decode.d0.loss_dice: 1.1693  decode.d1.loss_cls: 0.0683  decode.d1.loss_mask: 0.4540  decode.d1.loss_dice: 1.0488  decode.d2.loss_cls: 0.0630  decode.d2.loss_mask: 0.4490  decode.d2.loss_dice: 1.0453  decode.d3.loss_cls: 0.0579  decode.d3.loss_mask: 0.4468  decode.d3.loss_dice: 1.0190  decode.d4.loss_cls: 0.0650  decode.d4.loss_mask: 0.4405  decode.d4.loss_dice: 1.0026  decode.d5.loss_cls: 0.0563  decode.d5.loss_mask: 0.4509  decode.d5.loss_dice: 1.0173  decode.d6.loss_cls: 0.0587  decode.d6.loss_mask: 0.4449  decode.d6.loss_dice: 1.0131  decode.d7.loss_cls: 0.0548  decode.d7.loss_mask: 0.4488  decode.d7.loss_dice: 1.0169  decode.d8.loss_cls: 0.0625  decode.d8.loss_mask: 0.4443  decode.d8.loss_dice: 1.0018
11/15 22:33:30 - mmengine - INFO - Exp name: mask2former_swin-b-in1k-384x384-pre_8xb2-90k_cityscapes-512x1024_20241115_064336
11/15 22:33:30 - mmengine - INFO - Iter(train) [90000/90000]  base_lr: 0.0000e+00 lr: 0.0000e+00  eta: 0:00:00  time: 0.5995  data_time: 0.0106  memory: 10692  grad_norm: 243.5052  loss: 14.2342  decode.loss_cls: 0.0473  decode.loss_mask: 0.4494  decode.loss_dice: 0.8972  decode.d0.loss_cls: 0.0669  decode.d0.loss_mask: 0.4641  decode.d0.loss_dice: 0.9764  decode.d1.loss_cls: 0.0479  decode.d1.loss_mask: 0.4481  decode.d1.loss_dice: 0.9399  decode.d2.loss_cls: 0.0522  decode.d2.loss_mask: 0.4451  decode.d2.loss_dice: 0.9068  decode.d3.loss_cls: 0.0405  decode.d3.loss_mask: 0.4504  decode.d3.loss_dice: 0.9236  decode.d4.loss_cls: 0.0405  decode.d4.loss_mask: 0.4492  decode.d4.loss_dice: 0.8952  decode.d5.loss_cls: 0.0375  decode.d5.loss_mask: 0.4512  decode.d5.loss_dice: 0.9245  decode.d6.loss_cls: 0.0343  decode.d6.loss_mask: 0.4491  decode.d6.loss_dice: 0.9297  decode.d7.loss_cls: 0.0354  decode.d7.loss_mask: 0.4519  decode.d7.loss_dice: 0.9302  decode.d8.loss_cls: 0.0404  decode.d8.loss_mask: 0.4516  decode.d8.loss_dice: 0.9577
11/15 22:33:30 - mmengine - INFO - Saving checkpoint at 90000 iterations
11/15 22:33:48 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:21  time: 0.3086  data_time: 0.0040  memory: 4095  
11/15 22:34:04 - mmengine - INFO - Iter(val) [100/500]    eta: 0:02:04  time: 0.3083  data_time: 0.0042  memory: 4095  
11/15 22:34:19 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:48  time: 0.3081  data_time: 0.0040  memory: 4095  
11/15 22:34:35 - mmengine - INFO - Iter(val) [200/500]    eta: 0:01:32  time: 0.3082  data_time: 0.0041  memory: 4095  
11/15 22:34:50 - mmengine - INFO - Iter(val) [250/500]    eta: 0:01:17  time: 0.3083  data_time: 0.0038  memory: 4095  
11/15 22:35:05 - mmengine - INFO - Iter(val) [300/500]    eta: 0:01:01  time: 0.3084  data_time: 0.0039  memory: 4095  
11/15 22:35:21 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:46  time: 0.3088  data_time: 0.0041  memory: 4095  
11/15 22:35:36 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:30  time: 0.3083  data_time: 0.0038  memory: 4095  
11/15 22:35:52 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:15  time: 0.3094  data_time: 0.0042  memory: 4095  
11/15 22:36:07 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.3086  data_time: 0.0037  memory: 4095  
11/15 22:36:07 - mmengine - INFO - per class results:
11/15 22:36:07 - mmengine - INFO - 
+---------------+-------+-------+
|     Class     |  IoU  |  Acc  |
+---------------+-------+-------+
|      road     | 98.17 | 98.58 |
|    sidewalk   | 86.24 | 94.33 |
|    building   | 93.21 | 96.66 |
|      wall     | 65.25 |  77.8 |
|     fence     | 62.46 |  76.2 |
|      pole     | 68.85 | 81.14 |
| traffic light |  73.0 | 81.81 |
|  traffic sign | 81.89 | 88.46 |
|   vegetation  | 92.63 | 96.46 |
|    terrain    | 66.69 | 82.48 |
|      sky      | 95.02 | 97.27 |
|     person    | 83.05 | 90.47 |
|     rider     | 66.34 | 81.19 |
|      car      | 95.45 |  97.9 |
|     truck     | 83.25 | 91.49 |
|      bus      |  86.9 | 90.16 |
|     train     | 73.87 | 92.15 |
|   motorcycle  | 68.11 | 82.05 |
|    bicycle    | 79.48 | 88.93 |
+---------------+-------+-------+
11/15 22:36:07 - mmengine - INFO - Iter(val) [500/500]    aAcc: 96.3600  mIoU: 79.9900  mAcc: 88.7100  data_time: 0.0044  time: 0.3090
/var/spool/slurmd/job24675312/slurm_script: line 21: date +%s: syntax error: operand expected (error token is "%s")
Runtime:

============================= JOB FEEDBACK =============================

NodeName=uc2n484
Job ID: 24675312
Cluster: uc2
User/Group: ma_dschader/ma_ma
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 16
CPU Utilized: 21:09:44
CPU Efficiency: 8.31% of 10-14:44:32 core-walltime
Job Wall-clock time: 15:55:17
Memory Utilized: 8.15 GB
Memory Efficiency: 8.15% of 100.00 GB
