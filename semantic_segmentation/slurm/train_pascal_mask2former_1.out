Started at Sun May 26 10:51:07 CEST 2024
05/26 10:53:24 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.10.14 (main, Mar 21 2024, 16:24:04) [GCC 11.2.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1210821211
    GPU 0: Tesla V100-SXM2-32GB
    CUDA_HOME: /opt/bwhpc/common/devel/cuda/11.7
    NVCC: Cuda compilation tools, release 11.7, V11.7.99
    GCC: gcc (GCC) 8.5.0 20210514 (Red Hat 8.5.0-18)
    PyTorch: 1.13.1
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201402
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.6.0 (Git Hash 52b5f107dd9cf10910aaa19cb47f3abf9b349815)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.7
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.5
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.7, CUDNN_VERSION=8.5.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.13.1, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.14.1
    OpenCV: 4.9.0
    MMEngine: 0.10.4

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1210821211
    Distributed launcher: none
    Distributed training: False
    GPU number: 1
------------------------------------------------------------

05/26 10:53:25 - mmengine - INFO - Config:
auto_scale_lr = dict(base_batch_size=16, enable=False)
backbone_embed_multi = dict(decay_mult=0.0, lr_mult=0.1)
backbone_norm_multi = dict(decay_mult=0.0, lr_mult=0.1)
crop_size = (
    512,
    512,
)
custom_imports = dict(allow_failed_imports=False, imports='mmdet.models')
custom_keys = dict({
    'absolute_pos_embed':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone':
    dict(decay_mult=1.0, lr_mult=0.1),
    'backbone.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.patch_embed.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.0.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.1.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.2.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.3.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.4.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.blocks.5.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.2.downsample.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.0.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'backbone.stages.3.blocks.1.norm':
    dict(decay_mult=0.0, lr_mult=0.1),
    'level_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_embed':
    dict(decay_mult=0.0, lr_mult=1.0),
    'query_feat':
    dict(decay_mult=0.0, lr_mult=1.0),
    'relative_position_bias_table':
    dict(decay_mult=0.0, lr_mult=0.1)
})
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        512,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    test_cfg=dict(size_divisor=32),
    type='SegDataPreProcessor')
data_root = 'data/VOCdevkit/VOC2012'
dataset_aug = dict(
    ann_file='ImageSets/Segmentation/aug.txt',
    data_prefix=dict(
        img_path='JPEGImages', seg_map_path='SegmentationClassAug'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_train = dict(
    ann_file='ImageSets/Segmentation/train.txt',
    data_prefix=dict(img_path='JPEGImages', seg_map_path='SegmentationClass'),
    data_root='data/VOCdevkit/VOC2012',
    pipeline=[
        dict(type='LoadImageFromFile'),
        dict(type='LoadAnnotations'),
        dict(
            keep_ratio=True,
            ratio_range=(
                0.5,
                2.0,
            ),
            scale=(
                2048,
                512,
            ),
            type='RandomResize'),
        dict(cat_max_ratio=0.75, crop_size=(
            512,
            512,
        ), type='RandomCrop'),
        dict(prob=0.5, type='RandomFlip'),
        dict(type='PhotoMetricDistortion'),
        dict(size=(
            512,
            512,
        ), type='Pad'),
        dict(type='PackSegInputs'),
    ],
    type='PascalVOCDataset')
dataset_type = 'PascalVOCDataset'
default_hooks = dict(
    checkpoint=dict(
        by_epoch=False, interval=5000, save_best='mIoU',
        type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
depths = [
    2,
    2,
    6,
    2,
]
embed_multi = dict(decay_mult=0.0, lr_mult=1.0)
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'none'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
model = dict(
    backbone=dict(
        attn_drop_rate=0.0,
        depths=[
            2,
            2,
            6,
            2,
        ],
        drop_path_rate=0.3,
        drop_rate=0.0,
        embed_dims=96,
        frozen_stages=-1,
        init_cfg=dict(
            checkpoint=
            'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth',
            type='Pretrained'),
        mlp_ratio=4,
        num_heads=[
            3,
            6,
            12,
            24,
        ],
        out_indices=(
            0,
            1,
            2,
            3,
        ),
        patch_norm=True,
        qk_scale=None,
        qkv_bias=True,
        type='SwinTransformer',
        window_size=7,
        with_cp=False),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        test_cfg=dict(size_divisor=32),
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        enforce_decoder_input_project=False,
        feat_channels=256,
        in_channels=[
            96,
            192,
            384,
            768,
        ],
        loss_cls=dict(
            class_weight=[
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                1.0,
                0.1,
            ],
            loss_weight=2.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=False),
        loss_dice=dict(
            activate=True,
            eps=1.0,
            loss_weight=5.0,
            naive_dice=True,
            reduction='mean',
            type='mmdet.DiceLoss',
            use_sigmoid=True),
        loss_mask=dict(
            loss_weight=5.0,
            reduction='mean',
            type='mmdet.CrossEntropyLoss',
            use_sigmoid=True),
        num_classes=21,
        num_queries=100,
        num_transformer_feat_level=3,
        out_channels=256,
        pixel_decoder=dict(
            act_cfg=dict(type='ReLU'),
            encoder=dict(
                init_cfg=None,
                layer_cfg=dict(
                    ffn_cfg=dict(
                        act_cfg=dict(inplace=True, type='ReLU'),
                        embed_dims=256,
                        feedforward_channels=1024,
                        ffn_drop=0.0,
                        num_fcs=2),
                    self_attn_cfg=dict(
                        batch_first=True,
                        dropout=0.0,
                        embed_dims=256,
                        im2col_step=64,
                        init_cfg=None,
                        norm_cfg=None,
                        num_heads=8,
                        num_levels=3,
                        num_points=4)),
                num_layers=6),
            init_cfg=None,
            norm_cfg=dict(num_groups=32, type='GN'),
            num_outs=3,
            positional_encoding=dict(normalize=True, num_feats=128),
            type='mmdet.MSDeformAttnPixelDecoder'),
        positional_encoding=dict(normalize=True, num_feats=128),
        strides=[
            4,
            8,
            16,
            32,
        ],
        train_cfg=dict(
            assigner=dict(
                match_costs=[
                    dict(type='mmdet.ClassificationCost', weight=2.0),
                    dict(
                        type='mmdet.CrossEntropyLossCost',
                        use_sigmoid=True,
                        weight=5.0),
                    dict(
                        eps=1.0,
                        pred_act=True,
                        type='mmdet.DiceCost',
                        weight=5.0),
                ],
                type='mmdet.HungarianAssigner'),
            importance_sample_ratio=0.75,
            num_points=12544,
            oversample_ratio=3.0,
            sampler=dict(type='mmdet.MaskPseudoSampler')),
        transformer_decoder=dict(
            init_cfg=None,
            layer_cfg=dict(
                cross_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0),
                ffn_cfg=dict(
                    act_cfg=dict(inplace=True, type='ReLU'),
                    add_identity=True,
                    dropout_layer=None,
                    embed_dims=256,
                    feedforward_channels=2048,
                    ffn_drop=0.0,
                    num_fcs=2),
                self_attn_cfg=dict(
                    attn_drop=0.0,
                    batch_first=True,
                    dropout_layer=None,
                    embed_dims=256,
                    num_heads=8,
                    proj_drop=0.0)),
            num_layers=9,
            return_intermediate=True),
        type='Mask2FormerHead'),
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
num_classes = 21
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.01, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ),
        eps=1e-08,
        lr=0.0001,
        type='AdamW',
        weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict({
            'absolute_pos_embed':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone':
            dict(decay_mult=1.0, lr_mult=0.1),
            'backbone.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.patch_embed.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.0.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.1.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.2.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.3.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.4.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.blocks.5.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.2.downsample.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.0.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'backbone.stages.3.blocks.1.norm':
            dict(decay_mult=0.0, lr_mult=0.1),
            'level_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_embed':
            dict(decay_mult=0.0, lr_mult=1.0),
            'query_feat':
            dict(decay_mult=0.0, lr_mult=1.0),
            'relative_position_bias_table':
            dict(decay_mult=0.0, lr_mult=0.1)
        }),
        norm_decay_mult=0.0),
    type='OptimWrapper')
optimizer = dict(
    betas=(
        0.9,
        0.999,
    ),
    eps=1e-08,
    lr=0.0001,
    type='AdamW',
    weight_decay=0.05)
param_scheduler = [
    dict(
        begin=0,
        by_epoch=False,
        end=160000,
        eta_min=0,
        power=0.9,
        type='PolyLR'),
]
pretrained = 'https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth'
resume = False
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        512,
    ), type='Resize'),
    dict(type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(
    max_iters=160000, type='IterBasedTrainLoop', val_interval=5000)
train_dataloader = dict(
    batch_size=4,
    dataset=dict(
        datasets=[
            dict(
                ann_file='ImageSets/Segmentation/train.txt',
                data_prefix=dict(
                    img_path='JPEGImages', seg_map_path='SegmentationClass'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
            dict(
                ann_file='ImageSets/Segmentation/aug.txt',
                data_prefix=dict(
                    img_path='JPEGImages',
                    seg_map_path='SegmentationClassAug'),
                data_root='data/VOCdevkit/VOC2012',
                pipeline=[
                    dict(type='LoadImageFromFile'),
                    dict(type='LoadAnnotations'),
                    dict(
                        keep_ratio=True,
                        ratio_range=(
                            0.5,
                            2.0,
                        ),
                        scale=(
                            2048,
                            512,
                        ),
                        type='RandomResize'),
                    dict(
                        cat_max_ratio=0.75,
                        crop_size=(
                            512,
                            512,
                        ),
                        type='RandomCrop'),
                    dict(prob=0.5, type='RandomFlip'),
                    dict(type='PhotoMetricDistortion'),
                    dict(size=(
                        512,
                        512,
                    ), type='Pad'),
                    dict(type='PackSegInputs'),
                ],
                type='PascalVOCDataset'),
        ],
        type='ConcatDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(size=(
        512,
        512,
    ), type='Pad'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        ann_file='ImageSets/Segmentation/val.txt',
        data_prefix=dict(
            img_path='JPEGImages', seg_map_path='SegmentationClass'),
        data_root='data/VOCdevkit/VOC2012',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='PascalVOCDataset'),
    num_workers=4,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = '../work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512'

/pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/ops_dcnv3/modules/dcnv3.py:20: UserWarning: Now, we support DCNv4 in InternImage.
  warnings.warn('Now, we support DCNv4 in InternImage.')
05/26 10:53:46 - mmengine - INFO - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
/pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/mmsegmentation/mmseg/engine/hooks/visualization_hook.py:60: UserWarning: The draw is False, it means that the hook for visualization will not take effect. The results will NOT be visualized or stored.
  warnings.warn('The draw is False, it means that the '
05/26 10:53:46 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.projection.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.patch_embed.norm.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm1.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.norm2.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.0.ffn.layers.1.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm1.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.norm2.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.blocks.1.ffn.layers.1.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.norm.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.0.downsample.reduction.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm1.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.norm2.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.0.ffn.layers.1.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm1.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.norm2.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.blocks.1.ffn.layers.1.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.norm.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.1.downsample.reduction.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm1.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.norm2.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.0.ffn.layers.1.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm1.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.norm2.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.1.ffn.layers.1.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm1.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.relative_position_bias_table:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.qkv.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.attn.w_msa.proj.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.norm2.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.0.0.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.2.ffn.layers.1.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm1.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.relative_position_bias_table:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.qkv.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.attn.w_msa.proj.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.norm2.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.0.0.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.3.ffn.layers.1.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm1.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.relative_position_bias_table:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.qkv.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.attn.w_msa.proj.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.norm2.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.0.0.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.4.ffn.layers.1.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm1.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.relative_position_bias_table:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.qkv.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.attn.w_msa.proj.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.norm2.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.0.0.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.blocks.5.ffn.layers.1.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.norm.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.2.downsample.reduction.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm1.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.relative_position_bias_table:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.qkv.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.attn.w_msa.proj.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.norm2.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.0.0.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.0.ffn.layers.1.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm1.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.relative_position_bias_table:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.qkv.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.attn.w_msa.proj.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.norm2.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.0.0.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.weight:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:weight_decay=0.05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.stages.3.blocks.1.ffn.layers.1.bias:decay_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm0.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm0.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm1.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm1.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm2.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm2.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm3.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr=1e-05
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:lr_mult=0.1
05/26 10:53:49 - mmengine - INFO - paramwise_options -- backbone.norm3.bias:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.transformer_decoder.post_norm.bias:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr=0.0001
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:lr_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.query_embed.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr=0.0001
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:lr_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.query_feat.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr=0.0001
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:weight_decay=0.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:lr_mult=1.0
05/26 10:53:49 - mmengine - INFO - paramwise_options -- decode_head.level_embed.weight:decay_mult=0.0
05/26 10:53:49 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Loads checkpoint by http backend from path: https://download.openmmlab.com/mmsegmentation/v0.5/pretrain/swin/swin_tiny_patch4_window7_224_20220317-1cdeb081.pth
05/26 10:53:51 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
05/26 10:53:51 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
05/26 10:53:51 - mmengine - INFO - Checkpoints will be saved to /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512.
/pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/miniconda3/envs/py310/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1670525541990/work/aten/src/ATen/native/TensorShape.cpp:3190.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
05/26 10:55:04 - mmengine - INFO - Iter(train) [    50/160000]  base_lr: 9.9972e-05 lr: 9.9972e-06  eta: 2 days, 16:55:45  time: 0.4060  data_time: 0.0090  memory: 13047  grad_norm: 202.1568  loss: 82.1459  decode.loss_cls: 1.9679  decode.loss_mask: 3.3167  decode.loss_dice: 3.2372  decode.d0.loss_cls: 6.5062  decode.d0.loss_mask: 2.7215  decode.d0.loss_dice: 2.9213  decode.d1.loss_cls: 1.7999  decode.d1.loss_mask: 2.7505  decode.d1.loss_dice: 2.8752  decode.d2.loss_cls: 1.7428  decode.d2.loss_mask: 2.7424  decode.d2.loss_dice: 2.9360  decode.d3.loss_cls: 1.7018  decode.d3.loss_mask: 2.7585  decode.d3.loss_dice: 3.0076  decode.d4.loss_cls: 1.7737  decode.d4.loss_mask: 2.7073  decode.d4.loss_dice: 2.9326  decode.d5.loss_cls: 1.8012  decode.d5.loss_mask: 2.7972  decode.d5.loss_dice: 2.9965  decode.d6.loss_cls: 1.8497  decode.d6.loss_mask: 2.7890  decode.d6.loss_dice: 3.0558  decode.d7.loss_cls: 1.9412  decode.d7.loss_mask: 3.0433  decode.d7.loss_dice: 3.0667  decode.d8.loss_cls: 1.9525  decode.d8.loss_mask: 3.2847  decode.d8.loss_dice: 3.1690
05/26 10:55:25 - mmengine - INFO - Iter(train) [   100/160000]  base_lr: 9.9944e-05 lr: 9.9944e-06  eta: 1 day, 17:27:09  time: 0.4054  data_time: 0.0088  memory: 5980  grad_norm: 626.0280  loss: 67.1758  decode.loss_cls: 1.6592  decode.loss_mask: 2.4166  decode.loss_dice: 2.4238  decode.d0.loss_cls: 6.3957  decode.d0.loss_mask: 2.3434  decode.d0.loss_dice: 2.2836  decode.d1.loss_cls: 1.5275  decode.d1.loss_mask: 2.4549  decode.d1.loss_dice: 2.2995  decode.d2.loss_cls: 1.4638  decode.d2.loss_mask: 2.4580  decode.d2.loss_dice: 2.3354  decode.d3.loss_cls: 1.5501  decode.d3.loss_mask: 2.4291  decode.d3.loss_dice: 2.2511  decode.d4.loss_cls: 1.5303  decode.d4.loss_mask: 2.3631  decode.d4.loss_dice: 2.2052  decode.d5.loss_cls: 1.5426  decode.d5.loss_mask: 2.3640  decode.d5.loss_dice: 2.2024  decode.d6.loss_cls: 1.5451  decode.d6.loss_mask: 2.3744  decode.d6.loss_dice: 2.3281  decode.d7.loss_cls: 1.5621  decode.d7.loss_mask: 2.3082  decode.d7.loss_dice: 2.2982  decode.d8.loss_cls: 1.5482  decode.d8.loss_mask: 2.3558  decode.d8.loss_dice: 2.3564
05/26 10:55:45 - mmengine - INFO - Iter(train) [   150/160000]  base_lr: 9.9916e-05 lr: 9.9916e-06  eta: 1 day, 9:37:45  time: 0.4059  data_time: 0.0084  memory: 5970  grad_norm: 747.6214  loss: 57.5459  decode.loss_cls: 1.3564  decode.loss_mask: 2.2804  decode.loss_dice: 1.6973  decode.d0.loss_cls: 6.2807  decode.d0.loss_mask: 2.0708  decode.d0.loss_dice: 1.7697  decode.d1.loss_cls: 1.2923  decode.d1.loss_mask: 2.1660  decode.d1.loss_dice: 1.7708  decode.d2.loss_cls: 1.2719  decode.d2.loss_mask: 2.1764  decode.d2.loss_dice: 1.7632  decode.d3.loss_cls: 1.3487  decode.d3.loss_mask: 2.1851  decode.d3.loss_dice: 1.7690  decode.d4.loss_cls: 1.3969  decode.d4.loss_mask: 2.1362  decode.d4.loss_dice: 1.7241  decode.d5.loss_cls: 1.3916  decode.d5.loss_mask: 2.1859  decode.d5.loss_dice: 1.6861  decode.d6.loss_cls: 1.3869  decode.d6.loss_mask: 2.1997  decode.d6.loss_dice: 1.6495  decode.d7.loss_cls: 1.4304  decode.d7.loss_mask: 2.2170  decode.d7.loss_dice: 1.7115  decode.d8.loss_cls: 1.3381  decode.d8.loss_mask: 2.1518  decode.d8.loss_dice: 1.7414
05/26 10:56:05 - mmengine - INFO - Iter(train) [   200/160000]  base_lr: 9.9888e-05 lr: 9.9888e-06  eta: 1 day, 5:42:43  time: 0.4058  data_time: 0.0085  memory: 5967  grad_norm: 800.4751  loss: 62.5697  decode.loss_cls: 1.4484  decode.loss_mask: 2.2136  decode.loss_dice: 2.0777  decode.d0.loss_cls: 6.1489  decode.d0.loss_mask: 2.1835  decode.d0.loss_dice: 2.0675  decode.d1.loss_cls: 1.4248  decode.d1.loss_mask: 2.2407  decode.d1.loss_dice: 2.1023  decode.d2.loss_cls: 1.4107  decode.d2.loss_mask: 2.2289  decode.d2.loss_dice: 2.0912  decode.d3.loss_cls: 1.4262  decode.d3.loss_mask: 2.2043  decode.d3.loss_dice: 2.1283  decode.d4.loss_cls: 1.4916  decode.d4.loss_mask: 2.2531  decode.d4.loss_dice: 2.1268  decode.d5.loss_cls: 1.4696  decode.d5.loss_mask: 2.2650  decode.d5.loss_dice: 2.1428  decode.d6.loss_cls: 1.5106  decode.d6.loss_mask: 2.2318  decode.d6.loss_dice: 2.0848  decode.d7.loss_cls: 1.4828  decode.d7.loss_mask: 2.2631  decode.d7.loss_dice: 2.0780  decode.d8.loss_cls: 1.4750  decode.d8.loss_mask: 2.2552  decode.d8.loss_dice: 2.0425
05/26 10:56:25 - mmengine - INFO - Iter(train) [   250/160000]  base_lr: 9.9860e-05 lr: 9.9860e-06  eta: 1 day, 3:21:36  time: 0.4057  data_time: 0.0085  memory: 5972  grad_norm: 1139.6129  loss: 60.4745  decode.loss_cls: 1.5309  decode.loss_mask: 2.1438  decode.loss_dice: 2.0092  decode.d0.loss_cls: 6.2145  decode.d0.loss_mask: 1.9991  decode.d0.loss_dice: 1.9512  decode.d1.loss_cls: 1.5518  decode.d1.loss_mask: 2.1165  decode.d1.loss_dice: 1.9466  decode.d2.loss_cls: 1.4753  decode.d2.loss_mask: 2.1581  decode.d2.loss_dice: 1.9493  decode.d3.loss_cls: 1.4017  decode.d3.loss_mask: 2.1455  decode.d3.loss_dice: 2.0101  decode.d4.loss_cls: 1.3368  decode.d4.loss_mask: 2.2125  decode.d4.loss_dice: 1.9555  decode.d5.loss_cls: 1.3251  decode.d5.loss_mask: 2.2268  decode.d5.loss_dice: 1.9649  decode.d6.loss_cls: 1.3560  decode.d6.loss_mask: 2.1898  decode.d6.loss_dice: 2.0605  decode.d7.loss_cls: 1.3838  decode.d7.loss_mask: 2.2183  decode.d7.loss_dice: 2.0327  decode.d8.loss_cls: 1.4441  decode.d8.loss_mask: 2.1895  decode.d8.loss_dice: 1.9745
05/26 10:56:46 - mmengine - INFO - Iter(train) [   300/160000]  base_lr: 9.9832e-05 lr: 9.9832e-06  eta: 1 day, 1:47:26  time: 0.4056  data_time: 0.0085  memory: 5970  grad_norm: 1203.7802  loss: 56.0298  decode.loss_cls: 1.3770  decode.loss_mask: 2.0772  decode.loss_dice: 1.7631  decode.d0.loss_cls: 6.0333  decode.d0.loss_mask: 1.9270  decode.d0.loss_dice: 1.8545  decode.d1.loss_cls: 1.3240  decode.d1.loss_mask: 2.0496  decode.d1.loss_dice: 1.7997  decode.d2.loss_cls: 1.2078  decode.d2.loss_mask: 2.0058  decode.d2.loss_dice: 1.8543  decode.d3.loss_cls: 1.1957  decode.d3.loss_mask: 2.0500  decode.d3.loss_dice: 1.8367  decode.d4.loss_cls: 1.1526  decode.d4.loss_mask: 2.1866  decode.d4.loss_dice: 1.8818  decode.d5.loss_cls: 1.1291  decode.d5.loss_mask: 2.0935  decode.d5.loss_dice: 1.8826  decode.d6.loss_cls: 1.1462  decode.d6.loss_mask: 2.2303  decode.d6.loss_dice: 1.7890  decode.d7.loss_cls: 1.2221  decode.d7.loss_mask: 2.0434  decode.d7.loss_dice: 1.7997  decode.d8.loss_cls: 1.2778  decode.d8.loss_mask: 2.0680  decode.d8.loss_dice: 1.7714
05/26 10:57:06 - mmengine - INFO - Iter(train) [   350/160000]  base_lr: 9.9804e-05 lr: 9.9804e-06  eta: 1 day, 0:40:47  time: 0.4049  data_time: 0.0085  memory: 5970  grad_norm: 1364.9944  loss: 52.7701  decode.loss_cls: 1.2890  decode.loss_mask: 1.9929  decode.loss_dice: 1.6740  decode.d0.loss_cls: 5.9491  decode.d0.loss_mask: 1.8286  decode.d0.loss_dice: 1.6319  decode.d1.loss_cls: 1.2343  decode.d1.loss_mask: 1.9415  decode.d1.loss_dice: 1.6496  decode.d2.loss_cls: 1.1354  decode.d2.loss_mask: 2.0517  decode.d2.loss_dice: 1.6160  decode.d3.loss_cls: 1.1131  decode.d3.loss_mask: 1.9690  decode.d3.loss_dice: 1.6162  decode.d4.loss_cls: 1.1850  decode.d4.loss_mask: 1.8974  decode.d4.loss_dice: 1.5259  decode.d5.loss_cls: 1.2111  decode.d5.loss_mask: 1.9883  decode.d5.loss_dice: 1.5329  decode.d6.loss_cls: 1.2580  decode.d6.loss_mask: 1.9751  decode.d6.loss_dice: 1.5898  decode.d7.loss_cls: 1.3299  decode.d7.loss_mask: 2.0226  decode.d7.loss_dice: 1.6219  decode.d8.loss_cls: 1.2915  decode.d8.loss_mask: 2.0129  decode.d8.loss_dice: 1.6355
05/26 10:57:26 - mmengine - INFO - Iter(train) [   400/160000]  base_lr: 9.9776e-05 lr: 9.9776e-06  eta: 23:50:00  time: 0.4047  data_time: 0.0084  memory: 5967  grad_norm: 1160.9733  loss: 55.6471  decode.loss_cls: 1.3054  decode.loss_mask: 2.2093  decode.loss_dice: 1.7925  decode.d0.loss_cls: 5.8497  decode.d0.loss_mask: 2.0123  decode.d0.loss_dice: 1.7379  decode.d1.loss_cls: 1.2109  decode.d1.loss_mask: 2.1427  decode.d1.loss_dice: 1.7304  decode.d2.loss_cls: 1.1717  decode.d2.loss_mask: 2.0907  decode.d2.loss_dice: 1.7384  decode.d3.loss_cls: 1.1449  decode.d3.loss_mask: 2.2086  decode.d3.loss_dice: 1.7710  decode.d4.loss_cls: 1.1320  decode.d4.loss_mask: 2.1500  decode.d4.loss_dice: 1.7756  decode.d5.loss_cls: 1.2186  decode.d5.loss_mask: 2.1236  decode.d5.loss_dice: 1.6859  decode.d6.loss_cls: 1.3151  decode.d6.loss_mask: 2.1073  decode.d6.loss_dice: 1.6902  decode.d7.loss_cls: 1.2175  decode.d7.loss_mask: 2.1906  decode.d7.loss_dice: 1.6672  decode.d8.loss_cls: 1.2151  decode.d8.loss_mask: 2.2570  decode.d8.loss_dice: 1.7849
05/26 10:57:47 - mmengine - INFO - Iter(train) [   450/160000]  base_lr: 9.9747e-05 lr: 9.9747e-06  eta: 23:10:33  time: 0.4055  data_time: 0.0084  memory: 5967  grad_norm: 817.5964  loss: 49.9684  decode.loss_cls: 1.1519  decode.loss_mask: 1.9056  decode.loss_dice: 1.4909  decode.d0.loss_cls: 5.7293  decode.d0.loss_mask: 1.8479  decode.d0.loss_dice: 1.5592  decode.d1.loss_cls: 1.1626  decode.d1.loss_mask: 1.8807  decode.d1.loss_dice: 1.4961  decode.d2.loss_cls: 1.1538  decode.d2.loss_mask: 1.8885  decode.d2.loss_dice: 1.5109  decode.d3.loss_cls: 1.1502  decode.d3.loss_mask: 1.8773  decode.d3.loss_dice: 1.4568  decode.d4.loss_cls: 1.1531  decode.d4.loss_mask: 1.9068  decode.d4.loss_dice: 1.4949  decode.d5.loss_cls: 1.2095  decode.d5.loss_mask: 1.9117  decode.d5.loss_dice: 1.5074  decode.d6.loss_cls: 1.1412  decode.d6.loss_mask: 1.9033  decode.d6.loss_dice: 1.4889  decode.d7.loss_cls: 1.1465  decode.d7.loss_mask: 1.8877  decode.d7.loss_dice: 1.4294  decode.d8.loss_cls: 1.1838  decode.d8.loss_mask: 1.8970  decode.d8.loss_dice: 1.4456
05/26 10:58:07 - mmengine - INFO - Iter(train) [   500/160000]  base_lr: 9.9719e-05 lr: 9.9719e-06  eta: 22:39:03  time: 0.4060  data_time: 0.0085  memory: 5967  grad_norm: 930.3476  loss: 52.4081  decode.loss_cls: 1.1366  decode.loss_mask: 1.9398  decode.loss_dice: 1.5742  decode.d0.loss_cls: 5.5934  decode.d0.loss_mask: 1.9163  decode.d0.loss_dice: 1.6057  decode.d1.loss_cls: 1.1658  decode.d1.loss_mask: 1.9625  decode.d1.loss_dice: 1.5817  decode.d2.loss_cls: 1.1883  decode.d2.loss_mask: 1.9906  decode.d2.loss_dice: 1.6076  decode.d3.loss_cls: 1.1485  decode.d3.loss_mask: 2.0438  decode.d3.loss_dice: 1.5866  decode.d4.loss_cls: 1.2023  decode.d4.loss_mask: 2.0054  decode.d4.loss_dice: 1.5989  decode.d5.loss_cls: 1.1715  decode.d5.loss_mask: 2.0533  decode.d5.loss_dice: 1.5859  decode.d6.loss_cls: 1.0929  decode.d6.loss_mask: 2.2029  decode.d6.loss_dice: 1.6927  decode.d7.loss_cls: 1.0610  decode.d7.loss_mask: 2.2516  decode.d7.loss_dice: 1.7123  decode.d8.loss_cls: 1.0838  decode.d8.loss_mask: 2.0388  decode.d8.loss_dice: 1.6132
05/26 10:58:27 - mmengine - INFO - Iter(train) [   550/160000]  base_lr: 9.9691e-05 lr: 9.9691e-06  eta: 22:13:12  time: 0.4055  data_time: 0.0084  memory: 5968  grad_norm: 1291.1443  loss: 52.9954  decode.loss_cls: 1.3226  decode.loss_mask: 1.9324  decode.loss_dice: 1.6648  decode.d0.loss_cls: 5.5255  decode.d0.loss_mask: 1.8620  decode.d0.loss_dice: 1.6277  decode.d1.loss_cls: 1.2084  decode.d1.loss_mask: 1.9388  decode.d1.loss_dice: 1.6293  decode.d2.loss_cls: 1.2532  decode.d2.loss_mask: 1.9281  decode.d2.loss_dice: 1.6571  decode.d3.loss_cls: 1.2943  decode.d3.loss_mask: 1.9700  decode.d3.loss_dice: 1.6200  decode.d4.loss_cls: 1.3542  decode.d4.loss_mask: 1.8807  decode.d4.loss_dice: 1.6211  decode.d5.loss_cls: 1.4119  decode.d5.loss_mask: 1.8812  decode.d5.loss_dice: 1.6541  decode.d6.loss_cls: 1.3056  decode.d6.loss_mask: 1.9040  decode.d6.loss_dice: 1.6638  decode.d7.loss_cls: 1.3293  decode.d7.loss_mask: 1.9412  decode.d7.loss_dice: 1.6940  decode.d8.loss_cls: 1.2918  decode.d8.loss_mask: 1.9364  decode.d8.loss_dice: 1.6922
05/26 10:58:47 - mmengine - INFO - Iter(train) [   600/160000]  base_lr: 9.9663e-05 lr: 9.9663e-06  eta: 21:51:29  time: 0.4058  data_time: 0.0084  memory: 5980  grad_norm: 1375.9798  loss: 48.7482  decode.loss_cls: 1.1531  decode.loss_mask: 1.8249  decode.loss_dice: 1.5641  decode.d0.loss_cls: 5.3624  decode.d0.loss_mask: 1.7050  decode.d0.loss_dice: 1.5921  decode.d1.loss_cls: 1.0821  decode.d1.loss_mask: 1.6836  decode.d1.loss_dice: 1.5001  decode.d2.loss_cls: 1.0751  decode.d2.loss_mask: 1.7279  decode.d2.loss_dice: 1.5140  decode.d3.loss_cls: 1.0979  decode.d3.loss_mask: 1.8085  decode.d3.loss_dice: 1.5140  decode.d4.loss_cls: 1.0475  decode.d4.loss_mask: 1.8288  decode.d4.loss_dice: 1.6074  decode.d5.loss_cls: 1.0545  decode.d5.loss_mask: 1.8455  decode.d5.loss_dice: 1.6623  decode.d6.loss_cls: 0.9945  decode.d6.loss_mask: 1.7932  decode.d6.loss_dice: 1.6584  decode.d7.loss_cls: 0.9695  decode.d7.loss_mask: 1.8619  decode.d7.loss_dice: 1.7328  decode.d8.loss_cls: 0.9861  decode.d8.loss_mask: 1.8393  decode.d8.loss_dice: 1.6616
05/26 10:59:08 - mmengine - INFO - Iter(train) [   650/160000]  base_lr: 9.9635e-05 lr: 9.9635e-06  eta: 21:33:06  time: 0.4054  data_time: 0.0084  memory: 5970  grad_norm: 721.6066  loss: 43.4937  decode.loss_cls: 0.9471  decode.loss_mask: 1.6654  decode.loss_dice: 1.3093  decode.d0.loss_cls: 5.2729  decode.d0.loss_mask: 1.5486  decode.d0.loss_dice: 1.3511  decode.d1.loss_cls: 0.9300  decode.d1.loss_mask: 1.6101  decode.d1.loss_dice: 1.3108  decode.d2.loss_cls: 0.9464  decode.d2.loss_mask: 1.6443  decode.d2.loss_dice: 1.3838  decode.d3.loss_cls: 0.9317  decode.d3.loss_mask: 1.6744  decode.d3.loss_dice: 1.3675  decode.d4.loss_cls: 0.9753  decode.d4.loss_mask: 1.6338  decode.d4.loss_dice: 1.3123  decode.d5.loss_cls: 0.9158  decode.d5.loss_mask: 1.6889  decode.d5.loss_dice: 1.3284  decode.d6.loss_cls: 0.9341  decode.d6.loss_mask: 1.6995  decode.d6.loss_dice: 1.2985  decode.d7.loss_cls: 0.9139  decode.d7.loss_mask: 1.6711  decode.d7.loss_dice: 1.3248  decode.d8.loss_cls: 0.8753  decode.d8.loss_mask: 1.6936  decode.d8.loss_dice: 1.3347
05/26 10:59:28 - mmengine - INFO - Iter(train) [   700/160000]  base_lr: 9.9607e-05 lr: 9.9607e-06  eta: 21:17:20  time: 0.4053  data_time: 0.0084  memory: 5970  grad_norm: 1248.4623  loss: 46.2670  decode.loss_cls: 1.0390  decode.loss_mask: 1.9639  decode.loss_dice: 1.3266  decode.d0.loss_cls: 5.1237  decode.d0.loss_mask: 1.8668  decode.d0.loss_dice: 1.3526  decode.d1.loss_cls: 1.0615  decode.d1.loss_mask: 1.8421  decode.d1.loss_dice: 1.3022  decode.d2.loss_cls: 0.9928  decode.d2.loss_mask: 1.8905  decode.d2.loss_dice: 1.3197  decode.d3.loss_cls: 1.0375  decode.d3.loss_mask: 1.8300  decode.d3.loss_dice: 1.2554  decode.d4.loss_cls: 1.0251  decode.d4.loss_mask: 1.8959  decode.d4.loss_dice: 1.2907  decode.d5.loss_cls: 1.0290  decode.d5.loss_mask: 1.8976  decode.d5.loss_dice: 1.2853  decode.d6.loss_cls: 1.0782  decode.d6.loss_mask: 1.8928  decode.d6.loss_dice: 1.2836  decode.d7.loss_cls: 1.0024  decode.d7.loss_mask: 1.8987  decode.d7.loss_dice: 1.2944  decode.d8.loss_cls: 0.9897  decode.d8.loss_mask: 1.9134  decode.d8.loss_dice: 1.2858
05/26 10:59:48 - mmengine - INFO - Iter(train) [   750/160000]  base_lr: 9.9579e-05 lr: 9.9579e-06  eta: 21:03:37  time: 0.4061  data_time: 0.0085  memory: 5966  grad_norm: 920.8554  loss: 53.9578  decode.loss_cls: 1.1643  decode.loss_mask: 2.1740  decode.loss_dice: 1.7275  decode.d0.loss_cls: 5.1508  decode.d0.loss_mask: 1.9712  decode.d0.loss_dice: 1.7128  decode.d1.loss_cls: 1.2538  decode.d1.loss_mask: 2.0371  decode.d1.loss_dice: 1.7341  decode.d2.loss_cls: 1.2739  decode.d2.loss_mask: 2.0286  decode.d2.loss_dice: 1.7276  decode.d3.loss_cls: 1.1883  decode.d3.loss_mask: 2.1399  decode.d3.loss_dice: 1.6808  decode.d4.loss_cls: 1.1296  decode.d4.loss_mask: 2.1074  decode.d4.loss_dice: 1.7327  decode.d5.loss_cls: 1.1041  decode.d5.loss_mask: 2.1242  decode.d5.loss_dice: 1.7423  decode.d6.loss_cls: 1.0710  decode.d6.loss_mask: 2.1778  decode.d6.loss_dice: 1.7602  decode.d7.loss_cls: 1.0634  decode.d7.loss_mask: 2.1658  decode.d7.loss_dice: 1.8294  decode.d8.loss_cls: 1.1254  decode.d8.loss_mask: 2.1201  decode.d8.loss_dice: 1.7395
05/26 11:00:09 - mmengine - INFO - Iter(train) [   800/160000]  base_lr: 9.9550e-05 lr: 9.9550e-06  eta: 20:51:35  time: 0.4053  data_time: 0.0084  memory: 5972  grad_norm: 1077.8281  loss: 49.3412  decode.loss_cls: 1.0645  decode.loss_mask: 1.8336  decode.loss_dice: 1.5349  decode.d0.loss_cls: 4.9994  decode.d0.loss_mask: 1.8008  decode.d0.loss_dice: 1.5936  decode.d1.loss_cls: 1.0942  decode.d1.loss_mask: 1.7869  decode.d1.loss_dice: 1.5702  decode.d2.loss_cls: 1.1054  decode.d2.loss_mask: 1.8491  decode.d2.loss_dice: 1.5656  decode.d3.loss_cls: 1.1493  decode.d3.loss_mask: 1.8310  decode.d3.loss_dice: 1.5846  decode.d4.loss_cls: 1.1227  decode.d4.loss_mask: 1.9104  decode.d4.loss_dice: 1.5934  decode.d5.loss_cls: 1.1098  decode.d5.loss_mask: 1.9116  decode.d5.loss_dice: 1.5859  decode.d6.loss_cls: 1.1899  decode.d6.loss_mask: 1.8494  decode.d6.loss_dice: 1.6133  decode.d7.loss_cls: 1.1044  decode.d7.loss_mask: 1.8943  decode.d7.loss_dice: 1.5612  decode.d8.loss_cls: 1.0647  decode.d8.loss_mask: 1.8900  decode.d8.loss_dice: 1.5771
05/26 11:00:29 - mmengine - INFO - Iter(train) [   850/160000]  base_lr: 9.9522e-05 lr: 9.9522e-06  eta: 20:40:53  time: 0.4046  data_time: 0.0084  memory: 5967  grad_norm: 1020.3779  loss: 48.6291  decode.loss_cls: 1.0598  decode.loss_mask: 1.8848  decode.loss_dice: 1.5320  decode.d0.loss_cls: 4.9299  decode.d0.loss_mask: 1.7937  decode.d0.loss_dice: 1.4874  decode.d1.loss_cls: 1.0776  decode.d1.loss_mask: 1.8983  decode.d1.loss_dice: 1.5181  decode.d2.loss_cls: 1.0643  decode.d2.loss_mask: 1.9397  decode.d2.loss_dice: 1.5549  decode.d3.loss_cls: 1.0586  decode.d3.loss_mask: 1.8946  decode.d3.loss_dice: 1.4761  decode.d4.loss_cls: 1.0747  decode.d4.loss_mask: 1.9035  decode.d4.loss_dice: 1.5267  decode.d5.loss_cls: 1.1395  decode.d5.loss_mask: 1.8427  decode.d5.loss_dice: 1.4999  decode.d6.loss_cls: 1.0271  decode.d6.loss_mask: 1.8971  decode.d6.loss_dice: 1.5854  decode.d7.loss_cls: 0.9972  decode.d7.loss_mask: 1.9100  decode.d7.loss_dice: 1.5688  decode.d8.loss_cls: 1.0335  decode.d8.loss_mask: 1.9149  decode.d8.loss_dice: 1.5382
05/26 11:00:49 - mmengine - INFO - Iter(train) [   900/160000]  base_lr: 9.9494e-05 lr: 9.9494e-06  eta: 20:31:19  time: 0.4057  data_time: 0.0091  memory: 5982  grad_norm: 1099.2837  loss: 49.4588  decode.loss_cls: 1.0934  decode.loss_mask: 1.8159  decode.loss_dice: 1.6239  decode.d0.loss_cls: 4.8341  decode.d0.loss_mask: 1.7884  decode.d0.loss_dice: 1.6844  decode.d1.loss_cls: 1.1563  decode.d1.loss_mask: 1.7618  decode.d1.loss_dice: 1.6222  decode.d2.loss_cls: 1.2110  decode.d2.loss_mask: 1.7620  decode.d2.loss_dice: 1.6180  decode.d3.loss_cls: 1.2457  decode.d3.loss_mask: 1.7674  decode.d3.loss_dice: 1.5855  decode.d4.loss_cls: 1.1795  decode.d4.loss_mask: 1.7963  decode.d4.loss_dice: 1.6765  decode.d5.loss_cls: 1.2009  decode.d5.loss_mask: 1.7699  decode.d5.loss_dice: 1.6301  decode.d6.loss_cls: 1.1326  decode.d6.loss_mask: 1.8062  decode.d6.loss_dice: 1.6248  decode.d7.loss_cls: 1.1141  decode.d7.loss_mask: 1.8585  decode.d7.loss_dice: 1.5939  decode.d8.loss_cls: 1.0787  decode.d8.loss_mask: 1.8092  decode.d8.loss_dice: 1.6173
05/26 11:01:09 - mmengine - INFO - Iter(train) [   950/160000]  base_lr: 9.9466e-05 lr: 9.9466e-06  eta: 20:22:44  time: 0.4049  data_time: 0.0083  memory: 5966  grad_norm: 922.0662  loss: 45.6200  decode.loss_cls: 1.1345  decode.loss_mask: 1.6584  decode.loss_dice: 1.5369  decode.d0.loss_cls: 4.6924  decode.d0.loss_mask: 1.5869  decode.d0.loss_dice: 1.5416  decode.d1.loss_cls: 1.0577  decode.d1.loss_mask: 1.5832  decode.d1.loss_dice: 1.4506  decode.d2.loss_cls: 1.1090  decode.d2.loss_mask: 1.5726  decode.d2.loss_dice: 1.4521  decode.d3.loss_cls: 1.0502  decode.d3.loss_mask: 1.6010  decode.d3.loss_dice: 1.4327  decode.d4.loss_cls: 1.0714  decode.d4.loss_mask: 1.6011  decode.d4.loss_dice: 1.5106  decode.d5.loss_cls: 1.0953  decode.d5.loss_mask: 1.5984  decode.d5.loss_dice: 1.4724  decode.d6.loss_cls: 1.1018  decode.d6.loss_mask: 1.6172  decode.d6.loss_dice: 1.5330  decode.d7.loss_cls: 1.1086  decode.d7.loss_mask: 1.6184  decode.d7.loss_dice: 1.5118  decode.d8.loss_cls: 1.1029  decode.d8.loss_mask: 1.6873  decode.d8.loss_dice: 1.5297
05/26 11:01:30 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 11:01:30 - mmengine - INFO - Iter(train) [  1000/160000]  base_lr: 9.9438e-05 lr: 9.9438e-06  eta: 20:15:03  time: 0.4057  data_time: 0.0084  memory: 5968  grad_norm: 974.3608  loss: 43.2553  decode.loss_cls: 0.9856  decode.loss_mask: 1.5959  decode.loss_dice: 1.3543  decode.d0.loss_cls: 4.5304  decode.d0.loss_mask: 1.5131  decode.d0.loss_dice: 1.4313  decode.d1.loss_cls: 1.0369  decode.d1.loss_mask: 1.5196  decode.d1.loss_dice: 1.4197  decode.d2.loss_cls: 1.0256  decode.d2.loss_mask: 1.5336  decode.d2.loss_dice: 1.3259  decode.d3.loss_cls: 0.9309  decode.d3.loss_mask: 1.5749  decode.d3.loss_dice: 1.3931  decode.d4.loss_cls: 1.0337  decode.d4.loss_mask: 1.6016  decode.d4.loss_dice: 1.4256  decode.d5.loss_cls: 1.0494  decode.d5.loss_mask: 1.6075  decode.d5.loss_dice: 1.3923  decode.d6.loss_cls: 1.0317  decode.d6.loss_mask: 1.5962  decode.d6.loss_dice: 1.4098  decode.d7.loss_cls: 1.0160  decode.d7.loss_mask: 1.5935  decode.d7.loss_dice: 1.3797  decode.d8.loss_cls: 1.0415  decode.d8.loss_mask: 1.5530  decode.d8.loss_dice: 1.3528
05/26 11:01:50 - mmengine - INFO - Iter(train) [  1050/160000]  base_lr: 9.9410e-05 lr: 9.9410e-06  eta: 20:08:02  time: 0.4052  data_time: 0.0083  memory: 5966  grad_norm: 2459.9552  loss: 45.1897  decode.loss_cls: 0.8056  decode.loss_mask: 1.9742  decode.loss_dice: 1.4669  decode.d0.loss_cls: 4.3758  decode.d0.loss_mask: 1.8134  decode.d0.loss_dice: 1.3877  decode.d1.loss_cls: 0.8720  decode.d1.loss_mask: 1.8561  decode.d1.loss_dice: 1.3741  decode.d2.loss_cls: 0.8968  decode.d2.loss_mask: 1.9425  decode.d2.loss_dice: 1.3794  decode.d3.loss_cls: 0.8476  decode.d3.loss_mask: 1.8974  decode.d3.loss_dice: 1.3513  decode.d4.loss_cls: 0.9744  decode.d4.loss_mask: 1.8136  decode.d4.loss_dice: 1.3547  decode.d5.loss_cls: 0.9395  decode.d5.loss_mask: 1.9308  decode.d5.loss_dice: 1.3632  decode.d6.loss_cls: 0.8585  decode.d6.loss_mask: 1.9187  decode.d6.loss_dice: 1.4108  decode.d7.loss_cls: 0.8754  decode.d7.loss_mask: 1.8681  decode.d7.loss_dice: 1.4074  decode.d8.loss_cls: 0.8148  decode.d8.loss_mask: 1.9541  decode.d8.loss_dice: 1.4650
05/26 11:02:10 - mmengine - INFO - Iter(train) [  1100/160000]  base_lr: 9.9382e-05 lr: 9.9382e-06  eta: 20:01:40  time: 0.4061  data_time: 0.0084  memory: 5969  grad_norm: 824.5944  loss: 47.1985  decode.loss_cls: 1.0436  decode.loss_mask: 1.6866  decode.loss_dice: 1.6127  decode.d0.loss_cls: 4.3245  decode.d0.loss_mask: 1.6882  decode.d0.loss_dice: 1.6706  decode.d1.loss_cls: 1.1206  decode.d1.loss_mask: 1.6284  decode.d1.loss_dice: 1.6137  decode.d2.loss_cls: 1.1103  decode.d2.loss_mask: 1.7337  decode.d2.loss_dice: 1.6129  decode.d3.loss_cls: 1.1149  decode.d3.loss_mask: 1.7004  decode.d3.loss_dice: 1.6755  decode.d4.loss_cls: 1.0834  decode.d4.loss_mask: 1.6585  decode.d4.loss_dice: 1.6318  decode.d5.loss_cls: 1.0839  decode.d5.loss_mask: 1.6662  decode.d5.loss_dice: 1.6218  decode.d6.loss_cls: 1.0671  decode.d6.loss_mask: 1.6441  decode.d6.loss_dice: 1.6103  decode.d7.loss_cls: 1.1151  decode.d7.loss_mask: 1.6879  decode.d7.loss_dice: 1.6220  decode.d8.loss_cls: 1.0954  decode.d8.loss_mask: 1.6377  decode.d8.loss_dice: 1.6369
05/26 11:02:31 - mmengine - INFO - Iter(train) [  1150/160000]  base_lr: 9.9353e-05 lr: 9.9353e-06  eta: 19:55:51  time: 0.4068  data_time: 0.0082  memory: 5972  grad_norm: 1003.3184  loss: 42.5674  decode.loss_cls: 0.8437  decode.loss_mask: 1.5802  decode.loss_dice: 1.3687  decode.d0.loss_cls: 4.1288  decode.d0.loss_mask: 1.5999  decode.d0.loss_dice: 1.4245  decode.d1.loss_cls: 0.9181  decode.d1.loss_mask: 1.5888  decode.d1.loss_dice: 1.3859  decode.d2.loss_cls: 0.9289  decode.d2.loss_mask: 1.6247  decode.d2.loss_dice: 1.3450  decode.d3.loss_cls: 0.8667  decode.d3.loss_mask: 1.6277  decode.d3.loss_dice: 1.3701  decode.d4.loss_cls: 0.8238  decode.d4.loss_mask: 1.7401  decode.d4.loss_dice: 1.3961  decode.d5.loss_cls: 0.8183  decode.d5.loss_mask: 1.7044  decode.d5.loss_dice: 1.4389  decode.d6.loss_cls: 0.8687  decode.d6.loss_mask: 1.7602  decode.d6.loss_dice: 1.5025  decode.d7.loss_cls: 0.8252  decode.d7.loss_mask: 1.7015  decode.d7.loss_dice: 1.5355  decode.d8.loss_cls: 0.8316  decode.d8.loss_mask: 1.6256  decode.d8.loss_dice: 1.3934
05/26 11:02:51 - mmengine - INFO - Iter(train) [  1200/160000]  base_lr: 9.9325e-05 lr: 9.9325e-06  eta: 19:50:26  time: 0.4049  data_time: 0.0083  memory: 5969  grad_norm: 722.7941  loss: 41.4325  decode.loss_cls: 0.8180  decode.loss_mask: 1.7361  decode.loss_dice: 1.2613  decode.d0.loss_cls: 4.0898  decode.d0.loss_mask: 1.5589  decode.d0.loss_dice: 1.2771  decode.d1.loss_cls: 0.8878  decode.d1.loss_mask: 1.6540  decode.d1.loss_dice: 1.2060  decode.d2.loss_cls: 0.9270  decode.d2.loss_mask: 1.6225  decode.d2.loss_dice: 1.2494  decode.d3.loss_cls: 0.8707  decode.d3.loss_mask: 1.6963  decode.d3.loss_dice: 1.2271  decode.d4.loss_cls: 0.9561  decode.d4.loss_mask: 1.6879  decode.d4.loss_dice: 1.2727  decode.d5.loss_cls: 0.9329  decode.d5.loss_mask: 1.7950  decode.d5.loss_dice: 1.2828  decode.d6.loss_cls: 0.9135  decode.d6.loss_mask: 1.6492  decode.d6.loss_dice: 1.2577  decode.d7.loss_cls: 0.8467  decode.d7.loss_mask: 1.7090  decode.d7.loss_dice: 1.2460  decode.d8.loss_cls: 0.8493  decode.d8.loss_mask: 1.7246  decode.d8.loss_dice: 1.2270
05/26 11:03:11 - mmengine - INFO - Iter(train) [  1250/160000]  base_lr: 9.9297e-05 lr: 9.9297e-06  eta: 19:45:28  time: 0.4063  data_time: 0.0084  memory: 5982  grad_norm: 780.9118  loss: 46.3831  decode.loss_cls: 0.9834  decode.loss_mask: 1.7074  decode.loss_dice: 1.6004  decode.d0.loss_cls: 3.9658  decode.d0.loss_mask: 1.6542  decode.d0.loss_dice: 1.6731  decode.d1.loss_cls: 1.0432  decode.d1.loss_mask: 1.6678  decode.d1.loss_dice: 1.5705  decode.d2.loss_cls: 1.1014  decode.d2.loss_mask: 1.6841  decode.d2.loss_dice: 1.6361  decode.d3.loss_cls: 1.0697  decode.d3.loss_mask: 1.6518  decode.d3.loss_dice: 1.5968  decode.d4.loss_cls: 1.0796  decode.d4.loss_mask: 1.7271  decode.d4.loss_dice: 1.7088  decode.d5.loss_cls: 0.9774  decode.d5.loss_mask: 1.7312  decode.d5.loss_dice: 1.5851  decode.d6.loss_cls: 1.0346  decode.d6.loss_mask: 1.6954  decode.d6.loss_dice: 1.6342  decode.d7.loss_cls: 1.0111  decode.d7.loss_mask: 1.7063  decode.d7.loss_dice: 1.6272  decode.d8.loss_cls: 0.9926  decode.d8.loss_mask: 1.6846  decode.d8.loss_dice: 1.5825
05/26 11:03:32 - mmengine - INFO - Iter(train) [  1300/160000]  base_lr: 9.9269e-05 lr: 9.9269e-06  eta: 19:40:53  time: 0.4062  data_time: 0.0083  memory: 5975  grad_norm: 1454.2134  loss: 42.0309  decode.loss_cls: 0.9117  decode.loss_mask: 1.5324  decode.loss_dice: 1.3845  decode.d0.loss_cls: 3.7870  decode.d0.loss_mask: 1.5331  decode.d0.loss_dice: 1.4914  decode.d1.loss_cls: 0.9610  decode.d1.loss_mask: 1.5529  decode.d1.loss_dice: 1.4251  decode.d2.loss_cls: 0.9982  decode.d2.loss_mask: 1.5792  decode.d2.loss_dice: 1.4030  decode.d3.loss_cls: 0.9084  decode.d3.loss_mask: 1.5834  decode.d3.loss_dice: 1.4469  decode.d4.loss_cls: 1.0070  decode.d4.loss_mask: 1.5757  decode.d4.loss_dice: 1.3547  decode.d5.loss_cls: 0.9940  decode.d5.loss_mask: 1.5441  decode.d5.loss_dice: 1.3437  decode.d6.loss_cls: 0.9184  decode.d6.loss_mask: 1.5870  decode.d6.loss_dice: 1.3742  decode.d7.loss_cls: 0.9031  decode.d7.loss_mask: 1.5935  decode.d7.loss_dice: 1.3819  decode.d8.loss_cls: 0.8820  decode.d8.loss_mask: 1.6778  decode.d8.loss_dice: 1.3958
05/26 11:03:52 - mmengine - INFO - Iter(train) [  1350/160000]  base_lr: 9.9241e-05 lr: 9.9241e-06  eta: 19:36:34  time: 0.4062  data_time: 0.0083  memory: 5967  grad_norm: 776.0618  loss: 40.8883  decode.loss_cls: 0.8691  decode.loss_mask: 1.4080  decode.loss_dice: 1.4572  decode.d0.loss_cls: 3.6563  decode.d0.loss_mask: 1.3674  decode.d0.loss_dice: 1.5372  decode.d1.loss_cls: 0.9168  decode.d1.loss_mask: 1.3968  decode.d1.loss_dice: 1.4753  decode.d2.loss_cls: 0.9444  decode.d2.loss_mask: 1.4070  decode.d2.loss_dice: 1.4966  decode.d3.loss_cls: 0.9278  decode.d3.loss_mask: 1.4118  decode.d3.loss_dice: 1.5278  decode.d4.loss_cls: 0.9827  decode.d4.loss_mask: 1.3739  decode.d4.loss_dice: 1.4752  decode.d5.loss_cls: 0.9106  decode.d5.loss_mask: 1.4147  decode.d5.loss_dice: 1.4942  decode.d6.loss_cls: 0.9132  decode.d6.loss_mask: 1.4030  decode.d6.loss_dice: 1.5097  decode.d7.loss_cls: 0.9691  decode.d7.loss_mask: 1.3970  decode.d7.loss_dice: 1.4977  decode.d8.loss_cls: 0.8619  decode.d8.loss_mask: 1.4005  decode.d8.loss_dice: 1.4855
05/26 11:04:12 - mmengine - INFO - Iter(train) [  1400/160000]  base_lr: 9.9213e-05 lr: 9.9213e-06  eta: 19:32:36  time: 0.4071  data_time: 0.0087  memory: 5967  grad_norm: 704.7070  loss: 40.8855  decode.loss_cls: 0.7787  decode.loss_mask: 1.5076  decode.loss_dice: 1.4926  decode.d0.loss_cls: 3.5110  decode.d0.loss_mask: 1.5333  decode.d0.loss_dice: 1.5364  decode.d1.loss_cls: 0.7864  decode.d1.loss_mask: 1.4923  decode.d1.loss_dice: 1.4385  decode.d2.loss_cls: 0.8201  decode.d2.loss_mask: 1.5306  decode.d2.loss_dice: 1.4908  decode.d3.loss_cls: 0.7917  decode.d3.loss_mask: 1.4864  decode.d3.loss_dice: 1.4385  decode.d4.loss_cls: 0.8179  decode.d4.loss_mask: 1.5058  decode.d4.loss_dice: 1.4354  decode.d5.loss_cls: 0.8250  decode.d5.loss_mask: 1.5565  decode.d5.loss_dice: 1.4523  decode.d6.loss_cls: 0.8112  decode.d6.loss_mask: 1.5593  decode.d6.loss_dice: 1.5323  decode.d7.loss_cls: 0.8470  decode.d7.loss_mask: 1.5574  decode.d7.loss_dice: 1.5579  decode.d8.loss_cls: 0.8074  decode.d8.loss_mask: 1.5086  decode.d8.loss_dice: 1.4768
05/26 11:04:33 - mmengine - INFO - Iter(train) [  1450/160000]  base_lr: 9.9185e-05 lr: 9.9185e-06  eta: 19:29:02  time: 0.4056  data_time: 0.0085  memory: 5967  grad_norm: 1315.2138  loss: 47.5321  decode.loss_cls: 1.1543  decode.loss_mask: 1.7261  decode.loss_dice: 1.5753  decode.d0.loss_cls: 3.5331  decode.d0.loss_mask: 1.7560  decode.d0.loss_dice: 1.6287  decode.d1.loss_cls: 1.0489  decode.d1.loss_mask: 1.7408  decode.d1.loss_dice: 1.5524  decode.d2.loss_cls: 1.1902  decode.d2.loss_mask: 1.7327  decode.d2.loss_dice: 1.5485  decode.d3.loss_cls: 1.2195  decode.d3.loss_mask: 1.7425  decode.d3.loss_dice: 1.5580  decode.d4.loss_cls: 1.1965  decode.d4.loss_mask: 1.7797  decode.d4.loss_dice: 1.5305  decode.d5.loss_cls: 1.2164  decode.d5.loss_mask: 1.8301  decode.d5.loss_dice: 1.6263  decode.d6.loss_cls: 1.2091  decode.d6.loss_mask: 1.7783  decode.d6.loss_dice: 1.6004  decode.d7.loss_cls: 1.1074  decode.d7.loss_mask: 1.8435  decode.d7.loss_dice: 1.6432  decode.d8.loss_cls: 1.1009  decode.d8.loss_mask: 1.7711  decode.d8.loss_dice: 1.5919
05/26 11:04:53 - mmengine - INFO - Iter(train) [  1500/160000]  base_lr: 9.9156e-05 lr: 9.9156e-06  eta: 19:25:23  time: 0.4055  data_time: 0.0086  memory: 5971  grad_norm: 1016.7639  loss: 42.6329  decode.loss_cls: 1.0786  decode.loss_mask: 1.5997  decode.loss_dice: 1.3780  decode.d0.loss_cls: 3.4527  decode.d0.loss_mask: 1.5148  decode.d0.loss_dice: 1.4416  decode.d1.loss_cls: 1.0374  decode.d1.loss_mask: 1.5516  decode.d1.loss_dice: 1.4300  decode.d2.loss_cls: 1.0128  decode.d2.loss_mask: 1.5670  decode.d2.loss_dice: 1.3365  decode.d3.loss_cls: 0.9859  decode.d3.loss_mask: 1.6241  decode.d3.loss_dice: 1.3676  decode.d4.loss_cls: 0.9934  decode.d4.loss_mask: 1.5601  decode.d4.loss_dice: 1.3708  decode.d5.loss_cls: 1.1083  decode.d5.loss_mask: 1.5966  decode.d5.loss_dice: 1.3769  decode.d6.loss_cls: 1.0246  decode.d6.loss_mask: 1.6060  decode.d6.loss_dice: 1.3742  decode.d7.loss_cls: 0.9972  decode.d7.loss_mask: 1.7126  decode.d7.loss_dice: 1.4067  decode.d8.loss_cls: 1.1000  decode.d8.loss_mask: 1.5830  decode.d8.loss_dice: 1.4443
05/26 11:05:13 - mmengine - INFO - Iter(train) [  1550/160000]  base_lr: 9.9128e-05 lr: 9.9128e-06  eta: 19:21:58  time: 0.4061  data_time: 0.0086  memory: 5967  grad_norm: 786.6216  loss: 43.3893  decode.loss_cls: 1.0127  decode.loss_mask: 1.7960  decode.loss_dice: 1.2987  decode.d0.loss_cls: 3.2464  decode.d0.loss_mask: 1.7569  decode.d0.loss_dice: 1.4226  decode.d1.loss_cls: 0.9871  decode.d1.loss_mask: 1.6983  decode.d1.loss_dice: 1.3070  decode.d2.loss_cls: 1.0638  decode.d2.loss_mask: 1.7230  decode.d2.loss_dice: 1.3243  decode.d3.loss_cls: 1.0377  decode.d3.loss_mask: 1.7450  decode.d3.loss_dice: 1.3185  decode.d4.loss_cls: 0.9913  decode.d4.loss_mask: 1.8035  decode.d4.loss_dice: 1.3285  decode.d5.loss_cls: 1.0395  decode.d5.loss_mask: 1.7770  decode.d5.loss_dice: 1.2946  decode.d6.loss_cls: 1.0743  decode.d6.loss_mask: 1.7636  decode.d6.loss_dice: 1.2882  decode.d7.loss_cls: 1.0254  decode.d7.loss_mask: 1.8474  decode.d7.loss_dice: 1.3517  decode.d8.loss_cls: 1.0345  decode.d8.loss_mask: 1.7359  decode.d8.loss_dice: 1.2958
05/26 11:05:33 - mmengine - INFO - Iter(train) [  1600/160000]  base_lr: 9.9100e-05 lr: 9.9100e-06  eta: 19:18:44  time: 0.4051  data_time: 0.0085  memory: 5974  grad_norm: 1366.0316  loss: 37.2107  decode.loss_cls: 0.8012  decode.loss_mask: 1.5551  decode.loss_dice: 1.1641  decode.d0.loss_cls: 3.1523  decode.d0.loss_mask: 1.4124  decode.d0.loss_dice: 1.2081  decode.d1.loss_cls: 0.8802  decode.d1.loss_mask: 1.3927  decode.d1.loss_dice: 1.1463  decode.d2.loss_cls: 0.9527  decode.d2.loss_mask: 1.3812  decode.d2.loss_dice: 1.0919  decode.d3.loss_cls: 1.0012  decode.d3.loss_mask: 1.4181  decode.d3.loss_dice: 1.1118  decode.d4.loss_cls: 0.9627  decode.d4.loss_mask: 1.4612  decode.d4.loss_dice: 1.1334  decode.d5.loss_cls: 0.9771  decode.d5.loss_mask: 1.4006  decode.d5.loss_dice: 1.1387  decode.d6.loss_cls: 0.9292  decode.d6.loss_mask: 1.4403  decode.d6.loss_dice: 1.1793  decode.d7.loss_cls: 0.8381  decode.d7.loss_mask: 1.4823  decode.d7.loss_dice: 1.1496  decode.d8.loss_cls: 0.8520  decode.d8.loss_mask: 1.4815  decode.d8.loss_dice: 1.1156
05/26 11:05:54 - mmengine - INFO - Iter(train) [  1650/160000]  base_lr: 9.9072e-05 lr: 9.9072e-06  eta: 19:15:41  time: 0.4054  data_time: 0.0085  memory: 5967  grad_norm: 737.3104  loss: 43.6869  decode.loss_cls: 1.0681  decode.loss_mask: 1.6484  decode.loss_dice: 1.5104  decode.d0.loss_cls: 3.0382  decode.d0.loss_mask: 1.5977  decode.d0.loss_dice: 1.4759  decode.d1.loss_cls: 1.0057  decode.d1.loss_mask: 1.5516  decode.d1.loss_dice: 1.4082  decode.d2.loss_cls: 1.1366  decode.d2.loss_mask: 1.6350  decode.d2.loss_dice: 1.4529  decode.d3.loss_cls: 1.1670  decode.d3.loss_mask: 1.5938  decode.d3.loss_dice: 1.4346  decode.d4.loss_cls: 1.1148  decode.d4.loss_mask: 1.5999  decode.d4.loss_dice: 1.4266  decode.d5.loss_cls: 1.1046  decode.d5.loss_mask: 1.6353  decode.d5.loss_dice: 1.4623  decode.d6.loss_cls: 1.1752  decode.d6.loss_mask: 1.6323  decode.d6.loss_dice: 1.4641  decode.d7.loss_cls: 1.0768  decode.d7.loss_mask: 1.5961  decode.d7.loss_dice: 1.4654  decode.d8.loss_cls: 1.0521  decode.d8.loss_mask: 1.6651  decode.d8.loss_dice: 1.4922
05/26 11:06:14 - mmengine - INFO - Iter(train) [  1700/160000]  base_lr: 9.9044e-05 lr: 9.9044e-06  eta: 19:12:48  time: 0.4056  data_time: 0.0085  memory: 5971  grad_norm: 777.0234  loss: 41.4487  decode.loss_cls: 0.9448  decode.loss_mask: 1.6833  decode.loss_dice: 1.3553  decode.d0.loss_cls: 2.9373  decode.d0.loss_mask: 1.6688  decode.d0.loss_dice: 1.3545  decode.d1.loss_cls: 0.9178  decode.d1.loss_mask: 1.6792  decode.d1.loss_dice: 1.2929  decode.d2.loss_cls: 0.9510  decode.d2.loss_mask: 1.6604  decode.d2.loss_dice: 1.3104  decode.d3.loss_cls: 0.9286  decode.d3.loss_mask: 1.6526  decode.d3.loss_dice: 1.2611  decode.d4.loss_cls: 1.0152  decode.d4.loss_mask: 1.6528  decode.d4.loss_dice: 1.2606  decode.d5.loss_cls: 0.9806  decode.d5.loss_mask: 1.6637  decode.d5.loss_dice: 1.2955  decode.d6.loss_cls: 0.9799  decode.d6.loss_mask: 1.6787  decode.d6.loss_dice: 1.3507  decode.d7.loss_cls: 0.9941  decode.d7.loss_mask: 1.6822  decode.d7.loss_dice: 1.3177  decode.d8.loss_cls: 0.9503  decode.d8.loss_mask: 1.7118  decode.d8.loss_dice: 1.3168
05/26 11:06:34 - mmengine - INFO - Iter(train) [  1750/160000]  base_lr: 9.9016e-05 lr: 9.9016e-06  eta: 19:10:03  time: 0.4055  data_time: 0.0084  memory: 5967  grad_norm: 1279.5482  loss: 45.3576  decode.loss_cls: 1.0750  decode.loss_mask: 1.7679  decode.loss_dice: 1.4330  decode.d0.loss_cls: 2.9095  decode.d0.loss_mask: 1.6628  decode.d0.loss_dice: 1.4778  decode.d1.loss_cls: 1.1911  decode.d1.loss_mask: 1.7305  decode.d1.loss_dice: 1.4330  decode.d2.loss_cls: 1.0887  decode.d2.loss_mask: 1.7648  decode.d2.loss_dice: 1.4907  decode.d3.loss_cls: 1.0580  decode.d3.loss_mask: 1.7595  decode.d3.loss_dice: 1.4229  decode.d4.loss_cls: 1.1074  decode.d4.loss_mask: 1.8426  decode.d4.loss_dice: 1.5481  decode.d5.loss_cls: 1.1503  decode.d5.loss_mask: 1.7567  decode.d5.loss_dice: 1.4940  decode.d6.loss_cls: 1.0941  decode.d6.loss_mask: 1.8790  decode.d6.loss_dice: 1.4910  decode.d7.loss_cls: 1.0906  decode.d7.loss_mask: 1.8110  decode.d7.loss_dice: 1.4892  decode.d8.loss_cls: 1.1069  decode.d8.loss_mask: 1.7626  decode.d8.loss_dice: 1.4690
05/26 11:06:55 - mmengine - INFO - Iter(train) [  1800/160000]  base_lr: 9.8987e-05 lr: 9.8987e-06  eta: 19:07:27  time: 0.4057  data_time: 0.0084  memory: 5968  grad_norm: 830.4881  loss: 45.2523  decode.loss_cls: 1.1408  decode.loss_mask: 1.7329  decode.loss_dice: 1.5660  decode.d0.loss_cls: 2.7628  decode.d0.loss_mask: 1.6563  decode.d0.loss_dice: 1.5904  decode.d1.loss_cls: 1.0130  decode.d1.loss_mask: 1.6589  decode.d1.loss_dice: 1.5687  decode.d2.loss_cls: 1.0903  decode.d2.loss_mask: 1.6806  decode.d2.loss_dice: 1.5826  decode.d3.loss_cls: 1.0828  decode.d3.loss_mask: 1.6900  decode.d3.loss_dice: 1.5295  decode.d4.loss_cls: 1.1420  decode.d4.loss_mask: 1.6658  decode.d4.loss_dice: 1.5611  decode.d5.loss_cls: 1.1044  decode.d5.loss_mask: 1.7689  decode.d5.loss_dice: 1.5419  decode.d6.loss_cls: 1.0951  decode.d6.loss_mask: 1.7059  decode.d6.loss_dice: 1.5700  decode.d7.loss_cls: 1.1579  decode.d7.loss_mask: 1.7144  decode.d7.loss_dice: 1.5126  decode.d8.loss_cls: 1.1090  decode.d8.loss_mask: 1.7141  decode.d8.loss_dice: 1.5436
05/26 11:07:15 - mmengine - INFO - Iter(train) [  1850/160000]  base_lr: 9.8959e-05 lr: 9.8959e-06  eta: 19:04:57  time: 0.4050  data_time: 0.0085  memory: 5967  grad_norm: 990.3959  loss: 40.3044  decode.loss_cls: 0.8574  decode.loss_mask: 1.6488  decode.loss_dice: 1.4565  decode.d0.loss_cls: 2.6133  decode.d0.loss_mask: 1.5247  decode.d0.loss_dice: 1.3421  decode.d1.loss_cls: 0.9382  decode.d1.loss_mask: 1.5650  decode.d1.loss_dice: 1.3446  decode.d2.loss_cls: 0.8878  decode.d2.loss_mask: 1.5501  decode.d2.loss_dice: 1.2926  decode.d3.loss_cls: 0.9331  decode.d3.loss_mask: 1.5514  decode.d3.loss_dice: 1.2731  decode.d4.loss_cls: 0.9297  decode.d4.loss_mask: 1.6290  decode.d4.loss_dice: 1.3957  decode.d5.loss_cls: 0.8719  decode.d5.loss_mask: 1.6416  decode.d5.loss_dice: 1.4123  decode.d6.loss_cls: 0.8914  decode.d6.loss_mask: 1.6493  decode.d6.loss_dice: 1.3645  decode.d7.loss_cls: 0.9436  decode.d7.loss_mask: 1.5631  decode.d7.loss_dice: 1.3586  decode.d8.loss_cls: 0.9124  decode.d8.loss_mask: 1.5983  decode.d8.loss_dice: 1.3643
05/26 11:07:35 - mmengine - INFO - Iter(train) [  1900/160000]  base_lr: 9.8931e-05 lr: 9.8931e-06  eta: 19:02:33  time: 0.4049  data_time: 0.0084  memory: 5980  grad_norm: 996.6754  loss: 40.9212  decode.loss_cls: 0.8977  decode.loss_mask: 1.5777  decode.loss_dice: 1.4113  decode.d0.loss_cls: 2.5039  decode.d0.loss_mask: 1.5668  decode.d0.loss_dice: 1.4425  decode.d1.loss_cls: 0.9774  decode.d1.loss_mask: 1.5598  decode.d1.loss_dice: 1.4202  decode.d2.loss_cls: 1.0694  decode.d2.loss_mask: 1.5751  decode.d2.loss_dice: 1.3388  decode.d3.loss_cls: 1.0829  decode.d3.loss_mask: 1.5582  decode.d3.loss_dice: 1.3361  decode.d4.loss_cls: 0.9808  decode.d4.loss_mask: 1.5590  decode.d4.loss_dice: 1.3425  decode.d5.loss_cls: 0.9652  decode.d5.loss_mask: 1.5983  decode.d5.loss_dice: 1.3663  decode.d6.loss_cls: 0.9424  decode.d6.loss_mask: 1.6341  decode.d6.loss_dice: 1.3693  decode.d7.loss_cls: 0.8868  decode.d7.loss_mask: 1.6383  decode.d7.loss_dice: 1.3886  decode.d8.loss_cls: 0.8749  decode.d8.loss_mask: 1.6155  decode.d8.loss_dice: 1.4416
05/26 11:07:55 - mmengine - INFO - Iter(train) [  1950/160000]  base_lr: 9.8903e-05 lr: 9.8903e-06  eta: 19:00:16  time: 0.4047  data_time: 0.0085  memory: 5973  grad_norm: 761.8897  loss: 39.5963  decode.loss_cls: 0.7871  decode.loss_mask: 1.6932  decode.loss_dice: 1.3409  decode.d0.loss_cls: 2.3041  decode.d0.loss_mask: 1.6533  decode.d0.loss_dice: 1.3725  decode.d1.loss_cls: 0.8890  decode.d1.loss_mask: 1.5751  decode.d1.loss_dice: 1.3189  decode.d2.loss_cls: 0.9516  decode.d2.loss_mask: 1.5787  decode.d2.loss_dice: 1.2999  decode.d3.loss_cls: 0.9926  decode.d3.loss_mask: 1.5212  decode.d3.loss_dice: 1.2900  decode.d4.loss_cls: 0.9196  decode.d4.loss_mask: 1.6265  decode.d4.loss_dice: 1.2750  decode.d5.loss_cls: 0.9431  decode.d5.loss_mask: 1.6023  decode.d5.loss_dice: 1.2903  decode.d6.loss_cls: 0.9420  decode.d6.loss_mask: 1.5868  decode.d6.loss_dice: 1.2736  decode.d7.loss_cls: 0.8709  decode.d7.loss_mask: 1.5981  decode.d7.loss_dice: 1.2696  decode.d8.loss_cls: 0.8514  decode.d8.loss_mask: 1.6673  decode.d8.loss_dice: 1.3119
05/26 11:08:16 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 11:08:16 - mmengine - INFO - Iter(train) [  2000/160000]  base_lr: 9.8875e-05 lr: 9.8875e-06  eta: 18:58:06  time: 0.4046  data_time: 0.0085  memory: 5975  grad_norm: 764.0652  loss: 36.6499  decode.loss_cls: 0.8700  decode.loss_mask: 1.4711  decode.loss_dice: 1.2034  decode.d0.loss_cls: 2.2780  decode.d0.loss_mask: 1.4553  decode.d0.loss_dice: 1.2187  decode.d1.loss_cls: 0.8394  decode.d1.loss_mask: 1.4766  decode.d1.loss_dice: 1.2258  decode.d2.loss_cls: 0.8672  decode.d2.loss_mask: 1.4979  decode.d2.loss_dice: 1.1886  decode.d3.loss_cls: 0.8597  decode.d3.loss_mask: 1.4632  decode.d3.loss_dice: 1.1903  decode.d4.loss_cls: 0.8670  decode.d4.loss_mask: 1.4334  decode.d4.loss_dice: 1.1981  decode.d5.loss_cls: 0.8872  decode.d5.loss_mask: 1.4281  decode.d5.loss_dice: 1.1860  decode.d6.loss_cls: 0.8673  decode.d6.loss_mask: 1.4457  decode.d6.loss_dice: 1.2173  decode.d7.loss_cls: 0.8230  decode.d7.loss_mask: 1.4428  decode.d7.loss_dice: 1.2154  decode.d8.loss_cls: 0.8502  decode.d8.loss_mask: 1.4809  decode.d8.loss_dice: 1.2021
05/26 11:08:36 - mmengine - INFO - Iter(train) [  2050/160000]  base_lr: 9.8847e-05 lr: 9.8847e-06  eta: 18:55:59  time: 0.4050  data_time: 0.0084  memory: 5978  grad_norm: 1216.9241  loss: 43.7202  decode.loss_cls: 1.0197  decode.loss_mask: 1.7156  decode.loss_dice: 1.4562  decode.d0.loss_cls: 2.2574  decode.d0.loss_mask: 1.7294  decode.d0.loss_dice: 1.5532  decode.d1.loss_cls: 1.0471  decode.d1.loss_mask: 1.7316  decode.d1.loss_dice: 1.4760  decode.d2.loss_cls: 1.0270  decode.d2.loss_mask: 1.7364  decode.d2.loss_dice: 1.5527  decode.d3.loss_cls: 1.0424  decode.d3.loss_mask: 1.7078  decode.d3.loss_dice: 1.4771  decode.d4.loss_cls: 1.0343  decode.d4.loss_mask: 1.7293  decode.d4.loss_dice: 1.5263  decode.d5.loss_cls: 0.9676  decode.d5.loss_mask: 1.7865  decode.d5.loss_dice: 1.4499  decode.d6.loss_cls: 1.0016  decode.d6.loss_mask: 1.7452  decode.d6.loss_dice: 1.4938  decode.d7.loss_cls: 0.9977  decode.d7.loss_mask: 1.7392  decode.d7.loss_dice: 1.5478  decode.d8.loss_cls: 0.9733  decode.d8.loss_mask: 1.7529  decode.d8.loss_dice: 1.4455
05/26 11:08:56 - mmengine - INFO - Iter(train) [  2100/160000]  base_lr: 9.8819e-05 lr: 9.8819e-06  eta: 18:54:01  time: 0.4057  data_time: 0.0084  memory: 5978  grad_norm: 1111.0995  loss: 39.3722  decode.loss_cls: 0.8358  decode.loss_mask: 1.6628  decode.loss_dice: 1.3993  decode.d0.loss_cls: 2.0929  decode.d0.loss_mask: 1.5807  decode.d0.loss_dice: 1.3946  decode.d1.loss_cls: 0.8881  decode.d1.loss_mask: 1.6055  decode.d1.loss_dice: 1.3417  decode.d2.loss_cls: 0.9243  decode.d2.loss_mask: 1.5541  decode.d2.loss_dice: 1.2940  decode.d3.loss_cls: 0.9596  decode.d3.loss_mask: 1.5457  decode.d3.loss_dice: 1.2632  decode.d4.loss_cls: 0.9749  decode.d4.loss_mask: 1.5516  decode.d4.loss_dice: 1.2990  decode.d5.loss_cls: 0.8847  decode.d5.loss_mask: 1.6162  decode.d5.loss_dice: 1.3077  decode.d6.loss_cls: 0.9187  decode.d6.loss_mask: 1.5616  decode.d6.loss_dice: 1.3145  decode.d7.loss_cls: 0.9443  decode.d7.loss_mask: 1.5634  decode.d7.loss_dice: 1.3233  decode.d8.loss_cls: 0.8764  decode.d8.loss_mask: 1.5466  decode.d8.loss_dice: 1.3470
05/26 11:09:16 - mmengine - INFO - Iter(train) [  2150/160000]  base_lr: 9.8790e-05 lr: 9.8790e-06  eta: 18:52:07  time: 0.4049  data_time: 0.0084  memory: 5970  grad_norm: 735.4601  loss: 42.8691  decode.loss_cls: 0.8558  decode.loss_mask: 1.8316  decode.loss_dice: 1.4316  decode.d0.loss_cls: 1.9749  decode.d0.loss_mask: 1.8536  decode.d0.loss_dice: 1.4988  decode.d1.loss_cls: 0.8834  decode.d1.loss_mask: 1.7945  decode.d1.loss_dice: 1.4194  decode.d2.loss_cls: 0.8851  decode.d2.loss_mask: 1.8699  decode.d2.loss_dice: 1.4236  decode.d3.loss_cls: 0.8532  decode.d3.loss_mask: 1.8781  decode.d3.loss_dice: 1.4541  decode.d4.loss_cls: 0.9564  decode.d4.loss_mask: 1.8160  decode.d4.loss_dice: 1.4071  decode.d5.loss_cls: 0.9461  decode.d5.loss_mask: 1.8581  decode.d5.loss_dice: 1.4456  decode.d6.loss_cls: 0.9141  decode.d6.loss_mask: 1.8751  decode.d6.loss_dice: 1.4441  decode.d7.loss_cls: 0.9607  decode.d7.loss_mask: 1.8234  decode.d7.loss_dice: 1.3947  decode.d8.loss_cls: 0.9256  decode.d8.loss_mask: 1.7974  decode.d8.loss_dice: 1.3968
05/26 11:09:37 - mmengine - INFO - Iter(train) [  2200/160000]  base_lr: 9.8762e-05 lr: 9.8762e-06  eta: 18:50:16  time: 0.4048  data_time: 0.0085  memory: 5973  grad_norm: 968.5121  loss: 44.7779  decode.loss_cls: 1.1030  decode.loss_mask: 1.8850  decode.loss_dice: 1.5019  decode.d0.loss_cls: 2.1022  decode.d0.loss_mask: 1.7981  decode.d0.loss_dice: 1.4902  decode.d1.loss_cls: 1.0513  decode.d1.loss_mask: 1.7796  decode.d1.loss_dice: 1.4252  decode.d2.loss_cls: 1.0930  decode.d2.loss_mask: 1.8075  decode.d2.loss_dice: 1.4089  decode.d3.loss_cls: 1.0978  decode.d3.loss_mask: 1.8366  decode.d3.loss_dice: 1.4577  decode.d4.loss_cls: 1.0671  decode.d4.loss_mask: 1.8624  decode.d4.loss_dice: 1.4640  decode.d5.loss_cls: 1.0176  decode.d5.loss_mask: 1.8482  decode.d5.loss_dice: 1.4619  decode.d6.loss_cls: 1.0480  decode.d6.loss_mask: 1.9563  decode.d6.loss_dice: 1.4823  decode.d7.loss_cls: 1.0381  decode.d7.loss_mask: 1.8929  decode.d7.loss_dice: 1.4381  decode.d8.loss_cls: 1.1124  decode.d8.loss_mask: 1.8379  decode.d8.loss_dice: 1.4126
05/26 11:09:57 - mmengine - INFO - Iter(train) [  2250/160000]  base_lr: 9.8734e-05 lr: 9.8734e-06  eta: 18:48:28  time: 0.4048  data_time: 0.0083  memory: 5980  grad_norm: 847.7954  loss: 37.7239  decode.loss_cls: 0.8039  decode.loss_mask: 1.5693  decode.loss_dice: 1.2453  decode.d0.loss_cls: 1.8731  decode.d0.loss_mask: 1.6065  decode.d0.loss_dice: 1.3024  decode.d1.loss_cls: 0.8344  decode.d1.loss_mask: 1.5846  decode.d1.loss_dice: 1.2360  decode.d2.loss_cls: 0.8324  decode.d2.loss_mask: 1.6178  decode.d2.loss_dice: 1.2501  decode.d3.loss_cls: 0.7910  decode.d3.loss_mask: 1.6231  decode.d3.loss_dice: 1.2455  decode.d4.loss_cls: 0.8081  decode.d4.loss_mask: 1.6173  decode.d4.loss_dice: 1.2828  decode.d5.loss_cls: 0.7782  decode.d5.loss_mask: 1.6357  decode.d5.loss_dice: 1.2682  decode.d6.loss_cls: 0.8004  decode.d6.loss_mask: 1.5946  decode.d6.loss_dice: 1.2351  decode.d7.loss_cls: 0.8128  decode.d7.loss_mask: 1.6013  decode.d7.loss_dice: 1.2387  decode.d8.loss_cls: 0.8445  decode.d8.loss_mask: 1.5372  decode.d8.loss_dice: 1.2538
05/26 11:10:17 - mmengine - INFO - Iter(train) [  2300/160000]  base_lr: 9.8706e-05 lr: 9.8706e-06  eta: 18:46:47  time: 0.4051  data_time: 0.0084  memory: 5969  grad_norm: 865.6008  loss: 40.4621  decode.loss_cls: 0.8550  decode.loss_mask: 1.7302  decode.loss_dice: 1.3346  decode.d0.loss_cls: 1.8946  decode.d0.loss_mask: 1.6826  decode.d0.loss_dice: 1.3330  decode.d1.loss_cls: 0.8950  decode.d1.loss_mask: 1.6591  decode.d1.loss_dice: 1.3441  decode.d2.loss_cls: 0.9326  decode.d2.loss_mask: 1.6963  decode.d2.loss_dice: 1.3002  decode.d3.loss_cls: 0.9844  decode.d3.loss_mask: 1.7455  decode.d3.loss_dice: 1.3143  decode.d4.loss_cls: 0.9707  decode.d4.loss_mask: 1.6910  decode.d4.loss_dice: 1.3089  decode.d5.loss_cls: 0.9677  decode.d5.loss_mask: 1.7068  decode.d5.loss_dice: 1.3190  decode.d6.loss_cls: 0.8988  decode.d6.loss_mask: 1.6568  decode.d6.loss_dice: 1.3031  decode.d7.loss_cls: 0.9442  decode.d7.loss_mask: 1.6852  decode.d7.loss_dice: 1.3175  decode.d8.loss_cls: 0.9027  decode.d8.loss_mask: 1.7394  decode.d8.loss_dice: 1.3488
05/26 11:10:38 - mmengine - INFO - Iter(train) [  2350/160000]  base_lr: 9.8678e-05 lr: 9.8678e-06  eta: 18:45:08  time: 0.4050  data_time: 0.0084  memory: 5967  grad_norm: 962.5313  loss: 37.5736  decode.loss_cls: 0.7211  decode.loss_mask: 1.5797  decode.loss_dice: 1.2975  decode.d0.loss_cls: 1.7184  decode.d0.loss_mask: 1.4638  decode.d0.loss_dice: 1.2954  decode.d1.loss_cls: 0.8489  decode.d1.loss_mask: 1.4932  decode.d1.loss_dice: 1.2478  decode.d2.loss_cls: 0.8400  decode.d2.loss_mask: 1.5433  decode.d2.loss_dice: 1.2473  decode.d3.loss_cls: 0.8490  decode.d3.loss_mask: 1.5797  decode.d3.loss_dice: 1.2857  decode.d4.loss_cls: 0.8499  decode.d4.loss_mask: 1.5897  decode.d4.loss_dice: 1.2624  decode.d5.loss_cls: 0.9606  decode.d5.loss_mask: 1.5526  decode.d5.loss_dice: 1.2656  decode.d6.loss_cls: 0.8582  decode.d6.loss_mask: 1.5869  decode.d6.loss_dice: 1.2702  decode.d7.loss_cls: 0.9000  decode.d7.loss_mask: 1.5419  decode.d7.loss_dice: 1.2567  decode.d8.loss_cls: 0.7637  decode.d8.loss_mask: 1.5978  decode.d8.loss_dice: 1.3065
05/26 11:10:58 - mmengine - INFO - Iter(train) [  2400/160000]  base_lr: 9.8650e-05 lr: 9.8650e-06  eta: 18:43:30  time: 0.4036  data_time: 0.0082  memory: 5970  grad_norm: 900.4530  loss: 44.2720  decode.loss_cls: 0.9625  decode.loss_mask: 1.7841  decode.loss_dice: 1.5673  decode.d0.loss_cls: 1.7700  decode.d0.loss_mask: 1.7386  decode.d0.loss_dice: 1.6059  decode.d1.loss_cls: 1.0287  decode.d1.loss_mask: 1.7644  decode.d1.loss_dice: 1.5394  decode.d2.loss_cls: 1.0466  decode.d2.loss_mask: 1.7258  decode.d2.loss_dice: 1.5721  decode.d3.loss_cls: 1.0231  decode.d3.loss_mask: 1.7672  decode.d3.loss_dice: 1.5601  decode.d4.loss_cls: 0.9520  decode.d4.loss_mask: 1.8359  decode.d4.loss_dice: 1.5981  decode.d5.loss_cls: 1.0033  decode.d5.loss_mask: 1.7845  decode.d5.loss_dice: 1.5758  decode.d6.loss_cls: 1.0181  decode.d6.loss_mask: 1.7600  decode.d6.loss_dice: 1.5718  decode.d7.loss_cls: 1.0092  decode.d7.loss_mask: 1.8168  decode.d7.loss_dice: 1.5367  decode.d8.loss_cls: 0.9339  decode.d8.loss_mask: 1.8264  decode.d8.loss_dice: 1.5934
05/26 11:11:18 - mmengine - INFO - Iter(train) [  2450/160000]  base_lr: 9.8621e-05 lr: 9.8621e-06  eta: 18:42:07  time: 0.4161  data_time: 0.0087  memory: 5967  grad_norm: 671.7181  loss: 38.0334  decode.loss_cls: 0.9210  decode.loss_mask: 1.4597  decode.loss_dice: 1.3295  decode.d0.loss_cls: 1.7699  decode.d0.loss_mask: 1.4218  decode.d0.loss_dice: 1.3222  decode.d1.loss_cls: 0.9724  decode.d1.loss_mask: 1.4187  decode.d1.loss_dice: 1.3066  decode.d2.loss_cls: 1.0181  decode.d2.loss_mask: 1.4463  decode.d2.loss_dice: 1.3407  decode.d3.loss_cls: 0.9220  decode.d3.loss_mask: 1.4574  decode.d3.loss_dice: 1.2983  decode.d4.loss_cls: 1.0681  decode.d4.loss_mask: 1.4235  decode.d4.loss_dice: 1.3401  decode.d5.loss_cls: 1.0169  decode.d5.loss_mask: 1.4207  decode.d5.loss_dice: 1.3389  decode.d6.loss_cls: 0.9521  decode.d6.loss_mask: 1.4444  decode.d6.loss_dice: 1.2528  decode.d7.loss_cls: 0.9137  decode.d7.loss_mask: 1.4442  decode.d7.loss_dice: 1.3032  decode.d8.loss_cls: 0.9989  decode.d8.loss_mask: 1.4036  decode.d8.loss_dice: 1.3076
05/26 11:11:39 - mmengine - INFO - Iter(train) [  2500/160000]  base_lr: 9.8593e-05 lr: 9.8593e-06  eta: 18:40:40  time: 0.4063  data_time: 0.0087  memory: 5966  grad_norm: 820.2870  loss: 29.8212  decode.loss_cls: 0.6611  decode.loss_mask: 1.3521  decode.loss_dice: 0.8326  decode.d0.loss_cls: 1.5181  decode.d0.loss_mask: 1.3351  decode.d0.loss_dice: 0.8571  decode.d1.loss_cls: 0.6900  decode.d1.loss_mask: 1.3843  decode.d1.loss_dice: 0.8228  decode.d2.loss_cls: 0.7648  decode.d2.loss_mask: 1.3594  decode.d2.loss_dice: 0.8364  decode.d3.loss_cls: 0.7322  decode.d3.loss_mask: 1.3624  decode.d3.loss_dice: 0.8534  decode.d4.loss_cls: 0.7034  decode.d4.loss_mask: 1.3381  decode.d4.loss_dice: 0.8432  decode.d5.loss_cls: 0.7113  decode.d5.loss_mask: 1.3836  decode.d5.loss_dice: 0.8311  decode.d6.loss_cls: 0.7492  decode.d6.loss_mask: 1.3353  decode.d6.loss_dice: 0.8715  decode.d7.loss_cls: 0.6792  decode.d7.loss_mask: 1.3371  decode.d7.loss_dice: 0.8480  decode.d8.loss_cls: 0.6175  decode.d8.loss_mask: 1.3870  decode.d8.loss_dice: 0.8238
05/26 11:11:59 - mmengine - INFO - Iter(train) [  2550/160000]  base_lr: 9.8565e-05 lr: 9.8565e-06  eta: 18:39:15  time: 0.4054  data_time: 0.0083  memory: 5969  grad_norm: 1147.3421  loss: 39.8326  decode.loss_cls: 0.9921  decode.loss_mask: 1.5615  decode.loss_dice: 1.2982  decode.d0.loss_cls: 1.6777  decode.d0.loss_mask: 1.5196  decode.d0.loss_dice: 1.3698  decode.d1.loss_cls: 1.0167  decode.d1.loss_mask: 1.5729  decode.d1.loss_dice: 1.3557  decode.d2.loss_cls: 1.0277  decode.d2.loss_mask: 1.5626  decode.d2.loss_dice: 1.2825  decode.d3.loss_cls: 1.0360  decode.d3.loss_mask: 1.5673  decode.d3.loss_dice: 1.2773  decode.d4.loss_cls: 1.0049  decode.d4.loss_mask: 1.5984  decode.d4.loss_dice: 1.3213  decode.d5.loss_cls: 0.9672  decode.d5.loss_mask: 1.5908  decode.d5.loss_dice: 1.3333  decode.d6.loss_cls: 1.0119  decode.d6.loss_mask: 1.6683  decode.d6.loss_dice: 1.3607  decode.d7.loss_cls: 1.0522  decode.d7.loss_mask: 1.5608  decode.d7.loss_dice: 1.3418  decode.d8.loss_cls: 1.0319  decode.d8.loss_mask: 1.5634  decode.d8.loss_dice: 1.3082
05/26 11:12:19 - mmengine - INFO - Iter(train) [  2600/160000]  base_lr: 9.8537e-05 lr: 9.8537e-06  eta: 18:37:51  time: 0.4063  data_time: 0.0084  memory: 5967  grad_norm: 755.0136  loss: 37.4033  decode.loss_cls: 0.8904  decode.loss_mask: 1.4857  decode.loss_dice: 1.2973  decode.d0.loss_cls: 1.5831  decode.d0.loss_mask: 1.4522  decode.d0.loss_dice: 1.3417  decode.d1.loss_cls: 0.9117  decode.d1.loss_mask: 1.4487  decode.d1.loss_dice: 1.2341  decode.d2.loss_cls: 1.0163  decode.d2.loss_mask: 1.4204  decode.d2.loss_dice: 1.2745  decode.d3.loss_cls: 1.0024  decode.d3.loss_mask: 1.4576  decode.d3.loss_dice: 1.2716  decode.d4.loss_cls: 0.9408  decode.d4.loss_mask: 1.4659  decode.d4.loss_dice: 1.3028  decode.d5.loss_cls: 0.8926  decode.d5.loss_mask: 1.4601  decode.d5.loss_dice: 1.2631  decode.d6.loss_cls: 0.9635  decode.d6.loss_mask: 1.4299  decode.d6.loss_dice: 1.2429  decode.d7.loss_cls: 0.9154  decode.d7.loss_mask: 1.4810  decode.d7.loss_dice: 1.2999  decode.d8.loss_cls: 0.9273  decode.d8.loss_mask: 1.4613  decode.d8.loss_dice: 1.2691
05/26 11:12:38 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 11:12:39 - mmengine - INFO - Iter(train) [  2650/160000]  base_lr: 9.8509e-05 lr: 9.8509e-06  eta: 18:36:29  time: 0.4051  data_time: 0.0083  memory: 5967  grad_norm: 1102.1173  loss: 38.4882  decode.loss_cls: 0.8751  decode.loss_mask: 1.5712  decode.loss_dice: 1.2607  decode.d0.loss_cls: 1.5526  decode.d0.loss_mask: 1.5317  decode.d0.loss_dice: 1.2997  decode.d1.loss_cls: 0.8937  decode.d1.loss_mask: 1.5903  decode.d1.loss_dice: 1.2360  decode.d2.loss_cls: 0.9424  decode.d2.loss_mask: 1.6010  decode.d2.loss_dice: 1.3067  decode.d3.loss_cls: 0.9174  decode.d3.loss_mask: 1.6222  decode.d3.loss_dice: 1.2705  decode.d4.loss_cls: 0.9660  decode.d4.loss_mask: 1.6121  decode.d4.loss_dice: 1.2728  decode.d5.loss_cls: 0.9790  decode.d5.loss_mask: 1.6436  decode.d5.loss_dice: 1.2587  decode.d6.loss_cls: 0.8283  decode.d6.loss_mask: 1.6732  decode.d6.loss_dice: 1.2668  decode.d7.loss_cls: 0.8117  decode.d7.loss_mask: 1.6920  decode.d7.loss_dice: 1.2529  decode.d8.loss_cls: 0.9254  decode.d8.loss_mask: 1.6018  decode.d8.loss_dice: 1.2324
05/26 11:13:00 - mmengine - INFO - Iter(train) [  2700/160000]  base_lr: 9.8481e-05 lr: 9.8481e-06  eta: 18:35:07  time: 0.4050  data_time: 0.0083  memory: 5972  grad_norm: 916.4068  loss: 39.2102  decode.loss_cls: 0.8883  decode.loss_mask: 1.5588  decode.loss_dice: 1.3146  decode.d0.loss_cls: 1.5303  decode.d0.loss_mask: 1.5680  decode.d0.loss_dice: 1.4181  decode.d1.loss_cls: 0.8185  decode.d1.loss_mask: 1.5746  decode.d1.loss_dice: 1.3978  decode.d2.loss_cls: 0.9436  decode.d2.loss_mask: 1.6013  decode.d2.loss_dice: 1.3575  decode.d3.loss_cls: 0.8702  decode.d3.loss_mask: 1.6324  decode.d3.loss_dice: 1.4549  decode.d4.loss_cls: 0.9259  decode.d4.loss_mask: 1.5962  decode.d4.loss_dice: 1.3847  decode.d5.loss_cls: 0.8700  decode.d5.loss_mask: 1.5643  decode.d5.loss_dice: 1.4004  decode.d6.loss_cls: 0.8910  decode.d6.loss_mask: 1.6089  decode.d6.loss_dice: 1.4573  decode.d7.loss_cls: 0.8753  decode.d7.loss_mask: 1.5683  decode.d7.loss_dice: 1.3825  decode.d8.loss_cls: 0.8661  decode.d8.loss_mask: 1.5441  decode.d8.loss_dice: 1.3461
05/26 11:13:20 - mmengine - INFO - Iter(train) [  2750/160000]  base_lr: 9.8452e-05 lr: 9.8452e-06  eta: 18:33:48  time: 0.4049  data_time: 0.0095  memory: 5967  grad_norm: 1174.9856  loss: 36.4251  decode.loss_cls: 0.8220  decode.loss_mask: 1.4897  decode.loss_dice: 1.1948  decode.d0.loss_cls: 1.4088  decode.d0.loss_mask: 1.4907  decode.d0.loss_dice: 1.2287  decode.d1.loss_cls: 0.9091  decode.d1.loss_mask: 1.4590  decode.d1.loss_dice: 1.1527  decode.d2.loss_cls: 0.9280  decode.d2.loss_mask: 1.4690  decode.d2.loss_dice: 1.1516  decode.d3.loss_cls: 0.9172  decode.d3.loss_mask: 1.5339  decode.d3.loss_dice: 1.1994  decode.d4.loss_cls: 0.9236  decode.d4.loss_mask: 1.5020  decode.d4.loss_dice: 1.2038  decode.d5.loss_cls: 0.9059  decode.d5.loss_mask: 1.5814  decode.d5.loss_dice: 1.2108  decode.d6.loss_cls: 0.8824  decode.d6.loss_mask: 1.6090  decode.d6.loss_dice: 1.1921  decode.d7.loss_cls: 0.9210  decode.d7.loss_mask: 1.4872  decode.d7.loss_dice: 1.1630  decode.d8.loss_cls: 0.8559  decode.d8.loss_mask: 1.4670  decode.d8.loss_dice: 1.1654
05/26 11:13:40 - mmengine - INFO - Iter(train) [  2800/160000]  base_lr: 9.8424e-05 lr: 9.8424e-06  eta: 18:32:32  time: 0.4052  data_time: 0.0084  memory: 5973  grad_norm: 731.4280  loss: 43.3313  decode.loss_cls: 0.9751  decode.loss_mask: 1.7911  decode.loss_dice: 1.5177  decode.d0.loss_cls: 1.5422  decode.d0.loss_mask: 1.7337  decode.d0.loss_dice: 1.5312  decode.d1.loss_cls: 0.9853  decode.d1.loss_mask: 1.7792  decode.d1.loss_dice: 1.5091  decode.d2.loss_cls: 1.0085  decode.d2.loss_mask: 1.7980  decode.d2.loss_dice: 1.5173  decode.d3.loss_cls: 0.9832  decode.d3.loss_mask: 1.7949  decode.d3.loss_dice: 1.5053  decode.d4.loss_cls: 0.9632  decode.d4.loss_mask: 1.8131  decode.d4.loss_dice: 1.4771  decode.d5.loss_cls: 0.9423  decode.d5.loss_mask: 1.8231  decode.d5.loss_dice: 1.5010  decode.d6.loss_cls: 1.0436  decode.d6.loss_mask: 1.7601  decode.d6.loss_dice: 1.4856  decode.d7.loss_cls: 0.9954  decode.d7.loss_mask: 1.7936  decode.d7.loss_dice: 1.4813  decode.d8.loss_cls: 0.9873  decode.d8.loss_mask: 1.7662  decode.d8.loss_dice: 1.5266
05/26 11:14:00 - mmengine - INFO - Iter(train) [  2850/160000]  base_lr: 9.8396e-05 lr: 9.8396e-06  eta: 18:31:18  time: 0.4051  data_time: 0.0083  memory: 5976  grad_norm: 1121.7049  loss: 37.5081  decode.loss_cls: 0.7207  decode.loss_mask: 1.7542  decode.loss_dice: 1.1905  decode.d0.loss_cls: 1.2902  decode.d0.loss_mask: 1.6616  decode.d0.loss_dice: 1.2167  decode.d1.loss_cls: 0.7561  decode.d1.loss_mask: 1.7580  decode.d1.loss_dice: 1.2186  decode.d2.loss_cls: 0.8012  decode.d2.loss_mask: 1.7333  decode.d2.loss_dice: 1.2541  decode.d3.loss_cls: 0.7181  decode.d3.loss_mask: 1.6626  decode.d3.loss_dice: 1.2054  decode.d4.loss_cls: 0.8686  decode.d4.loss_mask: 1.6281  decode.d4.loss_dice: 1.2103  decode.d5.loss_cls: 0.7633  decode.d5.loss_mask: 1.8303  decode.d5.loss_dice: 1.2245  decode.d6.loss_cls: 0.7979  decode.d6.loss_mask: 1.6883  decode.d6.loss_dice: 1.2238  decode.d7.loss_cls: 0.7452  decode.d7.loss_mask: 1.7107  decode.d7.loss_dice: 1.1793  decode.d8.loss_cls: 0.6986  decode.d8.loss_mask: 1.7520  decode.d8.loss_dice: 1.2459
05/26 11:14:21 - mmengine - INFO - Iter(train) [  2900/160000]  base_lr: 9.8368e-05 lr: 9.8368e-06  eta: 18:30:06  time: 0.4048  data_time: 0.0085  memory: 5970  grad_norm: 903.6063  loss: 39.7897  decode.loss_cls: 0.9885  decode.loss_mask: 1.6437  decode.loss_dice: 1.3257  decode.d0.loss_cls: 1.3510  decode.d0.loss_mask: 1.5791  decode.d0.loss_dice: 1.3994  decode.d1.loss_cls: 0.9310  decode.d1.loss_mask: 1.5653  decode.d1.loss_dice: 1.3148  decode.d2.loss_cls: 0.9244  decode.d2.loss_mask: 1.5824  decode.d2.loss_dice: 1.3004  decode.d3.loss_cls: 1.0090  decode.d3.loss_mask: 1.5769  decode.d3.loss_dice: 1.3052  decode.d4.loss_cls: 1.1162  decode.d4.loss_mask: 1.4954  decode.d4.loss_dice: 1.3096  decode.d5.loss_cls: 1.0483  decode.d5.loss_mask: 1.5793  decode.d5.loss_dice: 1.3612  decode.d6.loss_cls: 1.0987  decode.d6.loss_mask: 1.5592  decode.d6.loss_dice: 1.3927  decode.d7.loss_cls: 1.0153  decode.d7.loss_mask: 1.6762  decode.d7.loss_dice: 1.3536  decode.d8.loss_cls: 1.0429  decode.d8.loss_mask: 1.6260  decode.d8.loss_dice: 1.3184
05/26 11:14:41 - mmengine - INFO - Iter(train) [  2950/160000]  base_lr: 9.8340e-05 lr: 9.8340e-06  eta: 18:28:54  time: 0.4039  data_time: 0.0083  memory: 5984  grad_norm: 1271.2405  loss: 40.6224  decode.loss_cls: 0.8078  decode.loss_mask: 1.7981  decode.loss_dice: 1.3697  decode.d0.loss_cls: 1.3418  decode.d0.loss_mask: 1.7067  decode.d0.loss_dice: 1.3896  decode.d1.loss_cls: 0.8751  decode.d1.loss_mask: 1.6759  decode.d1.loss_dice: 1.3638  decode.d2.loss_cls: 0.8985  decode.d2.loss_mask: 1.7708  decode.d2.loss_dice: 1.3630  decode.d3.loss_cls: 0.9686  decode.d3.loss_mask: 1.7948  decode.d3.loss_dice: 1.3974  decode.d4.loss_cls: 0.9072  decode.d4.loss_mask: 1.7511  decode.d4.loss_dice: 1.3760  decode.d5.loss_cls: 0.9262  decode.d5.loss_mask: 1.7508  decode.d5.loss_dice: 1.3389  decode.d6.loss_cls: 0.9411  decode.d6.loss_mask: 1.7812  decode.d6.loss_dice: 1.3717  decode.d7.loss_cls: 0.8673  decode.d7.loss_mask: 1.7496  decode.d7.loss_dice: 1.4242  decode.d8.loss_cls: 0.8470  decode.d8.loss_mask: 1.7435  decode.d8.loss_dice: 1.3248
05/26 11:15:01 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 11:15:01 - mmengine - INFO - Iter(train) [  3000/160000]  base_lr: 9.8311e-05 lr: 9.8311e-06  eta: 18:27:45  time: 0.4045  data_time: 0.0084  memory: 5975  grad_norm: 787.8700  loss: 36.7377  decode.loss_cls: 0.6754  decode.loss_mask: 1.6166  decode.loss_dice: 1.3019  decode.d0.loss_cls: 1.2503  decode.d0.loss_mask: 1.5414  decode.d0.loss_dice: 1.3272  decode.d1.loss_cls: 0.7822  decode.d1.loss_mask: 1.5439  decode.d1.loss_dice: 1.2660  decode.d2.loss_cls: 0.7898  decode.d2.loss_mask: 1.5351  decode.d2.loss_dice: 1.2502  decode.d3.loss_cls: 0.7872  decode.d3.loss_mask: 1.4971  decode.d3.loss_dice: 1.3055  decode.d4.loss_cls: 0.7944  decode.d4.loss_mask: 1.5506  decode.d4.loss_dice: 1.2897  decode.d5.loss_cls: 0.7939  decode.d5.loss_mask: 1.5715  decode.d5.loss_dice: 1.2838  decode.d6.loss_cls: 0.7351  decode.d6.loss_mask: 1.6615  decode.d6.loss_dice: 1.2868  decode.d7.loss_cls: 0.7218  decode.d7.loss_mask: 1.6607  decode.d7.loss_dice: 1.2906  decode.d8.loss_cls: 0.6458  decode.d8.loss_mask: 1.6640  decode.d8.loss_dice: 1.3177
05/26 11:15:22 - mmengine - INFO - Iter(train) [  3050/160000]  base_lr: 9.8283e-05 lr: 9.8283e-06  eta: 18:26:38  time: 0.4049  data_time: 0.0083  memory: 5967  grad_norm: 1238.6099  loss: 40.0540  decode.loss_cls: 0.8310  decode.loss_mask: 1.7319  decode.loss_dice: 1.3478  decode.d0.loss_cls: 1.2076  decode.d0.loss_mask: 1.7697  decode.d0.loss_dice: 1.3770  decode.d1.loss_cls: 0.8028  decode.d1.loss_mask: 1.8533  decode.d1.loss_dice: 1.3250  decode.d2.loss_cls: 0.8477  decode.d2.loss_mask: 1.7935  decode.d2.loss_dice: 1.3308  decode.d3.loss_cls: 0.7859  decode.d3.loss_mask: 1.8116  decode.d3.loss_dice: 1.3001  decode.d4.loss_cls: 0.8632  decode.d4.loss_mask: 1.8424  decode.d4.loss_dice: 1.3085  decode.d5.loss_cls: 0.9300  decode.d5.loss_mask: 1.7638  decode.d5.loss_dice: 1.2982  decode.d6.loss_cls: 0.9436  decode.d6.loss_mask: 1.7779  decode.d6.loss_dice: 1.2972  decode.d7.loss_cls: 0.9466  decode.d7.loss_mask: 1.8076  decode.d7.loss_dice: 1.2912  decode.d8.loss_cls: 0.7901  decode.d8.loss_mask: 1.7703  decode.d8.loss_dice: 1.3078
05/26 11:15:42 - mmengine - INFO - Iter(train) [  3100/160000]  base_lr: 9.8255e-05 lr: 9.8255e-06  eta: 18:25:32  time: 0.4053  data_time: 0.0084  memory: 5966  grad_norm: 946.8787  loss: 34.1279  decode.loss_cls: 0.6568  decode.loss_mask: 1.5160  decode.loss_dice: 1.1639  decode.d0.loss_cls: 1.1267  decode.d0.loss_mask: 1.4982  decode.d0.loss_dice: 1.1760  decode.d1.loss_cls: 0.7040  decode.d1.loss_mask: 1.5108  decode.d1.loss_dice: 1.1656  decode.d2.loss_cls: 0.6745  decode.d2.loss_mask: 1.5105  decode.d2.loss_dice: 1.1715  decode.d3.loss_cls: 0.7111  decode.d3.loss_mask: 1.5242  decode.d3.loss_dice: 1.1499  decode.d4.loss_cls: 0.7314  decode.d4.loss_mask: 1.5141  decode.d4.loss_dice: 1.1317  decode.d5.loss_cls: 0.6765  decode.d5.loss_mask: 1.5304  decode.d5.loss_dice: 1.1798  decode.d6.loss_cls: 0.7091  decode.d6.loss_mask: 1.5398  decode.d6.loss_dice: 1.1905  decode.d7.loss_cls: 0.7141  decode.d7.loss_mask: 1.5053  decode.d7.loss_dice: 1.1225  decode.d8.loss_cls: 0.6681  decode.d8.loss_mask: 1.5051  decode.d8.loss_dice: 1.1499
05/26 11:16:02 - mmengine - INFO - Iter(train) [  3150/160000]  base_lr: 9.8227e-05 lr: 9.8227e-06  eta: 18:24:29  time: 0.4066  data_time: 0.0083  memory: 5967  grad_norm: 602.9346  loss: 32.0198  decode.loss_cls: 0.5715  decode.loss_mask: 1.4537  decode.loss_dice: 1.0868  decode.d0.loss_cls: 1.1743  decode.d0.loss_mask: 1.3871  decode.d0.loss_dice: 1.0923  decode.d1.loss_cls: 0.6418  decode.d1.loss_mask: 1.3658  decode.d1.loss_dice: 1.1140  decode.d2.loss_cls: 0.6809  decode.d2.loss_mask: 1.3741  decode.d2.loss_dice: 1.0981  decode.d3.loss_cls: 0.6540  decode.d3.loss_mask: 1.4087  decode.d3.loss_dice: 1.1091  decode.d4.loss_cls: 0.7678  decode.d4.loss_mask: 1.3133  decode.d4.loss_dice: 1.0225  decode.d5.loss_cls: 0.7403  decode.d5.loss_mask: 1.3632  decode.d5.loss_dice: 1.0623  decode.d6.loss_cls: 0.7266  decode.d6.loss_mask: 1.3773  decode.d6.loss_dice: 1.0739  decode.d7.loss_cls: 0.6734  decode.d7.loss_mask: 1.4656  decode.d7.loss_dice: 1.1103  decode.d8.loss_cls: 0.6558  decode.d8.loss_mask: 1.3787  decode.d8.loss_dice: 1.0767
05/26 11:16:22 - mmengine - INFO - Iter(train) [  3200/160000]  base_lr: 9.8199e-05 lr: 9.8199e-06  eta: 18:23:27  time: 0.4051  data_time: 0.0084  memory: 5971  grad_norm: 721.6747  loss: 41.0299  decode.loss_cls: 0.9690  decode.loss_mask: 1.7035  decode.loss_dice: 1.4280  decode.d0.loss_cls: 1.3485  decode.d0.loss_mask: 1.5974  decode.d0.loss_dice: 1.4547  decode.d1.loss_cls: 1.0238  decode.d1.loss_mask: 1.6294  decode.d1.loss_dice: 1.3493  decode.d2.loss_cls: 1.0213  decode.d2.loss_mask: 1.5862  decode.d2.loss_dice: 1.3671  decode.d3.loss_cls: 1.0289  decode.d3.loss_mask: 1.5980  decode.d3.loss_dice: 1.2897  decode.d4.loss_cls: 1.0070  decode.d4.loss_mask: 1.6577  decode.d4.loss_dice: 1.3386  decode.d5.loss_cls: 1.1152  decode.d5.loss_mask: 1.6306  decode.d5.loss_dice: 1.3746  decode.d6.loss_cls: 1.1270  decode.d6.loss_mask: 1.5983  decode.d6.loss_dice: 1.4041  decode.d7.loss_cls: 1.0522  decode.d7.loss_mask: 1.6992  decode.d7.loss_dice: 1.3995  decode.d8.loss_cls: 1.0723  decode.d8.loss_mask: 1.7168  decode.d8.loss_dice: 1.4421
05/26 11:16:43 - mmengine - INFO - Iter(train) [  3250/160000]  base_lr: 9.8171e-05 lr: 9.8171e-06  eta: 18:22:27  time: 0.4074  data_time: 0.0089  memory: 5967  grad_norm: 677.8635  loss: 33.4451  decode.loss_cls: 0.8503  decode.loss_mask: 1.3042  decode.loss_dice: 1.1704  decode.d0.loss_cls: 1.1942  decode.d0.loss_mask: 1.2887  decode.d0.loss_dice: 1.1778  decode.d1.loss_cls: 0.7779  decode.d1.loss_mask: 1.2948  decode.d1.loss_dice: 1.1112  decode.d2.loss_cls: 0.8538  decode.d2.loss_mask: 1.2684  decode.d2.loss_dice: 1.0852  decode.d3.loss_cls: 0.9090  decode.d3.loss_mask: 1.2474  decode.d3.loss_dice: 1.0899  decode.d4.loss_cls: 0.9145  decode.d4.loss_mask: 1.2981  decode.d4.loss_dice: 1.1241  decode.d5.loss_cls: 0.8598  decode.d5.loss_mask: 1.3752  decode.d5.loss_dice: 1.1577  decode.d6.loss_cls: 0.9870  decode.d6.loss_mask: 1.3284  decode.d6.loss_dice: 1.1318  decode.d7.loss_cls: 0.8890  decode.d7.loss_mask: 1.2976  decode.d7.loss_dice: 1.1384  decode.d8.loss_cls: 0.8999  decode.d8.loss_mask: 1.2862  decode.d8.loss_dice: 1.1344
05/26 11:17:03 - mmengine - INFO - Iter(train) [  3300/160000]  base_lr: 9.8142e-05 lr: 9.8142e-06  eta: 18:21:27  time: 0.4062  data_time: 0.0084  memory: 5984  grad_norm: 959.8674  loss: 41.7406  decode.loss_cls: 1.1047  decode.loss_mask: 1.6706  decode.loss_dice: 1.4555  decode.d0.loss_cls: 1.3906  decode.d0.loss_mask: 1.5689  decode.d0.loss_dice: 1.5182  decode.d1.loss_cls: 1.0644  decode.d1.loss_mask: 1.5604  decode.d1.loss_dice: 1.3981  decode.d2.loss_cls: 1.1016  decode.d2.loss_mask: 1.5527  decode.d2.loss_dice: 1.4240  decode.d3.loss_cls: 1.1200  decode.d3.loss_mask: 1.5784  decode.d3.loss_dice: 1.4143  decode.d4.loss_cls: 1.2256  decode.d4.loss_mask: 1.5626  decode.d4.loss_dice: 1.3999  decode.d5.loss_cls: 1.1230  decode.d5.loss_mask: 1.5477  decode.d5.loss_dice: 1.4313  decode.d6.loss_cls: 1.1911  decode.d6.loss_mask: 1.5823  decode.d6.loss_dice: 1.4407  decode.d7.loss_cls: 1.0818  decode.d7.loss_mask: 1.5940  decode.d7.loss_dice: 1.4147  decode.d8.loss_cls: 1.0603  decode.d8.loss_mask: 1.6629  decode.d8.loss_dice: 1.5002
05/26 11:17:23 - mmengine - INFO - Iter(train) [  3350/160000]  base_lr: 9.8114e-05 lr: 9.8114e-06  eta: 18:20:26  time: 0.4051  data_time: 0.0084  memory: 5970  grad_norm: 840.3203  loss: 34.1173  decode.loss_cls: 0.8419  decode.loss_mask: 1.4668  decode.loss_dice: 1.0008  decode.d0.loss_cls: 1.0954  decode.d0.loss_mask: 1.5450  decode.d0.loss_dice: 1.0750  decode.d1.loss_cls: 0.7753  decode.d1.loss_mask: 1.5438  decode.d1.loss_dice: 1.0471  decode.d2.loss_cls: 0.7347  decode.d2.loss_mask: 1.5403  decode.d2.loss_dice: 1.0421  decode.d3.loss_cls: 0.8360  decode.d3.loss_mask: 1.5610  decode.d3.loss_dice: 1.0216  decode.d4.loss_cls: 0.7721  decode.d4.loss_mask: 1.5774  decode.d4.loss_dice: 1.0596  decode.d5.loss_cls: 0.8129  decode.d5.loss_mask: 1.5049  decode.d5.loss_dice: 1.0034  decode.d6.loss_cls: 0.8006  decode.d6.loss_mask: 1.5901  decode.d6.loss_dice: 1.0529  decode.d7.loss_cls: 0.8047  decode.d7.loss_mask: 1.5860  decode.d7.loss_dice: 1.0309  decode.d8.loss_cls: 0.8606  decode.d8.loss_mask: 1.5065  decode.d8.loss_dice: 1.0280
05/26 11:17:44 - mmengine - INFO - Iter(train) [  3400/160000]  base_lr: 9.8086e-05 lr: 9.8086e-06  eta: 18:19:29  time: 0.4096  data_time: 0.0088  memory: 5971  grad_norm: 631.7728  loss: 31.7793  decode.loss_cls: 0.6992  decode.loss_mask: 1.3320  decode.loss_dice: 1.1332  decode.d0.loss_cls: 1.0380  decode.d0.loss_mask: 1.3323  decode.d0.loss_dice: 1.0827  decode.d1.loss_cls: 0.7203  decode.d1.loss_mask: 1.3021  decode.d1.loss_dice: 1.0973  decode.d2.loss_cls: 0.6970  decode.d2.loss_mask: 1.2966  decode.d2.loss_dice: 1.0737  decode.d3.loss_cls: 0.8128  decode.d3.loss_mask: 1.2750  decode.d3.loss_dice: 1.0643  decode.d4.loss_cls: 0.6823  decode.d4.loss_mask: 1.3114  decode.d4.loss_dice: 1.1227  decode.d5.loss_cls: 0.7929  decode.d5.loss_mask: 1.3169  decode.d5.loss_dice: 1.1089  decode.d6.loss_cls: 0.7411  decode.d6.loss_mask: 1.3142  decode.d6.loss_dice: 1.1513  decode.d7.loss_cls: 0.6620  decode.d7.loss_mask: 1.3500  decode.d7.loss_dice: 1.1557  decode.d8.loss_cls: 0.6804  decode.d8.loss_mask: 1.3141  decode.d8.loss_dice: 1.1188
05/26 11:18:04 - mmengine - INFO - Iter(train) [  3450/160000]  base_lr: 9.8058e-05 lr: 9.8058e-06  eta: 18:18:33  time: 0.4065  data_time: 0.0083  memory: 5967  grad_norm: 1200.0318  loss: 34.2667  decode.loss_cls: 0.8103  decode.loss_mask: 1.3979  decode.loss_dice: 1.2156  decode.d0.loss_cls: 1.1128  decode.d0.loss_mask: 1.3357  decode.d0.loss_dice: 1.1942  decode.d1.loss_cls: 0.7784  decode.d1.loss_mask: 1.3979  decode.d1.loss_dice: 1.1770  decode.d2.loss_cls: 0.7297  decode.d2.loss_mask: 1.3686  decode.d2.loss_dice: 1.1899  decode.d3.loss_cls: 0.7834  decode.d3.loss_mask: 1.4176  decode.d3.loss_dice: 1.1980  decode.d4.loss_cls: 0.7937  decode.d4.loss_mask: 1.4065  decode.d4.loss_dice: 1.2058  decode.d5.loss_cls: 0.8793  decode.d5.loss_mask: 1.3859  decode.d5.loss_dice: 1.2010  decode.d6.loss_cls: 0.8004  decode.d6.loss_mask: 1.3621  decode.d6.loss_dice: 1.2527  decode.d7.loss_cls: 0.7902  decode.d7.loss_mask: 1.4649  decode.d7.loss_dice: 1.1818  decode.d8.loss_cls: 0.8778  decode.d8.loss_mask: 1.3672  decode.d8.loss_dice: 1.1901
05/26 11:18:24 - mmengine - INFO - Iter(train) [  3500/160000]  base_lr: 9.8030e-05 lr: 9.8030e-06  eta: 18:17:40  time: 0.4056  data_time: 0.0083  memory: 5967  grad_norm: 595.7138  loss: 36.1011  decode.loss_cls: 0.7540  decode.loss_mask: 1.6377  decode.loss_dice: 1.1900  decode.d0.loss_cls: 1.0833  decode.d0.loss_mask: 1.5803  decode.d0.loss_dice: 1.1616  decode.d1.loss_cls: 0.7808  decode.d1.loss_mask: 1.5917  decode.d1.loss_dice: 1.1057  decode.d2.loss_cls: 0.8698  decode.d2.loss_mask: 1.5590  decode.d2.loss_dice: 1.0787  decode.d3.loss_cls: 0.7687  decode.d3.loss_mask: 1.6089  decode.d3.loss_dice: 1.1080  decode.d4.loss_cls: 0.8976  decode.d4.loss_mask: 1.6290  decode.d4.loss_dice: 1.1598  decode.d5.loss_cls: 0.8853  decode.d5.loss_mask: 1.6110  decode.d5.loss_dice: 1.1682  decode.d6.loss_cls: 0.8690  decode.d6.loss_mask: 1.6790  decode.d6.loss_dice: 1.2088  decode.d7.loss_cls: 0.7473  decode.d7.loss_mask: 1.6482  decode.d7.loss_dice: 1.1524  decode.d8.loss_cls: 0.7335  decode.d8.loss_mask: 1.6467  decode.d8.loss_dice: 1.1874
05/26 11:18:44 - mmengine - INFO - Iter(train) [  3550/160000]  base_lr: 9.8001e-05 lr: 9.8001e-06  eta: 18:16:44  time: 0.4054  data_time: 0.0084  memory: 5969  grad_norm: 1060.6246  loss: 35.1450  decode.loss_cls: 0.9116  decode.loss_mask: 1.4888  decode.loss_dice: 1.1716  decode.d0.loss_cls: 1.1711  decode.d0.loss_mask: 1.3911  decode.d0.loss_dice: 1.1650  decode.d1.loss_cls: 0.8645  decode.d1.loss_mask: 1.4272  decode.d1.loss_dice: 1.1820  decode.d2.loss_cls: 0.9118  decode.d2.loss_mask: 1.4174  decode.d2.loss_dice: 1.1673  decode.d3.loss_cls: 0.9176  decode.d3.loss_mask: 1.4109  decode.d3.loss_dice: 1.1576  decode.d4.loss_cls: 0.9111  decode.d4.loss_mask: 1.4286  decode.d4.loss_dice: 1.1917  decode.d5.loss_cls: 1.0527  decode.d5.loss_mask: 1.3789  decode.d5.loss_dice: 1.1070  decode.d6.loss_cls: 0.9413  decode.d6.loss_mask: 1.3798  decode.d6.loss_dice: 1.1251  decode.d7.loss_cls: 0.8569  decode.d7.loss_mask: 1.4437  decode.d7.loss_dice: 1.1567  decode.d8.loss_cls: 0.8408  decode.d8.loss_mask: 1.4221  decode.d8.loss_dice: 1.1528
05/26 11:19:05 - mmengine - INFO - Iter(train) [  3600/160000]  base_lr: 9.7973e-05 lr: 9.7973e-06  eta: 18:15:49  time: 0.4056  data_time: 0.0085  memory: 5967  grad_norm: 587.6441  loss: 37.0657  decode.loss_cls: 0.8580  decode.loss_mask: 1.5251  decode.loss_dice: 1.3356  decode.d0.loss_cls: 1.1741  decode.d0.loss_mask: 1.4085  decode.d0.loss_dice: 1.2930  decode.d1.loss_cls: 0.9066  decode.d1.loss_mask: 1.4361  decode.d1.loss_dice: 1.2403  decode.d2.loss_cls: 0.8614  decode.d2.loss_mask: 1.4161  decode.d2.loss_dice: 1.3093  decode.d3.loss_cls: 0.8753  decode.d3.loss_mask: 1.4418  decode.d3.loss_dice: 1.3500  decode.d4.loss_cls: 1.0179  decode.d4.loss_mask: 1.4925  decode.d4.loss_dice: 1.2396  decode.d5.loss_cls: 1.0305  decode.d5.loss_mask: 1.5485  decode.d5.loss_dice: 1.3107  decode.d6.loss_cls: 0.9024  decode.d6.loss_mask: 1.5058  decode.d6.loss_dice: 1.3128  decode.d7.loss_cls: 0.8864  decode.d7.loss_mask: 1.4930  decode.d7.loss_dice: 1.2639  decode.d8.loss_cls: 0.8699  decode.d8.loss_mask: 1.4703  decode.d8.loss_dice: 1.2905
05/26 11:19:25 - mmengine - INFO - Iter(train) [  3650/160000]  base_lr: 9.7945e-05 lr: 9.7945e-06  eta: 18:14:55  time: 0.4054  data_time: 0.0083  memory: 5981  grad_norm: 890.4281  loss: 35.7694  decode.loss_cls: 0.7900  decode.loss_mask: 1.6147  decode.loss_dice: 1.1473  decode.d0.loss_cls: 1.0341  decode.d0.loss_mask: 1.5971  decode.d0.loss_dice: 1.1571  decode.d1.loss_cls: 0.7886  decode.d1.loss_mask: 1.5681  decode.d1.loss_dice: 1.1240  decode.d2.loss_cls: 0.7215  decode.d2.loss_mask: 1.6364  decode.d2.loss_dice: 1.1938  decode.d3.loss_cls: 0.8333  decode.d3.loss_mask: 1.6026  decode.d3.loss_dice: 1.1108  decode.d4.loss_cls: 0.7927  decode.d4.loss_mask: 1.6558  decode.d4.loss_dice: 1.1353  decode.d5.loss_cls: 0.8212  decode.d5.loss_mask: 1.6211  decode.d5.loss_dice: 1.1310  decode.d6.loss_cls: 0.8249  decode.d6.loss_mask: 1.6159  decode.d6.loss_dice: 1.1873  decode.d7.loss_cls: 0.8533  decode.d7.loss_mask: 1.5742  decode.d7.loss_dice: 1.1375  decode.d8.loss_cls: 0.7946  decode.d8.loss_mask: 1.5819  decode.d8.loss_dice: 1.1234
05/26 11:19:45 - mmengine - INFO - Iter(train) [  3700/160000]  base_lr: 9.7917e-05 lr: 9.7917e-06  eta: 18:14:02  time: 0.4060  data_time: 0.0085  memory: 5974  grad_norm: 1204.6404  loss: 41.4562  decode.loss_cls: 0.9150  decode.loss_mask: 1.6527  decode.loss_dice: 1.3953  decode.d0.loss_cls: 1.1696  decode.d0.loss_mask: 1.6368  decode.d0.loss_dice: 1.3900  decode.d1.loss_cls: 0.8636  decode.d1.loss_mask: 1.6975  decode.d1.loss_dice: 1.4259  decode.d2.loss_cls: 0.8717  decode.d2.loss_mask: 1.7980  decode.d2.loss_dice: 1.4181  decode.d3.loss_cls: 0.8894  decode.d3.loss_mask: 1.8143  decode.d3.loss_dice: 1.5212  decode.d4.loss_cls: 0.8835  decode.d4.loss_mask: 1.6964  decode.d4.loss_dice: 1.4572  decode.d5.loss_cls: 1.0011  decode.d5.loss_mask: 1.7340  decode.d5.loss_dice: 1.5039  decode.d6.loss_cls: 1.0704  decode.d6.loss_mask: 1.9196  decode.d6.loss_dice: 1.5474  decode.d7.loss_cls: 0.9520  decode.d7.loss_mask: 1.7372  decode.d7.loss_dice: 1.4502  decode.d8.loss_cls: 0.9546  decode.d8.loss_mask: 1.7167  decode.d8.loss_dice: 1.3731
05/26 11:20:05 - mmengine - INFO - Iter(train) [  3750/160000]  base_lr: 9.7889e-05 lr: 9.7889e-06  eta: 18:13:10  time: 0.4066  data_time: 0.0084  memory: 5967  grad_norm: 823.3338  loss: 35.7197  decode.loss_cls: 0.8012  decode.loss_mask: 1.4719  decode.loss_dice: 1.2461  decode.d0.loss_cls: 1.1446  decode.d0.loss_mask: 1.4526  decode.d0.loss_dice: 1.2117  decode.d1.loss_cls: 0.8557  decode.d1.loss_mask: 1.4823  decode.d1.loss_dice: 1.2415  decode.d2.loss_cls: 0.8257  decode.d2.loss_mask: 1.5034  decode.d2.loss_dice: 1.2779  decode.d3.loss_cls: 0.9321  decode.d3.loss_mask: 1.4721  decode.d3.loss_dice: 1.1880  decode.d4.loss_cls: 0.8300  decode.d4.loss_mask: 1.5072  decode.d4.loss_dice: 1.2219  decode.d5.loss_cls: 0.8797  decode.d5.loss_mask: 1.4593  decode.d5.loss_dice: 1.1776  decode.d6.loss_cls: 0.8946  decode.d6.loss_mask: 1.4625  decode.d6.loss_dice: 1.1933  decode.d7.loss_cls: 0.8758  decode.d7.loss_mask: 1.4579  decode.d7.loss_dice: 1.1927  decode.d8.loss_cls: 0.8047  decode.d8.loss_mask: 1.4400  decode.d8.loss_dice: 1.2157
05/26 11:20:26 - mmengine - INFO - Iter(train) [  3800/160000]  base_lr: 9.7860e-05 lr: 9.7860e-06  eta: 18:12:18  time: 0.4054  data_time: 0.0083  memory: 5966  grad_norm: 1045.9378  loss: 37.3471  decode.loss_cls: 0.9371  decode.loss_mask: 1.6654  decode.loss_dice: 1.0820  decode.d0.loss_cls: 1.2279  decode.d0.loss_mask: 1.6385  decode.d0.loss_dice: 1.1092  decode.d1.loss_cls: 0.8824  decode.d1.loss_mask: 1.6831  decode.d1.loss_dice: 1.1280  decode.d2.loss_cls: 0.8634  decode.d2.loss_mask: 1.7353  decode.d2.loss_dice: 1.1138  decode.d3.loss_cls: 0.9568  decode.d3.loss_mask: 1.6788  decode.d3.loss_dice: 1.1322  decode.d4.loss_cls: 0.8735  decode.d4.loss_mask: 1.7102  decode.d4.loss_dice: 1.1593  decode.d5.loss_cls: 0.8690  decode.d5.loss_mask: 1.6835  decode.d5.loss_dice: 1.1049  decode.d6.loss_cls: 0.9486  decode.d6.loss_mask: 1.6824  decode.d6.loss_dice: 1.0891  decode.d7.loss_cls: 0.9462  decode.d7.loss_mask: 1.6467  decode.d7.loss_dice: 1.1085  decode.d8.loss_cls: 0.9382  decode.d8.loss_mask: 1.6748  decode.d8.loss_dice: 1.0781
05/26 11:20:46 - mmengine - INFO - Iter(train) [  3850/160000]  base_lr: 9.7832e-05 lr: 9.7832e-06  eta: 18:11:28  time: 0.4045  data_time: 0.0084  memory: 5970  grad_norm: 766.3377  loss: 34.5408  decode.loss_cls: 0.8395  decode.loss_mask: 1.3613  decode.loss_dice: 1.2579  decode.d0.loss_cls: 1.1448  decode.d0.loss_mask: 1.3064  decode.d0.loss_dice: 1.2572  decode.d1.loss_cls: 0.8642  decode.d1.loss_mask: 1.3807  decode.d1.loss_dice: 1.2438  decode.d2.loss_cls: 0.9213  decode.d2.loss_mask: 1.3026  decode.d2.loss_dice: 1.1597  decode.d3.loss_cls: 0.9669  decode.d3.loss_mask: 1.2843  decode.d3.loss_dice: 1.1560  decode.d4.loss_cls: 1.0136  decode.d4.loss_mask: 1.2993  decode.d4.loss_dice: 1.1829  decode.d5.loss_cls: 0.9278  decode.d5.loss_mask: 1.3043  decode.d5.loss_dice: 1.1251  decode.d6.loss_cls: 0.9705  decode.d6.loss_mask: 1.3337  decode.d6.loss_dice: 1.2030  decode.d7.loss_cls: 0.9454  decode.d7.loss_mask: 1.2981  decode.d7.loss_dice: 1.1835  decode.d8.loss_cls: 0.8768  decode.d8.loss_mask: 1.2655  decode.d8.loss_dice: 1.1647
05/26 11:21:06 - mmengine - INFO - Iter(train) [  3900/160000]  base_lr: 9.7804e-05 lr: 9.7804e-06  eta: 18:10:38  time: 0.4036  data_time: 0.0083  memory: 5970  grad_norm: 648.3276  loss: 31.2670  decode.loss_cls: 0.5952  decode.loss_mask: 1.3792  decode.loss_dice: 1.0357  decode.d0.loss_cls: 1.0231  decode.d0.loss_mask: 1.3203  decode.d0.loss_dice: 1.0501  decode.d1.loss_cls: 0.6791  decode.d1.loss_mask: 1.3654  decode.d1.loss_dice: 1.0186  decode.d2.loss_cls: 0.6885  decode.d2.loss_mask: 1.3550  decode.d2.loss_dice: 1.0096  decode.d3.loss_cls: 0.6277  decode.d3.loss_mask: 1.3905  decode.d3.loss_dice: 1.0562  decode.d4.loss_cls: 0.7734  decode.d4.loss_mask: 1.3449  decode.d4.loss_dice: 1.0598  decode.d5.loss_cls: 0.6665  decode.d5.loss_mask: 1.3956  decode.d5.loss_dice: 1.0919  decode.d6.loss_cls: 0.7065  decode.d6.loss_mask: 1.3549  decode.d6.loss_dice: 1.0900  decode.d7.loss_cls: 0.7352  decode.d7.loss_mask: 1.3591  decode.d7.loss_dice: 1.0359  decode.d8.loss_cls: 0.6752  decode.d8.loss_mask: 1.3443  decode.d8.loss_dice: 1.0398
05/26 11:21:26 - mmengine - INFO - Iter(train) [  3950/160000]  base_lr: 9.7776e-05 lr: 9.7776e-06  eta: 18:09:50  time: 0.4043  data_time: 0.0084  memory: 5970  grad_norm: 674.0155  loss: 33.9832  decode.loss_cls: 0.7439  decode.loss_mask: 1.5658  decode.loss_dice: 1.1158  decode.d0.loss_cls: 1.0665  decode.d0.loss_mask: 1.5438  decode.d0.loss_dice: 1.1033  decode.d1.loss_cls: 0.7210  decode.d1.loss_mask: 1.5378  decode.d1.loss_dice: 1.0772  decode.d2.loss_cls: 0.7782  decode.d2.loss_mask: 1.4832  decode.d2.loss_dice: 1.0508  decode.d3.loss_cls: 0.8092  decode.d3.loss_mask: 1.4934  decode.d3.loss_dice: 1.1012  decode.d4.loss_cls: 0.8102  decode.d4.loss_mask: 1.4824  decode.d4.loss_dice: 1.0645  decode.d5.loss_cls: 0.7999  decode.d5.loss_mask: 1.5167  decode.d5.loss_dice: 1.0801  decode.d6.loss_cls: 0.7661  decode.d6.loss_mask: 1.5171  decode.d6.loss_dice: 1.0822  decode.d7.loss_cls: 0.7755  decode.d7.loss_mask: 1.4912  decode.d7.loss_dice: 1.0886  decode.d8.loss_cls: 0.7340  decode.d8.loss_mask: 1.5217  decode.d8.loss_dice: 1.0621
05/26 11:21:47 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 11:21:47 - mmengine - INFO - Iter(train) [  4000/160000]  base_lr: 9.7748e-05 lr: 9.7748e-06  eta: 18:09:02  time: 0.4044  data_time: 0.0084  memory: 5966  grad_norm: 819.5430  loss: 36.9929  decode.loss_cls: 0.8177  decode.loss_mask: 1.6180  decode.loss_dice: 1.1940  decode.d0.loss_cls: 1.0298  decode.d0.loss_mask: 1.7100  decode.d0.loss_dice: 1.2246  decode.d1.loss_cls: 0.7519  decode.d1.loss_mask: 1.6345  decode.d1.loss_dice: 1.2089  decode.d2.loss_cls: 0.7514  decode.d2.loss_mask: 1.6752  decode.d2.loss_dice: 1.1841  decode.d3.loss_cls: 0.7315  decode.d3.loss_mask: 1.7021  decode.d3.loss_dice: 1.1743  decode.d4.loss_cls: 0.8272  decode.d4.loss_mask: 1.7572  decode.d4.loss_dice: 1.2738  decode.d5.loss_cls: 0.7547  decode.d5.loss_mask: 1.6453  decode.d5.loss_dice: 1.2052  decode.d6.loss_cls: 0.8689  decode.d6.loss_mask: 1.6673  decode.d6.loss_dice: 1.1853  decode.d7.loss_cls: 0.8035  decode.d7.loss_mask: 1.6776  decode.d7.loss_dice: 1.2513  decode.d8.loss_cls: 0.7460  decode.d8.loss_mask: 1.7076  decode.d8.loss_dice: 1.2141
05/26 11:22:07 - mmengine - INFO - Iter(train) [  4050/160000]  base_lr: 9.7720e-05 lr: 9.7720e-06  eta: 18:08:16  time: 0.4037  data_time: 0.0083  memory: 5978  grad_norm: 948.9443  loss: 35.4153  decode.loss_cls: 0.6319  decode.loss_mask: 1.7152  decode.loss_dice: 1.1822  decode.d0.loss_cls: 1.0649  decode.d0.loss_mask: 1.6260  decode.d0.loss_dice: 1.2033  decode.d1.loss_cls: 0.6492  decode.d1.loss_mask: 1.6316  decode.d1.loss_dice: 1.1408  decode.d2.loss_cls: 0.6526  decode.d2.loss_mask: 1.6543  decode.d2.loss_dice: 1.1899  decode.d3.loss_cls: 0.6574  decode.d3.loss_mask: 1.7381  decode.d3.loss_dice: 1.1795  decode.d4.loss_cls: 0.6755  decode.d4.loss_mask: 1.7226  decode.d4.loss_dice: 1.1823  decode.d5.loss_cls: 0.7129  decode.d5.loss_mask: 1.6345  decode.d5.loss_dice: 1.1273  decode.d6.loss_cls: 0.7235  decode.d6.loss_mask: 1.6607  decode.d6.loss_dice: 1.1334  decode.d7.loss_cls: 0.6689  decode.d7.loss_mask: 1.5858  decode.d7.loss_dice: 1.1327  decode.d8.loss_cls: 0.6631  decode.d8.loss_mask: 1.6607  decode.d8.loss_dice: 1.2145
05/26 11:22:27 - mmengine - INFO - Iter(train) [  4100/160000]  base_lr: 9.7691e-05 lr: 9.7691e-06  eta: 18:07:29  time: 0.4034  data_time: 0.0084  memory: 5987  grad_norm: 714.2328  loss: 34.0736  decode.loss_cls: 0.7087  decode.loss_mask: 1.5490  decode.loss_dice: 1.1215  decode.d0.loss_cls: 1.0650  decode.d0.loss_mask: 1.5084  decode.d0.loss_dice: 1.1276  decode.d1.loss_cls: 0.7255  decode.d1.loss_mask: 1.4812  decode.d1.loss_dice: 1.1080  decode.d2.loss_cls: 0.7159  decode.d2.loss_mask: 1.4916  decode.d2.loss_dice: 1.0882  decode.d3.loss_cls: 0.7093  decode.d3.loss_mask: 1.5255  decode.d3.loss_dice: 1.1096  decode.d4.loss_cls: 0.8183  decode.d4.loss_mask: 1.5120  decode.d4.loss_dice: 1.1120  decode.d5.loss_cls: 0.7817  decode.d5.loss_mask: 1.5216  decode.d5.loss_dice: 1.1620  decode.d6.loss_cls: 0.8594  decode.d6.loss_mask: 1.4921  decode.d6.loss_dice: 1.0720  decode.d7.loss_cls: 0.7240  decode.d7.loss_mask: 1.5227  decode.d7.loss_dice: 1.1129  decode.d8.loss_cls: 0.7375  decode.d8.loss_mask: 1.5214  decode.d8.loss_dice: 1.0890
05/26 11:22:48 - mmengine - INFO - Iter(train) [  4150/160000]  base_lr: 9.7663e-05 lr: 9.7663e-06  eta: 18:06:44  time: 0.4044  data_time: 0.0085  memory: 5981  grad_norm: 850.2366  loss: 35.3129  decode.loss_cls: 0.8199  decode.loss_mask: 1.5021  decode.loss_dice: 1.2384  decode.d0.loss_cls: 1.1112  decode.d0.loss_mask: 1.5321  decode.d0.loss_dice: 1.2468  decode.d1.loss_cls: 0.8310  decode.d1.loss_mask: 1.4623  decode.d1.loss_dice: 1.1417  decode.d2.loss_cls: 0.8730  decode.d2.loss_mask: 1.4156  decode.d2.loss_dice: 1.1226  decode.d3.loss_cls: 0.8652  decode.d3.loss_mask: 1.4200  decode.d3.loss_dice: 1.1391  decode.d4.loss_cls: 0.8519  decode.d4.loss_mask: 1.4654  decode.d4.loss_dice: 1.1591  decode.d5.loss_cls: 0.9210  decode.d5.loss_mask: 1.4989  decode.d5.loss_dice: 1.1590  decode.d6.loss_cls: 0.8830  decode.d6.loss_mask: 1.5098  decode.d6.loss_dice: 1.1792  decode.d7.loss_cls: 0.8345  decode.d7.loss_mask: 1.4828  decode.d7.loss_dice: 1.1806  decode.d8.loss_cls: 0.8373  decode.d8.loss_mask: 1.5057  decode.d8.loss_dice: 1.1238
05/26 11:23:08 - mmengine - INFO - Iter(train) [  4200/160000]  base_lr: 9.7635e-05 lr: 9.7635e-06  eta: 18:05:58  time: 0.4040  data_time: 0.0084  memory: 5969  grad_norm: 817.3912  loss: 33.3703  decode.loss_cls: 0.7424  decode.loss_mask: 1.5053  decode.loss_dice: 1.1219  decode.d0.loss_cls: 1.0785  decode.d0.loss_mask: 1.3342  decode.d0.loss_dice: 1.1101  decode.d1.loss_cls: 0.8246  decode.d1.loss_mask: 1.3914  decode.d1.loss_dice: 1.0654  decode.d2.loss_cls: 0.7988  decode.d2.loss_mask: 1.4676  decode.d2.loss_dice: 1.0917  decode.d3.loss_cls: 0.8917  decode.d3.loss_mask: 1.3846  decode.d3.loss_dice: 1.0695  decode.d4.loss_cls: 0.8448  decode.d4.loss_mask: 1.4336  decode.d4.loss_dice: 1.0802  decode.d5.loss_cls: 0.7689  decode.d5.loss_mask: 1.4097  decode.d5.loss_dice: 1.0857  decode.d6.loss_cls: 0.8960  decode.d6.loss_mask: 1.4123  decode.d6.loss_dice: 1.0879  decode.d7.loss_cls: 0.7352  decode.d7.loss_mask: 1.3895  decode.d7.loss_dice: 1.0796  decode.d8.loss_cls: 0.7542  decode.d8.loss_mask: 1.4079  decode.d8.loss_dice: 1.1071
05/26 11:23:28 - mmengine - INFO - Iter(train) [  4250/160000]  base_lr: 9.7607e-05 lr: 9.7607e-06  eta: 18:05:14  time: 0.4036  data_time: 0.0084  memory: 5983  grad_norm: 889.0108  loss: 40.8512  decode.loss_cls: 0.8053  decode.loss_mask: 1.8034  decode.loss_dice: 1.5372  decode.d0.loss_cls: 1.0602  decode.d0.loss_mask: 1.6934  decode.d0.loss_dice: 1.4589  decode.d1.loss_cls: 0.7187  decode.d1.loss_mask: 1.7128  decode.d1.loss_dice: 1.4534  decode.d2.loss_cls: 0.7637  decode.d2.loss_mask: 1.7652  decode.d2.loss_dice: 1.4706  decode.d3.loss_cls: 0.7723  decode.d3.loss_mask: 1.7688  decode.d3.loss_dice: 1.4629  decode.d4.loss_cls: 0.8762  decode.d4.loss_mask: 1.7988  decode.d4.loss_dice: 1.5353  decode.d5.loss_cls: 0.8470  decode.d5.loss_mask: 1.7586  decode.d5.loss_dice: 1.5826  decode.d6.loss_cls: 0.7962  decode.d6.loss_mask: 1.7718  decode.d6.loss_dice: 1.5333  decode.d7.loss_cls: 0.7795  decode.d7.loss_mask: 1.7538  decode.d7.loss_dice: 1.5018  decode.d8.loss_cls: 0.7747  decode.d8.loss_mask: 1.7683  decode.d8.loss_dice: 1.5265
05/26 11:23:48 - mmengine - INFO - Iter(train) [  4300/160000]  base_lr: 9.7579e-05 lr: 9.7579e-06  eta: 18:04:30  time: 0.4055  data_time: 0.0093  memory: 5973  grad_norm: 1725.9476  loss: 36.0089  decode.loss_cls: 0.7244  decode.loss_mask: 1.6393  decode.loss_dice: 1.1673  decode.d0.loss_cls: 1.0626  decode.d0.loss_mask: 1.6440  decode.d0.loss_dice: 1.1412  decode.d1.loss_cls: 0.7255  decode.d1.loss_mask: 1.7007  decode.d1.loss_dice: 1.1979  decode.d2.loss_cls: 0.7385  decode.d2.loss_mask: 1.6388  decode.d2.loss_dice: 1.1540  decode.d3.loss_cls: 0.7716  decode.d3.loss_mask: 1.6666  decode.d3.loss_dice: 1.1472  decode.d4.loss_cls: 0.7934  decode.d4.loss_mask: 1.7036  decode.d4.loss_dice: 1.1170  decode.d5.loss_cls: 0.7789  decode.d5.loss_mask: 1.6705  decode.d5.loss_dice: 1.1634  decode.d6.loss_cls: 0.7588  decode.d6.loss_mask: 1.6981  decode.d6.loss_dice: 1.1285  decode.d7.loss_cls: 0.7457  decode.d7.loss_mask: 1.6208  decode.d7.loss_dice: 1.1718  decode.d8.loss_cls: 0.6955  decode.d8.loss_mask: 1.6976  decode.d8.loss_dice: 1.1456
05/26 11:24:09 - mmengine - INFO - Iter(train) [  4350/160000]  base_lr: 9.7550e-05 lr: 9.7550e-06  eta: 18:03:47  time: 0.4048  data_time: 0.0084  memory: 5982  grad_norm: 652.7774  loss: 33.4777  decode.loss_cls: 0.6598  decode.loss_mask: 1.4899  decode.loss_dice: 1.1102  decode.d0.loss_cls: 1.0214  decode.d0.loss_mask: 1.3818  decode.d0.loss_dice: 1.1061  decode.d1.loss_cls: 0.7877  decode.d1.loss_mask: 1.3715  decode.d1.loss_dice: 1.0917  decode.d2.loss_cls: 0.7141  decode.d2.loss_mask: 1.3866  decode.d2.loss_dice: 1.0897  decode.d3.loss_cls: 0.7752  decode.d3.loss_mask: 1.3794  decode.d3.loss_dice: 1.1018  decode.d4.loss_cls: 0.8087  decode.d4.loss_mask: 1.3791  decode.d4.loss_dice: 1.0910  decode.d5.loss_cls: 0.8764  decode.d5.loss_mask: 1.4228  decode.d5.loss_dice: 1.1307  decode.d6.loss_cls: 0.8243  decode.d6.loss_mask: 1.5269  decode.d6.loss_dice: 1.1945  decode.d7.loss_cls: 0.7930  decode.d7.loss_mask: 1.4963  decode.d7.loss_dice: 1.2128  decode.d8.loss_cls: 0.7940  decode.d8.loss_mask: 1.4043  decode.d8.loss_dice: 1.0557
05/26 11:24:29 - mmengine - INFO - Iter(train) [  4400/160000]  base_lr: 9.7522e-05 lr: 9.7522e-06  eta: 18:03:04  time: 0.4038  data_time: 0.0084  memory: 5967  grad_norm: 641.8344  loss: 35.5458  decode.loss_cls: 0.7847  decode.loss_mask: 1.5546  decode.loss_dice: 1.2088  decode.d0.loss_cls: 1.1165  decode.d0.loss_mask: 1.4933  decode.d0.loss_dice: 1.2243  decode.d1.loss_cls: 0.7203  decode.d1.loss_mask: 1.5110  decode.d1.loss_dice: 1.2088  decode.d2.loss_cls: 0.7920  decode.d2.loss_mask: 1.5070  decode.d2.loss_dice: 1.1924  decode.d3.loss_cls: 0.7675  decode.d3.loss_mask: 1.5096  decode.d3.loss_dice: 1.2258  decode.d4.loss_cls: 0.7827  decode.d4.loss_mask: 1.5670  decode.d4.loss_dice: 1.2142  decode.d5.loss_cls: 0.8328  decode.d5.loss_mask: 1.5442  decode.d5.loss_dice: 1.2050  decode.d6.loss_cls: 0.8382  decode.d6.loss_mask: 1.5053  decode.d6.loss_dice: 1.2253  decode.d7.loss_cls: 0.7903  decode.d7.loss_mask: 1.5064  decode.d7.loss_dice: 1.1838  decode.d8.loss_cls: 0.8357  decode.d8.loss_mask: 1.5316  decode.d8.loss_dice: 1.1667
05/26 11:24:49 - mmengine - INFO - Iter(train) [  4450/160000]  base_lr: 9.7494e-05 lr: 9.7494e-06  eta: 18:02:23  time: 0.4047  data_time: 0.0085  memory: 5975  grad_norm: 1091.1971  loss: 33.3115  decode.loss_cls: 0.6105  decode.loss_mask: 1.5277  decode.loss_dice: 1.1488  decode.d0.loss_cls: 0.9780  decode.d0.loss_mask: 1.4897  decode.d0.loss_dice: 1.1328  decode.d1.loss_cls: 0.6730  decode.d1.loss_mask: 1.5021  decode.d1.loss_dice: 1.1222  decode.d2.loss_cls: 0.6691  decode.d2.loss_mask: 1.5341  decode.d2.loss_dice: 1.1194  decode.d3.loss_cls: 0.6663  decode.d3.loss_mask: 1.5395  decode.d3.loss_dice: 1.1250  decode.d4.loss_cls: 0.7120  decode.d4.loss_mask: 1.5115  decode.d4.loss_dice: 1.1170  decode.d5.loss_cls: 0.6609  decode.d5.loss_mask: 1.5014  decode.d5.loss_dice: 1.1153  decode.d6.loss_cls: 0.6589  decode.d6.loss_mask: 1.5237  decode.d6.loss_dice: 1.1494  decode.d7.loss_cls: 0.6457  decode.d7.loss_mask: 1.5234  decode.d7.loss_dice: 1.0936  decode.d8.loss_cls: 0.6102  decode.d8.loss_mask: 1.5100  decode.d8.loss_dice: 1.1401
05/26 11:25:09 - mmengine - INFO - Iter(train) [  4500/160000]  base_lr: 9.7466e-05 lr: 9.7466e-06  eta: 18:01:40  time: 0.4043  data_time: 0.0084  memory: 5967  grad_norm: 864.9520  loss: 32.9132  decode.loss_cls: 0.7541  decode.loss_mask: 1.4492  decode.loss_dice: 1.1125  decode.d0.loss_cls: 0.9446  decode.d0.loss_mask: 1.3668  decode.d0.loss_dice: 1.1273  decode.d1.loss_cls: 0.7513  decode.d1.loss_mask: 1.3712  decode.d1.loss_dice: 1.1269  decode.d2.loss_cls: 0.7362  decode.d2.loss_mask: 1.3826  decode.d2.loss_dice: 1.1178  decode.d3.loss_cls: 0.8057  decode.d3.loss_mask: 1.4034  decode.d3.loss_dice: 1.1044  decode.d4.loss_cls: 0.7877  decode.d4.loss_mask: 1.3803  decode.d4.loss_dice: 1.1073  decode.d5.loss_cls: 0.7954  decode.d5.loss_mask: 1.3689  decode.d5.loss_dice: 1.1025  decode.d6.loss_cls: 0.8018  decode.d6.loss_mask: 1.4008  decode.d6.loss_dice: 1.0908  decode.d7.loss_cls: 0.7464  decode.d7.loss_mask: 1.4049  decode.d7.loss_dice: 1.1075  decode.d8.loss_cls: 0.7474  decode.d8.loss_mask: 1.4218  decode.d8.loss_dice: 1.0959
05/26 11:25:30 - mmengine - INFO - Iter(train) [  4550/160000]  base_lr: 9.7437e-05 lr: 9.7437e-06  eta: 18:01:02  time: 0.4038  data_time: 0.0084  memory: 5976  grad_norm: 680.6474  loss: 38.0207  decode.loss_cls: 1.0306  decode.loss_mask: 1.4851  decode.loss_dice: 1.4303  decode.d0.loss_cls: 1.1980  decode.d0.loss_mask: 1.3857  decode.d0.loss_dice: 1.3959  decode.d1.loss_cls: 0.8605  decode.d1.loss_mask: 1.3885  decode.d1.loss_dice: 1.3219  decode.d2.loss_cls: 0.9050  decode.d2.loss_mask: 1.3908  decode.d2.loss_dice: 1.3230  decode.d3.loss_cls: 0.9425  decode.d3.loss_mask: 1.5039  decode.d3.loss_dice: 1.3833  decode.d4.loss_cls: 0.9586  decode.d4.loss_mask: 1.4716  decode.d4.loss_dice: 1.4576  decode.d5.loss_cls: 0.9274  decode.d5.loss_mask: 1.4202  decode.d5.loss_dice: 1.4091  decode.d6.loss_cls: 1.0105  decode.d6.loss_mask: 1.4345  decode.d6.loss_dice: 1.3448  decode.d7.loss_cls: 0.9785  decode.d7.loss_mask: 1.4471  decode.d7.loss_dice: 1.3525  decode.d8.loss_cls: 1.0091  decode.d8.loss_mask: 1.4529  decode.d8.loss_dice: 1.4014
05/26 11:25:50 - mmengine - INFO - Iter(train) [  4600/160000]  base_lr: 9.7409e-05 lr: 9.7409e-06  eta: 18:00:21  time: 0.4056  data_time: 0.0085  memory: 5980  grad_norm: 677.7465  loss: 30.6334  decode.loss_cls: 0.6168  decode.loss_mask: 1.4324  decode.loss_dice: 0.9834  decode.d0.loss_cls: 0.8662  decode.d0.loss_mask: 1.3817  decode.d0.loss_dice: 0.9743  decode.d1.loss_cls: 0.5495  decode.d1.loss_mask: 1.4468  decode.d1.loss_dice: 1.0085  decode.d2.loss_cls: 0.5730  decode.d2.loss_mask: 1.4785  decode.d2.loss_dice: 0.9684  decode.d3.loss_cls: 0.6166  decode.d3.loss_mask: 1.4299  decode.d3.loss_dice: 0.9935  decode.d4.loss_cls: 0.6827  decode.d4.loss_mask: 1.4245  decode.d4.loss_dice: 0.9560  decode.d5.loss_cls: 0.6263  decode.d5.loss_mask: 1.4178  decode.d5.loss_dice: 1.0165  decode.d6.loss_cls: 0.6678  decode.d6.loss_mask: 1.4691  decode.d6.loss_dice: 1.0017  decode.d7.loss_cls: 0.6134  decode.d7.loss_mask: 1.3915  decode.d7.loss_dice: 0.9551  decode.d8.loss_cls: 0.6461  decode.d8.loss_mask: 1.4764  decode.d8.loss_dice: 0.9688
05/26 11:26:10 - mmengine - INFO - Iter(train) [  4650/160000]  base_lr: 9.7381e-05 lr: 9.7381e-06  eta: 17:59:40  time: 0.4042  data_time: 0.0083  memory: 5966  grad_norm: 943.4697  loss: 35.0728  decode.loss_cls: 0.7298  decode.loss_mask: 1.4773  decode.loss_dice: 1.2439  decode.d0.loss_cls: 1.0640  decode.d0.loss_mask: 1.4207  decode.d0.loss_dice: 1.2005  decode.d1.loss_cls: 0.8331  decode.d1.loss_mask: 1.4703  decode.d1.loss_dice: 1.2622  decode.d2.loss_cls: 0.7826  decode.d2.loss_mask: 1.5134  decode.d2.loss_dice: 1.2392  decode.d3.loss_cls: 0.8069  decode.d3.loss_mask: 1.4369  decode.d3.loss_dice: 1.2120  decode.d4.loss_cls: 0.8370  decode.d4.loss_mask: 1.4614  decode.d4.loss_dice: 1.2346  decode.d5.loss_cls: 0.7628  decode.d5.loss_mask: 1.4607  decode.d5.loss_dice: 1.2171  decode.d6.loss_cls: 0.8007  decode.d6.loss_mask: 1.4220  decode.d6.loss_dice: 1.1649  decode.d7.loss_cls: 0.8844  decode.d7.loss_mask: 1.4993  decode.d7.loss_dice: 1.2294  decode.d8.loss_cls: 0.6412  decode.d8.loss_mask: 1.5069  decode.d8.loss_dice: 1.2577
05/26 11:26:31 - mmengine - INFO - Iter(train) [  4700/160000]  base_lr: 9.7353e-05 lr: 9.7353e-06  eta: 17:59:00  time: 0.4046  data_time: 0.0085  memory: 5967  grad_norm: 706.3430  loss: 33.5368  decode.loss_cls: 0.6372  decode.loss_mask: 1.3991  decode.loss_dice: 1.2712  decode.d0.loss_cls: 0.8816  decode.d0.loss_mask: 1.3865  decode.d0.loss_dice: 1.2713  decode.d1.loss_cls: 0.6101  decode.d1.loss_mask: 1.3522  decode.d1.loss_dice: 1.2258  decode.d2.loss_cls: 0.6562  decode.d2.loss_mask: 1.4138  decode.d2.loss_dice: 1.2699  decode.d3.loss_cls: 0.6724  decode.d3.loss_mask: 1.4484  decode.d3.loss_dice: 1.2677  decode.d4.loss_cls: 0.7148  decode.d4.loss_mask: 1.4313  decode.d4.loss_dice: 1.2945  decode.d5.loss_cls: 0.6914  decode.d5.loss_mask: 1.3860  decode.d5.loss_dice: 1.2886  decode.d6.loss_cls: 0.6662  decode.d6.loss_mask: 1.3726  decode.d6.loss_dice: 1.2668  decode.d7.loss_cls: 0.6310  decode.d7.loss_mask: 1.4640  decode.d7.loss_dice: 1.2862  decode.d8.loss_cls: 0.5802  decode.d8.loss_mask: 1.4230  decode.d8.loss_dice: 1.2771
05/26 11:26:51 - mmengine - INFO - Iter(train) [  4750/160000]  base_lr: 9.7325e-05 lr: 9.7325e-06  eta: 17:58:20  time: 0.4040  data_time: 0.0085  memory: 5986  grad_norm: 975.6313  loss: 33.7899  decode.loss_cls: 0.7749  decode.loss_mask: 1.3599  decode.loss_dice: 1.1964  decode.d0.loss_cls: 1.0015  decode.d0.loss_mask: 1.3001  decode.d0.loss_dice: 1.2436  decode.d1.loss_cls: 0.7181  decode.d1.loss_mask: 1.3479  decode.d1.loss_dice: 1.2336  decode.d2.loss_cls: 0.8361  decode.d2.loss_mask: 1.3411  decode.d2.loss_dice: 1.1797  decode.d3.loss_cls: 0.8048  decode.d3.loss_mask: 1.3161  decode.d3.loss_dice: 1.2204  decode.d4.loss_cls: 0.8894  decode.d4.loss_mask: 1.3001  decode.d4.loss_dice: 1.2073  decode.d5.loss_cls: 0.8563  decode.d5.loss_mask: 1.3316  decode.d5.loss_dice: 1.1937  decode.d6.loss_cls: 0.7975  decode.d6.loss_mask: 1.3695  decode.d6.loss_dice: 1.2137  decode.d7.loss_cls: 0.8322  decode.d7.loss_mask: 1.3910  decode.d7.loss_dice: 1.2101  decode.d8.loss_cls: 0.7517  decode.d8.loss_mask: 1.3399  decode.d8.loss_dice: 1.2317
05/26 11:27:11 - mmengine - INFO - Iter(train) [  4800/160000]  base_lr: 9.7296e-05 lr: 9.7296e-06  eta: 17:57:40  time: 0.4049  data_time: 0.0084  memory: 5973  grad_norm: 738.0085  loss: 36.0924  decode.loss_cls: 0.8029  decode.loss_mask: 1.5592  decode.loss_dice: 1.2410  decode.d0.loss_cls: 1.0329  decode.d0.loss_mask: 1.4561  decode.d0.loss_dice: 1.1824  decode.d1.loss_cls: 0.8332  decode.d1.loss_mask: 1.5236  decode.d1.loss_dice: 1.2191  decode.d2.loss_cls: 1.0410  decode.d2.loss_mask: 1.3355  decode.d2.loss_dice: 1.1340  decode.d3.loss_cls: 0.9294  decode.d3.loss_mask: 1.4323  decode.d3.loss_dice: 1.1439  decode.d4.loss_cls: 0.9796  decode.d4.loss_mask: 1.5712  decode.d4.loss_dice: 1.1792  decode.d5.loss_cls: 0.8907  decode.d5.loss_mask: 1.5622  decode.d5.loss_dice: 1.2039  decode.d6.loss_cls: 0.8809  decode.d6.loss_mask: 1.4965  decode.d6.loss_dice: 1.2150  decode.d7.loss_cls: 0.8788  decode.d7.loss_mask: 1.5803  decode.d7.loss_dice: 1.2543  decode.d8.loss_cls: 0.8443  decode.d8.loss_mask: 1.5133  decode.d8.loss_dice: 1.1756
05/26 11:27:31 - mmengine - INFO - Iter(train) [  4850/160000]  base_lr: 9.7268e-05 lr: 9.7268e-06  eta: 17:57:01  time: 0.4039  data_time: 0.0084  memory: 5969  grad_norm: 788.5871  loss: 35.0624  decode.loss_cls: 0.7275  decode.loss_mask: 1.5696  decode.loss_dice: 1.1217  decode.d0.loss_cls: 1.0157  decode.d0.loss_mask: 1.5729  decode.d0.loss_dice: 1.1583  decode.d1.loss_cls: 0.7356  decode.d1.loss_mask: 1.5311  decode.d1.loss_dice: 1.1171  decode.d2.loss_cls: 0.7201  decode.d2.loss_mask: 1.5485  decode.d2.loss_dice: 1.1189  decode.d3.loss_cls: 0.6718  decode.d3.loss_mask: 1.6409  decode.d3.loss_dice: 1.1775  decode.d4.loss_cls: 0.7705  decode.d4.loss_mask: 1.5748  decode.d4.loss_dice: 1.1808  decode.d5.loss_cls: 0.7592  decode.d5.loss_mask: 1.5795  decode.d5.loss_dice: 1.1712  decode.d6.loss_cls: 0.7098  decode.d6.loss_mask: 1.6888  decode.d6.loss_dice: 1.2206  decode.d7.loss_cls: 0.7450  decode.d7.loss_mask: 1.6167  decode.d7.loss_dice: 1.1746  decode.d8.loss_cls: 0.6619  decode.d8.loss_mask: 1.6412  decode.d8.loss_dice: 1.1405
05/26 11:27:52 - mmengine - INFO - Iter(train) [  4900/160000]  base_lr: 9.7240e-05 lr: 9.7240e-06  eta: 17:56:22  time: 0.4042  data_time: 0.0085  memory: 5970  grad_norm: 643.4671  loss: 32.4299  decode.loss_cls: 0.7190  decode.loss_mask: 1.4455  decode.loss_dice: 1.0221  decode.d0.loss_cls: 0.9713  decode.d0.loss_mask: 1.5045  decode.d0.loss_dice: 1.1031  decode.d1.loss_cls: 0.6511  decode.d1.loss_mask: 1.4737  decode.d1.loss_dice: 1.0594  decode.d2.loss_cls: 0.6837  decode.d2.loss_mask: 1.4798  decode.d2.loss_dice: 1.0370  decode.d3.loss_cls: 0.6984  decode.d3.loss_mask: 1.4517  decode.d3.loss_dice: 1.0386  decode.d4.loss_cls: 0.7068  decode.d4.loss_mask: 1.4717  decode.d4.loss_dice: 1.0251  decode.d5.loss_cls: 0.6193  decode.d5.loss_mask: 1.5341  decode.d5.loss_dice: 1.0776  decode.d6.loss_cls: 0.6851  decode.d6.loss_mask: 1.4992  decode.d6.loss_dice: 1.1460  decode.d7.loss_cls: 0.5844  decode.d7.loss_mask: 1.4903  decode.d7.loss_dice: 1.0732  decode.d8.loss_cls: 0.6127  decode.d8.loss_mask: 1.5298  decode.d8.loss_dice: 1.0357
05/26 11:28:12 - mmengine - INFO - Iter(train) [  4950/160000]  base_lr: 9.7212e-05 lr: 9.7212e-06  eta: 17:55:44  time: 0.4059  data_time: 0.0085  memory: 5970  grad_norm: 654.4941  loss: 33.6760  decode.loss_cls: 0.6648  decode.loss_mask: 1.3511  decode.loss_dice: 1.2722  decode.d0.loss_cls: 0.9161  decode.d0.loss_mask: 1.3650  decode.d0.loss_dice: 1.2847  decode.d1.loss_cls: 0.6799  decode.d1.loss_mask: 1.3511  decode.d1.loss_dice: 1.2211  decode.d2.loss_cls: 0.6495  decode.d2.loss_mask: 1.3985  decode.d2.loss_dice: 1.2521  decode.d3.loss_cls: 0.6717  decode.d3.loss_mask: 1.4047  decode.d3.loss_dice: 1.2387  decode.d4.loss_cls: 0.7579  decode.d4.loss_mask: 1.4091  decode.d4.loss_dice: 1.2717  decode.d5.loss_cls: 0.7523  decode.d5.loss_mask: 1.4122  decode.d5.loss_dice: 1.2583  decode.d6.loss_cls: 0.7018  decode.d6.loss_mask: 1.4041  decode.d6.loss_dice: 1.2794  decode.d7.loss_cls: 0.6390  decode.d7.loss_mask: 1.4196  decode.d7.loss_dice: 1.2737  decode.d8.loss_cls: 0.6500  decode.d8.loss_mask: 1.4280  decode.d8.loss_dice: 1.2978
05/26 11:28:32 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 11:28:32 - mmengine - INFO - Iter(train) [  5000/160000]  base_lr: 9.7184e-05 lr: 9.7184e-06  eta: 17:55:06  time: 0.4064  data_time: 0.0084  memory: 5984  grad_norm: 662.4791  loss: 34.2041  decode.loss_cls: 0.7190  decode.loss_mask: 1.3722  decode.loss_dice: 1.2310  decode.d0.loss_cls: 0.9469  decode.d0.loss_mask: 1.3379  decode.d0.loss_dice: 1.2146  decode.d1.loss_cls: 0.7057  decode.d1.loss_mask: 1.3230  decode.d1.loss_dice: 1.2504  decode.d2.loss_cls: 0.8012  decode.d2.loss_mask: 1.3490  decode.d2.loss_dice: 1.3058  decode.d3.loss_cls: 0.7554  decode.d3.loss_mask: 1.3865  decode.d3.loss_dice: 1.2538  decode.d4.loss_cls: 0.7924  decode.d4.loss_mask: 1.3465  decode.d4.loss_dice: 1.2486  decode.d5.loss_cls: 0.8518  decode.d5.loss_mask: 1.3260  decode.d5.loss_dice: 1.2015  decode.d6.loss_cls: 0.8757  decode.d6.loss_mask: 1.4629  decode.d6.loss_dice: 1.3103  decode.d7.loss_cls: 0.7625  decode.d7.loss_mask: 1.4418  decode.d7.loss_dice: 1.3133  decode.d8.loss_cls: 0.7076  decode.d8.loss_mask: 1.3857  decode.d8.loss_dice: 1.2250
05/26 11:28:32 - mmengine - INFO - Saving checkpoint at 5000 iterations
05/26 11:28:51 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:07:49  time: 0.1788  data_time: 0.0013  memory: 13304  
05/26 11:28:57 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:05:14  time: 0.0499  data_time: 0.0012  memory: 13261  
05/26 11:29:02 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:04:07  time: 0.0955  data_time: 0.0011  memory: 13316  
05/26 11:29:06 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:03:18  time: 0.1222  data_time: 0.0012  memory: 13238  
05/26 11:29:08 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:02:44  time: 0.0487  data_time: 0.0012  memory: 1299  
05/26 11:29:11 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:02:20  time: 0.0492  data_time: 0.0012  memory: 1279  
05/26 11:29:14 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:02:05  time: 0.0488  data_time: 0.0012  memory: 13238  
05/26 11:29:17 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:01:53  time: 0.0514  data_time: 0.0019  memory: 13286  
05/26 11:29:20 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:01:41  time: 0.0484  data_time: 0.0012  memory: 1300  
05/26 11:29:23 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:01:32  time: 0.1017  data_time: 0.0012  memory: 13322  
05/26 11:29:27 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:01:26  time: 0.0493  data_time: 0.0012  memory: 13293  
05/26 11:29:30 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:01:18  time: 0.0490  data_time: 0.0012  memory: 1300  
05/26 11:29:32 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:01:11  time: 0.0499  data_time: 0.0012  memory: 1206  
05/26 11:29:36 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:01:06  time: 0.1390  data_time: 0.0012  memory: 13291  
05/26 11:29:39 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:01:00  time: 0.0499  data_time: 0.0012  memory: 13282  
05/26 11:29:44 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:56  time: 0.1386  data_time: 0.0013  memory: 13306  
05/26 11:29:46 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:50  time: 0.0489  data_time: 0.0012  memory: 1279  
05/26 11:29:49 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:45  time: 0.0493  data_time: 0.0012  memory: 1206  
05/26 11:29:51 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:40  time: 0.0492  data_time: 0.0012  memory: 1206  
05/26 11:29:54 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:36  time: 0.0484  data_time: 0.0012  memory: 13293  
05/26 11:29:57 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:31  time: 0.0487  data_time: 0.0012  memory: 1243  
05/26 11:30:00 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:27  time: 0.0939  data_time: 0.0012  memory: 13311  
05/26 11:30:02 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:22  time: 0.0490  data_time: 0.0012  memory: 1261  
05/26 11:30:05 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:18  time: 0.0494  data_time: 0.0012  memory: 1300  
05/26 11:30:07 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:14  time: 0.0492  data_time: 0.0013  memory: 13309  
05/26 11:30:10 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:10  time: 0.0483  data_time: 0.0012  memory: 1300  
05/26 11:30:12 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:07  time: 0.0507  data_time: 0.0012  memory: 1279  
05/26 11:30:15 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:03  time: 0.0488  data_time: 0.0012  memory: 1206  
05/26 11:30:17 - mmengine - INFO - per class results:
05/26 11:30:17 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 91.86 | 93.63 |
|  aeroplane  | 33.24 | 79.16 |
|   bicycle   |  6.51 |  7.12 |
|     bird    | 22.61 | 79.14 |
|     boat    |  4.62 |  5.25 |
|    bottle   |  1.55 |  1.56 |
|     bus     | 38.47 | 90.59 |
|     car     | 26.69 | 32.32 |
|     cat     | 47.72 | 91.12 |
|    chair    | 15.97 |  28.2 |
|     cow     |  0.0  |  0.0  |
| diningtable | 27.44 | 38.03 |
|     dog     |  7.86 | 13.64 |
|    horse    |  0.72 |  0.72 |
|  motorbike  | 26.17 | 31.78 |
|    person   | 71.98 | 74.89 |
| pottedplant |  0.02 |  0.02 |
|    sheep    |  0.0  |  0.0  |
|     sofa    | 14.47 | 68.44 |
|    train    | 19.86 | 29.79 |
|  tvmonitor  | 11.01 | 13.08 |
+-------------+-------+-------+
05/26 11:30:17 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 81.0700  mIoU: 22.3200  mAcc: 37.0700  data_time: 0.0024  time: 0.0712
05/26 11:30:18 - mmengine - INFO - The best checkpoint with 22.3200 mIoU at 5000 iter is saved to best_mIoU_iter_5000.pth.
05/26 11:30:41 - mmengine - INFO - Iter(train) [  5050/160000]  base_lr: 9.7155e-05 lr: 9.7155e-06  eta: 17:56:02  time: 0.4058  data_time: 0.0085  memory: 5992  grad_norm: 766.7675  loss: 32.2631  decode.loss_cls: 0.4635  decode.loss_mask: 1.6272  decode.loss_dice: 1.0673  decode.d0.loss_cls: 0.8395  decode.d0.loss_mask: 1.5680  decode.d0.loss_dice: 1.0067  decode.d1.loss_cls: 0.4627  decode.d1.loss_mask: 1.5972  decode.d1.loss_dice: 1.0552  decode.d2.loss_cls: 0.5288  decode.d2.loss_mask: 1.6310  decode.d2.loss_dice: 1.0525  decode.d3.loss_cls: 0.5409  decode.d3.loss_mask: 1.5963  decode.d3.loss_dice: 1.0681  decode.d4.loss_cls: 0.5850  decode.d4.loss_mask: 1.5909  decode.d4.loss_dice: 1.0744  decode.d5.loss_cls: 0.5716  decode.d5.loss_mask: 1.5853  decode.d5.loss_dice: 1.0298  decode.d6.loss_cls: 0.5455  decode.d6.loss_mask: 1.5925  decode.d6.loss_dice: 1.0478  decode.d7.loss_cls: 0.5008  decode.d7.loss_mask: 1.6631  decode.d7.loss_dice: 1.1130  decode.d8.loss_cls: 0.4726  decode.d8.loss_mask: 1.6454  decode.d8.loss_dice: 1.1406
05/26 11:31:01 - mmengine - INFO - Iter(train) [  5100/160000]  base_lr: 9.7127e-05 lr: 9.7127e-06  eta: 17:55:27  time: 0.4057  data_time: 0.0085  memory: 5973  grad_norm: 717.5535  loss: 35.2433  decode.loss_cls: 0.7053  decode.loss_mask: 1.4475  decode.loss_dice: 1.2806  decode.d0.loss_cls: 0.9176  decode.d0.loss_mask: 1.4855  decode.d0.loss_dice: 1.2716  decode.d1.loss_cls: 0.6844  decode.d1.loss_mask: 1.4630  decode.d1.loss_dice: 1.2937  decode.d2.loss_cls: 0.7965  decode.d2.loss_mask: 1.4721  decode.d2.loss_dice: 1.3160  decode.d3.loss_cls: 0.7153  decode.d3.loss_mask: 1.5107  decode.d3.loss_dice: 1.3578  decode.d4.loss_cls: 0.7477  decode.d4.loss_mask: 1.4771  decode.d4.loss_dice: 1.2727  decode.d5.loss_cls: 0.7592  decode.d5.loss_mask: 1.4165  decode.d5.loss_dice: 1.2796  decode.d6.loss_cls: 0.7098  decode.d6.loss_mask: 1.4861  decode.d6.loss_dice: 1.3220  decode.d7.loss_cls: 0.7142  decode.d7.loss_mask: 1.4963  decode.d7.loss_dice: 1.2755  decode.d8.loss_cls: 0.6974  decode.d8.loss_mask: 1.5094  decode.d8.loss_dice: 1.3624
05/26 11:31:21 - mmengine - INFO - Iter(train) [  5150/160000]  base_lr: 9.7099e-05 lr: 9.7099e-06  eta: 17:54:52  time: 0.4062  data_time: 0.0084  memory: 5987  grad_norm: 1050.3070  loss: 39.2923  decode.loss_cls: 0.7935  decode.loss_mask: 1.6918  decode.loss_dice: 1.3104  decode.d0.loss_cls: 1.0799  decode.d0.loss_mask: 1.7058  decode.d0.loss_dice: 1.3463  decode.d1.loss_cls: 0.8483  decode.d1.loss_mask: 1.6748  decode.d1.loss_dice: 1.2822  decode.d2.loss_cls: 0.8402  decode.d2.loss_mask: 1.7139  decode.d2.loss_dice: 1.2812  decode.d3.loss_cls: 0.7870  decode.d3.loss_mask: 1.7602  decode.d3.loss_dice: 1.3836  decode.d4.loss_cls: 0.8282  decode.d4.loss_mask: 1.7473  decode.d4.loss_dice: 1.3270  decode.d5.loss_cls: 0.8197  decode.d5.loss_mask: 1.7578  decode.d5.loss_dice: 1.3173  decode.d6.loss_cls: 0.8628  decode.d6.loss_mask: 1.7341  decode.d6.loss_dice: 1.3691  decode.d7.loss_cls: 0.8067  decode.d7.loss_mask: 1.8353  decode.d7.loss_dice: 1.4003  decode.d8.loss_cls: 0.7823  decode.d8.loss_mask: 1.8481  decode.d8.loss_dice: 1.3570
05/26 11:31:42 - mmengine - INFO - Iter(train) [  5200/160000]  base_lr: 9.7071e-05 lr: 9.7071e-06  eta: 17:54:17  time: 0.4060  data_time: 0.0084  memory: 5967  grad_norm: 909.4832  loss: 32.0294  decode.loss_cls: 0.6382  decode.loss_mask: 1.4198  decode.loss_dice: 1.1362  decode.d0.loss_cls: 0.9536  decode.d0.loss_mask: 1.3552  decode.d0.loss_dice: 1.1122  decode.d1.loss_cls: 0.6021  decode.d1.loss_mask: 1.4036  decode.d1.loss_dice: 1.1336  decode.d2.loss_cls: 0.6402  decode.d2.loss_mask: 1.4340  decode.d2.loss_dice: 1.1225  decode.d3.loss_cls: 0.5901  decode.d3.loss_mask: 1.4554  decode.d3.loss_dice: 1.1306  decode.d4.loss_cls: 0.6340  decode.d4.loss_mask: 1.4016  decode.d4.loss_dice: 1.1401  decode.d5.loss_cls: 0.6249  decode.d5.loss_mask: 1.4232  decode.d5.loss_dice: 1.1176  decode.d6.loss_cls: 0.6727  decode.d6.loss_mask: 1.4647  decode.d6.loss_dice: 1.1901  decode.d7.loss_cls: 0.5388  decode.d7.loss_mask: 1.4677  decode.d7.loss_dice: 1.1440  decode.d8.loss_cls: 0.5128  decode.d8.loss_mask: 1.4611  decode.d8.loss_dice: 1.1087
05/26 11:32:02 - mmengine - INFO - Iter(train) [  5250/160000]  base_lr: 9.7043e-05 lr: 9.7043e-06  eta: 17:53:42  time: 0.4066  data_time: 0.0085  memory: 5976  grad_norm: 693.5682  loss: 34.8490  decode.loss_cls: 0.6697  decode.loss_mask: 1.5380  decode.loss_dice: 1.3102  decode.d0.loss_cls: 1.0556  decode.d0.loss_mask: 1.4057  decode.d0.loss_dice: 1.1921  decode.d1.loss_cls: 0.7174  decode.d1.loss_mask: 1.4641  decode.d1.loss_dice: 1.1634  decode.d2.loss_cls: 0.7881  decode.d2.loss_mask: 1.4616  decode.d2.loss_dice: 1.1373  decode.d3.loss_cls: 0.8212  decode.d3.loss_mask: 1.4288  decode.d3.loss_dice: 1.1596  decode.d4.loss_cls: 0.7807  decode.d4.loss_mask: 1.5040  decode.d4.loss_dice: 1.2119  decode.d5.loss_cls: 0.8169  decode.d5.loss_mask: 1.4792  decode.d5.loss_dice: 1.2204  decode.d6.loss_cls: 0.7674  decode.d6.loss_mask: 1.4652  decode.d6.loss_dice: 1.2348  decode.d7.loss_cls: 0.6610  decode.d7.loss_mask: 1.5985  decode.d7.loss_dice: 1.3086  decode.d8.loss_cls: 0.6057  decode.d8.loss_mask: 1.5668  decode.d8.loss_dice: 1.3146
05/26 11:32:22 - mmengine - INFO - Iter(train) [  5300/160000]  base_lr: 9.7014e-05 lr: 9.7014e-06  eta: 17:53:07  time: 0.4069  data_time: 0.0085  memory: 5970  grad_norm: 904.7610  loss: 30.7452  decode.loss_cls: 0.6244  decode.loss_mask: 1.3504  decode.loss_dice: 1.0263  decode.d0.loss_cls: 0.9938  decode.d0.loss_mask: 1.3139  decode.d0.loss_dice: 1.0171  decode.d1.loss_cls: 0.6437  decode.d1.loss_mask: 1.3473  decode.d1.loss_dice: 0.9969  decode.d2.loss_cls: 0.6599  decode.d2.loss_mask: 1.3291  decode.d2.loss_dice: 1.0473  decode.d3.loss_cls: 0.6931  decode.d3.loss_mask: 1.3462  decode.d3.loss_dice: 1.0518  decode.d4.loss_cls: 0.7378  decode.d4.loss_mask: 1.3460  decode.d4.loss_dice: 0.9927  decode.d5.loss_cls: 0.6708  decode.d5.loss_mask: 1.3176  decode.d5.loss_dice: 1.0350  decode.d6.loss_cls: 0.6556  decode.d6.loss_mask: 1.3728  decode.d6.loss_dice: 1.0590  decode.d7.loss_cls: 0.6782  decode.d7.loss_mask: 1.3771  decode.d7.loss_dice: 1.0186  decode.d8.loss_cls: 0.5826  decode.d8.loss_mask: 1.4012  decode.d8.loss_dice: 1.0592
05/26 11:32:43 - mmengine - INFO - Iter(train) [  5350/160000]  base_lr: 9.6986e-05 lr: 9.6986e-06  eta: 17:52:33  time: 0.4085  data_time: 0.0085  memory: 5983  grad_norm: 1614.0887  loss: 35.9626  decode.loss_cls: 0.5955  decode.loss_mask: 1.6787  decode.loss_dice: 1.2176  decode.d0.loss_cls: 0.9135  decode.d0.loss_mask: 1.6202  decode.d0.loss_dice: 1.2109  decode.d1.loss_cls: 0.6902  decode.d1.loss_mask: 1.6677  decode.d1.loss_dice: 1.2494  decode.d2.loss_cls: 0.6304  decode.d2.loss_mask: 1.7531  decode.d2.loss_dice: 1.3213  decode.d3.loss_cls: 0.7411  decode.d3.loss_mask: 1.7342  decode.d3.loss_dice: 1.2195  decode.d4.loss_cls: 0.6818  decode.d4.loss_mask: 1.6762  decode.d4.loss_dice: 1.3050  decode.d5.loss_cls: 0.6994  decode.d5.loss_mask: 1.6436  decode.d5.loss_dice: 1.1485  decode.d6.loss_cls: 0.6768  decode.d6.loss_mask: 1.7141  decode.d6.loss_dice: 1.1630  decode.d7.loss_cls: 0.6124  decode.d7.loss_mask: 1.7103  decode.d7.loss_dice: 1.2074  decode.d8.loss_cls: 0.5914  decode.d8.loss_mask: 1.6796  decode.d8.loss_dice: 1.2094
05/26 11:33:03 - mmengine - INFO - Iter(train) [  5400/160000]  base_lr: 9.6958e-05 lr: 9.6958e-06  eta: 17:51:58  time: 0.4075  data_time: 0.0085  memory: 5968  grad_norm: 662.7071  loss: 31.9363  decode.loss_cls: 0.6179  decode.loss_mask: 1.2996  decode.loss_dice: 1.2563  decode.d0.loss_cls: 0.9832  decode.d0.loss_mask: 1.2038  decode.d0.loss_dice: 1.2351  decode.d1.loss_cls: 0.6016  decode.d1.loss_mask: 1.2680  decode.d1.loss_dice: 1.1757  decode.d2.loss_cls: 0.7220  decode.d2.loss_mask: 1.2146  decode.d2.loss_dice: 1.2113  decode.d3.loss_cls: 0.7047  decode.d3.loss_mask: 1.2616  decode.d3.loss_dice: 1.1926  decode.d4.loss_cls: 0.7732  decode.d4.loss_mask: 1.2171  decode.d4.loss_dice: 1.2034  decode.d5.loss_cls: 0.6180  decode.d5.loss_mask: 1.2818  decode.d5.loss_dice: 1.2123  decode.d6.loss_cls: 0.6409  decode.d6.loss_mask: 1.3401  decode.d6.loss_dice: 1.2723  decode.d7.loss_cls: 0.6963  decode.d7.loss_mask: 1.3087  decode.d7.loss_dice: 1.2616  decode.d8.loss_cls: 0.5941  decode.d8.loss_mask: 1.3082  decode.d8.loss_dice: 1.2604
05/26 11:33:23 - mmengine - INFO - Iter(train) [  5450/160000]  base_lr: 9.6930e-05 lr: 9.6930e-06  eta: 17:51:24  time: 0.4072  data_time: 0.0085  memory: 5973  grad_norm: 996.4490  loss: 38.7351  decode.loss_cls: 0.9021  decode.loss_mask: 1.5822  decode.loss_dice: 1.3373  decode.d0.loss_cls: 1.1263  decode.d0.loss_mask: 1.6063  decode.d0.loss_dice: 1.3517  decode.d1.loss_cls: 0.8176  decode.d1.loss_mask: 1.6880  decode.d1.loss_dice: 1.3292  decode.d2.loss_cls: 0.8551  decode.d2.loss_mask: 1.6394  decode.d2.loss_dice: 1.2650  decode.d3.loss_cls: 0.9377  decode.d3.loss_mask: 1.6439  decode.d3.loss_dice: 1.3997  decode.d4.loss_cls: 0.8982  decode.d4.loss_mask: 1.6168  decode.d4.loss_dice: 1.3219  decode.d5.loss_cls: 0.9532  decode.d5.loss_mask: 1.5751  decode.d5.loss_dice: 1.3107  decode.d6.loss_cls: 0.9502  decode.d6.loss_mask: 1.6061  decode.d6.loss_dice: 1.3930  decode.d7.loss_cls: 0.8974  decode.d7.loss_mask: 1.6063  decode.d7.loss_dice: 1.3523  decode.d8.loss_cls: 0.8426  decode.d8.loss_mask: 1.6099  decode.d8.loss_dice: 1.3196
05/26 11:33:44 - mmengine - INFO - Iter(train) [  5500/160000]  base_lr: 9.6901e-05 lr: 9.6901e-06  eta: 17:50:51  time: 0.4075  data_time: 0.0087  memory: 5968  grad_norm: 1079.6809  loss: 31.1401  decode.loss_cls: 0.6848  decode.loss_mask: 1.3139  decode.loss_dice: 1.0517  decode.d0.loss_cls: 0.9793  decode.d0.loss_mask: 1.3120  decode.d0.loss_dice: 1.0673  decode.d1.loss_cls: 0.6604  decode.d1.loss_mask: 1.3368  decode.d1.loss_dice: 1.0577  decode.d2.loss_cls: 0.6623  decode.d2.loss_mask: 1.3334  decode.d2.loss_dice: 1.0644  decode.d3.loss_cls: 0.6556  decode.d3.loss_mask: 1.3490  decode.d3.loss_dice: 1.0390  decode.d4.loss_cls: 0.6599  decode.d4.loss_mask: 1.3473  decode.d4.loss_dice: 1.1263  decode.d5.loss_cls: 0.6393  decode.d5.loss_mask: 1.4233  decode.d5.loss_dice: 1.1774  decode.d6.loss_cls: 0.6519  decode.d6.loss_mask: 1.3684  decode.d6.loss_dice: 1.1132  decode.d7.loss_cls: 0.6656  decode.d7.loss_mask: 1.3513  decode.d7.loss_dice: 1.0646  decode.d8.loss_cls: 0.6718  decode.d8.loss_mask: 1.2890  decode.d8.loss_dice: 1.0232
05/26 11:34:04 - mmengine - INFO - Iter(train) [  5550/160000]  base_lr: 9.6873e-05 lr: 9.6873e-06  eta: 17:50:18  time: 0.4077  data_time: 0.0085  memory: 5976  grad_norm: 1180.6708  loss: 34.0243  decode.loss_cls: 0.8325  decode.loss_mask: 1.3483  decode.loss_dice: 1.1988  decode.d0.loss_cls: 1.1253  decode.d0.loss_mask: 1.2843  decode.d0.loss_dice: 1.2156  decode.d1.loss_cls: 0.7176  decode.d1.loss_mask: 1.3956  decode.d1.loss_dice: 1.1961  decode.d2.loss_cls: 0.8388  decode.d2.loss_mask: 1.2871  decode.d2.loss_dice: 1.2247  decode.d3.loss_cls: 0.8236  decode.d3.loss_mask: 1.4057  decode.d3.loss_dice: 1.2119  decode.d4.loss_cls: 0.8708  decode.d4.loss_mask: 1.3536  decode.d4.loss_dice: 1.1888  decode.d5.loss_cls: 0.7843  decode.d5.loss_mask: 1.3348  decode.d5.loss_dice: 1.2115  decode.d6.loss_cls: 0.7777  decode.d6.loss_mask: 1.3959  decode.d6.loss_dice: 1.2024  decode.d7.loss_cls: 0.8409  decode.d7.loss_mask: 1.3644  decode.d7.loss_dice: 1.1788  decode.d8.loss_cls: 0.7991  decode.d8.loss_mask: 1.3975  decode.d8.loss_dice: 1.2179
05/26 11:34:24 - mmengine - INFO - Iter(train) [  5600/160000]  base_lr: 9.6845e-05 lr: 9.6845e-06  eta: 17:49:48  time: 0.4063  data_time: 0.0085  memory: 5978  grad_norm: 927.0480  loss: 28.1001  decode.loss_cls: 0.5168  decode.loss_mask: 1.3575  decode.loss_dice: 0.8700  decode.d0.loss_cls: 0.8243  decode.d0.loss_mask: 1.3262  decode.d0.loss_dice: 0.9275  decode.d1.loss_cls: 0.4849  decode.d1.loss_mask: 1.3753  decode.d1.loss_dice: 0.9273  decode.d2.loss_cls: 0.4861  decode.d2.loss_mask: 1.3671  decode.d2.loss_dice: 0.8823  decode.d3.loss_cls: 0.4644  decode.d3.loss_mask: 1.4341  decode.d3.loss_dice: 0.9296  decode.d4.loss_cls: 0.5519  decode.d4.loss_mask: 1.3401  decode.d4.loss_dice: 0.8943  decode.d5.loss_cls: 0.5536  decode.d5.loss_mask: 1.3883  decode.d5.loss_dice: 0.9282  decode.d6.loss_cls: 0.5434  decode.d6.loss_mask: 1.3569  decode.d6.loss_dice: 0.9006  decode.d7.loss_cls: 0.4760  decode.d7.loss_mask: 1.3626  decode.d7.loss_dice: 0.8882  decode.d8.loss_cls: 0.5262  decode.d8.loss_mask: 1.3330  decode.d8.loss_dice: 0.8832
05/26 11:34:45 - mmengine - INFO - Iter(train) [  5650/160000]  base_lr: 9.6817e-05 lr: 9.6817e-06  eta: 17:49:16  time: 0.4079  data_time: 0.0085  memory: 5973  grad_norm: 828.3870  loss: 32.3632  decode.loss_cls: 0.5896  decode.loss_mask: 1.4258  decode.loss_dice: 1.1036  decode.d0.loss_cls: 0.9545  decode.d0.loss_mask: 1.3206  decode.d0.loss_dice: 1.1121  decode.d1.loss_cls: 0.5881  decode.d1.loss_mask: 1.4241  decode.d1.loss_dice: 1.1014  decode.d2.loss_cls: 0.6128  decode.d2.loss_mask: 1.4432  decode.d2.loss_dice: 1.1643  decode.d3.loss_cls: 0.6228  decode.d3.loss_mask: 1.4660  decode.d3.loss_dice: 1.1096  decode.d4.loss_cls: 0.7888  decode.d4.loss_mask: 1.4302  decode.d4.loss_dice: 1.1217  decode.d5.loss_cls: 0.7184  decode.d5.loss_mask: 1.4293  decode.d5.loss_dice: 1.1309  decode.d6.loss_cls: 0.6190  decode.d6.loss_mask: 1.5513  decode.d6.loss_dice: 1.1892  decode.d7.loss_cls: 0.6189  decode.d7.loss_mask: 1.4498  decode.d7.loss_dice: 1.1329  decode.d8.loss_cls: 0.5942  decode.d8.loss_mask: 1.4464  decode.d8.loss_dice: 1.1039
05/26 11:35:05 - mmengine - INFO - Iter(train) [  5700/160000]  base_lr: 9.6789e-05 lr: 9.6789e-06  eta: 17:48:43  time: 0.4071  data_time: 0.0085  memory: 5976  grad_norm: 900.5843  loss: 34.9421  decode.loss_cls: 0.4624  decode.loss_mask: 1.7378  decode.loss_dice: 1.2173  decode.d0.loss_cls: 0.9591  decode.d0.loss_mask: 1.6360  decode.d0.loss_dice: 1.1294  decode.d1.loss_cls: 0.6108  decode.d1.loss_mask: 1.6523  decode.d1.loss_dice: 1.1767  decode.d2.loss_cls: 0.6518  decode.d2.loss_mask: 1.6175  decode.d2.loss_dice: 1.1429  decode.d3.loss_cls: 0.6574  decode.d3.loss_mask: 1.7020  decode.d3.loss_dice: 1.1551  decode.d4.loss_cls: 0.6092  decode.d4.loss_mask: 1.6509  decode.d4.loss_dice: 1.2038  decode.d5.loss_cls: 0.6760  decode.d5.loss_mask: 1.6050  decode.d5.loss_dice: 1.1501  decode.d6.loss_cls: 0.6421  decode.d6.loss_mask: 1.6486  decode.d6.loss_dice: 1.1732  decode.d7.loss_cls: 0.5987  decode.d7.loss_mask: 1.7434  decode.d7.loss_dice: 1.1774  decode.d8.loss_cls: 0.5064  decode.d8.loss_mask: 1.8080  decode.d8.loss_dice: 1.2408
05/26 11:35:25 - mmengine - INFO - Iter(train) [  5750/160000]  base_lr: 9.6760e-05 lr: 9.6760e-06  eta: 17:48:10  time: 0.4077  data_time: 0.0085  memory: 5966  grad_norm: 1239.9513  loss: 35.6027  decode.loss_cls: 0.8693  decode.loss_mask: 1.4791  decode.loss_dice: 1.2429  decode.d0.loss_cls: 1.0707  decode.d0.loss_mask: 1.4169  decode.d0.loss_dice: 1.2653  decode.d1.loss_cls: 0.8008  decode.d1.loss_mask: 1.3679  decode.d1.loss_dice: 1.2101  decode.d2.loss_cls: 0.8576  decode.d2.loss_mask: 1.4936  decode.d2.loss_dice: 1.2342  decode.d3.loss_cls: 0.8469  decode.d3.loss_mask: 1.4511  decode.d3.loss_dice: 1.2453  decode.d4.loss_cls: 0.8751  decode.d4.loss_mask: 1.4187  decode.d4.loss_dice: 1.2128  decode.d5.loss_cls: 0.8319  decode.d5.loss_mask: 1.4558  decode.d5.loss_dice: 1.2691  decode.d6.loss_cls: 0.8925  decode.d6.loss_mask: 1.3901  decode.d6.loss_dice: 1.2438  decode.d7.loss_cls: 0.9123  decode.d7.loss_mask: 1.4596  decode.d7.loss_dice: 1.2738  decode.d8.loss_cls: 0.9020  decode.d8.loss_mask: 1.3855  decode.d8.loss_dice: 1.2281
05/26 11:35:46 - mmengine - INFO - Iter(train) [  5800/160000]  base_lr: 9.6732e-05 lr: 9.6732e-06  eta: 17:47:37  time: 0.4073  data_time: 0.0087  memory: 5972  grad_norm: 713.2488  loss: 31.6081  decode.loss_cls: 0.5998  decode.loss_mask: 1.4690  decode.loss_dice: 1.0689  decode.d0.loss_cls: 0.8869  decode.d0.loss_mask: 1.4360  decode.d0.loss_dice: 1.0591  decode.d1.loss_cls: 0.5983  decode.d1.loss_mask: 1.4415  decode.d1.loss_dice: 1.0458  decode.d2.loss_cls: 0.6841  decode.d2.loss_mask: 1.3656  decode.d2.loss_dice: 0.9953  decode.d3.loss_cls: 0.6755  decode.d3.loss_mask: 1.4435  decode.d3.loss_dice: 1.0281  decode.d4.loss_cls: 0.7071  decode.d4.loss_mask: 1.4380  decode.d4.loss_dice: 1.0775  decode.d5.loss_cls: 0.6436  decode.d5.loss_mask: 1.4591  decode.d5.loss_dice: 1.0968  decode.d6.loss_cls: 0.6486  decode.d6.loss_mask: 1.4319  decode.d6.loss_dice: 1.0688  decode.d7.loss_cls: 0.6198  decode.d7.loss_mask: 1.4622  decode.d7.loss_dice: 1.0581  decode.d8.loss_cls: 0.5822  decode.d8.loss_mask: 1.4459  decode.d8.loss_dice: 1.0711
05/26 11:36:06 - mmengine - INFO - Iter(train) [  5850/160000]  base_lr: 9.6704e-05 lr: 9.6704e-06  eta: 17:47:06  time: 0.4062  data_time: 0.0085  memory: 5980  grad_norm: 830.9790  loss: 30.4277  decode.loss_cls: 0.5575  decode.loss_mask: 1.4698  decode.loss_dice: 0.9694  decode.d0.loss_cls: 0.9604  decode.d0.loss_mask: 1.4168  decode.d0.loss_dice: 0.9605  decode.d1.loss_cls: 0.5986  decode.d1.loss_mask: 1.4557  decode.d1.loss_dice: 0.9573  decode.d2.loss_cls: 0.6441  decode.d2.loss_mask: 1.4290  decode.d2.loss_dice: 0.9338  decode.d3.loss_cls: 0.6209  decode.d3.loss_mask: 1.4383  decode.d3.loss_dice: 0.9476  decode.d4.loss_cls: 0.6365  decode.d4.loss_mask: 1.4302  decode.d4.loss_dice: 0.9386  decode.d5.loss_cls: 0.6350  decode.d5.loss_mask: 1.4478  decode.d5.loss_dice: 0.9962  decode.d6.loss_cls: 0.6097  decode.d6.loss_mask: 1.4641  decode.d6.loss_dice: 1.0036  decode.d7.loss_cls: 0.5764  decode.d7.loss_mask: 1.4013  decode.d7.loss_dice: 0.9595  decode.d8.loss_cls: 0.6112  decode.d8.loss_mask: 1.4138  decode.d8.loss_dice: 0.9443
05/26 11:36:27 - mmengine - INFO - Iter(train) [  5900/160000]  base_lr: 9.6676e-05 lr: 9.6676e-06  eta: 17:46:33  time: 0.4056  data_time: 0.0085  memory: 5975  grad_norm: 1072.4165  loss: 37.3459  decode.loss_cls: 0.5985  decode.loss_mask: 1.8635  decode.loss_dice: 1.3037  decode.d0.loss_cls: 0.9226  decode.d0.loss_mask: 1.7998  decode.d0.loss_dice: 1.2814  decode.d1.loss_cls: 0.5880  decode.d1.loss_mask: 1.7962  decode.d1.loss_dice: 1.2699  decode.d2.loss_cls: 0.6088  decode.d2.loss_mask: 1.7979  decode.d2.loss_dice: 1.2809  decode.d3.loss_cls: 0.6004  decode.d3.loss_mask: 1.8263  decode.d3.loss_dice: 1.3152  decode.d4.loss_cls: 0.5536  decode.d4.loss_mask: 1.8702  decode.d4.loss_dice: 1.2929  decode.d5.loss_cls: 0.6229  decode.d5.loss_mask: 1.7666  decode.d5.loss_dice: 1.2569  decode.d6.loss_cls: 0.6599  decode.d6.loss_mask: 1.7621  decode.d6.loss_dice: 1.2399  decode.d7.loss_cls: 0.5829  decode.d7.loss_mask: 1.9069  decode.d7.loss_dice: 1.2900  decode.d8.loss_cls: 0.5460  decode.d8.loss_mask: 1.8806  decode.d8.loss_dice: 1.2615
05/26 11:36:47 - mmengine - INFO - Iter(train) [  5950/160000]  base_lr: 9.6647e-05 lr: 9.6647e-06  eta: 17:46:02  time: 0.4064  data_time: 0.0085  memory: 5969  grad_norm: 676.5392  loss: 28.8632  decode.loss_cls: 0.6165  decode.loss_mask: 1.2550  decode.loss_dice: 0.9787  decode.d0.loss_cls: 0.9185  decode.d0.loss_mask: 1.2059  decode.d0.loss_dice: 0.9569  decode.d1.loss_cls: 0.5965  decode.d1.loss_mask: 1.2464  decode.d1.loss_dice: 0.9890  decode.d2.loss_cls: 0.6314  decode.d2.loss_mask: 1.2637  decode.d2.loss_dice: 0.9957  decode.d3.loss_cls: 0.6140  decode.d3.loss_mask: 1.2664  decode.d3.loss_dice: 0.9407  decode.d4.loss_cls: 0.6530  decode.d4.loss_mask: 1.2427  decode.d4.loss_dice: 0.9879  decode.d5.loss_cls: 0.6016  decode.d5.loss_mask: 1.2942  decode.d5.loss_dice: 0.9528  decode.d6.loss_cls: 0.6278  decode.d6.loss_mask: 1.2472  decode.d6.loss_dice: 0.9762  decode.d7.loss_cls: 0.7030  decode.d7.loss_mask: 1.2719  decode.d7.loss_dice: 1.0003  decode.d8.loss_cls: 0.6064  decode.d8.loss_mask: 1.2425  decode.d8.loss_dice: 0.9803
05/26 11:37:07 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 11:37:07 - mmengine - INFO - Iter(train) [  6000/160000]  base_lr: 9.6619e-05 lr: 9.6619e-06  eta: 17:45:30  time: 0.4059  data_time: 0.0085  memory: 5983  grad_norm: 1532.3672  loss: 34.4426  decode.loss_cls: 0.5948  decode.loss_mask: 1.6358  decode.loss_dice: 1.1620  decode.d0.loss_cls: 1.0270  decode.d0.loss_mask: 1.5087  decode.d0.loss_dice: 1.1579  decode.d1.loss_cls: 0.7109  decode.d1.loss_mask: 1.5458  decode.d1.loss_dice: 1.1179  decode.d2.loss_cls: 0.7445  decode.d2.loss_mask: 1.5873  decode.d2.loss_dice: 1.1358  decode.d3.loss_cls: 0.6885  decode.d3.loss_mask: 1.5842  decode.d3.loss_dice: 1.1314  decode.d4.loss_cls: 0.6796  decode.d4.loss_mask: 1.6031  decode.d4.loss_dice: 1.1132  decode.d5.loss_cls: 0.7143  decode.d5.loss_mask: 1.6021  decode.d5.loss_dice: 1.1273  decode.d6.loss_cls: 0.6280  decode.d6.loss_mask: 1.5844  decode.d6.loss_dice: 1.1175  decode.d7.loss_cls: 0.6443  decode.d7.loss_mask: 1.6455  decode.d7.loss_dice: 1.1592  decode.d8.loss_cls: 0.6408  decode.d8.loss_mask: 1.6842  decode.d8.loss_dice: 1.1666
05/26 11:37:28 - mmengine - INFO - Iter(train) [  6050/160000]  base_lr: 9.6591e-05 lr: 9.6591e-06  eta: 17:44:59  time: 0.4061  data_time: 0.0086  memory: 5976  grad_norm: 608.3858  loss: 34.2366  decode.loss_cls: 0.6940  decode.loss_mask: 1.3449  decode.loss_dice: 1.2786  decode.d0.loss_cls: 0.9752  decode.d0.loss_mask: 1.3873  decode.d0.loss_dice: 1.3055  decode.d1.loss_cls: 0.7226  decode.d1.loss_mask: 1.4304  decode.d1.loss_dice: 1.2570  decode.d2.loss_cls: 0.7629  decode.d2.loss_mask: 1.3892  decode.d2.loss_dice: 1.2516  decode.d3.loss_cls: 0.7376  decode.d3.loss_mask: 1.4355  decode.d3.loss_dice: 1.2740  decode.d4.loss_cls: 0.7572  decode.d4.loss_mask: 1.4274  decode.d4.loss_dice: 1.2875  decode.d5.loss_cls: 0.7660  decode.d5.loss_mask: 1.4074  decode.d5.loss_dice: 1.2740  decode.d6.loss_cls: 0.7657  decode.d6.loss_mask: 1.3564  decode.d6.loss_dice: 1.2287  decode.d7.loss_cls: 0.7157  decode.d7.loss_mask: 1.3763  decode.d7.loss_dice: 1.2864  decode.d8.loss_cls: 0.7160  decode.d8.loss_mask: 1.3642  decode.d8.loss_dice: 1.2612
05/26 11:37:48 - mmengine - INFO - Iter(train) [  6100/160000]  base_lr: 9.6563e-05 lr: 9.6563e-06  eta: 17:44:28  time: 0.4091  data_time: 0.0109  memory: 5975  grad_norm: 989.2817  loss: 37.9193  decode.loss_cls: 0.8328  decode.loss_mask: 1.6494  decode.loss_dice: 1.3805  decode.d0.loss_cls: 1.1053  decode.d0.loss_mask: 1.4825  decode.d0.loss_dice: 1.2982  decode.d1.loss_cls: 0.8599  decode.d1.loss_mask: 1.5740  decode.d1.loss_dice: 1.2908  decode.d2.loss_cls: 0.9034  decode.d2.loss_mask: 1.5286  decode.d2.loss_dice: 1.2911  decode.d3.loss_cls: 0.9267  decode.d3.loss_mask: 1.6077  decode.d3.loss_dice: 1.2936  decode.d4.loss_cls: 0.8134  decode.d4.loss_mask: 1.6168  decode.d4.loss_dice: 1.3110  decode.d5.loss_cls: 0.9152  decode.d5.loss_mask: 1.5602  decode.d5.loss_dice: 1.2777  decode.d6.loss_cls: 0.8598  decode.d6.loss_mask: 1.6559  decode.d6.loss_dice: 1.3272  decode.d7.loss_cls: 0.7552  decode.d7.loss_mask: 1.6144  decode.d7.loss_dice: 1.3786  decode.d8.loss_cls: 0.7375  decode.d8.loss_mask: 1.7273  decode.d8.loss_dice: 1.3445
05/26 11:38:08 - mmengine - INFO - Iter(train) [  6150/160000]  base_lr: 9.6534e-05 lr: 9.6534e-06  eta: 17:43:57  time: 0.4066  data_time: 0.0085  memory: 5971  grad_norm: 548.7484  loss: 35.6872  decode.loss_cls: 0.8191  decode.loss_mask: 1.4131  decode.loss_dice: 1.2730  decode.d0.loss_cls: 1.1479  decode.d0.loss_mask: 1.3959  decode.d0.loss_dice: 1.2492  decode.d1.loss_cls: 0.8339  decode.d1.loss_mask: 1.3981  decode.d1.loss_dice: 1.2418  decode.d2.loss_cls: 0.8770  decode.d2.loss_mask: 1.4377  decode.d2.loss_dice: 1.2882  decode.d3.loss_cls: 0.8961  decode.d3.loss_mask: 1.4072  decode.d3.loss_dice: 1.2291  decode.d4.loss_cls: 0.8918  decode.d4.loss_mask: 1.3801  decode.d4.loss_dice: 1.2948  decode.d5.loss_cls: 0.9037  decode.d5.loss_mask: 1.3908  decode.d5.loss_dice: 1.2553  decode.d6.loss_cls: 0.8547  decode.d6.loss_mask: 1.3623  decode.d6.loss_dice: 1.2548  decode.d7.loss_cls: 0.8600  decode.d7.loss_mask: 1.4269  decode.d7.loss_dice: 1.3234  decode.d8.loss_cls: 0.7887  decode.d8.loss_mask: 1.4841  decode.d8.loss_dice: 1.3084
05/26 11:38:29 - mmengine - INFO - Iter(train) [  6200/160000]  base_lr: 9.6506e-05 lr: 9.6506e-06  eta: 17:43:25  time: 0.4055  data_time: 0.0085  memory: 5966  grad_norm: 969.3622  loss: 33.5264  decode.loss_cls: 0.6241  decode.loss_mask: 1.5633  decode.loss_dice: 1.0937  decode.d0.loss_cls: 0.8637  decode.d0.loss_mask: 1.6776  decode.d0.loss_dice: 1.1386  decode.d1.loss_cls: 0.6219  decode.d1.loss_mask: 1.6217  decode.d1.loss_dice: 1.0632  decode.d2.loss_cls: 0.6691  decode.d2.loss_mask: 1.5507  decode.d2.loss_dice: 1.0892  decode.d3.loss_cls: 0.6307  decode.d3.loss_mask: 1.6158  decode.d3.loss_dice: 1.0712  decode.d4.loss_cls: 0.6739  decode.d4.loss_mask: 1.7122  decode.d4.loss_dice: 1.0880  decode.d5.loss_cls: 0.6529  decode.d5.loss_mask: 1.6274  decode.d5.loss_dice: 1.0908  decode.d6.loss_cls: 0.5790  decode.d6.loss_mask: 1.6098  decode.d6.loss_dice: 1.0731  decode.d7.loss_cls: 0.5739  decode.d7.loss_mask: 1.6175  decode.d7.loss_dice: 1.0847  decode.d8.loss_cls: 0.5696  decode.d8.loss_mask: 1.6044  decode.d8.loss_dice: 1.0748
05/26 11:38:49 - mmengine - INFO - Iter(train) [  6250/160000]  base_lr: 9.6478e-05 lr: 9.6478e-06  eta: 17:42:54  time: 0.4060  data_time: 0.0085  memory: 5980  grad_norm: 1016.5475  loss: 32.0018  decode.loss_cls: 0.6787  decode.loss_mask: 1.3487  decode.loss_dice: 1.0634  decode.d0.loss_cls: 1.0895  decode.d0.loss_mask: 1.2968  decode.d0.loss_dice: 1.0955  decode.d1.loss_cls: 0.6806  decode.d1.loss_mask: 1.3353  decode.d1.loss_dice: 1.0893  decode.d2.loss_cls: 0.8324  decode.d2.loss_mask: 1.3106  decode.d2.loss_dice: 1.0871  decode.d3.loss_cls: 0.7616  decode.d3.loss_mask: 1.3296  decode.d3.loss_dice: 1.0718  decode.d4.loss_cls: 0.7682  decode.d4.loss_mask: 1.3288  decode.d4.loss_dice: 1.0963  decode.d5.loss_cls: 0.8199  decode.d5.loss_mask: 1.2947  decode.d5.loss_dice: 1.1018  decode.d6.loss_cls: 0.7412  decode.d6.loss_mask: 1.3663  decode.d6.loss_dice: 1.0695  decode.d7.loss_cls: 0.7053  decode.d7.loss_mask: 1.3361  decode.d7.loss_dice: 1.1260  decode.d8.loss_cls: 0.6698  decode.d8.loss_mask: 1.3969  decode.d8.loss_dice: 1.1102
05/26 11:39:09 - mmengine - INFO - Iter(train) [  6300/160000]  base_lr: 9.6450e-05 lr: 9.6450e-06  eta: 17:42:23  time: 0.4060  data_time: 0.0086  memory: 5969  grad_norm: 974.2137  loss: 29.9978  decode.loss_cls: 0.6363  decode.loss_mask: 1.3503  decode.loss_dice: 1.0322  decode.d0.loss_cls: 0.9498  decode.d0.loss_mask: 1.2403  decode.d0.loss_dice: 1.0243  decode.d1.loss_cls: 0.5988  decode.d1.loss_mask: 1.3928  decode.d1.loss_dice: 1.0636  decode.d2.loss_cls: 0.6682  decode.d2.loss_mask: 1.2564  decode.d2.loss_dice: 0.9909  decode.d3.loss_cls: 0.7264  decode.d3.loss_mask: 1.2761  decode.d3.loss_dice: 0.9764  decode.d4.loss_cls: 0.6498  decode.d4.loss_mask: 1.2925  decode.d4.loss_dice: 1.0090  decode.d5.loss_cls: 0.7193  decode.d5.loss_mask: 1.2370  decode.d5.loss_dice: 0.9848  decode.d6.loss_cls: 0.6585  decode.d6.loss_mask: 1.2530  decode.d6.loss_dice: 1.0258  decode.d7.loss_cls: 0.6331  decode.d7.loss_mask: 1.2901  decode.d7.loss_dice: 1.0254  decode.d8.loss_cls: 0.6428  decode.d8.loss_mask: 1.3388  decode.d8.loss_dice: 1.0553
05/26 11:39:30 - mmengine - INFO - Iter(train) [  6350/160000]  base_lr: 9.6421e-05 lr: 9.6421e-06  eta: 17:41:53  time: 0.4080  data_time: 0.0098  memory: 5982  grad_norm: 536.6948  loss: 32.7248  decode.loss_cls: 0.6969  decode.loss_mask: 1.4052  decode.loss_dice: 1.1516  decode.d0.loss_cls: 1.0590  decode.d0.loss_mask: 1.3861  decode.d0.loss_dice: 1.1826  decode.d1.loss_cls: 0.6928  decode.d1.loss_mask: 1.3698  decode.d1.loss_dice: 1.0957  decode.d2.loss_cls: 0.6978  decode.d2.loss_mask: 1.3825  decode.d2.loss_dice: 1.0915  decode.d3.loss_cls: 0.7668  decode.d3.loss_mask: 1.3387  decode.d3.loss_dice: 1.0754  decode.d4.loss_cls: 0.7353  decode.d4.loss_mask: 1.4025  decode.d4.loss_dice: 1.1615  decode.d5.loss_cls: 0.7651  decode.d5.loss_mask: 1.3682  decode.d5.loss_dice: 1.1534  decode.d6.loss_cls: 0.6746  decode.d6.loss_mask: 1.4460  decode.d6.loss_dice: 1.1938  decode.d7.loss_cls: 0.7393  decode.d7.loss_mask: 1.3631  decode.d7.loss_dice: 1.1121  decode.d8.loss_cls: 0.6831  decode.d8.loss_mask: 1.3916  decode.d8.loss_dice: 1.1431
05/26 11:39:50 - mmengine - INFO - Iter(train) [  6400/160000]  base_lr: 9.6393e-05 lr: 9.6393e-06  eta: 17:41:23  time: 0.4068  data_time: 0.0085  memory: 5975  grad_norm: 896.3606  loss: 36.5286  decode.loss_cls: 0.7905  decode.loss_mask: 1.4962  decode.loss_dice: 1.3405  decode.d0.loss_cls: 1.1109  decode.d0.loss_mask: 1.5028  decode.d0.loss_dice: 1.3541  decode.d1.loss_cls: 0.7771  decode.d1.loss_mask: 1.5120  decode.d1.loss_dice: 1.3096  decode.d2.loss_cls: 0.8639  decode.d2.loss_mask: 1.4910  decode.d2.loss_dice: 1.2900  decode.d3.loss_cls: 0.7861  decode.d3.loss_mask: 1.5025  decode.d3.loss_dice: 1.3355  decode.d4.loss_cls: 0.7516  decode.d4.loss_mask: 1.5611  decode.d4.loss_dice: 1.3194  decode.d5.loss_cls: 0.8230  decode.d5.loss_mask: 1.4347  decode.d5.loss_dice: 1.3028  decode.d6.loss_cls: 0.8036  decode.d6.loss_mask: 1.4852  decode.d6.loss_dice: 1.2998  decode.d7.loss_cls: 0.7787  decode.d7.loss_mask: 1.4844  decode.d7.loss_dice: 1.3486  decode.d8.loss_cls: 0.7361  decode.d8.loss_mask: 1.5544  decode.d8.loss_dice: 1.3825
05/26 11:40:10 - mmengine - INFO - Iter(train) [  6450/160000]  base_lr: 9.6365e-05 lr: 9.6365e-06  eta: 17:40:53  time: 0.4057  data_time: 0.0086  memory: 5974  grad_norm: 710.2853  loss: 34.3328  decode.loss_cls: 0.6000  decode.loss_mask: 1.6181  decode.loss_dice: 1.1468  decode.d0.loss_cls: 0.9172  decode.d0.loss_mask: 1.5896  decode.d0.loss_dice: 1.1476  decode.d1.loss_cls: 0.6884  decode.d1.loss_mask: 1.6318  decode.d1.loss_dice: 1.1479  decode.d2.loss_cls: 0.6216  decode.d2.loss_mask: 1.6150  decode.d2.loss_dice: 1.1487  decode.d3.loss_cls: 0.6186  decode.d3.loss_mask: 1.6115  decode.d3.loss_dice: 1.1272  decode.d4.loss_cls: 0.6382  decode.d4.loss_mask: 1.5888  decode.d4.loss_dice: 1.1710  decode.d5.loss_cls: 0.6397  decode.d5.loss_mask: 1.6683  decode.d5.loss_dice: 1.1265  decode.d6.loss_cls: 0.6717  decode.d6.loss_mask: 1.6787  decode.d6.loss_dice: 1.1325  decode.d7.loss_cls: 0.6785  decode.d7.loss_mask: 1.5937  decode.d7.loss_dice: 1.1383  decode.d8.loss_cls: 0.5812  decode.d8.loss_mask: 1.6541  decode.d8.loss_dice: 1.1418
05/26 11:40:31 - mmengine - INFO - Iter(train) [  6500/160000]  base_lr: 9.6337e-05 lr: 9.6337e-06  eta: 17:40:22  time: 0.4063  data_time: 0.0085  memory: 5973  grad_norm: 706.9333  loss: 28.9762  decode.loss_cls: 0.6317  decode.loss_mask: 1.3489  decode.loss_dice: 0.9792  decode.d0.loss_cls: 0.9665  decode.d0.loss_mask: 1.3020  decode.d0.loss_dice: 0.9751  decode.d1.loss_cls: 0.5670  decode.d1.loss_mask: 1.2718  decode.d1.loss_dice: 0.9096  decode.d2.loss_cls: 0.5739  decode.d2.loss_mask: 1.2785  decode.d2.loss_dice: 0.9606  decode.d3.loss_cls: 0.6376  decode.d3.loss_mask: 1.2676  decode.d3.loss_dice: 0.9171  decode.d4.loss_cls: 0.6601  decode.d4.loss_mask: 1.3216  decode.d4.loss_dice: 0.9554  decode.d5.loss_cls: 0.6810  decode.d5.loss_mask: 1.2279  decode.d5.loss_dice: 0.9043  decode.d6.loss_cls: 0.6385  decode.d6.loss_mask: 1.3082  decode.d6.loss_dice: 0.9539  decode.d7.loss_cls: 0.6842  decode.d7.loss_mask: 1.2737  decode.d7.loss_dice: 0.9457  decode.d8.loss_cls: 0.5919  decode.d8.loss_mask: 1.3322  decode.d8.loss_dice: 0.9103
05/26 11:40:51 - mmengine - INFO - Iter(train) [  6550/160000]  base_lr: 9.6309e-05 lr: 9.6309e-06  eta: 17:39:52  time: 0.4052  data_time: 0.0086  memory: 5966  grad_norm: 733.5878  loss: 31.7404  decode.loss_cls: 0.5902  decode.loss_mask: 1.3796  decode.loss_dice: 1.1472  decode.d0.loss_cls: 1.0168  decode.d0.loss_mask: 1.3121  decode.d0.loss_dice: 1.1287  decode.d1.loss_cls: 0.6510  decode.d1.loss_mask: 1.3310  decode.d1.loss_dice: 1.1454  decode.d2.loss_cls: 0.6295  decode.d2.loss_mask: 1.2899  decode.d2.loss_dice: 1.0906  decode.d3.loss_cls: 0.6621  decode.d3.loss_mask: 1.3323  decode.d3.loss_dice: 1.1558  decode.d4.loss_cls: 0.7718  decode.d4.loss_mask: 1.3206  decode.d4.loss_dice: 1.1395  decode.d5.loss_cls: 0.7540  decode.d5.loss_mask: 1.3237  decode.d5.loss_dice: 1.1234  decode.d6.loss_cls: 0.7170  decode.d6.loss_mask: 1.3062  decode.d6.loss_dice: 1.1674  decode.d7.loss_cls: 0.6725  decode.d7.loss_mask: 1.3793  decode.d7.loss_dice: 1.1191  decode.d8.loss_cls: 0.6249  decode.d8.loss_mask: 1.3593  decode.d8.loss_dice: 1.0995
05/26 11:41:11 - mmengine - INFO - Iter(train) [  6600/160000]  base_lr: 9.6280e-05 lr: 9.6280e-06  eta: 17:39:22  time: 0.4059  data_time: 0.0086  memory: 5969  grad_norm: 897.4330  loss: 32.2739  decode.loss_cls: 0.5673  decode.loss_mask: 1.5021  decode.loss_dice: 1.0517  decode.d0.loss_cls: 0.9650  decode.d0.loss_mask: 1.4841  decode.d0.loss_dice: 1.0302  decode.d1.loss_cls: 0.5798  decode.d1.loss_mask: 1.5537  decode.d1.loss_dice: 1.0632  decode.d2.loss_cls: 0.5766  decode.d2.loss_mask: 1.5626  decode.d2.loss_dice: 1.0313  decode.d3.loss_cls: 0.5706  decode.d3.loss_mask: 1.5743  decode.d3.loss_dice: 1.0159  decode.d4.loss_cls: 0.6899  decode.d4.loss_mask: 1.5113  decode.d4.loss_dice: 1.0501  decode.d5.loss_cls: 0.6156  decode.d5.loss_mask: 1.6027  decode.d5.loss_dice: 1.1428  decode.d6.loss_cls: 0.5867  decode.d6.loss_mask: 1.5001  decode.d6.loss_dice: 1.0496  decode.d7.loss_cls: 0.6114  decode.d7.loss_mask: 1.5581  decode.d7.loss_dice: 1.0619  decode.d8.loss_cls: 0.5155  decode.d8.loss_mask: 1.5986  decode.d8.loss_dice: 1.0512
05/26 11:41:32 - mmengine - INFO - Iter(train) [  6650/160000]  base_lr: 9.6252e-05 lr: 9.6252e-06  eta: 17:38:53  time: 0.4057  data_time: 0.0085  memory: 5976  grad_norm: 853.7952  loss: 33.0615  decode.loss_cls: 0.7007  decode.loss_mask: 1.3415  decode.loss_dice: 1.2515  decode.d0.loss_cls: 1.1478  decode.d0.loss_mask: 1.3459  decode.d0.loss_dice: 1.1786  decode.d1.loss_cls: 0.7471  decode.d1.loss_mask: 1.3436  decode.d1.loss_dice: 1.1478  decode.d2.loss_cls: 0.8322  decode.d2.loss_mask: 1.3200  decode.d2.loss_dice: 1.1268  decode.d3.loss_cls: 0.7415  decode.d3.loss_mask: 1.3218  decode.d3.loss_dice: 1.1996  decode.d4.loss_cls: 0.7619  decode.d4.loss_mask: 1.3632  decode.d4.loss_dice: 1.2254  decode.d5.loss_cls: 0.8331  decode.d5.loss_mask: 1.3348  decode.d5.loss_dice: 1.1564  decode.d6.loss_cls: 0.7500  decode.d6.loss_mask: 1.3249  decode.d6.loss_dice: 1.1678  decode.d7.loss_cls: 0.6871  decode.d7.loss_mask: 1.3366  decode.d7.loss_dice: 1.1402  decode.d8.loss_cls: 0.7320  decode.d8.loss_mask: 1.3311  decode.d8.loss_dice: 1.1707
05/26 11:41:52 - mmengine - INFO - Iter(train) [  6700/160000]  base_lr: 9.6224e-05 lr: 9.6224e-06  eta: 17:38:26  time: 0.4066  data_time: 0.0086  memory: 5968  grad_norm: 782.2367  loss: 30.4022  decode.loss_cls: 0.6148  decode.loss_mask: 1.4433  decode.loss_dice: 0.9507  decode.d0.loss_cls: 0.8749  decode.d0.loss_mask: 1.4195  decode.d0.loss_dice: 0.9843  decode.d1.loss_cls: 0.5459  decode.d1.loss_mask: 1.4854  decode.d1.loss_dice: 0.9758  decode.d2.loss_cls: 0.6367  decode.d2.loss_mask: 1.3915  decode.d2.loss_dice: 0.9427  decode.d3.loss_cls: 0.6311  decode.d3.loss_mask: 1.4779  decode.d3.loss_dice: 1.0060  decode.d4.loss_cls: 0.6751  decode.d4.loss_mask: 1.4998  decode.d4.loss_dice: 0.9287  decode.d5.loss_cls: 0.6573  decode.d5.loss_mask: 1.4099  decode.d5.loss_dice: 0.9496  decode.d6.loss_cls: 0.6312  decode.d6.loss_mask: 1.4272  decode.d6.loss_dice: 0.9503  decode.d7.loss_cls: 0.6018  decode.d7.loss_mask: 1.3914  decode.d7.loss_dice: 0.9498  decode.d8.loss_cls: 0.5755  decode.d8.loss_mask: 1.4304  decode.d8.loss_dice: 0.9439
05/26 11:42:12 - mmengine - INFO - Iter(train) [  6750/160000]  base_lr: 9.6196e-05 lr: 9.6196e-06  eta: 17:37:57  time: 0.4065  data_time: 0.0086  memory: 5966  grad_norm: 683.6861  loss: 30.8240  decode.loss_cls: 0.5615  decode.loss_mask: 1.5088  decode.loss_dice: 1.0147  decode.d0.loss_cls: 0.9618  decode.d0.loss_mask: 1.2959  decode.d0.loss_dice: 1.0283  decode.d1.loss_cls: 0.6190  decode.d1.loss_mask: 1.3557  decode.d1.loss_dice: 1.0126  decode.d2.loss_cls: 0.6696  decode.d2.loss_mask: 1.3650  decode.d2.loss_dice: 0.9801  decode.d3.loss_cls: 0.6651  decode.d3.loss_mask: 1.3398  decode.d3.loss_dice: 0.9726  decode.d4.loss_cls: 0.6998  decode.d4.loss_mask: 1.3620  decode.d4.loss_dice: 0.9858  decode.d5.loss_cls: 0.7210  decode.d5.loss_mask: 1.3155  decode.d5.loss_dice: 1.0351  decode.d6.loss_cls: 0.6771  decode.d6.loss_mask: 1.4491  decode.d6.loss_dice: 1.0550  decode.d7.loss_cls: 0.6238  decode.d7.loss_mask: 1.3976  decode.d7.loss_dice: 1.0358  decode.d8.loss_cls: 0.6454  decode.d8.loss_mask: 1.4220  decode.d8.loss_dice: 1.0485
05/26 11:42:33 - mmengine - INFO - Iter(train) [  6800/160000]  base_lr: 9.6167e-05 lr: 9.6167e-06  eta: 17:37:27  time: 0.4071  data_time: 0.0086  memory: 5967  grad_norm: 1602.2152  loss: 36.7132  decode.loss_cls: 0.6634  decode.loss_mask: 1.6499  decode.loss_dice: 1.2213  decode.d0.loss_cls: 0.9697  decode.d0.loss_mask: 1.6359  decode.d0.loss_dice: 1.3040  decode.d1.loss_cls: 0.6926  decode.d1.loss_mask: 1.6658  decode.d1.loss_dice: 1.3342  decode.d2.loss_cls: 0.7288  decode.d2.loss_mask: 1.6713  decode.d2.loss_dice: 1.2921  decode.d3.loss_cls: 0.7195  decode.d3.loss_mask: 1.6110  decode.d3.loss_dice: 1.2234  decode.d4.loss_cls: 0.8433  decode.d4.loss_mask: 1.6621  decode.d4.loss_dice: 1.2377  decode.d5.loss_cls: 0.7458  decode.d5.loss_mask: 1.6684  decode.d5.loss_dice: 1.3229  decode.d6.loss_cls: 0.7137  decode.d6.loss_mask: 1.6637  decode.d6.loss_dice: 1.2801  decode.d7.loss_cls: 0.5930  decode.d7.loss_mask: 1.7202  decode.d7.loss_dice: 1.3019  decode.d8.loss_cls: 0.6247  decode.d8.loss_mask: 1.6519  decode.d8.loss_dice: 1.3007
05/26 11:42:53 - mmengine - INFO - Iter(train) [  6850/160000]  base_lr: 9.6139e-05 lr: 9.6139e-06  eta: 17:36:58  time: 0.4069  data_time: 0.0086  memory: 5972  grad_norm: 632.9690  loss: 33.8019  decode.loss_cls: 0.7009  decode.loss_mask: 1.4877  decode.loss_dice: 1.1243  decode.d0.loss_cls: 1.0131  decode.d0.loss_mask: 1.3930  decode.d0.loss_dice: 1.1160  decode.d1.loss_cls: 0.7547  decode.d1.loss_mask: 1.4429  decode.d1.loss_dice: 1.1442  decode.d2.loss_cls: 0.7943  decode.d2.loss_mask: 1.5226  decode.d2.loss_dice: 1.1316  decode.d3.loss_cls: 0.7244  decode.d3.loss_mask: 1.4703  decode.d3.loss_dice: 1.1122  decode.d4.loss_cls: 0.8232  decode.d4.loss_mask: 1.4336  decode.d4.loss_dice: 1.0995  decode.d5.loss_cls: 0.7959  decode.d5.loss_mask: 1.4100  decode.d5.loss_dice: 1.1202  decode.d6.loss_cls: 0.7666  decode.d6.loss_mask: 1.4789  decode.d6.loss_dice: 1.1094  decode.d7.loss_cls: 0.7705  decode.d7.loss_mask: 1.5124  decode.d7.loss_dice: 1.1546  decode.d8.loss_cls: 0.7775  decode.d8.loss_mask: 1.4705  decode.d8.loss_dice: 1.1465
05/26 11:43:13 - mmengine - INFO - Iter(train) [  6900/160000]  base_lr: 9.6111e-05 lr: 9.6111e-06  eta: 17:36:29  time: 0.4081  data_time: 0.0086  memory: 5976  grad_norm: 690.0125  loss: 30.6985  decode.loss_cls: 0.5869  decode.loss_mask: 1.3654  decode.loss_dice: 1.0822  decode.d0.loss_cls: 0.9206  decode.d0.loss_mask: 1.3566  decode.d0.loss_dice: 1.0523  decode.d1.loss_cls: 0.6033  decode.d1.loss_mask: 1.3489  decode.d1.loss_dice: 1.0457  decode.d2.loss_cls: 0.6226  decode.d2.loss_mask: 1.3548  decode.d2.loss_dice: 1.0395  decode.d3.loss_cls: 0.6075  decode.d3.loss_mask: 1.3535  decode.d3.loss_dice: 1.0211  decode.d4.loss_cls: 0.6649  decode.d4.loss_mask: 1.3241  decode.d4.loss_dice: 0.9976  decode.d5.loss_cls: 0.6880  decode.d5.loss_mask: 1.3351  decode.d5.loss_dice: 1.0371  decode.d6.loss_cls: 0.6477  decode.d6.loss_mask: 1.3858  decode.d6.loss_dice: 1.0636  decode.d7.loss_cls: 0.5939  decode.d7.loss_mask: 1.4165  decode.d7.loss_dice: 1.0571  decode.d8.loss_cls: 0.6020  decode.d8.loss_mask: 1.4618  decode.d8.loss_dice: 1.0622
05/26 11:43:34 - mmengine - INFO - Iter(train) [  6950/160000]  base_lr: 9.6083e-05 lr: 9.6083e-06  eta: 17:36:00  time: 0.4071  data_time: 0.0085  memory: 5966  grad_norm: 738.6877  loss: 31.8579  decode.loss_cls: 0.6399  decode.loss_mask: 1.3791  decode.loss_dice: 1.1338  decode.d0.loss_cls: 1.0377  decode.d0.loss_mask: 1.2707  decode.d0.loss_dice: 1.1127  decode.d1.loss_cls: 0.7122  decode.d1.loss_mask: 1.3424  decode.d1.loss_dice: 1.1619  decode.d2.loss_cls: 0.5983  decode.d2.loss_mask: 1.3612  decode.d2.loss_dice: 1.1496  decode.d3.loss_cls: 0.6556  decode.d3.loss_mask: 1.3633  decode.d3.loss_dice: 1.1473  decode.d4.loss_cls: 0.7235  decode.d4.loss_mask: 1.3478  decode.d4.loss_dice: 1.1405  decode.d5.loss_cls: 0.6309  decode.d5.loss_mask: 1.3670  decode.d5.loss_dice: 1.1500  decode.d6.loss_cls: 0.6852  decode.d6.loss_mask: 1.2952  decode.d6.loss_dice: 1.1823  decode.d7.loss_cls: 0.6391  decode.d7.loss_mask: 1.3412  decode.d7.loss_dice: 1.1606  decode.d8.loss_cls: 0.6336  decode.d8.loss_mask: 1.3482  decode.d8.loss_dice: 1.1470
05/26 11:43:54 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 11:43:54 - mmengine - INFO - Iter(train) [  7000/160000]  base_lr: 9.6054e-05 lr: 9.6054e-06  eta: 17:35:32  time: 0.4076  data_time: 0.0086  memory: 5975  grad_norm: 779.3754  loss: 37.6957  decode.loss_cls: 0.7767  decode.loss_mask: 1.5767  decode.loss_dice: 1.3675  decode.d0.loss_cls: 1.1358  decode.d0.loss_mask: 1.5507  decode.d0.loss_dice: 1.3805  decode.d1.loss_cls: 0.8362  decode.d1.loss_mask: 1.5414  decode.d1.loss_dice: 1.3189  decode.d2.loss_cls: 0.8484  decode.d2.loss_mask: 1.5266  decode.d2.loss_dice: 1.2870  decode.d3.loss_cls: 0.8295  decode.d3.loss_mask: 1.5524  decode.d3.loss_dice: 1.2829  decode.d4.loss_cls: 0.8751  decode.d4.loss_mask: 1.5511  decode.d4.loss_dice: 1.3466  decode.d5.loss_cls: 0.9030  decode.d5.loss_mask: 1.6091  decode.d5.loss_dice: 1.3910  decode.d6.loss_cls: 0.8581  decode.d6.loss_mask: 1.6165  decode.d6.loss_dice: 1.3663  decode.d7.loss_cls: 0.8156  decode.d7.loss_mask: 1.5346  decode.d7.loss_dice: 1.3298  decode.d8.loss_cls: 0.8160  decode.d8.loss_mask: 1.5637  decode.d8.loss_dice: 1.3080
05/26 11:44:14 - mmengine - INFO - Iter(train) [  7050/160000]  base_lr: 9.6026e-05 lr: 9.6026e-06  eta: 17:35:06  time: 0.4077  data_time: 0.0086  memory: 5976  grad_norm: 893.9223  loss: 31.5571  decode.loss_cls: 0.6622  decode.loss_mask: 1.3606  decode.loss_dice: 1.0599  decode.d0.loss_cls: 0.9888  decode.d0.loss_mask: 1.3645  decode.d0.loss_dice: 1.0703  decode.d1.loss_cls: 0.6528  decode.d1.loss_mask: 1.3396  decode.d1.loss_dice: 1.0261  decode.d2.loss_cls: 0.6629  decode.d2.loss_mask: 1.4210  decode.d2.loss_dice: 1.0649  decode.d3.loss_cls: 0.7162  decode.d3.loss_mask: 1.4305  decode.d3.loss_dice: 1.0109  decode.d4.loss_cls: 0.7752  decode.d4.loss_mask: 1.4925  decode.d4.loss_dice: 1.0441  decode.d5.loss_cls: 0.7405  decode.d5.loss_mask: 1.3541  decode.d5.loss_dice: 0.9962  decode.d6.loss_cls: 0.7102  decode.d6.loss_mask: 1.3941  decode.d6.loss_dice: 1.0509  decode.d7.loss_cls: 0.6810  decode.d7.loss_mask: 1.3527  decode.d7.loss_dice: 1.0584  decode.d8.loss_cls: 0.6961  decode.d8.loss_mask: 1.3412  decode.d8.loss_dice: 1.0385
05/26 11:44:35 - mmengine - INFO - Iter(train) [  7100/160000]  base_lr: 9.5998e-05 lr: 9.5998e-06  eta: 17:34:37  time: 0.4073  data_time: 0.0086  memory: 5966  grad_norm: 594.6537  loss: 31.0755  decode.loss_cls: 0.6780  decode.loss_mask: 1.3559  decode.loss_dice: 1.0369  decode.d0.loss_cls: 0.9504  decode.d0.loss_mask: 1.3297  decode.d0.loss_dice: 1.0763  decode.d1.loss_cls: 0.6929  decode.d1.loss_mask: 1.3669  decode.d1.loss_dice: 1.0219  decode.d2.loss_cls: 0.6342  decode.d2.loss_mask: 1.3894  decode.d2.loss_dice: 1.0275  decode.d3.loss_cls: 0.6599  decode.d3.loss_mask: 1.3584  decode.d3.loss_dice: 1.0747  decode.d4.loss_cls: 0.7508  decode.d4.loss_mask: 1.3383  decode.d4.loss_dice: 1.0437  decode.d5.loss_cls: 0.7118  decode.d5.loss_mask: 1.3259  decode.d5.loss_dice: 1.0364  decode.d6.loss_cls: 0.6806  decode.d6.loss_mask: 1.3445  decode.d6.loss_dice: 1.0407  decode.d7.loss_cls: 0.6525  decode.d7.loss_mask: 1.3270  decode.d7.loss_dice: 1.0298  decode.d8.loss_cls: 0.7058  decode.d8.loss_mask: 1.3692  decode.d8.loss_dice: 1.0657
05/26 11:44:55 - mmengine - INFO - Iter(train) [  7150/160000]  base_lr: 9.5970e-05 lr: 9.5970e-06  eta: 17:34:09  time: 0.4065  data_time: 0.0086  memory: 5971  grad_norm: 944.6114  loss: 37.6592  decode.loss_cls: 0.6968  decode.loss_mask: 1.6387  decode.loss_dice: 1.3717  decode.d0.loss_cls: 1.1491  decode.d0.loss_mask: 1.5880  decode.d0.loss_dice: 1.3910  decode.d1.loss_cls: 0.7842  decode.d1.loss_mask: 1.5863  decode.d1.loss_dice: 1.3200  decode.d2.loss_cls: 0.7733  decode.d2.loss_mask: 1.6240  decode.d2.loss_dice: 1.3185  decode.d3.loss_cls: 0.7400  decode.d3.loss_mask: 1.6687  decode.d3.loss_dice: 1.3797  decode.d4.loss_cls: 0.8397  decode.d4.loss_mask: 1.5901  decode.d4.loss_dice: 1.3088  decode.d5.loss_cls: 0.8274  decode.d5.loss_mask: 1.5990  decode.d5.loss_dice: 1.2934  decode.d6.loss_cls: 0.8139  decode.d6.loss_mask: 1.5663  decode.d6.loss_dice: 1.3081  decode.d7.loss_cls: 0.7803  decode.d7.loss_mask: 1.6602  decode.d7.loss_dice: 1.3461  decode.d8.loss_cls: 0.7367  decode.d8.loss_mask: 1.5993  decode.d8.loss_dice: 1.3597
05/26 11:45:15 - mmengine - INFO - Iter(train) [  7200/160000]  base_lr: 9.5941e-05 lr: 9.5941e-06  eta: 17:33:41  time: 0.4075  data_time: 0.0086  memory: 5966  grad_norm: 998.0245  loss: 36.9463  decode.loss_cls: 0.6112  decode.loss_mask: 1.6299  decode.loss_dice: 1.3385  decode.d0.loss_cls: 0.9975  decode.d0.loss_mask: 1.5482  decode.d0.loss_dice: 1.3227  decode.d1.loss_cls: 0.6258  decode.d1.loss_mask: 1.6213  decode.d1.loss_dice: 1.3608  decode.d2.loss_cls: 0.6821  decode.d2.loss_mask: 1.6778  decode.d2.loss_dice: 1.3279  decode.d3.loss_cls: 0.6506  decode.d3.loss_mask: 1.7284  decode.d3.loss_dice: 1.3752  decode.d4.loss_cls: 0.7348  decode.d4.loss_mask: 1.6215  decode.d4.loss_dice: 1.3492  decode.d5.loss_cls: 0.7188  decode.d5.loss_mask: 1.6394  decode.d5.loss_dice: 1.3560  decode.d6.loss_cls: 0.6689  decode.d6.loss_mask: 1.6716  decode.d6.loss_dice: 1.3576  decode.d7.loss_cls: 0.6291  decode.d7.loss_mask: 1.6536  decode.d7.loss_dice: 1.3615  decode.d8.loss_cls: 0.6102  decode.d8.loss_mask: 1.6892  decode.d8.loss_dice: 1.3870
05/26 11:45:36 - mmengine - INFO - Iter(train) [  7250/160000]  base_lr: 9.5913e-05 lr: 9.5913e-06  eta: 17:33:13  time: 0.4071  data_time: 0.0087  memory: 5966  grad_norm: 769.6813  loss: 32.7175  decode.loss_cls: 0.6122  decode.loss_mask: 1.5068  decode.loss_dice: 1.0726  decode.d0.loss_cls: 0.9662  decode.d0.loss_mask: 1.4422  decode.d0.loss_dice: 1.0621  decode.d1.loss_cls: 0.6603  decode.d1.loss_mask: 1.4615  decode.d1.loss_dice: 1.1021  decode.d2.loss_cls: 0.6787  decode.d2.loss_mask: 1.5008  decode.d2.loss_dice: 1.0671  decode.d3.loss_cls: 0.7031  decode.d3.loss_mask: 1.5003  decode.d3.loss_dice: 1.0920  decode.d4.loss_cls: 0.6672  decode.d4.loss_mask: 1.4900  decode.d4.loss_dice: 1.0439  decode.d5.loss_cls: 0.6309  decode.d5.loss_mask: 1.5883  decode.d5.loss_dice: 1.1184  decode.d6.loss_cls: 0.6718  decode.d6.loss_mask: 1.5144  decode.d6.loss_dice: 1.0755  decode.d7.loss_cls: 0.5712  decode.d7.loss_mask: 1.6020  decode.d7.loss_dice: 1.0895  decode.d8.loss_cls: 0.6254  decode.d8.loss_mask: 1.5345  decode.d8.loss_dice: 1.0665
05/26 11:45:56 - mmengine - INFO - Iter(train) [  7300/160000]  base_lr: 9.5885e-05 lr: 9.5885e-06  eta: 17:32:45  time: 0.4046  data_time: 0.0086  memory: 5976  grad_norm: 918.7751  loss: 27.5074  decode.loss_cls: 0.4581  decode.loss_mask: 1.2256  decode.loss_dice: 0.9464  decode.d0.loss_cls: 0.8509  decode.d0.loss_mask: 1.2535  decode.d0.loss_dice: 0.9678  decode.d1.loss_cls: 0.5186  decode.d1.loss_mask: 1.2514  decode.d1.loss_dice: 0.9214  decode.d2.loss_cls: 0.5367  decode.d2.loss_mask: 1.2262  decode.d2.loss_dice: 0.9222  decode.d3.loss_cls: 0.5636  decode.d3.loss_mask: 1.2486  decode.d3.loss_dice: 0.9372  decode.d4.loss_cls: 0.5629  decode.d4.loss_mask: 1.2527  decode.d4.loss_dice: 0.9098  decode.d5.loss_cls: 0.5397  decode.d5.loss_mask: 1.2643  decode.d5.loss_dice: 0.9216  decode.d6.loss_cls: 0.5108  decode.d6.loss_mask: 1.2461  decode.d6.loss_dice: 0.9613  decode.d7.loss_cls: 0.4527  decode.d7.loss_mask: 1.3243  decode.d7.loss_dice: 1.0056  decode.d8.loss_cls: 0.4406  decode.d8.loss_mask: 1.3105  decode.d8.loss_dice: 0.9762
05/26 11:46:16 - mmengine - INFO - Iter(train) [  7350/160000]  base_lr: 9.5857e-05 lr: 9.5857e-06  eta: 17:32:17  time: 0.4065  data_time: 0.0086  memory: 5966  grad_norm: 807.9555  loss: 30.3811  decode.loss_cls: 0.5553  decode.loss_mask: 1.3268  decode.loss_dice: 1.0324  decode.d0.loss_cls: 0.9061  decode.d0.loss_mask: 1.3663  decode.d0.loss_dice: 1.0414  decode.d1.loss_cls: 0.5895  decode.d1.loss_mask: 1.3400  decode.d1.loss_dice: 1.0231  decode.d2.loss_cls: 0.6398  decode.d2.loss_mask: 1.3279  decode.d2.loss_dice: 1.0275  decode.d3.loss_cls: 0.5677  decode.d3.loss_mask: 1.3698  decode.d3.loss_dice: 1.0511  decode.d4.loss_cls: 0.6522  decode.d4.loss_mask: 1.3963  decode.d4.loss_dice: 1.0559  decode.d5.loss_cls: 0.6492  decode.d5.loss_mask: 1.4199  decode.d5.loss_dice: 1.0596  decode.d6.loss_cls: 0.5903  decode.d6.loss_mask: 1.3829  decode.d6.loss_dice: 1.0821  decode.d7.loss_cls: 0.4903  decode.d7.loss_mask: 1.3980  decode.d7.loss_dice: 1.0564  decode.d8.loss_cls: 0.5462  decode.d8.loss_mask: 1.3723  decode.d8.loss_dice: 1.0648
05/26 11:46:37 - mmengine - INFO - Iter(train) [  7400/160000]  base_lr: 9.5828e-05 lr: 9.5828e-06  eta: 17:31:49  time: 0.4059  data_time: 0.0085  memory: 5976  grad_norm: 935.7400  loss: 32.5310  decode.loss_cls: 0.6148  decode.loss_mask: 1.3203  decode.loss_dice: 1.2431  decode.d0.loss_cls: 1.0071  decode.d0.loss_mask: 1.2672  decode.d0.loss_dice: 1.2605  decode.d1.loss_cls: 0.6755  decode.d1.loss_mask: 1.2952  decode.d1.loss_dice: 1.2766  decode.d2.loss_cls: 0.6249  decode.d2.loss_mask: 1.2515  decode.d2.loss_dice: 1.2243  decode.d3.loss_cls: 0.7139  decode.d3.loss_mask: 1.2355  decode.d3.loss_dice: 1.2592  decode.d4.loss_cls: 0.7247  decode.d4.loss_mask: 1.2999  decode.d4.loss_dice: 1.2392  decode.d5.loss_cls: 0.7108  decode.d5.loss_mask: 1.2845  decode.d5.loss_dice: 1.2591  decode.d6.loss_cls: 0.7229  decode.d6.loss_mask: 1.3258  decode.d6.loss_dice: 1.2746  decode.d7.loss_cls: 0.6823  decode.d7.loss_mask: 1.3244  decode.d7.loss_dice: 1.2350  decode.d8.loss_cls: 0.6914  decode.d8.loss_mask: 1.2980  decode.d8.loss_dice: 1.1888
05/26 11:46:57 - mmengine - INFO - Iter(train) [  7450/160000]  base_lr: 9.5800e-05 lr: 9.5800e-06  eta: 17:31:22  time: 0.4070  data_time: 0.0086  memory: 5974  grad_norm: 636.3881  loss: 31.3407  decode.loss_cls: 0.6098  decode.loss_mask: 1.3519  decode.loss_dice: 1.1442  decode.d0.loss_cls: 0.9314  decode.d0.loss_mask: 1.2618  decode.d0.loss_dice: 1.1237  decode.d1.loss_cls: 0.5837  decode.d1.loss_mask: 1.2653  decode.d1.loss_dice: 1.1223  decode.d2.loss_cls: 0.6683  decode.d2.loss_mask: 1.2770  decode.d2.loss_dice: 1.1473  decode.d3.loss_cls: 0.6413  decode.d3.loss_mask: 1.2695  decode.d3.loss_dice: 1.2000  decode.d4.loss_cls: 0.7173  decode.d4.loss_mask: 1.2905  decode.d4.loss_dice: 1.1757  decode.d5.loss_cls: 0.7192  decode.d5.loss_mask: 1.3202  decode.d5.loss_dice: 1.1995  decode.d6.loss_cls: 0.6761  decode.d6.loss_mask: 1.3046  decode.d6.loss_dice: 1.1502  decode.d7.loss_cls: 0.6719  decode.d7.loss_mask: 1.2619  decode.d7.loss_dice: 1.1689  decode.d8.loss_cls: 0.6068  decode.d8.loss_mask: 1.3278  decode.d8.loss_dice: 1.1525
05/26 11:47:17 - mmengine - INFO - Iter(train) [  7500/160000]  base_lr: 9.5772e-05 lr: 9.5772e-06  eta: 17:30:54  time: 0.4068  data_time: 0.0085  memory: 5972  grad_norm: 683.7493  loss: 37.3257  decode.loss_cls: 0.7115  decode.loss_mask: 1.5355  decode.loss_dice: 1.4114  decode.d0.loss_cls: 1.0219  decode.d0.loss_mask: 1.5579  decode.d0.loss_dice: 1.4054  decode.d1.loss_cls: 0.7352  decode.d1.loss_mask: 1.5901  decode.d1.loss_dice: 1.3901  decode.d2.loss_cls: 0.6955  decode.d2.loss_mask: 1.5649  decode.d2.loss_dice: 1.3378  decode.d3.loss_cls: 0.7704  decode.d3.loss_mask: 1.5766  decode.d3.loss_dice: 1.3756  decode.d4.loss_cls: 0.8403  decode.d4.loss_mask: 1.5809  decode.d4.loss_dice: 1.3803  decode.d5.loss_cls: 0.8026  decode.d5.loss_mask: 1.5345  decode.d5.loss_dice: 1.3918  decode.d6.loss_cls: 0.7718  decode.d6.loss_mask: 1.5735  decode.d6.loss_dice: 1.3683  decode.d7.loss_cls: 0.7001  decode.d7.loss_mask: 1.6304  decode.d7.loss_dice: 1.4126  decode.d8.loss_cls: 0.6556  decode.d8.loss_mask: 1.5818  decode.d8.loss_dice: 1.4217
05/26 11:47:38 - mmengine - INFO - Iter(train) [  7550/160000]  base_lr: 9.5743e-05 lr: 9.5743e-06  eta: 17:30:27  time: 0.4074  data_time: 0.0085  memory: 5975  grad_norm: 662.5081  loss: 29.6487  decode.loss_cls: 0.5406  decode.loss_mask: 1.3610  decode.loss_dice: 1.0202  decode.d0.loss_cls: 0.8262  decode.d0.loss_mask: 1.3030  decode.d0.loss_dice: 0.9755  decode.d1.loss_cls: 0.6336  decode.d1.loss_mask: 1.2999  decode.d1.loss_dice: 0.9897  decode.d2.loss_cls: 0.5363  decode.d2.loss_mask: 1.3425  decode.d2.loss_dice: 1.0508  decode.d3.loss_cls: 0.5694  decode.d3.loss_mask: 1.3668  decode.d3.loss_dice: 1.0379  decode.d4.loss_cls: 0.6106  decode.d4.loss_mask: 1.3782  decode.d4.loss_dice: 1.0835  decode.d5.loss_cls: 0.6256  decode.d5.loss_mask: 1.3693  decode.d5.loss_dice: 0.9990  decode.d6.loss_cls: 0.5993  decode.d6.loss_mask: 1.3598  decode.d6.loss_dice: 1.0366  decode.d7.loss_cls: 0.5589  decode.d7.loss_mask: 1.3332  decode.d7.loss_dice: 1.0050  decode.d8.loss_cls: 0.5300  decode.d8.loss_mask: 1.3357  decode.d8.loss_dice: 0.9706
05/26 11:47:58 - mmengine - INFO - Iter(train) [  7600/160000]  base_lr: 9.5715e-05 lr: 9.5715e-06  eta: 17:29:59  time: 0.4065  data_time: 0.0087  memory: 5966  grad_norm: 567.3558  loss: 33.0774  decode.loss_cls: 0.7496  decode.loss_mask: 1.3409  decode.loss_dice: 1.2147  decode.d0.loss_cls: 1.0926  decode.d0.loss_mask: 1.3093  decode.d0.loss_dice: 1.2251  decode.d1.loss_cls: 0.6637  decode.d1.loss_mask: 1.3770  decode.d1.loss_dice: 1.2671  decode.d2.loss_cls: 0.7446  decode.d2.loss_mask: 1.3672  decode.d2.loss_dice: 1.1870  decode.d3.loss_cls: 0.7442  decode.d3.loss_mask: 1.3380  decode.d3.loss_dice: 1.2003  decode.d4.loss_cls: 0.7415  decode.d4.loss_mask: 1.3167  decode.d4.loss_dice: 1.1897  decode.d5.loss_cls: 0.7186  decode.d5.loss_mask: 1.3379  decode.d5.loss_dice: 1.2110  decode.d6.loss_cls: 0.6725  decode.d6.loss_mask: 1.3511  decode.d6.loss_dice: 1.2367  decode.d7.loss_cls: 0.6840  decode.d7.loss_mask: 1.3366  decode.d7.loss_dice: 1.1981  decode.d8.loss_cls: 0.7021  decode.d8.loss_mask: 1.3605  decode.d8.loss_dice: 1.1989
05/26 11:48:18 - mmengine - INFO - Iter(train) [  7650/160000]  base_lr: 9.5687e-05 lr: 9.5687e-06  eta: 17:29:32  time: 0.4059  data_time: 0.0086  memory: 5976  grad_norm: 838.7325  loss: 29.9187  decode.loss_cls: 0.4330  decode.loss_mask: 1.4130  decode.loss_dice: 1.0161  decode.d0.loss_cls: 0.8536  decode.d0.loss_mask: 1.3703  decode.d0.loss_dice: 0.9708  decode.d1.loss_cls: 0.4759  decode.d1.loss_mask: 1.3787  decode.d1.loss_dice: 0.9560  decode.d2.loss_cls: 0.5012  decode.d2.loss_mask: 1.4213  decode.d2.loss_dice: 1.0087  decode.d3.loss_cls: 0.5169  decode.d3.loss_mask: 1.4466  decode.d3.loss_dice: 1.0387  decode.d4.loss_cls: 0.5440  decode.d4.loss_mask: 1.4467  decode.d4.loss_dice: 1.0716  decode.d5.loss_cls: 0.5611  decode.d5.loss_mask: 1.4481  decode.d5.loss_dice: 1.0614  decode.d6.loss_cls: 0.4923  decode.d6.loss_mask: 1.5249  decode.d6.loss_dice: 1.0984  decode.d7.loss_cls: 0.4968  decode.d7.loss_mask: 1.4478  decode.d7.loss_dice: 0.9956  decode.d8.loss_cls: 0.4846  decode.d8.loss_mask: 1.4455  decode.d8.loss_dice: 0.9990
05/26 11:48:39 - mmengine - INFO - Iter(train) [  7700/160000]  base_lr: 9.5659e-05 lr: 9.5659e-06  eta: 17:29:07  time: 0.4175  data_time: 0.0086  memory: 5970  grad_norm: 940.7215  loss: 29.9249  decode.loss_cls: 0.5065  decode.loss_mask: 1.3039  decode.loss_dice: 1.0425  decode.d0.loss_cls: 0.9357  decode.d0.loss_mask: 1.2985  decode.d0.loss_dice: 1.0240  decode.d1.loss_cls: 0.6132  decode.d1.loss_mask: 1.3145  decode.d1.loss_dice: 0.9740  decode.d2.loss_cls: 0.6617  decode.d2.loss_mask: 1.3131  decode.d2.loss_dice: 0.9368  decode.d3.loss_cls: 0.6701  decode.d3.loss_mask: 1.2864  decode.d3.loss_dice: 1.0224  decode.d4.loss_cls: 0.7309  decode.d4.loss_mask: 1.3021  decode.d4.loss_dice: 0.9884  decode.d5.loss_cls: 0.6337  decode.d5.loss_mask: 1.4241  decode.d5.loss_dice: 1.0025  decode.d6.loss_cls: 0.6897  decode.d6.loss_mask: 1.3213  decode.d6.loss_dice: 0.9951  decode.d7.loss_cls: 0.6279  decode.d7.loss_mask: 1.2912  decode.d7.loss_dice: 1.0245  decode.d8.loss_cls: 0.6142  decode.d8.loss_mask: 1.3600  decode.d8.loss_dice: 1.0160
05/26 11:48:59 - mmengine - INFO - Iter(train) [  7750/160000]  base_lr: 9.5630e-05 lr: 9.5630e-06  eta: 17:28:40  time: 0.4065  data_time: 0.0086  memory: 5976  grad_norm: 822.3841  loss: 32.7320  decode.loss_cls: 0.7420  decode.loss_mask: 1.3162  decode.loss_dice: 1.1082  decode.d0.loss_cls: 1.1804  decode.d0.loss_mask: 1.3229  decode.d0.loss_dice: 1.1798  decode.d1.loss_cls: 0.7981  decode.d1.loss_mask: 1.3429  decode.d1.loss_dice: 1.1105  decode.d2.loss_cls: 0.8312  decode.d2.loss_mask: 1.3153  decode.d2.loss_dice: 1.1002  decode.d3.loss_cls: 0.7198  decode.d3.loss_mask: 1.2896  decode.d3.loss_dice: 1.1285  decode.d4.loss_cls: 0.7858  decode.d4.loss_mask: 1.3162  decode.d4.loss_dice: 1.0932  decode.d5.loss_cls: 0.7741  decode.d5.loss_mask: 1.3170  decode.d5.loss_dice: 1.1245  decode.d6.loss_cls: 0.6814  decode.d6.loss_mask: 1.4572  decode.d6.loss_dice: 1.1820  decode.d7.loss_cls: 0.8119  decode.d7.loss_mask: 1.3800  decode.d7.loss_dice: 1.0762  decode.d8.loss_cls: 0.7839  decode.d8.loss_mask: 1.3423  decode.d8.loss_dice: 1.1207
05/26 11:49:20 - mmengine - INFO - Iter(train) [  7800/160000]  base_lr: 9.5602e-05 lr: 9.5602e-06  eta: 17:28:13  time: 0.4058  data_time: 0.0086  memory: 5969  grad_norm: 686.3877  loss: 35.1146  decode.loss_cls: 0.6386  decode.loss_mask: 1.5280  decode.loss_dice: 1.2958  decode.d0.loss_cls: 1.0449  decode.d0.loss_mask: 1.4679  decode.d0.loss_dice: 1.2740  decode.d1.loss_cls: 0.7148  decode.d1.loss_mask: 1.4729  decode.d1.loss_dice: 1.1962  decode.d2.loss_cls: 0.6915  decode.d2.loss_mask: 1.5052  decode.d2.loss_dice: 1.2429  decode.d3.loss_cls: 0.7681  decode.d3.loss_mask: 1.4793  decode.d3.loss_dice: 1.2382  decode.d4.loss_cls: 0.7560  decode.d4.loss_mask: 1.5235  decode.d4.loss_dice: 1.2574  decode.d5.loss_cls: 0.7921  decode.d5.loss_mask: 1.4932  decode.d5.loss_dice: 1.2530  decode.d6.loss_cls: 0.6538  decode.d6.loss_mask: 1.5413  decode.d6.loss_dice: 1.2920  decode.d7.loss_cls: 0.7399  decode.d7.loss_mask: 1.5093  decode.d7.loss_dice: 1.2670  decode.d8.loss_cls: 0.6927  decode.d8.loss_mask: 1.5052  decode.d8.loss_dice: 1.2797
05/26 11:49:40 - mmengine - INFO - Iter(train) [  7850/160000]  base_lr: 9.5574e-05 lr: 9.5574e-06  eta: 17:27:46  time: 0.4060  data_time: 0.0086  memory: 5996  grad_norm: 727.4964  loss: 32.2729  decode.loss_cls: 0.5717  decode.loss_mask: 1.5440  decode.loss_dice: 1.0623  decode.d0.loss_cls: 0.9723  decode.d0.loss_mask: 1.3727  decode.d0.loss_dice: 1.0837  decode.d1.loss_cls: 0.6681  decode.d1.loss_mask: 1.4167  decode.d1.loss_dice: 1.0413  decode.d2.loss_cls: 0.6899  decode.d2.loss_mask: 1.4204  decode.d2.loss_dice: 1.0807  decode.d3.loss_cls: 0.6285  decode.d3.loss_mask: 1.4172  decode.d3.loss_dice: 1.0714  decode.d4.loss_cls: 0.7014  decode.d4.loss_mask: 1.4692  decode.d4.loss_dice: 1.0485  decode.d5.loss_cls: 0.7320  decode.d5.loss_mask: 1.4365  decode.d5.loss_dice: 1.0799  decode.d6.loss_cls: 0.6210  decode.d6.loss_mask: 1.4832  decode.d6.loss_dice: 1.0802  decode.d7.loss_cls: 0.6834  decode.d7.loss_mask: 1.5975  decode.d7.loss_dice: 1.1102  decode.d8.loss_cls: 0.6342  decode.d8.loss_mask: 1.4810  decode.d8.loss_dice: 1.0738
05/26 11:50:00 - mmengine - INFO - Iter(train) [  7900/160000]  base_lr: 9.5546e-05 lr: 9.5546e-06  eta: 17:27:20  time: 0.4075  data_time: 0.0085  memory: 5966  grad_norm: 1501.7911  loss: 29.0237  decode.loss_cls: 0.4378  decode.loss_mask: 1.2878  decode.loss_dice: 1.0369  decode.d0.loss_cls: 0.8676  decode.d0.loss_mask: 1.2733  decode.d0.loss_dice: 1.0112  decode.d1.loss_cls: 0.4752  decode.d1.loss_mask: 1.3510  decode.d1.loss_dice: 1.0559  decode.d2.loss_cls: 0.5109  decode.d2.loss_mask: 1.2918  decode.d2.loss_dice: 0.9868  decode.d3.loss_cls: 0.5070  decode.d3.loss_mask: 1.3168  decode.d3.loss_dice: 1.0381  decode.d4.loss_cls: 0.5423  decode.d4.loss_mask: 1.3189  decode.d4.loss_dice: 0.9932  decode.d5.loss_cls: 0.5714  decode.d5.loss_mask: 1.3221  decode.d5.loss_dice: 1.0929  decode.d6.loss_cls: 0.6343  decode.d6.loss_mask: 1.3204  decode.d6.loss_dice: 1.0210  decode.d7.loss_cls: 0.5392  decode.d7.loss_mask: 1.3119  decode.d7.loss_dice: 1.0382  decode.d8.loss_cls: 0.5108  decode.d8.loss_mask: 1.3453  decode.d8.loss_dice: 1.0137
05/26 11:50:21 - mmengine - INFO - Iter(train) [  7950/160000]  base_lr: 9.5517e-05 lr: 9.5517e-06  eta: 17:26:53  time: 0.4069  data_time: 0.0086  memory: 5982  grad_norm: 637.2163  loss: 34.9209  decode.loss_cls: 0.6772  decode.loss_mask: 1.4894  decode.loss_dice: 1.2643  decode.d0.loss_cls: 1.0592  decode.d0.loss_mask: 1.4557  decode.d0.loss_dice: 1.2303  decode.d1.loss_cls: 0.6892  decode.d1.loss_mask: 1.4293  decode.d1.loss_dice: 1.2388  decode.d2.loss_cls: 0.7434  decode.d2.loss_mask: 1.4572  decode.d2.loss_dice: 1.2360  decode.d3.loss_cls: 0.7111  decode.d3.loss_mask: 1.5492  decode.d3.loss_dice: 1.2362  decode.d4.loss_cls: 0.6887  decode.d4.loss_mask: 1.5333  decode.d4.loss_dice: 1.2342  decode.d5.loss_cls: 0.7234  decode.d5.loss_mask: 1.5051  decode.d5.loss_dice: 1.2811  decode.d6.loss_cls: 0.6949  decode.d6.loss_mask: 1.5101  decode.d6.loss_dice: 1.3016  decode.d7.loss_cls: 0.7052  decode.d7.loss_mask: 1.4757  decode.d7.loss_dice: 1.2866  decode.d8.loss_cls: 0.6691  decode.d8.loss_mask: 1.5318  decode.d8.loss_dice: 1.3135
05/26 11:50:41 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 11:50:41 - mmengine - INFO - Iter(train) [  8000/160000]  base_lr: 9.5489e-05 lr: 9.5489e-06  eta: 17:26:25  time: 0.4048  data_time: 0.0086  memory: 5975  grad_norm: 917.4030  loss: 34.0949  decode.loss_cls: 0.7327  decode.loss_mask: 1.5447  decode.loss_dice: 1.1727  decode.d0.loss_cls: 0.9639  decode.d0.loss_mask: 1.4942  decode.d0.loss_dice: 1.1367  decode.d1.loss_cls: 0.6997  decode.d1.loss_mask: 1.5378  decode.d1.loss_dice: 1.1569  decode.d2.loss_cls: 0.6792  decode.d2.loss_mask: 1.5465  decode.d2.loss_dice: 1.1682  decode.d3.loss_cls: 0.6631  decode.d3.loss_mask: 1.5484  decode.d3.loss_dice: 1.1843  decode.d4.loss_cls: 0.6555  decode.d4.loss_mask: 1.5491  decode.d4.loss_dice: 1.1763  decode.d5.loss_cls: 0.6015  decode.d5.loss_mask: 1.5518  decode.d5.loss_dice: 1.1630  decode.d6.loss_cls: 0.6218  decode.d6.loss_mask: 1.5799  decode.d6.loss_dice: 1.1363  decode.d7.loss_cls: 0.6525  decode.d7.loss_mask: 1.5729  decode.d7.loss_dice: 1.1761  decode.d8.loss_cls: 0.6471  decode.d8.loss_mask: 1.5882  decode.d8.loss_dice: 1.1940
05/26 11:51:01 - mmengine - INFO - Iter(train) [  8050/160000]  base_lr: 9.5461e-05 lr: 9.5461e-06  eta: 17:25:59  time: 0.4055  data_time: 0.0085  memory: 5972  grad_norm: 555.7277  loss: 28.0307  decode.loss_cls: 0.6531  decode.loss_mask: 1.1194  decode.loss_dice: 0.9733  decode.d0.loss_cls: 0.9009  decode.d0.loss_mask: 1.1670  decode.d0.loss_dice: 0.9717  decode.d1.loss_cls: 0.6113  decode.d1.loss_mask: 1.1498  decode.d1.loss_dice: 0.9761  decode.d2.loss_cls: 0.7013  decode.d2.loss_mask: 1.1551  decode.d2.loss_dice: 0.9327  decode.d3.loss_cls: 0.6461  decode.d3.loss_mask: 1.2739  decode.d3.loss_dice: 0.9792  decode.d4.loss_cls: 0.6902  decode.d4.loss_mask: 1.1350  decode.d4.loss_dice: 0.9424  decode.d5.loss_cls: 0.6298  decode.d5.loss_mask: 1.1626  decode.d5.loss_dice: 0.9791  decode.d6.loss_cls: 0.6878  decode.d6.loss_mask: 1.1860  decode.d6.loss_dice: 0.9509  decode.d7.loss_cls: 0.6219  decode.d7.loss_mask: 1.1608  decode.d7.loss_dice: 0.9509  decode.d8.loss_cls: 0.5601  decode.d8.loss_mask: 1.1670  decode.d8.loss_dice: 0.9954
05/26 11:51:22 - mmengine - INFO - Iter(train) [  8100/160000]  base_lr: 9.5433e-05 lr: 9.5433e-06  eta: 17:25:32  time: 0.4060  data_time: 0.0085  memory: 5974  grad_norm: 1127.4878  loss: 32.7915  decode.loss_cls: 0.6256  decode.loss_mask: 1.5200  decode.loss_dice: 1.1377  decode.d0.loss_cls: 0.8140  decode.d0.loss_mask: 1.4484  decode.d0.loss_dice: 1.1417  decode.d1.loss_cls: 0.6452  decode.d1.loss_mask: 1.4340  decode.d1.loss_dice: 1.0711  decode.d2.loss_cls: 0.5871  decode.d2.loss_mask: 1.5628  decode.d2.loss_dice: 1.1157  decode.d3.loss_cls: 0.6165  decode.d3.loss_mask: 1.4773  decode.d3.loss_dice: 1.1297  decode.d4.loss_cls: 0.6635  decode.d4.loss_mask: 1.5111  decode.d4.loss_dice: 1.1376  decode.d5.loss_cls: 0.6271  decode.d5.loss_mask: 1.5327  decode.d5.loss_dice: 1.1902  decode.d6.loss_cls: 0.6466  decode.d6.loss_mask: 1.4820  decode.d6.loss_dice: 1.1096  decode.d7.loss_cls: 0.6058  decode.d7.loss_mask: 1.5673  decode.d7.loss_dice: 1.1230  decode.d8.loss_cls: 0.5827  decode.d8.loss_mask: 1.5570  decode.d8.loss_dice: 1.1286
05/26 11:51:42 - mmengine - INFO - Iter(train) [  8150/160000]  base_lr: 9.5404e-05 lr: 9.5404e-06  eta: 17:25:05  time: 0.4066  data_time: 0.0086  memory: 5981  grad_norm: 534.0304  loss: 33.1492  decode.loss_cls: 0.7186  decode.loss_mask: 1.3191  decode.loss_dice: 1.2383  decode.d0.loss_cls: 1.1553  decode.d0.loss_mask: 1.2301  decode.d0.loss_dice: 1.2313  decode.d1.loss_cls: 0.7683  decode.d1.loss_mask: 1.2958  decode.d1.loss_dice: 1.2315  decode.d2.loss_cls: 0.7237  decode.d2.loss_mask: 1.3092  decode.d2.loss_dice: 1.2015  decode.d3.loss_cls: 0.7755  decode.d3.loss_mask: 1.3006  decode.d3.loss_dice: 1.2562  decode.d4.loss_cls: 0.7731  decode.d4.loss_mask: 1.3300  decode.d4.loss_dice: 1.2292  decode.d5.loss_cls: 0.6925  decode.d5.loss_mask: 1.2788  decode.d5.loss_dice: 1.2155  decode.d6.loss_cls: 0.7409  decode.d6.loss_mask: 1.3434  decode.d6.loss_dice: 1.2404  decode.d7.loss_cls: 0.6997  decode.d7.loss_mask: 1.3327  decode.d7.loss_dice: 1.2892  decode.d8.loss_cls: 0.7185  decode.d8.loss_mask: 1.3078  decode.d8.loss_dice: 1.2021
05/26 11:52:02 - mmengine - INFO - Iter(train) [  8200/160000]  base_lr: 9.5376e-05 lr: 9.5376e-06  eta: 17:24:39  time: 0.4066  data_time: 0.0086  memory: 5976  grad_norm: 852.1260  loss: 33.2973  decode.loss_cls: 0.5414  decode.loss_mask: 1.5111  decode.loss_dice: 1.2292  decode.d0.loss_cls: 1.0998  decode.d0.loss_mask: 1.4082  decode.d0.loss_dice: 1.1953  decode.d1.loss_cls: 0.7314  decode.d1.loss_mask: 1.4213  decode.d1.loss_dice: 1.1754  decode.d2.loss_cls: 0.6475  decode.d2.loss_mask: 1.4312  decode.d2.loss_dice: 1.1898  decode.d3.loss_cls: 0.6642  decode.d3.loss_mask: 1.3699  decode.d3.loss_dice: 1.2131  decode.d4.loss_cls: 0.6304  decode.d4.loss_mask: 1.4554  decode.d4.loss_dice: 1.1818  decode.d5.loss_cls: 0.6347  decode.d5.loss_mask: 1.4398  decode.d5.loss_dice: 1.1639  decode.d6.loss_cls: 0.6285  decode.d6.loss_mask: 1.4749  decode.d6.loss_dice: 1.2530  decode.d7.loss_cls: 0.6231  decode.d7.loss_mask: 1.4541  decode.d7.loss_dice: 1.2186  decode.d8.loss_cls: 0.6363  decode.d8.loss_mask: 1.4325  decode.d8.loss_dice: 1.2418
05/26 11:52:23 - mmengine - INFO - Iter(train) [  8250/160000]  base_lr: 9.5348e-05 lr: 9.5348e-06  eta: 17:24:12  time: 0.4074  data_time: 0.0086  memory: 5975  grad_norm: 856.4940  loss: 29.0197  decode.loss_cls: 0.5210  decode.loss_mask: 1.2897  decode.loss_dice: 0.9951  decode.d0.loss_cls: 0.8585  decode.d0.loss_mask: 1.2250  decode.d0.loss_dice: 1.0589  decode.d1.loss_cls: 0.6863  decode.d1.loss_mask: 1.2100  decode.d1.loss_dice: 0.9574  decode.d2.loss_cls: 0.6310  decode.d2.loss_mask: 1.2322  decode.d2.loss_dice: 0.9525  decode.d3.loss_cls: 0.6531  decode.d3.loss_mask: 1.2578  decode.d3.loss_dice: 1.0064  decode.d4.loss_cls: 0.6057  decode.d4.loss_mask: 1.2703  decode.d4.loss_dice: 0.9888  decode.d5.loss_cls: 0.6614  decode.d5.loss_mask: 1.2838  decode.d5.loss_dice: 1.0139  decode.d6.loss_cls: 0.6040  decode.d6.loss_mask: 1.2839  decode.d6.loss_dice: 0.9928  decode.d7.loss_cls: 0.6137  decode.d7.loss_mask: 1.2885  decode.d7.loss_dice: 1.0164  decode.d8.loss_cls: 0.5941  decode.d8.loss_mask: 1.2871  decode.d8.loss_dice: 0.9807
05/26 11:52:43 - mmengine - INFO - Iter(train) [  8300/160000]  base_lr: 9.5319e-05 lr: 9.5319e-06  eta: 17:23:46  time: 0.4076  data_time: 0.0086  memory: 5969  grad_norm: 1155.8400  loss: 32.4996  decode.loss_cls: 0.5024  decode.loss_mask: 1.5843  decode.loss_dice: 1.1428  decode.d0.loss_cls: 0.8928  decode.d0.loss_mask: 1.4301  decode.d0.loss_dice: 1.0836  decode.d1.loss_cls: 0.5917  decode.d1.loss_mask: 1.4671  decode.d1.loss_dice: 1.1234  decode.d2.loss_cls: 0.5893  decode.d2.loss_mask: 1.4885  decode.d2.loss_dice: 1.1179  decode.d3.loss_cls: 0.5587  decode.d3.loss_mask: 1.4943  decode.d3.loss_dice: 1.1567  decode.d4.loss_cls: 0.5393  decode.d4.loss_mask: 1.5272  decode.d4.loss_dice: 1.1307  decode.d5.loss_cls: 0.6365  decode.d5.loss_mask: 1.5455  decode.d5.loss_dice: 1.0966  decode.d6.loss_cls: 0.5699  decode.d6.loss_mask: 1.5527  decode.d6.loss_dice: 1.1424  decode.d7.loss_cls: 0.5180  decode.d7.loss_mask: 1.6634  decode.d7.loss_dice: 1.1529  decode.d8.loss_cls: 0.4963  decode.d8.loss_mask: 1.5454  decode.d8.loss_dice: 1.1593
05/26 11:53:03 - mmengine - INFO - Iter(train) [  8350/160000]  base_lr: 9.5291e-05 lr: 9.5291e-06  eta: 17:23:20  time: 0.4074  data_time: 0.0086  memory: 5971  grad_norm: 931.9852  loss: 33.6722  decode.loss_cls: 0.6284  decode.loss_mask: 1.5337  decode.loss_dice: 1.1652  decode.d0.loss_cls: 1.0282  decode.d0.loss_mask: 1.4170  decode.d0.loss_dice: 1.1599  decode.d1.loss_cls: 0.6541  decode.d1.loss_mask: 1.4976  decode.d1.loss_dice: 1.1454  decode.d2.loss_cls: 0.6667  decode.d2.loss_mask: 1.5131  decode.d2.loss_dice: 1.1502  decode.d3.loss_cls: 0.6855  decode.d3.loss_mask: 1.5182  decode.d3.loss_dice: 1.0828  decode.d4.loss_cls: 0.6959  decode.d4.loss_mask: 1.5410  decode.d4.loss_dice: 1.1329  decode.d5.loss_cls: 0.6436  decode.d5.loss_mask: 1.5929  decode.d5.loss_dice: 1.1741  decode.d6.loss_cls: 0.6474  decode.d6.loss_mask: 1.5120  decode.d6.loss_dice: 1.1298  decode.d7.loss_cls: 0.5998  decode.d7.loss_mask: 1.5940  decode.d7.loss_dice: 1.1903  decode.d8.loss_cls: 0.6053  decode.d8.loss_mask: 1.5897  decode.d8.loss_dice: 1.1776
05/26 11:53:24 - mmengine - INFO - Iter(train) [  8400/160000]  base_lr: 9.5263e-05 lr: 9.5263e-06  eta: 17:22:54  time: 0.4065  data_time: 0.0086  memory: 5976  grad_norm: 943.6133  loss: 29.7371  decode.loss_cls: 0.4943  decode.loss_mask: 1.3487  decode.loss_dice: 1.0133  decode.d0.loss_cls: 0.8989  decode.d0.loss_mask: 1.3264  decode.d0.loss_dice: 1.0840  decode.d1.loss_cls: 0.5604  decode.d1.loss_mask: 1.3613  decode.d1.loss_dice: 0.9979  decode.d2.loss_cls: 0.5658  decode.d2.loss_mask: 1.3179  decode.d2.loss_dice: 1.0111  decode.d3.loss_cls: 0.5848  decode.d3.loss_mask: 1.3386  decode.d3.loss_dice: 1.0181  decode.d4.loss_cls: 0.6595  decode.d4.loss_mask: 1.2694  decode.d4.loss_dice: 1.0074  decode.d5.loss_cls: 0.6073  decode.d5.loss_mask: 1.3773  decode.d5.loss_dice: 1.0837  decode.d6.loss_cls: 0.6371  decode.d6.loss_mask: 1.2927  decode.d6.loss_dice: 1.0176  decode.d7.loss_cls: 0.6190  decode.d7.loss_mask: 1.2923  decode.d7.loss_dice: 1.0115  decode.d8.loss_cls: 0.5354  decode.d8.loss_mask: 1.3363  decode.d8.loss_dice: 1.0693
05/26 11:53:44 - mmengine - INFO - Iter(train) [  8450/160000]  base_lr: 9.5235e-05 lr: 9.5235e-06  eta: 17:22:28  time: 0.4067  data_time: 0.0087  memory: 5967  grad_norm: 922.5488  loss: 36.7369  decode.loss_cls: 0.7268  decode.loss_mask: 1.6243  decode.loss_dice: 1.2120  decode.d0.loss_cls: 1.1220  decode.d0.loss_mask: 1.5413  decode.d0.loss_dice: 1.2129  decode.d1.loss_cls: 0.8605  decode.d1.loss_mask: 1.6079  decode.d1.loss_dice: 1.1847  decode.d2.loss_cls: 0.7406  decode.d2.loss_mask: 1.7215  decode.d2.loss_dice: 1.2137  decode.d3.loss_cls: 0.7261  decode.d3.loss_mask: 1.6361  decode.d3.loss_dice: 1.1740  decode.d4.loss_cls: 0.8479  decode.d4.loss_mask: 1.5332  decode.d4.loss_dice: 1.1822  decode.d5.loss_cls: 0.8080  decode.d5.loss_mask: 1.6637  decode.d5.loss_dice: 1.2322  decode.d6.loss_cls: 0.8354  decode.d6.loss_mask: 1.6959  decode.d6.loss_dice: 1.2737  decode.d7.loss_cls: 0.8206  decode.d7.loss_mask: 1.5996  decode.d7.loss_dice: 1.2687  decode.d8.loss_cls: 0.7475  decode.d8.loss_mask: 1.6561  decode.d8.loss_dice: 1.2675
05/26 11:54:04 - mmengine - INFO - Iter(train) [  8500/160000]  base_lr: 9.5206e-05 lr: 9.5206e-06  eta: 17:22:01  time: 0.4064  data_time: 0.0085  memory: 5968  grad_norm: 634.5743  loss: 29.9163  decode.loss_cls: 0.5946  decode.loss_mask: 1.2753  decode.loss_dice: 1.0756  decode.d0.loss_cls: 0.8612  decode.d0.loss_mask: 1.3065  decode.d0.loss_dice: 1.0855  decode.d1.loss_cls: 0.6092  decode.d1.loss_mask: 1.2719  decode.d1.loss_dice: 1.0421  decode.d2.loss_cls: 0.5953  decode.d2.loss_mask: 1.2802  decode.d2.loss_dice: 1.0707  decode.d3.loss_cls: 0.5557  decode.d3.loss_mask: 1.3055  decode.d3.loss_dice: 1.0796  decode.d4.loss_cls: 0.6512  decode.d4.loss_mask: 1.2934  decode.d4.loss_dice: 1.0941  decode.d5.loss_cls: 0.6142  decode.d5.loss_mask: 1.2416  decode.d5.loss_dice: 1.0420  decode.d6.loss_cls: 0.5984  decode.d6.loss_mask: 1.2730  decode.d6.loss_dice: 1.0534  decode.d7.loss_cls: 0.5988  decode.d7.loss_mask: 1.3002  decode.d7.loss_dice: 1.1045  decode.d8.loss_cls: 0.5918  decode.d8.loss_mask: 1.3225  decode.d8.loss_dice: 1.1282
05/26 11:54:25 - mmengine - INFO - Iter(train) [  8550/160000]  base_lr: 9.5178e-05 lr: 9.5178e-06  eta: 17:21:36  time: 0.4080  data_time: 0.0086  memory: 5968  grad_norm: 612.4132  loss: 30.0891  decode.loss_cls: 0.4825  decode.loss_mask: 1.3727  decode.loss_dice: 1.1145  decode.d0.loss_cls: 0.8982  decode.d0.loss_mask: 1.3511  decode.d0.loss_dice: 1.0371  decode.d1.loss_cls: 0.5093  decode.d1.loss_mask: 1.3713  decode.d1.loss_dice: 1.0838  decode.d2.loss_cls: 0.5732  decode.d2.loss_mask: 1.3539  decode.d2.loss_dice: 1.0583  decode.d3.loss_cls: 0.5405  decode.d3.loss_mask: 1.3311  decode.d3.loss_dice: 1.0454  decode.d4.loss_cls: 0.6099  decode.d4.loss_mask: 1.3674  decode.d4.loss_dice: 1.0291  decode.d5.loss_cls: 0.5374  decode.d5.loss_mask: 1.4509  decode.d5.loss_dice: 1.0557  decode.d6.loss_cls: 0.5542  decode.d6.loss_mask: 1.3582  decode.d6.loss_dice: 1.0682  decode.d7.loss_cls: 0.5553  decode.d7.loss_mask: 1.3947  decode.d7.loss_dice: 1.0592  decode.d8.loss_cls: 0.5137  decode.d8.loss_mask: 1.3818  decode.d8.loss_dice: 1.0304
05/26 11:54:45 - mmengine - INFO - Iter(train) [  8600/160000]  base_lr: 9.5150e-05 lr: 9.5150e-06  eta: 17:21:10  time: 0.4079  data_time: 0.0086  memory: 5967  grad_norm: 1645.0796  loss: 37.8893  decode.loss_cls: 0.6619  decode.loss_mask: 1.6335  decode.loss_dice: 1.3519  decode.d0.loss_cls: 1.0418  decode.d0.loss_mask: 1.5473  decode.d0.loss_dice: 1.2877  decode.d1.loss_cls: 0.7216  decode.d1.loss_mask: 1.6571  decode.d1.loss_dice: 1.3314  decode.d2.loss_cls: 0.7646  decode.d2.loss_mask: 1.7546  decode.d2.loss_dice: 1.3171  decode.d3.loss_cls: 0.7775  decode.d3.loss_mask: 1.7184  decode.d3.loss_dice: 1.3548  decode.d4.loss_cls: 0.7537  decode.d4.loss_mask: 1.6958  decode.d4.loss_dice: 1.4174  decode.d5.loss_cls: 0.7551  decode.d5.loss_mask: 1.7597  decode.d5.loss_dice: 1.3419  decode.d6.loss_cls: 0.7637  decode.d6.loss_mask: 1.6658  decode.d6.loss_dice: 1.3102  decode.d7.loss_cls: 0.8293  decode.d7.loss_mask: 1.6509  decode.d7.loss_dice: 1.3516  decode.d8.loss_cls: 0.7176  decode.d8.loss_mask: 1.6535  decode.d8.loss_dice: 1.3020
05/26 11:55:05 - mmengine - INFO - Iter(train) [  8650/160000]  base_lr: 9.5121e-05 lr: 9.5121e-06  eta: 17:20:44  time: 0.4068  data_time: 0.0086  memory: 5973  grad_norm: 1317.1876  loss: 33.1663  decode.loss_cls: 0.6189  decode.loss_mask: 1.5639  decode.loss_dice: 1.1774  decode.d0.loss_cls: 1.0814  decode.d0.loss_mask: 1.4212  decode.d0.loss_dice: 1.0805  decode.d1.loss_cls: 0.7577  decode.d1.loss_mask: 1.5075  decode.d1.loss_dice: 1.0504  decode.d2.loss_cls: 0.7203  decode.d2.loss_mask: 1.4532  decode.d2.loss_dice: 1.0365  decode.d3.loss_cls: 0.6887  decode.d3.loss_mask: 1.5096  decode.d3.loss_dice: 1.0758  decode.d4.loss_cls: 0.6973  decode.d4.loss_mask: 1.5167  decode.d4.loss_dice: 1.0500  decode.d5.loss_cls: 0.7050  decode.d5.loss_mask: 1.4562  decode.d5.loss_dice: 1.0994  decode.d6.loss_cls: 0.7307  decode.d6.loss_mask: 1.4522  decode.d6.loss_dice: 1.0874  decode.d7.loss_cls: 0.7240  decode.d7.loss_mask: 1.5575  decode.d7.loss_dice: 1.1089  decode.d8.loss_cls: 0.7074  decode.d8.loss_mask: 1.4620  decode.d8.loss_dice: 1.0684
05/26 11:55:26 - mmengine - INFO - Iter(train) [  8700/160000]  base_lr: 9.5093e-05 lr: 9.5093e-06  eta: 17:20:19  time: 0.4066  data_time: 0.0086  memory: 5975  grad_norm: 1044.3612  loss: 27.3921  decode.loss_cls: 0.4869  decode.loss_mask: 1.3612  decode.loss_dice: 0.8770  decode.d0.loss_cls: 0.7762  decode.d0.loss_mask: 1.3033  decode.d0.loss_dice: 0.8030  decode.d1.loss_cls: 0.5876  decode.d1.loss_mask: 1.3745  decode.d1.loss_dice: 0.8320  decode.d2.loss_cls: 0.6346  decode.d2.loss_mask: 1.2976  decode.d2.loss_dice: 0.8121  decode.d3.loss_cls: 0.5956  decode.d3.loss_mask: 1.3305  decode.d3.loss_dice: 0.7757  decode.d4.loss_cls: 0.5734  decode.d4.loss_mask: 1.3263  decode.d4.loss_dice: 0.8200  decode.d5.loss_cls: 0.5662  decode.d5.loss_mask: 1.3349  decode.d5.loss_dice: 0.8223  decode.d6.loss_cls: 0.6000  decode.d6.loss_mask: 1.3549  decode.d6.loss_dice: 0.8249  decode.d7.loss_cls: 0.5332  decode.d7.loss_mask: 1.2947  decode.d7.loss_dice: 0.8075  decode.d8.loss_cls: 0.5005  decode.d8.loss_mask: 1.3399  decode.d8.loss_dice: 0.8455
05/26 11:55:46 - mmengine - INFO - Iter(train) [  8750/160000]  base_lr: 9.5065e-05 lr: 9.5065e-06  eta: 17:19:56  time: 0.4063  data_time: 0.0086  memory: 5969  grad_norm: 893.9654  loss: 28.8929  decode.loss_cls: 0.4644  decode.loss_mask: 1.4484  decode.loss_dice: 0.9207  decode.d0.loss_cls: 0.8395  decode.d0.loss_mask: 1.3694  decode.d0.loss_dice: 0.9349  decode.d1.loss_cls: 0.5466  decode.d1.loss_mask: 1.3735  decode.d1.loss_dice: 0.9362  decode.d2.loss_cls: 0.5495  decode.d2.loss_mask: 1.3800  decode.d2.loss_dice: 0.8873  decode.d3.loss_cls: 0.5332  decode.d3.loss_mask: 1.3652  decode.d3.loss_dice: 0.9045  decode.d4.loss_cls: 0.5796  decode.d4.loss_mask: 1.3959  decode.d4.loss_dice: 0.9094  decode.d5.loss_cls: 0.5563  decode.d5.loss_mask: 1.3956  decode.d5.loss_dice: 0.9089  decode.d6.loss_cls: 0.5170  decode.d6.loss_mask: 1.4502  decode.d6.loss_dice: 0.9305  decode.d7.loss_cls: 0.5492  decode.d7.loss_mask: 1.4457  decode.d7.loss_dice: 0.9335  decode.d8.loss_cls: 0.5195  decode.d8.loss_mask: 1.4266  decode.d8.loss_dice: 0.9216
05/26 11:56:06 - mmengine - INFO - Iter(train) [  8800/160000]  base_lr: 9.5037e-05 lr: 9.5037e-06  eta: 17:19:30  time: 0.4057  data_time: 0.0086  memory: 5971  grad_norm: 727.1715  loss: 30.0467  decode.loss_cls: 0.6367  decode.loss_mask: 1.2813  decode.loss_dice: 1.1590  decode.d0.loss_cls: 1.0167  decode.d0.loss_mask: 1.2001  decode.d0.loss_dice: 1.0508  decode.d1.loss_cls: 0.7032  decode.d1.loss_mask: 1.1784  decode.d1.loss_dice: 1.0519  decode.d2.loss_cls: 0.6839  decode.d2.loss_mask: 1.2168  decode.d2.loss_dice: 1.0660  decode.d3.loss_cls: 0.6321  decode.d3.loss_mask: 1.2545  decode.d3.loss_dice: 1.0516  decode.d4.loss_cls: 0.7118  decode.d4.loss_mask: 1.2398  decode.d4.loss_dice: 1.0407  decode.d5.loss_cls: 0.6291  decode.d5.loss_mask: 1.2208  decode.d5.loss_dice: 1.0528  decode.d6.loss_cls: 0.6110  decode.d6.loss_mask: 1.2642  decode.d6.loss_dice: 1.0666  decode.d7.loss_cls: 0.5964  decode.d7.loss_mask: 1.3307  decode.d7.loss_dice: 1.1159  decode.d8.loss_cls: 0.5963  decode.d8.loss_mask: 1.2795  decode.d8.loss_dice: 1.1084
05/26 11:56:27 - mmengine - INFO - Iter(train) [  8850/160000]  base_lr: 9.5008e-05 lr: 9.5008e-06  eta: 17:19:05  time: 0.4056  data_time: 0.0086  memory: 5973  grad_norm: 486.0657  loss: 28.6207  decode.loss_cls: 0.5847  decode.loss_mask: 1.2008  decode.loss_dice: 1.0342  decode.d0.loss_cls: 0.8920  decode.d0.loss_mask: 1.1712  decode.d0.loss_dice: 1.0306  decode.d1.loss_cls: 0.5883  decode.d1.loss_mask: 1.1765  decode.d1.loss_dice: 1.0072  decode.d2.loss_cls: 0.5941  decode.d2.loss_mask: 1.2158  decode.d2.loss_dice: 1.0412  decode.d3.loss_cls: 0.6008  decode.d3.loss_mask: 1.2347  decode.d3.loss_dice: 1.0214  decode.d4.loss_cls: 0.6242  decode.d4.loss_mask: 1.2173  decode.d4.loss_dice: 1.0501  decode.d5.loss_cls: 0.5799  decode.d5.loss_mask: 1.2462  decode.d5.loss_dice: 1.0596  decode.d6.loss_cls: 0.5942  decode.d6.loss_mask: 1.2183  decode.d6.loss_dice: 1.1093  decode.d7.loss_cls: 0.5340  decode.d7.loss_mask: 1.1635  decode.d7.loss_dice: 1.0530  decode.d8.loss_cls: 0.5191  decode.d8.loss_mask: 1.2037  decode.d8.loss_dice: 1.0547
05/26 11:56:47 - mmengine - INFO - Iter(train) [  8900/160000]  base_lr: 9.4980e-05 lr: 9.4980e-06  eta: 17:18:40  time: 0.4066  data_time: 0.0087  memory: 5974  grad_norm: 549.8078  loss: 28.3121  decode.loss_cls: 0.5975  decode.loss_mask: 1.2552  decode.loss_dice: 0.9654  decode.d0.loss_cls: 0.9551  decode.d0.loss_mask: 1.2185  decode.d0.loss_dice: 0.9454  decode.d1.loss_cls: 0.6250  decode.d1.loss_mask: 1.1785  decode.d1.loss_dice: 0.8770  decode.d2.loss_cls: 0.6489  decode.d2.loss_mask: 1.2105  decode.d2.loss_dice: 0.9137  decode.d3.loss_cls: 0.6123  decode.d3.loss_mask: 1.1938  decode.d3.loss_dice: 0.9588  decode.d4.loss_cls: 0.7051  decode.d4.loss_mask: 1.2145  decode.d4.loss_dice: 0.9493  decode.d5.loss_cls: 0.6549  decode.d5.loss_mask: 1.2476  decode.d5.loss_dice: 0.9618  decode.d6.loss_cls: 0.5843  decode.d6.loss_mask: 1.2316  decode.d6.loss_dice: 0.9620  decode.d7.loss_cls: 0.5967  decode.d7.loss_mask: 1.2433  decode.d7.loss_dice: 0.9559  decode.d8.loss_cls: 0.6517  decode.d8.loss_mask: 1.1931  decode.d8.loss_dice: 1.0049
05/26 11:57:08 - mmengine - INFO - Iter(train) [  8950/160000]  base_lr: 9.4952e-05 lr: 9.4952e-06  eta: 17:18:14  time: 0.4072  data_time: 0.0087  memory: 5972  grad_norm: 618.8767  loss: 29.3291  decode.loss_cls: 0.5862  decode.loss_mask: 1.3091  decode.loss_dice: 0.9746  decode.d0.loss_cls: 0.8089  decode.d0.loss_mask: 1.2804  decode.d0.loss_dice: 0.9734  decode.d1.loss_cls: 0.5846  decode.d1.loss_mask: 1.3140  decode.d1.loss_dice: 0.9734  decode.d2.loss_cls: 0.6022  decode.d2.loss_mask: 1.3088  decode.d2.loss_dice: 0.9818  decode.d3.loss_cls: 0.6413  decode.d3.loss_mask: 1.3014  decode.d3.loss_dice: 0.9975  decode.d4.loss_cls: 0.6587  decode.d4.loss_mask: 1.3363  decode.d4.loss_dice: 0.9842  decode.d5.loss_cls: 0.5692  decode.d5.loss_mask: 1.3112  decode.d5.loss_dice: 1.0002  decode.d6.loss_cls: 0.6193  decode.d6.loss_mask: 1.3599  decode.d6.loss_dice: 1.0161  decode.d7.loss_cls: 0.5623  decode.d7.loss_mask: 1.3667  decode.d7.loss_dice: 1.0050  decode.d8.loss_cls: 0.5399  decode.d8.loss_mask: 1.3814  decode.d8.loss_dice: 0.9814
05/26 11:57:28 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 11:57:28 - mmengine - INFO - Iter(train) [  9000/160000]  base_lr: 9.4923e-05 lr: 9.4923e-06  eta: 17:17:49  time: 0.4075  data_time: 0.0095  memory: 5968  grad_norm: 1060.4321  loss: 30.8059  decode.loss_cls: 0.5146  decode.loss_mask: 1.4373  decode.loss_dice: 0.9931  decode.d0.loss_cls: 0.9313  decode.d0.loss_mask: 1.4288  decode.d0.loss_dice: 1.0448  decode.d1.loss_cls: 0.5371  decode.d1.loss_mask: 1.4099  decode.d1.loss_dice: 0.9974  decode.d2.loss_cls: 0.5485  decode.d2.loss_mask: 1.4948  decode.d2.loss_dice: 1.0460  decode.d3.loss_cls: 0.5258  decode.d3.loss_mask: 1.4770  decode.d3.loss_dice: 1.0179  decode.d4.loss_cls: 0.5624  decode.d4.loss_mask: 1.4367  decode.d4.loss_dice: 1.0242  decode.d5.loss_cls: 0.5833  decode.d5.loss_mask: 1.5020  decode.d5.loss_dice: 1.1025  decode.d6.loss_cls: 0.5573  decode.d6.loss_mask: 1.5220  decode.d6.loss_dice: 1.0502  decode.d7.loss_cls: 0.4973  decode.d7.loss_mask: 1.4855  decode.d7.loss_dice: 1.0214  decode.d8.loss_cls: 0.5426  decode.d8.loss_mask: 1.4841  decode.d8.loss_dice: 1.0304
05/26 11:57:48 - mmengine - INFO - Iter(train) [  9050/160000]  base_lr: 9.4895e-05 lr: 9.4895e-06  eta: 17:17:24  time: 0.4064  data_time: 0.0086  memory: 5966  grad_norm: 596.4055  loss: 29.3406  decode.loss_cls: 0.4380  decode.loss_mask: 1.5360  decode.loss_dice: 1.0140  decode.d0.loss_cls: 0.9386  decode.d0.loss_mask: 1.2904  decode.d0.loss_dice: 0.9229  decode.d1.loss_cls: 0.5208  decode.d1.loss_mask: 1.3301  decode.d1.loss_dice: 0.9447  decode.d2.loss_cls: 0.5295  decode.d2.loss_mask: 1.3882  decode.d2.loss_dice: 0.9582  decode.d3.loss_cls: 0.5308  decode.d3.loss_mask: 1.3787  decode.d3.loss_dice: 0.9737  decode.d4.loss_cls: 0.6014  decode.d4.loss_mask: 1.3274  decode.d4.loss_dice: 0.9769  decode.d5.loss_cls: 0.5381  decode.d5.loss_mask: 1.3717  decode.d5.loss_dice: 1.0124  decode.d6.loss_cls: 0.5531  decode.d6.loss_mask: 1.3969  decode.d6.loss_dice: 1.0260  decode.d7.loss_cls: 0.5285  decode.d7.loss_mask: 1.3647  decode.d7.loss_dice: 1.0116  decode.d8.loss_cls: 0.5014  decode.d8.loss_mask: 1.4256  decode.d8.loss_dice: 1.0104
05/26 11:58:09 - mmengine - INFO - Iter(train) [  9100/160000]  base_lr: 9.4867e-05 lr: 9.4867e-06  eta: 17:16:59  time: 0.4075  data_time: 0.0086  memory: 5971  grad_norm: 612.7339  loss: 31.7714  decode.loss_cls: 0.7071  decode.loss_mask: 1.3405  decode.loss_dice: 1.0289  decode.d0.loss_cls: 0.9942  decode.d0.loss_mask: 1.3271  decode.d0.loss_dice: 1.0422  decode.d1.loss_cls: 0.7370  decode.d1.loss_mask: 1.3415  decode.d1.loss_dice: 1.0455  decode.d2.loss_cls: 0.7213  decode.d2.loss_mask: 1.3426  decode.d2.loss_dice: 1.0244  decode.d3.loss_cls: 0.7358  decode.d3.loss_mask: 1.3979  decode.d3.loss_dice: 1.0586  decode.d4.loss_cls: 0.7607  decode.d4.loss_mask: 1.3955  decode.d4.loss_dice: 1.0264  decode.d5.loss_cls: 0.7268  decode.d5.loss_mask: 1.4396  decode.d5.loss_dice: 1.0571  decode.d6.loss_cls: 0.7446  decode.d6.loss_mask: 1.4024  decode.d6.loss_dice: 1.0611  decode.d7.loss_cls: 0.7544  decode.d7.loss_mask: 1.3640  decode.d7.loss_dice: 1.0668  decode.d8.loss_cls: 0.7344  decode.d8.loss_mask: 1.3562  decode.d8.loss_dice: 1.0367
05/26 11:58:29 - mmengine - INFO - Iter(train) [  9150/160000]  base_lr: 9.4839e-05 lr: 9.4839e-06  eta: 17:16:34  time: 0.4070  data_time: 0.0086  memory: 5971  grad_norm: 1068.2462  loss: 36.3198  decode.loss_cls: 0.6868  decode.loss_mask: 1.5966  decode.loss_dice: 1.2488  decode.d0.loss_cls: 1.0888  decode.d0.loss_mask: 1.5334  decode.d0.loss_dice: 1.2902  decode.d1.loss_cls: 0.7465  decode.d1.loss_mask: 1.5523  decode.d1.loss_dice: 1.2283  decode.d2.loss_cls: 0.7517  decode.d2.loss_mask: 1.5663  decode.d2.loss_dice: 1.2199  decode.d3.loss_cls: 0.7192  decode.d3.loss_mask: 1.6038  decode.d3.loss_dice: 1.2863  decode.d4.loss_cls: 0.8554  decode.d4.loss_mask: 1.5035  decode.d4.loss_dice: 1.2262  decode.d5.loss_cls: 0.7594  decode.d5.loss_mask: 1.5825  decode.d5.loss_dice: 1.3685  decode.d6.loss_cls: 0.8032  decode.d6.loss_mask: 1.5631  decode.d6.loss_dice: 1.3063  decode.d7.loss_cls: 0.7812  decode.d7.loss_mask: 1.5774  decode.d7.loss_dice: 1.2891  decode.d8.loss_cls: 0.7449  decode.d8.loss_mask: 1.5959  decode.d8.loss_dice: 1.2446
05/26 11:58:50 - mmengine - INFO - Iter(train) [  9200/160000]  base_lr: 9.4810e-05 lr: 9.4810e-06  eta: 17:16:16  time: 0.4476  data_time: 0.0087  memory: 5980  grad_norm: 1009.5943  loss: 33.9595  decode.loss_cls: 0.5390  decode.loss_mask: 1.5504  decode.loss_dice: 1.2215  decode.d0.loss_cls: 1.0457  decode.d0.loss_mask: 1.4134  decode.d0.loss_dice: 1.1654  decode.d1.loss_cls: 0.6094  decode.d1.loss_mask: 1.5197  decode.d1.loss_dice: 1.1856  decode.d2.loss_cls: 0.5865  decode.d2.loss_mask: 1.5606  decode.d2.loss_dice: 1.2474  decode.d3.loss_cls: 0.5949  decode.d3.loss_mask: 1.5797  decode.d3.loss_dice: 1.2125  decode.d4.loss_cls: 0.6316  decode.d4.loss_mask: 1.5815  decode.d4.loss_dice: 1.2162  decode.d5.loss_cls: 0.5637  decode.d5.loss_mask: 1.6286  decode.d5.loss_dice: 1.2440  decode.d6.loss_cls: 0.5697  decode.d6.loss_mask: 1.5804  decode.d6.loss_dice: 1.1919  decode.d7.loss_cls: 0.5202  decode.d7.loss_mask: 1.6200  decode.d7.loss_dice: 1.2407  decode.d8.loss_cls: 0.5554  decode.d8.loss_mask: 1.5734  decode.d8.loss_dice: 1.2106
05/26 11:59:10 - mmengine - INFO - Iter(train) [  9250/160000]  base_lr: 9.4782e-05 lr: 9.4782e-06  eta: 17:15:53  time: 0.4068  data_time: 0.0086  memory: 5971  grad_norm: 777.0489  loss: 36.7010  decode.loss_cls: 0.7151  decode.loss_mask: 1.7748  decode.loss_dice: 1.1878  decode.d0.loss_cls: 1.1120  decode.d0.loss_mask: 1.5899  decode.d0.loss_dice: 1.1420  decode.d1.loss_cls: 0.7952  decode.d1.loss_mask: 1.7205  decode.d1.loss_dice: 1.1244  decode.d2.loss_cls: 0.7442  decode.d2.loss_mask: 1.7092  decode.d2.loss_dice: 1.1116  decode.d3.loss_cls: 0.7660  decode.d3.loss_mask: 1.7033  decode.d3.loss_dice: 1.1056  decode.d4.loss_cls: 0.7641  decode.d4.loss_mask: 1.7453  decode.d4.loss_dice: 1.1916  decode.d5.loss_cls: 0.7195  decode.d5.loss_mask: 1.7877  decode.d5.loss_dice: 1.2016  decode.d6.loss_cls: 0.7936  decode.d6.loss_mask: 1.7177  decode.d6.loss_dice: 1.1548  decode.d7.loss_cls: 0.8298  decode.d7.loss_mask: 1.7218  decode.d7.loss_dice: 1.1334  decode.d8.loss_cls: 0.7362  decode.d8.loss_mask: 1.7391  decode.d8.loss_dice: 1.1634
05/26 11:59:31 - mmengine - INFO - Iter(train) [  9300/160000]  base_lr: 9.4754e-05 lr: 9.4754e-06  eta: 17:15:28  time: 0.4066  data_time: 0.0086  memory: 5970  grad_norm: 893.2113  loss: 31.3687  decode.loss_cls: 0.5312  decode.loss_mask: 1.4620  decode.loss_dice: 1.1408  decode.d0.loss_cls: 0.9726  decode.d0.loss_mask: 1.3269  decode.d0.loss_dice: 1.1099  decode.d1.loss_cls: 0.5848  decode.d1.loss_mask: 1.4089  decode.d1.loss_dice: 1.1077  decode.d2.loss_cls: 0.6293  decode.d2.loss_mask: 1.4218  decode.d2.loss_dice: 1.1208  decode.d3.loss_cls: 0.6138  decode.d3.loss_mask: 1.3503  decode.d3.loss_dice: 1.0941  decode.d4.loss_cls: 0.5713  decode.d4.loss_mask: 1.3834  decode.d4.loss_dice: 1.1517  decode.d5.loss_cls: 0.6506  decode.d5.loss_mask: 1.3490  decode.d5.loss_dice: 1.0694  decode.d6.loss_cls: 0.5894  decode.d6.loss_mask: 1.4319  decode.d6.loss_dice: 1.1195  decode.d7.loss_cls: 0.5211  decode.d7.loss_mask: 1.4377  decode.d7.loss_dice: 1.1200  decode.d8.loss_cls: 0.5632  decode.d8.loss_mask: 1.4245  decode.d8.loss_dice: 1.1109
05/26 11:59:51 - mmengine - INFO - Iter(train) [  9350/160000]  base_lr: 9.4725e-05 lr: 9.4725e-06  eta: 17:15:04  time: 0.4074  data_time: 0.0086  memory: 5975  grad_norm: 800.4550  loss: 31.6662  decode.loss_cls: 0.5191  decode.loss_mask: 1.4030  decode.loss_dice: 1.2013  decode.d0.loss_cls: 0.9803  decode.d0.loss_mask: 1.3507  decode.d0.loss_dice: 1.1844  decode.d1.loss_cls: 0.5308  decode.d1.loss_mask: 1.4670  decode.d1.loss_dice: 1.1928  decode.d2.loss_cls: 0.5859  decode.d2.loss_mask: 1.3418  decode.d2.loss_dice: 1.1465  decode.d3.loss_cls: 0.5261  decode.d3.loss_mask: 1.3655  decode.d3.loss_dice: 1.1867  decode.d4.loss_cls: 0.6225  decode.d4.loss_mask: 1.3668  decode.d4.loss_dice: 1.1787  decode.d5.loss_cls: 0.6149  decode.d5.loss_mask: 1.3686  decode.d5.loss_dice: 1.1756  decode.d6.loss_cls: 0.5478  decode.d6.loss_mask: 1.3649  decode.d6.loss_dice: 1.1468  decode.d7.loss_cls: 0.5042  decode.d7.loss_mask: 1.4209  decode.d7.loss_dice: 1.1809  decode.d8.loss_cls: 0.5847  decode.d8.loss_mask: 1.4092  decode.d8.loss_dice: 1.1977
05/26 12:00:11 - mmengine - INFO - Iter(train) [  9400/160000]  base_lr: 9.4697e-05 lr: 9.4697e-06  eta: 17:14:41  time: 0.4084  data_time: 0.0089  memory: 5979  grad_norm: 722.7672  loss: 30.9009  decode.loss_cls: 0.4490  decode.loss_mask: 1.4331  decode.loss_dice: 1.1274  decode.d0.loss_cls: 0.9256  decode.d0.loss_mask: 1.3342  decode.d0.loss_dice: 1.1283  decode.d1.loss_cls: 0.5907  decode.d1.loss_mask: 1.4195  decode.d1.loss_dice: 1.1125  decode.d2.loss_cls: 0.5902  decode.d2.loss_mask: 1.3776  decode.d2.loss_dice: 1.0808  decode.d3.loss_cls: 0.5333  decode.d3.loss_mask: 1.4498  decode.d3.loss_dice: 1.1600  decode.d4.loss_cls: 0.6034  decode.d4.loss_mask: 1.3867  decode.d4.loss_dice: 1.1117  decode.d5.loss_cls: 0.5597  decode.d5.loss_mask: 1.3366  decode.d5.loss_dice: 1.1176  decode.d6.loss_cls: 0.5634  decode.d6.loss_mask: 1.3973  decode.d6.loss_dice: 1.1108  decode.d7.loss_cls: 0.5476  decode.d7.loss_mask: 1.3453  decode.d7.loss_dice: 1.0978  decode.d8.loss_cls: 0.4989  decode.d8.loss_mask: 1.3995  decode.d8.loss_dice: 1.1124
05/26 12:00:32 - mmengine - INFO - Iter(train) [  9450/160000]  base_lr: 9.4669e-05 lr: 9.4669e-06  eta: 17:14:16  time: 0.4079  data_time: 0.0086  memory: 5975  grad_norm: 688.4559  loss: 32.4153  decode.loss_cls: 0.5343  decode.loss_mask: 1.4876  decode.loss_dice: 1.1690  decode.d0.loss_cls: 0.9579  decode.d0.loss_mask: 1.3913  decode.d0.loss_dice: 1.1053  decode.d1.loss_cls: 0.6416  decode.d1.loss_mask: 1.4366  decode.d1.loss_dice: 1.1497  decode.d2.loss_cls: 0.6367  decode.d2.loss_mask: 1.4944  decode.d2.loss_dice: 1.1132  decode.d3.loss_cls: 0.5732  decode.d3.loss_mask: 1.4511  decode.d3.loss_dice: 1.0937  decode.d4.loss_cls: 0.6511  decode.d4.loss_mask: 1.4744  decode.d4.loss_dice: 1.1501  decode.d5.loss_cls: 0.6500  decode.d5.loss_mask: 1.4844  decode.d5.loss_dice: 1.1495  decode.d6.loss_cls: 0.6424  decode.d6.loss_mask: 1.4759  decode.d6.loss_dice: 1.1132  decode.d7.loss_cls: 0.5719  decode.d7.loss_mask: 1.4624  decode.d7.loss_dice: 1.1718  decode.d8.loss_cls: 0.5811  decode.d8.loss_mask: 1.4554  decode.d8.loss_dice: 1.1461
05/26 12:00:52 - mmengine - INFO - Iter(train) [  9500/160000]  base_lr: 9.4641e-05 lr: 9.4641e-06  eta: 17:13:52  time: 0.4078  data_time: 0.0087  memory: 5968  grad_norm: 1564.5722  loss: 35.2476  decode.loss_cls: 0.3882  decode.loss_mask: 1.8048  decode.loss_dice: 1.2617  decode.d0.loss_cls: 0.9167  decode.d0.loss_mask: 1.6767  decode.d0.loss_dice: 1.2838  decode.d1.loss_cls: 0.5632  decode.d1.loss_mask: 1.6832  decode.d1.loss_dice: 1.2496  decode.d2.loss_cls: 0.5694  decode.d2.loss_mask: 1.7023  decode.d2.loss_dice: 1.2260  decode.d3.loss_cls: 0.5562  decode.d3.loss_mask: 1.7020  decode.d3.loss_dice: 1.2826  decode.d4.loss_cls: 0.4973  decode.d4.loss_mask: 1.7509  decode.d4.loss_dice: 1.2690  decode.d5.loss_cls: 0.5167  decode.d5.loss_mask: 1.7406  decode.d5.loss_dice: 1.2388  decode.d6.loss_cls: 0.5377  decode.d6.loss_mask: 1.6905  decode.d6.loss_dice: 1.2297  decode.d7.loss_cls: 0.5216  decode.d7.loss_mask: 1.6920  decode.d7.loss_dice: 1.2279  decode.d8.loss_cls: 0.5080  decode.d8.loss_mask: 1.7321  decode.d8.loss_dice: 1.2283
05/26 12:01:12 - mmengine - INFO - Iter(train) [  9550/160000]  base_lr: 9.4612e-05 lr: 9.4612e-06  eta: 17:13:27  time: 0.4068  data_time: 0.0086  memory: 5987  grad_norm: 668.4657  loss: 36.4400  decode.loss_cls: 0.6772  decode.loss_mask: 1.5871  decode.loss_dice: 1.3435  decode.d0.loss_cls: 1.1076  decode.d0.loss_mask: 1.5549  decode.d0.loss_dice: 1.4058  decode.d1.loss_cls: 0.7360  decode.d1.loss_mask: 1.5824  decode.d1.loss_dice: 1.3225  decode.d2.loss_cls: 0.7443  decode.d2.loss_mask: 1.5813  decode.d2.loss_dice: 1.2809  decode.d3.loss_cls: 0.6673  decode.d3.loss_mask: 1.5741  decode.d3.loss_dice: 1.2883  decode.d4.loss_cls: 0.6466  decode.d4.loss_mask: 1.5834  decode.d4.loss_dice: 1.3531  decode.d5.loss_cls: 0.6762  decode.d5.loss_mask: 1.5426  decode.d5.loss_dice: 1.3932  decode.d6.loss_cls: 0.6945  decode.d6.loss_mask: 1.5716  decode.d6.loss_dice: 1.3662  decode.d7.loss_cls: 0.6774  decode.d7.loss_mask: 1.5596  decode.d7.loss_dice: 1.3553  decode.d8.loss_cls: 0.6997  decode.d8.loss_mask: 1.5449  decode.d8.loss_dice: 1.3225
05/26 12:01:33 - mmengine - INFO - Iter(train) [  9600/160000]  base_lr: 9.4584e-05 lr: 9.4584e-06  eta: 17:13:02  time: 0.4081  data_time: 0.0087  memory: 5967  grad_norm: 999.3573  loss: 29.6624  decode.loss_cls: 0.4673  decode.loss_mask: 1.4017  decode.loss_dice: 0.9958  decode.d0.loss_cls: 0.9404  decode.d0.loss_mask: 1.3843  decode.d0.loss_dice: 0.9643  decode.d1.loss_cls: 0.5130  decode.d1.loss_mask: 1.3714  decode.d1.loss_dice: 0.9591  decode.d2.loss_cls: 0.5261  decode.d2.loss_mask: 1.3958  decode.d2.loss_dice: 0.9608  decode.d3.loss_cls: 0.5131  decode.d3.loss_mask: 1.4512  decode.d3.loss_dice: 0.9870  decode.d4.loss_cls: 0.5630  decode.d4.loss_mask: 1.4142  decode.d4.loss_dice: 0.9545  decode.d5.loss_cls: 0.5857  decode.d5.loss_mask: 1.4292  decode.d5.loss_dice: 0.9498  decode.d6.loss_cls: 0.6573  decode.d6.loss_mask: 1.4354  decode.d6.loss_dice: 0.9784  decode.d7.loss_cls: 0.5484  decode.d7.loss_mask: 1.4659  decode.d7.loss_dice: 0.9556  decode.d8.loss_cls: 0.5038  decode.d8.loss_mask: 1.4158  decode.d8.loss_dice: 0.9743
05/26 12:01:53 - mmengine - INFO - Iter(train) [  9650/160000]  base_lr: 9.4556e-05 lr: 9.4556e-06  eta: 17:12:38  time: 0.4073  data_time: 0.0086  memory: 5968  grad_norm: 616.2593  loss: 24.8475  decode.loss_cls: 0.3857  decode.loss_mask: 1.1638  decode.loss_dice: 0.8866  decode.d0.loss_cls: 0.7736  decode.d0.loss_mask: 1.1294  decode.d0.loss_dice: 0.8683  decode.d1.loss_cls: 0.4203  decode.d1.loss_mask: 1.1399  decode.d1.loss_dice: 0.8854  decode.d2.loss_cls: 0.4425  decode.d2.loss_mask: 1.1648  decode.d2.loss_dice: 0.8793  decode.d3.loss_cls: 0.4316  decode.d3.loss_mask: 1.1306  decode.d3.loss_dice: 0.8608  decode.d4.loss_cls: 0.4221  decode.d4.loss_mask: 1.1659  decode.d4.loss_dice: 0.8862  decode.d5.loss_cls: 0.4644  decode.d5.loss_mask: 1.1425  decode.d5.loss_dice: 0.8806  decode.d6.loss_cls: 0.4255  decode.d6.loss_mask: 1.1903  decode.d6.loss_dice: 0.8825  decode.d7.loss_cls: 0.3738  decode.d7.loss_mask: 1.1535  decode.d7.loss_dice: 0.8841  decode.d8.loss_cls: 0.3800  decode.d8.loss_mask: 1.1605  decode.d8.loss_dice: 0.8730
05/26 12:02:14 - mmengine - INFO - Iter(train) [  9700/160000]  base_lr: 9.4527e-05 lr: 9.4527e-06  eta: 17:12:14  time: 0.4070  data_time: 0.0086  memory: 5969  grad_norm: 651.9332  loss: 32.8206  decode.loss_cls: 0.5888  decode.loss_mask: 1.4827  decode.loss_dice: 1.1558  decode.d0.loss_cls: 0.9018  decode.d0.loss_mask: 1.4731  decode.d0.loss_dice: 1.1506  decode.d1.loss_cls: 0.6386  decode.d1.loss_mask: 1.4627  decode.d1.loss_dice: 1.1014  decode.d2.loss_cls: 0.6550  decode.d2.loss_mask: 1.4620  decode.d2.loss_dice: 1.1008  decode.d3.loss_cls: 0.6141  decode.d3.loss_mask: 1.4872  decode.d3.loss_dice: 1.0979  decode.d4.loss_cls: 0.6345  decode.d4.loss_mask: 1.4927  decode.d4.loss_dice: 1.1192  decode.d5.loss_cls: 0.6221  decode.d5.loss_mask: 1.5181  decode.d5.loss_dice: 1.1689  decode.d6.loss_cls: 0.5984  decode.d6.loss_mask: 1.5240  decode.d6.loss_dice: 1.1631  decode.d7.loss_cls: 0.4914  decode.d7.loss_mask: 1.6398  decode.d7.loss_dice: 1.2266  decode.d8.loss_cls: 0.5720  decode.d8.loss_mask: 1.5118  decode.d8.loss_dice: 1.1656
05/26 12:02:34 - mmengine - INFO - Iter(train) [  9750/160000]  base_lr: 9.4499e-05 lr: 9.4499e-06  eta: 17:11:49  time: 0.4070  data_time: 0.0086  memory: 5978  grad_norm: 690.4819  loss: 29.4175  decode.loss_cls: 0.4018  decode.loss_mask: 1.4035  decode.loss_dice: 1.0213  decode.d0.loss_cls: 0.8177  decode.d0.loss_mask: 1.3868  decode.d0.loss_dice: 0.9809  decode.d1.loss_cls: 0.4551  decode.d1.loss_mask: 1.4368  decode.d1.loss_dice: 1.0063  decode.d2.loss_cls: 0.5237  decode.d2.loss_mask: 1.4144  decode.d2.loss_dice: 1.0005  decode.d3.loss_cls: 0.4344  decode.d3.loss_mask: 1.4257  decode.d3.loss_dice: 0.9851  decode.d4.loss_cls: 0.5779  decode.d4.loss_mask: 1.4465  decode.d4.loss_dice: 1.0224  decode.d5.loss_cls: 0.5035  decode.d5.loss_mask: 1.4057  decode.d5.loss_dice: 1.0133  decode.d6.loss_cls: 0.4848  decode.d6.loss_mask: 1.4191  decode.d6.loss_dice: 1.0405  decode.d7.loss_cls: 0.4612  decode.d7.loss_mask: 1.3979  decode.d7.loss_dice: 1.0119  decode.d8.loss_cls: 0.4748  decode.d8.loss_mask: 1.4513  decode.d8.loss_dice: 1.0128
05/26 12:02:54 - mmengine - INFO - Iter(train) [  9800/160000]  base_lr: 9.4471e-05 lr: 9.4471e-06  eta: 17:11:27  time: 0.4292  data_time: 0.0086  memory: 5966  grad_norm: 816.6254  loss: 31.0899  decode.loss_cls: 0.4679  decode.loss_mask: 1.5032  decode.loss_dice: 1.0541  decode.d0.loss_cls: 0.9348  decode.d0.loss_mask: 1.4779  decode.d0.loss_dice: 1.0723  decode.d1.loss_cls: 0.4947  decode.d1.loss_mask: 1.5142  decode.d1.loss_dice: 1.0595  decode.d2.loss_cls: 0.5021  decode.d2.loss_mask: 1.5100  decode.d2.loss_dice: 1.0673  decode.d3.loss_cls: 0.5031  decode.d3.loss_mask: 1.5047  decode.d3.loss_dice: 1.0591  decode.d4.loss_cls: 0.5702  decode.d4.loss_mask: 1.4719  decode.d4.loss_dice: 1.0432  decode.d5.loss_cls: 0.6269  decode.d5.loss_mask: 1.4503  decode.d5.loss_dice: 1.0653  decode.d6.loss_cls: 0.4870  decode.d6.loss_mask: 1.5279  decode.d6.loss_dice: 1.0644  decode.d7.loss_cls: 0.4841  decode.d7.loss_mask: 1.4991  decode.d7.loss_dice: 1.0531  decode.d8.loss_cls: 0.4696  decode.d8.loss_mask: 1.5128  decode.d8.loss_dice: 1.0389
05/26 12:03:15 - mmengine - INFO - Iter(train) [  9850/160000]  base_lr: 9.4442e-05 lr: 9.4442e-06  eta: 17:11:04  time: 0.4083  data_time: 0.0086  memory: 5975  grad_norm: 978.2009  loss: 27.2236  decode.loss_cls: 0.3808  decode.loss_mask: 1.3389  decode.loss_dice: 0.9478  decode.d0.loss_cls: 0.8007  decode.d0.loss_mask: 1.3179  decode.d0.loss_dice: 0.9714  decode.d1.loss_cls: 0.3651  decode.d1.loss_mask: 1.3332  decode.d1.loss_dice: 0.9382  decode.d2.loss_cls: 0.3933  decode.d2.loss_mask: 1.2992  decode.d2.loss_dice: 0.8847  decode.d3.loss_cls: 0.4061  decode.d3.loss_mask: 1.3521  decode.d3.loss_dice: 0.9158  decode.d4.loss_cls: 0.4151  decode.d4.loss_mask: 1.3456  decode.d4.loss_dice: 0.9604  decode.d5.loss_cls: 0.3946  decode.d5.loss_mask: 1.3319  decode.d5.loss_dice: 1.0097  decode.d6.loss_cls: 0.4171  decode.d6.loss_mask: 1.3636  decode.d6.loss_dice: 0.9460  decode.d7.loss_cls: 0.4185  decode.d7.loss_mask: 1.3442  decode.d7.loss_dice: 0.9506  decode.d8.loss_cls: 0.3979  decode.d8.loss_mask: 1.3362  decode.d8.loss_dice: 0.9474
05/26 12:03:35 - mmengine - INFO - Iter(train) [  9900/160000]  base_lr: 9.4414e-05 lr: 9.4414e-06  eta: 17:10:40  time: 0.4076  data_time: 0.0086  memory: 5967  grad_norm: 671.8673  loss: 29.9676  decode.loss_cls: 0.5511  decode.loss_mask: 1.2827  decode.loss_dice: 1.1014  decode.d0.loss_cls: 0.9294  decode.d0.loss_mask: 1.2523  decode.d0.loss_dice: 1.1341  decode.d1.loss_cls: 0.5206  decode.d1.loss_mask: 1.2663  decode.d1.loss_dice: 1.0944  decode.d2.loss_cls: 0.5980  decode.d2.loss_mask: 1.2752  decode.d2.loss_dice: 1.1120  decode.d3.loss_cls: 0.6172  decode.d3.loss_mask: 1.2937  decode.d3.loss_dice: 1.1103  decode.d4.loss_cls: 0.5470  decode.d4.loss_mask: 1.2760  decode.d4.loss_dice: 1.0853  decode.d5.loss_cls: 0.6365  decode.d5.loss_mask: 1.2744  decode.d5.loss_dice: 1.0913  decode.d6.loss_cls: 0.5421  decode.d6.loss_mask: 1.3090  decode.d6.loss_dice: 1.1424  decode.d7.loss_cls: 0.5537  decode.d7.loss_mask: 1.2778  decode.d7.loss_dice: 1.1198  decode.d8.loss_cls: 0.5794  decode.d8.loss_mask: 1.3033  decode.d8.loss_dice: 1.0909
05/26 12:03:56 - mmengine - INFO - Iter(train) [  9950/160000]  base_lr: 9.4386e-05 lr: 9.4386e-06  eta: 17:10:16  time: 0.4073  data_time: 0.0090  memory: 5970  grad_norm: 774.5731  loss: 26.4327  decode.loss_cls: 0.3774  decode.loss_mask: 1.3081  decode.loss_dice: 0.8601  decode.d0.loss_cls: 0.8568  decode.d0.loss_mask: 1.2300  decode.d0.loss_dice: 0.8623  decode.d1.loss_cls: 0.4537  decode.d1.loss_mask: 1.2700  decode.d1.loss_dice: 0.8507  decode.d2.loss_cls: 0.5163  decode.d2.loss_mask: 1.2351  decode.d2.loss_dice: 0.8170  decode.d3.loss_cls: 0.4832  decode.d3.loss_mask: 1.2520  decode.d3.loss_dice: 0.8383  decode.d4.loss_cls: 0.5268  decode.d4.loss_mask: 1.2652  decode.d4.loss_dice: 0.8453  decode.d5.loss_cls: 0.5137  decode.d5.loss_mask: 1.2431  decode.d5.loss_dice: 0.8550  decode.d6.loss_cls: 0.4754  decode.d6.loss_mask: 1.3051  decode.d6.loss_dice: 0.9058  decode.d7.loss_cls: 0.5436  decode.d7.loss_mask: 1.2453  decode.d7.loss_dice: 0.8571  decode.d8.loss_cls: 0.4226  decode.d8.loss_mask: 1.3365  decode.d8.loss_dice: 0.8810
05/26 12:04:16 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 12:04:16 - mmengine - INFO - Iter(train) [ 10000/160000]  base_lr: 9.4358e-05 lr: 9.4358e-06  eta: 17:09:52  time: 0.4073  data_time: 0.0086  memory: 5976  grad_norm: 893.7079  loss: 28.1195  decode.loss_cls: 0.4347  decode.loss_mask: 1.2813  decode.loss_dice: 0.9887  decode.d0.loss_cls: 0.8614  decode.d0.loss_mask: 1.2360  decode.d0.loss_dice: 0.9571  decode.d1.loss_cls: 0.5304  decode.d1.loss_mask: 1.3235  decode.d1.loss_dice: 0.9449  decode.d2.loss_cls: 0.4682  decode.d2.loss_mask: 1.3409  decode.d2.loss_dice: 0.9575  decode.d3.loss_cls: 0.4395  decode.d3.loss_mask: 1.3137  decode.d3.loss_dice: 0.9860  decode.d4.loss_cls: 0.5143  decode.d4.loss_mask: 1.3212  decode.d4.loss_dice: 0.9967  decode.d5.loss_cls: 0.5187  decode.d5.loss_mask: 1.2671  decode.d5.loss_dice: 0.9718  decode.d6.loss_cls: 0.5921  decode.d6.loss_mask: 1.3402  decode.d6.loss_dice: 0.9580  decode.d7.loss_cls: 0.4686  decode.d7.loss_mask: 1.3043  decode.d7.loss_dice: 1.0016  decode.d8.loss_cls: 0.4530  decode.d8.loss_mask: 1.3612  decode.d8.loss_dice: 0.9869
05/26 12:04:16 - mmengine - INFO - Saving checkpoint at 10000 iterations
05/26 12:04:20 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:09  time: 0.0488  data_time: 0.0013  memory: 1391  
05/26 12:04:23 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:06  time: 0.0482  data_time: 0.0013  memory: 1205  
05/26 12:04:25 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:04  time: 0.0508  data_time: 0.0013  memory: 1596  
05/26 12:04:28 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:01  time: 0.0491  data_time: 0.0012  memory: 1298  
05/26 12:04:30 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:58  time: 0.0484  data_time: 0.0012  memory: 1298  
05/26 12:04:33 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:56  time: 0.0483  data_time: 0.0012  memory: 1279  
05/26 12:04:35 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:53  time: 0.0485  data_time: 0.0013  memory: 1224  
05/26 12:04:37 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:51  time: 0.0493  data_time: 0.0012  memory: 1298  
05/26 12:04:40 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0481  data_time: 0.0012  memory: 1298  
05/26 12:04:42 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:46  time: 0.0524  data_time: 0.0012  memory: 1725  
05/26 12:04:45 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:44  time: 0.0485  data_time: 0.0012  memory: 1336  
05/26 12:04:47 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:41  time: 0.0509  data_time: 0.0013  memory: 1298  
05/26 12:04:50 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:39  time: 0.0488  data_time: 0.0012  memory: 1205  
05/26 12:04:52 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0504  data_time: 0.0012  memory: 1316  
05/26 12:04:55 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:34  time: 0.0483  data_time: 0.0012  memory: 1279  
05/26 12:04:57 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0531  data_time: 0.0013  memory: 1410  
05/26 12:04:59 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:29  time: 0.0484  data_time: 0.0012  memory: 1279  
05/26 12:05:02 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0515  data_time: 0.0012  memory: 1205  
05/26 12:05:04 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0489  data_time: 0.0012  memory: 1205  
05/26 12:05:07 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0498  data_time: 0.0013  memory: 1336  
05/26 12:05:09 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0482  data_time: 0.0012  memory: 1246  
05/26 12:05:12 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0524  data_time: 0.0012  memory: 1503  
05/26 12:05:14 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0490  data_time: 0.0012  memory: 1261  
05/26 12:05:17 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0489  data_time: 0.0012  memory: 1298  
05/26 12:05:19 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0483  data_time: 0.0012  memory: 1447  
05/26 12:05:21 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0485  data_time: 0.0012  memory: 1298  
05/26 12:05:24 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0498  data_time: 0.0013  memory: 1279  
05/26 12:05:26 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0482  data_time: 0.0012  memory: 1205  
05/26 12:05:29 - mmengine - INFO - per class results:
05/26 12:05:29 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 94.27 | 96.82 |
|  aeroplane  | 73.68 |  96.6 |
|   bicycle   | 22.18 | 88.86 |
|     bird    | 75.66 |  78.4 |
|     boat    | 40.67 | 52.27 |
|    bottle   | 41.41 | 74.22 |
|     bus     | 56.04 | 93.64 |
|     car     | 71.46 | 92.91 |
|     cat     | 56.11 | 97.81 |
|    chair    | 16.99 |  18.5 |
|     cow     |  0.0  |  0.0  |
| diningtable | 50.57 | 64.83 |
|     dog     |  16.7 | 24.47 |
|    horse    | 29.43 | 66.85 |
|  motorbike  | 27.27 | 33.83 |
|    person   | 86.57 | 89.88 |
| pottedplant | 13.29 | 16.55 |
|    sheep    |  1.95 |  2.0  |
|     sofa    | 40.46 | 75.25 |
|    train    |  21.2 | 21.64 |
|  tvmonitor  | 15.38 |  19.4 |
+-------------+-------+-------+
05/26 12:05:29 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 87.8200  mIoU: 40.5400  mAcc: 57.3700  data_time: 0.0013  time: 0.0489
05/26 12:05:29 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_5000.pth is removed
05/26 12:05:30 - mmengine - INFO - The best checkpoint with 40.5400 mIoU at 10000 iter is saved to best_mIoU_iter_10000.pth.
05/26 12:05:52 - mmengine - INFO - Iter(train) [ 10050/160000]  base_lr: 9.4329e-05 lr: 9.4329e-06  eta: 17:10:11  time: 0.4068  data_time: 0.0086  memory: 5971  grad_norm: 929.0527  loss: 31.5118  decode.loss_cls: 0.5088  decode.loss_mask: 1.5450  decode.loss_dice: 1.0439  decode.d0.loss_cls: 0.8900  decode.d0.loss_mask: 1.5210  decode.d0.loss_dice: 1.0162  decode.d1.loss_cls: 0.5919  decode.d1.loss_mask: 1.4975  decode.d1.loss_dice: 0.9811  decode.d2.loss_cls: 0.5301  decode.d2.loss_mask: 1.5468  decode.d2.loss_dice: 1.0413  decode.d3.loss_cls: 0.5292  decode.d3.loss_mask: 1.5829  decode.d3.loss_dice: 1.0475  decode.d4.loss_cls: 0.5851  decode.d4.loss_mask: 1.5036  decode.d4.loss_dice: 1.0204  decode.d5.loss_cls: 0.5699  decode.d5.loss_mask: 1.5956  decode.d5.loss_dice: 1.0498  decode.d6.loss_cls: 0.5848  decode.d6.loss_mask: 1.5079  decode.d6.loss_dice: 1.0110  decode.d7.loss_cls: 0.5182  decode.d7.loss_mask: 1.5369  decode.d7.loss_dice: 1.0436  decode.d8.loss_cls: 0.4699  decode.d8.loss_mask: 1.5819  decode.d8.loss_dice: 1.0600
05/26 12:06:12 - mmengine - INFO - Iter(train) [ 10100/160000]  base_lr: 9.4301e-05 lr: 9.4301e-06  eta: 17:09:47  time: 0.4075  data_time: 0.0087  memory: 5976  grad_norm: 707.4133  loss: 29.7500  decode.loss_cls: 0.5213  decode.loss_mask: 1.1344  decode.loss_dice: 1.2016  decode.d0.loss_cls: 0.9000  decode.d0.loss_mask: 1.1471  decode.d0.loss_dice: 1.1849  decode.d1.loss_cls: 0.5762  decode.d1.loss_mask: 1.1311  decode.d1.loss_dice: 1.2027  decode.d2.loss_cls: 0.5786  decode.d2.loss_mask: 1.1747  decode.d2.loss_dice: 1.1940  decode.d3.loss_cls: 0.5571  decode.d3.loss_mask: 1.1317  decode.d3.loss_dice: 1.1916  decode.d4.loss_cls: 0.6463  decode.d4.loss_mask: 1.1411  decode.d4.loss_dice: 1.2025  decode.d5.loss_cls: 0.6022  decode.d5.loss_mask: 1.1578  decode.d5.loss_dice: 1.2181  decode.d6.loss_cls: 0.5872  decode.d6.loss_mask: 1.1843  decode.d6.loss_dice: 1.2087  decode.d7.loss_cls: 0.5715  decode.d7.loss_mask: 1.2011  decode.d7.loss_dice: 1.2347  decode.d8.loss_cls: 0.5117  decode.d8.loss_mask: 1.2116  decode.d8.loss_dice: 1.2441
05/26 12:06:33 - mmengine - INFO - Iter(train) [ 10150/160000]  base_lr: 9.4273e-05 lr: 9.4273e-06  eta: 17:09:22  time: 0.4079  data_time: 0.0086  memory: 5971  grad_norm: 667.9698  loss: 30.2818  decode.loss_cls: 0.5754  decode.loss_mask: 1.3497  decode.loss_dice: 1.0625  decode.d0.loss_cls: 0.9269  decode.d0.loss_mask: 1.2702  decode.d0.loss_dice: 0.9829  decode.d1.loss_cls: 0.5136  decode.d1.loss_mask: 1.3652  decode.d1.loss_dice: 1.0375  decode.d2.loss_cls: 0.5133  decode.d2.loss_mask: 1.4094  decode.d2.loss_dice: 1.0588  decode.d3.loss_cls: 0.5335  decode.d3.loss_mask: 1.3917  decode.d3.loss_dice: 1.0226  decode.d4.loss_cls: 0.5342  decode.d4.loss_mask: 1.4449  decode.d4.loss_dice: 1.1064  decode.d5.loss_cls: 0.5470  decode.d5.loss_mask: 1.4873  decode.d5.loss_dice: 1.0876  decode.d6.loss_cls: 0.5216  decode.d6.loss_mask: 1.4857  decode.d6.loss_dice: 1.0975  decode.d7.loss_cls: 0.5296  decode.d7.loss_mask: 1.3788  decode.d7.loss_dice: 1.0463  decode.d8.loss_cls: 0.5069  decode.d8.loss_mask: 1.4081  decode.d8.loss_dice: 1.0870
05/26 12:06:53 - mmengine - INFO - Iter(train) [ 10200/160000]  base_lr: 9.4244e-05 lr: 9.4244e-06  eta: 17:08:57  time: 0.4073  data_time: 0.0087  memory: 5969  grad_norm: 793.7353  loss: 28.9133  decode.loss_cls: 0.5032  decode.loss_mask: 1.3545  decode.loss_dice: 1.0624  decode.d0.loss_cls: 0.8517  decode.d0.loss_mask: 1.2900  decode.d0.loss_dice: 0.9961  decode.d1.loss_cls: 0.5454  decode.d1.loss_mask: 1.2831  decode.d1.loss_dice: 0.9911  decode.d2.loss_cls: 0.5121  decode.d2.loss_mask: 1.3046  decode.d2.loss_dice: 1.0101  decode.d3.loss_cls: 0.4996  decode.d3.loss_mask: 1.3094  decode.d3.loss_dice: 1.0504  decode.d4.loss_cls: 0.4814  decode.d4.loss_mask: 1.3541  decode.d4.loss_dice: 1.0366  decode.d5.loss_cls: 0.5284  decode.d5.loss_mask: 1.3373  decode.d5.loss_dice: 0.9946  decode.d6.loss_cls: 0.5229  decode.d6.loss_mask: 1.3558  decode.d6.loss_dice: 0.9964  decode.d7.loss_cls: 0.4971  decode.d7.loss_mask: 1.3397  decode.d7.loss_dice: 1.0042  decode.d8.loss_cls: 0.4889  decode.d8.loss_mask: 1.3816  decode.d8.loss_dice: 1.0308
05/26 12:07:13 - mmengine - INFO - Iter(train) [ 10250/160000]  base_lr: 9.4216e-05 lr: 9.4216e-06  eta: 17:08:34  time: 0.4078  data_time: 0.0086  memory: 5968  grad_norm: 769.8311  loss: 32.1819  decode.loss_cls: 0.6663  decode.loss_mask: 1.4310  decode.loss_dice: 0.9978  decode.d0.loss_cls: 0.9484  decode.d0.loss_mask: 1.3650  decode.d0.loss_dice: 1.0544  decode.d1.loss_cls: 0.7324  decode.d1.loss_mask: 1.3572  decode.d1.loss_dice: 1.0238  decode.d2.loss_cls: 0.7288  decode.d2.loss_mask: 1.3927  decode.d2.loss_dice: 0.9799  decode.d3.loss_cls: 0.7172  decode.d3.loss_mask: 1.4453  decode.d3.loss_dice: 1.0793  decode.d4.loss_cls: 0.7447  decode.d4.loss_mask: 1.5203  decode.d4.loss_dice: 1.1358  decode.d5.loss_cls: 0.7280  decode.d5.loss_mask: 1.3758  decode.d5.loss_dice: 1.0783  decode.d6.loss_cls: 0.7793  decode.d6.loss_mask: 1.5017  decode.d6.loss_dice: 1.1071  decode.d7.loss_cls: 0.7670  decode.d7.loss_mask: 1.4194  decode.d7.loss_dice: 1.0285  decode.d8.loss_cls: 0.6433  decode.d8.loss_mask: 1.4638  decode.d8.loss_dice: 0.9694
05/26 12:07:34 - mmengine - INFO - Iter(train) [ 10300/160000]  base_lr: 9.4188e-05 lr: 9.4188e-06  eta: 17:08:10  time: 0.4073  data_time: 0.0085  memory: 5969  grad_norm: 946.1141  loss: 31.4719  decode.loss_cls: 0.4951  decode.loss_mask: 1.4475  decode.loss_dice: 1.0814  decode.d0.loss_cls: 0.9231  decode.d0.loss_mask: 1.4449  decode.d0.loss_dice: 1.1447  decode.d1.loss_cls: 0.4878  decode.d1.loss_mask: 1.4665  decode.d1.loss_dice: 1.0970  decode.d2.loss_cls: 0.4863  decode.d2.loss_mask: 1.5030  decode.d2.loss_dice: 1.1333  decode.d3.loss_cls: 0.5029  decode.d3.loss_mask: 1.4823  decode.d3.loss_dice: 1.1525  decode.d4.loss_cls: 0.5077  decode.d4.loss_mask: 1.4554  decode.d4.loss_dice: 1.1226  decode.d5.loss_cls: 0.5559  decode.d5.loss_mask: 1.4543  decode.d5.loss_dice: 1.1262  decode.d6.loss_cls: 0.5531  decode.d6.loss_mask: 1.4681  decode.d6.loss_dice: 1.1350  decode.d7.loss_cls: 0.4858  decode.d7.loss_mask: 1.5086  decode.d7.loss_dice: 1.1500  decode.d8.loss_cls: 0.5410  decode.d8.loss_mask: 1.4498  decode.d8.loss_dice: 1.1102
05/26 12:07:54 - mmengine - INFO - Iter(train) [ 10350/160000]  base_lr: 9.4159e-05 lr: 9.4159e-06  eta: 17:07:45  time: 0.4077  data_time: 0.0086  memory: 5975  grad_norm: 518.0757  loss: 26.8520  decode.loss_cls: 0.3883  decode.loss_mask: 1.3021  decode.loss_dice: 0.9591  decode.d0.loss_cls: 0.8960  decode.d0.loss_mask: 1.1905  decode.d0.loss_dice: 0.9034  decode.d1.loss_cls: 0.4299  decode.d1.loss_mask: 1.2683  decode.d1.loss_dice: 0.9070  decode.d2.loss_cls: 0.4158  decode.d2.loss_mask: 1.3084  decode.d2.loss_dice: 0.9469  decode.d3.loss_cls: 0.4089  decode.d3.loss_mask: 1.2936  decode.d3.loss_dice: 0.9288  decode.d4.loss_cls: 0.3914  decode.d4.loss_mask: 1.3438  decode.d4.loss_dice: 0.9565  decode.d5.loss_cls: 0.4384  decode.d5.loss_mask: 1.2867  decode.d5.loss_dice: 0.9196  decode.d6.loss_cls: 0.4548  decode.d6.loss_mask: 1.2963  decode.d6.loss_dice: 0.9295  decode.d7.loss_cls: 0.4041  decode.d7.loss_mask: 1.2838  decode.d7.loss_dice: 0.9481  decode.d8.loss_cls: 0.3877  decode.d8.loss_mask: 1.3009  decode.d8.loss_dice: 0.9634
05/26 12:08:14 - mmengine - INFO - Iter(train) [ 10400/160000]  base_lr: 9.4131e-05 lr: 9.4131e-06  eta: 17:07:21  time: 0.4082  data_time: 0.0087  memory: 5969  grad_norm: 763.7843  loss: 28.4354  decode.loss_cls: 0.4452  decode.loss_mask: 1.3558  decode.loss_dice: 0.9819  decode.d0.loss_cls: 0.7636  decode.d0.loss_mask: 1.2755  decode.d0.loss_dice: 0.9394  decode.d1.loss_cls: 0.5096  decode.d1.loss_mask: 1.4168  decode.d1.loss_dice: 0.9515  decode.d2.loss_cls: 0.4700  decode.d2.loss_mask: 1.3678  decode.d2.loss_dice: 0.9854  decode.d3.loss_cls: 0.4041  decode.d3.loss_mask: 1.4492  decode.d3.loss_dice: 1.0236  decode.d4.loss_cls: 0.4601  decode.d4.loss_mask: 1.3661  decode.d4.loss_dice: 0.9921  decode.d5.loss_cls: 0.5083  decode.d5.loss_mask: 1.3284  decode.d5.loss_dice: 0.9893  decode.d6.loss_cls: 0.4858  decode.d6.loss_mask: 1.4128  decode.d6.loss_dice: 0.9709  decode.d7.loss_cls: 0.4628  decode.d7.loss_mask: 1.3544  decode.d7.loss_dice: 1.0036  decode.d8.loss_cls: 0.4422  decode.d8.loss_mask: 1.3634  decode.d8.loss_dice: 0.9562
05/26 12:08:35 - mmengine - INFO - Iter(train) [ 10450/160000]  base_lr: 9.4103e-05 lr: 9.4103e-06  eta: 17:06:57  time: 0.4075  data_time: 0.0085  memory: 5966  grad_norm: 688.9333  loss: 27.5066  decode.loss_cls: 0.2888  decode.loss_mask: 1.4448  decode.loss_dice: 0.9219  decode.d0.loss_cls: 0.6799  decode.d0.loss_mask: 1.3673  decode.d0.loss_dice: 0.9831  decode.d1.loss_cls: 0.3508  decode.d1.loss_mask: 1.4631  decode.d1.loss_dice: 0.9435  decode.d2.loss_cls: 0.3086  decode.d2.loss_mask: 1.4514  decode.d2.loss_dice: 0.9384  decode.d3.loss_cls: 0.3361  decode.d3.loss_mask: 1.4918  decode.d3.loss_dice: 1.0030  decode.d4.loss_cls: 0.3248  decode.d4.loss_mask: 1.4137  decode.d4.loss_dice: 0.9635  decode.d5.loss_cls: 0.4011  decode.d5.loss_mask: 1.4014  decode.d5.loss_dice: 0.9448  decode.d6.loss_cls: 0.3296  decode.d6.loss_mask: 1.4490  decode.d6.loss_dice: 0.9273  decode.d7.loss_cls: 0.2672  decode.d7.loss_mask: 1.4700  decode.d7.loss_dice: 0.9640  decode.d8.loss_cls: 0.3184  decode.d8.loss_mask: 1.4313  decode.d8.loss_dice: 0.9280
05/26 12:08:55 - mmengine - INFO - Iter(train) [ 10500/160000]  base_lr: 9.4074e-05 lr: 9.4074e-06  eta: 17:06:33  time: 0.4067  data_time: 0.0086  memory: 5983  grad_norm: 1231.6617  loss: 33.8278  decode.loss_cls: 0.6537  decode.loss_mask: 1.5407  decode.loss_dice: 1.1382  decode.d0.loss_cls: 0.9229  decode.d0.loss_mask: 1.4817  decode.d0.loss_dice: 1.1766  decode.d1.loss_cls: 0.6758  decode.d1.loss_mask: 1.5547  decode.d1.loss_dice: 1.1922  decode.d2.loss_cls: 0.6056  decode.d2.loss_mask: 1.6183  decode.d2.loss_dice: 1.1711  decode.d3.loss_cls: 0.5735  decode.d3.loss_mask: 1.6298  decode.d3.loss_dice: 1.1789  decode.d4.loss_cls: 0.6052  decode.d4.loss_mask: 1.5488  decode.d4.loss_dice: 1.1708  decode.d5.loss_cls: 0.6005  decode.d5.loss_mask: 1.5074  decode.d5.loss_dice: 1.1713  decode.d6.loss_cls: 0.6588  decode.d6.loss_mask: 1.4740  decode.d6.loss_dice: 1.1650  decode.d7.loss_cls: 0.7017  decode.d7.loss_mask: 1.5688  decode.d7.loss_dice: 1.1648  decode.d8.loss_cls: 0.7240  decode.d8.loss_mask: 1.5259  decode.d8.loss_dice: 1.1270
05/26 12:09:16 - mmengine - INFO - Iter(train) [ 10550/160000]  base_lr: 9.4046e-05 lr: 9.4046e-06  eta: 17:06:09  time: 0.4076  data_time: 0.0086  memory: 5966  grad_norm: 723.2988  loss: 30.8333  decode.loss_cls: 0.4263  decode.loss_mask: 1.6077  decode.loss_dice: 1.0131  decode.d0.loss_cls: 0.8300  decode.d0.loss_mask: 1.5032  decode.d0.loss_dice: 0.9797  decode.d1.loss_cls: 0.5532  decode.d1.loss_mask: 1.4976  decode.d1.loss_dice: 1.0134  decode.d2.loss_cls: 0.4701  decode.d2.loss_mask: 1.5799  decode.d2.loss_dice: 1.0271  decode.d3.loss_cls: 0.4694  decode.d3.loss_mask: 1.5624  decode.d3.loss_dice: 0.9855  decode.d4.loss_cls: 0.4376  decode.d4.loss_mask: 1.6242  decode.d4.loss_dice: 0.9747  decode.d5.loss_cls: 0.4781  decode.d5.loss_mask: 1.5614  decode.d5.loss_dice: 1.0202  decode.d6.loss_cls: 0.4940  decode.d6.loss_mask: 1.5769  decode.d6.loss_dice: 1.0085  decode.d7.loss_cls: 0.4815  decode.d7.loss_mask: 1.6008  decode.d7.loss_dice: 0.9954  decode.d8.loss_cls: 0.4243  decode.d8.loss_mask: 1.6150  decode.d8.loss_dice: 1.0222
05/26 12:09:36 - mmengine - INFO - Iter(train) [ 10600/160000]  base_lr: 9.4018e-05 lr: 9.4018e-06  eta: 17:05:45  time: 0.4064  data_time: 0.0086  memory: 5976  grad_norm: 640.5760  loss: 31.3184  decode.loss_cls: 0.5695  decode.loss_mask: 1.2419  decode.loss_dice: 1.2443  decode.d0.loss_cls: 0.9718  decode.d0.loss_mask: 1.2063  decode.d0.loss_dice: 1.1952  decode.d1.loss_cls: 0.6410  decode.d1.loss_mask: 1.2172  decode.d1.loss_dice: 1.1971  decode.d2.loss_cls: 0.6623  decode.d2.loss_mask: 1.2282  decode.d2.loss_dice: 1.2097  decode.d3.loss_cls: 0.6623  decode.d3.loss_mask: 1.2198  decode.d3.loss_dice: 1.2258  decode.d4.loss_cls: 0.6549  decode.d4.loss_mask: 1.2655  decode.d4.loss_dice: 1.2378  decode.d5.loss_cls: 0.6490  decode.d5.loss_mask: 1.2279  decode.d5.loss_dice: 1.2471  decode.d6.loss_cls: 0.6508  decode.d6.loss_mask: 1.2284  decode.d6.loss_dice: 1.2151  decode.d7.loss_cls: 0.6380  decode.d7.loss_mask: 1.2558  decode.d7.loss_dice: 1.2206  decode.d8.loss_cls: 0.5920  decode.d8.loss_mask: 1.2930  decode.d8.loss_dice: 1.2498
05/26 12:09:56 - mmengine - INFO - Iter(train) [ 10650/160000]  base_lr: 9.3989e-05 lr: 9.3989e-06  eta: 17:05:21  time: 0.4061  data_time: 0.0086  memory: 5973  grad_norm: 655.2065  loss: 32.1538  decode.loss_cls: 0.4933  decode.loss_mask: 1.5087  decode.loss_dice: 1.2063  decode.d0.loss_cls: 0.9488  decode.d0.loss_mask: 1.4189  decode.d0.loss_dice: 1.1410  decode.d1.loss_cls: 0.4773  decode.d1.loss_mask: 1.4981  decode.d1.loss_dice: 1.1725  decode.d2.loss_cls: 0.4333  decode.d2.loss_mask: 1.4806  decode.d2.loss_dice: 1.1693  decode.d3.loss_cls: 0.5181  decode.d3.loss_mask: 1.4874  decode.d3.loss_dice: 1.1664  decode.d4.loss_cls: 0.5608  decode.d4.loss_mask: 1.4821  decode.d4.loss_dice: 1.1779  decode.d5.loss_cls: 0.5075  decode.d5.loss_mask: 1.5305  decode.d5.loss_dice: 1.2001  decode.d6.loss_cls: 0.5402  decode.d6.loss_mask: 1.5193  decode.d6.loss_dice: 1.1905  decode.d7.loss_cls: 0.4627  decode.d7.loss_mask: 1.5286  decode.d7.loss_dice: 1.1993  decode.d8.loss_cls: 0.3993  decode.d8.loss_mask: 1.5128  decode.d8.loss_dice: 1.2225
05/26 12:10:17 - mmengine - INFO - Iter(train) [ 10700/160000]  base_lr: 9.3961e-05 lr: 9.3961e-06  eta: 17:04:57  time: 0.4061  data_time: 0.0086  memory: 5987  grad_norm: 689.1166  loss: 30.4706  decode.loss_cls: 0.4879  decode.loss_mask: 1.3221  decode.loss_dice: 1.0873  decode.d0.loss_cls: 1.0316  decode.d0.loss_mask: 1.3264  decode.d0.loss_dice: 1.0878  decode.d1.loss_cls: 0.5817  decode.d1.loss_mask: 1.2883  decode.d1.loss_dice: 1.1372  decode.d2.loss_cls: 0.5365  decode.d2.loss_mask: 1.4139  decode.d2.loss_dice: 1.1062  decode.d3.loss_cls: 0.5476  decode.d3.loss_mask: 1.3170  decode.d3.loss_dice: 1.1003  decode.d4.loss_cls: 0.5851  decode.d4.loss_mask: 1.2651  decode.d4.loss_dice: 1.0990  decode.d5.loss_cls: 0.5375  decode.d5.loss_mask: 1.3656  decode.d5.loss_dice: 1.1767  decode.d6.loss_cls: 0.6010  decode.d6.loss_mask: 1.3565  decode.d6.loss_dice: 1.1342  decode.d7.loss_cls: 0.5785  decode.d7.loss_mask: 1.3014  decode.d7.loss_dice: 1.1128  decode.d8.loss_cls: 0.5451  decode.d8.loss_mask: 1.2929  decode.d8.loss_dice: 1.1474
05/26 12:10:37 - mmengine - INFO - Iter(train) [ 10750/160000]  base_lr: 9.3933e-05 lr: 9.3933e-06  eta: 17:04:32  time: 0.4065  data_time: 0.0085  memory: 5974  grad_norm: 516.9917  loss: 28.2612  decode.loss_cls: 0.5780  decode.loss_mask: 1.0973  decode.loss_dice: 1.0679  decode.d0.loss_cls: 1.0036  decode.d0.loss_mask: 1.0520  decode.d0.loss_dice: 1.0327  decode.d1.loss_cls: 0.5960  decode.d1.loss_mask: 1.1390  decode.d1.loss_dice: 1.1028  decode.d2.loss_cls: 0.6224  decode.d2.loss_mask: 1.1076  decode.d2.loss_dice: 1.0248  decode.d3.loss_cls: 0.6689  decode.d3.loss_mask: 1.0697  decode.d3.loss_dice: 1.0267  decode.d4.loss_cls: 0.6849  decode.d4.loss_mask: 1.1207  decode.d4.loss_dice: 1.0767  decode.d5.loss_cls: 0.6823  decode.d5.loss_mask: 1.0987  decode.d5.loss_dice: 1.0787  decode.d6.loss_cls: 0.6750  decode.d6.loss_mask: 1.0858  decode.d6.loss_dice: 1.0534  decode.d7.loss_cls: 0.6434  decode.d7.loss_mask: 1.1010  decode.d7.loss_dice: 1.0479  decode.d8.loss_cls: 0.6115  decode.d8.loss_mask: 1.0753  decode.d8.loss_dice: 1.0365
05/26 12:10:57 - mmengine - INFO - Iter(train) [ 10800/160000]  base_lr: 9.3904e-05 lr: 9.3904e-06  eta: 17:04:08  time: 0.4069  data_time: 0.0086  memory: 5980  grad_norm: 1080.6718  loss: 31.8215  decode.loss_cls: 0.4247  decode.loss_mask: 1.6181  decode.loss_dice: 1.0544  decode.d0.loss_cls: 0.8975  decode.d0.loss_mask: 1.4845  decode.d0.loss_dice: 1.0282  decode.d1.loss_cls: 0.4827  decode.d1.loss_mask: 1.5978  decode.d1.loss_dice: 1.0581  decode.d2.loss_cls: 0.4856  decode.d2.loss_mask: 1.5257  decode.d2.loss_dice: 1.0699  decode.d3.loss_cls: 0.4750  decode.d3.loss_mask: 1.5424  decode.d3.loss_dice: 1.0644  decode.d4.loss_cls: 0.5478  decode.d4.loss_mask: 1.6786  decode.d4.loss_dice: 1.1130  decode.d5.loss_cls: 0.5348  decode.d5.loss_mask: 1.5970  decode.d5.loss_dice: 1.0625  decode.d6.loss_cls: 0.4969  decode.d6.loss_mask: 1.6159  decode.d6.loss_dice: 1.0580  decode.d7.loss_cls: 0.5260  decode.d7.loss_mask: 1.6037  decode.d7.loss_dice: 1.0808  decode.d8.loss_cls: 0.4520  decode.d8.loss_mask: 1.5774  decode.d8.loss_dice: 1.0681
05/26 12:11:18 - mmengine - INFO - Iter(train) [ 10850/160000]  base_lr: 9.3876e-05 lr: 9.3876e-06  eta: 17:03:45  time: 0.4065  data_time: 0.0086  memory: 5980  grad_norm: 842.7302  loss: 32.7999  decode.loss_cls: 0.4819  decode.loss_mask: 1.6008  decode.loss_dice: 1.1687  decode.d0.loss_cls: 1.0334  decode.d0.loss_mask: 1.4390  decode.d0.loss_dice: 1.0642  decode.d1.loss_cls: 0.5793  decode.d1.loss_mask: 1.5666  decode.d1.loss_dice: 1.1186  decode.d2.loss_cls: 0.5991  decode.d2.loss_mask: 1.5494  decode.d2.loss_dice: 1.1251  decode.d3.loss_cls: 0.5907  decode.d3.loss_mask: 1.5633  decode.d3.loss_dice: 1.1462  decode.d4.loss_cls: 0.6219  decode.d4.loss_mask: 1.5293  decode.d4.loss_dice: 1.0920  decode.d5.loss_cls: 0.5808  decode.d5.loss_mask: 1.5049  decode.d5.loss_dice: 1.1244  decode.d6.loss_cls: 0.6164  decode.d6.loss_mask: 1.5338  decode.d6.loss_dice: 1.1060  decode.d7.loss_cls: 0.5161  decode.d7.loss_mask: 1.5678  decode.d7.loss_dice: 1.1516  decode.d8.loss_cls: 0.5621  decode.d8.loss_mask: 1.5164  decode.d8.loss_dice: 1.1503
05/26 12:11:38 - mmengine - INFO - Iter(train) [ 10900/160000]  base_lr: 9.3848e-05 lr: 9.3848e-06  eta: 17:03:21  time: 0.4075  data_time: 0.0086  memory: 5967  grad_norm: 757.6775  loss: 32.6390  decode.loss_cls: 0.4918  decode.loss_mask: 1.5704  decode.loss_dice: 1.1626  decode.d0.loss_cls: 0.9804  decode.d0.loss_mask: 1.4552  decode.d0.loss_dice: 1.1290  decode.d1.loss_cls: 0.5556  decode.d1.loss_mask: 1.5022  decode.d1.loss_dice: 1.1428  decode.d2.loss_cls: 0.5024  decode.d2.loss_mask: 1.5439  decode.d2.loss_dice: 1.1139  decode.d3.loss_cls: 0.4911  decode.d3.loss_mask: 1.5449  decode.d3.loss_dice: 1.1411  decode.d4.loss_cls: 0.5813  decode.d4.loss_mask: 1.5392  decode.d4.loss_dice: 1.1517  decode.d5.loss_cls: 0.5429  decode.d5.loss_mask: 1.5142  decode.d5.loss_dice: 1.1559  decode.d6.loss_cls: 0.6220  decode.d6.loss_mask: 1.5080  decode.d6.loss_dice: 1.1376  decode.d7.loss_cls: 0.5663  decode.d7.loss_mask: 1.5977  decode.d7.loss_dice: 1.1452  decode.d8.loss_cls: 0.5283  decode.d8.loss_mask: 1.5686  decode.d8.loss_dice: 1.1531
05/26 12:11:58 - mmengine - INFO - Iter(train) [ 10950/160000]  base_lr: 9.3820e-05 lr: 9.3820e-06  eta: 17:02:57  time: 0.4067  data_time: 0.0086  memory: 5986  grad_norm: 914.2168  loss: 31.1618  decode.loss_cls: 0.5587  decode.loss_mask: 1.4252  decode.loss_dice: 1.0438  decode.d0.loss_cls: 0.9082  decode.d0.loss_mask: 1.3912  decode.d0.loss_dice: 1.0620  decode.d1.loss_cls: 0.5379  decode.d1.loss_mask: 1.4705  decode.d1.loss_dice: 1.0891  decode.d2.loss_cls: 0.5850  decode.d2.loss_mask: 1.4343  decode.d2.loss_dice: 1.0135  decode.d3.loss_cls: 0.6098  decode.d3.loss_mask: 1.5022  decode.d3.loss_dice: 1.0572  decode.d4.loss_cls: 0.5338  decode.d4.loss_mask: 1.4408  decode.d4.loss_dice: 1.0487  decode.d5.loss_cls: 0.5596  decode.d5.loss_mask: 1.4857  decode.d5.loss_dice: 1.0948  decode.d6.loss_cls: 0.6153  decode.d6.loss_mask: 1.4418  decode.d6.loss_dice: 1.0518  decode.d7.loss_cls: 0.4913  decode.d7.loss_mask: 1.5566  decode.d7.loss_dice: 1.0662  decode.d8.loss_cls: 0.5518  decode.d8.loss_mask: 1.4785  decode.d8.loss_dice: 1.0564
05/26 12:12:19 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 12:12:19 - mmengine - INFO - Iter(train) [ 11000/160000]  base_lr: 9.3791e-05 lr: 9.3791e-06  eta: 17:02:35  time: 0.4183  data_time: 0.0096  memory: 5967  grad_norm: 1154.5644  loss: 29.3785  decode.loss_cls: 0.5860  decode.loss_mask: 1.2992  decode.loss_dice: 0.9892  decode.d0.loss_cls: 0.8790  decode.d0.loss_mask: 1.3016  decode.d0.loss_dice: 1.0404  decode.d1.loss_cls: 0.5358  decode.d1.loss_mask: 1.3115  decode.d1.loss_dice: 0.9660  decode.d2.loss_cls: 0.5863  decode.d2.loss_mask: 1.3322  decode.d2.loss_dice: 1.0014  decode.d3.loss_cls: 0.5933  decode.d3.loss_mask: 1.2944  decode.d3.loss_dice: 0.9971  decode.d4.loss_cls: 0.5905  decode.d4.loss_mask: 1.3685  decode.d4.loss_dice: 1.0139  decode.d5.loss_cls: 0.6400  decode.d5.loss_mask: 1.3313  decode.d5.loss_dice: 0.9878  decode.d6.loss_cls: 0.6134  decode.d6.loss_mask: 1.3468  decode.d6.loss_dice: 0.9767  decode.d7.loss_cls: 0.6019  decode.d7.loss_mask: 1.3225  decode.d7.loss_dice: 0.9926  decode.d8.loss_cls: 0.5745  decode.d8.loss_mask: 1.3215  decode.d8.loss_dice: 0.9834
05/26 12:12:39 - mmengine - INFO - Iter(train) [ 11050/160000]  base_lr: 9.3763e-05 lr: 9.3763e-06  eta: 17:02:11  time: 0.4074  data_time: 0.0086  memory: 5968  grad_norm: 1572.5255  loss: 27.1136  decode.loss_cls: 0.5128  decode.loss_mask: 1.1538  decode.loss_dice: 0.9568  decode.d0.loss_cls: 0.8636  decode.d0.loss_mask: 1.2974  decode.d0.loss_dice: 1.0361  decode.d1.loss_cls: 0.5024  decode.d1.loss_mask: 1.2274  decode.d1.loss_dice: 0.9311  decode.d2.loss_cls: 0.4875  decode.d2.loss_mask: 1.2311  decode.d2.loss_dice: 0.9636  decode.d3.loss_cls: 0.4686  decode.d3.loss_mask: 1.2277  decode.d3.loss_dice: 0.9407  decode.d4.loss_cls: 0.4729  decode.d4.loss_mask: 1.2518  decode.d4.loss_dice: 0.9947  decode.d5.loss_cls: 0.5203  decode.d5.loss_mask: 1.2058  decode.d5.loss_dice: 0.9548  decode.d6.loss_cls: 0.4936  decode.d6.loss_mask: 1.2208  decode.d6.loss_dice: 0.9658  decode.d7.loss_cls: 0.4733  decode.d7.loss_mask: 1.1669  decode.d7.loss_dice: 1.0051  decode.d8.loss_cls: 0.4457  decode.d8.loss_mask: 1.1648  decode.d8.loss_dice: 0.9768
05/26 12:13:00 - mmengine - INFO - Iter(train) [ 11100/160000]  base_lr: 9.3735e-05 lr: 9.3735e-06  eta: 17:01:47  time: 0.4087  data_time: 0.0106  memory: 5973  grad_norm: 486.1819  loss: 29.8372  decode.loss_cls: 0.4740  decode.loss_mask: 1.3660  decode.loss_dice: 1.0914  decode.d0.loss_cls: 0.8655  decode.d0.loss_mask: 1.2849  decode.d0.loss_dice: 1.0501  decode.d1.loss_cls: 0.4989  decode.d1.loss_mask: 1.3539  decode.d1.loss_dice: 1.0913  decode.d2.loss_cls: 0.5041  decode.d2.loss_mask: 1.3424  decode.d2.loss_dice: 1.0669  decode.d3.loss_cls: 0.4729  decode.d3.loss_mask: 1.3948  decode.d3.loss_dice: 1.1120  decode.d4.loss_cls: 0.5184  decode.d4.loss_mask: 1.4059  decode.d4.loss_dice: 1.1216  decode.d5.loss_cls: 0.5866  decode.d5.loss_mask: 1.3012  decode.d5.loss_dice: 1.0604  decode.d6.loss_cls: 0.4929  decode.d6.loss_mask: 1.3415  decode.d6.loss_dice: 1.0955  decode.d7.loss_cls: 0.4465  decode.d7.loss_mask: 1.4085  decode.d7.loss_dice: 1.1160  decode.d8.loss_cls: 0.5122  decode.d8.loss_mask: 1.3776  decode.d8.loss_dice: 1.0835
05/26 12:13:20 - mmengine - INFO - Iter(train) [ 11150/160000]  base_lr: 9.3706e-05 lr: 9.3706e-06  eta: 17:01:23  time: 0.4070  data_time: 0.0085  memory: 5967  grad_norm: 888.1818  loss: 30.8104  decode.loss_cls: 0.5087  decode.loss_mask: 1.4715  decode.loss_dice: 1.0190  decode.d0.loss_cls: 0.8954  decode.d0.loss_mask: 1.4298  decode.d0.loss_dice: 1.0749  decode.d1.loss_cls: 0.5949  decode.d1.loss_mask: 1.4988  decode.d1.loss_dice: 1.0637  decode.d2.loss_cls: 0.5391  decode.d2.loss_mask: 1.4458  decode.d2.loss_dice: 1.0335  decode.d3.loss_cls: 0.5792  decode.d3.loss_mask: 1.3776  decode.d3.loss_dice: 0.9853  decode.d4.loss_cls: 0.5828  decode.d4.loss_mask: 1.4395  decode.d4.loss_dice: 1.0192  decode.d5.loss_cls: 0.5554  decode.d5.loss_mask: 1.4518  decode.d5.loss_dice: 1.0154  decode.d6.loss_cls: 0.6064  decode.d6.loss_mask: 1.4924  decode.d6.loss_dice: 1.0494  decode.d7.loss_cls: 0.5327  decode.d7.loss_mask: 1.4607  decode.d7.loss_dice: 1.0615  decode.d8.loss_cls: 0.5172  decode.d8.loss_mask: 1.4611  decode.d8.loss_dice: 1.0475
05/26 12:13:40 - mmengine - INFO - Iter(train) [ 11200/160000]  base_lr: 9.3678e-05 lr: 9.3678e-06  eta: 17:00:59  time: 0.4058  data_time: 0.0088  memory: 5974  grad_norm: 912.6008  loss: 33.1242  decode.loss_cls: 0.6955  decode.loss_mask: 1.4350  decode.loss_dice: 1.1130  decode.d0.loss_cls: 1.0247  decode.d0.loss_mask: 1.3709  decode.d0.loss_dice: 1.1324  decode.d1.loss_cls: 0.7465  decode.d1.loss_mask: 1.4462  decode.d1.loss_dice: 1.0913  decode.d2.loss_cls: 0.6922  decode.d2.loss_mask: 1.4706  decode.d2.loss_dice: 1.1059  decode.d3.loss_cls: 0.6675  decode.d3.loss_mask: 1.3779  decode.d3.loss_dice: 1.0499  decode.d4.loss_cls: 0.7748  decode.d4.loss_mask: 1.3685  decode.d4.loss_dice: 1.0854  decode.d5.loss_cls: 0.7833  decode.d5.loss_mask: 1.4313  decode.d5.loss_dice: 1.1109  decode.d6.loss_cls: 0.7824  decode.d6.loss_mask: 1.4454  decode.d6.loss_dice: 1.1429  decode.d7.loss_cls: 0.7723  decode.d7.loss_mask: 1.4282  decode.d7.loss_dice: 1.1454  decode.d8.loss_cls: 0.7010  decode.d8.loss_mask: 1.5364  decode.d8.loss_dice: 1.1968
05/26 12:14:01 - mmengine - INFO - Iter(train) [ 11250/160000]  base_lr: 9.3650e-05 lr: 9.3650e-06  eta: 17:00:35  time: 0.4059  data_time: 0.0086  memory: 5989  grad_norm: 676.7685  loss: 28.3647  decode.loss_cls: 0.6006  decode.loss_mask: 1.2267  decode.loss_dice: 1.0325  decode.d0.loss_cls: 1.0206  decode.d0.loss_mask: 1.0613  decode.d0.loss_dice: 0.9925  decode.d1.loss_cls: 0.5631  decode.d1.loss_mask: 1.1497  decode.d1.loss_dice: 0.9965  decode.d2.loss_cls: 0.6009  decode.d2.loss_mask: 1.2085  decode.d2.loss_dice: 0.9703  decode.d3.loss_cls: 0.6119  decode.d3.loss_mask: 1.2448  decode.d3.loss_dice: 0.9851  decode.d4.loss_cls: 0.5813  decode.d4.loss_mask: 1.2036  decode.d4.loss_dice: 0.9776  decode.d5.loss_cls: 0.5915  decode.d5.loss_mask: 1.1850  decode.d5.loss_dice: 0.9911  decode.d6.loss_cls: 0.5901  decode.d6.loss_mask: 1.2332  decode.d6.loss_dice: 0.9877  decode.d7.loss_cls: 0.5486  decode.d7.loss_mask: 1.3095  decode.d7.loss_dice: 0.9943  decode.d8.loss_cls: 0.5451  decode.d8.loss_mask: 1.3187  decode.d8.loss_dice: 1.0425
05/26 12:14:21 - mmengine - INFO - Iter(train) [ 11300/160000]  base_lr: 9.3621e-05 lr: 9.3621e-06  eta: 17:00:12  time: 0.4060  data_time: 0.0086  memory: 5976  grad_norm: 558.6470  loss: 26.0222  decode.loss_cls: 0.4074  decode.loss_mask: 1.2325  decode.loss_dice: 0.9374  decode.d0.loss_cls: 0.8850  decode.d0.loss_mask: 1.2893  decode.d0.loss_dice: 0.9434  decode.d1.loss_cls: 0.4544  decode.d1.loss_mask: 1.2393  decode.d1.loss_dice: 0.9231  decode.d2.loss_cls: 0.4064  decode.d2.loss_mask: 1.1958  decode.d2.loss_dice: 0.8943  decode.d3.loss_cls: 0.4152  decode.d3.loss_mask: 1.1624  decode.d3.loss_dice: 0.8652  decode.d4.loss_cls: 0.4572  decode.d4.loss_mask: 1.2045  decode.d4.loss_dice: 0.8745  decode.d5.loss_cls: 0.4005  decode.d5.loss_mask: 1.2209  decode.d5.loss_dice: 0.8802  decode.d6.loss_cls: 0.4338  decode.d6.loss_mask: 1.1698  decode.d6.loss_dice: 0.8676  decode.d7.loss_cls: 0.4136  decode.d7.loss_mask: 1.2198  decode.d7.loss_dice: 0.9103  decode.d8.loss_cls: 0.3503  decode.d8.loss_mask: 1.3389  decode.d8.loss_dice: 1.0290
05/26 12:14:41 - mmengine - INFO - Iter(train) [ 11350/160000]  base_lr: 9.3593e-05 lr: 9.3593e-06  eta: 16:59:48  time: 0.4053  data_time: 0.0084  memory: 5976  grad_norm: 842.4942  loss: 28.8656  decode.loss_cls: 0.3786  decode.loss_mask: 1.4139  decode.loss_dice: 1.0271  decode.d0.loss_cls: 0.8156  decode.d0.loss_mask: 1.3357  decode.d0.loss_dice: 0.9919  decode.d1.loss_cls: 0.4590  decode.d1.loss_mask: 1.3851  decode.d1.loss_dice: 1.0293  decode.d2.loss_cls: 0.3468  decode.d2.loss_mask: 1.4071  decode.d2.loss_dice: 1.0276  decode.d3.loss_cls: 0.4094  decode.d3.loss_mask: 1.3763  decode.d3.loss_dice: 1.0286  decode.d4.loss_cls: 0.4165  decode.d4.loss_mask: 1.4720  decode.d4.loss_dice: 1.0861  decode.d5.loss_cls: 0.4288  decode.d5.loss_mask: 1.4224  decode.d5.loss_dice: 1.0243  decode.d6.loss_cls: 0.4462  decode.d6.loss_mask: 1.4409  decode.d6.loss_dice: 1.0548  decode.d7.loss_cls: 0.4118  decode.d7.loss_mask: 1.3856  decode.d7.loss_dice: 1.0194  decode.d8.loss_cls: 0.3645  decode.d8.loss_mask: 1.4327  decode.d8.loss_dice: 1.0275
05/26 12:15:02 - mmengine - INFO - Iter(train) [ 11400/160000]  base_lr: 9.3565e-05 lr: 9.3565e-06  eta: 16:59:24  time: 0.4064  data_time: 0.0085  memory: 5969  grad_norm: 775.5948  loss: 30.8371  decode.loss_cls: 0.4652  decode.loss_mask: 1.5002  decode.loss_dice: 1.0343  decode.d0.loss_cls: 0.8845  decode.d0.loss_mask: 1.4621  decode.d0.loss_dice: 1.0770  decode.d1.loss_cls: 0.4020  decode.d1.loss_mask: 1.5390  decode.d1.loss_dice: 1.0791  decode.d2.loss_cls: 0.4517  decode.d2.loss_mask: 1.5121  decode.d2.loss_dice: 1.0520  decode.d3.loss_cls: 0.4265  decode.d3.loss_mask: 1.5160  decode.d3.loss_dice: 1.0394  decode.d4.loss_cls: 0.5006  decode.d4.loss_mask: 1.5711  decode.d4.loss_dice: 1.0560  decode.d5.loss_cls: 0.4718  decode.d5.loss_mask: 1.5144  decode.d5.loss_dice: 1.0907  decode.d6.loss_cls: 0.4508  decode.d6.loss_mask: 1.5112  decode.d6.loss_dice: 1.0975  decode.d7.loss_cls: 0.4313  decode.d7.loss_mask: 1.5801  decode.d7.loss_dice: 1.0872  decode.d8.loss_cls: 0.4456  decode.d8.loss_mask: 1.5041  decode.d8.loss_dice: 1.0835
05/26 12:15:22 - mmengine - INFO - Iter(train) [ 11450/160000]  base_lr: 9.3536e-05 lr: 9.3536e-06  eta: 16:59:01  time: 0.4068  data_time: 0.0086  memory: 5980  grad_norm: 648.9266  loss: 31.6519  decode.loss_cls: 0.6049  decode.loss_mask: 1.3276  decode.loss_dice: 1.1325  decode.d0.loss_cls: 1.0244  decode.d0.loss_mask: 1.2250  decode.d0.loss_dice: 1.0732  decode.d1.loss_cls: 0.6185  decode.d1.loss_mask: 1.2997  decode.d1.loss_dice: 1.1564  decode.d2.loss_cls: 0.7583  decode.d2.loss_mask: 1.2470  decode.d2.loss_dice: 1.0996  decode.d3.loss_cls: 0.7510  decode.d3.loss_mask: 1.3643  decode.d3.loss_dice: 1.1377  decode.d4.loss_cls: 0.7531  decode.d4.loss_mask: 1.2901  decode.d4.loss_dice: 1.1506  decode.d5.loss_cls: 0.6414  decode.d5.loss_mask: 1.3597  decode.d5.loss_dice: 1.1985  decode.d6.loss_cls: 0.6592  decode.d6.loss_mask: 1.3011  decode.d6.loss_dice: 1.1970  decode.d7.loss_cls: 0.6149  decode.d7.loss_mask: 1.3402  decode.d7.loss_dice: 1.1723  decode.d8.loss_cls: 0.5575  decode.d8.loss_mask: 1.3950  decode.d8.loss_dice: 1.2011
05/26 12:15:42 - mmengine - INFO - Iter(train) [ 11500/160000]  base_lr: 9.3508e-05 lr: 9.3508e-06  eta: 16:58:37  time: 0.4064  data_time: 0.0086  memory: 5979  grad_norm: 655.9225  loss: 30.3710  decode.loss_cls: 0.3747  decode.loss_mask: 1.5146  decode.loss_dice: 1.0550  decode.d0.loss_cls: 0.7625  decode.d0.loss_mask: 1.4791  decode.d0.loss_dice: 1.0567  decode.d1.loss_cls: 0.4506  decode.d1.loss_mask: 1.4742  decode.d1.loss_dice: 1.0682  decode.d2.loss_cls: 0.4148  decode.d2.loss_mask: 1.5085  decode.d2.loss_dice: 1.0687  decode.d3.loss_cls: 0.3882  decode.d3.loss_mask: 1.5186  decode.d3.loss_dice: 1.0585  decode.d4.loss_cls: 0.4499  decode.d4.loss_mask: 1.5395  decode.d4.loss_dice: 1.0357  decode.d5.loss_cls: 0.4685  decode.d5.loss_mask: 1.5515  decode.d5.loss_dice: 1.0663  decode.d6.loss_cls: 0.4000  decode.d6.loss_mask: 1.5492  decode.d6.loss_dice: 1.1082  decode.d7.loss_cls: 0.4228  decode.d7.loss_mask: 1.5429  decode.d7.loss_dice: 1.0697  decode.d8.loss_cls: 0.3815  decode.d8.loss_mask: 1.5185  decode.d8.loss_dice: 1.0740
05/26 12:16:03 - mmengine - INFO - Iter(train) [ 11550/160000]  base_lr: 9.3480e-05 lr: 9.3480e-06  eta: 16:58:14  time: 0.4079  data_time: 0.0085  memory: 5970  grad_norm: 641.5414  loss: 26.5919  decode.loss_cls: 0.4316  decode.loss_mask: 1.2354  decode.loss_dice: 0.8590  decode.d0.loss_cls: 0.9169  decode.d0.loss_mask: 1.2271  decode.d0.loss_dice: 0.8573  decode.d1.loss_cls: 0.5100  decode.d1.loss_mask: 1.2549  decode.d1.loss_dice: 0.8921  decode.d2.loss_cls: 0.4978  decode.d2.loss_mask: 1.2570  decode.d2.loss_dice: 0.8695  decode.d3.loss_cls: 0.5223  decode.d3.loss_mask: 1.1900  decode.d3.loss_dice: 0.8728  decode.d4.loss_cls: 0.5872  decode.d4.loss_mask: 1.2094  decode.d4.loss_dice: 0.8558  decode.d5.loss_cls: 0.4800  decode.d5.loss_mask: 1.2920  decode.d5.loss_dice: 0.9219  decode.d6.loss_cls: 0.5257  decode.d6.loss_mask: 1.2344  decode.d6.loss_dice: 0.8765  decode.d7.loss_cls: 0.4727  decode.d7.loss_mask: 1.2740  decode.d7.loss_dice: 0.8644  decode.d8.loss_cls: 0.4330  decode.d8.loss_mask: 1.2788  decode.d8.loss_dice: 0.8924
05/26 12:16:23 - mmengine - INFO - Iter(train) [ 11600/160000]  base_lr: 9.3451e-05 lr: 9.3451e-06  eta: 16:57:50  time: 0.4077  data_time: 0.0085  memory: 5983  grad_norm: 841.2131  loss: 32.9478  decode.loss_cls: 0.5952  decode.loss_mask: 1.5765  decode.loss_dice: 1.0381  decode.d0.loss_cls: 0.9448  decode.d0.loss_mask: 1.4924  decode.d0.loss_dice: 1.0614  decode.d1.loss_cls: 0.6570  decode.d1.loss_mask: 1.5329  decode.d1.loss_dice: 1.0498  decode.d2.loss_cls: 0.6421  decode.d2.loss_mask: 1.5937  decode.d2.loss_dice: 1.0461  decode.d3.loss_cls: 0.6190  decode.d3.loss_mask: 1.5415  decode.d3.loss_dice: 1.0463  decode.d4.loss_cls: 0.6880  decode.d4.loss_mask: 1.5706  decode.d4.loss_dice: 1.0679  decode.d5.loss_cls: 0.6044  decode.d5.loss_mask: 1.5948  decode.d5.loss_dice: 1.1151  decode.d6.loss_cls: 0.6451  decode.d6.loss_mask: 1.5773  decode.d6.loss_dice: 1.0738  decode.d7.loss_cls: 0.5675  decode.d7.loss_mask: 1.6726  decode.d7.loss_dice: 1.1255  decode.d8.loss_cls: 0.5759  decode.d8.loss_mask: 1.5446  decode.d8.loss_dice: 1.0878
05/26 12:16:43 - mmengine - INFO - Iter(train) [ 11650/160000]  base_lr: 9.3423e-05 lr: 9.3423e-06  eta: 16:57:28  time: 0.4105  data_time: 0.0090  memory: 5984  grad_norm: 661.9695  loss: 25.7366  decode.loss_cls: 0.4732  decode.loss_mask: 1.1265  decode.loss_dice: 0.8803  decode.d0.loss_cls: 0.9061  decode.d0.loss_mask: 1.1719  decode.d0.loss_dice: 0.8979  decode.d1.loss_cls: 0.5001  decode.d1.loss_mask: 1.1461  decode.d1.loss_dice: 0.8842  decode.d2.loss_cls: 0.5253  decode.d2.loss_mask: 1.1914  decode.d2.loss_dice: 0.8964  decode.d3.loss_cls: 0.4891  decode.d3.loss_mask: 1.1924  decode.d3.loss_dice: 0.9106  decode.d4.loss_cls: 0.5082  decode.d4.loss_mask: 1.1353  decode.d4.loss_dice: 0.8665  decode.d5.loss_cls: 0.5069  decode.d5.loss_mask: 1.1561  decode.d5.loss_dice: 0.8543  decode.d6.loss_cls: 0.5116  decode.d6.loss_mask: 1.1366  decode.d6.loss_dice: 0.8643  decode.d7.loss_cls: 0.4605  decode.d7.loss_mask: 1.1646  decode.d7.loss_dice: 0.8776  decode.d8.loss_cls: 0.4780  decode.d8.loss_mask: 1.1538  decode.d8.loss_dice: 0.8708
05/26 12:17:04 - mmengine - INFO - Iter(train) [ 11700/160000]  base_lr: 9.3395e-05 lr: 9.3395e-06  eta: 16:57:05  time: 0.4094  data_time: 0.0086  memory: 5980  grad_norm: 657.3222  loss: 25.9421  decode.loss_cls: 0.4144  decode.loss_mask: 1.2474  decode.loss_dice: 0.8344  decode.d0.loss_cls: 0.9356  decode.d0.loss_mask: 1.1701  decode.d0.loss_dice: 0.8046  decode.d1.loss_cls: 0.4917  decode.d1.loss_mask: 1.2666  decode.d1.loss_dice: 0.8104  decode.d2.loss_cls: 0.4473  decode.d2.loss_mask: 1.2322  decode.d2.loss_dice: 0.8340  decode.d3.loss_cls: 0.4593  decode.d3.loss_mask: 1.2468  decode.d3.loss_dice: 0.8132  decode.d4.loss_cls: 0.5427  decode.d4.loss_mask: 1.2327  decode.d4.loss_dice: 0.7945  decode.d5.loss_cls: 0.4476  decode.d5.loss_mask: 1.2839  decode.d5.loss_dice: 0.8356  decode.d6.loss_cls: 0.4697  decode.d6.loss_mask: 1.3467  decode.d6.loss_dice: 0.8426  decode.d7.loss_cls: 0.4801  decode.d7.loss_mask: 1.2485  decode.d7.loss_dice: 0.8451  decode.d8.loss_cls: 0.4684  decode.d8.loss_mask: 1.2355  decode.d8.loss_dice: 0.8604
05/26 12:17:24 - mmengine - INFO - Iter(train) [ 11750/160000]  base_lr: 9.3366e-05 lr: 9.3366e-06  eta: 16:56:42  time: 0.4093  data_time: 0.0088  memory: 5972  grad_norm: 1041.5110  loss: 29.0696  decode.loss_cls: 0.4509  decode.loss_mask: 1.4347  decode.loss_dice: 0.9812  decode.d0.loss_cls: 0.8383  decode.d0.loss_mask: 1.3694  decode.d0.loss_dice: 0.9506  decode.d1.loss_cls: 0.4915  decode.d1.loss_mask: 1.4206  decode.d1.loss_dice: 0.9732  decode.d2.loss_cls: 0.6059  decode.d2.loss_mask: 1.3089  decode.d2.loss_dice: 0.8936  decode.d3.loss_cls: 0.5181  decode.d3.loss_mask: 1.3331  decode.d3.loss_dice: 0.9437  decode.d4.loss_cls: 0.5892  decode.d4.loss_mask: 1.3761  decode.d4.loss_dice: 0.9219  decode.d5.loss_cls: 0.6271  decode.d5.loss_mask: 1.3743  decode.d5.loss_dice: 0.9808  decode.d6.loss_cls: 0.5941  decode.d6.loss_mask: 1.4436  decode.d6.loss_dice: 0.9539  decode.d7.loss_cls: 0.4794  decode.d7.loss_mask: 1.4339  decode.d7.loss_dice: 0.9770  decode.d8.loss_cls: 0.4703  decode.d8.loss_mask: 1.3665  decode.d8.loss_dice: 0.9677
05/26 12:17:45 - mmengine - INFO - Iter(train) [ 11800/160000]  base_lr: 9.3338e-05 lr: 9.3338e-06  eta: 16:56:19  time: 0.4094  data_time: 0.0086  memory: 5974  grad_norm: 767.6833  loss: 29.6871  decode.loss_cls: 0.4305  decode.loss_mask: 1.3096  decode.loss_dice: 1.0915  decode.d0.loss_cls: 0.9144  decode.d0.loss_mask: 1.2637  decode.d0.loss_dice: 1.0634  decode.d1.loss_cls: 0.5127  decode.d1.loss_mask: 1.3391  decode.d1.loss_dice: 1.1204  decode.d2.loss_cls: 0.5556  decode.d2.loss_mask: 1.3097  decode.d2.loss_dice: 1.1060  decode.d3.loss_cls: 0.4877  decode.d3.loss_mask: 1.3333  decode.d3.loss_dice: 1.1167  decode.d4.loss_cls: 0.5529  decode.d4.loss_mask: 1.2999  decode.d4.loss_dice: 1.1163  decode.d5.loss_cls: 0.4941  decode.d5.loss_mask: 1.2876  decode.d5.loss_dice: 1.1353  decode.d6.loss_cls: 0.5484  decode.d6.loss_mask: 1.2979  decode.d6.loss_dice: 1.1241  decode.d7.loss_cls: 0.5120  decode.d7.loss_mask: 1.2867  decode.d7.loss_dice: 1.1045  decode.d8.loss_cls: 0.5176  decode.d8.loss_mask: 1.3390  decode.d8.loss_dice: 1.1167
05/26 12:18:05 - mmengine - INFO - Iter(train) [ 11850/160000]  base_lr: 9.3310e-05 lr: 9.3310e-06  eta: 16:55:57  time: 0.4093  data_time: 0.0087  memory: 5981  grad_norm: 652.7692  loss: 27.4785  decode.loss_cls: 0.3906  decode.loss_mask: 1.3062  decode.loss_dice: 1.0004  decode.d0.loss_cls: 0.8567  decode.d0.loss_mask: 1.2028  decode.d0.loss_dice: 0.9639  decode.d1.loss_cls: 0.5003  decode.d1.loss_mask: 1.2903  decode.d1.loss_dice: 0.9536  decode.d2.loss_cls: 0.5195  decode.d2.loss_mask: 1.2610  decode.d2.loss_dice: 0.9822  decode.d3.loss_cls: 0.4758  decode.d3.loss_mask: 1.2714  decode.d3.loss_dice: 0.9676  decode.d4.loss_cls: 0.4788  decode.d4.loss_mask: 1.2420  decode.d4.loss_dice: 0.9512  decode.d5.loss_cls: 0.5023  decode.d5.loss_mask: 1.2779  decode.d5.loss_dice: 0.9901  decode.d6.loss_cls: 0.5036  decode.d6.loss_mask: 1.2597  decode.d6.loss_dice: 0.9734  decode.d7.loss_cls: 0.4571  decode.d7.loss_mask: 1.2821  decode.d7.loss_dice: 0.9826  decode.d8.loss_cls: 0.3908  decode.d8.loss_mask: 1.2879  decode.d8.loss_dice: 0.9568
05/26 12:18:25 - mmengine - INFO - Iter(train) [ 11900/160000]  base_lr: 9.3281e-05 lr: 9.3281e-06  eta: 16:55:34  time: 0.4079  data_time: 0.0087  memory: 5969  grad_norm: 1095.2569  loss: 32.2030  decode.loss_cls: 0.5577  decode.loss_mask: 1.4357  decode.loss_dice: 1.0908  decode.d0.loss_cls: 1.1084  decode.d0.loss_mask: 1.3147  decode.d0.loss_dice: 1.0383  decode.d1.loss_cls: 0.5881  decode.d1.loss_mask: 1.4599  decode.d1.loss_dice: 1.0899  decode.d2.loss_cls: 0.6198  decode.d2.loss_mask: 1.4296  decode.d2.loss_dice: 1.1282  decode.d3.loss_cls: 0.6247  decode.d3.loss_mask: 1.4829  decode.d3.loss_dice: 1.0781  decode.d4.loss_cls: 0.6877  decode.d4.loss_mask: 1.4745  decode.d4.loss_dice: 1.1678  decode.d5.loss_cls: 0.6545  decode.d5.loss_mask: 1.4610  decode.d5.loss_dice: 1.0706  decode.d6.loss_cls: 0.6476  decode.d6.loss_mask: 1.5384  decode.d6.loss_dice: 1.1662  decode.d7.loss_cls: 0.6573  decode.d7.loss_mask: 1.4212  decode.d7.loss_dice: 1.0874  decode.d8.loss_cls: 0.5425  decode.d8.loss_mask: 1.4662  decode.d8.loss_dice: 1.1132
05/26 12:18:46 - mmengine - INFO - Iter(train) [ 11950/160000]  base_lr: 9.3253e-05 lr: 9.3253e-06  eta: 16:55:11  time: 0.4088  data_time: 0.0086  memory: 5973  grad_norm: 484.5358  loss: 27.5607  decode.loss_cls: 0.4899  decode.loss_mask: 1.2938  decode.loss_dice: 0.8596  decode.d0.loss_cls: 0.8705  decode.d0.loss_mask: 1.2753  decode.d0.loss_dice: 0.8804  decode.d1.loss_cls: 0.5636  decode.d1.loss_mask: 1.3163  decode.d1.loss_dice: 0.8457  decode.d2.loss_cls: 0.5177  decode.d2.loss_mask: 1.3241  decode.d2.loss_dice: 0.8711  decode.d3.loss_cls: 0.5411  decode.d3.loss_mask: 1.2985  decode.d3.loss_dice: 0.8532  decode.d4.loss_cls: 0.5598  decode.d4.loss_mask: 1.3035  decode.d4.loss_dice: 0.8581  decode.d5.loss_cls: 0.5926  decode.d5.loss_mask: 1.3149  decode.d5.loss_dice: 0.8874  decode.d6.loss_cls: 0.5797  decode.d6.loss_mask: 1.2745  decode.d6.loss_dice: 0.8627  decode.d7.loss_cls: 0.5703  decode.d7.loss_mask: 1.3427  decode.d7.loss_dice: 0.8786  decode.d8.loss_cls: 0.4871  decode.d8.loss_mask: 1.3407  decode.d8.loss_dice: 0.9071
05/26 12:19:06 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 12:19:06 - mmengine - INFO - Iter(train) [ 12000/160000]  base_lr: 9.3224e-05 lr: 9.3224e-06  eta: 16:54:48  time: 0.4071  data_time: 0.0087  memory: 5967  grad_norm: 713.6624  loss: 29.6826  decode.loss_cls: 0.5439  decode.loss_mask: 1.3260  decode.loss_dice: 1.0151  decode.d0.loss_cls: 0.9704  decode.d0.loss_mask: 1.3327  decode.d0.loss_dice: 0.9555  decode.d1.loss_cls: 0.5323  decode.d1.loss_mask: 1.3697  decode.d1.loss_dice: 0.9996  decode.d2.loss_cls: 0.5968  decode.d2.loss_mask: 1.3137  decode.d2.loss_dice: 0.9562  decode.d3.loss_cls: 0.5961  decode.d3.loss_mask: 1.3394  decode.d3.loss_dice: 0.9668  decode.d4.loss_cls: 0.5834  decode.d4.loss_mask: 1.3420  decode.d4.loss_dice: 1.0161  decode.d5.loss_cls: 0.5897  decode.d5.loss_mask: 1.3517  decode.d5.loss_dice: 1.0030  decode.d6.loss_cls: 0.6307  decode.d6.loss_mask: 1.3717  decode.d6.loss_dice: 1.0216  decode.d7.loss_cls: 0.5971  decode.d7.loss_mask: 1.3960  decode.d7.loss_dice: 1.0717  decode.d8.loss_cls: 0.5079  decode.d8.loss_mask: 1.3856  decode.d8.loss_dice: 1.0001
05/26 12:19:27 - mmengine - INFO - Iter(train) [ 12050/160000]  base_lr: 9.3196e-05 lr: 9.3196e-06  eta: 16:54:27  time: 0.4175  data_time: 0.0086  memory: 5984  grad_norm: 993.5521  loss: 34.0340  decode.loss_cls: 0.5415  decode.loss_mask: 1.7199  decode.loss_dice: 1.1487  decode.d0.loss_cls: 0.9943  decode.d0.loss_mask: 1.5657  decode.d0.loss_dice: 1.1407  decode.d1.loss_cls: 0.4899  decode.d1.loss_mask: 1.6759  decode.d1.loss_dice: 1.2122  decode.d2.loss_cls: 0.4877  decode.d2.loss_mask: 1.5962  decode.d2.loss_dice: 1.1653  decode.d3.loss_cls: 0.5159  decode.d3.loss_mask: 1.7135  decode.d3.loss_dice: 1.1900  decode.d4.loss_cls: 0.5469  decode.d4.loss_mask: 1.6658  decode.d4.loss_dice: 1.1804  decode.d5.loss_cls: 0.5845  decode.d5.loss_mask: 1.5961  decode.d5.loss_dice: 1.1799  decode.d6.loss_cls: 0.5167  decode.d6.loss_mask: 1.6231  decode.d6.loss_dice: 1.1735  decode.d7.loss_cls: 0.5519  decode.d7.loss_mask: 1.6583  decode.d7.loss_dice: 1.1864  decode.d8.loss_cls: 0.5687  decode.d8.loss_mask: 1.6642  decode.d8.loss_dice: 1.1802
05/26 12:19:47 - mmengine - INFO - Iter(train) [ 12100/160000]  base_lr: 9.3168e-05 lr: 9.3168e-06  eta: 16:54:04  time: 0.4087  data_time: 0.0086  memory: 5970  grad_norm: 716.8255  loss: 32.4411  decode.loss_cls: 0.6247  decode.loss_mask: 1.5488  decode.loss_dice: 1.0783  decode.d0.loss_cls: 1.0185  decode.d0.loss_mask: 1.4458  decode.d0.loss_dice: 1.1000  decode.d1.loss_cls: 0.6515  decode.d1.loss_mask: 1.4930  decode.d1.loss_dice: 1.0953  decode.d2.loss_cls: 0.6301  decode.d2.loss_mask: 1.4652  decode.d2.loss_dice: 1.0499  decode.d3.loss_cls: 0.5817  decode.d3.loss_mask: 1.5188  decode.d3.loss_dice: 1.0675  decode.d4.loss_cls: 0.6747  decode.d4.loss_mask: 1.4731  decode.d4.loss_dice: 1.0687  decode.d5.loss_cls: 0.6893  decode.d5.loss_mask: 1.4787  decode.d5.loss_dice: 1.0583  decode.d6.loss_cls: 0.6738  decode.d6.loss_mask: 1.5153  decode.d6.loss_dice: 1.0572  decode.d7.loss_cls: 0.6119  decode.d7.loss_mask: 1.5270  decode.d7.loss_dice: 1.0944  decode.d8.loss_cls: 0.6690  decode.d8.loss_mask: 1.4552  decode.d8.loss_dice: 1.0253
05/26 12:20:07 - mmengine - INFO - Iter(train) [ 12150/160000]  base_lr: 9.3139e-05 lr: 9.3139e-06  eta: 16:53:41  time: 0.4086  data_time: 0.0088  memory: 5976  grad_norm: 848.2025  loss: 32.5309  decode.loss_cls: 0.3696  decode.loss_mask: 1.6545  decode.loss_dice: 1.1397  decode.d0.loss_cls: 0.9462  decode.d0.loss_mask: 1.5012  decode.d0.loss_dice: 1.1089  decode.d1.loss_cls: 0.3667  decode.d1.loss_mask: 1.6180  decode.d1.loss_dice: 1.1713  decode.d2.loss_cls: 0.4135  decode.d2.loss_mask: 1.6571  decode.d2.loss_dice: 1.1529  decode.d3.loss_cls: 0.3974  decode.d3.loss_mask: 1.6225  decode.d3.loss_dice: 1.1347  decode.d4.loss_cls: 0.4390  decode.d4.loss_mask: 1.6374  decode.d4.loss_dice: 1.1489  decode.d5.loss_cls: 0.4613  decode.d5.loss_mask: 1.6353  decode.d5.loss_dice: 1.1528  decode.d6.loss_cls: 0.4775  decode.d6.loss_mask: 1.6702  decode.d6.loss_dice: 1.1749  decode.d7.loss_cls: 0.4159  decode.d7.loss_mask: 1.6511  decode.d7.loss_dice: 1.1649  decode.d8.loss_cls: 0.3593  decode.d8.loss_mask: 1.7024  decode.d8.loss_dice: 1.1859
05/26 12:20:28 - mmengine - INFO - Iter(train) [ 12200/160000]  base_lr: 9.3111e-05 lr: 9.3111e-06  eta: 16:53:19  time: 0.4086  data_time: 0.0087  memory: 5971  grad_norm: 1179.4058  loss: 33.4513  decode.loss_cls: 0.6133  decode.loss_mask: 1.6371  decode.loss_dice: 1.1017  decode.d0.loss_cls: 1.0832  decode.d0.loss_mask: 1.4477  decode.d0.loss_dice: 1.0964  decode.d1.loss_cls: 0.7550  decode.d1.loss_mask: 1.4926  decode.d1.loss_dice: 1.0775  decode.d2.loss_cls: 0.6394  decode.d2.loss_mask: 1.5409  decode.d2.loss_dice: 1.0886  decode.d3.loss_cls: 0.6583  decode.d3.loss_mask: 1.5216  decode.d3.loss_dice: 1.1131  decode.d4.loss_cls: 0.6837  decode.d4.loss_mask: 1.5091  decode.d4.loss_dice: 1.1004  decode.d5.loss_cls: 0.6757  decode.d5.loss_mask: 1.5429  decode.d5.loss_dice: 1.1094  decode.d6.loss_cls: 0.6799  decode.d6.loss_mask: 1.5003  decode.d6.loss_dice: 1.0886  decode.d7.loss_cls: 0.7207  decode.d7.loss_mask: 1.5625  decode.d7.loss_dice: 1.1214  decode.d8.loss_cls: 0.7073  decode.d8.loss_mask: 1.5080  decode.d8.loss_dice: 1.0751
05/26 12:20:48 - mmengine - INFO - Iter(train) [ 12250/160000]  base_lr: 9.3083e-05 lr: 9.3083e-06  eta: 16:52:56  time: 0.4112  data_time: 0.0108  memory: 5981  grad_norm: 708.3328  loss: 30.5017  decode.loss_cls: 0.5263  decode.loss_mask: 1.4322  decode.loss_dice: 1.0856  decode.d0.loss_cls: 0.9509  decode.d0.loss_mask: 1.2462  decode.d0.loss_dice: 0.9818  decode.d1.loss_cls: 0.5489  decode.d1.loss_mask: 1.3763  decode.d1.loss_dice: 1.0556  decode.d2.loss_cls: 0.5532  decode.d2.loss_mask: 1.3726  decode.d2.loss_dice: 1.0539  decode.d3.loss_cls: 0.5984  decode.d3.loss_mask: 1.3457  decode.d3.loss_dice: 1.0630  decode.d4.loss_cls: 0.6095  decode.d4.loss_mask: 1.3968  decode.d4.loss_dice: 1.0659  decode.d5.loss_cls: 0.5025  decode.d5.loss_mask: 1.4888  decode.d5.loss_dice: 1.1100  decode.d6.loss_cls: 0.5581  decode.d6.loss_mask: 1.3924  decode.d6.loss_dice: 1.0849  decode.d7.loss_cls: 0.5755  decode.d7.loss_mask: 1.4206  decode.d7.loss_dice: 1.0920  decode.d8.loss_cls: 0.5868  decode.d8.loss_mask: 1.3593  decode.d8.loss_dice: 1.0680
05/26 12:21:09 - mmengine - INFO - Iter(train) [ 12300/160000]  base_lr: 9.3054e-05 lr: 9.3054e-06  eta: 16:52:34  time: 0.4099  data_time: 0.0108  memory: 5966  grad_norm: 1042.6018  loss: 31.8785  decode.loss_cls: 0.5316  decode.loss_mask: 1.4644  decode.loss_dice: 1.1778  decode.d0.loss_cls: 1.0097  decode.d0.loss_mask: 1.3256  decode.d0.loss_dice: 1.1131  decode.d1.loss_cls: 0.6030  decode.d1.loss_mask: 1.3834  decode.d1.loss_dice: 1.1374  decode.d2.loss_cls: 0.5991  decode.d2.loss_mask: 1.4356  decode.d2.loss_dice: 1.1433  decode.d3.loss_cls: 0.5954  decode.d3.loss_mask: 1.3624  decode.d3.loss_dice: 1.1526  decode.d4.loss_cls: 0.5750  decode.d4.loss_mask: 1.4545  decode.d4.loss_dice: 1.1650  decode.d5.loss_cls: 0.6368  decode.d5.loss_mask: 1.3815  decode.d5.loss_dice: 1.1322  decode.d6.loss_cls: 0.6063  decode.d6.loss_mask: 1.3855  decode.d6.loss_dice: 1.1442  decode.d7.loss_cls: 0.5982  decode.d7.loss_mask: 1.4208  decode.d7.loss_dice: 1.1771  decode.d8.loss_cls: 0.5368  decode.d8.loss_mask: 1.4771  decode.d8.loss_dice: 1.1533
05/26 12:21:29 - mmengine - INFO - Iter(train) [ 12350/160000]  base_lr: 9.3026e-05 lr: 9.3026e-06  eta: 16:52:11  time: 0.4075  data_time: 0.0088  memory: 5971  grad_norm: 638.0309  loss: 26.6947  decode.loss_cls: 0.4888  decode.loss_mask: 1.1900  decode.loss_dice: 0.9580  decode.d0.loss_cls: 1.0226  decode.d0.loss_mask: 1.0795  decode.d0.loss_dice: 0.9557  decode.d1.loss_cls: 0.5354  decode.d1.loss_mask: 1.1608  decode.d1.loss_dice: 0.9207  decode.d2.loss_cls: 0.5294  decode.d2.loss_mask: 1.1284  decode.d2.loss_dice: 0.9143  decode.d3.loss_cls: 0.5334  decode.d3.loss_mask: 1.1406  decode.d3.loss_dice: 0.9072  decode.d4.loss_cls: 0.5216  decode.d4.loss_mask: 1.1941  decode.d4.loss_dice: 0.9142  decode.d5.loss_cls: 0.5581  decode.d5.loss_mask: 1.1269  decode.d5.loss_dice: 0.9378  decode.d6.loss_cls: 0.5474  decode.d6.loss_mask: 1.1894  decode.d6.loss_dice: 0.9578  decode.d7.loss_cls: 0.5688  decode.d7.loss_mask: 1.0916  decode.d7.loss_dice: 0.9260  decode.d8.loss_cls: 0.5528  decode.d8.loss_mask: 1.1758  decode.d8.loss_dice: 0.9673
05/26 12:21:50 - mmengine - INFO - Iter(train) [ 12400/160000]  base_lr: 9.2998e-05 lr: 9.2998e-06  eta: 16:51:49  time: 0.4094  data_time: 0.0104  memory: 5971  grad_norm: 487.6791  loss: 28.8851  decode.loss_cls: 0.3931  decode.loss_mask: 1.3606  decode.loss_dice: 1.0323  decode.d0.loss_cls: 0.8807  decode.d0.loss_mask: 1.2924  decode.d0.loss_dice: 1.0370  decode.d1.loss_cls: 0.4838  decode.d1.loss_mask: 1.3456  decode.d1.loss_dice: 1.0485  decode.d2.loss_cls: 0.4139  decode.d2.loss_mask: 1.3597  decode.d2.loss_dice: 1.0598  decode.d3.loss_cls: 0.4906  decode.d3.loss_mask: 1.3676  decode.d3.loss_dice: 1.0572  decode.d4.loss_cls: 0.4450  decode.d4.loss_mask: 1.3273  decode.d4.loss_dice: 1.0360  decode.d5.loss_cls: 0.4958  decode.d5.loss_mask: 1.3211  decode.d5.loss_dice: 1.0698  decode.d6.loss_cls: 0.4604  decode.d6.loss_mask: 1.3399  decode.d6.loss_dice: 1.0338  decode.d7.loss_cls: 0.4659  decode.d7.loss_mask: 1.3652  decode.d7.loss_dice: 1.0830  decode.d8.loss_cls: 0.4268  decode.d8.loss_mask: 1.3291  decode.d8.loss_dice: 1.0632
05/26 12:22:10 - mmengine - INFO - Iter(train) [ 12450/160000]  base_lr: 9.2969e-05 lr: 9.2969e-06  eta: 16:51:27  time: 0.4088  data_time: 0.0101  memory: 5973  grad_norm: 731.7974  loss: 34.3065  decode.loss_cls: 0.5008  decode.loss_mask: 1.7094  decode.loss_dice: 1.1993  decode.d0.loss_cls: 0.9456  decode.d0.loss_mask: 1.5623  decode.d0.loss_dice: 1.1595  decode.d1.loss_cls: 0.5583  decode.d1.loss_mask: 1.6505  decode.d1.loss_dice: 1.1808  decode.d2.loss_cls: 0.5821  decode.d2.loss_mask: 1.6560  decode.d2.loss_dice: 1.1729  decode.d3.loss_cls: 0.5555  decode.d3.loss_mask: 1.6590  decode.d3.loss_dice: 1.1673  decode.d4.loss_cls: 0.5738  decode.d4.loss_mask: 1.6526  decode.d4.loss_dice: 1.1598  decode.d5.loss_cls: 0.5000  decode.d5.loss_mask: 1.6856  decode.d5.loss_dice: 1.1934  decode.d6.loss_cls: 0.5467  decode.d6.loss_mask: 1.7167  decode.d6.loss_dice: 1.1949  decode.d7.loss_cls: 0.5581  decode.d7.loss_mask: 1.6647  decode.d7.loss_dice: 1.1812  decode.d8.loss_cls: 0.5690  decode.d8.loss_mask: 1.6725  decode.d8.loss_dice: 1.1783
05/26 12:22:30 - mmengine - INFO - Iter(train) [ 12500/160000]  base_lr: 9.2941e-05 lr: 9.2941e-06  eta: 16:51:04  time: 0.4080  data_time: 0.0088  memory: 5990  grad_norm: 759.0346  loss: 28.1571  decode.loss_cls: 0.4414  decode.loss_mask: 1.3799  decode.loss_dice: 0.9272  decode.d0.loss_cls: 0.7886  decode.d0.loss_mask: 1.3157  decode.d0.loss_dice: 0.9039  decode.d1.loss_cls: 0.4994  decode.d1.loss_mask: 1.4313  decode.d1.loss_dice: 0.9258  decode.d2.loss_cls: 0.4715  decode.d2.loss_mask: 1.3727  decode.d2.loss_dice: 0.9051  decode.d3.loss_cls: 0.5088  decode.d3.loss_mask: 1.4050  decode.d3.loss_dice: 0.9078  decode.d4.loss_cls: 0.4885  decode.d4.loss_mask: 1.4393  decode.d4.loss_dice: 0.9324  decode.d5.loss_cls: 0.4706  decode.d5.loss_mask: 1.3743  decode.d5.loss_dice: 0.9174  decode.d6.loss_cls: 0.5022  decode.d6.loss_mask: 1.3879  decode.d6.loss_dice: 0.9166  decode.d7.loss_cls: 0.4810  decode.d7.loss_mask: 1.3744  decode.d7.loss_dice: 0.9095  decode.d8.loss_cls: 0.4646  decode.d8.loss_mask: 1.3914  decode.d8.loss_dice: 0.9228
05/26 12:22:51 - mmengine - INFO - Iter(train) [ 12550/160000]  base_lr: 9.2913e-05 lr: 9.2913e-06  eta: 16:50:41  time: 0.4083  data_time: 0.0087  memory: 5967  grad_norm: 768.0620  loss: 32.2258  decode.loss_cls: 0.6385  decode.loss_mask: 1.3761  decode.loss_dice: 1.0975  decode.d0.loss_cls: 1.1002  decode.d0.loss_mask: 1.3240  decode.d0.loss_dice: 1.1200  decode.d1.loss_cls: 0.6772  decode.d1.loss_mask: 1.3328  decode.d1.loss_dice: 1.1120  decode.d2.loss_cls: 0.6746  decode.d2.loss_mask: 1.3955  decode.d2.loss_dice: 1.1414  decode.d3.loss_cls: 0.6238  decode.d3.loss_mask: 1.3635  decode.d3.loss_dice: 1.1911  decode.d4.loss_cls: 0.6838  decode.d4.loss_mask: 1.4562  decode.d4.loss_dice: 1.2051  decode.d5.loss_cls: 0.6257  decode.d5.loss_mask: 1.4523  decode.d5.loss_dice: 1.1899  decode.d6.loss_cls: 0.6478  decode.d6.loss_mask: 1.4101  decode.d6.loss_dice: 1.1434  decode.d7.loss_cls: 0.5769  decode.d7.loss_mask: 1.4334  decode.d7.loss_dice: 1.1387  decode.d8.loss_cls: 0.6067  decode.d8.loss_mask: 1.3510  decode.d8.loss_dice: 1.1362
05/26 12:23:11 - mmengine - INFO - Iter(train) [ 12600/160000]  base_lr: 9.2884e-05 lr: 9.2884e-06  eta: 16:50:19  time: 0.4064  data_time: 0.0086  memory: 5976  grad_norm: 1049.1698  loss: 29.8987  decode.loss_cls: 0.5406  decode.loss_mask: 1.3555  decode.loss_dice: 1.0182  decode.d0.loss_cls: 0.8649  decode.d0.loss_mask: 1.3272  decode.d0.loss_dice: 1.0398  decode.d1.loss_cls: 0.5305  decode.d1.loss_mask: 1.3630  decode.d1.loss_dice: 1.0283  decode.d2.loss_cls: 0.5013  decode.d2.loss_mask: 1.3699  decode.d2.loss_dice: 0.9977  decode.d3.loss_cls: 0.5864  decode.d3.loss_mask: 1.4095  decode.d3.loss_dice: 1.0347  decode.d4.loss_cls: 0.5102  decode.d4.loss_mask: 1.4435  decode.d4.loss_dice: 1.0501  decode.d5.loss_cls: 0.5055  decode.d5.loss_mask: 1.4287  decode.d5.loss_dice: 1.0947  decode.d6.loss_cls: 0.5393  decode.d6.loss_mask: 1.4037  decode.d6.loss_dice: 1.0181  decode.d7.loss_cls: 0.4708  decode.d7.loss_mask: 1.4210  decode.d7.loss_dice: 1.0803  decode.d8.loss_cls: 0.5018  decode.d8.loss_mask: 1.3936  decode.d8.loss_dice: 1.0697
05/26 12:23:32 - mmengine - INFO - Iter(train) [ 12650/160000]  base_lr: 9.2856e-05 lr: 9.2856e-06  eta: 16:49:56  time: 0.4077  data_time: 0.0086  memory: 5970  grad_norm: 636.0282  loss: 32.8278  decode.loss_cls: 0.6433  decode.loss_mask: 1.3924  decode.loss_dice: 1.1973  decode.d0.loss_cls: 0.9656  decode.d0.loss_mask: 1.2823  decode.d0.loss_dice: 1.1954  decode.d1.loss_cls: 0.6742  decode.d1.loss_mask: 1.4019  decode.d1.loss_dice: 1.1939  decode.d2.loss_cls: 0.6063  decode.d2.loss_mask: 1.4382  decode.d2.loss_dice: 1.2174  decode.d3.loss_cls: 0.6821  decode.d3.loss_mask: 1.3809  decode.d3.loss_dice: 1.2052  decode.d4.loss_cls: 0.6355  decode.d4.loss_mask: 1.3783  decode.d4.loss_dice: 1.2023  decode.d5.loss_cls: 0.7603  decode.d5.loss_mask: 1.3531  decode.d5.loss_dice: 1.1809  decode.d6.loss_cls: 0.7177  decode.d6.loss_mask: 1.3896  decode.d6.loss_dice: 1.2046  decode.d7.loss_cls: 0.6407  decode.d7.loss_mask: 1.4333  decode.d7.loss_dice: 1.2099  decode.d8.loss_cls: 0.7037  decode.d8.loss_mask: 1.3777  decode.d8.loss_dice: 1.1639
05/26 12:23:52 - mmengine - INFO - Iter(train) [ 12700/160000]  base_lr: 9.2828e-05 lr: 9.2828e-06  eta: 16:49:34  time: 0.4072  data_time: 0.0087  memory: 5976  grad_norm: 665.8715  loss: 30.8223  decode.loss_cls: 0.5583  decode.loss_mask: 1.3407  decode.loss_dice: 1.1918  decode.d0.loss_cls: 0.9544  decode.d0.loss_mask: 1.1957  decode.d0.loss_dice: 1.1162  decode.d1.loss_cls: 0.6050  decode.d1.loss_mask: 1.2817  decode.d1.loss_dice: 1.1638  decode.d2.loss_cls: 0.6029  decode.d2.loss_mask: 1.2769  decode.d2.loss_dice: 1.1694  decode.d3.loss_cls: 0.6225  decode.d3.loss_mask: 1.2939  decode.d3.loss_dice: 1.1469  decode.d4.loss_cls: 0.5806  decode.d4.loss_mask: 1.2981  decode.d4.loss_dice: 1.1784  decode.d5.loss_cls: 0.5979  decode.d5.loss_mask: 1.3138  decode.d5.loss_dice: 1.1697  decode.d6.loss_cls: 0.6142  decode.d6.loss_mask: 1.2868  decode.d6.loss_dice: 1.1264  decode.d7.loss_cls: 0.5423  decode.d7.loss_mask: 1.3465  decode.d7.loss_dice: 1.1940  decode.d8.loss_cls: 0.5278  decode.d8.loss_mask: 1.3547  decode.d8.loss_dice: 1.1710
05/26 12:24:12 - mmengine - INFO - Iter(train) [ 12750/160000]  base_lr: 9.2799e-05 lr: 9.2799e-06  eta: 16:49:11  time: 0.4079  data_time: 0.0086  memory: 5970  grad_norm: 477.1276  loss: 28.7434  decode.loss_cls: 0.5358  decode.loss_mask: 1.2435  decode.loss_dice: 1.0733  decode.d0.loss_cls: 0.8165  decode.d0.loss_mask: 1.2296  decode.d0.loss_dice: 1.1145  decode.d1.loss_cls: 0.4552  decode.d1.loss_mask: 1.2399  decode.d1.loss_dice: 1.0849  decode.d2.loss_cls: 0.5321  decode.d2.loss_mask: 1.2692  decode.d2.loss_dice: 1.0927  decode.d3.loss_cls: 0.5247  decode.d3.loss_mask: 1.2549  decode.d3.loss_dice: 1.0457  decode.d4.loss_cls: 0.5389  decode.d4.loss_mask: 1.2754  decode.d4.loss_dice: 1.0883  decode.d5.loss_cls: 0.5236  decode.d5.loss_mask: 1.2303  decode.d5.loss_dice: 1.0627  decode.d6.loss_cls: 0.5887  decode.d6.loss_mask: 1.2150  decode.d6.loss_dice: 1.0618  decode.d7.loss_cls: 0.5408  decode.d7.loss_mask: 1.2094  decode.d7.loss_dice: 1.0736  decode.d8.loss_cls: 0.5391  decode.d8.loss_mask: 1.2449  decode.d8.loss_dice: 1.0383
05/26 12:24:33 - mmengine - INFO - Iter(train) [ 12800/160000]  base_lr: 9.2771e-05 lr: 9.2771e-06  eta: 16:48:48  time: 0.4074  data_time: 0.0086  memory: 5973  grad_norm: 733.8541  loss: 26.4973  decode.loss_cls: 0.4048  decode.loss_mask: 1.2927  decode.loss_dice: 0.8599  decode.d0.loss_cls: 0.8541  decode.d0.loss_mask: 1.2162  decode.d0.loss_dice: 0.8923  decode.d1.loss_cls: 0.4181  decode.d1.loss_mask: 1.3411  decode.d1.loss_dice: 0.8919  decode.d2.loss_cls: 0.4467  decode.d2.loss_mask: 1.2794  decode.d2.loss_dice: 0.8749  decode.d3.loss_cls: 0.4473  decode.d3.loss_mask: 1.3599  decode.d3.loss_dice: 0.9031  decode.d4.loss_cls: 0.5000  decode.d4.loss_mask: 1.2610  decode.d4.loss_dice: 0.8781  decode.d5.loss_cls: 0.4571  decode.d5.loss_mask: 1.2834  decode.d5.loss_dice: 0.8969  decode.d6.loss_cls: 0.4231  decode.d6.loss_mask: 1.2958  decode.d6.loss_dice: 0.8563  decode.d7.loss_cls: 0.4212  decode.d7.loss_mask: 1.3007  decode.d7.loss_dice: 0.8823  decode.d8.loss_cls: 0.3976  decode.d8.loss_mask: 1.2816  decode.d8.loss_dice: 0.8802
05/26 12:24:53 - mmengine - INFO - Iter(train) [ 12850/160000]  base_lr: 9.2742e-05 lr: 9.2742e-06  eta: 16:48:25  time: 0.4079  data_time: 0.0086  memory: 5967  grad_norm: 803.1146  loss: 29.9752  decode.loss_cls: 0.5941  decode.loss_mask: 1.3190  decode.loss_dice: 1.0577  decode.d0.loss_cls: 0.9359  decode.d0.loss_mask: 1.2450  decode.d0.loss_dice: 1.0632  decode.d1.loss_cls: 0.5706  decode.d1.loss_mask: 1.3333  decode.d1.loss_dice: 1.0527  decode.d2.loss_cls: 0.5955  decode.d2.loss_mask: 1.3340  decode.d2.loss_dice: 1.0780  decode.d3.loss_cls: 0.5900  decode.d3.loss_mask: 1.3043  decode.d3.loss_dice: 1.0282  decode.d4.loss_cls: 0.6105  decode.d4.loss_mask: 1.3181  decode.d4.loss_dice: 1.0572  decode.d5.loss_cls: 0.5459  decode.d5.loss_mask: 1.3066  decode.d5.loss_dice: 1.0799  decode.d6.loss_cls: 0.6384  decode.d6.loss_mask: 1.2759  decode.d6.loss_dice: 1.0687  decode.d7.loss_cls: 0.6208  decode.d7.loss_mask: 1.2592  decode.d7.loss_dice: 1.0978  decode.d8.loss_cls: 0.6479  decode.d8.loss_mask: 1.2762  decode.d8.loss_dice: 1.0707
05/26 12:25:13 - mmengine - INFO - Iter(train) [ 12900/160000]  base_lr: 9.2714e-05 lr: 9.2714e-06  eta: 16:48:02  time: 0.4074  data_time: 0.0087  memory: 5971  grad_norm: 531.3651  loss: 28.2454  decode.loss_cls: 0.4788  decode.loss_mask: 1.1819  decode.loss_dice: 1.1152  decode.d0.loss_cls: 0.8476  decode.d0.loss_mask: 1.1466  decode.d0.loss_dice: 1.0828  decode.d1.loss_cls: 0.4731  decode.d1.loss_mask: 1.2060  decode.d1.loss_dice: 1.0380  decode.d2.loss_cls: 0.5401  decode.d2.loss_mask: 1.2260  decode.d2.loss_dice: 1.0552  decode.d3.loss_cls: 0.5721  decode.d3.loss_mask: 1.1673  decode.d3.loss_dice: 1.0361  decode.d4.loss_cls: 0.4801  decode.d4.loss_mask: 1.2124  decode.d4.loss_dice: 1.0537  decode.d5.loss_cls: 0.5727  decode.d5.loss_mask: 1.2404  decode.d5.loss_dice: 1.1193  decode.d6.loss_cls: 0.5254  decode.d6.loss_mask: 1.1895  decode.d6.loss_dice: 1.1113  decode.d7.loss_cls: 0.4669  decode.d7.loss_mask: 1.1909  decode.d7.loss_dice: 1.1512  decode.d8.loss_cls: 0.4791  decode.d8.loss_mask: 1.1868  decode.d8.loss_dice: 1.0990
05/26 12:25:34 - mmengine - INFO - Iter(train) [ 12950/160000]  base_lr: 9.2686e-05 lr: 9.2686e-06  eta: 16:47:39  time: 0.4067  data_time: 0.0086  memory: 5977  grad_norm: 920.6829  loss: 30.6419  decode.loss_cls: 0.4203  decode.loss_mask: 1.6223  decode.loss_dice: 1.1112  decode.d0.loss_cls: 0.7956  decode.d0.loss_mask: 1.4997  decode.d0.loss_dice: 1.0021  decode.d1.loss_cls: 0.3440  decode.d1.loss_mask: 1.5814  decode.d1.loss_dice: 1.0696  decode.d2.loss_cls: 0.3302  decode.d2.loss_mask: 1.6495  decode.d2.loss_dice: 1.0820  decode.d3.loss_cls: 0.3661  decode.d3.loss_mask: 1.5887  decode.d3.loss_dice: 1.0554  decode.d4.loss_cls: 0.3721  decode.d4.loss_mask: 1.5501  decode.d4.loss_dice: 1.0462  decode.d5.loss_cls: 0.3880  decode.d5.loss_mask: 1.6318  decode.d5.loss_dice: 1.0780  decode.d6.loss_cls: 0.4043  decode.d6.loss_mask: 1.5235  decode.d6.loss_dice: 1.0544  decode.d7.loss_cls: 0.4236  decode.d7.loss_mask: 1.5279  decode.d7.loss_dice: 1.0632  decode.d8.loss_cls: 0.4109  decode.d8.loss_mask: 1.5785  decode.d8.loss_dice: 1.0712
05/26 12:25:54 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 12:25:54 - mmengine - INFO - Iter(train) [ 13000/160000]  base_lr: 9.2657e-05 lr: 9.2657e-06  eta: 16:47:16  time: 0.4070  data_time: 0.0086  memory: 5967  grad_norm: 779.1481  loss: 26.1767  decode.loss_cls: 0.3111  decode.loss_mask: 1.3228  decode.loss_dice: 0.9974  decode.d0.loss_cls: 0.7060  decode.d0.loss_mask: 1.2997  decode.d0.loss_dice: 0.9418  decode.d1.loss_cls: 0.3800  decode.d1.loss_mask: 1.2711  decode.d1.loss_dice: 0.9726  decode.d2.loss_cls: 0.3420  decode.d2.loss_mask: 1.2477  decode.d2.loss_dice: 0.9797  decode.d3.loss_cls: 0.3080  decode.d3.loss_mask: 1.2370  decode.d3.loss_dice: 0.9429  decode.d4.loss_cls: 0.3295  decode.d4.loss_mask: 1.2563  decode.d4.loss_dice: 0.9859  decode.d5.loss_cls: 0.3433  decode.d5.loss_mask: 1.2621  decode.d5.loss_dice: 1.0017  decode.d6.loss_cls: 0.3230  decode.d6.loss_mask: 1.2852  decode.d6.loss_dice: 0.9818  decode.d7.loss_cls: 0.2758  decode.d7.loss_mask: 1.3103  decode.d7.loss_dice: 0.9843  decode.d8.loss_cls: 0.3307  decode.d8.loss_mask: 1.2614  decode.d8.loss_dice: 0.9855
05/26 12:26:14 - mmengine - INFO - Iter(train) [ 13050/160000]  base_lr: 9.2629e-05 lr: 9.2629e-06  eta: 16:46:54  time: 0.4070  data_time: 0.0087  memory: 5976  grad_norm: 1060.0242  loss: 29.2641  decode.loss_cls: 0.4393  decode.loss_mask: 1.3839  decode.loss_dice: 0.9737  decode.d0.loss_cls: 0.8216  decode.d0.loss_mask: 1.3828  decode.d0.loss_dice: 1.0021  decode.d1.loss_cls: 0.4452  decode.d1.loss_mask: 1.4805  decode.d1.loss_dice: 1.0581  decode.d2.loss_cls: 0.4872  decode.d2.loss_mask: 1.4663  decode.d2.loss_dice: 1.0311  decode.d3.loss_cls: 0.4819  decode.d3.loss_mask: 1.3941  decode.d3.loss_dice: 0.9736  decode.d4.loss_cls: 0.4814  decode.d4.loss_mask: 1.4039  decode.d4.loss_dice: 0.9974  decode.d5.loss_cls: 0.4467  decode.d5.loss_mask: 1.4130  decode.d5.loss_dice: 0.9893  decode.d6.loss_cls: 0.4915  decode.d6.loss_mask: 1.4190  decode.d6.loss_dice: 1.0023  decode.d7.loss_cls: 0.4612  decode.d7.loss_mask: 1.4779  decode.d7.loss_dice: 0.9904  decode.d8.loss_cls: 0.4670  decode.d8.loss_mask: 1.3993  decode.d8.loss_dice: 1.0023
05/26 12:26:35 - mmengine - INFO - Iter(train) [ 13100/160000]  base_lr: 9.2601e-05 lr: 9.2601e-06  eta: 16:46:32  time: 0.4083  data_time: 0.0087  memory: 5977  grad_norm: 2084.4586  loss: 35.6266  decode.loss_cls: 0.6176  decode.loss_mask: 1.6744  decode.loss_dice: 1.2088  decode.d0.loss_cls: 1.0663  decode.d0.loss_mask: 1.7119  decode.d0.loss_dice: 1.1633  decode.d1.loss_cls: 0.7323  decode.d1.loss_mask: 1.6137  decode.d1.loss_dice: 1.1392  decode.d2.loss_cls: 0.6319  decode.d2.loss_mask: 1.6648  decode.d2.loss_dice: 1.1988  decode.d3.loss_cls: 0.6450  decode.d3.loss_mask: 1.6802  decode.d3.loss_dice: 1.1964  decode.d4.loss_cls: 0.7449  decode.d4.loss_mask: 1.5766  decode.d4.loss_dice: 1.1702  decode.d5.loss_cls: 0.6428  decode.d5.loss_mask: 1.6691  decode.d5.loss_dice: 1.2143  decode.d6.loss_cls: 0.7054  decode.d6.loss_mask: 1.6241  decode.d6.loss_dice: 1.1787  decode.d7.loss_cls: 0.6363  decode.d7.loss_mask: 1.7615  decode.d7.loss_dice: 1.2425  decode.d8.loss_cls: 0.6315  decode.d8.loss_mask: 1.6309  decode.d8.loss_dice: 1.2532
05/26 12:26:55 - mmengine - INFO - Iter(train) [ 13150/160000]  base_lr: 9.2572e-05 lr: 9.2572e-06  eta: 16:46:09  time: 0.4065  data_time: 0.0086  memory: 5966  grad_norm: 1183.0955  loss: 32.4124  decode.loss_cls: 0.5682  decode.loss_mask: 1.4174  decode.loss_dice: 1.2050  decode.d0.loss_cls: 0.9791  decode.d0.loss_mask: 1.3578  decode.d0.loss_dice: 1.1779  decode.d1.loss_cls: 0.5081  decode.d1.loss_mask: 1.4314  decode.d1.loss_dice: 1.1680  decode.d2.loss_cls: 0.5351  decode.d2.loss_mask: 1.4631  decode.d2.loss_dice: 1.1773  decode.d3.loss_cls: 0.5361  decode.d3.loss_mask: 1.4836  decode.d3.loss_dice: 1.1976  decode.d4.loss_cls: 0.6577  decode.d4.loss_mask: 1.4570  decode.d4.loss_dice: 1.1670  decode.d5.loss_cls: 0.5801  decode.d5.loss_mask: 1.4529  decode.d5.loss_dice: 1.2001  decode.d6.loss_cls: 0.5509  decode.d6.loss_mask: 1.4878  decode.d6.loss_dice: 1.1970  decode.d7.loss_cls: 0.4922  decode.d7.loss_mask: 1.5363  decode.d7.loss_dice: 1.1919  decode.d8.loss_cls: 0.5416  decode.d8.loss_mask: 1.4812  decode.d8.loss_dice: 1.2131
05/26 12:27:16 - mmengine - INFO - Iter(train) [ 13200/160000]  base_lr: 9.2544e-05 lr: 9.2544e-06  eta: 16:45:46  time: 0.4075  data_time: 0.0087  memory: 5976  grad_norm: 530.8263  loss: 27.8634  decode.loss_cls: 0.4552  decode.loss_mask: 1.2997  decode.loss_dice: 0.9284  decode.d0.loss_cls: 0.8499  decode.d0.loss_mask: 1.2624  decode.d0.loss_dice: 0.9321  decode.d1.loss_cls: 0.5205  decode.d1.loss_mask: 1.3083  decode.d1.loss_dice: 0.9670  decode.d2.loss_cls: 0.4812  decode.d2.loss_mask: 1.2675  decode.d2.loss_dice: 0.9785  decode.d3.loss_cls: 0.4507  decode.d3.loss_mask: 1.2897  decode.d3.loss_dice: 0.9364  decode.d4.loss_cls: 0.4911  decode.d4.loss_mask: 1.3167  decode.d4.loss_dice: 0.9287  decode.d5.loss_cls: 0.5295  decode.d5.loss_mask: 1.2813  decode.d5.loss_dice: 0.9426  decode.d6.loss_cls: 0.6131  decode.d6.loss_mask: 1.3681  decode.d6.loss_dice: 0.9606  decode.d7.loss_cls: 0.4995  decode.d7.loss_mask: 1.3134  decode.d7.loss_dice: 0.9745  decode.d8.loss_cls: 0.4853  decode.d8.loss_mask: 1.3016  decode.d8.loss_dice: 0.9300
05/26 12:27:36 - mmengine - INFO - Iter(train) [ 13250/160000]  base_lr: 9.2516e-05 lr: 9.2516e-06  eta: 16:45:23  time: 0.4058  data_time: 0.0085  memory: 5966  grad_norm: 792.4887  loss: 32.8870  decode.loss_cls: 0.4795  decode.loss_mask: 1.4499  decode.loss_dice: 1.1907  decode.d0.loss_cls: 0.8808  decode.d0.loss_mask: 1.4176  decode.d0.loss_dice: 1.1480  decode.d1.loss_cls: 0.4749  decode.d1.loss_mask: 1.7702  decode.d1.loss_dice: 1.1796  decode.d2.loss_cls: 0.4969  decode.d2.loss_mask: 1.4595  decode.d2.loss_dice: 1.1454  decode.d3.loss_cls: 0.4736  decode.d3.loss_mask: 1.6624  decode.d3.loss_dice: 1.1592  decode.d4.loss_cls: 0.3808  decode.d4.loss_mask: 1.9366  decode.d4.loss_dice: 1.2612  decode.d5.loss_cls: 0.4772  decode.d5.loss_mask: 1.5134  decode.d5.loss_dice: 1.1865  decode.d6.loss_cls: 0.4589  decode.d6.loss_mask: 1.5412  decode.d6.loss_dice: 1.2157  decode.d7.loss_cls: 0.5124  decode.d7.loss_mask: 1.6155  decode.d7.loss_dice: 1.1768  decode.d8.loss_cls: 0.4865  decode.d8.loss_mask: 1.5884  decode.d8.loss_dice: 1.1479
05/26 12:27:56 - mmengine - INFO - Iter(train) [ 13300/160000]  base_lr: 9.2487e-05 lr: 9.2487e-06  eta: 16:45:00  time: 0.4055  data_time: 0.0085  memory: 5984  grad_norm: 711.2213  loss: 30.4128  decode.loss_cls: 0.4532  decode.loss_mask: 1.5505  decode.loss_dice: 1.0506  decode.d0.loss_cls: 0.8586  decode.d0.loss_mask: 1.5085  decode.d0.loss_dice: 1.0174  decode.d1.loss_cls: 0.4637  decode.d1.loss_mask: 1.4594  decode.d1.loss_dice: 1.0168  decode.d2.loss_cls: 0.4627  decode.d2.loss_mask: 1.4694  decode.d2.loss_dice: 1.0585  decode.d3.loss_cls: 0.4647  decode.d3.loss_mask: 1.4582  decode.d3.loss_dice: 1.0342  decode.d4.loss_cls: 0.4601  decode.d4.loss_mask: 1.4543  decode.d4.loss_dice: 1.0111  decode.d5.loss_cls: 0.6007  decode.d5.loss_mask: 1.4332  decode.d5.loss_dice: 0.9737  decode.d6.loss_cls: 0.5595  decode.d6.loss_mask: 1.4256  decode.d6.loss_dice: 1.0204  decode.d7.loss_cls: 0.5259  decode.d7.loss_mask: 1.4921  decode.d7.loss_dice: 1.0071  decode.d8.loss_cls: 0.5287  decode.d8.loss_mask: 1.5547  decode.d8.loss_dice: 1.0393
05/26 12:28:17 - mmengine - INFO - Iter(train) [ 13350/160000]  base_lr: 9.2459e-05 lr: 9.2459e-06  eta: 16:44:38  time: 0.4071  data_time: 0.0088  memory: 5970  grad_norm: 803.3015  loss: 29.8222  decode.loss_cls: 0.4268  decode.loss_mask: 1.3307  decode.loss_dice: 1.1161  decode.d0.loss_cls: 0.9493  decode.d0.loss_mask: 1.2541  decode.d0.loss_dice: 1.0589  decode.d1.loss_cls: 0.4396  decode.d1.loss_mask: 1.2807  decode.d1.loss_dice: 1.1094  decode.d2.loss_cls: 0.4800  decode.d2.loss_mask: 1.2977  decode.d2.loss_dice: 1.1334  decode.d3.loss_cls: 0.4665  decode.d3.loss_mask: 1.3468  decode.d3.loss_dice: 1.1373  decode.d4.loss_cls: 0.4784  decode.d4.loss_mask: 1.3339  decode.d4.loss_dice: 1.1390  decode.d5.loss_cls: 0.5306  decode.d5.loss_mask: 1.3588  decode.d5.loss_dice: 1.1042  decode.d6.loss_cls: 0.4989  decode.d6.loss_mask: 1.3537  decode.d6.loss_dice: 1.0941  decode.d7.loss_cls: 0.5339  decode.d7.loss_mask: 1.4160  decode.d7.loss_dice: 1.1247  decode.d8.loss_cls: 0.4605  decode.d8.loss_mask: 1.4888  decode.d8.loss_dice: 1.0796
05/26 12:28:37 - mmengine - INFO - Iter(train) [ 13400/160000]  base_lr: 9.2430e-05 lr: 9.2430e-06  eta: 16:44:15  time: 0.4063  data_time: 0.0086  memory: 5980  grad_norm: 766.9376  loss: 33.4953  decode.loss_cls: 0.5840  decode.loss_mask: 1.4417  decode.loss_dice: 1.2714  decode.d0.loss_cls: 1.0878  decode.d0.loss_mask: 1.3431  decode.d0.loss_dice: 1.2185  decode.d1.loss_cls: 0.7050  decode.d1.loss_mask: 1.4264  decode.d1.loss_dice: 1.2415  decode.d2.loss_cls: 0.6619  decode.d2.loss_mask: 1.3645  decode.d2.loss_dice: 1.2554  decode.d3.loss_cls: 0.6466  decode.d3.loss_mask: 1.4373  decode.d3.loss_dice: 1.2643  decode.d4.loss_cls: 0.6438  decode.d4.loss_mask: 1.4635  decode.d4.loss_dice: 1.2441  decode.d5.loss_cls: 0.7316  decode.d5.loss_mask: 1.3897  decode.d5.loss_dice: 1.2149  decode.d6.loss_cls: 0.6073  decode.d6.loss_mask: 1.4593  decode.d6.loss_dice: 1.2441  decode.d7.loss_cls: 0.6545  decode.d7.loss_mask: 1.4331  decode.d7.loss_dice: 1.1958  decode.d8.loss_cls: 0.6046  decode.d8.loss_mask: 1.4622  decode.d8.loss_dice: 1.1973
05/26 12:28:57 - mmengine - INFO - Iter(train) [ 13450/160000]  base_lr: 9.2402e-05 lr: 9.2402e-06  eta: 16:43:52  time: 0.4068  data_time: 0.0087  memory: 5969  grad_norm: 634.8323  loss: 26.8265  decode.loss_cls: 0.3564  decode.loss_mask: 1.2823  decode.loss_dice: 0.9644  decode.d0.loss_cls: 0.7953  decode.d0.loss_mask: 1.2850  decode.d0.loss_dice: 0.9626  decode.d1.loss_cls: 0.4108  decode.d1.loss_mask: 1.3015  decode.d1.loss_dice: 0.9572  decode.d2.loss_cls: 0.3844  decode.d2.loss_mask: 1.3053  decode.d2.loss_dice: 0.9471  decode.d3.loss_cls: 0.4098  decode.d3.loss_mask: 1.2834  decode.d3.loss_dice: 0.9485  decode.d4.loss_cls: 0.3768  decode.d4.loss_mask: 1.2957  decode.d4.loss_dice: 0.9616  decode.d5.loss_cls: 0.3505  decode.d5.loss_mask: 1.3407  decode.d5.loss_dice: 0.9698  decode.d6.loss_cls: 0.4026  decode.d6.loss_mask: 1.2858  decode.d6.loss_dice: 0.9577  decode.d7.loss_cls: 0.4299  decode.d7.loss_mask: 1.2744  decode.d7.loss_dice: 0.9529  decode.d8.loss_cls: 0.3840  decode.d8.loss_mask: 1.2880  decode.d8.loss_dice: 0.9618
05/26 12:29:18 - mmengine - INFO - Iter(train) [ 13500/160000]  base_lr: 9.2374e-05 lr: 9.2374e-06  eta: 16:43:30  time: 0.4076  data_time: 0.0088  memory: 5981  grad_norm: 720.0701  loss: 30.7748  decode.loss_cls: 0.6232  decode.loss_mask: 1.2714  decode.loss_dice: 1.1252  decode.d0.loss_cls: 0.9886  decode.d0.loss_mask: 1.2321  decode.d0.loss_dice: 1.1568  decode.d1.loss_cls: 0.6980  decode.d1.loss_mask: 1.2598  decode.d1.loss_dice: 1.1205  decode.d2.loss_cls: 0.6482  decode.d2.loss_mask: 1.2388  decode.d2.loss_dice: 1.0958  decode.d3.loss_cls: 0.6001  decode.d3.loss_mask: 1.2512  decode.d3.loss_dice: 1.1523  decode.d4.loss_cls: 0.6351  decode.d4.loss_mask: 1.2724  decode.d4.loss_dice: 1.1567  decode.d5.loss_cls: 0.6802  decode.d5.loss_mask: 1.2584  decode.d5.loss_dice: 1.0986  decode.d6.loss_cls: 0.6278  decode.d6.loss_mask: 1.3137  decode.d6.loss_dice: 1.1303  decode.d7.loss_cls: 0.6512  decode.d7.loss_mask: 1.2500  decode.d7.loss_dice: 1.0910  decode.d8.loss_cls: 0.6578  decode.d8.loss_mask: 1.3144  decode.d8.loss_dice: 1.1754
05/26 12:29:38 - mmengine - INFO - Iter(train) [ 13550/160000]  base_lr: 9.2345e-05 lr: 9.2345e-06  eta: 16:43:07  time: 0.4068  data_time: 0.0087  memory: 5967  grad_norm: 1466.1342  loss: 28.8159  decode.loss_cls: 0.4291  decode.loss_mask: 1.2735  decode.loss_dice: 1.1038  decode.d0.loss_cls: 0.8267  decode.d0.loss_mask: 1.2315  decode.d0.loss_dice: 1.0919  decode.d1.loss_cls: 0.5294  decode.d1.loss_mask: 1.2529  decode.d1.loss_dice: 1.0933  decode.d2.loss_cls: 0.4634  decode.d2.loss_mask: 1.2954  decode.d2.loss_dice: 1.0997  decode.d3.loss_cls: 0.4878  decode.d3.loss_mask: 1.2434  decode.d3.loss_dice: 1.0477  decode.d4.loss_cls: 0.5233  decode.d4.loss_mask: 1.2729  decode.d4.loss_dice: 1.0907  decode.d5.loss_cls: 0.5076  decode.d5.loss_mask: 1.2692  decode.d5.loss_dice: 1.0852  decode.d6.loss_cls: 0.4566  decode.d6.loss_mask: 1.3074  decode.d6.loss_dice: 1.1402  decode.d7.loss_cls: 0.4607  decode.d7.loss_mask: 1.2785  decode.d7.loss_dice: 1.1048  decode.d8.loss_cls: 0.4098  decode.d8.loss_mask: 1.2922  decode.d8.loss_dice: 1.1472
05/26 12:29:58 - mmengine - INFO - Iter(train) [ 13600/160000]  base_lr: 9.2317e-05 lr: 9.2317e-06  eta: 16:42:44  time: 0.4056  data_time: 0.0087  memory: 5981  grad_norm: 481.0017  loss: 24.2078  decode.loss_cls: 0.4250  decode.loss_mask: 1.1168  decode.loss_dice: 0.8396  decode.d0.loss_cls: 0.7836  decode.d0.loss_mask: 1.0634  decode.d0.loss_dice: 0.8611  decode.d1.loss_cls: 0.4503  decode.d1.loss_mask: 1.0958  decode.d1.loss_dice: 0.8289  decode.d2.loss_cls: 0.4095  decode.d2.loss_mask: 1.1407  decode.d2.loss_dice: 0.8421  decode.d3.loss_cls: 0.4129  decode.d3.loss_mask: 1.0888  decode.d3.loss_dice: 0.8090  decode.d4.loss_cls: 0.3884  decode.d4.loss_mask: 1.1580  decode.d4.loss_dice: 0.8409  decode.d5.loss_cls: 0.4385  decode.d5.loss_mask: 1.1386  decode.d5.loss_dice: 0.8833  decode.d6.loss_cls: 0.4676  decode.d6.loss_mask: 1.0641  decode.d6.loss_dice: 0.8742  decode.d7.loss_cls: 0.4734  decode.d7.loss_mask: 1.0957  decode.d7.loss_dice: 0.8598  decode.d8.loss_cls: 0.4002  decode.d8.loss_mask: 1.1075  decode.d8.loss_dice: 0.8501
05/26 12:30:19 - mmengine - INFO - Iter(train) [ 13650/160000]  base_lr: 9.2289e-05 lr: 9.2289e-06  eta: 16:42:22  time: 0.4074  data_time: 0.0087  memory: 5972  grad_norm: 736.4810  loss: 22.7694  decode.loss_cls: 0.3411  decode.loss_mask: 1.0873  decode.loss_dice: 0.8227  decode.d0.loss_cls: 0.7458  decode.d0.loss_mask: 1.0051  decode.d0.loss_dice: 0.8412  decode.d1.loss_cls: 0.4023  decode.d1.loss_mask: 1.0744  decode.d1.loss_dice: 0.7947  decode.d2.loss_cls: 0.3580  decode.d2.loss_mask: 1.0480  decode.d2.loss_dice: 0.7690  decode.d3.loss_cls: 0.3971  decode.d3.loss_mask: 1.0210  decode.d3.loss_dice: 0.7707  decode.d4.loss_cls: 0.3714  decode.d4.loss_mask: 1.0729  decode.d4.loss_dice: 0.7775  decode.d5.loss_cls: 0.4339  decode.d5.loss_mask: 1.0186  decode.d5.loss_dice: 0.7823  decode.d6.loss_cls: 0.5250  decode.d6.loss_mask: 1.0170  decode.d6.loss_dice: 0.8218  decode.d7.loss_cls: 0.4260  decode.d7.loss_mask: 1.0172  decode.d7.loss_dice: 0.7870  decode.d8.loss_cls: 0.3719  decode.d8.loss_mask: 1.0487  decode.d8.loss_dice: 0.8196
05/26 12:30:39 - mmengine - INFO - Iter(train) [ 13700/160000]  base_lr: 9.2260e-05 lr: 9.2260e-06  eta: 16:41:59  time: 0.4067  data_time: 0.0086  memory: 5969  grad_norm: 710.9802  loss: 29.1370  decode.loss_cls: 0.4782  decode.loss_mask: 1.3171  decode.loss_dice: 1.0964  decode.d0.loss_cls: 0.8976  decode.d0.loss_mask: 1.2334  decode.d0.loss_dice: 1.0789  decode.d1.loss_cls: 0.6168  decode.d1.loss_mask: 1.2554  decode.d1.loss_dice: 1.0911  decode.d2.loss_cls: 0.5761  decode.d2.loss_mask: 1.2301  decode.d2.loss_dice: 1.0443  decode.d3.loss_cls: 0.5947  decode.d3.loss_mask: 1.2169  decode.d3.loss_dice: 1.0372  decode.d4.loss_cls: 0.5091  decode.d4.loss_mask: 1.3379  decode.d4.loss_dice: 1.0875  decode.d5.loss_cls: 0.5356  decode.d5.loss_mask: 1.2770  decode.d5.loss_dice: 1.0482  decode.d6.loss_cls: 0.5429  decode.d6.loss_mask: 1.2842  decode.d6.loss_dice: 1.0688  decode.d7.loss_cls: 0.4908  decode.d7.loss_mask: 1.2688  decode.d7.loss_dice: 1.0678  decode.d8.loss_cls: 0.5054  decode.d8.loss_mask: 1.2622  decode.d8.loss_dice: 1.0865
05/26 12:30:59 - mmengine - INFO - Iter(train) [ 13750/160000]  base_lr: 9.2232e-05 lr: 9.2232e-06  eta: 16:41:36  time: 0.4065  data_time: 0.0086  memory: 5970  grad_norm: 491.0248  loss: 25.9511  decode.loss_cls: 0.4230  decode.loss_mask: 1.1698  decode.loss_dice: 0.9475  decode.d0.loss_cls: 0.8040  decode.d0.loss_mask: 1.1511  decode.d0.loss_dice: 0.9492  decode.d1.loss_cls: 0.3719  decode.d1.loss_mask: 1.2219  decode.d1.loss_dice: 0.9332  decode.d2.loss_cls: 0.4541  decode.d2.loss_mask: 1.1846  decode.d2.loss_dice: 0.9076  decode.d3.loss_cls: 0.5092  decode.d3.loss_mask: 1.1529  decode.d3.loss_dice: 0.8715  decode.d4.loss_cls: 0.4214  decode.d4.loss_mask: 1.2281  decode.d4.loss_dice: 0.9372  decode.d5.loss_cls: 0.4568  decode.d5.loss_mask: 1.2799  decode.d5.loss_dice: 0.9299  decode.d6.loss_cls: 0.4371  decode.d6.loss_mask: 1.1946  decode.d6.loss_dice: 0.9321  decode.d7.loss_cls: 0.4320  decode.d7.loss_mask: 1.1995  decode.d7.loss_dice: 0.9318  decode.d8.loss_cls: 0.3977  decode.d8.loss_mask: 1.1995  decode.d8.loss_dice: 0.9220
05/26 12:31:20 - mmengine - INFO - Iter(train) [ 13800/160000]  base_lr: 9.2203e-05 lr: 9.2203e-06  eta: 16:41:13  time: 0.4065  data_time: 0.0087  memory: 5969  grad_norm: 1153.1794  loss: 26.6625  decode.loss_cls: 0.3755  decode.loss_mask: 1.1723  decode.loss_dice: 1.0087  decode.d0.loss_cls: 0.8795  decode.d0.loss_mask: 1.1954  decode.d0.loss_dice: 1.0278  decode.d1.loss_cls: 0.4554  decode.d1.loss_mask: 1.1848  decode.d1.loss_dice: 1.0055  decode.d2.loss_cls: 0.4238  decode.d2.loss_mask: 1.1447  decode.d2.loss_dice: 0.9986  decode.d3.loss_cls: 0.4214  decode.d3.loss_mask: 1.1669  decode.d3.loss_dice: 1.0098  decode.d4.loss_cls: 0.5626  decode.d4.loss_mask: 1.1486  decode.d4.loss_dice: 0.9676  decode.d5.loss_cls: 0.5073  decode.d5.loss_mask: 1.1690  decode.d5.loss_dice: 0.9697  decode.d6.loss_cls: 0.4606  decode.d6.loss_mask: 1.2258  decode.d6.loss_dice: 0.9681  decode.d7.loss_cls: 0.4701  decode.d7.loss_mask: 1.1756  decode.d7.loss_dice: 0.9761  decode.d8.loss_cls: 0.4293  decode.d8.loss_mask: 1.1759  decode.d8.loss_dice: 0.9861
05/26 12:31:40 - mmengine - INFO - Iter(train) [ 13850/160000]  base_lr: 9.2175e-05 lr: 9.2175e-06  eta: 16:40:51  time: 0.4057  data_time: 0.0087  memory: 5969  grad_norm: 639.6419  loss: 27.2496  decode.loss_cls: 0.5298  decode.loss_mask: 1.2641  decode.loss_dice: 0.8670  decode.d0.loss_cls: 0.8660  decode.d0.loss_mask: 1.3506  decode.d0.loss_dice: 0.8899  decode.d1.loss_cls: 0.5530  decode.d1.loss_mask: 1.2758  decode.d1.loss_dice: 0.8591  decode.d2.loss_cls: 0.4586  decode.d2.loss_mask: 1.3182  decode.d2.loss_dice: 0.8145  decode.d3.loss_cls: 0.4925  decode.d3.loss_mask: 1.3695  decode.d3.loss_dice: 0.8565  decode.d4.loss_cls: 0.5310  decode.d4.loss_mask: 1.2752  decode.d4.loss_dice: 0.8265  decode.d5.loss_cls: 0.4553  decode.d5.loss_mask: 1.3458  decode.d5.loss_dice: 0.8735  decode.d6.loss_cls: 0.4491  decode.d6.loss_mask: 1.3424  decode.d6.loss_dice: 0.8909  decode.d7.loss_cls: 0.5063  decode.d7.loss_mask: 1.3339  decode.d7.loss_dice: 0.9733  decode.d8.loss_cls: 0.5189  decode.d8.loss_mask: 1.2872  decode.d8.loss_dice: 0.8754
05/26 12:32:00 - mmengine - INFO - Iter(train) [ 13900/160000]  base_lr: 9.2147e-05 lr: 9.2147e-06  eta: 16:40:28  time: 0.4069  data_time: 0.0087  memory: 5967  grad_norm: 2263.5745  loss: 29.1920  decode.loss_cls: 0.4369  decode.loss_mask: 1.5042  decode.loss_dice: 0.9670  decode.d0.loss_cls: 0.7605  decode.d0.loss_mask: 1.4108  decode.d0.loss_dice: 0.9409  decode.d1.loss_cls: 0.4360  decode.d1.loss_mask: 1.5053  decode.d1.loss_dice: 0.9772  decode.d2.loss_cls: 0.3874  decode.d2.loss_mask: 1.4786  decode.d2.loss_dice: 0.9702  decode.d3.loss_cls: 0.4393  decode.d3.loss_mask: 1.4474  decode.d3.loss_dice: 0.9684  decode.d4.loss_cls: 0.4185  decode.d4.loss_mask: 1.4741  decode.d4.loss_dice: 0.9423  decode.d5.loss_cls: 0.4703  decode.d5.loss_mask: 1.4433  decode.d5.loss_dice: 0.9590  decode.d6.loss_cls: 0.4645  decode.d6.loss_mask: 1.5085  decode.d6.loss_dice: 1.0106  decode.d7.loss_cls: 0.4078  decode.d7.loss_mask: 1.5167  decode.d7.loss_dice: 1.0156  decode.d8.loss_cls: 0.4147  decode.d8.loss_mask: 1.5291  decode.d8.loss_dice: 0.9868
05/26 12:32:21 - mmengine - INFO - Iter(train) [ 13950/160000]  base_lr: 9.2118e-05 lr: 9.2118e-06  eta: 16:40:05  time: 0.4058  data_time: 0.0087  memory: 5965  grad_norm: 1084.4836  loss: 30.6185  decode.loss_cls: 0.6154  decode.loss_mask: 1.4034  decode.loss_dice: 0.9935  decode.d0.loss_cls: 1.0186  decode.d0.loss_mask: 1.3078  decode.d0.loss_dice: 1.0072  decode.d1.loss_cls: 0.7159  decode.d1.loss_mask: 1.3403  decode.d1.loss_dice: 1.0014  decode.d2.loss_cls: 0.6108  decode.d2.loss_mask: 1.3661  decode.d2.loss_dice: 1.0626  decode.d3.loss_cls: 0.6303  decode.d3.loss_mask: 1.3760  decode.d3.loss_dice: 1.0063  decode.d4.loss_cls: 0.6597  decode.d4.loss_mask: 1.3516  decode.d4.loss_dice: 0.9573  decode.d5.loss_cls: 0.6133  decode.d5.loss_mask: 1.3664  decode.d5.loss_dice: 1.0115  decode.d6.loss_cls: 0.6313  decode.d6.loss_mask: 1.4280  decode.d6.loss_dice: 1.0517  decode.d7.loss_cls: 0.6489  decode.d7.loss_mask: 1.4076  decode.d7.loss_dice: 1.0191  decode.d8.loss_cls: 0.6241  decode.d8.loss_mask: 1.3864  decode.d8.loss_dice: 1.0058
05/26 12:32:41 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 12:32:41 - mmengine - INFO - Iter(train) [ 14000/160000]  base_lr: 9.2090e-05 lr: 9.2090e-06  eta: 16:39:43  time: 0.4068  data_time: 0.0087  memory: 5965  grad_norm: 587.2850  loss: 27.6595  decode.loss_cls: 0.4278  decode.loss_mask: 1.3121  decode.loss_dice: 1.0245  decode.d0.loss_cls: 0.9553  decode.d0.loss_mask: 1.1868  decode.d0.loss_dice: 0.9926  decode.d1.loss_cls: 0.4850  decode.d1.loss_mask: 1.2576  decode.d1.loss_dice: 0.9875  decode.d2.loss_cls: 0.4611  decode.d2.loss_mask: 1.2305  decode.d2.loss_dice: 1.0002  decode.d3.loss_cls: 0.5104  decode.d3.loss_mask: 1.2245  decode.d3.loss_dice: 0.9659  decode.d4.loss_cls: 0.4902  decode.d4.loss_mask: 1.2372  decode.d4.loss_dice: 0.9615  decode.d5.loss_cls: 0.5332  decode.d5.loss_mask: 1.2411  decode.d5.loss_dice: 1.0120  decode.d6.loss_cls: 0.5013  decode.d6.loss_mask: 1.2757  decode.d6.loss_dice: 1.0048  decode.d7.loss_cls: 0.4735  decode.d7.loss_mask: 1.2244  decode.d7.loss_dice: 0.9821  decode.d8.loss_cls: 0.5119  decode.d8.loss_mask: 1.2171  decode.d8.loss_dice: 0.9718
05/26 12:33:02 - mmengine - INFO - Iter(train) [ 14050/160000]  base_lr: 9.2062e-05 lr: 9.2062e-06  eta: 16:39:21  time: 0.4063  data_time: 0.0086  memory: 5969  grad_norm: 745.7596  loss: 31.3075  decode.loss_cls: 0.4134  decode.loss_mask: 1.5807  decode.loss_dice: 1.1562  decode.d0.loss_cls: 0.7809  decode.d0.loss_mask: 1.5725  decode.d0.loss_dice: 1.1326  decode.d1.loss_cls: 0.4028  decode.d1.loss_mask: 1.5434  decode.d1.loss_dice: 1.1222  decode.d2.loss_cls: 0.3654  decode.d2.loss_mask: 1.5945  decode.d2.loss_dice: 1.1102  decode.d3.loss_cls: 0.4362  decode.d3.loss_mask: 1.5450  decode.d3.loss_dice: 1.1042  decode.d4.loss_cls: 0.4216  decode.d4.loss_mask: 1.5536  decode.d4.loss_dice: 1.1221  decode.d5.loss_cls: 0.3975  decode.d5.loss_mask: 1.6057  decode.d5.loss_dice: 1.1219  decode.d6.loss_cls: 0.4423  decode.d6.loss_mask: 1.5688  decode.d6.loss_dice: 1.1008  decode.d7.loss_cls: 0.3420  decode.d7.loss_mask: 1.5697  decode.d7.loss_dice: 1.1117  decode.d8.loss_cls: 0.3720  decode.d8.loss_mask: 1.5842  decode.d8.loss_dice: 1.1334
05/26 12:33:22 - mmengine - INFO - Iter(train) [ 14100/160000]  base_lr: 9.2033e-05 lr: 9.2033e-06  eta: 16:38:58  time: 0.4072  data_time: 0.0087  memory: 5976  grad_norm: 830.2873  loss: 32.3861  decode.loss_cls: 0.5294  decode.loss_mask: 1.4238  decode.loss_dice: 1.2410  decode.d0.loss_cls: 1.0698  decode.d0.loss_mask: 1.3446  decode.d0.loss_dice: 1.1640  decode.d1.loss_cls: 0.5102  decode.d1.loss_mask: 1.4563  decode.d1.loss_dice: 1.2334  decode.d2.loss_cls: 0.5047  decode.d2.loss_mask: 1.4548  decode.d2.loss_dice: 1.2525  decode.d3.loss_cls: 0.5495  decode.d3.loss_mask: 1.3997  decode.d3.loss_dice: 1.1981  decode.d4.loss_cls: 0.5292  decode.d4.loss_mask: 1.4030  decode.d4.loss_dice: 1.1801  decode.d5.loss_cls: 0.6061  decode.d5.loss_mask: 1.4467  decode.d5.loss_dice: 1.2431  decode.d6.loss_cls: 0.5600  decode.d6.loss_mask: 1.4493  decode.d6.loss_dice: 1.2244  decode.d7.loss_cls: 0.4958  decode.d7.loss_mask: 1.4226  decode.d7.loss_dice: 1.2385  decode.d8.loss_cls: 0.5458  decode.d8.loss_mask: 1.4203  decode.d8.loss_dice: 1.2892
05/26 12:33:42 - mmengine - INFO - Iter(train) [ 14150/160000]  base_lr: 9.2005e-05 lr: 9.2005e-06  eta: 16:38:37  time: 0.4185  data_time: 0.0087  memory: 5969  grad_norm: 758.3900  loss: 29.1713  decode.loss_cls: 0.4554  decode.loss_mask: 1.3902  decode.loss_dice: 0.9936  decode.d0.loss_cls: 0.9015  decode.d0.loss_mask: 1.2837  decode.d0.loss_dice: 0.9278  decode.d1.loss_cls: 0.4224  decode.d1.loss_mask: 1.3738  decode.d1.loss_dice: 1.0517  decode.d2.loss_cls: 0.3980  decode.d2.loss_mask: 1.4248  decode.d2.loss_dice: 0.9941  decode.d3.loss_cls: 0.4528  decode.d3.loss_mask: 1.4521  decode.d3.loss_dice: 1.0557  decode.d4.loss_cls: 0.4552  decode.d4.loss_mask: 1.4388  decode.d4.loss_dice: 1.0652  decode.d5.loss_cls: 0.4508  decode.d5.loss_mask: 1.4462  decode.d5.loss_dice: 1.0461  decode.d6.loss_cls: 0.4567  decode.d6.loss_mask: 1.3767  decode.d6.loss_dice: 1.0052  decode.d7.loss_cls: 0.4014  decode.d7.loss_mask: 1.4455  decode.d7.loss_dice: 1.0598  decode.d8.loss_cls: 0.4120  decode.d8.loss_mask: 1.4631  decode.d8.loss_dice: 1.0710
05/26 12:34:03 - mmengine - INFO - Iter(train) [ 14200/160000]  base_lr: 9.1976e-05 lr: 9.1976e-06  eta: 16:38:15  time: 0.4071  data_time: 0.0086  memory: 5966  grad_norm: 755.9245  loss: 28.7754  decode.loss_cls: 0.5276  decode.loss_mask: 1.3368  decode.loss_dice: 0.9916  decode.d0.loss_cls: 0.8706  decode.d0.loss_mask: 1.2988  decode.d0.loss_dice: 1.0029  decode.d1.loss_cls: 0.4880  decode.d1.loss_mask: 1.3074  decode.d1.loss_dice: 1.0208  decode.d2.loss_cls: 0.5061  decode.d2.loss_mask: 1.3704  decode.d2.loss_dice: 1.0350  decode.d3.loss_cls: 0.5299  decode.d3.loss_mask: 1.2780  decode.d3.loss_dice: 0.9522  decode.d4.loss_cls: 0.5030  decode.d4.loss_mask: 1.3445  decode.d4.loss_dice: 1.0488  decode.d5.loss_cls: 0.5289  decode.d5.loss_mask: 1.3020  decode.d5.loss_dice: 1.0077  decode.d6.loss_cls: 0.5587  decode.d6.loss_mask: 1.3185  decode.d6.loss_dice: 0.9819  decode.d7.loss_cls: 0.4793  decode.d7.loss_mask: 1.3627  decode.d7.loss_dice: 1.0383  decode.d8.loss_cls: 0.4697  decode.d8.loss_mask: 1.2952  decode.d8.loss_dice: 1.0203
05/26 12:34:23 - mmengine - INFO - Iter(train) [ 14250/160000]  base_lr: 9.1948e-05 lr: 9.1948e-06  eta: 16:37:52  time: 0.4073  data_time: 0.0087  memory: 5966  grad_norm: 1062.8445  loss: 22.6740  decode.loss_cls: 0.2410  decode.loss_mask: 1.1513  decode.loss_dice: 0.7898  decode.d0.loss_cls: 0.6554  decode.d0.loss_mask: 1.1639  decode.d0.loss_dice: 0.7558  decode.d1.loss_cls: 0.2612  decode.d1.loss_mask: 1.1919  decode.d1.loss_dice: 0.8135  decode.d2.loss_cls: 0.2482  decode.d2.loss_mask: 1.1906  decode.d2.loss_dice: 0.8245  decode.d3.loss_cls: 0.2668  decode.d3.loss_mask: 1.1707  decode.d3.loss_dice: 0.7903  decode.d4.loss_cls: 0.2766  decode.d4.loss_mask: 1.1317  decode.d4.loss_dice: 0.7587  decode.d5.loss_cls: 0.2640  decode.d5.loss_mask: 1.1662  decode.d5.loss_dice: 0.7920  decode.d6.loss_cls: 0.2962  decode.d6.loss_mask: 1.1521  decode.d6.loss_dice: 0.7700  decode.d7.loss_cls: 0.2774  decode.d7.loss_mask: 1.2030  decode.d7.loss_dice: 0.8548  decode.d8.loss_cls: 0.2524  decode.d8.loss_mask: 1.1658  decode.d8.loss_dice: 0.7982
05/26 12:34:43 - mmengine - INFO - Iter(train) [ 14300/160000]  base_lr: 9.1920e-05 lr: 9.1920e-06  eta: 16:37:30  time: 0.4076  data_time: 0.0086  memory: 5975  grad_norm: 1319.5276  loss: 30.7338  decode.loss_cls: 0.2511  decode.loss_mask: 1.5535  decode.loss_dice: 1.1809  decode.d0.loss_cls: 0.7722  decode.d0.loss_mask: 1.4923  decode.d0.loss_dice: 1.1118  decode.d1.loss_cls: 0.3611  decode.d1.loss_mask: 1.5311  decode.d1.loss_dice: 1.1356  decode.d2.loss_cls: 0.3252  decode.d2.loss_mask: 1.5640  decode.d2.loss_dice: 1.1972  decode.d3.loss_cls: 0.3567  decode.d3.loss_mask: 1.5384  decode.d3.loss_dice: 1.1298  decode.d4.loss_cls: 0.3584  decode.d4.loss_mask: 1.5137  decode.d4.loss_dice: 1.1321  decode.d5.loss_cls: 0.3271  decode.d5.loss_mask: 1.5666  decode.d5.loss_dice: 1.1535  decode.d6.loss_cls: 0.3916  decode.d6.loss_mask: 1.5544  decode.d6.loss_dice: 1.1954  decode.d7.loss_cls: 0.3709  decode.d7.loss_mask: 1.5225  decode.d7.loss_dice: 1.1823  decode.d8.loss_cls: 0.3202  decode.d8.loss_mask: 1.4906  decode.d8.loss_dice: 1.1536
05/26 12:35:04 - mmengine - INFO - Iter(train) [ 14350/160000]  base_lr: 9.1891e-05 lr: 9.1891e-06  eta: 16:37:08  time: 0.4081  data_time: 0.0086  memory: 5965  grad_norm: 939.8664  loss: 25.4648  decode.loss_cls: 0.3966  decode.loss_mask: 1.1477  decode.loss_dice: 0.9408  decode.d0.loss_cls: 0.7914  decode.d0.loss_mask: 1.0949  decode.d0.loss_dice: 0.9368  decode.d1.loss_cls: 0.4299  decode.d1.loss_mask: 1.1353  decode.d1.loss_dice: 0.9351  decode.d2.loss_cls: 0.3814  decode.d2.loss_mask: 1.1665  decode.d2.loss_dice: 0.9316  decode.d3.loss_cls: 0.4437  decode.d3.loss_mask: 1.1467  decode.d3.loss_dice: 0.9111  decode.d4.loss_cls: 0.4495  decode.d4.loss_mask: 1.1282  decode.d4.loss_dice: 0.9493  decode.d5.loss_cls: 0.5045  decode.d5.loss_mask: 1.1479  decode.d5.loss_dice: 1.0020  decode.d6.loss_cls: 0.3825  decode.d6.loss_mask: 1.1767  decode.d6.loss_dice: 0.9453  decode.d7.loss_cls: 0.4402  decode.d7.loss_mask: 1.1377  decode.d7.loss_dice: 0.9553  decode.d8.loss_cls: 0.3525  decode.d8.loss_mask: 1.1439  decode.d8.loss_dice: 0.9597
05/26 12:35:24 - mmengine - INFO - Iter(train) [ 14400/160000]  base_lr: 9.1863e-05 lr: 9.1863e-06  eta: 16:36:45  time: 0.4083  data_time: 0.0086  memory: 5969  grad_norm: 936.6645  loss: 31.7644  decode.loss_cls: 0.5046  decode.loss_mask: 1.4683  decode.loss_dice: 1.0854  decode.d0.loss_cls: 1.0333  decode.d0.loss_mask: 1.4184  decode.d0.loss_dice: 1.1265  decode.d1.loss_cls: 0.5483  decode.d1.loss_mask: 1.4253  decode.d1.loss_dice: 1.0799  decode.d2.loss_cls: 0.5700  decode.d2.loss_mask: 1.4164  decode.d2.loss_dice: 1.0673  decode.d3.loss_cls: 0.5843  decode.d3.loss_mask: 1.4479  decode.d3.loss_dice: 1.1024  decode.d4.loss_cls: 0.5809  decode.d4.loss_mask: 1.4012  decode.d4.loss_dice: 1.1553  decode.d5.loss_cls: 0.5937  decode.d5.loss_mask: 1.4895  decode.d5.loss_dice: 1.2180  decode.d6.loss_cls: 0.5852  decode.d6.loss_mask: 1.5103  decode.d6.loss_dice: 1.1971  decode.d7.loss_cls: 0.6045  decode.d7.loss_mask: 1.4006  decode.d7.loss_dice: 1.0861  decode.d8.loss_cls: 0.5005  decode.d8.loss_mask: 1.4525  decode.d8.loss_dice: 1.1104
05/26 12:35:45 - mmengine - INFO - Iter(train) [ 14450/160000]  base_lr: 9.1834e-05 lr: 9.1834e-06  eta: 16:36:23  time: 0.4079  data_time: 0.0087  memory: 5969  grad_norm: 561.4066  loss: 25.3802  decode.loss_cls: 0.3019  decode.loss_mask: 1.2430  decode.loss_dice: 0.9162  decode.d0.loss_cls: 0.8048  decode.d0.loss_mask: 1.1796  decode.d0.loss_dice: 0.8872  decode.d1.loss_cls: 0.3847  decode.d1.loss_mask: 1.2457  decode.d1.loss_dice: 0.8763  decode.d2.loss_cls: 0.4011  decode.d2.loss_mask: 1.1915  decode.d2.loss_dice: 0.8995  decode.d3.loss_cls: 0.3919  decode.d3.loss_mask: 1.2098  decode.d3.loss_dice: 0.9049  decode.d4.loss_cls: 0.4416  decode.d4.loss_mask: 1.1887  decode.d4.loss_dice: 0.8816  decode.d5.loss_cls: 0.4677  decode.d5.loss_mask: 1.1863  decode.d5.loss_dice: 0.8971  decode.d6.loss_cls: 0.4130  decode.d6.loss_mask: 1.1990  decode.d6.loss_dice: 0.8879  decode.d7.loss_cls: 0.3917  decode.d7.loss_mask: 1.2146  decode.d7.loss_dice: 0.8876  decode.d8.loss_cls: 0.3757  decode.d8.loss_mask: 1.2232  decode.d8.loss_dice: 0.8864
05/26 12:36:05 - mmengine - INFO - Iter(train) [ 14500/160000]  base_lr: 9.1806e-05 lr: 9.1806e-06  eta: 16:36:01  time: 0.4075  data_time: 0.0086  memory: 5976  grad_norm: 694.9753  loss: 30.0459  decode.loss_cls: 0.5405  decode.loss_mask: 1.5025  decode.loss_dice: 1.0002  decode.d0.loss_cls: 1.0969  decode.d0.loss_mask: 1.2515  decode.d0.loss_dice: 0.9375  decode.d1.loss_cls: 0.6040  decode.d1.loss_mask: 1.3480  decode.d1.loss_dice: 0.9540  decode.d2.loss_cls: 0.6654  decode.d2.loss_mask: 1.2600  decode.d2.loss_dice: 0.9710  decode.d3.loss_cls: 0.6219  decode.d3.loss_mask: 1.3090  decode.d3.loss_dice: 0.9537  decode.d4.loss_cls: 0.7354  decode.d4.loss_mask: 1.2742  decode.d4.loss_dice: 0.9395  decode.d5.loss_cls: 0.7532  decode.d5.loss_mask: 1.2952  decode.d5.loss_dice: 0.9685  decode.d6.loss_cls: 0.6974  decode.d6.loss_mask: 1.3957  decode.d6.loss_dice: 0.9550  decode.d7.loss_cls: 0.6251  decode.d7.loss_mask: 1.4571  decode.d7.loss_dice: 0.9951  decode.d8.loss_cls: 0.6536  decode.d8.loss_mask: 1.3271  decode.d8.loss_dice: 0.9580
05/26 12:36:25 - mmengine - INFO - Iter(train) [ 14550/160000]  base_lr: 9.1778e-05 lr: 9.1778e-06  eta: 16:35:38  time: 0.4071  data_time: 0.0088  memory: 5969  grad_norm: 1360.3309  loss: 28.4643  decode.loss_cls: 0.3838  decode.loss_mask: 1.3890  decode.loss_dice: 1.0095  decode.d0.loss_cls: 0.8471  decode.d0.loss_mask: 1.3269  decode.d0.loss_dice: 1.0073  decode.d1.loss_cls: 0.4289  decode.d1.loss_mask: 1.3761  decode.d1.loss_dice: 1.0172  decode.d2.loss_cls: 0.4243  decode.d2.loss_mask: 1.3463  decode.d2.loss_dice: 0.9401  decode.d3.loss_cls: 0.4508  decode.d3.loss_mask: 1.3606  decode.d3.loss_dice: 0.9895  decode.d4.loss_cls: 0.4684  decode.d4.loss_mask: 1.3693  decode.d4.loss_dice: 1.0038  decode.d5.loss_cls: 0.4822  decode.d5.loss_mask: 1.3822  decode.d5.loss_dice: 1.0174  decode.d6.loss_cls: 0.4787  decode.d6.loss_mask: 1.3670  decode.d6.loss_dice: 0.9946  decode.d7.loss_cls: 0.4575  decode.d7.loss_mask: 1.3190  decode.d7.loss_dice: 0.9662  decode.d8.loss_cls: 0.4454  decode.d8.loss_mask: 1.4093  decode.d8.loss_dice: 1.0058
05/26 12:36:46 - mmengine - INFO - Iter(train) [ 14600/160000]  base_lr: 9.1749e-05 lr: 9.1749e-06  eta: 16:35:16  time: 0.4067  data_time: 0.0086  memory: 5969  grad_norm: 605.9913  loss: 27.8124  decode.loss_cls: 0.5152  decode.loss_mask: 1.3913  decode.loss_dice: 0.9632  decode.d0.loss_cls: 0.8850  decode.d0.loss_mask: 1.2155  decode.d0.loss_dice: 0.9108  decode.d1.loss_cls: 0.4788  decode.d1.loss_mask: 1.2807  decode.d1.loss_dice: 0.8712  decode.d2.loss_cls: 0.5026  decode.d2.loss_mask: 1.3095  decode.d2.loss_dice: 0.8836  decode.d3.loss_cls: 0.4754  decode.d3.loss_mask: 1.2968  decode.d3.loss_dice: 0.9101  decode.d4.loss_cls: 0.5123  decode.d4.loss_mask: 1.3074  decode.d4.loss_dice: 0.9131  decode.d5.loss_cls: 0.4773  decode.d5.loss_mask: 1.3371  decode.d5.loss_dice: 0.9553  decode.d6.loss_cls: 0.5195  decode.d6.loss_mask: 1.3327  decode.d6.loss_dice: 0.9587  decode.d7.loss_cls: 0.5034  decode.d7.loss_mask: 1.3072  decode.d7.loss_dice: 0.9253  decode.d8.loss_cls: 0.5311  decode.d8.loss_mask: 1.3696  decode.d8.loss_dice: 0.9725
05/26 12:37:06 - mmengine - INFO - Iter(train) [ 14650/160000]  base_lr: 9.1721e-05 lr: 9.1721e-06  eta: 16:34:54  time: 0.4057  data_time: 0.0087  memory: 5981  grad_norm: 516.8290  loss: 25.2433  decode.loss_cls: 0.3100  decode.loss_mask: 1.2453  decode.loss_dice: 0.8595  decode.d0.loss_cls: 0.7869  decode.d0.loss_mask: 1.2157  decode.d0.loss_dice: 0.8471  decode.d1.loss_cls: 0.3653  decode.d1.loss_mask: 1.2771  decode.d1.loss_dice: 0.8775  decode.d2.loss_cls: 0.3650  decode.d2.loss_mask: 1.2478  decode.d2.loss_dice: 0.8361  decode.d3.loss_cls: 0.3693  decode.d3.loss_mask: 1.2766  decode.d3.loss_dice: 0.8571  decode.d4.loss_cls: 0.3897  decode.d4.loss_mask: 1.2895  decode.d4.loss_dice: 0.8552  decode.d5.loss_cls: 0.3985  decode.d5.loss_mask: 1.2678  decode.d5.loss_dice: 0.8697  decode.d6.loss_cls: 0.4051  decode.d6.loss_mask: 1.2409  decode.d6.loss_dice: 0.8471  decode.d7.loss_cls: 0.3815  decode.d7.loss_mask: 1.2405  decode.d7.loss_dice: 0.8397  decode.d8.loss_cls: 0.3616  decode.d8.loss_mask: 1.2592  decode.d8.loss_dice: 0.8611
05/26 12:37:26 - mmengine - INFO - Iter(train) [ 14700/160000]  base_lr: 9.1692e-05 lr: 9.1692e-06  eta: 16:34:31  time: 0.4061  data_time: 0.0086  memory: 5976  grad_norm: 592.3001  loss: 32.8473  decode.loss_cls: 0.6394  decode.loss_mask: 1.4624  decode.loss_dice: 1.0557  decode.d0.loss_cls: 1.0228  decode.d0.loss_mask: 1.4836  decode.d0.loss_dice: 1.0788  decode.d1.loss_cls: 0.6877  decode.d1.loss_mask: 1.4509  decode.d1.loss_dice: 1.0730  decode.d2.loss_cls: 0.6837  decode.d2.loss_mask: 1.4699  decode.d2.loss_dice: 1.0898  decode.d3.loss_cls: 0.6750  decode.d3.loss_mask: 1.4023  decode.d3.loss_dice: 1.0737  decode.d4.loss_cls: 0.6708  decode.d4.loss_mask: 1.5336  decode.d4.loss_dice: 1.0850  decode.d5.loss_cls: 0.6336  decode.d5.loss_mask: 1.5465  decode.d5.loss_dice: 1.1358  decode.d6.loss_cls: 0.7294  decode.d6.loss_mask: 1.4951  decode.d6.loss_dice: 1.0849  decode.d7.loss_cls: 0.6630  decode.d7.loss_mask: 1.5183  decode.d7.loss_dice: 1.1345  decode.d8.loss_cls: 0.6689  decode.d8.loss_mask: 1.5225  decode.d8.loss_dice: 1.0765
05/26 12:37:47 - mmengine - INFO - Iter(train) [ 14750/160000]  base_lr: 9.1664e-05 lr: 9.1664e-06  eta: 16:34:09  time: 0.4071  data_time: 0.0087  memory: 5973  grad_norm: 782.3666  loss: 27.7393  decode.loss_cls: 0.3903  decode.loss_mask: 1.3058  decode.loss_dice: 1.0082  decode.d0.loss_cls: 0.8291  decode.d0.loss_mask: 1.2960  decode.d0.loss_dice: 0.9830  decode.d1.loss_cls: 0.4474  decode.d1.loss_mask: 1.2939  decode.d1.loss_dice: 0.9694  decode.d2.loss_cls: 0.4767  decode.d2.loss_mask: 1.2944  decode.d2.loss_dice: 0.9878  decode.d3.loss_cls: 0.4568  decode.d3.loss_mask: 1.3009  decode.d3.loss_dice: 0.9322  decode.d4.loss_cls: 0.4572  decode.d4.loss_mask: 1.3016  decode.d4.loss_dice: 0.9705  decode.d5.loss_cls: 0.4375  decode.d5.loss_mask: 1.3012  decode.d5.loss_dice: 0.9934  decode.d6.loss_cls: 0.4157  decode.d6.loss_mask: 1.3206  decode.d6.loss_dice: 1.0244  decode.d7.loss_cls: 0.4235  decode.d7.loss_mask: 1.3353  decode.d7.loss_dice: 1.0502  decode.d8.loss_cls: 0.4207  decode.d8.loss_mask: 1.3107  decode.d8.loss_dice: 1.0047
05/26 12:38:07 - mmengine - INFO - Iter(train) [ 14800/160000]  base_lr: 9.1636e-05 lr: 9.1636e-06  eta: 16:33:47  time: 0.4070  data_time: 0.0087  memory: 5965  grad_norm: 832.6551  loss: 25.7540  decode.loss_cls: 0.4063  decode.loss_mask: 1.2322  decode.loss_dice: 0.9223  decode.d0.loss_cls: 0.8074  decode.d0.loss_mask: 1.1031  decode.d0.loss_dice: 0.8641  decode.d1.loss_cls: 0.4203  decode.d1.loss_mask: 1.1725  decode.d1.loss_dice: 0.8845  decode.d2.loss_cls: 0.4290  decode.d2.loss_mask: 1.2087  decode.d2.loss_dice: 0.9351  decode.d3.loss_cls: 0.4332  decode.d3.loss_mask: 1.2562  decode.d3.loss_dice: 0.9116  decode.d4.loss_cls: 0.4521  decode.d4.loss_mask: 1.2149  decode.d4.loss_dice: 0.9067  decode.d5.loss_cls: 0.4268  decode.d5.loss_mask: 1.1964  decode.d5.loss_dice: 0.9357  decode.d6.loss_cls: 0.3667  decode.d6.loss_mask: 1.2600  decode.d6.loss_dice: 0.9130  decode.d7.loss_cls: 0.4280  decode.d7.loss_mask: 1.2144  decode.d7.loss_dice: 0.9379  decode.d8.loss_cls: 0.4001  decode.d8.loss_mask: 1.2156  decode.d8.loss_dice: 0.8994
05/26 12:38:28 - mmengine - INFO - Iter(train) [ 14850/160000]  base_lr: 9.1607e-05 lr: 9.1607e-06  eta: 16:33:25  time: 0.4090  data_time: 0.0106  memory: 5968  grad_norm: 613.0006  loss: 31.6863  decode.loss_cls: 0.3813  decode.loss_mask: 1.5515  decode.loss_dice: 1.1584  decode.d0.loss_cls: 0.8134  decode.d0.loss_mask: 1.4868  decode.d0.loss_dice: 1.1168  decode.d1.loss_cls: 0.3955  decode.d1.loss_mask: 1.5746  decode.d1.loss_dice: 1.1510  decode.d2.loss_cls: 0.4082  decode.d2.loss_mask: 1.5440  decode.d2.loss_dice: 1.1565  decode.d3.loss_cls: 0.3876  decode.d3.loss_mask: 1.5595  decode.d3.loss_dice: 1.1881  decode.d4.loss_cls: 0.3938  decode.d4.loss_mask: 1.6087  decode.d4.loss_dice: 1.2275  decode.d5.loss_cls: 0.3623  decode.d5.loss_mask: 1.6232  decode.d5.loss_dice: 1.2162  decode.d6.loss_cls: 0.3081  decode.d6.loss_mask: 1.6344  decode.d6.loss_dice: 1.2184  decode.d7.loss_cls: 0.2531  decode.d7.loss_mask: 1.6426  decode.d7.loss_dice: 1.2160  decode.d8.loss_cls: 0.3507  decode.d8.loss_mask: 1.5594  decode.d8.loss_dice: 1.1986
05/26 12:38:48 - mmengine - INFO - Iter(train) [ 14900/160000]  base_lr: 9.1579e-05 lr: 9.1579e-06  eta: 16:33:03  time: 0.4081  data_time: 0.0088  memory: 5979  grad_norm: 880.3786  loss: 27.8524  decode.loss_cls: 0.5005  decode.loss_mask: 1.2324  decode.loss_dice: 0.9521  decode.d0.loss_cls: 0.8273  decode.d0.loss_mask: 1.2284  decode.d0.loss_dice: 0.9614  decode.d1.loss_cls: 0.4695  decode.d1.loss_mask: 1.2419  decode.d1.loss_dice: 1.0116  decode.d2.loss_cls: 0.5215  decode.d2.loss_mask: 1.2391  decode.d2.loss_dice: 0.9891  decode.d3.loss_cls: 0.5027  decode.d3.loss_mask: 1.2827  decode.d3.loss_dice: 1.0188  decode.d4.loss_cls: 0.5564  decode.d4.loss_mask: 1.2517  decode.d4.loss_dice: 0.9998  decode.d5.loss_cls: 0.4471  decode.d5.loss_mask: 1.2944  decode.d5.loss_dice: 1.0271  decode.d6.loss_cls: 0.5464  decode.d6.loss_mask: 1.2560  decode.d6.loss_dice: 0.9901  decode.d7.loss_cls: 0.4698  decode.d7.loss_mask: 1.3188  decode.d7.loss_dice: 1.0008  decode.d8.loss_cls: 0.4844  decode.d8.loss_mask: 1.2524  decode.d8.loss_dice: 0.9782
05/26 12:39:08 - mmengine - INFO - Iter(train) [ 14950/160000]  base_lr: 9.1550e-05 lr: 9.1550e-06  eta: 16:32:41  time: 0.4076  data_time: 0.0086  memory: 5968  grad_norm: 640.7952  loss: 26.7822  decode.loss_cls: 0.3853  decode.loss_mask: 1.2995  decode.loss_dice: 0.9356  decode.d0.loss_cls: 0.8355  decode.d0.loss_mask: 1.2835  decode.d0.loss_dice: 0.9312  decode.d1.loss_cls: 0.3983  decode.d1.loss_mask: 1.2721  decode.d1.loss_dice: 0.9567  decode.d2.loss_cls: 0.3953  decode.d2.loss_mask: 1.2598  decode.d2.loss_dice: 0.9226  decode.d3.loss_cls: 0.3854  decode.d3.loss_mask: 1.3047  decode.d3.loss_dice: 0.9345  decode.d4.loss_cls: 0.4285  decode.d4.loss_mask: 1.2789  decode.d4.loss_dice: 0.9156  decode.d5.loss_cls: 0.4545  decode.d5.loss_mask: 1.2629  decode.d5.loss_dice: 0.9422  decode.d6.loss_cls: 0.4618  decode.d6.loss_mask: 1.3243  decode.d6.loss_dice: 0.9703  decode.d7.loss_cls: 0.3670  decode.d7.loss_mask: 1.2946  decode.d7.loss_dice: 0.9373  decode.d8.loss_cls: 0.3546  decode.d8.loss_mask: 1.3110  decode.d8.loss_dice: 0.9789
05/26 12:39:29 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 12:39:29 - mmengine - INFO - Iter(train) [ 15000/160000]  base_lr: 9.1522e-05 lr: 9.1522e-06  eta: 16:32:19  time: 0.4064  data_time: 0.0087  memory: 5972  grad_norm: 649.0616  loss: 32.2459  decode.loss_cls: 0.5571  decode.loss_mask: 1.4475  decode.loss_dice: 1.1598  decode.d0.loss_cls: 0.9870  decode.d0.loss_mask: 1.4120  decode.d0.loss_dice: 1.1713  decode.d1.loss_cls: 0.5443  decode.d1.loss_mask: 1.4791  decode.d1.loss_dice: 1.1449  decode.d2.loss_cls: 0.5774  decode.d2.loss_mask: 1.4427  decode.d2.loss_dice: 1.1408  decode.d3.loss_cls: 0.5897  decode.d3.loss_mask: 1.4386  decode.d3.loss_dice: 1.0966  decode.d4.loss_cls: 0.6227  decode.d4.loss_mask: 1.4018  decode.d4.loss_dice: 1.1364  decode.d5.loss_cls: 0.6062  decode.d5.loss_mask: 1.4871  decode.d5.loss_dice: 1.1307  decode.d6.loss_cls: 0.6521  decode.d6.loss_mask: 1.4126  decode.d6.loss_dice: 1.1876  decode.d7.loss_cls: 0.5316  decode.d7.loss_mask: 1.4841  decode.d7.loss_dice: 1.2206  decode.d8.loss_cls: 0.5278  decode.d8.loss_mask: 1.4870  decode.d8.loss_dice: 1.1688
05/26 12:39:29 - mmengine - INFO - Saving checkpoint at 15000 iterations
05/26 12:39:33 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:10  time: 0.0487  data_time: 0.0012  memory: 1391  
05/26 12:39:35 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:06  time: 0.0481  data_time: 0.0012  memory: 1205  
05/26 12:39:38 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:04  time: 0.0506  data_time: 0.0012  memory: 1596  
05/26 12:39:40 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:01  time: 0.0490  data_time: 0.0012  memory: 1298  
05/26 12:39:43 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:58  time: 0.0482  data_time: 0.0012  memory: 1298  
05/26 12:39:45 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:56  time: 0.0484  data_time: 0.0012  memory: 1279  
05/26 12:39:48 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:54  time: 0.0482  data_time: 0.0013  memory: 1224  
05/26 12:39:50 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:51  time: 0.0499  data_time: 0.0012  memory: 1298  
05/26 12:39:53 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:49  time: 0.0481  data_time: 0.0012  memory: 1298  
05/26 12:39:55 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:46  time: 0.0520  data_time: 0.0012  memory: 1725  
05/26 12:39:58 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:44  time: 0.0487  data_time: 0.0012  memory: 1336  
05/26 12:40:00 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:41  time: 0.0487  data_time: 0.0012  memory: 1298  
05/26 12:40:02 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:39  time: 0.0490  data_time: 0.0012  memory: 1205  
05/26 12:40:05 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0497  data_time: 0.0012  memory: 1316  
05/26 12:40:07 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:34  time: 0.0484  data_time: 0.0012  memory: 1279  
05/26 12:40:10 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0519  data_time: 0.0012  memory: 1410  
05/26 12:40:12 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:29  time: 0.0495  data_time: 0.0012  memory: 1279  
05/26 12:40:15 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0492  data_time: 0.0012  memory: 1205  
05/26 12:40:17 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0502  data_time: 0.0012  memory: 1205  
05/26 12:40:20 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:22  time: 0.0487  data_time: 0.0013  memory: 1336  
05/26 12:40:22 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0507  data_time: 0.0012  memory: 1246  
05/26 12:40:25 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0507  data_time: 0.0012  memory: 1503  
05/26 12:40:27 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0518  data_time: 0.0029  memory: 1261  
05/26 12:40:30 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0495  data_time: 0.0013  memory: 1298  
05/26 12:40:32 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0515  data_time: 0.0012  memory: 1447  
05/26 12:40:34 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0484  data_time: 0.0013  memory: 1298  
05/26 12:40:37 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0509  data_time: 0.0012  memory: 1279  
05/26 12:40:39 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0487  data_time: 0.0012  memory: 1205  
05/26 12:40:42 - mmengine - INFO - per class results:
05/26 12:40:42 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 93.08 | 95.38 |
|  aeroplane  | 86.98 | 96.19 |
|   bicycle   | 38.66 | 81.33 |
|     bird    | 79.81 | 92.43 |
|     boat    | 49.77 | 84.11 |
|    bottle   | 54.73 | 83.27 |
|     bus     | 74.54 | 76.65 |
|     car     | 83.11 | 93.03 |
|     cat     | 51.56 | 52.96 |
|    chair    | 29.98 | 37.56 |
|     cow     |  0.0  |  0.0  |
| diningtable | 35.03 | 76.77 |
|     dog     | 50.24 | 80.07 |
|    horse    |  37.6 | 94.68 |
|  motorbike  | 77.74 | 93.84 |
|    person   | 85.37 | 91.82 |
| pottedplant | 30.23 | 44.92 |
|    sheep    |  49.1 | 64.28 |
|     sofa    | 35.49 | 41.62 |
|    train    | 69.07 | 90.74 |
|  tvmonitor  | 58.85 | 79.56 |
+-------------+-------+-------+
05/26 12:40:42 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 89.9500  mIoU: 55.7600  mAcc: 73.8700  data_time: 0.0013  time: 0.0491
05/26 12:40:42 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_10000.pth is removed
05/26 12:40:43 - mmengine - INFO - The best checkpoint with 55.7600 mIoU at 15000 iter is saved to best_mIoU_iter_15000.pth.
05/26 12:41:05 - mmengine - INFO - Iter(train) [ 15050/160000]  base_lr: 9.1494e-05 lr: 9.1494e-06  eta: 16:32:25  time: 0.4101  data_time: 0.0087  memory: 5971  grad_norm: 480.5898  loss: 25.4200  decode.loss_cls: 0.3868  decode.loss_mask: 1.1373  decode.loss_dice: 0.9118  decode.d0.loss_cls: 0.8708  decode.d0.loss_mask: 1.1145  decode.d0.loss_dice: 0.9182  decode.d1.loss_cls: 0.4762  decode.d1.loss_mask: 1.1513  decode.d1.loss_dice: 0.8848  decode.d2.loss_cls: 0.4546  decode.d2.loss_mask: 1.1423  decode.d2.loss_dice: 0.8709  decode.d3.loss_cls: 0.4671  decode.d3.loss_mask: 1.1323  decode.d3.loss_dice: 0.8634  decode.d4.loss_cls: 0.4818  decode.d4.loss_mask: 1.1431  decode.d4.loss_dice: 0.8836  decode.d5.loss_cls: 0.4673  decode.d5.loss_mask: 1.1737  decode.d5.loss_dice: 0.9221  decode.d6.loss_cls: 0.5174  decode.d6.loss_mask: 1.1487  decode.d6.loss_dice: 0.9132  decode.d7.loss_cls: 0.4380  decode.d7.loss_mask: 1.1390  decode.d7.loss_dice: 0.9158  decode.d8.loss_cls: 0.4686  decode.d8.loss_mask: 1.1214  decode.d8.loss_dice: 0.9039
05/26 12:41:25 - mmengine - INFO - Iter(train) [ 15100/160000]  base_lr: 9.1465e-05 lr: 9.1465e-06  eta: 16:32:03  time: 0.4091  data_time: 0.0087  memory: 5968  grad_norm: 463.9535  loss: 25.5096  decode.loss_cls: 0.3888  decode.loss_mask: 1.2083  decode.loss_dice: 0.9357  decode.d0.loss_cls: 0.7949  decode.d0.loss_mask: 1.1496  decode.d0.loss_dice: 0.9307  decode.d1.loss_cls: 0.3674  decode.d1.loss_mask: 1.1834  decode.d1.loss_dice: 0.9704  decode.d2.loss_cls: 0.3733  decode.d2.loss_mask: 1.1875  decode.d2.loss_dice: 0.9363  decode.d3.loss_cls: 0.3403  decode.d3.loss_mask: 1.1652  decode.d3.loss_dice: 0.9422  decode.d4.loss_cls: 0.3681  decode.d4.loss_mask: 1.1946  decode.d4.loss_dice: 0.9199  decode.d5.loss_cls: 0.3569  decode.d5.loss_mask: 1.1870  decode.d5.loss_dice: 0.9545  decode.d6.loss_cls: 0.4065  decode.d6.loss_mask: 1.1817  decode.d6.loss_dice: 0.9460  decode.d7.loss_cls: 0.4217  decode.d7.loss_mask: 1.2014  decode.d7.loss_dice: 0.9333  decode.d8.loss_cls: 0.3971  decode.d8.loss_mask: 1.2136  decode.d8.loss_dice: 0.9532
05/26 12:41:46 - mmengine - INFO - Iter(train) [ 15150/160000]  base_lr: 9.1437e-05 lr: 9.1437e-06  eta: 16:31:41  time: 0.4077  data_time: 0.0087  memory: 5991  grad_norm: 638.9683  loss: 26.1453  decode.loss_cls: 0.4059  decode.loss_mask: 1.1981  decode.loss_dice: 0.9251  decode.d0.loss_cls: 0.8961  decode.d0.loss_mask: 1.1391  decode.d0.loss_dice: 0.8905  decode.d1.loss_cls: 0.5047  decode.d1.loss_mask: 1.1568  decode.d1.loss_dice: 0.8962  decode.d2.loss_cls: 0.4488  decode.d2.loss_mask: 1.1939  decode.d2.loss_dice: 0.9238  decode.d3.loss_cls: 0.4899  decode.d3.loss_mask: 1.2253  decode.d3.loss_dice: 0.9374  decode.d4.loss_cls: 0.5198  decode.d4.loss_mask: 1.1647  decode.d4.loss_dice: 0.9200  decode.d5.loss_cls: 0.4443  decode.d5.loss_mask: 1.2234  decode.d5.loss_dice: 0.9479  decode.d6.loss_cls: 0.4783  decode.d6.loss_mask: 1.1928  decode.d6.loss_dice: 0.9291  decode.d7.loss_cls: 0.4797  decode.d7.loss_mask: 1.1842  decode.d7.loss_dice: 0.9138  decode.d8.loss_cls: 0.4111  decode.d8.loss_mask: 1.1737  decode.d8.loss_dice: 0.9309
05/26 12:42:06 - mmengine - INFO - Iter(train) [ 15200/160000]  base_lr: 9.1408e-05 lr: 9.1408e-06  eta: 16:31:20  time: 0.4079  data_time: 0.0089  memory: 5971  grad_norm: 1033.9203  loss: 28.5846  decode.loss_cls: 0.4362  decode.loss_mask: 1.3427  decode.loss_dice: 1.0259  decode.d0.loss_cls: 0.8873  decode.d0.loss_mask: 1.1994  decode.d0.loss_dice: 0.9935  decode.d1.loss_cls: 0.4965  decode.d1.loss_mask: 1.3076  decode.d1.loss_dice: 0.9702  decode.d2.loss_cls: 0.5240  decode.d2.loss_mask: 1.3192  decode.d2.loss_dice: 0.9767  decode.d3.loss_cls: 0.4645  decode.d3.loss_mask: 1.3179  decode.d3.loss_dice: 1.0245  decode.d4.loss_cls: 0.5064  decode.d4.loss_mask: 1.3950  decode.d4.loss_dice: 0.9942  decode.d5.loss_cls: 0.5031  decode.d5.loss_mask: 1.3092  decode.d5.loss_dice: 1.0277  decode.d6.loss_cls: 0.5533  decode.d6.loss_mask: 1.2932  decode.d6.loss_dice: 1.0288  decode.d7.loss_cls: 0.4899  decode.d7.loss_mask: 1.3738  decode.d7.loss_dice: 1.0209  decode.d8.loss_cls: 0.4130  decode.d8.loss_mask: 1.3651  decode.d8.loss_dice: 1.0249
05/26 12:42:27 - mmengine - INFO - Iter(train) [ 15250/160000]  base_lr: 9.1380e-05 lr: 9.1380e-06  eta: 16:30:59  time: 0.4076  data_time: 0.0087  memory: 5967  grad_norm: 871.9492  loss: 29.3291  decode.loss_cls: 0.5890  decode.loss_mask: 1.2098  decode.loss_dice: 1.0622  decode.d0.loss_cls: 0.9286  decode.d0.loss_mask: 1.1813  decode.d0.loss_dice: 1.0527  decode.d1.loss_cls: 0.6330  decode.d1.loss_mask: 1.1685  decode.d1.loss_dice: 1.0129  decode.d2.loss_cls: 0.6059  decode.d2.loss_mask: 1.2401  decode.d2.loss_dice: 1.0312  decode.d3.loss_cls: 0.7006  decode.d3.loss_mask: 1.2366  decode.d3.loss_dice: 1.0456  decode.d4.loss_cls: 0.6597  decode.d4.loss_mask: 1.2403  decode.d4.loss_dice: 1.0534  decode.d5.loss_cls: 0.5896  decode.d5.loss_mask: 1.3012  decode.d5.loss_dice: 1.0760  decode.d6.loss_cls: 0.6170  decode.d6.loss_mask: 1.2287  decode.d6.loss_dice: 1.0693  decode.d7.loss_cls: 0.5590  decode.d7.loss_mask: 1.2429  decode.d7.loss_dice: 1.1047  decode.d8.loss_cls: 0.5848  decode.d8.loss_mask: 1.2115  decode.d8.loss_dice: 1.0928
05/26 12:42:47 - mmengine - INFO - Iter(train) [ 15300/160000]  base_lr: 9.1352e-05 lr: 9.1352e-06  eta: 16:30:38  time: 0.4085  data_time: 0.0088  memory: 5969  grad_norm: 940.4472  loss: 30.3666  decode.loss_cls: 0.5406  decode.loss_mask: 1.4380  decode.loss_dice: 1.0769  decode.d0.loss_cls: 0.9078  decode.d0.loss_mask: 1.3834  decode.d0.loss_dice: 1.0694  decode.d1.loss_cls: 0.4637  decode.d1.loss_mask: 1.4555  decode.d1.loss_dice: 1.0458  decode.d2.loss_cls: 0.5221  decode.d2.loss_mask: 1.4040  decode.d2.loss_dice: 0.9952  decode.d3.loss_cls: 0.5037  decode.d3.loss_mask: 1.4591  decode.d3.loss_dice: 1.0552  decode.d4.loss_cls: 0.4974  decode.d4.loss_mask: 1.4111  decode.d4.loss_dice: 1.0621  decode.d5.loss_cls: 0.5077  decode.d5.loss_mask: 1.4228  decode.d5.loss_dice: 1.0860  decode.d6.loss_cls: 0.4646  decode.d6.loss_mask: 1.4504  decode.d6.loss_dice: 1.0646  decode.d7.loss_cls: 0.4796  decode.d7.loss_mask: 1.4102  decode.d7.loss_dice: 1.0290  decode.d8.loss_cls: 0.5368  decode.d8.loss_mask: 1.5182  decode.d8.loss_dice: 1.1056
05/26 12:43:08 - mmengine - INFO - Iter(train) [ 15350/160000]  base_lr: 9.1323e-05 lr: 9.1323e-06  eta: 16:30:16  time: 0.4076  data_time: 0.0088  memory: 5966  grad_norm: 669.0050  loss: 27.4352  decode.loss_cls: 0.4620  decode.loss_mask: 1.2660  decode.loss_dice: 0.8788  decode.d0.loss_cls: 0.9178  decode.d0.loss_mask: 1.1766  decode.d0.loss_dice: 0.8619  decode.d1.loss_cls: 0.5410  decode.d1.loss_mask: 1.3913  decode.d1.loss_dice: 0.9203  decode.d2.loss_cls: 0.5490  decode.d2.loss_mask: 1.1843  decode.d2.loss_dice: 0.8666  decode.d3.loss_cls: 0.5137  decode.d3.loss_mask: 1.3240  decode.d3.loss_dice: 0.9167  decode.d4.loss_cls: 0.5173  decode.d4.loss_mask: 1.2439  decode.d4.loss_dice: 0.9000  decode.d5.loss_cls: 0.5591  decode.d5.loss_mask: 1.3258  decode.d5.loss_dice: 0.9292  decode.d6.loss_cls: 0.5622  decode.d6.loss_mask: 1.3749  decode.d6.loss_dice: 0.9202  decode.d7.loss_cls: 0.5638  decode.d7.loss_mask: 1.2070  decode.d7.loss_dice: 0.9446  decode.d8.loss_cls: 0.5049  decode.d8.loss_mask: 1.2163  decode.d8.loss_dice: 0.8962
05/26 12:43:28 - mmengine - INFO - Iter(train) [ 15400/160000]  base_lr: 9.1295e-05 lr: 9.1295e-06  eta: 16:29:54  time: 0.4076  data_time: 0.0088  memory: 5968  grad_norm: 1055.4287  loss: 30.7706  decode.loss_cls: 0.4907  decode.loss_mask: 1.4304  decode.loss_dice: 1.1464  decode.d0.loss_cls: 0.9698  decode.d0.loss_mask: 1.3525  decode.d0.loss_dice: 1.0625  decode.d1.loss_cls: 0.5201  decode.d1.loss_mask: 1.3519  decode.d1.loss_dice: 1.0798  decode.d2.loss_cls: 0.5439  decode.d2.loss_mask: 1.3865  decode.d2.loss_dice: 1.0762  decode.d3.loss_cls: 0.5847  decode.d3.loss_mask: 1.4056  decode.d3.loss_dice: 1.1081  decode.d4.loss_cls: 0.5866  decode.d4.loss_mask: 1.3672  decode.d4.loss_dice: 1.0457  decode.d5.loss_cls: 0.5509  decode.d5.loss_mask: 1.4098  decode.d5.loss_dice: 1.1456  decode.d6.loss_cls: 0.5723  decode.d6.loss_mask: 1.4213  decode.d6.loss_dice: 1.1463  decode.d7.loss_cls: 0.5197  decode.d7.loss_mask: 1.4244  decode.d7.loss_dice: 1.0803  decode.d8.loss_cls: 0.4855  decode.d8.loss_mask: 1.3890  decode.d8.loss_dice: 1.1167
05/26 12:43:48 - mmengine - INFO - Iter(train) [ 15450/160000]  base_lr: 9.1266e-05 lr: 9.1266e-06  eta: 16:29:33  time: 0.4080  data_time: 0.0088  memory: 5989  grad_norm: 683.5169  loss: 26.3830  decode.loss_cls: 0.3329  decode.loss_mask: 1.3401  decode.loss_dice: 0.8860  decode.d0.loss_cls: 0.8224  decode.d0.loss_mask: 1.2182  decode.d0.loss_dice: 0.8495  decode.d1.loss_cls: 0.3543  decode.d1.loss_mask: 1.3808  decode.d1.loss_dice: 0.8836  decode.d2.loss_cls: 0.3129  decode.d2.loss_mask: 1.3813  decode.d2.loss_dice: 0.9043  decode.d3.loss_cls: 0.3269  decode.d3.loss_mask: 1.3878  decode.d3.loss_dice: 0.8925  decode.d4.loss_cls: 0.3780  decode.d4.loss_mask: 1.3817  decode.d4.loss_dice: 0.9107  decode.d5.loss_cls: 0.3160  decode.d5.loss_mask: 1.3910  decode.d5.loss_dice: 0.9141  decode.d6.loss_cls: 0.3681  decode.d6.loss_mask: 1.3478  decode.d6.loss_dice: 0.8931  decode.d7.loss_cls: 0.3928  decode.d7.loss_mask: 1.3572  decode.d7.loss_dice: 0.9083  decode.d8.loss_cls: 0.2976  decode.d8.loss_mask: 1.3642  decode.d8.loss_dice: 0.8891
05/26 12:44:09 - mmengine - INFO - Iter(train) [ 15500/160000]  base_lr: 9.1238e-05 lr: 9.1238e-06  eta: 16:29:11  time: 0.4073  data_time: 0.0088  memory: 5967  grad_norm: 706.2406  loss: 31.2243  decode.loss_cls: 0.4721  decode.loss_mask: 1.4918  decode.loss_dice: 1.1020  decode.d0.loss_cls: 1.0674  decode.d0.loss_mask: 1.4114  decode.d0.loss_dice: 1.0256  decode.d1.loss_cls: 0.5000  decode.d1.loss_mask: 1.5097  decode.d1.loss_dice: 1.0673  decode.d2.loss_cls: 0.4696  decode.d2.loss_mask: 1.4688  decode.d2.loss_dice: 1.1093  decode.d3.loss_cls: 0.4808  decode.d3.loss_mask: 1.4856  decode.d3.loss_dice: 1.0776  decode.d4.loss_cls: 0.5364  decode.d4.loss_mask: 1.4534  decode.d4.loss_dice: 1.0603  decode.d5.loss_cls: 0.5206  decode.d5.loss_mask: 1.4612  decode.d5.loss_dice: 1.0620  decode.d6.loss_cls: 0.5830  decode.d6.loss_mask: 1.5211  decode.d6.loss_dice: 1.0730  decode.d7.loss_cls: 0.5211  decode.d7.loss_mask: 1.5240  decode.d7.loss_dice: 1.0764  decode.d8.loss_cls: 0.4751  decode.d8.loss_mask: 1.4819  decode.d8.loss_dice: 1.1358
05/26 12:44:29 - mmengine - INFO - Iter(train) [ 15550/160000]  base_lr: 9.1210e-05 lr: 9.1210e-06  eta: 16:28:49  time: 0.4081  data_time: 0.0088  memory: 5966  grad_norm: 688.5525  loss: 24.1768  decode.loss_cls: 0.3724  decode.loss_mask: 1.2167  decode.loss_dice: 0.7886  decode.d0.loss_cls: 0.7841  decode.d0.loss_mask: 1.1562  decode.d0.loss_dice: 0.7623  decode.d1.loss_cls: 0.3641  decode.d1.loss_mask: 1.2066  decode.d1.loss_dice: 0.7815  decode.d2.loss_cls: 0.3186  decode.d2.loss_mask: 1.2371  decode.d2.loss_dice: 0.7924  decode.d3.loss_cls: 0.3360  decode.d3.loss_mask: 1.2688  decode.d3.loss_dice: 0.7959  decode.d4.loss_cls: 0.3426  decode.d4.loss_mask: 1.2436  decode.d4.loss_dice: 0.7966  decode.d5.loss_cls: 0.3279  decode.d5.loss_mask: 1.2593  decode.d5.loss_dice: 0.8147  decode.d6.loss_cls: 0.3656  decode.d6.loss_mask: 1.2850  decode.d6.loss_dice: 0.8054  decode.d7.loss_cls: 0.3298  decode.d7.loss_mask: 1.2556  decode.d7.loss_dice: 0.7807  decode.d8.loss_cls: 0.3937  decode.d8.loss_mask: 1.2104  decode.d8.loss_dice: 0.7845
05/26 12:44:50 - mmengine - INFO - Iter(train) [ 15600/160000]  base_lr: 9.1181e-05 lr: 9.1181e-06  eta: 16:28:28  time: 0.4084  data_time: 0.0088  memory: 5972  grad_norm: 948.0445  loss: 31.7867  decode.loss_cls: 0.4691  decode.loss_mask: 1.4865  decode.loss_dice: 1.1579  decode.d0.loss_cls: 1.0134  decode.d0.loss_mask: 1.4288  decode.d0.loss_dice: 1.0776  decode.d1.loss_cls: 0.5348  decode.d1.loss_mask: 1.4786  decode.d1.loss_dice: 1.1292  decode.d2.loss_cls: 0.5817  decode.d2.loss_mask: 1.4599  decode.d2.loss_dice: 1.1064  decode.d3.loss_cls: 0.5432  decode.d3.loss_mask: 1.4405  decode.d3.loss_dice: 1.0820  decode.d4.loss_cls: 0.5453  decode.d4.loss_mask: 1.4766  decode.d4.loss_dice: 1.1120  decode.d5.loss_cls: 0.5412  decode.d5.loss_mask: 1.4980  decode.d5.loss_dice: 1.1657  decode.d6.loss_cls: 0.5439  decode.d6.loss_mask: 1.4898  decode.d6.loss_dice: 1.0929  decode.d7.loss_cls: 0.5564  decode.d7.loss_mask: 1.4771  decode.d7.loss_dice: 1.1429  decode.d8.loss_cls: 0.5430  decode.d8.loss_mask: 1.4862  decode.d8.loss_dice: 1.1260
05/26 12:45:10 - mmengine - INFO - Iter(train) [ 15650/160000]  base_lr: 9.1153e-05 lr: 9.1153e-06  eta: 16:28:06  time: 0.4071  data_time: 0.0088  memory: 5969  grad_norm: 763.7951  loss: 26.4943  decode.loss_cls: 0.4071  decode.loss_mask: 1.2202  decode.loss_dice: 0.8915  decode.d0.loss_cls: 0.9186  decode.d0.loss_mask: 1.3027  decode.d0.loss_dice: 0.9553  decode.d1.loss_cls: 0.4217  decode.d1.loss_mask: 1.2584  decode.d1.loss_dice: 0.8913  decode.d2.loss_cls: 0.4593  decode.d2.loss_mask: 1.2960  decode.d2.loss_dice: 0.9163  decode.d3.loss_cls: 0.4402  decode.d3.loss_mask: 1.2566  decode.d3.loss_dice: 0.8697  decode.d4.loss_cls: 0.4731  decode.d4.loss_mask: 1.2384  decode.d4.loss_dice: 0.8962  decode.d5.loss_cls: 0.4792  decode.d5.loss_mask: 1.1935  decode.d5.loss_dice: 0.8985  decode.d6.loss_cls: 0.4488  decode.d6.loss_mask: 1.2718  decode.d6.loss_dice: 0.9094  decode.d7.loss_cls: 0.3917  decode.d7.loss_mask: 1.3067  decode.d7.loss_dice: 0.9199  decode.d8.loss_cls: 0.4418  decode.d8.loss_mask: 1.2154  decode.d8.loss_dice: 0.9051
05/26 12:45:31 - mmengine - INFO - Iter(train) [ 15700/160000]  base_lr: 9.1124e-05 lr: 9.1124e-06  eta: 16:27:44  time: 0.4068  data_time: 0.0088  memory: 5979  grad_norm: 754.1794  loss: 32.3617  decode.loss_cls: 0.5093  decode.loss_mask: 1.4317  decode.loss_dice: 1.1681  decode.d0.loss_cls: 0.9439  decode.d0.loss_mask: 1.4313  decode.d0.loss_dice: 1.1752  decode.d1.loss_cls: 0.4807  decode.d1.loss_mask: 1.4625  decode.d1.loss_dice: 1.1509  decode.d2.loss_cls: 0.5157  decode.d2.loss_mask: 1.5519  decode.d2.loss_dice: 1.2295  decode.d3.loss_cls: 0.5152  decode.d3.loss_mask: 1.5079  decode.d3.loss_dice: 1.1999  decode.d4.loss_cls: 0.5445  decode.d4.loss_mask: 1.5067  decode.d4.loss_dice: 1.1974  decode.d5.loss_cls: 0.5177  decode.d5.loss_mask: 1.4914  decode.d5.loss_dice: 1.2277  decode.d6.loss_cls: 0.5107  decode.d6.loss_mask: 1.4576  decode.d6.loss_dice: 1.2162  decode.d7.loss_cls: 0.5149  decode.d7.loss_mask: 1.5079  decode.d7.loss_dice: 1.1867  decode.d8.loss_cls: 0.4460  decode.d8.loss_mask: 1.5338  decode.d8.loss_dice: 1.2287
05/26 12:45:51 - mmengine - INFO - Iter(train) [ 15750/160000]  base_lr: 9.1096e-05 lr: 9.1096e-06  eta: 16:27:23  time: 0.4080  data_time: 0.0087  memory: 5967  grad_norm: 898.7082  loss: 28.4105  decode.loss_cls: 0.4842  decode.loss_mask: 1.3130  decode.loss_dice: 1.0119  decode.d0.loss_cls: 1.0270  decode.d0.loss_mask: 1.1943  decode.d0.loss_dice: 0.9356  decode.d1.loss_cls: 0.4805  decode.d1.loss_mask: 1.3206  decode.d1.loss_dice: 1.0219  decode.d2.loss_cls: 0.4647  decode.d2.loss_mask: 1.3126  decode.d2.loss_dice: 0.9841  decode.d3.loss_cls: 0.5445  decode.d3.loss_mask: 1.2877  decode.d3.loss_dice: 0.9930  decode.d4.loss_cls: 0.5203  decode.d4.loss_mask: 1.2799  decode.d4.loss_dice: 0.9813  decode.d5.loss_cls: 0.5135  decode.d5.loss_mask: 1.2766  decode.d5.loss_dice: 0.9834  decode.d6.loss_cls: 0.5603  decode.d6.loss_mask: 1.3003  decode.d6.loss_dice: 1.0067  decode.d7.loss_cls: 0.5127  decode.d7.loss_mask: 1.3056  decode.d7.loss_dice: 0.9818  decode.d8.loss_cls: 0.4913  decode.d8.loss_mask: 1.3139  decode.d8.loss_dice: 1.0073
05/26 12:46:11 - mmengine - INFO - Iter(train) [ 15800/160000]  base_lr: 9.1067e-05 lr: 9.1067e-06  eta: 16:27:01  time: 0.4072  data_time: 0.0087  memory: 5968  grad_norm: 507.8756  loss: 28.3437  decode.loss_cls: 0.4083  decode.loss_mask: 1.3372  decode.loss_dice: 1.0182  decode.d0.loss_cls: 0.9096  decode.d0.loss_mask: 1.2307  decode.d0.loss_dice: 0.9687  decode.d1.loss_cls: 0.5202  decode.d1.loss_mask: 1.3319  decode.d1.loss_dice: 1.0114  decode.d2.loss_cls: 0.4638  decode.d2.loss_mask: 1.2801  decode.d2.loss_dice: 1.0205  decode.d3.loss_cls: 0.4928  decode.d3.loss_mask: 1.2790  decode.d3.loss_dice: 0.9796  decode.d4.loss_cls: 0.5177  decode.d4.loss_mask: 1.2864  decode.d4.loss_dice: 0.9821  decode.d5.loss_cls: 0.5352  decode.d5.loss_mask: 1.3204  decode.d5.loss_dice: 1.0064  decode.d6.loss_cls: 0.4785  decode.d6.loss_mask: 1.3587  decode.d6.loss_dice: 1.0415  decode.d7.loss_cls: 0.4635  decode.d7.loss_mask: 1.2927  decode.d7.loss_dice: 0.9817  decode.d8.loss_cls: 0.5279  decode.d8.loss_mask: 1.2648  decode.d8.loss_dice: 1.0342
05/26 12:46:32 - mmengine - INFO - Iter(train) [ 15850/160000]  base_lr: 9.1039e-05 lr: 9.1039e-06  eta: 16:26:40  time: 0.4080  data_time: 0.0087  memory: 5966  grad_norm: 808.6838  loss: 25.9544  decode.loss_cls: 0.2334  decode.loss_mask: 1.3782  decode.loss_dice: 0.9287  decode.d0.loss_cls: 0.8101  decode.d0.loss_mask: 1.2050  decode.d0.loss_dice: 0.8535  decode.d1.loss_cls: 0.2494  decode.d1.loss_mask: 1.3734  decode.d1.loss_dice: 0.9860  decode.d2.loss_cls: 0.2850  decode.d2.loss_mask: 1.3340  decode.d2.loss_dice: 0.9182  decode.d3.loss_cls: 0.2889  decode.d3.loss_mask: 1.3219  decode.d3.loss_dice: 0.9454  decode.d4.loss_cls: 0.3446  decode.d4.loss_mask: 1.3011  decode.d4.loss_dice: 0.9181  decode.d5.loss_cls: 0.3435  decode.d5.loss_mask: 1.2998  decode.d5.loss_dice: 0.9094  decode.d6.loss_cls: 0.3448  decode.d6.loss_mask: 1.3727  decode.d6.loss_dice: 0.9199  decode.d7.loss_cls: 0.3268  decode.d7.loss_mask: 1.3139  decode.d7.loss_dice: 0.9287  decode.d8.loss_cls: 0.2775  decode.d8.loss_mask: 1.3244  decode.d8.loss_dice: 0.9184
05/26 12:46:52 - mmengine - INFO - Iter(train) [ 15900/160000]  base_lr: 9.1011e-05 lr: 9.1011e-06  eta: 16:26:18  time: 0.4088  data_time: 0.0088  memory: 5968  grad_norm: 1162.2769  loss: 34.4521  decode.loss_cls: 0.7430  decode.loss_mask: 1.5885  decode.loss_dice: 1.1601  decode.d0.loss_cls: 1.2114  decode.d0.loss_mask: 1.4752  decode.d0.loss_dice: 1.1346  decode.d1.loss_cls: 0.7107  decode.d1.loss_mask: 1.5435  decode.d1.loss_dice: 1.1450  decode.d2.loss_cls: 0.6300  decode.d2.loss_mask: 1.5867  decode.d2.loss_dice: 1.2265  decode.d3.loss_cls: 0.7261  decode.d3.loss_mask: 1.5531  decode.d3.loss_dice: 1.1717  decode.d4.loss_cls: 0.6537  decode.d4.loss_mask: 1.5240  decode.d4.loss_dice: 1.1886  decode.d5.loss_cls: 0.7002  decode.d5.loss_mask: 1.5270  decode.d5.loss_dice: 1.0960  decode.d6.loss_cls: 0.6371  decode.d6.loss_mask: 1.6263  decode.d6.loss_dice: 1.1839  decode.d7.loss_cls: 0.6847  decode.d7.loss_mask: 1.5128  decode.d7.loss_dice: 1.1519  decode.d8.loss_cls: 0.6454  decode.d8.loss_mask: 1.5450  decode.d8.loss_dice: 1.1694
05/26 12:47:13 - mmengine - INFO - Iter(train) [ 15950/160000]  base_lr: 9.0982e-05 lr: 9.0982e-06  eta: 16:25:56  time: 0.4085  data_time: 0.0088  memory: 5972  grad_norm: 737.6292  loss: 27.0261  decode.loss_cls: 0.4475  decode.loss_mask: 1.2834  decode.loss_dice: 0.9612  decode.d0.loss_cls: 0.8978  decode.d0.loss_mask: 1.1695  decode.d0.loss_dice: 0.9225  decode.d1.loss_cls: 0.3763  decode.d1.loss_mask: 1.2803  decode.d1.loss_dice: 0.9520  decode.d2.loss_cls: 0.4723  decode.d2.loss_mask: 1.2026  decode.d2.loss_dice: 0.9578  decode.d3.loss_cls: 0.4519  decode.d3.loss_mask: 1.2135  decode.d3.loss_dice: 0.9166  decode.d4.loss_cls: 0.4443  decode.d4.loss_mask: 1.2215  decode.d4.loss_dice: 0.9395  decode.d5.loss_cls: 0.4055  decode.d5.loss_mask: 1.2749  decode.d5.loss_dice: 0.9742  decode.d6.loss_cls: 0.4977  decode.d6.loss_mask: 1.2549  decode.d6.loss_dice: 0.9830  decode.d7.loss_cls: 0.4937  decode.d7.loss_mask: 1.2752  decode.d7.loss_dice: 0.9565  decode.d8.loss_cls: 0.4487  decode.d8.loss_mask: 1.3281  decode.d8.loss_dice: 1.0233
05/26 12:47:33 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 12:47:33 - mmengine - INFO - Iter(train) [ 16000/160000]  base_lr: 9.0954e-05 lr: 9.0954e-06  eta: 16:25:34  time: 0.4086  data_time: 0.0088  memory: 5982  grad_norm: 1988.8703  loss: 30.5138  decode.loss_cls: 0.5429  decode.loss_mask: 1.3811  decode.loss_dice: 1.0682  decode.d0.loss_cls: 0.9443  decode.d0.loss_mask: 1.3155  decode.d0.loss_dice: 1.0505  decode.d1.loss_cls: 0.5612  decode.d1.loss_mask: 1.3782  decode.d1.loss_dice: 1.0992  decode.d2.loss_cls: 0.5128  decode.d2.loss_mask: 1.3825  decode.d2.loss_dice: 1.0749  decode.d3.loss_cls: 0.4970  decode.d3.loss_mask: 1.4184  decode.d3.loss_dice: 1.0900  decode.d4.loss_cls: 0.5910  decode.d4.loss_mask: 1.4259  decode.d4.loss_dice: 1.0959  decode.d5.loss_cls: 0.5457  decode.d5.loss_mask: 1.4036  decode.d5.loss_dice: 1.1116  decode.d6.loss_cls: 0.6387  decode.d6.loss_mask: 1.3681  decode.d6.loss_dice: 1.0853  decode.d7.loss_cls: 0.5527  decode.d7.loss_mask: 1.3505  decode.d7.loss_dice: 1.0601  decode.d8.loss_cls: 0.5220  decode.d8.loss_mask: 1.3887  decode.d8.loss_dice: 1.0573
05/26 12:47:53 - mmengine - INFO - Iter(train) [ 16050/160000]  base_lr: 9.0925e-05 lr: 9.0925e-06  eta: 16:25:13  time: 0.4098  data_time: 0.0088  memory: 5975  grad_norm: 739.9566  loss: 28.3914  decode.loss_cls: 0.6059  decode.loss_mask: 1.2811  decode.loss_dice: 1.0277  decode.d0.loss_cls: 0.9448  decode.d0.loss_mask: 1.1691  decode.d0.loss_dice: 0.9092  decode.d1.loss_cls: 0.5382  decode.d1.loss_mask: 1.3048  decode.d1.loss_dice: 0.9716  decode.d2.loss_cls: 0.5519  decode.d2.loss_mask: 1.2642  decode.d2.loss_dice: 0.9989  decode.d3.loss_cls: 0.5732  decode.d3.loss_mask: 1.1924  decode.d3.loss_dice: 0.9586  decode.d4.loss_cls: 0.5890  decode.d4.loss_mask: 1.2739  decode.d4.loss_dice: 1.0443  decode.d5.loss_cls: 0.5814  decode.d5.loss_mask: 1.1870  decode.d5.loss_dice: 0.9116  decode.d6.loss_cls: 0.6355  decode.d6.loss_mask: 1.2686  decode.d6.loss_dice: 0.9796  decode.d7.loss_cls: 0.5850  decode.d7.loss_mask: 1.2945  decode.d7.loss_dice: 0.9674  decode.d8.loss_cls: 0.5358  decode.d8.loss_mask: 1.2627  decode.d8.loss_dice: 0.9836
05/26 12:48:14 - mmengine - INFO - Iter(train) [ 16100/160000]  base_lr: 9.0897e-05 lr: 9.0897e-06  eta: 16:24:51  time: 0.4092  data_time: 0.0088  memory: 5984  grad_norm: 547.2056  loss: 27.1149  decode.loss_cls: 0.3666  decode.loss_mask: 1.2434  decode.loss_dice: 0.9485  decode.d0.loss_cls: 0.8820  decode.d0.loss_mask: 1.2025  decode.d0.loss_dice: 0.9331  decode.d1.loss_cls: 0.4004  decode.d1.loss_mask: 1.3009  decode.d1.loss_dice: 0.9644  decode.d2.loss_cls: 0.4393  decode.d2.loss_mask: 1.2566  decode.d2.loss_dice: 0.9676  decode.d3.loss_cls: 0.4421  decode.d3.loss_mask: 1.2404  decode.d3.loss_dice: 0.9748  decode.d4.loss_cls: 0.4467  decode.d4.loss_mask: 1.2606  decode.d4.loss_dice: 0.9969  decode.d5.loss_cls: 0.4692  decode.d5.loss_mask: 1.3240  decode.d5.loss_dice: 1.0048  decode.d6.loss_cls: 0.4619  decode.d6.loss_mask: 1.2876  decode.d6.loss_dice: 1.0014  decode.d7.loss_cls: 0.4576  decode.d7.loss_mask: 1.2641  decode.d7.loss_dice: 0.9934  decode.d8.loss_cls: 0.3718  decode.d8.loss_mask: 1.2563  decode.d8.loss_dice: 0.9559
05/26 12:48:34 - mmengine - INFO - Iter(train) [ 16150/160000]  base_lr: 9.0868e-05 lr: 9.0868e-06  eta: 16:24:30  time: 0.4081  data_time: 0.0087  memory: 5972  grad_norm: 830.3605  loss: 30.1698  decode.loss_cls: 0.5204  decode.loss_mask: 1.4056  decode.loss_dice: 1.0384  decode.d0.loss_cls: 1.0286  decode.d0.loss_mask: 1.3229  decode.d0.loss_dice: 1.0215  decode.d1.loss_cls: 0.5762  decode.d1.loss_mask: 1.4095  decode.d1.loss_dice: 1.0468  decode.d2.loss_cls: 0.6707  decode.d2.loss_mask: 1.3257  decode.d2.loss_dice: 1.0365  decode.d3.loss_cls: 0.6466  decode.d3.loss_mask: 1.3315  decode.d3.loss_dice: 0.9695  decode.d4.loss_cls: 0.5950  decode.d4.loss_mask: 1.3597  decode.d4.loss_dice: 1.0077  decode.d5.loss_cls: 0.6021  decode.d5.loss_mask: 1.3633  decode.d5.loss_dice: 1.0166  decode.d6.loss_cls: 0.5802  decode.d6.loss_mask: 1.3592  decode.d6.loss_dice: 1.0273  decode.d7.loss_cls: 0.5451  decode.d7.loss_mask: 1.3739  decode.d7.loss_dice: 1.0348  decode.d8.loss_cls: 0.5414  decode.d8.loss_mask: 1.3850  decode.d8.loss_dice: 1.0279
05/26 12:48:55 - mmengine - INFO - Iter(train) [ 16200/160000]  base_lr: 9.0840e-05 lr: 9.0840e-06  eta: 16:24:08  time: 0.4085  data_time: 0.0088  memory: 5980  grad_norm: 1913.8915  loss: 25.3720  decode.loss_cls: 0.2643  decode.loss_mask: 1.1819  decode.loss_dice: 1.0046  decode.d0.loss_cls: 0.7105  decode.d0.loss_mask: 1.1728  decode.d0.loss_dice: 0.9989  decode.d1.loss_cls: 0.3316  decode.d1.loss_mask: 1.1891  decode.d1.loss_dice: 0.9733  decode.d2.loss_cls: 0.3285  decode.d2.loss_mask: 1.1960  decode.d2.loss_dice: 0.9880  decode.d3.loss_cls: 0.3121  decode.d3.loss_mask: 1.1924  decode.d3.loss_dice: 0.9926  decode.d4.loss_cls: 0.3421  decode.d4.loss_mask: 1.1574  decode.d4.loss_dice: 0.9913  decode.d5.loss_cls: 0.3589  decode.d5.loss_mask: 1.1667  decode.d5.loss_dice: 1.0129  decode.d6.loss_cls: 0.2938  decode.d6.loss_mask: 1.1780  decode.d6.loss_dice: 1.0206  decode.d7.loss_cls: 0.3218  decode.d7.loss_mask: 1.1826  decode.d7.loss_dice: 1.0076  decode.d8.loss_cls: 0.3256  decode.d8.loss_mask: 1.1978  decode.d8.loss_dice: 0.9781
05/26 12:49:15 - mmengine - INFO - Iter(train) [ 16250/160000]  base_lr: 9.0812e-05 lr: 9.0812e-06  eta: 16:23:48  time: 0.4086  data_time: 0.0088  memory: 5980  grad_norm: 699.2823  loss: 31.0493  decode.loss_cls: 0.4916  decode.loss_mask: 1.4462  decode.loss_dice: 1.0411  decode.d0.loss_cls: 1.0513  decode.d0.loss_mask: 1.3988  decode.d0.loss_dice: 1.1137  decode.d1.loss_cls: 0.5307  decode.d1.loss_mask: 1.4658  decode.d1.loss_dice: 1.0803  decode.d2.loss_cls: 0.5051  decode.d2.loss_mask: 1.4434  decode.d2.loss_dice: 1.0428  decode.d3.loss_cls: 0.5772  decode.d3.loss_mask: 1.4849  decode.d3.loss_dice: 1.0881  decode.d4.loss_cls: 0.5922  decode.d4.loss_mask: 1.4794  decode.d4.loss_dice: 1.1365  decode.d5.loss_cls: 0.5863  decode.d5.loss_mask: 1.4708  decode.d5.loss_dice: 1.0927  decode.d6.loss_cls: 0.5212  decode.d6.loss_mask: 1.4323  decode.d6.loss_dice: 1.0495  decode.d7.loss_cls: 0.5773  decode.d7.loss_mask: 1.3759  decode.d7.loss_dice: 0.9977  decode.d8.loss_cls: 0.4861  decode.d8.loss_mask: 1.4260  decode.d8.loss_dice: 1.0643
05/26 12:49:36 - mmengine - INFO - Iter(train) [ 16300/160000]  base_lr: 9.0783e-05 lr: 9.0783e-06  eta: 16:23:27  time: 0.4078  data_time: 0.0088  memory: 5970  grad_norm: 928.0087  loss: 31.8576  decode.loss_cls: 0.4251  decode.loss_mask: 1.6611  decode.loss_dice: 1.1070  decode.d0.loss_cls: 0.9949  decode.d0.loss_mask: 1.3735  decode.d0.loss_dice: 1.0454  decode.d1.loss_cls: 0.4923  decode.d1.loss_mask: 1.6602  decode.d1.loss_dice: 1.0599  decode.d2.loss_cls: 0.4779  decode.d2.loss_mask: 1.5797  decode.d2.loss_dice: 1.0836  decode.d3.loss_cls: 0.4431  decode.d3.loss_mask: 1.6017  decode.d3.loss_dice: 1.0585  decode.d4.loss_cls: 0.5042  decode.d4.loss_mask: 1.5480  decode.d4.loss_dice: 1.0278  decode.d5.loss_cls: 0.4599  decode.d5.loss_mask: 1.6050  decode.d5.loss_dice: 1.0574  decode.d6.loss_cls: 0.4607  decode.d6.loss_mask: 1.5659  decode.d6.loss_dice: 1.0668  decode.d7.loss_cls: 0.4701  decode.d7.loss_mask: 1.6613  decode.d7.loss_dice: 1.0933  decode.d8.loss_cls: 0.4495  decode.d8.loss_mask: 1.7100  decode.d8.loss_dice: 1.1141
05/26 12:49:56 - mmengine - INFO - Iter(train) [ 16350/160000]  base_lr: 9.0755e-05 lr: 9.0755e-06  eta: 16:23:05  time: 0.4070  data_time: 0.0088  memory: 5971  grad_norm: 800.5493  loss: 31.1731  decode.loss_cls: 0.5234  decode.loss_mask: 1.4140  decode.loss_dice: 1.1026  decode.d0.loss_cls: 0.9593  decode.d0.loss_mask: 1.2797  decode.d0.loss_dice: 1.1158  decode.d1.loss_cls: 0.4863  decode.d1.loss_mask: 1.4510  decode.d1.loss_dice: 1.1475  decode.d2.loss_cls: 0.4836  decode.d2.loss_mask: 1.4307  decode.d2.loss_dice: 1.1136  decode.d3.loss_cls: 0.5128  decode.d3.loss_mask: 1.4275  decode.d3.loss_dice: 1.1683  decode.d4.loss_cls: 0.5412  decode.d4.loss_mask: 1.4364  decode.d4.loss_dice: 1.1278  decode.d5.loss_cls: 0.5628  decode.d5.loss_mask: 1.4360  decode.d5.loss_dice: 1.1307  decode.d6.loss_cls: 0.5266  decode.d6.loss_mask: 1.4086  decode.d6.loss_dice: 1.1680  decode.d7.loss_cls: 0.5421  decode.d7.loss_mask: 1.4453  decode.d7.loss_dice: 1.1439  decode.d8.loss_cls: 0.5338  decode.d8.loss_mask: 1.4486  decode.d8.loss_dice: 1.1053
05/26 12:50:17 - mmengine - INFO - Iter(train) [ 16400/160000]  base_lr: 9.0726e-05 lr: 9.0726e-06  eta: 16:22:44  time: 0.4073  data_time: 0.0087  memory: 5976  grad_norm: 705.2575  loss: 27.7230  decode.loss_cls: 0.3387  decode.loss_mask: 1.3226  decode.loss_dice: 1.0773  decode.d0.loss_cls: 0.8505  decode.d0.loss_mask: 1.2347  decode.d0.loss_dice: 1.0021  decode.d1.loss_cls: 0.4004  decode.d1.loss_mask: 1.2607  decode.d1.loss_dice: 1.0481  decode.d2.loss_cls: 0.3358  decode.d2.loss_mask: 1.3100  decode.d2.loss_dice: 1.0907  decode.d3.loss_cls: 0.3635  decode.d3.loss_mask: 1.2806  decode.d3.loss_dice: 1.0867  decode.d4.loss_cls: 0.4599  decode.d4.loss_mask: 1.2688  decode.d4.loss_dice: 1.0745  decode.d5.loss_cls: 0.4961  decode.d5.loss_mask: 1.2105  decode.d5.loss_dice: 1.0120  decode.d6.loss_cls: 0.4933  decode.d6.loss_mask: 1.2723  decode.d6.loss_dice: 1.0512  decode.d7.loss_cls: 0.4384  decode.d7.loss_mask: 1.2518  decode.d7.loss_dice: 1.0224  decode.d8.loss_cls: 0.3910  decode.d8.loss_mask: 1.2367  decode.d8.loss_dice: 1.0417
05/26 12:50:37 - mmengine - INFO - Iter(train) [ 16450/160000]  base_lr: 9.0698e-05 lr: 9.0698e-06  eta: 16:22:22  time: 0.4069  data_time: 0.0088  memory: 5972  grad_norm: 752.1339  loss: 22.2312  decode.loss_cls: 0.2971  decode.loss_mask: 1.1000  decode.loss_dice: 0.7566  decode.d0.loss_cls: 0.7184  decode.d0.loss_mask: 1.0328  decode.d0.loss_dice: 0.7380  decode.d1.loss_cls: 0.3335  decode.d1.loss_mask: 1.0683  decode.d1.loss_dice: 0.7658  decode.d2.loss_cls: 0.3266  decode.d2.loss_mask: 1.0702  decode.d2.loss_dice: 0.8012  decode.d3.loss_cls: 0.3500  decode.d3.loss_mask: 1.0655  decode.d3.loss_dice: 0.7836  decode.d4.loss_cls: 0.3308  decode.d4.loss_mask: 1.0875  decode.d4.loss_dice: 0.7843  decode.d5.loss_cls: 0.3447  decode.d5.loss_mask: 1.0915  decode.d5.loss_dice: 0.7567  decode.d6.loss_cls: 0.4167  decode.d6.loss_mask: 1.0552  decode.d6.loss_dice: 0.7691  decode.d7.loss_cls: 0.3228  decode.d7.loss_mask: 1.0932  decode.d7.loss_dice: 0.8071  decode.d8.loss_cls: 0.3832  decode.d8.loss_mask: 1.0343  decode.d8.loss_dice: 0.7465
05/26 12:50:57 - mmengine - INFO - Iter(train) [ 16500/160000]  base_lr: 9.0669e-05 lr: 9.0669e-06  eta: 16:22:00  time: 0.4070  data_time: 0.0087  memory: 5969  grad_norm: 874.3492  loss: 32.3207  decode.loss_cls: 0.5542  decode.loss_mask: 1.4292  decode.loss_dice: 1.1644  decode.d0.loss_cls: 0.8940  decode.d0.loss_mask: 1.4290  decode.d0.loss_dice: 1.2100  decode.d1.loss_cls: 0.4873  decode.d1.loss_mask: 1.4802  decode.d1.loss_dice: 1.1983  decode.d2.loss_cls: 0.5002  decode.d2.loss_mask: 1.4840  decode.d2.loss_dice: 1.1870  decode.d3.loss_cls: 0.5496  decode.d3.loss_mask: 1.4757  decode.d3.loss_dice: 1.1863  decode.d4.loss_cls: 0.5246  decode.d4.loss_mask: 1.4632  decode.d4.loss_dice: 1.1789  decode.d5.loss_cls: 0.5380  decode.d5.loss_mask: 1.4697  decode.d5.loss_dice: 1.2096  decode.d6.loss_cls: 0.5821  decode.d6.loss_mask: 1.4824  decode.d6.loss_dice: 1.2056  decode.d7.loss_cls: 0.5352  decode.d7.loss_mask: 1.4720  decode.d7.loss_dice: 1.2584  decode.d8.loss_cls: 0.5573  decode.d8.loss_mask: 1.4240  decode.d8.loss_dice: 1.1900
05/26 12:51:18 - mmengine - INFO - Iter(train) [ 16550/160000]  base_lr: 9.0641e-05 lr: 9.0641e-06  eta: 16:21:38  time: 0.4079  data_time: 0.0089  memory: 5974  grad_norm: 603.9758  loss: 30.3193  decode.loss_cls: 0.4901  decode.loss_mask: 1.3691  decode.loss_dice: 1.1296  decode.d0.loss_cls: 0.9342  decode.d0.loss_mask: 1.2694  decode.d0.loss_dice: 1.1663  decode.d1.loss_cls: 0.5797  decode.d1.loss_mask: 1.3122  decode.d1.loss_dice: 1.1134  decode.d2.loss_cls: 0.4895  decode.d2.loss_mask: 1.3189  decode.d2.loss_dice: 1.1239  decode.d3.loss_cls: 0.4571  decode.d3.loss_mask: 1.3470  decode.d3.loss_dice: 1.1636  decode.d4.loss_cls: 0.5054  decode.d4.loss_mask: 1.2990  decode.d4.loss_dice: 1.1578  decode.d5.loss_cls: 0.4851  decode.d5.loss_mask: 1.2957  decode.d5.loss_dice: 1.1712  decode.d6.loss_cls: 0.5824  decode.d6.loss_mask: 1.3261  decode.d6.loss_dice: 1.1539  decode.d7.loss_cls: 0.6184  decode.d7.loss_mask: 1.3244  decode.d7.loss_dice: 1.1390  decode.d8.loss_cls: 0.5613  decode.d8.loss_mask: 1.3119  decode.d8.loss_dice: 1.1241
05/26 12:51:38 - mmengine - INFO - Iter(train) [ 16600/160000]  base_lr: 9.0613e-05 lr: 9.0613e-06  eta: 16:21:17  time: 0.4069  data_time: 0.0087  memory: 5971  grad_norm: 608.2262  loss: 29.8904  decode.loss_cls: 0.4456  decode.loss_mask: 1.3185  decode.loss_dice: 1.1507  decode.d0.loss_cls: 0.9939  decode.d0.loss_mask: 1.2706  decode.d0.loss_dice: 1.1086  decode.d1.loss_cls: 0.4337  decode.d1.loss_mask: 1.3187  decode.d1.loss_dice: 1.1528  decode.d2.loss_cls: 0.4846  decode.d2.loss_mask: 1.2932  decode.d2.loss_dice: 1.1254  decode.d3.loss_cls: 0.4725  decode.d3.loss_mask: 1.3219  decode.d3.loss_dice: 1.1379  decode.d4.loss_cls: 0.5403  decode.d4.loss_mask: 1.3101  decode.d4.loss_dice: 1.1264  decode.d5.loss_cls: 0.5180  decode.d5.loss_mask: 1.3318  decode.d5.loss_dice: 1.1497  decode.d6.loss_cls: 0.5273  decode.d6.loss_mask: 1.3403  decode.d6.loss_dice: 1.1300  decode.d7.loss_cls: 0.5086  decode.d7.loss_mask: 1.3131  decode.d7.loss_dice: 1.1550  decode.d8.loss_cls: 0.5133  decode.d8.loss_mask: 1.2897  decode.d8.loss_dice: 1.1083
05/26 12:51:59 - mmengine - INFO - Iter(train) [ 16650/160000]  base_lr: 9.0584e-05 lr: 9.0584e-06  eta: 16:20:55  time: 0.4076  data_time: 0.0088  memory: 5966  grad_norm: 989.8971  loss: 23.3458  decode.loss_cls: 0.2655  decode.loss_mask: 1.1796  decode.loss_dice: 0.8402  decode.d0.loss_cls: 0.6423  decode.d0.loss_mask: 1.1613  decode.d0.loss_dice: 0.8271  decode.d1.loss_cls: 0.3042  decode.d1.loss_mask: 1.1794  decode.d1.loss_dice: 0.8431  decode.d2.loss_cls: 0.3249  decode.d2.loss_mask: 1.1367  decode.d2.loss_dice: 0.8297  decode.d3.loss_cls: 0.2868  decode.d3.loss_mask: 1.1986  decode.d3.loss_dice: 0.8238  decode.d4.loss_cls: 0.3393  decode.d4.loss_mask: 1.1469  decode.d4.loss_dice: 0.8229  decode.d5.loss_cls: 0.3004  decode.d5.loss_mask: 1.1925  decode.d5.loss_dice: 0.8446  decode.d6.loss_cls: 0.2949  decode.d6.loss_mask: 1.1784  decode.d6.loss_dice: 0.8638  decode.d7.loss_cls: 0.2787  decode.d7.loss_mask: 1.1946  decode.d7.loss_dice: 0.8125  decode.d8.loss_cls: 0.2621  decode.d8.loss_mask: 1.1353  decode.d8.loss_dice: 0.8355
05/26 12:52:19 - mmengine - INFO - Iter(train) [ 16700/160000]  base_lr: 9.0556e-05 lr: 9.0556e-06  eta: 16:20:33  time: 0.4082  data_time: 0.0088  memory: 5968  grad_norm: 865.3388  loss: 30.7140  decode.loss_cls: 0.4799  decode.loss_mask: 1.4112  decode.loss_dice: 1.1592  decode.d0.loss_cls: 0.9185  decode.d0.loss_mask: 1.3527  decode.d0.loss_dice: 1.1091  decode.d1.loss_cls: 0.4581  decode.d1.loss_mask: 1.4251  decode.d1.loss_dice: 1.1876  decode.d2.loss_cls: 0.5393  decode.d2.loss_mask: 1.3331  decode.d2.loss_dice: 1.1559  decode.d3.loss_cls: 0.5207  decode.d3.loss_mask: 1.3497  decode.d3.loss_dice: 1.1232  decode.d4.loss_cls: 0.4740  decode.d4.loss_mask: 1.4187  decode.d4.loss_dice: 1.1502  decode.d5.loss_cls: 0.5727  decode.d5.loss_mask: 1.3709  decode.d5.loss_dice: 1.1511  decode.d6.loss_cls: 0.4969  decode.d6.loss_mask: 1.3627  decode.d6.loss_dice: 1.1343  decode.d7.loss_cls: 0.5249  decode.d7.loss_mask: 1.3618  decode.d7.loss_dice: 1.1586  decode.d8.loss_cls: 0.4991  decode.d8.loss_mask: 1.3401  decode.d8.loss_dice: 1.1747
05/26 12:52:39 - mmengine - INFO - Iter(train) [ 16750/160000]  base_lr: 9.0527e-05 lr: 9.0527e-06  eta: 16:20:12  time: 0.4070  data_time: 0.0087  memory: 5966  grad_norm: 479.8132  loss: 24.7453  decode.loss_cls: 0.3124  decode.loss_mask: 1.2180  decode.loss_dice: 0.8950  decode.d0.loss_cls: 0.7338  decode.d0.loss_mask: 1.1591  decode.d0.loss_dice: 0.8788  decode.d1.loss_cls: 0.3165  decode.d1.loss_mask: 1.1989  decode.d1.loss_dice: 0.9313  decode.d2.loss_cls: 0.3459  decode.d2.loss_mask: 1.1550  decode.d2.loss_dice: 0.8695  decode.d3.loss_cls: 0.3477  decode.d3.loss_mask: 1.2292  decode.d3.loss_dice: 0.8785  decode.d4.loss_cls: 0.3254  decode.d4.loss_mask: 1.2232  decode.d4.loss_dice: 0.8861  decode.d5.loss_cls: 0.3646  decode.d5.loss_mask: 1.2384  decode.d5.loss_dice: 0.9012  decode.d6.loss_cls: 0.4329  decode.d6.loss_mask: 1.1849  decode.d6.loss_dice: 0.8702  decode.d7.loss_cls: 0.3330  decode.d7.loss_mask: 1.1885  decode.d7.loss_dice: 0.9030  decode.d8.loss_cls: 0.3203  decode.d8.loss_mask: 1.2080  decode.d8.loss_dice: 0.8960
05/26 12:53:00 - mmengine - INFO - Iter(train) [ 16800/160000]  base_lr: 9.0499e-05 lr: 9.0499e-06  eta: 16:19:50  time: 0.4071  data_time: 0.0087  memory: 5969  grad_norm: 575.1199  loss: 25.2340  decode.loss_cls: 0.3178  decode.loss_mask: 1.2044  decode.loss_dice: 0.9384  decode.d0.loss_cls: 0.8769  decode.d0.loss_mask: 1.0980  decode.d0.loss_dice: 0.8647  decode.d1.loss_cls: 0.3772  decode.d1.loss_mask: 1.1430  decode.d1.loss_dice: 0.9013  decode.d2.loss_cls: 0.4042  decode.d2.loss_mask: 1.1436  decode.d2.loss_dice: 0.8948  decode.d3.loss_cls: 0.4111  decode.d3.loss_mask: 1.1565  decode.d3.loss_dice: 0.9117  decode.d4.loss_cls: 0.4625  decode.d4.loss_mask: 1.1753  decode.d4.loss_dice: 0.8946  decode.d5.loss_cls: 0.4407  decode.d5.loss_mask: 1.1677  decode.d5.loss_dice: 0.9491  decode.d6.loss_cls: 0.4477  decode.d6.loss_mask: 1.1662  decode.d6.loss_dice: 0.9090  decode.d7.loss_cls: 0.4034  decode.d7.loss_mask: 1.1540  decode.d7.loss_dice: 0.9121  decode.d8.loss_cls: 0.3426  decode.d8.loss_mask: 1.2136  decode.d8.loss_dice: 0.9520
05/26 12:53:20 - mmengine - INFO - Iter(train) [ 16850/160000]  base_lr: 9.0470e-05 lr: 9.0470e-06  eta: 16:19:29  time: 0.4084  data_time: 0.0088  memory: 5969  grad_norm: 590.3313  loss: 25.3970  decode.loss_cls: 0.2196  decode.loss_mask: 1.2157  decode.loss_dice: 1.0013  decode.d0.loss_cls: 0.6561  decode.d0.loss_mask: 1.1586  decode.d0.loss_dice: 0.9664  decode.d1.loss_cls: 0.2650  decode.d1.loss_mask: 1.2372  decode.d1.loss_dice: 0.9835  decode.d2.loss_cls: 0.2768  decode.d2.loss_mask: 1.2502  decode.d2.loss_dice: 0.9798  decode.d3.loss_cls: 0.2666  decode.d3.loss_mask: 1.2381  decode.d3.loss_dice: 0.9713  decode.d4.loss_cls: 0.2950  decode.d4.loss_mask: 1.2239  decode.d4.loss_dice: 0.9987  decode.d5.loss_cls: 0.2803  decode.d5.loss_mask: 1.2552  decode.d5.loss_dice: 0.9904  decode.d6.loss_cls: 0.2908  decode.d6.loss_mask: 1.2787  decode.d6.loss_dice: 1.0048  decode.d7.loss_cls: 0.3286  decode.d7.loss_mask: 1.2735  decode.d7.loss_dice: 0.9899  decode.d8.loss_cls: 0.2478  decode.d8.loss_mask: 1.2399  decode.d8.loss_dice: 1.0134
05/26 12:53:41 - mmengine - INFO - Iter(train) [ 16900/160000]  base_lr: 9.0442e-05 lr: 9.0442e-06  eta: 16:19:07  time: 0.4075  data_time: 0.0088  memory: 5971  grad_norm: 642.6636  loss: 25.9181  decode.loss_cls: 0.3813  decode.loss_mask: 1.2847  decode.loss_dice: 0.9129  decode.d0.loss_cls: 0.7858  decode.d0.loss_mask: 1.1943  decode.d0.loss_dice: 0.9023  decode.d1.loss_cls: 0.4306  decode.d1.loss_mask: 1.1979  decode.d1.loss_dice: 0.8699  decode.d2.loss_cls: 0.3902  decode.d2.loss_mask: 1.2226  decode.d2.loss_dice: 0.9131  decode.d3.loss_cls: 0.3968  decode.d3.loss_mask: 1.2701  decode.d3.loss_dice: 0.9315  decode.d4.loss_cls: 0.4464  decode.d4.loss_mask: 1.2255  decode.d4.loss_dice: 0.9146  decode.d5.loss_cls: 0.4410  decode.d5.loss_mask: 1.2148  decode.d5.loss_dice: 0.8835  decode.d6.loss_cls: 0.4537  decode.d6.loss_mask: 1.2247  decode.d6.loss_dice: 0.9358  decode.d7.loss_cls: 0.4212  decode.d7.loss_mask: 1.2047  decode.d7.loss_dice: 0.9088  decode.d8.loss_cls: 0.3949  decode.d8.loss_mask: 1.2422  decode.d8.loss_dice: 0.9223
05/26 12:54:01 - mmengine - INFO - Iter(train) [ 16950/160000]  base_lr: 9.0414e-05 lr: 9.0414e-06  eta: 16:18:46  time: 0.4074  data_time: 0.0088  memory: 5967  grad_norm: 679.4877  loss: 27.6338  decode.loss_cls: 0.4063  decode.loss_mask: 1.3408  decode.loss_dice: 1.0062  decode.d0.loss_cls: 0.9066  decode.d0.loss_mask: 1.2469  decode.d0.loss_dice: 0.9562  decode.d1.loss_cls: 0.4781  decode.d1.loss_mask: 1.2830  decode.d1.loss_dice: 0.9294  decode.d2.loss_cls: 0.4541  decode.d2.loss_mask: 1.2721  decode.d2.loss_dice: 0.9967  decode.d3.loss_cls: 0.4749  decode.d3.loss_mask: 1.3119  decode.d3.loss_dice: 0.9271  decode.d4.loss_cls: 0.4545  decode.d4.loss_mask: 1.3175  decode.d4.loss_dice: 0.9414  decode.d5.loss_cls: 0.4715  decode.d5.loss_mask: 1.3176  decode.d5.loss_dice: 0.9512  decode.d6.loss_cls: 0.4536  decode.d6.loss_mask: 1.3249  decode.d6.loss_dice: 0.9735  decode.d7.loss_cls: 0.4237  decode.d7.loss_mask: 1.3186  decode.d7.loss_dice: 0.9563  decode.d8.loss_cls: 0.4501  decode.d8.loss_mask: 1.3191  decode.d8.loss_dice: 0.9698
05/26 12:54:21 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 12:54:21 - mmengine - INFO - Iter(train) [ 17000/160000]  base_lr: 9.0385e-05 lr: 9.0385e-06  eta: 16:18:24  time: 0.4081  data_time: 0.0088  memory: 5969  grad_norm: 416.6444  loss: 25.7132  decode.loss_cls: 0.2603  decode.loss_mask: 1.1932  decode.loss_dice: 0.9585  decode.d0.loss_cls: 0.7830  decode.d0.loss_mask: 1.2014  decode.d0.loss_dice: 0.9900  decode.d1.loss_cls: 0.3417  decode.d1.loss_mask: 1.2066  decode.d1.loss_dice: 0.9496  decode.d2.loss_cls: 0.3272  decode.d2.loss_mask: 1.2118  decode.d2.loss_dice: 0.9564  decode.d3.loss_cls: 0.3285  decode.d3.loss_mask: 1.3410  decode.d3.loss_dice: 0.9799  decode.d4.loss_cls: 0.3642  decode.d4.loss_mask: 1.2247  decode.d4.loss_dice: 0.9672  decode.d5.loss_cls: 0.3258  decode.d5.loss_mask: 1.2731  decode.d5.loss_dice: 0.9747  decode.d6.loss_cls: 0.2869  decode.d6.loss_mask: 1.2196  decode.d6.loss_dice: 0.9776  decode.d7.loss_cls: 0.3127  decode.d7.loss_mask: 1.2237  decode.d7.loss_dice: 0.9664  decode.d8.loss_cls: 0.3127  decode.d8.loss_mask: 1.2688  decode.d8.loss_dice: 0.9861
05/26 12:54:42 - mmengine - INFO - Iter(train) [ 17050/160000]  base_lr: 9.0357e-05 lr: 9.0357e-06  eta: 16:18:03  time: 0.4096  data_time: 0.0088  memory: 5974  grad_norm: 919.6119  loss: 27.0080  decode.loss_cls: 0.3582  decode.loss_mask: 1.3603  decode.loss_dice: 1.0074  decode.d0.loss_cls: 0.8202  decode.d0.loss_mask: 1.2326  decode.d0.loss_dice: 0.9005  decode.d1.loss_cls: 0.4517  decode.d1.loss_mask: 1.2950  decode.d1.loss_dice: 0.9182  decode.d2.loss_cls: 0.4203  decode.d2.loss_mask: 1.2987  decode.d2.loss_dice: 0.9432  decode.d3.loss_cls: 0.4138  decode.d3.loss_mask: 1.3504  decode.d3.loss_dice: 0.9717  decode.d4.loss_cls: 0.4081  decode.d4.loss_mask: 1.2806  decode.d4.loss_dice: 0.9317  decode.d5.loss_cls: 0.4222  decode.d5.loss_mask: 1.3174  decode.d5.loss_dice: 0.9362  decode.d6.loss_cls: 0.4479  decode.d6.loss_mask: 1.3578  decode.d6.loss_dice: 0.9496  decode.d7.loss_cls: 0.3409  decode.d7.loss_mask: 1.3491  decode.d7.loss_dice: 0.9434  decode.d8.loss_cls: 0.3781  decode.d8.loss_mask: 1.2901  decode.d8.loss_dice: 0.9128
05/26 12:55:02 - mmengine - INFO - Iter(train) [ 17100/160000]  base_lr: 9.0328e-05 lr: 9.0328e-06  eta: 16:17:42  time: 0.4095  data_time: 0.0088  memory: 5976  grad_norm: 591.8076  loss: 27.2979  decode.loss_cls: 0.4187  decode.loss_mask: 1.2177  decode.loss_dice: 0.9575  decode.d0.loss_cls: 0.8576  decode.d0.loss_mask: 1.1722  decode.d0.loss_dice: 0.9394  decode.d1.loss_cls: 0.4038  decode.d1.loss_mask: 1.2436  decode.d1.loss_dice: 0.9506  decode.d2.loss_cls: 0.4346  decode.d2.loss_mask: 1.2749  decode.d2.loss_dice: 0.9740  decode.d3.loss_cls: 0.4161  decode.d3.loss_mask: 1.2858  decode.d3.loss_dice: 0.9760  decode.d4.loss_cls: 0.5042  decode.d4.loss_mask: 1.2818  decode.d4.loss_dice: 0.9808  decode.d5.loss_cls: 0.4512  decode.d5.loss_mask: 1.2954  decode.d5.loss_dice: 1.0001  decode.d6.loss_cls: 0.4523  decode.d6.loss_mask: 1.2664  decode.d6.loss_dice: 0.9949  decode.d7.loss_cls: 0.5088  decode.d7.loss_mask: 1.3011  decode.d7.loss_dice: 0.9782  decode.d8.loss_cls: 0.4234  decode.d8.loss_mask: 1.3410  decode.d8.loss_dice: 0.9956
05/26 12:55:23 - mmengine - INFO - Iter(train) [ 17150/160000]  base_lr: 9.0300e-05 lr: 9.0300e-06  eta: 16:17:20  time: 0.4091  data_time: 0.0088  memory: 5988  grad_norm: 776.4220  loss: 31.1456  decode.loss_cls: 0.4479  decode.loss_mask: 1.3993  decode.loss_dice: 1.2025  decode.d0.loss_cls: 0.9699  decode.d0.loss_mask: 1.3160  decode.d0.loss_dice: 1.1412  decode.d1.loss_cls: 0.4973  decode.d1.loss_mask: 1.3351  decode.d1.loss_dice: 1.1112  decode.d2.loss_cls: 0.4992  decode.d2.loss_mask: 1.3824  decode.d2.loss_dice: 1.1715  decode.d3.loss_cls: 0.4559  decode.d3.loss_mask: 1.4357  decode.d3.loss_dice: 1.2006  decode.d4.loss_cls: 0.5435  decode.d4.loss_mask: 1.3956  decode.d4.loss_dice: 1.1779  decode.d5.loss_cls: 0.5752  decode.d5.loss_mask: 1.3922  decode.d5.loss_dice: 1.1735  decode.d6.loss_cls: 0.5418  decode.d6.loss_mask: 1.3979  decode.d6.loss_dice: 1.2210  decode.d7.loss_cls: 0.5172  decode.d7.loss_mask: 1.3759  decode.d7.loss_dice: 1.1970  decode.d8.loss_cls: 0.5425  decode.d8.loss_mask: 1.3635  decode.d8.loss_dice: 1.1654
05/26 12:55:43 - mmengine - INFO - Iter(train) [ 17200/160000]  base_lr: 9.0271e-05 lr: 9.0271e-06  eta: 16:16:59  time: 0.4094  data_time: 0.0088  memory: 5969  grad_norm: 841.6091  loss: 26.7097  decode.loss_cls: 0.4435  decode.loss_mask: 1.2001  decode.loss_dice: 0.9224  decode.d0.loss_cls: 0.7899  decode.d0.loss_mask: 1.1743  decode.d0.loss_dice: 0.9435  decode.d1.loss_cls: 0.4456  decode.d1.loss_mask: 1.2341  decode.d1.loss_dice: 0.9648  decode.d2.loss_cls: 0.4962  decode.d2.loss_mask: 1.1785  decode.d2.loss_dice: 0.9529  decode.d3.loss_cls: 0.4796  decode.d3.loss_mask: 1.2281  decode.d3.loss_dice: 0.9493  decode.d4.loss_cls: 0.4736  decode.d4.loss_mask: 1.2258  decode.d4.loss_dice: 0.9652  decode.d5.loss_cls: 0.4827  decode.d5.loss_mask: 1.2288  decode.d5.loss_dice: 0.9661  decode.d6.loss_cls: 0.4411  decode.d6.loss_mask: 1.2647  decode.d6.loss_dice: 0.9778  decode.d7.loss_cls: 0.4583  decode.d7.loss_mask: 1.2000  decode.d7.loss_dice: 0.9731  decode.d8.loss_cls: 0.4479  decode.d8.loss_mask: 1.2121  decode.d8.loss_dice: 0.9897
05/26 12:56:04 - mmengine - INFO - Iter(train) [ 17250/160000]  base_lr: 9.0243e-05 lr: 9.0243e-06  eta: 16:16:38  time: 0.4089  data_time: 0.0088  memory: 5979  grad_norm: 712.8688  loss: 26.9245  decode.loss_cls: 0.3732  decode.loss_mask: 1.2900  decode.loss_dice: 1.0277  decode.d0.loss_cls: 0.8754  decode.d0.loss_mask: 1.1372  decode.d0.loss_dice: 0.9495  decode.d1.loss_cls: 0.4068  decode.d1.loss_mask: 1.2271  decode.d1.loss_dice: 1.0007  decode.d2.loss_cls: 0.3822  decode.d2.loss_mask: 1.2255  decode.d2.loss_dice: 1.0263  decode.d3.loss_cls: 0.3851  decode.d3.loss_mask: 1.2334  decode.d3.loss_dice: 1.0007  decode.d4.loss_cls: 0.3975  decode.d4.loss_mask: 1.2681  decode.d4.loss_dice: 1.0700  decode.d5.loss_cls: 0.4130  decode.d5.loss_mask: 1.2127  decode.d5.loss_dice: 1.0497  decode.d6.loss_cls: 0.4799  decode.d6.loss_mask: 1.1844  decode.d6.loss_dice: 0.9940  decode.d7.loss_cls: 0.4190  decode.d7.loss_mask: 1.2173  decode.d7.loss_dice: 1.0007  decode.d8.loss_cls: 0.4348  decode.d8.loss_mask: 1.2139  decode.d8.loss_dice: 1.0288
05/26 12:56:24 - mmengine - INFO - Iter(train) [ 17300/160000]  base_lr: 9.0214e-05 lr: 9.0214e-06  eta: 16:16:18  time: 0.4202  data_time: 0.0088  memory: 5969  grad_norm: 552.6069  loss: 25.1484  decode.loss_cls: 0.4217  decode.loss_mask: 1.2211  decode.loss_dice: 0.7919  decode.d0.loss_cls: 0.8033  decode.d0.loss_mask: 1.2641  decode.d0.loss_dice: 0.7917  decode.d1.loss_cls: 0.3679  decode.d1.loss_mask: 1.2318  decode.d1.loss_dice: 0.8410  decode.d2.loss_cls: 0.4244  decode.d2.loss_mask: 1.2039  decode.d2.loss_dice: 0.8357  decode.d3.loss_cls: 0.4352  decode.d3.loss_mask: 1.2138  decode.d3.loss_dice: 0.7817  decode.d4.loss_cls: 0.4121  decode.d4.loss_mask: 1.2686  decode.d4.loss_dice: 0.8064  decode.d5.loss_cls: 0.4542  decode.d5.loss_mask: 1.2303  decode.d5.loss_dice: 0.8118  decode.d6.loss_cls: 0.4184  decode.d6.loss_mask: 1.2771  decode.d6.loss_dice: 0.8405  decode.d7.loss_cls: 0.4657  decode.d7.loss_mask: 1.2188  decode.d7.loss_dice: 0.8092  decode.d8.loss_cls: 0.4161  decode.d8.loss_mask: 1.2717  decode.d8.loss_dice: 0.8185
05/26 12:56:45 - mmengine - INFO - Iter(train) [ 17350/160000]  base_lr: 9.0186e-05 lr: 9.0186e-06  eta: 16:15:56  time: 0.4095  data_time: 0.0088  memory: 5973  grad_norm: 733.1997  loss: 27.8632  decode.loss_cls: 0.4162  decode.loss_mask: 1.3244  decode.loss_dice: 0.9485  decode.d0.loss_cls: 0.8953  decode.d0.loss_mask: 1.2476  decode.d0.loss_dice: 0.9591  decode.d1.loss_cls: 0.4376  decode.d1.loss_mask: 1.3360  decode.d1.loss_dice: 0.9547  decode.d2.loss_cls: 0.5324  decode.d2.loss_mask: 1.3364  decode.d2.loss_dice: 0.9470  decode.d3.loss_cls: 0.4788  decode.d3.loss_mask: 1.3527  decode.d3.loss_dice: 0.9452  decode.d4.loss_cls: 0.4775  decode.d4.loss_mask: 1.3312  decode.d4.loss_dice: 0.9301  decode.d5.loss_cls: 0.4812  decode.d5.loss_mask: 1.3471  decode.d5.loss_dice: 0.9787  decode.d6.loss_cls: 0.5052  decode.d6.loss_mask: 1.3339  decode.d6.loss_dice: 0.9568  decode.d7.loss_cls: 0.4725  decode.d7.loss_mask: 1.3330  decode.d7.loss_dice: 0.9378  decode.d8.loss_cls: 0.4271  decode.d8.loss_mask: 1.3235  decode.d8.loss_dice: 0.9159
05/26 12:57:05 - mmengine - INFO - Iter(train) [ 17400/160000]  base_lr: 9.0158e-05 lr: 9.0158e-06  eta: 16:15:35  time: 0.4094  data_time: 0.0088  memory: 5967  grad_norm: 2186.6753  loss: 35.8409  decode.loss_cls: 0.4699  decode.loss_mask: 1.7810  decode.loss_dice: 1.3735  decode.d0.loss_cls: 0.9454  decode.d0.loss_mask: 1.6595  decode.d0.loss_dice: 1.3490  decode.d1.loss_cls: 0.4928  decode.d1.loss_mask: 1.6868  decode.d1.loss_dice: 1.3629  decode.d2.loss_cls: 0.5612  decode.d2.loss_mask: 1.5702  decode.d2.loss_dice: 1.3095  decode.d3.loss_cls: 0.5286  decode.d3.loss_mask: 1.6124  decode.d3.loss_dice: 1.3121  decode.d4.loss_cls: 0.5747  decode.d4.loss_mask: 1.6630  decode.d4.loss_dice: 1.3249  decode.d5.loss_cls: 0.4927  decode.d5.loss_mask: 1.6639  decode.d5.loss_dice: 1.3655  decode.d6.loss_cls: 0.5273  decode.d6.loss_mask: 1.7106  decode.d6.loss_dice: 1.4151  decode.d7.loss_cls: 0.5285  decode.d7.loss_mask: 1.6637  decode.d7.loss_dice: 1.3409  decode.d8.loss_cls: 0.4925  decode.d8.loss_mask: 1.7033  decode.d8.loss_dice: 1.3594
05/26 12:57:25 - mmengine - INFO - Iter(train) [ 17450/160000]  base_lr: 9.0129e-05 lr: 9.0129e-06  eta: 16:15:14  time: 0.4094  data_time: 0.0088  memory: 5972  grad_norm: 786.9430  loss: 29.1300  decode.loss_cls: 0.4665  decode.loss_mask: 1.3345  decode.loss_dice: 1.0791  decode.d0.loss_cls: 0.8665  decode.d0.loss_mask: 1.2697  decode.d0.loss_dice: 1.0099  decode.d1.loss_cls: 0.4788  decode.d1.loss_mask: 1.3363  decode.d1.loss_dice: 1.0498  decode.d2.loss_cls: 0.4297  decode.d2.loss_mask: 1.3255  decode.d2.loss_dice: 1.0622  decode.d3.loss_cls: 0.4273  decode.d3.loss_mask: 1.3551  decode.d3.loss_dice: 1.0792  decode.d4.loss_cls: 0.5087  decode.d4.loss_mask: 1.3286  decode.d4.loss_dice: 1.0431  decode.d5.loss_cls: 0.4989  decode.d5.loss_mask: 1.3739  decode.d5.loss_dice: 1.0778  decode.d6.loss_cls: 0.5234  decode.d6.loss_mask: 1.3295  decode.d6.loss_dice: 1.1143  decode.d7.loss_cls: 0.4610  decode.d7.loss_mask: 1.3343  decode.d7.loss_dice: 1.0525  decode.d8.loss_cls: 0.5055  decode.d8.loss_mask: 1.3613  decode.d8.loss_dice: 1.0471
05/26 12:57:46 - mmengine - INFO - Iter(train) [ 17500/160000]  base_lr: 9.0101e-05 lr: 9.0101e-06  eta: 16:14:53  time: 0.4081  data_time: 0.0088  memory: 5976  grad_norm: 625.8494  loss: 25.9257  decode.loss_cls: 0.3151  decode.loss_mask: 1.2293  decode.loss_dice: 1.0420  decode.d0.loss_cls: 0.8201  decode.d0.loss_mask: 1.1244  decode.d0.loss_dice: 0.9321  decode.d1.loss_cls: 0.3401  decode.d1.loss_mask: 1.2175  decode.d1.loss_dice: 0.9996  decode.d2.loss_cls: 0.4341  decode.d2.loss_mask: 1.1777  decode.d2.loss_dice: 1.0000  decode.d3.loss_cls: 0.4215  decode.d3.loss_mask: 1.1014  decode.d3.loss_dice: 0.9841  decode.d4.loss_cls: 0.3947  decode.d4.loss_mask: 1.1935  decode.d4.loss_dice: 0.9812  decode.d5.loss_cls: 0.4545  decode.d5.loss_mask: 1.1369  decode.d5.loss_dice: 0.9630  decode.d6.loss_cls: 0.3504  decode.d6.loss_mask: 1.1729  decode.d6.loss_dice: 1.0306  decode.d7.loss_cls: 0.3725  decode.d7.loss_mask: 1.1650  decode.d7.loss_dice: 1.0062  decode.d8.loss_cls: 0.3360  decode.d8.loss_mask: 1.2081  decode.d8.loss_dice: 1.0212
05/26 12:58:06 - mmengine - INFO - Iter(train) [ 17550/160000]  base_lr: 9.0072e-05 lr: 9.0072e-06  eta: 16:14:31  time: 0.4079  data_time: 0.0088  memory: 5974  grad_norm: 614.4094  loss: 24.6471  decode.loss_cls: 0.3420  decode.loss_mask: 1.1806  decode.loss_dice: 0.8496  decode.d0.loss_cls: 0.9043  decode.d0.loss_mask: 1.1244  decode.d0.loss_dice: 0.8275  decode.d1.loss_cls: 0.3834  decode.d1.loss_mask: 1.1986  decode.d1.loss_dice: 0.8075  decode.d2.loss_cls: 0.4109  decode.d2.loss_mask: 1.1704  decode.d2.loss_dice: 0.8289  decode.d3.loss_cls: 0.4452  decode.d3.loss_mask: 1.1435  decode.d3.loss_dice: 0.8204  decode.d4.loss_cls: 0.4229  decode.d4.loss_mask: 1.1827  decode.d4.loss_dice: 0.8028  decode.d5.loss_cls: 0.3961  decode.d5.loss_mask: 1.2318  decode.d5.loss_dice: 0.8268  decode.d6.loss_cls: 0.3668  decode.d6.loss_mask: 1.2865  decode.d6.loss_dice: 0.8575  decode.d7.loss_cls: 0.4343  decode.d7.loss_mask: 1.1911  decode.d7.loss_dice: 0.8035  decode.d8.loss_cls: 0.3703  decode.d8.loss_mask: 1.1806  decode.d8.loss_dice: 0.8562
05/26 12:58:27 - mmengine - INFO - Iter(train) [ 17600/160000]  base_lr: 9.0044e-05 lr: 9.0044e-06  eta: 16:14:10  time: 0.4074  data_time: 0.0087  memory: 5968  grad_norm: 522.6255  loss: 29.1038  decode.loss_cls: 0.4510  decode.loss_mask: 1.2821  decode.loss_dice: 1.0707  decode.d0.loss_cls: 1.0331  decode.d0.loss_mask: 1.2860  decode.d0.loss_dice: 1.0832  decode.d1.loss_cls: 0.4701  decode.d1.loss_mask: 1.3353  decode.d1.loss_dice: 1.0926  decode.d2.loss_cls: 0.4605  decode.d2.loss_mask: 1.3036  decode.d2.loss_dice: 1.0632  decode.d3.loss_cls: 0.4358  decode.d3.loss_mask: 1.2796  decode.d3.loss_dice: 1.0701  decode.d4.loss_cls: 0.4747  decode.d4.loss_mask: 1.2986  decode.d4.loss_dice: 1.0933  decode.d5.loss_cls: 0.4785  decode.d5.loss_mask: 1.3349  decode.d5.loss_dice: 1.0749  decode.d6.loss_cls: 0.5062  decode.d6.loss_mask: 1.3281  decode.d6.loss_dice: 1.1328  decode.d7.loss_cls: 0.5083  decode.d7.loss_mask: 1.3135  decode.d7.loss_dice: 1.0501  decode.d8.loss_cls: 0.5275  decode.d8.loss_mask: 1.2315  decode.d8.loss_dice: 1.0341
05/26 12:58:47 - mmengine - INFO - Iter(train) [ 17650/160000]  base_lr: 9.0015e-05 lr: 9.0015e-06  eta: 16:13:48  time: 0.4080  data_time: 0.0089  memory: 5966  grad_norm: 981.6013  loss: 27.1186  decode.loss_cls: 0.3810  decode.loss_mask: 1.2267  decode.loss_dice: 0.9532  decode.d0.loss_cls: 0.8239  decode.d0.loss_mask: 1.1786  decode.d0.loss_dice: 0.9239  decode.d1.loss_cls: 0.3965  decode.d1.loss_mask: 1.2165  decode.d1.loss_dice: 0.9773  decode.d2.loss_cls: 0.3571  decode.d2.loss_mask: 1.3253  decode.d2.loss_dice: 0.9908  decode.d3.loss_cls: 0.4908  decode.d3.loss_mask: 1.2443  decode.d3.loss_dice: 0.9318  decode.d4.loss_cls: 0.4027  decode.d4.loss_mask: 1.3220  decode.d4.loss_dice: 1.0422  decode.d5.loss_cls: 0.4425  decode.d5.loss_mask: 1.2589  decode.d5.loss_dice: 0.9878  decode.d6.loss_cls: 0.4954  decode.d6.loss_mask: 1.2619  decode.d6.loss_dice: 1.0270  decode.d7.loss_cls: 0.3624  decode.d7.loss_mask: 1.3264  decode.d7.loss_dice: 1.0394  decode.d8.loss_cls: 0.4707  decode.d8.loss_mask: 1.2861  decode.d8.loss_dice: 0.9754
05/26 12:59:08 - mmengine - INFO - Iter(train) [ 17700/160000]  base_lr: 8.9987e-05 lr: 8.9987e-06  eta: 16:13:27  time: 0.4073  data_time: 0.0088  memory: 5965  grad_norm: 1142.7842  loss: 31.9781  decode.loss_cls: 0.4776  decode.loss_mask: 1.5457  decode.loss_dice: 1.1024  decode.d0.loss_cls: 0.9251  decode.d0.loss_mask: 1.5054  decode.d0.loss_dice: 1.0429  decode.d1.loss_cls: 0.5096  decode.d1.loss_mask: 1.5862  decode.d1.loss_dice: 1.1016  decode.d2.loss_cls: 0.5401  decode.d2.loss_mask: 1.5663  decode.d2.loss_dice: 1.0858  decode.d3.loss_cls: 0.4939  decode.d3.loss_mask: 1.5492  decode.d3.loss_dice: 1.0310  decode.d4.loss_cls: 0.4630  decode.d4.loss_mask: 1.6382  decode.d4.loss_dice: 1.0743  decode.d5.loss_cls: 0.4817  decode.d5.loss_mask: 1.5917  decode.d5.loss_dice: 1.1069  decode.d6.loss_cls: 0.5442  decode.d6.loss_mask: 1.6067  decode.d6.loss_dice: 1.0676  decode.d7.loss_cls: 0.4704  decode.d7.loss_mask: 1.6053  decode.d7.loss_dice: 1.0614  decode.d8.loss_cls: 0.4827  decode.d8.loss_mask: 1.5878  decode.d8.loss_dice: 1.1333
05/26 12:59:28 - mmengine - INFO - Iter(train) [ 17750/160000]  base_lr: 8.9958e-05 lr: 8.9958e-06  eta: 16:13:06  time: 0.4084  data_time: 0.0088  memory: 5979  grad_norm: 606.3983  loss: 23.0183  decode.loss_cls: 0.4136  decode.loss_mask: 1.0755  decode.loss_dice: 0.7674  decode.d0.loss_cls: 0.6964  decode.d0.loss_mask: 1.0894  decode.d0.loss_dice: 0.7936  decode.d1.loss_cls: 0.4024  decode.d1.loss_mask: 1.0827  decode.d1.loss_dice: 0.8080  decode.d2.loss_cls: 0.3863  decode.d2.loss_mask: 1.0906  decode.d2.loss_dice: 0.7954  decode.d3.loss_cls: 0.3392  decode.d3.loss_mask: 1.1117  decode.d3.loss_dice: 0.7825  decode.d4.loss_cls: 0.3628  decode.d4.loss_mask: 1.0794  decode.d4.loss_dice: 0.7761  decode.d5.loss_cls: 0.3988  decode.d5.loss_mask: 1.1147  decode.d5.loss_dice: 0.8155  decode.d6.loss_cls: 0.3910  decode.d6.loss_mask: 1.1081  decode.d6.loss_dice: 0.8115  decode.d7.loss_cls: 0.3470  decode.d7.loss_mask: 1.1222  decode.d7.loss_dice: 0.8042  decode.d8.loss_cls: 0.3682  decode.d8.loss_mask: 1.0791  decode.d8.loss_dice: 0.8052
05/26 12:59:48 - mmengine - INFO - Iter(train) [ 17800/160000]  base_lr: 8.9930e-05 lr: 8.9930e-06  eta: 16:12:45  time: 0.4080  data_time: 0.0089  memory: 5969  grad_norm: 673.0983  loss: 28.6014  decode.loss_cls: 0.4300  decode.loss_mask: 1.4606  decode.loss_dice: 1.0275  decode.d0.loss_cls: 0.9041  decode.d0.loss_mask: 1.3680  decode.d0.loss_dice: 0.9652  decode.d1.loss_cls: 0.4517  decode.d1.loss_mask: 1.3837  decode.d1.loss_dice: 0.9389  decode.d2.loss_cls: 0.4203  decode.d2.loss_mask: 1.3221  decode.d2.loss_dice: 0.9312  decode.d3.loss_cls: 0.4239  decode.d3.loss_mask: 1.3961  decode.d3.loss_dice: 0.9905  decode.d4.loss_cls: 0.4373  decode.d4.loss_mask: 1.4334  decode.d4.loss_dice: 0.9816  decode.d5.loss_cls: 0.4699  decode.d5.loss_mask: 1.4082  decode.d5.loss_dice: 0.9597  decode.d6.loss_cls: 0.4290  decode.d6.loss_mask: 1.4421  decode.d6.loss_dice: 1.0194  decode.d7.loss_cls: 0.4110  decode.d7.loss_mask: 1.4218  decode.d7.loss_dice: 0.9644  decode.d8.loss_cls: 0.4487  decode.d8.loss_mask: 1.3772  decode.d8.loss_dice: 0.9840
05/26 13:00:09 - mmengine - INFO - Iter(train) [ 17850/160000]  base_lr: 8.9901e-05 lr: 8.9901e-06  eta: 16:12:23  time: 0.4079  data_time: 0.0088  memory: 5975  grad_norm: 1393.5740  loss: 30.0610  decode.loss_cls: 0.5004  decode.loss_mask: 1.4094  decode.loss_dice: 1.0185  decode.d0.loss_cls: 0.9960  decode.d0.loss_mask: 1.3684  decode.d0.loss_dice: 0.9944  decode.d1.loss_cls: 0.5119  decode.d1.loss_mask: 1.4512  decode.d1.loss_dice: 1.0192  decode.d2.loss_cls: 0.5935  decode.d2.loss_mask: 1.3975  decode.d2.loss_dice: 0.9843  decode.d3.loss_cls: 0.5886  decode.d3.loss_mask: 1.3965  decode.d3.loss_dice: 0.9487  decode.d4.loss_cls: 0.6132  decode.d4.loss_mask: 1.3989  decode.d4.loss_dice: 0.9432  decode.d5.loss_cls: 0.5632  decode.d5.loss_mask: 1.4595  decode.d5.loss_dice: 0.9519  decode.d6.loss_cls: 0.5196  decode.d6.loss_mask: 1.4629  decode.d6.loss_dice: 1.0030  decode.d7.loss_cls: 0.5421  decode.d7.loss_mask: 1.4379  decode.d7.loss_dice: 0.9538  decode.d8.loss_cls: 0.4597  decode.d8.loss_mask: 1.5745  decode.d8.loss_dice: 0.9992
05/26 13:00:29 - mmengine - INFO - Iter(train) [ 17900/160000]  base_lr: 8.9873e-05 lr: 8.9873e-06  eta: 16:12:02  time: 0.4076  data_time: 0.0089  memory: 5974  grad_norm: 612.2756  loss: 28.4324  decode.loss_cls: 0.4862  decode.loss_mask: 1.2810  decode.loss_dice: 1.0111  decode.d0.loss_cls: 0.9072  decode.d0.loss_mask: 1.2643  decode.d0.loss_dice: 0.9621  decode.d1.loss_cls: 0.4956  decode.d1.loss_mask: 1.2744  decode.d1.loss_dice: 0.9854  decode.d2.loss_cls: 0.4766  decode.d2.loss_mask: 1.3269  decode.d2.loss_dice: 1.0005  decode.d3.loss_cls: 0.4294  decode.d3.loss_mask: 1.3504  decode.d3.loss_dice: 0.9859  decode.d4.loss_cls: 0.4892  decode.d4.loss_mask: 1.3133  decode.d4.loss_dice: 1.0003  decode.d5.loss_cls: 0.5053  decode.d5.loss_mask: 1.3120  decode.d5.loss_dice: 0.9943  decode.d6.loss_cls: 0.5500  decode.d6.loss_mask: 1.3475  decode.d6.loss_dice: 1.0120  decode.d7.loss_cls: 0.4753  decode.d7.loss_mask: 1.3697  decode.d7.loss_dice: 1.0127  decode.d8.loss_cls: 0.4779  decode.d8.loss_mask: 1.3519  decode.d8.loss_dice: 0.9839
05/26 13:00:50 - mmengine - INFO - Iter(train) [ 17950/160000]  base_lr: 8.9845e-05 lr: 8.9845e-06  eta: 16:11:42  time: 0.4097  data_time: 0.0103  memory: 5975  grad_norm: 694.7073  loss: 24.3371  decode.loss_cls: 0.3684  decode.loss_mask: 1.1899  decode.loss_dice: 0.9128  decode.d0.loss_cls: 0.7467  decode.d0.loss_mask: 1.1067  decode.d0.loss_dice: 0.8350  decode.d1.loss_cls: 0.3833  decode.d1.loss_mask: 1.2131  decode.d1.loss_dice: 0.8825  decode.d2.loss_cls: 0.3872  decode.d2.loss_mask: 1.1775  decode.d2.loss_dice: 0.9118  decode.d3.loss_cls: 0.3184  decode.d3.loss_mask: 1.1533  decode.d3.loss_dice: 0.9007  decode.d4.loss_cls: 0.3633  decode.d4.loss_mask: 1.1362  decode.d4.loss_dice: 0.8754  decode.d5.loss_cls: 0.3493  decode.d5.loss_mask: 1.1490  decode.d5.loss_dice: 0.8602  decode.d6.loss_cls: 0.3709  decode.d6.loss_mask: 1.1589  decode.d6.loss_dice: 0.8567  decode.d7.loss_cls: 0.3540  decode.d7.loss_mask: 1.1412  decode.d7.loss_dice: 0.8566  decode.d8.loss_cls: 0.3711  decode.d8.loss_mask: 1.1396  decode.d8.loss_dice: 0.8671
05/26 13:01:10 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 13:01:10 - mmengine - INFO - Iter(train) [ 18000/160000]  base_lr: 8.9816e-05 lr: 8.9816e-06  eta: 16:11:22  time: 0.4176  data_time: 0.0105  memory: 5975  grad_norm: 770.8370  loss: 28.2732  decode.loss_cls: 0.4341  decode.loss_mask: 1.4479  decode.loss_dice: 0.9422  decode.d0.loss_cls: 0.8156  decode.d0.loss_mask: 1.2657  decode.d0.loss_dice: 0.9261  decode.d1.loss_cls: 0.4312  decode.d1.loss_mask: 1.3898  decode.d1.loss_dice: 0.9419  decode.d2.loss_cls: 0.4075  decode.d2.loss_mask: 1.3892  decode.d2.loss_dice: 0.9660  decode.d3.loss_cls: 0.4803  decode.d3.loss_mask: 1.3515  decode.d3.loss_dice: 0.9545  decode.d4.loss_cls: 0.4754  decode.d4.loss_mask: 1.3937  decode.d4.loss_dice: 0.9855  decode.d5.loss_cls: 0.4819  decode.d5.loss_mask: 1.3639  decode.d5.loss_dice: 0.9348  decode.d6.loss_cls: 0.4532  decode.d6.loss_mask: 1.4446  decode.d6.loss_dice: 0.9694  decode.d7.loss_cls: 0.4706  decode.d7.loss_mask: 1.3902  decode.d7.loss_dice: 0.9345  decode.d8.loss_cls: 0.4215  decode.d8.loss_mask: 1.4423  decode.d8.loss_dice: 0.9682
05/26 13:01:31 - mmengine - INFO - Iter(train) [ 18050/160000]  base_lr: 8.9788e-05 lr: 8.9788e-06  eta: 16:11:00  time: 0.4076  data_time: 0.0089  memory: 5980  grad_norm: 656.6707  loss: 28.3096  decode.loss_cls: 0.3076  decode.loss_mask: 1.4139  decode.loss_dice: 1.0068  decode.d0.loss_cls: 0.8807  decode.d0.loss_mask: 1.3564  decode.d0.loss_dice: 0.9905  decode.d1.loss_cls: 0.3334  decode.d1.loss_mask: 1.4117  decode.d1.loss_dice: 1.0458  decode.d2.loss_cls: 0.3563  decode.d2.loss_mask: 1.4171  decode.d2.loss_dice: 1.0624  decode.d3.loss_cls: 0.3048  decode.d3.loss_mask: 1.4353  decode.d3.loss_dice: 1.0958  decode.d4.loss_cls: 0.3786  decode.d4.loss_mask: 1.4142  decode.d4.loss_dice: 1.0280  decode.d5.loss_cls: 0.3699  decode.d5.loss_mask: 1.4074  decode.d5.loss_dice: 0.9949  decode.d6.loss_cls: 0.3948  decode.d6.loss_mask: 1.3986  decode.d6.loss_dice: 1.0343  decode.d7.loss_cls: 0.3469  decode.d7.loss_mask: 1.3978  decode.d7.loss_dice: 1.0182  decode.d8.loss_cls: 0.3100  decode.d8.loss_mask: 1.3976  decode.d8.loss_dice: 0.9995
05/26 13:01:52 - mmengine - INFO - Iter(train) [ 18100/160000]  base_lr: 8.9759e-05 lr: 8.9759e-06  eta: 16:10:44  time: 0.4092  data_time: 0.0089  memory: 5966  grad_norm: 1042.4751  loss: 25.8519  decode.loss_cls: 0.2747  decode.loss_mask: 1.2792  decode.loss_dice: 0.9568  decode.d0.loss_cls: 0.7185  decode.d0.loss_mask: 1.2452  decode.d0.loss_dice: 0.9687  decode.d1.loss_cls: 0.3118  decode.d1.loss_mask: 1.2889  decode.d1.loss_dice: 0.9532  decode.d2.loss_cls: 0.3027  decode.d2.loss_mask: 1.2725  decode.d2.loss_dice: 0.9391  decode.d3.loss_cls: 0.3356  decode.d3.loss_mask: 1.2841  decode.d3.loss_dice: 0.9032  decode.d4.loss_cls: 0.3317  decode.d4.loss_mask: 1.2977  decode.d4.loss_dice: 0.9326  decode.d5.loss_cls: 0.3354  decode.d5.loss_mask: 1.2672  decode.d5.loss_dice: 0.9590  decode.d6.loss_cls: 0.3207  decode.d6.loss_mask: 1.3155  decode.d6.loss_dice: 0.9556  decode.d7.loss_cls: 0.2979  decode.d7.loss_mask: 1.3016  decode.d7.loss_dice: 0.9705  decode.d8.loss_cls: 0.2690  decode.d8.loss_mask: 1.2950  decode.d8.loss_dice: 0.9685
05/26 13:02:12 - mmengine - INFO - Iter(train) [ 18150/160000]  base_lr: 8.9731e-05 lr: 8.9731e-06  eta: 16:10:23  time: 0.4093  data_time: 0.0089  memory: 5990  grad_norm: 662.2483  loss: 24.3384  decode.loss_cls: 0.1984  decode.loss_mask: 1.3288  decode.loss_dice: 0.8190  decode.d0.loss_cls: 0.8109  decode.d0.loss_mask: 1.1670  decode.d0.loss_dice: 0.7654  decode.d1.loss_cls: 0.2860  decode.d1.loss_mask: 1.2507  decode.d1.loss_dice: 0.8076  decode.d2.loss_cls: 0.2929  decode.d2.loss_mask: 1.3110  decode.d2.loss_dice: 0.8305  decode.d3.loss_cls: 0.2757  decode.d3.loss_mask: 1.3127  decode.d3.loss_dice: 0.8324  decode.d4.loss_cls: 0.3422  decode.d4.loss_mask: 1.3170  decode.d4.loss_dice: 0.8256  decode.d5.loss_cls: 0.3317  decode.d5.loss_mask: 1.2669  decode.d5.loss_dice: 0.7667  decode.d6.loss_cls: 0.3388  decode.d6.loss_mask: 1.2966  decode.d6.loss_dice: 0.8137  decode.d7.loss_cls: 0.2973  decode.d7.loss_mask: 1.2795  decode.d7.loss_dice: 0.8162  decode.d8.loss_cls: 0.2603  decode.d8.loss_mask: 1.2678  decode.d8.loss_dice: 0.8289
05/26 13:02:33 - mmengine - INFO - Iter(train) [ 18200/160000]  base_lr: 8.9702e-05 lr: 8.9702e-06  eta: 16:10:02  time: 0.4093  data_time: 0.0089  memory: 5974  grad_norm: 788.6893  loss: 26.4094  decode.loss_cls: 0.3756  decode.loss_mask: 1.3318  decode.loss_dice: 0.8866  decode.d0.loss_cls: 0.9039  decode.d0.loss_mask: 1.2040  decode.d0.loss_dice: 0.8244  decode.d1.loss_cls: 0.3702  decode.d1.loss_mask: 1.2725  decode.d1.loss_dice: 0.9134  decode.d2.loss_cls: 0.3879  decode.d2.loss_mask: 1.3174  decode.d2.loss_dice: 0.8974  decode.d3.loss_cls: 0.3872  decode.d3.loss_mask: 1.2804  decode.d3.loss_dice: 0.8801  decode.d4.loss_cls: 0.3867  decode.d4.loss_mask: 1.2867  decode.d4.loss_dice: 0.8608  decode.d5.loss_cls: 0.4294  decode.d5.loss_mask: 1.2937  decode.d5.loss_dice: 0.8866  decode.d6.loss_cls: 0.4844  decode.d6.loss_mask: 1.2900  decode.d6.loss_dice: 0.9367  decode.d7.loss_cls: 0.4000  decode.d7.loss_mask: 1.3392  decode.d7.loss_dice: 0.9260  decode.d8.loss_cls: 0.3455  decode.d8.loss_mask: 1.3853  decode.d8.loss_dice: 0.9259
05/26 13:02:53 - mmengine - INFO - Iter(train) [ 18250/160000]  base_lr: 8.9674e-05 lr: 8.9674e-06  eta: 16:09:41  time: 0.4092  data_time: 0.0089  memory: 5974  grad_norm: 694.8332  loss: 25.3733  decode.loss_cls: 0.3437  decode.loss_mask: 1.2059  decode.loss_dice: 0.9044  decode.d0.loss_cls: 0.6897  decode.d0.loss_mask: 1.2005  decode.d0.loss_dice: 0.9527  decode.d1.loss_cls: 0.3273  decode.d1.loss_mask: 1.2272  decode.d1.loss_dice: 0.9586  decode.d2.loss_cls: 0.3644  decode.d2.loss_mask: 1.2000  decode.d2.loss_dice: 0.8982  decode.d3.loss_cls: 0.3924  decode.d3.loss_mask: 1.2168  decode.d3.loss_dice: 0.9321  decode.d4.loss_cls: 0.3927  decode.d4.loss_mask: 1.1952  decode.d4.loss_dice: 0.9111  decode.d5.loss_cls: 0.3969  decode.d5.loss_mask: 1.2100  decode.d5.loss_dice: 0.9311  decode.d6.loss_cls: 0.3829  decode.d6.loss_mask: 1.2292  decode.d6.loss_dice: 0.9607  decode.d7.loss_cls: 0.3009  decode.d7.loss_mask: 1.2618  decode.d7.loss_dice: 0.9644  decode.d8.loss_cls: 0.2799  decode.d8.loss_mask: 1.2283  decode.d8.loss_dice: 0.9142
05/26 13:03:14 - mmengine - INFO - Iter(train) [ 18300/160000]  base_lr: 8.9645e-05 lr: 8.9645e-06  eta: 16:09:19  time: 0.4087  data_time: 0.0088  memory: 5971  grad_norm: 556.2110  loss: 25.8779  decode.loss_cls: 0.4200  decode.loss_mask: 1.2065  decode.loss_dice: 0.9263  decode.d0.loss_cls: 0.8815  decode.d0.loss_mask: 1.1212  decode.d0.loss_dice: 0.8869  decode.d1.loss_cls: 0.4352  decode.d1.loss_mask: 1.1455  decode.d1.loss_dice: 0.9331  decode.d2.loss_cls: 0.4649  decode.d2.loss_mask: 1.1764  decode.d2.loss_dice: 0.9196  decode.d3.loss_cls: 0.4491  decode.d3.loss_mask: 1.1211  decode.d3.loss_dice: 0.9112  decode.d4.loss_cls: 0.4515  decode.d4.loss_mask: 1.1819  decode.d4.loss_dice: 0.9214  decode.d5.loss_cls: 0.4800  decode.d5.loss_mask: 1.1420  decode.d5.loss_dice: 0.9669  decode.d6.loss_cls: 0.4184  decode.d6.loss_mask: 1.2068  decode.d6.loss_dice: 0.9487  decode.d7.loss_cls: 0.4218  decode.d7.loss_mask: 1.1607  decode.d7.loss_dice: 0.9293  decode.d8.loss_cls: 0.3975  decode.d8.loss_mask: 1.2502  decode.d8.loss_dice: 1.0019
05/26 13:03:34 - mmengine - INFO - Iter(train) [ 18350/160000]  base_lr: 8.9617e-05 lr: 8.9617e-06  eta: 16:08:59  time: 0.4103  data_time: 0.0089  memory: 5974  grad_norm: 584.3422  loss: 27.2162  decode.loss_cls: 0.3636  decode.loss_mask: 1.3026  decode.loss_dice: 0.9889  decode.d0.loss_cls: 0.7479  decode.d0.loss_mask: 1.2817  decode.d0.loss_dice: 1.0238  decode.d1.loss_cls: 0.3749  decode.d1.loss_mask: 1.2955  decode.d1.loss_dice: 0.9688  decode.d2.loss_cls: 0.3822  decode.d2.loss_mask: 1.2954  decode.d2.loss_dice: 0.9749  decode.d3.loss_cls: 0.3745  decode.d3.loss_mask: 1.2969  decode.d3.loss_dice: 0.9383  decode.d4.loss_cls: 0.4173  decode.d4.loss_mask: 1.3211  decode.d4.loss_dice: 0.9933  decode.d5.loss_cls: 0.4044  decode.d5.loss_mask: 1.3544  decode.d5.loss_dice: 0.9982  decode.d6.loss_cls: 0.4843  decode.d6.loss_mask: 1.3316  decode.d6.loss_dice: 0.9473  decode.d7.loss_cls: 0.4205  decode.d7.loss_mask: 1.2770  decode.d7.loss_dice: 0.9841  decode.d8.loss_cls: 0.4271  decode.d8.loss_mask: 1.2725  decode.d8.loss_dice: 0.9732
05/26 13:03:55 - mmengine - INFO - Iter(train) [ 18400/160000]  base_lr: 8.9588e-05 lr: 8.9588e-06  eta: 16:08:39  time: 0.4105  data_time: 0.0089  memory: 5967  grad_norm: 603.4636  loss: 25.4983  decode.loss_cls: 0.2718  decode.loss_mask: 1.2926  decode.loss_dice: 0.8692  decode.d0.loss_cls: 0.7986  decode.d0.loss_mask: 1.2584  decode.d0.loss_dice: 0.8404  decode.d1.loss_cls: 0.2571  decode.d1.loss_mask: 1.3503  decode.d1.loss_dice: 0.9096  decode.d2.loss_cls: 0.3552  decode.d2.loss_mask: 1.3186  decode.d2.loss_dice: 0.8810  decode.d3.loss_cls: 0.3165  decode.d3.loss_mask: 1.2974  decode.d3.loss_dice: 0.9033  decode.d4.loss_cls: 0.3489  decode.d4.loss_mask: 1.3053  decode.d4.loss_dice: 0.8854  decode.d5.loss_cls: 0.3156  decode.d5.loss_mask: 1.3006  decode.d5.loss_dice: 0.8802  decode.d6.loss_cls: 0.3086  decode.d6.loss_mask: 1.3062  decode.d6.loss_dice: 0.8982  decode.d7.loss_cls: 0.3175  decode.d7.loss_mask: 1.3048  decode.d7.loss_dice: 0.8983  decode.d8.loss_cls: 0.3182  decode.d8.loss_mask: 1.3059  decode.d8.loss_dice: 0.8846
05/26 13:04:15 - mmengine - INFO - Iter(train) [ 18450/160000]  base_lr: 8.9560e-05 lr: 8.9560e-06  eta: 16:08:18  time: 0.4106  data_time: 0.0089  memory: 5969  grad_norm: 874.1777  loss: 29.5643  decode.loss_cls: 0.1997  decode.loss_mask: 1.5299  decode.loss_dice: 1.1607  decode.d0.loss_cls: 0.7999  decode.d0.loss_mask: 1.4296  decode.d0.loss_dice: 1.0470  decode.d1.loss_cls: 0.2650  decode.d1.loss_mask: 1.5046  decode.d1.loss_dice: 1.1374  decode.d2.loss_cls: 0.2444  decode.d2.loss_mask: 1.5365  decode.d2.loss_dice: 1.1418  decode.d3.loss_cls: 0.2433  decode.d3.loss_mask: 1.5444  decode.d3.loss_dice: 1.1494  decode.d4.loss_cls: 0.3042  decode.d4.loss_mask: 1.5159  decode.d4.loss_dice: 1.1274  decode.d5.loss_cls: 0.2636  decode.d5.loss_mask: 1.5419  decode.d5.loss_dice: 1.1359  decode.d6.loss_cls: 0.3161  decode.d6.loss_mask: 1.4928  decode.d6.loss_dice: 1.1227  decode.d7.loss_cls: 0.2572  decode.d7.loss_mask: 1.5256  decode.d7.loss_dice: 1.1079  decode.d8.loss_cls: 0.2573  decode.d8.loss_mask: 1.5294  decode.d8.loss_dice: 1.1328
05/26 13:04:36 - mmengine - INFO - Iter(train) [ 18500/160000]  base_lr: 8.9531e-05 lr: 8.9531e-06  eta: 16:07:57  time: 0.4082  data_time: 0.0089  memory: 5969  grad_norm: 924.7230  loss: 22.1080  decode.loss_cls: 0.2180  decode.loss_mask: 1.1581  decode.loss_dice: 0.7697  decode.d0.loss_cls: 0.6717  decode.d0.loss_mask: 1.1052  decode.d0.loss_dice: 0.7552  decode.d1.loss_cls: 0.2890  decode.d1.loss_mask: 1.1347  decode.d1.loss_dice: 0.7612  decode.d2.loss_cls: 0.2672  decode.d2.loss_mask: 1.1224  decode.d2.loss_dice: 0.7384  decode.d3.loss_cls: 0.2894  decode.d3.loss_mask: 1.1116  decode.d3.loss_dice: 0.7268  decode.d4.loss_cls: 0.2651  decode.d4.loss_mask: 1.1572  decode.d4.loss_dice: 0.7701  decode.d5.loss_cls: 0.2557  decode.d5.loss_mask: 1.1659  decode.d5.loss_dice: 0.7770  decode.d6.loss_cls: 0.2407  decode.d6.loss_mask: 1.2150  decode.d6.loss_dice: 0.7920  decode.d7.loss_cls: 0.2053  decode.d7.loss_mask: 1.2114  decode.d7.loss_dice: 0.8122  decode.d8.loss_cls: 0.1827  decode.d8.loss_mask: 1.1604  decode.d8.loss_dice: 0.7789
05/26 13:04:56 - mmengine - INFO - Iter(train) [ 18550/160000]  base_lr: 8.9503e-05 lr: 8.9503e-06  eta: 16:07:36  time: 0.4070  data_time: 0.0089  memory: 5978  grad_norm: 1478.2558  loss: 28.2684  decode.loss_cls: 0.3449  decode.loss_mask: 1.2903  decode.loss_dice: 1.1185  decode.d0.loss_cls: 0.9272  decode.d0.loss_mask: 1.2042  decode.d0.loss_dice: 1.0565  decode.d1.loss_cls: 0.4026  decode.d1.loss_mask: 1.2962  decode.d1.loss_dice: 1.1242  decode.d2.loss_cls: 0.3546  decode.d2.loss_mask: 1.2811  decode.d2.loss_dice: 1.1085  decode.d3.loss_cls: 0.3590  decode.d3.loss_mask: 1.2728  decode.d3.loss_dice: 1.0979  decode.d4.loss_cls: 0.3831  decode.d4.loss_mask: 1.3197  decode.d4.loss_dice: 1.1378  decode.d5.loss_cls: 0.4280  decode.d5.loss_mask: 1.2763  decode.d5.loss_dice: 1.0941  decode.d6.loss_cls: 0.4312  decode.d6.loss_mask: 1.2818  decode.d6.loss_dice: 1.0882  decode.d7.loss_cls: 0.4331  decode.d7.loss_mask: 1.3000  decode.d7.loss_dice: 1.0937  decode.d8.loss_cls: 0.3989  decode.d8.loss_mask: 1.2916  decode.d8.loss_dice: 1.0728
05/26 13:05:17 - mmengine - INFO - Iter(train) [ 18600/160000]  base_lr: 8.9474e-05 lr: 8.9474e-06  eta: 16:07:15  time: 0.4085  data_time: 0.0089  memory: 5968  grad_norm: 634.0815  loss: 33.0956  decode.loss_cls: 0.5482  decode.loss_mask: 1.4359  decode.loss_dice: 1.2088  decode.d0.loss_cls: 1.0404  decode.d0.loss_mask: 1.4410  decode.d0.loss_dice: 1.1786  decode.d1.loss_cls: 0.5480  decode.d1.loss_mask: 1.4586  decode.d1.loss_dice: 1.2251  decode.d2.loss_cls: 0.4689  decode.d2.loss_mask: 1.5616  decode.d2.loss_dice: 1.2881  decode.d3.loss_cls: 0.4954  decode.d3.loss_mask: 1.5699  decode.d3.loss_dice: 1.2766  decode.d4.loss_cls: 0.5913  decode.d4.loss_mask: 1.5401  decode.d4.loss_dice: 1.2242  decode.d5.loss_cls: 0.5795  decode.d5.loss_mask: 1.4628  decode.d5.loss_dice: 1.1949  decode.d6.loss_cls: 0.6221  decode.d6.loss_mask: 1.4713  decode.d6.loss_dice: 1.2263  decode.d7.loss_cls: 0.5322  decode.d7.loss_mask: 1.4576  decode.d7.loss_dice: 1.1965  decode.d8.loss_cls: 0.5496  decode.d8.loss_mask: 1.4486  decode.d8.loss_dice: 1.2539
05/26 13:05:37 - mmengine - INFO - Iter(train) [ 18650/160000]  base_lr: 8.9446e-05 lr: 8.9446e-06  eta: 16:06:54  time: 0.4088  data_time: 0.0089  memory: 5967  grad_norm: 746.1202  loss: 28.8527  decode.loss_cls: 0.4208  decode.loss_mask: 1.4030  decode.loss_dice: 0.9838  decode.d0.loss_cls: 0.8905  decode.d0.loss_mask: 1.3551  decode.d0.loss_dice: 0.9802  decode.d1.loss_cls: 0.4920  decode.d1.loss_mask: 1.3809  decode.d1.loss_dice: 0.9950  decode.d2.loss_cls: 0.4370  decode.d2.loss_mask: 1.3996  decode.d2.loss_dice: 0.9792  decode.d3.loss_cls: 0.4627  decode.d3.loss_mask: 1.3773  decode.d3.loss_dice: 0.9787  decode.d4.loss_cls: 0.4820  decode.d4.loss_mask: 1.3984  decode.d4.loss_dice: 1.0048  decode.d5.loss_cls: 0.5167  decode.d5.loss_mask: 1.3383  decode.d5.loss_dice: 0.9730  decode.d6.loss_cls: 0.5344  decode.d6.loss_mask: 1.3545  decode.d6.loss_dice: 0.9781  decode.d7.loss_cls: 0.4763  decode.d7.loss_mask: 1.3726  decode.d7.loss_dice: 0.9764  decode.d8.loss_cls: 0.4799  decode.d8.loss_mask: 1.4242  decode.d8.loss_dice: 1.0072
05/26 13:05:58 - mmengine - INFO - Iter(train) [ 18700/160000]  base_lr: 8.9417e-05 lr: 8.9417e-06  eta: 16:06:32  time: 0.4078  data_time: 0.0089  memory: 5975  grad_norm: 635.9491  loss: 29.8573  decode.loss_cls: 0.3677  decode.loss_mask: 1.5504  decode.loss_dice: 1.0962  decode.d0.loss_cls: 0.9411  decode.d0.loss_mask: 1.3483  decode.d0.loss_dice: 1.0098  decode.d1.loss_cls: 0.4001  decode.d1.loss_mask: 1.4230  decode.d1.loss_dice: 1.0430  decode.d2.loss_cls: 0.3950  decode.d2.loss_mask: 1.4307  decode.d2.loss_dice: 1.0202  decode.d3.loss_cls: 0.4348  decode.d3.loss_mask: 1.4184  decode.d3.loss_dice: 1.0458  decode.d4.loss_cls: 0.4731  decode.d4.loss_mask: 1.4477  decode.d4.loss_dice: 1.0497  decode.d5.loss_cls: 0.4479  decode.d5.loss_mask: 1.5000  decode.d5.loss_dice: 1.0921  decode.d6.loss_cls: 0.3859  decode.d6.loss_mask: 1.4909  decode.d6.loss_dice: 1.0693  decode.d7.loss_cls: 0.3607  decode.d7.loss_mask: 1.4918  decode.d7.loss_dice: 1.1077  decode.d8.loss_cls: 0.3383  decode.d8.loss_mask: 1.5595  decode.d8.loss_dice: 1.1181
05/26 13:06:18 - mmengine - INFO - Iter(train) [ 18750/160000]  base_lr: 8.9389e-05 lr: 8.9389e-06  eta: 16:06:11  time: 0.4081  data_time: 0.0089  memory: 5979  grad_norm: 450.7385  loss: 27.4820  decode.loss_cls: 0.4565  decode.loss_mask: 1.3399  decode.loss_dice: 0.9453  decode.d0.loss_cls: 0.9315  decode.d0.loss_mask: 1.2490  decode.d0.loss_dice: 0.9369  decode.d1.loss_cls: 0.4772  decode.d1.loss_mask: 1.2305  decode.d1.loss_dice: 0.9418  decode.d2.loss_cls: 0.4571  decode.d2.loss_mask: 1.2586  decode.d2.loss_dice: 0.9291  decode.d3.loss_cls: 0.4873  decode.d3.loss_mask: 1.2591  decode.d3.loss_dice: 0.9144  decode.d4.loss_cls: 0.5675  decode.d4.loss_mask: 1.2395  decode.d4.loss_dice: 0.9400  decode.d5.loss_cls: 0.5328  decode.d5.loss_mask: 1.2512  decode.d5.loss_dice: 0.9928  decode.d6.loss_cls: 0.5390  decode.d6.loss_mask: 1.2773  decode.d6.loss_dice: 0.9688  decode.d7.loss_cls: 0.4835  decode.d7.loss_mask: 1.2669  decode.d7.loss_dice: 0.9063  decode.d8.loss_cls: 0.4687  decode.d8.loss_mask: 1.2906  decode.d8.loss_dice: 0.9430
05/26 13:06:39 - mmengine - INFO - Iter(train) [ 18800/160000]  base_lr: 8.9361e-05 lr: 8.9361e-06  eta: 16:05:51  time: 0.4091  data_time: 0.0089  memory: 5971  grad_norm: 1249.7810  loss: 28.6482  decode.loss_cls: 0.4567  decode.loss_mask: 1.2834  decode.loss_dice: 1.0367  decode.d0.loss_cls: 0.8701  decode.d0.loss_mask: 1.3126  decode.d0.loss_dice: 1.0755  decode.d1.loss_cls: 0.3556  decode.d1.loss_mask: 1.3064  decode.d1.loss_dice: 1.0998  decode.d2.loss_cls: 0.3958  decode.d2.loss_mask: 1.3833  decode.d2.loss_dice: 1.0863  decode.d3.loss_cls: 0.4384  decode.d3.loss_mask: 1.3046  decode.d3.loss_dice: 1.0326  decode.d4.loss_cls: 0.4655  decode.d4.loss_mask: 1.2796  decode.d4.loss_dice: 1.0167  decode.d5.loss_cls: 0.4539  decode.d5.loss_mask: 1.3077  decode.d5.loss_dice: 1.0383  decode.d6.loss_cls: 0.5032  decode.d6.loss_mask: 1.2901  decode.d6.loss_dice: 1.0742  decode.d7.loss_cls: 0.4722  decode.d7.loss_mask: 1.3313  decode.d7.loss_dice: 1.0449  decode.d8.loss_cls: 0.4156  decode.d8.loss_mask: 1.3656  decode.d8.loss_dice: 1.1517
05/26 13:06:59 - mmengine - INFO - Iter(train) [ 18850/160000]  base_lr: 8.9332e-05 lr: 8.9332e-06  eta: 16:05:30  time: 0.4085  data_time: 0.0089  memory: 5973  grad_norm: 1142.7876  loss: 26.8265  decode.loss_cls: 0.3892  decode.loss_mask: 1.3167  decode.loss_dice: 0.9405  decode.d0.loss_cls: 0.8467  decode.d0.loss_mask: 1.2282  decode.d0.loss_dice: 0.8997  decode.d1.loss_cls: 0.4268  decode.d1.loss_mask: 1.3172  decode.d1.loss_dice: 0.9316  decode.d2.loss_cls: 0.4189  decode.d2.loss_mask: 1.3012  decode.d2.loss_dice: 0.9163  decode.d3.loss_cls: 0.3716  decode.d3.loss_mask: 1.3284  decode.d3.loss_dice: 0.9444  decode.d4.loss_cls: 0.4508  decode.d4.loss_mask: 1.2766  decode.d4.loss_dice: 0.8866  decode.d5.loss_cls: 0.4356  decode.d5.loss_mask: 1.2580  decode.d5.loss_dice: 0.9566  decode.d6.loss_cls: 0.4279  decode.d6.loss_mask: 1.3386  decode.d6.loss_dice: 0.9274  decode.d7.loss_cls: 0.3856  decode.d7.loss_mask: 1.3451  decode.d7.loss_dice: 0.9487  decode.d8.loss_cls: 0.3590  decode.d8.loss_mask: 1.2990  decode.d8.loss_dice: 0.9536
05/26 13:07:19 - mmengine - INFO - Iter(train) [ 18900/160000]  base_lr: 8.9304e-05 lr: 8.9304e-06  eta: 16:05:09  time: 0.4097  data_time: 0.0089  memory: 5970  grad_norm: 745.4858  loss: 27.5743  decode.loss_cls: 0.4401  decode.loss_mask: 1.2993  decode.loss_dice: 0.9725  decode.d0.loss_cls: 0.8774  decode.d0.loss_mask: 1.2979  decode.d0.loss_dice: 0.9944  decode.d1.loss_cls: 0.4893  decode.d1.loss_mask: 1.2818  decode.d1.loss_dice: 1.0040  decode.d2.loss_cls: 0.4171  decode.d2.loss_mask: 1.2847  decode.d2.loss_dice: 0.9748  decode.d3.loss_cls: 0.4527  decode.d3.loss_mask: 1.2581  decode.d3.loss_dice: 0.9486  decode.d4.loss_cls: 0.4717  decode.d4.loss_mask: 1.2715  decode.d4.loss_dice: 0.9635  decode.d5.loss_cls: 0.4255  decode.d5.loss_mask: 1.2695  decode.d5.loss_dice: 0.9690  decode.d6.loss_cls: 0.4441  decode.d6.loss_mask: 1.3303  decode.d6.loss_dice: 0.9630  decode.d7.loss_cls: 0.4730  decode.d7.loss_mask: 1.3044  decode.d7.loss_dice: 1.0265  decode.d8.loss_cls: 0.4555  decode.d8.loss_mask: 1.2661  decode.d8.loss_dice: 0.9481
05/26 13:07:40 - mmengine - INFO - Iter(train) [ 18950/160000]  base_lr: 8.9275e-05 lr: 8.9275e-06  eta: 16:04:48  time: 0.4119  data_time: 0.0111  memory: 5979  grad_norm: 769.4012  loss: 25.8045  decode.loss_cls: 0.4084  decode.loss_mask: 1.1951  decode.loss_dice: 0.8945  decode.d0.loss_cls: 0.8901  decode.d0.loss_mask: 1.1349  decode.d0.loss_dice: 0.9104  decode.d1.loss_cls: 0.4152  decode.d1.loss_mask: 1.2245  decode.d1.loss_dice: 0.9284  decode.d2.loss_cls: 0.4294  decode.d2.loss_mask: 1.1752  decode.d2.loss_dice: 0.8998  decode.d3.loss_cls: 0.4669  decode.d3.loss_mask: 1.1578  decode.d3.loss_dice: 0.8866  decode.d4.loss_cls: 0.4718  decode.d4.loss_mask: 1.1768  decode.d4.loss_dice: 0.8880  decode.d5.loss_cls: 0.3837  decode.d5.loss_mask: 1.2561  decode.d5.loss_dice: 0.9360  decode.d6.loss_cls: 0.4837  decode.d6.loss_mask: 1.1409  decode.d6.loss_dice: 0.8805  decode.d7.loss_cls: 0.4130  decode.d7.loss_mask: 1.2515  decode.d7.loss_dice: 0.9026  decode.d8.loss_cls: 0.4504  decode.d8.loss_mask: 1.2019  decode.d8.loss_dice: 0.9503
05/26 13:08:00 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 13:08:00 - mmengine - INFO - Iter(train) [ 19000/160000]  base_lr: 8.9247e-05 lr: 8.9247e-06  eta: 16:04:27  time: 0.4099  data_time: 0.0089  memory: 5976  grad_norm: 904.4062  loss: 30.3296  decode.loss_cls: 0.5001  decode.loss_mask: 1.4234  decode.loss_dice: 1.0903  decode.d0.loss_cls: 0.9992  decode.d0.loss_mask: 1.3153  decode.d0.loss_dice: 1.0687  decode.d1.loss_cls: 0.4825  decode.d1.loss_mask: 1.4030  decode.d1.loss_dice: 1.1279  decode.d2.loss_cls: 0.4322  decode.d2.loss_mask: 1.4056  decode.d2.loss_dice: 1.0979  decode.d3.loss_cls: 0.4833  decode.d3.loss_mask: 1.3572  decode.d3.loss_dice: 1.0520  decode.d4.loss_cls: 0.5428  decode.d4.loss_mask: 1.2936  decode.d4.loss_dice: 1.0659  decode.d5.loss_cls: 0.5895  decode.d5.loss_mask: 1.3830  decode.d5.loss_dice: 1.0973  decode.d6.loss_cls: 0.5271  decode.d6.loss_mask: 1.3732  decode.d6.loss_dice: 1.1334  decode.d7.loss_cls: 0.5499  decode.d7.loss_mask: 1.3515  decode.d7.loss_dice: 1.1288  decode.d8.loss_cls: 0.5439  decode.d8.loss_mask: 1.4076  decode.d8.loss_dice: 1.1033
05/26 13:08:21 - mmengine - INFO - Iter(train) [ 19050/160000]  base_lr: 8.9218e-05 lr: 8.9218e-06  eta: 16:04:06  time: 0.4081  data_time: 0.0089  memory: 5968  grad_norm: 1376.9992  loss: 26.0972  decode.loss_cls: 0.3723  decode.loss_mask: 1.2466  decode.loss_dice: 0.9131  decode.d0.loss_cls: 0.8888  decode.d0.loss_mask: 1.1253  decode.d0.loss_dice: 0.8517  decode.d1.loss_cls: 0.4586  decode.d1.loss_mask: 1.2416  decode.d1.loss_dice: 0.8740  decode.d2.loss_cls: 0.3942  decode.d2.loss_mask: 1.2463  decode.d2.loss_dice: 0.9070  decode.d3.loss_cls: 0.4025  decode.d3.loss_mask: 1.3299  decode.d3.loss_dice: 0.8832  decode.d4.loss_cls: 0.4843  decode.d4.loss_mask: 1.1859  decode.d4.loss_dice: 0.8608  decode.d5.loss_cls: 0.4331  decode.d5.loss_mask: 1.3076  decode.d5.loss_dice: 0.8868  decode.d6.loss_cls: 0.4042  decode.d6.loss_mask: 1.2893  decode.d6.loss_dice: 0.9058  decode.d7.loss_cls: 0.4243  decode.d7.loss_mask: 1.3053  decode.d7.loss_dice: 0.9124  decode.d8.loss_cls: 0.3978  decode.d8.loss_mask: 1.2593  decode.d8.loss_dice: 0.9053
05/26 13:08:41 - mmengine - INFO - Iter(train) [ 19100/160000]  base_lr: 8.9190e-05 lr: 8.9190e-06  eta: 16:03:45  time: 0.4076  data_time: 0.0089  memory: 5974  grad_norm: 647.0182  loss: 28.2001  decode.loss_cls: 0.4565  decode.loss_mask: 1.3715  decode.loss_dice: 0.9660  decode.d0.loss_cls: 0.8100  decode.d0.loss_mask: 1.3063  decode.d0.loss_dice: 0.9324  decode.d1.loss_cls: 0.4022  decode.d1.loss_mask: 1.4156  decode.d1.loss_dice: 1.0063  decode.d2.loss_cls: 0.4755  decode.d2.loss_mask: 1.3792  decode.d2.loss_dice: 0.9750  decode.d3.loss_cls: 0.4674  decode.d3.loss_mask: 1.3711  decode.d3.loss_dice: 0.9926  decode.d4.loss_cls: 0.4717  decode.d4.loss_mask: 1.3543  decode.d4.loss_dice: 0.9497  decode.d5.loss_cls: 0.4427  decode.d5.loss_mask: 1.3844  decode.d5.loss_dice: 0.9574  decode.d6.loss_cls: 0.4543  decode.d6.loss_mask: 1.3385  decode.d6.loss_dice: 0.9279  decode.d7.loss_cls: 0.3981  decode.d7.loss_mask: 1.3923  decode.d7.loss_dice: 0.9810  decode.d8.loss_cls: 0.4731  decode.d8.loss_mask: 1.3618  decode.d8.loss_dice: 0.9854
05/26 13:09:02 - mmengine - INFO - Iter(train) [ 19150/160000]  base_lr: 8.9161e-05 lr: 8.9161e-06  eta: 16:03:25  time: 0.4095  data_time: 0.0089  memory: 5967  grad_norm: 650.1220  loss: 28.4452  decode.loss_cls: 0.4061  decode.loss_mask: 1.3438  decode.loss_dice: 1.0354  decode.d0.loss_cls: 0.8881  decode.d0.loss_mask: 1.2913  decode.d0.loss_dice: 1.0301  decode.d1.loss_cls: 0.4515  decode.d1.loss_mask: 1.3230  decode.d1.loss_dice: 1.0415  decode.d2.loss_cls: 0.4556  decode.d2.loss_mask: 1.3344  decode.d2.loss_dice: 0.9795  decode.d3.loss_cls: 0.4436  decode.d3.loss_mask: 1.3388  decode.d3.loss_dice: 1.0271  decode.d4.loss_cls: 0.4497  decode.d4.loss_mask: 1.2979  decode.d4.loss_dice: 0.9902  decode.d5.loss_cls: 0.4374  decode.d5.loss_mask: 1.2989  decode.d5.loss_dice: 0.9964  decode.d6.loss_cls: 0.4924  decode.d6.loss_mask: 1.3141  decode.d6.loss_dice: 1.0384  decode.d7.loss_cls: 0.4724  decode.d7.loss_mask: 1.3351  decode.d7.loss_dice: 1.0879  decode.d8.loss_cls: 0.4489  decode.d8.loss_mask: 1.3394  decode.d8.loss_dice: 1.0565
05/26 13:09:22 - mmengine - INFO - Iter(train) [ 19200/160000]  base_lr: 8.9133e-05 lr: 8.9133e-06  eta: 16:03:04  time: 0.4097  data_time: 0.0089  memory: 5970  grad_norm: 889.3601  loss: 30.6470  decode.loss_cls: 0.5352  decode.loss_mask: 1.3299  decode.loss_dice: 1.1458  decode.d0.loss_cls: 0.9483  decode.d0.loss_mask: 1.1799  decode.d0.loss_dice: 1.1206  decode.d1.loss_cls: 0.6567  decode.d1.loss_mask: 1.1968  decode.d1.loss_dice: 1.1725  decode.d2.loss_cls: 0.6484  decode.d2.loss_mask: 1.2305  decode.d2.loss_dice: 1.1441  decode.d3.loss_cls: 0.6692  decode.d3.loss_mask: 1.1986  decode.d3.loss_dice: 1.1239  decode.d4.loss_cls: 0.6545  decode.d4.loss_mask: 1.2530  decode.d4.loss_dice: 1.1477  decode.d5.loss_cls: 0.6217  decode.d5.loss_mask: 1.2627  decode.d5.loss_dice: 1.1568  decode.d6.loss_cls: 0.6123  decode.d6.loss_mask: 1.2431  decode.d6.loss_dice: 1.1892  decode.d7.loss_cls: 0.6019  decode.d7.loss_mask: 1.2775  decode.d7.loss_dice: 1.1947  decode.d8.loss_cls: 0.5986  decode.d8.loss_mask: 1.3539  decode.d8.loss_dice: 1.1790
05/26 13:09:43 - mmengine - INFO - Iter(train) [ 19250/160000]  base_lr: 8.9104e-05 lr: 8.9104e-06  eta: 16:02:43  time: 0.4094  data_time: 0.0088  memory: 5967  grad_norm: 750.3341  loss: 30.2807  decode.loss_cls: 0.4474  decode.loss_mask: 1.3600  decode.loss_dice: 1.1000  decode.d0.loss_cls: 0.9818  decode.d0.loss_mask: 1.2882  decode.d0.loss_dice: 1.0658  decode.d1.loss_cls: 0.4924  decode.d1.loss_mask: 1.4000  decode.d1.loss_dice: 1.1424  decode.d2.loss_cls: 0.4249  decode.d2.loss_mask: 1.4330  decode.d2.loss_dice: 1.1316  decode.d3.loss_cls: 0.4603  decode.d3.loss_mask: 1.4502  decode.d3.loss_dice: 1.1293  decode.d4.loss_cls: 0.5664  decode.d4.loss_mask: 1.3937  decode.d4.loss_dice: 1.1189  decode.d5.loss_cls: 0.5059  decode.d5.loss_mask: 1.3819  decode.d5.loss_dice: 1.0965  decode.d6.loss_cls: 0.5073  decode.d6.loss_mask: 1.4623  decode.d6.loss_dice: 1.0820  decode.d7.loss_cls: 0.4897  decode.d7.loss_mask: 1.3965  decode.d7.loss_dice: 1.0825  decode.d8.loss_cls: 0.4875  decode.d8.loss_mask: 1.3547  decode.d8.loss_dice: 1.0475
05/26 13:10:03 - mmengine - INFO - Iter(train) [ 19300/160000]  base_lr: 8.9076e-05 lr: 8.9076e-06  eta: 16:02:22  time: 0.4101  data_time: 0.0088  memory: 5967  grad_norm: 1166.4132  loss: 27.3850  decode.loss_cls: 0.4788  decode.loss_mask: 1.2509  decode.loss_dice: 0.9079  decode.d0.loss_cls: 0.8407  decode.d0.loss_mask: 1.1910  decode.d0.loss_dice: 0.9342  decode.d1.loss_cls: 0.5074  decode.d1.loss_mask: 1.2510  decode.d1.loss_dice: 0.9354  decode.d2.loss_cls: 0.5641  decode.d2.loss_mask: 1.2092  decode.d2.loss_dice: 0.9528  decode.d3.loss_cls: 0.4988  decode.d3.loss_mask: 1.2602  decode.d3.loss_dice: 0.9596  decode.d4.loss_cls: 0.5349  decode.d4.loss_mask: 1.2205  decode.d4.loss_dice: 0.9185  decode.d5.loss_cls: 0.4964  decode.d5.loss_mask: 1.2739  decode.d5.loss_dice: 0.9499  decode.d6.loss_cls: 0.5163  decode.d6.loss_mask: 1.2804  decode.d6.loss_dice: 0.9368  decode.d7.loss_cls: 0.5129  decode.d7.loss_mask: 1.2639  decode.d7.loss_dice: 0.9344  decode.d8.loss_cls: 0.4647  decode.d8.loss_mask: 1.3755  decode.d8.loss_dice: 0.9640
05/26 13:10:24 - mmengine - INFO - Iter(train) [ 19350/160000]  base_lr: 8.9047e-05 lr: 8.9047e-06  eta: 16:02:01  time: 0.4091  data_time: 0.0088  memory: 5969  grad_norm: 1094.1822  loss: 27.6628  decode.loss_cls: 0.2923  decode.loss_mask: 1.4553  decode.loss_dice: 0.9345  decode.d0.loss_cls: 0.7634  decode.d0.loss_mask: 1.4048  decode.d0.loss_dice: 0.8817  decode.d1.loss_cls: 0.3349  decode.d1.loss_mask: 1.4173  decode.d1.loss_dice: 0.8976  decode.d2.loss_cls: 0.3479  decode.d2.loss_mask: 1.4502  decode.d2.loss_dice: 0.9079  decode.d3.loss_cls: 0.3184  decode.d3.loss_mask: 1.4985  decode.d3.loss_dice: 0.9316  decode.d4.loss_cls: 0.3433  decode.d4.loss_mask: 1.4550  decode.d4.loss_dice: 0.9366  decode.d5.loss_cls: 0.3326  decode.d5.loss_mask: 1.5368  decode.d5.loss_dice: 0.9665  decode.d6.loss_cls: 0.3350  decode.d6.loss_mask: 1.5602  decode.d6.loss_dice: 0.9844  decode.d7.loss_cls: 0.3473  decode.d7.loss_mask: 1.4174  decode.d7.loss_dice: 0.9203  decode.d8.loss_cls: 0.3345  decode.d8.loss_mask: 1.4501  decode.d8.loss_dice: 0.9066
05/26 13:10:44 - mmengine - INFO - Iter(train) [ 19400/160000]  base_lr: 8.9019e-05 lr: 8.9019e-06  eta: 16:01:40  time: 0.4098  data_time: 0.0090  memory: 5969  grad_norm: 506.5322  loss: 20.3458  decode.loss_cls: 0.2351  decode.loss_mask: 1.0307  decode.loss_dice: 0.7184  decode.d0.loss_cls: 0.5788  decode.d0.loss_mask: 1.0080  decode.d0.loss_dice: 0.7296  decode.d1.loss_cls: 0.2363  decode.d1.loss_mask: 1.0196  decode.d1.loss_dice: 0.6936  decode.d2.loss_cls: 0.3038  decode.d2.loss_mask: 0.9734  decode.d2.loss_dice: 0.7009  decode.d3.loss_cls: 0.3018  decode.d3.loss_mask: 0.9978  decode.d3.loss_dice: 0.7180  decode.d4.loss_cls: 0.2855  decode.d4.loss_mask: 1.0232  decode.d4.loss_dice: 0.7149  decode.d5.loss_cls: 0.2195  decode.d5.loss_mask: 1.0810  decode.d5.loss_dice: 0.7317  decode.d6.loss_cls: 0.2706  decode.d6.loss_mask: 0.9815  decode.d6.loss_dice: 0.7059  decode.d7.loss_cls: 0.2888  decode.d7.loss_mask: 1.0362  decode.d7.loss_dice: 0.7262  decode.d8.loss_cls: 0.2594  decode.d8.loss_mask: 1.0408  decode.d8.loss_dice: 0.7347
05/26 13:11:05 - mmengine - INFO - Iter(train) [ 19450/160000]  base_lr: 8.8990e-05 lr: 8.8990e-06  eta: 16:01:20  time: 0.4089  data_time: 0.0089  memory: 5969  grad_norm: 1971.4856  loss: 32.4688  decode.loss_cls: 0.6279  decode.loss_mask: 1.4343  decode.loss_dice: 1.1776  decode.d0.loss_cls: 1.0623  decode.d0.loss_mask: 1.3636  decode.d0.loss_dice: 1.1292  decode.d1.loss_cls: 0.5586  decode.d1.loss_mask: 1.5071  decode.d1.loss_dice: 1.1506  decode.d2.loss_cls: 0.5688  decode.d2.loss_mask: 1.4551  decode.d2.loss_dice: 1.1433  decode.d3.loss_cls: 0.6147  decode.d3.loss_mask: 1.4913  decode.d3.loss_dice: 1.1604  decode.d4.loss_cls: 0.6466  decode.d4.loss_mask: 1.4600  decode.d4.loss_dice: 1.1551  decode.d5.loss_cls: 0.5730  decode.d5.loss_mask: 1.4369  decode.d5.loss_dice: 1.1245  decode.d6.loss_cls: 0.6288  decode.d6.loss_mask: 1.4253  decode.d6.loss_dice: 1.1115  decode.d7.loss_cls: 0.5833  decode.d7.loss_mask: 1.5342  decode.d7.loss_dice: 1.1982  decode.d8.loss_cls: 0.5432  decode.d8.loss_mask: 1.4523  decode.d8.loss_dice: 1.1510
05/26 13:11:25 - mmengine - INFO - Iter(train) [ 19500/160000]  base_lr: 8.8962e-05 lr: 8.8962e-06  eta: 16:00:59  time: 0.4100  data_time: 0.0089  memory: 5973  grad_norm: 803.4276  loss: 26.5196  decode.loss_cls: 0.3298  decode.loss_mask: 1.3190  decode.loss_dice: 0.9146  decode.d0.loss_cls: 0.8944  decode.d0.loss_mask: 1.2708  decode.d0.loss_dice: 0.8698  decode.d1.loss_cls: 0.3798  decode.d1.loss_mask: 1.3845  decode.d1.loss_dice: 0.8807  decode.d2.loss_cls: 0.3326  decode.d2.loss_mask: 1.3312  decode.d2.loss_dice: 0.9116  decode.d3.loss_cls: 0.3776  decode.d3.loss_mask: 1.3318  decode.d3.loss_dice: 0.9009  decode.d4.loss_cls: 0.4300  decode.d4.loss_mask: 1.3297  decode.d4.loss_dice: 0.8637  decode.d5.loss_cls: 0.3838  decode.d5.loss_mask: 1.3448  decode.d5.loss_dice: 0.9119  decode.d6.loss_cls: 0.4409  decode.d6.loss_mask: 1.3993  decode.d6.loss_dice: 0.9013  decode.d7.loss_cls: 0.3929  decode.d7.loss_mask: 1.3030  decode.d7.loss_dice: 0.8689  decode.d8.loss_cls: 0.3096  decode.d8.loss_mask: 1.3151  decode.d8.loss_dice: 0.8957
05/26 13:11:46 - mmengine - INFO - Iter(train) [ 19550/160000]  base_lr: 8.8933e-05 lr: 8.8933e-06  eta: 16:00:38  time: 0.4102  data_time: 0.0088  memory: 5984  grad_norm: 877.3595  loss: 29.5931  decode.loss_cls: 0.4190  decode.loss_mask: 1.4151  decode.loss_dice: 1.0635  decode.d0.loss_cls: 0.9410  decode.d0.loss_mask: 1.3033  decode.d0.loss_dice: 1.0199  decode.d1.loss_cls: 0.4919  decode.d1.loss_mask: 1.4421  decode.d1.loss_dice: 1.0705  decode.d2.loss_cls: 0.4548  decode.d2.loss_mask: 1.3640  decode.d2.loss_dice: 1.0907  decode.d3.loss_cls: 0.4565  decode.d3.loss_mask: 1.3902  decode.d3.loss_dice: 1.0776  decode.d4.loss_cls: 0.5356  decode.d4.loss_mask: 1.3636  decode.d4.loss_dice: 1.0323  decode.d5.loss_cls: 0.5101  decode.d5.loss_mask: 1.3480  decode.d5.loss_dice: 1.0355  decode.d6.loss_cls: 0.5257  decode.d6.loss_mask: 1.3687  decode.d6.loss_dice: 1.0738  decode.d7.loss_cls: 0.4806  decode.d7.loss_mask: 1.3745  decode.d7.loss_dice: 1.0541  decode.d8.loss_cls: 0.4485  decode.d8.loss_mask: 1.3812  decode.d8.loss_dice: 1.0609
05/26 13:12:06 - mmengine - INFO - Iter(train) [ 19600/160000]  base_lr: 8.8905e-05 lr: 8.8905e-06  eta: 16:00:17  time: 0.4093  data_time: 0.0088  memory: 5969  grad_norm: 466.9729  loss: 24.9912  decode.loss_cls: 0.2339  decode.loss_mask: 1.2470  decode.loss_dice: 0.9326  decode.d0.loss_cls: 0.6738  decode.d0.loss_mask: 1.2544  decode.d0.loss_dice: 0.9364  decode.d1.loss_cls: 0.2523  decode.d1.loss_mask: 1.2454  decode.d1.loss_dice: 0.9237  decode.d2.loss_cls: 0.3101  decode.d2.loss_mask: 1.2707  decode.d2.loss_dice: 0.9472  decode.d3.loss_cls: 0.2647  decode.d3.loss_mask: 1.2542  decode.d3.loss_dice: 0.9350  decode.d4.loss_cls: 0.2765  decode.d4.loss_mask: 1.2494  decode.d4.loss_dice: 0.9424  decode.d5.loss_cls: 0.2941  decode.d5.loss_mask: 1.2325  decode.d5.loss_dice: 0.9151  decode.d6.loss_cls: 0.2861  decode.d6.loss_mask: 1.2787  decode.d6.loss_dice: 0.9504  decode.d7.loss_cls: 0.2628  decode.d7.loss_mask: 1.2539  decode.d7.loss_dice: 0.9437  decode.d8.loss_cls: 0.2646  decode.d8.loss_mask: 1.2437  decode.d8.loss_dice: 0.9160
05/26 13:12:27 - mmengine - INFO - Iter(train) [ 19650/160000]  base_lr: 8.8876e-05 lr: 8.8876e-06  eta: 15:59:56  time: 0.4080  data_time: 0.0088  memory: 5967  grad_norm: 540.8361  loss: 20.7750  decode.loss_cls: 0.3102  decode.loss_mask: 0.9678  decode.loss_dice: 0.7530  decode.d0.loss_cls: 0.6476  decode.d0.loss_mask: 1.0115  decode.d0.loss_dice: 0.7399  decode.d1.loss_cls: 0.3283  decode.d1.loss_mask: 1.0083  decode.d1.loss_dice: 0.7381  decode.d2.loss_cls: 0.2674  decode.d2.loss_mask: 1.0070  decode.d2.loss_dice: 0.7350  decode.d3.loss_cls: 0.3123  decode.d3.loss_mask: 1.0370  decode.d3.loss_dice: 0.7550  decode.d4.loss_cls: 0.3297  decode.d4.loss_mask: 0.9729  decode.d4.loss_dice: 0.7360  decode.d5.loss_cls: 0.2955  decode.d5.loss_mask: 1.0101  decode.d5.loss_dice: 0.7203  decode.d6.loss_cls: 0.3211  decode.d6.loss_mask: 0.9864  decode.d6.loss_dice: 0.7487  decode.d7.loss_cls: 0.3482  decode.d7.loss_mask: 0.9678  decode.d7.loss_dice: 0.7149  decode.d8.loss_cls: 0.3217  decode.d8.loss_mask: 0.9716  decode.d8.loss_dice: 0.7118
05/26 13:12:47 - mmengine - INFO - Iter(train) [ 19700/160000]  base_lr: 8.8848e-05 lr: 8.8848e-06  eta: 15:59:35  time: 0.4097  data_time: 0.0089  memory: 5980  grad_norm: 550.2699  loss: 28.2018  decode.loss_cls: 0.4268  decode.loss_mask: 1.3663  decode.loss_dice: 1.0540  decode.d0.loss_cls: 0.9617  decode.d0.loss_mask: 1.2703  decode.d0.loss_dice: 0.9656  decode.d1.loss_cls: 0.3880  decode.d1.loss_mask: 1.3392  decode.d1.loss_dice: 0.9786  decode.d2.loss_cls: 0.4542  decode.d2.loss_mask: 1.3011  decode.d2.loss_dice: 0.9877  decode.d3.loss_cls: 0.4371  decode.d3.loss_mask: 1.3287  decode.d3.loss_dice: 1.0166  decode.d4.loss_cls: 0.4538  decode.d4.loss_mask: 1.2942  decode.d4.loss_dice: 0.9880  decode.d5.loss_cls: 0.4843  decode.d5.loss_mask: 1.3349  decode.d5.loss_dice: 1.0219  decode.d6.loss_cls: 0.4486  decode.d6.loss_mask: 1.3209  decode.d6.loss_dice: 0.9964  decode.d7.loss_cls: 0.4875  decode.d7.loss_mask: 1.3006  decode.d7.loss_dice: 0.9758  decode.d8.loss_cls: 0.4033  decode.d8.loss_mask: 1.3657  decode.d8.loss_dice: 1.0499
05/26 13:13:08 - mmengine - INFO - Iter(train) [ 19750/160000]  base_lr: 8.8819e-05 lr: 8.8819e-06  eta: 15:59:14  time: 0.4087  data_time: 0.0090  memory: 5976  grad_norm: 662.4853  loss: 27.8823  decode.loss_cls: 0.3525  decode.loss_mask: 1.3240  decode.loss_dice: 1.0222  decode.d0.loss_cls: 0.8649  decode.d0.loss_mask: 1.2850  decode.d0.loss_dice: 0.9861  decode.d1.loss_cls: 0.4982  decode.d1.loss_mask: 1.2946  decode.d1.loss_dice: 0.9951  decode.d2.loss_cls: 0.4137  decode.d2.loss_mask: 1.3122  decode.d2.loss_dice: 1.0114  decode.d3.loss_cls: 0.4103  decode.d3.loss_mask: 1.2711  decode.d3.loss_dice: 1.0009  decode.d4.loss_cls: 0.4148  decode.d4.loss_mask: 1.2986  decode.d4.loss_dice: 1.0007  decode.d5.loss_cls: 0.4266  decode.d5.loss_mask: 1.3125  decode.d5.loss_dice: 1.0141  decode.d6.loss_cls: 0.4674  decode.d6.loss_mask: 1.3153  decode.d6.loss_dice: 1.0164  decode.d7.loss_cls: 0.4192  decode.d7.loss_mask: 1.3610  decode.d7.loss_dice: 1.0187  decode.d8.loss_cls: 0.3812  decode.d8.loss_mask: 1.3403  decode.d8.loss_dice: 1.0534
05/26 13:13:28 - mmengine - INFO - Iter(train) [ 19800/160000]  base_lr: 8.8791e-05 lr: 8.8791e-06  eta: 15:58:53  time: 0.4092  data_time: 0.0089  memory: 5976  grad_norm: 1129.7938  loss: 25.2982  decode.loss_cls: 0.3900  decode.loss_mask: 1.2475  decode.loss_dice: 0.9230  decode.d0.loss_cls: 0.8654  decode.d0.loss_mask: 1.2092  decode.d0.loss_dice: 0.8848  decode.d1.loss_cls: 0.4857  decode.d1.loss_mask: 1.1640  decode.d1.loss_dice: 0.8423  decode.d2.loss_cls: 0.4158  decode.d2.loss_mask: 1.1613  decode.d2.loss_dice: 0.8492  decode.d3.loss_cls: 0.4105  decode.d3.loss_mask: 1.1999  decode.d3.loss_dice: 0.8421  decode.d4.loss_cls: 0.4138  decode.d4.loss_mask: 1.1689  decode.d4.loss_dice: 0.8266  decode.d5.loss_cls: 0.3638  decode.d5.loss_mask: 1.2515  decode.d5.loss_dice: 0.8666  decode.d6.loss_cls: 0.4493  decode.d6.loss_mask: 1.2173  decode.d6.loss_dice: 0.8467  decode.d7.loss_cls: 0.4637  decode.d7.loss_mask: 1.1722  decode.d7.loss_dice: 0.8464  decode.d8.loss_cls: 0.3801  decode.d8.loss_mask: 1.2829  decode.d8.loss_dice: 0.8578
05/26 13:13:49 - mmengine - INFO - Iter(train) [ 19850/160000]  base_lr: 8.8762e-05 lr: 8.8762e-06  eta: 15:58:33  time: 0.4109  data_time: 0.0090  memory: 5974  grad_norm: 892.1042  loss: 30.6727  decode.loss_cls: 0.4301  decode.loss_mask: 1.4671  decode.loss_dice: 1.1453  decode.d0.loss_cls: 0.9491  decode.d0.loss_mask: 1.2696  decode.d0.loss_dice: 1.0393  decode.d1.loss_cls: 0.4733  decode.d1.loss_mask: 1.3895  decode.d1.loss_dice: 1.1392  decode.d2.loss_cls: 0.4700  decode.d2.loss_mask: 1.3632  decode.d2.loss_dice: 1.0852  decode.d3.loss_cls: 0.5149  decode.d3.loss_mask: 1.4106  decode.d3.loss_dice: 1.1030  decode.d4.loss_cls: 0.4891  decode.d4.loss_mask: 1.3681  decode.d4.loss_dice: 1.1381  decode.d5.loss_cls: 0.4713  decode.d5.loss_mask: 1.4453  decode.d5.loss_dice: 1.1662  decode.d6.loss_cls: 0.5749  decode.d6.loss_mask: 1.4297  decode.d6.loss_dice: 1.1466  decode.d7.loss_cls: 0.4790  decode.d7.loss_mask: 1.4406  decode.d7.loss_dice: 1.1523  decode.d8.loss_cls: 0.5436  decode.d8.loss_mask: 1.4181  decode.d8.loss_dice: 1.1606
05/26 13:14:09 - mmengine - INFO - Iter(train) [ 19900/160000]  base_lr: 8.8734e-05 lr: 8.8734e-06  eta: 15:58:12  time: 0.4083  data_time: 0.0089  memory: 5976  grad_norm: 749.0208  loss: 27.4590  decode.loss_cls: 0.4107  decode.loss_mask: 1.3058  decode.loss_dice: 0.9812  decode.d0.loss_cls: 0.9338  decode.d0.loss_mask: 1.2468  decode.d0.loss_dice: 0.9662  decode.d1.loss_cls: 0.3974  decode.d1.loss_mask: 1.2929  decode.d1.loss_dice: 0.9687  decode.d2.loss_cls: 0.4180  decode.d2.loss_mask: 1.2975  decode.d2.loss_dice: 0.9671  decode.d3.loss_cls: 0.4418  decode.d3.loss_mask: 1.3088  decode.d3.loss_dice: 0.9691  decode.d4.loss_cls: 0.5090  decode.d4.loss_mask: 1.3089  decode.d4.loss_dice: 0.9497  decode.d5.loss_cls: 0.4013  decode.d5.loss_mask: 1.2750  decode.d5.loss_dice: 0.9375  decode.d6.loss_cls: 0.4586  decode.d6.loss_mask: 1.2964  decode.d6.loss_dice: 0.9527  decode.d7.loss_cls: 0.4668  decode.d7.loss_mask: 1.3397  decode.d7.loss_dice: 0.9736  decode.d8.loss_cls: 0.4236  decode.d8.loss_mask: 1.3033  decode.d8.loss_dice: 0.9570
05/26 13:14:29 - mmengine - INFO - Iter(train) [ 19950/160000]  base_lr: 8.8705e-05 lr: 8.8705e-06  eta: 15:57:51  time: 0.4093  data_time: 0.0089  memory: 5969  grad_norm: 649.1644  loss: 28.6504  decode.loss_cls: 0.4419  decode.loss_mask: 1.3552  decode.loss_dice: 0.9983  decode.d0.loss_cls: 0.9119  decode.d0.loss_mask: 1.2969  decode.d0.loss_dice: 0.9728  decode.d1.loss_cls: 0.4268  decode.d1.loss_mask: 1.3948  decode.d1.loss_dice: 0.9770  decode.d2.loss_cls: 0.4670  decode.d2.loss_mask: 1.3284  decode.d2.loss_dice: 0.9698  decode.d3.loss_cls: 0.3874  decode.d3.loss_mask: 1.3605  decode.d3.loss_dice: 0.9814  decode.d4.loss_cls: 0.5069  decode.d4.loss_mask: 1.3065  decode.d4.loss_dice: 0.9772  decode.d5.loss_cls: 0.5342  decode.d5.loss_mask: 1.2976  decode.d5.loss_dice: 1.0383  decode.d6.loss_cls: 0.5562  decode.d6.loss_mask: 1.3288  decode.d6.loss_dice: 1.0095  decode.d7.loss_cls: 0.5173  decode.d7.loss_mask: 1.3393  decode.d7.loss_dice: 0.9779  decode.d8.loss_cls: 0.5143  decode.d8.loss_mask: 1.4181  decode.d8.loss_dice: 1.0583
05/26 13:14:50 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 13:14:50 - mmengine - INFO - Iter(train) [ 20000/160000]  base_lr: 8.8677e-05 lr: 8.8677e-06  eta: 15:57:30  time: 0.4112  data_time: 0.0088  memory: 5968  grad_norm: 1120.3020  loss: 26.9107  decode.loss_cls: 0.4196  decode.loss_mask: 1.2678  decode.loss_dice: 0.9291  decode.d0.loss_cls: 0.9803  decode.d0.loss_mask: 1.1969  decode.d0.loss_dice: 0.8926  decode.d1.loss_cls: 0.5022  decode.d1.loss_mask: 1.2544  decode.d1.loss_dice: 0.8963  decode.d2.loss_cls: 0.5077  decode.d2.loss_mask: 1.2462  decode.d2.loss_dice: 0.9240  decode.d3.loss_cls: 0.4910  decode.d3.loss_mask: 1.2434  decode.d3.loss_dice: 0.9206  decode.d4.loss_cls: 0.4318  decode.d4.loss_mask: 1.2627  decode.d4.loss_dice: 0.8737  decode.d5.loss_cls: 0.4621  decode.d5.loss_mask: 1.2624  decode.d5.loss_dice: 0.9160  decode.d6.loss_cls: 0.5149  decode.d6.loss_mask: 1.2731  decode.d6.loss_dice: 0.9279  decode.d7.loss_cls: 0.5022  decode.d7.loss_mask: 1.2727  decode.d7.loss_dice: 0.9223  decode.d8.loss_cls: 0.4233  decode.d8.loss_mask: 1.2647  decode.d8.loss_dice: 0.9286
05/26 13:14:50 - mmengine - INFO - Saving checkpoint at 20000 iterations
05/26 13:14:54 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:09  time: 0.0487  data_time: 0.0012  memory: 1391  
05/26 13:14:57 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:06  time: 0.0489  data_time: 0.0012  memory: 1205  
05/26 13:14:59 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:04  time: 0.0511  data_time: 0.0013  memory: 1596  
05/26 13:15:02 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:01  time: 0.0515  data_time: 0.0012  memory: 1298  
05/26 13:15:04 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:59  time: 0.0484  data_time: 0.0013  memory: 1298  
05/26 13:15:07 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:56  time: 0.0487  data_time: 0.0013  memory: 1279  
05/26 13:15:09 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:54  time: 0.0487  data_time: 0.0012  memory: 1224  
05/26 13:15:12 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:51  time: 0.0511  data_time: 0.0012  memory: 1298  
05/26 13:15:14 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:49  time: 0.0484  data_time: 0.0013  memory: 1298  
05/26 13:15:17 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:46  time: 0.0520  data_time: 0.0013  memory: 1725  
05/26 13:15:19 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:44  time: 0.0486  data_time: 0.0012  memory: 1336  
05/26 13:15:21 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:41  time: 0.0496  data_time: 0.0012  memory: 1298  
05/26 13:15:24 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:39  time: 0.0492  data_time: 0.0013  memory: 1205  
05/26 13:15:26 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0496  data_time: 0.0013  memory: 1316  
05/26 13:15:29 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:34  time: 0.0487  data_time: 0.0013  memory: 1279  
05/26 13:15:31 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:32  time: 0.0520  data_time: 0.0013  memory: 1410  
05/26 13:15:34 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:29  time: 0.0483  data_time: 0.0012  memory: 1279  
05/26 13:15:36 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:27  time: 0.0491  data_time: 0.0012  memory: 1205  
05/26 13:15:39 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0490  data_time: 0.0012  memory: 1205  
05/26 13:15:41 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:22  time: 0.0487  data_time: 0.0012  memory: 1336  
05/26 13:15:44 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0485  data_time: 0.0012  memory: 1246  
05/26 13:15:46 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0503  data_time: 0.0013  memory: 1503  
05/26 13:15:49 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0484  data_time: 0.0012  memory: 1261  
05/26 13:15:51 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0492  data_time: 0.0012  memory: 1298  
05/26 13:15:53 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0484  data_time: 0.0012  memory: 1447  
05/26 13:15:56 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0481  data_time: 0.0013  memory: 1298  
05/26 13:15:58 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0495  data_time: 0.0012  memory: 1279  
05/26 13:16:01 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0483  data_time: 0.0012  memory: 1205  
05/26 13:16:03 - mmengine - INFO - per class results:
05/26 13:16:03 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 94.34 | 96.44 |
|  aeroplane  | 87.56 | 97.42 |
|   bicycle   | 42.01 | 89.33 |
|     bird    | 89.77 | 93.58 |
|     boat    | 53.77 | 64.24 |
|    bottle   | 75.12 | 93.12 |
|     bus     | 85.73 | 89.27 |
|     car     | 81.61 | 95.82 |
|     cat     |  86.2 |  97.2 |
|    chair    | 38.52 | 56.23 |
|     cow     | 16.42 | 17.57 |
| diningtable | 54.45 | 84.59 |
|     dog     | 72.29 | 87.18 |
|    horse    | 53.72 | 92.15 |
|  motorbike  | 84.89 | 92.47 |
|    person   | 87.49 | 93.83 |
| pottedplant | 46.68 | 68.62 |
|    sheep    | 74.27 | 75.09 |
|     sofa    | 43.05 | 52.28 |
|    train    | 84.34 | 95.38 |
|  tvmonitor  | 68.91 | 86.82 |
+-------------+-------+-------+
05/26 13:16:03 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 93.2000  mIoU: 67.6700  mAcc: 81.8400  data_time: 0.0013  time: 0.0492
05/26 13:16:03 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_15000.pth is removed
05/26 13:16:04 - mmengine - INFO - The best checkpoint with 67.6700 mIoU at 20000 iter is saved to best_mIoU_iter_20000.pth.
05/26 13:16:27 - mmengine - INFO - Iter(train) [ 20050/160000]  base_lr: 8.8648e-05 lr: 8.8648e-06  eta: 15:57:30  time: 0.4085  data_time: 0.0088  memory: 5976  grad_norm: 1010.2910  loss: 28.4744  decode.loss_cls: 0.5139  decode.loss_mask: 1.3154  decode.loss_dice: 0.9334  decode.d0.loss_cls: 1.0287  decode.d0.loss_mask: 1.1412  decode.d0.loss_dice: 0.9315  decode.d1.loss_cls: 0.5656  decode.d1.loss_mask: 1.2766  decode.d1.loss_dice: 0.9413  decode.d2.loss_cls: 0.6009  decode.d2.loss_mask: 1.2540  decode.d2.loss_dice: 0.9629  decode.d3.loss_cls: 0.5756  decode.d3.loss_mask: 1.2953  decode.d3.loss_dice: 0.9198  decode.d4.loss_cls: 0.5790  decode.d4.loss_mask: 1.3826  decode.d4.loss_dice: 0.9507  decode.d5.loss_cls: 0.6356  decode.d5.loss_mask: 1.2890  decode.d5.loss_dice: 0.9051  decode.d6.loss_cls: 0.6548  decode.d6.loss_mask: 1.3239  decode.d6.loss_dice: 0.9498  decode.d7.loss_cls: 0.6201  decode.d7.loss_mask: 1.2383  decode.d7.loss_dice: 0.9254  decode.d8.loss_cls: 0.5422  decode.d8.loss_mask: 1.3033  decode.d8.loss_dice: 0.9184
05/26 13:16:47 - mmengine - INFO - Iter(train) [ 20100/160000]  base_lr: 8.8620e-05 lr: 8.8620e-06  eta: 15:57:09  time: 0.4103  data_time: 0.0098  memory: 5988  grad_norm: 1122.1178  loss: 35.6688  decode.loss_cls: 0.6065  decode.loss_mask: 1.8220  decode.loss_dice: 1.2193  decode.d0.loss_cls: 1.0930  decode.d0.loss_mask: 1.6251  decode.d0.loss_dice: 1.1196  decode.d1.loss_cls: 0.6153  decode.d1.loss_mask: 1.6559  decode.d1.loss_dice: 1.1193  decode.d2.loss_cls: 0.7067  decode.d2.loss_mask: 1.6425  decode.d2.loss_dice: 1.1667  decode.d3.loss_cls: 0.6445  decode.d3.loss_mask: 1.7050  decode.d3.loss_dice: 1.1729  decode.d4.loss_cls: 0.6416  decode.d4.loss_mask: 1.6761  decode.d4.loss_dice: 1.1356  decode.d5.loss_cls: 0.6859  decode.d5.loss_mask: 1.7353  decode.d5.loss_dice: 1.2053  decode.d6.loss_cls: 0.6930  decode.d6.loss_mask: 1.6681  decode.d6.loss_dice: 1.1763  decode.d7.loss_cls: 0.6747  decode.d7.loss_mask: 1.6987  decode.d7.loss_dice: 1.1795  decode.d8.loss_cls: 0.6482  decode.d8.loss_mask: 1.7392  decode.d8.loss_dice: 1.1968
05/26 13:17:08 - mmengine - INFO - Iter(train) [ 20150/160000]  base_lr: 8.8591e-05 lr: 8.8591e-06  eta: 15:56:48  time: 0.4089  data_time: 0.0090  memory: 5967  grad_norm: 664.3512  loss: 25.9297  decode.loss_cls: 0.2370  decode.loss_mask: 1.4322  decode.loss_dice: 0.8990  decode.d0.loss_cls: 0.7273  decode.d0.loss_mask: 1.3160  decode.d0.loss_dice: 0.8840  decode.d1.loss_cls: 0.2605  decode.d1.loss_mask: 1.3463  decode.d1.loss_dice: 0.8883  decode.d2.loss_cls: 0.3006  decode.d2.loss_mask: 1.3929  decode.d2.loss_dice: 0.9205  decode.d3.loss_cls: 0.2722  decode.d3.loss_mask: 1.3749  decode.d3.loss_dice: 0.8938  decode.d4.loss_cls: 0.2764  decode.d4.loss_mask: 1.3811  decode.d4.loss_dice: 0.8965  decode.d5.loss_cls: 0.3030  decode.d5.loss_mask: 1.3226  decode.d5.loss_dice: 0.8853  decode.d6.loss_cls: 0.2976  decode.d6.loss_mask: 1.3541  decode.d6.loss_dice: 0.9113  decode.d7.loss_cls: 0.2833  decode.d7.loss_mask: 1.3807  decode.d7.loss_dice: 0.9198  decode.d8.loss_cls: 0.2334  decode.d8.loss_mask: 1.4171  decode.d8.loss_dice: 0.9224
05/26 13:17:28 - mmengine - INFO - Iter(train) [ 20200/160000]  base_lr: 8.8563e-05 lr: 8.8563e-06  eta: 15:56:27  time: 0.4090  data_time: 0.0089  memory: 5966  grad_norm: 808.5009  loss: 24.8391  decode.loss_cls: 0.4096  decode.loss_mask: 1.0427  decode.loss_dice: 0.9833  decode.d0.loss_cls: 0.8906  decode.d0.loss_mask: 0.9561  decode.d0.loss_dice: 0.9310  decode.d1.loss_cls: 0.4839  decode.d1.loss_mask: 1.0374  decode.d1.loss_dice: 0.9951  decode.d2.loss_cls: 0.4722  decode.d2.loss_mask: 1.0083  decode.d2.loss_dice: 0.9524  decode.d3.loss_cls: 0.4731  decode.d3.loss_mask: 1.0384  decode.d3.loss_dice: 1.0102  decode.d4.loss_cls: 0.4285  decode.d4.loss_mask: 1.0291  decode.d4.loss_dice: 0.9442  decode.d5.loss_cls: 0.4715  decode.d5.loss_mask: 1.0383  decode.d5.loss_dice: 0.9699  decode.d6.loss_cls: 0.4625  decode.d6.loss_mask: 1.0204  decode.d6.loss_dice: 0.9932  decode.d7.loss_cls: 0.4440  decode.d7.loss_mask: 1.0025  decode.d7.loss_dice: 0.9449  decode.d8.loss_cls: 0.4436  decode.d8.loss_mask: 1.0116  decode.d8.loss_dice: 0.9507
05/26 13:17:49 - mmengine - INFO - Iter(train) [ 20250/160000]  base_lr: 8.8534e-05 lr: 8.8534e-06  eta: 15:56:06  time: 0.4098  data_time: 0.0090  memory: 5975  grad_norm: 663.7328  loss: 25.1034  decode.loss_cls: 0.2901  decode.loss_mask: 1.1695  decode.loss_dice: 0.9694  decode.d0.loss_cls: 0.8081  decode.d0.loss_mask: 1.1917  decode.d0.loss_dice: 0.9382  decode.d1.loss_cls: 0.2734  decode.d1.loss_mask: 1.1930  decode.d1.loss_dice: 0.9843  decode.d2.loss_cls: 0.2690  decode.d2.loss_mask: 1.1782  decode.d2.loss_dice: 0.9783  decode.d3.loss_cls: 0.2866  decode.d3.loss_mask: 1.1816  decode.d3.loss_dice: 0.9473  decode.d4.loss_cls: 0.3381  decode.d4.loss_mask: 1.1726  decode.d4.loss_dice: 0.9309  decode.d5.loss_cls: 0.3335  decode.d5.loss_mask: 1.1725  decode.d5.loss_dice: 0.9557  decode.d6.loss_cls: 0.3249  decode.d6.loss_mask: 1.1860  decode.d6.loss_dice: 0.9707  decode.d7.loss_cls: 0.3662  decode.d7.loss_mask: 1.2077  decode.d7.loss_dice: 1.0102  decode.d8.loss_cls: 0.3055  decode.d8.loss_mask: 1.1902  decode.d8.loss_dice: 0.9799
05/26 13:18:09 - mmengine - INFO - Iter(train) [ 20300/160000]  base_lr: 8.8506e-05 lr: 8.8506e-06  eta: 15:55:46  time: 0.4096  data_time: 0.0089  memory: 5970  grad_norm: 686.9654  loss: 32.4874  decode.loss_cls: 0.4878  decode.loss_mask: 1.5657  decode.loss_dice: 1.2187  decode.d0.loss_cls: 0.9033  decode.d0.loss_mask: 1.4963  decode.d0.loss_dice: 1.1313  decode.d1.loss_cls: 0.4416  decode.d1.loss_mask: 1.5678  decode.d1.loss_dice: 1.1651  decode.d2.loss_cls: 0.4947  decode.d2.loss_mask: 1.5633  decode.d2.loss_dice: 1.1447  decode.d3.loss_cls: 0.4805  decode.d3.loss_mask: 1.5701  decode.d3.loss_dice: 1.1337  decode.d4.loss_cls: 0.5074  decode.d4.loss_mask: 1.5784  decode.d4.loss_dice: 1.1695  decode.d5.loss_cls: 0.5235  decode.d5.loss_mask: 1.4975  decode.d5.loss_dice: 1.1266  decode.d6.loss_cls: 0.5503  decode.d6.loss_mask: 1.5864  decode.d6.loss_dice: 1.1748  decode.d7.loss_cls: 0.5138  decode.d7.loss_mask: 1.5709  decode.d7.loss_dice: 1.1698  decode.d8.loss_cls: 0.4885  decode.d8.loss_mask: 1.5343  decode.d8.loss_dice: 1.1312
05/26 13:18:30 - mmengine - INFO - Iter(train) [ 20350/160000]  base_lr: 8.8477e-05 lr: 8.8477e-06  eta: 15:55:25  time: 0.4096  data_time: 0.0088  memory: 5972  grad_norm: 837.6483  loss: 31.8414  decode.loss_cls: 0.5363  decode.loss_mask: 1.3887  decode.loss_dice: 1.2172  decode.d0.loss_cls: 1.0373  decode.d0.loss_mask: 1.2879  decode.d0.loss_dice: 1.1591  decode.d1.loss_cls: 0.4973  decode.d1.loss_mask: 1.4562  decode.d1.loss_dice: 1.1997  decode.d2.loss_cls: 0.5838  decode.d2.loss_mask: 1.3941  decode.d2.loss_dice: 1.1509  decode.d3.loss_cls: 0.4879  decode.d3.loss_mask: 1.4638  decode.d3.loss_dice: 1.1389  decode.d4.loss_cls: 0.5435  decode.d4.loss_mask: 1.4179  decode.d4.loss_dice: 1.2215  decode.d5.loss_cls: 0.5094  decode.d5.loss_mask: 1.4718  decode.d5.loss_dice: 1.1751  decode.d6.loss_cls: 0.6110  decode.d6.loss_mask: 1.4270  decode.d6.loss_dice: 1.2063  decode.d7.loss_cls: 0.5221  decode.d7.loss_mask: 1.4585  decode.d7.loss_dice: 1.1847  decode.d8.loss_cls: 0.5544  decode.d8.loss_mask: 1.3589  decode.d8.loss_dice: 1.1803
05/26 13:18:50 - mmengine - INFO - Iter(train) [ 20400/160000]  base_lr: 8.8449e-05 lr: 8.8449e-06  eta: 15:55:04  time: 0.4100  data_time: 0.0089  memory: 5968  grad_norm: 797.7937  loss: 28.7387  decode.loss_cls: 0.4136  decode.loss_mask: 1.3616  decode.loss_dice: 0.9896  decode.d0.loss_cls: 0.9066  decode.d0.loss_mask: 1.2998  decode.d0.loss_dice: 0.9611  decode.d1.loss_cls: 0.4464  decode.d1.loss_mask: 1.3413  decode.d1.loss_dice: 1.0009  decode.d2.loss_cls: 0.4969  decode.d2.loss_mask: 1.3800  decode.d2.loss_dice: 1.0159  decode.d3.loss_cls: 0.4586  decode.d3.loss_mask: 1.3519  decode.d3.loss_dice: 0.9976  decode.d4.loss_cls: 0.4222  decode.d4.loss_mask: 1.3726  decode.d4.loss_dice: 1.0180  decode.d5.loss_cls: 0.4551  decode.d5.loss_mask: 1.4187  decode.d5.loss_dice: 0.9996  decode.d6.loss_cls: 0.5142  decode.d6.loss_mask: 1.3775  decode.d6.loss_dice: 0.9802  decode.d7.loss_cls: 0.4770  decode.d7.loss_mask: 1.4020  decode.d7.loss_dice: 1.0456  decode.d8.loss_cls: 0.4608  decode.d8.loss_mask: 1.3812  decode.d8.loss_dice: 0.9922
05/26 13:19:10 - mmengine - INFO - Iter(train) [ 20450/160000]  base_lr: 8.8420e-05 lr: 8.8420e-06  eta: 15:54:43  time: 0.4093  data_time: 0.0090  memory: 5967  grad_norm: 850.5819  loss: 31.6921  decode.loss_cls: 0.4354  decode.loss_mask: 1.5352  decode.loss_dice: 1.1995  decode.d0.loss_cls: 1.0086  decode.d0.loss_mask: 1.3682  decode.d0.loss_dice: 1.1519  decode.d1.loss_cls: 0.5164  decode.d1.loss_mask: 1.4326  decode.d1.loss_dice: 1.1793  decode.d2.loss_cls: 0.4544  decode.d2.loss_mask: 1.4321  decode.d2.loss_dice: 1.1331  decode.d3.loss_cls: 0.5024  decode.d3.loss_mask: 1.4299  decode.d3.loss_dice: 1.1533  decode.d4.loss_cls: 0.4523  decode.d4.loss_mask: 1.5161  decode.d4.loss_dice: 1.1725  decode.d5.loss_cls: 0.5106  decode.d5.loss_mask: 1.5052  decode.d5.loss_dice: 1.1821  decode.d6.loss_cls: 0.4452  decode.d6.loss_mask: 1.5209  decode.d6.loss_dice: 1.1902  decode.d7.loss_cls: 0.4377  decode.d7.loss_mask: 1.4800  decode.d7.loss_dice: 1.1688  decode.d8.loss_cls: 0.4480  decode.d8.loss_mask: 1.5300  decode.d8.loss_dice: 1.2002
05/26 13:19:31 - mmengine - INFO - Iter(train) [ 20500/160000]  base_lr: 8.8392e-05 lr: 8.8392e-06  eta: 15:54:22  time: 0.4086  data_time: 0.0089  memory: 5966  grad_norm: 1080.1184  loss: 27.5161  decode.loss_cls: 0.3481  decode.loss_mask: 1.3581  decode.loss_dice: 0.9883  decode.d0.loss_cls: 0.7669  decode.d0.loss_mask: 1.3193  decode.d0.loss_dice: 0.9695  decode.d1.loss_cls: 0.3291  decode.d1.loss_mask: 1.4280  decode.d1.loss_dice: 1.0135  decode.d2.loss_cls: 0.3671  decode.d2.loss_mask: 1.3723  decode.d2.loss_dice: 0.9814  decode.d3.loss_cls: 0.3451  decode.d3.loss_mask: 1.3967  decode.d3.loss_dice: 0.9655  decode.d4.loss_cls: 0.3987  decode.d4.loss_mask: 1.3710  decode.d4.loss_dice: 0.9712  decode.d5.loss_cls: 0.3864  decode.d5.loss_mask: 1.3617  decode.d5.loss_dice: 1.0021  decode.d6.loss_cls: 0.3569  decode.d6.loss_mask: 1.3793  decode.d6.loss_dice: 0.9926  decode.d7.loss_cls: 0.3646  decode.d7.loss_mask: 1.3657  decode.d7.loss_dice: 0.9808  decode.d8.loss_cls: 0.3583  decode.d8.loss_mask: 1.3206  decode.d8.loss_dice: 0.9570
05/26 13:19:51 - mmengine - INFO - Iter(train) [ 20550/160000]  base_lr: 8.8363e-05 lr: 8.8363e-06  eta: 15:54:01  time: 0.4090  data_time: 0.0089  memory: 5973  grad_norm: 495.2983  loss: 28.3915  decode.loss_cls: 0.3693  decode.loss_mask: 1.3315  decode.loss_dice: 1.0476  decode.d0.loss_cls: 0.8559  decode.d0.loss_mask: 1.2855  decode.d0.loss_dice: 1.0754  decode.d1.loss_cls: 0.4802  decode.d1.loss_mask: 1.2857  decode.d1.loss_dice: 1.0140  decode.d2.loss_cls: 0.4620  decode.d2.loss_mask: 1.3261  decode.d2.loss_dice: 1.0520  decode.d3.loss_cls: 0.3976  decode.d3.loss_mask: 1.4047  decode.d3.loss_dice: 1.0340  decode.d4.loss_cls: 0.4466  decode.d4.loss_mask: 1.2816  decode.d4.loss_dice: 1.0386  decode.d5.loss_cls: 0.3902  decode.d5.loss_mask: 1.3765  decode.d5.loss_dice: 1.1029  decode.d6.loss_cls: 0.4722  decode.d6.loss_mask: 1.3258  decode.d6.loss_dice: 1.0420  decode.d7.loss_cls: 0.4382  decode.d7.loss_mask: 1.3119  decode.d7.loss_dice: 1.0366  decode.d8.loss_cls: 0.4007  decode.d8.loss_mask: 1.2813  decode.d8.loss_dice: 1.0251
05/26 13:20:12 - mmengine - INFO - Iter(train) [ 20600/160000]  base_lr: 8.8335e-05 lr: 8.8335e-06  eta: 15:53:41  time: 0.4095  data_time: 0.0089  memory: 5973  grad_norm: 705.3839  loss: 32.1552  decode.loss_cls: 0.5044  decode.loss_mask: 1.4791  decode.loss_dice: 1.2528  decode.d0.loss_cls: 0.9926  decode.d0.loss_mask: 1.4407  decode.d0.loss_dice: 1.1647  decode.d1.loss_cls: 0.6004  decode.d1.loss_mask: 1.4443  decode.d1.loss_dice: 1.1599  decode.d2.loss_cls: 0.5980  decode.d2.loss_mask: 1.4483  decode.d2.loss_dice: 1.1968  decode.d3.loss_cls: 0.5622  decode.d3.loss_mask: 1.4285  decode.d3.loss_dice: 1.1904  decode.d4.loss_cls: 0.6071  decode.d4.loss_mask: 1.4221  decode.d4.loss_dice: 1.1537  decode.d5.loss_cls: 0.6122  decode.d5.loss_mask: 1.4372  decode.d5.loss_dice: 1.1262  decode.d6.loss_cls: 0.5697  decode.d6.loss_mask: 1.4299  decode.d6.loss_dice: 1.1422  decode.d7.loss_cls: 0.5615  decode.d7.loss_mask: 1.3920  decode.d7.loss_dice: 1.0895  decode.d8.loss_cls: 0.5280  decode.d8.loss_mask: 1.4271  decode.d8.loss_dice: 1.1938
05/26 13:20:32 - mmengine - INFO - Iter(train) [ 20650/160000]  base_lr: 8.8306e-05 lr: 8.8306e-06  eta: 15:53:20  time: 0.4099  data_time: 0.0088  memory: 5976  grad_norm: 884.2821  loss: 25.3026  decode.loss_cls: 0.4162  decode.loss_mask: 1.2577  decode.loss_dice: 0.8431  decode.d0.loss_cls: 0.8619  decode.d0.loss_mask: 1.0804  decode.d0.loss_dice: 0.8393  decode.d1.loss_cls: 0.4970  decode.d1.loss_mask: 1.2174  decode.d1.loss_dice: 0.8017  decode.d2.loss_cls: 0.4491  decode.d2.loss_mask: 1.2024  decode.d2.loss_dice: 0.8158  decode.d3.loss_cls: 0.4382  decode.d3.loss_mask: 1.2169  decode.d3.loss_dice: 0.7946  decode.d4.loss_cls: 0.5008  decode.d4.loss_mask: 1.2451  decode.d4.loss_dice: 0.8191  decode.d5.loss_cls: 0.4622  decode.d5.loss_mask: 1.2200  decode.d5.loss_dice: 0.7895  decode.d6.loss_cls: 0.4905  decode.d6.loss_mask: 1.2359  decode.d6.loss_dice: 0.8311  decode.d7.loss_cls: 0.3962  decode.d7.loss_mask: 1.2729  decode.d7.loss_dice: 0.8540  decode.d8.loss_cls: 0.3520  decode.d8.loss_mask: 1.2731  decode.d8.loss_dice: 0.8285
05/26 13:20:53 - mmengine - INFO - Iter(train) [ 20700/160000]  base_lr: 8.8278e-05 lr: 8.8278e-06  eta: 15:52:59  time: 0.4101  data_time: 0.0088  memory: 5983  grad_norm: 562.1141  loss: 26.7792  decode.loss_cls: 0.4544  decode.loss_mask: 1.1270  decode.loss_dice: 1.0281  decode.d0.loss_cls: 0.9207  decode.d0.loss_mask: 1.0816  decode.d0.loss_dice: 0.9944  decode.d1.loss_cls: 0.5051  decode.d1.loss_mask: 1.1455  decode.d1.loss_dice: 1.0078  decode.d2.loss_cls: 0.5121  decode.d2.loss_mask: 1.1501  decode.d2.loss_dice: 1.0171  decode.d3.loss_cls: 0.5354  decode.d3.loss_mask: 1.0569  decode.d3.loss_dice: 0.9579  decode.d4.loss_cls: 0.5772  decode.d4.loss_mask: 1.0516  decode.d4.loss_dice: 0.9716  decode.d5.loss_cls: 0.5093  decode.d5.loss_mask: 1.1482  decode.d5.loss_dice: 1.0454  decode.d6.loss_cls: 0.5239  decode.d6.loss_mask: 1.1562  decode.d6.loss_dice: 1.0712  decode.d7.loss_cls: 0.5057  decode.d7.loss_mask: 1.1010  decode.d7.loss_dice: 0.9919  decode.d8.loss_cls: 0.4956  decode.d8.loss_mask: 1.1308  decode.d8.loss_dice: 1.0056
05/26 13:21:13 - mmengine - INFO - Iter(train) [ 20750/160000]  base_lr: 8.8249e-05 lr: 8.8249e-06  eta: 15:52:38  time: 0.4102  data_time: 0.0087  memory: 5980  grad_norm: 694.9515  loss: 22.8313  decode.loss_cls: 0.3609  decode.loss_mask: 1.0268  decode.loss_dice: 0.8618  decode.d0.loss_cls: 0.8185  decode.d0.loss_mask: 1.0083  decode.d0.loss_dice: 0.8224  decode.d1.loss_cls: 0.3766  decode.d1.loss_mask: 1.0335  decode.d1.loss_dice: 0.8539  decode.d2.loss_cls: 0.3747  decode.d2.loss_mask: 0.9935  decode.d2.loss_dice: 0.8328  decode.d3.loss_cls: 0.4080  decode.d3.loss_mask: 1.0498  decode.d3.loss_dice: 0.8601  decode.d4.loss_cls: 0.3972  decode.d4.loss_mask: 1.0001  decode.d4.loss_dice: 0.8100  decode.d5.loss_cls: 0.4291  decode.d5.loss_mask: 0.9848  decode.d5.loss_dice: 0.8331  decode.d6.loss_cls: 0.4345  decode.d6.loss_mask: 1.0138  decode.d6.loss_dice: 0.8185  decode.d7.loss_cls: 0.3607  decode.d7.loss_mask: 1.0093  decode.d7.loss_dice: 0.8246  decode.d8.loss_cls: 0.4059  decode.d8.loss_mask: 0.9991  decode.d8.loss_dice: 0.8291
05/26 13:21:34 - mmengine - INFO - Iter(train) [ 20800/160000]  base_lr: 8.8221e-05 lr: 8.8221e-06  eta: 15:52:17  time: 0.4104  data_time: 0.0088  memory: 5967  grad_norm: 966.4838  loss: 29.4111  decode.loss_cls: 0.4905  decode.loss_mask: 1.2353  decode.loss_dice: 1.1295  decode.d0.loss_cls: 1.0296  decode.d0.loss_mask: 1.2115  decode.d0.loss_dice: 1.0470  decode.d1.loss_cls: 0.5756  decode.d1.loss_mask: 1.2239  decode.d1.loss_dice: 1.0657  decode.d2.loss_cls: 0.5365  decode.d2.loss_mask: 1.2660  decode.d2.loss_dice: 1.0849  decode.d3.loss_cls: 0.5085  decode.d3.loss_mask: 1.2661  decode.d3.loss_dice: 1.0719  decode.d4.loss_cls: 0.5579  decode.d4.loss_mask: 1.2522  decode.d4.loss_dice: 1.0959  decode.d5.loss_cls: 0.4703  decode.d5.loss_mask: 1.3550  decode.d5.loss_dice: 1.2072  decode.d6.loss_cls: 0.5094  decode.d6.loss_mask: 1.3233  decode.d6.loss_dice: 1.1439  decode.d7.loss_cls: 0.4680  decode.d7.loss_mask: 1.2531  decode.d7.loss_dice: 1.1304  decode.d8.loss_cls: 0.4953  decode.d8.loss_mask: 1.3062  decode.d8.loss_dice: 1.1003
05/26 13:21:54 - mmengine - INFO - Iter(train) [ 20850/160000]  base_lr: 8.8192e-05 lr: 8.8192e-06  eta: 15:51:56  time: 0.4085  data_time: 0.0088  memory: 5985  grad_norm: 963.8090  loss: 28.1755  decode.loss_cls: 0.4699  decode.loss_mask: 1.3718  decode.loss_dice: 0.9795  decode.d0.loss_cls: 0.9943  decode.d0.loss_mask: 1.3309  decode.d0.loss_dice: 0.9865  decode.d1.loss_cls: 0.4473  decode.d1.loss_mask: 1.3598  decode.d1.loss_dice: 0.9881  decode.d2.loss_cls: 0.5086  decode.d2.loss_mask: 1.3131  decode.d2.loss_dice: 0.9410  decode.d3.loss_cls: 0.5053  decode.d3.loss_mask: 1.2908  decode.d3.loss_dice: 0.9443  decode.d4.loss_cls: 0.5311  decode.d4.loss_mask: 1.3093  decode.d4.loss_dice: 0.9235  decode.d5.loss_cls: 0.5201  decode.d5.loss_mask: 1.3154  decode.d5.loss_dice: 0.9415  decode.d6.loss_cls: 0.5369  decode.d6.loss_mask: 1.2674  decode.d6.loss_dice: 0.9165  decode.d7.loss_cls: 0.5500  decode.d7.loss_mask: 1.3171  decode.d7.loss_dice: 0.9218  decode.d8.loss_cls: 0.4300  decode.d8.loss_mask: 1.3081  decode.d8.loss_dice: 0.9559
05/26 13:22:15 - mmengine - INFO - Iter(train) [ 20900/160000]  base_lr: 8.8164e-05 lr: 8.8164e-06  eta: 15:51:36  time: 0.4089  data_time: 0.0087  memory: 5968  grad_norm: 1046.0565  loss: 28.0001  decode.loss_cls: 0.3612  decode.loss_mask: 1.4101  decode.loss_dice: 1.0164  decode.d0.loss_cls: 0.7247  decode.d0.loss_mask: 1.3431  decode.d0.loss_dice: 0.9935  decode.d1.loss_cls: 0.3913  decode.d1.loss_mask: 1.4121  decode.d1.loss_dice: 1.0031  decode.d2.loss_cls: 0.3639  decode.d2.loss_mask: 1.4053  decode.d2.loss_dice: 0.9751  decode.d3.loss_cls: 0.3776  decode.d3.loss_mask: 1.3259  decode.d3.loss_dice: 1.0027  decode.d4.loss_cls: 0.3936  decode.d4.loss_mask: 1.3567  decode.d4.loss_dice: 1.0135  decode.d5.loss_cls: 0.4503  decode.d5.loss_mask: 1.3314  decode.d5.loss_dice: 1.0111  decode.d6.loss_cls: 0.4104  decode.d6.loss_mask: 1.3389  decode.d6.loss_dice: 1.0168  decode.d7.loss_cls: 0.4363  decode.d7.loss_mask: 1.3785  decode.d7.loss_dice: 1.0150  decode.d8.loss_cls: 0.3800  decode.d8.loss_mask: 1.3568  decode.d8.loss_dice: 1.0048
05/26 13:22:35 - mmengine - INFO - Iter(train) [ 20950/160000]  base_lr: 8.8135e-05 lr: 8.8135e-06  eta: 15:51:15  time: 0.4102  data_time: 0.0087  memory: 5968  grad_norm: 658.2381  loss: 24.3258  decode.loss_cls: 0.1806  decode.loss_mask: 1.2163  decode.loss_dice: 0.9471  decode.d0.loss_cls: 0.7226  decode.d0.loss_mask: 1.1893  decode.d0.loss_dice: 0.9376  decode.d1.loss_cls: 0.1851  decode.d1.loss_mask: 1.2519  decode.d1.loss_dice: 0.9726  decode.d2.loss_cls: 0.2110  decode.d2.loss_mask: 1.2196  decode.d2.loss_dice: 0.9508  decode.d3.loss_cls: 0.1951  decode.d3.loss_mask: 1.2076  decode.d3.loss_dice: 0.9515  decode.d4.loss_cls: 0.1903  decode.d4.loss_mask: 1.2000  decode.d4.loss_dice: 0.9602  decode.d5.loss_cls: 0.2546  decode.d5.loss_mask: 1.1806  decode.d5.loss_dice: 0.9839  decode.d6.loss_cls: 0.2258  decode.d6.loss_mask: 1.2254  decode.d6.loss_dice: 0.9854  decode.d7.loss_cls: 0.2235  decode.d7.loss_mask: 1.2195  decode.d7.loss_dice: 0.9647  decode.d8.loss_cls: 0.2048  decode.d8.loss_mask: 1.2215  decode.d8.loss_dice: 0.9468
05/26 13:22:56 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 13:22:56 - mmengine - INFO - Iter(train) [ 21000/160000]  base_lr: 8.8106e-05 lr: 8.8106e-06  eta: 15:50:54  time: 0.4096  data_time: 0.0088  memory: 5970  grad_norm: 1173.6899  loss: 25.9218  decode.loss_cls: 0.2421  decode.loss_mask: 1.2994  decode.loss_dice: 0.9616  decode.d0.loss_cls: 0.8191  decode.d0.loss_mask: 1.1550  decode.d0.loss_dice: 0.9059  decode.d1.loss_cls: 0.2615  decode.d1.loss_mask: 1.3008  decode.d1.loss_dice: 0.9830  decode.d2.loss_cls: 0.2595  decode.d2.loss_mask: 1.3082  decode.d2.loss_dice: 0.9446  decode.d3.loss_cls: 0.3019  decode.d3.loss_mask: 1.2949  decode.d3.loss_dice: 0.9827  decode.d4.loss_cls: 0.2924  decode.d4.loss_mask: 1.2884  decode.d4.loss_dice: 0.9555  decode.d5.loss_cls: 0.2644  decode.d5.loss_mask: 1.3156  decode.d5.loss_dice: 0.9614  decode.d6.loss_cls: 0.2825  decode.d6.loss_mask: 1.3282  decode.d6.loss_dice: 1.0111  decode.d7.loss_cls: 0.2660  decode.d7.loss_mask: 1.3752  decode.d7.loss_dice: 0.9743  decode.d8.loss_cls: 0.2424  decode.d8.loss_mask: 1.3487  decode.d8.loss_dice: 0.9951
05/26 13:23:16 - mmengine - INFO - Iter(train) [ 21050/160000]  base_lr: 8.8078e-05 lr: 8.8078e-06  eta: 15:50:33  time: 0.4088  data_time: 0.0089  memory: 5966  grad_norm: 826.0327  loss: 30.1015  decode.loss_cls: 0.4795  decode.loss_mask: 1.3238  decode.loss_dice: 1.1038  decode.d0.loss_cls: 1.0044  decode.d0.loss_mask: 1.2967  decode.d0.loss_dice: 1.1208  decode.d1.loss_cls: 0.5198  decode.d1.loss_mask: 1.3952  decode.d1.loss_dice: 1.1369  decode.d2.loss_cls: 0.5224  decode.d2.loss_mask: 1.3148  decode.d2.loss_dice: 1.1347  decode.d3.loss_cls: 0.5358  decode.d3.loss_mask: 1.2668  decode.d3.loss_dice: 1.0648  decode.d4.loss_cls: 0.5467  decode.d4.loss_mask: 1.3277  decode.d4.loss_dice: 1.1242  decode.d5.loss_cls: 0.4700  decode.d5.loss_mask: 1.3352  decode.d5.loss_dice: 1.1475  decode.d6.loss_cls: 0.5063  decode.d6.loss_mask: 1.3291  decode.d6.loss_dice: 1.1908  decode.d7.loss_cls: 0.5010  decode.d7.loss_mask: 1.3486  decode.d7.loss_dice: 1.1568  decode.d8.loss_cls: 0.4799  decode.d8.loss_mask: 1.3111  decode.d8.loss_dice: 1.1062
05/26 13:23:37 - mmengine - INFO - Iter(train) [ 21100/160000]  base_lr: 8.8049e-05 lr: 8.8049e-06  eta: 15:50:12  time: 0.4082  data_time: 0.0087  memory: 5971  grad_norm: 822.2065  loss: 28.3713  decode.loss_cls: 0.4021  decode.loss_mask: 1.3756  decode.loss_dice: 1.0187  decode.d0.loss_cls: 0.9492  decode.d0.loss_mask: 1.1818  decode.d0.loss_dice: 1.0264  decode.d1.loss_cls: 0.4717  decode.d1.loss_mask: 1.2995  decode.d1.loss_dice: 0.9987  decode.d2.loss_cls: 0.4748  decode.d2.loss_mask: 1.2957  decode.d2.loss_dice: 0.9683  decode.d3.loss_cls: 0.4654  decode.d3.loss_mask: 1.3486  decode.d3.loss_dice: 0.9940  decode.d4.loss_cls: 0.5057  decode.d4.loss_mask: 1.3273  decode.d4.loss_dice: 0.9867  decode.d5.loss_cls: 0.4715  decode.d5.loss_mask: 1.3586  decode.d5.loss_dice: 1.0053  decode.d6.loss_cls: 0.5267  decode.d6.loss_mask: 1.2982  decode.d6.loss_dice: 0.9704  decode.d7.loss_cls: 0.4691  decode.d7.loss_mask: 1.3700  decode.d7.loss_dice: 0.9873  decode.d8.loss_cls: 0.4564  decode.d8.loss_mask: 1.3745  decode.d8.loss_dice: 0.9930
05/26 13:23:57 - mmengine - INFO - Iter(train) [ 21150/160000]  base_lr: 8.8021e-05 lr: 8.8021e-06  eta: 15:49:52  time: 0.4081  data_time: 0.0089  memory: 5971  grad_norm: 461.3640  loss: 26.2362  decode.loss_cls: 0.2786  decode.loss_mask: 1.3736  decode.loss_dice: 0.9374  decode.d0.loss_cls: 0.6867  decode.d0.loss_mask: 1.2726  decode.d0.loss_dice: 0.8946  decode.d1.loss_cls: 0.3436  decode.d1.loss_mask: 1.3436  decode.d1.loss_dice: 0.9326  decode.d2.loss_cls: 0.3184  decode.d2.loss_mask: 1.3280  decode.d2.loss_dice: 0.9121  decode.d3.loss_cls: 0.3664  decode.d3.loss_mask: 1.3211  decode.d3.loss_dice: 0.9185  decode.d4.loss_cls: 0.3576  decode.d4.loss_mask: 1.3354  decode.d4.loss_dice: 0.9227  decode.d5.loss_cls: 0.3094  decode.d5.loss_mask: 1.3680  decode.d5.loss_dice: 0.9176  decode.d6.loss_cls: 0.3471  decode.d6.loss_mask: 1.3725  decode.d6.loss_dice: 0.9375  decode.d7.loss_cls: 0.3241  decode.d7.loss_mask: 1.3265  decode.d7.loss_dice: 0.9308  decode.d8.loss_cls: 0.3060  decode.d8.loss_mask: 1.3188  decode.d8.loss_dice: 0.9343
05/26 13:24:18 - mmengine - INFO - Iter(train) [ 21200/160000]  base_lr: 8.7992e-05 lr: 8.7992e-06  eta: 15:49:30  time: 0.4075  data_time: 0.0089  memory: 5969  grad_norm: 1140.7682  loss: 25.9196  decode.loss_cls: 0.3349  decode.loss_mask: 1.3308  decode.loss_dice: 0.9129  decode.d0.loss_cls: 0.8883  decode.d0.loss_mask: 1.2113  decode.d0.loss_dice: 0.8510  decode.d1.loss_cls: 0.2720  decode.d1.loss_mask: 1.3230  decode.d1.loss_dice: 0.8897  decode.d2.loss_cls: 0.3034  decode.d2.loss_mask: 1.4025  decode.d2.loss_dice: 0.9195  decode.d3.loss_cls: 0.3076  decode.d3.loss_mask: 1.3307  decode.d3.loss_dice: 0.9107  decode.d4.loss_cls: 0.3018  decode.d4.loss_mask: 1.3192  decode.d4.loss_dice: 0.8843  decode.d5.loss_cls: 0.3690  decode.d5.loss_mask: 1.2739  decode.d5.loss_dice: 0.9139  decode.d6.loss_cls: 0.3110  decode.d6.loss_mask: 1.2894  decode.d6.loss_dice: 0.9052  decode.d7.loss_cls: 0.3269  decode.d7.loss_mask: 1.3181  decode.d7.loss_dice: 0.9015  decode.d8.loss_cls: 0.3325  decode.d8.loss_mask: 1.3471  decode.d8.loss_dice: 0.9372
05/26 13:24:38 - mmengine - INFO - Iter(train) [ 21250/160000]  base_lr: 8.7964e-05 lr: 8.7964e-06  eta: 15:49:09  time: 0.4072  data_time: 0.0088  memory: 5973  grad_norm: 1044.8197  loss: 25.3179  decode.loss_cls: 0.2929  decode.loss_mask: 1.3540  decode.loss_dice: 0.8229  decode.d0.loss_cls: 0.7742  decode.d0.loss_mask: 1.2619  decode.d0.loss_dice: 0.8156  decode.d1.loss_cls: 0.3099  decode.d1.loss_mask: 1.3416  decode.d1.loss_dice: 0.8392  decode.d2.loss_cls: 0.3862  decode.d2.loss_mask: 1.3436  decode.d2.loss_dice: 0.8226  decode.d3.loss_cls: 0.3351  decode.d3.loss_mask: 1.2978  decode.d3.loss_dice: 0.8125  decode.d4.loss_cls: 0.3416  decode.d4.loss_mask: 1.3182  decode.d4.loss_dice: 0.8104  decode.d5.loss_cls: 0.3485  decode.d5.loss_mask: 1.3449  decode.d5.loss_dice: 0.8299  decode.d6.loss_cls: 0.3478  decode.d6.loss_mask: 1.3648  decode.d6.loss_dice: 0.8587  decode.d7.loss_cls: 0.3786  decode.d7.loss_mask: 1.3358  decode.d7.loss_dice: 0.8127  decode.d8.loss_cls: 0.3420  decode.d8.loss_mask: 1.3008  decode.d8.loss_dice: 0.7732
05/26 13:24:59 - mmengine - INFO - Iter(train) [ 21300/160000]  base_lr: 8.7935e-05 lr: 8.7935e-06  eta: 15:48:48  time: 0.4083  data_time: 0.0089  memory: 5968  grad_norm: 445.6875  loss: 26.7231  decode.loss_cls: 0.3973  decode.loss_mask: 1.2083  decode.loss_dice: 0.9062  decode.d0.loss_cls: 0.8548  decode.d0.loss_mask: 1.2237  decode.d0.loss_dice: 0.8823  decode.d1.loss_cls: 0.3831  decode.d1.loss_mask: 1.2893  decode.d1.loss_dice: 0.9780  decode.d2.loss_cls: 0.3856  decode.d2.loss_mask: 1.2577  decode.d2.loss_dice: 0.9540  decode.d3.loss_cls: 0.4126  decode.d3.loss_mask: 1.2740  decode.d3.loss_dice: 0.9525  decode.d4.loss_cls: 0.4080  decode.d4.loss_mask: 1.2798  decode.d4.loss_dice: 0.9311  decode.d5.loss_cls: 0.4088  decode.d5.loss_mask: 1.3277  decode.d5.loss_dice: 0.9597  decode.d6.loss_cls: 0.4440  decode.d6.loss_mask: 1.2727  decode.d6.loss_dice: 1.0094  decode.d7.loss_cls: 0.3883  decode.d7.loss_mask: 1.3258  decode.d7.loss_dice: 1.0389  decode.d8.loss_cls: 0.4083  decode.d8.loss_mask: 1.2102  decode.d8.loss_dice: 0.9511
05/26 13:25:19 - mmengine - INFO - Iter(train) [ 21350/160000]  base_lr: 8.7907e-05 lr: 8.7907e-06  eta: 15:48:27  time: 0.4078  data_time: 0.0088  memory: 6011  grad_norm: 631.1915  loss: 28.9207  decode.loss_cls: 0.4883  decode.loss_mask: 1.2325  decode.loss_dice: 1.1113  decode.d0.loss_cls: 0.9235  decode.d0.loss_mask: 1.1435  decode.d0.loss_dice: 1.0435  decode.d1.loss_cls: 0.4752  decode.d1.loss_mask: 1.2488  decode.d1.loss_dice: 1.1116  decode.d2.loss_cls: 0.5103  decode.d2.loss_mask: 1.2238  decode.d2.loss_dice: 1.1000  decode.d3.loss_cls: 0.5203  decode.d3.loss_mask: 1.2132  decode.d3.loss_dice: 1.0629  decode.d4.loss_cls: 0.5096  decode.d4.loss_mask: 1.2145  decode.d4.loss_dice: 1.0866  decode.d5.loss_cls: 0.5476  decode.d5.loss_mask: 1.2261  decode.d5.loss_dice: 1.1203  decode.d6.loss_cls: 0.5472  decode.d6.loss_mask: 1.2286  decode.d6.loss_dice: 1.1049  decode.d7.loss_cls: 0.5491  decode.d7.loss_mask: 1.3097  decode.d7.loss_dice: 1.1049  decode.d8.loss_cls: 0.5225  decode.d8.loss_mask: 1.2939  decode.d8.loss_dice: 1.1470
05/26 13:25:39 - mmengine - INFO - Iter(train) [ 21400/160000]  base_lr: 8.7878e-05 lr: 8.7878e-06  eta: 15:48:06  time: 0.4078  data_time: 0.0087  memory: 5965  grad_norm: 967.4904  loss: 27.7893  decode.loss_cls: 0.3397  decode.loss_mask: 1.4854  decode.loss_dice: 0.9525  decode.d0.loss_cls: 0.8684  decode.d0.loss_mask: 1.3703  decode.d0.loss_dice: 0.9628  decode.d1.loss_cls: 0.3435  decode.d1.loss_mask: 1.4187  decode.d1.loss_dice: 0.9553  decode.d2.loss_cls: 0.4036  decode.d2.loss_mask: 1.4074  decode.d2.loss_dice: 0.9374  decode.d3.loss_cls: 0.3767  decode.d3.loss_mask: 1.3341  decode.d3.loss_dice: 0.9265  decode.d4.loss_cls: 0.4127  decode.d4.loss_mask: 1.3627  decode.d4.loss_dice: 0.9426  decode.d5.loss_cls: 0.3902  decode.d5.loss_mask: 1.3616  decode.d5.loss_dice: 0.9524  decode.d6.loss_cls: 0.3966  decode.d6.loss_mask: 1.4243  decode.d6.loss_dice: 0.9161  decode.d7.loss_cls: 0.3674  decode.d7.loss_mask: 1.4635  decode.d7.loss_dice: 0.9717  decode.d8.loss_cls: 0.3631  decode.d8.loss_mask: 1.4315  decode.d8.loss_dice: 0.9507
05/26 13:26:00 - mmengine - INFO - Iter(train) [ 21450/160000]  base_lr: 8.7850e-05 lr: 8.7850e-06  eta: 15:47:45  time: 0.4079  data_time: 0.0087  memory: 5973  grad_norm: 689.8200  loss: 26.2449  decode.loss_cls: 0.3103  decode.loss_mask: 1.2420  decode.loss_dice: 0.9288  decode.d0.loss_cls: 0.7819  decode.d0.loss_mask: 1.2408  decode.d0.loss_dice: 0.9393  decode.d1.loss_cls: 0.4062  decode.d1.loss_mask: 1.2463  decode.d1.loss_dice: 0.9259  decode.d2.loss_cls: 0.3624  decode.d2.loss_mask: 1.2772  decode.d2.loss_dice: 0.9383  decode.d3.loss_cls: 0.3824  decode.d3.loss_mask: 1.3196  decode.d3.loss_dice: 0.9329  decode.d4.loss_cls: 0.4403  decode.d4.loss_mask: 1.2718  decode.d4.loss_dice: 0.9361  decode.d5.loss_cls: 0.3747  decode.d5.loss_mask: 1.2549  decode.d5.loss_dice: 0.9127  decode.d6.loss_cls: 0.4901  decode.d6.loss_mask: 1.2453  decode.d6.loss_dice: 0.9299  decode.d7.loss_cls: 0.3583  decode.d7.loss_mask: 1.3286  decode.d7.loss_dice: 0.9389  decode.d8.loss_cls: 0.3370  decode.d8.loss_mask: 1.2747  decode.d8.loss_dice: 0.9174
05/26 13:26:20 - mmengine - INFO - Iter(train) [ 21500/160000]  base_lr: 8.7821e-05 lr: 8.7821e-06  eta: 15:47:23  time: 0.4094  data_time: 0.0088  memory: 5966  grad_norm: 1046.3252  loss: 30.4881  decode.loss_cls: 0.4673  decode.loss_mask: 1.3697  decode.loss_dice: 1.2498  decode.d0.loss_cls: 0.8322  decode.d0.loss_mask: 1.3052  decode.d0.loss_dice: 1.1724  decode.d1.loss_cls: 0.4460  decode.d1.loss_mask: 1.3216  decode.d1.loss_dice: 1.1597  decode.d2.loss_cls: 0.4873  decode.d2.loss_mask: 1.3074  decode.d2.loss_dice: 1.1697  decode.d3.loss_cls: 0.4805  decode.d3.loss_mask: 1.3067  decode.d3.loss_dice: 1.2096  decode.d4.loss_cls: 0.5210  decode.d4.loss_mask: 1.3163  decode.d4.loss_dice: 1.1676  decode.d5.loss_cls: 0.5164  decode.d5.loss_mask: 1.3347  decode.d5.loss_dice: 1.2295  decode.d6.loss_cls: 0.5577  decode.d6.loss_mask: 1.3230  decode.d6.loss_dice: 1.2053  decode.d7.loss_cls: 0.5279  decode.d7.loss_mask: 1.2912  decode.d7.loss_dice: 1.1745  decode.d8.loss_cls: 0.4833  decode.d8.loss_mask: 1.3151  decode.d8.loss_dice: 1.2396
05/26 13:26:41 - mmengine - INFO - Iter(train) [ 21550/160000]  base_lr: 8.7793e-05 lr: 8.7793e-06  eta: 15:47:02  time: 0.4083  data_time: 0.0088  memory: 5967  grad_norm: 604.8374  loss: 23.6497  decode.loss_cls: 0.3017  decode.loss_mask: 1.2049  decode.loss_dice: 0.8388  decode.d0.loss_cls: 0.6711  decode.d0.loss_mask: 1.1294  decode.d0.loss_dice: 0.8063  decode.d1.loss_cls: 0.3468  decode.d1.loss_mask: 1.1306  decode.d1.loss_dice: 0.8063  decode.d2.loss_cls: 0.3180  decode.d2.loss_mask: 1.1739  decode.d2.loss_dice: 0.8218  decode.d3.loss_cls: 0.3157  decode.d3.loss_mask: 1.1998  decode.d3.loss_dice: 0.8347  decode.d4.loss_cls: 0.3466  decode.d4.loss_mask: 1.1412  decode.d4.loss_dice: 0.8326  decode.d5.loss_cls: 0.3367  decode.d5.loss_mask: 1.1633  decode.d5.loss_dice: 0.8168  decode.d6.loss_cls: 0.3274  decode.d6.loss_mask: 1.1950  decode.d6.loss_dice: 0.8077  decode.d7.loss_cls: 0.3704  decode.d7.loss_mask: 1.1902  decode.d7.loss_dice: 0.8521  decode.d8.loss_cls: 0.3322  decode.d8.loss_mask: 1.1971  decode.d8.loss_dice: 0.8407
05/26 13:27:01 - mmengine - INFO - Iter(train) [ 21600/160000]  base_lr: 8.7764e-05 lr: 8.7764e-06  eta: 15:46:41  time: 0.4073  data_time: 0.0088  memory: 5975  grad_norm: 634.2148  loss: 28.9191  decode.loss_cls: 0.4909  decode.loss_mask: 1.2692  decode.loss_dice: 1.0447  decode.d0.loss_cls: 0.9999  decode.d0.loss_mask: 1.2035  decode.d0.loss_dice: 1.0051  decode.d1.loss_cls: 0.5745  decode.d1.loss_mask: 1.2414  decode.d1.loss_dice: 1.0004  decode.d2.loss_cls: 0.5527  decode.d2.loss_mask: 1.2635  decode.d2.loss_dice: 0.9930  decode.d3.loss_cls: 0.5560  decode.d3.loss_mask: 1.2556  decode.d3.loss_dice: 0.9830  decode.d4.loss_cls: 0.6447  decode.d4.loss_mask: 1.2362  decode.d4.loss_dice: 1.0120  decode.d5.loss_cls: 0.5864  decode.d5.loss_mask: 1.2874  decode.d5.loss_dice: 1.0102  decode.d6.loss_cls: 0.5670  decode.d6.loss_mask: 1.3379  decode.d6.loss_dice: 1.0291  decode.d7.loss_cls: 0.5409  decode.d7.loss_mask: 1.3019  decode.d7.loss_dice: 1.0088  decode.d8.loss_cls: 0.5168  decode.d8.loss_mask: 1.3317  decode.d8.loss_dice: 1.0749
05/26 13:27:22 - mmengine - INFO - Iter(train) [ 21650/160000]  base_lr: 8.7736e-05 lr: 8.7736e-06  eta: 15:46:20  time: 0.4082  data_time: 0.0088  memory: 5966  grad_norm: 667.5657  loss: 27.4940  decode.loss_cls: 0.4596  decode.loss_mask: 1.2259  decode.loss_dice: 0.9853  decode.d0.loss_cls: 0.8349  decode.d0.loss_mask: 1.2138  decode.d0.loss_dice: 0.9421  decode.d1.loss_cls: 0.5297  decode.d1.loss_mask: 1.2459  decode.d1.loss_dice: 1.0095  decode.d2.loss_cls: 0.5152  decode.d2.loss_mask: 1.2037  decode.d2.loss_dice: 0.9977  decode.d3.loss_cls: 0.4764  decode.d3.loss_mask: 1.2148  decode.d3.loss_dice: 0.9572  decode.d4.loss_cls: 0.5550  decode.d4.loss_mask: 1.2169  decode.d4.loss_dice: 0.9487  decode.d5.loss_cls: 0.5587  decode.d5.loss_mask: 1.1942  decode.d5.loss_dice: 0.9668  decode.d6.loss_cls: 0.6145  decode.d6.loss_mask: 1.2054  decode.d6.loss_dice: 0.9773  decode.d7.loss_cls: 0.5242  decode.d7.loss_mask: 1.2239  decode.d7.loss_dice: 0.9986  decode.d8.loss_cls: 0.4757  decode.d8.loss_mask: 1.2180  decode.d8.loss_dice: 1.0044
05/26 13:27:42 - mmengine - INFO - Iter(train) [ 21700/160000]  base_lr: 8.7707e-05 lr: 8.7707e-06  eta: 15:45:59  time: 0.4092  data_time: 0.0088  memory: 5966  grad_norm: 639.7122  loss: 27.6476  decode.loss_cls: 0.3640  decode.loss_mask: 1.2582  decode.loss_dice: 1.0450  decode.d0.loss_cls: 0.8875  decode.d0.loss_mask: 1.1458  decode.d0.loss_dice: 1.0060  decode.d1.loss_cls: 0.4477  decode.d1.loss_mask: 1.1918  decode.d1.loss_dice: 1.0182  decode.d2.loss_cls: 0.4822  decode.d2.loss_mask: 1.2896  decode.d2.loss_dice: 1.0535  decode.d3.loss_cls: 0.4943  decode.d3.loss_mask: 1.2375  decode.d3.loss_dice: 1.0446  decode.d4.loss_cls: 0.4640  decode.d4.loss_mask: 1.2593  decode.d4.loss_dice: 1.0501  decode.d5.loss_cls: 0.4277  decode.d5.loss_mask: 1.2268  decode.d5.loss_dice: 1.0292  decode.d6.loss_cls: 0.5148  decode.d6.loss_mask: 1.2197  decode.d6.loss_dice: 1.0192  decode.d7.loss_cls: 0.4096  decode.d7.loss_mask: 1.2501  decode.d7.loss_dice: 1.0569  decode.d8.loss_cls: 0.4405  decode.d8.loss_mask: 1.2654  decode.d8.loss_dice: 1.0486
05/26 13:28:02 - mmengine - INFO - Iter(train) [ 21750/160000]  base_lr: 8.7678e-05 lr: 8.7678e-06  eta: 15:45:38  time: 0.4082  data_time: 0.0088  memory: 5979  grad_norm: 717.2225  loss: 28.0176  decode.loss_cls: 0.3622  decode.loss_mask: 1.4323  decode.loss_dice: 0.9678  decode.d0.loss_cls: 0.8714  decode.d0.loss_mask: 1.1763  decode.d0.loss_dice: 0.8941  decode.d1.loss_cls: 0.3849  decode.d1.loss_mask: 1.3881  decode.d1.loss_dice: 0.9872  decode.d2.loss_cls: 0.4983  decode.d2.loss_mask: 1.3405  decode.d2.loss_dice: 0.9720  decode.d3.loss_cls: 0.4371  decode.d3.loss_mask: 1.3372  decode.d3.loss_dice: 0.9813  decode.d4.loss_cls: 0.4664  decode.d4.loss_mask: 1.3801  decode.d4.loss_dice: 0.9592  decode.d5.loss_cls: 0.4891  decode.d5.loss_mask: 1.3253  decode.d5.loss_dice: 0.9938  decode.d6.loss_cls: 0.4432  decode.d6.loss_mask: 1.3978  decode.d6.loss_dice: 0.9368  decode.d7.loss_cls: 0.4571  decode.d7.loss_mask: 1.3994  decode.d7.loss_dice: 0.9383  decode.d8.loss_cls: 0.4154  decode.d8.loss_mask: 1.4224  decode.d8.loss_dice: 0.9626
05/26 13:28:23 - mmengine - INFO - Iter(train) [ 21800/160000]  base_lr: 8.7650e-05 lr: 8.7650e-06  eta: 15:45:17  time: 0.4094  data_time: 0.0087  memory: 5976  grad_norm: 574.8425  loss: 27.4385  decode.loss_cls: 0.3878  decode.loss_mask: 1.3298  decode.loss_dice: 0.9565  decode.d0.loss_cls: 0.9348  decode.d0.loss_mask: 1.2387  decode.d0.loss_dice: 0.9350  decode.d1.loss_cls: 0.3973  decode.d1.loss_mask: 1.3146  decode.d1.loss_dice: 0.9345  decode.d2.loss_cls: 0.4154  decode.d2.loss_mask: 1.3461  decode.d2.loss_dice: 0.9462  decode.d3.loss_cls: 0.4380  decode.d3.loss_mask: 1.3031  decode.d3.loss_dice: 0.9347  decode.d4.loss_cls: 0.4434  decode.d4.loss_mask: 1.2971  decode.d4.loss_dice: 0.9509  decode.d5.loss_cls: 0.4515  decode.d5.loss_mask: 1.3093  decode.d5.loss_dice: 0.9876  decode.d6.loss_cls: 0.4900  decode.d6.loss_mask: 1.2734  decode.d6.loss_dice: 0.9499  decode.d7.loss_cls: 0.4450  decode.d7.loss_mask: 1.3441  decode.d7.loss_dice: 0.9596  decode.d8.loss_cls: 0.4538  decode.d8.loss_mask: 1.3472  decode.d8.loss_dice: 0.9232
05/26 13:28:43 - mmengine - INFO - Iter(train) [ 21850/160000]  base_lr: 8.7621e-05 lr: 8.7621e-06  eta: 15:44:56  time: 0.4087  data_time: 0.0087  memory: 5975  grad_norm: 695.7546  loss: 26.6866  decode.loss_cls: 0.3391  decode.loss_mask: 1.3294  decode.loss_dice: 0.9329  decode.d0.loss_cls: 0.8197  decode.d0.loss_mask: 1.2661  decode.d0.loss_dice: 0.8611  decode.d1.loss_cls: 0.5032  decode.d1.loss_mask: 1.2586  decode.d1.loss_dice: 0.8711  decode.d2.loss_cls: 0.4805  decode.d2.loss_mask: 1.2876  decode.d2.loss_dice: 0.8778  decode.d3.loss_cls: 0.4756  decode.d3.loss_mask: 1.2910  decode.d3.loss_dice: 0.8963  decode.d4.loss_cls: 0.4670  decode.d4.loss_mask: 1.2879  decode.d4.loss_dice: 0.8986  decode.d5.loss_cls: 0.4417  decode.d5.loss_mask: 1.2982  decode.d5.loss_dice: 0.9163  decode.d6.loss_cls: 0.4211  decode.d6.loss_mask: 1.2758  decode.d6.loss_dice: 0.9215  decode.d7.loss_cls: 0.4721  decode.d7.loss_mask: 1.2765  decode.d7.loss_dice: 0.8826  decode.d8.loss_cls: 0.3663  decode.d8.loss_mask: 1.3458  decode.d8.loss_dice: 0.9251
05/26 13:29:04 - mmengine - INFO - Iter(train) [ 21900/160000]  base_lr: 8.7593e-05 lr: 8.7593e-06  eta: 15:44:35  time: 0.4086  data_time: 0.0088  memory: 5969  grad_norm: 442.7963  loss: 27.1588  decode.loss_cls: 0.3339  decode.loss_mask: 1.3531  decode.loss_dice: 0.9792  decode.d0.loss_cls: 0.8951  decode.d0.loss_mask: 1.2636  decode.d0.loss_dice: 0.8461  decode.d1.loss_cls: 0.3542  decode.d1.loss_mask: 1.3563  decode.d1.loss_dice: 0.9792  decode.d2.loss_cls: 0.4128  decode.d2.loss_mask: 1.3765  decode.d2.loss_dice: 0.9175  decode.d3.loss_cls: 0.3409  decode.d3.loss_mask: 1.3839  decode.d3.loss_dice: 0.9767  decode.d4.loss_cls: 0.4315  decode.d4.loss_mask: 1.3405  decode.d4.loss_dice: 0.9116  decode.d5.loss_cls: 0.4016  decode.d5.loss_mask: 1.3047  decode.d5.loss_dice: 0.9028  decode.d6.loss_cls: 0.3988  decode.d6.loss_mask: 1.3372  decode.d6.loss_dice: 0.9284  decode.d7.loss_cls: 0.4117  decode.d7.loss_mask: 1.3586  decode.d7.loss_dice: 0.9548  decode.d8.loss_cls: 0.3857  decode.d8.loss_mask: 1.3393  decode.d8.loss_dice: 0.9825
05/26 13:29:24 - mmengine - INFO - Iter(train) [ 21950/160000]  base_lr: 8.7564e-05 lr: 8.7564e-06  eta: 15:44:14  time: 0.4091  data_time: 0.0088  memory: 5967  grad_norm: 786.3314  loss: 25.7311  decode.loss_cls: 0.4242  decode.loss_mask: 1.2467  decode.loss_dice: 0.8362  decode.d0.loss_cls: 0.8830  decode.d0.loss_mask: 1.2582  decode.d0.loss_dice: 0.8529  decode.d1.loss_cls: 0.3462  decode.d1.loss_mask: 1.2747  decode.d1.loss_dice: 0.8575  decode.d2.loss_cls: 0.3476  decode.d2.loss_mask: 1.2750  decode.d2.loss_dice: 0.8439  decode.d3.loss_cls: 0.3850  decode.d3.loss_mask: 1.2661  decode.d3.loss_dice: 0.8518  decode.d4.loss_cls: 0.3864  decode.d4.loss_mask: 1.3169  decode.d4.loss_dice: 0.8805  decode.d5.loss_cls: 0.3921  decode.d5.loss_mask: 1.3049  decode.d5.loss_dice: 0.8475  decode.d6.loss_cls: 0.3793  decode.d6.loss_mask: 1.3061  decode.d6.loss_dice: 0.8754  decode.d7.loss_cls: 0.4002  decode.d7.loss_mask: 1.2953  decode.d7.loss_dice: 0.8458  decode.d8.loss_cls: 0.4426  decode.d8.loss_mask: 1.2611  decode.d8.loss_dice: 0.8479
05/26 13:29:45 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 13:29:45 - mmengine - INFO - Iter(train) [ 22000/160000]  base_lr: 8.7536e-05 lr: 8.7536e-06  eta: 15:43:53  time: 0.4087  data_time: 0.0087  memory: 5966  grad_norm: 1618.4875  loss: 31.2526  decode.loss_cls: 0.5197  decode.loss_mask: 1.5526  decode.loss_dice: 1.1567  decode.d0.loss_cls: 0.8782  decode.d0.loss_mask: 1.3964  decode.d0.loss_dice: 1.0783  decode.d1.loss_cls: 0.6149  decode.d1.loss_mask: 1.3464  decode.d1.loss_dice: 1.0769  decode.d2.loss_cls: 0.5812  decode.d2.loss_mask: 1.3831  decode.d2.loss_dice: 1.1451  decode.d3.loss_cls: 0.5634  decode.d3.loss_mask: 1.3501  decode.d3.loss_dice: 1.0625  decode.d4.loss_cls: 0.5496  decode.d4.loss_mask: 1.3739  decode.d4.loss_dice: 1.1136  decode.d5.loss_cls: 0.5012  decode.d5.loss_mask: 1.4013  decode.d5.loss_dice: 1.1281  decode.d6.loss_cls: 0.5730  decode.d6.loss_mask: 1.4662  decode.d6.loss_dice: 1.1381  decode.d7.loss_cls: 0.5741  decode.d7.loss_mask: 1.4227  decode.d7.loss_dice: 1.1186  decode.d8.loss_cls: 0.5292  decode.d8.loss_mask: 1.4967  decode.d8.loss_dice: 1.1610
05/26 13:30:05 - mmengine - INFO - Iter(train) [ 22050/160000]  base_lr: 8.7507e-05 lr: 8.7507e-06  eta: 15:43:32  time: 0.4094  data_time: 0.0088  memory: 5971  grad_norm: 1981.8629  loss: 28.4297  decode.loss_cls: 0.3375  decode.loss_mask: 1.3017  decode.loss_dice: 1.1222  decode.d0.loss_cls: 0.8688  decode.d0.loss_mask: 1.1969  decode.d0.loss_dice: 1.0593  decode.d1.loss_cls: 0.3974  decode.d1.loss_mask: 1.2923  decode.d1.loss_dice: 1.0930  decode.d2.loss_cls: 0.4432  decode.d2.loss_mask: 1.3200  decode.d2.loss_dice: 1.0447  decode.d3.loss_cls: 0.4277  decode.d3.loss_mask: 1.2940  decode.d3.loss_dice: 1.0804  decode.d4.loss_cls: 0.4005  decode.d4.loss_mask: 1.3493  decode.d4.loss_dice: 1.1014  decode.d5.loss_cls: 0.4008  decode.d5.loss_mask: 1.3109  decode.d5.loss_dice: 1.0694  decode.d6.loss_cls: 0.3929  decode.d6.loss_mask: 1.3616  decode.d6.loss_dice: 1.0942  decode.d7.loss_cls: 0.3925  decode.d7.loss_mask: 1.3456  decode.d7.loss_dice: 1.0892  decode.d8.loss_cls: 0.3983  decode.d8.loss_mask: 1.3032  decode.d8.loss_dice: 1.1408
05/26 13:30:26 - mmengine - INFO - Iter(train) [ 22100/160000]  base_lr: 8.7479e-05 lr: 8.7479e-06  eta: 15:43:11  time: 0.4092  data_time: 0.0089  memory: 5976  grad_norm: 988.1404  loss: 26.5256  decode.loss_cls: 0.3182  decode.loss_mask: 1.3926  decode.loss_dice: 1.0167  decode.d0.loss_cls: 0.7699  decode.d0.loss_mask: 1.2489  decode.d0.loss_dice: 0.8908  decode.d1.loss_cls: 0.2600  decode.d1.loss_mask: 1.3435  decode.d1.loss_dice: 0.9512  decode.d2.loss_cls: 0.2834  decode.d2.loss_mask: 1.3583  decode.d2.loss_dice: 0.9553  decode.d3.loss_cls: 0.2879  decode.d3.loss_mask: 1.2645  decode.d3.loss_dice: 0.9399  decode.d4.loss_cls: 0.3255  decode.d4.loss_mask: 1.2839  decode.d4.loss_dice: 1.0010  decode.d5.loss_cls: 0.3649  decode.d5.loss_mask: 1.2494  decode.d5.loss_dice: 0.9746  decode.d6.loss_cls: 0.3413  decode.d6.loss_mask: 1.2978  decode.d6.loss_dice: 0.9453  decode.d7.loss_cls: 0.3357  decode.d7.loss_mask: 1.4145  decode.d7.loss_dice: 1.0311  decode.d8.loss_cls: 0.2749  decode.d8.loss_mask: 1.3844  decode.d8.loss_dice: 1.0204
05/26 13:30:46 - mmengine - INFO - Iter(train) [ 22150/160000]  base_lr: 8.7450e-05 lr: 8.7450e-06  eta: 15:42:50  time: 0.4076  data_time: 0.0088  memory: 5971  grad_norm: 508.6496  loss: 22.5086  decode.loss_cls: 0.2945  decode.loss_mask: 1.0783  decode.loss_dice: 0.7740  decode.d0.loss_cls: 0.7255  decode.d0.loss_mask: 1.1020  decode.d0.loss_dice: 0.7750  decode.d1.loss_cls: 0.3214  decode.d1.loss_mask: 1.1152  decode.d1.loss_dice: 0.8035  decode.d2.loss_cls: 0.2943  decode.d2.loss_mask: 1.1216  decode.d2.loss_dice: 0.8001  decode.d3.loss_cls: 0.3439  decode.d3.loss_mask: 1.0748  decode.d3.loss_dice: 0.7732  decode.d4.loss_cls: 0.3036  decode.d4.loss_mask: 1.0835  decode.d4.loss_dice: 0.8297  decode.d5.loss_cls: 0.3004  decode.d5.loss_mask: 1.1241  decode.d5.loss_dice: 0.8216  decode.d6.loss_cls: 0.3321  decode.d6.loss_mask: 1.0995  decode.d6.loss_dice: 0.7919  decode.d7.loss_cls: 0.2959  decode.d7.loss_mask: 1.1332  decode.d7.loss_dice: 0.8175  decode.d8.loss_cls: 0.2899  decode.d8.loss_mask: 1.0923  decode.d8.loss_dice: 0.7960
05/26 13:31:06 - mmengine - INFO - Iter(train) [ 22200/160000]  base_lr: 8.7422e-05 lr: 8.7422e-06  eta: 15:42:29  time: 0.4069  data_time: 0.0087  memory: 5969  grad_norm: 1551.2502  loss: 28.0846  decode.loss_cls: 0.3149  decode.loss_mask: 1.4502  decode.loss_dice: 1.0544  decode.d0.loss_cls: 0.7669  decode.d0.loss_mask: 1.3780  decode.d0.loss_dice: 1.0129  decode.d1.loss_cls: 0.2850  decode.d1.loss_mask: 1.3760  decode.d1.loss_dice: 1.0092  decode.d2.loss_cls: 0.3275  decode.d2.loss_mask: 1.3928  decode.d2.loss_dice: 1.0117  decode.d3.loss_cls: 0.3260  decode.d3.loss_mask: 1.3996  decode.d3.loss_dice: 1.0260  decode.d4.loss_cls: 0.3164  decode.d4.loss_mask: 1.3933  decode.d4.loss_dice: 1.0647  decode.d5.loss_cls: 0.3231  decode.d5.loss_mask: 1.3940  decode.d5.loss_dice: 1.0755  decode.d6.loss_cls: 0.3332  decode.d6.loss_mask: 1.4066  decode.d6.loss_dice: 1.0830  decode.d7.loss_cls: 0.3347  decode.d7.loss_mask: 1.4453  decode.d7.loss_dice: 1.0412  decode.d8.loss_cls: 0.2709  decode.d8.loss_mask: 1.4226  decode.d8.loss_dice: 1.0493
05/26 13:31:27 - mmengine - INFO - Iter(train) [ 22250/160000]  base_lr: 8.7393e-05 lr: 8.7393e-06  eta: 15:42:08  time: 0.4079  data_time: 0.0088  memory: 5976  grad_norm: 566.5895  loss: 27.7261  decode.loss_cls: 0.3768  decode.loss_mask: 1.3202  decode.loss_dice: 1.0657  decode.d0.loss_cls: 0.7991  decode.d0.loss_mask: 1.2133  decode.d0.loss_dice: 0.9706  decode.d1.loss_cls: 0.4232  decode.d1.loss_mask: 1.3180  decode.d1.loss_dice: 1.0734  decode.d2.loss_cls: 0.4091  decode.d2.loss_mask: 1.2834  decode.d2.loss_dice: 1.0041  decode.d3.loss_cls: 0.4082  decode.d3.loss_mask: 1.3054  decode.d3.loss_dice: 1.0236  decode.d4.loss_cls: 0.4805  decode.d4.loss_mask: 1.2725  decode.d4.loss_dice: 0.9987  decode.d5.loss_cls: 0.4670  decode.d5.loss_mask: 1.3068  decode.d5.loss_dice: 1.0532  decode.d6.loss_cls: 0.4606  decode.d6.loss_mask: 1.2791  decode.d6.loss_dice: 0.9941  decode.d7.loss_cls: 0.4711  decode.d7.loss_mask: 1.2690  decode.d7.loss_dice: 0.9771  decode.d8.loss_cls: 0.3943  decode.d8.loss_mask: 1.2537  decode.d8.loss_dice: 1.0545
05/26 13:31:47 - mmengine - INFO - Iter(train) [ 22300/160000]  base_lr: 8.7365e-05 lr: 8.7365e-06  eta: 15:41:47  time: 0.4089  data_time: 0.0088  memory: 5966  grad_norm: 757.4919  loss: 25.4647  decode.loss_cls: 0.3431  decode.loss_mask: 1.2336  decode.loss_dice: 0.8823  decode.d0.loss_cls: 0.8409  decode.d0.loss_mask: 1.1846  decode.d0.loss_dice: 0.8533  decode.d1.loss_cls: 0.3925  decode.d1.loss_mask: 1.2014  decode.d1.loss_dice: 0.8393  decode.d2.loss_cls: 0.4181  decode.d2.loss_mask: 1.2340  decode.d2.loss_dice: 0.8537  decode.d3.loss_cls: 0.4114  decode.d3.loss_mask: 1.2922  decode.d3.loss_dice: 0.8928  decode.d4.loss_cls: 0.4125  decode.d4.loss_mask: 1.2481  decode.d4.loss_dice: 0.8625  decode.d5.loss_cls: 0.4359  decode.d5.loss_mask: 1.2715  decode.d5.loss_dice: 0.8802  decode.d6.loss_cls: 0.4240  decode.d6.loss_mask: 1.2346  decode.d6.loss_dice: 0.8575  decode.d7.loss_cls: 0.3627  decode.d7.loss_mask: 1.2665  decode.d7.loss_dice: 0.8717  decode.d8.loss_cls: 0.3402  decode.d8.loss_mask: 1.2427  decode.d8.loss_dice: 0.8809
05/26 13:32:08 - mmengine - INFO - Iter(train) [ 22350/160000]  base_lr: 8.7336e-05 lr: 8.7336e-06  eta: 15:41:26  time: 0.4074  data_time: 0.0088  memory: 5966  grad_norm: 817.0471  loss: 30.6549  decode.loss_cls: 0.4136  decode.loss_mask: 1.5738  decode.loss_dice: 1.0153  decode.d0.loss_cls: 0.8306  decode.d0.loss_mask: 1.4960  decode.d0.loss_dice: 0.9875  decode.d1.loss_cls: 0.5048  decode.d1.loss_mask: 1.4839  decode.d1.loss_dice: 0.9969  decode.d2.loss_cls: 0.4515  decode.d2.loss_mask: 1.5404  decode.d2.loss_dice: 1.0241  decode.d3.loss_cls: 0.4542  decode.d3.loss_mask: 1.5990  decode.d3.loss_dice: 1.0082  decode.d4.loss_cls: 0.4605  decode.d4.loss_mask: 1.5500  decode.d4.loss_dice: 0.9709  decode.d5.loss_cls: 0.5037  decode.d5.loss_mask: 1.5070  decode.d5.loss_dice: 1.0441  decode.d6.loss_cls: 0.4566  decode.d6.loss_mask: 1.5966  decode.d6.loss_dice: 1.0906  decode.d7.loss_cls: 0.4074  decode.d7.loss_mask: 1.5912  decode.d7.loss_dice: 1.0334  decode.d8.loss_cls: 0.4483  decode.d8.loss_mask: 1.5836  decode.d8.loss_dice: 1.0312
05/26 13:32:28 - mmengine - INFO - Iter(train) [ 22400/160000]  base_lr: 8.7307e-05 lr: 8.7307e-06  eta: 15:41:05  time: 0.4079  data_time: 0.0089  memory: 5974  grad_norm: 940.5247  loss: 24.6632  decode.loss_cls: 0.2708  decode.loss_mask: 1.0582  decode.loss_dice: 1.0012  decode.d0.loss_cls: 0.6951  decode.d0.loss_mask: 1.1449  decode.d0.loss_dice: 0.9443  decode.d1.loss_cls: 0.2789  decode.d1.loss_mask: 1.1977  decode.d1.loss_dice: 1.0373  decode.d2.loss_cls: 0.2493  decode.d2.loss_mask: 1.1282  decode.d2.loss_dice: 1.0326  decode.d3.loss_cls: 0.3680  decode.d3.loss_mask: 1.1265  decode.d3.loss_dice: 1.0529  decode.d4.loss_cls: 0.3551  decode.d4.loss_mask: 1.0873  decode.d4.loss_dice: 1.0161  decode.d5.loss_cls: 0.3436  decode.d5.loss_mask: 1.0573  decode.d5.loss_dice: 0.9802  decode.d6.loss_cls: 0.3569  decode.d6.loss_mask: 1.1120  decode.d6.loss_dice: 1.0220  decode.d7.loss_cls: 0.2682  decode.d7.loss_mask: 1.1251  decode.d7.loss_dice: 1.0212  decode.d8.loss_cls: 0.3377  decode.d8.loss_mask: 1.0485  decode.d8.loss_dice: 0.9462
05/26 13:32:49 - mmengine - INFO - Iter(train) [ 22450/160000]  base_lr: 8.7279e-05 lr: 8.7279e-06  eta: 15:40:44  time: 0.4086  data_time: 0.0087  memory: 5968  grad_norm: 449.3422  loss: 27.0135  decode.loss_cls: 0.2739  decode.loss_mask: 1.4589  decode.loss_dice: 0.9862  decode.d0.loss_cls: 0.7959  decode.d0.loss_mask: 1.3051  decode.d0.loss_dice: 0.9229  decode.d1.loss_cls: 0.3018  decode.d1.loss_mask: 1.3659  decode.d1.loss_dice: 0.9406  decode.d2.loss_cls: 0.3384  decode.d2.loss_mask: 1.3786  decode.d2.loss_dice: 0.9906  decode.d3.loss_cls: 0.3200  decode.d3.loss_mask: 1.3119  decode.d3.loss_dice: 0.9801  decode.d4.loss_cls: 0.3569  decode.d4.loss_mask: 1.3641  decode.d4.loss_dice: 0.9761  decode.d5.loss_cls: 0.3530  decode.d5.loss_mask: 1.3003  decode.d5.loss_dice: 0.9429  decode.d6.loss_cls: 0.3776  decode.d6.loss_mask: 1.3339  decode.d6.loss_dice: 0.9499  decode.d7.loss_cls: 0.3725  decode.d7.loss_mask: 1.3266  decode.d7.loss_dice: 0.9753  decode.d8.loss_cls: 0.3120  decode.d8.loss_mask: 1.4117  decode.d8.loss_dice: 0.9901
05/26 13:33:09 - mmengine - INFO - Iter(train) [ 22500/160000]  base_lr: 8.7250e-05 lr: 8.7250e-06  eta: 15:40:23  time: 0.4101  data_time: 0.0090  memory: 5969  grad_norm: 543.2315  loss: 20.2697  decode.loss_cls: 0.3035  decode.loss_mask: 0.9480  decode.loss_dice: 0.7297  decode.d0.loss_cls: 0.7975  decode.d0.loss_mask: 0.9111  decode.d0.loss_dice: 0.6515  decode.d1.loss_cls: 0.2908  decode.d1.loss_mask: 0.9573  decode.d1.loss_dice: 0.7212  decode.d2.loss_cls: 0.3177  decode.d2.loss_mask: 0.9402  decode.d2.loss_dice: 0.7423  decode.d3.loss_cls: 0.2797  decode.d3.loss_mask: 0.9877  decode.d3.loss_dice: 0.7568  decode.d4.loss_cls: 0.3167  decode.d4.loss_mask: 0.9943  decode.d4.loss_dice: 0.7083  decode.d5.loss_cls: 0.3220  decode.d5.loss_mask: 0.9372  decode.d5.loss_dice: 0.7284  decode.d6.loss_cls: 0.3579  decode.d6.loss_mask: 0.9272  decode.d6.loss_dice: 0.6890  decode.d7.loss_cls: 0.3219  decode.d7.loss_mask: 0.9609  decode.d7.loss_dice: 0.6976  decode.d8.loss_cls: 0.3200  decode.d8.loss_mask: 0.9449  decode.d8.loss_dice: 0.7083
05/26 13:33:30 - mmengine - INFO - Iter(train) [ 22550/160000]  base_lr: 8.7222e-05 lr: 8.7222e-06  eta: 15:40:02  time: 0.4094  data_time: 0.0088  memory: 5967  grad_norm: 545.2552  loss: 24.0701  decode.loss_cls: 0.3114  decode.loss_mask: 1.0982  decode.loss_dice: 0.9103  decode.d0.loss_cls: 0.7993  decode.d0.loss_mask: 1.0242  decode.d0.loss_dice: 0.8969  decode.d1.loss_cls: 0.3620  decode.d1.loss_mask: 1.0955  decode.d1.loss_dice: 0.9015  decode.d2.loss_cls: 0.3603  decode.d2.loss_mask: 1.0751  decode.d2.loss_dice: 0.8894  decode.d3.loss_cls: 0.3660  decode.d3.loss_mask: 1.1248  decode.d3.loss_dice: 0.9199  decode.d4.loss_cls: 0.3457  decode.d4.loss_mask: 1.1092  decode.d4.loss_dice: 0.9165  decode.d5.loss_cls: 0.3973  decode.d5.loss_mask: 1.0575  decode.d5.loss_dice: 0.8963  decode.d6.loss_cls: 0.4015  decode.d6.loss_mask: 1.0619  decode.d6.loss_dice: 0.9401  decode.d7.loss_cls: 0.3725  decode.d7.loss_mask: 1.1100  decode.d7.loss_dice: 0.9658  decode.d8.loss_cls: 0.3631  decode.d8.loss_mask: 1.0993  decode.d8.loss_dice: 0.8985
05/26 13:33:50 - mmengine - INFO - Iter(train) [ 22600/160000]  base_lr: 8.7193e-05 lr: 8.7193e-06  eta: 15:39:41  time: 0.4098  data_time: 0.0101  memory: 5979  grad_norm: 506.0153  loss: 22.0645  decode.loss_cls: 0.2097  decode.loss_mask: 1.1488  decode.loss_dice: 0.7647  decode.d0.loss_cls: 0.7405  decode.d0.loss_mask: 1.1202  decode.d0.loss_dice: 0.7015  decode.d1.loss_cls: 0.2332  decode.d1.loss_mask: 1.1843  decode.d1.loss_dice: 0.7808  decode.d2.loss_cls: 0.2214  decode.d2.loss_mask: 1.1878  decode.d2.loss_dice: 0.7377  decode.d3.loss_cls: 0.2509  decode.d3.loss_mask: 1.1775  decode.d3.loss_dice: 0.7424  decode.d4.loss_cls: 0.2479  decode.d4.loss_mask: 1.2114  decode.d4.loss_dice: 0.7722  decode.d5.loss_cls: 0.2690  decode.d5.loss_mask: 1.1435  decode.d5.loss_dice: 0.7283  decode.d6.loss_cls: 0.2444  decode.d6.loss_mask: 1.1915  decode.d6.loss_dice: 0.7892  decode.d7.loss_cls: 0.2852  decode.d7.loss_mask: 1.1618  decode.d7.loss_dice: 0.7214  decode.d8.loss_cls: 0.2404  decode.d8.loss_mask: 1.1337  decode.d8.loss_dice: 0.7234
05/26 13:34:10 - mmengine - INFO - Iter(train) [ 22650/160000]  base_lr: 8.7165e-05 lr: 8.7165e-06  eta: 15:39:20  time: 0.4076  data_time: 0.0088  memory: 5968  grad_norm: 1166.1094  loss: 26.2430  decode.loss_cls: 0.5515  decode.loss_mask: 1.2137  decode.loss_dice: 0.8957  decode.d0.loss_cls: 0.8333  decode.d0.loss_mask: 1.1567  decode.d0.loss_dice: 0.8924  decode.d1.loss_cls: 0.4580  decode.d1.loss_mask: 1.2063  decode.d1.loss_dice: 0.8747  decode.d2.loss_cls: 0.4711  decode.d2.loss_mask: 1.2080  decode.d2.loss_dice: 0.9239  decode.d3.loss_cls: 0.4701  decode.d3.loss_mask: 1.2314  decode.d3.loss_dice: 0.8954  decode.d4.loss_cls: 0.4839  decode.d4.loss_mask: 1.1986  decode.d4.loss_dice: 0.8745  decode.d5.loss_cls: 0.4656  decode.d5.loss_mask: 1.1885  decode.d5.loss_dice: 0.8746  decode.d6.loss_cls: 0.5199  decode.d6.loss_mask: 1.2515  decode.d6.loss_dice: 0.8966  decode.d7.loss_cls: 0.4632  decode.d7.loss_mask: 1.2490  decode.d7.loss_dice: 0.9128  decode.d8.loss_cls: 0.4414  decode.d8.loss_mask: 1.2438  decode.d8.loss_dice: 0.8970
05/26 13:34:32 - mmengine - INFO - Iter(train) [ 22700/160000]  base_lr: 8.7136e-05 lr: 8.7136e-06  eta: 15:39:03  time: 0.4077  data_time: 0.0090  memory: 5968  grad_norm: 778.5087  loss: 25.3972  decode.loss_cls: 0.3497  decode.loss_mask: 1.1984  decode.loss_dice: 0.9352  decode.d0.loss_cls: 0.7794  decode.d0.loss_mask: 1.1453  decode.d0.loss_dice: 0.9087  decode.d1.loss_cls: 0.4212  decode.d1.loss_mask: 1.1776  decode.d1.loss_dice: 0.9193  decode.d2.loss_cls: 0.4419  decode.d2.loss_mask: 1.1270  decode.d2.loss_dice: 0.9253  decode.d3.loss_cls: 0.4114  decode.d3.loss_mask: 1.1636  decode.d3.loss_dice: 0.9318  decode.d4.loss_cls: 0.4624  decode.d4.loss_mask: 1.1339  decode.d4.loss_dice: 0.9114  decode.d5.loss_cls: 0.4303  decode.d5.loss_mask: 1.1540  decode.d5.loss_dice: 0.9269  decode.d6.loss_cls: 0.4135  decode.d6.loss_mask: 1.1941  decode.d6.loss_dice: 0.9367  decode.d7.loss_cls: 0.4426  decode.d7.loss_mask: 1.1400  decode.d7.loss_dice: 0.9170  decode.d8.loss_cls: 0.4658  decode.d8.loss_mask: 1.1437  decode.d8.loss_dice: 0.8890
05/26 13:34:52 - mmengine - INFO - Iter(train) [ 22750/160000]  base_lr: 8.7108e-05 lr: 8.7108e-06  eta: 15:38:42  time: 0.4095  data_time: 0.0089  memory: 5969  grad_norm: 647.6763  loss: 30.9551  decode.loss_cls: 0.5088  decode.loss_mask: 1.4887  decode.loss_dice: 1.1473  decode.d0.loss_cls: 0.9591  decode.d0.loss_mask: 1.3992  decode.d0.loss_dice: 1.0509  decode.d1.loss_cls: 0.4628  decode.d1.loss_mask: 1.4217  decode.d1.loss_dice: 1.1419  decode.d2.loss_cls: 0.4686  decode.d2.loss_mask: 1.4028  decode.d2.loss_dice: 1.0810  decode.d3.loss_cls: 0.5216  decode.d3.loss_mask: 1.3972  decode.d3.loss_dice: 1.0846  decode.d4.loss_cls: 0.4927  decode.d4.loss_mask: 1.4350  decode.d4.loss_dice: 1.1395  decode.d5.loss_cls: 0.4860  decode.d5.loss_mask: 1.4246  decode.d5.loss_dice: 1.1210  decode.d6.loss_cls: 0.6268  decode.d6.loss_mask: 1.4200  decode.d6.loss_dice: 1.1586  decode.d7.loss_cls: 0.5814  decode.d7.loss_mask: 1.3974  decode.d7.loss_dice: 1.1138  decode.d8.loss_cls: 0.4812  decode.d8.loss_mask: 1.4431  decode.d8.loss_dice: 1.0978
05/26 13:35:12 - mmengine - INFO - Iter(train) [ 22800/160000]  base_lr: 8.7079e-05 lr: 8.7079e-06  eta: 15:38:21  time: 0.4092  data_time: 0.0090  memory: 5968  grad_norm: 940.7599  loss: 26.9451  decode.loss_cls: 0.3896  decode.loss_mask: 1.2787  decode.loss_dice: 0.9723  decode.d0.loss_cls: 0.9488  decode.d0.loss_mask: 1.2439  decode.d0.loss_dice: 0.9578  decode.d1.loss_cls: 0.4463  decode.d1.loss_mask: 1.2887  decode.d1.loss_dice: 0.9898  decode.d2.loss_cls: 0.4330  decode.d2.loss_mask: 1.2337  decode.d2.loss_dice: 0.9205  decode.d3.loss_cls: 0.4543  decode.d3.loss_mask: 1.2051  decode.d3.loss_dice: 0.8953  decode.d4.loss_cls: 0.4560  decode.d4.loss_mask: 1.2529  decode.d4.loss_dice: 0.9868  decode.d5.loss_cls: 0.4480  decode.d5.loss_mask: 1.2954  decode.d5.loss_dice: 0.9848  decode.d6.loss_cls: 0.4187  decode.d6.loss_mask: 1.2583  decode.d6.loss_dice: 0.9442  decode.d7.loss_cls: 0.4079  decode.d7.loss_mask: 1.2765  decode.d7.loss_dice: 0.9393  decode.d8.loss_cls: 0.4116  decode.d8.loss_mask: 1.2613  decode.d8.loss_dice: 0.9456
05/26 13:35:33 - mmengine - INFO - Iter(train) [ 22850/160000]  base_lr: 8.7050e-05 lr: 8.7050e-06  eta: 15:38:00  time: 0.4091  data_time: 0.0089  memory: 5981  grad_norm: 825.6003  loss: 29.6436  decode.loss_cls: 0.4231  decode.loss_mask: 1.4079  decode.loss_dice: 1.0851  decode.d0.loss_cls: 0.9428  decode.d0.loss_mask: 1.3158  decode.d0.loss_dice: 1.0219  decode.d1.loss_cls: 0.4413  decode.d1.loss_mask: 1.4164  decode.d1.loss_dice: 1.0478  decode.d2.loss_cls: 0.4913  decode.d2.loss_mask: 1.4146  decode.d2.loss_dice: 1.0685  decode.d3.loss_cls: 0.5000  decode.d3.loss_mask: 1.3415  decode.d3.loss_dice: 1.0396  decode.d4.loss_cls: 0.5049  decode.d4.loss_mask: 1.4081  decode.d4.loss_dice: 1.0241  decode.d5.loss_cls: 0.5181  decode.d5.loss_mask: 1.3596  decode.d5.loss_dice: 1.0508  decode.d6.loss_cls: 0.5482  decode.d6.loss_mask: 1.3703  decode.d6.loss_dice: 1.0533  decode.d7.loss_cls: 0.4981  decode.d7.loss_mask: 1.4062  decode.d7.loss_dice: 1.0551  decode.d8.loss_cls: 0.4377  decode.d8.loss_mask: 1.3963  decode.d8.loss_dice: 1.0550
05/26 13:35:53 - mmengine - INFO - Iter(train) [ 22900/160000]  base_lr: 8.7022e-05 lr: 8.7022e-06  eta: 15:37:39  time: 0.4106  data_time: 0.0092  memory: 5975  grad_norm: 909.4859  loss: 30.8408  decode.loss_cls: 0.3813  decode.loss_mask: 1.4841  decode.loss_dice: 1.1798  decode.d0.loss_cls: 0.8233  decode.d0.loss_mask: 1.4607  decode.d0.loss_dice: 1.1559  decode.d1.loss_cls: 0.4482  decode.d1.loss_mask: 1.4098  decode.d1.loss_dice: 1.1221  decode.d2.loss_cls: 0.4476  decode.d2.loss_mask: 1.4457  decode.d2.loss_dice: 1.1483  decode.d3.loss_cls: 0.4266  decode.d3.loss_mask: 1.4263  decode.d3.loss_dice: 1.1523  decode.d4.loss_cls: 0.3902  decode.d4.loss_mask: 1.4918  decode.d4.loss_dice: 1.1705  decode.d5.loss_cls: 0.4790  decode.d5.loss_mask: 1.4472  decode.d5.loss_dice: 1.1142  decode.d6.loss_cls: 0.4104  decode.d6.loss_mask: 1.4522  decode.d6.loss_dice: 1.2084  decode.d7.loss_cls: 0.4150  decode.d7.loss_mask: 1.5026  decode.d7.loss_dice: 1.2023  decode.d8.loss_cls: 0.3851  decode.d8.loss_mask: 1.4694  decode.d8.loss_dice: 1.1906
05/26 13:36:15 - mmengine - INFO - Iter(train) [ 22950/160000]  base_lr: 8.6993e-05 lr: 8.6993e-06  eta: 15:37:24  time: 0.4105  data_time: 0.0090  memory: 5968  grad_norm: 719.1156  loss: 30.9447  decode.loss_cls: 0.3649  decode.loss_mask: 1.5711  decode.loss_dice: 1.1337  decode.d0.loss_cls: 0.8274  decode.d0.loss_mask: 1.4679  decode.d0.loss_dice: 1.1022  decode.d1.loss_cls: 0.3748  decode.d1.loss_mask: 1.5692  decode.d1.loss_dice: 1.0980  decode.d2.loss_cls: 0.4028  decode.d2.loss_mask: 1.5303  decode.d2.loss_dice: 1.0689  decode.d3.loss_cls: 0.3646  decode.d3.loss_mask: 1.5541  decode.d3.loss_dice: 1.1252  decode.d4.loss_cls: 0.4398  decode.d4.loss_mask: 1.5203  decode.d4.loss_dice: 1.1062  decode.d5.loss_cls: 0.3800  decode.d5.loss_mask: 1.5449  decode.d5.loss_dice: 1.1021  decode.d6.loss_cls: 0.3942  decode.d6.loss_mask: 1.6316  decode.d6.loss_dice: 1.1514  decode.d7.loss_cls: 0.3411  decode.d7.loss_mask: 1.5674  decode.d7.loss_dice: 1.1257  decode.d8.loss_cls: 0.4130  decode.d8.loss_mask: 1.5698  decode.d8.loss_dice: 1.1022
05/26 13:36:36 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 13:36:36 - mmengine - INFO - Iter(train) [ 23000/160000]  base_lr: 8.6965e-05 lr: 8.6965e-06  eta: 15:37:05  time: 0.4118  data_time: 0.0091  memory: 5976  grad_norm: 1135.3747  loss: 28.0468  decode.loss_cls: 0.5296  decode.loss_mask: 1.2396  decode.loss_dice: 0.9810  decode.d0.loss_cls: 0.9972  decode.d0.loss_mask: 1.1808  decode.d0.loss_dice: 0.9119  decode.d1.loss_cls: 0.5254  decode.d1.loss_mask: 1.2493  decode.d1.loss_dice: 0.9787  decode.d2.loss_cls: 0.5317  decode.d2.loss_mask: 1.2468  decode.d2.loss_dice: 0.9466  decode.d3.loss_cls: 0.5857  decode.d3.loss_mask: 1.2645  decode.d3.loss_dice: 0.9696  decode.d4.loss_cls: 0.6354  decode.d4.loss_mask: 1.2019  decode.d4.loss_dice: 0.9543  decode.d5.loss_cls: 0.5134  decode.d5.loss_mask: 1.2703  decode.d5.loss_dice: 0.9910  decode.d6.loss_cls: 0.5596  decode.d6.loss_mask: 1.2552  decode.d6.loss_dice: 1.0044  decode.d7.loss_cls: 0.5548  decode.d7.loss_mask: 1.2323  decode.d7.loss_dice: 0.9337  decode.d8.loss_cls: 0.5169  decode.d8.loss_mask: 1.2605  decode.d8.loss_dice: 1.0245
05/26 13:36:56 - mmengine - INFO - Iter(train) [ 23050/160000]  base_lr: 8.6936e-05 lr: 8.6936e-06  eta: 15:36:45  time: 0.4106  data_time: 0.0093  memory: 5984  grad_norm: 875.3141  loss: 25.5512  decode.loss_cls: 0.3545  decode.loss_mask: 1.2147  decode.loss_dice: 0.9747  decode.d0.loss_cls: 0.8082  decode.d0.loss_mask: 1.1499  decode.d0.loss_dice: 0.8942  decode.d1.loss_cls: 0.3619  decode.d1.loss_mask: 1.2303  decode.d1.loss_dice: 0.9632  decode.d2.loss_cls: 0.3602  decode.d2.loss_mask: 1.2027  decode.d2.loss_dice: 0.9379  decode.d3.loss_cls: 0.3234  decode.d3.loss_mask: 1.2236  decode.d3.loss_dice: 0.9194  decode.d4.loss_cls: 0.3698  decode.d4.loss_mask: 1.2397  decode.d4.loss_dice: 0.9441  decode.d5.loss_cls: 0.3887  decode.d5.loss_mask: 1.2121  decode.d5.loss_dice: 0.9219  decode.d6.loss_cls: 0.3261  decode.d6.loss_mask: 1.2149  decode.d6.loss_dice: 0.9097  decode.d7.loss_cls: 0.3674  decode.d7.loss_mask: 1.2379  decode.d7.loss_dice: 0.9458  decode.d8.loss_cls: 0.3827  decode.d8.loss_mask: 1.2062  decode.d8.loss_dice: 0.9654
05/26 13:37:17 - mmengine - INFO - Iter(train) [ 23100/160000]  base_lr: 8.6908e-05 lr: 8.6908e-06  eta: 15:36:26  time: 0.4119  data_time: 0.0094  memory: 5976  grad_norm: 625.0775  loss: 28.9244  decode.loss_cls: 0.4853  decode.loss_mask: 1.1927  decode.loss_dice: 1.1185  decode.d0.loss_cls: 0.9370  decode.d0.loss_mask: 1.1381  decode.d0.loss_dice: 1.0523  decode.d1.loss_cls: 0.4828  decode.d1.loss_mask: 1.3266  decode.d1.loss_dice: 1.0948  decode.d2.loss_cls: 0.4982  decode.d2.loss_mask: 1.2665  decode.d2.loss_dice: 1.0972  decode.d3.loss_cls: 0.5537  decode.d3.loss_mask: 1.2784  decode.d3.loss_dice: 1.0865  decode.d4.loss_cls: 0.5022  decode.d4.loss_mask: 1.2744  decode.d4.loss_dice: 1.1376  decode.d5.loss_cls: 0.5129  decode.d5.loss_mask: 1.2130  decode.d5.loss_dice: 1.1039  decode.d6.loss_cls: 0.5038  decode.d6.loss_mask: 1.2739  decode.d6.loss_dice: 1.1094  decode.d7.loss_cls: 0.4233  decode.d7.loss_mask: 1.3190  decode.d7.loss_dice: 1.1001  decode.d8.loss_cls: 0.4698  decode.d8.loss_mask: 1.2526  decode.d8.loss_dice: 1.1197
05/26 13:37:37 - mmengine - INFO - Iter(train) [ 23150/160000]  base_lr: 8.6879e-05 lr: 8.6879e-06  eta: 15:36:06  time: 0.4111  data_time: 0.0091  memory: 5966  grad_norm: 562.0366  loss: 27.6224  decode.loss_cls: 0.3873  decode.loss_mask: 1.2902  decode.loss_dice: 1.0105  decode.d0.loss_cls: 0.9453  decode.d0.loss_mask: 1.2003  decode.d0.loss_dice: 0.9451  decode.d1.loss_cls: 0.4405  decode.d1.loss_mask: 1.2831  decode.d1.loss_dice: 1.0633  decode.d2.loss_cls: 0.4070  decode.d2.loss_mask: 1.3022  decode.d2.loss_dice: 1.0118  decode.d3.loss_cls: 0.4413  decode.d3.loss_mask: 1.2613  decode.d3.loss_dice: 1.0384  decode.d4.loss_cls: 0.4001  decode.d4.loss_mask: 1.2699  decode.d4.loss_dice: 1.0472  decode.d5.loss_cls: 0.3860  decode.d5.loss_mask: 1.2923  decode.d5.loss_dice: 1.0569  decode.d6.loss_cls: 0.4646  decode.d6.loss_mask: 1.2612  decode.d6.loss_dice: 1.0064  decode.d7.loss_cls: 0.4243  decode.d7.loss_mask: 1.2913  decode.d7.loss_dice: 1.0188  decode.d8.loss_cls: 0.4156  decode.d8.loss_mask: 1.2462  decode.d8.loss_dice: 1.0143
05/26 13:37:58 - mmengine - INFO - Iter(train) [ 23200/160000]  base_lr: 8.6850e-05 lr: 8.6850e-06  eta: 15:35:45  time: 0.4104  data_time: 0.0090  memory: 5976  grad_norm: 762.0526  loss: 29.5190  decode.loss_cls: 0.4844  decode.loss_mask: 1.3859  decode.loss_dice: 1.0579  decode.d0.loss_cls: 0.9694  decode.d0.loss_mask: 1.2785  decode.d0.loss_dice: 0.9696  decode.d1.loss_cls: 0.5255  decode.d1.loss_mask: 1.3649  decode.d1.loss_dice: 0.9986  decode.d2.loss_cls: 0.5288  decode.d2.loss_mask: 1.3396  decode.d2.loss_dice: 1.0004  decode.d3.loss_cls: 0.4975  decode.d3.loss_mask: 1.3630  decode.d3.loss_dice: 0.9916  decode.d4.loss_cls: 0.5084  decode.d4.loss_mask: 1.3584  decode.d4.loss_dice: 1.0053  decode.d5.loss_cls: 0.5129  decode.d5.loss_mask: 1.3330  decode.d5.loss_dice: 1.0268  decode.d6.loss_cls: 0.5249  decode.d6.loss_mask: 1.4051  decode.d6.loss_dice: 1.0820  decode.d7.loss_cls: 0.5136  decode.d7.loss_mask: 1.4050  decode.d7.loss_dice: 1.1103  decode.d8.loss_cls: 0.5046  decode.d8.loss_mask: 1.4132  decode.d8.loss_dice: 1.0597
05/26 13:38:19 - mmengine - INFO - Iter(train) [ 23250/160000]  base_lr: 8.6822e-05 lr: 8.6822e-06  eta: 15:35:27  time: 0.4101  data_time: 0.0091  memory: 5969  grad_norm: 1292.3361  loss: 30.0153  decode.loss_cls: 0.4178  decode.loss_mask: 1.3995  decode.loss_dice: 1.1341  decode.d0.loss_cls: 0.9324  decode.d0.loss_mask: 1.3151  decode.d0.loss_dice: 1.0242  decode.d1.loss_cls: 0.4824  decode.d1.loss_mask: 1.4215  decode.d1.loss_dice: 1.1279  decode.d2.loss_cls: 0.4496  decode.d2.loss_mask: 1.3743  decode.d2.loss_dice: 1.0561  decode.d3.loss_cls: 0.4560  decode.d3.loss_mask: 1.3857  decode.d3.loss_dice: 1.1020  decode.d4.loss_cls: 0.4785  decode.d4.loss_mask: 1.3715  decode.d4.loss_dice: 1.1008  decode.d5.loss_cls: 0.4471  decode.d5.loss_mask: 1.3884  decode.d5.loss_dice: 1.1280  decode.d6.loss_cls: 0.4615  decode.d6.loss_mask: 1.4201  decode.d6.loss_dice: 1.1667  decode.d7.loss_cls: 0.4488  decode.d7.loss_mask: 1.4362  decode.d7.loss_dice: 1.1450  decode.d8.loss_cls: 0.4196  decode.d8.loss_mask: 1.4058  decode.d8.loss_dice: 1.1186
05/26 13:38:43 - mmengine - INFO - Iter(train) [ 23300/160000]  base_lr: 8.6793e-05 lr: 8.6793e-06  eta: 15:35:26  time: 0.4109  data_time: 0.0090  memory: 5970  grad_norm: 594.7956  loss: 26.7422  decode.loss_cls: 0.3510  decode.loss_mask: 1.3966  decode.loss_dice: 0.9072  decode.d0.loss_cls: 0.7989  decode.d0.loss_mask: 1.3230  decode.d0.loss_dice: 0.8728  decode.d1.loss_cls: 0.3238  decode.d1.loss_mask: 1.4160  decode.d1.loss_dice: 0.9229  decode.d2.loss_cls: 0.3653  decode.d2.loss_mask: 1.3660  decode.d2.loss_dice: 0.9027  decode.d3.loss_cls: 0.3752  decode.d3.loss_mask: 1.3506  decode.d3.loss_dice: 0.8751  decode.d4.loss_cls: 0.3401  decode.d4.loss_mask: 1.3709  decode.d4.loss_dice: 0.9086  decode.d5.loss_cls: 0.3158  decode.d5.loss_mask: 1.4435  decode.d5.loss_dice: 0.9363  decode.d6.loss_cls: 0.3820  decode.d6.loss_mask: 1.3596  decode.d6.loss_dice: 0.9050  decode.d7.loss_cls: 0.3840  decode.d7.loss_mask: 1.3441  decode.d7.loss_dice: 0.9006  decode.d8.loss_cls: 0.3146  decode.d8.loss_mask: 1.4100  decode.d8.loss_dice: 0.8799
05/26 13:39:03 - mmengine - INFO - Iter(train) [ 23350/160000]  base_lr: 8.6765e-05 lr: 8.6765e-06  eta: 15:35:06  time: 0.4111  data_time: 0.0090  memory: 5966  grad_norm: 533.2540  loss: 21.0896  decode.loss_cls: 0.2571  decode.loss_mask: 1.0303  decode.loss_dice: 0.8059  decode.d0.loss_cls: 0.7652  decode.d0.loss_mask: 0.9595  decode.d0.loss_dice: 0.7601  decode.d1.loss_cls: 0.2708  decode.d1.loss_mask: 1.0115  decode.d1.loss_dice: 0.7998  decode.d2.loss_cls: 0.2920  decode.d2.loss_mask: 1.0058  decode.d2.loss_dice: 0.7853  decode.d3.loss_cls: 0.2812  decode.d3.loss_mask: 0.9663  decode.d3.loss_dice: 0.7850  decode.d4.loss_cls: 0.2901  decode.d4.loss_mask: 0.9767  decode.d4.loss_dice: 0.7789  decode.d5.loss_cls: 0.2667  decode.d5.loss_mask: 1.0160  decode.d5.loss_dice: 0.8238  decode.d6.loss_cls: 0.3541  decode.d6.loss_mask: 0.9529  decode.d6.loss_dice: 0.7738  decode.d7.loss_cls: 0.3241  decode.d7.loss_mask: 0.9594  decode.d7.loss_dice: 0.7581  decode.d8.loss_cls: 0.2726  decode.d8.loss_mask: 0.9858  decode.d8.loss_dice: 0.7808
05/26 13:39:24 - mmengine - INFO - Iter(train) [ 23400/160000]  base_lr: 8.6736e-05 lr: 8.6736e-06  eta: 15:34:45  time: 0.4104  data_time: 0.0090  memory: 5967  grad_norm: 1064.1796  loss: 24.6440  decode.loss_cls: 0.2554  decode.loss_mask: 1.2356  decode.loss_dice: 0.8947  decode.d0.loss_cls: 0.7122  decode.d0.loss_mask: 1.1812  decode.d0.loss_dice: 0.8833  decode.d1.loss_cls: 0.3017  decode.d1.loss_mask: 1.2121  decode.d1.loss_dice: 0.9160  decode.d2.loss_cls: 0.3235  decode.d2.loss_mask: 1.2000  decode.d2.loss_dice: 0.9061  decode.d3.loss_cls: 0.3754  decode.d3.loss_mask: 1.2182  decode.d3.loss_dice: 0.8765  decode.d4.loss_cls: 0.3499  decode.d4.loss_mask: 1.1988  decode.d4.loss_dice: 0.8766  decode.d5.loss_cls: 0.3208  decode.d5.loss_mask: 1.1650  decode.d5.loss_dice: 0.8867  decode.d6.loss_cls: 0.3244  decode.d6.loss_mask: 1.2019  decode.d6.loss_dice: 0.8759  decode.d7.loss_cls: 0.3496  decode.d7.loss_mask: 1.2509  decode.d7.loss_dice: 0.8689  decode.d8.loss_cls: 0.2772  decode.d8.loss_mask: 1.2822  decode.d8.loss_dice: 0.9232
05/26 13:39:45 - mmengine - INFO - Iter(train) [ 23450/160000]  base_lr: 8.6708e-05 lr: 8.6708e-06  eta: 15:34:29  time: 0.4114  data_time: 0.0090  memory: 5969  grad_norm: 721.6180  loss: 29.7373  decode.loss_cls: 0.3409  decode.loss_mask: 1.4377  decode.loss_dice: 1.1656  decode.d0.loss_cls: 0.8774  decode.d0.loss_mask: 1.3820  decode.d0.loss_dice: 1.0749  decode.d1.loss_cls: 0.3971  decode.d1.loss_mask: 1.3678  decode.d1.loss_dice: 1.0800  decode.d2.loss_cls: 0.3888  decode.d2.loss_mask: 1.3908  decode.d2.loss_dice: 1.1062  decode.d3.loss_cls: 0.4256  decode.d3.loss_mask: 1.4010  decode.d3.loss_dice: 1.0991  decode.d4.loss_cls: 0.3806  decode.d4.loss_mask: 1.4296  decode.d4.loss_dice: 1.1011  decode.d5.loss_cls: 0.4113  decode.d5.loss_mask: 1.4278  decode.d5.loss_dice: 1.1163  decode.d6.loss_cls: 0.5172  decode.d6.loss_mask: 1.4076  decode.d6.loss_dice: 1.1320  decode.d7.loss_cls: 0.4608  decode.d7.loss_mask: 1.4047  decode.d7.loss_dice: 1.0867  decode.d8.loss_cls: 0.3987  decode.d8.loss_mask: 1.4150  decode.d8.loss_dice: 1.1129
05/26 13:40:06 - mmengine - INFO - Iter(train) [ 23500/160000]  base_lr: 8.6679e-05 lr: 8.6679e-06  eta: 15:34:08  time: 0.4104  data_time: 0.0091  memory: 5965  grad_norm: 1008.7380  loss: 23.3993  decode.loss_cls: 0.3162  decode.loss_mask: 1.1538  decode.loss_dice: 0.8587  decode.d0.loss_cls: 0.7495  decode.d0.loss_mask: 1.1039  decode.d0.loss_dice: 0.8468  decode.d1.loss_cls: 0.3292  decode.d1.loss_mask: 1.1658  decode.d1.loss_dice: 0.8257  decode.d2.loss_cls: 0.3099  decode.d2.loss_mask: 1.1508  decode.d2.loss_dice: 0.8401  decode.d3.loss_cls: 0.2644  decode.d3.loss_mask: 1.1935  decode.d3.loss_dice: 0.8296  decode.d4.loss_cls: 0.3451  decode.d4.loss_mask: 1.1510  decode.d4.loss_dice: 0.8030  decode.d5.loss_cls: 0.3452  decode.d5.loss_mask: 1.1436  decode.d5.loss_dice: 0.8132  decode.d6.loss_cls: 0.3111  decode.d6.loss_mask: 1.1442  decode.d6.loss_dice: 0.8243  decode.d7.loss_cls: 0.3151  decode.d7.loss_mask: 1.1426  decode.d7.loss_dice: 0.8523  decode.d8.loss_cls: 0.3005  decode.d8.loss_mask: 1.1491  decode.d8.loss_dice: 0.8212
05/26 13:40:26 - mmengine - INFO - Iter(train) [ 23550/160000]  base_lr: 8.6650e-05 lr: 8.6650e-06  eta: 15:33:47  time: 0.4094  data_time: 0.0091  memory: 5974  grad_norm: 737.7126  loss: 25.7272  decode.loss_cls: 0.2982  decode.loss_mask: 1.2580  decode.loss_dice: 0.9748  decode.d0.loss_cls: 0.7550  decode.d0.loss_mask: 1.1027  decode.d0.loss_dice: 0.8980  decode.d1.loss_cls: 0.3354  decode.d1.loss_mask: 1.2726  decode.d1.loss_dice: 0.9819  decode.d2.loss_cls: 0.3607  decode.d2.loss_mask: 1.2270  decode.d2.loss_dice: 0.9752  decode.d3.loss_cls: 0.3314  decode.d3.loss_mask: 1.1999  decode.d3.loss_dice: 0.9581  decode.d4.loss_cls: 0.3543  decode.d4.loss_mask: 1.2121  decode.d4.loss_dice: 0.9802  decode.d5.loss_cls: 0.3761  decode.d5.loss_mask: 1.2311  decode.d5.loss_dice: 0.9631  decode.d6.loss_cls: 0.3403  decode.d6.loss_mask: 1.2653  decode.d6.loss_dice: 0.9720  decode.d7.loss_cls: 0.3942  decode.d7.loss_mask: 1.2343  decode.d7.loss_dice: 0.9734  decode.d8.loss_cls: 0.3349  decode.d8.loss_mask: 1.2091  decode.d8.loss_dice: 0.9578
05/26 13:40:47 - mmengine - INFO - Iter(train) [ 23600/160000]  base_lr: 8.6622e-05 lr: 8.6622e-06  eta: 15:33:27  time: 0.4091  data_time: 0.0090  memory: 5972  grad_norm: 836.0616  loss: 25.9592  decode.loss_cls: 0.4078  decode.loss_mask: 1.1994  decode.loss_dice: 0.9282  decode.d0.loss_cls: 0.7798  decode.d0.loss_mask: 1.1844  decode.d0.loss_dice: 0.8845  decode.d1.loss_cls: 0.3513  decode.d1.loss_mask: 1.2426  decode.d1.loss_dice: 0.9430  decode.d2.loss_cls: 0.3840  decode.d2.loss_mask: 1.2007  decode.d2.loss_dice: 0.9413  decode.d3.loss_cls: 0.4130  decode.d3.loss_mask: 1.2219  decode.d3.loss_dice: 0.9431  decode.d4.loss_cls: 0.3530  decode.d4.loss_mask: 1.2977  decode.d4.loss_dice: 0.9896  decode.d5.loss_cls: 0.3662  decode.d5.loss_mask: 1.2739  decode.d5.loss_dice: 0.9662  decode.d6.loss_cls: 0.4233  decode.d6.loss_mask: 1.2420  decode.d6.loss_dice: 0.9401  decode.d7.loss_cls: 0.4074  decode.d7.loss_mask: 1.2132  decode.d7.loss_dice: 0.9295  decode.d8.loss_cls: 0.4337  decode.d8.loss_mask: 1.1817  decode.d8.loss_dice: 0.9167
05/26 13:41:07 - mmengine - INFO - Iter(train) [ 23650/160000]  base_lr: 8.6593e-05 lr: 8.6593e-06  eta: 15:33:06  time: 0.4117  data_time: 0.0101  memory: 5976  grad_norm: 636.2697  loss: 28.2937  decode.loss_cls: 0.3903  decode.loss_mask: 1.4149  decode.loss_dice: 1.0050  decode.d0.loss_cls: 0.9012  decode.d0.loss_mask: 1.3286  decode.d0.loss_dice: 0.9639  decode.d1.loss_cls: 0.4913  decode.d1.loss_mask: 1.3217  decode.d1.loss_dice: 1.0510  decode.d2.loss_cls: 0.3766  decode.d2.loss_mask: 1.3889  decode.d2.loss_dice: 1.0145  decode.d3.loss_cls: 0.4147  decode.d3.loss_mask: 1.2905  decode.d3.loss_dice: 0.9776  decode.d4.loss_cls: 0.4244  decode.d4.loss_mask: 1.3296  decode.d4.loss_dice: 1.0058  decode.d5.loss_cls: 0.4296  decode.d5.loss_mask: 1.3799  decode.d5.loss_dice: 0.9804  decode.d6.loss_cls: 0.4728  decode.d6.loss_mask: 1.3201  decode.d6.loss_dice: 0.9830  decode.d7.loss_cls: 0.4440  decode.d7.loss_mask: 1.3821  decode.d7.loss_dice: 0.9884  decode.d8.loss_cls: 0.4322  decode.d8.loss_mask: 1.3915  decode.d8.loss_dice: 0.9992
05/26 13:41:28 - mmengine - INFO - Iter(train) [ 23700/160000]  base_lr: 8.6565e-05 lr: 8.6565e-06  eta: 15:32:45  time: 0.4098  data_time: 0.0091  memory: 5986  grad_norm: 680.2518  loss: 22.1241  decode.loss_cls: 0.2766  decode.loss_mask: 1.1241  decode.loss_dice: 0.7895  decode.d0.loss_cls: 0.6818  decode.d0.loss_mask: 1.1106  decode.d0.loss_dice: 0.7564  decode.d1.loss_cls: 0.2762  decode.d1.loss_mask: 1.0942  decode.d1.loss_dice: 0.7604  decode.d2.loss_cls: 0.2871  decode.d2.loss_mask: 1.1382  decode.d2.loss_dice: 0.7648  decode.d3.loss_cls: 0.2954  decode.d3.loss_mask: 1.0988  decode.d3.loss_dice: 0.7716  decode.d4.loss_cls: 0.3092  decode.d4.loss_mask: 1.1320  decode.d4.loss_dice: 0.7253  decode.d5.loss_cls: 0.2749  decode.d5.loss_mask: 1.1315  decode.d5.loss_dice: 0.7487  decode.d6.loss_cls: 0.2766  decode.d6.loss_mask: 1.1613  decode.d6.loss_dice: 0.7652  decode.d7.loss_cls: 0.2922  decode.d7.loss_mask: 1.1321  decode.d7.loss_dice: 0.7684  decode.d8.loss_cls: 0.2770  decode.d8.loss_mask: 1.1275  decode.d8.loss_dice: 0.7767
05/26 13:41:48 - mmengine - INFO - Iter(train) [ 23750/160000]  base_lr: 8.6536e-05 lr: 8.6536e-06  eta: 15:32:25  time: 0.4089  data_time: 0.0091  memory: 5975  grad_norm: 630.0886  loss: 26.3238  decode.loss_cls: 0.2695  decode.loss_mask: 1.3490  decode.loss_dice: 0.9517  decode.d0.loss_cls: 0.6674  decode.d0.loss_mask: 1.3147  decode.d0.loss_dice: 0.9158  decode.d1.loss_cls: 0.2868  decode.d1.loss_mask: 1.3174  decode.d1.loss_dice: 0.9503  decode.d2.loss_cls: 0.2999  decode.d2.loss_mask: 1.3895  decode.d2.loss_dice: 0.9634  decode.d3.loss_cls: 0.2726  decode.d3.loss_mask: 1.3645  decode.d3.loss_dice: 0.9410  decode.d4.loss_cls: 0.3487  decode.d4.loss_mask: 1.3475  decode.d4.loss_dice: 0.9243  decode.d5.loss_cls: 0.3238  decode.d5.loss_mask: 1.3851  decode.d5.loss_dice: 0.9705  decode.d6.loss_cls: 0.3055  decode.d6.loss_mask: 1.3871  decode.d6.loss_dice: 0.9432  decode.d7.loss_cls: 0.2479  decode.d7.loss_mask: 1.3972  decode.d7.loss_dice: 0.9491  decode.d8.loss_cls: 0.2647  decode.d8.loss_mask: 1.3328  decode.d8.loss_dice: 0.9430
05/26 13:42:09 - mmengine - INFO - Iter(train) [ 23800/160000]  base_lr: 8.6508e-05 lr: 8.6508e-06  eta: 15:32:04  time: 0.4076  data_time: 0.0089  memory: 5976  grad_norm: 1008.5064  loss: 33.4861  decode.loss_cls: 0.5874  decode.loss_mask: 1.5195  decode.loss_dice: 1.2059  decode.d0.loss_cls: 0.9204  decode.d0.loss_mask: 1.4798  decode.d0.loss_dice: 1.1402  decode.d1.loss_cls: 0.6303  decode.d1.loss_mask: 1.4549  decode.d1.loss_dice: 1.1404  decode.d2.loss_cls: 0.5724  decode.d2.loss_mask: 1.5688  decode.d2.loss_dice: 1.1518  decode.d3.loss_cls: 0.5942  decode.d3.loss_mask: 1.5081  decode.d3.loss_dice: 1.1614  decode.d4.loss_cls: 0.5823  decode.d4.loss_mask: 1.5753  decode.d4.loss_dice: 1.1829  decode.d5.loss_cls: 0.6321  decode.d5.loss_mask: 1.5113  decode.d5.loss_dice: 1.2169  decode.d6.loss_cls: 0.5821  decode.d6.loss_mask: 1.5839  decode.d6.loss_dice: 1.3028  decode.d7.loss_cls: 0.6434  decode.d7.loss_mask: 1.5169  decode.d7.loss_dice: 1.1954  decode.d8.loss_cls: 0.6210  decode.d8.loss_mask: 1.5190  decode.d8.loss_dice: 1.1856
05/26 13:42:29 - mmengine - INFO - Iter(train) [ 23850/160000]  base_lr: 8.6479e-05 lr: 8.6479e-06  eta: 15:31:43  time: 0.4097  data_time: 0.0090  memory: 5971  grad_norm: 636.9540  loss: 28.4621  decode.loss_cls: 0.3166  decode.loss_mask: 1.3457  decode.loss_dice: 1.0267  decode.d0.loss_cls: 0.8024  decode.d0.loss_mask: 1.3770  decode.d0.loss_dice: 1.0511  decode.d1.loss_cls: 0.3283  decode.d1.loss_mask: 1.4051  decode.d1.loss_dice: 1.0812  decode.d2.loss_cls: 0.2981  decode.d2.loss_mask: 1.4443  decode.d2.loss_dice: 1.0774  decode.d3.loss_cls: 0.3042  decode.d3.loss_mask: 1.4155  decode.d3.loss_dice: 1.0410  decode.d4.loss_cls: 0.3900  decode.d4.loss_mask: 1.3499  decode.d4.loss_dice: 1.0251  decode.d5.loss_cls: 0.3300  decode.d5.loss_mask: 1.4775  decode.d5.loss_dice: 1.0531  decode.d6.loss_cls: 0.3335  decode.d6.loss_mask: 1.4732  decode.d6.loss_dice: 1.0333  decode.d7.loss_cls: 0.4027  decode.d7.loss_mask: 1.3769  decode.d7.loss_dice: 1.0545  decode.d8.loss_cls: 0.3691  decode.d8.loss_mask: 1.3935  decode.d8.loss_dice: 1.0852
05/26 13:42:50 - mmengine - INFO - Iter(train) [ 23900/160000]  base_lr: 8.6450e-05 lr: 8.6450e-06  eta: 15:31:22  time: 0.4104  data_time: 0.0090  memory: 5965  grad_norm: 766.8677  loss: 28.0916  decode.loss_cls: 0.3389  decode.loss_mask: 1.3821  decode.loss_dice: 1.0477  decode.d0.loss_cls: 0.7879  decode.d0.loss_mask: 1.3784  decode.d0.loss_dice: 1.0441  decode.d1.loss_cls: 0.3957  decode.d1.loss_mask: 1.3496  decode.d1.loss_dice: 1.0340  decode.d2.loss_cls: 0.3088  decode.d2.loss_mask: 1.4045  decode.d2.loss_dice: 1.0691  decode.d3.loss_cls: 0.3576  decode.d3.loss_mask: 1.3328  decode.d3.loss_dice: 1.0771  decode.d4.loss_cls: 0.3988  decode.d4.loss_mask: 1.3021  decode.d4.loss_dice: 1.0028  decode.d5.loss_cls: 0.3723  decode.d5.loss_mask: 1.3549  decode.d5.loss_dice: 1.0674  decode.d6.loss_cls: 0.3548  decode.d6.loss_mask: 1.3527  decode.d6.loss_dice: 1.0747  decode.d7.loss_cls: 0.3495  decode.d7.loss_mask: 1.3520  decode.d7.loss_dice: 1.0248  decode.d8.loss_cls: 0.2997  decode.d8.loss_mask: 1.3752  decode.d8.loss_dice: 1.1015
05/26 13:43:10 - mmengine - INFO - Iter(train) [ 23950/160000]  base_lr: 8.6422e-05 lr: 8.6422e-06  eta: 15:31:01  time: 0.4081  data_time: 0.0091  memory: 5968  grad_norm: 1151.0246  loss: 18.0931  decode.loss_cls: 0.3079  decode.loss_mask: 0.8254  decode.loss_dice: 0.6273  decode.d0.loss_cls: 0.6887  decode.d0.loss_mask: 0.8413  decode.d0.loss_dice: 0.6344  decode.d1.loss_cls: 0.3228  decode.d1.loss_mask: 0.8393  decode.d1.loss_dice: 0.6257  decode.d2.loss_cls: 0.3000  decode.d2.loss_mask: 0.8436  decode.d2.loss_dice: 0.6313  decode.d3.loss_cls: 0.3076  decode.d3.loss_mask: 0.8281  decode.d3.loss_dice: 0.6279  decode.d4.loss_cls: 0.3023  decode.d4.loss_mask: 0.8338  decode.d4.loss_dice: 0.6240  decode.d5.loss_cls: 0.2952  decode.d5.loss_mask: 0.8306  decode.d5.loss_dice: 0.6183  decode.d6.loss_cls: 0.3600  decode.d6.loss_mask: 0.8252  decode.d6.loss_dice: 0.6198  decode.d7.loss_cls: 0.3301  decode.d7.loss_mask: 0.8124  decode.d7.loss_dice: 0.5983  decode.d8.loss_cls: 0.3640  decode.d8.loss_mask: 0.8241  decode.d8.loss_dice: 0.6036
05/26 13:43:31 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 13:43:31 - mmengine - INFO - Iter(train) [ 24000/160000]  base_lr: 8.6393e-05 lr: 8.6393e-06  eta: 15:30:40  time: 0.4091  data_time: 0.0090  memory: 5970  grad_norm: 954.1088  loss: 25.7351  decode.loss_cls: 0.2566  decode.loss_mask: 1.3086  decode.loss_dice: 0.9537  decode.d0.loss_cls: 0.7808  decode.d0.loss_mask: 1.1903  decode.d0.loss_dice: 0.8998  decode.d1.loss_cls: 0.3055  decode.d1.loss_mask: 1.3779  decode.d1.loss_dice: 0.9460  decode.d2.loss_cls: 0.3550  decode.d2.loss_mask: 1.2115  decode.d2.loss_dice: 0.9016  decode.d3.loss_cls: 0.3296  decode.d3.loss_mask: 1.2850  decode.d3.loss_dice: 0.9345  decode.d4.loss_cls: 0.3245  decode.d4.loss_mask: 1.2654  decode.d4.loss_dice: 0.9318  decode.d5.loss_cls: 0.3001  decode.d5.loss_mask: 1.2564  decode.d5.loss_dice: 0.9250  decode.d6.loss_cls: 0.2924  decode.d6.loss_mask: 1.2688  decode.d6.loss_dice: 0.9220  decode.d7.loss_cls: 0.3242  decode.d7.loss_mask: 1.3125  decode.d7.loss_dice: 0.9601  decode.d8.loss_cls: 0.3024  decode.d8.loss_mask: 1.3159  decode.d8.loss_dice: 0.9970
05/26 13:43:51 - mmengine - INFO - Iter(train) [ 24050/160000]  base_lr: 8.6365e-05 lr: 8.6365e-06  eta: 15:30:20  time: 0.4096  data_time: 0.0090  memory: 5985  grad_norm: 902.0360  loss: 30.1594  decode.loss_cls: 0.3772  decode.loss_mask: 1.4908  decode.loss_dice: 1.0794  decode.d0.loss_cls: 0.9894  decode.d0.loss_mask: 1.3805  decode.d0.loss_dice: 1.0078  decode.d1.loss_cls: 0.3933  decode.d1.loss_mask: 1.5283  decode.d1.loss_dice: 1.0648  decode.d2.loss_cls: 0.3719  decode.d2.loss_mask: 1.5592  decode.d2.loss_dice: 1.0871  decode.d3.loss_cls: 0.4312  decode.d3.loss_mask: 1.5144  decode.d3.loss_dice: 1.0716  decode.d4.loss_cls: 0.4429  decode.d4.loss_mask: 1.4892  decode.d4.loss_dice: 1.0220  decode.d5.loss_cls: 0.4069  decode.d5.loss_mask: 1.5283  decode.d5.loss_dice: 1.0709  decode.d6.loss_cls: 0.4287  decode.d6.loss_mask: 1.5182  decode.d6.loss_dice: 1.0997  decode.d7.loss_cls: 0.4574  decode.d7.loss_mask: 1.4217  decode.d7.loss_dice: 1.0474  decode.d8.loss_cls: 0.4277  decode.d8.loss_mask: 1.4212  decode.d8.loss_dice: 1.0302
05/26 13:44:12 - mmengine - INFO - Iter(train) [ 24100/160000]  base_lr: 8.6336e-05 lr: 8.6336e-06  eta: 15:30:00  time: 0.4089  data_time: 0.0089  memory: 5969  grad_norm: 448.7682  loss: 21.8655  decode.loss_cls: 0.2933  decode.loss_mask: 1.0179  decode.loss_dice: 0.8285  decode.d0.loss_cls: 0.7323  decode.d0.loss_mask: 0.9267  decode.d0.loss_dice: 0.8125  decode.d1.loss_cls: 0.3470  decode.d1.loss_mask: 0.9840  decode.d1.loss_dice: 0.8196  decode.d2.loss_cls: 0.3416  decode.d2.loss_mask: 0.9707  decode.d2.loss_dice: 0.8279  decode.d3.loss_cls: 0.3341  decode.d3.loss_mask: 0.9764  decode.d3.loss_dice: 0.8148  decode.d4.loss_cls: 0.3529  decode.d4.loss_mask: 0.9944  decode.d4.loss_dice: 0.8057  decode.d5.loss_cls: 0.4099  decode.d5.loss_mask: 0.9727  decode.d5.loss_dice: 0.8467  decode.d6.loss_cls: 0.3715  decode.d6.loss_mask: 0.9657  decode.d6.loss_dice: 0.8357  decode.d7.loss_cls: 0.3406  decode.d7.loss_mask: 0.9678  decode.d7.loss_dice: 0.8221  decode.d8.loss_cls: 0.2990  decode.d8.loss_mask: 1.0173  decode.d8.loss_dice: 0.8361
05/26 13:44:32 - mmengine - INFO - Iter(train) [ 24150/160000]  base_lr: 8.6307e-05 lr: 8.6307e-06  eta: 15:29:39  time: 0.4108  data_time: 0.0090  memory: 5969  grad_norm: 875.5703  loss: 28.4051  decode.loss_cls: 0.4731  decode.loss_mask: 1.3675  decode.loss_dice: 0.9202  decode.d0.loss_cls: 0.8848  decode.d0.loss_mask: 1.3228  decode.d0.loss_dice: 0.9593  decode.d1.loss_cls: 0.4517  decode.d1.loss_mask: 1.3840  decode.d1.loss_dice: 0.9691  decode.d2.loss_cls: 0.5207  decode.d2.loss_mask: 1.3342  decode.d2.loss_dice: 0.9705  decode.d3.loss_cls: 0.4279  decode.d3.loss_mask: 1.3589  decode.d3.loss_dice: 0.9887  decode.d4.loss_cls: 0.4962  decode.d4.loss_mask: 1.4234  decode.d4.loss_dice: 0.9866  decode.d5.loss_cls: 0.4430  decode.d5.loss_mask: 1.4408  decode.d5.loss_dice: 0.9583  decode.d6.loss_cls: 0.5278  decode.d6.loss_mask: 1.3091  decode.d6.loss_dice: 0.9648  decode.d7.loss_cls: 0.5277  decode.d7.loss_mask: 1.3164  decode.d7.loss_dice: 0.9281  decode.d8.loss_cls: 0.4831  decode.d8.loss_mask: 1.3342  decode.d8.loss_dice: 0.9322
05/26 13:44:53 - mmengine - INFO - Iter(train) [ 24200/160000]  base_lr: 8.6279e-05 lr: 8.6279e-06  eta: 15:29:18  time: 0.4119  data_time: 0.0092  memory: 5975  grad_norm: 1150.5779  loss: 30.6538  decode.loss_cls: 0.3716  decode.loss_mask: 1.6209  decode.loss_dice: 1.1124  decode.d0.loss_cls: 0.8327  decode.d0.loss_mask: 1.4965  decode.d0.loss_dice: 1.0817  decode.d1.loss_cls: 0.3537  decode.d1.loss_mask: 1.5371  decode.d1.loss_dice: 1.0472  decode.d2.loss_cls: 0.3029  decode.d2.loss_mask: 1.5534  decode.d2.loss_dice: 1.0709  decode.d3.loss_cls: 0.3779  decode.d3.loss_mask: 1.5213  decode.d3.loss_dice: 1.0785  decode.d4.loss_cls: 0.3767  decode.d4.loss_mask: 1.5701  decode.d4.loss_dice: 1.1019  decode.d5.loss_cls: 0.3668  decode.d5.loss_mask: 1.5794  decode.d5.loss_dice: 1.1075  decode.d6.loss_cls: 0.3544  decode.d6.loss_mask: 1.6441  decode.d6.loss_dice: 1.1125  decode.d7.loss_cls: 0.3766  decode.d7.loss_mask: 1.6079  decode.d7.loss_dice: 1.1042  decode.d8.loss_cls: 0.3618  decode.d8.loss_mask: 1.5488  decode.d8.loss_dice: 1.0823
05/26 13:45:13 - mmengine - INFO - Iter(train) [ 24250/160000]  base_lr: 8.6250e-05 lr: 8.6250e-06  eta: 15:28:59  time: 0.4163  data_time: 0.0093  memory: 5988  grad_norm: 442.0397  loss: 24.3815  decode.loss_cls: 0.3015  decode.loss_mask: 1.1758  decode.loss_dice: 0.8736  decode.d0.loss_cls: 0.7560  decode.d0.loss_mask: 1.1156  decode.d0.loss_dice: 0.8377  decode.d1.loss_cls: 0.3591  decode.d1.loss_mask: 1.1746  decode.d1.loss_dice: 0.8671  decode.d2.loss_cls: 0.3838  decode.d2.loss_mask: 1.1703  decode.d2.loss_dice: 0.8768  decode.d3.loss_cls: 0.3700  decode.d3.loss_mask: 1.1685  decode.d3.loss_dice: 0.8559  decode.d4.loss_cls: 0.4246  decode.d4.loss_mask: 1.1874  decode.d4.loss_dice: 0.8363  decode.d5.loss_cls: 0.3778  decode.d5.loss_mask: 1.1701  decode.d5.loss_dice: 0.8313  decode.d6.loss_cls: 0.4341  decode.d6.loss_mask: 1.1548  decode.d6.loss_dice: 0.8475  decode.d7.loss_cls: 0.3470  decode.d7.loss_mask: 1.1871  decode.d7.loss_dice: 0.8711  decode.d8.loss_cls: 0.3929  decode.d8.loss_mask: 1.1739  decode.d8.loss_dice: 0.8595
05/26 13:45:34 - mmengine - INFO - Iter(train) [ 24300/160000]  base_lr: 8.6222e-05 lr: 8.6222e-06  eta: 15:28:40  time: 0.4174  data_time: 0.0094  memory: 5966  grad_norm: 786.7820  loss: 28.2855  decode.loss_cls: 0.3947  decode.loss_mask: 1.4822  decode.loss_dice: 0.9820  decode.d0.loss_cls: 0.9383  decode.d0.loss_mask: 1.3371  decode.d0.loss_dice: 0.8769  decode.d1.loss_cls: 0.4036  decode.d1.loss_mask: 1.4142  decode.d1.loss_dice: 0.9534  decode.d2.loss_cls: 0.4548  decode.d2.loss_mask: 1.3564  decode.d2.loss_dice: 0.9015  decode.d3.loss_cls: 0.4815  decode.d3.loss_mask: 1.3553  decode.d3.loss_dice: 0.8947  decode.d4.loss_cls: 0.4762  decode.d4.loss_mask: 1.3934  decode.d4.loss_dice: 0.9288  decode.d5.loss_cls: 0.4548  decode.d5.loss_mask: 1.4578  decode.d5.loss_dice: 0.9451  decode.d6.loss_cls: 0.4106  decode.d6.loss_mask: 1.4754  decode.d6.loss_dice: 0.9874  decode.d7.loss_cls: 0.4134  decode.d7.loss_mask: 1.4343  decode.d7.loss_dice: 0.9734  decode.d8.loss_cls: 0.3826  decode.d8.loss_mask: 1.3870  decode.d8.loss_dice: 0.9385
05/26 13:45:55 - mmengine - INFO - Iter(train) [ 24350/160000]  base_lr: 8.6193e-05 lr: 8.6193e-06  eta: 15:28:19  time: 0.4095  data_time: 0.0090  memory: 5968  grad_norm: 530.5634  loss: 25.3351  decode.loss_cls: 0.3124  decode.loss_mask: 1.2494  decode.loss_dice: 0.9796  decode.d0.loss_cls: 0.8251  decode.d0.loss_mask: 1.2418  decode.d0.loss_dice: 0.9185  decode.d1.loss_cls: 0.3394  decode.d1.loss_mask: 1.2470  decode.d1.loss_dice: 0.9450  decode.d2.loss_cls: 0.3941  decode.d2.loss_mask: 1.1793  decode.d2.loss_dice: 0.9108  decode.d3.loss_cls: 0.3177  decode.d3.loss_mask: 1.1834  decode.d3.loss_dice: 0.8992  decode.d4.loss_cls: 0.3956  decode.d4.loss_mask: 1.1909  decode.d4.loss_dice: 0.9281  decode.d5.loss_cls: 0.3294  decode.d5.loss_mask: 1.1958  decode.d5.loss_dice: 0.8978  decode.d6.loss_cls: 0.3066  decode.d6.loss_mask: 1.2578  decode.d6.loss_dice: 0.9196  decode.d7.loss_cls: 0.2924  decode.d7.loss_mask: 1.2048  decode.d7.loss_dice: 0.9062  decode.d8.loss_cls: 0.3099  decode.d8.loss_mask: 1.2737  decode.d8.loss_dice: 0.9837
05/26 13:46:15 - mmengine - INFO - Iter(train) [ 24400/160000]  base_lr: 8.6164e-05 lr: 8.6164e-06  eta: 15:27:58  time: 0.4087  data_time: 0.0089  memory: 5966  grad_norm: 806.2806  loss: 21.9494  decode.loss_cls: 0.4108  decode.loss_mask: 0.9747  decode.loss_dice: 0.8042  decode.d0.loss_cls: 0.7566  decode.d0.loss_mask: 0.8586  decode.d0.loss_dice: 0.7959  decode.d1.loss_cls: 0.4389  decode.d1.loss_mask: 0.9413  decode.d1.loss_dice: 0.7821  decode.d2.loss_cls: 0.3804  decode.d2.loss_mask: 0.9636  decode.d2.loss_dice: 0.7879  decode.d3.loss_cls: 0.4335  decode.d3.loss_mask: 0.9392  decode.d3.loss_dice: 0.8123  decode.d4.loss_cls: 0.4390  decode.d4.loss_mask: 0.9432  decode.d4.loss_dice: 0.8137  decode.d5.loss_cls: 0.4332  decode.d5.loss_mask: 0.9156  decode.d5.loss_dice: 0.7534  decode.d6.loss_cls: 0.4559  decode.d6.loss_mask: 0.9230  decode.d6.loss_dice: 0.7743  decode.d7.loss_cls: 0.4522  decode.d7.loss_mask: 0.9956  decode.d7.loss_dice: 0.8056  decode.d8.loss_cls: 0.4680  decode.d8.loss_mask: 0.9397  decode.d8.loss_dice: 0.7569
05/26 13:46:36 - mmengine - INFO - Iter(train) [ 24450/160000]  base_lr: 8.6136e-05 lr: 8.6136e-06  eta: 15:27:38  time: 0.4160  data_time: 0.0094  memory: 5966  grad_norm: 844.9880  loss: 31.0972  decode.loss_cls: 0.3629  decode.loss_mask: 1.5741  decode.loss_dice: 1.0640  decode.d0.loss_cls: 0.9513  decode.d0.loss_mask: 1.4694  decode.d0.loss_dice: 1.0309  decode.d1.loss_cls: 0.4704  decode.d1.loss_mask: 1.4787  decode.d1.loss_dice: 1.0665  decode.d2.loss_cls: 0.3524  decode.d2.loss_mask: 1.5513  decode.d2.loss_dice: 1.0551  decode.d3.loss_cls: 0.3775  decode.d3.loss_mask: 1.5882  decode.d3.loss_dice: 1.0510  decode.d4.loss_cls: 0.4316  decode.d4.loss_mask: 1.6165  decode.d4.loss_dice: 1.0577  decode.d5.loss_cls: 0.4583  decode.d5.loss_mask: 1.5946  decode.d5.loss_dice: 1.0651  decode.d6.loss_cls: 0.4546  decode.d6.loss_mask: 1.5782  decode.d6.loss_dice: 1.1071  decode.d7.loss_cls: 0.4290  decode.d7.loss_mask: 1.6476  decode.d7.loss_dice: 1.1202  decode.d8.loss_cls: 0.4164  decode.d8.loss_mask: 1.5805  decode.d8.loss_dice: 1.0961
05/26 13:46:56 - mmengine - INFO - Iter(train) [ 24500/160000]  base_lr: 8.6107e-05 lr: 8.6107e-06  eta: 15:27:18  time: 0.4150  data_time: 0.0092  memory: 5976  grad_norm: 873.5577  loss: 23.6726  decode.loss_cls: 0.2798  decode.loss_mask: 1.2082  decode.loss_dice: 0.8754  decode.d0.loss_cls: 0.7906  decode.d0.loss_mask: 1.0964  decode.d0.loss_dice: 0.8363  decode.d1.loss_cls: 0.3420  decode.d1.loss_mask: 1.0867  decode.d1.loss_dice: 0.8500  decode.d2.loss_cls: 0.3381  decode.d2.loss_mask: 1.1395  decode.d2.loss_dice: 0.8513  decode.d3.loss_cls: 0.2918  decode.d3.loss_mask: 1.1580  decode.d3.loss_dice: 0.8677  decode.d4.loss_cls: 0.3311  decode.d4.loss_mask: 1.1500  decode.d4.loss_dice: 0.9123  decode.d5.loss_cls: 0.3027  decode.d5.loss_mask: 1.1091  decode.d5.loss_dice: 0.8808  decode.d6.loss_cls: 0.3653  decode.d6.loss_mask: 1.0898  decode.d6.loss_dice: 0.8650  decode.d7.loss_cls: 0.3127  decode.d7.loss_mask: 1.1623  decode.d7.loss_dice: 0.8646  decode.d8.loss_cls: 0.3208  decode.d8.loss_mask: 1.1461  decode.d8.loss_dice: 0.8481
05/26 13:47:17 - mmengine - INFO - Iter(train) [ 24550/160000]  base_lr: 8.6079e-05 lr: 8.6079e-06  eta: 15:27:00  time: 0.4104  data_time: 0.0091  memory: 5968  grad_norm: 612.9276  loss: 23.8349  decode.loss_cls: 0.2161  decode.loss_mask: 1.2002  decode.loss_dice: 0.8762  decode.d0.loss_cls: 0.7980  decode.d0.loss_mask: 1.1323  decode.d0.loss_dice: 0.8353  decode.d1.loss_cls: 0.2613  decode.d1.loss_mask: 1.1663  decode.d1.loss_dice: 0.8493  decode.d2.loss_cls: 0.2588  decode.d2.loss_mask: 1.2153  decode.d2.loss_dice: 0.8640  decode.d3.loss_cls: 0.2336  decode.d3.loss_mask: 1.1880  decode.d3.loss_dice: 0.8582  decode.d4.loss_cls: 0.2902  decode.d4.loss_mask: 1.1851  decode.d4.loss_dice: 0.8851  decode.d5.loss_cls: 0.2938  decode.d5.loss_mask: 1.2176  decode.d5.loss_dice: 0.8623  decode.d6.loss_cls: 0.2760  decode.d6.loss_mask: 1.2346  decode.d6.loss_dice: 0.8982  decode.d7.loss_cls: 0.2127  decode.d7.loss_mask: 1.3072  decode.d7.loss_dice: 0.8823  decode.d8.loss_cls: 0.2575  decode.d8.loss_mask: 1.2193  decode.d8.loss_dice: 0.8599
05/26 13:47:38 - mmengine - INFO - Iter(train) [ 24600/160000]  base_lr: 8.6050e-05 lr: 8.6050e-06  eta: 15:26:38  time: 0.4088  data_time: 0.0090  memory: 5971  grad_norm: 833.6114  loss: 31.9613  decode.loss_cls: 0.4808  decode.loss_mask: 1.5472  decode.loss_dice: 1.1016  decode.d0.loss_cls: 1.1111  decode.d0.loss_mask: 1.4621  decode.d0.loss_dice: 1.1285  decode.d1.loss_cls: 0.4957  decode.d1.loss_mask: 1.5305  decode.d1.loss_dice: 1.1392  decode.d2.loss_cls: 0.5241  decode.d2.loss_mask: 1.5132  decode.d2.loss_dice: 1.1201  decode.d3.loss_cls: 0.4436  decode.d3.loss_mask: 1.5502  decode.d3.loss_dice: 1.1389  decode.d4.loss_cls: 0.5543  decode.d4.loss_mask: 1.5391  decode.d4.loss_dice: 1.1055  decode.d5.loss_cls: 0.4805  decode.d5.loss_mask: 1.5164  decode.d5.loss_dice: 1.1243  decode.d6.loss_cls: 0.4502  decode.d6.loss_mask: 1.5413  decode.d6.loss_dice: 1.1515  decode.d7.loss_cls: 0.4822  decode.d7.loss_mask: 1.4789  decode.d7.loss_dice: 1.0872  decode.d8.loss_cls: 0.4785  decode.d8.loss_mask: 1.5632  decode.d8.loss_dice: 1.1212
05/26 13:47:58 - mmengine - INFO - Iter(train) [ 24650/160000]  base_lr: 8.6021e-05 lr: 8.6021e-06  eta: 15:26:17  time: 0.4075  data_time: 0.0089  memory: 5968  grad_norm: 843.5603  loss: 23.8227  decode.loss_cls: 0.3811  decode.loss_mask: 1.1318  decode.loss_dice: 0.8095  decode.d0.loss_cls: 0.8366  decode.d0.loss_mask: 1.0053  decode.d0.loss_dice: 0.7355  decode.d1.loss_cls: 0.4425  decode.d1.loss_mask: 1.2228  decode.d1.loss_dice: 0.8310  decode.d2.loss_cls: 0.4596  decode.d2.loss_mask: 1.1113  decode.d2.loss_dice: 0.8162  decode.d3.loss_cls: 0.4208  decode.d3.loss_mask: 1.0978  decode.d3.loss_dice: 0.7888  decode.d4.loss_cls: 0.4554  decode.d4.loss_mask: 1.1253  decode.d4.loss_dice: 0.7598  decode.d5.loss_cls: 0.4189  decode.d5.loss_mask: 1.1590  decode.d5.loss_dice: 0.8192  decode.d6.loss_cls: 0.4030  decode.d6.loss_mask: 1.1374  decode.d6.loss_dice: 0.8043  decode.d7.loss_cls: 0.4538  decode.d7.loss_mask: 1.1030  decode.d7.loss_dice: 0.7844  decode.d8.loss_cls: 0.4331  decode.d8.loss_mask: 1.0756  decode.d8.loss_dice: 0.7999
05/26 13:48:18 - mmengine - INFO - Iter(train) [ 24700/160000]  base_lr: 8.5993e-05 lr: 8.5993e-06  eta: 15:25:56  time: 0.4068  data_time: 0.0088  memory: 5965  grad_norm: 1014.4001  loss: 26.3649  decode.loss_cls: 0.3097  decode.loss_mask: 1.2959  decode.loss_dice: 0.8917  decode.d0.loss_cls: 0.8195  decode.d0.loss_mask: 1.2076  decode.d0.loss_dice: 0.8757  decode.d1.loss_cls: 0.3219  decode.d1.loss_mask: 1.3334  decode.d1.loss_dice: 0.9944  decode.d2.loss_cls: 0.3263  decode.d2.loss_mask: 1.3833  decode.d2.loss_dice: 1.0045  decode.d3.loss_cls: 0.3291  decode.d3.loss_mask: 1.3268  decode.d3.loss_dice: 0.9446  decode.d4.loss_cls: 0.3354  decode.d4.loss_mask: 1.3246  decode.d4.loss_dice: 0.9348  decode.d5.loss_cls: 0.3648  decode.d5.loss_mask: 1.3200  decode.d5.loss_dice: 0.9561  decode.d6.loss_cls: 0.2987  decode.d6.loss_mask: 1.3927  decode.d6.loss_dice: 0.9256  decode.d7.loss_cls: 0.3049  decode.d7.loss_mask: 1.3290  decode.d7.loss_dice: 0.9169  decode.d8.loss_cls: 0.3432  decode.d8.loss_mask: 1.3399  decode.d8.loss_dice: 0.9138
05/26 13:48:39 - mmengine - INFO - Iter(train) [ 24750/160000]  base_lr: 8.5964e-05 lr: 8.5964e-06  eta: 15:25:34  time: 0.4069  data_time: 0.0090  memory: 5986  grad_norm: 560.1073  loss: 23.3050  decode.loss_cls: 0.1968  decode.loss_mask: 1.1636  decode.loss_dice: 0.9126  decode.d0.loss_cls: 0.7042  decode.d0.loss_mask: 1.1357  decode.d0.loss_dice: 0.8816  decode.d1.loss_cls: 0.2668  decode.d1.loss_mask: 1.1481  decode.d1.loss_dice: 0.8813  decode.d2.loss_cls: 0.2857  decode.d2.loss_mask: 1.1298  decode.d2.loss_dice: 0.8708  decode.d3.loss_cls: 0.2435  decode.d3.loss_mask: 1.1300  decode.d3.loss_dice: 0.8721  decode.d4.loss_cls: 0.2575  decode.d4.loss_mask: 1.1421  decode.d4.loss_dice: 0.9075  decode.d5.loss_cls: 0.2489  decode.d5.loss_mask: 1.1461  decode.d5.loss_dice: 0.8860  decode.d6.loss_cls: 0.2423  decode.d6.loss_mask: 1.1673  decode.d6.loss_dice: 0.9224  decode.d7.loss_cls: 0.3011  decode.d7.loss_mask: 1.1311  decode.d7.loss_dice: 0.8850  decode.d8.loss_cls: 0.2186  decode.d8.loss_mask: 1.1305  decode.d8.loss_dice: 0.8959
05/26 13:48:59 - mmengine - INFO - Iter(train) [ 24800/160000]  base_lr: 8.5936e-05 lr: 8.5936e-06  eta: 15:25:13  time: 0.4078  data_time: 0.0091  memory: 5971  grad_norm: 641.0413  loss: 26.5297  decode.loss_cls: 0.3121  decode.loss_mask: 1.4259  decode.loss_dice: 0.9538  decode.d0.loss_cls: 0.8095  decode.d0.loss_mask: 1.2724  decode.d0.loss_dice: 0.9660  decode.d1.loss_cls: 0.3299  decode.d1.loss_mask: 1.3459  decode.d1.loss_dice: 0.9347  decode.d2.loss_cls: 0.3529  decode.d2.loss_mask: 1.2909  decode.d2.loss_dice: 0.9292  decode.d3.loss_cls: 0.3310  decode.d3.loss_mask: 1.3305  decode.d3.loss_dice: 0.9140  decode.d4.loss_cls: 0.3421  decode.d4.loss_mask: 1.2690  decode.d4.loss_dice: 0.9325  decode.d5.loss_cls: 0.3507  decode.d5.loss_mask: 1.3414  decode.d5.loss_dice: 0.9524  decode.d6.loss_cls: 0.3516  decode.d6.loss_mask: 1.3378  decode.d6.loss_dice: 0.9762  decode.d7.loss_cls: 0.3580  decode.d7.loss_mask: 1.3147  decode.d7.loss_dice: 0.9370  decode.d8.loss_cls: 0.3287  decode.d8.loss_mask: 1.3369  decode.d8.loss_dice: 0.9019
05/26 13:49:20 - mmengine - INFO - Iter(train) [ 24850/160000]  base_lr: 8.5907e-05 lr: 8.5907e-06  eta: 15:24:51  time: 0.4073  data_time: 0.0088  memory: 5991  grad_norm: 907.9099  loss: 26.0039  decode.loss_cls: 0.3168  decode.loss_mask: 1.3576  decode.loss_dice: 0.9061  decode.d0.loss_cls: 0.8562  decode.d0.loss_mask: 1.2453  decode.d0.loss_dice: 0.8582  decode.d1.loss_cls: 0.3634  decode.d1.loss_mask: 1.2932  decode.d1.loss_dice: 0.9103  decode.d2.loss_cls: 0.3895  decode.d2.loss_mask: 1.2449  decode.d2.loss_dice: 0.8507  decode.d3.loss_cls: 0.4069  decode.d3.loss_mask: 1.2969  decode.d3.loss_dice: 0.8692  decode.d4.loss_cls: 0.3850  decode.d4.loss_mask: 1.3297  decode.d4.loss_dice: 0.8936  decode.d5.loss_cls: 0.4087  decode.d5.loss_mask: 1.3285  decode.d5.loss_dice: 0.8756  decode.d6.loss_cls: 0.3612  decode.d6.loss_mask: 1.3286  decode.d6.loss_dice: 0.8600  decode.d7.loss_cls: 0.3635  decode.d7.loss_mask: 1.2907  decode.d7.loss_dice: 0.8588  decode.d8.loss_cls: 0.3409  decode.d8.loss_mask: 1.3126  decode.d8.loss_dice: 0.9011
05/26 13:49:40 - mmengine - INFO - Iter(train) [ 24900/160000]  base_lr: 8.5878e-05 lr: 8.5878e-06  eta: 15:24:30  time: 0.4097  data_time: 0.0090  memory: 5969  grad_norm: 466.6356  loss: 26.7219  decode.loss_cls: 0.2880  decode.loss_mask: 1.3433  decode.loss_dice: 0.9431  decode.d0.loss_cls: 0.7944  decode.d0.loss_mask: 1.2877  decode.d0.loss_dice: 0.9800  decode.d1.loss_cls: 0.3377  decode.d1.loss_mask: 1.3732  decode.d1.loss_dice: 0.9981  decode.d2.loss_cls: 0.3119  decode.d2.loss_mask: 1.3469  decode.d2.loss_dice: 0.9468  decode.d3.loss_cls: 0.3357  decode.d3.loss_mask: 1.3560  decode.d3.loss_dice: 0.9259  decode.d4.loss_cls: 0.3325  decode.d4.loss_mask: 1.3286  decode.d4.loss_dice: 0.9462  decode.d5.loss_cls: 0.3040  decode.d5.loss_mask: 1.3732  decode.d5.loss_dice: 0.9681  decode.d6.loss_cls: 0.2980  decode.d6.loss_mask: 1.3308  decode.d6.loss_dice: 1.0051  decode.d7.loss_cls: 0.3276  decode.d7.loss_mask: 1.3405  decode.d7.loss_dice: 0.9624  decode.d8.loss_cls: 0.3328  decode.d8.loss_mask: 1.3483  decode.d8.loss_dice: 0.9551
05/26 13:50:00 - mmengine - INFO - Iter(train) [ 24950/160000]  base_lr: 8.5850e-05 lr: 8.5850e-06  eta: 15:24:09  time: 0.4073  data_time: 0.0089  memory: 5976  grad_norm: 864.9011  loss: 29.5567  decode.loss_cls: 0.4021  decode.loss_mask: 1.5072  decode.loss_dice: 1.1085  decode.d0.loss_cls: 0.8385  decode.d0.loss_mask: 1.4107  decode.d0.loss_dice: 1.0610  decode.d1.loss_cls: 0.4113  decode.d1.loss_mask: 1.4297  decode.d1.loss_dice: 1.0810  decode.d2.loss_cls: 0.3808  decode.d2.loss_mask: 1.4073  decode.d2.loss_dice: 1.0452  decode.d3.loss_cls: 0.3567  decode.d3.loss_mask: 1.4316  decode.d3.loss_dice: 1.0173  decode.d4.loss_cls: 0.4062  decode.d4.loss_mask: 1.4936  decode.d4.loss_dice: 1.0833  decode.d5.loss_cls: 0.3776  decode.d5.loss_mask: 1.4956  decode.d5.loss_dice: 1.0912  decode.d6.loss_cls: 0.3238  decode.d6.loss_mask: 1.4766  decode.d6.loss_dice: 1.0512  decode.d7.loss_cls: 0.3739  decode.d7.loss_mask: 1.4915  decode.d7.loss_dice: 1.0684  decode.d8.loss_cls: 0.3667  decode.d8.loss_mask: 1.4959  decode.d8.loss_dice: 1.0722
05/26 13:50:21 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 13:50:21 - mmengine - INFO - Iter(train) [ 25000/160000]  base_lr: 8.5821e-05 lr: 8.5821e-06  eta: 15:23:48  time: 0.4095  data_time: 0.0093  memory: 5966  grad_norm: 727.1902  loss: 23.3062  decode.loss_cls: 0.3660  decode.loss_mask: 1.1135  decode.loss_dice: 0.7970  decode.d0.loss_cls: 0.9041  decode.d0.loss_mask: 1.0503  decode.d0.loss_dice: 0.7492  decode.d1.loss_cls: 0.3681  decode.d1.loss_mask: 1.0993  decode.d1.loss_dice: 0.7779  decode.d2.loss_cls: 0.3965  decode.d2.loss_mask: 1.1292  decode.d2.loss_dice: 0.7805  decode.d3.loss_cls: 0.3832  decode.d3.loss_mask: 1.0987  decode.d3.loss_dice: 0.7863  decode.d4.loss_cls: 0.4246  decode.d4.loss_mask: 1.0395  decode.d4.loss_dice: 0.7694  decode.d5.loss_cls: 0.4229  decode.d5.loss_mask: 1.0760  decode.d5.loss_dice: 0.7819  decode.d6.loss_cls: 0.4173  decode.d6.loss_mask: 1.1397  decode.d6.loss_dice: 0.8465  decode.d7.loss_cls: 0.3953  decode.d7.loss_mask: 1.1385  decode.d7.loss_dice: 0.7868  decode.d8.loss_cls: 0.3380  decode.d8.loss_mask: 1.1338  decode.d8.loss_dice: 0.7962
05/26 13:50:21 - mmengine - INFO - Saving checkpoint at 25000 iterations
05/26 13:50:25 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:12  time: 0.0486  data_time: 0.0012  memory: 1391  
05/26 13:50:28 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:07  time: 0.0483  data_time: 0.0012  memory: 1205  
05/26 13:50:30 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:05  time: 0.0507  data_time: 0.0012  memory: 1596  
05/26 13:50:33 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:02  time: 0.0495  data_time: 0.0012  memory: 1298  
05/26 13:50:35 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:59  time: 0.0483  data_time: 0.0012  memory: 1298  
05/26 13:50:37 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:56  time: 0.0486  data_time: 0.0013  memory: 1279  
05/26 13:50:40 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:54  time: 0.0487  data_time: 0.0012  memory: 1224  
05/26 13:50:42 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:51  time: 0.0494  data_time: 0.0012  memory: 1298  
05/26 13:50:45 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:49  time: 0.0479  data_time: 0.0012  memory: 1298  
05/26 13:50:47 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:46  time: 0.0525  data_time: 0.0013  memory: 1725  
05/26 13:50:50 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:44  time: 0.0483  data_time: 0.0012  memory: 1336  
05/26 13:50:52 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:41  time: 0.0488  data_time: 0.0013  memory: 1298  
05/26 13:50:55 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:39  time: 0.0486  data_time: 0.0012  memory: 1205  
05/26 13:50:57 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0505  data_time: 0.0012  memory: 1316  
05/26 13:50:59 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:34  time: 0.0482  data_time: 0.0012  memory: 1279  
05/26 13:51:02 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0517  data_time: 0.0012  memory: 1410  
05/26 13:51:04 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:29  time: 0.0482  data_time: 0.0012  memory: 1279  
05/26 13:51:07 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0507  data_time: 0.0012  memory: 1205  
05/26 13:51:09 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0490  data_time: 0.0012  memory: 1205  
05/26 13:51:12 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0482  data_time: 0.0012  memory: 1336  
05/26 13:51:14 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0479  data_time: 0.0012  memory: 1246  
05/26 13:51:17 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0508  data_time: 0.0012  memory: 1503  
05/26 13:51:19 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0480  data_time: 0.0012  memory: 1261  
05/26 13:51:21 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0488  data_time: 0.0012  memory: 1298  
05/26 13:51:24 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0484  data_time: 0.0012  memory: 1447  
05/26 13:51:26 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0480  data_time: 0.0012  memory: 1298  
05/26 13:51:29 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0496  data_time: 0.0012  memory: 1279  
05/26 13:51:31 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0484  data_time: 0.0012  memory: 1205  
05/26 13:51:34 - mmengine - INFO - per class results:
05/26 13:51:34 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 94.46 |  96.9 |
|  aeroplane  | 92.27 | 97.61 |
|   bicycle   | 43.26 | 90.38 |
|     bird    | 93.34 | 95.04 |
|     boat    | 71.65 | 84.45 |
|    bottle   | 73.75 | 81.86 |
|     bus     | 85.25 | 86.84 |
|     car     | 90.33 | 92.55 |
|     cat     |  85.2 | 94.91 |
|    chair    | 35.13 | 48.57 |
|     cow     | 17.93 | 19.91 |
| diningtable | 56.59 | 75.62 |
|     dog     |  58.8 | 83.82 |
|    horse    | 57.18 | 68.79 |
|  motorbike  | 89.86 | 94.55 |
|    person   | 87.97 | 94.98 |
| pottedplant | 55.59 | 70.72 |
|    sheep    | 72.58 | 94.63 |
|     sofa    | 46.83 | 71.14 |
|    train    | 84.48 | 93.09 |
|  tvmonitor  |  74.1 | 80.24 |
+-------------+-------+-------+
05/26 13:51:34 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 93.4000  mIoU: 69.8400  mAcc: 81.7400  data_time: 0.0013  time: 0.0488
05/26 13:51:34 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_20000.pth is removed
05/26 13:51:35 - mmengine - INFO - The best checkpoint with 69.8400 mIoU at 25000 iter is saved to best_mIoU_iter_25000.pth.
05/26 13:51:57 - mmengine - INFO - Iter(train) [ 25050/160000]  base_lr: 8.5793e-05 lr: 8.5793e-06  eta: 15:23:42  time: 0.4072  data_time: 0.0089  memory: 5969  grad_norm: 583.2773  loss: 28.0897  decode.loss_cls: 0.2826  decode.loss_mask: 1.4563  decode.loss_dice: 0.9956  decode.d0.loss_cls: 0.7909  decode.d0.loss_mask: 1.3908  decode.d0.loss_dice: 0.9740  decode.d1.loss_cls: 0.2825  decode.d1.loss_mask: 1.4823  decode.d1.loss_dice: 1.0128  decode.d2.loss_cls: 0.3293  decode.d2.loss_mask: 1.4007  decode.d2.loss_dice: 0.9719  decode.d3.loss_cls: 0.3460  decode.d3.loss_mask: 1.4660  decode.d3.loss_dice: 1.0064  decode.d4.loss_cls: 0.3866  decode.d4.loss_mask: 1.4311  decode.d4.loss_dice: 1.0048  decode.d5.loss_cls: 0.3304  decode.d5.loss_mask: 1.4460  decode.d5.loss_dice: 1.0115  decode.d6.loss_cls: 0.3072  decode.d6.loss_mask: 1.5136  decode.d6.loss_dice: 0.9932  decode.d7.loss_cls: 0.3090  decode.d7.loss_mask: 1.4022  decode.d7.loss_dice: 1.0044  decode.d8.loss_cls: 0.3235  decode.d8.loss_mask: 1.4326  decode.d8.loss_dice: 1.0057
05/26 13:52:17 - mmengine - INFO - Iter(train) [ 25100/160000]  base_lr: 8.5764e-05 lr: 8.5764e-06  eta: 15:23:21  time: 0.4078  data_time: 0.0090  memory: 5969  grad_norm: 794.2818  loss: 26.0459  decode.loss_cls: 0.3168  decode.loss_mask: 1.2537  decode.loss_dice: 0.9422  decode.d0.loss_cls: 0.7570  decode.d0.loss_mask: 1.2105  decode.d0.loss_dice: 0.9265  decode.d1.loss_cls: 0.3414  decode.d1.loss_mask: 1.3045  decode.d1.loss_dice: 0.9759  decode.d2.loss_cls: 0.3315  decode.d2.loss_mask: 1.2157  decode.d2.loss_dice: 0.9232  decode.d3.loss_cls: 0.2872  decode.d3.loss_mask: 1.2485  decode.d3.loss_dice: 0.9521  decode.d4.loss_cls: 0.3151  decode.d4.loss_mask: 1.2824  decode.d4.loss_dice: 0.9865  decode.d5.loss_cls: 0.3409  decode.d5.loss_mask: 1.2642  decode.d5.loss_dice: 0.9819  decode.d6.loss_cls: 0.2977  decode.d6.loss_mask: 1.3591  decode.d6.loss_dice: 1.0080  decode.d7.loss_cls: 0.3620  decode.d7.loss_mask: 1.3290  decode.d7.loss_dice: 1.0096  decode.d8.loss_cls: 0.3287  decode.d8.loss_mask: 1.2551  decode.d8.loss_dice: 0.9390
05/26 13:52:38 - mmengine - INFO - Iter(train) [ 25150/160000]  base_lr: 8.5735e-05 lr: 8.5735e-06  eta: 15:23:00  time: 0.4108  data_time: 0.0091  memory: 5990  grad_norm: 648.5329  loss: 26.6153  decode.loss_cls: 0.4171  decode.loss_mask: 1.2425  decode.loss_dice: 0.9621  decode.d0.loss_cls: 0.7780  decode.d0.loss_mask: 1.2116  decode.d0.loss_dice: 0.9651  decode.d1.loss_cls: 0.4167  decode.d1.loss_mask: 1.2525  decode.d1.loss_dice: 0.9708  decode.d2.loss_cls: 0.3780  decode.d2.loss_mask: 1.2472  decode.d2.loss_dice: 0.9984  decode.d3.loss_cls: 0.3723  decode.d3.loss_mask: 1.1968  decode.d3.loss_dice: 0.9811  decode.d4.loss_cls: 0.3966  decode.d4.loss_mask: 1.2951  decode.d4.loss_dice: 0.9845  decode.d5.loss_cls: 0.3799  decode.d5.loss_mask: 1.2700  decode.d5.loss_dice: 0.9818  decode.d6.loss_cls: 0.3803  decode.d6.loss_mask: 1.2291  decode.d6.loss_dice: 0.9822  decode.d7.loss_cls: 0.3153  decode.d7.loss_mask: 1.3478  decode.d7.loss_dice: 0.9972  decode.d8.loss_cls: 0.4115  decode.d8.loss_mask: 1.2864  decode.d8.loss_dice: 0.9676
05/26 13:52:58 - mmengine - INFO - Iter(train) [ 25200/160000]  base_lr: 8.5707e-05 lr: 8.5707e-06  eta: 15:22:38  time: 0.4073  data_time: 0.0090  memory: 5966  grad_norm: 876.6049  loss: 20.5396  decode.loss_cls: 0.2285  decode.loss_mask: 1.0309  decode.loss_dice: 0.7034  decode.d0.loss_cls: 0.6551  decode.d0.loss_mask: 1.0138  decode.d0.loss_dice: 0.6865  decode.d1.loss_cls: 0.2944  decode.d1.loss_mask: 1.0466  decode.d1.loss_dice: 0.6974  decode.d2.loss_cls: 0.2961  decode.d2.loss_mask: 1.0295  decode.d2.loss_dice: 0.6936  decode.d3.loss_cls: 0.2666  decode.d3.loss_mask: 1.0342  decode.d3.loss_dice: 0.6880  decode.d4.loss_cls: 0.2705  decode.d4.loss_mask: 1.0560  decode.d4.loss_dice: 0.7166  decode.d5.loss_cls: 0.2826  decode.d5.loss_mask: 1.0450  decode.d5.loss_dice: 0.7082  decode.d6.loss_cls: 0.2300  decode.d6.loss_mask: 1.1112  decode.d6.loss_dice: 0.7143  decode.d7.loss_cls: 0.3388  decode.d7.loss_mask: 1.0175  decode.d7.loss_dice: 0.6883  decode.d8.loss_cls: 0.2367  decode.d8.loss_mask: 1.0420  decode.d8.loss_dice: 0.7174
05/26 13:53:19 - mmengine - INFO - Iter(train) [ 25250/160000]  base_lr: 8.5678e-05 lr: 8.5678e-06  eta: 15:22:17  time: 0.4079  data_time: 0.0090  memory: 5966  grad_norm: 1395.3581  loss: 26.9308  decode.loss_cls: 0.3813  decode.loss_mask: 1.2817  decode.loss_dice: 0.9256  decode.d0.loss_cls: 0.9027  decode.d0.loss_mask: 1.2320  decode.d0.loss_dice: 0.8849  decode.d1.loss_cls: 0.3894  decode.d1.loss_mask: 1.2759  decode.d1.loss_dice: 0.9200  decode.d2.loss_cls: 0.4933  decode.d2.loss_mask: 1.3286  decode.d2.loss_dice: 0.8923  decode.d3.loss_cls: 0.4902  decode.d3.loss_mask: 1.3146  decode.d3.loss_dice: 0.8750  decode.d4.loss_cls: 0.4961  decode.d4.loss_mask: 1.3073  decode.d4.loss_dice: 0.9617  decode.d5.loss_cls: 0.4783  decode.d5.loss_mask: 1.2882  decode.d5.loss_dice: 0.9208  decode.d6.loss_cls: 0.4485  decode.d6.loss_mask: 1.2806  decode.d6.loss_dice: 0.8866  decode.d7.loss_cls: 0.4962  decode.d7.loss_mask: 1.2651  decode.d7.loss_dice: 0.9117  decode.d8.loss_cls: 0.4115  decode.d8.loss_mask: 1.3045  decode.d8.loss_dice: 0.8864
05/26 13:53:39 - mmengine - INFO - Iter(train) [ 25300/160000]  base_lr: 8.5650e-05 lr: 8.5650e-06  eta: 15:21:56  time: 0.4087  data_time: 0.0091  memory: 5975  grad_norm: 709.6501  loss: 24.4872  decode.loss_cls: 0.1980  decode.loss_mask: 1.2084  decode.loss_dice: 0.9797  decode.d0.loss_cls: 0.6972  decode.d0.loss_mask: 1.1776  decode.d0.loss_dice: 0.9102  decode.d1.loss_cls: 0.2312  decode.d1.loss_mask: 1.1857  decode.d1.loss_dice: 0.9691  decode.d2.loss_cls: 0.2486  decode.d2.loss_mask: 1.2189  decode.d2.loss_dice: 0.9449  decode.d3.loss_cls: 0.2497  decode.d3.loss_mask: 1.2095  decode.d3.loss_dice: 0.9619  decode.d4.loss_cls: 0.2647  decode.d4.loss_mask: 1.2381  decode.d4.loss_dice: 0.9667  decode.d5.loss_cls: 0.2704  decode.d5.loss_mask: 1.1955  decode.d5.loss_dice: 0.9258  decode.d6.loss_cls: 0.2662  decode.d6.loss_mask: 1.2092  decode.d6.loss_dice: 0.9886  decode.d7.loss_cls: 0.2409  decode.d7.loss_mask: 1.1935  decode.d7.loss_dice: 0.9536  decode.d8.loss_cls: 0.2050  decode.d8.loss_mask: 1.2155  decode.d8.loss_dice: 0.9630
05/26 13:53:59 - mmengine - INFO - Iter(train) [ 25350/160000]  base_lr: 8.5621e-05 lr: 8.5621e-06  eta: 15:21:35  time: 0.4079  data_time: 0.0089  memory: 5966  grad_norm: 842.4970  loss: 29.3890  decode.loss_cls: 0.3525  decode.loss_mask: 1.5094  decode.loss_dice: 1.0162  decode.d0.loss_cls: 0.8669  decode.d0.loss_mask: 1.4828  decode.d0.loss_dice: 1.0004  decode.d1.loss_cls: 0.4398  decode.d1.loss_mask: 1.4982  decode.d1.loss_dice: 0.9846  decode.d2.loss_cls: 0.4078  decode.d2.loss_mask: 1.4778  decode.d2.loss_dice: 0.9788  decode.d3.loss_cls: 0.4093  decode.d3.loss_mask: 1.4816  decode.d3.loss_dice: 0.9649  decode.d4.loss_cls: 0.4144  decode.d4.loss_mask: 1.4900  decode.d4.loss_dice: 1.0322  decode.d5.loss_cls: 0.4492  decode.d5.loss_mask: 1.4859  decode.d5.loss_dice: 1.0067  decode.d6.loss_cls: 0.4290  decode.d6.loss_mask: 1.4825  decode.d6.loss_dice: 0.9759  decode.d7.loss_cls: 0.4291  decode.d7.loss_mask: 1.4839  decode.d7.loss_dice: 0.9515  decode.d8.loss_cls: 0.3972  decode.d8.loss_mask: 1.4894  decode.d8.loss_dice: 1.0012
05/26 13:54:20 - mmengine - INFO - Iter(train) [ 25400/160000]  base_lr: 8.5592e-05 lr: 8.5592e-06  eta: 15:21:14  time: 0.4083  data_time: 0.0089  memory: 5967  grad_norm: 1064.0716  loss: 29.9784  decode.loss_cls: 0.3534  decode.loss_mask: 1.5198  decode.loss_dice: 1.0314  decode.d0.loss_cls: 0.8759  decode.d0.loss_mask: 1.4419  decode.d0.loss_dice: 1.0323  decode.d1.loss_cls: 0.4251  decode.d1.loss_mask: 1.5394  decode.d1.loss_dice: 1.0401  decode.d2.loss_cls: 0.3329  decode.d2.loss_mask: 1.5864  decode.d2.loss_dice: 1.0596  decode.d3.loss_cls: 0.3061  decode.d3.loss_mask: 1.5856  decode.d3.loss_dice: 1.0693  decode.d4.loss_cls: 0.3801  decode.d4.loss_mask: 1.4712  decode.d4.loss_dice: 1.0801  decode.d5.loss_cls: 0.3533  decode.d5.loss_mask: 1.5120  decode.d5.loss_dice: 1.0214  decode.d6.loss_cls: 0.3748  decode.d6.loss_mask: 1.5502  decode.d6.loss_dice: 1.0874  decode.d7.loss_cls: 0.3763  decode.d7.loss_mask: 1.5498  decode.d7.loss_dice: 1.0527  decode.d8.loss_cls: 0.3349  decode.d8.loss_mask: 1.5604  decode.d8.loss_dice: 1.0746
05/26 13:54:40 - mmengine - INFO - Iter(train) [ 25450/160000]  base_lr: 8.5564e-05 lr: 8.5564e-06  eta: 15:20:53  time: 0.4078  data_time: 0.0089  memory: 5976  grad_norm: 582.2895  loss: 28.0258  decode.loss_cls: 0.2574  decode.loss_mask: 1.4435  decode.loss_dice: 1.0787  decode.d0.loss_cls: 0.7421  decode.d0.loss_mask: 1.3031  decode.d0.loss_dice: 0.9798  decode.d1.loss_cls: 0.3218  decode.d1.loss_mask: 1.3663  decode.d1.loss_dice: 1.0399  decode.d2.loss_cls: 0.2727  decode.d2.loss_mask: 1.3703  decode.d2.loss_dice: 1.0786  decode.d3.loss_cls: 0.2917  decode.d3.loss_mask: 1.4446  decode.d3.loss_dice: 1.0963  decode.d4.loss_cls: 0.3011  decode.d4.loss_mask: 1.3916  decode.d4.loss_dice: 1.1010  decode.d5.loss_cls: 0.3366  decode.d5.loss_mask: 1.3499  decode.d5.loss_dice: 1.0751  decode.d6.loss_cls: 0.3099  decode.d6.loss_mask: 1.4546  decode.d6.loss_dice: 1.0875  decode.d7.loss_cls: 0.3254  decode.d7.loss_mask: 1.4054  decode.d7.loss_dice: 1.0808  decode.d8.loss_cls: 0.2799  decode.d8.loss_mask: 1.4034  decode.d8.loss_dice: 1.0368
05/26 13:55:01 - mmengine - INFO - Iter(train) [ 25500/160000]  base_lr: 8.5535e-05 lr: 8.5535e-06  eta: 15:20:32  time: 0.4091  data_time: 0.0090  memory: 5978  grad_norm: 606.8992  loss: 25.1928  decode.loss_cls: 0.4065  decode.loss_mask: 1.1713  decode.loss_dice: 0.8509  decode.d0.loss_cls: 0.9131  decode.d0.loss_mask: 1.0966  decode.d0.loss_dice: 0.8551  decode.d1.loss_cls: 0.3273  decode.d1.loss_mask: 1.2198  decode.d1.loss_dice: 0.9024  decode.d2.loss_cls: 0.3518  decode.d2.loss_mask: 1.2010  decode.d2.loss_dice: 0.8867  decode.d3.loss_cls: 0.3567  decode.d3.loss_mask: 1.2005  decode.d3.loss_dice: 0.8860  decode.d4.loss_cls: 0.4634  decode.d4.loss_mask: 1.1898  decode.d4.loss_dice: 0.9276  decode.d5.loss_cls: 0.4058  decode.d5.loss_mask: 1.2034  decode.d5.loss_dice: 0.9037  decode.d6.loss_cls: 0.3530  decode.d6.loss_mask: 1.2181  decode.d6.loss_dice: 0.9645  decode.d7.loss_cls: 0.4255  decode.d7.loss_mask: 1.1892  decode.d7.loss_dice: 0.8834  decode.d8.loss_cls: 0.4048  decode.d8.loss_mask: 1.1857  decode.d8.loss_dice: 0.8491
05/26 13:55:21 - mmengine - INFO - Iter(train) [ 25550/160000]  base_lr: 8.5507e-05 lr: 8.5507e-06  eta: 15:20:11  time: 0.4114  data_time: 0.0093  memory: 5972  grad_norm: 602.6610  loss: 29.9249  decode.loss_cls: 0.4445  decode.loss_mask: 1.4780  decode.loss_dice: 1.0489  decode.d0.loss_cls: 0.9174  decode.d0.loss_mask: 1.3230  decode.d0.loss_dice: 0.9715  decode.d1.loss_cls: 0.3857  decode.d1.loss_mask: 1.4687  decode.d1.loss_dice: 1.1145  decode.d2.loss_cls: 0.3625  decode.d2.loss_mask: 1.4818  decode.d2.loss_dice: 1.0859  decode.d3.loss_cls: 0.3891  decode.d3.loss_mask: 1.5060  decode.d3.loss_dice: 1.1056  decode.d4.loss_cls: 0.4567  decode.d4.loss_mask: 1.4231  decode.d4.loss_dice: 1.0485  decode.d5.loss_cls: 0.4234  decode.d5.loss_mask: 1.4730  decode.d5.loss_dice: 1.0968  decode.d6.loss_cls: 0.4580  decode.d6.loss_mask: 1.4632  decode.d6.loss_dice: 1.0913  decode.d7.loss_cls: 0.4974  decode.d7.loss_mask: 1.4622  decode.d7.loss_dice: 1.0387  decode.d8.loss_cls: 0.4880  decode.d8.loss_mask: 1.3900  decode.d8.loss_dice: 1.0314
05/26 13:55:42 - mmengine - INFO - Iter(train) [ 25600/160000]  base_lr: 8.5478e-05 lr: 8.5478e-06  eta: 15:19:49  time: 0.4068  data_time: 0.0089  memory: 5968  grad_norm: 608.3970  loss: 25.4276  decode.loss_cls: 0.2770  decode.loss_mask: 1.2232  decode.loss_dice: 0.9428  decode.d0.loss_cls: 0.7390  decode.d0.loss_mask: 1.1722  decode.d0.loss_dice: 0.8952  decode.d1.loss_cls: 0.3599  decode.d1.loss_mask: 1.1961  decode.d1.loss_dice: 0.9450  decode.d2.loss_cls: 0.3163  decode.d2.loss_mask: 1.2623  decode.d2.loss_dice: 0.9752  decode.d3.loss_cls: 0.3306  decode.d3.loss_mask: 1.2272  decode.d3.loss_dice: 0.9909  decode.d4.loss_cls: 0.3568  decode.d4.loss_mask: 1.2602  decode.d4.loss_dice: 0.9487  decode.d5.loss_cls: 0.3753  decode.d5.loss_mask: 1.2159  decode.d5.loss_dice: 0.9802  decode.d6.loss_cls: 0.3289  decode.d6.loss_mask: 1.2019  decode.d6.loss_dice: 0.9387  decode.d7.loss_cls: 0.3380  decode.d7.loss_mask: 1.2175  decode.d7.loss_dice: 0.9376  decode.d8.loss_cls: 0.3340  decode.d8.loss_mask: 1.2095  decode.d8.loss_dice: 0.9315
05/26 13:56:02 - mmengine - INFO - Iter(train) [ 25650/160000]  base_lr: 8.5449e-05 lr: 8.5449e-06  eta: 15:19:28  time: 0.4079  data_time: 0.0089  memory: 5967  grad_norm: 688.3094  loss: 25.1318  decode.loss_cls: 0.2698  decode.loss_mask: 1.2104  decode.loss_dice: 0.9719  decode.d0.loss_cls: 0.7470  decode.d0.loss_mask: 1.1437  decode.d0.loss_dice: 0.9638  decode.d1.loss_cls: 0.3103  decode.d1.loss_mask: 1.1901  decode.d1.loss_dice: 0.9932  decode.d2.loss_cls: 0.2587  decode.d2.loss_mask: 1.2050  decode.d2.loss_dice: 0.9980  decode.d3.loss_cls: 0.3156  decode.d3.loss_mask: 1.1609  decode.d3.loss_dice: 0.9493  decode.d4.loss_cls: 0.3803  decode.d4.loss_mask: 1.1755  decode.d4.loss_dice: 0.9675  decode.d5.loss_cls: 0.2864  decode.d5.loss_mask: 1.1841  decode.d5.loss_dice: 0.9657  decode.d6.loss_cls: 0.3559  decode.d6.loss_mask: 1.1818  decode.d6.loss_dice: 0.9936  decode.d7.loss_cls: 0.2948  decode.d7.loss_mask: 1.2102  decode.d7.loss_dice: 1.0026  decode.d8.loss_cls: 0.2772  decode.d8.loss_mask: 1.2143  decode.d8.loss_dice: 0.9542
05/26 13:56:22 - mmengine - INFO - Iter(train) [ 25700/160000]  base_lr: 8.5421e-05 lr: 8.5421e-06  eta: 15:19:07  time: 0.4083  data_time: 0.0090  memory: 5969  grad_norm: 1714.6107  loss: 28.9142  decode.loss_cls: 0.3078  decode.loss_mask: 1.5811  decode.loss_dice: 0.9678  decode.d0.loss_cls: 0.8950  decode.d0.loss_mask: 1.3733  decode.d0.loss_dice: 0.9265  decode.d1.loss_cls: 0.3984  decode.d1.loss_mask: 1.4336  decode.d1.loss_dice: 0.9831  decode.d2.loss_cls: 0.3644  decode.d2.loss_mask: 1.5079  decode.d2.loss_dice: 1.0145  decode.d3.loss_cls: 0.3371  decode.d3.loss_mask: 1.6173  decode.d3.loss_dice: 1.0227  decode.d4.loss_cls: 0.4178  decode.d4.loss_mask: 1.4600  decode.d4.loss_dice: 0.9958  decode.d5.loss_cls: 0.3978  decode.d5.loss_mask: 1.5134  decode.d5.loss_dice: 0.9890  decode.d6.loss_cls: 0.3635  decode.d6.loss_mask: 1.4771  decode.d6.loss_dice: 1.0231  decode.d7.loss_cls: 0.3867  decode.d7.loss_mask: 1.4611  decode.d7.loss_dice: 0.9300  decode.d8.loss_cls: 0.3785  decode.d8.loss_mask: 1.4386  decode.d8.loss_dice: 0.9515
05/26 13:56:43 - mmengine - INFO - Iter(train) [ 25750/160000]  base_lr: 8.5392e-05 lr: 8.5392e-06  eta: 15:18:46  time: 0.4073  data_time: 0.0088  memory: 5968  grad_norm: 724.4917  loss: 28.5619  decode.loss_cls: 0.3547  decode.loss_mask: 1.3900  decode.loss_dice: 1.0090  decode.d0.loss_cls: 0.9232  decode.d0.loss_mask: 1.3722  decode.d0.loss_dice: 0.9824  decode.d1.loss_cls: 0.4226  decode.d1.loss_mask: 1.4514  decode.d1.loss_dice: 1.0064  decode.d2.loss_cls: 0.3782  decode.d2.loss_mask: 1.4420  decode.d2.loss_dice: 1.0070  decode.d3.loss_cls: 0.3573  decode.d3.loss_mask: 1.4204  decode.d3.loss_dice: 1.0261  decode.d4.loss_cls: 0.4165  decode.d4.loss_mask: 1.4332  decode.d4.loss_dice: 1.0226  decode.d5.loss_cls: 0.4262  decode.d5.loss_mask: 1.3696  decode.d5.loss_dice: 1.0078  decode.d6.loss_cls: 0.3812  decode.d6.loss_mask: 1.4040  decode.d6.loss_dice: 1.0088  decode.d7.loss_cls: 0.4065  decode.d7.loss_mask: 1.3779  decode.d7.loss_dice: 0.9878  decode.d8.loss_cls: 0.3885  decode.d8.loss_mask: 1.3872  decode.d8.loss_dice: 1.0012
05/26 13:57:03 - mmengine - INFO - Iter(train) [ 25800/160000]  base_lr: 8.5363e-05 lr: 8.5363e-06  eta: 15:18:25  time: 0.4063  data_time: 0.0088  memory: 5971  grad_norm: 936.3377  loss: 31.0223  decode.loss_cls: 0.4680  decode.loss_mask: 1.5468  decode.loss_dice: 1.1030  decode.d0.loss_cls: 0.9216  decode.d0.loss_mask: 1.4230  decode.d0.loss_dice: 1.0126  decode.d1.loss_cls: 0.4938  decode.d1.loss_mask: 1.4821  decode.d1.loss_dice: 1.0506  decode.d2.loss_cls: 0.4954  decode.d2.loss_mask: 1.5380  decode.d2.loss_dice: 1.0584  decode.d3.loss_cls: 0.4886  decode.d3.loss_mask: 1.5416  decode.d3.loss_dice: 1.1038  decode.d4.loss_cls: 0.4812  decode.d4.loss_mask: 1.5000  decode.d4.loss_dice: 1.1066  decode.d5.loss_cls: 0.5007  decode.d5.loss_mask: 1.4811  decode.d5.loss_dice: 1.0525  decode.d6.loss_cls: 0.4119  decode.d6.loss_mask: 1.5692  decode.d6.loss_dice: 1.0792  decode.d7.loss_cls: 0.4934  decode.d7.loss_mask: 1.5058  decode.d7.loss_dice: 1.0442  decode.d8.loss_cls: 0.5301  decode.d8.loss_mask: 1.4932  decode.d8.loss_dice: 1.0459
05/26 13:57:23 - mmengine - INFO - Iter(train) [ 25850/160000]  base_lr: 8.5335e-05 lr: 8.5335e-06  eta: 15:18:03  time: 0.4071  data_time: 0.0090  memory: 5981  grad_norm: 309.2021  loss: 23.0991  decode.loss_cls: 0.3723  decode.loss_mask: 1.0616  decode.loss_dice: 0.9207  decode.d0.loss_cls: 0.8141  decode.d0.loss_mask: 0.9472  decode.d0.loss_dice: 0.8840  decode.d1.loss_cls: 0.3777  decode.d1.loss_mask: 0.9900  decode.d1.loss_dice: 0.9108  decode.d2.loss_cls: 0.4102  decode.d2.loss_mask: 0.9503  decode.d2.loss_dice: 0.8773  decode.d3.loss_cls: 0.3650  decode.d3.loss_mask: 0.9902  decode.d3.loss_dice: 0.9131  decode.d4.loss_cls: 0.3822  decode.d4.loss_mask: 0.9564  decode.d4.loss_dice: 0.9008  decode.d5.loss_cls: 0.3569  decode.d5.loss_mask: 0.9807  decode.d5.loss_dice: 0.9184  decode.d6.loss_cls: 0.4185  decode.d6.loss_mask: 0.9650  decode.d6.loss_dice: 0.9051  decode.d7.loss_cls: 0.3530  decode.d7.loss_mask: 1.0045  decode.d7.loss_dice: 0.8827  decode.d8.loss_cls: 0.3765  decode.d8.loss_mask: 1.0215  decode.d8.loss_dice: 0.8923
05/26 13:57:44 - mmengine - INFO - Iter(train) [ 25900/160000]  base_lr: 8.5306e-05 lr: 8.5306e-06  eta: 15:17:42  time: 0.4102  data_time: 0.0091  memory: 5969  grad_norm: 753.1698  loss: 28.0757  decode.loss_cls: 0.4943  decode.loss_mask: 1.2768  decode.loss_dice: 1.0484  decode.d0.loss_cls: 0.9410  decode.d0.loss_mask: 1.1234  decode.d0.loss_dice: 0.9727  decode.d1.loss_cls: 0.5269  decode.d1.loss_mask: 1.2084  decode.d1.loss_dice: 1.0214  decode.d2.loss_cls: 0.5570  decode.d2.loss_mask: 1.2129  decode.d2.loss_dice: 1.0196  decode.d3.loss_cls: 0.5086  decode.d3.loss_mask: 1.1681  decode.d3.loss_dice: 1.0142  decode.d4.loss_cls: 0.5787  decode.d4.loss_mask: 1.2291  decode.d4.loss_dice: 1.0189  decode.d5.loss_cls: 0.6071  decode.d5.loss_mask: 1.1940  decode.d5.loss_dice: 1.0186  decode.d6.loss_cls: 0.5740  decode.d6.loss_mask: 1.2527  decode.d6.loss_dice: 0.9988  decode.d7.loss_cls: 0.4728  decode.d7.loss_mask: 1.2999  decode.d7.loss_dice: 1.0751  decode.d8.loss_cls: 0.4426  decode.d8.loss_mask: 1.2078  decode.d8.loss_dice: 1.0118
05/26 13:58:04 - mmengine - INFO - Iter(train) [ 25950/160000]  base_lr: 8.5278e-05 lr: 8.5278e-06  eta: 15:17:21  time: 0.4114  data_time: 0.0092  memory: 5972  grad_norm: 693.0987  loss: 26.4622  decode.loss_cls: 0.3915  decode.loss_mask: 1.2120  decode.loss_dice: 0.9495  decode.d0.loss_cls: 0.9784  decode.d0.loss_mask: 1.1327  decode.d0.loss_dice: 0.9377  decode.d1.loss_cls: 0.4381  decode.d1.loss_mask: 1.2292  decode.d1.loss_dice: 0.9281  decode.d2.loss_cls: 0.4412  decode.d2.loss_mask: 1.1938  decode.d2.loss_dice: 0.9167  decode.d3.loss_cls: 0.4460  decode.d3.loss_mask: 1.1896  decode.d3.loss_dice: 0.9440  decode.d4.loss_cls: 0.4372  decode.d4.loss_mask: 1.2027  decode.d4.loss_dice: 0.9365  decode.d5.loss_cls: 0.3976  decode.d5.loss_mask: 1.2708  decode.d5.loss_dice: 0.9538  decode.d6.loss_cls: 0.5365  decode.d6.loss_mask: 1.2530  decode.d6.loss_dice: 0.9413  decode.d7.loss_cls: 0.4420  decode.d7.loss_mask: 1.2883  decode.d7.loss_dice: 0.9551  decode.d8.loss_cls: 0.4150  decode.d8.loss_mask: 1.1919  decode.d8.loss_dice: 0.9123
05/26 13:58:25 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 13:58:25 - mmengine - INFO - Iter(train) [ 26000/160000]  base_lr: 8.5249e-05 lr: 8.5249e-06  eta: 15:17:00  time: 0.4074  data_time: 0.0090  memory: 5976  grad_norm: 1065.2596  loss: 24.5975  decode.loss_cls: 0.3081  decode.loss_mask: 1.2761  decode.loss_dice: 0.9166  decode.d0.loss_cls: 0.7830  decode.d0.loss_mask: 1.0488  decode.d0.loss_dice: 0.7440  decode.d1.loss_cls: 0.3325  decode.d1.loss_mask: 1.2445  decode.d1.loss_dice: 0.9312  decode.d2.loss_cls: 0.3904  decode.d2.loss_mask: 1.1869  decode.d2.loss_dice: 0.8288  decode.d3.loss_cls: 0.3565  decode.d3.loss_mask: 1.1877  decode.d3.loss_dice: 0.8089  decode.d4.loss_cls: 0.3699  decode.d4.loss_mask: 1.1946  decode.d4.loss_dice: 0.8380  decode.d5.loss_cls: 0.4228  decode.d5.loss_mask: 1.2015  decode.d5.loss_dice: 0.8869  decode.d6.loss_cls: 0.3635  decode.d6.loss_mask: 1.2167  decode.d6.loss_dice: 0.8485  decode.d7.loss_cls: 0.3946  decode.d7.loss_mask: 1.2476  decode.d7.loss_dice: 0.8701  decode.d8.loss_cls: 0.3993  decode.d8.loss_mask: 1.1800  decode.d8.loss_dice: 0.8195
05/26 13:58:45 - mmengine - INFO - Iter(train) [ 26050/160000]  base_lr: 8.5220e-05 lr: 8.5220e-06  eta: 15:16:38  time: 0.4071  data_time: 0.0089  memory: 5969  grad_norm: 651.0063  loss: 21.3288  decode.loss_cls: 0.2221  decode.loss_mask: 1.0991  decode.loss_dice: 0.7795  decode.d0.loss_cls: 0.7112  decode.d0.loss_mask: 1.0324  decode.d0.loss_dice: 0.7042  decode.d1.loss_cls: 0.2573  decode.d1.loss_mask: 1.0973  decode.d1.loss_dice: 0.7652  decode.d2.loss_cls: 0.2949  decode.d2.loss_mask: 1.0334  decode.d2.loss_dice: 0.7552  decode.d3.loss_cls: 0.2699  decode.d3.loss_mask: 1.0337  decode.d3.loss_dice: 0.7405  decode.d4.loss_cls: 0.3241  decode.d4.loss_mask: 1.0450  decode.d4.loss_dice: 0.7202  decode.d5.loss_cls: 0.3093  decode.d5.loss_mask: 1.0515  decode.d5.loss_dice: 0.7367  decode.d6.loss_cls: 0.3225  decode.d6.loss_mask: 1.0532  decode.d6.loss_dice: 0.7410  decode.d7.loss_cls: 0.2192  decode.d7.loss_mask: 1.1429  decode.d7.loss_dice: 0.7875  decode.d8.loss_cls: 0.2479  decode.d8.loss_mask: 1.0713  decode.d8.loss_dice: 0.7607
05/26 13:59:06 - mmengine - INFO - Iter(train) [ 26100/160000]  base_lr: 8.5192e-05 lr: 8.5192e-06  eta: 15:16:17  time: 0.4074  data_time: 0.0089  memory: 5975  grad_norm: 779.7839  loss: 24.7454  decode.loss_cls: 0.3856  decode.loss_mask: 1.1592  decode.loss_dice: 0.8748  decode.d0.loss_cls: 0.7923  decode.d0.loss_mask: 1.1362  decode.d0.loss_dice: 0.8795  decode.d1.loss_cls: 0.4284  decode.d1.loss_mask: 1.1527  decode.d1.loss_dice: 0.8987  decode.d2.loss_cls: 0.3879  decode.d2.loss_mask: 1.1191  decode.d2.loss_dice: 0.9186  decode.d3.loss_cls: 0.4074  decode.d3.loss_mask: 1.1148  decode.d3.loss_dice: 0.8650  decode.d4.loss_cls: 0.3990  decode.d4.loss_mask: 1.1368  decode.d4.loss_dice: 0.8682  decode.d5.loss_cls: 0.3948  decode.d5.loss_mask: 1.1398  decode.d5.loss_dice: 0.8937  decode.d6.loss_cls: 0.4352  decode.d6.loss_mask: 1.1419  decode.d6.loss_dice: 0.9138  decode.d7.loss_cls: 0.4053  decode.d7.loss_mask: 1.1806  decode.d7.loss_dice: 0.9063  decode.d8.loss_cls: 0.4015  decode.d8.loss_mask: 1.1492  decode.d8.loss_dice: 0.8594
05/26 13:59:26 - mmengine - INFO - Iter(train) [ 26150/160000]  base_lr: 8.5163e-05 lr: 8.5163e-06  eta: 15:15:56  time: 0.4075  data_time: 0.0089  memory: 5971  grad_norm: 959.9216  loss: 26.8755  decode.loss_cls: 0.3293  decode.loss_mask: 1.2849  decode.loss_dice: 1.0145  decode.d0.loss_cls: 0.8151  decode.d0.loss_mask: 1.2465  decode.d0.loss_dice: 1.0003  decode.d1.loss_cls: 0.3195  decode.d1.loss_mask: 1.2843  decode.d1.loss_dice: 1.0100  decode.d2.loss_cls: 0.3279  decode.d2.loss_mask: 1.3073  decode.d2.loss_dice: 1.0369  decode.d3.loss_cls: 0.3417  decode.d3.loss_mask: 1.2922  decode.d3.loss_dice: 1.0298  decode.d4.loss_cls: 0.4125  decode.d4.loss_mask: 1.3110  decode.d4.loss_dice: 1.0313  decode.d5.loss_cls: 0.3339  decode.d5.loss_mask: 1.3148  decode.d5.loss_dice: 1.0150  decode.d6.loss_cls: 0.3844  decode.d6.loss_mask: 1.2920  decode.d6.loss_dice: 0.9975  decode.d7.loss_cls: 0.2776  decode.d7.loss_mask: 1.2848  decode.d7.loss_dice: 0.9935  decode.d8.loss_cls: 0.3358  decode.d8.loss_mask: 1.2568  decode.d8.loss_dice: 0.9942
05/26 13:59:46 - mmengine - INFO - Iter(train) [ 26200/160000]  base_lr: 8.5134e-05 lr: 8.5134e-06  eta: 15:15:34  time: 0.4075  data_time: 0.0088  memory: 5976  grad_norm: 385.3094  loss: 22.5684  decode.loss_cls: 0.2955  decode.loss_mask: 1.0839  decode.loss_dice: 0.8156  decode.d0.loss_cls: 0.7838  decode.d0.loss_mask: 0.9527  decode.d0.loss_dice: 0.7560  decode.d1.loss_cls: 0.3782  decode.d1.loss_mask: 1.0870  decode.d1.loss_dice: 0.7953  decode.d2.loss_cls: 0.3596  decode.d2.loss_mask: 1.0784  decode.d2.loss_dice: 0.8230  decode.d3.loss_cls: 0.3679  decode.d3.loss_mask: 1.0550  decode.d3.loss_dice: 0.7827  decode.d4.loss_cls: 0.4074  decode.d4.loss_mask: 1.0154  decode.d4.loss_dice: 0.7893  decode.d5.loss_cls: 0.3464  decode.d5.loss_mask: 1.0864  decode.d5.loss_dice: 0.7960  decode.d6.loss_cls: 0.3581  decode.d6.loss_mask: 1.0229  decode.d6.loss_dice: 0.7852  decode.d7.loss_cls: 0.3505  decode.d7.loss_mask: 1.0747  decode.d7.loss_dice: 0.7978  decode.d8.loss_cls: 0.3186  decode.d8.loss_mask: 1.1245  decode.d8.loss_dice: 0.8808
05/26 14:00:07 - mmengine - INFO - Iter(train) [ 26250/160000]  base_lr: 8.5106e-05 lr: 8.5106e-06  eta: 15:15:13  time: 0.4077  data_time: 0.0089  memory: 5966  grad_norm: 864.8487  loss: 28.6054  decode.loss_cls: 0.3038  decode.loss_mask: 1.4988  decode.loss_dice: 1.0232  decode.d0.loss_cls: 0.7183  decode.d0.loss_mask: 1.4379  decode.d0.loss_dice: 1.0261  decode.d1.loss_cls: 0.3240  decode.d1.loss_mask: 1.4130  decode.d1.loss_dice: 1.0125  decode.d2.loss_cls: 0.2986  decode.d2.loss_mask: 1.4241  decode.d2.loss_dice: 1.0516  decode.d3.loss_cls: 0.3204  decode.d3.loss_mask: 1.4359  decode.d3.loss_dice: 1.0206  decode.d4.loss_cls: 0.3845  decode.d4.loss_mask: 1.4563  decode.d4.loss_dice: 1.0095  decode.d5.loss_cls: 0.3016  decode.d5.loss_mask: 1.5418  decode.d5.loss_dice: 1.0481  decode.d6.loss_cls: 0.3188  decode.d6.loss_mask: 1.5248  decode.d6.loss_dice: 1.0318  decode.d7.loss_cls: 0.2553  decode.d7.loss_mask: 1.5176  decode.d7.loss_dice: 1.0411  decode.d8.loss_cls: 0.3438  decode.d8.loss_mask: 1.4968  decode.d8.loss_dice: 1.0250
05/26 14:00:27 - mmengine - INFO - Iter(train) [ 26300/160000]  base_lr: 8.5077e-05 lr: 8.5077e-06  eta: 15:14:52  time: 0.4090  data_time: 0.0090  memory: 5966  grad_norm: 907.4621  loss: 28.5315  decode.loss_cls: 0.4944  decode.loss_mask: 1.2579  decode.loss_dice: 1.0543  decode.d0.loss_cls: 1.0466  decode.d0.loss_mask: 1.1549  decode.d0.loss_dice: 1.0061  decode.d1.loss_cls: 0.5091  decode.d1.loss_mask: 1.2012  decode.d1.loss_dice: 1.0530  decode.d2.loss_cls: 0.4680  decode.d2.loss_mask: 1.2475  decode.d2.loss_dice: 1.0660  decode.d3.loss_cls: 0.5451  decode.d3.loss_mask: 1.2411  decode.d3.loss_dice: 1.0854  decode.d4.loss_cls: 0.5620  decode.d4.loss_mask: 1.1532  decode.d4.loss_dice: 1.0060  decode.d5.loss_cls: 0.5035  decode.d5.loss_mask: 1.2498  decode.d5.loss_dice: 1.1260  decode.d6.loss_cls: 0.5427  decode.d6.loss_mask: 1.1603  decode.d6.loss_dice: 1.0477  decode.d7.loss_cls: 0.5857  decode.d7.loss_mask: 1.1914  decode.d7.loss_dice: 1.0702  decode.d8.loss_cls: 0.5463  decode.d8.loss_mask: 1.2599  decode.d8.loss_dice: 1.0963
05/26 14:00:48 - mmengine - INFO - Iter(train) [ 26350/160000]  base_lr: 8.5048e-05 lr: 8.5048e-06  eta: 15:14:31  time: 0.4113  data_time: 0.0099  memory: 5972  grad_norm: 446.2141  loss: 23.4147  decode.loss_cls: 0.3289  decode.loss_mask: 1.0922  decode.loss_dice: 0.8763  decode.d0.loss_cls: 0.8163  decode.d0.loss_mask: 1.0583  decode.d0.loss_dice: 0.8099  decode.d1.loss_cls: 0.3504  decode.d1.loss_mask: 1.1376  decode.d1.loss_dice: 0.8471  decode.d2.loss_cls: 0.4064  decode.d2.loss_mask: 1.0467  decode.d2.loss_dice: 0.8450  decode.d3.loss_cls: 0.4002  decode.d3.loss_mask: 1.0675  decode.d3.loss_dice: 0.8340  decode.d4.loss_cls: 0.4409  decode.d4.loss_mask: 1.0396  decode.d4.loss_dice: 0.8021  decode.d5.loss_cls: 0.3856  decode.d5.loss_mask: 1.0588  decode.d5.loss_dice: 0.8374  decode.d6.loss_cls: 0.4619  decode.d6.loss_mask: 1.0636  decode.d6.loss_dice: 0.8129  decode.d7.loss_cls: 0.3891  decode.d7.loss_mask: 1.0925  decode.d7.loss_dice: 0.8402  decode.d8.loss_cls: 0.3572  decode.d8.loss_mask: 1.0666  decode.d8.loss_dice: 0.8496
05/26 14:01:08 - mmengine - INFO - Iter(train) [ 26400/160000]  base_lr: 8.5020e-05 lr: 8.5020e-06  eta: 15:14:10  time: 0.4102  data_time: 0.0090  memory: 5986  grad_norm: 642.4096  loss: 25.1478  decode.loss_cls: 0.3744  decode.loss_mask: 1.1257  decode.loss_dice: 0.9122  decode.d0.loss_cls: 0.9311  decode.d0.loss_mask: 1.0311  decode.d0.loss_dice: 0.9383  decode.d1.loss_cls: 0.4437  decode.d1.loss_mask: 1.0628  decode.d1.loss_dice: 0.9331  decode.d2.loss_cls: 0.4300  decode.d2.loss_mask: 1.1078  decode.d2.loss_dice: 0.9908  decode.d3.loss_cls: 0.3885  decode.d3.loss_mask: 1.1848  decode.d3.loss_dice: 0.9342  decode.d4.loss_cls: 0.4529  decode.d4.loss_mask: 1.0989  decode.d4.loss_dice: 0.9632  decode.d5.loss_cls: 0.3991  decode.d5.loss_mask: 1.1707  decode.d5.loss_dice: 0.9258  decode.d6.loss_cls: 0.4234  decode.d6.loss_mask: 1.0933  decode.d6.loss_dice: 0.9620  decode.d7.loss_cls: 0.4416  decode.d7.loss_mask: 1.0562  decode.d7.loss_dice: 0.9327  decode.d8.loss_cls: 0.4917  decode.d8.loss_mask: 1.0282  decode.d8.loss_dice: 0.9195
05/26 14:01:28 - mmengine - INFO - Iter(train) [ 26450/160000]  base_lr: 8.4991e-05 lr: 8.4991e-06  eta: 15:13:49  time: 0.4088  data_time: 0.0090  memory: 5970  grad_norm: 891.0130  loss: 25.3572  decode.loss_cls: 0.2411  decode.loss_mask: 1.3575  decode.loss_dice: 0.9425  decode.d0.loss_cls: 0.6856  decode.d0.loss_mask: 1.2273  decode.d0.loss_dice: 0.8681  decode.d1.loss_cls: 0.2624  decode.d1.loss_mask: 1.2945  decode.d1.loss_dice: 0.9142  decode.d2.loss_cls: 0.2487  decode.d2.loss_mask: 1.2870  decode.d2.loss_dice: 0.8949  decode.d3.loss_cls: 0.2554  decode.d3.loss_mask: 1.2904  decode.d3.loss_dice: 0.8925  decode.d4.loss_cls: 0.3387  decode.d4.loss_mask: 1.3127  decode.d4.loss_dice: 0.9094  decode.d5.loss_cls: 0.2531  decode.d5.loss_mask: 1.4320  decode.d5.loss_dice: 0.9972  decode.d6.loss_cls: 0.2906  decode.d6.loss_mask: 1.2654  decode.d6.loss_dice: 0.9461  decode.d7.loss_cls: 0.2546  decode.d7.loss_mask: 1.2935  decode.d7.loss_dice: 0.9408  decode.d8.loss_cls: 0.2682  decode.d8.loss_mask: 1.2859  decode.d8.loss_dice: 0.9068
05/26 14:01:49 - mmengine - INFO - Iter(train) [ 26500/160000]  base_lr: 8.4963e-05 lr: 8.4963e-06  eta: 15:13:28  time: 0.4070  data_time: 0.0089  memory: 5967  grad_norm: 520.7410  loss: 20.8808  decode.loss_cls: 0.2797  decode.loss_mask: 0.9194  decode.loss_dice: 0.8122  decode.d0.loss_cls: 0.7647  decode.d0.loss_mask: 0.9326  decode.d0.loss_dice: 0.8519  decode.d1.loss_cls: 0.2762  decode.d1.loss_mask: 0.8862  decode.d1.loss_dice: 0.7941  decode.d2.loss_cls: 0.3011  decode.d2.loss_mask: 0.9305  decode.d2.loss_dice: 0.8327  decode.d3.loss_cls: 0.3105  decode.d3.loss_mask: 0.8964  decode.d3.loss_dice: 0.7891  decode.d4.loss_cls: 0.2953  decode.d4.loss_mask: 0.9461  decode.d4.loss_dice: 0.8045  decode.d5.loss_cls: 0.3170  decode.d5.loss_mask: 0.9504  decode.d5.loss_dice: 0.8313  decode.d6.loss_cls: 0.3378  decode.d6.loss_mask: 0.9270  decode.d6.loss_dice: 0.8167  decode.d7.loss_cls: 0.3072  decode.d7.loss_mask: 0.9276  decode.d7.loss_dice: 0.8006  decode.d8.loss_cls: 0.2793  decode.d8.loss_mask: 0.9345  decode.d8.loss_dice: 0.8283
05/26 14:02:09 - mmengine - INFO - Iter(train) [ 26550/160000]  base_lr: 8.4934e-05 lr: 8.4934e-06  eta: 15:13:06  time: 0.4089  data_time: 0.0101  memory: 5969  grad_norm: 460.3830  loss: 24.2210  decode.loss_cls: 0.2764  decode.loss_mask: 1.2110  decode.loss_dice: 0.9404  decode.d0.loss_cls: 0.6538  decode.d0.loss_mask: 1.1354  decode.d0.loss_dice: 0.9103  decode.d1.loss_cls: 0.3223  decode.d1.loss_mask: 1.1297  decode.d1.loss_dice: 0.9101  decode.d2.loss_cls: 0.3217  decode.d2.loss_mask: 1.1790  decode.d2.loss_dice: 0.9359  decode.d3.loss_cls: 0.3498  decode.d3.loss_mask: 1.1059  decode.d3.loss_dice: 0.8915  decode.d4.loss_cls: 0.3651  decode.d4.loss_mask: 1.1327  decode.d4.loss_dice: 0.9031  decode.d5.loss_cls: 0.3488  decode.d5.loss_mask: 1.1303  decode.d5.loss_dice: 0.9270  decode.d6.loss_cls: 0.3200  decode.d6.loss_mask: 1.1306  decode.d6.loss_dice: 0.9136  decode.d7.loss_cls: 0.3058  decode.d7.loss_mask: 1.1838  decode.d7.loss_dice: 0.9374  decode.d8.loss_cls: 0.3140  decode.d8.loss_mask: 1.1236  decode.d8.loss_dice: 0.9119
05/26 14:02:29 - mmengine - INFO - Iter(train) [ 26600/160000]  base_lr: 8.4905e-05 lr: 8.4905e-06  eta: 15:12:45  time: 0.4074  data_time: 0.0090  memory: 5969  grad_norm: 600.1143  loss: 24.8030  decode.loss_cls: 0.3265  decode.loss_mask: 1.1892  decode.loss_dice: 0.8955  decode.d0.loss_cls: 0.8444  decode.d0.loss_mask: 1.1208  decode.d0.loss_dice: 0.8504  decode.d1.loss_cls: 0.3714  decode.d1.loss_mask: 1.1847  decode.d1.loss_dice: 0.8653  decode.d2.loss_cls: 0.3357  decode.d2.loss_mask: 1.1725  decode.d2.loss_dice: 0.8768  decode.d3.loss_cls: 0.3185  decode.d3.loss_mask: 1.2326  decode.d3.loss_dice: 0.9055  decode.d4.loss_cls: 0.3786  decode.d4.loss_mask: 1.1661  decode.d4.loss_dice: 0.8527  decode.d5.loss_cls: 0.3745  decode.d5.loss_mask: 1.1971  decode.d5.loss_dice: 0.9198  decode.d6.loss_cls: 0.3734  decode.d6.loss_mask: 1.1754  decode.d6.loss_dice: 0.9043  decode.d7.loss_cls: 0.2836  decode.d7.loss_mask: 1.3079  decode.d7.loss_dice: 0.9251  decode.d8.loss_cls: 0.3436  decode.d8.loss_mask: 1.1941  decode.d8.loss_dice: 0.9173
05/26 14:02:50 - mmengine - INFO - Iter(train) [ 26650/160000]  base_lr: 8.4877e-05 lr: 8.4877e-06  eta: 15:12:23  time: 0.4064  data_time: 0.0088  memory: 5980  grad_norm: 824.4146  loss: 22.1420  decode.loss_cls: 0.1940  decode.loss_mask: 1.1476  decode.loss_dice: 0.8511  decode.d0.loss_cls: 0.6832  decode.d0.loss_mask: 1.1185  decode.d0.loss_dice: 0.7694  decode.d1.loss_cls: 0.1850  decode.d1.loss_mask: 1.1400  decode.d1.loss_dice: 0.8216  decode.d2.loss_cls: 0.2423  decode.d2.loss_mask: 1.1056  decode.d2.loss_dice: 0.8195  decode.d3.loss_cls: 0.1750  decode.d3.loss_mask: 1.1748  decode.d3.loss_dice: 0.8500  decode.d4.loss_cls: 0.1783  decode.d4.loss_mask: 1.1500  decode.d4.loss_dice: 0.8170  decode.d5.loss_cls: 0.1640  decode.d5.loss_mask: 1.1688  decode.d5.loss_dice: 0.8271  decode.d6.loss_cls: 0.2228  decode.d6.loss_mask: 1.1487  decode.d6.loss_dice: 0.8227  decode.d7.loss_cls: 0.2044  decode.d7.loss_mask: 1.1703  decode.d7.loss_dice: 0.8426  decode.d8.loss_cls: 0.2000  decode.d8.loss_mask: 1.1216  decode.d8.loss_dice: 0.8260
05/26 14:03:10 - mmengine - INFO - Iter(train) [ 26700/160000]  base_lr: 8.4848e-05 lr: 8.4848e-06  eta: 15:12:02  time: 0.4072  data_time: 0.0088  memory: 5971  grad_norm: 925.4951  loss: 24.5558  decode.loss_cls: 0.2144  decode.loss_mask: 1.2497  decode.loss_dice: 0.9010  decode.d0.loss_cls: 0.7910  decode.d0.loss_mask: 1.2373  decode.d0.loss_dice: 0.8424  decode.d1.loss_cls: 0.2820  decode.d1.loss_mask: 1.2395  decode.d1.loss_dice: 0.8843  decode.d2.loss_cls: 0.2820  decode.d2.loss_mask: 1.2507  decode.d2.loss_dice: 0.8652  decode.d3.loss_cls: 0.2619  decode.d3.loss_mask: 1.2597  decode.d3.loss_dice: 0.8870  decode.d4.loss_cls: 0.2990  decode.d4.loss_mask: 1.2535  decode.d4.loss_dice: 0.8664  decode.d5.loss_cls: 0.3041  decode.d5.loss_mask: 1.2246  decode.d5.loss_dice: 0.8658  decode.d6.loss_cls: 0.3504  decode.d6.loss_mask: 1.2180  decode.d6.loss_dice: 0.8924  decode.d7.loss_cls: 0.2546  decode.d7.loss_mask: 1.2607  decode.d7.loss_dice: 0.9125  decode.d8.loss_cls: 0.2610  decode.d8.loss_mask: 1.2350  decode.d8.loss_dice: 0.9094
05/26 14:03:31 - mmengine - INFO - Iter(train) [ 26750/160000]  base_lr: 8.4819e-05 lr: 8.4819e-06  eta: 15:11:41  time: 0.4100  data_time: 0.0091  memory: 5967  grad_norm: 787.3246  loss: 21.4496  decode.loss_cls: 0.2069  decode.loss_mask: 1.0828  decode.loss_dice: 0.7832  decode.d0.loss_cls: 0.6879  decode.d0.loss_mask: 1.0362  decode.d0.loss_dice: 0.7559  decode.d1.loss_cls: 0.2642  decode.d1.loss_mask: 1.1231  decode.d1.loss_dice: 0.7914  decode.d2.loss_cls: 0.2470  decode.d2.loss_mask: 1.1301  decode.d2.loss_dice: 0.8047  decode.d3.loss_cls: 0.2950  decode.d3.loss_mask: 1.0713  decode.d3.loss_dice: 0.7705  decode.d4.loss_cls: 0.2679  decode.d4.loss_mask: 1.0720  decode.d4.loss_dice: 0.7458  decode.d5.loss_cls: 0.2828  decode.d5.loss_mask: 1.0408  decode.d5.loss_dice: 0.7441  decode.d6.loss_cls: 0.3130  decode.d6.loss_mask: 1.0644  decode.d6.loss_dice: 0.7416  decode.d7.loss_cls: 0.2769  decode.d7.loss_mask: 1.0230  decode.d7.loss_dice: 0.7417  decode.d8.loss_cls: 0.2591  decode.d8.loss_mask: 1.0669  decode.d8.loss_dice: 0.7594
05/26 14:03:51 - mmengine - INFO - Iter(train) [ 26800/160000]  base_lr: 8.4791e-05 lr: 8.4791e-06  eta: 15:11:20  time: 0.4073  data_time: 0.0089  memory: 5972  grad_norm: 698.2508  loss: 27.6718  decode.loss_cls: 0.3685  decode.loss_mask: 1.4045  decode.loss_dice: 0.9604  decode.d0.loss_cls: 0.8356  decode.d0.loss_mask: 1.3331  decode.d0.loss_dice: 0.9391  decode.d1.loss_cls: 0.3650  decode.d1.loss_mask: 1.4150  decode.d1.loss_dice: 1.0057  decode.d2.loss_cls: 0.3715  decode.d2.loss_mask: 1.3868  decode.d2.loss_dice: 0.9574  decode.d3.loss_cls: 0.3789  decode.d3.loss_mask: 1.3917  decode.d3.loss_dice: 0.9451  decode.d4.loss_cls: 0.3455  decode.d4.loss_mask: 1.4040  decode.d4.loss_dice: 0.9397  decode.d5.loss_cls: 0.3747  decode.d5.loss_mask: 1.3899  decode.d5.loss_dice: 0.9375  decode.d6.loss_cls: 0.4044  decode.d6.loss_mask: 1.3814  decode.d6.loss_dice: 0.9490  decode.d7.loss_cls: 0.3786  decode.d7.loss_mask: 1.4205  decode.d7.loss_dice: 0.9363  decode.d8.loss_cls: 0.3490  decode.d8.loss_mask: 1.4331  decode.d8.loss_dice: 0.9699
05/26 14:04:11 - mmengine - INFO - Iter(train) [ 26850/160000]  base_lr: 8.4762e-05 lr: 8.4762e-06  eta: 15:10:58  time: 0.4067  data_time: 0.0089  memory: 5971  grad_norm: 569.8668  loss: 23.6507  decode.loss_cls: 0.3183  decode.loss_mask: 1.2014  decode.loss_dice: 0.8363  decode.d0.loss_cls: 0.7720  decode.d0.loss_mask: 1.0711  decode.d0.loss_dice: 0.7868  decode.d1.loss_cls: 0.3028  decode.d1.loss_mask: 1.1594  decode.d1.loss_dice: 0.8259  decode.d2.loss_cls: 0.3461  decode.d2.loss_mask: 1.1678  decode.d2.loss_dice: 0.8382  decode.d3.loss_cls: 0.2994  decode.d3.loss_mask: 1.1846  decode.d3.loss_dice: 0.8220  decode.d4.loss_cls: 0.3369  decode.d4.loss_mask: 1.1709  decode.d4.loss_dice: 0.8163  decode.d5.loss_cls: 0.3660  decode.d5.loss_mask: 1.1673  decode.d5.loss_dice: 0.8239  decode.d6.loss_cls: 0.3292  decode.d6.loss_mask: 1.2046  decode.d6.loss_dice: 0.8461  decode.d7.loss_cls: 0.2666  decode.d7.loss_mask: 1.2006  decode.d7.loss_dice: 0.8419  decode.d8.loss_cls: 0.2987  decode.d8.loss_mask: 1.1924  decode.d8.loss_dice: 0.8575
05/26 14:04:32 - mmengine - INFO - Iter(train) [ 26900/160000]  base_lr: 8.4733e-05 lr: 8.4733e-06  eta: 15:10:37  time: 0.4069  data_time: 0.0090  memory: 5967  grad_norm: 471.1347  loss: 27.2443  decode.loss_cls: 0.3721  decode.loss_mask: 1.3714  decode.loss_dice: 0.9958  decode.d0.loss_cls: 0.8815  decode.d0.loss_mask: 1.2160  decode.d0.loss_dice: 0.9683  decode.d1.loss_cls: 0.3923  decode.d1.loss_mask: 1.3168  decode.d1.loss_dice: 0.9813  decode.d2.loss_cls: 0.3658  decode.d2.loss_mask: 1.3072  decode.d2.loss_dice: 0.9974  decode.d3.loss_cls: 0.3741  decode.d3.loss_mask: 1.3071  decode.d3.loss_dice: 0.9726  decode.d4.loss_cls: 0.3968  decode.d4.loss_mask: 1.2651  decode.d4.loss_dice: 0.9740  decode.d5.loss_cls: 0.3809  decode.d5.loss_mask: 1.2950  decode.d5.loss_dice: 0.9965  decode.d6.loss_cls: 0.4595  decode.d6.loss_mask: 1.2891  decode.d6.loss_dice: 0.9939  decode.d7.loss_cls: 0.3848  decode.d7.loss_mask: 1.2882  decode.d7.loss_dice: 0.9725  decode.d8.loss_cls: 0.4058  decode.d8.loss_mask: 1.3283  decode.d8.loss_dice: 0.9940
05/26 14:04:52 - mmengine - INFO - Iter(train) [ 26950/160000]  base_lr: 8.4705e-05 lr: 8.4705e-06  eta: 15:10:15  time: 0.4074  data_time: 0.0088  memory: 5971  grad_norm: 684.8946  loss: 23.9444  decode.loss_cls: 0.3552  decode.loss_mask: 1.2411  decode.loss_dice: 0.8638  decode.d0.loss_cls: 0.7537  decode.d0.loss_mask: 1.0855  decode.d0.loss_dice: 0.7642  decode.d1.loss_cls: 0.4239  decode.d1.loss_mask: 1.1497  decode.d1.loss_dice: 0.7719  decode.d2.loss_cls: 0.3756  decode.d2.loss_mask: 1.1285  decode.d2.loss_dice: 0.7885  decode.d3.loss_cls: 0.4000  decode.d3.loss_mask: 1.1310  decode.d3.loss_dice: 0.7621  decode.d4.loss_cls: 0.3957  decode.d4.loss_mask: 1.1538  decode.d4.loss_dice: 0.8119  decode.d5.loss_cls: 0.3651  decode.d5.loss_mask: 1.1890  decode.d5.loss_dice: 0.7689  decode.d6.loss_cls: 0.3901  decode.d6.loss_mask: 1.2051  decode.d6.loss_dice: 0.8196  decode.d7.loss_cls: 0.3995  decode.d7.loss_mask: 1.1920  decode.d7.loss_dice: 0.8210  decode.d8.loss_cls: 0.3767  decode.d8.loss_mask: 1.2371  decode.d8.loss_dice: 0.8242
05/26 14:05:12 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 14:05:12 - mmengine - INFO - Iter(train) [ 27000/160000]  base_lr: 8.4676e-05 lr: 8.4676e-06  eta: 15:09:54  time: 0.4062  data_time: 0.0088  memory: 5970  grad_norm: 680.2319  loss: 29.5541  decode.loss_cls: 0.3657  decode.loss_mask: 1.4803  decode.loss_dice: 1.0808  decode.d0.loss_cls: 0.7841  decode.d0.loss_mask: 1.5386  decode.d0.loss_dice: 1.0968  decode.d1.loss_cls: 0.3412  decode.d1.loss_mask: 1.5001  decode.d1.loss_dice: 1.0599  decode.d2.loss_cls: 0.3077  decode.d2.loss_mask: 1.5147  decode.d2.loss_dice: 1.0570  decode.d3.loss_cls: 0.2792  decode.d3.loss_mask: 1.5139  decode.d3.loss_dice: 1.0343  decode.d4.loss_cls: 0.3886  decode.d4.loss_mask: 1.5183  decode.d4.loss_dice: 1.0256  decode.d5.loss_cls: 0.3189  decode.d5.loss_mask: 1.5429  decode.d5.loss_dice: 1.0686  decode.d6.loss_cls: 0.3516  decode.d6.loss_mask: 1.4859  decode.d6.loss_dice: 1.0736  decode.d7.loss_cls: 0.3586  decode.d7.loss_mask: 1.5187  decode.d7.loss_dice: 1.0170  decode.d8.loss_cls: 0.3850  decode.d8.loss_mask: 1.5064  decode.d8.loss_dice: 1.0397
05/26 14:05:33 - mmengine - INFO - Iter(train) [ 27050/160000]  base_lr: 8.4647e-05 lr: 8.4647e-06  eta: 15:09:33  time: 0.4066  data_time: 0.0089  memory: 5980  grad_norm: 617.4352  loss: 22.2790  decode.loss_cls: 0.2743  decode.loss_mask: 1.1604  decode.loss_dice: 0.8181  decode.d0.loss_cls: 0.8043  decode.d0.loss_mask: 0.9732  decode.d0.loss_dice: 0.7603  decode.d1.loss_cls: 0.3129  decode.d1.loss_mask: 1.0815  decode.d1.loss_dice: 0.8014  decode.d2.loss_cls: 0.2537  decode.d2.loss_mask: 1.1134  decode.d2.loss_dice: 0.8034  decode.d3.loss_cls: 0.2465  decode.d3.loss_mask: 1.1174  decode.d3.loss_dice: 0.7946  decode.d4.loss_cls: 0.2873  decode.d4.loss_mask: 1.0781  decode.d4.loss_dice: 0.7791  decode.d5.loss_cls: 0.3138  decode.d5.loss_mask: 1.0600  decode.d5.loss_dice: 0.7938  decode.d6.loss_cls: 0.3013  decode.d6.loss_mask: 1.1234  decode.d6.loss_dice: 0.8225  decode.d7.loss_cls: 0.2792  decode.d7.loss_mask: 1.1245  decode.d7.loss_dice: 0.7911  decode.d8.loss_cls: 0.2624  decode.d8.loss_mask: 1.1011  decode.d8.loss_dice: 0.8461
05/26 14:05:53 - mmengine - INFO - Iter(train) [ 27100/160000]  base_lr: 8.4619e-05 lr: 8.4619e-06  eta: 15:09:11  time: 0.4075  data_time: 0.0089  memory: 5980  grad_norm: 1200.8181  loss: 26.1599  decode.loss_cls: 0.2775  decode.loss_mask: 1.2859  decode.loss_dice: 0.9777  decode.d0.loss_cls: 0.8347  decode.d0.loss_mask: 1.1869  decode.d0.loss_dice: 0.8742  decode.d1.loss_cls: 0.3377  decode.d1.loss_mask: 1.3323  decode.d1.loss_dice: 0.9319  decode.d2.loss_cls: 0.2998  decode.d2.loss_mask: 1.3373  decode.d2.loss_dice: 0.9374  decode.d3.loss_cls: 0.2326  decode.d3.loss_mask: 1.4041  decode.d3.loss_dice: 0.9677  decode.d4.loss_cls: 0.3164  decode.d4.loss_mask: 1.3188  decode.d4.loss_dice: 0.9509  decode.d5.loss_cls: 0.3378  decode.d5.loss_mask: 1.3114  decode.d5.loss_dice: 0.9617  decode.d6.loss_cls: 0.3418  decode.d6.loss_mask: 1.2614  decode.d6.loss_dice: 0.9382  decode.d7.loss_cls: 0.2753  decode.d7.loss_mask: 1.3925  decode.d7.loss_dice: 0.9340  decode.d8.loss_cls: 0.2991  decode.d8.loss_mask: 1.3176  decode.d8.loss_dice: 0.9854
05/26 14:06:13 - mmengine - INFO - Iter(train) [ 27150/160000]  base_lr: 8.4590e-05 lr: 8.4590e-06  eta: 15:08:50  time: 0.4078  data_time: 0.0090  memory: 5966  grad_norm: 599.4969  loss: 24.0475  decode.loss_cls: 0.2838  decode.loss_mask: 1.2264  decode.loss_dice: 0.8669  decode.d0.loss_cls: 0.8179  decode.d0.loss_mask: 1.1905  decode.d0.loss_dice: 0.8018  decode.d1.loss_cls: 0.2822  decode.d1.loss_mask: 1.2244  decode.d1.loss_dice: 0.8583  decode.d2.loss_cls: 0.2531  decode.d2.loss_mask: 1.2543  decode.d2.loss_dice: 0.8583  decode.d3.loss_cls: 0.2418  decode.d3.loss_mask: 1.2454  decode.d3.loss_dice: 0.8581  decode.d4.loss_cls: 0.3214  decode.d4.loss_mask: 1.2181  decode.d4.loss_dice: 0.8676  decode.d5.loss_cls: 0.2444  decode.d5.loss_mask: 1.2259  decode.d5.loss_dice: 0.8400  decode.d6.loss_cls: 0.2891  decode.d6.loss_mask: 1.2361  decode.d6.loss_dice: 0.8756  decode.d7.loss_cls: 0.2288  decode.d7.loss_mask: 1.2346  decode.d7.loss_dice: 0.8706  decode.d8.loss_cls: 0.2418  decode.d8.loss_mask: 1.2227  decode.d8.loss_dice: 0.8678
05/26 14:06:34 - mmengine - INFO - Iter(train) [ 27200/160000]  base_lr: 8.4562e-05 lr: 8.4562e-06  eta: 15:08:28  time: 0.4055  data_time: 0.0089  memory: 5968  grad_norm: 591.3978  loss: 24.8347  decode.loss_cls: 0.4620  decode.loss_mask: 1.1061  decode.loss_dice: 0.9097  decode.d0.loss_cls: 0.9009  decode.d0.loss_mask: 1.0716  decode.d0.loss_dice: 0.8563  decode.d1.loss_cls: 0.4607  decode.d1.loss_mask: 1.0871  decode.d1.loss_dice: 0.8622  decode.d2.loss_cls: 0.3695  decode.d2.loss_mask: 1.0919  decode.d2.loss_dice: 0.8818  decode.d3.loss_cls: 0.4076  decode.d3.loss_mask: 1.1161  decode.d3.loss_dice: 0.9194  decode.d4.loss_cls: 0.5205  decode.d4.loss_mask: 1.0871  decode.d4.loss_dice: 0.8837  decode.d5.loss_cls: 0.4630  decode.d5.loss_mask: 1.0941  decode.d5.loss_dice: 0.9296  decode.d6.loss_cls: 0.5304  decode.d6.loss_mask: 1.0700  decode.d6.loss_dice: 0.8978  decode.d7.loss_cls: 0.4454  decode.d7.loss_mask: 1.0911  decode.d7.loss_dice: 0.8881  decode.d8.loss_cls: 0.4014  decode.d8.loss_mask: 1.1436  decode.d8.loss_dice: 0.8859
05/26 14:06:54 - mmengine - INFO - Iter(train) [ 27250/160000]  base_lr: 8.4533e-05 lr: 8.4533e-06  eta: 15:08:07  time: 0.4066  data_time: 0.0089  memory: 5992  grad_norm: 738.2297  loss: 31.5058  decode.loss_cls: 0.4592  decode.loss_mask: 1.4963  decode.loss_dice: 1.1359  decode.d0.loss_cls: 0.9182  decode.d0.loss_mask: 1.4018  decode.d0.loss_dice: 1.0946  decode.d1.loss_cls: 0.4849  decode.d1.loss_mask: 1.5048  decode.d1.loss_dice: 1.1743  decode.d2.loss_cls: 0.5076  decode.d2.loss_mask: 1.4753  decode.d2.loss_dice: 1.1125  decode.d3.loss_cls: 0.4610  decode.d3.loss_mask: 1.4864  decode.d3.loss_dice: 1.1681  decode.d4.loss_cls: 0.5415  decode.d4.loss_mask: 1.4560  decode.d4.loss_dice: 1.1273  decode.d5.loss_cls: 0.5020  decode.d5.loss_mask: 1.5366  decode.d5.loss_dice: 1.1415  decode.d6.loss_cls: 0.4903  decode.d6.loss_mask: 1.4805  decode.d6.loss_dice: 1.1483  decode.d7.loss_cls: 0.4595  decode.d7.loss_mask: 1.4841  decode.d7.loss_dice: 1.1309  decode.d8.loss_cls: 0.4797  decode.d8.loss_mask: 1.5002  decode.d8.loss_dice: 1.1461
05/26 14:07:14 - mmengine - INFO - Iter(train) [ 27300/160000]  base_lr: 8.4504e-05 lr: 8.4504e-06  eta: 15:07:45  time: 0.4063  data_time: 0.0089  memory: 5967  grad_norm: 526.8814  loss: 23.6364  decode.loss_cls: 0.2689  decode.loss_mask: 1.2328  decode.loss_dice: 0.7817  decode.d0.loss_cls: 0.7530  decode.d0.loss_mask: 1.1685  decode.d0.loss_dice: 0.7965  decode.d1.loss_cls: 0.3109  decode.d1.loss_mask: 1.2125  decode.d1.loss_dice: 0.8119  decode.d2.loss_cls: 0.2761  decode.d2.loss_mask: 1.2553  decode.d2.loss_dice: 0.7992  decode.d3.loss_cls: 0.2362  decode.d3.loss_mask: 1.2296  decode.d3.loss_dice: 0.8206  decode.d4.loss_cls: 0.2940  decode.d4.loss_mask: 1.2794  decode.d4.loss_dice: 0.8116  decode.d5.loss_cls: 0.2822  decode.d5.loss_mask: 1.2537  decode.d5.loss_dice: 0.8199  decode.d6.loss_cls: 0.2881  decode.d6.loss_mask: 1.2199  decode.d6.loss_dice: 0.8072  decode.d7.loss_cls: 0.2327  decode.d7.loss_mask: 1.2563  decode.d7.loss_dice: 0.8323  decode.d8.loss_cls: 0.2540  decode.d8.loss_mask: 1.2580  decode.d8.loss_dice: 0.7935
05/26 14:07:35 - mmengine - INFO - Iter(train) [ 27350/160000]  base_lr: 8.4476e-05 lr: 8.4476e-06  eta: 15:07:24  time: 0.4056  data_time: 0.0089  memory: 5980  grad_norm: 554.3190  loss: 22.4633  decode.loss_cls: 0.2012  decode.loss_mask: 1.1216  decode.loss_dice: 0.8064  decode.d0.loss_cls: 0.6949  decode.d0.loss_mask: 1.1028  decode.d0.loss_dice: 0.8237  decode.d1.loss_cls: 0.2479  decode.d1.loss_mask: 1.1402  decode.d1.loss_dice: 0.8125  decode.d2.loss_cls: 0.3045  decode.d2.loss_mask: 1.1194  decode.d2.loss_dice: 0.7748  decode.d3.loss_cls: 0.2817  decode.d3.loss_mask: 1.0912  decode.d3.loss_dice: 0.7724  decode.d4.loss_cls: 0.2998  decode.d4.loss_mask: 1.1254  decode.d4.loss_dice: 0.8081  decode.d5.loss_cls: 0.3328  decode.d5.loss_mask: 1.1213  decode.d5.loss_dice: 0.7815  decode.d6.loss_cls: 0.2767  decode.d6.loss_mask: 1.1423  decode.d6.loss_dice: 0.8209  decode.d7.loss_cls: 0.2672  decode.d7.loss_mask: 1.1000  decode.d7.loss_dice: 0.8129  decode.d8.loss_cls: 0.2489  decode.d8.loss_mask: 1.1592  decode.d8.loss_dice: 0.8709
05/26 14:07:55 - mmengine - INFO - Iter(train) [ 27400/160000]  base_lr: 8.4447e-05 lr: 8.4447e-06  eta: 15:07:02  time: 0.4058  data_time: 0.0089  memory: 5971  grad_norm: 616.4606  loss: 23.2580  decode.loss_cls: 0.2752  decode.loss_mask: 1.1331  decode.loss_dice: 0.8233  decode.d0.loss_cls: 0.8015  decode.d0.loss_mask: 1.1413  decode.d0.loss_dice: 0.8242  decode.d1.loss_cls: 0.2612  decode.d1.loss_mask: 1.1847  decode.d1.loss_dice: 0.8451  decode.d2.loss_cls: 0.2651  decode.d2.loss_mask: 1.1661  decode.d2.loss_dice: 0.8373  decode.d3.loss_cls: 0.2359  decode.d3.loss_mask: 1.1619  decode.d3.loss_dice: 0.8392  decode.d4.loss_cls: 0.3693  decode.d4.loss_mask: 1.1612  decode.d4.loss_dice: 0.8286  decode.d5.loss_cls: 0.2851  decode.d5.loss_mask: 1.1700  decode.d5.loss_dice: 0.8382  decode.d6.loss_cls: 0.2673  decode.d6.loss_mask: 1.1819  decode.d6.loss_dice: 0.8471  decode.d7.loss_cls: 0.2934  decode.d7.loss_mask: 1.1442  decode.d7.loss_dice: 0.8322  decode.d8.loss_cls: 0.2875  decode.d8.loss_mask: 1.1184  decode.d8.loss_dice: 0.8383
05/26 14:08:15 - mmengine - INFO - Iter(train) [ 27450/160000]  base_lr: 8.4418e-05 lr: 8.4418e-06  eta: 15:06:41  time: 0.4055  data_time: 0.0088  memory: 5969  grad_norm: 822.1712  loss: 26.2514  decode.loss_cls: 0.2162  decode.loss_mask: 1.6565  decode.loss_dice: 0.8519  decode.d0.loss_cls: 0.7869  decode.d0.loss_mask: 1.3925  decode.d0.loss_dice: 0.8129  decode.d1.loss_cls: 0.2906  decode.d1.loss_mask: 1.3807  decode.d1.loss_dice: 0.8411  decode.d2.loss_cls: 0.3526  decode.d2.loss_mask: 1.3608  decode.d2.loss_dice: 0.8342  decode.d3.loss_cls: 0.2881  decode.d3.loss_mask: 1.4445  decode.d3.loss_dice: 0.8256  decode.d4.loss_cls: 0.3226  decode.d4.loss_mask: 1.3680  decode.d4.loss_dice: 0.8290  decode.d5.loss_cls: 0.2982  decode.d5.loss_mask: 1.4417  decode.d5.loss_dice: 0.8503  decode.d6.loss_cls: 0.2674  decode.d6.loss_mask: 1.4796  decode.d6.loss_dice: 0.8601  decode.d7.loss_cls: 0.2950  decode.d7.loss_mask: 1.4742  decode.d7.loss_dice: 0.8616  decode.d8.loss_cls: 0.2719  decode.d8.loss_mask: 1.4538  decode.d8.loss_dice: 0.8427
05/26 14:08:36 - mmengine - INFO - Iter(train) [ 27500/160000]  base_lr: 8.4390e-05 lr: 8.4390e-06  eta: 15:06:19  time: 0.4062  data_time: 0.0090  memory: 5969  grad_norm: 479.4545  loss: 21.2001  decode.loss_cls: 0.2901  decode.loss_mask: 0.9868  decode.loss_dice: 0.8168  decode.d0.loss_cls: 0.6318  decode.d0.loss_mask: 0.9686  decode.d0.loss_dice: 0.8197  decode.d1.loss_cls: 0.2540  decode.d1.loss_mask: 0.9754  decode.d1.loss_dice: 0.8286  decode.d2.loss_cls: 0.3258  decode.d2.loss_mask: 0.9651  decode.d2.loss_dice: 0.7932  decode.d3.loss_cls: 0.2773  decode.d3.loss_mask: 0.9723  decode.d3.loss_dice: 0.8269  decode.d4.loss_cls: 0.2674  decode.d4.loss_mask: 0.9783  decode.d4.loss_dice: 0.8440  decode.d5.loss_cls: 0.2586  decode.d5.loss_mask: 0.9690  decode.d5.loss_dice: 0.8126  decode.d6.loss_cls: 0.3037  decode.d6.loss_mask: 0.9817  decode.d6.loss_dice: 0.8287  decode.d7.loss_cls: 0.3228  decode.d7.loss_mask: 0.9687  decode.d7.loss_dice: 0.8162  decode.d8.loss_cls: 0.3090  decode.d8.loss_mask: 0.9780  decode.d8.loss_dice: 0.8288
05/26 14:08:56 - mmengine - INFO - Iter(train) [ 27550/160000]  base_lr: 8.4361e-05 lr: 8.4361e-06  eta: 15:05:58  time: 0.4085  data_time: 0.0091  memory: 5968  grad_norm: 1034.9516  loss: 23.9755  decode.loss_cls: 0.2974  decode.loss_mask: 1.2034  decode.loss_dice: 0.8997  decode.d0.loss_cls: 0.7303  decode.d0.loss_mask: 1.0936  decode.d0.loss_dice: 0.8175  decode.d1.loss_cls: 0.2929  decode.d1.loss_mask: 1.2145  decode.d1.loss_dice: 0.8867  decode.d2.loss_cls: 0.3395  decode.d2.loss_mask: 1.1460  decode.d2.loss_dice: 0.8540  decode.d3.loss_cls: 0.3464  decode.d3.loss_mask: 1.1723  decode.d3.loss_dice: 0.8556  decode.d4.loss_cls: 0.4099  decode.d4.loss_mask: 1.1374  decode.d4.loss_dice: 0.8648  decode.d5.loss_cls: 0.3442  decode.d5.loss_mask: 1.1519  decode.d5.loss_dice: 0.8505  decode.d6.loss_cls: 0.2865  decode.d6.loss_mask: 1.1935  decode.d6.loss_dice: 0.8483  decode.d7.loss_cls: 0.3451  decode.d7.loss_mask: 1.1547  decode.d7.loss_dice: 0.8723  decode.d8.loss_cls: 0.2926  decode.d8.loss_mask: 1.2032  decode.d8.loss_dice: 0.8709
05/26 14:09:16 - mmengine - INFO - Iter(train) [ 27600/160000]  base_lr: 8.4332e-05 lr: 8.4332e-06  eta: 15:05:37  time: 0.4068  data_time: 0.0089  memory: 5968  grad_norm: 797.4398  loss: 27.7002  decode.loss_cls: 0.3440  decode.loss_mask: 1.3549  decode.loss_dice: 1.0075  decode.d0.loss_cls: 0.8812  decode.d0.loss_mask: 1.2783  decode.d0.loss_dice: 0.9424  decode.d1.loss_cls: 0.3464  decode.d1.loss_mask: 1.3586  decode.d1.loss_dice: 1.0026  decode.d2.loss_cls: 0.3672  decode.d2.loss_mask: 1.3547  decode.d2.loss_dice: 0.9906  decode.d3.loss_cls: 0.4066  decode.d3.loss_mask: 1.3230  decode.d3.loss_dice: 0.9756  decode.d4.loss_cls: 0.3704  decode.d4.loss_mask: 1.3785  decode.d4.loss_dice: 1.0547  decode.d5.loss_cls: 0.3719  decode.d5.loss_mask: 1.3580  decode.d5.loss_dice: 1.0042  decode.d6.loss_cls: 0.3999  decode.d6.loss_mask: 1.3582  decode.d6.loss_dice: 1.0059  decode.d7.loss_cls: 0.3664  decode.d7.loss_mask: 1.3582  decode.d7.loss_dice: 1.0152  decode.d8.loss_cls: 0.3360  decode.d8.loss_mask: 1.3697  decode.d8.loss_dice: 1.0193
05/26 14:09:37 - mmengine - INFO - Iter(train) [ 27650/160000]  base_lr: 8.4304e-05 lr: 8.4304e-06  eta: 15:05:15  time: 0.4045  data_time: 0.0088  memory: 5986  grad_norm: 1015.4647  loss: 27.7739  decode.loss_cls: 0.3950  decode.loss_mask: 1.3694  decode.loss_dice: 0.9384  decode.d0.loss_cls: 0.8618  decode.d0.loss_mask: 1.3001  decode.d0.loss_dice: 0.9603  decode.d1.loss_cls: 0.4321  decode.d1.loss_mask: 1.3192  decode.d1.loss_dice: 0.9795  decode.d2.loss_cls: 0.4588  decode.d2.loss_mask: 1.3367  decode.d2.loss_dice: 0.9179  decode.d3.loss_cls: 0.4601  decode.d3.loss_mask: 1.4173  decode.d3.loss_dice: 0.9529  decode.d4.loss_cls: 0.4856  decode.d4.loss_mask: 1.3335  decode.d4.loss_dice: 0.9280  decode.d5.loss_cls: 0.5185  decode.d5.loss_mask: 1.3669  decode.d5.loss_dice: 0.9442  decode.d6.loss_cls: 0.4943  decode.d6.loss_mask: 1.3347  decode.d6.loss_dice: 0.9535  decode.d7.loss_cls: 0.3756  decode.d7.loss_mask: 1.3971  decode.d7.loss_dice: 0.9380  decode.d8.loss_cls: 0.4063  decode.d8.loss_mask: 1.3047  decode.d8.loss_dice: 0.8934
05/26 14:09:57 - mmengine - INFO - Iter(train) [ 27700/160000]  base_lr: 8.4275e-05 lr: 8.4275e-06  eta: 15:04:54  time: 0.4045  data_time: 0.0088  memory: 5966  grad_norm: 1411.5277  loss: 24.0006  decode.loss_cls: 0.2367  decode.loss_mask: 1.3174  decode.loss_dice: 0.8161  decode.d0.loss_cls: 0.6901  decode.d0.loss_mask: 1.1631  decode.d0.loss_dice: 0.7438  decode.d1.loss_cls: 0.2633  decode.d1.loss_mask: 1.2979  decode.d1.loss_dice: 0.8056  decode.d2.loss_cls: 0.2252  decode.d2.loss_mask: 1.3168  decode.d2.loss_dice: 0.8440  decode.d3.loss_cls: 0.2710  decode.d3.loss_mask: 1.3015  decode.d3.loss_dice: 0.8285  decode.d4.loss_cls: 0.3057  decode.d4.loss_mask: 1.2335  decode.d4.loss_dice: 0.8061  decode.d5.loss_cls: 0.2743  decode.d5.loss_mask: 1.2772  decode.d5.loss_dice: 0.7793  decode.d6.loss_cls: 0.2663  decode.d6.loss_mask: 1.3081  decode.d6.loss_dice: 0.8187  decode.d7.loss_cls: 0.2503  decode.d7.loss_mask: 1.3408  decode.d7.loss_dice: 0.8206  decode.d8.loss_cls: 0.2412  decode.d8.loss_mask: 1.3173  decode.d8.loss_dice: 0.8402
05/26 14:10:17 - mmengine - INFO - Iter(train) [ 27750/160000]  base_lr: 8.4246e-05 lr: 8.4246e-06  eta: 15:04:32  time: 0.4045  data_time: 0.0087  memory: 5966  grad_norm: 565.0385  loss: 24.7296  decode.loss_cls: 0.2945  decode.loss_mask: 1.1894  decode.loss_dice: 0.9402  decode.d0.loss_cls: 0.7394  decode.d0.loss_mask: 1.1780  decode.d0.loss_dice: 0.9559  decode.d1.loss_cls: 0.2749  decode.d1.loss_mask: 1.2016  decode.d1.loss_dice: 0.9429  decode.d2.loss_cls: 0.2647  decode.d2.loss_mask: 1.1593  decode.d2.loss_dice: 0.9405  decode.d3.loss_cls: 0.3264  decode.d3.loss_mask: 1.1784  decode.d3.loss_dice: 0.9621  decode.d4.loss_cls: 0.3235  decode.d4.loss_mask: 1.1699  decode.d4.loss_dice: 0.9865  decode.d5.loss_cls: 0.3396  decode.d5.loss_mask: 1.1743  decode.d5.loss_dice: 0.9352  decode.d6.loss_cls: 0.3188  decode.d6.loss_mask: 1.1497  decode.d6.loss_dice: 0.9235  decode.d7.loss_cls: 0.3123  decode.d7.loss_mask: 1.1774  decode.d7.loss_dice: 0.9518  decode.d8.loss_cls: 0.2558  decode.d8.loss_mask: 1.2044  decode.d8.loss_dice: 0.9587
05/26 14:10:38 - mmengine - INFO - Iter(train) [ 27800/160000]  base_lr: 8.4218e-05 lr: 8.4218e-06  eta: 15:04:10  time: 0.4049  data_time: 0.0088  memory: 5973  grad_norm: 707.9395  loss: 23.0040  decode.loss_cls: 0.3035  decode.loss_mask: 1.0664  decode.loss_dice: 0.8338  decode.d0.loss_cls: 0.7525  decode.d0.loss_mask: 1.1336  decode.d0.loss_dice: 0.8503  decode.d1.loss_cls: 0.3004  decode.d1.loss_mask: 1.1151  decode.d1.loss_dice: 0.8179  decode.d2.loss_cls: 0.3153  decode.d2.loss_mask: 1.1212  decode.d2.loss_dice: 0.8327  decode.d3.loss_cls: 0.3148  decode.d3.loss_mask: 1.1031  decode.d3.loss_dice: 0.8516  decode.d4.loss_cls: 0.3302  decode.d4.loss_mask: 1.0976  decode.d4.loss_dice: 0.8317  decode.d5.loss_cls: 0.3398  decode.d5.loss_mask: 1.1234  decode.d5.loss_dice: 0.8298  decode.d6.loss_cls: 0.3397  decode.d6.loss_mask: 1.1305  decode.d6.loss_dice: 0.8132  decode.d7.loss_cls: 0.3171  decode.d7.loss_mask: 1.0845  decode.d7.loss_dice: 0.8553  decode.d8.loss_cls: 0.2872  decode.d8.loss_mask: 1.0734  decode.d8.loss_dice: 0.8386
05/26 14:10:58 - mmengine - INFO - Iter(train) [ 27850/160000]  base_lr: 8.4189e-05 lr: 8.4189e-06  eta: 15:03:48  time: 0.4054  data_time: 0.0089  memory: 5973  grad_norm: 1117.9636  loss: 25.1163  decode.loss_cls: 0.3609  decode.loss_mask: 1.2292  decode.loss_dice: 0.9059  decode.d0.loss_cls: 0.8630  decode.d0.loss_mask: 1.1699  decode.d0.loss_dice: 0.8234  decode.d1.loss_cls: 0.4048  decode.d1.loss_mask: 1.1841  decode.d1.loss_dice: 0.8932  decode.d2.loss_cls: 0.3923  decode.d2.loss_mask: 1.2072  decode.d2.loss_dice: 0.9196  decode.d3.loss_cls: 0.3730  decode.d3.loss_mask: 1.2113  decode.d3.loss_dice: 0.9082  decode.d4.loss_cls: 0.3864  decode.d4.loss_mask: 1.1967  decode.d4.loss_dice: 0.8749  decode.d5.loss_cls: 0.4520  decode.d5.loss_mask: 1.1833  decode.d5.loss_dice: 0.8478  decode.d6.loss_cls: 0.3887  decode.d6.loss_mask: 1.1917  decode.d6.loss_dice: 0.8059  decode.d7.loss_cls: 0.3154  decode.d7.loss_mask: 1.2455  decode.d7.loss_dice: 0.9055  decode.d8.loss_cls: 0.3675  decode.d8.loss_mask: 1.2144  decode.d8.loss_dice: 0.8946
05/26 14:11:18 - mmengine - INFO - Iter(train) [ 27900/160000]  base_lr: 8.4160e-05 lr: 8.4160e-06  eta: 15:03:26  time: 0.4048  data_time: 0.0089  memory: 5980  grad_norm: 620.2742  loss: 24.3273  decode.loss_cls: 0.2633  decode.loss_mask: 1.2455  decode.loss_dice: 0.9351  decode.d0.loss_cls: 0.7945  decode.d0.loss_mask: 1.0700  decode.d0.loss_dice: 0.8080  decode.d1.loss_cls: 0.3173  decode.d1.loss_mask: 1.1904  decode.d1.loss_dice: 0.8564  decode.d2.loss_cls: 0.2776  decode.d2.loss_mask: 1.1784  decode.d2.loss_dice: 0.8823  decode.d3.loss_cls: 0.2623  decode.d3.loss_mask: 1.1598  decode.d3.loss_dice: 0.8943  decode.d4.loss_cls: 0.3139  decode.d4.loss_mask: 1.2076  decode.d4.loss_dice: 0.9130  decode.d5.loss_cls: 0.3168  decode.d5.loss_mask: 1.2123  decode.d5.loss_dice: 0.8807  decode.d6.loss_cls: 0.2881  decode.d6.loss_mask: 1.2331  decode.d6.loss_dice: 0.9086  decode.d7.loss_cls: 0.3269  decode.d7.loss_mask: 1.2420  decode.d7.loss_dice: 0.9023  decode.d8.loss_cls: 0.2555  decode.d8.loss_mask: 1.2543  decode.d8.loss_dice: 0.9370
05/26 14:11:38 - mmengine - INFO - Iter(train) [ 27950/160000]  base_lr: 8.4132e-05 lr: 8.4132e-06  eta: 15:03:05  time: 0.4061  data_time: 0.0088  memory: 5969  grad_norm: 730.7943  loss: 23.8930  decode.loss_cls: 0.3457  decode.loss_mask: 1.1570  decode.loss_dice: 0.9100  decode.d0.loss_cls: 0.8655  decode.d0.loss_mask: 1.0767  decode.d0.loss_dice: 0.8438  decode.d1.loss_cls: 0.4245  decode.d1.loss_mask: 1.1239  decode.d1.loss_dice: 0.8603  decode.d2.loss_cls: 0.3947  decode.d2.loss_mask: 1.0749  decode.d2.loss_dice: 0.8179  decode.d3.loss_cls: 0.4152  decode.d3.loss_mask: 1.0887  decode.d3.loss_dice: 0.8600  decode.d4.loss_cls: 0.4450  decode.d4.loss_mask: 1.0856  decode.d4.loss_dice: 0.8480  decode.d5.loss_cls: 0.4189  decode.d5.loss_mask: 1.0553  decode.d5.loss_dice: 0.8466  decode.d6.loss_cls: 0.4351  decode.d6.loss_mask: 1.0424  decode.d6.loss_dice: 0.8131  decode.d7.loss_cls: 0.3880  decode.d7.loss_mask: 1.0794  decode.d7.loss_dice: 0.8389  decode.d8.loss_cls: 0.4162  decode.d8.loss_mask: 1.0821  decode.d8.loss_dice: 0.8395
05/26 14:11:59 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 14:11:59 - mmengine - INFO - Iter(train) [ 28000/160000]  base_lr: 8.4103e-05 lr: 8.4103e-06  eta: 15:02:43  time: 0.4039  data_time: 0.0087  memory: 5965  grad_norm: 546.6470  loss: 21.0978  decode.loss_cls: 0.3102  decode.loss_mask: 0.9564  decode.loss_dice: 0.7303  decode.d0.loss_cls: 0.7638  decode.d0.loss_mask: 0.9484  decode.d0.loss_dice: 0.7194  decode.d1.loss_cls: 0.3431  decode.d1.loss_mask: 0.9904  decode.d1.loss_dice: 0.7497  decode.d2.loss_cls: 0.3116  decode.d2.loss_mask: 1.0377  decode.d2.loss_dice: 0.7622  decode.d3.loss_cls: 0.3314  decode.d3.loss_mask: 0.9894  decode.d3.loss_dice: 0.7653  decode.d4.loss_cls: 0.2882  decode.d4.loss_mask: 1.0187  decode.d4.loss_dice: 0.7714  decode.d5.loss_cls: 0.2701  decode.d5.loss_mask: 0.9950  decode.d5.loss_dice: 0.7618  decode.d6.loss_cls: 0.3282  decode.d6.loss_mask: 0.9786  decode.d6.loss_dice: 0.7697  decode.d7.loss_cls: 0.3055  decode.d7.loss_mask: 1.0284  decode.d7.loss_dice: 0.7685  decode.d8.loss_cls: 0.3132  decode.d8.loss_mask: 1.0117  decode.d8.loss_dice: 0.7794
05/26 14:12:19 - mmengine - INFO - Iter(train) [ 28050/160000]  base_lr: 8.4074e-05 lr: 8.4074e-06  eta: 15:02:21  time: 0.4047  data_time: 0.0088  memory: 5972  grad_norm: 472.6967  loss: 25.4665  decode.loss_cls: 0.3580  decode.loss_mask: 1.2421  decode.loss_dice: 0.9588  decode.d0.loss_cls: 0.7344  decode.d0.loss_mask: 1.1475  decode.d0.loss_dice: 0.9071  decode.d1.loss_cls: 0.3714  decode.d1.loss_mask: 1.1755  decode.d1.loss_dice: 0.8867  decode.d2.loss_cls: 0.3810  decode.d2.loss_mask: 1.2404  decode.d2.loss_dice: 0.9343  decode.d3.loss_cls: 0.3544  decode.d3.loss_mask: 1.1989  decode.d3.loss_dice: 0.9025  decode.d4.loss_cls: 0.3857  decode.d4.loss_mask: 1.1655  decode.d4.loss_dice: 0.8798  decode.d5.loss_cls: 0.3904  decode.d5.loss_mask: 1.1927  decode.d5.loss_dice: 0.9461  decode.d6.loss_cls: 0.3850  decode.d6.loss_mask: 1.2911  decode.d6.loss_dice: 0.9774  decode.d7.loss_cls: 0.3833  decode.d7.loss_mask: 1.2281  decode.d7.loss_dice: 0.9296  decode.d8.loss_cls: 0.3918  decode.d8.loss_mask: 1.1924  decode.d8.loss_dice: 0.9344
05/26 14:12:39 - mmengine - INFO - Iter(train) [ 28100/160000]  base_lr: 8.4046e-05 lr: 8.4046e-06  eta: 15:01:59  time: 0.4052  data_time: 0.0089  memory: 5967  grad_norm: 1017.3503  loss: 24.7120  decode.loss_cls: 0.2693  decode.loss_mask: 1.2932  decode.loss_dice: 0.8572  decode.d0.loss_cls: 0.7504  decode.d0.loss_mask: 1.2524  decode.d0.loss_dice: 0.8244  decode.d1.loss_cls: 0.2715  decode.d1.loss_mask: 1.2847  decode.d1.loss_dice: 0.8550  decode.d2.loss_cls: 0.2767  decode.d2.loss_mask: 1.2612  decode.d2.loss_dice: 0.8520  decode.d3.loss_cls: 0.2721  decode.d3.loss_mask: 1.2942  decode.d3.loss_dice: 0.8429  decode.d4.loss_cls: 0.3388  decode.d4.loss_mask: 1.2736  decode.d4.loss_dice: 0.8250  decode.d5.loss_cls: 0.2538  decode.d5.loss_mask: 1.3398  decode.d5.loss_dice: 0.8198  decode.d6.loss_cls: 0.3240  decode.d6.loss_mask: 1.3006  decode.d6.loss_dice: 0.8566  decode.d7.loss_cls: 0.2760  decode.d7.loss_mask: 1.3189  decode.d7.loss_dice: 0.8641  decode.d8.loss_cls: 0.2786  decode.d8.loss_mask: 1.2938  decode.d8.loss_dice: 0.8913
05/26 14:12:59 - mmengine - INFO - Iter(train) [ 28150/160000]  base_lr: 8.4017e-05 lr: 8.4017e-06  eta: 15:01:37  time: 0.4035  data_time: 0.0089  memory: 5987  grad_norm: 828.4587  loss: 26.4600  decode.loss_cls: 0.3650  decode.loss_mask: 1.2819  decode.loss_dice: 0.9643  decode.d0.loss_cls: 0.8311  decode.d0.loss_mask: 1.2297  decode.d0.loss_dice: 0.9577  decode.d1.loss_cls: 0.3960  decode.d1.loss_mask: 1.2722  decode.d1.loss_dice: 0.9369  decode.d2.loss_cls: 0.3836  decode.d2.loss_mask: 1.2585  decode.d2.loss_dice: 0.9309  decode.d3.loss_cls: 0.3686  decode.d3.loss_mask: 1.2910  decode.d3.loss_dice: 0.9249  decode.d4.loss_cls: 0.3566  decode.d4.loss_mask: 1.2937  decode.d4.loss_dice: 0.9406  decode.d5.loss_cls: 0.3702  decode.d5.loss_mask: 1.2857  decode.d5.loss_dice: 0.9515  decode.d6.loss_cls: 0.3975  decode.d6.loss_mask: 1.2642  decode.d6.loss_dice: 0.9594  decode.d7.loss_cls: 0.3683  decode.d7.loss_mask: 1.2732  decode.d7.loss_dice: 1.0198  decode.d8.loss_cls: 0.3554  decode.d8.loss_mask: 1.2709  decode.d8.loss_dice: 0.9603
05/26 14:13:19 - mmengine - INFO - Iter(train) [ 28200/160000]  base_lr: 8.3988e-05 lr: 8.3988e-06  eta: 15:01:15  time: 0.4053  data_time: 0.0089  memory: 5980  grad_norm: 808.4370  loss: 26.3658  decode.loss_cls: 0.4122  decode.loss_mask: 1.2474  decode.loss_dice: 0.9112  decode.d0.loss_cls: 0.7815  decode.d0.loss_mask: 1.2537  decode.d0.loss_dice: 0.9600  decode.d1.loss_cls: 0.3611  decode.d1.loss_mask: 1.3200  decode.d1.loss_dice: 0.9517  decode.d2.loss_cls: 0.4182  decode.d2.loss_mask: 1.1970  decode.d2.loss_dice: 0.9125  decode.d3.loss_cls: 0.3515  decode.d3.loss_mask: 1.3283  decode.d3.loss_dice: 0.9423  decode.d4.loss_cls: 0.3869  decode.d4.loss_mask: 1.2929  decode.d4.loss_dice: 0.9338  decode.d5.loss_cls: 0.4052  decode.d5.loss_mask: 1.2619  decode.d5.loss_dice: 0.9554  decode.d6.loss_cls: 0.4232  decode.d6.loss_mask: 1.2613  decode.d6.loss_dice: 0.9748  decode.d7.loss_cls: 0.3824  decode.d7.loss_mask: 1.2620  decode.d7.loss_dice: 0.9098  decode.d8.loss_cls: 0.3692  decode.d8.loss_mask: 1.2588  decode.d8.loss_dice: 0.9396
05/26 14:13:40 - mmengine - INFO - Iter(train) [ 28250/160000]  base_lr: 8.3960e-05 lr: 8.3960e-06  eta: 15:00:53  time: 0.4041  data_time: 0.0088  memory: 5969  grad_norm: 686.6379  loss: 20.9363  decode.loss_cls: 0.2026  decode.loss_mask: 1.0890  decode.loss_dice: 0.7553  decode.d0.loss_cls: 0.6125  decode.d0.loss_mask: 1.0269  decode.d0.loss_dice: 0.7550  decode.d1.loss_cls: 0.2162  decode.d1.loss_mask: 1.0794  decode.d1.loss_dice: 0.7454  decode.d2.loss_cls: 0.2099  decode.d2.loss_mask: 1.0979  decode.d2.loss_dice: 0.7627  decode.d3.loss_cls: 0.1934  decode.d3.loss_mask: 1.0922  decode.d3.loss_dice: 0.7576  decode.d4.loss_cls: 0.2218  decode.d4.loss_mask: 1.0698  decode.d4.loss_dice: 0.7680  decode.d5.loss_cls: 0.2073  decode.d5.loss_mask: 1.0833  decode.d5.loss_dice: 0.7624  decode.d6.loss_cls: 0.2334  decode.d6.loss_mask: 1.1006  decode.d6.loss_dice: 0.7581  decode.d7.loss_cls: 0.2290  decode.d7.loss_mask: 1.0688  decode.d7.loss_dice: 0.7612  decode.d8.loss_cls: 0.2284  decode.d8.loss_mask: 1.0960  decode.d8.loss_dice: 0.7522
05/26 14:14:00 - mmengine - INFO - Iter(train) [ 28300/160000]  base_lr: 8.3931e-05 lr: 8.3931e-06  eta: 15:00:32  time: 0.4060  data_time: 0.0093  memory: 5969  grad_norm: 551.3777  loss: 27.5589  decode.loss_cls: 0.4270  decode.loss_mask: 1.3214  decode.loss_dice: 0.9393  decode.d0.loss_cls: 0.9679  decode.d0.loss_mask: 1.2649  decode.d0.loss_dice: 0.9569  decode.d1.loss_cls: 0.4407  decode.d1.loss_mask: 1.3288  decode.d1.loss_dice: 0.9341  decode.d2.loss_cls: 0.4043  decode.d2.loss_mask: 1.3724  decode.d2.loss_dice: 0.9894  decode.d3.loss_cls: 0.3618  decode.d3.loss_mask: 1.3663  decode.d3.loss_dice: 0.9356  decode.d4.loss_cls: 0.3788  decode.d4.loss_mask: 1.3862  decode.d4.loss_dice: 0.9320  decode.d5.loss_cls: 0.4019  decode.d5.loss_mask: 1.4082  decode.d5.loss_dice: 0.9764  decode.d6.loss_cls: 0.3628  decode.d6.loss_mask: 1.3655  decode.d6.loss_dice: 0.9260  decode.d7.loss_cls: 0.3803  decode.d7.loss_mask: 1.3402  decode.d7.loss_dice: 0.9690  decode.d8.loss_cls: 0.3888  decode.d8.loss_mask: 1.3880  decode.d8.loss_dice: 0.9439
05/26 14:14:20 - mmengine - INFO - Iter(train) [ 28350/160000]  base_lr: 8.3902e-05 lr: 8.3902e-06  eta: 15:00:10  time: 0.4053  data_time: 0.0087  memory: 5969  grad_norm: 664.0047  loss: 28.1670  decode.loss_cls: 0.3179  decode.loss_mask: 1.3099  decode.loss_dice: 1.1475  decode.d0.loss_cls: 0.8751  decode.d0.loss_mask: 1.2386  decode.d0.loss_dice: 1.0830  decode.d1.loss_cls: 0.2907  decode.d1.loss_mask: 1.2742  decode.d1.loss_dice: 1.1159  decode.d2.loss_cls: 0.2795  decode.d2.loss_mask: 1.3348  decode.d2.loss_dice: 1.1866  decode.d3.loss_cls: 0.3149  decode.d3.loss_mask: 1.2999  decode.d3.loss_dice: 1.1615  decode.d4.loss_cls: 0.3464  decode.d4.loss_mask: 1.3106  decode.d4.loss_dice: 1.1229  decode.d5.loss_cls: 0.3691  decode.d5.loss_mask: 1.2911  decode.d5.loss_dice: 1.1011  decode.d6.loss_cls: 0.4035  decode.d6.loss_mask: 1.2604  decode.d6.loss_dice: 1.1448  decode.d7.loss_cls: 0.3678  decode.d7.loss_mask: 1.3131  decode.d7.loss_dice: 1.1200  decode.d8.loss_cls: 0.3089  decode.d8.loss_mask: 1.3348  decode.d8.loss_dice: 1.1424
05/26 14:14:40 - mmengine - INFO - Iter(train) [ 28400/160000]  base_lr: 8.3873e-05 lr: 8.3873e-06  eta: 14:59:48  time: 0.4045  data_time: 0.0089  memory: 5976  grad_norm: 662.9831  loss: 27.9387  decode.loss_cls: 0.3200  decode.loss_mask: 1.3441  decode.loss_dice: 1.0431  decode.d0.loss_cls: 0.8979  decode.d0.loss_mask: 1.2790  decode.d0.loss_dice: 0.9582  decode.d1.loss_cls: 0.4082  decode.d1.loss_mask: 1.3891  decode.d1.loss_dice: 1.0110  decode.d2.loss_cls: 0.3550  decode.d2.loss_mask: 1.3779  decode.d2.loss_dice: 1.0228  decode.d3.loss_cls: 0.3582  decode.d3.loss_mask: 1.3889  decode.d3.loss_dice: 1.0274  decode.d4.loss_cls: 0.3985  decode.d4.loss_mask: 1.3506  decode.d4.loss_dice: 0.9774  decode.d5.loss_cls: 0.4145  decode.d5.loss_mask: 1.3612  decode.d5.loss_dice: 0.9912  decode.d6.loss_cls: 0.3701  decode.d6.loss_mask: 1.4182  decode.d6.loss_dice: 1.0015  decode.d7.loss_cls: 0.3887  decode.d7.loss_mask: 1.3912  decode.d7.loss_dice: 0.9880  decode.d8.loss_cls: 0.3862  decode.d8.loss_mask: 1.3347  decode.d8.loss_dice: 0.9859
05/26 14:15:01 - mmengine - INFO - Iter(train) [ 28450/160000]  base_lr: 8.3845e-05 lr: 8.3845e-06  eta: 14:59:27  time: 0.4059  data_time: 0.0088  memory: 5970  grad_norm: 475.5840  loss: 29.1495  decode.loss_cls: 0.4687  decode.loss_mask: 1.3805  decode.loss_dice: 1.0838  decode.d0.loss_cls: 0.9362  decode.d0.loss_mask: 1.2716  decode.d0.loss_dice: 1.0433  decode.d1.loss_cls: 0.4666  decode.d1.loss_mask: 1.3237  decode.d1.loss_dice: 1.0169  decode.d2.loss_cls: 0.3676  decode.d2.loss_mask: 1.3770  decode.d2.loss_dice: 1.0712  decode.d3.loss_cls: 0.4473  decode.d3.loss_mask: 1.3724  decode.d3.loss_dice: 1.0675  decode.d4.loss_cls: 0.4988  decode.d4.loss_mask: 1.3829  decode.d4.loss_dice: 1.0575  decode.d5.loss_cls: 0.4587  decode.d5.loss_mask: 1.3604  decode.d5.loss_dice: 1.0645  decode.d6.loss_cls: 0.4916  decode.d6.loss_mask: 1.3394  decode.d6.loss_dice: 1.0648  decode.d7.loss_cls: 0.4302  decode.d7.loss_mask: 1.3897  decode.d7.loss_dice: 1.0368  decode.d8.loss_cls: 0.4668  decode.d8.loss_mask: 1.3615  decode.d8.loss_dice: 1.0517
05/26 14:15:21 - mmengine - INFO - Iter(train) [ 28500/160000]  base_lr: 8.3816e-05 lr: 8.3816e-06  eta: 14:59:05  time: 0.4046  data_time: 0.0088  memory: 5966  grad_norm: 1119.2011  loss: 27.6559  decode.loss_cls: 0.3583  decode.loss_mask: 1.3049  decode.loss_dice: 1.0315  decode.d0.loss_cls: 0.9712  decode.d0.loss_mask: 1.2687  decode.d0.loss_dice: 0.9908  decode.d1.loss_cls: 0.3822  decode.d1.loss_mask: 1.3353  decode.d1.loss_dice: 1.0286  decode.d2.loss_cls: 0.3768  decode.d2.loss_mask: 1.3483  decode.d2.loss_dice: 1.0176  decode.d3.loss_cls: 0.3874  decode.d3.loss_mask: 1.3043  decode.d3.loss_dice: 1.0122  decode.d4.loss_cls: 0.4047  decode.d4.loss_mask: 1.3188  decode.d4.loss_dice: 0.9988  decode.d5.loss_cls: 0.3832  decode.d5.loss_mask: 1.2895  decode.d5.loss_dice: 0.9749  decode.d6.loss_cls: 0.4610  decode.d6.loss_mask: 1.2704  decode.d6.loss_dice: 1.0026  decode.d7.loss_cls: 0.4084  decode.d7.loss_mask: 1.3024  decode.d7.loss_dice: 1.0179  decode.d8.loss_cls: 0.3872  decode.d8.loss_mask: 1.3089  decode.d8.loss_dice: 1.0089
05/26 14:15:41 - mmengine - INFO - Iter(train) [ 28550/160000]  base_lr: 8.3787e-05 lr: 8.3787e-06  eta: 14:58:44  time: 0.4043  data_time: 0.0087  memory: 5966  grad_norm: 730.9467  loss: 24.0874  decode.loss_cls: 0.4169  decode.loss_mask: 1.1309  decode.loss_dice: 0.8306  decode.d0.loss_cls: 0.7887  decode.d0.loss_mask: 1.1225  decode.d0.loss_dice: 0.8979  decode.d1.loss_cls: 0.3643  decode.d1.loss_mask: 1.1926  decode.d1.loss_dice: 0.8198  decode.d2.loss_cls: 0.4052  decode.d2.loss_mask: 1.1128  decode.d2.loss_dice: 0.7911  decode.d3.loss_cls: 0.3892  decode.d3.loss_mask: 1.1727  decode.d3.loss_dice: 0.8320  decode.d4.loss_cls: 0.4010  decode.d4.loss_mask: 1.1269  decode.d4.loss_dice: 0.8008  decode.d5.loss_cls: 0.3951  decode.d5.loss_mask: 1.1263  decode.d5.loss_dice: 0.8013  decode.d6.loss_cls: 0.4098  decode.d6.loss_mask: 1.1306  decode.d6.loss_dice: 0.8355  decode.d7.loss_cls: 0.4313  decode.d7.loss_mask: 1.1897  decode.d7.loss_dice: 0.8371  decode.d8.loss_cls: 0.3980  decode.d8.loss_mask: 1.1509  decode.d8.loss_dice: 0.7858
05/26 14:16:02 - mmengine - INFO - Iter(train) [ 28600/160000]  base_lr: 8.3759e-05 lr: 8.3759e-06  eta: 14:58:22  time: 0.4043  data_time: 0.0087  memory: 5969  grad_norm: 898.7967  loss: 23.9801  decode.loss_cls: 0.4133  decode.loss_mask: 1.0326  decode.loss_dice: 0.8707  decode.d0.loss_cls: 0.7976  decode.d0.loss_mask: 1.0500  decode.d0.loss_dice: 0.8441  decode.d1.loss_cls: 0.4689  decode.d1.loss_mask: 1.0587  decode.d1.loss_dice: 0.8695  decode.d2.loss_cls: 0.4084  decode.d2.loss_mask: 1.1067  decode.d2.loss_dice: 0.8901  decode.d3.loss_cls: 0.4643  decode.d3.loss_mask: 1.0487  decode.d3.loss_dice: 0.8800  decode.d4.loss_cls: 0.3961  decode.d4.loss_mask: 1.0846  decode.d4.loss_dice: 0.8745  decode.d5.loss_cls: 0.4478  decode.d5.loss_mask: 1.0262  decode.d5.loss_dice: 0.8623  decode.d6.loss_cls: 0.3615  decode.d6.loss_mask: 1.0782  decode.d6.loss_dice: 0.8982  decode.d7.loss_cls: 0.3636  decode.d7.loss_mask: 1.1185  decode.d7.loss_dice: 0.9201  decode.d8.loss_cls: 0.3753  decode.d8.loss_mask: 1.0826  decode.d8.loss_dice: 0.8868
05/26 14:16:22 - mmengine - INFO - Iter(train) [ 28650/160000]  base_lr: 8.3730e-05 lr: 8.3730e-06  eta: 14:58:00  time: 0.4044  data_time: 0.0087  memory: 5968  grad_norm: 573.7601  loss: 26.7828  decode.loss_cls: 0.3456  decode.loss_mask: 1.3361  decode.loss_dice: 0.9277  decode.d0.loss_cls: 0.9132  decode.d0.loss_mask: 1.2438  decode.d0.loss_dice: 0.8837  decode.d1.loss_cls: 0.3426  decode.d1.loss_mask: 1.3162  decode.d1.loss_dice: 0.9583  decode.d2.loss_cls: 0.3830  decode.d2.loss_mask: 1.2990  decode.d2.loss_dice: 0.9030  decode.d3.loss_cls: 0.3708  decode.d3.loss_mask: 1.2774  decode.d3.loss_dice: 0.9485  decode.d4.loss_cls: 0.3597  decode.d4.loss_mask: 1.2912  decode.d4.loss_dice: 0.9990  decode.d5.loss_cls: 0.3912  decode.d5.loss_mask: 1.2651  decode.d5.loss_dice: 0.9696  decode.d6.loss_cls: 0.4370  decode.d6.loss_mask: 1.2873  decode.d6.loss_dice: 0.9358  decode.d7.loss_cls: 0.4003  decode.d7.loss_mask: 1.3717  decode.d7.loss_dice: 0.9484  decode.d8.loss_cls: 0.3962  decode.d8.loss_mask: 1.3332  decode.d8.loss_dice: 0.9484
05/26 14:16:42 - mmengine - INFO - Iter(train) [ 28700/160000]  base_lr: 8.3701e-05 lr: 8.3701e-06  eta: 14:57:38  time: 0.4044  data_time: 0.0088  memory: 5974  grad_norm: 713.3329  loss: 23.6122  decode.loss_cls: 0.2093  decode.loss_mask: 1.2806  decode.loss_dice: 0.7987  decode.d0.loss_cls: 0.6949  decode.d0.loss_mask: 1.2579  decode.d0.loss_dice: 0.7825  decode.d1.loss_cls: 0.2141  decode.d1.loss_mask: 1.3199  decode.d1.loss_dice: 0.8228  decode.d2.loss_cls: 0.2344  decode.d2.loss_mask: 1.2972  decode.d2.loss_dice: 0.7957  decode.d3.loss_cls: 0.2019  decode.d3.loss_mask: 1.2882  decode.d3.loss_dice: 0.7840  decode.d4.loss_cls: 0.2367  decode.d4.loss_mask: 1.2831  decode.d4.loss_dice: 0.7888  decode.d5.loss_cls: 0.2202  decode.d5.loss_mask: 1.3020  decode.d5.loss_dice: 0.8125  decode.d6.loss_cls: 0.2523  decode.d6.loss_mask: 1.3070  decode.d6.loss_dice: 0.7930  decode.d7.loss_cls: 0.2533  decode.d7.loss_mask: 1.2868  decode.d7.loss_dice: 0.7500  decode.d8.loss_cls: 0.2591  decode.d8.loss_mask: 1.2956  decode.d8.loss_dice: 0.7900
05/26 14:17:02 - mmengine - INFO - Iter(train) [ 28750/160000]  base_lr: 8.3673e-05 lr: 8.3673e-06  eta: 14:57:16  time: 0.4042  data_time: 0.0088  memory: 5972  grad_norm: 701.5271  loss: 28.4124  decode.loss_cls: 0.4710  decode.loss_mask: 1.3385  decode.loss_dice: 0.9498  decode.d0.loss_cls: 0.9284  decode.d0.loss_mask: 1.2692  decode.d0.loss_dice: 0.9390  decode.d1.loss_cls: 0.4650  decode.d1.loss_mask: 1.3223  decode.d1.loss_dice: 0.9605  decode.d2.loss_cls: 0.4795  decode.d2.loss_mask: 1.3985  decode.d2.loss_dice: 0.9609  decode.d3.loss_cls: 0.4686  decode.d3.loss_mask: 1.4016  decode.d3.loss_dice: 0.9834  decode.d4.loss_cls: 0.4933  decode.d4.loss_mask: 1.3488  decode.d4.loss_dice: 0.9703  decode.d5.loss_cls: 0.5099  decode.d5.loss_mask: 1.3622  decode.d5.loss_dice: 0.9630  decode.d6.loss_cls: 0.5016  decode.d6.loss_mask: 1.3711  decode.d6.loss_dice: 0.9573  decode.d7.loss_cls: 0.4899  decode.d7.loss_mask: 1.3750  decode.d7.loss_dice: 0.9402  decode.d8.loss_cls: 0.5377  decode.d8.loss_mask: 1.3417  decode.d8.loss_dice: 0.9141
05/26 14:17:23 - mmengine - INFO - Iter(train) [ 28800/160000]  base_lr: 8.3644e-05 lr: 8.3644e-06  eta: 14:56:55  time: 0.4044  data_time: 0.0088  memory: 5980  grad_norm: 448.8844  loss: 24.8404  decode.loss_cls: 0.3347  decode.loss_mask: 1.1998  decode.loss_dice: 0.8930  decode.d0.loss_cls: 0.7389  decode.d0.loss_mask: 1.1970  decode.d0.loss_dice: 0.8974  decode.d1.loss_cls: 0.2612  decode.d1.loss_mask: 1.2219  decode.d1.loss_dice: 0.9254  decode.d2.loss_cls: 0.3215  decode.d2.loss_mask: 1.2516  decode.d2.loss_dice: 0.9197  decode.d3.loss_cls: 0.3091  decode.d3.loss_mask: 1.2145  decode.d3.loss_dice: 0.9086  decode.d4.loss_cls: 0.3002  decode.d4.loss_mask: 1.1852  decode.d4.loss_dice: 0.9166  decode.d5.loss_cls: 0.2852  decode.d5.loss_mask: 1.2423  decode.d5.loss_dice: 0.9226  decode.d6.loss_cls: 0.3493  decode.d6.loss_mask: 1.2168  decode.d6.loss_dice: 0.9505  decode.d7.loss_cls: 0.3422  decode.d7.loss_mask: 1.2158  decode.d7.loss_dice: 0.9161  decode.d8.loss_cls: 0.2839  decode.d8.loss_mask: 1.2121  decode.d8.loss_dice: 0.9070
05/26 14:17:43 - mmengine - INFO - Iter(train) [ 28850/160000]  base_lr: 8.3615e-05 lr: 8.3615e-06  eta: 14:56:33  time: 0.4046  data_time: 0.0087  memory: 5969  grad_norm: 599.2092  loss: 24.8795  decode.loss_cls: 0.2743  decode.loss_mask: 1.2047  decode.loss_dice: 0.9176  decode.d0.loss_cls: 0.8006  decode.d0.loss_mask: 1.1623  decode.d0.loss_dice: 0.8735  decode.d1.loss_cls: 0.3202  decode.d1.loss_mask: 1.2416  decode.d1.loss_dice: 0.8908  decode.d2.loss_cls: 0.2701  decode.d2.loss_mask: 1.2324  decode.d2.loss_dice: 0.9599  decode.d3.loss_cls: 0.2811  decode.d3.loss_mask: 1.2012  decode.d3.loss_dice: 0.9146  decode.d4.loss_cls: 0.3197  decode.d4.loss_mask: 1.2081  decode.d4.loss_dice: 0.8953  decode.d5.loss_cls: 0.3177  decode.d5.loss_mask: 1.2218  decode.d5.loss_dice: 0.9331  decode.d6.loss_cls: 0.3646  decode.d6.loss_mask: 1.2310  decode.d6.loss_dice: 0.9538  decode.d7.loss_cls: 0.2795  decode.d7.loss_mask: 1.2426  decode.d7.loss_dice: 0.9284  decode.d8.loss_cls: 0.2726  decode.d8.loss_mask: 1.2514  decode.d8.loss_dice: 0.9151
05/26 14:18:03 - mmengine - INFO - Iter(train) [ 28900/160000]  base_lr: 8.3587e-05 lr: 8.3587e-06  eta: 14:56:11  time: 0.4049  data_time: 0.0088  memory: 5966  grad_norm: 795.2422  loss: 26.0169  decode.loss_cls: 0.3546  decode.loss_mask: 1.3082  decode.loss_dice: 0.9414  decode.d0.loss_cls: 0.7984  decode.d0.loss_mask: 1.1670  decode.d0.loss_dice: 0.8966  decode.d1.loss_cls: 0.3007  decode.d1.loss_mask: 1.2758  decode.d1.loss_dice: 0.9554  decode.d2.loss_cls: 0.3688  decode.d2.loss_mask: 1.2683  decode.d2.loss_dice: 0.9619  decode.d3.loss_cls: 0.3571  decode.d3.loss_mask: 1.2658  decode.d3.loss_dice: 0.9558  decode.d4.loss_cls: 0.3765  decode.d4.loss_mask: 1.2555  decode.d4.loss_dice: 0.9647  decode.d5.loss_cls: 0.3285  decode.d5.loss_mask: 1.2832  decode.d5.loss_dice: 0.9581  decode.d6.loss_cls: 0.3794  decode.d6.loss_mask: 1.2477  decode.d6.loss_dice: 0.9091  decode.d7.loss_cls: 0.3089  decode.d7.loss_mask: 1.2972  decode.d7.loss_dice: 0.9640  decode.d8.loss_cls: 0.3408  decode.d8.loss_mask: 1.2777  decode.d8.loss_dice: 0.9497
05/26 14:18:23 - mmengine - INFO - Iter(train) [ 28950/160000]  base_lr: 8.3558e-05 lr: 8.3558e-06  eta: 14:55:50  time: 0.4043  data_time: 0.0087  memory: 5969  grad_norm: 1205.8328  loss: 25.5701  decode.loss_cls: 0.3374  decode.loss_mask: 1.2451  decode.loss_dice: 0.9893  decode.d0.loss_cls: 0.8240  decode.d0.loss_mask: 1.1863  decode.d0.loss_dice: 0.9182  decode.d1.loss_cls: 0.3695  decode.d1.loss_mask: 1.1821  decode.d1.loss_dice: 0.9306  decode.d2.loss_cls: 0.3695  decode.d2.loss_mask: 1.1897  decode.d2.loss_dice: 0.9413  decode.d3.loss_cls: 0.3482  decode.d3.loss_mask: 1.1932  decode.d3.loss_dice: 0.9113  decode.d4.loss_cls: 0.3807  decode.d4.loss_mask: 1.2150  decode.d4.loss_dice: 0.9215  decode.d5.loss_cls: 0.3642  decode.d5.loss_mask: 1.2127  decode.d5.loss_dice: 0.8987  decode.d6.loss_cls: 0.3885  decode.d6.loss_mask: 1.2108  decode.d6.loss_dice: 0.8839  decode.d7.loss_cls: 0.3194  decode.d7.loss_mask: 1.2913  decode.d7.loss_dice: 0.9592  decode.d8.loss_cls: 0.3726  decode.d8.loss_mask: 1.2535  decode.d8.loss_dice: 0.9622
05/26 14:18:43 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 14:18:43 - mmengine - INFO - Iter(train) [ 29000/160000]  base_lr: 8.3529e-05 lr: 8.3529e-06  eta: 14:55:28  time: 0.4035  data_time: 0.0086  memory: 5969  grad_norm: 1057.0378  loss: 29.8066  decode.loss_cls: 0.3080  decode.loss_mask: 1.4956  decode.loss_dice: 1.1701  decode.d0.loss_cls: 0.8578  decode.d0.loss_mask: 1.3549  decode.d0.loss_dice: 1.0596  decode.d1.loss_cls: 0.2900  decode.d1.loss_mask: 1.4860  decode.d1.loss_dice: 1.1498  decode.d2.loss_cls: 0.2847  decode.d2.loss_mask: 1.4881  decode.d2.loss_dice: 1.1800  decode.d3.loss_cls: 0.3002  decode.d3.loss_mask: 1.5017  decode.d3.loss_dice: 1.1892  decode.d4.loss_cls: 0.3080  decode.d4.loss_mask: 1.4660  decode.d4.loss_dice: 1.1375  decode.d5.loss_cls: 0.3064  decode.d5.loss_mask: 1.4823  decode.d5.loss_dice: 1.1341  decode.d6.loss_cls: 0.3535  decode.d6.loss_mask: 1.5204  decode.d6.loss_dice: 1.1654  decode.d7.loss_cls: 0.2807  decode.d7.loss_mask: 1.5028  decode.d7.loss_dice: 1.1486  decode.d8.loss_cls: 0.2596  decode.d8.loss_mask: 1.4872  decode.d8.loss_dice: 1.1386
05/26 14:19:04 - mmengine - INFO - Iter(train) [ 29050/160000]  base_lr: 8.3501e-05 lr: 8.3501e-06  eta: 14:55:06  time: 0.4034  data_time: 0.0086  memory: 5976  grad_norm: 922.1257  loss: 27.9303  decode.loss_cls: 0.4888  decode.loss_mask: 1.3249  decode.loss_dice: 1.0190  decode.d0.loss_cls: 0.9728  decode.d0.loss_mask: 1.2240  decode.d0.loss_dice: 0.9524  decode.d1.loss_cls: 0.4618  decode.d1.loss_mask: 1.2467  decode.d1.loss_dice: 0.9669  decode.d2.loss_cls: 0.4765  decode.d2.loss_mask: 1.2666  decode.d2.loss_dice: 0.9769  decode.d3.loss_cls: 0.4394  decode.d3.loss_mask: 1.2834  decode.d3.loss_dice: 0.9991  decode.d4.loss_cls: 0.4242  decode.d4.loss_mask: 1.2731  decode.d4.loss_dice: 0.9724  decode.d5.loss_cls: 0.4698  decode.d5.loss_mask: 1.2459  decode.d5.loss_dice: 1.0027  decode.d6.loss_cls: 0.4627  decode.d6.loss_mask: 1.3415  decode.d6.loss_dice: 1.0253  decode.d7.loss_cls: 0.4725  decode.d7.loss_mask: 1.3975  decode.d7.loss_dice: 1.0420  decode.d8.loss_cls: 0.4920  decode.d8.loss_mask: 1.2511  decode.d8.loss_dice: 0.9583
05/26 14:19:24 - mmengine - INFO - Iter(train) [ 29100/160000]  base_lr: 8.3472e-05 lr: 8.3472e-06  eta: 14:54:44  time: 0.4049  data_time: 0.0088  memory: 5967  grad_norm: 755.8932  loss: 26.4276  decode.loss_cls: 0.3184  decode.loss_mask: 1.3025  decode.loss_dice: 0.9440  decode.d0.loss_cls: 0.7198  decode.d0.loss_mask: 1.3001  decode.d0.loss_dice: 0.9443  decode.d1.loss_cls: 0.3413  decode.d1.loss_mask: 1.3672  decode.d1.loss_dice: 0.9730  decode.d2.loss_cls: 0.3288  decode.d2.loss_mask: 1.3498  decode.d2.loss_dice: 0.9379  decode.d3.loss_cls: 0.2966  decode.d3.loss_mask: 1.3253  decode.d3.loss_dice: 0.9476  decode.d4.loss_cls: 0.3504  decode.d4.loss_mask: 1.2994  decode.d4.loss_dice: 0.9438  decode.d5.loss_cls: 0.3486  decode.d5.loss_mask: 1.3058  decode.d5.loss_dice: 0.9282  decode.d6.loss_cls: 0.3550  decode.d6.loss_mask: 1.3394  decode.d6.loss_dice: 0.9532  decode.d7.loss_cls: 0.3641  decode.d7.loss_mask: 1.3012  decode.d7.loss_dice: 0.9464  decode.d8.loss_cls: 0.3374  decode.d8.loss_mask: 1.3122  decode.d8.loss_dice: 0.9461
05/26 14:19:44 - mmengine - INFO - Iter(train) [ 29150/160000]  base_lr: 8.3443e-05 lr: 8.3443e-06  eta: 14:54:22  time: 0.4045  data_time: 0.0087  memory: 5967  grad_norm: 654.9585  loss: 26.8540  decode.loss_cls: 0.3509  decode.loss_mask: 1.3148  decode.loss_dice: 0.9922  decode.d0.loss_cls: 0.8512  decode.d0.loss_mask: 1.2866  decode.d0.loss_dice: 0.9893  decode.d1.loss_cls: 0.3622  decode.d1.loss_mask: 1.2449  decode.d1.loss_dice: 0.9735  decode.d2.loss_cls: 0.4210  decode.d2.loss_mask: 1.2185  decode.d2.loss_dice: 0.9805  decode.d3.loss_cls: 0.3432  decode.d3.loss_mask: 1.2899  decode.d3.loss_dice: 0.9843  decode.d4.loss_cls: 0.3583  decode.d4.loss_mask: 1.2812  decode.d4.loss_dice: 0.9887  decode.d5.loss_cls: 0.3255  decode.d5.loss_mask: 1.3097  decode.d5.loss_dice: 1.0002  decode.d6.loss_cls: 0.3645  decode.d6.loss_mask: 1.2821  decode.d6.loss_dice: 0.9868  decode.d7.loss_cls: 0.3892  decode.d7.loss_mask: 1.3005  decode.d7.loss_dice: 1.0033  decode.d8.loss_cls: 0.4118  decode.d8.loss_mask: 1.2558  decode.d8.loss_dice: 0.9934
05/26 14:20:04 - mmengine - INFO - Iter(train) [ 29200/160000]  base_lr: 8.3414e-05 lr: 8.3414e-06  eta: 14:54:01  time: 0.4041  data_time: 0.0087  memory: 5976  grad_norm: 408.1539  loss: 18.9104  decode.loss_cls: 0.2463  decode.loss_mask: 0.9542  decode.loss_dice: 0.6401  decode.d0.loss_cls: 0.6181  decode.d0.loss_mask: 0.9945  decode.d0.loss_dice: 0.6650  decode.d1.loss_cls: 0.2237  decode.d1.loss_mask: 0.9351  decode.d1.loss_dice: 0.6521  decode.d2.loss_cls: 0.2426  decode.d2.loss_mask: 0.9004  decode.d2.loss_dice: 0.6418  decode.d3.loss_cls: 0.2640  decode.d3.loss_mask: 0.9682  decode.d3.loss_dice: 0.6517  decode.d4.loss_cls: 0.2508  decode.d4.loss_mask: 0.9565  decode.d4.loss_dice: 0.6378  decode.d5.loss_cls: 0.2353  decode.d5.loss_mask: 0.9624  decode.d5.loss_dice: 0.6442  decode.d6.loss_cls: 0.2428  decode.d6.loss_mask: 0.9671  decode.d6.loss_dice: 0.6580  decode.d7.loss_cls: 0.2196  decode.d7.loss_mask: 0.9709  decode.d7.loss_dice: 0.6552  decode.d8.loss_cls: 0.2406  decode.d8.loss_mask: 0.9835  decode.d8.loss_dice: 0.6878
05/26 14:20:25 - mmengine - INFO - Iter(train) [ 29250/160000]  base_lr: 8.3386e-05 lr: 8.3386e-06  eta: 14:53:39  time: 0.4042  data_time: 0.0087  memory: 5973  grad_norm: 530.3454  loss: 27.0541  decode.loss_cls: 0.3850  decode.loss_mask: 1.2079  decode.loss_dice: 1.0597  decode.d0.loss_cls: 0.9288  decode.d0.loss_mask: 1.1141  decode.d0.loss_dice: 1.0302  decode.d1.loss_cls: 0.4511  decode.d1.loss_mask: 1.1193  decode.d1.loss_dice: 1.0460  decode.d2.loss_cls: 0.4074  decode.d2.loss_mask: 1.0988  decode.d2.loss_dice: 1.0532  decode.d3.loss_cls: 0.4144  decode.d3.loss_mask: 1.1586  decode.d3.loss_dice: 1.0749  decode.d4.loss_cls: 0.3959  decode.d4.loss_mask: 1.2037  decode.d4.loss_dice: 1.1503  decode.d5.loss_cls: 0.3706  decode.d5.loss_mask: 1.2274  decode.d5.loss_dice: 1.1176  decode.d6.loss_cls: 0.4497  decode.d6.loss_mask: 1.2223  decode.d6.loss_dice: 1.0621  decode.d7.loss_cls: 0.4080  decode.d7.loss_mask: 1.1850  decode.d7.loss_dice: 1.0915  decode.d8.loss_cls: 0.3790  decode.d8.loss_mask: 1.1553  decode.d8.loss_dice: 1.0863
05/26 14:20:45 - mmengine - INFO - Iter(train) [ 29300/160000]  base_lr: 8.3357e-05 lr: 8.3357e-06  eta: 14:53:17  time: 0.4041  data_time: 0.0087  memory: 5966  grad_norm: 533.8805  loss: 27.3107  decode.loss_cls: 0.3647  decode.loss_mask: 1.3730  decode.loss_dice: 0.9563  decode.d0.loss_cls: 0.7927  decode.d0.loss_mask: 1.3524  decode.d0.loss_dice: 0.9826  decode.d1.loss_cls: 0.3765  decode.d1.loss_mask: 1.3449  decode.d1.loss_dice: 0.9684  decode.d2.loss_cls: 0.3726  decode.d2.loss_mask: 1.3347  decode.d2.loss_dice: 0.9754  decode.d3.loss_cls: 0.3883  decode.d3.loss_mask: 1.3184  decode.d3.loss_dice: 0.9450  decode.d4.loss_cls: 0.3621  decode.d4.loss_mask: 1.3617  decode.d4.loss_dice: 0.9482  decode.d5.loss_cls: 0.3766  decode.d5.loss_mask: 1.3495  decode.d5.loss_dice: 0.9822  decode.d6.loss_cls: 0.3586  decode.d6.loss_mask: 1.3637  decode.d6.loss_dice: 0.9763  decode.d7.loss_cls: 0.3524  decode.d7.loss_mask: 1.4453  decode.d7.loss_dice: 0.9571  decode.d8.loss_cls: 0.3409  decode.d8.loss_mask: 1.3513  decode.d8.loss_dice: 0.9391
05/26 14:21:05 - mmengine - INFO - Iter(train) [ 29350/160000]  base_lr: 8.3328e-05 lr: 8.3328e-06  eta: 14:52:55  time: 0.4040  data_time: 0.0087  memory: 5969  grad_norm: 635.0928  loss: 28.2584  decode.loss_cls: 0.3913  decode.loss_mask: 1.4137  decode.loss_dice: 0.9641  decode.d0.loss_cls: 0.8783  decode.d0.loss_mask: 1.2672  decode.d0.loss_dice: 0.8734  decode.d1.loss_cls: 0.4219  decode.d1.loss_mask: 1.3932  decode.d1.loss_dice: 0.9519  decode.d2.loss_cls: 0.4237  decode.d2.loss_mask: 1.3697  decode.d2.loss_dice: 0.9534  decode.d3.loss_cls: 0.3890  decode.d3.loss_mask: 1.4663  decode.d3.loss_dice: 0.9488  decode.d4.loss_cls: 0.4405  decode.d4.loss_mask: 1.4141  decode.d4.loss_dice: 0.9494  decode.d5.loss_cls: 0.3952  decode.d5.loss_mask: 1.4537  decode.d5.loss_dice: 0.9840  decode.d6.loss_cls: 0.4791  decode.d6.loss_mask: 1.3904  decode.d6.loss_dice: 0.9538  decode.d7.loss_cls: 0.3958  decode.d7.loss_mask: 1.4841  decode.d7.loss_dice: 1.0157  decode.d8.loss_cls: 0.4734  decode.d8.loss_mask: 1.3671  decode.d8.loss_dice: 0.9561
05/26 14:21:25 - mmengine - INFO - Iter(train) [ 29400/160000]  base_lr: 8.3300e-05 lr: 8.3300e-06  eta: 14:52:33  time: 0.4031  data_time: 0.0087  memory: 5983  grad_norm: 734.8572  loss: 21.2857  decode.loss_cls: 0.1614  decode.loss_mask: 1.0870  decode.loss_dice: 0.8354  decode.d0.loss_cls: 0.6367  decode.d0.loss_mask: 0.9898  decode.d0.loss_dice: 0.8164  decode.d1.loss_cls: 0.2292  decode.d1.loss_mask: 1.0098  decode.d1.loss_dice: 0.8136  decode.d2.loss_cls: 0.1799  decode.d2.loss_mask: 1.0577  decode.d2.loss_dice: 0.8554  decode.d3.loss_cls: 0.1584  decode.d3.loss_mask: 1.1035  decode.d3.loss_dice: 0.8778  decode.d4.loss_cls: 0.1765  decode.d4.loss_mask: 1.0874  decode.d4.loss_dice: 0.8691  decode.d5.loss_cls: 0.1763  decode.d5.loss_mask: 1.0551  decode.d5.loss_dice: 0.8478  decode.d6.loss_cls: 0.1761  decode.d6.loss_mask: 1.0679  decode.d6.loss_dice: 0.8576  decode.d7.loss_cls: 0.1632  decode.d7.loss_mask: 1.0937  decode.d7.loss_dice: 0.8690  decode.d8.loss_cls: 0.1865  decode.d8.loss_mask: 1.0379  decode.d8.loss_dice: 0.8096
05/26 14:21:45 - mmengine - INFO - Iter(train) [ 29450/160000]  base_lr: 8.3271e-05 lr: 8.3271e-06  eta: 14:52:11  time: 0.4036  data_time: 0.0086  memory: 5976  grad_norm: 1220.7158  loss: 33.7500  decode.loss_cls: 0.4337  decode.loss_mask: 1.8012  decode.loss_dice: 1.1741  decode.d0.loss_cls: 1.0866  decode.d0.loss_mask: 1.4718  decode.d0.loss_dice: 1.1207  decode.d1.loss_cls: 0.5242  decode.d1.loss_mask: 1.6106  decode.d1.loss_dice: 1.1384  decode.d2.loss_cls: 0.4989  decode.d2.loss_mask: 1.6679  decode.d2.loss_dice: 1.1511  decode.d3.loss_cls: 0.4290  decode.d3.loss_mask: 1.7473  decode.d3.loss_dice: 1.1466  decode.d4.loss_cls: 0.4679  decode.d4.loss_mask: 1.7764  decode.d4.loss_dice: 1.1502  decode.d5.loss_cls: 0.4536  decode.d5.loss_mask: 1.7562  decode.d5.loss_dice: 1.1814  decode.d6.loss_cls: 0.5169  decode.d6.loss_mask: 1.6922  decode.d6.loss_dice: 1.1639  decode.d7.loss_cls: 0.4205  decode.d7.loss_mask: 1.7576  decode.d7.loss_dice: 1.1702  decode.d8.loss_cls: 0.4539  decode.d8.loss_mask: 1.6506  decode.d8.loss_dice: 1.1363
05/26 14:22:06 - mmengine - INFO - Iter(train) [ 29500/160000]  base_lr: 8.3242e-05 lr: 8.3242e-06  eta: 14:51:50  time: 0.4037  data_time: 0.0087  memory: 5991  grad_norm: 524.4277  loss: 26.6579  decode.loss_cls: 0.3788  decode.loss_mask: 1.1747  decode.loss_dice: 1.0621  decode.d0.loss_cls: 0.8966  decode.d0.loss_mask: 1.1623  decode.d0.loss_dice: 1.0566  decode.d1.loss_cls: 0.4190  decode.d1.loss_mask: 1.1696  decode.d1.loss_dice: 1.0303  decode.d2.loss_cls: 0.3649  decode.d2.loss_mask: 1.1814  decode.d2.loss_dice: 1.0491  decode.d3.loss_cls: 0.3745  decode.d3.loss_mask: 1.2198  decode.d3.loss_dice: 1.0576  decode.d4.loss_cls: 0.3970  decode.d4.loss_mask: 1.1776  decode.d4.loss_dice: 1.0510  decode.d5.loss_cls: 0.4040  decode.d5.loss_mask: 1.2251  decode.d5.loss_dice: 1.0445  decode.d6.loss_cls: 0.3908  decode.d6.loss_mask: 1.2154  decode.d6.loss_dice: 1.0531  decode.d7.loss_cls: 0.3627  decode.d7.loss_mask: 1.1427  decode.d7.loss_dice: 1.0283  decode.d8.loss_cls: 0.3684  decode.d8.loss_mask: 1.1788  decode.d8.loss_dice: 1.0214
05/26 14:22:26 - mmengine - INFO - Iter(train) [ 29550/160000]  base_lr: 8.3214e-05 lr: 8.3214e-06  eta: 14:51:28  time: 0.4036  data_time: 0.0086  memory: 5971  grad_norm: 542.4158  loss: 25.2063  decode.loss_cls: 0.3312  decode.loss_mask: 1.2648  decode.loss_dice: 0.8517  decode.d0.loss_cls: 0.7335  decode.d0.loss_mask: 1.2708  decode.d0.loss_dice: 0.8772  decode.d1.loss_cls: 0.2449  decode.d1.loss_mask: 1.2972  decode.d1.loss_dice: 0.9035  decode.d2.loss_cls: 0.3077  decode.d2.loss_mask: 1.2476  decode.d2.loss_dice: 0.9085  decode.d3.loss_cls: 0.3286  decode.d3.loss_mask: 1.2739  decode.d3.loss_dice: 0.9123  decode.d4.loss_cls: 0.2976  decode.d4.loss_mask: 1.2756  decode.d4.loss_dice: 0.9195  decode.d5.loss_cls: 0.3359  decode.d5.loss_mask: 1.2694  decode.d5.loss_dice: 0.9107  decode.d6.loss_cls: 0.3308  decode.d6.loss_mask: 1.2478  decode.d6.loss_dice: 0.9042  decode.d7.loss_cls: 0.3231  decode.d7.loss_mask: 1.2639  decode.d7.loss_dice: 0.9038  decode.d8.loss_cls: 0.3069  decode.d8.loss_mask: 1.2722  decode.d8.loss_dice: 0.8915
05/26 14:22:46 - mmengine - INFO - Iter(train) [ 29600/160000]  base_lr: 8.3185e-05 lr: 8.3185e-06  eta: 14:51:07  time: 0.4044  data_time: 0.0086  memory: 5969  grad_norm: 982.3177  loss: 27.6867  decode.loss_cls: 0.2771  decode.loss_mask: 1.4957  decode.loss_dice: 0.9330  decode.d0.loss_cls: 0.9071  decode.d0.loss_mask: 1.3206  decode.d0.loss_dice: 0.8881  decode.d1.loss_cls: 0.2726  decode.d1.loss_mask: 1.4998  decode.d1.loss_dice: 0.9544  decode.d2.loss_cls: 0.2481  decode.d2.loss_mask: 1.4916  decode.d2.loss_dice: 0.9333  decode.d3.loss_cls: 0.2603  decode.d3.loss_mask: 1.5083  decode.d3.loss_dice: 0.9493  decode.d4.loss_cls: 0.3859  decode.d4.loss_mask: 1.5108  decode.d4.loss_dice: 0.9904  decode.d5.loss_cls: 0.3435  decode.d5.loss_mask: 1.4992  decode.d5.loss_dice: 0.9231  decode.d6.loss_cls: 0.3076  decode.d6.loss_mask: 1.5117  decode.d6.loss_dice: 0.9370  decode.d7.loss_cls: 0.3063  decode.d7.loss_mask: 1.5083  decode.d7.loss_dice: 0.9218  decode.d8.loss_cls: 0.3168  decode.d8.loss_mask: 1.4184  decode.d8.loss_dice: 0.8666
05/26 14:23:06 - mmengine - INFO - Iter(train) [ 29650/160000]  base_lr: 8.3156e-05 lr: 8.3156e-06  eta: 14:50:45  time: 0.4033  data_time: 0.0086  memory: 5965  grad_norm: 1004.4958  loss: 28.5136  decode.loss_cls: 0.2624  decode.loss_mask: 1.5659  decode.loss_dice: 1.0028  decode.d0.loss_cls: 0.8215  decode.d0.loss_mask: 1.3628  decode.d0.loss_dice: 0.9532  decode.d1.loss_cls: 0.3699  decode.d1.loss_mask: 1.5028  decode.d1.loss_dice: 0.9469  decode.d2.loss_cls: 0.3682  decode.d2.loss_mask: 1.4728  decode.d2.loss_dice: 0.9510  decode.d3.loss_cls: 0.3949  decode.d3.loss_mask: 1.4121  decode.d3.loss_dice: 0.9409  decode.d4.loss_cls: 0.4109  decode.d4.loss_mask: 1.4158  decode.d4.loss_dice: 0.9854  decode.d5.loss_cls: 0.3627  decode.d5.loss_mask: 1.4644  decode.d5.loss_dice: 0.9743  decode.d6.loss_cls: 0.3068  decode.d6.loss_mask: 1.5827  decode.d6.loss_dice: 1.0032  decode.d7.loss_cls: 0.2786  decode.d7.loss_mask: 1.5933  decode.d7.loss_dice: 1.0189  decode.d8.loss_cls: 0.3734  decode.d8.loss_mask: 1.4395  decode.d8.loss_dice: 0.9756
05/26 14:23:27 - mmengine - INFO - Iter(train) [ 29700/160000]  base_lr: 8.3127e-05 lr: 8.3127e-06  eta: 14:50:23  time: 0.4030  data_time: 0.0087  memory: 5966  grad_norm: 738.8918  loss: 24.2787  decode.loss_cls: 0.2660  decode.loss_mask: 1.2442  decode.loss_dice: 0.8397  decode.d0.loss_cls: 0.7081  decode.d0.loss_mask: 1.2296  decode.d0.loss_dice: 0.8705  decode.d1.loss_cls: 0.3168  decode.d1.loss_mask: 1.2735  decode.d1.loss_dice: 0.8683  decode.d2.loss_cls: 0.3038  decode.d2.loss_mask: 1.2697  decode.d2.loss_dice: 0.8444  decode.d3.loss_cls: 0.2869  decode.d3.loss_mask: 1.2340  decode.d3.loss_dice: 0.8179  decode.d4.loss_cls: 0.2861  decode.d4.loss_mask: 1.2558  decode.d4.loss_dice: 0.8585  decode.d5.loss_cls: 0.3037  decode.d5.loss_mask: 1.2172  decode.d5.loss_dice: 0.8506  decode.d6.loss_cls: 0.2627  decode.d6.loss_mask: 1.2600  decode.d6.loss_dice: 0.8566  decode.d7.loss_cls: 0.3182  decode.d7.loss_mask: 1.2222  decode.d7.loss_dice: 0.8312  decode.d8.loss_cls: 0.2719  decode.d8.loss_mask: 1.2666  decode.d8.loss_dice: 0.8439
05/26 14:23:47 - mmengine - INFO - Iter(train) [ 29750/160000]  base_lr: 8.3099e-05 lr: 8.3099e-06  eta: 14:50:01  time: 0.4032  data_time: 0.0087  memory: 5971  grad_norm: 860.5741  loss: 24.0187  decode.loss_cls: 0.3096  decode.loss_mask: 1.0701  decode.loss_dice: 0.9045  decode.d0.loss_cls: 0.7304  decode.d0.loss_mask: 1.1042  decode.d0.loss_dice: 0.9251  decode.d1.loss_cls: 0.3841  decode.d1.loss_mask: 1.0828  decode.d1.loss_dice: 0.8864  decode.d2.loss_cls: 0.3586  decode.d2.loss_mask: 1.0987  decode.d2.loss_dice: 0.9359  decode.d3.loss_cls: 0.3962  decode.d3.loss_mask: 1.1068  decode.d3.loss_dice: 0.9450  decode.d4.loss_cls: 0.3911  decode.d4.loss_mask: 1.0970  decode.d4.loss_dice: 0.9422  decode.d5.loss_cls: 0.3872  decode.d5.loss_mask: 1.0824  decode.d5.loss_dice: 0.9101  decode.d6.loss_cls: 0.3310  decode.d6.loss_mask: 1.0944  decode.d6.loss_dice: 0.9243  decode.d7.loss_cls: 0.3653  decode.d7.loss_mask: 1.0633  decode.d7.loss_dice: 0.8993  decode.d8.loss_cls: 0.3303  decode.d8.loss_mask: 1.0691  decode.d8.loss_dice: 0.8932
05/26 14:24:07 - mmengine - INFO - Iter(train) [ 29800/160000]  base_lr: 8.3070e-05 lr: 8.3070e-06  eta: 14:49:40  time: 0.4048  data_time: 0.0088  memory: 5970  grad_norm: 769.3646  loss: 28.6406  decode.loss_cls: 0.4448  decode.loss_mask: 1.2589  decode.loss_dice: 1.0828  decode.d0.loss_cls: 0.8305  decode.d0.loss_mask: 1.2780  decode.d0.loss_dice: 1.0624  decode.d1.loss_cls: 0.4284  decode.d1.loss_mask: 1.2917  decode.d1.loss_dice: 1.0854  decode.d2.loss_cls: 0.3912  decode.d2.loss_mask: 1.3552  decode.d2.loss_dice: 1.0902  decode.d3.loss_cls: 0.4223  decode.d3.loss_mask: 1.2912  decode.d3.loss_dice: 1.0800  decode.d4.loss_cls: 0.4002  decode.d4.loss_mask: 1.3704  decode.d4.loss_dice: 1.1435  decode.d5.loss_cls: 0.4549  decode.d5.loss_mask: 1.2954  decode.d5.loss_dice: 1.1131  decode.d6.loss_cls: 0.3884  decode.d6.loss_mask: 1.2963  decode.d6.loss_dice: 1.0967  decode.d7.loss_cls: 0.3828  decode.d7.loss_mask: 1.3705  decode.d7.loss_dice: 1.0845  decode.d8.loss_cls: 0.4212  decode.d8.loss_mask: 1.3396  decode.d8.loss_dice: 1.0899
05/26 14:24:27 - mmengine - INFO - Iter(train) [ 29850/160000]  base_lr: 8.3041e-05 lr: 8.3041e-06  eta: 14:49:18  time: 0.4042  data_time: 0.0087  memory: 5966  grad_norm: 705.3791  loss: 23.7154  decode.loss_cls: 0.3046  decode.loss_mask: 1.0158  decode.loss_dice: 0.9295  decode.d0.loss_cls: 0.9971  decode.d0.loss_mask: 0.9568  decode.d0.loss_dice: 0.8634  decode.d1.loss_cls: 0.3523  decode.d1.loss_mask: 1.0554  decode.d1.loss_dice: 0.9366  decode.d2.loss_cls: 0.3595  decode.d2.loss_mask: 0.9806  decode.d2.loss_dice: 0.9037  decode.d3.loss_cls: 0.3587  decode.d3.loss_mask: 0.9980  decode.d3.loss_dice: 0.9325  decode.d4.loss_cls: 0.3949  decode.d4.loss_mask: 1.0671  decode.d4.loss_dice: 0.9487  decode.d5.loss_cls: 0.3713  decode.d5.loss_mask: 1.0403  decode.d5.loss_dice: 0.9290  decode.d6.loss_cls: 0.4157  decode.d6.loss_mask: 1.0410  decode.d6.loss_dice: 0.9447  decode.d7.loss_cls: 0.3996  decode.d7.loss_mask: 1.0836  decode.d7.loss_dice: 0.9370  decode.d8.loss_cls: 0.3731  decode.d8.loss_mask: 0.9585  decode.d8.loss_dice: 0.8661
05/26 14:24:47 - mmengine - INFO - Iter(train) [ 29900/160000]  base_lr: 8.3013e-05 lr: 8.3013e-06  eta: 14:48:56  time: 0.4046  data_time: 0.0087  memory: 5972  grad_norm: 914.2341  loss: 26.1010  decode.loss_cls: 0.2641  decode.loss_mask: 1.3367  decode.loss_dice: 0.9965  decode.d0.loss_cls: 0.8165  decode.d0.loss_mask: 1.2015  decode.d0.loss_dice: 0.9218  decode.d1.loss_cls: 0.3198  decode.d1.loss_mask: 1.2189  decode.d1.loss_dice: 0.9385  decode.d2.loss_cls: 0.3018  decode.d2.loss_mask: 1.2352  decode.d2.loss_dice: 0.9358  decode.d3.loss_cls: 0.3676  decode.d3.loss_mask: 1.2977  decode.d3.loss_dice: 0.9660  decode.d4.loss_cls: 0.3681  decode.d4.loss_mask: 1.2101  decode.d4.loss_dice: 0.9380  decode.d5.loss_cls: 0.3097  decode.d5.loss_mask: 1.2474  decode.d5.loss_dice: 0.9582  decode.d6.loss_cls: 0.3634  decode.d6.loss_mask: 1.3514  decode.d6.loss_dice: 0.9813  decode.d7.loss_cls: 0.2451  decode.d7.loss_mask: 1.4039  decode.d7.loss_dice: 1.0049  decode.d8.loss_cls: 0.2676  decode.d8.loss_mask: 1.3323  decode.d8.loss_dice: 1.0010
05/26 14:25:08 - mmengine - INFO - Iter(train) [ 29950/160000]  base_lr: 8.2984e-05 lr: 8.2984e-06  eta: 14:48:34  time: 0.4035  data_time: 0.0087  memory: 5968  grad_norm: 1102.4229  loss: 28.3478  decode.loss_cls: 0.3372  decode.loss_mask: 1.4117  decode.loss_dice: 1.0387  decode.d0.loss_cls: 0.7992  decode.d0.loss_mask: 1.3308  decode.d0.loss_dice: 0.9404  decode.d1.loss_cls: 0.4033  decode.d1.loss_mask: 1.4510  decode.d1.loss_dice: 0.9632  decode.d2.loss_cls: 0.3682  decode.d2.loss_mask: 1.4083  decode.d2.loss_dice: 0.9386  decode.d3.loss_cls: 0.3896  decode.d3.loss_mask: 1.4066  decode.d3.loss_dice: 0.9606  decode.d4.loss_cls: 0.4154  decode.d4.loss_mask: 1.4009  decode.d4.loss_dice: 0.9709  decode.d5.loss_cls: 0.3820  decode.d5.loss_mask: 1.4331  decode.d5.loss_dice: 0.9945  decode.d6.loss_cls: 0.3396  decode.d6.loss_mask: 1.4739  decode.d6.loss_dice: 1.0615  decode.d7.loss_cls: 0.3036  decode.d7.loss_mask: 1.5640  decode.d7.loss_dice: 1.0564  decode.d8.loss_cls: 0.2924  decode.d8.loss_mask: 1.4668  decode.d8.loss_dice: 1.0453
05/26 14:25:28 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 14:25:28 - mmengine - INFO - Iter(train) [ 30000/160000]  base_lr: 8.2955e-05 lr: 8.2955e-06  eta: 14:48:12  time: 0.4050  data_time: 0.0086  memory: 5980  grad_norm: 1098.4449  loss: 25.2030  decode.loss_cls: 0.2486  decode.loss_mask: 1.2254  decode.loss_dice: 0.9299  decode.d0.loss_cls: 0.8410  decode.d0.loss_mask: 1.1917  decode.d0.loss_dice: 0.9284  decode.d1.loss_cls: 0.2579  decode.d1.loss_mask: 1.2678  decode.d1.loss_dice: 0.9719  decode.d2.loss_cls: 0.3558  decode.d2.loss_mask: 1.1637  decode.d2.loss_dice: 0.9174  decode.d3.loss_cls: 0.3394  decode.d3.loss_mask: 1.1803  decode.d3.loss_dice: 0.8845  decode.d4.loss_cls: 0.3761  decode.d4.loss_mask: 1.2272  decode.d4.loss_dice: 0.9523  decode.d5.loss_cls: 0.3620  decode.d5.loss_mask: 1.2417  decode.d5.loss_dice: 0.9095  decode.d6.loss_cls: 0.4161  decode.d6.loss_mask: 1.1550  decode.d6.loss_dice: 0.8964  decode.d7.loss_cls: 0.3400  decode.d7.loss_mask: 1.2404  decode.d7.loss_dice: 0.9499  decode.d8.loss_cls: 0.3545  decode.d8.loss_mask: 1.1801  decode.d8.loss_dice: 0.8981
05/26 14:25:28 - mmengine - INFO - Saving checkpoint at 30000 iterations
05/26 14:25:32 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:07  time: 0.0473  data_time: 0.0012  memory: 1391  
05/26 14:25:34 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:04  time: 0.0474  data_time: 0.0012  memory: 1205  
05/26 14:25:37 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:02  time: 0.0507  data_time: 0.0012  memory: 1596  
05/26 14:25:39 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0482  data_time: 0.0012  memory: 1298  
05/26 14:25:42 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:57  time: 0.0474  data_time: 0.0012  memory: 1298  
05/26 14:25:44 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0474  data_time: 0.0012  memory: 1279  
05/26 14:25:46 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:52  time: 0.0476  data_time: 0.0012  memory: 1224  
05/26 14:25:49 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0486  data_time: 0.0012  memory: 1298  
05/26 14:25:51 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:47  time: 0.0472  data_time: 0.0012  memory: 1298  
05/26 14:25:54 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0511  data_time: 0.0012  memory: 1725  
05/26 14:25:56 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0477  data_time: 0.0012  memory: 1336  
05/26 14:25:58 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0479  data_time: 0.0012  memory: 1298  
05/26 14:26:01 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0480  data_time: 0.0012  memory: 1205  
05/26 14:26:03 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:35  time: 0.0487  data_time: 0.0012  memory: 1316  
05/26 14:26:06 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0475  data_time: 0.0012  memory: 1279  
05/26 14:26:08 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0512  data_time: 0.0012  memory: 1410  
05/26 14:26:10 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0475  data_time: 0.0012  memory: 1279  
05/26 14:26:13 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0483  data_time: 0.0012  memory: 1205  
05/26 14:26:15 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:23  time: 0.0483  data_time: 0.0012  memory: 1205  
05/26 14:26:18 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0475  data_time: 0.0012  memory: 1336  
05/26 14:26:20 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0473  data_time: 0.0012  memory: 1246  
05/26 14:26:22 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0503  data_time: 0.0013  memory: 1503  
05/26 14:26:25 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0474  data_time: 0.0012  memory: 1261  
05/26 14:26:27 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0492  data_time: 0.0012  memory: 1298  
05/26 14:26:30 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0476  data_time: 0.0012  memory: 1447  
05/26 14:26:32 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0473  data_time: 0.0012  memory: 1298  
05/26 14:26:34 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0488  data_time: 0.0012  memory: 1279  
05/26 14:26:37 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0479  data_time: 0.0013  memory: 1205  
05/26 14:26:39 - mmengine - INFO - per class results:
05/26 14:26:39 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.03 | 96.98 |
|  aeroplane  | 90.18 | 95.78 |
|   bicycle   | 41.54 | 94.24 |
|     bird    | 89.14 | 93.93 |
|     boat    | 63.57 | 91.73 |
|    bottle   | 80.51 | 89.66 |
|     bus     |  89.0 |  98.1 |
|     car     | 89.74 | 94.71 |
|     cat     | 88.08 | 96.61 |
|    chair    | 37.56 | 58.61 |
|     cow     | 34.91 | 36.68 |
| diningtable |  61.9 |  73.2 |
|     dog     | 78.79 |  91.0 |
|    horse    | 61.45 | 94.48 |
|  motorbike  | 89.91 | 96.42 |
|    person   | 88.88 | 93.83 |
| pottedplant | 55.61 | 74.82 |
|    sheep    |  81.3 | 90.05 |
|     sofa    | 51.93 | 65.92 |
|    train    | 83.99 | 88.77 |
|  tvmonitor  | 72.03 | 80.89 |
+-------------+-------+-------+
05/26 14:26:39 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 94.3100  mIoU: 72.6200  mAcc: 85.5400  data_time: 0.0012  time: 0.0479
05/26 14:26:39 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_25000.pth is removed
05/26 14:26:40 - mmengine - INFO - The best checkpoint with 72.6200 mIoU at 30000 iter is saved to best_mIoU_iter_30000.pth.
05/26 14:27:02 - mmengine - INFO - Iter(train) [ 30050/160000]  base_lr: 8.2926e-05 lr: 8.2926e-06  eta: 14:48:03  time: 0.4042  data_time: 0.0087  memory: 5970  grad_norm: 569.3970  loss: 25.5349  decode.loss_cls: 0.3502  decode.loss_mask: 1.2739  decode.loss_dice: 0.9246  decode.d0.loss_cls: 0.8735  decode.d0.loss_mask: 1.1874  decode.d0.loss_dice: 0.8863  decode.d1.loss_cls: 0.3510  decode.d1.loss_mask: 1.2383  decode.d1.loss_dice: 0.9077  decode.d2.loss_cls: 0.3163  decode.d2.loss_mask: 1.2236  decode.d2.loss_dice: 0.9059  decode.d3.loss_cls: 0.3185  decode.d3.loss_mask: 1.2532  decode.d3.loss_dice: 0.9051  decode.d4.loss_cls: 0.3563  decode.d4.loss_mask: 1.2329  decode.d4.loss_dice: 0.9102  decode.d5.loss_cls: 0.3326  decode.d5.loss_mask: 1.2788  decode.d5.loss_dice: 0.9134  decode.d6.loss_cls: 0.3594  decode.d6.loss_mask: 1.2304  decode.d6.loss_dice: 0.9112  decode.d7.loss_cls: 0.3747  decode.d7.loss_mask: 1.2580  decode.d7.loss_dice: 0.9249  decode.d8.loss_cls: 0.3363  decode.d8.loss_mask: 1.2672  decode.d8.loss_dice: 0.9332
05/26 14:27:23 - mmengine - INFO - Iter(train) [ 30100/160000]  base_lr: 8.2898e-05 lr: 8.2898e-06  eta: 14:47:42  time: 0.4054  data_time: 0.0087  memory: 5981  grad_norm: 750.6068  loss: 29.8649  decode.loss_cls: 0.3994  decode.loss_mask: 1.4049  decode.loss_dice: 1.0703  decode.d0.loss_cls: 0.9747  decode.d0.loss_mask: 1.3076  decode.d0.loss_dice: 1.0470  decode.d1.loss_cls: 0.4664  decode.d1.loss_mask: 1.4062  decode.d1.loss_dice: 1.1065  decode.d2.loss_cls: 0.3791  decode.d2.loss_mask: 1.4043  decode.d2.loss_dice: 1.1241  decode.d3.loss_cls: 0.4030  decode.d3.loss_mask: 1.4255  decode.d3.loss_dice: 1.1347  decode.d4.loss_cls: 0.4399  decode.d4.loss_mask: 1.3857  decode.d4.loss_dice: 1.0997  decode.d5.loss_cls: 0.4814  decode.d5.loss_mask: 1.4112  decode.d5.loss_dice: 1.0886  decode.d6.loss_cls: 0.4772  decode.d6.loss_mask: 1.4268  decode.d6.loss_dice: 1.1049  decode.d7.loss_cls: 0.4937  decode.d7.loss_mask: 1.4078  decode.d7.loss_dice: 1.0716  decode.d8.loss_cls: 0.4377  decode.d8.loss_mask: 1.3916  decode.d8.loss_dice: 1.0933
05/26 14:27:43 - mmengine - INFO - Iter(train) [ 30150/160000]  base_lr: 8.2869e-05 lr: 8.2869e-06  eta: 14:47:20  time: 0.4051  data_time: 0.0087  memory: 5976  grad_norm: 866.5528  loss: 29.7424  decode.loss_cls: 0.4745  decode.loss_mask: 1.4732  decode.loss_dice: 0.9689  decode.d0.loss_cls: 0.9770  decode.d0.loss_mask: 1.4016  decode.d0.loss_dice: 0.8947  decode.d1.loss_cls: 0.4697  decode.d1.loss_mask: 1.5135  decode.d1.loss_dice: 1.0293  decode.d2.loss_cls: 0.5126  decode.d2.loss_mask: 1.3972  decode.d2.loss_dice: 0.9013  decode.d3.loss_cls: 0.5080  decode.d3.loss_mask: 1.5116  decode.d3.loss_dice: 0.9788  decode.d4.loss_cls: 0.4909  decode.d4.loss_mask: 1.5020  decode.d4.loss_dice: 1.0051  decode.d5.loss_cls: 0.5246  decode.d5.loss_mask: 1.4465  decode.d5.loss_dice: 0.9377  decode.d6.loss_cls: 0.4870  decode.d6.loss_mask: 1.4853  decode.d6.loss_dice: 0.9782  decode.d7.loss_cls: 0.4643  decode.d7.loss_mask: 1.5023  decode.d7.loss_dice: 0.9784  decode.d8.loss_cls: 0.5050  decode.d8.loss_mask: 1.4615  decode.d8.loss_dice: 0.9617
05/26 14:28:03 - mmengine - INFO - Iter(train) [ 30200/160000]  base_lr: 8.2840e-05 lr: 8.2840e-06  eta: 14:46:59  time: 0.4046  data_time: 0.0088  memory: 5971  grad_norm: 740.0666  loss: 29.4678  decode.loss_cls: 0.4461  decode.loss_mask: 1.5005  decode.loss_dice: 0.9961  decode.d0.loss_cls: 0.8961  decode.d0.loss_mask: 1.3215  decode.d0.loss_dice: 0.9807  decode.d1.loss_cls: 0.4714  decode.d1.loss_mask: 1.4045  decode.d1.loss_dice: 1.0273  decode.d2.loss_cls: 0.4423  decode.d2.loss_mask: 1.4307  decode.d2.loss_dice: 1.0143  decode.d3.loss_cls: 0.4847  decode.d3.loss_mask: 1.4479  decode.d3.loss_dice: 0.9978  decode.d4.loss_cls: 0.4781  decode.d4.loss_mask: 1.4191  decode.d4.loss_dice: 1.0055  decode.d5.loss_cls: 0.4667  decode.d5.loss_mask: 1.4596  decode.d5.loss_dice: 1.0061  decode.d6.loss_cls: 0.5033  decode.d6.loss_mask: 1.4758  decode.d6.loss_dice: 1.0335  decode.d7.loss_cls: 0.4391  decode.d7.loss_mask: 1.4452  decode.d7.loss_dice: 0.9994  decode.d8.loss_cls: 0.4193  decode.d8.loss_mask: 1.4778  decode.d8.loss_dice: 0.9774
05/26 14:28:23 - mmengine - INFO - Iter(train) [ 30250/160000]  base_lr: 8.2812e-05 lr: 8.2812e-06  eta: 14:46:37  time: 0.4055  data_time: 0.0088  memory: 5980  grad_norm: 706.3676  loss: 25.8175  decode.loss_cls: 0.1879  decode.loss_mask: 1.3747  decode.loss_dice: 0.9449  decode.d0.loss_cls: 0.8084  decode.d0.loss_mask: 1.2937  decode.d0.loss_dice: 0.8836  decode.d1.loss_cls: 0.1536  decode.d1.loss_mask: 1.3704  decode.d1.loss_dice: 0.9542  decode.d2.loss_cls: 0.2478  decode.d2.loss_mask: 1.3563  decode.d2.loss_dice: 0.9051  decode.d3.loss_cls: 0.2380  decode.d3.loss_mask: 1.3698  decode.d3.loss_dice: 0.9208  decode.d4.loss_cls: 0.2228  decode.d4.loss_mask: 1.3826  decode.d4.loss_dice: 0.9341  decode.d5.loss_cls: 0.2421  decode.d5.loss_mask: 1.3864  decode.d5.loss_dice: 0.9330  decode.d6.loss_cls: 0.2409  decode.d6.loss_mask: 1.3721  decode.d6.loss_dice: 0.9651  decode.d7.loss_cls: 0.2411  decode.d7.loss_mask: 1.4064  decode.d7.loss_dice: 0.9782  decode.d8.loss_cls: 0.2239  decode.d8.loss_mask: 1.3470  decode.d8.loss_dice: 0.9329
05/26 14:28:44 - mmengine - INFO - Iter(train) [ 30300/160000]  base_lr: 8.2783e-05 lr: 8.2783e-06  eta: 14:46:16  time: 0.4044  data_time: 0.0088  memory: 5969  grad_norm: 982.6225  loss: 29.4447  decode.loss_cls: 0.3430  decode.loss_mask: 1.4794  decode.loss_dice: 1.0187  decode.d0.loss_cls: 0.8790  decode.d0.loss_mask: 1.4155  decode.d0.loss_dice: 1.0054  decode.d1.loss_cls: 0.4822  decode.d1.loss_mask: 1.4082  decode.d1.loss_dice: 0.9962  decode.d2.loss_cls: 0.3386  decode.d2.loss_mask: 1.4587  decode.d2.loss_dice: 1.0451  decode.d3.loss_cls: 0.3480  decode.d3.loss_mask: 1.5270  decode.d3.loss_dice: 1.0184  decode.d4.loss_cls: 0.3945  decode.d4.loss_mask: 1.4942  decode.d4.loss_dice: 1.0172  decode.d5.loss_cls: 0.3669  decode.d5.loss_mask: 1.5552  decode.d5.loss_dice: 1.0393  decode.d6.loss_cls: 0.3661  decode.d6.loss_mask: 1.4947  decode.d6.loss_dice: 1.0339  decode.d7.loss_cls: 0.3719  decode.d7.loss_mask: 1.5687  decode.d7.loss_dice: 1.0769  decode.d8.loss_cls: 0.3566  decode.d8.loss_mask: 1.5276  decode.d8.loss_dice: 1.0179
05/26 14:29:04 - mmengine - INFO - Iter(train) [ 30350/160000]  base_lr: 8.2754e-05 lr: 8.2754e-06  eta: 14:45:54  time: 0.4042  data_time: 0.0087  memory: 5980  grad_norm: 1439.9387  loss: 27.5621  decode.loss_cls: 0.3084  decode.loss_mask: 1.3125  decode.loss_dice: 1.1259  decode.d0.loss_cls: 0.7703  decode.d0.loss_mask: 1.2535  decode.d0.loss_dice: 1.0571  decode.d1.loss_cls: 0.3858  decode.d1.loss_mask: 1.2533  decode.d1.loss_dice: 1.0638  decode.d2.loss_cls: 0.3569  decode.d2.loss_mask: 1.2412  decode.d2.loss_dice: 1.0987  decode.d3.loss_cls: 0.3266  decode.d3.loss_mask: 1.2567  decode.d3.loss_dice: 1.0836  decode.d4.loss_cls: 0.3478  decode.d4.loss_mask: 1.3007  decode.d4.loss_dice: 1.1031  decode.d5.loss_cls: 0.3696  decode.d5.loss_mask: 1.2638  decode.d5.loss_dice: 1.0948  decode.d6.loss_cls: 0.3405  decode.d6.loss_mask: 1.2482  decode.d6.loss_dice: 1.1068  decode.d7.loss_cls: 0.3986  decode.d7.loss_mask: 1.2666  decode.d7.loss_dice: 1.1030  decode.d8.loss_cls: 0.3466  decode.d8.loss_mask: 1.2662  decode.d8.loss_dice: 1.1117
05/26 14:29:24 - mmengine - INFO - Iter(train) [ 30400/160000]  base_lr: 8.2725e-05 lr: 8.2725e-06  eta: 14:45:33  time: 0.4045  data_time: 0.0088  memory: 5974  grad_norm: 744.1671  loss: 24.7098  decode.loss_cls: 0.2930  decode.loss_mask: 1.1553  decode.loss_dice: 0.8837  decode.d0.loss_cls: 0.8798  decode.d0.loss_mask: 1.0491  decode.d0.loss_dice: 0.8522  decode.d1.loss_cls: 0.3509  decode.d1.loss_mask: 1.2015  decode.d1.loss_dice: 0.9256  decode.d2.loss_cls: 0.3888  decode.d2.loss_mask: 1.1760  decode.d2.loss_dice: 0.8846  decode.d3.loss_cls: 0.3533  decode.d3.loss_mask: 1.1845  decode.d3.loss_dice: 0.8949  decode.d4.loss_cls: 0.3532  decode.d4.loss_mask: 1.1848  decode.d4.loss_dice: 0.8984  decode.d5.loss_cls: 0.3789  decode.d5.loss_mask: 1.1817  decode.d5.loss_dice: 0.9203  decode.d6.loss_cls: 0.2816  decode.d6.loss_mask: 1.2898  decode.d6.loss_dice: 0.9540  decode.d7.loss_cls: 0.3120  decode.d7.loss_mask: 1.2155  decode.d7.loss_dice: 0.9348  decode.d8.loss_cls: 0.3406  decode.d8.loss_mask: 1.1038  decode.d8.loss_dice: 0.8870
05/26 14:29:44 - mmengine - INFO - Iter(train) [ 30450/160000]  base_lr: 8.2697e-05 lr: 8.2697e-06  eta: 14:45:11  time: 0.4043  data_time: 0.0087  memory: 5969  grad_norm: 749.6013  loss: 23.9794  decode.loss_cls: 0.3026  decode.loss_mask: 1.1875  decode.loss_dice: 0.8446  decode.d0.loss_cls: 0.8270  decode.d0.loss_mask: 1.0794  decode.d0.loss_dice: 0.8156  decode.d1.loss_cls: 0.3578  decode.d1.loss_mask: 1.2136  decode.d1.loss_dice: 0.8320  decode.d2.loss_cls: 0.3681  decode.d2.loss_mask: 1.1671  decode.d2.loss_dice: 0.8483  decode.d3.loss_cls: 0.3271  decode.d3.loss_mask: 1.1602  decode.d3.loss_dice: 0.8438  decode.d4.loss_cls: 0.3418  decode.d4.loss_mask: 1.1217  decode.d4.loss_dice: 0.8260  decode.d5.loss_cls: 0.3813  decode.d5.loss_mask: 1.1905  decode.d5.loss_dice: 0.8565  decode.d6.loss_cls: 0.3542  decode.d6.loss_mask: 1.1778  decode.d6.loss_dice: 0.8668  decode.d7.loss_cls: 0.3475  decode.d7.loss_mask: 1.1539  decode.d7.loss_dice: 0.8482  decode.d8.loss_cls: 0.3185  decode.d8.loss_mask: 1.1868  decode.d8.loss_dice: 0.8331
05/26 14:30:05 - mmengine - INFO - Iter(train) [ 30500/160000]  base_lr: 8.2668e-05 lr: 8.2668e-06  eta: 14:44:50  time: 0.4045  data_time: 0.0087  memory: 5991  grad_norm: 747.5541  loss: 25.0001  decode.loss_cls: 0.3460  decode.loss_mask: 1.2097  decode.loss_dice: 0.9125  decode.d0.loss_cls: 0.8107  decode.d0.loss_mask: 1.1031  decode.d0.loss_dice: 0.8606  decode.d1.loss_cls: 0.4359  decode.d1.loss_mask: 1.1960  decode.d1.loss_dice: 0.8494  decode.d2.loss_cls: 0.4076  decode.d2.loss_mask: 1.1573  decode.d2.loss_dice: 0.8390  decode.d3.loss_cls: 0.3474  decode.d3.loss_mask: 1.2067  decode.d3.loss_dice: 0.8644  decode.d4.loss_cls: 0.4132  decode.d4.loss_mask: 1.2456  decode.d4.loss_dice: 0.9013  decode.d5.loss_cls: 0.3721  decode.d5.loss_mask: 1.1912  decode.d5.loss_dice: 0.9111  decode.d6.loss_cls: 0.3692  decode.d6.loss_mask: 1.2473  decode.d6.loss_dice: 0.8659  decode.d7.loss_cls: 0.3604  decode.d7.loss_mask: 1.2207  decode.d7.loss_dice: 0.8939  decode.d8.loss_cls: 0.3024  decode.d8.loss_mask: 1.2691  decode.d8.loss_dice: 0.8905
05/26 14:30:25 - mmengine - INFO - Iter(train) [ 30550/160000]  base_lr: 8.2639e-05 lr: 8.2639e-06  eta: 14:44:28  time: 0.4060  data_time: 0.0088  memory: 5984  grad_norm: 817.9724  loss: 26.5190  decode.loss_cls: 0.2619  decode.loss_mask: 1.4335  decode.loss_dice: 0.9977  decode.d0.loss_cls: 0.8643  decode.d0.loss_mask: 1.2719  decode.d0.loss_dice: 0.9479  decode.d1.loss_cls: 0.3046  decode.d1.loss_mask: 1.3280  decode.d1.loss_dice: 0.9252  decode.d2.loss_cls: 0.2807  decode.d2.loss_mask: 1.3478  decode.d2.loss_dice: 0.9764  decode.d3.loss_cls: 0.2965  decode.d3.loss_mask: 1.3466  decode.d3.loss_dice: 0.9368  decode.d4.loss_cls: 0.3575  decode.d4.loss_mask: 1.3098  decode.d4.loss_dice: 0.9586  decode.d5.loss_cls: 0.3099  decode.d5.loss_mask: 1.3542  decode.d5.loss_dice: 0.9911  decode.d6.loss_cls: 0.2314  decode.d6.loss_mask: 1.3749  decode.d6.loss_dice: 0.9940  decode.d7.loss_cls: 0.2954  decode.d7.loss_mask: 1.3414  decode.d7.loss_dice: 0.9568  decode.d8.loss_cls: 0.2737  decode.d8.loss_mask: 1.3213  decode.d8.loss_dice: 0.9293
05/26 14:30:45 - mmengine - INFO - Iter(train) [ 30600/160000]  base_lr: 8.2611e-05 lr: 8.2611e-06  eta: 14:44:07  time: 0.4050  data_time: 0.0087  memory: 5969  grad_norm: 815.7837  loss: 28.3938  decode.loss_cls: 0.3024  decode.loss_mask: 1.4818  decode.loss_dice: 1.0379  decode.d0.loss_cls: 0.7682  decode.d0.loss_mask: 1.3635  decode.d0.loss_dice: 0.9564  decode.d1.loss_cls: 0.2972  decode.d1.loss_mask: 1.4645  decode.d1.loss_dice: 1.0072  decode.d2.loss_cls: 0.3534  decode.d2.loss_mask: 1.4458  decode.d2.loss_dice: 0.9811  decode.d3.loss_cls: 0.3555  decode.d3.loss_mask: 1.4365  decode.d3.loss_dice: 0.9997  decode.d4.loss_cls: 0.4278  decode.d4.loss_mask: 1.4395  decode.d4.loss_dice: 1.0283  decode.d5.loss_cls: 0.3843  decode.d5.loss_mask: 1.4321  decode.d5.loss_dice: 0.9978  decode.d6.loss_cls: 0.3747  decode.d6.loss_mask: 1.4596  decode.d6.loss_dice: 1.0251  decode.d7.loss_cls: 0.3365  decode.d7.loss_mask: 1.4555  decode.d7.loss_dice: 1.0186  decode.d8.loss_cls: 0.3530  decode.d8.loss_mask: 1.4332  decode.d8.loss_dice: 0.9768
05/26 14:31:06 - mmengine - INFO - Iter(train) [ 30650/160000]  base_lr: 8.2582e-05 lr: 8.2582e-06  eta: 14:43:45  time: 0.4035  data_time: 0.0087  memory: 5967  grad_norm: 577.5289  loss: 24.2298  decode.loss_cls: 0.2937  decode.loss_mask: 1.2519  decode.loss_dice: 0.8627  decode.d0.loss_cls: 0.7420  decode.d0.loss_mask: 1.1851  decode.d0.loss_dice: 0.8248  decode.d1.loss_cls: 0.3017  decode.d1.loss_mask: 1.2168  decode.d1.loss_dice: 0.8399  decode.d2.loss_cls: 0.3639  decode.d2.loss_mask: 1.1858  decode.d2.loss_dice: 0.8411  decode.d3.loss_cls: 0.3500  decode.d3.loss_mask: 1.1954  decode.d3.loss_dice: 0.8433  decode.d4.loss_cls: 0.3378  decode.d4.loss_mask: 1.2359  decode.d4.loss_dice: 0.8432  decode.d5.loss_cls: 0.3342  decode.d5.loss_mask: 1.2196  decode.d5.loss_dice: 0.8595  decode.d6.loss_cls: 0.3443  decode.d6.loss_mask: 1.2122  decode.d6.loss_dice: 0.8818  decode.d7.loss_cls: 0.3391  decode.d7.loss_mask: 1.1738  decode.d7.loss_dice: 0.8350  decode.d8.loss_cls: 0.2960  decode.d8.loss_mask: 1.1848  decode.d8.loss_dice: 0.8341
05/26 14:31:26 - mmengine - INFO - Iter(train) [ 30700/160000]  base_lr: 8.2553e-05 lr: 8.2553e-06  eta: 14:43:24  time: 0.4056  data_time: 0.0088  memory: 5970  grad_norm: 903.1315  loss: 24.6700  decode.loss_cls: 0.1966  decode.loss_mask: 1.3100  decode.loss_dice: 0.9074  decode.d0.loss_cls: 0.7184  decode.d0.loss_mask: 1.2848  decode.d0.loss_dice: 0.8893  decode.d1.loss_cls: 0.2541  decode.d1.loss_mask: 1.2441  decode.d1.loss_dice: 0.8894  decode.d2.loss_cls: 0.2114  decode.d2.loss_mask: 1.2875  decode.d2.loss_dice: 0.8969  decode.d3.loss_cls: 0.2717  decode.d3.loss_mask: 1.3050  decode.d3.loss_dice: 0.8828  decode.d4.loss_cls: 0.2379  decode.d4.loss_mask: 1.2927  decode.d4.loss_dice: 0.8869  decode.d5.loss_cls: 0.2372  decode.d5.loss_mask: 1.2358  decode.d5.loss_dice: 0.8583  decode.d6.loss_cls: 0.2849  decode.d6.loss_mask: 1.2863  decode.d6.loss_dice: 0.8833  decode.d7.loss_cls: 0.2797  decode.d7.loss_mask: 1.2818  decode.d7.loss_dice: 0.8698  decode.d8.loss_cls: 0.2069  decode.d8.loss_mask: 1.3752  decode.d8.loss_dice: 0.9039
05/26 14:31:46 - mmengine - INFO - Iter(train) [ 30750/160000]  base_lr: 8.2524e-05 lr: 8.2524e-06  eta: 14:43:02  time: 0.4043  data_time: 0.0089  memory: 5973  grad_norm: 1013.9886  loss: 27.1695  decode.loss_cls: 0.3197  decode.loss_mask: 1.3367  decode.loss_dice: 1.0154  decode.d0.loss_cls: 0.7365  decode.d0.loss_mask: 1.3270  decode.d0.loss_dice: 0.9661  decode.d1.loss_cls: 0.3938  decode.d1.loss_mask: 1.3346  decode.d1.loss_dice: 0.9994  decode.d2.loss_cls: 0.3632  decode.d2.loss_mask: 1.3506  decode.d2.loss_dice: 0.9929  decode.d3.loss_cls: 0.3805  decode.d3.loss_mask: 1.3039  decode.d3.loss_dice: 0.9781  decode.d4.loss_cls: 0.3841  decode.d4.loss_mask: 1.3234  decode.d4.loss_dice: 0.9673  decode.d5.loss_cls: 0.3856  decode.d5.loss_mask: 1.3237  decode.d5.loss_dice: 0.9224  decode.d6.loss_cls: 0.3309  decode.d6.loss_mask: 1.3544  decode.d6.loss_dice: 0.9501  decode.d7.loss_cls: 0.3982  decode.d7.loss_mask: 1.3462  decode.d7.loss_dice: 0.9856  decode.d8.loss_cls: 0.3437  decode.d8.loss_mask: 1.3661  decode.d8.loss_dice: 0.9892
05/26 14:32:06 - mmengine - INFO - Iter(train) [ 30800/160000]  base_lr: 8.2496e-05 lr: 8.2496e-06  eta: 14:42:41  time: 0.4051  data_time: 0.0087  memory: 5968  grad_norm: 757.6496  loss: 29.2925  decode.loss_cls: 0.3742  decode.loss_mask: 1.4826  decode.loss_dice: 1.0268  decode.d0.loss_cls: 0.7697  decode.d0.loss_mask: 1.4715  decode.d0.loss_dice: 0.9994  decode.d1.loss_cls: 0.3786  decode.d1.loss_mask: 1.5026  decode.d1.loss_dice: 1.0346  decode.d2.loss_cls: 0.3787  decode.d2.loss_mask: 1.4737  decode.d2.loss_dice: 0.9731  decode.d3.loss_cls: 0.3404  decode.d3.loss_mask: 1.4810  decode.d3.loss_dice: 1.0240  decode.d4.loss_cls: 0.3937  decode.d4.loss_mask: 1.5117  decode.d4.loss_dice: 1.0220  decode.d5.loss_cls: 0.3404  decode.d5.loss_mask: 1.6081  decode.d5.loss_dice: 1.0322  decode.d6.loss_cls: 0.3917  decode.d6.loss_mask: 1.4868  decode.d6.loss_dice: 0.9744  decode.d7.loss_cls: 0.3098  decode.d7.loss_mask: 1.5576  decode.d7.loss_dice: 1.0654  decode.d8.loss_cls: 0.3264  decode.d8.loss_mask: 1.5069  decode.d8.loss_dice: 1.0542
05/26 14:32:27 - mmengine - INFO - Iter(train) [ 30850/160000]  base_lr: 8.2467e-05 lr: 8.2467e-06  eta: 14:42:19  time: 0.4046  data_time: 0.0086  memory: 5973  grad_norm: 780.6180  loss: 24.2713  decode.loss_cls: 0.2214  decode.loss_mask: 1.2532  decode.loss_dice: 0.9328  decode.d0.loss_cls: 0.7599  decode.d0.loss_mask: 1.1332  decode.d0.loss_dice: 0.8214  decode.d1.loss_cls: 0.2901  decode.d1.loss_mask: 1.2172  decode.d1.loss_dice: 0.8718  decode.d2.loss_cls: 0.2700  decode.d2.loss_mask: 1.2382  decode.d2.loss_dice: 0.8631  decode.d3.loss_cls: 0.2490  decode.d3.loss_mask: 1.2260  decode.d3.loss_dice: 0.8828  decode.d4.loss_cls: 0.3450  decode.d4.loss_mask: 1.1935  decode.d4.loss_dice: 0.8124  decode.d5.loss_cls: 0.3499  decode.d5.loss_mask: 1.2174  decode.d5.loss_dice: 0.8536  decode.d6.loss_cls: 0.3450  decode.d6.loss_mask: 1.2205  decode.d6.loss_dice: 0.8548  decode.d7.loss_cls: 0.3240  decode.d7.loss_mask: 1.2495  decode.d7.loss_dice: 0.8897  decode.d8.loss_cls: 0.2658  decode.d8.loss_mask: 1.2437  decode.d8.loss_dice: 0.8761
05/26 14:32:47 - mmengine - INFO - Iter(train) [ 30900/160000]  base_lr: 8.2438e-05 lr: 8.2438e-06  eta: 14:41:58  time: 0.4055  data_time: 0.0087  memory: 5968  grad_norm: 753.0112  loss: 27.5274  decode.loss_cls: 0.3865  decode.loss_mask: 1.3479  decode.loss_dice: 0.9496  decode.d0.loss_cls: 0.9722  decode.d0.loss_mask: 1.2396  decode.d0.loss_dice: 0.9426  decode.d1.loss_cls: 0.4901  decode.d1.loss_mask: 1.2317  decode.d1.loss_dice: 0.9593  decode.d2.loss_cls: 0.4578  decode.d2.loss_mask: 1.2734  decode.d2.loss_dice: 0.9861  decode.d3.loss_cls: 0.4710  decode.d3.loss_mask: 1.2372  decode.d3.loss_dice: 0.9805  decode.d4.loss_cls: 0.5355  decode.d4.loss_mask: 1.2505  decode.d4.loss_dice: 0.9829  decode.d5.loss_cls: 0.4505  decode.d5.loss_mask: 1.2644  decode.d5.loss_dice: 0.9809  decode.d6.loss_cls: 0.4663  decode.d6.loss_mask: 1.2412  decode.d6.loss_dice: 0.9842  decode.d7.loss_cls: 0.4122  decode.d7.loss_mask: 1.3142  decode.d7.loss_dice: 0.9743  decode.d8.loss_cls: 0.4230  decode.d8.loss_mask: 1.3269  decode.d8.loss_dice: 0.9950
05/26 14:33:07 - mmengine - INFO - Iter(train) [ 30950/160000]  base_lr: 8.2409e-05 lr: 8.2409e-06  eta: 14:41:37  time: 0.4062  data_time: 0.0087  memory: 5966  grad_norm: 836.6731  loss: 25.3761  decode.loss_cls: 0.3251  decode.loss_mask: 1.2900  decode.loss_dice: 0.9478  decode.d0.loss_cls: 0.8300  decode.d0.loss_mask: 1.1920  decode.d0.loss_dice: 0.8387  decode.d1.loss_cls: 0.2901  decode.d1.loss_mask: 1.2810  decode.d1.loss_dice: 0.9074  decode.d2.loss_cls: 0.2933  decode.d2.loss_mask: 1.2578  decode.d2.loss_dice: 0.9214  decode.d3.loss_cls: 0.3032  decode.d3.loss_mask: 1.2422  decode.d3.loss_dice: 0.8994  decode.d4.loss_cls: 0.3047  decode.d4.loss_mask: 1.2549  decode.d4.loss_dice: 0.8992  decode.d5.loss_cls: 0.3382  decode.d5.loss_mask: 1.3099  decode.d5.loss_dice: 0.9415  decode.d6.loss_cls: 0.2963  decode.d6.loss_mask: 1.3233  decode.d6.loss_dice: 0.8941  decode.d7.loss_cls: 0.3003  decode.d7.loss_mask: 1.2749  decode.d7.loss_dice: 0.8959  decode.d8.loss_cls: 0.2956  decode.d8.loss_mask: 1.3182  decode.d8.loss_dice: 0.9094
05/26 14:33:27 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 14:33:27 - mmengine - INFO - Iter(train) [ 31000/160000]  base_lr: 8.2381e-05 lr: 8.2381e-06  eta: 14:41:15  time: 0.4068  data_time: 0.0088  memory: 5976  grad_norm: 624.3943  loss: 25.9011  decode.loss_cls: 0.4827  decode.loss_mask: 1.1374  decode.loss_dice: 1.0060  decode.d0.loss_cls: 0.8497  decode.d0.loss_mask: 1.1018  decode.d0.loss_dice: 0.9455  decode.d1.loss_cls: 0.4117  decode.d1.loss_mask: 1.1272  decode.d1.loss_dice: 0.9546  decode.d2.loss_cls: 0.3871  decode.d2.loss_mask: 1.1280  decode.d2.loss_dice: 1.0173  decode.d3.loss_cls: 0.4151  decode.d3.loss_mask: 1.1389  decode.d3.loss_dice: 1.0138  decode.d4.loss_cls: 0.4505  decode.d4.loss_mask: 1.1176  decode.d4.loss_dice: 0.9918  decode.d5.loss_cls: 0.4767  decode.d5.loss_mask: 1.1128  decode.d5.loss_dice: 0.9617  decode.d6.loss_cls: 0.4948  decode.d6.loss_mask: 1.1087  decode.d6.loss_dice: 0.9720  decode.d7.loss_cls: 0.4609  decode.d7.loss_mask: 1.1077  decode.d7.loss_dice: 0.9845  decode.d8.loss_cls: 0.4079  decode.d8.loss_mask: 1.1447  decode.d8.loss_dice: 0.9919
05/26 14:33:48 - mmengine - INFO - Iter(train) [ 31050/160000]  base_lr: 8.2352e-05 lr: 8.2352e-06  eta: 14:40:54  time: 0.4042  data_time: 0.0087  memory: 5984  grad_norm: 929.0613  loss: 27.1629  decode.loss_cls: 0.2126  decode.loss_mask: 1.4119  decode.loss_dice: 0.9923  decode.d0.loss_cls: 0.7488  decode.d0.loss_mask: 1.3609  decode.d0.loss_dice: 0.9558  decode.d1.loss_cls: 0.2601  decode.d1.loss_mask: 1.3247  decode.d1.loss_dice: 0.9696  decode.d2.loss_cls: 0.2286  decode.d2.loss_mask: 1.3659  decode.d2.loss_dice: 0.9420  decode.d3.loss_cls: 0.2470  decode.d3.loss_mask: 1.4041  decode.d3.loss_dice: 0.9739  decode.d4.loss_cls: 0.3022  decode.d4.loss_mask: 1.4210  decode.d4.loss_dice: 0.9857  decode.d5.loss_cls: 0.2787  decode.d5.loss_mask: 1.4540  decode.d5.loss_dice: 1.0806  decode.d6.loss_cls: 0.2562  decode.d6.loss_mask: 1.4461  decode.d6.loss_dice: 1.0718  decode.d7.loss_cls: 0.2784  decode.d7.loss_mask: 1.4686  decode.d7.loss_dice: 1.0297  decode.d8.loss_cls: 0.1983  decode.d8.loss_mask: 1.4596  decode.d8.loss_dice: 1.0339
05/26 14:34:08 - mmengine - INFO - Iter(train) [ 31100/160000]  base_lr: 8.2323e-05 lr: 8.2323e-06  eta: 14:40:32  time: 0.4052  data_time: 0.0087  memory: 5980  grad_norm: 618.9876  loss: 24.3579  decode.loss_cls: 0.3014  decode.loss_mask: 1.1205  decode.loss_dice: 0.8907  decode.d0.loss_cls: 0.8156  decode.d0.loss_mask: 1.1287  decode.d0.loss_dice: 0.9422  decode.d1.loss_cls: 0.3767  decode.d1.loss_mask: 1.0975  decode.d1.loss_dice: 0.8720  decode.d2.loss_cls: 0.3248  decode.d2.loss_mask: 1.1434  decode.d2.loss_dice: 0.9195  decode.d3.loss_cls: 0.3158  decode.d3.loss_mask: 1.1337  decode.d3.loss_dice: 0.9164  decode.d4.loss_cls: 0.3620  decode.d4.loss_mask: 1.1254  decode.d4.loss_dice: 0.9340  decode.d5.loss_cls: 0.3075  decode.d5.loss_mask: 1.0945  decode.d5.loss_dice: 0.9162  decode.d6.loss_cls: 0.3275  decode.d6.loss_mask: 1.1215  decode.d6.loss_dice: 0.9351  decode.d7.loss_cls: 0.3567  decode.d7.loss_mask: 1.1996  decode.d7.loss_dice: 0.9424  decode.d8.loss_cls: 0.3460  decode.d8.loss_mask: 1.1716  decode.d8.loss_dice: 0.9187
05/26 14:34:28 - mmengine - INFO - Iter(train) [ 31150/160000]  base_lr: 8.2294e-05 lr: 8.2294e-06  eta: 14:40:11  time: 0.4058  data_time: 0.0088  memory: 5972  grad_norm: 590.4263  loss: 28.2012  decode.loss_cls: 0.3660  decode.loss_mask: 1.4318  decode.loss_dice: 1.0841  decode.d0.loss_cls: 0.7769  decode.d0.loss_mask: 1.3239  decode.d0.loss_dice: 0.9814  decode.d1.loss_cls: 0.3545  decode.d1.loss_mask: 1.3961  decode.d1.loss_dice: 1.0014  decode.d2.loss_cls: 0.3586  decode.d2.loss_mask: 1.3730  decode.d2.loss_dice: 1.0064  decode.d3.loss_cls: 0.4103  decode.d3.loss_mask: 1.3177  decode.d3.loss_dice: 0.9849  decode.d4.loss_cls: 0.3699  decode.d4.loss_mask: 1.3579  decode.d4.loss_dice: 1.0377  decode.d5.loss_cls: 0.3928  decode.d5.loss_mask: 1.3563  decode.d5.loss_dice: 1.0595  decode.d6.loss_cls: 0.4619  decode.d6.loss_mask: 1.3204  decode.d6.loss_dice: 0.9973  decode.d7.loss_cls: 0.4793  decode.d7.loss_mask: 1.3601  decode.d7.loss_dice: 1.0575  decode.d8.loss_cls: 0.3986  decode.d8.loss_mask: 1.3623  decode.d8.loss_dice: 1.0227
05/26 14:34:48 - mmengine - INFO - Iter(train) [ 31200/160000]  base_lr: 8.2266e-05 lr: 8.2266e-06  eta: 14:39:49  time: 0.4053  data_time: 0.0088  memory: 5971  grad_norm: 535.7878  loss: 23.2380  decode.loss_cls: 0.2816  decode.loss_mask: 1.1054  decode.loss_dice: 0.9207  decode.d0.loss_cls: 0.7107  decode.d0.loss_mask: 1.0535  decode.d0.loss_dice: 0.9545  decode.d1.loss_cls: 0.2627  decode.d1.loss_mask: 1.0607  decode.d1.loss_dice: 0.9222  decode.d2.loss_cls: 0.2543  decode.d2.loss_mask: 1.0770  decode.d2.loss_dice: 0.9198  decode.d3.loss_cls: 0.2630  decode.d3.loss_mask: 1.0374  decode.d3.loss_dice: 0.8805  decode.d4.loss_cls: 0.3074  decode.d4.loss_mask: 1.0783  decode.d4.loss_dice: 0.9518  decode.d5.loss_cls: 0.3141  decode.d5.loss_mask: 1.0456  decode.d5.loss_dice: 0.9219  decode.d6.loss_cls: 0.3487  decode.d6.loss_mask: 1.0546  decode.d6.loss_dice: 0.9221  decode.d7.loss_cls: 0.3154  decode.d7.loss_mask: 1.0728  decode.d7.loss_dice: 0.9119  decode.d8.loss_cls: 0.2988  decode.d8.loss_mask: 1.0681  decode.d8.loss_dice: 0.9224
05/26 14:35:09 - mmengine - INFO - Iter(train) [ 31250/160000]  base_lr: 8.2237e-05 lr: 8.2237e-06  eta: 14:39:28  time: 0.4054  data_time: 0.0086  memory: 5976  grad_norm: 595.5279  loss: 27.9388  decode.loss_cls: 0.3259  decode.loss_mask: 1.3967  decode.loss_dice: 1.0293  decode.d0.loss_cls: 0.8723  decode.d0.loss_mask: 1.2944  decode.d0.loss_dice: 1.0186  decode.d1.loss_cls: 0.2998  decode.d1.loss_mask: 1.3850  decode.d1.loss_dice: 1.0095  decode.d2.loss_cls: 0.3583  decode.d2.loss_mask: 1.3793  decode.d2.loss_dice: 1.0071  decode.d3.loss_cls: 0.3371  decode.d3.loss_mask: 1.4203  decode.d3.loss_dice: 1.0078  decode.d4.loss_cls: 0.3315  decode.d4.loss_mask: 1.3572  decode.d4.loss_dice: 1.0222  decode.d5.loss_cls: 0.3200  decode.d5.loss_mask: 1.3797  decode.d5.loss_dice: 1.0417  decode.d6.loss_cls: 0.4220  decode.d6.loss_mask: 1.3950  decode.d6.loss_dice: 1.0179  decode.d7.loss_cls: 0.3312  decode.d7.loss_mask: 1.3888  decode.d7.loss_dice: 1.0372  decode.d8.loss_cls: 0.3438  decode.d8.loss_mask: 1.3809  decode.d8.loss_dice: 1.0282
05/26 14:35:29 - mmengine - INFO - Iter(train) [ 31300/160000]  base_lr: 8.2208e-05 lr: 8.2208e-06  eta: 14:39:06  time: 0.4053  data_time: 0.0087  memory: 5971  grad_norm: 653.9461  loss: 27.5472  decode.loss_cls: 0.3109  decode.loss_mask: 1.4299  decode.loss_dice: 0.8519  decode.d0.loss_cls: 0.7497  decode.d0.loss_mask: 1.3575  decode.d0.loss_dice: 0.8895  decode.d1.loss_cls: 0.3947  decode.d1.loss_mask: 1.4245  decode.d1.loss_dice: 0.9021  decode.d2.loss_cls: 0.4164  decode.d2.loss_mask: 1.4342  decode.d2.loss_dice: 0.9069  decode.d3.loss_cls: 0.3733  decode.d3.loss_mask: 1.4940  decode.d3.loss_dice: 0.8914  decode.d4.loss_cls: 0.3938  decode.d4.loss_mask: 1.4416  decode.d4.loss_dice: 0.8709  decode.d5.loss_cls: 0.3344  decode.d5.loss_mask: 1.4916  decode.d5.loss_dice: 0.9254  decode.d6.loss_cls: 0.4023  decode.d6.loss_mask: 1.5483  decode.d6.loss_dice: 0.9314  decode.d7.loss_cls: 0.3650  decode.d7.loss_mask: 1.4862  decode.d7.loss_dice: 0.8689  decode.d8.loss_cls: 0.4092  decode.d8.loss_mask: 1.3809  decode.d8.loss_dice: 0.8706
05/26 14:35:49 - mmengine - INFO - Iter(train) [ 31350/160000]  base_lr: 8.2179e-05 lr: 8.2179e-06  eta: 14:38:45  time: 0.4063  data_time: 0.0088  memory: 5970  grad_norm: 930.0333  loss: 24.4562  decode.loss_cls: 0.3221  decode.loss_mask: 1.2186  decode.loss_dice: 0.8481  decode.d0.loss_cls: 0.6867  decode.d0.loss_mask: 1.1870  decode.d0.loss_dice: 0.8332  decode.d1.loss_cls: 0.3381  decode.d1.loss_mask: 1.2210  decode.d1.loss_dice: 0.8452  decode.d2.loss_cls: 0.2938  decode.d2.loss_mask: 1.2385  decode.d2.loss_dice: 0.8696  decode.d3.loss_cls: 0.4303  decode.d3.loss_mask: 1.1901  decode.d3.loss_dice: 0.8672  decode.d4.loss_cls: 0.3809  decode.d4.loss_mask: 1.1649  decode.d4.loss_dice: 0.8511  decode.d5.loss_cls: 0.4223  decode.d5.loss_mask: 1.1803  decode.d5.loss_dice: 0.8416  decode.d6.loss_cls: 0.4066  decode.d6.loss_mask: 1.1837  decode.d6.loss_dice: 0.8464  decode.d7.loss_cls: 0.3022  decode.d7.loss_mask: 1.2119  decode.d7.loss_dice: 0.8654  decode.d8.loss_cls: 0.3435  decode.d8.loss_mask: 1.2152  decode.d8.loss_dice: 0.8507
05/26 14:36:10 - mmengine - INFO - Iter(train) [ 31400/160000]  base_lr: 8.2151e-05 lr: 8.2151e-06  eta: 14:38:24  time: 0.4073  data_time: 0.0100  memory: 5965  grad_norm: 743.3213  loss: 25.3377  decode.loss_cls: 0.1982  decode.loss_mask: 1.4304  decode.loss_dice: 0.8888  decode.d0.loss_cls: 0.7198  decode.d0.loss_mask: 1.3060  decode.d0.loss_dice: 0.7962  decode.d1.loss_cls: 0.3006  decode.d1.loss_mask: 1.3552  decode.d1.loss_dice: 0.7976  decode.d2.loss_cls: 0.3231  decode.d2.loss_mask: 1.3569  decode.d2.loss_dice: 0.8487  decode.d3.loss_cls: 0.2996  decode.d3.loss_mask: 1.3424  decode.d3.loss_dice: 0.8433  decode.d4.loss_cls: 0.3391  decode.d4.loss_mask: 1.3820  decode.d4.loss_dice: 0.8507  decode.d5.loss_cls: 0.3451  decode.d5.loss_mask: 1.3175  decode.d5.loss_dice: 0.8018  decode.d6.loss_cls: 0.3300  decode.d6.loss_mask: 1.3849  decode.d6.loss_dice: 0.8198  decode.d7.loss_cls: 0.3147  decode.d7.loss_mask: 1.3461  decode.d7.loss_dice: 0.8303  decode.d8.loss_cls: 0.2473  decode.d8.loss_mask: 1.3728  decode.d8.loss_dice: 0.8488
05/26 14:36:30 - mmengine - INFO - Iter(train) [ 31450/160000]  base_lr: 8.2122e-05 lr: 8.2122e-06  eta: 14:38:02  time: 0.4059  data_time: 0.0087  memory: 5967  grad_norm: 767.0501  loss: 28.3372  decode.loss_cls: 0.3679  decode.loss_mask: 1.3219  decode.loss_dice: 1.0252  decode.d0.loss_cls: 0.9100  decode.d0.loss_mask: 1.2827  decode.d0.loss_dice: 1.0045  decode.d1.loss_cls: 0.3940  decode.d1.loss_mask: 1.3488  decode.d1.loss_dice: 1.0719  decode.d2.loss_cls: 0.3997  decode.d2.loss_mask: 1.3358  decode.d2.loss_dice: 1.0614  decode.d3.loss_cls: 0.3997  decode.d3.loss_mask: 1.2980  decode.d3.loss_dice: 1.0724  decode.d4.loss_cls: 0.4003  decode.d4.loss_mask: 1.2873  decode.d4.loss_dice: 1.0697  decode.d5.loss_cls: 0.4414  decode.d5.loss_mask: 1.3128  decode.d5.loss_dice: 1.0569  decode.d6.loss_cls: 0.4599  decode.d6.loss_mask: 1.3121  decode.d6.loss_dice: 1.0300  decode.d7.loss_cls: 0.4422  decode.d7.loss_mask: 1.3547  decode.d7.loss_dice: 1.0846  decode.d8.loss_cls: 0.4257  decode.d8.loss_mask: 1.3206  decode.d8.loss_dice: 1.0450
05/26 14:36:50 - mmengine - INFO - Iter(train) [ 31500/160000]  base_lr: 8.2093e-05 lr: 8.2093e-06  eta: 14:37:41  time: 0.4057  data_time: 0.0087  memory: 5980  grad_norm: 897.6544  loss: 25.8620  decode.loss_cls: 0.3147  decode.loss_mask: 1.2174  decode.loss_dice: 0.9949  decode.d0.loss_cls: 0.8663  decode.d0.loss_mask: 1.0805  decode.d0.loss_dice: 0.9614  decode.d1.loss_cls: 0.4342  decode.d1.loss_mask: 1.1429  decode.d1.loss_dice: 1.0002  decode.d2.loss_cls: 0.3892  decode.d2.loss_mask: 1.1878  decode.d2.loss_dice: 1.0150  decode.d3.loss_cls: 0.3537  decode.d3.loss_mask: 1.2257  decode.d3.loss_dice: 0.9846  decode.d4.loss_cls: 0.4085  decode.d4.loss_mask: 1.1519  decode.d4.loss_dice: 0.9690  decode.d5.loss_cls: 0.4004  decode.d5.loss_mask: 1.2072  decode.d5.loss_dice: 0.9704  decode.d6.loss_cls: 0.3844  decode.d6.loss_mask: 1.1742  decode.d6.loss_dice: 0.9738  decode.d7.loss_cls: 0.3784  decode.d7.loss_mask: 1.1870  decode.d7.loss_dice: 0.9905  decode.d8.loss_cls: 0.3070  decode.d8.loss_mask: 1.1886  decode.d8.loss_dice: 1.0023
05/26 14:37:10 - mmengine - INFO - Iter(train) [ 31550/160000]  base_lr: 8.2064e-05 lr: 8.2064e-06  eta: 14:37:20  time: 0.4155  data_time: 0.0086  memory: 5970  grad_norm: 587.1551  loss: 30.1465  decode.loss_cls: 0.4073  decode.loss_mask: 1.5042  decode.loss_dice: 1.0464  decode.d0.loss_cls: 0.8239  decode.d0.loss_mask: 1.4446  decode.d0.loss_dice: 1.0346  decode.d1.loss_cls: 0.3693  decode.d1.loss_mask: 1.4855  decode.d1.loss_dice: 1.0555  decode.d2.loss_cls: 0.4098  decode.d2.loss_mask: 1.5264  decode.d2.loss_dice: 1.0910  decode.d3.loss_cls: 0.3451  decode.d3.loss_mask: 1.5426  decode.d3.loss_dice: 1.0889  decode.d4.loss_cls: 0.4122  decode.d4.loss_mask: 1.5132  decode.d4.loss_dice: 1.0743  decode.d5.loss_cls: 0.4157  decode.d5.loss_mask: 1.5029  decode.d5.loss_dice: 1.0581  decode.d6.loss_cls: 0.3503  decode.d6.loss_mask: 1.5288  decode.d6.loss_dice: 1.1019  decode.d7.loss_cls: 0.3683  decode.d7.loss_mask: 1.5617  decode.d7.loss_dice: 1.0869  decode.d8.loss_cls: 0.4013  decode.d8.loss_mask: 1.5474  decode.d8.loss_dice: 1.0489
05/26 14:37:31 - mmengine - INFO - Iter(train) [ 31600/160000]  base_lr: 8.2036e-05 lr: 8.2036e-06  eta: 14:36:58  time: 0.4053  data_time: 0.0087  memory: 5971  grad_norm: 856.9309  loss: 30.1899  decode.loss_cls: 0.5535  decode.loss_mask: 1.3545  decode.loss_dice: 0.9836  decode.d0.loss_cls: 0.9996  decode.d0.loss_mask: 1.3350  decode.d0.loss_dice: 0.9903  decode.d1.loss_cls: 0.6665  decode.d1.loss_mask: 1.2829  decode.d1.loss_dice: 0.9755  decode.d2.loss_cls: 0.6228  decode.d2.loss_mask: 1.3750  decode.d2.loss_dice: 1.0083  decode.d3.loss_cls: 0.6080  decode.d3.loss_mask: 1.3626  decode.d3.loss_dice: 0.9748  decode.d4.loss_cls: 0.5535  decode.d4.loss_mask: 1.4262  decode.d4.loss_dice: 0.9999  decode.d5.loss_cls: 0.6523  decode.d5.loss_mask: 1.3221  decode.d5.loss_dice: 1.0569  decode.d6.loss_cls: 0.6069  decode.d6.loss_mask: 1.4739  decode.d6.loss_dice: 1.0781  decode.d7.loss_cls: 0.6203  decode.d7.loss_mask: 1.3634  decode.d7.loss_dice: 0.9917  decode.d8.loss_cls: 0.5676  decode.d8.loss_mask: 1.3622  decode.d8.loss_dice: 1.0219
05/26 14:37:51 - mmengine - INFO - Iter(train) [ 31650/160000]  base_lr: 8.2007e-05 lr: 8.2007e-06  eta: 14:36:37  time: 0.4050  data_time: 0.0086  memory: 5976  grad_norm: 716.0007  loss: 26.0862  decode.loss_cls: 0.3416  decode.loss_mask: 1.3068  decode.loss_dice: 0.9423  decode.d0.loss_cls: 0.7335  decode.d0.loss_mask: 1.1982  decode.d0.loss_dice: 0.9102  decode.d1.loss_cls: 0.3271  decode.d1.loss_mask: 1.2625  decode.d1.loss_dice: 0.9176  decode.d2.loss_cls: 0.3275  decode.d2.loss_mask: 1.2810  decode.d2.loss_dice: 0.9314  decode.d3.loss_cls: 0.3389  decode.d3.loss_mask: 1.2735  decode.d3.loss_dice: 0.9281  decode.d4.loss_cls: 0.3685  decode.d4.loss_mask: 1.2515  decode.d4.loss_dice: 0.9322  decode.d5.loss_cls: 0.4131  decode.d5.loss_mask: 1.2697  decode.d5.loss_dice: 0.9455  decode.d6.loss_cls: 0.3542  decode.d6.loss_mask: 1.3265  decode.d6.loss_dice: 0.9534  decode.d7.loss_cls: 0.4321  decode.d7.loss_mask: 1.3059  decode.d7.loss_dice: 0.9460  decode.d8.loss_cls: 0.3787  decode.d8.loss_mask: 1.2680  decode.d8.loss_dice: 0.9208
05/26 14:38:11 - mmengine - INFO - Iter(train) [ 31700/160000]  base_lr: 8.1978e-05 lr: 8.1978e-06  eta: 14:36:15  time: 0.4047  data_time: 0.0087  memory: 5971  grad_norm: 366.9716  loss: 23.0064  decode.loss_cls: 0.2742  decode.loss_mask: 1.0854  decode.loss_dice: 0.8457  decode.d0.loss_cls: 0.7729  decode.d0.loss_mask: 1.0821  decode.d0.loss_dice: 0.8310  decode.d1.loss_cls: 0.3027  decode.d1.loss_mask: 1.1387  decode.d1.loss_dice: 0.8023  decode.d2.loss_cls: 0.3163  decode.d2.loss_mask: 1.1043  decode.d2.loss_dice: 0.7957  decode.d3.loss_cls: 0.3383  decode.d3.loss_mask: 1.1042  decode.d3.loss_dice: 0.8145  decode.d4.loss_cls: 0.3044  decode.d4.loss_mask: 1.1092  decode.d4.loss_dice: 0.8571  decode.d5.loss_cls: 0.3362  decode.d5.loss_mask: 1.0802  decode.d5.loss_dice: 0.8225  decode.d6.loss_cls: 0.3887  decode.d6.loss_mask: 1.0975  decode.d6.loss_dice: 0.8614  decode.d7.loss_cls: 0.3131  decode.d7.loss_mask: 1.0943  decode.d7.loss_dice: 0.8461  decode.d8.loss_cls: 0.3141  decode.d8.loss_mask: 1.0961  decode.d8.loss_dice: 0.8773
05/26 14:38:31 - mmengine - INFO - Iter(train) [ 31750/160000]  base_lr: 8.1949e-05 lr: 8.1949e-06  eta: 14:35:54  time: 0.4063  data_time: 0.0088  memory: 5971  grad_norm: 1043.3474  loss: 28.2363  decode.loss_cls: 0.3755  decode.loss_mask: 1.4312  decode.loss_dice: 1.0129  decode.d0.loss_cls: 0.8601  decode.d0.loss_mask: 1.3146  decode.d0.loss_dice: 0.9458  decode.d1.loss_cls: 0.3923  decode.d1.loss_mask: 1.3746  decode.d1.loss_dice: 1.0083  decode.d2.loss_cls: 0.4509  decode.d2.loss_mask: 1.3218  decode.d2.loss_dice: 0.9870  decode.d3.loss_cls: 0.3612  decode.d3.loss_mask: 1.3726  decode.d3.loss_dice: 0.9879  decode.d4.loss_cls: 0.4043  decode.d4.loss_mask: 1.3995  decode.d4.loss_dice: 0.9923  decode.d5.loss_cls: 0.3986  decode.d5.loss_mask: 1.3715  decode.d5.loss_dice: 0.9978  decode.d6.loss_cls: 0.3683  decode.d6.loss_mask: 1.4938  decode.d6.loss_dice: 1.0109  decode.d7.loss_cls: 0.4044  decode.d7.loss_mask: 1.4401  decode.d7.loss_dice: 0.9915  decode.d8.loss_cls: 0.3370  decode.d8.loss_mask: 1.4401  decode.d8.loss_dice: 0.9894
05/26 14:38:52 - mmengine - INFO - Iter(train) [ 31800/160000]  base_lr: 8.1921e-05 lr: 8.1921e-06  eta: 14:35:33  time: 0.4057  data_time: 0.0088  memory: 5972  grad_norm: 1118.1696  loss: 29.0850  decode.loss_cls: 0.3117  decode.loss_mask: 1.5248  decode.loss_dice: 0.9527  decode.d0.loss_cls: 0.7967  decode.d0.loss_mask: 1.4195  decode.d0.loss_dice: 0.9452  decode.d1.loss_cls: 0.3874  decode.d1.loss_mask: 1.5150  decode.d1.loss_dice: 0.9305  decode.d2.loss_cls: 0.3106  decode.d2.loss_mask: 1.5625  decode.d2.loss_dice: 0.9829  decode.d3.loss_cls: 0.3928  decode.d3.loss_mask: 1.4708  decode.d3.loss_dice: 1.0001  decode.d4.loss_cls: 0.3191  decode.d4.loss_mask: 1.6089  decode.d4.loss_dice: 1.0530  decode.d5.loss_cls: 0.3082  decode.d5.loss_mask: 1.6108  decode.d5.loss_dice: 1.0177  decode.d6.loss_cls: 0.3768  decode.d6.loss_mask: 1.5243  decode.d6.loss_dice: 0.9928  decode.d7.loss_cls: 0.3033  decode.d7.loss_mask: 1.5885  decode.d7.loss_dice: 0.9987  decode.d8.loss_cls: 0.3375  decode.d8.loss_mask: 1.5383  decode.d8.loss_dice: 1.0043
05/26 14:39:12 - mmengine - INFO - Iter(train) [ 31850/160000]  base_lr: 8.1892e-05 lr: 8.1892e-06  eta: 14:35:11  time: 0.4046  data_time: 0.0087  memory: 5969  grad_norm: 932.4351  loss: 27.8335  decode.loss_cls: 0.2354  decode.loss_mask: 1.5703  decode.loss_dice: 1.0203  decode.d0.loss_cls: 0.7898  decode.d0.loss_mask: 1.3740  decode.d0.loss_dice: 0.9016  decode.d1.loss_cls: 0.3371  decode.d1.loss_mask: 1.4178  decode.d1.loss_dice: 0.9609  decode.d2.loss_cls: 0.3164  decode.d2.loss_mask: 1.4394  decode.d2.loss_dice: 0.9441  decode.d3.loss_cls: 0.3261  decode.d3.loss_mask: 1.4706  decode.d3.loss_dice: 0.9375  decode.d4.loss_cls: 0.3058  decode.d4.loss_mask: 1.4792  decode.d4.loss_dice: 0.9747  decode.d5.loss_cls: 0.3070  decode.d5.loss_mask: 1.4964  decode.d5.loss_dice: 0.9646  decode.d6.loss_cls: 0.3186  decode.d6.loss_mask: 1.5126  decode.d6.loss_dice: 0.9450  decode.d7.loss_cls: 0.3028  decode.d7.loss_mask: 1.4730  decode.d7.loss_dice: 0.9916  decode.d8.loss_cls: 0.2617  decode.d8.loss_mask: 1.4675  decode.d8.loss_dice: 0.9916
05/26 14:39:33 - mmengine - INFO - Iter(train) [ 31900/160000]  base_lr: 8.1863e-05 lr: 8.1863e-06  eta: 14:34:51  time: 0.4104  data_time: 0.0089  memory: 5976  grad_norm: 969.7664  loss: 25.8790  decode.loss_cls: 0.3351  decode.loss_mask: 1.2868  decode.loss_dice: 0.8524  decode.d0.loss_cls: 0.8274  decode.d0.loss_mask: 1.2673  decode.d0.loss_dice: 0.8785  decode.d1.loss_cls: 0.3343  decode.d1.loss_mask: 1.3320  decode.d1.loss_dice: 0.8601  decode.d2.loss_cls: 0.3174  decode.d2.loss_mask: 1.3485  decode.d2.loss_dice: 0.8945  decode.d3.loss_cls: 0.3459  decode.d3.loss_mask: 1.2966  decode.d3.loss_dice: 0.8400  decode.d4.loss_cls: 0.3849  decode.d4.loss_mask: 1.3209  decode.d4.loss_dice: 0.8506  decode.d5.loss_cls: 0.3733  decode.d5.loss_mask: 1.3186  decode.d5.loss_dice: 0.9151  decode.d6.loss_cls: 0.3928  decode.d6.loss_mask: 1.3376  decode.d6.loss_dice: 0.9299  decode.d7.loss_cls: 0.3928  decode.d7.loss_mask: 1.2552  decode.d7.loss_dice: 0.8613  decode.d8.loss_cls: 0.3656  decode.d8.loss_mask: 1.2777  decode.d8.loss_dice: 0.8858
05/26 14:39:53 - mmengine - INFO - Iter(train) [ 31950/160000]  base_lr: 8.1834e-05 lr: 8.1834e-06  eta: 14:34:30  time: 0.4051  data_time: 0.0087  memory: 5969  grad_norm: 971.5289  loss: 28.3867  decode.loss_cls: 0.2923  decode.loss_mask: 1.4402  decode.loss_dice: 1.0110  decode.d0.loss_cls: 0.7028  decode.d0.loss_mask: 1.4187  decode.d0.loss_dice: 0.9625  decode.d1.loss_cls: 0.3367  decode.d1.loss_mask: 1.4318  decode.d1.loss_dice: 0.9922  decode.d2.loss_cls: 0.2645  decode.d2.loss_mask: 1.5146  decode.d2.loss_dice: 1.0232  decode.d3.loss_cls: 0.2852  decode.d3.loss_mask: 1.4971  decode.d3.loss_dice: 1.0734  decode.d4.loss_cls: 0.3665  decode.d4.loss_mask: 1.4794  decode.d4.loss_dice: 1.0360  decode.d5.loss_cls: 0.3386  decode.d5.loss_mask: 1.4852  decode.d5.loss_dice: 1.0133  decode.d6.loss_cls: 0.3574  decode.d6.loss_mask: 1.4676  decode.d6.loss_dice: 1.0081  decode.d7.loss_cls: 0.2817  decode.d7.loss_mask: 1.5176  decode.d7.loss_dice: 1.0226  decode.d8.loss_cls: 0.2706  decode.d8.loss_mask: 1.4639  decode.d8.loss_dice: 1.0319
05/26 14:40:13 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 14:40:13 - mmengine - INFO - Iter(train) [ 32000/160000]  base_lr: 8.1806e-05 lr: 8.1806e-06  eta: 14:34:08  time: 0.4042  data_time: 0.0087  memory: 5971  grad_norm: 734.5275  loss: 25.7793  decode.loss_cls: 0.3633  decode.loss_mask: 1.2463  decode.loss_dice: 0.9023  decode.d0.loss_cls: 0.7744  decode.d0.loss_mask: 1.2158  decode.d0.loss_dice: 0.8901  decode.d1.loss_cls: 0.3750  decode.d1.loss_mask: 1.2500  decode.d1.loss_dice: 0.9110  decode.d2.loss_cls: 0.3735  decode.d2.loss_mask: 1.2329  decode.d2.loss_dice: 0.9179  decode.d3.loss_cls: 0.3847  decode.d3.loss_mask: 1.2589  decode.d3.loss_dice: 0.8952  decode.d4.loss_cls: 0.3699  decode.d4.loss_mask: 1.2176  decode.d4.loss_dice: 0.9108  decode.d5.loss_cls: 0.3859  decode.d5.loss_mask: 1.2655  decode.d5.loss_dice: 0.9484  decode.d6.loss_cls: 0.4083  decode.d6.loss_mask: 1.2474  decode.d6.loss_dice: 0.8948  decode.d7.loss_cls: 0.4123  decode.d7.loss_mask: 1.2528  decode.d7.loss_dice: 0.9443  decode.d8.loss_cls: 0.3567  decode.d8.loss_mask: 1.2621  decode.d8.loss_dice: 0.9114
05/26 14:40:33 - mmengine - INFO - Iter(train) [ 32050/160000]  base_lr: 8.1777e-05 lr: 8.1777e-06  eta: 14:33:47  time: 0.4051  data_time: 0.0087  memory: 5984  grad_norm: 822.1128  loss: 23.4488  decode.loss_cls: 0.2218  decode.loss_mask: 1.2031  decode.loss_dice: 0.8297  decode.d0.loss_cls: 0.6300  decode.d0.loss_mask: 1.1898  decode.d0.loss_dice: 0.8440  decode.d1.loss_cls: 0.2484  decode.d1.loss_mask: 1.2298  decode.d1.loss_dice: 0.8467  decode.d2.loss_cls: 0.2647  decode.d2.loss_mask: 1.1919  decode.d2.loss_dice: 0.8498  decode.d3.loss_cls: 0.2686  decode.d3.loss_mask: 1.2318  decode.d3.loss_dice: 0.8482  decode.d4.loss_cls: 0.2803  decode.d4.loss_mask: 1.2146  decode.d4.loss_dice: 0.8605  decode.d5.loss_cls: 0.2374  decode.d5.loss_mask: 1.2169  decode.d5.loss_dice: 0.8355  decode.d6.loss_cls: 0.2466  decode.d6.loss_mask: 1.2118  decode.d6.loss_dice: 0.8407  decode.d7.loss_cls: 0.2322  decode.d7.loss_mask: 1.2602  decode.d7.loss_dice: 0.8567  decode.d8.loss_cls: 0.2347  decode.d8.loss_mask: 1.1987  decode.d8.loss_dice: 0.8236
05/26 14:40:54 - mmengine - INFO - Iter(train) [ 32100/160000]  base_lr: 8.1748e-05 lr: 8.1748e-06  eta: 14:33:26  time: 0.4040  data_time: 0.0087  memory: 5980  grad_norm: 718.5601  loss: 24.3263  decode.loss_cls: 0.3077  decode.loss_mask: 1.2306  decode.loss_dice: 0.9262  decode.d0.loss_cls: 0.7362  decode.d0.loss_mask: 1.1131  decode.d0.loss_dice: 0.8539  decode.d1.loss_cls: 0.3101  decode.d1.loss_mask: 1.1795  decode.d1.loss_dice: 0.9011  decode.d2.loss_cls: 0.2889  decode.d2.loss_mask: 1.1842  decode.d2.loss_dice: 0.8986  decode.d3.loss_cls: 0.3142  decode.d3.loss_mask: 1.1719  decode.d3.loss_dice: 0.8715  decode.d4.loss_cls: 0.2996  decode.d4.loss_mask: 1.1498  decode.d4.loss_dice: 0.9074  decode.d5.loss_cls: 0.3394  decode.d5.loss_mask: 1.1666  decode.d5.loss_dice: 0.9061  decode.d6.loss_cls: 0.3022  decode.d6.loss_mask: 1.2254  decode.d6.loss_dice: 0.9347  decode.d7.loss_cls: 0.3792  decode.d7.loss_mask: 1.1386  decode.d7.loss_dice: 0.8768  decode.d8.loss_cls: 0.3310  decode.d8.loss_mask: 1.1706  decode.d8.loss_dice: 0.9114
05/26 14:41:14 - mmengine - INFO - Iter(train) [ 32150/160000]  base_lr: 8.1719e-05 lr: 8.1719e-06  eta: 14:33:05  time: 0.4149  data_time: 0.0091  memory: 5969  grad_norm: 727.3355  loss: 22.5884  decode.loss_cls: 0.2535  decode.loss_mask: 1.0855  decode.loss_dice: 0.8438  decode.d0.loss_cls: 0.7235  decode.d0.loss_mask: 1.0507  decode.d0.loss_dice: 0.8260  decode.d1.loss_cls: 0.2904  decode.d1.loss_mask: 1.1070  decode.d1.loss_dice: 0.8335  decode.d2.loss_cls: 0.2902  decode.d2.loss_mask: 1.0768  decode.d2.loss_dice: 0.8235  decode.d3.loss_cls: 0.2862  decode.d3.loss_mask: 1.0978  decode.d3.loss_dice: 0.8366  decode.d4.loss_cls: 0.2678  decode.d4.loss_mask: 1.1414  decode.d4.loss_dice: 0.8540  decode.d5.loss_cls: 0.2923  decode.d5.loss_mask: 1.0966  decode.d5.loss_dice: 0.8496  decode.d6.loss_cls: 0.3176  decode.d6.loss_mask: 1.0914  decode.d6.loss_dice: 0.8332  decode.d7.loss_cls: 0.2836  decode.d7.loss_mask: 1.0925  decode.d7.loss_dice: 0.8648  decode.d8.loss_cls: 0.2690  decode.d8.loss_mask: 1.0821  decode.d8.loss_dice: 0.8274
05/26 14:41:35 - mmengine - INFO - Iter(train) [ 32200/160000]  base_lr: 8.1691e-05 lr: 8.1691e-06  eta: 14:32:45  time: 0.4138  data_time: 0.0090  memory: 5966  grad_norm: 584.0830  loss: 23.9703  decode.loss_cls: 0.2593  decode.loss_mask: 1.2662  decode.loss_dice: 0.7809  decode.d0.loss_cls: 0.7792  decode.d0.loss_mask: 1.2203  decode.d0.loss_dice: 0.7785  decode.d1.loss_cls: 0.3309  decode.d1.loss_mask: 1.2072  decode.d1.loss_dice: 0.7813  decode.d2.loss_cls: 0.3355  decode.d2.loss_mask: 1.2136  decode.d2.loss_dice: 0.7662  decode.d3.loss_cls: 0.2935  decode.d3.loss_mask: 1.2474  decode.d3.loss_dice: 0.7714  decode.d4.loss_cls: 0.3737  decode.d4.loss_mask: 1.1960  decode.d4.loss_dice: 0.7948  decode.d5.loss_cls: 0.3580  decode.d5.loss_mask: 1.2212  decode.d5.loss_dice: 0.7985  decode.d6.loss_cls: 0.3854  decode.d6.loss_mask: 1.2241  decode.d6.loss_dice: 0.8107  decode.d7.loss_cls: 0.3861  decode.d7.loss_mask: 1.2205  decode.d7.loss_dice: 0.8013  decode.d8.loss_cls: 0.2962  decode.d8.loss_mask: 1.2785  decode.d8.loss_dice: 0.7940
05/26 14:41:56 - mmengine - INFO - Iter(train) [ 32250/160000]  base_lr: 8.1662e-05 lr: 8.1662e-06  eta: 14:32:28  time: 0.4200  data_time: 0.0093  memory: 5966  grad_norm: 632.2946  loss: 26.6090  decode.loss_cls: 0.2736  decode.loss_mask: 1.2791  decode.loss_dice: 1.0246  decode.d0.loss_cls: 0.7610  decode.d0.loss_mask: 1.2375  decode.d0.loss_dice: 1.0419  decode.d1.loss_cls: 0.2819  decode.d1.loss_mask: 1.2881  decode.d1.loss_dice: 1.0449  decode.d2.loss_cls: 0.2952  decode.d2.loss_mask: 1.3043  decode.d2.loss_dice: 1.0512  decode.d3.loss_cls: 0.2809  decode.d3.loss_mask: 1.2834  decode.d3.loss_dice: 1.0173  decode.d4.loss_cls: 0.3098  decode.d4.loss_mask: 1.2309  decode.d4.loss_dice: 1.0425  decode.d5.loss_cls: 0.2808  decode.d5.loss_mask: 1.3170  decode.d5.loss_dice: 1.0630  decode.d6.loss_cls: 0.3475  decode.d6.loss_mask: 1.2709  decode.d6.loss_dice: 1.0452  decode.d7.loss_cls: 0.3187  decode.d7.loss_mask: 1.2775  decode.d7.loss_dice: 1.0534  decode.d8.loss_cls: 0.3007  decode.d8.loss_mask: 1.2514  decode.d8.loss_dice: 1.0349
05/26 14:42:17 - mmengine - INFO - Iter(train) [ 32300/160000]  base_lr: 8.1633e-05 lr: 8.1633e-06  eta: 14:32:08  time: 0.4138  data_time: 0.0091  memory: 5975  grad_norm: 799.3623  loss: 25.5941  decode.loss_cls: 0.3736  decode.loss_mask: 1.2589  decode.loss_dice: 0.9080  decode.d0.loss_cls: 0.8646  decode.d0.loss_mask: 1.1337  decode.d0.loss_dice: 0.8773  decode.d1.loss_cls: 0.3611  decode.d1.loss_mask: 1.2055  decode.d1.loss_dice: 0.9556  decode.d2.loss_cls: 0.3995  decode.d2.loss_mask: 1.1630  decode.d2.loss_dice: 0.8986  decode.d3.loss_cls: 0.3780  decode.d3.loss_mask: 1.2214  decode.d3.loss_dice: 0.9118  decode.d4.loss_cls: 0.4359  decode.d4.loss_mask: 1.1978  decode.d4.loss_dice: 0.9074  decode.d5.loss_cls: 0.3953  decode.d5.loss_mask: 1.2175  decode.d5.loss_dice: 0.9155  decode.d6.loss_cls: 0.4637  decode.d6.loss_mask: 1.1813  decode.d6.loss_dice: 0.9047  decode.d7.loss_cls: 0.4367  decode.d7.loss_mask: 1.2147  decode.d7.loss_dice: 0.9235  decode.d8.loss_cls: 0.3972  decode.d8.loss_mask: 1.2096  decode.d8.loss_dice: 0.8826
05/26 14:42:38 - mmengine - INFO - Iter(train) [ 32350/160000]  base_lr: 8.1604e-05 lr: 8.1604e-06  eta: 14:31:49  time: 0.4147  data_time: 0.0092  memory: 5980  grad_norm: 543.8164  loss: 20.9731  decode.loss_cls: 0.2901  decode.loss_mask: 0.9932  decode.loss_dice: 0.7275  decode.d0.loss_cls: 0.7020  decode.d0.loss_mask: 1.0173  decode.d0.loss_dice: 0.7185  decode.d1.loss_cls: 0.2968  decode.d1.loss_mask: 1.0435  decode.d1.loss_dice: 0.7697  decode.d2.loss_cls: 0.2634  decode.d2.loss_mask: 1.0609  decode.d2.loss_dice: 0.7729  decode.d3.loss_cls: 0.2998  decode.d3.loss_mask: 1.0308  decode.d3.loss_dice: 0.7141  decode.d4.loss_cls: 0.2642  decode.d4.loss_mask: 1.0310  decode.d4.loss_dice: 0.7254  decode.d5.loss_cls: 0.2878  decode.d5.loss_mask: 1.0298  decode.d5.loss_dice: 0.7547  decode.d6.loss_cls: 0.3031  decode.d6.loss_mask: 1.0551  decode.d6.loss_dice: 0.7484  decode.d7.loss_cls: 0.3312  decode.d7.loss_mask: 1.0209  decode.d7.loss_dice: 0.7222  decode.d8.loss_cls: 0.2968  decode.d8.loss_mask: 0.9922  decode.d8.loss_dice: 0.7098
05/26 14:42:58 - mmengine - INFO - Iter(train) [ 32400/160000]  base_lr: 8.1576e-05 lr: 8.1576e-06  eta: 14:31:29  time: 0.4134  data_time: 0.0091  memory: 5967  grad_norm: 680.0689  loss: 22.6857  decode.loss_cls: 0.1903  decode.loss_mask: 1.1689  decode.loss_dice: 0.7860  decode.d0.loss_cls: 0.7240  decode.d0.loss_mask: 1.1709  decode.d0.loss_dice: 0.8028  decode.d1.loss_cls: 0.2267  decode.d1.loss_mask: 1.2280  decode.d1.loss_dice: 0.8245  decode.d2.loss_cls: 0.2653  decode.d2.loss_mask: 1.1790  decode.d2.loss_dice: 0.7808  decode.d3.loss_cls: 0.2318  decode.d3.loss_mask: 1.1976  decode.d3.loss_dice: 0.8288  decode.d4.loss_cls: 0.2521  decode.d4.loss_mask: 1.1670  decode.d4.loss_dice: 0.7868  decode.d5.loss_cls: 0.2866  decode.d5.loss_mask: 1.1522  decode.d5.loss_dice: 0.7933  decode.d6.loss_cls: 0.2530  decode.d6.loss_mask: 1.1653  decode.d6.loss_dice: 0.7778  decode.d7.loss_cls: 0.2396  decode.d7.loss_mask: 1.1895  decode.d7.loss_dice: 0.8338  decode.d8.loss_cls: 0.2333  decode.d8.loss_mask: 1.1707  decode.d8.loss_dice: 0.7790
05/26 14:43:19 - mmengine - INFO - Iter(train) [ 32450/160000]  base_lr: 8.1547e-05 lr: 8.1547e-06  eta: 14:31:09  time: 0.4128  data_time: 0.0091  memory: 5975  grad_norm: 538.7564  loss: 29.0128  decode.loss_cls: 0.4090  decode.loss_mask: 1.3915  decode.loss_dice: 0.9823  decode.d0.loss_cls: 0.8922  decode.d0.loss_mask: 1.3222  decode.d0.loss_dice: 0.9929  decode.d1.loss_cls: 0.4321  decode.d1.loss_mask: 1.4019  decode.d1.loss_dice: 1.0017  decode.d2.loss_cls: 0.4576  decode.d2.loss_mask: 1.4281  decode.d2.loss_dice: 0.9971  decode.d3.loss_cls: 0.4475  decode.d3.loss_mask: 1.3940  decode.d3.loss_dice: 0.9883  decode.d4.loss_cls: 0.4699  decode.d4.loss_mask: 1.3481  decode.d4.loss_dice: 1.0016  decode.d5.loss_cls: 0.4657  decode.d5.loss_mask: 1.4175  decode.d5.loss_dice: 1.0568  decode.d6.loss_cls: 0.4444  decode.d6.loss_mask: 1.4659  decode.d6.loss_dice: 1.0912  decode.d7.loss_cls: 0.4225  decode.d7.loss_mask: 1.4233  decode.d7.loss_dice: 1.0532  decode.d8.loss_cls: 0.4378  decode.d8.loss_mask: 1.3958  decode.d8.loss_dice: 0.9810
05/26 14:43:40 - mmengine - INFO - Iter(train) [ 32500/160000]  base_lr: 8.1518e-05 lr: 8.1518e-06  eta: 14:30:49  time: 0.4121  data_time: 0.0091  memory: 5968  grad_norm: 697.4109  loss: 25.1342  decode.loss_cls: 0.3271  decode.loss_mask: 1.2697  decode.loss_dice: 0.8636  decode.d0.loss_cls: 0.9300  decode.d0.loss_mask: 1.1611  decode.d0.loss_dice: 0.8732  decode.d1.loss_cls: 0.3449  decode.d1.loss_mask: 1.2540  decode.d1.loss_dice: 0.8517  decode.d2.loss_cls: 0.3473  decode.d2.loss_mask: 1.2441  decode.d2.loss_dice: 0.8495  decode.d3.loss_cls: 0.3336  decode.d3.loss_mask: 1.2537  decode.d3.loss_dice: 0.8570  decode.d4.loss_cls: 0.3637  decode.d4.loss_mask: 1.2505  decode.d4.loss_dice: 0.8550  decode.d5.loss_cls: 0.3572  decode.d5.loss_mask: 1.3059  decode.d5.loss_dice: 0.8671  decode.d6.loss_cls: 0.3417  decode.d6.loss_mask: 1.2198  decode.d6.loss_dice: 0.8589  decode.d7.loss_cls: 0.3573  decode.d7.loss_mask: 1.2746  decode.d7.loss_dice: 0.8666  decode.d8.loss_cls: 0.3562  decode.d8.loss_mask: 1.2401  decode.d8.loss_dice: 0.8591
05/26 14:44:00 - mmengine - INFO - Iter(train) [ 32550/160000]  base_lr: 8.1489e-05 lr: 8.1489e-06  eta: 14:30:29  time: 0.4128  data_time: 0.0091  memory: 5987  grad_norm: 704.1875  loss: 23.8268  decode.loss_cls: 0.3127  decode.loss_mask: 1.1049  decode.loss_dice: 0.9043  decode.d0.loss_cls: 0.7706  decode.d0.loss_mask: 1.1198  decode.d0.loss_dice: 0.9616  decode.d1.loss_cls: 0.3257  decode.d1.loss_mask: 1.0457  decode.d1.loss_dice: 0.9419  decode.d2.loss_cls: 0.3165  decode.d2.loss_mask: 1.0459  decode.d2.loss_dice: 0.9093  decode.d3.loss_cls: 0.3327  decode.d3.loss_mask: 1.0669  decode.d3.loss_dice: 0.8973  decode.d4.loss_cls: 0.3507  decode.d4.loss_mask: 1.0729  decode.d4.loss_dice: 0.9163  decode.d5.loss_cls: 0.3480  decode.d5.loss_mask: 1.1520  decode.d5.loss_dice: 0.9326  decode.d6.loss_cls: 0.3575  decode.d6.loss_mask: 1.0468  decode.d6.loss_dice: 0.9001  decode.d7.loss_cls: 0.3501  decode.d7.loss_mask: 1.0575  decode.d7.loss_dice: 0.9060  decode.d8.loss_cls: 0.3423  decode.d8.loss_mask: 1.1200  decode.d8.loss_dice: 0.9183
05/26 14:44:21 - mmengine - INFO - Iter(train) [ 32600/160000]  base_lr: 8.1460e-05 lr: 8.1460e-06  eta: 14:30:10  time: 0.4148  data_time: 0.0090  memory: 5980  grad_norm: 706.9960  loss: 30.1569  decode.loss_cls: 0.3624  decode.loss_mask: 1.4584  decode.loss_dice: 1.1399  decode.d0.loss_cls: 0.9171  decode.d0.loss_mask: 1.4099  decode.d0.loss_dice: 1.0606  decode.d1.loss_cls: 0.3601  decode.d1.loss_mask: 1.4619  decode.d1.loss_dice: 1.1290  decode.d2.loss_cls: 0.4066  decode.d2.loss_mask: 1.4509  decode.d2.loss_dice: 1.0948  decode.d3.loss_cls: 0.3917  decode.d3.loss_mask: 1.4418  decode.d3.loss_dice: 1.1019  decode.d4.loss_cls: 0.3885  decode.d4.loss_mask: 1.4572  decode.d4.loss_dice: 1.0740  decode.d5.loss_cls: 0.3715  decode.d5.loss_mask: 1.4804  decode.d5.loss_dice: 1.1547  decode.d6.loss_cls: 0.4251  decode.d6.loss_mask: 1.4545  decode.d6.loss_dice: 1.1154  decode.d7.loss_cls: 0.4270  decode.d7.loss_mask: 1.4851  decode.d7.loss_dice: 1.1333  decode.d8.loss_cls: 0.3948  decode.d8.loss_mask: 1.4741  decode.d8.loss_dice: 1.1346
05/26 14:44:42 - mmengine - INFO - Iter(train) [ 32650/160000]  base_lr: 8.1432e-05 lr: 8.1432e-06  eta: 14:29:50  time: 0.4047  data_time: 0.0087  memory: 5967  grad_norm: 808.3051  loss: 25.6392  decode.loss_cls: 0.3116  decode.loss_mask: 1.1892  decode.loss_dice: 0.9730  decode.d0.loss_cls: 0.7366  decode.d0.loss_mask: 1.2073  decode.d0.loss_dice: 1.0130  decode.d1.loss_cls: 0.3232  decode.d1.loss_mask: 1.1782  decode.d1.loss_dice: 0.9441  decode.d2.loss_cls: 0.3500  decode.d2.loss_mask: 1.1904  decode.d2.loss_dice: 0.9866  decode.d3.loss_cls: 0.3129  decode.d3.loss_mask: 1.1842  decode.d3.loss_dice: 1.0052  decode.d4.loss_cls: 0.2855  decode.d4.loss_mask: 1.2179  decode.d4.loss_dice: 1.0096  decode.d5.loss_cls: 0.3012  decode.d5.loss_mask: 1.2619  decode.d5.loss_dice: 1.0297  decode.d6.loss_cls: 0.3621  decode.d6.loss_mask: 1.2035  decode.d6.loss_dice: 0.9980  decode.d7.loss_cls: 0.3411  decode.d7.loss_mask: 1.2304  decode.d7.loss_dice: 1.0081  decode.d8.loss_cls: 0.2750  decode.d8.loss_mask: 1.2178  decode.d8.loss_dice: 0.9918
05/26 14:45:02 - mmengine - INFO - Iter(train) [ 32700/160000]  base_lr: 8.1403e-05 lr: 8.1403e-06  eta: 14:29:29  time: 0.4047  data_time: 0.0087  memory: 5972  grad_norm: 638.8998  loss: 24.2491  decode.loss_cls: 0.2614  decode.loss_mask: 1.2524  decode.loss_dice: 0.8178  decode.d0.loss_cls: 0.7012  decode.d0.loss_mask: 1.1755  decode.d0.loss_dice: 0.7716  decode.d1.loss_cls: 0.3229  decode.d1.loss_mask: 1.2618  decode.d1.loss_dice: 0.8589  decode.d2.loss_cls: 0.2946  decode.d2.loss_mask: 1.2578  decode.d2.loss_dice: 0.8339  decode.d3.loss_cls: 0.2762  decode.d3.loss_mask: 1.2615  decode.d3.loss_dice: 0.8328  decode.d4.loss_cls: 0.3073  decode.d4.loss_mask: 1.2293  decode.d4.loss_dice: 0.8256  decode.d5.loss_cls: 0.3405  decode.d5.loss_mask: 1.2363  decode.d5.loss_dice: 0.8618  decode.d6.loss_cls: 0.3465  decode.d6.loss_mask: 1.2582  decode.d6.loss_dice: 0.8578  decode.d7.loss_cls: 0.3640  decode.d7.loss_mask: 1.2303  decode.d7.loss_dice: 0.8262  decode.d8.loss_cls: 0.2890  decode.d8.loss_mask: 1.2657  decode.d8.loss_dice: 0.8302
05/26 14:45:23 - mmengine - INFO - Iter(train) [ 32750/160000]  base_lr: 8.1374e-05 lr: 8.1374e-06  eta: 14:29:09  time: 0.4142  data_time: 0.0089  memory: 5970  grad_norm: 577.9346  loss: 20.5832  decode.loss_cls: 0.2353  decode.loss_mask: 1.0316  decode.loss_dice: 0.7168  decode.d0.loss_cls: 0.6811  decode.d0.loss_mask: 1.0115  decode.d0.loss_dice: 0.7126  decode.d1.loss_cls: 0.1957  decode.d1.loss_mask: 1.0752  decode.d1.loss_dice: 0.7577  decode.d2.loss_cls: 0.2628  decode.d2.loss_mask: 1.0505  decode.d2.loss_dice: 0.7259  decode.d3.loss_cls: 0.2545  decode.d3.loss_mask: 1.0656  decode.d3.loss_dice: 0.7269  decode.d4.loss_cls: 0.2167  decode.d4.loss_mask: 1.0445  decode.d4.loss_dice: 0.7362  decode.d5.loss_cls: 0.2228  decode.d5.loss_mask: 1.0420  decode.d5.loss_dice: 0.7472  decode.d6.loss_cls: 0.2718  decode.d6.loss_mask: 1.0310  decode.d6.loss_dice: 0.7366  decode.d7.loss_cls: 0.2488  decode.d7.loss_mask: 1.0414  decode.d7.loss_dice: 0.7066  decode.d8.loss_cls: 0.2391  decode.d8.loss_mask: 1.0571  decode.d8.loss_dice: 0.7375
05/26 14:45:44 - mmengine - INFO - Iter(train) [ 32800/160000]  base_lr: 8.1345e-05 lr: 8.1345e-06  eta: 14:28:50  time: 0.4387  data_time: 0.0101  memory: 5966  grad_norm: 751.8968  loss: 21.7511  decode.loss_cls: 0.1939  decode.loss_mask: 1.0589  decode.loss_dice: 0.8501  decode.d0.loss_cls: 0.6374  decode.d0.loss_mask: 1.0867  decode.d0.loss_dice: 0.8368  decode.d1.loss_cls: 0.2280  decode.d1.loss_mask: 1.1245  decode.d1.loss_dice: 0.8466  decode.d2.loss_cls: 0.2291  decode.d2.loss_mask: 1.0640  decode.d2.loss_dice: 0.8578  decode.d3.loss_cls: 0.1995  decode.d3.loss_mask: 1.0649  decode.d3.loss_dice: 0.8423  decode.d4.loss_cls: 0.2203  decode.d4.loss_mask: 1.0257  decode.d4.loss_dice: 0.8528  decode.d5.loss_cls: 0.2138  decode.d5.loss_mask: 1.0571  decode.d5.loss_dice: 0.8639  decode.d6.loss_cls: 0.2749  decode.d6.loss_mask: 1.0410  decode.d6.loss_dice: 0.8412  decode.d7.loss_cls: 0.2070  decode.d7.loss_mask: 1.1177  decode.d7.loss_dice: 0.8497  decode.d8.loss_cls: 0.2045  decode.d8.loss_mask: 1.0146  decode.d8.loss_dice: 0.8465
05/26 14:46:04 - mmengine - INFO - Iter(train) [ 32850/160000]  base_lr: 8.1317e-05 lr: 8.1317e-06  eta: 14:28:31  time: 0.4140  data_time: 0.0092  memory: 5969  grad_norm: 764.6091  loss: 24.7123  decode.loss_cls: 0.2944  decode.loss_mask: 1.2602  decode.loss_dice: 0.8673  decode.d0.loss_cls: 0.7769  decode.d0.loss_mask: 1.1974  decode.d0.loss_dice: 0.8225  decode.d1.loss_cls: 0.3256  decode.d1.loss_mask: 1.2438  decode.d1.loss_dice: 0.8359  decode.d2.loss_cls: 0.3372  decode.d2.loss_mask: 1.2687  decode.d2.loss_dice: 0.8459  decode.d3.loss_cls: 0.3052  decode.d3.loss_mask: 1.2978  decode.d3.loss_dice: 0.8786  decode.d4.loss_cls: 0.3116  decode.d4.loss_mask: 1.2460  decode.d4.loss_dice: 0.8205  decode.d5.loss_cls: 0.3237  decode.d5.loss_mask: 1.1984  decode.d5.loss_dice: 0.8164  decode.d6.loss_cls: 0.2841  decode.d6.loss_mask: 1.3161  decode.d6.loss_dice: 0.8780  decode.d7.loss_cls: 0.3245  decode.d7.loss_mask: 1.3199  decode.d7.loss_dice: 0.8794  decode.d8.loss_cls: 0.3118  decode.d8.loss_mask: 1.2614  decode.d8.loss_dice: 0.8635
05/26 14:46:25 - mmengine - INFO - Iter(train) [ 32900/160000]  base_lr: 8.1288e-05 lr: 8.1288e-06  eta: 14:28:11  time: 0.4142  data_time: 0.0092  memory: 5966  grad_norm: 841.7474  loss: 21.5692  decode.loss_cls: 0.1890  decode.loss_mask: 1.1654  decode.loss_dice: 0.7662  decode.d0.loss_cls: 0.6880  decode.d0.loss_mask: 1.0784  decode.d0.loss_dice: 0.6992  decode.d1.loss_cls: 0.1969  decode.d1.loss_mask: 1.2092  decode.d1.loss_dice: 0.7356  decode.d2.loss_cls: 0.2109  decode.d2.loss_mask: 1.1506  decode.d2.loss_dice: 0.7270  decode.d3.loss_cls: 0.2310  decode.d3.loss_mask: 1.1816  decode.d3.loss_dice: 0.7233  decode.d4.loss_cls: 0.2504  decode.d4.loss_mask: 1.1631  decode.d4.loss_dice: 0.7476  decode.d5.loss_cls: 0.2446  decode.d5.loss_mask: 1.1317  decode.d5.loss_dice: 0.7460  decode.d6.loss_cls: 0.2524  decode.d6.loss_mask: 1.1524  decode.d6.loss_dice: 0.7269  decode.d7.loss_cls: 0.2082  decode.d7.loss_mask: 1.1716  decode.d7.loss_dice: 0.7184  decode.d8.loss_cls: 0.1800  decode.d8.loss_mask: 1.1728  decode.d8.loss_dice: 0.7508
05/26 14:46:46 - mmengine - INFO - Iter(train) [ 32950/160000]  base_lr: 8.1259e-05 lr: 8.1259e-06  eta: 14:27:51  time: 0.4137  data_time: 0.0092  memory: 5975  grad_norm: 693.5511  loss: 29.1254  decode.loss_cls: 0.4290  decode.loss_mask: 1.3854  decode.loss_dice: 1.0611  decode.d0.loss_cls: 1.0163  decode.d0.loss_mask: 1.2185  decode.d0.loss_dice: 0.9551  decode.d1.loss_cls: 0.5228  decode.d1.loss_mask: 1.3789  decode.d1.loss_dice: 1.0326  decode.d2.loss_cls: 0.4613  decode.d2.loss_mask: 1.3444  decode.d2.loss_dice: 1.0212  decode.d3.loss_cls: 0.4188  decode.d3.loss_mask: 1.3680  decode.d3.loss_dice: 1.0187  decode.d4.loss_cls: 0.5529  decode.d4.loss_mask: 1.3070  decode.d4.loss_dice: 1.0658  decode.d5.loss_cls: 0.4666  decode.d5.loss_mask: 1.3923  decode.d5.loss_dice: 1.0632  decode.d6.loss_cls: 0.4030  decode.d6.loss_mask: 1.3460  decode.d6.loss_dice: 1.0845  decode.d7.loss_cls: 0.5169  decode.d7.loss_mask: 1.3609  decode.d7.loss_dice: 1.0620  decode.d8.loss_cls: 0.3906  decode.d8.loss_mask: 1.3934  decode.d8.loss_dice: 1.0883
05/26 14:47:06 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 14:47:06 - mmengine - INFO - Iter(train) [ 33000/160000]  base_lr: 8.1230e-05 lr: 8.1230e-06  eta: 14:27:32  time: 0.4126  data_time: 0.0091  memory: 5968  grad_norm: 1009.8057  loss: 23.1354  decode.loss_cls: 0.1539  decode.loss_mask: 1.2591  decode.loss_dice: 0.8686  decode.d0.loss_cls: 0.6635  decode.d0.loss_mask: 1.1552  decode.d0.loss_dice: 0.8026  decode.d1.loss_cls: 0.1775  decode.d1.loss_mask: 1.2447  decode.d1.loss_dice: 0.8650  decode.d2.loss_cls: 0.2040  decode.d2.loss_mask: 1.1989  decode.d2.loss_dice: 0.8481  decode.d3.loss_cls: 0.1870  decode.d3.loss_mask: 1.2667  decode.d3.loss_dice: 0.8572  decode.d4.loss_cls: 0.1954  decode.d4.loss_mask: 1.2296  decode.d4.loss_dice: 0.8797  decode.d5.loss_cls: 0.1767  decode.d5.loss_mask: 1.2447  decode.d5.loss_dice: 0.8611  decode.d6.loss_cls: 0.1701  decode.d6.loss_mask: 1.2528  decode.d6.loss_dice: 0.8622  decode.d7.loss_cls: 0.1710  decode.d7.loss_mask: 1.2390  decode.d7.loss_dice: 0.8536  decode.d8.loss_cls: 0.1561  decode.d8.loss_mask: 1.2391  decode.d8.loss_dice: 0.8525
05/26 14:47:27 - mmengine - INFO - Iter(train) [ 33050/160000]  base_lr: 8.1201e-05 lr: 8.1201e-06  eta: 14:27:12  time: 0.4154  data_time: 0.0092  memory: 5980  grad_norm: 658.8115  loss: 26.7164  decode.loss_cls: 0.4198  decode.loss_mask: 1.1931  decode.loss_dice: 1.0107  decode.d0.loss_cls: 0.8809  decode.d0.loss_mask: 1.1493  decode.d0.loss_dice: 0.9960  decode.d1.loss_cls: 0.3661  decode.d1.loss_mask: 1.2159  decode.d1.loss_dice: 1.0127  decode.d2.loss_cls: 0.3634  decode.d2.loss_mask: 1.2201  decode.d2.loss_dice: 1.0450  decode.d3.loss_cls: 0.3273  decode.d3.loss_mask: 1.2279  decode.d3.loss_dice: 1.0113  decode.d4.loss_cls: 0.3957  decode.d4.loss_mask: 1.2258  decode.d4.loss_dice: 1.0229  decode.d5.loss_cls: 0.4291  decode.d5.loss_mask: 1.2255  decode.d5.loss_dice: 1.0395  decode.d6.loss_cls: 0.4536  decode.d6.loss_mask: 1.1906  decode.d6.loss_dice: 1.0391  decode.d7.loss_cls: 0.4122  decode.d7.loss_mask: 1.2227  decode.d7.loss_dice: 1.0043  decode.d8.loss_cls: 0.3717  decode.d8.loss_mask: 1.2252  decode.d8.loss_dice: 1.0187
05/26 14:47:48 - mmengine - INFO - Iter(train) [ 33100/160000]  base_lr: 8.1173e-05 lr: 8.1173e-06  eta: 14:26:52  time: 0.4133  data_time: 0.0091  memory: 5983  grad_norm: 584.6420  loss: 23.8144  decode.loss_cls: 0.1266  decode.loss_mask: 1.2742  decode.loss_dice: 0.8964  decode.d0.loss_cls: 0.8117  decode.d0.loss_mask: 1.1261  decode.d0.loss_dice: 0.8141  decode.d1.loss_cls: 0.1970  decode.d1.loss_mask: 1.2905  decode.d1.loss_dice: 0.8719  decode.d2.loss_cls: 0.2343  decode.d2.loss_mask: 1.2734  decode.d2.loss_dice: 0.8832  decode.d3.loss_cls: 0.2070  decode.d3.loss_mask: 1.2960  decode.d3.loss_dice: 0.8757  decode.d4.loss_cls: 0.2419  decode.d4.loss_mask: 1.2466  decode.d4.loss_dice: 0.8929  decode.d5.loss_cls: 0.2073  decode.d5.loss_mask: 1.2577  decode.d5.loss_dice: 0.8559  decode.d6.loss_cls: 0.2308  decode.d6.loss_mask: 1.2225  decode.d6.loss_dice: 0.8607  decode.d7.loss_cls: 0.1585  decode.d7.loss_mask: 1.2720  decode.d7.loss_dice: 0.8863  decode.d8.loss_cls: 0.2176  decode.d8.loss_mask: 1.2233  decode.d8.loss_dice: 0.8620
05/26 14:48:08 - mmengine - INFO - Iter(train) [ 33150/160000]  base_lr: 8.1144e-05 lr: 8.1144e-06  eta: 14:26:33  time: 0.4157  data_time: 0.0092  memory: 5968  grad_norm: 1000.8374  loss: 26.8347  decode.loss_cls: 0.2767  decode.loss_mask: 1.4184  decode.loss_dice: 0.9870  decode.d0.loss_cls: 0.8074  decode.d0.loss_mask: 1.3167  decode.d0.loss_dice: 0.9442  decode.d1.loss_cls: 0.2738  decode.d1.loss_mask: 1.3974  decode.d1.loss_dice: 0.9626  decode.d2.loss_cls: 0.3077  decode.d2.loss_mask: 1.3621  decode.d2.loss_dice: 0.9386  decode.d3.loss_cls: 0.3221  decode.d3.loss_mask: 1.3653  decode.d3.loss_dice: 0.9346  decode.d4.loss_cls: 0.2982  decode.d4.loss_mask: 1.3922  decode.d4.loss_dice: 0.9424  decode.d5.loss_cls: 0.2950  decode.d5.loss_mask: 1.4052  decode.d5.loss_dice: 0.9919  decode.d6.loss_cls: 0.2892  decode.d6.loss_mask: 1.3821  decode.d6.loss_dice: 0.9874  decode.d7.loss_cls: 0.3299  decode.d7.loss_mask: 1.3810  decode.d7.loss_dice: 0.9305  decode.d8.loss_cls: 0.3205  decode.d8.loss_mask: 1.3635  decode.d8.loss_dice: 0.9113
05/26 14:48:29 - mmengine - INFO - Iter(train) [ 33200/160000]  base_lr: 8.1115e-05 lr: 8.1115e-06  eta: 14:26:12  time: 0.4067  data_time: 0.0096  memory: 5965  grad_norm: 858.0181  loss: 24.8599  decode.loss_cls: 0.2749  decode.loss_mask: 1.2878  decode.loss_dice: 0.8955  decode.d0.loss_cls: 0.7910  decode.d0.loss_mask: 1.2231  decode.d0.loss_dice: 0.8750  decode.d1.loss_cls: 0.3201  decode.d1.loss_mask: 1.2614  decode.d1.loss_dice: 0.8578  decode.d2.loss_cls: 0.3071  decode.d2.loss_mask: 1.2495  decode.d2.loss_dice: 0.8641  decode.d3.loss_cls: 0.2753  decode.d3.loss_mask: 1.2709  decode.d3.loss_dice: 0.8649  decode.d4.loss_cls: 0.3386  decode.d4.loss_mask: 1.2421  decode.d4.loss_dice: 0.8577  decode.d5.loss_cls: 0.3678  decode.d5.loss_mask: 1.2462  decode.d5.loss_dice: 0.8534  decode.d6.loss_cls: 0.3025  decode.d6.loss_mask: 1.2503  decode.d6.loss_dice: 0.8878  decode.d7.loss_cls: 0.2961  decode.d7.loss_mask: 1.2631  decode.d7.loss_dice: 0.8775  decode.d8.loss_cls: 0.3257  decode.d8.loss_mask: 1.2633  decode.d8.loss_dice: 0.8695
05/26 14:48:49 - mmengine - INFO - Iter(train) [ 33250/160000]  base_lr: 8.1086e-05 lr: 8.1086e-06  eta: 14:25:51  time: 0.4054  data_time: 0.0088  memory: 5969  grad_norm: 1290.0445  loss: 23.3754  decode.loss_cls: 0.3013  decode.loss_mask: 1.1508  decode.loss_dice: 0.8705  decode.d0.loss_cls: 0.7767  decode.d0.loss_mask: 1.0722  decode.d0.loss_dice: 0.8109  decode.d1.loss_cls: 0.3658  decode.d1.loss_mask: 1.0886  decode.d1.loss_dice: 0.8631  decode.d2.loss_cls: 0.3960  decode.d2.loss_mask: 1.0750  decode.d2.loss_dice: 0.8230  decode.d3.loss_cls: 0.3787  decode.d3.loss_mask: 1.0922  decode.d3.loss_dice: 0.8292  decode.d4.loss_cls: 0.3596  decode.d4.loss_mask: 1.1131  decode.d4.loss_dice: 0.8699  decode.d5.loss_cls: 0.3482  decode.d5.loss_mask: 1.0950  decode.d5.loss_dice: 0.8427  decode.d6.loss_cls: 0.3778  decode.d6.loss_mask: 1.1036  decode.d6.loss_dice: 0.8489  decode.d7.loss_cls: 0.3728  decode.d7.loss_mask: 1.0696  decode.d7.loss_dice: 0.8104  decode.d8.loss_cls: 0.3582  decode.d8.loss_mask: 1.0720  decode.d8.loss_dice: 0.8396
05/26 14:49:10 - mmengine - INFO - Iter(train) [ 33300/160000]  base_lr: 8.1058e-05 lr: 8.1058e-06  eta: 14:25:30  time: 0.4080  data_time: 0.0089  memory: 5968  grad_norm: 546.9564  loss: 25.9386  decode.loss_cls: 0.2689  decode.loss_mask: 1.3023  decode.loss_dice: 0.9654  decode.d0.loss_cls: 0.7553  decode.d0.loss_mask: 1.2067  decode.d0.loss_dice: 0.9134  decode.d1.loss_cls: 0.3344  decode.d1.loss_mask: 1.2844  decode.d1.loss_dice: 0.9176  decode.d2.loss_cls: 0.3260  decode.d2.loss_mask: 1.2855  decode.d2.loss_dice: 0.9657  decode.d3.loss_cls: 0.3302  decode.d3.loss_mask: 1.3146  decode.d3.loss_dice: 0.9738  decode.d4.loss_cls: 0.3199  decode.d4.loss_mask: 1.2457  decode.d4.loss_dice: 0.9452  decode.d5.loss_cls: 0.3246  decode.d5.loss_mask: 1.2968  decode.d5.loss_dice: 0.9850  decode.d6.loss_cls: 0.3073  decode.d6.loss_mask: 1.2897  decode.d6.loss_dice: 0.9835  decode.d7.loss_cls: 0.3010  decode.d7.loss_mask: 1.2799  decode.d7.loss_dice: 0.9499  decode.d8.loss_cls: 0.3027  decode.d8.loss_mask: 1.2991  decode.d8.loss_dice: 0.9640
05/26 14:49:30 - mmengine - INFO - Iter(train) [ 33350/160000]  base_lr: 8.1029e-05 lr: 8.1029e-06  eta: 14:25:10  time: 0.4168  data_time: 0.0101  memory: 5996  grad_norm: 523.6676  loss: 24.5487  decode.loss_cls: 0.3741  decode.loss_mask: 1.0618  decode.loss_dice: 0.9192  decode.d0.loss_cls: 0.9253  decode.d0.loss_mask: 0.9882  decode.d0.loss_dice: 0.8718  decode.d1.loss_cls: 0.4542  decode.d1.loss_mask: 1.0512  decode.d1.loss_dice: 0.9478  decode.d2.loss_cls: 0.3645  decode.d2.loss_mask: 1.1275  decode.d2.loss_dice: 0.9560  decode.d3.loss_cls: 0.4199  decode.d3.loss_mask: 1.0486  decode.d3.loss_dice: 0.9229  decode.d4.loss_cls: 0.3931  decode.d4.loss_mask: 1.0541  decode.d4.loss_dice: 0.9299  decode.d5.loss_cls: 0.4181  decode.d5.loss_mask: 1.1361  decode.d5.loss_dice: 0.9437  decode.d6.loss_cls: 0.4012  decode.d6.loss_mask: 1.0737  decode.d6.loss_dice: 0.9265  decode.d7.loss_cls: 0.4476  decode.d7.loss_mask: 1.0967  decode.d7.loss_dice: 0.9298  decode.d8.loss_cls: 0.3669  decode.d8.loss_mask: 1.0726  decode.d8.loss_dice: 0.9256
05/26 14:49:51 - mmengine - INFO - Iter(train) [ 33400/160000]  base_lr: 8.1000e-05 lr: 8.1000e-06  eta: 14:24:52  time: 0.4138  data_time: 0.0092  memory: 5967  grad_norm: 1335.9774  loss: 28.5098  decode.loss_cls: 0.4803  decode.loss_mask: 1.2696  decode.loss_dice: 1.0072  decode.d0.loss_cls: 1.0971  decode.d0.loss_mask: 1.1747  decode.d0.loss_dice: 0.9615  decode.d1.loss_cls: 0.5499  decode.d1.loss_mask: 1.2417  decode.d1.loss_dice: 0.9559  decode.d2.loss_cls: 0.5119  decode.d2.loss_mask: 1.2725  decode.d2.loss_dice: 0.9844  decode.d3.loss_cls: 0.4470  decode.d3.loss_mask: 1.2831  decode.d3.loss_dice: 0.9964  decode.d4.loss_cls: 0.5158  decode.d4.loss_mask: 1.2702  decode.d4.loss_dice: 1.0222  decode.d5.loss_cls: 0.5446  decode.d5.loss_mask: 1.2775  decode.d5.loss_dice: 0.9719  decode.d6.loss_cls: 0.4670  decode.d6.loss_mask: 1.3008  decode.d6.loss_dice: 1.0287  decode.d7.loss_cls: 0.4632  decode.d7.loss_mask: 1.5321  decode.d7.loss_dice: 1.0891  decode.d8.loss_cls: 0.5023  decode.d8.loss_mask: 1.3021  decode.d8.loss_dice: 0.9893
05/26 14:50:12 - mmengine - INFO - Iter(train) [ 33450/160000]  base_lr: 8.0971e-05 lr: 8.0971e-06  eta: 14:24:32  time: 0.4139  data_time: 0.0092  memory: 5974  grad_norm: 788.5235  loss: 26.5388  decode.loss_cls: 0.2802  decode.loss_mask: 1.2653  decode.loss_dice: 1.0283  decode.d0.loss_cls: 0.8434  decode.d0.loss_mask: 1.2516  decode.d0.loss_dice: 1.0053  decode.d1.loss_cls: 0.2894  decode.d1.loss_mask: 1.2824  decode.d1.loss_dice: 1.0206  decode.d2.loss_cls: 0.2995  decode.d2.loss_mask: 1.2868  decode.d2.loss_dice: 1.0392  decode.d3.loss_cls: 0.2989  decode.d3.loss_mask: 1.2682  decode.d3.loss_dice: 1.0370  decode.d4.loss_cls: 0.3331  decode.d4.loss_mask: 1.2759  decode.d4.loss_dice: 1.0040  decode.d5.loss_cls: 0.3481  decode.d5.loss_mask: 1.2775  decode.d5.loss_dice: 1.0042  decode.d6.loss_cls: 0.2966  decode.d6.loss_mask: 1.2943  decode.d6.loss_dice: 1.0148  decode.d7.loss_cls: 0.3443  decode.d7.loss_mask: 1.2284  decode.d7.loss_dice: 1.0185  decode.d8.loss_cls: 0.2793  decode.d8.loss_mask: 1.3060  decode.d8.loss_dice: 1.0177
05/26 14:50:33 - mmengine - INFO - Iter(train) [ 33500/160000]  base_lr: 8.0942e-05 lr: 8.0942e-06  eta: 14:24:12  time: 0.4150  data_time: 0.0092  memory: 5969  grad_norm: 733.5592  loss: 28.7020  decode.loss_cls: 0.3338  decode.loss_mask: 1.4445  decode.loss_dice: 1.0478  decode.d0.loss_cls: 0.8582  decode.d0.loss_mask: 1.2581  decode.d0.loss_dice: 0.9512  decode.d1.loss_cls: 0.4430  decode.d1.loss_mask: 1.4099  decode.d1.loss_dice: 0.9755  decode.d2.loss_cls: 0.3807  decode.d2.loss_mask: 1.4707  decode.d2.loss_dice: 1.0210  decode.d3.loss_cls: 0.3866  decode.d3.loss_mask: 1.3913  decode.d3.loss_dice: 1.0122  decode.d4.loss_cls: 0.3983  decode.d4.loss_mask: 1.4504  decode.d4.loss_dice: 1.0703  decode.d5.loss_cls: 0.3516  decode.d5.loss_mask: 1.4435  decode.d5.loss_dice: 1.0397  decode.d6.loss_cls: 0.3497  decode.d6.loss_mask: 1.4221  decode.d6.loss_dice: 1.0451  decode.d7.loss_cls: 0.3587  decode.d7.loss_mask: 1.4755  decode.d7.loss_dice: 1.0746  decode.d8.loss_cls: 0.4344  decode.d8.loss_mask: 1.3832  decode.d8.loss_dice: 1.0204
05/26 14:50:54 - mmengine - INFO - Iter(train) [ 33550/160000]  base_lr: 8.0914e-05 lr: 8.0914e-06  eta: 14:23:53  time: 0.4135  data_time: 0.0092  memory: 5968  grad_norm: 663.2408  loss: 28.2291  decode.loss_cls: 0.4400  decode.loss_mask: 1.3039  decode.loss_dice: 1.0882  decode.d0.loss_cls: 0.9050  decode.d0.loss_mask: 1.2098  decode.d0.loss_dice: 1.0285  decode.d1.loss_cls: 0.4432  decode.d1.loss_mask: 1.2480  decode.d1.loss_dice: 1.0430  decode.d2.loss_cls: 0.4269  decode.d2.loss_mask: 1.2468  decode.d2.loss_dice: 1.0443  decode.d3.loss_cls: 0.4117  decode.d3.loss_mask: 1.3187  decode.d3.loss_dice: 1.0488  decode.d4.loss_cls: 0.4614  decode.d4.loss_mask: 1.3042  decode.d4.loss_dice: 1.0829  decode.d5.loss_cls: 0.4184  decode.d5.loss_mask: 1.2976  decode.d5.loss_dice: 1.0882  decode.d6.loss_cls: 0.4136  decode.d6.loss_mask: 1.3061  decode.d6.loss_dice: 1.1046  decode.d7.loss_cls: 0.4361  decode.d7.loss_mask: 1.2514  decode.d7.loss_dice: 1.0590  decode.d8.loss_cls: 0.4490  decode.d8.loss_mask: 1.2742  decode.d8.loss_dice: 1.0755
05/26 14:51:14 - mmengine - INFO - Iter(train) [ 33600/160000]  base_lr: 8.0885e-05 lr: 8.0885e-06  eta: 14:23:33  time: 0.4147  data_time: 0.0092  memory: 5980  grad_norm: 719.9925  loss: 26.7047  decode.loss_cls: 0.4333  decode.loss_mask: 1.2328  decode.loss_dice: 0.9553  decode.d0.loss_cls: 0.7808  decode.d0.loss_mask: 1.1683  decode.d0.loss_dice: 0.9483  decode.d1.loss_cls: 0.3869  decode.d1.loss_mask: 1.2797  decode.d1.loss_dice: 0.9853  decode.d2.loss_cls: 0.3768  decode.d2.loss_mask: 1.2446  decode.d2.loss_dice: 0.9796  decode.d3.loss_cls: 0.3927  decode.d3.loss_mask: 1.2534  decode.d3.loss_dice: 0.9610  decode.d4.loss_cls: 0.4143  decode.d4.loss_mask: 1.2375  decode.d4.loss_dice: 0.9499  decode.d5.loss_cls: 0.4224  decode.d5.loss_mask: 1.2420  decode.d5.loss_dice: 0.9854  decode.d6.loss_cls: 0.3945  decode.d6.loss_mask: 1.3256  decode.d6.loss_dice: 1.0598  decode.d7.loss_cls: 0.3732  decode.d7.loss_mask: 1.2535  decode.d7.loss_dice: 0.9975  decode.d8.loss_cls: 0.4598  decode.d8.loss_mask: 1.2497  decode.d8.loss_dice: 0.9607
05/26 14:51:35 - mmengine - INFO - Iter(train) [ 33650/160000]  base_lr: 8.0856e-05 lr: 8.0856e-06  eta: 14:23:14  time: 0.4131  data_time: 0.0092  memory: 5968  grad_norm: 904.9441  loss: 24.9525  decode.loss_cls: 0.2283  decode.loss_mask: 1.2303  decode.loss_dice: 0.9138  decode.d0.loss_cls: 0.6779  decode.d0.loss_mask: 1.2047  decode.d0.loss_dice: 0.9195  decode.d1.loss_cls: 0.3719  decode.d1.loss_mask: 1.2080  decode.d1.loss_dice: 0.9022  decode.d2.loss_cls: 0.3031  decode.d2.loss_mask: 1.2060  decode.d2.loss_dice: 0.9055  decode.d3.loss_cls: 0.3183  decode.d3.loss_mask: 1.2694  decode.d3.loss_dice: 0.9317  decode.d4.loss_cls: 0.3205  decode.d4.loss_mask: 1.2316  decode.d4.loss_dice: 0.9241  decode.d5.loss_cls: 0.2618  decode.d5.loss_mask: 1.2705  decode.d5.loss_dice: 0.9408  decode.d6.loss_cls: 0.2979  decode.d6.loss_mask: 1.2516  decode.d6.loss_dice: 0.9253  decode.d7.loss_cls: 0.3335  decode.d7.loss_mask: 1.2230  decode.d7.loss_dice: 0.9347  decode.d8.loss_cls: 0.2724  decode.d8.loss_mask: 1.2655  decode.d8.loss_dice: 0.9087
05/26 14:51:56 - mmengine - INFO - Iter(train) [ 33700/160000]  base_lr: 8.0827e-05 lr: 8.0827e-06  eta: 14:22:54  time: 0.4177  data_time: 0.0092  memory: 5994  grad_norm: 483.1814  loss: 28.3001  decode.loss_cls: 0.4730  decode.loss_mask: 1.2591  decode.loss_dice: 1.1199  decode.d0.loss_cls: 0.9724  decode.d0.loss_mask: 1.1479  decode.d0.loss_dice: 1.0767  decode.d1.loss_cls: 0.4003  decode.d1.loss_mask: 1.2765  decode.d1.loss_dice: 1.0791  decode.d2.loss_cls: 0.4277  decode.d2.loss_mask: 1.2282  decode.d2.loss_dice: 1.0882  decode.d3.loss_cls: 0.4020  decode.d3.loss_mask: 1.2210  decode.d3.loss_dice: 1.0847  decode.d4.loss_cls: 0.4245  decode.d4.loss_mask: 1.2299  decode.d4.loss_dice: 1.1031  decode.d5.loss_cls: 0.4650  decode.d5.loss_mask: 1.1884  decode.d5.loss_dice: 1.1023  decode.d6.loss_cls: 0.5052  decode.d6.loss_mask: 1.2267  decode.d6.loss_dice: 1.0982  decode.d7.loss_cls: 0.4737  decode.d7.loss_mask: 1.2175  decode.d7.loss_dice: 1.1220  decode.d8.loss_cls: 0.5334  decode.d8.loss_mask: 1.2196  decode.d8.loss_dice: 1.1338
05/26 14:52:17 - mmengine - INFO - Iter(train) [ 33750/160000]  base_lr: 8.0798e-05 lr: 8.0798e-06  eta: 14:22:35  time: 0.4155  data_time: 0.0092  memory: 5975  grad_norm: 750.2769  loss: 28.6938  decode.loss_cls: 0.4196  decode.loss_mask: 1.3542  decode.loss_dice: 1.0381  decode.d0.loss_cls: 1.0245  decode.d0.loss_mask: 1.2279  decode.d0.loss_dice: 1.0418  decode.d1.loss_cls: 0.3711  decode.d1.loss_mask: 1.3361  decode.d1.loss_dice: 1.0928  decode.d2.loss_cls: 0.3972  decode.d2.loss_mask: 1.3222  decode.d2.loss_dice: 1.0908  decode.d3.loss_cls: 0.3944  decode.d3.loss_mask: 1.3544  decode.d3.loss_dice: 1.1010  decode.d4.loss_cls: 0.4704  decode.d4.loss_mask: 1.3589  decode.d4.loss_dice: 1.0814  decode.d5.loss_cls: 0.4599  decode.d5.loss_mask: 1.3270  decode.d5.loss_dice: 1.0578  decode.d6.loss_cls: 0.4734  decode.d6.loss_mask: 1.2748  decode.d6.loss_dice: 1.0622  decode.d7.loss_cls: 0.4198  decode.d7.loss_mask: 1.2989  decode.d7.loss_dice: 1.0561  decode.d8.loss_cls: 0.4621  decode.d8.loss_mask: 1.2970  decode.d8.loss_dice: 1.0280
05/26 14:52:37 - mmengine - INFO - Iter(train) [ 33800/160000]  base_lr: 8.0770e-05 lr: 8.0770e-06  eta: 14:22:14  time: 0.4084  data_time: 0.0102  memory: 5974  grad_norm: 587.8882  loss: 26.3048  decode.loss_cls: 0.2761  decode.loss_mask: 1.2358  decode.loss_dice: 0.9769  decode.d0.loss_cls: 0.8788  decode.d0.loss_mask: 1.1982  decode.d0.loss_dice: 0.9280  decode.d1.loss_cls: 0.2804  decode.d1.loss_mask: 1.2861  decode.d1.loss_dice: 0.9912  decode.d2.loss_cls: 0.3414  decode.d2.loss_mask: 1.2859  decode.d2.loss_dice: 0.9840  decode.d3.loss_cls: 0.3020  decode.d3.loss_mask: 1.3003  decode.d3.loss_dice: 1.0227  decode.d4.loss_cls: 0.3573  decode.d4.loss_mask: 1.2812  decode.d4.loss_dice: 1.0187  decode.d5.loss_cls: 0.3898  decode.d5.loss_mask: 1.2320  decode.d5.loss_dice: 0.9748  decode.d6.loss_cls: 0.2982  decode.d6.loss_mask: 1.2840  decode.d6.loss_dice: 0.9991  decode.d7.loss_cls: 0.3204  decode.d7.loss_mask: 1.2834  decode.d7.loss_dice: 0.9958  decode.d8.loss_cls: 0.2822  decode.d8.loss_mask: 1.3086  decode.d8.loss_dice: 0.9915
05/26 14:52:57 - mmengine - INFO - Iter(train) [ 33850/160000]  base_lr: 8.0741e-05 lr: 8.0741e-06  eta: 14:21:53  time: 0.4059  data_time: 0.0088  memory: 5965  grad_norm: 632.9749  loss: 23.6581  decode.loss_cls: 0.1988  decode.loss_mask: 1.1850  decode.loss_dice: 0.9074  decode.d0.loss_cls: 0.6282  decode.d0.loss_mask: 1.2421  decode.d0.loss_dice: 0.9035  decode.d1.loss_cls: 0.2146  decode.d1.loss_mask: 1.2215  decode.d1.loss_dice: 0.9133  decode.d2.loss_cls: 0.1806  decode.d2.loss_mask: 1.2189  decode.d2.loss_dice: 0.8736  decode.d3.loss_cls: 0.1862  decode.d3.loss_mask: 1.2271  decode.d3.loss_dice: 0.9127  decode.d4.loss_cls: 0.2119  decode.d4.loss_mask: 1.2101  decode.d4.loss_dice: 0.8959  decode.d5.loss_cls: 0.2178  decode.d5.loss_mask: 1.2012  decode.d5.loss_dice: 0.9047  decode.d6.loss_cls: 0.1994  decode.d6.loss_mask: 1.2196  decode.d6.loss_dice: 0.8983  decode.d7.loss_cls: 0.2516  decode.d7.loss_mask: 1.2009  decode.d7.loss_dice: 0.8919  decode.d8.loss_cls: 0.1843  decode.d8.loss_mask: 1.2268  decode.d8.loss_dice: 0.9301
05/26 14:53:18 - mmengine - INFO - Iter(train) [ 33900/160000]  base_lr: 8.0712e-05 lr: 8.0712e-06  eta: 14:21:32  time: 0.4153  data_time: 0.0092  memory: 5967  grad_norm: 1043.7381  loss: 23.3635  decode.loss_cls: 0.1875  decode.loss_mask: 1.3095  decode.loss_dice: 0.7665  decode.d0.loss_cls: 0.6504  decode.d0.loss_mask: 1.2433  decode.d0.loss_dice: 0.7951  decode.d1.loss_cls: 0.1964  decode.d1.loss_mask: 1.3373  decode.d1.loss_dice: 0.8122  decode.d2.loss_cls: 0.1746  decode.d2.loss_mask: 1.3230  decode.d2.loss_dice: 0.7870  decode.d3.loss_cls: 0.1969  decode.d3.loss_mask: 1.2729  decode.d3.loss_dice: 0.7656  decode.d4.loss_cls: 0.1726  decode.d4.loss_mask: 1.3507  decode.d4.loss_dice: 0.7995  decode.d5.loss_cls: 0.1733  decode.d5.loss_mask: 1.3644  decode.d5.loss_dice: 0.8004  decode.d6.loss_cls: 0.2113  decode.d6.loss_mask: 1.2842  decode.d6.loss_dice: 0.7703  decode.d7.loss_cls: 0.2171  decode.d7.loss_mask: 1.3051  decode.d7.loss_dice: 0.7758  decode.d8.loss_cls: 0.1449  decode.d8.loss_mask: 1.3845  decode.d8.loss_dice: 0.7915
05/26 14:53:39 - mmengine - INFO - Iter(train) [ 33950/160000]  base_lr: 8.0683e-05 lr: 8.0683e-06  eta: 14:21:12  time: 0.4156  data_time: 0.0092  memory: 5981  grad_norm: 645.5183  loss: 25.2779  decode.loss_cls: 0.3802  decode.loss_mask: 1.1520  decode.loss_dice: 0.8638  decode.d0.loss_cls: 0.8852  decode.d0.loss_mask: 1.1649  decode.d0.loss_dice: 0.8600  decode.d1.loss_cls: 0.3741  decode.d1.loss_mask: 1.2241  decode.d1.loss_dice: 0.8490  decode.d2.loss_cls: 0.3572  decode.d2.loss_mask: 1.2920  decode.d2.loss_dice: 0.8655  decode.d3.loss_cls: 0.3961  decode.d3.loss_mask: 1.2323  decode.d3.loss_dice: 0.8649  decode.d4.loss_cls: 0.3804  decode.d4.loss_mask: 1.2620  decode.d4.loss_dice: 0.8329  decode.d5.loss_cls: 0.4066  decode.d5.loss_mask: 1.2303  decode.d5.loss_dice: 0.8409  decode.d6.loss_cls: 0.4459  decode.d6.loss_mask: 1.2157  decode.d6.loss_dice: 0.8596  decode.d7.loss_cls: 0.4247  decode.d7.loss_mask: 1.1960  decode.d7.loss_dice: 0.9132  decode.d8.loss_cls: 0.3475  decode.d8.loss_mask: 1.2593  decode.d8.loss_dice: 0.9015
05/26 14:54:00 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 14:54:00 - mmengine - INFO - Iter(train) [ 34000/160000]  base_lr: 8.0654e-05 lr: 8.0654e-06  eta: 14:20:54  time: 0.4146  data_time: 0.0092  memory: 5974  grad_norm: 840.7008  loss: 26.3864  decode.loss_cls: 0.3433  decode.loss_mask: 1.3044  decode.loss_dice: 0.9411  decode.d0.loss_cls: 0.8311  decode.d0.loss_mask: 1.2160  decode.d0.loss_dice: 0.8384  decode.d1.loss_cls: 0.3690  decode.d1.loss_mask: 1.3139  decode.d1.loss_dice: 0.9151  decode.d2.loss_cls: 0.3551  decode.d2.loss_mask: 1.2977  decode.d2.loss_dice: 0.9297  decode.d3.loss_cls: 0.3755  decode.d3.loss_mask: 1.3051  decode.d3.loss_dice: 0.9120  decode.d4.loss_cls: 0.4040  decode.d4.loss_mask: 1.2826  decode.d4.loss_dice: 0.9387  decode.d5.loss_cls: 0.3947  decode.d5.loss_mask: 1.2806  decode.d5.loss_dice: 0.9287  decode.d6.loss_cls: 0.3709  decode.d6.loss_mask: 1.3222  decode.d6.loss_dice: 0.9324  decode.d7.loss_cls: 0.3814  decode.d7.loss_mask: 1.3514  decode.d7.loss_dice: 0.9483  decode.d8.loss_cls: 0.3412  decode.d8.loss_mask: 1.3077  decode.d8.loss_dice: 0.9541
05/26 14:54:20 - mmengine - INFO - Iter(train) [ 34050/160000]  base_lr: 8.0626e-05 lr: 8.0626e-06  eta: 14:20:34  time: 0.4119  data_time: 0.0092  memory: 5975  grad_norm: 830.5537  loss: 24.1830  decode.loss_cls: 0.2361  decode.loss_mask: 1.3277  decode.loss_dice: 0.8988  decode.d0.loss_cls: 0.7320  decode.d0.loss_mask: 1.1263  decode.d0.loss_dice: 0.7859  decode.d1.loss_cls: 0.2877  decode.d1.loss_mask: 1.2497  decode.d1.loss_dice: 0.8633  decode.d2.loss_cls: 0.2745  decode.d2.loss_mask: 1.2431  decode.d2.loss_dice: 0.8805  decode.d3.loss_cls: 0.2880  decode.d3.loss_mask: 1.2085  decode.d3.loss_dice: 0.8319  decode.d4.loss_cls: 0.2874  decode.d4.loss_mask: 1.2462  decode.d4.loss_dice: 0.8524  decode.d5.loss_cls: 0.3452  decode.d5.loss_mask: 1.1238  decode.d5.loss_dice: 0.8193  decode.d6.loss_cls: 0.3099  decode.d6.loss_mask: 1.2394  decode.d6.loss_dice: 0.8528  decode.d7.loss_cls: 0.2293  decode.d7.loss_mask: 1.2964  decode.d7.loss_dice: 0.9051  decode.d8.loss_cls: 0.2933  decode.d8.loss_mask: 1.2438  decode.d8.loss_dice: 0.9046
05/26 14:54:41 - mmengine - INFO - Iter(train) [ 34100/160000]  base_lr: 8.0597e-05 lr: 8.0597e-06  eta: 14:20:14  time: 0.4127  data_time: 0.0092  memory: 5976  grad_norm: 441.2754  loss: 22.0689  decode.loss_cls: 0.2262  decode.loss_mask: 1.1382  decode.loss_dice: 0.8059  decode.d0.loss_cls: 0.7251  decode.d0.loss_mask: 1.0683  decode.d0.loss_dice: 0.8127  decode.d1.loss_cls: 0.2442  decode.d1.loss_mask: 1.1127  decode.d1.loss_dice: 0.8053  decode.d2.loss_cls: 0.2745  decode.d2.loss_mask: 1.0709  decode.d2.loss_dice: 0.7749  decode.d3.loss_cls: 0.2361  decode.d3.loss_mask: 1.1170  decode.d3.loss_dice: 0.7985  decode.d4.loss_cls: 0.2379  decode.d4.loss_mask: 1.1567  decode.d4.loss_dice: 0.8127  decode.d5.loss_cls: 0.2531  decode.d5.loss_mask: 1.1612  decode.d5.loss_dice: 0.7941  decode.d6.loss_cls: 0.2793  decode.d6.loss_mask: 1.0630  decode.d6.loss_dice: 0.7802  decode.d7.loss_cls: 0.2368  decode.d7.loss_mask: 1.1394  decode.d7.loss_dice: 0.7870  decode.d8.loss_cls: 0.2658  decode.d8.loss_mask: 1.1038  decode.d8.loss_dice: 0.7869
05/26 14:55:02 - mmengine - INFO - Iter(train) [ 34150/160000]  base_lr: 8.0568e-05 lr: 8.0568e-06  eta: 14:19:54  time: 0.4130  data_time: 0.0092  memory: 5981  grad_norm: 494.2030  loss: 24.2651  decode.loss_cls: 0.2801  decode.loss_mask: 1.2036  decode.loss_dice: 0.8631  decode.d0.loss_cls: 0.7446  decode.d0.loss_mask: 1.2435  decode.d0.loss_dice: 0.8876  decode.d1.loss_cls: 0.2948  decode.d1.loss_mask: 1.2416  decode.d1.loss_dice: 0.8559  decode.d2.loss_cls: 0.2973  decode.d2.loss_mask: 1.2024  decode.d2.loss_dice: 0.8664  decode.d3.loss_cls: 0.3101  decode.d3.loss_mask: 1.1942  decode.d3.loss_dice: 0.8357  decode.d4.loss_cls: 0.3529  decode.d4.loss_mask: 1.1680  decode.d4.loss_dice: 0.8202  decode.d5.loss_cls: 0.3228  decode.d5.loss_mask: 1.2249  decode.d5.loss_dice: 0.8673  decode.d6.loss_cls: 0.2986  decode.d6.loss_mask: 1.2696  decode.d6.loss_dice: 0.8595  decode.d7.loss_cls: 0.2914  decode.d7.loss_mask: 1.2070  decode.d7.loss_dice: 0.8734  decode.d8.loss_cls: 0.2663  decode.d8.loss_mask: 1.2243  decode.d8.loss_dice: 0.8979
05/26 14:55:22 - mmengine - INFO - Iter(train) [ 34200/160000]  base_lr: 8.0539e-05 lr: 8.0539e-06  eta: 14:19:34  time: 0.4135  data_time: 0.0092  memory: 5969  grad_norm: 549.1532  loss: 25.0344  decode.loss_cls: 0.3210  decode.loss_mask: 1.1627  decode.loss_dice: 0.9064  decode.d0.loss_cls: 0.7828  decode.d0.loss_mask: 1.1406  decode.d0.loss_dice: 0.9678  decode.d1.loss_cls: 0.3575  decode.d1.loss_mask: 1.1819  decode.d1.loss_dice: 0.9821  decode.d2.loss_cls: 0.3452  decode.d2.loss_mask: 1.1754  decode.d2.loss_dice: 0.9631  decode.d3.loss_cls: 0.3249  decode.d3.loss_mask: 1.1758  decode.d3.loss_dice: 0.9480  decode.d4.loss_cls: 0.3700  decode.d4.loss_mask: 1.1331  decode.d4.loss_dice: 0.9339  decode.d5.loss_cls: 0.3672  decode.d5.loss_mask: 1.1210  decode.d5.loss_dice: 0.9514  decode.d6.loss_cls: 0.3650  decode.d6.loss_mask: 1.1598  decode.d6.loss_dice: 0.9493  decode.d7.loss_cls: 0.3796  decode.d7.loss_mask: 1.1547  decode.d7.loss_dice: 0.9452  decode.d8.loss_cls: 0.3264  decode.d8.loss_mask: 1.1962  decode.d8.loss_dice: 0.9462
05/26 14:55:43 - mmengine - INFO - Iter(train) [ 34250/160000]  base_lr: 8.0510e-05 lr: 8.0510e-06  eta: 14:19:15  time: 0.4139  data_time: 0.0092  memory: 5967  grad_norm: 653.7140  loss: 28.8308  decode.loss_cls: 0.2972  decode.loss_mask: 1.7067  decode.loss_dice: 1.0671  decode.d0.loss_cls: 0.7724  decode.d0.loss_mask: 1.3730  decode.d0.loss_dice: 0.9140  decode.d1.loss_cls: 0.2630  decode.d1.loss_mask: 1.5050  decode.d1.loss_dice: 0.9848  decode.d2.loss_cls: 0.2835  decode.d2.loss_mask: 1.4879  decode.d2.loss_dice: 0.9408  decode.d3.loss_cls: 0.3081  decode.d3.loss_mask: 1.5119  decode.d3.loss_dice: 0.9900  decode.d4.loss_cls: 0.3031  decode.d4.loss_mask: 1.5231  decode.d4.loss_dice: 1.0196  decode.d5.loss_cls: 0.3296  decode.d5.loss_mask: 1.5646  decode.d5.loss_dice: 1.0220  decode.d6.loss_cls: 0.3592  decode.d6.loss_mask: 1.6068  decode.d6.loss_dice: 1.0082  decode.d7.loss_cls: 0.3509  decode.d7.loss_mask: 1.5041  decode.d7.loss_dice: 0.9639  decode.d8.loss_cls: 0.3134  decode.d8.loss_mask: 1.5620  decode.d8.loss_dice: 0.9951
05/26 14:56:04 - mmengine - INFO - Iter(train) [ 34300/160000]  base_lr: 8.0482e-05 lr: 8.0482e-06  eta: 14:18:55  time: 0.4151  data_time: 0.0092  memory: 5975  grad_norm: 700.0239  loss: 24.7599  decode.loss_cls: 0.3952  decode.loss_mask: 1.1241  decode.loss_dice: 0.8968  decode.d0.loss_cls: 0.8379  decode.d0.loss_mask: 1.0466  decode.d0.loss_dice: 0.9092  decode.d1.loss_cls: 0.3837  decode.d1.loss_mask: 1.1313  decode.d1.loss_dice: 0.9108  decode.d2.loss_cls: 0.4138  decode.d2.loss_mask: 1.0771  decode.d2.loss_dice: 0.9167  decode.d3.loss_cls: 0.3971  decode.d3.loss_mask: 1.0886  decode.d3.loss_dice: 0.9443  decode.d4.loss_cls: 0.4580  decode.d4.loss_mask: 1.1010  decode.d4.loss_dice: 0.9363  decode.d5.loss_cls: 0.4719  decode.d5.loss_mask: 1.0983  decode.d5.loss_dice: 0.8968  decode.d6.loss_cls: 0.4466  decode.d6.loss_mask: 1.1265  decode.d6.loss_dice: 0.9433  decode.d7.loss_cls: 0.4077  decode.d7.loss_mask: 1.0981  decode.d7.loss_dice: 0.8943  decode.d8.loss_cls: 0.3989  decode.d8.loss_mask: 1.1110  decode.d8.loss_dice: 0.8981
05/26 14:56:25 - mmengine - INFO - Iter(train) [ 34350/160000]  base_lr: 8.0453e-05 lr: 8.0453e-06  eta: 14:18:36  time: 0.4111  data_time: 0.0091  memory: 5982  grad_norm: 894.7157  loss: 26.7556  decode.loss_cls: 0.4068  decode.loss_mask: 1.1395  decode.loss_dice: 1.0485  decode.d0.loss_cls: 0.9792  decode.d0.loss_mask: 1.0757  decode.d0.loss_dice: 1.0219  decode.d1.loss_cls: 0.4165  decode.d1.loss_mask: 1.1783  decode.d1.loss_dice: 1.0970  decode.d2.loss_cls: 0.4320  decode.d2.loss_mask: 1.1727  decode.d2.loss_dice: 1.0341  decode.d3.loss_cls: 0.4889  decode.d3.loss_mask: 1.1246  decode.d3.loss_dice: 1.0434  decode.d4.loss_cls: 0.4837  decode.d4.loss_mask: 1.1238  decode.d4.loss_dice: 1.0306  decode.d5.loss_cls: 0.4505  decode.d5.loss_mask: 1.1374  decode.d5.loss_dice: 1.0624  decode.d6.loss_cls: 0.4388  decode.d6.loss_mask: 1.1300  decode.d6.loss_dice: 1.0287  decode.d7.loss_cls: 0.4752  decode.d7.loss_mask: 1.1161  decode.d7.loss_dice: 1.0127  decode.d8.loss_cls: 0.4120  decode.d8.loss_mask: 1.1664  decode.d8.loss_dice: 1.0279
05/26 14:56:45 - mmengine - INFO - Iter(train) [ 34400/160000]  base_lr: 8.0424e-05 lr: 8.0424e-06  eta: 14:18:15  time: 0.4056  data_time: 0.0089  memory: 5983  grad_norm: 513.2104  loss: 22.1395  decode.loss_cls: 0.2390  decode.loss_mask: 1.0868  decode.loss_dice: 0.8047  decode.d0.loss_cls: 0.6869  decode.d0.loss_mask: 1.1037  decode.d0.loss_dice: 0.8357  decode.d1.loss_cls: 0.2898  decode.d1.loss_mask: 1.1356  decode.d1.loss_dice: 0.8429  decode.d2.loss_cls: 0.2264  decode.d2.loss_mask: 1.0932  decode.d2.loss_dice: 0.7983  decode.d3.loss_cls: 0.2314  decode.d3.loss_mask: 1.1060  decode.d3.loss_dice: 0.8464  decode.d4.loss_cls: 0.2349  decode.d4.loss_mask: 1.1295  decode.d4.loss_dice: 0.8318  decode.d5.loss_cls: 0.2479  decode.d5.loss_mask: 1.1193  decode.d5.loss_dice: 0.8112  decode.d6.loss_cls: 0.2436  decode.d6.loss_mask: 1.1091  decode.d6.loss_dice: 0.8238  decode.d7.loss_cls: 0.2342  decode.d7.loss_mask: 1.0701  decode.d7.loss_dice: 0.7886  decode.d8.loss_cls: 0.2561  decode.d8.loss_mask: 1.0981  decode.d8.loss_dice: 0.8145
05/26 14:57:05 - mmengine - INFO - Iter(train) [ 34450/160000]  base_lr: 8.0395e-05 lr: 8.0395e-06  eta: 14:17:53  time: 0.4075  data_time: 0.0090  memory: 5966  grad_norm: 272.3117  loss: 20.6956  decode.loss_cls: 0.1990  decode.loss_mask: 1.0138  decode.loss_dice: 0.7700  decode.d0.loss_cls: 0.7980  decode.d0.loss_mask: 0.9734  decode.d0.loss_dice: 0.7783  decode.d1.loss_cls: 0.2554  decode.d1.loss_mask: 1.0771  decode.d1.loss_dice: 0.8055  decode.d2.loss_cls: 0.1968  decode.d2.loss_mask: 1.0512  decode.d2.loss_dice: 0.7966  decode.d3.loss_cls: 0.2210  decode.d3.loss_mask: 0.9957  decode.d3.loss_dice: 0.7648  decode.d4.loss_cls: 0.2972  decode.d4.loss_mask: 0.9665  decode.d4.loss_dice: 0.7599  decode.d5.loss_cls: 0.2207  decode.d5.loss_mask: 1.0172  decode.d5.loss_dice: 0.7929  decode.d6.loss_cls: 0.1913  decode.d6.loss_mask: 0.9775  decode.d6.loss_dice: 0.7828  decode.d7.loss_cls: 0.2677  decode.d7.loss_mask: 0.9757  decode.d7.loss_dice: 0.7704  decode.d8.loss_cls: 0.1993  decode.d8.loss_mask: 0.9899  decode.d8.loss_dice: 0.7900
05/26 14:57:26 - mmengine - INFO - Iter(train) [ 34500/160000]  base_lr: 8.0366e-05 lr: 8.0366e-06  eta: 14:17:34  time: 0.4164  data_time: 0.0092  memory: 5974  grad_norm: 664.4269  loss: 30.0678  decode.loss_cls: 0.5113  decode.loss_mask: 1.4234  decode.loss_dice: 1.0405  decode.d0.loss_cls: 1.0972  decode.d0.loss_mask: 1.2527  decode.d0.loss_dice: 0.9880  decode.d1.loss_cls: 0.5041  decode.d1.loss_mask: 1.3780  decode.d1.loss_dice: 1.0154  decode.d2.loss_cls: 0.5526  decode.d2.loss_mask: 1.3121  decode.d2.loss_dice: 1.0028  decode.d3.loss_cls: 0.4961  decode.d3.loss_mask: 1.4024  decode.d3.loss_dice: 1.0280  decode.d4.loss_cls: 0.5589  decode.d4.loss_mask: 1.4088  decode.d4.loss_dice: 1.0378  decode.d5.loss_cls: 0.5791  decode.d5.loss_mask: 1.4268  decode.d5.loss_dice: 1.0521  decode.d6.loss_cls: 0.5442  decode.d6.loss_mask: 1.4331  decode.d6.loss_dice: 1.0891  decode.d7.loss_cls: 0.5264  decode.d7.loss_mask: 1.3826  decode.d7.loss_dice: 1.0186  decode.d8.loss_cls: 0.5354  decode.d8.loss_mask: 1.4194  decode.d8.loss_dice: 1.0508
05/26 14:57:47 - mmengine - INFO - Iter(train) [ 34550/160000]  base_lr: 8.0337e-05 lr: 8.0337e-06  eta: 14:17:15  time: 0.4162  data_time: 0.0096  memory: 5975  grad_norm: 511.9041  loss: 21.0861  decode.loss_cls: 0.2057  decode.loss_mask: 1.1392  decode.loss_dice: 0.7123  decode.d0.loss_cls: 0.7549  decode.d0.loss_mask: 1.0962  decode.d0.loss_dice: 0.6731  decode.d1.loss_cls: 0.2885  decode.d1.loss_mask: 1.0869  decode.d1.loss_dice: 0.6731  decode.d2.loss_cls: 0.2579  decode.d2.loss_mask: 1.1374  decode.d2.loss_dice: 0.7014  decode.d3.loss_cls: 0.2272  decode.d3.loss_mask: 1.1201  decode.d3.loss_dice: 0.6806  decode.d4.loss_cls: 0.2928  decode.d4.loss_mask: 1.1066  decode.d4.loss_dice: 0.6902  decode.d5.loss_cls: 0.2500  decode.d5.loss_mask: 1.1242  decode.d5.loss_dice: 0.6837  decode.d6.loss_cls: 0.2732  decode.d6.loss_mask: 1.1672  decode.d6.loss_dice: 0.6945  decode.d7.loss_cls: 0.2258  decode.d7.loss_mask: 1.1251  decode.d7.loss_dice: 0.6816  decode.d8.loss_cls: 0.2249  decode.d8.loss_mask: 1.0998  decode.d8.loss_dice: 0.6920
05/26 14:58:08 - mmengine - INFO - Iter(train) [ 34600/160000]  base_lr: 8.0309e-05 lr: 8.0309e-06  eta: 14:16:56  time: 0.4159  data_time: 0.0096  memory: 5984  grad_norm: 520.9605  loss: 22.8836  decode.loss_cls: 0.4424  decode.loss_mask: 0.8944  decode.loss_dice: 0.9123  decode.d0.loss_cls: 0.9140  decode.d0.loss_mask: 0.8567  decode.d0.loss_dice: 0.9118  decode.d1.loss_cls: 0.4311  decode.d1.loss_mask: 0.9045  decode.d1.loss_dice: 0.8763  decode.d2.loss_cls: 0.3992  decode.d2.loss_mask: 0.8767  decode.d2.loss_dice: 0.9176  decode.d3.loss_cls: 0.4042  decode.d3.loss_mask: 0.8839  decode.d3.loss_dice: 0.8903  decode.d4.loss_cls: 0.4824  decode.d4.loss_mask: 0.8530  decode.d4.loss_dice: 0.8837  decode.d5.loss_cls: 0.4481  decode.d5.loss_mask: 0.8864  decode.d5.loss_dice: 0.9538  decode.d6.loss_cls: 0.4603  decode.d6.loss_mask: 0.9011  decode.d6.loss_dice: 0.9568  decode.d7.loss_cls: 0.4260  decode.d7.loss_mask: 0.9006  decode.d7.loss_dice: 0.9493  decode.d8.loss_cls: 0.4135  decode.d8.loss_mask: 0.8907  decode.d8.loss_dice: 0.9624
05/26 14:58:29 - mmengine - INFO - Iter(train) [ 34650/160000]  base_lr: 8.0280e-05 lr: 8.0280e-06  eta: 14:16:36  time: 0.4138  data_time: 0.0092  memory: 5966  grad_norm: 1008.4030  loss: 27.8649  decode.loss_cls: 0.3541  decode.loss_mask: 1.3133  decode.loss_dice: 1.0944  decode.d0.loss_cls: 0.8096  decode.d0.loss_mask: 1.2361  decode.d0.loss_dice: 1.0169  decode.d1.loss_cls: 0.3588  decode.d1.loss_mask: 1.3090  decode.d1.loss_dice: 1.0690  decode.d2.loss_cls: 0.4114  decode.d2.loss_mask: 1.2736  decode.d2.loss_dice: 1.0237  decode.d3.loss_cls: 0.3999  decode.d3.loss_mask: 1.2913  decode.d3.loss_dice: 1.0332  decode.d4.loss_cls: 0.4350  decode.d4.loss_mask: 1.3176  decode.d4.loss_dice: 1.0655  decode.d5.loss_cls: 0.3721  decode.d5.loss_mask: 1.2918  decode.d5.loss_dice: 1.0954  decode.d6.loss_cls: 0.4004  decode.d6.loss_mask: 1.3336  decode.d6.loss_dice: 1.0607  decode.d7.loss_cls: 0.3632  decode.d7.loss_mask: 1.3435  decode.d7.loss_dice: 1.0542  decode.d8.loss_cls: 0.4115  decode.d8.loss_mask: 1.2893  decode.d8.loss_dice: 1.0369
05/26 14:58:49 - mmengine - INFO - Iter(train) [ 34700/160000]  base_lr: 8.0251e-05 lr: 8.0251e-06  eta: 14:16:17  time: 0.4228  data_time: 0.0091  memory: 5969  grad_norm: 450.8935  loss: 26.0475  decode.loss_cls: 0.4063  decode.loss_mask: 1.1539  decode.loss_dice: 1.0124  decode.d0.loss_cls: 0.8571  decode.d0.loss_mask: 1.1178  decode.d0.loss_dice: 0.9425  decode.d1.loss_cls: 0.3420  decode.d1.loss_mask: 1.1750  decode.d1.loss_dice: 1.0062  decode.d2.loss_cls: 0.3645  decode.d2.loss_mask: 1.1829  decode.d2.loss_dice: 0.9846  decode.d3.loss_cls: 0.3965  decode.d3.loss_mask: 1.1939  decode.d3.loss_dice: 1.0010  decode.d4.loss_cls: 0.4126  decode.d4.loss_mask: 1.1612  decode.d4.loss_dice: 1.0091  decode.d5.loss_cls: 0.3776  decode.d5.loss_mask: 1.1935  decode.d5.loss_dice: 1.0259  decode.d6.loss_cls: 0.4313  decode.d6.loss_mask: 1.1317  decode.d6.loss_dice: 0.9924  decode.d7.loss_cls: 0.3913  decode.d7.loss_mask: 1.1522  decode.d7.loss_dice: 1.0351  decode.d8.loss_cls: 0.3634  decode.d8.loss_mask: 1.2026  decode.d8.loss_dice: 1.0309
05/26 14:59:10 - mmengine - INFO - Iter(train) [ 34750/160000]  base_lr: 8.0222e-05 lr: 8.0222e-06  eta: 14:15:57  time: 0.4129  data_time: 0.0091  memory: 5979  grad_norm: 1052.1644  loss: 24.1241  decode.loss_cls: 0.2222  decode.loss_mask: 1.1895  decode.loss_dice: 0.9281  decode.d0.loss_cls: 0.6793  decode.d0.loss_mask: 1.1131  decode.d0.loss_dice: 0.9246  decode.d1.loss_cls: 0.2769  decode.d1.loss_mask: 1.1475  decode.d1.loss_dice: 0.9410  decode.d2.loss_cls: 0.2280  decode.d2.loss_mask: 1.1418  decode.d2.loss_dice: 0.9523  decode.d3.loss_cls: 0.2637  decode.d3.loss_mask: 1.1383  decode.d3.loss_dice: 0.9520  decode.d4.loss_cls: 0.2977  decode.d4.loss_mask: 1.1794  decode.d4.loss_dice: 0.9938  decode.d5.loss_cls: 0.3165  decode.d5.loss_mask: 1.1755  decode.d5.loss_dice: 0.9757  decode.d6.loss_cls: 0.2914  decode.d6.loss_mask: 1.1592  decode.d6.loss_dice: 0.9438  decode.d7.loss_cls: 0.2729  decode.d7.loss_mask: 1.1306  decode.d7.loss_dice: 0.9062  decode.d8.loss_cls: 0.2620  decode.d8.loss_mask: 1.1641  decode.d8.loss_dice: 0.9569
05/26 14:59:31 - mmengine - INFO - Iter(train) [ 34800/160000]  base_lr: 8.0193e-05 lr: 8.0193e-06  eta: 14:15:38  time: 0.4179  data_time: 0.0096  memory: 5973  grad_norm: 513.7571  loss: 28.2015  decode.loss_cls: 0.4436  decode.loss_mask: 1.3203  decode.loss_dice: 1.0307  decode.d0.loss_cls: 0.9571  decode.d0.loss_mask: 1.2446  decode.d0.loss_dice: 0.9232  decode.d1.loss_cls: 0.5593  decode.d1.loss_mask: 1.2243  decode.d1.loss_dice: 0.9513  decode.d2.loss_cls: 0.4788  decode.d2.loss_mask: 1.3496  decode.d2.loss_dice: 1.0116  decode.d3.loss_cls: 0.5012  decode.d3.loss_mask: 1.2744  decode.d3.loss_dice: 0.9604  decode.d4.loss_cls: 0.5901  decode.d4.loss_mask: 1.2374  decode.d4.loss_dice: 0.9674  decode.d5.loss_cls: 0.5395  decode.d5.loss_mask: 1.2872  decode.d5.loss_dice: 1.0143  decode.d6.loss_cls: 0.5690  decode.d6.loss_mask: 1.2818  decode.d6.loss_dice: 0.9524  decode.d7.loss_cls: 0.6274  decode.d7.loss_mask: 1.2796  decode.d7.loss_dice: 0.9813  decode.d8.loss_cls: 0.4885  decode.d8.loss_mask: 1.2178  decode.d8.loss_dice: 0.9378
05/26 14:59:52 - mmengine - INFO - Iter(train) [ 34850/160000]  base_lr: 8.0165e-05 lr: 8.0165e-06  eta: 14:15:18  time: 0.4163  data_time: 0.0095  memory: 5980  grad_norm: 996.5229  loss: 23.0293  decode.loss_cls: 0.2712  decode.loss_mask: 1.1121  decode.loss_dice: 0.8104  decode.d0.loss_cls: 0.7181  decode.d0.loss_mask: 1.0955  decode.d0.loss_dice: 0.8481  decode.d1.loss_cls: 0.2880  decode.d1.loss_mask: 1.1376  decode.d1.loss_dice: 0.8265  decode.d2.loss_cls: 0.3261  decode.d2.loss_mask: 1.1146  decode.d2.loss_dice: 0.8261  decode.d3.loss_cls: 0.3027  decode.d3.loss_mask: 1.1197  decode.d3.loss_dice: 0.8351  decode.d4.loss_cls: 0.3758  decode.d4.loss_mask: 1.1163  decode.d4.loss_dice: 0.8489  decode.d5.loss_cls: 0.2897  decode.d5.loss_mask: 1.1341  decode.d5.loss_dice: 0.8306  decode.d6.loss_cls: 0.3238  decode.d6.loss_mask: 1.0989  decode.d6.loss_dice: 0.8623  decode.d7.loss_cls: 0.3219  decode.d7.loss_mask: 1.1417  decode.d7.loss_dice: 0.8592  decode.d8.loss_cls: 0.3266  decode.d8.loss_mask: 1.0726  decode.d8.loss_dice: 0.7951
05/26 15:00:13 - mmengine - INFO - Iter(train) [ 34900/160000]  base_lr: 8.0136e-05 lr: 8.0136e-06  eta: 14:14:59  time: 0.4186  data_time: 0.0095  memory: 5979  grad_norm: 366.5613  loss: 21.2045  decode.loss_cls: 0.2449  decode.loss_mask: 1.0254  decode.loss_dice: 0.8592  decode.d0.loss_cls: 0.7864  decode.d0.loss_mask: 0.9241  decode.d0.loss_dice: 0.7629  decode.d1.loss_cls: 0.2557  decode.d1.loss_mask: 0.9839  decode.d1.loss_dice: 0.8022  decode.d2.loss_cls: 0.2167  decode.d2.loss_mask: 1.0091  decode.d2.loss_dice: 0.8154  decode.d3.loss_cls: 0.2512  decode.d3.loss_mask: 1.0067  decode.d3.loss_dice: 0.8204  decode.d4.loss_cls: 0.2852  decode.d4.loss_mask: 1.0091  decode.d4.loss_dice: 0.8248  decode.d5.loss_cls: 0.2702  decode.d5.loss_mask: 1.0387  decode.d5.loss_dice: 0.8395  decode.d6.loss_cls: 0.2750  decode.d6.loss_mask: 0.9774  decode.d6.loss_dice: 0.8103  decode.d7.loss_cls: 0.2502  decode.d7.loss_mask: 0.9866  decode.d7.loss_dice: 0.8169  decode.d8.loss_cls: 0.2616  decode.d8.loss_mask: 0.9784  decode.d8.loss_dice: 0.8166
05/26 15:00:33 - mmengine - INFO - Iter(train) [ 34950/160000]  base_lr: 8.0107e-05 lr: 8.0107e-06  eta: 14:14:39  time: 0.4058  data_time: 0.0089  memory: 5968  grad_norm: 738.7542  loss: 24.9286  decode.loss_cls: 0.2299  decode.loss_mask: 1.3222  decode.loss_dice: 0.8454  decode.d0.loss_cls: 0.7938  decode.d0.loss_mask: 1.2367  decode.d0.loss_dice: 0.8340  decode.d1.loss_cls: 0.2894  decode.d1.loss_mask: 1.2312  decode.d1.loss_dice: 0.8543  decode.d2.loss_cls: 0.3335  decode.d2.loss_mask: 1.2376  decode.d2.loss_dice: 0.8361  decode.d3.loss_cls: 0.3823  decode.d3.loss_mask: 1.2848  decode.d3.loss_dice: 0.8598  decode.d4.loss_cls: 0.4140  decode.d4.loss_mask: 1.3118  decode.d4.loss_dice: 0.8566  decode.d5.loss_cls: 0.3000  decode.d5.loss_mask: 1.3012  decode.d5.loss_dice: 0.8623  decode.d6.loss_cls: 0.3096  decode.d6.loss_mask: 1.2807  decode.d6.loss_dice: 0.8526  decode.d7.loss_cls: 0.3032  decode.d7.loss_mask: 1.3333  decode.d7.loss_dice: 0.8504  decode.d8.loss_cls: 0.3113  decode.d8.loss_mask: 1.2548  decode.d8.loss_dice: 0.8159
05/26 15:00:54 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 15:00:54 - mmengine - INFO - Iter(train) [ 35000/160000]  base_lr: 8.0078e-05 lr: 8.0078e-06  eta: 14:14:18  time: 0.4055  data_time: 0.0089  memory: 5967  grad_norm: 502.5192  loss: 23.1506  decode.loss_cls: 0.2182  decode.loss_mask: 1.2188  decode.loss_dice: 0.8606  decode.d0.loss_cls: 0.7014  decode.d0.loss_mask: 1.1228  decode.d0.loss_dice: 0.7955  decode.d1.loss_cls: 0.2455  decode.d1.loss_mask: 1.1816  decode.d1.loss_dice: 0.8475  decode.d2.loss_cls: 0.2187  decode.d2.loss_mask: 1.2262  decode.d2.loss_dice: 0.8540  decode.d3.loss_cls: 0.1930  decode.d3.loss_mask: 1.2044  decode.d3.loss_dice: 0.8734  decode.d4.loss_cls: 0.2147  decode.d4.loss_mask: 1.1498  decode.d4.loss_dice: 0.8293  decode.d5.loss_cls: 0.2406  decode.d5.loss_mask: 1.1479  decode.d5.loss_dice: 0.8626  decode.d6.loss_cls: 0.2898  decode.d6.loss_mask: 1.1585  decode.d6.loss_dice: 0.8777  decode.d7.loss_cls: 0.2578  decode.d7.loss_mask: 1.2130  decode.d7.loss_dice: 0.8773  decode.d8.loss_cls: 0.2727  decode.d8.loss_mask: 1.1637  decode.d8.loss_dice: 0.8336
05/26 15:00:54 - mmengine - INFO - Saving checkpoint at 35000 iterations
05/26 15:00:58 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:08  time: 0.0480  data_time: 0.0012  memory: 1391  
05/26 15:01:00 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:04  time: 0.0476  data_time: 0.0012  memory: 1205  
05/26 15:01:03 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:02  time: 0.0503  data_time: 0.0012  memory: 1596  
05/26 15:01:05 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0485  data_time: 0.0012  memory: 1298  
05/26 15:01:07 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:57  time: 0.0480  data_time: 0.0012  memory: 1298  
05/26 15:01:10 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0501  data_time: 0.0012  memory: 1279  
05/26 15:01:12 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:53  time: 0.0508  data_time: 0.0012  memory: 1224  
05/26 15:01:15 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:51  time: 0.0516  data_time: 0.0012  memory: 1298  
05/26 15:01:18 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:49  time: 0.0509  data_time: 0.0012  memory: 1298  
05/26 15:01:20 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:46  time: 0.0530  data_time: 0.0013  memory: 1725  
05/26 15:01:23 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:44  time: 0.0510  data_time: 0.0012  memory: 1336  
05/26 15:01:25 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:42  time: 0.0513  data_time: 0.0013  memory: 1298  
05/26 15:01:28 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:39  time: 0.0517  data_time: 0.0013  memory: 1205  
05/26 15:01:30 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:37  time: 0.0520  data_time: 0.0012  memory: 1316  
05/26 15:01:33 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:34  time: 0.0514  data_time: 0.0013  memory: 1279  
05/26 15:01:36 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:32  time: 0.0538  data_time: 0.0012  memory: 1410  
05/26 15:01:38 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:30  time: 0.0503  data_time: 0.0012  memory: 1279  
05/26 15:01:41 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:27  time: 0.0575  data_time: 0.0014  memory: 1205  
05/26 15:01:44 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:25  time: 0.0584  data_time: 0.0014  memory: 1205  
05/26 15:01:46 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:22  time: 0.0497  data_time: 0.0013  memory: 1336  
05/26 15:01:49 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:20  time: 0.0499  data_time: 0.0012  memory: 1246  
05/26 15:01:51 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0519  data_time: 0.0013  memory: 1503  
05/26 15:01:54 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:15  time: 0.0501  data_time: 0.0012  memory: 1261  
05/26 15:01:56 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0505  data_time: 0.0012  memory: 1298  
05/26 15:01:59 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:10  time: 0.0501  data_time: 0.0013  memory: 1447  
05/26 15:02:01 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0502  data_time: 0.0013  memory: 1298  
05/26 15:02:04 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:05  time: 0.0513  data_time: 0.0013  memory: 1279  
05/26 15:02:06 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0498  data_time: 0.0013  memory: 1205  
05/26 15:02:09 - mmengine - INFO - per class results:
05/26 15:02:09 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 93.67 | 94.54 |
|  aeroplane  | 86.09 | 98.41 |
|   bicycle   | 37.73 | 97.68 |
|     bird    | 82.93 | 96.84 |
|     boat    | 58.64 |  85.0 |
|    bottle   | 79.48 | 91.72 |
|     bus     |  88.7 | 92.78 |
|     car     | 83.63 | 95.63 |
|     cat     |  90.1 | 94.41 |
|    chair    | 29.17 | 39.67 |
|     cow     |  7.34 |  7.35 |
| diningtable | 63.35 |  78.0 |
|     dog     | 85.01 | 94.29 |
|    horse    | 43.97 | 97.82 |
|  motorbike  |  81.9 | 91.77 |
|    person   | 86.67 | 93.72 |
| pottedplant | 52.96 | 94.13 |
|    sheep    |  81.7 | 91.47 |
|     sofa    |  44.2 | 92.05 |
|    train    | 82.85 | 96.48 |
|  tvmonitor  | 73.01 | 86.46 |
+-------------+-------+-------+
05/26 15:02:09 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 92.6500  mIoU: 68.2400  mAcc: 86.2000  data_time: 0.0013  time: 0.0507
05/26 15:02:30 - mmengine - INFO - Iter(train) [ 35050/160000]  base_lr: 8.0049e-05 lr: 8.0049e-06  eta: 14:13:58  time: 0.4159  data_time: 0.0096  memory: 5969  grad_norm: 977.5946  loss: 28.9500  decode.loss_cls: 0.3826  decode.loss_mask: 1.4485  decode.loss_dice: 1.0266  decode.d0.loss_cls: 0.8813  decode.d0.loss_mask: 1.4485  decode.d0.loss_dice: 1.0200  decode.d1.loss_cls: 0.3718  decode.d1.loss_mask: 1.4354  decode.d1.loss_dice: 0.9894  decode.d2.loss_cls: 0.4203  decode.d2.loss_mask: 1.4651  decode.d2.loss_dice: 0.9681  decode.d3.loss_cls: 0.4289  decode.d3.loss_mask: 1.4000  decode.d3.loss_dice: 0.9869  decode.d4.loss_cls: 0.4164  decode.d4.loss_mask: 1.4332  decode.d4.loss_dice: 0.9925  decode.d5.loss_cls: 0.4311  decode.d5.loss_mask: 1.4412  decode.d5.loss_dice: 1.0050  decode.d6.loss_cls: 0.3854  decode.d6.loss_mask: 1.4374  decode.d6.loss_dice: 1.0050  decode.d7.loss_cls: 0.4333  decode.d7.loss_mask: 1.4420  decode.d7.loss_dice: 0.9837  decode.d8.loss_cls: 0.4077  decode.d8.loss_mask: 1.4586  decode.d8.loss_dice: 1.0041
05/26 15:02:50 - mmengine - INFO - Iter(train) [ 35100/160000]  base_lr: 8.0020e-05 lr: 8.0020e-06  eta: 14:13:39  time: 0.4150  data_time: 0.0092  memory: 5991  grad_norm: 1069.3368  loss: 23.2167  decode.loss_cls: 0.2852  decode.loss_mask: 1.2604  decode.loss_dice: 0.7515  decode.d0.loss_cls: 0.7169  decode.d0.loss_mask: 1.0995  decode.d0.loss_dice: 0.7579  decode.d1.loss_cls: 0.2908  decode.d1.loss_mask: 1.1977  decode.d1.loss_dice: 0.7705  decode.d2.loss_cls: 0.2809  decode.d2.loss_mask: 1.2479  decode.d2.loss_dice: 0.7916  decode.d3.loss_cls: 0.2894  decode.d3.loss_mask: 1.2474  decode.d3.loss_dice: 0.7704  decode.d4.loss_cls: 0.3359  decode.d4.loss_mask: 1.2498  decode.d4.loss_dice: 0.7668  decode.d5.loss_cls: 0.3673  decode.d5.loss_mask: 1.1996  decode.d5.loss_dice: 0.7712  decode.d6.loss_cls: 0.3373  decode.d6.loss_mask: 1.1800  decode.d6.loss_dice: 0.7478  decode.d7.loss_cls: 0.2624  decode.d7.loss_mask: 1.2747  decode.d7.loss_dice: 0.7438  decode.d8.loss_cls: 0.2648  decode.d8.loss_mask: 1.2215  decode.d8.loss_dice: 0.7360
05/26 15:03:11 - mmengine - INFO - Iter(train) [ 35150/160000]  base_lr: 7.9992e-05 lr: 7.9992e-06  eta: 14:13:19  time: 0.4136  data_time: 0.0093  memory: 5969  grad_norm: 569.0542  loss: 21.7467  decode.loss_cls: 0.2245  decode.loss_mask: 1.1116  decode.loss_dice: 0.7471  decode.d0.loss_cls: 0.7226  decode.d0.loss_mask: 1.1135  decode.d0.loss_dice: 0.7754  decode.d1.loss_cls: 0.2002  decode.d1.loss_mask: 1.1458  decode.d1.loss_dice: 0.7625  decode.d2.loss_cls: 0.2480  decode.d2.loss_mask: 1.1358  decode.d2.loss_dice: 0.7892  decode.d3.loss_cls: 0.2260  decode.d3.loss_mask: 1.1621  decode.d3.loss_dice: 0.7951  decode.d4.loss_cls: 0.2152  decode.d4.loss_mask: 1.1273  decode.d4.loss_dice: 0.7547  decode.d5.loss_cls: 0.2314  decode.d5.loss_mask: 1.1279  decode.d5.loss_dice: 0.8021  decode.d6.loss_cls: 0.2582  decode.d6.loss_mask: 1.1517  decode.d6.loss_dice: 0.7697  decode.d7.loss_cls: 0.1977  decode.d7.loss_mask: 1.1223  decode.d7.loss_dice: 0.7652  decode.d8.loss_cls: 0.1850  decode.d8.loss_mask: 1.1221  decode.d8.loss_dice: 0.7570
05/26 15:03:32 - mmengine - INFO - Iter(train) [ 35200/160000]  base_lr: 7.9963e-05 lr: 7.9963e-06  eta: 14:12:59  time: 0.4136  data_time: 0.0093  memory: 5967  grad_norm: 723.3043  loss: 21.8056  decode.loss_cls: 0.1982  decode.loss_mask: 1.0673  decode.loss_dice: 0.8623  decode.d0.loss_cls: 0.6828  decode.d0.loss_mask: 1.0474  decode.d0.loss_dice: 0.8108  decode.d1.loss_cls: 0.1600  decode.d1.loss_mask: 1.1067  decode.d1.loss_dice: 0.8607  decode.d2.loss_cls: 0.1791  decode.d2.loss_mask: 1.0872  decode.d2.loss_dice: 0.8626  decode.d3.loss_cls: 0.1916  decode.d3.loss_mask: 1.0816  decode.d3.loss_dice: 0.8479  decode.d4.loss_cls: 0.2051  decode.d4.loss_mask: 1.1130  decode.d4.loss_dice: 0.8572  decode.d5.loss_cls: 0.2184  decode.d5.loss_mask: 1.1051  decode.d5.loss_dice: 0.8686  decode.d6.loss_cls: 0.1984  decode.d6.loss_mask: 1.0833  decode.d6.loss_dice: 0.8723  decode.d7.loss_cls: 0.1971  decode.d7.loss_mask: 1.0685  decode.d7.loss_dice: 0.8205  decode.d8.loss_cls: 0.2305  decode.d8.loss_mask: 1.0659  decode.d8.loss_dice: 0.8554
05/26 15:03:53 - mmengine - INFO - Iter(train) [ 35250/160000]  base_lr: 7.9934e-05 lr: 7.9934e-06  eta: 14:12:39  time: 0.4158  data_time: 0.0093  memory: 5979  grad_norm: 661.1702  loss: 29.4683  decode.loss_cls: 0.3233  decode.loss_mask: 1.4442  decode.loss_dice: 1.0933  decode.d0.loss_cls: 0.8760  decode.d0.loss_mask: 1.3693  decode.d0.loss_dice: 1.0068  decode.d1.loss_cls: 0.4079  decode.d1.loss_mask: 1.4317  decode.d1.loss_dice: 1.0257  decode.d2.loss_cls: 0.3470  decode.d2.loss_mask: 1.4913  decode.d2.loss_dice: 1.0488  decode.d3.loss_cls: 0.3530  decode.d3.loss_mask: 1.4798  decode.d3.loss_dice: 1.0560  decode.d4.loss_cls: 0.3671  decode.d4.loss_mask: 1.4940  decode.d4.loss_dice: 1.0538  decode.d5.loss_cls: 0.4317  decode.d5.loss_mask: 1.4682  decode.d5.loss_dice: 1.0611  decode.d6.loss_cls: 0.3971  decode.d6.loss_mask: 1.4667  decode.d6.loss_dice: 1.0980  decode.d7.loss_cls: 0.4167  decode.d7.loss_mask: 1.4760  decode.d7.loss_dice: 1.0623  decode.d8.loss_cls: 0.3910  decode.d8.loss_mask: 1.4646  decode.d8.loss_dice: 1.0659
05/26 15:04:13 - mmengine - INFO - Iter(train) [ 35300/160000]  base_lr: 7.9905e-05 lr: 7.9905e-06  eta: 14:12:20  time: 0.4164  data_time: 0.0092  memory: 5969  grad_norm: 832.7976  loss: 29.9104  decode.loss_cls: 0.3359  decode.loss_mask: 1.6599  decode.loss_dice: 0.9975  decode.d0.loss_cls: 0.8339  decode.d0.loss_mask: 1.5570  decode.d0.loss_dice: 0.9626  decode.d1.loss_cls: 0.4103  decode.d1.loss_mask: 1.5653  decode.d1.loss_dice: 0.9358  decode.d2.loss_cls: 0.3642  decode.d2.loss_mask: 1.5863  decode.d2.loss_dice: 0.9292  decode.d3.loss_cls: 0.4047  decode.d3.loss_mask: 1.5902  decode.d3.loss_dice: 1.0047  decode.d4.loss_cls: 0.4342  decode.d4.loss_mask: 1.5811  decode.d4.loss_dice: 1.0018  decode.d5.loss_cls: 0.4346  decode.d5.loss_mask: 1.5412  decode.d5.loss_dice: 0.9459  decode.d6.loss_cls: 0.3775  decode.d6.loss_mask: 1.5714  decode.d6.loss_dice: 0.9850  decode.d7.loss_cls: 0.4297  decode.d7.loss_mask: 1.5716  decode.d7.loss_dice: 0.9720  decode.d8.loss_cls: 0.3960  decode.d8.loss_mask: 1.5565  decode.d8.loss_dice: 0.9743
05/26 15:04:34 - mmengine - INFO - Iter(train) [ 35350/160000]  base_lr: 7.9876e-05 lr: 7.9876e-06  eta: 14:12:00  time: 0.4055  data_time: 0.0089  memory: 5980  grad_norm: 936.9055  loss: 29.1351  decode.loss_cls: 0.3431  decode.loss_mask: 1.4723  decode.loss_dice: 1.0297  decode.d0.loss_cls: 0.8066  decode.d0.loss_mask: 1.3957  decode.d0.loss_dice: 1.0360  decode.d1.loss_cls: 0.3589  decode.d1.loss_mask: 1.4552  decode.d1.loss_dice: 1.0480  decode.d2.loss_cls: 0.3442  decode.d2.loss_mask: 1.4883  decode.d2.loss_dice: 1.0686  decode.d3.loss_cls: 0.3367  decode.d3.loss_mask: 1.4644  decode.d3.loss_dice: 1.0941  decode.d4.loss_cls: 0.3450  decode.d4.loss_mask: 1.4711  decode.d4.loss_dice: 1.0509  decode.d5.loss_cls: 0.3081  decode.d5.loss_mask: 1.5109  decode.d5.loss_dice: 1.0788  decode.d6.loss_cls: 0.3598  decode.d6.loss_mask: 1.4806  decode.d6.loss_dice: 1.0467  decode.d7.loss_cls: 0.3237  decode.d7.loss_mask: 1.5000  decode.d7.loss_dice: 1.0627  decode.d8.loss_cls: 0.3501  decode.d8.loss_mask: 1.4576  decode.d8.loss_dice: 1.0472
05/26 15:04:54 - mmengine - INFO - Iter(train) [ 35400/160000]  base_lr: 7.9847e-05 lr: 7.9847e-06  eta: 14:11:39  time: 0.4053  data_time: 0.0089  memory: 5976  grad_norm: 473.2802  loss: 19.0407  decode.loss_cls: 0.1556  decode.loss_mask: 0.9722  decode.loss_dice: 0.7033  decode.d0.loss_cls: 0.5774  decode.d0.loss_mask: 0.9776  decode.d0.loss_dice: 0.6710  decode.d1.loss_cls: 0.1872  decode.d1.loss_mask: 0.9697  decode.d1.loss_dice: 0.7007  decode.d2.loss_cls: 0.1720  decode.d2.loss_mask: 0.9677  decode.d2.loss_dice: 0.6948  decode.d3.loss_cls: 0.1861  decode.d3.loss_mask: 0.9603  decode.d3.loss_dice: 0.7095  decode.d4.loss_cls: 0.2238  decode.d4.loss_mask: 0.9705  decode.d4.loss_dice: 0.7013  decode.d5.loss_cls: 0.2225  decode.d5.loss_mask: 0.9845  decode.d5.loss_dice: 0.7078  decode.d6.loss_cls: 0.2155  decode.d6.loss_mask: 0.9788  decode.d6.loss_dice: 0.6967  decode.d7.loss_cls: 0.1863  decode.d7.loss_mask: 0.9641  decode.d7.loss_dice: 0.7067  decode.d8.loss_cls: 0.1859  decode.d8.loss_mask: 0.9697  decode.d8.loss_dice: 0.7216
05/26 15:05:15 - mmengine - INFO - Iter(train) [ 35450/160000]  base_lr: 7.9819e-05 lr: 7.9819e-06  eta: 14:11:18  time: 0.4153  data_time: 0.0092  memory: 5980  grad_norm: 342.2363  loss: 21.7098  decode.loss_cls: 0.3215  decode.loss_mask: 0.9892  decode.loss_dice: 0.8046  decode.d0.loss_cls: 0.7928  decode.d0.loss_mask: 0.9743  decode.d0.loss_dice: 0.7826  decode.d1.loss_cls: 0.2902  decode.d1.loss_mask: 0.9918  decode.d1.loss_dice: 0.8293  decode.d2.loss_cls: 0.2753  decode.d2.loss_mask: 1.0054  decode.d2.loss_dice: 0.8306  decode.d3.loss_cls: 0.3268  decode.d3.loss_mask: 1.0091  decode.d3.loss_dice: 0.8360  decode.d4.loss_cls: 0.3505  decode.d4.loss_mask: 1.0168  decode.d4.loss_dice: 0.8068  decode.d5.loss_cls: 0.3435  decode.d5.loss_mask: 1.0060  decode.d5.loss_dice: 0.8301  decode.d6.loss_cls: 0.3198  decode.d6.loss_mask: 0.9809  decode.d6.loss_dice: 0.8085  decode.d7.loss_cls: 0.3163  decode.d7.loss_mask: 0.9812  decode.d7.loss_dice: 0.8147  decode.d8.loss_cls: 0.3232  decode.d8.loss_mask: 0.9711  decode.d8.loss_dice: 0.7809
05/26 15:05:36 - mmengine - INFO - Iter(train) [ 35500/160000]  base_lr: 7.9790e-05 lr: 7.9790e-06  eta: 14:10:58  time: 0.4157  data_time: 0.0093  memory: 5969  grad_norm: 560.0258  loss: 22.5318  decode.loss_cls: 0.1833  decode.loss_mask: 1.1831  decode.loss_dice: 0.9019  decode.d0.loss_cls: 0.7222  decode.d0.loss_mask: 1.0937  decode.d0.loss_dice: 0.7930  decode.d1.loss_cls: 0.2010  decode.d1.loss_mask: 1.1348  decode.d1.loss_dice: 0.8422  decode.d2.loss_cls: 0.2132  decode.d2.loss_mask: 1.1550  decode.d2.loss_dice: 0.8808  decode.d3.loss_cls: 0.2073  decode.d3.loss_mask: 1.1305  decode.d3.loss_dice: 0.8387  decode.d4.loss_cls: 0.2476  decode.d4.loss_mask: 1.1152  decode.d4.loss_dice: 0.8558  decode.d5.loss_cls: 0.2305  decode.d5.loss_mask: 1.1240  decode.d5.loss_dice: 0.8474  decode.d6.loss_cls: 0.2077  decode.d6.loss_mask: 1.1677  decode.d6.loss_dice: 0.8651  decode.d7.loss_cls: 0.2777  decode.d7.loss_mask: 1.1137  decode.d7.loss_dice: 0.8351  decode.d8.loss_cls: 0.1867  decode.d8.loss_mask: 1.1211  decode.d8.loss_dice: 0.8558
05/26 15:05:56 - mmengine - INFO - Iter(train) [ 35550/160000]  base_lr: 7.9761e-05 lr: 7.9761e-06  eta: 14:10:39  time: 0.4146  data_time: 0.0093  memory: 5967  grad_norm: 693.1485  loss: 25.8282  decode.loss_cls: 0.3531  decode.loss_mask: 1.3425  decode.loss_dice: 0.9246  decode.d0.loss_cls: 0.7562  decode.d0.loss_mask: 1.1832  decode.d0.loss_dice: 0.8613  decode.d1.loss_cls: 0.4084  decode.d1.loss_mask: 1.2024  decode.d1.loss_dice: 0.8799  decode.d2.loss_cls: 0.3461  decode.d2.loss_mask: 1.3083  decode.d2.loss_dice: 0.9124  decode.d3.loss_cls: 0.3045  decode.d3.loss_mask: 1.3199  decode.d3.loss_dice: 0.9214  decode.d4.loss_cls: 0.3449  decode.d4.loss_mask: 1.3485  decode.d4.loss_dice: 0.8627  decode.d5.loss_cls: 0.3076  decode.d5.loss_mask: 1.3645  decode.d5.loss_dice: 0.9120  decode.d6.loss_cls: 0.3386  decode.d6.loss_mask: 1.3458  decode.d6.loss_dice: 0.9579  decode.d7.loss_cls: 0.3266  decode.d7.loss_mask: 1.3372  decode.d7.loss_dice: 0.8769  decode.d8.loss_cls: 0.3526  decode.d8.loss_mask: 1.2681  decode.d8.loss_dice: 0.8603
05/26 15:06:17 - mmengine - INFO - Iter(train) [ 35600/160000]  base_lr: 7.9732e-05 lr: 7.9732e-06  eta: 14:10:20  time: 0.4144  data_time: 0.0093  memory: 5980  grad_norm: 551.7620  loss: 21.7758  decode.loss_cls: 0.2654  decode.loss_mask: 1.0373  decode.loss_dice: 0.7501  decode.d0.loss_cls: 0.6591  decode.d0.loss_mask: 1.0746  decode.d0.loss_dice: 0.7446  decode.d1.loss_cls: 0.2041  decode.d1.loss_mask: 1.0966  decode.d1.loss_dice: 0.8844  decode.d2.loss_cls: 0.2219  decode.d2.loss_mask: 1.1256  decode.d2.loss_dice: 0.7909  decode.d3.loss_cls: 0.2429  decode.d3.loss_mask: 1.1072  decode.d3.loss_dice: 0.7566  decode.d4.loss_cls: 0.2345  decode.d4.loss_mask: 1.1454  decode.d4.loss_dice: 0.7989  decode.d5.loss_cls: 0.2818  decode.d5.loss_mask: 1.1042  decode.d5.loss_dice: 0.8096  decode.d6.loss_cls: 0.2660  decode.d6.loss_mask: 1.1191  decode.d6.loss_dice: 0.8038  decode.d7.loss_cls: 0.2445  decode.d7.loss_mask: 1.0786  decode.d7.loss_dice: 0.7874  decode.d8.loss_cls: 0.2383  decode.d8.loss_mask: 1.1058  decode.d8.loss_dice: 0.7965
05/26 15:06:38 - mmengine - INFO - Iter(train) [ 35650/160000]  base_lr: 7.9703e-05 lr: 7.9703e-06  eta: 14:10:00  time: 0.4158  data_time: 0.0102  memory: 5967  grad_norm: 1505.3929  loss: 29.5966  decode.loss_cls: 0.4429  decode.loss_mask: 1.4138  decode.loss_dice: 1.0845  decode.d0.loss_cls: 0.9107  decode.d0.loss_mask: 1.3523  decode.d0.loss_dice: 1.0447  decode.d1.loss_cls: 0.4051  decode.d1.loss_mask: 1.4125  decode.d1.loss_dice: 1.1121  decode.d2.loss_cls: 0.4214  decode.d2.loss_mask: 1.4001  decode.d2.loss_dice: 1.0332  decode.d3.loss_cls: 0.4689  decode.d3.loss_mask: 1.4029  decode.d3.loss_dice: 1.0730  decode.d4.loss_cls: 0.5134  decode.d4.loss_mask: 1.3730  decode.d4.loss_dice: 1.0023  decode.d5.loss_cls: 0.4710  decode.d5.loss_mask: 1.3849  decode.d5.loss_dice: 1.0675  decode.d6.loss_cls: 0.4220  decode.d6.loss_mask: 1.4369  decode.d6.loss_dice: 1.0696  decode.d7.loss_cls: 0.4801  decode.d7.loss_mask: 1.4100  decode.d7.loss_dice: 1.0291  decode.d8.loss_cls: 0.4214  decode.d8.loss_mask: 1.4495  decode.d8.loss_dice: 1.0875
05/26 15:06:59 - mmengine - INFO - Iter(train) [ 35700/160000]  base_lr: 7.9674e-05 lr: 7.9674e-06  eta: 14:09:40  time: 0.4147  data_time: 0.0093  memory: 5966  grad_norm: 549.4450  loss: 25.8096  decode.loss_cls: 0.2622  decode.loss_mask: 1.3362  decode.loss_dice: 0.9180  decode.d0.loss_cls: 0.7911  decode.d0.loss_mask: 1.2414  decode.d0.loss_dice: 0.8430  decode.d1.loss_cls: 0.2928  decode.d1.loss_mask: 1.3209  decode.d1.loss_dice: 0.9256  decode.d2.loss_cls: 0.2651  decode.d2.loss_mask: 1.3621  decode.d2.loss_dice: 0.9640  decode.d3.loss_cls: 0.2586  decode.d3.loss_mask: 1.3299  decode.d3.loss_dice: 0.9351  decode.d4.loss_cls: 0.2665  decode.d4.loss_mask: 1.3495  decode.d4.loss_dice: 0.9654  decode.d5.loss_cls: 0.3332  decode.d5.loss_mask: 1.3177  decode.d5.loss_dice: 0.9256  decode.d6.loss_cls: 0.2925  decode.d6.loss_mask: 1.3425  decode.d6.loss_dice: 0.9486  decode.d7.loss_cls: 0.2696  decode.d7.loss_mask: 1.3481  decode.d7.loss_dice: 0.9292  decode.d8.loss_cls: 0.2605  decode.d8.loss_mask: 1.3030  decode.d8.loss_dice: 0.9118
05/26 15:07:19 - mmengine - INFO - Iter(train) [ 35750/160000]  base_lr: 7.9645e-05 lr: 7.9645e-06  eta: 14:09:20  time: 0.4132  data_time: 0.0092  memory: 5967  grad_norm: 465.6143  loss: 20.8849  decode.loss_cls: 0.2027  decode.loss_mask: 0.9999  decode.loss_dice: 0.8004  decode.d0.loss_cls: 0.6233  decode.d0.loss_mask: 0.9792  decode.d0.loss_dice: 0.7889  decode.d1.loss_cls: 0.2343  decode.d1.loss_mask: 1.0447  decode.d1.loss_dice: 0.8107  decode.d2.loss_cls: 0.2905  decode.d2.loss_mask: 0.9724  decode.d2.loss_dice: 0.7703  decode.d3.loss_cls: 0.2042  decode.d3.loss_mask: 1.0316  decode.d3.loss_dice: 0.7965  decode.d4.loss_cls: 0.1943  decode.d4.loss_mask: 1.0349  decode.d4.loss_dice: 0.8278  decode.d5.loss_cls: 0.2651  decode.d5.loss_mask: 1.0166  decode.d5.loss_dice: 0.8128  decode.d6.loss_cls: 0.2059  decode.d6.loss_mask: 1.0076  decode.d6.loss_dice: 0.8064  decode.d7.loss_cls: 0.2500  decode.d7.loss_mask: 1.0643  decode.d7.loss_dice: 0.7929  decode.d8.loss_cls: 0.2681  decode.d8.loss_mask: 0.9911  decode.d8.loss_dice: 0.7977
05/26 15:07:40 - mmengine - INFO - Iter(train) [ 35800/160000]  base_lr: 7.9617e-05 lr: 7.9617e-06  eta: 14:09:00  time: 0.4160  data_time: 0.0095  memory: 5972  grad_norm: 941.9506  loss: 21.1389  decode.loss_cls: 0.2493  decode.loss_mask: 1.0740  decode.loss_dice: 0.7112  decode.d0.loss_cls: 0.6870  decode.d0.loss_mask: 1.0863  decode.d0.loss_dice: 0.7427  decode.d1.loss_cls: 0.2259  decode.d1.loss_mask: 1.1521  decode.d1.loss_dice: 0.7397  decode.d2.loss_cls: 0.2893  decode.d2.loss_mask: 1.0771  decode.d2.loss_dice: 0.7332  decode.d3.loss_cls: 0.2538  decode.d3.loss_mask: 1.0805  decode.d3.loss_dice: 0.7315  decode.d4.loss_cls: 0.2548  decode.d4.loss_mask: 1.0658  decode.d4.loss_dice: 0.7179  decode.d5.loss_cls: 0.3074  decode.d5.loss_mask: 1.0260  decode.d5.loss_dice: 0.7067  decode.d6.loss_cls: 0.2653  decode.d6.loss_mask: 1.0625  decode.d6.loss_dice: 0.7318  decode.d7.loss_cls: 0.2538  decode.d7.loss_mask: 1.0908  decode.d7.loss_dice: 0.7243  decode.d8.loss_cls: 0.2769  decode.d8.loss_mask: 1.1043  decode.d8.loss_dice: 0.7170
05/26 15:08:01 - mmengine - INFO - Iter(train) [ 35850/160000]  base_lr: 7.9588e-05 lr: 7.9588e-06  eta: 14:08:41  time: 0.4167  data_time: 0.0093  memory: 5976  grad_norm: 467.7458  loss: 25.9935  decode.loss_cls: 0.3551  decode.loss_mask: 1.2674  decode.loss_dice: 0.8764  decode.d0.loss_cls: 0.8209  decode.d0.loss_mask: 1.2222  decode.d0.loss_dice: 0.8337  decode.d1.loss_cls: 0.2730  decode.d1.loss_mask: 1.4001  decode.d1.loss_dice: 1.0152  decode.d2.loss_cls: 0.3229  decode.d2.loss_mask: 1.3114  decode.d2.loss_dice: 0.9230  decode.d3.loss_cls: 0.3626  decode.d3.loss_mask: 1.2760  decode.d3.loss_dice: 0.9178  decode.d4.loss_cls: 0.3873  decode.d4.loss_mask: 1.2734  decode.d4.loss_dice: 0.8893  decode.d5.loss_cls: 0.3177  decode.d5.loss_mask: 1.2721  decode.d5.loss_dice: 0.8953  decode.d6.loss_cls: 0.3730  decode.d6.loss_mask: 1.3167  decode.d6.loss_dice: 0.9367  decode.d7.loss_cls: 0.4191  decode.d7.loss_mask: 1.2945  decode.d7.loss_dice: 0.8846  decode.d8.loss_cls: 0.3290  decode.d8.loss_mask: 1.3112  decode.d8.loss_dice: 0.9159
05/26 15:08:22 - mmengine - INFO - Iter(train) [ 35900/160000]  base_lr: 7.9559e-05 lr: 7.9559e-06  eta: 14:08:21  time: 0.4150  data_time: 0.0093  memory: 5994  grad_norm: 528.7887  loss: 23.6747  decode.loss_cls: 0.1967  decode.loss_mask: 1.2214  decode.loss_dice: 0.8387  decode.d0.loss_cls: 0.7449  decode.d0.loss_mask: 1.2509  decode.d0.loss_dice: 0.8520  decode.d1.loss_cls: 0.1817  decode.d1.loss_mask: 1.2472  decode.d1.loss_dice: 0.8509  decode.d2.loss_cls: 0.1935  decode.d2.loss_mask: 1.2623  decode.d2.loss_dice: 0.9061  decode.d3.loss_cls: 0.2227  decode.d3.loss_mask: 1.2688  decode.d3.loss_dice: 0.8946  decode.d4.loss_cls: 0.1917  decode.d4.loss_mask: 1.2581  decode.d4.loss_dice: 0.8974  decode.d5.loss_cls: 0.2274  decode.d5.loss_mask: 1.2265  decode.d5.loss_dice: 0.8654  decode.d6.loss_cls: 0.2013  decode.d6.loss_mask: 1.2328  decode.d6.loss_dice: 0.8730  decode.d7.loss_cls: 0.1813  decode.d7.loss_mask: 1.2302  decode.d7.loss_dice: 0.8570  decode.d8.loss_cls: 0.1746  decode.d8.loss_mask: 1.2459  decode.d8.loss_dice: 0.8793
05/26 15:08:42 - mmengine - INFO - Iter(train) [ 35950/160000]  base_lr: 7.9530e-05 lr: 7.9530e-06  eta: 14:08:00  time: 0.4057  data_time: 0.0089  memory: 5978  grad_norm: 709.9125  loss: 25.6677  decode.loss_cls: 0.4202  decode.loss_mask: 1.2171  decode.loss_dice: 0.8863  decode.d0.loss_cls: 0.9765  decode.d0.loss_mask: 1.1296  decode.d0.loss_dice: 0.8416  decode.d1.loss_cls: 0.3958  decode.d1.loss_mask: 1.2287  decode.d1.loss_dice: 0.9071  decode.d2.loss_cls: 0.4157  decode.d2.loss_mask: 1.2228  decode.d2.loss_dice: 0.9028  decode.d3.loss_cls: 0.4699  decode.d3.loss_mask: 1.1512  decode.d3.loss_dice: 0.8720  decode.d4.loss_cls: 0.5529  decode.d4.loss_mask: 1.1698  decode.d4.loss_dice: 0.8546  decode.d5.loss_cls: 0.4894  decode.d5.loss_mask: 1.1500  decode.d5.loss_dice: 0.8376  decode.d6.loss_cls: 0.4621  decode.d6.loss_mask: 1.2256  decode.d6.loss_dice: 0.8949  decode.d7.loss_cls: 0.4409  decode.d7.loss_mask: 1.1620  decode.d7.loss_dice: 0.8408  decode.d8.loss_cls: 0.4322  decode.d8.loss_mask: 1.2057  decode.d8.loss_dice: 0.9118
05/26 15:09:02 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 15:09:02 - mmengine - INFO - Iter(train) [ 36000/160000]  base_lr: 7.9501e-05 lr: 7.9501e-06  eta: 14:07:39  time: 0.4057  data_time: 0.0090  memory: 5968  grad_norm: 715.7639  loss: 22.6187  decode.loss_cls: 0.3022  decode.loss_mask: 1.1628  decode.loss_dice: 0.8298  decode.d0.loss_cls: 0.7243  decode.d0.loss_mask: 1.0011  decode.d0.loss_dice: 0.7477  decode.d1.loss_cls: 0.2919  decode.d1.loss_mask: 1.0534  decode.d1.loss_dice: 0.8426  decode.d2.loss_cls: 0.2831  decode.d2.loss_mask: 1.0921  decode.d2.loss_dice: 0.8579  decode.d3.loss_cls: 0.2691  decode.d3.loss_mask: 1.1320  decode.d3.loss_dice: 0.8768  decode.d4.loss_cls: 0.3019  decode.d4.loss_mask: 1.1237  decode.d4.loss_dice: 0.8130  decode.d5.loss_cls: 0.3338  decode.d5.loss_mask: 1.0494  decode.d5.loss_dice: 0.8352  decode.d6.loss_cls: 0.3468  decode.d6.loss_mask: 1.0774  decode.d6.loss_dice: 0.8416  decode.d7.loss_cls: 0.3513  decode.d7.loss_mask: 1.1035  decode.d7.loss_dice: 0.7994  decode.d8.loss_cls: 0.3516  decode.d8.loss_mask: 1.0241  decode.d8.loss_dice: 0.7991
05/26 15:09:23 - mmengine - INFO - Iter(train) [ 36050/160000]  base_lr: 7.9472e-05 lr: 7.9472e-06  eta: 14:07:19  time: 0.4145  data_time: 0.0092  memory: 5980  grad_norm: 695.6353  loss: 28.5785  decode.loss_cls: 0.2924  decode.loss_mask: 1.4864  decode.loss_dice: 1.0312  decode.d0.loss_cls: 0.9128  decode.d0.loss_mask: 1.3498  decode.d0.loss_dice: 1.0357  decode.d1.loss_cls: 0.2934  decode.d1.loss_mask: 1.4555  decode.d1.loss_dice: 1.0592  decode.d2.loss_cls: 0.2717  decode.d2.loss_mask: 1.4888  decode.d2.loss_dice: 1.0725  decode.d3.loss_cls: 0.2858  decode.d3.loss_mask: 1.4771  decode.d3.loss_dice: 1.0296  decode.d4.loss_cls: 0.3230  decode.d4.loss_mask: 1.4243  decode.d4.loss_dice: 1.0260  decode.d5.loss_cls: 0.2761  decode.d5.loss_mask: 1.5177  decode.d5.loss_dice: 1.0280  decode.d6.loss_cls: 0.2734  decode.d6.loss_mask: 1.4852  decode.d6.loss_dice: 1.0609  decode.d7.loss_cls: 0.3084  decode.d7.loss_mask: 1.4474  decode.d7.loss_dice: 1.0683  decode.d8.loss_cls: 0.3023  decode.d8.loss_mask: 1.4787  decode.d8.loss_dice: 1.0169
05/26 15:09:44 - mmengine - INFO - Iter(train) [ 36100/160000]  base_lr: 7.9444e-05 lr: 7.9444e-06  eta: 14:07:00  time: 0.4384  data_time: 0.0098  memory: 5966  grad_norm: 687.9164  loss: 24.0319  decode.loss_cls: 0.2787  decode.loss_mask: 1.1668  decode.loss_dice: 0.8694  decode.d0.loss_cls: 0.8223  decode.d0.loss_mask: 1.1160  decode.d0.loss_dice: 0.8345  decode.d1.loss_cls: 0.2962  decode.d1.loss_mask: 1.2079  decode.d1.loss_dice: 0.8885  decode.d2.loss_cls: 0.2860  decode.d2.loss_mask: 1.2520  decode.d2.loss_dice: 0.8839  decode.d3.loss_cls: 0.3316  decode.d3.loss_mask: 1.1763  decode.d3.loss_dice: 0.8728  decode.d4.loss_cls: 0.2843  decode.d4.loss_mask: 1.1943  decode.d4.loss_dice: 0.8626  decode.d5.loss_cls: 0.2947  decode.d5.loss_mask: 1.2466  decode.d5.loss_dice: 0.8625  decode.d6.loss_cls: 0.2816  decode.d6.loss_mask: 1.1858  decode.d6.loss_dice: 0.8496  decode.d7.loss_cls: 0.2899  decode.d7.loss_mask: 1.1765  decode.d7.loss_dice: 0.8798  decode.d8.loss_cls: 0.3006  decode.d8.loss_mask: 1.1785  decode.d8.loss_dice: 0.8616
05/26 15:10:05 - mmengine - INFO - Iter(train) [ 36150/160000]  base_lr: 7.9415e-05 lr: 7.9415e-06  eta: 14:06:40  time: 0.4079  data_time: 0.0091  memory: 5968  grad_norm: 350.6675  loss: 23.8629  decode.loss_cls: 0.3301  decode.loss_mask: 1.1270  decode.loss_dice: 0.9189  decode.d0.loss_cls: 0.7588  decode.d0.loss_mask: 1.0367  decode.d0.loss_dice: 0.8804  decode.d1.loss_cls: 0.2973  decode.d1.loss_mask: 1.1453  decode.d1.loss_dice: 0.9275  decode.d2.loss_cls: 0.3082  decode.d2.loss_mask: 1.0888  decode.d2.loss_dice: 0.9064  decode.d3.loss_cls: 0.3169  decode.d3.loss_mask: 1.0985  decode.d3.loss_dice: 0.8984  decode.d4.loss_cls: 0.3569  decode.d4.loss_mask: 1.0755  decode.d4.loss_dice: 0.8668  decode.d5.loss_cls: 0.2998  decode.d5.loss_mask: 1.1898  decode.d5.loss_dice: 0.9210  decode.d6.loss_cls: 0.3467  decode.d6.loss_mask: 1.1163  decode.d6.loss_dice: 0.9296  decode.d7.loss_cls: 0.3363  decode.d7.loss_mask: 1.1317  decode.d7.loss_dice: 0.9452  decode.d8.loss_cls: 0.3227  decode.d8.loss_mask: 1.0790  decode.d8.loss_dice: 0.9063
05/26 15:10:25 - mmengine - INFO - Iter(train) [ 36200/160000]  base_lr: 7.9386e-05 lr: 7.9386e-06  eta: 14:06:19  time: 0.4076  data_time: 0.0091  memory: 5984  grad_norm: 1060.2012  loss: 25.5738  decode.loss_cls: 0.3565  decode.loss_mask: 1.2745  decode.loss_dice: 0.9144  decode.d0.loss_cls: 0.7732  decode.d0.loss_mask: 1.1916  decode.d0.loss_dice: 0.8512  decode.d1.loss_cls: 0.3541  decode.d1.loss_mask: 1.2524  decode.d1.loss_dice: 0.9116  decode.d2.loss_cls: 0.2872  decode.d2.loss_mask: 1.3133  decode.d2.loss_dice: 0.9110  decode.d3.loss_cls: 0.3117  decode.d3.loss_mask: 1.2763  decode.d3.loss_dice: 0.9133  decode.d4.loss_cls: 0.3279  decode.d4.loss_mask: 1.3053  decode.d4.loss_dice: 0.9113  decode.d5.loss_cls: 0.3283  decode.d5.loss_mask: 1.3162  decode.d5.loss_dice: 0.9007  decode.d6.loss_cls: 0.3602  decode.d6.loss_mask: 1.2829  decode.d6.loss_dice: 0.9119  decode.d7.loss_cls: 0.3659  decode.d7.loss_mask: 1.2843  decode.d7.loss_dice: 0.8995  decode.d8.loss_cls: 0.3527  decode.d8.loss_mask: 1.2503  decode.d8.loss_dice: 0.8841
05/26 15:10:45 - mmengine - INFO - Iter(train) [ 36250/160000]  base_lr: 7.9357e-05 lr: 7.9357e-06  eta: 14:05:58  time: 0.4074  data_time: 0.0090  memory: 5966  grad_norm: 760.7134  loss: 26.1015  decode.loss_cls: 0.2797  decode.loss_mask: 1.3490  decode.loss_dice: 0.8866  decode.d0.loss_cls: 0.6609  decode.d0.loss_mask: 1.3023  decode.d0.loss_dice: 0.9154  decode.d1.loss_cls: 0.3017  decode.d1.loss_mask: 1.3442  decode.d1.loss_dice: 0.9315  decode.d2.loss_cls: 0.2700  decode.d2.loss_mask: 1.3690  decode.d2.loss_dice: 0.9178  decode.d3.loss_cls: 0.2663  decode.d3.loss_mask: 1.3992  decode.d3.loss_dice: 0.9141  decode.d4.loss_cls: 0.3302  decode.d4.loss_mask: 1.3882  decode.d4.loss_dice: 0.9427  decode.d5.loss_cls: 0.2644  decode.d5.loss_mask: 1.3914  decode.d5.loss_dice: 0.9259  decode.d6.loss_cls: 0.2706  decode.d6.loss_mask: 1.4013  decode.d6.loss_dice: 0.9080  decode.d7.loss_cls: 0.2509  decode.d7.loss_mask: 1.4081  decode.d7.loss_dice: 0.9399  decode.d8.loss_cls: 0.3030  decode.d8.loss_mask: 1.3639  decode.d8.loss_dice: 0.9054
05/26 15:11:06 - mmengine - INFO - Iter(train) [ 36300/160000]  base_lr: 7.9328e-05 lr: 7.9328e-06  eta: 14:05:37  time: 0.4075  data_time: 0.0090  memory: 5982  grad_norm: 707.2315  loss: 22.6761  decode.loss_cls: 0.2330  decode.loss_mask: 1.1204  decode.loss_dice: 0.8407  decode.d0.loss_cls: 0.7872  decode.d0.loss_mask: 1.0358  decode.d0.loss_dice: 0.8314  decode.d1.loss_cls: 0.2414  decode.d1.loss_mask: 1.1582  decode.d1.loss_dice: 0.8746  decode.d2.loss_cls: 0.2318  decode.d2.loss_mask: 1.1587  decode.d2.loss_dice: 0.8750  decode.d3.loss_cls: 0.2535  decode.d3.loss_mask: 1.1642  decode.d3.loss_dice: 0.8673  decode.d4.loss_cls: 0.2881  decode.d4.loss_mask: 1.1182  decode.d4.loss_dice: 0.8349  decode.d5.loss_cls: 0.2668  decode.d5.loss_mask: 1.1120  decode.d5.loss_dice: 0.8325  decode.d6.loss_cls: 0.2634  decode.d6.loss_mask: 1.1002  decode.d6.loss_dice: 0.8353  decode.d7.loss_cls: 0.2681  decode.d7.loss_mask: 1.0946  decode.d7.loss_dice: 0.8133  decode.d8.loss_cls: 0.2105  decode.d8.loss_mask: 1.1086  decode.d8.loss_dice: 0.8565
05/26 15:11:26 - mmengine - INFO - Iter(train) [ 36350/160000]  base_lr: 7.9299e-05 lr: 7.9299e-06  eta: 14:05:17  time: 0.4095  data_time: 0.0094  memory: 5972  grad_norm: 668.4696  loss: 23.8679  decode.loss_cls: 0.2792  decode.loss_mask: 1.1829  decode.loss_dice: 0.8349  decode.d0.loss_cls: 0.7877  decode.d0.loss_mask: 1.1548  decode.d0.loss_dice: 0.8197  decode.d1.loss_cls: 0.3100  decode.d1.loss_mask: 1.1661  decode.d1.loss_dice: 0.8622  decode.d2.loss_cls: 0.2615  decode.d2.loss_mask: 1.2283  decode.d2.loss_dice: 0.8762  decode.d3.loss_cls: 0.2612  decode.d3.loss_mask: 1.2125  decode.d3.loss_dice: 0.8493  decode.d4.loss_cls: 0.2566  decode.d4.loss_mask: 1.1955  decode.d4.loss_dice: 0.8421  decode.d5.loss_cls: 0.3075  decode.d5.loss_mask: 1.1853  decode.d5.loss_dice: 0.8633  decode.d6.loss_cls: 0.3252  decode.d6.loss_mask: 1.2317  decode.d6.loss_dice: 0.8692  decode.d7.loss_cls: 0.3003  decode.d7.loss_mask: 1.1846  decode.d7.loss_dice: 0.8508  decode.d8.loss_cls: 0.2890  decode.d8.loss_mask: 1.2075  decode.d8.loss_dice: 0.8729
05/26 15:11:47 - mmengine - INFO - Iter(train) [ 36400/160000]  base_lr: 7.9270e-05 lr: 7.9270e-06  eta: 14:04:56  time: 0.4086  data_time: 0.0092  memory: 5970  grad_norm: 452.2758  loss: 24.3506  decode.loss_cls: 0.2417  decode.loss_mask: 1.2222  decode.loss_dice: 0.9001  decode.d0.loss_cls: 0.7785  decode.d0.loss_mask: 1.1832  decode.d0.loss_dice: 0.8799  decode.d1.loss_cls: 0.2760  decode.d1.loss_mask: 1.2291  decode.d1.loss_dice: 0.8752  decode.d2.loss_cls: 0.2910  decode.d2.loss_mask: 1.1962  decode.d2.loss_dice: 0.8786  decode.d3.loss_cls: 0.2940  decode.d3.loss_mask: 1.2107  decode.d3.loss_dice: 0.8725  decode.d4.loss_cls: 0.3230  decode.d4.loss_mask: 1.1895  decode.d4.loss_dice: 0.8610  decode.d5.loss_cls: 0.3177  decode.d5.loss_mask: 1.1823  decode.d5.loss_dice: 0.8585  decode.d6.loss_cls: 0.3058  decode.d6.loss_mask: 1.2037  decode.d6.loss_dice: 0.8841  decode.d7.loss_cls: 0.3132  decode.d7.loss_mask: 1.2717  decode.d7.loss_dice: 0.9130  decode.d8.loss_cls: 0.3018  decode.d8.loss_mask: 1.2161  decode.d8.loss_dice: 0.8803
05/26 15:12:07 - mmengine - INFO - Iter(train) [ 36450/160000]  base_lr: 7.9242e-05 lr: 7.9242e-06  eta: 14:04:35  time: 0.4081  data_time: 0.0091  memory: 5968  grad_norm: 618.9704  loss: 23.8735  decode.loss_cls: 0.3226  decode.loss_mask: 1.2040  decode.loss_dice: 0.8291  decode.d0.loss_cls: 0.7467  decode.d0.loss_mask: 1.1124  decode.d0.loss_dice: 0.8270  decode.d1.loss_cls: 0.3213  decode.d1.loss_mask: 1.2283  decode.d1.loss_dice: 0.8261  decode.d2.loss_cls: 0.2769  decode.d2.loss_mask: 1.1996  decode.d2.loss_dice: 0.8379  decode.d3.loss_cls: 0.3490  decode.d3.loss_mask: 1.2131  decode.d3.loss_dice: 0.8341  decode.d4.loss_cls: 0.3608  decode.d4.loss_mask: 1.2407  decode.d4.loss_dice: 0.8187  decode.d5.loss_cls: 0.3648  decode.d5.loss_mask: 1.1817  decode.d5.loss_dice: 0.8235  decode.d6.loss_cls: 0.3042  decode.d6.loss_mask: 1.2114  decode.d6.loss_dice: 0.8297  decode.d7.loss_cls: 0.3433  decode.d7.loss_mask: 1.1448  decode.d7.loss_dice: 0.8180  decode.d8.loss_cls: 0.3156  decode.d8.loss_mask: 1.1673  decode.d8.loss_dice: 0.8208
05/26 15:12:28 - mmengine - INFO - Iter(train) [ 36500/160000]  base_lr: 7.9213e-05 lr: 7.9213e-06  eta: 14:04:15  time: 0.4087  data_time: 0.0091  memory: 5966  grad_norm: 579.4934  loss: 26.2416  decode.loss_cls: 0.3344  decode.loss_mask: 1.1586  decode.loss_dice: 1.0025  decode.d0.loss_cls: 0.9168  decode.d0.loss_mask: 1.2023  decode.d0.loss_dice: 0.9915  decode.d1.loss_cls: 0.4392  decode.d1.loss_mask: 1.1670  decode.d1.loss_dice: 1.0215  decode.d2.loss_cls: 0.4082  decode.d2.loss_mask: 1.1697  decode.d2.loss_dice: 1.0474  decode.d3.loss_cls: 0.4020  decode.d3.loss_mask: 1.1850  decode.d3.loss_dice: 1.0227  decode.d4.loss_cls: 0.4021  decode.d4.loss_mask: 1.1764  decode.d4.loss_dice: 0.9857  decode.d5.loss_cls: 0.4050  decode.d5.loss_mask: 1.2291  decode.d5.loss_dice: 0.9781  decode.d6.loss_cls: 0.4421  decode.d6.loss_mask: 1.1543  decode.d6.loss_dice: 0.9896  decode.d7.loss_cls: 0.3741  decode.d7.loss_mask: 1.1680  decode.d7.loss_dice: 0.9850  decode.d8.loss_cls: 0.3478  decode.d8.loss_mask: 1.1638  decode.d8.loss_dice: 0.9716
05/26 15:12:48 - mmengine - INFO - Iter(train) [ 36550/160000]  base_lr: 7.9184e-05 lr: 7.9184e-06  eta: 14:03:54  time: 0.4080  data_time: 0.0090  memory: 5967  grad_norm: 539.1816  loss: 23.4936  decode.loss_cls: 0.2687  decode.loss_mask: 1.1970  decode.loss_dice: 0.8479  decode.d0.loss_cls: 0.7407  decode.d0.loss_mask: 1.1752  decode.d0.loss_dice: 0.8573  decode.d1.loss_cls: 0.2668  decode.d1.loss_mask: 1.1424  decode.d1.loss_dice: 0.8650  decode.d2.loss_cls: 0.2565  decode.d2.loss_mask: 1.1486  decode.d2.loss_dice: 0.8833  decode.d3.loss_cls: 0.2753  decode.d3.loss_mask: 1.1196  decode.d3.loss_dice: 0.8257  decode.d4.loss_cls: 0.2940  decode.d4.loss_mask: 1.1703  decode.d4.loss_dice: 0.8465  decode.d5.loss_cls: 0.2826  decode.d5.loss_mask: 1.1752  decode.d5.loss_dice: 0.8890  decode.d6.loss_cls: 0.2756  decode.d6.loss_mask: 1.1862  decode.d6.loss_dice: 0.8991  decode.d7.loss_cls: 0.2920  decode.d7.loss_mask: 1.1954  decode.d7.loss_dice: 0.8454  decode.d8.loss_cls: 0.2813  decode.d8.loss_mask: 1.1590  decode.d8.loss_dice: 0.8316
05/26 15:13:09 - mmengine - INFO - Iter(train) [ 36600/160000]  base_lr: 7.9155e-05 lr: 7.9155e-06  eta: 14:03:33  time: 0.4076  data_time: 0.0091  memory: 5966  grad_norm: 633.1048  loss: 22.5020  decode.loss_cls: 0.3842  decode.loss_mask: 1.0393  decode.loss_dice: 0.7755  decode.d0.loss_cls: 0.7895  decode.d0.loss_mask: 1.0605  decode.d0.loss_dice: 0.7731  decode.d1.loss_cls: 0.3422  decode.d1.loss_mask: 1.1257  decode.d1.loss_dice: 0.8098  decode.d2.loss_cls: 0.3801  decode.d2.loss_mask: 1.0306  decode.d2.loss_dice: 0.7613  decode.d3.loss_cls: 0.3660  decode.d3.loss_mask: 1.0747  decode.d3.loss_dice: 0.7807  decode.d4.loss_cls: 0.3804  decode.d4.loss_mask: 1.0212  decode.d4.loss_dice: 0.7627  decode.d5.loss_cls: 0.3504  decode.d5.loss_mask: 1.0540  decode.d5.loss_dice: 0.7913  decode.d6.loss_cls: 0.3451  decode.d6.loss_mask: 1.0241  decode.d6.loss_dice: 0.7905  decode.d7.loss_cls: 0.3130  decode.d7.loss_mask: 1.1244  decode.d7.loss_dice: 0.8163  decode.d8.loss_cls: 0.3778  decode.d8.loss_mask: 1.0617  decode.d8.loss_dice: 0.7960
05/26 15:13:29 - mmengine - INFO - Iter(train) [ 36650/160000]  base_lr: 7.9126e-05 lr: 7.9126e-06  eta: 14:03:12  time: 0.4089  data_time: 0.0091  memory: 5976  grad_norm: 816.9877  loss: 24.8249  decode.loss_cls: 0.4393  decode.loss_mask: 1.0834  decode.loss_dice: 0.9845  decode.d0.loss_cls: 0.7727  decode.d0.loss_mask: 1.0519  decode.d0.loss_dice: 0.9398  decode.d1.loss_cls: 0.3942  decode.d1.loss_mask: 1.0513  decode.d1.loss_dice: 1.0046  decode.d2.loss_cls: 0.4218  decode.d2.loss_mask: 1.0591  decode.d2.loss_dice: 0.9533  decode.d3.loss_cls: 0.4337  decode.d3.loss_mask: 1.0120  decode.d3.loss_dice: 0.9165  decode.d4.loss_cls: 0.4337  decode.d4.loss_mask: 1.0597  decode.d4.loss_dice: 0.9208  decode.d5.loss_cls: 0.3973  decode.d5.loss_mask: 1.0881  decode.d5.loss_dice: 0.9483  decode.d6.loss_cls: 0.4464  decode.d6.loss_mask: 1.0981  decode.d6.loss_dice: 1.0066  decode.d7.loss_cls: 0.4163  decode.d7.loss_mask: 1.0896  decode.d7.loss_dice: 0.9745  decode.d8.loss_cls: 0.4382  decode.d8.loss_mask: 1.0507  decode.d8.loss_dice: 0.9385
05/26 15:13:49 - mmengine - INFO - Iter(train) [ 36700/160000]  base_lr: 7.9097e-05 lr: 7.9097e-06  eta: 14:02:52  time: 0.4081  data_time: 0.0090  memory: 5973  grad_norm: 656.1212  loss: 29.2437  decode.loss_cls: 0.3268  decode.loss_mask: 1.3898  decode.loss_dice: 1.1364  decode.d0.loss_cls: 0.8681  decode.d0.loss_mask: 1.2913  decode.d0.loss_dice: 1.0921  decode.d1.loss_cls: 0.3697  decode.d1.loss_mask: 1.3874  decode.d1.loss_dice: 1.1792  decode.d2.loss_cls: 0.3567  decode.d2.loss_mask: 1.3927  decode.d2.loss_dice: 1.1401  decode.d3.loss_cls: 0.3804  decode.d3.loss_mask: 1.4213  decode.d3.loss_dice: 1.1433  decode.d4.loss_cls: 0.3606  decode.d4.loss_mask: 1.3812  decode.d4.loss_dice: 1.1154  decode.d5.loss_cls: 0.3244  decode.d5.loss_mask: 1.4090  decode.d5.loss_dice: 1.1325  decode.d6.loss_cls: 0.4286  decode.d6.loss_mask: 1.3876  decode.d6.loss_dice: 1.1456  decode.d7.loss_cls: 0.3448  decode.d7.loss_mask: 1.3794  decode.d7.loss_dice: 1.1100  decode.d8.loss_cls: 0.3222  decode.d8.loss_mask: 1.4042  decode.d8.loss_dice: 1.1231
05/26 15:14:10 - mmengine - INFO - Iter(train) [ 36750/160000]  base_lr: 7.9068e-05 lr: 7.9068e-06  eta: 14:02:31  time: 0.4093  data_time: 0.0091  memory: 5970  grad_norm: 1315.5115  loss: 22.6247  decode.loss_cls: 0.1925  decode.loss_mask: 1.2752  decode.loss_dice: 0.7684  decode.d0.loss_cls: 0.7527  decode.d0.loss_mask: 1.1317  decode.d0.loss_dice: 0.6950  decode.d1.loss_cls: 0.2341  decode.d1.loss_mask: 1.2795  decode.d1.loss_dice: 0.7717  decode.d2.loss_cls: 0.2339  decode.d2.loss_mask: 1.2287  decode.d2.loss_dice: 0.7506  decode.d3.loss_cls: 0.2346  decode.d3.loss_mask: 1.2643  decode.d3.loss_dice: 0.7801  decode.d4.loss_cls: 0.2704  decode.d4.loss_mask: 1.2045  decode.d4.loss_dice: 0.7223  decode.d5.loss_cls: 0.2459  decode.d5.loss_mask: 1.2471  decode.d5.loss_dice: 0.7233  decode.d6.loss_cls: 0.2567  decode.d6.loss_mask: 1.2599  decode.d6.loss_dice: 0.7247  decode.d7.loss_cls: 0.2445  decode.d7.loss_mask: 1.2123  decode.d7.loss_dice: 0.7174  decode.d8.loss_cls: 0.3077  decode.d8.loss_mask: 1.1941  decode.d8.loss_dice: 0.7005
05/26 15:14:30 - mmengine - INFO - Iter(train) [ 36800/160000]  base_lr: 7.9039e-05 lr: 7.9039e-06  eta: 14:02:10  time: 0.4085  data_time: 0.0090  memory: 5971  grad_norm: 581.5149  loss: 24.5514  decode.loss_cls: 0.2750  decode.loss_mask: 1.1955  decode.loss_dice: 0.9307  decode.d0.loss_cls: 0.7886  decode.d0.loss_mask: 1.1756  decode.d0.loss_dice: 0.8595  decode.d1.loss_cls: 0.3303  decode.d1.loss_mask: 1.2037  decode.d1.loss_dice: 0.8937  decode.d2.loss_cls: 0.2820  decode.d2.loss_mask: 1.2309  decode.d2.loss_dice: 0.9173  decode.d3.loss_cls: 0.2439  decode.d3.loss_mask: 1.2804  decode.d3.loss_dice: 0.9316  decode.d4.loss_cls: 0.2657  decode.d4.loss_mask: 1.2474  decode.d4.loss_dice: 0.9233  decode.d5.loss_cls: 0.2431  decode.d5.loss_mask: 1.2190  decode.d5.loss_dice: 0.8953  decode.d6.loss_cls: 0.2960  decode.d6.loss_mask: 1.2155  decode.d6.loss_dice: 0.9080  decode.d7.loss_cls: 0.2504  decode.d7.loss_mask: 1.2574  decode.d7.loss_dice: 0.9020  decode.d8.loss_cls: 0.2838  decode.d8.loss_mask: 1.2265  decode.d8.loss_dice: 0.8794
05/26 15:14:51 - mmengine - INFO - Iter(train) [ 36850/160000]  base_lr: 7.9011e-05 lr: 7.9011e-06  eta: 14:01:49  time: 0.4092  data_time: 0.0091  memory: 5976  grad_norm: 739.3690  loss: 24.4179  decode.loss_cls: 0.2025  decode.loss_mask: 1.3085  decode.loss_dice: 0.8716  decode.d0.loss_cls: 0.6235  decode.d0.loss_mask: 1.2383  decode.d0.loss_dice: 0.8511  decode.d1.loss_cls: 0.2133  decode.d1.loss_mask: 1.3344  decode.d1.loss_dice: 0.8797  decode.d2.loss_cls: 0.2231  decode.d2.loss_mask: 1.3036  decode.d2.loss_dice: 0.8440  decode.d3.loss_cls: 0.2200  decode.d3.loss_mask: 1.2900  decode.d3.loss_dice: 0.8396  decode.d4.loss_cls: 0.2308  decode.d4.loss_mask: 1.3268  decode.d4.loss_dice: 0.8577  decode.d5.loss_cls: 0.2359  decode.d5.loss_mask: 1.3242  decode.d5.loss_dice: 0.8756  decode.d6.loss_cls: 0.2422  decode.d6.loss_mask: 1.3414  decode.d6.loss_dice: 0.8717  decode.d7.loss_cls: 0.2267  decode.d7.loss_mask: 1.3147  decode.d7.loss_dice: 0.8794  decode.d8.loss_cls: 0.2195  decode.d8.loss_mask: 1.3355  decode.d8.loss_dice: 0.8927
05/26 15:15:11 - mmengine - INFO - Iter(train) [ 36900/160000]  base_lr: 7.8982e-05 lr: 7.8982e-06  eta: 14:01:29  time: 0.4076  data_time: 0.0091  memory: 5974  grad_norm: 874.9946  loss: 25.6651  decode.loss_cls: 0.2416  decode.loss_mask: 1.3816  decode.loss_dice: 0.9187  decode.d0.loss_cls: 0.8124  decode.d0.loss_mask: 1.2184  decode.d0.loss_dice: 0.8497  decode.d1.loss_cls: 0.2650  decode.d1.loss_mask: 1.3973  decode.d1.loss_dice: 0.9252  decode.d2.loss_cls: 0.2097  decode.d2.loss_mask: 1.3252  decode.d2.loss_dice: 0.9079  decode.d3.loss_cls: 0.2369  decode.d3.loss_mask: 1.3242  decode.d3.loss_dice: 0.8989  decode.d4.loss_cls: 0.2985  decode.d4.loss_mask: 1.3368  decode.d4.loss_dice: 0.8977  decode.d5.loss_cls: 0.2663  decode.d5.loss_mask: 1.3615  decode.d5.loss_dice: 0.9076  decode.d6.loss_cls: 0.2780  decode.d6.loss_mask: 1.3727  decode.d6.loss_dice: 0.9437  decode.d7.loss_cls: 0.2356  decode.d7.loss_mask: 1.3450  decode.d7.loss_dice: 0.9244  decode.d8.loss_cls: 0.2604  decode.d8.loss_mask: 1.3981  decode.d8.loss_dice: 0.9263
05/26 15:15:32 - mmengine - INFO - Iter(train) [ 36950/160000]  base_lr: 7.8953e-05 lr: 7.8953e-06  eta: 14:01:08  time: 0.4093  data_time: 0.0091  memory: 5966  grad_norm: 718.4946  loss: 23.8682  decode.loss_cls: 0.1497  decode.loss_mask: 1.2295  decode.loss_dice: 0.8803  decode.d0.loss_cls: 0.7358  decode.d0.loss_mask: 1.1442  decode.d0.loss_dice: 0.9348  decode.d1.loss_cls: 0.2020  decode.d1.loss_mask: 1.2527  decode.d1.loss_dice: 0.9183  decode.d2.loss_cls: 0.1783  decode.d2.loss_mask: 1.2475  decode.d2.loss_dice: 0.9302  decode.d3.loss_cls: 0.2245  decode.d3.loss_mask: 1.2648  decode.d3.loss_dice: 0.9372  decode.d4.loss_cls: 0.1922  decode.d4.loss_mask: 1.2144  decode.d4.loss_dice: 0.9296  decode.d5.loss_cls: 0.2146  decode.d5.loss_mask: 1.2081  decode.d5.loss_dice: 0.9316  decode.d6.loss_cls: 0.2021  decode.d6.loss_mask: 1.2708  decode.d6.loss_dice: 0.9322  decode.d7.loss_cls: 0.1721  decode.d7.loss_mask: 1.1939  decode.d7.loss_dice: 0.8824  decode.d8.loss_cls: 0.2014  decode.d8.loss_mask: 1.2004  decode.d8.loss_dice: 0.8925
05/26 15:15:52 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 15:15:52 - mmengine - INFO - Iter(train) [ 37000/160000]  base_lr: 7.8924e-05 lr: 7.8924e-06  eta: 14:00:47  time: 0.4101  data_time: 0.0091  memory: 5968  grad_norm: 807.2143  loss: 29.0848  decode.loss_cls: 0.2736  decode.loss_mask: 1.5989  decode.loss_dice: 0.9740  decode.d0.loss_cls: 0.8622  decode.d0.loss_mask: 1.4618  decode.d0.loss_dice: 0.9248  decode.d1.loss_cls: 0.2454  decode.d1.loss_mask: 1.6020  decode.d1.loss_dice: 1.0197  decode.d2.loss_cls: 0.2175  decode.d2.loss_mask: 1.6299  decode.d2.loss_dice: 1.0202  decode.d3.loss_cls: 0.2970  decode.d3.loss_mask: 1.5400  decode.d3.loss_dice: 0.9867  decode.d4.loss_cls: 0.2333  decode.d4.loss_mask: 1.6284  decode.d4.loss_dice: 1.0360  decode.d5.loss_cls: 0.2653  decode.d5.loss_mask: 1.6038  decode.d5.loss_dice: 0.9837  decode.d6.loss_cls: 0.2480  decode.d6.loss_mask: 1.6365  decode.d6.loss_dice: 0.9959  decode.d7.loss_cls: 0.2996  decode.d7.loss_mask: 1.6383  decode.d7.loss_dice: 1.0282  decode.d8.loss_cls: 0.2916  decode.d8.loss_mask: 1.6104  decode.d8.loss_dice: 0.9322
05/26 15:16:13 - mmengine - INFO - Iter(train) [ 37050/160000]  base_lr: 7.8895e-05 lr: 7.8895e-06  eta: 14:00:27  time: 0.4196  data_time: 0.0091  memory: 5965  grad_norm: 705.3219  loss: 25.3384  decode.loss_cls: 0.2452  decode.loss_mask: 1.3563  decode.loss_dice: 0.8999  decode.d0.loss_cls: 0.7361  decode.d0.loss_mask: 1.2595  decode.d0.loss_dice: 0.8469  decode.d1.loss_cls: 0.3255  decode.d1.loss_mask: 1.3339  decode.d1.loss_dice: 0.9306  decode.d2.loss_cls: 0.3233  decode.d2.loss_mask: 1.2706  decode.d2.loss_dice: 0.8689  decode.d3.loss_cls: 0.2861  decode.d3.loss_mask: 1.3077  decode.d3.loss_dice: 0.9317  decode.d4.loss_cls: 0.3279  decode.d4.loss_mask: 1.2627  decode.d4.loss_dice: 0.8878  decode.d5.loss_cls: 0.3064  decode.d5.loss_mask: 1.2917  decode.d5.loss_dice: 0.9108  decode.d6.loss_cls: 0.3160  decode.d6.loss_mask: 1.2415  decode.d6.loss_dice: 0.8785  decode.d7.loss_cls: 0.3248  decode.d7.loss_mask: 1.2907  decode.d7.loss_dice: 0.9063  decode.d8.loss_cls: 0.2902  decode.d8.loss_mask: 1.2703  decode.d8.loss_dice: 0.9109
05/26 15:16:33 - mmengine - INFO - Iter(train) [ 37100/160000]  base_lr: 7.8866e-05 lr: 7.8866e-06  eta: 14:00:06  time: 0.4096  data_time: 0.0091  memory: 5972  grad_norm: 748.7698  loss: 23.3244  decode.loss_cls: 0.2543  decode.loss_mask: 1.1645  decode.loss_dice: 0.8298  decode.d0.loss_cls: 0.7563  decode.d0.loss_mask: 1.0634  decode.d0.loss_dice: 0.7832  decode.d1.loss_cls: 0.2695  decode.d1.loss_mask: 1.2315  decode.d1.loss_dice: 0.8660  decode.d2.loss_cls: 0.2421  decode.d2.loss_mask: 1.1785  decode.d2.loss_dice: 0.8037  decode.d3.loss_cls: 0.2576  decode.d3.loss_mask: 1.1911  decode.d3.loss_dice: 0.7987  decode.d4.loss_cls: 0.2511  decode.d4.loss_mask: 1.1847  decode.d4.loss_dice: 0.8142  decode.d5.loss_cls: 0.2708  decode.d5.loss_mask: 1.2719  decode.d5.loss_dice: 0.8432  decode.d6.loss_cls: 0.3481  decode.d6.loss_mask: 1.2371  decode.d6.loss_dice: 0.8355  decode.d7.loss_cls: 0.2487  decode.d7.loss_mask: 1.1822  decode.d7.loss_dice: 0.8035  decode.d8.loss_cls: 0.2852  decode.d8.loss_mask: 1.2085  decode.d8.loss_dice: 0.8495
05/26 15:16:54 - mmengine - INFO - Iter(train) [ 37150/160000]  base_lr: 7.8837e-05 lr: 7.8837e-06  eta: 13:59:46  time: 0.4089  data_time: 0.0091  memory: 5989  grad_norm: 868.4822  loss: 23.1809  decode.loss_cls: 0.2589  decode.loss_mask: 1.1886  decode.loss_dice: 0.8024  decode.d0.loss_cls: 0.7869  decode.d0.loss_mask: 1.1107  decode.d0.loss_dice: 0.7521  decode.d1.loss_cls: 0.3112  decode.d1.loss_mask: 1.1531  decode.d1.loss_dice: 0.8183  decode.d2.loss_cls: 0.3067  decode.d2.loss_mask: 1.2022  decode.d2.loss_dice: 0.8114  decode.d3.loss_cls: 0.3093  decode.d3.loss_mask: 1.2021  decode.d3.loss_dice: 0.8123  decode.d4.loss_cls: 0.3539  decode.d4.loss_mask: 1.1381  decode.d4.loss_dice: 0.7929  decode.d5.loss_cls: 0.2519  decode.d5.loss_mask: 1.1905  decode.d5.loss_dice: 0.8096  decode.d6.loss_cls: 0.3654  decode.d6.loss_mask: 1.1216  decode.d6.loss_dice: 0.8223  decode.d7.loss_cls: 0.2853  decode.d7.loss_mask: 1.1627  decode.d7.loss_dice: 0.8093  decode.d8.loss_cls: 0.2594  decode.d8.loss_mask: 1.1790  decode.d8.loss_dice: 0.8127
05/26 15:17:14 - mmengine - INFO - Iter(train) [ 37200/160000]  base_lr: 7.8808e-05 lr: 7.8808e-06  eta: 13:59:25  time: 0.4088  data_time: 0.0091  memory: 5969  grad_norm: 945.9602  loss: 25.5493  decode.loss_cls: 0.3628  decode.loss_mask: 1.3482  decode.loss_dice: 0.8660  decode.d0.loss_cls: 0.8783  decode.d0.loss_mask: 1.2505  decode.d0.loss_dice: 0.7834  decode.d1.loss_cls: 0.3119  decode.d1.loss_mask: 1.3394  decode.d1.loss_dice: 0.8251  decode.d2.loss_cls: 0.3432  decode.d2.loss_mask: 1.2859  decode.d2.loss_dice: 0.8042  decode.d3.loss_cls: 0.3695  decode.d3.loss_mask: 1.2450  decode.d3.loss_dice: 0.8246  decode.d4.loss_cls: 0.4004  decode.d4.loss_mask: 1.2786  decode.d4.loss_dice: 0.8362  decode.d5.loss_cls: 0.4327  decode.d5.loss_mask: 1.3251  decode.d5.loss_dice: 0.8321  decode.d6.loss_cls: 0.3529  decode.d6.loss_mask: 1.3575  decode.d6.loss_dice: 0.8622  decode.d7.loss_cls: 0.2966  decode.d7.loss_mask: 1.3334  decode.d7.loss_dice: 0.8546  decode.d8.loss_cls: 0.3462  decode.d8.loss_mask: 1.3554  decode.d8.loss_dice: 0.8473
05/26 15:17:35 - mmengine - INFO - Iter(train) [ 37250/160000]  base_lr: 7.8780e-05 lr: 7.8780e-06  eta: 13:59:04  time: 0.4101  data_time: 0.0092  memory: 5971  grad_norm: 563.7083  loss: 24.0331  decode.loss_cls: 0.4025  decode.loss_mask: 1.0283  decode.loss_dice: 0.8574  decode.d0.loss_cls: 0.8082  decode.d0.loss_mask: 1.0848  decode.d0.loss_dice: 0.8522  decode.d1.loss_cls: 0.3800  decode.d1.loss_mask: 1.1139  decode.d1.loss_dice: 0.8780  decode.d2.loss_cls: 0.3679  decode.d2.loss_mask: 1.0792  decode.d2.loss_dice: 0.9048  decode.d3.loss_cls: 0.3971  decode.d3.loss_mask: 1.0768  decode.d3.loss_dice: 0.9306  decode.d4.loss_cls: 0.4206  decode.d4.loss_mask: 1.0550  decode.d4.loss_dice: 0.8519  decode.d5.loss_cls: 0.4244  decode.d5.loss_mask: 1.0747  decode.d5.loss_dice: 0.8755  decode.d6.loss_cls: 0.4218  decode.d6.loss_mask: 1.0554  decode.d6.loss_dice: 0.9220  decode.d7.loss_cls: 0.4284  decode.d7.loss_mask: 1.0872  decode.d7.loss_dice: 0.8806  decode.d8.loss_cls: 0.4170  decode.d8.loss_mask: 1.0773  decode.d8.loss_dice: 0.8797
05/26 15:17:55 - mmengine - INFO - Iter(train) [ 37300/160000]  base_lr: 7.8751e-05 lr: 7.8751e-06  eta: 13:58:44  time: 0.4100  data_time: 0.0091  memory: 5969  grad_norm: 683.9210  loss: 27.5870  decode.loss_cls: 0.3319  decode.loss_mask: 1.3475  decode.loss_dice: 1.0071  decode.d0.loss_cls: 0.8130  decode.d0.loss_mask: 1.2633  decode.d0.loss_dice: 0.9090  decode.d1.loss_cls: 0.3559  decode.d1.loss_mask: 1.3498  decode.d1.loss_dice: 1.0204  decode.d2.loss_cls: 0.3440  decode.d2.loss_mask: 1.3413  decode.d2.loss_dice: 0.9967  decode.d3.loss_cls: 0.3203  decode.d3.loss_mask: 1.3926  decode.d3.loss_dice: 0.9719  decode.d4.loss_cls: 0.3923  decode.d4.loss_mask: 1.3732  decode.d4.loss_dice: 0.9729  decode.d5.loss_cls: 0.4094  decode.d5.loss_mask: 1.4176  decode.d5.loss_dice: 1.0318  decode.d6.loss_cls: 0.3588  decode.d6.loss_mask: 1.3992  decode.d6.loss_dice: 0.9857  decode.d7.loss_cls: 0.3212  decode.d7.loss_mask: 1.4152  decode.d7.loss_dice: 0.9975  decode.d8.loss_cls: 0.3251  decode.d8.loss_mask: 1.3751  decode.d8.loss_dice: 1.0473
05/26 15:18:16 - mmengine - INFO - Iter(train) [ 37350/160000]  base_lr: 7.8722e-05 lr: 7.8722e-06  eta: 13:58:23  time: 0.4103  data_time: 0.0092  memory: 5966  grad_norm: 682.8507  loss: 22.8260  decode.loss_cls: 0.2540  decode.loss_mask: 1.1906  decode.loss_dice: 0.7854  decode.d0.loss_cls: 0.6929  decode.d0.loss_mask: 1.1297  decode.d0.loss_dice: 0.7640  decode.d1.loss_cls: 0.2659  decode.d1.loss_mask: 1.1763  decode.d1.loss_dice: 0.7808  decode.d2.loss_cls: 0.2271  decode.d2.loss_mask: 1.3029  decode.d2.loss_dice: 0.7991  decode.d3.loss_cls: 0.2798  decode.d3.loss_mask: 1.1805  decode.d3.loss_dice: 0.7765  decode.d4.loss_cls: 0.2779  decode.d4.loss_mask: 1.1717  decode.d4.loss_dice: 0.7705  decode.d5.loss_cls: 0.2750  decode.d5.loss_mask: 1.1248  decode.d5.loss_dice: 0.7863  decode.d6.loss_cls: 0.3010  decode.d6.loss_mask: 1.2369  decode.d6.loss_dice: 0.8002  decode.d7.loss_cls: 0.2431  decode.d7.loss_mask: 1.2184  decode.d7.loss_dice: 0.7745  decode.d8.loss_cls: 0.2314  decode.d8.loss_mask: 1.2281  decode.d8.loss_dice: 0.7809
05/26 15:18:36 - mmengine - INFO - Iter(train) [ 37400/160000]  base_lr: 7.8693e-05 lr: 7.8693e-06  eta: 13:58:03  time: 0.4093  data_time: 0.0091  memory: 5966  grad_norm: 762.7567  loss: 27.2339  decode.loss_cls: 0.2450  decode.loss_mask: 1.4499  decode.loss_dice: 0.9717  decode.d0.loss_cls: 0.7928  decode.d0.loss_mask: 1.2752  decode.d0.loss_dice: 0.9382  decode.d1.loss_cls: 0.2945  decode.d1.loss_mask: 1.4276  decode.d1.loss_dice: 0.9863  decode.d2.loss_cls: 0.2835  decode.d2.loss_mask: 1.4072  decode.d2.loss_dice: 0.9367  decode.d3.loss_cls: 0.3682  decode.d3.loss_mask: 1.4112  decode.d3.loss_dice: 0.9449  decode.d4.loss_cls: 0.3239  decode.d4.loss_mask: 1.4186  decode.d4.loss_dice: 0.9454  decode.d5.loss_cls: 0.2824  decode.d5.loss_mask: 1.4631  decode.d5.loss_dice: 0.9635  decode.d6.loss_cls: 0.3033  decode.d6.loss_mask: 1.4629  decode.d6.loss_dice: 0.9596  decode.d7.loss_cls: 0.3170  decode.d7.loss_mask: 1.4389  decode.d7.loss_dice: 0.9756  decode.d8.loss_cls: 0.2581  decode.d8.loss_mask: 1.4205  decode.d8.loss_dice: 0.9682
05/26 15:18:56 - mmengine - INFO - Iter(train) [ 37450/160000]  base_lr: 7.8664e-05 lr: 7.8664e-06  eta: 13:57:42  time: 0.4099  data_time: 0.0091  memory: 5969  grad_norm: 820.1261  loss: 27.7289  decode.loss_cls: 0.3159  decode.loss_mask: 1.3146  decode.loss_dice: 1.0532  decode.d0.loss_cls: 0.7906  decode.d0.loss_mask: 1.3433  decode.d0.loss_dice: 1.0174  decode.d1.loss_cls: 0.3384  decode.d1.loss_mask: 1.3193  decode.d1.loss_dice: 1.0379  decode.d2.loss_cls: 0.2999  decode.d2.loss_mask: 1.3676  decode.d2.loss_dice: 1.0284  decode.d3.loss_cls: 0.3312  decode.d3.loss_mask: 1.3517  decode.d3.loss_dice: 1.0506  decode.d4.loss_cls: 0.3406  decode.d4.loss_mask: 1.2986  decode.d4.loss_dice: 1.0227  decode.d5.loss_cls: 0.3281  decode.d5.loss_mask: 1.3573  decode.d5.loss_dice: 1.0755  decode.d6.loss_cls: 0.3288  decode.d6.loss_mask: 1.3923  decode.d6.loss_dice: 1.0578  decode.d7.loss_cls: 0.3098  decode.d7.loss_mask: 1.3631  decode.d7.loss_dice: 1.0783  decode.d8.loss_cls: 0.3271  decode.d8.loss_mask: 1.4376  decode.d8.loss_dice: 1.0514
05/26 15:19:17 - mmengine - INFO - Iter(train) [ 37500/160000]  base_lr: 7.8635e-05 lr: 7.8635e-06  eta: 13:57:21  time: 0.4106  data_time: 0.0091  memory: 5968  grad_norm: 480.1409  loss: 19.7135  decode.loss_cls: 0.1256  decode.loss_mask: 1.0384  decode.loss_dice: 0.7511  decode.d0.loss_cls: 0.6809  decode.d0.loss_mask: 0.9759  decode.d0.loss_dice: 0.7244  decode.d1.loss_cls: 0.1501  decode.d1.loss_mask: 1.0377  decode.d1.loss_dice: 0.7460  decode.d2.loss_cls: 0.1490  decode.d2.loss_mask: 1.0682  decode.d2.loss_dice: 0.7334  decode.d3.loss_cls: 0.1312  decode.d3.loss_mask: 1.0436  decode.d3.loss_dice: 0.7274  decode.d4.loss_cls: 0.1585  decode.d4.loss_mask: 1.0266  decode.d4.loss_dice: 0.7298  decode.d5.loss_cls: 0.1264  decode.d5.loss_mask: 1.0411  decode.d5.loss_dice: 0.7533  decode.d6.loss_cls: 0.1619  decode.d6.loss_mask: 1.0561  decode.d6.loss_dice: 0.7483  decode.d7.loss_cls: 0.1692  decode.d7.loss_mask: 1.0217  decode.d7.loss_dice: 0.7292  decode.d8.loss_cls: 0.1502  decode.d8.loss_mask: 1.0208  decode.d8.loss_dice: 0.7371
05/26 15:19:37 - mmengine - INFO - Iter(train) [ 37550/160000]  base_lr: 7.8606e-05 lr: 7.8606e-06  eta: 13:57:01  time: 0.4094  data_time: 0.0091  memory: 5969  grad_norm: 807.9005  loss: 27.7547  decode.loss_cls: 0.3182  decode.loss_mask: 1.3740  decode.loss_dice: 0.9735  decode.d0.loss_cls: 0.7762  decode.d0.loss_mask: 1.3008  decode.d0.loss_dice: 0.9718  decode.d1.loss_cls: 0.3981  decode.d1.loss_mask: 1.3631  decode.d1.loss_dice: 0.9769  decode.d2.loss_cls: 0.3409  decode.d2.loss_mask: 1.3477  decode.d2.loss_dice: 1.0108  decode.d3.loss_cls: 0.3935  decode.d3.loss_mask: 1.3288  decode.d3.loss_dice: 0.9844  decode.d4.loss_cls: 0.4184  decode.d4.loss_mask: 1.3343  decode.d4.loss_dice: 1.0293  decode.d5.loss_cls: 0.4171  decode.d5.loss_mask: 1.3554  decode.d5.loss_dice: 1.0274  decode.d6.loss_cls: 0.4480  decode.d6.loss_mask: 1.3680  decode.d6.loss_dice: 0.9952  decode.d7.loss_cls: 0.4316  decode.d7.loss_mask: 1.3562  decode.d7.loss_dice: 0.9815  decode.d8.loss_cls: 0.3468  decode.d8.loss_mask: 1.3899  decode.d8.loss_dice: 0.9969
05/26 15:19:58 - mmengine - INFO - Iter(train) [ 37600/160000]  base_lr: 7.8577e-05 lr: 7.8577e-06  eta: 13:56:40  time: 0.4108  data_time: 0.0093  memory: 5981  grad_norm: 658.5554  loss: 26.8392  decode.loss_cls: 0.2952  decode.loss_mask: 1.2952  decode.loss_dice: 1.0037  decode.d0.loss_cls: 0.9049  decode.d0.loss_mask: 1.1941  decode.d0.loss_dice: 0.9629  decode.d1.loss_cls: 0.4134  decode.d1.loss_mask: 1.2787  decode.d1.loss_dice: 0.9890  decode.d2.loss_cls: 0.3817  decode.d2.loss_mask: 1.2520  decode.d2.loss_dice: 0.9745  decode.d3.loss_cls: 0.3842  decode.d3.loss_mask: 1.2973  decode.d3.loss_dice: 0.9800  decode.d4.loss_cls: 0.4209  decode.d4.loss_mask: 1.3049  decode.d4.loss_dice: 0.9528  decode.d5.loss_cls: 0.4048  decode.d5.loss_mask: 1.2981  decode.d5.loss_dice: 1.0126  decode.d6.loss_cls: 0.3660  decode.d6.loss_mask: 1.2720  decode.d6.loss_dice: 0.9803  decode.d7.loss_cls: 0.3850  decode.d7.loss_mask: 1.2356  decode.d7.loss_dice: 0.9644  decode.d8.loss_cls: 0.3446  decode.d8.loss_mask: 1.3064  decode.d8.loss_dice: 0.9839
05/26 15:20:18 - mmengine - INFO - Iter(train) [ 37650/160000]  base_lr: 7.8549e-05 lr: 7.8549e-06  eta: 13:56:19  time: 0.4106  data_time: 0.0092  memory: 5965  grad_norm: 628.1604  loss: 19.9385  decode.loss_cls: 0.1441  decode.loss_mask: 1.1015  decode.loss_dice: 0.6621  decode.d0.loss_cls: 0.6071  decode.d0.loss_mask: 1.1340  decode.d0.loss_dice: 0.7047  decode.d1.loss_cls: 0.1269  decode.d1.loss_mask: 1.1080  decode.d1.loss_dice: 0.7036  decode.d2.loss_cls: 0.1088  decode.d2.loss_mask: 1.1661  decode.d2.loss_dice: 0.7154  decode.d3.loss_cls: 0.1339  decode.d3.loss_mask: 1.1294  decode.d3.loss_dice: 0.6874  decode.d4.loss_cls: 0.1260  decode.d4.loss_mask: 1.1306  decode.d4.loss_dice: 0.6935  decode.d5.loss_cls: 0.1231  decode.d5.loss_mask: 1.1388  decode.d5.loss_dice: 0.6863  decode.d6.loss_cls: 0.1386  decode.d6.loss_mask: 1.1527  decode.d6.loss_dice: 0.6941  decode.d7.loss_cls: 0.1401  decode.d7.loss_mask: 1.1008  decode.d7.loss_dice: 0.6673  decode.d8.loss_cls: 0.1214  decode.d8.loss_mask: 1.1109  decode.d8.loss_dice: 0.6813
05/26 15:20:39 - mmengine - INFO - Iter(train) [ 37700/160000]  base_lr: 7.8520e-05 lr: 7.8520e-06  eta: 13:55:59  time: 0.4096  data_time: 0.0092  memory: 5976  grad_norm: 500.4655  loss: 22.2214  decode.loss_cls: 0.2191  decode.loss_mask: 1.1062  decode.loss_dice: 0.7928  decode.d0.loss_cls: 0.7692  decode.d0.loss_mask: 1.1060  decode.d0.loss_dice: 0.7912  decode.d1.loss_cls: 0.2965  decode.d1.loss_mask: 1.0974  decode.d1.loss_dice: 0.8015  decode.d2.loss_cls: 0.2324  decode.d2.loss_mask: 1.1667  decode.d2.loss_dice: 0.8311  decode.d3.loss_cls: 0.2461  decode.d3.loss_mask: 1.1075  decode.d3.loss_dice: 0.7949  decode.d4.loss_cls: 0.2326  decode.d4.loss_mask: 1.1518  decode.d4.loss_dice: 0.8085  decode.d5.loss_cls: 0.2510  decode.d5.loss_mask: 1.0991  decode.d5.loss_dice: 0.8235  decode.d6.loss_cls: 0.2252  decode.d6.loss_mask: 1.1095  decode.d6.loss_dice: 0.8183  decode.d7.loss_cls: 0.2097  decode.d7.loss_mask: 1.1492  decode.d7.loss_dice: 0.8209  decode.d8.loss_cls: 0.2636  decode.d8.loss_mask: 1.1266  decode.d8.loss_dice: 0.7734
05/26 15:20:59 - mmengine - INFO - Iter(train) [ 37750/160000]  base_lr: 7.8491e-05 lr: 7.8491e-06  eta: 13:55:38  time: 0.4102  data_time: 0.0093  memory: 5968  grad_norm: 981.8872  loss: 28.3246  decode.loss_cls: 0.2986  decode.loss_mask: 1.3659  decode.loss_dice: 1.0439  decode.d0.loss_cls: 0.8537  decode.d0.loss_mask: 1.3048  decode.d0.loss_dice: 1.0085  decode.d1.loss_cls: 0.3875  decode.d1.loss_mask: 1.3777  decode.d1.loss_dice: 1.0811  decode.d2.loss_cls: 0.3930  decode.d2.loss_mask: 1.3798  decode.d2.loss_dice: 1.1168  decode.d3.loss_cls: 0.3886  decode.d3.loss_mask: 1.3718  decode.d3.loss_dice: 1.0454  decode.d4.loss_cls: 0.3985  decode.d4.loss_mask: 1.3913  decode.d4.loss_dice: 1.0740  decode.d5.loss_cls: 0.4040  decode.d5.loss_mask: 1.3383  decode.d5.loss_dice: 1.0252  decode.d6.loss_cls: 0.4041  decode.d6.loss_mask: 1.3459  decode.d6.loss_dice: 1.0543  decode.d7.loss_cls: 0.3524  decode.d7.loss_mask: 1.3720  decode.d7.loss_dice: 1.0544  decode.d8.loss_cls: 0.3096  decode.d8.loss_mask: 1.3519  decode.d8.loss_dice: 1.0315
05/26 15:21:20 - mmengine - INFO - Iter(train) [ 37800/160000]  base_lr: 7.8462e-05 lr: 7.8462e-06  eta: 13:55:17  time: 0.4096  data_time: 0.0092  memory: 5975  grad_norm: 581.2941  loss: 23.5897  decode.loss_cls: 0.3120  decode.loss_mask: 1.1990  decode.loss_dice: 0.8362  decode.d0.loss_cls: 0.8446  decode.d0.loss_mask: 1.0722  decode.d0.loss_dice: 0.8185  decode.d1.loss_cls: 0.3513  decode.d1.loss_mask: 1.1430  decode.d1.loss_dice: 0.8111  decode.d2.loss_cls: 0.3140  decode.d2.loss_mask: 1.2330  decode.d2.loss_dice: 0.8210  decode.d3.loss_cls: 0.3091  decode.d3.loss_mask: 1.1677  decode.d3.loss_dice: 0.8300  decode.d4.loss_cls: 0.3487  decode.d4.loss_mask: 1.1303  decode.d4.loss_dice: 0.8374  decode.d5.loss_cls: 0.3566  decode.d5.loss_mask: 1.1299  decode.d5.loss_dice: 0.8074  decode.d6.loss_cls: 0.3648  decode.d6.loss_mask: 1.1383  decode.d6.loss_dice: 0.8418  decode.d7.loss_cls: 0.3099  decode.d7.loss_mask: 1.1490  decode.d7.loss_dice: 0.8364  decode.d8.loss_cls: 0.3393  decode.d8.loss_mask: 1.1343  decode.d8.loss_dice: 0.8028
05/26 15:21:40 - mmengine - INFO - Iter(train) [ 37850/160000]  base_lr: 7.8433e-05 lr: 7.8433e-06  eta: 13:54:57  time: 0.4100  data_time: 0.0093  memory: 5972  grad_norm: 698.7929  loss: 27.6083  decode.loss_cls: 0.3873  decode.loss_mask: 1.2126  decode.loss_dice: 1.0264  decode.d0.loss_cls: 0.8053  decode.d0.loss_mask: 1.2573  decode.d0.loss_dice: 1.0622  decode.d1.loss_cls: 0.3741  decode.d1.loss_mask: 1.2379  decode.d1.loss_dice: 1.0730  decode.d2.loss_cls: 0.3973  decode.d2.loss_mask: 1.2270  decode.d2.loss_dice: 1.0536  decode.d3.loss_cls: 0.3514  decode.d3.loss_mask: 1.3252  decode.d3.loss_dice: 1.0333  decode.d4.loss_cls: 0.3857  decode.d4.loss_mask: 1.3215  decode.d4.loss_dice: 1.0747  decode.d5.loss_cls: 0.3823  decode.d5.loss_mask: 1.2257  decode.d5.loss_dice: 1.0597  decode.d6.loss_cls: 0.4388  decode.d6.loss_mask: 1.2782  decode.d6.loss_dice: 1.0927  decode.d7.loss_cls: 0.4381  decode.d7.loss_mask: 1.3499  decode.d7.loss_dice: 1.0723  decode.d8.loss_cls: 0.3567  decode.d8.loss_mask: 1.2581  decode.d8.loss_dice: 1.0500
05/26 15:22:01 - mmengine - INFO - Iter(train) [ 37900/160000]  base_lr: 7.8404e-05 lr: 7.8404e-06  eta: 13:54:36  time: 0.4104  data_time: 0.0092  memory: 5973  grad_norm: 674.0789  loss: 25.7662  decode.loss_cls: 0.3157  decode.loss_mask: 1.1948  decode.loss_dice: 0.9969  decode.d0.loss_cls: 0.7997  decode.d0.loss_mask: 1.1743  decode.d0.loss_dice: 0.9730  decode.d1.loss_cls: 0.2623  decode.d1.loss_mask: 1.2222  decode.d1.loss_dice: 0.9850  decode.d2.loss_cls: 0.2861  decode.d2.loss_mask: 1.2321  decode.d2.loss_dice: 1.0062  decode.d3.loss_cls: 0.3279  decode.d3.loss_mask: 1.2250  decode.d3.loss_dice: 0.9937  decode.d4.loss_cls: 0.3533  decode.d4.loss_mask: 1.1889  decode.d4.loss_dice: 0.9563  decode.d5.loss_cls: 0.3368  decode.d5.loss_mask: 1.2029  decode.d5.loss_dice: 0.9945  decode.d6.loss_cls: 0.3752  decode.d6.loss_mask: 1.2138  decode.d6.loss_dice: 1.0029  decode.d7.loss_cls: 0.3385  decode.d7.loss_mask: 1.2285  decode.d7.loss_dice: 1.0142  decode.d8.loss_cls: 0.3142  decode.d8.loss_mask: 1.2419  decode.d8.loss_dice: 1.0094
05/26 15:22:21 - mmengine - INFO - Iter(train) [ 37950/160000]  base_lr: 7.8375e-05 lr: 7.8375e-06  eta: 13:54:15  time: 0.4103  data_time: 0.0092  memory: 5966  grad_norm: 792.5577  loss: 23.2335  decode.loss_cls: 0.2848  decode.loss_mask: 1.2300  decode.loss_dice: 0.7781  decode.d0.loss_cls: 0.7255  decode.d0.loss_mask: 1.1309  decode.d0.loss_dice: 0.7707  decode.d1.loss_cls: 0.2639  decode.d1.loss_mask: 1.1882  decode.d1.loss_dice: 0.7611  decode.d2.loss_cls: 0.2922  decode.d2.loss_mask: 1.2001  decode.d2.loss_dice: 0.7844  decode.d3.loss_cls: 0.3012  decode.d3.loss_mask: 1.2111  decode.d3.loss_dice: 0.7636  decode.d4.loss_cls: 0.2970  decode.d4.loss_mask: 1.1976  decode.d4.loss_dice: 0.7751  decode.d5.loss_cls: 0.3048  decode.d5.loss_mask: 1.2397  decode.d5.loss_dice: 0.7745  decode.d6.loss_cls: 0.3481  decode.d6.loss_mask: 1.2192  decode.d6.loss_dice: 0.7630  decode.d7.loss_cls: 0.3107  decode.d7.loss_mask: 1.2425  decode.d7.loss_dice: 0.7781  decode.d8.loss_cls: 0.2857  decode.d8.loss_mask: 1.2371  decode.d8.loss_dice: 0.7744
05/26 15:22:42 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 15:22:42 - mmengine - INFO - Iter(train) [ 38000/160000]  base_lr: 7.8346e-05 lr: 7.8346e-06  eta: 13:53:55  time: 0.4105  data_time: 0.0092  memory: 5976  grad_norm: 598.9210  loss: 25.3609  decode.loss_cls: 0.3361  decode.loss_mask: 1.2644  decode.loss_dice: 0.8704  decode.d0.loss_cls: 0.7830  decode.d0.loss_mask: 1.1371  decode.d0.loss_dice: 0.8631  decode.d1.loss_cls: 0.3320  decode.d1.loss_mask: 1.2499  decode.d1.loss_dice: 0.8974  decode.d2.loss_cls: 0.3672  decode.d2.loss_mask: 1.2433  decode.d2.loss_dice: 0.9555  decode.d3.loss_cls: 0.3236  decode.d3.loss_mask: 1.2498  decode.d3.loss_dice: 0.8963  decode.d4.loss_cls: 0.3694  decode.d4.loss_mask: 1.2112  decode.d4.loss_dice: 0.9079  decode.d5.loss_cls: 0.3960  decode.d5.loss_mask: 1.1924  decode.d5.loss_dice: 0.8909  decode.d6.loss_cls: 0.3497  decode.d6.loss_mask: 1.2646  decode.d6.loss_dice: 0.9067  decode.d7.loss_cls: 0.3537  decode.d7.loss_mask: 1.3017  decode.d7.loss_dice: 0.9440  decode.d8.loss_cls: 0.3603  decode.d8.loss_mask: 1.2646  decode.d8.loss_dice: 0.8790
05/26 15:23:02 - mmengine - INFO - Iter(train) [ 38050/160000]  base_lr: 7.8317e-05 lr: 7.8317e-06  eta: 13:53:34  time: 0.4092  data_time: 0.0093  memory: 5969  grad_norm: 556.2389  loss: 26.1122  decode.loss_cls: 0.2778  decode.loss_mask: 1.2877  decode.loss_dice: 0.9968  decode.d0.loss_cls: 0.7484  decode.d0.loss_mask: 1.2421  decode.d0.loss_dice: 0.9840  decode.d1.loss_cls: 0.3581  decode.d1.loss_mask: 1.2927  decode.d1.loss_dice: 0.9491  decode.d2.loss_cls: 0.2385  decode.d2.loss_mask: 1.2894  decode.d2.loss_dice: 1.0028  decode.d3.loss_cls: 0.2676  decode.d3.loss_mask: 1.2906  decode.d3.loss_dice: 1.0046  decode.d4.loss_cls: 0.2547  decode.d4.loss_mask: 1.3162  decode.d4.loss_dice: 0.9923  decode.d5.loss_cls: 0.2884  decode.d5.loss_mask: 1.3073  decode.d5.loss_dice: 1.0110  decode.d6.loss_cls: 0.2806  decode.d6.loss_mask: 1.2970  decode.d6.loss_dice: 1.0262  decode.d7.loss_cls: 0.2324  decode.d7.loss_mask: 1.3103  decode.d7.loss_dice: 1.0401  decode.d8.loss_cls: 0.2148  decode.d8.loss_mask: 1.3139  decode.d8.loss_dice: 0.9966
05/26 15:23:23 - mmengine - INFO - Iter(train) [ 38100/160000]  base_lr: 7.8288e-05 lr: 7.8288e-06  eta: 13:53:14  time: 0.4087  data_time: 0.0091  memory: 5967  grad_norm: 427.3216  loss: 20.4819  decode.loss_cls: 0.2894  decode.loss_mask: 0.9872  decode.loss_dice: 0.7514  decode.d0.loss_cls: 0.6632  decode.d0.loss_mask: 0.9498  decode.d0.loss_dice: 0.7429  decode.d1.loss_cls: 0.3449  decode.d1.loss_mask: 0.9514  decode.d1.loss_dice: 0.7074  decode.d2.loss_cls: 0.2995  decode.d2.loss_mask: 0.9872  decode.d2.loss_dice: 0.7674  decode.d3.loss_cls: 0.3229  decode.d3.loss_mask: 0.9757  decode.d3.loss_dice: 0.7087  decode.d4.loss_cls: 0.3076  decode.d4.loss_mask: 0.9460  decode.d4.loss_dice: 0.7323  decode.d5.loss_cls: 0.3027  decode.d5.loss_mask: 0.9690  decode.d5.loss_dice: 0.7541  decode.d6.loss_cls: 0.3013  decode.d6.loss_mask: 0.9416  decode.d6.loss_dice: 0.7268  decode.d7.loss_cls: 0.3068  decode.d7.loss_mask: 0.9599  decode.d7.loss_dice: 0.7453  decode.d8.loss_cls: 0.3096  decode.d8.loss_mask: 0.9715  decode.d8.loss_dice: 0.7583
05/26 15:23:43 - mmengine - INFO - Iter(train) [ 38150/160000]  base_lr: 7.8260e-05 lr: 7.8260e-06  eta: 13:52:53  time: 0.4095  data_time: 0.0092  memory: 5974  grad_norm: 701.1044  loss: 23.2053  decode.loss_cls: 0.3068  decode.loss_mask: 1.1076  decode.loss_dice: 0.8176  decode.d0.loss_cls: 0.7071  decode.d0.loss_mask: 1.1298  decode.d0.loss_dice: 0.8738  decode.d1.loss_cls: 0.3148  decode.d1.loss_mask: 1.1008  decode.d1.loss_dice: 0.8405  decode.d2.loss_cls: 0.3459  decode.d2.loss_mask: 1.1264  decode.d2.loss_dice: 0.8473  decode.d3.loss_cls: 0.2931  decode.d3.loss_mask: 1.1843  decode.d3.loss_dice: 0.8648  decode.d4.loss_cls: 0.3652  decode.d4.loss_mask: 1.0953  decode.d4.loss_dice: 0.8155  decode.d5.loss_cls: 0.3137  decode.d5.loss_mask: 1.1104  decode.d5.loss_dice: 0.8279  decode.d6.loss_cls: 0.3516  decode.d6.loss_mask: 1.1246  decode.d6.loss_dice: 0.8403  decode.d7.loss_cls: 0.3386  decode.d7.loss_mask: 1.1169  decode.d7.loss_dice: 0.8349  decode.d8.loss_cls: 0.2857  decode.d8.loss_mask: 1.1090  decode.d8.loss_dice: 0.8148
05/26 15:24:04 - mmengine - INFO - Iter(train) [ 38200/160000]  base_lr: 7.8231e-05 lr: 7.8231e-06  eta: 13:52:33  time: 0.4102  data_time: 0.0093  memory: 5969  grad_norm: 610.9691  loss: 29.2609  decode.loss_cls: 0.3553  decode.loss_mask: 1.4222  decode.loss_dice: 1.0151  decode.d0.loss_cls: 0.9226  decode.d0.loss_mask: 1.4102  decode.d0.loss_dice: 1.0155  decode.d1.loss_cls: 0.4178  decode.d1.loss_mask: 1.3923  decode.d1.loss_dice: 1.0299  decode.d2.loss_cls: 0.3783  decode.d2.loss_mask: 1.4931  decode.d2.loss_dice: 1.0354  decode.d3.loss_cls: 0.3494  decode.d3.loss_mask: 1.4689  decode.d3.loss_dice: 1.0230  decode.d4.loss_cls: 0.3600  decode.d4.loss_mask: 1.4997  decode.d4.loss_dice: 1.0272  decode.d5.loss_cls: 0.3592  decode.d5.loss_mask: 1.4650  decode.d5.loss_dice: 1.0673  decode.d6.loss_cls: 0.3646  decode.d6.loss_mask: 1.4629  decode.d6.loss_dice: 1.0728  decode.d7.loss_cls: 0.4036  decode.d7.loss_mask: 1.5057  decode.d7.loss_dice: 1.0729  decode.d8.loss_cls: 0.3911  decode.d8.loss_mask: 1.4652  decode.d8.loss_dice: 1.0148
05/26 15:24:24 - mmengine - INFO - Iter(train) [ 38250/160000]  base_lr: 7.8202e-05 lr: 7.8202e-06  eta: 13:52:12  time: 0.4105  data_time: 0.0094  memory: 5966  grad_norm: 1085.9806  loss: 24.1612  decode.loss_cls: 0.2494  decode.loss_mask: 1.2153  decode.loss_dice: 0.9029  decode.d0.loss_cls: 0.7966  decode.d0.loss_mask: 1.1380  decode.d0.loss_dice: 0.8411  decode.d1.loss_cls: 0.2134  decode.d1.loss_mask: 1.2402  decode.d1.loss_dice: 0.8842  decode.d2.loss_cls: 0.2343  decode.d2.loss_mask: 1.2532  decode.d2.loss_dice: 0.8987  decode.d3.loss_cls: 0.2661  decode.d3.loss_mask: 1.2480  decode.d3.loss_dice: 0.9054  decode.d4.loss_cls: 0.2486  decode.d4.loss_mask: 1.2079  decode.d4.loss_dice: 0.8779  decode.d5.loss_cls: 0.2524  decode.d5.loss_mask: 1.2275  decode.d5.loss_dice: 0.9102  decode.d6.loss_cls: 0.2540  decode.d6.loss_mask: 1.2821  decode.d6.loss_dice: 0.9175  decode.d7.loss_cls: 0.2408  decode.d7.loss_mask: 1.2324  decode.d7.loss_dice: 0.9144  decode.d8.loss_cls: 0.2109  decode.d8.loss_mask: 1.2133  decode.d8.loss_dice: 0.8845
05/26 15:24:45 - mmengine - INFO - Iter(train) [ 38300/160000]  base_lr: 7.8173e-05 lr: 7.8173e-06  eta: 13:51:52  time: 0.4102  data_time: 0.0094  memory: 5969  grad_norm: 765.8554  loss: 23.4587  decode.loss_cls: 0.2809  decode.loss_mask: 1.2082  decode.loss_dice: 0.8381  decode.d0.loss_cls: 0.8286  decode.d0.loss_mask: 1.1332  decode.d0.loss_dice: 0.8648  decode.d1.loss_cls: 0.2797  decode.d1.loss_mask: 1.1093  decode.d1.loss_dice: 0.8799  decode.d2.loss_cls: 0.3054  decode.d2.loss_mask: 1.1330  decode.d2.loss_dice: 0.8617  decode.d3.loss_cls: 0.2727  decode.d3.loss_mask: 1.1416  decode.d3.loss_dice: 0.8580  decode.d4.loss_cls: 0.2562  decode.d4.loss_mask: 1.1868  decode.d4.loss_dice: 0.8624  decode.d5.loss_cls: 0.2581  decode.d5.loss_mask: 1.1572  decode.d5.loss_dice: 0.8575  decode.d6.loss_cls: 0.3067  decode.d6.loss_mask: 1.1061  decode.d6.loss_dice: 0.8376  decode.d7.loss_cls: 0.2658  decode.d7.loss_mask: 1.1639  decode.d7.loss_dice: 0.8849  decode.d8.loss_cls: 0.2581  decode.d8.loss_mask: 1.2004  decode.d8.loss_dice: 0.8619
05/26 15:25:05 - mmengine - INFO - Iter(train) [ 38350/160000]  base_lr: 7.8144e-05 lr: 7.8144e-06  eta: 13:51:31  time: 0.4092  data_time: 0.0092  memory: 5981  grad_norm: 545.1573  loss: 26.4615  decode.loss_cls: 0.4152  decode.loss_mask: 1.3514  decode.loss_dice: 0.9152  decode.d0.loss_cls: 0.8829  decode.d0.loss_mask: 1.1825  decode.d0.loss_dice: 0.8889  decode.d1.loss_cls: 0.3820  decode.d1.loss_mask: 1.2856  decode.d1.loss_dice: 0.8849  decode.d2.loss_cls: 0.4661  decode.d2.loss_mask: 1.2723  decode.d2.loss_dice: 0.9048  decode.d3.loss_cls: 0.4368  decode.d3.loss_mask: 1.2898  decode.d3.loss_dice: 0.9082  decode.d4.loss_cls: 0.4451  decode.d4.loss_mask: 1.2979  decode.d4.loss_dice: 0.9159  decode.d5.loss_cls: 0.3848  decode.d5.loss_mask: 1.3646  decode.d5.loss_dice: 0.8760  decode.d6.loss_cls: 0.4226  decode.d6.loss_mask: 1.2835  decode.d6.loss_dice: 0.8740  decode.d7.loss_cls: 0.3940  decode.d7.loss_mask: 1.3346  decode.d7.loss_dice: 0.8773  decode.d8.loss_cls: 0.3680  decode.d8.loss_mask: 1.2984  decode.d8.loss_dice: 0.8581
05/26 15:25:26 - mmengine - INFO - Iter(train) [ 38400/160000]  base_lr: 7.8115e-05 lr: 7.8115e-06  eta: 13:51:10  time: 0.4109  data_time: 0.0093  memory: 5971  grad_norm: 557.8688  loss: 25.5288  decode.loss_cls: 0.2488  decode.loss_mask: 1.3810  decode.loss_dice: 0.8966  decode.d0.loss_cls: 0.6994  decode.d0.loss_mask: 1.2790  decode.d0.loss_dice: 0.8688  decode.d1.loss_cls: 0.2692  decode.d1.loss_mask: 1.3738  decode.d1.loss_dice: 0.9250  decode.d2.loss_cls: 0.2893  decode.d2.loss_mask: 1.3135  decode.d2.loss_dice: 0.8943  decode.d3.loss_cls: 0.2977  decode.d3.loss_mask: 1.2909  decode.d3.loss_dice: 0.9059  decode.d4.loss_cls: 0.3190  decode.d4.loss_mask: 1.2998  decode.d4.loss_dice: 0.9168  decode.d5.loss_cls: 0.3073  decode.d5.loss_mask: 1.2969  decode.d5.loss_dice: 0.9273  decode.d6.loss_cls: 0.2913  decode.d6.loss_mask: 1.3142  decode.d6.loss_dice: 0.9095  decode.d7.loss_cls: 0.2784  decode.d7.loss_mask: 1.3483  decode.d7.loss_dice: 0.8946  decode.d8.loss_cls: 0.2825  decode.d8.loss_mask: 1.3259  decode.d8.loss_dice: 0.8838
05/26 15:25:46 - mmengine - INFO - Iter(train) [ 38450/160000]  base_lr: 7.8086e-05 lr: 7.8086e-06  eta: 13:50:50  time: 0.4102  data_time: 0.0093  memory: 5969  grad_norm: 930.9825  loss: 23.2624  decode.loss_cls: 0.1924  decode.loss_mask: 1.2242  decode.loss_dice: 0.7875  decode.d0.loss_cls: 0.7461  decode.d0.loss_mask: 1.2229  decode.d0.loss_dice: 0.7790  decode.d1.loss_cls: 0.2054  decode.d1.loss_mask: 1.2263  decode.d1.loss_dice: 0.8219  decode.d2.loss_cls: 0.1965  decode.d2.loss_mask: 1.2651  decode.d2.loss_dice: 0.8235  decode.d3.loss_cls: 0.2014  decode.d3.loss_mask: 1.2662  decode.d3.loss_dice: 0.8351  decode.d4.loss_cls: 0.1998  decode.d4.loss_mask: 1.3121  decode.d4.loss_dice: 0.8331  decode.d5.loss_cls: 0.2167  decode.d5.loss_mask: 1.2337  decode.d5.loss_dice: 0.8157  decode.d6.loss_cls: 0.1558  decode.d6.loss_mask: 1.2908  decode.d6.loss_dice: 0.8264  decode.d7.loss_cls: 0.2095  decode.d7.loss_mask: 1.2733  decode.d7.loss_dice: 0.8248  decode.d8.loss_cls: 0.2213  decode.d8.loss_mask: 1.2384  decode.d8.loss_dice: 0.8178
05/26 15:26:07 - mmengine - INFO - Iter(train) [ 38500/160000]  base_lr: 7.8057e-05 lr: 7.8057e-06  eta: 13:50:29  time: 0.4116  data_time: 0.0093  memory: 5966  grad_norm: 1071.7912  loss: 27.2852  decode.loss_cls: 0.4072  decode.loss_mask: 1.3399  decode.loss_dice: 0.9343  decode.d0.loss_cls: 0.8213  decode.d0.loss_mask: 1.2989  decode.d0.loss_dice: 0.9034  decode.d1.loss_cls: 0.4201  decode.d1.loss_mask: 1.3128  decode.d1.loss_dice: 0.9080  decode.d2.loss_cls: 0.3532  decode.d2.loss_mask: 1.3773  decode.d2.loss_dice: 1.0064  decode.d3.loss_cls: 0.3567  decode.d3.loss_mask: 1.3846  decode.d3.loss_dice: 0.9216  decode.d4.loss_cls: 0.4477  decode.d4.loss_mask: 1.3606  decode.d4.loss_dice: 0.9193  decode.d5.loss_cls: 0.4264  decode.d5.loss_mask: 1.3222  decode.d5.loss_dice: 0.9267  decode.d6.loss_cls: 0.4273  decode.d6.loss_mask: 1.4118  decode.d6.loss_dice: 0.9993  decode.d7.loss_cls: 0.3674  decode.d7.loss_mask: 1.3444  decode.d7.loss_dice: 0.9272  decode.d8.loss_cls: 0.3494  decode.d8.loss_mask: 1.3769  decode.d8.loss_dice: 0.9332
05/26 15:26:27 - mmengine - INFO - Iter(train) [ 38550/160000]  base_lr: 7.8028e-05 lr: 7.8028e-06  eta: 13:50:09  time: 0.4096  data_time: 0.0092  memory: 5977  grad_norm: 755.1958  loss: 23.5426  decode.loss_cls: 0.2556  decode.loss_mask: 1.2000  decode.loss_dice: 0.8115  decode.d0.loss_cls: 0.7439  decode.d0.loss_mask: 1.1318  decode.d0.loss_dice: 0.8088  decode.d1.loss_cls: 0.2841  decode.d1.loss_mask: 1.2467  decode.d1.loss_dice: 0.8594  decode.d2.loss_cls: 0.2728  decode.d2.loss_mask: 1.2542  decode.d2.loss_dice: 0.8406  decode.d3.loss_cls: 0.2955  decode.d3.loss_mask: 1.2014  decode.d3.loss_dice: 0.8400  decode.d4.loss_cls: 0.2726  decode.d4.loss_mask: 1.1955  decode.d4.loss_dice: 0.8539  decode.d5.loss_cls: 0.2577  decode.d5.loss_mask: 1.2038  decode.d5.loss_dice: 0.8447  decode.d6.loss_cls: 0.2374  decode.d6.loss_mask: 1.2013  decode.d6.loss_dice: 0.8117  decode.d7.loss_cls: 0.2804  decode.d7.loss_mask: 1.2183  decode.d7.loss_dice: 0.8263  decode.d8.loss_cls: 0.2595  decode.d8.loss_mask: 1.2209  decode.d8.loss_dice: 0.8123
05/26 15:26:48 - mmengine - INFO - Iter(train) [ 38600/160000]  base_lr: 7.7999e-05 lr: 7.7999e-06  eta: 13:49:48  time: 0.4103  data_time: 0.0093  memory: 5989  grad_norm: 593.5071  loss: 23.1486  decode.loss_cls: 0.3047  decode.loss_mask: 1.1184  decode.loss_dice: 0.7936  decode.d0.loss_cls: 0.8310  decode.d0.loss_mask: 1.0672  decode.d0.loss_dice: 0.7726  decode.d1.loss_cls: 0.3516  decode.d1.loss_mask: 1.1336  decode.d1.loss_dice: 0.8131  decode.d2.loss_cls: 0.2693  decode.d2.loss_mask: 1.1758  decode.d2.loss_dice: 0.8502  decode.d3.loss_cls: 0.2901  decode.d3.loss_mask: 1.1710  decode.d3.loss_dice: 0.8426  decode.d4.loss_cls: 0.2777  decode.d4.loss_mask: 1.1542  decode.d4.loss_dice: 0.8522  decode.d5.loss_cls: 0.3034  decode.d5.loss_mask: 1.1073  decode.d5.loss_dice: 0.7955  decode.d6.loss_cls: 0.2836  decode.d6.loss_mask: 1.1312  decode.d6.loss_dice: 0.8607  decode.d7.loss_cls: 0.3121  decode.d7.loss_mask: 1.1520  decode.d7.loss_dice: 0.8479  decode.d8.loss_cls: 0.2991  decode.d8.loss_mask: 1.1534  decode.d8.loss_dice: 0.8332
05/26 15:27:08 - mmengine - INFO - Iter(train) [ 38650/160000]  base_lr: 7.7970e-05 lr: 7.7970e-06  eta: 13:49:28  time: 0.4115  data_time: 0.0093  memory: 5966  grad_norm: 829.5196  loss: 23.9388  decode.loss_cls: 0.3535  decode.loss_mask: 1.1564  decode.loss_dice: 0.8792  decode.d0.loss_cls: 0.7875  decode.d0.loss_mask: 1.0811  decode.d0.loss_dice: 0.8302  decode.d1.loss_cls: 0.3031  decode.d1.loss_mask: 1.1437  decode.d1.loss_dice: 0.8618  decode.d2.loss_cls: 0.3417  decode.d2.loss_mask: 1.1537  decode.d2.loss_dice: 0.8865  decode.d3.loss_cls: 0.3253  decode.d3.loss_mask: 1.1605  decode.d3.loss_dice: 0.8856  decode.d4.loss_cls: 0.3588  decode.d4.loss_mask: 1.1526  decode.d4.loss_dice: 0.8542  decode.d5.loss_cls: 0.3292  decode.d5.loss_mask: 1.1252  decode.d5.loss_dice: 0.8737  decode.d6.loss_cls: 0.3341  decode.d6.loss_mask: 1.1711  decode.d6.loss_dice: 0.9310  decode.d7.loss_cls: 0.3322  decode.d7.loss_mask: 1.1218  decode.d7.loss_dice: 0.8406  decode.d8.loss_cls: 0.3504  decode.d8.loss_mask: 1.1523  decode.d8.loss_dice: 0.8618
05/26 15:27:29 - mmengine - INFO - Iter(train) [ 38700/160000]  base_lr: 7.7942e-05 lr: 7.7942e-06  eta: 13:49:07  time: 0.4114  data_time: 0.0093  memory: 5976  grad_norm: 835.5488  loss: 25.1847  decode.loss_cls: 0.3092  decode.loss_mask: 1.3001  decode.loss_dice: 0.8742  decode.d0.loss_cls: 0.7557  decode.d0.loss_mask: 1.2539  decode.d0.loss_dice: 0.8347  decode.d1.loss_cls: 0.3007  decode.d1.loss_mask: 1.2844  decode.d1.loss_dice: 0.8877  decode.d2.loss_cls: 0.3049  decode.d2.loss_mask: 1.2812  decode.d2.loss_dice: 0.9308  decode.d3.loss_cls: 0.2935  decode.d3.loss_mask: 1.2616  decode.d3.loss_dice: 0.8766  decode.d4.loss_cls: 0.3085  decode.d4.loss_mask: 1.2781  decode.d4.loss_dice: 0.8806  decode.d5.loss_cls: 0.2840  decode.d5.loss_mask: 1.3017  decode.d5.loss_dice: 0.8851  decode.d6.loss_cls: 0.3457  decode.d6.loss_mask: 1.2640  decode.d6.loss_dice: 0.8850  decode.d7.loss_cls: 0.2687  decode.d7.loss_mask: 1.3113  decode.d7.loss_dice: 0.9059  decode.d8.loss_cls: 0.2443  decode.d8.loss_mask: 1.3717  decode.d8.loss_dice: 0.9008
05/26 15:27:49 - mmengine - INFO - Iter(train) [ 38750/160000]  base_lr: 7.7913e-05 lr: 7.7913e-06  eta: 13:48:47  time: 0.4102  data_time: 0.0093  memory: 5974  grad_norm: 576.3207  loss: 26.5312  decode.loss_cls: 0.3748  decode.loss_mask: 1.2173  decode.loss_dice: 1.0482  decode.d0.loss_cls: 0.8970  decode.d0.loss_mask: 1.1158  decode.d0.loss_dice: 0.9787  decode.d1.loss_cls: 0.3944  decode.d1.loss_mask: 1.1924  decode.d1.loss_dice: 1.0057  decode.d2.loss_cls: 0.4202  decode.d2.loss_mask: 1.1866  decode.d2.loss_dice: 1.0321  decode.d3.loss_cls: 0.4369  decode.d3.loss_mask: 1.1850  decode.d3.loss_dice: 1.0085  decode.d4.loss_cls: 0.4141  decode.d4.loss_mask: 1.2026  decode.d4.loss_dice: 1.0382  decode.d5.loss_cls: 0.3759  decode.d5.loss_mask: 1.1908  decode.d5.loss_dice: 0.9855  decode.d6.loss_cls: 0.3814  decode.d6.loss_mask: 1.2237  decode.d6.loss_dice: 1.0081  decode.d7.loss_cls: 0.3835  decode.d7.loss_mask: 1.2023  decode.d7.loss_dice: 1.0018  decode.d8.loss_cls: 0.3825  decode.d8.loss_mask: 1.2401  decode.d8.loss_dice: 1.0070
05/26 15:28:10 - mmengine - INFO - Iter(train) [ 38800/160000]  base_lr: 7.7884e-05 lr: 7.7884e-06  eta: 13:48:26  time: 0.4125  data_time: 0.0093  memory: 5968  grad_norm: 500.1562  loss: 25.9035  decode.loss_cls: 0.2847  decode.loss_mask: 1.3551  decode.loss_dice: 0.8911  decode.d0.loss_cls: 0.7440  decode.d0.loss_mask: 1.2994  decode.d0.loss_dice: 0.8708  decode.d1.loss_cls: 0.3503  decode.d1.loss_mask: 1.3162  decode.d1.loss_dice: 0.8775  decode.d2.loss_cls: 0.3405  decode.d2.loss_mask: 1.3393  decode.d2.loss_dice: 0.8820  decode.d3.loss_cls: 0.3578  decode.d3.loss_mask: 1.3122  decode.d3.loss_dice: 0.8699  decode.d4.loss_cls: 0.3679  decode.d4.loss_mask: 1.2988  decode.d4.loss_dice: 0.8859  decode.d5.loss_cls: 0.4023  decode.d5.loss_mask: 1.3249  decode.d5.loss_dice: 0.8700  decode.d6.loss_cls: 0.3440  decode.d6.loss_mask: 1.3255  decode.d6.loss_dice: 0.8765  decode.d7.loss_cls: 0.3790  decode.d7.loss_mask: 1.3376  decode.d7.loss_dice: 0.8906  decode.d8.loss_cls: 0.3305  decode.d8.loss_mask: 1.3262  decode.d8.loss_dice: 0.8529
05/26 15:28:30 - mmengine - INFO - Iter(train) [ 38850/160000]  base_lr: 7.7855e-05 lr: 7.7855e-06  eta: 13:48:06  time: 0.4091  data_time: 0.0093  memory: 5990  grad_norm: 455.8180  loss: 23.5356  decode.loss_cls: 0.3335  decode.loss_mask: 1.0680  decode.loss_dice: 0.8935  decode.d0.loss_cls: 0.7695  decode.d0.loss_mask: 1.0443  decode.d0.loss_dice: 0.8689  decode.d1.loss_cls: 0.3185  decode.d1.loss_mask: 1.1063  decode.d1.loss_dice: 0.8709  decode.d2.loss_cls: 0.2832  decode.d2.loss_mask: 1.1222  decode.d2.loss_dice: 0.9172  decode.d3.loss_cls: 0.3200  decode.d3.loss_mask: 1.1306  decode.d3.loss_dice: 0.9152  decode.d4.loss_cls: 0.3232  decode.d4.loss_mask: 1.0566  decode.d4.loss_dice: 0.8922  decode.d5.loss_cls: 0.3452  decode.d5.loss_mask: 1.0473  decode.d5.loss_dice: 0.8739  decode.d6.loss_cls: 0.3651  decode.d6.loss_mask: 1.0934  decode.d6.loss_dice: 0.8957  decode.d7.loss_cls: 0.3142  decode.d7.loss_mask: 1.1170  decode.d7.loss_dice: 0.9026  decode.d8.loss_cls: 0.3032  decode.d8.loss_mask: 1.1238  decode.d8.loss_dice: 0.9207
05/26 15:28:51 - mmengine - INFO - Iter(train) [ 38900/160000]  base_lr: 7.7826e-05 lr: 7.7826e-06  eta: 13:47:45  time: 0.4102  data_time: 0.0092  memory: 5984  grad_norm: 467.6376  loss: 22.3732  decode.loss_cls: 0.2862  decode.loss_mask: 1.0820  decode.loss_dice: 0.8431  decode.d0.loss_cls: 0.7019  decode.d0.loss_mask: 1.0264  decode.d0.loss_dice: 0.8065  decode.d1.loss_cls: 0.2600  decode.d1.loss_mask: 1.1034  decode.d1.loss_dice: 0.8235  decode.d2.loss_cls: 0.2553  decode.d2.loss_mask: 1.1076  decode.d2.loss_dice: 0.8907  decode.d3.loss_cls: 0.2919  decode.d3.loss_mask: 1.0619  decode.d3.loss_dice: 0.8685  decode.d4.loss_cls: 0.2880  decode.d4.loss_mask: 1.0855  decode.d4.loss_dice: 0.8430  decode.d5.loss_cls: 0.3556  decode.d5.loss_mask: 1.0663  decode.d5.loss_dice: 0.8140  decode.d6.loss_cls: 0.2360  decode.d6.loss_mask: 1.0620  decode.d6.loss_dice: 0.8329  decode.d7.loss_cls: 0.2567  decode.d7.loss_mask: 1.0639  decode.d7.loss_dice: 0.8507  decode.d8.loss_cls: 0.3049  decode.d8.loss_mask: 1.0763  decode.d8.loss_dice: 0.8284
05/26 15:29:11 - mmengine - INFO - Iter(train) [ 38950/160000]  base_lr: 7.7797e-05 lr: 7.7797e-06  eta: 13:47:24  time: 0.4097  data_time: 0.0092  memory: 5976  grad_norm: 458.9135  loss: 23.0672  decode.loss_cls: 0.3140  decode.loss_mask: 1.0512  decode.loss_dice: 0.8813  decode.d0.loss_cls: 0.8245  decode.d0.loss_mask: 0.9764  decode.d0.loss_dice: 0.8742  decode.d1.loss_cls: 0.2629  decode.d1.loss_mask: 1.0567  decode.d1.loss_dice: 0.8821  decode.d2.loss_cls: 0.3783  decode.d2.loss_mask: 1.0856  decode.d2.loss_dice: 0.8702  decode.d3.loss_cls: 0.2889  decode.d3.loss_mask: 1.0976  decode.d3.loss_dice: 0.8534  decode.d4.loss_cls: 0.3130  decode.d4.loss_mask: 1.0232  decode.d4.loss_dice: 0.8927  decode.d5.loss_cls: 0.3248  decode.d5.loss_mask: 1.0784  decode.d5.loss_dice: 0.8854  decode.d6.loss_cls: 0.3104  decode.d6.loss_mask: 1.0783  decode.d6.loss_dice: 0.8790  decode.d7.loss_cls: 0.3540  decode.d7.loss_mask: 1.0940  decode.d7.loss_dice: 0.8607  decode.d8.loss_cls: 0.3406  decode.d8.loss_mask: 1.0664  decode.d8.loss_dice: 0.8690
05/26 15:29:32 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 15:29:32 - mmengine - INFO - Iter(train) [ 39000/160000]  base_lr: 7.7768e-05 lr: 7.7768e-06  eta: 13:47:04  time: 0.4101  data_time: 0.0094  memory: 5975  grad_norm: 970.7650  loss: 26.1585  decode.loss_cls: 0.2558  decode.loss_mask: 1.3816  decode.loss_dice: 0.9077  decode.d0.loss_cls: 0.8088  decode.d0.loss_mask: 1.3483  decode.d0.loss_dice: 0.8986  decode.d1.loss_cls: 0.2234  decode.d1.loss_mask: 1.4190  decode.d1.loss_dice: 0.9273  decode.d2.loss_cls: 0.2365  decode.d2.loss_mask: 1.4228  decode.d2.loss_dice: 0.9303  decode.d3.loss_cls: 0.2013  decode.d3.loss_mask: 1.4106  decode.d3.loss_dice: 0.9129  decode.d4.loss_cls: 0.2194  decode.d4.loss_mask: 1.4128  decode.d4.loss_dice: 0.9143  decode.d5.loss_cls: 0.2541  decode.d5.loss_mask: 1.3935  decode.d5.loss_dice: 0.9126  decode.d6.loss_cls: 0.2147  decode.d6.loss_mask: 1.4516  decode.d6.loss_dice: 0.9425  decode.d7.loss_cls: 0.2138  decode.d7.loss_mask: 1.4540  decode.d7.loss_dice: 0.9261  decode.d8.loss_cls: 0.2345  decode.d8.loss_mask: 1.3993  decode.d8.loss_dice: 0.9305
05/26 15:29:52 - mmengine - INFO - Iter(train) [ 39050/160000]  base_lr: 7.7739e-05 lr: 7.7739e-06  eta: 13:46:43  time: 0.4089  data_time: 0.0092  memory: 5971  grad_norm: 827.2412  loss: 26.2884  decode.loss_cls: 0.4041  decode.loss_mask: 1.1488  decode.loss_dice: 1.0883  decode.d0.loss_cls: 0.9035  decode.d0.loss_mask: 1.0782  decode.d0.loss_dice: 0.9716  decode.d1.loss_cls: 0.3384  decode.d1.loss_mask: 1.1429  decode.d1.loss_dice: 1.0967  decode.d2.loss_cls: 0.3995  decode.d2.loss_mask: 1.1281  decode.d2.loss_dice: 1.0713  decode.d3.loss_cls: 0.3941  decode.d3.loss_mask: 1.1241  decode.d3.loss_dice: 1.0259  decode.d4.loss_cls: 0.3794  decode.d4.loss_mask: 1.1094  decode.d4.loss_dice: 1.0508  decode.d5.loss_cls: 0.3819  decode.d5.loss_mask: 1.1415  decode.d5.loss_dice: 1.0392  decode.d6.loss_cls: 0.4509  decode.d6.loss_mask: 1.1151  decode.d6.loss_dice: 1.0618  decode.d7.loss_cls: 0.4018  decode.d7.loss_mask: 1.1183  decode.d7.loss_dice: 1.0521  decode.d8.loss_cls: 0.4312  decode.d8.loss_mask: 1.1584  decode.d8.loss_dice: 1.0809
05/26 15:30:13 - mmengine - INFO - Iter(train) [ 39100/160000]  base_lr: 7.7710e-05 lr: 7.7710e-06  eta: 13:46:23  time: 0.4103  data_time: 0.0092  memory: 5967  grad_norm: 494.5227  loss: 22.4066  decode.loss_cls: 0.2562  decode.loss_mask: 1.1361  decode.loss_dice: 0.7916  decode.d0.loss_cls: 0.7042  decode.d0.loss_mask: 1.1392  decode.d0.loss_dice: 0.8083  decode.d1.loss_cls: 0.3074  decode.d1.loss_mask: 1.1245  decode.d1.loss_dice: 0.8009  decode.d2.loss_cls: 0.2964  decode.d2.loss_mask: 1.0777  decode.d2.loss_dice: 0.7704  decode.d3.loss_cls: 0.2708  decode.d3.loss_mask: 1.0974  decode.d3.loss_dice: 0.8101  decode.d4.loss_cls: 0.2539  decode.d4.loss_mask: 1.1273  decode.d4.loss_dice: 0.7997  decode.d5.loss_cls: 0.2812  decode.d5.loss_mask: 1.0921  decode.d5.loss_dice: 0.7889  decode.d6.loss_cls: 0.3212  decode.d6.loss_mask: 1.0926  decode.d6.loss_dice: 0.7913  decode.d7.loss_cls: 0.2609  decode.d7.loss_mask: 1.1490  decode.d7.loss_dice: 0.8246  decode.d8.loss_cls: 0.2529  decode.d8.loss_mask: 1.1551  decode.d8.loss_dice: 0.8247
05/26 15:30:33 - mmengine - INFO - Iter(train) [ 39150/160000]  base_lr: 7.7681e-05 lr: 7.7681e-06  eta: 13:46:03  time: 0.4165  data_time: 0.0126  memory: 5979  grad_norm: 620.8406  loss: 25.8583  decode.loss_cls: 0.4143  decode.loss_mask: 1.0990  decode.loss_dice: 1.0230  decode.d0.loss_cls: 0.8778  decode.d0.loss_mask: 1.0668  decode.d0.loss_dice: 0.9966  decode.d1.loss_cls: 0.3702  decode.d1.loss_mask: 1.1220  decode.d1.loss_dice: 1.0395  decode.d2.loss_cls: 0.4108  decode.d2.loss_mask: 1.1023  decode.d2.loss_dice: 0.9886  decode.d3.loss_cls: 0.4218  decode.d3.loss_mask: 1.0971  decode.d3.loss_dice: 1.0418  decode.d4.loss_cls: 0.3848  decode.d4.loss_mask: 1.1117  decode.d4.loss_dice: 1.0269  decode.d5.loss_cls: 0.4154  decode.d5.loss_mask: 1.1104  decode.d5.loss_dice: 1.0457  decode.d6.loss_cls: 0.3894  decode.d6.loss_mask: 1.0854  decode.d6.loss_dice: 1.0556  decode.d7.loss_cls: 0.4881  decode.d7.loss_mask: 1.0986  decode.d7.loss_dice: 1.0534  decode.d8.loss_cls: 0.4065  decode.d8.loss_mask: 1.1035  decode.d8.loss_dice: 1.0113
05/26 15:30:54 - mmengine - INFO - Iter(train) [ 39200/160000]  base_lr: 7.7652e-05 lr: 7.7652e-06  eta: 13:45:42  time: 0.4090  data_time: 0.0092  memory: 5982  grad_norm: 1239.2143  loss: 25.6035  decode.loss_cls: 0.4353  decode.loss_mask: 1.0888  decode.loss_dice: 0.9340  decode.d0.loss_cls: 0.8589  decode.d0.loss_mask: 1.1108  decode.d0.loss_dice: 0.9299  decode.d1.loss_cls: 0.4290  decode.d1.loss_mask: 1.1391  decode.d1.loss_dice: 0.9175  decode.d2.loss_cls: 0.4517  decode.d2.loss_mask: 1.1920  decode.d2.loss_dice: 0.9317  decode.d3.loss_cls: 0.3933  decode.d3.loss_mask: 1.1702  decode.d3.loss_dice: 0.9786  decode.d4.loss_cls: 0.4473  decode.d4.loss_mask: 1.1539  decode.d4.loss_dice: 0.9899  decode.d5.loss_cls: 0.4580  decode.d5.loss_mask: 1.1104  decode.d5.loss_dice: 0.9594  decode.d6.loss_cls: 0.4506  decode.d6.loss_mask: 1.1427  decode.d6.loss_dice: 0.9950  decode.d7.loss_cls: 0.4075  decode.d7.loss_mask: 1.1150  decode.d7.loss_dice: 0.9558  decode.d8.loss_cls: 0.4302  decode.d8.loss_mask: 1.1082  decode.d8.loss_dice: 0.9189
05/26 15:31:14 - mmengine - INFO - Iter(train) [ 39250/160000]  base_lr: 7.7623e-05 lr: 7.7623e-06  eta: 13:45:22  time: 0.4086  data_time: 0.0092  memory: 5966  grad_norm: 533.9008  loss: 23.3327  decode.loss_cls: 0.2414  decode.loss_mask: 1.2084  decode.loss_dice: 0.8152  decode.d0.loss_cls: 0.6551  decode.d0.loss_mask: 1.1719  decode.d0.loss_dice: 0.7988  decode.d1.loss_cls: 0.2699  decode.d1.loss_mask: 1.2109  decode.d1.loss_dice: 0.8095  decode.d2.loss_cls: 0.2509  decode.d2.loss_mask: 1.1906  decode.d2.loss_dice: 0.8331  decode.d3.loss_cls: 0.2308  decode.d3.loss_mask: 1.2189  decode.d3.loss_dice: 0.8323  decode.d4.loss_cls: 0.2784  decode.d4.loss_mask: 1.1998  decode.d4.loss_dice: 0.8202  decode.d5.loss_cls: 0.2167  decode.d5.loss_mask: 1.2118  decode.d5.loss_dice: 0.8579  decode.d6.loss_cls: 0.2271  decode.d6.loss_mask: 1.2585  decode.d6.loss_dice: 0.9084  decode.d7.loss_cls: 0.2692  decode.d7.loss_mask: 1.2509  decode.d7.loss_dice: 0.8686  decode.d8.loss_cls: 0.2671  decode.d8.loss_mask: 1.1607  decode.d8.loss_dice: 0.7999
05/26 15:31:35 - mmengine - INFO - Iter(train) [ 39300/160000]  base_lr: 7.7595e-05 lr: 7.7595e-06  eta: 13:45:01  time: 0.4089  data_time: 0.0091  memory: 5971  grad_norm: 1023.4828  loss: 26.0943  decode.loss_cls: 0.3949  decode.loss_mask: 1.2552  decode.loss_dice: 0.9883  decode.d0.loss_cls: 0.8857  decode.d0.loss_mask: 1.1465  decode.d0.loss_dice: 0.9308  decode.d1.loss_cls: 0.3488  decode.d1.loss_mask: 1.2003  decode.d1.loss_dice: 0.9712  decode.d2.loss_cls: 0.3753  decode.d2.loss_mask: 1.1969  decode.d2.loss_dice: 0.9489  decode.d3.loss_cls: 0.3495  decode.d3.loss_mask: 1.2459  decode.d3.loss_dice: 0.9986  decode.d4.loss_cls: 0.3951  decode.d4.loss_mask: 1.2117  decode.d4.loss_dice: 0.9572  decode.d5.loss_cls: 0.3845  decode.d5.loss_mask: 1.1697  decode.d5.loss_dice: 0.9458  decode.d6.loss_cls: 0.4158  decode.d6.loss_mask: 1.1981  decode.d6.loss_dice: 0.9687  decode.d7.loss_cls: 0.4371  decode.d7.loss_mask: 1.2159  decode.d7.loss_dice: 0.9791  decode.d8.loss_cls: 0.4021  decode.d8.loss_mask: 1.2210  decode.d8.loss_dice: 0.9556
05/26 15:31:55 - mmengine - INFO - Iter(train) [ 39350/160000]  base_lr: 7.7566e-05 lr: 7.7566e-06  eta: 13:44:41  time: 0.4095  data_time: 0.0092  memory: 5975  grad_norm: 436.8782  loss: 27.8519  decode.loss_cls: 0.3592  decode.loss_mask: 1.3426  decode.loss_dice: 1.0340  decode.d0.loss_cls: 0.9811  decode.d0.loss_mask: 1.2927  decode.d0.loss_dice: 1.0668  decode.d1.loss_cls: 0.3200  decode.d1.loss_mask: 1.3188  decode.d1.loss_dice: 1.0666  decode.d2.loss_cls: 0.2991  decode.d2.loss_mask: 1.3313  decode.d2.loss_dice: 1.0506  decode.d3.loss_cls: 0.3058  decode.d3.loss_mask: 1.3032  decode.d3.loss_dice: 1.0786  decode.d4.loss_cls: 0.3683  decode.d4.loss_mask: 1.2893  decode.d4.loss_dice: 1.0597  decode.d5.loss_cls: 0.3760  decode.d5.loss_mask: 1.3087  decode.d5.loss_dice: 1.0574  decode.d6.loss_cls: 0.3423  decode.d6.loss_mask: 1.3200  decode.d6.loss_dice: 1.0767  decode.d7.loss_cls: 0.3290  decode.d7.loss_mask: 1.3404  decode.d7.loss_dice: 1.0947  decode.d8.loss_cls: 0.2951  decode.d8.loss_mask: 1.3542  decode.d8.loss_dice: 1.0900
05/26 15:32:16 - mmengine - INFO - Iter(train) [ 39400/160000]  base_lr: 7.7537e-05 lr: 7.7537e-06  eta: 13:44:20  time: 0.4085  data_time: 0.0092  memory: 5980  grad_norm: 480.7587  loss: 22.6685  decode.loss_cls: 0.3238  decode.loss_mask: 1.0929  decode.loss_dice: 0.8362  decode.d0.loss_cls: 0.8101  decode.d0.loss_mask: 0.9756  decode.d0.loss_dice: 0.7805  decode.d1.loss_cls: 0.3620  decode.d1.loss_mask: 1.0149  decode.d1.loss_dice: 0.8404  decode.d2.loss_cls: 0.3228  decode.d2.loss_mask: 1.0523  decode.d2.loss_dice: 0.8543  decode.d3.loss_cls: 0.3713  decode.d3.loss_mask: 1.0145  decode.d3.loss_dice: 0.8007  decode.d4.loss_cls: 0.3813  decode.d4.loss_mask: 1.0402  decode.d4.loss_dice: 0.8215  decode.d5.loss_cls: 0.3950  decode.d5.loss_mask: 1.0467  decode.d5.loss_dice: 0.7806  decode.d6.loss_cls: 0.4495  decode.d6.loss_mask: 0.9718  decode.d6.loss_dice: 0.8059  decode.d7.loss_cls: 0.3406  decode.d7.loss_mask: 1.1061  decode.d7.loss_dice: 0.8362  decode.d8.loss_cls: 0.3672  decode.d8.loss_mask: 1.0371  decode.d8.loss_dice: 0.8363
05/26 15:32:36 - mmengine - INFO - Iter(train) [ 39450/160000]  base_lr: 7.7508e-05 lr: 7.7508e-06  eta: 13:44:00  time: 0.4082  data_time: 0.0092  memory: 5986  grad_norm: 449.0406  loss: 22.2238  decode.loss_cls: 0.2157  decode.loss_mask: 1.1540  decode.loss_dice: 0.7914  decode.d0.loss_cls: 0.7290  decode.d0.loss_mask: 1.1312  decode.d0.loss_dice: 0.7864  decode.d1.loss_cls: 0.2740  decode.d1.loss_mask: 1.1523  decode.d1.loss_dice: 0.8018  decode.d2.loss_cls: 0.2127  decode.d2.loss_mask: 1.1375  decode.d2.loss_dice: 0.8296  decode.d3.loss_cls: 0.2184  decode.d3.loss_mask: 1.1744  decode.d3.loss_dice: 0.8352  decode.d4.loss_cls: 0.2647  decode.d4.loss_mask: 1.0710  decode.d4.loss_dice: 0.7736  decode.d5.loss_cls: 0.2708  decode.d5.loss_mask: 1.1295  decode.d5.loss_dice: 0.7904  decode.d6.loss_cls: 0.2700  decode.d6.loss_mask: 1.1357  decode.d6.loss_dice: 0.7948  decode.d7.loss_cls: 0.2084  decode.d7.loss_mask: 1.1422  decode.d7.loss_dice: 0.8204  decode.d8.loss_cls: 0.2295  decode.d8.loss_mask: 1.1022  decode.d8.loss_dice: 0.7769
05/26 15:32:57 - mmengine - INFO - Iter(train) [ 39500/160000]  base_lr: 7.7479e-05 lr: 7.7479e-06  eta: 13:43:39  time: 0.4126  data_time: 0.0093  memory: 5991  grad_norm: 1909.3923  loss: 29.2568  decode.loss_cls: 0.3617  decode.loss_mask: 1.4368  decode.loss_dice: 1.0524  decode.d0.loss_cls: 1.0809  decode.d0.loss_mask: 1.3546  decode.d0.loss_dice: 1.0334  decode.d1.loss_cls: 0.4350  decode.d1.loss_mask: 1.4299  decode.d1.loss_dice: 0.9953  decode.d2.loss_cls: 0.4296  decode.d2.loss_mask: 1.3883  decode.d2.loss_dice: 1.0142  decode.d3.loss_cls: 0.3641  decode.d3.loss_mask: 1.4718  decode.d3.loss_dice: 1.1033  decode.d4.loss_cls: 0.4288  decode.d4.loss_mask: 1.5150  decode.d4.loss_dice: 1.0248  decode.d5.loss_cls: 0.4134  decode.d5.loss_mask: 1.3365  decode.d5.loss_dice: 1.0050  decode.d6.loss_cls: 0.4149  decode.d6.loss_mask: 1.3929  decode.d6.loss_dice: 1.0611  decode.d7.loss_cls: 0.4460  decode.d7.loss_mask: 1.4411  decode.d7.loss_dice: 1.0216  decode.d8.loss_cls: 0.4050  decode.d8.loss_mask: 1.3683  decode.d8.loss_dice: 1.0310
05/26 15:33:17 - mmengine - INFO - Iter(train) [ 39550/160000]  base_lr: 7.7450e-05 lr: 7.7450e-06  eta: 13:43:18  time: 0.4085  data_time: 0.0092  memory: 5976  grad_norm: 470.0739  loss: 26.2524  decode.loss_cls: 0.4167  decode.loss_mask: 1.2328  decode.loss_dice: 0.9061  decode.d0.loss_cls: 0.9112  decode.d0.loss_mask: 1.2488  decode.d0.loss_dice: 0.8877  decode.d1.loss_cls: 0.3856  decode.d1.loss_mask: 1.2659  decode.d1.loss_dice: 0.9352  decode.d2.loss_cls: 0.3939  decode.d2.loss_mask: 1.2599  decode.d2.loss_dice: 0.8788  decode.d3.loss_cls: 0.3984  decode.d3.loss_mask: 1.2911  decode.d3.loss_dice: 0.9602  decode.d4.loss_cls: 0.4071  decode.d4.loss_mask: 1.3052  decode.d4.loss_dice: 0.9123  decode.d5.loss_cls: 0.4124  decode.d5.loss_mask: 1.2623  decode.d5.loss_dice: 0.9066  decode.d6.loss_cls: 0.3931  decode.d6.loss_mask: 1.2312  decode.d6.loss_dice: 0.8990  decode.d7.loss_cls: 0.4167  decode.d7.loss_mask: 1.2449  decode.d7.loss_dice: 0.8591  decode.d8.loss_cls: 0.4444  decode.d8.loss_mask: 1.2765  decode.d8.loss_dice: 0.9093
05/26 15:33:38 - mmengine - INFO - Iter(train) [ 39600/160000]  base_lr: 7.7421e-05 lr: 7.7421e-06  eta: 13:42:58  time: 0.4085  data_time: 0.0093  memory: 5968  grad_norm: 657.5853  loss: 23.3011  decode.loss_cls: 0.2055  decode.loss_mask: 1.1713  decode.loss_dice: 0.8723  decode.d0.loss_cls: 0.6426  decode.d0.loss_mask: 1.0726  decode.d0.loss_dice: 0.8185  decode.d1.loss_cls: 0.2728  decode.d1.loss_mask: 1.1946  decode.d1.loss_dice: 0.8779  decode.d2.loss_cls: 0.2379  decode.d2.loss_mask: 1.1647  decode.d2.loss_dice: 0.8974  decode.d3.loss_cls: 0.2501  decode.d3.loss_mask: 1.1853  decode.d3.loss_dice: 0.8944  decode.d4.loss_cls: 0.2237  decode.d4.loss_mask: 1.1730  decode.d4.loss_dice: 0.8926  decode.d5.loss_cls: 0.2724  decode.d5.loss_mask: 1.1600  decode.d5.loss_dice: 0.8669  decode.d6.loss_cls: 0.2448  decode.d6.loss_mask: 1.1612  decode.d6.loss_dice: 0.8966  decode.d7.loss_cls: 0.2962  decode.d7.loss_mask: 1.1753  decode.d7.loss_dice: 0.8633  decode.d8.loss_cls: 0.2243  decode.d8.loss_mask: 1.1767  decode.d8.loss_dice: 0.9160
05/26 15:33:58 - mmengine - INFO - Iter(train) [ 39650/160000]  base_lr: 7.7392e-05 lr: 7.7392e-06  eta: 13:42:37  time: 0.4103  data_time: 0.0092  memory: 5969  grad_norm: 987.0708  loss: 25.1780  decode.loss_cls: 0.3978  decode.loss_mask: 1.1750  decode.loss_dice: 0.9210  decode.d0.loss_cls: 0.7925  decode.d0.loss_mask: 1.1463  decode.d0.loss_dice: 0.8781  decode.d1.loss_cls: 0.3845  decode.d1.loss_mask: 1.1870  decode.d1.loss_dice: 0.9078  decode.d2.loss_cls: 0.4079  decode.d2.loss_mask: 1.2028  decode.d2.loss_dice: 0.8921  decode.d3.loss_cls: 0.4054  decode.d3.loss_mask: 1.1257  decode.d3.loss_dice: 0.8781  decode.d4.loss_cls: 0.4099  decode.d4.loss_mask: 1.1595  decode.d4.loss_dice: 0.9009  decode.d5.loss_cls: 0.4074  decode.d5.loss_mask: 1.1401  decode.d5.loss_dice: 0.8909  decode.d6.loss_cls: 0.3980  decode.d6.loss_mask: 1.1897  decode.d6.loss_dice: 0.9214  decode.d7.loss_cls: 0.4129  decode.d7.loss_mask: 1.1984  decode.d7.loss_dice: 0.9337  decode.d8.loss_cls: 0.4262  decode.d8.loss_mask: 1.1603  decode.d8.loss_dice: 0.9265
05/26 15:34:19 - mmengine - INFO - Iter(train) [ 39700/160000]  base_lr: 7.7363e-05 lr: 7.7363e-06  eta: 13:42:17  time: 0.4088  data_time: 0.0093  memory: 5976  grad_norm: 685.2570  loss: 22.5348  decode.loss_cls: 0.2353  decode.loss_mask: 1.0873  decode.loss_dice: 0.7970  decode.d0.loss_cls: 0.7093  decode.d0.loss_mask: 1.1362  decode.d0.loss_dice: 0.8248  decode.d1.loss_cls: 0.3002  decode.d1.loss_mask: 1.1256  decode.d1.loss_dice: 0.8483  decode.d2.loss_cls: 0.2714  decode.d2.loss_mask: 1.1253  decode.d2.loss_dice: 0.8152  decode.d3.loss_cls: 0.2620  decode.d3.loss_mask: 1.1045  decode.d3.loss_dice: 0.8040  decode.d4.loss_cls: 0.3052  decode.d4.loss_mask: 1.0852  decode.d4.loss_dice: 0.7954  decode.d5.loss_cls: 0.2740  decode.d5.loss_mask: 1.1279  decode.d5.loss_dice: 0.8441  decode.d6.loss_cls: 0.2906  decode.d6.loss_mask: 1.1010  decode.d6.loss_dice: 0.8144  decode.d7.loss_cls: 0.2658  decode.d7.loss_mask: 1.1455  decode.d7.loss_dice: 0.8342  decode.d8.loss_cls: 0.2849  decode.d8.loss_mask: 1.1057  decode.d8.loss_dice: 0.8145
05/26 15:34:39 - mmengine - INFO - Iter(train) [ 39750/160000]  base_lr: 7.7334e-05 lr: 7.7334e-06  eta: 13:41:56  time: 0.4086  data_time: 0.0092  memory: 5969  grad_norm: 822.7319  loss: 23.1051  decode.loss_cls: 0.3279  decode.loss_mask: 1.1304  decode.loss_dice: 0.8234  decode.d0.loss_cls: 0.7986  decode.d0.loss_mask: 1.0773  decode.d0.loss_dice: 0.7576  decode.d1.loss_cls: 0.3168  decode.d1.loss_mask: 1.1358  decode.d1.loss_dice: 0.8039  decode.d2.loss_cls: 0.3390  decode.d2.loss_mask: 1.1212  decode.d2.loss_dice: 0.7832  decode.d3.loss_cls: 0.3515  decode.d3.loss_mask: 1.1157  decode.d3.loss_dice: 0.8060  decode.d4.loss_cls: 0.3700  decode.d4.loss_mask: 1.1168  decode.d4.loss_dice: 0.7894  decode.d5.loss_cls: 0.3354  decode.d5.loss_mask: 1.1472  decode.d5.loss_dice: 0.7803  decode.d6.loss_cls: 0.3962  decode.d6.loss_mask: 1.0985  decode.d6.loss_dice: 0.7740  decode.d7.loss_cls: 0.3206  decode.d7.loss_mask: 1.1926  decode.d7.loss_dice: 0.7931  decode.d8.loss_cls: 0.3843  decode.d8.loss_mask: 1.1240  decode.d8.loss_dice: 0.7943
05/26 15:35:00 - mmengine - INFO - Iter(train) [ 39800/160000]  base_lr: 7.7305e-05 lr: 7.7305e-06  eta: 13:41:35  time: 0.4091  data_time: 0.0092  memory: 5967  grad_norm: 534.4532  loss: 25.7275  decode.loss_cls: 0.2758  decode.loss_mask: 1.2543  decode.loss_dice: 0.9859  decode.d0.loss_cls: 0.8045  decode.d0.loss_mask: 1.2631  decode.d0.loss_dice: 0.9225  decode.d1.loss_cls: 0.2857  decode.d1.loss_mask: 1.3412  decode.d1.loss_dice: 0.9370  decode.d2.loss_cls: 0.3078  decode.d2.loss_mask: 1.2436  decode.d2.loss_dice: 0.9636  decode.d3.loss_cls: 0.2802  decode.d3.loss_mask: 1.2469  decode.d3.loss_dice: 0.9610  decode.d4.loss_cls: 0.3089  decode.d4.loss_mask: 1.2626  decode.d4.loss_dice: 0.9537  decode.d5.loss_cls: 0.2804  decode.d5.loss_mask: 1.2808  decode.d5.loss_dice: 0.9570  decode.d6.loss_cls: 0.3253  decode.d6.loss_mask: 1.2479  decode.d6.loss_dice: 0.9565  decode.d7.loss_cls: 0.3023  decode.d7.loss_mask: 1.2805  decode.d7.loss_dice: 0.9885  decode.d8.loss_cls: 0.2996  decode.d8.loss_mask: 1.2379  decode.d8.loss_dice: 0.9723
05/26 15:35:20 - mmengine - INFO - Iter(train) [ 39850/160000]  base_lr: 7.7276e-05 lr: 7.7276e-06  eta: 13:41:15  time: 0.4081  data_time: 0.0091  memory: 5967  grad_norm: 944.1150  loss: 25.4480  decode.loss_cls: 0.3037  decode.loss_mask: 1.3104  decode.loss_dice: 0.8941  decode.d0.loss_cls: 0.6841  decode.d0.loss_mask: 1.2747  decode.d0.loss_dice: 0.8550  decode.d1.loss_cls: 0.2927  decode.d1.loss_mask: 1.3382  decode.d1.loss_dice: 0.8902  decode.d2.loss_cls: 0.3438  decode.d2.loss_mask: 1.3447  decode.d2.loss_dice: 0.8723  decode.d3.loss_cls: 0.3566  decode.d3.loss_mask: 1.2980  decode.d3.loss_dice: 0.8495  decode.d4.loss_cls: 0.3226  decode.d4.loss_mask: 1.2882  decode.d4.loss_dice: 0.8775  decode.d5.loss_cls: 0.3070  decode.d5.loss_mask: 1.3462  decode.d5.loss_dice: 0.8664  decode.d6.loss_cls: 0.3192  decode.d6.loss_mask: 1.2582  decode.d6.loss_dice: 0.8315  decode.d7.loss_cls: 0.3048  decode.d7.loss_mask: 1.3965  decode.d7.loss_dice: 0.9139  decode.d8.loss_cls: 0.3435  decode.d8.loss_mask: 1.2859  decode.d8.loss_dice: 0.8787
05/26 15:35:41 - mmengine - INFO - Iter(train) [ 39900/160000]  base_lr: 7.7247e-05 lr: 7.7247e-06  eta: 13:40:54  time: 0.4098  data_time: 0.0092  memory: 5970  grad_norm: 1500.1535  loss: 21.7384  decode.loss_cls: 0.2204  decode.loss_mask: 1.1499  decode.loss_dice: 0.7494  decode.d0.loss_cls: 0.7100  decode.d0.loss_mask: 1.0740  decode.d0.loss_dice: 0.7196  decode.d1.loss_cls: 0.2966  decode.d1.loss_mask: 1.1194  decode.d1.loss_dice: 0.7419  decode.d2.loss_cls: 0.2244  decode.d2.loss_mask: 1.0866  decode.d2.loss_dice: 0.7409  decode.d3.loss_cls: 0.2097  decode.d3.loss_mask: 1.0908  decode.d3.loss_dice: 0.7258  decode.d4.loss_cls: 0.2783  decode.d4.loss_mask: 1.1402  decode.d4.loss_dice: 0.7452  decode.d5.loss_cls: 0.2504  decode.d5.loss_mask: 1.1315  decode.d5.loss_dice: 0.7899  decode.d6.loss_cls: 0.2210  decode.d6.loss_mask: 1.2065  decode.d6.loss_dice: 0.7905  decode.d7.loss_cls: 0.1762  decode.d7.loss_mask: 1.1960  decode.d7.loss_dice: 0.7927  decode.d8.loss_cls: 0.2132  decode.d8.loss_mask: 1.1482  decode.d8.loss_dice: 0.7991
05/26 15:36:01 - mmengine - INFO - Iter(train) [ 39950/160000]  base_lr: 7.7218e-05 lr: 7.7218e-06  eta: 13:40:34  time: 0.4082  data_time: 0.0092  memory: 5974  grad_norm: 582.4483  loss: 25.3240  decode.loss_cls: 0.3273  decode.loss_mask: 1.1860  decode.loss_dice: 0.9589  decode.d0.loss_cls: 0.7751  decode.d0.loss_mask: 1.1219  decode.d0.loss_dice: 0.9162  decode.d1.loss_cls: 0.3445  decode.d1.loss_mask: 1.2247  decode.d1.loss_dice: 1.0155  decode.d2.loss_cls: 0.3229  decode.d2.loss_mask: 1.1481  decode.d2.loss_dice: 0.9677  decode.d3.loss_cls: 0.3108  decode.d3.loss_mask: 1.1870  decode.d3.loss_dice: 0.9620  decode.d4.loss_cls: 0.3134  decode.d4.loss_mask: 1.2339  decode.d4.loss_dice: 0.9718  decode.d5.loss_cls: 0.3265  decode.d5.loss_mask: 1.2558  decode.d5.loss_dice: 0.9681  decode.d6.loss_cls: 0.3314  decode.d6.loss_mask: 1.2128  decode.d6.loss_dice: 0.9607  decode.d7.loss_cls: 0.3023  decode.d7.loss_mask: 1.2337  decode.d7.loss_dice: 0.9907  decode.d8.loss_cls: 0.2969  decode.d8.loss_mask: 1.2126  decode.d8.loss_dice: 0.9450
05/26 15:36:22 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 15:36:22 - mmengine - INFO - Iter(train) [ 40000/160000]  base_lr: 7.7189e-05 lr: 7.7189e-06  eta: 13:40:13  time: 0.4088  data_time: 0.0092  memory: 5986  grad_norm: 553.4689  loss: 26.0028  decode.loss_cls: 0.3387  decode.loss_mask: 1.1809  decode.loss_dice: 0.9811  decode.d0.loss_cls: 0.8798  decode.d0.loss_mask: 1.1695  decode.d0.loss_dice: 1.0028  decode.d1.loss_cls: 0.2864  decode.d1.loss_mask: 1.2081  decode.d1.loss_dice: 0.9909  decode.d2.loss_cls: 0.2830  decode.d2.loss_mask: 1.2646  decode.d2.loss_dice: 0.9614  decode.d3.loss_cls: 0.3433  decode.d3.loss_mask: 1.2188  decode.d3.loss_dice: 0.9650  decode.d4.loss_cls: 0.3036  decode.d4.loss_mask: 1.2869  decode.d4.loss_dice: 1.0240  decode.d5.loss_cls: 0.3390  decode.d5.loss_mask: 1.2412  decode.d5.loss_dice: 0.9800  decode.d6.loss_cls: 0.3292  decode.d6.loss_mask: 1.2539  decode.d6.loss_dice: 0.9837  decode.d7.loss_cls: 0.3279  decode.d7.loss_mask: 1.2935  decode.d7.loss_dice: 0.9931  decode.d8.loss_cls: 0.2940  decode.d8.loss_mask: 1.2855  decode.d8.loss_dice: 0.9931
05/26 15:36:22 - mmengine - INFO - Saving checkpoint at 40000 iterations
05/26 15:36:26 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:08  time: 0.0484  data_time: 0.0012  memory: 1391  
05/26 15:36:28 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:05  time: 0.0477  data_time: 0.0012  memory: 1205  
05/26 15:36:31 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:03  time: 0.0508  data_time: 0.0012  memory: 1596  
05/26 15:36:33 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:01  time: 0.0505  data_time: 0.0013  memory: 1298  
05/26 15:36:36 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:58  time: 0.0483  data_time: 0.0013  memory: 1298  
05/26 15:36:38 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:56  time: 0.0480  data_time: 0.0012  memory: 1279  
05/26 15:36:40 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:53  time: 0.0482  data_time: 0.0012  memory: 1224  
05/26 15:36:43 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:51  time: 0.0501  data_time: 0.0013  memory: 1298  
05/26 15:36:45 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0479  data_time: 0.0012  memory: 1298  
05/26 15:36:48 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:46  time: 0.0517  data_time: 0.0013  memory: 1725  
05/26 15:36:50 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0481  data_time: 0.0013  memory: 1336  
05/26 15:36:53 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:41  time: 0.0485  data_time: 0.0012  memory: 1298  
05/26 15:36:55 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0487  data_time: 0.0012  memory: 1205  
05/26 15:36:58 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0494  data_time: 0.0013  memory: 1316  
05/26 15:37:00 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:34  time: 0.0485  data_time: 0.0012  memory: 1279  
05/26 15:37:02 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0516  data_time: 0.0012  memory: 1410  
05/26 15:37:05 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:29  time: 0.0480  data_time: 0.0012  memory: 1279  
05/26 15:37:07 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0490  data_time: 0.0013  memory: 1205  
05/26 15:37:10 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0490  data_time: 0.0012  memory: 1205  
05/26 15:37:12 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0481  data_time: 0.0013  memory: 1336  
05/26 15:37:15 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0485  data_time: 0.0012  memory: 1246  
05/26 15:37:17 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0515  data_time: 0.0013  memory: 1503  
05/26 15:37:20 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0483  data_time: 0.0013  memory: 1261  
05/26 15:37:22 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0488  data_time: 0.0013  memory: 1298  
05/26 15:37:24 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0491  data_time: 0.0013  memory: 1447  
05/26 15:37:27 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0508  data_time: 0.0013  memory: 1298  
05/26 15:37:29 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0495  data_time: 0.0012  memory: 1279  
05/26 15:37:32 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0484  data_time: 0.0012  memory: 1205  
05/26 15:37:34 - mmengine - INFO - per class results:
05/26 15:37:34 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background |  94.5 | 97.89 |
|  aeroplane  | 92.31 | 95.24 |
|   bicycle   | 43.89 | 88.17 |
|     bird    | 91.95 | 97.79 |
|     boat    | 72.63 | 80.51 |
|    bottle   | 69.94 | 85.65 |
|     bus     | 88.71 | 94.24 |
|     car     | 88.64 | 91.96 |
|     cat     | 91.17 | 99.45 |
|    chair    | 33.42 |  58.0 |
|     cow     | 60.66 | 66.12 |
| diningtable | 64.68 |  72.8 |
|     dog     | 71.11 | 92.32 |
|    horse    | 79.12 | 88.04 |
|  motorbike  | 87.99 | 94.56 |
|    person   | 83.46 | 85.42 |
| pottedplant | 57.69 | 73.27 |
|    sheep    | 70.61 |  75.7 |
|     sofa    | 29.51 | 33.09 |
|    train    |  85.9 | 87.36 |
|  tvmonitor  | 74.42 | 79.79 |
+-------------+-------+-------+
05/26 15:37:34 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 94.0700  mIoU: 72.9700  mAcc: 82.7300  data_time: 0.0013  time: 0.0487
05/26 15:37:34 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_30000.pth is removed
05/26 15:37:35 - mmengine - INFO - The best checkpoint with 72.9700 mIoU at 40000 iter is saved to best_mIoU_iter_40000.pth.
05/26 15:37:58 - mmengine - INFO - Iter(train) [ 40050/160000]  base_lr: 7.7160e-05 lr: 7.7160e-06  eta: 13:40:01  time: 0.4097  data_time: 0.0093  memory: 5970  grad_norm: 643.2303  loss: 22.5253  decode.loss_cls: 0.1810  decode.loss_mask: 1.1447  decode.loss_dice: 0.8433  decode.d0.loss_cls: 0.7085  decode.d0.loss_mask: 1.1647  decode.d0.loss_dice: 0.8021  decode.d1.loss_cls: 0.2656  decode.d1.loss_mask: 1.1416  decode.d1.loss_dice: 0.8294  decode.d2.loss_cls: 0.1760  decode.d2.loss_mask: 1.1654  decode.d2.loss_dice: 0.8280  decode.d3.loss_cls: 0.2256  decode.d3.loss_mask: 1.1520  decode.d3.loss_dice: 0.8312  decode.d4.loss_cls: 0.1952  decode.d4.loss_mask: 1.1598  decode.d4.loss_dice: 0.8650  decode.d5.loss_cls: 0.2320  decode.d5.loss_mask: 1.1501  decode.d5.loss_dice: 0.7670  decode.d6.loss_cls: 0.1709  decode.d6.loss_mask: 1.1825  decode.d6.loss_dice: 0.8948  decode.d7.loss_cls: 0.1933  decode.d7.loss_mask: 1.1606  decode.d7.loss_dice: 0.8450  decode.d8.loss_cls: 0.2294  decode.d8.loss_mask: 1.1459  decode.d8.loss_dice: 0.8748
05/26 15:38:18 - mmengine - INFO - Iter(train) [ 40100/160000]  base_lr: 7.7131e-05 lr: 7.7131e-06  eta: 13:39:41  time: 0.4095  data_time: 0.0093  memory: 5970  grad_norm: 1023.7725  loss: 26.2865  decode.loss_cls: 0.3123  decode.loss_mask: 1.4100  decode.loss_dice: 0.9144  decode.d0.loss_cls: 0.7560  decode.d0.loss_mask: 1.3515  decode.d0.loss_dice: 0.8631  decode.d1.loss_cls: 0.3167  decode.d1.loss_mask: 1.4058  decode.d1.loss_dice: 0.9031  decode.d2.loss_cls: 0.2986  decode.d2.loss_mask: 1.3421  decode.d2.loss_dice: 0.8390  decode.d3.loss_cls: 0.2967  decode.d3.loss_mask: 1.4014  decode.d3.loss_dice: 0.8783  decode.d4.loss_cls: 0.3113  decode.d4.loss_mask: 1.4082  decode.d4.loss_dice: 0.8887  decode.d5.loss_cls: 0.2993  decode.d5.loss_mask: 1.3711  decode.d5.loss_dice: 0.8721  decode.d6.loss_cls: 0.2949  decode.d6.loss_mask: 1.3496  decode.d6.loss_dice: 0.8907  decode.d7.loss_cls: 0.2889  decode.d7.loss_mask: 1.4300  decode.d7.loss_dice: 0.9310  decode.d8.loss_cls: 0.3072  decode.d8.loss_mask: 1.4507  decode.d8.loss_dice: 0.9036
05/26 15:38:38 - mmengine - INFO - Iter(train) [ 40150/160000]  base_lr: 7.7103e-05 lr: 7.7103e-06  eta: 13:39:20  time: 0.4105  data_time: 0.0096  memory: 5971  grad_norm: 922.0278  loss: 25.9106  decode.loss_cls: 0.3452  decode.loss_mask: 1.2990  decode.loss_dice: 0.8627  decode.d0.loss_cls: 0.8906  decode.d0.loss_mask: 1.1756  decode.d0.loss_dice: 0.8630  decode.d1.loss_cls: 0.3977  decode.d1.loss_mask: 1.2903  decode.d1.loss_dice: 0.8962  decode.d2.loss_cls: 0.3468  decode.d2.loss_mask: 1.2882  decode.d2.loss_dice: 0.8871  decode.d3.loss_cls: 0.3710  decode.d3.loss_mask: 1.3248  decode.d3.loss_dice: 0.8724  decode.d4.loss_cls: 0.3888  decode.d4.loss_mask: 1.2798  decode.d4.loss_dice: 0.8889  decode.d5.loss_cls: 0.3888  decode.d5.loss_mask: 1.3505  decode.d5.loss_dice: 0.8960  decode.d6.loss_cls: 0.3420  decode.d6.loss_mask: 1.3126  decode.d6.loss_dice: 0.8578  decode.d7.loss_cls: 0.4011  decode.d7.loss_mask: 1.2989  decode.d7.loss_dice: 0.8915  decode.d8.loss_cls: 0.3584  decode.d8.loss_mask: 1.2806  decode.d8.loss_dice: 0.8643
05/26 15:38:59 - mmengine - INFO - Iter(train) [ 40200/160000]  base_lr: 7.7074e-05 lr: 7.7074e-06  eta: 13:38:59  time: 0.4099  data_time: 0.0093  memory: 5976  grad_norm: 1036.5255  loss: 25.1551  decode.loss_cls: 0.3772  decode.loss_mask: 1.1775  decode.loss_dice: 0.8663  decode.d0.loss_cls: 0.8363  decode.d0.loss_mask: 1.1035  decode.d0.loss_dice: 0.8320  decode.d1.loss_cls: 0.4009  decode.d1.loss_mask: 1.2617  decode.d1.loss_dice: 0.9144  decode.d2.loss_cls: 0.4271  decode.d2.loss_mask: 1.1778  decode.d2.loss_dice: 0.8527  decode.d3.loss_cls: 0.4260  decode.d3.loss_mask: 1.1868  decode.d3.loss_dice: 0.8793  decode.d4.loss_cls: 0.4403  decode.d4.loss_mask: 1.1633  decode.d4.loss_dice: 0.8591  decode.d5.loss_cls: 0.3954  decode.d5.loss_mask: 1.2098  decode.d5.loss_dice: 0.8918  decode.d6.loss_cls: 0.3844  decode.d6.loss_mask: 1.2031  decode.d6.loss_dice: 0.9026  decode.d7.loss_cls: 0.4093  decode.d7.loss_mask: 1.1988  decode.d7.loss_dice: 0.8987  decode.d8.loss_cls: 0.3844  decode.d8.loss_mask: 1.2314  decode.d8.loss_dice: 0.8630
05/26 15:39:19 - mmengine - INFO - Iter(train) [ 40250/160000]  base_lr: 7.7045e-05 lr: 7.7045e-06  eta: 13:38:39  time: 0.4096  data_time: 0.0092  memory: 5968  grad_norm: 417.9713  loss: 20.5344  decode.loss_cls: 0.2195  decode.loss_mask: 1.0077  decode.loss_dice: 0.8010  decode.d0.loss_cls: 0.6941  decode.d0.loss_mask: 0.9883  decode.d0.loss_dice: 0.7507  decode.d1.loss_cls: 0.2475  decode.d1.loss_mask: 0.9824  decode.d1.loss_dice: 0.7734  decode.d2.loss_cls: 0.2120  decode.d2.loss_mask: 1.0194  decode.d2.loss_dice: 0.7791  decode.d3.loss_cls: 0.2267  decode.d3.loss_mask: 1.0025  decode.d3.loss_dice: 0.7780  decode.d4.loss_cls: 0.2633  decode.d4.loss_mask: 0.9726  decode.d4.loss_dice: 0.7483  decode.d5.loss_cls: 0.2591  decode.d5.loss_mask: 0.9625  decode.d5.loss_dice: 0.7685  decode.d6.loss_cls: 0.2501  decode.d6.loss_mask: 1.0015  decode.d6.loss_dice: 0.8236  decode.d7.loss_cls: 0.2584  decode.d7.loss_mask: 0.9753  decode.d7.loss_dice: 0.7639  decode.d8.loss_cls: 0.2461  decode.d8.loss_mask: 0.9882  decode.d8.loss_dice: 0.7707
05/26 15:39:40 - mmengine - INFO - Iter(train) [ 40300/160000]  base_lr: 7.7016e-05 lr: 7.7016e-06  eta: 13:38:18  time: 0.4094  data_time: 0.0092  memory: 5968  grad_norm: 1133.2195  loss: 22.5926  decode.loss_cls: 0.2421  decode.loss_mask: 1.1321  decode.loss_dice: 0.8313  decode.d0.loss_cls: 0.7603  decode.d0.loss_mask: 1.0267  decode.d0.loss_dice: 0.7795  decode.d1.loss_cls: 0.2656  decode.d1.loss_mask: 1.0476  decode.d1.loss_dice: 0.8100  decode.d2.loss_cls: 0.3194  decode.d2.loss_mask: 1.0749  decode.d2.loss_dice: 0.8442  decode.d3.loss_cls: 0.2949  decode.d3.loss_mask: 1.1021  decode.d3.loss_dice: 0.8280  decode.d4.loss_cls: 0.3006  decode.d4.loss_mask: 1.1578  decode.d4.loss_dice: 0.8540  decode.d5.loss_cls: 0.2928  decode.d5.loss_mask: 1.1048  decode.d5.loss_dice: 0.8460  decode.d6.loss_cls: 0.2264  decode.d6.loss_mask: 1.1668  decode.d6.loss_dice: 0.8489  decode.d7.loss_cls: 0.2306  decode.d7.loss_mask: 1.1405  decode.d7.loss_dice: 0.8220  decode.d8.loss_cls: 0.2253  decode.d8.loss_mask: 1.1684  decode.d8.loss_dice: 0.8491
05/26 15:40:00 - mmengine - INFO - Iter(train) [ 40350/160000]  base_lr: 7.6987e-05 lr: 7.6987e-06  eta: 13:37:57  time: 0.4102  data_time: 0.0092  memory: 5968  grad_norm: 539.5297  loss: 21.8676  decode.loss_cls: 0.3210  decode.loss_mask: 1.1074  decode.loss_dice: 0.6892  decode.d0.loss_cls: 0.7762  decode.d0.loss_mask: 1.0325  decode.d0.loss_dice: 0.7346  decode.d1.loss_cls: 0.3067  decode.d1.loss_mask: 1.1196  decode.d1.loss_dice: 0.7674  decode.d2.loss_cls: 0.2880  decode.d2.loss_mask: 1.0945  decode.d2.loss_dice: 0.7507  decode.d3.loss_cls: 0.2944  decode.d3.loss_mask: 1.1077  decode.d3.loss_dice: 0.7115  decode.d4.loss_cls: 0.2928  decode.d4.loss_mask: 1.0700  decode.d4.loss_dice: 0.7034  decode.d5.loss_cls: 0.3051  decode.d5.loss_mask: 1.1042  decode.d5.loss_dice: 0.7354  decode.d6.loss_cls: 0.3790  decode.d6.loss_mask: 1.0901  decode.d6.loss_dice: 0.7355  decode.d7.loss_cls: 0.3242  decode.d7.loss_mask: 1.1051  decode.d7.loss_dice: 0.7377  decode.d8.loss_cls: 0.3087  decode.d8.loss_mask: 1.1286  decode.d8.loss_dice: 0.7464
05/26 15:40:21 - mmengine - INFO - Iter(train) [ 40400/160000]  base_lr: 7.6958e-05 lr: 7.6958e-06  eta: 13:37:37  time: 0.4090  data_time: 0.0093  memory: 5966  grad_norm: 541.5971  loss: 21.7789  decode.loss_cls: 0.3182  decode.loss_mask: 0.9598  decode.loss_dice: 0.8563  decode.d0.loss_cls: 0.7781  decode.d0.loss_mask: 0.8949  decode.d0.loss_dice: 0.8283  decode.d1.loss_cls: 0.3840  decode.d1.loss_mask: 1.0199  decode.d1.loss_dice: 0.8359  decode.d2.loss_cls: 0.3059  decode.d2.loss_mask: 1.0214  decode.d2.loss_dice: 0.8289  decode.d3.loss_cls: 0.3212  decode.d3.loss_mask: 0.9520  decode.d3.loss_dice: 0.8138  decode.d4.loss_cls: 0.3398  decode.d4.loss_mask: 0.9776  decode.d4.loss_dice: 0.8130  decode.d5.loss_cls: 0.3379  decode.d5.loss_mask: 0.9603  decode.d5.loss_dice: 0.8514  decode.d6.loss_cls: 0.3317  decode.d6.loss_mask: 0.9299  decode.d6.loss_dice: 0.8281  decode.d7.loss_cls: 0.3001  decode.d7.loss_mask: 0.9815  decode.d7.loss_dice: 0.8620  decode.d8.loss_cls: 0.3350  decode.d8.loss_mask: 0.9580  decode.d8.loss_dice: 0.8539
05/26 15:40:41 - mmengine - INFO - Iter(train) [ 40450/160000]  base_lr: 7.6929e-05 lr: 7.6929e-06  eta: 13:37:16  time: 0.4096  data_time: 0.0093  memory: 5966  grad_norm: 796.9710  loss: 25.6960  decode.loss_cls: 0.3632  decode.loss_mask: 1.2433  decode.loss_dice: 0.8232  decode.d0.loss_cls: 0.8406  decode.d0.loss_mask: 1.2331  decode.d0.loss_dice: 0.8485  decode.d1.loss_cls: 0.3643  decode.d1.loss_mask: 1.3168  decode.d1.loss_dice: 0.8312  decode.d2.loss_cls: 0.3699  decode.d2.loss_mask: 1.2868  decode.d2.loss_dice: 0.8538  decode.d3.loss_cls: 0.3376  decode.d3.loss_mask: 1.3993  decode.d3.loss_dice: 0.8278  decode.d4.loss_cls: 0.3891  decode.d4.loss_mask: 1.3554  decode.d4.loss_dice: 0.8386  decode.d5.loss_cls: 0.3615  decode.d5.loss_mask: 1.3252  decode.d5.loss_dice: 0.8183  decode.d6.loss_cls: 0.3674  decode.d6.loss_mask: 1.3403  decode.d6.loss_dice: 0.8342  decode.d7.loss_cls: 0.3484  decode.d7.loss_mask: 1.4064  decode.d7.loss_dice: 0.8732  decode.d8.loss_cls: 0.3421  decode.d8.loss_mask: 1.3204  decode.d8.loss_dice: 0.8361
05/26 15:41:02 - mmengine - INFO - Iter(train) [ 40500/160000]  base_lr: 7.6900e-05 lr: 7.6900e-06  eta: 13:36:56  time: 0.4098  data_time: 0.0092  memory: 5966  grad_norm: 698.3607  loss: 23.6279  decode.loss_cls: 0.3130  decode.loss_mask: 1.1249  decode.loss_dice: 0.8681  decode.d0.loss_cls: 0.8765  decode.d0.loss_mask: 0.9740  decode.d0.loss_dice: 0.8815  decode.d1.loss_cls: 0.3576  decode.d1.loss_mask: 1.1405  decode.d1.loss_dice: 0.8415  decode.d2.loss_cls: 0.3636  decode.d2.loss_mask: 1.1070  decode.d2.loss_dice: 0.8258  decode.d3.loss_cls: 0.3438  decode.d3.loss_mask: 1.1124  decode.d3.loss_dice: 0.8282  decode.d4.loss_cls: 0.3680  decode.d4.loss_mask: 1.1283  decode.d4.loss_dice: 0.8472  decode.d5.loss_cls: 0.3486  decode.d5.loss_mask: 1.1451  decode.d5.loss_dice: 0.8511  decode.d6.loss_cls: 0.2948  decode.d6.loss_mask: 1.1599  decode.d6.loss_dice: 0.8627  decode.d7.loss_cls: 0.3374  decode.d7.loss_mask: 1.1648  decode.d7.loss_dice: 0.8972  decode.d8.loss_cls: 0.2937  decode.d8.loss_mask: 1.1038  decode.d8.loss_dice: 0.8666
05/26 15:41:22 - mmengine - INFO - Iter(train) [ 40550/160000]  base_lr: 7.6871e-05 lr: 7.6871e-06  eta: 13:36:35  time: 0.4090  data_time: 0.0093  memory: 5976  grad_norm: 863.6062  loss: 23.6874  decode.loss_cls: 0.2679  decode.loss_mask: 1.1863  decode.loss_dice: 0.8744  decode.d0.loss_cls: 0.7576  decode.d0.loss_mask: 1.1323  decode.d0.loss_dice: 0.8404  decode.d1.loss_cls: 0.2481  decode.d1.loss_mask: 1.2172  decode.d1.loss_dice: 0.8949  decode.d2.loss_cls: 0.2163  decode.d2.loss_mask: 1.1757  decode.d2.loss_dice: 0.8591  decode.d3.loss_cls: 0.2356  decode.d3.loss_mask: 1.1847  decode.d3.loss_dice: 0.8622  decode.d4.loss_cls: 0.2674  decode.d4.loss_mask: 1.2029  decode.d4.loss_dice: 0.8962  decode.d5.loss_cls: 0.2969  decode.d5.loss_mask: 1.1649  decode.d5.loss_dice: 0.8902  decode.d6.loss_cls: 0.2615  decode.d6.loss_mask: 1.1752  decode.d6.loss_dice: 0.8950  decode.d7.loss_cls: 0.2894  decode.d7.loss_mask: 1.1823  decode.d7.loss_dice: 0.8764  decode.d8.loss_cls: 0.2690  decode.d8.loss_mask: 1.1792  decode.d8.loss_dice: 0.8881
05/26 15:41:43 - mmengine - INFO - Iter(train) [ 40600/160000]  base_lr: 7.6842e-05 lr: 7.6842e-06  eta: 13:36:14  time: 0.4091  data_time: 0.0092  memory: 5975  grad_norm: 521.6853  loss: 22.1048  decode.loss_cls: 0.2138  decode.loss_mask: 1.1741  decode.loss_dice: 0.7436  decode.d0.loss_cls: 0.7226  decode.d0.loss_mask: 1.1160  decode.d0.loss_dice: 0.7554  decode.d1.loss_cls: 0.2432  decode.d1.loss_mask: 1.1568  decode.d1.loss_dice: 0.7680  decode.d2.loss_cls: 0.2462  decode.d2.loss_mask: 1.1084  decode.d2.loss_dice: 0.7552  decode.d3.loss_cls: 0.2317  decode.d3.loss_mask: 1.1940  decode.d3.loss_dice: 0.8067  decode.d4.loss_cls: 0.2894  decode.d4.loss_mask: 1.1350  decode.d4.loss_dice: 0.7598  decode.d5.loss_cls: 0.2654  decode.d5.loss_mask: 1.1685  decode.d5.loss_dice: 0.7711  decode.d6.loss_cls: 0.2432  decode.d6.loss_mask: 1.1483  decode.d6.loss_dice: 0.7530  decode.d7.loss_cls: 0.2309  decode.d7.loss_mask: 1.1611  decode.d7.loss_dice: 0.7530  decode.d8.loss_cls: 0.2394  decode.d8.loss_mask: 1.1843  decode.d8.loss_dice: 0.7664
05/26 15:42:03 - mmengine - INFO - Iter(train) [ 40650/160000]  base_lr: 7.6813e-05 lr: 7.6813e-06  eta: 13:35:54  time: 0.4093  data_time: 0.0092  memory: 5970  grad_norm: 592.2827  loss: 20.3843  decode.loss_cls: 0.1743  decode.loss_mask: 1.0157  decode.loss_dice: 0.7824  decode.d0.loss_cls: 0.7590  decode.d0.loss_mask: 0.9581  decode.d0.loss_dice: 0.7724  decode.d1.loss_cls: 0.1821  decode.d1.loss_mask: 1.0000  decode.d1.loss_dice: 0.7866  decode.d2.loss_cls: 0.1299  decode.d2.loss_mask: 1.0092  decode.d2.loss_dice: 0.7939  decode.d3.loss_cls: 0.1504  decode.d3.loss_mask: 1.0119  decode.d3.loss_dice: 0.8136  decode.d4.loss_cls: 0.1860  decode.d4.loss_mask: 1.0201  decode.d4.loss_dice: 0.8131  decode.d5.loss_cls: 0.1897  decode.d5.loss_mask: 1.0271  decode.d5.loss_dice: 0.8033  decode.d6.loss_cls: 0.1757  decode.d6.loss_mask: 1.0027  decode.d6.loss_dice: 0.7886  decode.d7.loss_cls: 0.1880  decode.d7.loss_mask: 1.0551  decode.d7.loss_dice: 0.8024  decode.d8.loss_cls: 0.1139  decode.d8.loss_mask: 1.0688  decode.d8.loss_dice: 0.8106
05/26 15:42:24 - mmengine - INFO - Iter(train) [ 40700/160000]  base_lr: 7.6784e-05 lr: 7.6784e-06  eta: 13:35:33  time: 0.4090  data_time: 0.0092  memory: 5979  grad_norm: 851.4335  loss: 23.8890  decode.loss_cls: 0.3184  decode.loss_mask: 1.1391  decode.loss_dice: 0.8767  decode.d0.loss_cls: 0.7616  decode.d0.loss_mask: 1.1652  decode.d0.loss_dice: 0.8796  decode.d1.loss_cls: 0.3176  decode.d1.loss_mask: 1.1561  decode.d1.loss_dice: 0.8461  decode.d2.loss_cls: 0.3186  decode.d2.loss_mask: 1.1413  decode.d2.loss_dice: 0.8781  decode.d3.loss_cls: 0.2994  decode.d3.loss_mask: 1.1749  decode.d3.loss_dice: 0.8803  decode.d4.loss_cls: 0.2694  decode.d4.loss_mask: 1.1719  decode.d4.loss_dice: 0.8783  decode.d5.loss_cls: 0.3222  decode.d5.loss_mask: 1.1705  decode.d5.loss_dice: 0.8927  decode.d6.loss_cls: 0.2724  decode.d6.loss_mask: 1.1865  decode.d6.loss_dice: 0.8814  decode.d7.loss_cls: 0.2841  decode.d7.loss_mask: 1.1919  decode.d7.loss_dice: 0.8827  decode.d8.loss_cls: 0.2928  decode.d8.loss_mask: 1.1619  decode.d8.loss_dice: 0.8773
05/26 15:42:44 - mmengine - INFO - Iter(train) [ 40750/160000]  base_lr: 7.6755e-05 lr: 7.6755e-06  eta: 13:35:12  time: 0.4091  data_time: 0.0093  memory: 5969  grad_norm: 730.3694  loss: 26.1741  decode.loss_cls: 0.2657  decode.loss_mask: 1.3147  decode.loss_dice: 0.9710  decode.d0.loss_cls: 0.8131  decode.d0.loss_mask: 1.2488  decode.d0.loss_dice: 0.8926  decode.d1.loss_cls: 0.3360  decode.d1.loss_mask: 1.3314  decode.d1.loss_dice: 0.9562  decode.d2.loss_cls: 0.2886  decode.d2.loss_mask: 1.2898  decode.d2.loss_dice: 0.9671  decode.d3.loss_cls: 0.3421  decode.d3.loss_mask: 1.2910  decode.d3.loss_dice: 0.9361  decode.d4.loss_cls: 0.3464  decode.d4.loss_mask: 1.2624  decode.d4.loss_dice: 0.9385  decode.d5.loss_cls: 0.2862  decode.d5.loss_mask: 1.3162  decode.d5.loss_dice: 0.9630  decode.d6.loss_cls: 0.2998  decode.d6.loss_mask: 1.3477  decode.d6.loss_dice: 0.9692  decode.d7.loss_cls: 0.3451  decode.d7.loss_mask: 1.3147  decode.d7.loss_dice: 0.9434  decode.d8.loss_cls: 0.2877  decode.d8.loss_mask: 1.3287  decode.d8.loss_dice: 0.9807
05/26 15:43:05 - mmengine - INFO - Iter(train) [ 40800/160000]  base_lr: 7.6726e-05 lr: 7.6726e-06  eta: 13:34:51  time: 0.4088  data_time: 0.0093  memory: 5969  grad_norm: 1028.0064  loss: 25.3831  decode.loss_cls: 0.2285  decode.loss_mask: 1.2460  decode.loss_dice: 1.0280  decode.d0.loss_cls: 0.7479  decode.d0.loss_mask: 1.1136  decode.d0.loss_dice: 0.9045  decode.d1.loss_cls: 0.2270  decode.d1.loss_mask: 1.2215  decode.d1.loss_dice: 1.0251  decode.d2.loss_cls: 0.2334  decode.d2.loss_mask: 1.2445  decode.d2.loss_dice: 0.9957  decode.d3.loss_cls: 0.3045  decode.d3.loss_mask: 1.2396  decode.d3.loss_dice: 1.0056  decode.d4.loss_cls: 0.2510  decode.d4.loss_mask: 1.2758  decode.d4.loss_dice: 1.0177  decode.d5.loss_cls: 0.2496  decode.d5.loss_mask: 1.2466  decode.d5.loss_dice: 1.0450  decode.d6.loss_cls: 0.2284  decode.d6.loss_mask: 1.2494  decode.d6.loss_dice: 1.0139  decode.d7.loss_cls: 0.2657  decode.d7.loss_mask: 1.2140  decode.d7.loss_dice: 1.0128  decode.d8.loss_cls: 0.2410  decode.d8.loss_mask: 1.2787  decode.d8.loss_dice: 1.0281
05/26 15:43:25 - mmengine - INFO - Iter(train) [ 40850/160000]  base_lr: 7.6697e-05 lr: 7.6697e-06  eta: 13:34:31  time: 0.4089  data_time: 0.0092  memory: 5976  grad_norm: 610.5920  loss: 22.9816  decode.loss_cls: 0.1975  decode.loss_mask: 1.2214  decode.loss_dice: 0.8418  decode.d0.loss_cls: 0.6596  decode.d0.loss_mask: 1.1970  decode.d0.loss_dice: 0.8526  decode.d1.loss_cls: 0.2644  decode.d1.loss_mask: 1.1545  decode.d1.loss_dice: 0.8239  decode.d2.loss_cls: 0.1545  decode.d2.loss_mask: 1.1821  decode.d2.loss_dice: 0.8483  decode.d3.loss_cls: 0.2006  decode.d3.loss_mask: 1.2085  decode.d3.loss_dice: 0.8498  decode.d4.loss_cls: 0.2434  decode.d4.loss_mask: 1.1709  decode.d4.loss_dice: 0.8577  decode.d5.loss_cls: 0.2320  decode.d5.loss_mask: 1.1958  decode.d5.loss_dice: 0.8329  decode.d6.loss_cls: 0.2349  decode.d6.loss_mask: 1.1825  decode.d6.loss_dice: 0.8513  decode.d7.loss_cls: 0.1945  decode.d7.loss_mask: 1.1956  decode.d7.loss_dice: 0.8433  decode.d8.loss_cls: 0.2511  decode.d8.loss_mask: 1.1986  decode.d8.loss_dice: 0.8406
05/26 15:43:45 - mmengine - INFO - Iter(train) [ 40900/160000]  base_lr: 7.6668e-05 lr: 7.6668e-06  eta: 13:34:10  time: 0.4088  data_time: 0.0092  memory: 5971  grad_norm: 847.9601  loss: 25.1089  decode.loss_cls: 0.2401  decode.loss_mask: 1.3530  decode.loss_dice: 0.9150  decode.d0.loss_cls: 0.8210  decode.d0.loss_mask: 1.2284  decode.d0.loss_dice: 0.8786  decode.d1.loss_cls: 0.2582  decode.d1.loss_mask: 1.2949  decode.d1.loss_dice: 0.8959  decode.d2.loss_cls: 0.2511  decode.d2.loss_mask: 1.2908  decode.d2.loss_dice: 0.8919  decode.d3.loss_cls: 0.2615  decode.d3.loss_mask: 1.2910  decode.d3.loss_dice: 0.9107  decode.d4.loss_cls: 0.2717  decode.d4.loss_mask: 1.2491  decode.d4.loss_dice: 0.9127  decode.d5.loss_cls: 0.2945  decode.d5.loss_mask: 1.2641  decode.d5.loss_dice: 0.8992  decode.d6.loss_cls: 0.2813  decode.d6.loss_mask: 1.3014  decode.d6.loss_dice: 0.9056  decode.d7.loss_cls: 0.2939  decode.d7.loss_mask: 1.2682  decode.d7.loss_dice: 0.9420  decode.d8.loss_cls: 0.1847  decode.d8.loss_mask: 1.3326  decode.d8.loss_dice: 0.9258
05/26 15:44:06 - mmengine - INFO - Iter(train) [ 40950/160000]  base_lr: 7.6639e-05 lr: 7.6639e-06  eta: 13:33:49  time: 0.4082  data_time: 0.0092  memory: 5971  grad_norm: 919.0738  loss: 25.0105  decode.loss_cls: 0.2487  decode.loss_mask: 1.2750  decode.loss_dice: 0.9418  decode.d0.loss_cls: 0.7717  decode.d0.loss_mask: 1.1819  decode.d0.loss_dice: 0.8734  decode.d1.loss_cls: 0.2254  decode.d1.loss_mask: 1.2988  decode.d1.loss_dice: 0.9423  decode.d2.loss_cls: 0.2003  decode.d2.loss_mask: 1.2670  decode.d2.loss_dice: 0.9437  decode.d3.loss_cls: 0.2245  decode.d3.loss_mask: 1.2971  decode.d3.loss_dice: 0.9636  decode.d4.loss_cls: 0.2815  decode.d4.loss_mask: 1.2650  decode.d4.loss_dice: 0.9075  decode.d5.loss_cls: 0.2515  decode.d5.loss_mask: 1.2986  decode.d5.loss_dice: 0.9208  decode.d6.loss_cls: 0.2716  decode.d6.loss_mask: 1.2799  decode.d6.loss_dice: 0.9300  decode.d7.loss_cls: 0.2417  decode.d7.loss_mask: 1.3111  decode.d7.loss_dice: 0.9500  decode.d8.loss_cls: 0.2392  decode.d8.loss_mask: 1.2796  decode.d8.loss_dice: 0.9274
05/26 15:44:26 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 15:44:26 - mmengine - INFO - Iter(train) [ 41000/160000]  base_lr: 7.6610e-05 lr: 7.6610e-06  eta: 13:33:29  time: 0.4112  data_time: 0.0094  memory: 5969  grad_norm: 760.4745  loss: 23.0048  decode.loss_cls: 0.2038  decode.loss_mask: 1.2659  decode.loss_dice: 0.7751  decode.d0.loss_cls: 0.7073  decode.d0.loss_mask: 1.2230  decode.d0.loss_dice: 0.7554  decode.d1.loss_cls: 0.2611  decode.d1.loss_mask: 1.2639  decode.d1.loss_dice: 0.7641  decode.d2.loss_cls: 0.1727  decode.d2.loss_mask: 1.2839  decode.d2.loss_dice: 0.7877  decode.d3.loss_cls: 0.2030  decode.d3.loss_mask: 1.2593  decode.d3.loss_dice: 0.7667  decode.d4.loss_cls: 0.1822  decode.d4.loss_mask: 1.3017  decode.d4.loss_dice: 0.7781  decode.d5.loss_cls: 0.1895  decode.d5.loss_mask: 1.3025  decode.d5.loss_dice: 0.7886  decode.d6.loss_cls: 0.2124  decode.d6.loss_mask: 1.2752  decode.d6.loss_dice: 0.7734  decode.d7.loss_cls: 0.2219  decode.d7.loss_mask: 1.2927  decode.d7.loss_dice: 0.7824  decode.d8.loss_cls: 0.2428  decode.d8.loss_mask: 1.2182  decode.d8.loss_dice: 0.7504
05/26 15:44:47 - mmengine - INFO - Iter(train) [ 41050/160000]  base_lr: 7.6581e-05 lr: 7.6581e-06  eta: 13:33:09  time: 0.4079  data_time: 0.0093  memory: 5968  grad_norm: 713.2745  loss: 25.0787  decode.loss_cls: 0.3773  decode.loss_mask: 1.2771  decode.loss_dice: 0.7774  decode.d0.loss_cls: 0.9429  decode.d0.loss_mask: 1.1393  decode.d0.loss_dice: 0.8674  decode.d1.loss_cls: 0.3677  decode.d1.loss_mask: 1.2649  decode.d1.loss_dice: 0.8008  decode.d2.loss_cls: 0.3779  decode.d2.loss_mask: 1.2468  decode.d2.loss_dice: 0.8105  decode.d3.loss_cls: 0.3880  decode.d3.loss_mask: 1.2709  decode.d3.loss_dice: 0.7844  decode.d4.loss_cls: 0.3843  decode.d4.loss_mask: 1.2311  decode.d4.loss_dice: 0.7995  decode.d5.loss_cls: 0.4215  decode.d5.loss_mask: 1.2427  decode.d5.loss_dice: 0.8195  decode.d6.loss_cls: 0.3556  decode.d6.loss_mask: 1.3296  decode.d6.loss_dice: 0.8952  decode.d7.loss_cls: 0.3815  decode.d7.loss_mask: 1.2440  decode.d7.loss_dice: 0.8658  decode.d8.loss_cls: 0.3351  decode.d8.loss_mask: 1.2407  decode.d8.loss_dice: 0.8393
05/26 15:45:07 - mmengine - INFO - Iter(train) [ 41100/160000]  base_lr: 7.6552e-05 lr: 7.6552e-06  eta: 13:32:48  time: 0.4063  data_time: 0.0091  memory: 5966  grad_norm: 659.4841  loss: 25.3441  decode.loss_cls: 0.3438  decode.loss_mask: 1.2864  decode.loss_dice: 0.9133  decode.d0.loss_cls: 0.8575  decode.d0.loss_mask: 1.1266  decode.d0.loss_dice: 0.8520  decode.d1.loss_cls: 0.3032  decode.d1.loss_mask: 1.2406  decode.d1.loss_dice: 0.9279  decode.d2.loss_cls: 0.3224  decode.d2.loss_mask: 1.2781  decode.d2.loss_dice: 0.9041  decode.d3.loss_cls: 0.3965  decode.d3.loss_mask: 1.2417  decode.d3.loss_dice: 0.8890  decode.d4.loss_cls: 0.3851  decode.d4.loss_mask: 1.2397  decode.d4.loss_dice: 0.8565  decode.d5.loss_cls: 0.3904  decode.d5.loss_mask: 1.2240  decode.d5.loss_dice: 0.8791  decode.d6.loss_cls: 0.4260  decode.d6.loss_mask: 1.2258  decode.d6.loss_dice: 0.9027  decode.d7.loss_cls: 0.3611  decode.d7.loss_mask: 1.2198  decode.d7.loss_dice: 0.8749  decode.d8.loss_cls: 0.3452  decode.d8.loss_mask: 1.2482  decode.d8.loss_dice: 0.8824
05/26 15:45:28 - mmengine - INFO - Iter(train) [ 41150/160000]  base_lr: 7.6523e-05 lr: 7.6523e-06  eta: 13:32:27  time: 0.4063  data_time: 0.0091  memory: 5966  grad_norm: 575.4045  loss: 22.6711  decode.loss_cls: 0.2403  decode.loss_mask: 1.1978  decode.loss_dice: 0.7966  decode.d0.loss_cls: 0.7105  decode.d0.loss_mask: 1.1400  decode.d0.loss_dice: 0.7587  decode.d1.loss_cls: 0.2767  decode.d1.loss_mask: 1.1709  decode.d1.loss_dice: 0.7824  decode.d2.loss_cls: 0.2582  decode.d2.loss_mask: 1.1676  decode.d2.loss_dice: 0.7784  decode.d3.loss_cls: 0.2317  decode.d3.loss_mask: 1.1910  decode.d3.loss_dice: 0.8087  decode.d4.loss_cls: 0.2420  decode.d4.loss_mask: 1.1914  decode.d4.loss_dice: 0.8184  decode.d5.loss_cls: 0.2840  decode.d5.loss_mask: 1.2177  decode.d5.loss_dice: 0.8023  decode.d6.loss_cls: 0.2204  decode.d6.loss_mask: 1.1797  decode.d6.loss_dice: 0.8220  decode.d7.loss_cls: 0.1859  decode.d7.loss_mask: 1.1763  decode.d7.loss_dice: 0.8070  decode.d8.loss_cls: 0.2108  decode.d8.loss_mask: 1.2000  decode.d8.loss_dice: 0.8035
05/26 15:45:48 - mmengine - INFO - Iter(train) [ 41200/160000]  base_lr: 7.6494e-05 lr: 7.6494e-06  eta: 13:32:05  time: 0.4062  data_time: 0.0091  memory: 5979  grad_norm: 625.2309  loss: 26.2681  decode.loss_cls: 0.3514  decode.loss_mask: 1.1707  decode.loss_dice: 0.9740  decode.d0.loss_cls: 0.9307  decode.d0.loss_mask: 1.1391  decode.d0.loss_dice: 0.9642  decode.d1.loss_cls: 0.3728  decode.d1.loss_mask: 1.1894  decode.d1.loss_dice: 1.0036  decode.d2.loss_cls: 0.3932  decode.d2.loss_mask: 1.1814  decode.d2.loss_dice: 1.0050  decode.d3.loss_cls: 0.4035  decode.d3.loss_mask: 1.1662  decode.d3.loss_dice: 0.9800  decode.d4.loss_cls: 0.4749  decode.d4.loss_mask: 1.1664  decode.d4.loss_dice: 0.9985  decode.d5.loss_cls: 0.4573  decode.d5.loss_mask: 1.1717  decode.d5.loss_dice: 0.9969  decode.d6.loss_cls: 0.3714  decode.d6.loss_mask: 1.2259  decode.d6.loss_dice: 1.0313  decode.d7.loss_cls: 0.3787  decode.d7.loss_mask: 1.2584  decode.d7.loss_dice: 1.0024  decode.d8.loss_cls: 0.3310  decode.d8.loss_mask: 1.1727  decode.d8.loss_dice: 1.0053
05/26 15:46:08 - mmengine - INFO - Iter(train) [ 41250/160000]  base_lr: 7.6465e-05 lr: 7.6465e-06  eta: 13:31:44  time: 0.4066  data_time: 0.0091  memory: 5976  grad_norm: 390.7404  loss: 21.9362  decode.loss_cls: 0.1765  decode.loss_mask: 1.1150  decode.loss_dice: 0.8162  decode.d0.loss_cls: 0.6275  decode.d0.loss_mask: 1.0874  decode.d0.loss_dice: 0.8104  decode.d1.loss_cls: 0.1798  decode.d1.loss_mask: 1.1267  decode.d1.loss_dice: 0.8427  decode.d2.loss_cls: 0.1957  decode.d2.loss_mask: 1.1262  decode.d2.loss_dice: 0.8269  decode.d3.loss_cls: 0.2208  decode.d3.loss_mask: 1.1247  decode.d3.loss_dice: 0.8073  decode.d4.loss_cls: 0.2029  decode.d4.loss_mask: 1.1471  decode.d4.loss_dice: 0.8363  decode.d5.loss_cls: 0.2153  decode.d5.loss_mask: 1.1172  decode.d5.loss_dice: 0.8325  decode.d6.loss_cls: 0.1945  decode.d6.loss_mask: 1.1559  decode.d6.loss_dice: 0.8728  decode.d7.loss_cls: 0.1979  decode.d7.loss_mask: 1.1187  decode.d7.loss_dice: 0.8297  decode.d8.loss_cls: 0.1925  decode.d8.loss_mask: 1.1236  decode.d8.loss_dice: 0.8155
05/26 15:46:29 - mmengine - INFO - Iter(train) [ 41300/160000]  base_lr: 7.6436e-05 lr: 7.6436e-06  eta: 13:31:23  time: 0.4072  data_time: 0.0091  memory: 5966  grad_norm: 672.7225  loss: 23.6698  decode.loss_cls: 0.2899  decode.loss_mask: 1.0698  decode.loss_dice: 0.8496  decode.d0.loss_cls: 0.7975  decode.d0.loss_mask: 1.1016  decode.d0.loss_dice: 0.8821  decode.d1.loss_cls: 0.3442  decode.d1.loss_mask: 1.0956  decode.d1.loss_dice: 0.8824  decode.d2.loss_cls: 0.3145  decode.d2.loss_mask: 1.1514  decode.d2.loss_dice: 0.8794  decode.d3.loss_cls: 0.3078  decode.d3.loss_mask: 1.1691  decode.d3.loss_dice: 0.8764  decode.d4.loss_cls: 0.3057  decode.d4.loss_mask: 1.1674  decode.d4.loss_dice: 0.8896  decode.d5.loss_cls: 0.3147  decode.d5.loss_mask: 1.1273  decode.d5.loss_dice: 0.8670  decode.d6.loss_cls: 0.3134  decode.d6.loss_mask: 1.1853  decode.d6.loss_dice: 0.8965  decode.d7.loss_cls: 0.3144  decode.d7.loss_mask: 1.1423  decode.d7.loss_dice: 0.8720  decode.d8.loss_cls: 0.2859  decode.d8.loss_mask: 1.1144  decode.d8.loss_dice: 0.8627
05/26 15:46:49 - mmengine - INFO - Iter(train) [ 41350/160000]  base_lr: 7.6407e-05 lr: 7.6407e-06  eta: 13:31:02  time: 0.4081  data_time: 0.0093  memory: 5991  grad_norm: 457.9167  loss: 24.2503  decode.loss_cls: 0.3550  decode.loss_mask: 1.0750  decode.loss_dice: 0.8905  decode.d0.loss_cls: 0.7876  decode.d0.loss_mask: 1.0652  decode.d0.loss_dice: 0.8717  decode.d1.loss_cls: 0.4546  decode.d1.loss_mask: 1.0653  decode.d1.loss_dice: 0.8897  decode.d2.loss_cls: 0.3695  decode.d2.loss_mask: 1.1626  decode.d2.loss_dice: 0.9214  decode.d3.loss_cls: 0.3703  decode.d3.loss_mask: 1.1870  decode.d3.loss_dice: 0.9091  decode.d4.loss_cls: 0.3724  decode.d4.loss_mask: 1.1291  decode.d4.loss_dice: 0.8786  decode.d5.loss_cls: 0.3403  decode.d5.loss_mask: 1.1054  decode.d5.loss_dice: 0.8958  decode.d6.loss_cls: 0.3895  decode.d6.loss_mask: 1.0801  decode.d6.loss_dice: 0.8697  decode.d7.loss_cls: 0.3543  decode.d7.loss_mask: 1.1757  decode.d7.loss_dice: 0.9258  decode.d8.loss_cls: 0.3680  decode.d8.loss_mask: 1.0782  decode.d8.loss_dice: 0.9129
05/26 15:47:09 - mmengine - INFO - Iter(train) [ 41400/160000]  base_lr: 7.6378e-05 lr: 7.6378e-06  eta: 13:30:41  time: 0.4069  data_time: 0.0092  memory: 5973  grad_norm: 783.1617  loss: 23.3743  decode.loss_cls: 0.3575  decode.loss_mask: 1.0511  decode.loss_dice: 0.9062  decode.d0.loss_cls: 0.7171  decode.d0.loss_mask: 1.0439  decode.d0.loss_dice: 0.8465  decode.d1.loss_cls: 0.3625  decode.d1.loss_mask: 1.0704  decode.d1.loss_dice: 0.8885  decode.d2.loss_cls: 0.4028  decode.d2.loss_mask: 1.0549  decode.d2.loss_dice: 0.8385  decode.d3.loss_cls: 0.3789  decode.d3.loss_mask: 1.0784  decode.d3.loss_dice: 0.8697  decode.d4.loss_cls: 0.4121  decode.d4.loss_mask: 1.0725  decode.d4.loss_dice: 0.9054  decode.d5.loss_cls: 0.3814  decode.d5.loss_mask: 1.0541  decode.d5.loss_dice: 0.8460  decode.d6.loss_cls: 0.3689  decode.d6.loss_mask: 1.0594  decode.d6.loss_dice: 0.8661  decode.d7.loss_cls: 0.4038  decode.d7.loss_mask: 1.0424  decode.d7.loss_dice: 0.8585  decode.d8.loss_cls: 0.3963  decode.d8.loss_mask: 1.0193  decode.d8.loss_dice: 0.8213
05/26 15:47:30 - mmengine - INFO - Iter(train) [ 41450/160000]  base_lr: 7.6349e-05 lr: 7.6349e-06  eta: 13:30:20  time: 0.4069  data_time: 0.0091  memory: 5966  grad_norm: 802.4543  loss: 28.4683  decode.loss_cls: 0.3577  decode.loss_mask: 1.3555  decode.loss_dice: 1.0943  decode.d0.loss_cls: 1.0558  decode.d0.loss_mask: 1.1999  decode.d0.loss_dice: 1.0604  decode.d1.loss_cls: 0.3690  decode.d1.loss_mask: 1.3520  decode.d1.loss_dice: 1.1105  decode.d2.loss_cls: 0.3486  decode.d2.loss_mask: 1.3029  decode.d2.loss_dice: 1.0785  decode.d3.loss_cls: 0.3521  decode.d3.loss_mask: 1.3514  decode.d3.loss_dice: 1.0958  decode.d4.loss_cls: 0.3502  decode.d4.loss_mask: 1.3334  decode.d4.loss_dice: 1.0759  decode.d5.loss_cls: 0.3981  decode.d5.loss_mask: 1.3202  decode.d5.loss_dice: 1.0881  decode.d6.loss_cls: 0.4126  decode.d6.loss_mask: 1.3298  decode.d6.loss_dice: 1.0387  decode.d7.loss_cls: 0.4070  decode.d7.loss_mask: 1.3780  decode.d7.loss_dice: 1.0697  decode.d8.loss_cls: 0.4022  decode.d8.loss_mask: 1.3482  decode.d8.loss_dice: 1.0318
05/26 15:47:50 - mmengine - INFO - Iter(train) [ 41500/160000]  base_lr: 7.6320e-05 lr: 7.6320e-06  eta: 13:29:59  time: 0.4072  data_time: 0.0092  memory: 5966  grad_norm: 766.7346  loss: 26.5369  decode.loss_cls: 0.3154  decode.loss_mask: 1.3398  decode.loss_dice: 0.9050  decode.d0.loss_cls: 0.7587  decode.d0.loss_mask: 1.4246  decode.d0.loss_dice: 0.9812  decode.d1.loss_cls: 0.2771  decode.d1.loss_mask: 1.3771  decode.d1.loss_dice: 0.9697  decode.d2.loss_cls: 0.2955  decode.d2.loss_mask: 1.3633  decode.d2.loss_dice: 0.9422  decode.d3.loss_cls: 0.2827  decode.d3.loss_mask: 1.3578  decode.d3.loss_dice: 0.9447  decode.d4.loss_cls: 0.3141  decode.d4.loss_mask: 1.3415  decode.d4.loss_dice: 0.9390  decode.d5.loss_cls: 0.3108  decode.d5.loss_mask: 1.3640  decode.d5.loss_dice: 0.9353  decode.d6.loss_cls: 0.2585  decode.d6.loss_mask: 1.3681  decode.d6.loss_dice: 0.9780  decode.d7.loss_cls: 0.3131  decode.d7.loss_mask: 1.3588  decode.d7.loss_dice: 0.9531  decode.d8.loss_cls: 0.2738  decode.d8.loss_mask: 1.3801  decode.d8.loss_dice: 0.9138
05/26 15:48:10 - mmengine - INFO - Iter(train) [ 41550/160000]  base_lr: 7.6291e-05 lr: 7.6291e-06  eta: 13:29:39  time: 0.4066  data_time: 0.0091  memory: 5975  grad_norm: 1051.5604  loss: 29.8259  decode.loss_cls: 0.4483  decode.loss_mask: 1.5381  decode.loss_dice: 1.0220  decode.d0.loss_cls: 0.9862  decode.d0.loss_mask: 1.4031  decode.d0.loss_dice: 0.9186  decode.d1.loss_cls: 0.4088  decode.d1.loss_mask: 1.4634  decode.d1.loss_dice: 0.9783  decode.d2.loss_cls: 0.3496  decode.d2.loss_mask: 1.5905  decode.d2.loss_dice: 0.9766  decode.d3.loss_cls: 0.3799  decode.d3.loss_mask: 1.5546  decode.d3.loss_dice: 1.0059  decode.d4.loss_cls: 0.4090  decode.d4.loss_mask: 1.5333  decode.d4.loss_dice: 0.9877  decode.d5.loss_cls: 0.4002  decode.d5.loss_mask: 1.5490  decode.d5.loss_dice: 1.0587  decode.d6.loss_cls: 0.4785  decode.d6.loss_mask: 1.4969  decode.d6.loss_dice: 0.9986  decode.d7.loss_cls: 0.3741  decode.d7.loss_mask: 1.5495  decode.d7.loss_dice: 0.9964  decode.d8.loss_cls: 0.3917  decode.d8.loss_mask: 1.5595  decode.d8.loss_dice: 1.0191
05/26 15:48:31 - mmengine - INFO - Iter(train) [ 41600/160000]  base_lr: 7.6262e-05 lr: 7.6262e-06  eta: 13:29:18  time: 0.4075  data_time: 0.0091  memory: 5976  grad_norm: 703.7414  loss: 22.3640  decode.loss_cls: 0.1766  decode.loss_mask: 1.1829  decode.loss_dice: 0.8602  decode.d0.loss_cls: 0.6168  decode.d0.loss_mask: 1.1567  decode.d0.loss_dice: 0.8029  decode.d1.loss_cls: 0.2021  decode.d1.loss_mask: 1.1303  decode.d1.loss_dice: 0.8432  decode.d2.loss_cls: 0.2876  decode.d2.loss_mask: 1.0852  decode.d2.loss_dice: 0.8424  decode.d3.loss_cls: 0.2417  decode.d3.loss_mask: 1.1088  decode.d3.loss_dice: 0.8275  decode.d4.loss_cls: 0.2514  decode.d4.loss_mask: 1.1922  decode.d4.loss_dice: 0.8583  decode.d5.loss_cls: 0.2057  decode.d5.loss_mask: 1.1306  decode.d5.loss_dice: 0.8115  decode.d6.loss_cls: 0.2299  decode.d6.loss_mask: 1.1333  decode.d6.loss_dice: 0.8512  decode.d7.loss_cls: 0.2391  decode.d7.loss_mask: 1.0750  decode.d7.loss_dice: 0.8210  decode.d8.loss_cls: 0.1780  decode.d8.loss_mask: 1.1436  decode.d8.loss_dice: 0.8786
05/26 15:48:51 - mmengine - INFO - Iter(train) [ 41650/160000]  base_lr: 7.6234e-05 lr: 7.6234e-06  eta: 13:28:57  time: 0.4073  data_time: 0.0091  memory: 5969  grad_norm: 524.9443  loss: 26.1756  decode.loss_cls: 0.3994  decode.loss_mask: 1.1788  decode.loss_dice: 0.9959  decode.d0.loss_cls: 0.9063  decode.d0.loss_mask: 1.1078  decode.d0.loss_dice: 0.9317  decode.d1.loss_cls: 0.3444  decode.d1.loss_mask: 1.2459  decode.d1.loss_dice: 0.9716  decode.d2.loss_cls: 0.3949  decode.d2.loss_mask: 1.1858  decode.d2.loss_dice: 0.9591  decode.d3.loss_cls: 0.4309  decode.d3.loss_mask: 1.1928  decode.d3.loss_dice: 0.9448  decode.d4.loss_cls: 0.3541  decode.d4.loss_mask: 1.2592  decode.d4.loss_dice: 0.9723  decode.d5.loss_cls: 0.3630  decode.d5.loss_mask: 1.2708  decode.d5.loss_dice: 1.0206  decode.d6.loss_cls: 0.3308  decode.d6.loss_mask: 1.2996  decode.d6.loss_dice: 1.0090  decode.d7.loss_cls: 0.3805  decode.d7.loss_mask: 1.2129  decode.d7.loss_dice: 0.9953  decode.d8.loss_cls: 0.3628  decode.d8.loss_mask: 1.1927  decode.d8.loss_dice: 0.9619
05/26 15:49:12 - mmengine - INFO - Iter(train) [ 41700/160000]  base_lr: 7.6205e-05 lr: 7.6205e-06  eta: 13:28:36  time: 0.4059  data_time: 0.0091  memory: 5971  grad_norm: 700.6585  loss: 22.1535  decode.loss_cls: 0.0974  decode.loss_mask: 1.2194  decode.loss_dice: 0.8205  decode.d0.loss_cls: 0.6536  decode.d0.loss_mask: 1.0547  decode.d0.loss_dice: 0.7430  decode.d1.loss_cls: 0.1330  decode.d1.loss_mask: 1.2114  decode.d1.loss_dice: 0.8211  decode.d2.loss_cls: 0.1658  decode.d2.loss_mask: 1.2220  decode.d2.loss_dice: 0.8295  decode.d3.loss_cls: 0.1389  decode.d3.loss_mask: 1.2424  decode.d3.loss_dice: 0.8265  decode.d4.loss_cls: 0.1625  decode.d4.loss_mask: 1.2406  decode.d4.loss_dice: 0.8360  decode.d5.loss_cls: 0.1706  decode.d5.loss_mask: 1.2102  decode.d5.loss_dice: 0.8189  decode.d6.loss_cls: 0.1870  decode.d6.loss_mask: 1.1530  decode.d6.loss_dice: 0.8447  decode.d7.loss_cls: 0.1896  decode.d7.loss_mask: 1.1999  decode.d7.loss_dice: 0.8548  decode.d8.loss_cls: 0.2010  decode.d8.loss_mask: 1.1267  decode.d8.loss_dice: 0.7787
05/26 15:49:32 - mmengine - INFO - Iter(train) [ 41750/160000]  base_lr: 7.6176e-05 lr: 7.6176e-06  eta: 13:28:15  time: 0.4058  data_time: 0.0090  memory: 5980  grad_norm: 418.8041  loss: 23.9278  decode.loss_cls: 0.3186  decode.loss_mask: 1.2284  decode.loss_dice: 0.8738  decode.d0.loss_cls: 0.9151  decode.d0.loss_mask: 1.0557  decode.d0.loss_dice: 0.7827  decode.d1.loss_cls: 0.3622  decode.d1.loss_mask: 1.1542  decode.d1.loss_dice: 0.8546  decode.d2.loss_cls: 0.3905  decode.d2.loss_mask: 1.1725  decode.d2.loss_dice: 0.8323  decode.d3.loss_cls: 0.3219  decode.d3.loss_mask: 1.2121  decode.d3.loss_dice: 0.8428  decode.d4.loss_cls: 0.3666  decode.d4.loss_mask: 1.1215  decode.d4.loss_dice: 0.8153  decode.d5.loss_cls: 0.3104  decode.d5.loss_mask: 1.1781  decode.d5.loss_dice: 0.8467  decode.d6.loss_cls: 0.3510  decode.d6.loss_mask: 1.1527  decode.d6.loss_dice: 0.8649  decode.d7.loss_cls: 0.3606  decode.d7.loss_mask: 1.1304  decode.d7.loss_dice: 0.8089  decode.d8.loss_cls: 0.2765  decode.d8.loss_mask: 1.1758  decode.d8.loss_dice: 0.8511
05/26 15:49:52 - mmengine - INFO - Iter(train) [ 41800/160000]  base_lr: 7.6147e-05 lr: 7.6147e-06  eta: 13:27:54  time: 0.4058  data_time: 0.0090  memory: 5971  grad_norm: 671.6599  loss: 19.8594  decode.loss_cls: 0.1491  decode.loss_mask: 1.1015  decode.loss_dice: 0.7009  decode.d0.loss_cls: 0.6219  decode.d0.loss_mask: 1.0596  decode.d0.loss_dice: 0.6826  decode.d1.loss_cls: 0.1575  decode.d1.loss_mask: 1.1021  decode.d1.loss_dice: 0.7122  decode.d2.loss_cls: 0.1478  decode.d2.loss_mask: 1.1146  decode.d2.loss_dice: 0.6825  decode.d3.loss_cls: 0.1336  decode.d3.loss_mask: 1.1031  decode.d3.loss_dice: 0.6976  decode.d4.loss_cls: 0.1747  decode.d4.loss_mask: 1.0793  decode.d4.loss_dice: 0.6925  decode.d5.loss_cls: 0.1566  decode.d5.loss_mask: 1.0829  decode.d5.loss_dice: 0.6901  decode.d6.loss_cls: 0.1194  decode.d6.loss_mask: 1.0874  decode.d6.loss_dice: 0.7018  decode.d7.loss_cls: 0.1405  decode.d7.loss_mask: 1.1092  decode.d7.loss_dice: 0.7058  decode.d8.loss_cls: 0.1791  decode.d8.loss_mask: 1.0776  decode.d8.loss_dice: 0.6958
05/26 15:50:12 - mmengine - INFO - Iter(train) [ 41850/160000]  base_lr: 7.6118e-05 lr: 7.6118e-06  eta: 13:27:33  time: 0.4065  data_time: 0.0090  memory: 5972  grad_norm: 921.9189  loss: 24.7402  decode.loss_cls: 0.3133  decode.loss_mask: 1.2379  decode.loss_dice: 0.8674  decode.d0.loss_cls: 0.8992  decode.d0.loss_mask: 1.1737  decode.d0.loss_dice: 0.8171  decode.d1.loss_cls: 0.3254  decode.d1.loss_mask: 1.2863  decode.d1.loss_dice: 0.9110  decode.d2.loss_cls: 0.3049  decode.d2.loss_mask: 1.2678  decode.d2.loss_dice: 0.8587  decode.d3.loss_cls: 0.3770  decode.d3.loss_mask: 1.1996  decode.d3.loss_dice: 0.8526  decode.d4.loss_cls: 0.3268  decode.d4.loss_mask: 1.2132  decode.d4.loss_dice: 0.8245  decode.d5.loss_cls: 0.2880  decode.d5.loss_mask: 1.2578  decode.d5.loss_dice: 0.9282  decode.d6.loss_cls: 0.3068  decode.d6.loss_mask: 1.2547  decode.d6.loss_dice: 0.8863  decode.d7.loss_cls: 0.3489  decode.d7.loss_mask: 1.2071  decode.d7.loss_dice: 0.8205  decode.d8.loss_cls: 0.3306  decode.d8.loss_mask: 1.2053  decode.d8.loss_dice: 0.8497
05/26 15:50:33 - mmengine - INFO - Iter(train) [ 41900/160000]  base_lr: 7.6089e-05 lr: 7.6089e-06  eta: 13:27:12  time: 0.4057  data_time: 0.0092  memory: 5984  grad_norm: 788.0122  loss: 29.5705  decode.loss_cls: 0.3175  decode.loss_mask: 1.4830  decode.loss_dice: 1.0583  decode.d0.loss_cls: 0.8998  decode.d0.loss_mask: 1.3744  decode.d0.loss_dice: 0.9852  decode.d1.loss_cls: 0.3529  decode.d1.loss_mask: 1.4892  decode.d1.loss_dice: 1.0503  decode.d2.loss_cls: 0.3614  decode.d2.loss_mask: 1.4717  decode.d2.loss_dice: 1.0470  decode.d3.loss_cls: 0.3428  decode.d3.loss_mask: 1.5244  decode.d3.loss_dice: 1.0412  decode.d4.loss_cls: 0.3357  decode.d4.loss_mask: 1.6297  decode.d4.loss_dice: 1.0597  decode.d5.loss_cls: 0.3380  decode.d5.loss_mask: 1.5661  decode.d5.loss_dice: 1.0784  decode.d6.loss_cls: 0.3623  decode.d6.loss_mask: 1.5370  decode.d6.loss_dice: 1.0440  decode.d7.loss_cls: 0.3627  decode.d7.loss_mask: 1.5229  decode.d7.loss_dice: 1.0699  decode.d8.loss_cls: 0.3356  decode.d8.loss_mask: 1.4879  decode.d8.loss_dice: 1.0415
05/26 15:50:53 - mmengine - INFO - Iter(train) [ 41950/160000]  base_lr: 7.6060e-05 lr: 7.6060e-06  eta: 13:26:51  time: 0.4065  data_time: 0.0091  memory: 5976  grad_norm: 1083.5206  loss: 26.8595  decode.loss_cls: 0.2966  decode.loss_mask: 1.2745  decode.loss_dice: 1.0778  decode.d0.loss_cls: 0.8460  decode.d0.loss_mask: 1.1305  decode.d0.loss_dice: 1.0382  decode.d1.loss_cls: 0.3444  decode.d1.loss_mask: 1.2604  decode.d1.loss_dice: 1.0600  decode.d2.loss_cls: 0.3316  decode.d2.loss_mask: 1.2170  decode.d2.loss_dice: 1.0298  decode.d3.loss_cls: 0.3455  decode.d3.loss_mask: 1.1938  decode.d3.loss_dice: 1.0407  decode.d4.loss_cls: 0.3796  decode.d4.loss_mask: 1.2139  decode.d4.loss_dice: 1.0826  decode.d5.loss_cls: 0.4161  decode.d5.loss_mask: 1.2179  decode.d5.loss_dice: 1.0714  decode.d6.loss_cls: 0.4067  decode.d6.loss_mask: 1.2123  decode.d6.loss_dice: 1.0721  decode.d7.loss_cls: 0.3993  decode.d7.loss_mask: 1.2268  decode.d7.loss_dice: 1.0291  decode.d8.loss_cls: 0.3935  decode.d8.loss_mask: 1.2301  decode.d8.loss_dice: 1.0212
05/26 15:51:13 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 15:51:13 - mmengine - INFO - Iter(train) [ 42000/160000]  base_lr: 7.6031e-05 lr: 7.6031e-06  eta: 13:26:30  time: 0.4060  data_time: 0.0091  memory: 5970  grad_norm: 830.3528  loss: 26.9466  decode.loss_cls: 0.4386  decode.loss_mask: 1.2023  decode.loss_dice: 0.9846  decode.d0.loss_cls: 0.9042  decode.d0.loss_mask: 1.1549  decode.d0.loss_dice: 0.9419  decode.d1.loss_cls: 0.4608  decode.d1.loss_mask: 1.2116  decode.d1.loss_dice: 1.0388  decode.d2.loss_cls: 0.4393  decode.d2.loss_mask: 1.2468  decode.d2.loss_dice: 0.9957  decode.d3.loss_cls: 0.4470  decode.d3.loss_mask: 1.2654  decode.d3.loss_dice: 1.0382  decode.d4.loss_cls: 0.4750  decode.d4.loss_mask: 1.1831  decode.d4.loss_dice: 0.9924  decode.d5.loss_cls: 0.3854  decode.d5.loss_mask: 1.2037  decode.d5.loss_dice: 1.0130  decode.d6.loss_cls: 0.4890  decode.d6.loss_mask: 1.2237  decode.d6.loss_dice: 1.0407  decode.d7.loss_cls: 0.4164  decode.d7.loss_mask: 1.1854  decode.d7.loss_dice: 0.9978  decode.d8.loss_cls: 0.4913  decode.d8.loss_mask: 1.1420  decode.d8.loss_dice: 0.9376
05/26 15:51:34 - mmengine - INFO - Iter(train) [ 42050/160000]  base_lr: 7.6002e-05 lr: 7.6002e-06  eta: 13:26:09  time: 0.4067  data_time: 0.0091  memory: 5980  grad_norm: 792.4994  loss: 25.7466  decode.loss_cls: 0.2400  decode.loss_mask: 1.3598  decode.loss_dice: 0.9223  decode.d0.loss_cls: 0.7577  decode.d0.loss_mask: 1.3673  decode.d0.loss_dice: 0.9209  decode.d1.loss_cls: 0.1784  decode.d1.loss_mask: 1.4235  decode.d1.loss_dice: 0.9543  decode.d2.loss_cls: 0.1932  decode.d2.loss_mask: 1.3479  decode.d2.loss_dice: 0.9084  decode.d3.loss_cls: 0.2277  decode.d3.loss_mask: 1.3583  decode.d3.loss_dice: 0.9196  decode.d4.loss_cls: 0.2572  decode.d4.loss_mask: 1.3702  decode.d4.loss_dice: 0.9112  decode.d5.loss_cls: 0.2744  decode.d5.loss_mask: 1.3539  decode.d5.loss_dice: 0.9306  decode.d6.loss_cls: 0.2669  decode.d6.loss_mask: 1.3566  decode.d6.loss_dice: 0.9147  decode.d7.loss_cls: 0.2634  decode.d7.loss_mask: 1.3685  decode.d7.loss_dice: 0.9066  decode.d8.loss_cls: 0.2122  decode.d8.loss_mask: 1.3802  decode.d8.loss_dice: 0.9004
05/26 15:51:54 - mmengine - INFO - Iter(train) [ 42100/160000]  base_lr: 7.5973e-05 lr: 7.5973e-06  eta: 13:25:48  time: 0.4060  data_time: 0.0091  memory: 5968  grad_norm: 648.4737  loss: 24.8996  decode.loss_cls: 0.2677  decode.loss_mask: 1.2268  decode.loss_dice: 0.8974  decode.d0.loss_cls: 0.6924  decode.d0.loss_mask: 1.2145  decode.d0.loss_dice: 0.9106  decode.d1.loss_cls: 0.2533  decode.d1.loss_mask: 1.2703  decode.d1.loss_dice: 0.9421  decode.d2.loss_cls: 0.2294  decode.d2.loss_mask: 1.3106  decode.d2.loss_dice: 0.9303  decode.d3.loss_cls: 0.2304  decode.d3.loss_mask: 1.2742  decode.d3.loss_dice: 0.9078  decode.d4.loss_cls: 0.2588  decode.d4.loss_mask: 1.2605  decode.d4.loss_dice: 0.9148  decode.d5.loss_cls: 0.2570  decode.d5.loss_mask: 1.2826  decode.d5.loss_dice: 0.9311  decode.d6.loss_cls: 0.2653  decode.d6.loss_mask: 1.2620  decode.d6.loss_dice: 0.9338  decode.d7.loss_cls: 0.3425  decode.d7.loss_mask: 1.2660  decode.d7.loss_dice: 0.9252  decode.d8.loss_cls: 0.2503  decode.d8.loss_mask: 1.2691  decode.d8.loss_dice: 0.9227
05/26 15:52:15 - mmengine - INFO - Iter(train) [ 42150/160000]  base_lr: 7.5944e-05 lr: 7.5944e-06  eta: 13:25:27  time: 0.4060  data_time: 0.0092  memory: 5980  grad_norm: 819.8797  loss: 25.4616  decode.loss_cls: 0.3184  decode.loss_mask: 1.2571  decode.loss_dice: 0.9735  decode.d0.loss_cls: 0.8038  decode.d0.loss_mask: 1.1601  decode.d0.loss_dice: 0.9217  decode.d1.loss_cls: 0.3593  decode.d1.loss_mask: 1.1761  decode.d1.loss_dice: 0.9504  decode.d2.loss_cls: 0.3814  decode.d2.loss_mask: 1.1937  decode.d2.loss_dice: 0.9007  decode.d3.loss_cls: 0.4224  decode.d3.loss_mask: 1.2106  decode.d3.loss_dice: 0.9353  decode.d4.loss_cls: 0.3750  decode.d4.loss_mask: 1.1942  decode.d4.loss_dice: 0.9694  decode.d5.loss_cls: 0.3356  decode.d5.loss_mask: 1.2073  decode.d5.loss_dice: 0.9368  decode.d6.loss_cls: 0.3669  decode.d6.loss_mask: 1.2220  decode.d6.loss_dice: 0.9421  decode.d7.loss_cls: 0.3817  decode.d7.loss_mask: 1.1809  decode.d7.loss_dice: 0.8955  decode.d8.loss_cls: 0.3483  decode.d8.loss_mask: 1.2223  decode.d8.loss_dice: 0.9191
05/26 15:52:35 - mmengine - INFO - Iter(train) [ 42200/160000]  base_lr: 7.5915e-05 lr: 7.5915e-06  eta: 13:25:06  time: 0.4070  data_time: 0.0091  memory: 5971  grad_norm: 1095.5101  loss: 18.8964  decode.loss_cls: 0.2024  decode.loss_mask: 0.9131  decode.loss_dice: 0.6910  decode.d0.loss_cls: 0.6660  decode.d0.loss_mask: 0.8432  decode.d0.loss_dice: 0.6627  decode.d1.loss_cls: 0.2717  decode.d1.loss_mask: 0.8948  decode.d1.loss_dice: 0.6923  decode.d2.loss_cls: 0.2538  decode.d2.loss_mask: 0.9200  decode.d2.loss_dice: 0.6779  decode.d3.loss_cls: 0.2027  decode.d3.loss_mask: 0.9974  decode.d3.loss_dice: 0.6992  decode.d4.loss_cls: 0.2904  decode.d4.loss_mask: 0.9495  decode.d4.loss_dice: 0.6756  decode.d5.loss_cls: 0.2496  decode.d5.loss_mask: 0.8971  decode.d5.loss_dice: 0.6764  decode.d6.loss_cls: 0.2458  decode.d6.loss_mask: 0.9283  decode.d6.loss_dice: 0.6730  decode.d7.loss_cls: 0.2391  decode.d7.loss_mask: 0.9721  decode.d7.loss_dice: 0.7320  decode.d8.loss_cls: 0.2324  decode.d8.loss_mask: 0.8849  decode.d8.loss_dice: 0.6622
05/26 15:52:55 - mmengine - INFO - Iter(train) [ 42250/160000]  base_lr: 7.5886e-05 lr: 7.5886e-06  eta: 13:24:45  time: 0.4059  data_time: 0.0090  memory: 5996  grad_norm: 789.5165  loss: 24.2495  decode.loss_cls: 0.1660  decode.loss_mask: 1.3074  decode.loss_dice: 0.9498  decode.d0.loss_cls: 0.6949  decode.d0.loss_mask: 1.2008  decode.d0.loss_dice: 0.8537  decode.d1.loss_cls: 0.1771  decode.d1.loss_mask: 1.2518  decode.d1.loss_dice: 0.8979  decode.d2.loss_cls: 0.2217  decode.d2.loss_mask: 1.2675  decode.d2.loss_dice: 0.9267  decode.d3.loss_cls: 0.1740  decode.d3.loss_mask: 1.2726  decode.d3.loss_dice: 0.9261  decode.d4.loss_cls: 0.1826  decode.d4.loss_mask: 1.2746  decode.d4.loss_dice: 0.9362  decode.d5.loss_cls: 0.1774  decode.d5.loss_mask: 1.2844  decode.d5.loss_dice: 0.9259  decode.d6.loss_cls: 0.2268  decode.d6.loss_mask: 1.2423  decode.d6.loss_dice: 0.9337  decode.d7.loss_cls: 0.1776  decode.d7.loss_mask: 1.2882  decode.d7.loss_dice: 0.9327  decode.d8.loss_cls: 0.1837  decode.d8.loss_mask: 1.2652  decode.d8.loss_dice: 0.9301
05/26 15:53:16 - mmengine - INFO - Iter(train) [ 42300/160000]  base_lr: 7.5857e-05 lr: 7.5857e-06  eta: 13:24:24  time: 0.4062  data_time: 0.0091  memory: 5967  grad_norm: 578.2131  loss: 21.5183  decode.loss_cls: 0.1730  decode.loss_mask: 1.0714  decode.loss_dice: 0.8443  decode.d0.loss_cls: 0.7472  decode.d0.loss_mask: 0.9977  decode.d0.loss_dice: 0.7575  decode.d1.loss_cls: 0.2314  decode.d1.loss_mask: 1.0465  decode.d1.loss_dice: 0.8440  decode.d2.loss_cls: 0.2229  decode.d2.loss_mask: 1.0714  decode.d2.loss_dice: 0.8746  decode.d3.loss_cls: 0.2293  decode.d3.loss_mask: 1.0592  decode.d3.loss_dice: 0.8261  decode.d4.loss_cls: 0.2659  decode.d4.loss_mask: 1.0541  decode.d4.loss_dice: 0.8375  decode.d5.loss_cls: 0.2396  decode.d5.loss_mask: 0.9967  decode.d5.loss_dice: 0.7803  decode.d6.loss_cls: 0.2673  decode.d6.loss_mask: 1.0544  decode.d6.loss_dice: 0.7881  decode.d7.loss_cls: 0.2512  decode.d7.loss_mask: 1.0704  decode.d7.loss_dice: 0.8227  decode.d8.loss_cls: 0.2346  decode.d8.loss_mask: 1.0595  decode.d8.loss_dice: 0.7996
05/26 15:53:36 - mmengine - INFO - Iter(train) [ 42350/160000]  base_lr: 7.5828e-05 lr: 7.5828e-06  eta: 13:24:03  time: 0.4063  data_time: 0.0091  memory: 5966  grad_norm: 781.2138  loss: 24.5153  decode.loss_cls: 0.3159  decode.loss_mask: 1.1749  decode.loss_dice: 0.8780  decode.d0.loss_cls: 0.7250  decode.d0.loss_mask: 1.1825  decode.d0.loss_dice: 0.8847  decode.d1.loss_cls: 0.2740  decode.d1.loss_mask: 1.2412  decode.d1.loss_dice: 0.9287  decode.d2.loss_cls: 0.3347  decode.d2.loss_mask: 1.1945  decode.d2.loss_dice: 0.8792  decode.d3.loss_cls: 0.3213  decode.d3.loss_mask: 1.2243  decode.d3.loss_dice: 0.9159  decode.d4.loss_cls: 0.3295  decode.d4.loss_mask: 1.1740  decode.d4.loss_dice: 0.8557  decode.d5.loss_cls: 0.3172  decode.d5.loss_mask: 1.1985  decode.d5.loss_dice: 0.9150  decode.d6.loss_cls: 0.3168  decode.d6.loss_mask: 1.2127  decode.d6.loss_dice: 0.9178  decode.d7.loss_cls: 0.3441  decode.d7.loss_mask: 1.1783  decode.d7.loss_dice: 0.9132  decode.d8.loss_cls: 0.3278  decode.d8.loss_mask: 1.1668  decode.d8.loss_dice: 0.8729
05/26 15:53:56 - mmengine - INFO - Iter(train) [ 42400/160000]  base_lr: 7.5799e-05 lr: 7.5799e-06  eta: 13:23:42  time: 0.4069  data_time: 0.0091  memory: 5966  grad_norm: 695.0253  loss: 19.9618  decode.loss_cls: 0.1205  decode.loss_mask: 1.0821  decode.loss_dice: 0.6997  decode.d0.loss_cls: 0.5450  decode.d0.loss_mask: 1.0996  decode.d0.loss_dice: 0.6851  decode.d1.loss_cls: 0.1615  decode.d1.loss_mask: 1.1049  decode.d1.loss_dice: 0.7206  decode.d2.loss_cls: 0.1229  decode.d2.loss_mask: 1.1248  decode.d2.loss_dice: 0.7156  decode.d3.loss_cls: 0.1534  decode.d3.loss_mask: 1.0782  decode.d3.loss_dice: 0.6957  decode.d4.loss_cls: 0.1282  decode.d4.loss_mask: 1.1077  decode.d4.loss_dice: 0.7043  decode.d5.loss_cls: 0.1069  decode.d5.loss_mask: 1.1319  decode.d5.loss_dice: 0.7339  decode.d6.loss_cls: 0.1339  decode.d6.loss_mask: 1.1327  decode.d6.loss_dice: 0.7295  decode.d7.loss_cls: 0.1064  decode.d7.loss_mask: 1.1229  decode.d7.loss_dice: 0.7523  decode.d8.loss_cls: 0.1155  decode.d8.loss_mask: 1.1261  decode.d8.loss_dice: 0.7199
05/26 15:54:17 - mmengine - INFO - Iter(train) [ 42450/160000]  base_lr: 7.5770e-05 lr: 7.5770e-06  eta: 13:23:21  time: 0.4067  data_time: 0.0092  memory: 5983  grad_norm: 694.2218  loss: 20.6933  decode.loss_cls: 0.3039  decode.loss_mask: 0.9292  decode.loss_dice: 0.8051  decode.d0.loss_cls: 0.7487  decode.d0.loss_mask: 0.8133  decode.d0.loss_dice: 0.7400  decode.d1.loss_cls: 0.3888  decode.d1.loss_mask: 0.8778  decode.d1.loss_dice: 0.7919  decode.d2.loss_cls: 0.3261  decode.d2.loss_mask: 0.8911  decode.d2.loss_dice: 0.7995  decode.d3.loss_cls: 0.3812  decode.d3.loss_mask: 0.8333  decode.d3.loss_dice: 0.7287  decode.d4.loss_cls: 0.3761  decode.d4.loss_mask: 0.8784  decode.d4.loss_dice: 0.8008  decode.d5.loss_cls: 0.3891  decode.d5.loss_mask: 0.8641  decode.d5.loss_dice: 0.7561  decode.d6.loss_cls: 0.4214  decode.d6.loss_mask: 0.8829  decode.d6.loss_dice: 0.7912  decode.d7.loss_cls: 0.3800  decode.d7.loss_mask: 0.8920  decode.d7.loss_dice: 0.8346  decode.d8.loss_cls: 0.3633  decode.d8.loss_mask: 0.8943  decode.d8.loss_dice: 0.8105
05/26 15:54:37 - mmengine - INFO - Iter(train) [ 42500/160000]  base_lr: 7.5741e-05 lr: 7.5741e-06  eta: 13:23:00  time: 0.4064  data_time: 0.0092  memory: 5966  grad_norm: 684.7366  loss: 20.8205  decode.loss_cls: 0.2142  decode.loss_mask: 1.1958  decode.loss_dice: 0.7115  decode.d0.loss_cls: 0.5650  decode.d0.loss_mask: 1.1258  decode.d0.loss_dice: 0.6669  decode.d1.loss_cls: 0.1583  decode.d1.loss_mask: 1.1938  decode.d1.loss_dice: 0.6818  decode.d2.loss_cls: 0.1733  decode.d2.loss_mask: 1.1659  decode.d2.loss_dice: 0.6853  decode.d3.loss_cls: 0.1801  decode.d3.loss_mask: 1.1851  decode.d3.loss_dice: 0.6965  decode.d4.loss_cls: 0.1505  decode.d4.loss_mask: 1.1403  decode.d4.loss_dice: 0.6795  decode.d5.loss_cls: 0.1364  decode.d5.loss_mask: 1.2060  decode.d5.loss_dice: 0.6983  decode.d6.loss_cls: 0.1969  decode.d6.loss_mask: 1.1885  decode.d6.loss_dice: 0.7123  decode.d7.loss_cls: 0.1755  decode.d7.loss_mask: 1.1847  decode.d7.loss_dice: 0.6926  decode.d8.loss_cls: 0.1583  decode.d8.loss_mask: 1.2081  decode.d8.loss_dice: 0.6934
05/26 15:54:57 - mmengine - INFO - Iter(train) [ 42550/160000]  base_lr: 7.5712e-05 lr: 7.5712e-06  eta: 13:22:39  time: 0.4064  data_time: 0.0091  memory: 5969  grad_norm: 412.7917  loss: 19.9575  decode.loss_cls: 0.1242  decode.loss_mask: 1.0393  decode.loss_dice: 0.7605  decode.d0.loss_cls: 0.6976  decode.d0.loss_mask: 0.9932  decode.d0.loss_dice: 0.7041  decode.d1.loss_cls: 0.1875  decode.d1.loss_mask: 1.0240  decode.d1.loss_dice: 0.7380  decode.d2.loss_cls: 0.1809  decode.d2.loss_mask: 1.0246  decode.d2.loss_dice: 0.7341  decode.d3.loss_cls: 0.2109  decode.d3.loss_mask: 1.0337  decode.d3.loss_dice: 0.7205  decode.d4.loss_cls: 0.2015  decode.d4.loss_mask: 1.0324  decode.d4.loss_dice: 0.7085  decode.d5.loss_cls: 0.1767  decode.d5.loss_mask: 1.0421  decode.d5.loss_dice: 0.7374  decode.d6.loss_cls: 0.1673  decode.d6.loss_mask: 1.0693  decode.d6.loss_dice: 0.7532  decode.d7.loss_cls: 0.1627  decode.d7.loss_mask: 1.0331  decode.d7.loss_dice: 0.7604  decode.d8.loss_cls: 0.1557  decode.d8.loss_mask: 1.0618  decode.d8.loss_dice: 0.7222
05/26 15:55:18 - mmengine - INFO - Iter(train) [ 42600/160000]  base_lr: 7.5683e-05 lr: 7.5683e-06  eta: 13:22:18  time: 0.4064  data_time: 0.0091  memory: 5976  grad_norm: 523.8574  loss: 20.0534  decode.loss_cls: 0.3312  decode.loss_mask: 0.9745  decode.loss_dice: 0.7154  decode.d0.loss_cls: 0.7451  decode.d0.loss_mask: 0.9057  decode.d0.loss_dice: 0.6615  decode.d1.loss_cls: 0.3492  decode.d1.loss_mask: 0.9470  decode.d1.loss_dice: 0.6746  decode.d2.loss_cls: 0.2970  decode.d2.loss_mask: 0.9835  decode.d2.loss_dice: 0.6862  decode.d3.loss_cls: 0.2687  decode.d3.loss_mask: 0.9769  decode.d3.loss_dice: 0.6915  decode.d4.loss_cls: 0.2981  decode.d4.loss_mask: 1.0022  decode.d4.loss_dice: 0.6891  decode.d5.loss_cls: 0.2796  decode.d5.loss_mask: 1.0130  decode.d5.loss_dice: 0.6970  decode.d6.loss_cls: 0.2969  decode.d6.loss_mask: 0.9463  decode.d6.loss_dice: 0.6885  decode.d7.loss_cls: 0.2816  decode.d7.loss_mask: 0.9824  decode.d7.loss_dice: 0.7195  decode.d8.loss_cls: 0.2895  decode.d8.loss_mask: 0.9708  decode.d8.loss_dice: 0.6910
05/26 15:55:38 - mmengine - INFO - Iter(train) [ 42650/160000]  base_lr: 7.5654e-05 lr: 7.5654e-06  eta: 13:21:57  time: 0.4062  data_time: 0.0091  memory: 5983  grad_norm: 744.8546  loss: 22.9299  decode.loss_cls: 0.2324  decode.loss_mask: 1.1526  decode.loss_dice: 0.8196  decode.d0.loss_cls: 0.8216  decode.d0.loss_mask: 1.0819  decode.d0.loss_dice: 0.8202  decode.d1.loss_cls: 0.2923  decode.d1.loss_mask: 1.1072  decode.d1.loss_dice: 0.8115  decode.d2.loss_cls: 0.2417  decode.d2.loss_mask: 1.1662  decode.d2.loss_dice: 0.8382  decode.d3.loss_cls: 0.2768  decode.d3.loss_mask: 1.1607  decode.d3.loss_dice: 0.8203  decode.d4.loss_cls: 0.2887  decode.d4.loss_mask: 1.1311  decode.d4.loss_dice: 0.8209  decode.d5.loss_cls: 0.2478  decode.d5.loss_mask: 1.1944  decode.d5.loss_dice: 0.8226  decode.d6.loss_cls: 0.3082  decode.d6.loss_mask: 1.1303  decode.d6.loss_dice: 0.8066  decode.d7.loss_cls: 0.2795  decode.d7.loss_mask: 1.1407  decode.d7.loss_dice: 0.8243  decode.d8.loss_cls: 0.2201  decode.d8.loss_mask: 1.2067  decode.d8.loss_dice: 0.8651
05/26 15:55:58 - mmengine - INFO - Iter(train) [ 42700/160000]  base_lr: 7.5625e-05 lr: 7.5625e-06  eta: 13:21:36  time: 0.4072  data_time: 0.0092  memory: 5971  grad_norm: 712.3596  loss: 22.1025  decode.loss_cls: 0.2348  decode.loss_mask: 1.0849  decode.loss_dice: 0.8438  decode.d0.loss_cls: 0.8143  decode.d0.loss_mask: 1.0321  decode.d0.loss_dice: 0.8037  decode.d1.loss_cls: 0.2897  decode.d1.loss_mask: 1.0618  decode.d1.loss_dice: 0.8195  decode.d2.loss_cls: 0.2798  decode.d2.loss_mask: 1.0733  decode.d2.loss_dice: 0.8067  decode.d3.loss_cls: 0.2619  decode.d3.loss_mask: 1.0403  decode.d3.loss_dice: 0.8396  decode.d4.loss_cls: 0.2562  decode.d4.loss_mask: 1.0610  decode.d4.loss_dice: 0.8283  decode.d5.loss_cls: 0.2435  decode.d5.loss_mask: 1.0562  decode.d5.loss_dice: 0.8244  decode.d6.loss_cls: 0.3058  decode.d6.loss_mask: 1.0470  decode.d6.loss_dice: 0.8356  decode.d7.loss_cls: 0.2602  decode.d7.loss_mask: 1.0355  decode.d7.loss_dice: 0.8199  decode.d8.loss_cls: 0.2675  decode.d8.loss_mask: 1.1302  decode.d8.loss_dice: 0.8448
05/26 15:56:19 - mmengine - INFO - Iter(train) [ 42750/160000]  base_lr: 7.5596e-05 lr: 7.5596e-06  eta: 13:21:16  time: 0.4074  data_time: 0.0092  memory: 5969  grad_norm: 594.7031  loss: 25.6803  decode.loss_cls: 0.3835  decode.loss_mask: 1.1142  decode.loss_dice: 0.9724  decode.d0.loss_cls: 0.8666  decode.d0.loss_mask: 1.0614  decode.d0.loss_dice: 0.9541  decode.d1.loss_cls: 0.3831  decode.d1.loss_mask: 1.1347  decode.d1.loss_dice: 1.0062  decode.d2.loss_cls: 0.4152  decode.d2.loss_mask: 1.1139  decode.d2.loss_dice: 0.9731  decode.d3.loss_cls: 0.4140  decode.d3.loss_mask: 1.1309  decode.d3.loss_dice: 1.0040  decode.d4.loss_cls: 0.3968  decode.d4.loss_mask: 1.1557  decode.d4.loss_dice: 1.0312  decode.d5.loss_cls: 0.4002  decode.d5.loss_mask: 1.1476  decode.d5.loss_dice: 1.0056  decode.d6.loss_cls: 0.3808  decode.d6.loss_mask: 1.1315  decode.d6.loss_dice: 1.0207  decode.d7.loss_cls: 0.4378  decode.d7.loss_mask: 1.1123  decode.d7.loss_dice: 1.0300  decode.d8.loss_cls: 0.4179  decode.d8.loss_mask: 1.0743  decode.d8.loss_dice: 1.0107
05/26 15:56:39 - mmengine - INFO - Iter(train) [ 42800/160000]  base_lr: 7.5567e-05 lr: 7.5567e-06  eta: 13:20:55  time: 0.4069  data_time: 0.0091  memory: 5971  grad_norm: 589.0358  loss: 23.9173  decode.loss_cls: 0.3417  decode.loss_mask: 1.0960  decode.loss_dice: 0.8451  decode.d0.loss_cls: 0.8170  decode.d0.loss_mask: 1.0889  decode.d0.loss_dice: 0.8034  decode.d1.loss_cls: 0.3979  decode.d1.loss_mask: 1.0914  decode.d1.loss_dice: 0.8470  decode.d2.loss_cls: 0.3975  decode.d2.loss_mask: 1.1361  decode.d2.loss_dice: 0.8929  decode.d3.loss_cls: 0.3771  decode.d3.loss_mask: 1.1025  decode.d3.loss_dice: 0.8967  decode.d4.loss_cls: 0.4004  decode.d4.loss_mask: 1.0974  decode.d4.loss_dice: 0.8811  decode.d5.loss_cls: 0.3974  decode.d5.loss_mask: 1.1168  decode.d5.loss_dice: 0.8696  decode.d6.loss_cls: 0.4053  decode.d6.loss_mask: 1.1034  decode.d6.loss_dice: 0.8443  decode.d7.loss_cls: 0.3889  decode.d7.loss_mask: 1.1135  decode.d7.loss_dice: 0.8487  decode.d8.loss_cls: 0.3574  decode.d8.loss_mask: 1.0837  decode.d8.loss_dice: 0.8785
05/26 15:56:59 - mmengine - INFO - Iter(train) [ 42850/160000]  base_lr: 7.5537e-05 lr: 7.5537e-06  eta: 13:20:34  time: 0.4079  data_time: 0.0092  memory: 5975  grad_norm: 758.4400  loss: 27.2078  decode.loss_cls: 0.4094  decode.loss_mask: 1.3852  decode.loss_dice: 1.0046  decode.d0.loss_cls: 0.9771  decode.d0.loss_mask: 1.1849  decode.d0.loss_dice: 0.8814  decode.d1.loss_cls: 0.3970  decode.d1.loss_mask: 1.3446  decode.d1.loss_dice: 0.9986  decode.d2.loss_cls: 0.4297  decode.d2.loss_mask: 1.2342  decode.d2.loss_dice: 0.9500  decode.d3.loss_cls: 0.4350  decode.d3.loss_mask: 1.2497  decode.d3.loss_dice: 0.9607  decode.d4.loss_cls: 0.4380  decode.d4.loss_mask: 1.2272  decode.d4.loss_dice: 0.9227  decode.d5.loss_cls: 0.4363  decode.d5.loss_mask: 1.2580  decode.d5.loss_dice: 0.9561  decode.d6.loss_cls: 0.4831  decode.d6.loss_mask: 1.2296  decode.d6.loss_dice: 0.9764  decode.d7.loss_cls: 0.4658  decode.d7.loss_mask: 1.3002  decode.d7.loss_dice: 0.9786  decode.d8.loss_cls: 0.4042  decode.d8.loss_mask: 1.3342  decode.d8.loss_dice: 0.9553
05/26 15:57:20 - mmengine - INFO - Iter(train) [ 42900/160000]  base_lr: 7.5508e-05 lr: 7.5508e-06  eta: 13:20:13  time: 0.4056  data_time: 0.0091  memory: 5968  grad_norm: 503.8423  loss: 23.2653  decode.loss_cls: 0.2235  decode.loss_mask: 1.0843  decode.loss_dice: 0.9374  decode.d0.loss_cls: 0.6926  decode.d0.loss_mask: 1.0680  decode.d0.loss_dice: 0.8852  decode.d1.loss_cls: 0.3037  decode.d1.loss_mask: 1.0793  decode.d1.loss_dice: 0.9265  decode.d2.loss_cls: 0.2846  decode.d2.loss_mask: 1.0596  decode.d2.loss_dice: 0.9232  decode.d3.loss_cls: 0.2687  decode.d3.loss_mask: 1.0878  decode.d3.loss_dice: 0.9556  decode.d4.loss_cls: 0.2688  decode.d4.loss_mask: 1.0812  decode.d4.loss_dice: 0.9360  decode.d5.loss_cls: 0.2341  decode.d5.loss_mask: 1.1220  decode.d5.loss_dice: 0.9633  decode.d6.loss_cls: 0.2729  decode.d6.loss_mask: 1.0859  decode.d6.loss_dice: 0.9465  decode.d7.loss_cls: 0.2549  decode.d7.loss_mask: 1.0909  decode.d7.loss_dice: 0.9572  decode.d8.loss_cls: 0.2393  decode.d8.loss_mask: 1.0898  decode.d8.loss_dice: 0.9424
05/26 15:57:40 - mmengine - INFO - Iter(train) [ 42950/160000]  base_lr: 7.5479e-05 lr: 7.5479e-06  eta: 13:19:52  time: 0.4061  data_time: 0.0091  memory: 5967  grad_norm: 1392.8998  loss: 23.6408  decode.loss_cls: 0.2881  decode.loss_mask: 1.1008  decode.loss_dice: 0.8147  decode.d0.loss_cls: 0.9356  decode.d0.loss_mask: 1.1168  decode.d0.loss_dice: 0.8178  decode.d1.loss_cls: 0.2909  decode.d1.loss_mask: 1.1974  decode.d1.loss_dice: 0.8616  decode.d2.loss_cls: 0.2999  decode.d2.loss_mask: 1.1679  decode.d2.loss_dice: 0.8187  decode.d3.loss_cls: 0.2895  decode.d3.loss_mask: 1.1265  decode.d3.loss_dice: 0.8036  decode.d4.loss_cls: 0.2792  decode.d4.loss_mask: 1.1694  decode.d4.loss_dice: 0.8500  decode.d5.loss_cls: 0.3168  decode.d5.loss_mask: 1.1845  decode.d5.loss_dice: 0.8195  decode.d6.loss_cls: 0.3521  decode.d6.loss_mask: 1.1690  decode.d6.loss_dice: 0.8027  decode.d7.loss_cls: 0.3411  decode.d7.loss_mask: 1.2637  decode.d7.loss_dice: 0.8711  decode.d8.loss_cls: 0.3081  decode.d8.loss_mask: 1.1449  decode.d8.loss_dice: 0.8388
05/26 15:58:00 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 15:58:00 - mmengine - INFO - Iter(train) [ 43000/160000]  base_lr: 7.5450e-05 lr: 7.5450e-06  eta: 13:19:31  time: 0.4073  data_time: 0.0092  memory: 5983  grad_norm: 1181.2710  loss: 27.1258  decode.loss_cls: 0.3725  decode.loss_mask: 1.3434  decode.loss_dice: 0.9702  decode.d0.loss_cls: 0.7924  decode.d0.loss_mask: 1.2495  decode.d0.loss_dice: 0.9502  decode.d1.loss_cls: 0.3428  decode.d1.loss_mask: 1.3732  decode.d1.loss_dice: 1.0043  decode.d2.loss_cls: 0.3787  decode.d2.loss_mask: 1.3623  decode.d2.loss_dice: 0.9800  decode.d3.loss_cls: 0.3112  decode.d3.loss_mask: 1.3408  decode.d3.loss_dice: 0.9573  decode.d4.loss_cls: 0.2924  decode.d4.loss_mask: 1.4247  decode.d4.loss_dice: 0.9835  decode.d5.loss_cls: 0.3473  decode.d5.loss_mask: 1.3330  decode.d5.loss_dice: 0.9628  decode.d6.loss_cls: 0.3396  decode.d6.loss_mask: 1.3530  decode.d6.loss_dice: 0.9630  decode.d7.loss_cls: 0.2759  decode.d7.loss_mask: 1.4017  decode.d7.loss_dice: 1.0307  decode.d8.loss_cls: 0.3658  decode.d8.loss_mask: 1.3342  decode.d8.loss_dice: 0.9893
05/26 15:58:21 - mmengine - INFO - Iter(train) [ 43050/160000]  base_lr: 7.5421e-05 lr: 7.5421e-06  eta: 13:19:10  time: 0.4088  data_time: 0.0105  memory: 5968  grad_norm: 437.7453  loss: 21.6831  decode.loss_cls: 0.2299  decode.loss_mask: 1.0458  decode.loss_dice: 0.8171  decode.d0.loss_cls: 0.7094  decode.d0.loss_mask: 0.9818  decode.d0.loss_dice: 0.7968  decode.d1.loss_cls: 0.2069  decode.d1.loss_mask: 1.0556  decode.d1.loss_dice: 0.8284  decode.d2.loss_cls: 0.2097  decode.d2.loss_mask: 1.0572  decode.d2.loss_dice: 0.8226  decode.d3.loss_cls: 0.2278  decode.d3.loss_mask: 1.0406  decode.d3.loss_dice: 0.8302  decode.d4.loss_cls: 0.2187  decode.d4.loss_mask: 1.0786  decode.d4.loss_dice: 0.8419  decode.d5.loss_cls: 0.2312  decode.d5.loss_mask: 1.0773  decode.d5.loss_dice: 0.8383  decode.d6.loss_cls: 0.2217  decode.d6.loss_mask: 1.0472  decode.d6.loss_dice: 0.8516  decode.d7.loss_cls: 0.2504  decode.d7.loss_mask: 1.1204  decode.d7.loss_dice: 0.8527  decode.d8.loss_cls: 0.2322  decode.d8.loss_mask: 1.0926  decode.d8.loss_dice: 0.8685
05/26 15:58:41 - mmengine - INFO - Iter(train) [ 43100/160000]  base_lr: 7.5392e-05 lr: 7.5392e-06  eta: 13:18:49  time: 0.4063  data_time: 0.0091  memory: 5968  grad_norm: 573.9013  loss: 24.6860  decode.loss_cls: 0.3455  decode.loss_mask: 1.1798  decode.loss_dice: 0.8150  decode.d0.loss_cls: 0.7745  decode.d0.loss_mask: 1.1688  decode.d0.loss_dice: 0.8449  decode.d1.loss_cls: 0.2981  decode.d1.loss_mask: 1.2243  decode.d1.loss_dice: 0.8994  decode.d2.loss_cls: 0.2995  decode.d2.loss_mask: 1.2191  decode.d2.loss_dice: 0.8795  decode.d3.loss_cls: 0.3317  decode.d3.loss_mask: 1.2039  decode.d3.loss_dice: 0.8955  decode.d4.loss_cls: 0.2846  decode.d4.loss_mask: 1.1886  decode.d4.loss_dice: 0.8841  decode.d5.loss_cls: 0.3419  decode.d5.loss_mask: 1.2053  decode.d5.loss_dice: 0.9103  decode.d6.loss_cls: 0.3432  decode.d6.loss_mask: 1.2283  decode.d6.loss_dice: 0.8830  decode.d7.loss_cls: 0.3016  decode.d7.loss_mask: 1.3209  decode.d7.loss_dice: 0.9369  decode.d8.loss_cls: 0.3115  decode.d8.loss_mask: 1.2522  decode.d8.loss_dice: 0.9143
05/26 15:59:01 - mmengine - INFO - Iter(train) [ 43150/160000]  base_lr: 7.5363e-05 lr: 7.5363e-06  eta: 13:18:28  time: 0.4070  data_time: 0.0091  memory: 5975  grad_norm: 970.4097  loss: 23.2772  decode.loss_cls: 0.3417  decode.loss_mask: 1.1167  decode.loss_dice: 0.8272  decode.d0.loss_cls: 0.8683  decode.d0.loss_mask: 1.0254  decode.d0.loss_dice: 0.7854  decode.d1.loss_cls: 0.3805  decode.d1.loss_mask: 1.0856  decode.d1.loss_dice: 0.8498  decode.d2.loss_cls: 0.4050  decode.d2.loss_mask: 1.0647  decode.d2.loss_dice: 0.7919  decode.d3.loss_cls: 0.3636  decode.d3.loss_mask: 1.0977  decode.d3.loss_dice: 0.8051  decode.d4.loss_cls: 0.4253  decode.d4.loss_mask: 1.0598  decode.d4.loss_dice: 0.7888  decode.d5.loss_cls: 0.3673  decode.d5.loss_mask: 1.0716  decode.d5.loss_dice: 0.8227  decode.d6.loss_cls: 0.3793  decode.d6.loss_mask: 1.0889  decode.d6.loss_dice: 0.8227  decode.d7.loss_cls: 0.3950  decode.d7.loss_mask: 1.0865  decode.d7.loss_dice: 0.8284  decode.d8.loss_cls: 0.3859  decode.d8.loss_mask: 1.1270  decode.d8.loss_dice: 0.8191
05/26 15:59:22 - mmengine - INFO - Iter(train) [ 43200/160000]  base_lr: 7.5334e-05 lr: 7.5334e-06  eta: 13:18:07  time: 0.4066  data_time: 0.0092  memory: 5990  grad_norm: 343.3502  loss: 20.6327  decode.loss_cls: 0.3011  decode.loss_mask: 1.0056  decode.loss_dice: 0.7348  decode.d0.loss_cls: 0.7056  decode.d0.loss_mask: 0.9390  decode.d0.loss_dice: 0.7117  decode.d1.loss_cls: 0.3100  decode.d1.loss_mask: 1.0032  decode.d1.loss_dice: 0.7205  decode.d2.loss_cls: 0.2962  decode.d2.loss_mask: 1.0094  decode.d2.loss_dice: 0.6984  decode.d3.loss_cls: 0.3012  decode.d3.loss_mask: 0.9794  decode.d3.loss_dice: 0.7394  decode.d4.loss_cls: 0.3227  decode.d4.loss_mask: 0.9917  decode.d4.loss_dice: 0.7394  decode.d5.loss_cls: 0.3505  decode.d5.loss_mask: 0.9974  decode.d5.loss_dice: 0.6968  decode.d6.loss_cls: 0.3318  decode.d6.loss_mask: 0.9649  decode.d6.loss_dice: 0.7145  decode.d7.loss_cls: 0.3072  decode.d7.loss_mask: 0.9817  decode.d7.loss_dice: 0.7430  decode.d8.loss_cls: 0.3016  decode.d8.loss_mask: 0.9975  decode.d8.loss_dice: 0.7364
05/26 15:59:42 - mmengine - INFO - Iter(train) [ 43250/160000]  base_lr: 7.5305e-05 lr: 7.5305e-06  eta: 13:17:46  time: 0.4061  data_time: 0.0092  memory: 5980  grad_norm: 834.2837  loss: 23.5946  decode.loss_cls: 0.2069  decode.loss_mask: 1.2302  decode.loss_dice: 0.8393  decode.d0.loss_cls: 0.7417  decode.d0.loss_mask: 1.1636  decode.d0.loss_dice: 0.8441  decode.d1.loss_cls: 0.2295  decode.d1.loss_mask: 1.2258  decode.d1.loss_dice: 0.8330  decode.d2.loss_cls: 0.2758  decode.d2.loss_mask: 1.2237  decode.d2.loss_dice: 0.8169  decode.d3.loss_cls: 0.2589  decode.d3.loss_mask: 1.2350  decode.d3.loss_dice: 0.8254  decode.d4.loss_cls: 0.2668  decode.d4.loss_mask: 1.2406  decode.d4.loss_dice: 0.8390  decode.d5.loss_cls: 0.2544  decode.d5.loss_mask: 1.2575  decode.d5.loss_dice: 0.8877  decode.d6.loss_cls: 0.2536  decode.d6.loss_mask: 1.2240  decode.d6.loss_dice: 0.8594  decode.d7.loss_cls: 0.1935  decode.d7.loss_mask: 1.2518  decode.d7.loss_dice: 0.8709  decode.d8.loss_cls: 0.1962  decode.d8.loss_mask: 1.2211  decode.d8.loss_dice: 0.8281
05/26 16:00:02 - mmengine - INFO - Iter(train) [ 43300/160000]  base_lr: 7.5276e-05 lr: 7.5276e-06  eta: 13:17:25  time: 0.4062  data_time: 0.0093  memory: 5980  grad_norm: 1013.8644  loss: 24.8923  decode.loss_cls: 0.2809  decode.loss_mask: 1.4205  decode.loss_dice: 0.7940  decode.d0.loss_cls: 0.6711  decode.d0.loss_mask: 1.3002  decode.d0.loss_dice: 0.7716  decode.d1.loss_cls: 0.2282  decode.d1.loss_mask: 1.4185  decode.d1.loss_dice: 0.7691  decode.d2.loss_cls: 0.2255  decode.d2.loss_mask: 1.4106  decode.d2.loss_dice: 0.7733  decode.d3.loss_cls: 0.2134  decode.d3.loss_mask: 1.4776  decode.d3.loss_dice: 0.8038  decode.d4.loss_cls: 0.2014  decode.d4.loss_mask: 1.4582  decode.d4.loss_dice: 0.7959  decode.d5.loss_cls: 0.2218  decode.d5.loss_mask: 1.4123  decode.d5.loss_dice: 0.7780  decode.d6.loss_cls: 0.2410  decode.d6.loss_mask: 1.4840  decode.d6.loss_dice: 0.8001  decode.d7.loss_cls: 0.2754  decode.d7.loss_mask: 1.4185  decode.d7.loss_dice: 0.7917  decode.d8.loss_cls: 0.2245  decode.d8.loss_mask: 1.4455  decode.d8.loss_dice: 0.7857
05/26 16:00:23 - mmengine - INFO - Iter(train) [ 43350/160000]  base_lr: 7.5247e-05 lr: 7.5247e-06  eta: 13:17:04  time: 0.4071  data_time: 0.0092  memory: 5971  grad_norm: 661.9825  loss: 23.1354  decode.loss_cls: 0.3391  decode.loss_mask: 1.0901  decode.loss_dice: 0.8368  decode.d0.loss_cls: 0.8408  decode.d0.loss_mask: 1.0094  decode.d0.loss_dice: 0.8076  decode.d1.loss_cls: 0.3556  decode.d1.loss_mask: 1.0977  decode.d1.loss_dice: 0.8393  decode.d2.loss_cls: 0.3494  decode.d2.loss_mask: 1.0898  decode.d2.loss_dice: 0.8307  decode.d3.loss_cls: 0.3376  decode.d3.loss_mask: 1.0853  decode.d3.loss_dice: 0.8511  decode.d4.loss_cls: 0.3528  decode.d4.loss_mask: 1.0851  decode.d4.loss_dice: 0.8406  decode.d5.loss_cls: 0.3140  decode.d5.loss_mask: 1.0911  decode.d5.loss_dice: 0.8525  decode.d6.loss_cls: 0.3323  decode.d6.loss_mask: 1.1628  decode.d6.loss_dice: 0.8456  decode.d7.loss_cls: 0.3674  decode.d7.loss_mask: 1.1159  decode.d7.loss_dice: 0.8089  decode.d8.loss_cls: 0.3385  decode.d8.loss_mask: 1.0674  decode.d8.loss_dice: 0.8003
05/26 16:00:43 - mmengine - INFO - Iter(train) [ 43400/160000]  base_lr: 7.5218e-05 lr: 7.5218e-06  eta: 13:16:43  time: 0.4072  data_time: 0.0091  memory: 5969  grad_norm: 766.6158  loss: 24.5345  decode.loss_cls: 0.3508  decode.loss_mask: 1.1256  decode.loss_dice: 0.9914  decode.d0.loss_cls: 0.8192  decode.d0.loss_mask: 1.0713  decode.d0.loss_dice: 0.9146  decode.d1.loss_cls: 0.3874  decode.d1.loss_mask: 1.1078  decode.d1.loss_dice: 0.9267  decode.d2.loss_cls: 0.3394  decode.d2.loss_mask: 1.1496  decode.d2.loss_dice: 0.9465  decode.d3.loss_cls: 0.3753  decode.d3.loss_mask: 1.1218  decode.d3.loss_dice: 0.9010  decode.d4.loss_cls: 0.3754  decode.d4.loss_mask: 1.1193  decode.d4.loss_dice: 0.9091  decode.d5.loss_cls: 0.3858  decode.d5.loss_mask: 1.1146  decode.d5.loss_dice: 0.8898  decode.d6.loss_cls: 0.3931  decode.d6.loss_mask: 1.1217  decode.d6.loss_dice: 0.8966  decode.d7.loss_cls: 0.3398  decode.d7.loss_mask: 1.1280  decode.d7.loss_dice: 0.9129  decode.d8.loss_cls: 0.3016  decode.d8.loss_mask: 1.1407  decode.d8.loss_dice: 0.9775
05/26 16:01:04 - mmengine - INFO - Iter(train) [ 43450/160000]  base_lr: 7.5189e-05 lr: 7.5189e-06  eta: 13:16:22  time: 0.4057  data_time: 0.0092  memory: 5976  grad_norm: 504.9758  loss: 23.8608  decode.loss_cls: 0.2062  decode.loss_mask: 1.2497  decode.loss_dice: 0.8578  decode.d0.loss_cls: 0.7031  decode.d0.loss_mask: 1.2141  decode.d0.loss_dice: 0.7959  decode.d1.loss_cls: 0.2483  decode.d1.loss_mask: 1.2317  decode.d1.loss_dice: 0.8613  decode.d2.loss_cls: 0.2456  decode.d2.loss_mask: 1.2642  decode.d2.loss_dice: 0.8728  decode.d3.loss_cls: 0.2182  decode.d3.loss_mask: 1.2854  decode.d3.loss_dice: 0.8777  decode.d4.loss_cls: 0.2434  decode.d4.loss_mask: 1.2631  decode.d4.loss_dice: 0.8905  decode.d5.loss_cls: 0.1949  decode.d5.loss_mask: 1.2989  decode.d5.loss_dice: 0.9082  decode.d6.loss_cls: 0.2313  decode.d6.loss_mask: 1.2052  decode.d6.loss_dice: 0.8272  decode.d7.loss_cls: 0.3081  decode.d7.loss_mask: 1.1689  decode.d7.loss_dice: 0.8000  decode.d8.loss_cls: 0.2321  decode.d8.loss_mask: 1.2919  decode.d8.loss_dice: 0.8653
05/26 16:01:24 - mmengine - INFO - Iter(train) [ 43500/160000]  base_lr: 7.5160e-05 lr: 7.5160e-06  eta: 13:16:01  time: 0.4068  data_time: 0.0092  memory: 5966  grad_norm: 910.8940  loss: 24.7311  decode.loss_cls: 0.2763  decode.loss_mask: 1.2457  decode.loss_dice: 0.9754  decode.d0.loss_cls: 0.7098  decode.d0.loss_mask: 1.2221  decode.d0.loss_dice: 0.8691  decode.d1.loss_cls: 0.3124  decode.d1.loss_mask: 1.1927  decode.d1.loss_dice: 0.8725  decode.d2.loss_cls: 0.3242  decode.d2.loss_mask: 1.1806  decode.d2.loss_dice: 0.9022  decode.d3.loss_cls: 0.3189  decode.d3.loss_mask: 1.1896  decode.d3.loss_dice: 0.9029  decode.d4.loss_cls: 0.2955  decode.d4.loss_mask: 1.2170  decode.d4.loss_dice: 0.9465  decode.d5.loss_cls: 0.3305  decode.d5.loss_mask: 1.1842  decode.d5.loss_dice: 0.9159  decode.d6.loss_cls: 0.3406  decode.d6.loss_mask: 1.2553  decode.d6.loss_dice: 0.9139  decode.d7.loss_cls: 0.2795  decode.d7.loss_mask: 1.2226  decode.d7.loss_dice: 0.9187  decode.d8.loss_cls: 0.2692  decode.d8.loss_mask: 1.2192  decode.d8.loss_dice: 0.9279
05/26 16:01:44 - mmengine - INFO - Iter(train) [ 43550/160000]  base_lr: 7.5131e-05 lr: 7.5131e-06  eta: 13:15:40  time: 0.4055  data_time: 0.0090  memory: 5969  grad_norm: 827.6157  loss: 28.4628  decode.loss_cls: 0.4371  decode.loss_mask: 1.3318  decode.loss_dice: 0.9964  decode.d0.loss_cls: 0.9286  decode.d0.loss_mask: 1.2892  decode.d0.loss_dice: 0.9843  decode.d1.loss_cls: 0.4489  decode.d1.loss_mask: 1.4171  decode.d1.loss_dice: 1.0639  decode.d2.loss_cls: 0.4789  decode.d2.loss_mask: 1.3379  decode.d2.loss_dice: 1.0214  decode.d3.loss_cls: 0.4382  decode.d3.loss_mask: 1.3441  decode.d3.loss_dice: 0.9827  decode.d4.loss_cls: 0.4245  decode.d4.loss_mask: 1.3573  decode.d4.loss_dice: 1.0384  decode.d5.loss_cls: 0.4473  decode.d5.loss_mask: 1.3488  decode.d5.loss_dice: 1.0419  decode.d6.loss_cls: 0.4550  decode.d6.loss_mask: 1.3155  decode.d6.loss_dice: 1.0126  decode.d7.loss_cls: 0.4514  decode.d7.loss_mask: 1.3669  decode.d7.loss_dice: 0.9908  decode.d8.loss_cls: 0.4298  decode.d8.loss_mask: 1.3104  decode.d8.loss_dice: 0.9717
05/26 16:02:05 - mmengine - INFO - Iter(train) [ 43600/160000]  base_lr: 7.5102e-05 lr: 7.5102e-06  eta: 13:15:19  time: 0.4069  data_time: 0.0091  memory: 5984  grad_norm: 712.6294  loss: 23.8845  decode.loss_cls: 0.2383  decode.loss_mask: 1.2619  decode.loss_dice: 0.8527  decode.d0.loss_cls: 0.7425  decode.d0.loss_mask: 1.2156  decode.d0.loss_dice: 0.8524  decode.d1.loss_cls: 0.1985  decode.d1.loss_mask: 1.2406  decode.d1.loss_dice: 0.8608  decode.d2.loss_cls: 0.1943  decode.d2.loss_mask: 1.2764  decode.d2.loss_dice: 0.8543  decode.d3.loss_cls: 0.2105  decode.d3.loss_mask: 1.2696  decode.d3.loss_dice: 0.8776  decode.d4.loss_cls: 0.2093  decode.d4.loss_mask: 1.2354  decode.d4.loss_dice: 0.8716  decode.d5.loss_cls: 0.2307  decode.d5.loss_mask: 1.2354  decode.d5.loss_dice: 0.8749  decode.d6.loss_cls: 0.2271  decode.d6.loss_mask: 1.3328  decode.d6.loss_dice: 0.8792  decode.d7.loss_cls: 0.2533  decode.d7.loss_mask: 1.2591  decode.d7.loss_dice: 0.8530  decode.d8.loss_cls: 0.2145  decode.d8.loss_mask: 1.2168  decode.d8.loss_dice: 0.8451
05/26 16:02:25 - mmengine - INFO - Iter(train) [ 43650/160000]  base_lr: 7.5073e-05 lr: 7.5073e-06  eta: 13:14:59  time: 0.4067  data_time: 0.0092  memory: 5966  grad_norm: 688.2541  loss: 27.0967  decode.loss_cls: 0.1763  decode.loss_mask: 1.4358  decode.loss_dice: 1.0059  decode.d0.loss_cls: 0.7287  decode.d0.loss_mask: 1.3345  decode.d0.loss_dice: 0.9578  decode.d1.loss_cls: 0.2279  decode.d1.loss_mask: 1.4121  decode.d1.loss_dice: 1.0176  decode.d2.loss_cls: 0.1773  decode.d2.loss_mask: 1.5042  decode.d2.loss_dice: 1.0074  decode.d3.loss_cls: 0.1764  decode.d3.loss_mask: 1.5341  decode.d3.loss_dice: 0.9886  decode.d4.loss_cls: 0.1973  decode.d4.loss_mask: 1.5235  decode.d4.loss_dice: 1.0259  decode.d5.loss_cls: 0.2267  decode.d5.loss_mask: 1.4280  decode.d5.loss_dice: 1.0097  decode.d6.loss_cls: 0.2305  decode.d6.loss_mask: 1.4509  decode.d6.loss_dice: 1.0223  decode.d7.loss_cls: 0.2234  decode.d7.loss_mask: 1.4613  decode.d7.loss_dice: 1.0032  decode.d8.loss_cls: 0.2428  decode.d8.loss_mask: 1.3763  decode.d8.loss_dice: 0.9900
05/26 16:02:45 - mmengine - INFO - Iter(train) [ 43700/160000]  base_lr: 7.5044e-05 lr: 7.5044e-06  eta: 13:14:38  time: 0.4062  data_time: 0.0091  memory: 5986  grad_norm: 674.8179  loss: 24.2615  decode.loss_cls: 0.2859  decode.loss_mask: 1.1560  decode.loss_dice: 0.9168  decode.d0.loss_cls: 0.7113  decode.d0.loss_mask: 1.1251  decode.d0.loss_dice: 0.9217  decode.d1.loss_cls: 0.3995  decode.d1.loss_mask: 1.0875  decode.d1.loss_dice: 0.9432  decode.d2.loss_cls: 0.3391  decode.d2.loss_mask: 1.1544  decode.d2.loss_dice: 0.9194  decode.d3.loss_cls: 0.3750  decode.d3.loss_mask: 1.1419  decode.d3.loss_dice: 0.9184  decode.d4.loss_cls: 0.4142  decode.d4.loss_mask: 1.1066  decode.d4.loss_dice: 0.8817  decode.d5.loss_cls: 0.3480  decode.d5.loss_mask: 1.0872  decode.d5.loss_dice: 0.9065  decode.d6.loss_cls: 0.3363  decode.d6.loss_mask: 1.1514  decode.d6.loss_dice: 0.8806  decode.d7.loss_cls: 0.3322  decode.d7.loss_mask: 1.1190  decode.d7.loss_dice: 0.8866  decode.d8.loss_cls: 0.2982  decode.d8.loss_mask: 1.1705  decode.d8.loss_dice: 0.9472
05/26 16:03:06 - mmengine - INFO - Iter(train) [ 43750/160000]  base_lr: 7.5015e-05 lr: 7.5015e-06  eta: 13:14:17  time: 0.4072  data_time: 0.0092  memory: 5976  grad_norm: 363.3962  loss: 20.9173  decode.loss_cls: 0.3095  decode.loss_mask: 1.0173  decode.loss_dice: 0.7316  decode.d0.loss_cls: 0.6619  decode.d0.loss_mask: 1.0576  decode.d0.loss_dice: 0.7387  decode.d1.loss_cls: 0.2437  decode.d1.loss_mask: 1.0821  decode.d1.loss_dice: 0.7292  decode.d2.loss_cls: 0.2485  decode.d2.loss_mask: 1.0375  decode.d2.loss_dice: 0.7137  decode.d3.loss_cls: 0.2530  decode.d3.loss_mask: 1.0383  decode.d3.loss_dice: 0.7257  decode.d4.loss_cls: 0.2935  decode.d4.loss_mask: 1.0388  decode.d4.loss_dice: 0.7115  decode.d5.loss_cls: 0.3006  decode.d5.loss_mask: 1.0552  decode.d5.loss_dice: 0.7334  decode.d6.loss_cls: 0.2582  decode.d6.loss_mask: 1.0639  decode.d6.loss_dice: 0.7170  decode.d7.loss_cls: 0.2821  decode.d7.loss_mask: 1.0607  decode.d7.loss_dice: 0.7530  decode.d8.loss_cls: 0.2967  decode.d8.loss_mask: 1.0418  decode.d8.loss_dice: 0.7226
05/26 16:03:26 - mmengine - INFO - Iter(train) [ 43800/160000]  base_lr: 7.4986e-05 lr: 7.4986e-06  eta: 13:13:56  time: 0.4059  data_time: 0.0092  memory: 5978  grad_norm: 818.9048  loss: 22.4389  decode.loss_cls: 0.2469  decode.loss_mask: 1.1267  decode.loss_dice: 0.7782  decode.d0.loss_cls: 0.8049  decode.d0.loss_mask: 1.0762  decode.d0.loss_dice: 0.7487  decode.d1.loss_cls: 0.2465  decode.d1.loss_mask: 1.1394  decode.d1.loss_dice: 0.7801  decode.d2.loss_cls: 0.2972  decode.d2.loss_mask: 1.1313  decode.d2.loss_dice: 0.7700  decode.d3.loss_cls: 0.2737  decode.d3.loss_mask: 1.1486  decode.d3.loss_dice: 0.7671  decode.d4.loss_cls: 0.2757  decode.d4.loss_mask: 1.1545  decode.d4.loss_dice: 0.7853  decode.d5.loss_cls: 0.3182  decode.d5.loss_mask: 1.1400  decode.d5.loss_dice: 0.7823  decode.d6.loss_cls: 0.3228  decode.d6.loss_mask: 1.1262  decode.d6.loss_dice: 0.7738  decode.d7.loss_cls: 0.2960  decode.d7.loss_mask: 1.1515  decode.d7.loss_dice: 0.7701  decode.d8.loss_cls: 0.2360  decode.d8.loss_mask: 1.1866  decode.d8.loss_dice: 0.7845
05/26 16:03:46 - mmengine - INFO - Iter(train) [ 43850/160000]  base_lr: 7.4957e-05 lr: 7.4957e-06  eta: 13:13:35  time: 0.4066  data_time: 0.0092  memory: 5966  grad_norm: 488.7880  loss: 23.1016  decode.loss_cls: 0.2560  decode.loss_mask: 1.1444  decode.loss_dice: 0.8442  decode.d0.loss_cls: 0.8489  decode.d0.loss_mask: 1.0503  decode.d0.loss_dice: 0.7556  decode.d1.loss_cls: 0.3500  decode.d1.loss_mask: 1.1054  decode.d1.loss_dice: 0.7438  decode.d2.loss_cls: 0.3855  decode.d2.loss_mask: 1.1134  decode.d2.loss_dice: 0.7845  decode.d3.loss_cls: 0.2828  decode.d3.loss_mask: 1.1705  decode.d3.loss_dice: 0.7936  decode.d4.loss_cls: 0.3217  decode.d4.loss_mask: 1.1656  decode.d4.loss_dice: 0.8588  decode.d5.loss_cls: 0.2775  decode.d5.loss_mask: 1.1834  decode.d5.loss_dice: 0.8414  decode.d6.loss_cls: 0.3343  decode.d6.loss_mask: 1.1073  decode.d6.loss_dice: 0.8209  decode.d7.loss_cls: 0.4183  decode.d7.loss_mask: 1.1017  decode.d7.loss_dice: 0.7803  decode.d8.loss_cls: 0.3120  decode.d8.loss_mask: 1.1230  decode.d8.loss_dice: 0.8264
05/26 16:04:07 - mmengine - INFO - Iter(train) [ 43900/160000]  base_lr: 7.4928e-05 lr: 7.4928e-06  eta: 13:13:14  time: 0.4068  data_time: 0.0091  memory: 5981  grad_norm: 584.2103  loss: 24.3716  decode.loss_cls: 0.2410  decode.loss_mask: 1.2201  decode.loss_dice: 0.8953  decode.d0.loss_cls: 0.8052  decode.d0.loss_mask: 1.1615  decode.d0.loss_dice: 0.8701  decode.d1.loss_cls: 0.2833  decode.d1.loss_mask: 1.1918  decode.d1.loss_dice: 0.8576  decode.d2.loss_cls: 0.3072  decode.d2.loss_mask: 1.2052  decode.d2.loss_dice: 0.9151  decode.d3.loss_cls: 0.3001  decode.d3.loss_mask: 1.2169  decode.d3.loss_dice: 0.9160  decode.d4.loss_cls: 0.2897  decode.d4.loss_mask: 1.2069  decode.d4.loss_dice: 0.9147  decode.d5.loss_cls: 0.2971  decode.d5.loss_mask: 1.1930  decode.d5.loss_dice: 0.9248  decode.d6.loss_cls: 0.2822  decode.d6.loss_mask: 1.2471  decode.d6.loss_dice: 0.9202  decode.d7.loss_cls: 0.2489  decode.d7.loss_mask: 1.2081  decode.d7.loss_dice: 0.9134  decode.d8.loss_cls: 0.2443  decode.d8.loss_mask: 1.1977  decode.d8.loss_dice: 0.8976
05/26 16:04:27 - mmengine - INFO - Iter(train) [ 43950/160000]  base_lr: 7.4899e-05 lr: 7.4899e-06  eta: 13:12:53  time: 0.4066  data_time: 0.0091  memory: 5968  grad_norm: 576.3246  loss: 23.9988  decode.loss_cls: 0.2182  decode.loss_mask: 1.2247  decode.loss_dice: 0.8868  decode.d0.loss_cls: 0.8298  decode.d0.loss_mask: 1.1077  decode.d0.loss_dice: 0.8811  decode.d1.loss_cls: 0.2882  decode.d1.loss_mask: 1.2160  decode.d1.loss_dice: 0.8634  decode.d2.loss_cls: 0.2313  decode.d2.loss_mask: 1.2613  decode.d2.loss_dice: 0.9309  decode.d3.loss_cls: 0.2410  decode.d3.loss_mask: 1.2179  decode.d3.loss_dice: 0.8896  decode.d4.loss_cls: 0.2733  decode.d4.loss_mask: 1.2176  decode.d4.loss_dice: 0.9109  decode.d5.loss_cls: 0.3279  decode.d5.loss_mask: 1.1414  decode.d5.loss_dice: 0.8411  decode.d6.loss_cls: 0.2611  decode.d6.loss_mask: 1.1838  decode.d6.loss_dice: 0.8664  decode.d7.loss_cls: 0.2700  decode.d7.loss_mask: 1.1914  decode.d7.loss_dice: 0.8887  decode.d8.loss_cls: 0.2677  decode.d8.loss_mask: 1.1649  decode.d8.loss_dice: 0.9047
05/26 16:04:48 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 16:04:48 - mmengine - INFO - Iter(train) [ 44000/160000]  base_lr: 7.4870e-05 lr: 7.4870e-06  eta: 13:12:33  time: 0.4077  data_time: 0.0093  memory: 5969  grad_norm: 596.4625  loss: 23.4678  decode.loss_cls: 0.3134  decode.loss_mask: 1.1215  decode.loss_dice: 0.8795  decode.d0.loss_cls: 0.7857  decode.d0.loss_mask: 1.0862  decode.d0.loss_dice: 0.8646  decode.d1.loss_cls: 0.2980  decode.d1.loss_mask: 1.1116  decode.d1.loss_dice: 0.8786  decode.d2.loss_cls: 0.3180  decode.d2.loss_mask: 1.1150  decode.d2.loss_dice: 0.8495  decode.d3.loss_cls: 0.2866  decode.d3.loss_mask: 1.1252  decode.d3.loss_dice: 0.8830  decode.d4.loss_cls: 0.3166  decode.d4.loss_mask: 1.1383  decode.d4.loss_dice: 0.8936  decode.d5.loss_cls: 0.3016  decode.d5.loss_mask: 1.1056  decode.d5.loss_dice: 0.8818  decode.d6.loss_cls: 0.2935  decode.d6.loss_mask: 1.1321  decode.d6.loss_dice: 0.8902  decode.d7.loss_cls: 0.3125  decode.d7.loss_mask: 1.1005  decode.d7.loss_dice: 0.8887  decode.d8.loss_cls: 0.2937  decode.d8.loss_mask: 1.1261  decode.d8.loss_dice: 0.8770
05/26 16:05:08 - mmengine - INFO - Iter(train) [ 44050/160000]  base_lr: 7.4841e-05 lr: 7.4841e-06  eta: 13:12:12  time: 0.4067  data_time: 0.0091  memory: 5983  grad_norm: 322.8407  loss: 19.1434  decode.loss_cls: 0.1717  decode.loss_mask: 0.9672  decode.loss_dice: 0.7202  decode.d0.loss_cls: 0.6304  decode.d0.loss_mask: 0.9321  decode.d0.loss_dice: 0.6809  decode.d1.loss_cls: 0.1893  decode.d1.loss_mask: 0.9491  decode.d1.loss_dice: 0.7061  decode.d2.loss_cls: 0.2175  decode.d2.loss_mask: 0.9241  decode.d2.loss_dice: 0.6921  decode.d3.loss_cls: 0.1641  decode.d3.loss_mask: 0.9713  decode.d3.loss_dice: 0.7191  decode.d4.loss_cls: 0.2473  decode.d4.loss_mask: 0.9478  decode.d4.loss_dice: 0.6975  decode.d5.loss_cls: 0.2377  decode.d5.loss_mask: 0.9527  decode.d5.loss_dice: 0.7144  decode.d6.loss_cls: 0.2170  decode.d6.loss_mask: 0.9776  decode.d6.loss_dice: 0.7277  decode.d7.loss_cls: 0.1848  decode.d7.loss_mask: 0.9611  decode.d7.loss_dice: 0.7593  decode.d8.loss_cls: 0.1990  decode.d8.loss_mask: 0.9563  decode.d8.loss_dice: 0.7279
05/26 16:05:28 - mmengine - INFO - Iter(train) [ 44100/160000]  base_lr: 7.4812e-05 lr: 7.4812e-06  eta: 13:11:51  time: 0.4085  data_time: 0.0097  memory: 5976  grad_norm: 1091.4307  loss: 27.6982  decode.loss_cls: 0.4539  decode.loss_mask: 1.3256  decode.loss_dice: 0.9281  decode.d0.loss_cls: 0.8994  decode.d0.loss_mask: 1.2628  decode.d0.loss_dice: 0.9391  decode.d1.loss_cls: 0.4511  decode.d1.loss_mask: 1.3703  decode.d1.loss_dice: 0.9557  decode.d2.loss_cls: 0.4681  decode.d2.loss_mask: 1.3109  decode.d2.loss_dice: 0.9427  decode.d3.loss_cls: 0.4682  decode.d3.loss_mask: 1.3020  decode.d3.loss_dice: 0.9426  decode.d4.loss_cls: 0.4654  decode.d4.loss_mask: 1.2940  decode.d4.loss_dice: 0.9327  decode.d5.loss_cls: 0.4592  decode.d5.loss_mask: 1.2832  decode.d5.loss_dice: 0.9405  decode.d6.loss_cls: 0.4632  decode.d6.loss_mask: 1.3579  decode.d6.loss_dice: 0.9986  decode.d7.loss_cls: 0.4303  decode.d7.loss_mask: 1.3429  decode.d7.loss_dice: 0.9534  decode.d8.loss_cls: 0.4537  decode.d8.loss_mask: 1.3746  decode.d8.loss_dice: 0.9281
05/26 16:05:49 - mmengine - INFO - Iter(train) [ 44150/160000]  base_lr: 7.4783e-05 lr: 7.4783e-06  eta: 13:11:30  time: 0.4077  data_time: 0.0091  memory: 5972  grad_norm: 702.7698  loss: 19.7264  decode.loss_cls: 0.1737  decode.loss_mask: 0.9624  decode.loss_dice: 0.7691  decode.d0.loss_cls: 0.6998  decode.d0.loss_mask: 0.9022  decode.d0.loss_dice: 0.7271  decode.d1.loss_cls: 0.2975  decode.d1.loss_mask: 0.8843  decode.d1.loss_dice: 0.7260  decode.d2.loss_cls: 0.1886  decode.d2.loss_mask: 0.9422  decode.d2.loss_dice: 0.7527  decode.d3.loss_cls: 0.2584  decode.d3.loss_mask: 0.9457  decode.d3.loss_dice: 0.7462  decode.d4.loss_cls: 0.2635  decode.d4.loss_mask: 0.9244  decode.d4.loss_dice: 0.7441  decode.d5.loss_cls: 0.2581  decode.d5.loss_mask: 0.9745  decode.d5.loss_dice: 0.7530  decode.d6.loss_cls: 0.2931  decode.d6.loss_mask: 0.9328  decode.d6.loss_dice: 0.7590  decode.d7.loss_cls: 0.2216  decode.d7.loss_mask: 0.9407  decode.d7.loss_dice: 0.7596  decode.d8.loss_cls: 0.1735  decode.d8.loss_mask: 0.9785  decode.d8.loss_dice: 0.7742
05/26 16:06:09 - mmengine - INFO - Iter(train) [ 44200/160000]  base_lr: 7.4754e-05 lr: 7.4754e-06  eta: 13:11:09  time: 0.4074  data_time: 0.0092  memory: 5979  grad_norm: 599.2847  loss: 23.4291  decode.loss_cls: 0.3809  decode.loss_mask: 1.0528  decode.loss_dice: 0.8785  decode.d0.loss_cls: 0.7817  decode.d0.loss_mask: 1.0285  decode.d0.loss_dice: 0.8524  decode.d1.loss_cls: 0.3753  decode.d1.loss_mask: 1.0633  decode.d1.loss_dice: 0.8603  decode.d2.loss_cls: 0.3817  decode.d2.loss_mask: 1.0601  decode.d2.loss_dice: 0.8528  decode.d3.loss_cls: 0.3404  decode.d3.loss_mask: 1.0672  decode.d3.loss_dice: 0.8717  decode.d4.loss_cls: 0.3539  decode.d4.loss_mask: 1.0797  decode.d4.loss_dice: 0.8684  decode.d5.loss_cls: 0.3634  decode.d5.loss_mask: 1.0445  decode.d5.loss_dice: 0.8579  decode.d6.loss_cls: 0.3390  decode.d6.loss_mask: 1.0844  decode.d6.loss_dice: 0.8881  decode.d7.loss_cls: 0.4125  decode.d7.loss_mask: 1.0700  decode.d7.loss_dice: 0.8885  decode.d8.loss_cls: 0.3633  decode.d8.loss_mask: 1.0771  decode.d8.loss_dice: 0.8907
05/26 16:06:29 - mmengine - INFO - Iter(train) [ 44250/160000]  base_lr: 7.4725e-05 lr: 7.4725e-06  eta: 13:10:48  time: 0.4076  data_time: 0.0091  memory: 5966  grad_norm: 1381.0899  loss: 23.5352  decode.loss_cls: 0.2633  decode.loss_mask: 1.1655  decode.loss_dice: 0.8982  decode.d0.loss_cls: 0.8685  decode.d0.loss_mask: 1.0966  decode.d0.loss_dice: 0.8193  decode.d1.loss_cls: 0.2704  decode.d1.loss_mask: 1.0970  decode.d1.loss_dice: 0.8817  decode.d2.loss_cls: 0.2563  decode.d2.loss_mask: 1.1343  decode.d2.loss_dice: 0.8790  decode.d3.loss_cls: 0.2501  decode.d3.loss_mask: 1.1677  decode.d3.loss_dice: 0.8922  decode.d4.loss_cls: 0.2692  decode.d4.loss_mask: 1.1717  decode.d4.loss_dice: 0.8701  decode.d5.loss_cls: 0.3092  decode.d5.loss_mask: 1.1477  decode.d5.loss_dice: 0.8524  decode.d6.loss_cls: 0.2613  decode.d6.loss_mask: 1.1845  decode.d6.loss_dice: 0.9068  decode.d7.loss_cls: 0.3291  decode.d7.loss_mask: 1.1028  decode.d7.loss_dice: 0.8612  decode.d8.loss_cls: 0.3032  decode.d8.loss_mask: 1.1347  decode.d8.loss_dice: 0.8912
05/26 16:06:50 - mmengine - INFO - Iter(train) [ 44300/160000]  base_lr: 7.4696e-05 lr: 7.4696e-06  eta: 13:10:28  time: 0.4067  data_time: 0.0092  memory: 5972  grad_norm: 705.7228  loss: 24.7384  decode.loss_cls: 0.2310  decode.loss_mask: 1.2261  decode.loss_dice: 0.9590  decode.d0.loss_cls: 0.7650  decode.d0.loss_mask: 1.1831  decode.d0.loss_dice: 0.9074  decode.d1.loss_cls: 0.2571  decode.d1.loss_mask: 1.2335  decode.d1.loss_dice: 0.9560  decode.d2.loss_cls: 0.2221  decode.d2.loss_mask: 1.2626  decode.d2.loss_dice: 0.9489  decode.d3.loss_cls: 0.2370  decode.d3.loss_mask: 1.2678  decode.d3.loss_dice: 0.9805  decode.d4.loss_cls: 0.2346  decode.d4.loss_mask: 1.2460  decode.d4.loss_dice: 0.9493  decode.d5.loss_cls: 0.2421  decode.d5.loss_mask: 1.2040  decode.d5.loss_dice: 0.9455  decode.d6.loss_cls: 0.2457  decode.d6.loss_mask: 1.2183  decode.d6.loss_dice: 0.9083  decode.d7.loss_cls: 0.2815  decode.d7.loss_mask: 1.2144  decode.d7.loss_dice: 0.9736  decode.d8.loss_cls: 0.2450  decode.d8.loss_mask: 1.2277  decode.d8.loss_dice: 0.9656
05/26 16:07:10 - mmengine - INFO - Iter(train) [ 44350/160000]  base_lr: 7.4666e-05 lr: 7.4666e-06  eta: 13:10:07  time: 0.4071  data_time: 0.0091  memory: 5974  grad_norm: 850.7636  loss: 28.6463  decode.loss_cls: 0.3367  decode.loss_mask: 1.3807  decode.loss_dice: 1.0684  decode.d0.loss_cls: 0.9090  decode.d0.loss_mask: 1.2764  decode.d0.loss_dice: 1.0050  decode.d1.loss_cls: 0.2850  decode.d1.loss_mask: 1.4793  decode.d1.loss_dice: 1.1019  decode.d2.loss_cls: 0.3377  decode.d2.loss_mask: 1.4355  decode.d2.loss_dice: 1.0560  decode.d3.loss_cls: 0.3012  decode.d3.loss_mask: 1.4612  decode.d3.loss_dice: 1.0636  decode.d4.loss_cls: 0.3699  decode.d4.loss_mask: 1.4150  decode.d4.loss_dice: 1.0384  decode.d5.loss_cls: 0.3455  decode.d5.loss_mask: 1.4495  decode.d5.loss_dice: 1.0638  decode.d6.loss_cls: 0.3630  decode.d6.loss_mask: 1.4492  decode.d6.loss_dice: 1.0520  decode.d7.loss_cls: 0.3676  decode.d7.loss_mask: 1.3796  decode.d7.loss_dice: 1.0429  decode.d8.loss_cls: 0.3155  decode.d8.loss_mask: 1.4492  decode.d8.loss_dice: 1.0477
05/26 16:07:30 - mmengine - INFO - Iter(train) [ 44400/160000]  base_lr: 7.4637e-05 lr: 7.4637e-06  eta: 13:09:46  time: 0.4080  data_time: 0.0091  memory: 5976  grad_norm: 492.8937  loss: 22.1665  decode.loss_cls: 0.1222  decode.loss_mask: 1.1853  decode.loss_dice: 0.8352  decode.d0.loss_cls: 0.7636  decode.d0.loss_mask: 1.0574  decode.d0.loss_dice: 0.7955  decode.d1.loss_cls: 0.1889  decode.d1.loss_mask: 1.1809  decode.d1.loss_dice: 0.8297  decode.d2.loss_cls: 0.1872  decode.d2.loss_mask: 1.1798  decode.d2.loss_dice: 0.8466  decode.d3.loss_cls: 0.1546  decode.d3.loss_mask: 1.1856  decode.d3.loss_dice: 0.8549  decode.d4.loss_cls: 0.1664  decode.d4.loss_mask: 1.1553  decode.d4.loss_dice: 0.8477  decode.d5.loss_cls: 0.1595  decode.d5.loss_mask: 1.1495  decode.d5.loss_dice: 0.8344  decode.d6.loss_cls: 0.2102  decode.d6.loss_mask: 1.1776  decode.d6.loss_dice: 0.8153  decode.d7.loss_cls: 0.1700  decode.d7.loss_mask: 1.1765  decode.d7.loss_dice: 0.8319  decode.d8.loss_cls: 0.1435  decode.d8.loss_mask: 1.1548  decode.d8.loss_dice: 0.8065
05/26 16:07:51 - mmengine - INFO - Iter(train) [ 44450/160000]  base_lr: 7.4608e-05 lr: 7.4608e-06  eta: 13:09:25  time: 0.4072  data_time: 0.0092  memory: 5983  grad_norm: 758.3530  loss: 25.3276  decode.loss_cls: 0.2166  decode.loss_mask: 1.1973  decode.loss_dice: 0.9657  decode.d0.loss_cls: 0.8902  decode.d0.loss_mask: 1.1639  decode.d0.loss_dice: 0.9888  decode.d1.loss_cls: 0.2886  decode.d1.loss_mask: 1.2193  decode.d1.loss_dice: 0.9857  decode.d2.loss_cls: 0.2478  decode.d2.loss_mask: 1.2485  decode.d2.loss_dice: 1.0213  decode.d3.loss_cls: 0.2644  decode.d3.loss_mask: 1.2372  decode.d3.loss_dice: 0.9908  decode.d4.loss_cls: 0.3216  decode.d4.loss_mask: 1.2011  decode.d4.loss_dice: 0.9788  decode.d5.loss_cls: 0.2836  decode.d5.loss_mask: 1.2150  decode.d5.loss_dice: 0.9745  decode.d6.loss_cls: 0.2779  decode.d6.loss_mask: 1.2365  decode.d6.loss_dice: 0.9834  decode.d7.loss_cls: 0.2533  decode.d7.loss_mask: 1.2432  decode.d7.loss_dice: 1.0107  decode.d8.loss_cls: 0.2572  decode.d8.loss_mask: 1.2007  decode.d8.loss_dice: 0.9641
05/26 16:08:11 - mmengine - INFO - Iter(train) [ 44500/160000]  base_lr: 7.4579e-05 lr: 7.4579e-06  eta: 13:09:04  time: 0.4058  data_time: 0.0092  memory: 5969  grad_norm: 740.3938  loss: 26.1959  decode.loss_cls: 0.2827  decode.loss_mask: 1.2829  decode.loss_dice: 1.0052  decode.d0.loss_cls: 0.7434  decode.d0.loss_mask: 1.2558  decode.d0.loss_dice: 0.9616  decode.d1.loss_cls: 0.2657  decode.d1.loss_mask: 1.3554  decode.d1.loss_dice: 1.0593  decode.d2.loss_cls: 0.2421  decode.d2.loss_mask: 1.3478  decode.d2.loss_dice: 1.0202  decode.d3.loss_cls: 0.2493  decode.d3.loss_mask: 1.3396  decode.d3.loss_dice: 1.0066  decode.d4.loss_cls: 0.3023  decode.d4.loss_mask: 1.3127  decode.d4.loss_dice: 0.9985  decode.d5.loss_cls: 0.3396  decode.d5.loss_mask: 1.2692  decode.d5.loss_dice: 0.9913  decode.d6.loss_cls: 0.2653  decode.d6.loss_mask: 1.2906  decode.d6.loss_dice: 0.9845  decode.d7.loss_cls: 0.2698  decode.d7.loss_mask: 1.2586  decode.d7.loss_dice: 0.9811  decode.d8.loss_cls: 0.2256  decode.d8.loss_mask: 1.2788  decode.d8.loss_dice: 1.0105
05/26 16:08:32 - mmengine - INFO - Iter(train) [ 44550/160000]  base_lr: 7.4550e-05 lr: 7.4550e-06  eta: 13:08:43  time: 0.4069  data_time: 0.0091  memory: 5968  grad_norm: 756.4908  loss: 24.1922  decode.loss_cls: 0.1958  decode.loss_mask: 1.2724  decode.loss_dice: 0.9248  decode.d0.loss_cls: 0.6837  decode.d0.loss_mask: 1.2321  decode.d0.loss_dice: 0.8570  decode.d1.loss_cls: 0.2269  decode.d1.loss_mask: 1.2284  decode.d1.loss_dice: 0.8851  decode.d2.loss_cls: 0.2478  decode.d2.loss_mask: 1.2257  decode.d2.loss_dice: 0.9046  decode.d3.loss_cls: 0.2123  decode.d3.loss_mask: 1.2777  decode.d3.loss_dice: 0.9028  decode.d4.loss_cls: 0.2301  decode.d4.loss_mask: 1.2550  decode.d4.loss_dice: 0.9220  decode.d5.loss_cls: 0.2408  decode.d5.loss_mask: 1.2816  decode.d5.loss_dice: 0.8954  decode.d6.loss_cls: 0.2695  decode.d6.loss_mask: 1.2040  decode.d6.loss_dice: 0.8944  decode.d7.loss_cls: 0.2449  decode.d7.loss_mask: 1.2244  decode.d7.loss_dice: 0.8939  decode.d8.loss_cls: 0.2277  decode.d8.loss_mask: 1.2332  decode.d8.loss_dice: 0.8981
05/26 16:08:52 - mmengine - INFO - Iter(train) [ 44600/160000]  base_lr: 7.4521e-05 lr: 7.4521e-06  eta: 13:08:22  time: 0.4065  data_time: 0.0090  memory: 5969  grad_norm: 572.5475  loss: 21.0401  decode.loss_cls: 0.1881  decode.loss_mask: 1.0335  decode.loss_dice: 0.7715  decode.d0.loss_cls: 0.7264  decode.d0.loss_mask: 1.0262  decode.d0.loss_dice: 0.7567  decode.d1.loss_cls: 0.2104  decode.d1.loss_mask: 1.0609  decode.d1.loss_dice: 0.7785  decode.d2.loss_cls: 0.2520  decode.d2.loss_mask: 1.0441  decode.d2.loss_dice: 0.7657  decode.d3.loss_cls: 0.2189  decode.d3.loss_mask: 1.0820  decode.d3.loss_dice: 0.7752  decode.d4.loss_cls: 0.2573  decode.d4.loss_mask: 1.0546  decode.d4.loss_dice: 0.7743  decode.d5.loss_cls: 0.2629  decode.d5.loss_mask: 1.0815  decode.d5.loss_dice: 0.7910  decode.d6.loss_cls: 0.2241  decode.d6.loss_mask: 1.0489  decode.d6.loss_dice: 0.7942  decode.d7.loss_cls: 0.2222  decode.d7.loss_mask: 1.0396  decode.d7.loss_dice: 0.7762  decode.d8.loss_cls: 0.1899  decode.d8.loss_mask: 1.0408  decode.d8.loss_dice: 0.7925
05/26 16:09:12 - mmengine - INFO - Iter(train) [ 44650/160000]  base_lr: 7.4492e-05 lr: 7.4492e-06  eta: 13:08:01  time: 0.4065  data_time: 0.0090  memory: 5976  grad_norm: 827.8174  loss: 24.5324  decode.loss_cls: 0.3478  decode.loss_mask: 1.1394  decode.loss_dice: 0.9437  decode.d0.loss_cls: 0.8702  decode.d0.loss_mask: 0.9877  decode.d0.loss_dice: 0.9052  decode.d1.loss_cls: 0.3549  decode.d1.loss_mask: 1.0865  decode.d1.loss_dice: 0.9297  decode.d2.loss_cls: 0.4134  decode.d2.loss_mask: 1.0460  decode.d2.loss_dice: 0.8941  decode.d3.loss_cls: 0.4258  decode.d3.loss_mask: 1.0787  decode.d3.loss_dice: 0.9123  decode.d4.loss_cls: 0.4419  decode.d4.loss_mask: 1.0818  decode.d4.loss_dice: 0.9410  decode.d5.loss_cls: 0.4494  decode.d5.loss_mask: 1.0328  decode.d5.loss_dice: 0.9466  decode.d6.loss_cls: 0.4302  decode.d6.loss_mask: 1.0313  decode.d6.loss_dice: 0.8969  decode.d7.loss_cls: 0.4145  decode.d7.loss_mask: 1.0675  decode.d7.loss_dice: 1.0089  decode.d8.loss_cls: 0.3560  decode.d8.loss_mask: 1.1518  decode.d8.loss_dice: 0.9462
05/26 16:09:33 - mmengine - INFO - Iter(train) [ 44700/160000]  base_lr: 7.4463e-05 lr: 7.4463e-06  eta: 13:07:41  time: 0.4070  data_time: 0.0091  memory: 5967  grad_norm: 674.4004  loss: 26.4834  decode.loss_cls: 0.3131  decode.loss_mask: 1.2866  decode.loss_dice: 0.9674  decode.d0.loss_cls: 0.8120  decode.d0.loss_mask: 1.2798  decode.d0.loss_dice: 0.9363  decode.d1.loss_cls: 0.3113  decode.d1.loss_mask: 1.3165  decode.d1.loss_dice: 0.9440  decode.d2.loss_cls: 0.3209  decode.d2.loss_mask: 1.2804  decode.d2.loss_dice: 0.9345  decode.d3.loss_cls: 0.4191  decode.d3.loss_mask: 1.2597  decode.d3.loss_dice: 0.9253  decode.d4.loss_cls: 0.3491  decode.d4.loss_mask: 1.3116  decode.d4.loss_dice: 0.9465  decode.d5.loss_cls: 0.3641  decode.d5.loss_mask: 1.3170  decode.d5.loss_dice: 0.9883  decode.d6.loss_cls: 0.3735  decode.d6.loss_mask: 1.3038  decode.d6.loss_dice: 0.9857  decode.d7.loss_cls: 0.3647  decode.d7.loss_mask: 1.3153  decode.d7.loss_dice: 1.0189  decode.d8.loss_cls: 0.3158  decode.d8.loss_mask: 1.2801  decode.d8.loss_dice: 0.9419
05/26 16:09:53 - mmengine - INFO - Iter(train) [ 44750/160000]  base_lr: 7.4434e-05 lr: 7.4434e-06  eta: 13:07:20  time: 0.4062  data_time: 0.0091  memory: 5976  grad_norm: 872.3560  loss: 24.9266  decode.loss_cls: 0.3269  decode.loss_mask: 1.1760  decode.loss_dice: 0.9394  decode.d0.loss_cls: 0.9485  decode.d0.loss_mask: 1.0706  decode.d0.loss_dice: 0.8104  decode.d1.loss_cls: 0.4195  decode.d1.loss_mask: 1.1501  decode.d1.loss_dice: 0.8282  decode.d2.loss_cls: 0.3917  decode.d2.loss_mask: 1.1747  decode.d2.loss_dice: 0.8383  decode.d3.loss_cls: 0.3803  decode.d3.loss_mask: 1.2291  decode.d3.loss_dice: 0.9018  decode.d4.loss_cls: 0.4231  decode.d4.loss_mask: 1.1777  decode.d4.loss_dice: 0.8605  decode.d5.loss_cls: 0.3994  decode.d5.loss_mask: 1.1854  decode.d5.loss_dice: 0.8936  decode.d6.loss_cls: 0.3788  decode.d6.loss_mask: 1.1738  decode.d6.loss_dice: 0.9093  decode.d7.loss_cls: 0.3901  decode.d7.loss_mask: 1.1579  decode.d7.loss_dice: 0.9184  decode.d8.loss_cls: 0.3917  decode.d8.loss_mask: 1.2067  decode.d8.loss_dice: 0.8747
05/26 16:10:13 - mmengine - INFO - Iter(train) [ 44800/160000]  base_lr: 7.4405e-05 lr: 7.4405e-06  eta: 13:06:59  time: 0.4070  data_time: 0.0091  memory: 5966  grad_norm: 939.8335  loss: 26.4473  decode.loss_cls: 0.2380  decode.loss_mask: 1.3626  decode.loss_dice: 1.0044  decode.d0.loss_cls: 0.8484  decode.d0.loss_mask: 1.2308  decode.d0.loss_dice: 0.9195  decode.d1.loss_cls: 0.3192  decode.d1.loss_mask: 1.3269  decode.d1.loss_dice: 0.9373  decode.d2.loss_cls: 0.2883  decode.d2.loss_mask: 1.3102  decode.d2.loss_dice: 0.9613  decode.d3.loss_cls: 0.3327  decode.d3.loss_mask: 1.3269  decode.d3.loss_dice: 0.9899  decode.d4.loss_cls: 0.3023  decode.d4.loss_mask: 1.2982  decode.d4.loss_dice: 0.9712  decode.d5.loss_cls: 0.2838  decode.d5.loss_mask: 1.3512  decode.d5.loss_dice: 0.9841  decode.d6.loss_cls: 0.3170  decode.d6.loss_mask: 1.3246  decode.d6.loss_dice: 1.0036  decode.d7.loss_cls: 0.2450  decode.d7.loss_mask: 1.3970  decode.d7.loss_dice: 0.9887  decode.d8.loss_cls: 0.2444  decode.d8.loss_mask: 1.3375  decode.d8.loss_dice: 1.0025
05/26 16:10:34 - mmengine - INFO - Iter(train) [ 44850/160000]  base_lr: 7.4376e-05 lr: 7.4376e-06  eta: 13:06:38  time: 0.4067  data_time: 0.0091  memory: 5977  grad_norm: 814.5557  loss: 26.4034  decode.loss_cls: 0.2913  decode.loss_mask: 1.4029  decode.loss_dice: 0.9324  decode.d0.loss_cls: 0.7328  decode.d0.loss_mask: 1.2389  decode.d0.loss_dice: 0.8771  decode.d1.loss_cls: 0.2751  decode.d1.loss_mask: 1.4096  decode.d1.loss_dice: 0.9565  decode.d2.loss_cls: 0.3310  decode.d2.loss_mask: 1.3471  decode.d2.loss_dice: 0.9483  decode.d3.loss_cls: 0.2936  decode.d3.loss_mask: 1.3287  decode.d3.loss_dice: 0.9437  decode.d4.loss_cls: 0.2961  decode.d4.loss_mask: 1.3803  decode.d4.loss_dice: 0.9445  decode.d5.loss_cls: 0.2785  decode.d5.loss_mask: 1.4185  decode.d5.loss_dice: 0.9446  decode.d6.loss_cls: 0.3146  decode.d6.loss_mask: 1.3401  decode.d6.loss_dice: 0.9374  decode.d7.loss_cls: 0.2933  decode.d7.loss_mask: 1.3746  decode.d7.loss_dice: 0.9580  decode.d8.loss_cls: 0.2988  decode.d8.loss_mask: 1.3749  decode.d8.loss_dice: 0.9405
05/26 16:10:54 - mmengine - INFO - Iter(train) [ 44900/160000]  base_lr: 7.4347e-05 lr: 7.4347e-06  eta: 13:06:17  time: 0.4072  data_time: 0.0091  memory: 5971  grad_norm: 513.0779  loss: 27.5359  decode.loss_cls: 0.3474  decode.loss_mask: 1.3436  decode.loss_dice: 1.0189  decode.d0.loss_cls: 0.8995  decode.d0.loss_mask: 1.2274  decode.d0.loss_dice: 1.0107  decode.d1.loss_cls: 0.4078  decode.d1.loss_mask: 1.2646  decode.d1.loss_dice: 1.0326  decode.d2.loss_cls: 0.3900  decode.d2.loss_mask: 1.3833  decode.d2.loss_dice: 1.0491  decode.d3.loss_cls: 0.3913  decode.d3.loss_mask: 1.2536  decode.d3.loss_dice: 1.0275  decode.d4.loss_cls: 0.3649  decode.d4.loss_mask: 1.3172  decode.d4.loss_dice: 1.0648  decode.d5.loss_cls: 0.3436  decode.d5.loss_mask: 1.3143  decode.d5.loss_dice: 1.0072  decode.d6.loss_cls: 0.3600  decode.d6.loss_mask: 1.2981  decode.d6.loss_dice: 1.0630  decode.d7.loss_cls: 0.3701  decode.d7.loss_mask: 1.2521  decode.d7.loss_dice: 1.0515  decode.d8.loss_cls: 0.3910  decode.d8.loss_mask: 1.3014  decode.d8.loss_dice: 0.9896
05/26 16:11:14 - mmengine - INFO - Iter(train) [ 44950/160000]  base_lr: 7.4318e-05 lr: 7.4318e-06  eta: 13:05:56  time: 0.4065  data_time: 0.0091  memory: 5973  grad_norm: 573.9152  loss: 24.5575  decode.loss_cls: 0.2662  decode.loss_mask: 1.2132  decode.loss_dice: 0.9361  decode.d0.loss_cls: 0.7511  decode.d0.loss_mask: 1.2242  decode.d0.loss_dice: 0.8947  decode.d1.loss_cls: 0.2911  decode.d1.loss_mask: 1.2013  decode.d1.loss_dice: 0.9139  decode.d2.loss_cls: 0.2583  decode.d2.loss_mask: 1.2149  decode.d2.loss_dice: 0.9156  decode.d3.loss_cls: 0.2862  decode.d3.loss_mask: 1.2039  decode.d3.loss_dice: 0.9094  decode.d4.loss_cls: 0.2973  decode.d4.loss_mask: 1.1934  decode.d4.loss_dice: 0.8905  decode.d5.loss_cls: 0.3106  decode.d5.loss_mask: 1.2204  decode.d5.loss_dice: 0.9057  decode.d6.loss_cls: 0.2952  decode.d6.loss_mask: 1.2178  decode.d6.loss_dice: 0.8939  decode.d7.loss_cls: 0.2626  decode.d7.loss_mask: 1.2168  decode.d7.loss_dice: 0.9458  decode.d8.loss_cls: 0.2697  decode.d8.loss_mask: 1.2513  decode.d8.loss_dice: 0.9066
05/26 16:11:35 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 16:11:35 - mmengine - INFO - Iter(train) [ 45000/160000]  base_lr: 7.4289e-05 lr: 7.4289e-06  eta: 13:05:36  time: 0.4065  data_time: 0.0091  memory: 5969  grad_norm: 846.5692  loss: 21.1418  decode.loss_cls: 0.1496  decode.loss_mask: 1.2268  decode.loss_dice: 0.7131  decode.d0.loss_cls: 0.5494  decode.d0.loss_mask: 1.1124  decode.d0.loss_dice: 0.7116  decode.d1.loss_cls: 0.2100  decode.d1.loss_mask: 1.1494  decode.d1.loss_dice: 0.7091  decode.d2.loss_cls: 0.1673  decode.d2.loss_mask: 1.1681  decode.d2.loss_dice: 0.7132  decode.d3.loss_cls: 0.1613  decode.d3.loss_mask: 1.1958  decode.d3.loss_dice: 0.7016  decode.d4.loss_cls: 0.1908  decode.d4.loss_mask: 1.2147  decode.d4.loss_dice: 0.7264  decode.d5.loss_cls: 0.1775  decode.d5.loss_mask: 1.2045  decode.d5.loss_dice: 0.7044  decode.d6.loss_cls: 0.1438  decode.d6.loss_mask: 1.2425  decode.d6.loss_dice: 0.7241  decode.d7.loss_cls: 0.1766  decode.d7.loss_mask: 1.2073  decode.d7.loss_dice: 0.7163  decode.d8.loss_cls: 0.1524  decode.d8.loss_mask: 1.2107  decode.d8.loss_dice: 0.7111
05/26 16:11:35 - mmengine - INFO - Saving checkpoint at 45000 iterations
05/26 16:11:39 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:07  time: 0.0479  data_time: 0.0012  memory: 1391  
05/26 16:11:41 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:04  time: 0.0474  data_time: 0.0012  memory: 1205  
05/26 16:11:44 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:02  time: 0.0500  data_time: 0.0012  memory: 1596  
05/26 16:11:46 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0484  data_time: 0.0012  memory: 1298  
05/26 16:11:49 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:57  time: 0.0475  data_time: 0.0012  memory: 1298  
05/26 16:11:51 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0474  data_time: 0.0012  memory: 1279  
05/26 16:11:53 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:52  time: 0.0479  data_time: 0.0012  memory: 1224  
05/26 16:11:56 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0491  data_time: 0.0012  memory: 1298  
05/26 16:11:58 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0474  data_time: 0.0012  memory: 1298  
05/26 16:12:01 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0514  data_time: 0.0012  memory: 1725  
05/26 16:12:03 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0482  data_time: 0.0013  memory: 1336  
05/26 16:12:06 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0478  data_time: 0.0012  memory: 1298  
05/26 16:12:08 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0481  data_time: 0.0012  memory: 1205  
05/26 16:12:10 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0490  data_time: 0.0012  memory: 1316  
05/26 16:12:13 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0474  data_time: 0.0012  memory: 1279  
05/26 16:12:15 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0510  data_time: 0.0012  memory: 1410  
05/26 16:12:18 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0476  data_time: 0.0012  memory: 1279  
05/26 16:12:20 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0484  data_time: 0.0012  memory: 1205  
05/26 16:12:22 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0482  data_time: 0.0012  memory: 1205  
05/26 16:12:25 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0479  data_time: 0.0012  memory: 1336  
05/26 16:12:27 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0487  data_time: 0.0012  memory: 1246  
05/26 16:12:30 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0495  data_time: 0.0012  memory: 1503  
05/26 16:12:32 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0475  data_time: 0.0012  memory: 1261  
05/26 16:12:34 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0483  data_time: 0.0012  memory: 1298  
05/26 16:12:37 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0483  data_time: 0.0012  memory: 1447  
05/26 16:12:39 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0475  data_time: 0.0012  memory: 1298  
05/26 16:12:42 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0490  data_time: 0.0012  memory: 1279  
05/26 16:12:44 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0480  data_time: 0.0012  memory: 1205  
05/26 16:12:46 - mmengine - INFO - per class results:
05/26 16:12:46 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background |  95.5 |  96.9 |
|  aeroplane  | 92.29 | 97.11 |
|   bicycle   | 36.22 | 65.77 |
|     bird    | 92.94 |  97.7 |
|     boat    | 72.86 | 89.99 |
|    bottle   | 80.18 | 88.61 |
|     bus     | 93.21 | 97.66 |
|     car     | 87.82 | 92.97 |
|     cat     | 93.08 | 96.09 |
|    chair    | 41.53 |  63.4 |
|     cow     | 52.25 |  54.3 |
| diningtable | 69.44 | 80.22 |
|     dog     | 88.05 | 97.08 |
|    horse    | 62.99 | 96.74 |
|  motorbike  |  70.9 | 92.29 |
|    person   | 88.68 | 96.91 |
| pottedplant | 65.48 |  84.2 |
|    sheep    | 82.24 | 90.51 |
|     sofa    | 55.65 | 72.63 |
|    train    |  88.3 | 93.56 |
|  tvmonitor  |  78.1 | 86.32 |
+-------------+-------+-------+
05/26 16:12:46 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.0000  mIoU: 75.6000  mAcc: 87.1900  data_time: 0.0013  time: 0.0480
05/26 16:12:46 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_40000.pth is removed
05/26 16:12:47 - mmengine - INFO - The best checkpoint with 75.6000 mIoU at 45000 iter is saved to best_mIoU_iter_45000.pth.
05/26 16:13:10 - mmengine - INFO - Iter(train) [ 45050/160000]  base_lr: 7.4260e-05 lr: 7.4260e-06  eta: 13:05:22  time: 0.4067  data_time: 0.0092  memory: 5970  grad_norm: 833.7733  loss: 27.2154  decode.loss_cls: 0.3440  decode.loss_mask: 1.3146  decode.loss_dice: 1.0311  decode.d0.loss_cls: 0.7458  decode.d0.loss_mask: 1.3029  decode.d0.loss_dice: 0.9680  decode.d1.loss_cls: 0.3154  decode.d1.loss_mask: 1.3398  decode.d1.loss_dice: 1.0085  decode.d2.loss_cls: 0.3065  decode.d2.loss_mask: 1.3512  decode.d2.loss_dice: 0.9980  decode.d3.loss_cls: 0.2789  decode.d3.loss_mask: 1.3883  decode.d3.loss_dice: 0.9907  decode.d4.loss_cls: 0.3404  decode.d4.loss_mask: 1.3569  decode.d4.loss_dice: 0.9999  decode.d5.loss_cls: 0.2901  decode.d5.loss_mask: 1.3921  decode.d5.loss_dice: 1.0442  decode.d6.loss_cls: 0.3747  decode.d6.loss_mask: 1.3797  decode.d6.loss_dice: 1.0014  decode.d7.loss_cls: 0.3100  decode.d7.loss_mask: 1.3762  decode.d7.loss_dice: 0.9952  decode.d8.loss_cls: 0.3346  decode.d8.loss_mask: 1.3439  decode.d8.loss_dice: 0.9926
05/26 16:13:30 - mmengine - INFO - Iter(train) [ 45100/160000]  base_lr: 7.4231e-05 lr: 7.4231e-06  eta: 13:05:01  time: 0.4062  data_time: 0.0092  memory: 5967  grad_norm: 718.9219  loss: 24.8094  decode.loss_cls: 0.3745  decode.loss_mask: 1.1335  decode.loss_dice: 0.8833  decode.d0.loss_cls: 0.8001  decode.d0.loss_mask: 1.1598  decode.d0.loss_dice: 0.8881  decode.d1.loss_cls: 0.4429  decode.d1.loss_mask: 1.1331  decode.d1.loss_dice: 0.8816  decode.d2.loss_cls: 0.4373  decode.d2.loss_mask: 1.1242  decode.d2.loss_dice: 0.8882  decode.d3.loss_cls: 0.4884  decode.d3.loss_mask: 1.1090  decode.d3.loss_dice: 0.8706  decode.d4.loss_cls: 0.4313  decode.d4.loss_mask: 1.1231  decode.d4.loss_dice: 0.9157  decode.d5.loss_cls: 0.3725  decode.d5.loss_mask: 1.1371  decode.d5.loss_dice: 0.9147  decode.d6.loss_cls: 0.4015  decode.d6.loss_mask: 1.1444  decode.d6.loss_dice: 0.8907  decode.d7.loss_cls: 0.4009  decode.d7.loss_mask: 1.1522  decode.d7.loss_dice: 0.8852  decode.d8.loss_cls: 0.3909  decode.d8.loss_mask: 1.1244  decode.d8.loss_dice: 0.9101
05/26 16:13:50 - mmengine - INFO - Iter(train) [ 45150/160000]  base_lr: 7.4201e-05 lr: 7.4201e-06  eta: 13:04:40  time: 0.4070  data_time: 0.0091  memory: 5966  grad_norm: 312.1017  loss: 19.9798  decode.loss_cls: 0.2647  decode.loss_mask: 0.9896  decode.loss_dice: 0.6494  decode.d0.loss_cls: 0.6353  decode.d0.loss_mask: 1.0098  decode.d0.loss_dice: 0.7004  decode.d1.loss_cls: 0.2884  decode.d1.loss_mask: 0.9801  decode.d1.loss_dice: 0.6890  decode.d2.loss_cls: 0.1892  decode.d2.loss_mask: 1.0425  decode.d2.loss_dice: 0.6765  decode.d3.loss_cls: 0.2651  decode.d3.loss_mask: 1.0070  decode.d3.loss_dice: 0.6854  decode.d4.loss_cls: 0.2847  decode.d4.loss_mask: 1.0091  decode.d4.loss_dice: 0.6937  decode.d5.loss_cls: 0.2674  decode.d5.loss_mask: 1.0034  decode.d5.loss_dice: 0.7441  decode.d6.loss_cls: 0.2328  decode.d6.loss_mask: 1.0628  decode.d6.loss_dice: 0.7086  decode.d7.loss_cls: 0.2571  decode.d7.loss_mask: 1.0124  decode.d7.loss_dice: 0.6512  decode.d8.loss_cls: 0.2516  decode.d8.loss_mask: 1.0519  decode.d8.loss_dice: 0.6766
05/26 16:14:11 - mmengine - INFO - Iter(train) [ 45200/160000]  base_lr: 7.4172e-05 lr: 7.4172e-06  eta: 13:04:19  time: 0.4072  data_time: 0.0091  memory: 5976  grad_norm: 931.2416  loss: 24.3370  decode.loss_cls: 0.3134  decode.loss_mask: 1.2153  decode.loss_dice: 0.8392  decode.d0.loss_cls: 0.7755  decode.d0.loss_mask: 1.1834  decode.d0.loss_dice: 0.8505  decode.d1.loss_cls: 0.3054  decode.d1.loss_mask: 1.2511  decode.d1.loss_dice: 0.8923  decode.d2.loss_cls: 0.2250  decode.d2.loss_mask: 1.3281  decode.d2.loss_dice: 0.8697  decode.d3.loss_cls: 0.2593  decode.d3.loss_mask: 1.2610  decode.d3.loss_dice: 0.8486  decode.d4.loss_cls: 0.2801  decode.d4.loss_mask: 1.2670  decode.d4.loss_dice: 0.8569  decode.d5.loss_cls: 0.2754  decode.d5.loss_mask: 1.2175  decode.d5.loss_dice: 0.8357  decode.d6.loss_cls: 0.2927  decode.d6.loss_mask: 1.2921  decode.d6.loss_dice: 0.8709  decode.d7.loss_cls: 0.3071  decode.d7.loss_mask: 1.2395  decode.d7.loss_dice: 0.8676  decode.d8.loss_cls: 0.2801  decode.d8.loss_mask: 1.2006  decode.d8.loss_dice: 0.8363
05/26 16:14:31 - mmengine - INFO - Iter(train) [ 45250/160000]  base_lr: 7.4143e-05 lr: 7.4143e-06  eta: 13:03:59  time: 0.4066  data_time: 0.0091  memory: 5965  grad_norm: 555.9209  loss: 20.8810  decode.loss_cls: 0.2865  decode.loss_mask: 0.9939  decode.loss_dice: 0.7070  decode.d0.loss_cls: 0.8226  decode.d0.loss_mask: 0.9422  decode.d0.loss_dice: 0.6909  decode.d1.loss_cls: 0.3969  decode.d1.loss_mask: 0.9622  decode.d1.loss_dice: 0.6957  decode.d2.loss_cls: 0.4064  decode.d2.loss_mask: 0.9690  decode.d2.loss_dice: 0.6998  decode.d3.loss_cls: 0.3586  decode.d3.loss_mask: 0.9724  decode.d3.loss_dice: 0.6930  decode.d4.loss_cls: 0.3755  decode.d4.loss_mask: 0.9566  decode.d4.loss_dice: 0.6897  decode.d5.loss_cls: 0.4094  decode.d5.loss_mask: 0.9806  decode.d5.loss_dice: 0.6777  decode.d6.loss_cls: 0.4258  decode.d6.loss_mask: 0.9726  decode.d6.loss_dice: 0.6903  decode.d7.loss_cls: 0.3767  decode.d7.loss_mask: 1.0111  decode.d7.loss_dice: 0.6910  decode.d8.loss_cls: 0.3339  decode.d8.loss_mask: 0.9905  decode.d8.loss_dice: 0.7025
05/26 16:14:51 - mmengine - INFO - Iter(train) [ 45300/160000]  base_lr: 7.4114e-05 lr: 7.4114e-06  eta: 13:03:38  time: 0.4065  data_time: 0.0092  memory: 5977  grad_norm: 1206.3755  loss: 25.8754  decode.loss_cls: 0.3506  decode.loss_mask: 1.3261  decode.loss_dice: 0.8557  decode.d0.loss_cls: 0.7703  decode.d0.loss_mask: 1.2505  decode.d0.loss_dice: 0.8219  decode.d1.loss_cls: 0.3763  decode.d1.loss_mask: 1.3923  decode.d1.loss_dice: 0.9175  decode.d2.loss_cls: 0.3417  decode.d2.loss_mask: 1.3665  decode.d2.loss_dice: 0.8775  decode.d3.loss_cls: 0.3415  decode.d3.loss_mask: 1.2907  decode.d3.loss_dice: 0.8022  decode.d4.loss_cls: 0.3454  decode.d4.loss_mask: 1.3333  decode.d4.loss_dice: 0.8582  decode.d5.loss_cls: 0.3993  decode.d5.loss_mask: 1.3598  decode.d5.loss_dice: 0.8933  decode.d6.loss_cls: 0.3700  decode.d6.loss_mask: 1.3152  decode.d6.loss_dice: 0.8651  decode.d7.loss_cls: 0.3636  decode.d7.loss_mask: 1.3173  decode.d7.loss_dice: 0.8682  decode.d8.loss_cls: 0.3539  decode.d8.loss_mask: 1.3239  decode.d8.loss_dice: 0.8275
05/26 16:15:12 - mmengine - INFO - Iter(train) [ 45350/160000]  base_lr: 7.4085e-05 lr: 7.4085e-06  eta: 13:03:17  time: 0.4059  data_time: 0.0091  memory: 5967  grad_norm: 690.6062  loss: 22.2808  decode.loss_cls: 0.2154  decode.loss_mask: 1.1828  decode.loss_dice: 0.7381  decode.d0.loss_cls: 0.6942  decode.d0.loss_mask: 1.0871  decode.d0.loss_dice: 0.7047  decode.d1.loss_cls: 0.2183  decode.d1.loss_mask: 1.1821  decode.d1.loss_dice: 0.7727  decode.d2.loss_cls: 0.2116  decode.d2.loss_mask: 1.2825  decode.d2.loss_dice: 0.7785  decode.d3.loss_cls: 0.2274  decode.d3.loss_mask: 1.1943  decode.d3.loss_dice: 0.7550  decode.d4.loss_cls: 0.1913  decode.d4.loss_mask: 1.2759  decode.d4.loss_dice: 0.7639  decode.d5.loss_cls: 0.2575  decode.d5.loss_mask: 1.2039  decode.d5.loss_dice: 0.7375  decode.d6.loss_cls: 0.2299  decode.d6.loss_mask: 1.2462  decode.d6.loss_dice: 0.7493  decode.d7.loss_cls: 0.2262  decode.d7.loss_mask: 1.2092  decode.d7.loss_dice: 0.7792  decode.d8.loss_cls: 0.1931  decode.d8.loss_mask: 1.2164  decode.d8.loss_dice: 0.7566
05/26 16:15:32 - mmengine - INFO - Iter(train) [ 45400/160000]  base_lr: 7.4056e-05 lr: 7.4056e-06  eta: 13:02:56  time: 0.4067  data_time: 0.0092  memory: 5967  grad_norm: 562.5451  loss: 23.1278  decode.loss_cls: 0.3538  decode.loss_mask: 1.0829  decode.loss_dice: 0.8040  decode.d0.loss_cls: 0.8291  decode.d0.loss_mask: 1.0452  decode.d0.loss_dice: 0.7512  decode.d1.loss_cls: 0.3957  decode.d1.loss_mask: 1.0689  decode.d1.loss_dice: 0.7848  decode.d2.loss_cls: 0.3753  decode.d2.loss_mask: 1.0628  decode.d2.loss_dice: 0.8317  decode.d3.loss_cls: 0.3820  decode.d3.loss_mask: 1.0886  decode.d3.loss_dice: 0.8180  decode.d4.loss_cls: 0.4012  decode.d4.loss_mask: 1.1097  decode.d4.loss_dice: 0.8001  decode.d5.loss_cls: 0.3642  decode.d5.loss_mask: 1.1027  decode.d5.loss_dice: 0.7959  decode.d6.loss_cls: 0.4068  decode.d6.loss_mask: 1.0726  decode.d6.loss_dice: 0.8066  decode.d7.loss_cls: 0.3635  decode.d7.loss_mask: 1.0992  decode.d7.loss_dice: 0.9099  decode.d8.loss_cls: 0.3427  decode.d8.loss_mask: 1.0686  decode.d8.loss_dice: 0.8102
05/26 16:15:52 - mmengine - INFO - Iter(train) [ 45450/160000]  base_lr: 7.4027e-05 lr: 7.4027e-06  eta: 13:02:35  time: 0.4067  data_time: 0.0091  memory: 5968  grad_norm: 820.8502  loss: 21.0568  decode.loss_cls: 0.2079  decode.loss_mask: 1.1075  decode.loss_dice: 0.7857  decode.d0.loss_cls: 0.7583  decode.d0.loss_mask: 0.9942  decode.d0.loss_dice: 0.6972  decode.d1.loss_cls: 0.2249  decode.d1.loss_mask: 1.0952  decode.d1.loss_dice: 0.7699  decode.d2.loss_cls: 0.2192  decode.d2.loss_mask: 1.0871  decode.d2.loss_dice: 0.7725  decode.d3.loss_cls: 0.2130  decode.d3.loss_mask: 1.0866  decode.d3.loss_dice: 0.7419  decode.d4.loss_cls: 0.2253  decode.d4.loss_mask: 1.0821  decode.d4.loss_dice: 0.7422  decode.d5.loss_cls: 0.1983  decode.d5.loss_mask: 1.0738  decode.d5.loss_dice: 0.7549  decode.d6.loss_cls: 0.2262  decode.d6.loss_mask: 1.0789  decode.d6.loss_dice: 0.7532  decode.d7.loss_cls: 0.2164  decode.d7.loss_mask: 1.0894  decode.d7.loss_dice: 0.8053  decode.d8.loss_cls: 0.2242  decode.d8.loss_mask: 1.0777  decode.d8.loss_dice: 0.7478
05/26 16:16:13 - mmengine - INFO - Iter(train) [ 45500/160000]  base_lr: 7.3998e-05 lr: 7.3998e-06  eta: 13:02:14  time: 0.4071  data_time: 0.0091  memory: 5970  grad_norm: 857.6745  loss: 23.4999  decode.loss_cls: 0.2151  decode.loss_mask: 1.2602  decode.loss_dice: 0.8593  decode.d0.loss_cls: 0.6963  decode.d0.loss_mask: 1.1486  decode.d0.loss_dice: 0.8304  decode.d1.loss_cls: 0.1730  decode.d1.loss_mask: 1.2409  decode.d1.loss_dice: 0.8839  decode.d2.loss_cls: 0.1914  decode.d2.loss_mask: 1.2068  decode.d2.loss_dice: 0.8215  decode.d3.loss_cls: 0.1959  decode.d3.loss_mask: 1.2745  decode.d3.loss_dice: 0.8502  decode.d4.loss_cls: 0.1978  decode.d4.loss_mask: 1.2356  decode.d4.loss_dice: 0.8591  decode.d5.loss_cls: 0.2374  decode.d5.loss_mask: 1.2881  decode.d5.loss_dice: 0.8446  decode.d6.loss_cls: 0.2329  decode.d6.loss_mask: 1.2342  decode.d6.loss_dice: 0.8525  decode.d7.loss_cls: 0.2580  decode.d7.loss_mask: 1.2508  decode.d7.loss_dice: 0.8599  decode.d8.loss_cls: 0.2337  decode.d8.loss_mask: 1.2351  decode.d8.loss_dice: 0.8323
05/26 16:16:33 - mmengine - INFO - Iter(train) [ 45550/160000]  base_lr: 7.3969e-05 lr: 7.3969e-06  eta: 13:01:54  time: 0.4081  data_time: 0.0092  memory: 5968  grad_norm: 802.7242  loss: 27.6654  decode.loss_cls: 0.4554  decode.loss_mask: 1.2996  decode.loss_dice: 0.9618  decode.d0.loss_cls: 0.9315  decode.d0.loss_mask: 1.2656  decode.d0.loss_dice: 0.9118  decode.d1.loss_cls: 0.5127  decode.d1.loss_mask: 1.3119  decode.d1.loss_dice: 0.9417  decode.d2.loss_cls: 0.4090  decode.d2.loss_mask: 1.3636  decode.d2.loss_dice: 0.9415  decode.d3.loss_cls: 0.3783  decode.d3.loss_mask: 1.3455  decode.d3.loss_dice: 0.9255  decode.d4.loss_cls: 0.4078  decode.d4.loss_mask: 1.3353  decode.d4.loss_dice: 0.9548  decode.d5.loss_cls: 0.4783  decode.d5.loss_mask: 1.3899  decode.d5.loss_dice: 0.9069  decode.d6.loss_cls: 0.4804  decode.d6.loss_mask: 1.3459  decode.d6.loss_dice: 0.9494  decode.d7.loss_cls: 0.4602  decode.d7.loss_mask: 1.3275  decode.d7.loss_dice: 0.9365  decode.d8.loss_cls: 0.4600  decode.d8.loss_mask: 1.3083  decode.d8.loss_dice: 0.9686
05/26 16:16:54 - mmengine - INFO - Iter(train) [ 45600/160000]  base_lr: 7.3940e-05 lr: 7.3940e-06  eta: 13:01:33  time: 0.4062  data_time: 0.0092  memory: 5968  grad_norm: 655.3825  loss: 23.3876  decode.loss_cls: 0.3491  decode.loss_mask: 1.1864  decode.loss_dice: 0.8264  decode.d0.loss_cls: 0.7592  decode.d0.loss_mask: 1.1348  decode.d0.loss_dice: 0.7437  decode.d1.loss_cls: 0.4033  decode.d1.loss_mask: 1.1379  decode.d1.loss_dice: 0.7734  decode.d2.loss_cls: 0.3632  decode.d2.loss_mask: 1.1534  decode.d2.loss_dice: 0.7899  decode.d3.loss_cls: 0.3356  decode.d3.loss_mask: 1.1368  decode.d3.loss_dice: 0.7742  decode.d4.loss_cls: 0.3243  decode.d4.loss_mask: 1.1577  decode.d4.loss_dice: 0.7618  decode.d5.loss_cls: 0.3462  decode.d5.loss_mask: 1.1618  decode.d5.loss_dice: 0.7890  decode.d6.loss_cls: 0.3745  decode.d6.loss_mask: 1.1510  decode.d6.loss_dice: 0.7882  decode.d7.loss_cls: 0.4052  decode.d7.loss_mask: 1.1181  decode.d7.loss_dice: 0.7989  decode.d8.loss_cls: 0.3948  decode.d8.loss_mask: 1.1652  decode.d8.loss_dice: 0.7836
05/26 16:17:14 - mmengine - INFO - Iter(train) [ 45650/160000]  base_lr: 7.3911e-05 lr: 7.3911e-06  eta: 13:01:12  time: 0.4066  data_time: 0.0092  memory: 5968  grad_norm: 455.1739  loss: 23.0606  decode.loss_cls: 0.2948  decode.loss_mask: 1.1010  decode.loss_dice: 0.8582  decode.d0.loss_cls: 0.8203  decode.d0.loss_mask: 0.9959  decode.d0.loss_dice: 0.7800  decode.d1.loss_cls: 0.3149  decode.d1.loss_mask: 1.1157  decode.d1.loss_dice: 0.8380  decode.d2.loss_cls: 0.2946  decode.d2.loss_mask: 1.1163  decode.d2.loss_dice: 0.8345  decode.d3.loss_cls: 0.2933  decode.d3.loss_mask: 1.1118  decode.d3.loss_dice: 0.8283  decode.d4.loss_cls: 0.3162  decode.d4.loss_mask: 1.1517  decode.d4.loss_dice: 0.8513  decode.d5.loss_cls: 0.3126  decode.d5.loss_mask: 1.1259  decode.d5.loss_dice: 0.8543  decode.d6.loss_cls: 0.3467  decode.d6.loss_mask: 1.1149  decode.d6.loss_dice: 0.8243  decode.d7.loss_cls: 0.3474  decode.d7.loss_mask: 1.0957  decode.d7.loss_dice: 0.8355  decode.d8.loss_cls: 0.3019  decode.d8.loss_mask: 1.1149  decode.d8.loss_dice: 0.8696
05/26 16:17:34 - mmengine - INFO - Iter(train) [ 45700/160000]  base_lr: 7.3882e-05 lr: 7.3882e-06  eta: 13:00:51  time: 0.4070  data_time: 0.0092  memory: 5976  grad_norm: 651.9152  loss: 21.8259  decode.loss_cls: 0.1812  decode.loss_mask: 1.0752  decode.loss_dice: 0.8363  decode.d0.loss_cls: 0.7014  decode.d0.loss_mask: 1.0566  decode.d0.loss_dice: 0.8804  decode.d1.loss_cls: 0.1513  decode.d1.loss_mask: 1.1588  decode.d1.loss_dice: 0.9108  decode.d2.loss_cls: 0.1720  decode.d2.loss_mask: 1.1127  decode.d2.loss_dice: 0.8480  decode.d3.loss_cls: 0.1866  decode.d3.loss_mask: 1.0830  decode.d3.loss_dice: 0.8424  decode.d4.loss_cls: 0.1736  decode.d4.loss_mask: 1.1039  decode.d4.loss_dice: 0.8516  decode.d5.loss_cls: 0.1600  decode.d5.loss_mask: 1.1207  decode.d5.loss_dice: 0.8495  decode.d6.loss_cls: 0.1609  decode.d6.loss_mask: 1.0862  decode.d6.loss_dice: 0.8605  decode.d7.loss_cls: 0.1628  decode.d7.loss_mask: 1.0938  decode.d7.loss_dice: 0.8607  decode.d8.loss_cls: 0.1570  decode.d8.loss_mask: 1.1141  decode.d8.loss_dice: 0.8739
05/26 16:17:55 - mmengine - INFO - Iter(train) [ 45750/160000]  base_lr: 7.3852e-05 lr: 7.3852e-06  eta: 13:00:30  time: 0.4063  data_time: 0.0092  memory: 5968  grad_norm: 1130.9921  loss: 28.2286  decode.loss_cls: 0.4693  decode.loss_mask: 1.3838  decode.loss_dice: 0.8889  decode.d0.loss_cls: 0.8796  decode.d0.loss_mask: 1.3538  decode.d0.loss_dice: 0.9104  decode.d1.loss_cls: 0.4646  decode.d1.loss_mask: 1.4015  decode.d1.loss_dice: 0.9260  decode.d2.loss_cls: 0.4340  decode.d2.loss_mask: 1.4043  decode.d2.loss_dice: 0.9285  decode.d3.loss_cls: 0.4380  decode.d3.loss_mask: 1.3668  decode.d3.loss_dice: 0.9125  decode.d4.loss_cls: 0.5060  decode.d4.loss_mask: 1.4351  decode.d4.loss_dice: 0.9155  decode.d5.loss_cls: 0.4713  decode.d5.loss_mask: 1.3735  decode.d5.loss_dice: 0.8986  decode.d6.loss_cls: 0.5285  decode.d6.loss_mask: 1.4234  decode.d6.loss_dice: 0.9665  decode.d7.loss_cls: 0.4669  decode.d7.loss_mask: 1.4252  decode.d7.loss_dice: 0.9252  decode.d8.loss_cls: 0.4956  decode.d8.loss_mask: 1.3580  decode.d8.loss_dice: 0.8774
05/26 16:18:15 - mmengine - INFO - Iter(train) [ 45800/160000]  base_lr: 7.3823e-05 lr: 7.3823e-06  eta: 13:00:10  time: 0.4072  data_time: 0.0092  memory: 5976  grad_norm: 711.2313  loss: 25.9332  decode.loss_cls: 0.3360  decode.loss_mask: 1.2628  decode.loss_dice: 0.9724  decode.d0.loss_cls: 0.8098  decode.d0.loss_mask: 1.1706  decode.d0.loss_dice: 0.8964  decode.d1.loss_cls: 0.3861  decode.d1.loss_mask: 1.2111  decode.d1.loss_dice: 0.9383  decode.d2.loss_cls: 0.3432  decode.d2.loss_mask: 1.2269  decode.d2.loss_dice: 0.9194  decode.d3.loss_cls: 0.3729  decode.d3.loss_mask: 1.2074  decode.d3.loss_dice: 0.9526  decode.d4.loss_cls: 0.3914  decode.d4.loss_mask: 1.2293  decode.d4.loss_dice: 0.9821  decode.d5.loss_cls: 0.3588  decode.d5.loss_mask: 1.2840  decode.d5.loss_dice: 0.9738  decode.d6.loss_cls: 0.3511  decode.d6.loss_mask: 1.2237  decode.d6.loss_dice: 0.9440  decode.d7.loss_cls: 0.3511  decode.d7.loss_mask: 1.2579  decode.d7.loss_dice: 0.9914  decode.d8.loss_cls: 0.3345  decode.d8.loss_mask: 1.2822  decode.d8.loss_dice: 0.9721
05/26 16:18:36 - mmengine - INFO - Iter(train) [ 45850/160000]  base_lr: 7.3794e-05 lr: 7.3794e-06  eta: 12:59:49  time: 0.4075  data_time: 0.0091  memory: 5970  grad_norm: 555.0346  loss: 23.8364  decode.loss_cls: 0.1715  decode.loss_mask: 1.2647  decode.loss_dice: 0.9060  decode.d0.loss_cls: 0.7216  decode.d0.loss_mask: 1.2373  decode.d0.loss_dice: 0.8663  decode.d1.loss_cls: 0.2155  decode.d1.loss_mask: 1.2249  decode.d1.loss_dice: 0.8907  decode.d2.loss_cls: 0.1939  decode.d2.loss_mask: 1.2137  decode.d2.loss_dice: 0.8849  decode.d3.loss_cls: 0.1689  decode.d3.loss_mask: 1.2599  decode.d3.loss_dice: 0.9188  decode.d4.loss_cls: 0.2104  decode.d4.loss_mask: 1.2353  decode.d4.loss_dice: 0.8829  decode.d5.loss_cls: 0.1915  decode.d5.loss_mask: 1.2446  decode.d5.loss_dice: 0.8851  decode.d6.loss_cls: 0.2193  decode.d6.loss_mask: 1.2473  decode.d6.loss_dice: 0.8983  decode.d7.loss_cls: 0.1954  decode.d7.loss_mask: 1.2313  decode.d7.loss_dice: 0.8985  decode.d8.loss_cls: 0.2209  decode.d8.loss_mask: 1.2389  decode.d8.loss_dice: 0.8982
05/26 16:18:56 - mmengine - INFO - Iter(train) [ 45900/160000]  base_lr: 7.3765e-05 lr: 7.3765e-06  eta: 12:59:28  time: 0.4063  data_time: 0.0092  memory: 5970  grad_norm: 1127.4930  loss: 24.3906  decode.loss_cls: 0.3990  decode.loss_mask: 1.2548  decode.loss_dice: 0.8073  decode.d0.loss_cls: 0.8650  decode.d0.loss_mask: 1.1036  decode.d0.loss_dice: 0.7495  decode.d1.loss_cls: 0.3913  decode.d1.loss_mask: 1.2243  decode.d1.loss_dice: 0.7591  decode.d2.loss_cls: 0.3218  decode.d2.loss_mask: 1.2280  decode.d2.loss_dice: 0.8090  decode.d3.loss_cls: 0.3800  decode.d3.loss_mask: 1.2384  decode.d3.loss_dice: 0.7811  decode.d4.loss_cls: 0.4014  decode.d4.loss_mask: 1.1999  decode.d4.loss_dice: 0.8228  decode.d5.loss_cls: 0.3512  decode.d5.loss_mask: 1.2372  decode.d5.loss_dice: 0.8116  decode.d6.loss_cls: 0.3785  decode.d6.loss_mask: 1.2289  decode.d6.loss_dice: 0.7605  decode.d7.loss_cls: 0.3226  decode.d7.loss_mask: 1.2874  decode.d7.loss_dice: 0.8026  decode.d8.loss_cls: 0.4118  decode.d8.loss_mask: 1.2771  decode.d8.loss_dice: 0.7850
05/26 16:19:16 - mmengine - INFO - Iter(train) [ 45950/160000]  base_lr: 7.3736e-05 lr: 7.3736e-06  eta: 12:59:07  time: 0.4070  data_time: 0.0092  memory: 5981  grad_norm: 703.3022  loss: 20.1558  decode.loss_cls: 0.2038  decode.loss_mask: 1.0980  decode.loss_dice: 0.6741  decode.d0.loss_cls: 0.7123  decode.d0.loss_mask: 1.0262  decode.d0.loss_dice: 0.6371  decode.d1.loss_cls: 0.2590  decode.d1.loss_mask: 1.0901  decode.d1.loss_dice: 0.6851  decode.d2.loss_cls: 0.1679  decode.d2.loss_mask: 1.0853  decode.d2.loss_dice: 0.6549  decode.d3.loss_cls: 0.1880  decode.d3.loss_mask: 1.1115  decode.d3.loss_dice: 0.6803  decode.d4.loss_cls: 0.1885  decode.d4.loss_mask: 1.1038  decode.d4.loss_dice: 0.6588  decode.d5.loss_cls: 0.2111  decode.d5.loss_mask: 1.1213  decode.d5.loss_dice: 0.6813  decode.d6.loss_cls: 0.2247  decode.d6.loss_mask: 1.1245  decode.d6.loss_dice: 0.6648  decode.d7.loss_cls: 0.2510  decode.d7.loss_mask: 1.0798  decode.d7.loss_dice: 0.6313  decode.d8.loss_cls: 0.1798  decode.d8.loss_mask: 1.0915  decode.d8.loss_dice: 0.6700
05/26 16:19:37 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 16:19:37 - mmengine - INFO - Iter(train) [ 46000/160000]  base_lr: 7.3707e-05 lr: 7.3707e-06  eta: 12:58:47  time: 0.4076  data_time: 0.0091  memory: 5982  grad_norm: 1119.1303  loss: 27.1638  decode.loss_cls: 0.3096  decode.loss_mask: 1.3649  decode.loss_dice: 0.9085  decode.d0.loss_cls: 0.8199  decode.d0.loss_mask: 1.3121  decode.d0.loss_dice: 0.9170  decode.d1.loss_cls: 0.3953  decode.d1.loss_mask: 1.3707  decode.d1.loss_dice: 0.9412  decode.d2.loss_cls: 0.3953  decode.d2.loss_mask: 1.3889  decode.d2.loss_dice: 0.9107  decode.d3.loss_cls: 0.3491  decode.d3.loss_mask: 1.3859  decode.d3.loss_dice: 0.9088  decode.d4.loss_cls: 0.3891  decode.d4.loss_mask: 1.4088  decode.d4.loss_dice: 0.9390  decode.d5.loss_cls: 0.3456  decode.d5.loss_mask: 1.3853  decode.d5.loss_dice: 0.9574  decode.d6.loss_cls: 0.3544  decode.d6.loss_mask: 1.3893  decode.d6.loss_dice: 0.9052  decode.d7.loss_cls: 0.3701  decode.d7.loss_mask: 1.4185  decode.d7.loss_dice: 0.9171  decode.d8.loss_cls: 0.3572  decode.d8.loss_mask: 1.4027  decode.d8.loss_dice: 0.9461
05/26 16:19:57 - mmengine - INFO - Iter(train) [ 46050/160000]  base_lr: 7.3678e-05 lr: 7.3678e-06  eta: 12:58:26  time: 0.4082  data_time: 0.0092  memory: 5979  grad_norm: 610.3322  loss: 28.1023  decode.loss_cls: 0.5704  decode.loss_mask: 1.2740  decode.loss_dice: 1.0062  decode.d0.loss_cls: 1.0390  decode.d0.loss_mask: 1.1633  decode.d0.loss_dice: 0.9795  decode.d1.loss_cls: 0.5849  decode.d1.loss_mask: 1.2072  decode.d1.loss_dice: 0.9706  decode.d2.loss_cls: 0.5958  decode.d2.loss_mask: 1.2393  decode.d2.loss_dice: 1.0127  decode.d3.loss_cls: 0.5348  decode.d3.loss_mask: 1.2239  decode.d3.loss_dice: 1.0013  decode.d4.loss_cls: 0.5458  decode.d4.loss_mask: 1.2653  decode.d4.loss_dice: 1.0024  decode.d5.loss_cls: 0.5071  decode.d5.loss_mask: 1.2407  decode.d5.loss_dice: 1.0189  decode.d6.loss_cls: 0.5539  decode.d6.loss_mask: 1.1613  decode.d6.loss_dice: 0.9703  decode.d7.loss_cls: 0.5327  decode.d7.loss_mask: 1.2277  decode.d7.loss_dice: 0.9671  decode.d8.loss_cls: 0.5471  decode.d8.loss_mask: 1.1721  decode.d8.loss_dice: 0.9870
05/26 16:20:17 - mmengine - INFO - Iter(train) [ 46100/160000]  base_lr: 7.3649e-05 lr: 7.3649e-06  eta: 12:58:05  time: 0.4073  data_time: 0.0092  memory: 5975  grad_norm: 890.8471  loss: 24.4481  decode.loss_cls: 0.3247  decode.loss_mask: 1.1750  decode.loss_dice: 0.8819  decode.d0.loss_cls: 0.8044  decode.d0.loss_mask: 1.1902  decode.d0.loss_dice: 0.8711  decode.d1.loss_cls: 0.4078  decode.d1.loss_mask: 1.1697  decode.d1.loss_dice: 0.8609  decode.d2.loss_cls: 0.3642  decode.d2.loss_mask: 1.1355  decode.d2.loss_dice: 0.8460  decode.d3.loss_cls: 0.3859  decode.d3.loss_mask: 1.1787  decode.d3.loss_dice: 0.8515  decode.d4.loss_cls: 0.3647  decode.d4.loss_mask: 1.1467  decode.d4.loss_dice: 0.8388  decode.d5.loss_cls: 0.4293  decode.d5.loss_mask: 1.1533  decode.d5.loss_dice: 0.8258  decode.d6.loss_cls: 0.4186  decode.d6.loss_mask: 1.1654  decode.d6.loss_dice: 0.8350  decode.d7.loss_cls: 0.3853  decode.d7.loss_mask: 1.1835  decode.d7.loss_dice: 0.8694  decode.d8.loss_cls: 0.3227  decode.d8.loss_mask: 1.1978  decode.d8.loss_dice: 0.8643
05/26 16:20:38 - mmengine - INFO - Iter(train) [ 46150/160000]  base_lr: 7.3620e-05 lr: 7.3620e-06  eta: 12:57:44  time: 0.4085  data_time: 0.0092  memory: 5972  grad_norm: 557.9625  loss: 20.3412  decode.loss_cls: 0.2109  decode.loss_mask: 0.9855  decode.loss_dice: 0.7865  decode.d0.loss_cls: 0.6818  decode.d0.loss_mask: 0.9282  decode.d0.loss_dice: 0.8092  decode.d1.loss_cls: 0.1964  decode.d1.loss_mask: 0.9700  decode.d1.loss_dice: 0.8172  decode.d2.loss_cls: 0.2349  decode.d2.loss_mask: 0.9801  decode.d2.loss_dice: 0.7824  decode.d3.loss_cls: 0.2517  decode.d3.loss_mask: 0.9477  decode.d3.loss_dice: 0.7634  decode.d4.loss_cls: 0.2496  decode.d4.loss_mask: 0.9503  decode.d4.loss_dice: 0.7695  decode.d5.loss_cls: 0.2495  decode.d5.loss_mask: 0.9610  decode.d5.loss_dice: 0.7844  decode.d6.loss_cls: 0.2698  decode.d6.loss_mask: 0.9787  decode.d6.loss_dice: 0.8085  decode.d7.loss_cls: 0.3018  decode.d7.loss_mask: 0.9534  decode.d7.loss_dice: 0.7378  decode.d8.loss_cls: 0.2361  decode.d8.loss_mask: 0.9625  decode.d8.loss_dice: 0.7821
05/26 16:20:58 - mmengine - INFO - Iter(train) [ 46200/160000]  base_lr: 7.3591e-05 lr: 7.3591e-06  eta: 12:57:23  time: 0.4072  data_time: 0.0092  memory: 5974  grad_norm: 1364.6729  loss: 24.1598  decode.loss_cls: 0.2018  decode.loss_mask: 1.2526  decode.loss_dice: 0.8732  decode.d0.loss_cls: 0.7860  decode.d0.loss_mask: 1.2167  decode.d0.loss_dice: 0.8303  decode.d1.loss_cls: 0.3238  decode.d1.loss_mask: 1.2772  decode.d1.loss_dice: 0.8801  decode.d2.loss_cls: 0.2093  decode.d2.loss_mask: 1.2426  decode.d2.loss_dice: 0.8857  decode.d3.loss_cls: 0.2045  decode.d3.loss_mask: 1.2465  decode.d3.loss_dice: 0.8905  decode.d4.loss_cls: 0.2232  decode.d4.loss_mask: 1.2849  decode.d4.loss_dice: 0.9052  decode.d5.loss_cls: 0.2217  decode.d5.loss_mask: 1.2631  decode.d5.loss_dice: 0.8942  decode.d6.loss_cls: 0.2091  decode.d6.loss_mask: 1.2224  decode.d6.loss_dice: 0.8625  decode.d7.loss_cls: 0.2587  decode.d7.loss_mask: 1.2634  decode.d7.loss_dice: 0.8635  decode.d8.loss_cls: 0.2140  decode.d8.loss_mask: 1.2629  decode.d8.loss_dice: 0.8903
05/26 16:21:19 - mmengine - INFO - Iter(train) [ 46250/160000]  base_lr: 7.3562e-05 lr: 7.3562e-06  eta: 12:57:03  time: 0.4077  data_time: 0.0092  memory: 5969  grad_norm: 626.1840  loss: 26.7671  decode.loss_cls: 0.4089  decode.loss_mask: 1.2812  decode.loss_dice: 0.8807  decode.d0.loss_cls: 0.8950  decode.d0.loss_mask: 1.2414  decode.d0.loss_dice: 0.8728  decode.d1.loss_cls: 0.4346  decode.d1.loss_mask: 1.3656  decode.d1.loss_dice: 0.9497  decode.d2.loss_cls: 0.4625  decode.d2.loss_mask: 1.2877  decode.d2.loss_dice: 0.9249  decode.d3.loss_cls: 0.4177  decode.d3.loss_mask: 1.3052  decode.d3.loss_dice: 0.8800  decode.d4.loss_cls: 0.3961  decode.d4.loss_mask: 1.3496  decode.d4.loss_dice: 0.8825  decode.d5.loss_cls: 0.4359  decode.d5.loss_mask: 1.3982  decode.d5.loss_dice: 0.9220  decode.d6.loss_cls: 0.4891  decode.d6.loss_mask: 1.2968  decode.d6.loss_dice: 0.8363  decode.d7.loss_cls: 0.4129  decode.d7.loss_mask: 1.2868  decode.d7.loss_dice: 0.8769  decode.d8.loss_cls: 0.4307  decode.d8.loss_mask: 1.2911  decode.d8.loss_dice: 0.8543
05/26 16:21:39 - mmengine - INFO - Iter(train) [ 46300/160000]  base_lr: 7.3532e-05 lr: 7.3532e-06  eta: 12:56:42  time: 0.4070  data_time: 0.0093  memory: 5991  grad_norm: 968.1949  loss: 26.0746  decode.loss_cls: 0.2815  decode.loss_mask: 1.2392  decode.loss_dice: 1.0399  decode.d0.loss_cls: 0.7959  decode.d0.loss_mask: 1.1530  decode.d0.loss_dice: 1.0176  decode.d1.loss_cls: 0.3788  decode.d1.loss_mask: 1.1606  decode.d1.loss_dice: 1.0165  decode.d2.loss_cls: 0.2854  decode.d2.loss_mask: 1.2070  decode.d2.loss_dice: 1.0451  decode.d3.loss_cls: 0.2743  decode.d3.loss_mask: 1.1904  decode.d3.loss_dice: 1.0357  decode.d4.loss_cls: 0.3267  decode.d4.loss_mask: 1.2204  decode.d4.loss_dice: 1.1085  decode.d5.loss_cls: 0.2693  decode.d5.loss_mask: 1.2468  decode.d5.loss_dice: 1.0749  decode.d6.loss_cls: 0.3134  decode.d6.loss_mask: 1.2291  decode.d6.loss_dice: 1.0554  decode.d7.loss_cls: 0.3195  decode.d7.loss_mask: 1.1770  decode.d7.loss_dice: 1.0656  decode.d8.loss_cls: 0.3021  decode.d8.loss_mask: 1.2054  decode.d8.loss_dice: 1.0397
05/26 16:21:59 - mmengine - INFO - Iter(train) [ 46350/160000]  base_lr: 7.3503e-05 lr: 7.3503e-06  eta: 12:56:21  time: 0.4067  data_time: 0.0092  memory: 5976  grad_norm: 365.6819  loss: 17.0993  decode.loss_cls: 0.2540  decode.loss_mask: 0.8115  decode.loss_dice: 0.6583  decode.d0.loss_cls: 0.7566  decode.d0.loss_mask: 0.7854  decode.d0.loss_dice: 0.6190  decode.d1.loss_cls: 0.2141  decode.d1.loss_mask: 0.7718  decode.d1.loss_dice: 0.6303  decode.d2.loss_cls: 0.1793  decode.d2.loss_mask: 0.8008  decode.d2.loss_dice: 0.6334  decode.d3.loss_cls: 0.2097  decode.d3.loss_mask: 0.7874  decode.d3.loss_dice: 0.6102  decode.d4.loss_cls: 0.2161  decode.d4.loss_mask: 0.7758  decode.d4.loss_dice: 0.6552  decode.d5.loss_cls: 0.2128  decode.d5.loss_mask: 0.8031  decode.d5.loss_dice: 0.5945  decode.d6.loss_cls: 0.2235  decode.d6.loss_mask: 0.8329  decode.d6.loss_dice: 0.6920  decode.d7.loss_cls: 0.2713  decode.d7.loss_mask: 0.8198  decode.d7.loss_dice: 0.6028  decode.d8.loss_cls: 0.2694  decode.d8.loss_mask: 0.8039  decode.d8.loss_dice: 0.6043
05/26 16:22:20 - mmengine - INFO - Iter(train) [ 46400/160000]  base_lr: 7.3474e-05 lr: 7.3474e-06  eta: 12:56:00  time: 0.4072  data_time: 0.0092  memory: 5967  grad_norm: 626.7369  loss: 27.0054  decode.loss_cls: 0.2837  decode.loss_mask: 1.3194  decode.loss_dice: 1.0854  decode.d0.loss_cls: 0.8419  decode.d0.loss_mask: 1.1450  decode.d0.loss_dice: 0.9839  decode.d1.loss_cls: 0.3291  decode.d1.loss_mask: 1.2260  decode.d1.loss_dice: 1.0400  decode.d2.loss_cls: 0.3716  decode.d2.loss_mask: 1.2652  decode.d2.loss_dice: 1.0421  decode.d3.loss_cls: 0.3787  decode.d3.loss_mask: 1.1977  decode.d3.loss_dice: 0.9844  decode.d4.loss_cls: 0.4921  decode.d4.loss_mask: 1.2034  decode.d4.loss_dice: 1.0170  decode.d5.loss_cls: 0.4261  decode.d5.loss_mask: 1.2284  decode.d5.loss_dice: 1.0055  decode.d6.loss_cls: 0.4149  decode.d6.loss_mask: 1.2997  decode.d6.loss_dice: 1.0530  decode.d7.loss_cls: 0.3694  decode.d7.loss_mask: 1.2151  decode.d7.loss_dice: 1.0346  decode.d8.loss_cls: 0.3851  decode.d8.loss_mask: 1.3315  decode.d8.loss_dice: 1.0356
05/26 16:22:40 - mmengine - INFO - Iter(train) [ 46450/160000]  base_lr: 7.3445e-05 lr: 7.3445e-06  eta: 12:55:39  time: 0.4081  data_time: 0.0092  memory: 5966  grad_norm: 863.4832  loss: 19.9529  decode.loss_cls: 0.2164  decode.loss_mask: 1.0189  decode.loss_dice: 0.7061  decode.d0.loss_cls: 0.8177  decode.d0.loss_mask: 0.9855  decode.d0.loss_dice: 0.6465  decode.d1.loss_cls: 0.2260  decode.d1.loss_mask: 1.0154  decode.d1.loss_dice: 0.6600  decode.d2.loss_cls: 0.2302  decode.d2.loss_mask: 1.0041  decode.d2.loss_dice: 0.6593  decode.d3.loss_cls: 0.2407  decode.d3.loss_mask: 1.0245  decode.d3.loss_dice: 0.6632  decode.d4.loss_cls: 0.2715  decode.d4.loss_mask: 1.0119  decode.d4.loss_dice: 0.6788  decode.d5.loss_cls: 0.2195  decode.d5.loss_mask: 1.0935  decode.d5.loss_dice: 0.7224  decode.d6.loss_cls: 0.2560  decode.d6.loss_mask: 1.0089  decode.d6.loss_dice: 0.6788  decode.d7.loss_cls: 0.2277  decode.d7.loss_mask: 1.0195  decode.d7.loss_dice: 0.6923  decode.d8.loss_cls: 0.2381  decode.d8.loss_mask: 1.0288  decode.d8.loss_dice: 0.6906
05/26 16:23:00 - mmengine - INFO - Iter(train) [ 46500/160000]  base_lr: 7.3416e-05 lr: 7.3416e-06  eta: 12:55:19  time: 0.4089  data_time: 0.0092  memory: 5966  grad_norm: 576.2555  loss: 21.0741  decode.loss_cls: 0.2129  decode.loss_mask: 1.0056  decode.loss_dice: 0.8198  decode.d0.loss_cls: 0.7381  decode.d0.loss_mask: 0.9512  decode.d0.loss_dice: 0.7066  decode.d1.loss_cls: 0.3765  decode.d1.loss_mask: 0.9948  decode.d1.loss_dice: 0.7628  decode.d2.loss_cls: 0.2952  decode.d2.loss_mask: 1.0113  decode.d2.loss_dice: 0.7542  decode.d3.loss_cls: 0.2635  decode.d3.loss_mask: 1.0138  decode.d3.loss_dice: 0.8105  decode.d4.loss_cls: 0.3217  decode.d4.loss_mask: 0.9809  decode.d4.loss_dice: 0.7468  decode.d5.loss_cls: 0.2311  decode.d5.loss_mask: 1.0085  decode.d5.loss_dice: 0.8107  decode.d6.loss_cls: 0.2499  decode.d6.loss_mask: 1.0078  decode.d6.loss_dice: 0.8090  decode.d7.loss_cls: 0.2621  decode.d7.loss_mask: 1.0231  decode.d7.loss_dice: 0.8485  decode.d8.loss_cls: 0.2648  decode.d8.loss_mask: 1.0080  decode.d8.loss_dice: 0.7842
05/26 16:23:21 - mmengine - INFO - Iter(train) [ 46550/160000]  base_lr: 7.3387e-05 lr: 7.3387e-06  eta: 12:54:58  time: 0.4131  data_time: 0.0094  memory: 5975  grad_norm: 714.8555  loss: 25.8529  decode.loss_cls: 0.3631  decode.loss_mask: 1.2143  decode.loss_dice: 0.9418  decode.d0.loss_cls: 0.8269  decode.d0.loss_mask: 1.1766  decode.d0.loss_dice: 0.9853  decode.d1.loss_cls: 0.3906  decode.d1.loss_mask: 1.1765  decode.d1.loss_dice: 0.9293  decode.d2.loss_cls: 0.3957  decode.d2.loss_mask: 1.2081  decode.d2.loss_dice: 0.9683  decode.d3.loss_cls: 0.4085  decode.d3.loss_mask: 1.1608  decode.d3.loss_dice: 0.9539  decode.d4.loss_cls: 0.4446  decode.d4.loss_mask: 1.1890  decode.d4.loss_dice: 0.9565  decode.d5.loss_cls: 0.4115  decode.d5.loss_mask: 1.1894  decode.d5.loss_dice: 0.9595  decode.d6.loss_cls: 0.4013  decode.d6.loss_mask: 1.1767  decode.d6.loss_dice: 0.9535  decode.d7.loss_cls: 0.4056  decode.d7.loss_mask: 1.1927  decode.d7.loss_dice: 0.9569  decode.d8.loss_cls: 0.3725  decode.d8.loss_mask: 1.1926  decode.d8.loss_dice: 0.9509
05/26 16:23:42 - mmengine - INFO - Iter(train) [ 46600/160000]  base_lr: 7.3358e-05 lr: 7.3358e-06  eta: 12:54:38  time: 0.4141  data_time: 0.0095  memory: 5974  grad_norm: 783.4289  loss: 22.9511  decode.loss_cls: 0.2094  decode.loss_mask: 1.2334  decode.loss_dice: 0.7595  decode.d0.loss_cls: 0.6617  decode.d0.loss_mask: 1.2559  decode.d0.loss_dice: 0.7683  decode.d1.loss_cls: 0.1660  decode.d1.loss_mask: 1.3117  decode.d1.loss_dice: 0.8160  decode.d2.loss_cls: 0.1854  decode.d2.loss_mask: 1.2949  decode.d2.loss_dice: 0.7876  decode.d3.loss_cls: 0.2529  decode.d3.loss_mask: 1.2503  decode.d3.loss_dice: 0.7571  decode.d4.loss_cls: 0.2404  decode.d4.loss_mask: 1.2680  decode.d4.loss_dice: 0.7719  decode.d5.loss_cls: 0.2123  decode.d5.loss_mask: 1.2268  decode.d5.loss_dice: 0.7635  decode.d6.loss_cls: 0.1781  decode.d6.loss_mask: 1.2807  decode.d6.loss_dice: 0.7802  decode.d7.loss_cls: 0.2327  decode.d7.loss_mask: 1.2887  decode.d7.loss_dice: 0.7789  decode.d8.loss_cls: 0.2055  decode.d8.loss_mask: 1.2459  decode.d8.loss_dice: 0.7671
05/26 16:24:03 - mmengine - INFO - Iter(train) [ 46650/160000]  base_lr: 7.3329e-05 lr: 7.3329e-06  eta: 12:54:19  time: 0.4112  data_time: 0.0094  memory: 5976  grad_norm: 834.9407  loss: 26.5817  decode.loss_cls: 0.3752  decode.loss_mask: 1.3111  decode.loss_dice: 0.9423  decode.d0.loss_cls: 0.7517  decode.d0.loss_mask: 1.2442  decode.d0.loss_dice: 0.9334  decode.d1.loss_cls: 0.3282  decode.d1.loss_mask: 1.3243  decode.d1.loss_dice: 0.9045  decode.d2.loss_cls: 0.3187  decode.d2.loss_mask: 1.3506  decode.d2.loss_dice: 0.9290  decode.d3.loss_cls: 0.3220  decode.d3.loss_mask: 1.3580  decode.d3.loss_dice: 0.9648  decode.d4.loss_cls: 0.3979  decode.d4.loss_mask: 1.2828  decode.d4.loss_dice: 0.9322  decode.d5.loss_cls: 0.3546  decode.d5.loss_mask: 1.3404  decode.d5.loss_dice: 0.9218  decode.d6.loss_cls: 0.4012  decode.d6.loss_mask: 1.3415  decode.d6.loss_dice: 0.9393  decode.d7.loss_cls: 0.3936  decode.d7.loss_mask: 1.3069  decode.d7.loss_dice: 0.9255  decode.d8.loss_cls: 0.3778  decode.d8.loss_mask: 1.3267  decode.d8.loss_dice: 0.9815
05/26 16:24:23 - mmengine - INFO - Iter(train) [ 46700/160000]  base_lr: 7.3300e-05 lr: 7.3300e-06  eta: 12:53:58  time: 0.4094  data_time: 0.0093  memory: 5969  grad_norm: 439.8515  loss: 18.2203  decode.loss_cls: 0.1480  decode.loss_mask: 0.9703  decode.loss_dice: 0.6619  decode.d0.loss_cls: 0.6222  decode.d0.loss_mask: 0.9399  decode.d0.loss_dice: 0.6554  decode.d1.loss_cls: 0.1847  decode.d1.loss_mask: 0.9632  decode.d1.loss_dice: 0.6508  decode.d2.loss_cls: 0.1843  decode.d2.loss_mask: 0.9425  decode.d2.loss_dice: 0.6373  decode.d3.loss_cls: 0.1717  decode.d3.loss_mask: 0.9359  decode.d3.loss_dice: 0.6480  decode.d4.loss_cls: 0.1849  decode.d4.loss_mask: 0.9387  decode.d4.loss_dice: 0.6471  decode.d5.loss_cls: 0.1459  decode.d5.loss_mask: 0.9642  decode.d5.loss_dice: 0.6741  decode.d6.loss_cls: 0.1477  decode.d6.loss_mask: 0.9489  decode.d6.loss_dice: 0.6649  decode.d7.loss_cls: 0.1782  decode.d7.loss_mask: 0.9549  decode.d7.loss_dice: 0.6573  decode.d8.loss_cls: 0.1622  decode.d8.loss_mask: 0.9557  decode.d8.loss_dice: 0.6793
05/26 16:24:44 - mmengine - INFO - Iter(train) [ 46750/160000]  base_lr: 7.3270e-05 lr: 7.3270e-06  eta: 12:53:38  time: 0.4093  data_time: 0.0093  memory: 5975  grad_norm: 470.2750  loss: 25.0714  decode.loss_cls: 0.2137  decode.loss_mask: 1.2959  decode.loss_dice: 0.9104  decode.d0.loss_cls: 0.7785  decode.d0.loss_mask: 1.1787  decode.d0.loss_dice: 0.8709  decode.d1.loss_cls: 0.2968  decode.d1.loss_mask: 1.2579  decode.d1.loss_dice: 0.8936  decode.d2.loss_cls: 0.2909  decode.d2.loss_mask: 1.2760  decode.d2.loss_dice: 0.9026  decode.d3.loss_cls: 0.3189  decode.d3.loss_mask: 1.2623  decode.d3.loss_dice: 0.9044  decode.d4.loss_cls: 0.2497  decode.d4.loss_mask: 1.3044  decode.d4.loss_dice: 0.9395  decode.d5.loss_cls: 0.2796  decode.d5.loss_mask: 1.2982  decode.d5.loss_dice: 0.9121  decode.d6.loss_cls: 0.2699  decode.d6.loss_mask: 1.3184  decode.d6.loss_dice: 0.9291  decode.d7.loss_cls: 0.2765  decode.d7.loss_mask: 1.2905  decode.d7.loss_dice: 0.9254  decode.d8.loss_cls: 0.2405  decode.d8.loss_mask: 1.2578  decode.d8.loss_dice: 0.9283
05/26 16:25:04 - mmengine - INFO - Iter(train) [ 46800/160000]  base_lr: 7.3241e-05 lr: 7.3241e-06  eta: 12:53:17  time: 0.4102  data_time: 0.0093  memory: 5967  grad_norm: 497.7600  loss: 20.1963  decode.loss_cls: 0.2308  decode.loss_mask: 1.0305  decode.loss_dice: 0.7038  decode.d0.loss_cls: 0.6901  decode.d0.loss_mask: 0.9731  decode.d0.loss_dice: 0.6561  decode.d1.loss_cls: 0.2333  decode.d1.loss_mask: 1.0408  decode.d1.loss_dice: 0.7067  decode.d2.loss_cls: 0.2285  decode.d2.loss_mask: 1.0136  decode.d2.loss_dice: 0.7031  decode.d3.loss_cls: 0.2228  decode.d3.loss_mask: 1.0313  decode.d3.loss_dice: 0.6699  decode.d4.loss_cls: 0.2416  decode.d4.loss_mask: 1.0953  decode.d4.loss_dice: 0.7243  decode.d5.loss_cls: 0.2264  decode.d5.loss_mask: 1.0787  decode.d5.loss_dice: 0.7336  decode.d6.loss_cls: 0.2039  decode.d6.loss_mask: 1.0498  decode.d6.loss_dice: 0.6868  decode.d7.loss_cls: 0.2246  decode.d7.loss_mask: 1.0801  decode.d7.loss_dice: 0.7409  decode.d8.loss_cls: 0.2521  decode.d8.loss_mask: 1.0362  decode.d8.loss_dice: 0.6875
05/26 16:25:25 - mmengine - INFO - Iter(train) [ 46850/160000]  base_lr: 7.3212e-05 lr: 7.3212e-06  eta: 12:52:57  time: 0.4109  data_time: 0.0093  memory: 5969  grad_norm: 450.6797  loss: 22.0544  decode.loss_cls: 0.1867  decode.loss_mask: 1.0772  decode.loss_dice: 0.8041  decode.d0.loss_cls: 0.8070  decode.d0.loss_mask: 1.0484  decode.d0.loss_dice: 0.8120  decode.d1.loss_cls: 0.2675  decode.d1.loss_mask: 1.0761  decode.d1.loss_dice: 0.7918  decode.d2.loss_cls: 0.2289  decode.d2.loss_mask: 1.1054  decode.d2.loss_dice: 0.8272  decode.d3.loss_cls: 0.2422  decode.d3.loss_mask: 1.1013  decode.d3.loss_dice: 0.8366  decode.d4.loss_cls: 0.2457  decode.d4.loss_mask: 1.0903  decode.d4.loss_dice: 0.8331  decode.d5.loss_cls: 0.2719  decode.d5.loss_mask: 1.0840  decode.d5.loss_dice: 0.8273  decode.d6.loss_cls: 0.2290  decode.d6.loss_mask: 1.0928  decode.d6.loss_dice: 0.8414  decode.d7.loss_cls: 0.2838  decode.d7.loss_mask: 1.1012  decode.d7.loss_dice: 0.8384  decode.d8.loss_cls: 0.2047  decode.d8.loss_mask: 1.0818  decode.d8.loss_dice: 0.8165
05/26 16:25:45 - mmengine - INFO - Iter(train) [ 46900/160000]  base_lr: 7.3183e-05 lr: 7.3183e-06  eta: 12:52:37  time: 0.4112  data_time: 0.0093  memory: 5967  grad_norm: 611.1432  loss: 26.8669  decode.loss_cls: 0.3049  decode.loss_mask: 1.4609  decode.loss_dice: 0.9078  decode.d0.loss_cls: 0.7847  decode.d0.loss_mask: 1.3262  decode.d0.loss_dice: 0.8298  decode.d1.loss_cls: 0.3559  decode.d1.loss_mask: 1.3965  decode.d1.loss_dice: 0.8452  decode.d2.loss_cls: 0.4041  decode.d2.loss_mask: 1.3845  decode.d2.loss_dice: 0.8597  decode.d3.loss_cls: 0.3580  decode.d3.loss_mask: 1.4523  decode.d3.loss_dice: 0.8818  decode.d4.loss_cls: 0.3590  decode.d4.loss_mask: 1.4558  decode.d4.loss_dice: 0.9049  decode.d5.loss_cls: 0.3900  decode.d5.loss_mask: 1.3995  decode.d5.loss_dice: 0.8628  decode.d6.loss_cls: 0.2982  decode.d6.loss_mask: 1.4076  decode.d6.loss_dice: 0.8758  decode.d7.loss_cls: 0.3659  decode.d7.loss_mask: 1.4296  decode.d7.loss_dice: 0.8714  decode.d8.loss_cls: 0.3711  decode.d8.loss_mask: 1.4408  decode.d8.loss_dice: 0.8822
05/26 16:26:06 - mmengine - INFO - Iter(train) [ 46950/160000]  base_lr: 7.3154e-05 lr: 7.3154e-06  eta: 12:52:16  time: 0.4110  data_time: 0.0093  memory: 5969  grad_norm: 731.9918  loss: 18.8500  decode.loss_cls: 0.2029  decode.loss_mask: 0.9948  decode.loss_dice: 0.7008  decode.d0.loss_cls: 0.7034  decode.d0.loss_mask: 0.8991  decode.d0.loss_dice: 0.6467  decode.d1.loss_cls: 0.2555  decode.d1.loss_mask: 0.9719  decode.d1.loss_dice: 0.6597  decode.d2.loss_cls: 0.2339  decode.d2.loss_mask: 0.9689  decode.d2.loss_dice: 0.6544  decode.d3.loss_cls: 0.2331  decode.d3.loss_mask: 0.9259  decode.d3.loss_dice: 0.6483  decode.d4.loss_cls: 0.2413  decode.d4.loss_mask: 0.9377  decode.d4.loss_dice: 0.6268  decode.d5.loss_cls: 0.2175  decode.d5.loss_mask: 0.9513  decode.d5.loss_dice: 0.6383  decode.d6.loss_cls: 0.2717  decode.d6.loss_mask: 0.8946  decode.d6.loss_dice: 0.6429  decode.d7.loss_cls: 0.2226  decode.d7.loss_mask: 0.9348  decode.d7.loss_dice: 0.6944  decode.d8.loss_cls: 0.2237  decode.d8.loss_mask: 0.9655  decode.d8.loss_dice: 0.6878
05/26 16:26:26 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 16:26:26 - mmengine - INFO - Iter(train) [ 47000/160000]  base_lr: 7.3125e-05 lr: 7.3125e-06  eta: 12:51:56  time: 0.4097  data_time: 0.0093  memory: 5967  grad_norm: 976.9865  loss: 23.4626  decode.loss_cls: 0.2599  decode.loss_mask: 1.3168  decode.loss_dice: 0.7756  decode.d0.loss_cls: 0.8082  decode.d0.loss_mask: 1.1045  decode.d0.loss_dice: 0.7232  decode.d1.loss_cls: 0.2357  decode.d1.loss_mask: 1.3022  decode.d1.loss_dice: 0.7838  decode.d2.loss_cls: 0.2720  decode.d2.loss_mask: 1.2152  decode.d2.loss_dice: 0.7518  decode.d3.loss_cls: 0.2405  decode.d3.loss_mask: 1.3106  decode.d3.loss_dice: 0.7492  decode.d4.loss_cls: 0.2091  decode.d4.loss_mask: 1.3577  decode.d4.loss_dice: 0.7648  decode.d5.loss_cls: 0.2376  decode.d5.loss_mask: 1.3077  decode.d5.loss_dice: 0.7720  decode.d6.loss_cls: 0.2569  decode.d6.loss_mask: 1.3222  decode.d6.loss_dice: 0.7761  decode.d7.loss_cls: 0.2698  decode.d7.loss_mask: 1.2433  decode.d7.loss_dice: 0.7260  decode.d8.loss_cls: 0.2471  decode.d8.loss_mask: 1.3421  decode.d8.loss_dice: 0.7807
05/26 16:26:47 - mmengine - INFO - Iter(train) [ 47050/160000]  base_lr: 7.3096e-05 lr: 7.3096e-06  eta: 12:51:36  time: 0.4117  data_time: 0.0092  memory: 5966  grad_norm: 640.2064  loss: 26.2047  decode.loss_cls: 0.2317  decode.loss_mask: 1.3735  decode.loss_dice: 0.9792  decode.d0.loss_cls: 0.8277  decode.d0.loss_mask: 1.2135  decode.d0.loss_dice: 0.8529  decode.d1.loss_cls: 0.3209  decode.d1.loss_mask: 1.3203  decode.d1.loss_dice: 0.9336  decode.d2.loss_cls: 0.3029  decode.d2.loss_mask: 1.3501  decode.d2.loss_dice: 0.9546  decode.d3.loss_cls: 0.2579  decode.d3.loss_mask: 1.3644  decode.d3.loss_dice: 0.9902  decode.d4.loss_cls: 0.3303  decode.d4.loss_mask: 1.3213  decode.d4.loss_dice: 0.9135  decode.d5.loss_cls: 0.3164  decode.d5.loss_mask: 1.3309  decode.d5.loss_dice: 0.9344  decode.d6.loss_cls: 0.3340  decode.d6.loss_mask: 1.3011  decode.d6.loss_dice: 0.9541  decode.d7.loss_cls: 0.2488  decode.d7.loss_mask: 1.3576  decode.d7.loss_dice: 0.9579  decode.d8.loss_cls: 0.2478  decode.d8.loss_mask: 1.4114  decode.d8.loss_dice: 0.9719
05/26 16:27:08 - mmengine - INFO - Iter(train) [ 47100/160000]  base_lr: 7.3067e-05 lr: 7.3067e-06  eta: 12:51:15  time: 0.4109  data_time: 0.0093  memory: 5970  grad_norm: 682.4444  loss: 21.6275  decode.loss_cls: 0.2186  decode.loss_mask: 1.1416  decode.loss_dice: 0.8072  decode.d0.loss_cls: 0.6889  decode.d0.loss_mask: 1.0302  decode.d0.loss_dice: 0.7201  decode.d1.loss_cls: 0.2731  decode.d1.loss_mask: 1.0810  decode.d1.loss_dice: 0.7461  decode.d2.loss_cls: 0.2253  decode.d2.loss_mask: 1.1247  decode.d2.loss_dice: 0.7681  decode.d3.loss_cls: 0.2503  decode.d3.loss_mask: 1.1312  decode.d3.loss_dice: 0.7887  decode.d4.loss_cls: 0.2571  decode.d4.loss_mask: 1.1203  decode.d4.loss_dice: 0.7513  decode.d5.loss_cls: 0.2637  decode.d5.loss_mask: 1.0877  decode.d5.loss_dice: 0.7717  decode.d6.loss_cls: 0.2366  decode.d6.loss_mask: 1.1256  decode.d6.loss_dice: 0.7838  decode.d7.loss_cls: 0.2572  decode.d7.loss_mask: 1.0956  decode.d7.loss_dice: 0.7598  decode.d8.loss_cls: 0.2460  decode.d8.loss_mask: 1.1222  decode.d8.loss_dice: 0.7536
05/26 16:27:28 - mmengine - INFO - Iter(train) [ 47150/160000]  base_lr: 7.3037e-05 lr: 7.3037e-06  eta: 12:50:55  time: 0.4119  data_time: 0.0093  memory: 5971  grad_norm: 862.2753  loss: 26.6302  decode.loss_cls: 0.3360  decode.loss_mask: 1.3143  decode.loss_dice: 0.9273  decode.d0.loss_cls: 0.9236  decode.d0.loss_mask: 1.1436  decode.d0.loss_dice: 0.8919  decode.d1.loss_cls: 0.4256  decode.d1.loss_mask: 1.2209  decode.d1.loss_dice: 0.9062  decode.d2.loss_cls: 0.4277  decode.d2.loss_mask: 1.3165  decode.d2.loss_dice: 0.9431  decode.d3.loss_cls: 0.4299  decode.d3.loss_mask: 1.2417  decode.d3.loss_dice: 0.9176  decode.d4.loss_cls: 0.4708  decode.d4.loss_mask: 1.2692  decode.d4.loss_dice: 0.9116  decode.d5.loss_cls: 0.3582  decode.d5.loss_mask: 1.3225  decode.d5.loss_dice: 0.9641  decode.d6.loss_cls: 0.3917  decode.d6.loss_mask: 1.3453  decode.d6.loss_dice: 0.9548  decode.d7.loss_cls: 0.4802  decode.d7.loss_mask: 1.2543  decode.d7.loss_dice: 0.9327  decode.d8.loss_cls: 0.3648  decode.d8.loss_mask: 1.3167  decode.d8.loss_dice: 0.9275
05/26 16:27:49 - mmengine - INFO - Iter(train) [ 47200/160000]  base_lr: 7.3008e-05 lr: 7.3008e-06  eta: 12:50:34  time: 0.4120  data_time: 0.0093  memory: 5989  grad_norm: 587.3165  loss: 24.3502  decode.loss_cls: 0.2650  decode.loss_mask: 1.1689  decode.loss_dice: 0.9442  decode.d0.loss_cls: 0.6958  decode.d0.loss_mask: 1.1615  decode.d0.loss_dice: 0.9062  decode.d1.loss_cls: 0.2905  decode.d1.loss_mask: 1.2236  decode.d1.loss_dice: 0.9242  decode.d2.loss_cls: 0.2425  decode.d2.loss_mask: 1.1856  decode.d2.loss_dice: 0.9177  decode.d3.loss_cls: 0.3029  decode.d3.loss_mask: 1.1791  decode.d3.loss_dice: 0.9265  decode.d4.loss_cls: 0.2963  decode.d4.loss_mask: 1.2019  decode.d4.loss_dice: 0.9210  decode.d5.loss_cls: 0.3121  decode.d5.loss_mask: 1.1813  decode.d5.loss_dice: 0.9045  decode.d6.loss_cls: 0.3059  decode.d6.loss_mask: 1.1777  decode.d6.loss_dice: 0.9254  decode.d7.loss_cls: 0.2828  decode.d7.loss_mask: 1.1865  decode.d7.loss_dice: 0.9252  decode.d8.loss_cls: 0.2955  decode.d8.loss_mask: 1.1761  decode.d8.loss_dice: 0.9239
05/26 16:28:09 - mmengine - INFO - Iter(train) [ 47250/160000]  base_lr: 7.2979e-05 lr: 7.2979e-06  eta: 12:50:14  time: 0.4116  data_time: 0.0094  memory: 5975  grad_norm: 642.1777  loss: 26.7063  decode.loss_cls: 0.4016  decode.loss_mask: 1.2970  decode.loss_dice: 0.9063  decode.d0.loss_cls: 0.9300  decode.d0.loss_mask: 1.1919  decode.d0.loss_dice: 0.8659  decode.d1.loss_cls: 0.3797  decode.d1.loss_mask: 1.2834  decode.d1.loss_dice: 0.9262  decode.d2.loss_cls: 0.4042  decode.d2.loss_mask: 1.2975  decode.d2.loss_dice: 0.9323  decode.d3.loss_cls: 0.4512  decode.d3.loss_mask: 1.2570  decode.d3.loss_dice: 0.8651  decode.d4.loss_cls: 0.4229  decode.d4.loss_mask: 1.2670  decode.d4.loss_dice: 0.9062  decode.d5.loss_cls: 0.4540  decode.d5.loss_mask: 1.2579  decode.d5.loss_dice: 0.9271  decode.d6.loss_cls: 0.4549  decode.d6.loss_mask: 1.2856  decode.d6.loss_dice: 0.9608  decode.d7.loss_cls: 0.5252  decode.d7.loss_mask: 1.2406  decode.d7.loss_dice: 0.9097  decode.d8.loss_cls: 0.4842  decode.d8.loss_mask: 1.3076  decode.d8.loss_dice: 0.9134
05/26 16:28:30 - mmengine - INFO - Iter(train) [ 47300/160000]  base_lr: 7.2950e-05 lr: 7.2950e-06  eta: 12:49:54  time: 0.4113  data_time: 0.0094  memory: 5974  grad_norm: 580.8698  loss: 21.0998  decode.loss_cls: 0.2524  decode.loss_mask: 1.0160  decode.loss_dice: 0.7913  decode.d0.loss_cls: 0.7559  decode.d0.loss_mask: 0.9277  decode.d0.loss_dice: 0.7692  decode.d1.loss_cls: 0.2234  decode.d1.loss_mask: 1.0362  decode.d1.loss_dice: 0.8174  decode.d2.loss_cls: 0.2765  decode.d2.loss_mask: 1.0287  decode.d2.loss_dice: 0.8042  decode.d3.loss_cls: 0.3004  decode.d3.loss_mask: 1.0035  decode.d3.loss_dice: 0.7834  decode.d4.loss_cls: 0.3019  decode.d4.loss_mask: 0.9695  decode.d4.loss_dice: 0.7857  decode.d5.loss_cls: 0.2729  decode.d5.loss_mask: 0.9869  decode.d5.loss_dice: 0.7915  decode.d6.loss_cls: 0.2936  decode.d6.loss_mask: 0.9985  decode.d6.loss_dice: 0.7784  decode.d7.loss_cls: 0.2365  decode.d7.loss_mask: 1.0078  decode.d7.loss_dice: 0.8340  decode.d8.loss_cls: 0.2351  decode.d8.loss_mask: 1.0256  decode.d8.loss_dice: 0.7957
05/26 16:28:50 - mmengine - INFO - Iter(train) [ 47350/160000]  base_lr: 7.2921e-05 lr: 7.2921e-06  eta: 12:49:33  time: 0.4121  data_time: 0.0093  memory: 5975  grad_norm: 749.5362  loss: 26.9106  decode.loss_cls: 0.2498  decode.loss_mask: 1.3630  decode.loss_dice: 1.0415  decode.d0.loss_cls: 0.7192  decode.d0.loss_mask: 1.2870  decode.d0.loss_dice: 1.0234  decode.d1.loss_cls: 0.2495  decode.d1.loss_mask: 1.3477  decode.d1.loss_dice: 1.0349  decode.d2.loss_cls: 0.2415  decode.d2.loss_mask: 1.3740  decode.d2.loss_dice: 1.0512  decode.d3.loss_cls: 0.2413  decode.d3.loss_mask: 1.4219  decode.d3.loss_dice: 1.0572  decode.d4.loss_cls: 0.2206  decode.d4.loss_mask: 1.3917  decode.d4.loss_dice: 1.0538  decode.d5.loss_cls: 0.2125  decode.d5.loss_mask: 1.4488  decode.d5.loss_dice: 1.0410  decode.d6.loss_cls: 0.2277  decode.d6.loss_mask: 1.3576  decode.d6.loss_dice: 1.0033  decode.d7.loss_cls: 0.2468  decode.d7.loss_mask: 1.3428  decode.d7.loss_dice: 1.0339  decode.d8.loss_cls: 0.2352  decode.d8.loss_mask: 1.3654  decode.d8.loss_dice: 1.0263
05/26 16:29:11 - mmengine - INFO - Iter(train) [ 47400/160000]  base_lr: 7.2892e-05 lr: 7.2892e-06  eta: 12:49:13  time: 0.4119  data_time: 0.0093  memory: 5967  grad_norm: 1098.6978  loss: 23.2066  decode.loss_cls: 0.2525  decode.loss_mask: 1.1837  decode.loss_dice: 0.8599  decode.d0.loss_cls: 0.7502  decode.d0.loss_mask: 1.1446  decode.d0.loss_dice: 0.7962  decode.d1.loss_cls: 0.2383  decode.d1.loss_mask: 1.2350  decode.d1.loss_dice: 0.8251  decode.d2.loss_cls: 0.2346  decode.d2.loss_mask: 1.1770  decode.d2.loss_dice: 0.8452  decode.d3.loss_cls: 0.2783  decode.d3.loss_mask: 1.2143  decode.d3.loss_dice: 0.8341  decode.d4.loss_cls: 0.2758  decode.d4.loss_mask: 1.1354  decode.d4.loss_dice: 0.8124  decode.d5.loss_cls: 0.2476  decode.d5.loss_mask: 1.2013  decode.d5.loss_dice: 0.8314  decode.d6.loss_cls: 0.2589  decode.d6.loss_mask: 1.1860  decode.d6.loss_dice: 0.8229  decode.d7.loss_cls: 0.2490  decode.d7.loss_mask: 1.2033  decode.d7.loss_dice: 0.8479  decode.d8.loss_cls: 0.2426  decode.d8.loss_mask: 1.1789  decode.d8.loss_dice: 0.8443
05/26 16:29:31 - mmengine - INFO - Iter(train) [ 47450/160000]  base_lr: 7.2863e-05 lr: 7.2863e-06  eta: 12:48:53  time: 0.4114  data_time: 0.0094  memory: 5966  grad_norm: 545.2067  loss: 26.6157  decode.loss_cls: 0.4057  decode.loss_mask: 1.2343  decode.loss_dice: 0.9541  decode.d0.loss_cls: 0.9314  decode.d0.loss_mask: 1.1652  decode.d0.loss_dice: 0.8791  decode.d1.loss_cls: 0.4246  decode.d1.loss_mask: 1.2191  decode.d1.loss_dice: 0.9494  decode.d2.loss_cls: 0.4318  decode.d2.loss_mask: 1.2387  decode.d2.loss_dice: 0.9560  decode.d3.loss_cls: 0.3971  decode.d3.loss_mask: 1.2464  decode.d3.loss_dice: 0.9783  decode.d4.loss_cls: 0.3825  decode.d4.loss_mask: 1.2513  decode.d4.loss_dice: 1.0030  decode.d5.loss_cls: 0.4156  decode.d5.loss_mask: 1.2712  decode.d5.loss_dice: 1.0022  decode.d6.loss_cls: 0.4267  decode.d6.loss_mask: 1.2309  decode.d6.loss_dice: 0.9870  decode.d7.loss_cls: 0.4102  decode.d7.loss_mask: 1.2376  decode.d7.loss_dice: 0.9556  decode.d8.loss_cls: 0.3971  decode.d8.loss_mask: 1.2543  decode.d8.loss_dice: 0.9792
05/26 16:29:52 - mmengine - INFO - Iter(train) [ 47500/160000]  base_lr: 7.2834e-05 lr: 7.2834e-06  eta: 12:48:32  time: 0.4123  data_time: 0.0093  memory: 5966  grad_norm: 932.2203  loss: 21.1673  decode.loss_cls: 0.2955  decode.loss_mask: 0.9539  decode.loss_dice: 0.7891  decode.d0.loss_cls: 0.8100  decode.d0.loss_mask: 0.9090  decode.d0.loss_dice: 0.7608  decode.d1.loss_cls: 0.3339  decode.d1.loss_mask: 0.9963  decode.d1.loss_dice: 0.8078  decode.d2.loss_cls: 0.3127  decode.d2.loss_mask: 0.9534  decode.d2.loss_dice: 0.7848  decode.d3.loss_cls: 0.3009  decode.d3.loss_mask: 0.9474  decode.d3.loss_dice: 0.8196  decode.d4.loss_cls: 0.3121  decode.d4.loss_mask: 0.9589  decode.d4.loss_dice: 0.8043  decode.d5.loss_cls: 0.3063  decode.d5.loss_mask: 0.9662  decode.d5.loss_dice: 0.7900  decode.d6.loss_cls: 0.3321  decode.d6.loss_mask: 0.9795  decode.d6.loss_dice: 0.7835  decode.d7.loss_cls: 0.3571  decode.d7.loss_mask: 0.9485  decode.d7.loss_dice: 0.7788  decode.d8.loss_cls: 0.3365  decode.d8.loss_mask: 0.9693  decode.d8.loss_dice: 0.7691
05/26 16:30:13 - mmengine - INFO - Iter(train) [ 47550/160000]  base_lr: 7.2804e-05 lr: 7.2804e-06  eta: 12:48:12  time: 0.4112  data_time: 0.0093  memory: 5975  grad_norm: 1568.8258  loss: 24.0154  decode.loss_cls: 0.2953  decode.loss_mask: 1.1957  decode.loss_dice: 0.8480  decode.d0.loss_cls: 0.7919  decode.d0.loss_mask: 1.0990  decode.d0.loss_dice: 0.8030  decode.d1.loss_cls: 0.3547  decode.d1.loss_mask: 1.1960  decode.d1.loss_dice: 0.8449  decode.d2.loss_cls: 0.3201  decode.d2.loss_mask: 1.2211  decode.d2.loss_dice: 0.8624  decode.d3.loss_cls: 0.3334  decode.d3.loss_mask: 1.1776  decode.d3.loss_dice: 0.8378  decode.d4.loss_cls: 0.3407  decode.d4.loss_mask: 1.2048  decode.d4.loss_dice: 0.8592  decode.d5.loss_cls: 0.3317  decode.d5.loss_mask: 1.2146  decode.d5.loss_dice: 0.8655  decode.d6.loss_cls: 0.2616  decode.d6.loss_mask: 1.1966  decode.d6.loss_dice: 0.8582  decode.d7.loss_cls: 0.3347  decode.d7.loss_mask: 1.1674  decode.d7.loss_dice: 0.8536  decode.d8.loss_cls: 0.3531  decode.d8.loss_mask: 1.1542  decode.d8.loss_dice: 0.8387
05/26 16:30:33 - mmengine - INFO - Iter(train) [ 47600/160000]  base_lr: 7.2775e-05 lr: 7.2775e-06  eta: 12:47:52  time: 0.4115  data_time: 0.0093  memory: 5966  grad_norm: 453.1999  loss: 22.4465  decode.loss_cls: 0.1432  decode.loss_mask: 1.1923  decode.loss_dice: 0.8504  decode.d0.loss_cls: 0.7558  decode.d0.loss_mask: 1.0932  decode.d0.loss_dice: 0.7893  decode.d1.loss_cls: 0.2308  decode.d1.loss_mask: 1.1672  decode.d1.loss_dice: 0.7928  decode.d2.loss_cls: 0.1819  decode.d2.loss_mask: 1.1821  decode.d2.loss_dice: 0.8140  decode.d3.loss_cls: 0.2250  decode.d3.loss_mask: 1.1596  decode.d3.loss_dice: 0.8302  decode.d4.loss_cls: 0.1928  decode.d4.loss_mask: 1.1917  decode.d4.loss_dice: 0.8348  decode.d5.loss_cls: 0.2411  decode.d5.loss_mask: 1.1288  decode.d5.loss_dice: 0.8045  decode.d6.loss_cls: 0.2545  decode.d6.loss_mask: 1.1680  decode.d6.loss_dice: 0.8175  decode.d7.loss_cls: 0.1825  decode.d7.loss_mask: 1.1944  decode.d7.loss_dice: 0.8325  decode.d8.loss_cls: 0.1602  decode.d8.loss_mask: 1.1938  decode.d8.loss_dice: 0.8414
05/26 16:30:54 - mmengine - INFO - Iter(train) [ 47650/160000]  base_lr: 7.2746e-05 lr: 7.2746e-06  eta: 12:47:31  time: 0.4113  data_time: 0.0093  memory: 5979  grad_norm: 466.7782  loss: 24.6616  decode.loss_cls: 0.3502  decode.loss_mask: 1.1277  decode.loss_dice: 0.9444  decode.d0.loss_cls: 0.7558  decode.d0.loss_mask: 1.1265  decode.d0.loss_dice: 0.9440  decode.d1.loss_cls: 0.3302  decode.d1.loss_mask: 1.1175  decode.d1.loss_dice: 0.9213  decode.d2.loss_cls: 0.3294  decode.d2.loss_mask: 1.1518  decode.d2.loss_dice: 0.9199  decode.d3.loss_cls: 0.3213  decode.d3.loss_mask: 1.1688  decode.d3.loss_dice: 0.9489  decode.d4.loss_cls: 0.3283  decode.d4.loss_mask: 1.1362  decode.d4.loss_dice: 0.9762  decode.d5.loss_cls: 0.3792  decode.d5.loss_mask: 1.1088  decode.d5.loss_dice: 0.9431  decode.d6.loss_cls: 0.3608  decode.d6.loss_mask: 1.1856  decode.d6.loss_dice: 0.9557  decode.d7.loss_cls: 0.3139  decode.d7.loss_mask: 1.1508  decode.d7.loss_dice: 0.9604  decode.d8.loss_cls: 0.2924  decode.d8.loss_mask: 1.2008  decode.d8.loss_dice: 0.9119
05/26 16:31:14 - mmengine - INFO - Iter(train) [ 47700/160000]  base_lr: 7.2717e-05 lr: 7.2717e-06  eta: 12:47:11  time: 0.4111  data_time: 0.0093  memory: 5976  grad_norm: 1165.7038  loss: 26.5313  decode.loss_cls: 0.2964  decode.loss_mask: 1.3639  decode.loss_dice: 0.9139  decode.d0.loss_cls: 0.8613  decode.d0.loss_mask: 1.2660  decode.d0.loss_dice: 0.9298  decode.d1.loss_cls: 0.3232  decode.d1.loss_mask: 1.3651  decode.d1.loss_dice: 0.9192  decode.d2.loss_cls: 0.3570  decode.d2.loss_mask: 1.3372  decode.d2.loss_dice: 0.9131  decode.d3.loss_cls: 0.3450  decode.d3.loss_mask: 1.2584  decode.d3.loss_dice: 0.9250  decode.d4.loss_cls: 0.3499  decode.d4.loss_mask: 1.3575  decode.d4.loss_dice: 0.9627  decode.d5.loss_cls: 0.3467  decode.d5.loss_mask: 1.3395  decode.d5.loss_dice: 0.9382  decode.d6.loss_cls: 0.3342  decode.d6.loss_mask: 1.3599  decode.d6.loss_dice: 0.9542  decode.d7.loss_cls: 0.3354  decode.d7.loss_mask: 1.3508  decode.d7.loss_dice: 0.9333  decode.d8.loss_cls: 0.3366  decode.d8.loss_mask: 1.3509  decode.d8.loss_dice: 0.9071
05/26 16:31:35 - mmengine - INFO - Iter(train) [ 47750/160000]  base_lr: 7.2688e-05 lr: 7.2688e-06  eta: 12:46:51  time: 0.4119  data_time: 0.0093  memory: 5970  grad_norm: 402.1264  loss: 21.2414  decode.loss_cls: 0.2143  decode.loss_mask: 0.9910  decode.loss_dice: 0.8698  decode.d0.loss_cls: 0.6292  decode.d0.loss_mask: 0.9224  decode.d0.loss_dice: 0.8685  decode.d1.loss_cls: 0.2493  decode.d1.loss_mask: 0.9899  decode.d1.loss_dice: 0.8612  decode.d2.loss_cls: 0.2057  decode.d2.loss_mask: 1.0029  decode.d2.loss_dice: 0.8772  decode.d3.loss_cls: 0.2348  decode.d3.loss_mask: 1.0056  decode.d3.loss_dice: 0.8763  decode.d4.loss_cls: 0.2564  decode.d4.loss_mask: 0.9751  decode.d4.loss_dice: 0.8566  decode.d5.loss_cls: 0.2565  decode.d5.loss_mask: 0.9818  decode.d5.loss_dice: 0.8496  decode.d6.loss_cls: 0.2277  decode.d6.loss_mask: 0.9948  decode.d6.loss_dice: 0.8552  decode.d7.loss_cls: 0.2410  decode.d7.loss_mask: 0.9694  decode.d7.loss_dice: 0.8875  decode.d8.loss_cls: 0.2330  decode.d8.loss_mask: 0.9923  decode.d8.loss_dice: 0.8665
05/26 16:31:56 - mmengine - INFO - Iter(train) [ 47800/160000]  base_lr: 7.2659e-05 lr: 7.2659e-06  eta: 12:46:31  time: 0.4114  data_time: 0.0093  memory: 5976  grad_norm: 474.4662  loss: 22.9092  decode.loss_cls: 0.2668  decode.loss_mask: 1.0802  decode.loss_dice: 0.8362  decode.d0.loss_cls: 0.7946  decode.d0.loss_mask: 1.1243  decode.d0.loss_dice: 0.7863  decode.d1.loss_cls: 0.2852  decode.d1.loss_mask: 1.1064  decode.d1.loss_dice: 0.8211  decode.d2.loss_cls: 0.3110  decode.d2.loss_mask: 1.1311  decode.d2.loss_dice: 0.8434  decode.d3.loss_cls: 0.2896  decode.d3.loss_mask: 1.1251  decode.d3.loss_dice: 0.8462  decode.d4.loss_cls: 0.3293  decode.d4.loss_mask: 1.0994  decode.d4.loss_dice: 0.8359  decode.d5.loss_cls: 0.3318  decode.d5.loss_mask: 1.1011  decode.d5.loss_dice: 0.8415  decode.d6.loss_cls: 0.3446  decode.d6.loss_mask: 1.1004  decode.d6.loss_dice: 0.8215  decode.d7.loss_cls: 0.3218  decode.d7.loss_mask: 1.1276  decode.d7.loss_dice: 0.8554  decode.d8.loss_cls: 0.2888  decode.d8.loss_mask: 1.0493  decode.d8.loss_dice: 0.8133
05/26 16:32:16 - mmengine - INFO - Iter(train) [ 47850/160000]  base_lr: 7.2630e-05 lr: 7.2630e-06  eta: 12:46:10  time: 0.4117  data_time: 0.0093  memory: 5971  grad_norm: 501.1125  loss: 24.7127  decode.loss_cls: 0.2740  decode.loss_mask: 1.2141  decode.loss_dice: 0.9559  decode.d0.loss_cls: 0.7519  decode.d0.loss_mask: 1.1306  decode.d0.loss_dice: 0.8637  decode.d1.loss_cls: 0.2662  decode.d1.loss_mask: 1.1808  decode.d1.loss_dice: 0.9573  decode.d2.loss_cls: 0.2740  decode.d2.loss_mask: 1.1736  decode.d2.loss_dice: 0.9437  decode.d3.loss_cls: 0.3037  decode.d3.loss_mask: 1.1708  decode.d3.loss_dice: 0.8888  decode.d4.loss_cls: 0.3051  decode.d4.loss_mask: 1.2556  decode.d4.loss_dice: 0.9540  decode.d5.loss_cls: 0.2843  decode.d5.loss_mask: 1.2077  decode.d5.loss_dice: 0.9380  decode.d6.loss_cls: 0.3098  decode.d6.loss_mask: 1.1746  decode.d6.loss_dice: 0.9613  decode.d7.loss_cls: 0.2462  decode.d7.loss_mask: 1.2195  decode.d7.loss_dice: 0.9653  decode.d8.loss_cls: 0.3382  decode.d8.loss_mask: 1.2554  decode.d8.loss_dice: 0.9487
05/26 16:32:37 - mmengine - INFO - Iter(train) [ 47900/160000]  base_lr: 7.2600e-05 lr: 7.2600e-06  eta: 12:45:50  time: 0.4115  data_time: 0.0093  memory: 5975  grad_norm: 604.3737  loss: 27.3484  decode.loss_cls: 0.4822  decode.loss_mask: 1.1985  decode.loss_dice: 0.9429  decode.d0.loss_cls: 0.8817  decode.d0.loss_mask: 1.1643  decode.d0.loss_dice: 0.9270  decode.d1.loss_cls: 0.4835  decode.d1.loss_mask: 1.2924  decode.d1.loss_dice: 0.9764  decode.d2.loss_cls: 0.4901  decode.d2.loss_mask: 1.2441  decode.d2.loss_dice: 1.0070  decode.d3.loss_cls: 0.5042  decode.d3.loss_mask: 1.2305  decode.d3.loss_dice: 1.0021  decode.d4.loss_cls: 0.4287  decode.d4.loss_mask: 1.3794  decode.d4.loss_dice: 1.0348  decode.d5.loss_cls: 0.4847  decode.d5.loss_mask: 1.2286  decode.d5.loss_dice: 0.9495  decode.d6.loss_cls: 0.4182  decode.d6.loss_mask: 1.2620  decode.d6.loss_dice: 0.9951  decode.d7.loss_cls: 0.5166  decode.d7.loss_mask: 1.2104  decode.d7.loss_dice: 0.9668  decode.d8.loss_cls: 0.4840  decode.d8.loss_mask: 1.2073  decode.d8.loss_dice: 0.9553
05/26 16:32:57 - mmengine - INFO - Iter(train) [ 47950/160000]  base_lr: 7.2571e-05 lr: 7.2571e-06  eta: 12:45:30  time: 0.4111  data_time: 0.0093  memory: 5967  grad_norm: 773.4150  loss: 27.3509  decode.loss_cls: 0.3253  decode.loss_mask: 1.3868  decode.loss_dice: 0.9790  decode.d0.loss_cls: 0.8603  decode.d0.loss_mask: 1.2831  decode.d0.loss_dice: 0.9285  decode.d1.loss_cls: 0.3473  decode.d1.loss_mask: 1.4019  decode.d1.loss_dice: 0.9943  decode.d2.loss_cls: 0.3104  decode.d2.loss_mask: 1.4238  decode.d2.loss_dice: 0.9785  decode.d3.loss_cls: 0.3291  decode.d3.loss_mask: 1.3841  decode.d3.loss_dice: 0.9702  decode.d4.loss_cls: 0.2763  decode.d4.loss_mask: 1.4653  decode.d4.loss_dice: 0.9784  decode.d5.loss_cls: 0.2855  decode.d5.loss_mask: 1.4312  decode.d5.loss_dice: 0.9583  decode.d6.loss_cls: 0.3423  decode.d6.loss_mask: 1.3924  decode.d6.loss_dice: 0.9792  decode.d7.loss_cls: 0.2982  decode.d7.loss_mask: 1.4153  decode.d7.loss_dice: 0.9554  decode.d8.loss_cls: 0.3625  decode.d8.loss_mask: 1.3586  decode.d8.loss_dice: 0.9494
05/26 16:33:18 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 16:33:18 - mmengine - INFO - Iter(train) [ 48000/160000]  base_lr: 7.2542e-05 lr: 7.2542e-06  eta: 12:45:10  time: 0.4117  data_time: 0.0094  memory: 5966  grad_norm: 641.3324  loss: 26.3959  decode.loss_cls: 0.4231  decode.loss_mask: 1.1929  decode.loss_dice: 0.9384  decode.d0.loss_cls: 0.8862  decode.d0.loss_mask: 1.1602  decode.d0.loss_dice: 0.9107  decode.d1.loss_cls: 0.4358  decode.d1.loss_mask: 1.2490  decode.d1.loss_dice: 0.9881  decode.d2.loss_cls: 0.4926  decode.d2.loss_mask: 1.1435  decode.d2.loss_dice: 0.9764  decode.d3.loss_cls: 0.5185  decode.d3.loss_mask: 1.2139  decode.d3.loss_dice: 0.9519  decode.d4.loss_cls: 0.4359  decode.d4.loss_mask: 1.1765  decode.d4.loss_dice: 0.9524  decode.d5.loss_cls: 0.4868  decode.d5.loss_mask: 1.1705  decode.d5.loss_dice: 0.9461  decode.d6.loss_cls: 0.4860  decode.d6.loss_mask: 1.1816  decode.d6.loss_dice: 0.9140  decode.d7.loss_cls: 0.4042  decode.d7.loss_mask: 1.2265  decode.d7.loss_dice: 0.9745  decode.d8.loss_cls: 0.3631  decode.d8.loss_mask: 1.2224  decode.d8.loss_dice: 0.9744
05/26 16:33:39 - mmengine - INFO - Iter(train) [ 48050/160000]  base_lr: 7.2513e-05 lr: 7.2513e-06  eta: 12:44:49  time: 0.4121  data_time: 0.0094  memory: 5967  grad_norm: 725.3873  loss: 25.7321  decode.loss_cls: 0.3426  decode.loss_mask: 1.2182  decode.loss_dice: 0.9239  decode.d0.loss_cls: 0.8644  decode.d0.loss_mask: 1.1816  decode.d0.loss_dice: 0.9080  decode.d1.loss_cls: 0.3508  decode.d1.loss_mask: 1.2213  decode.d1.loss_dice: 1.0046  decode.d2.loss_cls: 0.3628  decode.d2.loss_mask: 1.2177  decode.d2.loss_dice: 0.9148  decode.d3.loss_cls: 0.3360  decode.d3.loss_mask: 1.2451  decode.d3.loss_dice: 0.9335  decode.d4.loss_cls: 0.3173  decode.d4.loss_mask: 1.2371  decode.d4.loss_dice: 0.9488  decode.d5.loss_cls: 0.3076  decode.d5.loss_mask: 1.2833  decode.d5.loss_dice: 0.9611  decode.d6.loss_cls: 0.3645  decode.d6.loss_mask: 1.2415  decode.d6.loss_dice: 0.9536  decode.d7.loss_cls: 0.3655  decode.d7.loss_mask: 1.2602  decode.d7.loss_dice: 0.9392  decode.d8.loss_cls: 0.3075  decode.d8.loss_mask: 1.2565  decode.d8.loss_dice: 0.9634
05/26 16:33:59 - mmengine - INFO - Iter(train) [ 48100/160000]  base_lr: 7.2484e-05 lr: 7.2484e-06  eta: 12:44:29  time: 0.4118  data_time: 0.0093  memory: 5980  grad_norm: 414.7893  loss: 21.4056  decode.loss_cls: 0.2261  decode.loss_mask: 1.0212  decode.loss_dice: 0.8009  decode.d0.loss_cls: 0.6750  decode.d0.loss_mask: 1.0428  decode.d0.loss_dice: 0.7981  decode.d1.loss_cls: 0.2183  decode.d1.loss_mask: 1.0318  decode.d1.loss_dice: 0.8429  decode.d2.loss_cls: 0.2160  decode.d2.loss_mask: 1.0411  decode.d2.loss_dice: 0.8515  decode.d3.loss_cls: 0.2578  decode.d3.loss_mask: 1.0175  decode.d3.loss_dice: 0.8143  decode.d4.loss_cls: 0.2367  decode.d4.loss_mask: 1.0521  decode.d4.loss_dice: 0.8663  decode.d5.loss_cls: 0.2508  decode.d5.loss_mask: 1.0223  decode.d5.loss_dice: 0.8275  decode.d6.loss_cls: 0.2595  decode.d6.loss_mask: 1.0305  decode.d6.loss_dice: 0.8011  decode.d7.loss_cls: 0.2543  decode.d7.loss_mask: 1.0395  decode.d7.loss_dice: 0.8183  decode.d8.loss_cls: 0.2556  decode.d8.loss_mask: 1.0107  decode.d8.loss_dice: 0.8250
05/26 16:34:20 - mmengine - INFO - Iter(train) [ 48150/160000]  base_lr: 7.2455e-05 lr: 7.2455e-06  eta: 12:44:09  time: 0.4112  data_time: 0.0093  memory: 5968  grad_norm: 475.7583  loss: 16.9003  decode.loss_cls: 0.1975  decode.loss_mask: 0.8451  decode.loss_dice: 0.5928  decode.d0.loss_cls: 0.5061  decode.d0.loss_mask: 0.8462  decode.d0.loss_dice: 0.6004  decode.d1.loss_cls: 0.1915  decode.d1.loss_mask: 0.8520  decode.d1.loss_dice: 0.6058  decode.d2.loss_cls: 0.1921  decode.d2.loss_mask: 0.8695  decode.d2.loss_dice: 0.6261  decode.d3.loss_cls: 0.1954  decode.d3.loss_mask: 0.8517  decode.d3.loss_dice: 0.5930  decode.d4.loss_cls: 0.1944  decode.d4.loss_mask: 0.8738  decode.d4.loss_dice: 0.6375  decode.d5.loss_cls: 0.1880  decode.d5.loss_mask: 0.8892  decode.d5.loss_dice: 0.6407  decode.d6.loss_cls: 0.1911  decode.d6.loss_mask: 0.8635  decode.d6.loss_dice: 0.6124  decode.d7.loss_cls: 0.1884  decode.d7.loss_mask: 0.8358  decode.d7.loss_dice: 0.5983  decode.d8.loss_cls: 0.1944  decode.d8.loss_mask: 0.8366  decode.d8.loss_dice: 0.5909
05/26 16:34:40 - mmengine - INFO - Iter(train) [ 48200/160000]  base_lr: 7.2426e-05 lr: 7.2426e-06  eta: 12:43:48  time: 0.4128  data_time: 0.0094  memory: 5976  grad_norm: 659.3306  loss: 20.9429  decode.loss_cls: 0.2050  decode.loss_mask: 1.0298  decode.loss_dice: 0.8339  decode.d0.loss_cls: 0.6771  decode.d0.loss_mask: 0.9844  decode.d0.loss_dice: 0.7835  decode.d1.loss_cls: 0.1994  decode.d1.loss_mask: 1.0184  decode.d1.loss_dice: 0.7889  decode.d2.loss_cls: 0.2389  decode.d2.loss_mask: 0.9858  decode.d2.loss_dice: 0.7804  decode.d3.loss_cls: 0.2256  decode.d3.loss_mask: 1.0104  decode.d3.loss_dice: 0.7786  decode.d4.loss_cls: 0.2071  decode.d4.loss_mask: 1.0330  decode.d4.loss_dice: 0.7910  decode.d5.loss_cls: 0.2378  decode.d5.loss_mask: 1.0174  decode.d5.loss_dice: 0.7990  decode.d6.loss_cls: 0.2268  decode.d6.loss_mask: 1.0603  decode.d6.loss_dice: 0.7967  decode.d7.loss_cls: 0.2409  decode.d7.loss_mask: 1.0692  decode.d7.loss_dice: 0.8150  decode.d8.loss_cls: 0.2546  decode.d8.loss_mask: 1.0344  decode.d8.loss_dice: 0.8194
05/26 16:35:01 - mmengine - INFO - Iter(train) [ 48250/160000]  base_lr: 7.2396e-05 lr: 7.2396e-06  eta: 12:43:28  time: 0.4115  data_time: 0.0093  memory: 5980  grad_norm: 805.8287  loss: 30.9565  decode.loss_cls: 0.3724  decode.loss_mask: 1.4932  decode.loss_dice: 1.1371  decode.d0.loss_cls: 0.9943  decode.d0.loss_mask: 1.4158  decode.d0.loss_dice: 1.0847  decode.d1.loss_cls: 0.4075  decode.d1.loss_mask: 1.5662  decode.d1.loss_dice: 1.1108  decode.d2.loss_cls: 0.3959  decode.d2.loss_mask: 1.5263  decode.d2.loss_dice: 1.1072  decode.d3.loss_cls: 0.3569  decode.d3.loss_mask: 1.5532  decode.d3.loss_dice: 1.1273  decode.d4.loss_cls: 0.4120  decode.d4.loss_mask: 1.5310  decode.d4.loss_dice: 1.1088  decode.d5.loss_cls: 0.4209  decode.d5.loss_mask: 1.5439  decode.d5.loss_dice: 1.1398  decode.d6.loss_cls: 0.3885  decode.d6.loss_mask: 1.5873  decode.d6.loss_dice: 1.1401  decode.d7.loss_cls: 0.3756  decode.d7.loss_mask: 1.5546  decode.d7.loss_dice: 1.1037  decode.d8.loss_cls: 0.4157  decode.d8.loss_mask: 1.5061  decode.d8.loss_dice: 1.0796
05/26 16:35:22 - mmengine - INFO - Iter(train) [ 48300/160000]  base_lr: 7.2367e-05 lr: 7.2367e-06  eta: 12:43:08  time: 0.4112  data_time: 0.0093  memory: 5976  grad_norm: 775.1229  loss: 27.7671  decode.loss_cls: 0.4097  decode.loss_mask: 1.3514  decode.loss_dice: 0.9590  decode.d0.loss_cls: 0.8819  decode.d0.loss_mask: 1.3541  decode.d0.loss_dice: 1.0050  decode.d1.loss_cls: 0.4168  decode.d1.loss_mask: 1.3162  decode.d1.loss_dice: 0.9559  decode.d2.loss_cls: 0.4116  decode.d2.loss_mask: 1.3476  decode.d2.loss_dice: 0.9782  decode.d3.loss_cls: 0.4893  decode.d3.loss_mask: 1.2896  decode.d3.loss_dice: 0.9316  decode.d4.loss_cls: 0.4252  decode.d4.loss_mask: 1.3700  decode.d4.loss_dice: 0.9801  decode.d5.loss_cls: 0.4476  decode.d5.loss_mask: 1.3334  decode.d5.loss_dice: 0.9391  decode.d6.loss_cls: 0.4229  decode.d6.loss_mask: 1.3347  decode.d6.loss_dice: 0.9592  decode.d7.loss_cls: 0.4273  decode.d7.loss_mask: 1.3487  decode.d7.loss_dice: 0.9512  decode.d8.loss_cls: 0.3891  decode.d8.loss_mask: 1.3666  decode.d8.loss_dice: 0.9740
05/26 16:35:42 - mmengine - INFO - Iter(train) [ 48350/160000]  base_lr: 7.2338e-05 lr: 7.2338e-06  eta: 12:42:47  time: 0.4122  data_time: 0.0093  memory: 5976  grad_norm: 809.2533  loss: 22.5862  decode.loss_cls: 0.2437  decode.loss_mask: 1.1290  decode.loss_dice: 0.8497  decode.d0.loss_cls: 0.6434  decode.d0.loss_mask: 1.1211  decode.d0.loss_dice: 0.8411  decode.d1.loss_cls: 0.2579  decode.d1.loss_mask: 1.1204  decode.d1.loss_dice: 0.8868  decode.d2.loss_cls: 0.2645  decode.d2.loss_mask: 1.1051  decode.d2.loss_dice: 0.8428  decode.d3.loss_cls: 0.2345  decode.d3.loss_mask: 1.1174  decode.d3.loss_dice: 0.8467  decode.d4.loss_cls: 0.2655  decode.d4.loss_mask: 1.1173  decode.d4.loss_dice: 0.8472  decode.d5.loss_cls: 0.2028  decode.d5.loss_mask: 1.1048  decode.d5.loss_dice: 0.8826  decode.d6.loss_cls: 0.2535  decode.d6.loss_mask: 1.1056  decode.d6.loss_dice: 0.8729  decode.d7.loss_cls: 0.2354  decode.d7.loss_mask: 1.1302  decode.d7.loss_dice: 0.8741  decode.d8.loss_cls: 0.2394  decode.d8.loss_mask: 1.1005  decode.d8.loss_dice: 0.8503
05/26 16:36:03 - mmengine - INFO - Iter(train) [ 48400/160000]  base_lr: 7.2309e-05 lr: 7.2309e-06  eta: 12:42:27  time: 0.4117  data_time: 0.0093  memory: 5973  grad_norm: 759.1151  loss: 21.1393  decode.loss_cls: 0.1906  decode.loss_mask: 1.1147  decode.loss_dice: 0.7859  decode.d0.loss_cls: 0.5758  decode.d0.loss_mask: 1.0686  decode.d0.loss_dice: 0.7686  decode.d1.loss_cls: 0.2083  decode.d1.loss_mask: 1.0406  decode.d1.loss_dice: 0.7834  decode.d2.loss_cls: 0.1991  decode.d2.loss_mask: 1.0645  decode.d2.loss_dice: 0.7858  decode.d3.loss_cls: 0.1983  decode.d3.loss_mask: 1.1072  decode.d3.loss_dice: 0.8075  decode.d4.loss_cls: 0.1970  decode.d4.loss_mask: 1.0864  decode.d4.loss_dice: 0.7869  decode.d5.loss_cls: 0.1925  decode.d5.loss_mask: 1.0995  decode.d5.loss_dice: 0.7908  decode.d6.loss_cls: 0.1717  decode.d6.loss_mask: 1.1099  decode.d6.loss_dice: 0.7874  decode.d7.loss_cls: 0.2066  decode.d7.loss_mask: 1.1074  decode.d7.loss_dice: 0.7970  decode.d8.loss_cls: 0.1824  decode.d8.loss_mask: 1.1293  decode.d8.loss_dice: 0.7956
05/26 16:36:23 - mmengine - INFO - Iter(train) [ 48450/160000]  base_lr: 7.2280e-05 lr: 7.2280e-06  eta: 12:42:07  time: 0.4110  data_time: 0.0094  memory: 5966  grad_norm: 1016.0862  loss: 22.2838  decode.loss_cls: 0.1724  decode.loss_mask: 1.1566  decode.loss_dice: 0.7772  decode.d0.loss_cls: 0.6742  decode.d0.loss_mask: 1.1188  decode.d0.loss_dice: 0.7865  decode.d1.loss_cls: 0.2323  decode.d1.loss_mask: 1.1608  decode.d1.loss_dice: 0.8209  decode.d2.loss_cls: 0.2642  decode.d2.loss_mask: 1.1546  decode.d2.loss_dice: 0.7952  decode.d3.loss_cls: 0.2593  decode.d3.loss_mask: 1.1638  decode.d3.loss_dice: 0.7980  decode.d4.loss_cls: 0.2229  decode.d4.loss_mask: 1.1688  decode.d4.loss_dice: 0.7935  decode.d5.loss_cls: 0.2518  decode.d5.loss_mask: 1.1397  decode.d5.loss_dice: 0.7917  decode.d6.loss_cls: 0.2285  decode.d6.loss_mask: 1.2173  decode.d6.loss_dice: 0.8033  decode.d7.loss_cls: 0.2155  decode.d7.loss_mask: 1.1748  decode.d7.loss_dice: 0.7729  decode.d8.loss_cls: 0.1875  decode.d8.loss_mask: 1.1983  decode.d8.loss_dice: 0.7827
05/26 16:36:44 - mmengine - INFO - Iter(train) [ 48500/160000]  base_lr: 7.2251e-05 lr: 7.2251e-06  eta: 12:41:47  time: 0.4123  data_time: 0.0094  memory: 5972  grad_norm: 926.5210  loss: 22.1528  decode.loss_cls: 0.2413  decode.loss_mask: 1.0494  decode.loss_dice: 0.8562  decode.d0.loss_cls: 0.6939  decode.d0.loss_mask: 1.0200  decode.d0.loss_dice: 0.8222  decode.d1.loss_cls: 0.2644  decode.d1.loss_mask: 1.0522  decode.d1.loss_dice: 0.8744  decode.d2.loss_cls: 0.2364  decode.d2.loss_mask: 1.0903  decode.d2.loss_dice: 0.8824  decode.d3.loss_cls: 0.2422  decode.d3.loss_mask: 1.0596  decode.d3.loss_dice: 0.8751  decode.d4.loss_cls: 0.2857  decode.d4.loss_mask: 1.0515  decode.d4.loss_dice: 0.8865  decode.d5.loss_cls: 0.2649  decode.d5.loss_mask: 1.0301  decode.d5.loss_dice: 0.8574  decode.d6.loss_cls: 0.2222  decode.d6.loss_mask: 1.1124  decode.d6.loss_dice: 0.8759  decode.d7.loss_cls: 0.2348  decode.d7.loss_mask: 1.0768  decode.d7.loss_dice: 0.8587  decode.d8.loss_cls: 0.2708  decode.d8.loss_mask: 1.0402  decode.d8.loss_dice: 0.8251
05/26 16:37:04 - mmengine - INFO - Iter(train) [ 48550/160000]  base_lr: 7.2222e-05 lr: 7.2222e-06  eta: 12:41:26  time: 0.4117  data_time: 0.0093  memory: 5971  grad_norm: 641.0785  loss: 22.0338  decode.loss_cls: 0.3180  decode.loss_mask: 1.0274  decode.loss_dice: 0.8393  decode.d0.loss_cls: 0.7849  decode.d0.loss_mask: 0.9564  decode.d0.loss_dice: 0.7746  decode.d1.loss_cls: 0.4033  decode.d1.loss_mask: 0.9786  decode.d1.loss_dice: 0.8237  decode.d2.loss_cls: 0.3178  decode.d2.loss_mask: 1.0168  decode.d2.loss_dice: 0.7940  decode.d3.loss_cls: 0.3476  decode.d3.loss_mask: 1.0070  decode.d3.loss_dice: 0.8002  decode.d4.loss_cls: 0.3446  decode.d4.loss_mask: 1.0229  decode.d4.loss_dice: 0.7911  decode.d5.loss_cls: 0.3456  decode.d5.loss_mask: 1.0156  decode.d5.loss_dice: 0.8152  decode.d6.loss_cls: 0.3536  decode.d6.loss_mask: 1.0104  decode.d6.loss_dice: 0.7993  decode.d7.loss_cls: 0.3724  decode.d7.loss_mask: 1.0142  decode.d7.loss_dice: 0.8250  decode.d8.loss_cls: 0.3435  decode.d8.loss_mask: 0.9954  decode.d8.loss_dice: 0.7953
05/26 16:37:25 - mmengine - INFO - Iter(train) [ 48600/160000]  base_lr: 7.2192e-05 lr: 7.2192e-06  eta: 12:41:06  time: 0.4117  data_time: 0.0093  memory: 5966  grad_norm: 747.6156  loss: 24.8366  decode.loss_cls: 0.3374  decode.loss_mask: 1.2665  decode.loss_dice: 0.8842  decode.d0.loss_cls: 0.7572  decode.d0.loss_mask: 1.2395  decode.d0.loss_dice: 0.8754  decode.d1.loss_cls: 0.2643  decode.d1.loss_mask: 1.2147  decode.d1.loss_dice: 0.9024  decode.d2.loss_cls: 0.3665  decode.d2.loss_mask: 1.2135  decode.d2.loss_dice: 0.8821  decode.d3.loss_cls: 0.2905  decode.d3.loss_mask: 1.2169  decode.d3.loss_dice: 0.9113  decode.d4.loss_cls: 0.3075  decode.d4.loss_mask: 1.2559  decode.d4.loss_dice: 0.9175  decode.d5.loss_cls: 0.3145  decode.d5.loss_mask: 1.2310  decode.d5.loss_dice: 0.9019  decode.d6.loss_cls: 0.3295  decode.d6.loss_mask: 1.2242  decode.d6.loss_dice: 0.9330  decode.d7.loss_cls: 0.3311  decode.d7.loss_mask: 1.1934  decode.d7.loss_dice: 0.8642  decode.d8.loss_cls: 0.3442  decode.d8.loss_mask: 1.2170  decode.d8.loss_dice: 0.8493
05/26 16:37:46 - mmengine - INFO - Iter(train) [ 48650/160000]  base_lr: 7.2163e-05 lr: 7.2163e-06  eta: 12:40:46  time: 0.4120  data_time: 0.0094  memory: 5966  grad_norm: 584.2409  loss: 24.7818  decode.loss_cls: 0.3443  decode.loss_mask: 1.1752  decode.loss_dice: 0.8910  decode.d0.loss_cls: 0.8419  decode.d0.loss_mask: 1.2233  decode.d0.loss_dice: 0.8308  decode.d1.loss_cls: 0.3348  decode.d1.loss_mask: 1.1909  decode.d1.loss_dice: 0.9040  decode.d2.loss_cls: 0.3204  decode.d2.loss_mask: 1.2190  decode.d2.loss_dice: 0.9155  decode.d3.loss_cls: 0.3691  decode.d3.loss_mask: 1.2130  decode.d3.loss_dice: 0.9013  decode.d4.loss_cls: 0.3375  decode.d4.loss_mask: 1.1765  decode.d4.loss_dice: 0.8874  decode.d5.loss_cls: 0.3159  decode.d5.loss_mask: 1.1954  decode.d5.loss_dice: 0.9023  decode.d6.loss_cls: 0.3101  decode.d6.loss_mask: 1.1927  decode.d6.loss_dice: 0.9040  decode.d7.loss_cls: 0.3008  decode.d7.loss_mask: 1.2492  decode.d7.loss_dice: 0.8968  decode.d8.loss_cls: 0.3352  decode.d8.loss_mask: 1.2099  decode.d8.loss_dice: 0.8937
05/26 16:38:06 - mmengine - INFO - Iter(train) [ 48700/160000]  base_lr: 7.2134e-05 lr: 7.2134e-06  eta: 12:40:26  time: 0.4120  data_time: 0.0093  memory: 5974  grad_norm: 863.0438  loss: 23.6149  decode.loss_cls: 0.3617  decode.loss_mask: 1.1117  decode.loss_dice: 0.8928  decode.d0.loss_cls: 0.8533  decode.d0.loss_mask: 1.0159  decode.d0.loss_dice: 0.8587  decode.d1.loss_cls: 0.3734  decode.d1.loss_mask: 1.0578  decode.d1.loss_dice: 0.9248  decode.d2.loss_cls: 0.3473  decode.d2.loss_mask: 1.0447  decode.d2.loss_dice: 0.9179  decode.d3.loss_cls: 0.3714  decode.d3.loss_mask: 1.0346  decode.d3.loss_dice: 0.8570  decode.d4.loss_cls: 0.3798  decode.d4.loss_mask: 1.0739  decode.d4.loss_dice: 0.8733  decode.d5.loss_cls: 0.3734  decode.d5.loss_mask: 1.0669  decode.d5.loss_dice: 0.8909  decode.d6.loss_cls: 0.3637  decode.d6.loss_mask: 1.0615  decode.d6.loss_dice: 0.8745  decode.d7.loss_cls: 0.4223  decode.d7.loss_mask: 1.0674  decode.d7.loss_dice: 0.8654  decode.d8.loss_cls: 0.4637  decode.d8.loss_mask: 0.9796  decode.d8.loss_dice: 0.8354
05/26 16:38:27 - mmengine - INFO - Iter(train) [ 48750/160000]  base_lr: 7.2105e-05 lr: 7.2105e-06  eta: 12:40:05  time: 0.4127  data_time: 0.0093  memory: 5968  grad_norm: 700.0532  loss: 24.7683  decode.loss_cls: 0.3235  decode.loss_mask: 1.1353  decode.loss_dice: 0.9684  decode.d0.loss_cls: 0.7699  decode.d0.loss_mask: 1.0667  decode.d0.loss_dice: 0.8875  decode.d1.loss_cls: 0.3544  decode.d1.loss_mask: 1.1185  decode.d1.loss_dice: 0.9601  decode.d2.loss_cls: 0.3377  decode.d2.loss_mask: 1.1453  decode.d2.loss_dice: 0.9749  decode.d3.loss_cls: 0.3352  decode.d3.loss_mask: 1.1538  decode.d3.loss_dice: 0.9367  decode.d4.loss_cls: 0.3738  decode.d4.loss_mask: 1.1245  decode.d4.loss_dice: 0.9384  decode.d5.loss_cls: 0.3481  decode.d5.loss_mask: 1.1262  decode.d5.loss_dice: 0.9465  decode.d6.loss_cls: 0.3376  decode.d6.loss_mask: 1.1629  decode.d6.loss_dice: 0.9636  decode.d7.loss_cls: 0.3710  decode.d7.loss_mask: 1.1634  decode.d7.loss_dice: 0.9585  decode.d8.loss_cls: 0.3609  decode.d8.loss_mask: 1.1658  decode.d8.loss_dice: 0.9594
05/26 16:38:48 - mmengine - INFO - Iter(train) [ 48800/160000]  base_lr: 7.2076e-05 lr: 7.2076e-06  eta: 12:39:45  time: 0.4127  data_time: 0.0094  memory: 5975  grad_norm: 1274.4015  loss: 29.2870  decode.loss_cls: 0.3886  decode.loss_mask: 1.3805  decode.loss_dice: 1.0827  decode.d0.loss_cls: 0.9003  decode.d0.loss_mask: 1.3306  decode.d0.loss_dice: 1.0348  decode.d1.loss_cls: 0.4517  decode.d1.loss_mask: 1.3778  decode.d1.loss_dice: 1.1051  decode.d2.loss_cls: 0.4436  decode.d2.loss_mask: 1.3735  decode.d2.loss_dice: 1.0877  decode.d3.loss_cls: 0.4190  decode.d3.loss_mask: 1.3884  decode.d3.loss_dice: 1.0898  decode.d4.loss_cls: 0.4514  decode.d4.loss_mask: 1.3348  decode.d4.loss_dice: 1.0603  decode.d5.loss_cls: 0.4188  decode.d5.loss_mask: 1.3917  decode.d5.loss_dice: 1.0688  decode.d6.loss_cls: 0.4162  decode.d6.loss_mask: 1.3768  decode.d6.loss_dice: 1.0716  decode.d7.loss_cls: 0.4081  decode.d7.loss_mask: 1.4083  decode.d7.loss_dice: 1.1202  decode.d8.loss_cls: 0.4506  decode.d8.loss_mask: 1.3453  decode.d8.loss_dice: 1.1101
05/26 16:39:08 - mmengine - INFO - Iter(train) [ 48850/160000]  base_lr: 7.2047e-05 lr: 7.2047e-06  eta: 12:39:25  time: 0.4116  data_time: 0.0093  memory: 5983  grad_norm: 498.5718  loss: 23.9591  decode.loss_cls: 0.3352  decode.loss_mask: 1.0743  decode.loss_dice: 0.8859  decode.d0.loss_cls: 0.6556  decode.d0.loss_mask: 1.0847  decode.d0.loss_dice: 0.9101  decode.d1.loss_cls: 0.3844  decode.d1.loss_mask: 1.1164  decode.d1.loss_dice: 0.9117  decode.d2.loss_cls: 0.3555  decode.d2.loss_mask: 1.1003  decode.d2.loss_dice: 0.9226  decode.d3.loss_cls: 0.3575  decode.d3.loss_mask: 1.1042  decode.d3.loss_dice: 0.9182  decode.d4.loss_cls: 0.3850  decode.d4.loss_mask: 1.0936  decode.d4.loss_dice: 0.8756  decode.d5.loss_cls: 0.3723  decode.d5.loss_mask: 1.0934  decode.d5.loss_dice: 0.9038  decode.d6.loss_cls: 0.3739  decode.d6.loss_mask: 1.0830  decode.d6.loss_dice: 0.9055  decode.d7.loss_cls: 0.3501  decode.d7.loss_mask: 1.1204  decode.d7.loss_dice: 0.9345  decode.d8.loss_cls: 0.3548  decode.d8.loss_mask: 1.0855  decode.d8.loss_dice: 0.9111
05/26 16:39:29 - mmengine - INFO - Iter(train) [ 48900/160000]  base_lr: 7.2017e-05 lr: 7.2017e-06  eta: 12:39:05  time: 0.4150  data_time: 0.0106  memory: 5969  grad_norm: 593.6505  loss: 19.8383  decode.loss_cls: 0.2782  decode.loss_mask: 0.8700  decode.loss_dice: 0.7955  decode.d0.loss_cls: 0.7005  decode.d0.loss_mask: 0.8267  decode.d0.loss_dice: 0.7463  decode.d1.loss_cls: 0.3656  decode.d1.loss_mask: 0.8414  decode.d1.loss_dice: 0.7737  decode.d2.loss_cls: 0.2612  decode.d2.loss_mask: 0.8689  decode.d2.loss_dice: 0.7591  decode.d3.loss_cls: 0.2790  decode.d3.loss_mask: 0.8527  decode.d3.loss_dice: 0.8115  decode.d4.loss_cls: 0.3758  decode.d4.loss_mask: 0.8525  decode.d4.loss_dice: 0.7990  decode.d5.loss_cls: 0.3185  decode.d5.loss_mask: 0.8203  decode.d5.loss_dice: 0.8152  decode.d6.loss_cls: 0.3265  decode.d6.loss_mask: 0.8619  decode.d6.loss_dice: 0.7684  decode.d7.loss_cls: 0.3226  decode.d7.loss_mask: 0.8377  decode.d7.loss_dice: 0.7972  decode.d8.loss_cls: 0.2343  decode.d8.loss_mask: 0.8647  decode.d8.loss_dice: 0.8132
05/26 16:39:49 - mmengine - INFO - Iter(train) [ 48950/160000]  base_lr: 7.1988e-05 lr: 7.1988e-06  eta: 12:38:44  time: 0.4120  data_time: 0.0093  memory: 5965  grad_norm: 468.5564  loss: 19.2945  decode.loss_cls: 0.1421  decode.loss_mask: 1.0953  decode.loss_dice: 0.6433  decode.d0.loss_cls: 0.6698  decode.d0.loss_mask: 0.9730  decode.d0.loss_dice: 0.6238  decode.d1.loss_cls: 0.1494  decode.d1.loss_mask: 1.0985  decode.d1.loss_dice: 0.6549  decode.d2.loss_cls: 0.1549  decode.d2.loss_mask: 1.0917  decode.d2.loss_dice: 0.6276  decode.d3.loss_cls: 0.1801  decode.d3.loss_mask: 1.0880  decode.d3.loss_dice: 0.6351  decode.d4.loss_cls: 0.1925  decode.d4.loss_mask: 1.0885  decode.d4.loss_dice: 0.6407  decode.d5.loss_cls: 0.1552  decode.d5.loss_mask: 1.1168  decode.d5.loss_dice: 0.6442  decode.d6.loss_cls: 0.1663  decode.d6.loss_mask: 1.0752  decode.d6.loss_dice: 0.6365  decode.d7.loss_cls: 0.1523  decode.d7.loss_mask: 1.1007  decode.d7.loss_dice: 0.6447  decode.d8.loss_cls: 0.1809  decode.d8.loss_mask: 1.0505  decode.d8.loss_dice: 0.6218
05/26 16:40:10 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 16:40:10 - mmengine - INFO - Iter(train) [ 49000/160000]  base_lr: 7.1959e-05 lr: 7.1959e-06  eta: 12:38:24  time: 0.4116  data_time: 0.0093  memory: 5975  grad_norm: 537.2048  loss: 21.0118  decode.loss_cls: 0.2600  decode.loss_mask: 1.0172  decode.loss_dice: 0.7548  decode.d0.loss_cls: 0.6996  decode.d0.loss_mask: 0.9975  decode.d0.loss_dice: 0.7767  decode.d1.loss_cls: 0.2495  decode.d1.loss_mask: 1.0474  decode.d1.loss_dice: 0.7631  decode.d2.loss_cls: 0.2520  decode.d2.loss_mask: 1.0611  decode.d2.loss_dice: 0.8060  decode.d3.loss_cls: 0.2559  decode.d3.loss_mask: 1.0166  decode.d3.loss_dice: 0.7949  decode.d4.loss_cls: 0.2612  decode.d4.loss_mask: 0.9876  decode.d4.loss_dice: 0.7854  decode.d5.loss_cls: 0.2631  decode.d5.loss_mask: 1.0238  decode.d5.loss_dice: 0.7699  decode.d6.loss_cls: 0.2846  decode.d6.loss_mask: 1.0246  decode.d6.loss_dice: 0.7665  decode.d7.loss_cls: 0.2671  decode.d7.loss_mask: 1.0074  decode.d7.loss_dice: 0.7787  decode.d8.loss_cls: 0.2507  decode.d8.loss_mask: 1.0227  decode.d8.loss_dice: 0.7663
05/26 16:40:31 - mmengine - INFO - Iter(train) [ 49050/160000]  base_lr: 7.1930e-05 lr: 7.1930e-06  eta: 12:38:04  time: 0.4120  data_time: 0.0093  memory: 5966  grad_norm: 805.4289  loss: 22.9993  decode.loss_cls: 0.1939  decode.loss_mask: 1.2190  decode.loss_dice: 0.8627  decode.d0.loss_cls: 0.6949  decode.d0.loss_mask: 1.1241  decode.d0.loss_dice: 0.8232  decode.d1.loss_cls: 0.1714  decode.d1.loss_mask: 1.2180  decode.d1.loss_dice: 0.8634  decode.d2.loss_cls: 0.1680  decode.d2.loss_mask: 1.2216  decode.d2.loss_dice: 0.8401  decode.d3.loss_cls: 0.1970  decode.d3.loss_mask: 1.1987  decode.d3.loss_dice: 0.8479  decode.d4.loss_cls: 0.1984  decode.d4.loss_mask: 1.2245  decode.d4.loss_dice: 0.8453  decode.d5.loss_cls: 0.1808  decode.d5.loss_mask: 1.2254  decode.d5.loss_dice: 0.8427  decode.d6.loss_cls: 0.1776  decode.d6.loss_mask: 1.2306  decode.d6.loss_dice: 0.8358  decode.d7.loss_cls: 0.1452  decode.d7.loss_mask: 1.2692  decode.d7.loss_dice: 0.8949  decode.d8.loss_cls: 0.1924  decode.d8.loss_mask: 1.2360  decode.d8.loss_dice: 0.8568
05/26 16:40:51 - mmengine - INFO - Iter(train) [ 49100/160000]  base_lr: 7.1901e-05 lr: 7.1901e-06  eta: 12:37:44  time: 0.4112  data_time: 0.0093  memory: 5968  grad_norm: 921.3159  loss: 21.8521  decode.loss_cls: 0.2182  decode.loss_mask: 1.0944  decode.loss_dice: 0.7712  decode.d0.loss_cls: 0.7530  decode.d0.loss_mask: 0.9918  decode.d0.loss_dice: 0.7552  decode.d1.loss_cls: 0.3030  decode.d1.loss_mask: 1.0553  decode.d1.loss_dice: 0.7798  decode.d2.loss_cls: 0.3111  decode.d2.loss_mask: 1.0693  decode.d2.loss_dice: 0.7930  decode.d3.loss_cls: 0.3318  decode.d3.loss_mask: 1.0523  decode.d3.loss_dice: 0.8046  decode.d4.loss_cls: 0.3026  decode.d4.loss_mask: 1.0576  decode.d4.loss_dice: 0.7774  decode.d5.loss_cls: 0.2933  decode.d5.loss_mask: 1.0821  decode.d5.loss_dice: 0.7897  decode.d6.loss_cls: 0.3159  decode.d6.loss_mask: 1.0952  decode.d6.loss_dice: 0.8331  decode.d7.loss_cls: 0.3263  decode.d7.loss_mask: 1.0376  decode.d7.loss_dice: 0.7637  decode.d8.loss_cls: 0.2319  decode.d8.loss_mask: 1.0936  decode.d8.loss_dice: 0.7681
05/26 16:41:12 - mmengine - INFO - Iter(train) [ 49150/160000]  base_lr: 7.1871e-05 lr: 7.1871e-06  eta: 12:37:23  time: 0.4115  data_time: 0.0093  memory: 5980  grad_norm: 768.9561  loss: 26.3461  decode.loss_cls: 0.2212  decode.loss_mask: 1.3033  decode.loss_dice: 1.0019  decode.d0.loss_cls: 0.8044  decode.d0.loss_mask: 1.2543  decode.d0.loss_dice: 0.9835  decode.d1.loss_cls: 0.3104  decode.d1.loss_mask: 1.2915  decode.d1.loss_dice: 1.0187  decode.d2.loss_cls: 0.2203  decode.d2.loss_mask: 1.3049  decode.d2.loss_dice: 1.0036  decode.d3.loss_cls: 0.2509  decode.d3.loss_mask: 1.2834  decode.d3.loss_dice: 0.9928  decode.d4.loss_cls: 0.3206  decode.d4.loss_mask: 1.2675  decode.d4.loss_dice: 1.0076  decode.d5.loss_cls: 0.2933  decode.d5.loss_mask: 1.3319  decode.d5.loss_dice: 1.0326  decode.d6.loss_cls: 0.2531  decode.d6.loss_mask: 1.3156  decode.d6.loss_dice: 1.0822  decode.d7.loss_cls: 0.2746  decode.d7.loss_mask: 1.3290  decode.d7.loss_dice: 1.0375  decode.d8.loss_cls: 0.2634  decode.d8.loss_mask: 1.2969  decode.d8.loss_dice: 0.9949
05/26 16:41:32 - mmengine - INFO - Iter(train) [ 49200/160000]  base_lr: 7.1842e-05 lr: 7.1842e-06  eta: 12:37:03  time: 0.4130  data_time: 0.0094  memory: 5976  grad_norm: 719.7937  loss: 26.7148  decode.loss_cls: 0.3297  decode.loss_mask: 1.2489  decode.loss_dice: 1.0149  decode.d0.loss_cls: 0.9360  decode.d0.loss_mask: 1.1777  decode.d0.loss_dice: 1.0504  decode.d1.loss_cls: 0.3518  decode.d1.loss_mask: 1.2795  decode.d1.loss_dice: 1.0002  decode.d2.loss_cls: 0.3075  decode.d2.loss_mask: 1.3152  decode.d2.loss_dice: 1.0334  decode.d3.loss_cls: 0.3520  decode.d3.loss_mask: 1.2316  decode.d3.loss_dice: 1.0245  decode.d4.loss_cls: 0.3652  decode.d4.loss_mask: 1.2294  decode.d4.loss_dice: 0.9961  decode.d5.loss_cls: 0.3609  decode.d5.loss_mask: 1.2810  decode.d5.loss_dice: 1.0359  decode.d6.loss_cls: 0.3041  decode.d6.loss_mask: 1.2540  decode.d6.loss_dice: 1.0379  decode.d7.loss_cls: 0.2889  decode.d7.loss_mask: 1.2816  decode.d7.loss_dice: 1.0432  decode.d8.loss_cls: 0.2774  decode.d8.loss_mask: 1.2758  decode.d8.loss_dice: 1.0302
05/26 16:41:53 - mmengine - INFO - Iter(train) [ 49250/160000]  base_lr: 7.1813e-05 lr: 7.1813e-06  eta: 12:36:43  time: 0.4102  data_time: 0.0093  memory: 5968  grad_norm: 619.4076  loss: 23.7220  decode.loss_cls: 0.1857  decode.loss_mask: 1.2406  decode.loss_dice: 0.8931  decode.d0.loss_cls: 0.6574  decode.d0.loss_mask: 1.1707  decode.d0.loss_dice: 0.8227  decode.d1.loss_cls: 0.2092  decode.d1.loss_mask: 1.2337  decode.d1.loss_dice: 0.8734  decode.d2.loss_cls: 0.2395  decode.d2.loss_mask: 1.2501  decode.d2.loss_dice: 0.8826  decode.d3.loss_cls: 0.1930  decode.d3.loss_mask: 1.2184  decode.d3.loss_dice: 0.8760  decode.d4.loss_cls: 0.2518  decode.d4.loss_mask: 1.2399  decode.d4.loss_dice: 0.8981  decode.d5.loss_cls: 0.2004  decode.d5.loss_mask: 1.2239  decode.d5.loss_dice: 0.8988  decode.d6.loss_cls: 0.2089  decode.d6.loss_mask: 1.2402  decode.d6.loss_dice: 0.9006  decode.d7.loss_cls: 0.1715  decode.d7.loss_mask: 1.2748  decode.d7.loss_dice: 0.9054  decode.d8.loss_cls: 0.2009  decode.d8.loss_mask: 1.2584  decode.d8.loss_dice: 0.9022
05/26 16:42:14 - mmengine - INFO - Iter(train) [ 49300/160000]  base_lr: 7.1784e-05 lr: 7.1784e-06  eta: 12:36:22  time: 0.4110  data_time: 0.0093  memory: 5981  grad_norm: 466.3499  loss: 22.7178  decode.loss_cls: 0.1920  decode.loss_mask: 1.2637  decode.loss_dice: 0.8560  decode.d0.loss_cls: 0.7575  decode.d0.loss_mask: 1.0968  decode.d0.loss_dice: 0.7832  decode.d1.loss_cls: 0.2219  decode.d1.loss_mask: 1.1471  decode.d1.loss_dice: 0.8301  decode.d2.loss_cls: 0.2534  decode.d2.loss_mask: 1.1433  decode.d2.loss_dice: 0.8220  decode.d3.loss_cls: 0.2323  decode.d3.loss_mask: 1.1693  decode.d3.loss_dice: 0.8265  decode.d4.loss_cls: 0.3202  decode.d4.loss_mask: 1.1083  decode.d4.loss_dice: 0.7917  decode.d5.loss_cls: 0.2825  decode.d5.loss_mask: 1.1524  decode.d5.loss_dice: 0.8192  decode.d6.loss_cls: 0.3075  decode.d6.loss_mask: 1.1461  decode.d6.loss_dice: 0.8014  decode.d7.loss_cls: 0.2494  decode.d7.loss_mask: 1.1426  decode.d7.loss_dice: 0.8224  decode.d8.loss_cls: 0.1871  decode.d8.loss_mask: 1.1677  decode.d8.loss_dice: 0.8243
05/26 16:42:34 - mmengine - INFO - Iter(train) [ 49350/160000]  base_lr: 7.1755e-05 lr: 7.1755e-06  eta: 12:36:02  time: 0.4125  data_time: 0.0094  memory: 5974  grad_norm: 336.6460  loss: 18.9482  decode.loss_cls: 0.1628  decode.loss_mask: 0.9327  decode.loss_dice: 0.7328  decode.d0.loss_cls: 0.6196  decode.d0.loss_mask: 0.9178  decode.d0.loss_dice: 0.7436  decode.d1.loss_cls: 0.1586  decode.d1.loss_mask: 0.9476  decode.d1.loss_dice: 0.7442  decode.d2.loss_cls: 0.1766  decode.d2.loss_mask: 0.9705  decode.d2.loss_dice: 0.7367  decode.d3.loss_cls: 0.1810  decode.d3.loss_mask: 0.9492  decode.d3.loss_dice: 0.7213  decode.d4.loss_cls: 0.2191  decode.d4.loss_mask: 0.9187  decode.d4.loss_dice: 0.7052  decode.d5.loss_cls: 0.1700  decode.d5.loss_mask: 0.9394  decode.d5.loss_dice: 0.7384  decode.d6.loss_cls: 0.2330  decode.d6.loss_mask: 0.9363  decode.d6.loss_dice: 0.7286  decode.d7.loss_cls: 0.1760  decode.d7.loss_mask: 0.9360  decode.d7.loss_dice: 0.7293  decode.d8.loss_cls: 0.1853  decode.d8.loss_mask: 0.9204  decode.d8.loss_dice: 0.7173
05/26 16:42:55 - mmengine - INFO - Iter(train) [ 49400/160000]  base_lr: 7.1726e-05 lr: 7.1726e-06  eta: 12:35:42  time: 0.4111  data_time: 0.0094  memory: 5968  grad_norm: 518.2233  loss: 23.9091  decode.loss_cls: 0.3107  decode.loss_mask: 1.1479  decode.loss_dice: 0.8808  decode.d0.loss_cls: 0.7305  decode.d0.loss_mask: 1.0885  decode.d0.loss_dice: 0.8715  decode.d1.loss_cls: 0.2826  decode.d1.loss_mask: 1.1601  decode.d1.loss_dice: 0.8898  decode.d2.loss_cls: 0.3080  decode.d2.loss_mask: 1.1558  decode.d2.loss_dice: 0.8736  decode.d3.loss_cls: 0.3151  decode.d3.loss_mask: 1.1596  decode.d3.loss_dice: 0.8875  decode.d4.loss_cls: 0.3964  decode.d4.loss_mask: 1.1522  decode.d4.loss_dice: 0.8389  decode.d5.loss_cls: 0.3424  decode.d5.loss_mask: 1.1432  decode.d5.loss_dice: 0.8681  decode.d6.loss_cls: 0.3489  decode.d6.loss_mask: 1.1669  decode.d6.loss_dice: 0.8815  decode.d7.loss_cls: 0.3130  decode.d7.loss_mask: 1.1921  decode.d7.loss_dice: 0.8745  decode.d8.loss_cls: 0.3172  decode.d8.loss_mask: 1.1441  decode.d8.loss_dice: 0.8676
05/26 16:43:15 - mmengine - INFO - Iter(train) [ 49450/160000]  base_lr: 7.1696e-05 lr: 7.1696e-06  eta: 12:35:21  time: 0.4109  data_time: 0.0093  memory: 5967  grad_norm: 824.4291  loss: 20.1821  decode.loss_cls: 0.1865  decode.loss_mask: 1.0302  decode.loss_dice: 0.7509  decode.d0.loss_cls: 0.6615  decode.d0.loss_mask: 0.9711  decode.d0.loss_dice: 0.7396  decode.d1.loss_cls: 0.2036  decode.d1.loss_mask: 1.0432  decode.d1.loss_dice: 0.7662  decode.d2.loss_cls: 0.2378  decode.d2.loss_mask: 1.0107  decode.d2.loss_dice: 0.7107  decode.d3.loss_cls: 0.1997  decode.d3.loss_mask: 1.0463  decode.d3.loss_dice: 0.7434  decode.d4.loss_cls: 0.1770  decode.d4.loss_mask: 1.0138  decode.d4.loss_dice: 0.8025  decode.d5.loss_cls: 0.1794  decode.d5.loss_mask: 1.0273  decode.d5.loss_dice: 0.7633  decode.d6.loss_cls: 0.2032  decode.d6.loss_mask: 1.0331  decode.d6.loss_dice: 0.7710  decode.d7.loss_cls: 0.2516  decode.d7.loss_mask: 0.9543  decode.d7.loss_dice: 0.7089  decode.d8.loss_cls: 0.1740  decode.d8.loss_mask: 1.0276  decode.d8.loss_dice: 0.7935
05/26 16:43:36 - mmengine - INFO - Iter(train) [ 49500/160000]  base_lr: 7.1667e-05 lr: 7.1667e-06  eta: 12:35:01  time: 0.4120  data_time: 0.0094  memory: 5971  grad_norm: 445.4488  loss: 20.1758  decode.loss_cls: 0.1853  decode.loss_mask: 1.0735  decode.loss_dice: 0.7505  decode.d0.loss_cls: 0.6974  decode.d0.loss_mask: 0.9488  decode.d0.loss_dice: 0.7110  decode.d1.loss_cls: 0.2099  decode.d1.loss_mask: 1.0101  decode.d1.loss_dice: 0.7382  decode.d2.loss_cls: 0.2173  decode.d2.loss_mask: 0.9953  decode.d2.loss_dice: 0.7253  decode.d3.loss_cls: 0.2151  decode.d3.loss_mask: 0.9936  decode.d3.loss_dice: 0.7250  decode.d4.loss_cls: 0.2768  decode.d4.loss_mask: 0.9851  decode.d4.loss_dice: 0.7250  decode.d5.loss_cls: 0.2750  decode.d5.loss_mask: 0.9959  decode.d5.loss_dice: 0.7357  decode.d6.loss_cls: 0.2395  decode.d6.loss_mask: 0.9903  decode.d6.loss_dice: 0.7376  decode.d7.loss_cls: 0.2736  decode.d7.loss_mask: 0.9918  decode.d7.loss_dice: 0.7265  decode.d8.loss_cls: 0.2354  decode.d8.loss_mask: 1.0469  decode.d8.loss_dice: 0.7443
05/26 16:43:57 - mmengine - INFO - Iter(train) [ 49550/160000]  base_lr: 7.1638e-05 lr: 7.1638e-06  eta: 12:34:41  time: 0.4113  data_time: 0.0093  memory: 5975  grad_norm: 780.1547  loss: 28.1673  decode.loss_cls: 0.3376  decode.loss_mask: 1.3434  decode.loss_dice: 1.0778  decode.d0.loss_cls: 0.8865  decode.d0.loss_mask: 1.3263  decode.d0.loss_dice: 1.0105  decode.d1.loss_cls: 0.4092  decode.d1.loss_mask: 1.3346  decode.d1.loss_dice: 1.0564  decode.d2.loss_cls: 0.3282  decode.d2.loss_mask: 1.3884  decode.d2.loss_dice: 1.0643  decode.d3.loss_cls: 0.3296  decode.d3.loss_mask: 1.3905  decode.d3.loss_dice: 1.1051  decode.d4.loss_cls: 0.3444  decode.d4.loss_mask: 1.3510  decode.d4.loss_dice: 1.0861  decode.d5.loss_cls: 0.3591  decode.d5.loss_mask: 1.3790  decode.d5.loss_dice: 1.1339  decode.d6.loss_cls: 0.3546  decode.d6.loss_mask: 1.3063  decode.d6.loss_dice: 1.0411  decode.d7.loss_cls: 0.3417  decode.d7.loss_mask: 1.3029  decode.d7.loss_dice: 1.0636  decode.d8.loss_cls: 0.3580  decode.d8.loss_mask: 1.3329  decode.d8.loss_dice: 1.0244
05/26 16:44:17 - mmengine - INFO - Iter(train) [ 49600/160000]  base_lr: 7.1609e-05 lr: 7.1609e-06  eta: 12:34:21  time: 0.4131  data_time: 0.0094  memory: 5972  grad_norm: 742.8085  loss: 27.0499  decode.loss_cls: 0.3952  decode.loss_mask: 1.2330  decode.loss_dice: 1.0262  decode.d0.loss_cls: 0.9320  decode.d0.loss_mask: 1.1689  decode.d0.loss_dice: 0.9378  decode.d1.loss_cls: 0.5129  decode.d1.loss_mask: 1.1712  decode.d1.loss_dice: 0.9461  decode.d2.loss_cls: 0.4705  decode.d2.loss_mask: 1.2515  decode.d2.loss_dice: 0.9640  decode.d3.loss_cls: 0.3786  decode.d3.loss_mask: 1.2824  decode.d3.loss_dice: 1.0204  decode.d4.loss_cls: 0.4231  decode.d4.loss_mask: 1.3083  decode.d4.loss_dice: 0.9637  decode.d5.loss_cls: 0.4363  decode.d5.loss_mask: 1.2439  decode.d5.loss_dice: 0.9503  decode.d6.loss_cls: 0.4080  decode.d6.loss_mask: 1.2158  decode.d6.loss_dice: 0.9922  decode.d7.loss_cls: 0.4411  decode.d7.loss_mask: 1.2464  decode.d7.loss_dice: 1.0053  decode.d8.loss_cls: 0.4911  decode.d8.loss_mask: 1.2555  decode.d8.loss_dice: 0.9783
05/26 16:44:38 - mmengine - INFO - Iter(train) [ 49650/160000]  base_lr: 7.1580e-05 lr: 7.1580e-06  eta: 12:34:00  time: 0.4127  data_time: 0.0093  memory: 5966  grad_norm: 403.8229  loss: 21.7724  decode.loss_cls: 0.1539  decode.loss_mask: 1.1224  decode.loss_dice: 0.8312  decode.d0.loss_cls: 0.7062  decode.d0.loss_mask: 1.0158  decode.d0.loss_dice: 0.8055  decode.d1.loss_cls: 0.2154  decode.d1.loss_mask: 1.1137  decode.d1.loss_dice: 0.8162  decode.d2.loss_cls: 0.1798  decode.d2.loss_mask: 1.1124  decode.d2.loss_dice: 0.8138  decode.d3.loss_cls: 0.1504  decode.d3.loss_mask: 1.1457  decode.d3.loss_dice: 0.8675  decode.d4.loss_cls: 0.2119  decode.d4.loss_mask: 1.1281  decode.d4.loss_dice: 0.8593  decode.d5.loss_cls: 0.1639  decode.d5.loss_mask: 1.1347  decode.d5.loss_dice: 0.8385  decode.d6.loss_cls: 0.1831  decode.d6.loss_mask: 1.1036  decode.d6.loss_dice: 0.8215  decode.d7.loss_cls: 0.2015  decode.d7.loss_mask: 1.1327  decode.d7.loss_dice: 0.8267  decode.d8.loss_cls: 0.1439  decode.d8.loss_mask: 1.1312  decode.d8.loss_dice: 0.8414
05/26 16:44:58 - mmengine - INFO - Iter(train) [ 49700/160000]  base_lr: 7.1550e-05 lr: 7.1550e-06  eta: 12:33:40  time: 0.4116  data_time: 0.0094  memory: 5970  grad_norm: 469.7703  loss: 20.9214  decode.loss_cls: 0.1790  decode.loss_mask: 1.0901  decode.loss_dice: 0.7277  decode.d0.loss_cls: 0.6388  decode.d0.loss_mask: 1.0722  decode.d0.loss_dice: 0.7393  decode.d1.loss_cls: 0.1686  decode.d1.loss_mask: 1.1246  decode.d1.loss_dice: 0.7421  decode.d2.loss_cls: 0.2055  decode.d2.loss_mask: 1.1179  decode.d2.loss_dice: 0.7465  decode.d3.loss_cls: 0.2086  decode.d3.loss_mask: 1.1188  decode.d3.loss_dice: 0.7633  decode.d4.loss_cls: 0.1864  decode.d4.loss_mask: 1.1224  decode.d4.loss_dice: 0.7618  decode.d5.loss_cls: 0.2022  decode.d5.loss_mask: 1.1180  decode.d5.loss_dice: 0.7494  decode.d6.loss_cls: 0.1504  decode.d6.loss_mask: 1.1579  decode.d6.loss_dice: 0.7724  decode.d7.loss_cls: 0.1595  decode.d7.loss_mask: 1.1220  decode.d7.loss_dice: 0.7506  decode.d8.loss_cls: 0.1636  decode.d8.loss_mask: 1.1240  decode.d8.loss_dice: 0.7378
05/26 16:45:19 - mmengine - INFO - Iter(train) [ 49750/160000]  base_lr: 7.1521e-05 lr: 7.1521e-06  eta: 12:33:20  time: 0.4119  data_time: 0.0094  memory: 5968  grad_norm: 512.7560  loss: 23.6392  decode.loss_cls: 0.2836  decode.loss_mask: 1.1923  decode.loss_dice: 0.7766  decode.d0.loss_cls: 0.8429  decode.d0.loss_mask: 1.0970  decode.d0.loss_dice: 0.7890  decode.d1.loss_cls: 0.3515  decode.d1.loss_mask: 1.1357  decode.d1.loss_dice: 0.7588  decode.d2.loss_cls: 0.3435  decode.d2.loss_mask: 1.2274  decode.d2.loss_dice: 0.7928  decode.d3.loss_cls: 0.3339  decode.d3.loss_mask: 1.1854  decode.d3.loss_dice: 0.7690  decode.d4.loss_cls: 0.3701  decode.d4.loss_mask: 1.2242  decode.d4.loss_dice: 0.8242  decode.d5.loss_cls: 0.4193  decode.d5.loss_mask: 1.2071  decode.d5.loss_dice: 0.7787  decode.d6.loss_cls: 0.3457  decode.d6.loss_mask: 1.2049  decode.d6.loss_dice: 0.7711  decode.d7.loss_cls: 0.3359  decode.d7.loss_mask: 1.1579  decode.d7.loss_dice: 0.8083  decode.d8.loss_cls: 0.3144  decode.d8.loss_mask: 1.2159  decode.d8.loss_dice: 0.7821
05/26 16:45:40 - mmengine - INFO - Iter(train) [ 49800/160000]  base_lr: 7.1492e-05 lr: 7.1492e-06  eta: 12:32:59  time: 0.4127  data_time: 0.0095  memory: 5984  grad_norm: 962.8906  loss: 21.9937  decode.loss_cls: 0.3289  decode.loss_mask: 1.0608  decode.loss_dice: 0.7979  decode.d0.loss_cls: 0.6814  decode.d0.loss_mask: 1.0425  decode.d0.loss_dice: 0.7597  decode.d1.loss_cls: 0.3463  decode.d1.loss_mask: 1.0657  decode.d1.loss_dice: 0.7851  decode.d2.loss_cls: 0.3587  decode.d2.loss_mask: 1.0366  decode.d2.loss_dice: 0.7823  decode.d3.loss_cls: 0.3301  decode.d3.loss_mask: 1.0477  decode.d3.loss_dice: 0.7642  decode.d4.loss_cls: 0.3726  decode.d4.loss_mask: 1.0267  decode.d4.loss_dice: 0.7536  decode.d5.loss_cls: 0.3324  decode.d5.loss_mask: 1.0147  decode.d5.loss_dice: 0.7838  decode.d6.loss_cls: 0.3967  decode.d6.loss_mask: 1.0145  decode.d6.loss_dice: 0.7396  decode.d7.loss_cls: 0.3038  decode.d7.loss_mask: 1.0950  decode.d7.loss_dice: 0.7919  decode.d8.loss_cls: 0.3420  decode.d8.loss_mask: 1.0537  decode.d8.loss_dice: 0.7848
05/26 16:46:00 - mmengine - INFO - Iter(train) [ 49850/160000]  base_lr: 7.1463e-05 lr: 7.1463e-06  eta: 12:32:39  time: 0.4115  data_time: 0.0093  memory: 5966  grad_norm: 599.8172  loss: 22.2007  decode.loss_cls: 0.1763  decode.loss_mask: 1.1467  decode.loss_dice: 0.8481  decode.d0.loss_cls: 0.7044  decode.d0.loss_mask: 1.0631  decode.d0.loss_dice: 0.7977  decode.d1.loss_cls: 0.1876  decode.d1.loss_mask: 1.1307  decode.d1.loss_dice: 0.8273  decode.d2.loss_cls: 0.2404  decode.d2.loss_mask: 1.1239  decode.d2.loss_dice: 0.8122  decode.d3.loss_cls: 0.1951  decode.d3.loss_mask: 1.1422  decode.d3.loss_dice: 0.8362  decode.d4.loss_cls: 0.2352  decode.d4.loss_mask: 1.1635  decode.d4.loss_dice: 0.8484  decode.d5.loss_cls: 0.2414  decode.d5.loss_mask: 1.1621  decode.d5.loss_dice: 0.8336  decode.d6.loss_cls: 0.2232  decode.d6.loss_mask: 1.1305  decode.d6.loss_dice: 0.8279  decode.d7.loss_cls: 0.2242  decode.d7.loss_mask: 1.1259  decode.d7.loss_dice: 0.7926  decode.d8.loss_cls: 0.1819  decode.d8.loss_mask: 1.1488  decode.d8.loss_dice: 0.8296
05/26 16:46:21 - mmengine - INFO - Iter(train) [ 49900/160000]  base_lr: 7.1434e-05 lr: 7.1434e-06  eta: 12:32:19  time: 0.4109  data_time: 0.0094  memory: 5967  grad_norm: 1289.4136  loss: 23.8057  decode.loss_cls: 0.1960  decode.loss_mask: 1.2687  decode.loss_dice: 0.8672  decode.d0.loss_cls: 0.7380  decode.d0.loss_mask: 1.2066  decode.d0.loss_dice: 0.8407  decode.d1.loss_cls: 0.2210  decode.d1.loss_mask: 1.2461  decode.d1.loss_dice: 0.8680  decode.d2.loss_cls: 0.1721  decode.d2.loss_mask: 1.2641  decode.d2.loss_dice: 0.8423  decode.d3.loss_cls: 0.1991  decode.d3.loss_mask: 1.2784  decode.d3.loss_dice: 0.8531  decode.d4.loss_cls: 0.2156  decode.d4.loss_mask: 1.2612  decode.d4.loss_dice: 0.8480  decode.d5.loss_cls: 0.2056  decode.d5.loss_mask: 1.2828  decode.d5.loss_dice: 0.8749  decode.d6.loss_cls: 0.1573  decode.d6.loss_mask: 1.2869  decode.d6.loss_dice: 0.9112  decode.d7.loss_cls: 0.2176  decode.d7.loss_mask: 1.2322  decode.d7.loss_dice: 0.8835  decode.d8.loss_cls: 0.2128  decode.d8.loss_mask: 1.2672  decode.d8.loss_dice: 0.8879
05/26 16:46:41 - mmengine - INFO - Iter(train) [ 49950/160000]  base_lr: 7.1404e-05 lr: 7.1404e-06  eta: 12:31:59  time: 0.4110  data_time: 0.0093  memory: 5973  grad_norm: 1313.7124  loss: 22.9366  decode.loss_cls: 0.2058  decode.loss_mask: 1.2141  decode.loss_dice: 0.7777  decode.d0.loss_cls: 0.6393  decode.d0.loss_mask: 1.2455  decode.d0.loss_dice: 0.7565  decode.d1.loss_cls: 0.2206  decode.d1.loss_mask: 1.2392  decode.d1.loss_dice: 0.8138  decode.d2.loss_cls: 0.2278  decode.d2.loss_mask: 1.2643  decode.d2.loss_dice: 0.7937  decode.d3.loss_cls: 0.2411  decode.d3.loss_mask: 1.2584  decode.d3.loss_dice: 0.7962  decode.d4.loss_cls: 0.2293  decode.d4.loss_mask: 1.2687  decode.d4.loss_dice: 0.7795  decode.d5.loss_cls: 0.2123  decode.d5.loss_mask: 1.2589  decode.d5.loss_dice: 0.7868  decode.d6.loss_cls: 0.2224  decode.d6.loss_mask: 1.2456  decode.d6.loss_dice: 0.8007  decode.d7.loss_cls: 0.2117  decode.d7.loss_mask: 1.2296  decode.d7.loss_dice: 0.7893  decode.d8.loss_cls: 0.2073  decode.d8.loss_mask: 1.2183  decode.d8.loss_dice: 0.7822
05/26 16:47:02 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 16:47:02 - mmengine - INFO - Iter(train) [ 50000/160000]  base_lr: 7.1375e-05 lr: 7.1375e-06  eta: 12:31:38  time: 0.4107  data_time: 0.0094  memory: 5973  grad_norm: 741.2796  loss: 27.1468  decode.loss_cls: 0.3157  decode.loss_mask: 1.2788  decode.loss_dice: 0.9741  decode.d0.loss_cls: 0.9054  decode.d0.loss_mask: 1.3029  decode.d0.loss_dice: 0.9963  decode.d1.loss_cls: 0.3728  decode.d1.loss_mask: 1.2880  decode.d1.loss_dice: 0.9769  decode.d2.loss_cls: 0.3596  decode.d2.loss_mask: 1.3509  decode.d2.loss_dice: 0.9875  decode.d3.loss_cls: 0.3416  decode.d3.loss_mask: 1.3533  decode.d3.loss_dice: 1.0417  decode.d4.loss_cls: 0.3955  decode.d4.loss_mask: 1.3255  decode.d4.loss_dice: 0.9877  decode.d5.loss_cls: 0.3818  decode.d5.loss_mask: 1.2490  decode.d5.loss_dice: 0.9301  decode.d6.loss_cls: 0.3065  decode.d6.loss_mask: 1.3590  decode.d6.loss_dice: 1.0252  decode.d7.loss_cls: 0.3313  decode.d7.loss_mask: 1.3548  decode.d7.loss_dice: 1.0245  decode.d8.loss_cls: 0.3550  decode.d8.loss_mask: 1.3055  decode.d8.loss_dice: 0.9701
05/26 16:47:02 - mmengine - INFO - Saving checkpoint at 50000 iterations
05/26 16:47:06 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:08  time: 0.0485  data_time: 0.0012  memory: 1391  
05/26 16:47:09 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:06  time: 0.0484  data_time: 0.0012  memory: 1205  
05/26 16:47:11 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:04  time: 0.0509  data_time: 0.0013  memory: 1596  
05/26 16:47:14 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:01  time: 0.0491  data_time: 0.0013  memory: 1298  
05/26 16:47:16 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:58  time: 0.0483  data_time: 0.0012  memory: 1298  
05/26 16:47:19 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:56  time: 0.0483  data_time: 0.0012  memory: 1279  
05/26 16:47:21 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:53  time: 0.0485  data_time: 0.0013  memory: 1224  
05/26 16:47:23 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:51  time: 0.0495  data_time: 0.0012  memory: 1298  
05/26 16:47:26 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0481  data_time: 0.0013  memory: 1298  
05/26 16:47:28 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:46  time: 0.0518  data_time: 0.0013  memory: 1725  
05/26 16:47:31 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:44  time: 0.0493  data_time: 0.0013  memory: 1336  
05/26 16:47:33 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:41  time: 0.0488  data_time: 0.0012  memory: 1298  
05/26 16:47:36 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:39  time: 0.0488  data_time: 0.0013  memory: 1205  
05/26 16:47:38 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0508  data_time: 0.0012  memory: 1316  
05/26 16:47:41 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:34  time: 0.0481  data_time: 0.0013  memory: 1279  
05/26 16:47:43 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0518  data_time: 0.0012  memory: 1410  
05/26 16:47:46 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:29  time: 0.0484  data_time: 0.0013  memory: 1279  
05/26 16:47:48 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0492  data_time: 0.0012  memory: 1205  
05/26 16:47:50 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0490  data_time: 0.0012  memory: 1205  
05/26 16:47:53 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0484  data_time: 0.0012  memory: 1336  
05/26 16:47:55 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0484  data_time: 0.0012  memory: 1246  
05/26 16:47:58 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0505  data_time: 0.0013  memory: 1503  
05/26 16:48:00 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0486  data_time: 0.0013  memory: 1261  
05/26 16:48:03 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0492  data_time: 0.0012  memory: 1298  
05/26 16:48:05 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0486  data_time: 0.0013  memory: 1447  
05/26 16:48:08 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0481  data_time: 0.0013  memory: 1298  
05/26 16:48:10 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0499  data_time: 0.0012  memory: 1279  
05/26 16:48:12 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0484  data_time: 0.0012  memory: 1205  
05/26 16:48:15 - mmengine - INFO - per class results:
05/26 16:48:15 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background |  95.0 | 96.41 |
|  aeroplane  |  91.5 | 95.85 |
|   bicycle   | 43.38 | 91.77 |
|     bird    | 90.08 | 96.23 |
|     boat    | 62.63 | 89.43 |
|    bottle   | 79.44 | 90.69 |
|     bus     | 92.64 | 95.71 |
|     car     | 85.72 | 94.87 |
|     cat     |  93.3 | 96.37 |
|    chair    | 38.87 | 66.76 |
|     cow     | 73.48 | 78.91 |
| diningtable | 65.23 |  74.0 |
|     dog     | 85.69 | 94.86 |
|    horse    | 82.25 | 93.66 |
|  motorbike  | 83.93 | 88.67 |
|    person   |  90.1 | 94.33 |
| pottedplant | 60.67 | 81.04 |
|    sheep    | 75.83 | 92.53 |
|     sofa    | 51.46 |  81.6 |
|    train    | 87.88 | 91.27 |
|  tvmonitor  | 71.57 | 89.86 |
+-------------+-------+-------+
05/26 16:48:15 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 94.8400  mIoU: 76.2200  mAcc: 89.2800  data_time: 0.0013  time: 0.0489
05/26 16:48:15 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_45000.pth is removed
05/26 16:48:16 - mmengine - INFO - The best checkpoint with 76.2200 mIoU at 50000 iter is saved to best_mIoU_iter_50000.pth.
05/26 16:48:38 - mmengine - INFO - Iter(train) [ 50050/160000]  base_lr: 7.1346e-05 lr: 7.1346e-06  eta: 12:31:25  time: 0.4116  data_time: 0.0094  memory: 5971  grad_norm: 832.7788  loss: 26.8042  decode.loss_cls: 0.2641  decode.loss_mask: 1.3951  decode.loss_dice: 0.9351  decode.d0.loss_cls: 0.8588  decode.d0.loss_mask: 1.3006  decode.d0.loss_dice: 0.8962  decode.d1.loss_cls: 0.2990  decode.d1.loss_mask: 1.3450  decode.d1.loss_dice: 0.9326  decode.d2.loss_cls: 0.3167  decode.d2.loss_mask: 1.4104  decode.d2.loss_dice: 0.9526  decode.d3.loss_cls: 0.2952  decode.d3.loss_mask: 1.4330  decode.d3.loss_dice: 0.9556  decode.d4.loss_cls: 0.3146  decode.d4.loss_mask: 1.4595  decode.d4.loss_dice: 0.9512  decode.d5.loss_cls: 0.3214  decode.d5.loss_mask: 1.3801  decode.d5.loss_dice: 0.9208  decode.d6.loss_cls: 0.3470  decode.d6.loss_mask: 1.3404  decode.d6.loss_dice: 0.9106  decode.d7.loss_cls: 0.4049  decode.d7.loss_mask: 1.3550  decode.d7.loss_dice: 0.8912  decode.d8.loss_cls: 0.3155  decode.d8.loss_mask: 1.3909  decode.d8.loss_dice: 0.9111
05/26 16:48:59 - mmengine - INFO - Iter(train) [ 50100/160000]  base_lr: 7.1317e-05 lr: 7.1317e-06  eta: 12:31:05  time: 0.4122  data_time: 0.0093  memory: 5966  grad_norm: 653.9956  loss: 19.4599  decode.loss_cls: 0.2256  decode.loss_mask: 0.9525  decode.loss_dice: 0.7410  decode.d0.loss_cls: 0.6505  decode.d0.loss_mask: 0.9176  decode.d0.loss_dice: 0.6871  decode.d1.loss_cls: 0.2096  decode.d1.loss_mask: 0.9466  decode.d1.loss_dice: 0.7549  decode.d2.loss_cls: 0.1706  decode.d2.loss_mask: 0.9596  decode.d2.loss_dice: 0.7342  decode.d3.loss_cls: 0.1924  decode.d3.loss_mask: 0.9795  decode.d3.loss_dice: 0.7183  decode.d4.loss_cls: 0.1663  decode.d4.loss_mask: 1.0340  decode.d4.loss_dice: 0.7516  decode.d5.loss_cls: 0.2713  decode.d5.loss_mask: 0.9244  decode.d5.loss_dice: 0.7166  decode.d6.loss_cls: 0.2362  decode.d6.loss_mask: 0.9245  decode.d6.loss_dice: 0.7676  decode.d7.loss_cls: 0.2215  decode.d7.loss_mask: 0.9420  decode.d7.loss_dice: 0.7479  decode.d8.loss_cls: 0.2098  decode.d8.loss_mask: 0.9617  decode.d8.loss_dice: 0.7444
05/26 16:49:20 - mmengine - INFO - Iter(train) [ 50150/160000]  base_lr: 7.1288e-05 lr: 7.1288e-06  eta: 12:30:44  time: 0.4122  data_time: 0.0093  memory: 5968  grad_norm: 580.6704  loss: 24.0263  decode.loss_cls: 0.2705  decode.loss_mask: 1.1241  decode.loss_dice: 0.9294  decode.d0.loss_cls: 0.7223  decode.d0.loss_mask: 1.1997  decode.d0.loss_dice: 0.9203  decode.d1.loss_cls: 0.3045  decode.d1.loss_mask: 1.1521  decode.d1.loss_dice: 0.9502  decode.d2.loss_cls: 0.2644  decode.d2.loss_mask: 1.1678  decode.d2.loss_dice: 0.9581  decode.d3.loss_cls: 0.3019  decode.d3.loss_mask: 1.1159  decode.d3.loss_dice: 0.9248  decode.d4.loss_cls: 0.3101  decode.d4.loss_mask: 1.1218  decode.d4.loss_dice: 0.9389  decode.d5.loss_cls: 0.3178  decode.d5.loss_mask: 1.1347  decode.d5.loss_dice: 0.9059  decode.d6.loss_cls: 0.3089  decode.d6.loss_mask: 1.1168  decode.d6.loss_dice: 0.9202  decode.d7.loss_cls: 0.3059  decode.d7.loss_mask: 1.1279  decode.d7.loss_dice: 0.9071  decode.d8.loss_cls: 0.2761  decode.d8.loss_mask: 1.1273  decode.d8.loss_dice: 0.9010
05/26 16:49:40 - mmengine - INFO - Iter(train) [ 50200/160000]  base_lr: 7.1258e-05 lr: 7.1258e-06  eta: 12:30:24  time: 0.4133  data_time: 0.0093  memory: 5969  grad_norm: 657.6536  loss: 24.1025  decode.loss_cls: 0.2187  decode.loss_mask: 1.2552  decode.loss_dice: 0.8589  decode.d0.loss_cls: 0.6889  decode.d0.loss_mask: 1.2236  decode.d0.loss_dice: 0.8680  decode.d1.loss_cls: 0.2106  decode.d1.loss_mask: 1.3151  decode.d1.loss_dice: 0.8581  decode.d2.loss_cls: 0.2224  decode.d2.loss_mask: 1.2715  decode.d2.loss_dice: 0.8967  decode.d3.loss_cls: 0.2585  decode.d3.loss_mask: 1.2534  decode.d3.loss_dice: 0.8621  decode.d4.loss_cls: 0.2018  decode.d4.loss_mask: 1.2588  decode.d4.loss_dice: 0.8460  decode.d5.loss_cls: 0.2380  decode.d5.loss_mask: 1.3239  decode.d5.loss_dice: 0.8429  decode.d6.loss_cls: 0.2478  decode.d6.loss_mask: 1.2676  decode.d6.loss_dice: 0.8775  decode.d7.loss_cls: 0.2479  decode.d7.loss_mask: 1.2927  decode.d7.loss_dice: 0.8502  decode.d8.loss_cls: 0.2306  decode.d8.loss_mask: 1.2894  decode.d8.loss_dice: 0.8256
05/26 16:50:01 - mmengine - INFO - Iter(train) [ 50250/160000]  base_lr: 7.1229e-05 lr: 7.1229e-06  eta: 12:30:04  time: 0.4109  data_time: 0.0093  memory: 5969  grad_norm: 768.8452  loss: 19.2068  decode.loss_cls: 0.2048  decode.loss_mask: 0.9731  decode.loss_dice: 0.6905  decode.d0.loss_cls: 0.5665  decode.d0.loss_mask: 1.0033  decode.d0.loss_dice: 0.7334  decode.d1.loss_cls: 0.2184  decode.d1.loss_mask: 0.9708  decode.d1.loss_dice: 0.7006  decode.d2.loss_cls: 0.2171  decode.d2.loss_mask: 0.9671  decode.d2.loss_dice: 0.6941  decode.d3.loss_cls: 0.2191  decode.d3.loss_mask: 0.9788  decode.d3.loss_dice: 0.7144  decode.d4.loss_cls: 0.1930  decode.d4.loss_mask: 0.9659  decode.d4.loss_dice: 0.6953  decode.d5.loss_cls: 0.1886  decode.d5.loss_mask: 0.9743  decode.d5.loss_dice: 0.7082  decode.d6.loss_cls: 0.2192  decode.d6.loss_mask: 0.9567  decode.d6.loss_dice: 0.7011  decode.d7.loss_cls: 0.2099  decode.d7.loss_mask: 0.9617  decode.d7.loss_dice: 0.6904  decode.d8.loss_cls: 0.2317  decode.d8.loss_mask: 0.9729  decode.d8.loss_dice: 0.6857
05/26 16:50:22 - mmengine - INFO - Iter(train) [ 50300/160000]  base_lr: 7.1200e-05 lr: 7.1200e-06  eta: 12:29:43  time: 0.4106  data_time: 0.0094  memory: 5979  grad_norm: 508.3017  loss: 21.2132  decode.loss_cls: 0.2234  decode.loss_mask: 1.0257  decode.loss_dice: 0.7504  decode.d0.loss_cls: 0.7165  decode.d0.loss_mask: 1.0190  decode.d0.loss_dice: 0.7343  decode.d1.loss_cls: 0.2065  decode.d1.loss_mask: 1.0912  decode.d1.loss_dice: 0.7864  decode.d2.loss_cls: 0.2452  decode.d2.loss_mask: 1.1462  decode.d2.loss_dice: 0.7686  decode.d3.loss_cls: 0.2596  decode.d3.loss_mask: 1.0466  decode.d3.loss_dice: 0.7728  decode.d4.loss_cls: 0.2241  decode.d4.loss_mask: 1.0656  decode.d4.loss_dice: 0.7971  decode.d5.loss_cls: 0.2699  decode.d5.loss_mask: 1.0515  decode.d5.loss_dice: 0.7601  decode.d6.loss_cls: 0.2757  decode.d6.loss_mask: 1.0419  decode.d6.loss_dice: 0.7339  decode.d7.loss_cls: 0.2745  decode.d7.loss_mask: 1.1039  decode.d7.loss_dice: 0.7628  decode.d8.loss_cls: 0.2199  decode.d8.loss_mask: 1.0766  decode.d8.loss_dice: 0.7633
05/26 16:50:42 - mmengine - INFO - Iter(train) [ 50350/160000]  base_lr: 7.1171e-05 lr: 7.1171e-06  eta: 12:29:23  time: 0.4128  data_time: 0.0094  memory: 5986  grad_norm: 481.2503  loss: 22.3785  decode.loss_cls: 0.2407  decode.loss_mask: 1.0702  decode.loss_dice: 0.8482  decode.d0.loss_cls: 0.8016  decode.d0.loss_mask: 0.9918  decode.d0.loss_dice: 0.8411  decode.d1.loss_cls: 0.2516  decode.d1.loss_mask: 1.0752  decode.d1.loss_dice: 0.8518  decode.d2.loss_cls: 0.2977  decode.d2.loss_mask: 1.0736  decode.d2.loss_dice: 0.8342  decode.d3.loss_cls: 0.2439  decode.d3.loss_mask: 1.0725  decode.d3.loss_dice: 0.8644  decode.d4.loss_cls: 0.2439  decode.d4.loss_mask: 1.0779  decode.d4.loss_dice: 0.8545  decode.d5.loss_cls: 0.2640  decode.d5.loss_mask: 1.0650  decode.d5.loss_dice: 0.8537  decode.d6.loss_cls: 0.2656  decode.d6.loss_mask: 1.0811  decode.d6.loss_dice: 0.8642  decode.d7.loss_cls: 0.3142  decode.d7.loss_mask: 1.0724  decode.d7.loss_dice: 0.8357  decode.d8.loss_cls: 0.2948  decode.d8.loss_mask: 1.0848  decode.d8.loss_dice: 0.8483
05/26 16:51:03 - mmengine - INFO - Iter(train) [ 50400/160000]  base_lr: 7.1142e-05 lr: 7.1142e-06  eta: 12:29:03  time: 0.4117  data_time: 0.0094  memory: 5967  grad_norm: 690.7777  loss: 22.8113  decode.loss_cls: 0.2304  decode.loss_mask: 1.1284  decode.loss_dice: 0.9114  decode.d0.loss_cls: 0.6542  decode.d0.loss_mask: 0.9998  decode.d0.loss_dice: 0.8640  decode.d1.loss_cls: 0.2320  decode.d1.loss_mask: 1.0869  decode.d1.loss_dice: 0.9127  decode.d2.loss_cls: 0.2089  decode.d2.loss_mask: 1.1045  decode.d2.loss_dice: 0.8794  decode.d3.loss_cls: 0.1982  decode.d3.loss_mask: 1.1452  decode.d3.loss_dice: 0.8927  decode.d4.loss_cls: 0.2385  decode.d4.loss_mask: 1.0700  decode.d4.loss_dice: 0.8945  decode.d5.loss_cls: 0.2749  decode.d5.loss_mask: 1.1248  decode.d5.loss_dice: 0.9036  decode.d6.loss_cls: 0.1901  decode.d6.loss_mask: 1.1517  decode.d6.loss_dice: 0.9238  decode.d7.loss_cls: 0.2454  decode.d7.loss_mask: 1.1232  decode.d7.loss_dice: 0.8979  decode.d8.loss_cls: 0.2770  decode.d8.loss_mask: 1.1385  decode.d8.loss_dice: 0.9086
05/26 16:51:23 - mmengine - INFO - Iter(train) [ 50450/160000]  base_lr: 7.1112e-05 lr: 7.1112e-06  eta: 12:28:43  time: 0.4112  data_time: 0.0093  memory: 5971  grad_norm: 714.3472  loss: 21.2340  decode.loss_cls: 0.2179  decode.loss_mask: 1.0798  decode.loss_dice: 0.8164  decode.d0.loss_cls: 0.7332  decode.d0.loss_mask: 1.0059  decode.d0.loss_dice: 0.7380  decode.d1.loss_cls: 0.2847  decode.d1.loss_mask: 1.0367  decode.d1.loss_dice: 0.7712  decode.d2.loss_cls: 0.2501  decode.d2.loss_mask: 1.0290  decode.d2.loss_dice: 0.7692  decode.d3.loss_cls: 0.2633  decode.d3.loss_mask: 0.9941  decode.d3.loss_dice: 0.7676  decode.d4.loss_cls: 0.2645  decode.d4.loss_mask: 1.0069  decode.d4.loss_dice: 0.7686  decode.d5.loss_cls: 0.2414  decode.d5.loss_mask: 0.9964  decode.d5.loss_dice: 0.7687  decode.d6.loss_cls: 0.2583  decode.d6.loss_mask: 1.0155  decode.d6.loss_dice: 0.7834  decode.d7.loss_cls: 0.2411  decode.d7.loss_mask: 1.0466  decode.d7.loss_dice: 0.7979  decode.d8.loss_cls: 0.2502  decode.d8.loss_mask: 1.2075  decode.d8.loss_dice: 0.8296
05/26 16:51:44 - mmengine - INFO - Iter(train) [ 50500/160000]  base_lr: 7.1083e-05 lr: 7.1083e-06  eta: 12:28:22  time: 0.4121  data_time: 0.0094  memory: 5966  grad_norm: 966.6330  loss: 19.9231  decode.loss_cls: 0.2936  decode.loss_mask: 0.9313  decode.loss_dice: 0.7428  decode.d0.loss_cls: 0.7152  decode.d0.loss_mask: 0.8489  decode.d0.loss_dice: 0.7201  decode.d1.loss_cls: 0.3542  decode.d1.loss_mask: 0.9161  decode.d1.loss_dice: 0.7472  decode.d2.loss_cls: 0.2129  decode.d2.loss_mask: 0.9693  decode.d2.loss_dice: 0.7769  decode.d3.loss_cls: 0.2590  decode.d3.loss_mask: 0.8996  decode.d3.loss_dice: 0.6971  decode.d4.loss_cls: 0.3611  decode.d4.loss_mask: 0.8868  decode.d4.loss_dice: 0.7414  decode.d5.loss_cls: 0.3554  decode.d5.loss_mask: 0.8955  decode.d5.loss_dice: 0.7098  decode.d6.loss_cls: 0.3549  decode.d6.loss_mask: 0.8587  decode.d6.loss_dice: 0.7130  decode.d7.loss_cls: 0.3868  decode.d7.loss_mask: 0.8776  decode.d7.loss_dice: 0.7390  decode.d8.loss_cls: 0.3524  decode.d8.loss_mask: 0.8682  decode.d8.loss_dice: 0.7382
05/26 16:52:05 - mmengine - INFO - Iter(train) [ 50550/160000]  base_lr: 7.1054e-05 lr: 7.1054e-06  eta: 12:28:02  time: 0.4125  data_time: 0.0094  memory: 5975  grad_norm: 667.3040  loss: 25.6088  decode.loss_cls: 0.3572  decode.loss_mask: 1.1569  decode.loss_dice: 0.9793  decode.d0.loss_cls: 0.8059  decode.d0.loss_mask: 1.1115  decode.d0.loss_dice: 0.9724  decode.d1.loss_cls: 0.4462  decode.d1.loss_mask: 1.1652  decode.d1.loss_dice: 0.9842  decode.d2.loss_cls: 0.3759  decode.d2.loss_mask: 1.1662  decode.d2.loss_dice: 0.9743  decode.d3.loss_cls: 0.4123  decode.d3.loss_mask: 1.1620  decode.d3.loss_dice: 0.9404  decode.d4.loss_cls: 0.3521  decode.d4.loss_mask: 1.1678  decode.d4.loss_dice: 0.9739  decode.d5.loss_cls: 0.3914  decode.d5.loss_mask: 1.1320  decode.d5.loss_dice: 0.9737  decode.d6.loss_cls: 0.3857  decode.d6.loss_mask: 1.1464  decode.d6.loss_dice: 0.9503  decode.d7.loss_cls: 0.3499  decode.d7.loss_mask: 1.1998  decode.d7.loss_dice: 0.9774  decode.d8.loss_cls: 0.3653  decode.d8.loss_mask: 1.1944  decode.d8.loss_dice: 1.0388
05/26 16:52:25 - mmengine - INFO - Iter(train) [ 50600/160000]  base_lr: 7.1025e-05 lr: 7.1025e-06  eta: 12:27:42  time: 0.4110  data_time: 0.0094  memory: 5972  grad_norm: 691.5612  loss: 22.0911  decode.loss_cls: 0.2662  decode.loss_mask: 1.2001  decode.loss_dice: 0.7234  decode.d0.loss_cls: 0.6967  decode.d0.loss_mask: 1.1622  decode.d0.loss_dice: 0.7051  decode.d1.loss_cls: 0.2508  decode.d1.loss_mask: 1.1641  decode.d1.loss_dice: 0.7248  decode.d2.loss_cls: 0.2553  decode.d2.loss_mask: 1.1840  decode.d2.loss_dice: 0.7243  decode.d3.loss_cls: 0.2742  decode.d3.loss_mask: 1.1585  decode.d3.loss_dice: 0.7081  decode.d4.loss_cls: 0.2656  decode.d4.loss_mask: 1.1421  decode.d4.loss_dice: 0.7270  decode.d5.loss_cls: 0.2621  decode.d5.loss_mask: 1.2042  decode.d5.loss_dice: 0.7095  decode.d6.loss_cls: 0.3105  decode.d6.loss_mask: 1.1562  decode.d6.loss_dice: 0.7121  decode.d7.loss_cls: 0.3062  decode.d7.loss_mask: 1.1872  decode.d7.loss_dice: 0.7088  decode.d8.loss_cls: 0.2904  decode.d8.loss_mask: 1.1923  decode.d8.loss_dice: 0.7191
05/26 16:52:46 - mmengine - INFO - Iter(train) [ 50650/160000]  base_lr: 7.0996e-05 lr: 7.0996e-06  eta: 12:27:21  time: 0.4121  data_time: 0.0094  memory: 5974  grad_norm: 768.5067  loss: 26.4079  decode.loss_cls: 0.3651  decode.loss_mask: 1.2081  decode.loss_dice: 1.0459  decode.d0.loss_cls: 0.9861  decode.d0.loss_mask: 1.1306  decode.d0.loss_dice: 1.0281  decode.d1.loss_cls: 0.3269  decode.d1.loss_mask: 1.1862  decode.d1.loss_dice: 0.9943  decode.d2.loss_cls: 0.3325  decode.d2.loss_mask: 1.1834  decode.d2.loss_dice: 1.0395  decode.d3.loss_cls: 0.3268  decode.d3.loss_mask: 1.1869  decode.d3.loss_dice: 1.0002  decode.d4.loss_cls: 0.4026  decode.d4.loss_mask: 1.2437  decode.d4.loss_dice: 1.0161  decode.d5.loss_cls: 0.3988  decode.d5.loss_mask: 1.2002  decode.d5.loss_dice: 1.0111  decode.d6.loss_cls: 0.3651  decode.d6.loss_mask: 1.2011  decode.d6.loss_dice: 1.0358  decode.d7.loss_cls: 0.4053  decode.d7.loss_mask: 1.2174  decode.d7.loss_dice: 1.0147  decode.d8.loss_cls: 0.3954  decode.d8.loss_mask: 1.1648  decode.d8.loss_dice: 0.9952
05/26 16:53:06 - mmengine - INFO - Iter(train) [ 50700/160000]  base_lr: 7.0966e-05 lr: 7.0966e-06  eta: 12:27:01  time: 0.4114  data_time: 0.0094  memory: 5975  grad_norm: 1988.4633  loss: 23.7302  decode.loss_cls: 0.2598  decode.loss_mask: 1.1411  decode.loss_dice: 0.9393  decode.d0.loss_cls: 0.8030  decode.d0.loss_mask: 1.0609  decode.d0.loss_dice: 0.8922  decode.d1.loss_cls: 0.2543  decode.d1.loss_mask: 1.1533  decode.d1.loss_dice: 0.9673  decode.d2.loss_cls: 0.2330  decode.d2.loss_mask: 1.1410  decode.d2.loss_dice: 0.9610  decode.d3.loss_cls: 0.2056  decode.d3.loss_mask: 1.1685  decode.d3.loss_dice: 0.9604  decode.d4.loss_cls: 0.2903  decode.d4.loss_mask: 1.1122  decode.d4.loss_dice: 0.9362  decode.d5.loss_cls: 0.2595  decode.d5.loss_mask: 1.1214  decode.d5.loss_dice: 0.9211  decode.d6.loss_cls: 0.2922  decode.d6.loss_mask: 1.1194  decode.d6.loss_dice: 0.9285  decode.d7.loss_cls: 0.2664  decode.d7.loss_mask: 1.1367  decode.d7.loss_dice: 0.9188  decode.d8.loss_cls: 0.2386  decode.d8.loss_mask: 1.1157  decode.d8.loss_dice: 0.9326
05/26 16:53:27 - mmengine - INFO - Iter(train) [ 50750/160000]  base_lr: 7.0937e-05 lr: 7.0937e-06  eta: 12:26:41  time: 0.4120  data_time: 0.0094  memory: 5970  grad_norm: 599.9414  loss: 25.2234  decode.loss_cls: 0.2265  decode.loss_mask: 1.3005  decode.loss_dice: 0.9345  decode.d0.loss_cls: 0.7305  decode.d0.loss_mask: 1.1557  decode.d0.loss_dice: 0.8501  decode.d1.loss_cls: 0.2503  decode.d1.loss_mask: 1.3074  decode.d1.loss_dice: 0.9071  decode.d2.loss_cls: 0.2658  decode.d2.loss_mask: 1.3412  decode.d2.loss_dice: 0.9605  decode.d3.loss_cls: 0.2252  decode.d3.loss_mask: 1.3045  decode.d3.loss_dice: 0.9438  decode.d4.loss_cls: 0.2753  decode.d4.loss_mask: 1.3112  decode.d4.loss_dice: 0.9330  decode.d5.loss_cls: 0.2998  decode.d5.loss_mask: 1.2433  decode.d5.loss_dice: 0.9293  decode.d6.loss_cls: 0.2708  decode.d6.loss_mask: 1.3089  decode.d6.loss_dice: 0.9643  decode.d7.loss_cls: 0.2786  decode.d7.loss_mask: 1.2865  decode.d7.loss_dice: 0.9164  decode.d8.loss_cls: 0.2510  decode.d8.loss_mask: 1.3140  decode.d8.loss_dice: 0.9375
05/26 16:53:48 - mmengine - INFO - Iter(train) [ 50800/160000]  base_lr: 7.0908e-05 lr: 7.0908e-06  eta: 12:26:21  time: 0.4134  data_time: 0.0097  memory: 5972  grad_norm: 484.5719  loss: 21.9921  decode.loss_cls: 0.1644  decode.loss_mask: 1.2086  decode.loss_dice: 0.7688  decode.d0.loss_cls: 0.7625  decode.d0.loss_mask: 1.1306  decode.d0.loss_dice: 0.7402  decode.d1.loss_cls: 0.2095  decode.d1.loss_mask: 1.2065  decode.d1.loss_dice: 0.7530  decode.d2.loss_cls: 0.1828  decode.d2.loss_mask: 1.2117  decode.d2.loss_dice: 0.7610  decode.d3.loss_cls: 0.1881  decode.d3.loss_mask: 1.2038  decode.d3.loss_dice: 0.7602  decode.d4.loss_cls: 0.1993  decode.d4.loss_mask: 1.2057  decode.d4.loss_dice: 0.7595  decode.d5.loss_cls: 0.2074  decode.d5.loss_mask: 1.2045  decode.d5.loss_dice: 0.7336  decode.d6.loss_cls: 0.2257  decode.d6.loss_mask: 1.2066  decode.d6.loss_dice: 0.7178  decode.d7.loss_cls: 0.1860  decode.d7.loss_mask: 1.2219  decode.d7.loss_dice: 0.7631  decode.d8.loss_cls: 0.1708  decode.d8.loss_mask: 1.1891  decode.d8.loss_dice: 0.7492
05/26 16:54:08 - mmengine - INFO - Iter(train) [ 50850/160000]  base_lr: 7.0879e-05 lr: 7.0879e-06  eta: 12:26:00  time: 0.4114  data_time: 0.0094  memory: 5967  grad_norm: 805.4359  loss: 23.1423  decode.loss_cls: 0.2756  decode.loss_mask: 1.2681  decode.loss_dice: 0.7832  decode.d0.loss_cls: 0.6552  decode.d0.loss_mask: 1.1996  decode.d0.loss_dice: 0.7353  decode.d1.loss_cls: 0.2103  decode.d1.loss_mask: 1.2691  decode.d1.loss_dice: 0.7252  decode.d2.loss_cls: 0.2536  decode.d2.loss_mask: 1.2618  decode.d2.loss_dice: 0.7536  decode.d3.loss_cls: 0.2352  decode.d3.loss_mask: 1.3053  decode.d3.loss_dice: 0.7509  decode.d4.loss_cls: 0.2490  decode.d4.loss_mask: 1.2561  decode.d4.loss_dice: 0.7392  decode.d5.loss_cls: 0.2250  decode.d5.loss_mask: 1.2963  decode.d5.loss_dice: 0.7640  decode.d6.loss_cls: 0.2163  decode.d6.loss_mask: 1.2811  decode.d6.loss_dice: 0.7375  decode.d7.loss_cls: 0.2127  decode.d7.loss_mask: 1.3957  decode.d7.loss_dice: 0.7788  decode.d8.loss_cls: 0.2141  decode.d8.loss_mask: 1.3346  decode.d8.loss_dice: 0.7596
05/26 16:54:29 - mmengine - INFO - Iter(train) [ 50900/160000]  base_lr: 7.0849e-05 lr: 7.0849e-06  eta: 12:25:40  time: 0.4119  data_time: 0.0094  memory: 5973  grad_norm: 720.3270  loss: 25.1522  decode.loss_cls: 0.2498  decode.loss_mask: 1.3039  decode.loss_dice: 0.8388  decode.d0.loss_cls: 0.8559  decode.d0.loss_mask: 1.1881  decode.d0.loss_dice: 0.8196  decode.d1.loss_cls: 0.2881  decode.d1.loss_mask: 1.3269  decode.d1.loss_dice: 0.8961  decode.d2.loss_cls: 0.3732  decode.d2.loss_mask: 1.3159  decode.d2.loss_dice: 0.8507  decode.d3.loss_cls: 0.3084  decode.d3.loss_mask: 1.3356  decode.d3.loss_dice: 0.8650  decode.d4.loss_cls: 0.3165  decode.d4.loss_mask: 1.2957  decode.d4.loss_dice: 0.8449  decode.d5.loss_cls: 0.2937  decode.d5.loss_mask: 1.3148  decode.d5.loss_dice: 0.8698  decode.d6.loss_cls: 0.3286  decode.d6.loss_mask: 1.2637  decode.d6.loss_dice: 0.8254  decode.d7.loss_cls: 0.2878  decode.d7.loss_mask: 1.3280  decode.d7.loss_dice: 0.8806  decode.d8.loss_cls: 0.2658  decode.d8.loss_mask: 1.3721  decode.d8.loss_dice: 0.8489
05/26 16:54:49 - mmengine - INFO - Iter(train) [ 50950/160000]  base_lr: 7.0820e-05 lr: 7.0820e-06  eta: 12:25:20  time: 0.4134  data_time: 0.0094  memory: 5973  grad_norm: 375.7702  loss: 23.0841  decode.loss_cls: 0.1280  decode.loss_mask: 1.1818  decode.loss_dice: 0.8988  decode.d0.loss_cls: 0.7764  decode.d0.loss_mask: 1.1078  decode.d0.loss_dice: 0.8682  decode.d1.loss_cls: 0.1353  decode.d1.loss_mask: 1.1956  decode.d1.loss_dice: 0.9238  decode.d2.loss_cls: 0.1679  decode.d2.loss_mask: 1.1884  decode.d2.loss_dice: 0.9296  decode.d3.loss_cls: 0.1504  decode.d3.loss_mask: 1.1952  decode.d3.loss_dice: 0.9057  decode.d4.loss_cls: 0.1598  decode.d4.loss_mask: 1.1873  decode.d4.loss_dice: 0.9162  decode.d5.loss_cls: 0.1557  decode.d5.loss_mask: 1.2305  decode.d5.loss_dice: 0.9249  decode.d6.loss_cls: 0.1436  decode.d6.loss_mask: 1.2077  decode.d6.loss_dice: 0.9128  decode.d7.loss_cls: 0.1367  decode.d7.loss_mask: 1.1846  decode.d7.loss_dice: 0.9165  decode.d8.loss_cls: 0.1103  decode.d8.loss_mask: 1.2143  decode.d8.loss_dice: 0.9301
05/26 16:55:10 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 16:55:10 - mmengine - INFO - Iter(train) [ 51000/160000]  base_lr: 7.0791e-05 lr: 7.0791e-06  eta: 12:25:00  time: 0.4181  data_time: 0.0096  memory: 5976  grad_norm: 834.0298  loss: 26.5988  decode.loss_cls: 0.2946  decode.loss_mask: 1.2775  decode.loss_dice: 0.9965  decode.d0.loss_cls: 0.8737  decode.d0.loss_mask: 1.2882  decode.d0.loss_dice: 0.9948  decode.d1.loss_cls: 0.2820  decode.d1.loss_mask: 1.2436  decode.d1.loss_dice: 0.9753  decode.d2.loss_cls: 0.3315  decode.d2.loss_mask: 1.2850  decode.d2.loss_dice: 0.9363  decode.d3.loss_cls: 0.3186  decode.d3.loss_mask: 1.2827  decode.d3.loss_dice: 0.9651  decode.d4.loss_cls: 0.3834  decode.d4.loss_mask: 1.2643  decode.d4.loss_dice: 1.0005  decode.d5.loss_cls: 0.3869  decode.d5.loss_mask: 1.2694  decode.d5.loss_dice: 0.9779  decode.d6.loss_cls: 0.3666  decode.d6.loss_mask: 1.3330  decode.d6.loss_dice: 0.9817  decode.d7.loss_cls: 0.3145  decode.d7.loss_mask: 1.3276  decode.d7.loss_dice: 1.0240  decode.d8.loss_cls: 0.2710  decode.d8.loss_mask: 1.3416  decode.d8.loss_dice: 1.0111
05/26 16:55:31 - mmengine - INFO - Iter(train) [ 51050/160000]  base_lr: 7.0762e-05 lr: 7.0762e-06  eta: 12:24:40  time: 0.4182  data_time: 0.0095  memory: 5966  grad_norm: 551.0081  loss: 20.3863  decode.loss_cls: 0.1745  decode.loss_mask: 1.0411  decode.loss_dice: 0.7623  decode.d0.loss_cls: 0.7358  decode.d0.loss_mask: 0.9333  decode.d0.loss_dice: 0.7000  decode.d1.loss_cls: 0.2028  decode.d1.loss_mask: 1.0441  decode.d1.loss_dice: 0.7442  decode.d2.loss_cls: 0.1926  decode.d2.loss_mask: 1.0237  decode.d2.loss_dice: 0.7537  decode.d3.loss_cls: 0.1917  decode.d3.loss_mask: 1.0327  decode.d3.loss_dice: 0.7394  decode.d4.loss_cls: 0.2181  decode.d4.loss_mask: 1.0601  decode.d4.loss_dice: 0.8002  decode.d5.loss_cls: 0.1916  decode.d5.loss_mask: 1.0553  decode.d5.loss_dice: 0.7638  decode.d6.loss_cls: 0.2317  decode.d6.loss_mask: 1.0772  decode.d6.loss_dice: 0.7840  decode.d7.loss_cls: 0.1761  decode.d7.loss_mask: 1.0305  decode.d7.loss_dice: 0.7588  decode.d8.loss_cls: 0.1833  decode.d8.loss_mask: 1.0337  decode.d8.loss_dice: 0.7498
05/26 16:55:52 - mmengine - INFO - Iter(train) [ 51100/160000]  base_lr: 7.0733e-05 lr: 7.0733e-06  eta: 12:24:21  time: 0.4201  data_time: 0.0096  memory: 5988  grad_norm: 995.0037  loss: 24.2654  decode.loss_cls: 0.2882  decode.loss_mask: 1.2305  decode.loss_dice: 0.8745  decode.d0.loss_cls: 0.8926  decode.d0.loss_mask: 1.0933  decode.d0.loss_dice: 0.8032  decode.d1.loss_cls: 0.3796  decode.d1.loss_mask: 1.1882  decode.d1.loss_dice: 0.8633  decode.d2.loss_cls: 0.2803  decode.d2.loss_mask: 1.1994  decode.d2.loss_dice: 0.8337  decode.d3.loss_cls: 0.3375  decode.d3.loss_mask: 1.1968  decode.d3.loss_dice: 0.8336  decode.d4.loss_cls: 0.3588  decode.d4.loss_mask: 1.1894  decode.d4.loss_dice: 0.8451  decode.d5.loss_cls: 0.3832  decode.d5.loss_mask: 1.1888  decode.d5.loss_dice: 0.8551  decode.d6.loss_cls: 0.3321  decode.d6.loss_mask: 1.2150  decode.d6.loss_dice: 0.8769  decode.d7.loss_cls: 0.3452  decode.d7.loss_mask: 1.2085  decode.d7.loss_dice: 0.8086  decode.d8.loss_cls: 0.3199  decode.d8.loss_mask: 1.2080  decode.d8.loss_dice: 0.8358
05/26 16:56:13 - mmengine - INFO - Iter(train) [ 51150/160000]  base_lr: 7.0703e-05 lr: 7.0703e-06  eta: 12:24:02  time: 0.4183  data_time: 0.0095  memory: 5981  grad_norm: 579.0553  loss: 24.6677  decode.loss_cls: 0.2573  decode.loss_mask: 1.1798  decode.loss_dice: 0.9117  decode.d0.loss_cls: 0.8674  decode.d0.loss_mask: 1.0803  decode.d0.loss_dice: 0.8733  decode.d1.loss_cls: 0.3298  decode.d1.loss_mask: 1.1835  decode.d1.loss_dice: 0.9293  decode.d2.loss_cls: 0.3209  decode.d2.loss_mask: 1.2011  decode.d2.loss_dice: 0.9392  decode.d3.loss_cls: 0.3611  decode.d3.loss_mask: 1.2091  decode.d3.loss_dice: 0.9227  decode.d4.loss_cls: 0.3121  decode.d4.loss_mask: 1.1395  decode.d4.loss_dice: 0.9280  decode.d5.loss_cls: 0.2818  decode.d5.loss_mask: 1.1754  decode.d5.loss_dice: 0.9125  decode.d6.loss_cls: 0.3113  decode.d6.loss_mask: 1.1999  decode.d6.loss_dice: 0.9417  decode.d7.loss_cls: 0.3299  decode.d7.loss_mask: 1.2153  decode.d7.loss_dice: 0.9314  decode.d8.loss_cls: 0.3061  decode.d8.loss_mask: 1.1963  decode.d8.loss_dice: 0.9199
05/26 16:56:34 - mmengine - INFO - Iter(train) [ 51200/160000]  base_lr: 7.0674e-05 lr: 7.0674e-06  eta: 12:23:42  time: 0.4162  data_time: 0.0096  memory: 5986  grad_norm: 506.5704  loss: 25.4563  decode.loss_cls: 0.2651  decode.loss_mask: 1.2254  decode.loss_dice: 0.9636  decode.d0.loss_cls: 0.8305  decode.d0.loss_mask: 1.1570  decode.d0.loss_dice: 0.9662  decode.d1.loss_cls: 0.3002  decode.d1.loss_mask: 1.2139  decode.d1.loss_dice: 0.9505  decode.d2.loss_cls: 0.3442  decode.d2.loss_mask: 1.2431  decode.d2.loss_dice: 0.9437  decode.d3.loss_cls: 0.3172  decode.d3.loss_mask: 1.2577  decode.d3.loss_dice: 0.9410  decode.d4.loss_cls: 0.3379  decode.d4.loss_mask: 1.2178  decode.d4.loss_dice: 0.9352  decode.d5.loss_cls: 0.3067  decode.d5.loss_mask: 1.2375  decode.d5.loss_dice: 0.9405  decode.d6.loss_cls: 0.3077  decode.d6.loss_mask: 1.2471  decode.d6.loss_dice: 0.9821  decode.d7.loss_cls: 0.3379  decode.d7.loss_mask: 1.2480  decode.d7.loss_dice: 0.9373  decode.d8.loss_cls: 0.2846  decode.d8.loss_mask: 1.2556  decode.d8.loss_dice: 0.9611
05/26 16:56:55 - mmengine - INFO - Iter(train) [ 51250/160000]  base_lr: 7.0645e-05 lr: 7.0645e-06  eta: 12:23:22  time: 0.4183  data_time: 0.0096  memory: 5968  grad_norm: 1077.3278  loss: 22.4452  decode.loss_cls: 0.1757  decode.loss_mask: 1.2494  decode.loss_dice: 0.7251  decode.d0.loss_cls: 0.7355  decode.d0.loss_mask: 1.1211  decode.d0.loss_dice: 0.6882  decode.d1.loss_cls: 0.1724  decode.d1.loss_mask: 1.3118  decode.d1.loss_dice: 0.7717  decode.d2.loss_cls: 0.1853  decode.d2.loss_mask: 1.2430  decode.d2.loss_dice: 0.7686  decode.d3.loss_cls: 0.1645  decode.d3.loss_mask: 1.2794  decode.d3.loss_dice: 0.7799  decode.d4.loss_cls: 0.1724  decode.d4.loss_mask: 1.2747  decode.d4.loss_dice: 0.7717  decode.d5.loss_cls: 0.2137  decode.d5.loss_mask: 1.2687  decode.d5.loss_dice: 0.7653  decode.d6.loss_cls: 0.1787  decode.d6.loss_mask: 1.2581  decode.d6.loss_dice: 0.7503  decode.d7.loss_cls: 0.1703  decode.d7.loss_mask: 1.2896  decode.d7.loss_dice: 0.7578  decode.d8.loss_cls: 0.1979  decode.d8.loss_mask: 1.2567  decode.d8.loss_dice: 0.7476
05/26 16:57:16 - mmengine - INFO - Iter(train) [ 51300/160000]  base_lr: 7.0616e-05 lr: 7.0616e-06  eta: 12:23:02  time: 0.4106  data_time: 0.0094  memory: 5969  grad_norm: 535.7575  loss: 21.8996  decode.loss_cls: 0.2410  decode.loss_mask: 1.0488  decode.loss_dice: 0.8427  decode.d0.loss_cls: 0.6857  decode.d0.loss_mask: 1.0209  decode.d0.loss_dice: 0.7862  decode.d1.loss_cls: 0.2571  decode.d1.loss_mask: 1.0165  decode.d1.loss_dice: 0.8128  decode.d2.loss_cls: 0.2822  decode.d2.loss_mask: 1.0662  decode.d2.loss_dice: 0.8333  decode.d3.loss_cls: 0.2911  decode.d3.loss_mask: 1.0707  decode.d3.loss_dice: 0.8342  decode.d4.loss_cls: 0.3079  decode.d4.loss_mask: 1.0701  decode.d4.loss_dice: 0.8234  decode.d5.loss_cls: 0.3061  decode.d5.loss_mask: 1.0468  decode.d5.loss_dice: 0.8283  decode.d6.loss_cls: 0.2665  decode.d6.loss_mask: 1.0180  decode.d6.loss_dice: 0.8059  decode.d7.loss_cls: 0.2618  decode.d7.loss_mask: 1.0690  decode.d7.loss_dice: 0.8406  decode.d8.loss_cls: 0.2477  decode.d8.loss_mask: 1.0702  decode.d8.loss_dice: 0.8478
05/26 16:57:36 - mmengine - INFO - Iter(train) [ 51350/160000]  base_lr: 7.0586e-05 lr: 7.0586e-06  eta: 12:22:42  time: 0.4115  data_time: 0.0095  memory: 5979  grad_norm: 477.2863  loss: 23.8039  decode.loss_cls: 0.2181  decode.loss_mask: 1.2169  decode.loss_dice: 0.8653  decode.d0.loss_cls: 0.6826  decode.d0.loss_mask: 1.1773  decode.d0.loss_dice: 0.8895  decode.d1.loss_cls: 0.2477  decode.d1.loss_mask: 1.1956  decode.d1.loss_dice: 0.8567  decode.d2.loss_cls: 0.2556  decode.d2.loss_mask: 1.2059  decode.d2.loss_dice: 0.8633  decode.d3.loss_cls: 0.2592  decode.d3.loss_mask: 1.1777  decode.d3.loss_dice: 0.8748  decode.d4.loss_cls: 0.3113  decode.d4.loss_mask: 1.2306  decode.d4.loss_dice: 0.8870  decode.d5.loss_cls: 0.2587  decode.d5.loss_mask: 1.2471  decode.d5.loss_dice: 0.8823  decode.d6.loss_cls: 0.2586  decode.d6.loss_mask: 1.2422  decode.d6.loss_dice: 0.8889  decode.d7.loss_cls: 0.2469  decode.d7.loss_mask: 1.1930  decode.d7.loss_dice: 0.8681  decode.d8.loss_cls: 0.2432  decode.d8.loss_mask: 1.2020  decode.d8.loss_dice: 0.8576
05/26 16:57:57 - mmengine - INFO - Iter(train) [ 51400/160000]  base_lr: 7.0557e-05 lr: 7.0557e-06  eta: 12:22:21  time: 0.4128  data_time: 0.0094  memory: 5966  grad_norm: 622.9695  loss: 22.0261  decode.loss_cls: 0.1814  decode.loss_mask: 1.1702  decode.loss_dice: 0.7708  decode.d0.loss_cls: 0.7581  decode.d0.loss_mask: 1.0851  decode.d0.loss_dice: 0.7189  decode.d1.loss_cls: 0.2511  decode.d1.loss_mask: 1.1687  decode.d1.loss_dice: 0.7718  decode.d2.loss_cls: 0.2317  decode.d2.loss_mask: 1.1339  decode.d2.loss_dice: 0.7553  decode.d3.loss_cls: 0.2451  decode.d3.loss_mask: 1.1394  decode.d3.loss_dice: 0.7396  decode.d4.loss_cls: 0.2004  decode.d4.loss_mask: 1.1966  decode.d4.loss_dice: 0.8144  decode.d5.loss_cls: 0.2441  decode.d5.loss_mask: 1.1532  decode.d5.loss_dice: 0.7835  decode.d6.loss_cls: 0.1786  decode.d6.loss_mask: 1.2807  decode.d6.loss_dice: 0.8162  decode.d7.loss_cls: 0.2192  decode.d7.loss_mask: 1.1339  decode.d7.loss_dice: 0.7626  decode.d8.loss_cls: 0.1709  decode.d8.loss_mask: 1.1676  decode.d8.loss_dice: 0.7832
05/26 16:58:18 - mmengine - INFO - Iter(train) [ 51450/160000]  base_lr: 7.0528e-05 lr: 7.0528e-06  eta: 12:22:01  time: 0.4108  data_time: 0.0094  memory: 5969  grad_norm: 372.3103  loss: 20.0313  decode.loss_cls: 0.2552  decode.loss_mask: 0.9522  decode.loss_dice: 0.7711  decode.d0.loss_cls: 0.6789  decode.d0.loss_mask: 0.9105  decode.d0.loss_dice: 0.7179  decode.d1.loss_cls: 0.2929  decode.d1.loss_mask: 0.9405  decode.d1.loss_dice: 0.7109  decode.d2.loss_cls: 0.2896  decode.d2.loss_mask: 0.9423  decode.d2.loss_dice: 0.7267  decode.d3.loss_cls: 0.2525  decode.d3.loss_mask: 0.9818  decode.d3.loss_dice: 0.7325  decode.d4.loss_cls: 0.2626  decode.d4.loss_mask: 0.9569  decode.d4.loss_dice: 0.7687  decode.d5.loss_cls: 0.2355  decode.d5.loss_mask: 0.9524  decode.d5.loss_dice: 0.7467  decode.d6.loss_cls: 0.2682  decode.d6.loss_mask: 0.9756  decode.d6.loss_dice: 0.7643  decode.d7.loss_cls: 0.2398  decode.d7.loss_mask: 0.9888  decode.d7.loss_dice: 0.7745  decode.d8.loss_cls: 0.2340  decode.d8.loss_mask: 0.9555  decode.d8.loss_dice: 0.7520
05/26 16:58:38 - mmengine - INFO - Iter(train) [ 51500/160000]  base_lr: 7.0499e-05 lr: 7.0499e-06  eta: 12:21:41  time: 0.4119  data_time: 0.0094  memory: 5969  grad_norm: 623.2883  loss: 25.0563  decode.loss_cls: 0.2855  decode.loss_mask: 1.2402  decode.loss_dice: 0.8938  decode.d0.loss_cls: 0.8484  decode.d0.loss_mask: 1.2270  decode.d0.loss_dice: 0.8637  decode.d1.loss_cls: 0.3264  decode.d1.loss_mask: 1.2400  decode.d1.loss_dice: 0.8293  decode.d2.loss_cls: 0.3327  decode.d2.loss_mask: 1.2003  decode.d2.loss_dice: 0.8564  decode.d3.loss_cls: 0.3475  decode.d3.loss_mask: 1.2366  decode.d3.loss_dice: 0.8762  decode.d4.loss_cls: 0.4058  decode.d4.loss_mask: 1.2307  decode.d4.loss_dice: 0.8913  decode.d5.loss_cls: 0.3583  decode.d5.loss_mask: 1.2756  decode.d5.loss_dice: 0.8794  decode.d6.loss_cls: 0.3353  decode.d6.loss_mask: 1.2664  decode.d6.loss_dice: 0.8838  decode.d7.loss_cls: 0.3681  decode.d7.loss_mask: 1.2260  decode.d7.loss_dice: 0.9124  decode.d8.loss_cls: 0.3639  decode.d8.loss_mask: 1.2017  decode.d8.loss_dice: 0.8535
05/26 16:58:59 - mmengine - INFO - Iter(train) [ 51550/160000]  base_lr: 7.0469e-05 lr: 7.0469e-06  eta: 12:21:20  time: 0.4124  data_time: 0.0094  memory: 5976  grad_norm: 1013.1113  loss: 20.1194  decode.loss_cls: 0.1898  decode.loss_mask: 0.9835  decode.loss_dice: 0.7431  decode.d0.loss_cls: 0.6835  decode.d0.loss_mask: 1.0361  decode.d0.loss_dice: 0.7283  decode.d1.loss_cls: 0.2141  decode.d1.loss_mask: 1.0459  decode.d1.loss_dice: 0.7538  decode.d2.loss_cls: 0.2213  decode.d2.loss_mask: 1.0524  decode.d2.loss_dice: 0.7554  decode.d3.loss_cls: 0.1848  decode.d3.loss_mask: 0.9995  decode.d3.loss_dice: 0.7480  decode.d4.loss_cls: 0.2273  decode.d4.loss_mask: 1.0199  decode.d4.loss_dice: 0.7366  decode.d5.loss_cls: 0.1890  decode.d5.loss_mask: 0.9937  decode.d5.loss_dice: 0.7601  decode.d6.loss_cls: 0.2317  decode.d6.loss_mask: 0.9988  decode.d6.loss_dice: 0.7469  decode.d7.loss_cls: 0.2536  decode.d7.loss_mask: 0.9656  decode.d7.loss_dice: 0.7284  decode.d8.loss_cls: 0.2754  decode.d8.loss_mask: 0.9397  decode.d8.loss_dice: 0.7131
05/26 16:59:19 - mmengine - INFO - Iter(train) [ 51600/160000]  base_lr: 7.0440e-05 lr: 7.0440e-06  eta: 12:21:00  time: 0.4121  data_time: 0.0093  memory: 5968  grad_norm: 518.7466  loss: 22.2465  decode.loss_cls: 0.1951  decode.loss_mask: 1.0931  decode.loss_dice: 0.8808  decode.d0.loss_cls: 0.7452  decode.d0.loss_mask: 1.0241  decode.d0.loss_dice: 0.8908  decode.d1.loss_cls: 0.2251  decode.d1.loss_mask: 1.0392  decode.d1.loss_dice: 0.8382  decode.d2.loss_cls: 0.2382  decode.d2.loss_mask: 1.0734  decode.d2.loss_dice: 0.8802  decode.d3.loss_cls: 0.2262  decode.d3.loss_mask: 1.0734  decode.d3.loss_dice: 0.8698  decode.d4.loss_cls: 0.2258  decode.d4.loss_mask: 1.1085  decode.d4.loss_dice: 0.8878  decode.d5.loss_cls: 0.2117  decode.d5.loss_mask: 1.0851  decode.d5.loss_dice: 0.8735  decode.d6.loss_cls: 0.2064  decode.d6.loss_mask: 1.0824  decode.d6.loss_dice: 0.9000  decode.d7.loss_cls: 0.2360  decode.d7.loss_mask: 1.0694  decode.d7.loss_dice: 0.8888  decode.d8.loss_cls: 0.2213  decode.d8.loss_mask: 1.0786  decode.d8.loss_dice: 0.8783
05/26 16:59:40 - mmengine - INFO - Iter(train) [ 51650/160000]  base_lr: 7.0411e-05 lr: 7.0411e-06  eta: 12:20:40  time: 0.4128  data_time: 0.0094  memory: 5967  grad_norm: 542.2223  loss: 23.5320  decode.loss_cls: 0.3535  decode.loss_mask: 1.0888  decode.loss_dice: 0.8729  decode.d0.loss_cls: 0.8291  decode.d0.loss_mask: 1.0113  decode.d0.loss_dice: 0.7528  decode.d1.loss_cls: 0.4311  decode.d1.loss_mask: 1.0886  decode.d1.loss_dice: 0.8214  decode.d2.loss_cls: 0.3714  decode.d2.loss_mask: 1.0781  decode.d2.loss_dice: 0.8435  decode.d3.loss_cls: 0.4080  decode.d3.loss_mask: 1.1410  decode.d3.loss_dice: 0.8684  decode.d4.loss_cls: 0.4145  decode.d4.loss_mask: 1.0727  decode.d4.loss_dice: 0.8437  decode.d5.loss_cls: 0.3842  decode.d5.loss_mask: 1.0809  decode.d5.loss_dice: 0.8374  decode.d6.loss_cls: 0.3819  decode.d6.loss_mask: 1.0704  decode.d6.loss_dice: 0.8346  decode.d7.loss_cls: 0.3974  decode.d7.loss_mask: 1.0938  decode.d7.loss_dice: 0.8447  decode.d8.loss_cls: 0.4001  decode.d8.loss_mask: 1.0820  decode.d8.loss_dice: 0.8336
05/26 17:00:01 - mmengine - INFO - Iter(train) [ 51700/160000]  base_lr: 7.0382e-05 lr: 7.0382e-06  eta: 12:20:20  time: 0.4119  data_time: 0.0095  memory: 5965  grad_norm: 982.7031  loss: 24.9725  decode.loss_cls: 0.1992  decode.loss_mask: 1.2493  decode.loss_dice: 0.9896  decode.d0.loss_cls: 0.6239  decode.d0.loss_mask: 1.1764  decode.d0.loss_dice: 0.9616  decode.d1.loss_cls: 0.2270  decode.d1.loss_mask: 1.2448  decode.d1.loss_dice: 0.9737  decode.d2.loss_cls: 0.2599  decode.d2.loss_mask: 1.2488  decode.d2.loss_dice: 0.9624  decode.d3.loss_cls: 0.2677  decode.d3.loss_mask: 1.2711  decode.d3.loss_dice: 1.0042  decode.d4.loss_cls: 0.2927  decode.d4.loss_mask: 1.1986  decode.d4.loss_dice: 0.9585  decode.d5.loss_cls: 0.2160  decode.d5.loss_mask: 1.2484  decode.d5.loss_dice: 1.0164  decode.d6.loss_cls: 0.2512  decode.d6.loss_mask: 1.2424  decode.d6.loss_dice: 0.9613  decode.d7.loss_cls: 0.2363  decode.d7.loss_mask: 1.2349  decode.d7.loss_dice: 0.9505  decode.d8.loss_cls: 0.2441  decode.d8.loss_mask: 1.2696  decode.d8.loss_dice: 0.9921
05/26 17:00:21 - mmengine - INFO - Iter(train) [ 51750/160000]  base_lr: 7.0353e-05 lr: 7.0353e-06  eta: 12:19:59  time: 0.4118  data_time: 0.0094  memory: 5975  grad_norm: 684.6522  loss: 22.3996  decode.loss_cls: 0.1894  decode.loss_mask: 1.1396  decode.loss_dice: 0.7869  decode.d0.loss_cls: 0.7162  decode.d0.loss_mask: 1.1441  decode.d0.loss_dice: 0.7692  decode.d1.loss_cls: 0.2409  decode.d1.loss_mask: 1.1710  decode.d1.loss_dice: 0.7923  decode.d2.loss_cls: 0.1720  decode.d2.loss_mask: 1.1682  decode.d2.loss_dice: 0.7978  decode.d3.loss_cls: 0.1869  decode.d3.loss_mask: 1.1641  decode.d3.loss_dice: 0.8213  decode.d4.loss_cls: 0.1829  decode.d4.loss_mask: 1.2307  decode.d4.loss_dice: 0.8807  decode.d5.loss_cls: 0.1992  decode.d5.loss_mask: 1.1971  decode.d5.loss_dice: 0.8631  decode.d6.loss_cls: 0.2211  decode.d6.loss_mask: 1.1702  decode.d6.loss_dice: 0.8211  decode.d7.loss_cls: 0.2099  decode.d7.loss_mask: 1.1934  decode.d7.loss_dice: 0.8115  decode.d8.loss_cls: 0.2069  decode.d8.loss_mask: 1.1362  decode.d8.loss_dice: 0.8156
05/26 17:00:42 - mmengine - INFO - Iter(train) [ 51800/160000]  base_lr: 7.0323e-05 lr: 7.0323e-06  eta: 12:19:39  time: 0.4119  data_time: 0.0094  memory: 5987  grad_norm: 641.8363  loss: 24.9372  decode.loss_cls: 0.3192  decode.loss_mask: 1.1931  decode.loss_dice: 0.9108  decode.d0.loss_cls: 0.8521  decode.d0.loss_mask: 1.1408  decode.d0.loss_dice: 0.8990  decode.d1.loss_cls: 0.3685  decode.d1.loss_mask: 1.1574  decode.d1.loss_dice: 0.9260  decode.d2.loss_cls: 0.3706  decode.d2.loss_mask: 1.1707  decode.d2.loss_dice: 0.8894  decode.d3.loss_cls: 0.3176  decode.d3.loss_mask: 1.2193  decode.d3.loss_dice: 0.9251  decode.d4.loss_cls: 0.3296  decode.d4.loss_mask: 1.2224  decode.d4.loss_dice: 0.9870  decode.d5.loss_cls: 0.3417  decode.d5.loss_mask: 1.1750  decode.d5.loss_dice: 0.8954  decode.d6.loss_cls: 0.3728  decode.d6.loss_mask: 1.1817  decode.d6.loss_dice: 0.9020  decode.d7.loss_cls: 0.3799  decode.d7.loss_mask: 1.1830  decode.d7.loss_dice: 0.9085  decode.d8.loss_cls: 0.3334  decode.d8.loss_mask: 1.1774  decode.d8.loss_dice: 0.8879
05/26 17:01:03 - mmengine - INFO - Iter(train) [ 51850/160000]  base_lr: 7.0294e-05 lr: 7.0294e-06  eta: 12:19:19  time: 0.4119  data_time: 0.0094  memory: 5976  grad_norm: 557.1654  loss: 24.5291  decode.loss_cls: 0.2009  decode.loss_mask: 1.2738  decode.loss_dice: 0.9382  decode.d0.loss_cls: 0.7389  decode.d0.loss_mask: 1.2453  decode.d0.loss_dice: 0.8937  decode.d1.loss_cls: 0.2944  decode.d1.loss_mask: 1.2195  decode.d1.loss_dice: 0.8939  decode.d2.loss_cls: 0.3058  decode.d2.loss_mask: 1.2227  decode.d2.loss_dice: 0.9071  decode.d3.loss_cls: 0.3005  decode.d3.loss_mask: 1.2339  decode.d3.loss_dice: 0.8953  decode.d4.loss_cls: 0.2801  decode.d4.loss_mask: 1.2535  decode.d4.loss_dice: 0.9022  decode.d5.loss_cls: 0.2429  decode.d5.loss_mask: 1.1989  decode.d5.loss_dice: 0.8888  decode.d6.loss_cls: 0.2539  decode.d6.loss_mask: 1.2159  decode.d6.loss_dice: 0.8981  decode.d7.loss_cls: 0.2682  decode.d7.loss_mask: 1.2168  decode.d7.loss_dice: 0.9083  decode.d8.loss_cls: 0.3110  decode.d8.loss_mask: 1.2314  decode.d8.loss_dice: 0.8950
05/26 17:01:23 - mmengine - INFO - Iter(train) [ 51900/160000]  base_lr: 7.0265e-05 lr: 7.0265e-06  eta: 12:18:58  time: 0.4216  data_time: 0.0097  memory: 5971  grad_norm: 649.0637  loss: 25.9947  decode.loss_cls: 0.2353  decode.loss_mask: 1.3779  decode.loss_dice: 0.8787  decode.d0.loss_cls: 0.8207  decode.d0.loss_mask: 1.2881  decode.d0.loss_dice: 0.8567  decode.d1.loss_cls: 0.2419  decode.d1.loss_mask: 1.3916  decode.d1.loss_dice: 0.9423  decode.d2.loss_cls: 0.2859  decode.d2.loss_mask: 1.3854  decode.d2.loss_dice: 0.8823  decode.d3.loss_cls: 0.2612  decode.d3.loss_mask: 1.3846  decode.d3.loss_dice: 0.8911  decode.d4.loss_cls: 0.3005  decode.d4.loss_mask: 1.4414  decode.d4.loss_dice: 0.9285  decode.d5.loss_cls: 0.2614  decode.d5.loss_mask: 1.4050  decode.d5.loss_dice: 0.9084  decode.d6.loss_cls: 0.2813  decode.d6.loss_mask: 1.3787  decode.d6.loss_dice: 0.8892  decode.d7.loss_cls: 0.2808  decode.d7.loss_mask: 1.3843  decode.d7.loss_dice: 0.8863  decode.d8.loss_cls: 0.2788  decode.d8.loss_mask: 1.3781  decode.d8.loss_dice: 0.8683
05/26 17:01:44 - mmengine - INFO - Iter(train) [ 51950/160000]  base_lr: 7.0236e-05 lr: 7.0236e-06  eta: 12:18:39  time: 0.4214  data_time: 0.0098  memory: 5981  grad_norm: 565.7444  loss: 22.9142  decode.loss_cls: 0.2476  decode.loss_mask: 1.2217  decode.loss_dice: 0.7805  decode.d0.loss_cls: 0.7154  decode.d0.loss_mask: 1.1728  decode.d0.loss_dice: 0.7756  decode.d1.loss_cls: 0.2591  decode.d1.loss_mask: 1.1695  decode.d1.loss_dice: 0.7930  decode.d2.loss_cls: 0.2877  decode.d2.loss_mask: 1.1763  decode.d2.loss_dice: 0.7633  decode.d3.loss_cls: 0.3012  decode.d3.loss_mask: 1.2006  decode.d3.loss_dice: 0.7848  decode.d4.loss_cls: 0.2398  decode.d4.loss_mask: 1.2493  decode.d4.loss_dice: 0.8002  decode.d5.loss_cls: 0.2804  decode.d5.loss_mask: 1.2070  decode.d5.loss_dice: 0.7897  decode.d6.loss_cls: 0.3504  decode.d6.loss_mask: 1.1263  decode.d6.loss_dice: 0.7617  decode.d7.loss_cls: 0.2635  decode.d7.loss_mask: 1.1788  decode.d7.loss_dice: 0.7759  decode.d8.loss_cls: 0.2358  decode.d8.loss_mask: 1.2162  decode.d8.loss_dice: 0.7901
05/26 17:02:06 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 17:02:06 - mmengine - INFO - Iter(train) [ 52000/160000]  base_lr: 7.0206e-05 lr: 7.0206e-06  eta: 12:18:20  time: 0.4190  data_time: 0.0098  memory: 5971  grad_norm: 466.3051  loss: 18.9839  decode.loss_cls: 0.1661  decode.loss_mask: 1.0277  decode.loss_dice: 0.6617  decode.d0.loss_cls: 0.5999  decode.d0.loss_mask: 1.0202  decode.d0.loss_dice: 0.6681  decode.d1.loss_cls: 0.1264  decode.d1.loss_mask: 1.0739  decode.d1.loss_dice: 0.6703  decode.d2.loss_cls: 0.1681  decode.d2.loss_mask: 1.0087  decode.d2.loss_dice: 0.6502  decode.d3.loss_cls: 0.1605  decode.d3.loss_mask: 1.0476  decode.d3.loss_dice: 0.6641  decode.d4.loss_cls: 0.1751  decode.d4.loss_mask: 1.0148  decode.d4.loss_dice: 0.6646  decode.d5.loss_cls: 0.1807  decode.d5.loss_mask: 1.0059  decode.d5.loss_dice: 0.6517  decode.d6.loss_cls: 0.1515  decode.d6.loss_mask: 1.0316  decode.d6.loss_dice: 0.6541  decode.d7.loss_cls: 0.1834  decode.d7.loss_mask: 1.0266  decode.d7.loss_dice: 0.6328  decode.d8.loss_cls: 0.1337  decode.d8.loss_mask: 1.0664  decode.d8.loss_dice: 0.6974
05/26 17:02:26 - mmengine - INFO - Iter(train) [ 52050/160000]  base_lr: 7.0177e-05 lr: 7.0177e-06  eta: 12:18:00  time: 0.4143  data_time: 0.0096  memory: 5969  grad_norm: 811.9266  loss: 24.5157  decode.loss_cls: 0.2072  decode.loss_mask: 1.3101  decode.loss_dice: 0.8668  decode.d0.loss_cls: 0.8250  decode.d0.loss_mask: 1.2636  decode.d0.loss_dice: 0.8406  decode.d1.loss_cls: 0.2845  decode.d1.loss_mask: 1.2771  decode.d1.loss_dice: 0.8368  decode.d2.loss_cls: 0.2506  decode.d2.loss_mask: 1.2912  decode.d2.loss_dice: 0.8644  decode.d3.loss_cls: 0.2298  decode.d3.loss_mask: 1.2847  decode.d3.loss_dice: 0.8482  decode.d4.loss_cls: 0.2361  decode.d4.loss_mask: 1.3150  decode.d4.loss_dice: 0.8483  decode.d5.loss_cls: 0.2448  decode.d5.loss_mask: 1.3144  decode.d5.loss_dice: 0.8926  decode.d6.loss_cls: 0.2241  decode.d6.loss_mask: 1.3063  decode.d6.loss_dice: 0.8467  decode.d7.loss_cls: 0.2681  decode.d7.loss_mask: 1.2848  decode.d7.loss_dice: 0.8547  decode.d8.loss_cls: 0.2565  decode.d8.loss_mask: 1.2884  decode.d8.loss_dice: 0.8545
05/26 17:02:47 - mmengine - INFO - Iter(train) [ 52100/160000]  base_lr: 7.0148e-05 lr: 7.0148e-06  eta: 12:17:40  time: 0.4155  data_time: 0.0096  memory: 5966  grad_norm: 634.6990  loss: 24.4625  decode.loss_cls: 0.3796  decode.loss_mask: 1.0568  decode.loss_dice: 0.9775  decode.d0.loss_cls: 0.7623  decode.d0.loss_mask: 0.9840  decode.d0.loss_dice: 0.9552  decode.d1.loss_cls: 0.3440  decode.d1.loss_mask: 1.0833  decode.d1.loss_dice: 0.9450  decode.d2.loss_cls: 0.3314  decode.d2.loss_mask: 1.1108  decode.d2.loss_dice: 0.9882  decode.d3.loss_cls: 0.3711  decode.d3.loss_mask: 1.0605  decode.d3.loss_dice: 0.9650  decode.d4.loss_cls: 0.3882  decode.d4.loss_mask: 1.0714  decode.d4.loss_dice: 0.9697  decode.d5.loss_cls: 0.3581  decode.d5.loss_mask: 1.1022  decode.d5.loss_dice: 1.0076  decode.d6.loss_cls: 0.3380  decode.d6.loss_mask: 1.0862  decode.d6.loss_dice: 0.9909  decode.d7.loss_cls: 0.3814  decode.d7.loss_mask: 1.0579  decode.d7.loss_dice: 0.9651  decode.d8.loss_cls: 0.3533  decode.d8.loss_mask: 1.0921  decode.d8.loss_dice: 0.9857
05/26 17:03:08 - mmengine - INFO - Iter(train) [ 52150/160000]  base_lr: 7.0118e-05 lr: 7.0118e-06  eta: 12:17:20  time: 0.4151  data_time: 0.0096  memory: 5970  grad_norm: 498.4663  loss: 18.7151  decode.loss_cls: 0.1379  decode.loss_mask: 1.0188  decode.loss_dice: 0.7110  decode.d0.loss_cls: 0.7001  decode.d0.loss_mask: 0.9180  decode.d0.loss_dice: 0.6182  decode.d1.loss_cls: 0.2398  decode.d1.loss_mask: 0.9643  decode.d1.loss_dice: 0.6431  decode.d2.loss_cls: 0.1992  decode.d2.loss_mask: 0.9391  decode.d2.loss_dice: 0.6370  decode.d3.loss_cls: 0.2076  decode.d3.loss_mask: 0.9722  decode.d3.loss_dice: 0.6444  decode.d4.loss_cls: 0.2167  decode.d4.loss_mask: 0.9817  decode.d4.loss_dice: 0.6440  decode.d5.loss_cls: 0.1990  decode.d5.loss_mask: 0.9584  decode.d5.loss_dice: 0.6635  decode.d6.loss_cls: 0.2277  decode.d6.loss_mask: 0.9470  decode.d6.loss_dice: 0.6395  decode.d7.loss_cls: 0.2318  decode.d7.loss_mask: 0.9670  decode.d7.loss_dice: 0.6463  decode.d8.loss_cls: 0.1841  decode.d8.loss_mask: 0.9799  decode.d8.loss_dice: 0.6778
05/26 17:03:29 - mmengine - INFO - Iter(train) [ 52200/160000]  base_lr: 7.0089e-05 lr: 7.0089e-06  eta: 12:17:00  time: 0.4158  data_time: 0.0098  memory: 5968  grad_norm: 589.6231  loss: 24.7462  decode.loss_cls: 0.3363  decode.loss_mask: 1.1020  decode.loss_dice: 0.9338  decode.d0.loss_cls: 0.9173  decode.d0.loss_mask: 1.0965  decode.d0.loss_dice: 0.9141  decode.d1.loss_cls: 0.3361  decode.d1.loss_mask: 1.1688  decode.d1.loss_dice: 0.9329  decode.d2.loss_cls: 0.3531  decode.d2.loss_mask: 1.1310  decode.d2.loss_dice: 0.9632  decode.d3.loss_cls: 0.3238  decode.d3.loss_mask: 1.1514  decode.d3.loss_dice: 0.9984  decode.d4.loss_cls: 0.3543  decode.d4.loss_mask: 1.1350  decode.d4.loss_dice: 0.9911  decode.d5.loss_cls: 0.3548  decode.d5.loss_mask: 1.1145  decode.d5.loss_dice: 0.9298  decode.d6.loss_cls: 0.2692  decode.d6.loss_mask: 1.1866  decode.d6.loss_dice: 1.0023  decode.d7.loss_cls: 0.3424  decode.d7.loss_mask: 1.0940  decode.d7.loss_dice: 0.9259  decode.d8.loss_cls: 0.3351  decode.d8.loss_mask: 1.1244  decode.d8.loss_dice: 0.9283
05/26 17:03:50 - mmengine - INFO - Iter(train) [ 52250/160000]  base_lr: 7.0060e-05 lr: 7.0060e-06  eta: 12:16:40  time: 0.4157  data_time: 0.0095  memory: 5967  grad_norm: 852.6157  loss: 24.9242  decode.loss_cls: 0.4256  decode.loss_mask: 1.2156  decode.loss_dice: 0.8086  decode.d0.loss_cls: 0.9216  decode.d0.loss_mask: 1.1182  decode.d0.loss_dice: 0.8167  decode.d1.loss_cls: 0.4167  decode.d1.loss_mask: 1.2329  decode.d1.loss_dice: 0.8002  decode.d2.loss_cls: 0.4301  decode.d2.loss_mask: 1.1987  decode.d2.loss_dice: 0.7780  decode.d3.loss_cls: 0.3695  decode.d3.loss_mask: 1.2280  decode.d3.loss_dice: 0.8013  decode.d4.loss_cls: 0.4316  decode.d4.loss_mask: 1.2310  decode.d4.loss_dice: 0.8068  decode.d5.loss_cls: 0.4075  decode.d5.loss_mask: 1.2502  decode.d5.loss_dice: 0.8318  decode.d6.loss_cls: 0.4690  decode.d6.loss_mask: 1.1980  decode.d6.loss_dice: 0.8235  decode.d7.loss_cls: 0.4061  decode.d7.loss_mask: 1.2391  decode.d7.loss_dice: 0.8390  decode.d8.loss_cls: 0.4092  decode.d8.loss_mask: 1.2352  decode.d8.loss_dice: 0.7847
05/26 17:04:10 - mmengine - INFO - Iter(train) [ 52300/160000]  base_lr: 7.0031e-05 lr: 7.0031e-06  eta: 12:16:20  time: 0.4151  data_time: 0.0096  memory: 5974  grad_norm: 481.5460  loss: 21.5549  decode.loss_cls: 0.1455  decode.loss_mask: 1.1281  decode.loss_dice: 0.7968  decode.d0.loss_cls: 0.6274  decode.d0.loss_mask: 1.1038  decode.d0.loss_dice: 0.7922  decode.d1.loss_cls: 0.1781  decode.d1.loss_mask: 1.1092  decode.d1.loss_dice: 0.8098  decode.d2.loss_cls: 0.1960  decode.d2.loss_mask: 1.1220  decode.d2.loss_dice: 0.8105  decode.d3.loss_cls: 0.1661  decode.d3.loss_mask: 1.1486  decode.d3.loss_dice: 0.8188  decode.d4.loss_cls: 0.1790  decode.d4.loss_mask: 1.1195  decode.d4.loss_dice: 0.8169  decode.d5.loss_cls: 0.1540  decode.d5.loss_mask: 1.1369  decode.d5.loss_dice: 0.7970  decode.d6.loss_cls: 0.1722  decode.d6.loss_mask: 1.1579  decode.d6.loss_dice: 0.8194  decode.d7.loss_cls: 0.1615  decode.d7.loss_mask: 1.1473  decode.d7.loss_dice: 0.8356  decode.d8.loss_cls: 0.1538  decode.d8.loss_mask: 1.1328  decode.d8.loss_dice: 0.8182
05/26 17:04:31 - mmengine - INFO - Iter(train) [ 52350/160000]  base_lr: 7.0001e-05 lr: 7.0001e-06  eta: 12:16:00  time: 0.4163  data_time: 0.0098  memory: 5975  grad_norm: 391.5678  loss: 20.6975  decode.loss_cls: 0.1872  decode.loss_mask: 1.0809  decode.loss_dice: 0.7725  decode.d0.loss_cls: 0.6789  decode.d0.loss_mask: 0.9992  decode.d0.loss_dice: 0.7557  decode.d1.loss_cls: 0.2550  decode.d1.loss_mask: 0.9885  decode.d1.loss_dice: 0.7554  decode.d2.loss_cls: 0.2255  decode.d2.loss_mask: 0.9897  decode.d2.loss_dice: 0.7646  decode.d3.loss_cls: 0.2532  decode.d3.loss_mask: 1.0000  decode.d3.loss_dice: 0.7647  decode.d4.loss_cls: 0.2563  decode.d4.loss_mask: 1.0394  decode.d4.loss_dice: 0.7522  decode.d5.loss_cls: 0.2512  decode.d5.loss_mask: 1.0148  decode.d5.loss_dice: 0.7850  decode.d6.loss_cls: 0.2283  decode.d6.loss_mask: 1.0344  decode.d6.loss_dice: 0.7800  decode.d7.loss_cls: 0.2282  decode.d7.loss_mask: 1.0708  decode.d7.loss_dice: 0.7967  decode.d8.loss_cls: 0.2319  decode.d8.loss_mask: 0.9911  decode.d8.loss_dice: 0.7660
05/26 17:04:52 - mmengine - INFO - Iter(train) [ 52400/160000]  base_lr: 6.9972e-05 lr: 6.9972e-06  eta: 12:15:40  time: 0.4146  data_time: 0.0096  memory: 5968  grad_norm: 517.2458  loss: 23.5429  decode.loss_cls: 0.2672  decode.loss_mask: 1.1531  decode.loss_dice: 0.9050  decode.d0.loss_cls: 0.8977  decode.d0.loss_mask: 1.0640  decode.d0.loss_dice: 0.8658  decode.d1.loss_cls: 0.2877  decode.d1.loss_mask: 1.1663  decode.d1.loss_dice: 0.8847  decode.d2.loss_cls: 0.2870  decode.d2.loss_mask: 1.1621  decode.d2.loss_dice: 0.8651  decode.d3.loss_cls: 0.2927  decode.d3.loss_mask: 1.1160  decode.d3.loss_dice: 0.8915  decode.d4.loss_cls: 0.2770  decode.d4.loss_mask: 1.1002  decode.d4.loss_dice: 0.8809  decode.d5.loss_cls: 0.3036  decode.d5.loss_mask: 1.0774  decode.d5.loss_dice: 0.8945  decode.d6.loss_cls: 0.2832  decode.d6.loss_mask: 1.1153  decode.d6.loss_dice: 0.9014  decode.d7.loss_cls: 0.2867  decode.d7.loss_mask: 1.1098  decode.d7.loss_dice: 0.9246  decode.d8.loss_cls: 0.2733  decode.d8.loss_mask: 1.1057  decode.d8.loss_dice: 0.9035
05/26 17:05:13 - mmengine - INFO - Iter(train) [ 52450/160000]  base_lr: 6.9943e-05 lr: 6.9943e-06  eta: 12:15:21  time: 0.4156  data_time: 0.0096  memory: 5974  grad_norm: 647.3374  loss: 24.1253  decode.loss_cls: 0.4568  decode.loss_mask: 1.0994  decode.loss_dice: 0.7735  decode.d0.loss_cls: 0.9722  decode.d0.loss_mask: 1.0434  decode.d0.loss_dice: 0.7439  decode.d1.loss_cls: 0.5060  decode.d1.loss_mask: 1.0665  decode.d1.loss_dice: 0.7797  decode.d2.loss_cls: 0.4639  decode.d2.loss_mask: 1.1308  decode.d2.loss_dice: 0.7975  decode.d3.loss_cls: 0.4460  decode.d3.loss_mask: 1.0779  decode.d3.loss_dice: 0.7908  decode.d4.loss_cls: 0.4473  decode.d4.loss_mask: 1.0735  decode.d4.loss_dice: 0.7936  decode.d5.loss_cls: 0.4728  decode.d5.loss_mask: 1.1288  decode.d5.loss_dice: 0.8391  decode.d6.loss_cls: 0.4913  decode.d6.loss_mask: 1.0999  decode.d6.loss_dice: 0.8218  decode.d7.loss_cls: 0.4696  decode.d7.loss_mask: 1.1100  decode.d7.loss_dice: 0.8390  decode.d8.loss_cls: 0.4440  decode.d8.loss_mask: 1.1282  decode.d8.loss_dice: 0.8182
05/26 17:05:33 - mmengine - INFO - Iter(train) [ 52500/160000]  base_lr: 6.9914e-05 lr: 6.9914e-06  eta: 12:15:01  time: 0.4159  data_time: 0.0096  memory: 5966  grad_norm: 539.4094  loss: 20.9665  decode.loss_cls: 0.2724  decode.loss_mask: 1.0568  decode.loss_dice: 0.7159  decode.d0.loss_cls: 0.7051  decode.d0.loss_mask: 1.0164  decode.d0.loss_dice: 0.7089  decode.d1.loss_cls: 0.2488  decode.d1.loss_mask: 1.1012  decode.d1.loss_dice: 0.7250  decode.d2.loss_cls: 0.2745  decode.d2.loss_mask: 1.1176  decode.d2.loss_dice: 0.6876  decode.d3.loss_cls: 0.2509  decode.d3.loss_mask: 1.0844  decode.d3.loss_dice: 0.7086  decode.d4.loss_cls: 0.2830  decode.d4.loss_mask: 1.0938  decode.d4.loss_dice: 0.7088  decode.d5.loss_cls: 0.2625  decode.d5.loss_mask: 1.0907  decode.d5.loss_dice: 0.6932  decode.d6.loss_cls: 0.3116  decode.d6.loss_mask: 1.0687  decode.d6.loss_dice: 0.7082  decode.d7.loss_cls: 0.2278  decode.d7.loss_mask: 1.0791  decode.d7.loss_dice: 0.7290  decode.d8.loss_cls: 0.2539  decode.d8.loss_mask: 1.0815  decode.d8.loss_dice: 0.7006
05/26 17:05:54 - mmengine - INFO - Iter(train) [ 52550/160000]  base_lr: 6.9884e-05 lr: 6.9884e-06  eta: 12:14:40  time: 0.4140  data_time: 0.0096  memory: 5976  grad_norm: 555.9546  loss: 23.3410  decode.loss_cls: 0.2948  decode.loss_mask: 1.1728  decode.loss_dice: 0.8193  decode.d0.loss_cls: 0.7677  decode.d0.loss_mask: 1.1260  decode.d0.loss_dice: 0.8190  decode.d1.loss_cls: 0.2595  decode.d1.loss_mask: 1.2206  decode.d1.loss_dice: 0.8373  decode.d2.loss_cls: 0.2777  decode.d2.loss_mask: 1.1831  decode.d2.loss_dice: 0.8244  decode.d3.loss_cls: 0.2741  decode.d3.loss_mask: 1.1523  decode.d3.loss_dice: 0.8046  decode.d4.loss_cls: 0.2748  decode.d4.loss_mask: 1.1753  decode.d4.loss_dice: 0.8197  decode.d5.loss_cls: 0.2803  decode.d5.loss_mask: 1.2146  decode.d5.loss_dice: 0.8421  decode.d6.loss_cls: 0.2739  decode.d6.loss_mask: 1.1525  decode.d6.loss_dice: 0.8327  decode.d7.loss_cls: 0.2952  decode.d7.loss_mask: 1.1970  decode.d7.loss_dice: 0.8272  decode.d8.loss_cls: 0.2974  decode.d8.loss_mask: 1.1860  decode.d8.loss_dice: 0.8391
05/26 17:06:15 - mmengine - INFO - Iter(train) [ 52600/160000]  base_lr: 6.9855e-05 lr: 6.9855e-06  eta: 12:14:21  time: 0.4164  data_time: 0.0096  memory: 5965  grad_norm: 404.8404  loss: 22.5197  decode.loss_cls: 0.2193  decode.loss_mask: 1.2216  decode.loss_dice: 0.8242  decode.d0.loss_cls: 0.6706  decode.d0.loss_mask: 1.1464  decode.d0.loss_dice: 0.8251  decode.d1.loss_cls: 0.1549  decode.d1.loss_mask: 1.2237  decode.d1.loss_dice: 0.8460  decode.d2.loss_cls: 0.1766  decode.d2.loss_mask: 1.2005  decode.d2.loss_dice: 0.8017  decode.d3.loss_cls: 0.1644  decode.d3.loss_mask: 1.2358  decode.d3.loss_dice: 0.8324  decode.d4.loss_cls: 0.1745  decode.d4.loss_mask: 1.1966  decode.d4.loss_dice: 0.8127  decode.d5.loss_cls: 0.1826  decode.d5.loss_mask: 1.2173  decode.d5.loss_dice: 0.8170  decode.d6.loss_cls: 0.1795  decode.d6.loss_mask: 1.2266  decode.d6.loss_dice: 0.8223  decode.d7.loss_cls: 0.1711  decode.d7.loss_mask: 1.2005  decode.d7.loss_dice: 0.8141  decode.d8.loss_cls: 0.1612  decode.d8.loss_mask: 1.2060  decode.d8.loss_dice: 0.7941
05/26 17:06:36 - mmengine - INFO - Iter(train) [ 52650/160000]  base_lr: 6.9826e-05 lr: 6.9826e-06  eta: 12:14:01  time: 0.4158  data_time: 0.0097  memory: 5966  grad_norm: 914.7393  loss: 24.7585  decode.loss_cls: 0.2859  decode.loss_mask: 1.2567  decode.loss_dice: 0.8998  decode.d0.loss_cls: 0.8815  decode.d0.loss_mask: 1.1522  decode.d0.loss_dice: 0.8260  decode.d1.loss_cls: 0.2950  decode.d1.loss_mask: 1.2238  decode.d1.loss_dice: 0.9030  decode.d2.loss_cls: 0.2918  decode.d2.loss_mask: 1.2381  decode.d2.loss_dice: 0.8983  decode.d3.loss_cls: 0.3102  decode.d3.loss_mask: 1.2612  decode.d3.loss_dice: 0.8935  decode.d4.loss_cls: 0.3094  decode.d4.loss_mask: 1.2575  decode.d4.loss_dice: 0.8887  decode.d5.loss_cls: 0.2864  decode.d5.loss_mask: 1.2255  decode.d5.loss_dice: 0.8726  decode.d6.loss_cls: 0.2601  decode.d6.loss_mask: 1.2767  decode.d6.loss_dice: 0.9276  decode.d7.loss_cls: 0.2745  decode.d7.loss_mask: 1.2443  decode.d7.loss_dice: 0.8740  decode.d8.loss_cls: 0.2982  decode.d8.loss_mask: 1.2458  decode.d8.loss_dice: 0.9002
05/26 17:06:57 - mmengine - INFO - Iter(train) [ 52700/160000]  base_lr: 6.9797e-05 lr: 6.9797e-06  eta: 12:13:41  time: 0.4155  data_time: 0.0096  memory: 5969  grad_norm: 598.2358  loss: 24.9119  decode.loss_cls: 0.3332  decode.loss_mask: 1.1753  decode.loss_dice: 0.9348  decode.d0.loss_cls: 0.7897  decode.d0.loss_mask: 1.1729  decode.d0.loss_dice: 0.9614  decode.d1.loss_cls: 0.3003  decode.d1.loss_mask: 1.1650  decode.d1.loss_dice: 0.9232  decode.d2.loss_cls: 0.3474  decode.d2.loss_mask: 1.1337  decode.d2.loss_dice: 0.9115  decode.d3.loss_cls: 0.3061  decode.d3.loss_mask: 1.1588  decode.d3.loss_dice: 0.9177  decode.d4.loss_cls: 0.3667  decode.d4.loss_mask: 1.1568  decode.d4.loss_dice: 0.9378  decode.d5.loss_cls: 0.3232  decode.d5.loss_mask: 1.2044  decode.d5.loss_dice: 0.9516  decode.d6.loss_cls: 0.3411  decode.d6.loss_mask: 1.1811  decode.d6.loss_dice: 0.9592  decode.d7.loss_cls: 0.3648  decode.d7.loss_mask: 1.1893  decode.d7.loss_dice: 0.9428  decode.d8.loss_cls: 0.3410  decode.d8.loss_mask: 1.1994  decode.d8.loss_dice: 0.9217
05/26 17:07:17 - mmengine - INFO - Iter(train) [ 52750/160000]  base_lr: 6.9767e-05 lr: 6.9767e-06  eta: 12:13:21  time: 0.4169  data_time: 0.0097  memory: 5976  grad_norm: 353.2117  loss: 19.2404  decode.loss_cls: 0.2205  decode.loss_mask: 0.9447  decode.loss_dice: 0.6956  decode.d0.loss_cls: 0.6782  decode.d0.loss_mask: 0.9269  decode.d0.loss_dice: 0.7364  decode.d1.loss_cls: 0.2637  decode.d1.loss_mask: 0.9332  decode.d1.loss_dice: 0.7125  decode.d2.loss_cls: 0.2639  decode.d2.loss_mask: 0.9135  decode.d2.loss_dice: 0.6898  decode.d3.loss_cls: 0.2420  decode.d3.loss_mask: 0.9339  decode.d3.loss_dice: 0.7018  decode.d4.loss_cls: 0.2388  decode.d4.loss_mask: 0.9186  decode.d4.loss_dice: 0.6886  decode.d5.loss_cls: 0.2409  decode.d5.loss_mask: 0.9194  decode.d5.loss_dice: 0.6964  decode.d6.loss_cls: 0.2780  decode.d6.loss_mask: 0.9290  decode.d6.loss_dice: 0.7344  decode.d7.loss_cls: 0.2139  decode.d7.loss_mask: 0.9385  decode.d7.loss_dice: 0.7338  decode.d8.loss_cls: 0.2390  decode.d8.loss_mask: 0.9229  decode.d8.loss_dice: 0.6914
05/26 17:07:38 - mmengine - INFO - Iter(train) [ 52800/160000]  base_lr: 6.9738e-05 lr: 6.9738e-06  eta: 12:13:01  time: 0.4164  data_time: 0.0097  memory: 5975  grad_norm: 704.3615  loss: 20.3886  decode.loss_cls: 0.2820  decode.loss_mask: 0.9681  decode.loss_dice: 0.7544  decode.d0.loss_cls: 0.7155  decode.d0.loss_mask: 0.9475  decode.d0.loss_dice: 0.7269  decode.d1.loss_cls: 0.2549  decode.d1.loss_mask: 1.0383  decode.d1.loss_dice: 0.7311  decode.d2.loss_cls: 0.2718  decode.d2.loss_mask: 0.9653  decode.d2.loss_dice: 0.6954  decode.d3.loss_cls: 0.2606  decode.d3.loss_mask: 0.9545  decode.d3.loss_dice: 0.6939  decode.d4.loss_cls: 0.2519  decode.d4.loss_mask: 1.0679  decode.d4.loss_dice: 0.7454  decode.d5.loss_cls: 0.3278  decode.d5.loss_mask: 0.9861  decode.d5.loss_dice: 0.6996  decode.d6.loss_cls: 0.2610  decode.d6.loss_mask: 1.0332  decode.d6.loss_dice: 0.7266  decode.d7.loss_cls: 0.2470  decode.d7.loss_mask: 0.9839  decode.d7.loss_dice: 0.7270  decode.d8.loss_cls: 0.2609  decode.d8.loss_mask: 1.0864  decode.d8.loss_dice: 0.7240
05/26 17:07:59 - mmengine - INFO - Iter(train) [ 52850/160000]  base_lr: 6.9709e-05 lr: 6.9709e-06  eta: 12:12:41  time: 0.4163  data_time: 0.0097  memory: 5968  grad_norm: 492.6386  loss: 22.9696  decode.loss_cls: 0.1616  decode.loss_mask: 1.2778  decode.loss_dice: 0.7945  decode.d0.loss_cls: 0.7317  decode.d0.loss_mask: 1.2381  decode.d0.loss_dice: 0.7303  decode.d1.loss_cls: 0.2307  decode.d1.loss_mask: 1.2927  decode.d1.loss_dice: 0.7979  decode.d2.loss_cls: 0.1719  decode.d2.loss_mask: 1.2777  decode.d2.loss_dice: 0.7906  decode.d3.loss_cls: 0.1772  decode.d3.loss_mask: 1.2826  decode.d3.loss_dice: 0.7973  decode.d4.loss_cls: 0.1561  decode.d4.loss_mask: 1.2730  decode.d4.loss_dice: 0.7733  decode.d5.loss_cls: 0.2029  decode.d5.loss_mask: 1.2715  decode.d5.loss_dice: 0.8104  decode.d6.loss_cls: 0.1911  decode.d6.loss_mask: 1.2755  decode.d6.loss_dice: 0.7708  decode.d7.loss_cls: 0.2057  decode.d7.loss_mask: 1.2905  decode.d7.loss_dice: 0.7895  decode.d8.loss_cls: 0.1323  decode.d8.loss_mask: 1.2921  decode.d8.loss_dice: 0.7821
05/26 17:08:20 - mmengine - INFO - Iter(train) [ 52900/160000]  base_lr: 6.9679e-05 lr: 6.9679e-06  eta: 12:12:21  time: 0.4189  data_time: 0.0107  memory: 5971  grad_norm: 442.4050  loss: 26.3207  decode.loss_cls: 0.2612  decode.loss_mask: 1.4055  decode.loss_dice: 0.9902  decode.d0.loss_cls: 0.8541  decode.d0.loss_mask: 1.2263  decode.d0.loss_dice: 0.8798  decode.d1.loss_cls: 0.3026  decode.d1.loss_mask: 1.2936  decode.d1.loss_dice: 0.9214  decode.d2.loss_cls: 0.3055  decode.d2.loss_mask: 1.3479  decode.d2.loss_dice: 0.9111  decode.d3.loss_cls: 0.2599  decode.d3.loss_mask: 1.3719  decode.d3.loss_dice: 0.9332  decode.d4.loss_cls: 0.3224  decode.d4.loss_mask: 1.3370  decode.d4.loss_dice: 0.9409  decode.d5.loss_cls: 0.3256  decode.d5.loss_mask: 1.3681  decode.d5.loss_dice: 0.9286  decode.d6.loss_cls: 0.3029  decode.d6.loss_mask: 1.3856  decode.d6.loss_dice: 0.9832  decode.d7.loss_cls: 0.2839  decode.d7.loss_mask: 1.3726  decode.d7.loss_dice: 0.9306  decode.d8.loss_cls: 0.3204  decode.d8.loss_mask: 1.3429  decode.d8.loss_dice: 0.9118
05/26 17:08:41 - mmengine - INFO - Iter(train) [ 52950/160000]  base_lr: 6.9650e-05 lr: 6.9650e-06  eta: 12:12:02  time: 0.4184  data_time: 0.0096  memory: 5966  grad_norm: 678.0191  loss: 21.3511  decode.loss_cls: 0.1678  decode.loss_mask: 1.1266  decode.loss_dice: 0.7913  decode.d0.loss_cls: 0.6862  decode.d0.loss_mask: 1.0188  decode.d0.loss_dice: 0.7263  decode.d1.loss_cls: 0.2075  decode.d1.loss_mask: 1.1659  decode.d1.loss_dice: 0.7708  decode.d2.loss_cls: 0.1983  decode.d2.loss_mask: 1.0704  decode.d2.loss_dice: 0.7655  decode.d3.loss_cls: 0.2111  decode.d3.loss_mask: 1.0797  decode.d3.loss_dice: 0.7697  decode.d4.loss_cls: 0.2598  decode.d4.loss_mask: 1.1758  decode.d4.loss_dice: 0.7875  decode.d5.loss_cls: 0.2385  decode.d5.loss_mask: 1.0767  decode.d5.loss_dice: 0.7799  decode.d6.loss_cls: 0.1736  decode.d6.loss_mask: 1.1824  decode.d6.loss_dice: 0.8190  decode.d7.loss_cls: 0.2195  decode.d7.loss_mask: 1.0729  decode.d7.loss_dice: 0.7874  decode.d8.loss_cls: 0.2218  decode.d8.loss_mask: 1.0494  decode.d8.loss_dice: 0.7512
05/26 17:09:02 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 17:09:02 - mmengine - INFO - Iter(train) [ 53000/160000]  base_lr: 6.9621e-05 lr: 6.9621e-06  eta: 12:11:42  time: 0.4188  data_time: 0.0096  memory: 5967  grad_norm: 442.2953  loss: 18.3893  decode.loss_cls: 0.2120  decode.loss_mask: 0.8448  decode.loss_dice: 0.7037  decode.d0.loss_cls: 0.6432  decode.d0.loss_mask: 0.8321  decode.d0.loss_dice: 0.7206  decode.d1.loss_cls: 0.2434  decode.d1.loss_mask: 0.8491  decode.d1.loss_dice: 0.7193  decode.d2.loss_cls: 0.2145  decode.d2.loss_mask: 0.8542  decode.d2.loss_dice: 0.7147  decode.d3.loss_cls: 0.2089  decode.d3.loss_mask: 0.8581  decode.d3.loss_dice: 0.7282  decode.d4.loss_cls: 0.1778  decode.d4.loss_mask: 0.8783  decode.d4.loss_dice: 0.7753  decode.d5.loss_cls: 0.2280  decode.d5.loss_mask: 0.8580  decode.d5.loss_dice: 0.7036  decode.d6.loss_cls: 0.1980  decode.d6.loss_mask: 0.8720  decode.d6.loss_dice: 0.7155  decode.d7.loss_cls: 0.2145  decode.d7.loss_mask: 0.8648  decode.d7.loss_dice: 0.7375  decode.d8.loss_cls: 0.2444  decode.d8.loss_mask: 0.8646  decode.d8.loss_dice: 0.7102
05/26 17:09:23 - mmengine - INFO - Iter(train) [ 53050/160000]  base_lr: 6.9592e-05 lr: 6.9592e-06  eta: 12:11:22  time: 0.4176  data_time: 0.0097  memory: 5980  grad_norm: 558.2079  loss: 19.1207  decode.loss_cls: 0.2204  decode.loss_mask: 0.9357  decode.loss_dice: 0.6978  decode.d0.loss_cls: 0.5796  decode.d0.loss_mask: 0.9452  decode.d0.loss_dice: 0.7355  decode.d1.loss_cls: 0.2188  decode.d1.loss_mask: 0.9295  decode.d1.loss_dice: 0.7187  decode.d2.loss_cls: 0.1871  decode.d2.loss_mask: 0.9383  decode.d2.loss_dice: 0.7112  decode.d3.loss_cls: 0.2645  decode.d3.loss_mask: 0.9131  decode.d3.loss_dice: 0.6910  decode.d4.loss_cls: 0.1976  decode.d4.loss_mask: 1.0140  decode.d4.loss_dice: 0.7238  decode.d5.loss_cls: 0.1587  decode.d5.loss_mask: 1.0042  decode.d5.loss_dice: 0.7335  decode.d6.loss_cls: 0.2021  decode.d6.loss_mask: 0.9409  decode.d6.loss_dice: 0.7181  decode.d7.loss_cls: 0.1997  decode.d7.loss_mask: 0.9411  decode.d7.loss_dice: 0.7338  decode.d8.loss_cls: 0.2352  decode.d8.loss_mask: 0.9239  decode.d8.loss_dice: 0.7077
05/26 17:09:44 - mmengine - INFO - Iter(train) [ 53100/160000]  base_lr: 6.9562e-05 lr: 6.9562e-06  eta: 12:11:02  time: 0.4164  data_time: 0.0097  memory: 5971  grad_norm: 721.6398  loss: 26.8742  decode.loss_cls: 0.2806  decode.loss_mask: 1.4280  decode.loss_dice: 0.9766  decode.d0.loss_cls: 0.7416  decode.d0.loss_mask: 1.3566  decode.d0.loss_dice: 0.9565  decode.d1.loss_cls: 0.3498  decode.d1.loss_mask: 1.3881  decode.d1.loss_dice: 0.9546  decode.d2.loss_cls: 0.2719  decode.d2.loss_mask: 1.3375  decode.d2.loss_dice: 0.9274  decode.d3.loss_cls: 0.3298  decode.d3.loss_mask: 1.3546  decode.d3.loss_dice: 0.9341  decode.d4.loss_cls: 0.2705  decode.d4.loss_mask: 1.3989  decode.d4.loss_dice: 0.9720  decode.d5.loss_cls: 0.2891  decode.d5.loss_mask: 1.4113  decode.d5.loss_dice: 0.9533  decode.d6.loss_cls: 0.2896  decode.d6.loss_mask: 1.4077  decode.d6.loss_dice: 0.9451  decode.d7.loss_cls: 0.2918  decode.d7.loss_mask: 1.4046  decode.d7.loss_dice: 0.9812  decode.d8.loss_cls: 0.2493  decode.d8.loss_mask: 1.4660  decode.d8.loss_dice: 0.9560
05/26 17:10:04 - mmengine - INFO - Iter(train) [ 53150/160000]  base_lr: 6.9533e-05 lr: 6.9533e-06  eta: 12:10:42  time: 0.4194  data_time: 0.0099  memory: 5970  grad_norm: 1011.2954  loss: 25.2867  decode.loss_cls: 0.2700  decode.loss_mask: 1.3227  decode.loss_dice: 0.8865  decode.d0.loss_cls: 0.7541  decode.d0.loss_mask: 1.2616  decode.d0.loss_dice: 0.9107  decode.d1.loss_cls: 0.2543  decode.d1.loss_mask: 1.2990  decode.d1.loss_dice: 0.9104  decode.d2.loss_cls: 0.2374  decode.d2.loss_mask: 1.4389  decode.d2.loss_dice: 0.9148  decode.d3.loss_cls: 0.2060  decode.d3.loss_mask: 1.3372  decode.d3.loss_dice: 0.9230  decode.d4.loss_cls: 0.2764  decode.d4.loss_mask: 1.3129  decode.d4.loss_dice: 0.8952  decode.d5.loss_cls: 0.2348  decode.d5.loss_mask: 1.3291  decode.d5.loss_dice: 0.9403  decode.d6.loss_cls: 0.2328  decode.d6.loss_mask: 1.3258  decode.d6.loss_dice: 0.9127  decode.d7.loss_cls: 0.2240  decode.d7.loss_mask: 1.2758  decode.d7.loss_dice: 0.8969  decode.d8.loss_cls: 0.2524  decode.d8.loss_mask: 1.3616  decode.d8.loss_dice: 0.8895
05/26 17:10:25 - mmengine - INFO - Iter(train) [ 53200/160000]  base_lr: 6.9504e-05 lr: 6.9504e-06  eta: 12:10:23  time: 0.4192  data_time: 0.0096  memory: 5968  grad_norm: 639.8310  loss: 23.0332  decode.loss_cls: 0.2397  decode.loss_mask: 1.1464  decode.loss_dice: 0.8878  decode.d0.loss_cls: 0.6675  decode.d0.loss_mask: 1.0698  decode.d0.loss_dice: 0.8542  decode.d1.loss_cls: 0.2319  decode.d1.loss_mask: 1.1671  decode.d1.loss_dice: 0.8380  decode.d2.loss_cls: 0.2653  decode.d2.loss_mask: 1.1318  decode.d2.loss_dice: 0.8637  decode.d3.loss_cls: 0.2538  decode.d3.loss_mask: 1.1592  decode.d3.loss_dice: 0.8672  decode.d4.loss_cls: 0.2505  decode.d4.loss_mask: 1.1426  decode.d4.loss_dice: 0.8685  decode.d5.loss_cls: 0.2715  decode.d5.loss_mask: 1.1444  decode.d5.loss_dice: 0.8757  decode.d6.loss_cls: 0.2848  decode.d6.loss_mask: 1.1431  decode.d6.loss_dice: 0.8798  decode.d7.loss_cls: 0.2763  decode.d7.loss_mask: 1.1697  decode.d7.loss_dice: 0.8643  decode.d8.loss_cls: 0.2302  decode.d8.loss_mask: 1.1183  decode.d8.loss_dice: 0.8700
05/26 17:10:46 - mmengine - INFO - Iter(train) [ 53250/160000]  base_lr: 6.9475e-05 lr: 6.9475e-06  eta: 12:10:03  time: 0.4189  data_time: 0.0096  memory: 5968  grad_norm: 692.4702  loss: 21.4232  decode.loss_cls: 0.4010  decode.loss_mask: 0.9213  decode.loss_dice: 0.8400  decode.d0.loss_cls: 0.7547  decode.d0.loss_mask: 0.9279  decode.d0.loss_dice: 0.7908  decode.d1.loss_cls: 0.3647  decode.d1.loss_mask: 0.9080  decode.d1.loss_dice: 0.7934  decode.d2.loss_cls: 0.3397  decode.d2.loss_mask: 0.9070  decode.d2.loss_dice: 0.8046  decode.d3.loss_cls: 0.3321  decode.d3.loss_mask: 0.9150  decode.d3.loss_dice: 0.7987  decode.d4.loss_cls: 0.3265  decode.d4.loss_mask: 0.9112  decode.d4.loss_dice: 0.8210  decode.d5.loss_cls: 0.3343  decode.d5.loss_mask: 0.9776  decode.d5.loss_dice: 0.8517  decode.d6.loss_cls: 0.3586  decode.d6.loss_mask: 0.9478  decode.d6.loss_dice: 0.8528  decode.d7.loss_cls: 0.3555  decode.d7.loss_mask: 0.9507  decode.d7.loss_dice: 0.8414  decode.d8.loss_cls: 0.3835  decode.d8.loss_mask: 0.8975  decode.d8.loss_dice: 0.8142
05/26 17:11:07 - mmengine - INFO - Iter(train) [ 53300/160000]  base_lr: 6.9445e-05 lr: 6.9445e-06  eta: 12:09:44  time: 0.4178  data_time: 0.0096  memory: 5965  grad_norm: 401.7403  loss: 24.4616  decode.loss_cls: 0.3404  decode.loss_mask: 1.1208  decode.loss_dice: 0.9121  decode.d0.loss_cls: 0.8507  decode.d0.loss_mask: 1.0882  decode.d0.loss_dice: 0.8744  decode.d1.loss_cls: 0.3840  decode.d1.loss_mask: 1.0872  decode.d1.loss_dice: 0.8958  decode.d2.loss_cls: 0.3791  decode.d2.loss_mask: 1.0979  decode.d2.loss_dice: 0.8823  decode.d3.loss_cls: 0.3826  decode.d3.loss_mask: 1.1195  decode.d3.loss_dice: 0.8970  decode.d4.loss_cls: 0.4116  decode.d4.loss_mask: 1.1184  decode.d4.loss_dice: 0.9106  decode.d5.loss_cls: 0.4207  decode.d5.loss_mask: 1.1338  decode.d5.loss_dice: 0.9549  decode.d6.loss_cls: 0.3979  decode.d6.loss_mask: 1.1069  decode.d6.loss_dice: 0.9296  decode.d7.loss_cls: 0.3545  decode.d7.loss_mask: 1.1093  decode.d7.loss_dice: 0.9146  decode.d8.loss_cls: 0.3412  decode.d8.loss_mask: 1.1368  decode.d8.loss_dice: 0.9087
05/26 17:11:28 - mmengine - INFO - Iter(train) [ 53350/160000]  base_lr: 6.9416e-05 lr: 6.9416e-06  eta: 12:09:24  time: 0.4177  data_time: 0.0097  memory: 5987  grad_norm: 426.6885  loss: 23.6425  decode.loss_cls: 0.2620  decode.loss_mask: 1.1803  decode.loss_dice: 0.8917  decode.d0.loss_cls: 0.7548  decode.d0.loss_mask: 1.1413  decode.d0.loss_dice: 0.8892  decode.d1.loss_cls: 0.3158  decode.d1.loss_mask: 1.1806  decode.d1.loss_dice: 0.8995  decode.d2.loss_cls: 0.2742  decode.d2.loss_mask: 1.1300  decode.d2.loss_dice: 0.8825  decode.d3.loss_cls: 0.2676  decode.d3.loss_mask: 1.1485  decode.d3.loss_dice: 0.9053  decode.d4.loss_cls: 0.2768  decode.d4.loss_mask: 1.1619  decode.d4.loss_dice: 0.8659  decode.d5.loss_cls: 0.2510  decode.d5.loss_mask: 1.1603  decode.d5.loss_dice: 0.8837  decode.d6.loss_cls: 0.2563  decode.d6.loss_mask: 1.1771  decode.d6.loss_dice: 0.8975  decode.d7.loss_cls: 0.2660  decode.d7.loss_mask: 1.1631  decode.d7.loss_dice: 0.8840  decode.d8.loss_cls: 0.2407  decode.d8.loss_mask: 1.1473  decode.d8.loss_dice: 0.8877
05/26 17:11:49 - mmengine - INFO - Iter(train) [ 53400/160000]  base_lr: 6.9387e-05 lr: 6.9387e-06  eta: 12:09:04  time: 0.4176  data_time: 0.0096  memory: 5984  grad_norm: 789.4553  loss: 24.1442  decode.loss_cls: 0.3149  decode.loss_mask: 1.2368  decode.loss_dice: 0.8001  decode.d0.loss_cls: 0.7934  decode.d0.loss_mask: 1.1661  decode.d0.loss_dice: 0.7685  decode.d1.loss_cls: 0.3010  decode.d1.loss_mask: 1.2733  decode.d1.loss_dice: 0.8392  decode.d2.loss_cls: 0.3557  decode.d2.loss_mask: 1.2301  decode.d2.loss_dice: 0.8161  decode.d3.loss_cls: 0.3591  decode.d3.loss_mask: 1.2488  decode.d3.loss_dice: 0.7858  decode.d4.loss_cls: 0.3315  decode.d4.loss_mask: 1.2015  decode.d4.loss_dice: 0.7968  decode.d5.loss_cls: 0.2466  decode.d5.loss_mask: 1.2954  decode.d5.loss_dice: 0.8840  decode.d6.loss_cls: 0.2980  decode.d6.loss_mask: 1.2514  decode.d6.loss_dice: 0.8431  decode.d7.loss_cls: 0.3021  decode.d7.loss_mask: 1.2236  decode.d7.loss_dice: 0.8250  decode.d8.loss_cls: 0.2605  decode.d8.loss_mask: 1.2554  decode.d8.loss_dice: 0.8405
05/26 17:12:10 - mmengine - INFO - Iter(train) [ 53450/160000]  base_lr: 6.9357e-05 lr: 6.9357e-06  eta: 12:08:44  time: 0.4168  data_time: 0.0096  memory: 5973  grad_norm: 438.4039  loss: 20.5691  decode.loss_cls: 0.2477  decode.loss_mask: 0.9719  decode.loss_dice: 0.8072  decode.d0.loss_cls: 0.6936  decode.d0.loss_mask: 0.9383  decode.d0.loss_dice: 0.7776  decode.d1.loss_cls: 0.2588  decode.d1.loss_mask: 0.9641  decode.d1.loss_dice: 0.8090  decode.d2.loss_cls: 0.2441  decode.d2.loss_mask: 0.9411  decode.d2.loss_dice: 0.7895  decode.d3.loss_cls: 0.2337  decode.d3.loss_mask: 0.9490  decode.d3.loss_dice: 0.8162  decode.d4.loss_cls: 0.2612  decode.d4.loss_mask: 0.9324  decode.d4.loss_dice: 0.7860  decode.d5.loss_cls: 0.2612  decode.d5.loss_mask: 0.9428  decode.d5.loss_dice: 0.8158  decode.d6.loss_cls: 0.2480  decode.d6.loss_mask: 0.9623  decode.d6.loss_dice: 0.8172  decode.d7.loss_cls: 0.2760  decode.d7.loss_mask: 0.9627  decode.d7.loss_dice: 0.8282  decode.d8.loss_cls: 0.2378  decode.d8.loss_mask: 0.9613  decode.d8.loss_dice: 0.8345
05/26 17:12:31 - mmengine - INFO - Iter(train) [ 53500/160000]  base_lr: 6.9328e-05 lr: 6.9328e-06  eta: 12:08:24  time: 0.4177  data_time: 0.0096  memory: 5969  grad_norm: 745.4349  loss: 25.3979  decode.loss_cls: 0.3556  decode.loss_mask: 1.2233  decode.loss_dice: 0.9266  decode.d0.loss_cls: 0.8159  decode.d0.loss_mask: 1.1763  decode.d0.loss_dice: 0.9134  decode.d1.loss_cls: 0.3531  decode.d1.loss_mask: 1.1823  decode.d1.loss_dice: 0.9042  decode.d2.loss_cls: 0.3840  decode.d2.loss_mask: 1.1799  decode.d2.loss_dice: 0.8554  decode.d3.loss_cls: 0.3866  decode.d3.loss_mask: 1.1832  decode.d3.loss_dice: 0.8690  decode.d4.loss_cls: 0.3936  decode.d4.loss_mask: 1.2341  decode.d4.loss_dice: 0.9162  decode.d5.loss_cls: 0.3398  decode.d5.loss_mask: 1.2218  decode.d5.loss_dice: 0.9605  decode.d6.loss_cls: 0.3850  decode.d6.loss_mask: 1.1870  decode.d6.loss_dice: 0.8850  decode.d7.loss_cls: 0.3979  decode.d7.loss_mask: 1.2518  decode.d7.loss_dice: 0.9369  decode.d8.loss_cls: 0.3484  decode.d8.loss_mask: 1.2875  decode.d8.loss_dice: 0.9435
05/26 17:12:52 - mmengine - INFO - Iter(train) [ 53550/160000]  base_lr: 6.9299e-05 lr: 6.9299e-06  eta: 12:08:04  time: 0.4174  data_time: 0.0096  memory: 5984  grad_norm: 598.3757  loss: 23.8026  decode.loss_cls: 0.3134  decode.loss_mask: 1.1137  decode.loss_dice: 0.9505  decode.d0.loss_cls: 0.7822  decode.d0.loss_mask: 1.0527  decode.d0.loss_dice: 0.8491  decode.d1.loss_cls: 0.3729  decode.d1.loss_mask: 1.1015  decode.d1.loss_dice: 0.8977  decode.d2.loss_cls: 0.3343  decode.d2.loss_mask: 1.1126  decode.d2.loss_dice: 0.8960  decode.d3.loss_cls: 0.3293  decode.d3.loss_mask: 1.0795  decode.d3.loss_dice: 0.8786  decode.d4.loss_cls: 0.4127  decode.d4.loss_mask: 1.0712  decode.d4.loss_dice: 0.8751  decode.d5.loss_cls: 0.3572  decode.d5.loss_mask: 1.0642  decode.d5.loss_dice: 0.8896  decode.d6.loss_cls: 0.3417  decode.d6.loss_mask: 1.0763  decode.d6.loss_dice: 0.9010  decode.d7.loss_cls: 0.2615  decode.d7.loss_mask: 1.2108  decode.d7.loss_dice: 0.9005  decode.d8.loss_cls: 0.2881  decode.d8.loss_mask: 1.1633  decode.d8.loss_dice: 0.9255
05/26 17:13:13 - mmengine - INFO - Iter(train) [ 53600/160000]  base_lr: 6.9269e-05 lr: 6.9269e-06  eta: 12:07:45  time: 0.4196  data_time: 0.0096  memory: 5969  grad_norm: 527.5507  loss: 20.6627  decode.loss_cls: 0.1617  decode.loss_mask: 1.0830  decode.loss_dice: 0.7480  decode.d0.loss_cls: 0.6184  decode.d0.loss_mask: 1.0946  decode.d0.loss_dice: 0.7359  decode.d1.loss_cls: 0.1967  decode.d1.loss_mask: 1.0789  decode.d1.loss_dice: 0.7464  decode.d2.loss_cls: 0.1795  decode.d2.loss_mask: 1.0938  decode.d2.loss_dice: 0.7293  decode.d3.loss_cls: 0.1566  decode.d3.loss_mask: 1.1296  decode.d3.loss_dice: 0.7602  decode.d4.loss_cls: 0.1702  decode.d4.loss_mask: 1.1068  decode.d4.loss_dice: 0.7468  decode.d5.loss_cls: 0.1600  decode.d5.loss_mask: 1.0757  decode.d5.loss_dice: 0.7254  decode.d6.loss_cls: 0.1759  decode.d6.loss_mask: 1.0835  decode.d6.loss_dice: 0.7653  decode.d7.loss_cls: 0.1621  decode.d7.loss_mask: 1.1386  decode.d7.loss_dice: 0.7961  decode.d8.loss_cls: 0.1922  decode.d8.loss_mask: 1.0854  decode.d8.loss_dice: 0.7661
05/26 17:13:34 - mmengine - INFO - Iter(train) [ 53650/160000]  base_lr: 6.9240e-05 lr: 6.9240e-06  eta: 12:07:25  time: 0.4194  data_time: 0.0096  memory: 5968  grad_norm: 1520.2458  loss: 24.2036  decode.loss_cls: 0.2163  decode.loss_mask: 1.2714  decode.loss_dice: 0.8736  decode.d0.loss_cls: 0.7749  decode.d0.loss_mask: 1.1485  decode.d0.loss_dice: 0.8524  decode.d1.loss_cls: 0.3111  decode.d1.loss_mask: 1.2105  decode.d1.loss_dice: 0.8598  decode.d2.loss_cls: 0.2719  decode.d2.loss_mask: 1.2558  decode.d2.loss_dice: 0.8729  decode.d3.loss_cls: 0.3337  decode.d3.loss_mask: 1.2534  decode.d3.loss_dice: 0.8601  decode.d4.loss_cls: 0.2946  decode.d4.loss_mask: 1.2282  decode.d4.loss_dice: 0.8737  decode.d5.loss_cls: 0.2436  decode.d5.loss_mask: 1.2646  decode.d5.loss_dice: 0.8893  decode.d6.loss_cls: 0.2861  decode.d6.loss_mask: 1.2546  decode.d6.loss_dice: 0.8755  decode.d7.loss_cls: 0.3222  decode.d7.loss_mask: 1.1984  decode.d7.loss_dice: 0.8361  decode.d8.loss_cls: 0.2254  decode.d8.loss_mask: 1.2109  decode.d8.loss_dice: 0.8342
05/26 17:13:55 - mmengine - INFO - Iter(train) [ 53700/160000]  base_lr: 6.9211e-05 lr: 6.9211e-06  eta: 12:07:05  time: 0.4206  data_time: 0.0098  memory: 5980  grad_norm: 991.5268  loss: 26.6643  decode.loss_cls: 0.5017  decode.loss_mask: 1.1094  decode.loss_dice: 0.9550  decode.d0.loss_cls: 1.0904  decode.d0.loss_mask: 1.1508  decode.d0.loss_dice: 0.9667  decode.d1.loss_cls: 0.4807  decode.d1.loss_mask: 1.1284  decode.d1.loss_dice: 0.9667  decode.d2.loss_cls: 0.5037  decode.d2.loss_mask: 1.0971  decode.d2.loss_dice: 0.9445  decode.d3.loss_cls: 0.4895  decode.d3.loss_mask: 1.1129  decode.d3.loss_dice: 1.0004  decode.d4.loss_cls: 0.4967  decode.d4.loss_mask: 1.1364  decode.d4.loss_dice: 0.9805  decode.d5.loss_cls: 0.5146  decode.d5.loss_mask: 1.1458  decode.d5.loss_dice: 0.9764  decode.d6.loss_cls: 0.5111  decode.d6.loss_mask: 1.1861  decode.d6.loss_dice: 1.0052  decode.d7.loss_cls: 0.5326  decode.d7.loss_mask: 1.1301  decode.d7.loss_dice: 0.9449  decode.d8.loss_cls: 0.4992  decode.d8.loss_mask: 1.1426  decode.d8.loss_dice: 0.9643
05/26 17:14:16 - mmengine - INFO - Iter(train) [ 53750/160000]  base_lr: 6.9182e-05 lr: 6.9182e-06  eta: 12:06:46  time: 0.4194  data_time: 0.0099  memory: 5970  grad_norm: 572.0686  loss: 24.2651  decode.loss_cls: 0.2436  decode.loss_mask: 1.2131  decode.loss_dice: 0.8984  decode.d0.loss_cls: 0.7616  decode.d0.loss_mask: 1.2089  decode.d0.loss_dice: 0.8945  decode.d1.loss_cls: 0.2055  decode.d1.loss_mask: 1.2695  decode.d1.loss_dice: 0.9413  decode.d2.loss_cls: 0.2497  decode.d2.loss_mask: 1.2275  decode.d2.loss_dice: 0.9103  decode.d3.loss_cls: 0.2251  decode.d3.loss_mask: 1.2049  decode.d3.loss_dice: 0.9129  decode.d4.loss_cls: 0.1993  decode.d4.loss_mask: 1.2310  decode.d4.loss_dice: 0.9115  decode.d5.loss_cls: 0.2284  decode.d5.loss_mask: 1.2321  decode.d5.loss_dice: 0.9112  decode.d6.loss_cls: 0.2350  decode.d6.loss_mask: 1.2460  decode.d6.loss_dice: 0.9026  decode.d7.loss_cls: 0.2516  decode.d7.loss_mask: 1.2340  decode.d7.loss_dice: 0.9209  decode.d8.loss_cls: 0.2588  decode.d8.loss_mask: 1.2374  decode.d8.loss_dice: 0.8984
05/26 17:14:36 - mmengine - INFO - Iter(train) [ 53800/160000]  base_lr: 6.9152e-05 lr: 6.9152e-06  eta: 12:06:26  time: 0.4190  data_time: 0.0097  memory: 5969  grad_norm: 756.6817  loss: 24.4957  decode.loss_cls: 0.2376  decode.loss_mask: 1.2155  decode.loss_dice: 0.8805  decode.d0.loss_cls: 0.7808  decode.d0.loss_mask: 1.2161  decode.d0.loss_dice: 0.8554  decode.d1.loss_cls: 0.2542  decode.d1.loss_mask: 1.2530  decode.d1.loss_dice: 0.9007  decode.d2.loss_cls: 0.2498  decode.d2.loss_mask: 1.2349  decode.d2.loss_dice: 0.8849  decode.d3.loss_cls: 0.2467  decode.d3.loss_mask: 1.2590  decode.d3.loss_dice: 0.8920  decode.d4.loss_cls: 0.2607  decode.d4.loss_mask: 1.2549  decode.d4.loss_dice: 0.8930  decode.d5.loss_cls: 0.2996  decode.d5.loss_mask: 1.2402  decode.d5.loss_dice: 0.8921  decode.d6.loss_cls: 0.2491  decode.d6.loss_mask: 1.2370  decode.d6.loss_dice: 0.8859  decode.d7.loss_cls: 0.1808  decode.d7.loss_mask: 1.3418  decode.d7.loss_dice: 0.9113  decode.d8.loss_cls: 0.1907  decode.d8.loss_mask: 1.3507  decode.d8.loss_dice: 0.9467
05/26 17:14:57 - mmengine - INFO - Iter(train) [ 53850/160000]  base_lr: 6.9123e-05 lr: 6.9123e-06  eta: 12:06:06  time: 0.4207  data_time: 0.0100  memory: 5966  grad_norm: 629.3849  loss: 25.4604  decode.loss_cls: 0.4592  decode.loss_mask: 1.1130  decode.loss_dice: 0.9378  decode.d0.loss_cls: 0.9660  decode.d0.loss_mask: 1.0206  decode.d0.loss_dice: 0.8888  decode.d1.loss_cls: 0.4676  decode.d1.loss_mask: 1.1222  decode.d1.loss_dice: 0.9533  decode.d2.loss_cls: 0.4654  decode.d2.loss_mask: 1.1058  decode.d2.loss_dice: 0.9230  decode.d3.loss_cls: 0.4811  decode.d3.loss_mask: 1.1036  decode.d3.loss_dice: 0.9382  decode.d4.loss_cls: 0.4623  decode.d4.loss_mask: 1.1290  decode.d4.loss_dice: 0.9526  decode.d5.loss_cls: 0.4003  decode.d5.loss_mask: 1.1488  decode.d5.loss_dice: 0.9581  decode.d6.loss_cls: 0.5096  decode.d6.loss_mask: 1.0909  decode.d6.loss_dice: 0.9331  decode.d7.loss_cls: 0.4686  decode.d7.loss_mask: 1.0755  decode.d7.loss_dice: 0.9315  decode.d8.loss_cls: 0.4293  decode.d8.loss_mask: 1.0938  decode.d8.loss_dice: 0.9314
05/26 17:15:19 - mmengine - INFO - Iter(train) [ 53900/160000]  base_lr: 6.9094e-05 lr: 6.9094e-06  eta: 12:05:47  time: 0.4200  data_time: 0.0098  memory: 5965  grad_norm: 585.3471  loss: 24.6143  decode.loss_cls: 0.2527  decode.loss_mask: 1.3235  decode.loss_dice: 0.8079  decode.d0.loss_cls: 0.6180  decode.d0.loss_mask: 1.3220  decode.d0.loss_dice: 0.8169  decode.d1.loss_cls: 0.3140  decode.d1.loss_mask: 1.3292  decode.d1.loss_dice: 0.8235  decode.d2.loss_cls: 0.2821  decode.d2.loss_mask: 1.3739  decode.d2.loss_dice: 0.8182  decode.d3.loss_cls: 0.2392  decode.d3.loss_mask: 1.4252  decode.d3.loss_dice: 0.8316  decode.d4.loss_cls: 0.3178  decode.d4.loss_mask: 1.3286  decode.d4.loss_dice: 0.8360  decode.d5.loss_cls: 0.2787  decode.d5.loss_mask: 1.3227  decode.d5.loss_dice: 0.8482  decode.d6.loss_cls: 0.2281  decode.d6.loss_mask: 1.2952  decode.d6.loss_dice: 0.8240  decode.d7.loss_cls: 0.3138  decode.d7.loss_mask: 1.2815  decode.d7.loss_dice: 0.7845  decode.d8.loss_cls: 0.2443  decode.d8.loss_mask: 1.3186  decode.d8.loss_dice: 0.8145
05/26 17:15:39 - mmengine - INFO - Iter(train) [ 53950/160000]  base_lr: 6.9064e-05 lr: 6.9064e-06  eta: 12:05:27  time: 0.4162  data_time: 0.0095  memory: 5966  grad_norm: 717.7253  loss: 24.0718  decode.loss_cls: 0.2785  decode.loss_mask: 1.2667  decode.loss_dice: 0.8173  decode.d0.loss_cls: 0.7611  decode.d0.loss_mask: 1.0921  decode.d0.loss_dice: 0.8136  decode.d1.loss_cls: 0.3036  decode.d1.loss_mask: 1.2229  decode.d1.loss_dice: 0.8467  decode.d2.loss_cls: 0.3156  decode.d2.loss_mask: 1.2312  decode.d2.loss_dice: 0.8508  decode.d3.loss_cls: 0.3326  decode.d3.loss_mask: 1.1374  decode.d3.loss_dice: 0.8204  decode.d4.loss_cls: 0.3479  decode.d4.loss_mask: 1.1465  decode.d4.loss_dice: 0.8507  decode.d5.loss_cls: 0.2977  decode.d5.loss_mask: 1.2821  decode.d5.loss_dice: 0.8322  decode.d6.loss_cls: 0.3635  decode.d6.loss_mask: 1.2444  decode.d6.loss_dice: 0.8152  decode.d7.loss_cls: 0.3229  decode.d7.loss_mask: 1.2291  decode.d7.loss_dice: 0.8304  decode.d8.loss_cls: 0.3181  decode.d8.loss_mask: 1.2509  decode.d8.loss_dice: 0.8497
05/26 17:16:00 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 17:16:00 - mmengine - INFO - Iter(train) [ 54000/160000]  base_lr: 6.9035e-05 lr: 6.9035e-06  eta: 12:05:07  time: 0.4155  data_time: 0.0096  memory: 5966  grad_norm: 492.7342  loss: 21.9879  decode.loss_cls: 0.1736  decode.loss_mask: 1.1934  decode.loss_dice: 0.7875  decode.d0.loss_cls: 0.6503  decode.d0.loss_mask: 1.1462  decode.d0.loss_dice: 0.7511  decode.d1.loss_cls: 0.1718  decode.d1.loss_mask: 1.1822  decode.d1.loss_dice: 0.8043  decode.d2.loss_cls: 0.2157  decode.d2.loss_mask: 1.1782  decode.d2.loss_dice: 0.8160  decode.d3.loss_cls: 0.1927  decode.d3.loss_mask: 1.1718  decode.d3.loss_dice: 0.7693  decode.d4.loss_cls: 0.1715  decode.d4.loss_mask: 1.1992  decode.d4.loss_dice: 0.8015  decode.d5.loss_cls: 0.1670  decode.d5.loss_mask: 1.1926  decode.d5.loss_dice: 0.7976  decode.d6.loss_cls: 0.1859  decode.d6.loss_mask: 1.1759  decode.d6.loss_dice: 0.8185  decode.d7.loss_cls: 0.1770  decode.d7.loss_mask: 1.1741  decode.d7.loss_dice: 0.8158  decode.d8.loss_cls: 0.2000  decode.d8.loss_mask: 1.1347  decode.d8.loss_dice: 0.7724
05/26 17:16:21 - mmengine - INFO - Iter(train) [ 54050/160000]  base_lr: 6.9006e-05 lr: 6.9006e-06  eta: 12:04:47  time: 0.4138  data_time: 0.0096  memory: 5969  grad_norm: 646.4603  loss: 25.7136  decode.loss_cls: 0.3857  decode.loss_mask: 1.1999  decode.loss_dice: 0.8834  decode.d0.loss_cls: 0.8114  decode.d0.loss_mask: 1.1968  decode.d0.loss_dice: 0.8844  decode.d1.loss_cls: 0.3644  decode.d1.loss_mask: 1.2448  decode.d1.loss_dice: 0.9242  decode.d2.loss_cls: 0.4011  decode.d2.loss_mask: 1.2385  decode.d2.loss_dice: 0.9541  decode.d3.loss_cls: 0.3838  decode.d3.loss_mask: 1.2709  decode.d3.loss_dice: 0.9425  decode.d4.loss_cls: 0.3511  decode.d4.loss_mask: 1.2693  decode.d4.loss_dice: 0.9350  decode.d5.loss_cls: 0.3926  decode.d5.loss_mask: 1.2432  decode.d5.loss_dice: 0.9323  decode.d6.loss_cls: 0.3840  decode.d6.loss_mask: 1.2173  decode.d6.loss_dice: 0.8927  decode.d7.loss_cls: 0.3630  decode.d7.loss_mask: 1.2227  decode.d7.loss_dice: 0.9026  decode.d8.loss_cls: 0.3621  decode.d8.loss_mask: 1.2265  decode.d8.loss_dice: 0.9334
05/26 17:16:41 - mmengine - INFO - Iter(train) [ 54100/160000]  base_lr: 6.8976e-05 lr: 6.8976e-06  eta: 12:04:26  time: 0.4129  data_time: 0.0096  memory: 5975  grad_norm: 566.5364  loss: 22.8183  decode.loss_cls: 0.2280  decode.loss_mask: 1.1493  decode.loss_dice: 0.8539  decode.d0.loss_cls: 0.6640  decode.d0.loss_mask: 1.1328  decode.d0.loss_dice: 0.8066  decode.d1.loss_cls: 0.2388  decode.d1.loss_mask: 1.1119  decode.d1.loss_dice: 0.8384  decode.d2.loss_cls: 0.2134  decode.d2.loss_mask: 1.1200  decode.d2.loss_dice: 0.8868  decode.d3.loss_cls: 0.1914  decode.d3.loss_mask: 1.1521  decode.d3.loss_dice: 0.8732  decode.d4.loss_cls: 0.2182  decode.d4.loss_mask: 1.1673  decode.d4.loss_dice: 0.8771  decode.d5.loss_cls: 0.2234  decode.d5.loss_mask: 1.1491  decode.d5.loss_dice: 0.8672  decode.d6.loss_cls: 0.2426  decode.d6.loss_mask: 1.1612  decode.d6.loss_dice: 0.8893  decode.d7.loss_cls: 0.2378  decode.d7.loss_mask: 1.1732  decode.d7.loss_dice: 0.8683  decode.d8.loss_cls: 0.2336  decode.d8.loss_mask: 1.1673  decode.d8.loss_dice: 0.8822
05/26 17:17:02 - mmengine - INFO - Iter(train) [ 54150/160000]  base_lr: 6.8947e-05 lr: 6.8947e-06  eta: 12:04:06  time: 0.4122  data_time: 0.0095  memory: 5968  grad_norm: 630.7668  loss: 22.8694  decode.loss_cls: 0.2872  decode.loss_mask: 1.1442  decode.loss_dice: 0.8094  decode.d0.loss_cls: 0.8652  decode.d0.loss_mask: 1.0261  decode.d0.loss_dice: 0.7280  decode.d1.loss_cls: 0.3712  decode.d1.loss_mask: 1.1061  decode.d1.loss_dice: 0.8227  decode.d2.loss_cls: 0.3449  decode.d2.loss_mask: 1.1099  decode.d2.loss_dice: 0.8066  decode.d3.loss_cls: 0.3562  decode.d3.loss_mask: 1.0718  decode.d3.loss_dice: 0.7861  decode.d4.loss_cls: 0.3715  decode.d4.loss_mask: 1.0839  decode.d4.loss_dice: 0.7910  decode.d5.loss_cls: 0.3613  decode.d5.loss_mask: 1.0962  decode.d5.loss_dice: 0.7731  decode.d6.loss_cls: 0.3595  decode.d6.loss_mask: 1.1139  decode.d6.loss_dice: 0.8024  decode.d7.loss_cls: 0.3131  decode.d7.loss_mask: 1.0945  decode.d7.loss_dice: 0.8157  decode.d8.loss_cls: 0.3435  decode.d8.loss_mask: 1.1026  decode.d8.loss_dice: 0.8118
05/26 17:17:23 - mmengine - INFO - Iter(train) [ 54200/160000]  base_lr: 6.8918e-05 lr: 6.8918e-06  eta: 12:03:46  time: 0.4152  data_time: 0.0096  memory: 5978  grad_norm: 695.3837  loss: 25.3913  decode.loss_cls: 0.3204  decode.loss_mask: 1.2796  decode.loss_dice: 0.8408  decode.d0.loss_cls: 0.8195  decode.d0.loss_mask: 1.1107  decode.d0.loss_dice: 0.8208  decode.d1.loss_cls: 0.3746  decode.d1.loss_mask: 1.2209  decode.d1.loss_dice: 0.8366  decode.d2.loss_cls: 0.4102  decode.d2.loss_mask: 1.2491  decode.d2.loss_dice: 0.8668  decode.d3.loss_cls: 0.3696  decode.d3.loss_mask: 1.2864  decode.d3.loss_dice: 0.9142  decode.d4.loss_cls: 0.4195  decode.d4.loss_mask: 1.2365  decode.d4.loss_dice: 0.8507  decode.d5.loss_cls: 0.4271  decode.d5.loss_mask: 1.2468  decode.d5.loss_dice: 0.9131  decode.d6.loss_cls: 0.4061  decode.d6.loss_mask: 1.2744  decode.d6.loss_dice: 0.8951  decode.d7.loss_cls: 0.4192  decode.d7.loss_mask: 1.2351  decode.d7.loss_dice: 0.8642  decode.d8.loss_cls: 0.4001  decode.d8.loss_mask: 1.2410  decode.d8.loss_dice: 0.8423
05/26 17:17:44 - mmengine - INFO - Iter(train) [ 54250/160000]  base_lr: 6.8889e-05 lr: 6.8889e-06  eta: 12:03:26  time: 0.4174  data_time: 0.0097  memory: 5980  grad_norm: 682.0259  loss: 21.9687  decode.loss_cls: 0.2648  decode.loss_mask: 1.0570  decode.loss_dice: 0.8324  decode.d0.loss_cls: 0.7260  decode.d0.loss_mask: 1.0332  decode.d0.loss_dice: 0.7965  decode.d1.loss_cls: 0.2327  decode.d1.loss_mask: 1.1008  decode.d1.loss_dice: 0.8825  decode.d2.loss_cls: 0.2441  decode.d2.loss_mask: 1.0464  decode.d2.loss_dice: 0.8232  decode.d3.loss_cls: 0.2640  decode.d3.loss_mask: 1.0834  decode.d3.loss_dice: 0.8295  decode.d4.loss_cls: 0.2454  decode.d4.loss_mask: 1.0692  decode.d4.loss_dice: 0.8174  decode.d5.loss_cls: 0.2510  decode.d5.loss_mask: 1.0504  decode.d5.loss_dice: 0.8193  decode.d6.loss_cls: 0.2835  decode.d6.loss_mask: 1.0951  decode.d6.loss_dice: 0.8351  decode.d7.loss_cls: 0.2864  decode.d7.loss_mask: 1.0550  decode.d7.loss_dice: 0.7984  decode.d8.loss_cls: 0.2428  decode.d8.loss_mask: 1.0678  decode.d8.loss_dice: 0.8355
05/26 17:18:05 - mmengine - INFO - Iter(train) [ 54300/160000]  base_lr: 6.8859e-05 lr: 6.8859e-06  eta: 12:03:06  time: 0.4162  data_time: 0.0097  memory: 5976  grad_norm: 592.1563  loss: 22.3997  decode.loss_cls: 0.3139  decode.loss_mask: 1.0438  decode.loss_dice: 0.8073  decode.d0.loss_cls: 0.7220  decode.d0.loss_mask: 1.0855  decode.d0.loss_dice: 0.8223  decode.d1.loss_cls: 0.3500  decode.d1.loss_mask: 1.0462  decode.d1.loss_dice: 0.7752  decode.d2.loss_cls: 0.3308  decode.d2.loss_mask: 1.0459  decode.d2.loss_dice: 0.7658  decode.d3.loss_cls: 0.2815  decode.d3.loss_mask: 1.1675  decode.d3.loss_dice: 0.8198  decode.d4.loss_cls: 0.3182  decode.d4.loss_mask: 1.0593  decode.d4.loss_dice: 0.8096  decode.d5.loss_cls: 0.2838  decode.d5.loss_mask: 1.1455  decode.d5.loss_dice: 0.8453  decode.d6.loss_cls: 0.2921  decode.d6.loss_mask: 1.1334  decode.d6.loss_dice: 0.8303  decode.d7.loss_cls: 0.2862  decode.d7.loss_mask: 1.0754  decode.d7.loss_dice: 0.7752  decode.d8.loss_cls: 0.2913  decode.d8.loss_mask: 1.0757  decode.d8.loss_dice: 0.8007
05/26 17:18:25 - mmengine - INFO - Iter(train) [ 54350/160000]  base_lr: 6.8830e-05 lr: 6.8830e-06  eta: 12:02:46  time: 0.4162  data_time: 0.0097  memory: 5980  grad_norm: 514.5685  loss: 25.3081  decode.loss_cls: 0.3490  decode.loss_mask: 1.1781  decode.loss_dice: 0.9204  decode.d0.loss_cls: 0.8637  decode.d0.loss_mask: 1.1290  decode.d0.loss_dice: 0.9063  decode.d1.loss_cls: 0.3862  decode.d1.loss_mask: 1.2009  decode.d1.loss_dice: 0.9383  decode.d2.loss_cls: 0.3498  decode.d2.loss_mask: 1.2204  decode.d2.loss_dice: 0.9030  decode.d3.loss_cls: 0.3924  decode.d3.loss_mask: 1.1727  decode.d3.loss_dice: 0.9337  decode.d4.loss_cls: 0.3890  decode.d4.loss_mask: 1.2110  decode.d4.loss_dice: 0.9180  decode.d5.loss_cls: 0.4011  decode.d5.loss_mask: 1.1749  decode.d5.loss_dice: 0.9167  decode.d6.loss_cls: 0.4040  decode.d6.loss_mask: 1.1871  decode.d6.loss_dice: 0.9351  decode.d7.loss_cls: 0.3360  decode.d7.loss_mask: 1.1889  decode.d7.loss_dice: 0.9341  decode.d8.loss_cls: 0.3480  decode.d8.loss_mask: 1.1882  decode.d8.loss_dice: 0.9321
05/26 17:18:46 - mmengine - INFO - Iter(train) [ 54400/160000]  base_lr: 6.8801e-05 lr: 6.8801e-06  eta: 12:02:27  time: 0.4167  data_time: 0.0098  memory: 5974  grad_norm: 756.7148  loss: 23.1536  decode.loss_cls: 0.3330  decode.loss_mask: 1.1251  decode.loss_dice: 0.7784  decode.d0.loss_cls: 0.8284  decode.d0.loss_mask: 1.0809  decode.d0.loss_dice: 0.7619  decode.d1.loss_cls: 0.3843  decode.d1.loss_mask: 1.1030  decode.d1.loss_dice: 0.8021  decode.d2.loss_cls: 0.4139  decode.d2.loss_mask: 1.0087  decode.d2.loss_dice: 0.7622  decode.d3.loss_cls: 0.3702  decode.d3.loss_mask: 1.1795  decode.d3.loss_dice: 0.8126  decode.d4.loss_cls: 0.3670  decode.d4.loss_mask: 1.0668  decode.d4.loss_dice: 0.7883  decode.d5.loss_cls: 0.3232  decode.d5.loss_mask: 1.1060  decode.d5.loss_dice: 0.8010  decode.d6.loss_cls: 0.3793  decode.d6.loss_mask: 1.1032  decode.d6.loss_dice: 0.8318  decode.d7.loss_cls: 0.3250  decode.d7.loss_mask: 1.1674  decode.d7.loss_dice: 0.8430  decode.d8.loss_cls: 0.3344  decode.d8.loss_mask: 1.1455  decode.d8.loss_dice: 0.8276
05/26 17:19:07 - mmengine - INFO - Iter(train) [ 54450/160000]  base_lr: 6.8771e-05 lr: 6.8771e-06  eta: 12:02:07  time: 0.4171  data_time: 0.0097  memory: 5966  grad_norm: 526.1406  loss: 24.6559  decode.loss_cls: 0.3850  decode.loss_mask: 1.2123  decode.loss_dice: 0.8185  decode.d0.loss_cls: 0.7811  decode.d0.loss_mask: 1.1709  decode.d0.loss_dice: 0.8235  decode.d1.loss_cls: 0.3542  decode.d1.loss_mask: 1.2503  decode.d1.loss_dice: 0.8923  decode.d2.loss_cls: 0.3525  decode.d2.loss_mask: 1.1904  decode.d2.loss_dice: 0.8746  decode.d3.loss_cls: 0.3934  decode.d3.loss_mask: 1.1680  decode.d3.loss_dice: 0.8509  decode.d4.loss_cls: 0.3802  decode.d4.loss_mask: 1.2118  decode.d4.loss_dice: 0.8491  decode.d5.loss_cls: 0.3582  decode.d5.loss_mask: 1.1918  decode.d5.loss_dice: 0.8463  decode.d6.loss_cls: 0.3717  decode.d6.loss_mask: 1.2000  decode.d6.loss_dice: 0.8623  decode.d7.loss_cls: 0.3612  decode.d7.loss_mask: 1.2252  decode.d7.loss_dice: 0.8592  decode.d8.loss_cls: 0.3877  decode.d8.loss_mask: 1.1852  decode.d8.loss_dice: 0.8480
05/26 17:19:28 - mmengine - INFO - Iter(train) [ 54500/160000]  base_lr: 6.8742e-05 lr: 6.8742e-06  eta: 12:01:47  time: 0.4184  data_time: 0.0097  memory: 5970  grad_norm: 498.5202  loss: 23.0433  decode.loss_cls: 0.1640  decode.loss_mask: 1.1934  decode.loss_dice: 0.8588  decode.d0.loss_cls: 0.6583  decode.d0.loss_mask: 1.1833  decode.d0.loss_dice: 0.8095  decode.d1.loss_cls: 0.2257  decode.d1.loss_mask: 1.2463  decode.d1.loss_dice: 0.8808  decode.d2.loss_cls: 0.1862  decode.d2.loss_mask: 1.2600  decode.d2.loss_dice: 0.8923  decode.d3.loss_cls: 0.1819  decode.d3.loss_mask: 1.2372  decode.d3.loss_dice: 0.9035  decode.d4.loss_cls: 0.2410  decode.d4.loss_mask: 1.1510  decode.d4.loss_dice: 0.8479  decode.d5.loss_cls: 0.1900  decode.d5.loss_mask: 1.2085  decode.d5.loss_dice: 0.9096  decode.d6.loss_cls: 0.2398  decode.d6.loss_mask: 1.1188  decode.d6.loss_dice: 0.8251  decode.d7.loss_cls: 0.2703  decode.d7.loss_mask: 1.1326  decode.d7.loss_dice: 0.8216  decode.d8.loss_cls: 0.2375  decode.d8.loss_mask: 1.1415  decode.d8.loss_dice: 0.8270
05/26 17:19:49 - mmengine - INFO - Iter(train) [ 54550/160000]  base_lr: 6.8713e-05 lr: 6.8713e-06  eta: 12:01:27  time: 0.4200  data_time: 0.0098  memory: 5968  grad_norm: 406.5755  loss: 21.2443  decode.loss_cls: 0.2033  decode.loss_mask: 1.0358  decode.loss_dice: 0.7700  decode.d0.loss_cls: 0.8091  decode.d0.loss_mask: 0.9842  decode.d0.loss_dice: 0.8017  decode.d1.loss_cls: 0.2856  decode.d1.loss_mask: 1.0151  decode.d1.loss_dice: 0.7858  decode.d2.loss_cls: 0.2649  decode.d2.loss_mask: 1.0061  decode.d2.loss_dice: 0.7924  decode.d3.loss_cls: 0.2520  decode.d3.loss_mask: 1.0170  decode.d3.loss_dice: 0.7775  decode.d4.loss_cls: 0.2669  decode.d4.loss_mask: 1.0209  decode.d4.loss_dice: 0.8607  decode.d5.loss_cls: 0.2441  decode.d5.loss_mask: 1.0358  decode.d5.loss_dice: 0.8441  decode.d6.loss_cls: 0.2801  decode.d6.loss_mask: 0.9841  decode.d6.loss_dice: 0.7981  decode.d7.loss_cls: 0.2305  decode.d7.loss_mask: 1.0117  decode.d7.loss_dice: 0.7964  decode.d8.loss_cls: 0.2192  decode.d8.loss_mask: 1.0303  decode.d8.loss_dice: 0.8209
05/26 17:20:10 - mmengine - INFO - Iter(train) [ 54600/160000]  base_lr: 6.8683e-05 lr: 6.8683e-06  eta: 12:01:07  time: 0.4191  data_time: 0.0097  memory: 5966  grad_norm: 632.2217  loss: 23.5777  decode.loss_cls: 0.1087  decode.loss_mask: 1.2869  decode.loss_dice: 0.8860  decode.d0.loss_cls: 0.6055  decode.d0.loss_mask: 1.2960  decode.d0.loss_dice: 0.8897  decode.d1.loss_cls: 0.1145  decode.d1.loss_mask: 1.3161  decode.d1.loss_dice: 0.9004  decode.d2.loss_cls: 0.1207  decode.d2.loss_mask: 1.2985  decode.d2.loss_dice: 0.8979  decode.d3.loss_cls: 0.1192  decode.d3.loss_mask: 1.2940  decode.d3.loss_dice: 0.8886  decode.d4.loss_cls: 0.1663  decode.d4.loss_mask: 1.2718  decode.d4.loss_dice: 0.8466  decode.d5.loss_cls: 0.1388  decode.d5.loss_mask: 1.3136  decode.d5.loss_dice: 0.9129  decode.d6.loss_cls: 0.1063  decode.d6.loss_mask: 1.3037  decode.d6.loss_dice: 0.8892  decode.d7.loss_cls: 0.1444  decode.d7.loss_mask: 1.2795  decode.d7.loss_dice: 0.8773  decode.d8.loss_cls: 0.1148  decode.d8.loss_mask: 1.3046  decode.d8.loss_dice: 0.8855
05/26 17:20:31 - mmengine - INFO - Iter(train) [ 54650/160000]  base_lr: 6.8654e-05 lr: 6.8654e-06  eta: 12:00:47  time: 0.4186  data_time: 0.0098  memory: 5976  grad_norm: 587.0805  loss: 20.1929  decode.loss_cls: 0.1911  decode.loss_mask: 1.0965  decode.loss_dice: 0.6745  decode.d0.loss_cls: 0.7429  decode.d0.loss_mask: 0.9917  decode.d0.loss_dice: 0.6710  decode.d1.loss_cls: 0.2099  decode.d1.loss_mask: 1.0778  decode.d1.loss_dice: 0.6819  decode.d2.loss_cls: 0.1978  decode.d2.loss_mask: 1.1038  decode.d2.loss_dice: 0.6970  decode.d3.loss_cls: 0.1811  decode.d3.loss_mask: 1.1549  decode.d3.loss_dice: 0.6783  decode.d4.loss_cls: 0.2850  decode.d4.loss_mask: 1.0960  decode.d4.loss_dice: 0.6845  decode.d5.loss_cls: 0.2042  decode.d5.loss_mask: 1.0179  decode.d5.loss_dice: 0.6649  decode.d6.loss_cls: 0.1688  decode.d6.loss_mask: 1.1071  decode.d6.loss_dice: 0.7014  decode.d7.loss_cls: 0.1959  decode.d7.loss_mask: 1.1123  decode.d7.loss_dice: 0.6655  decode.d8.loss_cls: 0.2411  decode.d8.loss_mask: 1.0341  decode.d8.loss_dice: 0.6640
05/26 17:20:52 - mmengine - INFO - Iter(train) [ 54700/160000]  base_lr: 6.8625e-05 lr: 6.8625e-06  eta: 12:00:27  time: 0.4174  data_time: 0.0096  memory: 5976  grad_norm: 675.3408  loss: 27.0340  decode.loss_cls: 0.3805  decode.loss_mask: 1.2930  decode.loss_dice: 0.9209  decode.d0.loss_cls: 0.8819  decode.d0.loss_mask: 1.2845  decode.d0.loss_dice: 0.9317  decode.d1.loss_cls: 0.4074  decode.d1.loss_mask: 1.3431  decode.d1.loss_dice: 0.9856  decode.d2.loss_cls: 0.4499  decode.d2.loss_mask: 1.2857  decode.d2.loss_dice: 0.9356  decode.d3.loss_cls: 0.3803  decode.d3.loss_mask: 1.2984  decode.d3.loss_dice: 0.9690  decode.d4.loss_cls: 0.4423  decode.d4.loss_mask: 1.2814  decode.d4.loss_dice: 0.9390  decode.d5.loss_cls: 0.4164  decode.d5.loss_mask: 1.3066  decode.d5.loss_dice: 0.9619  decode.d6.loss_cls: 0.3897  decode.d6.loss_mask: 1.3139  decode.d6.loss_dice: 0.9877  decode.d7.loss_cls: 0.4318  decode.d7.loss_mask: 1.2682  decode.d7.loss_dice: 0.9276  decode.d8.loss_cls: 0.3838  decode.d8.loss_mask: 1.2776  decode.d8.loss_dice: 0.9587
05/26 17:21:13 - mmengine - INFO - Iter(train) [ 54750/160000]  base_lr: 6.8595e-05 lr: 6.8595e-06  eta: 12:00:08  time: 0.4179  data_time: 0.0096  memory: 5979  grad_norm: 374.5765  loss: 22.5992  decode.loss_cls: 0.2873  decode.loss_mask: 1.0431  decode.loss_dice: 0.8536  decode.d0.loss_cls: 0.6613  decode.d0.loss_mask: 1.0242  decode.d0.loss_dice: 0.8442  decode.d1.loss_cls: 0.3152  decode.d1.loss_mask: 1.0477  decode.d1.loss_dice: 0.8170  decode.d2.loss_cls: 0.2514  decode.d2.loss_mask: 1.1401  decode.d2.loss_dice: 0.8790  decode.d3.loss_cls: 0.2559  decode.d3.loss_mask: 1.0777  decode.d3.loss_dice: 0.8677  decode.d4.loss_cls: 0.3061  decode.d4.loss_mask: 1.0613  decode.d4.loss_dice: 0.9020  decode.d5.loss_cls: 0.3151  decode.d5.loss_mask: 1.0421  decode.d5.loss_dice: 0.8975  decode.d6.loss_cls: 0.3289  decode.d6.loss_mask: 1.0321  decode.d6.loss_dice: 0.8491  decode.d7.loss_cls: 0.3279  decode.d7.loss_mask: 1.0349  decode.d7.loss_dice: 0.8492  decode.d8.loss_cls: 0.2723  decode.d8.loss_mask: 1.1387  decode.d8.loss_dice: 0.8767
05/26 17:21:33 - mmengine - INFO - Iter(train) [ 54800/160000]  base_lr: 6.8566e-05 lr: 6.8566e-06  eta: 11:59:48  time: 0.4183  data_time: 0.0097  memory: 5972  grad_norm: 609.6481  loss: 27.2247  decode.loss_cls: 0.3110  decode.loss_mask: 1.4122  decode.loss_dice: 0.9680  decode.d0.loss_cls: 0.9302  decode.d0.loss_mask: 1.3456  decode.d0.loss_dice: 0.9048  decode.d1.loss_cls: 0.3236  decode.d1.loss_mask: 1.4227  decode.d1.loss_dice: 0.9268  decode.d2.loss_cls: 0.3354  decode.d2.loss_mask: 1.3885  decode.d2.loss_dice: 0.9368  decode.d3.loss_cls: 0.3363  decode.d3.loss_mask: 1.4601  decode.d3.loss_dice: 0.9420  decode.d4.loss_cls: 0.3727  decode.d4.loss_mask: 1.3340  decode.d4.loss_dice: 0.9368  decode.d5.loss_cls: 0.3334  decode.d5.loss_mask: 1.3759  decode.d5.loss_dice: 0.9797  decode.d6.loss_cls: 0.3704  decode.d6.loss_mask: 1.3664  decode.d6.loss_dice: 0.9297  decode.d7.loss_cls: 0.3407  decode.d7.loss_mask: 1.3695  decode.d7.loss_dice: 0.9215  decode.d8.loss_cls: 0.3285  decode.d8.loss_mask: 1.3616  decode.d8.loss_dice: 0.9597
05/26 17:21:54 - mmengine - INFO - Iter(train) [ 54850/160000]  base_lr: 6.8537e-05 lr: 6.8537e-06  eta: 11:59:28  time: 0.4174  data_time: 0.0097  memory: 5987  grad_norm: 479.1734  loss: 23.7594  decode.loss_cls: 0.2571  decode.loss_mask: 1.2505  decode.loss_dice: 0.8741  decode.d0.loss_cls: 0.7434  decode.d0.loss_mask: 1.1253  decode.d0.loss_dice: 0.8148  decode.d1.loss_cls: 0.2504  decode.d1.loss_mask: 1.2566  decode.d1.loss_dice: 0.8384  decode.d2.loss_cls: 0.2777  decode.d2.loss_mask: 1.2058  decode.d2.loss_dice: 0.8487  decode.d3.loss_cls: 0.2535  decode.d3.loss_mask: 1.2160  decode.d3.loss_dice: 0.8446  decode.d4.loss_cls: 0.2923  decode.d4.loss_mask: 1.2084  decode.d4.loss_dice: 0.8642  decode.d5.loss_cls: 0.2840  decode.d5.loss_mask: 1.1812  decode.d5.loss_dice: 0.8442  decode.d6.loss_cls: 0.2845  decode.d6.loss_mask: 1.2156  decode.d6.loss_dice: 0.8735  decode.d7.loss_cls: 0.3145  decode.d7.loss_mask: 1.2043  decode.d7.loss_dice: 0.8232  decode.d8.loss_cls: 0.2666  decode.d8.loss_mask: 1.2174  decode.d8.loss_dice: 0.8286
05/26 17:22:15 - mmengine - INFO - Iter(train) [ 54900/160000]  base_lr: 6.8507e-05 lr: 6.8507e-06  eta: 11:59:08  time: 0.4174  data_time: 0.0097  memory: 5970  grad_norm: 600.2249  loss: 21.2701  decode.loss_cls: 0.1694  decode.loss_mask: 1.0570  decode.loss_dice: 0.8781  decode.d0.loss_cls: 0.6677  decode.d0.loss_mask: 0.9850  decode.d0.loss_dice: 0.8039  decode.d1.loss_cls: 0.1966  decode.d1.loss_mask: 1.0381  decode.d1.loss_dice: 0.8613  decode.d2.loss_cls: 0.1489  decode.d2.loss_mask: 1.0446  decode.d2.loss_dice: 0.8748  decode.d3.loss_cls: 0.2181  decode.d3.loss_mask: 1.0331  decode.d3.loss_dice: 0.8319  decode.d4.loss_cls: 0.2123  decode.d4.loss_mask: 1.0353  decode.d4.loss_dice: 0.8159  decode.d5.loss_cls: 0.2085  decode.d5.loss_mask: 1.0446  decode.d5.loss_dice: 0.8538  decode.d6.loss_cls: 0.2300  decode.d6.loss_mask: 1.0533  decode.d6.loss_dice: 0.8367  decode.d7.loss_cls: 0.2224  decode.d7.loss_mask: 1.0388  decode.d7.loss_dice: 0.8378  decode.d8.loss_cls: 0.1589  decode.d8.loss_mask: 1.0472  decode.d8.loss_dice: 0.8663
05/26 17:22:36 - mmengine - INFO - Iter(train) [ 54950/160000]  base_lr: 6.8478e-05 lr: 6.8478e-06  eta: 11:58:48  time: 0.4182  data_time: 0.0097  memory: 5976  grad_norm: 724.5211  loss: 24.5730  decode.loss_cls: 0.3649  decode.loss_mask: 1.2283  decode.loss_dice: 0.8439  decode.d0.loss_cls: 0.8425  decode.d0.loss_mask: 1.1664  decode.d0.loss_dice: 0.7875  decode.d1.loss_cls: 0.3754  decode.d1.loss_mask: 1.1959  decode.d1.loss_dice: 0.8116  decode.d2.loss_cls: 0.3719  decode.d2.loss_mask: 1.2517  decode.d2.loss_dice: 0.8248  decode.d3.loss_cls: 0.3591  decode.d3.loss_mask: 1.2480  decode.d3.loss_dice: 0.8239  decode.d4.loss_cls: 0.3691  decode.d4.loss_mask: 1.1917  decode.d4.loss_dice: 0.8221  decode.d5.loss_cls: 0.3524  decode.d5.loss_mask: 1.2457  decode.d5.loss_dice: 0.8590  decode.d6.loss_cls: 0.3783  decode.d6.loss_mask: 1.2143  decode.d6.loss_dice: 0.7985  decode.d7.loss_cls: 0.3978  decode.d7.loss_mask: 1.1991  decode.d7.loss_dice: 0.8230  decode.d8.loss_cls: 0.3630  decode.d8.loss_mask: 1.2180  decode.d8.loss_dice: 0.8455
05/26 17:22:57 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 17:22:57 - mmengine - INFO - Iter(train) [ 55000/160000]  base_lr: 6.8449e-05 lr: 6.8449e-06  eta: 11:58:29  time: 0.4178  data_time: 0.0097  memory: 5975  grad_norm: 544.7578  loss: 23.3918  decode.loss_cls: 0.2236  decode.loss_mask: 1.1638  decode.loss_dice: 0.8355  decode.d0.loss_cls: 0.7571  decode.d0.loss_mask: 1.0909  decode.d0.loss_dice: 0.8417  decode.d1.loss_cls: 0.3253  decode.d1.loss_mask: 1.1395  decode.d1.loss_dice: 0.8232  decode.d2.loss_cls: 0.2832  decode.d2.loss_mask: 1.1776  decode.d2.loss_dice: 0.8634  decode.d3.loss_cls: 0.2983  decode.d3.loss_mask: 1.1687  decode.d3.loss_dice: 0.8478  decode.d4.loss_cls: 0.3593  decode.d4.loss_mask: 1.1745  decode.d4.loss_dice: 0.8616  decode.d5.loss_cls: 0.2627  decode.d5.loss_mask: 1.1680  decode.d5.loss_dice: 0.8367  decode.d6.loss_cls: 0.2773  decode.d6.loss_mask: 1.1557  decode.d6.loss_dice: 0.8633  decode.d7.loss_cls: 0.3353  decode.d7.loss_mask: 1.1642  decode.d7.loss_dice: 0.8438  decode.d8.loss_cls: 0.2691  decode.d8.loss_mask: 1.1473  decode.d8.loss_dice: 0.8334
05/26 17:22:57 - mmengine - INFO - Saving checkpoint at 55000 iterations
05/26 17:23:01 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:11  time: 0.0503  data_time: 0.0012  memory: 1391  
05/26 17:23:04 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:08  time: 0.0497  data_time: 0.0013  memory: 1205  
05/26 17:23:07 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:06  time: 0.0537  data_time: 0.0013  memory: 1596  
05/26 17:23:09 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:04  time: 0.0530  data_time: 0.0013  memory: 1298  
05/26 17:23:12 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:01:02  time: 0.0525  data_time: 0.0013  memory: 1298  
05/26 17:23:15 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:59  time: 0.0529  data_time: 0.0013  memory: 1279  
05/26 17:23:17 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:57  time: 0.0550  data_time: 0.0026  memory: 1224  
05/26 17:23:20 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:54  time: 0.0540  data_time: 0.0013  memory: 1298  
05/26 17:23:22 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:52  time: 0.0512  data_time: 0.0013  memory: 1298  
05/26 17:23:25 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:49  time: 0.0536  data_time: 0.0013  memory: 1725  
05/26 17:23:28 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:46  time: 0.0506  data_time: 0.0013  memory: 1336  
05/26 17:23:30 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:44  time: 0.0515  data_time: 0.0013  memory: 1298  
05/26 17:23:33 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:41  time: 0.0527  data_time: 0.0013  memory: 1205  
05/26 17:23:35 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:38  time: 0.0513  data_time: 0.0013  memory: 1316  
05/26 17:23:38 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:36  time: 0.0495  data_time: 0.0013  memory: 1279  
05/26 17:23:40 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:33  time: 0.0536  data_time: 0.0013  memory: 1410  
05/26 17:23:43 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:30  time: 0.0505  data_time: 0.0013  memory: 1279  
05/26 17:23:46 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:28  time: 0.0508  data_time: 0.0013  memory: 1205  
05/26 17:23:48 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:25  time: 0.0505  data_time: 0.0013  memory: 1205  
05/26 17:23:51 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:23  time: 0.0499  data_time: 0.0013  memory: 1336  
05/26 17:23:53 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:20  time: 0.0507  data_time: 0.0013  memory: 1246  
05/26 17:23:56 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0517  data_time: 0.0013  memory: 1503  
05/26 17:23:58 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:15  time: 0.0500  data_time: 0.0013  memory: 1261  
05/26 17:24:01 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0508  data_time: 0.0013  memory: 1298  
05/26 17:24:03 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:10  time: 0.0514  data_time: 0.0013  memory: 1447  
05/26 17:24:06 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0500  data_time: 0.0013  memory: 1298  
05/26 17:24:08 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:05  time: 0.0511  data_time: 0.0013  memory: 1279  
05/26 17:24:11 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0505  data_time: 0.0013  memory: 1205  
05/26 17:24:13 - mmengine - INFO - per class results:
05/26 17:24:13 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background |  95.3 | 96.93 |
|  aeroplane  | 78.86 | 98.07 |
|   bicycle   | 44.53 | 95.35 |
|     bird    | 93.42 |  96.2 |
|     boat    | 46.74 | 61.46 |
|    bottle   | 78.88 |  89.8 |
|     bus     | 94.97 | 97.67 |
|     car     | 91.75 | 95.76 |
|     cat     | 92.97 | 98.38 |
|    chair    | 36.41 | 52.47 |
|     cow     | 71.32 |  80.6 |
| diningtable | 60.48 | 69.53 |
|     dog     | 85.54 | 94.25 |
|    horse    | 78.21 | 90.17 |
|  motorbike  |  87.9 |  94.2 |
|    person   | 90.83 | 94.63 |
| pottedplant | 66.37 | 88.65 |
|    sheep    | 78.54 |  91.9 |
|     sofa    | 59.11 |  83.4 |
|    train    | 87.05 | 93.65 |
|  tvmonitor  | 79.54 | 88.63 |
+-------------+-------+-------+
05/26 17:24:13 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.1400  mIoU: 76.1300  mAcc: 88.1800  data_time: 0.0013  time: 0.0513
05/26 17:24:34 - mmengine - INFO - Iter(train) [ 55050/160000]  base_lr: 6.8419e-05 lr: 6.8419e-06  eta: 11:58:09  time: 0.4184  data_time: 0.0098  memory: 5971  grad_norm: 750.8790  loss: 21.4958  decode.loss_cls: 0.1946  decode.loss_mask: 1.1500  decode.loss_dice: 0.7502  decode.d0.loss_cls: 0.6427  decode.d0.loss_mask: 1.1053  decode.d0.loss_dice: 0.7534  decode.d1.loss_cls: 0.2188  decode.d1.loss_mask: 1.1499  decode.d1.loss_dice: 0.7382  decode.d2.loss_cls: 0.2134  decode.d2.loss_mask: 1.1713  decode.d2.loss_dice: 0.7611  decode.d3.loss_cls: 0.2118  decode.d3.loss_mask: 1.1413  decode.d3.loss_dice: 0.7584  decode.d4.loss_cls: 0.2279  decode.d4.loss_mask: 1.1448  decode.d4.loss_dice: 0.7428  decode.d5.loss_cls: 0.1879  decode.d5.loss_mask: 1.1552  decode.d5.loss_dice: 0.7656  decode.d6.loss_cls: 0.2052  decode.d6.loss_mask: 1.1478  decode.d6.loss_dice: 0.7398  decode.d7.loss_cls: 0.2162  decode.d7.loss_mask: 1.1417  decode.d7.loss_dice: 0.7640  decode.d8.loss_cls: 0.2178  decode.d8.loss_mask: 1.1416  decode.d8.loss_dice: 0.7372
05/26 17:24:55 - mmengine - INFO - Iter(train) [ 55100/160000]  base_lr: 6.8390e-05 lr: 6.8390e-06  eta: 11:57:49  time: 0.4175  data_time: 0.0097  memory: 5987  grad_norm: 742.8779  loss: 26.6061  decode.loss_cls: 0.3685  decode.loss_mask: 1.2283  decode.loss_dice: 0.9380  decode.d0.loss_cls: 0.8366  decode.d0.loss_mask: 1.1709  decode.d0.loss_dice: 0.9452  decode.d1.loss_cls: 0.3933  decode.d1.loss_mask: 1.2593  decode.d1.loss_dice: 0.9721  decode.d2.loss_cls: 0.3831  decode.d2.loss_mask: 1.2722  decode.d2.loss_dice: 0.9777  decode.d3.loss_cls: 0.4299  decode.d3.loss_mask: 1.2296  decode.d3.loss_dice: 0.9530  decode.d4.loss_cls: 0.4304  decode.d4.loss_mask: 1.2785  decode.d4.loss_dice: 0.9959  decode.d5.loss_cls: 0.3743  decode.d5.loss_mask: 1.2546  decode.d5.loss_dice: 0.9854  decode.d6.loss_cls: 0.4219  decode.d6.loss_mask: 1.2446  decode.d6.loss_dice: 0.9846  decode.d7.loss_cls: 0.4185  decode.d7.loss_mask: 1.3089  decode.d7.loss_dice: 0.9688  decode.d8.loss_cls: 0.4064  decode.d8.loss_mask: 1.2307  decode.d8.loss_dice: 0.9450
05/26 17:25:16 - mmengine - INFO - Iter(train) [ 55150/160000]  base_lr: 6.8361e-05 lr: 6.8361e-06  eta: 11:57:29  time: 0.4177  data_time: 0.0097  memory: 5972  grad_norm: 1362.7678  loss: 24.4288  decode.loss_cls: 0.2573  decode.loss_mask: 1.2292  decode.loss_dice: 0.9609  decode.d0.loss_cls: 0.7662  decode.d0.loss_mask: 1.1225  decode.d0.loss_dice: 0.9039  decode.d1.loss_cls: 0.2507  decode.d1.loss_mask: 1.1979  decode.d1.loss_dice: 0.9436  decode.d2.loss_cls: 0.2605  decode.d2.loss_mask: 1.1804  decode.d2.loss_dice: 0.9150  decode.d3.loss_cls: 0.2604  decode.d3.loss_mask: 1.2249  decode.d3.loss_dice: 0.9452  decode.d4.loss_cls: 0.2985  decode.d4.loss_mask: 1.1961  decode.d4.loss_dice: 0.9247  decode.d5.loss_cls: 0.2258  decode.d5.loss_mask: 1.2096  decode.d5.loss_dice: 0.9578  decode.d6.loss_cls: 0.2506  decode.d6.loss_mask: 1.1779  decode.d6.loss_dice: 0.9552  decode.d7.loss_cls: 0.2507  decode.d7.loss_mask: 1.1935  decode.d7.loss_dice: 0.9255  decode.d8.loss_cls: 0.2538  decode.d8.loss_mask: 1.2247  decode.d8.loss_dice: 0.9660
05/26 17:25:37 - mmengine - INFO - Iter(train) [ 55200/160000]  base_lr: 6.8331e-05 lr: 6.8331e-06  eta: 11:57:09  time: 0.4199  data_time: 0.0111  memory: 5976  grad_norm: 732.0111  loss: 24.2760  decode.loss_cls: 0.2228  decode.loss_mask: 1.2697  decode.loss_dice: 0.8924  decode.d0.loss_cls: 0.7362  decode.d0.loss_mask: 1.2066  decode.d0.loss_dice: 0.8687  decode.d1.loss_cls: 0.2657  decode.d1.loss_mask: 1.2264  decode.d1.loss_dice: 0.8519  decode.d2.loss_cls: 0.3122  decode.d2.loss_mask: 1.1714  decode.d2.loss_dice: 0.8569  decode.d3.loss_cls: 0.2446  decode.d3.loss_mask: 1.2825  decode.d3.loss_dice: 0.8877  decode.d4.loss_cls: 0.2867  decode.d4.loss_mask: 1.2699  decode.d4.loss_dice: 0.9325  decode.d5.loss_cls: 0.2667  decode.d5.loss_mask: 1.2704  decode.d5.loss_dice: 0.8888  decode.d6.loss_cls: 0.2799  decode.d6.loss_mask: 1.2142  decode.d6.loss_dice: 0.8517  decode.d7.loss_cls: 0.2925  decode.d7.loss_mask: 1.1996  decode.d7.loss_dice: 0.8737  decode.d8.loss_cls: 0.2435  decode.d8.loss_mask: 1.2239  decode.d8.loss_dice: 0.8862
05/26 17:25:58 - mmengine - INFO - Iter(train) [ 55250/160000]  base_lr: 6.8302e-05 lr: 6.8302e-06  eta: 11:56:49  time: 0.4169  data_time: 0.0097  memory: 5971  grad_norm: 482.4219  loss: 21.8735  decode.loss_cls: 0.2458  decode.loss_mask: 1.0773  decode.loss_dice: 0.8251  decode.d0.loss_cls: 0.7278  decode.d0.loss_mask: 0.9878  decode.d0.loss_dice: 0.7984  decode.d1.loss_cls: 0.2214  decode.d1.loss_mask: 1.1157  decode.d1.loss_dice: 0.8398  decode.d2.loss_cls: 0.2300  decode.d2.loss_mask: 1.0769  decode.d2.loss_dice: 0.8293  decode.d3.loss_cls: 0.2400  decode.d3.loss_mask: 1.0362  decode.d3.loss_dice: 0.7921  decode.d4.loss_cls: 0.3275  decode.d4.loss_mask: 1.0465  decode.d4.loss_dice: 0.8145  decode.d5.loss_cls: 0.3094  decode.d5.loss_mask: 1.0535  decode.d5.loss_dice: 0.7921  decode.d6.loss_cls: 0.3191  decode.d6.loss_mask: 1.0947  decode.d6.loss_dice: 0.7999  decode.d7.loss_cls: 0.2776  decode.d7.loss_mask: 1.0641  decode.d7.loss_dice: 0.8192  decode.d8.loss_cls: 0.2731  decode.d8.loss_mask: 1.0391  decode.d8.loss_dice: 0.7994
05/26 17:26:19 - mmengine - INFO - Iter(train) [ 55300/160000]  base_lr: 6.8273e-05 lr: 6.8273e-06  eta: 11:56:30  time: 0.4171  data_time: 0.0097  memory: 5971  grad_norm: 620.0934  loss: 17.3770  decode.loss_cls: 0.0918  decode.loss_mask: 0.9476  decode.loss_dice: 0.6145  decode.d0.loss_cls: 0.5744  decode.d0.loss_mask: 0.9529  decode.d0.loss_dice: 0.6039  decode.d1.loss_cls: 0.1334  decode.d1.loss_mask: 0.9604  decode.d1.loss_dice: 0.6132  decode.d2.loss_cls: 0.1202  decode.d2.loss_mask: 0.9588  decode.d2.loss_dice: 0.6020  decode.d3.loss_cls: 0.1362  decode.d3.loss_mask: 0.9540  decode.d3.loss_dice: 0.6090  decode.d4.loss_cls: 0.1048  decode.d4.loss_mask: 0.9877  decode.d4.loss_dice: 0.6361  decode.d5.loss_cls: 0.1366  decode.d5.loss_mask: 0.9372  decode.d5.loss_dice: 0.6031  decode.d6.loss_cls: 0.1355  decode.d6.loss_mask: 0.9518  decode.d6.loss_dice: 0.6213  decode.d7.loss_cls: 0.1117  decode.d7.loss_mask: 0.9551  decode.d7.loss_dice: 0.6289  decode.d8.loss_cls: 0.0768  decode.d8.loss_mask: 0.9792  decode.d8.loss_dice: 0.6392
05/26 17:26:40 - mmengine - INFO - Iter(train) [ 55350/160000]  base_lr: 6.8243e-05 lr: 6.8243e-06  eta: 11:56:10  time: 0.4176  data_time: 0.0098  memory: 5975  grad_norm: 1108.5960  loss: 21.3391  decode.loss_cls: 0.2834  decode.loss_mask: 1.0040  decode.loss_dice: 0.7221  decode.d0.loss_cls: 0.7734  decode.d0.loss_mask: 1.0191  decode.d0.loss_dice: 0.7063  decode.d1.loss_cls: 0.3313  decode.d1.loss_mask: 1.0438  decode.d1.loss_dice: 0.7140  decode.d2.loss_cls: 0.3487  decode.d2.loss_mask: 1.0361  decode.d2.loss_dice: 0.7526  decode.d3.loss_cls: 0.3310  decode.d3.loss_mask: 1.0262  decode.d3.loss_dice: 0.7575  decode.d4.loss_cls: 0.3069  decode.d4.loss_mask: 1.0437  decode.d4.loss_dice: 0.7533  decode.d5.loss_cls: 0.3536  decode.d5.loss_mask: 1.0946  decode.d5.loss_dice: 0.7561  decode.d6.loss_cls: 0.3059  decode.d6.loss_mask: 1.0669  decode.d6.loss_dice: 0.7509  decode.d7.loss_cls: 0.3218  decode.d7.loss_mask: 1.0472  decode.d7.loss_dice: 0.7218  decode.d8.loss_cls: 0.2706  decode.d8.loss_mask: 0.9946  decode.d8.loss_dice: 0.7019
05/26 17:27:01 - mmengine - INFO - Iter(train) [ 55400/160000]  base_lr: 6.8214e-05 lr: 6.8214e-06  eta: 11:55:50  time: 0.4182  data_time: 0.0097  memory: 5981  grad_norm: 428.0515  loss: 21.2507  decode.loss_cls: 0.1330  decode.loss_mask: 1.1156  decode.loss_dice: 0.8182  decode.d0.loss_cls: 0.6552  decode.d0.loss_mask: 1.0421  decode.d0.loss_dice: 0.7628  decode.d1.loss_cls: 0.1612  decode.d1.loss_mask: 1.1316  decode.d1.loss_dice: 0.8149  decode.d2.loss_cls: 0.1622  decode.d2.loss_mask: 1.1262  decode.d2.loss_dice: 0.8213  decode.d3.loss_cls: 0.1092  decode.d3.loss_mask: 1.1356  decode.d3.loss_dice: 0.8157  decode.d4.loss_cls: 0.1637  decode.d4.loss_mask: 1.1175  decode.d4.loss_dice: 0.8334  decode.d5.loss_cls: 0.1424  decode.d5.loss_mask: 1.1228  decode.d5.loss_dice: 0.8212  decode.d6.loss_cls: 0.1948  decode.d6.loss_mask: 1.0931  decode.d6.loss_dice: 0.7698  decode.d7.loss_cls: 0.1697  decode.d7.loss_mask: 1.1360  decode.d7.loss_dice: 0.8020  decode.d8.loss_cls: 0.1354  decode.d8.loss_mask: 1.1289  decode.d8.loss_dice: 0.8153
05/26 17:27:22 - mmengine - INFO - Iter(train) [ 55450/160000]  base_lr: 6.8185e-05 lr: 6.8185e-06  eta: 11:55:30  time: 0.4187  data_time: 0.0098  memory: 5966  grad_norm: 531.4508  loss: 24.3457  decode.loss_cls: 0.2762  decode.loss_mask: 1.2190  decode.loss_dice: 0.8538  decode.d0.loss_cls: 0.7647  decode.d0.loss_mask: 1.1893  decode.d0.loss_dice: 0.7970  decode.d1.loss_cls: 0.2678  decode.d1.loss_mask: 1.2442  decode.d1.loss_dice: 0.8822  decode.d2.loss_cls: 0.2507  decode.d2.loss_mask: 1.2078  decode.d2.loss_dice: 0.8974  decode.d3.loss_cls: 0.2714  decode.d3.loss_mask: 1.2398  decode.d3.loss_dice: 0.8547  decode.d4.loss_cls: 0.3100  decode.d4.loss_mask: 1.2283  decode.d4.loss_dice: 0.8606  decode.d5.loss_cls: 0.2728  decode.d5.loss_mask: 1.2929  decode.d5.loss_dice: 0.8770  decode.d6.loss_cls: 0.3284  decode.d6.loss_mask: 1.2337  decode.d6.loss_dice: 0.8429  decode.d7.loss_cls: 0.2581  decode.d7.loss_mask: 1.3441  decode.d7.loss_dice: 0.8959  decode.d8.loss_cls: 0.2551  decode.d8.loss_mask: 1.2549  decode.d8.loss_dice: 0.8750
05/26 17:27:43 - mmengine - INFO - Iter(train) [ 55500/160000]  base_lr: 6.8155e-05 lr: 6.8155e-06  eta: 11:55:10  time: 0.4183  data_time: 0.0098  memory: 5970  grad_norm: 680.5919  loss: 23.0801  decode.loss_cls: 0.1991  decode.loss_mask: 1.1543  decode.loss_dice: 0.8855  decode.d0.loss_cls: 0.8220  decode.d0.loss_mask: 1.0785  decode.d0.loss_dice: 0.8405  decode.d1.loss_cls: 0.2407  decode.d1.loss_mask: 1.1168  decode.d1.loss_dice: 0.8631  decode.d2.loss_cls: 0.2394  decode.d2.loss_mask: 1.1381  decode.d2.loss_dice: 0.8649  decode.d3.loss_cls: 0.2630  decode.d3.loss_mask: 1.1532  decode.d3.loss_dice: 0.8848  decode.d4.loss_cls: 0.3203  decode.d4.loss_mask: 1.1080  decode.d4.loss_dice: 0.8432  decode.d5.loss_cls: 0.2483  decode.d5.loss_mask: 1.1010  decode.d5.loss_dice: 0.8490  decode.d6.loss_cls: 0.2634  decode.d6.loss_mask: 1.1332  decode.d6.loss_dice: 0.8582  decode.d7.loss_cls: 0.2615  decode.d7.loss_mask: 1.1688  decode.d7.loss_dice: 0.8613  decode.d8.loss_cls: 0.2976  decode.d8.loss_mask: 1.1680  decode.d8.loss_dice: 0.8546
05/26 17:28:04 - mmengine - INFO - Iter(train) [ 55550/160000]  base_lr: 6.8126e-05 lr: 6.8126e-06  eta: 11:54:51  time: 0.4198  data_time: 0.0098  memory: 5989  grad_norm: 880.1774  loss: 23.8843  decode.loss_cls: 0.1773  decode.loss_mask: 1.2238  decode.loss_dice: 0.8720  decode.d0.loss_cls: 0.6270  decode.d0.loss_mask: 1.2342  decode.d0.loss_dice: 0.8243  decode.d1.loss_cls: 0.2330  decode.d1.loss_mask: 1.2701  decode.d1.loss_dice: 0.8699  decode.d2.loss_cls: 0.2569  decode.d2.loss_mask: 1.2314  decode.d2.loss_dice: 0.8767  decode.d3.loss_cls: 0.2066  decode.d3.loss_mask: 1.2482  decode.d3.loss_dice: 0.8993  decode.d4.loss_cls: 0.2778  decode.d4.loss_mask: 1.2117  decode.d4.loss_dice: 0.8442  decode.d5.loss_cls: 0.2631  decode.d5.loss_mask: 1.2208  decode.d5.loss_dice: 0.8747  decode.d6.loss_cls: 0.3186  decode.d6.loss_mask: 1.2077  decode.d6.loss_dice: 0.8687  decode.d7.loss_cls: 0.2680  decode.d7.loss_mask: 1.2420  decode.d7.loss_dice: 0.8542  decode.d8.loss_cls: 0.2882  decode.d8.loss_mask: 1.2372  decode.d8.loss_dice: 0.8566
05/26 17:28:24 - mmengine - INFO - Iter(train) [ 55600/160000]  base_lr: 6.8097e-05 lr: 6.8097e-06  eta: 11:54:31  time: 0.4186  data_time: 0.0098  memory: 5972  grad_norm: 589.7489  loss: 22.0492  decode.loss_cls: 0.1501  decode.loss_mask: 1.1901  decode.loss_dice: 0.8181  decode.d0.loss_cls: 0.6264  decode.d0.loss_mask: 1.1605  decode.d0.loss_dice: 0.7470  decode.d1.loss_cls: 0.1467  decode.d1.loss_mask: 1.1889  decode.d1.loss_dice: 0.8346  decode.d2.loss_cls: 0.1646  decode.d2.loss_mask: 1.1877  decode.d2.loss_dice: 0.8302  decode.d3.loss_cls: 0.1250  decode.d3.loss_mask: 1.1807  decode.d3.loss_dice: 0.8402  decode.d4.loss_cls: 0.1342  decode.d4.loss_mask: 1.2073  decode.d4.loss_dice: 0.8054  decode.d5.loss_cls: 0.1618  decode.d5.loss_mask: 1.1887  decode.d5.loss_dice: 0.8456  decode.d6.loss_cls: 0.1427  decode.d6.loss_mask: 1.1979  decode.d6.loss_dice: 0.7966  decode.d7.loss_cls: 0.1311  decode.d7.loss_mask: 1.2116  decode.d7.loss_dice: 0.8429  decode.d8.loss_cls: 0.1625  decode.d8.loss_mask: 1.1879  decode.d8.loss_dice: 0.8424
05/26 17:28:45 - mmengine - INFO - Iter(train) [ 55650/160000]  base_lr: 6.8067e-05 lr: 6.8067e-06  eta: 11:54:11  time: 0.4181  data_time: 0.0097  memory: 5981  grad_norm: 649.1796  loss: 27.4340  decode.loss_cls: 0.4432  decode.loss_mask: 1.2208  decode.loss_dice: 0.9594  decode.d0.loss_cls: 1.0143  decode.d0.loss_mask: 1.1590  decode.d0.loss_dice: 0.8481  decode.d1.loss_cls: 0.4441  decode.d1.loss_mask: 1.2309  decode.d1.loss_dice: 0.9889  decode.d2.loss_cls: 0.5486  decode.d2.loss_mask: 1.2688  decode.d2.loss_dice: 1.0015  decode.d3.loss_cls: 0.5546  decode.d3.loss_mask: 1.2047  decode.d3.loss_dice: 0.9854  decode.d4.loss_cls: 0.4486  decode.d4.loss_mask: 1.2611  decode.d4.loss_dice: 0.9563  decode.d5.loss_cls: 0.4436  decode.d5.loss_mask: 1.2587  decode.d5.loss_dice: 0.9697  decode.d6.loss_cls: 0.4800  decode.d6.loss_mask: 1.2159  decode.d6.loss_dice: 0.9921  decode.d7.loss_cls: 0.4386  decode.d7.loss_mask: 1.3364  decode.d7.loss_dice: 1.0015  decode.d8.loss_cls: 0.4505  decode.d8.loss_mask: 1.3016  decode.d8.loss_dice: 1.0073
05/26 17:29:06 - mmengine - INFO - Iter(train) [ 55700/160000]  base_lr: 6.8038e-05 lr: 6.8038e-06  eta: 11:53:51  time: 0.4211  data_time: 0.0097  memory: 5986  grad_norm: 585.5719  loss: 21.1022  decode.loss_cls: 0.1557  decode.loss_mask: 1.1035  decode.loss_dice: 0.7924  decode.d0.loss_cls: 0.7187  decode.d0.loss_mask: 1.0084  decode.d0.loss_dice: 0.7241  decode.d1.loss_cls: 0.1824  decode.d1.loss_mask: 1.1205  decode.d1.loss_dice: 0.8030  decode.d2.loss_cls: 0.2194  decode.d2.loss_mask: 1.0316  decode.d2.loss_dice: 0.7630  decode.d3.loss_cls: 0.2090  decode.d3.loss_mask: 1.1171  decode.d3.loss_dice: 0.7613  decode.d4.loss_cls: 0.2005  decode.d4.loss_mask: 1.1225  decode.d4.loss_dice: 0.7984  decode.d5.loss_cls: 0.1865  decode.d5.loss_mask: 1.1179  decode.d5.loss_dice: 0.7827  decode.d6.loss_cls: 0.2282  decode.d6.loss_mask: 1.0466  decode.d6.loss_dice: 0.7629  decode.d7.loss_cls: 0.2032  decode.d7.loss_mask: 1.0977  decode.d7.loss_dice: 0.7895  decode.d8.loss_cls: 0.2125  decode.d8.loss_mask: 1.0441  decode.d8.loss_dice: 0.7988
05/26 17:29:27 - mmengine - INFO - Iter(train) [ 55750/160000]  base_lr: 6.8008e-05 lr: 6.8008e-06  eta: 11:53:32  time: 0.4200  data_time: 0.0098  memory: 5966  grad_norm: 659.4648  loss: 20.5073  decode.loss_cls: 0.2495  decode.loss_mask: 0.9999  decode.loss_dice: 0.6958  decode.d0.loss_cls: 0.7413  decode.d0.loss_mask: 0.9764  decode.d0.loss_dice: 0.6777  decode.d1.loss_cls: 0.2556  decode.d1.loss_mask: 1.0170  decode.d1.loss_dice: 0.6890  decode.d2.loss_cls: 0.2461  decode.d2.loss_mask: 1.0239  decode.d2.loss_dice: 0.7207  decode.d3.loss_cls: 0.2700  decode.d3.loss_mask: 1.0104  decode.d3.loss_dice: 0.6982  decode.d4.loss_cls: 0.2734  decode.d4.loss_mask: 1.0708  decode.d4.loss_dice: 0.7469  decode.d5.loss_cls: 0.3254  decode.d5.loss_mask: 1.0289  decode.d5.loss_dice: 0.6951  decode.d6.loss_cls: 0.3028  decode.d6.loss_mask: 1.0492  decode.d6.loss_dice: 0.6971  decode.d7.loss_cls: 0.2704  decode.d7.loss_mask: 1.0293  decode.d7.loss_dice: 0.7334  decode.d8.loss_cls: 0.2685  decode.d8.loss_mask: 1.0216  decode.d8.loss_dice: 0.7230
05/26 17:29:48 - mmengine - INFO - Iter(train) [ 55800/160000]  base_lr: 6.7979e-05 lr: 6.7979e-06  eta: 11:53:12  time: 0.4180  data_time: 0.0097  memory: 5968  grad_norm: 452.6451  loss: 15.5196  decode.loss_cls: 0.0468  decode.loss_mask: 0.8062  decode.loss_dice: 0.6221  decode.d0.loss_cls: 0.5691  decode.d0.loss_mask: 0.7911  decode.d0.loss_dice: 0.6002  decode.d1.loss_cls: 0.0593  decode.d1.loss_mask: 0.8333  decode.d1.loss_dice: 0.6466  decode.d2.loss_cls: 0.0471  decode.d2.loss_mask: 0.8231  decode.d2.loss_dice: 0.6222  decode.d3.loss_cls: 0.0435  decode.d3.loss_mask: 0.8292  decode.d3.loss_dice: 0.6194  decode.d4.loss_cls: 0.0608  decode.d4.loss_mask: 0.8113  decode.d4.loss_dice: 0.6216  decode.d5.loss_cls: 0.0695  decode.d5.loss_mask: 0.8252  decode.d5.loss_dice: 0.6304  decode.d6.loss_cls: 0.0612  decode.d6.loss_mask: 0.8334  decode.d6.loss_dice: 0.6256  decode.d7.loss_cls: 0.0659  decode.d7.loss_mask: 0.8139  decode.d7.loss_dice: 0.6281  decode.d8.loss_cls: 0.0426  decode.d8.loss_mask: 0.8377  decode.d8.loss_dice: 0.6329
05/26 17:30:09 - mmengine - INFO - Iter(train) [ 55850/160000]  base_lr: 6.7950e-05 lr: 6.7950e-06  eta: 11:52:52  time: 0.4174  data_time: 0.0097  memory: 5989  grad_norm: 1376.2291  loss: 29.8166  decode.loss_cls: 0.2694  decode.loss_mask: 1.5659  decode.loss_dice: 1.0995  decode.d0.loss_cls: 0.9423  decode.d0.loss_mask: 1.4095  decode.d0.loss_dice: 0.9923  decode.d1.loss_cls: 0.3074  decode.d1.loss_mask: 1.4690  decode.d1.loss_dice: 1.1020  decode.d2.loss_cls: 0.2753  decode.d2.loss_mask: 1.5356  decode.d2.loss_dice: 1.1163  decode.d3.loss_cls: 0.2505  decode.d3.loss_mask: 1.5269  decode.d3.loss_dice: 1.1190  decode.d4.loss_cls: 0.3308  decode.d4.loss_mask: 1.5776  decode.d4.loss_dice: 1.0871  decode.d5.loss_cls: 0.3057  decode.d5.loss_mask: 1.5566  decode.d5.loss_dice: 1.1194  decode.d6.loss_cls: 0.2995  decode.d6.loss_mask: 1.5485  decode.d6.loss_dice: 1.1108  decode.d7.loss_cls: 0.3116  decode.d7.loss_mask: 1.5236  decode.d7.loss_dice: 1.1347  decode.d8.loss_cls: 0.2804  decode.d8.loss_mask: 1.5570  decode.d8.loss_dice: 1.0923
05/26 17:30:30 - mmengine - INFO - Iter(train) [ 55900/160000]  base_lr: 6.7920e-05 lr: 6.7920e-06  eta: 11:52:32  time: 0.4191  data_time: 0.0097  memory: 5967  grad_norm: 631.6568  loss: 21.2502  decode.loss_cls: 0.2598  decode.loss_mask: 1.0312  decode.loss_dice: 0.7458  decode.d0.loss_cls: 0.7256  decode.d0.loss_mask: 1.0087  decode.d0.loss_dice: 0.7325  decode.d1.loss_cls: 0.3181  decode.d1.loss_mask: 0.9594  decode.d1.loss_dice: 0.7427  decode.d2.loss_cls: 0.3082  decode.d2.loss_mask: 1.0964  decode.d2.loss_dice: 0.7414  decode.d3.loss_cls: 0.2816  decode.d3.loss_mask: 1.0395  decode.d3.loss_dice: 0.7588  decode.d4.loss_cls: 0.2769  decode.d4.loss_mask: 1.0887  decode.d4.loss_dice: 0.7660  decode.d5.loss_cls: 0.2869  decode.d5.loss_mask: 1.0612  decode.d5.loss_dice: 0.7576  decode.d6.loss_cls: 0.3135  decode.d6.loss_mask: 1.1056  decode.d6.loss_dice: 0.7613  decode.d7.loss_cls: 0.2913  decode.d7.loss_mask: 1.0159  decode.d7.loss_dice: 0.7293  decode.d8.loss_cls: 0.2827  decode.d8.loss_mask: 1.0093  decode.d8.loss_dice: 0.7542
05/26 17:30:51 - mmengine - INFO - Iter(train) [ 55950/160000]  base_lr: 6.7891e-05 lr: 6.7891e-06  eta: 11:52:12  time: 0.4187  data_time: 0.0098  memory: 5988  grad_norm: 538.6466  loss: 24.9083  decode.loss_cls: 0.2593  decode.loss_mask: 1.2547  decode.loss_dice: 0.9118  decode.d0.loss_cls: 0.7097  decode.d0.loss_mask: 1.2326  decode.d0.loss_dice: 0.9088  decode.d1.loss_cls: 0.2517  decode.d1.loss_mask: 1.2544  decode.d1.loss_dice: 0.9083  decode.d2.loss_cls: 0.2116  decode.d2.loss_mask: 1.2921  decode.d2.loss_dice: 0.9513  decode.d3.loss_cls: 0.2590  decode.d3.loss_mask: 1.2422  decode.d3.loss_dice: 0.9229  decode.d4.loss_cls: 0.2444  decode.d4.loss_mask: 1.2665  decode.d4.loss_dice: 0.9317  decode.d5.loss_cls: 0.2631  decode.d5.loss_mask: 1.2360  decode.d5.loss_dice: 0.9376  decode.d6.loss_cls: 0.2577  decode.d6.loss_mask: 1.2938  decode.d6.loss_dice: 0.9294  decode.d7.loss_cls: 0.2027  decode.d7.loss_mask: 1.3806  decode.d7.loss_dice: 0.9520  decode.d8.loss_cls: 0.2446  decode.d8.loss_mask: 1.2766  decode.d8.loss_dice: 0.9211
05/26 17:31:12 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 17:31:12 - mmengine - INFO - Iter(train) [ 56000/160000]  base_lr: 6.7862e-05 lr: 6.7862e-06  eta: 11:51:53  time: 0.4207  data_time: 0.0098  memory: 5974  grad_norm: 820.6547  loss: 27.1432  decode.loss_cls: 0.3087  decode.loss_mask: 1.2494  decode.loss_dice: 1.0677  decode.d0.loss_cls: 0.8410  decode.d0.loss_mask: 1.2441  decode.d0.loss_dice: 1.0594  decode.d1.loss_cls: 0.3523  decode.d1.loss_mask: 1.1875  decode.d1.loss_dice: 1.0576  decode.d2.loss_cls: 0.4002  decode.d2.loss_mask: 1.1681  decode.d2.loss_dice: 1.0640  decode.d3.loss_cls: 0.3537  decode.d3.loss_mask: 1.1715  decode.d3.loss_dice: 1.0772  decode.d4.loss_cls: 0.3953  decode.d4.loss_mask: 1.2452  decode.d4.loss_dice: 1.1020  decode.d5.loss_cls: 0.3195  decode.d5.loss_mask: 1.2827  decode.d5.loss_dice: 1.1180  decode.d6.loss_cls: 0.3284  decode.d6.loss_mask: 1.2490  decode.d6.loss_dice: 1.1255  decode.d7.loss_cls: 0.3348  decode.d7.loss_mask: 1.1918  decode.d7.loss_dice: 1.1151  decode.d8.loss_cls: 0.3700  decode.d8.loss_mask: 1.2632  decode.d8.loss_dice: 1.1003
05/26 17:31:33 - mmengine - INFO - Iter(train) [ 56050/160000]  base_lr: 6.7832e-05 lr: 6.7832e-06  eta: 11:51:33  time: 0.4198  data_time: 0.0097  memory: 5966  grad_norm: 656.3034  loss: 20.9712  decode.loss_cls: 0.2031  decode.loss_mask: 1.0719  decode.loss_dice: 0.7871  decode.d0.loss_cls: 0.6596  decode.d0.loss_mask: 1.0240  decode.d0.loss_dice: 0.7685  decode.d1.loss_cls: 0.2144  decode.d1.loss_mask: 1.0637  decode.d1.loss_dice: 0.7802  decode.d2.loss_cls: 0.2407  decode.d2.loss_mask: 1.0710  decode.d2.loss_dice: 0.7750  decode.d3.loss_cls: 0.2171  decode.d3.loss_mask: 1.0390  decode.d3.loss_dice: 0.7504  decode.d4.loss_cls: 0.2398  decode.d4.loss_mask: 1.0505  decode.d4.loss_dice: 0.7931  decode.d5.loss_cls: 0.2232  decode.d5.loss_mask: 1.0544  decode.d5.loss_dice: 0.7798  decode.d6.loss_cls: 0.2412  decode.d6.loss_mask: 1.0661  decode.d6.loss_dice: 0.7635  decode.d7.loss_cls: 0.2297  decode.d7.loss_mask: 1.0550  decode.d7.loss_dice: 0.7728  decode.d8.loss_cls: 0.2150  decode.d8.loss_mask: 1.0489  decode.d8.loss_dice: 0.7726
05/26 17:31:54 - mmengine - INFO - Iter(train) [ 56100/160000]  base_lr: 6.7803e-05 lr: 6.7803e-06  eta: 11:51:13  time: 0.4181  data_time: 0.0097  memory: 5969  grad_norm: 758.6671  loss: 20.7420  decode.loss_cls: 0.1880  decode.loss_mask: 1.0099  decode.loss_dice: 0.7990  decode.d0.loss_cls: 0.7165  decode.d0.loss_mask: 0.9438  decode.d0.loss_dice: 0.7839  decode.d1.loss_cls: 0.2642  decode.d1.loss_mask: 1.0801  decode.d1.loss_dice: 0.7663  decode.d2.loss_cls: 0.2615  decode.d2.loss_mask: 1.0103  decode.d2.loss_dice: 0.7608  decode.d3.loss_cls: 0.2542  decode.d3.loss_mask: 0.9974  decode.d3.loss_dice: 0.7707  decode.d4.loss_cls: 0.2625  decode.d4.loss_mask: 0.9927  decode.d4.loss_dice: 0.7704  decode.d5.loss_cls: 0.2546  decode.d5.loss_mask: 1.0190  decode.d5.loss_dice: 0.7454  decode.d6.loss_cls: 0.2210  decode.d6.loss_mask: 0.9976  decode.d6.loss_dice: 0.8050  decode.d7.loss_cls: 0.2510  decode.d7.loss_mask: 1.0473  decode.d7.loss_dice: 0.7944  decode.d8.loss_cls: 0.2296  decode.d8.loss_mask: 0.9965  decode.d8.loss_dice: 0.7485
05/26 17:32:15 - mmengine - INFO - Iter(train) [ 56150/160000]  base_lr: 6.7774e-05 lr: 6.7774e-06  eta: 11:50:53  time: 0.4189  data_time: 0.0097  memory: 5965  grad_norm: 577.1714  loss: 21.4987  decode.loss_cls: 0.2248  decode.loss_mask: 1.0208  decode.loss_dice: 0.8182  decode.d0.loss_cls: 0.6819  decode.d0.loss_mask: 1.0153  decode.d0.loss_dice: 0.8203  decode.d1.loss_cls: 0.2806  decode.d1.loss_mask: 1.0180  decode.d1.loss_dice: 0.8263  decode.d2.loss_cls: 0.2900  decode.d2.loss_mask: 1.0266  decode.d2.loss_dice: 0.8259  decode.d3.loss_cls: 0.2625  decode.d3.loss_mask: 1.0121  decode.d3.loss_dice: 0.8495  decode.d4.loss_cls: 0.2592  decode.d4.loss_mask: 1.0347  decode.d4.loss_dice: 0.8153  decode.d5.loss_cls: 0.2626  decode.d5.loss_mask: 1.0165  decode.d5.loss_dice: 0.8142  decode.d6.loss_cls: 0.2587  decode.d6.loss_mask: 1.0060  decode.d6.loss_dice: 0.8514  decode.d7.loss_cls: 0.2768  decode.d7.loss_mask: 1.0299  decode.d7.loss_dice: 0.8176  decode.d8.loss_cls: 0.2445  decode.d8.loss_mask: 1.0096  decode.d8.loss_dice: 0.8290
05/26 17:32:36 - mmengine - INFO - Iter(train) [ 56200/160000]  base_lr: 6.7744e-05 lr: 6.7744e-06  eta: 11:50:33  time: 0.4180  data_time: 0.0097  memory: 5970  grad_norm: 449.5482  loss: 23.5473  decode.loss_cls: 0.2382  decode.loss_mask: 1.2455  decode.loss_dice: 0.7875  decode.d0.loss_cls: 0.7004  decode.d0.loss_mask: 1.2025  decode.d0.loss_dice: 0.8175  decode.d1.loss_cls: 0.2866  decode.d1.loss_mask: 1.2406  decode.d1.loss_dice: 0.7981  decode.d2.loss_cls: 0.2301  decode.d2.loss_mask: 1.2740  decode.d2.loss_dice: 0.8091  decode.d3.loss_cls: 0.2314  decode.d3.loss_mask: 1.2829  decode.d3.loss_dice: 0.8127  decode.d4.loss_cls: 0.3068  decode.d4.loss_mask: 1.2154  decode.d4.loss_dice: 0.7848  decode.d5.loss_cls: 0.2598  decode.d5.loss_mask: 1.2585  decode.d5.loss_dice: 0.8203  decode.d6.loss_cls: 0.2817  decode.d6.loss_mask: 1.2431  decode.d6.loss_dice: 0.8109  decode.d7.loss_cls: 0.2595  decode.d7.loss_mask: 1.2363  decode.d7.loss_dice: 0.7991  decode.d8.loss_cls: 0.2816  decode.d8.loss_mask: 1.2342  decode.d8.loss_dice: 0.7981
05/26 17:32:57 - mmengine - INFO - Iter(train) [ 56250/160000]  base_lr: 6.7715e-05 lr: 6.7715e-06  eta: 11:50:14  time: 0.4191  data_time: 0.0097  memory: 5965  grad_norm: 443.8012  loss: 21.2402  decode.loss_cls: 0.2758  decode.loss_mask: 1.0302  decode.loss_dice: 0.8259  decode.d0.loss_cls: 0.6461  decode.d0.loss_mask: 1.0080  decode.d0.loss_dice: 0.7978  decode.d1.loss_cls: 0.2850  decode.d1.loss_mask: 1.0010  decode.d1.loss_dice: 0.7992  decode.d2.loss_cls: 0.2501  decode.d2.loss_mask: 1.0183  decode.d2.loss_dice: 0.8115  decode.d3.loss_cls: 0.2872  decode.d3.loss_mask: 0.9821  decode.d3.loss_dice: 0.7876  decode.d4.loss_cls: 0.3014  decode.d4.loss_mask: 1.0122  decode.d4.loss_dice: 0.8012  decode.d5.loss_cls: 0.2639  decode.d5.loss_mask: 1.0347  decode.d5.loss_dice: 0.7890  decode.d6.loss_cls: 0.2841  decode.d6.loss_mask: 1.0142  decode.d6.loss_dice: 0.7999  decode.d7.loss_cls: 0.2506  decode.d7.loss_mask: 1.0265  decode.d7.loss_dice: 0.8061  decode.d8.loss_cls: 0.2594  decode.d8.loss_mask: 1.0015  decode.d8.loss_dice: 0.7897
05/26 17:33:18 - mmengine - INFO - Iter(train) [ 56300/160000]  base_lr: 6.7685e-05 lr: 6.7685e-06  eta: 11:49:54  time: 0.4203  data_time: 0.0098  memory: 5969  grad_norm: 626.2861  loss: 25.3382  decode.loss_cls: 0.3584  decode.loss_mask: 1.2710  decode.loss_dice: 0.8948  decode.d0.loss_cls: 0.7474  decode.d0.loss_mask: 1.2529  decode.d0.loss_dice: 0.8571  decode.d1.loss_cls: 0.3217  decode.d1.loss_mask: 1.2011  decode.d1.loss_dice: 0.8723  decode.d2.loss_cls: 0.3314  decode.d2.loss_mask: 1.2441  decode.d2.loss_dice: 0.8607  decode.d3.loss_cls: 0.3706  decode.d3.loss_mask: 1.2355  decode.d3.loss_dice: 0.8566  decode.d4.loss_cls: 0.3612  decode.d4.loss_mask: 1.2987  decode.d4.loss_dice: 0.8916  decode.d5.loss_cls: 0.3418  decode.d5.loss_mask: 1.2657  decode.d5.loss_dice: 0.8911  decode.d6.loss_cls: 0.4196  decode.d6.loss_mask: 1.2402  decode.d6.loss_dice: 0.8878  decode.d7.loss_cls: 0.3822  decode.d7.loss_mask: 1.2664  decode.d7.loss_dice: 0.9005  decode.d8.loss_cls: 0.3703  decode.d8.loss_mask: 1.2804  decode.d8.loss_dice: 0.8651
05/26 17:33:39 - mmengine - INFO - Iter(train) [ 56350/160000]  base_lr: 6.7656e-05 lr: 6.7656e-06  eta: 11:49:34  time: 0.4195  data_time: 0.0098  memory: 5981  grad_norm: 815.7110  loss: 24.7133  decode.loss_cls: 0.2928  decode.loss_mask: 1.1589  decode.loss_dice: 0.9516  decode.d0.loss_cls: 0.8654  decode.d0.loss_mask: 1.0227  decode.d0.loss_dice: 0.8334  decode.d1.loss_cls: 0.3752  decode.d1.loss_mask: 1.1862  decode.d1.loss_dice: 0.9255  decode.d2.loss_cls: 0.3723  decode.d2.loss_mask: 1.1312  decode.d2.loss_dice: 0.9226  decode.d3.loss_cls: 0.3673  decode.d3.loss_mask: 1.1488  decode.d3.loss_dice: 0.9072  decode.d4.loss_cls: 0.3622  decode.d4.loss_mask: 1.1953  decode.d4.loss_dice: 0.9383  decode.d5.loss_cls: 0.2962  decode.d5.loss_mask: 1.1877  decode.d5.loss_dice: 0.9288  decode.d6.loss_cls: 0.3082  decode.d6.loss_mask: 1.2052  decode.d6.loss_dice: 0.9172  decode.d7.loss_cls: 0.3153  decode.d7.loss_mask: 1.1691  decode.d7.loss_dice: 0.9482  decode.d8.loss_cls: 0.3166  decode.d8.loss_mask: 1.2313  decode.d8.loss_dice: 0.9328
05/26 17:34:00 - mmengine - INFO - Iter(train) [ 56400/160000]  base_lr: 6.7627e-05 lr: 6.7627e-06  eta: 11:49:15  time: 0.4188  data_time: 0.0098  memory: 5976  grad_norm: 626.7782  loss: 20.3032  decode.loss_cls: 0.1554  decode.loss_mask: 1.0325  decode.loss_dice: 0.7934  decode.d0.loss_cls: 0.6944  decode.d0.loss_mask: 0.9624  decode.d0.loss_dice: 0.7549  decode.d1.loss_cls: 0.1663  decode.d1.loss_mask: 0.9841  decode.d1.loss_dice: 0.7919  decode.d2.loss_cls: 0.1708  decode.d2.loss_mask: 1.0433  decode.d2.loss_dice: 0.8191  decode.d3.loss_cls: 0.1479  decode.d3.loss_mask: 1.0240  decode.d3.loss_dice: 0.8065  decode.d4.loss_cls: 0.1487  decode.d4.loss_mask: 1.0317  decode.d4.loss_dice: 0.8309  decode.d5.loss_cls: 0.1393  decode.d5.loss_mask: 1.0401  decode.d5.loss_dice: 0.8192  decode.d6.loss_cls: 0.1917  decode.d6.loss_mask: 1.0128  decode.d6.loss_dice: 0.7885  decode.d7.loss_cls: 0.1633  decode.d7.loss_mask: 1.0246  decode.d7.loss_dice: 0.8194  decode.d8.loss_cls: 0.1294  decode.d8.loss_mask: 1.0013  decode.d8.loss_dice: 0.8153
05/26 17:34:21 - mmengine - INFO - Iter(train) [ 56450/160000]  base_lr: 6.7597e-05 lr: 6.7597e-06  eta: 11:48:55  time: 0.4196  data_time: 0.0097  memory: 5994  grad_norm: 2081.0388  loss: 24.2145  decode.loss_cls: 0.3034  decode.loss_mask: 1.2925  decode.loss_dice: 0.8269  decode.d0.loss_cls: 0.8032  decode.d0.loss_mask: 1.0907  decode.d0.loss_dice: 0.7427  decode.d1.loss_cls: 0.3790  decode.d1.loss_mask: 1.1759  decode.d1.loss_dice: 0.8006  decode.d2.loss_cls: 0.3816  decode.d2.loss_mask: 1.1722  decode.d2.loss_dice: 0.7746  decode.d3.loss_cls: 0.3632  decode.d3.loss_mask: 1.1868  decode.d3.loss_dice: 0.7766  decode.d4.loss_cls: 0.3704  decode.d4.loss_mask: 1.2526  decode.d4.loss_dice: 0.8154  decode.d5.loss_cls: 0.2934  decode.d5.loss_mask: 1.3628  decode.d5.loss_dice: 0.7996  decode.d6.loss_cls: 0.3475  decode.d6.loss_mask: 1.2157  decode.d6.loss_dice: 0.8057  decode.d7.loss_cls: 0.4051  decode.d7.loss_mask: 1.2009  decode.d7.loss_dice: 0.8071  decode.d8.loss_cls: 0.3350  decode.d8.loss_mask: 1.2696  decode.d8.loss_dice: 0.8638
05/26 17:34:42 - mmengine - INFO - Iter(train) [ 56500/160000]  base_lr: 6.7568e-05 lr: 6.7568e-06  eta: 11:48:35  time: 0.4193  data_time: 0.0097  memory: 5966  grad_norm: 694.6056  loss: 26.1708  decode.loss_cls: 0.4782  decode.loss_mask: 1.1765  decode.loss_dice: 0.9270  decode.d0.loss_cls: 0.8688  decode.d0.loss_mask: 1.1559  decode.d0.loss_dice: 0.8772  decode.d1.loss_cls: 0.4085  decode.d1.loss_mask: 1.1998  decode.d1.loss_dice: 0.9103  decode.d2.loss_cls: 0.3595  decode.d2.loss_mask: 1.2171  decode.d2.loss_dice: 0.9679  decode.d3.loss_cls: 0.3805  decode.d3.loss_mask: 1.2426  decode.d3.loss_dice: 0.9472  decode.d4.loss_cls: 0.4383  decode.d4.loss_mask: 1.2135  decode.d4.loss_dice: 0.9187  decode.d5.loss_cls: 0.4017  decode.d5.loss_mask: 1.2558  decode.d5.loss_dice: 0.9752  decode.d6.loss_cls: 0.4537  decode.d6.loss_mask: 1.2715  decode.d6.loss_dice: 0.9446  decode.d7.loss_cls: 0.4289  decode.d7.loss_mask: 1.2206  decode.d7.loss_dice: 0.9477  decode.d8.loss_cls: 0.4238  decode.d8.loss_mask: 1.2251  decode.d8.loss_dice: 0.9345
05/26 17:35:03 - mmengine - INFO - Iter(train) [ 56550/160000]  base_lr: 6.7539e-05 lr: 6.7539e-06  eta: 11:48:15  time: 0.4190  data_time: 0.0097  memory: 5969  grad_norm: 567.0280  loss: 25.3873  decode.loss_cls: 0.2907  decode.loss_mask: 1.2553  decode.loss_dice: 0.9907  decode.d0.loss_cls: 0.7083  decode.d0.loss_mask: 1.1864  decode.d0.loss_dice: 0.9366  decode.d1.loss_cls: 0.3098  decode.d1.loss_mask: 1.2242  decode.d1.loss_dice: 0.9581  decode.d2.loss_cls: 0.3230  decode.d2.loss_mask: 1.2106  decode.d2.loss_dice: 0.9539  decode.d3.loss_cls: 0.3196  decode.d3.loss_mask: 1.2364  decode.d3.loss_dice: 0.9254  decode.d4.loss_cls: 0.3486  decode.d4.loss_mask: 1.2020  decode.d4.loss_dice: 0.9228  decode.d5.loss_cls: 0.3480  decode.d5.loss_mask: 1.2211  decode.d5.loss_dice: 0.9555  decode.d6.loss_cls: 0.3350  decode.d6.loss_mask: 1.2047  decode.d6.loss_dice: 0.9446  decode.d7.loss_cls: 0.3763  decode.d7.loss_mask: 1.1972  decode.d7.loss_dice: 0.9790  decode.d8.loss_cls: 0.3071  decode.d8.loss_mask: 1.2440  decode.d8.loss_dice: 0.9723
05/26 17:35:24 - mmengine - INFO - Iter(train) [ 56600/160000]  base_lr: 6.7509e-05 lr: 6.7509e-06  eta: 11:47:55  time: 0.4174  data_time: 0.0097  memory: 5976  grad_norm: 571.9171  loss: 26.3392  decode.loss_cls: 0.2685  decode.loss_mask: 1.2962  decode.loss_dice: 1.0162  decode.d0.loss_cls: 0.7534  decode.d0.loss_mask: 1.2199  decode.d0.loss_dice: 0.9550  decode.d1.loss_cls: 0.3123  decode.d1.loss_mask: 1.3078  decode.d1.loss_dice: 1.0105  decode.d2.loss_cls: 0.2867  decode.d2.loss_mask: 1.2922  decode.d2.loss_dice: 0.9987  decode.d3.loss_cls: 0.3142  decode.d3.loss_mask: 1.3033  decode.d3.loss_dice: 0.9872  decode.d4.loss_cls: 0.3270  decode.d4.loss_mask: 1.2576  decode.d4.loss_dice: 0.9915  decode.d5.loss_cls: 0.2941  decode.d5.loss_mask: 1.3028  decode.d5.loss_dice: 1.0102  decode.d6.loss_cls: 0.2835  decode.d6.loss_mask: 1.2562  decode.d6.loss_dice: 1.0255  decode.d7.loss_cls: 0.3445  decode.d7.loss_mask: 1.2680  decode.d7.loss_dice: 1.0361  decode.d8.loss_cls: 0.3659  decode.d8.loss_mask: 1.2546  decode.d8.loss_dice: 0.9994
05/26 17:35:45 - mmengine - INFO - Iter(train) [ 56650/160000]  base_lr: 6.7480e-05 lr: 6.7480e-06  eta: 11:47:36  time: 0.4181  data_time: 0.0097  memory: 5969  grad_norm: 632.2617  loss: 20.7062  decode.loss_cls: 0.2291  decode.loss_mask: 0.9910  decode.loss_dice: 0.7941  decode.d0.loss_cls: 0.7868  decode.d0.loss_mask: 0.9622  decode.d0.loss_dice: 0.7796  decode.d1.loss_cls: 0.2168  decode.d1.loss_mask: 0.9898  decode.d1.loss_dice: 0.8010  decode.d2.loss_cls: 0.2413  decode.d2.loss_mask: 0.9905  decode.d2.loss_dice: 0.7892  decode.d3.loss_cls: 0.2623  decode.d3.loss_mask: 0.9603  decode.d3.loss_dice: 0.7858  decode.d4.loss_cls: 0.2624  decode.d4.loss_mask: 0.9954  decode.d4.loss_dice: 0.8004  decode.d5.loss_cls: 0.2019  decode.d5.loss_mask: 0.9697  decode.d5.loss_dice: 0.8102  decode.d6.loss_cls: 0.2295  decode.d6.loss_mask: 1.0065  decode.d6.loss_dice: 0.8242  decode.d7.loss_cls: 0.2611  decode.d7.loss_mask: 1.0031  decode.d7.loss_dice: 0.8067  decode.d8.loss_cls: 0.2059  decode.d8.loss_mask: 0.9804  decode.d8.loss_dice: 0.7691
05/26 17:36:06 - mmengine - INFO - Iter(train) [ 56700/160000]  base_lr: 6.7450e-05 lr: 6.7450e-06  eta: 11:47:16  time: 0.4187  data_time: 0.0097  memory: 5976  grad_norm: 635.4125  loss: 25.5603  decode.loss_cls: 0.3638  decode.loss_mask: 1.1732  decode.loss_dice: 0.9214  decode.d0.loss_cls: 0.9588  decode.d0.loss_mask: 1.1489  decode.d0.loss_dice: 0.9169  decode.d1.loss_cls: 0.4435  decode.d1.loss_mask: 1.1642  decode.d1.loss_dice: 0.9087  decode.d2.loss_cls: 0.3548  decode.d2.loss_mask: 1.2148  decode.d2.loss_dice: 0.9019  decode.d3.loss_cls: 0.3980  decode.d3.loss_mask: 1.1449  decode.d3.loss_dice: 0.9057  decode.d4.loss_cls: 0.3793  decode.d4.loss_mask: 1.2185  decode.d4.loss_dice: 0.9532  decode.d5.loss_cls: 0.3821  decode.d5.loss_mask: 1.2407  decode.d5.loss_dice: 0.9274  decode.d6.loss_cls: 0.3961  decode.d6.loss_mask: 1.2030  decode.d6.loss_dice: 0.9458  decode.d7.loss_cls: 0.4182  decode.d7.loss_mask: 1.1512  decode.d7.loss_dice: 0.9078  decode.d8.loss_cls: 0.4038  decode.d8.loss_mask: 1.2072  decode.d8.loss_dice: 0.9064
05/26 17:36:26 - mmengine - INFO - Iter(train) [ 56750/160000]  base_lr: 6.7421e-05 lr: 6.7421e-06  eta: 11:46:56  time: 0.4176  data_time: 0.0097  memory: 5966  grad_norm: 817.1786  loss: 24.3051  decode.loss_cls: 0.2825  decode.loss_mask: 1.2382  decode.loss_dice: 0.8511  decode.d0.loss_cls: 0.7723  decode.d0.loss_mask: 1.2773  decode.d0.loss_dice: 0.8586  decode.d1.loss_cls: 0.2740  decode.d1.loss_mask: 1.2789  decode.d1.loss_dice: 0.8367  decode.d2.loss_cls: 0.2303  decode.d2.loss_mask: 1.2282  decode.d2.loss_dice: 0.8668  decode.d3.loss_cls: 0.2317  decode.d3.loss_mask: 1.2655  decode.d3.loss_dice: 0.8709  decode.d4.loss_cls: 0.2385  decode.d4.loss_mask: 1.2644  decode.d4.loss_dice: 0.8371  decode.d5.loss_cls: 0.2415  decode.d5.loss_mask: 1.2538  decode.d5.loss_dice: 0.8741  decode.d6.loss_cls: 0.2449  decode.d6.loss_mask: 1.2808  decode.d6.loss_dice: 0.8952  decode.d7.loss_cls: 0.2625  decode.d7.loss_mask: 1.2701  decode.d7.loss_dice: 0.8551  decode.d8.loss_cls: 0.2543  decode.d8.loss_mask: 1.2468  decode.d8.loss_dice: 0.9230
05/26 17:36:47 - mmengine - INFO - Iter(train) [ 56800/160000]  base_lr: 6.7392e-05 lr: 6.7392e-06  eta: 11:46:36  time: 0.4173  data_time: 0.0097  memory: 5976  grad_norm: 637.0978  loss: 22.5584  decode.loss_cls: 0.3760  decode.loss_mask: 1.0987  decode.loss_dice: 0.7137  decode.d0.loss_cls: 0.8308  decode.d0.loss_mask: 1.0977  decode.d0.loss_dice: 0.7903  decode.d1.loss_cls: 0.4186  decode.d1.loss_mask: 1.0887  decode.d1.loss_dice: 0.7133  decode.d2.loss_cls: 0.4151  decode.d2.loss_mask: 1.0800  decode.d2.loss_dice: 0.7231  decode.d3.loss_cls: 0.4189  decode.d3.loss_mask: 1.1089  decode.d3.loss_dice: 0.7129  decode.d4.loss_cls: 0.4340  decode.d4.loss_mask: 1.0573  decode.d4.loss_dice: 0.6713  decode.d5.loss_cls: 0.3991  decode.d5.loss_mask: 1.0679  decode.d5.loss_dice: 0.7041  decode.d6.loss_cls: 0.4002  decode.d6.loss_mask: 1.1644  decode.d6.loss_dice: 0.7231  decode.d7.loss_cls: 0.3647  decode.d7.loss_mask: 1.0896  decode.d7.loss_dice: 0.7220  decode.d8.loss_cls: 0.3720  decode.d8.loss_mask: 1.1092  decode.d8.loss_dice: 0.6931
05/26 17:37:08 - mmengine - INFO - Iter(train) [ 56850/160000]  base_lr: 6.7362e-05 lr: 6.7362e-06  eta: 11:46:16  time: 0.4167  data_time: 0.0097  memory: 5966  grad_norm: 612.7206  loss: 19.4192  decode.loss_cls: 0.1727  decode.loss_mask: 0.9255  decode.loss_dice: 0.7064  decode.d0.loss_cls: 0.5949  decode.d0.loss_mask: 0.9666  decode.d0.loss_dice: 0.7411  decode.d1.loss_cls: 0.1838  decode.d1.loss_mask: 1.0347  decode.d1.loss_dice: 0.7614  decode.d2.loss_cls: 0.1821  decode.d2.loss_mask: 1.0132  decode.d2.loss_dice: 0.7357  decode.d3.loss_cls: 0.1595  decode.d3.loss_mask: 0.9778  decode.d3.loss_dice: 0.7217  decode.d4.loss_cls: 0.1804  decode.d4.loss_mask: 0.9954  decode.d4.loss_dice: 0.7242  decode.d5.loss_cls: 0.1833  decode.d5.loss_mask: 1.0447  decode.d5.loss_dice: 0.7485  decode.d6.loss_cls: 0.1955  decode.d6.loss_mask: 0.9888  decode.d6.loss_dice: 0.7383  decode.d7.loss_cls: 0.1893  decode.d7.loss_mask: 0.9791  decode.d7.loss_dice: 0.7201  decode.d8.loss_cls: 0.2090  decode.d8.loss_mask: 0.9357  decode.d8.loss_dice: 0.7100
05/26 17:37:29 - mmengine - INFO - Iter(train) [ 56900/160000]  base_lr: 6.7333e-05 lr: 6.7333e-06  eta: 11:45:56  time: 0.4172  data_time: 0.0097  memory: 5976  grad_norm: 650.6546  loss: 24.4155  decode.loss_cls: 0.2883  decode.loss_mask: 1.2126  decode.loss_dice: 0.8691  decode.d0.loss_cls: 0.7838  decode.d0.loss_mask: 1.1179  decode.d0.loss_dice: 0.8626  decode.d1.loss_cls: 0.3080  decode.d1.loss_mask: 1.2068  decode.d1.loss_dice: 0.8533  decode.d2.loss_cls: 0.3493  decode.d2.loss_mask: 1.2278  decode.d2.loss_dice: 0.8605  decode.d3.loss_cls: 0.3380  decode.d3.loss_mask: 1.2032  decode.d3.loss_dice: 0.8540  decode.d4.loss_cls: 0.3645  decode.d4.loss_mask: 1.2267  decode.d4.loss_dice: 0.8763  decode.d5.loss_cls: 0.3104  decode.d5.loss_mask: 1.2337  decode.d5.loss_dice: 0.8697  decode.d6.loss_cls: 0.2738  decode.d6.loss_mask: 1.2310  decode.d6.loss_dice: 0.9080  decode.d7.loss_cls: 0.3544  decode.d7.loss_mask: 1.1980  decode.d7.loss_dice: 0.8812  decode.d8.loss_cls: 0.3080  decode.d8.loss_mask: 1.2034  decode.d8.loss_dice: 0.8415
05/26 17:37:50 - mmengine - INFO - Iter(train) [ 56950/160000]  base_lr: 6.7304e-05 lr: 6.7304e-06  eta: 11:45:36  time: 0.4182  data_time: 0.0098  memory: 5967  grad_norm: 702.0520  loss: 21.8102  decode.loss_cls: 0.2188  decode.loss_mask: 1.1086  decode.loss_dice: 0.8026  decode.d0.loss_cls: 0.6663  decode.d0.loss_mask: 1.0886  decode.d0.loss_dice: 0.7640  decode.d1.loss_cls: 0.1957  decode.d1.loss_mask: 1.1449  decode.d1.loss_dice: 0.7929  decode.d2.loss_cls: 0.2151  decode.d2.loss_mask: 1.1572  decode.d2.loss_dice: 0.7925  decode.d3.loss_cls: 0.2048  decode.d3.loss_mask: 1.0944  decode.d3.loss_dice: 0.7712  decode.d4.loss_cls: 0.2171  decode.d4.loss_mask: 1.1542  decode.d4.loss_dice: 0.7975  decode.d5.loss_cls: 0.2184  decode.d5.loss_mask: 1.1337  decode.d5.loss_dice: 0.7794  decode.d6.loss_cls: 0.1965  decode.d6.loss_mask: 1.1641  decode.d6.loss_dice: 0.8042  decode.d7.loss_cls: 0.2233  decode.d7.loss_mask: 1.1792  decode.d7.loss_dice: 0.7936  decode.d8.loss_cls: 0.2444  decode.d8.loss_mask: 1.1108  decode.d8.loss_dice: 0.7763
05/26 17:38:11 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 17:38:11 - mmengine - INFO - Iter(train) [ 57000/160000]  base_lr: 6.7274e-05 lr: 6.7274e-06  eta: 11:45:17  time: 0.4175  data_time: 0.0097  memory: 5978  grad_norm: 744.5033  loss: 26.4789  decode.loss_cls: 0.3326  decode.loss_mask: 1.3687  decode.loss_dice: 0.9004  decode.d0.loss_cls: 0.8315  decode.d0.loss_mask: 1.2550  decode.d0.loss_dice: 0.8504  decode.d1.loss_cls: 0.3073  decode.d1.loss_mask: 1.3939  decode.d1.loss_dice: 0.8631  decode.d2.loss_cls: 0.3884  decode.d2.loss_mask: 1.3793  decode.d2.loss_dice: 0.8710  decode.d3.loss_cls: 0.3444  decode.d3.loss_mask: 1.3499  decode.d3.loss_dice: 0.8876  decode.d4.loss_cls: 0.3445  decode.d4.loss_mask: 1.3662  decode.d4.loss_dice: 0.9059  decode.d5.loss_cls: 0.3145  decode.d5.loss_mask: 1.4123  decode.d5.loss_dice: 0.9014  decode.d6.loss_cls: 0.3440  decode.d6.loss_mask: 1.3867  decode.d6.loss_dice: 0.8780  decode.d7.loss_cls: 0.3933  decode.d7.loss_mask: 1.3918  decode.d7.loss_dice: 0.9019  decode.d8.loss_cls: 0.3525  decode.d8.loss_mask: 1.3699  decode.d8.loss_dice: 0.8924
05/26 17:38:32 - mmengine - INFO - Iter(train) [ 57050/160000]  base_lr: 6.7245e-05 lr: 6.7245e-06  eta: 11:44:57  time: 0.4173  data_time: 0.0098  memory: 5971  grad_norm: 842.9257  loss: 17.5516  decode.loss_cls: 0.1899  decode.loss_mask: 0.9246  decode.loss_dice: 0.6019  decode.d0.loss_cls: 0.5917  decode.d0.loss_mask: 0.9263  decode.d0.loss_dice: 0.5923  decode.d1.loss_cls: 0.2148  decode.d1.loss_mask: 0.9641  decode.d1.loss_dice: 0.5827  decode.d2.loss_cls: 0.1570  decode.d2.loss_mask: 0.9853  decode.d2.loss_dice: 0.5887  decode.d3.loss_cls: 0.1905  decode.d3.loss_mask: 0.9253  decode.d3.loss_dice: 0.5831  decode.d4.loss_cls: 0.2152  decode.d4.loss_mask: 0.9636  decode.d4.loss_dice: 0.5955  decode.d5.loss_cls: 0.1750  decode.d5.loss_mask: 0.9076  decode.d5.loss_dice: 0.5877  decode.d6.loss_cls: 0.2075  decode.d6.loss_mask: 0.8914  decode.d6.loss_dice: 0.5902  decode.d7.loss_cls: 0.1919  decode.d7.loss_mask: 0.9036  decode.d7.loss_dice: 0.5789  decode.d8.loss_cls: 0.2106  decode.d8.loss_mask: 0.9480  decode.d8.loss_dice: 0.5668
05/26 17:38:53 - mmengine - INFO - Iter(train) [ 57100/160000]  base_lr: 6.7215e-05 lr: 6.7215e-06  eta: 11:44:37  time: 0.4181  data_time: 0.0097  memory: 5974  grad_norm: 1062.0678  loss: 24.6188  decode.loss_cls: 0.3879  decode.loss_mask: 1.1236  decode.loss_dice: 0.9091  decode.d0.loss_cls: 0.8990  decode.d0.loss_mask: 1.1071  decode.d0.loss_dice: 0.8712  decode.d1.loss_cls: 0.3929  decode.d1.loss_mask: 1.1013  decode.d1.loss_dice: 0.8925  decode.d2.loss_cls: 0.3533  decode.d2.loss_mask: 1.1424  decode.d2.loss_dice: 0.9335  decode.d3.loss_cls: 0.3922  decode.d3.loss_mask: 1.0932  decode.d3.loss_dice: 0.8594  decode.d4.loss_cls: 0.3777  decode.d4.loss_mask: 1.1184  decode.d4.loss_dice: 0.8807  decode.d5.loss_cls: 0.3731  decode.d5.loss_mask: 1.1367  decode.d5.loss_dice: 0.8950  decode.d6.loss_cls: 0.4040  decode.d6.loss_mask: 1.1297  decode.d6.loss_dice: 0.9124  decode.d7.loss_cls: 0.4141  decode.d7.loss_mask: 1.1302  decode.d7.loss_dice: 0.9061  decode.d8.loss_cls: 0.4198  decode.d8.loss_mask: 1.1600  decode.d8.loss_dice: 0.9022
05/26 17:39:14 - mmengine - INFO - Iter(train) [ 57150/160000]  base_lr: 6.7186e-05 lr: 6.7186e-06  eta: 11:44:17  time: 0.4405  data_time: 0.0097  memory: 5966  grad_norm: 719.7185  loss: 24.5735  decode.loss_cls: 0.2562  decode.loss_mask: 1.1858  decode.loss_dice: 0.8676  decode.d0.loss_cls: 0.8001  decode.d0.loss_mask: 1.1343  decode.d0.loss_dice: 0.8717  decode.d1.loss_cls: 0.3601  decode.d1.loss_mask: 1.1778  decode.d1.loss_dice: 0.8946  decode.d2.loss_cls: 0.3229  decode.d2.loss_mask: 1.1704  decode.d2.loss_dice: 0.9144  decode.d3.loss_cls: 0.3392  decode.d3.loss_mask: 1.2198  decode.d3.loss_dice: 0.9082  decode.d4.loss_cls: 0.3529  decode.d4.loss_mask: 1.2374  decode.d4.loss_dice: 0.9574  decode.d5.loss_cls: 0.3186  decode.d5.loss_mask: 1.1866  decode.d5.loss_dice: 0.9083  decode.d6.loss_cls: 0.3394  decode.d6.loss_mask: 1.2298  decode.d6.loss_dice: 0.9588  decode.d7.loss_cls: 0.3114  decode.d7.loss_mask: 1.1250  decode.d7.loss_dice: 0.8477  decode.d8.loss_cls: 0.3045  decode.d8.loss_mask: 1.1591  decode.d8.loss_dice: 0.9134
05/26 17:39:35 - mmengine - INFO - Iter(train) [ 57200/160000]  base_lr: 6.7157e-05 lr: 6.7157e-06  eta: 11:43:57  time: 0.4175  data_time: 0.0097  memory: 5966  grad_norm: 403.1538  loss: 18.6686  decode.loss_cls: 0.3232  decode.loss_mask: 0.8038  decode.loss_dice: 0.6959  decode.d0.loss_cls: 0.6908  decode.d0.loss_mask: 0.7824  decode.d0.loss_dice: 0.6994  decode.d1.loss_cls: 0.3231  decode.d1.loss_mask: 0.8015  decode.d1.loss_dice: 0.6894  decode.d2.loss_cls: 0.2946  decode.d2.loss_mask: 0.8348  decode.d2.loss_dice: 0.7246  decode.d3.loss_cls: 0.2563  decode.d3.loss_mask: 0.8423  decode.d3.loss_dice: 0.7146  decode.d4.loss_cls: 0.3018  decode.d4.loss_mask: 0.8232  decode.d4.loss_dice: 0.7089  decode.d5.loss_cls: 0.3145  decode.d5.loss_mask: 0.8385  decode.d5.loss_dice: 0.7126  decode.d6.loss_cls: 0.2878  decode.d6.loss_mask: 0.8202  decode.d6.loss_dice: 0.7329  decode.d7.loss_cls: 0.3005  decode.d7.loss_mask: 0.8450  decode.d7.loss_dice: 0.6918  decode.d8.loss_cls: 0.2623  decode.d8.loss_mask: 0.8279  decode.d8.loss_dice: 0.7241
05/26 17:39:56 - mmengine - INFO - Iter(train) [ 57250/160000]  base_lr: 6.7127e-05 lr: 6.7127e-06  eta: 11:43:37  time: 0.4181  data_time: 0.0097  memory: 5975  grad_norm: 577.9080  loss: 24.8876  decode.loss_cls: 0.3297  decode.loss_mask: 1.1374  decode.loss_dice: 0.9838  decode.d0.loss_cls: 0.8802  decode.d0.loss_mask: 1.1416  decode.d0.loss_dice: 0.9310  decode.d1.loss_cls: 0.3112  decode.d1.loss_mask: 1.1559  decode.d1.loss_dice: 0.9614  decode.d2.loss_cls: 0.2826  decode.d2.loss_mask: 1.1604  decode.d2.loss_dice: 0.9904  decode.d3.loss_cls: 0.3096  decode.d3.loss_mask: 1.1904  decode.d3.loss_dice: 0.9834  decode.d4.loss_cls: 0.3267  decode.d4.loss_mask: 1.1327  decode.d4.loss_dice: 0.9299  decode.d5.loss_cls: 0.3443  decode.d5.loss_mask: 1.1840  decode.d5.loss_dice: 0.9787  decode.d6.loss_cls: 0.3422  decode.d6.loss_mask: 1.1492  decode.d6.loss_dice: 0.9604  decode.d7.loss_cls: 0.2932  decode.d7.loss_mask: 1.1418  decode.d7.loss_dice: 0.9678  decode.d8.loss_cls: 0.2966  decode.d8.loss_mask: 1.1481  decode.d8.loss_dice: 0.9429
05/26 17:40:17 - mmengine - INFO - Iter(train) [ 57300/160000]  base_lr: 6.7098e-05 lr: 6.7098e-06  eta: 11:43:17  time: 0.4178  data_time: 0.0097  memory: 5966  grad_norm: 501.0028  loss: 23.8097  decode.loss_cls: 0.2809  decode.loss_mask: 1.1851  decode.loss_dice: 0.8578  decode.d0.loss_cls: 0.7633  decode.d0.loss_mask: 1.0916  decode.d0.loss_dice: 0.8641  decode.d1.loss_cls: 0.3153  decode.d1.loss_mask: 1.1551  decode.d1.loss_dice: 0.8971  decode.d2.loss_cls: 0.2935  decode.d2.loss_mask: 1.1694  decode.d2.loss_dice: 0.9028  decode.d3.loss_cls: 0.3261  decode.d3.loss_mask: 1.1718  decode.d3.loss_dice: 0.8694  decode.d4.loss_cls: 0.3222  decode.d4.loss_mask: 1.1455  decode.d4.loss_dice: 0.8699  decode.d5.loss_cls: 0.2977  decode.d5.loss_mask: 1.1466  decode.d5.loss_dice: 0.8632  decode.d6.loss_cls: 0.3260  decode.d6.loss_mask: 1.1405  decode.d6.loss_dice: 0.8794  decode.d7.loss_cls: 0.3342  decode.d7.loss_mask: 1.1536  decode.d7.loss_dice: 0.8866  decode.d8.loss_cls: 0.3076  decode.d8.loss_mask: 1.1342  decode.d8.loss_dice: 0.8595
05/26 17:40:38 - mmengine - INFO - Iter(train) [ 57350/160000]  base_lr: 6.7068e-05 lr: 6.7068e-06  eta: 11:42:58  time: 0.4208  data_time: 0.0098  memory: 5987  grad_norm: 777.7832  loss: 26.4779  decode.loss_cls: 0.3632  decode.loss_mask: 1.2997  decode.loss_dice: 0.9653  decode.d0.loss_cls: 0.8427  decode.d0.loss_mask: 1.2080  decode.d0.loss_dice: 0.9298  decode.d1.loss_cls: 0.3364  decode.d1.loss_mask: 1.2806  decode.d1.loss_dice: 0.9711  decode.d2.loss_cls: 0.3586  decode.d2.loss_mask: 1.2855  decode.d2.loss_dice: 0.9518  decode.d3.loss_cls: 0.3481  decode.d3.loss_mask: 1.2725  decode.d3.loss_dice: 0.9428  decode.d4.loss_cls: 0.3860  decode.d4.loss_mask: 1.2911  decode.d4.loss_dice: 0.9561  decode.d5.loss_cls: 0.3664  decode.d5.loss_mask: 1.2732  decode.d5.loss_dice: 0.9807  decode.d6.loss_cls: 0.3943  decode.d6.loss_mask: 1.2950  decode.d6.loss_dice: 1.0158  decode.d7.loss_cls: 0.3392  decode.d7.loss_mask: 1.2521  decode.d7.loss_dice: 0.9434  decode.d8.loss_cls: 0.3478  decode.d8.loss_mask: 1.2946  decode.d8.loss_dice: 0.9863
05/26 17:40:59 - mmengine - INFO - Iter(train) [ 57400/160000]  base_lr: 6.7039e-05 lr: 6.7039e-06  eta: 11:42:38  time: 0.4196  data_time: 0.0099  memory: 5976  grad_norm: 438.5173  loss: 19.9979  decode.loss_cls: 0.1970  decode.loss_mask: 1.0043  decode.loss_dice: 0.7253  decode.d0.loss_cls: 0.6382  decode.d0.loss_mask: 1.0128  decode.d0.loss_dice: 0.6862  decode.d1.loss_cls: 0.2551  decode.d1.loss_mask: 1.0183  decode.d1.loss_dice: 0.7142  decode.d2.loss_cls: 0.2282  decode.d2.loss_mask: 1.0261  decode.d2.loss_dice: 0.7212  decode.d3.loss_cls: 0.2401  decode.d3.loss_mask: 1.0099  decode.d3.loss_dice: 0.7092  decode.d4.loss_cls: 0.2459  decode.d4.loss_mask: 1.0150  decode.d4.loss_dice: 0.6889  decode.d5.loss_cls: 0.2350  decode.d5.loss_mask: 1.0076  decode.d5.loss_dice: 0.7352  decode.d6.loss_cls: 0.2252  decode.d6.loss_mask: 1.0127  decode.d6.loss_dice: 0.7286  decode.d7.loss_cls: 0.2321  decode.d7.loss_mask: 1.0053  decode.d7.loss_dice: 0.7124  decode.d8.loss_cls: 0.2399  decode.d8.loss_mask: 1.0116  decode.d8.loss_dice: 0.7162
05/26 17:41:20 - mmengine - INFO - Iter(train) [ 57450/160000]  base_lr: 6.7010e-05 lr: 6.7010e-06  eta: 11:42:18  time: 0.4194  data_time: 0.0098  memory: 5969  grad_norm: 374.6350  loss: 21.2232  decode.loss_cls: 0.1623  decode.loss_mask: 1.1670  decode.loss_dice: 0.7309  decode.d0.loss_cls: 0.6808  decode.d0.loss_mask: 1.0274  decode.d0.loss_dice: 0.6883  decode.d1.loss_cls: 0.1729  decode.d1.loss_mask: 1.2161  decode.d1.loss_dice: 0.7398  decode.d2.loss_cls: 0.2232  decode.d2.loss_mask: 1.1320  decode.d2.loss_dice: 0.7387  decode.d3.loss_cls: 0.2017  decode.d3.loss_mask: 1.1936  decode.d3.loss_dice: 0.7137  decode.d4.loss_cls: 0.2108  decode.d4.loss_mask: 1.1783  decode.d4.loss_dice: 0.7035  decode.d5.loss_cls: 0.2341  decode.d5.loss_mask: 1.1175  decode.d5.loss_dice: 0.7184  decode.d6.loss_cls: 0.2475  decode.d6.loss_mask: 1.0476  decode.d6.loss_dice: 0.7220  decode.d7.loss_cls: 0.2072  decode.d7.loss_mask: 1.2077  decode.d7.loss_dice: 0.7302  decode.d8.loss_cls: 0.1819  decode.d8.loss_mask: 1.1851  decode.d8.loss_dice: 0.7431
05/26 17:41:41 - mmengine - INFO - Iter(train) [ 57500/160000]  base_lr: 6.6980e-05 lr: 6.6980e-06  eta: 11:41:58  time: 0.4202  data_time: 0.0097  memory: 5967  grad_norm: 465.4661  loss: 19.6631  decode.loss_cls: 0.1259  decode.loss_mask: 1.0330  decode.loss_dice: 0.7469  decode.d0.loss_cls: 0.6779  decode.d0.loss_mask: 0.9551  decode.d0.loss_dice: 0.7089  decode.d1.loss_cls: 0.1454  decode.d1.loss_mask: 1.0093  decode.d1.loss_dice: 0.7580  decode.d2.loss_cls: 0.1618  decode.d2.loss_mask: 1.0070  decode.d2.loss_dice: 0.7557  decode.d3.loss_cls: 0.1893  decode.d3.loss_mask: 0.9932  decode.d3.loss_dice: 0.7622  decode.d4.loss_cls: 0.1439  decode.d4.loss_mask: 1.0111  decode.d4.loss_dice: 0.7924  decode.d5.loss_cls: 0.1585  decode.d5.loss_mask: 0.9902  decode.d5.loss_dice: 0.7743  decode.d6.loss_cls: 0.1607  decode.d6.loss_mask: 1.0113  decode.d6.loss_dice: 0.7560  decode.d7.loss_cls: 0.1897  decode.d7.loss_mask: 1.0042  decode.d7.loss_dice: 0.7344  decode.d8.loss_cls: 0.1243  decode.d8.loss_mask: 1.0226  decode.d8.loss_dice: 0.7601
05/26 17:42:02 - mmengine - INFO - Iter(train) [ 57550/160000]  base_lr: 6.6951e-05 lr: 6.6951e-06  eta: 11:41:39  time: 0.4223  data_time: 0.0098  memory: 5971  grad_norm: 573.4962  loss: 23.1387  decode.loss_cls: 0.2451  decode.loss_mask: 1.1728  decode.loss_dice: 0.8165  decode.d0.loss_cls: 0.7329  decode.d0.loss_mask: 1.1183  decode.d0.loss_dice: 0.7882  decode.d1.loss_cls: 0.2204  decode.d1.loss_mask: 1.1961  decode.d1.loss_dice: 0.8387  decode.d2.loss_cls: 0.2726  decode.d2.loss_mask: 1.1903  decode.d2.loss_dice: 0.8336  decode.d3.loss_cls: 0.2641  decode.d3.loss_mask: 1.1668  decode.d3.loss_dice: 0.8091  decode.d4.loss_cls: 0.2669  decode.d4.loss_mask: 1.2054  decode.d4.loss_dice: 0.8313  decode.d5.loss_cls: 0.2806  decode.d5.loss_mask: 1.1893  decode.d5.loss_dice: 0.8221  decode.d6.loss_cls: 0.2861  decode.d6.loss_mask: 1.1763  decode.d6.loss_dice: 0.8015  decode.d7.loss_cls: 0.2836  decode.d7.loss_mask: 1.1727  decode.d7.loss_dice: 0.8404  decode.d8.loss_cls: 0.3010  decode.d8.loss_mask: 1.2017  decode.d8.loss_dice: 0.8144
05/26 17:42:23 - mmengine - INFO - Iter(train) [ 57600/160000]  base_lr: 6.6921e-05 lr: 6.6921e-06  eta: 11:41:19  time: 0.4186  data_time: 0.0097  memory: 5976  grad_norm: 672.3173  loss: 21.1711  decode.loss_cls: 0.2067  decode.loss_mask: 1.0449  decode.loss_dice: 0.7859  decode.d0.loss_cls: 0.7075  decode.d0.loss_mask: 0.9997  decode.d0.loss_dice: 0.7362  decode.d1.loss_cls: 0.2906  decode.d1.loss_mask: 0.9971  decode.d1.loss_dice: 0.8112  decode.d2.loss_cls: 0.3307  decode.d2.loss_mask: 1.0393  decode.d2.loss_dice: 0.7921  decode.d3.loss_cls: 0.2636  decode.d3.loss_mask: 1.0246  decode.d3.loss_dice: 0.7896  decode.d4.loss_cls: 0.2730  decode.d4.loss_mask: 1.0173  decode.d4.loss_dice: 0.7760  decode.d5.loss_cls: 0.2111  decode.d5.loss_mask: 1.0292  decode.d5.loss_dice: 0.7973  decode.d6.loss_cls: 0.2402  decode.d6.loss_mask: 1.0649  decode.d6.loss_dice: 0.8064  decode.d7.loss_cls: 0.2781  decode.d7.loss_mask: 1.0411  decode.d7.loss_dice: 0.7958  decode.d8.loss_cls: 0.2211  decode.d8.loss_mask: 1.0212  decode.d8.loss_dice: 0.7783
05/26 17:42:44 - mmengine - INFO - Iter(train) [ 57650/160000]  base_lr: 6.6892e-05 lr: 6.6892e-06  eta: 11:40:59  time: 0.4182  data_time: 0.0097  memory: 5966  grad_norm: 528.2759  loss: 22.2223  decode.loss_cls: 0.2187  decode.loss_mask: 1.1726  decode.loss_dice: 0.7641  decode.d0.loss_cls: 0.7991  decode.d0.loss_mask: 1.1461  decode.d0.loss_dice: 0.7586  decode.d1.loss_cls: 0.2664  decode.d1.loss_mask: 1.1932  decode.d1.loss_dice: 0.7862  decode.d2.loss_cls: 0.2449  decode.d2.loss_mask: 1.1719  decode.d2.loss_dice: 0.7570  decode.d3.loss_cls: 0.2553  decode.d3.loss_mask: 1.1695  decode.d3.loss_dice: 0.7696  decode.d4.loss_cls: 0.2601  decode.d4.loss_mask: 1.1595  decode.d4.loss_dice: 0.7844  decode.d5.loss_cls: 0.2712  decode.d5.loss_mask: 1.1226  decode.d5.loss_dice: 0.7268  decode.d6.loss_cls: 0.2417  decode.d6.loss_mask: 1.1342  decode.d6.loss_dice: 0.7401  decode.d7.loss_cls: 0.2577  decode.d7.loss_mask: 1.1393  decode.d7.loss_dice: 0.7543  decode.d8.loss_cls: 0.2374  decode.d8.loss_mask: 1.1709  decode.d8.loss_dice: 0.7490
05/26 17:43:04 - mmengine - INFO - Iter(train) [ 57700/160000]  base_lr: 6.6862e-05 lr: 6.6862e-06  eta: 11:40:39  time: 0.4178  data_time: 0.0097  memory: 5980  grad_norm: 518.8841  loss: 20.0696  decode.loss_cls: 0.1535  decode.loss_mask: 1.0963  decode.loss_dice: 0.7355  decode.d0.loss_cls: 0.6170  decode.d0.loss_mask: 1.0460  decode.d0.loss_dice: 0.6815  decode.d1.loss_cls: 0.1567  decode.d1.loss_mask: 1.0890  decode.d1.loss_dice: 0.7169  decode.d2.loss_cls: 0.1469  decode.d2.loss_mask: 1.0874  decode.d2.loss_dice: 0.7317  decode.d3.loss_cls: 0.1343  decode.d3.loss_mask: 1.0809  decode.d3.loss_dice: 0.7131  decode.d4.loss_cls: 0.1459  decode.d4.loss_mask: 1.0846  decode.d4.loss_dice: 0.7313  decode.d5.loss_cls: 0.1241  decode.d5.loss_mask: 1.1324  decode.d5.loss_dice: 0.7379  decode.d6.loss_cls: 0.1721  decode.d6.loss_mask: 1.0783  decode.d6.loss_dice: 0.7237  decode.d7.loss_cls: 0.1544  decode.d7.loss_mask: 1.1154  decode.d7.loss_dice: 0.7231  decode.d8.loss_cls: 0.1653  decode.d8.loss_mask: 1.0682  decode.d8.loss_dice: 0.7261
05/26 17:43:25 - mmengine - INFO - Iter(train) [ 57750/160000]  base_lr: 6.6833e-05 lr: 6.6833e-06  eta: 11:40:19  time: 0.4171  data_time: 0.0097  memory: 5979  grad_norm: 775.0667  loss: 19.4111  decode.loss_cls: 0.1389  decode.loss_mask: 1.0865  decode.loss_dice: 0.6992  decode.d0.loss_cls: 0.6275  decode.d0.loss_mask: 0.9925  decode.d0.loss_dice: 0.6150  decode.d1.loss_cls: 0.1366  decode.d1.loss_mask: 1.0326  decode.d1.loss_dice: 0.6839  decode.d2.loss_cls: 0.1600  decode.d2.loss_mask: 1.0251  decode.d2.loss_dice: 0.6711  decode.d3.loss_cls: 0.1284  decode.d3.loss_mask: 1.0395  decode.d3.loss_dice: 0.6845  decode.d4.loss_cls: 0.1438  decode.d4.loss_mask: 1.0381  decode.d4.loss_dice: 0.6983  decode.d5.loss_cls: 0.1770  decode.d5.loss_mask: 1.0692  decode.d5.loss_dice: 0.7097  decode.d6.loss_cls: 0.1537  decode.d6.loss_mask: 1.0974  decode.d6.loss_dice: 0.6857  decode.d7.loss_cls: 0.1612  decode.d7.loss_mask: 1.0832  decode.d7.loss_dice: 0.6783  decode.d8.loss_cls: 0.1430  decode.d8.loss_mask: 1.1405  decode.d8.loss_dice: 0.7109
05/26 17:43:46 - mmengine - INFO - Iter(train) [ 57800/160000]  base_lr: 6.6804e-05 lr: 6.6804e-06  eta: 11:39:59  time: 0.4177  data_time: 0.0097  memory: 5971  grad_norm: 744.5293  loss: 22.1618  decode.loss_cls: 0.2682  decode.loss_mask: 1.0779  decode.loss_dice: 0.7816  decode.d0.loss_cls: 0.7425  decode.d0.loss_mask: 1.0318  decode.d0.loss_dice: 0.7613  decode.d1.loss_cls: 0.2842  decode.d1.loss_mask: 1.1655  decode.d1.loss_dice: 0.7616  decode.d2.loss_cls: 0.2725  decode.d2.loss_mask: 1.1525  decode.d2.loss_dice: 0.7522  decode.d3.loss_cls: 0.2452  decode.d3.loss_mask: 1.1618  decode.d3.loss_dice: 0.7669  decode.d4.loss_cls: 0.2644  decode.d4.loss_mask: 1.1418  decode.d4.loss_dice: 0.7683  decode.d5.loss_cls: 0.2770  decode.d5.loss_mask: 1.1428  decode.d5.loss_dice: 0.7749  decode.d6.loss_cls: 0.2720  decode.d6.loss_mask: 1.1416  decode.d6.loss_dice: 0.7743  decode.d7.loss_cls: 0.2742  decode.d7.loss_mask: 1.1263  decode.d7.loss_dice: 0.7871  decode.d8.loss_cls: 0.2610  decode.d8.loss_mask: 1.1441  decode.d8.loss_dice: 0.7860
05/26 17:44:07 - mmengine - INFO - Iter(train) [ 57850/160000]  base_lr: 6.6774e-05 lr: 6.6774e-06  eta: 11:39:39  time: 0.4177  data_time: 0.0097  memory: 5996  grad_norm: 552.4688  loss: 21.9243  decode.loss_cls: 0.2179  decode.loss_mask: 1.1227  decode.loss_dice: 0.8551  decode.d0.loss_cls: 0.7503  decode.d0.loss_mask: 1.0411  decode.d0.loss_dice: 0.7350  decode.d1.loss_cls: 0.2385  decode.d1.loss_mask: 1.1205  decode.d1.loss_dice: 0.8372  decode.d2.loss_cls: 0.2857  decode.d2.loss_mask: 1.0399  decode.d2.loss_dice: 0.7803  decode.d3.loss_cls: 0.2756  decode.d3.loss_mask: 1.0875  decode.d3.loss_dice: 0.7879  decode.d4.loss_cls: 0.3216  decode.d4.loss_mask: 1.0633  decode.d4.loss_dice: 0.7694  decode.d5.loss_cls: 0.2895  decode.d5.loss_mask: 1.0959  decode.d5.loss_dice: 0.8208  decode.d6.loss_cls: 0.2525  decode.d6.loss_mask: 1.0837  decode.d6.loss_dice: 0.8133  decode.d7.loss_cls: 0.3024  decode.d7.loss_mask: 1.0484  decode.d7.loss_dice: 0.7543  decode.d8.loss_cls: 0.2450  decode.d8.loss_mask: 1.0780  decode.d8.loss_dice: 0.8110
05/26 17:44:28 - mmengine - INFO - Iter(train) [ 57900/160000]  base_lr: 6.6745e-05 lr: 6.6745e-06  eta: 11:39:20  time: 0.4177  data_time: 0.0097  memory: 5967  grad_norm: 428.6206  loss: 22.4076  decode.loss_cls: 0.2647  decode.loss_mask: 1.1473  decode.loss_dice: 0.8337  decode.d0.loss_cls: 0.7174  decode.d0.loss_mask: 1.0452  decode.d0.loss_dice: 0.7680  decode.d1.loss_cls: 0.2655  decode.d1.loss_mask: 1.1085  decode.d1.loss_dice: 0.8219  decode.d2.loss_cls: 0.2554  decode.d2.loss_mask: 1.1169  decode.d2.loss_dice: 0.8161  decode.d3.loss_cls: 0.2933  decode.d3.loss_mask: 1.1309  decode.d3.loss_dice: 0.7859  decode.d4.loss_cls: 0.2750  decode.d4.loss_mask: 1.1173  decode.d4.loss_dice: 0.8158  decode.d5.loss_cls: 0.2770  decode.d5.loss_mask: 1.1506  decode.d5.loss_dice: 0.8238  decode.d6.loss_cls: 0.2904  decode.d6.loss_mask: 1.1164  decode.d6.loss_dice: 0.8107  decode.d7.loss_cls: 0.2804  decode.d7.loss_mask: 1.1210  decode.d7.loss_dice: 0.7901  decode.d8.loss_cls: 0.2368  decode.d8.loss_mask: 1.1264  decode.d8.loss_dice: 0.8052
05/26 17:44:49 - mmengine - INFO - Iter(train) [ 57950/160000]  base_lr: 6.6715e-05 lr: 6.6715e-06  eta: 11:39:00  time: 0.4197  data_time: 0.0102  memory: 5971  grad_norm: 479.4948  loss: 20.1017  decode.loss_cls: 0.3205  decode.loss_mask: 0.9410  decode.loss_dice: 0.7034  decode.d0.loss_cls: 0.7366  decode.d0.loss_mask: 0.9103  decode.d0.loss_dice: 0.6914  decode.d1.loss_cls: 0.2748  decode.d1.loss_mask: 0.9719  decode.d1.loss_dice: 0.7012  decode.d2.loss_cls: 0.3240  decode.d2.loss_mask: 0.9212  decode.d2.loss_dice: 0.6883  decode.d3.loss_cls: 0.2837  decode.d3.loss_mask: 0.9345  decode.d3.loss_dice: 0.6937  decode.d4.loss_cls: 0.3443  decode.d4.loss_mask: 0.9662  decode.d4.loss_dice: 0.7693  decode.d5.loss_cls: 0.2973  decode.d5.loss_mask: 0.9570  decode.d5.loss_dice: 0.7231  decode.d6.loss_cls: 0.3271  decode.d6.loss_mask: 0.9524  decode.d6.loss_dice: 0.6987  decode.d7.loss_cls: 0.3192  decode.d7.loss_mask: 0.9532  decode.d7.loss_dice: 0.7110  decode.d8.loss_cls: 0.3335  decode.d8.loss_mask: 0.9440  decode.d8.loss_dice: 0.7088
05/26 17:45:10 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 17:45:10 - mmengine - INFO - Iter(train) [ 58000/160000]  base_lr: 6.6686e-05 lr: 6.6686e-06  eta: 11:38:40  time: 0.4193  data_time: 0.0098  memory: 5966  grad_norm: 515.8341  loss: 22.0035  decode.loss_cls: 0.2590  decode.loss_mask: 1.1175  decode.loss_dice: 0.7548  decode.d0.loss_cls: 0.6639  decode.d0.loss_mask: 1.0858  decode.d0.loss_dice: 0.7927  decode.d1.loss_cls: 0.2859  decode.d1.loss_mask: 1.1072  decode.d1.loss_dice: 0.7671  decode.d2.loss_cls: 0.2762  decode.d2.loss_mask: 1.1438  decode.d2.loss_dice: 0.8079  decode.d3.loss_cls: 0.2763  decode.d3.loss_mask: 1.1155  decode.d3.loss_dice: 0.7692  decode.d4.loss_cls: 0.3410  decode.d4.loss_mask: 1.0980  decode.d4.loss_dice: 0.7720  decode.d5.loss_cls: 0.2773  decode.d5.loss_mask: 1.1075  decode.d5.loss_dice: 0.7686  decode.d6.loss_cls: 0.2987  decode.d6.loss_mask: 1.0652  decode.d6.loss_dice: 0.7494  decode.d7.loss_cls: 0.2683  decode.d7.loss_mask: 1.1516  decode.d7.loss_dice: 0.7598  decode.d8.loss_cls: 0.2665  decode.d8.loss_mask: 1.1137  decode.d8.loss_dice: 0.7429
05/26 17:45:31 - mmengine - INFO - Iter(train) [ 58050/160000]  base_lr: 6.6657e-05 lr: 6.6657e-06  eta: 11:38:20  time: 0.4191  data_time: 0.0097  memory: 5980  grad_norm: 737.5931  loss: 26.1271  decode.loss_cls: 0.3426  decode.loss_mask: 1.2778  decode.loss_dice: 0.8920  decode.d0.loss_cls: 0.9524  decode.d0.loss_mask: 1.2116  decode.d0.loss_dice: 0.8552  decode.d1.loss_cls: 0.4226  decode.d1.loss_mask: 1.2886  decode.d1.loss_dice: 0.9143  decode.d2.loss_cls: 0.4345  decode.d2.loss_mask: 1.2609  decode.d2.loss_dice: 0.8733  decode.d3.loss_cls: 0.3972  decode.d3.loss_mask: 1.2493  decode.d3.loss_dice: 0.9177  decode.d4.loss_cls: 0.4182  decode.d4.loss_mask: 1.2414  decode.d4.loss_dice: 0.9031  decode.d5.loss_cls: 0.4063  decode.d5.loss_mask: 1.2700  decode.d5.loss_dice: 0.8840  decode.d6.loss_cls: 0.4049  decode.d6.loss_mask: 1.2579  decode.d6.loss_dice: 0.9079  decode.d7.loss_cls: 0.4055  decode.d7.loss_mask: 1.2884  decode.d7.loss_dice: 0.9149  decode.d8.loss_cls: 0.3803  decode.d8.loss_mask: 1.2582  decode.d8.loss_dice: 0.8959
05/26 17:45:52 - mmengine - INFO - Iter(train) [ 58100/160000]  base_lr: 6.6627e-05 lr: 6.6627e-06  eta: 11:38:00  time: 0.4187  data_time: 0.0097  memory: 5968  grad_norm: 530.6738  loss: 23.3395  decode.loss_cls: 0.3273  decode.loss_mask: 1.1958  decode.loss_dice: 0.8248  decode.d0.loss_cls: 0.7785  decode.d0.loss_mask: 1.0851  decode.d0.loss_dice: 0.7948  decode.d1.loss_cls: 0.3461  decode.d1.loss_mask: 1.1211  decode.d1.loss_dice: 0.7757  decode.d2.loss_cls: 0.3035  decode.d2.loss_mask: 1.1587  decode.d2.loss_dice: 0.7966  decode.d3.loss_cls: 0.2669  decode.d3.loss_mask: 1.1986  decode.d3.loss_dice: 0.8136  decode.d4.loss_cls: 0.3774  decode.d4.loss_mask: 1.1312  decode.d4.loss_dice: 0.8051  decode.d5.loss_cls: 0.3426  decode.d5.loss_mask: 1.1482  decode.d5.loss_dice: 0.8144  decode.d6.loss_cls: 0.3433  decode.d6.loss_mask: 1.1565  decode.d6.loss_dice: 0.8172  decode.d7.loss_cls: 0.3560  decode.d7.loss_mask: 1.1607  decode.d7.loss_dice: 0.8304  decode.d8.loss_cls: 0.3306  decode.d8.loss_mask: 1.1310  decode.d8.loss_dice: 0.8078
05/26 17:46:13 - mmengine - INFO - Iter(train) [ 58150/160000]  base_lr: 6.6598e-05 lr: 6.6598e-06  eta: 11:37:41  time: 0.4196  data_time: 0.0097  memory: 5971  grad_norm: 686.9901  loss: 24.5755  decode.loss_cls: 0.3134  decode.loss_mask: 1.1967  decode.loss_dice: 0.9287  decode.d0.loss_cls: 0.8475  decode.d0.loss_mask: 1.1321  decode.d0.loss_dice: 0.8881  decode.d1.loss_cls: 0.2705  decode.d1.loss_mask: 1.1960  decode.d1.loss_dice: 0.9651  decode.d2.loss_cls: 0.3400  decode.d2.loss_mask: 1.1594  decode.d2.loss_dice: 0.8939  decode.d3.loss_cls: 0.3575  decode.d3.loss_mask: 1.1527  decode.d3.loss_dice: 0.9194  decode.d4.loss_cls: 0.4011  decode.d4.loss_mask: 1.1353  decode.d4.loss_dice: 0.9031  decode.d5.loss_cls: 0.3507  decode.d5.loss_mask: 1.1701  decode.d5.loss_dice: 0.9088  decode.d6.loss_cls: 0.3287  decode.d6.loss_mask: 1.1608  decode.d6.loss_dice: 0.9152  decode.d7.loss_cls: 0.3283  decode.d7.loss_mask: 1.1286  decode.d7.loss_dice: 0.9077  decode.d8.loss_cls: 0.3019  decode.d8.loss_mask: 1.1739  decode.d8.loss_dice: 0.9004
05/26 17:46:34 - mmengine - INFO - Iter(train) [ 58200/160000]  base_lr: 6.6568e-05 lr: 6.6568e-06  eta: 11:37:21  time: 0.4201  data_time: 0.0110  memory: 5972  grad_norm: 501.6561  loss: 19.5889  decode.loss_cls: 0.2179  decode.loss_mask: 0.9741  decode.loss_dice: 0.7100  decode.d0.loss_cls: 0.6887  decode.d0.loss_mask: 0.9651  decode.d0.loss_dice: 0.7018  decode.d1.loss_cls: 0.3258  decode.d1.loss_mask: 0.9708  decode.d1.loss_dice: 0.6834  decode.d2.loss_cls: 0.2211  decode.d2.loss_mask: 0.9625  decode.d2.loss_dice: 0.6853  decode.d3.loss_cls: 0.2130  decode.d3.loss_mask: 0.9453  decode.d3.loss_dice: 0.6941  decode.d4.loss_cls: 0.2580  decode.d4.loss_mask: 0.9822  decode.d4.loss_dice: 0.6696  decode.d5.loss_cls: 0.2247  decode.d5.loss_mask: 0.9841  decode.d5.loss_dice: 0.7237  decode.d6.loss_cls: 0.2004  decode.d6.loss_mask: 1.0167  decode.d6.loss_dice: 0.7213  decode.d7.loss_cls: 0.2744  decode.d7.loss_mask: 0.9576  decode.d7.loss_dice: 0.6752  decode.d8.loss_cls: 0.1806  decode.d8.loss_mask: 1.0291  decode.d8.loss_dice: 0.7323
05/26 17:46:55 - mmengine - INFO - Iter(train) [ 58250/160000]  base_lr: 6.6539e-05 lr: 6.6539e-06  eta: 11:37:01  time: 0.4174  data_time: 0.0097  memory: 5966  grad_norm: 897.8359  loss: 21.4034  decode.loss_cls: 0.2479  decode.loss_mask: 1.0793  decode.loss_dice: 0.7179  decode.d0.loss_cls: 0.7764  decode.d0.loss_mask: 1.0441  decode.d0.loss_dice: 0.7288  decode.d1.loss_cls: 0.2816  decode.d1.loss_mask: 1.1280  decode.d1.loss_dice: 0.7284  decode.d2.loss_cls: 0.2779  decode.d2.loss_mask: 1.1056  decode.d2.loss_dice: 0.7150  decode.d3.loss_cls: 0.3032  decode.d3.loss_mask: 1.0654  decode.d3.loss_dice: 0.7313  decode.d4.loss_cls: 0.3039  decode.d4.loss_mask: 1.0313  decode.d4.loss_dice: 0.7066  decode.d5.loss_cls: 0.2552  decode.d5.loss_mask: 1.1105  decode.d5.loss_dice: 0.7302  decode.d6.loss_cls: 0.2800  decode.d6.loss_mask: 1.1436  decode.d6.loss_dice: 0.7607  decode.d7.loss_cls: 0.2472  decode.d7.loss_mask: 1.0862  decode.d7.loss_dice: 0.7178  decode.d8.loss_cls: 0.2562  decode.d8.loss_mask: 1.1143  decode.d8.loss_dice: 0.7290
05/26 17:47:16 - mmengine - INFO - Iter(train) [ 58300/160000]  base_lr: 6.6509e-05 lr: 6.6509e-06  eta: 11:36:41  time: 0.4172  data_time: 0.0098  memory: 5968  grad_norm: 383.8183  loss: 19.9207  decode.loss_cls: 0.1670  decode.loss_mask: 0.9820  decode.loss_dice: 0.7675  decode.d0.loss_cls: 0.6973  decode.d0.loss_mask: 0.9332  decode.d0.loss_dice: 0.7450  decode.d1.loss_cls: 0.2394  decode.d1.loss_mask: 0.9169  decode.d1.loss_dice: 0.7242  decode.d2.loss_cls: 0.2004  decode.d2.loss_mask: 0.9686  decode.d2.loss_dice: 0.7396  decode.d3.loss_cls: 0.2167  decode.d3.loss_mask: 0.9851  decode.d3.loss_dice: 0.7462  decode.d4.loss_cls: 0.2377  decode.d4.loss_mask: 1.0070  decode.d4.loss_dice: 0.7927  decode.d5.loss_cls: 0.2356  decode.d5.loss_mask: 0.9601  decode.d5.loss_dice: 0.7799  decode.d6.loss_cls: 0.2230  decode.d6.loss_mask: 0.9898  decode.d6.loss_dice: 0.7647  decode.d7.loss_cls: 0.2230  decode.d7.loss_mask: 0.9845  decode.d7.loss_dice: 0.7528  decode.d8.loss_cls: 0.1930  decode.d8.loss_mask: 0.9754  decode.d8.loss_dice: 0.7725
05/26 17:47:37 - mmengine - INFO - Iter(train) [ 58350/160000]  base_lr: 6.6480e-05 lr: 6.6480e-06  eta: 11:36:21  time: 0.4192  data_time: 0.0098  memory: 5966  grad_norm: 402.5101  loss: 19.2697  decode.loss_cls: 0.2100  decode.loss_mask: 0.9189  decode.loss_dice: 0.7159  decode.d0.loss_cls: 0.6963  decode.d0.loss_mask: 0.9080  decode.d0.loss_dice: 0.7033  decode.d1.loss_cls: 0.1791  decode.d1.loss_mask: 0.9523  decode.d1.loss_dice: 0.7287  decode.d2.loss_cls: 0.1989  decode.d2.loss_mask: 0.9571  decode.d2.loss_dice: 0.7379  decode.d3.loss_cls: 0.1697  decode.d3.loss_mask: 0.9320  decode.d3.loss_dice: 0.7224  decode.d4.loss_cls: 0.2009  decode.d4.loss_mask: 0.9605  decode.d4.loss_dice: 0.7342  decode.d5.loss_cls: 0.2279  decode.d5.loss_mask: 0.9780  decode.d5.loss_dice: 0.7503  decode.d6.loss_cls: 0.2155  decode.d6.loss_mask: 0.9609  decode.d6.loss_dice: 0.7380  decode.d7.loss_cls: 0.2140  decode.d7.loss_mask: 0.9430  decode.d7.loss_dice: 0.7226  decode.d8.loss_cls: 0.2135  decode.d8.loss_mask: 0.9388  decode.d8.loss_dice: 0.7411
05/26 17:47:58 - mmengine - INFO - Iter(train) [ 58400/160000]  base_lr: 6.6451e-05 lr: 6.6451e-06  eta: 11:36:01  time: 0.4167  data_time: 0.0096  memory: 5973  grad_norm: 560.3192  loss: 22.1922  decode.loss_cls: 0.2123  decode.loss_mask: 1.1855  decode.loss_dice: 0.8282  decode.d0.loss_cls: 0.6402  decode.d0.loss_mask: 1.1183  decode.d0.loss_dice: 0.7801  decode.d1.loss_cls: 0.2025  decode.d1.loss_mask: 1.1393  decode.d1.loss_dice: 0.8418  decode.d2.loss_cls: 0.2037  decode.d2.loss_mask: 1.1497  decode.d2.loss_dice: 0.8398  decode.d3.loss_cls: 0.1901  decode.d3.loss_mask: 1.1211  decode.d3.loss_dice: 0.8390  decode.d4.loss_cls: 0.2282  decode.d4.loss_mask: 1.1351  decode.d4.loss_dice: 0.8415  decode.d5.loss_cls: 0.2251  decode.d5.loss_mask: 1.1156  decode.d5.loss_dice: 0.8172  decode.d6.loss_cls: 0.2061  decode.d6.loss_mask: 1.1461  decode.d6.loss_dice: 0.8315  decode.d7.loss_cls: 0.2492  decode.d7.loss_mask: 1.0959  decode.d7.loss_dice: 0.7805  decode.d8.loss_cls: 0.2611  decode.d8.loss_mask: 1.1494  decode.d8.loss_dice: 0.8181
05/26 17:48:19 - mmengine - INFO - Iter(train) [ 58450/160000]  base_lr: 6.6421e-05 lr: 6.6421e-06  eta: 11:35:41  time: 0.4166  data_time: 0.0097  memory: 5972  grad_norm: 588.6355  loss: 26.3430  decode.loss_cls: 0.3415  decode.loss_mask: 1.2839  decode.loss_dice: 0.9963  decode.d0.loss_cls: 0.8732  decode.d0.loss_mask: 1.1616  decode.d0.loss_dice: 0.9532  decode.d1.loss_cls: 0.3134  decode.d1.loss_mask: 1.2549  decode.d1.loss_dice: 1.0104  decode.d2.loss_cls: 0.4058  decode.d2.loss_mask: 1.2080  decode.d2.loss_dice: 0.9941  decode.d3.loss_cls: 0.3662  decode.d3.loss_mask: 1.2046  decode.d3.loss_dice: 0.9869  decode.d4.loss_cls: 0.3766  decode.d4.loss_mask: 1.2327  decode.d4.loss_dice: 1.0135  decode.d5.loss_cls: 0.3445  decode.d5.loss_mask: 1.1935  decode.d5.loss_dice: 0.9924  decode.d6.loss_cls: 0.3141  decode.d6.loss_mask: 1.2659  decode.d6.loss_dice: 1.0314  decode.d7.loss_cls: 0.3539  decode.d7.loss_mask: 1.2955  decode.d7.loss_dice: 1.0078  decode.d8.loss_cls: 0.3214  decode.d8.loss_mask: 1.2448  decode.d8.loss_dice: 1.0012
05/26 17:48:39 - mmengine - INFO - Iter(train) [ 58500/160000]  base_lr: 6.6392e-05 lr: 6.6392e-06  eta: 11:35:21  time: 0.4180  data_time: 0.0097  memory: 5990  grad_norm: 572.3935  loss: 26.5903  decode.loss_cls: 0.4158  decode.loss_mask: 1.1648  decode.loss_dice: 0.9657  decode.d0.loss_cls: 0.8873  decode.d0.loss_mask: 1.0931  decode.d0.loss_dice: 0.9654  decode.d1.loss_cls: 0.4651  decode.d1.loss_mask: 1.1614  decode.d1.loss_dice: 0.9743  decode.d2.loss_cls: 0.4730  decode.d2.loss_mask: 1.1770  decode.d2.loss_dice: 0.9803  decode.d3.loss_cls: 0.4304  decode.d3.loss_mask: 1.1800  decode.d3.loss_dice: 0.9894  decode.d4.loss_cls: 0.4151  decode.d4.loss_mask: 1.2217  decode.d4.loss_dice: 1.0312  decode.d5.loss_cls: 0.4745  decode.d5.loss_mask: 1.1895  decode.d5.loss_dice: 0.9840  decode.d6.loss_cls: 0.5065  decode.d6.loss_mask: 1.1468  decode.d6.loss_dice: 1.0264  decode.d7.loss_cls: 0.4364  decode.d7.loss_mask: 1.1986  decode.d7.loss_dice: 1.0356  decode.d8.loss_cls: 0.4417  decode.d8.loss_mask: 1.1561  decode.d8.loss_dice: 1.0032
05/26 17:49:00 - mmengine - INFO - Iter(train) [ 58550/160000]  base_lr: 6.6362e-05 lr: 6.6362e-06  eta: 11:35:01  time: 0.4158  data_time: 0.0097  memory: 5974  grad_norm: 552.7737  loss: 22.7578  decode.loss_cls: 0.2217  decode.loss_mask: 1.1697  decode.loss_dice: 0.8653  decode.d0.loss_cls: 0.7358  decode.d0.loss_mask: 1.0839  decode.d0.loss_dice: 0.8207  decode.d1.loss_cls: 0.2595  decode.d1.loss_mask: 1.1121  decode.d1.loss_dice: 0.8558  decode.d2.loss_cls: 0.2415  decode.d2.loss_mask: 1.1141  decode.d2.loss_dice: 0.8571  decode.d3.loss_cls: 0.2542  decode.d3.loss_mask: 1.0878  decode.d3.loss_dice: 0.8460  decode.d4.loss_cls: 0.2763  decode.d4.loss_mask: 1.1119  decode.d4.loss_dice: 0.8552  decode.d5.loss_cls: 0.2465  decode.d5.loss_mask: 1.1183  decode.d5.loss_dice: 0.8497  decode.d6.loss_cls: 0.3157  decode.d6.loss_mask: 1.1108  decode.d6.loss_dice: 0.8506  decode.d7.loss_cls: 0.3164  decode.d7.loss_mask: 1.1266  decode.d7.loss_dice: 0.8417  decode.d8.loss_cls: 0.2097  decode.d8.loss_mask: 1.1495  decode.d8.loss_dice: 0.8536
05/26 17:49:21 - mmengine - INFO - Iter(train) [ 58600/160000]  base_lr: 6.6333e-05 lr: 6.6333e-06  eta: 11:34:41  time: 0.4170  data_time: 0.0097  memory: 5968  grad_norm: 507.7234  loss: 22.1552  decode.loss_cls: 0.1978  decode.loss_mask: 1.2438  decode.loss_dice: 0.7464  decode.d0.loss_cls: 0.6055  decode.d0.loss_mask: 1.1892  decode.d0.loss_dice: 0.7350  decode.d1.loss_cls: 0.1963  decode.d1.loss_mask: 1.2848  decode.d1.loss_dice: 0.7489  decode.d2.loss_cls: 0.1924  decode.d2.loss_mask: 1.2320  decode.d2.loss_dice: 0.7159  decode.d3.loss_cls: 0.1937  decode.d3.loss_mask: 1.2347  decode.d3.loss_dice: 0.7248  decode.d4.loss_cls: 0.2101  decode.d4.loss_mask: 1.2246  decode.d4.loss_dice: 0.7180  decode.d5.loss_cls: 0.1826  decode.d5.loss_mask: 1.2567  decode.d5.loss_dice: 0.7809  decode.d6.loss_cls: 0.2119  decode.d6.loss_mask: 1.2437  decode.d6.loss_dice: 0.7253  decode.d7.loss_cls: 0.2092  decode.d7.loss_mask: 1.2350  decode.d7.loss_dice: 0.7295  decode.d8.loss_cls: 0.1863  decode.d8.loss_mask: 1.2563  decode.d8.loss_dice: 0.7443
05/26 17:49:42 - mmengine - INFO - Iter(train) [ 58650/160000]  base_lr: 6.6303e-05 lr: 6.6303e-06  eta: 11:34:21  time: 0.4164  data_time: 0.0096  memory: 5980  grad_norm: 383.6462  loss: 23.6119  decode.loss_cls: 0.2410  decode.loss_mask: 1.1203  decode.loss_dice: 0.8991  decode.d0.loss_cls: 0.6184  decode.d0.loss_mask: 1.2064  decode.d0.loss_dice: 0.9025  decode.d1.loss_cls: 0.2781  decode.d1.loss_mask: 1.1244  decode.d1.loss_dice: 0.8818  decode.d2.loss_cls: 0.2454  decode.d2.loss_mask: 1.1651  decode.d2.loss_dice: 0.9042  decode.d3.loss_cls: 0.2508  decode.d3.loss_mask: 1.1633  decode.d3.loss_dice: 0.8927  decode.d4.loss_cls: 0.2820  decode.d4.loss_mask: 1.1576  decode.d4.loss_dice: 0.9061  decode.d5.loss_cls: 0.2770  decode.d5.loss_mask: 1.1743  decode.d5.loss_dice: 0.9142  decode.d6.loss_cls: 0.2877  decode.d6.loss_mask: 1.1885  decode.d6.loss_dice: 0.9219  decode.d7.loss_cls: 0.2697  decode.d7.loss_mask: 1.1350  decode.d7.loss_dice: 0.9174  decode.d8.loss_cls: 0.2190  decode.d8.loss_mask: 1.1622  decode.d8.loss_dice: 0.9058
05/26 17:50:03 - mmengine - INFO - Iter(train) [ 58700/160000]  base_lr: 6.6274e-05 lr: 6.6274e-06  eta: 11:34:01  time: 0.4200  data_time: 0.0098  memory: 5976  grad_norm: 684.8599  loss: 22.6445  decode.loss_cls: 0.2526  decode.loss_mask: 1.1663  decode.loss_dice: 0.7899  decode.d0.loss_cls: 0.7476  decode.d0.loss_mask: 1.1098  decode.d0.loss_dice: 0.7855  decode.d1.loss_cls: 0.2490  decode.d1.loss_mask: 1.1739  decode.d1.loss_dice: 0.7865  decode.d2.loss_cls: 0.3240  decode.d2.loss_mask: 1.1617  decode.d2.loss_dice: 0.7754  decode.d3.loss_cls: 0.2981  decode.d3.loss_mask: 1.1333  decode.d3.loss_dice: 0.7534  decode.d4.loss_cls: 0.2785  decode.d4.loss_mask: 1.1250  decode.d4.loss_dice: 0.7502  decode.d5.loss_cls: 0.2431  decode.d5.loss_mask: 1.1714  decode.d5.loss_dice: 0.8198  decode.d6.loss_cls: 0.2778  decode.d6.loss_mask: 1.1936  decode.d6.loss_dice: 0.7761  decode.d7.loss_cls: 0.2453  decode.d7.loss_mask: 1.1788  decode.d7.loss_dice: 0.7857  decode.d8.loss_cls: 0.3045  decode.d8.loss_mask: 1.1813  decode.d8.loss_dice: 0.8063
05/26 17:50:24 - mmengine - INFO - Iter(train) [ 58750/160000]  base_lr: 6.6245e-05 lr: 6.6245e-06  eta: 11:33:41  time: 0.4188  data_time: 0.0097  memory: 5982  grad_norm: 900.8644  loss: 22.1169  decode.loss_cls: 0.2898  decode.loss_mask: 1.0848  decode.loss_dice: 0.7135  decode.d0.loss_cls: 0.7647  decode.d0.loss_mask: 1.0982  decode.d0.loss_dice: 0.7515  decode.d1.loss_cls: 0.3738  decode.d1.loss_mask: 1.0576  decode.d1.loss_dice: 0.7575  decode.d2.loss_cls: 0.3510  decode.d2.loss_mask: 1.0461  decode.d2.loss_dice: 0.7223  decode.d3.loss_cls: 0.3031  decode.d3.loss_mask: 1.0845  decode.d3.loss_dice: 0.7668  decode.d4.loss_cls: 0.3044  decode.d4.loss_mask: 1.0768  decode.d4.loss_dice: 0.7811  decode.d5.loss_cls: 0.3694  decode.d5.loss_mask: 1.0871  decode.d5.loss_dice: 0.7608  decode.d6.loss_cls: 0.3424  decode.d6.loss_mask: 1.0976  decode.d6.loss_dice: 0.7721  decode.d7.loss_cls: 0.3778  decode.d7.loss_mask: 1.0595  decode.d7.loss_dice: 0.7570  decode.d8.loss_cls: 0.3535  decode.d8.loss_mask: 1.0540  decode.d8.loss_dice: 0.7581
05/26 17:50:45 - mmengine - INFO - Iter(train) [ 58800/160000]  base_lr: 6.6215e-05 lr: 6.6215e-06  eta: 11:33:21  time: 0.4180  data_time: 0.0098  memory: 5998  grad_norm: 780.4463  loss: 23.5566  decode.loss_cls: 0.1646  decode.loss_mask: 1.2869  decode.loss_dice: 0.8437  decode.d0.loss_cls: 0.7155  decode.d0.loss_mask: 1.1868  decode.d0.loss_dice: 0.8018  decode.d1.loss_cls: 0.1973  decode.d1.loss_mask: 1.2554  decode.d1.loss_dice: 0.8568  decode.d2.loss_cls: 0.1744  decode.d2.loss_mask: 1.2618  decode.d2.loss_dice: 0.8510  decode.d3.loss_cls: 0.2672  decode.d3.loss_mask: 1.2589  decode.d3.loss_dice: 0.8402  decode.d4.loss_cls: 0.2761  decode.d4.loss_mask: 1.2345  decode.d4.loss_dice: 0.8535  decode.d5.loss_cls: 0.2876  decode.d5.loss_mask: 1.2108  decode.d5.loss_dice: 0.8213  decode.d6.loss_cls: 0.2603  decode.d6.loss_mask: 1.2206  decode.d6.loss_dice: 0.8353  decode.d7.loss_cls: 0.2333  decode.d7.loss_mask: 1.2147  decode.d7.loss_dice: 0.8437  decode.d8.loss_cls: 0.2645  decode.d8.loss_mask: 1.2209  decode.d8.loss_dice: 0.8173
05/26 17:51:06 - mmengine - INFO - Iter(train) [ 58850/160000]  base_lr: 6.6186e-05 lr: 6.6186e-06  eta: 11:33:01  time: 0.4212  data_time: 0.0098  memory: 5967  grad_norm: 578.6158  loss: 21.1296  decode.loss_cls: 0.2480  decode.loss_mask: 0.9913  decode.loss_dice: 0.8545  decode.d0.loss_cls: 0.7370  decode.d0.loss_mask: 1.0029  decode.d0.loss_dice: 0.7756  decode.d1.loss_cls: 0.2094  decode.d1.loss_mask: 1.0293  decode.d1.loss_dice: 0.8384  decode.d2.loss_cls: 0.2746  decode.d2.loss_mask: 1.0045  decode.d2.loss_dice: 0.8016  decode.d3.loss_cls: 0.2702  decode.d3.loss_mask: 0.9767  decode.d3.loss_dice: 0.7771  decode.d4.loss_cls: 0.2552  decode.d4.loss_mask: 0.9974  decode.d4.loss_dice: 0.8220  decode.d5.loss_cls: 0.2689  decode.d5.loss_mask: 0.9940  decode.d5.loss_dice: 0.8017  decode.d6.loss_cls: 0.2249  decode.d6.loss_mask: 1.0077  decode.d6.loss_dice: 0.8314  decode.d7.loss_cls: 0.2639  decode.d7.loss_mask: 0.9815  decode.d7.loss_dice: 0.8105  decode.d8.loss_cls: 0.2753  decode.d8.loss_mask: 0.9868  decode.d8.loss_dice: 0.8173
05/26 17:51:27 - mmengine - INFO - Iter(train) [ 58900/160000]  base_lr: 6.6156e-05 lr: 6.6156e-06  eta: 11:32:41  time: 0.4177  data_time: 0.0098  memory: 5984  grad_norm: 552.9578  loss: 22.4651  decode.loss_cls: 0.1389  decode.loss_mask: 1.2486  decode.loss_dice: 0.8139  decode.d0.loss_cls: 0.6864  decode.d0.loss_mask: 1.1485  decode.d0.loss_dice: 0.8081  decode.d1.loss_cls: 0.1586  decode.d1.loss_mask: 1.2210  decode.d1.loss_dice: 0.7853  decode.d2.loss_cls: 0.1844  decode.d2.loss_mask: 1.2125  decode.d2.loss_dice: 0.7671  decode.d3.loss_cls: 0.1844  decode.d3.loss_mask: 1.2719  decode.d3.loss_dice: 0.7778  decode.d4.loss_cls: 0.1874  decode.d4.loss_mask: 1.2234  decode.d4.loss_dice: 0.7763  decode.d5.loss_cls: 0.1851  decode.d5.loss_mask: 1.2588  decode.d5.loss_dice: 0.8331  decode.d6.loss_cls: 0.1734  decode.d6.loss_mask: 1.2103  decode.d6.loss_dice: 0.7971  decode.d7.loss_cls: 0.1898  decode.d7.loss_mask: 1.2230  decode.d7.loss_dice: 0.7946  decode.d8.loss_cls: 0.1667  decode.d8.loss_mask: 1.2409  decode.d8.loss_dice: 0.7977
05/26 17:51:48 - mmengine - INFO - Iter(train) [ 58950/160000]  base_lr: 6.6127e-05 lr: 6.6127e-06  eta: 11:32:22  time: 0.4207  data_time: 0.0097  memory: 5980  grad_norm: 403.7914  loss: 21.6605  decode.loss_cls: 0.2616  decode.loss_mask: 0.9955  decode.loss_dice: 0.8166  decode.d0.loss_cls: 0.7493  decode.d0.loss_mask: 0.9818  decode.d0.loss_dice: 0.8131  decode.d1.loss_cls: 0.2626  decode.d1.loss_mask: 1.0162  decode.d1.loss_dice: 0.8337  decode.d2.loss_cls: 0.2852  decode.d2.loss_mask: 1.0253  decode.d2.loss_dice: 0.8577  decode.d3.loss_cls: 0.3088  decode.d3.loss_mask: 0.9811  decode.d3.loss_dice: 0.8234  decode.d4.loss_cls: 0.2876  decode.d4.loss_mask: 0.9966  decode.d4.loss_dice: 0.8066  decode.d5.loss_cls: 0.3124  decode.d5.loss_mask: 1.0094  decode.d5.loss_dice: 0.8024  decode.d6.loss_cls: 0.2994  decode.d6.loss_mask: 0.9816  decode.d6.loss_dice: 0.8302  decode.d7.loss_cls: 0.3111  decode.d7.loss_mask: 1.0241  decode.d7.loss_dice: 0.8456  decode.d8.loss_cls: 0.2640  decode.d8.loss_mask: 1.0427  decode.d8.loss_dice: 0.8349
05/26 17:52:09 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 17:52:09 - mmengine - INFO - Iter(train) [ 59000/160000]  base_lr: 6.6097e-05 lr: 6.6097e-06  eta: 11:32:02  time: 0.4204  data_time: 0.0097  memory: 5966  grad_norm: 870.0017  loss: 24.9216  decode.loss_cls: 0.2130  decode.loss_mask: 1.3686  decode.loss_dice: 0.9031  decode.d0.loss_cls: 0.7115  decode.d0.loss_mask: 1.2696  decode.d0.loss_dice: 0.8817  decode.d1.loss_cls: 0.2507  decode.d1.loss_mask: 1.3462  decode.d1.loss_dice: 0.9063  decode.d2.loss_cls: 0.2405  decode.d2.loss_mask: 1.3376  decode.d2.loss_dice: 0.8779  decode.d3.loss_cls: 0.2125  decode.d3.loss_mask: 1.3403  decode.d3.loss_dice: 0.8699  decode.d4.loss_cls: 0.2266  decode.d4.loss_mask: 1.3318  decode.d4.loss_dice: 0.8479  decode.d5.loss_cls: 0.2272  decode.d5.loss_mask: 1.3413  decode.d5.loss_dice: 0.8759  decode.d6.loss_cls: 0.2283  decode.d6.loss_mask: 1.3275  decode.d6.loss_dice: 0.8542  decode.d7.loss_cls: 0.2293  decode.d7.loss_mask: 1.3283  decode.d7.loss_dice: 0.8881  decode.d8.loss_cls: 0.2345  decode.d8.loss_mask: 1.3626  decode.d8.loss_dice: 0.8889
05/26 17:52:30 - mmengine - INFO - Iter(train) [ 59050/160000]  base_lr: 6.6068e-05 lr: 6.6068e-06  eta: 11:31:42  time: 0.4197  data_time: 0.0098  memory: 5979  grad_norm: 398.9028  loss: 21.4652  decode.loss_cls: 0.1784  decode.loss_mask: 1.0875  decode.loss_dice: 0.7888  decode.d0.loss_cls: 0.6639  decode.d0.loss_mask: 1.0803  decode.d0.loss_dice: 0.7425  decode.d1.loss_cls: 0.1664  decode.d1.loss_mask: 1.1105  decode.d1.loss_dice: 0.7849  decode.d2.loss_cls: 0.2215  decode.d2.loss_mask: 1.1391  decode.d2.loss_dice: 0.7936  decode.d3.loss_cls: 0.1840  decode.d3.loss_mask: 1.1298  decode.d3.loss_dice: 0.7910  decode.d4.loss_cls: 0.1842  decode.d4.loss_mask: 1.1229  decode.d4.loss_dice: 0.7996  decode.d5.loss_cls: 0.2069  decode.d5.loss_mask: 1.1191  decode.d5.loss_dice: 0.7906  decode.d6.loss_cls: 0.1977  decode.d6.loss_mask: 1.0877  decode.d6.loss_dice: 0.7765  decode.d7.loss_cls: 0.2012  decode.d7.loss_mask: 1.1641  decode.d7.loss_dice: 0.7826  decode.d8.loss_cls: 0.2427  decode.d8.loss_mask: 1.1207  decode.d8.loss_dice: 0.8065
05/26 17:52:51 - mmengine - INFO - Iter(train) [ 59100/160000]  base_lr: 6.6038e-05 lr: 6.6038e-06  eta: 11:31:22  time: 0.4205  data_time: 0.0098  memory: 5968  grad_norm: 799.5566  loss: 30.2022  decode.loss_cls: 0.5081  decode.loss_mask: 1.5085  decode.loss_dice: 1.0289  decode.d0.loss_cls: 0.8767  decode.d0.loss_mask: 1.3850  decode.d0.loss_dice: 0.9812  decode.d1.loss_cls: 0.5412  decode.d1.loss_mask: 1.4660  decode.d1.loss_dice: 1.0212  decode.d2.loss_cls: 0.4850  decode.d2.loss_mask: 1.4847  decode.d2.loss_dice: 0.9861  decode.d3.loss_cls: 0.4400  decode.d3.loss_mask: 1.4764  decode.d3.loss_dice: 0.9913  decode.d4.loss_cls: 0.5273  decode.d4.loss_mask: 1.4274  decode.d4.loss_dice: 0.9940  decode.d5.loss_cls: 0.4307  decode.d5.loss_mask: 1.5377  decode.d5.loss_dice: 1.0349  decode.d6.loss_cls: 0.4907  decode.d6.loss_mask: 1.5294  decode.d6.loss_dice: 1.0881  decode.d7.loss_cls: 0.4467  decode.d7.loss_mask: 1.5224  decode.d7.loss_dice: 1.0650  decode.d8.loss_cls: 0.4595  decode.d8.loss_mask: 1.4493  decode.d8.loss_dice: 1.0190
05/26 17:53:12 - mmengine - INFO - Iter(train) [ 59150/160000]  base_lr: 6.6009e-05 lr: 6.6009e-06  eta: 11:31:03  time: 0.4198  data_time: 0.0097  memory: 5983  grad_norm: 501.4896  loss: 25.2852  decode.loss_cls: 0.3657  decode.loss_mask: 1.1654  decode.loss_dice: 0.9414  decode.d0.loss_cls: 0.8753  decode.d0.loss_mask: 1.1005  decode.d0.loss_dice: 0.8694  decode.d1.loss_cls: 0.3382  decode.d1.loss_mask: 1.2158  decode.d1.loss_dice: 0.9589  decode.d2.loss_cls: 0.3263  decode.d2.loss_mask: 1.1937  decode.d2.loss_dice: 0.9334  decode.d3.loss_cls: 0.3622  decode.d3.loss_mask: 1.1889  decode.d3.loss_dice: 0.9633  decode.d4.loss_cls: 0.3512  decode.d4.loss_mask: 1.1800  decode.d4.loss_dice: 0.9842  decode.d5.loss_cls: 0.3336  decode.d5.loss_mask: 1.1655  decode.d5.loss_dice: 0.9575  decode.d6.loss_cls: 0.3524  decode.d6.loss_mask: 1.1912  decode.d6.loss_dice: 0.9927  decode.d7.loss_cls: 0.3235  decode.d7.loss_mask: 1.2012  decode.d7.loss_dice: 0.9947  decode.d8.loss_cls: 0.3258  decode.d8.loss_mask: 1.1867  decode.d8.loss_dice: 0.9468
05/26 17:53:33 - mmengine - INFO - Iter(train) [ 59200/160000]  base_lr: 6.5979e-05 lr: 6.5979e-06  eta: 11:30:43  time: 0.4168  data_time: 0.0097  memory: 5975  grad_norm: 388.4018  loss: 19.4760  decode.loss_cls: 0.1754  decode.loss_mask: 0.9925  decode.loss_dice: 0.7576  decode.d0.loss_cls: 0.7232  decode.d0.loss_mask: 0.9760  decode.d0.loss_dice: 0.7340  decode.d1.loss_cls: 0.1760  decode.d1.loss_mask: 0.9746  decode.d1.loss_dice: 0.7395  decode.d2.loss_cls: 0.1637  decode.d2.loss_mask: 0.9611  decode.d2.loss_dice: 0.7613  decode.d3.loss_cls: 0.1559  decode.d3.loss_mask: 0.9918  decode.d3.loss_dice: 0.7487  decode.d4.loss_cls: 0.1539  decode.d4.loss_mask: 0.9680  decode.d4.loss_dice: 0.7526  decode.d5.loss_cls: 0.1717  decode.d5.loss_mask: 0.9465  decode.d5.loss_dice: 0.7432  decode.d6.loss_cls: 0.1650  decode.d6.loss_mask: 0.9623  decode.d6.loss_dice: 0.7542  decode.d7.loss_cls: 0.2421  decode.d7.loss_mask: 0.9390  decode.d7.loss_dice: 0.7272  decode.d8.loss_cls: 0.1914  decode.d8.loss_mask: 0.9762  decode.d8.loss_dice: 0.7514
05/26 17:53:54 - mmengine - INFO - Iter(train) [ 59250/160000]  base_lr: 6.5950e-05 lr: 6.5950e-06  eta: 11:30:23  time: 0.4170  data_time: 0.0097  memory: 5983  grad_norm: 787.4412  loss: 20.8816  decode.loss_cls: 0.1307  decode.loss_mask: 1.2028  decode.loss_dice: 0.6991  decode.d0.loss_cls: 0.6396  decode.d0.loss_mask: 1.1366  decode.d0.loss_dice: 0.6928  decode.d1.loss_cls: 0.1348  decode.d1.loss_mask: 1.1900  decode.d1.loss_dice: 0.7272  decode.d2.loss_cls: 0.1596  decode.d2.loss_mask: 1.1773  decode.d2.loss_dice: 0.6855  decode.d3.loss_cls: 0.1799  decode.d3.loss_mask: 1.2064  decode.d3.loss_dice: 0.7116  decode.d4.loss_cls: 0.1286  decode.d4.loss_mask: 1.2209  decode.d4.loss_dice: 0.7089  decode.d5.loss_cls: 0.0991  decode.d5.loss_mask: 1.2397  decode.d5.loss_dice: 0.7256  decode.d6.loss_cls: 0.1549  decode.d6.loss_mask: 1.1736  decode.d6.loss_dice: 0.7035  decode.d7.loss_cls: 0.1634  decode.d7.loss_mask: 1.1463  decode.d7.loss_dice: 0.6832  decode.d8.loss_cls: 0.1433  decode.d8.loss_mask: 1.1962  decode.d8.loss_dice: 0.7204
05/26 17:54:15 - mmengine - INFO - Iter(train) [ 59300/160000]  base_lr: 6.5921e-05 lr: 6.5921e-06  eta: 11:30:03  time: 0.4176  data_time: 0.0098  memory: 5965  grad_norm: 986.9438  loss: 24.1015  decode.loss_cls: 0.3351  decode.loss_mask: 1.2359  decode.loss_dice: 0.8641  decode.d0.loss_cls: 0.8080  decode.d0.loss_mask: 1.0802  decode.d0.loss_dice: 0.8093  decode.d1.loss_cls: 0.3346  decode.d1.loss_mask: 1.1535  decode.d1.loss_dice: 0.8451  decode.d2.loss_cls: 0.3456  decode.d2.loss_mask: 1.1818  decode.d2.loss_dice: 0.8294  decode.d3.loss_cls: 0.3443  decode.d3.loss_mask: 1.2370  decode.d3.loss_dice: 0.8732  decode.d4.loss_cls: 0.3858  decode.d4.loss_mask: 1.1329  decode.d4.loss_dice: 0.8222  decode.d5.loss_cls: 0.3696  decode.d5.loss_mask: 1.1556  decode.d5.loss_dice: 0.8638  decode.d6.loss_cls: 0.3817  decode.d6.loss_mask: 1.1786  decode.d6.loss_dice: 0.8548  decode.d7.loss_cls: 0.3421  decode.d7.loss_mask: 1.1625  decode.d7.loss_dice: 0.8462  decode.d8.loss_cls: 0.2983  decode.d8.loss_mask: 1.2011  decode.d8.loss_dice: 0.8293
05/26 17:54:36 - mmengine - INFO - Iter(train) [ 59350/160000]  base_lr: 6.5891e-05 lr: 6.5891e-06  eta: 11:29:43  time: 0.4171  data_time: 0.0097  memory: 5976  grad_norm: 456.5291  loss: 24.0752  decode.loss_cls: 0.3126  decode.loss_mask: 1.1275  decode.loss_dice: 0.8623  decode.d0.loss_cls: 0.8249  decode.d0.loss_mask: 1.1024  decode.d0.loss_dice: 0.8133  decode.d1.loss_cls: 0.3366  decode.d1.loss_mask: 1.1950  decode.d1.loss_dice: 0.9139  decode.d2.loss_cls: 0.2960  decode.d2.loss_mask: 1.1350  decode.d2.loss_dice: 0.8527  decode.d3.loss_cls: 0.2917  decode.d3.loss_mask: 1.2204  decode.d3.loss_dice: 0.9021  decode.d4.loss_cls: 0.3412  decode.d4.loss_mask: 1.1550  decode.d4.loss_dice: 0.8836  decode.d5.loss_cls: 0.3476  decode.d5.loss_mask: 1.1868  decode.d5.loss_dice: 0.9267  decode.d6.loss_cls: 0.3070  decode.d6.loss_mask: 1.1972  decode.d6.loss_dice: 0.8968  decode.d7.loss_cls: 0.3134  decode.d7.loss_mask: 1.1567  decode.d7.loss_dice: 0.8894  decode.d8.loss_cls: 0.2705  decode.d8.loss_mask: 1.1505  decode.d8.loss_dice: 0.8666
05/26 17:54:56 - mmengine - INFO - Iter(train) [ 59400/160000]  base_lr: 6.5862e-05 lr: 6.5862e-06  eta: 11:29:23  time: 0.4176  data_time: 0.0098  memory: 5979  grad_norm: 349.8206  loss: 19.7378  decode.loss_cls: 0.1439  decode.loss_mask: 1.1424  decode.loss_dice: 0.6634  decode.d0.loss_cls: 0.5838  decode.d0.loss_mask: 1.0627  decode.d0.loss_dice: 0.6695  decode.d1.loss_cls: 0.1257  decode.d1.loss_mask: 1.1359  decode.d1.loss_dice: 0.6759  decode.d2.loss_cls: 0.1209  decode.d2.loss_mask: 1.1361  decode.d2.loss_dice: 0.6698  decode.d3.loss_cls: 0.1316  decode.d3.loss_mask: 1.1251  decode.d3.loss_dice: 0.6622  decode.d4.loss_cls: 0.1374  decode.d4.loss_mask: 1.1263  decode.d4.loss_dice: 0.6584  decode.d5.loss_cls: 0.1166  decode.d5.loss_mask: 1.1631  decode.d5.loss_dice: 0.6766  decode.d6.loss_cls: 0.1398  decode.d6.loss_mask: 1.1277  decode.d6.loss_dice: 0.6774  decode.d7.loss_cls: 0.1329  decode.d7.loss_mask: 1.1151  decode.d7.loss_dice: 0.6780  decode.d8.loss_cls: 0.1352  decode.d8.loss_mask: 1.1341  decode.d8.loss_dice: 0.6704
05/26 17:55:17 - mmengine - INFO - Iter(train) [ 59450/160000]  base_lr: 6.5832e-05 lr: 6.5832e-06  eta: 11:29:03  time: 0.4166  data_time: 0.0097  memory: 5976  grad_norm: 600.1414  loss: 18.9039  decode.loss_cls: 0.1441  decode.loss_mask: 1.0363  decode.loss_dice: 0.6839  decode.d0.loss_cls: 0.6227  decode.d0.loss_mask: 0.9298  decode.d0.loss_dice: 0.6579  decode.d1.loss_cls: 0.1554  decode.d1.loss_mask: 1.0437  decode.d1.loss_dice: 0.6533  decode.d2.loss_cls: 0.1374  decode.d2.loss_mask: 1.0335  decode.d2.loss_dice: 0.6644  decode.d3.loss_cls: 0.1821  decode.d3.loss_mask: 0.9769  decode.d3.loss_dice: 0.6383  decode.d4.loss_cls: 0.1888  decode.d4.loss_mask: 0.9927  decode.d4.loss_dice: 0.6374  decode.d5.loss_cls: 0.1731  decode.d5.loss_mask: 1.0601  decode.d5.loss_dice: 0.6795  decode.d6.loss_cls: 0.1931  decode.d6.loss_mask: 0.9974  decode.d6.loss_dice: 0.6549  decode.d7.loss_cls: 0.1682  decode.d7.loss_mask: 1.0372  decode.d7.loss_dice: 0.6706  decode.d8.loss_cls: 0.1497  decode.d8.loss_mask: 1.0570  decode.d8.loss_dice: 0.6841
05/26 17:55:38 - mmengine - INFO - Iter(train) [ 59500/160000]  base_lr: 6.5803e-05 lr: 6.5803e-06  eta: 11:28:43  time: 0.4197  data_time: 0.0097  memory: 5967  grad_norm: 648.0592  loss: 24.9932  decode.loss_cls: 0.1904  decode.loss_mask: 1.3985  decode.loss_dice: 0.9096  decode.d0.loss_cls: 0.5964  decode.d0.loss_mask: 1.3319  decode.d0.loss_dice: 0.8965  decode.d1.loss_cls: 0.1758  decode.d1.loss_mask: 1.3808  decode.d1.loss_dice: 0.8867  decode.d2.loss_cls: 0.1580  decode.d2.loss_mask: 1.3822  decode.d2.loss_dice: 0.8999  decode.d3.loss_cls: 0.1892  decode.d3.loss_mask: 1.3769  decode.d3.loss_dice: 0.8877  decode.d4.loss_cls: 0.2048  decode.d4.loss_mask: 1.3597  decode.d4.loss_dice: 0.8817  decode.d5.loss_cls: 0.1802  decode.d5.loss_mask: 1.3916  decode.d5.loss_dice: 0.8904  decode.d6.loss_cls: 0.1862  decode.d6.loss_mask: 1.4002  decode.d6.loss_dice: 0.8949  decode.d7.loss_cls: 0.2177  decode.d7.loss_mask: 1.3698  decode.d7.loss_dice: 0.8949  decode.d8.loss_cls: 0.1946  decode.d8.loss_mask: 1.3745  decode.d8.loss_dice: 0.8916
05/26 17:55:59 - mmengine - INFO - Iter(train) [ 59550/160000]  base_lr: 6.5773e-05 lr: 6.5773e-06  eta: 11:28:23  time: 0.4171  data_time: 0.0097  memory: 5968  grad_norm: 530.5826  loss: 21.5265  decode.loss_cls: 0.2278  decode.loss_mask: 1.0606  decode.loss_dice: 0.7989  decode.d0.loss_cls: 0.7460  decode.d0.loss_mask: 1.0353  decode.d0.loss_dice: 0.7457  decode.d1.loss_cls: 0.2393  decode.d1.loss_mask: 1.0584  decode.d1.loss_dice: 0.8124  decode.d2.loss_cls: 0.2622  decode.d2.loss_mask: 1.0467  decode.d2.loss_dice: 0.7798  decode.d3.loss_cls: 0.2259  decode.d3.loss_mask: 1.0585  decode.d3.loss_dice: 0.7894  decode.d4.loss_cls: 0.2388  decode.d4.loss_mask: 1.0711  decode.d4.loss_dice: 0.8080  decode.d5.loss_cls: 0.2638  decode.d5.loss_mask: 1.0656  decode.d5.loss_dice: 0.7787  decode.d6.loss_cls: 0.2689  decode.d6.loss_mask: 1.0616  decode.d6.loss_dice: 0.7876  decode.d7.loss_cls: 0.3030  decode.d7.loss_mask: 1.0744  decode.d7.loss_dice: 0.8175  decode.d8.loss_cls: 0.2909  decode.d8.loss_mask: 1.0288  decode.d8.loss_dice: 0.7808
05/26 17:56:20 - mmengine - INFO - Iter(train) [ 59600/160000]  base_lr: 6.5744e-05 lr: 6.5744e-06  eta: 11:28:03  time: 0.4184  data_time: 0.0097  memory: 5988  grad_norm: 857.3268  loss: 22.0247  decode.loss_cls: 0.2556  decode.loss_mask: 1.0884  decode.loss_dice: 0.8129  decode.d0.loss_cls: 0.6782  decode.d0.loss_mask: 1.0668  decode.d0.loss_dice: 0.7983  decode.d1.loss_cls: 0.3019  decode.d1.loss_mask: 1.0803  decode.d1.loss_dice: 0.8012  decode.d2.loss_cls: 0.2713  decode.d2.loss_mask: 1.1050  decode.d2.loss_dice: 0.7829  decode.d3.loss_cls: 0.2736  decode.d3.loss_mask: 1.0425  decode.d3.loss_dice: 0.7770  decode.d4.loss_cls: 0.2936  decode.d4.loss_mask: 1.0947  decode.d4.loss_dice: 0.7895  decode.d5.loss_cls: 0.2757  decode.d5.loss_mask: 1.1034  decode.d5.loss_dice: 0.8145  decode.d6.loss_cls: 0.2701  decode.d6.loss_mask: 1.1024  decode.d6.loss_dice: 0.8098  decode.d7.loss_cls: 0.2695  decode.d7.loss_mask: 1.0929  decode.d7.loss_dice: 0.7685  decode.d8.loss_cls: 0.2554  decode.d8.loss_mask: 1.1425  decode.d8.loss_dice: 0.8065
05/26 17:56:41 - mmengine - INFO - Iter(train) [ 59650/160000]  base_lr: 6.5714e-05 lr: 6.5714e-06  eta: 11:27:43  time: 0.4175  data_time: 0.0097  memory: 5966  grad_norm: 854.4666  loss: 26.8830  decode.loss_cls: 0.2621  decode.loss_mask: 1.3307  decode.loss_dice: 1.0025  decode.d0.loss_cls: 0.7778  decode.d0.loss_mask: 1.3553  decode.d0.loss_dice: 0.9743  decode.d1.loss_cls: 0.3145  decode.d1.loss_mask: 1.4008  decode.d1.loss_dice: 0.9943  decode.d2.loss_cls: 0.2820  decode.d2.loss_mask: 1.3371  decode.d2.loss_dice: 0.9761  decode.d3.loss_cls: 0.2729  decode.d3.loss_mask: 1.3162  decode.d3.loss_dice: 1.0101  decode.d4.loss_cls: 0.3315  decode.d4.loss_mask: 1.3365  decode.d4.loss_dice: 0.9911  decode.d5.loss_cls: 0.2436  decode.d5.loss_mask: 1.3568  decode.d5.loss_dice: 1.0214  decode.d6.loss_cls: 0.2787  decode.d6.loss_mask: 1.3767  decode.d6.loss_dice: 0.9859  decode.d7.loss_cls: 0.2839  decode.d7.loss_mask: 1.3775  decode.d7.loss_dice: 1.0383  decode.d8.loss_cls: 0.2528  decode.d8.loss_mask: 1.3745  decode.d8.loss_dice: 1.0274
05/26 17:57:02 - mmengine - INFO - Iter(train) [ 59700/160000]  base_lr: 6.5685e-05 lr: 6.5685e-06  eta: 11:27:22  time: 0.4165  data_time: 0.0097  memory: 5971  grad_norm: 787.3347  loss: 24.8143  decode.loss_cls: 0.4039  decode.loss_mask: 1.2046  decode.loss_dice: 0.9157  decode.d0.loss_cls: 0.6907  decode.d0.loss_mask: 1.1534  decode.d0.loss_dice: 0.8563  decode.d1.loss_cls: 0.3341  decode.d1.loss_mask: 1.1998  decode.d1.loss_dice: 0.8992  decode.d2.loss_cls: 0.3179  decode.d2.loss_mask: 1.2258  decode.d2.loss_dice: 0.8990  decode.d3.loss_cls: 0.3303  decode.d3.loss_mask: 1.2490  decode.d3.loss_dice: 0.9083  decode.d4.loss_cls: 0.3504  decode.d4.loss_mask: 1.2351  decode.d4.loss_dice: 0.8859  decode.d5.loss_cls: 0.3529  decode.d5.loss_mask: 1.1941  decode.d5.loss_dice: 0.9100  decode.d6.loss_cls: 0.3490  decode.d6.loss_mask: 1.2039  decode.d6.loss_dice: 0.8573  decode.d7.loss_cls: 0.3388  decode.d7.loss_mask: 1.1880  decode.d7.loss_dice: 0.9098  decode.d8.loss_cls: 0.4167  decode.d8.loss_mask: 1.1703  decode.d8.loss_dice: 0.8641
05/26 17:57:23 - mmengine - INFO - Iter(train) [ 59750/160000]  base_lr: 6.5655e-05 lr: 6.5655e-06  eta: 11:27:02  time: 0.4165  data_time: 0.0097  memory: 5972  grad_norm: 629.9410  loss: 21.2745  decode.loss_cls: 0.1793  decode.loss_mask: 1.0772  decode.loss_dice: 0.7916  decode.d0.loss_cls: 0.6683  decode.d0.loss_mask: 1.0482  decode.d0.loss_dice: 0.7559  decode.d1.loss_cls: 0.2069  decode.d1.loss_mask: 1.0947  decode.d1.loss_dice: 0.8125  decode.d2.loss_cls: 0.1904  decode.d2.loss_mask: 1.0809  decode.d2.loss_dice: 0.7893  decode.d3.loss_cls: 0.2086  decode.d3.loss_mask: 1.0800  decode.d3.loss_dice: 0.8053  decode.d4.loss_cls: 0.1877  decode.d4.loss_mask: 1.1128  decode.d4.loss_dice: 0.8323  decode.d5.loss_cls: 0.1884  decode.d5.loss_mask: 1.0645  decode.d5.loss_dice: 0.8185  decode.d6.loss_cls: 0.2339  decode.d6.loss_mask: 1.0799  decode.d6.loss_dice: 0.7921  decode.d7.loss_cls: 0.2132  decode.d7.loss_mask: 1.0866  decode.d7.loss_dice: 0.7956  decode.d8.loss_cls: 0.2043  decode.d8.loss_mask: 1.0859  decode.d8.loss_dice: 0.7899
05/26 17:57:43 - mmengine - INFO - Iter(train) [ 59800/160000]  base_lr: 6.5626e-05 lr: 6.5626e-06  eta: 11:26:42  time: 0.4165  data_time: 0.0098  memory: 5966  grad_norm: 565.6448  loss: 20.3834  decode.loss_cls: 0.2377  decode.loss_mask: 0.9850  decode.loss_dice: 0.7647  decode.d0.loss_cls: 0.7342  decode.d0.loss_mask: 0.9121  decode.d0.loss_dice: 0.7399  decode.d1.loss_cls: 0.2320  decode.d1.loss_mask: 0.9789  decode.d1.loss_dice: 0.7896  decode.d2.loss_cls: 0.2270  decode.d2.loss_mask: 0.9963  decode.d2.loss_dice: 0.7770  decode.d3.loss_cls: 0.2207  decode.d3.loss_mask: 1.0189  decode.d3.loss_dice: 0.7641  decode.d4.loss_cls: 0.3052  decode.d4.loss_mask: 0.9480  decode.d4.loss_dice: 0.7628  decode.d5.loss_cls: 0.2292  decode.d5.loss_mask: 0.9929  decode.d5.loss_dice: 0.8019  decode.d6.loss_cls: 0.2554  decode.d6.loss_mask: 0.9647  decode.d6.loss_dice: 0.7737  decode.d7.loss_cls: 0.2335  decode.d7.loss_mask: 0.9750  decode.d7.loss_dice: 0.7662  decode.d8.loss_cls: 0.2667  decode.d8.loss_mask: 0.9768  decode.d8.loss_dice: 0.7529
05/26 17:58:04 - mmengine - INFO - Iter(train) [ 59850/160000]  base_lr: 6.5596e-05 lr: 6.5596e-06  eta: 11:26:22  time: 0.4163  data_time: 0.0097  memory: 5971  grad_norm: 421.3854  loss: 20.6536  decode.loss_cls: 0.2582  decode.loss_mask: 0.9910  decode.loss_dice: 0.7647  decode.d0.loss_cls: 0.8802  decode.d0.loss_mask: 0.9492  decode.d0.loss_dice: 0.6936  decode.d1.loss_cls: 0.3079  decode.d1.loss_mask: 0.9517  decode.d1.loss_dice: 0.7389  decode.d2.loss_cls: 0.2682  decode.d2.loss_mask: 0.9647  decode.d2.loss_dice: 0.7313  decode.d3.loss_cls: 0.2934  decode.d3.loss_mask: 0.9694  decode.d3.loss_dice: 0.7218  decode.d4.loss_cls: 0.3125  decode.d4.loss_mask: 0.9535  decode.d4.loss_dice: 0.7297  decode.d5.loss_cls: 0.2926  decode.d5.loss_mask: 0.9659  decode.d5.loss_dice: 0.7585  decode.d6.loss_cls: 0.2764  decode.d6.loss_mask: 1.0296  decode.d6.loss_dice: 0.7590  decode.d7.loss_cls: 0.2987  decode.d7.loss_mask: 1.0362  decode.d7.loss_dice: 0.7520  decode.d8.loss_cls: 0.2704  decode.d8.loss_mask: 0.9675  decode.d8.loss_dice: 0.7669
05/26 17:58:25 - mmengine - INFO - Iter(train) [ 59900/160000]  base_lr: 6.5567e-05 lr: 6.5567e-06  eta: 11:26:02  time: 0.4158  data_time: 0.0097  memory: 5973  grad_norm: 494.5701  loss: 25.7161  decode.loss_cls: 0.3748  decode.loss_mask: 1.2567  decode.loss_dice: 0.8685  decode.d0.loss_cls: 0.8037  decode.d0.loss_mask: 1.2701  decode.d0.loss_dice: 0.8586  decode.d1.loss_cls: 0.3704  decode.d1.loss_mask: 1.2932  decode.d1.loss_dice: 0.8730  decode.d2.loss_cls: 0.4114  decode.d2.loss_mask: 1.3113  decode.d2.loss_dice: 0.8628  decode.d3.loss_cls: 0.3612  decode.d3.loss_mask: 1.3122  decode.d3.loss_dice: 0.8810  decode.d4.loss_cls: 0.3731  decode.d4.loss_mask: 1.3322  decode.d4.loss_dice: 0.8320  decode.d5.loss_cls: 0.3592  decode.d5.loss_mask: 1.2742  decode.d5.loss_dice: 0.8963  decode.d6.loss_cls: 0.3275  decode.d6.loss_mask: 1.3189  decode.d6.loss_dice: 0.8894  decode.d7.loss_cls: 0.3519  decode.d7.loss_mask: 1.2591  decode.d7.loss_dice: 0.8995  decode.d8.loss_cls: 0.3528  decode.d8.loss_mask: 1.2586  decode.d8.loss_dice: 0.8826
05/26 17:58:46 - mmengine - INFO - Iter(train) [ 59950/160000]  base_lr: 6.5537e-05 lr: 6.5537e-06  eta: 11:25:42  time: 0.4173  data_time: 0.0098  memory: 5975  grad_norm: 525.2429  loss: 24.4009  decode.loss_cls: 0.2864  decode.loss_mask: 1.1758  decode.loss_dice: 0.9070  decode.d0.loss_cls: 0.7396  decode.d0.loss_mask: 1.2245  decode.d0.loss_dice: 0.9164  decode.d1.loss_cls: 0.2557  decode.d1.loss_mask: 1.1721  decode.d1.loss_dice: 0.8925  decode.d2.loss_cls: 0.2866  decode.d2.loss_mask: 1.1635  decode.d2.loss_dice: 0.8991  decode.d3.loss_cls: 0.2948  decode.d3.loss_mask: 1.1609  decode.d3.loss_dice: 0.8976  decode.d4.loss_cls: 0.3030  decode.d4.loss_mask: 1.2974  decode.d4.loss_dice: 0.9577  decode.d5.loss_cls: 0.2976  decode.d5.loss_mask: 1.1411  decode.d5.loss_dice: 0.9047  decode.d6.loss_cls: 0.2561  decode.d6.loss_mask: 1.1837  decode.d6.loss_dice: 0.9557  decode.d7.loss_cls: 0.3203  decode.d7.loss_mask: 1.1548  decode.d7.loss_dice: 0.9280  decode.d8.loss_cls: 0.2902  decode.d8.loss_mask: 1.2107  decode.d8.loss_dice: 0.9277
05/26 17:59:07 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 17:59:07 - mmengine - INFO - Iter(train) [ 60000/160000]  base_lr: 6.5508e-05 lr: 6.5508e-06  eta: 11:25:22  time: 0.4176  data_time: 0.0097  memory: 5971  grad_norm: 669.8685  loss: 25.5934  decode.loss_cls: 0.2275  decode.loss_mask: 1.3934  decode.loss_dice: 0.8785  decode.d0.loss_cls: 0.7876  decode.d0.loss_mask: 1.3357  decode.d0.loss_dice: 0.8343  decode.d1.loss_cls: 0.2299  decode.d1.loss_mask: 1.3557  decode.d1.loss_dice: 0.8352  decode.d2.loss_cls: 0.2263  decode.d2.loss_mask: 1.4040  decode.d2.loss_dice: 0.8697  decode.d3.loss_cls: 0.1970  decode.d3.loss_mask: 1.4430  decode.d3.loss_dice: 0.8954  decode.d4.loss_cls: 0.2726  decode.d4.loss_mask: 1.3759  decode.d4.loss_dice: 0.8625  decode.d5.loss_cls: 0.3439  decode.d5.loss_mask: 1.3815  decode.d5.loss_dice: 0.8640  decode.d6.loss_cls: 0.2176  decode.d6.loss_mask: 1.4999  decode.d6.loss_dice: 0.9080  decode.d7.loss_cls: 0.2325  decode.d7.loss_mask: 1.3797  decode.d7.loss_dice: 0.8677  decode.d8.loss_cls: 0.2219  decode.d8.loss_mask: 1.3802  decode.d8.loss_dice: 0.8722
05/26 17:59:07 - mmengine - INFO - Saving checkpoint at 60000 iterations
05/26 17:59:11 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:11  time: 0.0495  data_time: 0.0012  memory: 1391  
05/26 17:59:14 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:07  time: 0.0494  data_time: 0.0013  memory: 1205  
05/26 17:59:16 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:05  time: 0.0516  data_time: 0.0013  memory: 1596  
05/26 17:59:19 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:02  time: 0.0501  data_time: 0.0013  memory: 1298  
05/26 17:59:21 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:01:00  time: 0.0504  data_time: 0.0013  memory: 1298  
05/26 17:59:24 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:57  time: 0.0502  data_time: 0.0013  memory: 1279  
05/26 17:59:26 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:55  time: 0.0496  data_time: 0.0013  memory: 1224  
05/26 17:59:29 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:52  time: 0.0500  data_time: 0.0012  memory: 1298  
05/26 17:59:31 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:50  time: 0.0490  data_time: 0.0013  memory: 1298  
05/26 17:59:34 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:47  time: 0.0533  data_time: 0.0013  memory: 1725  
05/26 17:59:36 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:45  time: 0.0493  data_time: 0.0012  memory: 1336  
05/26 17:59:39 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:42  time: 0.0495  data_time: 0.0013  memory: 1298  
05/26 17:59:41 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:39  time: 0.0501  data_time: 0.0013  memory: 1205  
05/26 17:59:44 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:37  time: 0.0502  data_time: 0.0013  memory: 1316  
05/26 17:59:46 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:34  time: 0.0493  data_time: 0.0013  memory: 1279  
05/26 17:59:49 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:32  time: 0.0526  data_time: 0.0013  memory: 1410  
05/26 17:59:51 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:29  time: 0.0507  data_time: 0.0013  memory: 1279  
05/26 17:59:54 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:27  time: 0.0505  data_time: 0.0013  memory: 1205  
05/26 17:59:56 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0504  data_time: 0.0013  memory: 1205  
05/26 17:59:59 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:22  time: 0.0501  data_time: 0.0013  memory: 1336  
05/26 18:00:01 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:20  time: 0.0499  data_time: 0.0013  memory: 1246  
05/26 18:00:04 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0529  data_time: 0.0013  memory: 1503  
05/26 18:00:07 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0502  data_time: 0.0013  memory: 1261  
05/26 18:00:09 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0508  data_time: 0.0013  memory: 1298  
05/26 18:00:12 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0499  data_time: 0.0013  memory: 1447  
05/26 18:00:14 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0502  data_time: 0.0013  memory: 1298  
05/26 18:00:17 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0511  data_time: 0.0013  memory: 1279  
05/26 18:00:19 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0509  data_time: 0.0013  memory: 1205  
05/26 18:00:22 - mmengine - INFO - per class results:
05/26 18:00:22 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 94.51 | 95.93 |
|  aeroplane  | 93.15 | 95.52 |
|   bicycle   | 42.26 | 92.15 |
|     bird    | 90.78 | 96.81 |
|     boat    | 63.73 | 94.62 |
|    bottle   | 81.39 | 90.43 |
|     bus     | 94.69 | 97.57 |
|     car     |  90.0 | 95.94 |
|     cat     | 95.11 | 97.89 |
|    chair    | 39.03 | 54.44 |
|     cow     | 85.72 | 95.06 |
| diningtable | 60.05 | 72.08 |
|     dog     | 88.11 | 97.98 |
|    horse    | 85.52 | 90.33 |
|  motorbike  | 90.03 | 97.11 |
|    person   | 88.73 |  96.3 |
| pottedplant | 68.47 | 89.94 |
|    sheep    | 88.35 | 91.43 |
|     sofa    | 51.31 | 84.95 |
|    train    | 90.48 | 94.18 |
|  tvmonitor  | 76.14 | 89.42 |
+-------------+-------+-------+
05/26 18:00:22 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.0200  mIoU: 78.9300  mAcc: 90.9600  data_time: 0.0013  time: 0.0502
05/26 18:00:22 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_50000.pth is removed
05/26 18:00:23 - mmengine - INFO - The best checkpoint with 78.9300 mIoU at 60000 iter is saved to best_mIoU_iter_60000.pth.
05/26 18:00:46 - mmengine - INFO - Iter(train) [ 60050/160000]  base_lr: 6.5479e-05 lr: 6.5479e-06  eta: 11:25:08  time: 0.4185  data_time: 0.0098  memory: 5975  grad_norm: 507.8200  loss: 19.0554  decode.loss_cls: 0.1994  decode.loss_mask: 0.9052  decode.loss_dice: 0.7249  decode.d0.loss_cls: 0.7260  decode.d0.loss_mask: 0.8684  decode.d0.loss_dice: 0.7134  decode.d1.loss_cls: 0.2335  decode.d1.loss_mask: 0.9215  decode.d1.loss_dice: 0.7239  decode.d2.loss_cls: 0.2082  decode.d2.loss_mask: 0.9500  decode.d2.loss_dice: 0.7615  decode.d3.loss_cls: 0.1983  decode.d3.loss_mask: 0.9017  decode.d3.loss_dice: 0.7441  decode.d4.loss_cls: 0.2596  decode.d4.loss_mask: 0.8676  decode.d4.loss_dice: 0.7068  decode.d5.loss_cls: 0.2433  decode.d5.loss_mask: 0.8951  decode.d5.loss_dice: 0.7381  decode.d6.loss_cls: 0.2213  decode.d6.loss_mask: 0.8980  decode.d6.loss_dice: 0.7505  decode.d7.loss_cls: 0.2289  decode.d7.loss_mask: 0.9097  decode.d7.loss_dice: 0.7355  decode.d8.loss_cls: 0.1504  decode.d8.loss_mask: 0.9341  decode.d8.loss_dice: 0.7364
05/26 18:01:07 - mmengine - INFO - Iter(train) [ 60100/160000]  base_lr: 6.5449e-05 lr: 6.5449e-06  eta: 11:24:48  time: 0.4192  data_time: 0.0097  memory: 5969  grad_norm: 366.6713  loss: 19.5914  decode.loss_cls: 0.1823  decode.loss_mask: 0.9517  decode.loss_dice: 0.7478  decode.d0.loss_cls: 0.6726  decode.d0.loss_mask: 0.9839  decode.d0.loss_dice: 0.7220  decode.d1.loss_cls: 0.1834  decode.d1.loss_mask: 0.9786  decode.d1.loss_dice: 0.7644  decode.d2.loss_cls: 0.1816  decode.d2.loss_mask: 0.9593  decode.d2.loss_dice: 0.7354  decode.d3.loss_cls: 0.1801  decode.d3.loss_mask: 0.9760  decode.d3.loss_dice: 0.7561  decode.d4.loss_cls: 0.1981  decode.d4.loss_mask: 0.9774  decode.d4.loss_dice: 0.7843  decode.d5.loss_cls: 0.1883  decode.d5.loss_mask: 0.9696  decode.d5.loss_dice: 0.7462  decode.d6.loss_cls: 0.2195  decode.d6.loss_mask: 0.9504  decode.d6.loss_dice: 0.7403  decode.d7.loss_cls: 0.1931  decode.d7.loss_mask: 0.9808  decode.d7.loss_dice: 0.7554  decode.d8.loss_cls: 0.1753  decode.d8.loss_mask: 0.9791  decode.d8.loss_dice: 0.7586
05/26 18:01:28 - mmengine - INFO - Iter(train) [ 60150/160000]  base_lr: 6.5420e-05 lr: 6.5420e-06  eta: 11:24:28  time: 0.4205  data_time: 0.0098  memory: 5974  grad_norm: 829.5758  loss: 22.1824  decode.loss_cls: 0.2877  decode.loss_mask: 1.1199  decode.loss_dice: 0.8050  decode.d0.loss_cls: 0.7459  decode.d0.loss_mask: 1.0343  decode.d0.loss_dice: 0.7666  decode.d1.loss_cls: 0.2878  decode.d1.loss_mask: 1.0724  decode.d1.loss_dice: 0.7818  decode.d2.loss_cls: 0.3130  decode.d2.loss_mask: 1.0705  decode.d2.loss_dice: 0.8081  decode.d3.loss_cls: 0.2462  decode.d3.loss_mask: 1.1036  decode.d3.loss_dice: 0.8079  decode.d4.loss_cls: 0.2482  decode.d4.loss_mask: 1.1084  decode.d4.loss_dice: 0.8294  decode.d5.loss_cls: 0.2758  decode.d5.loss_mask: 1.0870  decode.d5.loss_dice: 0.7833  decode.d6.loss_cls: 0.2450  decode.d6.loss_mask: 1.1081  decode.d6.loss_dice: 0.8168  decode.d7.loss_cls: 0.3379  decode.d7.loss_mask: 1.0961  decode.d7.loss_dice: 0.8053  decode.d8.loss_cls: 0.2897  decode.d8.loss_mask: 1.0934  decode.d8.loss_dice: 0.8072
05/26 18:01:49 - mmengine - INFO - Iter(train) [ 60200/160000]  base_lr: 6.5390e-05 lr: 6.5390e-06  eta: 11:24:08  time: 0.4193  data_time: 0.0099  memory: 5969  grad_norm: 743.6118  loss: 19.0371  decode.loss_cls: 0.1048  decode.loss_mask: 1.0157  decode.loss_dice: 0.7252  decode.d0.loss_cls: 0.6326  decode.d0.loss_mask: 0.9667  decode.d0.loss_dice: 0.7000  decode.d1.loss_cls: 0.1007  decode.d1.loss_mask: 1.0440  decode.d1.loss_dice: 0.7388  decode.d2.loss_cls: 0.0977  decode.d2.loss_mask: 1.0140  decode.d2.loss_dice: 0.7117  decode.d3.loss_cls: 0.0727  decode.d3.loss_mask: 1.0359  decode.d3.loss_dice: 0.7335  decode.d4.loss_cls: 0.1342  decode.d4.loss_mask: 0.9982  decode.d4.loss_dice: 0.7306  decode.d5.loss_cls: 0.1521  decode.d5.loss_mask: 1.0169  decode.d5.loss_dice: 0.7397  decode.d6.loss_cls: 0.1117  decode.d6.loss_mask: 1.0455  decode.d6.loss_dice: 0.7247  decode.d7.loss_cls: 0.0896  decode.d7.loss_mask: 1.0516  decode.d7.loss_dice: 0.7105  decode.d8.loss_cls: 0.1147  decode.d8.loss_mask: 1.0140  decode.d8.loss_dice: 0.7090
05/26 18:02:10 - mmengine - INFO - Iter(train) [ 60250/160000]  base_lr: 6.5361e-05 lr: 6.5361e-06  eta: 11:23:48  time: 0.4197  data_time: 0.0099  memory: 5968  grad_norm: 774.1899  loss: 18.7684  decode.loss_cls: 0.1924  decode.loss_mask: 0.9586  decode.loss_dice: 0.6597  decode.d0.loss_cls: 0.5695  decode.d0.loss_mask: 0.9361  decode.d0.loss_dice: 0.6493  decode.d1.loss_cls: 0.1886  decode.d1.loss_mask: 1.0081  decode.d1.loss_dice: 0.6896  decode.d2.loss_cls: 0.1967  decode.d2.loss_mask: 1.0075  decode.d2.loss_dice: 0.7051  decode.d3.loss_cls: 0.2108  decode.d3.loss_mask: 0.9674  decode.d3.loss_dice: 0.6896  decode.d4.loss_cls: 0.1880  decode.d4.loss_mask: 0.9483  decode.d4.loss_dice: 0.6582  decode.d5.loss_cls: 0.1826  decode.d5.loss_mask: 0.9680  decode.d5.loss_dice: 0.6798  decode.d6.loss_cls: 0.1913  decode.d6.loss_mask: 0.9486  decode.d6.loss_dice: 0.6609  decode.d7.loss_cls: 0.1931  decode.d7.loss_mask: 0.9702  decode.d7.loss_dice: 0.6641  decode.d8.loss_cls: 0.1877  decode.d8.loss_mask: 1.0106  decode.d8.loss_dice: 0.6879
05/26 18:02:31 - mmengine - INFO - Iter(train) [ 60300/160000]  base_lr: 6.5331e-05 lr: 6.5331e-06  eta: 11:23:28  time: 0.4207  data_time: 0.0106  memory: 5972  grad_norm: 561.5184  loss: 22.4525  decode.loss_cls: 0.3384  decode.loss_mask: 1.0024  decode.loss_dice: 0.8189  decode.d0.loss_cls: 0.7866  decode.d0.loss_mask: 0.9815  decode.d0.loss_dice: 0.7757  decode.d1.loss_cls: 0.3486  decode.d1.loss_mask: 1.0053  decode.d1.loss_dice: 0.8464  decode.d2.loss_cls: 0.3486  decode.d2.loss_mask: 1.0006  decode.d2.loss_dice: 0.8518  decode.d3.loss_cls: 0.3643  decode.d3.loss_mask: 1.0373  decode.d3.loss_dice: 0.8480  decode.d4.loss_cls: 0.3977  decode.d4.loss_mask: 0.9911  decode.d4.loss_dice: 0.8303  decode.d5.loss_cls: 0.3419  decode.d5.loss_mask: 1.0250  decode.d5.loss_dice: 0.8415  decode.d6.loss_cls: 0.3471  decode.d6.loss_mask: 1.0074  decode.d6.loss_dice: 0.7988  decode.d7.loss_cls: 0.3531  decode.d7.loss_mask: 1.0524  decode.d7.loss_dice: 0.8573  decode.d8.loss_cls: 0.3588  decode.d8.loss_mask: 1.0579  decode.d8.loss_dice: 0.8381
05/26 18:02:52 - mmengine - INFO - Iter(train) [ 60350/160000]  base_lr: 6.5302e-05 lr: 6.5302e-06  eta: 11:23:08  time: 0.4199  data_time: 0.0098  memory: 5975  grad_norm: 948.4010  loss: 18.8663  decode.loss_cls: 0.1921  decode.loss_mask: 0.9129  decode.loss_dice: 0.7171  decode.d0.loss_cls: 0.6912  decode.d0.loss_mask: 0.9118  decode.d0.loss_dice: 0.6867  decode.d1.loss_cls: 0.2131  decode.d1.loss_mask: 0.9264  decode.d1.loss_dice: 0.7239  decode.d2.loss_cls: 0.2235  decode.d2.loss_mask: 0.8843  decode.d2.loss_dice: 0.6911  decode.d3.loss_cls: 0.2003  decode.d3.loss_mask: 0.8844  decode.d3.loss_dice: 0.7061  decode.d4.loss_cls: 0.2229  decode.d4.loss_mask: 0.9391  decode.d4.loss_dice: 0.7122  decode.d5.loss_cls: 0.2013  decode.d5.loss_mask: 0.9304  decode.d5.loss_dice: 0.7118  decode.d6.loss_cls: 0.2285  decode.d6.loss_mask: 0.9637  decode.d6.loss_dice: 0.7227  decode.d7.loss_cls: 0.1940  decode.d7.loss_mask: 0.9127  decode.d7.loss_dice: 0.7169  decode.d8.loss_cls: 0.1946  decode.d8.loss_mask: 0.9362  decode.d8.loss_dice: 0.7143
05/26 18:03:13 - mmengine - INFO - Iter(train) [ 60400/160000]  base_lr: 6.5272e-05 lr: 6.5272e-06  eta: 11:22:48  time: 0.4216  data_time: 0.0098  memory: 5973  grad_norm: 595.5703  loss: 24.5320  decode.loss_cls: 0.4051  decode.loss_mask: 1.1140  decode.loss_dice: 0.9042  decode.d0.loss_cls: 0.8839  decode.d0.loss_mask: 1.0708  decode.d0.loss_dice: 0.9092  decode.d1.loss_cls: 0.3792  decode.d1.loss_mask: 1.0707  decode.d1.loss_dice: 0.9538  decode.d2.loss_cls: 0.3296  decode.d2.loss_mask: 1.1162  decode.d2.loss_dice: 0.9025  decode.d3.loss_cls: 0.3714  decode.d3.loss_mask: 1.1277  decode.d3.loss_dice: 0.9338  decode.d4.loss_cls: 0.3768  decode.d4.loss_mask: 1.1729  decode.d4.loss_dice: 0.9292  decode.d5.loss_cls: 0.3154  decode.d5.loss_mask: 1.1432  decode.d5.loss_dice: 0.9149  decode.d6.loss_cls: 0.3736  decode.d6.loss_mask: 1.1568  decode.d6.loss_dice: 0.9336  decode.d7.loss_cls: 0.3948  decode.d7.loss_mask: 1.0668  decode.d7.loss_dice: 0.8891  decode.d8.loss_cls: 0.3904  decode.d8.loss_mask: 1.1048  decode.d8.loss_dice: 0.8976
05/26 18:03:34 - mmengine - INFO - Iter(train) [ 60450/160000]  base_lr: 6.5243e-05 lr: 6.5243e-06  eta: 11:22:29  time: 0.4199  data_time: 0.0098  memory: 5975  grad_norm: 367.6460  loss: 17.2585  decode.loss_cls: 0.1261  decode.loss_mask: 0.9058  decode.loss_dice: 0.6502  decode.d0.loss_cls: 0.5974  decode.d0.loss_mask: 0.9008  decode.d0.loss_dice: 0.6161  decode.d1.loss_cls: 0.1801  decode.d1.loss_mask: 0.9114  decode.d1.loss_dice: 0.6441  decode.d2.loss_cls: 0.1168  decode.d2.loss_mask: 0.9207  decode.d2.loss_dice: 0.6347  decode.d3.loss_cls: 0.1293  decode.d3.loss_mask: 0.9022  decode.d3.loss_dice: 0.6407  decode.d4.loss_cls: 0.1399  decode.d4.loss_mask: 0.9171  decode.d4.loss_dice: 0.6551  decode.d5.loss_cls: 0.1602  decode.d5.loss_mask: 0.8988  decode.d5.loss_dice: 0.6250  decode.d6.loss_cls: 0.1557  decode.d6.loss_mask: 0.8967  decode.d6.loss_dice: 0.6135  decode.d7.loss_cls: 0.1112  decode.d7.loss_mask: 0.9004  decode.d7.loss_dice: 0.6347  decode.d8.loss_cls: 0.1217  decode.d8.loss_mask: 0.9057  decode.d8.loss_dice: 0.6463
05/26 18:03:55 - mmengine - INFO - Iter(train) [ 60500/160000]  base_lr: 6.5213e-05 lr: 6.5213e-06  eta: 11:22:09  time: 0.4200  data_time: 0.0098  memory: 5966  grad_norm: 1150.8763  loss: 23.9142  decode.loss_cls: 0.1969  decode.loss_mask: 1.2584  decode.loss_dice: 0.8781  decode.d0.loss_cls: 0.7675  decode.d0.loss_mask: 1.1959  decode.d0.loss_dice: 0.7952  decode.d1.loss_cls: 0.2718  decode.d1.loss_mask: 1.2216  decode.d1.loss_dice: 0.8349  decode.d2.loss_cls: 0.2511  decode.d2.loss_mask: 1.2173  decode.d2.loss_dice: 0.8266  decode.d3.loss_cls: 0.2388  decode.d3.loss_mask: 1.2723  decode.d3.loss_dice: 0.8412  decode.d4.loss_cls: 0.2465  decode.d4.loss_mask: 1.2608  decode.d4.loss_dice: 0.8442  decode.d5.loss_cls: 0.2128  decode.d5.loss_mask: 1.2749  decode.d5.loss_dice: 0.8524  decode.d6.loss_cls: 0.2803  decode.d6.loss_mask: 1.2279  decode.d6.loss_dice: 0.8510  decode.d7.loss_cls: 0.2739  decode.d7.loss_mask: 1.2298  decode.d7.loss_dice: 0.8388  decode.d8.loss_cls: 0.2320  decode.d8.loss_mask: 1.3167  decode.d8.loss_dice: 0.9046
05/26 18:04:16 - mmengine - INFO - Iter(train) [ 60550/160000]  base_lr: 6.5184e-05 lr: 6.5184e-06  eta: 11:21:49  time: 0.4197  data_time: 0.0098  memory: 5969  grad_norm: 760.5621  loss: 24.4120  decode.loss_cls: 0.3140  decode.loss_mask: 1.2214  decode.loss_dice: 0.8835  decode.d0.loss_cls: 0.8213  decode.d0.loss_mask: 1.1191  decode.d0.loss_dice: 0.8195  decode.d1.loss_cls: 0.3527  decode.d1.loss_mask: 1.1795  decode.d1.loss_dice: 0.8817  decode.d2.loss_cls: 0.3399  decode.d2.loss_mask: 1.1613  decode.d2.loss_dice: 0.8740  decode.d3.loss_cls: 0.3200  decode.d3.loss_mask: 1.1951  decode.d3.loss_dice: 0.8761  decode.d4.loss_cls: 0.3580  decode.d4.loss_mask: 1.1749  decode.d4.loss_dice: 0.8698  decode.d5.loss_cls: 0.2861  decode.d5.loss_mask: 1.2557  decode.d5.loss_dice: 0.9138  decode.d6.loss_cls: 0.2876  decode.d6.loss_mask: 1.2008  decode.d6.loss_dice: 0.8820  decode.d7.loss_cls: 0.2867  decode.d7.loss_mask: 1.2318  decode.d7.loss_dice: 0.8875  decode.d8.loss_cls: 0.3226  decode.d8.loss_mask: 1.2077  decode.d8.loss_dice: 0.8880
05/26 18:04:37 - mmengine - INFO - Iter(train) [ 60600/160000]  base_lr: 6.5154e-05 lr: 6.5154e-06  eta: 11:21:29  time: 0.4212  data_time: 0.0098  memory: 5971  grad_norm: 748.9948  loss: 23.6511  decode.loss_cls: 0.3672  decode.loss_mask: 0.9467  decode.loss_dice: 0.9783  decode.d0.loss_cls: 0.8612  decode.d0.loss_mask: 0.8720  decode.d0.loss_dice: 0.8893  decode.d1.loss_cls: 0.3944  decode.d1.loss_mask: 0.9704  decode.d1.loss_dice: 0.9853  decode.d2.loss_cls: 0.4188  decode.d2.loss_mask: 0.9748  decode.d2.loss_dice: 0.9980  decode.d3.loss_cls: 0.4119  decode.d3.loss_mask: 1.0015  decode.d3.loss_dice: 0.9802  decode.d4.loss_cls: 0.4336  decode.d4.loss_mask: 0.9514  decode.d4.loss_dice: 0.9773  decode.d5.loss_cls: 0.4019  decode.d5.loss_mask: 0.9002  decode.d5.loss_dice: 0.9241  decode.d6.loss_cls: 0.4198  decode.d6.loss_mask: 0.9733  decode.d6.loss_dice: 0.9852  decode.d7.loss_cls: 0.4031  decode.d7.loss_mask: 0.9577  decode.d7.loss_dice: 0.9655  decode.d8.loss_cls: 0.3974  decode.d8.loss_mask: 0.9267  decode.d8.loss_dice: 0.9840
05/26 18:04:58 - mmengine - INFO - Iter(train) [ 60650/160000]  base_lr: 6.5125e-05 lr: 6.5125e-06  eta: 11:21:09  time: 0.4201  data_time: 0.0098  memory: 5969  grad_norm: 336.6700  loss: 19.6780  decode.loss_cls: 0.1425  decode.loss_mask: 0.9567  decode.loss_dice: 0.8061  decode.d0.loss_cls: 0.7026  decode.d0.loss_mask: 0.9612  decode.d0.loss_dice: 0.7551  decode.d1.loss_cls: 0.2599  decode.d1.loss_mask: 0.8908  decode.d1.loss_dice: 0.7414  decode.d2.loss_cls: 0.1827  decode.d2.loss_mask: 0.9522  decode.d2.loss_dice: 0.7652  decode.d3.loss_cls: 0.1997  decode.d3.loss_mask: 0.9605  decode.d3.loss_dice: 0.8053  decode.d4.loss_cls: 0.2680  decode.d4.loss_mask: 0.9207  decode.d4.loss_dice: 0.7910  decode.d5.loss_cls: 0.1827  decode.d5.loss_mask: 0.9174  decode.d5.loss_dice: 0.8018  decode.d6.loss_cls: 0.1662  decode.d6.loss_mask: 0.9510  decode.d6.loss_dice: 0.7833  decode.d7.loss_cls: 0.1642  decode.d7.loss_mask: 0.9202  decode.d7.loss_dice: 0.7874  decode.d8.loss_cls: 0.1954  decode.d8.loss_mask: 0.9757  decode.d8.loss_dice: 0.7709
05/26 18:05:19 - mmengine - INFO - Iter(train) [ 60700/160000]  base_lr: 6.5095e-05 lr: 6.5095e-06  eta: 11:20:49  time: 0.4189  data_time: 0.0098  memory: 5967  grad_norm: 812.6448  loss: 16.7271  decode.loss_cls: 0.1469  decode.loss_mask: 0.9039  decode.loss_dice: 0.6200  decode.d0.loss_cls: 0.4995  decode.d0.loss_mask: 0.8773  decode.d0.loss_dice: 0.5954  decode.d1.loss_cls: 0.0914  decode.d1.loss_mask: 0.8928  decode.d1.loss_dice: 0.6509  decode.d2.loss_cls: 0.1294  decode.d2.loss_mask: 0.8753  decode.d2.loss_dice: 0.6189  decode.d3.loss_cls: 0.1117  decode.d3.loss_mask: 0.8822  decode.d3.loss_dice: 0.6299  decode.d4.loss_cls: 0.1073  decode.d4.loss_mask: 0.8840  decode.d4.loss_dice: 0.6440  decode.d5.loss_cls: 0.1300  decode.d5.loss_mask: 0.8788  decode.d5.loss_dice: 0.6505  decode.d6.loss_cls: 0.1119  decode.d6.loss_mask: 0.8960  decode.d6.loss_dice: 0.6400  decode.d7.loss_cls: 0.0897  decode.d7.loss_mask: 0.8786  decode.d7.loss_dice: 0.6384  decode.d8.loss_cls: 0.1089  decode.d8.loss_mask: 0.9008  decode.d8.loss_dice: 0.6423
05/26 18:05:40 - mmengine - INFO - Iter(train) [ 60750/160000]  base_lr: 6.5066e-05 lr: 6.5066e-06  eta: 11:20:29  time: 0.4193  data_time: 0.0098  memory: 5969  grad_norm: 605.6481  loss: 24.3743  decode.loss_cls: 0.3309  decode.loss_mask: 1.2356  decode.loss_dice: 0.8308  decode.d0.loss_cls: 0.7300  decode.d0.loss_mask: 1.1922  decode.d0.loss_dice: 0.8910  decode.d1.loss_cls: 0.3352  decode.d1.loss_mask: 1.2309  decode.d1.loss_dice: 0.8311  decode.d2.loss_cls: 0.3539  decode.d2.loss_mask: 1.2039  decode.d2.loss_dice: 0.8365  decode.d3.loss_cls: 0.3092  decode.d3.loss_mask: 1.2763  decode.d3.loss_dice: 0.8028  decode.d4.loss_cls: 0.3432  decode.d4.loss_mask: 1.2348  decode.d4.loss_dice: 0.8276  decode.d5.loss_cls: 0.2962  decode.d5.loss_mask: 1.2280  decode.d5.loss_dice: 0.8450  decode.d6.loss_cls: 0.3436  decode.d6.loss_mask: 1.2255  decode.d6.loss_dice: 0.8508  decode.d7.loss_cls: 0.3195  decode.d7.loss_mask: 1.2564  decode.d7.loss_dice: 0.8316  decode.d8.loss_cls: 0.3508  decode.d8.loss_mask: 1.2171  decode.d8.loss_dice: 0.8140
05/26 18:06:01 - mmengine - INFO - Iter(train) [ 60800/160000]  base_lr: 6.5036e-05 lr: 6.5036e-06  eta: 11:20:10  time: 0.4195  data_time: 0.0098  memory: 5971  grad_norm: 853.9050  loss: 25.9671  decode.loss_cls: 0.3884  decode.loss_mask: 1.2326  decode.loss_dice: 0.9345  decode.d0.loss_cls: 0.8830  decode.d0.loss_mask: 1.1356  decode.d0.loss_dice: 0.8993  decode.d1.loss_cls: 0.4071  decode.d1.loss_mask: 1.2038  decode.d1.loss_dice: 0.9356  decode.d2.loss_cls: 0.4606  decode.d2.loss_mask: 1.1593  decode.d2.loss_dice: 0.8982  decode.d3.loss_cls: 0.4083  decode.d3.loss_mask: 1.1768  decode.d3.loss_dice: 0.9021  decode.d4.loss_cls: 0.4090  decode.d4.loss_mask: 1.3746  decode.d4.loss_dice: 0.9713  decode.d5.loss_cls: 0.3560  decode.d5.loss_mask: 1.2673  decode.d5.loss_dice: 0.9639  decode.d6.loss_cls: 0.4158  decode.d6.loss_mask: 1.1795  decode.d6.loss_dice: 0.9457  decode.d7.loss_cls: 0.3947  decode.d7.loss_mask: 1.2027  decode.d7.loss_dice: 0.9425  decode.d8.loss_cls: 0.3815  decode.d8.loss_mask: 1.2174  decode.d8.loss_dice: 0.9201
05/26 18:06:22 - mmengine - INFO - Iter(train) [ 60850/160000]  base_lr: 6.5007e-05 lr: 6.5007e-06  eta: 11:19:50  time: 0.4192  data_time: 0.0098  memory: 5973  grad_norm: 801.5699  loss: 26.5120  decode.loss_cls: 0.1550  decode.loss_mask: 1.4751  decode.loss_dice: 0.9579  decode.d0.loss_cls: 0.7902  decode.d0.loss_mask: 1.3593  decode.d0.loss_dice: 0.8950  decode.d1.loss_cls: 0.2056  decode.d1.loss_mask: 1.4548  decode.d1.loss_dice: 0.9442  decode.d2.loss_cls: 0.2055  decode.d2.loss_mask: 1.4634  decode.d2.loss_dice: 0.9641  decode.d3.loss_cls: 0.2121  decode.d3.loss_mask: 1.4625  decode.d3.loss_dice: 0.9520  decode.d4.loss_cls: 0.1866  decode.d4.loss_mask: 1.4623  decode.d4.loss_dice: 0.9387  decode.d5.loss_cls: 0.2135  decode.d5.loss_mask: 1.4561  decode.d5.loss_dice: 0.9602  decode.d6.loss_cls: 0.2048  decode.d6.loss_mask: 1.4669  decode.d6.loss_dice: 0.9520  decode.d7.loss_cls: 0.1635  decode.d7.loss_mask: 1.4627  decode.d7.loss_dice: 0.9517  decode.d8.loss_cls: 0.1650  decode.d8.loss_mask: 1.4770  decode.d8.loss_dice: 0.9541
05/26 18:06:43 - mmengine - INFO - Iter(train) [ 60900/160000]  base_lr: 6.4977e-05 lr: 6.4977e-06  eta: 11:19:30  time: 0.4179  data_time: 0.0097  memory: 5973  grad_norm: 1139.2589  loss: 27.6204  decode.loss_cls: 0.3416  decode.loss_mask: 1.2926  decode.loss_dice: 1.0425  decode.d0.loss_cls: 0.9837  decode.d0.loss_mask: 1.1963  decode.d0.loss_dice: 0.9536  decode.d1.loss_cls: 0.3828  decode.d1.loss_mask: 1.3511  decode.d1.loss_dice: 1.0822  decode.d2.loss_cls: 0.3412  decode.d2.loss_mask: 1.2810  decode.d2.loss_dice: 0.9776  decode.d3.loss_cls: 0.4079  decode.d3.loss_mask: 1.2757  decode.d3.loss_dice: 0.9905  decode.d4.loss_cls: 0.4581  decode.d4.loss_mask: 1.2489  decode.d4.loss_dice: 0.9994  decode.d5.loss_cls: 0.4237  decode.d5.loss_mask: 1.2500  decode.d5.loss_dice: 1.0804  decode.d6.loss_cls: 0.4325  decode.d6.loss_mask: 1.3198  decode.d6.loss_dice: 1.1106  decode.d7.loss_cls: 0.4001  decode.d7.loss_mask: 1.2936  decode.d7.loss_dice: 1.0375  decode.d8.loss_cls: 0.3650  decode.d8.loss_mask: 1.2661  decode.d8.loss_dice: 1.0348
05/26 18:07:04 - mmengine - INFO - Iter(train) [ 60950/160000]  base_lr: 6.4948e-05 lr: 6.4948e-06  eta: 11:19:10  time: 0.4181  data_time: 0.0097  memory: 5970  grad_norm: 608.5567  loss: 21.5916  decode.loss_cls: 0.2212  decode.loss_mask: 1.0971  decode.loss_dice: 0.7912  decode.d0.loss_cls: 0.7648  decode.d0.loss_mask: 1.1204  decode.d0.loss_dice: 0.7807  decode.d1.loss_cls: 0.1989  decode.d1.loss_mask: 1.0720  decode.d1.loss_dice: 0.7807  decode.d2.loss_cls: 0.2294  decode.d2.loss_mask: 1.1091  decode.d2.loss_dice: 0.7912  decode.d3.loss_cls: 0.2153  decode.d3.loss_mask: 1.1002  decode.d3.loss_dice: 0.7948  decode.d4.loss_cls: 0.2133  decode.d4.loss_mask: 1.0960  decode.d4.loss_dice: 0.7952  decode.d5.loss_cls: 0.2016  decode.d5.loss_mask: 1.0976  decode.d5.loss_dice: 0.7954  decode.d6.loss_cls: 0.2219  decode.d6.loss_mask: 1.0758  decode.d6.loss_dice: 0.7749  decode.d7.loss_cls: 0.2201  decode.d7.loss_mask: 1.0908  decode.d7.loss_dice: 0.7900  decode.d8.loss_cls: 0.2263  decode.d8.loss_mask: 1.1148  decode.d8.loss_dice: 0.8111
05/26 18:07:25 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 18:07:25 - mmengine - INFO - Iter(train) [ 61000/160000]  base_lr: 6.4918e-05 lr: 6.4918e-06  eta: 11:18:50  time: 0.4193  data_time: 0.0097  memory: 5972  grad_norm: 368.0880  loss: 18.5135  decode.loss_cls: 0.2380  decode.loss_mask: 0.8989  decode.loss_dice: 0.7180  decode.d0.loss_cls: 0.5607  decode.d0.loss_mask: 0.9136  decode.d0.loss_dice: 0.7096  decode.d1.loss_cls: 0.1840  decode.d1.loss_mask: 0.9213  decode.d1.loss_dice: 0.7182  decode.d2.loss_cls: 0.2394  decode.d2.loss_mask: 0.9119  decode.d2.loss_dice: 0.6755  decode.d3.loss_cls: 0.2028  decode.d3.loss_mask: 0.9314  decode.d3.loss_dice: 0.6914  decode.d4.loss_cls: 0.2001  decode.d4.loss_mask: 0.8907  decode.d4.loss_dice: 0.6774  decode.d5.loss_cls: 0.2037  decode.d5.loss_mask: 0.8845  decode.d5.loss_dice: 0.6675  decode.d6.loss_cls: 0.1820  decode.d6.loss_mask: 0.9318  decode.d6.loss_dice: 0.7173  decode.d7.loss_cls: 0.2441  decode.d7.loss_mask: 0.8796  decode.d7.loss_dice: 0.6780  decode.d8.loss_cls: 0.2175  decode.d8.loss_mask: 0.9071  decode.d8.loss_dice: 0.7174
05/26 18:07:46 - mmengine - INFO - Iter(train) [ 61050/160000]  base_lr: 6.4889e-05 lr: 6.4889e-06  eta: 11:18:30  time: 0.4170  data_time: 0.0098  memory: 5982  grad_norm: 714.8829  loss: 20.9751  decode.loss_cls: 0.1880  decode.loss_mask: 1.0372  decode.loss_dice: 0.7867  decode.d0.loss_cls: 0.7775  decode.d0.loss_mask: 1.0299  decode.d0.loss_dice: 0.7708  decode.d1.loss_cls: 0.1876  decode.d1.loss_mask: 1.0853  decode.d1.loss_dice: 0.8199  decode.d2.loss_cls: 0.1751  decode.d2.loss_mask: 1.0585  decode.d2.loss_dice: 0.8088  decode.d3.loss_cls: 0.1659  decode.d3.loss_mask: 1.0416  decode.d3.loss_dice: 0.7935  decode.d4.loss_cls: 0.1808  decode.d4.loss_mask: 1.0632  decode.d4.loss_dice: 0.8088  decode.d5.loss_cls: 0.1814  decode.d5.loss_mask: 1.0525  decode.d5.loss_dice: 0.8023  decode.d6.loss_cls: 0.2073  decode.d6.loss_mask: 1.0682  decode.d6.loss_dice: 0.7970  decode.d7.loss_cls: 0.1825  decode.d7.loss_mask: 1.0668  decode.d7.loss_dice: 0.7857  decode.d8.loss_cls: 0.1878  decode.d8.loss_mask: 1.0689  decode.d8.loss_dice: 0.7955
05/26 18:08:07 - mmengine - INFO - Iter(train) [ 61100/160000]  base_lr: 6.4859e-05 lr: 6.4859e-06  eta: 11:18:10  time: 0.4189  data_time: 0.0098  memory: 5967  grad_norm: 646.4984  loss: 24.6343  decode.loss_cls: 0.1975  decode.loss_mask: 1.2283  decode.loss_dice: 0.9535  decode.d0.loss_cls: 0.6662  decode.d0.loss_mask: 1.1966  decode.d0.loss_dice: 0.9602  decode.d1.loss_cls: 0.2715  decode.d1.loss_mask: 1.1819  decode.d1.loss_dice: 0.9510  decode.d2.loss_cls: 0.2798  decode.d2.loss_mask: 1.2104  decode.d2.loss_dice: 0.9297  decode.d3.loss_cls: 0.3213  decode.d3.loss_mask: 1.2086  decode.d3.loss_dice: 0.9398  decode.d4.loss_cls: 0.2461  decode.d4.loss_mask: 1.2563  decode.d4.loss_dice: 0.9669  decode.d5.loss_cls: 0.2323  decode.d5.loss_mask: 1.2387  decode.d5.loss_dice: 0.9472  decode.d6.loss_cls: 0.2999  decode.d6.loss_mask: 1.2175  decode.d6.loss_dice: 0.9279  decode.d7.loss_cls: 0.2369  decode.d7.loss_mask: 1.2260  decode.d7.loss_dice: 0.9577  decode.d8.loss_cls: 0.2295  decode.d8.loss_mask: 1.2173  decode.d8.loss_dice: 0.9379
05/26 18:08:28 - mmengine - INFO - Iter(train) [ 61150/160000]  base_lr: 6.4830e-05 lr: 6.4830e-06  eta: 11:17:50  time: 0.4212  data_time: 0.0102  memory: 5980  grad_norm: 703.4596  loss: 23.8451  decode.loss_cls: 0.2980  decode.loss_mask: 1.0885  decode.loss_dice: 0.8762  decode.d0.loss_cls: 0.8184  decode.d0.loss_mask: 1.0765  decode.d0.loss_dice: 0.8816  decode.d1.loss_cls: 0.3140  decode.d1.loss_mask: 1.1069  decode.d1.loss_dice: 0.9034  decode.d2.loss_cls: 0.3694  decode.d2.loss_mask: 1.0885  decode.d2.loss_dice: 0.8865  decode.d3.loss_cls: 0.3586  decode.d3.loss_mask: 1.0976  decode.d3.loss_dice: 0.8874  decode.d4.loss_cls: 0.3144  decode.d4.loss_mask: 1.1249  decode.d4.loss_dice: 0.8699  decode.d5.loss_cls: 0.3046  decode.d5.loss_mask: 1.1884  decode.d5.loss_dice: 0.9274  decode.d6.loss_cls: 0.3390  decode.d6.loss_mask: 1.1288  decode.d6.loss_dice: 0.9268  decode.d7.loss_cls: 0.3390  decode.d7.loss_mask: 1.0926  decode.d7.loss_dice: 0.8830  decode.d8.loss_cls: 0.3606  decode.d8.loss_mask: 1.1153  decode.d8.loss_dice: 0.8791
05/26 18:08:49 - mmengine - INFO - Iter(train) [ 61200/160000]  base_lr: 6.4800e-05 lr: 6.4800e-06  eta: 11:17:30  time: 0.4200  data_time: 0.0101  memory: 5970  grad_norm: 1093.2937  loss: 26.3109  decode.loss_cls: 0.3102  decode.loss_mask: 1.2506  decode.loss_dice: 0.9224  decode.d0.loss_cls: 0.7670  decode.d0.loss_mask: 1.2756  decode.d0.loss_dice: 0.8918  decode.d1.loss_cls: 0.3209  decode.d1.loss_mask: 1.3394  decode.d1.loss_dice: 0.9211  decode.d2.loss_cls: 0.3277  decode.d2.loss_mask: 1.3379  decode.d2.loss_dice: 0.9475  decode.d3.loss_cls: 0.2729  decode.d3.loss_mask: 1.3865  decode.d3.loss_dice: 1.0070  decode.d4.loss_cls: 0.2565  decode.d4.loss_mask: 1.4267  decode.d4.loss_dice: 0.9957  decode.d5.loss_cls: 0.3249  decode.d5.loss_mask: 1.3236  decode.d5.loss_dice: 0.9392  decode.d6.loss_cls: 0.2848  decode.d6.loss_mask: 1.3755  decode.d6.loss_dice: 0.9793  decode.d7.loss_cls: 0.2972  decode.d7.loss_mask: 1.3185  decode.d7.loss_dice: 0.9750  decode.d8.loss_cls: 0.3224  decode.d8.loss_mask: 1.2859  decode.d8.loss_dice: 0.9272
05/26 18:09:10 - mmengine - INFO - Iter(train) [ 61250/160000]  base_lr: 6.4771e-05 lr: 6.4771e-06  eta: 11:17:10  time: 0.4222  data_time: 0.0101  memory: 5968  grad_norm: 1037.7818  loss: 24.6432  decode.loss_cls: 0.2481  decode.loss_mask: 1.3030  decode.loss_dice: 0.8962  decode.d0.loss_cls: 0.6994  decode.d0.loss_mask: 1.1287  decode.d0.loss_dice: 0.8421  decode.d1.loss_cls: 0.2280  decode.d1.loss_mask: 1.2552  decode.d1.loss_dice: 0.9198  decode.d2.loss_cls: 0.2405  decode.d2.loss_mask: 1.3119  decode.d2.loss_dice: 0.8794  decode.d3.loss_cls: 0.2712  decode.d3.loss_mask: 1.3144  decode.d3.loss_dice: 0.8926  decode.d4.loss_cls: 0.2458  decode.d4.loss_mask: 1.2529  decode.d4.loss_dice: 0.8984  decode.d5.loss_cls: 0.2340  decode.d5.loss_mask: 1.3265  decode.d5.loss_dice: 0.9567  decode.d6.loss_cls: 0.1926  decode.d6.loss_mask: 1.3344  decode.d6.loss_dice: 0.9187  decode.d7.loss_cls: 0.3053  decode.d7.loss_mask: 1.1895  decode.d7.loss_dice: 0.8875  decode.d8.loss_cls: 0.2990  decode.d8.loss_mask: 1.2489  decode.d8.loss_dice: 0.9223
05/26 18:09:31 - mmengine - INFO - Iter(train) [ 61300/160000]  base_lr: 6.4741e-05 lr: 6.4741e-06  eta: 11:16:50  time: 0.4142  data_time: 0.0098  memory: 5969  grad_norm: 828.2544  loss: 25.2323  decode.loss_cls: 0.4239  decode.loss_mask: 1.1408  decode.loss_dice: 0.8853  decode.d0.loss_cls: 0.9482  decode.d0.loss_mask: 1.1341  decode.d0.loss_dice: 0.8655  decode.d1.loss_cls: 0.3248  decode.d1.loss_mask: 1.2019  decode.d1.loss_dice: 0.8881  decode.d2.loss_cls: 0.3144  decode.d2.loss_mask: 1.2797  decode.d2.loss_dice: 0.9183  decode.d3.loss_cls: 0.2945  decode.d3.loss_mask: 1.2503  decode.d3.loss_dice: 0.9165  decode.d4.loss_cls: 0.3445  decode.d4.loss_mask: 1.2221  decode.d4.loss_dice: 0.8983  decode.d5.loss_cls: 0.3841  decode.d5.loss_mask: 1.1889  decode.d5.loss_dice: 0.8992  decode.d6.loss_cls: 0.3435  decode.d6.loss_mask: 1.2491  decode.d6.loss_dice: 0.9207  decode.d7.loss_cls: 0.4114  decode.d7.loss_mask: 1.1924  decode.d7.loss_dice: 0.9393  decode.d8.loss_cls: 0.4157  decode.d8.loss_mask: 1.1679  decode.d8.loss_dice: 0.8691
05/26 18:09:52 - mmengine - INFO - Iter(train) [ 61350/160000]  base_lr: 6.4712e-05 lr: 6.4712e-06  eta: 11:16:30  time: 0.4160  data_time: 0.0100  memory: 5972  grad_norm: 617.2588  loss: 28.4813  decode.loss_cls: 0.4511  decode.loss_mask: 1.3720  decode.loss_dice: 0.9955  decode.d0.loss_cls: 0.9658  decode.d0.loss_mask: 1.3240  decode.d0.loss_dice: 0.9971  decode.d1.loss_cls: 0.4047  decode.d1.loss_mask: 1.3669  decode.d1.loss_dice: 0.9639  decode.d2.loss_cls: 0.4580  decode.d2.loss_mask: 1.3749  decode.d2.loss_dice: 0.9597  decode.d3.loss_cls: 0.4441  decode.d3.loss_mask: 1.3409  decode.d3.loss_dice: 0.9635  decode.d4.loss_cls: 0.5032  decode.d4.loss_mask: 1.3709  decode.d4.loss_dice: 0.9625  decode.d5.loss_cls: 0.5151  decode.d5.loss_mask: 1.3553  decode.d5.loss_dice: 0.9627  decode.d6.loss_cls: 0.4873  decode.d6.loss_mask: 1.4034  decode.d6.loss_dice: 0.9660  decode.d7.loss_cls: 0.4626  decode.d7.loss_mask: 1.3522  decode.d7.loss_dice: 0.9673  decode.d8.loss_cls: 0.4802  decode.d8.loss_mask: 1.3426  decode.d8.loss_dice: 0.9676
05/26 18:10:12 - mmengine - INFO - Iter(train) [ 61400/160000]  base_lr: 6.4682e-05 lr: 6.4682e-06  eta: 11:16:10  time: 0.4133  data_time: 0.0095  memory: 5971  grad_norm: 637.1360  loss: 26.8579  decode.loss_cls: 0.2756  decode.loss_mask: 1.3921  decode.loss_dice: 0.9660  decode.d0.loss_cls: 0.7943  decode.d0.loss_mask: 1.3386  decode.d0.loss_dice: 0.9096  decode.d1.loss_cls: 0.2254  decode.d1.loss_mask: 1.3838  decode.d1.loss_dice: 0.9543  decode.d2.loss_cls: 0.2520  decode.d2.loss_mask: 1.4512  decode.d2.loss_dice: 0.9652  decode.d3.loss_cls: 0.2012  decode.d3.loss_mask: 1.4830  decode.d3.loss_dice: 0.9554  decode.d4.loss_cls: 0.2276  decode.d4.loss_mask: 1.4815  decode.d4.loss_dice: 0.9672  decode.d5.loss_cls: 0.2553  decode.d5.loss_mask: 1.3693  decode.d5.loss_dice: 0.9674  decode.d6.loss_cls: 0.3098  decode.d6.loss_mask: 1.4281  decode.d6.loss_dice: 0.9749  decode.d7.loss_cls: 0.3030  decode.d7.loss_mask: 1.4524  decode.d7.loss_dice: 0.9629  decode.d8.loss_cls: 0.2862  decode.d8.loss_mask: 1.3794  decode.d8.loss_dice: 0.9451
05/26 18:10:33 - mmengine - INFO - Iter(train) [ 61450/160000]  base_lr: 6.4653e-05 lr: 6.4653e-06  eta: 11:15:49  time: 0.4127  data_time: 0.0096  memory: 5967  grad_norm: 788.9238  loss: 25.6518  decode.loss_cls: 0.2859  decode.loss_mask: 1.2719  decode.loss_dice: 0.9190  decode.d0.loss_cls: 0.7660  decode.d0.loss_mask: 1.2450  decode.d0.loss_dice: 0.9321  decode.d1.loss_cls: 0.2818  decode.d1.loss_mask: 1.3293  decode.d1.loss_dice: 0.9361  decode.d2.loss_cls: 0.2889  decode.d2.loss_mask: 1.2586  decode.d2.loss_dice: 0.9126  decode.d3.loss_cls: 0.2730  decode.d3.loss_mask: 1.2838  decode.d3.loss_dice: 0.9056  decode.d4.loss_cls: 0.2896  decode.d4.loss_mask: 1.3187  decode.d4.loss_dice: 0.9337  decode.d5.loss_cls: 0.3060  decode.d5.loss_mask: 1.3129  decode.d5.loss_dice: 0.9391  decode.d6.loss_cls: 0.3099  decode.d6.loss_mask: 1.2983  decode.d6.loss_dice: 0.9177  decode.d7.loss_cls: 0.2778  decode.d7.loss_mask: 1.4048  decode.d7.loss_dice: 0.9492  decode.d8.loss_cls: 0.2845  decode.d8.loss_mask: 1.2931  decode.d8.loss_dice: 0.9269
05/26 18:10:54 - mmengine - INFO - Iter(train) [ 61500/160000]  base_lr: 6.4623e-05 lr: 6.4623e-06  eta: 11:15:29  time: 0.4147  data_time: 0.0097  memory: 5967  grad_norm: 411.8340  loss: 18.7213  decode.loss_cls: 0.0927  decode.loss_mask: 1.0434  decode.loss_dice: 0.6520  decode.d0.loss_cls: 0.5724  decode.d0.loss_mask: 1.0261  decode.d0.loss_dice: 0.6615  decode.d1.loss_cls: 0.0746  decode.d1.loss_mask: 1.0803  decode.d1.loss_dice: 0.6900  decode.d2.loss_cls: 0.0822  decode.d2.loss_mask: 1.0582  decode.d2.loss_dice: 0.6695  decode.d3.loss_cls: 0.0748  decode.d3.loss_mask: 1.1063  decode.d3.loss_dice: 0.6838  decode.d4.loss_cls: 0.1096  decode.d4.loss_mask: 1.0345  decode.d4.loss_dice: 0.6692  decode.d5.loss_cls: 0.1127  decode.d5.loss_mask: 1.0584  decode.d5.loss_dice: 0.6700  decode.d6.loss_cls: 0.1497  decode.d6.loss_mask: 1.0207  decode.d6.loss_dice: 0.6743  decode.d7.loss_cls: 0.0989  decode.d7.loss_mask: 1.0515  decode.d7.loss_dice: 0.6796  decode.d8.loss_cls: 0.0967  decode.d8.loss_mask: 1.0631  decode.d8.loss_dice: 0.6648
05/26 18:11:14 - mmengine - INFO - Iter(train) [ 61550/160000]  base_lr: 6.4593e-05 lr: 6.4593e-06  eta: 11:15:09  time: 0.4137  data_time: 0.0097  memory: 5967  grad_norm: 725.2762  loss: 22.6565  decode.loss_cls: 0.1682  decode.loss_mask: 1.1847  decode.loss_dice: 0.8632  decode.d0.loss_cls: 0.7306  decode.d0.loss_mask: 1.0958  decode.d0.loss_dice: 0.7865  decode.d1.loss_cls: 0.1954  decode.d1.loss_mask: 1.1537  decode.d1.loss_dice: 0.8795  decode.d2.loss_cls: 0.1935  decode.d2.loss_mask: 1.1855  decode.d2.loss_dice: 0.8794  decode.d3.loss_cls: 0.1909  decode.d3.loss_mask: 1.1696  decode.d3.loss_dice: 0.8548  decode.d4.loss_cls: 0.1645  decode.d4.loss_mask: 1.1913  decode.d4.loss_dice: 0.9021  decode.d5.loss_cls: 0.1837  decode.d5.loss_mask: 1.1771  decode.d5.loss_dice: 0.8879  decode.d6.loss_cls: 0.1758  decode.d6.loss_mask: 1.1801  decode.d6.loss_dice: 0.9048  decode.d7.loss_cls: 0.1838  decode.d7.loss_mask: 1.1393  decode.d7.loss_dice: 0.8579  decode.d8.loss_cls: 0.1803  decode.d8.loss_mask: 1.1536  decode.d8.loss_dice: 0.8426
05/26 18:11:35 - mmengine - INFO - Iter(train) [ 61600/160000]  base_lr: 6.4564e-05 lr: 6.4564e-06  eta: 11:14:48  time: 0.4171  data_time: 0.0097  memory: 5967  grad_norm: 345.6226  loss: 19.5543  decode.loss_cls: 0.1919  decode.loss_mask: 0.9438  decode.loss_dice: 0.7558  decode.d0.loss_cls: 0.6585  decode.d0.loss_mask: 0.9268  decode.d0.loss_dice: 0.7896  decode.d1.loss_cls: 0.1996  decode.d1.loss_mask: 0.9489  decode.d1.loss_dice: 0.7725  decode.d2.loss_cls: 0.1822  decode.d2.loss_mask: 0.9317  decode.d2.loss_dice: 0.7873  decode.d3.loss_cls: 0.2097  decode.d3.loss_mask: 0.9199  decode.d3.loss_dice: 0.7573  decode.d4.loss_cls: 0.1996  decode.d4.loss_mask: 0.9329  decode.d4.loss_dice: 0.7891  decode.d5.loss_cls: 0.2081  decode.d5.loss_mask: 0.9513  decode.d5.loss_dice: 0.7874  decode.d6.loss_cls: 0.1882  decode.d6.loss_mask: 0.9442  decode.d6.loss_dice: 0.7889  decode.d7.loss_cls: 0.1663  decode.d7.loss_mask: 0.9457  decode.d7.loss_dice: 0.7681  decode.d8.loss_cls: 0.1880  decode.d8.loss_mask: 0.9413  decode.d8.loss_dice: 0.7799
05/26 18:11:56 - mmengine - INFO - Iter(train) [ 61650/160000]  base_lr: 6.4534e-05 lr: 6.4534e-06  eta: 11:14:28  time: 0.4161  data_time: 0.0097  memory: 5968  grad_norm: 629.3170  loss: 21.1705  decode.loss_cls: 0.2588  decode.loss_mask: 1.1347  decode.loss_dice: 0.6938  decode.d0.loss_cls: 0.6656  decode.d0.loss_mask: 1.0677  decode.d0.loss_dice: 0.6638  decode.d1.loss_cls: 0.3099  decode.d1.loss_mask: 1.1189  decode.d1.loss_dice: 0.6948  decode.d2.loss_cls: 0.3089  decode.d2.loss_mask: 1.0984  decode.d2.loss_dice: 0.6732  decode.d3.loss_cls: 0.3096  decode.d3.loss_mask: 1.0923  decode.d3.loss_dice: 0.6681  decode.d4.loss_cls: 0.3064  decode.d4.loss_mask: 1.0984  decode.d4.loss_dice: 0.6841  decode.d5.loss_cls: 0.3064  decode.d5.loss_mask: 1.1040  decode.d5.loss_dice: 0.6677  decode.d6.loss_cls: 0.2407  decode.d6.loss_mask: 1.1393  decode.d6.loss_dice: 0.6809  decode.d7.loss_cls: 0.2724  decode.d7.loss_mask: 1.1554  decode.d7.loss_dice: 0.6741  decode.d8.loss_cls: 0.2664  decode.d8.loss_mask: 1.1379  decode.d8.loss_dice: 0.6778
05/26 18:12:17 - mmengine - INFO - Iter(train) [ 61700/160000]  base_lr: 6.4505e-05 lr: 6.4505e-06  eta: 11:14:08  time: 0.4150  data_time: 0.0096  memory: 5966  grad_norm: 582.5773  loss: 20.5989  decode.loss_cls: 0.1409  decode.loss_mask: 1.1146  decode.loss_dice: 0.7460  decode.d0.loss_cls: 0.6553  decode.d0.loss_mask: 1.0480  decode.d0.loss_dice: 0.6976  decode.d1.loss_cls: 0.1584  decode.d1.loss_mask: 1.1211  decode.d1.loss_dice: 0.7699  decode.d2.loss_cls: 0.1602  decode.d2.loss_mask: 1.1157  decode.d2.loss_dice: 0.7504  decode.d3.loss_cls: 0.1483  decode.d3.loss_mask: 1.1341  decode.d3.loss_dice: 0.7638  decode.d4.loss_cls: 0.1397  decode.d4.loss_mask: 1.1310  decode.d4.loss_dice: 0.7519  decode.d5.loss_cls: 0.1543  decode.d5.loss_mask: 1.0982  decode.d5.loss_dice: 0.7229  decode.d6.loss_cls: 0.1389  decode.d6.loss_mask: 1.1298  decode.d6.loss_dice: 0.7520  decode.d7.loss_cls: 0.1425  decode.d7.loss_mask: 1.1433  decode.d7.loss_dice: 0.7519  decode.d8.loss_cls: 0.1403  decode.d8.loss_mask: 1.1367  decode.d8.loss_dice: 0.7412
05/26 18:12:38 - mmengine - INFO - Iter(train) [ 61750/160000]  base_lr: 6.4475e-05 lr: 6.4475e-06  eta: 11:13:48  time: 0.4185  data_time: 0.0098  memory: 5976  grad_norm: 686.6093  loss: 26.9319  decode.loss_cls: 0.3235  decode.loss_mask: 1.3559  decode.loss_dice: 0.9365  decode.d0.loss_cls: 0.9003  decode.d0.loss_mask: 1.2077  decode.d0.loss_dice: 0.8952  decode.d1.loss_cls: 0.2546  decode.d1.loss_mask: 1.4680  decode.d1.loss_dice: 0.9887  decode.d2.loss_cls: 0.2965  decode.d2.loss_mask: 1.3851  decode.d2.loss_dice: 0.9896  decode.d3.loss_cls: 0.3180  decode.d3.loss_mask: 1.3344  decode.d3.loss_dice: 0.9374  decode.d4.loss_cls: 0.2997  decode.d4.loss_mask: 1.3765  decode.d4.loss_dice: 0.9782  decode.d5.loss_cls: 0.3504  decode.d5.loss_mask: 1.3701  decode.d5.loss_dice: 0.9619  decode.d6.loss_cls: 0.3636  decode.d6.loss_mask: 1.3248  decode.d6.loss_dice: 0.9508  decode.d7.loss_cls: 0.3225  decode.d7.loss_mask: 1.4069  decode.d7.loss_dice: 0.9978  decode.d8.loss_cls: 0.2956  decode.d8.loss_mask: 1.4061  decode.d8.loss_dice: 0.9355
05/26 18:12:58 - mmengine - INFO - Iter(train) [ 61800/160000]  base_lr: 6.4446e-05 lr: 6.4446e-06  eta: 11:13:27  time: 0.4132  data_time: 0.0096  memory: 5966  grad_norm: 803.3651  loss: 22.7020  decode.loss_cls: 0.3015  decode.loss_mask: 1.1477  decode.loss_dice: 0.7985  decode.d0.loss_cls: 0.6955  decode.d0.loss_mask: 1.1680  decode.d0.loss_dice: 0.8472  decode.d1.loss_cls: 0.2668  decode.d1.loss_mask: 1.1489  decode.d1.loss_dice: 0.7873  decode.d2.loss_cls: 0.3012  decode.d2.loss_mask: 1.1350  decode.d2.loss_dice: 0.7841  decode.d3.loss_cls: 0.2740  decode.d3.loss_mask: 1.1911  decode.d3.loss_dice: 0.8148  decode.d4.loss_cls: 0.2773  decode.d4.loss_mask: 1.1319  decode.d4.loss_dice: 0.7626  decode.d5.loss_cls: 0.3045  decode.d5.loss_mask: 1.1501  decode.d5.loss_dice: 0.7894  decode.d6.loss_cls: 0.2987  decode.d6.loss_mask: 1.1382  decode.d6.loss_dice: 0.7804  decode.d7.loss_cls: 0.3006  decode.d7.loss_mask: 1.1139  decode.d7.loss_dice: 0.7622  decode.d8.loss_cls: 0.2892  decode.d8.loss_mask: 1.1551  decode.d8.loss_dice: 0.7863
05/26 18:13:19 - mmengine - INFO - Iter(train) [ 61850/160000]  base_lr: 6.4416e-05 lr: 6.4416e-06  eta: 11:13:07  time: 0.4134  data_time: 0.0096  memory: 5968  grad_norm: 425.5175  loss: 20.7242  decode.loss_cls: 0.1825  decode.loss_mask: 1.0714  decode.loss_dice: 0.7683  decode.d0.loss_cls: 0.6623  decode.d0.loss_mask: 0.9582  decode.d0.loss_dice: 0.7482  decode.d1.loss_cls: 0.1923  decode.d1.loss_mask: 1.0354  decode.d1.loss_dice: 0.8071  decode.d2.loss_cls: 0.2443  decode.d2.loss_mask: 1.0275  decode.d2.loss_dice: 0.7703  decode.d3.loss_cls: 0.2408  decode.d3.loss_mask: 1.0448  decode.d3.loss_dice: 0.7790  decode.d4.loss_cls: 0.1917  decode.d4.loss_mask: 1.0928  decode.d4.loss_dice: 0.8000  decode.d5.loss_cls: 0.2011  decode.d5.loss_mask: 1.0462  decode.d5.loss_dice: 0.7802  decode.d6.loss_cls: 0.2061  decode.d6.loss_mask: 1.0971  decode.d6.loss_dice: 0.7776  decode.d7.loss_cls: 0.2103  decode.d7.loss_mask: 1.0317  decode.d7.loss_dice: 0.7582  decode.d8.loss_cls: 0.1677  decode.d8.loss_mask: 1.0525  decode.d8.loss_dice: 0.7783
05/26 18:13:40 - mmengine - INFO - Iter(train) [ 61900/160000]  base_lr: 6.4387e-05 lr: 6.4387e-06  eta: 11:12:47  time: 0.4144  data_time: 0.0096  memory: 5975  grad_norm: 1202.4806  loss: 25.0722  decode.loss_cls: 0.3246  decode.loss_mask: 1.2228  decode.loss_dice: 0.8636  decode.d0.loss_cls: 0.7935  decode.d0.loss_mask: 1.1031  decode.d0.loss_dice: 0.8031  decode.d1.loss_cls: 0.3587  decode.d1.loss_mask: 1.2338  decode.d1.loss_dice: 0.8688  decode.d2.loss_cls: 0.3171  decode.d2.loss_mask: 1.2912  decode.d2.loss_dice: 0.8768  decode.d3.loss_cls: 0.3401  decode.d3.loss_mask: 1.2991  decode.d3.loss_dice: 0.8708  decode.d4.loss_cls: 0.3673  decode.d4.loss_mask: 1.2412  decode.d4.loss_dice: 0.8692  decode.d5.loss_cls: 0.4170  decode.d5.loss_mask: 1.1936  decode.d5.loss_dice: 0.8259  decode.d6.loss_cls: 0.3591  decode.d6.loss_mask: 1.3523  decode.d6.loss_dice: 0.8970  decode.d7.loss_cls: 0.3473  decode.d7.loss_mask: 1.2690  decode.d7.loss_dice: 0.8926  decode.d8.loss_cls: 0.3462  decode.d8.loss_mask: 1.2349  decode.d8.loss_dice: 0.8924
05/26 18:14:00 - mmengine - INFO - Iter(train) [ 61950/160000]  base_lr: 6.4357e-05 lr: 6.4357e-06  eta: 11:12:26  time: 0.4151  data_time: 0.0097  memory: 5969  grad_norm: 489.9768  loss: 17.2104  decode.loss_cls: 0.1667  decode.loss_mask: 0.8134  decode.loss_dice: 0.6944  decode.d0.loss_cls: 0.6165  decode.d0.loss_mask: 0.7698  decode.d0.loss_dice: 0.6841  decode.d1.loss_cls: 0.2228  decode.d1.loss_mask: 0.7971  decode.d1.loss_dice: 0.7075  decode.d2.loss_cls: 0.1867  decode.d2.loss_mask: 0.7815  decode.d2.loss_dice: 0.6753  decode.d3.loss_cls: 0.2479  decode.d3.loss_mask: 0.7638  decode.d3.loss_dice: 0.6553  decode.d4.loss_cls: 0.2262  decode.d4.loss_mask: 0.7680  decode.d4.loss_dice: 0.6975  decode.d5.loss_cls: 0.2172  decode.d5.loss_mask: 0.7901  decode.d5.loss_dice: 0.6749  decode.d6.loss_cls: 0.1957  decode.d6.loss_mask: 0.8420  decode.d6.loss_dice: 0.7082  decode.d7.loss_cls: 0.2151  decode.d7.loss_mask: 0.7864  decode.d7.loss_dice: 0.6800  decode.d8.loss_cls: 0.1885  decode.d8.loss_mask: 0.7715  decode.d8.loss_dice: 0.6663
05/26 18:14:21 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 18:14:21 - mmengine - INFO - Iter(train) [ 62000/160000]  base_lr: 6.4328e-05 lr: 6.4328e-06  eta: 11:12:06  time: 0.4132  data_time: 0.0096  memory: 5968  grad_norm: 1014.4092  loss: 28.0663  decode.loss_cls: 0.2420  decode.loss_mask: 1.5917  decode.loss_dice: 0.9530  decode.d0.loss_cls: 0.7654  decode.d0.loss_mask: 1.3303  decode.d0.loss_dice: 0.9197  decode.d1.loss_cls: 0.2736  decode.d1.loss_mask: 1.5694  decode.d1.loss_dice: 0.9551  decode.d2.loss_cls: 0.2356  decode.d2.loss_mask: 1.5421  decode.d2.loss_dice: 0.9420  decode.d3.loss_cls: 0.3162  decode.d3.loss_mask: 1.5314  decode.d3.loss_dice: 0.9346  decode.d4.loss_cls: 0.3340  decode.d4.loss_mask: 1.5297  decode.d4.loss_dice: 0.9194  decode.d5.loss_cls: 0.3229  decode.d5.loss_mask: 1.5574  decode.d5.loss_dice: 0.9280  decode.d6.loss_cls: 0.2838  decode.d6.loss_mask: 1.5551  decode.d6.loss_dice: 0.9488  decode.d7.loss_cls: 0.2242  decode.d7.loss_mask: 1.6252  decode.d7.loss_dice: 0.9982  decode.d8.loss_cls: 0.2465  decode.d8.loss_mask: 1.5628  decode.d8.loss_dice: 0.9284
05/26 18:14:42 - mmengine - INFO - Iter(train) [ 62050/160000]  base_lr: 6.4298e-05 lr: 6.4298e-06  eta: 11:11:45  time: 0.4122  data_time: 0.0095  memory: 5971  grad_norm: 520.4013  loss: 23.7294  decode.loss_cls: 0.2349  decode.loss_mask: 1.1459  decode.loss_dice: 0.9125  decode.d0.loss_cls: 0.7974  decode.d0.loss_mask: 1.0985  decode.d0.loss_dice: 0.9239  decode.d1.loss_cls: 0.2551  decode.d1.loss_mask: 1.1436  decode.d1.loss_dice: 0.9221  decode.d2.loss_cls: 0.2527  decode.d2.loss_mask: 1.1363  decode.d2.loss_dice: 0.8969  decode.d3.loss_cls: 0.2632  decode.d3.loss_mask: 1.1283  decode.d3.loss_dice: 0.9000  decode.d4.loss_cls: 0.2450  decode.d4.loss_mask: 1.1213  decode.d4.loss_dice: 0.8977  decode.d5.loss_cls: 0.2830  decode.d5.loss_mask: 1.2409  decode.d5.loss_dice: 0.9305  decode.d6.loss_cls: 0.3064  decode.d6.loss_mask: 1.1452  decode.d6.loss_dice: 0.9349  decode.d7.loss_cls: 0.2617  decode.d7.loss_mask: 1.1550  decode.d7.loss_dice: 0.8984  decode.d8.loss_cls: 0.2853  decode.d8.loss_mask: 1.1086  decode.d8.loss_dice: 0.9040
05/26 18:15:03 - mmengine - INFO - Iter(train) [ 62100/160000]  base_lr: 6.4269e-05 lr: 6.4269e-06  eta: 11:11:25  time: 0.4232  data_time: 0.0096  memory: 5971  grad_norm: 2013.5506  loss: 21.4299  decode.loss_cls: 0.2746  decode.loss_mask: 0.9795  decode.loss_dice: 0.7757  decode.d0.loss_cls: 0.7194  decode.d0.loss_mask: 0.9891  decode.d0.loss_dice: 0.7400  decode.d1.loss_cls: 0.3083  decode.d1.loss_mask: 1.0051  decode.d1.loss_dice: 0.7928  decode.d2.loss_cls: 0.3336  decode.d2.loss_mask: 1.0128  decode.d2.loss_dice: 0.7998  decode.d3.loss_cls: 0.2973  decode.d3.loss_mask: 0.9919  decode.d3.loss_dice: 0.8116  decode.d4.loss_cls: 0.3477  decode.d4.loss_mask: 0.9720  decode.d4.loss_dice: 0.7885  decode.d5.loss_cls: 0.3124  decode.d5.loss_mask: 0.9753  decode.d5.loss_dice: 0.8254  decode.d6.loss_cls: 0.3247  decode.d6.loss_mask: 0.9782  decode.d6.loss_dice: 0.8127  decode.d7.loss_cls: 0.3561  decode.d7.loss_mask: 0.9759  decode.d7.loss_dice: 0.7977  decode.d8.loss_cls: 0.3284  decode.d8.loss_mask: 1.0048  decode.d8.loss_dice: 0.7986
05/26 18:15:23 - mmengine - INFO - Iter(train) [ 62150/160000]  base_lr: 6.4239e-05 lr: 6.4239e-06  eta: 11:11:05  time: 0.4117  data_time: 0.0095  memory: 5972  grad_norm: 993.8160  loss: 25.4355  decode.loss_cls: 0.2050  decode.loss_mask: 1.3566  decode.loss_dice: 0.9657  decode.d0.loss_cls: 0.7869  decode.d0.loss_mask: 1.2188  decode.d0.loss_dice: 0.8648  decode.d1.loss_cls: 0.2616  decode.d1.loss_mask: 1.2590  decode.d1.loss_dice: 0.9410  decode.d2.loss_cls: 0.3057  decode.d2.loss_mask: 1.2439  decode.d2.loss_dice: 0.8931  decode.d3.loss_cls: 0.2436  decode.d3.loss_mask: 1.2815  decode.d3.loss_dice: 0.9594  decode.d4.loss_cls: 0.2578  decode.d4.loss_mask: 1.3069  decode.d4.loss_dice: 0.9837  decode.d5.loss_cls: 0.2390  decode.d5.loss_mask: 1.3180  decode.d5.loss_dice: 0.9684  decode.d6.loss_cls: 0.2282  decode.d6.loss_mask: 1.3061  decode.d6.loss_dice: 0.9825  decode.d7.loss_cls: 0.2802  decode.d7.loss_mask: 1.3373  decode.d7.loss_dice: 0.9577  decode.d8.loss_cls: 0.2240  decode.d8.loss_mask: 1.3314  decode.d8.loss_dice: 0.9281
05/26 18:15:44 - mmengine - INFO - Iter(train) [ 62200/160000]  base_lr: 6.4210e-05 lr: 6.4210e-06  eta: 11:10:44  time: 0.4142  data_time: 0.0095  memory: 5969  grad_norm: 408.9574  loss: 20.5112  decode.loss_cls: 0.1490  decode.loss_mask: 1.0318  decode.loss_dice: 0.7803  decode.d0.loss_cls: 0.7232  decode.d0.loss_mask: 0.9672  decode.d0.loss_dice: 0.7491  decode.d1.loss_cls: 0.2439  decode.d1.loss_mask: 1.0231  decode.d1.loss_dice: 0.7862  decode.d2.loss_cls: 0.1869  decode.d2.loss_mask: 1.0388  decode.d2.loss_dice: 0.7677  decode.d3.loss_cls: 0.1804  decode.d3.loss_mask: 1.0310  decode.d3.loss_dice: 0.7973  decode.d4.loss_cls: 0.2818  decode.d4.loss_mask: 0.9906  decode.d4.loss_dice: 0.7523  decode.d5.loss_cls: 0.2293  decode.d5.loss_mask: 0.9943  decode.d5.loss_dice: 0.7499  decode.d6.loss_cls: 0.2020  decode.d6.loss_mask: 1.0411  decode.d6.loss_dice: 0.7839  decode.d7.loss_cls: 0.2203  decode.d7.loss_mask: 1.0227  decode.d7.loss_dice: 0.7756  decode.d8.loss_cls: 0.2287  decode.d8.loss_mask: 1.0133  decode.d8.loss_dice: 0.7699
05/26 18:16:05 - mmengine - INFO - Iter(train) [ 62250/160000]  base_lr: 6.4180e-05 lr: 6.4180e-06  eta: 11:10:24  time: 0.4124  data_time: 0.0095  memory: 5981  grad_norm: 406.8062  loss: 23.8374  decode.loss_cls: 0.3360  decode.loss_mask: 1.1270  decode.loss_dice: 0.8713  decode.d0.loss_cls: 0.8074  decode.d0.loss_mask: 1.0782  decode.d0.loss_dice: 0.8763  decode.d1.loss_cls: 0.3578  decode.d1.loss_mask: 1.1182  decode.d1.loss_dice: 0.8650  decode.d2.loss_cls: 0.3674  decode.d2.loss_mask: 1.1297  decode.d2.loss_dice: 0.8468  decode.d3.loss_cls: 0.3165  decode.d3.loss_mask: 1.1096  decode.d3.loss_dice: 0.8732  decode.d4.loss_cls: 0.3278  decode.d4.loss_mask: 1.1295  decode.d4.loss_dice: 0.8739  decode.d5.loss_cls: 0.3324  decode.d5.loss_mask: 1.1317  decode.d5.loss_dice: 0.8950  decode.d6.loss_cls: 0.3676  decode.d6.loss_mask: 1.1238  decode.d6.loss_dice: 0.8906  decode.d7.loss_cls: 0.3656  decode.d7.loss_mask: 1.1018  decode.d7.loss_dice: 0.8813  decode.d8.loss_cls: 0.3529  decode.d8.loss_mask: 1.1240  decode.d8.loss_dice: 0.8591
05/26 18:16:25 - mmengine - INFO - Iter(train) [ 62300/160000]  base_lr: 6.4150e-05 lr: 6.4150e-06  eta: 11:10:03  time: 0.4123  data_time: 0.0096  memory: 5972  grad_norm: 698.2748  loss: 22.8680  decode.loss_cls: 0.3449  decode.loss_mask: 1.1466  decode.loss_dice: 0.7573  decode.d0.loss_cls: 0.8004  decode.d0.loss_mask: 1.0454  decode.d0.loss_dice: 0.7100  decode.d1.loss_cls: 0.3704  decode.d1.loss_mask: 1.0959  decode.d1.loss_dice: 0.7131  decode.d2.loss_cls: 0.3076  decode.d2.loss_mask: 1.1658  decode.d2.loss_dice: 0.7483  decode.d3.loss_cls: 0.3120  decode.d3.loss_mask: 1.1099  decode.d3.loss_dice: 0.7232  decode.d4.loss_cls: 0.3246  decode.d4.loss_mask: 1.1837  decode.d4.loss_dice: 0.7369  decode.d5.loss_cls: 0.3383  decode.d5.loss_mask: 1.1946  decode.d5.loss_dice: 0.8052  decode.d6.loss_cls: 0.4120  decode.d6.loss_mask: 1.1484  decode.d6.loss_dice: 0.8077  decode.d7.loss_cls: 0.3425  decode.d7.loss_mask: 1.1736  decode.d7.loss_dice: 0.7874  decode.d8.loss_cls: 0.3093  decode.d8.loss_mask: 1.1730  decode.d8.loss_dice: 0.7796
05/26 18:16:46 - mmengine - INFO - Iter(train) [ 62350/160000]  base_lr: 6.4121e-05 lr: 6.4121e-06  eta: 11:09:43  time: 0.4130  data_time: 0.0095  memory: 5976  grad_norm: 301.5333  loss: 19.5080  decode.loss_cls: 0.2818  decode.loss_mask: 0.9438  decode.loss_dice: 0.7092  decode.d0.loss_cls: 0.6780  decode.d0.loss_mask: 0.9205  decode.d0.loss_dice: 0.6893  decode.d1.loss_cls: 0.3113  decode.d1.loss_mask: 0.9282  decode.d1.loss_dice: 0.6448  decode.d2.loss_cls: 0.3330  decode.d2.loss_mask: 0.9079  decode.d2.loss_dice: 0.6552  decode.d3.loss_cls: 0.2924  decode.d3.loss_mask: 0.9179  decode.d3.loss_dice: 0.6545  decode.d4.loss_cls: 0.2784  decode.d4.loss_mask: 0.9510  decode.d4.loss_dice: 0.7066  decode.d5.loss_cls: 0.3457  decode.d5.loss_mask: 0.9208  decode.d5.loss_dice: 0.6509  decode.d6.loss_cls: 0.2798  decode.d6.loss_mask: 0.9678  decode.d6.loss_dice: 0.7111  decode.d7.loss_cls: 0.2830  decode.d7.loss_mask: 0.9650  decode.d7.loss_dice: 0.7090  decode.d8.loss_cls: 0.2795  decode.d8.loss_mask: 0.9241  decode.d8.loss_dice: 0.6674
05/26 18:17:07 - mmengine - INFO - Iter(train) [ 62400/160000]  base_lr: 6.4091e-05 lr: 6.4091e-06  eta: 11:09:22  time: 0.4136  data_time: 0.0096  memory: 5987  grad_norm: 1317.4979  loss: 20.6154  decode.loss_cls: 0.1893  decode.loss_mask: 1.0125  decode.loss_dice: 0.8014  decode.d0.loss_cls: 0.6862  decode.d0.loss_mask: 1.0427  decode.d0.loss_dice: 0.7218  decode.d1.loss_cls: 0.2392  decode.d1.loss_mask: 1.0462  decode.d1.loss_dice: 0.8082  decode.d2.loss_cls: 0.2122  decode.d2.loss_mask: 1.0110  decode.d2.loss_dice: 0.7702  decode.d3.loss_cls: 0.2447  decode.d3.loss_mask: 1.0229  decode.d3.loss_dice: 0.7538  decode.d4.loss_cls: 0.2660  decode.d4.loss_mask: 1.0321  decode.d4.loss_dice: 0.7800  decode.d5.loss_cls: 0.2177  decode.d5.loss_mask: 1.0406  decode.d5.loss_dice: 0.7374  decode.d6.loss_cls: 0.1903  decode.d6.loss_mask: 1.0218  decode.d6.loss_dice: 0.7767  decode.d7.loss_cls: 0.2042  decode.d7.loss_mask: 1.0014  decode.d7.loss_dice: 0.7693  decode.d8.loss_cls: 0.2379  decode.d8.loss_mask: 1.0144  decode.d8.loss_dice: 0.7632
05/26 18:17:27 - mmengine - INFO - Iter(train) [ 62450/160000]  base_lr: 6.4062e-05 lr: 6.4062e-06  eta: 11:09:02  time: 0.4149  data_time: 0.0097  memory: 5976  grad_norm: 662.6293  loss: 26.3726  decode.loss_cls: 0.2602  decode.loss_mask: 1.3350  decode.loss_dice: 1.0059  decode.d0.loss_cls: 0.6720  decode.d0.loss_mask: 1.2805  decode.d0.loss_dice: 1.0285  decode.d1.loss_cls: 0.2753  decode.d1.loss_mask: 1.3443  decode.d1.loss_dice: 1.0013  decode.d2.loss_cls: 0.2370  decode.d2.loss_mask: 1.3859  decode.d2.loss_dice: 1.0172  decode.d3.loss_cls: 0.2292  decode.d3.loss_mask: 1.3389  decode.d3.loss_dice: 1.0021  decode.d4.loss_cls: 0.2725  decode.d4.loss_mask: 1.3330  decode.d4.loss_dice: 0.9757  decode.d5.loss_cls: 0.2687  decode.d5.loss_mask: 1.3363  decode.d5.loss_dice: 0.9898  decode.d6.loss_cls: 0.2590  decode.d6.loss_mask: 1.3659  decode.d6.loss_dice: 0.9911  decode.d7.loss_cls: 0.2807  decode.d7.loss_mask: 1.3179  decode.d7.loss_dice: 0.9712  decode.d8.loss_cls: 0.2421  decode.d8.loss_mask: 1.3474  decode.d8.loss_dice: 1.0081
05/26 18:17:48 - mmengine - INFO - Iter(train) [ 62500/160000]  base_lr: 6.4032e-05 lr: 6.4032e-06  eta: 11:08:41  time: 0.4129  data_time: 0.0095  memory: 5966  grad_norm: 598.9465  loss: 24.3353  decode.loss_cls: 0.2986  decode.loss_mask: 1.2548  decode.loss_dice: 0.8812  decode.d0.loss_cls: 0.8363  decode.d0.loss_mask: 1.1281  decode.d0.loss_dice: 0.8553  decode.d1.loss_cls: 0.3683  decode.d1.loss_mask: 1.1638  decode.d1.loss_dice: 0.8647  decode.d2.loss_cls: 0.3123  decode.d2.loss_mask: 1.2001  decode.d2.loss_dice: 0.8554  decode.d3.loss_cls: 0.3904  decode.d3.loss_mask: 1.1251  decode.d3.loss_dice: 0.8410  decode.d4.loss_cls: 0.3016  decode.d4.loss_mask: 1.1919  decode.d4.loss_dice: 0.8594  decode.d5.loss_cls: 0.2615  decode.d5.loss_mask: 1.2367  decode.d5.loss_dice: 0.8780  decode.d6.loss_cls: 0.3556  decode.d6.loss_mask: 1.1942  decode.d6.loss_dice: 0.8599  decode.d7.loss_cls: 0.3012  decode.d7.loss_mask: 1.2402  decode.d7.loss_dice: 0.8928  decode.d8.loss_cls: 0.3131  decode.d8.loss_mask: 1.1970  decode.d8.loss_dice: 0.8768
05/26 18:18:08 - mmengine - INFO - Iter(train) [ 62550/160000]  base_lr: 6.4003e-05 lr: 6.4003e-06  eta: 11:08:21  time: 0.4143  data_time: 0.0096  memory: 5970  grad_norm: 551.7486  loss: 25.0503  decode.loss_cls: 0.4164  decode.loss_mask: 1.0743  decode.loss_dice: 0.9230  decode.d0.loss_cls: 0.9964  decode.d0.loss_mask: 1.0630  decode.d0.loss_dice: 0.8536  decode.d1.loss_cls: 0.4814  decode.d1.loss_mask: 1.0556  decode.d1.loss_dice: 0.9277  decode.d2.loss_cls: 0.4885  decode.d2.loss_mask: 1.1059  decode.d2.loss_dice: 0.9506  decode.d3.loss_cls: 0.4138  decode.d3.loss_mask: 1.0869  decode.d3.loss_dice: 0.9050  decode.d4.loss_cls: 0.4314  decode.d4.loss_mask: 1.1397  decode.d4.loss_dice: 0.9703  decode.d5.loss_cls: 0.4383  decode.d5.loss_mask: 1.0478  decode.d5.loss_dice: 0.9093  decode.d6.loss_cls: 0.4193  decode.d6.loss_mask: 1.0962  decode.d6.loss_dice: 0.9738  decode.d7.loss_cls: 0.3947  decode.d7.loss_mask: 1.1088  decode.d7.loss_dice: 0.9742  decode.d8.loss_cls: 0.4472  decode.d8.loss_mask: 1.0433  decode.d8.loss_dice: 0.9140
05/26 18:18:29 - mmengine - INFO - Iter(train) [ 62600/160000]  base_lr: 6.3973e-05 lr: 6.3973e-06  eta: 11:08:01  time: 0.4133  data_time: 0.0096  memory: 5974  grad_norm: 502.7744  loss: 21.6164  decode.loss_cls: 0.2779  decode.loss_mask: 1.0197  decode.loss_dice: 0.8088  decode.d0.loss_cls: 0.7042  decode.d0.loss_mask: 0.9986  decode.d0.loss_dice: 0.8592  decode.d1.loss_cls: 0.3278  decode.d1.loss_mask: 0.9950  decode.d1.loss_dice: 0.8246  decode.d2.loss_cls: 0.2764  decode.d2.loss_mask: 0.9632  decode.d2.loss_dice: 0.8387  decode.d3.loss_cls: 0.2794  decode.d3.loss_mask: 0.9708  decode.d3.loss_dice: 0.7872  decode.d4.loss_cls: 0.2901  decode.d4.loss_mask: 0.9914  decode.d4.loss_dice: 0.8529  decode.d5.loss_cls: 0.3064  decode.d5.loss_mask: 0.9561  decode.d5.loss_dice: 0.8232  decode.d6.loss_cls: 0.2813  decode.d6.loss_mask: 0.9760  decode.d6.loss_dice: 0.8161  decode.d7.loss_cls: 0.3173  decode.d7.loss_mask: 1.0511  decode.d7.loss_dice: 0.8430  decode.d8.loss_cls: 0.3077  decode.d8.loss_mask: 1.0418  decode.d8.loss_dice: 0.8307
05/26 18:18:50 - mmengine - INFO - Iter(train) [ 62650/160000]  base_lr: 6.3944e-05 lr: 6.3944e-06  eta: 11:07:40  time: 0.4143  data_time: 0.0096  memory: 5988  grad_norm: 458.2890  loss: 22.9804  decode.loss_cls: 0.1700  decode.loss_mask: 1.2047  decode.loss_dice: 0.8792  decode.d0.loss_cls: 0.6511  decode.d0.loss_mask: 1.2001  decode.d0.loss_dice: 0.7989  decode.d1.loss_cls: 0.1936  decode.d1.loss_mask: 1.2022  decode.d1.loss_dice: 0.8556  decode.d2.loss_cls: 0.1722  decode.d2.loss_mask: 1.2077  decode.d2.loss_dice: 0.8514  decode.d3.loss_cls: 0.2053  decode.d3.loss_mask: 1.1951  decode.d3.loss_dice: 0.8466  decode.d4.loss_cls: 0.2085  decode.d4.loss_mask: 1.2199  decode.d4.loss_dice: 0.8650  decode.d5.loss_cls: 0.1826  decode.d5.loss_mask: 1.1912  decode.d5.loss_dice: 0.8656  decode.d6.loss_cls: 0.1749  decode.d6.loss_mask: 1.2209  decode.d6.loss_dice: 0.8659  decode.d7.loss_cls: 0.2101  decode.d7.loss_mask: 1.2118  decode.d7.loss_dice: 0.8536  decode.d8.loss_cls: 0.2003  decode.d8.loss_mask: 1.2188  decode.d8.loss_dice: 0.8574
05/26 18:19:11 - mmengine - INFO - Iter(train) [ 62700/160000]  base_lr: 6.3914e-05 lr: 6.3914e-06  eta: 11:07:20  time: 0.4141  data_time: 0.0097  memory: 5981  grad_norm: 1282.5524  loss: 25.1792  decode.loss_cls: 0.2593  decode.loss_mask: 1.2578  decode.loss_dice: 0.9716  decode.d0.loss_cls: 0.7649  decode.d0.loss_mask: 1.2256  decode.d0.loss_dice: 0.9219  decode.d1.loss_cls: 0.1970  decode.d1.loss_mask: 1.2803  decode.d1.loss_dice: 0.9784  decode.d2.loss_cls: 0.1837  decode.d2.loss_mask: 1.2583  decode.d2.loss_dice: 0.9642  decode.d3.loss_cls: 0.2035  decode.d3.loss_mask: 1.3105  decode.d3.loss_dice: 0.9998  decode.d4.loss_cls: 0.2153  decode.d4.loss_mask: 1.2873  decode.d4.loss_dice: 0.9612  decode.d5.loss_cls: 0.2135  decode.d5.loss_mask: 1.2837  decode.d5.loss_dice: 1.0041  decode.d6.loss_cls: 0.2336  decode.d6.loss_mask: 1.2837  decode.d6.loss_dice: 0.9773  decode.d7.loss_cls: 0.2376  decode.d7.loss_mask: 1.2822  decode.d7.loss_dice: 0.9548  decode.d8.loss_cls: 0.2527  decode.d8.loss_mask: 1.2675  decode.d8.loss_dice: 0.9478
05/26 18:19:31 - mmengine - INFO - Iter(train) [ 62750/160000]  base_lr: 6.3884e-05 lr: 6.3884e-06  eta: 11:06:59  time: 0.4171  data_time: 0.0097  memory: 5981  grad_norm: 514.3322  loss: 20.4744  decode.loss_cls: 0.3126  decode.loss_mask: 0.9012  decode.loss_dice: 0.6957  decode.d0.loss_cls: 0.7259  decode.d0.loss_mask: 0.8793  decode.d0.loss_dice: 0.6910  decode.d1.loss_cls: 0.3220  decode.d1.loss_mask: 0.9506  decode.d1.loss_dice: 0.7487  decode.d2.loss_cls: 0.3449  decode.d2.loss_mask: 0.9422  decode.d2.loss_dice: 0.7292  decode.d3.loss_cls: 0.3312  decode.d3.loss_mask: 0.9753  decode.d3.loss_dice: 0.7832  decode.d4.loss_cls: 0.3346  decode.d4.loss_mask: 0.9494  decode.d4.loss_dice: 0.7579  decode.d5.loss_cls: 0.3537  decode.d5.loss_mask: 0.9279  decode.d5.loss_dice: 0.7574  decode.d6.loss_cls: 0.3394  decode.d6.loss_mask: 0.9408  decode.d6.loss_dice: 0.7937  decode.d7.loss_cls: 0.3418  decode.d7.loss_mask: 0.9341  decode.d7.loss_dice: 0.7208  decode.d8.loss_cls: 0.3224  decode.d8.loss_mask: 0.9371  decode.d8.loss_dice: 0.7305
05/26 18:19:52 - mmengine - INFO - Iter(train) [ 62800/160000]  base_lr: 6.3855e-05 lr: 6.3855e-06  eta: 11:06:39  time: 0.4112  data_time: 0.0095  memory: 5975  grad_norm: 391.1303  loss: 18.6579  decode.loss_cls: 0.2225  decode.loss_mask: 0.8543  decode.loss_dice: 0.7124  decode.d0.loss_cls: 0.6061  decode.d0.loss_mask: 0.8297  decode.d0.loss_dice: 0.7261  decode.d1.loss_cls: 0.2130  decode.d1.loss_mask: 0.8374  decode.d1.loss_dice: 0.7083  decode.d2.loss_cls: 0.2135  decode.d2.loss_mask: 0.8867  decode.d2.loss_dice: 0.7472  decode.d3.loss_cls: 0.2163  decode.d3.loss_mask: 0.8909  decode.d3.loss_dice: 0.7646  decode.d4.loss_cls: 0.2407  decode.d4.loss_mask: 0.8921  decode.d4.loss_dice: 0.7476  decode.d5.loss_cls: 0.2585  decode.d5.loss_mask: 0.8922  decode.d5.loss_dice: 0.7214  decode.d6.loss_cls: 0.2436  decode.d6.loss_mask: 0.8826  decode.d6.loss_dice: 0.7254  decode.d7.loss_cls: 0.2138  decode.d7.loss_mask: 0.8876  decode.d7.loss_dice: 0.7132  decode.d8.loss_cls: 0.1948  decode.d8.loss_mask: 0.8819  decode.d8.loss_dice: 0.7335
05/26 18:20:13 - mmengine - INFO - Iter(train) [ 62850/160000]  base_lr: 6.3825e-05 lr: 6.3825e-06  eta: 11:06:19  time: 0.4137  data_time: 0.0096  memory: 5988  grad_norm: 528.3692  loss: 20.7018  decode.loss_cls: 0.2621  decode.loss_mask: 1.0716  decode.loss_dice: 0.7096  decode.d0.loss_cls: 0.6528  decode.d0.loss_mask: 1.0141  decode.d0.loss_dice: 0.7127  decode.d1.loss_cls: 0.2907  decode.d1.loss_mask: 1.0364  decode.d1.loss_dice: 0.7631  decode.d2.loss_cls: 0.2545  decode.d2.loss_mask: 1.0428  decode.d2.loss_dice: 0.7293  decode.d3.loss_cls: 0.2568  decode.d3.loss_mask: 1.0589  decode.d3.loss_dice: 0.7535  decode.d4.loss_cls: 0.2843  decode.d4.loss_mask: 1.0291  decode.d4.loss_dice: 0.7258  decode.d5.loss_cls: 0.2571  decode.d5.loss_mask: 1.0246  decode.d5.loss_dice: 0.6949  decode.d6.loss_cls: 0.2704  decode.d6.loss_mask: 1.0375  decode.d6.loss_dice: 0.7134  decode.d7.loss_cls: 0.2538  decode.d7.loss_mask: 1.0517  decode.d7.loss_dice: 0.7196  decode.d8.loss_cls: 0.2551  decode.d8.loss_mask: 1.0469  decode.d8.loss_dice: 0.7286
05/26 18:20:33 - mmengine - INFO - Iter(train) [ 62900/160000]  base_lr: 6.3796e-05 lr: 6.3796e-06  eta: 11:05:58  time: 0.4127  data_time: 0.0096  memory: 5966  grad_norm: 419.7456  loss: 20.6139  decode.loss_cls: 0.2140  decode.loss_mask: 0.9993  decode.loss_dice: 0.7503  decode.d0.loss_cls: 0.6630  decode.d0.loss_mask: 1.0463  decode.d0.loss_dice: 0.7863  decode.d1.loss_cls: 0.2362  decode.d1.loss_mask: 1.0825  decode.d1.loss_dice: 0.7798  decode.d2.loss_cls: 0.2016  decode.d2.loss_mask: 1.0390  decode.d2.loss_dice: 0.7668  decode.d3.loss_cls: 0.2517  decode.d3.loss_mask: 1.0189  decode.d3.loss_dice: 0.7680  decode.d4.loss_cls: 0.2066  decode.d4.loss_mask: 1.0155  decode.d4.loss_dice: 0.7840  decode.d5.loss_cls: 0.2118  decode.d5.loss_mask: 1.0242  decode.d5.loss_dice: 0.7617  decode.d6.loss_cls: 0.2424  decode.d6.loss_mask: 0.9988  decode.d6.loss_dice: 0.7717  decode.d7.loss_cls: 0.1990  decode.d7.loss_mask: 1.0231  decode.d7.loss_dice: 0.7884  decode.d8.loss_cls: 0.2150  decode.d8.loss_mask: 1.0202  decode.d8.loss_dice: 0.7477
05/26 18:20:54 - mmengine - INFO - Iter(train) [ 62950/160000]  base_lr: 6.3766e-05 lr: 6.3766e-06  eta: 11:05:38  time: 0.4148  data_time: 0.0097  memory: 5970  grad_norm: 459.2420  loss: 21.5015  decode.loss_cls: 0.1694  decode.loss_mask: 1.1044  decode.loss_dice: 0.7632  decode.d0.loss_cls: 0.6438  decode.d0.loss_mask: 1.1502  decode.d0.loss_dice: 0.7664  decode.d1.loss_cls: 0.1739  decode.d1.loss_mask: 1.1730  decode.d1.loss_dice: 0.8432  decode.d2.loss_cls: 0.1785  decode.d2.loss_mask: 1.1298  decode.d2.loss_dice: 0.7905  decode.d3.loss_cls: 0.1798  decode.d3.loss_mask: 1.1351  decode.d3.loss_dice: 0.7747  decode.d4.loss_cls: 0.1572  decode.d4.loss_mask: 1.1318  decode.d4.loss_dice: 0.7868  decode.d5.loss_cls: 0.1706  decode.d5.loss_mask: 1.1329  decode.d5.loss_dice: 0.7807  decode.d6.loss_cls: 0.2017  decode.d6.loss_mask: 1.1207  decode.d6.loss_dice: 0.8154  decode.d7.loss_cls: 0.1595  decode.d7.loss_mask: 1.1470  decode.d7.loss_dice: 0.8214  decode.d8.loss_cls: 0.1377  decode.d8.loss_mask: 1.1841  decode.d8.loss_dice: 0.7782
05/26 18:21:15 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 18:21:15 - mmengine - INFO - Iter(train) [ 63000/160000]  base_lr: 6.3737e-05 lr: 6.3737e-06  eta: 11:05:17  time: 0.4151  data_time: 0.0097  memory: 5975  grad_norm: 527.9761  loss: 20.5206  decode.loss_cls: 0.2197  decode.loss_mask: 0.9849  decode.loss_dice: 0.8180  decode.d0.loss_cls: 0.7102  decode.d0.loss_mask: 0.9466  decode.d0.loss_dice: 0.7834  decode.d1.loss_cls: 0.2260  decode.d1.loss_mask: 0.9933  decode.d1.loss_dice: 0.7949  decode.d2.loss_cls: 0.2618  decode.d2.loss_mask: 0.9631  decode.d2.loss_dice: 0.7532  decode.d3.loss_cls: 0.2624  decode.d3.loss_mask: 1.0001  decode.d3.loss_dice: 0.8064  decode.d4.loss_cls: 0.1862  decode.d4.loss_mask: 0.9736  decode.d4.loss_dice: 0.7918  decode.d5.loss_cls: 0.2235  decode.d5.loss_mask: 0.9802  decode.d5.loss_dice: 0.8388  decode.d6.loss_cls: 0.2451  decode.d6.loss_mask: 0.9655  decode.d6.loss_dice: 0.8144  decode.d7.loss_cls: 0.1962  decode.d7.loss_mask: 0.9716  decode.d7.loss_dice: 0.8094  decode.d8.loss_cls: 0.1676  decode.d8.loss_mask: 0.9900  decode.d8.loss_dice: 0.8428
05/26 18:21:36 - mmengine - INFO - Iter(train) [ 63050/160000]  base_lr: 6.3707e-05 lr: 6.3707e-06  eta: 11:04:57  time: 0.4156  data_time: 0.0097  memory: 5966  grad_norm: 475.8799  loss: 20.2432  decode.loss_cls: 0.1504  decode.loss_mask: 1.0571  decode.loss_dice: 0.7086  decode.d0.loss_cls: 0.7053  decode.d0.loss_mask: 1.0694  decode.d0.loss_dice: 0.7083  decode.d1.loss_cls: 0.1855  decode.d1.loss_mask: 1.0770  decode.d1.loss_dice: 0.7187  decode.d2.loss_cls: 0.1553  decode.d2.loss_mask: 1.0814  decode.d2.loss_dice: 0.7066  decode.d3.loss_cls: 0.1620  decode.d3.loss_mask: 1.0740  decode.d3.loss_dice: 0.7125  decode.d4.loss_cls: 0.1802  decode.d4.loss_mask: 1.0879  decode.d4.loss_dice: 0.7133  decode.d5.loss_cls: 0.1637  decode.d5.loss_mask: 1.0986  decode.d5.loss_dice: 0.7390  decode.d6.loss_cls: 0.1781  decode.d6.loss_mask: 1.0864  decode.d6.loss_dice: 0.7237  decode.d7.loss_cls: 0.1941  decode.d7.loss_mask: 1.1013  decode.d7.loss_dice: 0.7233  decode.d8.loss_cls: 0.1964  decode.d8.loss_mask: 1.0735  decode.d8.loss_dice: 0.7120
05/26 18:21:56 - mmengine - INFO - Iter(train) [ 63100/160000]  base_lr: 6.3677e-05 lr: 6.3677e-06  eta: 11:04:37  time: 0.4141  data_time: 0.0097  memory: 5970  grad_norm: 600.7023  loss: 19.3723  decode.loss_cls: 0.1589  decode.loss_mask: 0.9841  decode.loss_dice: 0.7392  decode.d0.loss_cls: 0.6061  decode.d0.loss_mask: 0.9523  decode.d0.loss_dice: 0.7534  decode.d1.loss_cls: 0.2093  decode.d1.loss_mask: 0.9634  decode.d1.loss_dice: 0.7218  decode.d2.loss_cls: 0.1377  decode.d2.loss_mask: 0.9686  decode.d2.loss_dice: 0.7349  decode.d3.loss_cls: 0.1831  decode.d3.loss_mask: 0.9964  decode.d3.loss_dice: 0.7482  decode.d4.loss_cls: 0.1835  decode.d4.loss_mask: 0.9893  decode.d4.loss_dice: 0.7479  decode.d5.loss_cls: 0.1599  decode.d5.loss_mask: 0.9872  decode.d5.loss_dice: 0.7481  decode.d6.loss_cls: 0.1551  decode.d6.loss_mask: 1.0035  decode.d6.loss_dice: 0.7398  decode.d7.loss_cls: 0.1843  decode.d7.loss_mask: 0.9648  decode.d7.loss_dice: 0.7473  decode.d8.loss_cls: 0.1916  decode.d8.loss_mask: 0.9680  decode.d8.loss_dice: 0.7445
05/26 18:22:17 - mmengine - INFO - Iter(train) [ 63150/160000]  base_lr: 6.3648e-05 lr: 6.3648e-06  eta: 11:04:17  time: 0.4143  data_time: 0.0098  memory: 5981  grad_norm: 501.5642  loss: 18.2603  decode.loss_cls: 0.2954  decode.loss_mask: 0.8893  decode.loss_dice: 0.6132  decode.d0.loss_cls: 0.6453  decode.d0.loss_mask: 0.8643  decode.d0.loss_dice: 0.5901  decode.d1.loss_cls: 0.3091  decode.d1.loss_mask: 0.8803  decode.d1.loss_dice: 0.5733  decode.d2.loss_cls: 0.2638  decode.d2.loss_mask: 0.9390  decode.d2.loss_dice: 0.6077  decode.d3.loss_cls: 0.2784  decode.d3.loss_mask: 0.8932  decode.d3.loss_dice: 0.6128  decode.d4.loss_cls: 0.2656  decode.d4.loss_mask: 0.8837  decode.d4.loss_dice: 0.6093  decode.d5.loss_cls: 0.2953  decode.d5.loss_mask: 0.9054  decode.d5.loss_dice: 0.6342  decode.d6.loss_cls: 0.3020  decode.d6.loss_mask: 0.8884  decode.d6.loss_dice: 0.6309  decode.d7.loss_cls: 0.3031  decode.d7.loss_mask: 0.8912  decode.d7.loss_dice: 0.6109  decode.d8.loss_cls: 0.2957  decode.d8.loss_mask: 0.8812  decode.d8.loss_dice: 0.6081
05/26 18:22:38 - mmengine - INFO - Iter(train) [ 63200/160000]  base_lr: 6.3618e-05 lr: 6.3618e-06  eta: 11:03:56  time: 0.4163  data_time: 0.0097  memory: 5975  grad_norm: 551.3230  loss: 21.9766  decode.loss_cls: 0.2354  decode.loss_mask: 1.0624  decode.loss_dice: 0.8125  decode.d0.loss_cls: 0.7884  decode.d0.loss_mask: 1.0133  decode.d0.loss_dice: 0.7405  decode.d1.loss_cls: 0.2416  decode.d1.loss_mask: 1.0884  decode.d1.loss_dice: 0.8138  decode.d2.loss_cls: 0.2715  decode.d2.loss_mask: 1.0651  decode.d2.loss_dice: 0.7681  decode.d3.loss_cls: 0.2226  decode.d3.loss_mask: 1.1005  decode.d3.loss_dice: 0.7988  decode.d4.loss_cls: 0.2595  decode.d4.loss_mask: 1.1277  decode.d4.loss_dice: 0.8491  decode.d5.loss_cls: 0.2409  decode.d5.loss_mask: 1.1585  decode.d5.loss_dice: 0.8105  decode.d6.loss_cls: 0.2408  decode.d6.loss_mask: 1.1272  decode.d6.loss_dice: 0.8305  decode.d7.loss_cls: 0.2664  decode.d7.loss_mask: 1.0836  decode.d7.loss_dice: 0.8084  decode.d8.loss_cls: 0.2671  decode.d8.loss_mask: 1.0693  decode.d8.loss_dice: 0.8146
05/26 18:23:02 - mmengine - INFO - Iter(train) [ 63250/160000]  base_lr: 6.3589e-05 lr: 6.3589e-06  eta: 11:03:41  time: 0.7204  data_time: 0.0096  memory: 5969  grad_norm: 655.9062  loss: 23.3533  decode.loss_cls: 0.2732  decode.loss_mask: 1.2150  decode.loss_dice: 0.7875  decode.d0.loss_cls: 0.7516  decode.d0.loss_mask: 1.1657  decode.d0.loss_dice: 0.7401  decode.d1.loss_cls: 0.2618  decode.d1.loss_mask: 1.2667  decode.d1.loss_dice: 0.7700  decode.d2.loss_cls: 0.2644  decode.d2.loss_mask: 1.2347  decode.d2.loss_dice: 0.7573  decode.d3.loss_cls: 0.3023  decode.d3.loss_mask: 1.2450  decode.d3.loss_dice: 0.7987  decode.d4.loss_cls: 0.2548  decode.d4.loss_mask: 1.2710  decode.d4.loss_dice: 0.7854  decode.d5.loss_cls: 0.2303  decode.d5.loss_mask: 1.2475  decode.d5.loss_dice: 0.7764  decode.d6.loss_cls: 0.2397  decode.d6.loss_mask: 1.3699  decode.d6.loss_dice: 0.8118  decode.d7.loss_cls: 0.3133  decode.d7.loss_mask: 1.2259  decode.d7.loss_dice: 0.7876  decode.d8.loss_cls: 0.2574  decode.d8.loss_mask: 1.1927  decode.d8.loss_dice: 0.7555
05/26 18:23:23 - mmengine - INFO - Iter(train) [ 63300/160000]  base_lr: 6.3559e-05 lr: 6.3559e-06  eta: 11:03:21  time: 0.4141  data_time: 0.0097  memory: 5968  grad_norm: 736.8326  loss: 20.1203  decode.loss_cls: 0.3270  decode.loss_mask: 0.8902  decode.loss_dice: 0.7457  decode.d0.loss_cls: 0.6895  decode.d0.loss_mask: 0.8675  decode.d0.loss_dice: 0.6807  decode.d1.loss_cls: 0.3286  decode.d1.loss_mask: 0.9497  decode.d1.loss_dice: 0.7579  decode.d2.loss_cls: 0.2916  decode.d2.loss_mask: 0.9465  decode.d2.loss_dice: 0.7489  decode.d3.loss_cls: 0.2866  decode.d3.loss_mask: 0.9681  decode.d3.loss_dice: 0.7417  decode.d4.loss_cls: 0.2997  decode.d4.loss_mask: 0.9502  decode.d4.loss_dice: 0.7465  decode.d5.loss_cls: 0.3112  decode.d5.loss_mask: 0.9531  decode.d5.loss_dice: 0.7185  decode.d6.loss_cls: 0.3282  decode.d6.loss_mask: 0.8907  decode.d6.loss_dice: 0.7344  decode.d7.loss_cls: 0.3378  decode.d7.loss_mask: 0.9123  decode.d7.loss_dice: 0.7551  decode.d8.loss_cls: 0.3174  decode.d8.loss_mask: 0.8993  decode.d8.loss_dice: 0.7457
05/26 18:23:43 - mmengine - INFO - Iter(train) [ 63350/160000]  base_lr: 6.3530e-05 lr: 6.3530e-06  eta: 11:03:00  time: 0.4145  data_time: 0.0097  memory: 5976  grad_norm: 1030.9957  loss: 21.8454  decode.loss_cls: 0.2133  decode.loss_mask: 1.1347  decode.loss_dice: 0.7849  decode.d0.loss_cls: 0.7479  decode.d0.loss_mask: 1.0302  decode.d0.loss_dice: 0.7599  decode.d1.loss_cls: 0.2785  decode.d1.loss_mask: 1.1314  decode.d1.loss_dice: 0.7793  decode.d2.loss_cls: 0.2337  decode.d2.loss_mask: 1.1513  decode.d2.loss_dice: 0.7647  decode.d3.loss_cls: 0.2525  decode.d3.loss_mask: 1.1101  decode.d3.loss_dice: 0.7698  decode.d4.loss_cls: 0.2205  decode.d4.loss_mask: 1.1142  decode.d4.loss_dice: 0.7736  decode.d5.loss_cls: 0.2355  decode.d5.loss_mask: 1.1266  decode.d5.loss_dice: 0.7657  decode.d6.loss_cls: 0.2371  decode.d6.loss_mask: 1.1693  decode.d6.loss_dice: 0.7895  decode.d7.loss_cls: 0.2159  decode.d7.loss_mask: 1.1419  decode.d7.loss_dice: 0.7886  decode.d8.loss_cls: 0.2401  decode.d8.loss_mask: 1.1097  decode.d8.loss_dice: 0.7749
05/26 18:24:04 - mmengine - INFO - Iter(train) [ 63400/160000]  base_lr: 6.3500e-05 lr: 6.3500e-06  eta: 11:02:40  time: 0.4132  data_time: 0.0096  memory: 5967  grad_norm: 708.7179  loss: 22.2459  decode.loss_cls: 0.2698  decode.loss_mask: 1.0710  decode.loss_dice: 0.8053  decode.d0.loss_cls: 0.6970  decode.d0.loss_mask: 1.0857  decode.d0.loss_dice: 0.8078  decode.d1.loss_cls: 0.2880  decode.d1.loss_mask: 1.0841  decode.d1.loss_dice: 0.8049  decode.d2.loss_cls: 0.2479  decode.d2.loss_mask: 1.2150  decode.d2.loss_dice: 0.8752  decode.d3.loss_cls: 0.2660  decode.d3.loss_mask: 1.0907  decode.d3.loss_dice: 0.8149  decode.d4.loss_cls: 0.2686  decode.d4.loss_mask: 1.0708  decode.d4.loss_dice: 0.8291  decode.d5.loss_cls: 0.2440  decode.d5.loss_mask: 1.0722  decode.d5.loss_dice: 0.8079  decode.d6.loss_cls: 0.2519  decode.d6.loss_mask: 1.0977  decode.d6.loss_dice: 0.8301  decode.d7.loss_cls: 0.2529  decode.d7.loss_mask: 1.1090  decode.d7.loss_dice: 0.8340  decode.d8.loss_cls: 0.2505  decode.d8.loss_mask: 1.0921  decode.d8.loss_dice: 0.8117
05/26 18:24:25 - mmengine - INFO - Iter(train) [ 63450/160000]  base_lr: 6.3470e-05 lr: 6.3470e-06  eta: 11:02:19  time: 0.4130  data_time: 0.0096  memory: 5971  grad_norm: 845.4195  loss: 25.8224  decode.loss_cls: 0.3954  decode.loss_mask: 1.2379  decode.loss_dice: 0.9388  decode.d0.loss_cls: 0.7402  decode.d0.loss_mask: 1.2563  decode.d0.loss_dice: 0.8974  decode.d1.loss_cls: 0.3574  decode.d1.loss_mask: 1.2553  decode.d1.loss_dice: 0.8832  decode.d2.loss_cls: 0.3857  decode.d2.loss_mask: 1.2510  decode.d2.loss_dice: 0.8974  decode.d3.loss_cls: 0.3796  decode.d3.loss_mask: 1.2740  decode.d3.loss_dice: 0.9109  decode.d4.loss_cls: 0.3745  decode.d4.loss_mask: 1.2853  decode.d4.loss_dice: 0.9492  decode.d5.loss_cls: 0.3316  decode.d5.loss_mask: 1.2602  decode.d5.loss_dice: 0.9084  decode.d6.loss_cls: 0.3654  decode.d6.loss_mask: 1.2977  decode.d6.loss_dice: 0.9359  decode.d7.loss_cls: 0.3425  decode.d7.loss_mask: 1.2577  decode.d7.loss_dice: 0.9164  decode.d8.loss_cls: 0.3686  decode.d8.loss_mask: 1.2378  decode.d8.loss_dice: 0.9306
05/26 18:24:45 - mmengine - INFO - Iter(train) [ 63500/160000]  base_lr: 6.3441e-05 lr: 6.3441e-06  eta: 11:01:59  time: 0.4125  data_time: 0.0096  memory: 5971  grad_norm: 797.1378  loss: 23.6766  decode.loss_cls: 0.3322  decode.loss_mask: 1.1617  decode.loss_dice: 0.8000  decode.d0.loss_cls: 0.8531  decode.d0.loss_mask: 1.1653  decode.d0.loss_dice: 0.7916  decode.d1.loss_cls: 0.2906  decode.d1.loss_mask: 1.2228  decode.d1.loss_dice: 0.8337  decode.d2.loss_cls: 0.2701  decode.d2.loss_mask: 1.2075  decode.d2.loss_dice: 0.8338  decode.d3.loss_cls: 0.2627  decode.d3.loss_mask: 1.1891  decode.d3.loss_dice: 0.8269  decode.d4.loss_cls: 0.2886  decode.d4.loss_mask: 1.2592  decode.d4.loss_dice: 0.8323  decode.d5.loss_cls: 0.3069  decode.d5.loss_mask: 1.2150  decode.d5.loss_dice: 0.8321  decode.d6.loss_cls: 0.3273  decode.d6.loss_mask: 1.1944  decode.d6.loss_dice: 0.8175  decode.d7.loss_cls: 0.3030  decode.d7.loss_mask: 1.1726  decode.d7.loss_dice: 0.7957  decode.d8.loss_cls: 0.2690  decode.d8.loss_mask: 1.2120  decode.d8.loss_dice: 0.8099
05/26 18:25:06 - mmengine - INFO - Iter(train) [ 63550/160000]  base_lr: 6.3411e-05 lr: 6.3411e-06  eta: 11:01:38  time: 0.4128  data_time: 0.0096  memory: 5975  grad_norm: 579.0130  loss: 19.5160  decode.loss_cls: 0.1511  decode.loss_mask: 0.9996  decode.loss_dice: 0.7140  decode.d0.loss_cls: 0.5933  decode.d0.loss_mask: 0.9575  decode.d0.loss_dice: 0.7154  decode.d1.loss_cls: 0.1598  decode.d1.loss_mask: 1.0409  decode.d1.loss_dice: 0.7507  decode.d2.loss_cls: 0.2083  decode.d2.loss_mask: 1.0136  decode.d2.loss_dice: 0.6945  decode.d3.loss_cls: 0.2366  decode.d3.loss_mask: 1.0171  decode.d3.loss_dice: 0.7368  decode.d4.loss_cls: 0.1935  decode.d4.loss_mask: 1.0295  decode.d4.loss_dice: 0.7172  decode.d5.loss_cls: 0.1916  decode.d5.loss_mask: 0.9905  decode.d5.loss_dice: 0.7134  decode.d6.loss_cls: 0.1669  decode.d6.loss_mask: 0.9884  decode.d6.loss_dice: 0.7224  decode.d7.loss_cls: 0.1786  decode.d7.loss_mask: 1.0263  decode.d7.loss_dice: 0.7461  decode.d8.loss_cls: 0.1508  decode.d8.loss_mask: 1.0007  decode.d8.loss_dice: 0.7111
05/26 18:25:27 - mmengine - INFO - Iter(train) [ 63600/160000]  base_lr: 6.3382e-05 lr: 6.3382e-06  eta: 11:01:18  time: 0.4136  data_time: 0.0097  memory: 5966  grad_norm: 796.5079  loss: 24.8086  decode.loss_cls: 0.2701  decode.loss_mask: 1.3000  decode.loss_dice: 0.9035  decode.d0.loss_cls: 0.7388  decode.d0.loss_mask: 1.1992  decode.d0.loss_dice: 0.8741  decode.d1.loss_cls: 0.2766  decode.d1.loss_mask: 1.2946  decode.d1.loss_dice: 0.8957  decode.d2.loss_cls: 0.2510  decode.d2.loss_mask: 1.2831  decode.d2.loss_dice: 0.9121  decode.d3.loss_cls: 0.2201  decode.d3.loss_mask: 1.2914  decode.d3.loss_dice: 0.9051  decode.d4.loss_cls: 0.2112  decode.d4.loss_mask: 1.2881  decode.d4.loss_dice: 0.8763  decode.d5.loss_cls: 0.2563  decode.d5.loss_mask: 1.3072  decode.d5.loss_dice: 0.8892  decode.d6.loss_cls: 0.2913  decode.d6.loss_mask: 1.3159  decode.d6.loss_dice: 0.9147  decode.d7.loss_cls: 0.2621  decode.d7.loss_mask: 1.2888  decode.d7.loss_dice: 0.9017  decode.d8.loss_cls: 0.2438  decode.d8.loss_mask: 1.2459  decode.d8.loss_dice: 0.9007
05/26 18:25:48 - mmengine - INFO - Iter(train) [ 63650/160000]  base_lr: 6.3352e-05 lr: 6.3352e-06  eta: 11:00:58  time: 0.4138  data_time: 0.0096  memory: 5967  grad_norm: 534.0124  loss: 21.6274  decode.loss_cls: 0.2408  decode.loss_mask: 1.1621  decode.loss_dice: 0.7093  decode.d0.loss_cls: 0.6388  decode.d0.loss_mask: 1.1657  decode.d0.loss_dice: 0.6950  decode.d1.loss_cls: 0.1850  decode.d1.loss_mask: 1.2449  decode.d1.loss_dice: 0.7289  decode.d2.loss_cls: 0.2122  decode.d2.loss_mask: 1.2289  decode.d2.loss_dice: 0.7452  decode.d3.loss_cls: 0.1683  decode.d3.loss_mask: 1.1916  decode.d3.loss_dice: 0.7064  decode.d4.loss_cls: 0.1456  decode.d4.loss_mask: 1.2332  decode.d4.loss_dice: 0.7082  decode.d5.loss_cls: 0.1874  decode.d5.loss_mask: 1.1888  decode.d5.loss_dice: 0.7142  decode.d6.loss_cls: 0.2102  decode.d6.loss_mask: 1.1778  decode.d6.loss_dice: 0.7012  decode.d7.loss_cls: 0.1991  decode.d7.loss_mask: 1.2588  decode.d7.loss_dice: 0.7332  decode.d8.loss_cls: 0.2436  decode.d8.loss_mask: 1.1729  decode.d8.loss_dice: 0.7302
05/26 18:26:08 - mmengine - INFO - Iter(train) [ 63700/160000]  base_lr: 6.3323e-05 lr: 6.3323e-06  eta: 11:00:37  time: 0.4126  data_time: 0.0096  memory: 5970  grad_norm: 785.7730  loss: 22.5981  decode.loss_cls: 0.2877  decode.loss_mask: 1.1541  decode.loss_dice: 0.7872  decode.d0.loss_cls: 0.8312  decode.d0.loss_mask: 1.0182  decode.d0.loss_dice: 0.7523  decode.d1.loss_cls: 0.2891  decode.d1.loss_mask: 1.1578  decode.d1.loss_dice: 0.7802  decode.d2.loss_cls: 0.3393  decode.d2.loss_mask: 1.0999  decode.d2.loss_dice: 0.7245  decode.d3.loss_cls: 0.3078  decode.d3.loss_mask: 1.1217  decode.d3.loss_dice: 0.7420  decode.d4.loss_cls: 0.3828  decode.d4.loss_mask: 1.1226  decode.d4.loss_dice: 0.7600  decode.d5.loss_cls: 0.3411  decode.d5.loss_mask: 1.1066  decode.d5.loss_dice: 0.7709  decode.d6.loss_cls: 0.3507  decode.d6.loss_mask: 1.1507  decode.d6.loss_dice: 0.7635  decode.d7.loss_cls: 0.2880  decode.d7.loss_mask: 1.1531  decode.d7.loss_dice: 0.7982  decode.d8.loss_cls: 0.2998  decode.d8.loss_mask: 1.1433  decode.d8.loss_dice: 0.7737
05/26 18:26:29 - mmengine - INFO - Iter(train) [ 63750/160000]  base_lr: 6.3293e-05 lr: 6.3293e-06  eta: 11:00:17  time: 0.4130  data_time: 0.0096  memory: 5968  grad_norm: 460.4128  loss: 22.0151  decode.loss_cls: 0.2465  decode.loss_mask: 1.0920  decode.loss_dice: 0.8266  decode.d0.loss_cls: 0.7713  decode.d0.loss_mask: 1.0221  decode.d0.loss_dice: 0.7252  decode.d1.loss_cls: 0.3399  decode.d1.loss_mask: 1.1135  decode.d1.loss_dice: 0.7969  decode.d2.loss_cls: 0.3086  decode.d2.loss_mask: 1.0624  decode.d2.loss_dice: 0.7892  decode.d3.loss_cls: 0.2999  decode.d3.loss_mask: 1.0483  decode.d3.loss_dice: 0.8078  decode.d4.loss_cls: 0.3120  decode.d4.loss_mask: 1.0385  decode.d4.loss_dice: 0.7985  decode.d5.loss_cls: 0.3010  decode.d5.loss_mask: 1.0684  decode.d5.loss_dice: 0.7994  decode.d6.loss_cls: 0.2620  decode.d6.loss_mask: 1.0397  decode.d6.loss_dice: 0.8155  decode.d7.loss_cls: 0.2608  decode.d7.loss_mask: 1.1073  decode.d7.loss_dice: 0.8289  decode.d8.loss_cls: 0.2603  decode.d8.loss_mask: 1.0736  decode.d8.loss_dice: 0.7989
05/26 18:26:50 - mmengine - INFO - Iter(train) [ 63800/160000]  base_lr: 6.3263e-05 lr: 6.3263e-06  eta: 10:59:56  time: 0.4140  data_time: 0.0096  memory: 5967  grad_norm: 407.8080  loss: 19.0078  decode.loss_cls: 0.2614  decode.loss_mask: 0.9226  decode.loss_dice: 0.6764  decode.d0.loss_cls: 0.6736  decode.d0.loss_mask: 0.9324  decode.d0.loss_dice: 0.6789  decode.d1.loss_cls: 0.2780  decode.d1.loss_mask: 0.9018  decode.d1.loss_dice: 0.6643  decode.d2.loss_cls: 0.2461  decode.d2.loss_mask: 0.9093  decode.d2.loss_dice: 0.6797  decode.d3.loss_cls: 0.2498  decode.d3.loss_mask: 0.8990  decode.d3.loss_dice: 0.6635  decode.d4.loss_cls: 0.2637  decode.d4.loss_mask: 0.9296  decode.d4.loss_dice: 0.6530  decode.d5.loss_cls: 0.2578  decode.d5.loss_mask: 0.9610  decode.d5.loss_dice: 0.6830  decode.d6.loss_cls: 0.2410  decode.d6.loss_mask: 0.9340  decode.d6.loss_dice: 0.6592  decode.d7.loss_cls: 0.2581  decode.d7.loss_mask: 0.9589  decode.d7.loss_dice: 0.6807  decode.d8.loss_cls: 0.3039  decode.d8.loss_mask: 0.9246  decode.d8.loss_dice: 0.6625
05/26 18:27:10 - mmengine - INFO - Iter(train) [ 63850/160000]  base_lr: 6.3234e-05 lr: 6.3234e-06  eta: 10:59:36  time: 0.4123  data_time: 0.0096  memory: 5976  grad_norm: 551.4578  loss: 21.1735  decode.loss_cls: 0.2481  decode.loss_mask: 1.0347  decode.loss_dice: 0.7971  decode.d0.loss_cls: 0.7599  decode.d0.loss_mask: 0.8629  decode.d0.loss_dice: 0.7103  decode.d1.loss_cls: 0.3866  decode.d1.loss_mask: 0.9751  decode.d1.loss_dice: 0.7780  decode.d2.loss_cls: 0.3048  decode.d2.loss_mask: 1.0298  decode.d2.loss_dice: 0.7839  decode.d3.loss_cls: 0.2375  decode.d3.loss_mask: 1.0359  decode.d3.loss_dice: 0.7963  decode.d4.loss_cls: 0.3293  decode.d4.loss_mask: 1.0994  decode.d4.loss_dice: 0.7603  decode.d5.loss_cls: 0.2492  decode.d5.loss_mask: 0.9879  decode.d5.loss_dice: 0.7737  decode.d6.loss_cls: 0.2727  decode.d6.loss_mask: 1.0116  decode.d6.loss_dice: 0.7745  decode.d7.loss_cls: 0.3058  decode.d7.loss_mask: 1.0014  decode.d7.loss_dice: 0.7741  decode.d8.loss_cls: 0.3113  decode.d8.loss_mask: 0.9942  decode.d8.loss_dice: 0.7872
05/26 18:27:31 - mmengine - INFO - Iter(train) [ 63900/160000]  base_lr: 6.3204e-05 lr: 6.3204e-06  eta: 10:59:15  time: 0.4115  data_time: 0.0096  memory: 5984  grad_norm: 479.0508  loss: 21.8139  decode.loss_cls: 0.3042  decode.loss_mask: 1.0430  decode.loss_dice: 0.7742  decode.d0.loss_cls: 0.8029  decode.d0.loss_mask: 0.9921  decode.d0.loss_dice: 0.7630  decode.d1.loss_cls: 0.3488  decode.d1.loss_mask: 1.0048  decode.d1.loss_dice: 0.7344  decode.d2.loss_cls: 0.3338  decode.d2.loss_mask: 1.0289  decode.d2.loss_dice: 0.7432  decode.d3.loss_cls: 0.3218  decode.d3.loss_mask: 1.0729  decode.d3.loss_dice: 0.7954  decode.d4.loss_cls: 0.3240  decode.d4.loss_mask: 1.0436  decode.d4.loss_dice: 0.7654  decode.d5.loss_cls: 0.3390  decode.d5.loss_mask: 1.0672  decode.d5.loss_dice: 0.8052  decode.d6.loss_cls: 0.3025  decode.d6.loss_mask: 1.0785  decode.d6.loss_dice: 0.7833  decode.d7.loss_cls: 0.3057  decode.d7.loss_mask: 1.0507  decode.d7.loss_dice: 0.7885  decode.d8.loss_cls: 0.2986  decode.d8.loss_mask: 1.0455  decode.d8.loss_dice: 0.7529
05/26 18:27:52 - mmengine - INFO - Iter(train) [ 63950/160000]  base_lr: 6.3175e-05 lr: 6.3175e-06  eta: 10:58:55  time: 0.4163  data_time: 0.0097  memory: 5970  grad_norm: 507.8480  loss: 21.9131  decode.loss_cls: 0.2033  decode.loss_mask: 1.0737  decode.loss_dice: 0.8682  decode.d0.loss_cls: 0.6661  decode.d0.loss_mask: 1.0051  decode.d0.loss_dice: 0.8291  decode.d1.loss_cls: 0.2502  decode.d1.loss_mask: 1.0830  decode.d1.loss_dice: 0.8499  decode.d2.loss_cls: 0.2034  decode.d2.loss_mask: 1.0782  decode.d2.loss_dice: 0.8412  decode.d3.loss_cls: 0.2093  decode.d3.loss_mask: 1.0842  decode.d3.loss_dice: 0.8538  decode.d4.loss_cls: 0.2163  decode.d4.loss_mask: 1.0623  decode.d4.loss_dice: 0.8655  decode.d5.loss_cls: 0.2405  decode.d5.loss_mask: 1.0820  decode.d5.loss_dice: 0.8588  decode.d6.loss_cls: 0.1941  decode.d6.loss_mask: 1.0854  decode.d6.loss_dice: 0.8569  decode.d7.loss_cls: 0.1934  decode.d7.loss_mask: 1.0909  decode.d7.loss_dice: 0.8917  decode.d8.loss_cls: 0.2255  decode.d8.loss_mask: 1.0901  decode.d8.loss_dice: 0.8611
05/26 18:28:12 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 18:28:12 - mmengine - INFO - Iter(train) [ 64000/160000]  base_lr: 6.3145e-05 lr: 6.3145e-06  eta: 10:58:34  time: 0.4147  data_time: 0.0097  memory: 5968  grad_norm: 667.6043  loss: 24.2258  decode.loss_cls: 0.2729  decode.loss_mask: 1.2219  decode.loss_dice: 0.8948  decode.d0.loss_cls: 0.8482  decode.d0.loss_mask: 1.1455  decode.d0.loss_dice: 0.8586  decode.d1.loss_cls: 0.2413  decode.d1.loss_mask: 1.1966  decode.d1.loss_dice: 0.9121  decode.d2.loss_cls: 0.2528  decode.d2.loss_mask: 1.2196  decode.d2.loss_dice: 0.9030  decode.d3.loss_cls: 0.2560  decode.d3.loss_mask: 1.1953  decode.d3.loss_dice: 0.8991  decode.d4.loss_cls: 0.2726  decode.d4.loss_mask: 1.1736  decode.d4.loss_dice: 0.8961  decode.d5.loss_cls: 0.2808  decode.d5.loss_mask: 1.1923  decode.d5.loss_dice: 0.8851  decode.d6.loss_cls: 0.2847  decode.d6.loss_mask: 1.2115  decode.d6.loss_dice: 0.9298  decode.d7.loss_cls: 0.2905  decode.d7.loss_mask: 1.1935  decode.d7.loss_dice: 0.8994  decode.d8.loss_cls: 0.2892  decode.d8.loss_mask: 1.1993  decode.d8.loss_dice: 0.9096
05/26 18:28:33 - mmengine - INFO - Iter(train) [ 64050/160000]  base_lr: 6.3115e-05 lr: 6.3115e-06  eta: 10:58:14  time: 0.4136  data_time: 0.0096  memory: 5970  grad_norm: 831.4323  loss: 26.4789  decode.loss_cls: 0.2843  decode.loss_mask: 1.3434  decode.loss_dice: 0.9893  decode.d0.loss_cls: 0.9259  decode.d0.loss_mask: 1.1639  decode.d0.loss_dice: 0.8633  decode.d1.loss_cls: 0.4311  decode.d1.loss_mask: 1.2735  decode.d1.loss_dice: 0.9316  decode.d2.loss_cls: 0.3627  decode.d2.loss_mask: 1.2882  decode.d2.loss_dice: 0.9688  decode.d3.loss_cls: 0.4458  decode.d3.loss_mask: 1.2217  decode.d3.loss_dice: 0.9296  decode.d4.loss_cls: 0.3937  decode.d4.loss_mask: 1.3167  decode.d4.loss_dice: 0.9519  decode.d5.loss_cls: 0.3901  decode.d5.loss_mask: 1.3159  decode.d5.loss_dice: 0.9481  decode.d6.loss_cls: 0.3700  decode.d6.loss_mask: 1.2697  decode.d6.loss_dice: 0.9603  decode.d7.loss_cls: 0.3849  decode.d7.loss_mask: 1.2721  decode.d7.loss_dice: 0.9239  decode.d8.loss_cls: 0.3294  decode.d8.loss_mask: 1.2907  decode.d8.loss_dice: 0.9385
05/26 18:28:54 - mmengine - INFO - Iter(train) [ 64100/160000]  base_lr: 6.3086e-05 lr: 6.3086e-06  eta: 10:57:54  time: 0.4125  data_time: 0.0096  memory: 5992  grad_norm: 629.3465  loss: 18.5847  decode.loss_cls: 0.1971  decode.loss_mask: 0.9176  decode.loss_dice: 0.7461  decode.d0.loss_cls: 0.6620  decode.d0.loss_mask: 0.8180  decode.d0.loss_dice: 0.6901  decode.d1.loss_cls: 0.1485  decode.d1.loss_mask: 0.8907  decode.d1.loss_dice: 0.7573  decode.d2.loss_cls: 0.1769  decode.d2.loss_mask: 0.8921  decode.d2.loss_dice: 0.7380  decode.d3.loss_cls: 0.1873  decode.d3.loss_mask: 0.9064  decode.d3.loss_dice: 0.7564  decode.d4.loss_cls: 0.1762  decode.d4.loss_mask: 0.8852  decode.d4.loss_dice: 0.7381  decode.d5.loss_cls: 0.1723  decode.d5.loss_mask: 0.8798  decode.d5.loss_dice: 0.7215  decode.d6.loss_cls: 0.2001  decode.d6.loss_mask: 0.9198  decode.d6.loss_dice: 0.7791  decode.d7.loss_cls: 0.1636  decode.d7.loss_mask: 0.9033  decode.d7.loss_dice: 0.7636  decode.d8.loss_cls: 0.1708  decode.d8.loss_mask: 0.8888  decode.d8.loss_dice: 0.7382
05/26 18:29:14 - mmengine - INFO - Iter(train) [ 64150/160000]  base_lr: 6.3056e-05 lr: 6.3056e-06  eta: 10:57:33  time: 0.4122  data_time: 0.0096  memory: 5976  grad_norm: 741.0506  loss: 19.7148  decode.loss_cls: 0.3136  decode.loss_mask: 0.8879  decode.loss_dice: 0.7339  decode.d0.loss_cls: 0.6155  decode.d0.loss_mask: 0.8724  decode.d0.loss_dice: 0.7427  decode.d1.loss_cls: 0.3081  decode.d1.loss_mask: 0.8837  decode.d1.loss_dice: 0.7162  decode.d2.loss_cls: 0.3215  decode.d2.loss_mask: 0.8770  decode.d2.loss_dice: 0.7148  decode.d3.loss_cls: 0.3130  decode.d3.loss_mask: 0.9065  decode.d3.loss_dice: 0.7565  decode.d4.loss_cls: 0.3164  decode.d4.loss_mask: 0.8833  decode.d4.loss_dice: 0.7289  decode.d5.loss_cls: 0.3001  decode.d5.loss_mask: 0.8906  decode.d5.loss_dice: 0.7291  decode.d6.loss_cls: 0.2966  decode.d6.loss_mask: 0.9085  decode.d6.loss_dice: 0.7591  decode.d7.loss_cls: 0.3171  decode.d7.loss_mask: 0.9029  decode.d7.loss_dice: 0.7640  decode.d8.loss_cls: 0.3479  decode.d8.loss_mask: 0.8810  decode.d8.loss_dice: 0.7258
05/26 18:29:35 - mmengine - INFO - Iter(train) [ 64200/160000]  base_lr: 6.3027e-05 lr: 6.3027e-06  eta: 10:57:13  time: 0.4151  data_time: 0.0097  memory: 5969  grad_norm: 789.1386  loss: 25.4119  decode.loss_cls: 0.3437  decode.loss_mask: 1.2196  decode.loss_dice: 0.8711  decode.d0.loss_cls: 0.7852  decode.d0.loss_mask: 1.1912  decode.d0.loss_dice: 0.8380  decode.d1.loss_cls: 0.4066  decode.d1.loss_mask: 1.2049  decode.d1.loss_dice: 0.8705  decode.d2.loss_cls: 0.4150  decode.d2.loss_mask: 1.2199  decode.d2.loss_dice: 0.8455  decode.d3.loss_cls: 0.3782  decode.d3.loss_mask: 1.2304  decode.d3.loss_dice: 0.8810  decode.d4.loss_cls: 0.3730  decode.d4.loss_mask: 1.2690  decode.d4.loss_dice: 0.8720  decode.d5.loss_cls: 0.3603  decode.d5.loss_mask: 1.2751  decode.d5.loss_dice: 0.8896  decode.d6.loss_cls: 0.3889  decode.d6.loss_mask: 1.3464  decode.d6.loss_dice: 0.8911  decode.d7.loss_cls: 0.4009  decode.d7.loss_mask: 1.2737  decode.d7.loss_dice: 0.9095  decode.d8.loss_cls: 0.3675  decode.d8.loss_mask: 1.2211  decode.d8.loss_dice: 0.8730
05/26 18:29:56 - mmengine - INFO - Iter(train) [ 64250/160000]  base_lr: 6.2997e-05 lr: 6.2997e-06  eta: 10:56:53  time: 0.4141  data_time: 0.0097  memory: 5970  grad_norm: 653.4991  loss: 25.8272  decode.loss_cls: 0.2266  decode.loss_mask: 1.4045  decode.loss_dice: 0.8998  decode.d0.loss_cls: 0.7375  decode.d0.loss_mask: 1.3019  decode.d0.loss_dice: 0.8816  decode.d1.loss_cls: 0.2167  decode.d1.loss_mask: 1.4317  decode.d1.loss_dice: 0.8921  decode.d2.loss_cls: 0.2248  decode.d2.loss_mask: 1.4308  decode.d2.loss_dice: 0.8590  decode.d3.loss_cls: 0.2305  decode.d3.loss_mask: 1.4391  decode.d3.loss_dice: 0.9079  decode.d4.loss_cls: 0.2777  decode.d4.loss_mask: 1.3296  decode.d4.loss_dice: 0.8621  decode.d5.loss_cls: 0.2652  decode.d5.loss_mask: 1.3919  decode.d5.loss_dice: 0.8998  decode.d6.loss_cls: 0.2154  decode.d6.loss_mask: 1.4203  decode.d6.loss_dice: 0.9234  decode.d7.loss_cls: 0.2171  decode.d7.loss_mask: 1.4349  decode.d7.loss_dice: 0.9080  decode.d8.loss_cls: 0.2045  decode.d8.loss_mask: 1.4782  decode.d8.loss_dice: 0.9146
05/26 18:30:17 - mmengine - INFO - Iter(train) [ 64300/160000]  base_lr: 6.2967e-05 lr: 6.2967e-06  eta: 10:56:32  time: 0.4149  data_time: 0.0097  memory: 5967  grad_norm: 873.6264  loss: 25.0928  decode.loss_cls: 0.2910  decode.loss_mask: 1.1733  decode.loss_dice: 0.9705  decode.d0.loss_cls: 0.7438  decode.d0.loss_mask: 1.0946  decode.d0.loss_dice: 0.9626  decode.d1.loss_cls: 0.3916  decode.d1.loss_mask: 1.1505  decode.d1.loss_dice: 0.9742  decode.d2.loss_cls: 0.3108  decode.d2.loss_mask: 1.1655  decode.d2.loss_dice: 0.9633  decode.d3.loss_cls: 0.3470  decode.d3.loss_mask: 1.1637  decode.d3.loss_dice: 0.9921  decode.d4.loss_cls: 0.3510  decode.d4.loss_mask: 1.2065  decode.d4.loss_dice: 0.9821  decode.d5.loss_cls: 0.3315  decode.d5.loss_mask: 1.1804  decode.d5.loss_dice: 1.0012  decode.d6.loss_cls: 0.3270  decode.d6.loss_mask: 1.1681  decode.d6.loss_dice: 0.9560  decode.d7.loss_cls: 0.3310  decode.d7.loss_mask: 1.1553  decode.d7.loss_dice: 0.9667  decode.d8.loss_cls: 0.2963  decode.d8.loss_mask: 1.1823  decode.d8.loss_dice: 0.9630
05/26 18:30:38 - mmengine - INFO - Iter(train) [ 64350/160000]  base_lr: 6.2938e-05 lr: 6.2938e-06  eta: 10:56:12  time: 0.4160  data_time: 0.0097  memory: 5974  grad_norm: 712.2590  loss: 22.5800  decode.loss_cls: 0.1805  decode.loss_mask: 1.2252  decode.loss_dice: 0.8077  decode.d0.loss_cls: 0.6575  decode.d0.loss_mask: 1.1516  decode.d0.loss_dice: 0.7529  decode.d1.loss_cls: 0.2065  decode.d1.loss_mask: 1.2267  decode.d1.loss_dice: 0.8112  decode.d2.loss_cls: 0.1648  decode.d2.loss_mask: 1.2339  decode.d2.loss_dice: 0.7913  decode.d3.loss_cls: 0.1728  decode.d3.loss_mask: 1.2362  decode.d3.loss_dice: 0.8171  decode.d4.loss_cls: 0.1577  decode.d4.loss_mask: 1.2541  decode.d4.loss_dice: 0.8084  decode.d5.loss_cls: 0.2125  decode.d5.loss_mask: 1.2139  decode.d5.loss_dice: 0.7927  decode.d6.loss_cls: 0.1635  decode.d6.loss_mask: 1.2242  decode.d6.loss_dice: 0.7941  decode.d7.loss_cls: 0.1904  decode.d7.loss_mask: 1.2396  decode.d7.loss_dice: 0.8249  decode.d8.loss_cls: 0.2227  decode.d8.loss_mask: 1.2224  decode.d8.loss_dice: 0.8231
05/26 18:30:58 - mmengine - INFO - Iter(train) [ 64400/160000]  base_lr: 6.2908e-05 lr: 6.2908e-06  eta: 10:55:52  time: 0.4145  data_time: 0.0097  memory: 5976  grad_norm: 846.4891  loss: 23.5881  decode.loss_cls: 0.2151  decode.loss_mask: 1.1117  decode.loss_dice: 0.9723  decode.d0.loss_cls: 0.7384  decode.d0.loss_mask: 1.0918  decode.d0.loss_dice: 0.9039  decode.d1.loss_cls: 0.1887  decode.d1.loss_mask: 1.1680  decode.d1.loss_dice: 0.9717  decode.d2.loss_cls: 0.2736  decode.d2.loss_mask: 1.1163  decode.d2.loss_dice: 0.9389  decode.d3.loss_cls: 0.2337  decode.d3.loss_mask: 1.1174  decode.d3.loss_dice: 0.9366  decode.d4.loss_cls: 0.2828  decode.d4.loss_mask: 1.1510  decode.d4.loss_dice: 0.9530  decode.d5.loss_cls: 0.2733  decode.d5.loss_mask: 1.1025  decode.d5.loss_dice: 0.9457  decode.d6.loss_cls: 0.2766  decode.d6.loss_mask: 1.1153  decode.d6.loss_dice: 0.9350  decode.d7.loss_cls: 0.2532  decode.d7.loss_mask: 1.0879  decode.d7.loss_dice: 0.9333  decode.d8.loss_cls: 0.2824  decode.d8.loss_mask: 1.0911  decode.d8.loss_dice: 0.9270
05/26 18:31:19 - mmengine - INFO - Iter(train) [ 64450/160000]  base_lr: 6.2878e-05 lr: 6.2878e-06  eta: 10:55:32  time: 0.4165  data_time: 0.0097  memory: 5967  grad_norm: 935.6364  loss: 21.8672  decode.loss_cls: 0.2901  decode.loss_mask: 1.0346  decode.loss_dice: 0.7156  decode.d0.loss_cls: 0.6723  decode.d0.loss_mask: 1.0880  decode.d0.loss_dice: 0.7198  decode.d1.loss_cls: 0.2631  decode.d1.loss_mask: 1.1100  decode.d1.loss_dice: 0.7254  decode.d2.loss_cls: 0.2948  decode.d2.loss_mask: 1.1319  decode.d2.loss_dice: 0.7747  decode.d3.loss_cls: 0.2277  decode.d3.loss_mask: 1.2186  decode.d3.loss_dice: 0.7618  decode.d4.loss_cls: 0.3195  decode.d4.loss_mask: 1.1542  decode.d4.loss_dice: 0.7225  decode.d5.loss_cls: 0.2646  decode.d5.loss_mask: 1.1932  decode.d5.loss_dice: 0.7793  decode.d6.loss_cls: 0.2502  decode.d6.loss_mask: 1.1126  decode.d6.loss_dice: 0.7619  decode.d7.loss_cls: 0.2961  decode.d7.loss_mask: 1.0723  decode.d7.loss_dice: 0.7151  decode.d8.loss_cls: 0.2870  decode.d8.loss_mask: 1.1478  decode.d8.loss_dice: 0.7624
05/26 18:31:40 - mmengine - INFO - Iter(train) [ 64500/160000]  base_lr: 6.2849e-05 lr: 6.2849e-06  eta: 10:55:11  time: 0.4190  data_time: 0.0097  memory: 5980  grad_norm: 611.8971  loss: 24.0412  decode.loss_cls: 0.2766  decode.loss_mask: 1.1964  decode.loss_dice: 0.8399  decode.d0.loss_cls: 0.7381  decode.d0.loss_mask: 1.2266  decode.d0.loss_dice: 0.8358  decode.d1.loss_cls: 0.3180  decode.d1.loss_mask: 1.2027  decode.d1.loss_dice: 0.8360  decode.d2.loss_cls: 0.3357  decode.d2.loss_mask: 1.2206  decode.d2.loss_dice: 0.8345  decode.d3.loss_cls: 0.2657  decode.d3.loss_mask: 1.2532  decode.d3.loss_dice: 0.8293  decode.d4.loss_cls: 0.3125  decode.d4.loss_mask: 1.2334  decode.d4.loss_dice: 0.8444  decode.d5.loss_cls: 0.2886  decode.d5.loss_mask: 1.2153  decode.d5.loss_dice: 0.8450  decode.d6.loss_cls: 0.3216  decode.d6.loss_mask: 1.2217  decode.d6.loss_dice: 0.8479  decode.d7.loss_cls: 0.3145  decode.d7.loss_mask: 1.1996  decode.d7.loss_dice: 0.7932  decode.d8.loss_cls: 0.3587  decode.d8.loss_mask: 1.2078  decode.d8.loss_dice: 0.8278
05/26 18:32:01 - mmengine - INFO - Iter(train) [ 64550/160000]  base_lr: 6.2819e-05 lr: 6.2819e-06  eta: 10:54:51  time: 0.4152  data_time: 0.0097  memory: 5988  grad_norm: 569.3920  loss: 22.6275  decode.loss_cls: 0.1755  decode.loss_mask: 1.1135  decode.loss_dice: 0.8747  decode.d0.loss_cls: 0.7486  decode.d0.loss_mask: 1.1117  decode.d0.loss_dice: 0.8334  decode.d1.loss_cls: 0.1732  decode.d1.loss_mask: 1.1246  decode.d1.loss_dice: 0.8849  decode.d2.loss_cls: 0.1794  decode.d2.loss_mask: 1.1305  decode.d2.loss_dice: 0.9075  decode.d3.loss_cls: 0.1895  decode.d3.loss_mask: 1.1358  decode.d3.loss_dice: 0.8807  decode.d4.loss_cls: 0.1555  decode.d4.loss_mask: 1.1777  decode.d4.loss_dice: 0.9063  decode.d5.loss_cls: 0.1728  decode.d5.loss_mask: 1.1552  decode.d5.loss_dice: 0.8775  decode.d6.loss_cls: 0.2120  decode.d6.loss_mask: 1.1206  decode.d6.loss_dice: 0.8601  decode.d7.loss_cls: 0.2353  decode.d7.loss_mask: 1.1393  decode.d7.loss_dice: 0.8964  decode.d8.loss_cls: 0.2557  decode.d8.loss_mask: 1.1291  decode.d8.loss_dice: 0.8707
05/26 18:32:22 - mmengine - INFO - Iter(train) [ 64600/160000]  base_lr: 6.2790e-05 lr: 6.2790e-06  eta: 10:54:31  time: 0.4160  data_time: 0.0097  memory: 5971  grad_norm: 493.6548  loss: 20.9810  decode.loss_cls: 0.1967  decode.loss_mask: 1.0741  decode.loss_dice: 0.7722  decode.d0.loss_cls: 0.7098  decode.d0.loss_mask: 1.0558  decode.d0.loss_dice: 0.7402  decode.d1.loss_cls: 0.2080  decode.d1.loss_mask: 1.1106  decode.d1.loss_dice: 0.7589  decode.d2.loss_cls: 0.2157  decode.d2.loss_mask: 1.0632  decode.d2.loss_dice: 0.7528  decode.d3.loss_cls: 0.2052  decode.d3.loss_mask: 1.0615  decode.d3.loss_dice: 0.7453  decode.d4.loss_cls: 0.2050  decode.d4.loss_mask: 1.0697  decode.d4.loss_dice: 0.7703  decode.d5.loss_cls: 0.2185  decode.d5.loss_mask: 1.0910  decode.d5.loss_dice: 0.7755  decode.d6.loss_cls: 0.2373  decode.d6.loss_mask: 1.0729  decode.d6.loss_dice: 0.7719  decode.d7.loss_cls: 0.2268  decode.d7.loss_mask: 1.0622  decode.d7.loss_dice: 0.7653  decode.d8.loss_cls: 0.2127  decode.d8.loss_mask: 1.0715  decode.d8.loss_dice: 0.7600
05/26 18:32:43 - mmengine - INFO - Iter(train) [ 64650/160000]  base_lr: 6.2760e-05 lr: 6.2760e-06  eta: 10:54:11  time: 0.4150  data_time: 0.0097  memory: 5986  grad_norm: 590.7010  loss: 22.6762  decode.loss_cls: 0.2156  decode.loss_mask: 1.2002  decode.loss_dice: 0.8414  decode.d0.loss_cls: 0.7100  decode.d0.loss_mask: 1.1254  decode.d0.loss_dice: 0.8285  decode.d1.loss_cls: 0.3071  decode.d1.loss_mask: 1.0939  decode.d1.loss_dice: 0.8516  decode.d2.loss_cls: 0.2550  decode.d2.loss_mask: 1.1529  decode.d2.loss_dice: 0.8410  decode.d3.loss_cls: 0.2827  decode.d3.loss_mask: 1.0986  decode.d3.loss_dice: 0.8361  decode.d4.loss_cls: 0.2342  decode.d4.loss_mask: 1.1379  decode.d4.loss_dice: 0.8436  decode.d5.loss_cls: 0.2581  decode.d5.loss_mask: 1.0870  decode.d5.loss_dice: 0.8333  decode.d6.loss_cls: 0.2831  decode.d6.loss_mask: 1.0743  decode.d6.loss_dice: 0.8387  decode.d7.loss_cls: 0.2636  decode.d7.loss_mask: 1.1419  decode.d7.loss_dice: 0.8243  decode.d8.loss_cls: 0.2360  decode.d8.loss_mask: 1.1481  decode.d8.loss_dice: 0.8320
05/26 18:33:04 - mmengine - INFO - Iter(train) [ 64700/160000]  base_lr: 6.2730e-05 lr: 6.2730e-06  eta: 10:53:51  time: 0.4166  data_time: 0.0098  memory: 5981  grad_norm: 927.5832  loss: 26.4699  decode.loss_cls: 0.2050  decode.loss_mask: 1.4160  decode.loss_dice: 0.9523  decode.d0.loss_cls: 0.6843  decode.d0.loss_mask: 1.4094  decode.d0.loss_dice: 0.8986  decode.d1.loss_cls: 0.2539  decode.d1.loss_mask: 1.4511  decode.d1.loss_dice: 0.9482  decode.d2.loss_cls: 0.2817  decode.d2.loss_mask: 1.3992  decode.d2.loss_dice: 0.9093  decode.d3.loss_cls: 0.2556  decode.d3.loss_mask: 1.4108  decode.d3.loss_dice: 0.9373  decode.d4.loss_cls: 0.2542  decode.d4.loss_mask: 1.4339  decode.d4.loss_dice: 0.9738  decode.d5.loss_cls: 0.2286  decode.d5.loss_mask: 1.4193  decode.d5.loss_dice: 0.9581  decode.d6.loss_cls: 0.2265  decode.d6.loss_mask: 1.4218  decode.d6.loss_dice: 0.9567  decode.d7.loss_cls: 0.2266  decode.d7.loss_mask: 1.4309  decode.d7.loss_dice: 0.9513  decode.d8.loss_cls: 0.2285  decode.d8.loss_mask: 1.3964  decode.d8.loss_dice: 0.9506
05/26 18:33:24 - mmengine - INFO - Iter(train) [ 64750/160000]  base_lr: 6.2701e-05 lr: 6.2701e-06  eta: 10:53:31  time: 0.4161  data_time: 0.0097  memory: 5975  grad_norm: 743.3766  loss: 24.2445  decode.loss_cls: 0.3114  decode.loss_mask: 1.1714  decode.loss_dice: 0.8909  decode.d0.loss_cls: 0.8543  decode.d0.loss_mask: 1.1055  decode.d0.loss_dice: 0.8794  decode.d1.loss_cls: 0.3953  decode.d1.loss_mask: 1.0766  decode.d1.loss_dice: 0.8935  decode.d2.loss_cls: 0.3459  decode.d2.loss_mask: 1.1643  decode.d2.loss_dice: 0.8897  decode.d3.loss_cls: 0.2954  decode.d3.loss_mask: 1.1755  decode.d3.loss_dice: 0.8707  decode.d4.loss_cls: 0.3565  decode.d4.loss_mask: 1.1168  decode.d4.loss_dice: 0.8867  decode.d5.loss_cls: 0.3073  decode.d5.loss_mask: 1.1628  decode.d5.loss_dice: 0.8828  decode.d6.loss_cls: 0.3495  decode.d6.loss_mask: 1.1861  decode.d6.loss_dice: 0.8828  decode.d7.loss_cls: 0.3809  decode.d7.loss_mask: 1.1788  decode.d7.loss_dice: 0.9066  decode.d8.loss_cls: 0.3095  decode.d8.loss_mask: 1.1321  decode.d8.loss_dice: 0.8856
05/26 18:33:45 - mmengine - INFO - Iter(train) [ 64800/160000]  base_lr: 6.2671e-05 lr: 6.2671e-06  eta: 10:53:10  time: 0.4154  data_time: 0.0097  memory: 5970  grad_norm: 548.8754  loss: 21.8010  decode.loss_cls: 0.1335  decode.loss_mask: 1.1514  decode.loss_dice: 0.8243  decode.d0.loss_cls: 0.6903  decode.d0.loss_mask: 1.1128  decode.d0.loss_dice: 0.7752  decode.d1.loss_cls: 0.1650  decode.d1.loss_mask: 1.1451  decode.d1.loss_dice: 0.8136  decode.d2.loss_cls: 0.1483  decode.d2.loss_mask: 1.1571  decode.d2.loss_dice: 0.8073  decode.d3.loss_cls: 0.1803  decode.d3.loss_mask: 1.1625  decode.d3.loss_dice: 0.7935  decode.d4.loss_cls: 0.1770  decode.d4.loss_mask: 1.1316  decode.d4.loss_dice: 0.8297  decode.d5.loss_cls: 0.2058  decode.d5.loss_mask: 1.1634  decode.d5.loss_dice: 0.7962  decode.d6.loss_cls: 0.1959  decode.d6.loss_mask: 1.1394  decode.d6.loss_dice: 0.7988  decode.d7.loss_cls: 0.1904  decode.d7.loss_mask: 1.1603  decode.d7.loss_dice: 0.8437  decode.d8.loss_cls: 0.1716  decode.d8.loss_mask: 1.1364  decode.d8.loss_dice: 0.8006
05/26 18:34:06 - mmengine - INFO - Iter(train) [ 64850/160000]  base_lr: 6.2642e-05 lr: 6.2642e-06  eta: 10:52:50  time: 0.4143  data_time: 0.0097  memory: 5979  grad_norm: 761.0882  loss: 19.0361  decode.loss_cls: 0.1900  decode.loss_mask: 1.0291  decode.loss_dice: 0.6291  decode.d0.loss_cls: 0.6018  decode.d0.loss_mask: 1.0405  decode.d0.loss_dice: 0.6331  decode.d1.loss_cls: 0.1876  decode.d1.loss_mask: 1.0739  decode.d1.loss_dice: 0.6419  decode.d2.loss_cls: 0.1708  decode.d2.loss_mask: 1.0618  decode.d2.loss_dice: 0.6307  decode.d3.loss_cls: 0.1548  decode.d3.loss_mask: 1.0415  decode.d3.loss_dice: 0.6329  decode.d4.loss_cls: 0.1680  decode.d4.loss_mask: 1.0591  decode.d4.loss_dice: 0.6431  decode.d5.loss_cls: 0.1781  decode.d5.loss_mask: 1.0343  decode.d5.loss_dice: 0.6285  decode.d6.loss_cls: 0.1784  decode.d6.loss_mask: 1.0434  decode.d6.loss_dice: 0.6488  decode.d7.loss_cls: 0.1816  decode.d7.loss_mask: 1.0406  decode.d7.loss_dice: 0.6522  decode.d8.loss_cls: 0.1726  decode.d8.loss_mask: 1.0374  decode.d8.loss_dice: 0.6506
05/26 18:34:27 - mmengine - INFO - Iter(train) [ 64900/160000]  base_lr: 6.2612e-05 lr: 6.2612e-06  eta: 10:52:30  time: 0.4181  data_time: 0.0097  memory: 5967  grad_norm: 636.7689  loss: 18.8229  decode.loss_cls: 0.1306  decode.loss_mask: 0.9887  decode.loss_dice: 0.6712  decode.d0.loss_cls: 0.5335  decode.d0.loss_mask: 1.0190  decode.d0.loss_dice: 0.6719  decode.d1.loss_cls: 0.1738  decode.d1.loss_mask: 1.0436  decode.d1.loss_dice: 0.6926  decode.d2.loss_cls: 0.1400  decode.d2.loss_mask: 1.0230  decode.d2.loss_dice: 0.6851  decode.d3.loss_cls: 0.1436  decode.d3.loss_mask: 1.0283  decode.d3.loss_dice: 0.7019  decode.d4.loss_cls: 0.1448  decode.d4.loss_mask: 0.9955  decode.d4.loss_dice: 0.6718  decode.d5.loss_cls: 0.1437  decode.d5.loss_mask: 0.9949  decode.d5.loss_dice: 0.6963  decode.d6.loss_cls: 0.1454  decode.d6.loss_mask: 1.0187  decode.d6.loss_dice: 0.6932  decode.d7.loss_cls: 0.1324  decode.d7.loss_mask: 1.0258  decode.d7.loss_dice: 0.6993  decode.d8.loss_cls: 0.1175  decode.d8.loss_mask: 1.0130  decode.d8.loss_dice: 0.6838
05/26 18:34:48 - mmengine - INFO - Iter(train) [ 64950/160000]  base_lr: 6.2582e-05 lr: 6.2582e-06  eta: 10:52:09  time: 0.4157  data_time: 0.0097  memory: 5979  grad_norm: 520.2775  loss: 25.9330  decode.loss_cls: 0.2364  decode.loss_mask: 1.3138  decode.loss_dice: 0.9832  decode.d0.loss_cls: 0.8760  decode.d0.loss_mask: 1.1170  decode.d0.loss_dice: 0.8633  decode.d1.loss_cls: 0.3066  decode.d1.loss_mask: 1.3264  decode.d1.loss_dice: 0.9820  decode.d2.loss_cls: 0.2781  decode.d2.loss_mask: 1.3203  decode.d2.loss_dice: 0.9682  decode.d3.loss_cls: 0.2652  decode.d3.loss_mask: 1.3087  decode.d3.loss_dice: 0.9635  decode.d4.loss_cls: 0.2540  decode.d4.loss_mask: 1.3126  decode.d4.loss_dice: 0.9884  decode.d5.loss_cls: 0.2569  decode.d5.loss_mask: 1.3110  decode.d5.loss_dice: 0.9758  decode.d6.loss_cls: 0.2457  decode.d6.loss_mask: 1.3478  decode.d6.loss_dice: 1.0114  decode.d7.loss_cls: 0.2794  decode.d7.loss_mask: 1.3097  decode.d7.loss_dice: 0.9806  decode.d8.loss_cls: 0.2624  decode.d8.loss_mask: 1.3079  decode.d8.loss_dice: 0.9806
05/26 18:35:08 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 18:35:08 - mmengine - INFO - Iter(train) [ 65000/160000]  base_lr: 6.2553e-05 lr: 6.2553e-06  eta: 10:51:49  time: 0.4160  data_time: 0.0097  memory: 5973  grad_norm: 610.9038  loss: 20.5229  decode.loss_cls: 0.1982  decode.loss_mask: 1.0531  decode.loss_dice: 0.7398  decode.d0.loss_cls: 0.6407  decode.d0.loss_mask: 1.0190  decode.d0.loss_dice: 0.6944  decode.d1.loss_cls: 0.2042  decode.d1.loss_mask: 1.0557  decode.d1.loss_dice: 0.7272  decode.d2.loss_cls: 0.2449  decode.d2.loss_mask: 1.0742  decode.d2.loss_dice: 0.7194  decode.d3.loss_cls: 0.2318  decode.d3.loss_mask: 1.1078  decode.d3.loss_dice: 0.7315  decode.d4.loss_cls: 0.1969  decode.d4.loss_mask: 1.1529  decode.d4.loss_dice: 0.7470  decode.d5.loss_cls: 0.2141  decode.d5.loss_mask: 1.0477  decode.d5.loss_dice: 0.7237  decode.d6.loss_cls: 0.2100  decode.d6.loss_mask: 1.0836  decode.d6.loss_dice: 0.7193  decode.d7.loss_cls: 0.2117  decode.d7.loss_mask: 1.0521  decode.d7.loss_dice: 0.7439  decode.d8.loss_cls: 0.2421  decode.d8.loss_mask: 1.0147  decode.d8.loss_dice: 0.7210
05/26 18:35:08 - mmengine - INFO - Saving checkpoint at 65000 iterations
05/26 18:35:13 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:14  time: 0.0495  data_time: 0.0012  memory: 1391  
05/26 18:35:15 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:08  time: 0.0490  data_time: 0.0013  memory: 1205  
05/26 18:35:18 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:07  time: 0.0514  data_time: 0.0012  memory: 1596  
05/26 18:35:21 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:04  time: 0.0503  data_time: 0.0013  memory: 1298  
05/26 18:35:23 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:01:01  time: 0.0493  data_time: 0.0013  memory: 1298  
05/26 18:35:26 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:58  time: 0.0495  data_time: 0.0013  memory: 1279  
05/26 18:35:28 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:55  time: 0.0487  data_time: 0.0012  memory: 1224  
05/26 18:35:31 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:52  time: 0.0506  data_time: 0.0013  memory: 1298  
05/26 18:35:33 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:50  time: 0.0486  data_time: 0.0013  memory: 1298  
05/26 18:35:36 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:47  time: 0.0521  data_time: 0.0013  memory: 1725  
05/26 18:35:38 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:45  time: 0.0492  data_time: 0.0012  memory: 1336  
05/26 18:35:40 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:42  time: 0.0492  data_time: 0.0012  memory: 1298  
05/26 18:35:43 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:39  time: 0.0494  data_time: 0.0012  memory: 1205  
05/26 18:35:45 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:37  time: 0.0497  data_time: 0.0013  memory: 1316  
05/26 18:35:48 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:34  time: 0.0493  data_time: 0.0013  memory: 1279  
05/26 18:35:50 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:32  time: 0.0524  data_time: 0.0013  memory: 1410  
05/26 18:35:53 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:29  time: 0.0497  data_time: 0.0013  memory: 1279  
05/26 18:35:55 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:27  time: 0.0501  data_time: 0.0013  memory: 1205  
05/26 18:35:58 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0502  data_time: 0.0013  memory: 1205  
05/26 18:36:00 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:22  time: 0.0493  data_time: 0.0013  memory: 1336  
05/26 18:36:03 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0493  data_time: 0.0013  memory: 1246  
05/26 18:36:05 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0511  data_time: 0.0013  memory: 1503  
05/26 18:36:08 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0490  data_time: 0.0013  memory: 1261  
05/26 18:36:10 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0502  data_time: 0.0013  memory: 1298  
05/26 18:36:13 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0485  data_time: 0.0012  memory: 1447  
05/26 18:36:15 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0486  data_time: 0.0012  memory: 1298  
05/26 18:36:18 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0507  data_time: 0.0013  memory: 1279  
05/26 18:36:20 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0494  data_time: 0.0012  memory: 1205  
05/26 18:36:23 - mmengine - INFO - per class results:
05/26 18:36:23 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 94.91 | 96.35 |
|  aeroplane  |  92.4 | 95.35 |
|   bicycle   | 43.86 | 95.19 |
|     bird    | 95.21 | 98.04 |
|     boat    | 63.57 | 89.37 |
|    bottle   | 82.07 | 92.35 |
|     bus     | 93.87 | 96.56 |
|     car     | 88.02 | 96.97 |
|     cat     | 95.67 | 98.32 |
|    chair    | 32.69 |  70.9 |
|     cow     | 73.58 | 78.63 |
| diningtable | 58.36 |  70.7 |
|     dog     | 89.18 | 98.12 |
|    horse    | 78.21 |  92.9 |
|  motorbike  | 91.04 | 94.89 |
|    person   | 90.34 | 95.15 |
| pottedplant |  62.9 | 94.12 |
|    sheep    | 83.97 | 89.97 |
|     sofa    | 53.37 | 67.78 |
|    train    | 89.89 | 92.64 |
|  tvmonitor  | 81.04 | 90.29 |
+-------------+-------+-------+
05/26 18:36:23 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 94.9600  mIoU: 77.8200  mAcc: 90.2200  data_time: 0.0013  time: 0.0498
05/26 18:36:43 - mmengine - INFO - Iter(train) [ 65050/160000]  base_lr: 6.2523e-05 lr: 6.2523e-06  eta: 10:51:29  time: 0.4150  data_time: 0.0096  memory: 5971  grad_norm: 609.8981  loss: 20.0031  decode.loss_cls: 0.1657  decode.loss_mask: 1.0215  decode.loss_dice: 0.7108  decode.d0.loss_cls: 0.7138  decode.d0.loss_mask: 0.9878  decode.d0.loss_dice: 0.7174  decode.d1.loss_cls: 0.2471  decode.d1.loss_mask: 1.0047  decode.d1.loss_dice: 0.7083  decode.d2.loss_cls: 0.2381  decode.d2.loss_mask: 1.0418  decode.d2.loss_dice: 0.7395  decode.d3.loss_cls: 0.2054  decode.d3.loss_mask: 1.0483  decode.d3.loss_dice: 0.7197  decode.d4.loss_cls: 0.2039  decode.d4.loss_mask: 1.0224  decode.d4.loss_dice: 0.7185  decode.d5.loss_cls: 0.2183  decode.d5.loss_mask: 1.0334  decode.d5.loss_dice: 0.7319  decode.d6.loss_cls: 0.2500  decode.d6.loss_mask: 0.9788  decode.d6.loss_dice: 0.7195  decode.d7.loss_cls: 0.1913  decode.d7.loss_mask: 1.0351  decode.d7.loss_dice: 0.7078  decode.d8.loss_cls: 0.2129  decode.d8.loss_mask: 1.0204  decode.d8.loss_dice: 0.6888
05/26 18:37:04 - mmengine - INFO - Iter(train) [ 65100/160000]  base_lr: 6.2493e-05 lr: 6.2493e-06  eta: 10:51:08  time: 0.4140  data_time: 0.0096  memory: 5967  grad_norm: 412.9119  loss: 20.2046  decode.loss_cls: 0.1783  decode.loss_mask: 1.0603  decode.loss_dice: 0.7151  decode.d0.loss_cls: 0.6419  decode.d0.loss_mask: 1.0495  decode.d0.loss_dice: 0.7339  decode.d1.loss_cls: 0.1873  decode.d1.loss_mask: 1.0722  decode.d1.loss_dice: 0.7209  decode.d2.loss_cls: 0.2176  decode.d2.loss_mask: 1.0426  decode.d2.loss_dice: 0.7083  decode.d3.loss_cls: 0.1971  decode.d3.loss_mask: 1.0563  decode.d3.loss_dice: 0.7278  decode.d4.loss_cls: 0.2293  decode.d4.loss_mask: 1.0560  decode.d4.loss_dice: 0.7009  decode.d5.loss_cls: 0.1874  decode.d5.loss_mask: 1.0619  decode.d5.loss_dice: 0.7338  decode.d6.loss_cls: 0.1909  decode.d6.loss_mask: 1.0627  decode.d6.loss_dice: 0.7256  decode.d7.loss_cls: 0.2430  decode.d7.loss_mask: 1.0548  decode.d7.loss_dice: 0.7229  decode.d8.loss_cls: 0.1560  decode.d8.loss_mask: 1.0598  decode.d8.loss_dice: 0.7105
05/26 18:37:25 - mmengine - INFO - Iter(train) [ 65150/160000]  base_lr: 6.2464e-05 lr: 6.2464e-06  eta: 10:50:48  time: 0.4152  data_time: 0.0097  memory: 5980  grad_norm: 1314.6913  loss: 24.2241  decode.loss_cls: 0.3090  decode.loss_mask: 1.1998  decode.loss_dice: 0.9005  decode.d0.loss_cls: 0.8259  decode.d0.loss_mask: 1.1282  decode.d0.loss_dice: 0.8334  decode.d1.loss_cls: 0.2620  decode.d1.loss_mask: 1.2268  decode.d1.loss_dice: 0.8986  decode.d2.loss_cls: 0.3051  decode.d2.loss_mask: 1.2089  decode.d2.loss_dice: 0.8893  decode.d3.loss_cls: 0.2759  decode.d3.loss_mask: 1.1889  decode.d3.loss_dice: 0.8624  decode.d4.loss_cls: 0.2862  decode.d4.loss_mask: 1.1904  decode.d4.loss_dice: 0.8608  decode.d5.loss_cls: 0.2865  decode.d5.loss_mask: 1.1928  decode.d5.loss_dice: 0.8902  decode.d6.loss_cls: 0.2911  decode.d6.loss_mask: 1.2221  decode.d6.loss_dice: 0.9030  decode.d7.loss_cls: 0.2899  decode.d7.loss_mask: 1.1977  decode.d7.loss_dice: 0.8850  decode.d8.loss_cls: 0.2980  decode.d8.loss_mask: 1.2131  decode.d8.loss_dice: 0.9028
05/26 18:37:46 - mmengine - INFO - Iter(train) [ 65200/160000]  base_lr: 6.2434e-05 lr: 6.2434e-06  eta: 10:50:28  time: 0.4141  data_time: 0.0096  memory: 5979  grad_norm: 432.9871  loss: 21.9636  decode.loss_cls: 0.2110  decode.loss_mask: 1.0221  decode.loss_dice: 0.8570  decode.d0.loss_cls: 0.7064  decode.d0.loss_mask: 1.0408  decode.d0.loss_dice: 0.8694  decode.d1.loss_cls: 0.2720  decode.d1.loss_mask: 1.0377  decode.d1.loss_dice: 0.8684  decode.d2.loss_cls: 0.2993  decode.d2.loss_mask: 1.0460  decode.d2.loss_dice: 0.8350  decode.d3.loss_cls: 0.2469  decode.d3.loss_mask: 1.0379  decode.d3.loss_dice: 0.8561  decode.d4.loss_cls: 0.2064  decode.d4.loss_mask: 1.0439  decode.d4.loss_dice: 0.8821  decode.d5.loss_cls: 0.2640  decode.d5.loss_mask: 1.0382  decode.d5.loss_dice: 0.8737  decode.d6.loss_cls: 0.2652  decode.d6.loss_mask: 1.0445  decode.d6.loss_dice: 0.8503  decode.d7.loss_cls: 0.2514  decode.d7.loss_mask: 1.0419  decode.d7.loss_dice: 0.8622  decode.d8.loss_cls: 0.2347  decode.d8.loss_mask: 1.0469  decode.d8.loss_dice: 0.8523
05/26 18:38:07 - mmengine - INFO - Iter(train) [ 65250/160000]  base_lr: 6.2404e-05 lr: 6.2404e-06  eta: 10:50:07  time: 0.4135  data_time: 0.0095  memory: 5967  grad_norm: 1565.3225  loss: 22.3973  decode.loss_cls: 0.2450  decode.loss_mask: 1.1848  decode.loss_dice: 0.7783  decode.d0.loss_cls: 0.7509  decode.d0.loss_mask: 1.0869  decode.d0.loss_dice: 0.7241  decode.d1.loss_cls: 0.3129  decode.d1.loss_mask: 1.1269  decode.d1.loss_dice: 0.7739  decode.d2.loss_cls: 0.2746  decode.d2.loss_mask: 1.1182  decode.d2.loss_dice: 0.7555  decode.d3.loss_cls: 0.2936  decode.d3.loss_mask: 1.0992  decode.d3.loss_dice: 0.7284  decode.d4.loss_cls: 0.2714  decode.d4.loss_mask: 1.1667  decode.d4.loss_dice: 0.7811  decode.d5.loss_cls: 0.2883  decode.d5.loss_mask: 1.1973  decode.d5.loss_dice: 0.7818  decode.d6.loss_cls: 0.2860  decode.d6.loss_mask: 1.1784  decode.d6.loss_dice: 0.8084  decode.d7.loss_cls: 0.2640  decode.d7.loss_mask: 1.1637  decode.d7.loss_dice: 0.7691  decode.d8.loss_cls: 0.2583  decode.d8.loss_mask: 1.1568  decode.d8.loss_dice: 0.7727
05/26 18:38:27 - mmengine - INFO - Iter(train) [ 65300/160000]  base_lr: 6.2375e-05 lr: 6.2375e-06  eta: 10:49:47  time: 0.4146  data_time: 0.0096  memory: 5974  grad_norm: 547.2430  loss: 18.8281  decode.loss_cls: 0.2379  decode.loss_mask: 0.9490  decode.loss_dice: 0.6875  decode.d0.loss_cls: 0.5922  decode.d0.loss_mask: 0.8931  decode.d0.loss_dice: 0.6966  decode.d1.loss_cls: 0.2442  decode.d1.loss_mask: 0.9307  decode.d1.loss_dice: 0.6754  decode.d2.loss_cls: 0.2439  decode.d2.loss_mask: 0.9288  decode.d2.loss_dice: 0.6808  decode.d3.loss_cls: 0.2252  decode.d3.loss_mask: 0.9262  decode.d3.loss_dice: 0.6854  decode.d4.loss_cls: 0.2164  decode.d4.loss_mask: 0.9542  decode.d4.loss_dice: 0.6870  decode.d5.loss_cls: 0.1895  decode.d5.loss_mask: 0.9631  decode.d5.loss_dice: 0.6972  decode.d6.loss_cls: 0.1915  decode.d6.loss_mask: 0.9554  decode.d6.loss_dice: 0.6927  decode.d7.loss_cls: 0.2168  decode.d7.loss_mask: 0.9251  decode.d7.loss_dice: 0.6595  decode.d8.loss_cls: 0.2284  decode.d8.loss_mask: 0.9663  decode.d8.loss_dice: 0.6883
05/26 18:38:48 - mmengine - INFO - Iter(train) [ 65350/160000]  base_lr: 6.2345e-05 lr: 6.2345e-06  eta: 10:49:27  time: 0.4156  data_time: 0.0097  memory: 5966  grad_norm: 438.8522  loss: 21.4676  decode.loss_cls: 0.1882  decode.loss_mask: 1.0726  decode.loss_dice: 0.8179  decode.d0.loss_cls: 0.7078  decode.d0.loss_mask: 1.0038  decode.d0.loss_dice: 0.8100  decode.d1.loss_cls: 0.2019  decode.d1.loss_mask: 1.0471  decode.d1.loss_dice: 0.7935  decode.d2.loss_cls: 0.2280  decode.d2.loss_mask: 1.0454  decode.d2.loss_dice: 0.8059  decode.d3.loss_cls: 0.2448  decode.d3.loss_mask: 1.0828  decode.d3.loss_dice: 0.8163  decode.d4.loss_cls: 0.2674  decode.d4.loss_mask: 1.0850  decode.d4.loss_dice: 0.8370  decode.d5.loss_cls: 0.2465  decode.d5.loss_mask: 1.0508  decode.d5.loss_dice: 0.8330  decode.d6.loss_cls: 0.2543  decode.d6.loss_mask: 1.0615  decode.d6.loss_dice: 0.8060  decode.d7.loss_cls: 0.2001  decode.d7.loss_mask: 1.0709  decode.d7.loss_dice: 0.8273  decode.d8.loss_cls: 0.1828  decode.d8.loss_mask: 1.0658  decode.d8.loss_dice: 0.8133
05/26 18:39:09 - mmengine - INFO - Iter(train) [ 65400/160000]  base_lr: 6.2316e-05 lr: 6.2316e-06  eta: 10:49:06  time: 0.4172  data_time: 0.0096  memory: 5967  grad_norm: 688.3658  loss: 21.1459  decode.loss_cls: 0.2242  decode.loss_mask: 1.0520  decode.loss_dice: 0.7992  decode.d0.loss_cls: 0.8329  decode.d0.loss_mask: 0.9772  decode.d0.loss_dice: 0.7582  decode.d1.loss_cls: 0.2477  decode.d1.loss_mask: 1.0196  decode.d1.loss_dice: 0.7742  decode.d2.loss_cls: 0.2236  decode.d2.loss_mask: 1.0324  decode.d2.loss_dice: 0.7799  decode.d3.loss_cls: 0.2163  decode.d3.loss_mask: 1.0349  decode.d3.loss_dice: 0.7846  decode.d4.loss_cls: 0.2430  decode.d4.loss_mask: 1.0357  decode.d4.loss_dice: 0.7798  decode.d5.loss_cls: 0.2396  decode.d5.loss_mask: 1.0417  decode.d5.loss_dice: 0.7928  decode.d6.loss_cls: 0.2638  decode.d6.loss_mask: 1.0384  decode.d6.loss_dice: 0.8033  decode.d7.loss_cls: 0.2735  decode.d7.loss_mask: 1.0261  decode.d7.loss_dice: 0.7890  decode.d8.loss_cls: 0.2416  decode.d8.loss_mask: 1.0380  decode.d8.loss_dice: 0.7826
05/26 18:39:30 - mmengine - INFO - Iter(train) [ 65450/160000]  base_lr: 6.2286e-05 lr: 6.2286e-06  eta: 10:48:46  time: 0.4163  data_time: 0.0096  memory: 5974  grad_norm: 589.9588  loss: 17.4037  decode.loss_cls: 0.1189  decode.loss_mask: 0.8827  decode.loss_dice: 0.6781  decode.d0.loss_cls: 0.6679  decode.d0.loss_mask: 0.8254  decode.d0.loss_dice: 0.6228  decode.d1.loss_cls: 0.1403  decode.d1.loss_mask: 0.8756  decode.d1.loss_dice: 0.6771  decode.d2.loss_cls: 0.1533  decode.d2.loss_mask: 0.8657  decode.d2.loss_dice: 0.6531  decode.d3.loss_cls: 0.1552  decode.d3.loss_mask: 0.9135  decode.d3.loss_dice: 0.6767  decode.d4.loss_cls: 0.1772  decode.d4.loss_mask: 0.8811  decode.d4.loss_dice: 0.6683  decode.d5.loss_cls: 0.1660  decode.d5.loss_mask: 0.8766  decode.d5.loss_dice: 0.6732  decode.d6.loss_cls: 0.1694  decode.d6.loss_mask: 0.8814  decode.d6.loss_dice: 0.6539  decode.d7.loss_cls: 0.1264  decode.d7.loss_mask: 0.8823  decode.d7.loss_dice: 0.6855  decode.d8.loss_cls: 0.1366  decode.d8.loss_mask: 0.8647  decode.d8.loss_dice: 0.6550
05/26 18:39:50 - mmengine - INFO - Iter(train) [ 65500/160000]  base_lr: 6.2256e-05 lr: 6.2256e-06  eta: 10:48:26  time: 0.4164  data_time: 0.0103  memory: 5966  grad_norm: 506.1998  loss: 23.4799  decode.loss_cls: 0.1919  decode.loss_mask: 1.1120  decode.loss_dice: 0.9927  decode.d0.loss_cls: 0.6783  decode.d0.loss_mask: 1.0639  decode.d0.loss_dice: 0.9493  decode.d1.loss_cls: 0.2541  decode.d1.loss_mask: 1.0913  decode.d1.loss_dice: 0.9675  decode.d2.loss_cls: 0.2340  decode.d2.loss_mask: 1.0858  decode.d2.loss_dice: 0.9542  decode.d3.loss_cls: 0.2292  decode.d3.loss_mask: 1.0963  decode.d3.loss_dice: 0.9679  decode.d4.loss_cls: 0.2469  decode.d4.loss_mask: 1.0826  decode.d4.loss_dice: 0.9924  decode.d5.loss_cls: 0.2320  decode.d5.loss_mask: 1.0766  decode.d5.loss_dice: 0.9963  decode.d6.loss_cls: 0.2534  decode.d6.loss_mask: 1.0944  decode.d6.loss_dice: 0.9909  decode.d7.loss_cls: 0.1900  decode.d7.loss_mask: 1.1763  decode.d7.loss_dice: 0.9918  decode.d8.loss_cls: 0.2101  decode.d8.loss_mask: 1.0940  decode.d8.loss_dice: 0.9839
05/26 18:40:11 - mmengine - INFO - Iter(train) [ 65550/160000]  base_lr: 6.2227e-05 lr: 6.2227e-06  eta: 10:48:06  time: 0.4144  data_time: 0.0096  memory: 5968  grad_norm: 550.6468  loss: 20.9474  decode.loss_cls: 0.1931  decode.loss_mask: 1.1031  decode.loss_dice: 0.7881  decode.d0.loss_cls: 0.6700  decode.d0.loss_mask: 1.0869  decode.d0.loss_dice: 0.7314  decode.d1.loss_cls: 0.1839  decode.d1.loss_mask: 1.1197  decode.d1.loss_dice: 0.7946  decode.d2.loss_cls: 0.1742  decode.d2.loss_mask: 1.0744  decode.d2.loss_dice: 0.7349  decode.d3.loss_cls: 0.2005  decode.d3.loss_mask: 1.0908  decode.d3.loss_dice: 0.7296  decode.d4.loss_cls: 0.1717  decode.d4.loss_mask: 1.0920  decode.d4.loss_dice: 0.7466  decode.d5.loss_cls: 0.1605  decode.d5.loss_mask: 1.0975  decode.d5.loss_dice: 0.7400  decode.d6.loss_cls: 0.2033  decode.d6.loss_mask: 1.1201  decode.d6.loss_dice: 0.7701  decode.d7.loss_cls: 0.2242  decode.d7.loss_mask: 1.0963  decode.d7.loss_dice: 0.7770  decode.d8.loss_cls: 0.1870  decode.d8.loss_mask: 1.1141  decode.d8.loss_dice: 0.7715
05/26 18:40:32 - mmengine - INFO - Iter(train) [ 65600/160000]  base_lr: 6.2197e-05 lr: 6.2197e-06  eta: 10:47:45  time: 0.4144  data_time: 0.0096  memory: 5968  grad_norm: 1527.3266  loss: 21.2279  decode.loss_cls: 0.2200  decode.loss_mask: 1.0830  decode.loss_dice: 0.7546  decode.d0.loss_cls: 0.7269  decode.d0.loss_mask: 0.9614  decode.d0.loss_dice: 0.6894  decode.d1.loss_cls: 0.2616  decode.d1.loss_mask: 1.0975  decode.d1.loss_dice: 0.7827  decode.d2.loss_cls: 0.2301  decode.d2.loss_mask: 1.0503  decode.d2.loss_dice: 0.7931  decode.d3.loss_cls: 0.2152  decode.d3.loss_mask: 1.0488  decode.d3.loss_dice: 0.7712  decode.d4.loss_cls: 0.2064  decode.d4.loss_mask: 1.0970  decode.d4.loss_dice: 0.8086  decode.d5.loss_cls: 0.2000  decode.d5.loss_mask: 1.1301  decode.d5.loss_dice: 0.8081  decode.d6.loss_cls: 0.2365  decode.d6.loss_mask: 1.1109  decode.d6.loss_dice: 0.8100  decode.d7.loss_cls: 0.2353  decode.d7.loss_mask: 1.0622  decode.d7.loss_dice: 0.7695  decode.d8.loss_cls: 0.2336  decode.d8.loss_mask: 1.0612  decode.d8.loss_dice: 0.7729
05/26 18:40:53 - mmengine - INFO - Iter(train) [ 65650/160000]  base_lr: 6.2167e-05 lr: 6.2167e-06  eta: 10:47:25  time: 0.4147  data_time: 0.0096  memory: 5965  grad_norm: 486.8922  loss: 21.4399  decode.loss_cls: 0.1945  decode.loss_mask: 1.1544  decode.loss_dice: 0.7365  decode.d0.loss_cls: 0.6687  decode.d0.loss_mask: 1.0933  decode.d0.loss_dice: 0.7402  decode.d1.loss_cls: 0.2442  decode.d1.loss_mask: 1.1261  decode.d1.loss_dice: 0.7198  decode.d2.loss_cls: 0.2341  decode.d2.loss_mask: 1.1240  decode.d2.loss_dice: 0.7399  decode.d3.loss_cls: 0.2415  decode.d3.loss_mask: 1.1339  decode.d3.loss_dice: 0.7386  decode.d4.loss_cls: 0.2540  decode.d4.loss_mask: 1.1222  decode.d4.loss_dice: 0.7247  decode.d5.loss_cls: 0.2250  decode.d5.loss_mask: 1.1154  decode.d5.loss_dice: 0.7381  decode.d6.loss_cls: 0.2142  decode.d6.loss_mask: 1.1670  decode.d6.loss_dice: 0.7335  decode.d7.loss_cls: 0.2287  decode.d7.loss_mask: 1.1681  decode.d7.loss_dice: 0.7317  decode.d8.loss_cls: 0.2298  decode.d8.loss_mask: 1.1815  decode.d8.loss_dice: 0.7164
05/26 18:41:13 - mmengine - INFO - Iter(train) [ 65700/160000]  base_lr: 6.2138e-05 lr: 6.2138e-06  eta: 10:47:04  time: 0.4140  data_time: 0.0096  memory: 5970  grad_norm: 558.1201  loss: 25.2885  decode.loss_cls: 0.2357  decode.loss_mask: 1.2086  decode.loss_dice: 0.9883  decode.d0.loss_cls: 0.7299  decode.d0.loss_mask: 1.1921  decode.d0.loss_dice: 0.9618  decode.d1.loss_cls: 0.2520  decode.d1.loss_mask: 1.2471  decode.d1.loss_dice: 0.9987  decode.d2.loss_cls: 0.2561  decode.d2.loss_mask: 1.2476  decode.d2.loss_dice: 1.0214  decode.d3.loss_cls: 0.2278  decode.d3.loss_mask: 1.2228  decode.d3.loss_dice: 0.9887  decode.d4.loss_cls: 0.2527  decode.d4.loss_mask: 1.2569  decode.d4.loss_dice: 1.0154  decode.d5.loss_cls: 0.2523  decode.d5.loss_mask: 1.2564  decode.d5.loss_dice: 0.9903  decode.d6.loss_cls: 0.2592  decode.d6.loss_mask: 1.2366  decode.d6.loss_dice: 0.9950  decode.d7.loss_cls: 0.2377  decode.d7.loss_mask: 1.2528  decode.d7.loss_dice: 1.0147  decode.d8.loss_cls: 0.2668  decode.d8.loss_mask: 1.2443  decode.d8.loss_dice: 0.9788
05/26 18:41:34 - mmengine - INFO - Iter(train) [ 65750/160000]  base_lr: 6.2108e-05 lr: 6.2108e-06  eta: 10:46:44  time: 0.4146  data_time: 0.0097  memory: 5968  grad_norm: 934.2150  loss: 25.8297  decode.loss_cls: 0.2731  decode.loss_mask: 1.2964  decode.loss_dice: 0.9652  decode.d0.loss_cls: 0.7783  decode.d0.loss_mask: 1.2474  decode.d0.loss_dice: 0.9273  decode.d1.loss_cls: 0.2742  decode.d1.loss_mask: 1.3344  decode.d1.loss_dice: 0.9792  decode.d2.loss_cls: 0.2480  decode.d2.loss_mask: 1.2734  decode.d2.loss_dice: 0.9484  decode.d3.loss_cls: 0.2903  decode.d3.loss_mask: 1.3233  decode.d3.loss_dice: 0.9716  decode.d4.loss_cls: 0.2765  decode.d4.loss_mask: 1.3067  decode.d4.loss_dice: 0.9799  decode.d5.loss_cls: 0.2701  decode.d5.loss_mask: 1.2756  decode.d5.loss_dice: 0.9523  decode.d6.loss_cls: 0.2104  decode.d6.loss_mask: 1.3181  decode.d6.loss_dice: 0.9830  decode.d7.loss_cls: 0.2368  decode.d7.loss_mask: 1.3221  decode.d7.loss_dice: 0.9949  decode.d8.loss_cls: 0.2511  decode.d8.loss_mask: 1.3303  decode.d8.loss_dice: 0.9916
05/26 18:41:55 - mmengine - INFO - Iter(train) [ 65800/160000]  base_lr: 6.2078e-05 lr: 6.2078e-06  eta: 10:46:24  time: 0.4136  data_time: 0.0097  memory: 5981  grad_norm: 656.8358  loss: 25.7962  decode.loss_cls: 0.2902  decode.loss_mask: 1.2985  decode.loss_dice: 0.9523  decode.d0.loss_cls: 0.7804  decode.d0.loss_mask: 1.2339  decode.d0.loss_dice: 0.9170  decode.d1.loss_cls: 0.3113  decode.d1.loss_mask: 1.2832  decode.d1.loss_dice: 0.9824  decode.d2.loss_cls: 0.2860  decode.d2.loss_mask: 1.2582  decode.d2.loss_dice: 0.9437  decode.d3.loss_cls: 0.2960  decode.d3.loss_mask: 1.2462  decode.d3.loss_dice: 0.9349  decode.d4.loss_cls: 0.3019  decode.d4.loss_mask: 1.2726  decode.d4.loss_dice: 0.9667  decode.d5.loss_cls: 0.2831  decode.d5.loss_mask: 1.2671  decode.d5.loss_dice: 0.9509  decode.d6.loss_cls: 0.3320  decode.d6.loss_mask: 1.2624  decode.d6.loss_dice: 0.9616  decode.d7.loss_cls: 0.2665  decode.d7.loss_mask: 1.3432  decode.d7.loss_dice: 1.0067  decode.d8.loss_cls: 0.2424  decode.d8.loss_mask: 1.3486  decode.d8.loss_dice: 0.9763
05/26 18:42:16 - mmengine - INFO - Iter(train) [ 65850/160000]  base_lr: 6.2049e-05 lr: 6.2049e-06  eta: 10:46:03  time: 0.4149  data_time: 0.0096  memory: 5976  grad_norm: 924.2913  loss: 22.1169  decode.loss_cls: 0.3105  decode.loss_mask: 1.0503  decode.loss_dice: 0.8010  decode.d0.loss_cls: 0.7383  decode.d0.loss_mask: 1.0304  decode.d0.loss_dice: 0.7828  decode.d1.loss_cls: 0.3226  decode.d1.loss_mask: 1.0544  decode.d1.loss_dice: 0.7741  decode.d2.loss_cls: 0.2888  decode.d2.loss_mask: 1.0614  decode.d2.loss_dice: 0.7854  decode.d3.loss_cls: 0.3088  decode.d3.loss_mask: 1.0624  decode.d3.loss_dice: 0.8173  decode.d4.loss_cls: 0.3326  decode.d4.loss_mask: 1.0720  decode.d4.loss_dice: 0.8024  decode.d5.loss_cls: 0.2897  decode.d5.loss_mask: 1.0383  decode.d5.loss_dice: 0.7996  decode.d6.loss_cls: 0.2563  decode.d6.loss_mask: 1.0426  decode.d6.loss_dice: 0.8110  decode.d7.loss_cls: 0.3109  decode.d7.loss_mask: 1.0807  decode.d7.loss_dice: 0.8450  decode.d8.loss_cls: 0.3263  decode.d8.loss_mask: 1.1033  decode.d8.loss_dice: 0.8175
05/26 18:42:37 - mmengine - INFO - Iter(train) [ 65900/160000]  base_lr: 6.2019e-05 lr: 6.2019e-06  eta: 10:45:43  time: 0.4144  data_time: 0.0096  memory: 5981  grad_norm: 889.5627  loss: 23.5614  decode.loss_cls: 0.2787  decode.loss_mask: 1.1814  decode.loss_dice: 0.8385  decode.d0.loss_cls: 0.7082  decode.d0.loss_mask: 1.0981  decode.d0.loss_dice: 0.7898  decode.d1.loss_cls: 0.2836  decode.d1.loss_mask: 1.2099  decode.d1.loss_dice: 0.8435  decode.d2.loss_cls: 0.2490  decode.d2.loss_mask: 1.2193  decode.d2.loss_dice: 0.8607  decode.d3.loss_cls: 0.2740  decode.d3.loss_mask: 1.1792  decode.d3.loss_dice: 0.8482  decode.d4.loss_cls: 0.2732  decode.d4.loss_mask: 1.2165  decode.d4.loss_dice: 0.8634  decode.d5.loss_cls: 0.2824  decode.d5.loss_mask: 1.2108  decode.d5.loss_dice: 0.8764  decode.d6.loss_cls: 0.3258  decode.d6.loss_mask: 1.1948  decode.d6.loss_dice: 0.8430  decode.d7.loss_cls: 0.2692  decode.d7.loss_mask: 1.2000  decode.d7.loss_dice: 0.8403  decode.d8.loss_cls: 0.2785  decode.d8.loss_mask: 1.1936  decode.d8.loss_dice: 0.8315
05/26 18:42:57 - mmengine - INFO - Iter(train) [ 65950/160000]  base_lr: 6.1989e-05 lr: 6.1989e-06  eta: 10:45:23  time: 0.4126  data_time: 0.0095  memory: 5966  grad_norm: 614.7468  loss: 22.9699  decode.loss_cls: 0.2831  decode.loss_mask: 1.0863  decode.loss_dice: 0.9181  decode.d0.loss_cls: 0.7426  decode.d0.loss_mask: 1.0551  decode.d0.loss_dice: 0.8590  decode.d1.loss_cls: 0.2948  decode.d1.loss_mask: 1.0696  decode.d1.loss_dice: 0.9265  decode.d2.loss_cls: 0.2900  decode.d2.loss_mask: 1.0791  decode.d2.loss_dice: 0.8914  decode.d3.loss_cls: 0.2617  decode.d3.loss_mask: 1.0857  decode.d3.loss_dice: 0.9217  decode.d4.loss_cls: 0.2799  decode.d4.loss_mask: 1.0625  decode.d4.loss_dice: 0.8983  decode.d5.loss_cls: 0.2712  decode.d5.loss_mask: 1.0534  decode.d5.loss_dice: 0.9276  decode.d6.loss_cls: 0.2832  decode.d6.loss_mask: 1.0620  decode.d6.loss_dice: 0.9021  decode.d7.loss_cls: 0.2869  decode.d7.loss_mask: 1.0584  decode.d7.loss_dice: 0.8925  decode.d8.loss_cls: 0.2653  decode.d8.loss_mask: 1.0660  decode.d8.loss_dice: 0.8960
05/26 18:43:18 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 18:43:18 - mmengine - INFO - Iter(train) [ 66000/160000]  base_lr: 6.1960e-05 lr: 6.1960e-06  eta: 10:45:02  time: 0.4149  data_time: 0.0096  memory: 5982  grad_norm: 655.3051  loss: 22.8627  decode.loss_cls: 0.1835  decode.loss_mask: 1.2144  decode.loss_dice: 0.8305  decode.d0.loss_cls: 0.6441  decode.d0.loss_mask: 1.2249  decode.d0.loss_dice: 0.8346  decode.d1.loss_cls: 0.1897  decode.d1.loss_mask: 1.2074  decode.d1.loss_dice: 0.8098  decode.d2.loss_cls: 0.1802  decode.d2.loss_mask: 1.2331  decode.d2.loss_dice: 0.8336  decode.d3.loss_cls: 0.1768  decode.d3.loss_mask: 1.2388  decode.d3.loss_dice: 0.8280  decode.d4.loss_cls: 0.1934  decode.d4.loss_mask: 1.2125  decode.d4.loss_dice: 0.8188  decode.d5.loss_cls: 0.1962  decode.d5.loss_mask: 1.2352  decode.d5.loss_dice: 0.8450  decode.d6.loss_cls: 0.2031  decode.d6.loss_mask: 1.2535  decode.d6.loss_dice: 0.8363  decode.d7.loss_cls: 0.1800  decode.d7.loss_mask: 1.2180  decode.d7.loss_dice: 0.8218  decode.d8.loss_cls: 0.1706  decode.d8.loss_mask: 1.2281  decode.d8.loss_dice: 0.8206
05/26 18:43:39 - mmengine - INFO - Iter(train) [ 66050/160000]  base_lr: 6.1930e-05 lr: 6.1930e-06  eta: 10:44:42  time: 0.4138  data_time: 0.0096  memory: 5981  grad_norm: 612.2067  loss: 25.8813  decode.loss_cls: 0.2249  decode.loss_mask: 1.3814  decode.loss_dice: 0.9672  decode.d0.loss_cls: 0.7441  decode.d0.loss_mask: 1.3013  decode.d0.loss_dice: 0.9053  decode.d1.loss_cls: 0.2593  decode.d1.loss_mask: 1.3524  decode.d1.loss_dice: 0.9064  decode.d2.loss_cls: 0.2663  decode.d2.loss_mask: 1.4160  decode.d2.loss_dice: 0.9226  decode.d3.loss_cls: 0.2334  decode.d3.loss_mask: 1.4140  decode.d3.loss_dice: 0.9117  decode.d4.loss_cls: 0.2534  decode.d4.loss_mask: 1.3768  decode.d4.loss_dice: 0.9387  decode.d5.loss_cls: 0.2640  decode.d5.loss_mask: 1.3699  decode.d5.loss_dice: 0.9002  decode.d6.loss_cls: 0.2667  decode.d6.loss_mask: 1.3165  decode.d6.loss_dice: 0.9186  decode.d7.loss_cls: 0.2438  decode.d7.loss_mask: 1.4076  decode.d7.loss_dice: 0.9247  decode.d8.loss_cls: 0.2299  decode.d8.loss_mask: 1.3526  decode.d8.loss_dice: 0.9115
05/26 18:43:59 - mmengine - INFO - Iter(train) [ 66100/160000]  base_lr: 6.1900e-05 lr: 6.1900e-06  eta: 10:44:21  time: 0.4150  data_time: 0.0096  memory: 5973  grad_norm: 531.3489  loss: 22.6751  decode.loss_cls: 0.1762  decode.loss_mask: 1.2336  decode.loss_dice: 0.8508  decode.d0.loss_cls: 0.6897  decode.d0.loss_mask: 1.1308  decode.d0.loss_dice: 0.7446  decode.d1.loss_cls: 0.1965  decode.d1.loss_mask: 1.2036  decode.d1.loss_dice: 0.8398  decode.d2.loss_cls: 0.2188  decode.d2.loss_mask: 1.1496  decode.d2.loss_dice: 0.8048  decode.d3.loss_cls: 0.2079  decode.d3.loss_mask: 1.1902  decode.d3.loss_dice: 0.8220  decode.d4.loss_cls: 0.1877  decode.d4.loss_mask: 1.2122  decode.d4.loss_dice: 0.8279  decode.d5.loss_cls: 0.2577  decode.d5.loss_mask: 1.1614  decode.d5.loss_dice: 0.8146  decode.d6.loss_cls: 0.2134  decode.d6.loss_mask: 1.2295  decode.d6.loss_dice: 0.8310  decode.d7.loss_cls: 0.1683  decode.d7.loss_mask: 1.2323  decode.d7.loss_dice: 0.8551  decode.d8.loss_cls: 0.1736  decode.d8.loss_mask: 1.2176  decode.d8.loss_dice: 0.8341
05/26 18:44:20 - mmengine - INFO - Iter(train) [ 66150/160000]  base_lr: 6.1871e-05 lr: 6.1871e-06  eta: 10:44:01  time: 0.4137  data_time: 0.0097  memory: 5974  grad_norm: 612.1390  loss: 19.8569  decode.loss_cls: 0.1625  decode.loss_mask: 1.0139  decode.loss_dice: 0.7567  decode.d0.loss_cls: 0.6139  decode.d0.loss_mask: 0.9593  decode.d0.loss_dice: 0.7172  decode.d1.loss_cls: 0.2410  decode.d1.loss_mask: 0.9691  decode.d1.loss_dice: 0.7153  decode.d2.loss_cls: 0.2190  decode.d2.loss_mask: 0.9906  decode.d2.loss_dice: 0.7832  decode.d3.loss_cls: 0.1937  decode.d3.loss_mask: 0.9823  decode.d3.loss_dice: 0.7846  decode.d4.loss_cls: 0.1509  decode.d4.loss_mask: 1.0160  decode.d4.loss_dice: 0.7760  decode.d5.loss_cls: 0.1453  decode.d5.loss_mask: 1.0164  decode.d5.loss_dice: 0.8095  decode.d6.loss_cls: 0.1602  decode.d6.loss_mask: 1.0321  decode.d6.loss_dice: 0.7905  decode.d7.loss_cls: 0.1434  decode.d7.loss_mask: 1.0165  decode.d7.loss_dice: 0.7737  decode.d8.loss_cls: 0.1571  decode.d8.loss_mask: 1.0108  decode.d8.loss_dice: 0.7562
05/26 18:44:41 - mmengine - INFO - Iter(train) [ 66200/160000]  base_lr: 6.1841e-05 lr: 6.1841e-06  eta: 10:43:40  time: 0.4145  data_time: 0.0097  memory: 5972  grad_norm: 587.3994  loss: 22.6333  decode.loss_cls: 0.1773  decode.loss_mask: 1.1965  decode.loss_dice: 0.8281  decode.d0.loss_cls: 0.7212  decode.d0.loss_mask: 1.1192  decode.d0.loss_dice: 0.7945  decode.d1.loss_cls: 0.2050  decode.d1.loss_mask: 1.1743  decode.d1.loss_dice: 0.8415  decode.d2.loss_cls: 0.2227  decode.d2.loss_mask: 1.1419  decode.d2.loss_dice: 0.8292  decode.d3.loss_cls: 0.1607  decode.d3.loss_mask: 1.2341  decode.d3.loss_dice: 0.8482  decode.d4.loss_cls: 0.1689  decode.d4.loss_mask: 1.1970  decode.d4.loss_dice: 0.8591  decode.d5.loss_cls: 0.1515  decode.d5.loss_mask: 1.2244  decode.d5.loss_dice: 0.8757  decode.d6.loss_cls: 0.2639  decode.d6.loss_mask: 1.1508  decode.d6.loss_dice: 0.8312  decode.d7.loss_cls: 0.1882  decode.d7.loss_mask: 1.1816  decode.d7.loss_dice: 0.8552  decode.d8.loss_cls: 0.1854  decode.d8.loss_mask: 1.1601  decode.d8.loss_dice: 0.8459
05/26 18:45:02 - mmengine - INFO - Iter(train) [ 66250/160000]  base_lr: 6.1811e-05 lr: 6.1811e-06  eta: 10:43:20  time: 0.4147  data_time: 0.0097  memory: 5971  grad_norm: 674.0538  loss: 25.1323  decode.loss_cls: 0.3381  decode.loss_mask: 1.3218  decode.loss_dice: 0.8229  decode.d0.loss_cls: 0.8269  decode.d0.loss_mask: 1.2202  decode.d0.loss_dice: 0.7868  decode.d1.loss_cls: 0.3356  decode.d1.loss_mask: 1.2973  decode.d1.loss_dice: 0.8264  decode.d2.loss_cls: 0.3257  decode.d2.loss_mask: 1.3249  decode.d2.loss_dice: 0.8830  decode.d3.loss_cls: 0.3140  decode.d3.loss_mask: 1.2984  decode.d3.loss_dice: 0.8467  decode.d4.loss_cls: 0.3442  decode.d4.loss_mask: 1.2934  decode.d4.loss_dice: 0.8333  decode.d5.loss_cls: 0.3405  decode.d5.loss_mask: 1.2990  decode.d5.loss_dice: 0.8496  decode.d6.loss_cls: 0.3412  decode.d6.loss_mask: 1.3122  decode.d6.loss_dice: 0.8496  decode.d7.loss_cls: 0.3010  decode.d7.loss_mask: 1.3023  decode.d7.loss_dice: 0.8217  decode.d8.loss_cls: 0.3515  decode.d8.loss_mask: 1.3067  decode.d8.loss_dice: 0.8175
05/26 18:45:22 - mmengine - INFO - Iter(train) [ 66300/160000]  base_lr: 6.1782e-05 lr: 6.1782e-06  eta: 10:43:00  time: 0.4140  data_time: 0.0097  memory: 5979  grad_norm: 712.5035  loss: 21.3627  decode.loss_cls: 0.2096  decode.loss_mask: 1.0920  decode.loss_dice: 0.7848  decode.d0.loss_cls: 0.6624  decode.d0.loss_mask: 1.0866  decode.d0.loss_dice: 0.7578  decode.d1.loss_cls: 0.2411  decode.d1.loss_mask: 1.0801  decode.d1.loss_dice: 0.7588  decode.d2.loss_cls: 0.2328  decode.d2.loss_mask: 1.0896  decode.d2.loss_dice: 0.7507  decode.d3.loss_cls: 0.2321  decode.d3.loss_mask: 1.1125  decode.d3.loss_dice: 0.7741  decode.d4.loss_cls: 0.2759  decode.d4.loss_mask: 1.0613  decode.d4.loss_dice: 0.7381  decode.d5.loss_cls: 0.2788  decode.d5.loss_mask: 1.1101  decode.d5.loss_dice: 0.7583  decode.d6.loss_cls: 0.2311  decode.d6.loss_mask: 1.1304  decode.d6.loss_dice: 0.7653  decode.d7.loss_cls: 0.2150  decode.d7.loss_mask: 1.0876  decode.d7.loss_dice: 0.7678  decode.d8.loss_cls: 0.2293  decode.d8.loss_mask: 1.0683  decode.d8.loss_dice: 0.7804
05/26 18:45:43 - mmengine - INFO - Iter(train) [ 66350/160000]  base_lr: 6.1752e-05 lr: 6.1752e-06  eta: 10:42:39  time: 0.4157  data_time: 0.0096  memory: 5983  grad_norm: 612.3957  loss: 25.0653  decode.loss_cls: 0.3124  decode.loss_mask: 1.2197  decode.loss_dice: 0.9331  decode.d0.loss_cls: 0.9373  decode.d0.loss_mask: 1.1023  decode.d0.loss_dice: 0.8754  decode.d1.loss_cls: 0.3115  decode.d1.loss_mask: 1.2714  decode.d1.loss_dice: 0.9312  decode.d2.loss_cls: 0.3281  decode.d2.loss_mask: 1.2098  decode.d2.loss_dice: 0.8987  decode.d3.loss_cls: 0.3226  decode.d3.loss_mask: 1.2258  decode.d3.loss_dice: 0.9034  decode.d4.loss_cls: 0.3331  decode.d4.loss_mask: 1.2005  decode.d4.loss_dice: 0.8847  decode.d5.loss_cls: 0.3419  decode.d5.loss_mask: 1.1977  decode.d5.loss_dice: 0.8986  decode.d6.loss_cls: 0.3393  decode.d6.loss_mask: 1.1642  decode.d6.loss_dice: 0.8927  decode.d7.loss_cls: 0.3573  decode.d7.loss_mask: 1.2668  decode.d7.loss_dice: 0.9433  decode.d8.loss_cls: 0.3651  decode.d8.loss_mask: 1.1940  decode.d8.loss_dice: 0.9035
05/26 18:46:04 - mmengine - INFO - Iter(train) [ 66400/160000]  base_lr: 6.1722e-05 lr: 6.1722e-06  eta: 10:42:19  time: 0.4122  data_time: 0.0095  memory: 5973  grad_norm: 658.4971  loss: 22.5361  decode.loss_cls: 0.2487  decode.loss_mask: 1.1497  decode.loss_dice: 0.8274  decode.d0.loss_cls: 0.6906  decode.d0.loss_mask: 1.0563  decode.d0.loss_dice: 0.7527  decode.d1.loss_cls: 0.3078  decode.d1.loss_mask: 1.1148  decode.d1.loss_dice: 0.8062  decode.d2.loss_cls: 0.2428  decode.d2.loss_mask: 1.1248  decode.d2.loss_dice: 0.8298  decode.d3.loss_cls: 0.2717  decode.d3.loss_mask: 1.1238  decode.d3.loss_dice: 0.7647  decode.d4.loss_cls: 0.3198  decode.d4.loss_mask: 1.1380  decode.d4.loss_dice: 0.8400  decode.d5.loss_cls: 0.2862  decode.d5.loss_mask: 1.1410  decode.d5.loss_dice: 0.8271  decode.d6.loss_cls: 0.2874  decode.d6.loss_mask: 1.1733  decode.d6.loss_dice: 0.8208  decode.d7.loss_cls: 0.2386  decode.d7.loss_mask: 1.1176  decode.d7.loss_dice: 0.8296  decode.d8.loss_cls: 0.2937  decode.d8.loss_mask: 1.1099  decode.d8.loss_dice: 0.8013
05/26 18:46:24 - mmengine - INFO - Iter(train) [ 66450/160000]  base_lr: 6.1693e-05 lr: 6.1693e-06  eta: 10:41:58  time: 0.4127  data_time: 0.0095  memory: 5966  grad_norm: 554.8402  loss: 20.1707  decode.loss_cls: 0.2318  decode.loss_mask: 1.0000  decode.loss_dice: 0.6811  decode.d0.loss_cls: 0.6002  decode.d0.loss_mask: 0.9830  decode.d0.loss_dice: 0.7237  decode.d1.loss_cls: 0.2432  decode.d1.loss_mask: 1.0338  decode.d1.loss_dice: 0.7064  decode.d2.loss_cls: 0.2275  decode.d2.loss_mask: 1.0310  decode.d2.loss_dice: 0.7222  decode.d3.loss_cls: 0.2589  decode.d3.loss_mask: 1.0525  decode.d3.loss_dice: 0.7002  decode.d4.loss_cls: 0.2291  decode.d4.loss_mask: 1.0361  decode.d4.loss_dice: 0.7162  decode.d5.loss_cls: 0.2272  decode.d5.loss_mask: 1.0763  decode.d5.loss_dice: 0.7398  decode.d6.loss_cls: 0.2425  decode.d6.loss_mask: 1.0256  decode.d6.loss_dice: 0.7529  decode.d7.loss_cls: 0.2638  decode.d7.loss_mask: 1.0069  decode.d7.loss_dice: 0.6650  decode.d8.loss_cls: 0.2323  decode.d8.loss_mask: 1.0554  decode.d8.loss_dice: 0.7064
05/26 18:46:45 - mmengine - INFO - Iter(train) [ 66500/160000]  base_lr: 6.1663e-05 lr: 6.1663e-06  eta: 10:41:38  time: 0.4131  data_time: 0.0095  memory: 5976  grad_norm: 1285.5970  loss: 18.3992  decode.loss_cls: 0.1346  decode.loss_mask: 1.0043  decode.loss_dice: 0.6587  decode.d0.loss_cls: 0.6210  decode.d0.loss_mask: 0.9694  decode.d0.loss_dice: 0.6341  decode.d1.loss_cls: 0.2135  decode.d1.loss_mask: 0.9534  decode.d1.loss_dice: 0.6425  decode.d2.loss_cls: 0.1571  decode.d2.loss_mask: 0.9884  decode.d2.loss_dice: 0.6459  decode.d3.loss_cls: 0.1878  decode.d3.loss_mask: 0.9527  decode.d3.loss_dice: 0.6331  decode.d4.loss_cls: 0.1648  decode.d4.loss_mask: 0.9826  decode.d4.loss_dice: 0.6388  decode.d5.loss_cls: 0.1801  decode.d5.loss_mask: 0.9781  decode.d5.loss_dice: 0.6571  decode.d6.loss_cls: 0.1584  decode.d6.loss_mask: 0.9711  decode.d6.loss_dice: 0.6610  decode.d7.loss_cls: 0.1600  decode.d7.loss_mask: 1.0078  decode.d7.loss_dice: 0.6529  decode.d8.loss_cls: 0.1824  decode.d8.loss_mask: 0.9610  decode.d8.loss_dice: 0.6466
05/26 18:47:06 - mmengine - INFO - Iter(train) [ 66550/160000]  base_lr: 6.1633e-05 lr: 6.1633e-06  eta: 10:41:18  time: 0.4125  data_time: 0.0095  memory: 5968  grad_norm: 544.4387  loss: 24.5364  decode.loss_cls: 0.2786  decode.loss_mask: 1.2272  decode.loss_dice: 0.9561  decode.d0.loss_cls: 0.7676  decode.d0.loss_mask: 1.1171  decode.d0.loss_dice: 0.8849  decode.d1.loss_cls: 0.2588  decode.d1.loss_mask: 1.1951  decode.d1.loss_dice: 0.9255  decode.d2.loss_cls: 0.2833  decode.d2.loss_mask: 1.2099  decode.d2.loss_dice: 0.9376  decode.d3.loss_cls: 0.2323  decode.d3.loss_mask: 1.2409  decode.d3.loss_dice: 0.9252  decode.d4.loss_cls: 0.2705  decode.d4.loss_mask: 1.2310  decode.d4.loss_dice: 0.9460  decode.d5.loss_cls: 0.2725  decode.d5.loss_mask: 1.2050  decode.d5.loss_dice: 0.9311  decode.d6.loss_cls: 0.2683  decode.d6.loss_mask: 1.2050  decode.d6.loss_dice: 0.9138  decode.d7.loss_cls: 0.2612  decode.d7.loss_mask: 1.2224  decode.d7.loss_dice: 0.9547  decode.d8.loss_cls: 0.2524  decode.d8.loss_mask: 1.2075  decode.d8.loss_dice: 0.9550
05/26 18:47:26 - mmengine - INFO - Iter(train) [ 66600/160000]  base_lr: 6.1604e-05 lr: 6.1604e-06  eta: 10:40:57  time: 0.4130  data_time: 0.0096  memory: 5988  grad_norm: 601.3239  loss: 21.2784  decode.loss_cls: 0.2825  decode.loss_mask: 1.0602  decode.loss_dice: 0.7293  decode.d0.loss_cls: 0.7272  decode.d0.loss_mask: 1.0617  decode.d0.loss_dice: 0.7931  decode.d1.loss_cls: 0.2821  decode.d1.loss_mask: 1.0651  decode.d1.loss_dice: 0.7271  decode.d2.loss_cls: 0.3233  decode.d2.loss_mask: 1.0491  decode.d2.loss_dice: 0.7158  decode.d3.loss_cls: 0.2534  decode.d3.loss_mask: 1.0681  decode.d3.loss_dice: 0.7285  decode.d4.loss_cls: 0.2274  decode.d4.loss_mask: 1.1112  decode.d4.loss_dice: 0.7532  decode.d5.loss_cls: 0.2455  decode.d5.loss_mask: 1.0954  decode.d5.loss_dice: 0.7400  decode.d6.loss_cls: 0.2339  decode.d6.loss_mask: 1.0969  decode.d6.loss_dice: 0.7398  decode.d7.loss_cls: 0.2643  decode.d7.loss_mask: 1.0970  decode.d7.loss_dice: 0.7483  decode.d8.loss_cls: 0.2901  decode.d8.loss_mask: 1.0452  decode.d8.loss_dice: 0.7237
05/26 18:47:47 - mmengine - INFO - Iter(train) [ 66650/160000]  base_lr: 6.1574e-05 lr: 6.1574e-06  eta: 10:40:37  time: 0.4241  data_time: 0.0210  memory: 5967  grad_norm: 518.7276  loss: 22.0317  decode.loss_cls: 0.2070  decode.loss_mask: 1.1059  decode.loss_dice: 0.7902  decode.d0.loss_cls: 0.7447  decode.d0.loss_mask: 1.0897  decode.d0.loss_dice: 0.8144  decode.d1.loss_cls: 0.1833  decode.d1.loss_mask: 1.1584  decode.d1.loss_dice: 0.8444  decode.d2.loss_cls: 0.2868  decode.d2.loss_mask: 1.0811  decode.d2.loss_dice: 0.7932  decode.d3.loss_cls: 0.1729  decode.d3.loss_mask: 1.1825  decode.d3.loss_dice: 0.8520  decode.d4.loss_cls: 0.2051  decode.d4.loss_mask: 1.1494  decode.d4.loss_dice: 0.8356  decode.d5.loss_cls: 0.2235  decode.d5.loss_mask: 1.1511  decode.d5.loss_dice: 0.7620  decode.d6.loss_cls: 0.2581  decode.d6.loss_mask: 1.1276  decode.d6.loss_dice: 0.8082  decode.d7.loss_cls: 0.2362  decode.d7.loss_mask: 1.1137  decode.d7.loss_dice: 0.7649  decode.d8.loss_cls: 0.2309  decode.d8.loss_mask: 1.0946  decode.d8.loss_dice: 0.7640
05/26 18:48:08 - mmengine - INFO - Iter(train) [ 66700/160000]  base_lr: 6.1544e-05 lr: 6.1544e-06  eta: 10:40:16  time: 0.4144  data_time: 0.0096  memory: 5975  grad_norm: 324.7695  loss: 22.4747  decode.loss_cls: 0.2403  decode.loss_mask: 1.0863  decode.loss_dice: 0.8088  decode.d0.loss_cls: 0.8086  decode.d0.loss_mask: 1.0604  decode.d0.loss_dice: 0.7848  decode.d1.loss_cls: 0.2635  decode.d1.loss_mask: 1.1196  decode.d1.loss_dice: 0.8533  decode.d2.loss_cls: 0.1987  decode.d2.loss_mask: 1.1198  decode.d2.loss_dice: 0.8701  decode.d3.loss_cls: 0.2402  decode.d3.loss_mask: 1.1030  decode.d3.loss_dice: 0.8553  decode.d4.loss_cls: 0.2383  decode.d4.loss_mask: 1.1189  decode.d4.loss_dice: 0.8780  decode.d5.loss_cls: 0.2409  decode.d5.loss_mask: 1.1065  decode.d5.loss_dice: 0.8593  decode.d6.loss_cls: 0.2495  decode.d6.loss_mask: 1.0872  decode.d6.loss_dice: 0.8324  decode.d7.loss_cls: 0.2378  decode.d7.loss_mask: 1.1312  decode.d7.loss_dice: 0.8578  decode.d8.loss_cls: 0.2076  decode.d8.loss_mask: 1.1342  decode.d8.loss_dice: 0.8821
05/26 18:48:29 - mmengine - INFO - Iter(train) [ 66750/160000]  base_lr: 6.1515e-05 lr: 6.1515e-06  eta: 10:39:56  time: 0.4143  data_time: 0.0095  memory: 5976  grad_norm: 803.5389  loss: 23.4102  decode.loss_cls: 0.1867  decode.loss_mask: 1.2064  decode.loss_dice: 0.9278  decode.d0.loss_cls: 0.6309  decode.d0.loss_mask: 1.0685  decode.d0.loss_dice: 0.8855  decode.d1.loss_cls: 0.1724  decode.d1.loss_mask: 1.1813  decode.d1.loss_dice: 0.9235  decode.d2.loss_cls: 0.1741  decode.d2.loss_mask: 1.1837  decode.d2.loss_dice: 0.9432  decode.d3.loss_cls: 0.1774  decode.d3.loss_mask: 1.1861  decode.d3.loss_dice: 0.9288  decode.d4.loss_cls: 0.1808  decode.d4.loss_mask: 1.1810  decode.d4.loss_dice: 0.9227  decode.d5.loss_cls: 0.1788  decode.d5.loss_mask: 1.1985  decode.d5.loss_dice: 0.9411  decode.d6.loss_cls: 0.1749  decode.d6.loss_mask: 1.2236  decode.d6.loss_dice: 0.9664  decode.d7.loss_cls: 0.1708  decode.d7.loss_mask: 1.2193  decode.d7.loss_dice: 0.9588  decode.d8.loss_cls: 0.1343  decode.d8.loss_mask: 1.2112  decode.d8.loss_dice: 0.9717
05/26 18:48:50 - mmengine - INFO - Iter(train) [ 66800/160000]  base_lr: 6.1485e-05 lr: 6.1485e-06  eta: 10:39:36  time: 0.4155  data_time: 0.0096  memory: 5976  grad_norm: 721.0220  loss: 22.4654  decode.loss_cls: 0.2433  decode.loss_mask: 1.1576  decode.loss_dice: 0.7857  decode.d0.loss_cls: 0.6793  decode.d0.loss_mask: 1.0787  decode.d0.loss_dice: 0.7622  decode.d1.loss_cls: 0.2156  decode.d1.loss_mask: 1.1822  decode.d1.loss_dice: 0.7778  decode.d2.loss_cls: 0.2260  decode.d2.loss_mask: 1.1825  decode.d2.loss_dice: 0.7910  decode.d3.loss_cls: 0.2384  decode.d3.loss_mask: 1.2097  decode.d3.loss_dice: 0.7982  decode.d4.loss_cls: 0.2166  decode.d4.loss_mask: 1.2347  decode.d4.loss_dice: 0.8110  decode.d5.loss_cls: 0.2295  decode.d5.loss_mask: 1.1978  decode.d5.loss_dice: 0.7759  decode.d6.loss_cls: 0.2496  decode.d6.loss_mask: 1.1740  decode.d6.loss_dice: 0.7834  decode.d7.loss_cls: 0.2325  decode.d7.loss_mask: 1.2003  decode.d7.loss_dice: 0.7997  decode.d8.loss_cls: 0.2134  decode.d8.loss_mask: 1.2336  decode.d8.loss_dice: 0.7852
05/26 18:49:10 - mmengine - INFO - Iter(train) [ 66850/160000]  base_lr: 6.1455e-05 lr: 6.1455e-06  eta: 10:39:15  time: 0.4162  data_time: 0.0096  memory: 5983  grad_norm: 920.6956  loss: 24.0900  decode.loss_cls: 0.3518  decode.loss_mask: 1.1252  decode.loss_dice: 0.8852  decode.d0.loss_cls: 0.7643  decode.d0.loss_mask: 1.0894  decode.d0.loss_dice: 0.9007  decode.d1.loss_cls: 0.3627  decode.d1.loss_mask: 1.1133  decode.d1.loss_dice: 0.8892  decode.d2.loss_cls: 0.3203  decode.d2.loss_mask: 1.1186  decode.d2.loss_dice: 0.9033  decode.d3.loss_cls: 0.3487  decode.d3.loss_mask: 1.1472  decode.d3.loss_dice: 0.9190  decode.d4.loss_cls: 0.4032  decode.d4.loss_mask: 1.0895  decode.d4.loss_dice: 0.9021  decode.d5.loss_cls: 0.3572  decode.d5.loss_mask: 1.1046  decode.d5.loss_dice: 0.9033  decode.d6.loss_cls: 0.3478  decode.d6.loss_mask: 1.1115  decode.d6.loss_dice: 0.8985  decode.d7.loss_cls: 0.4016  decode.d7.loss_mask: 1.1054  decode.d7.loss_dice: 0.8805  decode.d8.loss_cls: 0.3616  decode.d8.loss_mask: 1.0953  decode.d8.loss_dice: 0.8890
05/26 18:49:31 - mmengine - INFO - Iter(train) [ 66900/160000]  base_lr: 6.1426e-05 lr: 6.1426e-06  eta: 10:38:55  time: 0.4134  data_time: 0.0096  memory: 5969  grad_norm: 621.6708  loss: 17.6166  decode.loss_cls: 0.1567  decode.loss_mask: 0.9389  decode.loss_dice: 0.6477  decode.d0.loss_cls: 0.6800  decode.d0.loss_mask: 0.8390  decode.d0.loss_dice: 0.6150  decode.d1.loss_cls: 0.1949  decode.d1.loss_mask: 0.9115  decode.d1.loss_dice: 0.6351  decode.d2.loss_cls: 0.1277  decode.d2.loss_mask: 0.9284  decode.d2.loss_dice: 0.6619  decode.d3.loss_cls: 0.1780  decode.d3.loss_mask: 0.9017  decode.d3.loss_dice: 0.6399  decode.d4.loss_cls: 0.1573  decode.d4.loss_mask: 0.8747  decode.d4.loss_dice: 0.6592  decode.d5.loss_cls: 0.1411  decode.d5.loss_mask: 0.9220  decode.d5.loss_dice: 0.6649  decode.d6.loss_cls: 0.1449  decode.d6.loss_mask: 0.8887  decode.d6.loss_dice: 0.6479  decode.d7.loss_cls: 0.1696  decode.d7.loss_mask: 0.9092  decode.d7.loss_dice: 0.6546  decode.d8.loss_cls: 0.1736  decode.d8.loss_mask: 0.9009  decode.d8.loss_dice: 0.6513
05/26 18:49:52 - mmengine - INFO - Iter(train) [ 66950/160000]  base_lr: 6.1396e-05 lr: 6.1396e-06  eta: 10:38:34  time: 0.4132  data_time: 0.0096  memory: 5968  grad_norm: 419.4622  loss: 19.8765  decode.loss_cls: 0.1901  decode.loss_mask: 1.0453  decode.loss_dice: 0.7411  decode.d0.loss_cls: 0.6503  decode.d0.loss_mask: 0.9569  decode.d0.loss_dice: 0.7188  decode.d1.loss_cls: 0.2130  decode.d1.loss_mask: 1.0135  decode.d1.loss_dice: 0.7242  decode.d2.loss_cls: 0.2231  decode.d2.loss_mask: 1.0084  decode.d2.loss_dice: 0.7301  decode.d3.loss_cls: 0.2372  decode.d3.loss_mask: 0.9911  decode.d3.loss_dice: 0.7215  decode.d4.loss_cls: 0.1965  decode.d4.loss_mask: 0.9919  decode.d4.loss_dice: 0.7079  decode.d5.loss_cls: 0.2324  decode.d5.loss_mask: 0.9799  decode.d5.loss_dice: 0.7053  decode.d6.loss_cls: 0.2291  decode.d6.loss_mask: 1.0095  decode.d6.loss_dice: 0.7369  decode.d7.loss_cls: 0.2210  decode.d7.loss_mask: 1.0007  decode.d7.loss_dice: 0.7251  decode.d8.loss_cls: 0.2246  decode.d8.loss_mask: 1.0214  decode.d8.loss_dice: 0.7296
05/26 18:50:12 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 18:50:12 - mmengine - INFO - Iter(train) [ 67000/160000]  base_lr: 6.1366e-05 lr: 6.1366e-06  eta: 10:38:14  time: 0.4116  data_time: 0.0096  memory: 5968  grad_norm: 493.2799  loss: 21.8867  decode.loss_cls: 0.2529  decode.loss_mask: 1.0775  decode.loss_dice: 0.7445  decode.d0.loss_cls: 0.7152  decode.d0.loss_mask: 1.0465  decode.d0.loss_dice: 0.7281  decode.d1.loss_cls: 0.3286  decode.d1.loss_mask: 1.0808  decode.d1.loss_dice: 0.7384  decode.d2.loss_cls: 0.2938  decode.d2.loss_mask: 1.0968  decode.d2.loss_dice: 0.7523  decode.d3.loss_cls: 0.2990  decode.d3.loss_mask: 1.1098  decode.d3.loss_dice: 0.7439  decode.d4.loss_cls: 0.3441  decode.d4.loss_mask: 1.0425  decode.d4.loss_dice: 0.7404  decode.d5.loss_cls: 0.3027  decode.d5.loss_mask: 1.1215  decode.d5.loss_dice: 0.7573  decode.d6.loss_cls: 0.3187  decode.d6.loss_mask: 1.0792  decode.d6.loss_dice: 0.7570  decode.d7.loss_cls: 0.2898  decode.d7.loss_mask: 1.1371  decode.d7.loss_dice: 0.7465  decode.d8.loss_cls: 0.2887  decode.d8.loss_mask: 1.1766  decode.d8.loss_dice: 0.7766
05/26 18:50:33 - mmengine - INFO - Iter(train) [ 67050/160000]  base_lr: 6.1336e-05 lr: 6.1336e-06  eta: 10:37:53  time: 0.4117  data_time: 0.0096  memory: 5974  grad_norm: 767.9446  loss: 23.5836  decode.loss_cls: 0.3149  decode.loss_mask: 1.0923  decode.loss_dice: 0.8783  decode.d0.loss_cls: 0.8009  decode.d0.loss_mask: 1.0275  decode.d0.loss_dice: 0.8182  decode.d1.loss_cls: 0.3008  decode.d1.loss_mask: 1.1193  decode.d1.loss_dice: 0.9138  decode.d2.loss_cls: 0.3183  decode.d2.loss_mask: 1.1160  decode.d2.loss_dice: 0.8742  decode.d3.loss_cls: 0.3340  decode.d3.loss_mask: 1.1276  decode.d3.loss_dice: 0.8996  decode.d4.loss_cls: 0.2976  decode.d4.loss_mask: 1.1316  decode.d4.loss_dice: 0.8882  decode.d5.loss_cls: 0.2848  decode.d5.loss_mask: 1.1592  decode.d5.loss_dice: 0.8792  decode.d6.loss_cls: 0.2990  decode.d6.loss_mask: 1.1723  decode.d6.loss_dice: 0.8995  decode.d7.loss_cls: 0.2757  decode.d7.loss_mask: 1.1273  decode.d7.loss_dice: 0.8926  decode.d8.loss_cls: 0.3000  decode.d8.loss_mask: 1.1489  decode.d8.loss_dice: 0.8919
05/26 18:50:54 - mmengine - INFO - Iter(train) [ 67100/160000]  base_lr: 6.1307e-05 lr: 6.1307e-06  eta: 10:37:33  time: 0.4114  data_time: 0.0097  memory: 5969  grad_norm: 593.8986  loss: 22.3382  decode.loss_cls: 0.2554  decode.loss_mask: 1.1186  decode.loss_dice: 0.8357  decode.d0.loss_cls: 0.8139  decode.d0.loss_mask: 1.0517  decode.d0.loss_dice: 0.7534  decode.d1.loss_cls: 0.2571  decode.d1.loss_mask: 1.0952  decode.d1.loss_dice: 0.8468  decode.d2.loss_cls: 0.2400  decode.d2.loss_mask: 1.0641  decode.d2.loss_dice: 0.8233  decode.d3.loss_cls: 0.2283  decode.d3.loss_mask: 1.1075  decode.d3.loss_dice: 0.8812  decode.d4.loss_cls: 0.3209  decode.d4.loss_mask: 1.0842  decode.d4.loss_dice: 0.7868  decode.d5.loss_cls: 0.2874  decode.d5.loss_mask: 1.0638  decode.d5.loss_dice: 0.8006  decode.d6.loss_cls: 0.2949  decode.d6.loss_mask: 1.1076  decode.d6.loss_dice: 0.8178  decode.d7.loss_cls: 0.2606  decode.d7.loss_mask: 1.1433  decode.d7.loss_dice: 0.8357  decode.d8.loss_cls: 0.2308  decode.d8.loss_mask: 1.0790  decode.d8.loss_dice: 0.8528
05/26 18:51:14 - mmengine - INFO - Iter(train) [ 67150/160000]  base_lr: 6.1277e-05 lr: 6.1277e-06  eta: 10:37:12  time: 0.4107  data_time: 0.0096  memory: 5974  grad_norm: 610.5915  loss: 23.5732  decode.loss_cls: 0.2168  decode.loss_mask: 1.2189  decode.loss_dice: 0.8821  decode.d0.loss_cls: 0.7196  decode.d0.loss_mask: 1.1509  decode.d0.loss_dice: 0.8519  decode.d1.loss_cls: 0.2262  decode.d1.loss_mask: 1.1780  decode.d1.loss_dice: 0.8801  decode.d2.loss_cls: 0.2672  decode.d2.loss_mask: 1.1815  decode.d2.loss_dice: 0.9173  decode.d3.loss_cls: 0.2570  decode.d3.loss_mask: 1.1761  decode.d3.loss_dice: 0.8827  decode.d4.loss_cls: 0.2392  decode.d4.loss_mask: 1.1933  decode.d4.loss_dice: 0.8939  decode.d5.loss_cls: 0.2380  decode.d5.loss_mask: 1.2130  decode.d5.loss_dice: 0.9133  decode.d6.loss_cls: 0.2359  decode.d6.loss_mask: 1.1848  decode.d6.loss_dice: 0.9012  decode.d7.loss_cls: 0.2336  decode.d7.loss_mask: 1.1771  decode.d7.loss_dice: 0.8838  decode.d8.loss_cls: 0.2093  decode.d8.loss_mask: 1.1713  decode.d8.loss_dice: 0.8794
05/26 18:51:35 - mmengine - INFO - Iter(train) [ 67200/160000]  base_lr: 6.1247e-05 lr: 6.1247e-06  eta: 10:36:52  time: 0.4111  data_time: 0.0096  memory: 5973  grad_norm: 871.9517  loss: 25.6114  decode.loss_cls: 0.2505  decode.loss_mask: 1.4253  decode.loss_dice: 0.8379  decode.d0.loss_cls: 0.6501  decode.d0.loss_mask: 1.3444  decode.d0.loss_dice: 0.8185  decode.d1.loss_cls: 0.2658  decode.d1.loss_mask: 1.3890  decode.d1.loss_dice: 0.8367  decode.d2.loss_cls: 0.2577  decode.d2.loss_mask: 1.4090  decode.d2.loss_dice: 0.8253  decode.d3.loss_cls: 0.2183  decode.d3.loss_mask: 1.4224  decode.d3.loss_dice: 0.8684  decode.d4.loss_cls: 0.2508  decode.d4.loss_mask: 1.4056  decode.d4.loss_dice: 0.8357  decode.d5.loss_cls: 0.2271  decode.d5.loss_mask: 1.4693  decode.d5.loss_dice: 0.8542  decode.d6.loss_cls: 0.2778  decode.d6.loss_mask: 1.5160  decode.d6.loss_dice: 0.8926  decode.d7.loss_cls: 0.2196  decode.d7.loss_mask: 1.4276  decode.d7.loss_dice: 0.8260  decode.d8.loss_cls: 0.2707  decode.d8.loss_mask: 1.4640  decode.d8.loss_dice: 0.8552
05/26 18:51:55 - mmengine - INFO - Iter(train) [ 67250/160000]  base_lr: 6.1218e-05 lr: 6.1218e-06  eta: 10:36:31  time: 0.4117  data_time: 0.0095  memory: 5971  grad_norm: 491.0767  loss: 22.7278  decode.loss_cls: 0.1192  decode.loss_mask: 1.1878  decode.loss_dice: 0.9092  decode.d0.loss_cls: 0.5582  decode.d0.loss_mask: 1.1575  decode.d0.loss_dice: 0.8989  decode.d1.loss_cls: 0.1709  decode.d1.loss_mask: 1.1789  decode.d1.loss_dice: 0.9051  decode.d2.loss_cls: 0.1550  decode.d2.loss_mask: 1.1809  decode.d2.loss_dice: 0.9131  decode.d3.loss_cls: 0.1424  decode.d3.loss_mask: 1.1824  decode.d3.loss_dice: 0.9011  decode.d4.loss_cls: 0.1467  decode.d4.loss_mask: 1.1832  decode.d4.loss_dice: 0.8983  decode.d5.loss_cls: 0.1653  decode.d5.loss_mask: 1.1807  decode.d5.loss_dice: 0.8987  decode.d6.loss_cls: 0.1802  decode.d6.loss_mask: 1.1864  decode.d6.loss_dice: 0.9003  decode.d7.loss_cls: 0.1304  decode.d7.loss_mask: 1.1855  decode.d7.loss_dice: 0.8968  decode.d8.loss_cls: 0.1603  decode.d8.loss_mask: 1.1719  decode.d8.loss_dice: 0.8826
05/26 18:52:16 - mmengine - INFO - Iter(train) [ 67300/160000]  base_lr: 6.1188e-05 lr: 6.1188e-06  eta: 10:36:11  time: 0.4114  data_time: 0.0096  memory: 5967  grad_norm: 419.7027  loss: 22.3628  decode.loss_cls: 0.2242  decode.loss_mask: 1.1654  decode.loss_dice: 0.7927  decode.d0.loss_cls: 0.7441  decode.d0.loss_mask: 1.0925  decode.d0.loss_dice: 0.7768  decode.d1.loss_cls: 0.2732  decode.d1.loss_mask: 1.1600  decode.d1.loss_dice: 0.7913  decode.d2.loss_cls: 0.2101  decode.d2.loss_mask: 1.1826  decode.d2.loss_dice: 0.8173  decode.d3.loss_cls: 0.2070  decode.d3.loss_mask: 1.1561  decode.d3.loss_dice: 0.8002  decode.d4.loss_cls: 0.1898  decode.d4.loss_mask: 1.1735  decode.d4.loss_dice: 0.8083  decode.d5.loss_cls: 0.2258  decode.d5.loss_mask: 1.1413  decode.d5.loss_dice: 0.7851  decode.d6.loss_cls: 0.2498  decode.d6.loss_mask: 1.1590  decode.d6.loss_dice: 0.7839  decode.d7.loss_cls: 0.2316  decode.d7.loss_mask: 1.2291  decode.d7.loss_dice: 0.7772  decode.d8.loss_cls: 0.2382  decode.d8.loss_mask: 1.1799  decode.d8.loss_dice: 0.7968
05/26 18:52:37 - mmengine - INFO - Iter(train) [ 67350/160000]  base_lr: 6.1158e-05 lr: 6.1158e-06  eta: 10:35:50  time: 0.4125  data_time: 0.0097  memory: 5976  grad_norm: 433.0747  loss: 24.5139  decode.loss_cls: 0.3435  decode.loss_mask: 1.1427  decode.loss_dice: 0.9291  decode.d0.loss_cls: 0.8899  decode.d0.loss_mask: 1.0919  decode.d0.loss_dice: 0.9569  decode.d1.loss_cls: 0.3720  decode.d1.loss_mask: 1.1417  decode.d1.loss_dice: 0.9428  decode.d2.loss_cls: 0.3517  decode.d2.loss_mask: 1.1099  decode.d2.loss_dice: 0.9377  decode.d3.loss_cls: 0.3597  decode.d3.loss_mask: 1.1087  decode.d3.loss_dice: 0.9339  decode.d4.loss_cls: 0.3151  decode.d4.loss_mask: 1.1344  decode.d4.loss_dice: 0.9359  decode.d5.loss_cls: 0.3796  decode.d5.loss_mask: 1.0966  decode.d5.loss_dice: 0.9244  decode.d6.loss_cls: 0.4098  decode.d6.loss_mask: 1.0998  decode.d6.loss_dice: 0.9091  decode.d7.loss_cls: 0.3369  decode.d7.loss_mask: 1.1136  decode.d7.loss_dice: 0.9124  decode.d8.loss_cls: 0.3279  decode.d8.loss_mask: 1.1094  decode.d8.loss_dice: 0.8969
05/26 18:52:57 - mmengine - INFO - Iter(train) [ 67400/160000]  base_lr: 6.1129e-05 lr: 6.1129e-06  eta: 10:35:29  time: 0.4106  data_time: 0.0096  memory: 5967  grad_norm: 788.1768  loss: 23.7114  decode.loss_cls: 0.2737  decode.loss_mask: 1.1065  decode.loss_dice: 0.9144  decode.d0.loss_cls: 0.8315  decode.d0.loss_mask: 1.0120  decode.d0.loss_dice: 0.8766  decode.d1.loss_cls: 0.2919  decode.d1.loss_mask: 1.0962  decode.d1.loss_dice: 0.9262  decode.d2.loss_cls: 0.2892  decode.d2.loss_mask: 1.1315  decode.d2.loss_dice: 0.9509  decode.d3.loss_cls: 0.2942  decode.d3.loss_mask: 1.1081  decode.d3.loss_dice: 0.9354  decode.d4.loss_cls: 0.2890  decode.d4.loss_mask: 1.1308  decode.d4.loss_dice: 0.9578  decode.d5.loss_cls: 0.2930  decode.d5.loss_mask: 1.1237  decode.d5.loss_dice: 0.9192  decode.d6.loss_cls: 0.2937  decode.d6.loss_mask: 1.1596  decode.d6.loss_dice: 0.9070  decode.d7.loss_cls: 0.2629  decode.d7.loss_mask: 1.1274  decode.d7.loss_dice: 0.9260  decode.d8.loss_cls: 0.2848  decode.d8.loss_mask: 1.0933  decode.d8.loss_dice: 0.9048
05/26 18:53:18 - mmengine - INFO - Iter(train) [ 67450/160000]  base_lr: 6.1099e-05 lr: 6.1099e-06  eta: 10:35:09  time: 0.4118  data_time: 0.0096  memory: 5976  grad_norm: 466.6900  loss: 18.9250  decode.loss_cls: 0.1886  decode.loss_mask: 0.9164  decode.loss_dice: 0.7386  decode.d0.loss_cls: 0.5994  decode.d0.loss_mask: 0.8921  decode.d0.loss_dice: 0.7350  decode.d1.loss_cls: 0.1959  decode.d1.loss_mask: 0.9325  decode.d1.loss_dice: 0.7447  decode.d2.loss_cls: 0.1909  decode.d2.loss_mask: 0.9199  decode.d2.loss_dice: 0.7238  decode.d3.loss_cls: 0.2334  decode.d3.loss_mask: 0.8923  decode.d3.loss_dice: 0.7240  decode.d4.loss_cls: 0.2148  decode.d4.loss_mask: 0.9122  decode.d4.loss_dice: 0.7491  decode.d5.loss_cls: 0.2141  decode.d5.loss_mask: 0.9219  decode.d5.loss_dice: 0.7343  decode.d6.loss_cls: 0.1681  decode.d6.loss_mask: 0.9166  decode.d6.loss_dice: 0.7532  decode.d7.loss_cls: 0.1730  decode.d7.loss_mask: 0.9209  decode.d7.loss_dice: 0.7640  decode.d8.loss_cls: 0.1665  decode.d8.loss_mask: 0.9275  decode.d8.loss_dice: 0.7612
05/26 18:53:38 - mmengine - INFO - Iter(train) [ 67500/160000]  base_lr: 6.1069e-05 lr: 6.1069e-06  eta: 10:34:48  time: 0.4114  data_time: 0.0096  memory: 5969  grad_norm: 963.6173  loss: 22.4488  decode.loss_cls: 0.2417  decode.loss_mask: 1.1403  decode.loss_dice: 0.8108  decode.d0.loss_cls: 0.7685  decode.d0.loss_mask: 1.0467  decode.d0.loss_dice: 0.7724  decode.d1.loss_cls: 0.2919  decode.d1.loss_mask: 1.1065  decode.d1.loss_dice: 0.8142  decode.d2.loss_cls: 0.2928  decode.d2.loss_mask: 1.1242  decode.d2.loss_dice: 0.7949  decode.d3.loss_cls: 0.2638  decode.d3.loss_mask: 1.1102  decode.d3.loss_dice: 0.8077  decode.d4.loss_cls: 0.3319  decode.d4.loss_mask: 1.0947  decode.d4.loss_dice: 0.7902  decode.d5.loss_cls: 0.3120  decode.d5.loss_mask: 1.1075  decode.d5.loss_dice: 0.8104  decode.d6.loss_cls: 0.2987  decode.d6.loss_mask: 1.1194  decode.d6.loss_dice: 0.7939  decode.d7.loss_cls: 0.2614  decode.d7.loss_mask: 1.1226  decode.d7.loss_dice: 0.7919  decode.d8.loss_cls: 0.3132  decode.d8.loss_mask: 1.1102  decode.d8.loss_dice: 0.8042
05/26 18:53:59 - mmengine - INFO - Iter(train) [ 67550/160000]  base_lr: 6.1039e-05 lr: 6.1039e-06  eta: 10:34:28  time: 0.4127  data_time: 0.0097  memory: 5966  grad_norm: 552.2707  loss: 23.8526  decode.loss_cls: 0.2966  decode.loss_mask: 1.1089  decode.loss_dice: 0.9689  decode.d0.loss_cls: 0.6984  decode.d0.loss_mask: 1.0275  decode.d0.loss_dice: 0.8790  decode.d1.loss_cls: 0.3363  decode.d1.loss_mask: 1.1279  decode.d1.loss_dice: 0.9309  decode.d2.loss_cls: 0.3393  decode.d2.loss_mask: 1.0681  decode.d2.loss_dice: 0.8965  decode.d3.loss_cls: 0.2850  decode.d3.loss_mask: 1.1244  decode.d3.loss_dice: 0.9382  decode.d4.loss_cls: 0.3069  decode.d4.loss_mask: 1.1104  decode.d4.loss_dice: 0.9439  decode.d5.loss_cls: 0.3340  decode.d5.loss_mask: 1.1020  decode.d5.loss_dice: 0.9355  decode.d6.loss_cls: 0.3036  decode.d6.loss_mask: 1.1132  decode.d6.loss_dice: 0.9160  decode.d7.loss_cls: 0.3145  decode.d7.loss_mask: 1.1488  decode.d7.loss_dice: 0.9499  decode.d8.loss_cls: 0.3313  decode.d8.loss_mask: 1.0889  decode.d8.loss_dice: 0.9281
05/26 18:54:20 - mmengine - INFO - Iter(train) [ 67600/160000]  base_lr: 6.1010e-05 lr: 6.1010e-06  eta: 10:34:07  time: 0.4137  data_time: 0.0097  memory: 5967  grad_norm: 526.5262  loss: 28.8337  decode.loss_cls: 0.3473  decode.loss_mask: 1.4238  decode.loss_dice: 1.0786  decode.d0.loss_cls: 0.8361  decode.d0.loss_mask: 1.3596  decode.d0.loss_dice: 1.0064  decode.d1.loss_cls: 0.3672  decode.d1.loss_mask: 1.4007  decode.d1.loss_dice: 1.0277  decode.d2.loss_cls: 0.4007  decode.d2.loss_mask: 1.4551  decode.d2.loss_dice: 1.0268  decode.d3.loss_cls: 0.3405  decode.d3.loss_mask: 1.3925  decode.d3.loss_dice: 1.0224  decode.d4.loss_cls: 0.3864  decode.d4.loss_mask: 1.4547  decode.d4.loss_dice: 1.0166  decode.d5.loss_cls: 0.3587  decode.d5.loss_mask: 1.4722  decode.d5.loss_dice: 1.0487  decode.d6.loss_cls: 0.3715  decode.d6.loss_mask: 1.4723  decode.d6.loss_dice: 1.0599  decode.d7.loss_cls: 0.3510  decode.d7.loss_mask: 1.4770  decode.d7.loss_dice: 1.0356  decode.d8.loss_cls: 0.3316  decode.d8.loss_mask: 1.4776  decode.d8.loss_dice: 1.0345
05/26 18:54:40 - mmengine - INFO - Iter(train) [ 67650/160000]  base_lr: 6.0980e-05 lr: 6.0980e-06  eta: 10:33:47  time: 0.4132  data_time: 0.0097  memory: 5976  grad_norm: 520.5230  loss: 20.5976  decode.loss_cls: 0.1943  decode.loss_mask: 0.9958  decode.loss_dice: 0.8273  decode.d0.loss_cls: 0.7045  decode.d0.loss_mask: 0.9221  decode.d0.loss_dice: 0.7931  decode.d1.loss_cls: 0.2123  decode.d1.loss_mask: 0.9782  decode.d1.loss_dice: 0.8338  decode.d2.loss_cls: 0.1753  decode.d2.loss_mask: 1.0075  decode.d2.loss_dice: 0.8264  decode.d3.loss_cls: 0.2012  decode.d3.loss_mask: 0.9836  decode.d3.loss_dice: 0.8318  decode.d4.loss_cls: 0.2112  decode.d4.loss_mask: 0.9641  decode.d4.loss_dice: 0.8495  decode.d5.loss_cls: 0.1849  decode.d5.loss_mask: 0.9829  decode.d5.loss_dice: 0.8280  decode.d6.loss_cls: 0.2222  decode.d6.loss_mask: 0.9740  decode.d6.loss_dice: 0.8564  decode.d7.loss_cls: 0.1768  decode.d7.loss_mask: 0.9752  decode.d7.loss_dice: 0.8396  decode.d8.loss_cls: 0.1806  decode.d8.loss_mask: 0.9996  decode.d8.loss_dice: 0.8655
05/26 18:55:01 - mmengine - INFO - Iter(train) [ 67700/160000]  base_lr: 6.0950e-05 lr: 6.0950e-06  eta: 10:33:26  time: 0.4128  data_time: 0.0097  memory: 5979  grad_norm: 721.5381  loss: 26.9344  decode.loss_cls: 0.3778  decode.loss_mask: 1.2699  decode.loss_dice: 0.9849  decode.d0.loss_cls: 0.9419  decode.d0.loss_mask: 1.1335  decode.d0.loss_dice: 0.9585  decode.d1.loss_cls: 0.3902  decode.d1.loss_mask: 1.2643  decode.d1.loss_dice: 0.9781  decode.d2.loss_cls: 0.4889  decode.d2.loss_mask: 1.2308  decode.d2.loss_dice: 0.9435  decode.d3.loss_cls: 0.4618  decode.d3.loss_mask: 1.2273  decode.d3.loss_dice: 0.9457  decode.d4.loss_cls: 0.4516  decode.d4.loss_mask: 1.2180  decode.d4.loss_dice: 0.9763  decode.d5.loss_cls: 0.4020  decode.d5.loss_mask: 1.3197  decode.d5.loss_dice: 0.9999  decode.d6.loss_cls: 0.4079  decode.d6.loss_mask: 1.3418  decode.d6.loss_dice: 0.9971  decode.d7.loss_cls: 0.4461  decode.d7.loss_mask: 1.1890  decode.d7.loss_dice: 0.9337  decode.d8.loss_cls: 0.4048  decode.d8.loss_mask: 1.2770  decode.d8.loss_dice: 0.9725
05/26 18:55:22 - mmengine - INFO - Iter(train) [ 67750/160000]  base_lr: 6.0921e-05 lr: 6.0921e-06  eta: 10:33:06  time: 0.4125  data_time: 0.0096  memory: 5967  grad_norm: 502.9399  loss: 16.1793  decode.loss_cls: 0.0934  decode.loss_mask: 0.8609  decode.loss_dice: 0.6051  decode.d0.loss_cls: 0.5160  decode.d0.loss_mask: 0.8442  decode.d0.loss_dice: 0.6062  decode.d1.loss_cls: 0.1259  decode.d1.loss_mask: 0.8681  decode.d1.loss_dice: 0.5976  decode.d2.loss_cls: 0.1281  decode.d2.loss_mask: 0.8610  decode.d2.loss_dice: 0.5973  decode.d3.loss_cls: 0.1031  decode.d3.loss_mask: 0.8909  decode.d3.loss_dice: 0.5911  decode.d4.loss_cls: 0.1238  decode.d4.loss_mask: 0.8691  decode.d4.loss_dice: 0.5996  decode.d5.loss_cls: 0.1304  decode.d5.loss_mask: 0.8508  decode.d5.loss_dice: 0.5892  decode.d6.loss_cls: 0.1220  decode.d6.loss_mask: 0.8654  decode.d6.loss_dice: 0.5980  decode.d7.loss_cls: 0.1230  decode.d7.loss_mask: 0.8588  decode.d7.loss_dice: 0.6062  decode.d8.loss_cls: 0.1124  decode.d8.loss_mask: 0.8442  decode.d8.loss_dice: 0.5978
05/26 18:55:42 - mmengine - INFO - Iter(train) [ 67800/160000]  base_lr: 6.0891e-05 lr: 6.0891e-06  eta: 10:32:45  time: 0.4123  data_time: 0.0096  memory: 5971  grad_norm: 538.2633  loss: 19.9998  decode.loss_cls: 0.1920  decode.loss_mask: 1.0239  decode.loss_dice: 0.7230  decode.d0.loss_cls: 0.7158  decode.d0.loss_mask: 0.9777  decode.d0.loss_dice: 0.7046  decode.d1.loss_cls: 0.2183  decode.d1.loss_mask: 1.0090  decode.d1.loss_dice: 0.7281  decode.d2.loss_cls: 0.2171  decode.d2.loss_mask: 1.0042  decode.d2.loss_dice: 0.7142  decode.d3.loss_cls: 0.1429  decode.d3.loss_mask: 1.0706  decode.d3.loss_dice: 0.7457  decode.d4.loss_cls: 0.2030  decode.d4.loss_mask: 1.0153  decode.d4.loss_dice: 0.7175  decode.d5.loss_cls: 0.2156  decode.d5.loss_mask: 1.0200  decode.d5.loss_dice: 0.7267  decode.d6.loss_cls: 0.2202  decode.d6.loss_mask: 1.0218  decode.d6.loss_dice: 0.7321  decode.d7.loss_cls: 0.1961  decode.d7.loss_mask: 1.0375  decode.d7.loss_dice: 0.7335  decode.d8.loss_cls: 0.1459  decode.d8.loss_mask: 1.0638  decode.d8.loss_dice: 0.7638
05/26 18:56:03 - mmengine - INFO - Iter(train) [ 67850/160000]  base_lr: 6.0861e-05 lr: 6.0861e-06  eta: 10:32:25  time: 0.4126  data_time: 0.0096  memory: 5983  grad_norm: 403.9158  loss: 18.5578  decode.loss_cls: 0.1873  decode.loss_mask: 0.9884  decode.loss_dice: 0.6243  decode.d0.loss_cls: 0.6507  decode.d0.loss_mask: 0.9386  decode.d0.loss_dice: 0.6309  decode.d1.loss_cls: 0.2127  decode.d1.loss_mask: 0.9781  decode.d1.loss_dice: 0.6036  decode.d2.loss_cls: 0.2146  decode.d2.loss_mask: 0.9857  decode.d2.loss_dice: 0.6290  decode.d3.loss_cls: 0.1823  decode.d3.loss_mask: 0.9880  decode.d3.loss_dice: 0.6183  decode.d4.loss_cls: 0.1969  decode.d4.loss_mask: 0.9980  decode.d4.loss_dice: 0.6280  decode.d5.loss_cls: 0.2118  decode.d5.loss_mask: 1.0094  decode.d5.loss_dice: 0.6411  decode.d6.loss_cls: 0.1965  decode.d6.loss_mask: 1.0049  decode.d6.loss_dice: 0.6223  decode.d7.loss_cls: 0.1976  decode.d7.loss_mask: 0.9918  decode.d7.loss_dice: 0.6346  decode.d8.loss_cls: 0.1940  decode.d8.loss_mask: 0.9870  decode.d8.loss_dice: 0.6114
05/26 18:56:24 - mmengine - INFO - Iter(train) [ 67900/160000]  base_lr: 6.0831e-05 lr: 6.0831e-06  eta: 10:32:04  time: 0.4134  data_time: 0.0096  memory: 5966  grad_norm: 983.6956  loss: 22.2624  decode.loss_cls: 0.2739  decode.loss_mask: 1.1093  decode.loss_dice: 0.8042  decode.d0.loss_cls: 0.8620  decode.d0.loss_mask: 1.0472  decode.d0.loss_dice: 0.7494  decode.d1.loss_cls: 0.3382  decode.d1.loss_mask: 1.1076  decode.d1.loss_dice: 0.7571  decode.d2.loss_cls: 0.3150  decode.d2.loss_mask: 1.0668  decode.d2.loss_dice: 0.7466  decode.d3.loss_cls: 0.3738  decode.d3.loss_mask: 1.0960  decode.d3.loss_dice: 0.7631  decode.d4.loss_cls: 0.3155  decode.d4.loss_mask: 1.0443  decode.d4.loss_dice: 0.7722  decode.d5.loss_cls: 0.2889  decode.d5.loss_mask: 1.0957  decode.d5.loss_dice: 0.7789  decode.d6.loss_cls: 0.3277  decode.d6.loss_mask: 1.0728  decode.d6.loss_dice: 0.7899  decode.d7.loss_cls: 0.2912  decode.d7.loss_mask: 1.1014  decode.d7.loss_dice: 0.7892  decode.d8.loss_cls: 0.3118  decode.d8.loss_mask: 1.0859  decode.d8.loss_dice: 0.7869
05/26 18:56:45 - mmengine - INFO - Iter(train) [ 67950/160000]  base_lr: 6.0802e-05 lr: 6.0802e-06  eta: 10:31:44  time: 0.4125  data_time: 0.0096  memory: 5990  grad_norm: 680.4253  loss: 21.8731  decode.loss_cls: 0.3342  decode.loss_mask: 0.9411  decode.loss_dice: 0.8289  decode.d0.loss_cls: 0.8701  decode.d0.loss_mask: 0.9038  decode.d0.loss_dice: 0.7770  decode.d1.loss_cls: 0.3352  decode.d1.loss_mask: 0.9618  decode.d1.loss_dice: 0.8372  decode.d2.loss_cls: 0.3910  decode.d2.loss_mask: 0.9403  decode.d2.loss_dice: 0.8073  decode.d3.loss_cls: 0.3953  decode.d3.loss_mask: 0.9434  decode.d3.loss_dice: 0.8063  decode.d4.loss_cls: 0.3405  decode.d4.loss_mask: 0.9575  decode.d4.loss_dice: 0.8292  decode.d5.loss_cls: 0.3385  decode.d5.loss_mask: 0.9675  decode.d5.loss_dice: 0.8482  decode.d6.loss_cls: 0.4213  decode.d6.loss_mask: 0.9377  decode.d6.loss_dice: 0.8102  decode.d7.loss_cls: 0.3619  decode.d7.loss_mask: 0.9524  decode.d7.loss_dice: 0.8347  decode.d8.loss_cls: 0.3601  decode.d8.loss_mask: 0.9813  decode.d8.loss_dice: 0.8594
05/26 18:57:05 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 18:57:05 - mmengine - INFO - Iter(train) [ 68000/160000]  base_lr: 6.0772e-05 lr: 6.0772e-06  eta: 10:31:23  time: 0.4125  data_time: 0.0097  memory: 5976  grad_norm: 594.9762  loss: 21.0558  decode.loss_cls: 0.1702  decode.loss_mask: 1.0568  decode.loss_dice: 0.7948  decode.d0.loss_cls: 0.6294  decode.d0.loss_mask: 1.0415  decode.d0.loss_dice: 0.7996  decode.d1.loss_cls: 0.1716  decode.d1.loss_mask: 1.0858  decode.d1.loss_dice: 0.8125  decode.d2.loss_cls: 0.1707  decode.d2.loss_mask: 1.0664  decode.d2.loss_dice: 0.8118  decode.d3.loss_cls: 0.1529  decode.d3.loss_mask: 1.0596  decode.d3.loss_dice: 0.7911  decode.d4.loss_cls: 0.1721  decode.d4.loss_mask: 1.0818  decode.d4.loss_dice: 0.8113  decode.d5.loss_cls: 0.2335  decode.d5.loss_mask: 1.0538  decode.d5.loss_dice: 0.8079  decode.d6.loss_cls: 0.1631  decode.d6.loss_mask: 1.1029  decode.d6.loss_dice: 0.8255  decode.d7.loss_cls: 0.2046  decode.d7.loss_mask: 1.0634  decode.d7.loss_dice: 0.8359  decode.d8.loss_cls: 0.1963  decode.d8.loss_mask: 1.0740  decode.d8.loss_dice: 0.8150
05/26 18:57:26 - mmengine - INFO - Iter(train) [ 68050/160000]  base_lr: 6.0742e-05 lr: 6.0742e-06  eta: 10:31:03  time: 0.4131  data_time: 0.0097  memory: 5968  grad_norm: 443.0974  loss: 16.2800  decode.loss_cls: 0.2398  decode.loss_mask: 0.7413  decode.loss_dice: 0.5768  decode.d0.loss_cls: 0.6203  decode.d0.loss_mask: 0.7171  decode.d0.loss_dice: 0.5904  decode.d1.loss_cls: 0.1928  decode.d1.loss_mask: 0.7656  decode.d1.loss_dice: 0.6556  decode.d2.loss_cls: 0.1937  decode.d2.loss_mask: 0.7627  decode.d2.loss_dice: 0.6327  decode.d3.loss_cls: 0.1833  decode.d3.loss_mask: 0.7673  decode.d3.loss_dice: 0.6020  decode.d4.loss_cls: 0.2842  decode.d4.loss_mask: 0.7417  decode.d4.loss_dice: 0.5929  decode.d5.loss_cls: 0.2450  decode.d5.loss_mask: 0.7531  decode.d5.loss_dice: 0.6178  decode.d6.loss_cls: 0.2158  decode.d6.loss_mask: 0.7512  decode.d6.loss_dice: 0.6346  decode.d7.loss_cls: 0.2093  decode.d7.loss_mask: 0.7584  decode.d7.loss_dice: 0.6332  decode.d8.loss_cls: 0.2299  decode.d8.loss_mask: 0.7554  decode.d8.loss_dice: 0.6161
05/26 18:57:47 - mmengine - INFO - Iter(train) [ 68100/160000]  base_lr: 6.0713e-05 lr: 6.0713e-06  eta: 10:30:42  time: 0.4122  data_time: 0.0096  memory: 5969  grad_norm: 526.8503  loss: 22.8907  decode.loss_cls: 0.2476  decode.loss_mask: 1.1763  decode.loss_dice: 0.8573  decode.d0.loss_cls: 0.6143  decode.d0.loss_mask: 1.0610  decode.d0.loss_dice: 0.8347  decode.d1.loss_cls: 0.2129  decode.d1.loss_mask: 1.1616  decode.d1.loss_dice: 0.8470  decode.d2.loss_cls: 0.2664  decode.d2.loss_mask: 1.1107  decode.d2.loss_dice: 0.8335  decode.d3.loss_cls: 0.2597  decode.d3.loss_mask: 1.1292  decode.d3.loss_dice: 0.8712  decode.d4.loss_cls: 0.2572  decode.d4.loss_mask: 1.1752  decode.d4.loss_dice: 0.8578  decode.d5.loss_cls: 0.2221  decode.d5.loss_mask: 1.1573  decode.d5.loss_dice: 0.8660  decode.d6.loss_cls: 0.2192  decode.d6.loss_mask: 1.2079  decode.d6.loss_dice: 0.8981  decode.d7.loss_cls: 0.2790  decode.d7.loss_mask: 1.1334  decode.d7.loss_dice: 0.8383  decode.d8.loss_cls: 0.2435  decode.d8.loss_mask: 1.1846  decode.d8.loss_dice: 0.8674
05/26 18:58:07 - mmengine - INFO - Iter(train) [ 68150/160000]  base_lr: 6.0683e-05 lr: 6.0683e-06  eta: 10:30:22  time: 0.4136  data_time: 0.0097  memory: 5982  grad_norm: 1160.5638  loss: 22.8318  decode.loss_cls: 0.3120  decode.loss_mask: 1.1219  decode.loss_dice: 0.8007  decode.d0.loss_cls: 0.7750  decode.d0.loss_mask: 1.0056  decode.d0.loss_dice: 0.7307  decode.d1.loss_cls: 0.3252  decode.d1.loss_mask: 1.1631  decode.d1.loss_dice: 0.8449  decode.d2.loss_cls: 0.3314  decode.d2.loss_mask: 1.1286  decode.d2.loss_dice: 0.8446  decode.d3.loss_cls: 0.3360  decode.d3.loss_mask: 1.1344  decode.d3.loss_dice: 0.8206  decode.d4.loss_cls: 0.3340  decode.d4.loss_mask: 1.1186  decode.d4.loss_dice: 0.8139  decode.d5.loss_cls: 0.3169  decode.d5.loss_mask: 1.0992  decode.d5.loss_dice: 0.7930  decode.d6.loss_cls: 0.3231  decode.d6.loss_mask: 1.0672  decode.d6.loss_dice: 0.7646  decode.d7.loss_cls: 0.3407  decode.d7.loss_mask: 1.1005  decode.d7.loss_dice: 0.8202  decode.d8.loss_cls: 0.3486  decode.d8.loss_mask: 1.1237  decode.d8.loss_dice: 0.7932
05/26 18:58:28 - mmengine - INFO - Iter(train) [ 68200/160000]  base_lr: 6.0653e-05 lr: 6.0653e-06  eta: 10:30:01  time: 0.4124  data_time: 0.0097  memory: 5971  grad_norm: 696.1523  loss: 21.9291  decode.loss_cls: 0.3572  decode.loss_mask: 1.1452  decode.loss_dice: 0.6580  decode.d0.loss_cls: 0.8257  decode.d0.loss_mask: 1.0432  decode.d0.loss_dice: 0.6672  decode.d1.loss_cls: 0.3896  decode.d1.loss_mask: 1.1392  decode.d1.loss_dice: 0.6662  decode.d2.loss_cls: 0.3214  decode.d2.loss_mask: 1.1465  decode.d2.loss_dice: 0.6928  decode.d3.loss_cls: 0.3164  decode.d3.loss_mask: 1.1274  decode.d3.loss_dice: 0.6698  decode.d4.loss_cls: 0.3127  decode.d4.loss_mask: 1.1191  decode.d4.loss_dice: 0.6889  decode.d5.loss_cls: 0.3044  decode.d5.loss_mask: 1.1532  decode.d5.loss_dice: 0.6860  decode.d6.loss_cls: 0.3102  decode.d6.loss_mask: 1.1497  decode.d6.loss_dice: 0.6963  decode.d7.loss_cls: 0.3661  decode.d7.loss_mask: 1.1180  decode.d7.loss_dice: 0.6922  decode.d8.loss_cls: 0.3661  decode.d8.loss_mask: 1.1117  decode.d8.loss_dice: 0.6886
05/26 18:58:48 - mmengine - INFO - Iter(train) [ 68250/160000]  base_lr: 6.0623e-05 lr: 6.0623e-06  eta: 10:29:41  time: 0.4123  data_time: 0.0097  memory: 5967  grad_norm: 408.6229  loss: 21.2451  decode.loss_cls: 0.2173  decode.loss_mask: 1.0524  decode.loss_dice: 0.7914  decode.d0.loss_cls: 0.5411  decode.d0.loss_mask: 1.0443  decode.d0.loss_dice: 0.7804  decode.d1.loss_cls: 0.1979  decode.d1.loss_mask: 1.0698  decode.d1.loss_dice: 0.8477  decode.d2.loss_cls: 0.2505  decode.d2.loss_mask: 1.0700  decode.d2.loss_dice: 0.8040  decode.d3.loss_cls: 0.2408  decode.d3.loss_mask: 1.0493  decode.d3.loss_dice: 0.7905  decode.d4.loss_cls: 0.2498  decode.d4.loss_mask: 1.0556  decode.d4.loss_dice: 0.8001  decode.d5.loss_cls: 0.2515  decode.d5.loss_mask: 1.0573  decode.d5.loss_dice: 0.7901  decode.d6.loss_cls: 0.2106  decode.d6.loss_mask: 1.0610  decode.d6.loss_dice: 0.8258  decode.d7.loss_cls: 0.2474  decode.d7.loss_mask: 1.0656  decode.d7.loss_dice: 0.8087  decode.d8.loss_cls: 0.2099  decode.d8.loss_mask: 1.0577  decode.d8.loss_dice: 0.8065
05/26 18:59:09 - mmengine - INFO - Iter(train) [ 68300/160000]  base_lr: 6.0594e-05 lr: 6.0594e-06  eta: 10:29:20  time: 0.4388  data_time: 0.0097  memory: 5966  grad_norm: 504.5473  loss: 23.7846  decode.loss_cls: 0.2327  decode.loss_mask: 1.2815  decode.loss_dice: 0.8133  decode.d0.loss_cls: 0.8897  decode.d0.loss_mask: 1.1795  decode.d0.loss_dice: 0.8012  decode.d1.loss_cls: 0.3274  decode.d1.loss_mask: 1.2164  decode.d1.loss_dice: 0.8320  decode.d2.loss_cls: 0.3033  decode.d2.loss_mask: 1.1332  decode.d2.loss_dice: 0.8100  decode.d3.loss_cls: 0.2646  decode.d3.loss_mask: 1.2808  decode.d3.loss_dice: 0.8350  decode.d4.loss_cls: 0.2815  decode.d4.loss_mask: 1.2499  decode.d4.loss_dice: 0.8356  decode.d5.loss_cls: 0.3635  decode.d5.loss_mask: 1.0742  decode.d5.loss_dice: 0.7754  decode.d6.loss_cls: 0.3255  decode.d6.loss_mask: 1.1011  decode.d6.loss_dice: 0.7885  decode.d7.loss_cls: 0.3076  decode.d7.loss_mask: 1.2309  decode.d7.loss_dice: 0.8655  decode.d8.loss_cls: 0.2474  decode.d8.loss_mask: 1.2953  decode.d8.loss_dice: 0.8421
05/26 18:59:30 - mmengine - INFO - Iter(train) [ 68350/160000]  base_lr: 6.0564e-05 lr: 6.0564e-06  eta: 10:29:00  time: 0.4131  data_time: 0.0097  memory: 5974  grad_norm: 1009.3614  loss: 23.5369  decode.loss_cls: 0.2640  decode.loss_mask: 1.2235  decode.loss_dice: 0.8304  decode.d0.loss_cls: 0.6867  decode.d0.loss_mask: 1.1362  decode.d0.loss_dice: 0.7729  decode.d1.loss_cls: 0.2990  decode.d1.loss_mask: 1.1854  decode.d1.loss_dice: 0.8483  decode.d2.loss_cls: 0.2437  decode.d2.loss_mask: 1.2303  decode.d2.loss_dice: 0.8601  decode.d3.loss_cls: 0.2659  decode.d3.loss_mask: 1.2125  decode.d3.loss_dice: 0.8455  decode.d4.loss_cls: 0.2439  decode.d4.loss_mask: 1.2168  decode.d4.loss_dice: 0.8295  decode.d5.loss_cls: 0.2456  decode.d5.loss_mask: 1.2182  decode.d5.loss_dice: 0.8322  decode.d6.loss_cls: 0.2438  decode.d6.loss_mask: 1.2464  decode.d6.loss_dice: 0.8346  decode.d7.loss_cls: 0.2062  decode.d7.loss_mask: 1.2670  decode.d7.loss_dice: 0.8919  decode.d8.loss_cls: 0.3181  decode.d8.loss_mask: 1.1801  decode.d8.loss_dice: 0.8582
05/26 18:59:51 - mmengine - INFO - Iter(train) [ 68400/160000]  base_lr: 6.0534e-05 lr: 6.0534e-06  eta: 10:28:40  time: 0.4143  data_time: 0.0097  memory: 5968  grad_norm: 739.7942  loss: 21.0208  decode.loss_cls: 0.2407  decode.loss_mask: 1.0788  decode.loss_dice: 0.7342  decode.d0.loss_cls: 0.5991  decode.d0.loss_mask: 1.1318  decode.d0.loss_dice: 0.7832  decode.d1.loss_cls: 0.1773  decode.d1.loss_mask: 1.0819  decode.d1.loss_dice: 0.7555  decode.d2.loss_cls: 0.2381  decode.d2.loss_mask: 1.1157  decode.d2.loss_dice: 0.7359  decode.d3.loss_cls: 0.2224  decode.d3.loss_mask: 1.1116  decode.d3.loss_dice: 0.7408  decode.d4.loss_cls: 0.2311  decode.d4.loss_mask: 1.1332  decode.d4.loss_dice: 0.7671  decode.d5.loss_cls: 0.2232  decode.d5.loss_mask: 1.0761  decode.d5.loss_dice: 0.7538  decode.d6.loss_cls: 0.2336  decode.d6.loss_mask: 1.0650  decode.d6.loss_dice: 0.7344  decode.d7.loss_cls: 0.2199  decode.d7.loss_mask: 1.1149  decode.d7.loss_dice: 0.7303  decode.d8.loss_cls: 0.1938  decode.d8.loss_mask: 1.0650  decode.d8.loss_dice: 0.7324
05/26 19:00:11 - mmengine - INFO - Iter(train) [ 68450/160000]  base_lr: 6.0504e-05 lr: 6.0504e-06  eta: 10:28:19  time: 0.4150  data_time: 0.0098  memory: 5969  grad_norm: 935.5266  loss: 26.3206  decode.loss_cls: 0.2446  decode.loss_mask: 1.3277  decode.loss_dice: 0.9744  decode.d0.loss_cls: 0.8769  decode.d0.loss_mask: 1.2054  decode.d0.loss_dice: 0.8984  decode.d1.loss_cls: 0.3257  decode.d1.loss_mask: 1.3442  decode.d1.loss_dice: 0.9550  decode.d2.loss_cls: 0.2440  decode.d2.loss_mask: 1.3528  decode.d2.loss_dice: 0.9916  decode.d3.loss_cls: 0.2612  decode.d3.loss_mask: 1.3296  decode.d3.loss_dice: 0.9904  decode.d4.loss_cls: 0.2997  decode.d4.loss_mask: 1.3441  decode.d4.loss_dice: 0.9843  decode.d5.loss_cls: 0.3161  decode.d5.loss_mask: 1.3305  decode.d5.loss_dice: 0.9533  decode.d6.loss_cls: 0.2727  decode.d6.loss_mask: 1.3553  decode.d6.loss_dice: 0.9692  decode.d7.loss_cls: 0.2399  decode.d7.loss_mask: 1.3668  decode.d7.loss_dice: 0.9981  decode.d8.loss_cls: 0.2460  decode.d8.loss_mask: 1.3397  decode.d8.loss_dice: 0.9830
05/26 19:00:32 - mmengine - INFO - Iter(train) [ 68500/160000]  base_lr: 6.0475e-05 lr: 6.0475e-06  eta: 10:27:59  time: 0.4154  data_time: 0.0098  memory: 5965  grad_norm: 1420.2041  loss: 20.8715  decode.loss_cls: 0.1895  decode.loss_mask: 1.1489  decode.loss_dice: 0.7295  decode.d0.loss_cls: 0.6244  decode.d0.loss_mask: 1.0641  decode.d0.loss_dice: 0.7201  decode.d1.loss_cls: 0.2464  decode.d1.loss_mask: 1.0900  decode.d1.loss_dice: 0.7132  decode.d2.loss_cls: 0.2086  decode.d2.loss_mask: 1.1136  decode.d2.loss_dice: 0.7305  decode.d3.loss_cls: 0.2182  decode.d3.loss_mask: 1.1132  decode.d3.loss_dice: 0.7282  decode.d4.loss_cls: 0.2559  decode.d4.loss_mask: 1.0951  decode.d4.loss_dice: 0.7262  decode.d5.loss_cls: 0.2326  decode.d5.loss_mask: 1.1069  decode.d5.loss_dice: 0.7177  decode.d6.loss_cls: 0.1930  decode.d6.loss_mask: 1.0672  decode.d6.loss_dice: 0.7056  decode.d7.loss_cls: 0.2111  decode.d7.loss_mask: 1.1044  decode.d7.loss_dice: 0.7322  decode.d8.loss_cls: 0.2451  decode.d8.loss_mask: 1.1044  decode.d8.loss_dice: 0.7356
05/26 19:00:53 - mmengine - INFO - Iter(train) [ 68550/160000]  base_lr: 6.0445e-05 lr: 6.0445e-06  eta: 10:27:38  time: 0.4128  data_time: 0.0097  memory: 5982  grad_norm: 718.2760  loss: 25.1761  decode.loss_cls: 0.2617  decode.loss_mask: 1.3707  decode.loss_dice: 0.9079  decode.d0.loss_cls: 0.5910  decode.d0.loss_mask: 1.2836  decode.d0.loss_dice: 0.8556  decode.d1.loss_cls: 0.2778  decode.d1.loss_mask: 1.3195  decode.d1.loss_dice: 0.8508  decode.d2.loss_cls: 0.2622  decode.d2.loss_mask: 1.3054  decode.d2.loss_dice: 0.8589  decode.d3.loss_cls: 0.2358  decode.d3.loss_mask: 1.3596  decode.d3.loss_dice: 0.9299  decode.d4.loss_cls: 0.2337  decode.d4.loss_mask: 1.3260  decode.d4.loss_dice: 0.8721  decode.d5.loss_cls: 0.2679  decode.d5.loss_mask: 1.3487  decode.d5.loss_dice: 0.9073  decode.d6.loss_cls: 0.2823  decode.d6.loss_mask: 1.3149  decode.d6.loss_dice: 0.8610  decode.d7.loss_cls: 0.2697  decode.d7.loss_mask: 1.3880  decode.d7.loss_dice: 0.8861  decode.d8.loss_cls: 0.2351  decode.d8.loss_mask: 1.3971  decode.d8.loss_dice: 0.9159
05/26 19:01:14 - mmengine - INFO - Iter(train) [ 68600/160000]  base_lr: 6.0415e-05 lr: 6.0415e-06  eta: 10:27:18  time: 0.4133  data_time: 0.0097  memory: 5979  grad_norm: 865.3292  loss: 21.0977  decode.loss_cls: 0.1335  decode.loss_mask: 1.1378  decode.loss_dice: 0.7632  decode.d0.loss_cls: 0.7144  decode.d0.loss_mask: 1.1184  decode.d0.loss_dice: 0.7673  decode.d1.loss_cls: 0.1766  decode.d1.loss_mask: 1.1072  decode.d1.loss_dice: 0.7928  decode.d2.loss_cls: 0.1335  decode.d2.loss_mask: 1.0953  decode.d2.loss_dice: 0.7923  decode.d3.loss_cls: 0.1230  decode.d3.loss_mask: 1.1097  decode.d3.loss_dice: 0.7838  decode.d4.loss_cls: 0.1660  decode.d4.loss_mask: 1.1381  decode.d4.loss_dice: 0.8005  decode.d5.loss_cls: 0.1911  decode.d5.loss_mask: 1.1040  decode.d5.loss_dice: 0.7620  decode.d6.loss_cls: 0.2318  decode.d6.loss_mask: 1.0799  decode.d6.loss_dice: 0.7393  decode.d7.loss_cls: 0.1846  decode.d7.loss_mask: 1.1219  decode.d7.loss_dice: 0.7788  decode.d8.loss_cls: 0.1528  decode.d8.loss_mask: 1.1180  decode.d8.loss_dice: 0.7801
05/26 19:01:35 - mmengine - INFO - Iter(train) [ 68650/160000]  base_lr: 6.0385e-05 lr: 6.0385e-06  eta: 10:26:58  time: 0.4154  data_time: 0.0097  memory: 5976  grad_norm: 535.6342  loss: 22.7061  decode.loss_cls: 0.1788  decode.loss_mask: 1.0882  decode.loss_dice: 0.9207  decode.d0.loss_cls: 0.7964  decode.d0.loss_mask: 1.0730  decode.d0.loss_dice: 0.9245  decode.d1.loss_cls: 0.2524  decode.d1.loss_mask: 1.0699  decode.d1.loss_dice: 0.8859  decode.d2.loss_cls: 0.2741  decode.d2.loss_mask: 1.0638  decode.d2.loss_dice: 0.8704  decode.d3.loss_cls: 0.2527  decode.d3.loss_mask: 1.0985  decode.d3.loss_dice: 0.8818  decode.d4.loss_cls: 0.2405  decode.d4.loss_mask: 1.0884  decode.d4.loss_dice: 0.8975  decode.d5.loss_cls: 0.2530  decode.d5.loss_mask: 1.0654  decode.d5.loss_dice: 0.9109  decode.d6.loss_cls: 0.2306  decode.d6.loss_mask: 1.0754  decode.d6.loss_dice: 0.9150  decode.d7.loss_cls: 0.2130  decode.d7.loss_mask: 1.0720  decode.d7.loss_dice: 0.9105  decode.d8.loss_cls: 0.2218  decode.d8.loss_mask: 1.0655  decode.d8.loss_dice: 0.9155
05/26 19:01:55 - mmengine - INFO - Iter(train) [ 68700/160000]  base_lr: 6.0356e-05 lr: 6.0356e-06  eta: 10:26:37  time: 0.4142  data_time: 0.0097  memory: 5971  grad_norm: 684.5485  loss: 23.8024  decode.loss_cls: 0.3362  decode.loss_mask: 1.1123  decode.loss_dice: 0.8878  decode.d0.loss_cls: 0.8428  decode.d0.loss_mask: 1.0641  decode.d0.loss_dice: 0.8596  decode.d1.loss_cls: 0.3392  decode.d1.loss_mask: 1.1496  decode.d1.loss_dice: 0.8486  decode.d2.loss_cls: 0.3291  decode.d2.loss_mask: 1.0992  decode.d2.loss_dice: 0.8571  decode.d3.loss_cls: 0.3586  decode.d3.loss_mask: 1.1108  decode.d3.loss_dice: 0.9013  decode.d4.loss_cls: 0.2749  decode.d4.loss_mask: 1.1603  decode.d4.loss_dice: 0.8877  decode.d5.loss_cls: 0.3602  decode.d5.loss_mask: 1.1446  decode.d5.loss_dice: 0.8723  decode.d6.loss_cls: 0.3811  decode.d6.loss_mask: 1.0842  decode.d6.loss_dice: 0.8815  decode.d7.loss_cls: 0.3631  decode.d7.loss_mask: 1.0973  decode.d7.loss_dice: 0.8563  decode.d8.loss_cls: 0.3683  decode.d8.loss_mask: 1.0887  decode.d8.loss_dice: 0.8854
05/26 19:02:16 - mmengine - INFO - Iter(train) [ 68750/160000]  base_lr: 6.0326e-05 lr: 6.0326e-06  eta: 10:26:17  time: 0.4143  data_time: 0.0098  memory: 5966  grad_norm: 549.0451  loss: 23.9405  decode.loss_cls: 0.2102  decode.loss_mask: 1.2419  decode.loss_dice: 0.8652  decode.d0.loss_cls: 0.8235  decode.d0.loss_mask: 1.1380  decode.d0.loss_dice: 0.8353  decode.d1.loss_cls: 0.2406  decode.d1.loss_mask: 1.2273  decode.d1.loss_dice: 0.8812  decode.d2.loss_cls: 0.2623  decode.d2.loss_mask: 1.2466  decode.d2.loss_dice: 0.8797  decode.d3.loss_cls: 0.2385  decode.d3.loss_mask: 1.2335  decode.d3.loss_dice: 0.9175  decode.d4.loss_cls: 0.2558  decode.d4.loss_mask: 1.2185  decode.d4.loss_dice: 0.8801  decode.d5.loss_cls: 0.2476  decode.d5.loss_mask: 1.2080  decode.d5.loss_dice: 0.8681  decode.d6.loss_cls: 0.2295  decode.d6.loss_mask: 1.2266  decode.d6.loss_dice: 0.8859  decode.d7.loss_cls: 0.2255  decode.d7.loss_mask: 1.2244  decode.d7.loss_dice: 0.9239  decode.d8.loss_cls: 0.2138  decode.d8.loss_mask: 1.2263  decode.d8.loss_dice: 0.8653
05/26 19:02:37 - mmengine - INFO - Iter(train) [ 68800/160000]  base_lr: 6.0296e-05 lr: 6.0296e-06  eta: 10:25:57  time: 0.4137  data_time: 0.0097  memory: 5975  grad_norm: 745.1890  loss: 25.0226  decode.loss_cls: 0.3297  decode.loss_mask: 1.2551  decode.loss_dice: 0.7824  decode.d0.loss_cls: 0.7327  decode.d0.loss_mask: 1.2221  decode.d0.loss_dice: 0.8237  decode.d1.loss_cls: 0.3573  decode.d1.loss_mask: 1.2963  decode.d1.loss_dice: 0.8198  decode.d2.loss_cls: 0.3369  decode.d2.loss_mask: 1.3603  decode.d2.loss_dice: 0.8665  decode.d3.loss_cls: 0.3231  decode.d3.loss_mask: 1.3438  decode.d3.loss_dice: 0.8671  decode.d4.loss_cls: 0.3395  decode.d4.loss_mask: 1.3627  decode.d4.loss_dice: 0.8426  decode.d5.loss_cls: 0.3047  decode.d5.loss_mask: 1.2961  decode.d5.loss_dice: 0.8190  decode.d6.loss_cls: 0.3688  decode.d6.loss_mask: 1.2781  decode.d6.loss_dice: 0.8153  decode.d7.loss_cls: 0.3378  decode.d7.loss_mask: 1.2962  decode.d7.loss_dice: 0.8213  decode.d8.loss_cls: 0.3167  decode.d8.loss_mask: 1.2837  decode.d8.loss_dice: 0.8233
05/26 19:02:58 - mmengine - INFO - Iter(train) [ 68850/160000]  base_lr: 6.0266e-05 lr: 6.0266e-06  eta: 10:25:36  time: 0.4141  data_time: 0.0098  memory: 5979  grad_norm: 760.0428  loss: 27.9096  decode.loss_cls: 0.4480  decode.loss_mask: 1.3012  decode.loss_dice: 1.0474  decode.d0.loss_cls: 0.9505  decode.d0.loss_mask: 1.2026  decode.d0.loss_dice: 0.9863  decode.d1.loss_cls: 0.4384  decode.d1.loss_mask: 1.2370  decode.d1.loss_dice: 0.9705  decode.d2.loss_cls: 0.4279  decode.d2.loss_mask: 1.2859  decode.d2.loss_dice: 0.9897  decode.d3.loss_cls: 0.3836  decode.d3.loss_mask: 1.4198  decode.d3.loss_dice: 0.9991  decode.d4.loss_cls: 0.3891  decode.d4.loss_mask: 1.3096  decode.d4.loss_dice: 0.9911  decode.d5.loss_cls: 0.4655  decode.d5.loss_mask: 1.2789  decode.d5.loss_dice: 1.0345  decode.d6.loss_cls: 0.4275  decode.d6.loss_mask: 1.2815  decode.d6.loss_dice: 1.0280  decode.d7.loss_cls: 0.4105  decode.d7.loss_mask: 1.3726  decode.d7.loss_dice: 1.0307  decode.d8.loss_cls: 0.4804  decode.d8.loss_mask: 1.2866  decode.d8.loss_dice: 1.0353
05/26 19:03:19 - mmengine - INFO - Iter(train) [ 68900/160000]  base_lr: 6.0237e-05 lr: 6.0237e-06  eta: 10:25:17  time: 0.4721  data_time: 0.0098  memory: 5966  grad_norm: 471.6907  loss: 20.7361  decode.loss_cls: 0.1295  decode.loss_mask: 1.1135  decode.loss_dice: 0.7763  decode.d0.loss_cls: 0.5638  decode.d0.loss_mask: 1.0875  decode.d0.loss_dice: 0.7678  decode.d1.loss_cls: 0.1071  decode.d1.loss_mask: 1.1086  decode.d1.loss_dice: 0.8077  decode.d2.loss_cls: 0.0996  decode.d2.loss_mask: 1.1189  decode.d2.loss_dice: 0.8000  decode.d3.loss_cls: 0.0878  decode.d3.loss_mask: 1.1374  decode.d3.loss_dice: 0.8266  decode.d4.loss_cls: 0.0962  decode.d4.loss_mask: 1.1382  decode.d4.loss_dice: 0.8328  decode.d5.loss_cls: 0.0843  decode.d5.loss_mask: 1.1483  decode.d5.loss_dice: 0.7926  decode.d6.loss_cls: 0.1043  decode.d6.loss_mask: 1.1372  decode.d6.loss_dice: 0.7771  decode.d7.loss_cls: 0.1042  decode.d7.loss_mask: 1.1448  decode.d7.loss_dice: 0.7806  decode.d8.loss_cls: 0.1743  decode.d8.loss_mask: 1.1088  decode.d8.loss_dice: 0.7804
05/26 19:03:40 - mmengine - INFO - Iter(train) [ 68950/160000]  base_lr: 6.0207e-05 lr: 6.0207e-06  eta: 10:24:56  time: 0.4166  data_time: 0.0097  memory: 5966  grad_norm: 499.0353  loss: 23.7554  decode.loss_cls: 0.3274  decode.loss_mask: 1.1216  decode.loss_dice: 0.8947  decode.d0.loss_cls: 0.7640  decode.d0.loss_mask: 1.0830  decode.d0.loss_dice: 0.8807  decode.d1.loss_cls: 0.2987  decode.d1.loss_mask: 1.1486  decode.d1.loss_dice: 0.8924  decode.d2.loss_cls: 0.2601  decode.d2.loss_mask: 1.1707  decode.d2.loss_dice: 0.8860  decode.d3.loss_cls: 0.3289  decode.d3.loss_mask: 1.1710  decode.d3.loss_dice: 0.8953  decode.d4.loss_cls: 0.2569  decode.d4.loss_mask: 1.1563  decode.d4.loss_dice: 0.8925  decode.d5.loss_cls: 0.2832  decode.d5.loss_mask: 1.1063  decode.d5.loss_dice: 0.8705  decode.d6.loss_cls: 0.3394  decode.d6.loss_mask: 1.1316  decode.d6.loss_dice: 0.8916  decode.d7.loss_cls: 0.3427  decode.d7.loss_mask: 1.1272  decode.d7.loss_dice: 0.9112  decode.d8.loss_cls: 0.3119  decode.d8.loss_mask: 1.1150  decode.d8.loss_dice: 0.8959
05/26 19:04:01 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 19:04:01 - mmengine - INFO - Iter(train) [ 69000/160000]  base_lr: 6.0177e-05 lr: 6.0177e-06  eta: 10:24:36  time: 0.4180  data_time: 0.0097  memory: 5976  grad_norm: 630.3319  loss: 21.5802  decode.loss_cls: 0.2332  decode.loss_mask: 1.1135  decode.loss_dice: 0.7731  decode.d0.loss_cls: 0.7114  decode.d0.loss_mask: 0.9871  decode.d0.loss_dice: 0.7578  decode.d1.loss_cls: 0.2809  decode.d1.loss_mask: 1.0491  decode.d1.loss_dice: 0.7810  decode.d2.loss_cls: 0.3124  decode.d2.loss_mask: 1.0679  decode.d2.loss_dice: 0.7985  decode.d3.loss_cls: 0.2900  decode.d3.loss_mask: 1.0824  decode.d3.loss_dice: 0.7385  decode.d4.loss_cls: 0.2626  decode.d4.loss_mask: 1.0887  decode.d4.loss_dice: 0.7824  decode.d5.loss_cls: 0.2677  decode.d5.loss_mask: 1.0799  decode.d5.loss_dice: 0.7581  decode.d6.loss_cls: 0.2487  decode.d6.loss_mask: 1.0895  decode.d6.loss_dice: 0.7844  decode.d7.loss_cls: 0.2648  decode.d7.loss_mask: 1.0999  decode.d7.loss_dice: 0.7655  decode.d8.loss_cls: 0.2479  decode.d8.loss_mask: 1.0666  decode.d8.loss_dice: 0.7967
05/26 19:04:21 - mmengine - INFO - Iter(train) [ 69050/160000]  base_lr: 6.0147e-05 lr: 6.0147e-06  eta: 10:24:16  time: 0.4171  data_time: 0.0099  memory: 5970  grad_norm: 734.1603  loss: 22.6644  decode.loss_cls: 0.3103  decode.loss_mask: 1.0175  decode.loss_dice: 0.8578  decode.d0.loss_cls: 0.9000  decode.d0.loss_mask: 0.9552  decode.d0.loss_dice: 0.8125  decode.d1.loss_cls: 0.3314  decode.d1.loss_mask: 1.0148  decode.d1.loss_dice: 0.8776  decode.d2.loss_cls: 0.3250  decode.d2.loss_mask: 1.0737  decode.d2.loss_dice: 0.8797  decode.d3.loss_cls: 0.3588  decode.d3.loss_mask: 1.0074  decode.d3.loss_dice: 0.8581  decode.d4.loss_cls: 0.4048  decode.d4.loss_mask: 0.9793  decode.d4.loss_dice: 0.8402  decode.d5.loss_cls: 0.3473  decode.d5.loss_mask: 1.0221  decode.d5.loss_dice: 0.8610  decode.d6.loss_cls: 0.3549  decode.d6.loss_mask: 0.9931  decode.d6.loss_dice: 0.8585  decode.d7.loss_cls: 0.3257  decode.d7.loss_mask: 1.0073  decode.d7.loss_dice: 0.8906  decode.d8.loss_cls: 0.3201  decode.d8.loss_mask: 1.0131  decode.d8.loss_dice: 0.8666
05/26 19:04:42 - mmengine - INFO - Iter(train) [ 69100/160000]  base_lr: 6.0118e-05 lr: 6.0118e-06  eta: 10:23:55  time: 0.4156  data_time: 0.0097  memory: 5989  grad_norm: 610.1267  loss: 24.2074  decode.loss_cls: 0.3580  decode.loss_mask: 1.1223  decode.loss_dice: 0.8431  decode.d0.loss_cls: 0.8317  decode.d0.loss_mask: 1.1025  decode.d0.loss_dice: 0.8442  decode.d1.loss_cls: 0.3772  decode.d1.loss_mask: 1.1408  decode.d1.loss_dice: 0.8530  decode.d2.loss_cls: 0.3188  decode.d2.loss_mask: 1.2337  decode.d2.loss_dice: 0.8792  decode.d3.loss_cls: 0.3384  decode.d3.loss_mask: 1.1408  decode.d3.loss_dice: 0.8413  decode.d4.loss_cls: 0.3285  decode.d4.loss_mask: 1.1898  decode.d4.loss_dice: 0.8290  decode.d5.loss_cls: 0.3329  decode.d5.loss_mask: 1.2037  decode.d5.loss_dice: 0.8439  decode.d6.loss_cls: 0.3547  decode.d6.loss_mask: 1.2769  decode.d6.loss_dice: 0.8575  decode.d7.loss_cls: 0.3469  decode.d7.loss_mask: 1.1854  decode.d7.loss_dice: 0.8667  decode.d8.loss_cls: 0.2897  decode.d8.loss_mask: 1.1973  decode.d8.loss_dice: 0.8796
05/26 19:05:03 - mmengine - INFO - Iter(train) [ 69150/160000]  base_lr: 6.0088e-05 lr: 6.0088e-06  eta: 10:23:35  time: 0.4153  data_time: 0.0097  memory: 5989  grad_norm: 1167.1976  loss: 24.1772  decode.loss_cls: 0.3338  decode.loss_mask: 1.2167  decode.loss_dice: 0.8512  decode.d0.loss_cls: 0.7860  decode.d0.loss_mask: 1.1105  decode.d0.loss_dice: 0.8578  decode.d1.loss_cls: 0.3604  decode.d1.loss_mask: 1.1622  decode.d1.loss_dice: 0.8392  decode.d2.loss_cls: 0.2719  decode.d2.loss_mask: 1.2264  decode.d2.loss_dice: 0.8732  decode.d3.loss_cls: 0.2997  decode.d3.loss_mask: 1.1805  decode.d3.loss_dice: 0.8630  decode.d4.loss_cls: 0.3059  decode.d4.loss_mask: 1.1757  decode.d4.loss_dice: 0.8444  decode.d5.loss_cls: 0.3248  decode.d5.loss_mask: 1.1845  decode.d5.loss_dice: 0.8451  decode.d6.loss_cls: 0.3077  decode.d6.loss_mask: 1.2037  decode.d6.loss_dice: 0.8710  decode.d7.loss_cls: 0.2782  decode.d7.loss_mask: 1.2577  decode.d7.loss_dice: 0.8889  decode.d8.loss_cls: 0.3502  decode.d8.loss_mask: 1.2334  decode.d8.loss_dice: 0.8736
05/26 19:05:24 - mmengine - INFO - Iter(train) [ 69200/160000]  base_lr: 6.0058e-05 lr: 6.0058e-06  eta: 10:23:14  time: 0.4134  data_time: 0.0096  memory: 5975  grad_norm: 875.8443  loss: 20.3779  decode.loss_cls: 0.1412  decode.loss_mask: 1.1483  decode.loss_dice: 0.7272  decode.d0.loss_cls: 0.5820  decode.d0.loss_mask: 1.0877  decode.d0.loss_dice: 0.7254  decode.d1.loss_cls: 0.1558  decode.d1.loss_mask: 1.1100  decode.d1.loss_dice: 0.6834  decode.d2.loss_cls: 0.1919  decode.d2.loss_mask: 1.0969  decode.d2.loss_dice: 0.7136  decode.d3.loss_cls: 0.1641  decode.d3.loss_mask: 1.1403  decode.d3.loss_dice: 0.7069  decode.d4.loss_cls: 0.1739  decode.d4.loss_mask: 1.1036  decode.d4.loss_dice: 0.7248  decode.d5.loss_cls: 0.1195  decode.d5.loss_mask: 1.1512  decode.d5.loss_dice: 0.7383  decode.d6.loss_cls: 0.1565  decode.d6.loss_mask: 1.1299  decode.d6.loss_dice: 0.7262  decode.d7.loss_cls: 0.1334  decode.d7.loss_mask: 1.1615  decode.d7.loss_dice: 0.7270  decode.d8.loss_cls: 0.1688  decode.d8.loss_mask: 1.0873  decode.d8.loss_dice: 0.7015
05/26 19:05:46 - mmengine - INFO - Iter(train) [ 69250/160000]  base_lr: 6.0028e-05 lr: 6.0028e-06  eta: 10:22:56  time: 0.4133  data_time: 0.0097  memory: 5971  grad_norm: 710.2870  loss: 23.0661  decode.loss_cls: 0.2671  decode.loss_mask: 1.1253  decode.loss_dice: 0.7915  decode.d0.loss_cls: 0.7882  decode.d0.loss_mask: 1.2243  decode.d0.loss_dice: 0.8226  decode.d1.loss_cls: 0.2470  decode.d1.loss_mask: 1.1998  decode.d1.loss_dice: 0.8301  decode.d2.loss_cls: 0.2254  decode.d2.loss_mask: 1.1658  decode.d2.loss_dice: 0.8095  decode.d3.loss_cls: 0.2674  decode.d3.loss_mask: 1.1616  decode.d3.loss_dice: 0.8120  decode.d4.loss_cls: 0.2735  decode.d4.loss_mask: 1.1714  decode.d4.loss_dice: 0.8133  decode.d5.loss_cls: 0.2651  decode.d5.loss_mask: 1.1840  decode.d5.loss_dice: 0.8072  decode.d6.loss_cls: 0.2909  decode.d6.loss_mask: 1.1910  decode.d6.loss_dice: 0.8189  decode.d7.loss_cls: 0.2552  decode.d7.loss_mask: 1.2112  decode.d7.loss_dice: 0.8323  decode.d8.loss_cls: 0.2771  decode.d8.loss_mask: 1.1458  decode.d8.loss_dice: 0.7917
05/26 19:06:06 - mmengine - INFO - Iter(train) [ 69300/160000]  base_lr: 5.9999e-05 lr: 5.9999e-06  eta: 10:22:35  time: 0.4136  data_time: 0.0096  memory: 5980  grad_norm: 609.1583  loss: 19.4816  decode.loss_cls: 0.1685  decode.loss_mask: 0.9445  decode.loss_dice: 0.8037  decode.d0.loss_cls: 0.6732  decode.d0.loss_mask: 0.8589  decode.d0.loss_dice: 0.7392  decode.d1.loss_cls: 0.1816  decode.d1.loss_mask: 0.9549  decode.d1.loss_dice: 0.7745  decode.d2.loss_cls: 0.2413  decode.d2.loss_mask: 0.9104  decode.d2.loss_dice: 0.7499  decode.d3.loss_cls: 0.1962  decode.d3.loss_mask: 0.9349  decode.d3.loss_dice: 0.7621  decode.d4.loss_cls: 0.2302  decode.d4.loss_mask: 0.9138  decode.d4.loss_dice: 0.7986  decode.d5.loss_cls: 0.2111  decode.d5.loss_mask: 0.9207  decode.d5.loss_dice: 0.7448  decode.d6.loss_cls: 0.2045  decode.d6.loss_mask: 0.9275  decode.d6.loss_dice: 0.7940  decode.d7.loss_cls: 0.1884  decode.d7.loss_mask: 0.9274  decode.d7.loss_dice: 0.7815  decode.d8.loss_cls: 0.1789  decode.d8.loss_mask: 0.9600  decode.d8.loss_dice: 0.8064
05/26 19:06:27 - mmengine - INFO - Iter(train) [ 69350/160000]  base_lr: 5.9969e-05 lr: 5.9969e-06  eta: 10:22:15  time: 0.4142  data_time: 0.0098  memory: 5972  grad_norm: 923.6505  loss: 23.3647  decode.loss_cls: 0.2657  decode.loss_mask: 1.2291  decode.loss_dice: 0.8349  decode.d0.loss_cls: 0.7609  decode.d0.loss_mask: 1.1182  decode.d0.loss_dice: 0.7523  decode.d1.loss_cls: 0.2219  decode.d1.loss_mask: 1.2510  decode.d1.loss_dice: 0.8263  decode.d2.loss_cls: 0.2808  decode.d2.loss_mask: 1.2287  decode.d2.loss_dice: 0.7954  decode.d3.loss_cls: 0.2466  decode.d3.loss_mask: 1.2437  decode.d3.loss_dice: 0.8337  decode.d4.loss_cls: 0.2833  decode.d4.loss_mask: 1.2334  decode.d4.loss_dice: 0.8089  decode.d5.loss_cls: 0.2589  decode.d5.loss_mask: 1.1997  decode.d5.loss_dice: 0.7762  decode.d6.loss_cls: 0.2934  decode.d6.loss_mask: 1.1880  decode.d6.loss_dice: 0.7633  decode.d7.loss_cls: 0.2826  decode.d7.loss_mask: 1.2588  decode.d7.loss_dice: 0.8202  decode.d8.loss_cls: 0.2411  decode.d8.loss_mask: 1.2507  decode.d8.loss_dice: 0.8169
05/26 19:06:48 - mmengine - INFO - Iter(train) [ 69400/160000]  base_lr: 5.9939e-05 lr: 5.9939e-06  eta: 10:21:55  time: 0.4156  data_time: 0.0111  memory: 5971  grad_norm: 655.8428  loss: 21.9107  decode.loss_cls: 0.2150  decode.loss_mask: 1.1494  decode.loss_dice: 0.7680  decode.d0.loss_cls: 0.7198  decode.d0.loss_mask: 1.0643  decode.d0.loss_dice: 0.7163  decode.d1.loss_cls: 0.1879  decode.d1.loss_mask: 1.1952  decode.d1.loss_dice: 0.7774  decode.d2.loss_cls: 0.1642  decode.d2.loss_mask: 1.1707  decode.d2.loss_dice: 0.7308  decode.d3.loss_cls: 0.1750  decode.d3.loss_mask: 1.2330  decode.d3.loss_dice: 0.7446  decode.d4.loss_cls: 0.2047  decode.d4.loss_mask: 1.2238  decode.d4.loss_dice: 0.7694  decode.d5.loss_cls: 0.2057  decode.d5.loss_mask: 1.1813  decode.d5.loss_dice: 0.7715  decode.d6.loss_cls: 0.2333  decode.d6.loss_mask: 1.1873  decode.d6.loss_dice: 0.7647  decode.d7.loss_cls: 0.1683  decode.d7.loss_mask: 1.2476  decode.d7.loss_dice: 0.7678  decode.d8.loss_cls: 0.2173  decode.d8.loss_mask: 1.1780  decode.d8.loss_dice: 0.7784
05/26 19:07:09 - mmengine - INFO - Iter(train) [ 69450/160000]  base_lr: 5.9909e-05 lr: 5.9909e-06  eta: 10:21:34  time: 0.4136  data_time: 0.0096  memory: 5983  grad_norm: 404.1450  loss: 17.5392  decode.loss_cls: 0.1913  decode.loss_mask: 0.7879  decode.loss_dice: 0.6681  decode.d0.loss_cls: 0.6307  decode.d0.loss_mask: 0.7859  decode.d0.loss_dice: 0.6933  decode.d1.loss_cls: 0.2277  decode.d1.loss_mask: 0.8050  decode.d1.loss_dice: 0.6987  decode.d2.loss_cls: 0.2461  decode.d2.loss_mask: 0.7968  decode.d2.loss_dice: 0.6889  decode.d3.loss_cls: 0.2257  decode.d3.loss_mask: 0.7950  decode.d3.loss_dice: 0.7026  decode.d4.loss_cls: 0.2593  decode.d4.loss_mask: 0.8013  decode.d4.loss_dice: 0.6673  decode.d5.loss_cls: 0.2424  decode.d5.loss_mask: 0.7965  decode.d5.loss_dice: 0.6944  decode.d6.loss_cls: 0.2160  decode.d6.loss_mask: 0.8339  decode.d6.loss_dice: 0.6876  decode.d7.loss_cls: 0.2681  decode.d7.loss_mask: 0.7780  decode.d7.loss_dice: 0.6580  decode.d8.loss_cls: 0.2136  decode.d8.loss_mask: 0.7943  decode.d8.loss_dice: 0.6848
05/26 19:07:29 - mmengine - INFO - Iter(train) [ 69500/160000]  base_lr: 5.9880e-05 lr: 5.9880e-06  eta: 10:21:14  time: 0.4149  data_time: 0.0097  memory: 5984  grad_norm: 580.8283  loss: 21.4485  decode.loss_cls: 0.2289  decode.loss_mask: 1.1389  decode.loss_dice: 0.7149  decode.d0.loss_cls: 0.6771  decode.d0.loss_mask: 1.1042  decode.d0.loss_dice: 0.6956  decode.d1.loss_cls: 0.2888  decode.d1.loss_mask: 1.1124  decode.d1.loss_dice: 0.7211  decode.d2.loss_cls: 0.2284  decode.d2.loss_mask: 1.0986  decode.d2.loss_dice: 0.7233  decode.d3.loss_cls: 0.2543  decode.d3.loss_mask: 1.1070  decode.d3.loss_dice: 0.7161  decode.d4.loss_cls: 0.2558  decode.d4.loss_mask: 1.1878  decode.d4.loss_dice: 0.7467  decode.d5.loss_cls: 0.2549  decode.d5.loss_mask: 1.1370  decode.d5.loss_dice: 0.7367  decode.d6.loss_cls: 0.2485  decode.d6.loss_mask: 1.1186  decode.d6.loss_dice: 0.7449  decode.d7.loss_cls: 0.2395  decode.d7.loss_mask: 1.1541  decode.d7.loss_dice: 0.7241  decode.d8.loss_cls: 0.2654  decode.d8.loss_mask: 1.1248  decode.d8.loss_dice: 0.6999
05/26 19:07:50 - mmengine - INFO - Iter(train) [ 69550/160000]  base_lr: 5.9850e-05 lr: 5.9850e-06  eta: 10:20:53  time: 0.4151  data_time: 0.0097  memory: 5968  grad_norm: 516.8760  loss: 19.7821  decode.loss_cls: 0.1438  decode.loss_mask: 1.0761  decode.loss_dice: 0.6799  decode.d0.loss_cls: 0.5758  decode.d0.loss_mask: 1.0998  decode.d0.loss_dice: 0.7229  decode.d1.loss_cls: 0.1872  decode.d1.loss_mask: 1.0802  decode.d1.loss_dice: 0.6737  decode.d2.loss_cls: 0.1758  decode.d2.loss_mask: 1.0710  decode.d2.loss_dice: 0.6904  decode.d3.loss_cls: 0.1742  decode.d3.loss_mask: 1.0748  decode.d3.loss_dice: 0.6810  decode.d4.loss_cls: 0.1997  decode.d4.loss_mask: 1.0750  decode.d4.loss_dice: 0.6834  decode.d5.loss_cls: 0.1689  decode.d5.loss_mask: 1.0820  decode.d5.loss_dice: 0.6899  decode.d6.loss_cls: 0.1735  decode.d6.loss_mask: 1.0768  decode.d6.loss_dice: 0.6872  decode.d7.loss_cls: 0.2011  decode.d7.loss_mask: 1.0687  decode.d7.loss_dice: 0.6855  decode.d8.loss_cls: 0.1695  decode.d8.loss_mask: 1.0492  decode.d8.loss_dice: 0.6653
05/26 19:08:11 - mmengine - INFO - Iter(train) [ 69600/160000]  base_lr: 5.9820e-05 lr: 5.9820e-06  eta: 10:20:33  time: 0.4143  data_time: 0.0096  memory: 5975  grad_norm: 580.0433  loss: 19.1810  decode.loss_cls: 0.1518  decode.loss_mask: 1.0343  decode.loss_dice: 0.6497  decode.d0.loss_cls: 0.6034  decode.d0.loss_mask: 1.0703  decode.d0.loss_dice: 0.6225  decode.d1.loss_cls: 0.1930  decode.d1.loss_mask: 1.0480  decode.d1.loss_dice: 0.6467  decode.d2.loss_cls: 0.1890  decode.d2.loss_mask: 1.0747  decode.d2.loss_dice: 0.6636  decode.d3.loss_cls: 0.1653  decode.d3.loss_mask: 1.0607  decode.d3.loss_dice: 0.6427  decode.d4.loss_cls: 0.2066  decode.d4.loss_mask: 1.0529  decode.d4.loss_dice: 0.6391  decode.d5.loss_cls: 0.1846  decode.d5.loss_mask: 1.0514  decode.d5.loss_dice: 0.6542  decode.d6.loss_cls: 0.1581  decode.d6.loss_mask: 1.0456  decode.d6.loss_dice: 0.6513  decode.d7.loss_cls: 0.1617  decode.d7.loss_mask: 1.0457  decode.d7.loss_dice: 0.6397  decode.d8.loss_cls: 0.1704  decode.d8.loss_mask: 1.0432  decode.d8.loss_dice: 0.6611
05/26 19:08:32 - mmengine - INFO - Iter(train) [ 69650/160000]  base_lr: 5.9790e-05 lr: 5.9790e-06  eta: 10:20:12  time: 0.4133  data_time: 0.0097  memory: 5968  grad_norm: 629.3905  loss: 18.7287  decode.loss_cls: 0.2257  decode.loss_mask: 0.9430  decode.loss_dice: 0.6538  decode.d0.loss_cls: 0.6259  decode.d0.loss_mask: 0.9347  decode.d0.loss_dice: 0.6288  decode.d1.loss_cls: 0.2212  decode.d1.loss_mask: 0.9859  decode.d1.loss_dice: 0.6565  decode.d2.loss_cls: 0.2424  decode.d2.loss_mask: 0.9855  decode.d2.loss_dice: 0.6388  decode.d3.loss_cls: 0.2410  decode.d3.loss_mask: 0.9194  decode.d3.loss_dice: 0.6598  decode.d4.loss_cls: 0.2704  decode.d4.loss_mask: 0.9947  decode.d4.loss_dice: 0.6641  decode.d5.loss_cls: 0.2054  decode.d5.loss_mask: 0.9462  decode.d5.loss_dice: 0.6237  decode.d6.loss_cls: 0.2349  decode.d6.loss_mask: 0.9610  decode.d6.loss_dice: 0.6675  decode.d7.loss_cls: 0.2431  decode.d7.loss_mask: 0.9228  decode.d7.loss_dice: 0.6206  decode.d8.loss_cls: 0.2733  decode.d8.loss_mask: 0.9081  decode.d8.loss_dice: 0.6306
05/26 19:08:52 - mmengine - INFO - Iter(train) [ 69700/160000]  base_lr: 5.9760e-05 lr: 5.9760e-06  eta: 10:19:52  time: 0.4147  data_time: 0.0097  memory: 5982  grad_norm: 1018.7735  loss: 25.6409  decode.loss_cls: 0.4160  decode.loss_mask: 1.2314  decode.loss_dice: 0.8912  decode.d0.loss_cls: 0.8451  decode.d0.loss_mask: 1.1700  decode.d0.loss_dice: 0.8871  decode.d1.loss_cls: 0.4140  decode.d1.loss_mask: 1.1582  decode.d1.loss_dice: 0.8950  decode.d2.loss_cls: 0.3116  decode.d2.loss_mask: 1.3152  decode.d2.loss_dice: 0.9130  decode.d3.loss_cls: 0.3699  decode.d3.loss_mask: 1.2807  decode.d3.loss_dice: 0.8882  decode.d4.loss_cls: 0.3334  decode.d4.loss_mask: 1.3033  decode.d4.loss_dice: 0.8834  decode.d5.loss_cls: 0.3659  decode.d5.loss_mask: 1.2098  decode.d5.loss_dice: 0.8699  decode.d6.loss_cls: 0.3695  decode.d6.loss_mask: 1.2755  decode.d6.loss_dice: 0.9257  decode.d7.loss_cls: 0.3638  decode.d7.loss_mask: 1.3202  decode.d7.loss_dice: 0.9099  decode.d8.loss_cls: 0.3695  decode.d8.loss_mask: 1.2467  decode.d8.loss_dice: 0.9076
05/26 19:09:13 - mmengine - INFO - Iter(train) [ 69750/160000]  base_lr: 5.9731e-05 lr: 5.9731e-06  eta: 10:19:32  time: 0.4144  data_time: 0.0097  memory: 5966  grad_norm: 311.0674  loss: 19.8391  decode.loss_cls: 0.2125  decode.loss_mask: 0.9511  decode.loss_dice: 0.8036  decode.d0.loss_cls: 0.5179  decode.d0.loss_mask: 0.9687  decode.d0.loss_dice: 0.8150  decode.d1.loss_cls: 0.1813  decode.d1.loss_mask: 0.9355  decode.d1.loss_dice: 0.7997  decode.d2.loss_cls: 0.1835  decode.d2.loss_mask: 0.9696  decode.d2.loss_dice: 0.8042  decode.d3.loss_cls: 0.1654  decode.d3.loss_mask: 0.9600  decode.d3.loss_dice: 0.8133  decode.d4.loss_cls: 0.1869  decode.d4.loss_mask: 0.9566  decode.d4.loss_dice: 0.8000  decode.d5.loss_cls: 0.1885  decode.d5.loss_mask: 0.9667  decode.d5.loss_dice: 0.7916  decode.d6.loss_cls: 0.1986  decode.d6.loss_mask: 0.9614  decode.d6.loss_dice: 0.7906  decode.d7.loss_cls: 0.1932  decode.d7.loss_mask: 0.9532  decode.d7.loss_dice: 0.8089  decode.d8.loss_cls: 0.1888  decode.d8.loss_mask: 0.9348  decode.d8.loss_dice: 0.8378
05/26 19:09:34 - mmengine - INFO - Iter(train) [ 69800/160000]  base_lr: 5.9701e-05 lr: 5.9701e-06  eta: 10:19:11  time: 0.4139  data_time: 0.0098  memory: 5974  grad_norm: 841.4783  loss: 20.0886  decode.loss_cls: 0.2050  decode.loss_mask: 1.0559  decode.loss_dice: 0.7275  decode.d0.loss_cls: 0.6680  decode.d0.loss_mask: 1.0003  decode.d0.loss_dice: 0.7309  decode.d1.loss_cls: 0.2571  decode.d1.loss_mask: 1.0230  decode.d1.loss_dice: 0.7252  decode.d2.loss_cls: 0.2053  decode.d2.loss_mask: 1.0248  decode.d2.loss_dice: 0.7230  decode.d3.loss_cls: 0.1809  decode.d3.loss_mask: 1.0399  decode.d3.loss_dice: 0.7422  decode.d4.loss_cls: 0.2322  decode.d4.loss_mask: 1.0123  decode.d4.loss_dice: 0.6906  decode.d5.loss_cls: 0.1775  decode.d5.loss_mask: 1.0283  decode.d5.loss_dice: 0.7407  decode.d6.loss_cls: 0.1980  decode.d6.loss_mask: 1.0736  decode.d6.loss_dice: 0.7318  decode.d7.loss_cls: 0.2293  decode.d7.loss_mask: 1.0114  decode.d7.loss_dice: 0.6838  decode.d8.loss_cls: 0.1717  decode.d8.loss_mask: 1.0609  decode.d8.loss_dice: 0.7376
05/26 19:09:55 - mmengine - INFO - Iter(train) [ 69850/160000]  base_lr: 5.9671e-05 lr: 5.9671e-06  eta: 10:18:51  time: 0.4137  data_time: 0.0097  memory: 5967  grad_norm: 471.5711  loss: 23.9937  decode.loss_cls: 0.2944  decode.loss_mask: 1.1931  decode.loss_dice: 0.8835  decode.d0.loss_cls: 0.7252  decode.d0.loss_mask: 1.1442  decode.d0.loss_dice: 0.9073  decode.d1.loss_cls: 0.2520  decode.d1.loss_mask: 1.1689  decode.d1.loss_dice: 0.9350  decode.d2.loss_cls: 0.3043  decode.d2.loss_mask: 1.1727  decode.d2.loss_dice: 0.8981  decode.d3.loss_cls: 0.2999  decode.d3.loss_mask: 1.1229  decode.d3.loss_dice: 0.8797  decode.d4.loss_cls: 0.2360  decode.d4.loss_mask: 1.1400  decode.d4.loss_dice: 0.9329  decode.d5.loss_cls: 0.2814  decode.d5.loss_mask: 1.1587  decode.d5.loss_dice: 0.9302  decode.d6.loss_cls: 0.2672  decode.d6.loss_mask: 1.1664  decode.d6.loss_dice: 0.9274  decode.d7.loss_cls: 0.2963  decode.d7.loss_mask: 1.1965  decode.d7.loss_dice: 0.9119  decode.d8.loss_cls: 0.2895  decode.d8.loss_mask: 1.1621  decode.d8.loss_dice: 0.9160
05/26 19:10:15 - mmengine - INFO - Iter(train) [ 69900/160000]  base_lr: 5.9641e-05 lr: 5.9641e-06  eta: 10:18:30  time: 0.4130  data_time: 0.0097  memory: 5969  grad_norm: 918.1847  loss: 23.5120  decode.loss_cls: 0.3398  decode.loss_mask: 1.0640  decode.loss_dice: 0.8809  decode.d0.loss_cls: 0.7366  decode.d0.loss_mask: 1.0410  decode.d0.loss_dice: 0.9061  decode.d1.loss_cls: 0.3788  decode.d1.loss_mask: 1.0573  decode.d1.loss_dice: 0.8941  decode.d2.loss_cls: 0.3390  decode.d2.loss_mask: 1.0906  decode.d2.loss_dice: 0.9099  decode.d3.loss_cls: 0.3690  decode.d3.loss_mask: 1.0858  decode.d3.loss_dice: 0.9031  decode.d4.loss_cls: 0.2906  decode.d4.loss_mask: 1.0994  decode.d4.loss_dice: 0.8956  decode.d5.loss_cls: 0.3105  decode.d5.loss_mask: 1.1051  decode.d5.loss_dice: 0.9557  decode.d6.loss_cls: 0.2893  decode.d6.loss_mask: 1.0957  decode.d6.loss_dice: 0.8926  decode.d7.loss_cls: 0.3017  decode.d7.loss_mask: 1.0934  decode.d7.loss_dice: 0.8940  decode.d8.loss_cls: 0.2785  decode.d8.loss_mask: 1.1122  decode.d8.loss_dice: 0.9020
05/26 19:10:36 - mmengine - INFO - Iter(train) [ 69950/160000]  base_lr: 5.9611e-05 lr: 5.9611e-06  eta: 10:18:10  time: 0.4139  data_time: 0.0096  memory: 5971  grad_norm: 1052.3324  loss: 29.0661  decode.loss_cls: 0.3880  decode.loss_mask: 1.4932  decode.loss_dice: 1.0201  decode.d0.loss_cls: 0.9491  decode.d0.loss_mask: 1.3512  decode.d0.loss_dice: 0.9638  decode.d1.loss_cls: 0.4103  decode.d1.loss_mask: 1.4145  decode.d1.loss_dice: 0.9820  decode.d2.loss_cls: 0.3800  decode.d2.loss_mask: 1.4674  decode.d2.loss_dice: 0.9857  decode.d3.loss_cls: 0.3727  decode.d3.loss_mask: 1.4835  decode.d3.loss_dice: 1.0183  decode.d4.loss_cls: 0.4637  decode.d4.loss_mask: 1.3810  decode.d4.loss_dice: 0.9971  decode.d5.loss_cls: 0.3648  decode.d5.loss_mask: 1.4605  decode.d5.loss_dice: 1.0072  decode.d6.loss_cls: 0.4182  decode.d6.loss_mask: 1.4141  decode.d6.loss_dice: 0.9778  decode.d7.loss_cls: 0.4179  decode.d7.loss_mask: 1.5256  decode.d7.loss_dice: 1.0399  decode.d8.loss_cls: 0.4152  decode.d8.loss_mask: 1.4800  decode.d8.loss_dice: 1.0232
05/26 19:10:57 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 19:10:57 - mmengine - INFO - Iter(train) [ 70000/160000]  base_lr: 5.9582e-05 lr: 5.9582e-06  eta: 10:17:50  time: 0.4143  data_time: 0.0098  memory: 5974  grad_norm: 509.7811  loss: 21.1100  decode.loss_cls: 0.2110  decode.loss_mask: 1.0591  decode.loss_dice: 0.7487  decode.d0.loss_cls: 0.6986  decode.d0.loss_mask: 1.0227  decode.d0.loss_dice: 0.7420  decode.d1.loss_cls: 0.2282  decode.d1.loss_mask: 1.0841  decode.d1.loss_dice: 0.7545  decode.d2.loss_cls: 0.2189  decode.d2.loss_mask: 1.0894  decode.d2.loss_dice: 0.7485  decode.d3.loss_cls: 0.2217  decode.d3.loss_mask: 1.0778  decode.d3.loss_dice: 0.8027  decode.d4.loss_cls: 0.2302  decode.d4.loss_mask: 1.0392  decode.d4.loss_dice: 0.7797  decode.d5.loss_cls: 0.2461  decode.d5.loss_mask: 1.0802  decode.d5.loss_dice: 0.7713  decode.d6.loss_cls: 0.2626  decode.d6.loss_mask: 1.0793  decode.d6.loss_dice: 0.7947  decode.d7.loss_cls: 0.2279  decode.d7.loss_mask: 1.0694  decode.d7.loss_dice: 0.7489  decode.d8.loss_cls: 0.2693  decode.d8.loss_mask: 1.0540  decode.d8.loss_dice: 0.7491
05/26 19:10:57 - mmengine - INFO - Saving checkpoint at 70000 iterations
05/26 19:11:02 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:10  time: 0.0494  data_time: 0.0013  memory: 1391  
05/26 19:11:04 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:06  time: 0.0486  data_time: 0.0013  memory: 1205  
05/26 19:11:07 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:05  time: 0.0511  data_time: 0.0013  memory: 1596  
05/26 19:11:09 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:02  time: 0.0496  data_time: 0.0013  memory: 1298  
05/26 19:11:12 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:59  time: 0.0484  data_time: 0.0013  memory: 1298  
05/26 19:11:14 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:57  time: 0.0489  data_time: 0.0013  memory: 1279  
05/26 19:11:16 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:54  time: 0.0484  data_time: 0.0013  memory: 1224  
05/26 19:11:19 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:52  time: 0.0500  data_time: 0.0013  memory: 1298  
05/26 19:11:21 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:49  time: 0.0501  data_time: 0.0013  memory: 1298  
05/26 19:11:24 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:47  time: 0.0527  data_time: 0.0013  memory: 1725  
05/26 19:11:26 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:44  time: 0.0485  data_time: 0.0013  memory: 1336  
05/26 19:11:29 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:42  time: 0.0493  data_time: 0.0013  memory: 1298  
05/26 19:11:31 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:39  time: 0.0493  data_time: 0.0013  memory: 1205  
05/26 19:11:34 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:37  time: 0.0502  data_time: 0.0013  memory: 1316  
05/26 19:11:36 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:34  time: 0.0487  data_time: 0.0013  memory: 1279  
05/26 19:11:39 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:32  time: 0.0522  data_time: 0.0013  memory: 1410  
05/26 19:11:41 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:29  time: 0.0488  data_time: 0.0013  memory: 1279  
05/26 19:11:44 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:27  time: 0.0493  data_time: 0.0013  memory: 1205  
05/26 19:11:46 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0490  data_time: 0.0012  memory: 1205  
05/26 19:11:49 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:22  time: 0.0493  data_time: 0.0013  memory: 1336  
05/26 19:11:51 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0484  data_time: 0.0013  memory: 1246  
05/26 19:11:54 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0508  data_time: 0.0013  memory: 1503  
05/26 19:11:56 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0486  data_time: 0.0013  memory: 1261  
05/26 19:11:58 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0493  data_time: 0.0013  memory: 1298  
05/26 19:12:01 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0489  data_time: 0.0013  memory: 1447  
05/26 19:12:03 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0481  data_time: 0.0013  memory: 1298  
05/26 19:12:06 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0499  data_time: 0.0013  memory: 1279  
05/26 19:12:08 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0501  data_time: 0.0013  memory: 1205  
05/26 19:12:11 - mmengine - INFO - per class results:
05/26 19:12:11 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.07 | 96.83 |
|  aeroplane  | 91.52 | 95.97 |
|   bicycle   | 43.53 | 96.64 |
|     bird    | 92.63 |  98.5 |
|     boat    | 65.57 | 90.47 |
|    bottle   | 80.96 | 95.91 |
|     bus     | 92.72 | 95.01 |
|     car     | 88.25 |  96.3 |
|     cat     | 93.56 | 96.14 |
|    chair    | 39.18 | 66.39 |
|     cow     | 77.61 | 85.72 |
| diningtable | 66.87 | 74.06 |
|     dog     |  83.5 | 98.97 |
|    horse    | 84.53 | 90.59 |
|  motorbike  | 91.67 |  97.5 |
|    person   | 90.73 | 94.25 |
| pottedplant | 68.31 | 85.78 |
|    sheep    | 77.63 | 92.24 |
|     sofa    | 50.28 | 61.95 |
|    train    | 84.79 | 90.69 |
|  tvmonitor  | 82.99 | 89.48 |
+-------------+-------+-------+
05/26 19:12:11 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.1900  mIoU: 78.1900  mAcc: 89.9700  data_time: 0.0013  time: 0.0493
05/26 19:12:32 - mmengine - INFO - Iter(train) [ 70050/160000]  base_lr: 5.9552e-05 lr: 5.9552e-06  eta: 10:17:30  time: 0.4159  data_time: 0.0101  memory: 5990  grad_norm: 1109.2296  loss: 24.4768  decode.loss_cls: 0.2133  decode.loss_mask: 1.2889  decode.loss_dice: 0.8850  decode.d0.loss_cls: 0.6734  decode.d0.loss_mask: 1.2413  decode.d0.loss_dice: 0.9167  decode.d1.loss_cls: 0.2197  decode.d1.loss_mask: 1.2941  decode.d1.loss_dice: 0.9305  decode.d2.loss_cls: 0.2487  decode.d2.loss_mask: 1.2882  decode.d2.loss_dice: 0.8918  decode.d3.loss_cls: 0.2103  decode.d3.loss_mask: 1.2753  decode.d3.loss_dice: 0.9104  decode.d4.loss_cls: 0.2329  decode.d4.loss_mask: 1.2712  decode.d4.loss_dice: 0.8964  decode.d5.loss_cls: 0.2177  decode.d5.loss_mask: 1.2817  decode.d5.loss_dice: 0.9093  decode.d6.loss_cls: 0.2206  decode.d6.loss_mask: 1.2678  decode.d6.loss_dice: 0.9150  decode.d7.loss_cls: 0.2311  decode.d7.loss_mask: 1.2570  decode.d7.loss_dice: 0.9006  decode.d8.loss_cls: 0.2044  decode.d8.loss_mask: 1.2959  decode.d8.loss_dice: 0.8876
05/26 19:12:52 - mmengine - INFO - Iter(train) [ 70100/160000]  base_lr: 5.9522e-05 lr: 5.9522e-06  eta: 10:17:10  time: 0.4141  data_time: 0.0097  memory: 5986  grad_norm: 483.1075  loss: 20.8815  decode.loss_cls: 0.2388  decode.loss_mask: 1.0397  decode.loss_dice: 0.7285  decode.d0.loss_cls: 0.7695  decode.d0.loss_mask: 1.0142  decode.d0.loss_dice: 0.7379  decode.d1.loss_cls: 0.2591  decode.d1.loss_mask: 1.0232  decode.d1.loss_dice: 0.7475  decode.d2.loss_cls: 0.2410  decode.d2.loss_mask: 1.0614  decode.d2.loss_dice: 0.7680  decode.d3.loss_cls: 0.2481  decode.d3.loss_mask: 1.0509  decode.d3.loss_dice: 0.7405  decode.d4.loss_cls: 0.3230  decode.d4.loss_mask: 0.9810  decode.d4.loss_dice: 0.7303  decode.d5.loss_cls: 0.2963  decode.d5.loss_mask: 1.0083  decode.d5.loss_dice: 0.7437  decode.d6.loss_cls: 0.3367  decode.d6.loss_mask: 1.0006  decode.d6.loss_dice: 0.7475  decode.d7.loss_cls: 0.2273  decode.d7.loss_mask: 1.0168  decode.d7.loss_dice: 0.7510  decode.d8.loss_cls: 0.2557  decode.d8.loss_mask: 1.0196  decode.d8.loss_dice: 0.7753
05/26 19:13:13 - mmengine - INFO - Iter(train) [ 70150/160000]  base_lr: 5.9492e-05 lr: 5.9492e-06  eta: 10:16:49  time: 0.4130  data_time: 0.0096  memory: 5970  grad_norm: 372.0160  loss: 17.3630  decode.loss_cls: 0.1198  decode.loss_mask: 0.9781  decode.loss_dice: 0.5893  decode.d0.loss_cls: 0.5111  decode.d0.loss_mask: 0.9817  decode.d0.loss_dice: 0.6091  decode.d1.loss_cls: 0.1054  decode.d1.loss_mask: 1.0198  decode.d1.loss_dice: 0.6266  decode.d2.loss_cls: 0.0919  decode.d2.loss_mask: 1.0114  decode.d2.loss_dice: 0.6021  decode.d3.loss_cls: 0.0789  decode.d3.loss_mask: 0.9881  decode.d3.loss_dice: 0.6029  decode.d4.loss_cls: 0.1058  decode.d4.loss_mask: 1.0139  decode.d4.loss_dice: 0.5841  decode.d5.loss_cls: 0.0909  decode.d5.loss_mask: 1.0010  decode.d5.loss_dice: 0.5922  decode.d6.loss_cls: 0.1196  decode.d6.loss_mask: 0.9752  decode.d6.loss_dice: 0.5946  decode.d7.loss_cls: 0.0880  decode.d7.loss_mask: 1.0058  decode.d7.loss_dice: 0.6045  decode.d8.loss_cls: 0.0957  decode.d8.loss_mask: 0.9858  decode.d8.loss_dice: 0.5900
05/26 19:13:34 - mmengine - INFO - Iter(train) [ 70200/160000]  base_lr: 5.9462e-05 lr: 5.9462e-06  eta: 10:16:29  time: 0.4127  data_time: 0.0098  memory: 5966  grad_norm: 1040.7695  loss: 21.1824  decode.loss_cls: 0.1733  decode.loss_mask: 1.1509  decode.loss_dice: 0.7622  decode.d0.loss_cls: 0.6824  decode.d0.loss_mask: 1.0475  decode.d0.loss_dice: 0.7523  decode.d1.loss_cls: 0.2474  decode.d1.loss_mask: 1.0728  decode.d1.loss_dice: 0.7539  decode.d2.loss_cls: 0.2241  decode.d2.loss_mask: 1.0807  decode.d2.loss_dice: 0.7614  decode.d3.loss_cls: 0.2090  decode.d3.loss_mask: 1.1137  decode.d3.loss_dice: 0.7630  decode.d4.loss_cls: 0.2302  decode.d4.loss_mask: 1.1022  decode.d4.loss_dice: 0.7532  decode.d5.loss_cls: 0.2330  decode.d5.loss_mask: 1.0860  decode.d5.loss_dice: 0.7585  decode.d6.loss_cls: 0.2229  decode.d6.loss_mask: 1.0816  decode.d6.loss_dice: 0.7591  decode.d7.loss_cls: 0.2046  decode.d7.loss_mask: 1.1107  decode.d7.loss_dice: 0.7672  decode.d8.loss_cls: 0.1852  decode.d8.loss_mask: 1.1068  decode.d8.loss_dice: 0.7862
05/26 19:13:55 - mmengine - INFO - Iter(train) [ 70250/160000]  base_lr: 5.9433e-05 lr: 5.9433e-06  eta: 10:16:08  time: 0.4141  data_time: 0.0097  memory: 5980  grad_norm: 371.4589  loss: 20.4871  decode.loss_cls: 0.1745  decode.loss_mask: 1.1210  decode.loss_dice: 0.7409  decode.d0.loss_cls: 0.6244  decode.d0.loss_mask: 1.0529  decode.d0.loss_dice: 0.7139  decode.d1.loss_cls: 0.2003  decode.d1.loss_mask: 1.0532  decode.d1.loss_dice: 0.7228  decode.d2.loss_cls: 0.2686  decode.d2.loss_mask: 1.0456  decode.d2.loss_dice: 0.7514  decode.d3.loss_cls: 0.2282  decode.d3.loss_mask: 1.0438  decode.d3.loss_dice: 0.7130  decode.d4.loss_cls: 0.2102  decode.d4.loss_mask: 1.0991  decode.d4.loss_dice: 0.7129  decode.d5.loss_cls: 0.2383  decode.d5.loss_mask: 1.0121  decode.d5.loss_dice: 0.7235  decode.d6.loss_cls: 0.2276  decode.d6.loss_mask: 1.0643  decode.d6.loss_dice: 0.7439  decode.d7.loss_cls: 0.2099  decode.d7.loss_mask: 1.0777  decode.d7.loss_dice: 0.7269  decode.d8.loss_cls: 0.1906  decode.d8.loss_mask: 1.0684  decode.d8.loss_dice: 0.7274
05/26 19:14:15 - mmengine - INFO - Iter(train) [ 70300/160000]  base_lr: 5.9403e-05 lr: 5.9403e-06  eta: 10:15:48  time: 0.4127  data_time: 0.0096  memory: 5972  grad_norm: 396.0590  loss: 17.3992  decode.loss_cls: 0.1262  decode.loss_mask: 0.8441  decode.loss_dice: 0.7016  decode.d0.loss_cls: 0.6240  decode.d0.loss_mask: 0.8527  decode.d0.loss_dice: 0.6918  decode.d1.loss_cls: 0.1124  decode.d1.loss_mask: 0.8653  decode.d1.loss_dice: 0.7041  decode.d2.loss_cls: 0.0997  decode.d2.loss_mask: 0.8794  decode.d2.loss_dice: 0.7119  decode.d3.loss_cls: 0.1226  decode.d3.loss_mask: 0.8644  decode.d3.loss_dice: 0.7174  decode.d4.loss_cls: 0.1207  decode.d4.loss_mask: 0.8749  decode.d4.loss_dice: 0.7091  decode.d5.loss_cls: 0.1459  decode.d5.loss_mask: 0.8564  decode.d5.loss_dice: 0.7006  decode.d6.loss_cls: 0.1698  decode.d6.loss_mask: 0.8263  decode.d6.loss_dice: 0.7036  decode.d7.loss_cls: 0.1165  decode.d7.loss_mask: 0.8724  decode.d7.loss_dice: 0.6835  decode.d8.loss_cls: 0.1403  decode.d8.loss_mask: 0.8512  decode.d8.loss_dice: 0.7105
05/26 19:14:36 - mmengine - INFO - Iter(train) [ 70350/160000]  base_lr: 5.9373e-05 lr: 5.9373e-06  eta: 10:15:27  time: 0.4146  data_time: 0.0096  memory: 5966  grad_norm: 761.9444  loss: 25.3421  decode.loss_cls: 0.2472  decode.loss_mask: 1.2142  decode.loss_dice: 1.0114  decode.d0.loss_cls: 0.8449  decode.d0.loss_mask: 1.1137  decode.d0.loss_dice: 0.9498  decode.d1.loss_cls: 0.3282  decode.d1.loss_mask: 1.2194  decode.d1.loss_dice: 1.0262  decode.d2.loss_cls: 0.2809  decode.d2.loss_mask: 1.1949  decode.d2.loss_dice: 0.9989  decode.d3.loss_cls: 0.3228  decode.d3.loss_mask: 1.1928  decode.d3.loss_dice: 0.9968  decode.d4.loss_cls: 0.2817  decode.d4.loss_mask: 1.2514  decode.d4.loss_dice: 1.0195  decode.d5.loss_cls: 0.2945  decode.d5.loss_mask: 1.1833  decode.d5.loss_dice: 0.9939  decode.d6.loss_cls: 0.2639  decode.d6.loss_mask: 1.1772  decode.d6.loss_dice: 0.9988  decode.d7.loss_cls: 0.2971  decode.d7.loss_mask: 1.1841  decode.d7.loss_dice: 0.9864  decode.d8.loss_cls: 0.2593  decode.d8.loss_mask: 1.1899  decode.d8.loss_dice: 1.0188
05/26 19:14:57 - mmengine - INFO - Iter(train) [ 70400/160000]  base_lr: 5.9343e-05 lr: 5.9343e-06  eta: 10:15:07  time: 0.4143  data_time: 0.0096  memory: 5971  grad_norm: 338.3197  loss: 20.4841  decode.loss_cls: 0.2221  decode.loss_mask: 1.0251  decode.loss_dice: 0.7889  decode.d0.loss_cls: 0.6715  decode.d0.loss_mask: 0.9503  decode.d0.loss_dice: 0.7640  decode.d1.loss_cls: 0.2443  decode.d1.loss_mask: 0.9900  decode.d1.loss_dice: 0.7807  decode.d2.loss_cls: 0.2281  decode.d2.loss_mask: 0.9932  decode.d2.loss_dice: 0.7881  decode.d3.loss_cls: 0.1978  decode.d3.loss_mask: 0.9794  decode.d3.loss_dice: 0.7617  decode.d4.loss_cls: 0.2504  decode.d4.loss_mask: 0.9742  decode.d4.loss_dice: 0.7486  decode.d5.loss_cls: 0.2504  decode.d5.loss_mask: 0.9901  decode.d5.loss_dice: 0.7691  decode.d6.loss_cls: 0.2357  decode.d6.loss_mask: 1.0114  decode.d6.loss_dice: 0.7627  decode.d7.loss_cls: 0.2793  decode.d7.loss_mask: 1.0001  decode.d7.loss_dice: 0.7742  decode.d8.loss_cls: 0.2569  decode.d8.loss_mask: 1.0158  decode.d8.loss_dice: 0.7800
05/26 19:15:18 - mmengine - INFO - Iter(train) [ 70450/160000]  base_lr: 5.9313e-05 lr: 5.9313e-06  eta: 10:14:46  time: 0.4146  data_time: 0.0098  memory: 5987  grad_norm: 366.4945  loss: 18.2781  decode.loss_cls: 0.1696  decode.loss_mask: 0.8837  decode.loss_dice: 0.7194  decode.d0.loss_cls: 0.6384  decode.d0.loss_mask: 0.9019  decode.d0.loss_dice: 0.7270  decode.d1.loss_cls: 0.2367  decode.d1.loss_mask: 0.8655  decode.d1.loss_dice: 0.6941  decode.d2.loss_cls: 0.1888  decode.d2.loss_mask: 0.8817  decode.d2.loss_dice: 0.7117  decode.d3.loss_cls: 0.1834  decode.d3.loss_mask: 0.8797  decode.d3.loss_dice: 0.6889  decode.d4.loss_cls: 0.2387  decode.d4.loss_mask: 0.8669  decode.d4.loss_dice: 0.6951  decode.d5.loss_cls: 0.1848  decode.d5.loss_mask: 0.8687  decode.d5.loss_dice: 0.6851  decode.d6.loss_cls: 0.1825  decode.d6.loss_mask: 0.8695  decode.d6.loss_dice: 0.7042  decode.d7.loss_cls: 0.1896  decode.d7.loss_mask: 0.8789  decode.d7.loss_dice: 0.7180  decode.d8.loss_cls: 0.2299  decode.d8.loss_mask: 0.8793  decode.d8.loss_dice: 0.7163
05/26 19:15:38 - mmengine - INFO - Iter(train) [ 70500/160000]  base_lr: 5.9284e-05 lr: 5.9284e-06  eta: 10:14:26  time: 0.4148  data_time: 0.0097  memory: 5983  grad_norm: 550.0583  loss: 22.2323  decode.loss_cls: 0.2004  decode.loss_mask: 1.1894  decode.loss_dice: 0.7687  decode.d0.loss_cls: 0.6929  decode.d0.loss_mask: 1.0889  decode.d0.loss_dice: 0.7506  decode.d1.loss_cls: 0.2311  decode.d1.loss_mask: 1.1956  decode.d1.loss_dice: 0.7495  decode.d2.loss_cls: 0.2065  decode.d2.loss_mask: 1.2507  decode.d2.loss_dice: 0.7587  decode.d3.loss_cls: 0.2000  decode.d3.loss_mask: 1.2533  decode.d3.loss_dice: 0.7776  decode.d4.loss_cls: 0.1768  decode.d4.loss_mask: 1.2676  decode.d4.loss_dice: 0.7792  decode.d5.loss_cls: 0.2221  decode.d5.loss_mask: 1.1808  decode.d5.loss_dice: 0.7444  decode.d6.loss_cls: 0.2203  decode.d6.loss_mask: 1.1978  decode.d6.loss_dice: 0.7758  decode.d7.loss_cls: 0.2609  decode.d7.loss_mask: 1.1523  decode.d7.loss_dice: 0.7563  decode.d8.loss_cls: 0.2436  decode.d8.loss_mask: 1.1880  decode.d8.loss_dice: 0.7527
05/26 19:15:59 - mmengine - INFO - Iter(train) [ 70550/160000]  base_lr: 5.9254e-05 lr: 5.9254e-06  eta: 10:14:06  time: 0.4144  data_time: 0.0097  memory: 5967  grad_norm: 557.0574  loss: 23.6551  decode.loss_cls: 0.1989  decode.loss_mask: 1.3027  decode.loss_dice: 0.8289  decode.d0.loss_cls: 0.7904  decode.d0.loss_mask: 1.2149  decode.d0.loss_dice: 0.7720  decode.d1.loss_cls: 0.2037  decode.d1.loss_mask: 1.3184  decode.d1.loss_dice: 0.8147  decode.d2.loss_cls: 0.2196  decode.d2.loss_mask: 1.3277  decode.d2.loss_dice: 0.7927  decode.d3.loss_cls: 0.1927  decode.d3.loss_mask: 1.2918  decode.d3.loss_dice: 0.7618  decode.d4.loss_cls: 0.2246  decode.d4.loss_mask: 1.2931  decode.d4.loss_dice: 0.7872  decode.d5.loss_cls: 0.2436  decode.d5.loss_mask: 1.3026  decode.d5.loss_dice: 0.7918  decode.d6.loss_cls: 0.2024  decode.d6.loss_mask: 1.3023  decode.d6.loss_dice: 0.7699  decode.d7.loss_cls: 0.2122  decode.d7.loss_mask: 1.3370  decode.d7.loss_dice: 0.8375  decode.d8.loss_cls: 0.1940  decode.d8.loss_mask: 1.2998  decode.d8.loss_dice: 0.8262
05/26 19:16:20 - mmengine - INFO - Iter(train) [ 70600/160000]  base_lr: 5.9224e-05 lr: 5.9224e-06  eta: 10:13:45  time: 0.4158  data_time: 0.0097  memory: 5968  grad_norm: 845.2079  loss: 22.6362  decode.loss_cls: 0.2366  decode.loss_mask: 1.1625  decode.loss_dice: 0.8205  decode.d0.loss_cls: 0.7670  decode.d0.loss_mask: 1.0813  decode.d0.loss_dice: 0.7704  decode.d1.loss_cls: 0.1962  decode.d1.loss_mask: 1.1828  decode.d1.loss_dice: 0.8264  decode.d2.loss_cls: 0.2007  decode.d2.loss_mask: 1.1806  decode.d2.loss_dice: 0.8397  decode.d3.loss_cls: 0.2410  decode.d3.loss_mask: 1.1748  decode.d3.loss_dice: 0.8219  decode.d4.loss_cls: 0.2837  decode.d4.loss_mask: 1.1321  decode.d4.loss_dice: 0.8238  decode.d5.loss_cls: 0.2637  decode.d5.loss_mask: 1.1385  decode.d5.loss_dice: 0.8267  decode.d6.loss_cls: 0.2323  decode.d6.loss_mask: 1.1458  decode.d6.loss_dice: 0.8178  decode.d7.loss_cls: 0.1910  decode.d7.loss_mask: 1.1854  decode.d7.loss_dice: 0.8451  decode.d8.loss_cls: 0.2113  decode.d8.loss_mask: 1.1728  decode.d8.loss_dice: 0.8637
05/26 19:16:41 - mmengine - INFO - Iter(train) [ 70650/160000]  base_lr: 5.9194e-05 lr: 5.9194e-06  eta: 10:13:25  time: 0.4170  data_time: 0.0097  memory: 5970  grad_norm: 543.1371  loss: 23.0617  decode.loss_cls: 0.1740  decode.loss_mask: 1.2004  decode.loss_dice: 0.8608  decode.d0.loss_cls: 0.7919  decode.d0.loss_mask: 1.1541  decode.d0.loss_dice: 0.8228  decode.d1.loss_cls: 0.2080  decode.d1.loss_mask: 1.2266  decode.d1.loss_dice: 0.8529  decode.d2.loss_cls: 0.2085  decode.d2.loss_mask: 1.1789  decode.d2.loss_dice: 0.8352  decode.d3.loss_cls: 0.2087  decode.d3.loss_mask: 1.2304  decode.d3.loss_dice: 0.8712  decode.d4.loss_cls: 0.1940  decode.d4.loss_mask: 1.2067  decode.d4.loss_dice: 0.8584  decode.d5.loss_cls: 0.1956  decode.d5.loss_mask: 1.2287  decode.d5.loss_dice: 0.8507  decode.d6.loss_cls: 0.1940  decode.d6.loss_mask: 1.2022  decode.d6.loss_dice: 0.8654  decode.d7.loss_cls: 0.2203  decode.d7.loss_mask: 1.1670  decode.d7.loss_dice: 0.8258  decode.d8.loss_cls: 0.1943  decode.d8.loss_mask: 1.1776  decode.d8.loss_dice: 0.8564
05/26 19:17:01 - mmengine - INFO - Iter(train) [ 70700/160000]  base_lr: 5.9164e-05 lr: 5.9164e-06  eta: 10:13:04  time: 0.4149  data_time: 0.0097  memory: 5989  grad_norm: 472.7730  loss: 21.5197  decode.loss_cls: 0.3393  decode.loss_mask: 1.0149  decode.loss_dice: 0.7743  decode.d0.loss_cls: 0.7606  decode.d0.loss_mask: 0.9723  decode.d0.loss_dice: 0.7662  decode.d1.loss_cls: 0.3707  decode.d1.loss_mask: 1.0148  decode.d1.loss_dice: 0.7435  decode.d2.loss_cls: 0.3497  decode.d2.loss_mask: 1.0250  decode.d2.loss_dice: 0.7455  decode.d3.loss_cls: 0.3343  decode.d3.loss_mask: 1.0251  decode.d3.loss_dice: 0.7257  decode.d4.loss_cls: 0.3715  decode.d4.loss_mask: 1.0067  decode.d4.loss_dice: 0.7566  decode.d5.loss_cls: 0.3637  decode.d5.loss_mask: 0.9999  decode.d5.loss_dice: 0.7211  decode.d6.loss_cls: 0.3491  decode.d6.loss_mask: 1.0190  decode.d6.loss_dice: 0.7427  decode.d7.loss_cls: 0.3496  decode.d7.loss_mask: 1.0241  decode.d7.loss_dice: 0.7630  decode.d8.loss_cls: 0.3844  decode.d8.loss_mask: 0.9987  decode.d8.loss_dice: 0.7079
05/26 19:17:22 - mmengine - INFO - Iter(train) [ 70750/160000]  base_lr: 5.9135e-05 lr: 5.9135e-06  eta: 10:12:44  time: 0.4141  data_time: 0.0096  memory: 5976  grad_norm: 891.4276  loss: 21.1319  decode.loss_cls: 0.1879  decode.loss_mask: 1.1649  decode.loss_dice: 0.7265  decode.d0.loss_cls: 0.7048  decode.d0.loss_mask: 1.0166  decode.d0.loss_dice: 0.7105  decode.d1.loss_cls: 0.1794  decode.d1.loss_mask: 1.1532  decode.d1.loss_dice: 0.7495  decode.d2.loss_cls: 0.1610  decode.d2.loss_mask: 1.1873  decode.d2.loss_dice: 0.7338  decode.d3.loss_cls: 0.1604  decode.d3.loss_mask: 1.1746  decode.d3.loss_dice: 0.7218  decode.d4.loss_cls: 0.2459  decode.d4.loss_mask: 1.1190  decode.d4.loss_dice: 0.7269  decode.d5.loss_cls: 0.2015  decode.d5.loss_mask: 1.1660  decode.d5.loss_dice: 0.7341  decode.d6.loss_cls: 0.1822  decode.d6.loss_mask: 1.1773  decode.d6.loss_dice: 0.7366  decode.d7.loss_cls: 0.1991  decode.d7.loss_mask: 1.1226  decode.d7.loss_dice: 0.7220  decode.d8.loss_cls: 0.1415  decode.d8.loss_mask: 1.1939  decode.d8.loss_dice: 0.7313
05/26 19:17:43 - mmengine - INFO - Iter(train) [ 70800/160000]  base_lr: 5.9105e-05 lr: 5.9105e-06  eta: 10:12:24  time: 0.4149  data_time: 0.0097  memory: 5966  grad_norm: 559.6168  loss: 23.7962  decode.loss_cls: 0.2302  decode.loss_mask: 1.1994  decode.loss_dice: 0.8739  decode.d0.loss_cls: 0.8539  decode.d0.loss_mask: 1.1894  decode.d0.loss_dice: 0.8624  decode.d1.loss_cls: 0.2493  decode.d1.loss_mask: 1.1965  decode.d1.loss_dice: 0.9060  decode.d2.loss_cls: 0.2163  decode.d2.loss_mask: 1.2006  decode.d2.loss_dice: 0.8681  decode.d3.loss_cls: 0.2146  decode.d3.loss_mask: 1.1999  decode.d3.loss_dice: 0.8919  decode.d4.loss_cls: 0.2503  decode.d4.loss_mask: 1.2169  decode.d4.loss_dice: 0.9145  decode.d5.loss_cls: 0.2199  decode.d5.loss_mask: 1.2139  decode.d5.loss_dice: 0.9123  decode.d6.loss_cls: 0.3025  decode.d6.loss_mask: 1.1735  decode.d6.loss_dice: 0.8852  decode.d7.loss_cls: 0.2055  decode.d7.loss_mask: 1.2077  decode.d7.loss_dice: 0.8679  decode.d8.loss_cls: 0.2024  decode.d8.loss_mask: 1.1914  decode.d8.loss_dice: 0.8799
05/26 19:18:04 - mmengine - INFO - Iter(train) [ 70850/160000]  base_lr: 5.9075e-05 lr: 5.9075e-06  eta: 10:12:03  time: 0.4144  data_time: 0.0097  memory: 5966  grad_norm: 458.4590  loss: 21.5759  decode.loss_cls: 0.1415  decode.loss_mask: 1.2271  decode.loss_dice: 0.7578  decode.d0.loss_cls: 0.7528  decode.d0.loss_mask: 1.1138  decode.d0.loss_dice: 0.7277  decode.d1.loss_cls: 0.1787  decode.d1.loss_mask: 1.1750  decode.d1.loss_dice: 0.7333  decode.d2.loss_cls: 0.1898  decode.d2.loss_mask: 1.1822  decode.d2.loss_dice: 0.7544  decode.d3.loss_cls: 0.1837  decode.d3.loss_mask: 1.1802  decode.d3.loss_dice: 0.7563  decode.d4.loss_cls: 0.2063  decode.d4.loss_mask: 1.0958  decode.d4.loss_dice: 0.7138  decode.d5.loss_cls: 0.1963  decode.d5.loss_mask: 1.1629  decode.d5.loss_dice: 0.7297  decode.d6.loss_cls: 0.1792  decode.d6.loss_mask: 1.1781  decode.d6.loss_dice: 0.7597  decode.d7.loss_cls: 0.1659  decode.d7.loss_mask: 1.2188  decode.d7.loss_dice: 0.7718  decode.d8.loss_cls: 0.1816  decode.d8.loss_mask: 1.1891  decode.d8.loss_dice: 0.7725
05/26 19:18:24 - mmengine - INFO - Iter(train) [ 70900/160000]  base_lr: 5.9045e-05 lr: 5.9045e-06  eta: 10:11:43  time: 0.4159  data_time: 0.0099  memory: 5974  grad_norm: 649.4725  loss: 20.5835  decode.loss_cls: 0.1779  decode.loss_mask: 1.0236  decode.loss_dice: 0.7872  decode.d0.loss_cls: 0.7004  decode.d0.loss_mask: 0.9267  decode.d0.loss_dice: 0.7288  decode.d1.loss_cls: 0.2439  decode.d1.loss_mask: 1.0565  decode.d1.loss_dice: 0.7834  decode.d2.loss_cls: 0.2091  decode.d2.loss_mask: 1.0486  decode.d2.loss_dice: 0.8003  decode.d3.loss_cls: 0.1956  decode.d3.loss_mask: 1.0251  decode.d3.loss_dice: 0.7711  decode.d4.loss_cls: 0.1879  decode.d4.loss_mask: 1.0431  decode.d4.loss_dice: 0.8019  decode.d5.loss_cls: 0.2224  decode.d5.loss_mask: 1.0519  decode.d5.loss_dice: 0.7921  decode.d6.loss_cls: 0.2817  decode.d6.loss_mask: 0.9825  decode.d6.loss_dice: 0.7393  decode.d7.loss_cls: 0.2080  decode.d7.loss_mask: 1.0412  decode.d7.loss_dice: 0.7705  decode.d8.loss_cls: 0.2224  decode.d8.loss_mask: 1.0090  decode.d8.loss_dice: 0.7512
05/26 19:18:45 - mmengine - INFO - Iter(train) [ 70950/160000]  base_lr: 5.9015e-05 lr: 5.9015e-06  eta: 10:11:22  time: 0.4172  data_time: 0.0100  memory: 5970  grad_norm: 606.9168  loss: 25.7858  decode.loss_cls: 0.3267  decode.loss_mask: 1.1081  decode.loss_dice: 1.0300  decode.d0.loss_cls: 1.0111  decode.d0.loss_mask: 1.0818  decode.d0.loss_dice: 0.9768  decode.d1.loss_cls: 0.3493  decode.d1.loss_mask: 1.1378  decode.d1.loss_dice: 1.0493  decode.d2.loss_cls: 0.3530  decode.d2.loss_mask: 1.1558  decode.d2.loss_dice: 1.0194  decode.d3.loss_cls: 0.3934  decode.d3.loss_mask: 1.1585  decode.d3.loss_dice: 1.0478  decode.d4.loss_cls: 0.3568  decode.d4.loss_mask: 1.1456  decode.d4.loss_dice: 1.0727  decode.d5.loss_cls: 0.3549  decode.d5.loss_mask: 1.1139  decode.d5.loss_dice: 1.0188  decode.d6.loss_cls: 0.3592  decode.d6.loss_mask: 1.1328  decode.d6.loss_dice: 1.0317  decode.d7.loss_cls: 0.3489  decode.d7.loss_mask: 1.1404  decode.d7.loss_dice: 1.0259  decode.d8.loss_cls: 0.2859  decode.d8.loss_mask: 1.1434  decode.d8.loss_dice: 1.0560
05/26 19:19:06 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 19:19:06 - mmengine - INFO - Iter(train) [ 71000/160000]  base_lr: 5.8986e-05 lr: 5.8986e-06  eta: 10:11:02  time: 0.4152  data_time: 0.0097  memory: 5966  grad_norm: 558.0418  loss: 20.9150  decode.loss_cls: 0.2138  decode.loss_mask: 1.0069  decode.loss_dice: 0.8327  decode.d0.loss_cls: 0.7556  decode.d0.loss_mask: 0.9010  decode.d0.loss_dice: 0.7408  decode.d1.loss_cls: 0.2615  decode.d1.loss_mask: 0.9996  decode.d1.loss_dice: 0.8411  decode.d2.loss_cls: 0.2515  decode.d2.loss_mask: 0.9757  decode.d2.loss_dice: 0.8117  decode.d3.loss_cls: 0.2366  decode.d3.loss_mask: 0.9856  decode.d3.loss_dice: 0.8260  decode.d4.loss_cls: 0.2572  decode.d4.loss_mask: 0.9600  decode.d4.loss_dice: 0.8103  decode.d5.loss_cls: 0.3211  decode.d5.loss_mask: 0.9421  decode.d5.loss_dice: 0.7965  decode.d6.loss_cls: 0.2980  decode.d6.loss_mask: 0.9387  decode.d6.loss_dice: 0.8033  decode.d7.loss_cls: 0.2808  decode.d7.loss_mask: 0.9794  decode.d7.loss_dice: 0.8315  decode.d8.loss_cls: 0.3063  decode.d8.loss_mask: 0.9456  decode.d8.loss_dice: 0.8042
05/26 19:19:27 - mmengine - INFO - Iter(train) [ 71050/160000]  base_lr: 5.8956e-05 lr: 5.8956e-06  eta: 10:10:42  time: 0.4176  data_time: 0.0098  memory: 5976  grad_norm: 1711.4862  loss: 21.6236  decode.loss_cls: 0.2030  decode.loss_mask: 1.1253  decode.loss_dice: 0.7512  decode.d0.loss_cls: 0.6298  decode.d0.loss_mask: 1.1914  decode.d0.loss_dice: 0.7804  decode.d1.loss_cls: 0.2386  decode.d1.loss_mask: 1.1494  decode.d1.loss_dice: 0.7544  decode.d2.loss_cls: 0.2216  decode.d2.loss_mask: 1.1267  decode.d2.loss_dice: 0.7418  decode.d3.loss_cls: 0.2407  decode.d3.loss_mask: 1.1280  decode.d3.loss_dice: 0.7590  decode.d4.loss_cls: 0.2729  decode.d4.loss_mask: 1.1106  decode.d4.loss_dice: 0.7414  decode.d5.loss_cls: 0.2892  decode.d5.loss_mask: 1.1491  decode.d5.loss_dice: 0.7433  decode.d6.loss_cls: 0.2293  decode.d6.loss_mask: 1.1070  decode.d6.loss_dice: 0.7503  decode.d7.loss_cls: 0.2475  decode.d7.loss_mask: 1.1114  decode.d7.loss_dice: 0.7395  decode.d8.loss_cls: 0.2142  decode.d8.loss_mask: 1.1237  decode.d8.loss_dice: 0.7528
05/26 19:19:48 - mmengine - INFO - Iter(train) [ 71100/160000]  base_lr: 5.8926e-05 lr: 5.8926e-06  eta: 10:10:22  time: 0.4287  data_time: 0.0100  memory: 5980  grad_norm: 400.8121  loss: 22.4242  decode.loss_cls: 0.2303  decode.loss_mask: 1.1727  decode.loss_dice: 0.7745  decode.d0.loss_cls: 0.7125  decode.d0.loss_mask: 1.1337  decode.d0.loss_dice: 0.7132  decode.d1.loss_cls: 0.2519  decode.d1.loss_mask: 1.1864  decode.d1.loss_dice: 0.7769  decode.d2.loss_cls: 0.2536  decode.d2.loss_mask: 1.2203  decode.d2.loss_dice: 0.7926  decode.d3.loss_cls: 0.2713  decode.d3.loss_mask: 1.1707  decode.d3.loss_dice: 0.7692  decode.d4.loss_cls: 0.2949  decode.d4.loss_mask: 1.1617  decode.d4.loss_dice: 0.7582  decode.d5.loss_cls: 0.2602  decode.d5.loss_mask: 1.1609  decode.d5.loss_dice: 0.7521  decode.d6.loss_cls: 0.2669  decode.d6.loss_mask: 1.1713  decode.d6.loss_dice: 0.7828  decode.d7.loss_cls: 0.2471  decode.d7.loss_mask: 1.1815  decode.d7.loss_dice: 0.7608  decode.d8.loss_cls: 0.2569  decode.d8.loss_mask: 1.1730  decode.d8.loss_dice: 0.7662
05/26 19:20:09 - mmengine - INFO - Iter(train) [ 71150/160000]  base_lr: 5.8896e-05 lr: 5.8896e-06  eta: 10:10:01  time: 0.4150  data_time: 0.0097  memory: 5969  grad_norm: 541.6734  loss: 19.0696  decode.loss_cls: 0.1997  decode.loss_mask: 1.0055  decode.loss_dice: 0.6374  decode.d0.loss_cls: 0.7173  decode.d0.loss_mask: 0.9501  decode.d0.loss_dice: 0.6424  decode.d1.loss_cls: 0.2012  decode.d1.loss_mask: 1.0206  decode.d1.loss_dice: 0.6424  decode.d2.loss_cls: 0.2002  decode.d2.loss_mask: 1.0042  decode.d2.loss_dice: 0.6395  decode.d3.loss_cls: 0.2130  decode.d3.loss_mask: 0.9926  decode.d3.loss_dice: 0.6027  decode.d4.loss_cls: 0.2164  decode.d4.loss_mask: 1.0201  decode.d4.loss_dice: 0.6492  decode.d5.loss_cls: 0.2422  decode.d5.loss_mask: 1.0434  decode.d5.loss_dice: 0.6632  decode.d6.loss_cls: 0.2103  decode.d6.loss_mask: 1.0190  decode.d6.loss_dice: 0.6544  decode.d7.loss_cls: 0.1774  decode.d7.loss_mask: 1.0125  decode.d7.loss_dice: 0.6415  decode.d8.loss_cls: 0.2068  decode.d8.loss_mask: 1.0135  decode.d8.loss_dice: 0.6312
05/26 19:20:29 - mmengine - INFO - Iter(train) [ 71200/160000]  base_lr: 5.8866e-05 lr: 5.8866e-06  eta: 10:09:41  time: 0.4140  data_time: 0.0097  memory: 5980  grad_norm: 531.9637  loss: 20.1860  decode.loss_cls: 0.1966  decode.loss_mask: 0.9926  decode.loss_dice: 0.7852  decode.d0.loss_cls: 0.6566  decode.d0.loss_mask: 0.9641  decode.d0.loss_dice: 0.7851  decode.d1.loss_cls: 0.2142  decode.d1.loss_mask: 0.9768  decode.d1.loss_dice: 0.7961  decode.d2.loss_cls: 0.2023  decode.d2.loss_mask: 0.9767  decode.d2.loss_dice: 0.7989  decode.d3.loss_cls: 0.1871  decode.d3.loss_mask: 0.9806  decode.d3.loss_dice: 0.8076  decode.d4.loss_cls: 0.2090  decode.d4.loss_mask: 0.9930  decode.d4.loss_dice: 0.7850  decode.d5.loss_cls: 0.2024  decode.d5.loss_mask: 0.9687  decode.d5.loss_dice: 0.7843  decode.d6.loss_cls: 0.1972  decode.d6.loss_mask: 0.9632  decode.d6.loss_dice: 0.7868  decode.d7.loss_cls: 0.1940  decode.d7.loss_mask: 1.0004  decode.d7.loss_dice: 0.8010  decode.d8.loss_cls: 0.1781  decode.d8.loss_mask: 1.0130  decode.d8.loss_dice: 0.7894
05/26 19:20:50 - mmengine - INFO - Iter(train) [ 71250/160000]  base_lr: 5.8836e-05 lr: 5.8836e-06  eta: 10:09:20  time: 0.4143  data_time: 0.0097  memory: 5974  grad_norm: 449.9912  loss: 17.8919  decode.loss_cls: 0.1341  decode.loss_mask: 0.9754  decode.loss_dice: 0.6478  decode.d0.loss_cls: 0.6285  decode.d0.loss_mask: 0.8641  decode.d0.loss_dice: 0.6159  decode.d1.loss_cls: 0.2145  decode.d1.loss_mask: 0.9446  decode.d1.loss_dice: 0.6278  decode.d2.loss_cls: 0.1857  decode.d2.loss_mask: 0.9133  decode.d2.loss_dice: 0.6326  decode.d3.loss_cls: 0.1531  decode.d3.loss_mask: 0.9516  decode.d3.loss_dice: 0.6415  decode.d4.loss_cls: 0.1735  decode.d4.loss_mask: 0.9245  decode.d4.loss_dice: 0.6345  decode.d5.loss_cls: 0.1948  decode.d5.loss_mask: 0.9301  decode.d5.loss_dice: 0.6313  decode.d6.loss_cls: 0.1787  decode.d6.loss_mask: 0.9240  decode.d6.loss_dice: 0.6336  decode.d7.loss_cls: 0.1826  decode.d7.loss_mask: 0.9306  decode.d7.loss_dice: 0.6400  decode.d8.loss_cls: 0.1668  decode.d8.loss_mask: 0.9650  decode.d8.loss_dice: 0.6513
05/26 19:21:11 - mmengine - INFO - Iter(train) [ 71300/160000]  base_lr: 5.8807e-05 lr: 5.8807e-06  eta: 10:09:00  time: 0.4181  data_time: 0.0098  memory: 5967  grad_norm: 666.7892  loss: 26.2367  decode.loss_cls: 0.3590  decode.loss_mask: 1.2648  decode.loss_dice: 0.9264  decode.d0.loss_cls: 0.9254  decode.d0.loss_mask: 1.2788  decode.d0.loss_dice: 0.9425  decode.d1.loss_cls: 0.3811  decode.d1.loss_mask: 1.2957  decode.d1.loss_dice: 0.9361  decode.d2.loss_cls: 0.4032  decode.d2.loss_mask: 1.2491  decode.d2.loss_dice: 0.8610  decode.d3.loss_cls: 0.4119  decode.d3.loss_mask: 1.2513  decode.d3.loss_dice: 0.9107  decode.d4.loss_cls: 0.4242  decode.d4.loss_mask: 1.2212  decode.d4.loss_dice: 0.8984  decode.d5.loss_cls: 0.4003  decode.d5.loss_mask: 1.2451  decode.d5.loss_dice: 0.9083  decode.d6.loss_cls: 0.3926  decode.d6.loss_mask: 1.2577  decode.d6.loss_dice: 0.9639  decode.d7.loss_cls: 0.3725  decode.d7.loss_mask: 1.2713  decode.d7.loss_dice: 0.9269  decode.d8.loss_cls: 0.3373  decode.d8.loss_mask: 1.2787  decode.d8.loss_dice: 0.9414
05/26 19:21:32 - mmengine - INFO - Iter(train) [ 71350/160000]  base_lr: 5.8777e-05 lr: 5.8777e-06  eta: 10:08:40  time: 0.4151  data_time: 0.0097  memory: 5975  grad_norm: 405.9254  loss: 16.4094  decode.loss_cls: 0.1043  decode.loss_mask: 0.9127  decode.loss_dice: 0.5832  decode.d0.loss_cls: 0.6183  decode.d0.loss_mask: 0.8960  decode.d0.loss_dice: 0.5788  decode.d1.loss_cls: 0.2035  decode.d1.loss_mask: 0.8591  decode.d1.loss_dice: 0.5482  decode.d2.loss_cls: 0.1630  decode.d2.loss_mask: 0.8528  decode.d2.loss_dice: 0.5457  decode.d3.loss_cls: 0.1546  decode.d3.loss_mask: 0.8472  decode.d3.loss_dice: 0.5401  decode.d4.loss_cls: 0.2047  decode.d4.loss_mask: 0.8451  decode.d4.loss_dice: 0.5468  decode.d5.loss_cls: 0.1610  decode.d5.loss_mask: 0.8905  decode.d5.loss_dice: 0.5686  decode.d6.loss_cls: 0.1572  decode.d6.loss_mask: 0.8794  decode.d6.loss_dice: 0.5651  decode.d7.loss_cls: 0.1307  decode.d7.loss_mask: 0.8931  decode.d7.loss_dice: 0.5669  decode.d8.loss_cls: 0.1314  decode.d8.loss_mask: 0.8875  decode.d8.loss_dice: 0.5739
05/26 19:21:52 - mmengine - INFO - Iter(train) [ 71400/160000]  base_lr: 5.8747e-05 lr: 5.8747e-06  eta: 10:08:19  time: 0.4159  data_time: 0.0098  memory: 5967  grad_norm: 1166.8941  loss: 24.2837  decode.loss_cls: 0.2898  decode.loss_mask: 1.2279  decode.loss_dice: 0.8000  decode.d0.loss_cls: 0.8364  decode.d0.loss_mask: 1.1455  decode.d0.loss_dice: 0.7859  decode.d1.loss_cls: 0.3500  decode.d1.loss_mask: 1.2707  decode.d1.loss_dice: 0.8238  decode.d2.loss_cls: 0.2907  decode.d2.loss_mask: 1.2948  decode.d2.loss_dice: 0.8348  decode.d3.loss_cls: 0.3279  decode.d3.loss_mask: 1.2778  decode.d3.loss_dice: 0.8075  decode.d4.loss_cls: 0.3084  decode.d4.loss_mask: 1.3184  decode.d4.loss_dice: 0.8662  decode.d5.loss_cls: 0.2879  decode.d5.loss_mask: 1.2472  decode.d5.loss_dice: 0.8223  decode.d6.loss_cls: 0.3029  decode.d6.loss_mask: 1.2231  decode.d6.loss_dice: 0.8090  decode.d7.loss_cls: 0.2960  decode.d7.loss_mask: 1.2479  decode.d7.loss_dice: 0.7974  decode.d8.loss_cls: 0.2821  decode.d8.loss_mask: 1.2740  decode.d8.loss_dice: 0.8373
05/26 19:22:13 - mmengine - INFO - Iter(train) [ 71450/160000]  base_lr: 5.8717e-05 lr: 5.8717e-06  eta: 10:07:59  time: 0.4167  data_time: 0.0098  memory: 5966  grad_norm: 574.3778  loss: 23.4190  decode.loss_cls: 0.3049  decode.loss_mask: 1.1103  decode.loss_dice: 0.8732  decode.d0.loss_cls: 0.6844  decode.d0.loss_mask: 1.1401  decode.d0.loss_dice: 0.8688  decode.d1.loss_cls: 0.2844  decode.d1.loss_mask: 1.1366  decode.d1.loss_dice: 0.8865  decode.d2.loss_cls: 0.2500  decode.d2.loss_mask: 1.1431  decode.d2.loss_dice: 0.8818  decode.d3.loss_cls: 0.3005  decode.d3.loss_mask: 1.1318  decode.d3.loss_dice: 0.8411  decode.d4.loss_cls: 0.2612  decode.d4.loss_mask: 1.1426  decode.d4.loss_dice: 0.8535  decode.d5.loss_cls: 0.3344  decode.d5.loss_mask: 1.1185  decode.d5.loss_dice: 0.8475  decode.d6.loss_cls: 0.3007  decode.d6.loss_mask: 1.1881  decode.d6.loss_dice: 0.9036  decode.d7.loss_cls: 0.3111  decode.d7.loss_mask: 1.1383  decode.d7.loss_dice: 0.8764  decode.d8.loss_cls: 0.3053  decode.d8.loss_mask: 1.1331  decode.d8.loss_dice: 0.8673
05/26 19:22:34 - mmengine - INFO - Iter(train) [ 71500/160000]  base_lr: 5.8687e-05 lr: 5.8687e-06  eta: 10:07:38  time: 0.4140  data_time: 0.0097  memory: 5975  grad_norm: 729.2572  loss: 27.6803  decode.loss_cls: 0.3364  decode.loss_mask: 1.4078  decode.loss_dice: 0.9674  decode.d0.loss_cls: 0.9515  decode.d0.loss_mask: 1.3314  decode.d0.loss_dice: 0.9130  decode.d1.loss_cls: 0.3822  decode.d1.loss_mask: 1.4112  decode.d1.loss_dice: 0.9343  decode.d2.loss_cls: 0.3994  decode.d2.loss_mask: 1.3713  decode.d2.loss_dice: 0.9523  decode.d3.loss_cls: 0.3590  decode.d3.loss_mask: 1.3607  decode.d3.loss_dice: 0.9502  decode.d4.loss_cls: 0.3984  decode.d4.loss_mask: 1.4062  decode.d4.loss_dice: 0.9426  decode.d5.loss_cls: 0.4083  decode.d5.loss_mask: 1.4102  decode.d5.loss_dice: 0.9621  decode.d6.loss_cls: 0.3764  decode.d6.loss_mask: 1.3814  decode.d6.loss_dice: 0.9279  decode.d7.loss_cls: 0.4081  decode.d7.loss_mask: 1.3599  decode.d7.loss_dice: 0.9595  decode.d8.loss_cls: 0.3610  decode.d8.loss_mask: 1.4144  decode.d8.loss_dice: 0.9357
05/26 19:22:55 - mmengine - INFO - Iter(train) [ 71550/160000]  base_lr: 5.8657e-05 lr: 5.8657e-06  eta: 10:07:18  time: 0.4138  data_time: 0.0098  memory: 5966  grad_norm: 530.4876  loss: 18.5929  decode.loss_cls: 0.1202  decode.loss_mask: 1.0063  decode.loss_dice: 0.6612  decode.d0.loss_cls: 0.6478  decode.d0.loss_mask: 0.9885  decode.d0.loss_dice: 0.6375  decode.d1.loss_cls: 0.1672  decode.d1.loss_mask: 1.0086  decode.d1.loss_dice: 0.6888  decode.d2.loss_cls: 0.1385  decode.d2.loss_mask: 0.9898  decode.d2.loss_dice: 0.7087  decode.d3.loss_cls: 0.1457  decode.d3.loss_mask: 1.0046  decode.d3.loss_dice: 0.6909  decode.d4.loss_cls: 0.1495  decode.d4.loss_mask: 0.9780  decode.d4.loss_dice: 0.6771  decode.d5.loss_cls: 0.1090  decode.d5.loss_mask: 1.0010  decode.d5.loss_dice: 0.6865  decode.d6.loss_cls: 0.1110  decode.d6.loss_mask: 1.0150  decode.d6.loss_dice: 0.6748  decode.d7.loss_cls: 0.1232  decode.d7.loss_mask: 1.0070  decode.d7.loss_dice: 0.6645  decode.d8.loss_cls: 0.1567  decode.d8.loss_mask: 0.9680  decode.d8.loss_dice: 0.6676
05/26 19:23:15 - mmengine - INFO - Iter(train) [ 71600/160000]  base_lr: 5.8628e-05 lr: 5.8628e-06  eta: 10:06:58  time: 0.4123  data_time: 0.0096  memory: 5969  grad_norm: 618.7505  loss: 22.0269  decode.loss_cls: 0.2630  decode.loss_mask: 1.0784  decode.loss_dice: 0.8436  decode.d0.loss_cls: 0.7215  decode.d0.loss_mask: 0.9782  decode.d0.loss_dice: 0.8162  decode.d1.loss_cls: 0.3368  decode.d1.loss_mask: 1.0124  decode.d1.loss_dice: 0.8029  decode.d2.loss_cls: 0.3002  decode.d2.loss_mask: 1.0039  decode.d2.loss_dice: 0.8191  decode.d3.loss_cls: 0.2908  decode.d3.loss_mask: 1.0404  decode.d3.loss_dice: 0.8355  decode.d4.loss_cls: 0.2940  decode.d4.loss_mask: 1.0514  decode.d4.loss_dice: 0.8190  decode.d5.loss_cls: 0.2789  decode.d5.loss_mask: 1.1158  decode.d5.loss_dice: 0.8535  decode.d6.loss_cls: 0.2607  decode.d6.loss_mask: 1.0827  decode.d6.loss_dice: 0.8625  decode.d7.loss_cls: 0.2529  decode.d7.loss_mask: 1.0739  decode.d7.loss_dice: 0.8468  decode.d8.loss_cls: 0.3034  decode.d8.loss_mask: 1.0043  decode.d8.loss_dice: 0.7842
05/26 19:23:36 - mmengine - INFO - Iter(train) [ 71650/160000]  base_lr: 5.8598e-05 lr: 5.8598e-06  eta: 10:06:37  time: 0.4136  data_time: 0.0097  memory: 5984  grad_norm: 444.6622  loss: 17.9045  decode.loss_cls: 0.1982  decode.loss_mask: 0.8844  decode.loss_dice: 0.6530  decode.d0.loss_cls: 0.6508  decode.d0.loss_mask: 0.8098  decode.d0.loss_dice: 0.6434  decode.d1.loss_cls: 0.2063  decode.d1.loss_mask: 0.8864  decode.d1.loss_dice: 0.6589  decode.d2.loss_cls: 0.2348  decode.d2.loss_mask: 0.8427  decode.d2.loss_dice: 0.6307  decode.d3.loss_cls: 0.2238  decode.d3.loss_mask: 0.8628  decode.d3.loss_dice: 0.6665  decode.d4.loss_cls: 0.2381  decode.d4.loss_mask: 0.8714  decode.d4.loss_dice: 0.6508  decode.d5.loss_cls: 0.1778  decode.d5.loss_mask: 0.9294  decode.d5.loss_dice: 0.6715  decode.d6.loss_cls: 0.1944  decode.d6.loss_mask: 0.8889  decode.d6.loss_dice: 0.6618  decode.d7.loss_cls: 0.1585  decode.d7.loss_mask: 0.9242  decode.d7.loss_dice: 0.6884  decode.d8.loss_cls: 0.1875  decode.d8.loss_mask: 0.9197  decode.d8.loss_dice: 0.6896
05/26 19:23:57 - mmengine - INFO - Iter(train) [ 71700/160000]  base_lr: 5.8568e-05 lr: 5.8568e-06  eta: 10:06:17  time: 0.4141  data_time: 0.0098  memory: 5976  grad_norm: 551.8870  loss: 22.2456  decode.loss_cls: 0.1667  decode.loss_mask: 1.2276  decode.loss_dice: 0.8129  decode.d0.loss_cls: 0.6241  decode.d0.loss_mask: 1.1430  decode.d0.loss_dice: 0.7874  decode.d1.loss_cls: 0.1755  decode.d1.loss_mask: 1.1630  decode.d1.loss_dice: 0.8034  decode.d2.loss_cls: 0.1918  decode.d2.loss_mask: 1.1368  decode.d2.loss_dice: 0.7742  decode.d3.loss_cls: 0.2197  decode.d3.loss_mask: 1.2021  decode.d3.loss_dice: 0.7961  decode.d4.loss_cls: 0.2499  decode.d4.loss_mask: 1.2322  decode.d4.loss_dice: 0.7846  decode.d5.loss_cls: 0.2047  decode.d5.loss_mask: 1.1469  decode.d5.loss_dice: 0.8344  decode.d6.loss_cls: 0.2415  decode.d6.loss_mask: 1.1188  decode.d6.loss_dice: 0.8262  decode.d7.loss_cls: 0.2145  decode.d7.loss_mask: 1.1652  decode.d7.loss_dice: 0.8189  decode.d8.loss_cls: 0.1674  decode.d8.loss_mask: 1.2053  decode.d8.loss_dice: 0.8103
05/26 19:24:18 - mmengine - INFO - Iter(train) [ 71750/160000]  base_lr: 5.8538e-05 lr: 5.8538e-06  eta: 10:05:56  time: 0.4138  data_time: 0.0097  memory: 5976  grad_norm: 423.8155  loss: 22.4954  decode.loss_cls: 0.4140  decode.loss_mask: 1.0091  decode.loss_dice: 0.7876  decode.d0.loss_cls: 0.8780  decode.d0.loss_mask: 0.9066  decode.d0.loss_dice: 0.7878  decode.d1.loss_cls: 0.4351  decode.d1.loss_mask: 0.9510  decode.d1.loss_dice: 0.7914  decode.d2.loss_cls: 0.3949  decode.d2.loss_mask: 1.0248  decode.d2.loss_dice: 0.7901  decode.d3.loss_cls: 0.3722  decode.d3.loss_mask: 1.0174  decode.d3.loss_dice: 0.8155  decode.d4.loss_cls: 0.4259  decode.d4.loss_mask: 0.9895  decode.d4.loss_dice: 0.7889  decode.d5.loss_cls: 0.4171  decode.d5.loss_mask: 1.0006  decode.d5.loss_dice: 0.8300  decode.d6.loss_cls: 0.3833  decode.d6.loss_mask: 1.0056  decode.d6.loss_dice: 0.8192  decode.d7.loss_cls: 0.4084  decode.d7.loss_mask: 0.9808  decode.d7.loss_dice: 0.8518  decode.d8.loss_cls: 0.4286  decode.d8.loss_mask: 0.9625  decode.d8.loss_dice: 0.8277
05/26 19:24:38 - mmengine - INFO - Iter(train) [ 71800/160000]  base_lr: 5.8508e-05 lr: 5.8508e-06  eta: 10:05:36  time: 0.4190  data_time: 0.0098  memory: 5966  grad_norm: 458.6707  loss: 22.6714  decode.loss_cls: 0.2025  decode.loss_mask: 1.2412  decode.loss_dice: 0.7828  decode.d0.loss_cls: 0.6894  decode.d0.loss_mask: 1.1424  decode.d0.loss_dice: 0.7289  decode.d1.loss_cls: 0.1784  decode.d1.loss_mask: 1.2852  decode.d1.loss_dice: 0.7995  decode.d2.loss_cls: 0.1882  decode.d2.loss_mask: 1.2605  decode.d2.loss_dice: 0.8027  decode.d3.loss_cls: 0.1505  decode.d3.loss_mask: 1.2828  decode.d3.loss_dice: 0.8004  decode.d4.loss_cls: 0.1790  decode.d4.loss_mask: 1.2743  decode.d4.loss_dice: 0.7989  decode.d5.loss_cls: 0.1802  decode.d5.loss_mask: 1.2658  decode.d5.loss_dice: 0.7628  decode.d6.loss_cls: 0.1601  decode.d6.loss_mask: 1.2851  decode.d6.loss_dice: 0.7828  decode.d7.loss_cls: 0.1847  decode.d7.loss_mask: 1.2733  decode.d7.loss_dice: 0.7863  decode.d8.loss_cls: 0.1880  decode.d8.loss_mask: 1.2464  decode.d8.loss_dice: 0.7684
05/26 19:24:59 - mmengine - INFO - Iter(train) [ 71850/160000]  base_lr: 5.8478e-05 lr: 5.8478e-06  eta: 10:05:15  time: 0.4149  data_time: 0.0097  memory: 5967  grad_norm: 493.8104  loss: 19.0775  decode.loss_cls: 0.2484  decode.loss_mask: 0.9911  decode.loss_dice: 0.6343  decode.d0.loss_cls: 0.6658  decode.d0.loss_mask: 0.9943  decode.d0.loss_dice: 0.6426  decode.d1.loss_cls: 0.2261  decode.d1.loss_mask: 1.0488  decode.d1.loss_dice: 0.6589  decode.d2.loss_cls: 0.2205  decode.d2.loss_mask: 0.9632  decode.d2.loss_dice: 0.6399  decode.d3.loss_cls: 0.2250  decode.d3.loss_mask: 0.9717  decode.d3.loss_dice: 0.6399  decode.d4.loss_cls: 0.2095  decode.d4.loss_mask: 0.9877  decode.d4.loss_dice: 0.6411  decode.d5.loss_cls: 0.2474  decode.d5.loss_mask: 0.9784  decode.d5.loss_dice: 0.6368  decode.d6.loss_cls: 0.3012  decode.d6.loss_mask: 0.9722  decode.d6.loss_dice: 0.6158  decode.d7.loss_cls: 0.2569  decode.d7.loss_mask: 0.9773  decode.d7.loss_dice: 0.6341  decode.d8.loss_cls: 0.2600  decode.d8.loss_mask: 0.9623  decode.d8.loss_dice: 0.6262
05/26 19:25:20 - mmengine - INFO - Iter(train) [ 71900/160000]  base_lr: 5.8448e-05 lr: 5.8448e-06  eta: 10:04:55  time: 0.4149  data_time: 0.0097  memory: 5970  grad_norm: 500.6297  loss: 18.8524  decode.loss_cls: 0.2068  decode.loss_mask: 0.9641  decode.loss_dice: 0.6365  decode.d0.loss_cls: 0.6976  decode.d0.loss_mask: 0.9616  decode.d0.loss_dice: 0.6694  decode.d1.loss_cls: 0.2278  decode.d1.loss_mask: 0.9404  decode.d1.loss_dice: 0.6539  decode.d2.loss_cls: 0.1941  decode.d2.loss_mask: 0.9324  decode.d2.loss_dice: 0.6367  decode.d3.loss_cls: 0.2280  decode.d3.loss_mask: 1.0042  decode.d3.loss_dice: 0.6557  decode.d4.loss_cls: 0.2293  decode.d4.loss_mask: 1.0044  decode.d4.loss_dice: 0.6359  decode.d5.loss_cls: 0.2177  decode.d5.loss_mask: 0.9812  decode.d5.loss_dice: 0.6391  decode.d6.loss_cls: 0.2183  decode.d6.loss_mask: 0.9859  decode.d6.loss_dice: 0.6498  decode.d7.loss_cls: 0.2070  decode.d7.loss_mask: 1.0079  decode.d7.loss_dice: 0.6550  decode.d8.loss_cls: 0.2264  decode.d8.loss_mask: 0.9523  decode.d8.loss_dice: 0.6331
05/26 19:25:41 - mmengine - INFO - Iter(train) [ 71950/160000]  base_lr: 5.8419e-05 lr: 5.8419e-06  eta: 10:04:35  time: 0.4167  data_time: 0.0098  memory: 5966  grad_norm: 551.9383  loss: 20.4886  decode.loss_cls: 0.1132  decode.loss_mask: 1.0863  decode.loss_dice: 0.7915  decode.d0.loss_cls: 0.6326  decode.d0.loss_mask: 1.0379  decode.d0.loss_dice: 0.7297  decode.d1.loss_cls: 0.1254  decode.d1.loss_mask: 1.0855  decode.d1.loss_dice: 0.8137  decode.d2.loss_cls: 0.1164  decode.d2.loss_mask: 1.0918  decode.d2.loss_dice: 0.7887  decode.d3.loss_cls: 0.1303  decode.d3.loss_mask: 1.0803  decode.d3.loss_dice: 0.7888  decode.d4.loss_cls: 0.1486  decode.d4.loss_mask: 1.0831  decode.d4.loss_dice: 0.7855  decode.d5.loss_cls: 0.1175  decode.d5.loss_mask: 1.1014  decode.d5.loss_dice: 0.8062  decode.d6.loss_cls: 0.1343  decode.d6.loss_mask: 1.0855  decode.d6.loss_dice: 0.7966  decode.d7.loss_cls: 0.1368  decode.d7.loss_mask: 1.0946  decode.d7.loss_dice: 0.7916  decode.d8.loss_cls: 0.0951  decode.d8.loss_mask: 1.0998  decode.d8.loss_dice: 0.7999
05/26 19:26:01 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 19:26:01 - mmengine - INFO - Iter(train) [ 72000/160000]  base_lr: 5.8389e-05 lr: 5.8389e-06  eta: 10:04:14  time: 0.4145  data_time: 0.0097  memory: 5968  grad_norm: 293.7269  loss: 15.2519  decode.loss_cls: 0.1217  decode.loss_mask: 0.8165  decode.loss_dice: 0.5618  decode.d0.loss_cls: 0.5669  decode.d0.loss_mask: 0.7673  decode.d0.loss_dice: 0.5745  decode.d1.loss_cls: 0.1390  decode.d1.loss_mask: 0.7829  decode.d1.loss_dice: 0.5714  decode.d2.loss_cls: 0.0701  decode.d2.loss_mask: 0.8078  decode.d2.loss_dice: 0.5899  decode.d3.loss_cls: 0.0952  decode.d3.loss_mask: 0.8103  decode.d3.loss_dice: 0.5664  decode.d4.loss_cls: 0.1178  decode.d4.loss_mask: 0.8109  decode.d4.loss_dice: 0.5498  decode.d5.loss_cls: 0.1005  decode.d5.loss_mask: 0.8105  decode.d5.loss_dice: 0.5360  decode.d6.loss_cls: 0.1256  decode.d6.loss_mask: 0.8064  decode.d6.loss_dice: 0.5690  decode.d7.loss_cls: 0.1071  decode.d7.loss_mask: 0.8010  decode.d7.loss_dice: 0.5634  decode.d8.loss_cls: 0.1249  decode.d8.loss_mask: 0.8016  decode.d8.loss_dice: 0.5859
05/26 19:26:22 - mmengine - INFO - Iter(train) [ 72050/160000]  base_lr: 5.8359e-05 lr: 5.8359e-06  eta: 10:03:54  time: 0.4147  data_time: 0.0097  memory: 5979  grad_norm: 602.7538  loss: 24.5158  decode.loss_cls: 0.3378  decode.loss_mask: 1.1242  decode.loss_dice: 0.9663  decode.d0.loss_cls: 0.9015  decode.d0.loss_mask: 1.0208  decode.d0.loss_dice: 0.8995  decode.d1.loss_cls: 0.3479  decode.d1.loss_mask: 1.1022  decode.d1.loss_dice: 1.0136  decode.d2.loss_cls: 0.2993  decode.d2.loss_mask: 1.1041  decode.d2.loss_dice: 0.9597  decode.d3.loss_cls: 0.3555  decode.d3.loss_mask: 1.1171  decode.d3.loss_dice: 0.9599  decode.d4.loss_cls: 0.2640  decode.d4.loss_mask: 1.1042  decode.d4.loss_dice: 0.9591  decode.d5.loss_cls: 0.3219  decode.d5.loss_mask: 1.1319  decode.d5.loss_dice: 0.9899  decode.d6.loss_cls: 0.3530  decode.d6.loss_mask: 1.0905  decode.d6.loss_dice: 0.9782  decode.d7.loss_cls: 0.3252  decode.d7.loss_mask: 1.0884  decode.d7.loss_dice: 0.9575  decode.d8.loss_cls: 0.3736  decode.d8.loss_mask: 1.0846  decode.d8.loss_dice: 0.9842
05/26 19:26:43 - mmengine - INFO - Iter(train) [ 72100/160000]  base_lr: 5.8329e-05 lr: 5.8329e-06  eta: 10:03:33  time: 0.4139  data_time: 0.0096  memory: 5971  grad_norm: 618.2127  loss: 20.0839  decode.loss_cls: 0.2755  decode.loss_mask: 1.0347  decode.loss_dice: 0.6986  decode.d0.loss_cls: 0.5881  decode.d0.loss_mask: 1.0432  decode.d0.loss_dice: 0.6997  decode.d1.loss_cls: 0.2892  decode.d1.loss_mask: 0.9967  decode.d1.loss_dice: 0.6898  decode.d2.loss_cls: 0.2043  decode.d2.loss_mask: 1.0426  decode.d2.loss_dice: 0.6922  decode.d3.loss_cls: 0.2135  decode.d3.loss_mask: 1.0412  decode.d3.loss_dice: 0.6886  decode.d4.loss_cls: 0.2204  decode.d4.loss_mask: 1.0815  decode.d4.loss_dice: 0.6999  decode.d5.loss_cls: 0.2026  decode.d5.loss_mask: 1.0565  decode.d5.loss_dice: 0.7156  decode.d6.loss_cls: 0.2832  decode.d6.loss_mask: 0.9899  decode.d6.loss_dice: 0.6784  decode.d7.loss_cls: 0.2209  decode.d7.loss_mask: 1.0221  decode.d7.loss_dice: 0.6952  decode.d8.loss_cls: 0.2649  decode.d8.loss_mask: 1.0517  decode.d8.loss_dice: 0.7033
05/26 19:27:04 - mmengine - INFO - Iter(train) [ 72150/160000]  base_lr: 5.8299e-05 lr: 5.8299e-06  eta: 10:03:13  time: 0.4136  data_time: 0.0097  memory: 5966  grad_norm: 668.1548  loss: 24.9325  decode.loss_cls: 0.3678  decode.loss_mask: 1.1698  decode.loss_dice: 0.9626  decode.d0.loss_cls: 0.8060  decode.d0.loss_mask: 1.1026  decode.d0.loss_dice: 0.9335  decode.d1.loss_cls: 0.3833  decode.d1.loss_mask: 1.1334  decode.d1.loss_dice: 0.9419  decode.d2.loss_cls: 0.3394  decode.d2.loss_mask: 1.1137  decode.d2.loss_dice: 0.9268  decode.d3.loss_cls: 0.3543  decode.d3.loss_mask: 1.1763  decode.d3.loss_dice: 0.9422  decode.d4.loss_cls: 0.3743  decode.d4.loss_mask: 1.1598  decode.d4.loss_dice: 0.9532  decode.d5.loss_cls: 0.3516  decode.d5.loss_mask: 1.1247  decode.d5.loss_dice: 0.9191  decode.d6.loss_cls: 0.3959  decode.d6.loss_mask: 1.1629  decode.d6.loss_dice: 0.9479  decode.d7.loss_cls: 0.3828  decode.d7.loss_mask: 1.1170  decode.d7.loss_dice: 0.9131  decode.d8.loss_cls: 0.4157  decode.d8.loss_mask: 1.1292  decode.d8.loss_dice: 0.9317
05/26 19:27:25 - mmengine - INFO - Iter(train) [ 72200/160000]  base_lr: 5.8269e-05 lr: 5.8269e-06  eta: 10:02:53  time: 0.4142  data_time: 0.0097  memory: 5966  grad_norm: 846.2793  loss: 22.0300  decode.loss_cls: 0.3212  decode.loss_mask: 1.0838  decode.loss_dice: 0.7757  decode.d0.loss_cls: 0.7661  decode.d0.loss_mask: 1.0235  decode.d0.loss_dice: 0.7316  decode.d1.loss_cls: 0.3702  decode.d1.loss_mask: 1.0147  decode.d1.loss_dice: 0.7410  decode.d2.loss_cls: 0.2874  decode.d2.loss_mask: 1.0602  decode.d2.loss_dice: 0.7545  decode.d3.loss_cls: 0.3092  decode.d3.loss_mask: 1.0885  decode.d3.loss_dice: 0.7597  decode.d4.loss_cls: 0.3289  decode.d4.loss_mask: 1.1007  decode.d4.loss_dice: 0.7851  decode.d5.loss_cls: 0.3243  decode.d5.loss_mask: 1.1001  decode.d5.loss_dice: 0.7266  decode.d6.loss_cls: 0.3089  decode.d6.loss_mask: 1.1243  decode.d6.loss_dice: 0.7755  decode.d7.loss_cls: 0.3415  decode.d7.loss_mask: 1.0729  decode.d7.loss_dice: 0.7468  decode.d8.loss_cls: 0.2811  decode.d8.loss_mask: 1.1364  decode.d8.loss_dice: 0.7897
05/26 19:27:45 - mmengine - INFO - Iter(train) [ 72250/160000]  base_lr: 5.8239e-05 lr: 5.8239e-06  eta: 10:02:32  time: 0.4143  data_time: 0.0098  memory: 5975  grad_norm: 605.6552  loss: 22.2576  decode.loss_cls: 0.2941  decode.loss_mask: 1.0882  decode.loss_dice: 0.7723  decode.d0.loss_cls: 0.7234  decode.d0.loss_mask: 1.1287  decode.d0.loss_dice: 0.7609  decode.d1.loss_cls: 0.2979  decode.d1.loss_mask: 1.1614  decode.d1.loss_dice: 0.7637  decode.d2.loss_cls: 0.3057  decode.d2.loss_mask: 1.1251  decode.d2.loss_dice: 0.7515  decode.d3.loss_cls: 0.2664  decode.d3.loss_mask: 1.1566  decode.d3.loss_dice: 0.7747  decode.d4.loss_cls: 0.3102  decode.d4.loss_mask: 1.1133  decode.d4.loss_dice: 0.7435  decode.d5.loss_cls: 0.3428  decode.d5.loss_mask: 1.0913  decode.d5.loss_dice: 0.7519  decode.d6.loss_cls: 0.3147  decode.d6.loss_mask: 1.1050  decode.d6.loss_dice: 0.7502  decode.d7.loss_cls: 0.2963  decode.d7.loss_mask: 1.1216  decode.d7.loss_dice: 0.7605  decode.d8.loss_cls: 0.2827  decode.d8.loss_mask: 1.1282  decode.d8.loss_dice: 0.7749
05/26 19:28:06 - mmengine - INFO - Iter(train) [ 72300/160000]  base_lr: 5.8210e-05 lr: 5.8210e-06  eta: 10:02:12  time: 0.4126  data_time: 0.0097  memory: 5967  grad_norm: 488.2072  loss: 17.0807  decode.loss_cls: 0.1627  decode.loss_mask: 0.8308  decode.loss_dice: 0.6748  decode.d0.loss_cls: 0.5630  decode.d0.loss_mask: 0.7747  decode.d0.loss_dice: 0.6063  decode.d1.loss_cls: 0.1695  decode.d1.loss_mask: 0.8439  decode.d1.loss_dice: 0.6819  decode.d2.loss_cls: 0.2077  decode.d2.loss_mask: 0.8281  decode.d2.loss_dice: 0.6734  decode.d3.loss_cls: 0.2044  decode.d3.loss_mask: 0.7980  decode.d3.loss_dice: 0.6497  decode.d4.loss_cls: 0.2418  decode.d4.loss_mask: 0.8131  decode.d4.loss_dice: 0.6379  decode.d5.loss_cls: 0.1580  decode.d5.loss_mask: 0.8071  decode.d5.loss_dice: 0.6674  decode.d6.loss_cls: 0.1756  decode.d6.loss_mask: 0.8259  decode.d6.loss_dice: 0.6678  decode.d7.loss_cls: 0.2023  decode.d7.loss_mask: 0.8413  decode.d7.loss_dice: 0.7001  decode.d8.loss_cls: 0.1577  decode.d8.loss_mask: 0.8397  decode.d8.loss_dice: 0.6763
05/26 19:28:27 - mmengine - INFO - Iter(train) [ 72350/160000]  base_lr: 5.8180e-05 lr: 5.8180e-06  eta: 10:01:51  time: 0.4156  data_time: 0.0098  memory: 5976  grad_norm: 474.0019  loss: 21.1310  decode.loss_cls: 0.2006  decode.loss_mask: 1.0991  decode.loss_dice: 0.7557  decode.d0.loss_cls: 0.7472  decode.d0.loss_mask: 1.0688  decode.d0.loss_dice: 0.7212  decode.d1.loss_cls: 0.2115  decode.d1.loss_mask: 1.1231  decode.d1.loss_dice: 0.7895  decode.d2.loss_cls: 0.1540  decode.d2.loss_mask: 1.1400  decode.d2.loss_dice: 0.7544  decode.d3.loss_cls: 0.1611  decode.d3.loss_mask: 1.1299  decode.d3.loss_dice: 0.7399  decode.d4.loss_cls: 0.1815  decode.d4.loss_mask: 1.1321  decode.d4.loss_dice: 0.7559  decode.d5.loss_cls: 0.1575  decode.d5.loss_mask: 1.1452  decode.d5.loss_dice: 0.7727  decode.d6.loss_cls: 0.1724  decode.d6.loss_mask: 1.1089  decode.d6.loss_dice: 0.7612  decode.d7.loss_cls: 0.1733  decode.d7.loss_mask: 1.1341  decode.d7.loss_dice: 0.7721  decode.d8.loss_cls: 0.1436  decode.d8.loss_mask: 1.1501  decode.d8.loss_dice: 0.7744
05/26 19:28:47 - mmengine - INFO - Iter(train) [ 72400/160000]  base_lr: 5.8150e-05 lr: 5.8150e-06  eta: 10:01:31  time: 0.4123  data_time: 0.0095  memory: 5969  grad_norm: 762.8892  loss: 22.0297  decode.loss_cls: 0.2054  decode.loss_mask: 1.1819  decode.loss_dice: 0.7797  decode.d0.loss_cls: 0.6302  decode.d0.loss_mask: 1.1037  decode.d0.loss_dice: 0.7468  decode.d1.loss_cls: 0.2403  decode.d1.loss_mask: 1.1802  decode.d1.loss_dice: 0.7874  decode.d2.loss_cls: 0.2005  decode.d2.loss_mask: 1.1901  decode.d2.loss_dice: 0.7878  decode.d3.loss_cls: 0.2037  decode.d3.loss_mask: 1.1685  decode.d3.loss_dice: 0.7959  decode.d4.loss_cls: 0.1959  decode.d4.loss_mask: 1.1563  decode.d4.loss_dice: 0.7806  decode.d5.loss_cls: 0.2020  decode.d5.loss_mask: 1.1684  decode.d5.loss_dice: 0.7728  decode.d6.loss_cls: 0.2306  decode.d6.loss_mask: 1.1590  decode.d6.loss_dice: 0.8010  decode.d7.loss_cls: 0.2002  decode.d7.loss_mask: 1.1625  decode.d7.loss_dice: 0.7982  decode.d8.loss_cls: 0.2088  decode.d8.loss_mask: 1.1894  decode.d8.loss_dice: 0.8020
05/26 19:29:08 - mmengine - INFO - Iter(train) [ 72450/160000]  base_lr: 5.8120e-05 lr: 5.8120e-06  eta: 10:01:10  time: 0.4148  data_time: 0.0097  memory: 5975  grad_norm: 459.0279  loss: 20.4791  decode.loss_cls: 0.2111  decode.loss_mask: 1.0343  decode.loss_dice: 0.7406  decode.d0.loss_cls: 0.6781  decode.d0.loss_mask: 0.9678  decode.d0.loss_dice: 0.7139  decode.d1.loss_cls: 0.1689  decode.d1.loss_mask: 1.0958  decode.d1.loss_dice: 0.7792  decode.d2.loss_cls: 0.2027  decode.d2.loss_mask: 1.0419  decode.d2.loss_dice: 0.7620  decode.d3.loss_cls: 0.1889  decode.d3.loss_mask: 1.0667  decode.d3.loss_dice: 0.7980  decode.d4.loss_cls: 0.1881  decode.d4.loss_mask: 1.0679  decode.d4.loss_dice: 0.7823  decode.d5.loss_cls: 0.1593  decode.d5.loss_mask: 1.0774  decode.d5.loss_dice: 0.7682  decode.d6.loss_cls: 0.1820  decode.d6.loss_mask: 1.0293  decode.d6.loss_dice: 0.7479  decode.d7.loss_cls: 0.1853  decode.d7.loss_mask: 1.0960  decode.d7.loss_dice: 0.7521  decode.d8.loss_cls: 0.1659  decode.d8.loss_mask: 1.0606  decode.d8.loss_dice: 0.7668
05/26 19:29:29 - mmengine - INFO - Iter(train) [ 72500/160000]  base_lr: 5.8090e-05 lr: 5.8090e-06  eta: 10:00:50  time: 0.4147  data_time: 0.0098  memory: 5966  grad_norm: 557.5861  loss: 21.6666  decode.loss_cls: 0.1895  decode.loss_mask: 1.1192  decode.loss_dice: 0.8200  decode.d0.loss_cls: 0.6069  decode.d0.loss_mask: 1.0735  decode.d0.loss_dice: 0.7835  decode.d1.loss_cls: 0.1794  decode.d1.loss_mask: 1.1087  decode.d1.loss_dice: 0.8297  decode.d2.loss_cls: 0.1966  decode.d2.loss_mask: 1.1241  decode.d2.loss_dice: 0.8248  decode.d3.loss_cls: 0.1520  decode.d3.loss_mask: 1.0982  decode.d3.loss_dice: 0.8158  decode.d4.loss_cls: 0.1877  decode.d4.loss_mask: 1.1069  decode.d4.loss_dice: 0.8255  decode.d5.loss_cls: 0.2019  decode.d5.loss_mask: 1.1184  decode.d5.loss_dice: 0.8137  decode.d6.loss_cls: 0.1913  decode.d6.loss_mask: 1.1233  decode.d6.loss_dice: 0.8203  decode.d7.loss_cls: 0.2172  decode.d7.loss_mask: 1.1447  decode.d7.loss_dice: 0.8471  decode.d8.loss_cls: 0.2137  decode.d8.loss_mask: 1.1174  decode.d8.loss_dice: 0.8157
05/26 19:29:50 - mmengine - INFO - Iter(train) [ 72550/160000]  base_lr: 5.8060e-05 lr: 5.8060e-06  eta: 10:00:29  time: 0.4163  data_time: 0.0097  memory: 5975  grad_norm: 490.4210  loss: 20.7012  decode.loss_cls: 0.2788  decode.loss_mask: 0.9622  decode.loss_dice: 0.7389  decode.d0.loss_cls: 0.7172  decode.d0.loss_mask: 0.9925  decode.d0.loss_dice: 0.7367  decode.d1.loss_cls: 0.2939  decode.d1.loss_mask: 0.9510  decode.d1.loss_dice: 0.7558  decode.d2.loss_cls: 0.3299  decode.d2.loss_mask: 0.9822  decode.d2.loss_dice: 0.7613  decode.d3.loss_cls: 0.2741  decode.d3.loss_mask: 0.9861  decode.d3.loss_dice: 0.7633  decode.d4.loss_cls: 0.2605  decode.d4.loss_mask: 0.9907  decode.d4.loss_dice: 0.8102  decode.d5.loss_cls: 0.3449  decode.d5.loss_mask: 0.9633  decode.d5.loss_dice: 0.7914  decode.d6.loss_cls: 0.3130  decode.d6.loss_mask: 0.9795  decode.d6.loss_dice: 0.7383  decode.d7.loss_cls: 0.3115  decode.d7.loss_mask: 0.9640  decode.d7.loss_dice: 0.7323  decode.d8.loss_cls: 0.2695  decode.d8.loss_mask: 0.9558  decode.d8.loss_dice: 0.7525
05/26 19:30:10 - mmengine - INFO - Iter(train) [ 72600/160000]  base_lr: 5.8030e-05 lr: 5.8030e-06  eta: 10:00:09  time: 0.4165  data_time: 0.0098  memory: 5971  grad_norm: 674.5041  loss: 21.8028  decode.loss_cls: 0.2487  decode.loss_mask: 0.9974  decode.loss_dice: 0.8810  decode.d0.loss_cls: 0.7392  decode.d0.loss_mask: 0.9960  decode.d0.loss_dice: 0.8413  decode.d1.loss_cls: 0.2365  decode.d1.loss_mask: 1.0129  decode.d1.loss_dice: 0.8705  decode.d2.loss_cls: 0.2732  decode.d2.loss_mask: 0.9799  decode.d2.loss_dice: 0.8724  decode.d3.loss_cls: 0.2418  decode.d3.loss_mask: 1.0370  decode.d3.loss_dice: 0.8860  decode.d4.loss_cls: 0.2166  decode.d4.loss_mask: 1.0296  decode.d4.loss_dice: 0.8783  decode.d5.loss_cls: 0.2084  decode.d5.loss_mask: 1.0337  decode.d5.loss_dice: 0.8939  decode.d6.loss_cls: 0.2428  decode.d6.loss_mask: 1.0193  decode.d6.loss_dice: 0.8957  decode.d7.loss_cls: 0.2532  decode.d7.loss_mask: 1.0048  decode.d7.loss_dice: 0.8813  decode.d8.loss_cls: 0.2178  decode.d8.loss_mask: 1.0273  decode.d8.loss_dice: 0.8861
05/26 19:30:31 - mmengine - INFO - Iter(train) [ 72650/160000]  base_lr: 5.8000e-05 lr: 5.8000e-06  eta: 9:59:48  time: 0.4160  data_time: 0.0097  memory: 5966  grad_norm: 867.8651  loss: 17.7436  decode.loss_cls: 0.0923  decode.loss_mask: 0.9846  decode.loss_dice: 0.6350  decode.d0.loss_cls: 0.5378  decode.d0.loss_mask: 0.9875  decode.d0.loss_dice: 0.6503  decode.d1.loss_cls: 0.1338  decode.d1.loss_mask: 0.9720  decode.d1.loss_dice: 0.6198  decode.d2.loss_cls: 0.1275  decode.d2.loss_mask: 0.9646  decode.d2.loss_dice: 0.6404  decode.d3.loss_cls: 0.1079  decode.d3.loss_mask: 0.9677  decode.d3.loss_dice: 0.6391  decode.d4.loss_cls: 0.1489  decode.d4.loss_mask: 0.9674  decode.d4.loss_dice: 0.6491  decode.d5.loss_cls: 0.1562  decode.d5.loss_mask: 0.9593  decode.d5.loss_dice: 0.6089  decode.d6.loss_cls: 0.1245  decode.d6.loss_mask: 0.9751  decode.d6.loss_dice: 0.6318  decode.d7.loss_cls: 0.1282  decode.d7.loss_mask: 0.9698  decode.d7.loss_dice: 0.6312  decode.d8.loss_cls: 0.1094  decode.d8.loss_mask: 0.9838  decode.d8.loss_dice: 0.6394
05/26 19:30:52 - mmengine - INFO - Iter(train) [ 72700/160000]  base_lr: 5.7971e-05 lr: 5.7971e-06  eta: 9:59:28  time: 0.4152  data_time: 0.0098  memory: 5969  grad_norm: 527.5837  loss: 21.7301  decode.loss_cls: 0.1788  decode.loss_mask: 1.1967  decode.loss_dice: 0.7659  decode.d0.loss_cls: 0.7098  decode.d0.loss_mask: 1.0951  decode.d0.loss_dice: 0.7558  decode.d1.loss_cls: 0.1765  decode.d1.loss_mask: 1.2085  decode.d1.loss_dice: 0.7871  decode.d2.loss_cls: 0.1658  decode.d2.loss_mask: 1.1775  decode.d2.loss_dice: 0.7739  decode.d3.loss_cls: 0.1706  decode.d3.loss_mask: 1.1495  decode.d3.loss_dice: 0.7633  decode.d4.loss_cls: 0.1916  decode.d4.loss_mask: 1.1601  decode.d4.loss_dice: 0.7487  decode.d5.loss_cls: 0.1974  decode.d5.loss_mask: 1.1511  decode.d5.loss_dice: 0.7851  decode.d6.loss_cls: 0.2009  decode.d6.loss_mask: 1.1776  decode.d6.loss_dice: 0.7593  decode.d7.loss_cls: 0.2261  decode.d7.loss_mask: 1.1662  decode.d7.loss_dice: 0.7497  decode.d8.loss_cls: 0.1967  decode.d8.loss_mask: 1.1884  decode.d8.loss_dice: 0.7565
05/26 19:31:13 - mmengine - INFO - Iter(train) [ 72750/160000]  base_lr: 5.7941e-05 lr: 5.7941e-06  eta: 9:59:08  time: 0.4149  data_time: 0.0097  memory: 5980  grad_norm: 485.6698  loss: 21.8801  decode.loss_cls: 0.2256  decode.loss_mask: 1.1575  decode.loss_dice: 0.7654  decode.d0.loss_cls: 0.6707  decode.d0.loss_mask: 1.1214  decode.d0.loss_dice: 0.7818  decode.d1.loss_cls: 0.2469  decode.d1.loss_mask: 1.1219  decode.d1.loss_dice: 0.7717  decode.d2.loss_cls: 0.2309  decode.d2.loss_mask: 1.1291  decode.d2.loss_dice: 0.7699  decode.d3.loss_cls: 0.2407  decode.d3.loss_mask: 1.1272  decode.d3.loss_dice: 0.7743  decode.d4.loss_cls: 0.2263  decode.d4.loss_mask: 1.1275  decode.d4.loss_dice: 0.7639  decode.d5.loss_cls: 0.2223  decode.d5.loss_mask: 1.1240  decode.d5.loss_dice: 0.7650  decode.d6.loss_cls: 0.2432  decode.d6.loss_mask: 1.1405  decode.d6.loss_dice: 0.7727  decode.d7.loss_cls: 0.2427  decode.d7.loss_mask: 1.1775  decode.d7.loss_dice: 0.7823  decode.d8.loss_cls: 0.2433  decode.d8.loss_mask: 1.1355  decode.d8.loss_dice: 0.7783
05/26 19:31:34 - mmengine - INFO - Iter(train) [ 72800/160000]  base_lr: 5.7911e-05 lr: 5.7911e-06  eta: 9:58:47  time: 0.4169  data_time: 0.0099  memory: 5973  grad_norm: 702.5209  loss: 22.2336  decode.loss_cls: 0.2595  decode.loss_mask: 1.1389  decode.loss_dice: 0.7346  decode.d0.loss_cls: 0.8436  decode.d0.loss_mask: 1.0406  decode.d0.loss_dice: 0.7004  decode.d1.loss_cls: 0.3345  decode.d1.loss_mask: 1.1055  decode.d1.loss_dice: 0.7548  decode.d2.loss_cls: 0.2434  decode.d2.loss_mask: 1.1839  decode.d2.loss_dice: 0.8075  decode.d3.loss_cls: 0.3024  decode.d3.loss_mask: 1.1422  decode.d3.loss_dice: 0.7678  decode.d4.loss_cls: 0.2888  decode.d4.loss_mask: 1.1521  decode.d4.loss_dice: 0.7474  decode.d5.loss_cls: 0.3155  decode.d5.loss_mask: 1.1318  decode.d5.loss_dice: 0.7355  decode.d6.loss_cls: 0.2585  decode.d6.loss_mask: 1.1675  decode.d6.loss_dice: 0.7617  decode.d7.loss_cls: 0.3133  decode.d7.loss_mask: 1.1106  decode.d7.loss_dice: 0.7563  decode.d8.loss_cls: 0.2472  decode.d8.loss_mask: 1.1329  decode.d8.loss_dice: 0.7548
05/26 19:31:54 - mmengine - INFO - Iter(train) [ 72850/160000]  base_lr: 5.7881e-05 lr: 5.7881e-06  eta: 9:58:27  time: 0.4163  data_time: 0.0098  memory: 5983  grad_norm: 513.6529  loss: 20.7682  decode.loss_cls: 0.2132  decode.loss_mask: 1.0971  decode.loss_dice: 0.8108  decode.d0.loss_cls: 0.7621  decode.d0.loss_mask: 0.9270  decode.d0.loss_dice: 0.7515  decode.d1.loss_cls: 0.3152  decode.d1.loss_mask: 0.9602  decode.d1.loss_dice: 0.7443  decode.d2.loss_cls: 0.2825  decode.d2.loss_mask: 0.9731  decode.d2.loss_dice: 0.7666  decode.d3.loss_cls: 0.2828  decode.d3.loss_mask: 0.9550  decode.d3.loss_dice: 0.7428  decode.d4.loss_cls: 0.2734  decode.d4.loss_mask: 1.0258  decode.d4.loss_dice: 0.7731  decode.d5.loss_cls: 0.2837  decode.d5.loss_mask: 0.9672  decode.d5.loss_dice: 0.7772  decode.d6.loss_cls: 0.2790  decode.d6.loss_mask: 0.9739  decode.d6.loss_dice: 0.7573  decode.d7.loss_cls: 0.2971  decode.d7.loss_mask: 0.9657  decode.d7.loss_dice: 0.7800  decode.d8.loss_cls: 0.2294  decode.d8.loss_mask: 1.0224  decode.d8.loss_dice: 0.7785
05/26 19:32:15 - mmengine - INFO - Iter(train) [ 72900/160000]  base_lr: 5.7851e-05 lr: 5.7851e-06  eta: 9:58:07  time: 0.4184  data_time: 0.0099  memory: 5966  grad_norm: 1042.4393  loss: 21.2002  decode.loss_cls: 0.2146  decode.loss_mask: 1.1050  decode.loss_dice: 0.7957  decode.d0.loss_cls: 0.6605  decode.d0.loss_mask: 1.0653  decode.d0.loss_dice: 0.7413  decode.d1.loss_cls: 0.1822  decode.d1.loss_mask: 1.0915  decode.d1.loss_dice: 0.7767  decode.d2.loss_cls: 0.2116  decode.d2.loss_mask: 1.1074  decode.d2.loss_dice: 0.7750  decode.d3.loss_cls: 0.2089  decode.d3.loss_mask: 1.0941  decode.d3.loss_dice: 0.7839  decode.d4.loss_cls: 0.2257  decode.d4.loss_mask: 1.1042  decode.d4.loss_dice: 0.7812  decode.d5.loss_cls: 0.2279  decode.d5.loss_mask: 1.0888  decode.d5.loss_dice: 0.7669  decode.d6.loss_cls: 0.1915  decode.d6.loss_mask: 1.0864  decode.d6.loss_dice: 0.7583  decode.d7.loss_cls: 0.2147  decode.d7.loss_mask: 1.1095  decode.d7.loss_dice: 0.7640  decode.d8.loss_cls: 0.2079  decode.d8.loss_mask: 1.1007  decode.d8.loss_dice: 0.7588
05/26 19:32:36 - mmengine - INFO - Iter(train) [ 72950/160000]  base_lr: 5.7821e-05 lr: 5.7821e-06  eta: 9:57:47  time: 0.4171  data_time: 0.0099  memory: 5968  grad_norm: 815.3824  loss: 16.5946  decode.loss_cls: 0.0800  decode.loss_mask: 0.8710  decode.loss_dice: 0.6838  decode.d0.loss_cls: 0.5121  decode.d0.loss_mask: 0.8216  decode.d0.loss_dice: 0.6579  decode.d1.loss_cls: 0.0739  decode.d1.loss_mask: 0.8331  decode.d1.loss_dice: 0.6877  decode.d2.loss_cls: 0.1306  decode.d2.loss_mask: 0.8318  decode.d2.loss_dice: 0.6774  decode.d3.loss_cls: 0.0981  decode.d3.loss_mask: 0.8299  decode.d3.loss_dice: 0.6674  decode.d4.loss_cls: 0.1033  decode.d4.loss_mask: 0.8487  decode.d4.loss_dice: 0.6828  decode.d5.loss_cls: 0.0948  decode.d5.loss_mask: 0.8376  decode.d5.loss_dice: 0.6829  decode.d6.loss_cls: 0.1042  decode.d6.loss_mask: 0.8486  decode.d6.loss_dice: 0.6764  decode.d7.loss_cls: 0.1095  decode.d7.loss_mask: 0.8491  decode.d7.loss_dice: 0.6688  decode.d8.loss_cls: 0.0926  decode.d8.loss_mask: 0.8544  decode.d8.loss_dice: 0.6843
05/26 19:32:57 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 19:32:57 - mmengine - INFO - Iter(train) [ 73000/160000]  base_lr: 5.7791e-05 lr: 5.7791e-06  eta: 9:57:26  time: 0.4211  data_time: 0.0100  memory: 5974  grad_norm: 901.6726  loss: 19.7762  decode.loss_cls: 0.1352  decode.loss_mask: 1.1208  decode.loss_dice: 0.6906  decode.d0.loss_cls: 0.5851  decode.d0.loss_mask: 1.0902  decode.d0.loss_dice: 0.6661  decode.d1.loss_cls: 0.1392  decode.d1.loss_mask: 1.1229  decode.d1.loss_dice: 0.6941  decode.d2.loss_cls: 0.1395  decode.d2.loss_mask: 1.1169  decode.d2.loss_dice: 0.6849  decode.d3.loss_cls: 0.1401  decode.d3.loss_mask: 1.1295  decode.d3.loss_dice: 0.6912  decode.d4.loss_cls: 0.1097  decode.d4.loss_mask: 1.1268  decode.d4.loss_dice: 0.7036  decode.d5.loss_cls: 0.1720  decode.d5.loss_mask: 1.0858  decode.d5.loss_dice: 0.6607  decode.d6.loss_cls: 0.1419  decode.d6.loss_mask: 1.0794  decode.d6.loss_dice: 0.6871  decode.d7.loss_cls: 0.1168  decode.d7.loss_mask: 1.1277  decode.d7.loss_dice: 0.6937  decode.d8.loss_cls: 0.1209  decode.d8.loss_mask: 1.1206  decode.d8.loss_dice: 0.6831
05/26 19:33:18 - mmengine - INFO - Iter(train) [ 73050/160000]  base_lr: 5.7761e-05 lr: 5.7761e-06  eta: 9:57:06  time: 0.4142  data_time: 0.0097  memory: 5969  grad_norm: 570.7462  loss: 19.6287  decode.loss_cls: 0.2044  decode.loss_mask: 1.0499  decode.loss_dice: 0.7070  decode.d0.loss_cls: 0.6220  decode.d0.loss_mask: 0.9603  decode.d0.loss_dice: 0.6644  decode.d1.loss_cls: 0.1455  decode.d1.loss_mask: 1.0275  decode.d1.loss_dice: 0.7020  decode.d2.loss_cls: 0.1792  decode.d2.loss_mask: 1.0348  decode.d2.loss_dice: 0.7076  decode.d3.loss_cls: 0.1747  decode.d3.loss_mask: 1.0442  decode.d3.loss_dice: 0.7241  decode.d4.loss_cls: 0.1866  decode.d4.loss_mask: 1.0379  decode.d4.loss_dice: 0.7049  decode.d5.loss_cls: 0.1951  decode.d5.loss_mask: 1.0108  decode.d5.loss_dice: 0.7136  decode.d6.loss_cls: 0.2021  decode.d6.loss_mask: 1.0095  decode.d6.loss_dice: 0.7057  decode.d7.loss_cls: 0.2159  decode.d7.loss_mask: 1.0137  decode.d7.loss_dice: 0.6915  decode.d8.loss_cls: 0.1917  decode.d8.loss_mask: 1.0804  decode.d8.loss_dice: 0.7216
05/26 19:33:39 - mmengine - INFO - Iter(train) [ 73100/160000]  base_lr: 5.7731e-05 lr: 5.7731e-06  eta: 9:56:46  time: 0.4144  data_time: 0.0098  memory: 5980  grad_norm: 626.0048  loss: 19.3036  decode.loss_cls: 0.2319  decode.loss_mask: 0.9926  decode.loss_dice: 0.6599  decode.d0.loss_cls: 0.7730  decode.d0.loss_mask: 0.9126  decode.d0.loss_dice: 0.5904  decode.d1.loss_cls: 0.2134  decode.d1.loss_mask: 0.9643  decode.d1.loss_dice: 0.6623  decode.d2.loss_cls: 0.2562  decode.d2.loss_mask: 0.9623  decode.d2.loss_dice: 0.6192  decode.d3.loss_cls: 0.2256  decode.d3.loss_mask: 1.0810  decode.d3.loss_dice: 0.6342  decode.d4.loss_cls: 0.3018  decode.d4.loss_mask: 0.9803  decode.d4.loss_dice: 0.6442  decode.d5.loss_cls: 0.2930  decode.d5.loss_mask: 0.9396  decode.d5.loss_dice: 0.6230  decode.d6.loss_cls: 0.2838  decode.d6.loss_mask: 0.9619  decode.d6.loss_dice: 0.6693  decode.d7.loss_cls: 0.2759  decode.d7.loss_mask: 0.9437  decode.d7.loss_dice: 0.6528  decode.d8.loss_cls: 0.2107  decode.d8.loss_mask: 1.0808  decode.d8.loss_dice: 0.6639
05/26 19:34:00 - mmengine - INFO - Iter(train) [ 73150/160000]  base_lr: 5.7702e-05 lr: 5.7702e-06  eta: 9:56:25  time: 0.4138  data_time: 0.0098  memory: 5980  grad_norm: 537.7972  loss: 25.1892  decode.loss_cls: 0.4476  decode.loss_mask: 1.0861  decode.loss_dice: 0.9348  decode.d0.loss_cls: 0.9332  decode.d0.loss_mask: 1.0601  decode.d0.loss_dice: 0.8703  decode.d1.loss_cls: 0.4226  decode.d1.loss_mask: 1.1408  decode.d1.loss_dice: 0.9757  decode.d2.loss_cls: 0.4366  decode.d2.loss_mask: 1.0911  decode.d2.loss_dice: 0.9212  decode.d3.loss_cls: 0.4401  decode.d3.loss_mask: 1.0812  decode.d3.loss_dice: 0.9448  decode.d4.loss_cls: 0.4964  decode.d4.loss_mask: 1.1084  decode.d4.loss_dice: 0.9081  decode.d5.loss_cls: 0.4489  decode.d5.loss_mask: 1.0635  decode.d5.loss_dice: 0.9529  decode.d6.loss_cls: 0.4599  decode.d6.loss_mask: 1.1019  decode.d6.loss_dice: 0.8994  decode.d7.loss_cls: 0.4081  decode.d7.loss_mask: 1.1389  decode.d7.loss_dice: 0.9457  decode.d8.loss_cls: 0.4635  decode.d8.loss_mask: 1.0900  decode.d8.loss_dice: 0.9176
05/26 19:34:21 - mmengine - INFO - Iter(train) [ 73200/160000]  base_lr: 5.7672e-05 lr: 5.7672e-06  eta: 9:56:05  time: 0.4276  data_time: 0.0105  memory: 5986  grad_norm: 959.9793  loss: 28.0087  decode.loss_cls: 0.3190  decode.loss_mask: 1.4995  decode.loss_dice: 0.9098  decode.d0.loss_cls: 0.8190  decode.d0.loss_mask: 1.4278  decode.d0.loss_dice: 0.8971  decode.d1.loss_cls: 0.3581  decode.d1.loss_mask: 1.4999  decode.d1.loss_dice: 0.9206  decode.d2.loss_cls: 0.2804  decode.d2.loss_mask: 1.5364  decode.d2.loss_dice: 0.9220  decode.d3.loss_cls: 0.2934  decode.d3.loss_mask: 1.4935  decode.d3.loss_dice: 0.9474  decode.d4.loss_cls: 0.3093  decode.d4.loss_mask: 1.4913  decode.d4.loss_dice: 0.9308  decode.d5.loss_cls: 0.3963  decode.d5.loss_mask: 1.4394  decode.d5.loss_dice: 0.9029  decode.d6.loss_cls: 0.3709  decode.d6.loss_mask: 1.4958  decode.d6.loss_dice: 0.9526  decode.d7.loss_cls: 0.3685  decode.d7.loss_mask: 1.4812  decode.d7.loss_dice: 0.9415  decode.d8.loss_cls: 0.3748  decode.d8.loss_mask: 1.5079  decode.d8.loss_dice: 0.9212
05/26 19:34:41 - mmengine - INFO - Iter(train) [ 73250/160000]  base_lr: 5.7642e-05 lr: 5.7642e-06  eta: 9:55:45  time: 0.4178  data_time: 0.0098  memory: 5977  grad_norm: 489.6244  loss: 23.2581  decode.loss_cls: 0.2231  decode.loss_mask: 1.2760  decode.loss_dice: 0.8062  decode.d0.loss_cls: 0.7116  decode.d0.loss_mask: 1.1906  decode.d0.loss_dice: 0.8208  decode.d1.loss_cls: 0.2675  decode.d1.loss_mask: 1.2042  decode.d1.loss_dice: 0.8298  decode.d2.loss_cls: 0.2906  decode.d2.loss_mask: 1.1775  decode.d2.loss_dice: 0.8135  decode.d3.loss_cls: 0.3096  decode.d3.loss_mask: 1.1860  decode.d3.loss_dice: 0.7979  decode.d4.loss_cls: 0.2602  decode.d4.loss_mask: 1.2386  decode.d4.loss_dice: 0.8341  decode.d5.loss_cls: 0.2707  decode.d5.loss_mask: 1.1901  decode.d5.loss_dice: 0.8073  decode.d6.loss_cls: 0.2463  decode.d6.loss_mask: 1.1670  decode.d6.loss_dice: 0.8078  decode.d7.loss_cls: 0.2320  decode.d7.loss_mask: 1.1909  decode.d7.loss_dice: 0.8162  decode.d8.loss_cls: 0.2589  decode.d8.loss_mask: 1.2119  decode.d8.loss_dice: 0.8211
05/26 19:35:02 - mmengine - INFO - Iter(train) [ 73300/160000]  base_lr: 5.7612e-05 lr: 5.7612e-06  eta: 9:55:24  time: 0.4125  data_time: 0.0099  memory: 5970  grad_norm: 662.9064  loss: 26.9494  decode.loss_cls: 0.2530  decode.loss_mask: 1.4446  decode.loss_dice: 0.9053  decode.d0.loss_cls: 0.8100  decode.d0.loss_mask: 1.3608  decode.d0.loss_dice: 0.9409  decode.d1.loss_cls: 0.2922  decode.d1.loss_mask: 1.4574  decode.d1.loss_dice: 0.9023  decode.d2.loss_cls: 0.3249  decode.d2.loss_mask: 1.4360  decode.d2.loss_dice: 0.9084  decode.d3.loss_cls: 0.3004  decode.d3.loss_mask: 1.5146  decode.d3.loss_dice: 0.9554  decode.d4.loss_cls: 0.3046  decode.d4.loss_mask: 1.3913  decode.d4.loss_dice: 0.8673  decode.d5.loss_cls: 0.2859  decode.d5.loss_mask: 1.4476  decode.d5.loss_dice: 0.9182  decode.d6.loss_cls: 0.2849  decode.d6.loss_mask: 1.4392  decode.d6.loss_dice: 0.9104  decode.d7.loss_cls: 0.2740  decode.d7.loss_mask: 1.4739  decode.d7.loss_dice: 0.9205  decode.d8.loss_cls: 0.2664  decode.d8.loss_mask: 1.4529  decode.d8.loss_dice: 0.9058
05/26 19:35:23 - mmengine - INFO - Iter(train) [ 73350/160000]  base_lr: 5.7582e-05 lr: 5.7582e-06  eta: 9:55:04  time: 0.4117  data_time: 0.0096  memory: 5975  grad_norm: 739.5394  loss: 22.6896  decode.loss_cls: 0.2069  decode.loss_mask: 1.1719  decode.loss_dice: 0.8374  decode.d0.loss_cls: 0.9126  decode.d0.loss_mask: 1.1075  decode.d0.loss_dice: 0.7604  decode.d1.loss_cls: 0.2549  decode.d1.loss_mask: 1.1498  decode.d1.loss_dice: 0.8222  decode.d2.loss_cls: 0.1852  decode.d2.loss_mask: 1.1666  decode.d2.loss_dice: 0.8138  decode.d3.loss_cls: 0.1800  decode.d3.loss_mask: 1.1632  decode.d3.loss_dice: 0.8122  decode.d4.loss_cls: 0.2291  decode.d4.loss_mask: 1.2102  decode.d4.loss_dice: 0.8429  decode.d5.loss_cls: 0.1757  decode.d5.loss_mask: 1.2071  decode.d5.loss_dice: 0.8374  decode.d6.loss_cls: 0.2140  decode.d6.loss_mask: 1.1876  decode.d6.loss_dice: 0.8087  decode.d7.loss_cls: 0.2086  decode.d7.loss_mask: 1.2046  decode.d7.loss_dice: 0.8201  decode.d8.loss_cls: 0.2266  decode.d8.loss_mask: 1.1794  decode.d8.loss_dice: 0.7928
05/26 19:35:43 - mmengine - INFO - Iter(train) [ 73400/160000]  base_lr: 5.7552e-05 lr: 5.7552e-06  eta: 9:54:43  time: 0.4179  data_time: 0.0099  memory: 5967  grad_norm: 520.2604  loss: 20.3590  decode.loss_cls: 0.2216  decode.loss_mask: 1.0546  decode.loss_dice: 0.7154  decode.d0.loss_cls: 0.7358  decode.d0.loss_mask: 1.0414  decode.d0.loss_dice: 0.7097  decode.d1.loss_cls: 0.2296  decode.d1.loss_mask: 1.0638  decode.d1.loss_dice: 0.7082  decode.d2.loss_cls: 0.2171  decode.d2.loss_mask: 1.0458  decode.d2.loss_dice: 0.6829  decode.d3.loss_cls: 0.2175  decode.d3.loss_mask: 1.0513  decode.d3.loss_dice: 0.6921  decode.d4.loss_cls: 0.2691  decode.d4.loss_mask: 1.0567  decode.d4.loss_dice: 0.7067  decode.d5.loss_cls: 0.2403  decode.d5.loss_mask: 1.0581  decode.d5.loss_dice: 0.6965  decode.d6.loss_cls: 0.2583  decode.d6.loss_mask: 1.0641  decode.d6.loss_dice: 0.6887  decode.d7.loss_cls: 0.2345  decode.d7.loss_mask: 1.0488  decode.d7.loss_dice: 0.6864  decode.d8.loss_cls: 0.1939  decode.d8.loss_mask: 1.0818  decode.d8.loss_dice: 0.6884
05/26 19:36:04 - mmengine - INFO - Iter(train) [ 73450/160000]  base_lr: 5.7522e-05 lr: 5.7522e-06  eta: 9:54:23  time: 0.4139  data_time: 0.0097  memory: 5983  grad_norm: 477.2289  loss: 18.9382  decode.loss_cls: 0.1869  decode.loss_mask: 0.9836  decode.loss_dice: 0.6925  decode.d0.loss_cls: 0.5585  decode.d0.loss_mask: 0.9932  decode.d0.loss_dice: 0.6736  decode.d1.loss_cls: 0.2080  decode.d1.loss_mask: 0.9883  decode.d1.loss_dice: 0.6888  decode.d2.loss_cls: 0.1688  decode.d2.loss_mask: 0.9850  decode.d2.loss_dice: 0.6731  decode.d3.loss_cls: 0.1377  decode.d3.loss_mask: 1.0014  decode.d3.loss_dice: 0.6861  decode.d4.loss_cls: 0.1637  decode.d4.loss_mask: 1.0162  decode.d4.loss_dice: 0.6781  decode.d5.loss_cls: 0.1975  decode.d5.loss_mask: 1.0323  decode.d5.loss_dice: 0.6888  decode.d6.loss_cls: 0.1463  decode.d6.loss_mask: 0.9881  decode.d6.loss_dice: 0.6654  decode.d7.loss_cls: 0.1746  decode.d7.loss_mask: 1.0082  decode.d7.loss_dice: 0.6953  decode.d8.loss_cls: 0.1838  decode.d8.loss_mask: 0.9987  decode.d8.loss_dice: 0.6754
05/26 19:36:25 - mmengine - INFO - Iter(train) [ 73500/160000]  base_lr: 5.7492e-05 lr: 5.7492e-06  eta: 9:54:02  time: 0.4115  data_time: 0.0097  memory: 5974  grad_norm: 354.3609  loss: 21.6698  decode.loss_cls: 0.1733  decode.loss_mask: 1.1196  decode.loss_dice: 0.8156  decode.d0.loss_cls: 0.5833  decode.d0.loss_mask: 1.1118  decode.d0.loss_dice: 0.8034  decode.d1.loss_cls: 0.1850  decode.d1.loss_mask: 1.1397  decode.d1.loss_dice: 0.8043  decode.d2.loss_cls: 0.1942  decode.d2.loss_mask: 1.1487  decode.d2.loss_dice: 0.8238  decode.d3.loss_cls: 0.1933  decode.d3.loss_mask: 1.1449  decode.d3.loss_dice: 0.8255  decode.d4.loss_cls: 0.1958  decode.d4.loss_mask: 1.1267  decode.d4.loss_dice: 0.8163  decode.d5.loss_cls: 0.1190  decode.d5.loss_mask: 1.1598  decode.d5.loss_dice: 0.8337  decode.d6.loss_cls: 0.1697  decode.d6.loss_mask: 1.1551  decode.d6.loss_dice: 0.8076  decode.d7.loss_cls: 0.1570  decode.d7.loss_mask: 1.1690  decode.d7.loss_dice: 0.8114  decode.d8.loss_cls: 0.1661  decode.d8.loss_mask: 1.1083  decode.d8.loss_dice: 0.8082
05/26 19:36:46 - mmengine - INFO - Iter(train) [ 73550/160000]  base_lr: 5.7462e-05 lr: 5.7462e-06  eta: 9:53:42  time: 0.4130  data_time: 0.0098  memory: 5975  grad_norm: 625.4504  loss: 22.6127  decode.loss_cls: 0.2612  decode.loss_mask: 1.1509  decode.loss_dice: 0.8275  decode.d0.loss_cls: 0.8072  decode.d0.loss_mask: 1.0693  decode.d0.loss_dice: 0.7947  decode.d1.loss_cls: 0.2834  decode.d1.loss_mask: 1.1566  decode.d1.loss_dice: 0.8226  decode.d2.loss_cls: 0.3084  decode.d2.loss_mask: 1.1147  decode.d2.loss_dice: 0.7950  decode.d3.loss_cls: 0.2999  decode.d3.loss_mask: 1.1158  decode.d3.loss_dice: 0.7912  decode.d4.loss_cls: 0.2912  decode.d4.loss_mask: 1.1090  decode.d4.loss_dice: 0.8019  decode.d5.loss_cls: 0.2819  decode.d5.loss_mask: 1.0988  decode.d5.loss_dice: 0.7874  decode.d6.loss_cls: 0.2670  decode.d6.loss_mask: 1.1086  decode.d6.loss_dice: 0.7955  decode.d7.loss_cls: 0.3166  decode.d7.loss_mask: 1.1204  decode.d7.loss_dice: 0.7971  decode.d8.loss_cls: 0.3072  decode.d8.loss_mask: 1.1138  decode.d8.loss_dice: 0.8179
05/26 19:37:06 - mmengine - INFO - Iter(train) [ 73600/160000]  base_lr: 5.7432e-05 lr: 5.7432e-06  eta: 9:53:21  time: 0.4126  data_time: 0.0097  memory: 5982  grad_norm: 546.9634  loss: 21.3827  decode.loss_cls: 0.1452  decode.loss_mask: 1.1633  decode.loss_dice: 0.7875  decode.d0.loss_cls: 0.6813  decode.d0.loss_mask: 1.0618  decode.d0.loss_dice: 0.7437  decode.d1.loss_cls: 0.2163  decode.d1.loss_mask: 1.1353  decode.d1.loss_dice: 0.7438  decode.d2.loss_cls: 0.1832  decode.d2.loss_mask: 1.1411  decode.d2.loss_dice: 0.7542  decode.d3.loss_cls: 0.1559  decode.d3.loss_mask: 1.1754  decode.d3.loss_dice: 0.7939  decode.d4.loss_cls: 0.1756  decode.d4.loss_mask: 1.1629  decode.d4.loss_dice: 0.7541  decode.d5.loss_cls: 0.1633  decode.d5.loss_mask: 1.1564  decode.d5.loss_dice: 0.7835  decode.d6.loss_cls: 0.1823  decode.d6.loss_mask: 1.1765  decode.d6.loss_dice: 0.7735  decode.d7.loss_cls: 0.1729  decode.d7.loss_mask: 1.1582  decode.d7.loss_dice: 0.7698  decode.d8.loss_cls: 0.1453  decode.d8.loss_mask: 1.1662  decode.d8.loss_dice: 0.7603
05/26 19:37:27 - mmengine - INFO - Iter(train) [ 73650/160000]  base_lr: 5.7402e-05 lr: 5.7402e-06  eta: 9:53:01  time: 0.4156  data_time: 0.0098  memory: 5966  grad_norm: 557.2090  loss: 20.8328  decode.loss_cls: 0.1455  decode.loss_mask: 1.1889  decode.loss_dice: 0.6865  decode.d0.loss_cls: 0.5862  decode.d0.loss_mask: 1.1494  decode.d0.loss_dice: 0.6889  decode.d1.loss_cls: 0.1732  decode.d1.loss_mask: 1.1743  decode.d1.loss_dice: 0.6822  decode.d2.loss_cls: 0.1637  decode.d2.loss_mask: 1.1802  decode.d2.loss_dice: 0.6780  decode.d3.loss_cls: 0.1978  decode.d3.loss_mask: 1.1672  decode.d3.loss_dice: 0.6724  decode.d4.loss_cls: 0.2059  decode.d4.loss_mask: 1.1889  decode.d4.loss_dice: 0.6981  decode.d5.loss_cls: 0.2074  decode.d5.loss_mask: 1.1783  decode.d5.loss_dice: 0.7071  decode.d6.loss_cls: 0.1807  decode.d6.loss_mask: 1.1667  decode.d6.loss_dice: 0.6819  decode.d7.loss_cls: 0.2240  decode.d7.loss_mask: 1.1566  decode.d7.loss_dice: 0.6845  decode.d8.loss_cls: 0.1711  decode.d8.loss_mask: 1.1726  decode.d8.loss_dice: 0.6745
05/26 19:37:48 - mmengine - INFO - Iter(train) [ 73700/160000]  base_lr: 5.7373e-05 lr: 5.7373e-06  eta: 9:52:41  time: 0.4126  data_time: 0.0096  memory: 5971  grad_norm: 409.2758  loss: 16.0649  decode.loss_cls: 0.1127  decode.loss_mask: 0.8620  decode.loss_dice: 0.5997  decode.d0.loss_cls: 0.5438  decode.d0.loss_mask: 0.8413  decode.d0.loss_dice: 0.5736  decode.d1.loss_cls: 0.1431  decode.d1.loss_mask: 0.8253  decode.d1.loss_dice: 0.5767  decode.d2.loss_cls: 0.1104  decode.d2.loss_mask: 0.8595  decode.d2.loss_dice: 0.6032  decode.d3.loss_cls: 0.1266  decode.d3.loss_mask: 0.8237  decode.d3.loss_dice: 0.5823  decode.d4.loss_cls: 0.1291  decode.d4.loss_mask: 0.8591  decode.d4.loss_dice: 0.5923  decode.d5.loss_cls: 0.1481  decode.d5.loss_mask: 0.8291  decode.d5.loss_dice: 0.5926  decode.d6.loss_cls: 0.1835  decode.d6.loss_mask: 0.8420  decode.d6.loss_dice: 0.5901  decode.d7.loss_cls: 0.1551  decode.d7.loss_mask: 0.8329  decode.d7.loss_dice: 0.5669  decode.d8.loss_cls: 0.1117  decode.d8.loss_mask: 0.8520  decode.d8.loss_dice: 0.5969
05/26 19:38:09 - mmengine - INFO - Iter(train) [ 73750/160000]  base_lr: 5.7343e-05 lr: 5.7343e-06  eta: 9:52:20  time: 0.4133  data_time: 0.0097  memory: 5974  grad_norm: 662.1097  loss: 24.5607  decode.loss_cls: 0.4229  decode.loss_mask: 1.1298  decode.loss_dice: 0.8828  decode.d0.loss_cls: 0.9403  decode.d0.loss_mask: 1.0526  decode.d0.loss_dice: 0.8227  decode.d1.loss_cls: 0.3688  decode.d1.loss_mask: 1.1182  decode.d1.loss_dice: 0.8457  decode.d2.loss_cls: 0.3778  decode.d2.loss_mask: 1.1238  decode.d2.loss_dice: 0.8637  decode.d3.loss_cls: 0.3209  decode.d3.loss_mask: 1.1686  decode.d3.loss_dice: 0.9017  decode.d4.loss_cls: 0.4254  decode.d4.loss_mask: 1.1400  decode.d4.loss_dice: 0.8724  decode.d5.loss_cls: 0.4151  decode.d5.loss_mask: 1.1839  decode.d5.loss_dice: 0.8942  decode.d6.loss_cls: 0.4084  decode.d6.loss_mask: 1.1653  decode.d6.loss_dice: 0.8725  decode.d7.loss_cls: 0.3936  decode.d7.loss_mask: 1.1393  decode.d7.loss_dice: 0.8843  decode.d8.loss_cls: 0.4044  decode.d8.loss_mask: 1.1337  decode.d8.loss_dice: 0.8879
05/26 19:38:29 - mmengine - INFO - Iter(train) [ 73800/160000]  base_lr: 5.7313e-05 lr: 5.7313e-06  eta: 9:51:59  time: 0.4120  data_time: 0.0101  memory: 5981  grad_norm: 1024.3626  loss: 26.5022  decode.loss_cls: 0.3125  decode.loss_mask: 1.3715  decode.loss_dice: 0.8554  decode.d0.loss_cls: 0.8618  decode.d0.loss_mask: 1.2833  decode.d0.loss_dice: 0.8556  decode.d1.loss_cls: 0.3482  decode.d1.loss_mask: 1.3756  decode.d1.loss_dice: 0.8707  decode.d2.loss_cls: 0.3043  decode.d2.loss_mask: 1.3970  decode.d2.loss_dice: 0.8764  decode.d3.loss_cls: 0.3886  decode.d3.loss_mask: 1.4526  decode.d3.loss_dice: 0.8690  decode.d4.loss_cls: 0.3426  decode.d4.loss_mask: 1.4170  decode.d4.loss_dice: 0.8903  decode.d5.loss_cls: 0.3255  decode.d5.loss_mask: 1.3644  decode.d5.loss_dice: 0.8829  decode.d6.loss_cls: 0.2876  decode.d6.loss_mask: 1.5320  decode.d6.loss_dice: 0.8869  decode.d7.loss_cls: 0.3320  decode.d7.loss_mask: 1.3683  decode.d7.loss_dice: 0.8622  decode.d8.loss_cls: 0.3158  decode.d8.loss_mask: 1.4039  decode.d8.loss_dice: 0.8682
05/26 19:38:50 - mmengine - INFO - Iter(train) [ 73850/160000]  base_lr: 5.7283e-05 lr: 5.7283e-06  eta: 9:51:39  time: 0.4114  data_time: 0.0096  memory: 5969  grad_norm: 787.9591  loss: 24.2617  decode.loss_cls: 0.1876  decode.loss_mask: 1.2591  decode.loss_dice: 0.9642  decode.d0.loss_cls: 0.7052  decode.d0.loss_mask: 1.2230  decode.d0.loss_dice: 0.9434  decode.d1.loss_cls: 0.1861  decode.d1.loss_mask: 1.2273  decode.d1.loss_dice: 0.9641  decode.d2.loss_cls: 0.1857  decode.d2.loss_mask: 1.2581  decode.d2.loss_dice: 0.9751  decode.d3.loss_cls: 0.1804  decode.d3.loss_mask: 1.2246  decode.d3.loss_dice: 0.9523  decode.d4.loss_cls: 0.1678  decode.d4.loss_mask: 1.2335  decode.d4.loss_dice: 0.9644  decode.d5.loss_cls: 0.1618  decode.d5.loss_mask: 1.2742  decode.d5.loss_dice: 0.9563  decode.d6.loss_cls: 0.1766  decode.d6.loss_mask: 1.2415  decode.d6.loss_dice: 0.9431  decode.d7.loss_cls: 0.1710  decode.d7.loss_mask: 1.2343  decode.d7.loss_dice: 0.9558  decode.d8.loss_cls: 0.1892  decode.d8.loss_mask: 1.2153  decode.d8.loss_dice: 0.9405
05/26 19:39:10 - mmengine - INFO - Iter(train) [ 73900/160000]  base_lr: 5.7253e-05 lr: 5.7253e-06  eta: 9:51:18  time: 0.4129  data_time: 0.0096  memory: 5967  grad_norm: 539.6240  loss: 19.8094  decode.loss_cls: 0.2054  decode.loss_mask: 1.0634  decode.loss_dice: 0.6779  decode.d0.loss_cls: 0.7424  decode.d0.loss_mask: 1.0054  decode.d0.loss_dice: 0.6563  decode.d1.loss_cls: 0.2133  decode.d1.loss_mask: 1.0602  decode.d1.loss_dice: 0.6967  decode.d2.loss_cls: 0.2487  decode.d2.loss_mask: 1.0144  decode.d2.loss_dice: 0.6719  decode.d3.loss_cls: 0.1849  decode.d3.loss_mask: 1.0468  decode.d3.loss_dice: 0.7061  decode.d4.loss_cls: 0.1933  decode.d4.loss_mask: 1.0115  decode.d4.loss_dice: 0.6571  decode.d5.loss_cls: 0.1785  decode.d5.loss_mask: 1.0554  decode.d5.loss_dice: 0.6919  decode.d6.loss_cls: 0.2095  decode.d6.loss_mask: 1.0531  decode.d6.loss_dice: 0.6743  decode.d7.loss_cls: 0.1915  decode.d7.loss_mask: 1.0632  decode.d7.loss_dice: 0.7150  decode.d8.loss_cls: 0.1899  decode.d8.loss_mask: 1.0491  decode.d8.loss_dice: 0.6824
05/26 19:39:31 - mmengine - INFO - Iter(train) [ 73950/160000]  base_lr: 5.7223e-05 lr: 5.7223e-06  eta: 9:50:57  time: 0.4110  data_time: 0.0096  memory: 5965  grad_norm: 271.1429  loss: 16.2280  decode.loss_cls: 0.1697  decode.loss_mask: 0.8156  decode.loss_dice: 0.6145  decode.d0.loss_cls: 0.5490  decode.d0.loss_mask: 0.7662  decode.d0.loss_dice: 0.5907  decode.d1.loss_cls: 0.1439  decode.d1.loss_mask: 0.8549  decode.d1.loss_dice: 0.5969  decode.d2.loss_cls: 0.1654  decode.d2.loss_mask: 0.8490  decode.d2.loss_dice: 0.6177  decode.d3.loss_cls: 0.1917  decode.d3.loss_mask: 0.7761  decode.d3.loss_dice: 0.5720  decode.d4.loss_cls: 0.1742  decode.d4.loss_mask: 0.8393  decode.d4.loss_dice: 0.6209  decode.d5.loss_cls: 0.1798  decode.d5.loss_mask: 0.8194  decode.d5.loss_dice: 0.6152  decode.d6.loss_cls: 0.1446  decode.d6.loss_mask: 0.8043  decode.d6.loss_dice: 0.6092  decode.d7.loss_cls: 0.1650  decode.d7.loss_mask: 0.8002  decode.d7.loss_dice: 0.6027  decode.d8.loss_cls: 0.1809  decode.d8.loss_mask: 0.8018  decode.d8.loss_dice: 0.5971
05/26 19:39:52 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 19:39:52 - mmengine - INFO - Iter(train) [ 74000/160000]  base_lr: 5.7193e-05 lr: 5.7193e-06  eta: 9:50:37  time: 0.4120  data_time: 0.0097  memory: 5972  grad_norm: 942.1929  loss: 25.4842  decode.loss_cls: 0.2913  decode.loss_mask: 1.4098  decode.loss_dice: 0.8040  decode.d0.loss_cls: 0.8046  decode.d0.loss_mask: 1.3004  decode.d0.loss_dice: 0.8116  decode.d1.loss_cls: 0.3374  decode.d1.loss_mask: 1.4325  decode.d1.loss_dice: 0.8130  decode.d2.loss_cls: 0.3298  decode.d2.loss_mask: 1.3736  decode.d2.loss_dice: 0.8135  decode.d3.loss_cls: 0.2734  decode.d3.loss_mask: 1.3985  decode.d3.loss_dice: 0.8183  decode.d4.loss_cls: 0.3181  decode.d4.loss_mask: 1.3587  decode.d4.loss_dice: 0.8015  decode.d5.loss_cls: 0.2683  decode.d5.loss_mask: 1.4202  decode.d5.loss_dice: 0.8071  decode.d6.loss_cls: 0.2904  decode.d6.loss_mask: 1.3964  decode.d6.loss_dice: 0.8134  decode.d7.loss_cls: 0.2520  decode.d7.loss_mask: 1.4333  decode.d7.loss_dice: 0.8201  decode.d8.loss_cls: 0.2623  decode.d8.loss_mask: 1.4247  decode.d8.loss_dice: 0.8062
05/26 19:40:12 - mmengine - INFO - Iter(train) [ 74050/160000]  base_lr: 5.7163e-05 lr: 5.7163e-06  eta: 9:50:16  time: 0.4119  data_time: 0.0096  memory: 5969  grad_norm: 497.8650  loss: 21.1394  decode.loss_cls: 0.2128  decode.loss_mask: 1.0122  decode.loss_dice: 0.8078  decode.d0.loss_cls: 0.6857  decode.d0.loss_mask: 1.0488  decode.d0.loss_dice: 0.7665  decode.d1.loss_cls: 0.2100  decode.d1.loss_mask: 1.0538  decode.d1.loss_dice: 0.7909  decode.d2.loss_cls: 0.2240  decode.d2.loss_mask: 1.0428  decode.d2.loss_dice: 0.8164  decode.d3.loss_cls: 0.2224  decode.d3.loss_mask: 1.0530  decode.d3.loss_dice: 0.8070  decode.d4.loss_cls: 0.2450  decode.d4.loss_mask: 1.0176  decode.d4.loss_dice: 0.7724  decode.d5.loss_cls: 0.2337  decode.d5.loss_mask: 1.0285  decode.d5.loss_dice: 0.7812  decode.d6.loss_cls: 0.2132  decode.d6.loss_mask: 1.0657  decode.d6.loss_dice: 0.7863  decode.d7.loss_cls: 0.2159  decode.d7.loss_mask: 1.0826  decode.d7.loss_dice: 0.8124  decode.d8.loss_cls: 0.2369  decode.d8.loss_mask: 1.0702  decode.d8.loss_dice: 0.8238
05/26 19:40:33 - mmengine - INFO - Iter(train) [ 74100/160000]  base_lr: 5.7133e-05 lr: 5.7133e-06  eta: 9:49:56  time: 0.4118  data_time: 0.0096  memory: 5971  grad_norm: 600.3858  loss: 25.0443  decode.loss_cls: 0.3070  decode.loss_mask: 1.2639  decode.loss_dice: 0.8565  decode.d0.loss_cls: 0.8289  decode.d0.loss_mask: 1.1959  decode.d0.loss_dice: 0.8301  decode.d1.loss_cls: 0.3010  decode.d1.loss_mask: 1.2556  decode.d1.loss_dice: 0.8524  decode.d2.loss_cls: 0.3121  decode.d2.loss_mask: 1.3048  decode.d2.loss_dice: 0.8522  decode.d3.loss_cls: 0.3635  decode.d3.loss_mask: 1.2590  decode.d3.loss_dice: 0.8503  decode.d4.loss_cls: 0.3889  decode.d4.loss_mask: 1.2616  decode.d4.loss_dice: 0.8889  decode.d5.loss_cls: 0.3485  decode.d5.loss_mask: 1.3089  decode.d5.loss_dice: 0.8629  decode.d6.loss_cls: 0.3238  decode.d6.loss_mask: 1.2887  decode.d6.loss_dice: 0.8684  decode.d7.loss_cls: 0.3255  decode.d7.loss_mask: 1.2647  decode.d7.loss_dice: 0.8465  decode.d8.loss_cls: 0.3039  decode.d8.loss_mask: 1.2876  decode.d8.loss_dice: 0.8423
05/26 19:40:54 - mmengine - INFO - Iter(train) [ 74150/160000]  base_lr: 5.7103e-05 lr: 5.7103e-06  eta: 9:49:35  time: 0.4120  data_time: 0.0097  memory: 5968  grad_norm: 577.0592  loss: 21.5021  decode.loss_cls: 0.2063  decode.loss_mask: 1.0531  decode.loss_dice: 0.8254  decode.d0.loss_cls: 0.6728  decode.d0.loss_mask: 0.9956  decode.d0.loss_dice: 0.7859  decode.d1.loss_cls: 0.2107  decode.d1.loss_mask: 1.0587  decode.d1.loss_dice: 0.8474  decode.d2.loss_cls: 0.2254  decode.d2.loss_mask: 1.0694  decode.d2.loss_dice: 0.8506  decode.d3.loss_cls: 0.2394  decode.d3.loss_mask: 1.0518  decode.d3.loss_dice: 0.8231  decode.d4.loss_cls: 0.2337  decode.d4.loss_mask: 1.0483  decode.d4.loss_dice: 0.8184  decode.d5.loss_cls: 0.2047  decode.d5.loss_mask: 1.0843  decode.d5.loss_dice: 0.8386  decode.d6.loss_cls: 0.1845  decode.d6.loss_mask: 1.1069  decode.d6.loss_dice: 0.8565  decode.d7.loss_cls: 0.2095  decode.d7.loss_mask: 1.0854  decode.d7.loss_dice: 0.8342  decode.d8.loss_cls: 0.2221  decode.d8.loss_mask: 1.0433  decode.d8.loss_dice: 0.8161
05/26 19:41:14 - mmengine - INFO - Iter(train) [ 74200/160000]  base_lr: 5.7073e-05 lr: 5.7073e-06  eta: 9:49:14  time: 0.4111  data_time: 0.0097  memory: 5969  grad_norm: 439.6436  loss: 17.2687  decode.loss_cls: 0.1245  decode.loss_mask: 0.8867  decode.loss_dice: 0.6087  decode.d0.loss_cls: 0.6618  decode.d0.loss_mask: 0.8896  decode.d0.loss_dice: 0.6037  decode.d1.loss_cls: 0.1674  decode.d1.loss_mask: 0.8905  decode.d1.loss_dice: 0.6186  decode.d2.loss_cls: 0.1846  decode.d2.loss_mask: 0.8781  decode.d2.loss_dice: 0.6019  decode.d3.loss_cls: 0.1798  decode.d3.loss_mask: 0.8665  decode.d3.loss_dice: 0.6193  decode.d4.loss_cls: 0.1685  decode.d4.loss_mask: 0.8930  decode.d4.loss_dice: 0.6299  decode.d5.loss_cls: 0.1579  decode.d5.loss_mask: 0.9490  decode.d5.loss_dice: 0.6362  decode.d6.loss_cls: 0.1365  decode.d6.loss_mask: 0.9673  decode.d6.loss_dice: 0.6434  decode.d7.loss_cls: 0.1395  decode.d7.loss_mask: 0.8920  decode.d7.loss_dice: 0.6252  decode.d8.loss_cls: 0.1310  decode.d8.loss_mask: 0.8828  decode.d8.loss_dice: 0.6350
05/26 19:41:35 - mmengine - INFO - Iter(train) [ 74250/160000]  base_lr: 5.7043e-05 lr: 5.7043e-06  eta: 9:48:54  time: 0.4112  data_time: 0.0097  memory: 5969  grad_norm: 962.5792  loss: 23.9192  decode.loss_cls: 0.2027  decode.loss_mask: 1.2487  decode.loss_dice: 0.8462  decode.d0.loss_cls: 0.7384  decode.d0.loss_mask: 1.2239  decode.d0.loss_dice: 0.8266  decode.d1.loss_cls: 0.2045  decode.d1.loss_mask: 1.2678  decode.d1.loss_dice: 0.9224  decode.d2.loss_cls: 0.2215  decode.d2.loss_mask: 1.2496  decode.d2.loss_dice: 0.8796  decode.d3.loss_cls: 0.2001  decode.d3.loss_mask: 1.2798  decode.d3.loss_dice: 0.8621  decode.d4.loss_cls: 0.2097  decode.d4.loss_mask: 1.3200  decode.d4.loss_dice: 0.8602  decode.d5.loss_cls: 0.1936  decode.d5.loss_mask: 1.3458  decode.d5.loss_dice: 0.8349  decode.d6.loss_cls: 0.2366  decode.d6.loss_mask: 1.2518  decode.d6.loss_dice: 0.8376  decode.d7.loss_cls: 0.1978  decode.d7.loss_mask: 1.2365  decode.d7.loss_dice: 0.8673  decode.d8.loss_cls: 0.2272  decode.d8.loss_mask: 1.2629  decode.d8.loss_dice: 0.8635
05/26 19:41:55 - mmengine - INFO - Iter(train) [ 74300/160000]  base_lr: 5.7013e-05 lr: 5.7013e-06  eta: 9:48:33  time: 0.4100  data_time: 0.0096  memory: 5969  grad_norm: 920.3811  loss: 25.0514  decode.loss_cls: 0.3241  decode.loss_mask: 1.1112  decode.loss_dice: 1.0195  decode.d0.loss_cls: 0.7768  decode.d0.loss_mask: 1.0894  decode.d0.loss_dice: 0.9875  decode.d1.loss_cls: 0.3454  decode.d1.loss_mask: 1.1629  decode.d1.loss_dice: 1.0234  decode.d2.loss_cls: 0.3226  decode.d2.loss_mask: 1.1354  decode.d2.loss_dice: 1.0147  decode.d3.loss_cls: 0.2950  decode.d3.loss_mask: 1.1203  decode.d3.loss_dice: 1.0130  decode.d4.loss_cls: 0.3155  decode.d4.loss_mask: 1.1411  decode.d4.loss_dice: 1.0387  decode.d5.loss_cls: 0.2984  decode.d5.loss_mask: 1.1201  decode.d5.loss_dice: 1.0178  decode.d6.loss_cls: 0.3279  decode.d6.loss_mask: 1.1204  decode.d6.loss_dice: 1.0018  decode.d7.loss_cls: 0.3036  decode.d7.loss_mask: 1.1363  decode.d7.loss_dice: 1.0364  decode.d8.loss_cls: 0.2887  decode.d8.loss_mask: 1.1377  decode.d8.loss_dice: 1.0258
05/26 19:42:16 - mmengine - INFO - Iter(train) [ 74350/160000]  base_lr: 5.6983e-05 lr: 5.6983e-06  eta: 9:48:13  time: 0.4108  data_time: 0.0095  memory: 5968  grad_norm: 483.6819  loss: 22.0349  decode.loss_cls: 0.2141  decode.loss_mask: 1.1297  decode.loss_dice: 0.8233  decode.d0.loss_cls: 0.6145  decode.d0.loss_mask: 1.1464  decode.d0.loss_dice: 0.7985  decode.d1.loss_cls: 0.2340  decode.d1.loss_mask: 1.1725  decode.d1.loss_dice: 0.8400  decode.d2.loss_cls: 0.1693  decode.d2.loss_mask: 1.1265  decode.d2.loss_dice: 0.8015  decode.d3.loss_cls: 0.1985  decode.d3.loss_mask: 1.1297  decode.d3.loss_dice: 0.8206  decode.d4.loss_cls: 0.1656  decode.d4.loss_mask: 1.1694  decode.d4.loss_dice: 0.8301  decode.d5.loss_cls: 0.1974  decode.d5.loss_mask: 1.1603  decode.d5.loss_dice: 0.8152  decode.d6.loss_cls: 0.1930  decode.d6.loss_mask: 1.1662  decode.d6.loss_dice: 0.8259  decode.d7.loss_cls: 0.1682  decode.d7.loss_mask: 1.1528  decode.d7.loss_dice: 0.8168  decode.d8.loss_cls: 0.1661  decode.d8.loss_mask: 1.1729  decode.d8.loss_dice: 0.8157
05/26 19:42:37 - mmengine - INFO - Iter(train) [ 74400/160000]  base_lr: 5.6954e-05 lr: 5.6954e-06  eta: 9:47:52  time: 0.4120  data_time: 0.0096  memory: 5984  grad_norm: 506.0118  loss: 22.8179  decode.loss_cls: 0.2973  decode.loss_mask: 1.0068  decode.loss_dice: 0.8706  decode.d0.loss_cls: 0.8180  decode.d0.loss_mask: 1.0201  decode.d0.loss_dice: 0.8745  decode.d1.loss_cls: 0.2422  decode.d1.loss_mask: 1.0716  decode.d1.loss_dice: 0.8960  decode.d2.loss_cls: 0.3080  decode.d2.loss_mask: 1.0718  decode.d2.loss_dice: 0.8695  decode.d3.loss_cls: 0.2565  decode.d3.loss_mask: 1.0674  decode.d3.loss_dice: 0.9236  decode.d4.loss_cls: 0.2716  decode.d4.loss_mask: 1.0612  decode.d4.loss_dice: 0.9013  decode.d5.loss_cls: 0.2976  decode.d5.loss_mask: 1.0659  decode.d5.loss_dice: 0.8932  decode.d6.loss_cls: 0.2933  decode.d6.loss_mask: 1.0562  decode.d6.loss_dice: 0.8827  decode.d7.loss_cls: 0.2896  decode.d7.loss_mask: 1.0494  decode.d7.loss_dice: 0.8989  decode.d8.loss_cls: 0.2884  decode.d8.loss_mask: 1.0789  decode.d8.loss_dice: 0.8959
05/26 19:42:57 - mmengine - INFO - Iter(train) [ 74450/160000]  base_lr: 5.6924e-05 lr: 5.6924e-06  eta: 9:47:31  time: 0.4117  data_time: 0.0096  memory: 5965  grad_norm: 665.0960  loss: 18.5909  decode.loss_cls: 0.1227  decode.loss_mask: 0.9531  decode.loss_dice: 0.7324  decode.d0.loss_cls: 0.6547  decode.d0.loss_mask: 0.8777  decode.d0.loss_dice: 0.7013  decode.d1.loss_cls: 0.0983  decode.d1.loss_mask: 0.9895  decode.d1.loss_dice: 0.7605  decode.d2.loss_cls: 0.1042  decode.d2.loss_mask: 0.9589  decode.d2.loss_dice: 0.7527  decode.d3.loss_cls: 0.1178  decode.d3.loss_mask: 0.9421  decode.d3.loss_dice: 0.7371  decode.d4.loss_cls: 0.1401  decode.d4.loss_mask: 0.9344  decode.d4.loss_dice: 0.7266  decode.d5.loss_cls: 0.1121  decode.d5.loss_mask: 0.9789  decode.d5.loss_dice: 0.7499  decode.d6.loss_cls: 0.1088  decode.d6.loss_mask: 0.9614  decode.d6.loss_dice: 0.7384  decode.d7.loss_cls: 0.0868  decode.d7.loss_mask: 0.9937  decode.d7.loss_dice: 0.7567  decode.d8.loss_cls: 0.0910  decode.d8.loss_mask: 0.9692  decode.d8.loss_dice: 0.7400
05/26 19:43:18 - mmengine - INFO - Iter(train) [ 74500/160000]  base_lr: 5.6894e-05 lr: 5.6894e-06  eta: 9:47:11  time: 0.4119  data_time: 0.0096  memory: 5974  grad_norm: 562.1625  loss: 24.4185  decode.loss_cls: 0.2731  decode.loss_mask: 1.2676  decode.loss_dice: 0.8661  decode.d0.loss_cls: 0.8312  decode.d0.loss_mask: 1.1785  decode.d0.loss_dice: 0.8862  decode.d1.loss_cls: 0.2938  decode.d1.loss_mask: 1.2216  decode.d1.loss_dice: 0.8687  decode.d2.loss_cls: 0.2531  decode.d2.loss_mask: 1.2396  decode.d2.loss_dice: 0.8560  decode.d3.loss_cls: 0.2702  decode.d3.loss_mask: 1.2397  decode.d3.loss_dice: 0.8746  decode.d4.loss_cls: 0.3032  decode.d4.loss_mask: 1.2547  decode.d4.loss_dice: 0.8821  decode.d5.loss_cls: 0.2911  decode.d5.loss_mask: 1.2468  decode.d5.loss_dice: 0.8783  decode.d6.loss_cls: 0.2923  decode.d6.loss_mask: 1.2188  decode.d6.loss_dice: 0.8587  decode.d7.loss_cls: 0.2309  decode.d7.loss_mask: 1.2687  decode.d7.loss_dice: 0.9102  decode.d8.loss_cls: 0.2420  decode.d8.loss_mask: 1.2483  decode.d8.loss_dice: 0.8721
05/26 19:43:38 - mmengine - INFO - Iter(train) [ 74550/160000]  base_lr: 5.6864e-05 lr: 5.6864e-06  eta: 9:46:50  time: 0.4115  data_time: 0.0096  memory: 5976  grad_norm: 417.6492  loss: 19.9868  decode.loss_cls: 0.1721  decode.loss_mask: 1.0484  decode.loss_dice: 0.7628  decode.d0.loss_cls: 0.6369  decode.d0.loss_mask: 1.0218  decode.d0.loss_dice: 0.7259  decode.d1.loss_cls: 0.1268  decode.d1.loss_mask: 1.0330  decode.d1.loss_dice: 0.7187  decode.d2.loss_cls: 0.1636  decode.d2.loss_mask: 1.0368  decode.d2.loss_dice: 0.7571  decode.d3.loss_cls: 0.1428  decode.d3.loss_mask: 1.0834  decode.d3.loss_dice: 0.7606  decode.d4.loss_cls: 0.1578  decode.d4.loss_mask: 1.0544  decode.d4.loss_dice: 0.7404  decode.d5.loss_cls: 0.1140  decode.d5.loss_mask: 1.1011  decode.d5.loss_dice: 0.7443  decode.d6.loss_cls: 0.1384  decode.d6.loss_mask: 1.0536  decode.d6.loss_dice: 0.7482  decode.d7.loss_cls: 0.1507  decode.d7.loss_mask: 1.0684  decode.d7.loss_dice: 0.7685  decode.d8.loss_cls: 0.1569  decode.d8.loss_mask: 1.0478  decode.d8.loss_dice: 0.7516
05/26 19:43:59 - mmengine - INFO - Iter(train) [ 74600/160000]  base_lr: 5.6834e-05 lr: 5.6834e-06  eta: 9:46:29  time: 0.4115  data_time: 0.0096  memory: 5967  grad_norm: 525.5728  loss: 20.5599  decode.loss_cls: 0.2201  decode.loss_mask: 1.0344  decode.loss_dice: 0.7311  decode.d0.loss_cls: 0.7288  decode.d0.loss_mask: 0.9953  decode.d0.loss_dice: 0.7441  decode.d1.loss_cls: 0.2602  decode.d1.loss_mask: 1.0020  decode.d1.loss_dice: 0.7183  decode.d2.loss_cls: 0.2527  decode.d2.loss_mask: 0.9996  decode.d2.loss_dice: 0.7383  decode.d3.loss_cls: 0.2269  decode.d3.loss_mask: 1.0537  decode.d3.loss_dice: 0.7526  decode.d4.loss_cls: 0.2919  decode.d4.loss_mask: 1.0139  decode.d4.loss_dice: 0.7245  decode.d5.loss_cls: 0.2685  decode.d5.loss_mask: 1.0044  decode.d5.loss_dice: 0.7180  decode.d6.loss_cls: 0.2952  decode.d6.loss_mask: 1.0292  decode.d6.loss_dice: 0.7313  decode.d7.loss_cls: 0.2840  decode.d7.loss_mask: 1.0256  decode.d7.loss_dice: 0.7405  decode.d8.loss_cls: 0.2721  decode.d8.loss_mask: 0.9961  decode.d8.loss_dice: 0.7066
05/26 19:44:19 - mmengine - INFO - Iter(train) [ 74650/160000]  base_lr: 5.6804e-05 lr: 5.6804e-06  eta: 9:46:09  time: 0.4131  data_time: 0.0096  memory: 5967  grad_norm: 684.3295  loss: 24.1819  decode.loss_cls: 0.2974  decode.loss_mask: 1.2125  decode.loss_dice: 0.9014  decode.d0.loss_cls: 0.7928  decode.d0.loss_mask: 1.1344  decode.d0.loss_dice: 0.8378  decode.d1.loss_cls: 0.3118  decode.d1.loss_mask: 1.1832  decode.d1.loss_dice: 0.8795  decode.d2.loss_cls: 0.3032  decode.d2.loss_mask: 1.1866  decode.d2.loss_dice: 0.8886  decode.d3.loss_cls: 0.3290  decode.d3.loss_mask: 1.1505  decode.d3.loss_dice: 0.8529  decode.d4.loss_cls: 0.3274  decode.d4.loss_mask: 1.1822  decode.d4.loss_dice: 0.8554  decode.d5.loss_cls: 0.3672  decode.d5.loss_mask: 1.1791  decode.d5.loss_dice: 0.8729  decode.d6.loss_cls: 0.3336  decode.d6.loss_mask: 1.2199  decode.d6.loss_dice: 0.8905  decode.d7.loss_cls: 0.3135  decode.d7.loss_mask: 1.1793  decode.d7.loss_dice: 0.8635  decode.d8.loss_cls: 0.3290  decode.d8.loss_mask: 1.1674  decode.d8.loss_dice: 0.8393
05/26 19:44:40 - mmengine - INFO - Iter(train) [ 74700/160000]  base_lr: 5.6774e-05 lr: 5.6774e-06  eta: 9:45:48  time: 0.4139  data_time: 0.0097  memory: 5985  grad_norm: 784.3069  loss: 25.6787  decode.loss_cls: 0.4447  decode.loss_mask: 1.1176  decode.loss_dice: 0.9803  decode.d0.loss_cls: 0.8487  decode.d0.loss_mask: 1.0863  decode.d0.loss_dice: 0.9879  decode.d1.loss_cls: 0.4345  decode.d1.loss_mask: 1.1047  decode.d1.loss_dice: 0.9477  decode.d2.loss_cls: 0.4010  decode.d2.loss_mask: 1.1255  decode.d2.loss_dice: 0.9872  decode.d3.loss_cls: 0.4228  decode.d3.loss_mask: 1.0882  decode.d3.loss_dice: 0.9582  decode.d4.loss_cls: 0.4375  decode.d4.loss_mask: 1.1435  decode.d4.loss_dice: 1.0116  decode.d5.loss_cls: 0.4965  decode.d5.loss_mask: 1.0830  decode.d5.loss_dice: 0.9737  decode.d6.loss_cls: 0.4837  decode.d6.loss_mask: 1.1027  decode.d6.loss_dice: 0.9361  decode.d7.loss_cls: 0.3812  decode.d7.loss_mask: 1.1157  decode.d7.loss_dice: 0.9688  decode.d8.loss_cls: 0.4739  decode.d8.loss_mask: 1.1493  decode.d8.loss_dice: 0.9858
05/26 19:45:01 - mmengine - INFO - Iter(train) [ 74750/160000]  base_lr: 5.6744e-05 lr: 5.6744e-06  eta: 9:45:28  time: 0.4115  data_time: 0.0096  memory: 5974  grad_norm: 569.2141  loss: 22.1139  decode.loss_cls: 0.2038  decode.loss_mask: 1.1667  decode.loss_dice: 0.7913  decode.d0.loss_cls: 0.7514  decode.d0.loss_mask: 1.0600  decode.d0.loss_dice: 0.7491  decode.d1.loss_cls: 0.2655  decode.d1.loss_mask: 1.1194  decode.d1.loss_dice: 0.7752  decode.d2.loss_cls: 0.2582  decode.d2.loss_mask: 1.1348  decode.d2.loss_dice: 0.7705  decode.d3.loss_cls: 0.2131  decode.d3.loss_mask: 1.1643  decode.d3.loss_dice: 0.7848  decode.d4.loss_cls: 0.2709  decode.d4.loss_mask: 1.1613  decode.d4.loss_dice: 0.7845  decode.d5.loss_cls: 0.2487  decode.d5.loss_mask: 1.1683  decode.d5.loss_dice: 0.7973  decode.d6.loss_cls: 0.2364  decode.d6.loss_mask: 1.1576  decode.d6.loss_dice: 0.7755  decode.d7.loss_cls: 0.2842  decode.d7.loss_mask: 1.1076  decode.d7.loss_dice: 0.7482  decode.d8.loss_cls: 0.2272  decode.d8.loss_mask: 1.1609  decode.d8.loss_dice: 0.7772
05/26 19:45:21 - mmengine - INFO - Iter(train) [ 74800/160000]  base_lr: 5.6714e-05 lr: 5.6714e-06  eta: 9:45:07  time: 0.4113  data_time: 0.0095  memory: 5981  grad_norm: 838.8825  loss: 19.4997  decode.loss_cls: 0.0990  decode.loss_mask: 1.1020  decode.loss_dice: 0.7593  decode.d0.loss_cls: 0.6192  decode.d0.loss_mask: 0.9918  decode.d0.loss_dice: 0.6717  decode.d1.loss_cls: 0.1139  decode.d1.loss_mask: 1.1001  decode.d1.loss_dice: 0.7254  decode.d2.loss_cls: 0.1505  decode.d2.loss_mask: 1.0342  decode.d2.loss_dice: 0.6854  decode.d3.loss_cls: 0.0990  decode.d3.loss_mask: 1.1120  decode.d3.loss_dice: 0.7507  decode.d4.loss_cls: 0.1426  decode.d4.loss_mask: 1.0371  decode.d4.loss_dice: 0.6917  decode.d5.loss_cls: 0.1274  decode.d5.loss_mask: 1.0521  decode.d5.loss_dice: 0.6900  decode.d6.loss_cls: 0.1313  decode.d6.loss_mask: 1.0560  decode.d6.loss_dice: 0.7149  decode.d7.loss_cls: 0.1404  decode.d7.loss_mask: 1.0523  decode.d7.loss_dice: 0.7007  decode.d8.loss_cls: 0.1276  decode.d8.loss_mask: 1.0894  decode.d8.loss_dice: 0.7321
05/26 19:45:42 - mmengine - INFO - Iter(train) [ 74850/160000]  base_lr: 5.6684e-05 lr: 5.6684e-06  eta: 9:44:46  time: 0.4116  data_time: 0.0096  memory: 5968  grad_norm: 700.6574  loss: 23.0570  decode.loss_cls: 0.1456  decode.loss_mask: 1.3118  decode.loss_dice: 0.8399  decode.d0.loss_cls: 0.7705  decode.d0.loss_mask: 1.1630  decode.d0.loss_dice: 0.8081  decode.d1.loss_cls: 0.1531  decode.d1.loss_mask: 1.3232  decode.d1.loss_dice: 0.8306  decode.d2.loss_cls: 0.1665  decode.d2.loss_mask: 1.2647  decode.d2.loss_dice: 0.8193  decode.d3.loss_cls: 0.1643  decode.d3.loss_mask: 1.2392  decode.d3.loss_dice: 0.8115  decode.d4.loss_cls: 0.1748  decode.d4.loss_mask: 1.2412  decode.d4.loss_dice: 0.8075  decode.d5.loss_cls: 0.1795  decode.d5.loss_mask: 1.3023  decode.d5.loss_dice: 0.7877  decode.d6.loss_cls: 0.1882  decode.d6.loss_mask: 1.2230  decode.d6.loss_dice: 0.7894  decode.d7.loss_cls: 0.1842  decode.d7.loss_mask: 1.2843  decode.d7.loss_dice: 0.8084  decode.d8.loss_cls: 0.1802  decode.d8.loss_mask: 1.2853  decode.d8.loss_dice: 0.8099
05/26 19:46:02 - mmengine - INFO - Iter(train) [ 74900/160000]  base_lr: 5.6654e-05 lr: 5.6654e-06  eta: 9:44:26  time: 0.4114  data_time: 0.0097  memory: 5966  grad_norm: 473.7631  loss: 19.0766  decode.loss_cls: 0.1328  decode.loss_mask: 0.9945  decode.loss_dice: 0.7406  decode.d0.loss_cls: 0.5880  decode.d0.loss_mask: 0.9800  decode.d0.loss_dice: 0.7104  decode.d1.loss_cls: 0.1812  decode.d1.loss_mask: 0.9990  decode.d1.loss_dice: 0.7238  decode.d2.loss_cls: 0.1348  decode.d2.loss_mask: 0.9820  decode.d2.loss_dice: 0.7187  decode.d3.loss_cls: 0.2161  decode.d3.loss_mask: 0.9588  decode.d3.loss_dice: 0.7076  decode.d4.loss_cls: 0.1659  decode.d4.loss_mask: 0.9629  decode.d4.loss_dice: 0.6944  decode.d5.loss_cls: 0.1252  decode.d5.loss_mask: 0.9925  decode.d5.loss_dice: 0.7400  decode.d6.loss_cls: 0.1570  decode.d6.loss_mask: 1.0121  decode.d6.loss_dice: 0.7399  decode.d7.loss_cls: 0.1325  decode.d7.loss_mask: 0.9879  decode.d7.loss_dice: 0.7339  decode.d8.loss_cls: 0.1431  decode.d8.loss_mask: 0.9902  decode.d8.loss_dice: 0.7310
05/26 19:46:23 - mmengine - INFO - Iter(train) [ 74950/160000]  base_lr: 5.6624e-05 lr: 5.6624e-06  eta: 9:44:05  time: 0.4099  data_time: 0.0097  memory: 5967  grad_norm: 683.5200  loss: 20.7454  decode.loss_cls: 0.2591  decode.loss_mask: 1.0725  decode.loss_dice: 0.6944  decode.d0.loss_cls: 0.6990  decode.d0.loss_mask: 1.0063  decode.d0.loss_dice: 0.6565  decode.d1.loss_cls: 0.2557  decode.d1.loss_mask: 1.0501  decode.d1.loss_dice: 0.6547  decode.d2.loss_cls: 0.2551  decode.d2.loss_mask: 1.0617  decode.d2.loss_dice: 0.6734  decode.d3.loss_cls: 0.2506  decode.d3.loss_mask: 1.0837  decode.d3.loss_dice: 0.6931  decode.d4.loss_cls: 0.2211  decode.d4.loss_mask: 1.1132  decode.d4.loss_dice: 0.7014  decode.d5.loss_cls: 0.2535  decode.d5.loss_mask: 1.1213  decode.d5.loss_dice: 0.7240  decode.d6.loss_cls: 0.2450  decode.d6.loss_mask: 1.1300  decode.d6.loss_dice: 0.7065  decode.d7.loss_cls: 0.2540  decode.d7.loss_mask: 1.1119  decode.d7.loss_dice: 0.7119  decode.d8.loss_cls: 0.2413  decode.d8.loss_mask: 1.1378  decode.d8.loss_dice: 0.7068
05/26 19:46:44 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 19:46:44 - mmengine - INFO - Iter(train) [ 75000/160000]  base_lr: 5.6594e-05 lr: 5.6594e-06  eta: 9:43:45  time: 0.4116  data_time: 0.0096  memory: 5981  grad_norm: 572.6699  loss: 24.8295  decode.loss_cls: 0.2461  decode.loss_mask: 1.2854  decode.loss_dice: 0.8397  decode.d0.loss_cls: 0.6598  decode.d0.loss_mask: 1.3203  decode.d0.loss_dice: 0.8592  decode.d1.loss_cls: 0.2539  decode.d1.loss_mask: 1.3455  decode.d1.loss_dice: 0.8883  decode.d2.loss_cls: 0.2605  decode.d2.loss_mask: 1.3283  decode.d2.loss_dice: 0.8415  decode.d3.loss_cls: 0.2453  decode.d3.loss_mask: 1.3313  decode.d3.loss_dice: 0.8704  decode.d4.loss_cls: 0.2659  decode.d4.loss_mask: 1.3156  decode.d4.loss_dice: 0.8646  decode.d5.loss_cls: 0.2449  decode.d5.loss_mask: 1.3241  decode.d5.loss_dice: 0.8625  decode.d6.loss_cls: 0.2554  decode.d6.loss_mask: 1.3193  decode.d6.loss_dice: 0.8569  decode.d7.loss_cls: 0.2466  decode.d7.loss_mask: 1.3714  decode.d7.loss_dice: 0.9131  decode.d8.loss_cls: 0.2281  decode.d8.loss_mask: 1.3218  decode.d8.loss_dice: 0.8639
05/26 19:46:44 - mmengine - INFO - Saving checkpoint at 75000 iterations
05/26 19:46:48 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:08  time: 0.0485  data_time: 0.0012  memory: 1391  
05/26 19:46:50 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:05  time: 0.0476  data_time: 0.0012  memory: 1205  
05/26 19:46:53 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:03  time: 0.0500  data_time: 0.0012  memory: 1596  
05/26 19:46:55 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0488  data_time: 0.0012  memory: 1298  
05/26 19:46:58 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:58  time: 0.0476  data_time: 0.0012  memory: 1298  
05/26 19:47:00 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0486  data_time: 0.0013  memory: 1279  
05/26 19:47:02 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:53  time: 0.0478  data_time: 0.0012  memory: 1224  
05/26 19:47:05 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0486  data_time: 0.0012  memory: 1298  
05/26 19:47:07 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0474  data_time: 0.0012  memory: 1298  
05/26 19:47:10 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0518  data_time: 0.0013  memory: 1725  
05/26 19:47:12 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0478  data_time: 0.0012  memory: 1336  
05/26 19:47:15 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:41  time: 0.0478  data_time: 0.0012  memory: 1298  
05/26 19:47:17 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0508  data_time: 0.0022  memory: 1205  
05/26 19:47:19 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0490  data_time: 0.0012  memory: 1316  
05/26 19:47:22 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0476  data_time: 0.0013  memory: 1279  
05/26 19:47:24 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0511  data_time: 0.0012  memory: 1410  
05/26 19:47:27 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0494  data_time: 0.0013  memory: 1279  
05/26 19:47:29 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0486  data_time: 0.0012  memory: 1205  
05/26 19:47:32 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0486  data_time: 0.0012  memory: 1205  
05/26 19:47:34 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0476  data_time: 0.0012  memory: 1336  
05/26 19:47:36 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0484  data_time: 0.0013  memory: 1246  
05/26 19:47:39 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0497  data_time: 0.0012  memory: 1503  
05/26 19:47:41 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0475  data_time: 0.0012  memory: 1261  
05/26 19:47:44 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0486  data_time: 0.0012  memory: 1298  
05/26 19:47:46 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0480  data_time: 0.0012  memory: 1447  
05/26 19:47:49 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0475  data_time: 0.0012  memory: 1298  
05/26 19:47:51 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0490  data_time: 0.0012  memory: 1279  
05/26 19:47:53 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0489  data_time: 0.0013  memory: 1205  
05/26 19:47:56 - mmengine - INFO - per class results:
05/26 19:47:56 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.15 | 98.14 |
|  aeroplane  | 90.27 | 97.94 |
|   bicycle   | 48.15 | 95.38 |
|     bird    |  94.4 | 96.46 |
|     boat    | 66.94 | 91.64 |
|    bottle   | 81.06 | 91.68 |
|     bus     | 92.48 | 93.78 |
|     car     | 90.39 | 91.95 |
|     cat     | 93.98 | 96.28 |
|    chair    | 39.94 | 61.54 |
|     cow     |  84.0 | 90.35 |
| diningtable | 58.73 | 61.37 |
|     dog     | 90.88 | 97.68 |
|    horse    | 86.54 | 93.94 |
|  motorbike  |  92.3 | 95.93 |
|    person   | 89.55 | 92.86 |
| pottedplant | 71.14 | 85.38 |
|    sheep    | 85.37 | 92.06 |
|     sofa    | 35.13 | 36.84 |
|    train    | 90.13 |  93.4 |
|  tvmonitor  | 79.81 |  83.1 |
+-------------+-------+-------+
05/26 19:47:56 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.4500  mIoU: 78.8700  mAcc: 87.5100  data_time: 0.0013  time: 0.0483
05/26 19:48:16 - mmengine - INFO - Iter(train) [ 75050/160000]  base_lr: 5.6564e-05 lr: 5.6564e-06  eta: 9:43:24  time: 0.4118  data_time: 0.0097  memory: 5975  grad_norm: 472.0486  loss: 21.9139  decode.loss_cls: 0.2881  decode.loss_mask: 1.0735  decode.loss_dice: 0.7975  decode.d0.loss_cls: 0.6165  decode.d0.loss_mask: 1.0655  decode.d0.loss_dice: 0.7826  decode.d1.loss_cls: 0.2600  decode.d1.loss_mask: 1.1018  decode.d1.loss_dice: 0.8027  decode.d2.loss_cls: 0.2724  decode.d2.loss_mask: 1.0823  decode.d2.loss_dice: 0.8059  decode.d3.loss_cls: 0.2460  decode.d3.loss_mask: 1.0703  decode.d3.loss_dice: 0.8051  decode.d4.loss_cls: 0.3299  decode.d4.loss_mask: 1.0714  decode.d4.loss_dice: 0.7905  decode.d5.loss_cls: 0.2944  decode.d5.loss_mask: 1.0846  decode.d5.loss_dice: 0.7979  decode.d6.loss_cls: 0.2697  decode.d6.loss_mask: 1.1155  decode.d6.loss_dice: 0.7937  decode.d7.loss_cls: 0.2411  decode.d7.loss_mask: 1.0845  decode.d7.loss_dice: 0.8046  decode.d8.loss_cls: 0.2384  decode.d8.loss_mask: 1.1059  decode.d8.loss_dice: 0.8215
05/26 19:48:37 - mmengine - INFO - Iter(train) [ 75100/160000]  base_lr: 5.6534e-05 lr: 5.6534e-06  eta: 9:43:03  time: 0.4113  data_time: 0.0096  memory: 5969  grad_norm: 824.6931  loss: 25.0135  decode.loss_cls: 0.2820  decode.loss_mask: 1.2814  decode.loss_dice: 0.8951  decode.d0.loss_cls: 0.7366  decode.d0.loss_mask: 1.2690  decode.d0.loss_dice: 0.8452  decode.d1.loss_cls: 0.2887  decode.d1.loss_mask: 1.2931  decode.d1.loss_dice: 0.8823  decode.d2.loss_cls: 0.2800  decode.d2.loss_mask: 1.2957  decode.d2.loss_dice: 0.8791  decode.d3.loss_cls: 0.2762  decode.d3.loss_mask: 1.2771  decode.d3.loss_dice: 0.8921  decode.d4.loss_cls: 0.2829  decode.d4.loss_mask: 1.2912  decode.d4.loss_dice: 0.8700  decode.d5.loss_cls: 0.2736  decode.d5.loss_mask: 1.3270  decode.d5.loss_dice: 0.9131  decode.d6.loss_cls: 0.2741  decode.d6.loss_mask: 1.3170  decode.d6.loss_dice: 0.8950  decode.d7.loss_cls: 0.2922  decode.d7.loss_mask: 1.2703  decode.d7.loss_dice: 0.8779  decode.d8.loss_cls: 0.2761  decode.d8.loss_mask: 1.2896  decode.d8.loss_dice: 0.8900
05/26 19:48:57 - mmengine - INFO - Iter(train) [ 75150/160000]  base_lr: 5.6504e-05 lr: 5.6504e-06  eta: 9:42:43  time: 0.4129  data_time: 0.0095  memory: 5973  grad_norm: 848.7133  loss: 22.8299  decode.loss_cls: 0.2559  decode.loss_mask: 1.1740  decode.loss_dice: 0.7884  decode.d0.loss_cls: 0.7455  decode.d0.loss_mask: 1.1512  decode.d0.loss_dice: 0.8691  decode.d1.loss_cls: 0.2656  decode.d1.loss_mask: 1.1377  decode.d1.loss_dice: 0.7840  decode.d2.loss_cls: 0.2340  decode.d2.loss_mask: 1.2014  decode.d2.loss_dice: 0.8078  decode.d3.loss_cls: 0.2635  decode.d3.loss_mask: 1.1781  decode.d3.loss_dice: 0.8227  decode.d4.loss_cls: 0.2309  decode.d4.loss_mask: 1.2358  decode.d4.loss_dice: 0.8367  decode.d5.loss_cls: 0.2281  decode.d5.loss_mask: 1.1858  decode.d5.loss_dice: 0.8144  decode.d6.loss_cls: 0.2238  decode.d6.loss_mask: 1.1914  decode.d6.loss_dice: 0.8144  decode.d7.loss_cls: 0.2693  decode.d7.loss_mask: 1.1467  decode.d7.loss_dice: 0.7879  decode.d8.loss_cls: 0.2355  decode.d8.loss_mask: 1.1677  decode.d8.loss_dice: 0.7826
05/26 19:49:18 - mmengine - INFO - Iter(train) [ 75200/160000]  base_lr: 5.6474e-05 lr: 5.6474e-06  eta: 9:42:22  time: 0.4121  data_time: 0.0095  memory: 5967  grad_norm: 936.7320  loss: 22.7180  decode.loss_cls: 0.2304  decode.loss_mask: 1.1271  decode.loss_dice: 0.8725  decode.d0.loss_cls: 0.7935  decode.d0.loss_mask: 1.0947  decode.d0.loss_dice: 0.8125  decode.d1.loss_cls: 0.2847  decode.d1.loss_mask: 1.1125  decode.d1.loss_dice: 0.8524  decode.d2.loss_cls: 0.2941  decode.d2.loss_mask: 1.1112  decode.d2.loss_dice: 0.8423  decode.d3.loss_cls: 0.2578  decode.d3.loss_mask: 1.1104  decode.d3.loss_dice: 0.8603  decode.d4.loss_cls: 0.2550  decode.d4.loss_mask: 1.1444  decode.d4.loss_dice: 0.8424  decode.d5.loss_cls: 0.2404  decode.d5.loss_mask: 1.1180  decode.d5.loss_dice: 0.8533  decode.d6.loss_cls: 0.2587  decode.d6.loss_mask: 1.0934  decode.d6.loss_dice: 0.8425  decode.d7.loss_cls: 0.2539  decode.d7.loss_mask: 1.0953  decode.d7.loss_dice: 0.8484  decode.d8.loss_cls: 0.2482  decode.d8.loss_mask: 1.1143  decode.d8.loss_dice: 0.8534
05/26 19:49:39 - mmengine - INFO - Iter(train) [ 75250/160000]  base_lr: 5.6444e-05 lr: 5.6444e-06  eta: 9:42:01  time: 0.4127  data_time: 0.0095  memory: 5982  grad_norm: 438.2495  loss: 19.1907  decode.loss_cls: 0.1608  decode.loss_mask: 1.0049  decode.loss_dice: 0.7027  decode.d0.loss_cls: 0.6288  decode.d0.loss_mask: 0.9380  decode.d0.loss_dice: 0.6959  decode.d1.loss_cls: 0.1842  decode.d1.loss_mask: 1.0033  decode.d1.loss_dice: 0.7244  decode.d2.loss_cls: 0.2130  decode.d2.loss_mask: 0.9614  decode.d2.loss_dice: 0.6953  decode.d3.loss_cls: 0.1565  decode.d3.loss_mask: 0.9982  decode.d3.loss_dice: 0.7288  decode.d4.loss_cls: 0.1666  decode.d4.loss_mask: 1.0100  decode.d4.loss_dice: 0.7330  decode.d5.loss_cls: 0.2485  decode.d5.loss_mask: 0.9152  decode.d5.loss_dice: 0.7346  decode.d6.loss_cls: 0.1877  decode.d6.loss_mask: 0.9259  decode.d6.loss_dice: 0.7226  decode.d7.loss_cls: 0.1832  decode.d7.loss_mask: 0.9553  decode.d7.loss_dice: 0.7004  decode.d8.loss_cls: 0.1621  decode.d8.loss_mask: 1.0121  decode.d8.loss_dice: 0.7373
05/26 19:49:59 - mmengine - INFO - Iter(train) [ 75300/160000]  base_lr: 5.6414e-05 lr: 5.6414e-06  eta: 9:41:41  time: 0.4107  data_time: 0.0094  memory: 5971  grad_norm: 406.7908  loss: 19.0013  decode.loss_cls: 0.2072  decode.loss_mask: 0.8852  decode.loss_dice: 0.7284  decode.d0.loss_cls: 0.6419  decode.d0.loss_mask: 0.9331  decode.d0.loss_dice: 0.7542  decode.d1.loss_cls: 0.2351  decode.d1.loss_mask: 0.9039  decode.d1.loss_dice: 0.7580  decode.d2.loss_cls: 0.1980  decode.d2.loss_mask: 0.9386  decode.d2.loss_dice: 0.7796  decode.d3.loss_cls: 0.2141  decode.d3.loss_mask: 0.9008  decode.d3.loss_dice: 0.7425  decode.d4.loss_cls: 0.1922  decode.d4.loss_mask: 0.8749  decode.d4.loss_dice: 0.7282  decode.d5.loss_cls: 0.2250  decode.d5.loss_mask: 0.8812  decode.d5.loss_dice: 0.7354  decode.d6.loss_cls: 0.2268  decode.d6.loss_mask: 0.8973  decode.d6.loss_dice: 0.7411  decode.d7.loss_cls: 0.2632  decode.d7.loss_mask: 0.8680  decode.d7.loss_dice: 0.7131  decode.d8.loss_cls: 0.2411  decode.d8.loss_mask: 0.8835  decode.d8.loss_dice: 0.7096
05/26 19:50:20 - mmengine - INFO - Iter(train) [ 75350/160000]  base_lr: 5.6384e-05 lr: 5.6384e-06  eta: 9:41:20  time: 0.4110  data_time: 0.0097  memory: 5980  grad_norm: 567.5668  loss: 20.6086  decode.loss_cls: 0.2022  decode.loss_mask: 1.0475  decode.loss_dice: 0.7388  decode.d0.loss_cls: 0.6596  decode.d0.loss_mask: 1.0437  decode.d0.loss_dice: 0.7644  decode.d1.loss_cls: 0.1595  decode.d1.loss_mask: 1.0681  decode.d1.loss_dice: 0.7648  decode.d2.loss_cls: 0.1620  decode.d2.loss_mask: 1.0596  decode.d2.loss_dice: 0.7549  decode.d3.loss_cls: 0.1554  decode.d3.loss_mask: 1.0733  decode.d3.loss_dice: 0.7901  decode.d4.loss_cls: 0.1580  decode.d4.loss_mask: 1.0983  decode.d4.loss_dice: 0.7947  decode.d5.loss_cls: 0.1488  decode.d5.loss_mask: 1.1082  decode.d5.loss_dice: 0.7841  decode.d6.loss_cls: 0.1818  decode.d6.loss_mask: 1.0738  decode.d6.loss_dice: 0.7793  decode.d7.loss_cls: 0.1682  decode.d7.loss_mask: 1.0966  decode.d7.loss_dice: 0.7761  decode.d8.loss_cls: 0.2052  decode.d8.loss_mask: 1.0504  decode.d8.loss_dice: 0.7412
05/26 19:50:40 - mmengine - INFO - Iter(train) [ 75400/160000]  base_lr: 5.6354e-05 lr: 5.6354e-06  eta: 9:40:59  time: 0.4113  data_time: 0.0097  memory: 5971  grad_norm: 495.9054  loss: 18.5961  decode.loss_cls: 0.1141  decode.loss_mask: 1.0197  decode.loss_dice: 0.6096  decode.d0.loss_cls: 0.6753  decode.d0.loss_mask: 1.0276  decode.d0.loss_dice: 0.6430  decode.d1.loss_cls: 0.1592  decode.d1.loss_mask: 1.0277  decode.d1.loss_dice: 0.6243  decode.d2.loss_cls: 0.1547  decode.d2.loss_mask: 1.0249  decode.d2.loss_dice: 0.6203  decode.d3.loss_cls: 0.1499  decode.d3.loss_mask: 1.0203  decode.d3.loss_dice: 0.6236  decode.d4.loss_cls: 0.1704  decode.d4.loss_mask: 1.0330  decode.d4.loss_dice: 0.6503  decode.d5.loss_cls: 0.1302  decode.d5.loss_mask: 1.0308  decode.d5.loss_dice: 0.6417  decode.d6.loss_cls: 0.1729  decode.d6.loss_mask: 1.0192  decode.d6.loss_dice: 0.6191  decode.d7.loss_cls: 0.1777  decode.d7.loss_mask: 1.0279  decode.d7.loss_dice: 0.6306  decode.d8.loss_cls: 0.1329  decode.d8.loss_mask: 1.0373  decode.d8.loss_dice: 0.6281
05/26 19:51:01 - mmengine - INFO - Iter(train) [ 75450/160000]  base_lr: 5.6324e-05 lr: 5.6324e-06  eta: 9:40:39  time: 0.4107  data_time: 0.0097  memory: 5969  grad_norm: 612.8217  loss: 17.7855  decode.loss_cls: 0.1961  decode.loss_mask: 0.8834  decode.loss_dice: 0.6622  decode.d0.loss_cls: 0.6105  decode.d0.loss_mask: 0.8313  decode.d0.loss_dice: 0.6972  decode.d1.loss_cls: 0.1826  decode.d1.loss_mask: 0.8821  decode.d1.loss_dice: 0.6621  decode.d2.loss_cls: 0.1462  decode.d2.loss_mask: 0.8720  decode.d2.loss_dice: 0.6859  decode.d3.loss_cls: 0.1796  decode.d3.loss_mask: 0.8775  decode.d3.loss_dice: 0.6807  decode.d4.loss_cls: 0.1921  decode.d4.loss_mask: 0.8624  decode.d4.loss_dice: 0.6736  decode.d5.loss_cls: 0.2207  decode.d5.loss_mask: 0.8640  decode.d5.loss_dice: 0.6592  decode.d6.loss_cls: 0.2361  decode.d6.loss_mask: 0.8768  decode.d6.loss_dice: 0.6791  decode.d7.loss_cls: 0.1978  decode.d7.loss_mask: 0.8743  decode.d7.loss_dice: 0.6633  decode.d8.loss_cls: 0.2191  decode.d8.loss_mask: 0.8556  decode.d8.loss_dice: 0.6622
05/26 19:51:22 - mmengine - INFO - Iter(train) [ 75500/160000]  base_lr: 5.6294e-05 lr: 5.6294e-06  eta: 9:40:18  time: 0.4112  data_time: 0.0096  memory: 5986  grad_norm: 453.5321  loss: 22.3038  decode.loss_cls: 0.2992  decode.loss_mask: 1.0128  decode.loss_dice: 0.8316  decode.d0.loss_cls: 0.8378  decode.d0.loss_mask: 0.9477  decode.d0.loss_dice: 0.7918  decode.d1.loss_cls: 0.3301  decode.d1.loss_mask: 1.0565  decode.d1.loss_dice: 0.8655  decode.d2.loss_cls: 0.3189  decode.d2.loss_mask: 0.9805  decode.d2.loss_dice: 0.8610  decode.d3.loss_cls: 0.3318  decode.d3.loss_mask: 1.0367  decode.d3.loss_dice: 0.8151  decode.d4.loss_cls: 0.3407  decode.d4.loss_mask: 1.0438  decode.d4.loss_dice: 0.8465  decode.d5.loss_cls: 0.3175  decode.d5.loss_mask: 1.0481  decode.d5.loss_dice: 0.8344  decode.d6.loss_cls: 0.3472  decode.d6.loss_mask: 0.9802  decode.d6.loss_dice: 0.8200  decode.d7.loss_cls: 0.3397  decode.d7.loss_mask: 1.0158  decode.d7.loss_dice: 0.8620  decode.d8.loss_cls: 0.2976  decode.d8.loss_mask: 1.0297  decode.d8.loss_dice: 0.8636
05/26 19:51:42 - mmengine - INFO - Iter(train) [ 75550/160000]  base_lr: 5.6264e-05 lr: 5.6264e-06  eta: 9:39:58  time: 0.4117  data_time: 0.0097  memory: 5980  grad_norm: 485.5860  loss: 19.9472  decode.loss_cls: 0.3445  decode.loss_mask: 0.7979  decode.loss_dice: 0.7472  decode.d0.loss_cls: 0.7700  decode.d0.loss_mask: 0.7667  decode.d0.loss_dice: 0.7255  decode.d1.loss_cls: 0.3535  decode.d1.loss_mask: 0.9310  decode.d1.loss_dice: 0.7384  decode.d2.loss_cls: 0.3849  decode.d2.loss_mask: 0.9132  decode.d2.loss_dice: 0.7316  decode.d3.loss_cls: 0.3897  decode.d3.loss_mask: 0.8717  decode.d3.loss_dice: 0.7546  decode.d4.loss_cls: 0.3284  decode.d4.loss_mask: 0.8710  decode.d4.loss_dice: 0.7204  decode.d5.loss_cls: 0.3027  decode.d5.loss_mask: 0.9070  decode.d5.loss_dice: 0.7503  decode.d6.loss_cls: 0.3799  decode.d6.loss_mask: 0.8654  decode.d6.loss_dice: 0.7172  decode.d7.loss_cls: 0.3496  decode.d7.loss_mask: 0.8721  decode.d7.loss_dice: 0.7356  decode.d8.loss_cls: 0.3661  decode.d8.loss_mask: 0.8179  decode.d8.loss_dice: 0.7431
05/26 19:52:03 - mmengine - INFO - Iter(train) [ 75600/160000]  base_lr: 5.6234e-05 lr: 5.6234e-06  eta: 9:39:37  time: 0.4102  data_time: 0.0097  memory: 5976  grad_norm: 801.6134  loss: 22.2266  decode.loss_cls: 0.2724  decode.loss_mask: 1.0347  decode.loss_dice: 0.8041  decode.d0.loss_cls: 0.7141  decode.d0.loss_mask: 1.0440  decode.d0.loss_dice: 0.7832  decode.d1.loss_cls: 0.3331  decode.d1.loss_mask: 1.1106  decode.d1.loss_dice: 0.7660  decode.d2.loss_cls: 0.3057  decode.d2.loss_mask: 1.0988  decode.d2.loss_dice: 0.7966  decode.d3.loss_cls: 0.2999  decode.d3.loss_mask: 1.0412  decode.d3.loss_dice: 0.7972  decode.d4.loss_cls: 0.3247  decode.d4.loss_mask: 1.1221  decode.d4.loss_dice: 0.7772  decode.d5.loss_cls: 0.3604  decode.d5.loss_mask: 1.0722  decode.d5.loss_dice: 0.7865  decode.d6.loss_cls: 0.3345  decode.d6.loss_mask: 1.0782  decode.d6.loss_dice: 0.7806  decode.d7.loss_cls: 0.3052  decode.d7.loss_mask: 1.0864  decode.d7.loss_dice: 0.8283  decode.d8.loss_cls: 0.3219  decode.d8.loss_mask: 1.0493  decode.d8.loss_dice: 0.7976
05/26 19:52:23 - mmengine - INFO - Iter(train) [ 75650/160000]  base_lr: 5.6204e-05 lr: 5.6204e-06  eta: 9:39:16  time: 0.4102  data_time: 0.0096  memory: 5969  grad_norm: 711.4460  loss: 18.2164  decode.loss_cls: 0.0976  decode.loss_mask: 0.9744  decode.loss_dice: 0.6786  decode.d0.loss_cls: 0.5820  decode.d0.loss_mask: 0.9253  decode.d0.loss_dice: 0.6401  decode.d1.loss_cls: 0.1112  decode.d1.loss_mask: 1.0148  decode.d1.loss_dice: 0.7056  decode.d2.loss_cls: 0.1311  decode.d2.loss_mask: 1.0034  decode.d2.loss_dice: 0.6872  decode.d3.loss_cls: 0.1757  decode.d3.loss_mask: 0.9695  decode.d3.loss_dice: 0.6658  decode.d4.loss_cls: 0.1366  decode.d4.loss_mask: 0.9864  decode.d4.loss_dice: 0.6947  decode.d5.loss_cls: 0.1077  decode.d5.loss_mask: 0.9773  decode.d5.loss_dice: 0.6853  decode.d6.loss_cls: 0.1157  decode.d6.loss_mask: 0.9659  decode.d6.loss_dice: 0.6855  decode.d7.loss_cls: 0.1212  decode.d7.loss_mask: 0.9593  decode.d7.loss_dice: 0.6897  decode.d8.loss_cls: 0.1278  decode.d8.loss_mask: 0.9416  decode.d8.loss_dice: 0.6595
05/26 19:52:44 - mmengine - INFO - Iter(train) [ 75700/160000]  base_lr: 5.6175e-05 lr: 5.6175e-06  eta: 9:38:55  time: 0.4108  data_time: 0.0096  memory: 5976  grad_norm: 431.9402  loss: 21.4391  decode.loss_cls: 0.1452  decode.loss_mask: 1.1701  decode.loss_dice: 0.7382  decode.d0.loss_cls: 0.7488  decode.d0.loss_mask: 1.0355  decode.d0.loss_dice: 0.7057  decode.d1.loss_cls: 0.1414  decode.d1.loss_mask: 1.2079  decode.d1.loss_dice: 0.7656  decode.d2.loss_cls: 0.1535  decode.d2.loss_mask: 1.1933  decode.d2.loss_dice: 0.7803  decode.d3.loss_cls: 0.1437  decode.d3.loss_mask: 1.1926  decode.d3.loss_dice: 0.7637  decode.d4.loss_cls: 0.1592  decode.d4.loss_mask: 1.1873  decode.d4.loss_dice: 0.7491  decode.d5.loss_cls: 0.1361  decode.d5.loss_mask: 1.2113  decode.d5.loss_dice: 0.7654  decode.d6.loss_cls: 0.1700  decode.d6.loss_mask: 1.1927  decode.d6.loss_dice: 0.7750  decode.d7.loss_cls: 0.1670  decode.d7.loss_mask: 1.1574  decode.d7.loss_dice: 0.7598  decode.d8.loss_cls: 0.1441  decode.d8.loss_mask: 1.2180  decode.d8.loss_dice: 0.7611
05/26 19:53:04 - mmengine - INFO - Iter(train) [ 75750/160000]  base_lr: 5.6145e-05 lr: 5.6145e-06  eta: 9:38:35  time: 0.4105  data_time: 0.0095  memory: 5966  grad_norm: 371.0411  loss: 18.3893  decode.loss_cls: 0.1365  decode.loss_mask: 0.9696  decode.loss_dice: 0.6919  decode.d0.loss_cls: 0.5843  decode.d0.loss_mask: 0.9441  decode.d0.loss_dice: 0.6583  decode.d1.loss_cls: 0.1367  decode.d1.loss_mask: 0.9714  decode.d1.loss_dice: 0.6787  decode.d2.loss_cls: 0.1184  decode.d2.loss_mask: 0.9786  decode.d2.loss_dice: 0.6944  decode.d3.loss_cls: 0.1343  decode.d3.loss_mask: 0.9995  decode.d3.loss_dice: 0.7142  decode.d4.loss_cls: 0.1459  decode.d4.loss_mask: 0.9732  decode.d4.loss_dice: 0.6740  decode.d5.loss_cls: 0.1483  decode.d5.loss_mask: 0.9875  decode.d5.loss_dice: 0.6654  decode.d6.loss_cls: 0.1008  decode.d6.loss_mask: 0.9905  decode.d6.loss_dice: 0.6972  decode.d7.loss_cls: 0.1496  decode.d7.loss_mask: 0.9773  decode.d7.loss_dice: 0.6638  decode.d8.loss_cls: 0.1431  decode.d8.loss_mask: 0.9866  decode.d8.loss_dice: 0.6749
05/26 19:53:25 - mmengine - INFO - Iter(train) [ 75800/160000]  base_lr: 5.6115e-05 lr: 5.6115e-06  eta: 9:38:14  time: 0.4109  data_time: 0.0096  memory: 5967  grad_norm: 823.2047  loss: 23.7404  decode.loss_cls: 0.2119  decode.loss_mask: 1.3008  decode.loss_dice: 0.8367  decode.d0.loss_cls: 0.8450  decode.d0.loss_mask: 1.1646  decode.d0.loss_dice: 0.8665  decode.d1.loss_cls: 0.3008  decode.d1.loss_mask: 1.2129  decode.d1.loss_dice: 0.8462  decode.d2.loss_cls: 0.2596  decode.d2.loss_mask: 1.2722  decode.d2.loss_dice: 0.8375  decode.d3.loss_cls: 0.2546  decode.d3.loss_mask: 1.2251  decode.d3.loss_dice: 0.8433  decode.d4.loss_cls: 0.2082  decode.d4.loss_mask: 1.2470  decode.d4.loss_dice: 0.8786  decode.d5.loss_cls: 0.2573  decode.d5.loss_mask: 1.1905  decode.d5.loss_dice: 0.8061  decode.d6.loss_cls: 0.2312  decode.d6.loss_mask: 1.2830  decode.d6.loss_dice: 0.8588  decode.d7.loss_cls: 0.2847  decode.d7.loss_mask: 1.1760  decode.d7.loss_dice: 0.8272  decode.d8.loss_cls: 0.2214  decode.d8.loss_mask: 1.1763  decode.d8.loss_dice: 0.8162
05/26 19:53:46 - mmengine - INFO - Iter(train) [ 75850/160000]  base_lr: 5.6085e-05 lr: 5.6085e-06  eta: 9:37:54  time: 0.4115  data_time: 0.0095  memory: 5973  grad_norm: 639.3664  loss: 23.6784  decode.loss_cls: 0.2179  decode.loss_mask: 1.1628  decode.loss_dice: 0.8896  decode.d0.loss_cls: 0.6902  decode.d0.loss_mask: 1.2068  decode.d0.loss_dice: 0.8999  decode.d1.loss_cls: 0.2184  decode.d1.loss_mask: 1.2154  decode.d1.loss_dice: 0.9554  decode.d2.loss_cls: 0.2294  decode.d2.loss_mask: 1.1703  decode.d2.loss_dice: 0.9175  decode.d3.loss_cls: 0.2335  decode.d3.loss_mask: 1.1822  decode.d3.loss_dice: 0.8894  decode.d4.loss_cls: 0.1980  decode.d4.loss_mask: 1.2237  decode.d4.loss_dice: 0.9213  decode.d5.loss_cls: 0.2298  decode.d5.loss_mask: 1.1796  decode.d5.loss_dice: 0.8924  decode.d6.loss_cls: 0.2233  decode.d6.loss_mask: 1.1750  decode.d6.loss_dice: 0.9096  decode.d7.loss_cls: 0.2588  decode.d7.loss_mask: 1.2044  decode.d7.loss_dice: 0.9022  decode.d8.loss_cls: 0.2297  decode.d8.loss_mask: 1.1373  decode.d8.loss_dice: 0.9149
05/26 19:54:06 - mmengine - INFO - Iter(train) [ 75900/160000]  base_lr: 5.6055e-05 lr: 5.6055e-06  eta: 9:37:33  time: 0.4111  data_time: 0.0095  memory: 5972  grad_norm: 574.2148  loss: 20.0236  decode.loss_cls: 0.1940  decode.loss_mask: 0.9807  decode.loss_dice: 0.7717  decode.d0.loss_cls: 0.6451  decode.d0.loss_mask: 0.9905  decode.d0.loss_dice: 0.7729  decode.d1.loss_cls: 0.1984  decode.d1.loss_mask: 0.9754  decode.d1.loss_dice: 0.7911  decode.d2.loss_cls: 0.2291  decode.d2.loss_mask: 0.9980  decode.d2.loss_dice: 0.7651  decode.d3.loss_cls: 0.2108  decode.d3.loss_mask: 0.9752  decode.d3.loss_dice: 0.7538  decode.d4.loss_cls: 0.1860  decode.d4.loss_mask: 0.9960  decode.d4.loss_dice: 0.7732  decode.d5.loss_cls: 0.2396  decode.d5.loss_mask: 0.9747  decode.d5.loss_dice: 0.7679  decode.d6.loss_cls: 0.2039  decode.d6.loss_mask: 0.9730  decode.d6.loss_dice: 0.7685  decode.d7.loss_cls: 0.1988  decode.d7.loss_mask: 0.9714  decode.d7.loss_dice: 0.7741  decode.d8.loss_cls: 0.2064  decode.d8.loss_mask: 0.9676  decode.d8.loss_dice: 0.7707
05/26 19:54:27 - mmengine - INFO - Iter(train) [ 75950/160000]  base_lr: 5.6025e-05 lr: 5.6025e-06  eta: 9:37:13  time: 0.4123  data_time: 0.0100  memory: 5967  grad_norm: 899.3272  loss: 24.4080  decode.loss_cls: 0.2564  decode.loss_mask: 1.2898  decode.loss_dice: 0.9259  decode.d0.loss_cls: 0.7709  decode.d0.loss_mask: 1.2132  decode.d0.loss_dice: 0.8292  decode.d1.loss_cls: 0.2475  decode.d1.loss_mask: 1.3065  decode.d1.loss_dice: 0.8882  decode.d2.loss_cls: 0.2965  decode.d2.loss_mask: 1.2427  decode.d2.loss_dice: 0.8137  decode.d3.loss_cls: 0.3017  decode.d3.loss_mask: 1.1939  decode.d3.loss_dice: 0.8155  decode.d4.loss_cls: 0.3063  decode.d4.loss_mask: 1.2193  decode.d4.loss_dice: 0.8451  decode.d5.loss_cls: 0.2767  decode.d5.loss_mask: 1.2678  decode.d5.loss_dice: 0.8885  decode.d6.loss_cls: 0.2923  decode.d6.loss_mask: 1.2583  decode.d6.loss_dice: 0.8633  decode.d7.loss_cls: 0.3051  decode.d7.loss_mask: 1.2638  decode.d7.loss_dice: 0.8332  decode.d8.loss_cls: 0.2381  decode.d8.loss_mask: 1.2928  decode.d8.loss_dice: 0.8657
05/26 19:54:48 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 19:54:48 - mmengine - INFO - Iter(train) [ 76000/160000]  base_lr: 5.5995e-05 lr: 5.5995e-06  eta: 9:36:52  time: 0.4117  data_time: 0.0096  memory: 5967  grad_norm: 563.8079  loss: 18.3248  decode.loss_cls: 0.2276  decode.loss_mask: 0.9076  decode.loss_dice: 0.6448  decode.d0.loss_cls: 0.7434  decode.d0.loss_mask: 0.8548  decode.d0.loss_dice: 0.6355  decode.d1.loss_cls: 0.2191  decode.d1.loss_mask: 0.8917  decode.d1.loss_dice: 0.6133  decode.d2.loss_cls: 0.2481  decode.d2.loss_mask: 0.9295  decode.d2.loss_dice: 0.6402  decode.d3.loss_cls: 0.2356  decode.d3.loss_mask: 0.9269  decode.d3.loss_dice: 0.6297  decode.d4.loss_cls: 0.2970  decode.d4.loss_mask: 0.8750  decode.d4.loss_dice: 0.6282  decode.d5.loss_cls: 0.2243  decode.d5.loss_mask: 0.9193  decode.d5.loss_dice: 0.6397  decode.d6.loss_cls: 0.2471  decode.d6.loss_mask: 0.9258  decode.d6.loss_dice: 0.6321  decode.d7.loss_cls: 0.2520  decode.d7.loss_mask: 0.8983  decode.d7.loss_dice: 0.6439  decode.d8.loss_cls: 0.2552  decode.d8.loss_mask: 0.9141  decode.d8.loss_dice: 0.6248
05/26 19:55:08 - mmengine - INFO - Iter(train) [ 76050/160000]  base_lr: 5.5965e-05 lr: 5.5965e-06  eta: 9:36:31  time: 0.4107  data_time: 0.0096  memory: 5984  grad_norm: 591.7879  loss: 21.4342  decode.loss_cls: 0.1511  decode.loss_mask: 1.1072  decode.loss_dice: 0.7858  decode.d0.loss_cls: 0.7505  decode.d0.loss_mask: 1.1080  decode.d0.loss_dice: 0.8590  decode.d1.loss_cls: 0.1898  decode.d1.loss_mask: 1.1136  decode.d1.loss_dice: 0.7755  decode.d2.loss_cls: 0.1665  decode.d2.loss_mask: 1.1359  decode.d2.loss_dice: 0.8034  decode.d3.loss_cls: 0.1588  decode.d3.loss_mask: 1.1280  decode.d3.loss_dice: 0.8152  decode.d4.loss_cls: 0.1620  decode.d4.loss_mask: 1.1022  decode.d4.loss_dice: 0.8092  decode.d5.loss_cls: 0.1605  decode.d5.loss_mask: 1.1172  decode.d5.loss_dice: 0.7895  decode.d6.loss_cls: 0.1663  decode.d6.loss_mask: 1.1497  decode.d6.loss_dice: 0.7774  decode.d7.loss_cls: 0.2075  decode.d7.loss_mask: 1.0655  decode.d7.loss_dice: 0.7682  decode.d8.loss_cls: 0.1568  decode.d8.loss_mask: 1.1322  decode.d8.loss_dice: 0.8217
05/26 19:55:29 - mmengine - INFO - Iter(train) [ 76100/160000]  base_lr: 5.5935e-05 lr: 5.5935e-06  eta: 9:36:11  time: 0.4112  data_time: 0.0096  memory: 5969  grad_norm: 856.5457  loss: 22.2281  decode.loss_cls: 0.1860  decode.loss_mask: 1.1325  decode.loss_dice: 0.8432  decode.d0.loss_cls: 0.6981  decode.d0.loss_mask: 1.1121  decode.d0.loss_dice: 0.7532  decode.d1.loss_cls: 0.2095  decode.d1.loss_mask: 1.1146  decode.d1.loss_dice: 0.8297  decode.d2.loss_cls: 0.1957  decode.d2.loss_mask: 1.1726  decode.d2.loss_dice: 0.8581  decode.d3.loss_cls: 0.2056  decode.d3.loss_mask: 1.1372  decode.d3.loss_dice: 0.8316  decode.d4.loss_cls: 0.2247  decode.d4.loss_mask: 1.1395  decode.d4.loss_dice: 0.8303  decode.d5.loss_cls: 0.2035  decode.d5.loss_mask: 1.1513  decode.d5.loss_dice: 0.8504  decode.d6.loss_cls: 0.1967  decode.d6.loss_mask: 1.1639  decode.d6.loss_dice: 0.8691  decode.d7.loss_cls: 0.2229  decode.d7.loss_mask: 1.1041  decode.d7.loss_dice: 0.8191  decode.d8.loss_cls: 0.1784  decode.d8.loss_mask: 1.1459  decode.d8.loss_dice: 0.8486
05/26 19:55:49 - mmengine - INFO - Iter(train) [ 76150/160000]  base_lr: 5.5905e-05 lr: 5.5905e-06  eta: 9:35:50  time: 0.4113  data_time: 0.0095  memory: 5971  grad_norm: 509.0172  loss: 22.7803  decode.loss_cls: 0.2622  decode.loss_mask: 1.1026  decode.loss_dice: 0.8573  decode.d0.loss_cls: 0.7919  decode.d0.loss_mask: 1.1078  decode.d0.loss_dice: 0.7947  decode.d1.loss_cls: 0.2489  decode.d1.loss_mask: 1.1952  decode.d1.loss_dice: 0.8524  decode.d2.loss_cls: 0.2773  decode.d2.loss_mask: 1.1338  decode.d2.loss_dice: 0.8465  decode.d3.loss_cls: 0.2581  decode.d3.loss_mask: 1.1739  decode.d3.loss_dice: 0.8423  decode.d4.loss_cls: 0.2845  decode.d4.loss_mask: 1.1141  decode.d4.loss_dice: 0.8357  decode.d5.loss_cls: 0.2658  decode.d5.loss_mask: 1.1763  decode.d5.loss_dice: 0.8313  decode.d6.loss_cls: 0.2521  decode.d6.loss_mask: 1.0924  decode.d6.loss_dice: 0.8089  decode.d7.loss_cls: 0.1997  decode.d7.loss_mask: 1.1826  decode.d7.loss_dice: 0.8128  decode.d8.loss_cls: 0.2161  decode.d8.loss_mask: 1.1259  decode.d8.loss_dice: 0.8373
05/26 19:56:10 - mmengine - INFO - Iter(train) [ 76200/160000]  base_lr: 5.5875e-05 lr: 5.5875e-06  eta: 9:35:30  time: 0.4130  data_time: 0.0104  memory: 5967  grad_norm: 413.5254  loss: 17.7484  decode.loss_cls: 0.0958  decode.loss_mask: 0.9440  decode.loss_dice: 0.6623  decode.d0.loss_cls: 0.6639  decode.d0.loss_mask: 0.8515  decode.d0.loss_dice: 0.6421  decode.d1.loss_cls: 0.1354  decode.d1.loss_mask: 0.9457  decode.d1.loss_dice: 0.6550  decode.d2.loss_cls: 0.1033  decode.d2.loss_mask: 0.9631  decode.d2.loss_dice: 0.6516  decode.d3.loss_cls: 0.0975  decode.d3.loss_mask: 0.9481  decode.d3.loss_dice: 0.6707  decode.d4.loss_cls: 0.1219  decode.d4.loss_mask: 0.9550  decode.d4.loss_dice: 0.6917  decode.d5.loss_cls: 0.0814  decode.d5.loss_mask: 0.9702  decode.d5.loss_dice: 0.6902  decode.d6.loss_cls: 0.1135  decode.d6.loss_mask: 0.9113  decode.d6.loss_dice: 0.6723  decode.d7.loss_cls: 0.1246  decode.d7.loss_mask: 0.9599  decode.d7.loss_dice: 0.6872  decode.d8.loss_cls: 0.1533  decode.d8.loss_mask: 0.9199  decode.d8.loss_dice: 0.6663
05/26 19:56:31 - mmengine - INFO - Iter(train) [ 76250/160000]  base_lr: 5.5845e-05 lr: 5.5845e-06  eta: 9:35:09  time: 0.4127  data_time: 0.0099  memory: 5967  grad_norm: 711.3740  loss: 21.1866  decode.loss_cls: 0.3407  decode.loss_mask: 1.0850  decode.loss_dice: 0.6642  decode.d0.loss_cls: 0.7458  decode.d0.loss_mask: 1.0234  decode.d0.loss_dice: 0.6647  decode.d1.loss_cls: 0.2640  decode.d1.loss_mask: 1.1061  decode.d1.loss_dice: 0.7119  decode.d2.loss_cls: 0.2864  decode.d2.loss_mask: 1.1449  decode.d2.loss_dice: 0.6948  decode.d3.loss_cls: 0.2640  decode.d3.loss_mask: 1.1062  decode.d3.loss_dice: 0.6759  decode.d4.loss_cls: 0.2892  decode.d4.loss_mask: 1.1519  decode.d4.loss_dice: 0.6614  decode.d5.loss_cls: 0.3089  decode.d5.loss_mask: 1.0878  decode.d5.loss_dice: 0.6653  decode.d6.loss_cls: 0.2732  decode.d6.loss_mask: 1.1020  decode.d6.loss_dice: 0.6581  decode.d7.loss_cls: 0.3103  decode.d7.loss_mask: 1.1175  decode.d7.loss_dice: 0.6904  decode.d8.loss_cls: 0.2835  decode.d8.loss_mask: 1.1275  decode.d8.loss_dice: 0.6817
05/26 19:56:51 - mmengine - INFO - Iter(train) [ 76300/160000]  base_lr: 5.5815e-05 lr: 5.5815e-06  eta: 9:34:48  time: 0.4117  data_time: 0.0095  memory: 5970  grad_norm: 787.8639  loss: 20.5413  decode.loss_cls: 0.2631  decode.loss_mask: 1.0002  decode.loss_dice: 0.7308  decode.d0.loss_cls: 0.6904  decode.d0.loss_mask: 0.9734  decode.d0.loss_dice: 0.7430  decode.d1.loss_cls: 0.2709  decode.d1.loss_mask: 1.0008  decode.d1.loss_dice: 0.7763  decode.d2.loss_cls: 0.2625  decode.d2.loss_mask: 0.9850  decode.d2.loss_dice: 0.7393  decode.d3.loss_cls: 0.2574  decode.d3.loss_mask: 0.9945  decode.d3.loss_dice: 0.7496  decode.d4.loss_cls: 0.2381  decode.d4.loss_mask: 0.9970  decode.d4.loss_dice: 0.7632  decode.d5.loss_cls: 0.2418  decode.d5.loss_mask: 0.9925  decode.d5.loss_dice: 0.7487  decode.d6.loss_cls: 0.2958  decode.d6.loss_mask: 1.0069  decode.d6.loss_dice: 0.7782  decode.d7.loss_cls: 0.2783  decode.d7.loss_mask: 0.9816  decode.d7.loss_dice: 0.7455  decode.d8.loss_cls: 0.2695  decode.d8.loss_mask: 1.0086  decode.d8.loss_dice: 0.7584
05/26 19:57:12 - mmengine - INFO - Iter(train) [ 76350/160000]  base_lr: 5.5785e-05 lr: 5.5785e-06  eta: 9:34:28  time: 0.4123  data_time: 0.0095  memory: 5966  grad_norm: 843.3888  loss: 20.6293  decode.loss_cls: 0.2603  decode.loss_mask: 1.0169  decode.loss_dice: 0.7442  decode.d0.loss_cls: 0.6493  decode.d0.loss_mask: 0.9524  decode.d0.loss_dice: 0.7031  decode.d1.loss_cls: 0.2900  decode.d1.loss_mask: 0.9951  decode.d1.loss_dice: 0.7822  decode.d2.loss_cls: 0.2626  decode.d2.loss_mask: 1.0281  decode.d2.loss_dice: 0.7660  decode.d3.loss_cls: 0.2840  decode.d3.loss_mask: 1.0014  decode.d3.loss_dice: 0.7637  decode.d4.loss_cls: 0.3368  decode.d4.loss_mask: 0.9751  decode.d4.loss_dice: 0.7471  decode.d5.loss_cls: 0.2989  decode.d5.loss_mask: 0.9590  decode.d5.loss_dice: 0.7369  decode.d6.loss_cls: 0.2332  decode.d6.loss_mask: 1.0139  decode.d6.loss_dice: 0.7708  decode.d7.loss_cls: 0.2933  decode.d7.loss_mask: 1.0035  decode.d7.loss_dice: 0.7299  decode.d8.loss_cls: 0.2200  decode.d8.loss_mask: 1.0399  decode.d8.loss_dice: 0.7718
05/26 19:57:32 - mmengine - INFO - Iter(train) [ 76400/160000]  base_lr: 5.5755e-05 lr: 5.5755e-06  eta: 9:34:07  time: 0.4110  data_time: 0.0096  memory: 5969  grad_norm: 545.4807  loss: 16.6812  decode.loss_cls: 0.1601  decode.loss_mask: 0.8863  decode.loss_dice: 0.5851  decode.d0.loss_cls: 0.5438  decode.d0.loss_mask: 0.8542  decode.d0.loss_dice: 0.5564  decode.d1.loss_cls: 0.1410  decode.d1.loss_mask: 0.9120  decode.d1.loss_dice: 0.6161  decode.d2.loss_cls: 0.1551  decode.d2.loss_mask: 0.8403  decode.d2.loss_dice: 0.5944  decode.d3.loss_cls: 0.1406  decode.d3.loss_mask: 0.8671  decode.d3.loss_dice: 0.6118  decode.d4.loss_cls: 0.1498  decode.d4.loss_mask: 0.8586  decode.d4.loss_dice: 0.5872  decode.d5.loss_cls: 0.0938  decode.d5.loss_mask: 0.9375  decode.d5.loss_dice: 0.6136  decode.d6.loss_cls: 0.1942  decode.d6.loss_mask: 0.9060  decode.d6.loss_dice: 0.5862  decode.d7.loss_cls: 0.1738  decode.d7.loss_mask: 0.8995  decode.d7.loss_dice: 0.5942  decode.d8.loss_cls: 0.1328  decode.d8.loss_mask: 0.8753  decode.d8.loss_dice: 0.6142
05/26 19:57:53 - mmengine - INFO - Iter(train) [ 76450/160000]  base_lr: 5.5725e-05 lr: 5.5725e-06  eta: 9:33:46  time: 0.4109  data_time: 0.0096  memory: 5969  grad_norm: 752.5584  loss: 18.2575  decode.loss_cls: 0.1352  decode.loss_mask: 0.9838  decode.loss_dice: 0.6597  decode.d0.loss_cls: 0.5964  decode.d0.loss_mask: 0.9037  decode.d0.loss_dice: 0.6301  decode.d1.loss_cls: 0.1983  decode.d1.loss_mask: 0.9416  decode.d1.loss_dice: 0.6515  decode.d2.loss_cls: 0.1595  decode.d2.loss_mask: 1.0297  decode.d2.loss_dice: 0.6805  decode.d3.loss_cls: 0.1743  decode.d3.loss_mask: 0.9463  decode.d3.loss_dice: 0.6459  decode.d4.loss_cls: 0.2127  decode.d4.loss_mask: 0.9199  decode.d4.loss_dice: 0.6489  decode.d5.loss_cls: 0.1670  decode.d5.loss_mask: 0.9322  decode.d5.loss_dice: 0.6507  decode.d6.loss_cls: 0.1759  decode.d6.loss_mask: 0.9816  decode.d6.loss_dice: 0.6592  decode.d7.loss_cls: 0.2247  decode.d7.loss_mask: 0.9321  decode.d7.loss_dice: 0.6426  decode.d8.loss_cls: 0.1684  decode.d8.loss_mask: 0.9505  decode.d8.loss_dice: 0.6545
05/26 19:58:14 - mmengine - INFO - Iter(train) [ 76500/160000]  base_lr: 5.5694e-05 lr: 5.5694e-06  eta: 9:33:26  time: 0.4102  data_time: 0.0096  memory: 5967  grad_norm: 594.5367  loss: 18.8435  decode.loss_cls: 0.1094  decode.loss_mask: 1.0168  decode.loss_dice: 0.6824  decode.d0.loss_cls: 0.5651  decode.d0.loss_mask: 1.0403  decode.d0.loss_dice: 0.6927  decode.d1.loss_cls: 0.1089  decode.d1.loss_mask: 1.0566  decode.d1.loss_dice: 0.6968  decode.d2.loss_cls: 0.1258  decode.d2.loss_mask: 1.0378  decode.d2.loss_dice: 0.6864  decode.d3.loss_cls: 0.1310  decode.d3.loss_mask: 1.0149  decode.d3.loss_dice: 0.6624  decode.d4.loss_cls: 0.1204  decode.d4.loss_mask: 1.0263  decode.d4.loss_dice: 0.6891  decode.d5.loss_cls: 0.1192  decode.d5.loss_mask: 1.0482  decode.d5.loss_dice: 0.6973  decode.d6.loss_cls: 0.1306  decode.d6.loss_mask: 1.0241  decode.d6.loss_dice: 0.6776  decode.d7.loss_cls: 0.1266  decode.d7.loss_mask: 1.0332  decode.d7.loss_dice: 0.6838  decode.d8.loss_cls: 0.1407  decode.d8.loss_mask: 1.0198  decode.d8.loss_dice: 0.6793
05/26 19:58:34 - mmengine - INFO - Iter(train) [ 76550/160000]  base_lr: 5.5664e-05 lr: 5.5664e-06  eta: 9:33:05  time: 0.4102  data_time: 0.0096  memory: 5966  grad_norm: 413.4594  loss: 21.4472  decode.loss_cls: 0.2081  decode.loss_mask: 1.1316  decode.loss_dice: 0.7440  decode.d0.loss_cls: 0.7318  decode.d0.loss_mask: 1.0815  decode.d0.loss_dice: 0.7549  decode.d1.loss_cls: 0.2331  decode.d1.loss_mask: 1.1355  decode.d1.loss_dice: 0.7481  decode.d2.loss_cls: 0.2598  decode.d2.loss_mask: 1.0905  decode.d2.loss_dice: 0.7457  decode.d3.loss_cls: 0.2761  decode.d3.loss_mask: 1.0544  decode.d3.loss_dice: 0.7456  decode.d4.loss_cls: 0.2421  decode.d4.loss_mask: 1.0867  decode.d4.loss_dice: 0.7870  decode.d5.loss_cls: 0.2627  decode.d5.loss_mask: 1.0901  decode.d5.loss_dice: 0.7565  decode.d6.loss_cls: 0.2712  decode.d6.loss_mask: 1.1094  decode.d6.loss_dice: 0.7739  decode.d7.loss_cls: 0.2102  decode.d7.loss_mask: 1.1057  decode.d7.loss_dice: 0.7383  decode.d8.loss_cls: 0.2129  decode.d8.loss_mask: 1.1158  decode.d8.loss_dice: 0.7436
05/26 19:58:55 - mmengine - INFO - Iter(train) [ 76600/160000]  base_lr: 5.5634e-05 lr: 5.5634e-06  eta: 9:32:45  time: 0.4116  data_time: 0.0096  memory: 5976  grad_norm: 543.1893  loss: 20.9190  decode.loss_cls: 0.1533  decode.loss_mask: 1.1761  decode.loss_dice: 0.7455  decode.d0.loss_cls: 0.6746  decode.d0.loss_mask: 1.0414  decode.d0.loss_dice: 0.6930  decode.d1.loss_cls: 0.1515  decode.d1.loss_mask: 1.1132  decode.d1.loss_dice: 0.7334  decode.d2.loss_cls: 0.2238  decode.d2.loss_mask: 1.1269  decode.d2.loss_dice: 0.7482  decode.d3.loss_cls: 0.1945  decode.d3.loss_mask: 1.1590  decode.d3.loss_dice: 0.7362  decode.d4.loss_cls: 0.2505  decode.d4.loss_mask: 1.1230  decode.d4.loss_dice: 0.7285  decode.d5.loss_cls: 0.1841  decode.d5.loss_mask: 1.1416  decode.d5.loss_dice: 0.7194  decode.d6.loss_cls: 0.2190  decode.d6.loss_mask: 1.1100  decode.d6.loss_dice: 0.7171  decode.d7.loss_cls: 0.1863  decode.d7.loss_mask: 1.1306  decode.d7.loss_dice: 0.7289  decode.d8.loss_cls: 0.1477  decode.d8.loss_mask: 1.1319  decode.d8.loss_dice: 0.7294
05/26 19:59:15 - mmengine - INFO - Iter(train) [ 76650/160000]  base_lr: 5.5604e-05 lr: 5.5604e-06  eta: 9:32:24  time: 0.4116  data_time: 0.0096  memory: 5976  grad_norm: 386.8223  loss: 19.2664  decode.loss_cls: 0.2621  decode.loss_mask: 0.9418  decode.loss_dice: 0.6724  decode.d0.loss_cls: 0.7728  decode.d0.loss_mask: 0.8581  decode.d0.loss_dice: 0.6365  decode.d1.loss_cls: 0.2494  decode.d1.loss_mask: 0.9452  decode.d1.loss_dice: 0.6704  decode.d2.loss_cls: 0.2301  decode.d2.loss_mask: 0.9482  decode.d2.loss_dice: 0.6896  decode.d3.loss_cls: 0.2490  decode.d3.loss_mask: 0.9459  decode.d3.loss_dice: 0.6848  decode.d4.loss_cls: 0.2349  decode.d4.loss_mask: 0.9772  decode.d4.loss_dice: 0.7116  decode.d5.loss_cls: 0.2489  decode.d5.loss_mask: 0.9774  decode.d5.loss_dice: 0.7284  decode.d6.loss_cls: 0.2595  decode.d6.loss_mask: 0.9137  decode.d6.loss_dice: 0.6785  decode.d7.loss_cls: 0.2438  decode.d7.loss_mask: 0.9307  decode.d7.loss_dice: 0.6713  decode.d8.loss_cls: 0.2397  decode.d8.loss_mask: 0.9873  decode.d8.loss_dice: 0.7070
05/26 19:59:38 - mmengine - INFO - Iter(train) [ 76700/160000]  base_lr: 5.5574e-05 lr: 5.5574e-06  eta: 9:32:05  time: 0.6066  data_time: 0.0098  memory: 5969  grad_norm: 320.5361  loss: 19.3007  decode.loss_cls: 0.1868  decode.loss_mask: 0.9563  decode.loss_dice: 0.7177  decode.d0.loss_cls: 0.7109  decode.d0.loss_mask: 0.9249  decode.d0.loss_dice: 0.6884  decode.d1.loss_cls: 0.2281  decode.d1.loss_mask: 0.9145  decode.d1.loss_dice: 0.6873  decode.d2.loss_cls: 0.2473  decode.d2.loss_mask: 0.9428  decode.d2.loss_dice: 0.7240  decode.d3.loss_cls: 0.2353  decode.d3.loss_mask: 0.9149  decode.d3.loss_dice: 0.6817  decode.d4.loss_cls: 0.2371  decode.d4.loss_mask: 0.9347  decode.d4.loss_dice: 0.7303  decode.d5.loss_cls: 0.1945  decode.d5.loss_mask: 0.9746  decode.d5.loss_dice: 0.7515  decode.d6.loss_cls: 0.2134  decode.d6.loss_mask: 0.9835  decode.d6.loss_dice: 0.7427  decode.d7.loss_cls: 0.2331  decode.d7.loss_mask: 0.9118  decode.d7.loss_dice: 0.7257  decode.d8.loss_cls: 0.2124  decode.d8.loss_mask: 0.9477  decode.d8.loss_dice: 0.7466
05/26 19:59:58 - mmengine - INFO - Iter(train) [ 76750/160000]  base_lr: 5.5544e-05 lr: 5.5544e-06  eta: 9:31:45  time: 0.4114  data_time: 0.0096  memory: 5971  grad_norm: 529.6679  loss: 18.7830  decode.loss_cls: 0.2436  decode.loss_mask: 0.8901  decode.loss_dice: 0.6735  decode.d0.loss_cls: 0.6586  decode.d0.loss_mask: 0.8942  decode.d0.loss_dice: 0.6856  decode.d1.loss_cls: 0.2692  decode.d1.loss_mask: 0.9135  decode.d1.loss_dice: 0.6885  decode.d2.loss_cls: 0.2194  decode.d2.loss_mask: 0.9117  decode.d2.loss_dice: 0.7022  decode.d3.loss_cls: 0.2208  decode.d3.loss_mask: 0.9205  decode.d3.loss_dice: 0.6970  decode.d4.loss_cls: 0.2064  decode.d4.loss_mask: 0.9245  decode.d4.loss_dice: 0.7036  decode.d5.loss_cls: 0.2115  decode.d5.loss_mask: 0.9321  decode.d5.loss_dice: 0.6951  decode.d6.loss_cls: 0.2594  decode.d6.loss_mask: 0.9142  decode.d6.loss_dice: 0.6828  decode.d7.loss_cls: 0.2590  decode.d7.loss_mask: 0.9144  decode.d7.loss_dice: 0.6837  decode.d8.loss_cls: 0.2104  decode.d8.loss_mask: 0.8875  decode.d8.loss_dice: 0.7100
05/26 20:00:19 - mmengine - INFO - Iter(train) [ 76800/160000]  base_lr: 5.5514e-05 lr: 5.5514e-06  eta: 9:31:24  time: 0.4128  data_time: 0.0097  memory: 5967  grad_norm: 653.6268  loss: 22.2647  decode.loss_cls: 0.2683  decode.loss_mask: 1.1191  decode.loss_dice: 0.7854  decode.d0.loss_cls: 0.6366  decode.d0.loss_mask: 1.0768  decode.d0.loss_dice: 0.8440  decode.d1.loss_cls: 0.2674  decode.d1.loss_mask: 1.1154  decode.d1.loss_dice: 0.8022  decode.d2.loss_cls: 0.2862  decode.d2.loss_mask: 1.1150  decode.d2.loss_dice: 0.7860  decode.d3.loss_cls: 0.2539  decode.d3.loss_mask: 1.1210  decode.d3.loss_dice: 0.8043  decode.d4.loss_cls: 0.3170  decode.d4.loss_mask: 1.0927  decode.d4.loss_dice: 0.7873  decode.d5.loss_cls: 0.2875  decode.d5.loss_mask: 1.0978  decode.d5.loss_dice: 0.8020  decode.d6.loss_cls: 0.2943  decode.d6.loss_mask: 1.1042  decode.d6.loss_dice: 0.7905  decode.d7.loss_cls: 0.3126  decode.d7.loss_mask: 1.1044  decode.d7.loss_dice: 0.7798  decode.d8.loss_cls: 0.2933  decode.d8.loss_mask: 1.1294  decode.d8.loss_dice: 0.7902
05/26 20:00:40 - mmengine - INFO - Iter(train) [ 76850/160000]  base_lr: 5.5484e-05 lr: 5.5484e-06  eta: 9:31:04  time: 0.4110  data_time: 0.0096  memory: 5968  grad_norm: 795.9358  loss: 21.3425  decode.loss_cls: 0.2066  decode.loss_mask: 1.1397  decode.loss_dice: 0.7185  decode.d0.loss_cls: 0.7492  decode.d0.loss_mask: 1.0626  decode.d0.loss_dice: 0.7229  decode.d1.loss_cls: 0.2660  decode.d1.loss_mask: 1.1337  decode.d1.loss_dice: 0.7012  decode.d2.loss_cls: 0.2629  decode.d2.loss_mask: 1.1385  decode.d2.loss_dice: 0.7342  decode.d3.loss_cls: 0.2300  decode.d3.loss_mask: 1.1374  decode.d3.loss_dice: 0.7406  decode.d4.loss_cls: 0.2210  decode.d4.loss_mask: 1.1184  decode.d4.loss_dice: 0.7183  decode.d5.loss_cls: 0.2069  decode.d5.loss_mask: 1.1105  decode.d5.loss_dice: 0.7391  decode.d6.loss_cls: 0.2361  decode.d6.loss_mask: 1.1037  decode.d6.loss_dice: 0.7536  decode.d7.loss_cls: 0.2664  decode.d7.loss_mask: 1.1018  decode.d7.loss_dice: 0.7474  decode.d8.loss_cls: 0.2243  decode.d8.loss_mask: 1.1256  decode.d8.loss_dice: 0.7255
05/26 20:01:00 - mmengine - INFO - Iter(train) [ 76900/160000]  base_lr: 5.5454e-05 lr: 5.5454e-06  eta: 9:30:43  time: 0.4123  data_time: 0.0097  memory: 5983  grad_norm: 587.8870  loss: 18.7888  decode.loss_cls: 0.2009  decode.loss_mask: 0.8826  decode.loss_dice: 0.7682  decode.d0.loss_cls: 0.7199  decode.d0.loss_mask: 0.8269  decode.d0.loss_dice: 0.7063  decode.d1.loss_cls: 0.2238  decode.d1.loss_mask: 0.8949  decode.d1.loss_dice: 0.7312  decode.d2.loss_cls: 0.1863  decode.d2.loss_mask: 0.8805  decode.d2.loss_dice: 0.7495  decode.d3.loss_cls: 0.1924  decode.d3.loss_mask: 0.8857  decode.d3.loss_dice: 0.7523  decode.d4.loss_cls: 0.2136  decode.d4.loss_mask: 0.8918  decode.d4.loss_dice: 0.7505  decode.d5.loss_cls: 0.1812  decode.d5.loss_mask: 0.8797  decode.d5.loss_dice: 0.7515  decode.d6.loss_cls: 0.1748  decode.d6.loss_mask: 0.9041  decode.d6.loss_dice: 0.7663  decode.d7.loss_cls: 0.2075  decode.d7.loss_mask: 0.8780  decode.d7.loss_dice: 0.7576  decode.d8.loss_cls: 0.1984  decode.d8.loss_mask: 0.8827  decode.d8.loss_dice: 0.7501
05/26 20:01:21 - mmengine - INFO - Iter(train) [ 76950/160000]  base_lr: 5.5424e-05 lr: 5.5424e-06  eta: 9:30:22  time: 0.4130  data_time: 0.0098  memory: 5966  grad_norm: 735.7541  loss: 21.8128  decode.loss_cls: 0.1951  decode.loss_mask: 1.2491  decode.loss_dice: 0.6894  decode.d0.loss_cls: 0.6521  decode.d0.loss_mask: 1.1835  decode.d0.loss_dice: 0.7004  decode.d1.loss_cls: 0.2288  decode.d1.loss_mask: 1.2447  decode.d1.loss_dice: 0.6693  decode.d2.loss_cls: 0.2356  decode.d2.loss_mask: 1.2025  decode.d2.loss_dice: 0.6552  decode.d3.loss_cls: 0.1660  decode.d3.loss_mask: 1.2594  decode.d3.loss_dice: 0.6657  decode.d4.loss_cls: 0.2193  decode.d4.loss_mask: 1.2685  decode.d4.loss_dice: 0.6647  decode.d5.loss_cls: 0.2171  decode.d5.loss_mask: 1.2714  decode.d5.loss_dice: 0.6649  decode.d6.loss_cls: 0.1680  decode.d6.loss_mask: 1.3494  decode.d6.loss_dice: 0.6964  decode.d7.loss_cls: 0.2010  decode.d7.loss_mask: 1.2491  decode.d7.loss_dice: 0.7101  decode.d8.loss_cls: 0.2105  decode.d8.loss_mask: 1.2563  decode.d8.loss_dice: 0.6691
05/26 20:01:42 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 20:01:42 - mmengine - INFO - Iter(train) [ 77000/160000]  base_lr: 5.5394e-05 lr: 5.5394e-06  eta: 9:30:02  time: 0.4129  data_time: 0.0097  memory: 5966  grad_norm: 444.3386  loss: 18.9548  decode.loss_cls: 0.1785  decode.loss_mask: 1.0215  decode.loss_dice: 0.6431  decode.d0.loss_cls: 0.6135  decode.d0.loss_mask: 0.9443  decode.d0.loss_dice: 0.6198  decode.d1.loss_cls: 0.2214  decode.d1.loss_mask: 0.9891  decode.d1.loss_dice: 0.6416  decode.d2.loss_cls: 0.2167  decode.d2.loss_mask: 0.9999  decode.d2.loss_dice: 0.6260  decode.d3.loss_cls: 0.1977  decode.d3.loss_mask: 1.0532  decode.d3.loss_dice: 0.6310  decode.d4.loss_cls: 0.1788  decode.d4.loss_mask: 1.0570  decode.d4.loss_dice: 0.6968  decode.d5.loss_cls: 0.1665  decode.d5.loss_mask: 0.9960  decode.d5.loss_dice: 0.6328  decode.d6.loss_cls: 0.1864  decode.d6.loss_mask: 1.0169  decode.d6.loss_dice: 0.6591  decode.d7.loss_cls: 0.1622  decode.d7.loss_mask: 1.0593  decode.d7.loss_dice: 0.6707  decode.d8.loss_cls: 0.2032  decode.d8.loss_mask: 1.0135  decode.d8.loss_dice: 0.6583
05/26 20:02:02 - mmengine - INFO - Iter(train) [ 77050/160000]  base_lr: 5.5364e-05 lr: 5.5364e-06  eta: 9:29:41  time: 0.4116  data_time: 0.0096  memory: 5967  grad_norm: 1047.4922  loss: 23.8331  decode.loss_cls: 0.2799  decode.loss_mask: 1.1474  decode.loss_dice: 0.8801  decode.d0.loss_cls: 0.7421  decode.d0.loss_mask: 1.1027  decode.d0.loss_dice: 0.8292  decode.d1.loss_cls: 0.3081  decode.d1.loss_mask: 1.1490  decode.d1.loss_dice: 0.8832  decode.d2.loss_cls: 0.2931  decode.d2.loss_mask: 1.1673  decode.d2.loss_dice: 0.8596  decode.d3.loss_cls: 0.3101  decode.d3.loss_mask: 1.1697  decode.d3.loss_dice: 0.8581  decode.d4.loss_cls: 0.3057  decode.d4.loss_mask: 1.1782  decode.d4.loss_dice: 0.8529  decode.d5.loss_cls: 0.2851  decode.d5.loss_mask: 1.1855  decode.d5.loss_dice: 0.8690  decode.d6.loss_cls: 0.3178  decode.d6.loss_mask: 1.1972  decode.d6.loss_dice: 0.9268  decode.d7.loss_cls: 0.3013  decode.d7.loss_mask: 1.1668  decode.d7.loss_dice: 0.9000  decode.d8.loss_cls: 0.3374  decode.d8.loss_mask: 1.1373  decode.d8.loss_dice: 0.8924
05/26 20:02:23 - mmengine - INFO - Iter(train) [ 77100/160000]  base_lr: 5.5334e-05 lr: 5.5334e-06  eta: 9:29:21  time: 0.4116  data_time: 0.0096  memory: 5976  grad_norm: 628.5317  loss: 22.4301  decode.loss_cls: 0.2701  decode.loss_mask: 1.0912  decode.loss_dice: 0.8157  decode.d0.loss_cls: 0.8192  decode.d0.loss_mask: 1.0423  decode.d0.loss_dice: 0.7757  decode.d1.loss_cls: 0.2662  decode.d1.loss_mask: 1.0968  decode.d1.loss_dice: 0.8158  decode.d2.loss_cls: 0.2369  decode.d2.loss_mask: 1.1312  decode.d2.loss_dice: 0.8178  decode.d3.loss_cls: 0.2636  decode.d3.loss_mask: 1.1073  decode.d3.loss_dice: 0.8120  decode.d4.loss_cls: 0.2680  decode.d4.loss_mask: 1.1281  decode.d4.loss_dice: 0.8372  decode.d5.loss_cls: 0.2999  decode.d5.loss_mask: 1.0833  decode.d5.loss_dice: 0.8004  decode.d6.loss_cls: 0.2857  decode.d6.loss_mask: 1.1307  decode.d6.loss_dice: 0.8255  decode.d7.loss_cls: 0.2707  decode.d7.loss_mask: 1.0991  decode.d7.loss_dice: 0.7982  decode.d8.loss_cls: 0.2881  decode.d8.loss_mask: 1.1201  decode.d8.loss_dice: 0.8335
05/26 20:02:43 - mmengine - INFO - Iter(train) [ 77150/160000]  base_lr: 5.5304e-05 lr: 5.5304e-06  eta: 9:29:00  time: 0.4119  data_time: 0.0097  memory: 5984  grad_norm: 994.3458  loss: 22.0146  decode.loss_cls: 0.2176  decode.loss_mask: 1.1019  decode.loss_dice: 0.8015  decode.d0.loss_cls: 0.7014  decode.d0.loss_mask: 1.0190  decode.d0.loss_dice: 0.8333  decode.d1.loss_cls: 0.2287  decode.d1.loss_mask: 1.0748  decode.d1.loss_dice: 0.8179  decode.d2.loss_cls: 0.2166  decode.d2.loss_mask: 1.1141  decode.d2.loss_dice: 0.7992  decode.d3.loss_cls: 0.2640  decode.d3.loss_mask: 1.0345  decode.d3.loss_dice: 0.7965  decode.d4.loss_cls: 0.2585  decode.d4.loss_mask: 1.1165  decode.d4.loss_dice: 0.8448  decode.d5.loss_cls: 0.2727  decode.d5.loss_mask: 1.0928  decode.d5.loss_dice: 0.8131  decode.d6.loss_cls: 0.2960  decode.d6.loss_mask: 1.1064  decode.d6.loss_dice: 0.8184  decode.d7.loss_cls: 0.2541  decode.d7.loss_mask: 1.1493  decode.d7.loss_dice: 0.8041  decode.d8.loss_cls: 0.2264  decode.d8.loss_mask: 1.1253  decode.d8.loss_dice: 0.8151
05/26 20:03:05 - mmengine - INFO - Iter(train) [ 77200/160000]  base_lr: 5.5274e-05 lr: 5.5274e-06  eta: 9:28:41  time: 0.4111  data_time: 0.0096  memory: 5969  grad_norm: 944.0024  loss: 22.8144  decode.loss_cls: 0.1812  decode.loss_mask: 1.1413  decode.loss_dice: 0.8652  decode.d0.loss_cls: 0.7295  decode.d0.loss_mask: 1.0893  decode.d0.loss_dice: 0.8629  decode.d1.loss_cls: 0.2610  decode.d1.loss_mask: 1.1216  decode.d1.loss_dice: 0.8894  decode.d2.loss_cls: 0.2209  decode.d2.loss_mask: 1.1815  decode.d2.loss_dice: 0.9063  decode.d3.loss_cls: 0.2348  decode.d3.loss_mask: 1.1224  decode.d3.loss_dice: 0.8593  decode.d4.loss_cls: 0.2174  decode.d4.loss_mask: 1.1397  decode.d4.loss_dice: 0.8767  decode.d5.loss_cls: 0.2348  decode.d5.loss_mask: 1.1215  decode.d5.loss_dice: 0.8578  decode.d6.loss_cls: 0.2170  decode.d6.loss_mask: 1.1702  decode.d6.loss_dice: 0.9148  decode.d7.loss_cls: 0.2168  decode.d7.loss_mask: 1.1298  decode.d7.loss_dice: 0.8677  decode.d8.loss_cls: 0.2148  decode.d8.loss_mask: 1.1275  decode.d8.loss_dice: 0.8414
05/26 20:03:26 - mmengine - INFO - Iter(train) [ 77250/160000]  base_lr: 5.5244e-05 lr: 5.5244e-06  eta: 9:28:20  time: 0.4114  data_time: 0.0097  memory: 5969  grad_norm: 480.9180  loss: 24.2461  decode.loss_cls: 0.2704  decode.loss_mask: 1.1342  decode.loss_dice: 0.9239  decode.d0.loss_cls: 0.7644  decode.d0.loss_mask: 1.1290  decode.d0.loss_dice: 0.9096  decode.d1.loss_cls: 0.3167  decode.d1.loss_mask: 1.1745  decode.d1.loss_dice: 0.9291  decode.d2.loss_cls: 0.2454  decode.d2.loss_mask: 1.1818  decode.d2.loss_dice: 0.9621  decode.d3.loss_cls: 0.2698  decode.d3.loss_mask: 1.1547  decode.d3.loss_dice: 0.9266  decode.d4.loss_cls: 0.2470  decode.d4.loss_mask: 1.1922  decode.d4.loss_dice: 0.9849  decode.d5.loss_cls: 0.2873  decode.d5.loss_mask: 1.1717  decode.d5.loss_dice: 0.9441  decode.d6.loss_cls: 0.3037  decode.d6.loss_mask: 1.1685  decode.d6.loss_dice: 0.9363  decode.d7.loss_cls: 0.2949  decode.d7.loss_mask: 1.1564  decode.d7.loss_dice: 0.9292  decode.d8.loss_cls: 0.2464  decode.d8.loss_mask: 1.1600  decode.d8.loss_dice: 0.9313
05/26 20:03:46 - mmengine - INFO - Iter(train) [ 77300/160000]  base_lr: 5.5214e-05 lr: 5.5214e-06  eta: 9:27:59  time: 0.4111  data_time: 0.0096  memory: 5976  grad_norm: 350.5797  loss: 20.3408  decode.loss_cls: 0.1359  decode.loss_mask: 1.1518  decode.loss_dice: 0.6924  decode.d0.loss_cls: 0.5435  decode.d0.loss_mask: 1.1147  decode.d0.loss_dice: 0.6944  decode.d1.loss_cls: 0.1404  decode.d1.loss_mask: 1.1545  decode.d1.loss_dice: 0.7167  decode.d2.loss_cls: 0.1628  decode.d2.loss_mask: 1.1458  decode.d2.loss_dice: 0.7149  decode.d3.loss_cls: 0.1656  decode.d3.loss_mask: 1.1222  decode.d3.loss_dice: 0.6934  decode.d4.loss_cls: 0.1506  decode.d4.loss_mask: 1.1498  decode.d4.loss_dice: 0.7009  decode.d5.loss_cls: 0.1349  decode.d5.loss_mask: 1.1462  decode.d5.loss_dice: 0.7116  decode.d6.loss_cls: 0.1223  decode.d6.loss_mask: 1.1542  decode.d6.loss_dice: 0.7274  decode.d7.loss_cls: 0.1293  decode.d7.loss_mask: 1.1572  decode.d7.loss_dice: 0.7112  decode.d8.loss_cls: 0.1390  decode.d8.loss_mask: 1.1485  decode.d8.loss_dice: 0.7089
05/26 20:04:07 - mmengine - INFO - Iter(train) [ 77350/160000]  base_lr: 5.5184e-05 lr: 5.5184e-06  eta: 9:27:39  time: 0.4138  data_time: 0.0109  memory: 5972  grad_norm: 870.6175  loss: 24.9742  decode.loss_cls: 0.2266  decode.loss_mask: 1.2001  decode.loss_dice: 0.9589  decode.d0.loss_cls: 0.8689  decode.d0.loss_mask: 1.1731  decode.d0.loss_dice: 0.9196  decode.d1.loss_cls: 0.2600  decode.d1.loss_mask: 1.2427  decode.d1.loss_dice: 0.9400  decode.d2.loss_cls: 0.2187  decode.d2.loss_mask: 1.3069  decode.d2.loss_dice: 0.9708  decode.d3.loss_cls: 0.2059  decode.d3.loss_mask: 1.2697  decode.d3.loss_dice: 0.9772  decode.d4.loss_cls: 0.2958  decode.d4.loss_mask: 1.2078  decode.d4.loss_dice: 0.9565  decode.d5.loss_cls: 0.2369  decode.d5.loss_mask: 1.2612  decode.d5.loss_dice: 0.9471  decode.d6.loss_cls: 0.2655  decode.d6.loss_mask: 1.2435  decode.d6.loss_dice: 0.9575  decode.d7.loss_cls: 0.1911  decode.d7.loss_mask: 1.2536  decode.d7.loss_dice: 0.9717  decode.d8.loss_cls: 0.2459  decode.d8.loss_mask: 1.2300  decode.d8.loss_dice: 0.9707
05/26 20:04:28 - mmengine - INFO - Iter(train) [ 77400/160000]  base_lr: 5.5154e-05 lr: 5.5154e-06  eta: 9:27:18  time: 0.4125  data_time: 0.0096  memory: 5968  grad_norm: 631.4896  loss: 23.7952  decode.loss_cls: 0.3116  decode.loss_mask: 1.2487  decode.loss_dice: 0.7789  decode.d0.loss_cls: 0.8219  decode.d0.loss_mask: 1.1155  decode.d0.loss_dice: 0.8083  decode.d1.loss_cls: 0.3358  decode.d1.loss_mask: 1.1991  decode.d1.loss_dice: 0.7769  decode.d2.loss_cls: 0.3699  decode.d2.loss_mask: 1.1925  decode.d2.loss_dice: 0.7613  decode.d3.loss_cls: 0.3214  decode.d3.loss_mask: 1.2399  decode.d3.loss_dice: 0.7963  decode.d4.loss_cls: 0.3519  decode.d4.loss_mask: 1.2363  decode.d4.loss_dice: 0.8005  decode.d5.loss_cls: 0.3425  decode.d5.loss_mask: 1.1999  decode.d5.loss_dice: 0.7682  decode.d6.loss_cls: 0.3381  decode.d6.loss_mask: 1.1954  decode.d6.loss_dice: 0.7968  decode.d7.loss_cls: 0.3146  decode.d7.loss_mask: 1.2284  decode.d7.loss_dice: 0.7604  decode.d8.loss_cls: 0.3539  decode.d8.loss_mask: 1.2568  decode.d8.loss_dice: 0.7733
05/26 20:04:48 - mmengine - INFO - Iter(train) [ 77450/160000]  base_lr: 5.5124e-05 lr: 5.5124e-06  eta: 9:26:58  time: 0.4135  data_time: 0.0096  memory: 5987  grad_norm: 387.3970  loss: 20.0411  decode.loss_cls: 0.2848  decode.loss_mask: 0.9057  decode.loss_dice: 0.7346  decode.d0.loss_cls: 0.7959  decode.d0.loss_mask: 0.9114  decode.d0.loss_dice: 0.7542  decode.d1.loss_cls: 0.2402  decode.d1.loss_mask: 0.9767  decode.d1.loss_dice: 0.7739  decode.d2.loss_cls: 0.2572  decode.d2.loss_mask: 0.9299  decode.d2.loss_dice: 0.7355  decode.d3.loss_cls: 0.2637  decode.d3.loss_mask: 0.9333  decode.d3.loss_dice: 0.7623  decode.d4.loss_cls: 0.2927  decode.d4.loss_mask: 0.9134  decode.d4.loss_dice: 0.7795  decode.d5.loss_cls: 0.2589  decode.d5.loss_mask: 0.9095  decode.d5.loss_dice: 0.7573  decode.d6.loss_cls: 0.3034  decode.d6.loss_mask: 0.9178  decode.d6.loss_dice: 0.7746  decode.d7.loss_cls: 0.2569  decode.d7.loss_mask: 0.9197  decode.d7.loss_dice: 0.7740  decode.d8.loss_cls: 0.2604  decode.d8.loss_mask: 0.9292  decode.d8.loss_dice: 0.7346
05/26 20:05:09 - mmengine - INFO - Iter(train) [ 77500/160000]  base_lr: 5.5094e-05 lr: 5.5094e-06  eta: 9:26:37  time: 0.4134  data_time: 0.0096  memory: 5968  grad_norm: 386.8962  loss: 20.2389  decode.loss_cls: 0.2082  decode.loss_mask: 0.9460  decode.loss_dice: 0.8146  decode.d0.loss_cls: 0.6183  decode.d0.loss_mask: 0.9594  decode.d0.loss_dice: 0.8049  decode.d1.loss_cls: 0.1680  decode.d1.loss_mask: 0.9440  decode.d1.loss_dice: 0.8502  decode.d2.loss_cls: 0.2084  decode.d2.loss_mask: 0.9382  decode.d2.loss_dice: 0.8392  decode.d3.loss_cls: 0.2143  decode.d3.loss_mask: 0.9364  decode.d3.loss_dice: 0.8362  decode.d4.loss_cls: 0.1954  decode.d4.loss_mask: 0.9600  decode.d4.loss_dice: 0.8336  decode.d5.loss_cls: 0.2138  decode.d5.loss_mask: 0.9569  decode.d5.loss_dice: 0.8319  decode.d6.loss_cls: 0.2051  decode.d6.loss_mask: 0.9549  decode.d6.loss_dice: 0.8388  decode.d7.loss_cls: 0.1794  decode.d7.loss_mask: 0.9579  decode.d7.loss_dice: 0.8439  decode.d8.loss_cls: 0.1904  decode.d8.loss_mask: 0.9522  decode.d8.loss_dice: 0.8383
05/26 20:05:30 - mmengine - INFO - Iter(train) [ 77550/160000]  base_lr: 5.5064e-05 lr: 5.5064e-06  eta: 9:26:17  time: 0.4120  data_time: 0.0096  memory: 5981  grad_norm: 383.9596  loss: 19.6676  decode.loss_cls: 0.2305  decode.loss_mask: 0.9726  decode.loss_dice: 0.6768  decode.d0.loss_cls: 0.6259  decode.d0.loss_mask: 0.9677  decode.d0.loss_dice: 0.7207  decode.d1.loss_cls: 0.2301  decode.d1.loss_mask: 0.9947  decode.d1.loss_dice: 0.7178  decode.d2.loss_cls: 0.2469  decode.d2.loss_mask: 0.9725  decode.d2.loss_dice: 0.6991  decode.d3.loss_cls: 0.2265  decode.d3.loss_mask: 0.9922  decode.d3.loss_dice: 0.6899  decode.d4.loss_cls: 0.2307  decode.d4.loss_mask: 1.0340  decode.d4.loss_dice: 0.7174  decode.d5.loss_cls: 0.2821  decode.d5.loss_mask: 0.9710  decode.d5.loss_dice: 0.6904  decode.d6.loss_cls: 0.2517  decode.d6.loss_mask: 1.0303  decode.d6.loss_dice: 0.6959  decode.d7.loss_cls: 0.2742  decode.d7.loss_mask: 0.9740  decode.d7.loss_dice: 0.6660  decode.d8.loss_cls: 0.2277  decode.d8.loss_mask: 0.9714  decode.d8.loss_dice: 0.6868
05/26 20:05:50 - mmengine - INFO - Iter(train) [ 77600/160000]  base_lr: 5.5034e-05 lr: 5.5034e-06  eta: 9:25:56  time: 0.4120  data_time: 0.0097  memory: 5985  grad_norm: 886.1507  loss: 19.5506  decode.loss_cls: 0.1745  decode.loss_mask: 0.9782  decode.loss_dice: 0.7225  decode.d0.loss_cls: 0.6259  decode.d0.loss_mask: 0.9889  decode.d0.loss_dice: 0.7276  decode.d1.loss_cls: 0.1461  decode.d1.loss_mask: 1.0104  decode.d1.loss_dice: 0.7577  decode.d2.loss_cls: 0.1385  decode.d2.loss_mask: 1.0474  decode.d2.loss_dice: 0.7666  decode.d3.loss_cls: 0.1675  decode.d3.loss_mask: 0.9911  decode.d3.loss_dice: 0.7188  decode.d4.loss_cls: 0.1584  decode.d4.loss_mask: 1.0062  decode.d4.loss_dice: 0.7381  decode.d5.loss_cls: 0.1505  decode.d5.loss_mask: 0.9837  decode.d5.loss_dice: 0.7539  decode.d6.loss_cls: 0.1618  decode.d6.loss_mask: 1.0272  decode.d6.loss_dice: 0.7567  decode.d7.loss_cls: 0.1664  decode.d7.loss_mask: 0.9988  decode.d7.loss_dice: 0.7455  decode.d8.loss_cls: 0.2036  decode.d8.loss_mask: 1.0137  decode.d8.loss_dice: 0.7245
05/26 20:06:11 - mmengine - INFO - Iter(train) [ 77650/160000]  base_lr: 5.5004e-05 lr: 5.5004e-06  eta: 9:25:35  time: 0.4111  data_time: 0.0096  memory: 5965  grad_norm: 1105.2545  loss: 26.7315  decode.loss_cls: 0.3491  decode.loss_mask: 1.3957  decode.loss_dice: 0.9030  decode.d0.loss_cls: 0.8210  decode.d0.loss_mask: 1.2924  decode.d0.loss_dice: 0.8738  decode.d1.loss_cls: 0.3806  decode.d1.loss_mask: 1.3632  decode.d1.loss_dice: 0.9162  decode.d2.loss_cls: 0.3925  decode.d2.loss_mask: 1.3480  decode.d2.loss_dice: 0.9183  decode.d3.loss_cls: 0.3985  decode.d3.loss_mask: 1.2712  decode.d3.loss_dice: 0.9042  decode.d4.loss_cls: 0.3917  decode.d4.loss_mask: 1.3326  decode.d4.loss_dice: 0.9381  decode.d5.loss_cls: 0.3424  decode.d5.loss_mask: 1.3246  decode.d5.loss_dice: 0.9873  decode.d6.loss_cls: 0.4096  decode.d6.loss_mask: 1.2911  decode.d6.loss_dice: 0.8802  decode.d7.loss_cls: 0.3482  decode.d7.loss_mask: 1.4217  decode.d7.loss_dice: 0.9025  decode.d8.loss_cls: 0.3314  decode.d8.loss_mask: 1.4029  decode.d8.loss_dice: 0.8995
05/26 20:06:32 - mmengine - INFO - Iter(train) [ 77700/160000]  base_lr: 5.4974e-05 lr: 5.4974e-06  eta: 9:25:15  time: 0.4111  data_time: 0.0096  memory: 5966  grad_norm: 506.4733  loss: 21.1094  decode.loss_cls: 0.2697  decode.loss_mask: 1.0300  decode.loss_dice: 0.7941  decode.d0.loss_cls: 0.7708  decode.d0.loss_mask: 0.9548  decode.d0.loss_dice: 0.7808  decode.d1.loss_cls: 0.2881  decode.d1.loss_mask: 1.0112  decode.d1.loss_dice: 0.7993  decode.d2.loss_cls: 0.2594  decode.d2.loss_mask: 0.9883  decode.d2.loss_dice: 0.7775  decode.d3.loss_cls: 0.3106  decode.d3.loss_mask: 0.9626  decode.d3.loss_dice: 0.7772  decode.d4.loss_cls: 0.2453  decode.d4.loss_mask: 0.9824  decode.d4.loss_dice: 0.8059  decode.d5.loss_cls: 0.2703  decode.d5.loss_mask: 0.9981  decode.d5.loss_dice: 0.8256  decode.d6.loss_cls: 0.2527  decode.d6.loss_mask: 1.0142  decode.d6.loss_dice: 0.8212  decode.d7.loss_cls: 0.2547  decode.d7.loss_mask: 1.0036  decode.d7.loss_dice: 0.8001  decode.d8.loss_cls: 0.2908  decode.d8.loss_mask: 0.9845  decode.d8.loss_dice: 0.7856
05/26 20:06:52 - mmengine - INFO - Iter(train) [ 77750/160000]  base_lr: 5.4944e-05 lr: 5.4944e-06  eta: 9:24:54  time: 0.4154  data_time: 0.0098  memory: 5968  grad_norm: 847.3909  loss: 25.4670  decode.loss_cls: 0.3512  decode.loss_mask: 1.2422  decode.loss_dice: 0.8040  decode.d0.loss_cls: 0.9505  decode.d0.loss_mask: 1.2264  decode.d0.loss_dice: 0.8270  decode.d1.loss_cls: 0.3647  decode.d1.loss_mask: 1.3494  decode.d1.loss_dice: 0.8557  decode.d2.loss_cls: 0.3031  decode.d2.loss_mask: 1.3113  decode.d2.loss_dice: 0.8824  decode.d3.loss_cls: 0.2929  decode.d3.loss_mask: 1.3883  decode.d3.loss_dice: 0.8839  decode.d4.loss_cls: 0.2981  decode.d4.loss_mask: 1.3312  decode.d4.loss_dice: 0.8942  decode.d5.loss_cls: 0.2963  decode.d5.loss_mask: 1.3094  decode.d5.loss_dice: 0.8676  decode.d6.loss_cls: 0.3689  decode.d6.loss_mask: 1.3199  decode.d6.loss_dice: 0.8478  decode.d7.loss_cls: 0.3340  decode.d7.loss_mask: 1.2978  decode.d7.loss_dice: 0.8178  decode.d8.loss_cls: 0.2382  decode.d8.loss_mask: 1.3304  decode.d8.loss_dice: 0.8826
05/26 20:07:13 - mmengine - INFO - Iter(train) [ 77800/160000]  base_lr: 5.4913e-05 lr: 5.4913e-06  eta: 9:24:34  time: 0.4109  data_time: 0.0097  memory: 5969  grad_norm: 798.8334  loss: 24.8781  decode.loss_cls: 0.3429  decode.loss_mask: 1.1887  decode.loss_dice: 0.8210  decode.d0.loss_cls: 0.7217  decode.d0.loss_mask: 1.2357  decode.d0.loss_dice: 0.9099  decode.d1.loss_cls: 0.3538  decode.d1.loss_mask: 1.1792  decode.d1.loss_dice: 0.8698  decode.d2.loss_cls: 0.2975  decode.d2.loss_mask: 1.2718  decode.d2.loss_dice: 0.8929  decode.d3.loss_cls: 0.3055  decode.d3.loss_mask: 1.2941  decode.d3.loss_dice: 0.8825  decode.d4.loss_cls: 0.3797  decode.d4.loss_mask: 1.2557  decode.d4.loss_dice: 0.8575  decode.d5.loss_cls: 0.2805  decode.d5.loss_mask: 1.3090  decode.d5.loss_dice: 0.9180  decode.d6.loss_cls: 0.3296  decode.d6.loss_mask: 1.2430  decode.d6.loss_dice: 0.9084  decode.d7.loss_cls: 0.3306  decode.d7.loss_mask: 1.2703  decode.d7.loss_dice: 0.8437  decode.d8.loss_cls: 0.3535  decode.d8.loss_mask: 1.2007  decode.d8.loss_dice: 0.8307
05/26 20:07:34 - mmengine - INFO - Iter(train) [ 77850/160000]  base_lr: 5.4883e-05 lr: 5.4883e-06  eta: 9:24:13  time: 0.4114  data_time: 0.0097  memory: 5984  grad_norm: 561.7809  loss: 22.5241  decode.loss_cls: 0.1651  decode.loss_mask: 1.1480  decode.loss_dice: 0.9043  decode.d0.loss_cls: 0.7758  decode.d0.loss_mask: 1.0742  decode.d0.loss_dice: 0.8856  decode.d1.loss_cls: 0.1755  decode.d1.loss_mask: 1.1040  decode.d1.loss_dice: 0.9055  decode.d2.loss_cls: 0.1910  decode.d2.loss_mask: 1.1113  decode.d2.loss_dice: 0.8954  decode.d3.loss_cls: 0.2027  decode.d3.loss_mask: 1.0720  decode.d3.loss_dice: 0.8612  decode.d4.loss_cls: 0.2038  decode.d4.loss_mask: 1.1273  decode.d4.loss_dice: 0.8991  decode.d5.loss_cls: 0.2178  decode.d5.loss_mask: 1.0899  decode.d5.loss_dice: 0.8858  decode.d6.loss_cls: 0.2196  decode.d6.loss_mask: 1.0665  decode.d6.loss_dice: 0.8887  decode.d7.loss_cls: 0.2151  decode.d7.loss_mask: 1.0984  decode.d7.loss_dice: 0.8752  decode.d8.loss_cls: 0.2590  decode.d8.loss_mask: 1.1092  decode.d8.loss_dice: 0.8972
05/26 20:07:54 - mmengine - INFO - Iter(train) [ 77900/160000]  base_lr: 5.4853e-05 lr: 5.4853e-06  eta: 9:23:53  time: 0.4112  data_time: 0.0097  memory: 5989  grad_norm: 499.1829  loss: 22.1765  decode.loss_cls: 0.2117  decode.loss_mask: 1.0910  decode.loss_dice: 0.8414  decode.d0.loss_cls: 0.6269  decode.d0.loss_mask: 1.0700  decode.d0.loss_dice: 0.8077  decode.d1.loss_cls: 0.2272  decode.d1.loss_mask: 1.1191  decode.d1.loss_dice: 0.8571  decode.d2.loss_cls: 0.2375  decode.d2.loss_mask: 1.1091  decode.d2.loss_dice: 0.8350  decode.d3.loss_cls: 0.2112  decode.d3.loss_mask: 1.1109  decode.d3.loss_dice: 0.8353  decode.d4.loss_cls: 0.2121  decode.d4.loss_mask: 1.1165  decode.d4.loss_dice: 0.8854  decode.d5.loss_cls: 0.2144  decode.d5.loss_mask: 1.1104  decode.d5.loss_dice: 0.8587  decode.d6.loss_cls: 0.2256  decode.d6.loss_mask: 1.1286  decode.d6.loss_dice: 0.8461  decode.d7.loss_cls: 0.2390  decode.d7.loss_mask: 1.1113  decode.d7.loss_dice: 0.8458  decode.d8.loss_cls: 0.2069  decode.d8.loss_mask: 1.1223  decode.d8.loss_dice: 0.8622
05/26 20:08:15 - mmengine - INFO - Iter(train) [ 77950/160000]  base_lr: 5.4823e-05 lr: 5.4823e-06  eta: 9:23:32  time: 0.4116  data_time: 0.0097  memory: 5966  grad_norm: 669.8923  loss: 21.4533  decode.loss_cls: 0.3163  decode.loss_mask: 1.0796  decode.loss_dice: 0.7196  decode.d0.loss_cls: 0.7999  decode.d0.loss_mask: 0.9800  decode.d0.loss_dice: 0.6831  decode.d1.loss_cls: 0.2673  decode.d1.loss_mask: 1.0999  decode.d1.loss_dice: 0.7231  decode.d2.loss_cls: 0.3040  decode.d2.loss_mask: 1.0841  decode.d2.loss_dice: 0.7155  decode.d3.loss_cls: 0.2808  decode.d3.loss_mask: 1.1054  decode.d3.loss_dice: 0.7186  decode.d4.loss_cls: 0.2751  decode.d4.loss_mask: 1.1185  decode.d4.loss_dice: 0.7265  decode.d5.loss_cls: 0.2842  decode.d5.loss_mask: 1.1070  decode.d5.loss_dice: 0.7178  decode.d6.loss_cls: 0.2695  decode.d6.loss_mask: 1.0920  decode.d6.loss_dice: 0.6873  decode.d7.loss_cls: 0.2367  decode.d7.loss_mask: 1.1786  decode.d7.loss_dice: 0.7334  decode.d8.loss_cls: 0.3098  decode.d8.loss_mask: 1.1217  decode.d8.loss_dice: 0.7179
05/26 20:08:36 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 20:08:36 - mmengine - INFO - Iter(train) [ 78000/160000]  base_lr: 5.4793e-05 lr: 5.4793e-06  eta: 9:23:11  time: 0.4117  data_time: 0.0097  memory: 5971  grad_norm: 748.0870  loss: 19.3932  decode.loss_cls: 0.2320  decode.loss_mask: 0.9587  decode.loss_dice: 0.6719  decode.d0.loss_cls: 0.6848  decode.d0.loss_mask: 0.9742  decode.d0.loss_dice: 0.7118  decode.d1.loss_cls: 0.1766  decode.d1.loss_mask: 1.0386  decode.d1.loss_dice: 0.6954  decode.d2.loss_cls: 0.1812  decode.d2.loss_mask: 1.0346  decode.d2.loss_dice: 0.7281  decode.d3.loss_cls: 0.1642  decode.d3.loss_mask: 1.0355  decode.d3.loss_dice: 0.7077  decode.d4.loss_cls: 0.1911  decode.d4.loss_mask: 0.9870  decode.d4.loss_dice: 0.7147  decode.d5.loss_cls: 0.1832  decode.d5.loss_mask: 0.9739  decode.d5.loss_dice: 0.6737  decode.d6.loss_cls: 0.1660  decode.d6.loss_mask: 1.0507  decode.d6.loss_dice: 0.6891  decode.d7.loss_cls: 0.2026  decode.d7.loss_mask: 1.0175  decode.d7.loss_dice: 0.6798  decode.d8.loss_cls: 0.1960  decode.d8.loss_mask: 0.9997  decode.d8.loss_dice: 0.6732
05/26 20:08:56 - mmengine - INFO - Iter(train) [ 78050/160000]  base_lr: 5.4763e-05 lr: 5.4763e-06  eta: 9:22:51  time: 0.4124  data_time: 0.0097  memory: 5992  grad_norm: 387.7797  loss: 20.6579  decode.loss_cls: 0.2132  decode.loss_mask: 1.0494  decode.loss_dice: 0.7535  decode.d0.loss_cls: 0.7359  decode.d0.loss_mask: 0.9744  decode.d0.loss_dice: 0.7502  decode.d1.loss_cls: 0.2187  decode.d1.loss_mask: 1.0158  decode.d1.loss_dice: 0.7483  decode.d2.loss_cls: 0.2148  decode.d2.loss_mask: 1.0028  decode.d2.loss_dice: 0.7440  decode.d3.loss_cls: 0.2568  decode.d3.loss_mask: 1.0010  decode.d3.loss_dice: 0.7540  decode.d4.loss_cls: 0.2355  decode.d4.loss_mask: 1.0522  decode.d4.loss_dice: 0.7884  decode.d5.loss_cls: 0.1981  decode.d5.loss_mask: 1.0680  decode.d5.loss_dice: 0.8121  decode.d6.loss_cls: 0.2344  decode.d6.loss_mask: 1.0295  decode.d6.loss_dice: 0.7818  decode.d7.loss_cls: 0.2311  decode.d7.loss_mask: 1.0112  decode.d7.loss_dice: 0.7631  decode.d8.loss_cls: 0.2312  decode.d8.loss_mask: 1.0181  decode.d8.loss_dice: 0.7703
05/26 20:09:17 - mmengine - INFO - Iter(train) [ 78100/160000]  base_lr: 5.4733e-05 lr: 5.4733e-06  eta: 9:22:30  time: 0.4128  data_time: 0.0098  memory: 5977  grad_norm: 628.0741  loss: 20.8230  decode.loss_cls: 0.1638  decode.loss_mask: 1.0403  decode.loss_dice: 0.7856  decode.d0.loss_cls: 0.6797  decode.d0.loss_mask: 0.9810  decode.d0.loss_dice: 0.7220  decode.d1.loss_cls: 0.2018  decode.d1.loss_mask: 1.0510  decode.d1.loss_dice: 0.7897  decode.d2.loss_cls: 0.2408  decode.d2.loss_mask: 1.0585  decode.d2.loss_dice: 0.8068  decode.d3.loss_cls: 0.1940  decode.d3.loss_mask: 1.0537  decode.d3.loss_dice: 0.8122  decode.d4.loss_cls: 0.2006  decode.d4.loss_mask: 1.0309  decode.d4.loss_dice: 0.8347  decode.d5.loss_cls: 0.1896  decode.d5.loss_mask: 1.0489  decode.d5.loss_dice: 0.8515  decode.d6.loss_cls: 0.1408  decode.d6.loss_mask: 1.0616  decode.d6.loss_dice: 0.8493  decode.d7.loss_cls: 0.1635  decode.d7.loss_mask: 1.0410  decode.d7.loss_dice: 0.8028  decode.d8.loss_cls: 0.1627  decode.d8.loss_mask: 1.0404  decode.d8.loss_dice: 0.8236
05/26 20:09:37 - mmengine - INFO - Iter(train) [ 78150/160000]  base_lr: 5.4703e-05 lr: 5.4703e-06  eta: 9:22:10  time: 0.4127  data_time: 0.0096  memory: 5969  grad_norm: 888.5567  loss: 20.9619  decode.loss_cls: 0.1824  decode.loss_mask: 1.1134  decode.loss_dice: 0.7382  decode.d0.loss_cls: 0.7944  decode.d0.loss_mask: 1.0237  decode.d0.loss_dice: 0.7078  decode.d1.loss_cls: 0.2130  decode.d1.loss_mask: 1.0958  decode.d1.loss_dice: 0.7154  decode.d2.loss_cls: 0.1906  decode.d2.loss_mask: 1.1248  decode.d2.loss_dice: 0.7379  decode.d3.loss_cls: 0.1520  decode.d3.loss_mask: 1.1659  decode.d3.loss_dice: 0.7640  decode.d4.loss_cls: 0.2214  decode.d4.loss_mask: 1.1115  decode.d4.loss_dice: 0.7642  decode.d5.loss_cls: 0.1662  decode.d5.loss_mask: 1.1497  decode.d5.loss_dice: 0.7738  decode.d6.loss_cls: 0.1841  decode.d6.loss_mask: 1.1280  decode.d6.loss_dice: 0.7558  decode.d7.loss_cls: 0.1716  decode.d7.loss_mask: 1.0685  decode.d7.loss_dice: 0.7125  decode.d8.loss_cls: 0.1616  decode.d8.loss_mask: 1.1169  decode.d8.loss_dice: 0.7570
05/26 20:09:58 - mmengine - INFO - Iter(train) [ 78200/160000]  base_lr: 5.4673e-05 lr: 5.4673e-06  eta: 9:21:49  time: 0.4127  data_time: 0.0096  memory: 5967  grad_norm: 443.7068  loss: 19.3052  decode.loss_cls: 0.1258  decode.loss_mask: 1.0298  decode.loss_dice: 0.7227  decode.d0.loss_cls: 0.5872  decode.d0.loss_mask: 0.9376  decode.d0.loss_dice: 0.6717  decode.d1.loss_cls: 0.1334  decode.d1.loss_mask: 1.0177  decode.d1.loss_dice: 0.7201  decode.d2.loss_cls: 0.1330  decode.d2.loss_mask: 1.0451  decode.d2.loss_dice: 0.7273  decode.d3.loss_cls: 0.1443  decode.d3.loss_mask: 1.0343  decode.d3.loss_dice: 0.7270  decode.d4.loss_cls: 0.1354  decode.d4.loss_mask: 1.0454  decode.d4.loss_dice: 0.7418  decode.d5.loss_cls: 0.1238  decode.d5.loss_mask: 1.0408  decode.d5.loss_dice: 0.7234  decode.d6.loss_cls: 0.1346  decode.d6.loss_mask: 1.0356  decode.d6.loss_dice: 0.7274  decode.d7.loss_cls: 0.1634  decode.d7.loss_mask: 1.0488  decode.d7.loss_dice: 0.7203  decode.d8.loss_cls: 0.1514  decode.d8.loss_mask: 1.0446  decode.d8.loss_dice: 0.7115
05/26 20:10:19 - mmengine - INFO - Iter(train) [ 78250/160000]  base_lr: 5.4643e-05 lr: 5.4643e-06  eta: 9:21:28  time: 0.4115  data_time: 0.0096  memory: 5971  grad_norm: 562.5470  loss: 16.9225  decode.loss_cls: 0.1827  decode.loss_mask: 0.8696  decode.loss_dice: 0.6436  decode.d0.loss_cls: 0.6731  decode.d0.loss_mask: 0.7857  decode.d0.loss_dice: 0.5523  decode.d1.loss_cls: 0.2083  decode.d1.loss_mask: 0.8317  decode.d1.loss_dice: 0.6031  decode.d2.loss_cls: 0.1609  decode.d2.loss_mask: 0.8413  decode.d2.loss_dice: 0.5944  decode.d3.loss_cls: 0.1878  decode.d3.loss_mask: 0.8289  decode.d3.loss_dice: 0.5972  decode.d4.loss_cls: 0.1997  decode.d4.loss_mask: 0.8507  decode.d4.loss_dice: 0.6230  decode.d5.loss_cls: 0.1827  decode.d5.loss_mask: 0.8699  decode.d5.loss_dice: 0.6613  decode.d6.loss_cls: 0.1641  decode.d6.loss_mask: 0.8594  decode.d6.loss_dice: 0.6277  decode.d7.loss_cls: 0.1771  decode.d7.loss_mask: 0.8521  decode.d7.loss_dice: 0.6321  decode.d8.loss_cls: 0.1700  decode.d8.loss_mask: 0.8535  decode.d8.loss_dice: 0.6385
05/26 20:10:39 - mmengine - INFO - Iter(train) [ 78300/160000]  base_lr: 5.4613e-05 lr: 5.4613e-06  eta: 9:21:08  time: 0.4125  data_time: 0.0096  memory: 5971  grad_norm: 685.9924  loss: 26.5254  decode.loss_cls: 0.3525  decode.loss_mask: 1.3466  decode.loss_dice: 0.8988  decode.d0.loss_cls: 0.8966  decode.d0.loss_mask: 1.2752  decode.d0.loss_dice: 0.8290  decode.d1.loss_cls: 0.3660  decode.d1.loss_mask: 1.3750  decode.d1.loss_dice: 0.8739  decode.d2.loss_cls: 0.3387  decode.d2.loss_mask: 1.4086  decode.d2.loss_dice: 0.9458  decode.d3.loss_cls: 0.3475  decode.d3.loss_mask: 1.4165  decode.d3.loss_dice: 0.9260  decode.d4.loss_cls: 0.3780  decode.d4.loss_mask: 1.3295  decode.d4.loss_dice: 0.8813  decode.d5.loss_cls: 0.3467  decode.d5.loss_mask: 1.3521  decode.d5.loss_dice: 0.8735  decode.d6.loss_cls: 0.3311  decode.d6.loss_mask: 1.3801  decode.d6.loss_dice: 0.8770  decode.d7.loss_cls: 0.2779  decode.d7.loss_mask: 1.4026  decode.d7.loss_dice: 0.9030  decode.d8.loss_cls: 0.3254  decode.d8.loss_mask: 1.3871  decode.d8.loss_dice: 0.8832
05/26 20:11:00 - mmengine - INFO - Iter(train) [ 78350/160000]  base_lr: 5.4583e-05 lr: 5.4583e-06  eta: 9:20:47  time: 0.4115  data_time: 0.0097  memory: 5966  grad_norm: 1158.8735  loss: 20.1727  decode.loss_cls: 0.2181  decode.loss_mask: 0.9277  decode.loss_dice: 0.7448  decode.d0.loss_cls: 0.7945  decode.d0.loss_mask: 0.9451  decode.d0.loss_dice: 0.7407  decode.d1.loss_cls: 0.2255  decode.d1.loss_mask: 0.9304  decode.d1.loss_dice: 0.7402  decode.d2.loss_cls: 0.2325  decode.d2.loss_mask: 0.9387  decode.d2.loss_dice: 0.7742  decode.d3.loss_cls: 0.2393  decode.d3.loss_mask: 0.9399  decode.d3.loss_dice: 0.7523  decode.d4.loss_cls: 0.2561  decode.d4.loss_mask: 0.9338  decode.d4.loss_dice: 0.7797  decode.d5.loss_cls: 0.2653  decode.d5.loss_mask: 0.9862  decode.d5.loss_dice: 0.8026  decode.d6.loss_cls: 0.2436  decode.d6.loss_mask: 0.9924  decode.d6.loss_dice: 0.8083  decode.d7.loss_cls: 0.2607  decode.d7.loss_mask: 0.9590  decode.d7.loss_dice: 0.7943  decode.d8.loss_cls: 0.2348  decode.d8.loss_mask: 0.9477  decode.d8.loss_dice: 0.7641
05/26 20:11:20 - mmengine - INFO - Iter(train) [ 78400/160000]  base_lr: 5.4553e-05 lr: 5.4553e-06  eta: 9:20:27  time: 0.4122  data_time: 0.0098  memory: 5971  grad_norm: 495.3260  loss: 20.3472  decode.loss_cls: 0.1470  decode.loss_mask: 1.0678  decode.loss_dice: 0.7392  decode.d0.loss_cls: 0.6177  decode.d0.loss_mask: 1.0840  decode.d0.loss_dice: 0.7090  decode.d1.loss_cls: 0.1686  decode.d1.loss_mask: 1.0719  decode.d1.loss_dice: 0.7204  decode.d2.loss_cls: 0.1788  decode.d2.loss_mask: 1.0558  decode.d2.loss_dice: 0.7520  decode.d3.loss_cls: 0.1994  decode.d3.loss_mask: 1.0613  decode.d3.loss_dice: 0.7345  decode.d4.loss_cls: 0.1885  decode.d4.loss_mask: 1.0541  decode.d4.loss_dice: 0.7458  decode.d5.loss_cls: 0.1454  decode.d5.loss_mask: 1.0966  decode.d5.loss_dice: 0.7957  decode.d6.loss_cls: 0.1647  decode.d6.loss_mask: 1.0773  decode.d6.loss_dice: 0.7636  decode.d7.loss_cls: 0.1838  decode.d7.loss_mask: 1.0859  decode.d7.loss_dice: 0.7714  decode.d8.loss_cls: 0.1662  decode.d8.loss_mask: 1.0544  decode.d8.loss_dice: 0.7465
05/26 20:11:41 - mmengine - INFO - Iter(train) [ 78450/160000]  base_lr: 5.4523e-05 lr: 5.4523e-06  eta: 9:20:06  time: 0.4122  data_time: 0.0096  memory: 5993  grad_norm: 587.3777  loss: 22.8926  decode.loss_cls: 0.2824  decode.loss_mask: 1.2046  decode.loss_dice: 0.7605  decode.d0.loss_cls: 0.7333  decode.d0.loss_mask: 1.1810  decode.d0.loss_dice: 0.7126  decode.d1.loss_cls: 0.2836  decode.d1.loss_mask: 1.1989  decode.d1.loss_dice: 0.7666  decode.d2.loss_cls: 0.2488  decode.d2.loss_mask: 1.2220  decode.d2.loss_dice: 0.7768  decode.d3.loss_cls: 0.2218  decode.d3.loss_mask: 1.2507  decode.d3.loss_dice: 0.7643  decode.d4.loss_cls: 0.3049  decode.d4.loss_mask: 1.1906  decode.d4.loss_dice: 0.7959  decode.d5.loss_cls: 0.2892  decode.d5.loss_mask: 1.2061  decode.d5.loss_dice: 0.7746  decode.d6.loss_cls: 0.2341  decode.d6.loss_mask: 1.2203  decode.d6.loss_dice: 0.7870  decode.d7.loss_cls: 0.2340  decode.d7.loss_mask: 1.2248  decode.d7.loss_dice: 0.7774  decode.d8.loss_cls: 0.2362  decode.d8.loss_mask: 1.2198  decode.d8.loss_dice: 0.7897
05/26 20:12:02 - mmengine - INFO - Iter(train) [ 78500/160000]  base_lr: 5.4492e-05 lr: 5.4492e-06  eta: 9:19:45  time: 0.4126  data_time: 0.0097  memory: 5975  grad_norm: 345.5790  loss: 19.9425  decode.loss_cls: 0.1728  decode.loss_mask: 1.0013  decode.loss_dice: 0.7615  decode.d0.loss_cls: 0.6691  decode.d0.loss_mask: 0.9834  decode.d0.loss_dice: 0.7352  decode.d1.loss_cls: 0.1504  decode.d1.loss_mask: 1.0299  decode.d1.loss_dice: 0.7892  decode.d2.loss_cls: 0.1935  decode.d2.loss_mask: 1.0033  decode.d2.loss_dice: 0.7651  decode.d3.loss_cls: 0.1366  decode.d3.loss_mask: 0.9923  decode.d3.loss_dice: 0.7789  decode.d4.loss_cls: 0.1930  decode.d4.loss_mask: 0.9992  decode.d4.loss_dice: 0.7933  decode.d5.loss_cls: 0.1425  decode.d5.loss_mask: 1.0264  decode.d5.loss_dice: 0.7922  decode.d6.loss_cls: 0.1419  decode.d6.loss_mask: 1.0358  decode.d6.loss_dice: 0.7708  decode.d7.loss_cls: 0.1324  decode.d7.loss_mask: 1.0342  decode.d7.loss_dice: 0.7894  decode.d8.loss_cls: 0.1723  decode.d8.loss_mask: 0.9948  decode.d8.loss_dice: 0.7618
05/26 20:12:22 - mmengine - INFO - Iter(train) [ 78550/160000]  base_lr: 5.4462e-05 lr: 5.4462e-06  eta: 9:19:25  time: 0.4122  data_time: 0.0097  memory: 5981  grad_norm: 506.6522  loss: 23.6905  decode.loss_cls: 0.2206  decode.loss_mask: 1.2107  decode.loss_dice: 0.8911  decode.d0.loss_cls: 0.7932  decode.d0.loss_mask: 1.1263  decode.d0.loss_dice: 0.9164  decode.d1.loss_cls: 0.2658  decode.d1.loss_mask: 1.2043  decode.d1.loss_dice: 0.8802  decode.d2.loss_cls: 0.2536  decode.d2.loss_mask: 1.1626  decode.d2.loss_dice: 0.8814  decode.d3.loss_cls: 0.2353  decode.d3.loss_mask: 1.2111  decode.d3.loss_dice: 0.8855  decode.d4.loss_cls: 0.2429  decode.d4.loss_mask: 1.1659  decode.d4.loss_dice: 0.8899  decode.d5.loss_cls: 0.1986  decode.d5.loss_mask: 1.1907  decode.d5.loss_dice: 0.8991  decode.d6.loss_cls: 0.2140  decode.d6.loss_mask: 1.1721  decode.d6.loss_dice: 0.8895  decode.d7.loss_cls: 0.2664  decode.d7.loss_mask: 1.1767  decode.d7.loss_dice: 0.8966  decode.d8.loss_cls: 0.2711  decode.d8.loss_mask: 1.1754  decode.d8.loss_dice: 0.9034
05/26 20:12:43 - mmengine - INFO - Iter(train) [ 78600/160000]  base_lr: 5.4432e-05 lr: 5.4432e-06  eta: 9:19:04  time: 0.4128  data_time: 0.0096  memory: 5970  grad_norm: 474.7051  loss: 20.4886  decode.loss_cls: 0.1546  decode.loss_mask: 1.0443  decode.loss_dice: 0.7731  decode.d0.loss_cls: 0.6267  decode.d0.loss_mask: 1.0593  decode.d0.loss_dice: 0.7623  decode.d1.loss_cls: 0.1944  decode.d1.loss_mask: 1.0806  decode.d1.loss_dice: 0.7777  decode.d2.loss_cls: 0.1891  decode.d2.loss_mask: 1.0338  decode.d2.loss_dice: 0.7684  decode.d3.loss_cls: 0.1879  decode.d3.loss_mask: 1.0566  decode.d3.loss_dice: 0.7856  decode.d4.loss_cls: 0.1694  decode.d4.loss_mask: 1.0381  decode.d4.loss_dice: 0.7917  decode.d5.loss_cls: 0.1866  decode.d5.loss_mask: 1.0615  decode.d5.loss_dice: 0.7751  decode.d6.loss_cls: 0.1991  decode.d6.loss_mask: 1.0426  decode.d6.loss_dice: 0.7798  decode.d7.loss_cls: 0.1815  decode.d7.loss_mask: 1.0442  decode.d7.loss_dice: 0.7717  decode.d8.loss_cls: 0.1555  decode.d8.loss_mask: 1.0459  decode.d8.loss_dice: 0.7514
05/26 20:13:04 - mmengine - INFO - Iter(train) [ 78650/160000]  base_lr: 5.4402e-05 lr: 5.4402e-06  eta: 9:18:44  time: 0.4122  data_time: 0.0096  memory: 5968  grad_norm: 490.1240  loss: 22.5187  decode.loss_cls: 0.2852  decode.loss_mask: 1.1473  decode.loss_dice: 0.7526  decode.d0.loss_cls: 0.6764  decode.d0.loss_mask: 1.0604  decode.d0.loss_dice: 0.7291  decode.d1.loss_cls: 0.3027  decode.d1.loss_mask: 1.1671  decode.d1.loss_dice: 0.8019  decode.d2.loss_cls: 0.3043  decode.d2.loss_mask: 1.1313  decode.d2.loss_dice: 0.7837  decode.d3.loss_cls: 0.3167  decode.d3.loss_mask: 1.1162  decode.d3.loss_dice: 0.7704  decode.d4.loss_cls: 0.3260  decode.d4.loss_mask: 1.0961  decode.d4.loss_dice: 0.7699  decode.d5.loss_cls: 0.3089  decode.d5.loss_mask: 1.1489  decode.d5.loss_dice: 0.7691  decode.d6.loss_cls: 0.3381  decode.d6.loss_mask: 1.1636  decode.d6.loss_dice: 0.7977  decode.d7.loss_cls: 0.3298  decode.d7.loss_mask: 1.0895  decode.d7.loss_dice: 0.7751  decode.d8.loss_cls: 0.3166  decode.d8.loss_mask: 1.1427  decode.d8.loss_dice: 0.8013
05/26 20:13:24 - mmengine - INFO - Iter(train) [ 78700/160000]  base_lr: 5.4372e-05 lr: 5.4372e-06  eta: 9:18:23  time: 0.4192  data_time: 0.0099  memory: 5975  grad_norm: 647.0312  loss: 20.2020  decode.loss_cls: 0.1979  decode.loss_mask: 1.0676  decode.loss_dice: 0.6801  decode.d0.loss_cls: 0.6810  decode.d0.loss_mask: 1.0501  decode.d0.loss_dice: 0.6977  decode.d1.loss_cls: 0.1993  decode.d1.loss_mask: 1.0543  decode.d1.loss_dice: 0.6906  decode.d2.loss_cls: 0.1874  decode.d2.loss_mask: 1.0836  decode.d2.loss_dice: 0.6887  decode.d3.loss_cls: 0.1648  decode.d3.loss_mask: 1.1313  decode.d3.loss_dice: 0.7065  decode.d4.loss_cls: 0.1997  decode.d4.loss_mask: 1.0942  decode.d4.loss_dice: 0.7171  decode.d5.loss_cls: 0.1862  decode.d5.loss_mask: 1.0894  decode.d5.loss_dice: 0.7020  decode.d6.loss_cls: 0.2253  decode.d6.loss_mask: 1.1305  decode.d6.loss_dice: 0.6950  decode.d7.loss_cls: 0.1748  decode.d7.loss_mask: 1.0873  decode.d7.loss_dice: 0.6891  decode.d8.loss_cls: 0.1745  decode.d8.loss_mask: 1.0614  decode.d8.loss_dice: 0.6944
05/26 20:13:45 - mmengine - INFO - Iter(train) [ 78750/160000]  base_lr: 5.4342e-05 lr: 5.4342e-06  eta: 9:18:03  time: 0.4282  data_time: 0.0101  memory: 5974  grad_norm: 652.7391  loss: 17.7858  decode.loss_cls: 0.1931  decode.loss_mask: 1.0103  decode.loss_dice: 0.5831  decode.d0.loss_cls: 0.6251  decode.d0.loss_mask: 0.9223  decode.d0.loss_dice: 0.5549  decode.d1.loss_cls: 0.1875  decode.d1.loss_mask: 1.0208  decode.d1.loss_dice: 0.5703  decode.d2.loss_cls: 0.1965  decode.d2.loss_mask: 0.9392  decode.d2.loss_dice: 0.5701  decode.d3.loss_cls: 0.1928  decode.d3.loss_mask: 0.9712  decode.d3.loss_dice: 0.5580  decode.d4.loss_cls: 0.2506  decode.d4.loss_mask: 0.9330  decode.d4.loss_dice: 0.5514  decode.d5.loss_cls: 0.2650  decode.d5.loss_mask: 0.9325  decode.d5.loss_dice: 0.5459  decode.d6.loss_cls: 0.2107  decode.d6.loss_mask: 0.9877  decode.d6.loss_dice: 0.5747  decode.d7.loss_cls: 0.2138  decode.d7.loss_mask: 0.9502  decode.d7.loss_dice: 0.5707  decode.d8.loss_cls: 0.2059  decode.d8.loss_mask: 0.9427  decode.d8.loss_dice: 0.5555
05/26 20:14:06 - mmengine - INFO - Iter(train) [ 78800/160000]  base_lr: 5.4312e-05 lr: 5.4312e-06  eta: 9:17:43  time: 0.4128  data_time: 0.0096  memory: 5969  grad_norm: 592.8230  loss: 19.9294  decode.loss_cls: 0.1855  decode.loss_mask: 1.0495  decode.loss_dice: 0.6609  decode.d0.loss_cls: 0.6893  decode.d0.loss_mask: 1.0357  decode.d0.loss_dice: 0.6899  decode.d1.loss_cls: 0.2593  decode.d1.loss_mask: 1.0533  decode.d1.loss_dice: 0.6661  decode.d2.loss_cls: 0.1862  decode.d2.loss_mask: 1.0721  decode.d2.loss_dice: 0.6996  decode.d3.loss_cls: 0.1824  decode.d3.loss_mask: 1.1082  decode.d3.loss_dice: 0.6877  decode.d4.loss_cls: 0.1971  decode.d4.loss_mask: 1.0509  decode.d4.loss_dice: 0.6748  decode.d5.loss_cls: 0.1859  decode.d5.loss_mask: 1.0599  decode.d5.loss_dice: 0.6831  decode.d6.loss_cls: 0.1990  decode.d6.loss_mask: 1.0643  decode.d6.loss_dice: 0.6894  decode.d7.loss_cls: 0.2204  decode.d7.loss_mask: 1.0716  decode.d7.loss_dice: 0.6904  decode.d8.loss_cls: 0.2038  decode.d8.loss_mask: 1.0539  decode.d8.loss_dice: 0.6592
05/26 20:14:27 - mmengine - INFO - Iter(train) [ 78850/160000]  base_lr: 5.4282e-05 lr: 5.4282e-06  eta: 9:17:22  time: 0.4121  data_time: 0.0096  memory: 5967  grad_norm: 452.0691  loss: 20.8542  decode.loss_cls: 0.2212  decode.loss_mask: 1.0284  decode.loss_dice: 0.7626  decode.d0.loss_cls: 0.7332  decode.d0.loss_mask: 1.0097  decode.d0.loss_dice: 0.7596  decode.d1.loss_cls: 0.2436  decode.d1.loss_mask: 1.0108  decode.d1.loss_dice: 0.7788  decode.d2.loss_cls: 0.2442  decode.d2.loss_mask: 1.0292  decode.d2.loss_dice: 0.8031  decode.d3.loss_cls: 0.2401  decode.d3.loss_mask: 1.0603  decode.d3.loss_dice: 0.7907  decode.d4.loss_cls: 0.2501  decode.d4.loss_mask: 1.0427  decode.d4.loss_dice: 0.7754  decode.d5.loss_cls: 0.2165  decode.d5.loss_mask: 1.0162  decode.d5.loss_dice: 0.7668  decode.d6.loss_cls: 0.2388  decode.d6.loss_mask: 1.0075  decode.d6.loss_dice: 0.7688  decode.d7.loss_cls: 0.2311  decode.d7.loss_mask: 1.0277  decode.d7.loss_dice: 0.7848  decode.d8.loss_cls: 0.2007  decode.d8.loss_mask: 1.0236  decode.d8.loss_dice: 0.7880
05/26 20:14:48 - mmengine - INFO - Iter(train) [ 78900/160000]  base_lr: 5.4252e-05 lr: 5.4252e-06  eta: 9:17:02  time: 0.4120  data_time: 0.0096  memory: 5967  grad_norm: 495.8977  loss: 21.6416  decode.loss_cls: 0.0854  decode.loss_mask: 1.3087  decode.loss_dice: 0.7412  decode.d0.loss_cls: 0.6451  decode.d0.loss_mask: 1.1263  decode.d0.loss_dice: 0.6743  decode.d1.loss_cls: 0.1066  decode.d1.loss_mask: 1.2959  decode.d1.loss_dice: 0.7409  decode.d2.loss_cls: 0.1228  decode.d2.loss_mask: 1.2892  decode.d2.loss_dice: 0.7478  decode.d3.loss_cls: 0.1467  decode.d3.loss_mask: 1.2717  decode.d3.loss_dice: 0.7184  decode.d4.loss_cls: 0.1568  decode.d4.loss_mask: 1.2543  decode.d4.loss_dice: 0.7239  decode.d5.loss_cls: 0.1078  decode.d5.loss_mask: 1.2928  decode.d5.loss_dice: 0.7318  decode.d6.loss_cls: 0.1035  decode.d6.loss_mask: 1.3028  decode.d6.loss_dice: 0.7270  decode.d7.loss_cls: 0.0882  decode.d7.loss_mask: 1.3011  decode.d7.loss_dice: 0.7116  decode.d8.loss_cls: 0.1218  decode.d8.loss_mask: 1.2910  decode.d8.loss_dice: 0.7061
05/26 20:15:08 - mmengine - INFO - Iter(train) [ 78950/160000]  base_lr: 5.4222e-05 lr: 5.4222e-06  eta: 9:16:41  time: 0.4114  data_time: 0.0096  memory: 5982  grad_norm: 731.8679  loss: 22.6350  decode.loss_cls: 0.2885  decode.loss_mask: 1.0865  decode.loss_dice: 0.8779  decode.d0.loss_cls: 0.9067  decode.d0.loss_mask: 0.9790  decode.d0.loss_dice: 0.8363  decode.d1.loss_cls: 0.3915  decode.d1.loss_mask: 1.0170  decode.d1.loss_dice: 0.8130  decode.d2.loss_cls: 0.3487  decode.d2.loss_mask: 1.0581  decode.d2.loss_dice: 0.8924  decode.d3.loss_cls: 0.3791  decode.d3.loss_mask: 0.9978  decode.d3.loss_dice: 0.8286  decode.d4.loss_cls: 0.4130  decode.d4.loss_mask: 0.9158  decode.d4.loss_dice: 0.8034  decode.d5.loss_cls: 0.3973  decode.d5.loss_mask: 0.9269  decode.d5.loss_dice: 0.8249  decode.d6.loss_cls: 0.4105  decode.d6.loss_mask: 0.9970  decode.d6.loss_dice: 0.8827  decode.d7.loss_cls: 0.3638  decode.d7.loss_mask: 0.9955  decode.d7.loss_dice: 0.8504  decode.d8.loss_cls: 0.3367  decode.d8.loss_mask: 0.9818  decode.d8.loss_dice: 0.8345
05/26 20:15:29 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 20:15:29 - mmengine - INFO - Iter(train) [ 79000/160000]  base_lr: 5.4191e-05 lr: 5.4191e-06  eta: 9:16:20  time: 0.4127  data_time: 0.0096  memory: 5968  grad_norm: 923.2569  loss: 22.0635  decode.loss_cls: 0.1617  decode.loss_mask: 1.1949  decode.loss_dice: 0.7325  decode.d0.loss_cls: 0.7205  decode.d0.loss_mask: 1.1099  decode.d0.loss_dice: 0.7350  decode.d1.loss_cls: 0.1654  decode.d1.loss_mask: 1.2356  decode.d1.loss_dice: 0.7920  decode.d2.loss_cls: 0.1732  decode.d2.loss_mask: 1.2633  decode.d2.loss_dice: 0.7733  decode.d3.loss_cls: 0.1867  decode.d3.loss_mask: 1.1915  decode.d3.loss_dice: 0.7857  decode.d4.loss_cls: 0.1778  decode.d4.loss_mask: 1.2402  decode.d4.loss_dice: 0.7612  decode.d5.loss_cls: 0.2081  decode.d5.loss_mask: 1.2355  decode.d5.loss_dice: 0.7705  decode.d6.loss_cls: 0.2027  decode.d6.loss_mask: 1.1689  decode.d6.loss_dice: 0.7543  decode.d7.loss_cls: 0.1784  decode.d7.loss_mask: 1.2230  decode.d7.loss_dice: 0.7796  decode.d8.loss_cls: 0.1653  decode.d8.loss_mask: 1.2353  decode.d8.loss_dice: 0.7413
05/26 20:15:50 - mmengine - INFO - Iter(train) [ 79050/160000]  base_lr: 5.4161e-05 lr: 5.4161e-06  eta: 9:16:00  time: 0.4129  data_time: 0.0096  memory: 5967  grad_norm: 837.2274  loss: 23.8862  decode.loss_cls: 0.2787  decode.loss_mask: 1.1996  decode.loss_dice: 0.8462  decode.d0.loss_cls: 0.7693  decode.d0.loss_mask: 1.1870  decode.d0.loss_dice: 0.9043  decode.d1.loss_cls: 0.2943  decode.d1.loss_mask: 1.2125  decode.d1.loss_dice: 0.8569  decode.d2.loss_cls: 0.2813  decode.d2.loss_mask: 1.2210  decode.d2.loss_dice: 0.8522  decode.d3.loss_cls: 0.2680  decode.d3.loss_mask: 1.2050  decode.d3.loss_dice: 0.8584  decode.d4.loss_cls: 0.2312  decode.d4.loss_mask: 1.1979  decode.d4.loss_dice: 0.8788  decode.d5.loss_cls: 0.2696  decode.d5.loss_mask: 1.2171  decode.d5.loss_dice: 0.9158  decode.d6.loss_cls: 0.2639  decode.d6.loss_mask: 1.2011  decode.d6.loss_dice: 0.8587  decode.d7.loss_cls: 0.2593  decode.d7.loss_mask: 1.2084  decode.d7.loss_dice: 0.8460  decode.d8.loss_cls: 0.2288  decode.d8.loss_mask: 1.2088  decode.d8.loss_dice: 0.8663
05/26 20:16:10 - mmengine - INFO - Iter(train) [ 79100/160000]  base_lr: 5.4131e-05 lr: 5.4131e-06  eta: 9:15:39  time: 0.4136  data_time: 0.0096  memory: 5998  grad_norm: 737.9312  loss: 23.8254  decode.loss_cls: 0.1259  decode.loss_mask: 1.1702  decode.loss_dice: 1.0406  decode.d0.loss_cls: 0.7293  decode.d0.loss_mask: 1.1413  decode.d0.loss_dice: 0.9594  decode.d1.loss_cls: 0.1328  decode.d1.loss_mask: 1.1798  decode.d1.loss_dice: 1.0169  decode.d2.loss_cls: 0.1460  decode.d2.loss_mask: 1.1842  decode.d2.loss_dice: 0.9900  decode.d3.loss_cls: 0.1234  decode.d3.loss_mask: 1.2121  decode.d3.loss_dice: 1.0243  decode.d4.loss_cls: 0.1488  decode.d4.loss_mask: 1.1717  decode.d4.loss_dice: 1.0050  decode.d5.loss_cls: 0.1218  decode.d5.loss_mask: 1.1710  decode.d5.loss_dice: 1.0110  decode.d6.loss_cls: 0.1428  decode.d6.loss_mask: 1.1829  decode.d6.loss_dice: 1.0240  decode.d7.loss_cls: 0.1368  decode.d7.loss_mask: 1.1884  decode.d7.loss_dice: 1.0090  decode.d8.loss_cls: 0.1224  decode.d8.loss_mask: 1.1814  decode.d8.loss_dice: 1.0324
05/26 20:16:31 - mmengine - INFO - Iter(train) [ 79150/160000]  base_lr: 5.4101e-05 lr: 5.4101e-06  eta: 9:15:19  time: 0.4126  data_time: 0.0097  memory: 5968  grad_norm: 592.1539  loss: 25.9788  decode.loss_cls: 0.2485  decode.loss_mask: 1.2970  decode.loss_dice: 0.9330  decode.d0.loss_cls: 0.7846  decode.d0.loss_mask: 1.2652  decode.d0.loss_dice: 0.9101  decode.d1.loss_cls: 0.3452  decode.d1.loss_mask: 1.3414  decode.d1.loss_dice: 0.9478  decode.d2.loss_cls: 0.2484  decode.d2.loss_mask: 1.3763  decode.d2.loss_dice: 0.9459  decode.d3.loss_cls: 0.2877  decode.d3.loss_mask: 1.3093  decode.d3.loss_dice: 0.9462  decode.d4.loss_cls: 0.2999  decode.d4.loss_mask: 1.3500  decode.d4.loss_dice: 0.9682  decode.d5.loss_cls: 0.2277  decode.d5.loss_mask: 1.3979  decode.d5.loss_dice: 0.9551  decode.d6.loss_cls: 0.2997  decode.d6.loss_mask: 1.3156  decode.d6.loss_dice: 0.9590  decode.d7.loss_cls: 0.2403  decode.d7.loss_mask: 1.3368  decode.d7.loss_dice: 0.9388  decode.d8.loss_cls: 0.2434  decode.d8.loss_mask: 1.3175  decode.d8.loss_dice: 0.9425
05/26 20:16:52 - mmengine - INFO - Iter(train) [ 79200/160000]  base_lr: 5.4071e-05 lr: 5.4071e-06  eta: 9:14:58  time: 0.4128  data_time: 0.0096  memory: 5976  grad_norm: 488.4188  loss: 21.9007  decode.loss_cls: 0.2086  decode.loss_mask: 1.1424  decode.loss_dice: 0.7767  decode.d0.loss_cls: 0.6126  decode.d0.loss_mask: 1.1204  decode.d0.loss_dice: 0.7526  decode.d1.loss_cls: 0.2400  decode.d1.loss_mask: 1.1610  decode.d1.loss_dice: 0.7891  decode.d2.loss_cls: 0.2140  decode.d2.loss_mask: 1.1532  decode.d2.loss_dice: 0.7771  decode.d3.loss_cls: 0.2050  decode.d3.loss_mask: 1.1677  decode.d3.loss_dice: 0.7819  decode.d4.loss_cls: 0.2057  decode.d4.loss_mask: 1.1652  decode.d4.loss_dice: 0.7814  decode.d5.loss_cls: 0.2233  decode.d5.loss_mask: 1.1614  decode.d5.loss_dice: 0.7830  decode.d6.loss_cls: 0.2140  decode.d6.loss_mask: 1.1686  decode.d6.loss_dice: 0.7766  decode.d7.loss_cls: 0.2010  decode.d7.loss_mask: 1.1505  decode.d7.loss_dice: 0.7746  decode.d8.loss_cls: 0.2275  decode.d8.loss_mask: 1.1698  decode.d8.loss_dice: 0.7955
05/26 20:17:12 - mmengine - INFO - Iter(train) [ 79250/160000]  base_lr: 5.4041e-05 lr: 5.4041e-06  eta: 9:14:38  time: 0.4117  data_time: 0.0098  memory: 5966  grad_norm: 492.1828  loss: 21.0638  decode.loss_cls: 0.2430  decode.loss_mask: 1.0387  decode.loss_dice: 0.7756  decode.d0.loss_cls: 0.7975  decode.d0.loss_mask: 0.9934  decode.d0.loss_dice: 0.7753  decode.d1.loss_cls: 0.2812  decode.d1.loss_mask: 1.0092  decode.d1.loss_dice: 0.7703  decode.d2.loss_cls: 0.2983  decode.d2.loss_mask: 1.0268  decode.d2.loss_dice: 0.7574  decode.d3.loss_cls: 0.2337  decode.d3.loss_mask: 1.0101  decode.d3.loss_dice: 0.7690  decode.d4.loss_cls: 0.2364  decode.d4.loss_mask: 1.0241  decode.d4.loss_dice: 0.7548  decode.d5.loss_cls: 0.2820  decode.d5.loss_mask: 1.0192  decode.d5.loss_dice: 0.7621  decode.d6.loss_cls: 0.2866  decode.d6.loss_mask: 1.0056  decode.d6.loss_dice: 0.7703  decode.d7.loss_cls: 0.2469  decode.d7.loss_mask: 1.0340  decode.d7.loss_dice: 0.7862  decode.d8.loss_cls: 0.2563  decode.d8.loss_mask: 1.0403  decode.d8.loss_dice: 0.7796
05/26 20:17:33 - mmengine - INFO - Iter(train) [ 79300/160000]  base_lr: 5.4011e-05 lr: 5.4011e-06  eta: 9:14:17  time: 0.4126  data_time: 0.0097  memory: 5976  grad_norm: 418.2709  loss: 22.2900  decode.loss_cls: 0.3665  decode.loss_mask: 0.9159  decode.loss_dice: 0.8797  decode.d0.loss_cls: 0.8246  decode.d0.loss_mask: 0.8838  decode.d0.loss_dice: 0.7972  decode.d1.loss_cls: 0.4036  decode.d1.loss_mask: 0.9279  decode.d1.loss_dice: 0.8298  decode.d2.loss_cls: 0.3885  decode.d2.loss_mask: 0.9544  decode.d2.loss_dice: 0.8180  decode.d3.loss_cls: 0.3405  decode.d3.loss_mask: 1.0183  decode.d3.loss_dice: 0.8439  decode.d4.loss_cls: 0.3624  decode.d4.loss_mask: 1.0434  decode.d4.loss_dice: 0.8418  decode.d5.loss_cls: 0.3848  decode.d5.loss_mask: 0.9582  decode.d5.loss_dice: 0.8694  decode.d6.loss_cls: 0.2920  decode.d6.loss_mask: 1.0534  decode.d6.loss_dice: 0.9068  decode.d7.loss_cls: 0.3768  decode.d7.loss_mask: 0.9592  decode.d7.loss_dice: 0.8491  decode.d8.loss_cls: 0.3820  decode.d8.loss_mask: 0.9665  decode.d8.loss_dice: 0.8511
05/26 20:17:54 - mmengine - INFO - Iter(train) [ 79350/160000]  base_lr: 5.3981e-05 lr: 5.3981e-06  eta: 9:13:56  time: 0.4117  data_time: 0.0097  memory: 5990  grad_norm: 644.5845  loss: 22.9829  decode.loss_cls: 0.2897  decode.loss_mask: 1.2249  decode.loss_dice: 0.7744  decode.d0.loss_cls: 0.7426  decode.d0.loss_mask: 1.1442  decode.d0.loss_dice: 0.7806  decode.d1.loss_cls: 0.2380  decode.d1.loss_mask: 1.2218  decode.d1.loss_dice: 0.8084  decode.d2.loss_cls: 0.2255  decode.d2.loss_mask: 1.2251  decode.d2.loss_dice: 0.8149  decode.d3.loss_cls: 0.2299  decode.d3.loss_mask: 1.2210  decode.d3.loss_dice: 0.7823  decode.d4.loss_cls: 0.2767  decode.d4.loss_mask: 1.2269  decode.d4.loss_dice: 0.7773  decode.d5.loss_cls: 0.2653  decode.d5.loss_mask: 1.2484  decode.d5.loss_dice: 0.7986  decode.d6.loss_cls: 0.2088  decode.d6.loss_mask: 1.2249  decode.d6.loss_dice: 0.7935  decode.d7.loss_cls: 0.2507  decode.d7.loss_mask: 1.1948  decode.d7.loss_dice: 0.7859  decode.d8.loss_cls: 0.2449  decode.d8.loss_mask: 1.2023  decode.d8.loss_dice: 0.7605
05/26 20:18:14 - mmengine - INFO - Iter(train) [ 79400/160000]  base_lr: 5.3951e-05 lr: 5.3951e-06  eta: 9:13:36  time: 0.4125  data_time: 0.0097  memory: 5966  grad_norm: 462.8748  loss: 23.2946  decode.loss_cls: 0.2077  decode.loss_mask: 1.1602  decode.loss_dice: 0.8452  decode.d0.loss_cls: 0.7250  decode.d0.loss_mask: 1.1365  decode.d0.loss_dice: 0.8289  decode.d1.loss_cls: 0.2573  decode.d1.loss_mask: 1.1966  decode.d1.loss_dice: 0.8678  decode.d2.loss_cls: 0.2200  decode.d2.loss_mask: 1.2358  decode.d2.loss_dice: 0.8548  decode.d3.loss_cls: 0.2489  decode.d3.loss_mask: 1.1618  decode.d3.loss_dice: 0.8514  decode.d4.loss_cls: 0.2430  decode.d4.loss_mask: 1.1854  decode.d4.loss_dice: 0.8386  decode.d5.loss_cls: 0.2864  decode.d5.loss_mask: 1.2138  decode.d5.loss_dice: 0.8615  decode.d6.loss_cls: 0.2690  decode.d6.loss_mask: 1.2150  decode.d6.loss_dice: 0.8445  decode.d7.loss_cls: 0.2449  decode.d7.loss_mask: 1.1796  decode.d7.loss_dice: 0.8334  decode.d8.loss_cls: 0.2553  decode.d8.loss_mask: 1.1787  decode.d8.loss_dice: 0.8477
05/26 20:18:35 - mmengine - INFO - Iter(train) [ 79450/160000]  base_lr: 5.3920e-05 lr: 5.3920e-06  eta: 9:13:15  time: 0.4123  data_time: 0.0097  memory: 5966  grad_norm: 711.9269  loss: 20.0480  decode.loss_cls: 0.1709  decode.loss_mask: 1.0014  decode.loss_dice: 0.7789  decode.d0.loss_cls: 0.6817  decode.d0.loss_mask: 0.9239  decode.d0.loss_dice: 0.7251  decode.d1.loss_cls: 0.1803  decode.d1.loss_mask: 0.9738  decode.d1.loss_dice: 0.7598  decode.d2.loss_cls: 0.1920  decode.d2.loss_mask: 0.9753  decode.d2.loss_dice: 0.7337  decode.d3.loss_cls: 0.1878  decode.d3.loss_mask: 0.9830  decode.d3.loss_dice: 0.7861  decode.d4.loss_cls: 0.2279  decode.d4.loss_mask: 0.9879  decode.d4.loss_dice: 0.7566  decode.d5.loss_cls: 0.2115  decode.d5.loss_mask: 1.0046  decode.d5.loss_dice: 0.7707  decode.d6.loss_cls: 0.2127  decode.d6.loss_mask: 1.0163  decode.d6.loss_dice: 0.7626  decode.d7.loss_cls: 0.1873  decode.d7.loss_mask: 1.0418  decode.d7.loss_dice: 0.8021  decode.d8.loss_cls: 0.1872  decode.d8.loss_mask: 1.0219  decode.d8.loss_dice: 0.8031
05/26 20:18:55 - mmengine - INFO - Iter(train) [ 79500/160000]  base_lr: 5.3890e-05 lr: 5.3890e-06  eta: 9:12:55  time: 0.4115  data_time: 0.0096  memory: 5966  grad_norm: 582.2224  loss: 20.5056  decode.loss_cls: 0.0985  decode.loss_mask: 1.1890  decode.loss_dice: 0.7419  decode.d0.loss_cls: 0.6072  decode.d0.loss_mask: 1.0876  decode.d0.loss_dice: 0.7103  decode.d1.loss_cls: 0.1465  decode.d1.loss_mask: 1.1377  decode.d1.loss_dice: 0.7122  decode.d2.loss_cls: 0.1540  decode.d2.loss_mask: 1.1377  decode.d2.loss_dice: 0.7071  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 1.1717  decode.d3.loss_dice: 0.7206  decode.d4.loss_cls: 0.1358  decode.d4.loss_mask: 1.1023  decode.d4.loss_dice: 0.7179  decode.d5.loss_cls: 0.1413  decode.d5.loss_mask: 1.1870  decode.d5.loss_dice: 0.7414  decode.d6.loss_cls: 0.1809  decode.d6.loss_mask: 1.1276  decode.d6.loss_dice: 0.7322  decode.d7.loss_cls: 0.1484  decode.d7.loss_mask: 1.1118  decode.d7.loss_dice: 0.7105  decode.d8.loss_cls: 0.1568  decode.d8.loss_mask: 1.1506  decode.d8.loss_dice: 0.7374
05/26 20:19:16 - mmengine - INFO - Iter(train) [ 79550/160000]  base_lr: 5.3860e-05 lr: 5.3860e-06  eta: 9:12:34  time: 0.4119  data_time: 0.0097  memory: 5998  grad_norm: 1133.6621  loss: 22.2400  decode.loss_cls: 0.2071  decode.loss_mask: 1.1739  decode.loss_dice: 0.7378  decode.d0.loss_cls: 0.6828  decode.d0.loss_mask: 1.1578  decode.d0.loss_dice: 0.7188  decode.d1.loss_cls: 0.2597  decode.d1.loss_mask: 1.1743  decode.d1.loss_dice: 0.7417  decode.d2.loss_cls: 0.2233  decode.d2.loss_mask: 1.1858  decode.d2.loss_dice: 0.7535  decode.d3.loss_cls: 0.2447  decode.d3.loss_mask: 1.1876  decode.d3.loss_dice: 0.7607  decode.d4.loss_cls: 0.2324  decode.d4.loss_mask: 1.2482  decode.d4.loss_dice: 0.7754  decode.d5.loss_cls: 0.2433  decode.d5.loss_mask: 1.2122  decode.d5.loss_dice: 0.7405  decode.d6.loss_cls: 0.2472  decode.d6.loss_mask: 1.2109  decode.d6.loss_dice: 0.7460  decode.d7.loss_cls: 0.2348  decode.d7.loss_mask: 1.2033  decode.d7.loss_dice: 0.7817  decode.d8.loss_cls: 0.2207  decode.d8.loss_mask: 1.2002  decode.d8.loss_dice: 0.7337
05/26 20:19:37 - mmengine - INFO - Iter(train) [ 79600/160000]  base_lr: 5.3830e-05 lr: 5.3830e-06  eta: 9:12:13  time: 0.4116  data_time: 0.0097  memory: 5966  grad_norm: 530.9168  loss: 20.1410  decode.loss_cls: 0.1866  decode.loss_mask: 0.9876  decode.loss_dice: 0.7803  decode.d0.loss_cls: 0.6493  decode.d0.loss_mask: 1.0015  decode.d0.loss_dice: 0.7803  decode.d1.loss_cls: 0.2640  decode.d1.loss_mask: 0.9864  decode.d1.loss_dice: 0.7663  decode.d2.loss_cls: 0.1786  decode.d2.loss_mask: 0.9766  decode.d2.loss_dice: 0.7645  decode.d3.loss_cls: 0.2024  decode.d3.loss_mask: 0.9819  decode.d3.loss_dice: 0.7729  decode.d4.loss_cls: 0.1833  decode.d4.loss_mask: 1.0048  decode.d4.loss_dice: 0.7802  decode.d5.loss_cls: 0.2046  decode.d5.loss_mask: 0.9833  decode.d5.loss_dice: 0.7542  decode.d6.loss_cls: 0.2221  decode.d6.loss_mask: 1.0070  decode.d6.loss_dice: 0.7628  decode.d7.loss_cls: 0.1926  decode.d7.loss_mask: 0.9989  decode.d7.loss_dice: 0.7997  decode.d8.loss_cls: 0.1848  decode.d8.loss_mask: 0.9954  decode.d8.loss_dice: 0.7883
05/26 20:19:57 - mmengine - INFO - Iter(train) [ 79650/160000]  base_lr: 5.3800e-05 lr: 5.3800e-06  eta: 9:11:53  time: 0.4125  data_time: 0.0096  memory: 5979  grad_norm: 548.7870  loss: 24.0727  decode.loss_cls: 0.2872  decode.loss_mask: 1.1626  decode.loss_dice: 0.8748  decode.d0.loss_cls: 0.9058  decode.d0.loss_mask: 1.1803  decode.d0.loss_dice: 0.8741  decode.d1.loss_cls: 0.2944  decode.d1.loss_mask: 1.1619  decode.d1.loss_dice: 0.8856  decode.d2.loss_cls: 0.2985  decode.d2.loss_mask: 1.1574  decode.d2.loss_dice: 0.8416  decode.d3.loss_cls: 0.3257  decode.d3.loss_mask: 1.1587  decode.d3.loss_dice: 0.8502  decode.d4.loss_cls: 0.3182  decode.d4.loss_mask: 1.1648  decode.d4.loss_dice: 0.8847  decode.d5.loss_cls: 0.3466  decode.d5.loss_mask: 1.1702  decode.d5.loss_dice: 0.8692  decode.d6.loss_cls: 0.3019  decode.d6.loss_mask: 1.1975  decode.d6.loss_dice: 0.8944  decode.d7.loss_cls: 0.3052  decode.d7.loss_mask: 1.1823  decode.d7.loss_dice: 0.8738  decode.d8.loss_cls: 0.3090  decode.d8.loss_mask: 1.1375  decode.d8.loss_dice: 0.8587
05/26 20:20:18 - mmengine - INFO - Iter(train) [ 79700/160000]  base_lr: 5.3770e-05 lr: 5.3770e-06  eta: 9:11:32  time: 0.4131  data_time: 0.0096  memory: 5967  grad_norm: 507.7362  loss: 19.9000  decode.loss_cls: 0.1422  decode.loss_mask: 1.0185  decode.loss_dice: 0.7572  decode.d0.loss_cls: 0.6828  decode.d0.loss_mask: 0.9729  decode.d0.loss_dice: 0.7267  decode.d1.loss_cls: 0.1594  decode.d1.loss_mask: 1.0238  decode.d1.loss_dice: 0.7603  decode.d2.loss_cls: 0.1743  decode.d2.loss_mask: 1.0195  decode.d2.loss_dice: 0.7536  decode.d3.loss_cls: 0.1683  decode.d3.loss_mask: 1.0164  decode.d3.loss_dice: 0.7528  decode.d4.loss_cls: 0.1747  decode.d4.loss_mask: 1.0187  decode.d4.loss_dice: 0.7478  decode.d5.loss_cls: 0.1716  decode.d5.loss_mask: 1.0326  decode.d5.loss_dice: 0.7653  decode.d6.loss_cls: 0.1573  decode.d6.loss_mask: 1.0337  decode.d6.loss_dice: 0.7581  decode.d7.loss_cls: 0.1477  decode.d7.loss_mask: 1.0295  decode.d7.loss_dice: 0.7607  decode.d8.loss_cls: 0.1794  decode.d8.loss_mask: 1.0227  decode.d8.loss_dice: 0.7714
05/26 20:20:39 - mmengine - INFO - Iter(train) [ 79750/160000]  base_lr: 5.3740e-05 lr: 5.3740e-06  eta: 9:11:12  time: 0.4112  data_time: 0.0096  memory: 5972  grad_norm: 434.6418  loss: 16.6541  decode.loss_cls: 0.1644  decode.loss_mask: 0.7995  decode.loss_dice: 0.6836  decode.d0.loss_cls: 0.5592  decode.d0.loss_mask: 0.7431  decode.d0.loss_dice: 0.6303  decode.d1.loss_cls: 0.1970  decode.d1.loss_mask: 0.8072  decode.d1.loss_dice: 0.6488  decode.d2.loss_cls: 0.1679  decode.d2.loss_mask: 0.7863  decode.d2.loss_dice: 0.6519  decode.d3.loss_cls: 0.1856  decode.d3.loss_mask: 0.7946  decode.d3.loss_dice: 0.6625  decode.d4.loss_cls: 0.1936  decode.d4.loss_mask: 0.7837  decode.d4.loss_dice: 0.6531  decode.d5.loss_cls: 0.1768  decode.d5.loss_mask: 0.7908  decode.d5.loss_dice: 0.6684  decode.d6.loss_cls: 0.1792  decode.d6.loss_mask: 0.7985  decode.d6.loss_dice: 0.6649  decode.d7.loss_cls: 0.1943  decode.d7.loss_mask: 0.7845  decode.d7.loss_dice: 0.6491  decode.d8.loss_cls: 0.1625  decode.d8.loss_mask: 0.8030  decode.d8.loss_dice: 0.6699
05/26 20:20:59 - mmengine - INFO - Iter(train) [ 79800/160000]  base_lr: 5.3710e-05 lr: 5.3710e-06  eta: 9:10:51  time: 0.4121  data_time: 0.0096  memory: 5967  grad_norm: 487.6694  loss: 22.1123  decode.loss_cls: 0.1765  decode.loss_mask: 1.1339  decode.loss_dice: 0.8770  decode.d0.loss_cls: 0.6555  decode.d0.loss_mask: 1.1121  decode.d0.loss_dice: 0.7884  decode.d1.loss_cls: 0.1890  decode.d1.loss_mask: 1.1349  decode.d1.loss_dice: 0.8542  decode.d2.loss_cls: 0.1954  decode.d2.loss_mask: 1.1387  decode.d2.loss_dice: 0.8580  decode.d3.loss_cls: 0.2129  decode.d3.loss_mask: 1.1126  decode.d3.loss_dice: 0.8397  decode.d4.loss_cls: 0.1828  decode.d4.loss_mask: 1.1328  decode.d4.loss_dice: 0.8535  decode.d5.loss_cls: 0.1488  decode.d5.loss_mask: 1.1372  decode.d5.loss_dice: 0.8680  decode.d6.loss_cls: 0.2087  decode.d6.loss_mask: 1.1126  decode.d6.loss_dice: 0.8367  decode.d7.loss_cls: 0.1996  decode.d7.loss_mask: 1.1457  decode.d7.loss_dice: 0.8399  decode.d8.loss_cls: 0.1484  decode.d8.loss_mask: 1.1610  decode.d8.loss_dice: 0.8577
05/26 20:21:20 - mmengine - INFO - Iter(train) [ 79850/160000]  base_lr: 5.3679e-05 lr: 5.3679e-06  eta: 9:10:30  time: 0.4115  data_time: 0.0096  memory: 5967  grad_norm: 431.9887  loss: 20.2602  decode.loss_cls: 0.2483  decode.loss_mask: 0.9096  decode.loss_dice: 0.7411  decode.d0.loss_cls: 0.8292  decode.d0.loss_mask: 0.8611  decode.d0.loss_dice: 0.7356  decode.d1.loss_cls: 0.2596  decode.d1.loss_mask: 0.9394  decode.d1.loss_dice: 0.7446  decode.d2.loss_cls: 0.2797  decode.d2.loss_mask: 0.9381  decode.d2.loss_dice: 0.7386  decode.d3.loss_cls: 0.3298  decode.d3.loss_mask: 1.0228  decode.d3.loss_dice: 0.7623  decode.d4.loss_cls: 0.2468  decode.d4.loss_mask: 0.9883  decode.d4.loss_dice: 0.7612  decode.d5.loss_cls: 0.2312  decode.d5.loss_mask: 1.0389  decode.d5.loss_dice: 0.7726  decode.d6.loss_cls: 0.3210  decode.d6.loss_mask: 0.9473  decode.d6.loss_dice: 0.7335  decode.d7.loss_cls: 0.2425  decode.d7.loss_mask: 1.0090  decode.d7.loss_dice: 0.7130  decode.d8.loss_cls: 0.2754  decode.d8.loss_mask: 0.8866  decode.d8.loss_dice: 0.7530
05/26 20:21:40 - mmengine - INFO - Iter(train) [ 79900/160000]  base_lr: 5.3649e-05 lr: 5.3649e-06  eta: 9:10:10  time: 0.4209  data_time: 0.0096  memory: 5966  grad_norm: 639.4484  loss: 22.1467  decode.loss_cls: 0.3485  decode.loss_mask: 0.9968  decode.loss_dice: 0.7729  decode.d0.loss_cls: 0.7994  decode.d0.loss_mask: 1.0200  decode.d0.loss_dice: 0.7830  decode.d1.loss_cls: 0.3568  decode.d1.loss_mask: 0.9711  decode.d1.loss_dice: 0.7663  decode.d2.loss_cls: 0.3754  decode.d2.loss_mask: 1.0434  decode.d2.loss_dice: 0.7383  decode.d3.loss_cls: 0.3584  decode.d3.loss_mask: 1.0399  decode.d3.loss_dice: 0.7826  decode.d4.loss_cls: 0.3760  decode.d4.loss_mask: 1.0875  decode.d4.loss_dice: 0.7502  decode.d5.loss_cls: 0.3266  decode.d5.loss_mask: 1.1699  decode.d5.loss_dice: 0.8076  decode.d6.loss_cls: 0.3410  decode.d6.loss_mask: 1.0678  decode.d6.loss_dice: 0.7911  decode.d7.loss_cls: 0.3502  decode.d7.loss_mask: 1.0341  decode.d7.loss_dice: 0.7744  decode.d8.loss_cls: 0.3546  decode.d8.loss_mask: 1.0016  decode.d8.loss_dice: 0.7614
05/26 20:22:01 - mmengine - INFO - Iter(train) [ 79950/160000]  base_lr: 5.3619e-05 lr: 5.3619e-06  eta: 9:09:49  time: 0.4109  data_time: 0.0096  memory: 5976  grad_norm: 663.0750  loss: 22.0264  decode.loss_cls: 0.1268  decode.loss_mask: 1.1772  decode.loss_dice: 0.8429  decode.d0.loss_cls: 0.6199  decode.d0.loss_mask: 1.1420  decode.d0.loss_dice: 0.8305  decode.d1.loss_cls: 0.1719  decode.d1.loss_mask: 1.1451  decode.d1.loss_dice: 0.8540  decode.d2.loss_cls: 0.1194  decode.d2.loss_mask: 1.1845  decode.d2.loss_dice: 0.8484  decode.d3.loss_cls: 0.1659  decode.d3.loss_mask: 1.1486  decode.d3.loss_dice: 0.8372  decode.d4.loss_cls: 0.1377  decode.d4.loss_mask: 1.1929  decode.d4.loss_dice: 0.8436  decode.d5.loss_cls: 0.1238  decode.d5.loss_mask: 1.1703  decode.d5.loss_dice: 0.8533  decode.d6.loss_cls: 0.1180  decode.d6.loss_mask: 1.1770  decode.d6.loss_dice: 0.8560  decode.d7.loss_cls: 0.1180  decode.d7.loss_mask: 1.1844  decode.d7.loss_dice: 0.8722  decode.d8.loss_cls: 0.1252  decode.d8.loss_mask: 1.1745  decode.d8.loss_dice: 0.8649
05/26 20:22:22 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 20:22:22 - mmengine - INFO - Iter(train) [ 80000/160000]  base_lr: 5.3589e-05 lr: 5.3589e-06  eta: 9:09:29  time: 0.4113  data_time: 0.0096  memory: 5982  grad_norm: 772.6722  loss: 21.4204  decode.loss_cls: 0.1960  decode.loss_mask: 1.0727  decode.loss_dice: 0.8193  decode.d0.loss_cls: 0.7273  decode.d0.loss_mask: 1.0741  decode.d0.loss_dice: 0.8190  decode.d1.loss_cls: 0.1721  decode.d1.loss_mask: 1.0973  decode.d1.loss_dice: 0.8443  decode.d2.loss_cls: 0.2119  decode.d2.loss_mask: 1.0669  decode.d2.loss_dice: 0.8166  decode.d3.loss_cls: 0.2067  decode.d3.loss_mask: 1.0631  decode.d3.loss_dice: 0.8033  decode.d4.loss_cls: 0.2061  decode.d4.loss_mask: 1.0978  decode.d4.loss_dice: 0.8325  decode.d5.loss_cls: 0.1991  decode.d5.loss_mask: 1.0936  decode.d5.loss_dice: 0.8102  decode.d6.loss_cls: 0.1827  decode.d6.loss_mask: 1.0946  decode.d6.loss_dice: 0.8030  decode.d7.loss_cls: 0.1728  decode.d7.loss_mask: 1.1004  decode.d7.loss_dice: 0.8091  decode.d8.loss_cls: 0.1592  decode.d8.loss_mask: 1.0757  decode.d8.loss_dice: 0.7928
05/26 20:22:22 - mmengine - INFO - Saving checkpoint at 80000 iterations
05/26 20:22:26 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:10  time: 0.0479  data_time: 0.0012  memory: 1391  
05/26 20:22:28 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:06  time: 0.0475  data_time: 0.0012  memory: 1205  
05/26 20:22:31 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:03  time: 0.0502  data_time: 0.0012  memory: 1596  
05/26 20:22:33 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0483  data_time: 0.0012  memory: 1298  
05/26 20:22:35 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:58  time: 0.0477  data_time: 0.0012  memory: 1298  
05/26 20:22:38 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0476  data_time: 0.0012  memory: 1279  
05/26 20:22:40 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:53  time: 0.0479  data_time: 0.0012  memory: 1224  
05/26 20:22:43 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0497  data_time: 0.0013  memory: 1298  
05/26 20:22:45 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0472  data_time: 0.0012  memory: 1298  
05/26 20:22:48 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0513  data_time: 0.0012  memory: 1725  
05/26 20:22:50 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0477  data_time: 0.0012  memory: 1336  
05/26 20:22:52 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0480  data_time: 0.0012  memory: 1298  
05/26 20:22:55 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0484  data_time: 0.0012  memory: 1205  
05/26 20:22:57 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0514  data_time: 0.0027  memory: 1316  
05/26 20:23:00 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0478  data_time: 0.0012  memory: 1279  
05/26 20:23:02 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0515  data_time: 0.0012  memory: 1410  
05/26 20:23:04 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0477  data_time: 0.0012  memory: 1279  
05/26 20:23:07 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0495  data_time: 0.0013  memory: 1205  
05/26 20:23:09 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0484  data_time: 0.0012  memory: 1205  
05/26 20:23:12 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0476  data_time: 0.0012  memory: 1336  
05/26 20:23:14 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0476  data_time: 0.0012  memory: 1246  
05/26 20:23:16 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0501  data_time: 0.0012  memory: 1503  
05/26 20:23:19 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0476  data_time: 0.0012  memory: 1261  
05/26 20:23:21 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0485  data_time: 0.0012  memory: 1298  
05/26 20:23:24 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0480  data_time: 0.0012  memory: 1447  
05/26 20:23:26 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0482  data_time: 0.0013  memory: 1298  
05/26 20:23:29 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0490  data_time: 0.0012  memory: 1279  
05/26 20:23:31 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0477  data_time: 0.0012  memory: 1205  
05/26 20:23:33 - mmengine - INFO - per class results:
05/26 20:23:33 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.18 | 96.45 |
|  aeroplane  | 88.94 |  96.0 |
|   bicycle   | 43.13 | 97.35 |
|     bird    | 92.73 | 97.33 |
|     boat    | 60.94 | 89.57 |
|    bottle   | 80.85 | 94.18 |
|     bus     | 86.24 | 87.58 |
|     car     | 89.79 | 93.54 |
|     cat     | 94.43 | 97.68 |
|    chair    |  42.4 | 74.11 |
|     cow     | 86.99 | 97.41 |
| diningtable | 62.24 | 85.13 |
|     dog     | 89.77 | 96.65 |
|    horse    | 88.02 | 91.73 |
|  motorbike  | 91.56 | 96.22 |
|    person   | 90.17 | 93.91 |
| pottedplant | 65.69 | 94.51 |
|    sheep    | 85.58 | 88.71 |
|     sofa    | 58.93 | 67.87 |
|    train    |  79.8 | 98.95 |
|  tvmonitor  | 79.93 | 92.88 |
+-------------+-------+-------+
05/26 20:23:33 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.2700  mIoU: 78.7300  mAcc: 91.8000  data_time: 0.0013  time: 0.0481
05/26 20:23:54 - mmengine - INFO - Iter(train) [ 80050/160000]  base_lr: 5.3559e-05 lr: 5.3559e-06  eta: 9:09:08  time: 0.4119  data_time: 0.0096  memory: 5983  grad_norm: 467.5974  loss: 20.3984  decode.loss_cls: 0.1580  decode.loss_mask: 1.0978  decode.loss_dice: 0.7032  decode.d0.loss_cls: 0.6503  decode.d0.loss_mask: 1.0887  decode.d0.loss_dice: 0.7138  decode.d1.loss_cls: 0.1337  decode.d1.loss_mask: 1.1188  decode.d1.loss_dice: 0.7169  decode.d2.loss_cls: 0.1571  decode.d2.loss_mask: 1.1097  decode.d2.loss_dice: 0.7075  decode.d3.loss_cls: 0.1346  decode.d3.loss_mask: 1.1194  decode.d3.loss_dice: 0.7196  decode.d4.loss_cls: 0.2012  decode.d4.loss_mask: 1.1101  decode.d4.loss_dice: 0.6948  decode.d5.loss_cls: 0.2124  decode.d5.loss_mask: 1.1255  decode.d5.loss_dice: 0.7282  decode.d6.loss_cls: 0.1989  decode.d6.loss_mask: 1.1185  decode.d6.loss_dice: 0.7038  decode.d7.loss_cls: 0.1594  decode.d7.loss_mask: 1.1137  decode.d7.loss_dice: 0.7000  decode.d8.loss_cls: 0.1815  decode.d8.loss_mask: 1.1023  decode.d8.loss_dice: 0.7190
05/26 20:24:15 - mmengine - INFO - Iter(train) [ 80100/160000]  base_lr: 5.3529e-05 lr: 5.3529e-06  eta: 9:08:48  time: 0.4123  data_time: 0.0096  memory: 5971  grad_norm: 494.3970  loss: 19.5970  decode.loss_cls: 0.1922  decode.loss_mask: 0.9613  decode.loss_dice: 0.7416  decode.d0.loss_cls: 0.7074  decode.d0.loss_mask: 0.9152  decode.d0.loss_dice: 0.6990  decode.d1.loss_cls: 0.1899  decode.d1.loss_mask: 1.0004  decode.d1.loss_dice: 0.7646  decode.d2.loss_cls: 0.1660  decode.d2.loss_mask: 0.9813  decode.d2.loss_dice: 0.7626  decode.d3.loss_cls: 0.1909  decode.d3.loss_mask: 0.9776  decode.d3.loss_dice: 0.7739  decode.d4.loss_cls: 0.2217  decode.d4.loss_mask: 0.9616  decode.d4.loss_dice: 0.7317  decode.d5.loss_cls: 0.1933  decode.d5.loss_mask: 0.9693  decode.d5.loss_dice: 0.7551  decode.d6.loss_cls: 0.1860  decode.d6.loss_mask: 0.9688  decode.d6.loss_dice: 0.7570  decode.d7.loss_cls: 0.1866  decode.d7.loss_mask: 0.9670  decode.d7.loss_dice: 0.7622  decode.d8.loss_cls: 0.1817  decode.d8.loss_mask: 0.9794  decode.d8.loss_dice: 0.7518
05/26 20:24:35 - mmengine - INFO - Iter(train) [ 80150/160000]  base_lr: 5.3499e-05 lr: 5.3499e-06  eta: 9:08:27  time: 0.4122  data_time: 0.0096  memory: 5981  grad_norm: 442.2957  loss: 17.6183  decode.loss_cls: 0.2059  decode.loss_mask: 0.8510  decode.loss_dice: 0.6321  decode.d0.loss_cls: 0.6494  decode.d0.loss_mask: 0.8660  decode.d0.loss_dice: 0.6557  decode.d1.loss_cls: 0.2145  decode.d1.loss_mask: 0.8672  decode.d1.loss_dice: 0.6383  decode.d2.loss_cls: 0.2361  decode.d2.loss_mask: 0.8662  decode.d2.loss_dice: 0.6412  decode.d3.loss_cls: 0.2354  decode.d3.loss_mask: 0.8743  decode.d3.loss_dice: 0.6298  decode.d4.loss_cls: 0.1964  decode.d4.loss_mask: 0.8665  decode.d4.loss_dice: 0.6369  decode.d5.loss_cls: 0.2367  decode.d5.loss_mask: 0.8650  decode.d5.loss_dice: 0.6419  decode.d6.loss_cls: 0.2315  decode.d6.loss_mask: 0.8624  decode.d6.loss_dice: 0.6479  decode.d7.loss_cls: 0.2157  decode.d7.loss_mask: 0.8568  decode.d7.loss_dice: 0.6210  decode.d8.loss_cls: 0.1925  decode.d8.loss_mask: 0.8515  decode.d8.loss_dice: 0.6327
05/26 20:24:56 - mmengine - INFO - Iter(train) [ 80200/160000]  base_lr: 5.3468e-05 lr: 5.3468e-06  eta: 9:08:06  time: 0.4120  data_time: 0.0095  memory: 5966  grad_norm: 743.0272  loss: 29.1906  decode.loss_cls: 0.4242  decode.loss_mask: 1.3900  decode.loss_dice: 1.0099  decode.d0.loss_cls: 0.8997  decode.d0.loss_mask: 1.3413  decode.d0.loss_dice: 1.0284  decode.d1.loss_cls: 0.4331  decode.d1.loss_mask: 1.4007  decode.d1.loss_dice: 1.0232  decode.d2.loss_cls: 0.4372  decode.d2.loss_mask: 1.4011  decode.d2.loss_dice: 1.0112  decode.d3.loss_cls: 0.4761  decode.d3.loss_mask: 1.4168  decode.d3.loss_dice: 1.0232  decode.d4.loss_cls: 0.4719  decode.d4.loss_mask: 1.3819  decode.d4.loss_dice: 1.0072  decode.d5.loss_cls: 0.4523  decode.d5.loss_mask: 1.3841  decode.d5.loss_dice: 1.0410  decode.d6.loss_cls: 0.4761  decode.d6.loss_mask: 1.4053  decode.d6.loss_dice: 1.0323  decode.d7.loss_cls: 0.4557  decode.d7.loss_mask: 1.3980  decode.d7.loss_dice: 1.0175  decode.d8.loss_cls: 0.4755  decode.d8.loss_mask: 1.4274  decode.d8.loss_dice: 1.0485
05/26 20:25:17 - mmengine - INFO - Iter(train) [ 80250/160000]  base_lr: 5.3438e-05 lr: 5.3438e-06  eta: 9:07:46  time: 0.4119  data_time: 0.0097  memory: 5980  grad_norm: 677.7925  loss: 20.2706  decode.loss_cls: 0.1865  decode.loss_mask: 0.9849  decode.loss_dice: 0.7677  decode.d0.loss_cls: 0.7436  decode.d0.loss_mask: 0.9810  decode.d0.loss_dice: 0.7347  decode.d1.loss_cls: 0.2516  decode.d1.loss_mask: 1.0108  decode.d1.loss_dice: 0.7842  decode.d2.loss_cls: 0.1912  decode.d2.loss_mask: 0.9773  decode.d2.loss_dice: 0.7657  decode.d3.loss_cls: 0.2272  decode.d3.loss_mask: 0.9706  decode.d3.loss_dice: 0.7745  decode.d4.loss_cls: 0.2053  decode.d4.loss_mask: 1.0092  decode.d4.loss_dice: 0.8005  decode.d5.loss_cls: 0.1832  decode.d5.loss_mask: 1.0141  decode.d5.loss_dice: 0.7996  decode.d6.loss_cls: 0.2368  decode.d6.loss_mask: 0.9687  decode.d6.loss_dice: 0.7742  decode.d7.loss_cls: 0.2015  decode.d7.loss_mask: 0.9828  decode.d7.loss_dice: 0.7751  decode.d8.loss_cls: 0.1875  decode.d8.loss_mask: 0.9917  decode.d8.loss_dice: 0.7888
05/26 20:25:37 - mmengine - INFO - Iter(train) [ 80300/160000]  base_lr: 5.3408e-05 lr: 5.3408e-06  eta: 9:07:25  time: 0.4118  data_time: 0.0096  memory: 5982  grad_norm: 1032.6214  loss: 19.7410  decode.loss_cls: 0.1141  decode.loss_mask: 1.0915  decode.loss_dice: 0.6848  decode.d0.loss_cls: 0.7145  decode.d0.loss_mask: 1.0049  decode.d0.loss_dice: 0.6189  decode.d1.loss_cls: 0.1244  decode.d1.loss_mask: 1.0871  decode.d1.loss_dice: 0.7280  decode.d2.loss_cls: 0.1109  decode.d2.loss_mask: 1.0882  decode.d2.loss_dice: 0.7181  decode.d3.loss_cls: 0.1262  decode.d3.loss_mask: 1.0579  decode.d3.loss_dice: 0.6767  decode.d4.loss_cls: 0.1111  decode.d4.loss_mask: 1.1122  decode.d4.loss_dice: 0.7169  decode.d5.loss_cls: 0.0970  decode.d5.loss_mask: 1.1201  decode.d5.loss_dice: 0.7421  decode.d6.loss_cls: 0.1217  decode.d6.loss_mask: 1.1160  decode.d6.loss_dice: 0.7399  decode.d7.loss_cls: 0.1354  decode.d7.loss_mask: 1.1209  decode.d7.loss_dice: 0.7312  decode.d8.loss_cls: 0.1282  decode.d8.loss_mask: 1.0968  decode.d8.loss_dice: 0.7054
05/26 20:25:58 - mmengine - INFO - Iter(train) [ 80350/160000]  base_lr: 5.3378e-05 lr: 5.3378e-06  eta: 9:07:05  time: 0.4124  data_time: 0.0097  memory: 5967  grad_norm: 521.7012  loss: 19.1529  decode.loss_cls: 0.1563  decode.loss_mask: 1.0416  decode.loss_dice: 0.7164  decode.d0.loss_cls: 0.6835  decode.d0.loss_mask: 0.9619  decode.d0.loss_dice: 0.6779  decode.d1.loss_cls: 0.1440  decode.d1.loss_mask: 1.0496  decode.d1.loss_dice: 0.6862  decode.d2.loss_cls: 0.1453  decode.d2.loss_mask: 0.9906  decode.d2.loss_dice: 0.6648  decode.d3.loss_cls: 0.1523  decode.d3.loss_mask: 0.9943  decode.d3.loss_dice: 0.6730  decode.d4.loss_cls: 0.1458  decode.d4.loss_mask: 1.0444  decode.d4.loss_dice: 0.6878  decode.d5.loss_cls: 0.1774  decode.d5.loss_mask: 1.0312  decode.d5.loss_dice: 0.6742  decode.d6.loss_cls: 0.1797  decode.d6.loss_mask: 1.0314  decode.d6.loss_dice: 0.6871  decode.d7.loss_cls: 0.1545  decode.d7.loss_mask: 1.0425  decode.d7.loss_dice: 0.6884  decode.d8.loss_cls: 0.1232  decode.d8.loss_mask: 1.0517  decode.d8.loss_dice: 0.6959
05/26 20:26:18 - mmengine - INFO - Iter(train) [ 80400/160000]  base_lr: 5.3348e-05 lr: 5.3348e-06  eta: 9:06:44  time: 0.4118  data_time: 0.0095  memory: 5975  grad_norm: 623.4483  loss: 25.5089  decode.loss_cls: 0.3314  decode.loss_mask: 1.2311  decode.loss_dice: 0.9065  decode.d0.loss_cls: 0.8383  decode.d0.loss_mask: 1.1863  decode.d0.loss_dice: 0.9237  decode.d1.loss_cls: 0.4335  decode.d1.loss_mask: 1.2111  decode.d1.loss_dice: 0.8937  decode.d2.loss_cls: 0.3432  decode.d2.loss_mask: 1.2363  decode.d2.loss_dice: 0.9068  decode.d3.loss_cls: 0.3502  decode.d3.loss_mask: 1.2525  decode.d3.loss_dice: 0.9235  decode.d4.loss_cls: 0.4133  decode.d4.loss_mask: 1.2260  decode.d4.loss_dice: 0.9221  decode.d5.loss_cls: 0.3645  decode.d5.loss_mask: 1.2134  decode.d5.loss_dice: 0.8904  decode.d6.loss_cls: 0.3770  decode.d6.loss_mask: 1.2341  decode.d6.loss_dice: 0.9057  decode.d7.loss_cls: 0.3445  decode.d7.loss_mask: 1.2388  decode.d7.loss_dice: 0.9493  decode.d8.loss_cls: 0.3793  decode.d8.loss_mask: 1.2096  decode.d8.loss_dice: 0.8727
05/26 20:26:39 - mmengine - INFO - Iter(train) [ 80450/160000]  base_lr: 5.3318e-05 lr: 5.3318e-06  eta: 9:06:23  time: 0.4123  data_time: 0.0097  memory: 5979  grad_norm: 298.9477  loss: 16.2432  decode.loss_cls: 0.2207  decode.loss_mask: 0.7901  decode.loss_dice: 0.6102  decode.d0.loss_cls: 0.6331  decode.d0.loss_mask: 0.8002  decode.d0.loss_dice: 0.6014  decode.d1.loss_cls: 0.2245  decode.d1.loss_mask: 0.7626  decode.d1.loss_dice: 0.5659  decode.d2.loss_cls: 0.2328  decode.d2.loss_mask: 0.7635  decode.d2.loss_dice: 0.5778  decode.d3.loss_cls: 0.1980  decode.d3.loss_mask: 0.7905  decode.d3.loss_dice: 0.5871  decode.d4.loss_cls: 0.1949  decode.d4.loss_mask: 0.8142  decode.d4.loss_dice: 0.5829  decode.d5.loss_cls: 0.2075  decode.d5.loss_mask: 0.7839  decode.d5.loss_dice: 0.5782  decode.d6.loss_cls: 0.2013  decode.d6.loss_mask: 0.7796  decode.d6.loss_dice: 0.5745  decode.d7.loss_cls: 0.1952  decode.d7.loss_mask: 0.7838  decode.d7.loss_dice: 0.5857  decode.d8.loss_cls: 0.2294  decode.d8.loss_mask: 0.7968  decode.d8.loss_dice: 0.5769
05/26 20:27:00 - mmengine - INFO - Iter(train) [ 80500/160000]  base_lr: 5.3287e-05 lr: 5.3287e-06  eta: 9:06:03  time: 0.4125  data_time: 0.0096  memory: 5967  grad_norm: 1320.1735  loss: 19.7080  decode.loss_cls: 0.1417  decode.loss_mask: 1.0155  decode.loss_dice: 0.7410  decode.d0.loss_cls: 0.6431  decode.d0.loss_mask: 1.0116  decode.d0.loss_dice: 0.7756  decode.d1.loss_cls: 0.1457  decode.d1.loss_mask: 1.0431  decode.d1.loss_dice: 0.7566  decode.d2.loss_cls: 0.1307  decode.d2.loss_mask: 1.0148  decode.d2.loss_dice: 0.7496  decode.d3.loss_cls: 0.1400  decode.d3.loss_mask: 1.0015  decode.d3.loss_dice: 0.7313  decode.d4.loss_cls: 0.1561  decode.d4.loss_mask: 1.0255  decode.d4.loss_dice: 0.7683  decode.d5.loss_cls: 0.1450  decode.d5.loss_mask: 1.0246  decode.d5.loss_dice: 0.7594  decode.d6.loss_cls: 0.1488  decode.d6.loss_mask: 1.0073  decode.d6.loss_dice: 0.7765  decode.d7.loss_cls: 0.1666  decode.d7.loss_mask: 1.0168  decode.d7.loss_dice: 0.7534  decode.d8.loss_cls: 0.1387  decode.d8.loss_mask: 1.0160  decode.d8.loss_dice: 0.7631
05/26 20:27:20 - mmengine - INFO - Iter(train) [ 80550/160000]  base_lr: 5.3257e-05 lr: 5.3257e-06  eta: 9:05:42  time: 0.4147  data_time: 0.0105  memory: 5966  grad_norm: 695.5891  loss: 20.7201  decode.loss_cls: 0.1696  decode.loss_mask: 1.0772  decode.loss_dice: 0.7673  decode.d0.loss_cls: 0.7970  decode.d0.loss_mask: 1.0161  decode.d0.loss_dice: 0.7391  decode.d1.loss_cls: 0.1681  decode.d1.loss_mask: 1.0927  decode.d1.loss_dice: 0.7552  decode.d2.loss_cls: 0.1976  decode.d2.loss_mask: 1.0872  decode.d2.loss_dice: 0.7508  decode.d3.loss_cls: 0.2133  decode.d3.loss_mask: 1.0740  decode.d3.loss_dice: 0.7695  decode.d4.loss_cls: 0.1756  decode.d4.loss_mask: 1.0577  decode.d4.loss_dice: 0.7637  decode.d5.loss_cls: 0.1405  decode.d5.loss_mask: 1.0763  decode.d5.loss_dice: 0.7867  decode.d6.loss_cls: 0.2210  decode.d6.loss_mask: 1.0423  decode.d6.loss_dice: 0.7579  decode.d7.loss_cls: 0.1729  decode.d7.loss_mask: 1.0809  decode.d7.loss_dice: 0.7669  decode.d8.loss_cls: 0.1518  decode.d8.loss_mask: 1.0719  decode.d8.loss_dice: 0.7791
05/26 20:27:41 - mmengine - INFO - Iter(train) [ 80600/160000]  base_lr: 5.3227e-05 lr: 5.3227e-06  eta: 9:05:22  time: 0.4136  data_time: 0.0096  memory: 5985  grad_norm: 471.1209  loss: 24.9723  decode.loss_cls: 0.3112  decode.loss_mask: 1.1813  decode.loss_dice: 0.9897  decode.d0.loss_cls: 0.8236  decode.d0.loss_mask: 1.1331  decode.d0.loss_dice: 0.9584  decode.d1.loss_cls: 0.2621  decode.d1.loss_mask: 1.2096  decode.d1.loss_dice: 0.9742  decode.d2.loss_cls: 0.2531  decode.d2.loss_mask: 1.1694  decode.d2.loss_dice: 0.9631  decode.d3.loss_cls: 0.2968  decode.d3.loss_mask: 1.1754  decode.d3.loss_dice: 1.0027  decode.d4.loss_cls: 0.2968  decode.d4.loss_mask: 1.1685  decode.d4.loss_dice: 0.9855  decode.d5.loss_cls: 0.2965  decode.d5.loss_mask: 1.1848  decode.d5.loss_dice: 0.9749  decode.d6.loss_cls: 0.2810  decode.d6.loss_mask: 1.1766  decode.d6.loss_dice: 1.0007  decode.d7.loss_cls: 0.2921  decode.d7.loss_mask: 1.1514  decode.d7.loss_dice: 0.9759  decode.d8.loss_cls: 0.3342  decode.d8.loss_mask: 1.1783  decode.d8.loss_dice: 0.9711
05/26 20:28:02 - mmengine - INFO - Iter(train) [ 80650/160000]  base_lr: 5.3197e-05 lr: 5.3197e-06  eta: 9:05:01  time: 0.4117  data_time: 0.0097  memory: 5973  grad_norm: 520.8408  loss: 18.5615  decode.loss_cls: 0.1422  decode.loss_mask: 0.9613  decode.loss_dice: 0.6872  decode.d0.loss_cls: 0.6043  decode.d0.loss_mask: 0.9556  decode.d0.loss_dice: 0.6819  decode.d1.loss_cls: 0.1637  decode.d1.loss_mask: 0.9617  decode.d1.loss_dice: 0.6983  decode.d2.loss_cls: 0.1546  decode.d2.loss_mask: 0.9406  decode.d2.loss_dice: 0.6949  decode.d3.loss_cls: 0.1957  decode.d3.loss_mask: 0.9648  decode.d3.loss_dice: 0.6999  decode.d4.loss_cls: 0.1770  decode.d4.loss_mask: 0.9406  decode.d4.loss_dice: 0.6987  decode.d5.loss_cls: 0.1627  decode.d5.loss_mask: 0.9701  decode.d5.loss_dice: 0.6906  decode.d6.loss_cls: 0.2167  decode.d6.loss_mask: 0.9179  decode.d6.loss_dice: 0.6841  decode.d7.loss_cls: 0.1552  decode.d7.loss_mask: 0.9645  decode.d7.loss_dice: 0.6910  decode.d8.loss_cls: 0.1330  decode.d8.loss_mask: 0.9493  decode.d8.loss_dice: 0.7034
05/26 20:28:22 - mmengine - INFO - Iter(train) [ 80700/160000]  base_lr: 5.3167e-05 lr: 5.3167e-06  eta: 9:04:40  time: 0.4119  data_time: 0.0096  memory: 5971  grad_norm: 720.7200  loss: 23.1908  decode.loss_cls: 0.2530  decode.loss_mask: 1.1622  decode.loss_dice: 0.8114  decode.d0.loss_cls: 0.8298  decode.d0.loss_mask: 1.0998  decode.d0.loss_dice: 0.8263  decode.d1.loss_cls: 0.2340  decode.d1.loss_mask: 1.1880  decode.d1.loss_dice: 0.8516  decode.d2.loss_cls: 0.2644  decode.d2.loss_mask: 1.1783  decode.d2.loss_dice: 0.8344  decode.d3.loss_cls: 0.2655  decode.d3.loss_mask: 1.1544  decode.d3.loss_dice: 0.8723  decode.d4.loss_cls: 0.2402  decode.d4.loss_mask: 1.1878  decode.d4.loss_dice: 0.8545  decode.d5.loss_cls: 0.2468  decode.d5.loss_mask: 1.1951  decode.d5.loss_dice: 0.8533  decode.d6.loss_cls: 0.2261  decode.d6.loss_mask: 1.1778  decode.d6.loss_dice: 0.8662  decode.d7.loss_cls: 0.2317  decode.d7.loss_mask: 1.1657  decode.d7.loss_dice: 0.8483  decode.d8.loss_cls: 0.2619  decode.d8.loss_mask: 1.1731  decode.d8.loss_dice: 0.8368
05/26 20:28:43 - mmengine - INFO - Iter(train) [ 80750/160000]  base_lr: 5.3137e-05 lr: 5.3137e-06  eta: 9:04:20  time: 0.4127  data_time: 0.0096  memory: 5966  grad_norm: 473.6091  loss: 20.9238  decode.loss_cls: 0.3174  decode.loss_mask: 0.9752  decode.loss_dice: 0.7552  decode.d0.loss_cls: 0.7139  decode.d0.loss_mask: 0.9715  decode.d0.loss_dice: 0.7349  decode.d1.loss_cls: 0.3199  decode.d1.loss_mask: 0.9752  decode.d1.loss_dice: 0.7526  decode.d2.loss_cls: 0.2968  decode.d2.loss_mask: 0.9836  decode.d2.loss_dice: 0.7379  decode.d3.loss_cls: 0.3141  decode.d3.loss_mask: 0.9588  decode.d3.loss_dice: 0.7488  decode.d4.loss_cls: 0.3223  decode.d4.loss_mask: 0.9670  decode.d4.loss_dice: 0.7665  decode.d5.loss_cls: 0.2843  decode.d5.loss_mask: 1.0306  decode.d5.loss_dice: 0.7897  decode.d6.loss_cls: 0.2960  decode.d6.loss_mask: 1.0366  decode.d6.loss_dice: 0.7834  decode.d7.loss_cls: 0.2772  decode.d7.loss_mask: 0.9725  decode.d7.loss_dice: 0.7740  decode.d8.loss_cls: 0.3043  decode.d8.loss_mask: 0.9836  decode.d8.loss_dice: 0.7801
05/26 20:29:04 - mmengine - INFO - Iter(train) [ 80800/160000]  base_lr: 5.3106e-05 lr: 5.3106e-06  eta: 9:03:59  time: 0.4116  data_time: 0.0096  memory: 5975  grad_norm: 1006.0928  loss: 22.3311  decode.loss_cls: 0.1393  decode.loss_mask: 1.2926  decode.loss_dice: 0.8108  decode.d0.loss_cls: 0.6553  decode.d0.loss_mask: 1.1569  decode.d0.loss_dice: 0.7446  decode.d1.loss_cls: 0.1674  decode.d1.loss_mask: 1.2148  decode.d1.loss_dice: 0.7880  decode.d2.loss_cls: 0.1688  decode.d2.loss_mask: 1.2573  decode.d2.loss_dice: 0.7829  decode.d3.loss_cls: 0.1728  decode.d3.loss_mask: 1.2585  decode.d3.loss_dice: 0.8217  decode.d4.loss_cls: 0.1684  decode.d4.loss_mask: 1.2492  decode.d4.loss_dice: 0.7760  decode.d5.loss_cls: 0.1620  decode.d5.loss_mask: 1.2586  decode.d5.loss_dice: 0.7710  decode.d6.loss_cls: 0.1840  decode.d6.loss_mask: 1.2171  decode.d6.loss_dice: 0.7747  decode.d7.loss_cls: 0.1789  decode.d7.loss_mask: 1.1986  decode.d7.loss_dice: 0.7935  decode.d8.loss_cls: 0.1722  decode.d8.loss_mask: 1.2226  decode.d8.loss_dice: 0.7728
05/26 20:29:24 - mmengine - INFO - Iter(train) [ 80850/160000]  base_lr: 5.3076e-05 lr: 5.3076e-06  eta: 9:03:39  time: 0.4119  data_time: 0.0096  memory: 5968  grad_norm: 440.2576  loss: 17.9537  decode.loss_cls: 0.1372  decode.loss_mask: 1.0091  decode.loss_dice: 0.6496  decode.d0.loss_cls: 0.4565  decode.d0.loss_mask: 0.9670  decode.d0.loss_dice: 0.6330  decode.d1.loss_cls: 0.1117  decode.d1.loss_mask: 1.0139  decode.d1.loss_dice: 0.6800  decode.d2.loss_cls: 0.1223  decode.d2.loss_mask: 0.9734  decode.d2.loss_dice: 0.6436  decode.d3.loss_cls: 0.1206  decode.d3.loss_mask: 0.9887  decode.d3.loss_dice: 0.6560  decode.d4.loss_cls: 0.0992  decode.d4.loss_mask: 1.0016  decode.d4.loss_dice: 0.6556  decode.d5.loss_cls: 0.0916  decode.d5.loss_mask: 1.0001  decode.d5.loss_dice: 0.6568  decode.d6.loss_cls: 0.1004  decode.d6.loss_mask: 0.9890  decode.d6.loss_dice: 0.6435  decode.d7.loss_cls: 0.1334  decode.d7.loss_mask: 0.9872  decode.d7.loss_dice: 0.6433  decode.d8.loss_cls: 0.1352  decode.d8.loss_mask: 1.0018  decode.d8.loss_dice: 0.6527
05/26 20:29:45 - mmengine - INFO - Iter(train) [ 80900/160000]  base_lr: 5.3046e-05 lr: 5.3046e-06  eta: 9:03:18  time: 0.4127  data_time: 0.0096  memory: 5984  grad_norm: 1117.0420  loss: 19.4569  decode.loss_cls: 0.2084  decode.loss_mask: 1.0089  decode.loss_dice: 0.6980  decode.d0.loss_cls: 0.7373  decode.d0.loss_mask: 0.8884  decode.d0.loss_dice: 0.6648  decode.d1.loss_cls: 0.2219  decode.d1.loss_mask: 0.9712  decode.d1.loss_dice: 0.7001  decode.d2.loss_cls: 0.2243  decode.d2.loss_mask: 0.9922  decode.d2.loss_dice: 0.6864  decode.d3.loss_cls: 0.2184  decode.d3.loss_mask: 0.9962  decode.d3.loss_dice: 0.6996  decode.d4.loss_cls: 0.1907  decode.d4.loss_mask: 1.0088  decode.d4.loss_dice: 0.6912  decode.d5.loss_cls: 0.2181  decode.d5.loss_mask: 0.9768  decode.d5.loss_dice: 0.7015  decode.d6.loss_cls: 0.2665  decode.d6.loss_mask: 0.9571  decode.d6.loss_dice: 0.6991  decode.d7.loss_cls: 0.2311  decode.d7.loss_mask: 0.9608  decode.d7.loss_dice: 0.7075  decode.d8.loss_cls: 0.2176  decode.d8.loss_mask: 1.0083  decode.d8.loss_dice: 0.7059
05/26 20:30:05 - mmengine - INFO - Iter(train) [ 80950/160000]  base_lr: 5.3016e-05 lr: 5.3016e-06  eta: 9:02:57  time: 0.4114  data_time: 0.0096  memory: 5970  grad_norm: 412.1100  loss: 20.1021  decode.loss_cls: 0.1957  decode.loss_mask: 1.0717  decode.loss_dice: 0.6972  decode.d0.loss_cls: 0.5871  decode.d0.loss_mask: 1.0861  decode.d0.loss_dice: 0.6475  decode.d1.loss_cls: 0.2235  decode.d1.loss_mask: 1.0825  decode.d1.loss_dice: 0.6680  decode.d2.loss_cls: 0.2224  decode.d2.loss_mask: 1.0797  decode.d2.loss_dice: 0.6881  decode.d3.loss_cls: 0.1736  decode.d3.loss_mask: 1.0891  decode.d3.loss_dice: 0.7036  decode.d4.loss_cls: 0.1751  decode.d4.loss_mask: 1.1197  decode.d4.loss_dice: 0.6933  decode.d5.loss_cls: 0.2030  decode.d5.loss_mask: 1.0798  decode.d5.loss_dice: 0.6785  decode.d6.loss_cls: 0.1858  decode.d6.loss_mask: 1.0914  decode.d6.loss_dice: 0.7115  decode.d7.loss_cls: 0.2182  decode.d7.loss_mask: 1.0855  decode.d7.loss_dice: 0.6885  decode.d8.loss_cls: 0.1961  decode.d8.loss_mask: 1.0813  decode.d8.loss_dice: 0.6786
05/26 20:30:26 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 20:30:26 - mmengine - INFO - Iter(train) [ 81000/160000]  base_lr: 5.2986e-05 lr: 5.2986e-06  eta: 9:02:37  time: 0.4117  data_time: 0.0097  memory: 5976  grad_norm: 601.5313  loss: 21.7513  decode.loss_cls: 0.2018  decode.loss_mask: 1.2234  decode.loss_dice: 0.7675  decode.d0.loss_cls: 0.7250  decode.d0.loss_mask: 1.1145  decode.d0.loss_dice: 0.7459  decode.d1.loss_cls: 0.2295  decode.d1.loss_mask: 1.1780  decode.d1.loss_dice: 0.7451  decode.d2.loss_cls: 0.1353  decode.d2.loss_mask: 1.1723  decode.d2.loss_dice: 0.7773  decode.d3.loss_cls: 0.1621  decode.d3.loss_mask: 1.1740  decode.d3.loss_dice: 0.7747  decode.d4.loss_cls: 0.1638  decode.d4.loss_mask: 1.1759  decode.d4.loss_dice: 0.7544  decode.d5.loss_cls: 0.2084  decode.d5.loss_mask: 1.1701  decode.d5.loss_dice: 0.7465  decode.d6.loss_cls: 0.2125  decode.d6.loss_mask: 1.1790  decode.d6.loss_dice: 0.7522  decode.d7.loss_cls: 0.2148  decode.d7.loss_mask: 1.1679  decode.d7.loss_dice: 0.7523  decode.d8.loss_cls: 0.2123  decode.d8.loss_mask: 1.1555  decode.d8.loss_dice: 0.7590
05/26 20:30:47 - mmengine - INFO - Iter(train) [ 81050/160000]  base_lr: 5.2956e-05 lr: 5.2956e-06  eta: 9:02:16  time: 0.4144  data_time: 0.0099  memory: 5987  grad_norm: 518.3330  loss: 24.1289  decode.loss_cls: 0.1802  decode.loss_mask: 1.3053  decode.loss_dice: 0.8795  decode.d0.loss_cls: 0.6669  decode.d0.loss_mask: 1.1338  decode.d0.loss_dice: 0.8497  decode.d1.loss_cls: 0.2737  decode.d1.loss_mask: 1.2599  decode.d1.loss_dice: 0.8664  decode.d2.loss_cls: 0.2307  decode.d2.loss_mask: 1.2385  decode.d2.loss_dice: 0.8650  decode.d3.loss_cls: 0.2254  decode.d3.loss_mask: 1.3040  decode.d3.loss_dice: 0.8956  decode.d4.loss_cls: 0.2113  decode.d4.loss_mask: 1.2701  decode.d4.loss_dice: 0.8806  decode.d5.loss_cls: 0.2132  decode.d5.loss_mask: 1.2666  decode.d5.loss_dice: 0.9156  decode.d6.loss_cls: 0.1595  decode.d6.loss_mask: 1.3466  decode.d6.loss_dice: 0.9062  decode.d7.loss_cls: 0.2230  decode.d7.loss_mask: 1.3093  decode.d7.loss_dice: 0.8999  decode.d8.loss_cls: 0.2227  decode.d8.loss_mask: 1.2419  decode.d8.loss_dice: 0.8879
05/26 20:31:07 - mmengine - INFO - Iter(train) [ 81100/160000]  base_lr: 5.2925e-05 lr: 5.2925e-06  eta: 9:01:56  time: 0.4121  data_time: 0.0097  memory: 5966  grad_norm: 365.5762  loss: 19.1128  decode.loss_cls: 0.1656  decode.loss_mask: 0.9463  decode.loss_dice: 0.7289  decode.d0.loss_cls: 0.5894  decode.d0.loss_mask: 0.9556  decode.d0.loss_dice: 0.7286  decode.d1.loss_cls: 0.2060  decode.d1.loss_mask: 0.9448  decode.d1.loss_dice: 0.7372  decode.d2.loss_cls: 0.1830  decode.d2.loss_mask: 0.9512  decode.d2.loss_dice: 0.7342  decode.d3.loss_cls: 0.1948  decode.d3.loss_mask: 0.9498  decode.d3.loss_dice: 0.7305  decode.d4.loss_cls: 0.1979  decode.d4.loss_mask: 0.9491  decode.d4.loss_dice: 0.7472  decode.d5.loss_cls: 0.1891  decode.d5.loss_mask: 0.9539  decode.d5.loss_dice: 0.7361  decode.d6.loss_cls: 0.1486  decode.d6.loss_mask: 0.9701  decode.d6.loss_dice: 0.7521  decode.d7.loss_cls: 0.1754  decode.d7.loss_mask: 0.9405  decode.d7.loss_dice: 0.7358  decode.d8.loss_cls: 0.1864  decode.d8.loss_mask: 0.9567  decode.d8.loss_dice: 0.7281
05/26 20:31:28 - mmengine - INFO - Iter(train) [ 81150/160000]  base_lr: 5.2895e-05 lr: 5.2895e-06  eta: 9:01:35  time: 0.4116  data_time: 0.0095  memory: 5976  grad_norm: 570.5408  loss: 23.6681  decode.loss_cls: 0.2433  decode.loss_mask: 1.2661  decode.loss_dice: 0.8146  decode.d0.loss_cls: 0.6555  decode.d0.loss_mask: 1.2435  decode.d0.loss_dice: 0.8544  decode.d1.loss_cls: 0.2469  decode.d1.loss_mask: 1.2469  decode.d1.loss_dice: 0.8160  decode.d2.loss_cls: 0.2511  decode.d2.loss_mask: 1.2679  decode.d2.loss_dice: 0.8169  decode.d3.loss_cls: 0.2523  decode.d3.loss_mask: 1.3001  decode.d3.loss_dice: 0.8324  decode.d4.loss_cls: 0.2103  decode.d4.loss_mask: 1.2901  decode.d4.loss_dice: 0.8251  decode.d5.loss_cls: 0.2352  decode.d5.loss_mask: 1.2676  decode.d5.loss_dice: 0.8187  decode.d6.loss_cls: 0.1778  decode.d6.loss_mask: 1.3155  decode.d6.loss_dice: 0.8272  decode.d7.loss_cls: 0.2308  decode.d7.loss_mask: 1.2518  decode.d7.loss_dice: 0.8068  decode.d8.loss_cls: 0.2086  decode.d8.loss_mask: 1.2863  decode.d8.loss_dice: 0.8086
05/26 20:31:49 - mmengine - INFO - Iter(train) [ 81200/160000]  base_lr: 5.2865e-05 lr: 5.2865e-06  eta: 9:01:15  time: 0.4128  data_time: 0.0097  memory: 5966  grad_norm: 491.4126  loss: 22.0759  decode.loss_cls: 0.2083  decode.loss_mask: 1.0920  decode.loss_dice: 0.8170  decode.d0.loss_cls: 0.6965  decode.d0.loss_mask: 1.0643  decode.d0.loss_dice: 0.8558  decode.d1.loss_cls: 0.2509  decode.d1.loss_mask: 1.0754  decode.d1.loss_dice: 0.7996  decode.d2.loss_cls: 0.2597  decode.d2.loss_mask: 1.0917  decode.d2.loss_dice: 0.8222  decode.d3.loss_cls: 0.2571  decode.d3.loss_mask: 1.0803  decode.d3.loss_dice: 0.8114  decode.d4.loss_cls: 0.2610  decode.d4.loss_mask: 1.0782  decode.d4.loss_dice: 0.8224  decode.d5.loss_cls: 0.2275  decode.d5.loss_mask: 1.0895  decode.d5.loss_dice: 0.8422  decode.d6.loss_cls: 0.2238  decode.d6.loss_mask: 1.1107  decode.d6.loss_dice: 0.8253  decode.d7.loss_cls: 0.2179  decode.d7.loss_mask: 1.1347  decode.d7.loss_dice: 0.8600  decode.d8.loss_cls: 0.2358  decode.d8.loss_mask: 1.1168  decode.d8.loss_dice: 0.8477
05/26 20:32:09 - mmengine - INFO - Iter(train) [ 81250/160000]  base_lr: 5.2835e-05 lr: 5.2835e-06  eta: 9:00:54  time: 0.4116  data_time: 0.0096  memory: 5966  grad_norm: 996.4578  loss: 20.9953  decode.loss_cls: 0.1833  decode.loss_mask: 1.1493  decode.loss_dice: 0.7399  decode.d0.loss_cls: 0.7144  decode.d0.loss_mask: 1.0499  decode.d0.loss_dice: 0.6931  decode.d1.loss_cls: 0.2050  decode.d1.loss_mask: 1.1096  decode.d1.loss_dice: 0.7422  decode.d2.loss_cls: 0.1964  decode.d2.loss_mask: 1.1040  decode.d2.loss_dice: 0.7047  decode.d3.loss_cls: 0.1885  decode.d3.loss_mask: 1.0900  decode.d3.loss_dice: 0.7310  decode.d4.loss_cls: 0.1854  decode.d4.loss_mask: 1.1313  decode.d4.loss_dice: 0.7377  decode.d5.loss_cls: 0.2177  decode.d5.loss_mask: 1.1514  decode.d5.loss_dice: 0.7641  decode.d6.loss_cls: 0.2278  decode.d6.loss_mask: 1.1293  decode.d6.loss_dice: 0.7466  decode.d7.loss_cls: 0.2099  decode.d7.loss_mask: 1.1120  decode.d7.loss_dice: 0.7404  decode.d8.loss_cls: 0.1915  decode.d8.loss_mask: 1.0987  decode.d8.loss_dice: 0.7503
05/26 20:32:30 - mmengine - INFO - Iter(train) [ 81300/160000]  base_lr: 5.2805e-05 lr: 5.2805e-06  eta: 9:00:33  time: 0.4135  data_time: 0.0105  memory: 5965  grad_norm: 734.5959  loss: 23.3038  decode.loss_cls: 0.3397  decode.loss_mask: 1.1074  decode.loss_dice: 0.8870  decode.d0.loss_cls: 0.8874  decode.d0.loss_mask: 1.0084  decode.d0.loss_dice: 0.8187  decode.d1.loss_cls: 0.3816  decode.d1.loss_mask: 1.0369  decode.d1.loss_dice: 0.8368  decode.d2.loss_cls: 0.3670  decode.d2.loss_mask: 1.0617  decode.d2.loss_dice: 0.8351  decode.d3.loss_cls: 0.3628  decode.d3.loss_mask: 1.0678  decode.d3.loss_dice: 0.8401  decode.d4.loss_cls: 0.3718  decode.d4.loss_mask: 1.0847  decode.d4.loss_dice: 0.8830  decode.d5.loss_cls: 0.3329  decode.d5.loss_mask: 1.0760  decode.d5.loss_dice: 0.8553  decode.d6.loss_cls: 0.3348  decode.d6.loss_mask: 1.0752  decode.d6.loss_dice: 0.8635  decode.d7.loss_cls: 0.3621  decode.d7.loss_mask: 1.0672  decode.d7.loss_dice: 0.8495  decode.d8.loss_cls: 0.3531  decode.d8.loss_mask: 1.0969  decode.d8.loss_dice: 0.8592
05/26 20:32:51 - mmengine - INFO - Iter(train) [ 81350/160000]  base_lr: 5.2774e-05 lr: 5.2774e-06  eta: 9:00:13  time: 0.4125  data_time: 0.0095  memory: 5982  grad_norm: 602.3773  loss: 19.8859  decode.loss_cls: 0.1382  decode.loss_mask: 1.0556  decode.loss_dice: 0.7036  decode.d0.loss_cls: 0.6455  decode.d0.loss_mask: 1.0211  decode.d0.loss_dice: 0.6614  decode.d1.loss_cls: 0.1999  decode.d1.loss_mask: 1.0691  decode.d1.loss_dice: 0.6852  decode.d2.loss_cls: 0.1879  decode.d2.loss_mask: 1.0754  decode.d2.loss_dice: 0.6854  decode.d3.loss_cls: 0.1829  decode.d3.loss_mask: 1.0683  decode.d3.loss_dice: 0.7053  decode.d4.loss_cls: 0.2130  decode.d4.loss_mask: 1.0699  decode.d4.loss_dice: 0.6796  decode.d5.loss_cls: 0.1587  decode.d5.loss_mask: 1.0748  decode.d5.loss_dice: 0.7121  decode.d6.loss_cls: 0.1827  decode.d6.loss_mask: 1.0740  decode.d6.loss_dice: 0.7156  decode.d7.loss_cls: 0.1687  decode.d7.loss_mask: 1.1067  decode.d7.loss_dice: 0.7103  decode.d8.loss_cls: 0.1630  decode.d8.loss_mask: 1.0608  decode.d8.loss_dice: 0.7112
05/26 20:33:11 - mmengine - INFO - Iter(train) [ 81400/160000]  base_lr: 5.2744e-05 lr: 5.2744e-06  eta: 8:59:52  time: 0.4121  data_time: 0.0096  memory: 5980  grad_norm: 517.7932  loss: 21.4667  decode.loss_cls: 0.1907  decode.loss_mask: 1.1046  decode.loss_dice: 0.7743  decode.d0.loss_cls: 0.6556  decode.d0.loss_mask: 1.1091  decode.d0.loss_dice: 0.7813  decode.d1.loss_cls: 0.1932  decode.d1.loss_mask: 1.1517  decode.d1.loss_dice: 0.7825  decode.d2.loss_cls: 0.2088  decode.d2.loss_mask: 1.1048  decode.d2.loss_dice: 0.7740  decode.d3.loss_cls: 0.1929  decode.d3.loss_mask: 1.1027  decode.d3.loss_dice: 0.7645  decode.d4.loss_cls: 0.1917  decode.d4.loss_mask: 1.1490  decode.d4.loss_dice: 0.7874  decode.d5.loss_cls: 0.1926  decode.d5.loss_mask: 1.1372  decode.d5.loss_dice: 0.7891  decode.d6.loss_cls: 0.1903  decode.d6.loss_mask: 1.1506  decode.d6.loss_dice: 0.7711  decode.d7.loss_cls: 0.1656  decode.d7.loss_mask: 1.1848  decode.d7.loss_dice: 0.7866  decode.d8.loss_cls: 0.1905  decode.d8.loss_mask: 1.1201  decode.d8.loss_dice: 0.7693
05/26 20:33:32 - mmengine - INFO - Iter(train) [ 81450/160000]  base_lr: 5.2714e-05 lr: 5.2714e-06  eta: 8:59:32  time: 0.4127  data_time: 0.0097  memory: 5973  grad_norm: 400.6948  loss: 19.5374  decode.loss_cls: 0.2072  decode.loss_mask: 0.9373  decode.loss_dice: 0.7876  decode.d0.loss_cls: 0.7640  decode.d0.loss_mask: 0.9048  decode.d0.loss_dice: 0.7373  decode.d1.loss_cls: 0.1811  decode.d1.loss_mask: 0.9378  decode.d1.loss_dice: 0.7794  decode.d2.loss_cls: 0.1751  decode.d2.loss_mask: 0.9338  decode.d2.loss_dice: 0.7740  decode.d3.loss_cls: 0.2128  decode.d3.loss_mask: 0.9295  decode.d3.loss_dice: 0.7570  decode.d4.loss_cls: 0.2337  decode.d4.loss_mask: 0.9255  decode.d4.loss_dice: 0.7541  decode.d5.loss_cls: 0.1736  decode.d5.loss_mask: 0.9381  decode.d5.loss_dice: 0.7913  decode.d6.loss_cls: 0.2019  decode.d6.loss_mask: 0.9246  decode.d6.loss_dice: 0.7736  decode.d7.loss_cls: 0.1835  decode.d7.loss_mask: 0.9376  decode.d7.loss_dice: 0.7682  decode.d8.loss_cls: 0.1927  decode.d8.loss_mask: 0.9393  decode.d8.loss_dice: 0.7808
05/26 20:33:52 - mmengine - INFO - Iter(train) [ 81500/160000]  base_lr: 5.2684e-05 lr: 5.2684e-06  eta: 8:59:11  time: 0.4114  data_time: 0.0095  memory: 5968  grad_norm: 708.0413  loss: 24.3874  decode.loss_cls: 0.2474  decode.loss_mask: 1.2728  decode.loss_dice: 0.8497  decode.d0.loss_cls: 0.7474  decode.d0.loss_mask: 1.2208  decode.d0.loss_dice: 0.8342  decode.d1.loss_cls: 0.2701  decode.d1.loss_mask: 1.2506  decode.d1.loss_dice: 0.8453  decode.d2.loss_cls: 0.2266  decode.d2.loss_mask: 1.2878  decode.d2.loss_dice: 0.8921  decode.d3.loss_cls: 0.2341  decode.d3.loss_mask: 1.2903  decode.d3.loss_dice: 0.8359  decode.d4.loss_cls: 0.1955  decode.d4.loss_mask: 1.3818  decode.d4.loss_dice: 0.8732  decode.d5.loss_cls: 0.2327  decode.d5.loss_mask: 1.3422  decode.d5.loss_dice: 0.8519  decode.d6.loss_cls: 0.2397  decode.d6.loss_mask: 1.2895  decode.d6.loss_dice: 0.8331  decode.d7.loss_cls: 0.2284  decode.d7.loss_mask: 1.3086  decode.d7.loss_dice: 0.8569  decode.d8.loss_cls: 0.2271  decode.d8.loss_mask: 1.3450  decode.d8.loss_dice: 0.8764
05/26 20:34:13 - mmengine - INFO - Iter(train) [ 81550/160000]  base_lr: 5.2654e-05 lr: 5.2654e-06  eta: 8:58:50  time: 0.4114  data_time: 0.0095  memory: 5977  grad_norm: 946.8875  loss: 21.7173  decode.loss_cls: 0.2851  decode.loss_mask: 1.1259  decode.loss_dice: 0.7197  decode.d0.loss_cls: 0.8034  decode.d0.loss_mask: 1.0632  decode.d0.loss_dice: 0.6559  decode.d1.loss_cls: 0.2736  decode.d1.loss_mask: 1.1468  decode.d1.loss_dice: 0.7265  decode.d2.loss_cls: 0.2773  decode.d2.loss_mask: 1.1003  decode.d2.loss_dice: 0.7155  decode.d3.loss_cls: 0.2970  decode.d3.loss_mask: 1.0798  decode.d3.loss_dice: 0.7148  decode.d4.loss_cls: 0.2850  decode.d4.loss_mask: 1.0847  decode.d4.loss_dice: 0.7235  decode.d5.loss_cls: 0.2180  decode.d5.loss_mask: 1.2030  decode.d5.loss_dice: 0.7697  decode.d6.loss_cls: 0.3393  decode.d6.loss_mask: 1.1553  decode.d6.loss_dice: 0.7266  decode.d7.loss_cls: 0.3020  decode.d7.loss_mask: 1.0855  decode.d7.loss_dice: 0.7112  decode.d8.loss_cls: 0.3331  decode.d8.loss_mask: 1.0691  decode.d8.loss_dice: 0.7265
05/26 20:34:34 - mmengine - INFO - Iter(train) [ 81600/160000]  base_lr: 5.2623e-05 lr: 5.2623e-06  eta: 8:58:30  time: 0.4117  data_time: 0.0096  memory: 5969  grad_norm: 1217.6927  loss: 26.4857  decode.loss_cls: 0.2753  decode.loss_mask: 1.3173  decode.loss_dice: 0.9960  decode.d0.loss_cls: 0.7718  decode.d0.loss_mask: 1.2384  decode.d0.loss_dice: 0.9558  decode.d1.loss_cls: 0.2691  decode.d1.loss_mask: 1.3365  decode.d1.loss_dice: 1.0133  decode.d2.loss_cls: 0.2825  decode.d2.loss_mask: 1.3515  decode.d2.loss_dice: 0.9983  decode.d3.loss_cls: 0.2766  decode.d3.loss_mask: 1.3425  decode.d3.loss_dice: 0.9869  decode.d4.loss_cls: 0.3188  decode.d4.loss_mask: 1.2807  decode.d4.loss_dice: 0.9454  decode.d5.loss_cls: 0.3208  decode.d5.loss_mask: 1.3144  decode.d5.loss_dice: 0.9498  decode.d6.loss_cls: 0.2891  decode.d6.loss_mask: 1.3269  decode.d6.loss_dice: 0.9962  decode.d7.loss_cls: 0.2506  decode.d7.loss_mask: 1.3620  decode.d7.loss_dice: 1.0236  decode.d8.loss_cls: 0.2515  decode.d8.loss_mask: 1.4132  decode.d8.loss_dice: 1.0311
05/26 20:34:54 - mmengine - INFO - Iter(train) [ 81650/160000]  base_lr: 5.2593e-05 lr: 5.2593e-06  eta: 8:58:09  time: 0.4121  data_time: 0.0097  memory: 5971  grad_norm: 656.0594  loss: 25.8104  decode.loss_cls: 0.3444  decode.loss_mask: 1.1421  decode.loss_dice: 0.9744  decode.d0.loss_cls: 0.9260  decode.d0.loss_mask: 1.0516  decode.d0.loss_dice: 0.9506  decode.d1.loss_cls: 0.3779  decode.d1.loss_mask: 1.1668  decode.d1.loss_dice: 1.0450  decode.d2.loss_cls: 0.3831  decode.d2.loss_mask: 1.1722  decode.d2.loss_dice: 0.9961  decode.d3.loss_cls: 0.4036  decode.d3.loss_mask: 1.1692  decode.d3.loss_dice: 0.9711  decode.d4.loss_cls: 0.3634  decode.d4.loss_mask: 1.2114  decode.d4.loss_dice: 1.0022  decode.d5.loss_cls: 0.3834  decode.d5.loss_mask: 1.1855  decode.d5.loss_dice: 1.0348  decode.d6.loss_cls: 0.3883  decode.d6.loss_mask: 1.1594  decode.d6.loss_dice: 1.0093  decode.d7.loss_cls: 0.3554  decode.d7.loss_mask: 1.1263  decode.d7.loss_dice: 0.9891  decode.d8.loss_cls: 0.3460  decode.d8.loss_mask: 1.1725  decode.d8.loss_dice: 1.0093
05/26 20:35:15 - mmengine - INFO - Iter(train) [ 81700/160000]  base_lr: 5.2563e-05 lr: 5.2563e-06  eta: 8:57:49  time: 0.4131  data_time: 0.0097  memory: 5966  grad_norm: 462.1052  loss: 22.0990  decode.loss_cls: 0.2890  decode.loss_mask: 1.0101  decode.loss_dice: 0.8487  decode.d0.loss_cls: 0.7183  decode.d0.loss_mask: 1.0280  decode.d0.loss_dice: 0.8277  decode.d1.loss_cls: 0.2500  decode.d1.loss_mask: 1.0184  decode.d1.loss_dice: 0.8630  decode.d2.loss_cls: 0.3068  decode.d2.loss_mask: 1.0410  decode.d2.loss_dice: 0.8337  decode.d3.loss_cls: 0.2943  decode.d3.loss_mask: 1.0592  decode.d3.loss_dice: 0.8218  decode.d4.loss_cls: 0.3205  decode.d4.loss_mask: 1.0560  decode.d4.loss_dice: 0.8186  decode.d5.loss_cls: 0.3072  decode.d5.loss_mask: 1.0776  decode.d5.loss_dice: 0.8342  decode.d6.loss_cls: 0.3169  decode.d6.loss_mask: 1.0282  decode.d6.loss_dice: 0.8444  decode.d7.loss_cls: 0.2473  decode.d7.loss_mask: 1.0241  decode.d7.loss_dice: 0.8552  decode.d8.loss_cls: 0.3218  decode.d8.loss_mask: 1.0019  decode.d8.loss_dice: 0.8350
05/26 20:35:36 - mmengine - INFO - Iter(train) [ 81750/160000]  base_lr: 5.2533e-05 lr: 5.2533e-06  eta: 8:57:28  time: 0.4132  data_time: 0.0097  memory: 5968  grad_norm: 469.5613  loss: 24.0794  decode.loss_cls: 0.2763  decode.loss_mask: 1.2262  decode.loss_dice: 0.8287  decode.d0.loss_cls: 0.8289  decode.d0.loss_mask: 1.1614  decode.d0.loss_dice: 0.7984  decode.d1.loss_cls: 0.3181  decode.d1.loss_mask: 1.2406  decode.d1.loss_dice: 0.8272  decode.d2.loss_cls: 0.2797  decode.d2.loss_mask: 1.2429  decode.d2.loss_dice: 0.8214  decode.d3.loss_cls: 0.3200  decode.d3.loss_mask: 1.1931  decode.d3.loss_dice: 0.7917  decode.d4.loss_cls: 0.3293  decode.d4.loss_mask: 1.2064  decode.d4.loss_dice: 0.8225  decode.d5.loss_cls: 0.3547  decode.d5.loss_mask: 1.2141  decode.d5.loss_dice: 0.8405  decode.d6.loss_cls: 0.3692  decode.d6.loss_mask: 1.2137  decode.d6.loss_dice: 0.8214  decode.d7.loss_cls: 0.3078  decode.d7.loss_mask: 1.2472  decode.d7.loss_dice: 0.8656  decode.d8.loss_cls: 0.2800  decode.d8.loss_mask: 1.2145  decode.d8.loss_dice: 0.8377
05/26 20:35:56 - mmengine - INFO - Iter(train) [ 81800/160000]  base_lr: 5.2503e-05 lr: 5.2503e-06  eta: 8:57:08  time: 0.4120  data_time: 0.0096  memory: 5969  grad_norm: 662.6031  loss: 21.2681  decode.loss_cls: 0.1790  decode.loss_mask: 1.1342  decode.loss_dice: 0.7379  decode.d0.loss_cls: 0.6849  decode.d0.loss_mask: 1.0877  decode.d0.loss_dice: 0.7183  decode.d1.loss_cls: 0.2297  decode.d1.loss_mask: 1.1110  decode.d1.loss_dice: 0.7048  decode.d2.loss_cls: 0.2126  decode.d2.loss_mask: 1.1430  decode.d2.loss_dice: 0.7341  decode.d3.loss_cls: 0.1710  decode.d3.loss_mask: 1.1547  decode.d3.loss_dice: 0.7573  decode.d4.loss_cls: 0.2182  decode.d4.loss_mask: 1.1465  decode.d4.loss_dice: 0.7166  decode.d5.loss_cls: 0.2131  decode.d5.loss_mask: 1.1211  decode.d5.loss_dice: 0.7560  decode.d6.loss_cls: 0.2084  decode.d6.loss_mask: 1.1366  decode.d6.loss_dice: 0.7628  decode.d7.loss_cls: 0.2035  decode.d7.loss_mask: 1.1542  decode.d7.loss_dice: 0.7797  decode.d8.loss_cls: 0.1964  decode.d8.loss_mask: 1.1537  decode.d8.loss_dice: 0.7411
05/26 20:36:17 - mmengine - INFO - Iter(train) [ 81850/160000]  base_lr: 5.2472e-05 lr: 5.2472e-06  eta: 8:56:47  time: 0.4142  data_time: 0.0098  memory: 5970  grad_norm: 1270.5321  loss: 18.3318  decode.loss_cls: 0.1971  decode.loss_mask: 0.9059  decode.loss_dice: 0.6295  decode.d0.loss_cls: 0.7064  decode.d0.loss_mask: 0.9297  decode.d0.loss_dice: 0.6592  decode.d1.loss_cls: 0.2166  decode.d1.loss_mask: 0.9527  decode.d1.loss_dice: 0.6684  decode.d2.loss_cls: 0.2006  decode.d2.loss_mask: 0.9288  decode.d2.loss_dice: 0.6591  decode.d3.loss_cls: 0.2263  decode.d3.loss_mask: 0.8938  decode.d3.loss_dice: 0.6202  decode.d4.loss_cls: 0.2094  decode.d4.loss_mask: 0.9122  decode.d4.loss_dice: 0.6403  decode.d5.loss_cls: 0.2073  decode.d5.loss_mask: 0.9062  decode.d5.loss_dice: 0.6417  decode.d6.loss_cls: 0.2412  decode.d6.loss_mask: 0.9271  decode.d6.loss_dice: 0.6312  decode.d7.loss_cls: 0.1979  decode.d7.loss_mask: 0.9462  decode.d7.loss_dice: 0.6963  decode.d8.loss_cls: 0.1959  decode.d8.loss_mask: 0.9465  decode.d8.loss_dice: 0.6383
05/26 20:36:38 - mmengine - INFO - Iter(train) [ 81900/160000]  base_lr: 5.2442e-05 lr: 5.2442e-06  eta: 8:56:26  time: 0.4128  data_time: 0.0097  memory: 5965  grad_norm: 796.3941  loss: 20.6391  decode.loss_cls: 0.2604  decode.loss_mask: 1.0192  decode.loss_dice: 0.7381  decode.d0.loss_cls: 0.7097  decode.d0.loss_mask: 0.9600  decode.d0.loss_dice: 0.7354  decode.d1.loss_cls: 0.2430  decode.d1.loss_mask: 1.0136  decode.d1.loss_dice: 0.7391  decode.d2.loss_cls: 0.2092  decode.d2.loss_mask: 1.0291  decode.d2.loss_dice: 0.7711  decode.d3.loss_cls: 0.2089  decode.d3.loss_mask: 1.0682  decode.d3.loss_dice: 0.7591  decode.d4.loss_cls: 0.2660  decode.d4.loss_mask: 0.9711  decode.d4.loss_dice: 0.7384  decode.d5.loss_cls: 0.2564  decode.d5.loss_mask: 0.9978  decode.d5.loss_dice: 0.7516  decode.d6.loss_cls: 0.2198  decode.d6.loss_mask: 1.0528  decode.d6.loss_dice: 0.7632  decode.d7.loss_cls: 0.2796  decode.d7.loss_mask: 1.0540  decode.d7.loss_dice: 0.7544  decode.d8.loss_cls: 0.2278  decode.d8.loss_mask: 1.0722  decode.d8.loss_dice: 0.7701
05/26 20:36:58 - mmengine - INFO - Iter(train) [ 81950/160000]  base_lr: 5.2412e-05 lr: 5.2412e-06  eta: 8:56:06  time: 0.4135  data_time: 0.0107  memory: 5967  grad_norm: 784.0634  loss: 19.9103  decode.loss_cls: 0.1842  decode.loss_mask: 0.8934  decode.loss_dice: 0.8254  decode.d0.loss_cls: 0.6231  decode.d0.loss_mask: 0.8986  decode.d0.loss_dice: 0.8542  decode.d1.loss_cls: 0.2543  decode.d1.loss_mask: 0.8954  decode.d1.loss_dice: 0.8339  decode.d2.loss_cls: 0.1953  decode.d2.loss_mask: 0.9206  decode.d2.loss_dice: 0.8291  decode.d3.loss_cls: 0.1878  decode.d3.loss_mask: 0.9250  decode.d3.loss_dice: 0.8426  decode.d4.loss_cls: 0.1885  decode.d4.loss_mask: 0.9326  decode.d4.loss_dice: 0.8359  decode.d5.loss_cls: 0.1714  decode.d5.loss_mask: 0.8940  decode.d5.loss_dice: 0.8422  decode.d6.loss_cls: 0.2291  decode.d6.loss_mask: 0.9367  decode.d6.loss_dice: 0.8180  decode.d7.loss_cls: 0.1967  decode.d7.loss_mask: 0.9525  decode.d7.loss_dice: 0.8517  decode.d8.loss_cls: 0.2075  decode.d8.loss_mask: 0.8851  decode.d8.loss_dice: 0.8054
05/26 20:37:19 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 20:37:19 - mmengine - INFO - Iter(train) [ 82000/160000]  base_lr: 5.2382e-05 lr: 5.2382e-06  eta: 8:55:45  time: 0.4126  data_time: 0.0097  memory: 5973  grad_norm: 540.1716  loss: 21.1673  decode.loss_cls: 0.1385  decode.loss_mask: 1.0789  decode.loss_dice: 0.8499  decode.d0.loss_cls: 0.7221  decode.d0.loss_mask: 1.0302  decode.d0.loss_dice: 0.8343  decode.d1.loss_cls: 0.1626  decode.d1.loss_mask: 1.0547  decode.d1.loss_dice: 0.8088  decode.d2.loss_cls: 0.1505  decode.d2.loss_mask: 1.0489  decode.d2.loss_dice: 0.8100  decode.d3.loss_cls: 0.1706  decode.d3.loss_mask: 1.0580  decode.d3.loss_dice: 0.8082  decode.d4.loss_cls: 0.2017  decode.d4.loss_mask: 1.0600  decode.d4.loss_dice: 0.8395  decode.d5.loss_cls: 0.1916  decode.d5.loss_mask: 1.0511  decode.d5.loss_dice: 0.8404  decode.d6.loss_cls: 0.1580  decode.d6.loss_mask: 1.0740  decode.d6.loss_dice: 0.8475  decode.d7.loss_cls: 0.1839  decode.d7.loss_mask: 1.0702  decode.d7.loss_dice: 0.8217  decode.d8.loss_cls: 0.1961  decode.d8.loss_mask: 1.0708  decode.d8.loss_dice: 0.8347
05/26 20:37:40 - mmengine - INFO - Iter(train) [ 82050/160000]  base_lr: 5.2351e-05 lr: 5.2351e-06  eta: 8:55:25  time: 0.4121  data_time: 0.0097  memory: 5973  grad_norm: 459.0503  loss: 20.5481  decode.loss_cls: 0.2767  decode.loss_mask: 0.9442  decode.loss_dice: 0.7519  decode.d0.loss_cls: 0.6471  decode.d0.loss_mask: 0.8929  decode.d0.loss_dice: 0.7479  decode.d1.loss_cls: 0.3216  decode.d1.loss_mask: 0.9417  decode.d1.loss_dice: 0.7728  decode.d2.loss_cls: 0.3429  decode.d2.loss_mask: 0.9628  decode.d2.loss_dice: 0.7443  decode.d3.loss_cls: 0.3025  decode.d3.loss_mask: 0.9551  decode.d3.loss_dice: 0.7530  decode.d4.loss_cls: 0.3269  decode.d4.loss_mask: 0.9585  decode.d4.loss_dice: 0.7813  decode.d5.loss_cls: 0.3211  decode.d5.loss_mask: 0.9459  decode.d5.loss_dice: 0.7863  decode.d6.loss_cls: 0.2899  decode.d6.loss_mask: 0.9572  decode.d6.loss_dice: 0.8089  decode.d7.loss_cls: 0.2961  decode.d7.loss_mask: 0.9543  decode.d7.loss_dice: 0.7741  decode.d8.loss_cls: 0.3095  decode.d8.loss_mask: 0.9398  decode.d8.loss_dice: 0.7408
05/26 20:38:00 - mmengine - INFO - Iter(train) [ 82100/160000]  base_lr: 5.2321e-05 lr: 5.2321e-06  eta: 8:55:04  time: 0.4105  data_time: 0.0097  memory: 5976  grad_norm: 765.4419  loss: 22.6326  decode.loss_cls: 0.2376  decode.loss_mask: 1.0874  decode.loss_dice: 0.7998  decode.d0.loss_cls: 0.7290  decode.d0.loss_mask: 1.1345  decode.d0.loss_dice: 0.8411  decode.d1.loss_cls: 0.2895  decode.d1.loss_mask: 1.1628  decode.d1.loss_dice: 0.8423  decode.d2.loss_cls: 0.2318  decode.d2.loss_mask: 1.2017  decode.d2.loss_dice: 0.8230  decode.d3.loss_cls: 0.2149  decode.d3.loss_mask: 1.1903  decode.d3.loss_dice: 0.7977  decode.d4.loss_cls: 0.2719  decode.d4.loss_mask: 1.1567  decode.d4.loss_dice: 0.8505  decode.d5.loss_cls: 0.2586  decode.d5.loss_mask: 1.1001  decode.d5.loss_dice: 0.7949  decode.d6.loss_cls: 0.2414  decode.d6.loss_mask: 1.1789  decode.d6.loss_dice: 0.8208  decode.d7.loss_cls: 0.2577  decode.d7.loss_mask: 1.1225  decode.d7.loss_dice: 0.7936  decode.d8.loss_cls: 0.2596  decode.d8.loss_mask: 1.1253  decode.d8.loss_dice: 0.8165
05/26 20:38:21 - mmengine - INFO - Iter(train) [ 82150/160000]  base_lr: 5.2291e-05 lr: 5.2291e-06  eta: 8:54:43  time: 0.4237  data_time: 0.0110  memory: 5979  grad_norm: 544.6399  loss: 24.2640  decode.loss_cls: 0.3073  decode.loss_mask: 1.1424  decode.loss_dice: 0.8981  decode.d0.loss_cls: 0.8541  decode.d0.loss_mask: 1.1258  decode.d0.loss_dice: 0.8739  decode.d1.loss_cls: 0.3181  decode.d1.loss_mask: 1.1480  decode.d1.loss_dice: 0.9273  decode.d2.loss_cls: 0.2607  decode.d2.loss_mask: 1.1765  decode.d2.loss_dice: 0.9305  decode.d3.loss_cls: 0.3326  decode.d3.loss_mask: 1.1432  decode.d3.loss_dice: 0.9136  decode.d4.loss_cls: 0.3172  decode.d4.loss_mask: 1.1337  decode.d4.loss_dice: 0.8848  decode.d5.loss_cls: 0.3320  decode.d5.loss_mask: 1.1581  decode.d5.loss_dice: 0.9000  decode.d6.loss_cls: 0.3184  decode.d6.loss_mask: 1.1608  decode.d6.loss_dice: 0.8974  decode.d7.loss_cls: 0.2786  decode.d7.loss_mask: 1.2027  decode.d7.loss_dice: 0.9350  decode.d8.loss_cls: 0.2799  decode.d8.loss_mask: 1.1639  decode.d8.loss_dice: 0.9496
05/26 20:38:42 - mmengine - INFO - Iter(train) [ 82200/160000]  base_lr: 5.2261e-05 lr: 5.2261e-06  eta: 8:54:23  time: 0.4123  data_time: 0.0097  memory: 5975  grad_norm: 444.4163  loss: 21.3626  decode.loss_cls: 0.2325  decode.loss_mask: 1.0104  decode.loss_dice: 0.8897  decode.d0.loss_cls: 0.7543  decode.d0.loss_mask: 0.9566  decode.d0.loss_dice: 0.8147  decode.d1.loss_cls: 0.2812  decode.d1.loss_mask: 0.9595  decode.d1.loss_dice: 0.8322  decode.d2.loss_cls: 0.2540  decode.d2.loss_mask: 1.0099  decode.d2.loss_dice: 0.8320  decode.d3.loss_cls: 0.2373  decode.d3.loss_mask: 0.9668  decode.d3.loss_dice: 0.8360  decode.d4.loss_cls: 0.1896  decode.d4.loss_mask: 1.0323  decode.d4.loss_dice: 0.8778  decode.d5.loss_cls: 0.2426  decode.d5.loss_mask: 0.9644  decode.d5.loss_dice: 0.8119  decode.d6.loss_cls: 0.2206  decode.d6.loss_mask: 1.0166  decode.d6.loss_dice: 0.8941  decode.d7.loss_cls: 0.2041  decode.d7.loss_mask: 1.0501  decode.d7.loss_dice: 0.8835  decode.d8.loss_cls: 0.2714  decode.d8.loss_mask: 0.9755  decode.d8.loss_dice: 0.8607
05/26 20:39:02 - mmengine - INFO - Iter(train) [ 82250/160000]  base_lr: 5.2231e-05 lr: 5.2231e-06  eta: 8:54:02  time: 0.4119  data_time: 0.0097  memory: 5976  grad_norm: 583.9937  loss: 24.0464  decode.loss_cls: 0.3888  decode.loss_mask: 1.1949  decode.loss_dice: 0.7797  decode.d0.loss_cls: 0.8342  decode.d0.loss_mask: 1.1431  decode.d0.loss_dice: 0.7945  decode.d1.loss_cls: 0.3338  decode.d1.loss_mask: 1.1818  decode.d1.loss_dice: 0.8216  decode.d2.loss_cls: 0.3530  decode.d2.loss_mask: 1.2209  decode.d2.loss_dice: 0.7765  decode.d3.loss_cls: 0.3687  decode.d3.loss_mask: 1.2053  decode.d3.loss_dice: 0.8244  decode.d4.loss_cls: 0.3877  decode.d4.loss_mask: 1.1868  decode.d4.loss_dice: 0.7988  decode.d5.loss_cls: 0.3740  decode.d5.loss_mask: 1.1912  decode.d5.loss_dice: 0.8142  decode.d6.loss_cls: 0.3569  decode.d6.loss_mask: 1.1927  decode.d6.loss_dice: 0.8233  decode.d7.loss_cls: 0.3412  decode.d7.loss_mask: 1.1782  decode.d7.loss_dice: 0.8180  decode.d8.loss_cls: 0.3910  decode.d8.loss_mask: 1.1774  decode.d8.loss_dice: 0.7936
05/26 20:39:23 - mmengine - INFO - Iter(train) [ 82300/160000]  base_lr: 5.2200e-05 lr: 5.2200e-06  eta: 8:53:42  time: 0.4122  data_time: 0.0096  memory: 5969  grad_norm: 654.1722  loss: 19.4364  decode.loss_cls: 0.2559  decode.loss_mask: 0.9607  decode.loss_dice: 0.6989  decode.d0.loss_cls: 0.7078  decode.d0.loss_mask: 0.9457  decode.d0.loss_dice: 0.7284  decode.d1.loss_cls: 0.2638  decode.d1.loss_mask: 0.9539  decode.d1.loss_dice: 0.7166  decode.d2.loss_cls: 0.2122  decode.d2.loss_mask: 0.9535  decode.d2.loss_dice: 0.7177  decode.d3.loss_cls: 0.2181  decode.d3.loss_mask: 0.9388  decode.d3.loss_dice: 0.7064  decode.d4.loss_cls: 0.2379  decode.d4.loss_mask: 0.9547  decode.d4.loss_dice: 0.7089  decode.d5.loss_cls: 0.2269  decode.d5.loss_mask: 0.9495  decode.d5.loss_dice: 0.7163  decode.d6.loss_cls: 0.2427  decode.d6.loss_mask: 0.9622  decode.d6.loss_dice: 0.7079  decode.d7.loss_cls: 0.2081  decode.d7.loss_mask: 0.9774  decode.d7.loss_dice: 0.7085  decode.d8.loss_cls: 0.1946  decode.d8.loss_mask: 0.9683  decode.d8.loss_dice: 0.6943
05/26 20:39:43 - mmengine - INFO - Iter(train) [ 82350/160000]  base_lr: 5.2170e-05 lr: 5.2170e-06  eta: 8:53:21  time: 0.4123  data_time: 0.0097  memory: 5989  grad_norm: 596.2644  loss: 22.7569  decode.loss_cls: 0.2368  decode.loss_mask: 1.1434  decode.loss_dice: 0.8398  decode.d0.loss_cls: 0.7655  decode.d0.loss_mask: 1.1037  decode.d0.loss_dice: 0.8429  decode.d1.loss_cls: 0.2683  decode.d1.loss_mask: 1.1331  decode.d1.loss_dice: 0.8406  decode.d2.loss_cls: 0.2757  decode.d2.loss_mask: 1.0957  decode.d2.loss_dice: 0.8480  decode.d3.loss_cls: 0.2446  decode.d3.loss_mask: 1.1327  decode.d3.loss_dice: 0.8575  decode.d4.loss_cls: 0.2792  decode.d4.loss_mask: 1.1190  decode.d4.loss_dice: 0.8415  decode.d5.loss_cls: 0.2656  decode.d5.loss_mask: 1.1241  decode.d5.loss_dice: 0.8462  decode.d6.loss_cls: 0.2640  decode.d6.loss_mask: 1.1162  decode.d6.loss_dice: 0.8366  decode.d7.loss_cls: 0.2400  decode.d7.loss_mask: 1.1312  decode.d7.loss_dice: 0.8404  decode.d8.loss_cls: 0.2573  decode.d8.loss_mask: 1.1239  decode.d8.loss_dice: 0.8434
05/26 20:40:04 - mmengine - INFO - Iter(train) [ 82400/160000]  base_lr: 5.2140e-05 lr: 5.2140e-06  eta: 8:53:00  time: 0.4108  data_time: 0.0096  memory: 5972  grad_norm: 531.5642  loss: 19.6462  decode.loss_cls: 0.1664  decode.loss_mask: 1.0391  decode.loss_dice: 0.7347  decode.d0.loss_cls: 0.7680  decode.d0.loss_mask: 0.9251  decode.d0.loss_dice: 0.7060  decode.d1.loss_cls: 0.1829  decode.d1.loss_mask: 1.0082  decode.d1.loss_dice: 0.7050  decode.d2.loss_cls: 0.1880  decode.d2.loss_mask: 1.0235  decode.d2.loss_dice: 0.7141  decode.d3.loss_cls: 0.1900  decode.d3.loss_mask: 1.0011  decode.d3.loss_dice: 0.7019  decode.d4.loss_cls: 0.1812  decode.d4.loss_mask: 1.0294  decode.d4.loss_dice: 0.7170  decode.d5.loss_cls: 0.1712  decode.d5.loss_mask: 1.0153  decode.d5.loss_dice: 0.7143  decode.d6.loss_cls: 0.1610  decode.d6.loss_mask: 1.0416  decode.d6.loss_dice: 0.7116  decode.d7.loss_cls: 0.2085  decode.d7.loss_mask: 1.0106  decode.d7.loss_dice: 0.6879  decode.d8.loss_cls: 0.1762  decode.d8.loss_mask: 1.0492  decode.d8.loss_dice: 0.7173
05/26 20:40:25 - mmengine - INFO - Iter(train) [ 82450/160000]  base_lr: 5.2110e-05 lr: 5.2110e-06  eta: 8:52:40  time: 0.4122  data_time: 0.0097  memory: 5984  grad_norm: 983.2219  loss: 23.7582  decode.loss_cls: 0.3175  decode.loss_mask: 1.1869  decode.loss_dice: 0.8121  decode.d0.loss_cls: 0.7472  decode.d0.loss_mask: 1.2005  decode.d0.loss_dice: 0.7856  decode.d1.loss_cls: 0.3075  decode.d1.loss_mask: 1.1994  decode.d1.loss_dice: 0.8307  decode.d2.loss_cls: 0.3076  decode.d2.loss_mask: 1.2222  decode.d2.loss_dice: 0.8188  decode.d3.loss_cls: 0.3146  decode.d3.loss_mask: 1.2282  decode.d3.loss_dice: 0.8236  decode.d4.loss_cls: 0.3011  decode.d4.loss_mask: 1.2011  decode.d4.loss_dice: 0.8064  decode.d5.loss_cls: 0.2825  decode.d5.loss_mask: 1.2297  decode.d5.loss_dice: 0.8386  decode.d6.loss_cls: 0.3028  decode.d6.loss_mask: 1.1687  decode.d6.loss_dice: 0.8305  decode.d7.loss_cls: 0.3084  decode.d7.loss_mask: 1.2023  decode.d7.loss_dice: 0.8409  decode.d8.loss_cls: 0.2987  decode.d8.loss_mask: 1.2000  decode.d8.loss_dice: 0.8439
05/26 20:40:45 - mmengine - INFO - Iter(train) [ 82500/160000]  base_lr: 5.2079e-05 lr: 5.2079e-06  eta: 8:52:19  time: 0.4129  data_time: 0.0098  memory: 5966  grad_norm: 703.8939  loss: 18.4068  decode.loss_cls: 0.2179  decode.loss_mask: 0.9344  decode.loss_dice: 0.6425  decode.d0.loss_cls: 0.6907  decode.d0.loss_mask: 0.8901  decode.d0.loss_dice: 0.6001  decode.d1.loss_cls: 0.2365  decode.d1.loss_mask: 0.9635  decode.d1.loss_dice: 0.6424  decode.d2.loss_cls: 0.2033  decode.d2.loss_mask: 0.9583  decode.d2.loss_dice: 0.6591  decode.d3.loss_cls: 0.1513  decode.d3.loss_mask: 0.9672  decode.d3.loss_dice: 0.6609  decode.d4.loss_cls: 0.2145  decode.d4.loss_mask: 0.9138  decode.d4.loss_dice: 0.6363  decode.d5.loss_cls: 0.1884  decode.d5.loss_mask: 0.9608  decode.d5.loss_dice: 0.6436  decode.d6.loss_cls: 0.2158  decode.d6.loss_mask: 0.9656  decode.d6.loss_dice: 0.6477  decode.d7.loss_cls: 0.2080  decode.d7.loss_mask: 0.9145  decode.d7.loss_dice: 0.6451  decode.d8.loss_cls: 0.2162  decode.d8.loss_mask: 0.9682  decode.d8.loss_dice: 0.6501
05/26 20:41:06 - mmengine - INFO - Iter(train) [ 82550/160000]  base_lr: 5.2049e-05 lr: 5.2049e-06  eta: 8:51:59  time: 0.4123  data_time: 0.0098  memory: 5966  grad_norm: 664.4354  loss: 21.5886  decode.loss_cls: 0.2680  decode.loss_mask: 1.1141  decode.loss_dice: 0.7071  decode.d0.loss_cls: 0.7903  decode.d0.loss_mask: 1.0830  decode.d0.loss_dice: 0.6455  decode.d1.loss_cls: 0.3707  decode.d1.loss_mask: 1.1057  decode.d1.loss_dice: 0.6826  decode.d2.loss_cls: 0.3462  decode.d2.loss_mask: 1.1121  decode.d2.loss_dice: 0.6768  decode.d3.loss_cls: 0.3114  decode.d3.loss_mask: 1.1026  decode.d3.loss_dice: 0.6561  decode.d4.loss_cls: 0.2731  decode.d4.loss_mask: 1.1427  decode.d4.loss_dice: 0.7104  decode.d5.loss_cls: 0.3121  decode.d5.loss_mask: 1.1261  decode.d5.loss_dice: 0.7135  decode.d6.loss_cls: 0.2861  decode.d6.loss_mask: 1.1213  decode.d6.loss_dice: 0.7147  decode.d7.loss_cls: 0.2932  decode.d7.loss_mask: 1.1174  decode.d7.loss_dice: 0.7026  decode.d8.loss_cls: 0.2292  decode.d8.loss_mask: 1.1664  decode.d8.loss_dice: 0.7075
05/26 20:41:26 - mmengine - INFO - Iter(train) [ 82600/160000]  base_lr: 5.2019e-05 lr: 5.2019e-06  eta: 8:51:38  time: 0.4116  data_time: 0.0097  memory: 5985  grad_norm: 508.9675  loss: 19.7302  decode.loss_cls: 0.1789  decode.loss_mask: 1.0848  decode.loss_dice: 0.6767  decode.d0.loss_cls: 0.7330  decode.d0.loss_mask: 0.9596  decode.d0.loss_dice: 0.6327  decode.d1.loss_cls: 0.1967  decode.d1.loss_mask: 1.0480  decode.d1.loss_dice: 0.7102  decode.d2.loss_cls: 0.1847  decode.d2.loss_mask: 1.0278  decode.d2.loss_dice: 0.6986  decode.d3.loss_cls: 0.1651  decode.d3.loss_mask: 1.0843  decode.d3.loss_dice: 0.7011  decode.d4.loss_cls: 0.1855  decode.d4.loss_mask: 1.1008  decode.d4.loss_dice: 0.7037  decode.d5.loss_cls: 0.1760  decode.d5.loss_mask: 1.0774  decode.d5.loss_dice: 0.7043  decode.d6.loss_cls: 0.2111  decode.d6.loss_mask: 1.0345  decode.d6.loss_dice: 0.7002  decode.d7.loss_cls: 0.2089  decode.d7.loss_mask: 1.0004  decode.d7.loss_dice: 0.6569  decode.d8.loss_cls: 0.2094  decode.d8.loss_mask: 1.0138  decode.d8.loss_dice: 0.6651
05/26 20:41:47 - mmengine - INFO - Iter(train) [ 82650/160000]  base_lr: 5.1989e-05 lr: 5.1989e-06  eta: 8:51:17  time: 0.4124  data_time: 0.0097  memory: 5966  grad_norm: 837.8454  loss: 20.9822  decode.loss_cls: 0.1546  decode.loss_mask: 1.1075  decode.loss_dice: 0.7566  decode.d0.loss_cls: 0.7001  decode.d0.loss_mask: 1.0421  decode.d0.loss_dice: 0.6887  decode.d1.loss_cls: 0.1643  decode.d1.loss_mask: 1.1175  decode.d1.loss_dice: 0.8159  decode.d2.loss_cls: 0.1379  decode.d2.loss_mask: 1.1445  decode.d2.loss_dice: 0.7677  decode.d3.loss_cls: 0.1431  decode.d3.loss_mask: 1.1045  decode.d3.loss_dice: 0.7704  decode.d4.loss_cls: 0.2154  decode.d4.loss_mask: 1.0642  decode.d4.loss_dice: 0.8053  decode.d5.loss_cls: 0.1865  decode.d5.loss_mask: 1.0891  decode.d5.loss_dice: 0.7974  decode.d6.loss_cls: 0.1511  decode.d6.loss_mask: 1.1191  decode.d6.loss_dice: 0.7968  decode.d7.loss_cls: 0.1562  decode.d7.loss_mask: 1.1145  decode.d7.loss_dice: 0.7899  decode.d8.loss_cls: 0.1532  decode.d8.loss_mask: 1.1228  decode.d8.loss_dice: 0.8054
05/26 20:42:08 - mmengine - INFO - Iter(train) [ 82700/160000]  base_lr: 5.1958e-05 lr: 5.1958e-06  eta: 8:50:57  time: 0.4706  data_time: 0.0097  memory: 5967  grad_norm: 553.3192  loss: 19.4055  decode.loss_cls: 0.1616  decode.loss_mask: 0.9740  decode.loss_dice: 0.7626  decode.d0.loss_cls: 0.6126  decode.d0.loss_mask: 0.9608  decode.d0.loss_dice: 0.7415  decode.d1.loss_cls: 0.1748  decode.d1.loss_mask: 0.9444  decode.d1.loss_dice: 0.7593  decode.d2.loss_cls: 0.1390  decode.d2.loss_mask: 0.9797  decode.d2.loss_dice: 0.7743  decode.d3.loss_cls: 0.1641  decode.d3.loss_mask: 0.9461  decode.d3.loss_dice: 0.7535  decode.d4.loss_cls: 0.1953  decode.d4.loss_mask: 0.9516  decode.d4.loss_dice: 0.7820  decode.d5.loss_cls: 0.1493  decode.d5.loss_mask: 0.9853  decode.d5.loss_dice: 0.7837  decode.d6.loss_cls: 0.1731  decode.d6.loss_mask: 0.9692  decode.d6.loss_dice: 0.7596  decode.d7.loss_cls: 0.1585  decode.d7.loss_mask: 0.9798  decode.d7.loss_dice: 0.7831  decode.d8.loss_cls: 0.1476  decode.d8.loss_mask: 0.9789  decode.d8.loss_dice: 0.7604
05/26 20:42:29 - mmengine - INFO - Iter(train) [ 82750/160000]  base_lr: 5.1928e-05 lr: 5.1928e-06  eta: 8:50:37  time: 0.4151  data_time: 0.0110  memory: 5969  grad_norm: 595.2591  loss: 22.6580  decode.loss_cls: 0.1325  decode.loss_mask: 1.2417  decode.loss_dice: 0.8108  decode.d0.loss_cls: 0.6877  decode.d0.loss_mask: 1.1539  decode.d0.loss_dice: 0.7514  decode.d1.loss_cls: 0.1951  decode.d1.loss_mask: 1.2117  decode.d1.loss_dice: 0.8413  decode.d2.loss_cls: 0.2024  decode.d2.loss_mask: 1.2191  decode.d2.loss_dice: 0.7884  decode.d3.loss_cls: 0.1778  decode.d3.loss_mask: 1.2574  decode.d3.loss_dice: 0.8265  decode.d4.loss_cls: 0.1396  decode.d4.loss_mask: 1.2379  decode.d4.loss_dice: 0.8131  decode.d5.loss_cls: 0.1796  decode.d5.loss_mask: 1.2411  decode.d5.loss_dice: 0.7914  decode.d6.loss_cls: 0.1709  decode.d6.loss_mask: 1.2573  decode.d6.loss_dice: 0.8575  decode.d7.loss_cls: 0.1300  decode.d7.loss_mask: 1.2507  decode.d7.loss_dice: 0.8526  decode.d8.loss_cls: 0.1438  decode.d8.loss_mask: 1.2559  decode.d8.loss_dice: 0.8388
05/26 20:42:50 - mmengine - INFO - Iter(train) [ 82800/160000]  base_lr: 5.1898e-05 lr: 5.1898e-06  eta: 8:50:16  time: 0.4144  data_time: 0.0097  memory: 5972  grad_norm: 517.1574  loss: 22.5051  decode.loss_cls: 0.1787  decode.loss_mask: 1.1961  decode.loss_dice: 0.8245  decode.d0.loss_cls: 0.6196  decode.d0.loss_mask: 1.1917  decode.d0.loss_dice: 0.7538  decode.d1.loss_cls: 0.2812  decode.d1.loss_mask: 1.1912  decode.d1.loss_dice: 0.7981  decode.d2.loss_cls: 0.2484  decode.d2.loss_mask: 1.1839  decode.d2.loss_dice: 0.7785  decode.d3.loss_cls: 0.2183  decode.d3.loss_mask: 1.1644  decode.d3.loss_dice: 0.7958  decode.d4.loss_cls: 0.2804  decode.d4.loss_mask: 1.1626  decode.d4.loss_dice: 0.7835  decode.d5.loss_cls: 0.2646  decode.d5.loss_mask: 1.1622  decode.d5.loss_dice: 0.7497  decode.d6.loss_cls: 0.2565  decode.d6.loss_mask: 1.1661  decode.d6.loss_dice: 0.7724  decode.d7.loss_cls: 0.2386  decode.d7.loss_mask: 1.1982  decode.d7.loss_dice: 0.8208  decode.d8.loss_cls: 0.2666  decode.d8.loss_mask: 1.1868  decode.d8.loss_dice: 0.7719
05/26 20:43:11 - mmengine - INFO - Iter(train) [ 82850/160000]  base_lr: 5.1868e-05 lr: 5.1868e-06  eta: 8:49:56  time: 0.4140  data_time: 0.0096  memory: 5965  grad_norm: 557.1709  loss: 25.0648  decode.loss_cls: 0.3164  decode.loss_mask: 1.2610  decode.loss_dice: 0.9114  decode.d0.loss_cls: 0.8008  decode.d0.loss_mask: 1.0999  decode.d0.loss_dice: 0.8360  decode.d1.loss_cls: 0.3884  decode.d1.loss_mask: 1.1377  decode.d1.loss_dice: 0.8734  decode.d2.loss_cls: 0.3538  decode.d2.loss_mask: 1.2512  decode.d2.loss_dice: 0.9157  decode.d3.loss_cls: 0.3369  decode.d3.loss_mask: 1.2989  decode.d3.loss_dice: 0.9197  decode.d4.loss_cls: 0.3585  decode.d4.loss_mask: 1.2310  decode.d4.loss_dice: 0.9195  decode.d5.loss_cls: 0.3670  decode.d5.loss_mask: 1.1732  decode.d5.loss_dice: 0.9073  decode.d6.loss_cls: 0.3489  decode.d6.loss_mask: 1.2209  decode.d6.loss_dice: 0.8969  decode.d7.loss_cls: 0.3442  decode.d7.loss_mask: 1.2270  decode.d7.loss_dice: 0.9063  decode.d8.loss_cls: 0.3448  decode.d8.loss_mask: 1.2045  decode.d8.loss_dice: 0.9138
05/26 20:43:31 - mmengine - INFO - Iter(train) [ 82900/160000]  base_lr: 5.1837e-05 lr: 5.1837e-06  eta: 8:49:35  time: 0.4134  data_time: 0.0097  memory: 5973  grad_norm: 632.7723  loss: 21.2272  decode.loss_cls: 0.1757  decode.loss_mask: 1.1390  decode.loss_dice: 0.7916  decode.d0.loss_cls: 0.7033  decode.d0.loss_mask: 1.0624  decode.d0.loss_dice: 0.7508  decode.d1.loss_cls: 0.2208  decode.d1.loss_mask: 1.0858  decode.d1.loss_dice: 0.7578  decode.d2.loss_cls: 0.1656  decode.d2.loss_mask: 1.1163  decode.d2.loss_dice: 0.7534  decode.d3.loss_cls: 0.1860  decode.d3.loss_mask: 1.1008  decode.d3.loss_dice: 0.7647  decode.d4.loss_cls: 0.2284  decode.d4.loss_mask: 1.0679  decode.d4.loss_dice: 0.7575  decode.d5.loss_cls: 0.2314  decode.d5.loss_mask: 1.1203  decode.d5.loss_dice: 0.7618  decode.d6.loss_cls: 0.1921  decode.d6.loss_mask: 1.1537  decode.d6.loss_dice: 0.8010  decode.d7.loss_cls: 0.1794  decode.d7.loss_mask: 1.1189  decode.d7.loss_dice: 0.7967  decode.d8.loss_cls: 0.1884  decode.d8.loss_mask: 1.0923  decode.d8.loss_dice: 0.7634
05/26 20:43:52 - mmengine - INFO - Iter(train) [ 82950/160000]  base_lr: 5.1807e-05 lr: 5.1807e-06  eta: 8:49:15  time: 0.4142  data_time: 0.0097  memory: 5971  grad_norm: 687.5729  loss: 18.7118  decode.loss_cls: 0.1291  decode.loss_mask: 0.9926  decode.loss_dice: 0.6937  decode.d0.loss_cls: 0.6581  decode.d0.loss_mask: 0.9641  decode.d0.loss_dice: 0.7050  decode.d1.loss_cls: 0.1282  decode.d1.loss_mask: 0.9866  decode.d1.loss_dice: 0.6657  decode.d2.loss_cls: 0.1257  decode.d2.loss_mask: 1.0036  decode.d2.loss_dice: 0.6742  decode.d3.loss_cls: 0.1187  decode.d3.loss_mask: 1.0170  decode.d3.loss_dice: 0.6744  decode.d4.loss_cls: 0.1339  decode.d4.loss_mask: 1.0051  decode.d4.loss_dice: 0.6843  decode.d5.loss_cls: 0.1759  decode.d5.loss_mask: 0.9993  decode.d5.loss_dice: 0.6909  decode.d6.loss_cls: 0.1356  decode.d6.loss_mask: 0.9969  decode.d6.loss_dice: 0.6880  decode.d7.loss_cls: 0.1311  decode.d7.loss_mask: 0.9849  decode.d7.loss_dice: 0.6827  decode.d8.loss_cls: 0.1621  decode.d8.loss_mask: 1.0063  decode.d8.loss_dice: 0.6982
05/26 20:44:13 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 20:44:13 - mmengine - INFO - Iter(train) [ 83000/160000]  base_lr: 5.1777e-05 lr: 5.1777e-06  eta: 8:48:54  time: 0.4135  data_time: 0.0098  memory: 5972  grad_norm: 682.0292  loss: 22.8682  decode.loss_cls: 0.2447  decode.loss_mask: 1.1551  decode.loss_dice: 0.8381  decode.d0.loss_cls: 0.7326  decode.d0.loss_mask: 1.1397  decode.d0.loss_dice: 0.8641  decode.d1.loss_cls: 0.2097  decode.d1.loss_mask: 1.1794  decode.d1.loss_dice: 0.8307  decode.d2.loss_cls: 0.2321  decode.d2.loss_mask: 1.1433  decode.d2.loss_dice: 0.8231  decode.d3.loss_cls: 0.2343  decode.d3.loss_mask: 1.1869  decode.d3.loss_dice: 0.8365  decode.d4.loss_cls: 0.2794  decode.d4.loss_mask: 1.1892  decode.d4.loss_dice: 0.8121  decode.d5.loss_cls: 0.2281  decode.d5.loss_mask: 1.1799  decode.d5.loss_dice: 0.8356  decode.d6.loss_cls: 0.2744  decode.d6.loss_mask: 1.1280  decode.d6.loss_dice: 0.8058  decode.d7.loss_cls: 0.2449  decode.d7.loss_mask: 1.1611  decode.d7.loss_dice: 0.8007  decode.d8.loss_cls: 0.2400  decode.d8.loss_mask: 1.1892  decode.d8.loss_dice: 0.8495
05/26 20:44:33 - mmengine - INFO - Iter(train) [ 83050/160000]  base_lr: 5.1747e-05 lr: 5.1747e-06  eta: 8:48:34  time: 0.4135  data_time: 0.0097  memory: 5976  grad_norm: 487.5064  loss: 24.5058  decode.loss_cls: 0.3616  decode.loss_mask: 1.1578  decode.loss_dice: 0.9000  decode.d0.loss_cls: 0.8198  decode.d0.loss_mask: 1.1464  decode.d0.loss_dice: 0.8774  decode.d1.loss_cls: 0.2857  decode.d1.loss_mask: 1.2253  decode.d1.loss_dice: 0.9685  decode.d2.loss_cls: 0.3356  decode.d2.loss_mask: 1.0956  decode.d2.loss_dice: 0.9214  decode.d3.loss_cls: 0.3085  decode.d3.loss_mask: 1.1602  decode.d3.loss_dice: 0.9356  decode.d4.loss_cls: 0.3252  decode.d4.loss_mask: 1.0934  decode.d4.loss_dice: 0.9117  decode.d5.loss_cls: 0.3322  decode.d5.loss_mask: 1.0947  decode.d5.loss_dice: 0.9406  decode.d6.loss_cls: 0.3160  decode.d6.loss_mask: 1.2015  decode.d6.loss_dice: 0.9436  decode.d7.loss_cls: 0.2955  decode.d7.loss_mask: 1.1985  decode.d7.loss_dice: 0.9651  decode.d8.loss_cls: 0.2770  decode.d8.loss_mask: 1.1708  decode.d8.loss_dice: 0.9405
05/26 20:44:54 - mmengine - INFO - Iter(train) [ 83100/160000]  base_lr: 5.1716e-05 lr: 5.1716e-06  eta: 8:48:13  time: 0.4137  data_time: 0.0097  memory: 5975  grad_norm: 730.6894  loss: 26.9136  decode.loss_cls: 0.2944  decode.loss_mask: 1.4416  decode.loss_dice: 0.9406  decode.d0.loss_cls: 0.7235  decode.d0.loss_mask: 1.3422  decode.d0.loss_dice: 0.8550  decode.d1.loss_cls: 0.2966  decode.d1.loss_mask: 1.4176  decode.d1.loss_dice: 0.9040  decode.d2.loss_cls: 0.3169  decode.d2.loss_mask: 1.4330  decode.d2.loss_dice: 0.9170  decode.d3.loss_cls: 0.3295  decode.d3.loss_mask: 1.3954  decode.d3.loss_dice: 0.8967  decode.d4.loss_cls: 0.3118  decode.d4.loss_mask: 1.4199  decode.d4.loss_dice: 0.8837  decode.d5.loss_cls: 0.3251  decode.d5.loss_mask: 1.4863  decode.d5.loss_dice: 0.8936  decode.d6.loss_cls: 0.3386  decode.d6.loss_mask: 1.4459  decode.d6.loss_dice: 0.9259  decode.d7.loss_cls: 0.3170  decode.d7.loss_mask: 1.4450  decode.d7.loss_dice: 0.9349  decode.d8.loss_cls: 0.3297  decode.d8.loss_mask: 1.4366  decode.d8.loss_dice: 0.9154
05/26 20:45:15 - mmengine - INFO - Iter(train) [ 83150/160000]  base_lr: 5.1686e-05 lr: 5.1686e-06  eta: 8:47:53  time: 0.4136  data_time: 0.0097  memory: 5966  grad_norm: 723.0023  loss: 21.9417  decode.loss_cls: 0.1887  decode.loss_mask: 1.2034  decode.loss_dice: 0.7841  decode.d0.loss_cls: 0.6696  decode.d0.loss_mask: 1.0803  decode.d0.loss_dice: 0.7013  decode.d1.loss_cls: 0.2708  decode.d1.loss_mask: 1.1157  decode.d1.loss_dice: 0.7466  decode.d2.loss_cls: 0.2982  decode.d2.loss_mask: 1.1058  decode.d2.loss_dice: 0.7436  decode.d3.loss_cls: 0.3238  decode.d3.loss_mask: 1.1170  decode.d3.loss_dice: 0.7645  decode.d4.loss_cls: 0.2371  decode.d4.loss_mask: 1.2193  decode.d4.loss_dice: 0.7801  decode.d5.loss_cls: 0.2579  decode.d5.loss_mask: 1.1279  decode.d5.loss_dice: 0.7638  decode.d6.loss_cls: 0.2302  decode.d6.loss_mask: 1.1948  decode.d6.loss_dice: 0.7880  decode.d7.loss_cls: 0.2402  decode.d7.loss_mask: 1.1560  decode.d7.loss_dice: 0.7614  decode.d8.loss_cls: 0.2439  decode.d8.loss_mask: 1.0927  decode.d8.loss_dice: 0.7349
05/26 20:45:35 - mmengine - INFO - Iter(train) [ 83200/160000]  base_lr: 5.1656e-05 lr: 5.1656e-06  eta: 8:47:32  time: 0.4130  data_time: 0.0097  memory: 5979  grad_norm: 407.5587  loss: 18.6169  decode.loss_cls: 0.1429  decode.loss_mask: 0.9305  decode.loss_dice: 0.7069  decode.d0.loss_cls: 0.7530  decode.d0.loss_mask: 0.8213  decode.d0.loss_dice: 0.6727  decode.d1.loss_cls: 0.1287  decode.d1.loss_mask: 0.9460  decode.d1.loss_dice: 0.7147  decode.d2.loss_cls: 0.1942  decode.d2.loss_mask: 0.9457  decode.d2.loss_dice: 0.7527  decode.d3.loss_cls: 0.1670  decode.d3.loss_mask: 0.9559  decode.d3.loss_dice: 0.7263  decode.d4.loss_cls: 0.1632  decode.d4.loss_mask: 0.9343  decode.d4.loss_dice: 0.7200  decode.d5.loss_cls: 0.1388  decode.d5.loss_mask: 0.8966  decode.d5.loss_dice: 0.7319  decode.d6.loss_cls: 0.1381  decode.d6.loss_mask: 0.9419  decode.d6.loss_dice: 0.7389  decode.d7.loss_cls: 0.2001  decode.d7.loss_mask: 0.9146  decode.d7.loss_dice: 0.7132  decode.d8.loss_cls: 0.1446  decode.d8.loss_mask: 0.9485  decode.d8.loss_dice: 0.7336
05/26 20:45:56 - mmengine - INFO - Iter(train) [ 83250/160000]  base_lr: 5.1626e-05 lr: 5.1626e-06  eta: 8:47:12  time: 0.4127  data_time: 0.0097  memory: 5980  grad_norm: 617.1654  loss: 20.9768  decode.loss_cls: 0.1581  decode.loss_mask: 1.1208  decode.loss_dice: 0.8029  decode.d0.loss_cls: 0.7137  decode.d0.loss_mask: 1.0168  decode.d0.loss_dice: 0.7463  decode.d1.loss_cls: 0.1864  decode.d1.loss_mask: 1.0656  decode.d1.loss_dice: 0.7688  decode.d2.loss_cls: 0.1566  decode.d2.loss_mask: 1.1092  decode.d2.loss_dice: 0.8091  decode.d3.loss_cls: 0.1727  decode.d3.loss_mask: 1.1065  decode.d3.loss_dice: 0.8084  decode.d4.loss_cls: 0.1872  decode.d4.loss_mask: 1.0322  decode.d4.loss_dice: 0.7986  decode.d5.loss_cls: 0.2207  decode.d5.loss_mask: 1.0216  decode.d5.loss_dice: 0.7803  decode.d6.loss_cls: 0.1978  decode.d6.loss_mask: 1.0995  decode.d6.loss_dice: 0.8097  decode.d7.loss_cls: 0.2146  decode.d7.loss_mask: 0.9929  decode.d7.loss_dice: 0.7882  decode.d8.loss_cls: 0.1863  decode.d8.loss_mask: 1.1059  decode.d8.loss_dice: 0.7992
05/26 20:46:17 - mmengine - INFO - Iter(train) [ 83300/160000]  base_lr: 5.1595e-05 lr: 5.1595e-06  eta: 8:46:51  time: 0.4133  data_time: 0.0097  memory: 5973  grad_norm: 652.2879  loss: 25.4545  decode.loss_cls: 0.2195  decode.loss_mask: 1.2434  decode.loss_dice: 0.9586  decode.d0.loss_cls: 0.8487  decode.d0.loss_mask: 1.2469  decode.d0.loss_dice: 0.9639  decode.d1.loss_cls: 0.3183  decode.d1.loss_mask: 1.2915  decode.d1.loss_dice: 0.9712  decode.d2.loss_cls: 0.2698  decode.d2.loss_mask: 1.2355  decode.d2.loss_dice: 0.9656  decode.d3.loss_cls: 0.2709  decode.d3.loss_mask: 1.2481  decode.d3.loss_dice: 0.9479  decode.d4.loss_cls: 0.2933  decode.d4.loss_mask: 1.2844  decode.d4.loss_dice: 0.9462  decode.d5.loss_cls: 0.3012  decode.d5.loss_mask: 1.3160  decode.d5.loss_dice: 0.9597  decode.d6.loss_cls: 0.2804  decode.d6.loss_mask: 1.2445  decode.d6.loss_dice: 0.9544  decode.d7.loss_cls: 0.2546  decode.d7.loss_mask: 1.2368  decode.d7.loss_dice: 0.9483  decode.d8.loss_cls: 0.2381  decode.d8.loss_mask: 1.2474  decode.d8.loss_dice: 0.9493
05/26 20:46:38 - mmengine - INFO - Iter(train) [ 83350/160000]  base_lr: 5.1565e-05 lr: 5.1565e-06  eta: 8:46:31  time: 0.4132  data_time: 0.0097  memory: 5975  grad_norm: 457.8862  loss: 21.1277  decode.loss_cls: 0.2676  decode.loss_mask: 1.0550  decode.loss_dice: 0.7218  decode.d0.loss_cls: 0.6765  decode.d0.loss_mask: 1.0365  decode.d0.loss_dice: 0.7795  decode.d1.loss_cls: 0.2580  decode.d1.loss_mask: 1.0500  decode.d1.loss_dice: 0.7550  decode.d2.loss_cls: 0.2634  decode.d2.loss_mask: 1.0796  decode.d2.loss_dice: 0.7726  decode.d3.loss_cls: 0.2489  decode.d3.loss_mask: 1.0757  decode.d3.loss_dice: 0.7567  decode.d4.loss_cls: 0.2498  decode.d4.loss_mask: 1.0667  decode.d4.loss_dice: 0.7269  decode.d5.loss_cls: 0.2681  decode.d5.loss_mask: 1.0527  decode.d5.loss_dice: 0.7467  decode.d6.loss_cls: 0.2465  decode.d6.loss_mask: 1.0708  decode.d6.loss_dice: 0.7611  decode.d7.loss_cls: 0.2743  decode.d7.loss_mask: 1.0423  decode.d7.loss_dice: 0.7511  decode.d8.loss_cls: 0.2687  decode.d8.loss_mask: 1.0651  decode.d8.loss_dice: 0.7401
05/26 20:46:58 - mmengine - INFO - Iter(train) [ 83400/160000]  base_lr: 5.1535e-05 lr: 5.1535e-06  eta: 8:46:10  time: 0.4136  data_time: 0.0098  memory: 5970  grad_norm: 753.8823  loss: 21.4549  decode.loss_cls: 0.2670  decode.loss_mask: 1.0718  decode.loss_dice: 0.7697  decode.d0.loss_cls: 0.6646  decode.d0.loss_mask: 1.0697  decode.d0.loss_dice: 0.7660  decode.d1.loss_cls: 0.2915  decode.d1.loss_mask: 1.0865  decode.d1.loss_dice: 0.7842  decode.d2.loss_cls: 0.2715  decode.d2.loss_mask: 1.0700  decode.d2.loss_dice: 0.7872  decode.d3.loss_cls: 0.2540  decode.d3.loss_mask: 1.0586  decode.d3.loss_dice: 0.7539  decode.d4.loss_cls: 0.2873  decode.d4.loss_mask: 1.0319  decode.d4.loss_dice: 0.7489  decode.d5.loss_cls: 0.2860  decode.d5.loss_mask: 1.0500  decode.d5.loss_dice: 0.7658  decode.d6.loss_cls: 0.2776  decode.d6.loss_mask: 1.0698  decode.d6.loss_dice: 0.7775  decode.d7.loss_cls: 0.2737  decode.d7.loss_mask: 1.0604  decode.d7.loss_dice: 0.7803  decode.d8.loss_cls: 0.2617  decode.d8.loss_mask: 1.0566  decode.d8.loss_dice: 0.7610
05/26 20:47:19 - mmengine - INFO - Iter(train) [ 83450/160000]  base_lr: 5.1504e-05 lr: 5.1504e-06  eta: 8:45:50  time: 0.4145  data_time: 0.0097  memory: 5966  grad_norm: 436.3582  loss: 20.6972  decode.loss_cls: 0.1221  decode.loss_mask: 1.1416  decode.loss_dice: 0.7390  decode.d0.loss_cls: 0.6424  decode.d0.loss_mask: 1.0945  decode.d0.loss_dice: 0.7287  decode.d1.loss_cls: 0.1555  decode.d1.loss_mask: 1.1130  decode.d1.loss_dice: 0.7512  decode.d2.loss_cls: 0.1004  decode.d2.loss_mask: 1.1535  decode.d2.loss_dice: 0.7521  decode.d3.loss_cls: 0.1341  decode.d3.loss_mask: 1.1504  decode.d3.loss_dice: 0.7292  decode.d4.loss_cls: 0.1274  decode.d4.loss_mask: 1.1587  decode.d4.loss_dice: 0.7447  decode.d5.loss_cls: 0.1154  decode.d5.loss_mask: 1.1418  decode.d5.loss_dice: 0.7555  decode.d6.loss_cls: 0.1644  decode.d6.loss_mask: 1.1470  decode.d6.loss_dice: 0.7495  decode.d7.loss_cls: 0.1598  decode.d7.loss_mask: 1.1606  decode.d7.loss_dice: 0.7437  decode.d8.loss_cls: 0.1641  decode.d8.loss_mask: 1.1199  decode.d8.loss_dice: 0.7372
05/26 20:47:40 - mmengine - INFO - Iter(train) [ 83500/160000]  base_lr: 5.1474e-05 lr: 5.1474e-06  eta: 8:45:29  time: 0.4135  data_time: 0.0098  memory: 5984  grad_norm: 825.9221  loss: 23.3731  decode.loss_cls: 0.2686  decode.loss_mask: 1.1366  decode.loss_dice: 0.8183  decode.d0.loss_cls: 0.7790  decode.d0.loss_mask: 1.0759  decode.d0.loss_dice: 0.8011  decode.d1.loss_cls: 0.2794  decode.d1.loss_mask: 1.1990  decode.d1.loss_dice: 0.8284  decode.d2.loss_cls: 0.2791  decode.d2.loss_mask: 1.1925  decode.d2.loss_dice: 0.8568  decode.d3.loss_cls: 0.2717  decode.d3.loss_mask: 1.1593  decode.d3.loss_dice: 0.8153  decode.d4.loss_cls: 0.3011  decode.d4.loss_mask: 1.2239  decode.d4.loss_dice: 0.8540  decode.d5.loss_cls: 0.3102  decode.d5.loss_mask: 1.2375  decode.d5.loss_dice: 0.8485  decode.d6.loss_cls: 0.3326  decode.d6.loss_mask: 1.2141  decode.d6.loss_dice: 0.8466  decode.d7.loss_cls: 0.2965  decode.d7.loss_mask: 1.1356  decode.d7.loss_dice: 0.8194  decode.d8.loss_cls: 0.3004  decode.d8.loss_mask: 1.1045  decode.d8.loss_dice: 0.7870
05/26 20:48:00 - mmengine - INFO - Iter(train) [ 83550/160000]  base_lr: 5.1444e-05 lr: 5.1444e-06  eta: 8:45:09  time: 0.4152  data_time: 0.0097  memory: 5976  grad_norm: 399.6863  loss: 17.9996  decode.loss_cls: 0.2089  decode.loss_mask: 0.8205  decode.loss_dice: 0.7265  decode.d0.loss_cls: 0.6298  decode.d0.loss_mask: 0.8224  decode.d0.loss_dice: 0.7031  decode.d1.loss_cls: 0.2523  decode.d1.loss_mask: 0.8365  decode.d1.loss_dice: 0.7145  decode.d2.loss_cls: 0.2382  decode.d2.loss_mask: 0.8384  decode.d2.loss_dice: 0.7127  decode.d3.loss_cls: 0.2464  decode.d3.loss_mask: 0.8195  decode.d3.loss_dice: 0.7043  decode.d4.loss_cls: 0.2449  decode.d4.loss_mask: 0.8078  decode.d4.loss_dice: 0.6992  decode.d5.loss_cls: 0.2370  decode.d5.loss_mask: 0.8198  decode.d5.loss_dice: 0.7005  decode.d6.loss_cls: 0.2326  decode.d6.loss_mask: 0.8129  decode.d6.loss_dice: 0.6994  decode.d7.loss_cls: 0.2179  decode.d7.loss_mask: 0.8159  decode.d7.loss_dice: 0.7121  decode.d8.loss_cls: 0.2023  decode.d8.loss_mask: 0.8165  decode.d8.loss_dice: 0.7067
05/26 20:48:21 - mmengine - INFO - Iter(train) [ 83600/160000]  base_lr: 5.1414e-05 lr: 5.1414e-06  eta: 8:44:48  time: 0.4144  data_time: 0.0097  memory: 5966  grad_norm: 684.2157  loss: 23.1680  decode.loss_cls: 0.2118  decode.loss_mask: 1.2154  decode.loss_dice: 0.8370  decode.d0.loss_cls: 0.7248  decode.d0.loss_mask: 1.0909  decode.d0.loss_dice: 0.7901  decode.d1.loss_cls: 0.1694  decode.d1.loss_mask: 1.2394  decode.d1.loss_dice: 0.8580  decode.d2.loss_cls: 0.1872  decode.d2.loss_mask: 1.2338  decode.d2.loss_dice: 0.8453  decode.d3.loss_cls: 0.1893  decode.d3.loss_mask: 1.3048  decode.d3.loss_dice: 0.8709  decode.d4.loss_cls: 0.2029  decode.d4.loss_mask: 1.2232  decode.d4.loss_dice: 0.8474  decode.d5.loss_cls: 0.1735  decode.d5.loss_mask: 1.2574  decode.d5.loss_dice: 0.8753  decode.d6.loss_cls: 0.2034  decode.d6.loss_mask: 1.2846  decode.d6.loss_dice: 0.8379  decode.d7.loss_cls: 0.1632  decode.d7.loss_mask: 1.2382  decode.d7.loss_dice: 0.8581  decode.d8.loss_cls: 0.1973  decode.d8.loss_mask: 1.2069  decode.d8.loss_dice: 0.8306
05/26 20:48:42 - mmengine - INFO - Iter(train) [ 83650/160000]  base_lr: 5.1383e-05 lr: 5.1383e-06  eta: 8:44:27  time: 0.4135  data_time: 0.0096  memory: 5984  grad_norm: 782.7102  loss: 20.3516  decode.loss_cls: 0.2385  decode.loss_mask: 1.0413  decode.loss_dice: 0.7269  decode.d0.loss_cls: 0.7080  decode.d0.loss_mask: 0.9837  decode.d0.loss_dice: 0.6769  decode.d1.loss_cls: 0.1928  decode.d1.loss_mask: 1.0583  decode.d1.loss_dice: 0.7393  decode.d2.loss_cls: 0.2130  decode.d2.loss_mask: 1.0500  decode.d2.loss_dice: 0.7226  decode.d3.loss_cls: 0.2497  decode.d3.loss_mask: 1.0019  decode.d3.loss_dice: 0.7033  decode.d4.loss_cls: 0.2641  decode.d4.loss_mask: 0.9805  decode.d4.loss_dice: 0.7011  decode.d5.loss_cls: 0.2540  decode.d5.loss_mask: 1.0291  decode.d5.loss_dice: 0.7182  decode.d6.loss_cls: 0.2727  decode.d6.loss_mask: 1.0437  decode.d6.loss_dice: 0.7019  decode.d7.loss_cls: 0.2730  decode.d7.loss_mask: 1.0527  decode.d7.loss_dice: 0.7378  decode.d8.loss_cls: 0.2878  decode.d8.loss_mask: 1.0223  decode.d8.loss_dice: 0.7063
05/26 20:49:03 - mmengine - INFO - Iter(train) [ 83700/160000]  base_lr: 5.1353e-05 lr: 5.1353e-06  eta: 8:44:07  time: 0.4133  data_time: 0.0096  memory: 5971  grad_norm: 402.2586  loss: 19.0856  decode.loss_cls: 0.1541  decode.loss_mask: 0.9699  decode.loss_dice: 0.7488  decode.d0.loss_cls: 0.6345  decode.d0.loss_mask: 0.9251  decode.d0.loss_dice: 0.7291  decode.d1.loss_cls: 0.1680  decode.d1.loss_mask: 0.9427  decode.d1.loss_dice: 0.7369  decode.d2.loss_cls: 0.1547  decode.d2.loss_mask: 0.9717  decode.d2.loss_dice: 0.7312  decode.d3.loss_cls: 0.1649  decode.d3.loss_mask: 0.9310  decode.d3.loss_dice: 0.7137  decode.d4.loss_cls: 0.1236  decode.d4.loss_mask: 1.0189  decode.d4.loss_dice: 0.7585  decode.d5.loss_cls: 0.1400  decode.d5.loss_mask: 0.9928  decode.d5.loss_dice: 0.7461  decode.d6.loss_cls: 0.1328  decode.d6.loss_mask: 1.0054  decode.d6.loss_dice: 0.7579  decode.d7.loss_cls: 0.1665  decode.d7.loss_mask: 0.9628  decode.d7.loss_dice: 0.7321  decode.d8.loss_cls: 0.1347  decode.d8.loss_mask: 0.9868  decode.d8.loss_dice: 0.7504
05/26 20:49:23 - mmengine - INFO - Iter(train) [ 83750/160000]  base_lr: 5.1323e-05 lr: 5.1323e-06  eta: 8:43:46  time: 0.4136  data_time: 0.0097  memory: 5977  grad_norm: 793.2089  loss: 22.5758  decode.loss_cls: 0.2772  decode.loss_mask: 1.1262  decode.loss_dice: 0.8172  decode.d0.loss_cls: 0.7928  decode.d0.loss_mask: 0.9615  decode.d0.loss_dice: 0.7553  decode.d1.loss_cls: 0.2392  decode.d1.loss_mask: 1.1662  decode.d1.loss_dice: 0.8451  decode.d2.loss_cls: 0.2551  decode.d2.loss_mask: 1.0875  decode.d2.loss_dice: 0.8307  decode.d3.loss_cls: 0.3304  decode.d3.loss_mask: 1.0829  decode.d3.loss_dice: 0.8038  decode.d4.loss_cls: 0.3356  decode.d4.loss_mask: 1.0733  decode.d4.loss_dice: 0.8196  decode.d5.loss_cls: 0.2806  decode.d5.loss_mask: 1.1315  decode.d5.loss_dice: 0.8424  decode.d6.loss_cls: 0.2874  decode.d6.loss_mask: 1.0980  decode.d6.loss_dice: 0.8196  decode.d7.loss_cls: 0.3053  decode.d7.loss_mask: 1.1268  decode.d7.loss_dice: 0.8378  decode.d8.loss_cls: 0.3179  decode.d8.loss_mask: 1.1160  decode.d8.loss_dice: 0.8130
05/26 20:49:44 - mmengine - INFO - Iter(train) [ 83800/160000]  base_lr: 5.1293e-05 lr: 5.1293e-06  eta: 8:43:26  time: 0.4137  data_time: 0.0097  memory: 5989  grad_norm: 368.6834  loss: 18.5534  decode.loss_cls: 0.2103  decode.loss_mask: 0.9023  decode.loss_dice: 0.6859  decode.d0.loss_cls: 0.7085  decode.d0.loss_mask: 0.8865  decode.d0.loss_dice: 0.6861  decode.d1.loss_cls: 0.2130  decode.d1.loss_mask: 0.8816  decode.d1.loss_dice: 0.6981  decode.d2.loss_cls: 0.2549  decode.d2.loss_mask: 0.8794  decode.d2.loss_dice: 0.6908  decode.d3.loss_cls: 0.2446  decode.d3.loss_mask: 0.8826  decode.d3.loss_dice: 0.6811  decode.d4.loss_cls: 0.1922  decode.d4.loss_mask: 0.8864  decode.d4.loss_dice: 0.7119  decode.d5.loss_cls: 0.2009  decode.d5.loss_mask: 0.8945  decode.d5.loss_dice: 0.6971  decode.d6.loss_cls: 0.2214  decode.d6.loss_mask: 0.9078  decode.d6.loss_dice: 0.6829  decode.d7.loss_cls: 0.2334  decode.d7.loss_mask: 0.8899  decode.d7.loss_dice: 0.6838  decode.d8.loss_cls: 0.2595  decode.d8.loss_mask: 0.8745  decode.d8.loss_dice: 0.7115
05/26 20:50:05 - mmengine - INFO - Iter(train) [ 83850/160000]  base_lr: 5.1262e-05 lr: 5.1262e-06  eta: 8:43:05  time: 0.4137  data_time: 0.0097  memory: 5970  grad_norm: 491.9481  loss: 22.0925  decode.loss_cls: 0.2242  decode.loss_mask: 1.0584  decode.loss_dice: 0.8865  decode.d0.loss_cls: 0.7678  decode.d0.loss_mask: 1.0682  decode.d0.loss_dice: 0.8312  decode.d1.loss_cls: 0.2192  decode.d1.loss_mask: 1.0767  decode.d1.loss_dice: 0.8744  decode.d2.loss_cls: 0.2082  decode.d2.loss_mask: 1.0718  decode.d2.loss_dice: 0.8754  decode.d3.loss_cls: 0.2370  decode.d3.loss_mask: 1.0652  decode.d3.loss_dice: 0.8470  decode.d4.loss_cls: 0.2596  decode.d4.loss_mask: 1.0434  decode.d4.loss_dice: 0.8293  decode.d5.loss_cls: 0.2160  decode.d5.loss_mask: 1.0721  decode.d5.loss_dice: 0.8685  decode.d6.loss_cls: 0.2339  decode.d6.loss_mask: 1.0630  decode.d6.loss_dice: 0.8625  decode.d7.loss_cls: 0.2581  decode.d7.loss_mask: 1.0462  decode.d7.loss_dice: 0.8750  decode.d8.loss_cls: 0.2302  decode.d8.loss_mask: 1.0532  decode.d8.loss_dice: 0.8706
05/26 20:50:25 - mmengine - INFO - Iter(train) [ 83900/160000]  base_lr: 5.1232e-05 lr: 5.1232e-06  eta: 8:42:45  time: 0.4137  data_time: 0.0097  memory: 5969  grad_norm: 664.7168  loss: 24.0806  decode.loss_cls: 0.3310  decode.loss_mask: 1.1045  decode.loss_dice: 0.8704  decode.d0.loss_cls: 0.9566  decode.d0.loss_mask: 1.0253  decode.d0.loss_dice: 0.8462  decode.d1.loss_cls: 0.3903  decode.d1.loss_mask: 1.1000  decode.d1.loss_dice: 0.8593  decode.d2.loss_cls: 0.3958  decode.d2.loss_mask: 1.0985  decode.d2.loss_dice: 0.8594  decode.d3.loss_cls: 0.3842  decode.d3.loss_mask: 1.1517  decode.d3.loss_dice: 0.8906  decode.d4.loss_cls: 0.3606  decode.d4.loss_mask: 1.1124  decode.d4.loss_dice: 0.8773  decode.d5.loss_cls: 0.3607  decode.d5.loss_mask: 1.1195  decode.d5.loss_dice: 0.8738  decode.d6.loss_cls: 0.4051  decode.d6.loss_mask: 1.1566  decode.d6.loss_dice: 0.8861  decode.d7.loss_cls: 0.4134  decode.d7.loss_mask: 1.0700  decode.d7.loss_dice: 0.8482  decode.d8.loss_cls: 0.3178  decode.d8.loss_mask: 1.1256  decode.d8.loss_dice: 0.8898
05/26 20:50:46 - mmengine - INFO - Iter(train) [ 83950/160000]  base_lr: 5.1202e-05 lr: 5.1202e-06  eta: 8:42:24  time: 0.4147  data_time: 0.0098  memory: 5978  grad_norm: 590.1409  loss: 19.1883  decode.loss_cls: 0.1842  decode.loss_mask: 0.9478  decode.loss_dice: 0.7406  decode.d0.loss_cls: 0.6321  decode.d0.loss_mask: 0.8929  decode.d0.loss_dice: 0.7455  decode.d1.loss_cls: 0.1929  decode.d1.loss_mask: 0.9122  decode.d1.loss_dice: 0.7458  decode.d2.loss_cls: 0.2103  decode.d2.loss_mask: 0.9057  decode.d2.loss_dice: 0.7524  decode.d3.loss_cls: 0.1989  decode.d3.loss_mask: 0.9333  decode.d3.loss_dice: 0.7487  decode.d4.loss_cls: 0.2038  decode.d4.loss_mask: 0.9373  decode.d4.loss_dice: 0.7383  decode.d5.loss_cls: 0.2070  decode.d5.loss_mask: 0.9513  decode.d5.loss_dice: 0.7449  decode.d6.loss_cls: 0.1944  decode.d6.loss_mask: 0.9608  decode.d6.loss_dice: 0.7609  decode.d7.loss_cls: 0.2061  decode.d7.loss_mask: 0.9419  decode.d7.loss_dice: 0.7359  decode.d8.loss_cls: 0.1857  decode.d8.loss_mask: 0.9395  decode.d8.loss_dice: 0.7371
05/26 20:51:07 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 20:51:07 - mmengine - INFO - Iter(train) [ 84000/160000]  base_lr: 5.1171e-05 lr: 5.1171e-06  eta: 8:42:04  time: 0.4139  data_time: 0.0098  memory: 5976  grad_norm: 613.4909  loss: 21.3655  decode.loss_cls: 0.2330  decode.loss_mask: 1.0479  decode.loss_dice: 0.8226  decode.d0.loss_cls: 0.7568  decode.d0.loss_mask: 0.9645  decode.d0.loss_dice: 0.7849  decode.d1.loss_cls: 0.2563  decode.d1.loss_mask: 1.0569  decode.d1.loss_dice: 0.8245  decode.d2.loss_cls: 0.2283  decode.d2.loss_mask: 1.0361  decode.d2.loss_dice: 0.8286  decode.d3.loss_cls: 0.2026  decode.d3.loss_mask: 1.0749  decode.d3.loss_dice: 0.8412  decode.d4.loss_cls: 0.3088  decode.d4.loss_mask: 1.0362  decode.d4.loss_dice: 0.7721  decode.d5.loss_cls: 0.2468  decode.d5.loss_mask: 1.0203  decode.d5.loss_dice: 0.7850  decode.d6.loss_cls: 0.2323  decode.d6.loss_mask: 1.0497  decode.d6.loss_dice: 0.8327  decode.d7.loss_cls: 0.2222  decode.d7.loss_mask: 1.0390  decode.d7.loss_dice: 0.8074  decode.d8.loss_cls: 0.2170  decode.d8.loss_mask: 1.0519  decode.d8.loss_dice: 0.7848
05/26 20:51:27 - mmengine - INFO - Iter(train) [ 84050/160000]  base_lr: 5.1141e-05 lr: 5.1141e-06  eta: 8:41:43  time: 0.4140  data_time: 0.0098  memory: 5971  grad_norm: 426.3597  loss: 18.4627  decode.loss_cls: 0.1781  decode.loss_mask: 0.9983  decode.loss_dice: 0.6525  decode.d0.loss_cls: 0.6586  decode.d0.loss_mask: 0.8407  decode.d0.loss_dice: 0.6543  decode.d1.loss_cls: 0.2268  decode.d1.loss_mask: 0.9146  decode.d1.loss_dice: 0.6712  decode.d2.loss_cls: 0.2043  decode.d2.loss_mask: 0.9706  decode.d2.loss_dice: 0.6872  decode.d3.loss_cls: 0.2214  decode.d3.loss_mask: 0.9352  decode.d3.loss_dice: 0.6328  decode.d4.loss_cls: 0.2188  decode.d4.loss_mask: 0.9796  decode.d4.loss_dice: 0.7014  decode.d5.loss_cls: 0.2978  decode.d5.loss_mask: 0.8716  decode.d5.loss_dice: 0.6294  decode.d6.loss_cls: 0.2098  decode.d6.loss_mask: 0.9191  decode.d6.loss_dice: 0.6004  decode.d7.loss_cls: 0.1830  decode.d7.loss_mask: 0.9456  decode.d7.loss_dice: 0.6655  decode.d8.loss_cls: 0.1907  decode.d8.loss_mask: 0.9330  decode.d8.loss_dice: 0.6705
05/26 20:51:48 - mmengine - INFO - Iter(train) [ 84100/160000]  base_lr: 5.1111e-05 lr: 5.1111e-06  eta: 8:41:23  time: 0.4138  data_time: 0.0097  memory: 5980  grad_norm: 638.8839  loss: 23.6516  decode.loss_cls: 0.2315  decode.loss_mask: 1.2026  decode.loss_dice: 0.8206  decode.d0.loss_cls: 0.8502  decode.d0.loss_mask: 1.0567  decode.d0.loss_dice: 0.7997  decode.d1.loss_cls: 0.3005  decode.d1.loss_mask: 1.2028  decode.d1.loss_dice: 0.8841  decode.d2.loss_cls: 0.2768  decode.d2.loss_mask: 1.1474  decode.d2.loss_dice: 0.8614  decode.d3.loss_cls: 0.2579  decode.d3.loss_mask: 1.1696  decode.d3.loss_dice: 0.8311  decode.d4.loss_cls: 0.3092  decode.d4.loss_mask: 1.2522  decode.d4.loss_dice: 0.8884  decode.d5.loss_cls: 0.3393  decode.d5.loss_mask: 1.1947  decode.d5.loss_dice: 0.8591  decode.d6.loss_cls: 0.2927  decode.d6.loss_mask: 1.2170  decode.d6.loss_dice: 0.8821  decode.d7.loss_cls: 0.2852  decode.d7.loss_mask: 1.1696  decode.d7.loss_dice: 0.8474  decode.d8.loss_cls: 0.2287  decode.d8.loss_mask: 1.1672  decode.d8.loss_dice: 0.8256
05/26 20:52:09 - mmengine - INFO - Iter(train) [ 84150/160000]  base_lr: 5.1080e-05 lr: 5.1080e-06  eta: 8:41:02  time: 0.4140  data_time: 0.0097  memory: 5992  grad_norm: 506.0496  loss: 21.2457  decode.loss_cls: 0.1911  decode.loss_mask: 1.1346  decode.loss_dice: 0.7395  decode.d0.loss_cls: 0.7354  decode.d0.loss_mask: 1.0921  decode.d0.loss_dice: 0.7155  decode.d1.loss_cls: 0.1754  decode.d1.loss_mask: 1.1395  decode.d1.loss_dice: 0.7529  decode.d2.loss_cls: 0.1905  decode.d2.loss_mask: 1.1329  decode.d2.loss_dice: 0.7480  decode.d3.loss_cls: 0.2033  decode.d3.loss_mask: 1.1227  decode.d3.loss_dice: 0.7418  decode.d4.loss_cls: 0.1715  decode.d4.loss_mask: 1.1250  decode.d4.loss_dice: 0.7478  decode.d5.loss_cls: 0.2277  decode.d5.loss_mask: 1.1330  decode.d5.loss_dice: 0.7386  decode.d6.loss_cls: 0.1980  decode.d6.loss_mask: 1.1322  decode.d6.loss_dice: 0.7558  decode.d7.loss_cls: 0.2115  decode.d7.loss_mask: 1.1401  decode.d7.loss_dice: 0.7503  decode.d8.loss_cls: 0.1801  decode.d8.loss_mask: 1.1591  decode.d8.loss_dice: 0.7598
05/26 20:52:30 - mmengine - INFO - Iter(train) [ 84200/160000]  base_lr: 5.1050e-05 lr: 5.1050e-06  eta: 8:40:42  time: 0.4139  data_time: 0.0098  memory: 5967  grad_norm: 444.2398  loss: 19.2505  decode.loss_cls: 0.1528  decode.loss_mask: 0.9330  decode.loss_dice: 0.7609  decode.d0.loss_cls: 0.6493  decode.d0.loss_mask: 0.9247  decode.d0.loss_dice: 0.7595  decode.d1.loss_cls: 0.1575  decode.d1.loss_mask: 0.9365  decode.d1.loss_dice: 0.7553  decode.d2.loss_cls: 0.2004  decode.d2.loss_mask: 0.9284  decode.d2.loss_dice: 0.7401  decode.d3.loss_cls: 0.1552  decode.d3.loss_mask: 0.9641  decode.d3.loss_dice: 0.7960  decode.d4.loss_cls: 0.1862  decode.d4.loss_mask: 0.9439  decode.d4.loss_dice: 0.7497  decode.d5.loss_cls: 0.1963  decode.d5.loss_mask: 0.9452  decode.d5.loss_dice: 0.7381  decode.d6.loss_cls: 0.2045  decode.d6.loss_mask: 0.9508  decode.d6.loss_dice: 0.7509  decode.d7.loss_cls: 0.1907  decode.d7.loss_mask: 0.9320  decode.d7.loss_dice: 0.7534  decode.d8.loss_cls: 0.1761  decode.d8.loss_mask: 0.9445  decode.d8.loss_dice: 0.7744
05/26 20:52:50 - mmengine - INFO - Iter(train) [ 84250/160000]  base_lr: 5.1020e-05 lr: 5.1020e-06  eta: 8:40:21  time: 0.4143  data_time: 0.0097  memory: 5970  grad_norm: 450.3684  loss: 18.8239  decode.loss_cls: 0.1796  decode.loss_mask: 0.9985  decode.loss_dice: 0.6695  decode.d0.loss_cls: 0.5857  decode.d0.loss_mask: 0.9898  decode.d0.loss_dice: 0.6868  decode.d1.loss_cls: 0.1924  decode.d1.loss_mask: 0.9969  decode.d1.loss_dice: 0.6944  decode.d2.loss_cls: 0.1772  decode.d2.loss_mask: 0.9815  decode.d2.loss_dice: 0.6609  decode.d3.loss_cls: 0.1650  decode.d3.loss_mask: 0.9983  decode.d3.loss_dice: 0.6699  decode.d4.loss_cls: 0.1716  decode.d4.loss_mask: 0.9890  decode.d4.loss_dice: 0.6571  decode.d5.loss_cls: 0.1901  decode.d5.loss_mask: 0.9917  decode.d5.loss_dice: 0.6592  decode.d6.loss_cls: 0.1924  decode.d6.loss_mask: 1.0053  decode.d6.loss_dice: 0.6630  decode.d7.loss_cls: 0.1595  decode.d7.loss_mask: 0.9966  decode.d7.loss_dice: 0.6584  decode.d8.loss_cls: 0.1853  decode.d8.loss_mask: 0.9967  decode.d8.loss_dice: 0.6615
05/26 20:53:11 - mmengine - INFO - Iter(train) [ 84300/160000]  base_lr: 5.0989e-05 lr: 5.0989e-06  eta: 8:40:01  time: 0.4137  data_time: 0.0096  memory: 5980  grad_norm: 553.9490  loss: 20.7362  decode.loss_cls: 0.1123  decode.loss_mask: 1.1057  decode.loss_dice: 0.8007  decode.d0.loss_cls: 0.6844  decode.d0.loss_mask: 0.9839  decode.d0.loss_dice: 0.7585  decode.d1.loss_cls: 0.1258  decode.d1.loss_mask: 1.1231  decode.d1.loss_dice: 0.8156  decode.d2.loss_cls: 0.1180  decode.d2.loss_mask: 1.1086  decode.d2.loss_dice: 0.8126  decode.d3.loss_cls: 0.1300  decode.d3.loss_mask: 1.0927  decode.d3.loss_dice: 0.8156  decode.d4.loss_cls: 0.1301  decode.d4.loss_mask: 1.1089  decode.d4.loss_dice: 0.8166  decode.d5.loss_cls: 0.1250  decode.d5.loss_mask: 1.1079  decode.d5.loss_dice: 0.8112  decode.d6.loss_cls: 0.1265  decode.d6.loss_mask: 1.0939  decode.d6.loss_dice: 0.7900  decode.d7.loss_cls: 0.1260  decode.d7.loss_mask: 1.1194  decode.d7.loss_dice: 0.7888  decode.d8.loss_cls: 0.1187  decode.d8.loss_mask: 1.1008  decode.d8.loss_dice: 0.7850
05/26 20:53:32 - mmengine - INFO - Iter(train) [ 84350/160000]  base_lr: 5.0959e-05 lr: 5.0959e-06  eta: 8:39:40  time: 0.4137  data_time: 0.0096  memory: 5965  grad_norm: 554.1512  loss: 23.3440  decode.loss_cls: 0.3734  decode.loss_mask: 1.0717  decode.loss_dice: 0.8182  decode.d0.loss_cls: 0.6194  decode.d0.loss_mask: 1.1639  decode.d0.loss_dice: 0.8669  decode.d1.loss_cls: 0.3787  decode.d1.loss_mask: 1.0762  decode.d1.loss_dice: 0.8302  decode.d2.loss_cls: 0.3382  decode.d2.loss_mask: 1.1766  decode.d2.loss_dice: 0.8176  decode.d3.loss_cls: 0.3133  decode.d3.loss_mask: 1.1812  decode.d3.loss_dice: 0.8680  decode.d4.loss_cls: 0.3250  decode.d4.loss_mask: 1.1185  decode.d4.loss_dice: 0.9069  decode.d5.loss_cls: 0.3199  decode.d5.loss_mask: 1.1179  decode.d5.loss_dice: 0.8287  decode.d6.loss_cls: 0.3438  decode.d6.loss_mask: 1.0936  decode.d6.loss_dice: 0.8393  decode.d7.loss_cls: 0.3244  decode.d7.loss_mask: 1.1301  decode.d7.loss_dice: 0.8616  decode.d8.loss_cls: 0.3618  decode.d8.loss_mask: 1.0780  decode.d8.loss_dice: 0.8011
05/26 20:53:53 - mmengine - INFO - Iter(train) [ 84400/160000]  base_lr: 5.0929e-05 lr: 5.0929e-06  eta: 8:39:20  time: 0.4136  data_time: 0.0097  memory: 5988  grad_norm: 1248.9088  loss: 21.0366  decode.loss_cls: 0.1979  decode.loss_mask: 1.1292  decode.loss_dice: 0.7079  decode.d0.loss_cls: 0.6885  decode.d0.loss_mask: 1.0770  decode.d0.loss_dice: 0.6872  decode.d1.loss_cls: 0.2673  decode.d1.loss_mask: 1.1425  decode.d1.loss_dice: 0.6693  decode.d2.loss_cls: 0.2628  decode.d2.loss_mask: 1.1455  decode.d2.loss_dice: 0.6787  decode.d3.loss_cls: 0.2614  decode.d3.loss_mask: 1.1443  decode.d3.loss_dice: 0.6720  decode.d4.loss_cls: 0.2772  decode.d4.loss_mask: 1.1410  decode.d4.loss_dice: 0.6865  decode.d5.loss_cls: 0.3002  decode.d5.loss_mask: 1.0977  decode.d5.loss_dice: 0.6707  decode.d6.loss_cls: 0.3004  decode.d6.loss_mask: 1.0885  decode.d6.loss_dice: 0.6570  decode.d7.loss_cls: 0.2526  decode.d7.loss_mask: 1.1176  decode.d7.loss_dice: 0.6610  decode.d8.loss_cls: 0.2555  decode.d8.loss_mask: 1.0975  decode.d8.loss_dice: 0.7018
05/26 20:54:13 - mmengine - INFO - Iter(train) [ 84450/160000]  base_lr: 5.0899e-05 lr: 5.0899e-06  eta: 8:38:59  time: 0.4135  data_time: 0.0097  memory: 5973  grad_norm: 598.4148  loss: 21.1156  decode.loss_cls: 0.1627  decode.loss_mask: 1.1884  decode.loss_dice: 0.7317  decode.d0.loss_cls: 0.6864  decode.d0.loss_mask: 1.0515  decode.d0.loss_dice: 0.6833  decode.d1.loss_cls: 0.2091  decode.d1.loss_mask: 1.1758  decode.d1.loss_dice: 0.7592  decode.d2.loss_cls: 0.1455  decode.d2.loss_mask: 1.1831  decode.d2.loss_dice: 0.7223  decode.d3.loss_cls: 0.1602  decode.d3.loss_mask: 1.1641  decode.d3.loss_dice: 0.7146  decode.d4.loss_cls: 0.1904  decode.d4.loss_mask: 1.1742  decode.d4.loss_dice: 0.7173  decode.d5.loss_cls: 0.1858  decode.d5.loss_mask: 1.1597  decode.d5.loss_dice: 0.7218  decode.d6.loss_cls: 0.2073  decode.d6.loss_mask: 1.1687  decode.d6.loss_dice: 0.7275  decode.d7.loss_cls: 0.1425  decode.d7.loss_mask: 1.1879  decode.d7.loss_dice: 0.7314  decode.d8.loss_cls: 0.1448  decode.d8.loss_mask: 1.1853  decode.d8.loss_dice: 0.7331
05/26 20:54:34 - mmengine - INFO - Iter(train) [ 84500/160000]  base_lr: 5.0868e-05 lr: 5.0868e-06  eta: 8:38:39  time: 0.4146  data_time: 0.0096  memory: 5975  grad_norm: 547.7404  loss: 17.0365  decode.loss_cls: 0.0693  decode.loss_mask: 0.9141  decode.loss_dice: 0.6559  decode.d0.loss_cls: 0.5210  decode.d0.loss_mask: 0.8638  decode.d0.loss_dice: 0.6449  decode.d1.loss_cls: 0.1102  decode.d1.loss_mask: 0.9150  decode.d1.loss_dice: 0.6526  decode.d2.loss_cls: 0.0791  decode.d2.loss_mask: 0.8998  decode.d2.loss_dice: 0.6571  decode.d3.loss_cls: 0.1293  decode.d3.loss_mask: 0.8987  decode.d3.loss_dice: 0.6390  decode.d4.loss_cls: 0.1104  decode.d4.loss_mask: 0.9123  decode.d4.loss_dice: 0.6471  decode.d5.loss_cls: 0.0952  decode.d5.loss_mask: 0.9091  decode.d5.loss_dice: 0.6484  decode.d6.loss_cls: 0.1213  decode.d6.loss_mask: 0.9209  decode.d6.loss_dice: 0.6641  decode.d7.loss_cls: 0.1033  decode.d7.loss_mask: 0.9099  decode.d7.loss_dice: 0.6643  decode.d8.loss_cls: 0.0834  decode.d8.loss_mask: 0.9231  decode.d8.loss_dice: 0.6738
05/26 20:54:55 - mmengine - INFO - Iter(train) [ 84550/160000]  base_lr: 5.0838e-05 lr: 5.0838e-06  eta: 8:38:18  time: 0.4133  data_time: 0.0098  memory: 5986  grad_norm: 651.0087  loss: 16.1622  decode.loss_cls: 0.0938  decode.loss_mask: 0.8519  decode.loss_dice: 0.6091  decode.d0.loss_cls: 0.7024  decode.d0.loss_mask: 0.8209  decode.d0.loss_dice: 0.5461  decode.d1.loss_cls: 0.1392  decode.d1.loss_mask: 0.8397  decode.d1.loss_dice: 0.5712  decode.d2.loss_cls: 0.1390  decode.d2.loss_mask: 0.8638  decode.d2.loss_dice: 0.5803  decode.d3.loss_cls: 0.1326  decode.d3.loss_mask: 0.8344  decode.d3.loss_dice: 0.5652  decode.d4.loss_cls: 0.1316  decode.d4.loss_mask: 0.8377  decode.d4.loss_dice: 0.5648  decode.d5.loss_cls: 0.1314  decode.d5.loss_mask: 0.8450  decode.d5.loss_dice: 0.6237  decode.d6.loss_cls: 0.1327  decode.d6.loss_mask: 0.8542  decode.d6.loss_dice: 0.6182  decode.d7.loss_cls: 0.1266  decode.d7.loss_mask: 0.8283  decode.d7.loss_dice: 0.5862  decode.d8.loss_cls: 0.1179  decode.d8.loss_mask: 0.8479  decode.d8.loss_dice: 0.6262
05/26 20:55:16 - mmengine - INFO - Iter(train) [ 84600/160000]  base_lr: 5.0808e-05 lr: 5.0808e-06  eta: 8:37:58  time: 0.4133  data_time: 0.0098  memory: 5970  grad_norm: 1126.1244  loss: 21.7344  decode.loss_cls: 0.1956  decode.loss_mask: 1.1171  decode.loss_dice: 0.7959  decode.d0.loss_cls: 0.6792  decode.d0.loss_mask: 1.0884  decode.d0.loss_dice: 0.7557  decode.d1.loss_cls: 0.2440  decode.d1.loss_mask: 1.1014  decode.d1.loss_dice: 0.8198  decode.d2.loss_cls: 0.2373  decode.d2.loss_mask: 1.0649  decode.d2.loss_dice: 0.7564  decode.d3.loss_cls: 0.2437  decode.d3.loss_mask: 1.0853  decode.d3.loss_dice: 0.8025  decode.d4.loss_cls: 0.2169  decode.d4.loss_mask: 1.0840  decode.d4.loss_dice: 0.8202  decode.d5.loss_cls: 0.2705  decode.d5.loss_mask: 1.1178  decode.d5.loss_dice: 0.7981  decode.d6.loss_cls: 0.2303  decode.d6.loss_mask: 1.1128  decode.d6.loss_dice: 0.8065  decode.d7.loss_cls: 0.2388  decode.d7.loss_mask: 1.0868  decode.d7.loss_dice: 0.8248  decode.d8.loss_cls: 0.2080  decode.d8.loss_mask: 1.1230  decode.d8.loss_dice: 0.8085
05/26 20:55:36 - mmengine - INFO - Iter(train) [ 84650/160000]  base_lr: 5.0777e-05 lr: 5.0777e-06  eta: 8:37:37  time: 0.4149  data_time: 0.0104  memory: 5984  grad_norm: 391.9676  loss: 15.9076  decode.loss_cls: 0.0946  decode.loss_mask: 0.9055  decode.loss_dice: 0.5530  decode.d0.loss_cls: 0.4729  decode.d0.loss_mask: 0.8808  decode.d0.loss_dice: 0.5392  decode.d1.loss_cls: 0.0991  decode.d1.loss_mask: 0.9009  decode.d1.loss_dice: 0.5649  decode.d2.loss_cls: 0.0960  decode.d2.loss_mask: 0.9108  decode.d2.loss_dice: 0.5551  decode.d3.loss_cls: 0.1050  decode.d3.loss_mask: 0.9113  decode.d3.loss_dice: 0.5429  decode.d4.loss_cls: 0.0990  decode.d4.loss_mask: 0.8982  decode.d4.loss_dice: 0.5491  decode.d5.loss_cls: 0.1120  decode.d5.loss_mask: 0.8982  decode.d5.loss_dice: 0.5536  decode.d6.loss_cls: 0.1075  decode.d6.loss_mask: 0.9019  decode.d6.loss_dice: 0.5544  decode.d7.loss_cls: 0.1054  decode.d7.loss_mask: 0.8967  decode.d7.loss_dice: 0.5513  decode.d8.loss_cls: 0.0922  decode.d8.loss_mask: 0.8966  decode.d8.loss_dice: 0.5594
05/26 20:55:57 - mmengine - INFO - Iter(train) [ 84700/160000]  base_lr: 5.0747e-05 lr: 5.0747e-06  eta: 8:37:16  time: 0.4125  data_time: 0.0098  memory: 5981  grad_norm: 846.2429  loss: 23.7320  decode.loss_cls: 0.2398  decode.loss_mask: 1.3306  decode.loss_dice: 0.8069  decode.d0.loss_cls: 0.7394  decode.d0.loss_mask: 1.2282  decode.d0.loss_dice: 0.7772  decode.d1.loss_cls: 0.2675  decode.d1.loss_mask: 1.2943  decode.d1.loss_dice: 0.7762  decode.d2.loss_cls: 0.2684  decode.d2.loss_mask: 1.2756  decode.d2.loss_dice: 0.7768  decode.d3.loss_cls: 0.2371  decode.d3.loss_mask: 1.2496  decode.d3.loss_dice: 0.7737  decode.d4.loss_cls: 0.2681  decode.d4.loss_mask: 1.2682  decode.d4.loss_dice: 0.7888  decode.d5.loss_cls: 0.3459  decode.d5.loss_mask: 1.2538  decode.d5.loss_dice: 0.7880  decode.d6.loss_cls: 0.2389  decode.d6.loss_mask: 1.3065  decode.d6.loss_dice: 0.8072  decode.d7.loss_cls: 0.2848  decode.d7.loss_mask: 1.2972  decode.d7.loss_dice: 0.7864  decode.d8.loss_cls: 0.2560  decode.d8.loss_mask: 1.2461  decode.d8.loss_dice: 0.7549
05/26 20:56:18 - mmengine - INFO - Iter(train) [ 84750/160000]  base_lr: 5.0717e-05 lr: 5.0717e-06  eta: 8:36:56  time: 0.4138  data_time: 0.0097  memory: 5967  grad_norm: 1139.7625  loss: 17.4878  decode.loss_cls: 0.0938  decode.loss_mask: 0.9046  decode.loss_dice: 0.6755  decode.d0.loss_cls: 0.5379  decode.d0.loss_mask: 0.8794  decode.d0.loss_dice: 0.6705  decode.d1.loss_cls: 0.1418  decode.d1.loss_mask: 0.8981  decode.d1.loss_dice: 0.6631  decode.d2.loss_cls: 0.0997  decode.d2.loss_mask: 0.9225  decode.d2.loss_dice: 0.7001  decode.d3.loss_cls: 0.1060  decode.d3.loss_mask: 0.9202  decode.d3.loss_dice: 0.6902  decode.d4.loss_cls: 0.1266  decode.d4.loss_mask: 0.8997  decode.d4.loss_dice: 0.6774  decode.d5.loss_cls: 0.1210  decode.d5.loss_mask: 0.9198  decode.d5.loss_dice: 0.7029  decode.d6.loss_cls: 0.1330  decode.d6.loss_mask: 0.9111  decode.d6.loss_dice: 0.6781  decode.d7.loss_cls: 0.1067  decode.d7.loss_mask: 0.9256  decode.d7.loss_dice: 0.6788  decode.d8.loss_cls: 0.1025  decode.d8.loss_mask: 0.9221  decode.d8.loss_dice: 0.6793
05/26 20:56:38 - mmengine - INFO - Iter(train) [ 84800/160000]  base_lr: 5.0686e-05 lr: 5.0686e-06  eta: 8:36:35  time: 0.4127  data_time: 0.0097  memory: 5971  grad_norm: 428.3025  loss: 23.0355  decode.loss_cls: 0.2881  decode.loss_mask: 1.0858  decode.loss_dice: 0.8806  decode.d0.loss_cls: 0.7556  decode.d0.loss_mask: 1.0409  decode.d0.loss_dice: 0.8329  decode.d1.loss_cls: 0.3141  decode.d1.loss_mask: 1.0723  decode.d1.loss_dice: 0.8609  decode.d2.loss_cls: 0.3137  decode.d2.loss_mask: 1.0609  decode.d2.loss_dice: 0.8750  decode.d3.loss_cls: 0.3114  decode.d3.loss_mask: 1.0747  decode.d3.loss_dice: 0.8695  decode.d4.loss_cls: 0.3364  decode.d4.loss_mask: 1.0986  decode.d4.loss_dice: 0.8943  decode.d5.loss_cls: 0.3408  decode.d5.loss_mask: 1.0627  decode.d5.loss_dice: 0.8357  decode.d6.loss_cls: 0.3063  decode.d6.loss_mask: 1.0952  decode.d6.loss_dice: 0.8538  decode.d7.loss_cls: 0.3124  decode.d7.loss_mask: 1.1055  decode.d7.loss_dice: 0.8692  decode.d8.loss_cls: 0.2735  decode.d8.loss_mask: 1.1220  decode.d8.loss_dice: 0.8926
05/26 20:56:59 - mmengine - INFO - Iter(train) [ 84850/160000]  base_lr: 5.0656e-05 lr: 5.0656e-06  eta: 8:36:15  time: 0.4127  data_time: 0.0098  memory: 5975  grad_norm: 631.1428  loss: 18.7719  decode.loss_cls: 0.1615  decode.loss_mask: 0.9611  decode.loss_dice: 0.6875  decode.d0.loss_cls: 0.5939  decode.d0.loss_mask: 0.9557  decode.d0.loss_dice: 0.7126  decode.d1.loss_cls: 0.1650  decode.d1.loss_mask: 0.9619  decode.d1.loss_dice: 0.6992  decode.d2.loss_cls: 0.1329  decode.d2.loss_mask: 0.9679  decode.d2.loss_dice: 0.7150  decode.d3.loss_cls: 0.1349  decode.d3.loss_mask: 0.9767  decode.d3.loss_dice: 0.7344  decode.d4.loss_cls: 0.1469  decode.d4.loss_mask: 1.0267  decode.d4.loss_dice: 0.6972  decode.d5.loss_cls: 0.1676  decode.d5.loss_mask: 0.9476  decode.d5.loss_dice: 0.7060  decode.d6.loss_cls: 0.1757  decode.d6.loss_mask: 0.9880  decode.d6.loss_dice: 0.6829  decode.d7.loss_cls: 0.1952  decode.d7.loss_mask: 0.9630  decode.d7.loss_dice: 0.6889  decode.d8.loss_cls: 0.1845  decode.d8.loss_mask: 0.9514  decode.d8.loss_dice: 0.6900
05/26 20:57:20 - mmengine - INFO - Iter(train) [ 84900/160000]  base_lr: 5.0626e-05 lr: 5.0626e-06  eta: 8:35:54  time: 0.4137  data_time: 0.0097  memory: 5969  grad_norm: 392.0896  loss: 20.1604  decode.loss_cls: 0.2820  decode.loss_mask: 0.9054  decode.loss_dice: 0.7307  decode.d0.loss_cls: 0.7355  decode.d0.loss_mask: 0.8988  decode.d0.loss_dice: 0.7328  decode.d1.loss_cls: 0.3006  decode.d1.loss_mask: 0.9173  decode.d1.loss_dice: 0.7611  decode.d2.loss_cls: 0.2617  decode.d2.loss_mask: 0.9289  decode.d2.loss_dice: 0.7452  decode.d3.loss_cls: 0.2834  decode.d3.loss_mask: 0.9175  decode.d3.loss_dice: 0.7517  decode.d4.loss_cls: 0.2750  decode.d4.loss_mask: 0.9362  decode.d4.loss_dice: 0.7485  decode.d5.loss_cls: 0.3158  decode.d5.loss_mask: 0.9207  decode.d5.loss_dice: 0.7502  decode.d6.loss_cls: 0.3272  decode.d6.loss_mask: 0.9386  decode.d6.loss_dice: 0.7772  decode.d7.loss_cls: 0.3091  decode.d7.loss_mask: 0.9538  decode.d7.loss_dice: 0.7843  decode.d8.loss_cls: 0.2721  decode.d8.loss_mask: 0.9516  decode.d8.loss_dice: 0.7472
05/26 20:57:40 - mmengine - INFO - Iter(train) [ 84950/160000]  base_lr: 5.0595e-05 lr: 5.0595e-06  eta: 8:35:34  time: 0.4132  data_time: 0.0097  memory: 5976  grad_norm: 279.6530  loss: 19.5330  decode.loss_cls: 0.1886  decode.loss_mask: 0.8925  decode.loss_dice: 0.7920  decode.d0.loss_cls: 0.6640  decode.d0.loss_mask: 0.8784  decode.d0.loss_dice: 0.7842  decode.d1.loss_cls: 0.2399  decode.d1.loss_mask: 0.9045  decode.d1.loss_dice: 0.7906  decode.d2.loss_cls: 0.2151  decode.d2.loss_mask: 0.9106  decode.d2.loss_dice: 0.8185  decode.d3.loss_cls: 0.1822  decode.d3.loss_mask: 0.9031  decode.d3.loss_dice: 0.8183  decode.d4.loss_cls: 0.2160  decode.d4.loss_mask: 0.9004  decode.d4.loss_dice: 0.8140  decode.d5.loss_cls: 0.2006  decode.d5.loss_mask: 0.8739  decode.d5.loss_dice: 0.8230  decode.d6.loss_cls: 0.2469  decode.d6.loss_mask: 0.8934  decode.d6.loss_dice: 0.7808  decode.d7.loss_cls: 0.1831  decode.d7.loss_mask: 0.9148  decode.d7.loss_dice: 0.8126  decode.d8.loss_cls: 0.1979  decode.d8.loss_mask: 0.9026  decode.d8.loss_dice: 0.7904
05/26 20:58:01 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 20:58:01 - mmengine - INFO - Iter(train) [ 85000/160000]  base_lr: 5.0565e-05 lr: 5.0565e-06  eta: 8:35:13  time: 0.4134  data_time: 0.0097  memory: 5967  grad_norm: 709.9678  loss: 18.9226  decode.loss_cls: 0.1046  decode.loss_mask: 1.0363  decode.loss_dice: 0.7146  decode.d0.loss_cls: 0.6418  decode.d0.loss_mask: 0.9871  decode.d0.loss_dice: 0.6846  decode.d1.loss_cls: 0.1531  decode.d1.loss_mask: 1.0036  decode.d1.loss_dice: 0.6990  decode.d2.loss_cls: 0.1331  decode.d2.loss_mask: 1.0112  decode.d2.loss_dice: 0.7057  decode.d3.loss_cls: 0.1118  decode.d3.loss_mask: 1.0009  decode.d3.loss_dice: 0.6986  decode.d4.loss_cls: 0.1300  decode.d4.loss_mask: 1.0152  decode.d4.loss_dice: 0.7083  decode.d5.loss_cls: 0.1040  decode.d5.loss_mask: 1.0232  decode.d5.loss_dice: 0.7052  decode.d6.loss_cls: 0.1312  decode.d6.loss_mask: 1.0500  decode.d6.loss_dice: 0.7111  decode.d7.loss_cls: 0.1377  decode.d7.loss_mask: 0.9893  decode.d7.loss_dice: 0.6911  decode.d8.loss_cls: 0.1011  decode.d8.loss_mask: 1.0453  decode.d8.loss_dice: 0.6938
05/26 20:58:01 - mmengine - INFO - Saving checkpoint at 85000 iterations
05/26 20:58:05 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:08  time: 0.0479  data_time: 0.0012  memory: 1391  
05/26 20:58:08 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:05  time: 0.0477  data_time: 0.0012  memory: 1205  
05/26 20:58:10 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:03  time: 0.0506  data_time: 0.0012  memory: 1596  
05/26 20:58:13 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0487  data_time: 0.0012  memory: 1298  
05/26 20:58:15 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:58  time: 0.0477  data_time: 0.0012  memory: 1298  
05/26 20:58:17 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0481  data_time: 0.0012  memory: 1279  
05/26 20:58:20 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:53  time: 0.0481  data_time: 0.0012  memory: 1224  
05/26 20:58:22 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0488  data_time: 0.0012  memory: 1298  
05/26 20:58:25 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0476  data_time: 0.0012  memory: 1298  
05/26 20:58:27 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0527  data_time: 0.0012  memory: 1725  
05/26 20:58:30 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0480  data_time: 0.0012  memory: 1336  
05/26 20:58:32 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:41  time: 0.0482  data_time: 0.0012  memory: 1298  
05/26 20:58:34 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0487  data_time: 0.0012  memory: 1205  
05/26 20:58:37 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0498  data_time: 0.0012  memory: 1316  
05/26 20:58:39 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0477  data_time: 0.0012  memory: 1279  
05/26 20:58:42 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0514  data_time: 0.0013  memory: 1410  
05/26 20:58:44 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0489  data_time: 0.0013  memory: 1279  
05/26 20:58:47 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0486  data_time: 0.0012  memory: 1205  
05/26 20:58:49 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0487  data_time: 0.0012  memory: 1205  
05/26 20:58:51 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0481  data_time: 0.0013  memory: 1336  
05/26 20:58:54 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0479  data_time: 0.0012  memory: 1246  
05/26 20:58:56 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0499  data_time: 0.0012  memory: 1503  
05/26 20:58:59 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0478  data_time: 0.0012  memory: 1261  
05/26 20:59:01 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0485  data_time: 0.0012  memory: 1298  
05/26 20:59:03 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0480  data_time: 0.0012  memory: 1447  
05/26 20:59:06 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0477  data_time: 0.0012  memory: 1298  
05/26 20:59:08 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0492  data_time: 0.0012  memory: 1279  
05/26 20:59:11 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0477  data_time: 0.0012  memory: 1205  
05/26 20:59:13 - mmengine - INFO - per class results:
05/26 20:59:13 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.56 | 97.28 |
|  aeroplane  | 91.85 | 95.75 |
|   bicycle   | 40.34 | 96.95 |
|     bird    | 89.77 | 92.92 |
|     boat    |  70.3 | 88.69 |
|    bottle   | 80.58 | 89.86 |
|     bus     | 93.89 | 97.96 |
|     car     | 92.46 | 94.12 |
|     cat     |  94.6 |  98.1 |
|    chair    | 43.16 |  65.1 |
|     cow     | 84.45 | 88.84 |
| diningtable | 60.53 |  64.7 |
|     dog     | 88.52 | 98.56 |
|    horse    | 90.43 | 95.44 |
|  motorbike  | 89.99 | 94.61 |
|    person   | 91.13 | 95.14 |
| pottedplant | 71.92 | 88.19 |
|    sheep    | 84.49 | 91.74 |
|     sofa    | 59.99 | 81.16 |
|    train    | 88.84 |  93.1 |
|  tvmonitor  | 80.52 | 86.76 |
+-------------+-------+-------+
05/26 20:59:13 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.7500  mIoU: 80.1600  mAcc: 90.2400  data_time: 0.0012  time: 0.0483
05/26 20:59:13 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_60000.pth is removed
05/26 20:59:14 - mmengine - INFO - The best checkpoint with 80.1600 mIoU at 85000 iter is saved to best_mIoU_iter_85000.pth.
05/26 20:59:37 - mmengine - INFO - Iter(train) [ 85050/160000]  base_lr: 5.0535e-05 lr: 5.0535e-06  eta: 8:34:55  time: 0.4126  data_time: 0.0097  memory: 5966  grad_norm: 550.2461  loss: 23.6182  decode.loss_cls: 0.1786  decode.loss_mask: 1.2683  decode.loss_dice: 0.8657  decode.d0.loss_cls: 0.7707  decode.d0.loss_mask: 1.1865  decode.d0.loss_dice: 0.8356  decode.d1.loss_cls: 0.2044  decode.d1.loss_mask: 1.2703  decode.d1.loss_dice: 0.8667  decode.d2.loss_cls: 0.2258  decode.d2.loss_mask: 1.2162  decode.d2.loss_dice: 0.8403  decode.d3.loss_cls: 0.2175  decode.d3.loss_mask: 1.2224  decode.d3.loss_dice: 0.8510  decode.d4.loss_cls: 0.1964  decode.d4.loss_mask: 1.2751  decode.d4.loss_dice: 0.8609  decode.d5.loss_cls: 0.2015  decode.d5.loss_mask: 1.2138  decode.d5.loss_dice: 0.8555  decode.d6.loss_cls: 0.1812  decode.d6.loss_mask: 1.2837  decode.d6.loss_dice: 0.8644  decode.d7.loss_cls: 0.1823  decode.d7.loss_mask: 1.2757  decode.d7.loss_dice: 0.8852  decode.d8.loss_cls: 0.1858  decode.d8.loss_mask: 1.2657  decode.d8.loss_dice: 0.8713
05/26 20:59:58 - mmengine - INFO - Iter(train) [ 85100/160000]  base_lr: 5.0504e-05 lr: 5.0504e-06  eta: 8:34:35  time: 0.4128  data_time: 0.0110  memory: 5967  grad_norm: 419.4739  loss: 17.6333  decode.loss_cls: 0.1724  decode.loss_mask: 0.8499  decode.loss_dice: 0.6532  decode.d0.loss_cls: 0.6183  decode.d0.loss_mask: 0.8543  decode.d0.loss_dice: 0.7014  decode.d1.loss_cls: 0.1728  decode.d1.loss_mask: 0.8567  decode.d1.loss_dice: 0.6934  decode.d2.loss_cls: 0.2023  decode.d2.loss_mask: 0.8574  decode.d2.loss_dice: 0.6845  decode.d3.loss_cls: 0.2190  decode.d3.loss_mask: 0.8558  decode.d3.loss_dice: 0.6772  decode.d4.loss_cls: 0.1741  decode.d4.loss_mask: 0.8756  decode.d4.loss_dice: 0.6925  decode.d5.loss_cls: 0.1539  decode.d5.loss_mask: 0.8637  decode.d5.loss_dice: 0.6916  decode.d6.loss_cls: 0.1800  decode.d6.loss_mask: 0.8175  decode.d6.loss_dice: 0.6659  decode.d7.loss_cls: 0.1870  decode.d7.loss_mask: 0.8776  decode.d7.loss_dice: 0.6733  decode.d8.loss_cls: 0.1650  decode.d8.loss_mask: 0.8642  decode.d8.loss_dice: 0.6829
05/26 21:00:18 - mmengine - INFO - Iter(train) [ 85150/160000]  base_lr: 5.0474e-05 lr: 5.0474e-06  eta: 8:34:14  time: 0.4124  data_time: 0.0097  memory: 5968  grad_norm: 441.1765  loss: 21.0420  decode.loss_cls: 0.2812  decode.loss_mask: 0.9937  decode.loss_dice: 0.7472  decode.d0.loss_cls: 0.8954  decode.d0.loss_mask: 0.9125  decode.d0.loss_dice: 0.7187  decode.d1.loss_cls: 0.2750  decode.d1.loss_mask: 0.9944  decode.d1.loss_dice: 0.7629  decode.d2.loss_cls: 0.2963  decode.d2.loss_mask: 0.9883  decode.d2.loss_dice: 0.7178  decode.d3.loss_cls: 0.3637  decode.d3.loss_mask: 0.9993  decode.d3.loss_dice: 0.7417  decode.d4.loss_cls: 0.3111  decode.d4.loss_mask: 0.9933  decode.d4.loss_dice: 0.7407  decode.d5.loss_cls: 0.3226  decode.d5.loss_mask: 0.9954  decode.d5.loss_dice: 0.7544  decode.d6.loss_cls: 0.3394  decode.d6.loss_mask: 1.0111  decode.d6.loss_dice: 0.7530  decode.d7.loss_cls: 0.2823  decode.d7.loss_mask: 1.0197  decode.d7.loss_dice: 0.7702  decode.d8.loss_cls: 0.2976  decode.d8.loss_mask: 1.0031  decode.d8.loss_dice: 0.7599
05/26 21:00:39 - mmengine - INFO - Iter(train) [ 85200/160000]  base_lr: 5.0444e-05 lr: 5.0444e-06  eta: 8:33:53  time: 0.4129  data_time: 0.0098  memory: 5975  grad_norm: 596.5192  loss: 19.7531  decode.loss_cls: 0.2197  decode.loss_mask: 1.0173  decode.loss_dice: 0.6700  decode.d0.loss_cls: 0.6569  decode.d0.loss_mask: 0.9848  decode.d0.loss_dice: 0.7184  decode.d1.loss_cls: 0.2249  decode.d1.loss_mask: 1.0255  decode.d1.loss_dice: 0.6903  decode.d2.loss_cls: 0.2122  decode.d2.loss_mask: 1.0303  decode.d2.loss_dice: 0.6900  decode.d3.loss_cls: 0.2246  decode.d3.loss_mask: 0.9865  decode.d3.loss_dice: 0.6778  decode.d4.loss_cls: 0.2203  decode.d4.loss_mask: 1.0427  decode.d4.loss_dice: 0.7095  decode.d5.loss_cls: 0.2249  decode.d5.loss_mask: 1.0081  decode.d5.loss_dice: 0.6766  decode.d6.loss_cls: 0.2614  decode.d6.loss_mask: 0.9794  decode.d6.loss_dice: 0.6954  decode.d7.loss_cls: 0.2198  decode.d7.loss_mask: 1.0394  decode.d7.loss_dice: 0.6972  decode.d8.loss_cls: 0.2229  decode.d8.loss_mask: 1.0342  decode.d8.loss_dice: 0.6922
05/26 21:00:59 - mmengine - INFO - Iter(train) [ 85250/160000]  base_lr: 5.0413e-05 lr: 5.0413e-06  eta: 8:33:33  time: 0.4123  data_time: 0.0097  memory: 5968  grad_norm: 609.2150  loss: 22.5746  decode.loss_cls: 0.2468  decode.loss_mask: 1.1613  decode.loss_dice: 0.7665  decode.d0.loss_cls: 0.7648  decode.d0.loss_mask: 1.1639  decode.d0.loss_dice: 0.7664  decode.d1.loss_cls: 0.2666  decode.d1.loss_mask: 1.1808  decode.d1.loss_dice: 0.7785  decode.d2.loss_cls: 0.2390  decode.d2.loss_mask: 1.1659  decode.d2.loss_dice: 0.7964  decode.d3.loss_cls: 0.2143  decode.d3.loss_mask: 1.2072  decode.d3.loss_dice: 0.8045  decode.d4.loss_cls: 0.2526  decode.d4.loss_mask: 1.1580  decode.d4.loss_dice: 0.7800  decode.d5.loss_cls: 0.2309  decode.d5.loss_mask: 1.1804  decode.d5.loss_dice: 0.7849  decode.d6.loss_cls: 0.2518  decode.d6.loss_mask: 1.1815  decode.d6.loss_dice: 0.8080  decode.d7.loss_cls: 0.2046  decode.d7.loss_mask: 1.2176  decode.d7.loss_dice: 0.8174  decode.d8.loss_cls: 0.2436  decode.d8.loss_mask: 1.1543  decode.d8.loss_dice: 0.7858
05/26 21:01:20 - mmengine - INFO - Iter(train) [ 85300/160000]  base_lr: 5.0383e-05 lr: 5.0383e-06  eta: 8:33:12  time: 0.4129  data_time: 0.0096  memory: 5967  grad_norm: 634.5901  loss: 20.5669  decode.loss_cls: 0.1836  decode.loss_mask: 1.0317  decode.loss_dice: 0.7583  decode.d0.loss_cls: 0.6692  decode.d0.loss_mask: 1.0960  decode.d0.loss_dice: 0.7604  decode.d1.loss_cls: 0.1980  decode.d1.loss_mask: 1.0702  decode.d1.loss_dice: 0.7427  decode.d2.loss_cls: 0.2059  decode.d2.loss_mask: 1.0657  decode.d2.loss_dice: 0.7234  decode.d3.loss_cls: 0.1779  decode.d3.loss_mask: 1.1058  decode.d3.loss_dice: 0.7448  decode.d4.loss_cls: 0.1946  decode.d4.loss_mask: 1.0462  decode.d4.loss_dice: 0.7229  decode.d5.loss_cls: 0.1848  decode.d5.loss_mask: 1.1226  decode.d5.loss_dice: 0.7522  decode.d6.loss_cls: 0.1807  decode.d6.loss_mask: 1.0658  decode.d6.loss_dice: 0.7370  decode.d7.loss_cls: 0.2127  decode.d7.loss_mask: 1.0593  decode.d7.loss_dice: 0.7475  decode.d8.loss_cls: 0.2148  decode.d8.loss_mask: 1.0332  decode.d8.loss_dice: 0.7591
05/26 21:01:41 - mmengine - INFO - Iter(train) [ 85350/160000]  base_lr: 5.0353e-05 lr: 5.0353e-06  eta: 8:32:52  time: 0.4123  data_time: 0.0097  memory: 5987  grad_norm: 798.3298  loss: 28.6857  decode.loss_cls: 0.4206  decode.loss_mask: 1.3937  decode.loss_dice: 0.9433  decode.d0.loss_cls: 1.0128  decode.d0.loss_mask: 1.3427  decode.d0.loss_dice: 0.9834  decode.d1.loss_cls: 0.4279  decode.d1.loss_mask: 1.4368  decode.d1.loss_dice: 1.0070  decode.d2.loss_cls: 0.4321  decode.d2.loss_mask: 1.4111  decode.d2.loss_dice: 0.9380  decode.d3.loss_cls: 0.4481  decode.d3.loss_mask: 1.4066  decode.d3.loss_dice: 0.9513  decode.d4.loss_cls: 0.5247  decode.d4.loss_mask: 1.3750  decode.d4.loss_dice: 0.9297  decode.d5.loss_cls: 0.4774  decode.d5.loss_mask: 1.4203  decode.d5.loss_dice: 0.9416  decode.d6.loss_cls: 0.5094  decode.d6.loss_mask: 1.3982  decode.d6.loss_dice: 0.9463  decode.d7.loss_cls: 0.4647  decode.d7.loss_mask: 1.4181  decode.d7.loss_dice: 0.9368  decode.d8.loss_cls: 0.4452  decode.d8.loss_mask: 1.3911  decode.d8.loss_dice: 0.9521
05/26 21:02:01 - mmengine - INFO - Iter(train) [ 85400/160000]  base_lr: 5.0322e-05 lr: 5.0322e-06  eta: 8:32:31  time: 0.4123  data_time: 0.0097  memory: 5966  grad_norm: 479.6248  loss: 19.8334  decode.loss_cls: 0.2046  decode.loss_mask: 0.9649  decode.loss_dice: 0.7278  decode.d0.loss_cls: 0.6928  decode.d0.loss_mask: 0.9231  decode.d0.loss_dice: 0.7266  decode.d1.loss_cls: 0.2800  decode.d1.loss_mask: 0.9526  decode.d1.loss_dice: 0.7418  decode.d2.loss_cls: 0.2456  decode.d2.loss_mask: 0.9275  decode.d2.loss_dice: 0.7772  decode.d3.loss_cls: 0.2400  decode.d3.loss_mask: 0.9767  decode.d3.loss_dice: 0.7542  decode.d4.loss_cls: 0.2269  decode.d4.loss_mask: 0.9515  decode.d4.loss_dice: 0.7685  decode.d5.loss_cls: 0.2320  decode.d5.loss_mask: 0.9815  decode.d5.loss_dice: 0.7496  decode.d6.loss_cls: 0.2203  decode.d6.loss_mask: 0.9607  decode.d6.loss_dice: 0.7516  decode.d7.loss_cls: 0.2227  decode.d7.loss_mask: 0.9622  decode.d7.loss_dice: 0.7475  decode.d8.loss_cls: 0.2425  decode.d8.loss_mask: 0.9535  decode.d8.loss_dice: 0.7270
05/26 21:02:22 - mmengine - INFO - Iter(train) [ 85450/160000]  base_lr: 5.0292e-05 lr: 5.0292e-06  eta: 8:32:10  time: 0.4111  data_time: 0.0096  memory: 5974  grad_norm: 687.7201  loss: 21.7033  decode.loss_cls: 0.3066  decode.loss_mask: 0.9319  decode.loss_dice: 0.8490  decode.d0.loss_cls: 0.8436  decode.d0.loss_mask: 0.9124  decode.d0.loss_dice: 0.8363  decode.d1.loss_cls: 0.3074  decode.d1.loss_mask: 0.9741  decode.d1.loss_dice: 0.8616  decode.d2.loss_cls: 0.3259  decode.d2.loss_mask: 0.9788  decode.d2.loss_dice: 0.8618  decode.d3.loss_cls: 0.3195  decode.d3.loss_mask: 0.9489  decode.d3.loss_dice: 0.8476  decode.d4.loss_cls: 0.3041  decode.d4.loss_mask: 0.9783  decode.d4.loss_dice: 0.8514  decode.d5.loss_cls: 0.3114  decode.d5.loss_mask: 0.9706  decode.d5.loss_dice: 0.8339  decode.d6.loss_cls: 0.3386  decode.d6.loss_mask: 0.9614  decode.d6.loss_dice: 0.8267  decode.d7.loss_cls: 0.3396  decode.d7.loss_mask: 0.9731  decode.d7.loss_dice: 0.8798  decode.d8.loss_cls: 0.2971  decode.d8.loss_mask: 0.9201  decode.d8.loss_dice: 0.8119
05/26 21:02:42 - mmengine - INFO - Iter(train) [ 85500/160000]  base_lr: 5.0261e-05 lr: 5.0261e-06  eta: 8:31:50  time: 0.4115  data_time: 0.0096  memory: 5979  grad_norm: 741.5044  loss: 22.5767  decode.loss_cls: 0.3064  decode.loss_mask: 1.0961  decode.loss_dice: 0.7849  decode.d0.loss_cls: 0.7698  decode.d0.loss_mask: 1.0648  decode.d0.loss_dice: 0.7963  decode.d1.loss_cls: 0.3278  decode.d1.loss_mask: 1.0512  decode.d1.loss_dice: 0.7646  decode.d2.loss_cls: 0.3326  decode.d2.loss_mask: 1.0901  decode.d2.loss_dice: 0.7769  decode.d3.loss_cls: 0.3643  decode.d3.loss_mask: 1.0915  decode.d3.loss_dice: 0.7940  decode.d4.loss_cls: 0.3205  decode.d4.loss_mask: 1.1181  decode.d4.loss_dice: 0.8237  decode.d5.loss_cls: 0.3585  decode.d5.loss_mask: 1.0965  decode.d5.loss_dice: 0.8124  decode.d6.loss_cls: 0.3141  decode.d6.loss_mask: 1.1292  decode.d6.loss_dice: 0.8306  decode.d7.loss_cls: 0.3178  decode.d7.loss_mask: 1.1225  decode.d7.loss_dice: 0.7642  decode.d8.loss_cls: 0.2584  decode.d8.loss_mask: 1.1216  decode.d8.loss_dice: 0.7775
05/26 21:03:03 - mmengine - INFO - Iter(train) [ 85550/160000]  base_lr: 5.0231e-05 lr: 5.0231e-06  eta: 8:31:29  time: 0.4118  data_time: 0.0097  memory: 5980  grad_norm: 464.1745  loss: 17.8799  decode.loss_cls: 0.1488  decode.loss_mask: 0.8681  decode.loss_dice: 0.6739  decode.d0.loss_cls: 0.6431  decode.d0.loss_mask: 0.9350  decode.d0.loss_dice: 0.7199  decode.d1.loss_cls: 0.1578  decode.d1.loss_mask: 0.9165  decode.d1.loss_dice: 0.6864  decode.d2.loss_cls: 0.1925  decode.d2.loss_mask: 0.8736  decode.d2.loss_dice: 0.7083  decode.d3.loss_cls: 0.1686  decode.d3.loss_mask: 0.8674  decode.d3.loss_dice: 0.6762  decode.d4.loss_cls: 0.1699  decode.d4.loss_mask: 0.8845  decode.d4.loss_dice: 0.6904  decode.d5.loss_cls: 0.1516  decode.d5.loss_mask: 0.8692  decode.d5.loss_dice: 0.6767  decode.d6.loss_cls: 0.1725  decode.d6.loss_mask: 0.8713  decode.d6.loss_dice: 0.6795  decode.d7.loss_cls: 0.1569  decode.d7.loss_mask: 0.9197  decode.d7.loss_dice: 0.6917  decode.d8.loss_cls: 0.1651  decode.d8.loss_mask: 0.8656  decode.d8.loss_dice: 0.6793
05/26 21:03:24 - mmengine - INFO - Iter(train) [ 85600/160000]  base_lr: 5.0201e-05 lr: 5.0201e-06  eta: 8:31:08  time: 0.4124  data_time: 0.0096  memory: 5971  grad_norm: 786.3867  loss: 21.5566  decode.loss_cls: 0.1390  decode.loss_mask: 1.1012  decode.loss_dice: 0.8453  decode.d0.loss_cls: 0.5785  decode.d0.loss_mask: 1.0428  decode.d0.loss_dice: 0.8343  decode.d1.loss_cls: 0.1807  decode.d1.loss_mask: 1.1042  decode.d1.loss_dice: 0.8722  decode.d2.loss_cls: 0.2294  decode.d2.loss_mask: 1.0936  decode.d2.loss_dice: 0.8525  decode.d3.loss_cls: 0.2120  decode.d3.loss_mask: 1.0745  decode.d3.loss_dice: 0.8257  decode.d4.loss_cls: 0.2446  decode.d4.loss_mask: 1.0554  decode.d4.loss_dice: 0.8043  decode.d5.loss_cls: 0.1811  decode.d5.loss_mask: 1.0696  decode.d5.loss_dice: 0.8341  decode.d6.loss_cls: 0.1583  decode.d6.loss_mask: 1.1059  decode.d6.loss_dice: 0.8641  decode.d7.loss_cls: 0.1755  decode.d7.loss_mask: 1.0940  decode.d7.loss_dice: 0.8791  decode.d8.loss_cls: 0.1711  decode.d8.loss_mask: 1.1033  decode.d8.loss_dice: 0.8304
05/26 21:03:44 - mmengine - INFO - Iter(train) [ 85650/160000]  base_lr: 5.0170e-05 lr: 5.0170e-06  eta: 8:30:48  time: 0.4104  data_time: 0.0096  memory: 5990  grad_norm: 730.6715  loss: 31.0916  decode.loss_cls: 0.3665  decode.loss_mask: 1.5607  decode.loss_dice: 1.1261  decode.d0.loss_cls: 0.9279  decode.d0.loss_mask: 1.4855  decode.d0.loss_dice: 1.0742  decode.d1.loss_cls: 0.4039  decode.d1.loss_mask: 1.5278  decode.d1.loss_dice: 1.1474  decode.d2.loss_cls: 0.3816  decode.d2.loss_mask: 1.5464  decode.d2.loss_dice: 1.0916  decode.d3.loss_cls: 0.4261  decode.d3.loss_mask: 1.5638  decode.d3.loss_dice: 1.1122  decode.d4.loss_cls: 0.4097  decode.d4.loss_mask: 1.5444  decode.d4.loss_dice: 1.1329  decode.d5.loss_cls: 0.3636  decode.d5.loss_mask: 1.5383  decode.d5.loss_dice: 1.0901  decode.d6.loss_cls: 0.3834  decode.d6.loss_mask: 1.5427  decode.d6.loss_dice: 1.1559  decode.d7.loss_cls: 0.4139  decode.d7.loss_mask: 1.5952  decode.d7.loss_dice: 1.1417  decode.d8.loss_cls: 0.3803  decode.d8.loss_mask: 1.5481  decode.d8.loss_dice: 1.1101
05/26 21:04:05 - mmengine - INFO - Iter(train) [ 85700/160000]  base_lr: 5.0140e-05 lr: 5.0140e-06  eta: 8:30:27  time: 0.4212  data_time: 0.0097  memory: 5969  grad_norm: 473.0636  loss: 21.1775  decode.loss_cls: 0.1863  decode.loss_mask: 1.1433  decode.loss_dice: 0.7408  decode.d0.loss_cls: 0.6578  decode.d0.loss_mask: 1.0239  decode.d0.loss_dice: 0.7205  decode.d1.loss_cls: 0.2086  decode.d1.loss_mask: 1.1425  decode.d1.loss_dice: 0.7193  decode.d2.loss_cls: 0.2540  decode.d2.loss_mask: 1.0904  decode.d2.loss_dice: 0.6961  decode.d3.loss_cls: 0.2374  decode.d3.loss_mask: 1.1446  decode.d3.loss_dice: 0.7198  decode.d4.loss_cls: 0.2632  decode.d4.loss_mask: 1.1365  decode.d4.loss_dice: 0.7086  decode.d5.loss_cls: 0.2149  decode.d5.loss_mask: 1.1714  decode.d5.loss_dice: 0.7230  decode.d6.loss_cls: 0.2019  decode.d6.loss_mask: 1.1924  decode.d6.loss_dice: 0.7331  decode.d7.loss_cls: 0.1982  decode.d7.loss_mask: 1.1622  decode.d7.loss_dice: 0.7196  decode.d8.loss_cls: 0.2064  decode.d8.loss_mask: 1.1395  decode.d8.loss_dice: 0.7217
05/26 21:04:26 - mmengine - INFO - Iter(train) [ 85750/160000]  base_lr: 5.0110e-05 lr: 5.0110e-06  eta: 8:30:07  time: 0.4113  data_time: 0.0096  memory: 5976  grad_norm: 502.1676  loss: 19.5414  decode.loss_cls: 0.2753  decode.loss_mask: 0.9158  decode.loss_dice: 0.7508  decode.d0.loss_cls: 0.7333  decode.d0.loss_mask: 0.9446  decode.d0.loss_dice: 0.7848  decode.d1.loss_cls: 0.2220  decode.d1.loss_mask: 0.9393  decode.d1.loss_dice: 0.7351  decode.d2.loss_cls: 0.2928  decode.d2.loss_mask: 0.9014  decode.d2.loss_dice: 0.7494  decode.d3.loss_cls: 0.2643  decode.d3.loss_mask: 0.8981  decode.d3.loss_dice: 0.7404  decode.d4.loss_cls: 0.3223  decode.d4.loss_mask: 0.8860  decode.d4.loss_dice: 0.7387  decode.d5.loss_cls: 0.1924  decode.d5.loss_mask: 0.9143  decode.d5.loss_dice: 0.7605  decode.d6.loss_cls: 0.2428  decode.d6.loss_mask: 0.8735  decode.d6.loss_dice: 0.7348  decode.d7.loss_cls: 0.2092  decode.d7.loss_mask: 0.8963  decode.d7.loss_dice: 0.7479  decode.d8.loss_cls: 0.2831  decode.d8.loss_mask: 0.8644  decode.d8.loss_dice: 0.7278
05/26 21:04:46 - mmengine - INFO - Iter(train) [ 85800/160000]  base_lr: 5.0079e-05 lr: 5.0079e-06  eta: 8:29:46  time: 0.4124  data_time: 0.0096  memory: 5995  grad_norm: 854.2015  loss: 21.4798  decode.loss_cls: 0.2717  decode.loss_mask: 1.0744  decode.loss_dice: 0.8328  decode.d0.loss_cls: 0.8484  decode.d0.loss_mask: 0.9708  decode.d0.loss_dice: 0.7357  decode.d1.loss_cls: 0.2635  decode.d1.loss_mask: 1.0735  decode.d1.loss_dice: 0.8327  decode.d2.loss_cls: 0.2706  decode.d2.loss_mask: 1.0275  decode.d2.loss_dice: 0.7952  decode.d3.loss_cls: 0.2348  decode.d3.loss_mask: 1.0277  decode.d3.loss_dice: 0.7664  decode.d4.loss_cls: 0.2509  decode.d4.loss_mask: 1.0710  decode.d4.loss_dice: 0.8065  decode.d5.loss_cls: 0.2752  decode.d5.loss_mask: 0.9983  decode.d5.loss_dice: 0.7756  decode.d6.loss_cls: 0.2525  decode.d6.loss_mask: 1.0840  decode.d6.loss_dice: 0.7906  decode.d7.loss_cls: 0.2605  decode.d7.loss_mask: 1.0062  decode.d7.loss_dice: 0.7806  decode.d8.loss_cls: 0.2753  decode.d8.loss_mask: 1.0180  decode.d8.loss_dice: 0.8090
05/26 21:05:07 - mmengine - INFO - Iter(train) [ 85850/160000]  base_lr: 5.0049e-05 lr: 5.0049e-06  eta: 8:29:25  time: 0.4124  data_time: 0.0097  memory: 5971  grad_norm: 896.4211  loss: 18.5784  decode.loss_cls: 0.1506  decode.loss_mask: 0.9948  decode.loss_dice: 0.6582  decode.d0.loss_cls: 0.6947  decode.d0.loss_mask: 0.9738  decode.d0.loss_dice: 0.6342  decode.d1.loss_cls: 0.1590  decode.d1.loss_mask: 0.9953  decode.d1.loss_dice: 0.6530  decode.d2.loss_cls: 0.1607  decode.d2.loss_mask: 0.9879  decode.d2.loss_dice: 0.6415  decode.d3.loss_cls: 0.1526  decode.d3.loss_mask: 0.9965  decode.d3.loss_dice: 0.6770  decode.d4.loss_cls: 0.1554  decode.d4.loss_mask: 0.9753  decode.d4.loss_dice: 0.6547  decode.d5.loss_cls: 0.1371  decode.d5.loss_mask: 1.0015  decode.d5.loss_dice: 0.6544  decode.d6.loss_cls: 0.1521  decode.d6.loss_mask: 1.0377  decode.d6.loss_dice: 0.6855  decode.d7.loss_cls: 0.1365  decode.d7.loss_mask: 0.9898  decode.d7.loss_dice: 0.6526  decode.d8.loss_cls: 0.1468  decode.d8.loss_mask: 1.0058  decode.d8.loss_dice: 0.6635
05/26 21:05:27 - mmengine - INFO - Iter(train) [ 85900/160000]  base_lr: 5.0019e-05 lr: 5.0019e-06  eta: 8:29:05  time: 0.4136  data_time: 0.0096  memory: 5970  grad_norm: 1508.4144  loss: 23.1865  decode.loss_cls: 0.1763  decode.loss_mask: 1.1906  decode.loss_dice: 0.8577  decode.d0.loss_cls: 0.7254  decode.d0.loss_mask: 1.1575  decode.d0.loss_dice: 0.8318  decode.d1.loss_cls: 0.1941  decode.d1.loss_mask: 1.2434  decode.d1.loss_dice: 0.8991  decode.d2.loss_cls: 0.2292  decode.d2.loss_mask: 1.2193  decode.d2.loss_dice: 0.9057  decode.d3.loss_cls: 0.1960  decode.d3.loss_mask: 1.2009  decode.d3.loss_dice: 0.8683  decode.d4.loss_cls: 0.2373  decode.d4.loss_mask: 1.1360  decode.d4.loss_dice: 0.8297  decode.d5.loss_cls: 0.1891  decode.d5.loss_mask: 1.2089  decode.d5.loss_dice: 0.8619  decode.d6.loss_cls: 0.1927  decode.d6.loss_mask: 1.2136  decode.d6.loss_dice: 0.8662  decode.d7.loss_cls: 0.1788  decode.d7.loss_mask: 1.2272  decode.d7.loss_dice: 0.8890  decode.d8.loss_cls: 0.1681  decode.d8.loss_mask: 1.2127  decode.d8.loss_dice: 0.8798
05/26 21:05:48 - mmengine - INFO - Iter(train) [ 85950/160000]  base_lr: 4.9988e-05 lr: 4.9988e-06  eta: 8:28:44  time: 0.4137  data_time: 0.0096  memory: 5967  grad_norm: 618.8808  loss: 21.5318  decode.loss_cls: 0.2220  decode.loss_mask: 1.0304  decode.loss_dice: 0.8330  decode.d0.loss_cls: 0.7906  decode.d0.loss_mask: 0.9932  decode.d0.loss_dice: 0.7464  decode.d1.loss_cls: 0.2453  decode.d1.loss_mask: 1.0355  decode.d1.loss_dice: 0.8149  decode.d2.loss_cls: 0.2792  decode.d2.loss_mask: 1.0290  decode.d2.loss_dice: 0.8217  decode.d3.loss_cls: 0.2638  decode.d3.loss_mask: 1.0116  decode.d3.loss_dice: 0.8174  decode.d4.loss_cls: 0.2630  decode.d4.loss_mask: 1.0150  decode.d4.loss_dice: 0.8119  decode.d5.loss_cls: 0.2454  decode.d5.loss_mask: 1.0304  decode.d5.loss_dice: 0.8568  decode.d6.loss_cls: 0.2448  decode.d6.loss_mask: 1.0439  decode.d6.loss_dice: 0.8393  decode.d7.loss_cls: 0.2531  decode.d7.loss_mask: 1.0292  decode.d7.loss_dice: 0.8436  decode.d8.loss_cls: 0.2245  decode.d8.loss_mask: 1.0351  decode.d8.loss_dice: 0.8620
05/26 21:06:09 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 21:06:09 - mmengine - INFO - Iter(train) [ 86000/160000]  base_lr: 4.9958e-05 lr: 4.9958e-06  eta: 8:28:24  time: 0.4130  data_time: 0.0096  memory: 5974  grad_norm: 521.5571  loss: 18.1733  decode.loss_cls: 0.0579  decode.loss_mask: 1.0559  decode.loss_dice: 0.6434  decode.d0.loss_cls: 0.5095  decode.d0.loss_mask: 1.0072  decode.d0.loss_dice: 0.6371  decode.d1.loss_cls: 0.0999  decode.d1.loss_mask: 1.0619  decode.d1.loss_dice: 0.6578  decode.d2.loss_cls: 0.0969  decode.d2.loss_mask: 1.0485  decode.d2.loss_dice: 0.6411  decode.d3.loss_cls: 0.0876  decode.d3.loss_mask: 1.0401  decode.d3.loss_dice: 0.6431  decode.d4.loss_cls: 0.1539  decode.d4.loss_mask: 1.0369  decode.d4.loss_dice: 0.6292  decode.d5.loss_cls: 0.0951  decode.d5.loss_mask: 1.0348  decode.d5.loss_dice: 0.6253  decode.d6.loss_cls: 0.0712  decode.d6.loss_mask: 1.0456  decode.d6.loss_dice: 0.6445  decode.d7.loss_cls: 0.0865  decode.d7.loss_mask: 1.0497  decode.d7.loss_dice: 0.6411  decode.d8.loss_cls: 0.0662  decode.d8.loss_mask: 1.0630  decode.d8.loss_dice: 0.6421
05/26 21:06:29 - mmengine - INFO - Iter(train) [ 86050/160000]  base_lr: 4.9927e-05 lr: 4.9927e-06  eta: 8:28:03  time: 0.4126  data_time: 0.0095  memory: 5986  grad_norm: 446.1613  loss: 18.8812  decode.loss_cls: 0.1515  decode.loss_mask: 0.9520  decode.loss_dice: 0.7458  decode.d0.loss_cls: 0.6801  decode.d0.loss_mask: 0.8894  decode.d0.loss_dice: 0.7203  decode.d1.loss_cls: 0.0871  decode.d1.loss_mask: 0.9667  decode.d1.loss_dice: 0.7709  decode.d2.loss_cls: 0.1115  decode.d2.loss_mask: 0.9417  decode.d2.loss_dice: 0.7474  decode.d3.loss_cls: 0.1136  decode.d3.loss_mask: 0.9613  decode.d3.loss_dice: 0.7552  decode.d4.loss_cls: 0.1203  decode.d4.loss_mask: 0.9502  decode.d4.loss_dice: 0.7385  decode.d5.loss_cls: 0.1609  decode.d5.loss_mask: 0.9531  decode.d5.loss_dice: 0.7220  decode.d6.loss_cls: 0.1888  decode.d6.loss_mask: 0.9612  decode.d6.loss_dice: 0.7276  decode.d7.loss_cls: 0.1739  decode.d7.loss_mask: 0.9571  decode.d7.loss_dice: 0.7573  decode.d8.loss_cls: 0.1444  decode.d8.loss_mask: 0.9639  decode.d8.loss_dice: 0.7676
05/26 21:06:50 - mmengine - INFO - Iter(train) [ 86100/160000]  base_lr: 4.9897e-05 lr: 4.9897e-06  eta: 8:27:42  time: 0.4128  data_time: 0.0096  memory: 5966  grad_norm: 626.4105  loss: 18.5096  decode.loss_cls: 0.2180  decode.loss_mask: 0.8928  decode.loss_dice: 0.6971  decode.d0.loss_cls: 0.6865  decode.d0.loss_mask: 0.8724  decode.d0.loss_dice: 0.7183  decode.d1.loss_cls: 0.2118  decode.d1.loss_mask: 0.8960  decode.d1.loss_dice: 0.6894  decode.d2.loss_cls: 0.2076  decode.d2.loss_mask: 0.8965  decode.d2.loss_dice: 0.7145  decode.d3.loss_cls: 0.1904  decode.d3.loss_mask: 0.8981  decode.d3.loss_dice: 0.7031  decode.d4.loss_cls: 0.2052  decode.d4.loss_mask: 0.9058  decode.d4.loss_dice: 0.6876  decode.d5.loss_cls: 0.1908  decode.d5.loss_mask: 0.8907  decode.d5.loss_dice: 0.6667  decode.d6.loss_cls: 0.2342  decode.d6.loss_mask: 0.9148  decode.d6.loss_dice: 0.6913  decode.d7.loss_cls: 0.2266  decode.d7.loss_mask: 0.9174  decode.d7.loss_dice: 0.6888  decode.d8.loss_cls: 0.1949  decode.d8.loss_mask: 0.9201  decode.d8.loss_dice: 0.6827
05/26 21:07:11 - mmengine - INFO - Iter(train) [ 86150/160000]  base_lr: 4.9867e-05 lr: 4.9867e-06  eta: 8:27:22  time: 0.4129  data_time: 0.0096  memory: 5976  grad_norm: 697.7299  loss: 19.9440  decode.loss_cls: 0.1171  decode.loss_mask: 1.1002  decode.loss_dice: 0.7046  decode.d0.loss_cls: 0.5143  decode.d0.loss_mask: 1.1096  decode.d0.loss_dice: 0.7409  decode.d1.loss_cls: 0.1403  decode.d1.loss_mask: 1.1014  decode.d1.loss_dice: 0.7433  decode.d2.loss_cls: 0.1087  decode.d2.loss_mask: 1.1024  decode.d2.loss_dice: 0.7393  decode.d3.loss_cls: 0.1368  decode.d3.loss_mask: 1.0958  decode.d3.loss_dice: 0.7345  decode.d4.loss_cls: 0.1159  decode.d4.loss_mask: 1.1165  decode.d4.loss_dice: 0.7173  decode.d5.loss_cls: 0.1337  decode.d5.loss_mask: 1.0992  decode.d5.loss_dice: 0.7296  decode.d6.loss_cls: 0.1428  decode.d6.loss_mask: 1.0980  decode.d6.loss_dice: 0.7277  decode.d7.loss_cls: 0.1186  decode.d7.loss_mask: 1.1005  decode.d7.loss_dice: 0.7230  decode.d8.loss_cls: 0.1153  decode.d8.loss_mask: 1.0979  decode.d8.loss_dice: 0.7187
05/26 21:07:31 - mmengine - INFO - Iter(train) [ 86200/160000]  base_lr: 4.9836e-05 lr: 4.9836e-06  eta: 8:27:01  time: 0.4129  data_time: 0.0096  memory: 5976  grad_norm: 824.6979  loss: 20.9470  decode.loss_cls: 0.1846  decode.loss_mask: 1.0865  decode.loss_dice: 0.7825  decode.d0.loss_cls: 0.5716  decode.d0.loss_mask: 1.1001  decode.d0.loss_dice: 0.7700  decode.d1.loss_cls: 0.1644  decode.d1.loss_mask: 1.1001  decode.d1.loss_dice: 0.7752  decode.d2.loss_cls: 0.1630  decode.d2.loss_mask: 1.0829  decode.d2.loss_dice: 0.8015  decode.d3.loss_cls: 0.1946  decode.d3.loss_mask: 1.0769  decode.d3.loss_dice: 0.7757  decode.d4.loss_cls: 0.1835  decode.d4.loss_mask: 1.1535  decode.d4.loss_dice: 0.7889  decode.d5.loss_cls: 0.1550  decode.d5.loss_mask: 1.1083  decode.d5.loss_dice: 0.7809  decode.d6.loss_cls: 0.1465  decode.d6.loss_mask: 1.0950  decode.d6.loss_dice: 0.8036  decode.d7.loss_cls: 0.1803  decode.d7.loss_mask: 1.1058  decode.d7.loss_dice: 0.7754  decode.d8.loss_cls: 0.1716  decode.d8.loss_mask: 1.0943  decode.d8.loss_dice: 0.7748
05/26 21:07:52 - mmengine - INFO - Iter(train) [ 86250/160000]  base_lr: 4.9806e-05 lr: 4.9806e-06  eta: 8:26:41  time: 0.4119  data_time: 0.0096  memory: 5968  grad_norm: 797.3241  loss: 24.6675  decode.loss_cls: 0.1574  decode.loss_mask: 1.3708  decode.loss_dice: 0.8862  decode.d0.loss_cls: 0.6074  decode.d0.loss_mask: 1.3023  decode.d0.loss_dice: 0.8493  decode.d1.loss_cls: 0.1329  decode.d1.loss_mask: 1.3697  decode.d1.loss_dice: 0.9243  decode.d2.loss_cls: 0.1393  decode.d2.loss_mask: 1.3519  decode.d2.loss_dice: 0.9424  decode.d3.loss_cls: 0.1559  decode.d3.loss_mask: 1.3381  decode.d3.loss_dice: 0.9452  decode.d4.loss_cls: 0.1860  decode.d4.loss_mask: 1.3038  decode.d4.loss_dice: 0.8935  decode.d5.loss_cls: 0.2172  decode.d5.loss_mask: 1.3146  decode.d5.loss_dice: 0.9194  decode.d6.loss_cls: 0.1643  decode.d6.loss_mask: 1.3588  decode.d6.loss_dice: 0.9274  decode.d7.loss_cls: 0.1435  decode.d7.loss_mask: 1.3744  decode.d7.loss_dice: 0.9119  decode.d8.loss_cls: 0.1590  decode.d8.loss_mask: 1.4003  decode.d8.loss_dice: 0.9203
05/26 21:08:13 - mmengine - INFO - Iter(train) [ 86300/160000]  base_lr: 4.9775e-05 lr: 4.9775e-06  eta: 8:26:20  time: 0.4119  data_time: 0.0097  memory: 5971  grad_norm: 676.5143  loss: 23.5047  decode.loss_cls: 0.2971  decode.loss_mask: 1.1128  decode.loss_dice: 0.8308  decode.d0.loss_cls: 0.8329  decode.d0.loss_mask: 1.0898  decode.d0.loss_dice: 0.8266  decode.d1.loss_cls: 0.3601  decode.d1.loss_mask: 1.0889  decode.d1.loss_dice: 0.8090  decode.d2.loss_cls: 0.3406  decode.d2.loss_mask: 1.1151  decode.d2.loss_dice: 0.8344  decode.d3.loss_cls: 0.3890  decode.d3.loss_mask: 1.0925  decode.d3.loss_dice: 0.8239  decode.d4.loss_cls: 0.4000  decode.d4.loss_mask: 1.0865  decode.d4.loss_dice: 0.8141  decode.d5.loss_cls: 0.3927  decode.d5.loss_mask: 1.0957  decode.d5.loss_dice: 0.8365  decode.d6.loss_cls: 0.4251  decode.d6.loss_mask: 1.0967  decode.d6.loss_dice: 0.8448  decode.d7.loss_cls: 0.3538  decode.d7.loss_mask: 1.2056  decode.d7.loss_dice: 0.8474  decode.d8.loss_cls: 0.3551  decode.d8.loss_mask: 1.0775  decode.d8.loss_dice: 0.8298
05/26 21:08:33 - mmengine - INFO - Iter(train) [ 86350/160000]  base_lr: 4.9745e-05 lr: 4.9745e-06  eta: 8:25:59  time: 0.4124  data_time: 0.0096  memory: 5971  grad_norm: 466.5373  loss: 20.0188  decode.loss_cls: 0.2151  decode.loss_mask: 1.0219  decode.loss_dice: 0.7138  decode.d0.loss_cls: 0.7364  decode.d0.loss_mask: 0.9675  decode.d0.loss_dice: 0.6349  decode.d1.loss_cls: 0.2478  decode.d1.loss_mask: 1.0082  decode.d1.loss_dice: 0.6891  decode.d2.loss_cls: 0.2378  decode.d2.loss_mask: 1.0293  decode.d2.loss_dice: 0.7320  decode.d3.loss_cls: 0.2531  decode.d3.loss_mask: 1.0255  decode.d3.loss_dice: 0.7028  decode.d4.loss_cls: 0.2258  decode.d4.loss_mask: 1.0474  decode.d4.loss_dice: 0.7013  decode.d5.loss_cls: 0.2011  decode.d5.loss_mask: 1.0352  decode.d5.loss_dice: 0.7022  decode.d6.loss_cls: 0.2993  decode.d6.loss_mask: 0.9609  decode.d6.loss_dice: 0.6748  decode.d7.loss_cls: 0.2119  decode.d7.loss_mask: 1.0461  decode.d7.loss_dice: 0.7224  decode.d8.loss_cls: 0.1883  decode.d8.loss_mask: 1.0651  decode.d8.loss_dice: 0.7219
05/26 21:08:54 - mmengine - INFO - Iter(train) [ 86400/160000]  base_lr: 4.9715e-05 lr: 4.9715e-06  eta: 8:25:39  time: 0.4118  data_time: 0.0096  memory: 5968  grad_norm: 522.5511  loss: 20.5967  decode.loss_cls: 0.2094  decode.loss_mask: 1.0477  decode.loss_dice: 0.7455  decode.d0.loss_cls: 0.7171  decode.d0.loss_mask: 0.9698  decode.d0.loss_dice: 0.7448  decode.d1.loss_cls: 0.3082  decode.d1.loss_mask: 1.0324  decode.d1.loss_dice: 0.7351  decode.d2.loss_cls: 0.2149  decode.d2.loss_mask: 1.0259  decode.d2.loss_dice: 0.7260  decode.d3.loss_cls: 0.2425  decode.d3.loss_mask: 1.0116  decode.d3.loss_dice: 0.7347  decode.d4.loss_cls: 0.2352  decode.d4.loss_mask: 1.0572  decode.d4.loss_dice: 0.7605  decode.d5.loss_cls: 0.2397  decode.d5.loss_mask: 1.0339  decode.d5.loss_dice: 0.7403  decode.d6.loss_cls: 0.2356  decode.d6.loss_mask: 1.0372  decode.d6.loss_dice: 0.7411  decode.d7.loss_cls: 0.2318  decode.d7.loss_mask: 1.0527  decode.d7.loss_dice: 0.7474  decode.d8.loss_cls: 0.2418  decode.d8.loss_mask: 1.0457  decode.d8.loss_dice: 0.7309
05/26 21:09:14 - mmengine - INFO - Iter(train) [ 86450/160000]  base_lr: 4.9684e-05 lr: 4.9684e-06  eta: 8:25:18  time: 0.4124  data_time: 0.0096  memory: 5969  grad_norm: 852.7796  loss: 22.5483  decode.loss_cls: 0.2892  decode.loss_mask: 1.0980  decode.loss_dice: 0.7806  decode.d0.loss_cls: 0.6718  decode.d0.loss_mask: 1.1134  decode.d0.loss_dice: 0.7904  decode.d1.loss_cls: 0.2776  decode.d1.loss_mask: 1.0984  decode.d1.loss_dice: 0.8098  decode.d2.loss_cls: 0.2812  decode.d2.loss_mask: 1.1585  decode.d2.loss_dice: 0.8263  decode.d3.loss_cls: 0.2939  decode.d3.loss_mask: 1.1527  decode.d3.loss_dice: 0.8124  decode.d4.loss_cls: 0.2925  decode.d4.loss_mask: 1.1607  decode.d4.loss_dice: 0.8216  decode.d5.loss_cls: 0.3001  decode.d5.loss_mask: 1.1331  decode.d5.loss_dice: 0.8156  decode.d6.loss_cls: 0.2737  decode.d6.loss_mask: 1.1504  decode.d6.loss_dice: 0.8144  decode.d7.loss_cls: 0.2664  decode.d7.loss_mask: 1.1114  decode.d7.loss_dice: 0.7983  decode.d8.loss_cls: 0.2819  decode.d8.loss_mask: 1.0940  decode.d8.loss_dice: 0.7801
05/26 21:09:35 - mmengine - INFO - Iter(train) [ 86500/160000]  base_lr: 4.9654e-05 lr: 4.9654e-06  eta: 8:24:58  time: 0.4118  data_time: 0.0095  memory: 5996  grad_norm: 515.5745  loss: 21.6300  decode.loss_cls: 0.1417  decode.loss_mask: 1.0890  decode.loss_dice: 0.8819  decode.d0.loss_cls: 0.7761  decode.d0.loss_mask: 1.0562  decode.d0.loss_dice: 0.8289  decode.d1.loss_cls: 0.2124  decode.d1.loss_mask: 1.0907  decode.d1.loss_dice: 0.8472  decode.d2.loss_cls: 0.1624  decode.d2.loss_mask: 1.0694  decode.d2.loss_dice: 0.8722  decode.d3.loss_cls: 0.1583  decode.d3.loss_mask: 1.0876  decode.d3.loss_dice: 0.8694  decode.d4.loss_cls: 0.1951  decode.d4.loss_mask: 1.0651  decode.d4.loss_dice: 0.8356  decode.d5.loss_cls: 0.1493  decode.d5.loss_mask: 1.0772  decode.d5.loss_dice: 0.8603  decode.d6.loss_cls: 0.1689  decode.d6.loss_mask: 1.0541  decode.d6.loss_dice: 0.8449  decode.d7.loss_cls: 0.1681  decode.d7.loss_mask: 1.0959  decode.d7.loss_dice: 0.8674  decode.d8.loss_cls: 0.1580  decode.d8.loss_mask: 1.0862  decode.d8.loss_dice: 0.8607
05/26 21:09:56 - mmengine - INFO - Iter(train) [ 86550/160000]  base_lr: 4.9623e-05 lr: 4.9623e-06  eta: 8:24:37  time: 0.4126  data_time: 0.0097  memory: 5967  grad_norm: 404.2439  loss: 17.6935  decode.loss_cls: 0.1230  decode.loss_mask: 0.8696  decode.loss_dice: 0.7091  decode.d0.loss_cls: 0.6423  decode.d0.loss_mask: 0.8410  decode.d0.loss_dice: 0.6709  decode.d1.loss_cls: 0.1446  decode.d1.loss_mask: 0.8709  decode.d1.loss_dice: 0.7186  decode.d2.loss_cls: 0.1543  decode.d2.loss_mask: 0.8718  decode.d2.loss_dice: 0.7195  decode.d3.loss_cls: 0.1341  decode.d3.loss_mask: 0.8721  decode.d3.loss_dice: 0.7031  decode.d4.loss_cls: 0.1455  decode.d4.loss_mask: 0.8749  decode.d4.loss_dice: 0.7197  decode.d5.loss_cls: 0.1391  decode.d5.loss_mask: 0.8810  decode.d5.loss_dice: 0.7234  decode.d6.loss_cls: 0.1300  decode.d6.loss_mask: 0.8835  decode.d6.loss_dice: 0.7136  decode.d7.loss_cls: 0.1391  decode.d7.loss_mask: 0.8773  decode.d7.loss_dice: 0.7084  decode.d8.loss_cls: 0.1364  decode.d8.loss_mask: 0.8686  decode.d8.loss_dice: 0.7081
05/26 21:10:16 - mmengine - INFO - Iter(train) [ 86600/160000]  base_lr: 4.9593e-05 lr: 4.9593e-06  eta: 8:24:16  time: 0.4116  data_time: 0.0095  memory: 5966  grad_norm: 642.3659  loss: 20.5022  decode.loss_cls: 0.1188  decode.loss_mask: 1.0992  decode.loss_dice: 0.7385  decode.d0.loss_cls: 0.6057  decode.d0.loss_mask: 1.1013  decode.d0.loss_dice: 0.7230  decode.d1.loss_cls: 0.1353  decode.d1.loss_mask: 1.1180  decode.d1.loss_dice: 0.7642  decode.d2.loss_cls: 0.1196  decode.d2.loss_mask: 1.1531  decode.d2.loss_dice: 0.7888  decode.d3.loss_cls: 0.1469  decode.d3.loss_mask: 1.1134  decode.d3.loss_dice: 0.7492  decode.d4.loss_cls: 0.1604  decode.d4.loss_mask: 1.0991  decode.d4.loss_dice: 0.7530  decode.d5.loss_cls: 0.1585  decode.d5.loss_mask: 1.1175  decode.d5.loss_dice: 0.7501  decode.d6.loss_cls: 0.1238  decode.d6.loss_mask: 1.1214  decode.d6.loss_dice: 0.7746  decode.d7.loss_cls: 0.1272  decode.d7.loss_mask: 1.1091  decode.d7.loss_dice: 0.7412  decode.d8.loss_cls: 0.1071  decode.d8.loss_mask: 1.1203  decode.d8.loss_dice: 0.7640
05/26 21:10:37 - mmengine - INFO - Iter(train) [ 86650/160000]  base_lr: 4.9563e-05 lr: 4.9563e-06  eta: 8:23:56  time: 0.4121  data_time: 0.0096  memory: 5974  grad_norm: 445.5185  loss: 18.8693  decode.loss_cls: 0.1718  decode.loss_mask: 1.0340  decode.loss_dice: 0.6748  decode.d0.loss_cls: 0.7511  decode.d0.loss_mask: 0.9291  decode.d0.loss_dice: 0.6015  decode.d1.loss_cls: 0.2803  decode.d1.loss_mask: 0.9437  decode.d1.loss_dice: 0.6280  decode.d2.loss_cls: 0.2708  decode.d2.loss_mask: 0.9411  decode.d2.loss_dice: 0.6171  decode.d3.loss_cls: 0.2669  decode.d3.loss_mask: 0.9393  decode.d3.loss_dice: 0.6142  decode.d4.loss_cls: 0.2615  decode.d4.loss_mask: 0.9676  decode.d4.loss_dice: 0.6062  decode.d5.loss_cls: 0.2472  decode.d5.loss_mask: 0.9676  decode.d5.loss_dice: 0.6278  decode.d6.loss_cls: 0.2384  decode.d6.loss_mask: 0.9766  decode.d6.loss_dice: 0.6507  decode.d7.loss_cls: 0.2173  decode.d7.loss_mask: 0.9656  decode.d7.loss_dice: 0.6527  decode.d8.loss_cls: 0.2170  decode.d8.loss_mask: 0.9654  decode.d8.loss_dice: 0.6441
05/26 21:10:58 - mmengine - INFO - Iter(train) [ 86700/160000]  base_lr: 4.9532e-05 lr: 4.9532e-06  eta: 8:23:35  time: 0.4115  data_time: 0.0096  memory: 5980  grad_norm: 548.1529  loss: 21.1714  decode.loss_cls: 0.1773  decode.loss_mask: 1.0775  decode.loss_dice: 0.7738  decode.d0.loss_cls: 0.6127  decode.d0.loss_mask: 1.0878  decode.d0.loss_dice: 0.7624  decode.d1.loss_cls: 0.1920  decode.d1.loss_mask: 1.1342  decode.d1.loss_dice: 0.7719  decode.d2.loss_cls: 0.2062  decode.d2.loss_mask: 1.0991  decode.d2.loss_dice: 0.7625  decode.d3.loss_cls: 0.2129  decode.d3.loss_mask: 1.1040  decode.d3.loss_dice: 0.7473  decode.d4.loss_cls: 0.2253  decode.d4.loss_mask: 1.0997  decode.d4.loss_dice: 0.7471  decode.d5.loss_cls: 0.1727  decode.d5.loss_mask: 1.1262  decode.d5.loss_dice: 0.7712  decode.d6.loss_cls: 0.1878  decode.d6.loss_mask: 1.1200  decode.d6.loss_dice: 0.7905  decode.d7.loss_cls: 0.1691  decode.d7.loss_mask: 1.1316  decode.d7.loss_dice: 0.8080  decode.d8.loss_cls: 0.1862  decode.d8.loss_mask: 1.1255  decode.d8.loss_dice: 0.7893
05/26 21:11:18 - mmengine - INFO - Iter(train) [ 86750/160000]  base_lr: 4.9502e-05 lr: 4.9502e-06  eta: 8:23:15  time: 0.4120  data_time: 0.0096  memory: 5969  grad_norm: 700.6842  loss: 17.3509  decode.loss_cls: 0.0868  decode.loss_mask: 0.9228  decode.loss_dice: 0.6492  decode.d0.loss_cls: 0.5957  decode.d0.loss_mask: 0.9109  decode.d0.loss_dice: 0.6238  decode.d1.loss_cls: 0.1374  decode.d1.loss_mask: 0.9364  decode.d1.loss_dice: 0.6514  decode.d2.loss_cls: 0.0881  decode.d2.loss_mask: 0.9325  decode.d2.loss_dice: 0.6579  decode.d3.loss_cls: 0.1077  decode.d3.loss_mask: 0.9424  decode.d3.loss_dice: 0.6404  decode.d4.loss_cls: 0.1184  decode.d4.loss_mask: 0.9513  decode.d4.loss_dice: 0.6420  decode.d5.loss_cls: 0.1224  decode.d5.loss_mask: 0.9350  decode.d5.loss_dice: 0.6459  decode.d6.loss_cls: 0.1412  decode.d6.loss_mask: 0.9005  decode.d6.loss_dice: 0.6385  decode.d7.loss_cls: 0.1502  decode.d7.loss_mask: 0.9051  decode.d7.loss_dice: 0.6330  decode.d8.loss_cls: 0.1240  decode.d8.loss_mask: 0.9200  decode.d8.loss_dice: 0.6399
05/26 21:11:39 - mmengine - INFO - Iter(train) [ 86800/160000]  base_lr: 4.9471e-05 lr: 4.9471e-06  eta: 8:22:54  time: 0.4120  data_time: 0.0095  memory: 5980  grad_norm: 573.8908  loss: 21.6862  decode.loss_cls: 0.2104  decode.loss_mask: 1.0642  decode.loss_dice: 0.8399  decode.d0.loss_cls: 0.7667  decode.d0.loss_mask: 1.0203  decode.d0.loss_dice: 0.7844  decode.d1.loss_cls: 0.2716  decode.d1.loss_mask: 1.0789  decode.d1.loss_dice: 0.8219  decode.d2.loss_cls: 0.2436  decode.d2.loss_mask: 1.0664  decode.d2.loss_dice: 0.7989  decode.d3.loss_cls: 0.2211  decode.d3.loss_mask: 1.0785  decode.d3.loss_dice: 0.8103  decode.d4.loss_cls: 0.2587  decode.d4.loss_mask: 1.0487  decode.d4.loss_dice: 0.7886  decode.d5.loss_cls: 0.2826  decode.d5.loss_mask: 1.0239  decode.d5.loss_dice: 0.7994  decode.d6.loss_cls: 0.2109  decode.d6.loss_mask: 1.0586  decode.d6.loss_dice: 0.8413  decode.d7.loss_cls: 0.2315  decode.d7.loss_mask: 1.0631  decode.d7.loss_dice: 0.8432  decode.d8.loss_cls: 0.2491  decode.d8.loss_mask: 1.0650  decode.d8.loss_dice: 0.8447
05/26 21:11:59 - mmengine - INFO - Iter(train) [ 86850/160000]  base_lr: 4.9441e-05 lr: 4.9441e-06  eta: 8:22:33  time: 0.4123  data_time: 0.0096  memory: 5967  grad_norm: 502.1005  loss: 18.6094  decode.loss_cls: 0.1274  decode.loss_mask: 0.9828  decode.loss_dice: 0.6607  decode.d0.loss_cls: 0.6359  decode.d0.loss_mask: 1.0219  decode.d0.loss_dice: 0.6839  decode.d1.loss_cls: 0.1675  decode.d1.loss_mask: 1.0221  decode.d1.loss_dice: 0.6924  decode.d2.loss_cls: 0.1402  decode.d2.loss_mask: 1.0379  decode.d2.loss_dice: 0.6885  decode.d3.loss_cls: 0.1481  decode.d3.loss_mask: 0.9783  decode.d3.loss_dice: 0.6578  decode.d4.loss_cls: 0.1619  decode.d4.loss_mask: 0.9913  decode.d4.loss_dice: 0.6691  decode.d5.loss_cls: 0.1694  decode.d5.loss_mask: 0.9478  decode.d5.loss_dice: 0.6524  decode.d6.loss_cls: 0.1322  decode.d6.loss_mask: 0.9829  decode.d6.loss_dice: 0.6692  decode.d7.loss_cls: 0.1374  decode.d7.loss_mask: 0.9990  decode.d7.loss_dice: 0.6716  decode.d8.loss_cls: 0.1494  decode.d8.loss_mask: 0.9638  decode.d8.loss_dice: 0.6667
05/26 21:12:20 - mmengine - INFO - Iter(train) [ 86900/160000]  base_lr: 4.9411e-05 lr: 4.9411e-06  eta: 8:22:13  time: 0.4117  data_time: 0.0097  memory: 5967  grad_norm: 469.1033  loss: 20.7678  decode.loss_cls: 0.2305  decode.loss_mask: 1.0107  decode.loss_dice: 0.7889  decode.d0.loss_cls: 0.7357  decode.d0.loss_mask: 0.9896  decode.d0.loss_dice: 0.7744  decode.d1.loss_cls: 0.2565  decode.d1.loss_mask: 1.0232  decode.d1.loss_dice: 0.7792  decode.d2.loss_cls: 0.2532  decode.d2.loss_mask: 1.0047  decode.d2.loss_dice: 0.7717  decode.d3.loss_cls: 0.2368  decode.d3.loss_mask: 1.0205  decode.d3.loss_dice: 0.7709  decode.d4.loss_cls: 0.2434  decode.d4.loss_mask: 1.0038  decode.d4.loss_dice: 0.7692  decode.d5.loss_cls: 0.2559  decode.d5.loss_mask: 0.9986  decode.d5.loss_dice: 0.7914  decode.d6.loss_cls: 0.2258  decode.d6.loss_mask: 1.0147  decode.d6.loss_dice: 0.7788  decode.d7.loss_cls: 0.2465  decode.d7.loss_mask: 0.9996  decode.d7.loss_dice: 0.7841  decode.d8.loss_cls: 0.2298  decode.d8.loss_mask: 0.9877  decode.d8.loss_dice: 0.7920
05/26 21:12:41 - mmengine - INFO - Iter(train) [ 86950/160000]  base_lr: 4.9380e-05 lr: 4.9380e-06  eta: 8:21:52  time: 0.4136  data_time: 0.0111  memory: 5980  grad_norm: 554.8705  loss: 17.9719  decode.loss_cls: 0.1119  decode.loss_mask: 1.0400  decode.loss_dice: 0.5985  decode.d0.loss_cls: 0.4925  decode.d0.loss_mask: 0.9958  decode.d0.loss_dice: 0.5988  decode.d1.loss_cls: 0.1199  decode.d1.loss_mask: 1.0367  decode.d1.loss_dice: 0.6030  decode.d2.loss_cls: 0.1450  decode.d2.loss_mask: 1.0142  decode.d2.loss_dice: 0.5966  decode.d3.loss_cls: 0.1189  decode.d3.loss_mask: 1.0418  decode.d3.loss_dice: 0.6224  decode.d4.loss_cls: 0.1210  decode.d4.loss_mask: 1.0281  decode.d4.loss_dice: 0.6045  decode.d5.loss_cls: 0.1114  decode.d5.loss_mask: 1.0513  decode.d5.loss_dice: 0.5984  decode.d6.loss_cls: 0.1298  decode.d6.loss_mask: 1.0533  decode.d6.loss_dice: 0.6140  decode.d7.loss_cls: 0.1272  decode.d7.loss_mask: 1.0326  decode.d7.loss_dice: 0.6026  decode.d8.loss_cls: 0.1127  decode.d8.loss_mask: 1.0487  decode.d8.loss_dice: 0.6004
05/26 21:13:01 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 21:13:01 - mmengine - INFO - Iter(train) [ 87000/160000]  base_lr: 4.9350e-05 lr: 4.9350e-06  eta: 8:21:32  time: 0.4120  data_time: 0.0097  memory: 5974  grad_norm: 500.7352  loss: 18.8490  decode.loss_cls: 0.1870  decode.loss_mask: 0.9046  decode.loss_dice: 0.7323  decode.d0.loss_cls: 0.5878  decode.d0.loss_mask: 0.9104  decode.d0.loss_dice: 0.7541  decode.d1.loss_cls: 0.1796  decode.d1.loss_mask: 0.9106  decode.d1.loss_dice: 0.7449  decode.d2.loss_cls: 0.2132  decode.d2.loss_mask: 0.9035  decode.d2.loss_dice: 0.7418  decode.d3.loss_cls: 0.2123  decode.d3.loss_mask: 0.9100  decode.d3.loss_dice: 0.7223  decode.d4.loss_cls: 0.2062  decode.d4.loss_mask: 0.9138  decode.d4.loss_dice: 0.7230  decode.d5.loss_cls: 0.2177  decode.d5.loss_mask: 0.9089  decode.d5.loss_dice: 0.7162  decode.d6.loss_cls: 0.2108  decode.d6.loss_mask: 0.9228  decode.d6.loss_dice: 0.7318  decode.d7.loss_cls: 0.2090  decode.d7.loss_mask: 0.9085  decode.d7.loss_dice: 0.7371  decode.d8.loss_cls: 0.1736  decode.d8.loss_mask: 0.9190  decode.d8.loss_dice: 0.7360
05/26 21:13:22 - mmengine - INFO - Iter(train) [ 87050/160000]  base_lr: 4.9319e-05 lr: 4.9319e-06  eta: 8:21:11  time: 0.4108  data_time: 0.0097  memory: 5967  grad_norm: 834.3643  loss: 23.1775  decode.loss_cls: 0.2069  decode.loss_mask: 1.1588  decode.loss_dice: 0.8605  decode.d0.loss_cls: 0.6923  decode.d0.loss_mask: 1.1888  decode.d0.loss_dice: 0.8863  decode.d1.loss_cls: 0.1870  decode.d1.loss_mask: 1.2625  decode.d1.loss_dice: 0.9094  decode.d2.loss_cls: 0.2229  decode.d2.loss_mask: 1.1748  decode.d2.loss_dice: 0.8558  decode.d3.loss_cls: 0.2057  decode.d3.loss_mask: 1.1954  decode.d3.loss_dice: 0.8694  decode.d4.loss_cls: 0.1993  decode.d4.loss_mask: 1.2312  decode.d4.loss_dice: 0.8820  decode.d5.loss_cls: 0.2272  decode.d5.loss_mask: 1.1761  decode.d5.loss_dice: 0.8820  decode.d6.loss_cls: 0.2061  decode.d6.loss_mask: 1.1830  decode.d6.loss_dice: 0.8635  decode.d7.loss_cls: 0.2121  decode.d7.loss_mask: 1.1657  decode.d7.loss_dice: 0.8586  decode.d8.loss_cls: 0.1856  decode.d8.loss_mask: 1.1760  decode.d8.loss_dice: 0.8526
05/26 21:13:43 - mmengine - INFO - Iter(train) [ 87100/160000]  base_lr: 4.9289e-05 lr: 4.9289e-06  eta: 8:20:50  time: 0.4113  data_time: 0.0095  memory: 5971  grad_norm: 517.2984  loss: 21.0856  decode.loss_cls: 0.2170  decode.loss_mask: 1.0196  decode.loss_dice: 0.8163  decode.d0.loss_cls: 0.6997  decode.d0.loss_mask: 1.0138  decode.d0.loss_dice: 0.8070  decode.d1.loss_cls: 0.2589  decode.d1.loss_mask: 1.0292  decode.d1.loss_dice: 0.7897  decode.d2.loss_cls: 0.2565  decode.d2.loss_mask: 1.0478  decode.d2.loss_dice: 0.7999  decode.d3.loss_cls: 0.2304  decode.d3.loss_mask: 1.0316  decode.d3.loss_dice: 0.7928  decode.d4.loss_cls: 0.2179  decode.d4.loss_mask: 1.0637  decode.d4.loss_dice: 0.8151  decode.d5.loss_cls: 0.2419  decode.d5.loss_mask: 1.0116  decode.d5.loss_dice: 0.7824  decode.d6.loss_cls: 0.2220  decode.d6.loss_mask: 1.0047  decode.d6.loss_dice: 0.7871  decode.d7.loss_cls: 0.2160  decode.d7.loss_mask: 1.0384  decode.d7.loss_dice: 0.8241  decode.d8.loss_cls: 0.2119  decode.d8.loss_mask: 1.0316  decode.d8.loss_dice: 0.8073
05/26 21:14:03 - mmengine - INFO - Iter(train) [ 87150/160000]  base_lr: 4.9258e-05 lr: 4.9258e-06  eta: 8:20:30  time: 0.4128  data_time: 0.0096  memory: 5967  grad_norm: 621.9029  loss: 21.0968  decode.loss_cls: 0.1931  decode.loss_mask: 1.0897  decode.loss_dice: 0.7481  decode.d0.loss_cls: 0.7736  decode.d0.loss_mask: 1.0373  decode.d0.loss_dice: 0.7076  decode.d1.loss_cls: 0.2361  decode.d1.loss_mask: 1.1046  decode.d1.loss_dice: 0.7262  decode.d2.loss_cls: 0.2375  decode.d2.loss_mask: 1.0977  decode.d2.loss_dice: 0.7506  decode.d3.loss_cls: 0.2431  decode.d3.loss_mask: 1.0723  decode.d3.loss_dice: 0.7949  decode.d4.loss_cls: 0.2237  decode.d4.loss_mask: 1.0778  decode.d4.loss_dice: 0.7635  decode.d5.loss_cls: 0.2170  decode.d5.loss_mask: 1.0925  decode.d5.loss_dice: 0.7813  decode.d6.loss_cls: 0.2006  decode.d6.loss_mask: 1.1151  decode.d6.loss_dice: 0.7893  decode.d7.loss_cls: 0.1912  decode.d7.loss_mask: 1.0621  decode.d7.loss_dice: 0.7648  decode.d8.loss_cls: 0.1941  decode.d8.loss_mask: 1.0513  decode.d8.loss_dice: 0.7601
05/26 21:14:24 - mmengine - INFO - Iter(train) [ 87200/160000]  base_lr: 4.9228e-05 lr: 4.9228e-06  eta: 8:20:09  time: 0.4125  data_time: 0.0097  memory: 5966  grad_norm: 561.3087  loss: 21.1247  decode.loss_cls: 0.2932  decode.loss_mask: 1.1137  decode.loss_dice: 0.7418  decode.d0.loss_cls: 0.8287  decode.d0.loss_mask: 0.9835  decode.d0.loss_dice: 0.7150  decode.d1.loss_cls: 0.2862  decode.d1.loss_mask: 1.0517  decode.d1.loss_dice: 0.7767  decode.d2.loss_cls: 0.3108  decode.d2.loss_mask: 1.0324  decode.d2.loss_dice: 0.7393  decode.d3.loss_cls: 0.3304  decode.d3.loss_mask: 1.0099  decode.d3.loss_dice: 0.7164  decode.d4.loss_cls: 0.3115  decode.d4.loss_mask: 1.0386  decode.d4.loss_dice: 0.7451  decode.d5.loss_cls: 0.2882  decode.d5.loss_mask: 1.0106  decode.d5.loss_dice: 0.7028  decode.d6.loss_cls: 0.2959  decode.d6.loss_mask: 1.0065  decode.d6.loss_dice: 0.7078  decode.d7.loss_cls: 0.2858  decode.d7.loss_mask: 1.0322  decode.d7.loss_dice: 0.7428  decode.d8.loss_cls: 0.2940  decode.d8.loss_mask: 1.0087  decode.d8.loss_dice: 0.7248
05/26 21:14:45 - mmengine - INFO - Iter(train) [ 87250/160000]  base_lr: 4.9198e-05 lr: 4.9198e-06  eta: 8:19:48  time: 0.4122  data_time: 0.0096  memory: 5966  grad_norm: 586.4267  loss: 23.1151  decode.loss_cls: 0.2666  decode.loss_mask: 1.0994  decode.loss_dice: 0.8321  decode.d0.loss_cls: 0.8013  decode.d0.loss_mask: 1.0761  decode.d0.loss_dice: 0.8141  decode.d1.loss_cls: 0.2397  decode.d1.loss_mask: 1.1320  decode.d1.loss_dice: 0.8795  decode.d2.loss_cls: 0.2670  decode.d2.loss_mask: 1.1376  decode.d2.loss_dice: 0.8652  decode.d3.loss_cls: 0.2475  decode.d3.loss_mask: 1.1401  decode.d3.loss_dice: 0.8713  decode.d4.loss_cls: 0.3342  decode.d4.loss_mask: 1.1383  decode.d4.loss_dice: 0.8719  decode.d5.loss_cls: 0.2861  decode.d5.loss_mask: 1.1415  decode.d5.loss_dice: 0.8684  decode.d6.loss_cls: 0.2485  decode.d6.loss_mask: 1.1681  decode.d6.loss_dice: 0.8951  decode.d7.loss_cls: 0.2730  decode.d7.loss_mask: 1.1259  decode.d7.loss_dice: 0.8442  decode.d8.loss_cls: 0.2788  decode.d8.loss_mask: 1.1193  decode.d8.loss_dice: 0.8522
05/26 21:15:05 - mmengine - INFO - Iter(train) [ 87300/160000]  base_lr: 4.9167e-05 lr: 4.9167e-06  eta: 8:19:28  time: 0.4115  data_time: 0.0097  memory: 5966  grad_norm: 479.3612  loss: 24.0050  decode.loss_cls: 0.4110  decode.loss_mask: 1.0285  decode.loss_dice: 0.9208  decode.d0.loss_cls: 0.8700  decode.d0.loss_mask: 1.0292  decode.d0.loss_dice: 0.8967  decode.d1.loss_cls: 0.3992  decode.d1.loss_mask: 1.0374  decode.d1.loss_dice: 0.9155  decode.d2.loss_cls: 0.3528  decode.d2.loss_mask: 1.0675  decode.d2.loss_dice: 0.9204  decode.d3.loss_cls: 0.3693  decode.d3.loss_mask: 1.1105  decode.d3.loss_dice: 0.9231  decode.d4.loss_cls: 0.3837  decode.d4.loss_mask: 1.0289  decode.d4.loss_dice: 0.9045  decode.d5.loss_cls: 0.4047  decode.d5.loss_mask: 1.0456  decode.d5.loss_dice: 0.8816  decode.d6.loss_cls: 0.3561  decode.d6.loss_mask: 1.0667  decode.d6.loss_dice: 0.9240  decode.d7.loss_cls: 0.3862  decode.d7.loss_mask: 1.0668  decode.d7.loss_dice: 0.9395  decode.d8.loss_cls: 0.4173  decode.d8.loss_mask: 1.0369  decode.d8.loss_dice: 0.9103
05/26 21:15:26 - mmengine - INFO - Iter(train) [ 87350/160000]  base_lr: 4.9137e-05 lr: 4.9137e-06  eta: 8:19:07  time: 0.4108  data_time: 0.0096  memory: 5970  grad_norm: 636.0711  loss: 22.0803  decode.loss_cls: 0.1812  decode.loss_mask: 1.1302  decode.loss_dice: 0.8177  decode.d0.loss_cls: 0.6834  decode.d0.loss_mask: 1.1508  decode.d0.loss_dice: 0.7685  decode.d1.loss_cls: 0.2444  decode.d1.loss_mask: 1.1161  decode.d1.loss_dice: 0.7912  decode.d2.loss_cls: 0.2299  decode.d2.loss_mask: 1.1117  decode.d2.loss_dice: 0.7961  decode.d3.loss_cls: 0.2374  decode.d3.loss_mask: 1.0981  decode.d3.loss_dice: 0.8018  decode.d4.loss_cls: 0.2528  decode.d4.loss_mask: 1.1308  decode.d4.loss_dice: 0.8019  decode.d5.loss_cls: 0.2238  decode.d5.loss_mask: 1.1467  decode.d5.loss_dice: 0.8088  decode.d6.loss_cls: 0.2110  decode.d6.loss_mask: 1.1301  decode.d6.loss_dice: 0.8047  decode.d7.loss_cls: 0.1974  decode.d7.loss_mask: 1.1916  decode.d7.loss_dice: 0.8634  decode.d8.loss_cls: 0.2263  decode.d8.loss_mask: 1.1304  decode.d8.loss_dice: 0.8019
05/26 21:15:46 - mmengine - INFO - Iter(train) [ 87400/160000]  base_lr: 4.9106e-05 lr: 4.9106e-06  eta: 8:18:47  time: 0.4117  data_time: 0.0096  memory: 5971  grad_norm: 713.5643  loss: 14.0525  decode.loss_cls: 0.0791  decode.loss_mask: 0.7630  decode.loss_dice: 0.5145  decode.d0.loss_cls: 0.5634  decode.d0.loss_mask: 0.7516  decode.d0.loss_dice: 0.5065  decode.d1.loss_cls: 0.0724  decode.d1.loss_mask: 0.7623  decode.d1.loss_dice: 0.5304  decode.d2.loss_cls: 0.0721  decode.d2.loss_mask: 0.7638  decode.d2.loss_dice: 0.5185  decode.d3.loss_cls: 0.0754  decode.d3.loss_mask: 0.7670  decode.d3.loss_dice: 0.5165  decode.d4.loss_cls: 0.1007  decode.d4.loss_mask: 0.7283  decode.d4.loss_dice: 0.5073  decode.d5.loss_cls: 0.0857  decode.d5.loss_mask: 0.7562  decode.d5.loss_dice: 0.5107  decode.d6.loss_cls: 0.0864  decode.d6.loss_mask: 0.7642  decode.d6.loss_dice: 0.5137  decode.d7.loss_cls: 0.0907  decode.d7.loss_mask: 0.7715  decode.d7.loss_dice: 0.5165  decode.d8.loss_cls: 0.0823  decode.d8.loss_mask: 0.7686  decode.d8.loss_dice: 0.5134
05/26 21:16:07 - mmengine - INFO - Iter(train) [ 87450/160000]  base_lr: 4.9076e-05 lr: 4.9076e-06  eta: 8:18:26  time: 0.4115  data_time: 0.0096  memory: 5973  grad_norm: 721.0988  loss: 21.0265  decode.loss_cls: 0.2284  decode.loss_mask: 1.0691  decode.loss_dice: 0.7680  decode.d0.loss_cls: 0.8122  decode.d0.loss_mask: 0.9851  decode.d0.loss_dice: 0.7016  decode.d1.loss_cls: 0.2426  decode.d1.loss_mask: 1.0473  decode.d1.loss_dice: 0.7892  decode.d2.loss_cls: 0.1943  decode.d2.loss_mask: 1.0732  decode.d2.loss_dice: 0.7743  decode.d3.loss_cls: 0.2652  decode.d3.loss_mask: 1.0077  decode.d3.loss_dice: 0.7533  decode.d4.loss_cls: 0.2359  decode.d4.loss_mask: 1.0698  decode.d4.loss_dice: 0.8006  decode.d5.loss_cls: 0.2665  decode.d5.loss_mask: 1.0302  decode.d5.loss_dice: 0.7360  decode.d6.loss_cls: 0.2699  decode.d6.loss_mask: 1.0314  decode.d6.loss_dice: 0.7485  decode.d7.loss_cls: 0.2696  decode.d7.loss_mask: 1.0516  decode.d7.loss_dice: 0.7540  decode.d8.loss_cls: 0.2658  decode.d8.loss_mask: 1.0225  decode.d8.loss_dice: 0.7628
05/26 21:16:28 - mmengine - INFO - Iter(train) [ 87500/160000]  base_lr: 4.9045e-05 lr: 4.9045e-06  eta: 8:18:05  time: 0.4120  data_time: 0.0097  memory: 5971  grad_norm: 1388.1893  loss: 23.2245  decode.loss_cls: 0.2816  decode.loss_mask: 1.1803  decode.loss_dice: 0.8412  decode.d0.loss_cls: 0.6274  decode.d0.loss_mask: 1.1493  decode.d0.loss_dice: 0.8370  decode.d1.loss_cls: 0.2954  decode.d1.loss_mask: 1.1639  decode.d1.loss_dice: 0.8433  decode.d2.loss_cls: 0.3119  decode.d2.loss_mask: 1.1511  decode.d2.loss_dice: 0.8090  decode.d3.loss_cls: 0.2850  decode.d3.loss_mask: 1.1571  decode.d3.loss_dice: 0.8096  decode.d4.loss_cls: 0.3069  decode.d4.loss_mask: 1.1441  decode.d4.loss_dice: 0.8222  decode.d5.loss_cls: 0.2678  decode.d5.loss_mask: 1.1792  decode.d5.loss_dice: 0.8091  decode.d6.loss_cls: 0.3066  decode.d6.loss_mask: 1.1856  decode.d6.loss_dice: 0.8397  decode.d7.loss_cls: 0.2821  decode.d7.loss_mask: 1.1851  decode.d7.loss_dice: 0.8462  decode.d8.loss_cls: 0.2697  decode.d8.loss_mask: 1.1843  decode.d8.loss_dice: 0.8528
05/26 21:16:48 - mmengine - INFO - Iter(train) [ 87550/160000]  base_lr: 4.9015e-05 lr: 4.9015e-06  eta: 8:17:45  time: 0.4127  data_time: 0.0096  memory: 5970  grad_norm: 475.4515  loss: 22.8337  decode.loss_cls: 0.2978  decode.loss_mask: 1.0671  decode.loss_dice: 0.8564  decode.d0.loss_cls: 0.7441  decode.d0.loss_mask: 1.0692  decode.d0.loss_dice: 0.8107  decode.d1.loss_cls: 0.3243  decode.d1.loss_mask: 1.0964  decode.d1.loss_dice: 0.8502  decode.d2.loss_cls: 0.3267  decode.d2.loss_mask: 1.0765  decode.d2.loss_dice: 0.8130  decode.d3.loss_cls: 0.3403  decode.d3.loss_mask: 1.0843  decode.d3.loss_dice: 0.8419  decode.d4.loss_cls: 0.2922  decode.d4.loss_mask: 1.0806  decode.d4.loss_dice: 0.8234  decode.d5.loss_cls: 0.3205  decode.d5.loss_mask: 1.0969  decode.d5.loss_dice: 0.8387  decode.d6.loss_cls: 0.3294  decode.d6.loss_mask: 1.0839  decode.d6.loss_dice: 0.8484  decode.d7.loss_cls: 0.3058  decode.d7.loss_mask: 1.0880  decode.d7.loss_dice: 0.8580  decode.d8.loss_cls: 0.3008  decode.d8.loss_mask: 1.1309  decode.d8.loss_dice: 0.8374
05/26 21:17:09 - mmengine - INFO - Iter(train) [ 87600/160000]  base_lr: 4.8985e-05 lr: 4.8985e-06  eta: 8:17:24  time: 0.4108  data_time: 0.0096  memory: 5969  grad_norm: 461.4305  loss: 21.4961  decode.loss_cls: 0.3758  decode.loss_mask: 0.9370  decode.loss_dice: 0.7500  decode.d0.loss_cls: 0.7973  decode.d0.loss_mask: 0.9395  decode.d0.loss_dice: 0.7958  decode.d1.loss_cls: 0.3237  decode.d1.loss_mask: 0.9559  decode.d1.loss_dice: 0.7712  decode.d2.loss_cls: 0.3162  decode.d2.loss_mask: 0.9917  decode.d2.loss_dice: 0.7757  decode.d3.loss_cls: 0.3025  decode.d3.loss_mask: 1.0004  decode.d3.loss_dice: 0.8019  decode.d4.loss_cls: 0.3695  decode.d4.loss_mask: 1.0034  decode.d4.loss_dice: 0.7840  decode.d5.loss_cls: 0.3047  decode.d5.loss_mask: 1.0049  decode.d5.loss_dice: 0.8040  decode.d6.loss_cls: 0.3208  decode.d6.loss_mask: 1.0082  decode.d6.loss_dice: 0.7878  decode.d7.loss_cls: 0.3056  decode.d7.loss_mask: 1.0305  decode.d7.loss_dice: 0.8060  decode.d8.loss_cls: 0.2977  decode.d8.loss_mask: 1.0440  decode.d8.loss_dice: 0.7903
05/26 21:17:29 - mmengine - INFO - Iter(train) [ 87650/160000]  base_lr: 4.8954e-05 lr: 4.8954e-06  eta: 8:17:03  time: 0.4120  data_time: 0.0096  memory: 5971  grad_norm: 387.0053  loss: 16.5420  decode.loss_cls: 0.0894  decode.loss_mask: 0.8906  decode.loss_dice: 0.6485  decode.d0.loss_cls: 0.5406  decode.d0.loss_mask: 0.8996  decode.d0.loss_dice: 0.6289  decode.d1.loss_cls: 0.0698  decode.d1.loss_mask: 0.8930  decode.d1.loss_dice: 0.6507  decode.d2.loss_cls: 0.0714  decode.d2.loss_mask: 0.8844  decode.d2.loss_dice: 0.6214  decode.d3.loss_cls: 0.0756  decode.d3.loss_mask: 0.8875  decode.d3.loss_dice: 0.6381  decode.d4.loss_cls: 0.1108  decode.d4.loss_mask: 0.8981  decode.d4.loss_dice: 0.6438  decode.d5.loss_cls: 0.0896  decode.d5.loss_mask: 0.8754  decode.d5.loss_dice: 0.6271  decode.d6.loss_cls: 0.1006  decode.d6.loss_mask: 0.8711  decode.d6.loss_dice: 0.6322  decode.d7.loss_cls: 0.0804  decode.d7.loss_mask: 0.8825  decode.d7.loss_dice: 0.6417  decode.d8.loss_cls: 0.0944  decode.d8.loss_mask: 0.8738  decode.d8.loss_dice: 0.6311
05/26 21:17:50 - mmengine - INFO - Iter(train) [ 87700/160000]  base_lr: 4.8924e-05 lr: 4.8924e-06  eta: 8:16:43  time: 0.4115  data_time: 0.0096  memory: 5974  grad_norm: 403.7025  loss: 21.3516  decode.loss_cls: 0.2112  decode.loss_mask: 1.1051  decode.loss_dice: 0.7534  decode.d0.loss_cls: 0.6507  decode.d0.loss_mask: 1.1093  decode.d0.loss_dice: 0.6983  decode.d1.loss_cls: 0.1889  decode.d1.loss_mask: 1.1651  decode.d1.loss_dice: 0.7449  decode.d2.loss_cls: 0.2006  decode.d2.loss_mask: 1.1588  decode.d2.loss_dice: 0.7562  decode.d3.loss_cls: 0.2167  decode.d3.loss_mask: 1.1714  decode.d3.loss_dice: 0.7677  decode.d4.loss_cls: 0.1974  decode.d4.loss_mask: 1.1390  decode.d4.loss_dice: 0.7588  decode.d5.loss_cls: 0.2017  decode.d5.loss_mask: 1.1072  decode.d5.loss_dice: 0.7291  decode.d6.loss_cls: 0.2470  decode.d6.loss_mask: 1.1090  decode.d6.loss_dice: 0.7418  decode.d7.loss_cls: 0.2111  decode.d7.loss_mask: 1.1192  decode.d7.loss_dice: 0.7592  decode.d8.loss_cls: 0.2077  decode.d8.loss_mask: 1.1644  decode.d8.loss_dice: 0.7605
05/26 21:18:10 - mmengine - INFO - Iter(train) [ 87750/160000]  base_lr: 4.8893e-05 lr: 4.8893e-06  eta: 8:16:22  time: 0.4121  data_time: 0.0097  memory: 5965  grad_norm: 1408.5097  loss: 24.4092  decode.loss_cls: 0.2415  decode.loss_mask: 1.1993  decode.loss_dice: 0.9572  decode.d0.loss_cls: 0.7437  decode.d0.loss_mask: 1.2128  decode.d0.loss_dice: 0.9124  decode.d1.loss_cls: 0.2663  decode.d1.loss_mask: 1.1719  decode.d1.loss_dice: 0.9027  decode.d2.loss_cls: 0.2197  decode.d2.loss_mask: 1.2117  decode.d2.loss_dice: 0.9440  decode.d3.loss_cls: 0.2372  decode.d3.loss_mask: 1.2198  decode.d3.loss_dice: 0.9343  decode.d4.loss_cls: 0.2746  decode.d4.loss_mask: 1.1993  decode.d4.loss_dice: 0.9348  decode.d5.loss_cls: 0.2235  decode.d5.loss_mask: 1.2317  decode.d5.loss_dice: 0.9467  decode.d6.loss_cls: 0.2145  decode.d6.loss_mask: 1.2858  decode.d6.loss_dice: 0.9557  decode.d7.loss_cls: 0.2425  decode.d7.loss_mask: 1.1995  decode.d7.loss_dice: 0.9630  decode.d8.loss_cls: 0.2433  decode.d8.loss_mask: 1.1875  decode.d8.loss_dice: 0.9324
05/26 21:18:31 - mmengine - INFO - Iter(train) [ 87800/160000]  base_lr: 4.8863e-05 lr: 4.8863e-06  eta: 8:16:02  time: 0.4230  data_time: 0.0096  memory: 5966  grad_norm: 536.4160  loss: 18.8279  decode.loss_cls: 0.1523  decode.loss_mask: 1.0186  decode.loss_dice: 0.6565  decode.d0.loss_cls: 0.7669  decode.d0.loss_mask: 0.8989  decode.d0.loss_dice: 0.6152  decode.d1.loss_cls: 0.1543  decode.d1.loss_mask: 0.9945  decode.d1.loss_dice: 0.6752  decode.d2.loss_cls: 0.1775  decode.d2.loss_mask: 0.9978  decode.d2.loss_dice: 0.6571  decode.d3.loss_cls: 0.1883  decode.d3.loss_mask: 0.9924  decode.d3.loss_dice: 0.6578  decode.d4.loss_cls: 0.1750  decode.d4.loss_mask: 1.0296  decode.d4.loss_dice: 0.6865  decode.d5.loss_cls: 0.1823  decode.d5.loss_mask: 0.9915  decode.d5.loss_dice: 0.6586  decode.d6.loss_cls: 0.2106  decode.d6.loss_mask: 0.9687  decode.d6.loss_dice: 0.6351  decode.d7.loss_cls: 0.2233  decode.d7.loss_mask: 0.9928  decode.d7.loss_dice: 0.6493  decode.d8.loss_cls: 0.1746  decode.d8.loss_mask: 0.9919  decode.d8.loss_dice: 0.6549
05/26 21:18:52 - mmengine - INFO - Iter(train) [ 87850/160000]  base_lr: 4.8832e-05 lr: 4.8832e-06  eta: 8:15:41  time: 0.4116  data_time: 0.0095  memory: 5976  grad_norm: 474.4516  loss: 26.4590  decode.loss_cls: 0.2416  decode.loss_mask: 1.2465  decode.loss_dice: 1.0502  decode.d0.loss_cls: 0.7738  decode.d0.loss_mask: 1.1889  decode.d0.loss_dice: 1.0802  decode.d1.loss_cls: 0.2890  decode.d1.loss_mask: 1.2653  decode.d1.loss_dice: 1.0717  decode.d2.loss_cls: 0.2554  decode.d2.loss_mask: 1.2782  decode.d2.loss_dice: 1.0501  decode.d3.loss_cls: 0.2852  decode.d3.loss_mask: 1.2564  decode.d3.loss_dice: 1.0389  decode.d4.loss_cls: 0.2227  decode.d4.loss_mask: 1.2692  decode.d4.loss_dice: 1.1135  decode.d5.loss_cls: 0.2739  decode.d5.loss_mask: 1.2664  decode.d5.loss_dice: 1.0786  decode.d6.loss_cls: 0.2366  decode.d6.loss_mask: 1.2941  decode.d6.loss_dice: 1.1133  decode.d7.loss_cls: 0.2064  decode.d7.loss_mask: 1.2805  decode.d7.loss_dice: 1.1016  decode.d8.loss_cls: 0.2353  decode.d8.loss_mask: 1.3030  decode.d8.loss_dice: 1.0924
05/26 21:19:12 - mmengine - INFO - Iter(train) [ 87900/160000]  base_lr: 4.8802e-05 lr: 4.8802e-06  eta: 8:15:20  time: 0.4139  data_time: 0.0096  memory: 5979  grad_norm: 381.9924  loss: 19.9143  decode.loss_cls: 0.2367  decode.loss_mask: 0.8703  decode.loss_dice: 0.8091  decode.d0.loss_cls: 0.7885  decode.d0.loss_mask: 0.8260  decode.d0.loss_dice: 0.7759  decode.d1.loss_cls: 0.3137  decode.d1.loss_mask: 0.8563  decode.d1.loss_dice: 0.7971  decode.d2.loss_cls: 0.2802  decode.d2.loss_mask: 0.8505  decode.d2.loss_dice: 0.8028  decode.d3.loss_cls: 0.3540  decode.d3.loss_mask: 0.8609  decode.d3.loss_dice: 0.7945  decode.d4.loss_cls: 0.3331  decode.d4.loss_mask: 0.8482  decode.d4.loss_dice: 0.7877  decode.d5.loss_cls: 0.2964  decode.d5.loss_mask: 0.8529  decode.d5.loss_dice: 0.7852  decode.d6.loss_cls: 0.2950  decode.d6.loss_mask: 0.8400  decode.d6.loss_dice: 0.7924  decode.d7.loss_cls: 0.2712  decode.d7.loss_mask: 0.8656  decode.d7.loss_dice: 0.7858  decode.d8.loss_cls: 0.2730  decode.d8.loss_mask: 0.8865  decode.d8.loss_dice: 0.7847
05/26 21:19:33 - mmengine - INFO - Iter(train) [ 87950/160000]  base_lr: 4.8771e-05 lr: 4.8771e-06  eta: 8:15:00  time: 0.4125  data_time: 0.0098  memory: 5968  grad_norm: 381.5030  loss: 17.2899  decode.loss_cls: 0.2024  decode.loss_mask: 0.7928  decode.loss_dice: 0.6625  decode.d0.loss_cls: 0.7314  decode.d0.loss_mask: 0.7654  decode.d0.loss_dice: 0.6371  decode.d1.loss_cls: 0.2011  decode.d1.loss_mask: 0.8162  decode.d1.loss_dice: 0.7023  decode.d2.loss_cls: 0.2080  decode.d2.loss_mask: 0.8039  decode.d2.loss_dice: 0.6666  decode.d3.loss_cls: 0.1885  decode.d3.loss_mask: 0.8307  decode.d3.loss_dice: 0.6812  decode.d4.loss_cls: 0.2316  decode.d4.loss_mask: 0.8116  decode.d4.loss_dice: 0.6673  decode.d5.loss_cls: 0.2288  decode.d5.loss_mask: 0.7984  decode.d5.loss_dice: 0.6479  decode.d6.loss_cls: 0.2272  decode.d6.loss_mask: 0.8015  decode.d6.loss_dice: 0.6814  decode.d7.loss_cls: 0.1646  decode.d7.loss_mask: 0.8067  decode.d7.loss_dice: 0.6822  decode.d8.loss_cls: 0.1625  decode.d8.loss_mask: 0.8126  decode.d8.loss_dice: 0.6756
05/26 21:19:54 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 21:19:54 - mmengine - INFO - Iter(train) [ 88000/160000]  base_lr: 4.8741e-05 lr: 4.8741e-06  eta: 8:14:39  time: 0.4112  data_time: 0.0096  memory: 5968  grad_norm: 680.9056  loss: 23.0024  decode.loss_cls: 0.2140  decode.loss_mask: 1.2534  decode.loss_dice: 0.8167  decode.d0.loss_cls: 0.7144  decode.d0.loss_mask: 1.2237  decode.d0.loss_dice: 0.7856  decode.d1.loss_cls: 0.1739  decode.d1.loss_mask: 1.2777  decode.d1.loss_dice: 0.8301  decode.d2.loss_cls: 0.1798  decode.d2.loss_mask: 1.2187  decode.d2.loss_dice: 0.8283  decode.d3.loss_cls: 0.2040  decode.d3.loss_mask: 1.1623  decode.d3.loss_dice: 0.7900  decode.d4.loss_cls: 0.1897  decode.d4.loss_mask: 1.2507  decode.d4.loss_dice: 0.8295  decode.d5.loss_cls: 0.1865  decode.d5.loss_mask: 1.2175  decode.d5.loss_dice: 0.8473  decode.d6.loss_cls: 0.1856  decode.d6.loss_mask: 1.2580  decode.d6.loss_dice: 0.8435  decode.d7.loss_cls: 0.1843  decode.d7.loss_mask: 1.2516  decode.d7.loss_dice: 0.8338  decode.d8.loss_cls: 0.2462  decode.d8.loss_mask: 1.2053  decode.d8.loss_dice: 0.8003
05/26 21:20:14 - mmengine - INFO - Iter(train) [ 88050/160000]  base_lr: 4.8710e-05 lr: 4.8710e-06  eta: 8:14:19  time: 0.4116  data_time: 0.0097  memory: 5974  grad_norm: 496.2484  loss: 19.3325  decode.loss_cls: 0.1403  decode.loss_mask: 1.0577  decode.loss_dice: 0.6979  decode.d0.loss_cls: 0.6422  decode.d0.loss_mask: 0.9930  decode.d0.loss_dice: 0.6671  decode.d1.loss_cls: 0.1397  decode.d1.loss_mask: 1.0840  decode.d1.loss_dice: 0.6920  decode.d2.loss_cls: 0.1738  decode.d2.loss_mask: 1.0472  decode.d2.loss_dice: 0.6909  decode.d3.loss_cls: 0.1477  decode.d3.loss_mask: 1.0557  decode.d3.loss_dice: 0.6980  decode.d4.loss_cls: 0.1451  decode.d4.loss_mask: 1.0512  decode.d4.loss_dice: 0.6940  decode.d5.loss_cls: 0.1416  decode.d5.loss_mask: 1.0433  decode.d5.loss_dice: 0.6919  decode.d6.loss_cls: 0.1423  decode.d6.loss_mask: 1.0570  decode.d6.loss_dice: 0.6853  decode.d7.loss_cls: 0.1368  decode.d7.loss_mask: 1.0565  decode.d7.loss_dice: 0.6895  decode.d8.loss_cls: 0.1423  decode.d8.loss_mask: 1.0495  decode.d8.loss_dice: 0.6791
05/26 21:20:35 - mmengine - INFO - Iter(train) [ 88100/160000]  base_lr: 4.8680e-05 lr: 4.8680e-06  eta: 8:13:58  time: 0.4115  data_time: 0.0096  memory: 5980  grad_norm: 635.3786  loss: 24.2831  decode.loss_cls: 0.3455  decode.loss_mask: 1.2034  decode.loss_dice: 0.8764  decode.d0.loss_cls: 0.8452  decode.d0.loss_mask: 1.1192  decode.d0.loss_dice: 0.8281  decode.d1.loss_cls: 0.3456  decode.d1.loss_mask: 1.1936  decode.d1.loss_dice: 0.9114  decode.d2.loss_cls: 0.2974  decode.d2.loss_mask: 1.1876  decode.d2.loss_dice: 0.8724  decode.d3.loss_cls: 0.2865  decode.d3.loss_mask: 1.1463  decode.d3.loss_dice: 0.8528  decode.d4.loss_cls: 0.3425  decode.d4.loss_mask: 1.1402  decode.d4.loss_dice: 0.8654  decode.d5.loss_cls: 0.3370  decode.d5.loss_mask: 1.1901  decode.d5.loss_dice: 0.8871  decode.d6.loss_cls: 0.3667  decode.d6.loss_mask: 1.1921  decode.d6.loss_dice: 0.8825  decode.d7.loss_cls: 0.3249  decode.d7.loss_mask: 1.1637  decode.d7.loss_dice: 0.8862  decode.d8.loss_cls: 0.3356  decode.d8.loss_mask: 1.1700  decode.d8.loss_dice: 0.8880
05/26 21:20:56 - mmengine - INFO - Iter(train) [ 88150/160000]  base_lr: 4.8650e-05 lr: 4.8650e-06  eta: 8:13:37  time: 0.4115  data_time: 0.0096  memory: 5972  grad_norm: 1036.5101  loss: 23.4458  decode.loss_cls: 0.3462  decode.loss_mask: 1.0806  decode.loss_dice: 0.8380  decode.d0.loss_cls: 0.7579  decode.d0.loss_mask: 1.0154  decode.d0.loss_dice: 0.8116  decode.d1.loss_cls: 0.3313  decode.d1.loss_mask: 1.0915  decode.d1.loss_dice: 0.8569  decode.d2.loss_cls: 0.3587  decode.d2.loss_mask: 1.1013  decode.d2.loss_dice: 0.8814  decode.d3.loss_cls: 0.3428  decode.d3.loss_mask: 1.0987  decode.d3.loss_dice: 0.9022  decode.d4.loss_cls: 0.3104  decode.d4.loss_mask: 1.0893  decode.d4.loss_dice: 0.8791  decode.d5.loss_cls: 0.3519  decode.d5.loss_mask: 1.1163  decode.d5.loss_dice: 0.9312  decode.d6.loss_cls: 0.3683  decode.d6.loss_mask: 1.1026  decode.d6.loss_dice: 0.8719  decode.d7.loss_cls: 0.3168  decode.d7.loss_mask: 1.1061  decode.d7.loss_dice: 0.9029  decode.d8.loss_cls: 0.3071  decode.d8.loss_mask: 1.0904  decode.d8.loss_dice: 0.8870
05/26 21:21:16 - mmengine - INFO - Iter(train) [ 88200/160000]  base_lr: 4.8619e-05 lr: 4.8619e-06  eta: 8:13:17  time: 0.4127  data_time: 0.0098  memory: 5970  grad_norm: 345.2198  loss: 16.8275  decode.loss_cls: 0.2355  decode.loss_mask: 0.7714  decode.loss_dice: 0.6044  decode.d0.loss_cls: 0.7360  decode.d0.loss_mask: 0.7374  decode.d0.loss_dice: 0.6178  decode.d1.loss_cls: 0.2295  decode.d1.loss_mask: 0.7646  decode.d1.loss_dice: 0.6199  decode.d2.loss_cls: 0.2550  decode.d2.loss_mask: 0.7756  decode.d2.loss_dice: 0.5936  decode.d3.loss_cls: 0.2732  decode.d3.loss_mask: 0.7713  decode.d3.loss_dice: 0.5920  decode.d4.loss_cls: 0.2438  decode.d4.loss_mask: 0.7720  decode.d4.loss_dice: 0.6202  decode.d5.loss_cls: 0.2374  decode.d5.loss_mask: 0.7730  decode.d5.loss_dice: 0.6210  decode.d6.loss_cls: 0.2751  decode.d6.loss_mask: 0.7986  decode.d6.loss_dice: 0.6038  decode.d7.loss_cls: 0.2999  decode.d7.loss_mask: 0.7647  decode.d7.loss_dice: 0.6106  decode.d8.loss_cls: 0.3032  decode.d8.loss_mask: 0.7528  decode.d8.loss_dice: 0.5742
05/26 21:21:37 - mmengine - INFO - Iter(train) [ 88250/160000]  base_lr: 4.8589e-05 lr: 4.8589e-06  eta: 8:12:56  time: 0.4125  data_time: 0.0096  memory: 5968  grad_norm: 617.1965  loss: 22.9576  decode.loss_cls: 0.3187  decode.loss_mask: 1.1196  decode.loss_dice: 0.7869  decode.d0.loss_cls: 0.7903  decode.d0.loss_mask: 1.0794  decode.d0.loss_dice: 0.7817  decode.d1.loss_cls: 0.3633  decode.d1.loss_mask: 1.1203  decode.d1.loss_dice: 0.7824  decode.d2.loss_cls: 0.3407  decode.d2.loss_mask: 1.1024  decode.d2.loss_dice: 0.7622  decode.d3.loss_cls: 0.3384  decode.d3.loss_mask: 1.1511  decode.d3.loss_dice: 0.7838  decode.d4.loss_cls: 0.2972  decode.d4.loss_mask: 1.1892  decode.d4.loss_dice: 0.7849  decode.d5.loss_cls: 0.3104  decode.d5.loss_mask: 1.1920  decode.d5.loss_dice: 0.7850  decode.d6.loss_cls: 0.3272  decode.d6.loss_mask: 1.1522  decode.d6.loss_dice: 0.7958  decode.d7.loss_cls: 0.3086  decode.d7.loss_mask: 1.1796  decode.d7.loss_dice: 0.7917  decode.d8.loss_cls: 0.2978  decode.d8.loss_mask: 1.1333  decode.d8.loss_dice: 0.7915
05/26 21:21:58 - mmengine - INFO - Iter(train) [ 88300/160000]  base_lr: 4.8558e-05 lr: 4.8558e-06  eta: 8:12:36  time: 0.4122  data_time: 0.0098  memory: 5967  grad_norm: 598.0921  loss: 19.2282  decode.loss_cls: 0.1569  decode.loss_mask: 1.0234  decode.loss_dice: 0.7162  decode.d0.loss_cls: 0.5392  decode.d0.loss_mask: 1.0154  decode.d0.loss_dice: 0.7089  decode.d1.loss_cls: 0.1664  decode.d1.loss_mask: 1.0074  decode.d1.loss_dice: 0.6846  decode.d2.loss_cls: 0.1402  decode.d2.loss_mask: 1.0419  decode.d2.loss_dice: 0.7108  decode.d3.loss_cls: 0.1527  decode.d3.loss_mask: 1.0067  decode.d3.loss_dice: 0.6972  decode.d4.loss_cls: 0.1298  decode.d4.loss_mask: 1.0516  decode.d4.loss_dice: 0.7385  decode.d5.loss_cls: 0.1486  decode.d5.loss_mask: 1.0594  decode.d5.loss_dice: 0.7255  decode.d6.loss_cls: 0.1535  decode.d6.loss_mask: 1.0009  decode.d6.loss_dice: 0.6961  decode.d7.loss_cls: 0.1816  decode.d7.loss_mask: 0.9921  decode.d7.loss_dice: 0.6846  decode.d8.loss_cls: 0.1070  decode.d8.loss_mask: 1.0718  decode.d8.loss_dice: 0.7193
05/26 21:22:18 - mmengine - INFO - Iter(train) [ 88350/160000]  base_lr: 4.8528e-05 lr: 4.8528e-06  eta: 8:12:15  time: 0.4129  data_time: 0.0096  memory: 5969  grad_norm: 531.1285  loss: 20.4746  decode.loss_cls: 0.1503  decode.loss_mask: 1.0613  decode.loss_dice: 0.7491  decode.d0.loss_cls: 0.6183  decode.d0.loss_mask: 1.0443  decode.d0.loss_dice: 0.7267  decode.d1.loss_cls: 0.1899  decode.d1.loss_mask: 1.0810  decode.d1.loss_dice: 0.7781  decode.d2.loss_cls: 0.1822  decode.d2.loss_mask: 1.0918  decode.d2.loss_dice: 0.7572  decode.d3.loss_cls: 0.1600  decode.d3.loss_mask: 1.0782  decode.d3.loss_dice: 0.7645  decode.d4.loss_cls: 0.1719  decode.d4.loss_mask: 1.0840  decode.d4.loss_dice: 0.7649  decode.d5.loss_cls: 0.1448  decode.d5.loss_mask: 1.0788  decode.d5.loss_dice: 0.7514  decode.d6.loss_cls: 0.1831  decode.d6.loss_mask: 1.0839  decode.d6.loss_dice: 0.7820  decode.d7.loss_cls: 0.1828  decode.d7.loss_mask: 1.0740  decode.d7.loss_dice: 0.7618  decode.d8.loss_cls: 0.1593  decode.d8.loss_mask: 1.0741  decode.d8.loss_dice: 0.7446
05/26 21:22:39 - mmengine - INFO - Iter(train) [ 88400/160000]  base_lr: 4.8497e-05 lr: 4.8497e-06  eta: 8:11:54  time: 0.4122  data_time: 0.0097  memory: 5969  grad_norm: 578.9744  loss: 22.2024  decode.loss_cls: 0.2352  decode.loss_mask: 1.1328  decode.loss_dice: 0.8166  decode.d0.loss_cls: 0.7901  decode.d0.loss_mask: 1.0942  decode.d0.loss_dice: 0.7690  decode.d1.loss_cls: 0.2393  decode.d1.loss_mask: 1.1065  decode.d1.loss_dice: 0.8125  decode.d2.loss_cls: 0.2139  decode.d2.loss_mask: 1.1347  decode.d2.loss_dice: 0.8071  decode.d3.loss_cls: 0.2037  decode.d3.loss_mask: 1.1083  decode.d3.loss_dice: 0.8044  decode.d4.loss_cls: 0.2004  decode.d4.loss_mask: 1.1478  decode.d4.loss_dice: 0.8378  decode.d5.loss_cls: 0.2211  decode.d5.loss_mask: 1.1202  decode.d5.loss_dice: 0.8040  decode.d6.loss_cls: 0.2588  decode.d6.loss_mask: 1.1230  decode.d6.loss_dice: 0.8189  decode.d7.loss_cls: 0.2448  decode.d7.loss_mask: 1.1524  decode.d7.loss_dice: 0.8202  decode.d8.loss_cls: 0.2564  decode.d8.loss_mask: 1.1387  decode.d8.loss_dice: 0.7897
05/26 21:23:00 - mmengine - INFO - Iter(train) [ 88450/160000]  base_lr: 4.8467e-05 lr: 4.8467e-06  eta: 8:11:34  time: 0.4136  data_time: 0.0096  memory: 5972  grad_norm: 591.3064  loss: 17.4506  decode.loss_cls: 0.1704  decode.loss_mask: 0.8308  decode.loss_dice: 0.6906  decode.d0.loss_cls: 0.6672  decode.d0.loss_mask: 0.8032  decode.d0.loss_dice: 0.6465  decode.d1.loss_cls: 0.1672  decode.d1.loss_mask: 0.8312  decode.d1.loss_dice: 0.7032  decode.d2.loss_cls: 0.1749  decode.d2.loss_mask: 0.8295  decode.d2.loss_dice: 0.6812  decode.d3.loss_cls: 0.1864  decode.d3.loss_mask: 0.8385  decode.d3.loss_dice: 0.7068  decode.d4.loss_cls: 0.1796  decode.d4.loss_mask: 0.8614  decode.d4.loss_dice: 0.7046  decode.d5.loss_cls: 0.1724  decode.d5.loss_mask: 0.8386  decode.d5.loss_dice: 0.7065  decode.d6.loss_cls: 0.1506  decode.d6.loss_mask: 0.8213  decode.d6.loss_dice: 0.6835  decode.d7.loss_cls: 0.1683  decode.d7.loss_mask: 0.8430  decode.d7.loss_dice: 0.6953  decode.d8.loss_cls: 0.1826  decode.d8.loss_mask: 0.8339  decode.d8.loss_dice: 0.6813
05/26 21:23:20 - mmengine - INFO - Iter(train) [ 88500/160000]  base_lr: 4.8436e-05 lr: 4.8436e-06  eta: 8:11:13  time: 0.4130  data_time: 0.0096  memory: 5973  grad_norm: 501.4803  loss: 20.9125  decode.loss_cls: 0.2095  decode.loss_mask: 1.0899  decode.loss_dice: 0.7411  decode.d0.loss_cls: 0.6120  decode.d0.loss_mask: 1.0696  decode.d0.loss_dice: 0.7436  decode.d1.loss_cls: 0.2484  decode.d1.loss_mask: 1.0912  decode.d1.loss_dice: 0.7744  decode.d2.loss_cls: 0.2318  decode.d2.loss_mask: 1.0646  decode.d2.loss_dice: 0.7182  decode.d3.loss_cls: 0.2225  decode.d3.loss_mask: 1.0825  decode.d3.loss_dice: 0.7393  decode.d4.loss_cls: 0.2057  decode.d4.loss_mask: 1.0949  decode.d4.loss_dice: 0.7583  decode.d5.loss_cls: 0.2234  decode.d5.loss_mask: 1.0906  decode.d5.loss_dice: 0.7334  decode.d6.loss_cls: 0.2390  decode.d6.loss_mask: 1.1027  decode.d6.loss_dice: 0.7268  decode.d7.loss_cls: 0.2072  decode.d7.loss_mask: 1.1027  decode.d7.loss_dice: 0.7613  decode.d8.loss_cls: 0.1845  decode.d8.loss_mask: 1.0958  decode.d8.loss_dice: 0.7476
05/26 21:23:41 - mmengine - INFO - Iter(train) [ 88550/160000]  base_lr: 4.8406e-05 lr: 4.8406e-06  eta: 8:10:53  time: 0.4127  data_time: 0.0096  memory: 5969  grad_norm: 613.7661  loss: 21.8990  decode.loss_cls: 0.2639  decode.loss_mask: 1.1118  decode.loss_dice: 0.7469  decode.d0.loss_cls: 0.7734  decode.d0.loss_mask: 1.0774  decode.d0.loss_dice: 0.7253  decode.d1.loss_cls: 0.2471  decode.d1.loss_mask: 1.1213  decode.d1.loss_dice: 0.7569  decode.d2.loss_cls: 0.2583  decode.d2.loss_mask: 1.1241  decode.d2.loss_dice: 0.7658  decode.d3.loss_cls: 0.2863  decode.d3.loss_mask: 1.1204  decode.d3.loss_dice: 0.7447  decode.d4.loss_cls: 0.2448  decode.d4.loss_mask: 1.2020  decode.d4.loss_dice: 0.7628  decode.d5.loss_cls: 0.2962  decode.d5.loss_mask: 1.0978  decode.d5.loss_dice: 0.7520  decode.d6.loss_cls: 0.2753  decode.d6.loss_mask: 1.1719  decode.d6.loss_dice: 0.7531  decode.d7.loss_cls: 0.2288  decode.d7.loss_mask: 1.1334  decode.d7.loss_dice: 0.7472  decode.d8.loss_cls: 0.2513  decode.d8.loss_mask: 1.1267  decode.d8.loss_dice: 0.7324
05/26 21:24:01 - mmengine - INFO - Iter(train) [ 88600/160000]  base_lr: 4.8375e-05 lr: 4.8375e-06  eta: 8:10:32  time: 0.4113  data_time: 0.0096  memory: 5990  grad_norm: 632.9870  loss: 19.6830  decode.loss_cls: 0.2212  decode.loss_mask: 1.0158  decode.loss_dice: 0.6758  decode.d0.loss_cls: 0.7137  decode.d0.loss_mask: 0.9745  decode.d0.loss_dice: 0.6788  decode.d1.loss_cls: 0.2429  decode.d1.loss_mask: 1.0274  decode.d1.loss_dice: 0.6915  decode.d2.loss_cls: 0.2229  decode.d2.loss_mask: 1.0097  decode.d2.loss_dice: 0.6796  decode.d3.loss_cls: 0.2300  decode.d3.loss_mask: 1.0099  decode.d3.loss_dice: 0.6805  decode.d4.loss_cls: 0.2283  decode.d4.loss_mask: 1.0113  decode.d4.loss_dice: 0.7010  decode.d5.loss_cls: 0.2261  decode.d5.loss_mask: 0.9930  decode.d5.loss_dice: 0.6832  decode.d6.loss_cls: 0.2012  decode.d6.loss_mask: 1.0050  decode.d6.loss_dice: 0.7011  decode.d7.loss_cls: 0.2345  decode.d7.loss_mask: 1.0099  decode.d7.loss_dice: 0.6972  decode.d8.loss_cls: 0.2229  decode.d8.loss_mask: 0.9992  decode.d8.loss_dice: 0.6947
05/26 21:24:22 - mmengine - INFO - Iter(train) [ 88650/160000]  base_lr: 4.8345e-05 lr: 4.8345e-06  eta: 8:10:11  time: 0.4121  data_time: 0.0096  memory: 5966  grad_norm: 802.0532  loss: 19.2710  decode.loss_cls: 0.2521  decode.loss_mask: 0.9449  decode.loss_dice: 0.6858  decode.d0.loss_cls: 0.6955  decode.d0.loss_mask: 0.9371  decode.d0.loss_dice: 0.6505  decode.d1.loss_cls: 0.2736  decode.d1.loss_mask: 0.9209  decode.d1.loss_dice: 0.6714  decode.d2.loss_cls: 0.2641  decode.d2.loss_mask: 0.9315  decode.d2.loss_dice: 0.6832  decode.d3.loss_cls: 0.2788  decode.d3.loss_mask: 0.9475  decode.d3.loss_dice: 0.6899  decode.d4.loss_cls: 0.2807  decode.d4.loss_mask: 0.9253  decode.d4.loss_dice: 0.6550  decode.d5.loss_cls: 0.2754  decode.d5.loss_mask: 0.9651  decode.d5.loss_dice: 0.7065  decode.d6.loss_cls: 0.2431  decode.d6.loss_mask: 0.9328  decode.d6.loss_dice: 0.6735  decode.d7.loss_cls: 0.2582  decode.d7.loss_mask: 0.9249  decode.d7.loss_dice: 0.7115  decode.d8.loss_cls: 0.2372  decode.d8.loss_mask: 0.9411  decode.d8.loss_dice: 0.7140
05/26 21:24:43 - mmengine - INFO - Iter(train) [ 88700/160000]  base_lr: 4.8314e-05 lr: 4.8314e-06  eta: 8:09:51  time: 0.4124  data_time: 0.0096  memory: 5971  grad_norm: 524.0869  loss: 23.2379  decode.loss_cls: 0.2825  decode.loss_mask: 1.2080  decode.loss_dice: 0.8214  decode.d0.loss_cls: 0.8269  decode.d0.loss_mask: 1.0943  decode.d0.loss_dice: 0.7874  decode.d1.loss_cls: 0.3046  decode.d1.loss_mask: 1.1583  decode.d1.loss_dice: 0.7922  decode.d2.loss_cls: 0.3430  decode.d2.loss_mask: 1.1390  decode.d2.loss_dice: 0.7882  decode.d3.loss_cls: 0.3179  decode.d3.loss_mask: 1.1551  decode.d3.loss_dice: 0.8204  decode.d4.loss_cls: 0.3140  decode.d4.loss_mask: 1.1631  decode.d4.loss_dice: 0.7996  decode.d5.loss_cls: 0.2755  decode.d5.loss_mask: 1.1451  decode.d5.loss_dice: 0.8024  decode.d6.loss_cls: 0.2955  decode.d6.loss_mask: 1.1750  decode.d6.loss_dice: 0.8003  decode.d7.loss_cls: 0.2905  decode.d7.loss_mask: 1.1973  decode.d7.loss_dice: 0.8190  decode.d8.loss_cls: 0.3005  decode.d8.loss_mask: 1.2094  decode.d8.loss_dice: 0.8115
05/26 21:25:03 - mmengine - INFO - Iter(train) [ 88750/160000]  base_lr: 4.8284e-05 lr: 4.8284e-06  eta: 8:09:30  time: 0.4116  data_time: 0.0096  memory: 5968  grad_norm: 425.5565  loss: 18.8285  decode.loss_cls: 0.1922  decode.loss_mask: 0.9481  decode.loss_dice: 0.6595  decode.d0.loss_cls: 0.6846  decode.d0.loss_mask: 0.9162  decode.d0.loss_dice: 0.6601  decode.d1.loss_cls: 0.2358  decode.d1.loss_mask: 0.9523  decode.d1.loss_dice: 0.6678  decode.d2.loss_cls: 0.2114  decode.d2.loss_mask: 0.9580  decode.d2.loss_dice: 0.6830  decode.d3.loss_cls: 0.2117  decode.d3.loss_mask: 0.9561  decode.d3.loss_dice: 0.6595  decode.d4.loss_cls: 0.2181  decode.d4.loss_mask: 0.9492  decode.d4.loss_dice: 0.6543  decode.d5.loss_cls: 0.1919  decode.d5.loss_mask: 0.9707  decode.d5.loss_dice: 0.6900  decode.d6.loss_cls: 0.2116  decode.d6.loss_mask: 0.9701  decode.d6.loss_dice: 0.6651  decode.d7.loss_cls: 0.1989  decode.d7.loss_mask: 0.9647  decode.d7.loss_dice: 0.6779  decode.d8.loss_cls: 0.2065  decode.d8.loss_mask: 0.9881  decode.d8.loss_dice: 0.6749
05/26 21:25:24 - mmengine - INFO - Iter(train) [ 88800/160000]  base_lr: 4.8253e-05 lr: 4.8253e-06  eta: 8:09:10  time: 0.4118  data_time: 0.0096  memory: 5966  grad_norm: 881.6103  loss: 20.3985  decode.loss_cls: 0.1867  decode.loss_mask: 1.0605  decode.loss_dice: 0.7262  decode.d0.loss_cls: 0.6708  decode.d0.loss_mask: 1.0151  decode.d0.loss_dice: 0.7004  decode.d1.loss_cls: 0.1787  decode.d1.loss_mask: 1.0724  decode.d1.loss_dice: 0.7654  decode.d2.loss_cls: 0.1759  decode.d2.loss_mask: 1.0922  decode.d2.loss_dice: 0.7644  decode.d3.loss_cls: 0.1907  decode.d3.loss_mask: 1.0626  decode.d3.loss_dice: 0.7473  decode.d4.loss_cls: 0.1601  decode.d4.loss_mask: 1.0618  decode.d4.loss_dice: 0.7508  decode.d5.loss_cls: 0.1895  decode.d5.loss_mask: 1.0675  decode.d5.loss_dice: 0.7578  decode.d6.loss_cls: 0.1633  decode.d6.loss_mask: 1.1011  decode.d6.loss_dice: 0.7640  decode.d7.loss_cls: 0.1818  decode.d7.loss_mask: 1.0607  decode.d7.loss_dice: 0.7333  decode.d8.loss_cls: 0.1933  decode.d8.loss_mask: 1.0667  decode.d8.loss_dice: 0.7373
05/26 21:25:45 - mmengine - INFO - Iter(train) [ 88850/160000]  base_lr: 4.8223e-05 lr: 4.8223e-06  eta: 8:08:49  time: 0.4219  data_time: 0.0096  memory: 5975  grad_norm: 598.6396  loss: 23.3672  decode.loss_cls: 0.1850  decode.loss_mask: 1.2422  decode.loss_dice: 0.8571  decode.d0.loss_cls: 0.7433  decode.d0.loss_mask: 1.2017  decode.d0.loss_dice: 0.8538  decode.d1.loss_cls: 0.2265  decode.d1.loss_mask: 1.2347  decode.d1.loss_dice: 0.8345  decode.d2.loss_cls: 0.2145  decode.d2.loss_mask: 1.2363  decode.d2.loss_dice: 0.8373  decode.d3.loss_cls: 0.2123  decode.d3.loss_mask: 1.2188  decode.d3.loss_dice: 0.8409  decode.d4.loss_cls: 0.2283  decode.d4.loss_mask: 1.2110  decode.d4.loss_dice: 0.8360  decode.d5.loss_cls: 0.2120  decode.d5.loss_mask: 1.2318  decode.d5.loss_dice: 0.8388  decode.d6.loss_cls: 0.2340  decode.d6.loss_mask: 1.2209  decode.d6.loss_dice: 0.8523  decode.d7.loss_cls: 0.2576  decode.d7.loss_mask: 1.2246  decode.d7.loss_dice: 0.8346  decode.d8.loss_cls: 0.2190  decode.d8.loss_mask: 1.2065  decode.d8.loss_dice: 0.8208
05/26 21:26:05 - mmengine - INFO - Iter(train) [ 88900/160000]  base_lr: 4.8192e-05 lr: 4.8192e-06  eta: 8:08:28  time: 0.4120  data_time: 0.0098  memory: 5967  grad_norm: 601.3416  loss: 19.8863  decode.loss_cls: 0.2329  decode.loss_mask: 1.0293  decode.loss_dice: 0.7120  decode.d0.loss_cls: 0.7222  decode.d0.loss_mask: 0.9399  decode.d0.loss_dice: 0.6425  decode.d1.loss_cls: 0.2560  decode.d1.loss_mask: 0.9981  decode.d1.loss_dice: 0.6875  decode.d2.loss_cls: 0.2740  decode.d2.loss_mask: 0.9905  decode.d2.loss_dice: 0.6888  decode.d3.loss_cls: 0.2409  decode.d3.loss_mask: 0.9842  decode.d3.loss_dice: 0.6730  decode.d4.loss_cls: 0.2335  decode.d4.loss_mask: 1.0642  decode.d4.loss_dice: 0.6868  decode.d5.loss_cls: 0.2417  decode.d5.loss_mask: 1.0013  decode.d5.loss_dice: 0.6924  decode.d6.loss_cls: 0.2393  decode.d6.loss_mask: 1.0515  decode.d6.loss_dice: 0.7019  decode.d7.loss_cls: 0.2517  decode.d7.loss_mask: 0.9834  decode.d7.loss_dice: 0.7254  decode.d8.loss_cls: 0.2579  decode.d8.loss_mask: 0.9953  decode.d8.loss_dice: 0.6884
05/26 21:26:26 - mmengine - INFO - Iter(train) [ 88950/160000]  base_lr: 4.8162e-05 lr: 4.8162e-06  eta: 8:08:08  time: 0.4125  data_time: 0.0096  memory: 5976  grad_norm: 836.5494  loss: 19.5835  decode.loss_cls: 0.1002  decode.loss_mask: 1.0192  decode.loss_dice: 0.7691  decode.d0.loss_cls: 0.6344  decode.d0.loss_mask: 0.9902  decode.d0.loss_dice: 0.7246  decode.d1.loss_cls: 0.1284  decode.d1.loss_mask: 1.0252  decode.d1.loss_dice: 0.7785  decode.d2.loss_cls: 0.1145  decode.d2.loss_mask: 1.0272  decode.d2.loss_dice: 0.7651  decode.d3.loss_cls: 0.1271  decode.d3.loss_mask: 1.0368  decode.d3.loss_dice: 0.7746  decode.d4.loss_cls: 0.1564  decode.d4.loss_mask: 1.0246  decode.d4.loss_dice: 0.7541  decode.d5.loss_cls: 0.1093  decode.d5.loss_mask: 1.0361  decode.d5.loss_dice: 0.7674  decode.d6.loss_cls: 0.0936  decode.d6.loss_mask: 1.0479  decode.d6.loss_dice: 0.7696  decode.d7.loss_cls: 0.1254  decode.d7.loss_mask: 1.0218  decode.d7.loss_dice: 0.7658  decode.d8.loss_cls: 0.1043  decode.d8.loss_mask: 1.0266  decode.d8.loss_dice: 0.7656
05/26 21:26:47 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 21:26:47 - mmengine - INFO - Iter(train) [ 89000/160000]  base_lr: 4.8131e-05 lr: 4.8131e-06  eta: 8:07:47  time: 0.4129  data_time: 0.0096  memory: 5971  grad_norm: 638.2328  loss: 21.7261  decode.loss_cls: 0.2517  decode.loss_mask: 1.0014  decode.loss_dice: 0.8512  decode.d0.loss_cls: 0.7319  decode.d0.loss_mask: 0.9380  decode.d0.loss_dice: 0.8103  decode.d1.loss_cls: 0.3046  decode.d1.loss_mask: 1.0086  decode.d1.loss_dice: 0.8542  decode.d2.loss_cls: 0.2728  decode.d2.loss_mask: 1.0136  decode.d2.loss_dice: 0.8567  decode.d3.loss_cls: 0.2535  decode.d3.loss_mask: 1.0092  decode.d3.loss_dice: 0.8484  decode.d4.loss_cls: 0.2872  decode.d4.loss_mask: 1.0150  decode.d4.loss_dice: 0.8354  decode.d5.loss_cls: 0.2558  decode.d5.loss_mask: 1.0131  decode.d5.loss_dice: 0.8578  decode.d6.loss_cls: 0.2919  decode.d6.loss_mask: 0.9854  decode.d6.loss_dice: 0.8564  decode.d7.loss_cls: 0.2701  decode.d7.loss_mask: 1.0278  decode.d7.loss_dice: 0.8576  decode.d8.loss_cls: 0.1978  decode.d8.loss_mask: 1.1118  decode.d8.loss_dice: 0.8568
05/26 21:27:07 - mmengine - INFO - Iter(train) [ 89050/160000]  base_lr: 4.8101e-05 lr: 4.8101e-06  eta: 8:07:27  time: 0.4120  data_time: 0.0097  memory: 5969  grad_norm: 688.2739  loss: 19.2931  decode.loss_cls: 0.2080  decode.loss_mask: 0.9157  decode.loss_dice: 0.7463  decode.d0.loss_cls: 0.7365  decode.d0.loss_mask: 0.8481  decode.d0.loss_dice: 0.7109  decode.d1.loss_cls: 0.1642  decode.d1.loss_mask: 0.9258  decode.d1.loss_dice: 0.7491  decode.d2.loss_cls: 0.2402  decode.d2.loss_mask: 0.9211  decode.d2.loss_dice: 0.7208  decode.d3.loss_cls: 0.1895  decode.d3.loss_mask: 0.9263  decode.d3.loss_dice: 0.7289  decode.d4.loss_cls: 0.2045  decode.d4.loss_mask: 0.9300  decode.d4.loss_dice: 0.7481  decode.d5.loss_cls: 0.2470  decode.d5.loss_mask: 0.9553  decode.d5.loss_dice: 0.7335  decode.d6.loss_cls: 0.2452  decode.d6.loss_mask: 0.9439  decode.d6.loss_dice: 0.7604  decode.d7.loss_cls: 0.2364  decode.d7.loss_mask: 0.9241  decode.d7.loss_dice: 0.7481  decode.d8.loss_cls: 0.2296  decode.d8.loss_mask: 0.9176  decode.d8.loss_dice: 0.7381
05/26 21:27:32 - mmengine - INFO - Iter(train) [ 89100/160000]  base_lr: 4.8070e-05 lr: 4.8070e-06  eta: 8:07:09  time: 0.4371  data_time: 0.0118  memory: 5984  grad_norm: 661.8426  loss: 24.2234  decode.loss_cls: 0.3106  decode.loss_mask: 1.2623  decode.loss_dice: 0.8158  decode.d0.loss_cls: 0.9214  decode.d0.loss_mask: 1.1781  decode.d0.loss_dice: 0.7860  decode.d1.loss_cls: 0.3020  decode.d1.loss_mask: 1.2620  decode.d1.loss_dice: 0.7931  decode.d2.loss_cls: 0.3104  decode.d2.loss_mask: 1.2676  decode.d2.loss_dice: 0.7870  decode.d3.loss_cls: 0.2755  decode.d3.loss_mask: 1.2561  decode.d3.loss_dice: 0.8369  decode.d4.loss_cls: 0.2571  decode.d4.loss_mask: 1.2683  decode.d4.loss_dice: 0.8132  decode.d5.loss_cls: 0.2925  decode.d5.loss_mask: 1.2736  decode.d5.loss_dice: 0.8308  decode.d6.loss_cls: 0.3118  decode.d6.loss_mask: 1.2464  decode.d6.loss_dice: 0.8353  decode.d7.loss_cls: 0.2965  decode.d7.loss_mask: 1.2397  decode.d7.loss_dice: 0.7931  decode.d8.loss_cls: 0.3260  decode.d8.loss_mask: 1.2694  decode.d8.loss_dice: 0.8047
05/26 21:27:53 - mmengine - INFO - Iter(train) [ 89150/160000]  base_lr: 4.8040e-05 lr: 4.8040e-06  eta: 8:06:49  time: 0.4119  data_time: 0.0096  memory: 5966  grad_norm: 1044.8513  loss: 19.9642  decode.loss_cls: 0.2939  decode.loss_mask: 0.9726  decode.loss_dice: 0.7292  decode.d0.loss_cls: 0.7168  decode.d0.loss_mask: 0.8473  decode.d0.loss_dice: 0.7041  decode.d1.loss_cls: 0.2805  decode.d1.loss_mask: 0.9712  decode.d1.loss_dice: 0.7250  decode.d2.loss_cls: 0.3102  decode.d2.loss_mask: 0.9098  decode.d2.loss_dice: 0.7324  decode.d3.loss_cls: 0.2982  decode.d3.loss_mask: 0.9036  decode.d3.loss_dice: 0.7344  decode.d4.loss_cls: 0.3175  decode.d4.loss_mask: 0.8894  decode.d4.loss_dice: 0.6941  decode.d5.loss_cls: 0.3010  decode.d5.loss_mask: 0.9097  decode.d5.loss_dice: 0.7182  decode.d6.loss_cls: 0.2992  decode.d6.loss_mask: 0.9297  decode.d6.loss_dice: 0.7177  decode.d7.loss_cls: 0.3353  decode.d7.loss_mask: 1.0185  decode.d7.loss_dice: 0.6941  decode.d8.loss_cls: 0.2931  decode.d8.loss_mask: 0.9860  decode.d8.loss_dice: 0.7313
05/26 21:28:13 - mmengine - INFO - Iter(train) [ 89200/160000]  base_lr: 4.8009e-05 lr: 4.8009e-06  eta: 8:06:28  time: 0.4126  data_time: 0.0096  memory: 5966  grad_norm: 274.7394  loss: 16.8056  decode.loss_cls: 0.0716  decode.loss_mask: 0.9447  decode.loss_dice: 0.6207  decode.d0.loss_cls: 0.6172  decode.d0.loss_mask: 0.9101  decode.d0.loss_dice: 0.6011  decode.d1.loss_cls: 0.0943  decode.d1.loss_mask: 0.9217  decode.d1.loss_dice: 0.6124  decode.d2.loss_cls: 0.0844  decode.d2.loss_mask: 0.9102  decode.d2.loss_dice: 0.6060  decode.d3.loss_cls: 0.1009  decode.d3.loss_mask: 0.9214  decode.d3.loss_dice: 0.6137  decode.d4.loss_cls: 0.1007  decode.d4.loss_mask: 0.9555  decode.d4.loss_dice: 0.6112  decode.d5.loss_cls: 0.0997  decode.d5.loss_mask: 0.9245  decode.d5.loss_dice: 0.6041  decode.d6.loss_cls: 0.0965  decode.d6.loss_mask: 0.9143  decode.d6.loss_dice: 0.6028  decode.d7.loss_cls: 0.0849  decode.d7.loss_mask: 0.9236  decode.d7.loss_dice: 0.6114  decode.d8.loss_cls: 0.0674  decode.d8.loss_mask: 0.9583  decode.d8.loss_dice: 0.6204
05/26 21:28:34 - mmengine - INFO - Iter(train) [ 89250/160000]  base_lr: 4.7979e-05 lr: 4.7979e-06  eta: 8:06:08  time: 0.4124  data_time: 0.0097  memory: 5973  grad_norm: 873.9809  loss: 21.4883  decode.loss_cls: 0.2357  decode.loss_mask: 1.0630  decode.loss_dice: 0.7758  decode.d0.loss_cls: 0.7445  decode.d0.loss_mask: 0.9984  decode.d0.loss_dice: 0.7577  decode.d1.loss_cls: 0.2366  decode.d1.loss_mask: 1.0902  decode.d1.loss_dice: 0.7879  decode.d2.loss_cls: 0.2425  decode.d2.loss_mask: 1.0871  decode.d2.loss_dice: 0.7958  decode.d3.loss_cls: 0.2212  decode.d3.loss_mask: 1.0709  decode.d3.loss_dice: 0.7702  decode.d4.loss_cls: 0.2001  decode.d4.loss_mask: 1.1326  decode.d4.loss_dice: 0.8069  decode.d5.loss_cls: 0.2649  decode.d5.loss_mask: 1.0737  decode.d5.loss_dice: 0.7912  decode.d6.loss_cls: 0.2353  decode.d6.loss_mask: 1.1173  decode.d6.loss_dice: 0.7796  decode.d7.loss_cls: 0.2923  decode.d7.loss_mask: 1.0629  decode.d7.loss_dice: 0.7476  decode.d8.loss_cls: 0.2656  decode.d8.loss_mask: 1.0724  decode.d8.loss_dice: 0.7684
05/26 21:28:55 - mmengine - INFO - Iter(train) [ 89300/160000]  base_lr: 4.7948e-05 lr: 4.7948e-06  eta: 8:05:47  time: 0.4123  data_time: 0.0097  memory: 5982  grad_norm: 504.9279  loss: 18.2816  decode.loss_cls: 0.2650  decode.loss_mask: 0.8482  decode.loss_dice: 0.6504  decode.d0.loss_cls: 0.5808  decode.d0.loss_mask: 0.9056  decode.d0.loss_dice: 0.6779  decode.d1.loss_cls: 0.2870  decode.d1.loss_mask: 0.8463  decode.d1.loss_dice: 0.6512  decode.d2.loss_cls: 0.2091  decode.d2.loss_mask: 0.8508  decode.d2.loss_dice: 0.6467  decode.d3.loss_cls: 0.2146  decode.d3.loss_mask: 0.8479  decode.d3.loss_dice: 0.6550  decode.d4.loss_cls: 0.2453  decode.d4.loss_mask: 0.8559  decode.d4.loss_dice: 0.6516  decode.d5.loss_cls: 0.2494  decode.d5.loss_mask: 0.8742  decode.d5.loss_dice: 0.7041  decode.d6.loss_cls: 0.2601  decode.d6.loss_mask: 0.8652  decode.d6.loss_dice: 0.6562  decode.d7.loss_cls: 0.2585  decode.d7.loss_mask: 0.9424  decode.d7.loss_dice: 0.7026  decode.d8.loss_cls: 0.2786  decode.d8.loss_mask: 0.9314  decode.d8.loss_dice: 0.6695
05/26 21:29:15 - mmengine - INFO - Iter(train) [ 89350/160000]  base_lr: 4.7918e-05 lr: 4.7918e-06  eta: 8:05:26  time: 0.4119  data_time: 0.0098  memory: 5979  grad_norm: 1152.1072  loss: 23.5512  decode.loss_cls: 0.2814  decode.loss_mask: 1.1629  decode.loss_dice: 0.8265  decode.d0.loss_cls: 0.8281  decode.d0.loss_mask: 1.1005  decode.d0.loss_dice: 0.7879  decode.d1.loss_cls: 0.3383  decode.d1.loss_mask: 1.1492  decode.d1.loss_dice: 0.8114  decode.d2.loss_cls: 0.3443  decode.d2.loss_mask: 1.1882  decode.d2.loss_dice: 0.8342  decode.d3.loss_cls: 0.3230  decode.d3.loss_mask: 1.1307  decode.d3.loss_dice: 0.7857  decode.d4.loss_cls: 0.3501  decode.d4.loss_mask: 1.1672  decode.d4.loss_dice: 0.8394  decode.d5.loss_cls: 0.2982  decode.d5.loss_mask: 1.1861  decode.d5.loss_dice: 0.8286  decode.d6.loss_cls: 0.2764  decode.d6.loss_mask: 1.2447  decode.d6.loss_dice: 0.8710  decode.d7.loss_cls: 0.3113  decode.d7.loss_mask: 1.1715  decode.d7.loss_dice: 0.8217  decode.d8.loss_cls: 0.2918  decode.d8.loss_mask: 1.1642  decode.d8.loss_dice: 0.8364
05/26 21:29:36 - mmengine - INFO - Iter(train) [ 89400/160000]  base_lr: 4.7887e-05 lr: 4.7887e-06  eta: 8:05:06  time: 0.4122  data_time: 0.0098  memory: 5966  grad_norm: 468.2289  loss: 18.8648  decode.loss_cls: 0.1536  decode.loss_mask: 1.0052  decode.loss_dice: 0.6626  decode.d0.loss_cls: 0.6974  decode.d0.loss_mask: 0.9292  decode.d0.loss_dice: 0.6748  decode.d1.loss_cls: 0.2023  decode.d1.loss_mask: 1.0069  decode.d1.loss_dice: 0.6665  decode.d2.loss_cls: 0.1803  decode.d2.loss_mask: 0.9959  decode.d2.loss_dice: 0.6522  decode.d3.loss_cls: 0.1695  decode.d3.loss_mask: 0.9891  decode.d3.loss_dice: 0.6555  decode.d4.loss_cls: 0.1898  decode.d4.loss_mask: 1.0083  decode.d4.loss_dice: 0.6829  decode.d5.loss_cls: 0.1405  decode.d5.loss_mask: 1.0343  decode.d5.loss_dice: 0.6946  decode.d6.loss_cls: 0.2234  decode.d6.loss_mask: 0.9712  decode.d6.loss_dice: 0.6619  decode.d7.loss_cls: 0.1751  decode.d7.loss_mask: 0.9889  decode.d7.loss_dice: 0.6442  decode.d8.loss_cls: 0.1852  decode.d8.loss_mask: 0.9963  decode.d8.loss_dice: 0.6274
05/26 21:29:57 - mmengine - INFO - Iter(train) [ 89450/160000]  base_lr: 4.7857e-05 lr: 4.7857e-06  eta: 8:04:45  time: 0.4136  data_time: 0.0098  memory: 5968  grad_norm: 618.5877  loss: 18.3430  decode.loss_cls: 0.1473  decode.loss_mask: 0.9579  decode.loss_dice: 0.6739  decode.d0.loss_cls: 0.7035  decode.d0.loss_mask: 0.8777  decode.d0.loss_dice: 0.6023  decode.d1.loss_cls: 0.2205  decode.d1.loss_mask: 0.9643  decode.d1.loss_dice: 0.6584  decode.d2.loss_cls: 0.1712  decode.d2.loss_mask: 0.9725  decode.d2.loss_dice: 0.6451  decode.d3.loss_cls: 0.1597  decode.d3.loss_mask: 0.9323  decode.d3.loss_dice: 0.6539  decode.d4.loss_cls: 0.1992  decode.d4.loss_mask: 0.9451  decode.d4.loss_dice: 0.6778  decode.d5.loss_cls: 0.1873  decode.d5.loss_mask: 0.9424  decode.d5.loss_dice: 0.6714  decode.d6.loss_cls: 0.1365  decode.d6.loss_mask: 0.9223  decode.d6.loss_dice: 0.6811  decode.d7.loss_cls: 0.1533  decode.d7.loss_mask: 0.9801  decode.d7.loss_dice: 0.6738  decode.d8.loss_cls: 0.1488  decode.d8.loss_mask: 0.9825  decode.d8.loss_dice: 0.7007
05/26 21:30:17 - mmengine - INFO - Iter(train) [ 89500/160000]  base_lr: 4.7826e-05 lr: 4.7826e-06  eta: 8:04:25  time: 0.4131  data_time: 0.0097  memory: 5986  grad_norm: 627.6363  loss: 25.3639  decode.loss_cls: 0.2313  decode.loss_mask: 1.3215  decode.loss_dice: 0.9366  decode.d0.loss_cls: 0.8062  decode.d0.loss_mask: 1.2882  decode.d0.loss_dice: 0.8921  decode.d1.loss_cls: 0.3000  decode.d1.loss_mask: 1.2735  decode.d1.loss_dice: 0.9102  decode.d2.loss_cls: 0.2036  decode.d2.loss_mask: 1.3307  decode.d2.loss_dice: 0.9457  decode.d3.loss_cls: 0.2220  decode.d3.loss_mask: 1.2960  decode.d3.loss_dice: 0.9431  decode.d4.loss_cls: 0.2547  decode.d4.loss_mask: 1.2941  decode.d4.loss_dice: 0.9067  decode.d5.loss_cls: 0.2335  decode.d5.loss_mask: 1.3258  decode.d5.loss_dice: 0.9376  decode.d6.loss_cls: 0.2411  decode.d6.loss_mask: 1.3089  decode.d6.loss_dice: 0.9455  decode.d7.loss_cls: 0.2343  decode.d7.loss_mask: 1.3410  decode.d7.loss_dice: 0.9175  decode.d8.loss_cls: 0.2625  decode.d8.loss_mask: 1.3346  decode.d8.loss_dice: 0.9254
05/26 21:30:38 - mmengine - INFO - Iter(train) [ 89550/160000]  base_lr: 4.7796e-05 lr: 4.7796e-06  eta: 8:04:04  time: 0.4140  data_time: 0.0098  memory: 5976  grad_norm: 1744.0841  loss: 23.9822  decode.loss_cls: 0.3778  decode.loss_mask: 1.1506  decode.loss_dice: 0.7962  decode.d0.loss_cls: 0.8930  decode.d0.loss_mask: 1.1671  decode.d0.loss_dice: 0.7745  decode.d1.loss_cls: 0.3946  decode.d1.loss_mask: 1.1441  decode.d1.loss_dice: 0.8070  decode.d2.loss_cls: 0.3964  decode.d2.loss_mask: 1.1717  decode.d2.loss_dice: 0.8067  decode.d3.loss_cls: 0.4133  decode.d3.loss_mask: 1.1467  decode.d3.loss_dice: 0.7903  decode.d4.loss_cls: 0.3957  decode.d4.loss_mask: 1.1705  decode.d4.loss_dice: 0.7804  decode.d5.loss_cls: 0.4342  decode.d5.loss_mask: 1.1264  decode.d5.loss_dice: 0.7687  decode.d6.loss_cls: 0.4327  decode.d6.loss_mask: 1.1447  decode.d6.loss_dice: 0.8261  decode.d7.loss_cls: 0.4156  decode.d7.loss_mask: 1.1607  decode.d7.loss_dice: 0.8099  decode.d8.loss_cls: 0.4037  decode.d8.loss_mask: 1.1265  decode.d8.loss_dice: 0.7566
05/26 21:30:59 - mmengine - INFO - Iter(train) [ 89600/160000]  base_lr: 4.7765e-05 lr: 4.7765e-06  eta: 8:03:43  time: 0.4131  data_time: 0.0097  memory: 5967  grad_norm: 602.6832  loss: 21.4905  decode.loss_cls: 0.1758  decode.loss_mask: 1.1562  decode.loss_dice: 0.7007  decode.d0.loss_cls: 0.6918  decode.d0.loss_mask: 1.1869  decode.d0.loss_dice: 0.6919  decode.d1.loss_cls: 0.1853  decode.d1.loss_mask: 1.2370  decode.d1.loss_dice: 0.7274  decode.d2.loss_cls: 0.2291  decode.d2.loss_mask: 1.1833  decode.d2.loss_dice: 0.7083  decode.d3.loss_cls: 0.1949  decode.d3.loss_mask: 1.1647  decode.d3.loss_dice: 0.7001  decode.d4.loss_cls: 0.1893  decode.d4.loss_mask: 1.1897  decode.d4.loss_dice: 0.7105  decode.d5.loss_cls: 0.1889  decode.d5.loss_mask: 1.2024  decode.d5.loss_dice: 0.7200  decode.d6.loss_cls: 0.2195  decode.d6.loss_mask: 1.2025  decode.d6.loss_dice: 0.6966  decode.d7.loss_cls: 0.2002  decode.d7.loss_mask: 1.1990  decode.d7.loss_dice: 0.7116  decode.d8.loss_cls: 0.1788  decode.d8.loss_mask: 1.2086  decode.d8.loss_dice: 0.7395
05/26 21:31:19 - mmengine - INFO - Iter(train) [ 89650/160000]  base_lr: 4.7734e-05 lr: 4.7734e-06  eta: 8:03:23  time: 0.4137  data_time: 0.0097  memory: 5979  grad_norm: 472.3793  loss: 20.9301  decode.loss_cls: 0.2259  decode.loss_mask: 1.0124  decode.loss_dice: 0.7854  decode.d0.loss_cls: 0.6612  decode.d0.loss_mask: 0.9755  decode.d0.loss_dice: 0.8011  decode.d1.loss_cls: 0.2710  decode.d1.loss_mask: 1.0165  decode.d1.loss_dice: 0.7823  decode.d2.loss_cls: 0.2688  decode.d2.loss_mask: 1.0038  decode.d2.loss_dice: 0.7695  decode.d3.loss_cls: 0.2818  decode.d3.loss_mask: 0.9913  decode.d3.loss_dice: 0.7709  decode.d4.loss_cls: 0.2612  decode.d4.loss_mask: 1.0111  decode.d4.loss_dice: 0.7708  decode.d5.loss_cls: 0.2577  decode.d5.loss_mask: 1.0248  decode.d5.loss_dice: 0.7698  decode.d6.loss_cls: 0.2432  decode.d6.loss_mask: 1.0307  decode.d6.loss_dice: 0.7955  decode.d7.loss_cls: 0.2630  decode.d7.loss_mask: 1.0318  decode.d7.loss_dice: 0.7668  decode.d8.loss_cls: 0.2615  decode.d8.loss_mask: 1.0283  decode.d8.loss_dice: 0.7965
05/26 21:31:40 - mmengine - INFO - Iter(train) [ 89700/160000]  base_lr: 4.7704e-05 lr: 4.7704e-06  eta: 8:03:02  time: 0.4209  data_time: 0.0100  memory: 5971  grad_norm: 717.0496  loss: 24.4274  decode.loss_cls: 0.3929  decode.loss_mask: 1.1629  decode.loss_dice: 0.7946  decode.d0.loss_cls: 0.7854  decode.d0.loss_mask: 1.1112  decode.d0.loss_dice: 0.7963  decode.d1.loss_cls: 0.3155  decode.d1.loss_mask: 1.2708  decode.d1.loss_dice: 0.8544  decode.d2.loss_cls: 0.2970  decode.d2.loss_mask: 1.2456  decode.d2.loss_dice: 0.8577  decode.d3.loss_cls: 0.3236  decode.d3.loss_mask: 1.1949  decode.d3.loss_dice: 0.8650  decode.d4.loss_cls: 0.3249  decode.d4.loss_mask: 1.2359  decode.d4.loss_dice: 0.8438  decode.d5.loss_cls: 0.3419  decode.d5.loss_mask: 1.1990  decode.d5.loss_dice: 0.8516  decode.d6.loss_cls: 0.3933  decode.d6.loss_mask: 1.2382  decode.d6.loss_dice: 0.8498  decode.d7.loss_cls: 0.3841  decode.d7.loss_mask: 1.2376  decode.d7.loss_dice: 0.8504  decode.d8.loss_cls: 0.3899  decode.d8.loss_mask: 1.2093  decode.d8.loss_dice: 0.8096
05/26 21:32:01 - mmengine - INFO - Iter(train) [ 89750/160000]  base_lr: 4.7673e-05 lr: 4.7673e-06  eta: 8:02:42  time: 0.4207  data_time: 0.0101  memory: 5980  grad_norm: 627.0391  loss: 20.4633  decode.loss_cls: 0.1834  decode.loss_mask: 1.0204  decode.loss_dice: 0.7580  decode.d0.loss_cls: 0.7007  decode.d0.loss_mask: 0.9384  decode.d0.loss_dice: 0.7458  decode.d1.loss_cls: 0.1736  decode.d1.loss_mask: 1.0806  decode.d1.loss_dice: 0.7780  decode.d2.loss_cls: 0.1787  decode.d2.loss_mask: 1.0551  decode.d2.loss_dice: 0.7853  decode.d3.loss_cls: 0.1817  decode.d3.loss_mask: 1.0484  decode.d3.loss_dice: 0.7633  decode.d4.loss_cls: 0.1653  decode.d4.loss_mask: 1.0409  decode.d4.loss_dice: 0.7819  decode.d5.loss_cls: 0.1419  decode.d5.loss_mask: 1.0799  decode.d5.loss_dice: 0.8109  decode.d6.loss_cls: 0.1879  decode.d6.loss_mask: 1.0530  decode.d6.loss_dice: 0.7803  decode.d7.loss_cls: 0.1921  decode.d7.loss_mask: 1.0588  decode.d7.loss_dice: 0.8030  decode.d8.loss_cls: 0.1947  decode.d8.loss_mask: 1.0212  decode.d8.loss_dice: 0.7601
05/26 21:32:22 - mmengine - INFO - Iter(train) [ 89800/160000]  base_lr: 4.7643e-05 lr: 4.7643e-06  eta: 8:02:22  time: 0.4191  data_time: 0.0098  memory: 5966  grad_norm: 537.9256  loss: 21.5766  decode.loss_cls: 0.1364  decode.loss_mask: 1.2207  decode.loss_dice: 0.7481  decode.d0.loss_cls: 0.7318  decode.d0.loss_mask: 1.0999  decode.d0.loss_dice: 0.7365  decode.d1.loss_cls: 0.1448  decode.d1.loss_mask: 1.2105  decode.d1.loss_dice: 0.7674  decode.d2.loss_cls: 0.1478  decode.d2.loss_mask: 1.2350  decode.d2.loss_dice: 0.7581  decode.d3.loss_cls: 0.1411  decode.d3.loss_mask: 1.2094  decode.d3.loss_dice: 0.7594  decode.d4.loss_cls: 0.1687  decode.d4.loss_mask: 1.1653  decode.d4.loss_dice: 0.7265  decode.d5.loss_cls: 0.1149  decode.d5.loss_mask: 1.2343  decode.d5.loss_dice: 0.7763  decode.d6.loss_cls: 0.1204  decode.d6.loss_mask: 1.2346  decode.d6.loss_dice: 0.7749  decode.d7.loss_cls: 0.1525  decode.d7.loss_mask: 1.2048  decode.d7.loss_dice: 0.7415  decode.d8.loss_cls: 0.1746  decode.d8.loss_mask: 1.1919  decode.d8.loss_dice: 0.7482
05/26 21:32:43 - mmengine - INFO - Iter(train) [ 89850/160000]  base_lr: 4.7612e-05 lr: 4.7612e-06  eta: 8:02:01  time: 0.4157  data_time: 0.0100  memory: 5968  grad_norm: 438.9522  loss: 19.3966  decode.loss_cls: 0.2143  decode.loss_mask: 1.0046  decode.loss_dice: 0.7194  decode.d0.loss_cls: 0.6656  decode.d0.loss_mask: 0.9325  decode.d0.loss_dice: 0.6507  decode.d1.loss_cls: 0.2384  decode.d1.loss_mask: 0.9921  decode.d1.loss_dice: 0.7063  decode.d2.loss_cls: 0.2145  decode.d2.loss_mask: 0.9834  decode.d2.loss_dice: 0.6917  decode.d3.loss_cls: 0.2027  decode.d3.loss_mask: 0.9970  decode.d3.loss_dice: 0.6908  decode.d4.loss_cls: 0.2106  decode.d4.loss_mask: 0.9716  decode.d4.loss_dice: 0.6887  decode.d5.loss_cls: 0.2028  decode.d5.loss_mask: 0.9752  decode.d5.loss_dice: 0.7024  decode.d6.loss_cls: 0.2353  decode.d6.loss_mask: 0.9705  decode.d6.loss_dice: 0.6907  decode.d7.loss_cls: 0.2277  decode.d7.loss_mask: 1.0084  decode.d7.loss_dice: 0.7131  decode.d8.loss_cls: 0.2496  decode.d8.loss_mask: 0.9396  decode.d8.loss_dice: 0.7065
05/26 21:33:04 - mmengine - INFO - Iter(train) [ 89900/160000]  base_lr: 4.7582e-05 lr: 4.7582e-06  eta: 8:01:41  time: 0.4185  data_time: 0.0100  memory: 5981  grad_norm: 507.0850  loss: 17.8510  decode.loss_cls: 0.2064  decode.loss_mask: 0.8760  decode.loss_dice: 0.6346  decode.d0.loss_cls: 0.7362  decode.d0.loss_mask: 0.8729  decode.d0.loss_dice: 0.6124  decode.d1.loss_cls: 0.1829  decode.d1.loss_mask: 0.9153  decode.d1.loss_dice: 0.6310  decode.d2.loss_cls: 0.2065  decode.d2.loss_mask: 0.8988  decode.d2.loss_dice: 0.6343  decode.d3.loss_cls: 0.2092  decode.d3.loss_mask: 0.8705  decode.d3.loss_dice: 0.6234  decode.d4.loss_cls: 0.2071  decode.d4.loss_mask: 0.9304  decode.d4.loss_dice: 0.6261  decode.d5.loss_cls: 0.2063  decode.d5.loss_mask: 0.9038  decode.d5.loss_dice: 0.6246  decode.d6.loss_cls: 0.2510  decode.d6.loss_mask: 0.8613  decode.d6.loss_dice: 0.6200  decode.d7.loss_cls: 0.2378  decode.d7.loss_mask: 0.8770  decode.d7.loss_dice: 0.6597  decode.d8.loss_cls: 0.1905  decode.d8.loss_mask: 0.8897  decode.d8.loss_dice: 0.6550
05/26 21:33:25 - mmengine - INFO - Iter(train) [ 89950/160000]  base_lr: 4.7551e-05 lr: 4.7551e-06  eta: 8:01:21  time: 0.4184  data_time: 0.0099  memory: 5969  grad_norm: 513.9195  loss: 18.8402  decode.loss_cls: 0.1933  decode.loss_mask: 0.9312  decode.loss_dice: 0.6730  decode.d0.loss_cls: 0.7073  decode.d0.loss_mask: 0.8984  decode.d0.loss_dice: 0.6809  decode.d1.loss_cls: 0.2128  decode.d1.loss_mask: 0.9634  decode.d1.loss_dice: 0.6824  decode.d2.loss_cls: 0.1785  decode.d2.loss_mask: 1.0100  decode.d2.loss_dice: 0.7056  decode.d3.loss_cls: 0.2306  decode.d3.loss_mask: 0.8863  decode.d3.loss_dice: 0.6895  decode.d4.loss_cls: 0.2184  decode.d4.loss_mask: 0.9513  decode.d4.loss_dice: 0.6860  decode.d5.loss_cls: 0.2065  decode.d5.loss_mask: 0.9192  decode.d5.loss_dice: 0.6850  decode.d6.loss_cls: 0.2132  decode.d6.loss_mask: 0.9366  decode.d6.loss_dice: 0.6866  decode.d7.loss_cls: 0.1404  decode.d7.loss_mask: 1.0187  decode.d7.loss_dice: 0.7053  decode.d8.loss_cls: 0.1395  decode.d8.loss_mask: 0.9865  decode.d8.loss_dice: 0.7038
05/26 21:33:46 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 21:33:46 - mmengine - INFO - Iter(train) [ 90000/160000]  base_lr: 4.7521e-05 lr: 4.7521e-06  eta: 8:01:00  time: 0.4166  data_time: 0.0099  memory: 5987  grad_norm: 1930.7604  loss: 18.1765  decode.loss_cls: 0.1028  decode.loss_mask: 0.9868  decode.loss_dice: 0.6394  decode.d0.loss_cls: 0.5371  decode.d0.loss_mask: 1.0028  decode.d0.loss_dice: 0.6411  decode.d1.loss_cls: 0.1374  decode.d1.loss_mask: 0.9907  decode.d1.loss_dice: 0.6353  decode.d2.loss_cls: 0.0851  decode.d2.loss_mask: 1.0563  decode.d2.loss_dice: 0.6650  decode.d3.loss_cls: 0.1031  decode.d3.loss_mask: 1.0284  decode.d3.loss_dice: 0.6509  decode.d4.loss_cls: 0.1006  decode.d4.loss_mask: 1.0534  decode.d4.loss_dice: 0.6691  decode.d5.loss_cls: 0.1029  decode.d5.loss_mask: 1.0403  decode.d5.loss_dice: 0.6601  decode.d6.loss_cls: 0.1005  decode.d6.loss_mask: 1.0161  decode.d6.loss_dice: 0.6385  decode.d7.loss_cls: 0.0936  decode.d7.loss_mask: 1.0212  decode.d7.loss_dice: 0.6447  decode.d8.loss_cls: 0.0870  decode.d8.loss_mask: 1.0317  decode.d8.loss_dice: 0.6544
05/26 21:33:46 - mmengine - INFO - Saving checkpoint at 90000 iterations
05/26 21:33:50 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:15  time: 0.0484  data_time: 0.0012  memory: 1391  
05/26 21:33:53 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:08  time: 0.0486  data_time: 0.0012  memory: 1205  
05/26 21:33:55 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:05  time: 0.0510  data_time: 0.0013  memory: 1596  
05/26 21:33:58 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:02  time: 0.0504  data_time: 0.0013  memory: 1298  
05/26 21:34:00 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:01:00  time: 0.0493  data_time: 0.0013  memory: 1298  
05/26 21:34:03 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:57  time: 0.0503  data_time: 0.0012  memory: 1279  
05/26 21:34:05 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:55  time: 0.0491  data_time: 0.0013  memory: 1224  
05/26 21:34:08 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:52  time: 0.0506  data_time: 0.0013  memory: 1298  
05/26 21:34:10 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:50  time: 0.0484  data_time: 0.0012  memory: 1298  
05/26 21:34:13 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:47  time: 0.0527  data_time: 0.0013  memory: 1725  
05/26 21:34:15 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:44  time: 0.0487  data_time: 0.0013  memory: 1336  
05/26 21:34:18 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:42  time: 0.0486  data_time: 0.0012  memory: 1298  
05/26 21:34:20 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:39  time: 0.0491  data_time: 0.0013  memory: 1205  
05/26 21:34:23 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:37  time: 0.0496  data_time: 0.0012  memory: 1316  
05/26 21:34:25 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:34  time: 0.0480  data_time: 0.0013  memory: 1279  
05/26 21:34:27 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:32  time: 0.0520  data_time: 0.0012  memory: 1410  
05/26 21:34:30 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:29  time: 0.0484  data_time: 0.0013  memory: 1279  
05/26 21:34:32 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:27  time: 0.0506  data_time: 0.0013  memory: 1205  
05/26 21:34:35 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0488  data_time: 0.0012  memory: 1205  
05/26 21:34:37 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:22  time: 0.0487  data_time: 0.0013  memory: 1336  
05/26 21:34:40 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0484  data_time: 0.0012  memory: 1246  
05/26 21:34:42 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0516  data_time: 0.0012  memory: 1503  
05/26 21:34:45 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0481  data_time: 0.0012  memory: 1261  
05/26 21:34:47 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0529  data_time: 0.0013  memory: 1298  
05/26 21:34:50 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0484  data_time: 0.0012  memory: 1447  
05/26 21:34:52 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0490  data_time: 0.0013  memory: 1298  
05/26 21:34:55 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0493  data_time: 0.0012  memory: 1279  
05/26 21:34:57 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0509  data_time: 0.0013  memory: 1205  
05/26 21:35:00 - mmengine - INFO - per class results:
05/26 21:35:00 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.45 | 97.01 |
|  aeroplane  | 93.39 | 98.47 |
|   bicycle   | 43.01 | 97.23 |
|     bird    | 94.82 | 97.08 |
|     boat    | 66.46 | 91.86 |
|    bottle   | 81.95 |  92.4 |
|     bus     | 95.18 | 98.12 |
|     car     | 90.75 | 96.13 |
|     cat     | 94.19 | 97.12 |
|    chair    | 41.69 | 73.82 |
|     cow     |  71.1 |  93.3 |
| diningtable | 66.71 | 72.49 |
|     dog     | 89.44 |  98.5 |
|    horse    | 66.74 | 69.63 |
|  motorbike  | 92.65 | 96.78 |
|    person   | 90.43 | 95.52 |
| pottedplant | 68.94 | 91.61 |
|    sheep    | 81.69 | 92.46 |
|     sofa    | 51.77 |  60.2 |
|    train    | 93.49 | 96.15 |
|  tvmonitor  | 83.44 | 90.25 |
+-------------+-------+-------+
05/26 21:35:00 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.4400  mIoU: 78.7300  mAcc: 90.2900  data_time: 0.0013  time: 0.0494
05/26 21:35:20 - mmengine - INFO - Iter(train) [ 90050/160000]  base_lr: 4.7490e-05 lr: 4.7490e-06  eta: 8:00:40  time: 0.4179  data_time: 0.0112  memory: 5984  grad_norm: 545.2568  loss: 21.8398  decode.loss_cls: 0.2132  decode.loss_mask: 1.0523  decode.loss_dice: 0.8529  decode.d0.loss_cls: 0.6540  decode.d0.loss_mask: 1.0216  decode.d0.loss_dice: 0.8335  decode.d1.loss_cls: 0.1875  decode.d1.loss_mask: 1.0655  decode.d1.loss_dice: 0.8711  decode.d2.loss_cls: 0.2385  decode.d2.loss_mask: 1.0744  decode.d2.loss_dice: 0.8950  decode.d3.loss_cls: 0.2504  decode.d3.loss_mask: 1.0142  decode.d3.loss_dice: 0.8348  decode.d4.loss_cls: 0.2722  decode.d4.loss_mask: 1.0699  decode.d4.loss_dice: 0.8537  decode.d5.loss_cls: 0.2654  decode.d5.loss_mask: 1.0289  decode.d5.loss_dice: 0.8430  decode.d6.loss_cls: 0.2119  decode.d6.loss_mask: 1.0763  decode.d6.loss_dice: 0.8391  decode.d7.loss_cls: 0.2278  decode.d7.loss_mask: 1.0587  decode.d7.loss_dice: 0.8789  decode.d8.loss_cls: 0.2303  decode.d8.loss_mask: 1.0710  decode.d8.loss_dice: 0.8538
05/26 21:35:41 - mmengine - INFO - Iter(train) [ 90100/160000]  base_lr: 4.7460e-05 lr: 4.7460e-06  eta: 8:00:19  time: 0.4164  data_time: 0.0098  memory: 5968  grad_norm: 798.2286  loss: 24.4874  decode.loss_cls: 0.3229  decode.loss_mask: 1.2251  decode.loss_dice: 0.8469  decode.d0.loss_cls: 0.9294  decode.d0.loss_mask: 1.1463  decode.d0.loss_dice: 0.8114  decode.d1.loss_cls: 0.3622  decode.d1.loss_mask: 1.2077  decode.d1.loss_dice: 0.8312  decode.d2.loss_cls: 0.3672  decode.d2.loss_mask: 1.1789  decode.d2.loss_dice: 0.8234  decode.d3.loss_cls: 0.3547  decode.d3.loss_mask: 1.2200  decode.d3.loss_dice: 0.8302  decode.d4.loss_cls: 0.3765  decode.d4.loss_mask: 1.2257  decode.d4.loss_dice: 0.8452  decode.d5.loss_cls: 0.3678  decode.d5.loss_mask: 1.2218  decode.d5.loss_dice: 0.8160  decode.d6.loss_cls: 0.3305  decode.d6.loss_mask: 1.2480  decode.d6.loss_dice: 0.8242  decode.d7.loss_cls: 0.3397  decode.d7.loss_mask: 1.2275  decode.d7.loss_dice: 0.8321  decode.d8.loss_cls: 0.3332  decode.d8.loss_mask: 1.2063  decode.d8.loss_dice: 0.8357
05/26 21:36:02 - mmengine - INFO - Iter(train) [ 90150/160000]  base_lr: 4.7429e-05 lr: 4.7429e-06  eta: 7:59:59  time: 0.4167  data_time: 0.0098  memory: 5966  grad_norm: 425.7484  loss: 17.7531  decode.loss_cls: 0.1000  decode.loss_mask: 0.9517  decode.loss_dice: 0.6738  decode.d0.loss_cls: 0.5822  decode.d0.loss_mask: 0.8967  decode.d0.loss_dice: 0.6145  decode.d1.loss_cls: 0.0996  decode.d1.loss_mask: 0.9530  decode.d1.loss_dice: 0.6766  decode.d2.loss_cls: 0.1181  decode.d2.loss_mask: 0.9708  decode.d2.loss_dice: 0.6738  decode.d3.loss_cls: 0.1039  decode.d3.loss_mask: 0.9647  decode.d3.loss_dice: 0.6747  decode.d4.loss_cls: 0.1284  decode.d4.loss_mask: 0.9425  decode.d4.loss_dice: 0.6575  decode.d5.loss_cls: 0.1348  decode.d5.loss_mask: 0.9388  decode.d5.loss_dice: 0.6762  decode.d6.loss_cls: 0.1064  decode.d6.loss_mask: 0.9675  decode.d6.loss_dice: 0.6965  decode.d7.loss_cls: 0.1326  decode.d7.loss_mask: 0.9478  decode.d7.loss_dice: 0.6576  decode.d8.loss_cls: 0.1175  decode.d8.loss_mask: 0.9332  decode.d8.loss_dice: 0.6618
05/26 21:36:23 - mmengine - INFO - Iter(train) [ 90200/160000]  base_lr: 4.7398e-05 lr: 4.7398e-06  eta: 7:59:39  time: 0.4271  data_time: 0.0098  memory: 5967  grad_norm: 304.6753  loss: 17.8165  decode.loss_cls: 0.1356  decode.loss_mask: 0.8711  decode.loss_dice: 0.7384  decode.d0.loss_cls: 0.6551  decode.d0.loss_mask: 0.8356  decode.d0.loss_dice: 0.6903  decode.d1.loss_cls: 0.1391  decode.d1.loss_mask: 0.8786  decode.d1.loss_dice: 0.7177  decode.d2.loss_cls: 0.1470  decode.d2.loss_mask: 0.8661  decode.d2.loss_dice: 0.7055  decode.d3.loss_cls: 0.1780  decode.d3.loss_mask: 0.8805  decode.d3.loss_dice: 0.7228  decode.d4.loss_cls: 0.1485  decode.d4.loss_mask: 0.8698  decode.d4.loss_dice: 0.7064  decode.d5.loss_cls: 0.1524  decode.d5.loss_mask: 0.8669  decode.d5.loss_dice: 0.7020  decode.d6.loss_cls: 0.1469  decode.d6.loss_mask: 0.8668  decode.d6.loss_dice: 0.7021  decode.d7.loss_cls: 0.1622  decode.d7.loss_mask: 0.8759  decode.d7.loss_dice: 0.7267  decode.d8.loss_cls: 0.1276  decode.d8.loss_mask: 0.8777  decode.d8.loss_dice: 0.7229
05/26 21:36:44 - mmengine - INFO - Iter(train) [ 90250/160000]  base_lr: 4.7368e-05 lr: 4.7368e-06  eta: 7:59:18  time: 0.4158  data_time: 0.0097  memory: 5969  grad_norm: 572.3624  loss: 23.3681  decode.loss_cls: 0.2496  decode.loss_mask: 1.1923  decode.loss_dice: 0.8193  decode.d0.loss_cls: 0.8399  decode.d0.loss_mask: 1.1185  decode.d0.loss_dice: 0.8332  decode.d1.loss_cls: 0.2433  decode.d1.loss_mask: 1.1876  decode.d1.loss_dice: 0.8438  decode.d2.loss_cls: 0.2023  decode.d2.loss_mask: 1.2051  decode.d2.loss_dice: 0.8413  decode.d3.loss_cls: 0.2214  decode.d3.loss_mask: 1.2404  decode.d3.loss_dice: 0.8546  decode.d4.loss_cls: 0.2692  decode.d4.loss_mask: 1.2076  decode.d4.loss_dice: 0.8560  decode.d5.loss_cls: 0.2716  decode.d5.loss_mask: 1.1909  decode.d5.loss_dice: 0.8422  decode.d6.loss_cls: 0.2345  decode.d6.loss_mask: 1.2272  decode.d6.loss_dice: 0.8521  decode.d7.loss_cls: 0.1947  decode.d7.loss_mask: 1.2184  decode.d7.loss_dice: 0.8494  decode.d8.loss_cls: 0.2279  decode.d8.loss_mask: 1.2006  decode.d8.loss_dice: 0.8336
05/26 21:37:05 - mmengine - INFO - Iter(train) [ 90300/160000]  base_lr: 4.7337e-05 lr: 4.7337e-06  eta: 7:58:58  time: 0.4161  data_time: 0.0097  memory: 5971  grad_norm: 509.8969  loss: 22.6785  decode.loss_cls: 0.1822  decode.loss_mask: 1.1264  decode.loss_dice: 0.8588  decode.d0.loss_cls: 0.6811  decode.d0.loss_mask: 1.1119  decode.d0.loss_dice: 0.8841  decode.d1.loss_cls: 0.2439  decode.d1.loss_mask: 1.1538  decode.d1.loss_dice: 0.8748  decode.d2.loss_cls: 0.2574  decode.d2.loss_mask: 1.1383  decode.d2.loss_dice: 0.8627  decode.d3.loss_cls: 0.2413  decode.d3.loss_mask: 1.1343  decode.d3.loss_dice: 0.8654  decode.d4.loss_cls: 0.2190  decode.d4.loss_mask: 1.1119  decode.d4.loss_dice: 0.8808  decode.d5.loss_cls: 0.2164  decode.d5.loss_mask: 1.1035  decode.d5.loss_dice: 0.8568  decode.d6.loss_cls: 0.2208  decode.d6.loss_mask: 1.1699  decode.d6.loss_dice: 0.8590  decode.d7.loss_cls: 0.2054  decode.d7.loss_mask: 1.1274  decode.d7.loss_dice: 0.8855  decode.d8.loss_cls: 0.2205  decode.d8.loss_mask: 1.1249  decode.d8.loss_dice: 0.8604
05/26 21:37:26 - mmengine - INFO - Iter(train) [ 90350/160000]  base_lr: 4.7307e-05 lr: 4.7307e-06  eta: 7:58:37  time: 0.4168  data_time: 0.0098  memory: 5967  grad_norm: 487.7211  loss: 18.6910  decode.loss_cls: 0.1712  decode.loss_mask: 0.9317  decode.loss_dice: 0.6854  decode.d0.loss_cls: 0.7313  decode.d0.loss_mask: 0.9264  decode.d0.loss_dice: 0.7269  decode.d1.loss_cls: 0.1658  decode.d1.loss_mask: 0.9525  decode.d1.loss_dice: 0.6990  decode.d2.loss_cls: 0.1837  decode.d2.loss_mask: 0.9345  decode.d2.loss_dice: 0.7010  decode.d3.loss_cls: 0.2094  decode.d3.loss_mask: 0.9116  decode.d3.loss_dice: 0.6944  decode.d4.loss_cls: 0.1930  decode.d4.loss_mask: 0.9352  decode.d4.loss_dice: 0.6845  decode.d5.loss_cls: 0.1741  decode.d5.loss_mask: 0.9454  decode.d5.loss_dice: 0.7082  decode.d6.loss_cls: 0.1994  decode.d6.loss_mask: 0.9260  decode.d6.loss_dice: 0.6837  decode.d7.loss_cls: 0.1638  decode.d7.loss_mask: 0.9438  decode.d7.loss_dice: 0.6932  decode.d8.loss_cls: 0.1751  decode.d8.loss_mask: 0.9443  decode.d8.loss_dice: 0.6964
05/26 21:37:46 - mmengine - INFO - Iter(train) [ 90400/160000]  base_lr: 4.7276e-05 lr: 4.7276e-06  eta: 7:58:17  time: 0.4161  data_time: 0.0097  memory: 5967  grad_norm: 477.2088  loss: 20.9211  decode.loss_cls: 0.2314  decode.loss_mask: 1.0875  decode.loss_dice: 0.7154  decode.d0.loss_cls: 0.7997  decode.d0.loss_mask: 1.0258  decode.d0.loss_dice: 0.6899  decode.d1.loss_cls: 0.1782  decode.d1.loss_mask: 1.1295  decode.d1.loss_dice: 0.7594  decode.d2.loss_cls: 0.1704  decode.d2.loss_mask: 1.1259  decode.d2.loss_dice: 0.7674  decode.d3.loss_cls: 0.1781  decode.d3.loss_mask: 1.1372  decode.d3.loss_dice: 0.7675  decode.d4.loss_cls: 0.1774  decode.d4.loss_mask: 1.1367  decode.d4.loss_dice: 0.7497  decode.d5.loss_cls: 0.1724  decode.d5.loss_mask: 1.0971  decode.d5.loss_dice: 0.7355  decode.d6.loss_cls: 0.2285  decode.d6.loss_mask: 1.0500  decode.d6.loss_dice: 0.7150  decode.d7.loss_cls: 0.2225  decode.d7.loss_mask: 1.0896  decode.d7.loss_dice: 0.7463  decode.d8.loss_cls: 0.1748  decode.d8.loss_mask: 1.1094  decode.d8.loss_dice: 0.7529
05/26 21:38:07 - mmengine - INFO - Iter(train) [ 90450/160000]  base_lr: 4.7246e-05 lr: 4.7246e-06  eta: 7:57:56  time: 0.4161  data_time: 0.0097  memory: 5983  grad_norm: 900.2972  loss: 19.1717  decode.loss_cls: 0.1049  decode.loss_mask: 1.0608  decode.loss_dice: 0.7082  decode.d0.loss_cls: 0.6503  decode.d0.loss_mask: 1.0073  decode.d0.loss_dice: 0.6971  decode.d1.loss_cls: 0.1150  decode.d1.loss_mask: 1.0031  decode.d1.loss_dice: 0.6914  decode.d2.loss_cls: 0.1075  decode.d2.loss_mask: 1.0803  decode.d2.loss_dice: 0.7160  decode.d3.loss_cls: 0.1039  decode.d3.loss_mask: 1.0774  decode.d3.loss_dice: 0.7101  decode.d4.loss_cls: 0.1458  decode.d4.loss_mask: 1.0469  decode.d4.loss_dice: 0.6862  decode.d5.loss_cls: 0.1145  decode.d5.loss_mask: 1.0333  decode.d5.loss_dice: 0.6944  decode.d6.loss_cls: 0.1160  decode.d6.loss_mask: 1.0334  decode.d6.loss_dice: 0.7134  decode.d7.loss_cls: 0.1194  decode.d7.loss_mask: 1.0407  decode.d7.loss_dice: 0.7074  decode.d8.loss_cls: 0.1452  decode.d8.loss_mask: 1.0355  decode.d8.loss_dice: 0.7064
05/26 21:38:28 - mmengine - INFO - Iter(train) [ 90500/160000]  base_lr: 4.7215e-05 lr: 4.7215e-06  eta: 7:57:36  time: 0.4161  data_time: 0.0098  memory: 5976  grad_norm: 457.5762  loss: 19.2359  decode.loss_cls: 0.2142  decode.loss_mask: 0.9699  decode.loss_dice: 0.6733  decode.d0.loss_cls: 0.6058  decode.d0.loss_mask: 0.9760  decode.d0.loss_dice: 0.6775  decode.d1.loss_cls: 0.2577  decode.d1.loss_mask: 0.9927  decode.d1.loss_dice: 0.6716  decode.d2.loss_cls: 0.2858  decode.d2.loss_mask: 0.9688  decode.d2.loss_dice: 0.6577  decode.d3.loss_cls: 0.2507  decode.d3.loss_mask: 0.9673  decode.d3.loss_dice: 0.6853  decode.d4.loss_cls: 0.2060  decode.d4.loss_mask: 0.9733  decode.d4.loss_dice: 0.6674  decode.d5.loss_cls: 0.2292  decode.d5.loss_mask: 0.9975  decode.d5.loss_dice: 0.6637  decode.d6.loss_cls: 0.2235  decode.d6.loss_mask: 1.0077  decode.d6.loss_dice: 0.6581  decode.d7.loss_cls: 0.2165  decode.d7.loss_mask: 0.9557  decode.d7.loss_dice: 0.6660  decode.d8.loss_cls: 0.2427  decode.d8.loss_mask: 1.0104  decode.d8.loss_dice: 0.6638
05/26 21:38:49 - mmengine - INFO - Iter(train) [ 90550/160000]  base_lr: 4.7185e-05 lr: 4.7185e-06  eta: 7:57:16  time: 0.4170  data_time: 0.0098  memory: 5969  grad_norm: 286.2392  loss: 18.3875  decode.loss_cls: 0.1936  decode.loss_mask: 0.8741  decode.loss_dice: 0.7125  decode.d0.loss_cls: 0.6762  decode.d0.loss_mask: 0.8731  decode.d0.loss_dice: 0.6914  decode.d1.loss_cls: 0.1733  decode.d1.loss_mask: 0.9034  decode.d1.loss_dice: 0.7196  decode.d2.loss_cls: 0.1700  decode.d2.loss_mask: 0.8815  decode.d2.loss_dice: 0.7293  decode.d3.loss_cls: 0.1839  decode.d3.loss_mask: 0.8976  decode.d3.loss_dice: 0.7268  decode.d4.loss_cls: 0.1669  decode.d4.loss_mask: 0.8909  decode.d4.loss_dice: 0.7156  decode.d5.loss_cls: 0.1879  decode.d5.loss_mask: 0.8724  decode.d5.loss_dice: 0.7192  decode.d6.loss_cls: 0.1990  decode.d6.loss_mask: 0.8923  decode.d6.loss_dice: 0.7474  decode.d7.loss_cls: 0.1832  decode.d7.loss_mask: 0.8984  decode.d7.loss_dice: 0.7349  decode.d8.loss_cls: 0.1659  decode.d8.loss_mask: 0.8743  decode.d8.loss_dice: 0.7327
05/26 21:39:10 - mmengine - INFO - Iter(train) [ 90600/160000]  base_lr: 4.7154e-05 lr: 4.7154e-06  eta: 7:56:55  time: 0.4160  data_time: 0.0097  memory: 5968  grad_norm: 773.1732  loss: 25.2579  decode.loss_cls: 0.2529  decode.loss_mask: 1.3169  decode.loss_dice: 0.8557  decode.d0.loss_cls: 0.8130  decode.d0.loss_mask: 1.1824  decode.d0.loss_dice: 0.8355  decode.d1.loss_cls: 0.2234  decode.d1.loss_mask: 1.3493  decode.d1.loss_dice: 0.9179  decode.d2.loss_cls: 0.2766  decode.d2.loss_mask: 1.3486  decode.d2.loss_dice: 0.9031  decode.d3.loss_cls: 0.2333  decode.d3.loss_mask: 1.3476  decode.d3.loss_dice: 0.8900  decode.d4.loss_cls: 0.2917  decode.d4.loss_mask: 1.3979  decode.d4.loss_dice: 0.8879  decode.d5.loss_cls: 0.2673  decode.d5.loss_mask: 1.3183  decode.d5.loss_dice: 0.8900  decode.d6.loss_cls: 0.2184  decode.d6.loss_mask: 1.3560  decode.d6.loss_dice: 0.9321  decode.d7.loss_cls: 0.2858  decode.d7.loss_mask: 1.3364  decode.d7.loss_dice: 0.9123  decode.d8.loss_cls: 0.2904  decode.d8.loss_mask: 1.2932  decode.d8.loss_dice: 0.8340
05/26 21:39:31 - mmengine - INFO - Iter(train) [ 90650/160000]  base_lr: 4.7123e-05 lr: 4.7123e-06  eta: 7:56:35  time: 0.4176  data_time: 0.0100  memory: 5966  grad_norm: 541.0108  loss: 19.6727  decode.loss_cls: 0.1834  decode.loss_mask: 0.9936  decode.loss_dice: 0.7222  decode.d0.loss_cls: 0.6557  decode.d0.loss_mask: 0.9874  decode.d0.loss_dice: 0.7427  decode.d1.loss_cls: 0.1673  decode.d1.loss_mask: 1.0299  decode.d1.loss_dice: 0.7613  decode.d2.loss_cls: 0.1733  decode.d2.loss_mask: 1.0132  decode.d2.loss_dice: 0.7303  decode.d3.loss_cls: 0.1667  decode.d3.loss_mask: 0.9984  decode.d3.loss_dice: 0.7279  decode.d4.loss_cls: 0.1897  decode.d4.loss_mask: 0.9933  decode.d4.loss_dice: 0.7052  decode.d5.loss_cls: 0.1845  decode.d5.loss_mask: 0.9825  decode.d5.loss_dice: 0.7391  decode.d6.loss_cls: 0.1704  decode.d6.loss_mask: 1.0285  decode.d6.loss_dice: 0.7602  decode.d7.loss_cls: 0.1937  decode.d7.loss_mask: 1.0308  decode.d7.loss_dice: 0.7353  decode.d8.loss_cls: 0.1839  decode.d8.loss_mask: 1.0047  decode.d8.loss_dice: 0.7175
05/26 21:39:52 - mmengine - INFO - Iter(train) [ 90700/160000]  base_lr: 4.7093e-05 lr: 4.7093e-06  eta: 7:56:14  time: 0.4185  data_time: 0.0099  memory: 5970  grad_norm: 519.0089  loss: 18.0986  decode.loss_cls: 0.2341  decode.loss_mask: 0.8701  decode.loss_dice: 0.6783  decode.d0.loss_cls: 0.6329  decode.d0.loss_mask: 0.8418  decode.d0.loss_dice: 0.6971  decode.d1.loss_cls: 0.2655  decode.d1.loss_mask: 0.8707  decode.d1.loss_dice: 0.6614  decode.d2.loss_cls: 0.1783  decode.d2.loss_mask: 0.8773  decode.d2.loss_dice: 0.6737  decode.d3.loss_cls: 0.2060  decode.d3.loss_mask: 0.8880  decode.d3.loss_dice: 0.6701  decode.d4.loss_cls: 0.2212  decode.d4.loss_mask: 0.8439  decode.d4.loss_dice: 0.6773  decode.d5.loss_cls: 0.2468  decode.d5.loss_mask: 0.8779  decode.d5.loss_dice: 0.6673  decode.d6.loss_cls: 0.2335  decode.d6.loss_mask: 0.8590  decode.d6.loss_dice: 0.6822  decode.d7.loss_cls: 0.2209  decode.d7.loss_mask: 0.8701  decode.d7.loss_dice: 0.7210  decode.d8.loss_cls: 0.2374  decode.d8.loss_mask: 0.8412  decode.d8.loss_dice: 0.6538
05/26 21:40:12 - mmengine - INFO - Iter(train) [ 90750/160000]  base_lr: 4.7062e-05 lr: 4.7062e-06  eta: 7:55:54  time: 0.4195  data_time: 0.0100  memory: 5972  grad_norm: 489.0217  loss: 22.8875  decode.loss_cls: 0.2327  decode.loss_mask: 1.0924  decode.loss_dice: 0.9175  decode.d0.loss_cls: 0.7475  decode.d0.loss_mask: 1.0454  decode.d0.loss_dice: 0.9396  decode.d1.loss_cls: 0.2359  decode.d1.loss_mask: 1.1542  decode.d1.loss_dice: 0.9598  decode.d2.loss_cls: 0.1970  decode.d2.loss_mask: 1.0840  decode.d2.loss_dice: 0.8958  decode.d3.loss_cls: 0.2155  decode.d3.loss_mask: 1.0906  decode.d3.loss_dice: 0.9222  decode.d4.loss_cls: 0.2239  decode.d4.loss_mask: 1.0886  decode.d4.loss_dice: 0.8999  decode.d5.loss_cls: 0.2077  decode.d5.loss_mask: 1.1291  decode.d5.loss_dice: 0.9107  decode.d6.loss_cls: 0.2202  decode.d6.loss_mask: 1.0963  decode.d6.loss_dice: 0.9134  decode.d7.loss_cls: 0.2202  decode.d7.loss_mask: 1.0713  decode.d7.loss_dice: 0.9055  decode.d8.loss_cls: 0.2739  decode.d8.loss_mask: 1.0886  decode.d8.loss_dice: 0.9082
05/26 21:40:34 - mmengine - INFO - Iter(train) [ 90800/160000]  base_lr: 4.7032e-05 lr: 4.7032e-06  eta: 7:55:34  time: 0.4186  data_time: 0.0102  memory: 5984  grad_norm: 515.8303  loss: 20.2595  decode.loss_cls: 0.1598  decode.loss_mask: 1.0300  decode.loss_dice: 0.7382  decode.d0.loss_cls: 0.6271  decode.d0.loss_mask: 1.0447  decode.d0.loss_dice: 0.7197  decode.d1.loss_cls: 0.1628  decode.d1.loss_mask: 1.0607  decode.d1.loss_dice: 0.7418  decode.d2.loss_cls: 0.1841  decode.d2.loss_mask: 1.0680  decode.d2.loss_dice: 0.7555  decode.d3.loss_cls: 0.1687  decode.d3.loss_mask: 1.0893  decode.d3.loss_dice: 0.7468  decode.d4.loss_cls: 0.1470  decode.d4.loss_mask: 1.0696  decode.d4.loss_dice: 0.7224  decode.d5.loss_cls: 0.1644  decode.d5.loss_mask: 1.0882  decode.d5.loss_dice: 0.7444  decode.d6.loss_cls: 0.2054  decode.d6.loss_mask: 1.0623  decode.d6.loss_dice: 0.7360  decode.d7.loss_cls: 0.2132  decode.d7.loss_mask: 1.0574  decode.d7.loss_dice: 0.7350  decode.d8.loss_cls: 0.1808  decode.d8.loss_mask: 1.0831  decode.d8.loss_dice: 0.7532
05/26 21:40:54 - mmengine - INFO - Iter(train) [ 90850/160000]  base_lr: 4.7001e-05 lr: 4.7001e-06  eta: 7:55:13  time: 0.4134  data_time: 0.0097  memory: 5970  grad_norm: 771.5024  loss: 20.6273  decode.loss_cls: 0.1794  decode.loss_mask: 1.1073  decode.loss_dice: 0.6928  decode.d0.loss_cls: 0.6606  decode.d0.loss_mask: 1.0249  decode.d0.loss_dice: 0.7240  decode.d1.loss_cls: 0.2352  decode.d1.loss_mask: 1.1361  decode.d1.loss_dice: 0.7296  decode.d2.loss_cls: 0.2369  decode.d2.loss_mask: 1.0519  decode.d2.loss_dice: 0.7289  decode.d3.loss_cls: 0.2792  decode.d3.loss_mask: 1.0517  decode.d3.loss_dice: 0.7241  decode.d4.loss_cls: 0.2381  decode.d4.loss_mask: 1.0715  decode.d4.loss_dice: 0.7312  decode.d5.loss_cls: 0.2439  decode.d5.loss_mask: 1.0565  decode.d5.loss_dice: 0.7286  decode.d6.loss_cls: 0.2500  decode.d6.loss_mask: 1.0361  decode.d6.loss_dice: 0.7106  decode.d7.loss_cls: 0.2160  decode.d7.loss_mask: 1.0774  decode.d7.loss_dice: 0.7187  decode.d8.loss_cls: 0.2172  decode.d8.loss_mask: 1.0574  decode.d8.loss_dice: 0.7119
05/26 21:41:15 - mmengine - INFO - Iter(train) [ 90900/160000]  base_lr: 4.6970e-05 lr: 4.6970e-06  eta: 7:54:52  time: 0.4131  data_time: 0.0097  memory: 5969  grad_norm: 861.6854  loss: 17.5378  decode.loss_cls: 0.1994  decode.loss_mask: 0.8384  decode.loss_dice: 0.6425  decode.d0.loss_cls: 0.8109  decode.d0.loss_mask: 0.7388  decode.d0.loss_dice: 0.5532  decode.d1.loss_cls: 0.2278  decode.d1.loss_mask: 0.8385  decode.d1.loss_dice: 0.6401  decode.d2.loss_cls: 0.2341  decode.d2.loss_mask: 0.8451  decode.d2.loss_dice: 0.6342  decode.d3.loss_cls: 0.2587  decode.d3.loss_mask: 0.8398  decode.d3.loss_dice: 0.6385  decode.d4.loss_cls: 0.2126  decode.d4.loss_mask: 0.8690  decode.d4.loss_dice: 0.6405  decode.d5.loss_cls: 0.2294  decode.d5.loss_mask: 0.8362  decode.d5.loss_dice: 0.6297  decode.d6.loss_cls: 0.2001  decode.d6.loss_mask: 0.8262  decode.d6.loss_dice: 0.6358  decode.d7.loss_cls: 0.2191  decode.d7.loss_mask: 0.8781  decode.d7.loss_dice: 0.6490  decode.d8.loss_cls: 0.2089  decode.d8.loss_mask: 0.9211  decode.d8.loss_dice: 0.6421
05/26 21:41:36 - mmengine - INFO - Iter(train) [ 90950/160000]  base_lr: 4.6940e-05 lr: 4.6940e-06  eta: 7:54:32  time: 0.4173  data_time: 0.0100  memory: 5976  grad_norm: 646.4421  loss: 25.0339  decode.loss_cls: 0.4041  decode.loss_mask: 1.1578  decode.loss_dice: 0.8825  decode.d0.loss_cls: 0.8810  decode.d0.loss_mask: 1.1587  decode.d0.loss_dice: 0.8854  decode.d1.loss_cls: 0.3913  decode.d1.loss_mask: 1.1538  decode.d1.loss_dice: 0.8760  decode.d2.loss_cls: 0.4304  decode.d2.loss_mask: 1.1357  decode.d2.loss_dice: 0.8706  decode.d3.loss_cls: 0.3631  decode.d3.loss_mask: 1.1353  decode.d3.loss_dice: 0.8750  decode.d4.loss_cls: 0.3515  decode.d4.loss_mask: 1.1995  decode.d4.loss_dice: 0.9295  decode.d5.loss_cls: 0.3356  decode.d5.loss_mask: 1.1748  decode.d5.loss_dice: 0.9229  decode.d6.loss_cls: 0.3616  decode.d6.loss_mask: 1.2065  decode.d6.loss_dice: 0.9129  decode.d7.loss_cls: 0.4042  decode.d7.loss_mask: 1.1637  decode.d7.loss_dice: 0.8817  decode.d8.loss_cls: 0.4280  decode.d8.loss_mask: 1.2532  decode.d8.loss_dice: 0.9076
05/26 21:41:57 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 21:41:57 - mmengine - INFO - Iter(train) [ 91000/160000]  base_lr: 4.6909e-05 lr: 4.6909e-06  eta: 7:54:12  time: 0.4200  data_time: 0.0101  memory: 5967  grad_norm: 418.6269  loss: 22.4341  decode.loss_cls: 0.3094  decode.loss_mask: 1.0814  decode.loss_dice: 0.8200  decode.d0.loss_cls: 0.7475  decode.d0.loss_mask: 1.0232  decode.d0.loss_dice: 0.8263  decode.d1.loss_cls: 0.2936  decode.d1.loss_mask: 1.0689  decode.d1.loss_dice: 0.7991  decode.d2.loss_cls: 0.2986  decode.d2.loss_mask: 1.0498  decode.d2.loss_dice: 0.8265  decode.d3.loss_cls: 0.2577  decode.d3.loss_mask: 1.0921  decode.d3.loss_dice: 0.8832  decode.d4.loss_cls: 0.3223  decode.d4.loss_mask: 1.0622  decode.d4.loss_dice: 0.8483  decode.d5.loss_cls: 0.2577  decode.d5.loss_mask: 1.0755  decode.d5.loss_dice: 0.8545  decode.d6.loss_cls: 0.3004  decode.d6.loss_mask: 1.0771  decode.d6.loss_dice: 0.8644  decode.d7.loss_cls: 0.3172  decode.d7.loss_mask: 1.0661  decode.d7.loss_dice: 0.8439  decode.d8.loss_cls: 0.2613  decode.d8.loss_mask: 1.0841  decode.d8.loss_dice: 0.8218
05/26 21:42:18 - mmengine - INFO - Iter(train) [ 91050/160000]  base_lr: 4.6879e-05 lr: 4.6879e-06  eta: 7:53:51  time: 0.4182  data_time: 0.0098  memory: 5970  grad_norm: 785.2757  loss: 20.3465  decode.loss_cls: 0.3143  decode.loss_mask: 0.9606  decode.loss_dice: 0.7089  decode.d0.loss_cls: 0.9221  decode.d0.loss_mask: 0.8741  decode.d0.loss_dice: 0.6578  decode.d1.loss_cls: 0.2944  decode.d1.loss_mask: 0.9631  decode.d1.loss_dice: 0.7584  decode.d2.loss_cls: 0.2877  decode.d2.loss_mask: 0.9526  decode.d2.loss_dice: 0.7130  decode.d3.loss_cls: 0.2756  decode.d3.loss_mask: 0.9323  decode.d3.loss_dice: 0.7225  decode.d4.loss_cls: 0.3164  decode.d4.loss_mask: 0.9291  decode.d4.loss_dice: 0.7290  decode.d5.loss_cls: 0.3324  decode.d5.loss_mask: 0.9284  decode.d5.loss_dice: 0.7250  decode.d6.loss_cls: 0.3153  decode.d6.loss_mask: 0.9537  decode.d6.loss_dice: 0.7188  decode.d7.loss_cls: 0.2958  decode.d7.loss_mask: 1.0230  decode.d7.loss_dice: 0.7375  decode.d8.loss_cls: 0.3436  decode.d8.loss_mask: 0.9488  decode.d8.loss_dice: 0.7125
05/26 21:42:39 - mmengine - INFO - Iter(train) [ 91100/160000]  base_lr: 4.6848e-05 lr: 4.6848e-06  eta: 7:53:31  time: 0.4178  data_time: 0.0100  memory: 5975  grad_norm: 591.8733  loss: 21.4542  decode.loss_cls: 0.2955  decode.loss_mask: 1.0765  decode.loss_dice: 0.7834  decode.d0.loss_cls: 0.7426  decode.d0.loss_mask: 1.0141  decode.d0.loss_dice: 0.6961  decode.d1.loss_cls: 0.2727  decode.d1.loss_mask: 1.0806  decode.d1.loss_dice: 0.7907  decode.d2.loss_cls: 0.2708  decode.d2.loss_mask: 1.0565  decode.d2.loss_dice: 0.7472  decode.d3.loss_cls: 0.2801  decode.d3.loss_mask: 1.0437  decode.d3.loss_dice: 0.7345  decode.d4.loss_cls: 0.2900  decode.d4.loss_mask: 1.0320  decode.d4.loss_dice: 0.7481  decode.d5.loss_cls: 0.2432  decode.d5.loss_mask: 1.0915  decode.d5.loss_dice: 0.7881  decode.d6.loss_cls: 0.2531  decode.d6.loss_mask: 1.0652  decode.d6.loss_dice: 0.7950  decode.d7.loss_cls: 0.2714  decode.d7.loss_mask: 1.1167  decode.d7.loss_dice: 0.7618  decode.d8.loss_cls: 0.2894  decode.d8.loss_mask: 1.0672  decode.d8.loss_dice: 0.7564
05/26 21:43:00 - mmengine - INFO - Iter(train) [ 91150/160000]  base_lr: 4.6817e-05 lr: 4.6817e-06  eta: 7:53:10  time: 0.4193  data_time: 0.0110  memory: 5976  grad_norm: 313.5795  loss: 18.6520  decode.loss_cls: 0.1865  decode.loss_mask: 0.9233  decode.loss_dice: 0.6876  decode.d0.loss_cls: 0.6421  decode.d0.loss_mask: 0.9044  decode.d0.loss_dice: 0.7054  decode.d1.loss_cls: 0.1873  decode.d1.loss_mask: 0.9366  decode.d1.loss_dice: 0.7285  decode.d2.loss_cls: 0.2061  decode.d2.loss_mask: 0.9243  decode.d2.loss_dice: 0.7059  decode.d3.loss_cls: 0.1987  decode.d3.loss_mask: 0.9291  decode.d3.loss_dice: 0.7083  decode.d4.loss_cls: 0.2067  decode.d4.loss_mask: 0.9105  decode.d4.loss_dice: 0.6922  decode.d5.loss_cls: 0.1987  decode.d5.loss_mask: 0.9108  decode.d5.loss_dice: 0.6995  decode.d6.loss_cls: 0.1785  decode.d6.loss_mask: 0.9360  decode.d6.loss_dice: 0.6920  decode.d7.loss_cls: 0.2342  decode.d7.loss_mask: 0.9184  decode.d7.loss_dice: 0.7089  decode.d8.loss_cls: 0.1724  decode.d8.loss_mask: 0.9130  decode.d8.loss_dice: 0.7060
05/26 21:43:21 - mmengine - INFO - Iter(train) [ 91200/160000]  base_lr: 4.6787e-05 lr: 4.6787e-06  eta: 7:52:50  time: 0.4220  data_time: 0.0105  memory: 5967  grad_norm: 494.6547  loss: 20.2550  decode.loss_cls: 0.1401  decode.loss_mask: 1.0763  decode.loss_dice: 0.7418  decode.d0.loss_cls: 0.5430  decode.d0.loss_mask: 1.0748  decode.d0.loss_dice: 0.7580  decode.d1.loss_cls: 0.1447  decode.d1.loss_mask: 1.0824  decode.d1.loss_dice: 0.7498  decode.d2.loss_cls: 0.1242  decode.d2.loss_mask: 1.1198  decode.d2.loss_dice: 0.7440  decode.d3.loss_cls: 0.1192  decode.d3.loss_mask: 1.1151  decode.d3.loss_dice: 0.7689  decode.d4.loss_cls: 0.1207  decode.d4.loss_mask: 1.1231  decode.d4.loss_dice: 0.7764  decode.d5.loss_cls: 0.1038  decode.d5.loss_mask: 1.1275  decode.d5.loss_dice: 0.7533  decode.d6.loss_cls: 0.1032  decode.d6.loss_mask: 1.1205  decode.d6.loss_dice: 0.7682  decode.d7.loss_cls: 0.0981  decode.d7.loss_mask: 1.1181  decode.d7.loss_dice: 0.7522  decode.d8.loss_cls: 0.1149  decode.d8.loss_mask: 1.1238  decode.d8.loss_dice: 0.7492
05/26 21:43:42 - mmengine - INFO - Iter(train) [ 91250/160000]  base_lr: 4.6756e-05 lr: 4.6756e-06  eta: 7:52:30  time: 0.4297  data_time: 0.0103  memory: 5976  grad_norm: 594.0247  loss: 18.3946  decode.loss_cls: 0.1254  decode.loss_mask: 1.0452  decode.loss_dice: 0.6361  decode.d0.loss_cls: 0.5695  decode.d0.loss_mask: 0.9791  decode.d0.loss_dice: 0.6328  decode.d1.loss_cls: 0.1629  decode.d1.loss_mask: 0.9781  decode.d1.loss_dice: 0.6376  decode.d2.loss_cls: 0.1110  decode.d2.loss_mask: 1.0489  decode.d2.loss_dice: 0.6551  decode.d3.loss_cls: 0.1079  decode.d3.loss_mask: 1.0516  decode.d3.loss_dice: 0.6586  decode.d4.loss_cls: 0.1273  decode.d4.loss_mask: 1.0429  decode.d4.loss_dice: 0.6454  decode.d5.loss_cls: 0.1037  decode.d5.loss_mask: 1.0570  decode.d5.loss_dice: 0.6563  decode.d6.loss_cls: 0.1079  decode.d6.loss_mask: 1.0115  decode.d6.loss_dice: 0.6316  decode.d7.loss_cls: 0.1172  decode.d7.loss_mask: 1.0589  decode.d7.loss_dice: 0.6549  decode.d8.loss_cls: 0.1015  decode.d8.loss_mask: 1.0379  decode.d8.loss_dice: 0.6406
05/26 21:44:03 - mmengine - INFO - Iter(train) [ 91300/160000]  base_lr: 4.6726e-05 lr: 4.6726e-06  eta: 7:52:09  time: 0.4178  data_time: 0.0102  memory: 5967  grad_norm: 717.2935  loss: 23.6892  decode.loss_cls: 0.2779  decode.loss_mask: 1.1550  decode.loss_dice: 0.8643  decode.d0.loss_cls: 0.8350  decode.d0.loss_mask: 1.0805  decode.d0.loss_dice: 0.8691  decode.d1.loss_cls: 0.3037  decode.d1.loss_mask: 1.1968  decode.d1.loss_dice: 0.9129  decode.d2.loss_cls: 0.2803  decode.d2.loss_mask: 1.1944  decode.d2.loss_dice: 0.8839  decode.d3.loss_cls: 0.3293  decode.d3.loss_mask: 1.1005  decode.d3.loss_dice: 0.8490  decode.d4.loss_cls: 0.2861  decode.d4.loss_mask: 1.1683  decode.d4.loss_dice: 0.8706  decode.d5.loss_cls: 0.2697  decode.d5.loss_mask: 1.1651  decode.d5.loss_dice: 0.8639  decode.d6.loss_cls: 0.2616  decode.d6.loss_mask: 1.1647  decode.d6.loss_dice: 0.8867  decode.d7.loss_cls: 0.2787  decode.d7.loss_mask: 1.1394  decode.d7.loss_dice: 0.8836  decode.d8.loss_cls: 0.2782  decode.d8.loss_mask: 1.1560  decode.d8.loss_dice: 0.8842
05/26 21:44:24 - mmengine - INFO - Iter(train) [ 91350/160000]  base_lr: 4.6695e-05 lr: 4.6695e-06  eta: 7:51:49  time: 0.4181  data_time: 0.0103  memory: 5975  grad_norm: 548.5455  loss: 22.5057  decode.loss_cls: 0.3447  decode.loss_mask: 1.0581  decode.loss_dice: 0.7854  decode.d0.loss_cls: 0.8795  decode.d0.loss_mask: 1.0375  decode.d0.loss_dice: 0.8163  decode.d1.loss_cls: 0.3157  decode.d1.loss_mask: 1.0718  decode.d1.loss_dice: 0.7631  decode.d2.loss_cls: 0.3245  decode.d2.loss_mask: 1.0833  decode.d2.loss_dice: 0.7814  decode.d3.loss_cls: 0.3755  decode.d3.loss_mask: 1.1341  decode.d3.loss_dice: 0.7966  decode.d4.loss_cls: 0.2938  decode.d4.loss_mask: 1.1330  decode.d4.loss_dice: 0.8347  decode.d5.loss_cls: 0.3582  decode.d5.loss_mask: 1.0574  decode.d5.loss_dice: 0.7297  decode.d6.loss_cls: 0.3593  decode.d6.loss_mask: 1.0616  decode.d6.loss_dice: 0.7488  decode.d7.loss_cls: 0.3364  decode.d7.loss_mask: 1.0703  decode.d7.loss_dice: 0.7826  decode.d8.loss_cls: 0.3107  decode.d8.loss_mask: 1.0714  decode.d8.loss_dice: 0.7904
05/26 21:44:45 - mmengine - INFO - Iter(train) [ 91400/160000]  base_lr: 4.6664e-05 lr: 4.6664e-06  eta: 7:51:29  time: 0.4185  data_time: 0.0102  memory: 5966  grad_norm: 466.9995  loss: 20.0666  decode.loss_cls: 0.1002  decode.loss_mask: 1.0806  decode.loss_dice: 0.7715  decode.d0.loss_cls: 0.6295  decode.d0.loss_mask: 1.0096  decode.d0.loss_dice: 0.7443  decode.d1.loss_cls: 0.0960  decode.d1.loss_mask: 1.1116  decode.d1.loss_dice: 0.7728  decode.d2.loss_cls: 0.1426  decode.d2.loss_mask: 1.0789  decode.d2.loss_dice: 0.7690  decode.d3.loss_cls: 0.0861  decode.d3.loss_mask: 1.0891  decode.d3.loss_dice: 0.7724  decode.d4.loss_cls: 0.1260  decode.d4.loss_mask: 1.0775  decode.d4.loss_dice: 0.7546  decode.d5.loss_cls: 0.0806  decode.d5.loss_mask: 1.1167  decode.d5.loss_dice: 0.7802  decode.d6.loss_cls: 0.1085  decode.d6.loss_mask: 1.0841  decode.d6.loss_dice: 0.7778  decode.d7.loss_cls: 0.1012  decode.d7.loss_mask: 1.0845  decode.d7.loss_dice: 0.7739  decode.d8.loss_cls: 0.0643  decode.d8.loss_mask: 1.1035  decode.d8.loss_dice: 0.7789
05/26 21:45:05 - mmengine - INFO - Iter(train) [ 91450/160000]  base_lr: 4.6634e-05 lr: 4.6634e-06  eta: 7:51:08  time: 0.4172  data_time: 0.0099  memory: 5971  grad_norm: 347.2358  loss: 20.1110  decode.loss_cls: 0.2488  decode.loss_mask: 0.9996  decode.loss_dice: 0.6889  decode.d0.loss_cls: 0.8140  decode.d0.loss_mask: 0.9465  decode.d0.loss_dice: 0.6553  decode.d1.loss_cls: 0.2760  decode.d1.loss_mask: 1.0120  decode.d1.loss_dice: 0.7094  decode.d2.loss_cls: 0.2606  decode.d2.loss_mask: 1.0036  decode.d2.loss_dice: 0.6882  decode.d3.loss_cls: 0.2996  decode.d3.loss_mask: 1.0211  decode.d3.loss_dice: 0.6748  decode.d4.loss_cls: 0.2881  decode.d4.loss_mask: 0.9954  decode.d4.loss_dice: 0.6747  decode.d5.loss_cls: 0.3100  decode.d5.loss_mask: 1.0040  decode.d5.loss_dice: 0.6778  decode.d6.loss_cls: 0.2438  decode.d6.loss_mask: 1.0166  decode.d6.loss_dice: 0.7207  decode.d7.loss_cls: 0.2389  decode.d7.loss_mask: 1.0268  decode.d7.loss_dice: 0.6712  decode.d8.loss_cls: 0.2943  decode.d8.loss_mask: 0.9907  decode.d8.loss_dice: 0.6595
05/26 21:45:26 - mmengine - INFO - Iter(train) [ 91500/160000]  base_lr: 4.6603e-05 lr: 4.6603e-06  eta: 7:50:48  time: 0.4172  data_time: 0.0098  memory: 5990  grad_norm: 566.8528  loss: 24.9338  decode.loss_cls: 0.1921  decode.loss_mask: 1.2810  decode.loss_dice: 0.9687  decode.d0.loss_cls: 0.6982  decode.d0.loss_mask: 1.1904  decode.d0.loss_dice: 0.9499  decode.d1.loss_cls: 0.2272  decode.d1.loss_mask: 1.2603  decode.d1.loss_dice: 0.9857  decode.d2.loss_cls: 0.2347  decode.d2.loss_mask: 1.2311  decode.d2.loss_dice: 0.9647  decode.d3.loss_cls: 0.2328  decode.d3.loss_mask: 1.2449  decode.d3.loss_dice: 0.9717  decode.d4.loss_cls: 0.2217  decode.d4.loss_mask: 1.2819  decode.d4.loss_dice: 0.9813  decode.d5.loss_cls: 0.2040  decode.d5.loss_mask: 1.2778  decode.d5.loss_dice: 0.9815  decode.d6.loss_cls: 0.2220  decode.d6.loss_mask: 1.2612  decode.d6.loss_dice: 1.0089  decode.d7.loss_cls: 0.2162  decode.d7.loss_mask: 1.2532  decode.d7.loss_dice: 0.9682  decode.d8.loss_cls: 0.2251  decode.d8.loss_mask: 1.2144  decode.d8.loss_dice: 0.9830
05/26 21:45:47 - mmengine - INFO - Iter(train) [ 91550/160000]  base_lr: 4.6573e-05 lr: 4.6573e-06  eta: 7:50:27  time: 0.4174  data_time: 0.0099  memory: 5975  grad_norm: 292.4410  loss: 15.9854  decode.loss_cls: 0.1003  decode.loss_mask: 0.8767  decode.loss_dice: 0.6004  decode.d0.loss_cls: 0.6156  decode.d0.loss_mask: 0.8389  decode.d0.loss_dice: 0.5689  decode.d1.loss_cls: 0.1093  decode.d1.loss_mask: 0.8715  decode.d1.loss_dice: 0.6098  decode.d2.loss_cls: 0.1455  decode.d2.loss_mask: 0.8360  decode.d2.loss_dice: 0.5400  decode.d3.loss_cls: 0.1293  decode.d3.loss_mask: 0.8335  decode.d3.loss_dice: 0.5360  decode.d4.loss_cls: 0.1469  decode.d4.loss_mask: 0.8258  decode.d4.loss_dice: 0.5586  decode.d5.loss_cls: 0.1253  decode.d5.loss_mask: 0.8473  decode.d5.loss_dice: 0.5899  decode.d6.loss_cls: 0.1287  decode.d6.loss_mask: 0.8496  decode.d6.loss_dice: 0.6043  decode.d7.loss_cls: 0.1343  decode.d7.loss_mask: 0.8509  decode.d7.loss_dice: 0.5734  decode.d8.loss_cls: 0.1150  decode.d8.loss_mask: 0.8639  decode.d8.loss_dice: 0.5601
05/26 21:46:08 - mmengine - INFO - Iter(train) [ 91600/160000]  base_lr: 4.6542e-05 lr: 4.6542e-06  eta: 7:50:07  time: 0.4176  data_time: 0.0098  memory: 5980  grad_norm: 705.1483  loss: 24.5911  decode.loss_cls: 0.2565  decode.loss_mask: 1.1557  decode.loss_dice: 0.9846  decode.d0.loss_cls: 0.8308  decode.d0.loss_mask: 1.0621  decode.d0.loss_dice: 0.9222  decode.d1.loss_cls: 0.3037  decode.d1.loss_mask: 1.1286  decode.d1.loss_dice: 0.9472  decode.d2.loss_cls: 0.3258  decode.d2.loss_mask: 1.2375  decode.d2.loss_dice: 0.9805  decode.d3.loss_cls: 0.3143  decode.d3.loss_mask: 1.1035  decode.d3.loss_dice: 0.9616  decode.d4.loss_cls: 0.3446  decode.d4.loss_mask: 1.0883  decode.d4.loss_dice: 0.9615  decode.d5.loss_cls: 0.3194  decode.d5.loss_mask: 1.1344  decode.d5.loss_dice: 0.9880  decode.d6.loss_cls: 0.3524  decode.d6.loss_mask: 1.1051  decode.d6.loss_dice: 0.9482  decode.d7.loss_cls: 0.3278  decode.d7.loss_mask: 1.1546  decode.d7.loss_dice: 0.9527  decode.d8.loss_cls: 0.3125  decode.d8.loss_mask: 1.1252  decode.d8.loss_dice: 0.9618
05/26 21:46:29 - mmengine - INFO - Iter(train) [ 91650/160000]  base_lr: 4.6511e-05 lr: 4.6511e-06  eta: 7:49:46  time: 0.4170  data_time: 0.0099  memory: 5973  grad_norm: 809.6597  loss: 22.2949  decode.loss_cls: 0.3084  decode.loss_mask: 1.0375  decode.loss_dice: 0.8440  decode.d0.loss_cls: 0.8410  decode.d0.loss_mask: 0.9921  decode.d0.loss_dice: 0.7945  decode.d1.loss_cls: 0.3153  decode.d1.loss_mask: 1.0395  decode.d1.loss_dice: 0.8346  decode.d2.loss_cls: 0.3433  decode.d2.loss_mask: 1.0343  decode.d2.loss_dice: 0.8065  decode.d3.loss_cls: 0.3763  decode.d3.loss_mask: 1.0104  decode.d3.loss_dice: 0.8248  decode.d4.loss_cls: 0.3241  decode.d4.loss_mask: 1.0116  decode.d4.loss_dice: 0.8082  decode.d5.loss_cls: 0.3273  decode.d5.loss_mask: 1.0234  decode.d5.loss_dice: 0.8147  decode.d6.loss_cls: 0.3221  decode.d6.loss_mask: 1.0477  decode.d6.loss_dice: 0.8232  decode.d7.loss_cls: 0.3285  decode.d7.loss_mask: 1.0558  decode.d7.loss_dice: 0.8253  decode.d8.loss_cls: 0.3035  decode.d8.loss_mask: 1.0498  decode.d8.loss_dice: 0.8271
05/26 21:46:50 - mmengine - INFO - Iter(train) [ 91700/160000]  base_lr: 4.6481e-05 lr: 4.6481e-06  eta: 7:49:26  time: 0.4176  data_time: 0.0099  memory: 5968  grad_norm: 755.1892  loss: 23.3010  decode.loss_cls: 0.2933  decode.loss_mask: 1.0724  decode.loss_dice: 0.8430  decode.d0.loss_cls: 0.8355  decode.d0.loss_mask: 1.0912  decode.d0.loss_dice: 0.8410  decode.d1.loss_cls: 0.2693  decode.d1.loss_mask: 1.1553  decode.d1.loss_dice: 0.8848  decode.d2.loss_cls: 0.3147  decode.d2.loss_mask: 1.1060  decode.d2.loss_dice: 0.8630  decode.d3.loss_cls: 0.2813  decode.d3.loss_mask: 1.0982  decode.d3.loss_dice: 0.8877  decode.d4.loss_cls: 0.3106  decode.d4.loss_mask: 1.0967  decode.d4.loss_dice: 0.8428  decode.d5.loss_cls: 0.3286  decode.d5.loss_mask: 1.1432  decode.d5.loss_dice: 0.8756  decode.d6.loss_cls: 0.2912  decode.d6.loss_mask: 1.1077  decode.d6.loss_dice: 0.8514  decode.d7.loss_cls: 0.3116  decode.d7.loss_mask: 1.1440  decode.d7.loss_dice: 0.8840  decode.d8.loss_cls: 0.3079  decode.d8.loss_mask: 1.1139  decode.d8.loss_dice: 0.8551
05/26 21:47:11 - mmengine - INFO - Iter(train) [ 91750/160000]  base_lr: 4.6450e-05 lr: 4.6450e-06  eta: 7:49:06  time: 0.4154  data_time: 0.0099  memory: 6006  grad_norm: 581.4150  loss: 21.6353  decode.loss_cls: 0.1883  decode.loss_mask: 1.1169  decode.loss_dice: 0.7838  decode.d0.loss_cls: 0.7061  decode.d0.loss_mask: 1.0862  decode.d0.loss_dice: 0.8027  decode.d1.loss_cls: 0.2235  decode.d1.loss_mask: 1.1186  decode.d1.loss_dice: 0.7775  decode.d2.loss_cls: 0.2000  decode.d2.loss_mask: 1.1148  decode.d2.loss_dice: 0.7758  decode.d3.loss_cls: 0.2051  decode.d3.loss_mask: 1.1143  decode.d3.loss_dice: 0.7845  decode.d4.loss_cls: 0.2091  decode.d4.loss_mask: 1.1239  decode.d4.loss_dice: 0.7984  decode.d5.loss_cls: 0.2130  decode.d5.loss_mask: 1.1294  decode.d5.loss_dice: 0.8012  decode.d6.loss_cls: 0.2602  decode.d6.loss_mask: 1.0964  decode.d6.loss_dice: 0.7769  decode.d7.loss_cls: 0.2421  decode.d7.loss_mask: 1.1155  decode.d7.loss_dice: 0.7747  decode.d8.loss_cls: 0.2376  decode.d8.loss_mask: 1.0932  decode.d8.loss_dice: 0.7657
05/26 21:47:31 - mmengine - INFO - Iter(train) [ 91800/160000]  base_lr: 4.6419e-05 lr: 4.6419e-06  eta: 7:48:45  time: 0.4201  data_time: 0.0100  memory: 5967  grad_norm: 712.0589  loss: 21.7104  decode.loss_cls: 0.1800  decode.loss_mask: 1.0760  decode.loss_dice: 0.8234  decode.d0.loss_cls: 0.7007  decode.d0.loss_mask: 0.9854  decode.d0.loss_dice: 0.7869  decode.d1.loss_cls: 0.2450  decode.d1.loss_mask: 1.1186  decode.d1.loss_dice: 0.8342  decode.d2.loss_cls: 0.2074  decode.d2.loss_mask: 1.1464  decode.d2.loss_dice: 0.8558  decode.d3.loss_cls: 0.2141  decode.d3.loss_mask: 1.1427  decode.d3.loss_dice: 0.8353  decode.d4.loss_cls: 0.2232  decode.d4.loss_mask: 1.0873  decode.d4.loss_dice: 0.7727  decode.d5.loss_cls: 0.2142  decode.d5.loss_mask: 1.1142  decode.d5.loss_dice: 0.8300  decode.d6.loss_cls: 0.2317  decode.d6.loss_mask: 1.0727  decode.d6.loss_dice: 0.7979  decode.d7.loss_cls: 0.2454  decode.d7.loss_mask: 1.0983  decode.d7.loss_dice: 0.7898  decode.d8.loss_cls: 0.2176  decode.d8.loss_mask: 1.0986  decode.d8.loss_dice: 0.7648
05/26 21:47:52 - mmengine - INFO - Iter(train) [ 91850/160000]  base_lr: 4.6389e-05 lr: 4.6389e-06  eta: 7:48:25  time: 0.4208  data_time: 0.0101  memory: 5969  grad_norm: 751.7172  loss: 23.2613  decode.loss_cls: 0.2679  decode.loss_mask: 1.2257  decode.loss_dice: 0.7832  decode.d0.loss_cls: 0.7967  decode.d0.loss_mask: 1.1565  decode.d0.loss_dice: 0.8071  decode.d1.loss_cls: 0.2576  decode.d1.loss_mask: 1.2383  decode.d1.loss_dice: 0.8115  decode.d2.loss_cls: 0.2845  decode.d2.loss_mask: 1.2066  decode.d2.loss_dice: 0.7861  decode.d3.loss_cls: 0.2839  decode.d3.loss_mask: 1.2160  decode.d3.loss_dice: 0.8222  decode.d4.loss_cls: 0.3032  decode.d4.loss_mask: 1.1475  decode.d4.loss_dice: 0.7823  decode.d5.loss_cls: 0.2876  decode.d5.loss_mask: 1.1353  decode.d5.loss_dice: 0.7748  decode.d6.loss_cls: 0.2542  decode.d6.loss_mask: 1.2412  decode.d6.loss_dice: 0.8074  decode.d7.loss_cls: 0.2734  decode.d7.loss_mask: 1.2229  decode.d7.loss_dice: 0.8055  decode.d8.loss_cls: 0.2565  decode.d8.loss_mask: 1.2136  decode.d8.loss_dice: 0.8120
05/26 21:48:13 - mmengine - INFO - Iter(train) [ 91900/160000]  base_lr: 4.6358e-05 lr: 4.6358e-06  eta: 7:48:04  time: 0.4120  data_time: 0.0096  memory: 5968  grad_norm: 1008.9802  loss: 19.9723  decode.loss_cls: 0.2578  decode.loss_mask: 0.9736  decode.loss_dice: 0.7137  decode.d0.loss_cls: 0.8225  decode.d0.loss_mask: 0.9400  decode.d0.loss_dice: 0.7268  decode.d1.loss_cls: 0.3287  decode.d1.loss_mask: 0.9253  decode.d1.loss_dice: 0.6845  decode.d2.loss_cls: 0.2854  decode.d2.loss_mask: 0.9139  decode.d2.loss_dice: 0.6726  decode.d3.loss_cls: 0.2971  decode.d3.loss_mask: 0.9303  decode.d3.loss_dice: 0.6997  decode.d4.loss_cls: 0.3054  decode.d4.loss_mask: 0.9632  decode.d4.loss_dice: 0.7180  decode.d5.loss_cls: 0.3353  decode.d5.loss_mask: 0.9375  decode.d5.loss_dice: 0.6974  decode.d6.loss_cls: 0.3274  decode.d6.loss_mask: 0.9499  decode.d6.loss_dice: 0.7137  decode.d7.loss_cls: 0.2729  decode.d7.loss_mask: 0.9193  decode.d7.loss_dice: 0.6966  decode.d8.loss_cls: 0.2928  decode.d8.loss_mask: 0.9677  decode.d8.loss_dice: 0.7035
05/26 21:48:34 - mmengine - INFO - Iter(train) [ 91950/160000]  base_lr: 4.6328e-05 lr: 4.6328e-06  eta: 7:47:44  time: 0.4123  data_time: 0.0097  memory: 5972  grad_norm: 595.2829  loss: 22.3636  decode.loss_cls: 0.2163  decode.loss_mask: 1.1453  decode.loss_dice: 0.7698  decode.d0.loss_cls: 0.7037  decode.d0.loss_mask: 1.1568  decode.d0.loss_dice: 0.8128  decode.d1.loss_cls: 0.2235  decode.d1.loss_mask: 1.2329  decode.d1.loss_dice: 0.8425  decode.d2.loss_cls: 0.2318  decode.d2.loss_mask: 1.1332  decode.d2.loss_dice: 0.7938  decode.d3.loss_cls: 0.2349  decode.d3.loss_mask: 1.1620  decode.d3.loss_dice: 0.8200  decode.d4.loss_cls: 0.2558  decode.d4.loss_mask: 1.1431  decode.d4.loss_dice: 0.7806  decode.d5.loss_cls: 0.2276  decode.d5.loss_mask: 1.1389  decode.d5.loss_dice: 0.7746  decode.d6.loss_cls: 0.2564  decode.d6.loss_mask: 1.1526  decode.d6.loss_dice: 0.7893  decode.d7.loss_cls: 0.2596  decode.d7.loss_mask: 1.1568  decode.d7.loss_dice: 0.7688  decode.d8.loss_cls: 0.2596  decode.d8.loss_mask: 1.1349  decode.d8.loss_dice: 0.7855
05/26 21:48:54 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 21:48:54 - mmengine - INFO - Iter(train) [ 92000/160000]  base_lr: 4.6297e-05 lr: 4.6297e-06  eta: 7:47:23  time: 0.4124  data_time: 0.0096  memory: 5977  grad_norm: 683.1507  loss: 21.8199  decode.loss_cls: 0.2943  decode.loss_mask: 1.0468  decode.loss_dice: 0.7866  decode.d0.loss_cls: 0.9176  decode.d0.loss_mask: 0.9783  decode.d0.loss_dice: 0.7212  decode.d1.loss_cls: 0.2996  decode.d1.loss_mask: 1.0389  decode.d1.loss_dice: 0.7874  decode.d2.loss_cls: 0.2757  decode.d2.loss_mask: 1.0403  decode.d2.loss_dice: 0.7782  decode.d3.loss_cls: 0.2705  decode.d3.loss_mask: 1.0357  decode.d3.loss_dice: 0.7568  decode.d4.loss_cls: 0.3114  decode.d4.loss_mask: 1.0870  decode.d4.loss_dice: 0.8131  decode.d5.loss_cls: 0.2645  decode.d5.loss_mask: 1.0660  decode.d5.loss_dice: 0.8040  decode.d6.loss_cls: 0.2488  decode.d6.loss_mask: 1.0592  decode.d6.loss_dice: 0.8225  decode.d7.loss_cls: 0.2849  decode.d7.loss_mask: 1.0450  decode.d7.loss_dice: 0.8547  decode.d8.loss_cls: 0.2731  decode.d8.loss_mask: 1.0483  decode.d8.loss_dice: 0.8095
05/26 21:49:15 - mmengine - INFO - Iter(train) [ 92050/160000]  base_lr: 4.6266e-05 lr: 4.6266e-06  eta: 7:47:02  time: 0.4126  data_time: 0.0096  memory: 5979  grad_norm: 491.4327  loss: 21.0936  decode.loss_cls: 0.2430  decode.loss_mask: 1.0136  decode.loss_dice: 0.7703  decode.d0.loss_cls: 0.7851  decode.d0.loss_mask: 1.0256  decode.d0.loss_dice: 0.7656  decode.d1.loss_cls: 0.2401  decode.d1.loss_mask: 1.0488  decode.d1.loss_dice: 0.8086  decode.d2.loss_cls: 0.2318  decode.d2.loss_mask: 1.0571  decode.d2.loss_dice: 0.7636  decode.d3.loss_cls: 0.2086  decode.d3.loss_mask: 1.0812  decode.d3.loss_dice: 0.7848  decode.d4.loss_cls: 0.2669  decode.d4.loss_mask: 1.0170  decode.d4.loss_dice: 0.7694  decode.d5.loss_cls: 0.2569  decode.d5.loss_mask: 1.0276  decode.d5.loss_dice: 0.7864  decode.d6.loss_cls: 0.2418  decode.d6.loss_mask: 1.0251  decode.d6.loss_dice: 0.7891  decode.d7.loss_cls: 0.2647  decode.d7.loss_mask: 1.0228  decode.d7.loss_dice: 0.7845  decode.d8.loss_cls: 0.2514  decode.d8.loss_mask: 1.0143  decode.d8.loss_dice: 0.7478
05/26 21:49:36 - mmengine - INFO - Iter(train) [ 92100/160000]  base_lr: 4.6236e-05 lr: 4.6236e-06  eta: 7:46:42  time: 0.4172  data_time: 0.0097  memory: 5969  grad_norm: 675.0732  loss: 20.9806  decode.loss_cls: 0.2395  decode.loss_mask: 0.9890  decode.loss_dice: 0.7676  decode.d0.loss_cls: 0.7657  decode.d0.loss_mask: 0.9810  decode.d0.loss_dice: 0.7791  decode.d1.loss_cls: 0.2650  decode.d1.loss_mask: 1.0130  decode.d1.loss_dice: 0.7886  decode.d2.loss_cls: 0.2224  decode.d2.loss_mask: 1.0115  decode.d2.loss_dice: 0.7803  decode.d3.loss_cls: 0.2521  decode.d3.loss_mask: 0.9908  decode.d3.loss_dice: 0.7822  decode.d4.loss_cls: 0.2441  decode.d4.loss_mask: 1.0174  decode.d4.loss_dice: 0.7654  decode.d5.loss_cls: 0.2393  decode.d5.loss_mask: 1.1216  decode.d5.loss_dice: 0.8193  decode.d6.loss_cls: 0.2513  decode.d6.loss_mask: 1.0087  decode.d6.loss_dice: 0.7771  decode.d7.loss_cls: 0.2783  decode.d7.loss_mask: 0.9974  decode.d7.loss_dice: 0.7848  decode.d8.loss_cls: 0.2818  decode.d8.loss_mask: 0.9841  decode.d8.loss_dice: 0.7823
05/26 21:49:57 - mmengine - INFO - Iter(train) [ 92150/160000]  base_lr: 4.6205e-05 lr: 4.6205e-06  eta: 7:46:22  time: 0.4209  data_time: 0.0099  memory: 5976  grad_norm: 606.6172  loss: 20.4714  decode.loss_cls: 0.1479  decode.loss_mask: 1.1278  decode.loss_dice: 0.7190  decode.d0.loss_cls: 0.7166  decode.d0.loss_mask: 1.0820  decode.d0.loss_dice: 0.6867  decode.d1.loss_cls: 0.1404  decode.d1.loss_mask: 1.1279  decode.d1.loss_dice: 0.7418  decode.d2.loss_cls: 0.1628  decode.d2.loss_mask: 1.1212  decode.d2.loss_dice: 0.7352  decode.d3.loss_cls: 0.2000  decode.d3.loss_mask: 1.1090  decode.d3.loss_dice: 0.7033  decode.d4.loss_cls: 0.1207  decode.d4.loss_mask: 1.1300  decode.d4.loss_dice: 0.7220  decode.d5.loss_cls: 0.1938  decode.d5.loss_mask: 1.1150  decode.d5.loss_dice: 0.6936  decode.d6.loss_cls: 0.1297  decode.d6.loss_mask: 1.1281  decode.d6.loss_dice: 0.7257  decode.d7.loss_cls: 0.1140  decode.d7.loss_mask: 1.1324  decode.d7.loss_dice: 0.7139  decode.d8.loss_cls: 0.1244  decode.d8.loss_mask: 1.1525  decode.d8.loss_dice: 0.7541
05/26 21:50:18 - mmengine - INFO - Iter(train) [ 92200/160000]  base_lr: 4.6174e-05 lr: 4.6174e-06  eta: 7:46:01  time: 0.4177  data_time: 0.0098  memory: 5965  grad_norm: 489.4672  loss: 18.7895  decode.loss_cls: 0.1474  decode.loss_mask: 0.9468  decode.loss_dice: 0.7636  decode.d0.loss_cls: 0.6327  decode.d0.loss_mask: 0.9058  decode.d0.loss_dice: 0.7097  decode.d1.loss_cls: 0.1048  decode.d1.loss_mask: 0.9498  decode.d1.loss_dice: 0.7715  decode.d2.loss_cls: 0.1610  decode.d2.loss_mask: 0.9390  decode.d2.loss_dice: 0.7441  decode.d3.loss_cls: 0.1742  decode.d3.loss_mask: 0.9402  decode.d3.loss_dice: 0.7257  decode.d4.loss_cls: 0.1261  decode.d4.loss_mask: 0.9551  decode.d4.loss_dice: 0.7706  decode.d5.loss_cls: 0.1570  decode.d5.loss_mask: 0.9319  decode.d5.loss_dice: 0.7219  decode.d6.loss_cls: 0.1589  decode.d6.loss_mask: 0.9441  decode.d6.loss_dice: 0.7524  decode.d7.loss_cls: 0.1383  decode.d7.loss_mask: 0.9117  decode.d7.loss_dice: 0.7631  decode.d8.loss_cls: 0.1236  decode.d8.loss_mask: 0.9497  decode.d8.loss_dice: 0.7689
05/26 21:50:39 - mmengine - INFO - Iter(train) [ 92250/160000]  base_lr: 4.6144e-05 lr: 4.6144e-06  eta: 7:45:41  time: 0.4178  data_time: 0.0098  memory: 5968  grad_norm: 659.6570  loss: 22.9115  decode.loss_cls: 0.2674  decode.loss_mask: 1.1203  decode.loss_dice: 0.8571  decode.d0.loss_cls: 0.7803  decode.d0.loss_mask: 1.0454  decode.d0.loss_dice: 0.7997  decode.d1.loss_cls: 0.2906  decode.d1.loss_mask: 1.1360  decode.d1.loss_dice: 0.8632  decode.d2.loss_cls: 0.2759  decode.d2.loss_mask: 1.1357  decode.d2.loss_dice: 0.8250  decode.d3.loss_cls: 0.2747  decode.d3.loss_mask: 1.1324  decode.d3.loss_dice: 0.8553  decode.d4.loss_cls: 0.2702  decode.d4.loss_mask: 1.1229  decode.d4.loss_dice: 0.8426  decode.d5.loss_cls: 0.2858  decode.d5.loss_mask: 1.1297  decode.d5.loss_dice: 0.8433  decode.d6.loss_cls: 0.2853  decode.d6.loss_mask: 1.1304  decode.d6.loss_dice: 0.8428  decode.d7.loss_cls: 0.3120  decode.d7.loss_mask: 1.1057  decode.d7.loss_dice: 0.8505  decode.d8.loss_cls: 0.2736  decode.d8.loss_mask: 1.1099  decode.d8.loss_dice: 0.8478
05/26 21:51:00 - mmengine - INFO - Iter(train) [ 92300/160000]  base_lr: 4.6113e-05 lr: 4.6113e-06  eta: 7:45:20  time: 0.4166  data_time: 0.0097  memory: 5975  grad_norm: 413.1734  loss: 19.1741  decode.loss_cls: 0.2155  decode.loss_mask: 0.8773  decode.loss_dice: 0.7666  decode.d0.loss_cls: 0.6634  decode.d0.loss_mask: 0.8924  decode.d0.loss_dice: 0.7704  decode.d1.loss_cls: 0.1987  decode.d1.loss_mask: 0.8840  decode.d1.loss_dice: 0.7898  decode.d2.loss_cls: 0.2076  decode.d2.loss_mask: 0.8885  decode.d2.loss_dice: 0.7817  decode.d3.loss_cls: 0.1754  decode.d3.loss_mask: 0.8934  decode.d3.loss_dice: 0.7917  decode.d4.loss_cls: 0.2017  decode.d4.loss_mask: 0.9004  decode.d4.loss_dice: 0.7945  decode.d5.loss_cls: 0.1790  decode.d5.loss_mask: 0.8849  decode.d5.loss_dice: 0.7644  decode.d6.loss_cls: 0.1998  decode.d6.loss_mask: 0.8913  decode.d6.loss_dice: 0.7876  decode.d7.loss_cls: 0.2435  decode.d7.loss_mask: 0.8805  decode.d7.loss_dice: 0.8037  decode.d8.loss_cls: 0.2136  decode.d8.loss_mask: 0.8748  decode.d8.loss_dice: 0.7581
05/26 21:51:21 - mmengine - INFO - Iter(train) [ 92350/160000]  base_lr: 4.6082e-05 lr: 4.6082e-06  eta: 7:45:00  time: 0.4185  data_time: 0.0099  memory: 5986  grad_norm: 508.3106  loss: 21.8786  decode.loss_cls: 0.2125  decode.loss_mask: 1.0812  decode.loss_dice: 0.8589  decode.d0.loss_cls: 0.8448  decode.d0.loss_mask: 1.0256  decode.d0.loss_dice: 0.8482  decode.d1.loss_cls: 0.2026  decode.d1.loss_mask: 1.0825  decode.d1.loss_dice: 0.8701  decode.d2.loss_cls: 0.2099  decode.d2.loss_mask: 1.0547  decode.d2.loss_dice: 0.8603  decode.d3.loss_cls: 0.1970  decode.d3.loss_mask: 1.0351  decode.d3.loss_dice: 0.8522  decode.d4.loss_cls: 0.2063  decode.d4.loss_mask: 1.0661  decode.d4.loss_dice: 0.8524  decode.d5.loss_cls: 0.2163  decode.d5.loss_mask: 1.0715  decode.d5.loss_dice: 0.8519  decode.d6.loss_cls: 0.2572  decode.d6.loss_mask: 1.0499  decode.d6.loss_dice: 0.8601  decode.d7.loss_cls: 0.1970  decode.d7.loss_mask: 1.0636  decode.d7.loss_dice: 0.8737  decode.d8.loss_cls: 0.1896  decode.d8.loss_mask: 1.0332  decode.d8.loss_dice: 0.8542
05/26 21:51:42 - mmengine - INFO - Iter(train) [ 92400/160000]  base_lr: 4.6052e-05 lr: 4.6052e-06  eta: 7:44:40  time: 0.4163  data_time: 0.0098  memory: 5966  grad_norm: 444.5488  loss: 21.0706  decode.loss_cls: 0.1675  decode.loss_mask: 1.0763  decode.loss_dice: 0.8128  decode.d0.loss_cls: 0.7476  decode.d0.loss_mask: 1.0030  decode.d0.loss_dice: 0.7533  decode.d1.loss_cls: 0.1873  decode.d1.loss_mask: 1.0717  decode.d1.loss_dice: 0.7907  decode.d2.loss_cls: 0.1677  decode.d2.loss_mask: 1.0620  decode.d2.loss_dice: 0.8199  decode.d3.loss_cls: 0.1811  decode.d3.loss_mask: 1.0797  decode.d3.loss_dice: 0.8023  decode.d4.loss_cls: 0.1689  decode.d4.loss_mask: 1.0840  decode.d4.loss_dice: 0.8245  decode.d5.loss_cls: 0.1604  decode.d5.loss_mask: 1.0949  decode.d5.loss_dice: 0.8163  decode.d6.loss_cls: 0.1711  decode.d6.loss_mask: 1.0581  decode.d6.loss_dice: 0.8077  decode.d7.loss_cls: 0.1825  decode.d7.loss_mask: 1.0806  decode.d7.loss_dice: 0.8075  decode.d8.loss_cls: 0.1972  decode.d8.loss_mask: 1.0846  decode.d8.loss_dice: 0.8096
05/26 21:52:03 - mmengine - INFO - Iter(train) [ 92450/160000]  base_lr: 4.6021e-05 lr: 4.6021e-06  eta: 7:44:19  time: 0.4181  data_time: 0.0098  memory: 5968  grad_norm: 509.5435  loss: 20.1740  decode.loss_cls: 0.1407  decode.loss_mask: 1.0372  decode.loss_dice: 0.7417  decode.d0.loss_cls: 0.6992  decode.d0.loss_mask: 0.9931  decode.d0.loss_dice: 0.7482  decode.d1.loss_cls: 0.1619  decode.d1.loss_mask: 1.0497  decode.d1.loss_dice: 0.7646  decode.d2.loss_cls: 0.1529  decode.d2.loss_mask: 1.0683  decode.d2.loss_dice: 0.7655  decode.d3.loss_cls: 0.1296  decode.d3.loss_mask: 1.0764  decode.d3.loss_dice: 0.7840  decode.d4.loss_cls: 0.1444  decode.d4.loss_mask: 1.0664  decode.d4.loss_dice: 0.7685  decode.d5.loss_cls: 0.1385  decode.d5.loss_mask: 1.0618  decode.d5.loss_dice: 0.7652  decode.d6.loss_cls: 0.1197  decode.d6.loss_mask: 1.0616  decode.d6.loss_dice: 0.7668  decode.d7.loss_cls: 0.1241  decode.d7.loss_mask: 1.0725  decode.d7.loss_dice: 0.7683  decode.d8.loss_cls: 0.1546  decode.d8.loss_mask: 1.0635  decode.d8.loss_dice: 0.7853
05/26 21:52:23 - mmengine - INFO - Iter(train) [ 92500/160000]  base_lr: 4.5990e-05 lr: 4.5990e-06  eta: 7:43:59  time: 0.4170  data_time: 0.0099  memory: 5976  grad_norm: 653.2190  loss: 20.4821  decode.loss_cls: 0.1685  decode.loss_mask: 1.0394  decode.loss_dice: 0.7769  decode.d0.loss_cls: 0.7150  decode.d0.loss_mask: 1.0241  decode.d0.loss_dice: 0.7669  decode.d1.loss_cls: 0.1793  decode.d1.loss_mask: 1.0559  decode.d1.loss_dice: 0.7592  decode.d2.loss_cls: 0.1863  decode.d2.loss_mask: 1.0365  decode.d2.loss_dice: 0.7448  decode.d3.loss_cls: 0.1794  decode.d3.loss_mask: 1.0506  decode.d3.loss_dice: 0.7611  decode.d4.loss_cls: 0.1874  decode.d4.loss_mask: 1.0500  decode.d4.loss_dice: 0.7558  decode.d5.loss_cls: 0.1820  decode.d5.loss_mask: 1.0369  decode.d5.loss_dice: 0.7520  decode.d6.loss_cls: 0.1884  decode.d6.loss_mask: 1.0776  decode.d6.loss_dice: 0.7747  decode.d7.loss_cls: 0.1845  decode.d7.loss_mask: 1.0670  decode.d7.loss_dice: 0.7626  decode.d8.loss_cls: 0.2001  decode.d8.loss_mask: 1.0540  decode.d8.loss_dice: 0.7651
05/26 21:52:44 - mmengine - INFO - Iter(train) [ 92550/160000]  base_lr: 4.5960e-05 lr: 4.5960e-06  eta: 7:43:38  time: 0.4176  data_time: 0.0099  memory: 5973  grad_norm: 577.4315  loss: 19.2027  decode.loss_cls: 0.1187  decode.loss_mask: 0.9508  decode.loss_dice: 0.7568  decode.d0.loss_cls: 0.6648  decode.d0.loss_mask: 0.9132  decode.d0.loss_dice: 0.7324  decode.d1.loss_cls: 0.1009  decode.d1.loss_mask: 0.9747  decode.d1.loss_dice: 0.7852  decode.d2.loss_cls: 0.1495  decode.d2.loss_mask: 0.9834  decode.d2.loss_dice: 0.7698  decode.d3.loss_cls: 0.1692  decode.d3.loss_mask: 0.9701  decode.d3.loss_dice: 0.7559  decode.d4.loss_cls: 0.1419  decode.d4.loss_mask: 0.9695  decode.d4.loss_dice: 0.7770  decode.d5.loss_cls: 0.1348  decode.d5.loss_mask: 0.9708  decode.d5.loss_dice: 0.7661  decode.d6.loss_cls: 0.1371  decode.d6.loss_mask: 0.9697  decode.d6.loss_dice: 0.7744  decode.d7.loss_cls: 0.1547  decode.d7.loss_mask: 0.9923  decode.d7.loss_dice: 0.7628  decode.d8.loss_cls: 0.1468  decode.d8.loss_mask: 0.9680  decode.d8.loss_dice: 0.7416
05/26 21:53:05 - mmengine - INFO - Iter(train) [ 92600/160000]  base_lr: 4.5929e-05 lr: 4.5929e-06  eta: 7:43:18  time: 0.4186  data_time: 0.0099  memory: 5967  grad_norm: 408.2843  loss: 18.5694  decode.loss_cls: 0.1307  decode.loss_mask: 0.9706  decode.loss_dice: 0.7262  decode.d0.loss_cls: 0.6529  decode.d0.loss_mask: 0.9623  decode.d0.loss_dice: 0.7135  decode.d1.loss_cls: 0.1417  decode.d1.loss_mask: 0.9432  decode.d1.loss_dice: 0.6866  decode.d2.loss_cls: 0.1374  decode.d2.loss_mask: 0.9637  decode.d2.loss_dice: 0.6983  decode.d3.loss_cls: 0.1454  decode.d3.loss_mask: 0.9644  decode.d3.loss_dice: 0.7096  decode.d4.loss_cls: 0.1308  decode.d4.loss_mask: 0.9698  decode.d4.loss_dice: 0.7157  decode.d5.loss_cls: 0.1444  decode.d5.loss_mask: 0.9668  decode.d5.loss_dice: 0.7131  decode.d6.loss_cls: 0.1386  decode.d6.loss_mask: 0.9447  decode.d6.loss_dice: 0.6936  decode.d7.loss_cls: 0.1436  decode.d7.loss_mask: 0.9433  decode.d7.loss_dice: 0.6942  decode.d8.loss_cls: 0.1435  decode.d8.loss_mask: 0.9626  decode.d8.loss_dice: 0.7181
05/26 21:53:26 - mmengine - INFO - Iter(train) [ 92650/160000]  base_lr: 4.5898e-05 lr: 4.5898e-06  eta: 7:42:57  time: 0.4164  data_time: 0.0099  memory: 5970  grad_norm: 838.2744  loss: 19.4982  decode.loss_cls: 0.2146  decode.loss_mask: 1.0373  decode.loss_dice: 0.6629  decode.d0.loss_cls: 0.6740  decode.d0.loss_mask: 0.9807  decode.d0.loss_dice: 0.6448  decode.d1.loss_cls: 0.2138  decode.d1.loss_mask: 1.0036  decode.d1.loss_dice: 0.6517  decode.d2.loss_cls: 0.2064  decode.d2.loss_mask: 1.0556  decode.d2.loss_dice: 0.6620  decode.d3.loss_cls: 0.2220  decode.d3.loss_mask: 1.0215  decode.d3.loss_dice: 0.6590  decode.d4.loss_cls: 0.2460  decode.d4.loss_mask: 1.0418  decode.d4.loss_dice: 0.6544  decode.d5.loss_cls: 0.2207  decode.d5.loss_mask: 1.0600  decode.d5.loss_dice: 0.6758  decode.d6.loss_cls: 0.2226  decode.d6.loss_mask: 1.0016  decode.d6.loss_dice: 0.6605  decode.d7.loss_cls: 0.2142  decode.d7.loss_mask: 1.0283  decode.d7.loss_dice: 0.6674  decode.d8.loss_cls: 0.2026  decode.d8.loss_mask: 1.0252  decode.d8.loss_dice: 0.6673
05/26 21:53:47 - mmengine - INFO - Iter(train) [ 92700/160000]  base_lr: 4.5868e-05 lr: 4.5868e-06  eta: 7:42:37  time: 0.4156  data_time: 0.0098  memory: 5973  grad_norm: 586.1902  loss: 19.7573  decode.loss_cls: 0.2269  decode.loss_mask: 0.9847  decode.loss_dice: 0.7714  decode.d0.loss_cls: 0.7597  decode.d0.loss_mask: 0.9368  decode.d0.loss_dice: 0.7582  decode.d1.loss_cls: 0.1973  decode.d1.loss_mask: 0.9540  decode.d1.loss_dice: 0.7677  decode.d2.loss_cls: 0.1873  decode.d2.loss_mask: 0.9164  decode.d2.loss_dice: 0.7592  decode.d3.loss_cls: 0.1951  decode.d3.loss_mask: 0.8982  decode.d3.loss_dice: 0.7459  decode.d4.loss_cls: 0.1963  decode.d4.loss_mask: 0.9156  decode.d4.loss_dice: 0.7477  decode.d5.loss_cls: 0.2013  decode.d5.loss_mask: 0.9488  decode.d5.loss_dice: 0.7567  decode.d6.loss_cls: 0.2101  decode.d6.loss_mask: 0.9831  decode.d6.loss_dice: 0.7893  decode.d7.loss_cls: 0.1918  decode.d7.loss_mask: 0.9511  decode.d7.loss_dice: 0.7890  decode.d8.loss_cls: 0.1867  decode.d8.loss_mask: 1.0614  decode.d8.loss_dice: 0.7696
05/26 21:54:08 - mmengine - INFO - Iter(train) [ 92750/160000]  base_lr: 4.5837e-05 lr: 4.5837e-06  eta: 7:42:16  time: 0.4191  data_time: 0.0102  memory: 5976  grad_norm: 394.2530  loss: 19.6808  decode.loss_cls: 0.2049  decode.loss_mask: 1.0252  decode.loss_dice: 0.6871  decode.d0.loss_cls: 0.7670  decode.d0.loss_mask: 0.9273  decode.d0.loss_dice: 0.6744  decode.d1.loss_cls: 0.2379  decode.d1.loss_mask: 1.0228  decode.d1.loss_dice: 0.6839  decode.d2.loss_cls: 0.2154  decode.d2.loss_mask: 1.0254  decode.d2.loss_dice: 0.6728  decode.d3.loss_cls: 0.1978  decode.d3.loss_mask: 1.0278  decode.d3.loss_dice: 0.6856  decode.d4.loss_cls: 0.2189  decode.d4.loss_mask: 1.0194  decode.d4.loss_dice: 0.7071  decode.d5.loss_cls: 0.2161  decode.d5.loss_mask: 1.0176  decode.d5.loss_dice: 0.6897  decode.d6.loss_cls: 0.2048  decode.d6.loss_mask: 1.0501  decode.d6.loss_dice: 0.6998  decode.d7.loss_cls: 0.2042  decode.d7.loss_mask: 1.0173  decode.d7.loss_dice: 0.6813  decode.d8.loss_cls: 0.2032  decode.d8.loss_mask: 1.0184  decode.d8.loss_dice: 0.6777
05/26 21:54:29 - mmengine - INFO - Iter(train) [ 92800/160000]  base_lr: 4.5806e-05 lr: 4.5806e-06  eta: 7:41:56  time: 0.4179  data_time: 0.0099  memory: 5974  grad_norm: 443.6370  loss: 18.5078  decode.loss_cls: 0.1779  decode.loss_mask: 0.8810  decode.loss_dice: 0.7143  decode.d0.loss_cls: 0.6943  decode.d0.loss_mask: 0.8921  decode.d0.loss_dice: 0.7086  decode.d1.loss_cls: 0.1832  decode.d1.loss_mask: 0.9089  decode.d1.loss_dice: 0.7533  decode.d2.loss_cls: 0.2043  decode.d2.loss_mask: 0.8766  decode.d2.loss_dice: 0.6976  decode.d3.loss_cls: 0.1774  decode.d3.loss_mask: 0.8911  decode.d3.loss_dice: 0.7003  decode.d4.loss_cls: 0.2189  decode.d4.loss_mask: 0.8795  decode.d4.loss_dice: 0.6925  decode.d5.loss_cls: 0.2060  decode.d5.loss_mask: 0.8820  decode.d5.loss_dice: 0.7067  decode.d6.loss_cls: 0.1712  decode.d6.loss_mask: 0.8992  decode.d6.loss_dice: 0.7292  decode.d7.loss_cls: 0.2177  decode.d7.loss_mask: 0.8912  decode.d7.loss_dice: 0.7120  decode.d8.loss_cls: 0.1884  decode.d8.loss_mask: 0.9155  decode.d8.loss_dice: 0.7371
05/26 21:54:50 - mmengine - INFO - Iter(train) [ 92850/160000]  base_lr: 4.5776e-05 lr: 4.5776e-06  eta: 7:41:36  time: 0.4175  data_time: 0.0099  memory: 5970  grad_norm: 696.2007  loss: 20.2694  decode.loss_cls: 0.2798  decode.loss_mask: 0.9776  decode.loss_dice: 0.7034  decode.d0.loss_cls: 0.6836  decode.d0.loss_mask: 0.9676  decode.d0.loss_dice: 0.7123  decode.d1.loss_cls: 0.2436  decode.d1.loss_mask: 1.0147  decode.d1.loss_dice: 0.7336  decode.d2.loss_cls: 0.2750  decode.d2.loss_mask: 0.9701  decode.d2.loss_dice: 0.6965  decode.d3.loss_cls: 0.2931  decode.d3.loss_mask: 1.0019  decode.d3.loss_dice: 0.6952  decode.d4.loss_cls: 0.2323  decode.d4.loss_mask: 1.0656  decode.d4.loss_dice: 0.7538  decode.d5.loss_cls: 0.2640  decode.d5.loss_mask: 0.9837  decode.d5.loss_dice: 0.7112  decode.d6.loss_cls: 0.2340  decode.d6.loss_mask: 1.0422  decode.d6.loss_dice: 0.7297  decode.d7.loss_cls: 0.3134  decode.d7.loss_mask: 1.0277  decode.d7.loss_dice: 0.7246  decode.d8.loss_cls: 0.3084  decode.d8.loss_mask: 0.9452  decode.d8.loss_dice: 0.6857
05/26 21:55:10 - mmengine - INFO - Iter(train) [ 92900/160000]  base_lr: 4.5745e-05 lr: 4.5745e-06  eta: 7:41:15  time: 0.4180  data_time: 0.0111  memory: 5973  grad_norm: 502.1709  loss: 20.6775  decode.loss_cls: 0.2845  decode.loss_mask: 1.0348  decode.loss_dice: 0.6827  decode.d0.loss_cls: 0.7201  decode.d0.loss_mask: 1.0577  decode.d0.loss_dice: 0.6659  decode.d1.loss_cls: 0.3099  decode.d1.loss_mask: 1.0965  decode.d1.loss_dice: 0.7244  decode.d2.loss_cls: 0.2929  decode.d2.loss_mask: 1.0494  decode.d2.loss_dice: 0.6984  decode.d3.loss_cls: 0.2661  decode.d3.loss_mask: 1.0457  decode.d3.loss_dice: 0.6903  decode.d4.loss_cls: 0.2739  decode.d4.loss_mask: 1.0366  decode.d4.loss_dice: 0.6901  decode.d5.loss_cls: 0.2960  decode.d5.loss_mask: 1.0300  decode.d5.loss_dice: 0.6769  decode.d6.loss_cls: 0.2715  decode.d6.loss_mask: 1.0442  decode.d6.loss_dice: 0.6883  decode.d7.loss_cls: 0.2663  decode.d7.loss_mask: 1.0654  decode.d7.loss_dice: 0.6895  decode.d8.loss_cls: 0.2877  decode.d8.loss_mask: 1.0375  decode.d8.loss_dice: 0.7045
05/26 21:55:31 - mmengine - INFO - Iter(train) [ 92950/160000]  base_lr: 4.5714e-05 lr: 4.5714e-06  eta: 7:40:55  time: 0.4205  data_time: 0.0101  memory: 5974  grad_norm: 496.4051  loss: 24.3277  decode.loss_cls: 0.3202  decode.loss_mask: 1.2146  decode.loss_dice: 0.8625  decode.d0.loss_cls: 0.7101  decode.d0.loss_mask: 1.1838  decode.d0.loss_dice: 0.8336  decode.d1.loss_cls: 0.3442  decode.d1.loss_mask: 1.2124  decode.d1.loss_dice: 0.8762  decode.d2.loss_cls: 0.3134  decode.d2.loss_mask: 1.2123  decode.d2.loss_dice: 0.8693  decode.d3.loss_cls: 0.3568  decode.d3.loss_mask: 1.1933  decode.d3.loss_dice: 0.8819  decode.d4.loss_cls: 0.3686  decode.d4.loss_mask: 1.1791  decode.d4.loss_dice: 0.8435  decode.d5.loss_cls: 0.3493  decode.d5.loss_mask: 1.1552  decode.d5.loss_dice: 0.8391  decode.d6.loss_cls: 0.3401  decode.d6.loss_mask: 1.1736  decode.d6.loss_dice: 0.8766  decode.d7.loss_cls: 0.3730  decode.d7.loss_mask: 1.1400  decode.d7.loss_dice: 0.8376  decode.d8.loss_cls: 0.3076  decode.d8.loss_mask: 1.2411  decode.d8.loss_dice: 0.9191
05/26 21:55:52 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 21:55:52 - mmengine - INFO - Iter(train) [ 93000/160000]  base_lr: 4.5684e-05 lr: 4.5684e-06  eta: 7:40:34  time: 0.4197  data_time: 0.0099  memory: 5969  grad_norm: 372.5445  loss: 17.4308  decode.loss_cls: 0.1319  decode.loss_mask: 0.8951  decode.loss_dice: 0.6504  decode.d0.loss_cls: 0.6031  decode.d0.loss_mask: 0.8661  decode.d0.loss_dice: 0.6280  decode.d1.loss_cls: 0.2113  decode.d1.loss_mask: 0.8943  decode.d1.loss_dice: 0.6556  decode.d2.loss_cls: 0.1689  decode.d2.loss_mask: 0.8943  decode.d2.loss_dice: 0.6346  decode.d3.loss_cls: 0.1588  decode.d3.loss_mask: 0.9054  decode.d3.loss_dice: 0.6340  decode.d4.loss_cls: 0.1479  decode.d4.loss_mask: 0.8871  decode.d4.loss_dice: 0.6571  decode.d5.loss_cls: 0.1584  decode.d5.loss_mask: 0.8881  decode.d5.loss_dice: 0.6518  decode.d6.loss_cls: 0.1583  decode.d6.loss_mask: 0.8957  decode.d6.loss_dice: 0.6405  decode.d7.loss_cls: 0.1594  decode.d7.loss_mask: 0.8935  decode.d7.loss_dice: 0.6589  decode.d8.loss_cls: 0.1479  decode.d8.loss_mask: 0.8976  decode.d8.loss_dice: 0.6566
05/26 21:56:13 - mmengine - INFO - Iter(train) [ 93050/160000]  base_lr: 4.5653e-05 lr: 4.5653e-06  eta: 7:40:14  time: 0.4127  data_time: 0.0098  memory: 5969  grad_norm: 337.2983  loss: 19.2412  decode.loss_cls: 0.2048  decode.loss_mask: 1.0045  decode.loss_dice: 0.6850  decode.d0.loss_cls: 0.6434  decode.d0.loss_mask: 0.9911  decode.d0.loss_dice: 0.6889  decode.d1.loss_cls: 0.1839  decode.d1.loss_mask: 1.0138  decode.d1.loss_dice: 0.6735  decode.d2.loss_cls: 0.1930  decode.d2.loss_mask: 1.0253  decode.d2.loss_dice: 0.6832  decode.d3.loss_cls: 0.1928  decode.d3.loss_mask: 0.9973  decode.d3.loss_dice: 0.6717  decode.d4.loss_cls: 0.1908  decode.d4.loss_mask: 1.0218  decode.d4.loss_dice: 0.6795  decode.d5.loss_cls: 0.1869  decode.d5.loss_mask: 1.0036  decode.d5.loss_dice: 0.6826  decode.d6.loss_cls: 0.1661  decode.d6.loss_mask: 1.0085  decode.d6.loss_dice: 0.6697  decode.d7.loss_cls: 0.2105  decode.d7.loss_mask: 1.0165  decode.d7.loss_dice: 0.6638  decode.d8.loss_cls: 0.2344  decode.d8.loss_mask: 0.9836  decode.d8.loss_dice: 0.6706
05/26 21:56:34 - mmengine - INFO - Iter(train) [ 93100/160000]  base_lr: 4.5622e-05 lr: 4.5622e-06  eta: 7:39:53  time: 0.4129  data_time: 0.0097  memory: 5966  grad_norm: 570.2500  loss: 19.8281  decode.loss_cls: 0.1341  decode.loss_mask: 1.0373  decode.loss_dice: 0.7900  decode.d0.loss_cls: 0.5735  decode.d0.loss_mask: 1.0185  decode.d0.loss_dice: 0.7435  decode.d1.loss_cls: 0.1709  decode.d1.loss_mask: 1.0264  decode.d1.loss_dice: 0.7650  decode.d2.loss_cls: 0.1583  decode.d2.loss_mask: 1.0278  decode.d2.loss_dice: 0.7511  decode.d3.loss_cls: 0.1499  decode.d3.loss_mask: 1.0163  decode.d3.loss_dice: 0.7579  decode.d4.loss_cls: 0.1602  decode.d4.loss_mask: 1.0406  decode.d4.loss_dice: 0.7856  decode.d5.loss_cls: 0.1404  decode.d5.loss_mask: 0.9902  decode.d5.loss_dice: 0.7563  decode.d6.loss_cls: 0.1474  decode.d6.loss_mask: 1.0421  decode.d6.loss_dice: 0.7853  decode.d7.loss_cls: 0.1440  decode.d7.loss_mask: 0.9879  decode.d7.loss_dice: 0.7801  decode.d8.loss_cls: 0.1591  decode.d8.loss_mask: 1.0068  decode.d8.loss_dice: 0.7816
05/26 21:56:54 - mmengine - INFO - Iter(train) [ 93150/160000]  base_lr: 4.5592e-05 lr: 4.5592e-06  eta: 7:39:33  time: 0.4126  data_time: 0.0096  memory: 5967  grad_norm: 471.3469  loss: 20.2779  decode.loss_cls: 0.2081  decode.loss_mask: 1.0228  decode.loss_dice: 0.7607  decode.d0.loss_cls: 0.6916  decode.d0.loss_mask: 0.9489  decode.d0.loss_dice: 0.7359  decode.d1.loss_cls: 0.1804  decode.d1.loss_mask: 1.0092  decode.d1.loss_dice: 0.7793  decode.d2.loss_cls: 0.2028  decode.d2.loss_mask: 1.0108  decode.d2.loss_dice: 0.7809  decode.d3.loss_cls: 0.2038  decode.d3.loss_mask: 1.0135  decode.d3.loss_dice: 0.7851  decode.d4.loss_cls: 0.2172  decode.d4.loss_mask: 1.0182  decode.d4.loss_dice: 0.7640  decode.d5.loss_cls: 0.2053  decode.d5.loss_mask: 1.0089  decode.d5.loss_dice: 0.7651  decode.d6.loss_cls: 0.1982  decode.d6.loss_mask: 1.0342  decode.d6.loss_dice: 0.8076  decode.d7.loss_cls: 0.1747  decode.d7.loss_mask: 1.0170  decode.d7.loss_dice: 0.7616  decode.d8.loss_cls: 0.2125  decode.d8.loss_mask: 1.0063  decode.d8.loss_dice: 0.7532
05/26 21:57:15 - mmengine - INFO - Iter(train) [ 93200/160000]  base_lr: 4.5561e-05 lr: 4.5561e-06  eta: 7:39:12  time: 0.4126  data_time: 0.0097  memory: 5966  grad_norm: 484.9748  loss: 21.0666  decode.loss_cls: 0.1585  decode.loss_mask: 1.1018  decode.loss_dice: 0.7737  decode.d0.loss_cls: 0.6698  decode.d0.loss_mask: 1.0775  decode.d0.loss_dice: 0.7646  decode.d1.loss_cls: 0.1953  decode.d1.loss_mask: 1.0981  decode.d1.loss_dice: 0.7828  decode.d2.loss_cls: 0.1799  decode.d2.loss_mask: 1.1007  decode.d2.loss_dice: 0.7803  decode.d3.loss_cls: 0.2052  decode.d3.loss_mask: 1.1017  decode.d3.loss_dice: 0.7632  decode.d4.loss_cls: 0.2002  decode.d4.loss_mask: 1.0986  decode.d4.loss_dice: 0.7643  decode.d5.loss_cls: 0.2433  decode.d5.loss_mask: 1.0473  decode.d5.loss_dice: 0.7506  decode.d6.loss_cls: 0.2067  decode.d6.loss_mask: 1.0945  decode.d6.loss_dice: 0.7657  decode.d7.loss_cls: 0.1858  decode.d7.loss_mask: 1.1050  decode.d7.loss_dice: 0.7808  decode.d8.loss_cls: 0.1798  decode.d8.loss_mask: 1.1131  decode.d8.loss_dice: 0.7777
05/26 21:57:36 - mmengine - INFO - Iter(train) [ 93250/160000]  base_lr: 4.5530e-05 lr: 4.5530e-06  eta: 7:38:51  time: 0.4155  data_time: 0.0098  memory: 5971  grad_norm: 313.2235  loss: 16.5924  decode.loss_cls: 0.1760  decode.loss_mask: 0.8835  decode.loss_dice: 0.5630  decode.d0.loss_cls: 0.6807  decode.d0.loss_mask: 0.7544  decode.d0.loss_dice: 0.5400  decode.d1.loss_cls: 0.1809  decode.d1.loss_mask: 0.8830  decode.d1.loss_dice: 0.5797  decode.d2.loss_cls: 0.2042  decode.d2.loss_mask: 0.8367  decode.d2.loss_dice: 0.5480  decode.d3.loss_cls: 0.2055  decode.d3.loss_mask: 0.8432  decode.d3.loss_dice: 0.5670  decode.d4.loss_cls: 0.2062  decode.d4.loss_mask: 0.8712  decode.d4.loss_dice: 0.5691  decode.d5.loss_cls: 0.2301  decode.d5.loss_mask: 0.8272  decode.d5.loss_dice: 0.5714  decode.d6.loss_cls: 0.1756  decode.d6.loss_mask: 0.8890  decode.d6.loss_dice: 0.5655  decode.d7.loss_cls: 0.2177  decode.d7.loss_mask: 0.8479  decode.d7.loss_dice: 0.5578  decode.d8.loss_cls: 0.2133  decode.d8.loss_mask: 0.8373  decode.d8.loss_dice: 0.5673
05/26 21:57:57 - mmengine - INFO - Iter(train) [ 93300/160000]  base_lr: 4.5500e-05 lr: 4.5500e-06  eta: 7:38:31  time: 0.4199  data_time: 0.0099  memory: 5966  grad_norm: 787.1251  loss: 22.2865  decode.loss_cls: 0.2882  decode.loss_mask: 1.0891  decode.loss_dice: 0.8164  decode.d0.loss_cls: 0.7485  decode.d0.loss_mask: 1.0412  decode.d0.loss_dice: 0.7567  decode.d1.loss_cls: 0.2430  decode.d1.loss_mask: 1.1284  decode.d1.loss_dice: 0.8509  decode.d2.loss_cls: 0.2727  decode.d2.loss_mask: 1.0877  decode.d2.loss_dice: 0.8026  decode.d3.loss_cls: 0.2721  decode.d3.loss_mask: 1.0771  decode.d3.loss_dice: 0.8073  decode.d4.loss_cls: 0.2823  decode.d4.loss_mask: 1.1128  decode.d4.loss_dice: 0.8075  decode.d5.loss_cls: 0.2602  decode.d5.loss_mask: 1.1321  decode.d5.loss_dice: 0.8074  decode.d6.loss_cls: 0.3163  decode.d6.loss_mask: 1.1003  decode.d6.loss_dice: 0.7999  decode.d7.loss_cls: 0.2870  decode.d7.loss_mask: 1.1160  decode.d7.loss_dice: 0.8005  decode.d8.loss_cls: 0.2574  decode.d8.loss_mask: 1.1150  decode.d8.loss_dice: 0.8100
05/26 21:58:18 - mmengine - INFO - Iter(train) [ 93350/160000]  base_lr: 4.5469e-05 lr: 4.5469e-06  eta: 7:38:11  time: 0.4280  data_time: 0.0099  memory: 5967  grad_norm: 652.4856  loss: 23.1687  decode.loss_cls: 0.2546  decode.loss_mask: 1.1541  decode.loss_dice: 0.9118  decode.d0.loss_cls: 0.6759  decode.d0.loss_mask: 1.1061  decode.d0.loss_dice: 0.9002  decode.d1.loss_cls: 0.2044  decode.d1.loss_mask: 1.1210  decode.d1.loss_dice: 0.8838  decode.d2.loss_cls: 0.2456  decode.d2.loss_mask: 1.1490  decode.d2.loss_dice: 0.8793  decode.d3.loss_cls: 0.2396  decode.d3.loss_mask: 1.1338  decode.d3.loss_dice: 0.8713  decode.d4.loss_cls: 0.2142  decode.d4.loss_mask: 1.1281  decode.d4.loss_dice: 0.8826  decode.d5.loss_cls: 0.2535  decode.d5.loss_mask: 1.1594  decode.d5.loss_dice: 0.9188  decode.d6.loss_cls: 0.2665  decode.d6.loss_mask: 1.1315  decode.d6.loss_dice: 0.9011  decode.d7.loss_cls: 0.2632  decode.d7.loss_mask: 1.1333  decode.d7.loss_dice: 0.8991  decode.d8.loss_cls: 0.2384  decode.d8.loss_mask: 1.1348  decode.d8.loss_dice: 0.9135
05/26 21:58:39 - mmengine - INFO - Iter(train) [ 93400/160000]  base_lr: 4.5438e-05 lr: 4.5438e-06  eta: 7:37:50  time: 0.4165  data_time: 0.0098  memory: 5967  grad_norm: 429.3060  loss: 18.1769  decode.loss_cls: 0.1677  decode.loss_mask: 0.9413  decode.loss_dice: 0.7174  decode.d0.loss_cls: 0.6232  decode.d0.loss_mask: 0.8747  decode.d0.loss_dice: 0.7259  decode.d1.loss_cls: 0.2251  decode.d1.loss_mask: 0.8778  decode.d1.loss_dice: 0.6768  decode.d2.loss_cls: 0.1631  decode.d2.loss_mask: 0.8898  decode.d2.loss_dice: 0.6682  decode.d3.loss_cls: 0.1298  decode.d3.loss_mask: 0.8878  decode.d3.loss_dice: 0.6999  decode.d4.loss_cls: 0.1798  decode.d4.loss_mask: 0.8795  decode.d4.loss_dice: 0.6611  decode.d5.loss_cls: 0.1956  decode.d5.loss_mask: 0.8827  decode.d5.loss_dice: 0.7064  decode.d6.loss_cls: 0.1965  decode.d6.loss_mask: 0.8806  decode.d6.loss_dice: 0.6876  decode.d7.loss_cls: 0.2145  decode.d7.loss_mask: 0.8831  decode.d7.loss_dice: 0.7070  decode.d8.loss_cls: 0.1878  decode.d8.loss_mask: 0.9016  decode.d8.loss_dice: 0.7444
05/26 21:59:00 - mmengine - INFO - Iter(train) [ 93450/160000]  base_lr: 4.5408e-05 lr: 4.5408e-06  eta: 7:37:30  time: 0.4172  data_time: 0.0099  memory: 5974  grad_norm: 531.2707  loss: 21.5035  decode.loss_cls: 0.1983  decode.loss_mask: 1.0856  decode.loss_dice: 0.7653  decode.d0.loss_cls: 0.6929  decode.d0.loss_mask: 1.0270  decode.d0.loss_dice: 0.7455  decode.d1.loss_cls: 0.2256  decode.d1.loss_mask: 1.0997  decode.d1.loss_dice: 0.7641  decode.d2.loss_cls: 0.2268  decode.d2.loss_mask: 1.1585  decode.d2.loss_dice: 0.7923  decode.d3.loss_cls: 0.1890  decode.d3.loss_mask: 1.1725  decode.d3.loss_dice: 0.7817  decode.d4.loss_cls: 0.2141  decode.d4.loss_mask: 1.1816  decode.d4.loss_dice: 0.7830  decode.d5.loss_cls: 0.2084  decode.d5.loss_mask: 1.1198  decode.d5.loss_dice: 0.7677  decode.d6.loss_cls: 0.2129  decode.d6.loss_mask: 1.1451  decode.d6.loss_dice: 0.7690  decode.d7.loss_cls: 0.2425  decode.d7.loss_mask: 1.0909  decode.d7.loss_dice: 0.7583  decode.d8.loss_cls: 0.2422  decode.d8.loss_mask: 1.0886  decode.d8.loss_dice: 0.7544
05/26 21:59:20 - mmengine - INFO - Iter(train) [ 93500/160000]  base_lr: 4.5377e-05 lr: 4.5377e-06  eta: 7:37:09  time: 0.4171  data_time: 0.0098  memory: 5980  grad_norm: 616.2302  loss: 19.4928  decode.loss_cls: 0.1739  decode.loss_mask: 1.0358  decode.loss_dice: 0.6602  decode.d0.loss_cls: 0.6635  decode.d0.loss_mask: 1.0227  decode.d0.loss_dice: 0.6717  decode.d1.loss_cls: 0.2057  decode.d1.loss_mask: 1.0380  decode.d1.loss_dice: 0.7039  decode.d2.loss_cls: 0.1572  decode.d2.loss_mask: 0.9984  decode.d2.loss_dice: 0.6563  decode.d3.loss_cls: 0.1634  decode.d3.loss_mask: 1.0976  decode.d3.loss_dice: 0.7124  decode.d4.loss_cls: 0.1851  decode.d4.loss_mask: 1.0333  decode.d4.loss_dice: 0.6950  decode.d5.loss_cls: 0.1796  decode.d5.loss_mask: 1.0246  decode.d5.loss_dice: 0.6956  decode.d6.loss_cls: 0.1970  decode.d6.loss_mask: 1.0307  decode.d6.loss_dice: 0.6804  decode.d7.loss_cls: 0.1981  decode.d7.loss_mask: 1.0360  decode.d7.loss_dice: 0.6739  decode.d8.loss_cls: 0.1731  decode.d8.loss_mask: 1.0598  decode.d8.loss_dice: 0.6700
05/26 21:59:41 - mmengine - INFO - Iter(train) [ 93550/160000]  base_lr: 4.5346e-05 lr: 4.5346e-06  eta: 7:36:49  time: 0.4151  data_time: 0.0098  memory: 5969  grad_norm: 590.3943  loss: 17.0611  decode.loss_cls: 0.1093  decode.loss_mask: 0.8999  decode.loss_dice: 0.6720  decode.d0.loss_cls: 0.5878  decode.d0.loss_mask: 0.8168  decode.d0.loss_dice: 0.6454  decode.d1.loss_cls: 0.1234  decode.d1.loss_mask: 0.8893  decode.d1.loss_dice: 0.6457  decode.d2.loss_cls: 0.1430  decode.d2.loss_mask: 0.8800  decode.d2.loss_dice: 0.6394  decode.d3.loss_cls: 0.1194  decode.d3.loss_mask: 0.8910  decode.d3.loss_dice: 0.6421  decode.d4.loss_cls: 0.1265  decode.d4.loss_mask: 0.8938  decode.d4.loss_dice: 0.6446  decode.d5.loss_cls: 0.1015  decode.d5.loss_mask: 0.8864  decode.d5.loss_dice: 0.6619  decode.d6.loss_cls: 0.1458  decode.d6.loss_mask: 0.8850  decode.d6.loss_dice: 0.6576  decode.d7.loss_cls: 0.1075  decode.d7.loss_mask: 0.9155  decode.d7.loss_dice: 0.6717  decode.d8.loss_cls: 0.1274  decode.d8.loss_mask: 0.8886  decode.d8.loss_dice: 0.6430
05/26 22:00:04 - mmengine - INFO - Iter(train) [ 93600/160000]  base_lr: 4.5315e-05 lr: 4.5315e-06  eta: 7:36:29  time: 0.4155  data_time: 0.0098  memory: 5970  grad_norm: 534.6853  loss: 22.8120  decode.loss_cls: 0.1743  decode.loss_mask: 1.2634  decode.loss_dice: 0.8407  decode.d0.loss_cls: 0.6662  decode.d0.loss_mask: 1.1650  decode.d0.loss_dice: 0.7663  decode.d1.loss_cls: 0.2080  decode.d1.loss_mask: 1.2661  decode.d1.loss_dice: 0.8017  decode.d2.loss_cls: 0.1735  decode.d2.loss_mask: 1.2535  decode.d2.loss_dice: 0.7984  decode.d3.loss_cls: 0.1742  decode.d3.loss_mask: 1.2491  decode.d3.loss_dice: 0.8002  decode.d4.loss_cls: 0.1972  decode.d4.loss_mask: 1.2543  decode.d4.loss_dice: 0.8026  decode.d5.loss_cls: 0.1853  decode.d5.loss_mask: 1.2533  decode.d5.loss_dice: 0.8068  decode.d6.loss_cls: 0.1915  decode.d6.loss_mask: 1.2500  decode.d6.loss_dice: 0.8083  decode.d7.loss_cls: 0.1636  decode.d7.loss_mask: 1.2502  decode.d7.loss_dice: 0.8180  decode.d8.loss_cls: 0.1917  decode.d8.loss_mask: 1.2459  decode.d8.loss_dice: 0.7926
05/26 22:00:25 - mmengine - INFO - Iter(train) [ 93650/160000]  base_lr: 4.5285e-05 lr: 4.5285e-06  eta: 7:36:09  time: 0.4158  data_time: 0.0099  memory: 5965  grad_norm: 644.7002  loss: 24.2390  decode.loss_cls: 0.1535  decode.loss_mask: 1.2959  decode.loss_dice: 0.9197  decode.d0.loss_cls: 0.7721  decode.d0.loss_mask: 1.2383  decode.d0.loss_dice: 0.8552  decode.d1.loss_cls: 0.1610  decode.d1.loss_mask: 1.3073  decode.d1.loss_dice: 0.9235  decode.d2.loss_cls: 0.1730  decode.d2.loss_mask: 1.2707  decode.d2.loss_dice: 0.8893  decode.d3.loss_cls: 0.2170  decode.d3.loss_mask: 1.2847  decode.d3.loss_dice: 0.9085  decode.d4.loss_cls: 0.1772  decode.d4.loss_mask: 1.2927  decode.d4.loss_dice: 0.9223  decode.d5.loss_cls: 0.1734  decode.d5.loss_mask: 1.2983  decode.d5.loss_dice: 0.8662  decode.d6.loss_cls: 0.1981  decode.d6.loss_mask: 1.2961  decode.d6.loss_dice: 0.9258  decode.d7.loss_cls: 0.1694  decode.d7.loss_mask: 1.2782  decode.d7.loss_dice: 0.9108  decode.d8.loss_cls: 0.1713  decode.d8.loss_mask: 1.2810  decode.d8.loss_dice: 0.9083
05/26 22:00:45 - mmengine - INFO - Iter(train) [ 93700/160000]  base_lr: 4.5254e-05 lr: 4.5254e-06  eta: 7:35:49  time: 0.4160  data_time: 0.0099  memory: 5967  grad_norm: 457.7240  loss: 22.1424  decode.loss_cls: 0.1974  decode.loss_mask: 1.1466  decode.loss_dice: 0.8349  decode.d0.loss_cls: 0.6304  decode.d0.loss_mask: 1.1134  decode.d0.loss_dice: 0.8107  decode.d1.loss_cls: 0.2382  decode.d1.loss_mask: 1.1436  decode.d1.loss_dice: 0.8480  decode.d2.loss_cls: 0.2212  decode.d2.loss_mask: 1.1161  decode.d2.loss_dice: 0.8371  decode.d3.loss_cls: 0.2152  decode.d3.loss_mask: 1.1225  decode.d3.loss_dice: 0.8425  decode.d4.loss_cls: 0.2204  decode.d4.loss_mask: 1.1144  decode.d4.loss_dice: 0.8364  decode.d5.loss_cls: 0.2113  decode.d5.loss_mask: 1.1194  decode.d5.loss_dice: 0.8309  decode.d6.loss_cls: 0.1816  decode.d6.loss_mask: 1.1353  decode.d6.loss_dice: 0.8609  decode.d7.loss_cls: 0.2142  decode.d7.loss_mask: 1.0897  decode.d7.loss_dice: 0.8570  decode.d8.loss_cls: 0.1831  decode.d8.loss_mask: 1.1286  decode.d8.loss_dice: 0.8413
05/26 22:01:06 - mmengine - INFO - Iter(train) [ 93750/160000]  base_lr: 4.5223e-05 lr: 4.5223e-06  eta: 7:35:28  time: 0.4177  data_time: 0.0102  memory: 5967  grad_norm: 516.7407  loss: 22.2363  decode.loss_cls: 0.2447  decode.loss_mask: 1.0811  decode.loss_dice: 0.8678  decode.d0.loss_cls: 0.7049  decode.d0.loss_mask: 1.0325  decode.d0.loss_dice: 0.8477  decode.d1.loss_cls: 0.2924  decode.d1.loss_mask: 1.0609  decode.d1.loss_dice: 0.8736  decode.d2.loss_cls: 0.2541  decode.d2.loss_mask: 1.0831  decode.d2.loss_dice: 0.8334  decode.d3.loss_cls: 0.2050  decode.d3.loss_mask: 1.0736  decode.d3.loss_dice: 0.8615  decode.d4.loss_cls: 0.2755  decode.d4.loss_mask: 1.0730  decode.d4.loss_dice: 0.8458  decode.d5.loss_cls: 0.2413  decode.d5.loss_mask: 1.0694  decode.d5.loss_dice: 0.8640  decode.d6.loss_cls: 0.2085  decode.d6.loss_mask: 1.0736  decode.d6.loss_dice: 0.8795  decode.d7.loss_cls: 0.2185  decode.d7.loss_mask: 1.0930  decode.d7.loss_dice: 0.8675  decode.d8.loss_cls: 0.2132  decode.d8.loss_mask: 1.1212  decode.d8.loss_dice: 0.8759
05/26 22:01:27 - mmengine - INFO - Iter(train) [ 93800/160000]  base_lr: 4.5193e-05 lr: 4.5193e-06  eta: 7:35:08  time: 0.4171  data_time: 0.0099  memory: 5967  grad_norm: 683.3154  loss: 20.7912  decode.loss_cls: 0.2885  decode.loss_mask: 1.0246  decode.loss_dice: 0.7612  decode.d0.loss_cls: 0.7735  decode.d0.loss_mask: 0.9501  decode.d0.loss_dice: 0.7467  decode.d1.loss_cls: 0.2535  decode.d1.loss_mask: 1.0100  decode.d1.loss_dice: 0.7737  decode.d2.loss_cls: 0.2415  decode.d2.loss_mask: 0.9820  decode.d2.loss_dice: 0.7805  decode.d3.loss_cls: 0.2629  decode.d3.loss_mask: 0.9651  decode.d3.loss_dice: 0.7583  decode.d4.loss_cls: 0.3231  decode.d4.loss_mask: 0.9464  decode.d4.loss_dice: 0.7411  decode.d5.loss_cls: 0.2690  decode.d5.loss_mask: 1.0020  decode.d5.loss_dice: 0.7319  decode.d6.loss_cls: 0.3189  decode.d6.loss_mask: 1.0160  decode.d6.loss_dice: 0.7632  decode.d7.loss_cls: 0.2952  decode.d7.loss_mask: 0.9547  decode.d7.loss_dice: 0.7522  decode.d8.loss_cls: 0.2920  decode.d8.loss_mask: 1.0553  decode.d8.loss_dice: 0.7582
05/26 22:01:48 - mmengine - INFO - Iter(train) [ 93850/160000]  base_lr: 4.5162e-05 lr: 4.5162e-06  eta: 7:34:47  time: 0.4173  data_time: 0.0099  memory: 5974  grad_norm: 693.9317  loss: 19.7196  decode.loss_cls: 0.1607  decode.loss_mask: 1.0677  decode.loss_dice: 0.6939  decode.d0.loss_cls: 0.6275  decode.d0.loss_mask: 1.0410  decode.d0.loss_dice: 0.6668  decode.d1.loss_cls: 0.2081  decode.d1.loss_mask: 1.0536  decode.d1.loss_dice: 0.6792  decode.d2.loss_cls: 0.1841  decode.d2.loss_mask: 1.0580  decode.d2.loss_dice: 0.6818  decode.d3.loss_cls: 0.1527  decode.d3.loss_mask: 1.0646  decode.d3.loss_dice: 0.6735  decode.d4.loss_cls: 0.1966  decode.d4.loss_mask: 1.0601  decode.d4.loss_dice: 0.6821  decode.d5.loss_cls: 0.1693  decode.d5.loss_mask: 1.0723  decode.d5.loss_dice: 0.6824  decode.d6.loss_cls: 0.2105  decode.d6.loss_mask: 1.0542  decode.d6.loss_dice: 0.6804  decode.d7.loss_cls: 0.1885  decode.d7.loss_mask: 1.0493  decode.d7.loss_dice: 0.6891  decode.d8.loss_cls: 0.2008  decode.d8.loss_mask: 1.0819  decode.d8.loss_dice: 0.6891
05/26 22:02:09 - mmengine - INFO - Iter(train) [ 93900/160000]  base_lr: 4.5131e-05 lr: 4.5131e-06  eta: 7:34:27  time: 0.4167  data_time: 0.0098  memory: 5976  grad_norm: 1085.2218  loss: 22.3054  decode.loss_cls: 0.2386  decode.loss_mask: 1.1632  decode.loss_dice: 0.7518  decode.d0.loss_cls: 0.7213  decode.d0.loss_mask: 1.1871  decode.d0.loss_dice: 0.7872  decode.d1.loss_cls: 0.2624  decode.d1.loss_mask: 1.1662  decode.d1.loss_dice: 0.7786  decode.d2.loss_cls: 0.2268  decode.d2.loss_mask: 1.1756  decode.d2.loss_dice: 0.7801  decode.d3.loss_cls: 0.2165  decode.d3.loss_mask: 1.1238  decode.d3.loss_dice: 0.7744  decode.d4.loss_cls: 0.2302  decode.d4.loss_mask: 1.1806  decode.d4.loss_dice: 0.7893  decode.d5.loss_cls: 0.2184  decode.d5.loss_mask: 1.1781  decode.d5.loss_dice: 0.7941  decode.d6.loss_cls: 0.2234  decode.d6.loss_mask: 1.1724  decode.d6.loss_dice: 0.7932  decode.d7.loss_cls: 0.2730  decode.d7.loss_mask: 1.1073  decode.d7.loss_dice: 0.7758  decode.d8.loss_cls: 0.2494  decode.d8.loss_mask: 1.1967  decode.d8.loss_dice: 0.7697
05/26 22:02:30 - mmengine - INFO - Iter(train) [ 93950/160000]  base_lr: 4.5100e-05 lr: 4.5100e-06  eta: 7:34:06  time: 0.4173  data_time: 0.0098  memory: 5968  grad_norm: 524.6037  loss: 18.6695  decode.loss_cls: 0.0932  decode.loss_mask: 1.0977  decode.loss_dice: 0.6292  decode.d0.loss_cls: 0.5645  decode.d0.loss_mask: 1.0106  decode.d0.loss_dice: 0.6044  decode.d1.loss_cls: 0.1256  decode.d1.loss_mask: 1.0903  decode.d1.loss_dice: 0.6161  decode.d2.loss_cls: 0.1259  decode.d2.loss_mask: 1.0714  decode.d2.loss_dice: 0.6142  decode.d3.loss_cls: 0.1193  decode.d3.loss_mask: 1.0960  decode.d3.loss_dice: 0.6221  decode.d4.loss_cls: 0.0961  decode.d4.loss_mask: 1.1013  decode.d4.loss_dice: 0.6281  decode.d5.loss_cls: 0.1284  decode.d5.loss_mask: 1.0963  decode.d5.loss_dice: 0.6202  decode.d6.loss_cls: 0.1201  decode.d6.loss_mask: 1.0967  decode.d6.loss_dice: 0.6292  decode.d7.loss_cls: 0.1185  decode.d7.loss_mask: 1.1097  decode.d7.loss_dice: 0.6111  decode.d8.loss_cls: 0.1010  decode.d8.loss_mask: 1.1049  decode.d8.loss_dice: 0.6276
05/26 22:02:50 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 22:02:50 - mmengine - INFO - Iter(train) [ 94000/160000]  base_lr: 4.5070e-05 lr: 4.5070e-06  eta: 7:33:46  time: 0.4169  data_time: 0.0099  memory: 5966  grad_norm: 766.8740  loss: 25.3346  decode.loss_cls: 0.2795  decode.loss_mask: 1.2739  decode.loss_dice: 0.8899  decode.d0.loss_cls: 0.7618  decode.d0.loss_mask: 1.2816  decode.d0.loss_dice: 0.8489  decode.d1.loss_cls: 0.2900  decode.d1.loss_mask: 1.3378  decode.d1.loss_dice: 0.8933  decode.d2.loss_cls: 0.2889  decode.d2.loss_mask: 1.3145  decode.d2.loss_dice: 0.8643  decode.d3.loss_cls: 0.3511  decode.d3.loss_mask: 1.3400  decode.d3.loss_dice: 0.8826  decode.d4.loss_cls: 0.3166  decode.d4.loss_mask: 1.3324  decode.d4.loss_dice: 0.8862  decode.d5.loss_cls: 0.2733  decode.d5.loss_mask: 1.2901  decode.d5.loss_dice: 0.8820  decode.d6.loss_cls: 0.2672  decode.d6.loss_mask: 1.3380  decode.d6.loss_dice: 0.9084  decode.d7.loss_cls: 0.2673  decode.d7.loss_mask: 1.3305  decode.d7.loss_dice: 0.8857  decode.d8.loss_cls: 0.2409  decode.d8.loss_mask: 1.3272  decode.d8.loss_dice: 0.8908
05/26 22:03:15 - mmengine - INFO - Iter(train) [ 94050/160000]  base_lr: 4.5039e-05 lr: 4.5039e-06  eta: 7:33:28  time: 0.4148  data_time: 0.0098  memory: 5971  grad_norm: 898.8231  loss: 23.2630  decode.loss_cls: 0.2426  decode.loss_mask: 1.1499  decode.loss_dice: 0.8557  decode.d0.loss_cls: 0.7450  decode.d0.loss_mask: 1.1138  decode.d0.loss_dice: 0.8484  decode.d1.loss_cls: 0.2513  decode.d1.loss_mask: 1.1962  decode.d1.loss_dice: 0.8570  decode.d2.loss_cls: 0.2727  decode.d2.loss_mask: 1.1645  decode.d2.loss_dice: 0.8570  decode.d3.loss_cls: 0.2618  decode.d3.loss_mask: 1.1681  decode.d3.loss_dice: 0.8533  decode.d4.loss_cls: 0.2810  decode.d4.loss_mask: 1.1489  decode.d4.loss_dice: 0.8604  decode.d5.loss_cls: 0.2820  decode.d5.loss_mask: 1.1083  decode.d5.loss_dice: 0.8650  decode.d6.loss_cls: 0.2706  decode.d6.loss_mask: 1.1617  decode.d6.loss_dice: 0.8432  decode.d7.loss_cls: 0.3005  decode.d7.loss_mask: 1.1586  decode.d7.loss_dice: 0.8462  decode.d8.loss_cls: 0.2437  decode.d8.loss_mask: 1.1906  decode.d8.loss_dice: 0.8647
05/26 22:03:37 - mmengine - INFO - Iter(train) [ 94100/160000]  base_lr: 4.5008e-05 lr: 4.5008e-06  eta: 7:33:08  time: 0.4165  data_time: 0.0101  memory: 5966  grad_norm: 715.4027  loss: 24.1045  decode.loss_cls: 0.2555  decode.loss_mask: 1.3325  decode.loss_dice: 0.8054  decode.d0.loss_cls: 0.7373  decode.d0.loss_mask: 1.2468  decode.d0.loss_dice: 0.7932  decode.d1.loss_cls: 0.2175  decode.d1.loss_mask: 1.3438  decode.d1.loss_dice: 0.7986  decode.d2.loss_cls: 0.2454  decode.d2.loss_mask: 1.3137  decode.d2.loss_dice: 0.7820  decode.d3.loss_cls: 0.2238  decode.d3.loss_mask: 1.3070  decode.d3.loss_dice: 0.8175  decode.d4.loss_cls: 0.2309  decode.d4.loss_mask: 1.3200  decode.d4.loss_dice: 0.8003  decode.d5.loss_cls: 0.2136  decode.d5.loss_mask: 1.3845  decode.d5.loss_dice: 0.8184  decode.d6.loss_cls: 0.2543  decode.d6.loss_mask: 1.3111  decode.d6.loss_dice: 0.8030  decode.d7.loss_cls: 0.2682  decode.d7.loss_mask: 1.3308  decode.d7.loss_dice: 0.8012  decode.d8.loss_cls: 0.2181  decode.d8.loss_mask: 1.3272  decode.d8.loss_dice: 0.8030
05/26 22:03:57 - mmengine - INFO - Iter(train) [ 94150/160000]  base_lr: 4.4977e-05 lr: 4.4977e-06  eta: 7:32:47  time: 0.4164  data_time: 0.0098  memory: 5979  grad_norm: 453.4429  loss: 20.8549  decode.loss_cls: 0.1329  decode.loss_mask: 1.1140  decode.loss_dice: 0.7710  decode.d0.loss_cls: 0.6948  decode.d0.loss_mask: 1.0961  decode.d0.loss_dice: 0.7605  decode.d1.loss_cls: 0.1573  decode.d1.loss_mask: 1.1495  decode.d1.loss_dice: 0.7847  decode.d2.loss_cls: 0.1385  decode.d2.loss_mask: 1.1152  decode.d2.loss_dice: 0.7696  decode.d3.loss_cls: 0.1498  decode.d3.loss_mask: 1.1095  decode.d3.loss_dice: 0.7718  decode.d4.loss_cls: 0.1399  decode.d4.loss_mask: 1.1056  decode.d4.loss_dice: 0.7723  decode.d5.loss_cls: 0.1538  decode.d5.loss_mask: 1.1067  decode.d5.loss_dice: 0.7736  decode.d6.loss_cls: 0.1380  decode.d6.loss_mask: 1.1068  decode.d6.loss_dice: 0.7730  decode.d7.loss_cls: 0.1333  decode.d7.loss_mask: 1.1103  decode.d7.loss_dice: 0.7733  decode.d8.loss_cls: 0.1328  decode.d8.loss_mask: 1.1204  decode.d8.loss_dice: 0.7997
05/26 22:04:18 - mmengine - INFO - Iter(train) [ 94200/160000]  base_lr: 4.4947e-05 lr: 4.4947e-06  eta: 7:32:27  time: 0.4171  data_time: 0.0099  memory: 5973  grad_norm: 532.8651  loss: 19.8540  decode.loss_cls: 0.2933  decode.loss_mask: 0.9790  decode.loss_dice: 0.7376  decode.d0.loss_cls: 0.7161  decode.d0.loss_mask: 0.8575  decode.d0.loss_dice: 0.7340  decode.d1.loss_cls: 0.3088  decode.d1.loss_mask: 0.9651  decode.d1.loss_dice: 0.7041  decode.d2.loss_cls: 0.3103  decode.d2.loss_mask: 0.9137  decode.d2.loss_dice: 0.6940  decode.d3.loss_cls: 0.2724  decode.d3.loss_mask: 0.9665  decode.d3.loss_dice: 0.6980  decode.d4.loss_cls: 0.3627  decode.d4.loss_mask: 0.8966  decode.d4.loss_dice: 0.7037  decode.d5.loss_cls: 0.3035  decode.d5.loss_mask: 0.9315  decode.d5.loss_dice: 0.7041  decode.d6.loss_cls: 0.2986  decode.d6.loss_mask: 0.9423  decode.d6.loss_dice: 0.7176  decode.d7.loss_cls: 0.3643  decode.d7.loss_mask: 0.8507  decode.d7.loss_dice: 0.7030  decode.d8.loss_cls: 0.3357  decode.d8.loss_mask: 0.8481  decode.d8.loss_dice: 0.7413
05/26 22:04:39 - mmengine - INFO - Iter(train) [ 94250/160000]  base_lr: 4.4916e-05 lr: 4.4916e-06  eta: 7:32:06  time: 0.4169  data_time: 0.0099  memory: 5975  grad_norm: 505.6650  loss: 19.0471  decode.loss_cls: 0.1871  decode.loss_mask: 0.9592  decode.loss_dice: 0.7002  decode.d0.loss_cls: 0.6986  decode.d0.loss_mask: 0.9518  decode.d0.loss_dice: 0.7033  decode.d1.loss_cls: 0.1512  decode.d1.loss_mask: 1.0252  decode.d1.loss_dice: 0.7137  decode.d2.loss_cls: 0.1446  decode.d2.loss_mask: 1.0131  decode.d2.loss_dice: 0.7251  decode.d3.loss_cls: 0.1632  decode.d3.loss_mask: 0.9670  decode.d3.loss_dice: 0.7137  decode.d4.loss_cls: 0.1723  decode.d4.loss_mask: 0.9910  decode.d4.loss_dice: 0.6907  decode.d5.loss_cls: 0.1996  decode.d5.loss_mask: 0.9608  decode.d5.loss_dice: 0.6828  decode.d6.loss_cls: 0.1869  decode.d6.loss_mask: 0.9860  decode.d6.loss_dice: 0.6994  decode.d7.loss_cls: 0.1857  decode.d7.loss_mask: 0.9603  decode.d7.loss_dice: 0.6882  decode.d8.loss_cls: 0.1731  decode.d8.loss_mask: 0.9623  decode.d8.loss_dice: 0.6909
05/26 22:05:00 - mmengine - INFO - Iter(train) [ 94300/160000]  base_lr: 4.4885e-05 lr: 4.4885e-06  eta: 7:31:46  time: 0.4173  data_time: 0.0098  memory: 5976  grad_norm: 1090.7371  loss: 23.2818  decode.loss_cls: 0.2825  decode.loss_mask: 1.1995  decode.loss_dice: 0.8353  decode.d0.loss_cls: 0.7835  decode.d0.loss_mask: 1.0980  decode.d0.loss_dice: 0.7769  decode.d1.loss_cls: 0.2948  decode.d1.loss_mask: 1.1700  decode.d1.loss_dice: 0.8029  decode.d2.loss_cls: 0.2983  decode.d2.loss_mask: 1.1654  decode.d2.loss_dice: 0.7836  decode.d3.loss_cls: 0.3003  decode.d3.loss_mask: 1.1695  decode.d3.loss_dice: 0.8117  decode.d4.loss_cls: 0.3142  decode.d4.loss_mask: 1.1950  decode.d4.loss_dice: 0.7869  decode.d5.loss_cls: 0.3063  decode.d5.loss_mask: 1.1951  decode.d5.loss_dice: 0.7900  decode.d6.loss_cls: 0.3437  decode.d6.loss_mask: 1.1764  decode.d6.loss_dice: 0.7915  decode.d7.loss_cls: 0.3043  decode.d7.loss_mask: 1.2065  decode.d7.loss_dice: 0.8211  decode.d8.loss_cls: 0.2992  decode.d8.loss_mask: 1.1647  decode.d8.loss_dice: 0.8150
05/26 22:05:21 - mmengine - INFO - Iter(train) [ 94350/160000]  base_lr: 4.4854e-05 lr: 4.4854e-06  eta: 7:31:25  time: 0.4169  data_time: 0.0099  memory: 5972  grad_norm: 597.9290  loss: 20.9995  decode.loss_cls: 0.1270  decode.loss_mask: 1.2478  decode.loss_dice: 0.7109  decode.d0.loss_cls: 0.5684  decode.d0.loss_mask: 1.1658  decode.d0.loss_dice: 0.6717  decode.d1.loss_cls: 0.1046  decode.d1.loss_mask: 1.2558  decode.d1.loss_dice: 0.7052  decode.d2.loss_cls: 0.1019  decode.d2.loss_mask: 1.2597  decode.d2.loss_dice: 0.7043  decode.d3.loss_cls: 0.0998  decode.d3.loss_mask: 1.2585  decode.d3.loss_dice: 0.7007  decode.d4.loss_cls: 0.1177  decode.d4.loss_mask: 1.2352  decode.d4.loss_dice: 0.7021  decode.d5.loss_cls: 0.1536  decode.d5.loss_mask: 1.2250  decode.d5.loss_dice: 0.6868  decode.d6.loss_cls: 0.1388  decode.d6.loss_mask: 1.2287  decode.d6.loss_dice: 0.6940  decode.d7.loss_cls: 0.1383  decode.d7.loss_mask: 1.2316  decode.d7.loss_dice: 0.6904  decode.d8.loss_cls: 0.1214  decode.d8.loss_mask: 1.2437  decode.d8.loss_dice: 0.7101
05/26 22:05:42 - mmengine - INFO - Iter(train) [ 94400/160000]  base_lr: 4.4824e-05 lr: 4.4824e-06  eta: 7:31:05  time: 0.4153  data_time: 0.0098  memory: 5971  grad_norm: 948.6660  loss: 21.3084  decode.loss_cls: 0.2388  decode.loss_mask: 1.0390  decode.loss_dice: 0.7831  decode.d0.loss_cls: 0.7641  decode.d0.loss_mask: 0.9910  decode.d0.loss_dice: 0.7871  decode.d1.loss_cls: 0.2333  decode.d1.loss_mask: 1.1005  decode.d1.loss_dice: 0.8235  decode.d2.loss_cls: 0.2423  decode.d2.loss_mask: 1.0934  decode.d2.loss_dice: 0.8281  decode.d3.loss_cls: 0.2270  decode.d3.loss_mask: 1.0714  decode.d3.loss_dice: 0.7932  decode.d4.loss_cls: 0.2285  decode.d4.loss_mask: 1.0704  decode.d4.loss_dice: 0.7770  decode.d5.loss_cls: 0.2593  decode.d5.loss_mask: 1.0350  decode.d5.loss_dice: 0.7659  decode.d6.loss_cls: 0.2044  decode.d6.loss_mask: 1.0662  decode.d6.loss_dice: 0.8028  decode.d7.loss_cls: 0.2316  decode.d7.loss_mask: 1.0324  decode.d7.loss_dice: 0.7849  decode.d8.loss_cls: 0.2234  decode.d8.loss_mask: 1.0365  decode.d8.loss_dice: 0.7742
05/26 22:06:03 - mmengine - INFO - Iter(train) [ 94450/160000]  base_lr: 4.4793e-05 lr: 4.4793e-06  eta: 7:30:45  time: 0.4159  data_time: 0.0098  memory: 5976  grad_norm: 479.3787  loss: 18.2524  decode.loss_cls: 0.1174  decode.loss_mask: 0.9345  decode.loss_dice: 0.7147  decode.d0.loss_cls: 0.6225  decode.d0.loss_mask: 0.9270  decode.d0.loss_dice: 0.6722  decode.d1.loss_cls: 0.1009  decode.d1.loss_mask: 0.9874  decode.d1.loss_dice: 0.7250  decode.d2.loss_cls: 0.0922  decode.d2.loss_mask: 0.9849  decode.d2.loss_dice: 0.7172  decode.d3.loss_cls: 0.0933  decode.d3.loss_mask: 0.9635  decode.d3.loss_dice: 0.7148  decode.d4.loss_cls: 0.1262  decode.d4.loss_mask: 0.9416  decode.d4.loss_dice: 0.7056  decode.d5.loss_cls: 0.1131  decode.d5.loss_mask: 0.9555  decode.d5.loss_dice: 0.7034  decode.d6.loss_cls: 0.0903  decode.d6.loss_mask: 0.9620  decode.d6.loss_dice: 0.7272  decode.d7.loss_cls: 0.1176  decode.d7.loss_mask: 0.9520  decode.d7.loss_dice: 0.7144  decode.d8.loss_cls: 0.0944  decode.d8.loss_mask: 0.9617  decode.d8.loss_dice: 0.7202
05/26 22:06:24 - mmengine - INFO - Iter(train) [ 94500/160000]  base_lr: 4.4762e-05 lr: 4.4762e-06  eta: 7:30:24  time: 0.4157  data_time: 0.0098  memory: 5976  grad_norm: 445.9276  loss: 23.0723  decode.loss_cls: 0.2831  decode.loss_mask: 1.1218  decode.loss_dice: 0.8820  decode.d0.loss_cls: 0.8273  decode.d0.loss_mask: 1.0664  decode.d0.loss_dice: 0.8724  decode.d1.loss_cls: 0.3319  decode.d1.loss_mask: 1.0661  decode.d1.loss_dice: 0.8399  decode.d2.loss_cls: 0.2933  decode.d2.loss_mask: 1.1061  decode.d2.loss_dice: 0.8436  decode.d3.loss_cls: 0.2727  decode.d3.loss_mask: 1.1100  decode.d3.loss_dice: 0.8534  decode.d4.loss_cls: 0.2901  decode.d4.loss_mask: 1.0847  decode.d4.loss_dice: 0.8445  decode.d5.loss_cls: 0.2820  decode.d5.loss_mask: 1.1163  decode.d5.loss_dice: 0.8672  decode.d6.loss_cls: 0.2896  decode.d6.loss_mask: 1.1389  decode.d6.loss_dice: 0.8808  decode.d7.loss_cls: 0.3037  decode.d7.loss_mask: 1.1043  decode.d7.loss_dice: 0.8451  decode.d8.loss_cls: 0.2910  decode.d8.loss_mask: 1.1071  decode.d8.loss_dice: 0.8568
05/26 22:06:45 - mmengine - INFO - Iter(train) [ 94550/160000]  base_lr: 4.4731e-05 lr: 4.4731e-06  eta: 7:30:04  time: 0.4154  data_time: 0.0099  memory: 5969  grad_norm: 565.9916  loss: 20.0483  decode.loss_cls: 0.3361  decode.loss_mask: 0.9700  decode.loss_dice: 0.6655  decode.d0.loss_cls: 0.7580  decode.d0.loss_mask: 0.9626  decode.d0.loss_dice: 0.6608  decode.d1.loss_cls: 0.3475  decode.d1.loss_mask: 0.9576  decode.d1.loss_dice: 0.6613  decode.d2.loss_cls: 0.3528  decode.d2.loss_mask: 1.0043  decode.d2.loss_dice: 0.6822  decode.d3.loss_cls: 0.3564  decode.d3.loss_mask: 0.9298  decode.d3.loss_dice: 0.6432  decode.d4.loss_cls: 0.3711  decode.d4.loss_mask: 0.9403  decode.d4.loss_dice: 0.6399  decode.d5.loss_cls: 0.3612  decode.d5.loss_mask: 0.9180  decode.d5.loss_dice: 0.6645  decode.d6.loss_cls: 0.3125  decode.d6.loss_mask: 0.9114  decode.d6.loss_dice: 0.7039  decode.d7.loss_cls: 0.3599  decode.d7.loss_mask: 0.9400  decode.d7.loss_dice: 0.6659  decode.d8.loss_cls: 0.3257  decode.d8.loss_mask: 0.9800  decode.d8.loss_dice: 0.6661
05/26 22:07:06 - mmengine - INFO - Iter(train) [ 94600/160000]  base_lr: 4.4701e-05 lr: 4.4701e-06  eta: 7:29:43  time: 0.4141  data_time: 0.0098  memory: 5976  grad_norm: 847.1763  loss: 21.5721  decode.loss_cls: 0.2164  decode.loss_mask: 1.1490  decode.loss_dice: 0.7500  decode.d0.loss_cls: 0.6893  decode.d0.loss_mask: 1.0598  decode.d0.loss_dice: 0.7081  decode.d1.loss_cls: 0.2593  decode.d1.loss_mask: 1.1149  decode.d1.loss_dice: 0.7513  decode.d2.loss_cls: 0.2428  decode.d2.loss_mask: 1.1605  decode.d2.loss_dice: 0.7629  decode.d3.loss_cls: 0.2132  decode.d3.loss_mask: 1.1332  decode.d3.loss_dice: 0.7488  decode.d4.loss_cls: 0.2268  decode.d4.loss_mask: 1.1387  decode.d4.loss_dice: 0.7582  decode.d5.loss_cls: 0.2630  decode.d5.loss_mask: 1.1285  decode.d5.loss_dice: 0.7404  decode.d6.loss_cls: 0.2347  decode.d6.loss_mask: 1.1345  decode.d6.loss_dice: 0.7439  decode.d7.loss_cls: 0.2477  decode.d7.loss_mask: 1.1079  decode.d7.loss_dice: 0.7476  decode.d8.loss_cls: 0.2504  decode.d8.loss_mask: 1.1287  decode.d8.loss_dice: 0.7619
05/26 22:07:26 - mmengine - INFO - Iter(train) [ 94650/160000]  base_lr: 4.4670e-05 lr: 4.4670e-06  eta: 7:29:23  time: 0.4151  data_time: 0.0098  memory: 5976  grad_norm: 750.0310  loss: 22.1696  decode.loss_cls: 0.2820  decode.loss_mask: 1.0449  decode.loss_dice: 0.8393  decode.d0.loss_cls: 0.7276  decode.d0.loss_mask: 1.0449  decode.d0.loss_dice: 0.8948  decode.d1.loss_cls: 0.2617  decode.d1.loss_mask: 1.0564  decode.d1.loss_dice: 0.8448  decode.d2.loss_cls: 0.2422  decode.d2.loss_mask: 1.0368  decode.d2.loss_dice: 0.8273  decode.d3.loss_cls: 0.2723  decode.d3.loss_mask: 1.0786  decode.d3.loss_dice: 0.8313  decode.d4.loss_cls: 0.2611  decode.d4.loss_mask: 1.0540  decode.d4.loss_dice: 0.8363  decode.d5.loss_cls: 0.2536  decode.d5.loss_mask: 1.0651  decode.d5.loss_dice: 0.8525  decode.d6.loss_cls: 0.2605  decode.d6.loss_mask: 1.0597  decode.d6.loss_dice: 0.8441  decode.d7.loss_cls: 0.2511  decode.d7.loss_mask: 1.1122  decode.d7.loss_dice: 0.8811  decode.d8.loss_cls: 0.2639  decode.d8.loss_mask: 1.0543  decode.d8.loss_dice: 0.8351
05/26 22:07:47 - mmengine - INFO - Iter(train) [ 94700/160000]  base_lr: 4.4639e-05 lr: 4.4639e-06  eta: 7:29:02  time: 0.4147  data_time: 0.0099  memory: 5976  grad_norm: 704.8064  loss: 21.5530  decode.loss_cls: 0.2389  decode.loss_mask: 1.0809  decode.loss_dice: 0.7959  decode.d0.loss_cls: 0.7932  decode.d0.loss_mask: 1.0005  decode.d0.loss_dice: 0.7661  decode.d1.loss_cls: 0.2786  decode.d1.loss_mask: 1.0544  decode.d1.loss_dice: 0.7840  decode.d2.loss_cls: 0.2527  decode.d2.loss_mask: 1.0305  decode.d2.loss_dice: 0.7630  decode.d3.loss_cls: 0.2453  decode.d3.loss_mask: 1.0877  decode.d3.loss_dice: 0.8195  decode.d4.loss_cls: 0.2947  decode.d4.loss_mask: 1.0107  decode.d4.loss_dice: 0.7843  decode.d5.loss_cls: 0.2656  decode.d5.loss_mask: 1.0396  decode.d5.loss_dice: 0.7894  decode.d6.loss_cls: 0.2658  decode.d6.loss_mask: 1.0628  decode.d6.loss_dice: 0.8222  decode.d7.loss_cls: 0.2292  decode.d7.loss_mask: 1.0709  decode.d7.loss_dice: 0.7799  decode.d8.loss_cls: 0.2678  decode.d8.loss_mask: 1.0721  decode.d8.loss_dice: 0.8069
05/26 22:08:08 - mmengine - INFO - Iter(train) [ 94750/160000]  base_lr: 4.4608e-05 lr: 4.4608e-06  eta: 7:28:42  time: 0.4173  data_time: 0.0100  memory: 5966  grad_norm: 1654.0249  loss: 21.7579  decode.loss_cls: 0.1891  decode.loss_mask: 1.1786  decode.loss_dice: 0.7482  decode.d0.loss_cls: 0.6118  decode.d0.loss_mask: 1.1485  decode.d0.loss_dice: 0.7765  decode.d1.loss_cls: 0.2277  decode.d1.loss_mask: 1.1883  decode.d1.loss_dice: 0.7612  decode.d2.loss_cls: 0.2126  decode.d2.loss_mask: 1.1899  decode.d2.loss_dice: 0.7689  decode.d3.loss_cls: 0.1732  decode.d3.loss_mask: 1.1967  decode.d3.loss_dice: 0.7620  decode.d4.loss_cls: 0.1820  decode.d4.loss_mask: 1.1812  decode.d4.loss_dice: 0.7380  decode.d5.loss_cls: 0.1815  decode.d5.loss_mask: 1.1865  decode.d5.loss_dice: 0.7317  decode.d6.loss_cls: 0.1746  decode.d6.loss_mask: 1.1932  decode.d6.loss_dice: 0.7462  decode.d7.loss_cls: 0.1916  decode.d7.loss_mask: 1.1951  decode.d7.loss_dice: 0.7487  decode.d8.loss_cls: 0.2054  decode.d8.loss_mask: 1.2012  decode.d8.loss_dice: 0.7680
05/26 22:08:29 - mmengine - INFO - Iter(train) [ 94800/160000]  base_lr: 4.4578e-05 lr: 4.4578e-06  eta: 7:28:21  time: 0.4177  data_time: 0.0099  memory: 5969  grad_norm: 525.9526  loss: 20.9298  decode.loss_cls: 0.2453  decode.loss_mask: 0.9879  decode.loss_dice: 0.7837  decode.d0.loss_cls: 0.8583  decode.d0.loss_mask: 0.9437  decode.d0.loss_dice: 0.7694  decode.d1.loss_cls: 0.3024  decode.d1.loss_mask: 0.9768  decode.d1.loss_dice: 0.7799  decode.d2.loss_cls: 0.2821  decode.d2.loss_mask: 0.9675  decode.d2.loss_dice: 0.7718  decode.d3.loss_cls: 0.2735  decode.d3.loss_mask: 0.9670  decode.d3.loss_dice: 0.7834  decode.d4.loss_cls: 0.2798  decode.d4.loss_mask: 0.9493  decode.d4.loss_dice: 0.7832  decode.d5.loss_cls: 0.2735  decode.d5.loss_mask: 0.9864  decode.d5.loss_dice: 0.7776  decode.d6.loss_cls: 0.3129  decode.d6.loss_mask: 1.0002  decode.d6.loss_dice: 0.7833  decode.d7.loss_cls: 0.2703  decode.d7.loss_mask: 0.9749  decode.d7.loss_dice: 0.7849  decode.d8.loss_cls: 0.2623  decode.d8.loss_mask: 0.9918  decode.d8.loss_dice: 0.8069
05/26 22:08:50 - mmengine - INFO - Iter(train) [ 94850/160000]  base_lr: 4.4547e-05 lr: 4.4547e-06  eta: 7:28:01  time: 0.4139  data_time: 0.0097  memory: 5967  grad_norm: 598.0480  loss: 21.2336  decode.loss_cls: 0.2607  decode.loss_mask: 1.0627  decode.loss_dice: 0.7422  decode.d0.loss_cls: 0.6839  decode.d0.loss_mask: 1.0654  decode.d0.loss_dice: 0.7416  decode.d1.loss_cls: 0.3203  decode.d1.loss_mask: 1.0839  decode.d1.loss_dice: 0.7397  decode.d2.loss_cls: 0.2356  decode.d2.loss_mask: 1.0752  decode.d2.loss_dice: 0.7481  decode.d3.loss_cls: 0.2874  decode.d3.loss_mask: 1.0805  decode.d3.loss_dice: 0.7185  decode.d4.loss_cls: 0.3235  decode.d4.loss_mask: 1.0662  decode.d4.loss_dice: 0.7134  decode.d5.loss_cls: 0.2633  decode.d5.loss_mask: 1.0706  decode.d5.loss_dice: 0.7395  decode.d6.loss_cls: 0.2518  decode.d6.loss_mask: 1.0904  decode.d6.loss_dice: 0.7390  decode.d7.loss_cls: 0.3095  decode.d7.loss_mask: 1.0397  decode.d7.loss_dice: 0.7372  decode.d8.loss_cls: 0.2629  decode.d8.loss_mask: 1.0603  decode.d8.loss_dice: 0.7204
05/26 22:09:10 - mmengine - INFO - Iter(train) [ 94900/160000]  base_lr: 4.4516e-05 lr: 4.4516e-06  eta: 7:27:40  time: 0.4135  data_time: 0.0097  memory: 5969  grad_norm: 1021.7128  loss: 24.2149  decode.loss_cls: 0.1584  decode.loss_mask: 1.3167  decode.loss_dice: 0.8767  decode.d0.loss_cls: 0.7857  decode.d0.loss_mask: 1.2488  decode.d0.loss_dice: 0.8292  decode.d1.loss_cls: 0.2006  decode.d1.loss_mask: 1.2882  decode.d1.loss_dice: 0.9033  decode.d2.loss_cls: 0.1544  decode.d2.loss_mask: 1.3440  decode.d2.loss_dice: 0.9106  decode.d3.loss_cls: 0.1917  decode.d3.loss_mask: 1.3118  decode.d3.loss_dice: 0.8868  decode.d4.loss_cls: 0.1693  decode.d4.loss_mask: 1.3211  decode.d4.loss_dice: 0.9059  decode.d5.loss_cls: 0.1820  decode.d5.loss_mask: 1.2847  decode.d5.loss_dice: 0.8908  decode.d6.loss_cls: 0.2019  decode.d6.loss_mask: 1.2763  decode.d6.loss_dice: 0.8705  decode.d7.loss_cls: 0.2126  decode.d7.loss_mask: 1.2848  decode.d7.loss_dice: 0.8716  decode.d8.loss_cls: 0.1804  decode.d8.loss_mask: 1.2840  decode.d8.loss_dice: 0.8720
05/26 22:09:31 - mmengine - INFO - Iter(train) [ 94950/160000]  base_lr: 4.4485e-05 lr: 4.4485e-06  eta: 7:27:20  time: 0.4119  data_time: 0.0097  memory: 5967  grad_norm: 584.7181  loss: 18.2475  decode.loss_cls: 0.1045  decode.loss_mask: 0.9688  decode.loss_dice: 0.7087  decode.d0.loss_cls: 0.5184  decode.d0.loss_mask: 0.9702  decode.d0.loss_dice: 0.6583  decode.d1.loss_cls: 0.1309  decode.d1.loss_mask: 0.9731  decode.d1.loss_dice: 0.6854  decode.d2.loss_cls: 0.1586  decode.d2.loss_mask: 0.9322  decode.d2.loss_dice: 0.6833  decode.d3.loss_cls: 0.1606  decode.d3.loss_mask: 0.9542  decode.d3.loss_dice: 0.6814  decode.d4.loss_cls: 0.1348  decode.d4.loss_mask: 0.9566  decode.d4.loss_dice: 0.6753  decode.d5.loss_cls: 0.2036  decode.d5.loss_mask: 0.9512  decode.d5.loss_dice: 0.7057  decode.d6.loss_cls: 0.1403  decode.d6.loss_mask: 0.9503  decode.d6.loss_dice: 0.7004  decode.d7.loss_cls: 0.1669  decode.d7.loss_mask: 0.9294  decode.d7.loss_dice: 0.6783  decode.d8.loss_cls: 0.1314  decode.d8.loss_mask: 0.9396  decode.d8.loss_dice: 0.6947
05/26 22:09:52 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 22:09:52 - mmengine - INFO - Iter(train) [ 95000/160000]  base_lr: 4.4455e-05 lr: 4.4455e-06  eta: 7:26:59  time: 0.4179  data_time: 0.0100  memory: 5969  grad_norm: 394.1946  loss: 20.6670  decode.loss_cls: 0.2359  decode.loss_mask: 1.0396  decode.loss_dice: 0.7254  decode.d0.loss_cls: 0.7114  decode.d0.loss_mask: 1.0484  decode.d0.loss_dice: 0.6878  decode.d1.loss_cls: 0.2253  decode.d1.loss_mask: 1.0946  decode.d1.loss_dice: 0.7208  decode.d2.loss_cls: 0.2382  decode.d2.loss_mask: 1.0700  decode.d2.loss_dice: 0.6994  decode.d3.loss_cls: 0.2987  decode.d3.loss_mask: 1.0268  decode.d3.loss_dice: 0.7034  decode.d4.loss_cls: 0.2393  decode.d4.loss_mask: 1.0883  decode.d4.loss_dice: 0.7117  decode.d5.loss_cls: 0.2579  decode.d5.loss_mask: 1.0693  decode.d5.loss_dice: 0.7224  decode.d6.loss_cls: 0.2391  decode.d6.loss_mask: 1.0610  decode.d6.loss_dice: 0.7433  decode.d7.loss_cls: 0.2467  decode.d7.loss_mask: 1.0604  decode.d7.loss_dice: 0.7205  decode.d8.loss_cls: 0.1936  decode.d8.loss_mask: 1.0738  decode.d8.loss_dice: 0.7141
05/26 22:09:52 - mmengine - INFO - Saving checkpoint at 95000 iterations
05/26 22:09:57 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:12  time: 0.0508  data_time: 0.0013  memory: 1391  
05/26 22:09:59 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:07  time: 0.0486  data_time: 0.0012  memory: 1205  
05/26 22:10:02 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:05  time: 0.0518  data_time: 0.0012  memory: 1596  
05/26 22:10:04 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:02  time: 0.0554  data_time: 0.0013  memory: 1298  
05/26 22:10:07 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:01:01  time: 0.0563  data_time: 0.0013  memory: 1298  
05/26 22:10:10 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:58  time: 0.0483  data_time: 0.0013  memory: 1279  
05/26 22:10:12 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:55  time: 0.0481  data_time: 0.0013  memory: 1224  
05/26 22:10:15 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:52  time: 0.0491  data_time: 0.0012  memory: 1298  
05/26 22:10:17 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:50  time: 0.0501  data_time: 0.0013  memory: 1298  
05/26 22:10:19 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:47  time: 0.0517  data_time: 0.0012  memory: 1725  
05/26 22:10:22 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:45  time: 0.0492  data_time: 0.0012  memory: 1336  
05/26 22:10:24 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:42  time: 0.0485  data_time: 0.0012  memory: 1298  
05/26 22:10:27 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:39  time: 0.0505  data_time: 0.0013  memory: 1205  
05/26 22:10:29 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:37  time: 0.0499  data_time: 0.0013  memory: 1316  
05/26 22:10:32 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:34  time: 0.0481  data_time: 0.0012  memory: 1279  
05/26 22:10:34 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:32  time: 0.0523  data_time: 0.0012  memory: 1410  
05/26 22:10:37 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:29  time: 0.0488  data_time: 0.0013  memory: 1279  
05/26 22:10:39 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:27  time: 0.0500  data_time: 0.0012  memory: 1205  
05/26 22:10:42 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0487  data_time: 0.0012  memory: 1205  
05/26 22:10:44 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:22  time: 0.0493  data_time: 0.0012  memory: 1336  
05/26 22:10:46 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0479  data_time: 0.0012  memory: 1246  
05/26 22:10:49 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0519  data_time: 0.0013  memory: 1503  
05/26 22:10:51 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0490  data_time: 0.0012  memory: 1261  
05/26 22:10:54 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0492  data_time: 0.0012  memory: 1298  
05/26 22:10:56 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0496  data_time: 0.0012  memory: 1447  
05/26 22:10:59 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0481  data_time: 0.0013  memory: 1298  
05/26 22:11:01 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0507  data_time: 0.0012  memory: 1279  
05/26 22:11:04 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0482  data_time: 0.0012  memory: 1205  
05/26 22:11:06 - mmengine - INFO - per class results:
05/26 22:11:06 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.12 | 96.32 |
|  aeroplane  | 94.79 | 97.35 |
|   bicycle   | 43.82 | 96.58 |
|     bird    | 94.16 | 96.01 |
|     boat    | 72.03 | 88.68 |
|    bottle   | 83.39 | 93.56 |
|     bus     | 95.79 |  97.6 |
|     car     | 91.47 | 95.15 |
|     cat     | 93.87 | 96.08 |
|    chair    | 42.53 | 66.11 |
|     cow     | 76.36 | 79.61 |
| diningtable | 66.14 | 84.82 |
|     dog     | 89.92 | 97.96 |
|    horse    | 80.18 | 96.25 |
|  motorbike  | 90.72 | 94.47 |
|    person   | 89.92 |  95.4 |
| pottedplant | 70.46 | 91.07 |
|    sheep    |  85.0 | 92.13 |
|     sofa    | 49.13 | 82.77 |
|    train    | 88.94 | 93.27 |
|  tvmonitor  | 77.98 | 88.87 |
+-------------+-------+-------+
05/26 22:11:06 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.2700  mIoU: 79.6100  mAcc: 91.4300  data_time: 0.0013  time: 0.0495
05/26 22:11:27 - mmengine - INFO - Iter(train) [ 95050/160000]  base_lr: 4.4424e-05 lr: 4.4424e-06  eta: 7:26:39  time: 0.4196  data_time: 0.0099  memory: 5975  grad_norm: 1430.2768  loss: 22.1956  decode.loss_cls: 0.2363  decode.loss_mask: 1.0823  decode.loss_dice: 0.8433  decode.d0.loss_cls: 0.7538  decode.d0.loss_mask: 1.0393  decode.d0.loss_dice: 0.8066  decode.d1.loss_cls: 0.2811  decode.d1.loss_mask: 1.0753  decode.d1.loss_dice: 0.8311  decode.d2.loss_cls: 0.2664  decode.d2.loss_mask: 1.0915  decode.d2.loss_dice: 0.8599  decode.d3.loss_cls: 0.2585  decode.d3.loss_mask: 1.0834  decode.d3.loss_dice: 0.8295  decode.d4.loss_cls: 0.2374  decode.d4.loss_mask: 1.0892  decode.d4.loss_dice: 0.8348  decode.d5.loss_cls: 0.2410  decode.d5.loss_mask: 1.0634  decode.d5.loss_dice: 0.8304  decode.d6.loss_cls: 0.2786  decode.d6.loss_mask: 1.0852  decode.d6.loss_dice: 0.8633  decode.d7.loss_cls: 0.2464  decode.d7.loss_mask: 1.0740  decode.d7.loss_dice: 0.8468  decode.d8.loss_cls: 0.2363  decode.d8.loss_mask: 1.0645  decode.d8.loss_dice: 0.8662
05/26 22:11:48 - mmengine - INFO - Iter(train) [ 95100/160000]  base_lr: 4.4393e-05 lr: 4.4393e-06  eta: 7:26:18  time: 0.4180  data_time: 0.0099  memory: 5967  grad_norm: 825.6464  loss: 21.8051  decode.loss_cls: 0.2832  decode.loss_mask: 1.1162  decode.loss_dice: 0.7529  decode.d0.loss_cls: 0.7626  decode.d0.loss_mask: 1.0356  decode.d0.loss_dice: 0.7161  decode.d1.loss_cls: 0.2923  decode.d1.loss_mask: 1.1245  decode.d1.loss_dice: 0.7485  decode.d2.loss_cls: 0.2943  decode.d2.loss_mask: 1.1127  decode.d2.loss_dice: 0.7241  decode.d3.loss_cls: 0.2876  decode.d3.loss_mask: 1.1365  decode.d3.loss_dice: 0.7490  decode.d4.loss_cls: 0.2719  decode.d4.loss_mask: 1.1400  decode.d4.loss_dice: 0.7417  decode.d5.loss_cls: 0.2453  decode.d5.loss_mask: 1.1490  decode.d5.loss_dice: 0.7468  decode.d6.loss_cls: 0.2548  decode.d6.loss_mask: 1.1286  decode.d6.loss_dice: 0.7518  decode.d7.loss_cls: 0.2645  decode.d7.loss_mask: 1.1223  decode.d7.loss_dice: 0.7455  decode.d8.loss_cls: 0.2258  decode.d8.loss_mask: 1.1277  decode.d8.loss_dice: 0.7531
05/26 22:12:09 - mmengine - INFO - Iter(train) [ 95150/160000]  base_lr: 4.4362e-05 lr: 4.4362e-06  eta: 7:25:58  time: 0.4180  data_time: 0.0098  memory: 5976  grad_norm: 514.5501  loss: 23.6906  decode.loss_cls: 0.3258  decode.loss_mask: 1.0992  decode.loss_dice: 0.9630  decode.d0.loss_cls: 0.9084  decode.d0.loss_mask: 0.9733  decode.d0.loss_dice: 0.8775  decode.d1.loss_cls: 0.3586  decode.d1.loss_mask: 1.0831  decode.d1.loss_dice: 0.9362  decode.d2.loss_cls: 0.3006  decode.d2.loss_mask: 1.0567  decode.d2.loss_dice: 0.9422  decode.d3.loss_cls: 0.3228  decode.d3.loss_mask: 1.0306  decode.d3.loss_dice: 0.9423  decode.d4.loss_cls: 0.3576  decode.d4.loss_mask: 1.0391  decode.d4.loss_dice: 0.9231  decode.d5.loss_cls: 0.3215  decode.d5.loss_mask: 1.0517  decode.d5.loss_dice: 0.9298  decode.d6.loss_cls: 0.3354  decode.d6.loss_mask: 1.0466  decode.d6.loss_dice: 0.9171  decode.d7.loss_cls: 0.3431  decode.d7.loss_mask: 1.0562  decode.d7.loss_dice: 0.9398  decode.d8.loss_cls: 0.3622  decode.d8.loss_mask: 1.0331  decode.d8.loss_dice: 0.9140
05/26 22:12:30 - mmengine - INFO - Iter(train) [ 95200/160000]  base_lr: 4.4331e-05 lr: 4.4331e-06  eta: 7:25:37  time: 0.4165  data_time: 0.0098  memory: 5980  grad_norm: 719.3792  loss: 21.9965  decode.loss_cls: 0.2097  decode.loss_mask: 1.1416  decode.loss_dice: 0.7828  decode.d0.loss_cls: 0.7051  decode.d0.loss_mask: 1.1324  decode.d0.loss_dice: 0.7457  decode.d1.loss_cls: 0.2343  decode.d1.loss_mask: 1.1760  decode.d1.loss_dice: 0.7504  decode.d2.loss_cls: 0.1959  decode.d2.loss_mask: 1.1834  decode.d2.loss_dice: 0.7996  decode.d3.loss_cls: 0.1821  decode.d3.loss_mask: 1.1584  decode.d3.loss_dice: 0.7817  decode.d4.loss_cls: 0.2619  decode.d4.loss_mask: 1.1484  decode.d4.loss_dice: 0.7852  decode.d5.loss_cls: 0.1958  decode.d5.loss_mask: 1.1752  decode.d5.loss_dice: 0.8135  decode.d6.loss_cls: 0.2355  decode.d6.loss_mask: 1.1631  decode.d6.loss_dice: 0.7742  decode.d7.loss_cls: 0.2262  decode.d7.loss_mask: 1.1668  decode.d7.loss_dice: 0.7676  decode.d8.loss_cls: 0.1703  decode.d8.loss_mask: 1.1443  decode.d8.loss_dice: 0.7893
05/26 22:12:51 - mmengine - INFO - Iter(train) [ 95250/160000]  base_lr: 4.4301e-05 lr: 4.4301e-06  eta: 7:25:17  time: 0.4176  data_time: 0.0098  memory: 5974  grad_norm: 416.6534  loss: 24.2559  decode.loss_cls: 0.2372  decode.loss_mask: 1.3375  decode.loss_dice: 0.8150  decode.d0.loss_cls: 0.7542  decode.d0.loss_mask: 1.2575  decode.d0.loss_dice: 0.7903  decode.d1.loss_cls: 0.2881  decode.d1.loss_mask: 1.3139  decode.d1.loss_dice: 0.7792  decode.d2.loss_cls: 0.2168  decode.d2.loss_mask: 1.3290  decode.d2.loss_dice: 0.7992  decode.d3.loss_cls: 0.2867  decode.d3.loss_mask: 1.2880  decode.d3.loss_dice: 0.7879  decode.d4.loss_cls: 0.2609  decode.d4.loss_mask: 1.2814  decode.d4.loss_dice: 0.7989  decode.d5.loss_cls: 0.2235  decode.d5.loss_mask: 1.3683  decode.d5.loss_dice: 0.8314  decode.d6.loss_cls: 0.2049  decode.d6.loss_mask: 1.3652  decode.d6.loss_dice: 0.8365  decode.d7.loss_cls: 0.2571  decode.d7.loss_mask: 1.3572  decode.d7.loss_dice: 0.8034  decode.d8.loss_cls: 0.3092  decode.d8.loss_mask: 1.2894  decode.d8.loss_dice: 0.7881
05/26 22:13:12 - mmengine - INFO - Iter(train) [ 95300/160000]  base_lr: 4.4270e-05 lr: 4.4270e-06  eta: 7:24:56  time: 0.4178  data_time: 0.0099  memory: 5976  grad_norm: 667.2411  loss: 22.0504  decode.loss_cls: 0.1514  decode.loss_mask: 1.2003  decode.loss_dice: 0.8073  decode.d0.loss_cls: 0.6713  decode.d0.loss_mask: 1.1559  decode.d0.loss_dice: 0.7880  decode.d1.loss_cls: 0.1686  decode.d1.loss_mask: 1.1937  decode.d1.loss_dice: 0.7910  decode.d2.loss_cls: 0.1741  decode.d2.loss_mask: 1.1737  decode.d2.loss_dice: 0.8009  decode.d3.loss_cls: 0.1546  decode.d3.loss_mask: 1.2055  decode.d3.loss_dice: 0.8217  decode.d4.loss_cls: 0.1756  decode.d4.loss_mask: 1.1666  decode.d4.loss_dice: 0.8041  decode.d5.loss_cls: 0.2066  decode.d5.loss_mask: 1.1236  decode.d5.loss_dice: 0.8184  decode.d6.loss_cls: 0.1883  decode.d6.loss_mask: 1.1630  decode.d6.loss_dice: 0.8159  decode.d7.loss_cls: 0.1639  decode.d7.loss_mask: 1.2024  decode.d7.loss_dice: 0.8083  decode.d8.loss_cls: 0.1422  decode.d8.loss_mask: 1.2081  decode.d8.loss_dice: 0.8052
05/26 22:13:32 - mmengine - INFO - Iter(train) [ 95350/160000]  base_lr: 4.4239e-05 lr: 4.4239e-06  eta: 7:24:36  time: 0.4185  data_time: 0.0098  memory: 5965  grad_norm: 697.2826  loss: 19.5763  decode.loss_cls: 0.1107  decode.loss_mask: 1.0796  decode.loss_dice: 0.7259  decode.d0.loss_cls: 0.5412  decode.d0.loss_mask: 1.0318  decode.d0.loss_dice: 0.7208  decode.d1.loss_cls: 0.1175  decode.d1.loss_mask: 1.0834  decode.d1.loss_dice: 0.7505  decode.d2.loss_cls: 0.1068  decode.d2.loss_mask: 1.0795  decode.d2.loss_dice: 0.7393  decode.d3.loss_cls: 0.1213  decode.d3.loss_mask: 1.0575  decode.d3.loss_dice: 0.7189  decode.d4.loss_cls: 0.0980  decode.d4.loss_mask: 1.0799  decode.d4.loss_dice: 0.7456  decode.d5.loss_cls: 0.0986  decode.d5.loss_mask: 1.0942  decode.d5.loss_dice: 0.7482  decode.d6.loss_cls: 0.1235  decode.d6.loss_mask: 1.0753  decode.d6.loss_dice: 0.7378  decode.d7.loss_cls: 0.1347  decode.d7.loss_mask: 1.0599  decode.d7.loss_dice: 0.7121  decode.d8.loss_cls: 0.1122  decode.d8.loss_mask: 1.0555  decode.d8.loss_dice: 0.7160
05/26 22:13:53 - mmengine - INFO - Iter(train) [ 95400/160000]  base_lr: 4.4208e-05 lr: 4.4208e-06  eta: 7:24:15  time: 0.4164  data_time: 0.0099  memory: 5974  grad_norm: 840.5960  loss: 21.1183  decode.loss_cls: 0.1621  decode.loss_mask: 1.0601  decode.loss_dice: 0.7851  decode.d0.loss_cls: 0.7612  decode.d0.loss_mask: 1.0550  decode.d0.loss_dice: 0.7686  decode.d1.loss_cls: 0.2195  decode.d1.loss_mask: 1.1533  decode.d1.loss_dice: 0.8017  decode.d2.loss_cls: 0.1850  decode.d2.loss_mask: 1.1055  decode.d2.loss_dice: 0.7957  decode.d3.loss_cls: 0.2031  decode.d3.loss_mask: 1.0499  decode.d3.loss_dice: 0.7962  decode.d4.loss_cls: 0.2053  decode.d4.loss_mask: 1.0715  decode.d4.loss_dice: 0.7699  decode.d5.loss_cls: 0.1940  decode.d5.loss_mask: 1.0759  decode.d5.loss_dice: 0.8125  decode.d6.loss_cls: 0.1920  decode.d6.loss_mask: 1.0534  decode.d6.loss_dice: 0.7895  decode.d7.loss_cls: 0.1752  decode.d7.loss_mask: 1.0580  decode.d7.loss_dice: 0.7847  decode.d8.loss_cls: 0.2084  decode.d8.loss_mask: 1.0568  decode.d8.loss_dice: 0.7694
05/26 22:14:14 - mmengine - INFO - Iter(train) [ 95450/160000]  base_lr: 4.4177e-05 lr: 4.4177e-06  eta: 7:23:55  time: 0.4161  data_time: 0.0098  memory: 5980  grad_norm: 1387.5113  loss: 20.6474  decode.loss_cls: 0.1613  decode.loss_mask: 1.0627  decode.loss_dice: 0.7393  decode.d0.loss_cls: 0.5783  decode.d0.loss_mask: 1.1234  decode.d0.loss_dice: 0.7979  decode.d1.loss_cls: 0.1329  decode.d1.loss_mask: 1.1240  decode.d1.loss_dice: 0.7815  decode.d2.loss_cls: 0.1489  decode.d2.loss_mask: 1.1044  decode.d2.loss_dice: 0.7790  decode.d3.loss_cls: 0.1567  decode.d3.loss_mask: 1.1133  decode.d3.loss_dice: 0.7916  decode.d4.loss_cls: 0.1590  decode.d4.loss_mask: 1.0765  decode.d4.loss_dice: 0.7581  decode.d5.loss_cls: 0.1704  decode.d5.loss_mask: 1.1095  decode.d5.loss_dice: 0.7819  decode.d6.loss_cls: 0.1411  decode.d6.loss_mask: 1.1193  decode.d6.loss_dice: 0.7760  decode.d7.loss_cls: 0.1366  decode.d7.loss_mask: 1.0768  decode.d7.loss_dice: 0.7758  decode.d8.loss_cls: 0.1480  decode.d8.loss_mask: 1.0679  decode.d8.loss_dice: 0.7552
05/26 22:14:35 - mmengine - INFO - Iter(train) [ 95500/160000]  base_lr: 4.4147e-05 lr: 4.4147e-06  eta: 7:23:34  time: 0.4183  data_time: 0.0098  memory: 5975  grad_norm: 655.5236  loss: 20.5471  decode.loss_cls: 0.2230  decode.loss_mask: 1.0093  decode.loss_dice: 0.7396  decode.d0.loss_cls: 0.8129  decode.d0.loss_mask: 0.9535  decode.d0.loss_dice: 0.7253  decode.d1.loss_cls: 0.2060  decode.d1.loss_mask: 1.0421  decode.d1.loss_dice: 0.7682  decode.d2.loss_cls: 0.2274  decode.d2.loss_mask: 1.0188  decode.d2.loss_dice: 0.7555  decode.d3.loss_cls: 0.2133  decode.d3.loss_mask: 1.0372  decode.d3.loss_dice: 0.7692  decode.d4.loss_cls: 0.2070  decode.d4.loss_mask: 1.0248  decode.d4.loss_dice: 0.7651  decode.d5.loss_cls: 0.2273  decode.d5.loss_mask: 1.0338  decode.d5.loss_dice: 0.7729  decode.d6.loss_cls: 0.2251  decode.d6.loss_mask: 1.0180  decode.d6.loss_dice: 0.7571  decode.d7.loss_cls: 0.2303  decode.d7.loss_mask: 1.0284  decode.d7.loss_dice: 0.7546  decode.d8.loss_cls: 0.2444  decode.d8.loss_mask: 1.0133  decode.d8.loss_dice: 0.7438
05/26 22:14:56 - mmengine - INFO - Iter(train) [ 95550/160000]  base_lr: 4.4116e-05 lr: 4.4116e-06  eta: 7:23:14  time: 0.4169  data_time: 0.0099  memory: 5971  grad_norm: 227.2048  loss: 20.0263  decode.loss_cls: 0.1217  decode.loss_mask: 1.0653  decode.loss_dice: 0.7773  decode.d0.loss_cls: 0.5317  decode.d0.loss_mask: 1.0423  decode.d0.loss_dice: 0.7893  decode.d1.loss_cls: 0.1126  decode.d1.loss_mask: 1.0621  decode.d1.loss_dice: 0.7682  decode.d2.loss_cls: 0.1423  decode.d2.loss_mask: 1.0595  decode.d2.loss_dice: 0.7833  decode.d3.loss_cls: 0.1405  decode.d3.loss_mask: 1.0706  decode.d3.loss_dice: 0.7840  decode.d4.loss_cls: 0.0957  decode.d4.loss_mask: 1.0823  decode.d4.loss_dice: 0.7922  decode.d5.loss_cls: 0.0828  decode.d5.loss_mask: 1.0890  decode.d5.loss_dice: 0.7942  decode.d6.loss_cls: 0.0926  decode.d6.loss_mask: 1.0513  decode.d6.loss_dice: 0.7891  decode.d7.loss_cls: 0.1014  decode.d7.loss_mask: 1.0674  decode.d7.loss_dice: 0.7928  decode.d8.loss_cls: 0.0839  decode.d8.loss_mask: 1.0845  decode.d8.loss_dice: 0.7765
05/26 22:15:17 - mmengine - INFO - Iter(train) [ 95600/160000]  base_lr: 4.4085e-05 lr: 4.4085e-06  eta: 7:22:53  time: 0.4173  data_time: 0.0098  memory: 5970  grad_norm: 600.5515  loss: 22.0545  decode.loss_cls: 0.2420  decode.loss_mask: 1.1271  decode.loss_dice: 0.8020  decode.d0.loss_cls: 0.6359  decode.d0.loss_mask: 1.1086  decode.d0.loss_dice: 0.8404  decode.d1.loss_cls: 0.2532  decode.d1.loss_mask: 1.1364  decode.d1.loss_dice: 0.7979  decode.d2.loss_cls: 0.2260  decode.d2.loss_mask: 1.1243  decode.d2.loss_dice: 0.8142  decode.d3.loss_cls: 0.1836  decode.d3.loss_mask: 1.1352  decode.d3.loss_dice: 0.8287  decode.d4.loss_cls: 0.2404  decode.d4.loss_mask: 1.0911  decode.d4.loss_dice: 0.8236  decode.d5.loss_cls: 0.2244  decode.d5.loss_mask: 1.1321  decode.d5.loss_dice: 0.8392  decode.d6.loss_cls: 0.1523  decode.d6.loss_mask: 1.1448  decode.d6.loss_dice: 0.8535  decode.d7.loss_cls: 0.2299  decode.d7.loss_mask: 1.1136  decode.d7.loss_dice: 0.7942  decode.d8.loss_cls: 0.1939  decode.d8.loss_mask: 1.1510  decode.d8.loss_dice: 0.8147
05/26 22:15:38 - mmengine - INFO - Iter(train) [ 95650/160000]  base_lr: 4.4054e-05 lr: 4.4054e-06  eta: 7:22:33  time: 0.4188  data_time: 0.0098  memory: 5966  grad_norm: 484.1443  loss: 19.4015  decode.loss_cls: 0.2291  decode.loss_mask: 0.9489  decode.loss_dice: 0.6975  decode.d0.loss_cls: 0.6730  decode.d0.loss_mask: 0.9373  decode.d0.loss_dice: 0.7231  decode.d1.loss_cls: 0.2668  decode.d1.loss_mask: 0.9530  decode.d1.loss_dice: 0.7070  decode.d2.loss_cls: 0.2958  decode.d2.loss_mask: 0.9454  decode.d2.loss_dice: 0.6778  decode.d3.loss_cls: 0.2581  decode.d3.loss_mask: 0.9425  decode.d3.loss_dice: 0.6624  decode.d4.loss_cls: 0.2387  decode.d4.loss_mask: 0.9343  decode.d4.loss_dice: 0.7011  decode.d5.loss_cls: 0.2367  decode.d5.loss_mask: 0.9591  decode.d5.loss_dice: 0.7244  decode.d6.loss_cls: 0.2357  decode.d6.loss_mask: 0.9432  decode.d6.loss_dice: 0.6995  decode.d7.loss_cls: 0.2741  decode.d7.loss_mask: 0.9454  decode.d7.loss_dice: 0.6842  decode.d8.loss_cls: 0.2546  decode.d8.loss_mask: 0.9550  decode.d8.loss_dice: 0.6976
05/26 22:15:59 - mmengine - INFO - Iter(train) [ 95700/160000]  base_lr: 4.4023e-05 lr: 4.4023e-06  eta: 7:22:13  time: 0.4214  data_time: 0.0105  memory: 5985  grad_norm: 599.2189  loss: 19.6942  decode.loss_cls: 0.1863  decode.loss_mask: 1.0493  decode.loss_dice: 0.6649  decode.d0.loss_cls: 0.6510  decode.d0.loss_mask: 1.0040  decode.d0.loss_dice: 0.6434  decode.d1.loss_cls: 0.2021  decode.d1.loss_mask: 1.1017  decode.d1.loss_dice: 0.6771  decode.d2.loss_cls: 0.2127  decode.d2.loss_mask: 1.0409  decode.d2.loss_dice: 0.6575  decode.d3.loss_cls: 0.1859  decode.d3.loss_mask: 1.0929  decode.d3.loss_dice: 0.6799  decode.d4.loss_cls: 0.2046  decode.d4.loss_mask: 1.0502  decode.d4.loss_dice: 0.6486  decode.d5.loss_cls: 0.2320  decode.d5.loss_mask: 1.0293  decode.d5.loss_dice: 0.6657  decode.d6.loss_cls: 0.2215  decode.d6.loss_mask: 1.0345  decode.d6.loss_dice: 0.6638  decode.d7.loss_cls: 0.2065  decode.d7.loss_mask: 1.0817  decode.d7.loss_dice: 0.6809  decode.d8.loss_cls: 0.2217  decode.d8.loss_mask: 1.0372  decode.d8.loss_dice: 0.6666
05/26 22:16:19 - mmengine - INFO - Iter(train) [ 95750/160000]  base_lr: 4.3993e-05 lr: 4.3993e-06  eta: 7:21:52  time: 0.4132  data_time: 0.0097  memory: 5969  grad_norm: 481.1854  loss: 18.2797  decode.loss_cls: 0.0594  decode.loss_mask: 1.0755  decode.loss_dice: 0.6406  decode.d0.loss_cls: 0.5805  decode.d0.loss_mask: 1.0327  decode.d0.loss_dice: 0.6000  decode.d1.loss_cls: 0.0640  decode.d1.loss_mask: 1.1107  decode.d1.loss_dice: 0.6387  decode.d2.loss_cls: 0.0657  decode.d2.loss_mask: 1.0787  decode.d2.loss_dice: 0.6341  decode.d3.loss_cls: 0.0596  decode.d3.loss_mask: 1.0801  decode.d3.loss_dice: 0.6251  decode.d4.loss_cls: 0.0547  decode.d4.loss_mask: 1.0802  decode.d4.loss_dice: 0.6322  decode.d5.loss_cls: 0.0954  decode.d5.loss_mask: 1.0667  decode.d5.loss_dice: 0.6328  decode.d6.loss_cls: 0.0662  decode.d6.loss_mask: 1.0819  decode.d6.loss_dice: 0.6282  decode.d7.loss_cls: 0.0642  decode.d7.loss_mask: 1.0983  decode.d7.loss_dice: 0.6503  decode.d8.loss_cls: 0.0617  decode.d8.loss_mask: 1.0825  decode.d8.loss_dice: 0.6391
05/26 22:16:40 - mmengine - INFO - Iter(train) [ 95800/160000]  base_lr: 4.3962e-05 lr: 4.3962e-06  eta: 7:21:31  time: 0.4127  data_time: 0.0096  memory: 5970  grad_norm: 457.4176  loss: 22.5797  decode.loss_cls: 0.3713  decode.loss_mask: 1.0137  decode.loss_dice: 0.7744  decode.d0.loss_cls: 0.9495  decode.d0.loss_mask: 0.9337  decode.d0.loss_dice: 0.7455  decode.d1.loss_cls: 0.3677  decode.d1.loss_mask: 1.0359  decode.d1.loss_dice: 0.7856  decode.d2.loss_cls: 0.4010  decode.d2.loss_mask: 1.0194  decode.d2.loss_dice: 0.7685  decode.d3.loss_cls: 0.3986  decode.d3.loss_mask: 1.0130  decode.d3.loss_dice: 0.7791  decode.d4.loss_cls: 0.3629  decode.d4.loss_mask: 1.0954  decode.d4.loss_dice: 0.8207  decode.d5.loss_cls: 0.3594  decode.d5.loss_mask: 1.0933  decode.d5.loss_dice: 0.8125  decode.d6.loss_cls: 0.3629  decode.d6.loss_mask: 1.0509  decode.d6.loss_dice: 0.8117  decode.d7.loss_cls: 0.4040  decode.d7.loss_mask: 1.0196  decode.d7.loss_dice: 0.7845  decode.d8.loss_cls: 0.4108  decode.d8.loss_mask: 1.0409  decode.d8.loss_dice: 0.7934
05/26 22:17:01 - mmengine - INFO - Iter(train) [ 95850/160000]  base_lr: 4.3931e-05 lr: 4.3931e-06  eta: 7:21:11  time: 0.4129  data_time: 0.0097  memory: 5971  grad_norm: 576.9637  loss: 20.8672  decode.loss_cls: 0.1963  decode.loss_mask: 1.0992  decode.loss_dice: 0.7189  decode.d0.loss_cls: 0.5874  decode.d0.loss_mask: 1.1178  decode.d0.loss_dice: 0.6920  decode.d1.loss_cls: 0.1589  decode.d1.loss_mask: 1.1262  decode.d1.loss_dice: 0.7337  decode.d2.loss_cls: 0.1996  decode.d2.loss_mask: 1.1042  decode.d2.loss_dice: 0.7501  decode.d3.loss_cls: 0.1735  decode.d3.loss_mask: 1.1104  decode.d3.loss_dice: 0.7289  decode.d4.loss_cls: 0.1591  decode.d4.loss_mask: 1.2288  decode.d4.loss_dice: 0.7362  decode.d5.loss_cls: 0.1960  decode.d5.loss_mask: 1.1068  decode.d5.loss_dice: 0.7359  decode.d6.loss_cls: 0.1571  decode.d6.loss_mask: 1.2031  decode.d6.loss_dice: 0.7517  decode.d7.loss_cls: 0.1813  decode.d7.loss_mask: 1.1432  decode.d7.loss_dice: 0.7316  decode.d8.loss_cls: 0.2010  decode.d8.loss_mask: 1.1216  decode.d8.loss_dice: 0.7167
05/26 22:17:22 - mmengine - INFO - Iter(train) [ 95900/160000]  base_lr: 4.3900e-05 lr: 4.3900e-06  eta: 7:20:50  time: 0.4123  data_time: 0.0098  memory: 5971  grad_norm: 514.5824  loss: 19.6864  decode.loss_cls: 0.1506  decode.loss_mask: 1.1138  decode.loss_dice: 0.6543  decode.d0.loss_cls: 0.6405  decode.d0.loss_mask: 1.0293  decode.d0.loss_dice: 0.6161  decode.d1.loss_cls: 0.1406  decode.d1.loss_mask: 1.1440  decode.d1.loss_dice: 0.6545  decode.d2.loss_cls: 0.1544  decode.d2.loss_mask: 1.1054  decode.d2.loss_dice: 0.6428  decode.d3.loss_cls: 0.1579  decode.d3.loss_mask: 1.0915  decode.d3.loss_dice: 0.6436  decode.d4.loss_cls: 0.1341  decode.d4.loss_mask: 1.1340  decode.d4.loss_dice: 0.6597  decode.d5.loss_cls: 0.1692  decode.d5.loss_mask: 1.1412  decode.d5.loss_dice: 0.6443  decode.d6.loss_cls: 0.1693  decode.d6.loss_mask: 1.1574  decode.d6.loss_dice: 0.6715  decode.d7.loss_cls: 0.1863  decode.d7.loss_mask: 1.1116  decode.d7.loss_dice: 0.6516  decode.d8.loss_cls: 0.1785  decode.d8.loss_mask: 1.1084  decode.d8.loss_dice: 0.6301
05/26 22:17:42 - mmengine - INFO - Iter(train) [ 95950/160000]  base_lr: 4.3869e-05 lr: 4.3869e-06  eta: 7:20:30  time: 0.4131  data_time: 0.0097  memory: 5966  grad_norm: 546.1429  loss: 20.6192  decode.loss_cls: 0.2232  decode.loss_mask: 1.0951  decode.loss_dice: 0.7631  decode.d0.loss_cls: 0.5911  decode.d0.loss_mask: 1.1075  decode.d0.loss_dice: 0.7309  decode.d1.loss_cls: 0.1459  decode.d1.loss_mask: 1.1004  decode.d1.loss_dice: 0.7329  decode.d2.loss_cls: 0.1827  decode.d2.loss_mask: 1.1012  decode.d2.loss_dice: 0.7496  decode.d3.loss_cls: 0.2393  decode.d3.loss_mask: 1.1205  decode.d3.loss_dice: 0.7457  decode.d4.loss_cls: 0.1984  decode.d4.loss_mask: 1.0941  decode.d4.loss_dice: 0.7378  decode.d5.loss_cls: 0.2054  decode.d5.loss_mask: 1.1045  decode.d5.loss_dice: 0.7429  decode.d6.loss_cls: 0.1541  decode.d6.loss_mask: 1.0954  decode.d6.loss_dice: 0.7143  decode.d7.loss_cls: 0.1434  decode.d7.loss_mask: 1.0898  decode.d7.loss_dice: 0.7104  decode.d8.loss_cls: 0.1674  decode.d8.loss_mask: 1.1220  decode.d8.loss_dice: 0.7101
05/26 22:18:03 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 22:18:03 - mmengine - INFO - Iter(train) [ 96000/160000]  base_lr: 4.3839e-05 lr: 4.3839e-06  eta: 7:20:09  time: 0.4133  data_time: 0.0096  memory: 5973  grad_norm: 460.9805  loss: 18.5063  decode.loss_cls: 0.1637  decode.loss_mask: 0.9292  decode.loss_dice: 0.6933  decode.d0.loss_cls: 0.6954  decode.d0.loss_mask: 0.8915  decode.d0.loss_dice: 0.6988  decode.d1.loss_cls: 0.1550  decode.d1.loss_mask: 0.9297  decode.d1.loss_dice: 0.6975  decode.d2.loss_cls: 0.1941  decode.d2.loss_mask: 0.9335  decode.d2.loss_dice: 0.7105  decode.d3.loss_cls: 0.1203  decode.d3.loss_mask: 0.9337  decode.d3.loss_dice: 0.7205  decode.d4.loss_cls: 0.1588  decode.d4.loss_mask: 0.9322  decode.d4.loss_dice: 0.7019  decode.d5.loss_cls: 0.1435  decode.d5.loss_mask: 0.9392  decode.d5.loss_dice: 0.7231  decode.d6.loss_cls: 0.1539  decode.d6.loss_mask: 0.9389  decode.d6.loss_dice: 0.6863  decode.d7.loss_cls: 0.2355  decode.d7.loss_mask: 0.9339  decode.d7.loss_dice: 0.7164  decode.d8.loss_cls: 0.1369  decode.d8.loss_mask: 0.9506  decode.d8.loss_dice: 0.6886
05/26 22:18:24 - mmengine - INFO - Iter(train) [ 96050/160000]  base_lr: 4.3808e-05 lr: 4.3808e-06  eta: 7:19:48  time: 0.4124  data_time: 0.0097  memory: 5988  grad_norm: 543.8020  loss: 21.5250  decode.loss_cls: 0.2103  decode.loss_mask: 1.0706  decode.loss_dice: 0.7498  decode.d0.loss_cls: 0.8103  decode.d0.loss_mask: 1.1139  decode.d0.loss_dice: 0.7667  decode.d1.loss_cls: 0.2062  decode.d1.loss_mask: 1.1517  decode.d1.loss_dice: 0.7710  decode.d2.loss_cls: 0.1682  decode.d2.loss_mask: 1.1145  decode.d2.loss_dice: 0.7738  decode.d3.loss_cls: 0.2256  decode.d3.loss_mask: 1.0916  decode.d3.loss_dice: 0.7816  decode.d4.loss_cls: 0.2075  decode.d4.loss_mask: 1.1511  decode.d4.loss_dice: 0.7752  decode.d5.loss_cls: 0.2373  decode.d5.loss_mask: 1.0859  decode.d5.loss_dice: 0.7821  decode.d6.loss_cls: 0.2084  decode.d6.loss_mask: 1.1271  decode.d6.loss_dice: 0.7810  decode.d7.loss_cls: 0.1903  decode.d7.loss_mask: 1.1261  decode.d7.loss_dice: 0.7788  decode.d8.loss_cls: 0.1862  decode.d8.loss_mask: 1.1294  decode.d8.loss_dice: 0.7524
05/26 22:18:44 - mmengine - INFO - Iter(train) [ 96100/160000]  base_lr: 4.3777e-05 lr: 4.3777e-06  eta: 7:19:28  time: 0.4130  data_time: 0.0097  memory: 5969  grad_norm: 478.1090  loss: 19.1290  decode.loss_cls: 0.1916  decode.loss_mask: 0.9820  decode.loss_dice: 0.7002  decode.d0.loss_cls: 0.7052  decode.d0.loss_mask: 0.9601  decode.d0.loss_dice: 0.6855  decode.d1.loss_cls: 0.1671  decode.d1.loss_mask: 0.9826  decode.d1.loss_dice: 0.7269  decode.d2.loss_cls: 0.1682  decode.d2.loss_mask: 0.9779  decode.d2.loss_dice: 0.7045  decode.d3.loss_cls: 0.1691  decode.d3.loss_mask: 0.9823  decode.d3.loss_dice: 0.7029  decode.d4.loss_cls: 0.1646  decode.d4.loss_mask: 0.9855  decode.d4.loss_dice: 0.7164  decode.d5.loss_cls: 0.1775  decode.d5.loss_mask: 0.9875  decode.d5.loss_dice: 0.7066  decode.d6.loss_cls: 0.1767  decode.d6.loss_mask: 0.9914  decode.d6.loss_dice: 0.7088  decode.d7.loss_cls: 0.1535  decode.d7.loss_mask: 0.9873  decode.d7.loss_dice: 0.7051  decode.d8.loss_cls: 0.1428  decode.d8.loss_mask: 1.0020  decode.d8.loss_dice: 0.7171
05/26 22:19:05 - mmengine - INFO - Iter(train) [ 96150/160000]  base_lr: 4.3746e-05 lr: 4.3746e-06  eta: 7:19:07  time: 0.4126  data_time: 0.0096  memory: 5973  grad_norm: 723.1698  loss: 17.7526  decode.loss_cls: 0.1338  decode.loss_mask: 0.9043  decode.loss_dice: 0.6773  decode.d0.loss_cls: 0.5812  decode.d0.loss_mask: 0.8981  decode.d0.loss_dice: 0.6954  decode.d1.loss_cls: 0.1444  decode.d1.loss_mask: 0.9162  decode.d1.loss_dice: 0.7099  decode.d2.loss_cls: 0.1316  decode.d2.loss_mask: 0.8942  decode.d2.loss_dice: 0.6750  decode.d3.loss_cls: 0.1263  decode.d3.loss_mask: 0.9072  decode.d3.loss_dice: 0.6921  decode.d4.loss_cls: 0.1415  decode.d4.loss_mask: 0.9003  decode.d4.loss_dice: 0.6805  decode.d5.loss_cls: 0.1315  decode.d5.loss_mask: 0.9019  decode.d5.loss_dice: 0.7003  decode.d6.loss_cls: 0.1353  decode.d6.loss_mask: 0.9000  decode.d6.loss_dice: 0.6813  decode.d7.loss_cls: 0.1030  decode.d7.loss_mask: 0.9301  decode.d7.loss_dice: 0.7197  decode.d8.loss_cls: 0.1509  decode.d8.loss_mask: 0.8975  decode.d8.loss_dice: 0.6919
05/26 22:19:26 - mmengine - INFO - Iter(train) [ 96200/160000]  base_lr: 4.3715e-05 lr: 4.3715e-06  eta: 7:18:47  time: 0.4123  data_time: 0.0097  memory: 5972  grad_norm: 560.9682  loss: 17.7467  decode.loss_cls: 0.1842  decode.loss_mask: 0.8800  decode.loss_dice: 0.6802  decode.d0.loss_cls: 0.5718  decode.d0.loss_mask: 0.8805  decode.d0.loss_dice: 0.6805  decode.d1.loss_cls: 0.1852  decode.d1.loss_mask: 0.9174  decode.d1.loss_dice: 0.6801  decode.d2.loss_cls: 0.2117  decode.d2.loss_mask: 0.8537  decode.d2.loss_dice: 0.6672  decode.d3.loss_cls: 0.1749  decode.d3.loss_mask: 0.8552  decode.d3.loss_dice: 0.6599  decode.d4.loss_cls: 0.2141  decode.d4.loss_mask: 0.8522  decode.d4.loss_dice: 0.6682  decode.d5.loss_cls: 0.2382  decode.d5.loss_mask: 0.8428  decode.d5.loss_dice: 0.6782  decode.d6.loss_cls: 0.2159  decode.d6.loss_mask: 0.8463  decode.d6.loss_dice: 0.6781  decode.d7.loss_cls: 0.2231  decode.d7.loss_mask: 0.8435  decode.d7.loss_dice: 0.6681  decode.d8.loss_cls: 0.1589  decode.d8.loss_mask: 0.8702  decode.d8.loss_dice: 0.6664
05/26 22:19:46 - mmengine - INFO - Iter(train) [ 96250/160000]  base_lr: 4.3684e-05 lr: 4.3684e-06  eta: 7:18:26  time: 0.4176  data_time: 0.0097  memory: 5971  grad_norm: 667.7478  loss: 20.3421  decode.loss_cls: 0.1383  decode.loss_mask: 1.0323  decode.loss_dice: 0.7788  decode.d0.loss_cls: 0.7434  decode.d0.loss_mask: 1.0332  decode.d0.loss_dice: 0.7607  decode.d1.loss_cls: 0.2168  decode.d1.loss_mask: 1.0230  decode.d1.loss_dice: 0.7680  decode.d2.loss_cls: 0.1905  decode.d2.loss_mask: 1.0234  decode.d2.loss_dice: 0.7631  decode.d3.loss_cls: 0.1710  decode.d3.loss_mask: 1.0273  decode.d3.loss_dice: 0.7535  decode.d4.loss_cls: 0.1404  decode.d4.loss_mask: 1.0365  decode.d4.loss_dice: 0.7752  decode.d5.loss_cls: 0.1769  decode.d5.loss_mask: 1.0131  decode.d5.loss_dice: 0.7672  decode.d6.loss_cls: 0.1819  decode.d6.loss_mask: 1.0247  decode.d6.loss_dice: 0.7838  decode.d7.loss_cls: 0.1576  decode.d7.loss_mask: 1.0565  decode.d7.loss_dice: 0.7909  decode.d8.loss_cls: 0.1481  decode.d8.loss_mask: 1.0651  decode.d8.loss_dice: 0.8009
05/26 22:20:07 - mmengine - INFO - Iter(train) [ 96300/160000]  base_lr: 4.3654e-05 lr: 4.3654e-06  eta: 7:18:06  time: 0.4303  data_time: 0.0103  memory: 5971  grad_norm: 396.0462  loss: 17.8718  decode.loss_cls: 0.1650  decode.loss_mask: 0.9093  decode.loss_dice: 0.6171  decode.d0.loss_cls: 0.7693  decode.d0.loss_mask: 0.8762  decode.d0.loss_dice: 0.6830  decode.d1.loss_cls: 0.2063  decode.d1.loss_mask: 0.9227  decode.d1.loss_dice: 0.6261  decode.d2.loss_cls: 0.1621  decode.d2.loss_mask: 0.9319  decode.d2.loss_dice: 0.6276  decode.d3.loss_cls: 0.1613  decode.d3.loss_mask: 0.9269  decode.d3.loss_dice: 0.6444  decode.d4.loss_cls: 0.1803  decode.d4.loss_mask: 0.9243  decode.d4.loss_dice: 0.6490  decode.d5.loss_cls: 0.1787  decode.d5.loss_mask: 0.9128  decode.d5.loss_dice: 0.6170  decode.d6.loss_cls: 0.1936  decode.d6.loss_mask: 0.9132  decode.d6.loss_dice: 0.6212  decode.d7.loss_cls: 0.1945  decode.d7.loss_mask: 0.9252  decode.d7.loss_dice: 0.6321  decode.d8.loss_cls: 0.1691  decode.d8.loss_mask: 0.9062  decode.d8.loss_dice: 0.6254
05/26 22:20:28 - mmengine - INFO - Iter(train) [ 96350/160000]  base_lr: 4.3623e-05 lr: 4.3623e-06  eta: 7:17:45  time: 0.4178  data_time: 0.0099  memory: 5966  grad_norm: 588.3387  loss: 21.8779  decode.loss_cls: 0.2617  decode.loss_mask: 1.0802  decode.loss_dice: 0.7259  decode.d0.loss_cls: 0.7887  decode.d0.loss_mask: 1.0843  decode.d0.loss_dice: 0.7047  decode.d1.loss_cls: 0.3239  decode.d1.loss_mask: 1.1314  decode.d1.loss_dice: 0.7508  decode.d2.loss_cls: 0.3201  decode.d2.loss_mask: 1.1173  decode.d2.loss_dice: 0.7203  decode.d3.loss_cls: 0.2635  decode.d3.loss_mask: 1.1059  decode.d3.loss_dice: 0.7274  decode.d4.loss_cls: 0.3331  decode.d4.loss_mask: 1.0918  decode.d4.loss_dice: 0.7431  decode.d5.loss_cls: 0.2975  decode.d5.loss_mask: 1.1098  decode.d5.loss_dice: 0.7664  decode.d6.loss_cls: 0.2522  decode.d6.loss_mask: 1.1381  decode.d6.loss_dice: 0.7597  decode.d7.loss_cls: 0.2838  decode.d7.loss_mask: 1.0824  decode.d7.loss_dice: 0.7440  decode.d8.loss_cls: 0.2511  decode.d8.loss_mask: 1.1572  decode.d8.loss_dice: 0.7617
05/26 22:20:49 - mmengine - INFO - Iter(train) [ 96400/160000]  base_lr: 4.3592e-05 lr: 4.3592e-06  eta: 7:17:25  time: 0.4172  data_time: 0.0099  memory: 5969  grad_norm: 627.9039  loss: 21.1670  decode.loss_cls: 0.2449  decode.loss_mask: 1.1348  decode.loss_dice: 0.7451  decode.d0.loss_cls: 0.7292  decode.d0.loss_mask: 1.0076  decode.d0.loss_dice: 0.7301  decode.d1.loss_cls: 0.2501  decode.d1.loss_mask: 1.0370  decode.d1.loss_dice: 0.7295  decode.d2.loss_cls: 0.2295  decode.d2.loss_mask: 1.0594  decode.d2.loss_dice: 0.7292  decode.d3.loss_cls: 0.2554  decode.d3.loss_mask: 1.0518  decode.d3.loss_dice: 0.7565  decode.d4.loss_cls: 0.2263  decode.d4.loss_mask: 1.1242  decode.d4.loss_dice: 0.7489  decode.d5.loss_cls: 0.2661  decode.d5.loss_mask: 1.0691  decode.d5.loss_dice: 0.7226  decode.d6.loss_cls: 0.2540  decode.d6.loss_mask: 1.1085  decode.d6.loss_dice: 0.7435  decode.d7.loss_cls: 0.2562  decode.d7.loss_mask: 1.0848  decode.d7.loss_dice: 0.7488  decode.d8.loss_cls: 0.2326  decode.d8.loss_mask: 1.1382  decode.d8.loss_dice: 0.7530
05/26 22:21:10 - mmengine - INFO - Iter(train) [ 96450/160000]  base_lr: 4.3561e-05 lr: 4.3561e-06  eta: 7:17:04  time: 0.4172  data_time: 0.0098  memory: 5990  grad_norm: 782.7676  loss: 21.4044  decode.loss_cls: 0.1527  decode.loss_mask: 1.1620  decode.loss_dice: 0.8021  decode.d0.loss_cls: 0.6828  decode.d0.loss_mask: 1.0925  decode.d0.loss_dice: 0.7495  decode.d1.loss_cls: 0.1593  decode.d1.loss_mask: 1.1460  decode.d1.loss_dice: 0.7910  decode.d2.loss_cls: 0.1864  decode.d2.loss_mask: 1.1070  decode.d2.loss_dice: 0.7781  decode.d3.loss_cls: 0.1744  decode.d3.loss_mask: 1.1761  decode.d3.loss_dice: 0.7826  decode.d4.loss_cls: 0.1592  decode.d4.loss_mask: 1.1373  decode.d4.loss_dice: 0.7625  decode.d5.loss_cls: 0.1885  decode.d5.loss_mask: 1.1485  decode.d5.loss_dice: 0.7682  decode.d6.loss_cls: 0.1591  decode.d6.loss_mask: 1.1616  decode.d6.loss_dice: 0.7632  decode.d7.loss_cls: 0.1719  decode.d7.loss_mask: 1.1440  decode.d7.loss_dice: 0.7849  decode.d8.loss_cls: 0.1620  decode.d8.loss_mask: 1.1594  decode.d8.loss_dice: 0.7918
05/26 22:21:31 - mmengine - INFO - Iter(train) [ 96500/160000]  base_lr: 4.3530e-05 lr: 4.3530e-06  eta: 7:16:44  time: 0.4184  data_time: 0.0098  memory: 5980  grad_norm: 578.4487  loss: 16.6756  decode.loss_cls: 0.1053  decode.loss_mask: 0.9247  decode.loss_dice: 0.5918  decode.d0.loss_cls: 0.6400  decode.d0.loss_mask: 0.9024  decode.d0.loss_dice: 0.5630  decode.d1.loss_cls: 0.0791  decode.d1.loss_mask: 0.9274  decode.d1.loss_dice: 0.5931  decode.d2.loss_cls: 0.1279  decode.d2.loss_mask: 0.9450  decode.d2.loss_dice: 0.5802  decode.d3.loss_cls: 0.1140  decode.d3.loss_mask: 0.9317  decode.d3.loss_dice: 0.5768  decode.d4.loss_cls: 0.0974  decode.d4.loss_mask: 0.9388  decode.d4.loss_dice: 0.5852  decode.d5.loss_cls: 0.1265  decode.d5.loss_mask: 0.9312  decode.d5.loss_dice: 0.5717  decode.d6.loss_cls: 0.0614  decode.d6.loss_mask: 0.9498  decode.d6.loss_dice: 0.6000  decode.d7.loss_cls: 0.0921  decode.d7.loss_mask: 0.9292  decode.d7.loss_dice: 0.5928  decode.d8.loss_cls: 0.0706  decode.d8.loss_mask: 0.9325  decode.d8.loss_dice: 0.5940
05/26 22:21:52 - mmengine - INFO - Iter(train) [ 96550/160000]  base_lr: 4.3499e-05 lr: 4.3499e-06  eta: 7:16:23  time: 0.4171  data_time: 0.0098  memory: 5970  grad_norm: 725.5067  loss: 22.2576  decode.loss_cls: 0.2266  decode.loss_mask: 1.1761  decode.loss_dice: 0.7798  decode.d0.loss_cls: 0.7879  decode.d0.loss_mask: 1.0897  decode.d0.loss_dice: 0.7278  decode.d1.loss_cls: 0.1565  decode.d1.loss_mask: 1.3137  decode.d1.loss_dice: 0.8230  decode.d2.loss_cls: 0.2082  decode.d2.loss_mask: 1.1757  decode.d2.loss_dice: 0.7577  decode.d3.loss_cls: 0.1843  decode.d3.loss_mask: 1.2003  decode.d3.loss_dice: 0.7775  decode.d4.loss_cls: 0.1894  decode.d4.loss_mask: 1.1277  decode.d4.loss_dice: 0.7574  decode.d5.loss_cls: 0.1575  decode.d5.loss_mask: 1.2235  decode.d5.loss_dice: 0.8129  decode.d6.loss_cls: 0.1665  decode.d6.loss_mask: 1.2220  decode.d6.loss_dice: 0.8074  decode.d7.loss_cls: 0.2227  decode.d7.loss_mask: 1.2140  decode.d7.loss_dice: 0.8011  decode.d8.loss_cls: 0.1769  decode.d8.loss_mask: 1.2153  decode.d8.loss_dice: 0.7786
05/26 22:22:13 - mmengine - INFO - Iter(train) [ 96600/160000]  base_lr: 4.3469e-05 lr: 4.3469e-06  eta: 7:16:03  time: 0.4165  data_time: 0.0098  memory: 5967  grad_norm: 541.4287  loss: 20.3981  decode.loss_cls: 0.2227  decode.loss_mask: 0.9417  decode.loss_dice: 0.8014  decode.d0.loss_cls: 0.6978  decode.d0.loss_mask: 0.9042  decode.d0.loss_dice: 0.8011  decode.d1.loss_cls: 0.2243  decode.d1.loss_mask: 0.9757  decode.d1.loss_dice: 0.8014  decode.d2.loss_cls: 0.2415  decode.d2.loss_mask: 1.0104  decode.d2.loss_dice: 0.8058  decode.d3.loss_cls: 0.2494  decode.d3.loss_mask: 0.9496  decode.d3.loss_dice: 0.7739  decode.d4.loss_cls: 0.2697  decode.d4.loss_mask: 0.9696  decode.d4.loss_dice: 0.8034  decode.d5.loss_cls: 0.2651  decode.d5.loss_mask: 0.9643  decode.d5.loss_dice: 0.7942  decode.d6.loss_cls: 0.2459  decode.d6.loss_mask: 0.9523  decode.d6.loss_dice: 0.7814  decode.d7.loss_cls: 0.2390  decode.d7.loss_mask: 0.9559  decode.d7.loss_dice: 0.7604  decode.d8.loss_cls: 0.2347  decode.d8.loss_mask: 0.9715  decode.d8.loss_dice: 0.7898
05/26 22:22:34 - mmengine - INFO - Iter(train) [ 96650/160000]  base_lr: 4.3438e-05 lr: 4.3438e-06  eta: 7:15:42  time: 0.4169  data_time: 0.0099  memory: 5969  grad_norm: 484.0569  loss: 15.7132  decode.loss_cls: 0.0869  decode.loss_mask: 0.8651  decode.loss_dice: 0.5201  decode.d0.loss_cls: 0.6617  decode.d0.loss_mask: 0.8435  decode.d0.loss_dice: 0.5069  decode.d1.loss_cls: 0.0995  decode.d1.loss_mask: 0.8992  decode.d1.loss_dice: 0.5404  decode.d2.loss_cls: 0.1054  decode.d2.loss_mask: 0.8762  decode.d2.loss_dice: 0.5172  decode.d3.loss_cls: 0.1575  decode.d3.loss_mask: 0.8513  decode.d3.loss_dice: 0.5089  decode.d4.loss_cls: 0.1140  decode.d4.loss_mask: 0.9019  decode.d4.loss_dice: 0.5419  decode.d5.loss_cls: 0.1145  decode.d5.loss_mask: 0.8984  decode.d5.loss_dice: 0.5405  decode.d6.loss_cls: 0.1449  decode.d6.loss_mask: 0.8849  decode.d6.loss_dice: 0.5357  decode.d7.loss_cls: 0.0891  decode.d7.loss_mask: 0.8931  decode.d7.loss_dice: 0.5359  decode.d8.loss_cls: 0.1218  decode.d8.loss_mask: 0.8522  decode.d8.loss_dice: 0.5045
05/26 22:22:55 - mmengine - INFO - Iter(train) [ 96700/160000]  base_lr: 4.3407e-05 lr: 4.3407e-06  eta: 7:15:22  time: 0.4159  data_time: 0.0099  memory: 5974  grad_norm: 331.4409  loss: 15.1893  decode.loss_cls: 0.0715  decode.loss_mask: 0.8167  decode.loss_dice: 0.5732  decode.d0.loss_cls: 0.5893  decode.d0.loss_mask: 0.8028  decode.d0.loss_dice: 0.5433  decode.d1.loss_cls: 0.0999  decode.d1.loss_mask: 0.8206  decode.d1.loss_dice: 0.5793  decode.d2.loss_cls: 0.0763  decode.d2.loss_mask: 0.8028  decode.d2.loss_dice: 0.5556  decode.d3.loss_cls: 0.0522  decode.d3.loss_mask: 0.7982  decode.d3.loss_dice: 0.5484  decode.d4.loss_cls: 0.0614  decode.d4.loss_mask: 0.8226  decode.d4.loss_dice: 0.5768  decode.d5.loss_cls: 0.0834  decode.d5.loss_mask: 0.8225  decode.d5.loss_dice: 0.5771  decode.d6.loss_cls: 0.1287  decode.d6.loss_mask: 0.8226  decode.d6.loss_dice: 0.5802  decode.d7.loss_cls: 0.1187  decode.d7.loss_mask: 0.8149  decode.d7.loss_dice: 0.5714  decode.d8.loss_cls: 0.0930  decode.d8.loss_mask: 0.8152  decode.d8.loss_dice: 0.5705
05/26 22:23:15 - mmengine - INFO - Iter(train) [ 96750/160000]  base_lr: 4.3376e-05 lr: 4.3376e-06  eta: 7:15:01  time: 0.4166  data_time: 0.0099  memory: 5985  grad_norm: 626.8359  loss: 23.6165  decode.loss_cls: 0.2875  decode.loss_mask: 1.1284  decode.loss_dice: 0.9470  decode.d0.loss_cls: 0.7138  decode.d0.loss_mask: 1.0810  decode.d0.loss_dice: 0.9005  decode.d1.loss_cls: 0.2735  decode.d1.loss_mask: 1.1315  decode.d1.loss_dice: 0.9341  decode.d2.loss_cls: 0.2428  decode.d2.loss_mask: 1.1441  decode.d2.loss_dice: 0.9248  decode.d3.loss_cls: 0.2362  decode.d3.loss_mask: 1.1316  decode.d3.loss_dice: 0.9193  decode.d4.loss_cls: 0.2130  decode.d4.loss_mask: 1.1554  decode.d4.loss_dice: 0.9381  decode.d5.loss_cls: 0.1817  decode.d5.loss_mask: 1.1707  decode.d5.loss_dice: 0.9564  decode.d6.loss_cls: 0.2642  decode.d6.loss_mask: 1.1214  decode.d6.loss_dice: 0.9261  decode.d7.loss_cls: 0.2765  decode.d7.loss_mask: 1.1275  decode.d7.loss_dice: 0.9160  decode.d8.loss_cls: 0.2890  decode.d8.loss_mask: 1.1472  decode.d8.loss_dice: 0.9368
05/26 22:23:36 - mmengine - INFO - Iter(train) [ 96800/160000]  base_lr: 4.3345e-05 lr: 4.3345e-06  eta: 7:14:41  time: 0.4156  data_time: 0.0099  memory: 5968  grad_norm: 344.1750  loss: 17.1747  decode.loss_cls: 0.0972  decode.loss_mask: 0.9434  decode.loss_dice: 0.6037  decode.d0.loss_cls: 0.5905  decode.d0.loss_mask: 0.9495  decode.d0.loss_dice: 0.6361  decode.d1.loss_cls: 0.1084  decode.d1.loss_mask: 0.9581  decode.d1.loss_dice: 0.6175  decode.d2.loss_cls: 0.0976  decode.d2.loss_mask: 0.9571  decode.d2.loss_dice: 0.6161  decode.d3.loss_cls: 0.1012  decode.d3.loss_mask: 0.9542  decode.d3.loss_dice: 0.6187  decode.d4.loss_cls: 0.0914  decode.d4.loss_mask: 0.9538  decode.d4.loss_dice: 0.6146  decode.d5.loss_cls: 0.0943  decode.d5.loss_mask: 0.9567  decode.d5.loss_dice: 0.6314  decode.d6.loss_cls: 0.0975  decode.d6.loss_mask: 0.9530  decode.d6.loss_dice: 0.6209  decode.d7.loss_cls: 0.1010  decode.d7.loss_mask: 0.9514  decode.d7.loss_dice: 0.6178  decode.d8.loss_cls: 0.0903  decode.d8.loss_mask: 0.9370  decode.d8.loss_dice: 0.6142
05/26 22:23:57 - mmengine - INFO - Iter(train) [ 96850/160000]  base_lr: 4.3314e-05 lr: 4.3314e-06  eta: 7:14:20  time: 0.4171  data_time: 0.0099  memory: 5972  grad_norm: 541.5549  loss: 20.6793  decode.loss_cls: 0.1112  decode.loss_mask: 1.1153  decode.loss_dice: 0.7808  decode.d0.loss_cls: 0.6143  decode.d0.loss_mask: 1.0589  decode.d0.loss_dice: 0.7946  decode.d1.loss_cls: 0.1095  decode.d1.loss_mask: 1.1133  decode.d1.loss_dice: 0.7907  decode.d2.loss_cls: 0.1107  decode.d2.loss_mask: 1.1201  decode.d2.loss_dice: 0.7852  decode.d3.loss_cls: 0.1172  decode.d3.loss_mask: 1.1130  decode.d3.loss_dice: 0.7908  decode.d4.loss_cls: 0.1209  decode.d4.loss_mask: 1.1129  decode.d4.loss_dice: 0.8004  decode.d5.loss_cls: 0.1327  decode.d5.loss_mask: 1.0777  decode.d5.loss_dice: 0.7898  decode.d6.loss_cls: 0.1200  decode.d6.loss_mask: 1.0958  decode.d6.loss_dice: 0.8044  decode.d7.loss_cls: 0.1575  decode.d7.loss_mask: 1.1200  decode.d7.loss_dice: 0.7897  decode.d8.loss_cls: 0.1170  decode.d8.loss_mask: 1.1117  decode.d8.loss_dice: 0.8032
05/26 22:24:18 - mmengine - INFO - Iter(train) [ 96900/160000]  base_lr: 4.3283e-05 lr: 4.3283e-06  eta: 7:14:00  time: 0.4176  data_time: 0.0100  memory: 5968  grad_norm: 519.8954  loss: 20.0842  decode.loss_cls: 0.2187  decode.loss_mask: 1.0136  decode.loss_dice: 0.6947  decode.d0.loss_cls: 0.7266  decode.d0.loss_mask: 1.0314  decode.d0.loss_dice: 0.6694  decode.d1.loss_cls: 0.2676  decode.d1.loss_mask: 1.0300  decode.d1.loss_dice: 0.6691  decode.d2.loss_cls: 0.2625  decode.d2.loss_mask: 1.0560  decode.d2.loss_dice: 0.6917  decode.d3.loss_cls: 0.2685  decode.d3.loss_mask: 1.0212  decode.d3.loss_dice: 0.6462  decode.d4.loss_cls: 0.2718  decode.d4.loss_mask: 1.0947  decode.d4.loss_dice: 0.6925  decode.d5.loss_cls: 0.2616  decode.d5.loss_mask: 1.0157  decode.d5.loss_dice: 0.6583  decode.d6.loss_cls: 0.2835  decode.d6.loss_mask: 1.0167  decode.d6.loss_dice: 0.6528  decode.d7.loss_cls: 0.2627  decode.d7.loss_mask: 0.9990  decode.d7.loss_dice: 0.6769  decode.d8.loss_cls: 0.2757  decode.d8.loss_mask: 0.9944  decode.d8.loss_dice: 0.6609
05/26 22:24:39 - mmengine - INFO - Iter(train) [ 96950/160000]  base_lr: 4.3252e-05 lr: 4.3252e-06  eta: 7:13:39  time: 0.4158  data_time: 0.0099  memory: 5980  grad_norm: 810.4251  loss: 18.8331  decode.loss_cls: 0.1506  decode.loss_mask: 0.9792  decode.loss_dice: 0.7234  decode.d0.loss_cls: 0.6725  decode.d0.loss_mask: 0.8868  decode.d0.loss_dice: 0.7276  decode.d1.loss_cls: 0.1709  decode.d1.loss_mask: 1.0060  decode.d1.loss_dice: 0.7523  decode.d2.loss_cls: 0.1364  decode.d2.loss_mask: 0.9710  decode.d2.loss_dice: 0.7080  decode.d3.loss_cls: 0.1455  decode.d3.loss_mask: 0.9862  decode.d3.loss_dice: 0.7170  decode.d4.loss_cls: 0.1529  decode.d4.loss_mask: 0.9679  decode.d4.loss_dice: 0.6837  decode.d5.loss_cls: 0.1655  decode.d5.loss_mask: 0.9412  decode.d5.loss_dice: 0.6854  decode.d6.loss_cls: 0.1842  decode.d6.loss_mask: 0.9861  decode.d6.loss_dice: 0.7288  decode.d7.loss_cls: 0.1127  decode.d7.loss_mask: 0.9911  decode.d7.loss_dice: 0.6987  decode.d8.loss_cls: 0.1256  decode.d8.loss_mask: 0.9742  decode.d8.loss_dice: 0.7016
05/26 22:25:00 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 22:25:00 - mmengine - INFO - Iter(train) [ 97000/160000]  base_lr: 4.3222e-05 lr: 4.3222e-06  eta: 7:13:19  time: 0.4169  data_time: 0.0099  memory: 5965  grad_norm: 903.9932  loss: 24.6961  decode.loss_cls: 0.2328  decode.loss_mask: 1.3655  decode.loss_dice: 0.8193  decode.d0.loss_cls: 0.6379  decode.d0.loss_mask: 1.3315  decode.d0.loss_dice: 0.7680  decode.d1.loss_cls: 0.2280  decode.d1.loss_mask: 1.4384  decode.d1.loss_dice: 0.7966  decode.d2.loss_cls: 0.2121  decode.d2.loss_mask: 1.4237  decode.d2.loss_dice: 0.8038  decode.d3.loss_cls: 0.2199  decode.d3.loss_mask: 1.4325  decode.d3.loss_dice: 0.8089  decode.d4.loss_cls: 0.2348  decode.d4.loss_mask: 1.4270  decode.d4.loss_dice: 0.8078  decode.d5.loss_cls: 0.2337  decode.d5.loss_mask: 1.4278  decode.d5.loss_dice: 0.8134  decode.d6.loss_cls: 0.2687  decode.d6.loss_mask: 1.3835  decode.d6.loss_dice: 0.7990  decode.d7.loss_cls: 0.1521  decode.d7.loss_mask: 1.4287  decode.d7.loss_dice: 0.8067  decode.d8.loss_cls: 0.1998  decode.d8.loss_mask: 1.3872  decode.d8.loss_dice: 0.8073
05/26 22:25:21 - mmengine - INFO - Iter(train) [ 97050/160000]  base_lr: 4.3191e-05 lr: 4.3191e-06  eta: 7:12:58  time: 0.4174  data_time: 0.0099  memory: 5970  grad_norm: 666.9166  loss: 22.8452  decode.loss_cls: 0.1658  decode.loss_mask: 1.2264  decode.loss_dice: 0.8603  decode.d0.loss_cls: 0.7743  decode.d0.loss_mask: 1.0704  decode.d0.loss_dice: 0.7602  decode.d1.loss_cls: 0.2098  decode.d1.loss_mask: 1.2300  decode.d1.loss_dice: 0.8232  decode.d2.loss_cls: 0.2272  decode.d2.loss_mask: 1.2124  decode.d2.loss_dice: 0.8165  decode.d3.loss_cls: 0.2126  decode.d3.loss_mask: 1.1940  decode.d3.loss_dice: 0.7999  decode.d4.loss_cls: 0.2142  decode.d4.loss_mask: 1.2212  decode.d4.loss_dice: 0.8159  decode.d5.loss_cls: 0.2744  decode.d5.loss_mask: 1.1830  decode.d5.loss_dice: 0.7997  decode.d6.loss_cls: 0.2692  decode.d6.loss_mask: 1.1976  decode.d6.loss_dice: 0.7806  decode.d7.loss_cls: 0.2684  decode.d7.loss_mask: 1.1692  decode.d7.loss_dice: 0.8304  decode.d8.loss_cls: 0.2111  decode.d8.loss_mask: 1.2217  decode.d8.loss_dice: 0.8055
05/26 22:25:42 - mmengine - INFO - Iter(train) [ 97100/160000]  base_lr: 4.3160e-05 lr: 4.3160e-06  eta: 7:12:38  time: 0.4190  data_time: 0.0100  memory: 5966  grad_norm: 439.2734  loss: 20.8510  decode.loss_cls: 0.2160  decode.loss_mask: 1.0766  decode.loss_dice: 0.7170  decode.d0.loss_cls: 0.7075  decode.d0.loss_mask: 1.0371  decode.d0.loss_dice: 0.6627  decode.d1.loss_cls: 0.2477  decode.d1.loss_mask: 1.0843  decode.d1.loss_dice: 0.7320  decode.d2.loss_cls: 0.2417  decode.d2.loss_mask: 1.0854  decode.d2.loss_dice: 0.7214  decode.d3.loss_cls: 0.2314  decode.d3.loss_mask: 1.0975  decode.d3.loss_dice: 0.7145  decode.d4.loss_cls: 0.2448  decode.d4.loss_mask: 1.1087  decode.d4.loss_dice: 0.7289  decode.d5.loss_cls: 0.2415  decode.d5.loss_mask: 1.0965  decode.d5.loss_dice: 0.7293  decode.d6.loss_cls: 0.2492  decode.d6.loss_mask: 1.0790  decode.d6.loss_dice: 0.7249  decode.d7.loss_cls: 0.2124  decode.d7.loss_mask: 1.1032  decode.d7.loss_dice: 0.7367  decode.d8.loss_cls: 0.2053  decode.d8.loss_mask: 1.0952  decode.d8.loss_dice: 0.7227
05/26 22:26:03 - mmengine - INFO - Iter(train) [ 97150/160000]  base_lr: 4.3129e-05 lr: 4.3129e-06  eta: 7:12:18  time: 0.4137  data_time: 0.0096  memory: 5968  grad_norm: 574.1562  loss: 18.7634  decode.loss_cls: 0.2355  decode.loss_mask: 0.8990  decode.loss_dice: 0.6666  decode.d0.loss_cls: 0.7547  decode.d0.loss_mask: 0.8746  decode.d0.loss_dice: 0.6498  decode.d1.loss_cls: 0.2974  decode.d1.loss_mask: 0.8690  decode.d1.loss_dice: 0.6591  decode.d2.loss_cls: 0.2545  decode.d2.loss_mask: 0.8959  decode.d2.loss_dice: 0.6972  decode.d3.loss_cls: 0.2732  decode.d3.loss_mask: 0.8798  decode.d3.loss_dice: 0.6525  decode.d4.loss_cls: 0.2756  decode.d4.loss_mask: 0.9014  decode.d4.loss_dice: 0.6891  decode.d5.loss_cls: 0.2531  decode.d5.loss_mask: 0.9184  decode.d5.loss_dice: 0.6940  decode.d6.loss_cls: 0.2493  decode.d6.loss_mask: 0.8978  decode.d6.loss_dice: 0.6927  decode.d7.loss_cls: 0.2434  decode.d7.loss_mask: 0.8738  decode.d7.loss_dice: 0.6569  decode.d8.loss_cls: 0.2449  decode.d8.loss_mask: 0.9223  decode.d8.loss_dice: 0.6917
05/26 22:26:23 - mmengine - INFO - Iter(train) [ 97200/160000]  base_lr: 4.3098e-05 lr: 4.3098e-06  eta: 7:11:57  time: 0.4136  data_time: 0.0098  memory: 5970  grad_norm: 683.0955  loss: 21.6365  decode.loss_cls: 0.1698  decode.loss_mask: 1.1228  decode.loss_dice: 0.8108  decode.d0.loss_cls: 0.5971  decode.d0.loss_mask: 1.0735  decode.d0.loss_dice: 0.7793  decode.d1.loss_cls: 0.1199  decode.d1.loss_mask: 1.1612  decode.d1.loss_dice: 0.8196  decode.d2.loss_cls: 0.1452  decode.d2.loss_mask: 1.1570  decode.d2.loss_dice: 0.8217  decode.d3.loss_cls: 0.1981  decode.d3.loss_mask: 1.1285  decode.d3.loss_dice: 0.8036  decode.d4.loss_cls: 0.1702  decode.d4.loss_mask: 1.1379  decode.d4.loss_dice: 0.8140  decode.d5.loss_cls: 0.1530  decode.d5.loss_mask: 1.1883  decode.d5.loss_dice: 0.8459  decode.d6.loss_cls: 0.1808  decode.d6.loss_mask: 1.1697  decode.d6.loss_dice: 0.8351  decode.d7.loss_cls: 0.1508  decode.d7.loss_mask: 1.1692  decode.d7.loss_dice: 0.8285  decode.d8.loss_cls: 0.1603  decode.d8.loss_mask: 1.1285  decode.d8.loss_dice: 0.7961
05/26 22:26:44 - mmengine - INFO - Iter(train) [ 97250/160000]  base_lr: 4.3067e-05 lr: 4.3067e-06  eta: 7:11:36  time: 0.4134  data_time: 0.0096  memory: 5975  grad_norm: 589.4346  loss: 22.3091  decode.loss_cls: 0.1333  decode.loss_mask: 1.2020  decode.loss_dice: 0.8401  decode.d0.loss_cls: 0.5905  decode.d0.loss_mask: 1.1400  decode.d0.loss_dice: 0.8288  decode.d1.loss_cls: 0.1484  decode.d1.loss_mask: 1.1931  decode.d1.loss_dice: 0.8454  decode.d2.loss_cls: 0.1619  decode.d2.loss_mask: 1.1758  decode.d2.loss_dice: 0.8476  decode.d3.loss_cls: 0.1739  decode.d3.loss_mask: 1.1818  decode.d3.loss_dice: 0.8369  decode.d4.loss_cls: 0.1974  decode.d4.loss_mask: 1.1709  decode.d4.loss_dice: 0.8621  decode.d5.loss_cls: 0.1972  decode.d5.loss_mask: 1.1746  decode.d5.loss_dice: 0.8419  decode.d6.loss_cls: 0.1865  decode.d6.loss_mask: 1.1621  decode.d6.loss_dice: 0.8483  decode.d7.loss_cls: 0.1992  decode.d7.loss_mask: 1.1545  decode.d7.loss_dice: 0.8420  decode.d8.loss_cls: 0.1337  decode.d8.loss_mask: 1.1888  decode.d8.loss_dice: 0.8503
05/26 22:27:05 - mmengine - INFO - Iter(train) [ 97300/160000]  base_lr: 4.3036e-05 lr: 4.3036e-06  eta: 7:11:16  time: 0.4130  data_time: 0.0096  memory: 5974  grad_norm: 705.1106  loss: 25.3679  decode.loss_cls: 0.2594  decode.loss_mask: 1.2370  decode.loss_dice: 1.0076  decode.d0.loss_cls: 0.7336  decode.d0.loss_mask: 1.2323  decode.d0.loss_dice: 0.9405  decode.d1.loss_cls: 0.2789  decode.d1.loss_mask: 1.2634  decode.d1.loss_dice: 1.0092  decode.d2.loss_cls: 0.3023  decode.d2.loss_mask: 1.2509  decode.d2.loss_dice: 0.9617  decode.d3.loss_cls: 0.2818  decode.d3.loss_mask: 1.2229  decode.d3.loss_dice: 0.9151  decode.d4.loss_cls: 0.3233  decode.d4.loss_mask: 1.2318  decode.d4.loss_dice: 0.9170  decode.d5.loss_cls: 0.2786  decode.d5.loss_mask: 1.2486  decode.d5.loss_dice: 0.9666  decode.d6.loss_cls: 0.2952  decode.d6.loss_mask: 1.2356  decode.d6.loss_dice: 0.9883  decode.d7.loss_cls: 0.2642  decode.d7.loss_mask: 1.2593  decode.d7.loss_dice: 0.9866  decode.d8.loss_cls: 0.2799  decode.d8.loss_mask: 1.2281  decode.d8.loss_dice: 0.9684
05/26 22:27:25 - mmengine - INFO - Iter(train) [ 97350/160000]  base_lr: 4.3005e-05 lr: 4.3005e-06  eta: 7:10:55  time: 0.4133  data_time: 0.0097  memory: 5966  grad_norm: 395.1957  loss: 17.8870  decode.loss_cls: 0.2222  decode.loss_mask: 0.8424  decode.loss_dice: 0.6785  decode.d0.loss_cls: 0.6433  decode.d0.loss_mask: 0.8050  decode.d0.loss_dice: 0.6839  decode.d1.loss_cls: 0.2222  decode.d1.loss_mask: 0.8503  decode.d1.loss_dice: 0.6657  decode.d2.loss_cls: 0.1988  decode.d2.loss_mask: 0.8629  decode.d2.loss_dice: 0.6617  decode.d3.loss_cls: 0.2600  decode.d3.loss_mask: 0.8472  decode.d3.loss_dice: 0.6673  decode.d4.loss_cls: 0.2395  decode.d4.loss_mask: 0.8638  decode.d4.loss_dice: 0.6469  decode.d5.loss_cls: 0.2598  decode.d5.loss_mask: 0.8709  decode.d5.loss_dice: 0.6441  decode.d6.loss_cls: 0.2446  decode.d6.loss_mask: 0.8613  decode.d6.loss_dice: 0.6532  decode.d7.loss_cls: 0.2253  decode.d7.loss_mask: 0.8525  decode.d7.loss_dice: 0.6507  decode.d8.loss_cls: 0.2049  decode.d8.loss_mask: 0.8677  decode.d8.loss_dice: 0.6903
05/26 22:27:46 - mmengine - INFO - Iter(train) [ 97400/160000]  base_lr: 4.2975e-05 lr: 4.2975e-06  eta: 7:10:34  time: 0.4139  data_time: 0.0096  memory: 5974  grad_norm: 624.1839  loss: 20.2315  decode.loss_cls: 0.2923  decode.loss_mask: 0.9180  decode.loss_dice: 0.7177  decode.d0.loss_cls: 0.6878  decode.d0.loss_mask: 0.9947  decode.d0.loss_dice: 0.7699  decode.d1.loss_cls: 0.2718  decode.d1.loss_mask: 0.9568  decode.d1.loss_dice: 0.7509  decode.d2.loss_cls: 0.3195  decode.d2.loss_mask: 0.9909  decode.d2.loss_dice: 0.7429  decode.d3.loss_cls: 0.2628  decode.d3.loss_mask: 0.9921  decode.d3.loss_dice: 0.7272  decode.d4.loss_cls: 0.2866  decode.d4.loss_mask: 0.9340  decode.d4.loss_dice: 0.7345  decode.d5.loss_cls: 0.3172  decode.d5.loss_mask: 0.9405  decode.d5.loss_dice: 0.7327  decode.d6.loss_cls: 0.3378  decode.d6.loss_mask: 0.9313  decode.d6.loss_dice: 0.7297  decode.d7.loss_cls: 0.2991  decode.d7.loss_mask: 0.9432  decode.d7.loss_dice: 0.7264  decode.d8.loss_cls: 0.2842  decode.d8.loss_mask: 0.9141  decode.d8.loss_dice: 0.7250
05/26 22:28:07 - mmengine - INFO - Iter(train) [ 97450/160000]  base_lr: 4.2944e-05 lr: 4.2944e-06  eta: 7:10:14  time: 0.4137  data_time: 0.0096  memory: 5975  grad_norm: 340.7383  loss: 18.4616  decode.loss_cls: 0.1736  decode.loss_mask: 0.9217  decode.loss_dice: 0.6962  decode.d0.loss_cls: 0.6336  decode.d0.loss_mask: 0.9120  decode.d0.loss_dice: 0.7019  decode.d1.loss_cls: 0.1723  decode.d1.loss_mask: 0.9279  decode.d1.loss_dice: 0.7002  decode.d2.loss_cls: 0.1538  decode.d2.loss_mask: 0.9407  decode.d2.loss_dice: 0.7110  decode.d3.loss_cls: 0.1869  decode.d3.loss_mask: 0.9210  decode.d3.loss_dice: 0.6890  decode.d4.loss_cls: 0.1736  decode.d4.loss_mask: 0.9249  decode.d4.loss_dice: 0.6906  decode.d5.loss_cls: 0.1626  decode.d5.loss_mask: 0.9453  decode.d5.loss_dice: 0.7015  decode.d6.loss_cls: 0.1818  decode.d6.loss_mask: 0.9406  decode.d6.loss_dice: 0.7008  decode.d7.loss_cls: 0.1719  decode.d7.loss_mask: 0.9391  decode.d7.loss_dice: 0.6961  decode.d8.loss_cls: 0.1741  decode.d8.loss_mask: 0.9221  decode.d8.loss_dice: 0.6949
05/26 22:28:27 - mmengine - INFO - Iter(train) [ 97500/160000]  base_lr: 4.2913e-05 lr: 4.2913e-06  eta: 7:09:53  time: 0.4134  data_time: 0.0096  memory: 5966  grad_norm: 600.4566  loss: 20.4477  decode.loss_cls: 0.2035  decode.loss_mask: 1.0450  decode.loss_dice: 0.7014  decode.d0.loss_cls: 0.6666  decode.d0.loss_mask: 1.0211  decode.d0.loss_dice: 0.7209  decode.d1.loss_cls: 0.1914  decode.d1.loss_mask: 1.0512  decode.d1.loss_dice: 0.7251  decode.d2.loss_cls: 0.1875  decode.d2.loss_mask: 1.0359  decode.d2.loss_dice: 0.7187  decode.d3.loss_cls: 0.2131  decode.d3.loss_mask: 1.0540  decode.d3.loss_dice: 0.7274  decode.d4.loss_cls: 0.1554  decode.d4.loss_mask: 1.1594  decode.d4.loss_dice: 0.7391  decode.d5.loss_cls: 0.2097  decode.d5.loss_mask: 1.0657  decode.d5.loss_dice: 0.7256  decode.d6.loss_cls: 0.1726  decode.d6.loss_mask: 1.1316  decode.d6.loss_dice: 0.7286  decode.d7.loss_cls: 0.1704  decode.d7.loss_mask: 1.1574  decode.d7.loss_dice: 0.7335  decode.d8.loss_cls: 0.1639  decode.d8.loss_mask: 1.1496  decode.d8.loss_dice: 0.7223
05/26 22:28:48 - mmengine - INFO - Iter(train) [ 97550/160000]  base_lr: 4.2882e-05 lr: 4.2882e-06  eta: 7:09:33  time: 0.4136  data_time: 0.0097  memory: 5980  grad_norm: 326.4646  loss: 15.4840  decode.loss_cls: 0.0669  decode.loss_mask: 0.8819  decode.loss_dice: 0.5554  decode.d0.loss_cls: 0.4648  decode.d0.loss_mask: 0.8713  decode.d0.loss_dice: 0.5656  decode.d1.loss_cls: 0.0499  decode.d1.loss_mask: 0.8864  decode.d1.loss_dice: 0.5710  decode.d2.loss_cls: 0.0540  decode.d2.loss_mask: 0.8925  decode.d2.loss_dice: 0.5756  decode.d3.loss_cls: 0.0581  decode.d3.loss_mask: 0.8763  decode.d3.loss_dice: 0.5600  decode.d4.loss_cls: 0.0590  decode.d4.loss_mask: 0.8916  decode.d4.loss_dice: 0.5760  decode.d5.loss_cls: 0.0509  decode.d5.loss_mask: 0.8820  decode.d5.loss_dice: 0.5586  decode.d6.loss_cls: 0.0523  decode.d6.loss_mask: 0.8944  decode.d6.loss_dice: 0.5711  decode.d7.loss_cls: 0.0527  decode.d7.loss_mask: 0.8823  decode.d7.loss_dice: 0.5784  decode.d8.loss_cls: 0.0560  decode.d8.loss_mask: 0.8829  decode.d8.loss_dice: 0.5662
05/26 22:29:09 - mmengine - INFO - Iter(train) [ 97600/160000]  base_lr: 4.2851e-05 lr: 4.2851e-06  eta: 7:09:12  time: 0.4127  data_time: 0.0096  memory: 5974  grad_norm: 533.9172  loss: 21.6820  decode.loss_cls: 0.1948  decode.loss_mask: 1.0626  decode.loss_dice: 0.7957  decode.d0.loss_cls: 0.6945  decode.d0.loss_mask: 1.0724  decode.d0.loss_dice: 0.7838  decode.d1.loss_cls: 0.2488  decode.d1.loss_mask: 1.0745  decode.d1.loss_dice: 0.8048  decode.d2.loss_cls: 0.2574  decode.d2.loss_mask: 1.0813  decode.d2.loss_dice: 0.8116  decode.d3.loss_cls: 0.2228  decode.d3.loss_mask: 1.0964  decode.d3.loss_dice: 0.8060  decode.d4.loss_cls: 0.2324  decode.d4.loss_mask: 1.1004  decode.d4.loss_dice: 0.8042  decode.d5.loss_cls: 0.2426  decode.d5.loss_mask: 1.1107  decode.d5.loss_dice: 0.8161  decode.d6.loss_cls: 0.2238  decode.d6.loss_mask: 1.0897  decode.d6.loss_dice: 0.8107  decode.d7.loss_cls: 0.2234  decode.d7.loss_mask: 1.0792  decode.d7.loss_dice: 0.8205  decode.d8.loss_cls: 0.1740  decode.d8.loss_mask: 1.1250  decode.d8.loss_dice: 0.8220
05/26 22:29:29 - mmengine - INFO - Iter(train) [ 97650/160000]  base_lr: 4.2820e-05 lr: 4.2820e-06  eta: 7:08:51  time: 0.4134  data_time: 0.0096  memory: 5975  grad_norm: 513.3236  loss: 19.3907  decode.loss_cls: 0.1833  decode.loss_mask: 1.0106  decode.loss_dice: 0.6476  decode.d0.loss_cls: 0.6698  decode.d0.loss_mask: 1.0313  decode.d0.loss_dice: 0.6996  decode.d1.loss_cls: 0.1751  decode.d1.loss_mask: 1.0671  decode.d1.loss_dice: 0.6822  decode.d2.loss_cls: 0.1442  decode.d2.loss_mask: 1.0675  decode.d2.loss_dice: 0.6713  decode.d3.loss_cls: 0.1675  decode.d3.loss_mask: 1.0285  decode.d3.loss_dice: 0.6498  decode.d4.loss_cls: 0.1551  decode.d4.loss_mask: 1.0705  decode.d4.loss_dice: 0.6745  decode.d5.loss_cls: 0.1778  decode.d5.loss_mask: 1.0904  decode.d5.loss_dice: 0.7007  decode.d6.loss_cls: 0.1675  decode.d6.loss_mask: 1.0599  decode.d6.loss_dice: 0.6695  decode.d7.loss_cls: 0.1576  decode.d7.loss_mask: 1.0571  decode.d7.loss_dice: 0.6690  decode.d8.loss_cls: 0.1694  decode.d8.loss_mask: 1.0200  decode.d8.loss_dice: 0.6564
05/26 22:29:50 - mmengine - INFO - Iter(train) [ 97700/160000]  base_lr: 4.2789e-05 lr: 4.2789e-06  eta: 7:08:31  time: 0.4220  data_time: 0.0099  memory: 5980  grad_norm: 567.2950  loss: 19.2566  decode.loss_cls: 0.2701  decode.loss_mask: 0.9170  decode.loss_dice: 0.6916  decode.d0.loss_cls: 0.6915  decode.d0.loss_mask: 0.9098  decode.d0.loss_dice: 0.6750  decode.d1.loss_cls: 0.2350  decode.d1.loss_mask: 0.9238  decode.d1.loss_dice: 0.7123  decode.d2.loss_cls: 0.2611  decode.d2.loss_mask: 0.9325  decode.d2.loss_dice: 0.6900  decode.d3.loss_cls: 0.2666  decode.d3.loss_mask: 0.9419  decode.d3.loss_dice: 0.6971  decode.d4.loss_cls: 0.2056  decode.d4.loss_mask: 0.9440  decode.d4.loss_dice: 0.6826  decode.d5.loss_cls: 0.2607  decode.d5.loss_mask: 0.9549  decode.d5.loss_dice: 0.7159  decode.d6.loss_cls: 0.2741  decode.d6.loss_mask: 0.9222  decode.d6.loss_dice: 0.6930  decode.d7.loss_cls: 0.2525  decode.d7.loss_mask: 0.9199  decode.d7.loss_dice: 0.7007  decode.d8.loss_cls: 0.3058  decode.d8.loss_mask: 0.9191  decode.d8.loss_dice: 0.6903
05/26 22:30:11 - mmengine - INFO - Iter(train) [ 97750/160000]  base_lr: 4.2758e-05 lr: 4.2758e-06  eta: 7:08:11  time: 0.4219  data_time: 0.0099  memory: 5990  grad_norm: 571.8497  loss: 23.8598  decode.loss_cls: 0.2684  decode.loss_mask: 1.2102  decode.loss_dice: 0.8291  decode.d0.loss_cls: 0.7968  decode.d0.loss_mask: 1.2033  decode.d0.loss_dice: 0.8331  decode.d1.loss_cls: 0.3126  decode.d1.loss_mask: 1.2308  decode.d1.loss_dice: 0.8509  decode.d2.loss_cls: 0.3031  decode.d2.loss_mask: 1.1772  decode.d2.loss_dice: 0.8352  decode.d3.loss_cls: 0.3318  decode.d3.loss_mask: 1.1550  decode.d3.loss_dice: 0.8071  decode.d4.loss_cls: 0.3075  decode.d4.loss_mask: 1.1561  decode.d4.loss_dice: 0.8112  decode.d5.loss_cls: 0.3062  decode.d5.loss_mask: 1.1735  decode.d5.loss_dice: 0.8241  decode.d6.loss_cls: 0.3195  decode.d6.loss_mask: 1.1983  decode.d6.loss_dice: 0.8268  decode.d7.loss_cls: 0.2728  decode.d7.loss_mask: 1.3244  decode.d7.loss_dice: 0.8527  decode.d8.loss_cls: 0.2746  decode.d8.loss_mask: 1.2513  decode.d8.loss_dice: 0.8164
05/26 22:30:32 - mmengine - INFO - Iter(train) [ 97800/160000]  base_lr: 4.2727e-05 lr: 4.2727e-06  eta: 7:07:50  time: 0.4166  data_time: 0.0100  memory: 5980  grad_norm: 545.3324  loss: 22.5768  decode.loss_cls: 0.2314  decode.loss_mask: 1.1029  decode.loss_dice: 0.9025  decode.d0.loss_cls: 0.7688  decode.d0.loss_mask: 1.0480  decode.d0.loss_dice: 0.8670  decode.d1.loss_cls: 0.2510  decode.d1.loss_mask: 1.0981  decode.d1.loss_dice: 0.8983  decode.d2.loss_cls: 0.2492  decode.d2.loss_mask: 1.0863  decode.d2.loss_dice: 0.8918  decode.d3.loss_cls: 0.2918  decode.d3.loss_mask: 1.0812  decode.d3.loss_dice: 0.8659  decode.d4.loss_cls: 0.2751  decode.d4.loss_mask: 1.0628  decode.d4.loss_dice: 0.8570  decode.d5.loss_cls: 0.2845  decode.d5.loss_mask: 1.0866  decode.d5.loss_dice: 0.8711  decode.d6.loss_cls: 0.2249  decode.d6.loss_mask: 1.0734  decode.d6.loss_dice: 0.8625  decode.d7.loss_cls: 0.2197  decode.d7.loss_mask: 1.1169  decode.d7.loss_dice: 0.8634  decode.d8.loss_cls: 0.2338  decode.d8.loss_mask: 1.0685  decode.d8.loss_dice: 0.8423
05/26 22:30:53 - mmengine - INFO - Iter(train) [ 97850/160000]  base_lr: 4.2696e-05 lr: 4.2696e-06  eta: 7:07:30  time: 0.4160  data_time: 0.0098  memory: 5976  grad_norm: 560.3632  loss: 19.8423  decode.loss_cls: 0.1939  decode.loss_mask: 1.0384  decode.loss_dice: 0.6723  decode.d0.loss_cls: 0.5872  decode.d0.loss_mask: 1.0384  decode.d0.loss_dice: 0.7045  decode.d1.loss_cls: 0.1849  decode.d1.loss_mask: 1.0872  decode.d1.loss_dice: 0.7142  decode.d2.loss_cls: 0.1608  decode.d2.loss_mask: 1.0711  decode.d2.loss_dice: 0.6941  decode.d3.loss_cls: 0.1762  decode.d3.loss_mask: 1.0710  decode.d3.loss_dice: 0.7177  decode.d4.loss_cls: 0.1661  decode.d4.loss_mask: 1.0686  decode.d4.loss_dice: 0.7136  decode.d5.loss_cls: 0.1823  decode.d5.loss_mask: 1.0588  decode.d5.loss_dice: 0.7011  decode.d6.loss_cls: 0.2066  decode.d6.loss_mask: 1.0798  decode.d6.loss_dice: 0.6915  decode.d7.loss_cls: 0.2126  decode.d7.loss_mask: 1.0309  decode.d7.loss_dice: 0.6989  decode.d8.loss_cls: 0.1848  decode.d8.loss_mask: 1.0510  decode.d8.loss_dice: 0.6834
05/26 22:31:14 - mmengine - INFO - Iter(train) [ 97900/160000]  base_lr: 4.2666e-05 lr: 4.2666e-06  eta: 7:07:09  time: 0.4170  data_time: 0.0099  memory: 5996  grad_norm: 386.4719  loss: 17.8128  decode.loss_cls: 0.0842  decode.loss_mask: 0.9909  decode.loss_dice: 0.6747  decode.d0.loss_cls: 0.6574  decode.d0.loss_mask: 0.8580  decode.d0.loss_dice: 0.6239  decode.d1.loss_cls: 0.0923  decode.d1.loss_mask: 0.9903  decode.d1.loss_dice: 0.6736  decode.d2.loss_cls: 0.0662  decode.d2.loss_mask: 0.9953  decode.d2.loss_dice: 0.6781  decode.d3.loss_cls: 0.0919  decode.d3.loss_mask: 0.9791  decode.d3.loss_dice: 0.6623  decode.d4.loss_cls: 0.0707  decode.d4.loss_mask: 0.9970  decode.d4.loss_dice: 0.6666  decode.d5.loss_cls: 0.0878  decode.d5.loss_mask: 0.9830  decode.d5.loss_dice: 0.6659  decode.d6.loss_cls: 0.0945  decode.d6.loss_mask: 0.9889  decode.d6.loss_dice: 0.6704  decode.d7.loss_cls: 0.0801  decode.d7.loss_mask: 0.9631  decode.d7.loss_dice: 0.6594  decode.d8.loss_cls: 0.0789  decode.d8.loss_mask: 0.9998  decode.d8.loss_dice: 0.6885
05/26 22:31:35 - mmengine - INFO - Iter(train) [ 97950/160000]  base_lr: 4.2635e-05 lr: 4.2635e-06  eta: 7:06:49  time: 0.4273  data_time: 0.0099  memory: 5968  grad_norm: 593.5987  loss: 22.3023  decode.loss_cls: 0.2508  decode.loss_mask: 0.9913  decode.loss_dice: 0.8943  decode.d0.loss_cls: 0.8617  decode.d0.loss_mask: 1.0082  decode.d0.loss_dice: 0.8191  decode.d1.loss_cls: 0.2975  decode.d1.loss_mask: 1.0273  decode.d1.loss_dice: 0.8847  decode.d2.loss_cls: 0.2862  decode.d2.loss_mask: 1.0072  decode.d2.loss_dice: 0.8692  decode.d3.loss_cls: 0.2899  decode.d3.loss_mask: 1.0217  decode.d3.loss_dice: 0.9115  decode.d4.loss_cls: 0.2421  decode.d4.loss_mask: 1.0660  decode.d4.loss_dice: 0.9138  decode.d5.loss_cls: 0.2778  decode.d5.loss_mask: 1.0360  decode.d5.loss_dice: 0.8613  decode.d6.loss_cls: 0.2768  decode.d6.loss_mask: 1.0298  decode.d6.loss_dice: 0.9029  decode.d7.loss_cls: 0.3088  decode.d7.loss_mask: 0.9649  decode.d7.loss_dice: 0.8390  decode.d8.loss_cls: 0.2739  decode.d8.loss_mask: 0.9966  decode.d8.loss_dice: 0.8921
05/26 22:31:56 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 22:31:56 - mmengine - INFO - Iter(train) [ 98000/160000]  base_lr: 4.2604e-05 lr: 4.2604e-06  eta: 7:06:28  time: 0.4158  data_time: 0.0099  memory: 5970  grad_norm: 774.2030  loss: 19.3569  decode.loss_cls: 0.0886  decode.loss_mask: 1.0347  decode.loss_dice: 0.7249  decode.d0.loss_cls: 0.6354  decode.d0.loss_mask: 1.0427  decode.d0.loss_dice: 0.7334  decode.d1.loss_cls: 0.1184  decode.d1.loss_mask: 1.0520  decode.d1.loss_dice: 0.7466  decode.d2.loss_cls: 0.0846  decode.d2.loss_mask: 1.0586  decode.d2.loss_dice: 0.7490  decode.d3.loss_cls: 0.0989  decode.d3.loss_mask: 1.0558  decode.d3.loss_dice: 0.7384  decode.d4.loss_cls: 0.1286  decode.d4.loss_mask: 1.0455  decode.d4.loss_dice: 0.7448  decode.d5.loss_cls: 0.1420  decode.d5.loss_mask: 1.0393  decode.d5.loss_dice: 0.7367  decode.d6.loss_cls: 0.0909  decode.d6.loss_mask: 1.0458  decode.d6.loss_dice: 0.7323  decode.d7.loss_cls: 0.0773  decode.d7.loss_mask: 1.0565  decode.d7.loss_dice: 0.7325  decode.d8.loss_cls: 0.0501  decode.d8.loss_mask: 1.0406  decode.d8.loss_dice: 0.7320
05/26 22:32:17 - mmengine - INFO - Iter(train) [ 98050/160000]  base_lr: 4.2573e-05 lr: 4.2573e-06  eta: 7:06:08  time: 0.4169  data_time: 0.0099  memory: 5969  grad_norm: 493.6057  loss: 19.2837  decode.loss_cls: 0.1594  decode.loss_mask: 0.9195  decode.loss_dice: 0.7577  decode.d0.loss_cls: 0.7094  decode.d0.loss_mask: 0.9445  decode.d0.loss_dice: 0.7423  decode.d1.loss_cls: 0.2073  decode.d1.loss_mask: 0.9402  decode.d1.loss_dice: 0.7704  decode.d2.loss_cls: 0.1824  decode.d2.loss_mask: 0.9173  decode.d2.loss_dice: 0.7818  decode.d3.loss_cls: 0.1785  decode.d3.loss_mask: 0.9138  decode.d3.loss_dice: 0.7768  decode.d4.loss_cls: 0.1844  decode.d4.loss_mask: 0.9344  decode.d4.loss_dice: 0.7777  decode.d5.loss_cls: 0.1800  decode.d5.loss_mask: 0.9235  decode.d5.loss_dice: 0.7646  decode.d6.loss_cls: 0.2108  decode.d6.loss_mask: 0.9221  decode.d6.loss_dice: 0.7619  decode.d7.loss_cls: 0.2002  decode.d7.loss_mask: 0.9183  decode.d7.loss_dice: 0.7652  decode.d8.loss_cls: 0.1720  decode.d8.loss_mask: 0.9275  decode.d8.loss_dice: 0.7399
05/26 22:32:38 - mmengine - INFO - Iter(train) [ 98100/160000]  base_lr: 4.2542e-05 lr: 4.2542e-06  eta: 7:05:47  time: 0.4176  data_time: 0.0099  memory: 5972  grad_norm: 754.8774  loss: 20.3767  decode.loss_cls: 0.1654  decode.loss_mask: 1.0640  decode.loss_dice: 0.7491  decode.d0.loss_cls: 0.6645  decode.d0.loss_mask: 0.9833  decode.d0.loss_dice: 0.7410  decode.d1.loss_cls: 0.1611  decode.d1.loss_mask: 1.0541  decode.d1.loss_dice: 0.7616  decode.d2.loss_cls: 0.1458  decode.d2.loss_mask: 1.0741  decode.d2.loss_dice: 0.7712  decode.d3.loss_cls: 0.1042  decode.d3.loss_mask: 1.1311  decode.d3.loss_dice: 0.7697  decode.d4.loss_cls: 0.1372  decode.d4.loss_mask: 1.0940  decode.d4.loss_dice: 0.7797  decode.d5.loss_cls: 0.1509  decode.d5.loss_mask: 1.0529  decode.d5.loss_dice: 0.7630  decode.d6.loss_cls: 0.1159  decode.d6.loss_mask: 1.1307  decode.d6.loss_dice: 0.7698  decode.d7.loss_cls: 0.1347  decode.d7.loss_mask: 1.1218  decode.d7.loss_dice: 0.7691  decode.d8.loss_cls: 0.1693  decode.d8.loss_mask: 1.0812  decode.d8.loss_dice: 0.7662
05/26 22:32:59 - mmengine - INFO - Iter(train) [ 98150/160000]  base_lr: 4.2511e-05 lr: 4.2511e-06  eta: 7:05:27  time: 0.4169  data_time: 0.0099  memory: 5969  grad_norm: 616.9736  loss: 23.0151  decode.loss_cls: 0.1718  decode.loss_mask: 1.2173  decode.loss_dice: 0.8345  decode.d0.loss_cls: 0.7561  decode.d0.loss_mask: 1.1420  decode.d0.loss_dice: 0.8238  decode.d1.loss_cls: 0.2197  decode.d1.loss_mask: 1.1775  decode.d1.loss_dice: 0.8635  decode.d2.loss_cls: 0.2512  decode.d2.loss_mask: 1.1701  decode.d2.loss_dice: 0.8081  decode.d3.loss_cls: 0.1885  decode.d3.loss_mask: 1.2185  decode.d3.loss_dice: 0.8507  decode.d4.loss_cls: 0.2545  decode.d4.loss_mask: 1.2146  decode.d4.loss_dice: 0.8213  decode.d5.loss_cls: 0.2872  decode.d5.loss_mask: 1.1578  decode.d5.loss_dice: 0.8230  decode.d6.loss_cls: 0.2434  decode.d6.loss_mask: 1.1851  decode.d6.loss_dice: 0.8212  decode.d7.loss_cls: 0.3182  decode.d7.loss_mask: 1.1216  decode.d7.loss_dice: 0.8039  decode.d8.loss_cls: 0.1967  decode.d8.loss_mask: 1.2303  decode.d8.loss_dice: 0.8429
05/26 22:33:19 - mmengine - INFO - Iter(train) [ 98200/160000]  base_lr: 4.2480e-05 lr: 4.2480e-06  eta: 7:05:06  time: 0.4179  data_time: 0.0100  memory: 5974  grad_norm: 507.4901  loss: 21.3827  decode.loss_cls: 0.2176  decode.loss_mask: 1.0930  decode.loss_dice: 0.7476  decode.d0.loss_cls: 0.8473  decode.d0.loss_mask: 1.0389  decode.d0.loss_dice: 0.7473  decode.d1.loss_cls: 0.2563  decode.d1.loss_mask: 1.0626  decode.d1.loss_dice: 0.7369  decode.d2.loss_cls: 0.2293  decode.d2.loss_mask: 1.0525  decode.d2.loss_dice: 0.7457  decode.d3.loss_cls: 0.2456  decode.d3.loss_mask: 1.0757  decode.d3.loss_dice: 0.7622  decode.d4.loss_cls: 0.2273  decode.d4.loss_mask: 1.1170  decode.d4.loss_dice: 0.7726  decode.d5.loss_cls: 0.2077  decode.d5.loss_mask: 1.1267  decode.d5.loss_dice: 0.7983  decode.d6.loss_cls: 0.2711  decode.d6.loss_mask: 1.0772  decode.d6.loss_dice: 0.7494  decode.d7.loss_cls: 0.2416  decode.d7.loss_mask: 1.0684  decode.d7.loss_dice: 0.7840  decode.d8.loss_cls: 0.2552  decode.d8.loss_mask: 1.0697  decode.d8.loss_dice: 0.7580
05/26 22:33:40 - mmengine - INFO - Iter(train) [ 98250/160000]  base_lr: 4.2449e-05 lr: 4.2449e-06  eta: 7:04:46  time: 0.4177  data_time: 0.0099  memory: 5966  grad_norm: 641.2358  loss: 20.0961  decode.loss_cls: 0.1131  decode.loss_mask: 1.1319  decode.loss_dice: 0.7062  decode.d0.loss_cls: 0.6497  decode.d0.loss_mask: 1.0846  decode.d0.loss_dice: 0.6867  decode.d1.loss_cls: 0.1300  decode.d1.loss_mask: 1.1336  decode.d1.loss_dice: 0.7117  decode.d2.loss_cls: 0.1154  decode.d2.loss_mask: 1.1295  decode.d2.loss_dice: 0.7087  decode.d3.loss_cls: 0.0976  decode.d3.loss_mask: 1.1471  decode.d3.loss_dice: 0.7346  decode.d4.loss_cls: 0.0908  decode.d4.loss_mask: 1.1571  decode.d4.loss_dice: 0.7547  decode.d5.loss_cls: 0.1008  decode.d5.loss_mask: 1.1535  decode.d5.loss_dice: 0.7297  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 1.1230  decode.d6.loss_dice: 0.7352  decode.d7.loss_cls: 0.1006  decode.d7.loss_mask: 1.1318  decode.d7.loss_dice: 0.7164  decode.d8.loss_cls: 0.0976  decode.d8.loss_mask: 1.1216  decode.d8.loss_dice: 0.7104
05/26 22:34:01 - mmengine - INFO - Iter(train) [ 98300/160000]  base_lr: 4.2418e-05 lr: 4.2418e-06  eta: 7:04:25  time: 0.4167  data_time: 0.0099  memory: 5975  grad_norm: 411.7192  loss: 18.5492  decode.loss_cls: 0.1497  decode.loss_mask: 0.9591  decode.loss_dice: 0.6617  decode.d0.loss_cls: 0.6665  decode.d0.loss_mask: 0.9541  decode.d0.loss_dice: 0.6650  decode.d1.loss_cls: 0.1588  decode.d1.loss_mask: 0.9728  decode.d1.loss_dice: 0.7253  decode.d2.loss_cls: 0.1736  decode.d2.loss_mask: 0.9667  decode.d2.loss_dice: 0.6844  decode.d3.loss_cls: 0.1675  decode.d3.loss_mask: 0.9414  decode.d3.loss_dice: 0.6635  decode.d4.loss_cls: 0.1569  decode.d4.loss_mask: 0.9610  decode.d4.loss_dice: 0.6790  decode.d5.loss_cls: 0.1576  decode.d5.loss_mask: 0.9672  decode.d5.loss_dice: 0.6771  decode.d6.loss_cls: 0.1604  decode.d6.loss_mask: 0.9684  decode.d6.loss_dice: 0.7047  decode.d7.loss_cls: 0.1527  decode.d7.loss_mask: 0.9500  decode.d7.loss_dice: 0.6843  decode.d8.loss_cls: 0.1599  decode.d8.loss_mask: 0.9844  decode.d8.loss_dice: 0.6755
05/26 22:34:22 - mmengine - INFO - Iter(train) [ 98350/160000]  base_lr: 4.2387e-05 lr: 4.2387e-06  eta: 7:04:05  time: 0.4183  data_time: 0.0100  memory: 5969  grad_norm: 551.4602  loss: 21.1541  decode.loss_cls: 0.1617  decode.loss_mask: 1.1300  decode.loss_dice: 0.7719  decode.d0.loss_cls: 0.6990  decode.d0.loss_mask: 1.1006  decode.d0.loss_dice: 0.7675  decode.d1.loss_cls: 0.2109  decode.d1.loss_mask: 1.0957  decode.d1.loss_dice: 0.7425  decode.d2.loss_cls: 0.2113  decode.d2.loss_mask: 1.0756  decode.d2.loss_dice: 0.7195  decode.d3.loss_cls: 0.1701  decode.d3.loss_mask: 1.0866  decode.d3.loss_dice: 0.7674  decode.d4.loss_cls: 0.1547  decode.d4.loss_mask: 1.1564  decode.d4.loss_dice: 0.7933  decode.d5.loss_cls: 0.1894  decode.d5.loss_mask: 1.0956  decode.d5.loss_dice: 0.7955  decode.d6.loss_cls: 0.1979  decode.d6.loss_mask: 1.1031  decode.d6.loss_dice: 0.7801  decode.d7.loss_cls: 0.1970  decode.d7.loss_mask: 1.1031  decode.d7.loss_dice: 0.7903  decode.d8.loss_cls: 0.1853  decode.d8.loss_mask: 1.1341  decode.d8.loss_dice: 0.7680
05/26 22:34:43 - mmengine - INFO - Iter(train) [ 98400/160000]  base_lr: 4.2356e-05 lr: 4.2356e-06  eta: 7:03:44  time: 0.4179  data_time: 0.0100  memory: 5981  grad_norm: 592.5153  loss: 22.2743  decode.loss_cls: 0.1816  decode.loss_mask: 1.1766  decode.loss_dice: 0.8249  decode.d0.loss_cls: 0.8671  decode.d0.loss_mask: 1.0683  decode.d0.loss_dice: 0.7634  decode.d1.loss_cls: 0.2197  decode.d1.loss_mask: 1.1246  decode.d1.loss_dice: 0.7883  decode.d2.loss_cls: 0.2181  decode.d2.loss_mask: 1.1665  decode.d2.loss_dice: 0.8056  decode.d3.loss_cls: 0.2371  decode.d3.loss_mask: 1.1003  decode.d3.loss_dice: 0.7722  decode.d4.loss_cls: 0.2846  decode.d4.loss_mask: 1.1024  decode.d4.loss_dice: 0.7602  decode.d5.loss_cls: 0.2514  decode.d5.loss_mask: 1.1318  decode.d5.loss_dice: 0.7939  decode.d6.loss_cls: 0.3242  decode.d6.loss_mask: 1.1129  decode.d6.loss_dice: 0.7738  decode.d7.loss_cls: 0.2562  decode.d7.loss_mask: 1.1373  decode.d7.loss_dice: 0.8126  decode.d8.loss_cls: 0.2064  decode.d8.loss_mask: 1.1979  decode.d8.loss_dice: 0.8145
05/26 22:35:04 - mmengine - INFO - Iter(train) [ 98450/160000]  base_lr: 4.2325e-05 lr: 4.2325e-06  eta: 7:03:24  time: 0.4163  data_time: 0.0100  memory: 5969  grad_norm: 345.6484  loss: 18.9236  decode.loss_cls: 0.1377  decode.loss_mask: 1.0017  decode.loss_dice: 0.6934  decode.d0.loss_cls: 0.7739  decode.d0.loss_mask: 0.9729  decode.d0.loss_dice: 0.7194  decode.d1.loss_cls: 0.1408  decode.d1.loss_mask: 1.0083  decode.d1.loss_dice: 0.6893  decode.d2.loss_cls: 0.1550  decode.d2.loss_mask: 0.9965  decode.d2.loss_dice: 0.6761  decode.d3.loss_cls: 0.1446  decode.d3.loss_mask: 0.9993  decode.d3.loss_dice: 0.6874  decode.d4.loss_cls: 0.1351  decode.d4.loss_mask: 0.9808  decode.d4.loss_dice: 0.6909  decode.d5.loss_cls: 0.1627  decode.d5.loss_mask: 0.9728  decode.d5.loss_dice: 0.6891  decode.d6.loss_cls: 0.1626  decode.d6.loss_mask: 0.9833  decode.d6.loss_dice: 0.6829  decode.d7.loss_cls: 0.1577  decode.d7.loss_mask: 0.9807  decode.d7.loss_dice: 0.6852  decode.d8.loss_cls: 0.1664  decode.d8.loss_mask: 0.9955  decode.d8.loss_dice: 0.6815
05/26 22:35:25 - mmengine - INFO - Iter(train) [ 98500/160000]  base_lr: 4.2294e-05 lr: 4.2294e-06  eta: 7:03:03  time: 0.4160  data_time: 0.0099  memory: 5976  grad_norm: 457.2645  loss: 17.6032  decode.loss_cls: 0.1394  decode.loss_mask: 0.9152  decode.loss_dice: 0.6374  decode.d0.loss_cls: 0.6455  decode.d0.loss_mask: 0.8566  decode.d0.loss_dice: 0.6445  decode.d1.loss_cls: 0.1959  decode.d1.loss_mask: 0.9174  decode.d1.loss_dice: 0.6380  decode.d2.loss_cls: 0.1425  decode.d2.loss_mask: 0.9082  decode.d2.loss_dice: 0.6304  decode.d3.loss_cls: 0.1597  decode.d3.loss_mask: 0.9286  decode.d3.loss_dice: 0.6454  decode.d4.loss_cls: 0.1462  decode.d4.loss_mask: 0.9077  decode.d4.loss_dice: 0.6515  decode.d5.loss_cls: 0.1750  decode.d5.loss_mask: 0.9106  decode.d5.loss_dice: 0.6524  decode.d6.loss_cls: 0.1332  decode.d6.loss_mask: 0.9182  decode.d6.loss_dice: 0.6635  decode.d7.loss_cls: 0.1547  decode.d7.loss_mask: 0.9095  decode.d7.loss_dice: 0.6519  decode.d8.loss_cls: 0.1550  decode.d8.loss_mask: 0.9138  decode.d8.loss_dice: 0.6553
05/26 22:35:46 - mmengine - INFO - Iter(train) [ 98550/160000]  base_lr: 4.2263e-05 lr: 4.2263e-06  eta: 7:02:43  time: 0.4202  data_time: 0.0099  memory: 5974  grad_norm: 611.8117  loss: 20.6710  decode.loss_cls: 0.2450  decode.loss_mask: 0.9185  decode.loss_dice: 0.7946  decode.d0.loss_cls: 0.8351  decode.d0.loss_mask: 0.8421  decode.d0.loss_dice: 0.7959  decode.d1.loss_cls: 0.2807  decode.d1.loss_mask: 0.9098  decode.d1.loss_dice: 0.8487  decode.d2.loss_cls: 0.2785  decode.d2.loss_mask: 0.9411  decode.d2.loss_dice: 0.8384  decode.d3.loss_cls: 0.2681  decode.d3.loss_mask: 0.9618  decode.d3.loss_dice: 0.8185  decode.d4.loss_cls: 0.3029  decode.d4.loss_mask: 0.9364  decode.d4.loss_dice: 0.7962  decode.d5.loss_cls: 0.3331  decode.d5.loss_mask: 0.8958  decode.d5.loss_dice: 0.7932  decode.d6.loss_cls: 0.2997  decode.d6.loss_mask: 0.9239  decode.d6.loss_dice: 0.8149  decode.d7.loss_cls: 0.2843  decode.d7.loss_mask: 0.9218  decode.d7.loss_dice: 0.8083  decode.d8.loss_cls: 0.2755  decode.d8.loss_mask: 0.9028  decode.d8.loss_dice: 0.8054
05/26 22:36:07 - mmengine - INFO - Iter(train) [ 98600/160000]  base_lr: 4.2232e-05 lr: 4.2232e-06  eta: 7:02:22  time: 0.4130  data_time: 0.0098  memory: 5969  grad_norm: 594.3210  loss: 17.0095  decode.loss_cls: 0.1290  decode.loss_mask: 0.8949  decode.loss_dice: 0.6057  decode.d0.loss_cls: 0.5910  decode.d0.loss_mask: 0.8118  decode.d0.loss_dice: 0.6259  decode.d1.loss_cls: 0.1485  decode.d1.loss_mask: 0.8871  decode.d1.loss_dice: 0.6305  decode.d2.loss_cls: 0.1468  decode.d2.loss_mask: 0.8966  decode.d2.loss_dice: 0.6215  decode.d3.loss_cls: 0.1688  decode.d3.loss_mask: 0.9038  decode.d3.loss_dice: 0.6056  decode.d4.loss_cls: 0.1721  decode.d4.loss_mask: 0.9091  decode.d4.loss_dice: 0.6239  decode.d5.loss_cls: 0.1748  decode.d5.loss_mask: 0.8903  decode.d5.loss_dice: 0.6105  decode.d6.loss_cls: 0.1511  decode.d6.loss_mask: 0.9047  decode.d6.loss_dice: 0.6042  decode.d7.loss_cls: 0.1768  decode.d7.loss_mask: 0.8816  decode.d7.loss_dice: 0.6022  decode.d8.loss_cls: 0.1464  decode.d8.loss_mask: 0.8853  decode.d8.loss_dice: 0.6088
05/26 22:36:27 - mmengine - INFO - Iter(train) [ 98650/160000]  base_lr: 4.2201e-05 lr: 4.2201e-06  eta: 7:02:02  time: 0.4128  data_time: 0.0097  memory: 5970  grad_norm: 495.6030  loss: 17.7719  decode.loss_cls: 0.1037  decode.loss_mask: 1.0060  decode.loss_dice: 0.6126  decode.d0.loss_cls: 0.5953  decode.d0.loss_mask: 0.9695  decode.d0.loss_dice: 0.6238  decode.d1.loss_cls: 0.1040  decode.d1.loss_mask: 1.0277  decode.d1.loss_dice: 0.6070  decode.d2.loss_cls: 0.1033  decode.d2.loss_mask: 1.0057  decode.d2.loss_dice: 0.6121  decode.d3.loss_cls: 0.1116  decode.d3.loss_mask: 1.0046  decode.d3.loss_dice: 0.6305  decode.d4.loss_cls: 0.1069  decode.d4.loss_mask: 1.0222  decode.d4.loss_dice: 0.6255  decode.d5.loss_cls: 0.0977  decode.d5.loss_mask: 1.0236  decode.d5.loss_dice: 0.6134  decode.d6.loss_cls: 0.0844  decode.d6.loss_mask: 1.0273  decode.d6.loss_dice: 0.6114  decode.d7.loss_cls: 0.1063  decode.d7.loss_mask: 1.0074  decode.d7.loss_dice: 0.6064  decode.d8.loss_cls: 0.1229  decode.d8.loss_mask: 0.9948  decode.d8.loss_dice: 0.6039
05/26 22:36:48 - mmengine - INFO - Iter(train) [ 98700/160000]  base_lr: 4.2171e-05 lr: 4.2171e-06  eta: 7:01:41  time: 0.4138  data_time: 0.0109  memory: 5966  grad_norm: 224.5101  loss: 16.2475  decode.loss_cls: 0.1582  decode.loss_mask: 0.7645  decode.loss_dice: 0.6573  decode.d0.loss_cls: 0.5610  decode.d0.loss_mask: 0.7604  decode.d0.loss_dice: 0.6678  decode.d1.loss_cls: 0.1126  decode.d1.loss_mask: 0.7691  decode.d1.loss_dice: 0.6665  decode.d2.loss_cls: 0.1600  decode.d2.loss_mask: 0.7644  decode.d2.loss_dice: 0.6629  decode.d3.loss_cls: 0.1320  decode.d3.loss_mask: 0.7705  decode.d3.loss_dice: 0.6774  decode.d4.loss_cls: 0.1611  decode.d4.loss_mask: 0.7694  decode.d4.loss_dice: 0.6668  decode.d5.loss_cls: 0.1098  decode.d5.loss_mask: 0.7785  decode.d5.loss_dice: 0.6847  decode.d6.loss_cls: 0.1544  decode.d6.loss_mask: 0.7796  decode.d6.loss_dice: 0.6675  decode.d7.loss_cls: 0.1522  decode.d7.loss_mask: 0.7760  decode.d7.loss_dice: 0.6775  decode.d8.loss_cls: 0.1272  decode.d8.loss_mask: 0.7782  decode.d8.loss_dice: 0.6803
05/26 22:37:09 - mmengine - INFO - Iter(train) [ 98750/160000]  base_lr: 4.2140e-05 lr: 4.2140e-06  eta: 7:01:20  time: 0.4141  data_time: 0.0098  memory: 5973  grad_norm: 825.0771  loss: 16.2389  decode.loss_cls: 0.1717  decode.loss_mask: 0.7980  decode.loss_dice: 0.6234  decode.d0.loss_cls: 0.6441  decode.d0.loss_mask: 0.7936  decode.d0.loss_dice: 0.6227  decode.d1.loss_cls: 0.2029  decode.d1.loss_mask: 0.7987  decode.d1.loss_dice: 0.6328  decode.d2.loss_cls: 0.1645  decode.d2.loss_mask: 0.7697  decode.d2.loss_dice: 0.5989  decode.d3.loss_cls: 0.1574  decode.d3.loss_mask: 0.7969  decode.d3.loss_dice: 0.6174  decode.d4.loss_cls: 0.1800  decode.d4.loss_mask: 0.8016  decode.d4.loss_dice: 0.6095  decode.d5.loss_cls: 0.1823  decode.d5.loss_mask: 0.7712  decode.d5.loss_dice: 0.6159  decode.d6.loss_cls: 0.1851  decode.d6.loss_mask: 0.7729  decode.d6.loss_dice: 0.6145  decode.d7.loss_cls: 0.1825  decode.d7.loss_mask: 0.7671  decode.d7.loss_dice: 0.6159  decode.d8.loss_cls: 0.1791  decode.d8.loss_mask: 0.7651  decode.d8.loss_dice: 0.6034
05/26 22:37:29 - mmengine - INFO - Iter(train) [ 98800/160000]  base_lr: 4.2109e-05 lr: 4.2109e-06  eta: 7:01:00  time: 0.4145  data_time: 0.0097  memory: 5967  grad_norm: 589.3200  loss: 21.4378  decode.loss_cls: 0.3327  decode.loss_mask: 1.0046  decode.loss_dice: 0.7485  decode.d0.loss_cls: 0.7486  decode.d0.loss_mask: 1.0020  decode.d0.loss_dice: 0.7594  decode.d1.loss_cls: 0.3104  decode.d1.loss_mask: 1.0518  decode.d1.loss_dice: 0.7869  decode.d2.loss_cls: 0.3562  decode.d2.loss_mask: 0.9903  decode.d2.loss_dice: 0.7538  decode.d3.loss_cls: 0.3187  decode.d3.loss_mask: 0.9966  decode.d3.loss_dice: 0.7504  decode.d4.loss_cls: 0.3291  decode.d4.loss_mask: 0.9979  decode.d4.loss_dice: 0.7723  decode.d5.loss_cls: 0.3308  decode.d5.loss_mask: 1.0095  decode.d5.loss_dice: 0.7861  decode.d6.loss_cls: 0.3103  decode.d6.loss_mask: 1.0074  decode.d6.loss_dice: 0.7895  decode.d7.loss_cls: 0.2998  decode.d7.loss_mask: 1.0295  decode.d7.loss_dice: 0.7662  decode.d8.loss_cls: 0.3363  decode.d8.loss_mask: 0.9999  decode.d8.loss_dice: 0.7623
05/26 22:37:50 - mmengine - INFO - Iter(train) [ 98850/160000]  base_lr: 4.2078e-05 lr: 4.2078e-06  eta: 7:00:39  time: 0.4144  data_time: 0.0107  memory: 5968  grad_norm: 855.4294  loss: 22.4503  decode.loss_cls: 0.1850  decode.loss_mask: 1.1731  decode.loss_dice: 0.8068  decode.d0.loss_cls: 0.6909  decode.d0.loss_mask: 1.0997  decode.d0.loss_dice: 0.8421  decode.d1.loss_cls: 0.1927  decode.d1.loss_mask: 1.2112  decode.d1.loss_dice: 0.8160  decode.d2.loss_cls: 0.1996  decode.d2.loss_mask: 1.1897  decode.d2.loss_dice: 0.8026  decode.d3.loss_cls: 0.1940  decode.d3.loss_mask: 1.1833  decode.d3.loss_dice: 0.8133  decode.d4.loss_cls: 0.2190  decode.d4.loss_mask: 1.1770  decode.d4.loss_dice: 0.8184  decode.d5.loss_cls: 0.2142  decode.d5.loss_mask: 1.1725  decode.d5.loss_dice: 0.7887  decode.d6.loss_cls: 0.1947  decode.d6.loss_mask: 1.1722  decode.d6.loss_dice: 0.8063  decode.d7.loss_cls: 0.1783  decode.d7.loss_mask: 1.2569  decode.d7.loss_dice: 0.8509  decode.d8.loss_cls: 0.2092  decode.d8.loss_mask: 1.1764  decode.d8.loss_dice: 0.8159
05/26 22:38:11 - mmengine - INFO - Iter(train) [ 98900/160000]  base_lr: 4.2047e-05 lr: 4.2047e-06  eta: 7:00:19  time: 0.4123  data_time: 0.0097  memory: 5967  grad_norm: 570.6202  loss: 19.1120  decode.loss_cls: 0.1141  decode.loss_mask: 1.0654  decode.loss_dice: 0.6783  decode.d0.loss_cls: 0.6109  decode.d0.loss_mask: 0.9896  decode.d0.loss_dice: 0.6874  decode.d1.loss_cls: 0.1085  decode.d1.loss_mask: 1.0463  decode.d1.loss_dice: 0.7019  decode.d2.loss_cls: 0.0975  decode.d2.loss_mask: 1.0842  decode.d2.loss_dice: 0.6961  decode.d3.loss_cls: 0.0983  decode.d3.loss_mask: 1.0873  decode.d3.loss_dice: 0.6843  decode.d4.loss_cls: 0.0995  decode.d4.loss_mask: 1.0884  decode.d4.loss_dice: 0.7018  decode.d5.loss_cls: 0.1301  decode.d5.loss_mask: 1.0392  decode.d5.loss_dice: 0.6888  decode.d6.loss_cls: 0.1316  decode.d6.loss_mask: 1.0585  decode.d6.loss_dice: 0.6682  decode.d7.loss_cls: 0.1177  decode.d7.loss_mask: 1.0743  decode.d7.loss_dice: 0.6916  decode.d8.loss_cls: 0.1370  decode.d8.loss_mask: 1.0453  decode.d8.loss_dice: 0.6899
05/26 22:38:31 - mmengine - INFO - Iter(train) [ 98950/160000]  base_lr: 4.2016e-05 lr: 4.2016e-06  eta: 6:59:58  time: 0.4139  data_time: 0.0097  memory: 5979  grad_norm: 844.9025  loss: 20.8322  decode.loss_cls: 0.1752  decode.loss_mask: 1.0515  decode.loss_dice: 0.7747  decode.d0.loss_cls: 0.7945  decode.d0.loss_mask: 1.0183  decode.d0.loss_dice: 0.7265  decode.d1.loss_cls: 0.1597  decode.d1.loss_mask: 1.0881  decode.d1.loss_dice: 0.8034  decode.d2.loss_cls: 0.1655  decode.d2.loss_mask: 1.0691  decode.d2.loss_dice: 0.7716  decode.d3.loss_cls: 0.1381  decode.d3.loss_mask: 1.0663  decode.d3.loss_dice: 0.7784  decode.d4.loss_cls: 0.2042  decode.d4.loss_mask: 1.0794  decode.d4.loss_dice: 0.7778  decode.d5.loss_cls: 0.1835  decode.d5.loss_mask: 1.0752  decode.d5.loss_dice: 0.7800  decode.d6.loss_cls: 0.1832  decode.d6.loss_mask: 1.0935  decode.d6.loss_dice: 0.8177  decode.d7.loss_cls: 0.1668  decode.d7.loss_mask: 1.0856  decode.d7.loss_dice: 0.7987  decode.d8.loss_cls: 0.1749  decode.d8.loss_mask: 1.0464  decode.d8.loss_dice: 0.7845
05/26 22:38:53 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 22:38:53 - mmengine - INFO - Iter(train) [ 99000/160000]  base_lr: 4.1985e-05 lr: 4.1985e-06  eta: 6:59:38  time: 0.4900  data_time: 0.0099  memory: 5975  grad_norm: 615.0012  loss: 21.6320  decode.loss_cls: 0.2299  decode.loss_mask: 1.1061  decode.loss_dice: 0.8125  decode.d0.loss_cls: 0.7067  decode.d0.loss_mask: 1.0535  decode.d0.loss_dice: 0.7384  decode.d1.loss_cls: 0.3123  decode.d1.loss_mask: 1.0667  decode.d1.loss_dice: 0.7569  decode.d2.loss_cls: 0.2677  decode.d2.loss_mask: 1.0786  decode.d2.loss_dice: 0.7653  decode.d3.loss_cls: 0.2585  decode.d3.loss_mask: 1.0898  decode.d3.loss_dice: 0.7898  decode.d4.loss_cls: 0.2694  decode.d4.loss_mask: 1.0617  decode.d4.loss_dice: 0.7542  decode.d5.loss_cls: 0.2814  decode.d5.loss_mask: 1.0829  decode.d5.loss_dice: 0.8081  decode.d6.loss_cls: 0.2608  decode.d6.loss_mask: 1.0559  decode.d6.loss_dice: 0.7640  decode.d7.loss_cls: 0.2849  decode.d7.loss_mask: 1.1083  decode.d7.loss_dice: 0.7710  decode.d8.loss_cls: 0.2234  decode.d8.loss_mask: 1.0989  decode.d8.loss_dice: 0.7743
05/26 22:39:16 - mmengine - INFO - Iter(train) [ 99050/160000]  base_lr: 4.1954e-05 lr: 4.1954e-06  eta: 6:59:19  time: 0.4137  data_time: 0.0097  memory: 5966  grad_norm: 610.0528  loss: 22.7979  decode.loss_cls: 0.3240  decode.loss_mask: 1.1046  decode.loss_dice: 0.7851  decode.d0.loss_cls: 0.8840  decode.d0.loss_mask: 1.1076  decode.d0.loss_dice: 0.7510  decode.d1.loss_cls: 0.3682  decode.d1.loss_mask: 1.1119  decode.d1.loss_dice: 0.7939  decode.d2.loss_cls: 0.3430  decode.d2.loss_mask: 1.0963  decode.d2.loss_dice: 0.7895  decode.d3.loss_cls: 0.3749  decode.d3.loss_mask: 1.1006  decode.d3.loss_dice: 0.7810  decode.d4.loss_cls: 0.3767  decode.d4.loss_mask: 1.0863  decode.d4.loss_dice: 0.7561  decode.d5.loss_cls: 0.3614  decode.d5.loss_mask: 1.0660  decode.d5.loss_dice: 0.7774  decode.d6.loss_cls: 0.3858  decode.d6.loss_mask: 1.0759  decode.d6.loss_dice: 0.7463  decode.d7.loss_cls: 0.3533  decode.d7.loss_mask: 1.0930  decode.d7.loss_dice: 0.7903  decode.d8.loss_cls: 0.3585  decode.d8.loss_mask: 1.0791  decode.d8.loss_dice: 0.7762
05/26 22:39:36 - mmengine - INFO - Iter(train) [ 99100/160000]  base_lr: 4.1923e-05 lr: 4.1923e-06  eta: 6:58:58  time: 0.4131  data_time: 0.0097  memory: 5975  grad_norm: 372.2145  loss: 20.7862  decode.loss_cls: 0.2808  decode.loss_mask: 1.0395  decode.loss_dice: 0.7780  decode.d0.loss_cls: 0.7194  decode.d0.loss_mask: 1.0173  decode.d0.loss_dice: 0.7357  decode.d1.loss_cls: 0.2225  decode.d1.loss_mask: 1.0209  decode.d1.loss_dice: 0.7283  decode.d2.loss_cls: 0.2725  decode.d2.loss_mask: 1.0065  decode.d2.loss_dice: 0.7309  decode.d3.loss_cls: 0.2662  decode.d3.loss_mask: 1.0271  decode.d3.loss_dice: 0.7301  decode.d4.loss_cls: 0.2524  decode.d4.loss_mask: 1.0266  decode.d4.loss_dice: 0.7273  decode.d5.loss_cls: 0.3038  decode.d5.loss_mask: 1.0077  decode.d5.loss_dice: 0.7658  decode.d6.loss_cls: 0.2796  decode.d6.loss_mask: 1.0143  decode.d6.loss_dice: 0.7867  decode.d7.loss_cls: 0.2509  decode.d7.loss_mask: 1.0294  decode.d7.loss_dice: 0.7660  decode.d8.loss_cls: 0.2597  decode.d8.loss_mask: 0.9987  decode.d8.loss_dice: 0.7416
05/26 22:39:57 - mmengine - INFO - Iter(train) [ 99150/160000]  base_lr: 4.1892e-05 lr: 4.1892e-06  eta: 6:58:37  time: 0.4139  data_time: 0.0098  memory: 5969  grad_norm: 324.3369  loss: 20.1735  decode.loss_cls: 0.2838  decode.loss_mask: 0.9760  decode.loss_dice: 0.7282  decode.d0.loss_cls: 0.6291  decode.d0.loss_mask: 0.9362  decode.d0.loss_dice: 0.7189  decode.d1.loss_cls: 0.2375  decode.d1.loss_mask: 1.0095  decode.d1.loss_dice: 0.7394  decode.d2.loss_cls: 0.2473  decode.d2.loss_mask: 0.9961  decode.d2.loss_dice: 0.7453  decode.d3.loss_cls: 0.2450  decode.d3.loss_mask: 0.9946  decode.d3.loss_dice: 0.7392  decode.d4.loss_cls: 0.2361  decode.d4.loss_mask: 1.0176  decode.d4.loss_dice: 0.7440  decode.d5.loss_cls: 0.2353  decode.d5.loss_mask: 0.9974  decode.d5.loss_dice: 0.7587  decode.d6.loss_cls: 0.2297  decode.d6.loss_mask: 0.9810  decode.d6.loss_dice: 0.7437  decode.d7.loss_cls: 0.2432  decode.d7.loss_mask: 1.0111  decode.d7.loss_dice: 0.7553  decode.d8.loss_cls: 0.2509  decode.d8.loss_mask: 1.0006  decode.d8.loss_dice: 0.7430
05/26 22:40:18 - mmengine - INFO - Iter(train) [ 99200/160000]  base_lr: 4.1861e-05 lr: 4.1861e-06  eta: 6:58:17  time: 0.4148  data_time: 0.0097  memory: 5969  grad_norm: 758.8533  loss: 21.8013  decode.loss_cls: 0.2718  decode.loss_mask: 1.1268  decode.loss_dice: 0.8034  decode.d0.loss_cls: 0.7143  decode.d0.loss_mask: 1.0697  decode.d0.loss_dice: 0.7412  decode.d1.loss_cls: 0.3088  decode.d1.loss_mask: 1.0840  decode.d1.loss_dice: 0.7530  decode.d2.loss_cls: 0.2375  decode.d2.loss_mask: 1.1086  decode.d2.loss_dice: 0.7856  decode.d3.loss_cls: 0.2376  decode.d3.loss_mask: 1.0966  decode.d3.loss_dice: 0.7888  decode.d4.loss_cls: 0.2265  decode.d4.loss_mask: 1.1270  decode.d4.loss_dice: 0.8022  decode.d5.loss_cls: 0.2334  decode.d5.loss_mask: 1.0961  decode.d5.loss_dice: 0.7826  decode.d6.loss_cls: 0.2353  decode.d6.loss_mask: 1.1035  decode.d6.loss_dice: 0.7805  decode.d7.loss_cls: 0.2373  decode.d7.loss_mask: 1.1108  decode.d7.loss_dice: 0.8139  decode.d8.loss_cls: 0.2359  decode.d8.loss_mask: 1.0986  decode.d8.loss_dice: 0.7898
05/26 22:40:39 - mmengine - INFO - Iter(train) [ 99250/160000]  base_lr: 4.1830e-05 lr: 4.1830e-06  eta: 6:57:56  time: 0.4143  data_time: 0.0098  memory: 5978  grad_norm: 529.5338  loss: 21.8325  decode.loss_cls: 0.3429  decode.loss_mask: 0.9902  decode.loss_dice: 0.7775  decode.d0.loss_cls: 0.7869  decode.d0.loss_mask: 0.9845  decode.d0.loss_dice: 0.7768  decode.d1.loss_cls: 0.3711  decode.d1.loss_mask: 1.0093  decode.d1.loss_dice: 0.7776  decode.d2.loss_cls: 0.3547  decode.d2.loss_mask: 1.0068  decode.d2.loss_dice: 0.7853  decode.d3.loss_cls: 0.3480  decode.d3.loss_mask: 1.0097  decode.d3.loss_dice: 0.7708  decode.d4.loss_cls: 0.3532  decode.d4.loss_mask: 1.0201  decode.d4.loss_dice: 0.7608  decode.d5.loss_cls: 0.3624  decode.d5.loss_mask: 0.9989  decode.d5.loss_dice: 0.7818  decode.d6.loss_cls: 0.3684  decode.d6.loss_mask: 0.9945  decode.d6.loss_dice: 0.7652  decode.d7.loss_cls: 0.3341  decode.d7.loss_mask: 1.0379  decode.d7.loss_dice: 0.7899  decode.d8.loss_cls: 0.3514  decode.d8.loss_mask: 1.0071  decode.d8.loss_dice: 0.8147
05/26 22:40:59 - mmengine - INFO - Iter(train) [ 99300/160000]  base_lr: 4.1799e-05 lr: 4.1799e-06  eta: 6:57:36  time: 0.4130  data_time: 0.0098  memory: 5982  grad_norm: 851.8860  loss: 20.3512  decode.loss_cls: 0.1258  decode.loss_mask: 1.0924  decode.loss_dice: 0.7502  decode.d0.loss_cls: 0.6130  decode.d0.loss_mask: 1.0454  decode.d0.loss_dice: 0.7509  decode.d1.loss_cls: 0.1069  decode.d1.loss_mask: 1.1295  decode.d1.loss_dice: 0.7807  decode.d2.loss_cls: 0.1203  decode.d2.loss_mask: 1.0963  decode.d2.loss_dice: 0.7587  decode.d3.loss_cls: 0.1130  decode.d3.loss_mask: 1.0975  decode.d3.loss_dice: 0.7574  decode.d4.loss_cls: 0.1053  decode.d4.loss_mask: 1.1206  decode.d4.loss_dice: 0.7778  decode.d5.loss_cls: 0.1177  decode.d5.loss_mask: 1.1210  decode.d5.loss_dice: 0.7754  decode.d6.loss_cls: 0.1369  decode.d6.loss_mask: 1.0870  decode.d6.loss_dice: 0.7671  decode.d7.loss_cls: 0.1243  decode.d7.loss_mask: 1.0920  decode.d7.loss_dice: 0.7843  decode.d8.loss_cls: 0.1518  decode.d8.loss_mask: 1.0905  decode.d8.loss_dice: 0.7615
05/26 22:41:20 - mmengine - INFO - Iter(train) [ 99350/160000]  base_lr: 4.1768e-05 lr: 4.1768e-06  eta: 6:57:15  time: 0.4130  data_time: 0.0098  memory: 5975  grad_norm: 912.0581  loss: 23.0639  decode.loss_cls: 0.3755  decode.loss_mask: 1.0932  decode.loss_dice: 0.7506  decode.d0.loss_cls: 0.8628  decode.d0.loss_mask: 1.0464  decode.d0.loss_dice: 0.7451  decode.d1.loss_cls: 0.3302  decode.d1.loss_mask: 1.2280  decode.d1.loss_dice: 0.7912  decode.d2.loss_cls: 0.3032  decode.d2.loss_mask: 1.1937  decode.d2.loss_dice: 0.8240  decode.d3.loss_cls: 0.3227  decode.d3.loss_mask: 1.1211  decode.d3.loss_dice: 0.7536  decode.d4.loss_cls: 0.3759  decode.d4.loss_mask: 1.1495  decode.d4.loss_dice: 0.7921  decode.d5.loss_cls: 0.2834  decode.d5.loss_mask: 1.1549  decode.d5.loss_dice: 0.7881  decode.d6.loss_cls: 0.3330  decode.d6.loss_mask: 1.1324  decode.d6.loss_dice: 0.7822  decode.d7.loss_cls: 0.3129  decode.d7.loss_mask: 1.1859  decode.d7.loss_dice: 0.7796  decode.d8.loss_cls: 0.3748  decode.d8.loss_mask: 1.1229  decode.d8.loss_dice: 0.7553
05/26 22:41:41 - mmengine - INFO - Iter(train) [ 99400/160000]  base_lr: 4.1737e-05 lr: 4.1737e-06  eta: 6:56:54  time: 0.4202  data_time: 0.0100  memory: 5976  grad_norm: 335.3184  loss: 15.0955  decode.loss_cls: 0.1287  decode.loss_mask: 0.7696  decode.loss_dice: 0.5427  decode.d0.loss_cls: 0.5882  decode.d0.loss_mask: 0.7405  decode.d0.loss_dice: 0.5375  decode.d1.loss_cls: 0.1835  decode.d1.loss_mask: 0.7762  decode.d1.loss_dice: 0.5310  decode.d2.loss_cls: 0.1349  decode.d2.loss_mask: 0.8087  decode.d2.loss_dice: 0.5391  decode.d3.loss_cls: 0.1399  decode.d3.loss_mask: 0.8028  decode.d3.loss_dice: 0.5489  decode.d4.loss_cls: 0.1706  decode.d4.loss_mask: 0.7767  decode.d4.loss_dice: 0.5359  decode.d5.loss_cls: 0.1515  decode.d5.loss_mask: 0.7870  decode.d5.loss_dice: 0.5295  decode.d6.loss_cls: 0.1268  decode.d6.loss_mask: 0.7919  decode.d6.loss_dice: 0.5350  decode.d7.loss_cls: 0.1628  decode.d7.loss_mask: 0.7645  decode.d7.loss_dice: 0.5509  decode.d8.loss_cls: 0.1346  decode.d8.loss_mask: 0.7688  decode.d8.loss_dice: 0.5369
05/26 22:42:02 - mmengine - INFO - Iter(train) [ 99450/160000]  base_lr: 4.1706e-05 lr: 4.1706e-06  eta: 6:56:34  time: 0.4201  data_time: 0.0100  memory: 5966  grad_norm: 1209.9800  loss: 21.1756  decode.loss_cls: 0.1442  decode.loss_mask: 1.1369  decode.loss_dice: 0.8149  decode.d0.loss_cls: 0.5888  decode.d0.loss_mask: 1.1439  decode.d0.loss_dice: 0.7645  decode.d1.loss_cls: 0.1560  decode.d1.loss_mask: 1.1375  decode.d1.loss_dice: 0.7842  decode.d2.loss_cls: 0.1697  decode.d2.loss_mask: 1.0970  decode.d2.loss_dice: 0.7667  decode.d3.loss_cls: 0.1332  decode.d3.loss_mask: 1.1235  decode.d3.loss_dice: 0.7792  decode.d4.loss_cls: 0.1337  decode.d4.loss_mask: 1.1453  decode.d4.loss_dice: 0.8068  decode.d5.loss_cls: 0.1475  decode.d5.loss_mask: 1.1273  decode.d5.loss_dice: 0.7875  decode.d6.loss_cls: 0.1606  decode.d6.loss_mask: 1.1354  decode.d6.loss_dice: 0.8083  decode.d7.loss_cls: 0.1358  decode.d7.loss_mask: 1.1274  decode.d7.loss_dice: 0.8120  decode.d8.loss_cls: 0.1697  decode.d8.loss_mask: 1.1262  decode.d8.loss_dice: 0.8120
05/26 22:42:23 - mmengine - INFO - Iter(train) [ 99500/160000]  base_lr: 4.1675e-05 lr: 4.1675e-06  eta: 6:56:14  time: 0.4201  data_time: 0.0099  memory: 5966  grad_norm: 567.6521  loss: 21.4401  decode.loss_cls: 0.2416  decode.loss_mask: 1.0917  decode.loss_dice: 0.7771  decode.d0.loss_cls: 0.7679  decode.d0.loss_mask: 1.0059  decode.d0.loss_dice: 0.7392  decode.d1.loss_cls: 0.2326  decode.d1.loss_mask: 1.0881  decode.d1.loss_dice: 0.7936  decode.d2.loss_cls: 0.2353  decode.d2.loss_mask: 1.0903  decode.d2.loss_dice: 0.7560  decode.d3.loss_cls: 0.2255  decode.d3.loss_mask: 1.1049  decode.d3.loss_dice: 0.7856  decode.d4.loss_cls: 0.1973  decode.d4.loss_mask: 1.1050  decode.d4.loss_dice: 0.7786  decode.d5.loss_cls: 0.2181  decode.d5.loss_mask: 1.1024  decode.d5.loss_dice: 0.7908  decode.d6.loss_cls: 0.2286  decode.d6.loss_mask: 1.0997  decode.d6.loss_dice: 0.7934  decode.d7.loss_cls: 0.2398  decode.d7.loss_mask: 1.0827  decode.d7.loss_dice: 0.7770  decode.d8.loss_cls: 0.2350  decode.d8.loss_mask: 1.0767  decode.d8.loss_dice: 0.7798
05/26 22:42:44 - mmengine - INFO - Iter(train) [ 99550/160000]  base_lr: 4.1644e-05 lr: 4.1644e-06  eta: 6:55:53  time: 0.4170  data_time: 0.0100  memory: 5969  grad_norm: 435.8034  loss: 17.9482  decode.loss_cls: 0.1258  decode.loss_mask: 0.9516  decode.loss_dice: 0.6484  decode.d0.loss_cls: 0.5960  decode.d0.loss_mask: 0.9275  decode.d0.loss_dice: 0.6543  decode.d1.loss_cls: 0.1287  decode.d1.loss_mask: 0.9652  decode.d1.loss_dice: 0.6735  decode.d2.loss_cls: 0.1242  decode.d2.loss_mask: 0.9592  decode.d2.loss_dice: 0.6739  decode.d3.loss_cls: 0.1209  decode.d3.loss_mask: 0.9628  decode.d3.loss_dice: 0.6668  decode.d4.loss_cls: 0.1346  decode.d4.loss_mask: 0.9597  decode.d4.loss_dice: 0.6639  decode.d5.loss_cls: 0.1295  decode.d5.loss_mask: 0.9618  decode.d5.loss_dice: 0.6733  decode.d6.loss_cls: 0.1191  decode.d6.loss_mask: 0.9648  decode.d6.loss_dice: 0.6719  decode.d7.loss_cls: 0.1358  decode.d7.loss_mask: 0.9480  decode.d7.loss_dice: 0.6652  decode.d8.loss_cls: 0.1329  decode.d8.loss_mask: 0.9514  decode.d8.loss_dice: 0.6574
05/26 22:43:05 - mmengine - INFO - Iter(train) [ 99600/160000]  base_lr: 4.1613e-05 lr: 4.1613e-06  eta: 6:55:33  time: 0.4183  data_time: 0.0099  memory: 5980  grad_norm: 513.9895  loss: 25.3000  decode.loss_cls: 0.3606  decode.loss_mask: 1.1757  decode.loss_dice: 0.9387  decode.d0.loss_cls: 0.9679  decode.d0.loss_mask: 1.1268  decode.d0.loss_dice: 0.8579  decode.d1.loss_cls: 0.4044  decode.d1.loss_mask: 1.1449  decode.d1.loss_dice: 0.9087  decode.d2.loss_cls: 0.3755  decode.d2.loss_mask: 1.1711  decode.d2.loss_dice: 0.8926  decode.d3.loss_cls: 0.4000  decode.d3.loss_mask: 1.1543  decode.d3.loss_dice: 0.9169  decode.d4.loss_cls: 0.4160  decode.d4.loss_mask: 1.1520  decode.d4.loss_dice: 0.9028  decode.d5.loss_cls: 0.3791  decode.d5.loss_mask: 1.1824  decode.d5.loss_dice: 0.9444  decode.d6.loss_cls: 0.3627  decode.d6.loss_mask: 1.1738  decode.d6.loss_dice: 0.9438  decode.d7.loss_cls: 0.3694  decode.d7.loss_mask: 1.1880  decode.d7.loss_dice: 0.9567  decode.d8.loss_cls: 0.3687  decode.d8.loss_mask: 1.1924  decode.d8.loss_dice: 0.9719
05/26 22:43:26 - mmengine - INFO - Iter(train) [ 99650/160000]  base_lr: 4.1582e-05 lr: 4.1582e-06  eta: 6:55:12  time: 0.4189  data_time: 0.0100  memory: 5969  grad_norm: 532.1195  loss: 16.5598  decode.loss_cls: 0.1320  decode.loss_mask: 0.8437  decode.loss_dice: 0.6096  decode.d0.loss_cls: 0.5604  decode.d0.loss_mask: 0.8612  decode.d0.loss_dice: 0.6418  decode.d1.loss_cls: 0.1252  decode.d1.loss_mask: 0.8537  decode.d1.loss_dice: 0.6054  decode.d2.loss_cls: 0.1338  decode.d2.loss_mask: 0.8545  decode.d2.loss_dice: 0.6168  decode.d3.loss_cls: 0.1316  decode.d3.loss_mask: 0.8588  decode.d3.loss_dice: 0.6288  decode.d4.loss_cls: 0.1070  decode.d4.loss_mask: 0.8611  decode.d4.loss_dice: 0.6435  decode.d5.loss_cls: 0.1490  decode.d5.loss_mask: 0.8558  decode.d5.loss_dice: 0.6198  decode.d6.loss_cls: 0.1506  decode.d6.loss_mask: 0.8260  decode.d6.loss_dice: 0.6429  decode.d7.loss_cls: 0.1591  decode.d7.loss_mask: 0.8606  decode.d7.loss_dice: 0.6207  decode.d8.loss_cls: 0.1408  decode.d8.loss_mask: 0.8357  decode.d8.loss_dice: 0.6297
05/26 22:43:47 - mmengine - INFO - Iter(train) [ 99700/160000]  base_lr: 4.1551e-05 lr: 4.1551e-06  eta: 6:54:52  time: 0.4180  data_time: 0.0099  memory: 5972  grad_norm: 574.5325  loss: 18.2605  decode.loss_cls: 0.1524  decode.loss_mask: 0.9272  decode.loss_dice: 0.7048  decode.d0.loss_cls: 0.6285  decode.d0.loss_mask: 0.9088  decode.d0.loss_dice: 0.6951  decode.d1.loss_cls: 0.1491  decode.d1.loss_mask: 0.9284  decode.d1.loss_dice: 0.6802  decode.d2.loss_cls: 0.1703  decode.d2.loss_mask: 0.9225  decode.d2.loss_dice: 0.6730  decode.d3.loss_cls: 0.1608  decode.d3.loss_mask: 0.9277  decode.d3.loss_dice: 0.6926  decode.d4.loss_cls: 0.1341  decode.d4.loss_mask: 0.9279  decode.d4.loss_dice: 0.6835  decode.d5.loss_cls: 0.2195  decode.d5.loss_mask: 0.9569  decode.d5.loss_dice: 0.7222  decode.d6.loss_cls: 0.1894  decode.d6.loss_mask: 0.9375  decode.d6.loss_dice: 0.6921  decode.d7.loss_cls: 0.1279  decode.d7.loss_mask: 0.9029  decode.d7.loss_dice: 0.6812  decode.d8.loss_cls: 0.1477  decode.d8.loss_mask: 0.9380  decode.d8.loss_dice: 0.6782
05/26 22:44:08 - mmengine - INFO - Iter(train) [ 99750/160000]  base_lr: 4.1520e-05 lr: 4.1520e-06  eta: 6:54:31  time: 0.4186  data_time: 0.0099  memory: 5967  grad_norm: 594.3528  loss: 17.6971  decode.loss_cls: 0.1052  decode.loss_mask: 0.9754  decode.loss_dice: 0.6108  decode.d0.loss_cls: 0.7108  decode.d0.loss_mask: 0.8681  decode.d0.loss_dice: 0.6040  decode.d1.loss_cls: 0.1227  decode.d1.loss_mask: 1.0250  decode.d1.loss_dice: 0.6258  decode.d2.loss_cls: 0.0847  decode.d2.loss_mask: 1.0073  decode.d2.loss_dice: 0.6351  decode.d3.loss_cls: 0.1118  decode.d3.loss_mask: 0.9506  decode.d3.loss_dice: 0.6041  decode.d4.loss_cls: 0.1265  decode.d4.loss_mask: 1.0118  decode.d4.loss_dice: 0.6218  decode.d5.loss_cls: 0.0941  decode.d5.loss_mask: 0.9936  decode.d5.loss_dice: 0.6308  decode.d6.loss_cls: 0.1478  decode.d6.loss_mask: 0.9479  decode.d6.loss_dice: 0.6390  decode.d7.loss_cls: 0.1419  decode.d7.loss_mask: 0.9427  decode.d7.loss_dice: 0.6469  decode.d8.loss_cls: 0.1464  decode.d8.loss_mask: 0.9360  decode.d8.loss_dice: 0.6284
05/26 22:44:29 - mmengine - INFO - Iter(train) [ 99800/160000]  base_lr: 4.1489e-05 lr: 4.1489e-06  eta: 6:54:11  time: 0.4188  data_time: 0.0099  memory: 5967  grad_norm: 336.7207  loss: 20.9267  decode.loss_cls: 0.1852  decode.loss_mask: 1.0625  decode.loss_dice: 0.8101  decode.d0.loss_cls: 0.6701  decode.d0.loss_mask: 1.0412  decode.d0.loss_dice: 0.7867  decode.d1.loss_cls: 0.1806  decode.d1.loss_mask: 1.0533  decode.d1.loss_dice: 0.7726  decode.d2.loss_cls: 0.1641  decode.d2.loss_mask: 1.0680  decode.d2.loss_dice: 0.8182  decode.d3.loss_cls: 0.1698  decode.d3.loss_mask: 1.0623  decode.d3.loss_dice: 0.8133  decode.d4.loss_cls: 0.1897  decode.d4.loss_mask: 1.0703  decode.d4.loss_dice: 0.8109  decode.d5.loss_cls: 0.1684  decode.d5.loss_mask: 1.0717  decode.d5.loss_dice: 0.8020  decode.d6.loss_cls: 0.1842  decode.d6.loss_mask: 1.0667  decode.d6.loss_dice: 0.7875  decode.d7.loss_cls: 0.1752  decode.d7.loss_mask: 1.0658  decode.d7.loss_dice: 0.8206  decode.d8.loss_cls: 0.1799  decode.d8.loss_mask: 1.0653  decode.d8.loss_dice: 0.8107
05/26 22:44:50 - mmengine - INFO - Iter(train) [ 99850/160000]  base_lr: 4.1458e-05 lr: 4.1458e-06  eta: 6:53:51  time: 0.4193  data_time: 0.0099  memory: 5968  grad_norm: 613.5085  loss: 24.3251  decode.loss_cls: 0.2962  decode.loss_mask: 1.1925  decode.loss_dice: 0.8887  decode.d0.loss_cls: 0.8874  decode.d0.loss_mask: 1.1389  decode.d0.loss_dice: 0.8538  decode.d1.loss_cls: 0.3135  decode.d1.loss_mask: 1.2048  decode.d1.loss_dice: 0.8956  decode.d2.loss_cls: 0.3423  decode.d2.loss_mask: 1.1716  decode.d2.loss_dice: 0.8792  decode.d3.loss_cls: 0.2915  decode.d3.loss_mask: 1.1813  decode.d3.loss_dice: 0.8825  decode.d4.loss_cls: 0.2702  decode.d4.loss_mask: 1.1918  decode.d4.loss_dice: 0.8783  decode.d5.loss_cls: 0.2823  decode.d5.loss_mask: 1.2236  decode.d5.loss_dice: 0.8919  decode.d6.loss_cls: 0.3198  decode.d6.loss_mask: 1.1904  decode.d6.loss_dice: 0.8841  decode.d7.loss_cls: 0.3136  decode.d7.loss_mask: 1.1718  decode.d7.loss_dice: 0.8803  decode.d8.loss_cls: 0.2845  decode.d8.loss_mask: 1.2173  decode.d8.loss_dice: 0.9055
05/26 22:45:11 - mmengine - INFO - Iter(train) [ 99900/160000]  base_lr: 4.1427e-05 lr: 4.1427e-06  eta: 6:53:30  time: 0.4183  data_time: 0.0100  memory: 5976  grad_norm: 1007.5879  loss: 17.4214  decode.loss_cls: 0.1442  decode.loss_mask: 0.8612  decode.loss_dice: 0.6762  decode.d0.loss_cls: 0.6582  decode.d0.loss_mask: 0.8519  decode.d0.loss_dice: 0.6628  decode.d1.loss_cls: 0.1299  decode.d1.loss_mask: 0.9107  decode.d1.loss_dice: 0.6916  decode.d2.loss_cls: 0.1142  decode.d2.loss_mask: 0.8987  decode.d2.loss_dice: 0.6673  decode.d3.loss_cls: 0.1248  decode.d3.loss_mask: 0.8918  decode.d3.loss_dice: 0.6711  decode.d4.loss_cls: 0.1335  decode.d4.loss_mask: 0.8882  decode.d4.loss_dice: 0.6753  decode.d5.loss_cls: 0.1710  decode.d5.loss_mask: 0.8511  decode.d5.loss_dice: 0.6641  decode.d6.loss_cls: 0.1144  decode.d6.loss_mask: 0.9056  decode.d6.loss_dice: 0.6935  decode.d7.loss_cls: 0.1396  decode.d7.loss_mask: 0.8633  decode.d7.loss_dice: 0.6900  decode.d8.loss_cls: 0.1298  decode.d8.loss_mask: 0.8808  decode.d8.loss_dice: 0.6665
05/26 22:45:32 - mmengine - INFO - Iter(train) [ 99950/160000]  base_lr: 4.1396e-05 lr: 4.1396e-06  eta: 6:53:10  time: 0.4188  data_time: 0.0100  memory: 5968  grad_norm: 1209.9165  loss: 18.0096  decode.loss_cls: 0.1449  decode.loss_mask: 0.9476  decode.loss_dice: 0.6778  decode.d0.loss_cls: 0.6326  decode.d0.loss_mask: 0.9072  decode.d0.loss_dice: 0.6452  decode.d1.loss_cls: 0.1526  decode.d1.loss_mask: 0.9378  decode.d1.loss_dice: 0.6588  decode.d2.loss_cls: 0.1208  decode.d2.loss_mask: 0.9388  decode.d2.loss_dice: 0.6711  decode.d3.loss_cls: 0.1440  decode.d3.loss_mask: 0.9520  decode.d3.loss_dice: 0.6591  decode.d4.loss_cls: 0.1519  decode.d4.loss_mask: 0.9445  decode.d4.loss_dice: 0.6587  decode.d5.loss_cls: 0.1481  decode.d5.loss_mask: 0.9472  decode.d5.loss_dice: 0.6725  decode.d6.loss_cls: 0.1582  decode.d6.loss_mask: 0.9421  decode.d6.loss_dice: 0.6681  decode.d7.loss_cls: 0.1407  decode.d7.loss_mask: 0.9392  decode.d7.loss_dice: 0.6792  decode.d8.loss_cls: 0.1564  decode.d8.loss_mask: 0.9417  decode.d8.loss_dice: 0.6707
05/26 22:45:52 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 22:45:52 - mmengine - INFO - Iter(train) [100000/160000]  base_lr: 4.1365e-05 lr: 4.1365e-06  eta: 6:52:49  time: 0.4174  data_time: 0.0101  memory: 5974  grad_norm: 559.2688  loss: 24.0191  decode.loss_cls: 0.2622  decode.loss_mask: 1.2267  decode.loss_dice: 0.8343  decode.d0.loss_cls: 0.9350  decode.d0.loss_mask: 1.1204  decode.d0.loss_dice: 0.8304  decode.d1.loss_cls: 0.2795  decode.d1.loss_mask: 1.2733  decode.d1.loss_dice: 0.8549  decode.d2.loss_cls: 0.2873  decode.d2.loss_mask: 1.2273  decode.d2.loss_dice: 0.8463  decode.d3.loss_cls: 0.2802  decode.d3.loss_mask: 1.2043  decode.d3.loss_dice: 0.8192  decode.d4.loss_cls: 0.2787  decode.d4.loss_mask: 1.2450  decode.d4.loss_dice: 0.8666  decode.d5.loss_cls: 0.2359  decode.d5.loss_mask: 1.2787  decode.d5.loss_dice: 0.8770  decode.d6.loss_cls: 0.2173  decode.d6.loss_mask: 1.2085  decode.d6.loss_dice: 0.8438  decode.d7.loss_cls: 0.2520  decode.d7.loss_mask: 1.2401  decode.d7.loss_dice: 0.8722  decode.d8.loss_cls: 0.2560  decode.d8.loss_mask: 1.2325  decode.d8.loss_dice: 0.8333
05/26 22:45:52 - mmengine - INFO - Saving checkpoint at 100000 iterations
05/26 22:45:57 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:10  time: 0.0512  data_time: 0.0021  memory: 1391  
05/26 22:46:00 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:06  time: 0.0489  data_time: 0.0012  memory: 1205  
05/26 22:46:02 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:06  time: 0.0507  data_time: 0.0012  memory: 1596  
05/26 22:46:05 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:03  time: 0.0493  data_time: 0.0012  memory: 1298  
05/26 22:46:07 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:01:00  time: 0.0496  data_time: 0.0013  memory: 1298  
05/26 22:46:10 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:57  time: 0.0483  data_time: 0.0012  memory: 1279  
05/26 22:46:12 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:54  time: 0.0489  data_time: 0.0012  memory: 1224  
05/26 22:46:15 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:52  time: 0.0493  data_time: 0.0012  memory: 1298  
05/26 22:46:17 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:49  time: 0.0505  data_time: 0.0013  memory: 1298  
05/26 22:46:19 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:47  time: 0.0521  data_time: 0.0012  memory: 1725  
05/26 22:46:22 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:44  time: 0.0497  data_time: 0.0012  memory: 1336  
05/26 22:46:24 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:42  time: 0.0484  data_time: 0.0012  memory: 1298  
05/26 22:46:27 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:39  time: 0.0502  data_time: 0.0013  memory: 1205  
05/26 22:46:29 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:37  time: 0.0493  data_time: 0.0012  memory: 1316  
05/26 22:46:32 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:34  time: 0.0487  data_time: 0.0012  memory: 1279  
05/26 22:46:34 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:32  time: 0.0515  data_time: 0.0012  memory: 1410  
05/26 22:46:37 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:29  time: 0.0485  data_time: 0.0012  memory: 1279  
05/26 22:46:39 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:27  time: 0.0494  data_time: 0.0012  memory: 1205  
05/26 22:46:42 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0490  data_time: 0.0012  memory: 1205  
05/26 22:46:44 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:22  time: 0.0492  data_time: 0.0012  memory: 1336  
05/26 22:46:46 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0478  data_time: 0.0012  memory: 1246  
05/26 22:46:49 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:17  time: 0.0516  data_time: 0.0012  memory: 1503  
05/26 22:46:51 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0483  data_time: 0.0012  memory: 1261  
05/26 22:46:54 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0514  data_time: 0.0013  memory: 1298  
05/26 22:46:56 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0481  data_time: 0.0013  memory: 1447  
05/26 22:46:59 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0490  data_time: 0.0012  memory: 1298  
05/26 22:47:01 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0494  data_time: 0.0012  memory: 1279  
05/26 22:47:04 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0492  data_time: 0.0012  memory: 1205  
05/26 22:47:06 - mmengine - INFO - per class results:
05/26 22:47:06 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.63 | 97.32 |
|  aeroplane  | 94.45 | 98.29 |
|   bicycle   | 45.11 | 95.36 |
|     bird    | 95.32 | 97.24 |
|     boat    | 72.21 | 89.24 |
|    bottle   | 84.93 | 94.94 |
|     bus     | 96.21 |  97.7 |
|     car     | 91.79 | 93.75 |
|     cat     | 95.61 | 98.78 |
|    chair    | 41.82 | 67.86 |
|     cow     | 87.04 | 92.86 |
| diningtable | 66.15 | 76.34 |
|     dog     | 91.92 | 97.94 |
|    horse    | 91.68 | 95.52 |
|  motorbike  | 92.01 | 96.48 |
|    person   | 90.76 | 95.92 |
| pottedplant | 71.22 |  93.5 |
|    sheep    | 83.54 | 92.32 |
|     sofa    | 54.31 | 64.25 |
|    train    | 87.99 |  94.0 |
|  tvmonitor  | 82.36 |  87.1 |
+-------------+-------+-------+
05/26 22:47:06 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.9400  mIoU: 81.5300  mAcc: 91.2700  data_time: 0.0013  time: 0.0492
05/26 22:47:06 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_85000.pth is removed
05/26 22:47:07 - mmengine - INFO - The best checkpoint with 81.5300 mIoU at 100000 iter is saved to best_mIoU_iter_100000.pth.
05/26 22:47:30 - mmengine - INFO - Iter(train) [100050/160000]  base_lr: 4.1334e-05 lr: 4.1334e-06  eta: 6:52:31  time: 0.4174  data_time: 0.0099  memory: 5974  grad_norm: 1251.1561  loss: 20.4688  decode.loss_cls: 0.2016  decode.loss_mask: 1.0932  decode.loss_dice: 0.7092  decode.d0.loss_cls: 0.6247  decode.d0.loss_mask: 1.0470  decode.d0.loss_dice: 0.6919  decode.d1.loss_cls: 0.1733  decode.d1.loss_mask: 1.1194  decode.d1.loss_dice: 0.7384  decode.d2.loss_cls: 0.2242  decode.d2.loss_mask: 1.1005  decode.d2.loss_dice: 0.7003  decode.d3.loss_cls: 0.1898  decode.d3.loss_mask: 1.0941  decode.d3.loss_dice: 0.6904  decode.d4.loss_cls: 0.1981  decode.d4.loss_mask: 1.1040  decode.d4.loss_dice: 0.7101  decode.d5.loss_cls: 0.2055  decode.d5.loss_mask: 1.0952  decode.d5.loss_dice: 0.7230  decode.d6.loss_cls: 0.2143  decode.d6.loss_mask: 1.0756  decode.d6.loss_dice: 0.7237  decode.d7.loss_cls: 0.1809  decode.d7.loss_mask: 1.1057  decode.d7.loss_dice: 0.7240  decode.d8.loss_cls: 0.2049  decode.d8.loss_mask: 1.0935  decode.d8.loss_dice: 0.7124
05/26 22:47:51 - mmengine - INFO - Iter(train) [100100/160000]  base_lr: 4.1303e-05 lr: 4.1303e-06  eta: 6:52:10  time: 0.4221  data_time: 0.0100  memory: 5984  grad_norm: 654.8466  loss: 20.8565  decode.loss_cls: 0.2245  decode.loss_mask: 1.1100  decode.loss_dice: 0.7088  decode.d0.loss_cls: 0.7296  decode.d0.loss_mask: 1.1090  decode.d0.loss_dice: 0.7282  decode.d1.loss_cls: 0.2422  decode.d1.loss_mask: 1.0836  decode.d1.loss_dice: 0.7119  decode.d2.loss_cls: 0.2198  decode.d2.loss_mask: 1.1048  decode.d2.loss_dice: 0.7057  decode.d3.loss_cls: 0.2307  decode.d3.loss_mask: 1.0967  decode.d3.loss_dice: 0.7191  decode.d4.loss_cls: 0.2042  decode.d4.loss_mask: 1.0795  decode.d4.loss_dice: 0.7071  decode.d5.loss_cls: 0.2074  decode.d5.loss_mask: 1.0819  decode.d5.loss_dice: 0.6970  decode.d6.loss_cls: 0.2581  decode.d6.loss_mask: 1.0963  decode.d6.loss_dice: 0.7051  decode.d7.loss_cls: 0.2193  decode.d7.loss_mask: 1.1097  decode.d7.loss_dice: 0.7198  decode.d8.loss_cls: 0.2120  decode.d8.loss_mask: 1.1057  decode.d8.loss_dice: 0.7287
05/26 22:48:12 - mmengine - INFO - Iter(train) [100150/160000]  base_lr: 4.1272e-05 lr: 4.1272e-06  eta: 6:51:50  time: 0.4136  data_time: 0.0097  memory: 5986  grad_norm: 646.2818  loss: 22.3126  decode.loss_cls: 0.3150  decode.loss_mask: 1.0719  decode.loss_dice: 0.7491  decode.d0.loss_cls: 0.8210  decode.d0.loss_mask: 1.0549  decode.d0.loss_dice: 0.7676  decode.d1.loss_cls: 0.3021  decode.d1.loss_mask: 1.0903  decode.d1.loss_dice: 0.7750  decode.d2.loss_cls: 0.3392  decode.d2.loss_mask: 1.0928  decode.d2.loss_dice: 0.7755  decode.d3.loss_cls: 0.2727  decode.d3.loss_mask: 1.1173  decode.d3.loss_dice: 0.7693  decode.d4.loss_cls: 0.2897  decode.d4.loss_mask: 1.1235  decode.d4.loss_dice: 0.7920  decode.d5.loss_cls: 0.3200  decode.d5.loss_mask: 1.1284  decode.d5.loss_dice: 0.7888  decode.d6.loss_cls: 0.3324  decode.d6.loss_mask: 1.0802  decode.d6.loss_dice: 0.7659  decode.d7.loss_cls: 0.3054  decode.d7.loss_mask: 1.1196  decode.d7.loss_dice: 0.7887  decode.d8.loss_cls: 0.3136  decode.d8.loss_mask: 1.1007  decode.d8.loss_dice: 0.7498
05/26 22:48:33 - mmengine - INFO - Iter(train) [100200/160000]  base_lr: 4.1241e-05 lr: 4.1241e-06  eta: 6:51:29  time: 0.4136  data_time: 0.0096  memory: 5975  grad_norm: 622.8374  loss: 19.2054  decode.loss_cls: 0.2267  decode.loss_mask: 0.9289  decode.loss_dice: 0.7506  decode.d0.loss_cls: 0.7336  decode.d0.loss_mask: 0.9111  decode.d0.loss_dice: 0.7464  decode.d1.loss_cls: 0.2104  decode.d1.loss_mask: 0.9416  decode.d1.loss_dice: 0.7569  decode.d2.loss_cls: 0.1997  decode.d2.loss_mask: 0.9248  decode.d2.loss_dice: 0.7266  decode.d3.loss_cls: 0.2156  decode.d3.loss_mask: 0.9210  decode.d3.loss_dice: 0.7315  decode.d4.loss_cls: 0.1604  decode.d4.loss_mask: 0.9426  decode.d4.loss_dice: 0.7416  decode.d5.loss_cls: 0.1960  decode.d5.loss_mask: 0.9271  decode.d5.loss_dice: 0.7271  decode.d6.loss_cls: 0.1991  decode.d6.loss_mask: 0.9192  decode.d6.loss_dice: 0.7350  decode.d7.loss_cls: 0.1875  decode.d7.loss_mask: 0.9315  decode.d7.loss_dice: 0.7647  decode.d8.loss_cls: 0.1989  decode.d8.loss_mask: 0.9206  decode.d8.loss_dice: 0.7286
05/26 22:48:54 - mmengine - INFO - Iter(train) [100250/160000]  base_lr: 4.1210e-05 lr: 4.1210e-06  eta: 6:51:08  time: 0.4148  data_time: 0.0097  memory: 5966  grad_norm: 354.4750  loss: 16.3544  decode.loss_cls: 0.0992  decode.loss_mask: 0.9213  decode.loss_dice: 0.5488  decode.d0.loss_cls: 0.5218  decode.d0.loss_mask: 0.9431  decode.d0.loss_dice: 0.5473  decode.d1.loss_cls: 0.0856  decode.d1.loss_mask: 0.9551  decode.d1.loss_dice: 0.5721  decode.d2.loss_cls: 0.0922  decode.d2.loss_mask: 0.9280  decode.d2.loss_dice: 0.5575  decode.d3.loss_cls: 0.1268  decode.d3.loss_mask: 0.9231  decode.d3.loss_dice: 0.5417  decode.d4.loss_cls: 0.1449  decode.d4.loss_mask: 0.9285  decode.d4.loss_dice: 0.5537  decode.d5.loss_cls: 0.0828  decode.d5.loss_mask: 0.9301  decode.d5.loss_dice: 0.5599  decode.d6.loss_cls: 0.1048  decode.d6.loss_mask: 0.9250  decode.d6.loss_dice: 0.5523  decode.d7.loss_cls: 0.1199  decode.d7.loss_mask: 0.9210  decode.d7.loss_dice: 0.5487  decode.d8.loss_cls: 0.1150  decode.d8.loss_mask: 0.9419  decode.d8.loss_dice: 0.5625
05/26 22:49:14 - mmengine - INFO - Iter(train) [100300/160000]  base_lr: 4.1179e-05 lr: 4.1179e-06  eta: 6:50:48  time: 0.4128  data_time: 0.0096  memory: 5968  grad_norm: 724.8539  loss: 18.0792  decode.loss_cls: 0.1403  decode.loss_mask: 0.9896  decode.loss_dice: 0.6191  decode.d0.loss_cls: 0.5803  decode.d0.loss_mask: 0.9742  decode.d0.loss_dice: 0.6284  decode.d1.loss_cls: 0.2001  decode.d1.loss_mask: 0.9946  decode.d1.loss_dice: 0.6233  decode.d2.loss_cls: 0.1532  decode.d2.loss_mask: 0.9992  decode.d2.loss_dice: 0.6171  decode.d3.loss_cls: 0.1245  decode.d3.loss_mask: 0.9718  decode.d3.loss_dice: 0.6047  decode.d4.loss_cls: 0.1455  decode.d4.loss_mask: 0.9973  decode.d4.loss_dice: 0.6376  decode.d5.loss_cls: 0.1682  decode.d5.loss_mask: 0.9752  decode.d5.loss_dice: 0.6163  decode.d6.loss_cls: 0.2143  decode.d6.loss_mask: 0.9566  decode.d6.loss_dice: 0.6247  decode.d7.loss_cls: 0.1567  decode.d7.loss_mask: 0.9933  decode.d7.loss_dice: 0.6191  decode.d8.loss_cls: 0.1389  decode.d8.loss_mask: 0.9880  decode.d8.loss_dice: 0.6271
05/26 22:49:35 - mmengine - INFO - Iter(train) [100350/160000]  base_lr: 4.1148e-05 lr: 4.1148e-06  eta: 6:50:27  time: 0.4135  data_time: 0.0097  memory: 5967  grad_norm: 430.4036  loss: 18.7215  decode.loss_cls: 0.1832  decode.loss_mask: 0.9659  decode.loss_dice: 0.6804  decode.d0.loss_cls: 0.7177  decode.d0.loss_mask: 0.8352  decode.d0.loss_dice: 0.6593  decode.d1.loss_cls: 0.2521  decode.d1.loss_mask: 0.8902  decode.d1.loss_dice: 0.6580  decode.d2.loss_cls: 0.2437  decode.d2.loss_mask: 0.9055  decode.d2.loss_dice: 0.6795  decode.d3.loss_cls: 0.2720  decode.d3.loss_mask: 0.8872  decode.d3.loss_dice: 0.6661  decode.d4.loss_cls: 0.2550  decode.d4.loss_mask: 0.9380  decode.d4.loss_dice: 0.6823  decode.d5.loss_cls: 0.2711  decode.d5.loss_mask: 0.8838  decode.d5.loss_dice: 0.6585  decode.d6.loss_cls: 0.2704  decode.d6.loss_mask: 0.9171  decode.d6.loss_dice: 0.6784  decode.d7.loss_cls: 0.2463  decode.d7.loss_mask: 0.9314  decode.d7.loss_dice: 0.7003  decode.d8.loss_cls: 0.2166  decode.d8.loss_mask: 0.9026  decode.d8.loss_dice: 0.6735
05/26 22:49:56 - mmengine - INFO - Iter(train) [100400/160000]  base_lr: 4.1116e-05 lr: 4.1116e-06  eta: 6:50:07  time: 0.4137  data_time: 0.0096  memory: 5966  grad_norm: 483.2757  loss: 16.8106  decode.loss_cls: 0.0747  decode.loss_mask: 0.8971  decode.loss_dice: 0.6195  decode.d0.loss_cls: 0.5218  decode.d0.loss_mask: 0.9240  decode.d0.loss_dice: 0.6137  decode.d1.loss_cls: 0.0612  decode.d1.loss_mask: 0.9447  decode.d1.loss_dice: 0.6589  decode.d2.loss_cls: 0.0934  decode.d2.loss_mask: 0.9172  decode.d2.loss_dice: 0.6211  decode.d3.loss_cls: 0.0583  decode.d3.loss_mask: 0.9078  decode.d3.loss_dice: 0.6331  decode.d4.loss_cls: 0.0889  decode.d4.loss_mask: 0.9523  decode.d4.loss_dice: 0.6587  decode.d5.loss_cls: 0.0923  decode.d5.loss_mask: 0.9140  decode.d5.loss_dice: 0.6045  decode.d6.loss_cls: 0.0609  decode.d6.loss_mask: 0.9488  decode.d6.loss_dice: 0.6368  decode.d7.loss_cls: 0.0764  decode.d7.loss_mask: 0.9467  decode.d7.loss_dice: 0.6339  decode.d8.loss_cls: 0.0539  decode.d8.loss_mask: 0.9441  decode.d8.loss_dice: 0.6520
05/26 22:50:17 - mmengine - INFO - Iter(train) [100450/160000]  base_lr: 4.1085e-05 lr: 4.1085e-06  eta: 6:49:46  time: 0.4142  data_time: 0.0096  memory: 5971  grad_norm: 649.1463  loss: 20.2747  decode.loss_cls: 0.1614  decode.loss_mask: 1.0511  decode.loss_dice: 0.7496  decode.d0.loss_cls: 0.6467  decode.d0.loss_mask: 1.0141  decode.d0.loss_dice: 0.6928  decode.d1.loss_cls: 0.1833  decode.d1.loss_mask: 1.0675  decode.d1.loss_dice: 0.7704  decode.d2.loss_cls: 0.1578  decode.d2.loss_mask: 1.0528  decode.d2.loss_dice: 0.7666  decode.d3.loss_cls: 0.1394  decode.d3.loss_mask: 1.0529  decode.d3.loss_dice: 0.7455  decode.d4.loss_cls: 0.1954  decode.d4.loss_mask: 1.0696  decode.d4.loss_dice: 0.7498  decode.d5.loss_cls: 0.1678  decode.d5.loss_mask: 1.0866  decode.d5.loss_dice: 0.7885  decode.d6.loss_cls: 0.1496  decode.d6.loss_mask: 1.0692  decode.d6.loss_dice: 0.7609  decode.d7.loss_cls: 0.1411  decode.d7.loss_mask: 1.0874  decode.d7.loss_dice: 0.7493  decode.d8.loss_cls: 0.1533  decode.d8.loss_mask: 1.0789  decode.d8.loss_dice: 0.7757
05/26 22:50:37 - mmengine - INFO - Iter(train) [100500/160000]  base_lr: 4.1054e-05 lr: 4.1054e-06  eta: 6:49:25  time: 0.4139  data_time: 0.0096  memory: 5984  grad_norm: 790.0573  loss: 22.2445  decode.loss_cls: 0.2218  decode.loss_mask: 1.1559  decode.loss_dice: 0.7560  decode.d0.loss_cls: 0.7028  decode.d0.loss_mask: 1.1167  decode.d0.loss_dice: 0.7328  decode.d1.loss_cls: 0.2994  decode.d1.loss_mask: 1.1273  decode.d1.loss_dice: 0.7655  decode.d2.loss_cls: 0.2828  decode.d2.loss_mask: 1.1466  decode.d2.loss_dice: 0.7769  decode.d3.loss_cls: 0.2908  decode.d3.loss_mask: 1.1209  decode.d3.loss_dice: 0.7343  decode.d4.loss_cls: 0.2528  decode.d4.loss_mask: 1.2146  decode.d4.loss_dice: 0.8057  decode.d5.loss_cls: 0.2685  decode.d5.loss_mask: 1.1406  decode.d5.loss_dice: 0.7653  decode.d6.loss_cls: 0.2964  decode.d6.loss_mask: 1.1264  decode.d6.loss_dice: 0.7820  decode.d7.loss_cls: 0.2530  decode.d7.loss_mask: 1.1354  decode.d7.loss_dice: 0.7720  decode.d8.loss_cls: 0.2640  decode.d8.loss_mask: 1.1456  decode.d8.loss_dice: 0.7917
05/26 22:50:58 - mmengine - INFO - Iter(train) [100550/160000]  base_lr: 4.1023e-05 lr: 4.1023e-06  eta: 6:49:05  time: 0.4132  data_time: 0.0097  memory: 5972  grad_norm: 575.2288  loss: 18.2843  decode.loss_cls: 0.1407  decode.loss_mask: 1.0236  decode.loss_dice: 0.6043  decode.d0.loss_cls: 0.5883  decode.d0.loss_mask: 1.0321  decode.d0.loss_dice: 0.6061  decode.d1.loss_cls: 0.1653  decode.d1.loss_mask: 1.0130  decode.d1.loss_dice: 0.6182  decode.d2.loss_cls: 0.1534  decode.d2.loss_mask: 1.0149  decode.d2.loss_dice: 0.6187  decode.d3.loss_cls: 0.1965  decode.d3.loss_mask: 0.9888  decode.d3.loss_dice: 0.6052  decode.d4.loss_cls: 0.1676  decode.d4.loss_mask: 1.0320  decode.d4.loss_dice: 0.6234  decode.d5.loss_cls: 0.1502  decode.d5.loss_mask: 1.0326  decode.d5.loss_dice: 0.6232  decode.d6.loss_cls: 0.1577  decode.d6.loss_mask: 1.0096  decode.d6.loss_dice: 0.6117  decode.d7.loss_cls: 0.1393  decode.d7.loss_mask: 1.0231  decode.d7.loss_dice: 0.6039  decode.d8.loss_cls: 0.1314  decode.d8.loss_mask: 1.0078  decode.d8.loss_dice: 0.6017
05/26 22:51:19 - mmengine - INFO - Iter(train) [100600/160000]  base_lr: 4.0992e-05 lr: 4.0992e-06  eta: 6:48:44  time: 0.4143  data_time: 0.0102  memory: 5976  grad_norm: 275.4470  loss: 17.1930  decode.loss_cls: 0.1575  decode.loss_mask: 0.7903  decode.loss_dice: 0.7222  decode.d0.loss_cls: 0.6532  decode.d0.loss_mask: 0.7466  decode.d0.loss_dice: 0.6626  decode.d1.loss_cls: 0.1589  decode.d1.loss_mask: 0.7861  decode.d1.loss_dice: 0.7154  decode.d2.loss_cls: 0.2045  decode.d2.loss_mask: 0.7745  decode.d2.loss_dice: 0.7000  decode.d3.loss_cls: 0.1859  decode.d3.loss_mask: 0.7803  decode.d3.loss_dice: 0.7103  decode.d4.loss_cls: 0.1731  decode.d4.loss_mask: 0.7886  decode.d4.loss_dice: 0.7148  decode.d5.loss_cls: 0.2046  decode.d5.loss_mask: 0.7976  decode.d5.loss_dice: 0.6982  decode.d6.loss_cls: 0.1980  decode.d6.loss_mask: 0.7726  decode.d6.loss_dice: 0.7102  decode.d7.loss_cls: 0.2007  decode.d7.loss_mask: 0.7798  decode.d7.loss_dice: 0.7002  decode.d8.loss_cls: 0.2010  decode.d8.loss_mask: 0.7793  decode.d8.loss_dice: 0.7261
05/26 22:51:39 - mmengine - INFO - Iter(train) [100650/160000]  base_lr: 4.0961e-05 lr: 4.0961e-06  eta: 6:48:24  time: 0.4128  data_time: 0.0096  memory: 5976  grad_norm: 704.5508  loss: 20.0996  decode.loss_cls: 0.2657  decode.loss_mask: 0.9939  decode.loss_dice: 0.6984  decode.d0.loss_cls: 0.7386  decode.d0.loss_mask: 0.9920  decode.d0.loss_dice: 0.7075  decode.d1.loss_cls: 0.2611  decode.d1.loss_mask: 0.9837  decode.d1.loss_dice: 0.6952  decode.d2.loss_cls: 0.2721  decode.d2.loss_mask: 0.9782  decode.d2.loss_dice: 0.7070  decode.d3.loss_cls: 0.2847  decode.d3.loss_mask: 0.9929  decode.d3.loss_dice: 0.6961  decode.d4.loss_cls: 0.2796  decode.d4.loss_mask: 1.0208  decode.d4.loss_dice: 0.7106  decode.d5.loss_cls: 0.2482  decode.d5.loss_mask: 0.9713  decode.d5.loss_dice: 0.6848  decode.d6.loss_cls: 0.2424  decode.d6.loss_mask: 1.0280  decode.d6.loss_dice: 0.7366  decode.d7.loss_cls: 0.2728  decode.d7.loss_mask: 1.0022  decode.d7.loss_dice: 0.7138  decode.d8.loss_cls: 0.2014  decode.d8.loss_mask: 0.9983  decode.d8.loss_dice: 0.7219
05/26 22:52:00 - mmengine - INFO - Iter(train) [100700/160000]  base_lr: 4.0930e-05 lr: 4.0930e-06  eta: 6:48:03  time: 0.4145  data_time: 0.0097  memory: 5966  grad_norm: 784.3975  loss: 18.7278  decode.loss_cls: 0.0902  decode.loss_mask: 1.0172  decode.loss_dice: 0.7373  decode.d0.loss_cls: 0.6809  decode.d0.loss_mask: 0.9570  decode.d0.loss_dice: 0.6695  decode.d1.loss_cls: 0.1081  decode.d1.loss_mask: 1.0061  decode.d1.loss_dice: 0.7235  decode.d2.loss_cls: 0.0936  decode.d2.loss_mask: 0.9930  decode.d2.loss_dice: 0.7148  decode.d3.loss_cls: 0.0779  decode.d3.loss_mask: 1.0341  decode.d3.loss_dice: 0.7180  decode.d4.loss_cls: 0.0927  decode.d4.loss_mask: 1.0066  decode.d4.loss_dice: 0.7157  decode.d5.loss_cls: 0.1011  decode.d5.loss_mask: 0.9999  decode.d5.loss_dice: 0.7099  decode.d6.loss_cls: 0.1187  decode.d6.loss_mask: 1.0199  decode.d6.loss_dice: 0.7146  decode.d7.loss_cls: 0.1489  decode.d7.loss_mask: 0.9751  decode.d7.loss_dice: 0.6798  decode.d8.loss_cls: 0.0948  decode.d8.loss_mask: 1.0113  decode.d8.loss_dice: 0.7179
05/26 22:52:21 - mmengine - INFO - Iter(train) [100750/160000]  base_lr: 4.0899e-05 lr: 4.0899e-06  eta: 6:47:42  time: 0.4134  data_time: 0.0098  memory: 5969  grad_norm: 975.6541  loss: 21.1574  decode.loss_cls: 0.2411  decode.loss_mask: 1.0480  decode.loss_dice: 0.7879  decode.d0.loss_cls: 0.7838  decode.d0.loss_mask: 0.9871  decode.d0.loss_dice: 0.7477  decode.d1.loss_cls: 0.2698  decode.d1.loss_mask: 1.0493  decode.d1.loss_dice: 0.7817  decode.d2.loss_cls: 0.2413  decode.d2.loss_mask: 1.0601  decode.d2.loss_dice: 0.7864  decode.d3.loss_cls: 0.2787  decode.d3.loss_mask: 1.0048  decode.d3.loss_dice: 0.7832  decode.d4.loss_cls: 0.3096  decode.d4.loss_mask: 0.9999  decode.d4.loss_dice: 0.8006  decode.d5.loss_cls: 0.2781  decode.d5.loss_mask: 1.0125  decode.d5.loss_dice: 0.7981  decode.d6.loss_cls: 0.2644  decode.d6.loss_mask: 1.0094  decode.d6.loss_dice: 0.7711  decode.d7.loss_cls: 0.2605  decode.d7.loss_mask: 1.0181  decode.d7.loss_dice: 0.7483  decode.d8.loss_cls: 0.2719  decode.d8.loss_mask: 1.0024  decode.d8.loss_dice: 0.7615
05/26 22:52:42 - mmengine - INFO - Iter(train) [100800/160000]  base_lr: 4.0868e-05 lr: 4.0868e-06  eta: 6:47:22  time: 0.4135  data_time: 0.0096  memory: 5976  grad_norm: 669.4555  loss: 16.6785  decode.loss_cls: 0.2324  decode.loss_mask: 0.7972  decode.loss_dice: 0.5976  decode.d0.loss_cls: 0.7134  decode.d0.loss_mask: 0.7968  decode.d0.loss_dice: 0.5680  decode.d1.loss_cls: 0.2495  decode.d1.loss_mask: 0.8437  decode.d1.loss_dice: 0.6032  decode.d2.loss_cls: 0.1942  decode.d2.loss_mask: 0.8146  decode.d2.loss_dice: 0.5986  decode.d3.loss_cls: 0.2140  decode.d3.loss_mask: 0.7934  decode.d3.loss_dice: 0.5743  decode.d4.loss_cls: 0.2645  decode.d4.loss_mask: 0.8015  decode.d4.loss_dice: 0.5734  decode.d5.loss_cls: 0.1922  decode.d5.loss_mask: 0.7994  decode.d5.loss_dice: 0.6062  decode.d6.loss_cls: 0.2076  decode.d6.loss_mask: 0.8093  decode.d6.loss_dice: 0.6031  decode.d7.loss_cls: 0.2393  decode.d7.loss_mask: 0.8159  decode.d7.loss_dice: 0.5878  decode.d8.loss_cls: 0.2001  decode.d8.loss_mask: 0.8000  decode.d8.loss_dice: 0.5872
05/26 22:53:02 - mmengine - INFO - Iter(train) [100850/160000]  base_lr: 4.0837e-05 lr: 4.0837e-06  eta: 6:47:01  time: 0.4127  data_time: 0.0097  memory: 5967  grad_norm: 371.0276  loss: 19.5626  decode.loss_cls: 0.1646  decode.loss_mask: 1.0578  decode.loss_dice: 0.7102  decode.d0.loss_cls: 0.6847  decode.d0.loss_mask: 0.9994  decode.d0.loss_dice: 0.7662  decode.d1.loss_cls: 0.1397  decode.d1.loss_mask: 1.0180  decode.d1.loss_dice: 0.7248  decode.d2.loss_cls: 0.1590  decode.d2.loss_mask: 1.0195  decode.d2.loss_dice: 0.7057  decode.d3.loss_cls: 0.1356  decode.d3.loss_mask: 1.0212  decode.d3.loss_dice: 0.7407  decode.d4.loss_cls: 0.1716  decode.d4.loss_mask: 1.0025  decode.d4.loss_dice: 0.7303  decode.d5.loss_cls: 0.1468  decode.d5.loss_mask: 1.0260  decode.d5.loss_dice: 0.7168  decode.d6.loss_cls: 0.1498  decode.d6.loss_mask: 1.0338  decode.d6.loss_dice: 0.7054  decode.d7.loss_cls: 0.1752  decode.d7.loss_mask: 1.0209  decode.d7.loss_dice: 0.7194  decode.d8.loss_cls: 0.1748  decode.d8.loss_mask: 1.0285  decode.d8.loss_dice: 0.7137
05/26 22:53:23 - mmengine - INFO - Iter(train) [100900/160000]  base_lr: 4.0806e-05 lr: 4.0806e-06  eta: 6:46:41  time: 0.4137  data_time: 0.0097  memory: 5968  grad_norm: 805.5675  loss: 22.1053  decode.loss_cls: 0.1892  decode.loss_mask: 1.1401  decode.loss_dice: 0.8290  decode.d0.loss_cls: 0.6823  decode.d0.loss_mask: 1.0054  decode.d0.loss_dice: 0.7761  decode.d1.loss_cls: 0.2206  decode.d1.loss_mask: 1.1235  decode.d1.loss_dice: 0.8390  decode.d2.loss_cls: 0.2074  decode.d2.loss_mask: 1.1461  decode.d2.loss_dice: 0.8648  decode.d3.loss_cls: 0.1801  decode.d3.loss_mask: 1.1667  decode.d3.loss_dice: 0.8497  decode.d4.loss_cls: 0.2058  decode.d4.loss_mask: 1.1360  decode.d4.loss_dice: 0.8432  decode.d5.loss_cls: 0.1880  decode.d5.loss_mask: 1.1438  decode.d5.loss_dice: 0.8283  decode.d6.loss_cls: 0.2306  decode.d6.loss_mask: 1.1091  decode.d6.loss_dice: 0.7903  decode.d7.loss_cls: 0.1864  decode.d7.loss_mask: 1.1483  decode.d7.loss_dice: 0.8646  decode.d8.loss_cls: 0.1851  decode.d8.loss_mask: 1.1668  decode.d8.loss_dice: 0.8589
05/26 22:53:44 - mmengine - INFO - Iter(train) [100950/160000]  base_lr: 4.0775e-05 lr: 4.0775e-06  eta: 6:46:20  time: 0.4144  data_time: 0.0097  memory: 5970  grad_norm: 611.1769  loss: 20.8275  decode.loss_cls: 0.2122  decode.loss_mask: 1.0606  decode.loss_dice: 0.7644  decode.d0.loss_cls: 0.7566  decode.d0.loss_mask: 1.0339  decode.d0.loss_dice: 0.7329  decode.d1.loss_cls: 0.1774  decode.d1.loss_mask: 1.0841  decode.d1.loss_dice: 0.7600  decode.d2.loss_cls: 0.1802  decode.d2.loss_mask: 1.0916  decode.d2.loss_dice: 0.7731  decode.d3.loss_cls: 0.2002  decode.d3.loss_mask: 1.0634  decode.d3.loss_dice: 0.7868  decode.d4.loss_cls: 0.2127  decode.d4.loss_mask: 1.0751  decode.d4.loss_dice: 0.7903  decode.d5.loss_cls: 0.2162  decode.d5.loss_mask: 1.0655  decode.d5.loss_dice: 0.7429  decode.d6.loss_cls: 0.1800  decode.d6.loss_mask: 1.0825  decode.d6.loss_dice: 0.7619  decode.d7.loss_cls: 0.2222  decode.d7.loss_mask: 1.0392  decode.d7.loss_dice: 0.7438  decode.d8.loss_cls: 0.2301  decode.d8.loss_mask: 1.0577  decode.d8.loss_dice: 0.7298
05/26 22:54:04 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 22:54:04 - mmengine - INFO - Iter(train) [101000/160000]  base_lr: 4.0744e-05 lr: 4.0744e-06  eta: 6:45:59  time: 0.4139  data_time: 0.0097  memory: 5978  grad_norm: 782.8587  loss: 25.6728  decode.loss_cls: 0.3731  decode.loss_mask: 1.3305  decode.loss_dice: 0.8929  decode.d0.loss_cls: 0.9452  decode.d0.loss_mask: 1.1777  decode.d0.loss_dice: 0.7888  decode.d1.loss_cls: 0.3826  decode.d1.loss_mask: 1.3130  decode.d1.loss_dice: 0.8797  decode.d2.loss_cls: 0.3856  decode.d2.loss_mask: 1.2468  decode.d2.loss_dice: 0.8671  decode.d3.loss_cls: 0.4085  decode.d3.loss_mask: 1.2441  decode.d3.loss_dice: 0.8196  decode.d4.loss_cls: 0.3866  decode.d4.loss_mask: 1.2645  decode.d4.loss_dice: 0.8412  decode.d5.loss_cls: 0.3610  decode.d5.loss_mask: 1.3405  decode.d5.loss_dice: 0.8731  decode.d6.loss_cls: 0.3328  decode.d6.loss_mask: 1.2909  decode.d6.loss_dice: 0.8726  decode.d7.loss_cls: 0.3310  decode.d7.loss_mask: 1.3164  decode.d7.loss_dice: 0.9047  decode.d8.loss_cls: 0.3758  decode.d8.loss_mask: 1.2638  decode.d8.loss_dice: 0.8625
05/26 22:54:25 - mmengine - INFO - Iter(train) [101050/160000]  base_lr: 4.0713e-05 lr: 4.0713e-06  eta: 6:45:39  time: 0.4145  data_time: 0.0097  memory: 5987  grad_norm: 523.2260  loss: 20.5387  decode.loss_cls: 0.2918  decode.loss_mask: 0.9909  decode.loss_dice: 0.7374  decode.d0.loss_cls: 0.8033  decode.d0.loss_mask: 0.9203  decode.d0.loss_dice: 0.7036  decode.d1.loss_cls: 0.2786  decode.d1.loss_mask: 0.9600  decode.d1.loss_dice: 0.7504  decode.d2.loss_cls: 0.2865  decode.d2.loss_mask: 0.9577  decode.d2.loss_dice: 0.7504  decode.d3.loss_cls: 0.2575  decode.d3.loss_mask: 0.9971  decode.d3.loss_dice: 0.7400  decode.d4.loss_cls: 0.2814  decode.d4.loss_mask: 0.9947  decode.d4.loss_dice: 0.7646  decode.d5.loss_cls: 0.3440  decode.d5.loss_mask: 0.9374  decode.d5.loss_dice: 0.7403  decode.d6.loss_cls: 0.3188  decode.d6.loss_mask: 0.9585  decode.d6.loss_dice: 0.7578  decode.d7.loss_cls: 0.2891  decode.d7.loss_mask: 0.9760  decode.d7.loss_dice: 0.7589  decode.d8.loss_cls: 0.3189  decode.d8.loss_mask: 0.9449  decode.d8.loss_dice: 0.7278
05/26 22:54:46 - mmengine - INFO - Iter(train) [101100/160000]  base_lr: 4.0682e-05 lr: 4.0682e-06  eta: 6:45:18  time: 0.4143  data_time: 0.0096  memory: 5966  grad_norm: 1022.0104  loss: 22.2864  decode.loss_cls: 0.3406  decode.loss_mask: 1.0345  decode.loss_dice: 0.7997  decode.d0.loss_cls: 0.7912  decode.d0.loss_mask: 1.0005  decode.d0.loss_dice: 0.7816  decode.d1.loss_cls: 0.2896  decode.d1.loss_mask: 1.0535  decode.d1.loss_dice: 0.8137  decode.d2.loss_cls: 0.3122  decode.d2.loss_mask: 1.0120  decode.d2.loss_dice: 0.8037  decode.d3.loss_cls: 0.3045  decode.d3.loss_mask: 1.0599  decode.d3.loss_dice: 0.8553  decode.d4.loss_cls: 0.2827  decode.d4.loss_mask: 1.0756  decode.d4.loss_dice: 0.8708  decode.d5.loss_cls: 0.3312  decode.d5.loss_mask: 1.0910  decode.d5.loss_dice: 0.8415  decode.d6.loss_cls: 0.3305  decode.d6.loss_mask: 1.0592  decode.d6.loss_dice: 0.8319  decode.d7.loss_cls: 0.2948  decode.d7.loss_mask: 1.0454  decode.d7.loss_dice: 0.8144  decode.d8.loss_cls: 0.3108  decode.d8.loss_mask: 1.0517  decode.d8.loss_dice: 0.8024
05/26 22:55:07 - mmengine - INFO - Iter(train) [101150/160000]  base_lr: 4.0651e-05 lr: 4.0651e-06  eta: 6:44:57  time: 0.4138  data_time: 0.0097  memory: 5981  grad_norm: 829.3457  loss: 21.2705  decode.loss_cls: 0.2385  decode.loss_mask: 1.0229  decode.loss_dice: 0.7984  decode.d0.loss_cls: 0.6261  decode.d0.loss_mask: 1.0265  decode.d0.loss_dice: 0.7996  decode.d1.loss_cls: 0.2333  decode.d1.loss_mask: 1.0319  decode.d1.loss_dice: 0.7819  decode.d2.loss_cls: 0.2560  decode.d2.loss_mask: 1.0290  decode.d2.loss_dice: 0.8082  decode.d3.loss_cls: 0.2302  decode.d3.loss_mask: 1.0609  decode.d3.loss_dice: 0.8436  decode.d4.loss_cls: 0.2639  decode.d4.loss_mask: 1.0160  decode.d4.loss_dice: 0.8144  decode.d5.loss_cls: 0.2592  decode.d5.loss_mask: 1.0314  decode.d5.loss_dice: 0.8222  decode.d6.loss_cls: 0.2584  decode.d6.loss_mask: 1.0312  decode.d6.loss_dice: 0.7856  decode.d7.loss_cls: 0.2376  decode.d7.loss_mask: 1.0397  decode.d7.loss_dice: 0.8297  decode.d8.loss_cls: 0.2312  decode.d8.loss_mask: 1.0404  decode.d8.loss_dice: 0.8226
05/26 22:55:27 - mmengine - INFO - Iter(train) [101200/160000]  base_lr: 4.0619e-05 lr: 4.0619e-06  eta: 6:44:37  time: 0.4257  data_time: 0.0096  memory: 5967  grad_norm: 491.2890  loss: 20.7549  decode.loss_cls: 0.2370  decode.loss_mask: 1.0472  decode.loss_dice: 0.7544  decode.d0.loss_cls: 0.7633  decode.d0.loss_mask: 1.0330  decode.d0.loss_dice: 0.7399  decode.d1.loss_cls: 0.2462  decode.d1.loss_mask: 1.0618  decode.d1.loss_dice: 0.7760  decode.d2.loss_cls: 0.2202  decode.d2.loss_mask: 1.0321  decode.d2.loss_dice: 0.7489  decode.d3.loss_cls: 0.2390  decode.d3.loss_mask: 1.0347  decode.d3.loss_dice: 0.7612  decode.d4.loss_cls: 0.2220  decode.d4.loss_mask: 1.0251  decode.d4.loss_dice: 0.7507  decode.d5.loss_cls: 0.2284  decode.d5.loss_mask: 1.0365  decode.d5.loss_dice: 0.7467  decode.d6.loss_cls: 0.2403  decode.d6.loss_mask: 1.0580  decode.d6.loss_dice: 0.7637  decode.d7.loss_cls: 0.2252  decode.d7.loss_mask: 1.0313  decode.d7.loss_dice: 0.7458  decode.d8.loss_cls: 0.2260  decode.d8.loss_mask: 1.0193  decode.d8.loss_dice: 0.7410
05/26 22:55:48 - mmengine - INFO - Iter(train) [101250/160000]  base_lr: 4.0588e-05 lr: 4.0588e-06  eta: 6:44:16  time: 0.4142  data_time: 0.0096  memory: 5970  grad_norm: 990.3251  loss: 24.7645  decode.loss_cls: 0.2940  decode.loss_mask: 1.2163  decode.loss_dice: 0.9434  decode.d0.loss_cls: 0.9184  decode.d0.loss_mask: 1.1185  decode.d0.loss_dice: 0.8519  decode.d1.loss_cls: 0.2977  decode.d1.loss_mask: 1.2177  decode.d1.loss_dice: 0.9542  decode.d2.loss_cls: 0.3016  decode.d2.loss_mask: 1.1729  decode.d2.loss_dice: 0.9369  decode.d3.loss_cls: 0.3189  decode.d3.loss_mask: 1.1657  decode.d3.loss_dice: 0.9064  decode.d4.loss_cls: 0.3193  decode.d4.loss_mask: 1.1785  decode.d4.loss_dice: 0.9371  decode.d5.loss_cls: 0.3703  decode.d5.loss_mask: 1.1579  decode.d5.loss_dice: 0.8944  decode.d6.loss_cls: 0.3365  decode.d6.loss_mask: 1.1742  decode.d6.loss_dice: 0.9079  decode.d7.loss_cls: 0.3474  decode.d7.loss_mask: 1.1384  decode.d7.loss_dice: 0.9069  decode.d8.loss_cls: 0.2936  decode.d8.loss_mask: 1.2130  decode.d8.loss_dice: 0.9747
05/26 22:56:09 - mmengine - INFO - Iter(train) [101300/160000]  base_lr: 4.0557e-05 lr: 4.0557e-06  eta: 6:43:56  time: 0.4139  data_time: 0.0098  memory: 5978  grad_norm: 906.6392  loss: 22.6485  decode.loss_cls: 0.2536  decode.loss_mask: 1.1424  decode.loss_dice: 0.8629  decode.d0.loss_cls: 0.7374  decode.d0.loss_mask: 1.0700  decode.d0.loss_dice: 0.8172  decode.d1.loss_cls: 0.2514  decode.d1.loss_mask: 1.1332  decode.d1.loss_dice: 0.8390  decode.d2.loss_cls: 0.2492  decode.d2.loss_mask: 1.1147  decode.d2.loss_dice: 0.8350  decode.d3.loss_cls: 0.2149  decode.d3.loss_mask: 1.1455  decode.d3.loss_dice: 0.8678  decode.d4.loss_cls: 0.2545  decode.d4.loss_mask: 1.1758  decode.d4.loss_dice: 0.8399  decode.d5.loss_cls: 0.2182  decode.d5.loss_mask: 1.1548  decode.d5.loss_dice: 0.8565  decode.d6.loss_cls: 0.2599  decode.d6.loss_mask: 1.1075  decode.d6.loss_dice: 0.8244  decode.d7.loss_cls: 0.2099  decode.d7.loss_mask: 1.1778  decode.d7.loss_dice: 0.8413  decode.d8.loss_cls: 0.2080  decode.d8.loss_mask: 1.1313  decode.d8.loss_dice: 0.8544
05/26 22:56:30 - mmengine - INFO - Iter(train) [101350/160000]  base_lr: 4.0526e-05 lr: 4.0526e-06  eta: 6:43:35  time: 0.4151  data_time: 0.0098  memory: 5966  grad_norm: 1139.4452  loss: 22.0293  decode.loss_cls: 0.3157  decode.loss_mask: 1.1567  decode.loss_dice: 0.7138  decode.d0.loss_cls: 0.7329  decode.d0.loss_mask: 1.0977  decode.d0.loss_dice: 0.6918  decode.d1.loss_cls: 0.3052  decode.d1.loss_mask: 1.1691  decode.d1.loss_dice: 0.6940  decode.d2.loss_cls: 0.2955  decode.d2.loss_mask: 1.1816  decode.d2.loss_dice: 0.7109  decode.d3.loss_cls: 0.3177  decode.d3.loss_mask: 1.1572  decode.d3.loss_dice: 0.6937  decode.d4.loss_cls: 0.2649  decode.d4.loss_mask: 1.1563  decode.d4.loss_dice: 0.6973  decode.d5.loss_cls: 0.3009  decode.d5.loss_mask: 1.1504  decode.d5.loss_dice: 0.6967  decode.d6.loss_cls: 0.2709  decode.d6.loss_mask: 1.1987  decode.d6.loss_dice: 0.7026  decode.d7.loss_cls: 0.3116  decode.d7.loss_mask: 1.1574  decode.d7.loss_dice: 0.6886  decode.d8.loss_cls: 0.2463  decode.d8.loss_mask: 1.2118  decode.d8.loss_dice: 0.7412
05/26 22:56:50 - mmengine - INFO - Iter(train) [101400/160000]  base_lr: 4.0495e-05 lr: 4.0495e-06  eta: 6:43:15  time: 0.4143  data_time: 0.0097  memory: 5966  grad_norm: 571.1320  loss: 19.6785  decode.loss_cls: 0.1236  decode.loss_mask: 1.0569  decode.loss_dice: 0.7436  decode.d0.loss_cls: 0.6829  decode.d0.loss_mask: 1.0355  decode.d0.loss_dice: 0.7277  decode.d1.loss_cls: 0.2059  decode.d1.loss_mask: 1.0331  decode.d1.loss_dice: 0.7044  decode.d2.loss_cls: 0.1529  decode.d2.loss_mask: 1.0469  decode.d2.loss_dice: 0.7152  decode.d3.loss_cls: 0.1518  decode.d3.loss_mask: 1.0421  decode.d3.loss_dice: 0.7143  decode.d4.loss_cls: 0.1594  decode.d4.loss_mask: 1.0323  decode.d4.loss_dice: 0.7043  decode.d5.loss_cls: 0.1832  decode.d5.loss_mask: 1.0273  decode.d5.loss_dice: 0.7040  decode.d6.loss_cls: 0.1413  decode.d6.loss_mask: 1.0464  decode.d6.loss_dice: 0.7184  decode.d7.loss_cls: 0.1726  decode.d7.loss_mask: 1.0227  decode.d7.loss_dice: 0.7034  decode.d8.loss_cls: 0.1379  decode.d8.loss_mask: 1.0588  decode.d8.loss_dice: 0.7295
05/26 22:57:11 - mmengine - INFO - Iter(train) [101450/160000]  base_lr: 4.0464e-05 lr: 4.0464e-06  eta: 6:42:54  time: 0.4145  data_time: 0.0098  memory: 5969  grad_norm: 949.2979  loss: 17.8322  decode.loss_cls: 0.1687  decode.loss_mask: 0.9027  decode.loss_dice: 0.6587  decode.d0.loss_cls: 0.6435  decode.d0.loss_mask: 0.8791  decode.d0.loss_dice: 0.6461  decode.d1.loss_cls: 0.1522  decode.d1.loss_mask: 0.9223  decode.d1.loss_dice: 0.6753  decode.d2.loss_cls: 0.1609  decode.d2.loss_mask: 0.9126  decode.d2.loss_dice: 0.6697  decode.d3.loss_cls: 0.1793  decode.d3.loss_mask: 0.9196  decode.d3.loss_dice: 0.6494  decode.d4.loss_cls: 0.1810  decode.d4.loss_mask: 0.9024  decode.d4.loss_dice: 0.6498  decode.d5.loss_cls: 0.1975  decode.d5.loss_mask: 0.9047  decode.d5.loss_dice: 0.6458  decode.d6.loss_cls: 0.1783  decode.d6.loss_mask: 0.9016  decode.d6.loss_dice: 0.6511  decode.d7.loss_cls: 0.1640  decode.d7.loss_mask: 0.8984  decode.d7.loss_dice: 0.6637  decode.d8.loss_cls: 0.2013  decode.d8.loss_mask: 0.8875  decode.d8.loss_dice: 0.6652
05/26 22:57:32 - mmengine - INFO - Iter(train) [101500/160000]  base_lr: 4.0433e-05 lr: 4.0433e-06  eta: 6:42:33  time: 0.4148  data_time: 0.0097  memory: 5990  grad_norm: 776.5210  loss: 20.6236  decode.loss_cls: 0.1343  decode.loss_mask: 1.1370  decode.loss_dice: 0.7340  decode.d0.loss_cls: 0.6872  decode.d0.loss_mask: 1.0566  decode.d0.loss_dice: 0.6911  decode.d1.loss_cls: 0.1595  decode.d1.loss_mask: 1.1354  decode.d1.loss_dice: 0.7457  decode.d2.loss_cls: 0.1568  decode.d2.loss_mask: 1.1113  decode.d2.loss_dice: 0.7551  decode.d3.loss_cls: 0.1629  decode.d3.loss_mask: 1.1196  decode.d3.loss_dice: 0.7356  decode.d4.loss_cls: 0.1800  decode.d4.loss_mask: 1.1208  decode.d4.loss_dice: 0.7329  decode.d5.loss_cls: 0.1612  decode.d5.loss_mask: 1.1011  decode.d5.loss_dice: 0.7185  decode.d6.loss_cls: 0.1699  decode.d6.loss_mask: 1.1125  decode.d6.loss_dice: 0.7396  decode.d7.loss_cls: 0.1649  decode.d7.loss_mask: 1.1380  decode.d7.loss_dice: 0.7397  decode.d8.loss_cls: 0.1529  decode.d8.loss_mask: 1.1210  decode.d8.loss_dice: 0.7486
05/26 22:57:53 - mmengine - INFO - Iter(train) [101550/160000]  base_lr: 4.0402e-05 lr: 4.0402e-06  eta: 6:42:13  time: 0.4144  data_time: 0.0098  memory: 5967  grad_norm: 485.2418  loss: 18.4583  decode.loss_cls: 0.1110  decode.loss_mask: 0.9946  decode.loss_dice: 0.7004  decode.d0.loss_cls: 0.6142  decode.d0.loss_mask: 0.9359  decode.d0.loss_dice: 0.6658  decode.d1.loss_cls: 0.1169  decode.d1.loss_mask: 0.9906  decode.d1.loss_dice: 0.7120  decode.d2.loss_cls: 0.0977  decode.d2.loss_mask: 0.9996  decode.d2.loss_dice: 0.7022  decode.d3.loss_cls: 0.1128  decode.d3.loss_mask: 0.9952  decode.d3.loss_dice: 0.7064  decode.d4.loss_cls: 0.1286  decode.d4.loss_mask: 0.9906  decode.d4.loss_dice: 0.7002  decode.d5.loss_cls: 0.1105  decode.d5.loss_mask: 0.9986  decode.d5.loss_dice: 0.6938  decode.d6.loss_cls: 0.1281  decode.d6.loss_mask: 0.9676  decode.d6.loss_dice: 0.6864  decode.d7.loss_cls: 0.0961  decode.d7.loss_mask: 0.9950  decode.d7.loss_dice: 0.7025  decode.d8.loss_cls: 0.1027  decode.d8.loss_mask: 1.0015  decode.d8.loss_dice: 0.7009
05/26 22:58:13 - mmengine - INFO - Iter(train) [101600/160000]  base_lr: 4.0371e-05 lr: 4.0371e-06  eta: 6:41:52  time: 0.4156  data_time: 0.0099  memory: 5976  grad_norm: 547.4111  loss: 21.1845  decode.loss_cls: 0.1954  decode.loss_mask: 1.0749  decode.loss_dice: 0.7439  decode.d0.loss_cls: 0.6698  decode.d0.loss_mask: 1.0943  decode.d0.loss_dice: 0.7654  decode.d1.loss_cls: 0.2005  decode.d1.loss_mask: 1.1184  decode.d1.loss_dice: 0.7761  decode.d2.loss_cls: 0.2139  decode.d2.loss_mask: 1.0983  decode.d2.loss_dice: 0.7624  decode.d3.loss_cls: 0.1961  decode.d3.loss_mask: 1.1065  decode.d3.loss_dice: 0.7505  decode.d4.loss_cls: 0.2294  decode.d4.loss_mask: 1.1193  decode.d4.loss_dice: 0.7803  decode.d5.loss_cls: 0.2341  decode.d5.loss_mask: 1.1213  decode.d5.loss_dice: 0.7626  decode.d6.loss_cls: 0.2357  decode.d6.loss_mask: 1.0780  decode.d6.loss_dice: 0.7321  decode.d7.loss_cls: 0.2038  decode.d7.loss_mask: 1.1018  decode.d7.loss_dice: 0.7462  decode.d8.loss_cls: 0.2226  decode.d8.loss_mask: 1.1086  decode.d8.loss_dice: 0.7422
05/26 22:58:34 - mmengine - INFO - Iter(train) [101650/160000]  base_lr: 4.0340e-05 lr: 4.0340e-06  eta: 6:41:32  time: 0.4151  data_time: 0.0098  memory: 5967  grad_norm: 771.7619  loss: 19.2112  decode.loss_cls: 0.1950  decode.loss_mask: 0.9445  decode.loss_dice: 0.6779  decode.d0.loss_cls: 0.6619  decode.d0.loss_mask: 0.9119  decode.d0.loss_dice: 0.6983  decode.d1.loss_cls: 0.2087  decode.d1.loss_mask: 0.9703  decode.d1.loss_dice: 0.7246  decode.d2.loss_cls: 0.2219  decode.d2.loss_mask: 0.9670  decode.d2.loss_dice: 0.7172  decode.d3.loss_cls: 0.2525  decode.d3.loss_mask: 0.9228  decode.d3.loss_dice: 0.6992  decode.d4.loss_cls: 0.2152  decode.d4.loss_mask: 0.9759  decode.d4.loss_dice: 0.7097  decode.d5.loss_cls: 0.2253  decode.d5.loss_mask: 0.9505  decode.d5.loss_dice: 0.6925  decode.d6.loss_cls: 0.2174  decode.d6.loss_mask: 0.9556  decode.d6.loss_dice: 0.7078  decode.d7.loss_cls: 0.2335  decode.d7.loss_mask: 0.9731  decode.d7.loss_dice: 0.7023  decode.d8.loss_cls: 0.1865  decode.d8.loss_mask: 0.9712  decode.d8.loss_dice: 0.7211
05/26 22:58:55 - mmengine - INFO - Iter(train) [101700/160000]  base_lr: 4.0308e-05 lr: 4.0308e-06  eta: 6:41:11  time: 0.4140  data_time: 0.0101  memory: 5966  grad_norm: 561.2299  loss: 18.3712  decode.loss_cls: 0.1740  decode.loss_mask: 0.9409  decode.loss_dice: 0.6502  decode.d0.loss_cls: 0.6491  decode.d0.loss_mask: 0.9596  decode.d0.loss_dice: 0.6597  decode.d1.loss_cls: 0.2255  decode.d1.loss_mask: 0.9426  decode.d1.loss_dice: 0.6343  decode.d2.loss_cls: 0.2047  decode.d2.loss_mask: 0.9362  decode.d2.loss_dice: 0.6440  decode.d3.loss_cls: 0.1809  decode.d3.loss_mask: 0.9314  decode.d3.loss_dice: 0.6373  decode.d4.loss_cls: 0.1874  decode.d4.loss_mask: 0.9399  decode.d4.loss_dice: 0.6681  decode.d5.loss_cls: 0.1717  decode.d5.loss_mask: 0.9638  decode.d5.loss_dice: 0.6874  decode.d6.loss_cls: 0.1834  decode.d6.loss_mask: 0.9687  decode.d6.loss_dice: 0.6853  decode.d7.loss_cls: 0.1960  decode.d7.loss_mask: 0.9292  decode.d7.loss_dice: 0.6532  decode.d8.loss_cls: 0.1862  decode.d8.loss_mask: 0.9337  decode.d8.loss_dice: 0.6468
05/26 22:59:16 - mmengine - INFO - Iter(train) [101750/160000]  base_lr: 4.0277e-05 lr: 4.0277e-06  eta: 6:40:51  time: 0.4148  data_time: 0.0098  memory: 5966  grad_norm: 859.3561  loss: 21.7562  decode.loss_cls: 0.1364  decode.loss_mask: 1.1420  decode.loss_dice: 0.8397  decode.d0.loss_cls: 0.7366  decode.d0.loss_mask: 1.0796  decode.d0.loss_dice: 0.7811  decode.d1.loss_cls: 0.1561  decode.d1.loss_mask: 1.1497  decode.d1.loss_dice: 0.8167  decode.d2.loss_cls: 0.1936  decode.d2.loss_mask: 1.1318  decode.d2.loss_dice: 0.7987  decode.d3.loss_cls: 0.1725  decode.d3.loss_mask: 1.1425  decode.d3.loss_dice: 0.8153  decode.d4.loss_cls: 0.1527  decode.d4.loss_mask: 1.1568  decode.d4.loss_dice: 0.8302  decode.d5.loss_cls: 0.1786  decode.d5.loss_mask: 1.1612  decode.d5.loss_dice: 0.8184  decode.d6.loss_cls: 0.1986  decode.d6.loss_mask: 1.1347  decode.d6.loss_dice: 0.8100  decode.d7.loss_cls: 0.1398  decode.d7.loss_mask: 1.1576  decode.d7.loss_dice: 0.8169  decode.d8.loss_cls: 0.1600  decode.d8.loss_mask: 1.1317  decode.d8.loss_dice: 0.8166
05/26 22:59:37 - mmengine - INFO - Iter(train) [101800/160000]  base_lr: 4.0246e-05 lr: 4.0246e-06  eta: 6:40:30  time: 0.4218  data_time: 0.0098  memory: 5969  grad_norm: 658.2170  loss: 20.0544  decode.loss_cls: 0.1982  decode.loss_mask: 1.0388  decode.loss_dice: 0.7468  decode.d0.loss_cls: 0.6446  decode.d0.loss_mask: 0.9806  decode.d0.loss_dice: 0.7201  decode.d1.loss_cls: 0.2163  decode.d1.loss_mask: 1.0086  decode.d1.loss_dice: 0.7235  decode.d2.loss_cls: 0.2114  decode.d2.loss_mask: 1.0165  decode.d2.loss_dice: 0.7298  decode.d3.loss_cls: 0.2153  decode.d3.loss_mask: 1.0282  decode.d3.loss_dice: 0.7286  decode.d4.loss_cls: 0.2545  decode.d4.loss_mask: 1.0050  decode.d4.loss_dice: 0.6931  decode.d5.loss_cls: 0.2126  decode.d5.loss_mask: 1.0181  decode.d5.loss_dice: 0.7342  decode.d6.loss_cls: 0.1895  decode.d6.loss_mask: 1.0203  decode.d6.loss_dice: 0.7353  decode.d7.loss_cls: 0.2069  decode.d7.loss_mask: 1.0327  decode.d7.loss_dice: 0.7415  decode.d8.loss_cls: 0.1673  decode.d8.loss_mask: 1.0694  decode.d8.loss_dice: 0.7665
05/26 22:59:58 - mmengine - INFO - Iter(train) [101850/160000]  base_lr: 4.0215e-05 lr: 4.0215e-06  eta: 6:40:09  time: 0.4160  data_time: 0.0098  memory: 5972  grad_norm: 287.0696  loss: 18.8147  decode.loss_cls: 0.1787  decode.loss_mask: 0.9429  decode.loss_dice: 0.7325  decode.d0.loss_cls: 0.6824  decode.d0.loss_mask: 0.8363  decode.d0.loss_dice: 0.6742  decode.d1.loss_cls: 0.1968  decode.d1.loss_mask: 0.9191  decode.d1.loss_dice: 0.7295  decode.d2.loss_cls: 0.2027  decode.d2.loss_mask: 0.8979  decode.d2.loss_dice: 0.7145  decode.d3.loss_cls: 0.2053  decode.d3.loss_mask: 0.9303  decode.d3.loss_dice: 0.7358  decode.d4.loss_cls: 0.2184  decode.d4.loss_mask: 0.9128  decode.d4.loss_dice: 0.7143  decode.d5.loss_cls: 0.1980  decode.d5.loss_mask: 0.9312  decode.d5.loss_dice: 0.7233  decode.d6.loss_cls: 0.1876  decode.d6.loss_mask: 0.9367  decode.d6.loss_dice: 0.7243  decode.d7.loss_cls: 0.2191  decode.d7.loss_mask: 0.9124  decode.d7.loss_dice: 0.7250  decode.d8.loss_cls: 0.1838  decode.d8.loss_mask: 0.9179  decode.d8.loss_dice: 0.7311
05/26 23:00:18 - mmengine - INFO - Iter(train) [101900/160000]  base_lr: 4.0184e-05 lr: 4.0184e-06  eta: 6:39:49  time: 0.4156  data_time: 0.0099  memory: 5975  grad_norm: 311.4415  loss: 17.2763  decode.loss_cls: 0.1349  decode.loss_mask: 0.8232  decode.loss_dice: 0.6968  decode.d0.loss_cls: 0.6650  decode.d0.loss_mask: 0.7989  decode.d0.loss_dice: 0.6979  decode.d1.loss_cls: 0.1692  decode.d1.loss_mask: 0.8240  decode.d1.loss_dice: 0.6938  decode.d2.loss_cls: 0.1957  decode.d2.loss_mask: 0.8227  decode.d2.loss_dice: 0.6909  decode.d3.loss_cls: 0.1898  decode.d3.loss_mask: 0.8194  decode.d3.loss_dice: 0.6788  decode.d4.loss_cls: 0.1705  decode.d4.loss_mask: 0.8257  decode.d4.loss_dice: 0.6892  decode.d5.loss_cls: 0.1548  decode.d5.loss_mask: 0.8211  decode.d5.loss_dice: 0.6938  decode.d6.loss_cls: 0.1478  decode.d6.loss_mask: 0.8303  decode.d6.loss_dice: 0.7081  decode.d7.loss_cls: 0.1421  decode.d7.loss_mask: 0.8333  decode.d7.loss_dice: 0.6999  decode.d8.loss_cls: 0.1647  decode.d8.loss_mask: 0.7988  decode.d8.loss_dice: 0.6951
05/26 23:00:39 - mmengine - INFO - Iter(train) [101950/160000]  base_lr: 4.0153e-05 lr: 4.0153e-06  eta: 6:39:28  time: 0.4167  data_time: 0.0113  memory: 5968  grad_norm: 567.7709  loss: 18.9838  decode.loss_cls: 0.3024  decode.loss_mask: 0.8636  decode.loss_dice: 0.6378  decode.d0.loss_cls: 0.8609  decode.d0.loss_mask: 0.8044  decode.d0.loss_dice: 0.6263  decode.d1.loss_cls: 0.3181  decode.d1.loss_mask: 0.8895  decode.d1.loss_dice: 0.6752  decode.d2.loss_cls: 0.3070  decode.d2.loss_mask: 0.8934  decode.d2.loss_dice: 0.6420  decode.d3.loss_cls: 0.3289  decode.d3.loss_mask: 0.8732  decode.d3.loss_dice: 0.6795  decode.d4.loss_cls: 0.3023  decode.d4.loss_mask: 0.9178  decode.d4.loss_dice: 0.7004  decode.d5.loss_cls: 0.2998  decode.d5.loss_mask: 0.8916  decode.d5.loss_dice: 0.6429  decode.d6.loss_cls: 0.3206  decode.d6.loss_mask: 0.8712  decode.d6.loss_dice: 0.6522  decode.d7.loss_cls: 0.3228  decode.d7.loss_mask: 0.8904  decode.d7.loss_dice: 0.6621  decode.d8.loss_cls: 0.2973  decode.d8.loss_mask: 0.8708  decode.d8.loss_dice: 0.6396
05/26 23:01:00 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 23:01:00 - mmengine - INFO - Iter(train) [102000/160000]  base_lr: 4.0122e-05 lr: 4.0122e-06  eta: 6:39:08  time: 0.4160  data_time: 0.0098  memory: 5971  grad_norm: 428.9775  loss: 19.5293  decode.loss_cls: 0.2898  decode.loss_mask: 0.8506  decode.loss_dice: 0.7629  decode.d0.loss_cls: 0.7849  decode.d0.loss_mask: 0.8322  decode.d0.loss_dice: 0.7338  decode.d1.loss_cls: 0.2822  decode.d1.loss_mask: 0.8735  decode.d1.loss_dice: 0.8080  decode.d2.loss_cls: 0.2868  decode.d2.loss_mask: 0.8592  decode.d2.loss_dice: 0.7508  decode.d3.loss_cls: 0.3152  decode.d3.loss_mask: 0.8551  decode.d3.loss_dice: 0.7590  decode.d4.loss_cls: 0.2915  decode.d4.loss_mask: 0.8490  decode.d4.loss_dice: 0.7455  decode.d5.loss_cls: 0.3068  decode.d5.loss_mask: 0.8531  decode.d5.loss_dice: 0.7521  decode.d6.loss_cls: 0.3033  decode.d6.loss_mask: 0.8432  decode.d6.loss_dice: 0.7364  decode.d7.loss_cls: 0.3438  decode.d7.loss_mask: 0.8279  decode.d7.loss_dice: 0.7241  decode.d8.loss_cls: 0.3147  decode.d8.loss_mask: 0.8441  decode.d8.loss_dice: 0.7497
05/26 23:01:21 - mmengine - INFO - Iter(train) [102050/160000]  base_lr: 4.0091e-05 lr: 4.0091e-06  eta: 6:38:47  time: 0.4155  data_time: 0.0098  memory: 5968  grad_norm: 454.7396  loss: 19.1809  decode.loss_cls: 0.1106  decode.loss_mask: 1.0499  decode.loss_dice: 0.7025  decode.d0.loss_cls: 0.6221  decode.d0.loss_mask: 1.0072  decode.d0.loss_dice: 0.7306  decode.d1.loss_cls: 0.1021  decode.d1.loss_mask: 1.0149  decode.d1.loss_dice: 0.7165  decode.d2.loss_cls: 0.1574  decode.d2.loss_mask: 1.0343  decode.d2.loss_dice: 0.7094  decode.d3.loss_cls: 0.1481  decode.d3.loss_mask: 1.0352  decode.d3.loss_dice: 0.7316  decode.d4.loss_cls: 0.0986  decode.d4.loss_mask: 1.0491  decode.d4.loss_dice: 0.7144  decode.d5.loss_cls: 0.1162  decode.d5.loss_mask: 1.0534  decode.d5.loss_dice: 0.7062  decode.d6.loss_cls: 0.1274  decode.d6.loss_mask: 1.0518  decode.d6.loss_dice: 0.7096  decode.d7.loss_cls: 0.0964  decode.d7.loss_mask: 1.0284  decode.d7.loss_dice: 0.7050  decode.d8.loss_cls: 0.1102  decode.d8.loss_mask: 1.0148  decode.d8.loss_dice: 0.7271
05/26 23:01:42 - mmengine - INFO - Iter(train) [102100/160000]  base_lr: 4.0059e-05 lr: 4.0059e-06  eta: 6:38:27  time: 0.4146  data_time: 0.0099  memory: 5967  grad_norm: 472.8765  loss: 20.8956  decode.loss_cls: 0.1456  decode.loss_mask: 1.1012  decode.loss_dice: 0.7778  decode.d0.loss_cls: 0.6474  decode.d0.loss_mask: 1.0851  decode.d0.loss_dice: 0.7637  decode.d1.loss_cls: 0.1317  decode.d1.loss_mask: 1.1076  decode.d1.loss_dice: 0.7826  decode.d2.loss_cls: 0.1411  decode.d2.loss_mask: 1.1288  decode.d2.loss_dice: 0.7879  decode.d3.loss_cls: 0.1374  decode.d3.loss_mask: 1.1132  decode.d3.loss_dice: 0.7886  decode.d4.loss_cls: 0.1388  decode.d4.loss_mask: 1.1221  decode.d4.loss_dice: 0.7737  decode.d5.loss_cls: 0.1352  decode.d5.loss_mask: 1.1275  decode.d5.loss_dice: 0.7824  decode.d6.loss_cls: 0.1494  decode.d6.loss_mask: 1.1032  decode.d6.loss_dice: 0.7993  decode.d7.loss_cls: 0.1334  decode.d7.loss_mask: 1.1204  decode.d7.loss_dice: 0.7949  decode.d8.loss_cls: 0.1467  decode.d8.loss_mask: 1.1355  decode.d8.loss_dice: 0.7935
05/26 23:02:02 - mmengine - INFO - Iter(train) [102150/160000]  base_lr: 4.0028e-05 lr: 4.0028e-06  eta: 6:38:06  time: 0.4155  data_time: 0.0098  memory: 5970  grad_norm: 698.8077  loss: 22.5543  decode.loss_cls: 0.2489  decode.loss_mask: 1.2189  decode.loss_dice: 0.7417  decode.d0.loss_cls: 0.7080  decode.d0.loss_mask: 1.2058  decode.d0.loss_dice: 0.7305  decode.d1.loss_cls: 0.2068  decode.d1.loss_mask: 1.2617  decode.d1.loss_dice: 0.7520  decode.d2.loss_cls: 0.2300  decode.d2.loss_mask: 1.2564  decode.d2.loss_dice: 0.7521  decode.d3.loss_cls: 0.2149  decode.d3.loss_mask: 1.2424  decode.d3.loss_dice: 0.7550  decode.d4.loss_cls: 0.2339  decode.d4.loss_mask: 1.2352  decode.d4.loss_dice: 0.7460  decode.d5.loss_cls: 0.1929  decode.d5.loss_mask: 1.2394  decode.d5.loss_dice: 0.7585  decode.d6.loss_cls: 0.2051  decode.d6.loss_mask: 1.2393  decode.d6.loss_dice: 0.7633  decode.d7.loss_cls: 0.2537  decode.d7.loss_mask: 1.2179  decode.d7.loss_dice: 0.7602  decode.d8.loss_cls: 0.2256  decode.d8.loss_mask: 1.2032  decode.d8.loss_dice: 0.7551
05/26 23:02:23 - mmengine - INFO - Iter(train) [102200/160000]  base_lr: 3.9997e-05 lr: 3.9997e-06  eta: 6:37:45  time: 0.4153  data_time: 0.0099  memory: 5966  grad_norm: 389.2169  loss: 17.4747  decode.loss_cls: 0.2064  decode.loss_mask: 0.8681  decode.loss_dice: 0.6508  decode.d0.loss_cls: 0.6847  decode.d0.loss_mask: 0.8157  decode.d0.loss_dice: 0.6216  decode.d1.loss_cls: 0.1794  decode.d1.loss_mask: 0.8639  decode.d1.loss_dice: 0.6657  decode.d2.loss_cls: 0.2094  decode.d2.loss_mask: 0.8598  decode.d2.loss_dice: 0.6263  decode.d3.loss_cls: 0.2182  decode.d3.loss_mask: 0.8567  decode.d3.loss_dice: 0.6319  decode.d4.loss_cls: 0.2089  decode.d4.loss_mask: 0.8973  decode.d4.loss_dice: 0.6181  decode.d5.loss_cls: 0.1937  decode.d5.loss_mask: 0.9111  decode.d5.loss_dice: 0.6295  decode.d6.loss_cls: 0.1836  decode.d6.loss_mask: 0.8603  decode.d6.loss_dice: 0.6205  decode.d7.loss_cls: 0.1833  decode.d7.loss_mask: 0.8641  decode.d7.loss_dice: 0.6323  decode.d8.loss_cls: 0.2112  decode.d8.loss_mask: 0.8677  decode.d8.loss_dice: 0.6345
05/26 23:02:44 - mmengine - INFO - Iter(train) [102250/160000]  base_lr: 3.9966e-05 lr: 3.9966e-06  eta: 6:37:25  time: 0.4153  data_time: 0.0098  memory: 5967  grad_norm: 720.2857  loss: 19.5494  decode.loss_cls: 0.1708  decode.loss_mask: 1.0189  decode.loss_dice: 0.6511  decode.d0.loss_cls: 0.7384  decode.d0.loss_mask: 0.9788  decode.d0.loss_dice: 0.6747  decode.d1.loss_cls: 0.2465  decode.d1.loss_mask: 1.0593  decode.d1.loss_dice: 0.6694  decode.d2.loss_cls: 0.2330  decode.d2.loss_mask: 1.0452  decode.d2.loss_dice: 0.6951  decode.d3.loss_cls: 0.2298  decode.d3.loss_mask: 1.0283  decode.d3.loss_dice: 0.6788  decode.d4.loss_cls: 0.1709  decode.d4.loss_mask: 1.0463  decode.d4.loss_dice: 0.6682  decode.d5.loss_cls: 0.1511  decode.d5.loss_mask: 1.0397  decode.d5.loss_dice: 0.6641  decode.d6.loss_cls: 0.1817  decode.d6.loss_mask: 1.0332  decode.d6.loss_dice: 0.6732  decode.d7.loss_cls: 0.2094  decode.d7.loss_mask: 1.0278  decode.d7.loss_dice: 0.6870  decode.d8.loss_cls: 0.1790  decode.d8.loss_mask: 1.0305  decode.d8.loss_dice: 0.6691
05/26 23:03:05 - mmengine - INFO - Iter(train) [102300/160000]  base_lr: 3.9935e-05 lr: 3.9935e-06  eta: 6:37:04  time: 0.4150  data_time: 0.0098  memory: 5971  grad_norm: 484.1602  loss: 21.1039  decode.loss_cls: 0.1901  decode.loss_mask: 1.0905  decode.loss_dice: 0.7587  decode.d0.loss_cls: 0.5847  decode.d0.loss_mask: 1.0573  decode.d0.loss_dice: 0.7564  decode.d1.loss_cls: 0.1954  decode.d1.loss_mask: 1.0961  decode.d1.loss_dice: 0.7807  decode.d2.loss_cls: 0.2114  decode.d2.loss_mask: 1.1138  decode.d2.loss_dice: 0.7790  decode.d3.loss_cls: 0.1897  decode.d3.loss_mask: 1.1098  decode.d3.loss_dice: 0.7578  decode.d4.loss_cls: 0.2509  decode.d4.loss_mask: 1.0676  decode.d4.loss_dice: 0.7517  decode.d5.loss_cls: 0.2848  decode.d5.loss_mask: 1.0552  decode.d5.loss_dice: 0.7060  decode.d6.loss_cls: 0.2439  decode.d6.loss_mask: 1.0768  decode.d6.loss_dice: 0.7500  decode.d7.loss_cls: 0.2561  decode.d7.loss_mask: 1.1217  decode.d7.loss_dice: 0.7955  decode.d8.loss_cls: 0.2373  decode.d8.loss_mask: 1.0737  decode.d8.loss_dice: 0.7612
05/26 23:03:26 - mmengine - INFO - Iter(train) [102350/160000]  base_lr: 3.9904e-05 lr: 3.9904e-06  eta: 6:36:44  time: 0.4160  data_time: 0.0099  memory: 5983  grad_norm: 703.3168  loss: 24.7440  decode.loss_cls: 0.2496  decode.loss_mask: 1.2431  decode.loss_dice: 0.8194  decode.d0.loss_cls: 0.8028  decode.d0.loss_mask: 1.2084  decode.d0.loss_dice: 0.8222  decode.d1.loss_cls: 0.3184  decode.d1.loss_mask: 1.2889  decode.d1.loss_dice: 0.8563  decode.d2.loss_cls: 0.2952  decode.d2.loss_mask: 1.2922  decode.d2.loss_dice: 0.8620  decode.d3.loss_cls: 0.2605  decode.d3.loss_mask: 1.3230  decode.d3.loss_dice: 0.8239  decode.d4.loss_cls: 0.3090  decode.d4.loss_mask: 1.3324  decode.d4.loss_dice: 0.8514  decode.d5.loss_cls: 0.3243  decode.d5.loss_mask: 1.2723  decode.d5.loss_dice: 0.8430  decode.d6.loss_cls: 0.3116  decode.d6.loss_mask: 1.2639  decode.d6.loss_dice: 0.8760  decode.d7.loss_cls: 0.3104  decode.d7.loss_mask: 1.2937  decode.d7.loss_dice: 0.8524  decode.d8.loss_cls: 0.2976  decode.d8.loss_mask: 1.2902  decode.d8.loss_dice: 0.8496
05/26 23:03:47 - mmengine - INFO - Iter(train) [102400/160000]  base_lr: 3.9873e-05 lr: 3.9873e-06  eta: 6:36:23  time: 0.4163  data_time: 0.0098  memory: 5976  grad_norm: 725.5876  loss: 21.2164  decode.loss_cls: 0.1547  decode.loss_mask: 1.1616  decode.loss_dice: 0.7648  decode.d0.loss_cls: 0.7069  decode.d0.loss_mask: 1.0534  decode.d0.loss_dice: 0.7501  decode.d1.loss_cls: 0.1782  decode.d1.loss_mask: 1.2242  decode.d1.loss_dice: 0.7913  decode.d2.loss_cls: 0.2522  decode.d2.loss_mask: 1.0652  decode.d2.loss_dice: 0.7449  decode.d3.loss_cls: 0.2142  decode.d3.loss_mask: 1.0818  decode.d3.loss_dice: 0.7442  decode.d4.loss_cls: 0.2219  decode.d4.loss_mask: 1.1496  decode.d4.loss_dice: 0.7501  decode.d5.loss_cls: 0.1786  decode.d5.loss_mask: 1.0869  decode.d5.loss_dice: 0.7675  decode.d6.loss_cls: 0.2522  decode.d6.loss_mask: 1.0611  decode.d6.loss_dice: 0.7468  decode.d7.loss_cls: 0.2272  decode.d7.loss_mask: 1.1094  decode.d7.loss_dice: 0.7407  decode.d8.loss_cls: 0.2352  decode.d8.loss_mask: 1.0539  decode.d8.loss_dice: 0.7472
05/26 23:04:07 - mmengine - INFO - Iter(train) [102450/160000]  base_lr: 3.9841e-05 lr: 3.9841e-06  eta: 6:36:03  time: 0.4161  data_time: 0.0098  memory: 5971  grad_norm: 576.8203  loss: 18.7768  decode.loss_cls: 0.2042  decode.loss_mask: 0.9349  decode.loss_dice: 0.7016  decode.d0.loss_cls: 0.7631  decode.d0.loss_mask: 0.8687  decode.d0.loss_dice: 0.6367  decode.d1.loss_cls: 0.2810  decode.d1.loss_mask: 0.9224  decode.d1.loss_dice: 0.6693  decode.d2.loss_cls: 0.2347  decode.d2.loss_mask: 0.9144  decode.d2.loss_dice: 0.6626  decode.d3.loss_cls: 0.2777  decode.d3.loss_mask: 0.8985  decode.d3.loss_dice: 0.6563  decode.d4.loss_cls: 0.2614  decode.d4.loss_mask: 0.9078  decode.d4.loss_dice: 0.6724  decode.d5.loss_cls: 0.2433  decode.d5.loss_mask: 0.8813  decode.d5.loss_dice: 0.6654  decode.d6.loss_cls: 0.2261  decode.d6.loss_mask: 0.9149  decode.d6.loss_dice: 0.6828  decode.d7.loss_cls: 0.2431  decode.d7.loss_mask: 0.9075  decode.d7.loss_dice: 0.6756  decode.d8.loss_cls: 0.2610  decode.d8.loss_mask: 0.9198  decode.d8.loss_dice: 0.6882
05/26 23:04:28 - mmengine - INFO - Iter(train) [102500/160000]  base_lr: 3.9810e-05 lr: 3.9810e-06  eta: 6:35:42  time: 0.4153  data_time: 0.0098  memory: 5981  grad_norm: 506.3640  loss: 17.5725  decode.loss_cls: 0.1187  decode.loss_mask: 0.9056  decode.loss_dice: 0.6703  decode.d0.loss_cls: 0.6638  decode.d0.loss_mask: 0.8592  decode.d0.loss_dice: 0.6477  decode.d1.loss_cls: 0.1427  decode.d1.loss_mask: 0.9308  decode.d1.loss_dice: 0.6699  decode.d2.loss_cls: 0.1327  decode.d2.loss_mask: 0.9196  decode.d2.loss_dice: 0.6703  decode.d3.loss_cls: 0.1388  decode.d3.loss_mask: 0.9164  decode.d3.loss_dice: 0.6592  decode.d4.loss_cls: 0.1692  decode.d4.loss_mask: 0.9153  decode.d4.loss_dice: 0.6635  decode.d5.loss_cls: 0.1398  decode.d5.loss_mask: 0.8933  decode.d5.loss_dice: 0.6489  decode.d6.loss_cls: 0.1474  decode.d6.loss_mask: 0.8857  decode.d6.loss_dice: 0.6567  decode.d7.loss_cls: 0.1144  decode.d7.loss_mask: 0.9270  decode.d7.loss_dice: 0.6697  decode.d8.loss_cls: 0.1119  decode.d8.loss_mask: 0.9211  decode.d8.loss_dice: 0.6632
05/26 23:04:49 - mmengine - INFO - Iter(train) [102550/160000]  base_lr: 3.9779e-05 lr: 3.9779e-06  eta: 6:35:22  time: 0.4149  data_time: 0.0098  memory: 5976  grad_norm: 449.8640  loss: 17.1533  decode.loss_cls: 0.2610  decode.loss_mask: 0.7347  decode.loss_dice: 0.5981  decode.d0.loss_cls: 0.7217  decode.d0.loss_mask: 0.7282  decode.d0.loss_dice: 0.6157  decode.d1.loss_cls: 0.2893  decode.d1.loss_mask: 0.7767  decode.d1.loss_dice: 0.6306  decode.d2.loss_cls: 0.2450  decode.d2.loss_mask: 0.7593  decode.d2.loss_dice: 0.6362  decode.d3.loss_cls: 0.2613  decode.d3.loss_mask: 0.8283  decode.d3.loss_dice: 0.6300  decode.d4.loss_cls: 0.2772  decode.d4.loss_mask: 0.8260  decode.d4.loss_dice: 0.6189  decode.d5.loss_cls: 0.2763  decode.d5.loss_mask: 0.7614  decode.d5.loss_dice: 0.6497  decode.d6.loss_cls: 0.2744  decode.d6.loss_mask: 0.8286  decode.d6.loss_dice: 0.6306  decode.d7.loss_cls: 0.2812  decode.d7.loss_mask: 0.7837  decode.d7.loss_dice: 0.6223  decode.d8.loss_cls: 0.2344  decode.d8.loss_mask: 0.7676  decode.d8.loss_dice: 0.6048
05/26 23:05:10 - mmengine - INFO - Iter(train) [102600/160000]  base_lr: 3.9748e-05 lr: 3.9748e-06  eta: 6:35:01  time: 0.4165  data_time: 0.0098  memory: 5983  grad_norm: 691.1542  loss: 24.6035  decode.loss_cls: 0.2032  decode.loss_mask: 1.3131  decode.loss_dice: 0.8906  decode.d0.loss_cls: 0.6505  decode.d0.loss_mask: 1.2428  decode.d0.loss_dice: 0.8635  decode.d1.loss_cls: 0.2819  decode.d1.loss_mask: 1.2958  decode.d1.loss_dice: 0.9088  decode.d2.loss_cls: 0.2390  decode.d2.loss_mask: 1.2987  decode.d2.loss_dice: 0.8682  decode.d3.loss_cls: 0.2045  decode.d3.loss_mask: 1.3251  decode.d3.loss_dice: 0.8912  decode.d4.loss_cls: 0.1937  decode.d4.loss_mask: 1.3454  decode.d4.loss_dice: 0.8926  decode.d5.loss_cls: 0.2563  decode.d5.loss_mask: 1.3087  decode.d5.loss_dice: 0.8943  decode.d6.loss_cls: 0.2498  decode.d6.loss_mask: 1.3137  decode.d6.loss_dice: 0.8967  decode.d7.loss_cls: 0.2265  decode.d7.loss_mask: 1.2824  decode.d7.loss_dice: 0.8694  decode.d8.loss_cls: 0.2236  decode.d8.loss_mask: 1.2856  decode.d8.loss_dice: 0.8880
05/26 23:05:31 - mmengine - INFO - Iter(train) [102650/160000]  base_lr: 3.9717e-05 lr: 3.9717e-06  eta: 6:34:41  time: 0.4148  data_time: 0.0098  memory: 5965  grad_norm: 487.7998  loss: 19.3002  decode.loss_cls: 0.1786  decode.loss_mask: 1.0061  decode.loss_dice: 0.6645  decode.d0.loss_cls: 0.6658  decode.d0.loss_mask: 0.9786  decode.d0.loss_dice: 0.6692  decode.d1.loss_cls: 0.2173  decode.d1.loss_mask: 1.0232  decode.d1.loss_dice: 0.6778  decode.d2.loss_cls: 0.1870  decode.d2.loss_mask: 1.0095  decode.d2.loss_dice: 0.6642  decode.d3.loss_cls: 0.2003  decode.d3.loss_mask: 1.0093  decode.d3.loss_dice: 0.6820  decode.d4.loss_cls: 0.1915  decode.d4.loss_mask: 1.0067  decode.d4.loss_dice: 0.6724  decode.d5.loss_cls: 0.1677  decode.d5.loss_mask: 1.0484  decode.d5.loss_dice: 0.7030  decode.d6.loss_cls: 0.2175  decode.d6.loss_mask: 1.0199  decode.d6.loss_dice: 0.6880  decode.d7.loss_cls: 0.1997  decode.d7.loss_mask: 0.9997  decode.d7.loss_dice: 0.6805  decode.d8.loss_cls: 0.1941  decode.d8.loss_mask: 1.0082  decode.d8.loss_dice: 0.6694
05/26 23:05:52 - mmengine - INFO - Iter(train) [102700/160000]  base_lr: 3.9686e-05 lr: 3.9686e-06  eta: 6:34:20  time: 0.4161  data_time: 0.0098  memory: 5969  grad_norm: 613.7126  loss: 20.1408  decode.loss_cls: 0.2972  decode.loss_mask: 0.9400  decode.loss_dice: 0.7026  decode.d0.loss_cls: 0.7429  decode.d0.loss_mask: 0.9252  decode.d0.loss_dice: 0.7133  decode.d1.loss_cls: 0.3088  decode.d1.loss_mask: 0.9437  decode.d1.loss_dice: 0.6945  decode.d2.loss_cls: 0.3201  decode.d2.loss_mask: 0.9556  decode.d2.loss_dice: 0.7171  decode.d3.loss_cls: 0.2827  decode.d3.loss_mask: 1.0158  decode.d3.loss_dice: 0.7337  decode.d4.loss_cls: 0.3027  decode.d4.loss_mask: 1.0013  decode.d4.loss_dice: 0.7292  decode.d5.loss_cls: 0.2692  decode.d5.loss_mask: 0.9771  decode.d5.loss_dice: 0.6932  decode.d6.loss_cls: 0.3112  decode.d6.loss_mask: 0.9672  decode.d6.loss_dice: 0.7118  decode.d7.loss_cls: 0.3065  decode.d7.loss_mask: 0.9350  decode.d7.loss_dice: 0.6975  decode.d8.loss_cls: 0.3138  decode.d8.loss_mask: 0.9363  decode.d8.loss_dice: 0.6953
05/26 23:06:13 - mmengine - INFO - Iter(train) [102750/160000]  base_lr: 3.9654e-05 lr: 3.9654e-06  eta: 6:34:00  time: 0.4149  data_time: 0.0099  memory: 5997  grad_norm: 487.2019  loss: 23.3731  decode.loss_cls: 0.2297  decode.loss_mask: 1.2085  decode.loss_dice: 0.8368  decode.d0.loss_cls: 0.8139  decode.d0.loss_mask: 1.1109  decode.d0.loss_dice: 0.8133  decode.d1.loss_cls: 0.1792  decode.d1.loss_mask: 1.2063  decode.d1.loss_dice: 0.8461  decode.d2.loss_cls: 0.2324  decode.d2.loss_mask: 1.2084  decode.d2.loss_dice: 0.8562  decode.d3.loss_cls: 0.1927  decode.d3.loss_mask: 1.2213  decode.d3.loss_dice: 0.8809  decode.d4.loss_cls: 0.2108  decode.d4.loss_mask: 1.2320  decode.d4.loss_dice: 0.8720  decode.d5.loss_cls: 0.1977  decode.d5.loss_mask: 1.2463  decode.d5.loss_dice: 0.8737  decode.d6.loss_cls: 0.1910  decode.d6.loss_mask: 1.2374  decode.d6.loss_dice: 0.8755  decode.d7.loss_cls: 0.2181  decode.d7.loss_mask: 1.2205  decode.d7.loss_dice: 0.8515  decode.d8.loss_cls: 0.1871  decode.d8.loss_mask: 1.2492  decode.d8.loss_dice: 0.8738
05/26 23:06:33 - mmengine - INFO - Iter(train) [102800/160000]  base_lr: 3.9623e-05 lr: 3.9623e-06  eta: 6:33:39  time: 0.4155  data_time: 0.0098  memory: 5971  grad_norm: 484.0911  loss: 17.9758  decode.loss_cls: 0.1824  decode.loss_mask: 0.8907  decode.loss_dice: 0.6993  decode.d0.loss_cls: 0.6855  decode.d0.loss_mask: 0.8617  decode.d0.loss_dice: 0.6788  decode.d1.loss_cls: 0.1833  decode.d1.loss_mask: 0.8849  decode.d1.loss_dice: 0.6725  decode.d2.loss_cls: 0.1879  decode.d2.loss_mask: 0.8933  decode.d2.loss_dice: 0.6839  decode.d3.loss_cls: 0.1592  decode.d3.loss_mask: 0.8838  decode.d3.loss_dice: 0.7023  decode.d4.loss_cls: 0.1877  decode.d4.loss_mask: 0.8766  decode.d4.loss_dice: 0.6663  decode.d5.loss_cls: 0.1797  decode.d5.loss_mask: 0.8877  decode.d5.loss_dice: 0.6838  decode.d6.loss_cls: 0.1800  decode.d6.loss_mask: 0.8864  decode.d6.loss_dice: 0.6771  decode.d7.loss_cls: 0.1858  decode.d7.loss_mask: 0.8845  decode.d7.loss_dice: 0.6748  decode.d8.loss_cls: 0.1846  decode.d8.loss_mask: 0.8942  decode.d8.loss_dice: 0.6774
05/26 23:06:54 - mmengine - INFO - Iter(train) [102850/160000]  base_lr: 3.9592e-05 lr: 3.9592e-06  eta: 6:33:18  time: 0.4156  data_time: 0.0098  memory: 5968  grad_norm: 625.6859  loss: 20.2750  decode.loss_cls: 0.2711  decode.loss_mask: 1.0333  decode.loss_dice: 0.7472  decode.d0.loss_cls: 0.7316  decode.d0.loss_mask: 0.8729  decode.d0.loss_dice: 0.7322  decode.d1.loss_cls: 0.3182  decode.d1.loss_mask: 0.9857  decode.d1.loss_dice: 0.7219  decode.d2.loss_cls: 0.3401  decode.d2.loss_mask: 0.9187  decode.d2.loss_dice: 0.6975  decode.d3.loss_cls: 0.2615  decode.d3.loss_mask: 0.9761  decode.d3.loss_dice: 0.7561  decode.d4.loss_cls: 0.3161  decode.d4.loss_mask: 0.8984  decode.d4.loss_dice: 0.7144  decode.d5.loss_cls: 0.2931  decode.d5.loss_mask: 0.9460  decode.d5.loss_dice: 0.7180  decode.d6.loss_cls: 0.2813  decode.d6.loss_mask: 1.0376  decode.d6.loss_dice: 0.7726  decode.d7.loss_cls: 0.2774  decode.d7.loss_mask: 0.9450  decode.d7.loss_dice: 0.7201  decode.d8.loss_cls: 0.2428  decode.d8.loss_mask: 1.0277  decode.d8.loss_dice: 0.7206
05/26 23:07:15 - mmengine - INFO - Iter(train) [102900/160000]  base_lr: 3.9561e-05 lr: 3.9561e-06  eta: 6:32:58  time: 0.4147  data_time: 0.0098  memory: 5973  grad_norm: 630.7697  loss: 22.2919  decode.loss_cls: 0.2055  decode.loss_mask: 1.1848  decode.loss_dice: 0.7801  decode.d0.loss_cls: 0.7086  decode.d0.loss_mask: 1.1191  decode.d0.loss_dice: 0.7606  decode.d1.loss_cls: 0.2681  decode.d1.loss_mask: 1.1969  decode.d1.loss_dice: 0.7923  decode.d2.loss_cls: 0.2072  decode.d2.loss_mask: 1.1991  decode.d2.loss_dice: 0.7872  decode.d3.loss_cls: 0.2110  decode.d3.loss_mask: 1.1887  decode.d3.loss_dice: 0.7921  decode.d4.loss_cls: 0.1928  decode.d4.loss_mask: 1.2185  decode.d4.loss_dice: 0.7857  decode.d5.loss_cls: 0.1876  decode.d5.loss_mask: 1.2274  decode.d5.loss_dice: 0.7996  decode.d6.loss_cls: 0.1711  decode.d6.loss_mask: 1.2116  decode.d6.loss_dice: 0.7724  decode.d7.loss_cls: 0.2260  decode.d7.loss_mask: 1.1716  decode.d7.loss_dice: 0.7643  decode.d8.loss_cls: 0.2087  decode.d8.loss_mask: 1.1881  decode.d8.loss_dice: 0.7651
05/26 23:07:36 - mmengine - INFO - Iter(train) [102950/160000]  base_lr: 3.9530e-05 lr: 3.9530e-06  eta: 6:32:37  time: 0.4158  data_time: 0.0098  memory: 5966  grad_norm: 474.9935  loss: 19.5644  decode.loss_cls: 0.1396  decode.loss_mask: 1.0396  decode.loss_dice: 0.7327  decode.d0.loss_cls: 0.5823  decode.d0.loss_mask: 0.9989  decode.d0.loss_dice: 0.7307  decode.d1.loss_cls: 0.1515  decode.d1.loss_mask: 1.0491  decode.d1.loss_dice: 0.7325  decode.d2.loss_cls: 0.1419  decode.d2.loss_mask: 1.0196  decode.d2.loss_dice: 0.7399  decode.d3.loss_cls: 0.1570  decode.d3.loss_mask: 1.0210  decode.d3.loss_dice: 0.7306  decode.d4.loss_cls: 0.1494  decode.d4.loss_mask: 1.0305  decode.d4.loss_dice: 0.7379  decode.d5.loss_cls: 0.1281  decode.d5.loss_mask: 1.0305  decode.d5.loss_dice: 0.7361  decode.d6.loss_cls: 0.1295  decode.d6.loss_mask: 1.0367  decode.d6.loss_dice: 0.7614  decode.d7.loss_cls: 0.1487  decode.d7.loss_mask: 1.0605  decode.d7.loss_dice: 0.7467  decode.d8.loss_cls: 0.1341  decode.d8.loss_mask: 1.0263  decode.d8.loss_dice: 0.7412
05/26 23:07:57 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 23:07:57 - mmengine - INFO - Iter(train) [103000/160000]  base_lr: 3.9499e-05 lr: 3.9499e-06  eta: 6:32:17  time: 0.4131  data_time: 0.0098  memory: 5981  grad_norm: 683.8042  loss: 19.8586  decode.loss_cls: 0.2163  decode.loss_mask: 0.9564  decode.loss_dice: 0.7764  decode.d0.loss_cls: 0.6899  decode.d0.loss_mask: 0.9624  decode.d0.loss_dice: 0.7279  decode.d1.loss_cls: 0.2148  decode.d1.loss_mask: 0.9911  decode.d1.loss_dice: 0.7418  decode.d2.loss_cls: 0.2510  decode.d2.loss_mask: 1.0077  decode.d2.loss_dice: 0.7333  decode.d3.loss_cls: 0.2682  decode.d3.loss_mask: 0.9895  decode.d3.loss_dice: 0.7282  decode.d4.loss_cls: 0.2251  decode.d4.loss_mask: 0.9698  decode.d4.loss_dice: 0.7483  decode.d5.loss_cls: 0.2083  decode.d5.loss_mask: 0.9629  decode.d5.loss_dice: 0.7523  decode.d6.loss_cls: 0.2161  decode.d6.loss_mask: 0.9544  decode.d6.loss_dice: 0.7485  decode.d7.loss_cls: 0.2035  decode.d7.loss_mask: 0.9723  decode.d7.loss_dice: 0.7397  decode.d8.loss_cls: 0.2118  decode.d8.loss_mask: 0.9500  decode.d8.loss_dice: 0.7404
05/26 23:08:17 - mmengine - INFO - Iter(train) [103050/160000]  base_lr: 3.9467e-05 lr: 3.9467e-06  eta: 6:31:56  time: 0.4150  data_time: 0.0098  memory: 5971  grad_norm: 921.4797  loss: 21.8798  decode.loss_cls: 0.1827  decode.loss_mask: 1.2181  decode.loss_dice: 0.7041  decode.d0.loss_cls: 0.7237  decode.d0.loss_mask: 1.1685  decode.d0.loss_dice: 0.7117  decode.d1.loss_cls: 0.1997  decode.d1.loss_mask: 1.2226  decode.d1.loss_dice: 0.7049  decode.d2.loss_cls: 0.2561  decode.d2.loss_mask: 1.1825  decode.d2.loss_dice: 0.7024  decode.d3.loss_cls: 0.1757  decode.d3.loss_mask: 1.2397  decode.d3.loss_dice: 0.7331  decode.d4.loss_cls: 0.1943  decode.d4.loss_mask: 1.2360  decode.d4.loss_dice: 0.7214  decode.d5.loss_cls: 0.1868  decode.d5.loss_mask: 1.2456  decode.d5.loss_dice: 0.7290  decode.d6.loss_cls: 0.1833  decode.d6.loss_mask: 1.2492  decode.d6.loss_dice: 0.7452  decode.d7.loss_cls: 0.1887  decode.d7.loss_mask: 1.2195  decode.d7.loss_dice: 0.7293  decode.d8.loss_cls: 0.2085  decode.d8.loss_mask: 1.2186  decode.d8.loss_dice: 0.6991
05/26 23:08:38 - mmengine - INFO - Iter(train) [103100/160000]  base_lr: 3.9436e-05 lr: 3.9436e-06  eta: 6:31:36  time: 0.4145  data_time: 0.0098  memory: 5966  grad_norm: 963.3172  loss: 21.0311  decode.loss_cls: 0.2719  decode.loss_mask: 1.0303  decode.loss_dice: 0.7148  decode.d0.loss_cls: 0.7855  decode.d0.loss_mask: 1.0643  decode.d0.loss_dice: 0.7367  decode.d1.loss_cls: 0.3068  decode.d1.loss_mask: 1.0585  decode.d1.loss_dice: 0.7281  decode.d2.loss_cls: 0.2852  decode.d2.loss_mask: 1.0488  decode.d2.loss_dice: 0.7365  decode.d3.loss_cls: 0.2594  decode.d3.loss_mask: 1.0470  decode.d3.loss_dice: 0.7056  decode.d4.loss_cls: 0.2976  decode.d4.loss_mask: 1.0553  decode.d4.loss_dice: 0.7218  decode.d5.loss_cls: 0.2862  decode.d5.loss_mask: 1.0481  decode.d5.loss_dice: 0.7199  decode.d6.loss_cls: 0.2984  decode.d6.loss_mask: 1.0308  decode.d6.loss_dice: 0.7108  decode.d7.loss_cls: 0.2827  decode.d7.loss_mask: 1.0642  decode.d7.loss_dice: 0.7270  decode.d8.loss_cls: 0.2558  decode.d8.loss_mask: 1.0392  decode.d8.loss_dice: 0.7137
05/26 23:08:59 - mmengine - INFO - Iter(train) [103150/160000]  base_lr: 3.9405e-05 lr: 3.9405e-06  eta: 6:31:15  time: 0.4152  data_time: 0.0097  memory: 5980  grad_norm: 565.0676  loss: 21.1555  decode.loss_cls: 0.2546  decode.loss_mask: 1.0055  decode.loss_dice: 0.7978  decode.d0.loss_cls: 0.9442  decode.d0.loss_mask: 0.9175  decode.d0.loss_dice: 0.7047  decode.d1.loss_cls: 0.3204  decode.d1.loss_mask: 0.9723  decode.d1.loss_dice: 0.7545  decode.d2.loss_cls: 0.3193  decode.d2.loss_mask: 0.9626  decode.d2.loss_dice: 0.7545  decode.d3.loss_cls: 0.3068  decode.d3.loss_mask: 1.0115  decode.d3.loss_dice: 0.7654  decode.d4.loss_cls: 0.2952  decode.d4.loss_mask: 0.9611  decode.d4.loss_dice: 0.7879  decode.d5.loss_cls: 0.2949  decode.d5.loss_mask: 1.0280  decode.d5.loss_dice: 0.7799  decode.d6.loss_cls: 0.2919  decode.d6.loss_mask: 0.9825  decode.d6.loss_dice: 0.7821  decode.d7.loss_cls: 0.3251  decode.d7.loss_mask: 0.9762  decode.d7.loss_dice: 0.8135  decode.d8.loss_cls: 0.2828  decode.d8.loss_mask: 0.9894  decode.d8.loss_dice: 0.7733
05/26 23:09:20 - mmengine - INFO - Iter(train) [103200/160000]  base_lr: 3.9374e-05 lr: 3.9374e-06  eta: 6:30:54  time: 0.4138  data_time: 0.0097  memory: 5975  grad_norm: 498.1821  loss: 21.4945  decode.loss_cls: 0.3034  decode.loss_mask: 1.0197  decode.loss_dice: 0.7997  decode.d0.loss_cls: 0.7162  decode.d0.loss_mask: 1.0561  decode.d0.loss_dice: 0.7789  decode.d1.loss_cls: 0.3335  decode.d1.loss_mask: 1.1029  decode.d1.loss_dice: 0.7636  decode.d2.loss_cls: 0.2939  decode.d2.loss_mask: 1.0634  decode.d2.loss_dice: 0.7486  decode.d3.loss_cls: 0.3232  decode.d3.loss_mask: 1.0635  decode.d3.loss_dice: 0.7293  decode.d4.loss_cls: 0.3951  decode.d4.loss_mask: 1.0401  decode.d4.loss_dice: 0.7319  decode.d5.loss_cls: 0.2627  decode.d5.loss_mask: 1.0617  decode.d5.loss_dice: 0.7437  decode.d6.loss_cls: 0.2508  decode.d6.loss_mask: 1.0709  decode.d6.loss_dice: 0.7678  decode.d7.loss_cls: 0.2806  decode.d7.loss_mask: 0.9993  decode.d7.loss_dice: 0.7732  decode.d8.loss_cls: 0.2458  decode.d8.loss_mask: 1.0179  decode.d8.loss_dice: 0.7573
05/26 23:09:40 - mmengine - INFO - Iter(train) [103250/160000]  base_lr: 3.9343e-05 lr: 3.9343e-06  eta: 6:30:34  time: 0.4152  data_time: 0.0098  memory: 5967  grad_norm: 470.6365  loss: 20.2803  decode.loss_cls: 0.1505  decode.loss_mask: 1.1260  decode.loss_dice: 0.7476  decode.d0.loss_cls: 0.6212  decode.d0.loss_mask: 1.0852  decode.d0.loss_dice: 0.7254  decode.d1.loss_cls: 0.1591  decode.d1.loss_mask: 1.1170  decode.d1.loss_dice: 0.7475  decode.d2.loss_cls: 0.1746  decode.d2.loss_mask: 1.1155  decode.d2.loss_dice: 0.7305  decode.d3.loss_cls: 0.1829  decode.d3.loss_mask: 1.0964  decode.d3.loss_dice: 0.6958  decode.d4.loss_cls: 0.1733  decode.d4.loss_mask: 1.0817  decode.d4.loss_dice: 0.6860  decode.d5.loss_cls: 0.1750  decode.d5.loss_mask: 1.0888  decode.d5.loss_dice: 0.7037  decode.d6.loss_cls: 0.1692  decode.d6.loss_mask: 1.0788  decode.d6.loss_dice: 0.7434  decode.d7.loss_cls: 0.1618  decode.d7.loss_mask: 1.0795  decode.d7.loss_dice: 0.7079  decode.d8.loss_cls: 0.1435  decode.d8.loss_mask: 1.0993  decode.d8.loss_dice: 0.7131
05/26 23:10:01 - mmengine - INFO - Iter(train) [103300/160000]  base_lr: 3.9311e-05 lr: 3.9311e-06  eta: 6:30:13  time: 0.4387  data_time: 0.0097  memory: 5967  grad_norm: 635.3556  loss: 21.5044  decode.loss_cls: 0.2252  decode.loss_mask: 1.0943  decode.loss_dice: 0.7939  decode.d0.loss_cls: 0.7286  decode.d0.loss_mask: 1.0521  decode.d0.loss_dice: 0.7683  decode.d1.loss_cls: 0.2397  decode.d1.loss_mask: 1.0877  decode.d1.loss_dice: 0.8214  decode.d2.loss_cls: 0.2174  decode.d2.loss_mask: 1.0446  decode.d2.loss_dice: 0.7940  decode.d3.loss_cls: 0.2103  decode.d3.loss_mask: 1.0824  decode.d3.loss_dice: 0.8008  decode.d4.loss_cls: 0.2302  decode.d4.loss_mask: 1.0756  decode.d4.loss_dice: 0.7687  decode.d5.loss_cls: 0.2550  decode.d5.loss_mask: 1.0865  decode.d5.loss_dice: 0.7742  decode.d6.loss_cls: 0.2566  decode.d6.loss_mask: 1.0497  decode.d6.loss_dice: 0.8039  decode.d7.loss_cls: 0.2438  decode.d7.loss_mask: 1.0702  decode.d7.loss_dice: 0.8067  decode.d8.loss_cls: 0.2255  decode.d8.loss_mask: 1.0827  decode.d8.loss_dice: 0.8145
05/26 23:10:22 - mmengine - INFO - Iter(train) [103350/160000]  base_lr: 3.9280e-05 lr: 3.9280e-06  eta: 6:29:53  time: 0.4129  data_time: 0.0097  memory: 5975  grad_norm: 391.8865  loss: 18.5115  decode.loss_cls: 0.2357  decode.loss_mask: 0.8921  decode.loss_dice: 0.6852  decode.d0.loss_cls: 0.6046  decode.d0.loss_mask: 0.8891  decode.d0.loss_dice: 0.6681  decode.d1.loss_cls: 0.2796  decode.d1.loss_mask: 0.8724  decode.d1.loss_dice: 0.6804  decode.d2.loss_cls: 0.2773  decode.d2.loss_mask: 0.9058  decode.d2.loss_dice: 0.6737  decode.d3.loss_cls: 0.2303  decode.d3.loss_mask: 0.9035  decode.d3.loss_dice: 0.6549  decode.d4.loss_cls: 0.2794  decode.d4.loss_mask: 0.8908  decode.d4.loss_dice: 0.6660  decode.d5.loss_cls: 0.2982  decode.d5.loss_mask: 0.8659  decode.d5.loss_dice: 0.6661  decode.d6.loss_cls: 0.2894  decode.d6.loss_mask: 0.8698  decode.d6.loss_dice: 0.6655  decode.d7.loss_cls: 0.1991  decode.d7.loss_mask: 0.8998  decode.d7.loss_dice: 0.6755  decode.d8.loss_cls: 0.2286  decode.d8.loss_mask: 0.9005  decode.d8.loss_dice: 0.6645
05/26 23:10:43 - mmengine - INFO - Iter(train) [103400/160000]  base_lr: 3.9249e-05 lr: 3.9249e-06  eta: 6:29:32  time: 0.4141  data_time: 0.0098  memory: 5971  grad_norm: 532.7423  loss: 21.7261  decode.loss_cls: 0.2501  decode.loss_mask: 1.0323  decode.loss_dice: 0.8234  decode.d0.loss_cls: 0.8976  decode.d0.loss_mask: 0.9766  decode.d0.loss_dice: 0.7920  decode.d1.loss_cls: 0.3231  decode.d1.loss_mask: 1.0041  decode.d1.loss_dice: 0.8082  decode.d2.loss_cls: 0.3121  decode.d2.loss_mask: 1.0004  decode.d2.loss_dice: 0.8086  decode.d3.loss_cls: 0.2666  decode.d3.loss_mask: 1.0150  decode.d3.loss_dice: 0.8080  decode.d4.loss_cls: 0.2707  decode.d4.loss_mask: 1.0241  decode.d4.loss_dice: 0.8202  decode.d5.loss_cls: 0.2430  decode.d5.loss_mask: 1.0202  decode.d5.loss_dice: 0.8241  decode.d6.loss_cls: 0.2787  decode.d6.loss_mask: 1.0252  decode.d6.loss_dice: 0.8190  decode.d7.loss_cls: 0.2629  decode.d7.loss_mask: 1.0615  decode.d7.loss_dice: 0.8289  decode.d8.loss_cls: 0.2618  decode.d8.loss_mask: 1.0420  decode.d8.loss_dice: 0.8254
05/26 23:11:03 - mmengine - INFO - Iter(train) [103450/160000]  base_lr: 3.9218e-05 lr: 3.9218e-06  eta: 6:29:11  time: 0.4138  data_time: 0.0097  memory: 5972  grad_norm: 625.3026  loss: 16.4008  decode.loss_cls: 0.1373  decode.loss_mask: 0.8017  decode.loss_dice: 0.6149  decode.d0.loss_cls: 0.6168  decode.d0.loss_mask: 0.8002  decode.d0.loss_dice: 0.5883  decode.d1.loss_cls: 0.0923  decode.d1.loss_mask: 0.8508  decode.d1.loss_dice: 0.6769  decode.d2.loss_cls: 0.1138  decode.d2.loss_mask: 0.8335  decode.d2.loss_dice: 0.6586  decode.d3.loss_cls: 0.1263  decode.d3.loss_mask: 0.8257  decode.d3.loss_dice: 0.6534  decode.d4.loss_cls: 0.0856  decode.d4.loss_mask: 0.8343  decode.d4.loss_dice: 0.6927  decode.d5.loss_cls: 0.1022  decode.d5.loss_mask: 0.8351  decode.d5.loss_dice: 0.6598  decode.d6.loss_cls: 0.1164  decode.d6.loss_mask: 0.8365  decode.d6.loss_dice: 0.6540  decode.d7.loss_cls: 0.1409  decode.d7.loss_mask: 0.8375  decode.d7.loss_dice: 0.6197  decode.d8.loss_cls: 0.1176  decode.d8.loss_mask: 0.8299  decode.d8.loss_dice: 0.6481
05/26 23:11:24 - mmengine - INFO - Iter(train) [103500/160000]  base_lr: 3.9187e-05 lr: 3.9187e-06  eta: 6:28:51  time: 0.4134  data_time: 0.0097  memory: 5983  grad_norm: 386.1374  loss: 20.2424  decode.loss_cls: 0.2329  decode.loss_mask: 1.0529  decode.loss_dice: 0.7041  decode.d0.loss_cls: 0.6308  decode.d0.loss_mask: 1.0369  decode.d0.loss_dice: 0.6735  decode.d1.loss_cls: 0.2288  decode.d1.loss_mask: 1.0603  decode.d1.loss_dice: 0.7056  decode.d2.loss_cls: 0.2576  decode.d2.loss_mask: 1.0119  decode.d2.loss_dice: 0.6796  decode.d3.loss_cls: 0.2455  decode.d3.loss_mask: 1.0111  decode.d3.loss_dice: 0.6908  decode.d4.loss_cls: 0.2255  decode.d4.loss_mask: 1.0337  decode.d4.loss_dice: 0.6922  decode.d5.loss_cls: 0.2490  decode.d5.loss_mask: 1.0710  decode.d5.loss_dice: 0.7117  decode.d6.loss_cls: 0.2669  decode.d6.loss_mask: 1.0617  decode.d6.loss_dice: 0.6981  decode.d7.loss_cls: 0.2656  decode.d7.loss_mask: 1.0165  decode.d7.loss_dice: 0.6958  decode.d8.loss_cls: 0.2343  decode.d8.loss_mask: 1.0813  decode.d8.loss_dice: 0.7166
05/26 23:11:45 - mmengine - INFO - Iter(train) [103550/160000]  base_lr: 3.9155e-05 lr: 3.9155e-06  eta: 6:28:30  time: 0.4135  data_time: 0.0098  memory: 5986  grad_norm: 516.9923  loss: 20.4656  decode.loss_cls: 0.1861  decode.loss_mask: 0.9280  decode.loss_dice: 0.8675  decode.d0.loss_cls: 0.7802  decode.d0.loss_mask: 0.8513  decode.d0.loss_dice: 0.8343  decode.d1.loss_cls: 0.2171  decode.d1.loss_mask: 0.9245  decode.d1.loss_dice: 0.8541  decode.d2.loss_cls: 0.1880  decode.d2.loss_mask: 0.8981  decode.d2.loss_dice: 0.8651  decode.d3.loss_cls: 0.1989  decode.d3.loss_mask: 0.9102  decode.d3.loss_dice: 0.8710  decode.d4.loss_cls: 0.2318  decode.d4.loss_mask: 0.9462  decode.d4.loss_dice: 0.8976  decode.d5.loss_cls: 0.2174  decode.d5.loss_mask: 0.9462  decode.d5.loss_dice: 0.8550  decode.d6.loss_cls: 0.1740  decode.d6.loss_mask: 0.9373  decode.d6.loss_dice: 0.8901  decode.d7.loss_cls: 0.1999  decode.d7.loss_mask: 0.9257  decode.d7.loss_dice: 0.8558  decode.d8.loss_cls: 0.1971  decode.d8.loss_mask: 0.9421  decode.d8.loss_dice: 0.8751
05/26 23:12:06 - mmengine - INFO - Iter(train) [103600/160000]  base_lr: 3.9124e-05 lr: 3.9124e-06  eta: 6:28:10  time: 0.4139  data_time: 0.0097  memory: 5972  grad_norm: 745.3293  loss: 21.7185  decode.loss_cls: 0.1586  decode.loss_mask: 1.2061  decode.loss_dice: 0.7642  decode.d0.loss_cls: 0.7317  decode.d0.loss_mask: 1.1268  decode.d0.loss_dice: 0.7252  decode.d1.loss_cls: 0.1962  decode.d1.loss_mask: 1.2164  decode.d1.loss_dice: 0.7575  decode.d2.loss_cls: 0.1816  decode.d2.loss_mask: 1.2071  decode.d2.loss_dice: 0.7438  decode.d3.loss_cls: 0.1862  decode.d3.loss_mask: 1.1928  decode.d3.loss_dice: 0.7603  decode.d4.loss_cls: 0.1550  decode.d4.loss_mask: 1.1842  decode.d4.loss_dice: 0.7385  decode.d5.loss_cls: 0.1954  decode.d5.loss_mask: 1.1810  decode.d5.loss_dice: 0.7476  decode.d6.loss_cls: 0.1841  decode.d6.loss_mask: 1.2071  decode.d6.loss_dice: 0.7536  decode.d7.loss_cls: 0.1693  decode.d7.loss_mask: 1.1923  decode.d7.loss_dice: 0.7319  decode.d8.loss_cls: 0.1746  decode.d8.loss_mask: 1.2003  decode.d8.loss_dice: 0.7494
05/26 23:12:26 - mmengine - INFO - Iter(train) [103650/160000]  base_lr: 3.9093e-05 lr: 3.9093e-06  eta: 6:27:49  time: 0.4136  data_time: 0.0098  memory: 5969  grad_norm: 488.4933  loss: 20.7412  decode.loss_cls: 0.1879  decode.loss_mask: 1.0319  decode.loss_dice: 0.8076  decode.d0.loss_cls: 0.6203  decode.d0.loss_mask: 1.0173  decode.d0.loss_dice: 0.7581  decode.d1.loss_cls: 0.2283  decode.d1.loss_mask: 1.0760  decode.d1.loss_dice: 0.8131  decode.d2.loss_cls: 0.1858  decode.d2.loss_mask: 1.0691  decode.d2.loss_dice: 0.8019  decode.d3.loss_cls: 0.1651  decode.d3.loss_mask: 1.0220  decode.d3.loss_dice: 0.7880  decode.d4.loss_cls: 0.1877  decode.d4.loss_mask: 1.0515  decode.d4.loss_dice: 0.8000  decode.d5.loss_cls: 0.1798  decode.d5.loss_mask: 1.0495  decode.d5.loss_dice: 0.8049  decode.d6.loss_cls: 0.1812  decode.d6.loss_mask: 1.0385  decode.d6.loss_dice: 0.8064  decode.d7.loss_cls: 0.2143  decode.d7.loss_mask: 1.0243  decode.d7.loss_dice: 0.8005  decode.d8.loss_cls: 0.2044  decode.d8.loss_mask: 1.0229  decode.d8.loss_dice: 0.8026
05/26 23:12:47 - mmengine - INFO - Iter(train) [103700/160000]  base_lr: 3.9062e-05 lr: 3.9062e-06  eta: 6:27:28  time: 0.4137  data_time: 0.0098  memory: 5989  grad_norm: 789.9701  loss: 21.6581  decode.loss_cls: 0.3225  decode.loss_mask: 1.0111  decode.loss_dice: 0.8199  decode.d0.loss_cls: 0.7393  decode.d0.loss_mask: 0.9364  decode.d0.loss_dice: 0.7572  decode.d1.loss_cls: 0.2294  decode.d1.loss_mask: 1.0321  decode.d1.loss_dice: 0.8575  decode.d2.loss_cls: 0.3072  decode.d2.loss_mask: 1.0032  decode.d2.loss_dice: 0.7986  decode.d3.loss_cls: 0.2949  decode.d3.loss_mask: 0.9883  decode.d3.loss_dice: 0.8449  decode.d4.loss_cls: 0.3150  decode.d4.loss_mask: 1.0027  decode.d4.loss_dice: 0.7983  decode.d5.loss_cls: 0.3012  decode.d5.loss_mask: 0.9932  decode.d5.loss_dice: 0.8234  decode.d6.loss_cls: 0.2904  decode.d6.loss_mask: 1.0134  decode.d6.loss_dice: 0.8441  decode.d7.loss_cls: 0.3224  decode.d7.loss_mask: 1.0284  decode.d7.loss_dice: 0.8392  decode.d8.loss_cls: 0.2831  decode.d8.loss_mask: 1.0176  decode.d8.loss_dice: 0.8431
05/26 23:13:08 - mmengine - INFO - Iter(train) [103750/160000]  base_lr: 3.9031e-05 lr: 3.9031e-06  eta: 6:27:08  time: 0.4141  data_time: 0.0097  memory: 5974  grad_norm: 428.1482  loss: 21.3179  decode.loss_cls: 0.1279  decode.loss_mask: 1.1428  decode.loss_dice: 0.8312  decode.d0.loss_cls: 0.6315  decode.d0.loss_mask: 1.1328  decode.d0.loss_dice: 0.8135  decode.d1.loss_cls: 0.2007  decode.d1.loss_mask: 1.1243  decode.d1.loss_dice: 0.7952  decode.d2.loss_cls: 0.1570  decode.d2.loss_mask: 1.1384  decode.d2.loss_dice: 0.7901  decode.d3.loss_cls: 0.1526  decode.d3.loss_mask: 1.1267  decode.d3.loss_dice: 0.7990  decode.d4.loss_cls: 0.1600  decode.d4.loss_mask: 1.1320  decode.d4.loss_dice: 0.7911  decode.d5.loss_cls: 0.1391  decode.d5.loss_mask: 1.1339  decode.d5.loss_dice: 0.8059  decode.d6.loss_cls: 0.1548  decode.d6.loss_mask: 1.1302  decode.d6.loss_dice: 0.8051  decode.d7.loss_cls: 0.1334  decode.d7.loss_mask: 1.1267  decode.d7.loss_dice: 0.7889  decode.d8.loss_cls: 0.1575  decode.d8.loss_mask: 1.1096  decode.d8.loss_dice: 0.7859
05/26 23:13:29 - mmengine - INFO - Iter(train) [103800/160000]  base_lr: 3.8999e-05 lr: 3.8999e-06  eta: 6:26:47  time: 0.4133  data_time: 0.0097  memory: 5988  grad_norm: 744.9497  loss: 20.8853  decode.loss_cls: 0.2056  decode.loss_mask: 1.1526  decode.loss_dice: 0.7110  decode.d0.loss_cls: 0.6810  decode.d0.loss_mask: 1.0856  decode.d0.loss_dice: 0.6813  decode.d1.loss_cls: 0.2162  decode.d1.loss_mask: 1.1401  decode.d1.loss_dice: 0.7011  decode.d2.loss_cls: 0.1510  decode.d2.loss_mask: 1.2419  decode.d2.loss_dice: 0.7268  decode.d3.loss_cls: 0.1805  decode.d3.loss_mask: 1.1307  decode.d3.loss_dice: 0.6827  decode.d4.loss_cls: 0.1589  decode.d4.loss_mask: 1.1601  decode.d4.loss_dice: 0.7025  decode.d5.loss_cls: 0.2037  decode.d5.loss_mask: 1.1318  decode.d5.loss_dice: 0.6961  decode.d6.loss_cls: 0.1714  decode.d6.loss_mask: 1.1893  decode.d6.loss_dice: 0.7084  decode.d7.loss_cls: 0.1431  decode.d7.loss_mask: 1.1817  decode.d7.loss_dice: 0.7065  decode.d8.loss_cls: 0.1416  decode.d8.loss_mask: 1.1874  decode.d8.loss_dice: 0.7145
05/26 23:13:49 - mmengine - INFO - Iter(train) [103850/160000]  base_lr: 3.8968e-05 lr: 3.8968e-06  eta: 6:26:27  time: 0.4134  data_time: 0.0098  memory: 5969  grad_norm: 662.4363  loss: 20.3009  decode.loss_cls: 0.1111  decode.loss_mask: 1.1201  decode.loss_dice: 0.7223  decode.d0.loss_cls: 0.6572  decode.d0.loss_mask: 1.1178  decode.d0.loss_dice: 0.7136  decode.d1.loss_cls: 0.1185  decode.d1.loss_mask: 1.1263  decode.d1.loss_dice: 0.7727  decode.d2.loss_cls: 0.1574  decode.d2.loss_mask: 1.1315  decode.d2.loss_dice: 0.7496  decode.d3.loss_cls: 0.1453  decode.d3.loss_mask: 1.1084  decode.d3.loss_dice: 0.7376  decode.d4.loss_cls: 0.1152  decode.d4.loss_mask: 1.1104  decode.d4.loss_dice: 0.7400  decode.d5.loss_cls: 0.1080  decode.d5.loss_mask: 1.1247  decode.d5.loss_dice: 0.7404  decode.d6.loss_cls: 0.1157  decode.d6.loss_mask: 1.1057  decode.d6.loss_dice: 0.7431  decode.d7.loss_cls: 0.1171  decode.d7.loss_mask: 1.0977  decode.d7.loss_dice: 0.7192  decode.d8.loss_cls: 0.1052  decode.d8.loss_mask: 1.1287  decode.d8.loss_dice: 0.7403
05/26 23:14:10 - mmengine - INFO - Iter(train) [103900/160000]  base_lr: 3.8937e-05 lr: 3.8937e-06  eta: 6:26:06  time: 0.4145  data_time: 0.0098  memory: 5971  grad_norm: 664.0459  loss: 17.6945  decode.loss_cls: 0.1437  decode.loss_mask: 0.9159  decode.loss_dice: 0.6601  decode.d0.loss_cls: 0.6970  decode.d0.loss_mask: 0.8345  decode.d0.loss_dice: 0.6071  decode.d1.loss_cls: 0.2226  decode.d1.loss_mask: 0.8280  decode.d1.loss_dice: 0.6264  decode.d2.loss_cls: 0.1713  decode.d2.loss_mask: 0.9042  decode.d2.loss_dice: 0.6307  decode.d3.loss_cls: 0.1702  decode.d3.loss_mask: 0.9092  decode.d3.loss_dice: 0.6443  decode.d4.loss_cls: 0.1920  decode.d4.loss_mask: 0.9649  decode.d4.loss_dice: 0.6548  decode.d5.loss_cls: 0.2050  decode.d5.loss_mask: 0.8452  decode.d5.loss_dice: 0.6137  decode.d6.loss_cls: 0.1905  decode.d6.loss_mask: 0.9044  decode.d6.loss_dice: 0.6407  decode.d7.loss_cls: 0.1746  decode.d7.loss_mask: 0.9885  decode.d7.loss_dice: 0.6613  decode.d8.loss_cls: 0.1472  decode.d8.loss_mask: 0.9057  decode.d8.loss_dice: 0.6405
05/26 23:14:31 - mmengine - INFO - Iter(train) [103950/160000]  base_lr: 3.8906e-05 lr: 3.8906e-06  eta: 6:25:45  time: 0.4144  data_time: 0.0097  memory: 5969  grad_norm: 592.8422  loss: 22.0407  decode.loss_cls: 0.2206  decode.loss_mask: 1.0862  decode.loss_dice: 0.8659  decode.d0.loss_cls: 0.7183  decode.d0.loss_mask: 1.0676  decode.d0.loss_dice: 0.8548  decode.d1.loss_cls: 0.2346  decode.d1.loss_mask: 1.1170  decode.d1.loss_dice: 0.8999  decode.d2.loss_cls: 0.2493  decode.d2.loss_mask: 1.0912  decode.d2.loss_dice: 0.8762  decode.d3.loss_cls: 0.2018  decode.d3.loss_mask: 1.0749  decode.d3.loss_dice: 0.8514  decode.d4.loss_cls: 0.2099  decode.d4.loss_mask: 1.0612  decode.d4.loss_dice: 0.8565  decode.d5.loss_cls: 0.2060  decode.d5.loss_mask: 1.0499  decode.d5.loss_dice: 0.8372  decode.d6.loss_cls: 0.2070  decode.d6.loss_mask: 1.0625  decode.d6.loss_dice: 0.8455  decode.d7.loss_cls: 0.2021  decode.d7.loss_mask: 1.1078  decode.d7.loss_dice: 0.8662  decode.d8.loss_cls: 0.2037  decode.d8.loss_mask: 1.0801  decode.d8.loss_dice: 0.8358
05/26 23:14:51 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 23:14:51 - mmengine - INFO - Iter(train) [104000/160000]  base_lr: 3.8874e-05 lr: 3.8874e-06  eta: 6:25:25  time: 0.4139  data_time: 0.0097  memory: 5975  grad_norm: 579.4907  loss: 23.8057  decode.loss_cls: 0.2198  decode.loss_mask: 1.2325  decode.loss_dice: 0.8654  decode.d0.loss_cls: 0.8277  decode.d0.loss_mask: 1.1841  decode.d0.loss_dice: 0.8090  decode.d1.loss_cls: 0.2866  decode.d1.loss_mask: 1.1963  decode.d1.loss_dice: 0.8384  decode.d2.loss_cls: 0.2661  decode.d2.loss_mask: 1.2307  decode.d2.loss_dice: 0.8457  decode.d3.loss_cls: 0.2307  decode.d3.loss_mask: 1.1881  decode.d3.loss_dice: 0.8310  decode.d4.loss_cls: 0.2579  decode.d4.loss_mask: 1.2371  decode.d4.loss_dice: 0.8535  decode.d5.loss_cls: 0.2427  decode.d5.loss_mask: 1.2325  decode.d5.loss_dice: 0.8637  decode.d6.loss_cls: 0.2508  decode.d6.loss_mask: 1.2371  decode.d6.loss_dice: 0.8651  decode.d7.loss_cls: 0.2309  decode.d7.loss_mask: 1.2455  decode.d7.loss_dice: 0.8887  decode.d8.loss_cls: 0.2419  decode.d8.loss_mask: 1.2392  decode.d8.loss_dice: 0.8671
05/26 23:15:12 - mmengine - INFO - Iter(train) [104050/160000]  base_lr: 3.8843e-05 lr: 3.8843e-06  eta: 6:25:04  time: 0.4134  data_time: 0.0098  memory: 5972  grad_norm: 510.0802  loss: 17.8932  decode.loss_cls: 0.2993  decode.loss_mask: 0.7680  decode.loss_dice: 0.6732  decode.d0.loss_cls: 0.7215  decode.d0.loss_mask: 0.7690  decode.d0.loss_dice: 0.6705  decode.d1.loss_cls: 0.2618  decode.d1.loss_mask: 0.8301  decode.d1.loss_dice: 0.7183  decode.d2.loss_cls: 0.2942  decode.d2.loss_mask: 0.7642  decode.d2.loss_dice: 0.6879  decode.d3.loss_cls: 0.2341  decode.d3.loss_mask: 0.8104  decode.d3.loss_dice: 0.6819  decode.d4.loss_cls: 0.2697  decode.d4.loss_mask: 0.7703  decode.d4.loss_dice: 0.6845  decode.d5.loss_cls: 0.2064  decode.d5.loss_mask: 0.8143  decode.d5.loss_dice: 0.7098  decode.d6.loss_cls: 0.2613  decode.d6.loss_mask: 0.7880  decode.d6.loss_dice: 0.7127  decode.d7.loss_cls: 0.2609  decode.d7.loss_mask: 0.8056  decode.d7.loss_dice: 0.7019  decode.d8.loss_cls: 0.2469  decode.d8.loss_mask: 0.7790  decode.d8.loss_dice: 0.6973
05/26 23:15:33 - mmengine - INFO - Iter(train) [104100/160000]  base_lr: 3.8812e-05 lr: 3.8812e-06  eta: 6:24:43  time: 0.4139  data_time: 0.0098  memory: 5975  grad_norm: 847.5416  loss: 21.3242  decode.loss_cls: 0.1209  decode.loss_mask: 1.2210  decode.loss_dice: 0.8251  decode.d0.loss_cls: 0.5946  decode.d0.loss_mask: 1.1353  decode.d0.loss_dice: 0.7757  decode.d1.loss_cls: 0.2129  decode.d1.loss_mask: 1.1146  decode.d1.loss_dice: 0.7430  decode.d2.loss_cls: 0.1551  decode.d2.loss_mask: 1.1600  decode.d2.loss_dice: 0.7768  decode.d3.loss_cls: 0.1592  decode.d3.loss_mask: 1.1489  decode.d3.loss_dice: 0.7894  decode.d4.loss_cls: 0.1438  decode.d4.loss_mask: 1.1503  decode.d4.loss_dice: 0.7837  decode.d5.loss_cls: 0.1652  decode.d5.loss_mask: 1.1052  decode.d5.loss_dice: 0.7726  decode.d6.loss_cls: 0.1072  decode.d6.loss_mask: 1.1618  decode.d6.loss_dice: 0.8102  decode.d7.loss_cls: 0.1672  decode.d7.loss_mask: 1.1249  decode.d7.loss_dice: 0.7810  decode.d8.loss_cls: 0.1435  decode.d8.loss_mask: 1.1637  decode.d8.loss_dice: 0.8115
05/26 23:15:54 - mmengine - INFO - Iter(train) [104150/160000]  base_lr: 3.8781e-05 lr: 3.8781e-06  eta: 6:24:23  time: 0.4149  data_time: 0.0099  memory: 5969  grad_norm: 1128.5896  loss: 17.9981  decode.loss_cls: 0.1447  decode.loss_mask: 0.9281  decode.loss_dice: 0.6372  decode.d0.loss_cls: 0.6590  decode.d0.loss_mask: 0.8776  decode.d0.loss_dice: 0.6185  decode.d1.loss_cls: 0.1933  decode.d1.loss_mask: 0.9316  decode.d1.loss_dice: 0.6146  decode.d2.loss_cls: 0.1902  decode.d2.loss_mask: 0.9257  decode.d2.loss_dice: 0.6271  decode.d3.loss_cls: 0.1775  decode.d3.loss_mask: 0.9499  decode.d3.loss_dice: 0.6209  decode.d4.loss_cls: 0.2010  decode.d4.loss_mask: 0.9389  decode.d4.loss_dice: 0.6376  decode.d5.loss_cls: 0.2295  decode.d5.loss_mask: 0.9370  decode.d5.loss_dice: 0.6245  decode.d6.loss_cls: 0.2315  decode.d6.loss_mask: 0.9549  decode.d6.loss_dice: 0.6413  decode.d7.loss_cls: 0.1889  decode.d7.loss_mask: 0.9398  decode.d7.loss_dice: 0.6235  decode.d8.loss_cls: 0.1789  decode.d8.loss_mask: 0.9398  decode.d8.loss_dice: 0.6351
05/26 23:16:14 - mmengine - INFO - Iter(train) [104200/160000]  base_lr: 3.8749e-05 lr: 3.8749e-06  eta: 6:24:02  time: 0.4129  data_time: 0.0098  memory: 5966  grad_norm: 380.8113  loss: 18.0051  decode.loss_cls: 0.1230  decode.loss_mask: 0.9200  decode.loss_dice: 0.7172  decode.d0.loss_cls: 0.5862  decode.d0.loss_mask: 0.8983  decode.d0.loss_dice: 0.7030  decode.d1.loss_cls: 0.1215  decode.d1.loss_mask: 0.9305  decode.d1.loss_dice: 0.7199  decode.d2.loss_cls: 0.0920  decode.d2.loss_mask: 0.9247  decode.d2.loss_dice: 0.7243  decode.d3.loss_cls: 0.1236  decode.d3.loss_mask: 0.9075  decode.d3.loss_dice: 0.7118  decode.d4.loss_cls: 0.1262  decode.d4.loss_mask: 0.9074  decode.d4.loss_dice: 0.7120  decode.d5.loss_cls: 0.1115  decode.d5.loss_mask: 0.9295  decode.d5.loss_dice: 0.7147  decode.d6.loss_cls: 0.1110  decode.d6.loss_mask: 0.9212  decode.d6.loss_dice: 0.7177  decode.d7.loss_cls: 0.1236  decode.d7.loss_mask: 0.9311  decode.d7.loss_dice: 0.7201  decode.d8.loss_cls: 0.1203  decode.d8.loss_mask: 0.9366  decode.d8.loss_dice: 0.7189
05/26 23:16:35 - mmengine - INFO - Iter(train) [104250/160000]  base_lr: 3.8718e-05 lr: 3.8718e-06  eta: 6:23:42  time: 0.4137  data_time: 0.0098  memory: 5980  grad_norm: 894.2893  loss: 22.4226  decode.loss_cls: 0.2701  decode.loss_mask: 1.1809  decode.loss_dice: 0.7760  decode.d0.loss_cls: 0.7678  decode.d0.loss_mask: 1.0689  decode.d0.loss_dice: 0.7062  decode.d1.loss_cls: 0.2687  decode.d1.loss_mask: 1.1423  decode.d1.loss_dice: 0.7640  decode.d2.loss_cls: 0.2791  decode.d2.loss_mask: 1.1765  decode.d2.loss_dice: 0.7598  decode.d3.loss_cls: 0.2492  decode.d3.loss_mask: 1.1567  decode.d3.loss_dice: 0.8104  decode.d4.loss_cls: 0.2654  decode.d4.loss_mask: 1.1517  decode.d4.loss_dice: 0.7805  decode.d5.loss_cls: 0.2693  decode.d5.loss_mask: 1.1460  decode.d5.loss_dice: 0.7570  decode.d6.loss_cls: 0.2881  decode.d6.loss_mask: 1.1345  decode.d6.loss_dice: 0.7873  decode.d7.loss_cls: 0.3198  decode.d7.loss_mask: 1.1634  decode.d7.loss_dice: 0.7547  decode.d8.loss_cls: 0.3521  decode.d8.loss_mask: 1.1246  decode.d8.loss_dice: 0.7516
05/26 23:16:56 - mmengine - INFO - Iter(train) [104300/160000]  base_lr: 3.8687e-05 lr: 3.8687e-06  eta: 6:23:21  time: 0.4142  data_time: 0.0098  memory: 5988  grad_norm: 481.6476  loss: 22.0900  decode.loss_cls: 0.2892  decode.loss_mask: 1.0022  decode.loss_dice: 0.8674  decode.d0.loss_cls: 0.7718  decode.d0.loss_mask: 0.9361  decode.d0.loss_dice: 0.8103  decode.d1.loss_cls: 0.2624  decode.d1.loss_mask: 1.0105  decode.d1.loss_dice: 0.8679  decode.d2.loss_cls: 0.2524  decode.d2.loss_mask: 1.0204  decode.d2.loss_dice: 0.8957  decode.d3.loss_cls: 0.2685  decode.d3.loss_mask: 0.9993  decode.d3.loss_dice: 0.8887  decode.d4.loss_cls: 0.2544  decode.d4.loss_mask: 1.0253  decode.d4.loss_dice: 0.8880  decode.d5.loss_cls: 0.2709  decode.d5.loss_mask: 0.9995  decode.d5.loss_dice: 0.8870  decode.d6.loss_cls: 0.2998  decode.d6.loss_mask: 1.0096  decode.d6.loss_dice: 0.8786  decode.d7.loss_cls: 0.3330  decode.d7.loss_mask: 1.0226  decode.d7.loss_dice: 0.8737  decode.d8.loss_cls: 0.3217  decode.d8.loss_mask: 1.0073  decode.d8.loss_dice: 0.8760
05/26 23:17:17 - mmengine - INFO - Iter(train) [104350/160000]  base_lr: 3.8656e-05 lr: 3.8656e-06  eta: 6:23:00  time: 0.4250  data_time: 0.0098  memory: 5966  grad_norm: 568.8885  loss: 19.0892  decode.loss_cls: 0.1844  decode.loss_mask: 0.9917  decode.loss_dice: 0.6895  decode.d0.loss_cls: 0.6928  decode.d0.loss_mask: 0.9530  decode.d0.loss_dice: 0.6514  decode.d1.loss_cls: 0.1911  decode.d1.loss_mask: 0.9834  decode.d1.loss_dice: 0.7063  decode.d2.loss_cls: 0.1844  decode.d2.loss_mask: 0.9993  decode.d2.loss_dice: 0.6869  decode.d3.loss_cls: 0.1916  decode.d3.loss_mask: 1.0047  decode.d3.loss_dice: 0.6768  decode.d4.loss_cls: 0.1975  decode.d4.loss_mask: 1.0017  decode.d4.loss_dice: 0.6805  decode.d5.loss_cls: 0.1716  decode.d5.loss_mask: 0.9902  decode.d5.loss_dice: 0.7040  decode.d6.loss_cls: 0.1892  decode.d6.loss_mask: 0.9723  decode.d6.loss_dice: 0.6747  decode.d7.loss_cls: 0.1669  decode.d7.loss_mask: 1.0096  decode.d7.loss_dice: 0.6988  decode.d8.loss_cls: 0.1827  decode.d8.loss_mask: 0.9833  decode.d8.loss_dice: 0.6789
05/26 23:17:37 - mmengine - INFO - Iter(train) [104400/160000]  base_lr: 3.8624e-05 lr: 3.8624e-06  eta: 6:22:40  time: 0.4148  data_time: 0.0098  memory: 5980  grad_norm: 489.1102  loss: 17.9413  decode.loss_cls: 0.2256  decode.loss_mask: 0.8706  decode.loss_dice: 0.6567  decode.d0.loss_cls: 0.7024  decode.d0.loss_mask: 0.8371  decode.d0.loss_dice: 0.6128  decode.d1.loss_cls: 0.2006  decode.d1.loss_mask: 0.8878  decode.d1.loss_dice: 0.6663  decode.d2.loss_cls: 0.1869  decode.d2.loss_mask: 0.9160  decode.d2.loss_dice: 0.6885  decode.d3.loss_cls: 0.2018  decode.d3.loss_mask: 0.8881  decode.d3.loss_dice: 0.6743  decode.d4.loss_cls: 0.2045  decode.d4.loss_mask: 0.8724  decode.d4.loss_dice: 0.6682  decode.d5.loss_cls: 0.1980  decode.d5.loss_mask: 0.8847  decode.d5.loss_dice: 0.6663  decode.d6.loss_cls: 0.1986  decode.d6.loss_mask: 0.8667  decode.d6.loss_dice: 0.6688  decode.d7.loss_cls: 0.1869  decode.d7.loss_mask: 0.8983  decode.d7.loss_dice: 0.6679  decode.d8.loss_cls: 0.2025  decode.d8.loss_mask: 0.8900  decode.d8.loss_dice: 0.6520
05/26 23:17:58 - mmengine - INFO - Iter(train) [104450/160000]  base_lr: 3.8593e-05 lr: 3.8593e-06  eta: 6:22:19  time: 0.4145  data_time: 0.0099  memory: 5971  grad_norm: 780.5346  loss: 20.9340  decode.loss_cls: 0.2520  decode.loss_mask: 1.0186  decode.loss_dice: 0.6811  decode.d0.loss_cls: 0.7171  decode.d0.loss_mask: 1.0238  decode.d0.loss_dice: 0.7100  decode.d1.loss_cls: 0.2858  decode.d1.loss_mask: 1.0803  decode.d1.loss_dice: 0.7752  decode.d2.loss_cls: 0.2902  decode.d2.loss_mask: 1.0191  decode.d2.loss_dice: 0.7222  decode.d3.loss_cls: 0.2724  decode.d3.loss_mask: 1.0344  decode.d3.loss_dice: 0.7149  decode.d4.loss_cls: 0.2639  decode.d4.loss_mask: 1.0774  decode.d4.loss_dice: 0.7078  decode.d5.loss_cls: 0.2590  decode.d5.loss_mask: 1.0688  decode.d5.loss_dice: 0.7593  decode.d6.loss_cls: 0.2978  decode.d6.loss_mask: 1.0324  decode.d6.loss_dice: 0.7242  decode.d7.loss_cls: 0.2905  decode.d7.loss_mask: 1.0467  decode.d7.loss_dice: 0.7169  decode.d8.loss_cls: 0.2721  decode.d8.loss_mask: 1.1044  decode.d8.loss_dice: 0.7157
05/26 23:18:19 - mmengine - INFO - Iter(train) [104500/160000]  base_lr: 3.8562e-05 lr: 3.8562e-06  eta: 6:21:59  time: 0.4138  data_time: 0.0098  memory: 5974  grad_norm: 762.1065  loss: 20.8990  decode.loss_cls: 0.2050  decode.loss_mask: 1.1187  decode.loss_dice: 0.7063  decode.d0.loss_cls: 0.7376  decode.d0.loss_mask: 1.0863  decode.d0.loss_dice: 0.7150  decode.d1.loss_cls: 0.2023  decode.d1.loss_mask: 1.0851  decode.d1.loss_dice: 0.7164  decode.d2.loss_cls: 0.2068  decode.d2.loss_mask: 1.1151  decode.d2.loss_dice: 0.7259  decode.d3.loss_cls: 0.1784  decode.d3.loss_mask: 1.1035  decode.d3.loss_dice: 0.7136  decode.d4.loss_cls: 0.1994  decode.d4.loss_mask: 1.1102  decode.d4.loss_dice: 0.7133  decode.d5.loss_cls: 0.2386  decode.d5.loss_mask: 1.1224  decode.d5.loss_dice: 0.7228  decode.d6.loss_cls: 0.2367  decode.d6.loss_mask: 1.0783  decode.d6.loss_dice: 0.7131  decode.d7.loss_cls: 0.1758  decode.d7.loss_mask: 1.1812  decode.d7.loss_dice: 0.7116  decode.d8.loss_cls: 0.1900  decode.d8.loss_mask: 1.1696  decode.d8.loss_dice: 0.7202
05/26 23:18:40 - mmengine - INFO - Iter(train) [104550/160000]  base_lr: 3.8531e-05 lr: 3.8531e-06  eta: 6:21:38  time: 0.4152  data_time: 0.0098  memory: 5967  grad_norm: 626.8919  loss: 19.0029  decode.loss_cls: 0.2596  decode.loss_mask: 0.8780  decode.loss_dice: 0.6884  decode.d0.loss_cls: 0.7177  decode.d0.loss_mask: 0.8893  decode.d0.loss_dice: 0.6877  decode.d1.loss_cls: 0.2699  decode.d1.loss_mask: 0.9110  decode.d1.loss_dice: 0.7219  decode.d2.loss_cls: 0.2340  decode.d2.loss_mask: 0.9246  decode.d2.loss_dice: 0.7048  decode.d3.loss_cls: 0.2614  decode.d3.loss_mask: 0.8975  decode.d3.loss_dice: 0.7171  decode.d4.loss_cls: 0.2543  decode.d4.loss_mask: 0.8896  decode.d4.loss_dice: 0.6860  decode.d5.loss_cls: 0.2933  decode.d5.loss_mask: 0.8728  decode.d5.loss_dice: 0.6849  decode.d6.loss_cls: 0.2855  decode.d6.loss_mask: 0.8684  decode.d6.loss_dice: 0.6964  decode.d7.loss_cls: 0.2772  decode.d7.loss_mask: 0.8790  decode.d7.loss_dice: 0.6754  decode.d8.loss_cls: 0.2561  decode.d8.loss_mask: 0.9132  decode.d8.loss_dice: 0.7077
05/26 23:19:00 - mmengine - INFO - Iter(train) [104600/160000]  base_lr: 3.8499e-05 lr: 3.8499e-06  eta: 6:21:17  time: 0.4148  data_time: 0.0098  memory: 5966  grad_norm: 591.7028  loss: 19.7526  decode.loss_cls: 0.1603  decode.loss_mask: 1.1010  decode.loss_dice: 0.6739  decode.d0.loss_cls: 0.5696  decode.d0.loss_mask: 1.0431  decode.d0.loss_dice: 0.6792  decode.d1.loss_cls: 0.1498  decode.d1.loss_mask: 1.1268  decode.d1.loss_dice: 0.7284  decode.d2.loss_cls: 0.1338  decode.d2.loss_mask: 1.1283  decode.d2.loss_dice: 0.7115  decode.d3.loss_cls: 0.1740  decode.d3.loss_mask: 1.0633  decode.d3.loss_dice: 0.6885  decode.d4.loss_cls: 0.1199  decode.d4.loss_mask: 1.1175  decode.d4.loss_dice: 0.6900  decode.d5.loss_cls: 0.1143  decode.d5.loss_mask: 1.1517  decode.d5.loss_dice: 0.6920  decode.d6.loss_cls: 0.1095  decode.d6.loss_mask: 1.1128  decode.d6.loss_dice: 0.6975  decode.d7.loss_cls: 0.1097  decode.d7.loss_mask: 1.1633  decode.d7.loss_dice: 0.6848  decode.d8.loss_cls: 0.1292  decode.d8.loss_mask: 1.0729  decode.d8.loss_dice: 0.6560
05/26 23:19:21 - mmengine - INFO - Iter(train) [104650/160000]  base_lr: 3.8468e-05 lr: 3.8468e-06  eta: 6:20:57  time: 0.4143  data_time: 0.0098  memory: 5970  grad_norm: 314.7885  loss: 19.6768  decode.loss_cls: 0.2073  decode.loss_mask: 1.0173  decode.loss_dice: 0.6884  decode.d0.loss_cls: 0.7105  decode.d0.loss_mask: 0.9606  decode.d0.loss_dice: 0.6867  decode.d1.loss_cls: 0.2494  decode.d1.loss_mask: 1.0261  decode.d1.loss_dice: 0.6845  decode.d2.loss_cls: 0.2059  decode.d2.loss_mask: 1.0334  decode.d2.loss_dice: 0.7088  decode.d3.loss_cls: 0.2029  decode.d3.loss_mask: 1.0326  decode.d3.loss_dice: 0.7050  decode.d4.loss_cls: 0.2204  decode.d4.loss_mask: 1.0224  decode.d4.loss_dice: 0.6796  decode.d5.loss_cls: 0.2086  decode.d5.loss_mask: 1.0105  decode.d5.loss_dice: 0.6704  decode.d6.loss_cls: 0.1995  decode.d6.loss_mask: 1.0242  decode.d6.loss_dice: 0.6906  decode.d7.loss_cls: 0.2391  decode.d7.loss_mask: 1.0183  decode.d7.loss_dice: 0.6804  decode.d8.loss_cls: 0.2052  decode.d8.loss_mask: 1.0120  decode.d8.loss_dice: 0.6761
05/26 23:19:42 - mmengine - INFO - Iter(train) [104700/160000]  base_lr: 3.8437e-05 lr: 3.8437e-06  eta: 6:20:36  time: 0.4142  data_time: 0.0097  memory: 5990  grad_norm: 516.1527  loss: 19.3501  decode.loss_cls: 0.2009  decode.loss_mask: 1.0364  decode.loss_dice: 0.7154  decode.d0.loss_cls: 0.6273  decode.d0.loss_mask: 0.9893  decode.d0.loss_dice: 0.6592  decode.d1.loss_cls: 0.1454  decode.d1.loss_mask: 1.0228  decode.d1.loss_dice: 0.6862  decode.d2.loss_cls: 0.1696  decode.d2.loss_mask: 1.0555  decode.d2.loss_dice: 0.7073  decode.d3.loss_cls: 0.1137  decode.d3.loss_mask: 1.0182  decode.d3.loss_dice: 0.6782  decode.d4.loss_cls: 0.1585  decode.d4.loss_mask: 0.9886  decode.d4.loss_dice: 0.7096  decode.d5.loss_cls: 0.1697  decode.d5.loss_mask: 1.0705  decode.d5.loss_dice: 0.7207  decode.d6.loss_cls: 0.1496  decode.d6.loss_mask: 1.0349  decode.d6.loss_dice: 0.6952  decode.d7.loss_cls: 0.1912  decode.d7.loss_mask: 1.0195  decode.d7.loss_dice: 0.7155  decode.d8.loss_cls: 0.1809  decode.d8.loss_mask: 1.0176  decode.d8.loss_dice: 0.7027
05/26 23:20:03 - mmengine - INFO - Iter(train) [104750/160000]  base_lr: 3.8406e-05 lr: 3.8406e-06  eta: 6:20:16  time: 0.4137  data_time: 0.0098  memory: 5969  grad_norm: 545.1503  loss: 20.9090  decode.loss_cls: 0.2312  decode.loss_mask: 1.0714  decode.loss_dice: 0.7312  decode.d0.loss_cls: 0.7530  decode.d0.loss_mask: 1.0413  decode.d0.loss_dice: 0.7008  decode.d1.loss_cls: 0.1972  decode.d1.loss_mask: 1.1192  decode.d1.loss_dice: 0.7863  decode.d2.loss_cls: 0.1981  decode.d2.loss_mask: 1.0933  decode.d2.loss_dice: 0.7506  decode.d3.loss_cls: 0.2009  decode.d3.loss_mask: 1.0870  decode.d3.loss_dice: 0.7401  decode.d4.loss_cls: 0.2150  decode.d4.loss_mask: 1.0886  decode.d4.loss_dice: 0.7557  decode.d5.loss_cls: 0.2569  decode.d5.loss_mask: 1.0814  decode.d5.loss_dice: 0.7260  decode.d6.loss_cls: 0.2328  decode.d6.loss_mask: 1.0627  decode.d6.loss_dice: 0.7126  decode.d7.loss_cls: 0.2159  decode.d7.loss_mask: 1.0850  decode.d7.loss_dice: 0.7276  decode.d8.loss_cls: 0.2139  decode.d8.loss_mask: 1.0948  decode.d8.loss_dice: 0.7385
05/26 23:20:23 - mmengine - INFO - Iter(train) [104800/160000]  base_lr: 3.8374e-05 lr: 3.8374e-06  eta: 6:19:55  time: 0.4150  data_time: 0.0098  memory: 5976  grad_norm: 621.5409  loss: 22.7684  decode.loss_cls: 0.2530  decode.loss_mask: 1.1670  decode.loss_dice: 0.8108  decode.d0.loss_cls: 0.7050  decode.d0.loss_mask: 1.1295  decode.d0.loss_dice: 0.8512  decode.d1.loss_cls: 0.2473  decode.d1.loss_mask: 1.1533  decode.d1.loss_dice: 0.8077  decode.d2.loss_cls: 0.2388  decode.d2.loss_mask: 1.1795  decode.d2.loss_dice: 0.8219  decode.d3.loss_cls: 0.2452  decode.d3.loss_mask: 1.1759  decode.d3.loss_dice: 0.8259  decode.d4.loss_cls: 0.2531  decode.d4.loss_mask: 1.1532  decode.d4.loss_dice: 0.8191  decode.d5.loss_cls: 0.2316  decode.d5.loss_mask: 1.1834  decode.d5.loss_dice: 0.8410  decode.d6.loss_cls: 0.3020  decode.d6.loss_mask: 1.1267  decode.d6.loss_dice: 0.8114  decode.d7.loss_cls: 0.2840  decode.d7.loss_mask: 1.1502  decode.d7.loss_dice: 0.8118  decode.d8.loss_cls: 0.2442  decode.d8.loss_mask: 1.1372  decode.d8.loss_dice: 0.8078
05/26 23:20:44 - mmengine - INFO - Iter(train) [104850/160000]  base_lr: 3.8343e-05 lr: 3.8343e-06  eta: 6:19:34  time: 0.4131  data_time: 0.0097  memory: 5971  grad_norm: 772.5603  loss: 19.4749  decode.loss_cls: 0.2273  decode.loss_mask: 0.8994  decode.loss_dice: 0.7526  decode.d0.loss_cls: 0.7506  decode.d0.loss_mask: 0.9184  decode.d0.loss_dice: 0.7803  decode.d1.loss_cls: 0.2525  decode.d1.loss_mask: 0.9069  decode.d1.loss_dice: 0.7604  decode.d2.loss_cls: 0.2027  decode.d2.loss_mask: 0.9088  decode.d2.loss_dice: 0.7557  decode.d3.loss_cls: 0.2394  decode.d3.loss_mask: 0.8743  decode.d3.loss_dice: 0.7392  decode.d4.loss_cls: 0.2228  decode.d4.loss_mask: 0.9134  decode.d4.loss_dice: 0.7716  decode.d5.loss_cls: 0.2270  decode.d5.loss_mask: 0.8985  decode.d5.loss_dice: 0.7422  decode.d6.loss_cls: 0.2341  decode.d6.loss_mask: 0.9318  decode.d6.loss_dice: 0.7772  decode.d7.loss_cls: 0.2232  decode.d7.loss_mask: 0.9358  decode.d7.loss_dice: 0.7319  decode.d8.loss_cls: 0.2614  decode.d8.loss_mask: 0.8870  decode.d8.loss_dice: 0.7484
05/26 23:21:05 - mmengine - INFO - Iter(train) [104900/160000]  base_lr: 3.8312e-05 lr: 3.8312e-06  eta: 6:19:14  time: 0.4146  data_time: 0.0099  memory: 5974  grad_norm: 421.4045  loss: 21.4660  decode.loss_cls: 0.2289  decode.loss_mask: 1.0263  decode.loss_dice: 0.8110  decode.d0.loss_cls: 0.7176  decode.d0.loss_mask: 1.0235  decode.d0.loss_dice: 0.8015  decode.d1.loss_cls: 0.2617  decode.d1.loss_mask: 1.0503  decode.d1.loss_dice: 0.8184  decode.d2.loss_cls: 0.2794  decode.d2.loss_mask: 1.0467  decode.d2.loss_dice: 0.7988  decode.d3.loss_cls: 0.2536  decode.d3.loss_mask: 1.0605  decode.d3.loss_dice: 0.8052  decode.d4.loss_cls: 0.2342  decode.d4.loss_mask: 1.0442  decode.d4.loss_dice: 0.8349  decode.d5.loss_cls: 0.2400  decode.d5.loss_mask: 1.0781  decode.d5.loss_dice: 0.8240  decode.d6.loss_cls: 0.2302  decode.d6.loss_mask: 1.0350  decode.d6.loss_dice: 0.8055  decode.d7.loss_cls: 0.2425  decode.d7.loss_mask: 1.0274  decode.d7.loss_dice: 0.8037  decode.d8.loss_cls: 0.2826  decode.d8.loss_mask: 1.0265  decode.d8.loss_dice: 0.7736
05/26 23:21:26 - mmengine - INFO - Iter(train) [104950/160000]  base_lr: 3.8280e-05 lr: 3.8280e-06  eta: 6:18:53  time: 0.4137  data_time: 0.0098  memory: 5967  grad_norm: 918.4615  loss: 22.7008  decode.loss_cls: 0.2285  decode.loss_mask: 1.1559  decode.loss_dice: 0.8249  decode.d0.loss_cls: 0.7889  decode.d0.loss_mask: 1.1402  decode.d0.loss_dice: 0.8343  decode.d1.loss_cls: 0.2765  decode.d1.loss_mask: 1.1159  decode.d1.loss_dice: 0.8151  decode.d2.loss_cls: 0.2505  decode.d2.loss_mask: 1.1198  decode.d2.loss_dice: 0.8073  decode.d3.loss_cls: 0.2496  decode.d3.loss_mask: 1.1451  decode.d3.loss_dice: 0.8428  decode.d4.loss_cls: 0.2912  decode.d4.loss_mask: 1.1323  decode.d4.loss_dice: 0.8243  decode.d5.loss_cls: 0.2656  decode.d5.loss_mask: 1.1714  decode.d5.loss_dice: 0.8538  decode.d6.loss_cls: 0.2505  decode.d6.loss_mask: 1.1299  decode.d6.loss_dice: 0.8066  decode.d7.loss_cls: 0.2022  decode.d7.loss_mask: 1.1517  decode.d7.loss_dice: 0.8247  decode.d8.loss_cls: 0.2197  decode.d8.loss_mask: 1.1717  decode.d8.loss_dice: 0.8101
05/26 23:21:46 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 23:21:46 - mmengine - INFO - Iter(train) [105000/160000]  base_lr: 3.8249e-05 lr: 3.8249e-06  eta: 6:18:33  time: 0.4135  data_time: 0.0098  memory: 5979  grad_norm: 340.1756  loss: 18.4890  decode.loss_cls: 0.1912  decode.loss_mask: 0.8938  decode.loss_dice: 0.7471  decode.d0.loss_cls: 0.6560  decode.d0.loss_mask: 0.8771  decode.d0.loss_dice: 0.7359  decode.d1.loss_cls: 0.1893  decode.d1.loss_mask: 0.8832  decode.d1.loss_dice: 0.7442  decode.d2.loss_cls: 0.1920  decode.d2.loss_mask: 0.8596  decode.d2.loss_dice: 0.7266  decode.d3.loss_cls: 0.2041  decode.d3.loss_mask: 0.8672  decode.d3.loss_dice: 0.7244  decode.d4.loss_cls: 0.1536  decode.d4.loss_mask: 0.8870  decode.d4.loss_dice: 0.7573  decode.d5.loss_cls: 0.1717  decode.d5.loss_mask: 0.8796  decode.d5.loss_dice: 0.7281  decode.d6.loss_cls: 0.2083  decode.d6.loss_mask: 0.8736  decode.d6.loss_dice: 0.7417  decode.d7.loss_cls: 0.1832  decode.d7.loss_mask: 0.8922  decode.d7.loss_dice: 0.7382  decode.d8.loss_cls: 0.2015  decode.d8.loss_mask: 0.8580  decode.d8.loss_dice: 0.7233
05/26 23:21:46 - mmengine - INFO - Saving checkpoint at 105000 iterations
05/26 23:21:51 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:08  time: 0.0483  data_time: 0.0012  memory: 1391  
05/26 23:21:53 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:05  time: 0.0476  data_time: 0.0012  memory: 1205  
05/26 23:21:56 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:03  time: 0.0502  data_time: 0.0012  memory: 1596  
05/26 23:21:58 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0486  data_time: 0.0012  memory: 1298  
05/26 23:22:00 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:58  time: 0.0479  data_time: 0.0012  memory: 1298  
05/26 23:22:03 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0478  data_time: 0.0013  memory: 1279  
05/26 23:22:05 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:53  time: 0.0480  data_time: 0.0012  memory: 1224  
05/26 23:22:08 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0489  data_time: 0.0012  memory: 1298  
05/26 23:22:10 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0476  data_time: 0.0012  memory: 1298  
05/26 23:22:12 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0512  data_time: 0.0012  memory: 1725  
05/26 23:22:15 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0479  data_time: 0.0012  memory: 1336  
05/26 23:22:17 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:41  time: 0.0481  data_time: 0.0012  memory: 1298  
05/26 23:22:20 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0485  data_time: 0.0012  memory: 1205  
05/26 23:22:22 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0488  data_time: 0.0012  memory: 1316  
05/26 23:22:25 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0476  data_time: 0.0012  memory: 1279  
05/26 23:22:27 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0523  data_time: 0.0012  memory: 1410  
05/26 23:22:29 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0477  data_time: 0.0012  memory: 1279  
05/26 23:22:32 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0485  data_time: 0.0012  memory: 1205  
05/26 23:22:34 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0500  data_time: 0.0012  memory: 1205  
05/26 23:22:37 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0509  data_time: 0.0013  memory: 1336  
05/26 23:22:39 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0497  data_time: 0.0012  memory: 1246  
05/26 23:22:42 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0515  data_time: 0.0012  memory: 1503  
05/26 23:22:44 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0500  data_time: 0.0013  memory: 1261  
05/26 23:22:47 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:12  time: 0.0518  data_time: 0.0020  memory: 1298  
05/26 23:22:49 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0498  data_time: 0.0012  memory: 1447  
05/26 23:22:52 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0498  data_time: 0.0012  memory: 1298  
05/26 23:22:54 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0507  data_time: 0.0012  memory: 1279  
05/26 23:22:57 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0510  data_time: 0.0012  memory: 1205  
05/26 23:22:59 - mmengine - INFO - per class results:
05/26 23:22:59 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.51 |  97.2 |
|  aeroplane  | 90.79 | 96.33 |
|   bicycle   | 44.77 | 96.26 |
|     bird    | 94.83 | 98.14 |
|     boat    | 62.18 | 93.16 |
|    bottle   | 83.34 | 92.01 |
|     bus     | 87.32 | 88.37 |
|     car     | 81.39 | 96.12 |
|     cat     | 95.08 | 98.17 |
|    chair    | 40.13 | 70.31 |
|     cow     | 88.25 |  94.4 |
| diningtable | 60.59 | 69.71 |
|     dog     | 91.11 | 97.74 |
|    horse    | 90.73 | 94.46 |
|  motorbike  | 92.06 | 97.35 |
|    person   | 90.58 | 94.54 |
| pottedplant | 70.55 | 91.65 |
|    sheep    | 85.03 | 92.33 |
|     sofa    | 50.66 | 59.13 |
|    train    | 89.47 | 95.45 |
|  tvmonitor  | 86.66 | 88.94 |
+-------------+-------+-------+
05/26 23:22:59 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.5500  mIoU: 79.5700  mAcc: 90.5600  data_time: 0.0013  time: 0.0489
05/26 23:23:21 - mmengine - INFO - Iter(train) [105050/160000]  base_lr: 3.8218e-05 lr: 3.8218e-06  eta: 6:18:12  time: 0.4182  data_time: 0.0098  memory: 5967  grad_norm: 407.0581  loss: 17.1412  decode.loss_cls: 0.1028  decode.loss_mask: 0.9433  decode.loss_dice: 0.6001  decode.d0.loss_cls: 0.5734  decode.d0.loss_mask: 0.9404  decode.d0.loss_dice: 0.6247  decode.d1.loss_cls: 0.1113  decode.d1.loss_mask: 0.9602  decode.d1.loss_dice: 0.6191  decode.d2.loss_cls: 0.1017  decode.d2.loss_mask: 0.9514  decode.d2.loss_dice: 0.6098  decode.d3.loss_cls: 0.1070  decode.d3.loss_mask: 0.9676  decode.d3.loss_dice: 0.6207  decode.d4.loss_cls: 0.1116  decode.d4.loss_mask: 0.9492  decode.d4.loss_dice: 0.6083  decode.d5.loss_cls: 0.1007  decode.d5.loss_mask: 0.9633  decode.d5.loss_dice: 0.5953  decode.d6.loss_cls: 0.0847  decode.d6.loss_mask: 0.9558  decode.d6.loss_dice: 0.5985  decode.d7.loss_cls: 0.1132  decode.d7.loss_mask: 0.9516  decode.d7.loss_dice: 0.5977  decode.d8.loss_cls: 0.1137  decode.d8.loss_mask: 0.9523  decode.d8.loss_dice: 0.6117
05/26 23:23:42 - mmengine - INFO - Iter(train) [105100/160000]  base_lr: 3.8186e-05 lr: 3.8186e-06  eta: 6:17:52  time: 0.4167  data_time: 0.0098  memory: 5980  grad_norm: 593.7434  loss: 20.9803  decode.loss_cls: 0.1915  decode.loss_mask: 1.0764  decode.loss_dice: 0.7632  decode.d0.loss_cls: 0.6737  decode.d0.loss_mask: 1.0698  decode.d0.loss_dice: 0.7682  decode.d1.loss_cls: 0.2003  decode.d1.loss_mask: 1.0748  decode.d1.loss_dice: 0.7567  decode.d2.loss_cls: 0.2188  decode.d2.loss_mask: 1.1113  decode.d2.loss_dice: 0.8123  decode.d3.loss_cls: 0.2042  decode.d3.loss_mask: 1.1021  decode.d3.loss_dice: 0.7832  decode.d4.loss_cls: 0.1991  decode.d4.loss_mask: 1.0797  decode.d4.loss_dice: 0.7702  decode.d5.loss_cls: 0.1600  decode.d5.loss_mask: 1.0961  decode.d5.loss_dice: 0.7790  decode.d6.loss_cls: 0.2099  decode.d6.loss_mask: 1.0713  decode.d6.loss_dice: 0.7698  decode.d7.loss_cls: 0.2085  decode.d7.loss_mask: 1.0705  decode.d7.loss_dice: 0.7492  decode.d8.loss_cls: 0.1941  decode.d8.loss_mask: 1.0626  decode.d8.loss_dice: 0.7535
05/26 23:24:02 - mmengine - INFO - Iter(train) [105150/160000]  base_lr: 3.8155e-05 lr: 3.8155e-06  eta: 6:17:31  time: 0.4171  data_time: 0.0098  memory: 5967  grad_norm: 553.4013  loss: 21.1267  decode.loss_cls: 0.2010  decode.loss_mask: 1.0924  decode.loss_dice: 0.7475  decode.d0.loss_cls: 0.6737  decode.d0.loss_mask: 1.0495  decode.d0.loss_dice: 0.7727  decode.d1.loss_cls: 0.2624  decode.d1.loss_mask: 1.1080  decode.d1.loss_dice: 0.7463  decode.d2.loss_cls: 0.2395  decode.d2.loss_mask: 1.0564  decode.d2.loss_dice: 0.7322  decode.d3.loss_cls: 0.2023  decode.d3.loss_mask: 1.0867  decode.d3.loss_dice: 0.7381  decode.d4.loss_cls: 0.2044  decode.d4.loss_mask: 1.1322  decode.d4.loss_dice: 0.7702  decode.d5.loss_cls: 0.2127  decode.d5.loss_mask: 1.1386  decode.d5.loss_dice: 0.7592  decode.d6.loss_cls: 0.2439  decode.d6.loss_mask: 1.0985  decode.d6.loss_dice: 0.7429  decode.d7.loss_cls: 0.2222  decode.d7.loss_mask: 1.1007  decode.d7.loss_dice: 0.7586  decode.d8.loss_cls: 0.2007  decode.d8.loss_mask: 1.0965  decode.d8.loss_dice: 0.7365
05/26 23:24:23 - mmengine - INFO - Iter(train) [105200/160000]  base_lr: 3.8124e-05 lr: 3.8124e-06  eta: 6:17:11  time: 0.4167  data_time: 0.0098  memory: 5968  grad_norm: 449.9198  loss: 20.0895  decode.loss_cls: 0.2800  decode.loss_mask: 0.9149  decode.loss_dice: 0.7699  decode.d0.loss_cls: 0.7800  decode.d0.loss_mask: 0.8987  decode.d0.loss_dice: 0.7732  decode.d1.loss_cls: 0.3594  decode.d1.loss_mask: 0.9012  decode.d1.loss_dice: 0.7364  decode.d2.loss_cls: 0.3347  decode.d2.loss_mask: 0.8962  decode.d2.loss_dice: 0.7541  decode.d3.loss_cls: 0.3108  decode.d3.loss_mask: 0.9337  decode.d3.loss_dice: 0.7434  decode.d4.loss_cls: 0.3078  decode.d4.loss_mask: 0.9228  decode.d4.loss_dice: 0.7345  decode.d5.loss_cls: 0.3274  decode.d5.loss_mask: 0.8936  decode.d5.loss_dice: 0.7368  decode.d6.loss_cls: 0.3202  decode.d6.loss_mask: 0.8636  decode.d6.loss_dice: 0.7333  decode.d7.loss_cls: 0.3463  decode.d7.loss_mask: 0.8646  decode.d7.loss_dice: 0.7428  decode.d8.loss_cls: 0.3311  decode.d8.loss_mask: 0.8601  decode.d8.loss_dice: 0.7177
05/26 23:24:44 - mmengine - INFO - Iter(train) [105250/160000]  base_lr: 3.8093e-05 lr: 3.8093e-06  eta: 6:16:50  time: 0.4150  data_time: 0.0098  memory: 5982  grad_norm: 621.7926  loss: 22.7553  decode.loss_cls: 0.2332  decode.loss_mask: 1.1547  decode.loss_dice: 0.8334  decode.d0.loss_cls: 0.6813  decode.d0.loss_mask: 1.1558  decode.d0.loss_dice: 0.7754  decode.d1.loss_cls: 0.2673  decode.d1.loss_mask: 1.1622  decode.d1.loss_dice: 0.8095  decode.d2.loss_cls: 0.2538  decode.d2.loss_mask: 1.1729  decode.d2.loss_dice: 0.8283  decode.d3.loss_cls: 0.2807  decode.d3.loss_mask: 1.1339  decode.d3.loss_dice: 0.8129  decode.d4.loss_cls: 0.2552  decode.d4.loss_mask: 1.1428  decode.d4.loss_dice: 0.8220  decode.d5.loss_cls: 0.2739  decode.d5.loss_mask: 1.1544  decode.d5.loss_dice: 0.8146  decode.d6.loss_cls: 0.2953  decode.d6.loss_mask: 1.1496  decode.d6.loss_dice: 0.8255  decode.d7.loss_cls: 0.2868  decode.d7.loss_mask: 1.1341  decode.d7.loss_dice: 0.8067  decode.d8.loss_cls: 0.2642  decode.d8.loss_mask: 1.1590  decode.d8.loss_dice: 0.8159
05/26 23:25:05 - mmengine - INFO - Iter(train) [105300/160000]  base_lr: 3.8061e-05 lr: 3.8061e-06  eta: 6:16:30  time: 0.4171  data_time: 0.0098  memory: 5971  grad_norm: 548.2443  loss: 21.0786  decode.loss_cls: 0.2364  decode.loss_mask: 0.9967  decode.loss_dice: 0.7967  decode.d0.loss_cls: 0.7987  decode.d0.loss_mask: 0.9983  decode.d0.loss_dice: 0.7791  decode.d1.loss_cls: 0.2570  decode.d1.loss_mask: 1.0416  decode.d1.loss_dice: 0.8116  decode.d2.loss_cls: 0.2250  decode.d2.loss_mask: 1.0355  decode.d2.loss_dice: 0.7917  decode.d3.loss_cls: 0.2353  decode.d3.loss_mask: 1.0234  decode.d3.loss_dice: 0.8006  decode.d4.loss_cls: 0.2517  decode.d4.loss_mask: 1.0016  decode.d4.loss_dice: 0.7930  decode.d5.loss_cls: 0.2514  decode.d5.loss_mask: 1.0118  decode.d5.loss_dice: 0.7776  decode.d6.loss_cls: 0.2128  decode.d6.loss_mask: 1.0188  decode.d6.loss_dice: 0.7983  decode.d7.loss_cls: 0.2248  decode.d7.loss_mask: 1.0369  decode.d7.loss_dice: 0.8003  decode.d8.loss_cls: 0.2296  decode.d8.loss_mask: 1.0389  decode.d8.loss_dice: 0.8035
05/26 23:25:26 - mmengine - INFO - Iter(train) [105350/160000]  base_lr: 3.8030e-05 lr: 3.8030e-06  eta: 6:16:09  time: 0.4182  data_time: 0.0098  memory: 5966  grad_norm: 351.4093  loss: 17.9752  decode.loss_cls: 0.1796  decode.loss_mask: 0.9044  decode.loss_dice: 0.6435  decode.d0.loss_cls: 0.6794  decode.d0.loss_mask: 0.9345  decode.d0.loss_dice: 0.6457  decode.d1.loss_cls: 0.1826  decode.d1.loss_mask: 0.9143  decode.d1.loss_dice: 0.6764  decode.d2.loss_cls: 0.1661  decode.d2.loss_mask: 0.9153  decode.d2.loss_dice: 0.6640  decode.d3.loss_cls: 0.1796  decode.d3.loss_mask: 0.8968  decode.d3.loss_dice: 0.6472  decode.d4.loss_cls: 0.1693  decode.d4.loss_mask: 0.9170  decode.d4.loss_dice: 0.6504  decode.d5.loss_cls: 0.1086  decode.d5.loss_mask: 1.0308  decode.d5.loss_dice: 0.7066  decode.d6.loss_cls: 0.1557  decode.d6.loss_mask: 0.9016  decode.d6.loss_dice: 0.6521  decode.d7.loss_cls: 0.1557  decode.d7.loss_mask: 0.9124  decode.d7.loss_dice: 0.6700  decode.d8.loss_cls: 0.1429  decode.d8.loss_mask: 0.9179  decode.d8.loss_dice: 0.6544
05/26 23:25:47 - mmengine - INFO - Iter(train) [105400/160000]  base_lr: 3.7999e-05 lr: 3.7999e-06  eta: 6:15:49  time: 0.4170  data_time: 0.0098  memory: 5969  grad_norm: 611.9181  loss: 21.2653  decode.loss_cls: 0.1978  decode.loss_mask: 1.0670  decode.loss_dice: 0.8167  decode.d0.loss_cls: 0.5942  decode.d0.loss_mask: 1.0458  decode.d0.loss_dice: 0.7844  decode.d1.loss_cls: 0.2152  decode.d1.loss_mask: 1.0943  decode.d1.loss_dice: 0.8293  decode.d2.loss_cls: 0.2125  decode.d2.loss_mask: 1.0870  decode.d2.loss_dice: 0.7998  decode.d3.loss_cls: 0.2203  decode.d3.loss_mask: 1.0619  decode.d3.loss_dice: 0.7946  decode.d4.loss_cls: 0.2241  decode.d4.loss_mask: 1.0758  decode.d4.loss_dice: 0.8001  decode.d5.loss_cls: 0.2123  decode.d5.loss_mask: 1.0830  decode.d5.loss_dice: 0.8054  decode.d6.loss_cls: 0.2156  decode.d6.loss_mask: 1.0645  decode.d6.loss_dice: 0.7987  decode.d7.loss_cls: 0.2205  decode.d7.loss_mask: 1.0703  decode.d7.loss_dice: 0.7993  decode.d8.loss_cls: 0.2126  decode.d8.loss_mask: 1.0666  decode.d8.loss_dice: 0.7957
05/26 23:26:08 - mmengine - INFO - Iter(train) [105450/160000]  base_lr: 3.7967e-05 lr: 3.7967e-06  eta: 6:15:28  time: 0.4174  data_time: 0.0098  memory: 5967  grad_norm: 505.8343  loss: 17.7922  decode.loss_cls: 0.1389  decode.loss_mask: 0.8910  decode.loss_dice: 0.7111  decode.d0.loss_cls: 0.6720  decode.d0.loss_mask: 0.8707  decode.d0.loss_dice: 0.6781  decode.d1.loss_cls: 0.1191  decode.d1.loss_mask: 0.9238  decode.d1.loss_dice: 0.7416  decode.d2.loss_cls: 0.1408  decode.d2.loss_mask: 0.8942  decode.d2.loss_dice: 0.7050  decode.d3.loss_cls: 0.1322  decode.d3.loss_mask: 0.8808  decode.d3.loss_dice: 0.6976  decode.d4.loss_cls: 0.0969  decode.d4.loss_mask: 0.9242  decode.d4.loss_dice: 0.7264  decode.d5.loss_cls: 0.1102  decode.d5.loss_mask: 0.9052  decode.d5.loss_dice: 0.7132  decode.d6.loss_cls: 0.0911  decode.d6.loss_mask: 0.8950  decode.d6.loss_dice: 0.7144  decode.d7.loss_cls: 0.0987  decode.d7.loss_mask: 0.9066  decode.d7.loss_dice: 0.7143  decode.d8.loss_cls: 0.1407  decode.d8.loss_mask: 0.8779  decode.d8.loss_dice: 0.6801
05/26 23:26:29 - mmengine - INFO - Iter(train) [105500/160000]  base_lr: 3.7936e-05 lr: 3.7936e-06  eta: 6:15:08  time: 0.4189  data_time: 0.0097  memory: 5975  grad_norm: 447.0844  loss: 19.6082  decode.loss_cls: 0.1423  decode.loss_mask: 1.0993  decode.loss_dice: 0.6754  decode.d0.loss_cls: 0.6670  decode.d0.loss_mask: 1.0255  decode.d0.loss_dice: 0.6586  decode.d1.loss_cls: 0.1856  decode.d1.loss_mask: 1.0817  decode.d1.loss_dice: 0.6754  decode.d2.loss_cls: 0.1776  decode.d2.loss_mask: 1.0921  decode.d2.loss_dice: 0.6578  decode.d3.loss_cls: 0.1600  decode.d3.loss_mask: 1.1342  decode.d3.loss_dice: 0.6726  decode.d4.loss_cls: 0.1541  decode.d4.loss_mask: 1.0890  decode.d4.loss_dice: 0.6454  decode.d5.loss_cls: 0.1826  decode.d5.loss_mask: 1.0677  decode.d5.loss_dice: 0.6525  decode.d6.loss_cls: 0.1591  decode.d6.loss_mask: 1.0770  decode.d6.loss_dice: 0.6646  decode.d7.loss_cls: 0.1835  decode.d7.loss_mask: 1.0746  decode.d7.loss_dice: 0.6569  decode.d8.loss_cls: 0.1684  decode.d8.loss_mask: 1.0690  decode.d8.loss_dice: 0.6587
05/26 23:26:50 - mmengine - INFO - Iter(train) [105550/160000]  base_lr: 3.7905e-05 lr: 3.7905e-06  eta: 6:14:47  time: 0.4181  data_time: 0.0098  memory: 5966  grad_norm: 404.1430  loss: 18.7233  decode.loss_cls: 0.1841  decode.loss_mask: 0.8946  decode.loss_dice: 0.7086  decode.d0.loss_cls: 0.7660  decode.d0.loss_mask: 0.8980  decode.d0.loss_dice: 0.7167  decode.d1.loss_cls: 0.1988  decode.d1.loss_mask: 0.9074  decode.d1.loss_dice: 0.7176  decode.d2.loss_cls: 0.1812  decode.d2.loss_mask: 0.8876  decode.d2.loss_dice: 0.7112  decode.d3.loss_cls: 0.2199  decode.d3.loss_mask: 0.8839  decode.d3.loss_dice: 0.7007  decode.d4.loss_cls: 0.2123  decode.d4.loss_mask: 0.9053  decode.d4.loss_dice: 0.7235  decode.d5.loss_cls: 0.2270  decode.d5.loss_mask: 0.8936  decode.d5.loss_dice: 0.7000  decode.d6.loss_cls: 0.2033  decode.d6.loss_mask: 0.8945  decode.d6.loss_dice: 0.7440  decode.d7.loss_cls: 0.1950  decode.d7.loss_mask: 0.8942  decode.d7.loss_dice: 0.7163  decode.d8.loss_cls: 0.1810  decode.d8.loss_mask: 0.9176  decode.d8.loss_dice: 0.7395
05/26 23:27:10 - mmengine - INFO - Iter(train) [105600/160000]  base_lr: 3.7873e-05 lr: 3.7873e-06  eta: 6:14:26  time: 0.4169  data_time: 0.0098  memory: 5982  grad_norm: 512.9811  loss: 18.3670  decode.loss_cls: 0.1462  decode.loss_mask: 0.9720  decode.loss_dice: 0.6495  decode.d0.loss_cls: 0.6016  decode.d0.loss_mask: 0.9535  decode.d0.loss_dice: 0.6594  decode.d1.loss_cls: 0.1553  decode.d1.loss_mask: 0.9730  decode.d1.loss_dice: 0.6544  decode.d2.loss_cls: 0.1668  decode.d2.loss_mask: 0.9714  decode.d2.loss_dice: 0.6576  decode.d3.loss_cls: 0.1521  decode.d3.loss_mask: 0.9847  decode.d3.loss_dice: 0.6542  decode.d4.loss_cls: 0.1674  decode.d4.loss_mask: 0.9877  decode.d4.loss_dice: 0.6695  decode.d5.loss_cls: 0.1412  decode.d5.loss_mask: 0.9877  decode.d5.loss_dice: 0.6625  decode.d6.loss_cls: 0.1211  decode.d6.loss_mask: 0.9931  decode.d6.loss_dice: 0.6646  decode.d7.loss_cls: 0.1467  decode.d7.loss_mask: 0.9880  decode.d7.loss_dice: 0.6527  decode.d8.loss_cls: 0.1590  decode.d8.loss_mask: 0.9989  decode.d8.loss_dice: 0.6753
05/26 23:27:31 - mmengine - INFO - Iter(train) [105650/160000]  base_lr: 3.7842e-05 lr: 3.7842e-06  eta: 6:14:06  time: 0.4190  data_time: 0.0097  memory: 5969  grad_norm: 954.6313  loss: 23.0327  decode.loss_cls: 0.2457  decode.loss_mask: 1.1210  decode.loss_dice: 0.8631  decode.d0.loss_cls: 0.8424  decode.d0.loss_mask: 1.0989  decode.d0.loss_dice: 0.8298  decode.d1.loss_cls: 0.2840  decode.d1.loss_mask: 1.1149  decode.d1.loss_dice: 0.8438  decode.d2.loss_cls: 0.3007  decode.d2.loss_mask: 1.1668  decode.d2.loss_dice: 0.8806  decode.d3.loss_cls: 0.2739  decode.d3.loss_mask: 1.1394  decode.d3.loss_dice: 0.8665  decode.d4.loss_cls: 0.2546  decode.d4.loss_mask: 1.1256  decode.d4.loss_dice: 0.8345  decode.d5.loss_cls: 0.2508  decode.d5.loss_mask: 1.1387  decode.d5.loss_dice: 0.8457  decode.d6.loss_cls: 0.2481  decode.d6.loss_mask: 1.1370  decode.d6.loss_dice: 0.8613  decode.d7.loss_cls: 0.2583  decode.d7.loss_mask: 1.1268  decode.d7.loss_dice: 0.8579  decode.d8.loss_cls: 0.2593  decode.d8.loss_mask: 1.1250  decode.d8.loss_dice: 0.8377
05/26 23:27:52 - mmengine - INFO - Iter(train) [105700/160000]  base_lr: 3.7811e-05 lr: 3.7811e-06  eta: 6:13:45  time: 0.4183  data_time: 0.0098  memory: 5971  grad_norm: 705.7314  loss: 21.9146  decode.loss_cls: 0.2232  decode.loss_mask: 1.0931  decode.loss_dice: 0.7810  decode.d0.loss_cls: 0.7501  decode.d0.loss_mask: 1.0224  decode.d0.loss_dice: 0.8183  decode.d1.loss_cls: 0.2060  decode.d1.loss_mask: 1.1047  decode.d1.loss_dice: 0.8109  decode.d2.loss_cls: 0.2091  decode.d2.loss_mask: 1.1184  decode.d2.loss_dice: 0.8086  decode.d3.loss_cls: 0.2416  decode.d3.loss_mask: 1.1447  decode.d3.loss_dice: 0.7933  decode.d4.loss_cls: 0.2142  decode.d4.loss_mask: 1.1671  decode.d4.loss_dice: 0.7972  decode.d5.loss_cls: 0.2212  decode.d5.loss_mask: 1.1502  decode.d5.loss_dice: 0.8032  decode.d6.loss_cls: 0.2479  decode.d6.loss_mask: 1.1169  decode.d6.loss_dice: 0.7961  decode.d7.loss_cls: 0.1881  decode.d7.loss_mask: 1.1284  decode.d7.loss_dice: 0.8126  decode.d8.loss_cls: 0.2303  decode.d8.loss_mask: 1.1282  decode.d8.loss_dice: 0.7876
05/26 23:28:13 - mmengine - INFO - Iter(train) [105750/160000]  base_lr: 3.7779e-05 lr: 3.7779e-06  eta: 6:13:25  time: 0.4176  data_time: 0.0097  memory: 5969  grad_norm: 1495.6351  loss: 17.1629  decode.loss_cls: 0.2007  decode.loss_mask: 0.9141  decode.loss_dice: 0.5936  decode.d0.loss_cls: 0.7256  decode.d0.loss_mask: 0.8297  decode.d0.loss_dice: 0.5716  decode.d1.loss_cls: 0.2682  decode.d1.loss_mask: 0.8628  decode.d1.loss_dice: 0.5532  decode.d2.loss_cls: 0.2098  decode.d2.loss_mask: 0.8726  decode.d2.loss_dice: 0.5630  decode.d3.loss_cls: 0.1915  decode.d3.loss_mask: 0.8834  decode.d3.loss_dice: 0.5899  decode.d4.loss_cls: 0.1897  decode.d4.loss_mask: 0.9018  decode.d4.loss_dice: 0.5735  decode.d5.loss_cls: 0.1868  decode.d5.loss_mask: 0.9102  decode.d5.loss_dice: 0.5880  decode.d6.loss_cls: 0.1641  decode.d6.loss_mask: 0.9170  decode.d6.loss_dice: 0.5973  decode.d7.loss_cls: 0.1980  decode.d7.loss_mask: 0.8724  decode.d7.loss_dice: 0.5430  decode.d8.loss_cls: 0.1745  decode.d8.loss_mask: 0.9188  decode.d8.loss_dice: 0.5980
05/26 23:28:34 - mmengine - INFO - Iter(train) [105800/160000]  base_lr: 3.7748e-05 lr: 3.7748e-06  eta: 6:13:04  time: 0.4181  data_time: 0.0097  memory: 5970  grad_norm: 385.8071  loss: 18.1592  decode.loss_cls: 0.1493  decode.loss_mask: 0.9140  decode.loss_dice: 0.7038  decode.d0.loss_cls: 0.6682  decode.d0.loss_mask: 0.8521  decode.d0.loss_dice: 0.6821  decode.d1.loss_cls: 0.2073  decode.d1.loss_mask: 0.8953  decode.d1.loss_dice: 0.6856  decode.d2.loss_cls: 0.1509  decode.d2.loss_mask: 0.8943  decode.d2.loss_dice: 0.6903  decode.d3.loss_cls: 0.1472  decode.d3.loss_mask: 0.9120  decode.d3.loss_dice: 0.7080  decode.d4.loss_cls: 0.2025  decode.d4.loss_mask: 0.8831  decode.d4.loss_dice: 0.6807  decode.d5.loss_cls: 0.2096  decode.d5.loss_mask: 0.8707  decode.d5.loss_dice: 0.6769  decode.d6.loss_cls: 0.2148  decode.d6.loss_mask: 0.9174  decode.d6.loss_dice: 0.6849  decode.d7.loss_cls: 0.1391  decode.d7.loss_mask: 0.9105  decode.d7.loss_dice: 0.7120  decode.d8.loss_cls: 0.1619  decode.d8.loss_mask: 0.9074  decode.d8.loss_dice: 0.7277
05/26 23:28:55 - mmengine - INFO - Iter(train) [105850/160000]  base_lr: 3.7717e-05 lr: 3.7717e-06  eta: 6:12:44  time: 0.4162  data_time: 0.0099  memory: 5970  grad_norm: 573.0575  loss: 20.4996  decode.loss_cls: 0.2440  decode.loss_mask: 0.8795  decode.loss_dice: 0.8365  decode.d0.loss_cls: 0.8191  decode.d0.loss_mask: 0.8140  decode.d0.loss_dice: 0.7780  decode.d1.loss_cls: 0.3498  decode.d1.loss_mask: 0.9172  decode.d1.loss_dice: 0.7957  decode.d2.loss_cls: 0.3003  decode.d2.loss_mask: 0.9075  decode.d2.loss_dice: 0.8024  decode.d3.loss_cls: 0.2548  decode.d3.loss_mask: 0.9516  decode.d3.loss_dice: 0.8217  decode.d4.loss_cls: 0.2693  decode.d4.loss_mask: 0.9223  decode.d4.loss_dice: 0.7976  decode.d5.loss_cls: 0.3221  decode.d5.loss_mask: 0.8909  decode.d5.loss_dice: 0.7808  decode.d6.loss_cls: 0.3187  decode.d6.loss_mask: 0.8733  decode.d6.loss_dice: 0.7696  decode.d7.loss_cls: 0.2755  decode.d7.loss_mask: 0.9306  decode.d7.loss_dice: 0.8454  decode.d8.loss_cls: 0.2322  decode.d8.loss_mask: 0.9505  decode.d8.loss_dice: 0.8490
05/26 23:29:16 - mmengine - INFO - Iter(train) [105900/160000]  base_lr: 3.7685e-05 lr: 3.7685e-06  eta: 6:12:23  time: 0.4178  data_time: 0.0099  memory: 5980  grad_norm: 489.9613  loss: 21.9339  decode.loss_cls: 0.2170  decode.loss_mask: 1.2250  decode.loss_dice: 0.7029  decode.d0.loss_cls: 0.6155  decode.d0.loss_mask: 1.2316  decode.d0.loss_dice: 0.7022  decode.d1.loss_cls: 0.2149  decode.d1.loss_mask: 1.2234  decode.d1.loss_dice: 0.7102  decode.d2.loss_cls: 0.2035  decode.d2.loss_mask: 1.2448  decode.d2.loss_dice: 0.7070  decode.d3.loss_cls: 0.1978  decode.d3.loss_mask: 1.2297  decode.d3.loss_dice: 0.6897  decode.d4.loss_cls: 0.2153  decode.d4.loss_mask: 1.2680  decode.d4.loss_dice: 0.7083  decode.d5.loss_cls: 0.1770  decode.d5.loss_mask: 1.2564  decode.d5.loss_dice: 0.7237  decode.d6.loss_cls: 0.2201  decode.d6.loss_mask: 1.2309  decode.d6.loss_dice: 0.7134  decode.d7.loss_cls: 0.1993  decode.d7.loss_mask: 1.2337  decode.d7.loss_dice: 0.7080  decode.d8.loss_cls: 0.2266  decode.d8.loss_mask: 1.2355  decode.d8.loss_dice: 0.7023
05/26 23:29:37 - mmengine - INFO - Iter(train) [105950/160000]  base_lr: 3.7654e-05 lr: 3.7654e-06  eta: 6:12:03  time: 0.4167  data_time: 0.0098  memory: 5971  grad_norm: 567.0472  loss: 21.5754  decode.loss_cls: 0.1716  decode.loss_mask: 1.1968  decode.loss_dice: 0.7115  decode.d0.loss_cls: 0.6416  decode.d0.loss_mask: 1.1850  decode.d0.loss_dice: 0.7330  decode.d1.loss_cls: 0.1986  decode.d1.loss_mask: 1.1879  decode.d1.loss_dice: 0.7161  decode.d2.loss_cls: 0.1912  decode.d2.loss_mask: 1.2077  decode.d2.loss_dice: 0.7420  decode.d3.loss_cls: 0.1948  decode.d3.loss_mask: 1.1938  decode.d3.loss_dice: 0.7248  decode.d4.loss_cls: 0.1936  decode.d4.loss_mask: 1.1863  decode.d4.loss_dice: 0.7266  decode.d5.loss_cls: 0.1889  decode.d5.loss_mask: 1.2030  decode.d5.loss_dice: 0.7287  decode.d6.loss_cls: 0.1948  decode.d6.loss_mask: 1.1974  decode.d6.loss_dice: 0.7329  decode.d7.loss_cls: 0.2128  decode.d7.loss_mask: 1.2007  decode.d7.loss_dice: 0.7240  decode.d8.loss_cls: 0.1803  decode.d8.loss_mask: 1.1953  decode.d8.loss_dice: 0.7134
05/26 23:29:58 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 23:29:58 - mmengine - INFO - Iter(train) [106000/160000]  base_lr: 3.7623e-05 lr: 3.7623e-06  eta: 6:11:42  time: 0.4165  data_time: 0.0098  memory: 5972  grad_norm: 621.3918  loss: 20.5266  decode.loss_cls: 0.2184  decode.loss_mask: 0.9583  decode.loss_dice: 0.7810  decode.d0.loss_cls: 0.8357  decode.d0.loss_mask: 0.9166  decode.d0.loss_dice: 0.7407  decode.d1.loss_cls: 0.2296  decode.d1.loss_mask: 1.0130  decode.d1.loss_dice: 0.8035  decode.d2.loss_cls: 0.1824  decode.d2.loss_mask: 0.9953  decode.d2.loss_dice: 0.8105  decode.d3.loss_cls: 0.1690  decode.d3.loss_mask: 0.9945  decode.d3.loss_dice: 0.8238  decode.d4.loss_cls: 0.1567  decode.d4.loss_mask: 0.9897  decode.d4.loss_dice: 0.8192  decode.d5.loss_cls: 0.1797  decode.d5.loss_mask: 1.0340  decode.d5.loss_dice: 0.8350  decode.d6.loss_cls: 0.2162  decode.d6.loss_mask: 0.9881  decode.d6.loss_dice: 0.8079  decode.d7.loss_cls: 0.2369  decode.d7.loss_mask: 0.9735  decode.d7.loss_dice: 0.8065  decode.d8.loss_cls: 0.2122  decode.d8.loss_mask: 0.9910  decode.d8.loss_dice: 0.8075
05/26 23:30:18 - mmengine - INFO - Iter(train) [106050/160000]  base_lr: 3.7591e-05 lr: 3.7591e-06  eta: 6:11:22  time: 0.4172  data_time: 0.0099  memory: 5980  grad_norm: 782.5152  loss: 22.9778  decode.loss_cls: 0.1399  decode.loss_mask: 1.2300  decode.loss_dice: 0.8636  decode.d0.loss_cls: 0.7033  decode.d0.loss_mask: 1.1671  decode.d0.loss_dice: 0.8459  decode.d1.loss_cls: 0.2206  decode.d1.loss_mask: 1.2181  decode.d1.loss_dice: 0.8439  decode.d2.loss_cls: 0.1914  decode.d2.loss_mask: 1.2099  decode.d2.loss_dice: 0.8612  decode.d3.loss_cls: 0.2237  decode.d3.loss_mask: 1.2033  decode.d3.loss_dice: 0.8603  decode.d4.loss_cls: 0.1588  decode.d4.loss_mask: 1.2000  decode.d4.loss_dice: 0.8776  decode.d5.loss_cls: 0.1894  decode.d5.loss_mask: 1.2019  decode.d5.loss_dice: 0.8596  decode.d6.loss_cls: 0.1609  decode.d6.loss_mask: 1.2116  decode.d6.loss_dice: 0.8694  decode.d7.loss_cls: 0.1624  decode.d7.loss_mask: 1.2046  decode.d7.loss_dice: 0.8692  decode.d8.loss_cls: 0.1600  decode.d8.loss_mask: 1.2056  decode.d8.loss_dice: 0.8649
05/26 23:30:39 - mmengine - INFO - Iter(train) [106100/160000]  base_lr: 3.7560e-05 lr: 3.7560e-06  eta: 6:11:01  time: 0.4161  data_time: 0.0098  memory: 5970  grad_norm: 758.6549  loss: 14.8267  decode.loss_cls: 0.1342  decode.loss_mask: 0.7435  decode.loss_dice: 0.5169  decode.d0.loss_cls: 0.5498  decode.d0.loss_mask: 0.7611  decode.d0.loss_dice: 0.5644  decode.d1.loss_cls: 0.1200  decode.d1.loss_mask: 0.7580  decode.d1.loss_dice: 0.5426  decode.d2.loss_cls: 0.1431  decode.d2.loss_mask: 0.7545  decode.d2.loss_dice: 0.5251  decode.d3.loss_cls: 0.1310  decode.d3.loss_mask: 0.7821  decode.d3.loss_dice: 0.5425  decode.d4.loss_cls: 0.1462  decode.d4.loss_mask: 0.7750  decode.d4.loss_dice: 0.5507  decode.d5.loss_cls: 0.1223  decode.d5.loss_mask: 0.7908  decode.d5.loss_dice: 0.5640  decode.d6.loss_cls: 0.1243  decode.d6.loss_mask: 0.7524  decode.d6.loss_dice: 0.5568  decode.d7.loss_cls: 0.1888  decode.d7.loss_mask: 0.7541  decode.d7.loss_dice: 0.5073  decode.d8.loss_cls: 0.1205  decode.d8.loss_mask: 0.7661  decode.d8.loss_dice: 0.5388
05/26 23:31:00 - mmengine - INFO - Iter(train) [106150/160000]  base_lr: 3.7529e-05 lr: 3.7529e-06  eta: 6:10:41  time: 0.4163  data_time: 0.0098  memory: 5981  grad_norm: 512.8207  loss: 23.7971  decode.loss_cls: 0.2871  decode.loss_mask: 1.1336  decode.loss_dice: 0.9002  decode.d0.loss_cls: 0.7905  decode.d0.loss_mask: 1.0111  decode.d0.loss_dice: 0.8519  decode.d1.loss_cls: 0.3007  decode.d1.loss_mask: 1.1524  decode.d1.loss_dice: 0.9206  decode.d2.loss_cls: 0.3175  decode.d2.loss_mask: 1.1338  decode.d2.loss_dice: 0.9395  decode.d3.loss_cls: 0.3250  decode.d3.loss_mask: 1.0856  decode.d3.loss_dice: 0.8926  decode.d4.loss_cls: 0.3473  decode.d4.loss_mask: 1.1084  decode.d4.loss_dice: 0.8983  decode.d5.loss_cls: 0.3395  decode.d5.loss_mask: 1.1210  decode.d5.loss_dice: 0.9206  decode.d6.loss_cls: 0.2766  decode.d6.loss_mask: 1.1567  decode.d6.loss_dice: 0.9432  decode.d7.loss_cls: 0.3315  decode.d7.loss_mask: 1.0732  decode.d7.loss_dice: 0.8995  decode.d8.loss_cls: 0.3315  decode.d8.loss_mask: 1.1093  decode.d8.loss_dice: 0.8985
05/26 23:31:21 - mmengine - INFO - Iter(train) [106200/160000]  base_lr: 3.7497e-05 lr: 3.7497e-06  eta: 6:10:20  time: 0.4166  data_time: 0.0098  memory: 5967  grad_norm: 430.3715  loss: 17.9647  decode.loss_cls: 0.1670  decode.loss_mask: 0.9033  decode.loss_dice: 0.6645  decode.d0.loss_cls: 0.5600  decode.d0.loss_mask: 0.8988  decode.d0.loss_dice: 0.6553  decode.d1.loss_cls: 0.1833  decode.d1.loss_mask: 0.9238  decode.d1.loss_dice: 0.6888  decode.d2.loss_cls: 0.1827  decode.d2.loss_mask: 0.9379  decode.d2.loss_dice: 0.6620  decode.d3.loss_cls: 0.2048  decode.d3.loss_mask: 0.9338  decode.d3.loss_dice: 0.6409  decode.d4.loss_cls: 0.1770  decode.d4.loss_mask: 0.8971  decode.d4.loss_dice: 0.6537  decode.d5.loss_cls: 0.1881  decode.d5.loss_mask: 0.9056  decode.d5.loss_dice: 0.6573  decode.d6.loss_cls: 0.1842  decode.d6.loss_mask: 0.8889  decode.d6.loss_dice: 0.6430  decode.d7.loss_cls: 0.1865  decode.d7.loss_mask: 0.9351  decode.d7.loss_dice: 0.6821  decode.d8.loss_cls: 0.1682  decode.d8.loss_mask: 0.9233  decode.d8.loss_dice: 0.6676
05/26 23:31:42 - mmengine - INFO - Iter(train) [106250/160000]  base_lr: 3.7466e-05 lr: 3.7466e-06  eta: 6:09:59  time: 0.4164  data_time: 0.0099  memory: 5968  grad_norm: 824.0792  loss: 18.5057  decode.loss_cls: 0.1425  decode.loss_mask: 1.0289  decode.loss_dice: 0.6757  decode.d0.loss_cls: 0.5646  decode.d0.loss_mask: 0.9825  decode.d0.loss_dice: 0.6123  decode.d1.loss_cls: 0.1166  decode.d1.loss_mask: 1.0137  decode.d1.loss_dice: 0.6582  decode.d2.loss_cls: 0.1398  decode.d2.loss_mask: 1.0346  decode.d2.loss_dice: 0.6598  decode.d3.loss_cls: 0.1173  decode.d3.loss_mask: 1.0294  decode.d3.loss_dice: 0.6846  decode.d4.loss_cls: 0.1461  decode.d4.loss_mask: 1.0186  decode.d4.loss_dice: 0.6666  decode.d5.loss_cls: 0.1177  decode.d5.loss_mask: 1.0315  decode.d5.loss_dice: 0.6595  decode.d6.loss_cls: 0.1286  decode.d6.loss_mask: 1.0178  decode.d6.loss_dice: 0.6616  decode.d7.loss_cls: 0.1279  decode.d7.loss_mask: 1.0328  decode.d7.loss_dice: 0.6575  decode.d8.loss_cls: 0.1315  decode.d8.loss_mask: 0.9995  decode.d8.loss_dice: 0.6481
05/26 23:32:03 - mmengine - INFO - Iter(train) [106300/160000]  base_lr: 3.7434e-05 lr: 3.7434e-06  eta: 6:09:39  time: 0.4167  data_time: 0.0098  memory: 5976  grad_norm: 262.3235  loss: 18.2000  decode.loss_cls: 0.1583  decode.loss_mask: 0.9365  decode.loss_dice: 0.6713  decode.d0.loss_cls: 0.7531  decode.d0.loss_mask: 0.8291  decode.d0.loss_dice: 0.6274  decode.d1.loss_cls: 0.1175  decode.d1.loss_mask: 0.9777  decode.d1.loss_dice: 0.6807  decode.d2.loss_cls: 0.1088  decode.d2.loss_mask: 0.9815  decode.d2.loss_dice: 0.6977  decode.d3.loss_cls: 0.1382  decode.d3.loss_mask: 0.9600  decode.d3.loss_dice: 0.6817  decode.d4.loss_cls: 0.1500  decode.d4.loss_mask: 0.9667  decode.d4.loss_dice: 0.6711  decode.d5.loss_cls: 0.1045  decode.d5.loss_mask: 0.9749  decode.d5.loss_dice: 0.6841  decode.d6.loss_cls: 0.1276  decode.d6.loss_mask: 0.9671  decode.d6.loss_dice: 0.6854  decode.d7.loss_cls: 0.1291  decode.d7.loss_mask: 0.9708  decode.d7.loss_dice: 0.6748  decode.d8.loss_cls: 0.1381  decode.d8.loss_mask: 0.9610  decode.d8.loss_dice: 0.6750
05/26 23:32:24 - mmengine - INFO - Iter(train) [106350/160000]  base_lr: 3.7403e-05 lr: 3.7403e-06  eta: 6:09:18  time: 0.4166  data_time: 0.0099  memory: 5967  grad_norm: 535.7188  loss: 21.3650  decode.loss_cls: 0.1713  decode.loss_mask: 1.1276  decode.loss_dice: 0.7713  decode.d0.loss_cls: 0.6967  decode.d0.loss_mask: 1.1106  decode.d0.loss_dice: 0.7232  decode.d1.loss_cls: 0.1910  decode.d1.loss_mask: 1.1356  decode.d1.loss_dice: 0.7705  decode.d2.loss_cls: 0.1362  decode.d2.loss_mask: 1.1438  decode.d2.loss_dice: 0.7832  decode.d3.loss_cls: 0.1741  decode.d3.loss_mask: 1.1453  decode.d3.loss_dice: 0.7777  decode.d4.loss_cls: 0.1841  decode.d4.loss_mask: 1.1432  decode.d4.loss_dice: 0.7690  decode.d5.loss_cls: 0.2028  decode.d5.loss_mask: 1.1243  decode.d5.loss_dice: 0.7675  decode.d6.loss_cls: 0.1840  decode.d6.loss_mask: 1.1394  decode.d6.loss_dice: 0.7736  decode.d7.loss_cls: 0.1571  decode.d7.loss_mask: 1.1559  decode.d7.loss_dice: 0.7735  decode.d8.loss_cls: 0.2029  decode.d8.loss_mask: 1.1445  decode.d8.loss_dice: 0.7851
05/26 23:32:44 - mmengine - INFO - Iter(train) [106400/160000]  base_lr: 3.7372e-05 lr: 3.7372e-06  eta: 6:08:58  time: 0.4166  data_time: 0.0099  memory: 5975  grad_norm: 665.9814  loss: 22.7921  decode.loss_cls: 0.1941  decode.loss_mask: 1.2430  decode.loss_dice: 0.8291  decode.d0.loss_cls: 0.6416  decode.d0.loss_mask: 1.1716  decode.d0.loss_dice: 0.7814  decode.d1.loss_cls: 0.2299  decode.d1.loss_mask: 1.1947  decode.d1.loss_dice: 0.7865  decode.d2.loss_cls: 0.2461  decode.d2.loss_mask: 1.1990  decode.d2.loss_dice: 0.7988  decode.d3.loss_cls: 0.1856  decode.d3.loss_mask: 1.1977  decode.d3.loss_dice: 0.8301  decode.d4.loss_cls: 0.1871  decode.d4.loss_mask: 1.2375  decode.d4.loss_dice: 0.8438  decode.d5.loss_cls: 0.1839  decode.d5.loss_mask: 1.2415  decode.d5.loss_dice: 0.8360  decode.d6.loss_cls: 0.1905  decode.d6.loss_mask: 1.2189  decode.d6.loss_dice: 0.8213  decode.d7.loss_cls: 0.2306  decode.d7.loss_mask: 1.2228  decode.d7.loss_dice: 0.8077  decode.d8.loss_cls: 0.1709  decode.d8.loss_mask: 1.2436  decode.d8.loss_dice: 0.8266
05/26 23:33:05 - mmengine - INFO - Iter(train) [106450/160000]  base_lr: 3.7340e-05 lr: 3.7340e-06  eta: 6:08:37  time: 0.4153  data_time: 0.0098  memory: 5967  grad_norm: 777.9872  loss: 19.7956  decode.loss_cls: 0.1223  decode.loss_mask: 1.1010  decode.loss_dice: 0.7158  decode.d0.loss_cls: 0.6726  decode.d0.loss_mask: 1.0920  decode.d0.loss_dice: 0.6604  decode.d1.loss_cls: 0.0918  decode.d1.loss_mask: 1.1336  decode.d1.loss_dice: 0.7250  decode.d2.loss_cls: 0.0922  decode.d2.loss_mask: 1.1101  decode.d2.loss_dice: 0.6960  decode.d3.loss_cls: 0.1217  decode.d3.loss_mask: 1.0866  decode.d3.loss_dice: 0.7104  decode.d4.loss_cls: 0.1201  decode.d4.loss_mask: 1.1282  decode.d4.loss_dice: 0.7054  decode.d5.loss_cls: 0.1273  decode.d5.loss_mask: 1.1052  decode.d5.loss_dice: 0.7031  decode.d6.loss_cls: 0.1411  decode.d6.loss_mask: 1.1127  decode.d6.loss_dice: 0.6825  decode.d7.loss_cls: 0.1198  decode.d7.loss_mask: 1.1163  decode.d7.loss_dice: 0.6868  decode.d8.loss_cls: 0.1465  decode.d8.loss_mask: 1.0753  decode.d8.loss_dice: 0.6938
05/26 23:33:26 - mmengine - INFO - Iter(train) [106500/160000]  base_lr: 3.7309e-05 lr: 3.7309e-06  eta: 6:08:17  time: 0.4207  data_time: 0.0100  memory: 5976  grad_norm: 711.3284  loss: 21.3136  decode.loss_cls: 0.2314  decode.loss_mask: 1.0972  decode.loss_dice: 0.7423  decode.d0.loss_cls: 0.7695  decode.d0.loss_mask: 1.0982  decode.d0.loss_dice: 0.7715  decode.d1.loss_cls: 0.2303  decode.d1.loss_mask: 1.1074  decode.d1.loss_dice: 0.7540  decode.d2.loss_cls: 0.2116  decode.d2.loss_mask: 1.1001  decode.d2.loss_dice: 0.7499  decode.d3.loss_cls: 0.2151  decode.d3.loss_mask: 1.0939  decode.d3.loss_dice: 0.7366  decode.d4.loss_cls: 0.2198  decode.d4.loss_mask: 1.1068  decode.d4.loss_dice: 0.7594  decode.d5.loss_cls: 0.2316  decode.d5.loss_mask: 1.1018  decode.d5.loss_dice: 0.7478  decode.d6.loss_cls: 0.1822  decode.d6.loss_mask: 1.1163  decode.d6.loss_dice: 0.7624  decode.d7.loss_cls: 0.2576  decode.d7.loss_mask: 1.1087  decode.d7.loss_dice: 0.7510  decode.d8.loss_cls: 0.2358  decode.d8.loss_mask: 1.0949  decode.d8.loss_dice: 0.7284
05/26 23:33:47 - mmengine - INFO - Iter(train) [106550/160000]  base_lr: 3.7278e-05 lr: 3.7278e-06  eta: 6:07:56  time: 0.4146  data_time: 0.0098  memory: 5974  grad_norm: 468.2388  loss: 22.2399  decode.loss_cls: 0.2407  decode.loss_mask: 1.0716  decode.loss_dice: 0.8314  decode.d0.loss_cls: 0.7868  decode.d0.loss_mask: 1.0259  decode.d0.loss_dice: 0.8431  decode.d1.loss_cls: 0.1950  decode.d1.loss_mask: 1.1286  decode.d1.loss_dice: 0.8682  decode.d2.loss_cls: 0.2284  decode.d2.loss_mask: 1.1165  decode.d2.loss_dice: 0.8473  decode.d3.loss_cls: 0.2164  decode.d3.loss_mask: 1.0814  decode.d3.loss_dice: 0.8479  decode.d4.loss_cls: 0.2102  decode.d4.loss_mask: 1.1182  decode.d4.loss_dice: 0.8459  decode.d5.loss_cls: 0.2608  decode.d5.loss_mask: 1.1028  decode.d5.loss_dice: 0.8495  decode.d6.loss_cls: 0.2325  decode.d6.loss_mask: 1.0993  decode.d6.loss_dice: 0.8559  decode.d7.loss_cls: 0.1872  decode.d7.loss_mask: 1.1134  decode.d7.loss_dice: 0.8518  decode.d8.loss_cls: 0.2002  decode.d8.loss_mask: 1.1282  decode.d8.loss_dice: 0.8550
05/26 23:34:08 - mmengine - INFO - Iter(train) [106600/160000]  base_lr: 3.7246e-05 lr: 3.7246e-06  eta: 6:07:36  time: 0.4138  data_time: 0.0097  memory: 5966  grad_norm: 643.8349  loss: 19.4236  decode.loss_cls: 0.2010  decode.loss_mask: 0.9568  decode.loss_dice: 0.6995  decode.d0.loss_cls: 0.7463  decode.d0.loss_mask: 0.9688  decode.d0.loss_dice: 0.7241  decode.d1.loss_cls: 0.1988  decode.d1.loss_mask: 1.0202  decode.d1.loss_dice: 0.7420  decode.d2.loss_cls: 0.1874  decode.d2.loss_mask: 0.9726  decode.d2.loss_dice: 0.7099  decode.d3.loss_cls: 0.1798  decode.d3.loss_mask: 0.9606  decode.d3.loss_dice: 0.7130  decode.d4.loss_cls: 0.1996  decode.d4.loss_mask: 0.9599  decode.d4.loss_dice: 0.7078  decode.d5.loss_cls: 0.2074  decode.d5.loss_mask: 0.9555  decode.d5.loss_dice: 0.6981  decode.d6.loss_cls: 0.2229  decode.d6.loss_mask: 0.9710  decode.d6.loss_dice: 0.6948  decode.d7.loss_cls: 0.2129  decode.d7.loss_mask: 0.9837  decode.d7.loss_dice: 0.7275  decode.d8.loss_cls: 0.2199  decode.d8.loss_mask: 0.9647  decode.d8.loss_dice: 0.7172
05/26 23:34:29 - mmengine - INFO - Iter(train) [106650/160000]  base_lr: 3.7215e-05 lr: 3.7215e-06  eta: 6:07:15  time: 0.4153  data_time: 0.0097  memory: 5972  grad_norm: 766.7146  loss: 18.4170  decode.loss_cls: 0.1371  decode.loss_mask: 0.9378  decode.loss_dice: 0.6750  decode.d0.loss_cls: 0.6148  decode.d0.loss_mask: 0.9855  decode.d0.loss_dice: 0.7048  decode.d1.loss_cls: 0.1313  decode.d1.loss_mask: 0.9372  decode.d1.loss_dice: 0.7031  decode.d2.loss_cls: 0.1149  decode.d2.loss_mask: 0.9896  decode.d2.loss_dice: 0.7209  decode.d3.loss_cls: 0.1627  decode.d3.loss_mask: 0.9308  decode.d3.loss_dice: 0.6758  decode.d4.loss_cls: 0.1330  decode.d4.loss_mask: 0.9871  decode.d4.loss_dice: 0.7341  decode.d5.loss_cls: 0.1006  decode.d5.loss_mask: 0.9644  decode.d5.loss_dice: 0.7214  decode.d6.loss_cls: 0.1565  decode.d6.loss_mask: 0.9500  decode.d6.loss_dice: 0.6965  decode.d7.loss_cls: 0.1362  decode.d7.loss_mask: 0.9520  decode.d7.loss_dice: 0.7079  decode.d8.loss_cls: 0.1364  decode.d8.loss_mask: 0.9414  decode.d8.loss_dice: 0.6784
05/26 23:34:49 - mmengine - INFO - Iter(train) [106700/160000]  base_lr: 3.7183e-05 lr: 3.7183e-06  eta: 6:06:54  time: 0.4132  data_time: 0.0098  memory: 5970  grad_norm: 1182.4220  loss: 22.7682  decode.loss_cls: 0.2455  decode.loss_mask: 1.1294  decode.loss_dice: 0.8777  decode.d0.loss_cls: 0.7408  decode.d0.loss_mask: 1.1070  decode.d0.loss_dice: 0.8419  decode.d1.loss_cls: 0.2730  decode.d1.loss_mask: 1.1240  decode.d1.loss_dice: 0.8419  decode.d2.loss_cls: 0.2871  decode.d2.loss_mask: 1.0951  decode.d2.loss_dice: 0.8381  decode.d3.loss_cls: 0.2461  decode.d3.loss_mask: 1.1323  decode.d3.loss_dice: 0.8545  decode.d4.loss_cls: 0.2694  decode.d4.loss_mask: 1.1137  decode.d4.loss_dice: 0.8882  decode.d5.loss_cls: 0.2656  decode.d5.loss_mask: 1.0864  decode.d5.loss_dice: 0.8550  decode.d6.loss_cls: 0.2609  decode.d6.loss_mask: 1.1006  decode.d6.loss_dice: 0.8185  decode.d7.loss_cls: 0.2662  decode.d7.loss_mask: 1.1182  decode.d7.loss_dice: 0.8508  decode.d8.loss_cls: 0.2821  decode.d8.loss_mask: 1.1052  decode.d8.loss_dice: 0.8531
05/26 23:35:10 - mmengine - INFO - Iter(train) [106750/160000]  base_lr: 3.7152e-05 lr: 3.7152e-06  eta: 6:06:34  time: 0.4137  data_time: 0.0098  memory: 5981  grad_norm: 504.9813  loss: 16.5195  decode.loss_cls: 0.0672  decode.loss_mask: 0.8825  decode.loss_dice: 0.6546  decode.d0.loss_cls: 0.5504  decode.d0.loss_mask: 0.8800  decode.d0.loss_dice: 0.6150  decode.d1.loss_cls: 0.0835  decode.d1.loss_mask: 0.8808  decode.d1.loss_dice: 0.6626  decode.d2.loss_cls: 0.1105  decode.d2.loss_mask: 0.8736  decode.d2.loss_dice: 0.6478  decode.d3.loss_cls: 0.1117  decode.d3.loss_mask: 0.8651  decode.d3.loss_dice: 0.6300  decode.d4.loss_cls: 0.1169  decode.d4.loss_mask: 0.9040  decode.d4.loss_dice: 0.6347  decode.d5.loss_cls: 0.0765  decode.d5.loss_mask: 0.8607  decode.d5.loss_dice: 0.6402  decode.d6.loss_cls: 0.0772  decode.d6.loss_mask: 0.8734  decode.d6.loss_dice: 0.6435  decode.d7.loss_cls: 0.0945  decode.d7.loss_mask: 0.8531  decode.d7.loss_dice: 0.6279  decode.d8.loss_cls: 0.1054  decode.d8.loss_mask: 0.8619  decode.d8.loss_dice: 0.6343
05/26 23:35:31 - mmengine - INFO - Iter(train) [106800/160000]  base_lr: 3.7121e-05 lr: 3.7121e-06  eta: 6:06:13  time: 0.4138  data_time: 0.0098  memory: 5969  grad_norm: 335.5313  loss: 18.2488  decode.loss_cls: 0.1360  decode.loss_mask: 1.0091  decode.loss_dice: 0.6598  decode.d0.loss_cls: 0.6041  decode.d0.loss_mask: 0.9592  decode.d0.loss_dice: 0.6103  decode.d1.loss_cls: 0.1882  decode.d1.loss_mask: 0.9887  decode.d1.loss_dice: 0.6127  decode.d2.loss_cls: 0.1718  decode.d2.loss_mask: 0.9799  decode.d2.loss_dice: 0.6118  decode.d3.loss_cls: 0.1751  decode.d3.loss_mask: 0.9944  decode.d3.loss_dice: 0.6360  decode.d4.loss_cls: 0.1574  decode.d4.loss_mask: 0.9721  decode.d4.loss_dice: 0.6137  decode.d5.loss_cls: 0.1684  decode.d5.loss_mask: 0.9857  decode.d5.loss_dice: 0.6222  decode.d6.loss_cls: 0.1894  decode.d6.loss_mask: 0.9662  decode.d6.loss_dice: 0.6288  decode.d7.loss_cls: 0.1436  decode.d7.loss_mask: 0.9909  decode.d7.loss_dice: 0.6588  decode.d8.loss_cls: 0.1758  decode.d8.loss_mask: 0.9954  decode.d8.loss_dice: 0.6435
05/26 23:35:52 - mmengine - INFO - Iter(train) [106850/160000]  base_lr: 3.7089e-05 lr: 3.7089e-06  eta: 6:05:52  time: 0.4147  data_time: 0.0097  memory: 5966  grad_norm: 317.5801  loss: 18.3047  decode.loss_cls: 0.1879  decode.loss_mask: 0.8980  decode.loss_dice: 0.7230  decode.d0.loss_cls: 0.6249  decode.d0.loss_mask: 0.9165  decode.d0.loss_dice: 0.7039  decode.d1.loss_cls: 0.1665  decode.d1.loss_mask: 0.9050  decode.d1.loss_dice: 0.7229  decode.d2.loss_cls: 0.1615  decode.d2.loss_mask: 0.9016  decode.d2.loss_dice: 0.7123  decode.d3.loss_cls: 0.1874  decode.d3.loss_mask: 0.8903  decode.d3.loss_dice: 0.7051  decode.d4.loss_cls: 0.1352  decode.d4.loss_mask: 0.8893  decode.d4.loss_dice: 0.7214  decode.d5.loss_cls: 0.1891  decode.d5.loss_mask: 0.9008  decode.d5.loss_dice: 0.7134  decode.d6.loss_cls: 0.1630  decode.d6.loss_mask: 0.8888  decode.d6.loss_dice: 0.7132  decode.d7.loss_cls: 0.1652  decode.d7.loss_mask: 0.9026  decode.d7.loss_dice: 0.7265  decode.d8.loss_cls: 0.1681  decode.d8.loss_mask: 0.8960  decode.d8.loss_dice: 0.7254
05/26 23:36:12 - mmengine - INFO - Iter(train) [106900/160000]  base_lr: 3.7058e-05 lr: 3.7058e-06  eta: 6:05:32  time: 0.4139  data_time: 0.0099  memory: 5968  grad_norm: 634.3534  loss: 16.1908  decode.loss_cls: 0.1213  decode.loss_mask: 0.9179  decode.loss_dice: 0.6164  decode.d0.loss_cls: 0.5393  decode.d0.loss_mask: 0.8928  decode.d0.loss_dice: 0.6094  decode.d1.loss_cls: 0.1150  decode.d1.loss_mask: 0.8424  decode.d1.loss_dice: 0.5899  decode.d2.loss_cls: 0.1042  decode.d2.loss_mask: 0.8197  decode.d2.loss_dice: 0.6041  decode.d3.loss_cls: 0.1041  decode.d3.loss_mask: 0.8239  decode.d3.loss_dice: 0.6038  decode.d4.loss_cls: 0.1182  decode.d4.loss_mask: 0.8281  decode.d4.loss_dice: 0.5973  decode.d5.loss_cls: 0.1400  decode.d5.loss_mask: 0.8418  decode.d5.loss_dice: 0.6086  decode.d6.loss_cls: 0.1197  decode.d6.loss_mask: 0.8391  decode.d6.loss_dice: 0.6050  decode.d7.loss_cls: 0.1301  decode.d7.loss_mask: 0.8289  decode.d7.loss_dice: 0.5865  decode.d8.loss_cls: 0.1220  decode.d8.loss_mask: 0.9000  decode.d8.loss_dice: 0.6215
05/26 23:36:33 - mmengine - INFO - Iter(train) [106950/160000]  base_lr: 3.7026e-05 lr: 3.7026e-06  eta: 6:05:11  time: 0.4131  data_time: 0.0096  memory: 5966  grad_norm: 467.8832  loss: 19.3166  decode.loss_cls: 0.1963  decode.loss_mask: 0.9831  decode.loss_dice: 0.7199  decode.d0.loss_cls: 0.7015  decode.d0.loss_mask: 0.9503  decode.d0.loss_dice: 0.7005  decode.d1.loss_cls: 0.2348  decode.d1.loss_mask: 0.9211  decode.d1.loss_dice: 0.6880  decode.d2.loss_cls: 0.1574  decode.d2.loss_mask: 1.0011  decode.d2.loss_dice: 0.7384  decode.d3.loss_cls: 0.1901  decode.d3.loss_mask: 0.9745  decode.d3.loss_dice: 0.7216  decode.d4.loss_cls: 0.2126  decode.d4.loss_mask: 0.9708  decode.d4.loss_dice: 0.7245  decode.d5.loss_cls: 0.2035  decode.d5.loss_mask: 1.0014  decode.d5.loss_dice: 0.7326  decode.d6.loss_cls: 0.2273  decode.d6.loss_mask: 0.9300  decode.d6.loss_dice: 0.6868  decode.d7.loss_cls: 0.2115  decode.d7.loss_mask: 0.9441  decode.d7.loss_dice: 0.7009  decode.d8.loss_cls: 0.1921  decode.d8.loss_mask: 0.9825  decode.d8.loss_dice: 0.7173
05/26 23:36:54 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 23:36:54 - mmengine - INFO - Iter(train) [107000/160000]  base_lr: 3.6995e-05 lr: 3.6995e-06  eta: 6:04:51  time: 0.4142  data_time: 0.0097  memory: 5966  grad_norm: 579.5040  loss: 20.2736  decode.loss_cls: 0.1940  decode.loss_mask: 1.0997  decode.loss_dice: 0.7206  decode.d0.loss_cls: 0.6304  decode.d0.loss_mask: 1.0935  decode.d0.loss_dice: 0.7192  decode.d1.loss_cls: 0.1755  decode.d1.loss_mask: 1.0899  decode.d1.loss_dice: 0.7272  decode.d2.loss_cls: 0.1493  decode.d2.loss_mask: 1.0841  decode.d2.loss_dice: 0.7194  decode.d3.loss_cls: 0.1815  decode.d3.loss_mask: 1.0698  decode.d3.loss_dice: 0.7209  decode.d4.loss_cls: 0.1747  decode.d4.loss_mask: 1.0619  decode.d4.loss_dice: 0.7193  decode.d5.loss_cls: 0.1924  decode.d5.loss_mask: 1.0598  decode.d5.loss_dice: 0.7086  decode.d6.loss_cls: 0.1891  decode.d6.loss_mask: 1.0543  decode.d6.loss_dice: 0.7344  decode.d7.loss_cls: 0.1645  decode.d7.loss_mask: 1.0905  decode.d7.loss_dice: 0.7323  decode.d8.loss_cls: 0.1880  decode.d8.loss_mask: 1.0976  decode.d8.loss_dice: 0.7312
05/26 23:37:14 - mmengine - INFO - Iter(train) [107050/160000]  base_lr: 3.6964e-05 lr: 3.6964e-06  eta: 6:04:30  time: 0.4149  data_time: 0.0097  memory: 5971  grad_norm: 554.5054  loss: 18.5741  decode.loss_cls: 0.1212  decode.loss_mask: 1.0040  decode.loss_dice: 0.6919  decode.d0.loss_cls: 0.5407  decode.d0.loss_mask: 0.9813  decode.d0.loss_dice: 0.6968  decode.d1.loss_cls: 0.1255  decode.d1.loss_mask: 0.9992  decode.d1.loss_dice: 0.7102  decode.d2.loss_cls: 0.1195  decode.d2.loss_mask: 0.9915  decode.d2.loss_dice: 0.6871  decode.d3.loss_cls: 0.1493  decode.d3.loss_mask: 0.9881  decode.d3.loss_dice: 0.6956  decode.d4.loss_cls: 0.1346  decode.d4.loss_mask: 0.9847  decode.d4.loss_dice: 0.7068  decode.d5.loss_cls: 0.1183  decode.d5.loss_mask: 0.9861  decode.d5.loss_dice: 0.7114  decode.d6.loss_cls: 0.1380  decode.d6.loss_mask: 0.9687  decode.d6.loss_dice: 0.6904  decode.d7.loss_cls: 0.1402  decode.d7.loss_mask: 0.9758  decode.d7.loss_dice: 0.6920  decode.d8.loss_cls: 0.1432  decode.d8.loss_mask: 0.9882  decode.d8.loss_dice: 0.6940
05/26 23:37:35 - mmengine - INFO - Iter(train) [107100/160000]  base_lr: 3.6932e-05 lr: 3.6932e-06  eta: 6:04:09  time: 0.4142  data_time: 0.0097  memory: 5969  grad_norm: 555.4459  loss: 19.4964  decode.loss_cls: 0.1838  decode.loss_mask: 0.9914  decode.loss_dice: 0.6887  decode.d0.loss_cls: 0.6586  decode.d0.loss_mask: 0.9773  decode.d0.loss_dice: 0.6879  decode.d1.loss_cls: 0.2536  decode.d1.loss_mask: 1.0110  decode.d1.loss_dice: 0.7025  decode.d2.loss_cls: 0.2125  decode.d2.loss_mask: 0.9978  decode.d2.loss_dice: 0.7126  decode.d3.loss_cls: 0.2190  decode.d3.loss_mask: 1.0097  decode.d3.loss_dice: 0.6944  decode.d4.loss_cls: 0.1887  decode.d4.loss_mask: 1.0163  decode.d4.loss_dice: 0.6757  decode.d5.loss_cls: 0.2242  decode.d5.loss_mask: 1.0022  decode.d5.loss_dice: 0.7068  decode.d6.loss_cls: 0.2202  decode.d6.loss_mask: 0.9744  decode.d6.loss_dice: 0.7059  decode.d7.loss_cls: 0.2386  decode.d7.loss_mask: 0.9788  decode.d7.loss_dice: 0.6909  decode.d8.loss_cls: 0.1985  decode.d8.loss_mask: 0.9790  decode.d8.loss_dice: 0.6952
05/26 23:37:56 - mmengine - INFO - Iter(train) [107150/160000]  base_lr: 3.6901e-05 lr: 3.6901e-06  eta: 6:03:49  time: 0.4146  data_time: 0.0097  memory: 5975  grad_norm: 812.4427  loss: 20.8160  decode.loss_cls: 0.1855  decode.loss_mask: 1.0750  decode.loss_dice: 0.7511  decode.d0.loss_cls: 0.7453  decode.d0.loss_mask: 1.0428  decode.d0.loss_dice: 0.7103  decode.d1.loss_cls: 0.1619  decode.d1.loss_mask: 1.0806  decode.d1.loss_dice: 0.7415  decode.d2.loss_cls: 0.1536  decode.d2.loss_mask: 1.1276  decode.d2.loss_dice: 0.7663  decode.d3.loss_cls: 0.1697  decode.d3.loss_mask: 1.1278  decode.d3.loss_dice: 0.7730  decode.d4.loss_cls: 0.1715  decode.d4.loss_mask: 1.1060  decode.d4.loss_dice: 0.7798  decode.d5.loss_cls: 0.1606  decode.d5.loss_mask: 1.1169  decode.d5.loss_dice: 0.7834  decode.d6.loss_cls: 0.1835  decode.d6.loss_mask: 1.1157  decode.d6.loss_dice: 0.7488  decode.d7.loss_cls: 0.1815  decode.d7.loss_mask: 1.0970  decode.d7.loss_dice: 0.7623  decode.d8.loss_cls: 0.1818  decode.d8.loss_mask: 1.0759  decode.d8.loss_dice: 0.7389
05/26 23:38:17 - mmengine - INFO - Iter(train) [107200/160000]  base_lr: 3.6869e-05 lr: 3.6869e-06  eta: 6:03:28  time: 0.4144  data_time: 0.0099  memory: 5983  grad_norm: 762.1549  loss: 19.0313  decode.loss_cls: 0.1150  decode.loss_mask: 1.0790  decode.loss_dice: 0.6886  decode.d0.loss_cls: 0.6046  decode.d0.loss_mask: 1.0212  decode.d0.loss_dice: 0.6652  decode.d1.loss_cls: 0.1184  decode.d1.loss_mask: 1.0858  decode.d1.loss_dice: 0.6700  decode.d2.loss_cls: 0.1296  decode.d2.loss_mask: 1.0395  decode.d2.loss_dice: 0.6631  decode.d3.loss_cls: 0.1172  decode.d3.loss_mask: 1.0604  decode.d3.loss_dice: 0.6953  decode.d4.loss_cls: 0.1326  decode.d4.loss_mask: 1.0519  decode.d4.loss_dice: 0.6760  decode.d5.loss_cls: 0.1194  decode.d5.loss_mask: 1.0336  decode.d5.loss_dice: 0.6907  decode.d6.loss_cls: 0.1534  decode.d6.loss_mask: 1.0423  decode.d6.loss_dice: 0.6640  decode.d7.loss_cls: 0.1106  decode.d7.loss_mask: 1.0757  decode.d7.loss_dice: 0.6791  decode.d8.loss_cls: 0.1121  decode.d8.loss_mask: 1.0669  decode.d8.loss_dice: 0.6699
05/26 23:38:37 - mmengine - INFO - Iter(train) [107250/160000]  base_lr: 3.6838e-05 lr: 3.6838e-06  eta: 6:03:07  time: 0.4153  data_time: 0.0098  memory: 5974  grad_norm: 448.0348  loss: 19.3585  decode.loss_cls: 0.1749  decode.loss_mask: 0.9324  decode.loss_dice: 0.7636  decode.d0.loss_cls: 0.6061  decode.d0.loss_mask: 0.9175  decode.d0.loss_dice: 0.7654  decode.d1.loss_cls: 0.1484  decode.d1.loss_mask: 0.9614  decode.d1.loss_dice: 0.7895  decode.d2.loss_cls: 0.1601  decode.d2.loss_mask: 0.9367  decode.d2.loss_dice: 0.7756  decode.d3.loss_cls: 0.2151  decode.d3.loss_mask: 0.9339  decode.d3.loss_dice: 0.7684  decode.d4.loss_cls: 0.2167  decode.d4.loss_mask: 0.8790  decode.d4.loss_dice: 0.7562  decode.d5.loss_cls: 0.1926  decode.d5.loss_mask: 0.9673  decode.d5.loss_dice: 0.7912  decode.d6.loss_cls: 0.1827  decode.d6.loss_mask: 0.9350  decode.d6.loss_dice: 0.7487  decode.d7.loss_cls: 0.2023  decode.d7.loss_mask: 0.9432  decode.d7.loss_dice: 0.7612  decode.d8.loss_cls: 0.2042  decode.d8.loss_mask: 0.9698  decode.d8.loss_dice: 0.7596
05/26 23:38:58 - mmengine - INFO - Iter(train) [107300/160000]  base_lr: 3.6806e-05 lr: 3.6806e-06  eta: 6:02:47  time: 0.4153  data_time: 0.0098  memory: 5972  grad_norm: 884.0687  loss: 20.0970  decode.loss_cls: 0.2086  decode.loss_mask: 1.1018  decode.loss_dice: 0.6694  decode.d0.loss_cls: 0.7791  decode.d0.loss_mask: 1.0561  decode.d0.loss_dice: 0.6649  decode.d1.loss_cls: 0.1692  decode.d1.loss_mask: 1.0657  decode.d1.loss_dice: 0.6951  decode.d2.loss_cls: 0.1775  decode.d2.loss_mask: 1.0662  decode.d2.loss_dice: 0.6907  decode.d3.loss_cls: 0.1617  decode.d3.loss_mask: 1.1090  decode.d3.loss_dice: 0.6924  decode.d4.loss_cls: 0.1511  decode.d4.loss_mask: 1.1438  decode.d4.loss_dice: 0.6987  decode.d5.loss_cls: 0.1524  decode.d5.loss_mask: 1.1029  decode.d5.loss_dice: 0.6776  decode.d6.loss_cls: 0.1880  decode.d6.loss_mask: 1.0772  decode.d6.loss_dice: 0.6637  decode.d7.loss_cls: 0.1869  decode.d7.loss_mask: 1.0950  decode.d7.loss_dice: 0.6701  decode.d8.loss_cls: 0.1923  decode.d8.loss_mask: 1.1164  decode.d8.loss_dice: 0.6735
05/26 23:39:19 - mmengine - INFO - Iter(train) [107350/160000]  base_lr: 3.6775e-05 lr: 3.6775e-06  eta: 6:02:26  time: 0.4147  data_time: 0.0098  memory: 5982  grad_norm: 634.0466  loss: 23.1595  decode.loss_cls: 0.2339  decode.loss_mask: 1.1170  decode.loss_dice: 0.8847  decode.d0.loss_cls: 0.8314  decode.d0.loss_mask: 1.0447  decode.d0.loss_dice: 0.8846  decode.d1.loss_cls: 0.2969  decode.d1.loss_mask: 1.1158  decode.d1.loss_dice: 0.9219  decode.d2.loss_cls: 0.2325  decode.d2.loss_mask: 1.1337  decode.d2.loss_dice: 0.9172  decode.d3.loss_cls: 0.2327  decode.d3.loss_mask: 1.1024  decode.d3.loss_dice: 0.8965  decode.d4.loss_cls: 0.2672  decode.d4.loss_mask: 1.0916  decode.d4.loss_dice: 0.8999  decode.d5.loss_cls: 0.2323  decode.d5.loss_mask: 1.1136  decode.d5.loss_dice: 0.8943  decode.d6.loss_cls: 0.2449  decode.d6.loss_mask: 1.1129  decode.d6.loss_dice: 0.9097  decode.d7.loss_cls: 0.2527  decode.d7.loss_mask: 1.1143  decode.d7.loss_dice: 0.9184  decode.d8.loss_cls: 0.2288  decode.d8.loss_mask: 1.1179  decode.d8.loss_dice: 0.9152
05/26 23:39:40 - mmengine - INFO - Iter(train) [107400/160000]  base_lr: 3.6744e-05 lr: 3.6744e-06  eta: 6:02:06  time: 0.4149  data_time: 0.0099  memory: 5971  grad_norm: 1044.6841  loss: 19.3879  decode.loss_cls: 0.1276  decode.loss_mask: 1.0487  decode.loss_dice: 0.7203  decode.d0.loss_cls: 0.6248  decode.d0.loss_mask: 0.9682  decode.d0.loss_dice: 0.7032  decode.d1.loss_cls: 0.1772  decode.d1.loss_mask: 1.0261  decode.d1.loss_dice: 0.6597  decode.d2.loss_cls: 0.1415  decode.d2.loss_mask: 1.0299  decode.d2.loss_dice: 0.6983  decode.d3.loss_cls: 0.1523  decode.d3.loss_mask: 1.0453  decode.d3.loss_dice: 0.7292  decode.d4.loss_cls: 0.1566  decode.d4.loss_mask: 1.0698  decode.d4.loss_dice: 0.7101  decode.d5.loss_cls: 0.1290  decode.d5.loss_mask: 1.0620  decode.d5.loss_dice: 0.7162  decode.d6.loss_cls: 0.1543  decode.d6.loss_mask: 1.0463  decode.d6.loss_dice: 0.7130  decode.d7.loss_cls: 0.1491  decode.d7.loss_mask: 1.0361  decode.d7.loss_dice: 0.7103  decode.d8.loss_cls: 0.1598  decode.d8.loss_mask: 1.0115  decode.d8.loss_dice: 0.7115
05/26 23:40:00 - mmengine - INFO - Iter(train) [107450/160000]  base_lr: 3.6712e-05 lr: 3.6712e-06  eta: 6:01:45  time: 0.4144  data_time: 0.0099  memory: 5972  grad_norm: 337.2024  loss: 17.9058  decode.loss_cls: 0.2123  decode.loss_mask: 0.8519  decode.loss_dice: 0.6762  decode.d0.loss_cls: 0.5597  decode.d0.loss_mask: 0.8690  decode.d0.loss_dice: 0.6695  decode.d1.loss_cls: 0.2152  decode.d1.loss_mask: 0.8708  decode.d1.loss_dice: 0.6844  decode.d2.loss_cls: 0.1985  decode.d2.loss_mask: 0.8579  decode.d2.loss_dice: 0.6684  decode.d3.loss_cls: 0.2122  decode.d3.loss_mask: 0.8509  decode.d3.loss_dice: 0.6920  decode.d4.loss_cls: 0.2024  decode.d4.loss_mask: 0.8638  decode.d4.loss_dice: 0.7028  decode.d5.loss_cls: 0.2272  decode.d5.loss_mask: 0.8849  decode.d5.loss_dice: 0.6830  decode.d6.loss_cls: 0.1958  decode.d6.loss_mask: 0.8636  decode.d6.loss_dice: 0.6900  decode.d7.loss_cls: 0.2152  decode.d7.loss_mask: 0.8583  decode.d7.loss_dice: 0.6812  decode.d8.loss_cls: 0.2218  decode.d8.loss_mask: 0.8482  decode.d8.loss_dice: 0.6786
05/26 23:40:21 - mmengine - INFO - Iter(train) [107500/160000]  base_lr: 3.6681e-05 lr: 3.6681e-06  eta: 6:01:24  time: 0.4136  data_time: 0.0098  memory: 5980  grad_norm: 594.0558  loss: 22.3447  decode.loss_cls: 0.2239  decode.loss_mask: 1.1671  decode.loss_dice: 0.7934  decode.d0.loss_cls: 0.7602  decode.d0.loss_mask: 1.0703  decode.d0.loss_dice: 0.7806  decode.d1.loss_cls: 0.2310  decode.d1.loss_mask: 1.1650  decode.d1.loss_dice: 0.8230  decode.d2.loss_cls: 0.2221  decode.d2.loss_mask: 1.1868  decode.d2.loss_dice: 0.7863  decode.d3.loss_cls: 0.2153  decode.d3.loss_mask: 1.1823  decode.d3.loss_dice: 0.8039  decode.d4.loss_cls: 0.2206  decode.d4.loss_mask: 1.2022  decode.d4.loss_dice: 0.8116  decode.d5.loss_cls: 0.2130  decode.d5.loss_mask: 1.1782  decode.d5.loss_dice: 0.8134  decode.d6.loss_cls: 0.2476  decode.d6.loss_mask: 1.1449  decode.d6.loss_dice: 0.7849  decode.d7.loss_cls: 0.2386  decode.d7.loss_mask: 1.1530  decode.d7.loss_dice: 0.7823  decode.d8.loss_cls: 0.2459  decode.d8.loss_mask: 1.1263  decode.d8.loss_dice: 0.7708
05/26 23:40:42 - mmengine - INFO - Iter(train) [107550/160000]  base_lr: 3.6649e-05 lr: 3.6649e-06  eta: 6:01:04  time: 0.4139  data_time: 0.0098  memory: 5978  grad_norm: 525.7894  loss: 18.5833  decode.loss_cls: 0.1610  decode.loss_mask: 0.9599  decode.loss_dice: 0.6934  decode.d0.loss_cls: 0.6648  decode.d0.loss_mask: 0.9330  decode.d0.loss_dice: 0.6909  decode.d1.loss_cls: 0.1638  decode.d1.loss_mask: 0.9548  decode.d1.loss_dice: 0.7007  decode.d2.loss_cls: 0.1403  decode.d2.loss_mask: 0.9642  decode.d2.loss_dice: 0.6960  decode.d3.loss_cls: 0.1652  decode.d3.loss_mask: 0.9290  decode.d3.loss_dice: 0.6944  decode.d4.loss_cls: 0.1446  decode.d4.loss_mask: 0.9449  decode.d4.loss_dice: 0.7056  decode.d5.loss_cls: 0.1242  decode.d5.loss_mask: 0.9422  decode.d5.loss_dice: 0.7106  decode.d6.loss_cls: 0.1769  decode.d6.loss_mask: 0.9692  decode.d6.loss_dice: 0.7071  decode.d7.loss_cls: 0.1623  decode.d7.loss_mask: 0.9712  decode.d7.loss_dice: 0.7069  decode.d8.loss_cls: 0.1402  decode.d8.loss_mask: 0.9656  decode.d8.loss_dice: 0.7003
05/26 23:41:02 - mmengine - INFO - Iter(train) [107600/160000]  base_lr: 3.6618e-05 lr: 3.6618e-06  eta: 6:00:43  time: 0.4133  data_time: 0.0098  memory: 5972  grad_norm: 541.8388  loss: 18.7681  decode.loss_cls: 0.1270  decode.loss_mask: 1.0616  decode.loss_dice: 0.6634  decode.d0.loss_cls: 0.7356  decode.d0.loss_mask: 0.9575  decode.d0.loss_dice: 0.6140  decode.d1.loss_cls: 0.1579  decode.d1.loss_mask: 1.0093  decode.d1.loss_dice: 0.6414  decode.d2.loss_cls: 0.1400  decode.d2.loss_mask: 1.0587  decode.d2.loss_dice: 0.6736  decode.d3.loss_cls: 0.1325  decode.d3.loss_mask: 1.0475  decode.d3.loss_dice: 0.6641  decode.d4.loss_cls: 0.1199  decode.d4.loss_mask: 1.0434  decode.d4.loss_dice: 0.6534  decode.d5.loss_cls: 0.1359  decode.d5.loss_mask: 1.0139  decode.d5.loss_dice: 0.6545  decode.d6.loss_cls: 0.1705  decode.d6.loss_mask: 1.0188  decode.d6.loss_dice: 0.6412  decode.d7.loss_cls: 0.1326  decode.d7.loss_mask: 1.0433  decode.d7.loss_dice: 0.6472  decode.d8.loss_cls: 0.1263  decode.d8.loss_mask: 1.0356  decode.d8.loss_dice: 0.6478
05/26 23:41:23 - mmengine - INFO - Iter(train) [107650/160000]  base_lr: 3.6586e-05 lr: 3.6586e-06  eta: 6:00:22  time: 0.4135  data_time: 0.0098  memory: 5971  grad_norm: 360.9513  loss: 20.6234  decode.loss_cls: 0.1437  decode.loss_mask: 1.1819  decode.loss_dice: 0.7081  decode.d0.loss_cls: 0.6159  decode.d0.loss_mask: 1.1575  decode.d0.loss_dice: 0.6911  decode.d1.loss_cls: 0.1198  decode.d1.loss_mask: 1.1670  decode.d1.loss_dice: 0.7040  decode.d2.loss_cls: 0.1206  decode.d2.loss_mask: 1.1778  decode.d2.loss_dice: 0.7112  decode.d3.loss_cls: 0.1211  decode.d3.loss_mask: 1.1590  decode.d3.loss_dice: 0.7124  decode.d4.loss_cls: 0.1347  decode.d4.loss_mask: 1.1874  decode.d4.loss_dice: 0.7200  decode.d5.loss_cls: 0.1195  decode.d5.loss_mask: 1.1893  decode.d5.loss_dice: 0.7095  decode.d6.loss_cls: 0.1447  decode.d6.loss_mask: 1.1974  decode.d6.loss_dice: 0.7188  decode.d7.loss_cls: 0.1116  decode.d7.loss_mask: 1.1837  decode.d7.loss_dice: 0.6949  decode.d8.loss_cls: 0.1340  decode.d8.loss_mask: 1.1879  decode.d8.loss_dice: 0.6989
05/26 23:41:44 - mmengine - INFO - Iter(train) [107700/160000]  base_lr: 3.6555e-05 lr: 3.6555e-06  eta: 6:00:02  time: 0.4139  data_time: 0.0097  memory: 5976  grad_norm: 707.8607  loss: 21.2426  decode.loss_cls: 0.1842  decode.loss_mask: 1.1259  decode.loss_dice: 0.7732  decode.d0.loss_cls: 0.6333  decode.d0.loss_mask: 1.0372  decode.d0.loss_dice: 0.7589  decode.d1.loss_cls: 0.2148  decode.d1.loss_mask: 1.1036  decode.d1.loss_dice: 0.7691  decode.d2.loss_cls: 0.2160  decode.d2.loss_mask: 1.0915  decode.d2.loss_dice: 0.7934  decode.d3.loss_cls: 0.2270  decode.d3.loss_mask: 1.0972  decode.d3.loss_dice: 0.7699  decode.d4.loss_cls: 0.1987  decode.d4.loss_mask: 1.0937  decode.d4.loss_dice: 0.7667  decode.d5.loss_cls: 0.2200  decode.d5.loss_mask: 1.1276  decode.d5.loss_dice: 0.7718  decode.d6.loss_cls: 0.1895  decode.d6.loss_mask: 1.1373  decode.d6.loss_dice: 0.7596  decode.d7.loss_cls: 0.2080  decode.d7.loss_mask: 1.1174  decode.d7.loss_dice: 0.7657  decode.d8.loss_cls: 0.1961  decode.d8.loss_mask: 1.1177  decode.d8.loss_dice: 0.7775
05/26 23:42:05 - mmengine - INFO - Iter(train) [107750/160000]  base_lr: 3.6523e-05 lr: 3.6523e-06  eta: 5:59:41  time: 0.4132  data_time: 0.0097  memory: 5971  grad_norm: 332.1989  loss: 18.0764  decode.loss_cls: 0.1726  decode.loss_mask: 0.9330  decode.loss_dice: 0.6788  decode.d0.loss_cls: 0.6594  decode.d0.loss_mask: 0.8765  decode.d0.loss_dice: 0.6666  decode.d1.loss_cls: 0.1809  decode.d1.loss_mask: 0.9317  decode.d1.loss_dice: 0.6787  decode.d2.loss_cls: 0.1562  decode.d2.loss_mask: 0.9279  decode.d2.loss_dice: 0.6769  decode.d3.loss_cls: 0.1638  decode.d3.loss_mask: 0.9069  decode.d3.loss_dice: 0.6734  decode.d4.loss_cls: 0.1763  decode.d4.loss_mask: 0.8964  decode.d4.loss_dice: 0.6797  decode.d5.loss_cls: 0.1453  decode.d5.loss_mask: 0.9217  decode.d5.loss_dice: 0.6812  decode.d6.loss_cls: 0.1724  decode.d6.loss_mask: 0.9129  decode.d6.loss_dice: 0.6681  decode.d7.loss_cls: 0.1697  decode.d7.loss_mask: 0.9201  decode.d7.loss_dice: 0.6802  decode.d8.loss_cls: 0.1819  decode.d8.loss_mask: 0.9060  decode.d8.loss_dice: 0.6812
05/26 23:42:25 - mmengine - INFO - Iter(train) [107800/160000]  base_lr: 3.6492e-05 lr: 3.6492e-06  eta: 5:59:21  time: 0.4152  data_time: 0.0099  memory: 5983  grad_norm: 594.2476  loss: 18.6858  decode.loss_cls: 0.1414  decode.loss_mask: 0.9824  decode.loss_dice: 0.6890  decode.d0.loss_cls: 0.6549  decode.d0.loss_mask: 0.9029  decode.d0.loss_dice: 0.6697  decode.d1.loss_cls: 0.1943  decode.d1.loss_mask: 0.9481  decode.d1.loss_dice: 0.6833  decode.d2.loss_cls: 0.1266  decode.d2.loss_mask: 0.9942  decode.d2.loss_dice: 0.7382  decode.d3.loss_cls: 0.1834  decode.d3.loss_mask: 0.9785  decode.d3.loss_dice: 0.6857  decode.d4.loss_cls: 0.1771  decode.d4.loss_mask: 0.9498  decode.d4.loss_dice: 0.6806  decode.d5.loss_cls: 0.1467  decode.d5.loss_mask: 0.9580  decode.d5.loss_dice: 0.7102  decode.d6.loss_cls: 0.1882  decode.d6.loss_mask: 0.9442  decode.d6.loss_dice: 0.6751  decode.d7.loss_cls: 0.1547  decode.d7.loss_mask: 0.9936  decode.d7.loss_dice: 0.7210  decode.d8.loss_cls: 0.1361  decode.d8.loss_mask: 0.9809  decode.d8.loss_dice: 0.6968
05/26 23:42:46 - mmengine - INFO - Iter(train) [107850/160000]  base_lr: 3.6461e-05 lr: 3.6461e-06  eta: 5:59:00  time: 0.4154  data_time: 0.0097  memory: 5969  grad_norm: 593.6899  loss: 18.5927  decode.loss_cls: 0.1817  decode.loss_mask: 0.9093  decode.loss_dice: 0.7036  decode.d0.loss_cls: 0.5644  decode.d0.loss_mask: 0.9162  decode.d0.loss_dice: 0.6672  decode.d1.loss_cls: 0.1938  decode.d1.loss_mask: 0.9262  decode.d1.loss_dice: 0.7064  decode.d2.loss_cls: 0.2161  decode.d2.loss_mask: 0.9199  decode.d2.loss_dice: 0.7279  decode.d3.loss_cls: 0.1870  decode.d3.loss_mask: 0.9146  decode.d3.loss_dice: 0.7170  decode.d4.loss_cls: 0.2002  decode.d4.loss_mask: 0.9230  decode.d4.loss_dice: 0.6952  decode.d5.loss_cls: 0.2008  decode.d5.loss_mask: 0.9288  decode.d5.loss_dice: 0.6971  decode.d6.loss_cls: 0.1995  decode.d6.loss_mask: 0.9201  decode.d6.loss_dice: 0.7384  decode.d7.loss_cls: 0.1961  decode.d7.loss_mask: 0.9206  decode.d7.loss_dice: 0.7131  decode.d8.loss_cls: 0.1860  decode.d8.loss_mask: 0.9153  decode.d8.loss_dice: 0.7076
05/26 23:43:07 - mmengine - INFO - Iter(train) [107900/160000]  base_lr: 3.6429e-05 lr: 3.6429e-06  eta: 5:58:39  time: 0.4144  data_time: 0.0098  memory: 5967  grad_norm: 419.9164  loss: 19.3892  decode.loss_cls: 0.2224  decode.loss_mask: 0.9306  decode.loss_dice: 0.7194  decode.d0.loss_cls: 0.7587  decode.d0.loss_mask: 0.8914  decode.d0.loss_dice: 0.7217  decode.d1.loss_cls: 0.2295  decode.d1.loss_mask: 0.9395  decode.d1.loss_dice: 0.7463  decode.d2.loss_cls: 0.1504  decode.d2.loss_mask: 0.9467  decode.d2.loss_dice: 0.7567  decode.d3.loss_cls: 0.1557  decode.d3.loss_mask: 0.9596  decode.d3.loss_dice: 0.8059  decode.d4.loss_cls: 0.1923  decode.d4.loss_mask: 0.9422  decode.d4.loss_dice: 0.7732  decode.d5.loss_cls: 0.1875  decode.d5.loss_mask: 0.9368  decode.d5.loss_dice: 0.7522  decode.d6.loss_cls: 0.1414  decode.d6.loss_mask: 0.9632  decode.d6.loss_dice: 0.8316  decode.d7.loss_cls: 0.1841  decode.d7.loss_mask: 0.9337  decode.d7.loss_dice: 0.7531  decode.d8.loss_cls: 0.1705  decode.d8.loss_mask: 0.9388  decode.d8.loss_dice: 0.7540
05/26 23:43:28 - mmengine - INFO - Iter(train) [107950/160000]  base_lr: 3.6398e-05 lr: 3.6398e-06  eta: 5:58:19  time: 0.4143  data_time: 0.0098  memory: 5968  grad_norm: 753.1792  loss: 22.1611  decode.loss_cls: 0.2094  decode.loss_mask: 1.1259  decode.loss_dice: 0.8163  decode.d0.loss_cls: 0.7682  decode.d0.loss_mask: 1.0395  decode.d0.loss_dice: 0.7841  decode.d1.loss_cls: 0.2531  decode.d1.loss_mask: 1.1174  decode.d1.loss_dice: 0.8176  decode.d2.loss_cls: 0.2348  decode.d2.loss_mask: 1.1137  decode.d2.loss_dice: 0.8139  decode.d3.loss_cls: 0.2753  decode.d3.loss_mask: 1.0833  decode.d3.loss_dice: 0.7972  decode.d4.loss_cls: 0.2374  decode.d4.loss_mask: 1.1012  decode.d4.loss_dice: 0.8017  decode.d5.loss_cls: 0.2521  decode.d5.loss_mask: 1.0952  decode.d5.loss_dice: 0.7986  decode.d6.loss_cls: 0.2996  decode.d6.loss_mask: 1.1452  decode.d6.loss_dice: 0.8182  decode.d7.loss_cls: 0.2177  decode.d7.loss_mask: 1.1294  decode.d7.loss_dice: 0.8495  decode.d8.loss_cls: 0.2818  decode.d8.loss_mask: 1.0797  decode.d8.loss_dice: 0.8040
05/26 23:43:48 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 23:43:48 - mmengine - INFO - Iter(train) [108000/160000]  base_lr: 3.6366e-05 lr: 3.6366e-06  eta: 5:57:58  time: 0.4147  data_time: 0.0098  memory: 5971  grad_norm: 520.0955  loss: 16.2375  decode.loss_cls: 0.1278  decode.loss_mask: 0.8948  decode.loss_dice: 0.5720  decode.d0.loss_cls: 0.5877  decode.d0.loss_mask: 0.8705  decode.d0.loss_dice: 0.5676  decode.d1.loss_cls: 0.1150  decode.d1.loss_mask: 0.9054  decode.d1.loss_dice: 0.5560  decode.d2.loss_cls: 0.1561  decode.d2.loss_mask: 0.8718  decode.d2.loss_dice: 0.5521  decode.d3.loss_cls: 0.1254  decode.d3.loss_mask: 0.8787  decode.d3.loss_dice: 0.5477  decode.d4.loss_cls: 0.1302  decode.d4.loss_mask: 0.9026  decode.d4.loss_dice: 0.5799  decode.d5.loss_cls: 0.1278  decode.d5.loss_mask: 0.8922  decode.d5.loss_dice: 0.5734  decode.d6.loss_cls: 0.1219  decode.d6.loss_mask: 0.8953  decode.d6.loss_dice: 0.5577  decode.d7.loss_cls: 0.1208  decode.d7.loss_mask: 0.8926  decode.d7.loss_dice: 0.5572  decode.d8.loss_cls: 0.1279  decode.d8.loss_mask: 0.8766  decode.d8.loss_dice: 0.5526
05/26 23:44:09 - mmengine - INFO - Iter(train) [108050/160000]  base_lr: 3.6335e-05 lr: 3.6335e-06  eta: 5:57:38  time: 0.4150  data_time: 0.0108  memory: 5977  grad_norm: 807.2696  loss: 23.7007  decode.loss_cls: 0.3310  decode.loss_mask: 1.1904  decode.loss_dice: 0.8268  decode.d0.loss_cls: 0.9270  decode.d0.loss_mask: 1.0866  decode.d0.loss_dice: 0.7652  decode.d1.loss_cls: 0.3111  decode.d1.loss_mask: 1.2267  decode.d1.loss_dice: 0.8100  decode.d2.loss_cls: 0.3433  decode.d2.loss_mask: 1.1931  decode.d2.loss_dice: 0.8225  decode.d3.loss_cls: 0.3206  decode.d3.loss_mask: 1.1925  decode.d3.loss_dice: 0.8145  decode.d4.loss_cls: 0.3383  decode.d4.loss_mask: 1.1501  decode.d4.loss_dice: 0.7957  decode.d5.loss_cls: 0.3531  decode.d5.loss_mask: 1.1380  decode.d5.loss_dice: 0.8156  decode.d6.loss_cls: 0.3276  decode.d6.loss_mask: 1.1291  decode.d6.loss_dice: 0.8077  decode.d7.loss_cls: 0.4173  decode.d7.loss_mask: 1.1023  decode.d7.loss_dice: 0.8031  decode.d8.loss_cls: 0.3678  decode.d8.loss_mask: 1.1569  decode.d8.loss_dice: 0.8367
05/26 23:44:30 - mmengine - INFO - Iter(train) [108100/160000]  base_lr: 3.6303e-05 lr: 3.6303e-06  eta: 5:57:17  time: 0.4148  data_time: 0.0098  memory: 5969  grad_norm: 368.2068  loss: 18.9211  decode.loss_cls: 0.1816  decode.loss_mask: 0.9598  decode.loss_dice: 0.7532  decode.d0.loss_cls: 0.7338  decode.d0.loss_mask: 0.8160  decode.d0.loss_dice: 0.7117  decode.d1.loss_cls: 0.1833  decode.d1.loss_mask: 0.9455  decode.d1.loss_dice: 0.7764  decode.d2.loss_cls: 0.1340  decode.d2.loss_mask: 0.9478  decode.d2.loss_dice: 0.7698  decode.d3.loss_cls: 0.1529  decode.d3.loss_mask: 0.9073  decode.d3.loss_dice: 0.7566  decode.d4.loss_cls: 0.1691  decode.d4.loss_mask: 0.9528  decode.d4.loss_dice: 0.7559  decode.d5.loss_cls: 0.1998  decode.d5.loss_mask: 0.8940  decode.d5.loss_dice: 0.7554  decode.d6.loss_cls: 0.1753  decode.d6.loss_mask: 0.8940  decode.d6.loss_dice: 0.7616  decode.d7.loss_cls: 0.1608  decode.d7.loss_mask: 0.9190  decode.d7.loss_dice: 0.7466  decode.d8.loss_cls: 0.1381  decode.d8.loss_mask: 0.9243  decode.d8.loss_dice: 0.7446
05/26 23:44:51 - mmengine - INFO - Iter(train) [108150/160000]  base_lr: 3.6272e-05 lr: 3.6272e-06  eta: 5:56:56  time: 0.4139  data_time: 0.0098  memory: 5972  grad_norm: 444.5334  loss: 21.6905  decode.loss_cls: 0.2141  decode.loss_mask: 1.1493  decode.loss_dice: 0.7716  decode.d0.loss_cls: 0.6830  decode.d0.loss_mask: 1.1171  decode.d0.loss_dice: 0.7548  decode.d1.loss_cls: 0.1972  decode.d1.loss_mask: 1.1541  decode.d1.loss_dice: 0.7722  decode.d2.loss_cls: 0.1957  decode.d2.loss_mask: 1.1463  decode.d2.loss_dice: 0.7828  decode.d3.loss_cls: 0.2024  decode.d3.loss_mask: 1.1551  decode.d3.loss_dice: 0.7816  decode.d4.loss_cls: 0.2292  decode.d4.loss_mask: 1.1000  decode.d4.loss_dice: 0.7657  decode.d5.loss_cls: 0.2104  decode.d5.loss_mask: 1.1405  decode.d5.loss_dice: 0.7684  decode.d6.loss_cls: 0.1996  decode.d6.loss_mask: 1.1554  decode.d6.loss_dice: 0.7885  decode.d7.loss_cls: 0.2010  decode.d7.loss_mask: 1.1686  decode.d7.loss_dice: 0.7895  decode.d8.loss_cls: 0.2026  decode.d8.loss_mask: 1.1306  decode.d8.loss_dice: 0.7630
05/26 23:45:11 - mmengine - INFO - Iter(train) [108200/160000]  base_lr: 3.6240e-05 lr: 3.6240e-06  eta: 5:56:36  time: 0.4133  data_time: 0.0098  memory: 5970  grad_norm: 603.2077  loss: 20.3836  decode.loss_cls: 0.1910  decode.loss_mask: 1.0684  decode.loss_dice: 0.7297  decode.d0.loss_cls: 0.7006  decode.d0.loss_mask: 0.9587  decode.d0.loss_dice: 0.6698  decode.d1.loss_cls: 0.1980  decode.d1.loss_mask: 1.0860  decode.d1.loss_dice: 0.7588  decode.d2.loss_cls: 0.1419  decode.d2.loss_mask: 1.1035  decode.d2.loss_dice: 0.7623  decode.d3.loss_cls: 0.1680  decode.d3.loss_mask: 1.0979  decode.d3.loss_dice: 0.7455  decode.d4.loss_cls: 0.2133  decode.d4.loss_mask: 1.0543  decode.d4.loss_dice: 0.7372  decode.d5.loss_cls: 0.1959  decode.d5.loss_mask: 1.0477  decode.d5.loss_dice: 0.7324  decode.d6.loss_cls: 0.1891  decode.d6.loss_mask: 1.0780  decode.d6.loss_dice: 0.7423  decode.d7.loss_cls: 0.1777  decode.d7.loss_mask: 1.0978  decode.d7.loss_dice: 0.7419  decode.d8.loss_cls: 0.2107  decode.d8.loss_mask: 1.0658  decode.d8.loss_dice: 0.7195
05/26 23:45:32 - mmengine - INFO - Iter(train) [108250/160000]  base_lr: 3.6209e-05 lr: 3.6209e-06  eta: 5:56:15  time: 0.4135  data_time: 0.0098  memory: 5971  grad_norm: 561.9608  loss: 20.4868  decode.loss_cls: 0.2061  decode.loss_mask: 1.0808  decode.loss_dice: 0.7454  decode.d0.loss_cls: 0.7461  decode.d0.loss_mask: 1.0134  decode.d0.loss_dice: 0.7207  decode.d1.loss_cls: 0.1665  decode.d1.loss_mask: 1.0843  decode.d1.loss_dice: 0.7432  decode.d2.loss_cls: 0.2004  decode.d2.loss_mask: 1.0963  decode.d2.loss_dice: 0.7368  decode.d3.loss_cls: 0.1760  decode.d3.loss_mask: 1.0918  decode.d3.loss_dice: 0.7218  decode.d4.loss_cls: 0.1980  decode.d4.loss_mask: 1.0991  decode.d4.loss_dice: 0.7468  decode.d5.loss_cls: 0.1722  decode.d5.loss_mask: 1.0768  decode.d5.loss_dice: 0.7213  decode.d6.loss_cls: 0.1973  decode.d6.loss_mask: 1.0843  decode.d6.loss_dice: 0.7273  decode.d7.loss_cls: 0.1982  decode.d7.loss_mask: 1.0751  decode.d7.loss_dice: 0.7398  decode.d8.loss_cls: 0.1630  decode.d8.loss_mask: 1.0513  decode.d8.loss_dice: 0.7067
05/26 23:45:53 - mmengine - INFO - Iter(train) [108300/160000]  base_lr: 3.6177e-05 lr: 3.6177e-06  eta: 5:55:54  time: 0.4138  data_time: 0.0099  memory: 5973  grad_norm: 638.4675  loss: 21.9712  decode.loss_cls: 0.2485  decode.loss_mask: 1.0318  decode.loss_dice: 0.8634  decode.d0.loss_cls: 0.7860  decode.d0.loss_mask: 1.0382  decode.d0.loss_dice: 0.8458  decode.d1.loss_cls: 0.2798  decode.d1.loss_mask: 1.0355  decode.d1.loss_dice: 0.8528  decode.d2.loss_cls: 0.2681  decode.d2.loss_mask: 1.0268  decode.d2.loss_dice: 0.8371  decode.d3.loss_cls: 0.2590  decode.d3.loss_mask: 1.0272  decode.d3.loss_dice: 0.8433  decode.d4.loss_cls: 0.3014  decode.d4.loss_mask: 1.0034  decode.d4.loss_dice: 0.8255  decode.d5.loss_cls: 0.2710  decode.d5.loss_mask: 1.0246  decode.d5.loss_dice: 0.8343  decode.d6.loss_cls: 0.2791  decode.d6.loss_mask: 1.0235  decode.d6.loss_dice: 0.8591  decode.d7.loss_cls: 0.2631  decode.d7.loss_mask: 1.0523  decode.d7.loss_dice: 0.8460  decode.d8.loss_cls: 0.2483  decode.d8.loss_mask: 1.0506  decode.d8.loss_dice: 0.8457
05/26 23:46:14 - mmengine - INFO - Iter(train) [108350/160000]  base_lr: 3.6146e-05 lr: 3.6146e-06  eta: 5:55:34  time: 0.4134  data_time: 0.0097  memory: 5967  grad_norm: 551.8192  loss: 19.2152  decode.loss_cls: 0.1831  decode.loss_mask: 1.0167  decode.loss_dice: 0.6623  decode.d0.loss_cls: 0.7359  decode.d0.loss_mask: 0.9753  decode.d0.loss_dice: 0.6415  decode.d1.loss_cls: 0.2216  decode.d1.loss_mask: 1.0066  decode.d1.loss_dice: 0.6661  decode.d2.loss_cls: 0.2229  decode.d2.loss_mask: 0.9915  decode.d2.loss_dice: 0.6470  decode.d3.loss_cls: 0.1762  decode.d3.loss_mask: 0.9809  decode.d3.loss_dice: 0.6380  decode.d4.loss_cls: 0.1750  decode.d4.loss_mask: 1.0388  decode.d4.loss_dice: 0.6699  decode.d5.loss_cls: 0.1963  decode.d5.loss_mask: 1.0507  decode.d5.loss_dice: 0.6560  decode.d6.loss_cls: 0.1974  decode.d6.loss_mask: 1.0378  decode.d6.loss_dice: 0.6697  decode.d7.loss_cls: 0.2324  decode.d7.loss_mask: 0.9989  decode.d7.loss_dice: 0.6461  decode.d8.loss_cls: 0.2327  decode.d8.loss_mask: 0.9937  decode.d8.loss_dice: 0.6541
05/26 23:46:34 - mmengine - INFO - Iter(train) [108400/160000]  base_lr: 3.6114e-05 lr: 3.6114e-06  eta: 5:55:13  time: 0.4140  data_time: 0.0098  memory: 5975  grad_norm: 496.4851  loss: 17.3975  decode.loss_cls: 0.1486  decode.loss_mask: 0.9491  decode.loss_dice: 0.5790  decode.d0.loss_cls: 0.5282  decode.d0.loss_mask: 0.9409  decode.d0.loss_dice: 0.6307  decode.d1.loss_cls: 0.1562  decode.d1.loss_mask: 0.9322  decode.d1.loss_dice: 0.6059  decode.d2.loss_cls: 0.1689  decode.d2.loss_mask: 0.9344  decode.d2.loss_dice: 0.5815  decode.d3.loss_cls: 0.1594  decode.d3.loss_mask: 0.9455  decode.d3.loss_dice: 0.5868  decode.d4.loss_cls: 0.1559  decode.d4.loss_mask: 0.9541  decode.d4.loss_dice: 0.5934  decode.d5.loss_cls: 0.1659  decode.d5.loss_mask: 0.9600  decode.d5.loss_dice: 0.6163  decode.d6.loss_cls: 0.1608  decode.d6.loss_mask: 0.9757  decode.d6.loss_dice: 0.5889  decode.d7.loss_cls: 0.1592  decode.d7.loss_mask: 0.9421  decode.d7.loss_dice: 0.5986  decode.d8.loss_cls: 0.1582  decode.d8.loss_mask: 0.9430  decode.d8.loss_dice: 0.5783
05/26 23:46:55 - mmengine - INFO - Iter(train) [108450/160000]  base_lr: 3.6083e-05 lr: 3.6083e-06  eta: 5:54:53  time: 0.4147  data_time: 0.0098  memory: 5975  grad_norm: 701.3666  loss: 20.2646  decode.loss_cls: 0.1589  decode.loss_mask: 1.0721  decode.loss_dice: 0.7469  decode.d0.loss_cls: 0.5771  decode.d0.loss_mask: 1.0216  decode.d0.loss_dice: 0.7426  decode.d1.loss_cls: 0.1783  decode.d1.loss_mask: 1.0569  decode.d1.loss_dice: 0.7381  decode.d2.loss_cls: 0.1936  decode.d2.loss_mask: 1.0521  decode.d2.loss_dice: 0.7427  decode.d3.loss_cls: 0.1869  decode.d3.loss_mask: 1.0541  decode.d3.loss_dice: 0.7638  decode.d4.loss_cls: 0.2022  decode.d4.loss_mask: 1.0539  decode.d4.loss_dice: 0.7525  decode.d5.loss_cls: 0.1590  decode.d5.loss_mask: 1.0499  decode.d5.loss_dice: 0.7475  decode.d6.loss_cls: 0.2031  decode.d6.loss_mask: 1.0580  decode.d6.loss_dice: 0.7649  decode.d7.loss_cls: 0.1657  decode.d7.loss_mask: 1.0697  decode.d7.loss_dice: 0.7875  decode.d8.loss_cls: 0.1792  decode.d8.loss_mask: 1.0413  decode.d8.loss_dice: 0.7446
05/26 23:47:16 - mmengine - INFO - Iter(train) [108500/160000]  base_lr: 3.6051e-05 lr: 3.6051e-06  eta: 5:54:32  time: 0.4143  data_time: 0.0098  memory: 5981  grad_norm: 564.2300  loss: 20.9615  decode.loss_cls: 0.1684  decode.loss_mask: 1.1269  decode.loss_dice: 0.7392  decode.d0.loss_cls: 0.6141  decode.d0.loss_mask: 1.0997  decode.d0.loss_dice: 0.7459  decode.d1.loss_cls: 0.2300  decode.d1.loss_mask: 1.1922  decode.d1.loss_dice: 0.7419  decode.d2.loss_cls: 0.1979  decode.d2.loss_mask: 1.1415  decode.d2.loss_dice: 0.7173  decode.d3.loss_cls: 0.1948  decode.d3.loss_mask: 1.0990  decode.d3.loss_dice: 0.7564  decode.d4.loss_cls: 0.2618  decode.d4.loss_mask: 1.0844  decode.d4.loss_dice: 0.7211  decode.d5.loss_cls: 0.2119  decode.d5.loss_mask: 1.0770  decode.d5.loss_dice: 0.7163  decode.d6.loss_cls: 0.2123  decode.d6.loss_mask: 1.0958  decode.d6.loss_dice: 0.7402  decode.d7.loss_cls: 0.1803  decode.d7.loss_mask: 1.1213  decode.d7.loss_dice: 0.7376  decode.d8.loss_cls: 0.1586  decode.d8.loss_mask: 1.1215  decode.d8.loss_dice: 0.7560
05/26 23:47:37 - mmengine - INFO - Iter(train) [108550/160000]  base_lr: 3.6020e-05 lr: 3.6020e-06  eta: 5:54:11  time: 0.4141  data_time: 0.0098  memory: 5980  grad_norm: 512.2519  loss: 19.2216  decode.loss_cls: 0.2096  decode.loss_mask: 0.9867  decode.loss_dice: 0.6980  decode.d0.loss_cls: 0.8057  decode.d0.loss_mask: 0.9611  decode.d0.loss_dice: 0.6866  decode.d1.loss_cls: 0.1928  decode.d1.loss_mask: 0.9729  decode.d1.loss_dice: 0.6949  decode.d2.loss_cls: 0.1837  decode.d2.loss_mask: 0.9562  decode.d2.loss_dice: 0.6927  decode.d3.loss_cls: 0.1933  decode.d3.loss_mask: 0.9602  decode.d3.loss_dice: 0.7031  decode.d4.loss_cls: 0.2104  decode.d4.loss_mask: 0.9630  decode.d4.loss_dice: 0.6947  decode.d5.loss_cls: 0.2078  decode.d5.loss_mask: 0.9721  decode.d5.loss_dice: 0.6877  decode.d6.loss_cls: 0.2143  decode.d6.loss_mask: 0.9609  decode.d6.loss_dice: 0.6750  decode.d7.loss_cls: 0.2191  decode.d7.loss_mask: 0.9556  decode.d7.loss_dice: 0.6921  decode.d8.loss_cls: 0.2209  decode.d8.loss_mask: 0.9518  decode.d8.loss_dice: 0.6987
05/26 23:47:57 - mmengine - INFO - Iter(train) [108600/160000]  base_lr: 3.5988e-05 lr: 3.5988e-06  eta: 5:53:51  time: 0.4146  data_time: 0.0098  memory: 5969  grad_norm: 549.5450  loss: 19.2982  decode.loss_cls: 0.0966  decode.loss_mask: 1.0029  decode.loss_dice: 0.7384  decode.d0.loss_cls: 0.6491  decode.d0.loss_mask: 1.0072  decode.d0.loss_dice: 0.7138  decode.d1.loss_cls: 0.0874  decode.d1.loss_mask: 1.0220  decode.d1.loss_dice: 0.7895  decode.d2.loss_cls: 0.0935  decode.d2.loss_mask: 0.9939  decode.d2.loss_dice: 0.7649  decode.d3.loss_cls: 0.0727  decode.d3.loss_mask: 1.0098  decode.d3.loss_dice: 0.7913  decode.d4.loss_cls: 0.0784  decode.d4.loss_mask: 1.0285  decode.d4.loss_dice: 0.7904  decode.d5.loss_cls: 0.0937  decode.d5.loss_mask: 1.0115  decode.d5.loss_dice: 0.7743  decode.d6.loss_cls: 0.0774  decode.d6.loss_mask: 1.0334  decode.d6.loss_dice: 0.7926  decode.d7.loss_cls: 0.1022  decode.d7.loss_mask: 1.0038  decode.d7.loss_dice: 0.7620  decode.d8.loss_cls: 0.0880  decode.d8.loss_mask: 1.0436  decode.d8.loss_dice: 0.7851
05/26 23:48:18 - mmengine - INFO - Iter(train) [108650/160000]  base_lr: 3.5957e-05 lr: 3.5957e-06  eta: 5:53:30  time: 0.4140  data_time: 0.0098  memory: 5971  grad_norm: 579.4040  loss: 21.7400  decode.loss_cls: 0.1985  decode.loss_mask: 1.0967  decode.loss_dice: 0.8453  decode.d0.loss_cls: 0.5744  decode.d0.loss_mask: 1.0868  decode.d0.loss_dice: 0.8676  decode.d1.loss_cls: 0.2011  decode.d1.loss_mask: 1.0845  decode.d1.loss_dice: 0.8512  decode.d2.loss_cls: 0.1793  decode.d2.loss_mask: 1.1015  decode.d2.loss_dice: 0.8527  decode.d3.loss_cls: 0.1615  decode.d3.loss_mask: 1.0976  decode.d3.loss_dice: 0.8584  decode.d4.loss_cls: 0.2115  decode.d4.loss_mask: 1.0852  decode.d4.loss_dice: 0.8520  decode.d5.loss_cls: 0.1997  decode.d5.loss_mask: 1.0960  decode.d5.loss_dice: 0.8376  decode.d6.loss_cls: 0.1946  decode.d6.loss_mask: 1.0950  decode.d6.loss_dice: 0.8465  decode.d7.loss_cls: 0.1971  decode.d7.loss_mask: 1.0748  decode.d7.loss_dice: 0.8499  decode.d8.loss_cls: 0.2052  decode.d8.loss_mask: 1.0951  decode.d8.loss_dice: 0.8426
05/26 23:48:39 - mmengine - INFO - Iter(train) [108700/160000]  base_lr: 3.5925e-05 lr: 3.5925e-06  eta: 5:53:09  time: 0.4147  data_time: 0.0098  memory: 5972  grad_norm: 456.6749  loss: 20.4435  decode.loss_cls: 0.1712  decode.loss_mask: 1.1251  decode.loss_dice: 0.7023  decode.d0.loss_cls: 0.7332  decode.d0.loss_mask: 1.0585  decode.d0.loss_dice: 0.6915  decode.d1.loss_cls: 0.2239  decode.d1.loss_mask: 1.0571  decode.d1.loss_dice: 0.7290  decode.d2.loss_cls: 0.2264  decode.d2.loss_mask: 1.0551  decode.d2.loss_dice: 0.6938  decode.d3.loss_cls: 0.1790  decode.d3.loss_mask: 1.0866  decode.d3.loss_dice: 0.7060  decode.d4.loss_cls: 0.2437  decode.d4.loss_mask: 1.0680  decode.d4.loss_dice: 0.7053  decode.d5.loss_cls: 0.2373  decode.d5.loss_mask: 1.0755  decode.d5.loss_dice: 0.6914  decode.d6.loss_cls: 0.2304  decode.d6.loss_mask: 1.0911  decode.d6.loss_dice: 0.7447  decode.d7.loss_cls: 0.1946  decode.d7.loss_mask: 1.0806  decode.d7.loss_dice: 0.7171  decode.d8.loss_cls: 0.1687  decode.d8.loss_mask: 1.0727  decode.d8.loss_dice: 0.6839
05/26 23:48:59 - mmengine - INFO - Iter(train) [108750/160000]  base_lr: 3.5894e-05 lr: 3.5894e-06  eta: 5:52:49  time: 0.4154  data_time: 0.0099  memory: 5968  grad_norm: 479.7183  loss: 18.0204  decode.loss_cls: 0.0558  decode.loss_mask: 0.9818  decode.loss_dice: 0.7147  decode.d0.loss_cls: 0.6527  decode.d0.loss_mask: 0.8602  decode.d0.loss_dice: 0.6608  decode.d1.loss_cls: 0.1065  decode.d1.loss_mask: 0.9602  decode.d1.loss_dice: 0.7096  decode.d2.loss_cls: 0.0788  decode.d2.loss_mask: 0.9887  decode.d2.loss_dice: 0.7082  decode.d3.loss_cls: 0.0601  decode.d3.loss_mask: 1.0129  decode.d3.loss_dice: 0.7192  decode.d4.loss_cls: 0.1118  decode.d4.loss_mask: 0.9454  decode.d4.loss_dice: 0.6896  decode.d5.loss_cls: 0.0793  decode.d5.loss_mask: 0.9894  decode.d5.loss_dice: 0.7076  decode.d6.loss_cls: 0.0802  decode.d6.loss_mask: 0.9909  decode.d6.loss_dice: 0.6919  decode.d7.loss_cls: 0.0892  decode.d7.loss_mask: 0.9469  decode.d7.loss_dice: 0.7086  decode.d8.loss_cls: 0.0906  decode.d8.loss_mask: 0.9392  decode.d8.loss_dice: 0.6895
05/26 23:49:20 - mmengine - INFO - Iter(train) [108800/160000]  base_lr: 3.5862e-05 lr: 3.5862e-06  eta: 5:52:28  time: 0.4141  data_time: 0.0097  memory: 5966  grad_norm: 723.8456  loss: 14.2219  decode.loss_cls: 0.0601  decode.loss_mask: 0.7077  decode.loss_dice: 0.5887  decode.d0.loss_cls: 0.5590  decode.d0.loss_mask: 0.6709  decode.d0.loss_dice: 0.5514  decode.d1.loss_cls: 0.0680  decode.d1.loss_mask: 0.7162  decode.d1.loss_dice: 0.6075  decode.d2.loss_cls: 0.0567  decode.d2.loss_mask: 0.7190  decode.d2.loss_dice: 0.6053  decode.d3.loss_cls: 0.0685  decode.d3.loss_mask: 0.7196  decode.d3.loss_dice: 0.6046  decode.d4.loss_cls: 0.0742  decode.d4.loss_mask: 0.7086  decode.d4.loss_dice: 0.5986  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.7122  decode.d5.loss_dice: 0.5904  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 0.7154  decode.d6.loss_dice: 0.6029  decode.d7.loss_cls: 0.0490  decode.d7.loss_mask: 0.7130  decode.d7.loss_dice: 0.6085  decode.d8.loss_cls: 0.0661  decode.d8.loss_mask: 0.7072  decode.d8.loss_dice: 0.6023
05/26 23:49:41 - mmengine - INFO - Iter(train) [108850/160000]  base_lr: 3.5831e-05 lr: 3.5831e-06  eta: 5:52:08  time: 0.4149  data_time: 0.0099  memory: 5984  grad_norm: 523.1124  loss: 20.2680  decode.loss_cls: 0.1438  decode.loss_mask: 1.1391  decode.loss_dice: 0.7396  decode.d0.loss_cls: 0.7440  decode.d0.loss_mask: 1.0267  decode.d0.loss_dice: 0.7265  decode.d1.loss_cls: 0.1991  decode.d1.loss_mask: 1.0858  decode.d1.loss_dice: 0.7249  decode.d2.loss_cls: 0.1459  decode.d2.loss_mask: 1.0905  decode.d2.loss_dice: 0.7227  decode.d3.loss_cls: 0.1907  decode.d3.loss_mask: 1.0789  decode.d3.loss_dice: 0.7090  decode.d4.loss_cls: 0.1608  decode.d4.loss_mask: 1.0755  decode.d4.loss_dice: 0.7183  decode.d5.loss_cls: 0.1703  decode.d5.loss_mask: 1.0611  decode.d5.loss_dice: 0.7196  decode.d6.loss_cls: 0.1581  decode.d6.loss_mask: 1.0851  decode.d6.loss_dice: 0.7168  decode.d7.loss_cls: 0.1669  decode.d7.loss_mask: 1.0777  decode.d7.loss_dice: 0.7114  decode.d8.loss_cls: 0.1710  decode.d8.loss_mask: 1.0892  decode.d8.loss_dice: 0.7192
05/26 23:50:02 - mmengine - INFO - Iter(train) [108900/160000]  base_lr: 3.5799e-05 lr: 3.5799e-06  eta: 5:51:47  time: 0.4142  data_time: 0.0098  memory: 5981  grad_norm: 433.2350  loss: 23.7914  decode.loss_cls: 0.1457  decode.loss_mask: 1.3041  decode.loss_dice: 0.8645  decode.d0.loss_cls: 0.7057  decode.d0.loss_mask: 1.3049  decode.d0.loss_dice: 0.8087  decode.d1.loss_cls: 0.1344  decode.d1.loss_mask: 1.3552  decode.d1.loss_dice: 0.8705  decode.d2.loss_cls: 0.1435  decode.d2.loss_mask: 1.3377  decode.d2.loss_dice: 0.8419  decode.d3.loss_cls: 0.1473  decode.d3.loss_mask: 1.3349  decode.d3.loss_dice: 0.8488  decode.d4.loss_cls: 0.1389  decode.d4.loss_mask: 1.3449  decode.d4.loss_dice: 0.8403  decode.d5.loss_cls: 0.1426  decode.d5.loss_mask: 1.3304  decode.d5.loss_dice: 0.8599  decode.d6.loss_cls: 0.1366  decode.d6.loss_mask: 1.3344  decode.d6.loss_dice: 0.8495  decode.d7.loss_cls: 0.1554  decode.d7.loss_mask: 1.3321  decode.d7.loss_dice: 0.8446  decode.d8.loss_cls: 0.1634  decode.d8.loss_mask: 1.3254  decode.d8.loss_dice: 0.8450
05/26 23:50:23 - mmengine - INFO - Iter(train) [108950/160000]  base_lr: 3.5768e-05 lr: 3.5768e-06  eta: 5:51:26  time: 0.4147  data_time: 0.0098  memory: 5976  grad_norm: 990.2820  loss: 20.3211  decode.loss_cls: 0.2482  decode.loss_mask: 1.0007  decode.loss_dice: 0.7576  decode.d0.loss_cls: 0.8391  decode.d0.loss_mask: 0.9328  decode.d0.loss_dice: 0.7035  decode.d1.loss_cls: 0.2709  decode.d1.loss_mask: 0.9826  decode.d1.loss_dice: 0.7075  decode.d2.loss_cls: 0.2348  decode.d2.loss_mask: 1.0495  decode.d2.loss_dice: 0.7758  decode.d3.loss_cls: 0.2368  decode.d3.loss_mask: 1.0016  decode.d3.loss_dice: 0.7400  decode.d4.loss_cls: 0.2356  decode.d4.loss_mask: 0.9695  decode.d4.loss_dice: 0.7298  decode.d5.loss_cls: 0.2301  decode.d5.loss_mask: 0.9961  decode.d5.loss_dice: 0.7592  decode.d6.loss_cls: 0.2409  decode.d6.loss_mask: 0.9716  decode.d6.loss_dice: 0.7247  decode.d7.loss_cls: 0.2727  decode.d7.loss_mask: 0.9766  decode.d7.loss_dice: 0.7280  decode.d8.loss_cls: 0.2546  decode.d8.loss_mask: 0.9973  decode.d8.loss_dice: 0.7528
05/26 23:50:43 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 23:50:43 - mmengine - INFO - Iter(train) [109000/160000]  base_lr: 3.5736e-05 lr: 3.5736e-06  eta: 5:51:06  time: 0.4146  data_time: 0.0098  memory: 5980  grad_norm: 298.6962  loss: 15.2567  decode.loss_cls: 0.1227  decode.loss_mask: 0.7780  decode.loss_dice: 0.5684  decode.d0.loss_cls: 0.5809  decode.d0.loss_mask: 0.7976  decode.d0.loss_dice: 0.5635  decode.d1.loss_cls: 0.1065  decode.d1.loss_mask: 0.7768  decode.d1.loss_dice: 0.5994  decode.d2.loss_cls: 0.1107  decode.d2.loss_mask: 0.7692  decode.d2.loss_dice: 0.5661  decode.d3.loss_cls: 0.0937  decode.d3.loss_mask: 0.8061  decode.d3.loss_dice: 0.5813  decode.d4.loss_cls: 0.1106  decode.d4.loss_mask: 0.7877  decode.d4.loss_dice: 0.5626  decode.d5.loss_cls: 0.1205  decode.d5.loss_mask: 0.7676  decode.d5.loss_dice: 0.5725  decode.d6.loss_cls: 0.1185  decode.d6.loss_mask: 0.7818  decode.d6.loss_dice: 0.6109  decode.d7.loss_cls: 0.1259  decode.d7.loss_mask: 0.8037  decode.d7.loss_dice: 0.6031  decode.d8.loss_cls: 0.1097  decode.d8.loss_mask: 0.7856  decode.d8.loss_dice: 0.5752
05/26 23:51:04 - mmengine - INFO - Iter(train) [109050/160000]  base_lr: 3.5705e-05 lr: 3.5705e-06  eta: 5:50:45  time: 0.4140  data_time: 0.0098  memory: 5965  grad_norm: 512.1718  loss: 19.8250  decode.loss_cls: 0.1639  decode.loss_mask: 1.0671  decode.loss_dice: 0.6956  decode.d0.loss_cls: 0.7280  decode.d0.loss_mask: 1.0037  decode.d0.loss_dice: 0.6834  decode.d1.loss_cls: 0.2068  decode.d1.loss_mask: 1.0399  decode.d1.loss_dice: 0.6875  decode.d2.loss_cls: 0.2021  decode.d2.loss_mask: 1.0415  decode.d2.loss_dice: 0.6883  decode.d3.loss_cls: 0.2053  decode.d3.loss_mask: 1.0351  decode.d3.loss_dice: 0.6749  decode.d4.loss_cls: 0.1880  decode.d4.loss_mask: 1.0597  decode.d4.loss_dice: 0.6921  decode.d5.loss_cls: 0.1644  decode.d5.loss_mask: 1.0655  decode.d5.loss_dice: 0.6757  decode.d6.loss_cls: 0.1848  decode.d6.loss_mask: 1.0565  decode.d6.loss_dice: 0.6797  decode.d7.loss_cls: 0.2023  decode.d7.loss_mask: 1.0607  decode.d7.loss_dice: 0.7127  decode.d8.loss_cls: 0.1859  decode.d8.loss_mask: 1.0784  decode.d8.loss_dice: 0.6955
05/26 23:51:25 - mmengine - INFO - Iter(train) [109100/160000]  base_lr: 3.5673e-05 lr: 3.5673e-06  eta: 5:50:25  time: 0.4148  data_time: 0.0098  memory: 5975  grad_norm: 1274.7478  loss: 25.1490  decode.loss_cls: 0.1916  decode.loss_mask: 1.3777  decode.loss_dice: 0.9013  decode.d0.loss_cls: 0.8520  decode.d0.loss_mask: 1.2183  decode.d0.loss_dice: 0.8322  decode.d1.loss_cls: 0.1687  decode.d1.loss_mask: 1.4098  decode.d1.loss_dice: 0.9026  decode.d2.loss_cls: 0.2006  decode.d2.loss_mask: 1.3788  decode.d2.loss_dice: 0.8883  decode.d3.loss_cls: 0.2282  decode.d3.loss_mask: 1.3675  decode.d3.loss_dice: 0.8612  decode.d4.loss_cls: 0.1830  decode.d4.loss_mask: 1.3936  decode.d4.loss_dice: 0.8965  decode.d5.loss_cls: 0.1645  decode.d5.loss_mask: 1.3774  decode.d5.loss_dice: 0.8941  decode.d6.loss_cls: 0.1870  decode.d6.loss_mask: 1.3989  decode.d6.loss_dice: 0.8861  decode.d7.loss_cls: 0.2047  decode.d7.loss_mask: 1.3990  decode.d7.loss_dice: 0.9017  decode.d8.loss_cls: 0.1922  decode.d8.loss_mask: 1.3892  decode.d8.loss_dice: 0.9025
05/26 23:51:46 - mmengine - INFO - Iter(train) [109150/160000]  base_lr: 3.5642e-05 lr: 3.5642e-06  eta: 5:50:04  time: 0.4147  data_time: 0.0098  memory: 5966  grad_norm: 572.4552  loss: 17.5913  decode.loss_cls: 0.1768  decode.loss_mask: 0.9095  decode.loss_dice: 0.6442  decode.d0.loss_cls: 0.5985  decode.d0.loss_mask: 0.8854  decode.d0.loss_dice: 0.6271  decode.d1.loss_cls: 0.1556  decode.d1.loss_mask: 0.9340  decode.d1.loss_dice: 0.6422  decode.d2.loss_cls: 0.1344  decode.d2.loss_mask: 0.9160  decode.d2.loss_dice: 0.6393  decode.d3.loss_cls: 0.1421  decode.d3.loss_mask: 0.9111  decode.d3.loss_dice: 0.6372  decode.d4.loss_cls: 0.1671  decode.d4.loss_mask: 0.9247  decode.d4.loss_dice: 0.6455  decode.d5.loss_cls: 0.1422  decode.d5.loss_mask: 0.9218  decode.d5.loss_dice: 0.6601  decode.d6.loss_cls: 0.1675  decode.d6.loss_mask: 0.9084  decode.d6.loss_dice: 0.6561  decode.d7.loss_cls: 0.1843  decode.d7.loss_mask: 0.9026  decode.d7.loss_dice: 0.6562  decode.d8.loss_cls: 0.1461  decode.d8.loss_mask: 0.9066  decode.d8.loss_dice: 0.6486
05/26 23:52:06 - mmengine - INFO - Iter(train) [109200/160000]  base_lr: 3.5610e-05 lr: 3.5610e-06  eta: 5:49:43  time: 0.4136  data_time: 0.0098  memory: 5968  grad_norm: 624.1990  loss: 22.8100  decode.loss_cls: 0.1779  decode.loss_mask: 1.2872  decode.loss_dice: 0.7616  decode.d0.loss_cls: 0.5810  decode.d0.loss_mask: 1.2845  decode.d0.loss_dice: 0.7771  decode.d1.loss_cls: 0.1957  decode.d1.loss_mask: 1.3203  decode.d1.loss_dice: 0.7695  decode.d2.loss_cls: 0.1882  decode.d2.loss_mask: 1.2727  decode.d2.loss_dice: 0.7802  decode.d3.loss_cls: 0.1398  decode.d3.loss_mask: 1.3142  decode.d3.loss_dice: 0.7549  decode.d4.loss_cls: 0.1762  decode.d4.loss_mask: 1.2735  decode.d4.loss_dice: 0.7378  decode.d5.loss_cls: 0.2011  decode.d5.loss_mask: 1.2428  decode.d5.loss_dice: 0.7576  decode.d6.loss_cls: 0.1749  decode.d6.loss_mask: 1.3452  decode.d6.loss_dice: 0.7862  decode.d7.loss_cls: 0.1569  decode.d7.loss_mask: 1.3662  decode.d7.loss_dice: 0.7731  decode.d8.loss_cls: 0.1606  decode.d8.loss_mask: 1.2953  decode.d8.loss_dice: 0.7580
05/26 23:52:27 - mmengine - INFO - Iter(train) [109250/160000]  base_lr: 3.5578e-05 lr: 3.5578e-06  eta: 5:49:23  time: 0.4147  data_time: 0.0098  memory: 5969  grad_norm: 329.2697  loss: 15.1560  decode.loss_cls: 0.0793  decode.loss_mask: 0.8488  decode.loss_dice: 0.5550  decode.d0.loss_cls: 0.5125  decode.d0.loss_mask: 0.8212  decode.d0.loss_dice: 0.5687  decode.d1.loss_cls: 0.1280  decode.d1.loss_mask: 0.8558  decode.d1.loss_dice: 0.5679  decode.d2.loss_cls: 0.0645  decode.d2.loss_mask: 0.8318  decode.d2.loss_dice: 0.5583  decode.d3.loss_cls: 0.0566  decode.d3.loss_mask: 0.8003  decode.d3.loss_dice: 0.5312  decode.d4.loss_cls: 0.0831  decode.d4.loss_mask: 0.8312  decode.d4.loss_dice: 0.5461  decode.d5.loss_cls: 0.0923  decode.d5.loss_mask: 0.8348  decode.d5.loss_dice: 0.5655  decode.d6.loss_cls: 0.0577  decode.d6.loss_mask: 0.8233  decode.d6.loss_dice: 0.5459  decode.d7.loss_cls: 0.1028  decode.d7.loss_mask: 0.8356  decode.d7.loss_dice: 0.5571  decode.d8.loss_cls: 0.0882  decode.d8.loss_mask: 0.8453  decode.d8.loss_dice: 0.5673
05/26 23:52:48 - mmengine - INFO - Iter(train) [109300/160000]  base_lr: 3.5547e-05 lr: 3.5547e-06  eta: 5:49:02  time: 0.4164  data_time: 0.0101  memory: 5980  grad_norm: 679.2878  loss: 20.3427  decode.loss_cls: 0.1983  decode.loss_mask: 1.0941  decode.loss_dice: 0.6878  decode.d0.loss_cls: 0.6440  decode.d0.loss_mask: 1.0368  decode.d0.loss_dice: 0.6749  decode.d1.loss_cls: 0.2103  decode.d1.loss_mask: 1.0752  decode.d1.loss_dice: 0.6765  decode.d2.loss_cls: 0.2046  decode.d2.loss_mask: 1.0973  decode.d2.loss_dice: 0.7015  decode.d3.loss_cls: 0.1970  decode.d3.loss_mask: 1.1089  decode.d3.loss_dice: 0.6990  decode.d4.loss_cls: 0.2085  decode.d4.loss_mask: 1.0889  decode.d4.loss_dice: 0.6719  decode.d5.loss_cls: 0.2225  decode.d5.loss_mask: 1.0948  decode.d5.loss_dice: 0.6847  decode.d6.loss_cls: 0.2448  decode.d6.loss_mask: 1.1264  decode.d6.loss_dice: 0.6843  decode.d7.loss_cls: 0.2181  decode.d7.loss_mask: 1.1082  decode.d7.loss_dice: 0.7007  decode.d8.loss_cls: 0.2171  decode.d8.loss_mask: 1.0853  decode.d8.loss_dice: 0.6805
05/26 23:53:11 - mmengine - INFO - Iter(train) [109350/160000]  base_lr: 3.5515e-05 lr: 3.5515e-06  eta: 5:48:42  time: 0.4149  data_time: 0.0099  memory: 5966  grad_norm: 368.3282  loss: 17.4533  decode.loss_cls: 0.1093  decode.loss_mask: 1.0293  decode.loss_dice: 0.5455  decode.d0.loss_cls: 0.5569  decode.d0.loss_mask: 0.9917  decode.d0.loss_dice: 0.5571  decode.d1.loss_cls: 0.1790  decode.d1.loss_mask: 1.0285  decode.d1.loss_dice: 0.5544  decode.d2.loss_cls: 0.1223  decode.d2.loss_mask: 1.0345  decode.d2.loss_dice: 0.5501  decode.d3.loss_cls: 0.1172  decode.d3.loss_mask: 1.0307  decode.d3.loss_dice: 0.5518  decode.d4.loss_cls: 0.1211  decode.d4.loss_mask: 1.0402  decode.d4.loss_dice: 0.5504  decode.d5.loss_cls: 0.1258  decode.d5.loss_mask: 1.0411  decode.d5.loss_dice: 0.5514  decode.d6.loss_cls: 0.1088  decode.d6.loss_mask: 1.0323  decode.d6.loss_dice: 0.5559  decode.d7.loss_cls: 0.0968  decode.d7.loss_mask: 1.0315  decode.d7.loss_dice: 0.5581  decode.d8.loss_cls: 0.0948  decode.d8.loss_mask: 1.0326  decode.d8.loss_dice: 0.5540
05/26 23:53:31 - mmengine - INFO - Iter(train) [109400/160000]  base_lr: 3.5484e-05 lr: 3.5484e-06  eta: 5:48:22  time: 0.4152  data_time: 0.0098  memory: 5975  grad_norm: 502.8418  loss: 17.6802  decode.loss_cls: 0.1197  decode.loss_mask: 0.9290  decode.loss_dice: 0.6911  decode.d0.loss_cls: 0.5586  decode.d0.loss_mask: 0.8934  decode.d0.loss_dice: 0.6629  decode.d1.loss_cls: 0.1424  decode.d1.loss_mask: 0.8802  decode.d1.loss_dice: 0.6858  decode.d2.loss_cls: 0.1510  decode.d2.loss_mask: 0.8789  decode.d2.loss_dice: 0.6930  decode.d3.loss_cls: 0.1442  decode.d3.loss_mask: 0.8908  decode.d3.loss_dice: 0.6975  decode.d4.loss_cls: 0.1416  decode.d4.loss_mask: 0.8716  decode.d4.loss_dice: 0.6818  decode.d5.loss_cls: 0.1173  decode.d5.loss_mask: 0.9253  decode.d5.loss_dice: 0.7152  decode.d6.loss_cls: 0.1023  decode.d6.loss_mask: 0.9433  decode.d6.loss_dice: 0.7384  decode.d7.loss_cls: 0.1514  decode.d7.loss_mask: 0.8820  decode.d7.loss_dice: 0.6903  decode.d8.loss_cls: 0.1340  decode.d8.loss_mask: 0.8776  decode.d8.loss_dice: 0.6897
05/26 23:53:52 - mmengine - INFO - Iter(train) [109450/160000]  base_lr: 3.5452e-05 lr: 3.5452e-06  eta: 5:48:01  time: 0.4144  data_time: 0.0099  memory: 5970  grad_norm: 643.3289  loss: 22.2408  decode.loss_cls: 0.2827  decode.loss_mask: 1.0821  decode.loss_dice: 0.8023  decode.d0.loss_cls: 0.7743  decode.d0.loss_mask: 1.0935  decode.d0.loss_dice: 0.8293  decode.d1.loss_cls: 0.2449  decode.d1.loss_mask: 1.0883  decode.d1.loss_dice: 0.8080  decode.d2.loss_cls: 0.1998  decode.d2.loss_mask: 1.1759  decode.d2.loss_dice: 0.8211  decode.d3.loss_cls: 0.2404  decode.d3.loss_mask: 1.1241  decode.d3.loss_dice: 0.8067  decode.d4.loss_cls: 0.2664  decode.d4.loss_mask: 1.1148  decode.d4.loss_dice: 0.8073  decode.d5.loss_cls: 0.2455  decode.d5.loss_mask: 1.0986  decode.d5.loss_dice: 0.8362  decode.d6.loss_cls: 0.2214  decode.d6.loss_mask: 1.0780  decode.d6.loss_dice: 0.8097  decode.d7.loss_cls: 0.1987  decode.d7.loss_mask: 1.1455  decode.d7.loss_dice: 0.8203  decode.d8.loss_cls: 0.2067  decode.d8.loss_mask: 1.1917  decode.d8.loss_dice: 0.8267
05/26 23:54:13 - mmengine - INFO - Iter(train) [109500/160000]  base_lr: 3.5421e-05 lr: 3.5421e-06  eta: 5:47:41  time: 0.4161  data_time: 0.0100  memory: 5971  grad_norm: 338.6235  loss: 18.7408  decode.loss_cls: 0.1553  decode.loss_mask: 0.9687  decode.loss_dice: 0.6844  decode.d0.loss_cls: 0.7424  decode.d0.loss_mask: 0.9024  decode.d0.loss_dice: 0.6831  decode.d1.loss_cls: 0.1957  decode.d1.loss_mask: 0.9939  decode.d1.loss_dice: 0.6816  decode.d2.loss_cls: 0.1525  decode.d2.loss_mask: 0.9770  decode.d2.loss_dice: 0.6786  decode.d3.loss_cls: 0.1934  decode.d3.loss_mask: 0.9904  decode.d3.loss_dice: 0.6819  decode.d4.loss_cls: 0.1477  decode.d4.loss_mask: 0.9801  decode.d4.loss_dice: 0.6761  decode.d5.loss_cls: 0.1273  decode.d5.loss_mask: 0.9936  decode.d5.loss_dice: 0.6956  decode.d6.loss_cls: 0.1591  decode.d6.loss_mask: 0.9718  decode.d6.loss_dice: 0.6913  decode.d7.loss_cls: 0.1458  decode.d7.loss_mask: 0.9742  decode.d7.loss_dice: 0.6793  decode.d8.loss_cls: 0.1668  decode.d8.loss_mask: 0.9663  decode.d8.loss_dice: 0.6845
05/26 23:54:34 - mmengine - INFO - Iter(train) [109550/160000]  base_lr: 3.5389e-05 lr: 3.5389e-06  eta: 5:47:20  time: 0.4154  data_time: 0.0098  memory: 5966  grad_norm: 1199.2787  loss: 21.0677  decode.loss_cls: 0.1768  decode.loss_mask: 1.1108  decode.loss_dice: 0.7307  decode.d0.loss_cls: 0.6503  decode.d0.loss_mask: 1.0920  decode.d0.loss_dice: 0.7158  decode.d1.loss_cls: 0.1666  decode.d1.loss_mask: 1.1878  decode.d1.loss_dice: 0.7811  decode.d2.loss_cls: 0.1871  decode.d2.loss_mask: 1.1526  decode.d2.loss_dice: 0.7276  decode.d3.loss_cls: 0.1939  decode.d3.loss_mask: 1.1213  decode.d3.loss_dice: 0.7108  decode.d4.loss_cls: 0.1670  decode.d4.loss_mask: 1.1873  decode.d4.loss_dice: 0.7487  decode.d5.loss_cls: 0.1516  decode.d5.loss_mask: 1.1808  decode.d5.loss_dice: 0.7530  decode.d6.loss_cls: 0.1807  decode.d6.loss_mask: 1.1364  decode.d6.loss_dice: 0.7539  decode.d7.loss_cls: 0.1693  decode.d7.loss_mask: 1.1548  decode.d7.loss_dice: 0.7358  decode.d8.loss_cls: 0.1611  decode.d8.loss_mask: 1.1429  decode.d8.loss_dice: 0.7390
05/26 23:54:55 - mmengine - INFO - Iter(train) [109600/160000]  base_lr: 3.5358e-05 lr: 3.5358e-06  eta: 5:46:59  time: 0.4150  data_time: 0.0098  memory: 5971  grad_norm: 502.3766  loss: 20.3776  decode.loss_cls: 0.2509  decode.loss_mask: 0.9492  decode.loss_dice: 0.7927  decode.d0.loss_cls: 0.7185  decode.d0.loss_mask: 0.9268  decode.d0.loss_dice: 0.8141  decode.d1.loss_cls: 0.2731  decode.d1.loss_mask: 0.9267  decode.d1.loss_dice: 0.7835  decode.d2.loss_cls: 0.2825  decode.d2.loss_mask: 0.9366  decode.d2.loss_dice: 0.7589  decode.d3.loss_cls: 0.2712  decode.d3.loss_mask: 0.9373  decode.d3.loss_dice: 0.7387  decode.d4.loss_cls: 0.2741  decode.d4.loss_mask: 0.9362  decode.d4.loss_dice: 0.7621  decode.d5.loss_cls: 0.2724  decode.d5.loss_mask: 0.9529  decode.d5.loss_dice: 0.8049  decode.d6.loss_cls: 0.3150  decode.d6.loss_mask: 0.9251  decode.d6.loss_dice: 0.7706  decode.d7.loss_cls: 0.2801  decode.d7.loss_mask: 0.9488  decode.d7.loss_dice: 0.7654  decode.d8.loss_cls: 0.2643  decode.d8.loss_mask: 0.9593  decode.d8.loss_dice: 0.7858
05/26 23:55:15 - mmengine - INFO - Iter(train) [109650/160000]  base_lr: 3.5326e-05 lr: 3.5326e-06  eta: 5:46:39  time: 0.4165  data_time: 0.0099  memory: 5967  grad_norm: 472.5365  loss: 20.6122  decode.loss_cls: 0.2325  decode.loss_mask: 1.0346  decode.loss_dice: 0.7802  decode.d0.loss_cls: 0.7596  decode.d0.loss_mask: 0.9458  decode.d0.loss_dice: 0.6948  decode.d1.loss_cls: 0.2247  decode.d1.loss_mask: 1.0399  decode.d1.loss_dice: 0.7634  decode.d2.loss_cls: 0.2594  decode.d2.loss_mask: 1.0072  decode.d2.loss_dice: 0.7207  decode.d3.loss_cls: 0.2756  decode.d3.loss_mask: 1.0457  decode.d3.loss_dice: 0.7326  decode.d4.loss_cls: 0.2425  decode.d4.loss_mask: 1.0329  decode.d4.loss_dice: 0.7472  decode.d5.loss_cls: 0.2265  decode.d5.loss_mask: 1.0356  decode.d5.loss_dice: 0.7666  decode.d6.loss_cls: 0.3115  decode.d6.loss_mask: 1.0093  decode.d6.loss_dice: 0.7343  decode.d7.loss_cls: 0.2421  decode.d7.loss_mask: 1.0262  decode.d7.loss_dice: 0.7503  decode.d8.loss_cls: 0.2189  decode.d8.loss_mask: 1.0030  decode.d8.loss_dice: 0.7484
05/26 23:55:36 - mmengine - INFO - Iter(train) [109700/160000]  base_lr: 3.5294e-05 lr: 3.5294e-06  eta: 5:46:18  time: 0.4150  data_time: 0.0100  memory: 5983  grad_norm: 443.5551  loss: 17.3928  decode.loss_cls: 0.2086  decode.loss_mask: 0.8650  decode.loss_dice: 0.6150  decode.d0.loss_cls: 0.8084  decode.d0.loss_mask: 0.7791  decode.d0.loss_dice: 0.5924  decode.d1.loss_cls: 0.2442  decode.d1.loss_mask: 0.8019  decode.d1.loss_dice: 0.6270  decode.d2.loss_cls: 0.2249  decode.d2.loss_mask: 0.8044  decode.d2.loss_dice: 0.6306  decode.d3.loss_cls: 0.2272  decode.d3.loss_mask: 0.8157  decode.d3.loss_dice: 0.6324  decode.d4.loss_cls: 0.2552  decode.d4.loss_mask: 0.8331  decode.d4.loss_dice: 0.6598  decode.d5.loss_cls: 0.2466  decode.d5.loss_mask: 0.8348  decode.d5.loss_dice: 0.6225  decode.d6.loss_cls: 0.2340  decode.d6.loss_mask: 0.8149  decode.d6.loss_dice: 0.6482  decode.d7.loss_cls: 0.2406  decode.d7.loss_mask: 0.8338  decode.d7.loss_dice: 0.6495  decode.d8.loss_cls: 0.2262  decode.d8.loss_mask: 0.8020  decode.d8.loss_dice: 0.6148
05/26 23:55:57 - mmengine - INFO - Iter(train) [109750/160000]  base_lr: 3.5263e-05 lr: 3.5263e-06  eta: 5:45:58  time: 0.4166  data_time: 0.0099  memory: 5967  grad_norm: 561.7365  loss: 17.1439  decode.loss_cls: 0.1410  decode.loss_mask: 0.9185  decode.loss_dice: 0.6079  decode.d0.loss_cls: 0.6450  decode.d0.loss_mask: 0.8946  decode.d0.loss_dice: 0.6448  decode.d1.loss_cls: 0.1943  decode.d1.loss_mask: 0.8699  decode.d1.loss_dice: 0.5681  decode.d2.loss_cls: 0.1498  decode.d2.loss_mask: 0.9259  decode.d2.loss_dice: 0.5783  decode.d3.loss_cls: 0.1647  decode.d3.loss_mask: 0.9360  decode.d3.loss_dice: 0.5983  decode.d4.loss_cls: 0.1473  decode.d4.loss_mask: 0.9257  decode.d4.loss_dice: 0.5925  decode.d5.loss_cls: 0.1491  decode.d5.loss_mask: 0.9060  decode.d5.loss_dice: 0.5811  decode.d6.loss_cls: 0.1887  decode.d6.loss_mask: 0.8738  decode.d6.loss_dice: 0.6129  decode.d7.loss_cls: 0.1417  decode.d7.loss_mask: 0.9096  decode.d7.loss_dice: 0.5986  decode.d8.loss_cls: 0.1492  decode.d8.loss_mask: 0.9337  decode.d8.loss_dice: 0.5966
05/26 23:56:18 - mmengine - INFO - Iter(train) [109800/160000]  base_lr: 3.5231e-05 lr: 3.5231e-06  eta: 5:45:37  time: 0.4160  data_time: 0.0099  memory: 5975  grad_norm: 576.2344  loss: 17.2284  decode.loss_cls: 0.1760  decode.loss_mask: 0.8977  decode.loss_dice: 0.6074  decode.d0.loss_cls: 0.7242  decode.d0.loss_mask: 0.8351  decode.d0.loss_dice: 0.5908  decode.d1.loss_cls: 0.1969  decode.d1.loss_mask: 0.8623  decode.d1.loss_dice: 0.6043  decode.d2.loss_cls: 0.1530  decode.d2.loss_mask: 0.8953  decode.d2.loss_dice: 0.6150  decode.d3.loss_cls: 0.1407  decode.d3.loss_mask: 0.8872  decode.d3.loss_dice: 0.6106  decode.d4.loss_cls: 0.1662  decode.d4.loss_mask: 0.8913  decode.d4.loss_dice: 0.6213  decode.d5.loss_cls: 0.1369  decode.d5.loss_mask: 0.8961  decode.d5.loss_dice: 0.6180  decode.d6.loss_cls: 0.1260  decode.d6.loss_mask: 0.9474  decode.d6.loss_dice: 0.6424  decode.d7.loss_cls: 0.1502  decode.d7.loss_mask: 0.9047  decode.d7.loss_dice: 0.6339  decode.d8.loss_cls: 0.1627  decode.d8.loss_mask: 0.9043  decode.d8.loss_dice: 0.6307
05/26 23:56:39 - mmengine - INFO - Iter(train) [109850/160000]  base_lr: 3.5200e-05 lr: 3.5200e-06  eta: 5:45:16  time: 0.4155  data_time: 0.0098  memory: 5969  grad_norm: 341.1466  loss: 17.4136  decode.loss_cls: 0.1150  decode.loss_mask: 0.9143  decode.loss_dice: 0.6353  decode.d0.loss_cls: 0.6155  decode.d0.loss_mask: 0.8595  decode.d0.loss_dice: 0.6601  decode.d1.loss_cls: 0.1835  decode.d1.loss_mask: 0.9089  decode.d1.loss_dice: 0.6331  decode.d2.loss_cls: 0.1717  decode.d2.loss_mask: 0.9033  decode.d2.loss_dice: 0.6478  decode.d3.loss_cls: 0.1617  decode.d3.loss_mask: 0.9177  decode.d3.loss_dice: 0.6343  decode.d4.loss_cls: 0.1589  decode.d4.loss_mask: 0.9211  decode.d4.loss_dice: 0.6433  decode.d5.loss_cls: 0.1551  decode.d5.loss_mask: 0.9020  decode.d5.loss_dice: 0.6390  decode.d6.loss_cls: 0.1880  decode.d6.loss_mask: 0.8791  decode.d6.loss_dice: 0.6389  decode.d7.loss_cls: 0.1673  decode.d7.loss_mask: 0.8694  decode.d7.loss_dice: 0.6394  decode.d8.loss_cls: 0.1719  decode.d8.loss_mask: 0.8561  decode.d8.loss_dice: 0.6226
05/26 23:57:00 - mmengine - INFO - Iter(train) [109900/160000]  base_lr: 3.5168e-05 lr: 3.5168e-06  eta: 5:44:56  time: 0.4166  data_time: 0.0099  memory: 5965  grad_norm: 554.9555  loss: 17.7640  decode.loss_cls: 0.1227  decode.loss_mask: 0.9606  decode.loss_dice: 0.6539  decode.d0.loss_cls: 0.6159  decode.d0.loss_mask: 0.9407  decode.d0.loss_dice: 0.6190  decode.d1.loss_cls: 0.1493  decode.d1.loss_mask: 0.9507  decode.d1.loss_dice: 0.6583  decode.d2.loss_cls: 0.1383  decode.d2.loss_mask: 0.9667  decode.d2.loss_dice: 0.6363  decode.d3.loss_cls: 0.1030  decode.d3.loss_mask: 0.9573  decode.d3.loss_dice: 0.6485  decode.d4.loss_cls: 0.1184  decode.d4.loss_mask: 0.9607  decode.d4.loss_dice: 0.6454  decode.d5.loss_cls: 0.1140  decode.d5.loss_mask: 0.9543  decode.d5.loss_dice: 0.6338  decode.d6.loss_cls: 0.1310  decode.d6.loss_mask: 0.9621  decode.d6.loss_dice: 0.6490  decode.d7.loss_cls: 0.1294  decode.d7.loss_mask: 0.9572  decode.d7.loss_dice: 0.6502  decode.d8.loss_cls: 0.1129  decode.d8.loss_mask: 0.9665  decode.d8.loss_dice: 0.6577
05/26 23:57:20 - mmengine - INFO - Iter(train) [109950/160000]  base_lr: 3.5136e-05 lr: 3.5136e-06  eta: 5:44:35  time: 0.4167  data_time: 0.0100  memory: 5974  grad_norm: 408.1274  loss: 15.0066  decode.loss_cls: 0.1243  decode.loss_mask: 0.8549  decode.loss_dice: 0.5202  decode.d0.loss_cls: 0.5567  decode.d0.loss_mask: 0.8004  decode.d0.loss_dice: 0.5052  decode.d1.loss_cls: 0.1322  decode.d1.loss_mask: 0.8089  decode.d1.loss_dice: 0.4799  decode.d2.loss_cls: 0.1167  decode.d2.loss_mask: 0.8325  decode.d2.loss_dice: 0.5102  decode.d3.loss_cls: 0.1212  decode.d3.loss_mask: 0.8537  decode.d3.loss_dice: 0.5128  decode.d4.loss_cls: 0.1394  decode.d4.loss_mask: 0.8551  decode.d4.loss_dice: 0.4889  decode.d5.loss_cls: 0.1331  decode.d5.loss_mask: 0.8245  decode.d5.loss_dice: 0.4889  decode.d6.loss_cls: 0.1429  decode.d6.loss_mask: 0.8211  decode.d6.loss_dice: 0.4800  decode.d7.loss_cls: 0.1288  decode.d7.loss_mask: 0.8311  decode.d7.loss_dice: 0.4918  decode.d8.loss_cls: 0.1296  decode.d8.loss_mask: 0.8345  decode.d8.loss_dice: 0.4870
05/26 23:57:41 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/26 23:57:41 - mmengine - INFO - Iter(train) [110000/160000]  base_lr: 3.5105e-05 lr: 3.5105e-06  eta: 5:44:15  time: 0.4151  data_time: 0.0098  memory: 5966  grad_norm: 715.3975  loss: 21.7325  decode.loss_cls: 0.3638  decode.loss_mask: 1.0307  decode.loss_dice: 0.7252  decode.d0.loss_cls: 0.7802  decode.d0.loss_mask: 0.9421  decode.d0.loss_dice: 0.7338  decode.d1.loss_cls: 0.3706  decode.d1.loss_mask: 1.0471  decode.d1.loss_dice: 0.7453  decode.d2.loss_cls: 0.3749  decode.d2.loss_mask: 1.0602  decode.d2.loss_dice: 0.7460  decode.d3.loss_cls: 0.3723  decode.d3.loss_mask: 1.0155  decode.d3.loss_dice: 0.7178  decode.d4.loss_cls: 0.3238  decode.d4.loss_mask: 1.0975  decode.d4.loss_dice: 0.7301  decode.d5.loss_cls: 0.2708  decode.d5.loss_mask: 1.0770  decode.d5.loss_dice: 0.7482  decode.d6.loss_cls: 0.3334  decode.d6.loss_mask: 1.0599  decode.d6.loss_dice: 0.7431  decode.d7.loss_cls: 0.3588  decode.d7.loss_mask: 1.0863  decode.d7.loss_dice: 0.7446  decode.d8.loss_cls: 0.3562  decode.d8.loss_mask: 1.0295  decode.d8.loss_dice: 0.7479
05/26 23:57:41 - mmengine - INFO - Saving checkpoint at 110000 iterations
05/26 23:57:46 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:09  time: 0.0476  data_time: 0.0012  memory: 1391  
05/26 23:57:48 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:05  time: 0.0473  data_time: 0.0012  memory: 1205  
05/26 23:57:50 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:03  time: 0.0501  data_time: 0.0012  memory: 1596  
05/26 23:57:53 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0483  data_time: 0.0012  memory: 1298  
05/26 23:57:55 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:58  time: 0.0479  data_time: 0.0013  memory: 1298  
05/26 23:57:58 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0474  data_time: 0.0012  memory: 1279  
05/26 23:58:00 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:53  time: 0.0477  data_time: 0.0012  memory: 1224  
05/26 23:58:02 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0486  data_time: 0.0012  memory: 1298  
05/26 23:58:05 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0472  data_time: 0.0012  memory: 1298  
05/26 23:58:07 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0522  data_time: 0.0012  memory: 1725  
05/26 23:58:10 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0474  data_time: 0.0012  memory: 1336  
05/26 23:58:12 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0479  data_time: 0.0012  memory: 1298  
05/26 23:58:14 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0478  data_time: 0.0012  memory: 1205  
05/26 23:58:17 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:35  time: 0.0492  data_time: 0.0012  memory: 1316  
05/26 23:58:19 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0474  data_time: 0.0012  memory: 1279  
05/26 23:58:22 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0510  data_time: 0.0012  memory: 1410  
05/26 23:58:24 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0472  data_time: 0.0012  memory: 1279  
05/26 23:58:26 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0482  data_time: 0.0012  memory: 1205  
05/26 23:58:29 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:23  time: 0.0481  data_time: 0.0012  memory: 1205  
05/26 23:58:31 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0474  data_time: 0.0012  memory: 1336  
05/26 23:58:34 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0473  data_time: 0.0012  memory: 1246  
05/26 23:58:36 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0497  data_time: 0.0012  memory: 1503  
05/26 23:58:38 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0472  data_time: 0.0012  memory: 1261  
05/26 23:58:41 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0481  data_time: 0.0012  memory: 1298  
05/26 23:58:43 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0473  data_time: 0.0012  memory: 1447  
05/26 23:58:45 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0472  data_time: 0.0012  memory: 1298  
05/26 23:58:48 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0487  data_time: 0.0012  memory: 1279  
05/26 23:58:50 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0474  data_time: 0.0012  memory: 1205  
05/26 23:58:53 - mmengine - INFO - per class results:
05/26 23:58:53 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background |  95.4 | 97.35 |
|  aeroplane  |  94.9 | 98.23 |
|   bicycle   | 45.26 |  96.8 |
|     bird    | 92.75 | 97.08 |
|     boat    |  62.4 | 90.12 |
|    bottle   | 84.38 | 93.51 |
|     bus     | 93.31 | 98.45 |
|     car     | 90.25 | 94.78 |
|     cat     | 93.48 | 95.91 |
|    chair    | 43.18 | 66.39 |
|     cow     | 85.15 | 89.39 |
| diningtable | 66.12 | 71.66 |
|     dog     | 90.97 | 98.21 |
|    horse    | 87.54 | 97.05 |
|  motorbike  | 92.75 | 97.42 |
|    person   | 91.08 | 94.08 |
| pottedplant | 71.66 | 86.34 |
|    sheep    |  85.2 | 92.44 |
|     sofa    | 54.58 | 65.51 |
|    train    | 90.67 | 96.75 |
|  tvmonitor  | 86.29 | 87.49 |
+-------------+-------+-------+
05/26 23:58:53 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.7800  mIoU: 80.8200  mAcc: 90.7100  data_time: 0.0012  time: 0.0479
05/26 23:59:13 - mmengine - INFO - Iter(train) [110050/160000]  base_lr: 3.5073e-05 lr: 3.5073e-06  eta: 5:43:54  time: 0.4123  data_time: 0.0097  memory: 5967  grad_norm: 527.6007  loss: 19.3613  decode.loss_cls: 0.1044  decode.loss_mask: 1.0505  decode.loss_dice: 0.7190  decode.d0.loss_cls: 0.5788  decode.d0.loss_mask: 1.0278  decode.d0.loss_dice: 0.6936  decode.d1.loss_cls: 0.1379  decode.d1.loss_mask: 1.0514  decode.d1.loss_dice: 0.7366  decode.d2.loss_cls: 0.0984  decode.d2.loss_mask: 1.0775  decode.d2.loss_dice: 0.7548  decode.d3.loss_cls: 0.1287  decode.d3.loss_mask: 1.0255  decode.d3.loss_dice: 0.7233  decode.d4.loss_cls: 0.1377  decode.d4.loss_mask: 1.0490  decode.d4.loss_dice: 0.7049  decode.d5.loss_cls: 0.1339  decode.d5.loss_mask: 1.0461  decode.d5.loss_dice: 0.7060  decode.d6.loss_cls: 0.1069  decode.d6.loss_mask: 1.0406  decode.d6.loss_dice: 0.7376  decode.d7.loss_cls: 0.1034  decode.d7.loss_mask: 1.0588  decode.d7.loss_dice: 0.7373  decode.d8.loss_cls: 0.0923  decode.d8.loss_mask: 1.0542  decode.d8.loss_dice: 0.7440
05/26 23:59:34 - mmengine - INFO - Iter(train) [110100/160000]  base_lr: 3.5042e-05 lr: 3.5042e-06  eta: 5:43:34  time: 0.4236  data_time: 0.0097  memory: 5976  grad_norm: 538.6434  loss: 15.6175  decode.loss_cls: 0.1462  decode.loss_mask: 0.8393  decode.loss_dice: 0.5246  decode.d0.loss_cls: 0.5917  decode.d0.loss_mask: 0.8373  decode.d0.loss_dice: 0.5570  decode.d1.loss_cls: 0.1681  decode.d1.loss_mask: 0.8332  decode.d1.loss_dice: 0.5349  decode.d2.loss_cls: 0.1376  decode.d2.loss_mask: 0.8237  decode.d2.loss_dice: 0.5278  decode.d3.loss_cls: 0.1599  decode.d3.loss_mask: 0.8362  decode.d3.loss_dice: 0.5262  decode.d4.loss_cls: 0.1164  decode.d4.loss_mask: 0.9101  decode.d4.loss_dice: 0.5301  decode.d5.loss_cls: 0.1102  decode.d5.loss_mask: 0.9078  decode.d5.loss_dice: 0.5252  decode.d6.loss_cls: 0.1456  decode.d6.loss_mask: 0.8414  decode.d6.loss_dice: 0.5288  decode.d7.loss_cls: 0.1433  decode.d7.loss_mask: 0.8215  decode.d7.loss_dice: 0.5272  decode.d8.loss_cls: 0.1282  decode.d8.loss_mask: 0.8140  decode.d8.loss_dice: 0.5242
05/26 23:59:55 - mmengine - INFO - Iter(train) [110150/160000]  base_lr: 3.5010e-05 lr: 3.5010e-06  eta: 5:43:13  time: 0.4151  data_time: 0.0100  memory: 5973  grad_norm: 440.4410  loss: 19.5186  decode.loss_cls: 0.1977  decode.loss_mask: 0.9711  decode.loss_dice: 0.7114  decode.d0.loss_cls: 0.6861  decode.d0.loss_mask: 0.9716  decode.d0.loss_dice: 0.7224  decode.d1.loss_cls: 0.2371  decode.d1.loss_mask: 0.9622  decode.d1.loss_dice: 0.7427  decode.d2.loss_cls: 0.2221  decode.d2.loss_mask: 0.9600  decode.d2.loss_dice: 0.7300  decode.d3.loss_cls: 0.1936  decode.d3.loss_mask: 0.9710  decode.d3.loss_dice: 0.7199  decode.d4.loss_cls: 0.2442  decode.d4.loss_mask: 0.9678  decode.d4.loss_dice: 0.7055  decode.d5.loss_cls: 0.2039  decode.d5.loss_mask: 0.9618  decode.d5.loss_dice: 0.7132  decode.d6.loss_cls: 0.1770  decode.d6.loss_mask: 1.0288  decode.d6.loss_dice: 0.7295  decode.d7.loss_cls: 0.2038  decode.d7.loss_mask: 0.9646  decode.d7.loss_dice: 0.7127  decode.d8.loss_cls: 0.2220  decode.d8.loss_mask: 0.9728  decode.d8.loss_dice: 0.7121
05/27 00:00:16 - mmengine - INFO - Iter(train) [110200/160000]  base_lr: 3.4978e-05 lr: 3.4978e-06  eta: 5:42:52  time: 0.4160  data_time: 0.0098  memory: 5966  grad_norm: 386.6925  loss: 18.8498  decode.loss_cls: 0.2288  decode.loss_mask: 0.9409  decode.loss_dice: 0.6441  decode.d0.loss_cls: 0.6732  decode.d0.loss_mask: 0.9361  decode.d0.loss_dice: 0.6442  decode.d1.loss_cls: 0.2550  decode.d1.loss_mask: 0.9340  decode.d1.loss_dice: 0.6255  decode.d2.loss_cls: 0.3092  decode.d2.loss_mask: 0.9266  decode.d2.loss_dice: 0.6047  decode.d3.loss_cls: 0.3043  decode.d3.loss_mask: 0.9175  decode.d3.loss_dice: 0.6109  decode.d4.loss_cls: 0.2645  decode.d4.loss_mask: 1.0011  decode.d4.loss_dice: 0.6276  decode.d5.loss_cls: 0.2523  decode.d5.loss_mask: 0.9940  decode.d5.loss_dice: 0.6268  decode.d6.loss_cls: 0.2892  decode.d6.loss_mask: 0.9350  decode.d6.loss_dice: 0.6215  decode.d7.loss_cls: 0.2821  decode.d7.loss_mask: 0.9476  decode.d7.loss_dice: 0.6249  decode.d8.loss_cls: 0.2661  decode.d8.loss_mask: 0.9346  decode.d8.loss_dice: 0.6275
05/27 00:00:37 - mmengine - INFO - Iter(train) [110250/160000]  base_lr: 3.4947e-05 lr: 3.4947e-06  eta: 5:42:32  time: 0.4153  data_time: 0.0099  memory: 5966  grad_norm: 568.8220  loss: 20.8230  decode.loss_cls: 0.1735  decode.loss_mask: 1.1414  decode.loss_dice: 0.7107  decode.d0.loss_cls: 0.7455  decode.d0.loss_mask: 1.0683  decode.d0.loss_dice: 0.7237  decode.d1.loss_cls: 0.1767  decode.d1.loss_mask: 1.1611  decode.d1.loss_dice: 0.7260  decode.d2.loss_cls: 0.2306  decode.d2.loss_mask: 1.1637  decode.d2.loss_dice: 0.7357  decode.d3.loss_cls: 0.1931  decode.d3.loss_mask: 1.1323  decode.d3.loss_dice: 0.7171  decode.d4.loss_cls: 0.1563  decode.d4.loss_mask: 1.1233  decode.d4.loss_dice: 0.7186  decode.d5.loss_cls: 0.1590  decode.d5.loss_mask: 1.1284  decode.d5.loss_dice: 0.7190  decode.d6.loss_cls: 0.1790  decode.d6.loss_mask: 1.1134  decode.d6.loss_dice: 0.7028  decode.d7.loss_cls: 0.1951  decode.d7.loss_mask: 1.1229  decode.d7.loss_dice: 0.6883  decode.d8.loss_cls: 0.1870  decode.d8.loss_mask: 1.1181  decode.d8.loss_dice: 0.7122
05/27 00:00:57 - mmengine - INFO - Iter(train) [110300/160000]  base_lr: 3.4915e-05 lr: 3.4915e-06  eta: 5:42:11  time: 0.4164  data_time: 0.0098  memory: 5972  grad_norm: 471.2489  loss: 23.4435  decode.loss_cls: 0.3373  decode.loss_mask: 1.0995  decode.loss_dice: 0.8965  decode.d0.loss_cls: 0.8603  decode.d0.loss_mask: 1.0267  decode.d0.loss_dice: 0.8663  decode.d1.loss_cls: 0.3359  decode.d1.loss_mask: 1.1107  decode.d1.loss_dice: 0.9089  decode.d2.loss_cls: 0.4049  decode.d2.loss_mask: 1.0649  decode.d2.loss_dice: 0.8334  decode.d3.loss_cls: 0.3755  decode.d3.loss_mask: 1.0527  decode.d3.loss_dice: 0.8517  decode.d4.loss_cls: 0.3575  decode.d4.loss_mask: 1.0875  decode.d4.loss_dice: 0.8571  decode.d5.loss_cls: 0.3571  decode.d5.loss_mask: 1.0607  decode.d5.loss_dice: 0.8940  decode.d6.loss_cls: 0.3378  decode.d6.loss_mask: 1.0890  decode.d6.loss_dice: 0.9144  decode.d7.loss_cls: 0.3559  decode.d7.loss_mask: 1.0154  decode.d7.loss_dice: 0.8809  decode.d8.loss_cls: 0.3761  decode.d8.loss_mask: 0.9910  decode.d8.loss_dice: 0.8440
05/27 00:01:18 - mmengine - INFO - Iter(train) [110350/160000]  base_lr: 3.4884e-05 lr: 3.4884e-06  eta: 5:41:51  time: 0.4160  data_time: 0.0098  memory: 5970  grad_norm: 451.2395  loss: 16.9166  decode.loss_cls: 0.1841  decode.loss_mask: 0.8839  decode.loss_dice: 0.6008  decode.d0.loss_cls: 0.5181  decode.d0.loss_mask: 0.9243  decode.d0.loss_dice: 0.5924  decode.d1.loss_cls: 0.1538  decode.d1.loss_mask: 0.9059  decode.d1.loss_dice: 0.5929  decode.d2.loss_cls: 0.1761  decode.d2.loss_mask: 0.9080  decode.d2.loss_dice: 0.5895  decode.d3.loss_cls: 0.1581  decode.d3.loss_mask: 0.9169  decode.d3.loss_dice: 0.5871  decode.d4.loss_cls: 0.1493  decode.d4.loss_mask: 0.9176  decode.d4.loss_dice: 0.5882  decode.d5.loss_cls: 0.1817  decode.d5.loss_mask: 0.8636  decode.d5.loss_dice: 0.5735  decode.d6.loss_cls: 0.1882  decode.d6.loss_mask: 0.8610  decode.d6.loss_dice: 0.5685  decode.d7.loss_cls: 0.1612  decode.d7.loss_mask: 0.9078  decode.d7.loss_dice: 0.5995  decode.d8.loss_cls: 0.1566  decode.d8.loss_mask: 0.9109  decode.d8.loss_dice: 0.5970
05/27 00:01:39 - mmengine - INFO - Iter(train) [110400/160000]  base_lr: 3.4852e-05 lr: 3.4852e-06  eta: 5:41:30  time: 0.4149  data_time: 0.0098  memory: 5979  grad_norm: 715.9388  loss: 23.2184  decode.loss_cls: 0.2817  decode.loss_mask: 1.1817  decode.loss_dice: 0.8280  decode.d0.loss_cls: 0.7639  decode.d0.loss_mask: 1.1537  decode.d0.loss_dice: 0.8327  decode.d1.loss_cls: 0.2779  decode.d1.loss_mask: 1.1671  decode.d1.loss_dice: 0.8123  decode.d2.loss_cls: 0.2545  decode.d2.loss_mask: 1.1729  decode.d2.loss_dice: 0.8121  decode.d3.loss_cls: 0.2592  decode.d3.loss_mask: 1.1496  decode.d3.loss_dice: 0.8189  decode.d4.loss_cls: 0.2631  decode.d4.loss_mask: 1.1947  decode.d4.loss_dice: 0.8447  decode.d5.loss_cls: 0.2575  decode.d5.loss_mask: 1.1776  decode.d5.loss_dice: 0.8354  decode.d6.loss_cls: 0.2684  decode.d6.loss_mask: 1.1822  decode.d6.loss_dice: 0.8437  decode.d7.loss_cls: 0.2465  decode.d7.loss_mask: 1.2165  decode.d7.loss_dice: 0.8673  decode.d8.loss_cls: 0.2575  decode.d8.loss_mask: 1.1813  decode.d8.loss_dice: 0.8159
05/27 00:02:00 - mmengine - INFO - Iter(train) [110450/160000]  base_lr: 3.4820e-05 lr: 3.4820e-06  eta: 5:41:09  time: 0.4154  data_time: 0.0099  memory: 5968  grad_norm: 516.4328  loss: 18.6849  decode.loss_cls: 0.2562  decode.loss_mask: 0.9240  decode.loss_dice: 0.6266  decode.d0.loss_cls: 0.7734  decode.d0.loss_mask: 0.8957  decode.d0.loss_dice: 0.6442  decode.d1.loss_cls: 0.2851  decode.d1.loss_mask: 0.9167  decode.d1.loss_dice: 0.6579  decode.d2.loss_cls: 0.2848  decode.d2.loss_mask: 0.9045  decode.d2.loss_dice: 0.6348  decode.d3.loss_cls: 0.2624  decode.d3.loss_mask: 0.9562  decode.d3.loss_dice: 0.6255  decode.d4.loss_cls: 0.2950  decode.d4.loss_mask: 0.9117  decode.d4.loss_dice: 0.6083  decode.d5.loss_cls: 0.2873  decode.d5.loss_mask: 0.9198  decode.d5.loss_dice: 0.6254  decode.d6.loss_cls: 0.2995  decode.d6.loss_mask: 0.8966  decode.d6.loss_dice: 0.6377  decode.d7.loss_cls: 0.2734  decode.d7.loss_mask: 0.8936  decode.d7.loss_dice: 0.6055  decode.d8.loss_cls: 0.2479  decode.d8.loss_mask: 0.9243  decode.d8.loss_dice: 0.6107
05/27 00:02:21 - mmengine - INFO - Iter(train) [110500/160000]  base_lr: 3.4789e-05 lr: 3.4789e-06  eta: 5:40:49  time: 0.4154  data_time: 0.0099  memory: 5970  grad_norm: 492.0956  loss: 19.6453  decode.loss_cls: 0.1271  decode.loss_mask: 1.0612  decode.loss_dice: 0.7156  decode.d0.loss_cls: 0.6827  decode.d0.loss_mask: 1.0382  decode.d0.loss_dice: 0.7382  decode.d1.loss_cls: 0.1344  decode.d1.loss_mask: 1.0598  decode.d1.loss_dice: 0.7529  decode.d2.loss_cls: 0.1618  decode.d2.loss_mask: 1.0701  decode.d2.loss_dice: 0.7322  decode.d3.loss_cls: 0.1088  decode.d3.loss_mask: 1.0495  decode.d3.loss_dice: 0.7159  decode.d4.loss_cls: 0.0944  decode.d4.loss_mask: 1.0485  decode.d4.loss_dice: 0.7450  decode.d5.loss_cls: 0.1403  decode.d5.loss_mask: 1.0530  decode.d5.loss_dice: 0.7137  decode.d6.loss_cls: 0.1650  decode.d6.loss_mask: 1.0476  decode.d6.loss_dice: 0.7215  decode.d7.loss_cls: 0.1055  decode.d7.loss_mask: 1.0575  decode.d7.loss_dice: 0.7257  decode.d8.loss_cls: 0.1291  decode.d8.loss_mask: 1.0378  decode.d8.loss_dice: 0.7123
05/27 00:02:41 - mmengine - INFO - Iter(train) [110550/160000]  base_lr: 3.4757e-05 lr: 3.4757e-06  eta: 5:40:28  time: 0.4149  data_time: 0.0099  memory: 5989  grad_norm: 470.7335  loss: 17.4261  decode.loss_cls: 0.1628  decode.loss_mask: 0.8783  decode.loss_dice: 0.6411  decode.d0.loss_cls: 0.6192  decode.d0.loss_mask: 0.8569  decode.d0.loss_dice: 0.6434  decode.d1.loss_cls: 0.2134  decode.d1.loss_mask: 0.8873  decode.d1.loss_dice: 0.6627  decode.d2.loss_cls: 0.1739  decode.d2.loss_mask: 0.8703  decode.d2.loss_dice: 0.6506  decode.d3.loss_cls: 0.1536  decode.d3.loss_mask: 0.8777  decode.d3.loss_dice: 0.6592  decode.d4.loss_cls: 0.1811  decode.d4.loss_mask: 0.8772  decode.d4.loss_dice: 0.6442  decode.d5.loss_cls: 0.1475  decode.d5.loss_mask: 0.8791  decode.d5.loss_dice: 0.6500  decode.d6.loss_cls: 0.1756  decode.d6.loss_mask: 0.8565  decode.d6.loss_dice: 0.6302  decode.d7.loss_cls: 0.1963  decode.d7.loss_mask: 0.8777  decode.d7.loss_dice: 0.6377  decode.d8.loss_cls: 0.1561  decode.d8.loss_mask: 0.9022  decode.d8.loss_dice: 0.6644
05/27 00:03:02 - mmengine - INFO - Iter(train) [110600/160000]  base_lr: 3.4726e-05 lr: 3.4726e-06  eta: 5:40:08  time: 0.4148  data_time: 0.0099  memory: 5974  grad_norm: 493.8469  loss: 19.7377  decode.loss_cls: 0.1635  decode.loss_mask: 1.0456  decode.loss_dice: 0.7125  decode.d0.loss_cls: 0.6304  decode.d0.loss_mask: 1.0559  decode.d0.loss_dice: 0.7133  decode.d1.loss_cls: 0.1860  decode.d1.loss_mask: 1.0403  decode.d1.loss_dice: 0.7003  decode.d2.loss_cls: 0.1325  decode.d2.loss_mask: 1.0563  decode.d2.loss_dice: 0.7080  decode.d3.loss_cls: 0.1753  decode.d3.loss_mask: 1.0405  decode.d3.loss_dice: 0.7041  decode.d4.loss_cls: 0.1909  decode.d4.loss_mask: 1.0369  decode.d4.loss_dice: 0.7026  decode.d5.loss_cls: 0.1534  decode.d5.loss_mask: 1.0792  decode.d5.loss_dice: 0.7357  decode.d6.loss_cls: 0.1584  decode.d6.loss_mask: 1.0554  decode.d6.loss_dice: 0.7472  decode.d7.loss_cls: 0.1638  decode.d7.loss_mask: 1.0476  decode.d7.loss_dice: 0.6958  decode.d8.loss_cls: 0.1664  decode.d8.loss_mask: 1.0383  decode.d8.loss_dice: 0.7015
05/27 00:03:23 - mmengine - INFO - Iter(train) [110650/160000]  base_lr: 3.4694e-05 lr: 3.4694e-06  eta: 5:39:47  time: 0.4156  data_time: 0.0099  memory: 5975  grad_norm: 556.4531  loss: 19.4228  decode.loss_cls: 0.1779  decode.loss_mask: 0.9429  decode.loss_dice: 0.7298  decode.d0.loss_cls: 0.7012  decode.d0.loss_mask: 0.9163  decode.d0.loss_dice: 0.7148  decode.d1.loss_cls: 0.1633  decode.d1.loss_mask: 0.9586  decode.d1.loss_dice: 0.7519  decode.d2.loss_cls: 0.1593  decode.d2.loss_mask: 0.9338  decode.d2.loss_dice: 0.7291  decode.d3.loss_cls: 0.1467  decode.d3.loss_mask: 0.9775  decode.d3.loss_dice: 0.7527  decode.d4.loss_cls: 0.1894  decode.d4.loss_mask: 0.9898  decode.d4.loss_dice: 0.7644  decode.d5.loss_cls: 0.2025  decode.d5.loss_mask: 1.0071  decode.d5.loss_dice: 0.7640  decode.d6.loss_cls: 0.2037  decode.d6.loss_mask: 0.9600  decode.d6.loss_dice: 0.7460  decode.d7.loss_cls: 0.2503  decode.d7.loss_mask: 0.9286  decode.d7.loss_dice: 0.7322  decode.d8.loss_cls: 0.1705  decode.d8.loss_mask: 0.9918  decode.d8.loss_dice: 0.7667
05/27 00:03:44 - mmengine - INFO - Iter(train) [110700/160000]  base_lr: 3.4662e-05 lr: 3.4662e-06  eta: 5:39:26  time: 0.4161  data_time: 0.0100  memory: 5972  grad_norm: 858.8647  loss: 20.6361  decode.loss_cls: 0.2117  decode.loss_mask: 1.0657  decode.loss_dice: 0.7355  decode.d0.loss_cls: 0.7128  decode.d0.loss_mask: 1.0775  decode.d0.loss_dice: 0.7672  decode.d1.loss_cls: 0.2501  decode.d1.loss_mask: 1.0532  decode.d1.loss_dice: 0.7353  decode.d2.loss_cls: 0.2463  decode.d2.loss_mask: 1.0521  decode.d2.loss_dice: 0.7152  decode.d3.loss_cls: 0.2586  decode.d3.loss_mask: 1.0472  decode.d3.loss_dice: 0.7154  decode.d4.loss_cls: 0.2306  decode.d4.loss_mask: 1.0401  decode.d4.loss_dice: 0.7303  decode.d5.loss_cls: 0.2216  decode.d5.loss_mask: 1.0631  decode.d5.loss_dice: 0.7313  decode.d6.loss_cls: 0.2262  decode.d6.loss_mask: 1.0290  decode.d6.loss_dice: 0.7274  decode.d7.loss_cls: 0.2251  decode.d7.loss_mask: 1.0416  decode.d7.loss_dice: 0.7245  decode.d8.loss_cls: 0.2167  decode.d8.loss_mask: 1.0540  decode.d8.loss_dice: 0.7310
05/27 00:04:05 - mmengine - INFO - Iter(train) [110750/160000]  base_lr: 3.4631e-05 lr: 3.4631e-06  eta: 5:39:06  time: 0.4159  data_time: 0.0099  memory: 5970  grad_norm: 481.3712  loss: 19.8384  decode.loss_cls: 0.2310  decode.loss_mask: 0.9236  decode.loss_dice: 0.7801  decode.d0.loss_cls: 0.6041  decode.d0.loss_mask: 0.9213  decode.d0.loss_dice: 0.7860  decode.d1.loss_cls: 0.2094  decode.d1.loss_mask: 0.9790  decode.d1.loss_dice: 0.8106  decode.d2.loss_cls: 0.2437  decode.d2.loss_mask: 0.9117  decode.d2.loss_dice: 0.7807  decode.d3.loss_cls: 0.2283  decode.d3.loss_mask: 0.9210  decode.d3.loss_dice: 0.7839  decode.d4.loss_cls: 0.2266  decode.d4.loss_mask: 0.9202  decode.d4.loss_dice: 0.7777  decode.d5.loss_cls: 0.2422  decode.d5.loss_mask: 0.9422  decode.d5.loss_dice: 0.8016  decode.d6.loss_cls: 0.2186  decode.d6.loss_mask: 0.9435  decode.d6.loss_dice: 0.8010  decode.d7.loss_cls: 0.2316  decode.d7.loss_mask: 0.9217  decode.d7.loss_dice: 0.7792  decode.d8.loss_cls: 0.2397  decode.d8.loss_mask: 0.9140  decode.d8.loss_dice: 0.7641
05/27 00:04:25 - mmengine - INFO - Iter(train) [110800/160000]  base_lr: 3.4599e-05 lr: 3.4599e-06  eta: 5:38:45  time: 0.4153  data_time: 0.0098  memory: 5968  grad_norm: 736.6939  loss: 21.0173  decode.loss_cls: 0.1263  decode.loss_mask: 1.1525  decode.loss_dice: 0.7589  decode.d0.loss_cls: 0.6861  decode.d0.loss_mask: 1.0723  decode.d0.loss_dice: 0.6979  decode.d1.loss_cls: 0.1512  decode.d1.loss_mask: 1.1375  decode.d1.loss_dice: 0.7597  decode.d2.loss_cls: 0.1320  decode.d2.loss_mask: 1.1538  decode.d2.loss_dice: 0.7706  decode.d3.loss_cls: 0.1460  decode.d3.loss_mask: 1.1588  decode.d3.loss_dice: 0.7648  decode.d4.loss_cls: 0.1380  decode.d4.loss_mask: 1.1505  decode.d4.loss_dice: 0.7562  decode.d5.loss_cls: 0.1473  decode.d5.loss_mask: 1.1556  decode.d5.loss_dice: 0.7538  decode.d6.loss_cls: 0.1655  decode.d6.loss_mask: 1.1892  decode.d6.loss_dice: 0.7685  decode.d7.loss_cls: 0.1457  decode.d7.loss_mask: 1.1615  decode.d7.loss_dice: 0.7725  decode.d8.loss_cls: 0.1416  decode.d8.loss_mask: 1.1424  decode.d8.loss_dice: 0.7607
05/27 00:04:46 - mmengine - INFO - Iter(train) [110850/160000]  base_lr: 3.4567e-05 lr: 3.4567e-06  eta: 5:38:25  time: 0.4160  data_time: 0.0098  memory: 5976  grad_norm: 515.7982  loss: 19.6430  decode.loss_cls: 0.1177  decode.loss_mask: 1.0007  decode.loss_dice: 0.7726  decode.d0.loss_cls: 0.6027  decode.d0.loss_mask: 0.9887  decode.d0.loss_dice: 0.7528  decode.d1.loss_cls: 0.1742  decode.d1.loss_mask: 1.0040  decode.d1.loss_dice: 0.7756  decode.d2.loss_cls: 0.1173  decode.d2.loss_mask: 1.0122  decode.d2.loss_dice: 0.7939  decode.d3.loss_cls: 0.1251  decode.d3.loss_mask: 1.0037  decode.d3.loss_dice: 0.7802  decode.d4.loss_cls: 0.1332  decode.d4.loss_mask: 1.0164  decode.d4.loss_dice: 0.7974  decode.d5.loss_cls: 0.1561  decode.d5.loss_mask: 0.9912  decode.d5.loss_dice: 0.7610  decode.d6.loss_cls: 0.1196  decode.d6.loss_mask: 1.0120  decode.d6.loss_dice: 0.7793  decode.d7.loss_cls: 0.1216  decode.d7.loss_mask: 1.0098  decode.d7.loss_dice: 0.7799  decode.d8.loss_cls: 0.1248  decode.d8.loss_mask: 1.0251  decode.d8.loss_dice: 0.7944
05/27 00:05:07 - mmengine - INFO - Iter(train) [110900/160000]  base_lr: 3.4536e-05 lr: 3.4536e-06  eta: 5:38:04  time: 0.4156  data_time: 0.0099  memory: 5968  grad_norm: 481.7521  loss: 18.5586  decode.loss_cls: 0.2003  decode.loss_mask: 0.9461  decode.loss_dice: 0.6633  decode.d0.loss_cls: 0.7494  decode.d0.loss_mask: 0.9654  decode.d0.loss_dice: 0.6375  decode.d1.loss_cls: 0.2140  decode.d1.loss_mask: 0.9375  decode.d1.loss_dice: 0.6690  decode.d2.loss_cls: 0.1974  decode.d2.loss_mask: 0.9348  decode.d2.loss_dice: 0.6464  decode.d3.loss_cls: 0.1817  decode.d3.loss_mask: 0.9337  decode.d3.loss_dice: 0.6612  decode.d4.loss_cls: 0.1690  decode.d4.loss_mask: 0.9444  decode.d4.loss_dice: 0.6821  decode.d5.loss_cls: 0.1733  decode.d5.loss_mask: 0.9430  decode.d5.loss_dice: 0.6829  decode.d6.loss_cls: 0.1994  decode.d6.loss_mask: 0.9402  decode.d6.loss_dice: 0.6563  decode.d7.loss_cls: 0.1773  decode.d7.loss_mask: 0.9576  decode.d7.loss_dice: 0.6655  decode.d8.loss_cls: 0.2213  decode.d8.loss_mask: 0.9454  decode.d8.loss_dice: 0.6630
05/27 00:05:28 - mmengine - INFO - Iter(train) [110950/160000]  base_lr: 3.4504e-05 lr: 3.4504e-06  eta: 5:37:43  time: 0.4165  data_time: 0.0097  memory: 5971  grad_norm: 616.1034  loss: 22.3951  decode.loss_cls: 0.3302  decode.loss_mask: 1.0709  decode.loss_dice: 0.8121  decode.d0.loss_cls: 0.8073  decode.d0.loss_mask: 0.9928  decode.d0.loss_dice: 0.7989  decode.d1.loss_cls: 0.4219  decode.d1.loss_mask: 0.9985  decode.d1.loss_dice: 0.7704  decode.d2.loss_cls: 0.3499  decode.d2.loss_mask: 1.0345  decode.d2.loss_dice: 0.7858  decode.d3.loss_cls: 0.3736  decode.d3.loss_mask: 1.0464  decode.d3.loss_dice: 0.8154  decode.d4.loss_cls: 0.3684  decode.d4.loss_mask: 1.0188  decode.d4.loss_dice: 0.7864  decode.d5.loss_cls: 0.3388  decode.d5.loss_mask: 1.0670  decode.d5.loss_dice: 0.7978  decode.d6.loss_cls: 0.3816  decode.d6.loss_mask: 1.0249  decode.d6.loss_dice: 0.8071  decode.d7.loss_cls: 0.3984  decode.d7.loss_mask: 1.0392  decode.d7.loss_dice: 0.7721  decode.d8.loss_cls: 0.3338  decode.d8.loss_mask: 1.0598  decode.d8.loss_dice: 0.7924
05/27 00:05:48 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 00:05:48 - mmengine - INFO - Iter(train) [111000/160000]  base_lr: 3.4472e-05 lr: 3.4472e-06  eta: 5:37:23  time: 0.4163  data_time: 0.0099  memory: 5984  grad_norm: 370.7399  loss: 17.7076  decode.loss_cls: 0.1473  decode.loss_mask: 0.8840  decode.loss_dice: 0.7093  decode.d0.loss_cls: 0.5891  decode.d0.loss_mask: 0.8357  decode.d0.loss_dice: 0.6890  decode.d1.loss_cls: 0.1022  decode.d1.loss_mask: 0.8956  decode.d1.loss_dice: 0.7406  decode.d2.loss_cls: 0.1552  decode.d2.loss_mask: 0.8651  decode.d2.loss_dice: 0.7204  decode.d3.loss_cls: 0.1456  decode.d3.loss_mask: 0.8617  decode.d3.loss_dice: 0.7152  decode.d4.loss_cls: 0.1285  decode.d4.loss_mask: 0.8917  decode.d4.loss_dice: 0.7214  decode.d5.loss_cls: 0.1542  decode.d5.loss_mask: 0.8672  decode.d5.loss_dice: 0.7208  decode.d6.loss_cls: 0.1702  decode.d6.loss_mask: 0.8639  decode.d6.loss_dice: 0.6973  decode.d7.loss_cls: 0.1327  decode.d7.loss_mask: 0.8622  decode.d7.loss_dice: 0.7160  decode.d8.loss_cls: 0.1018  decode.d8.loss_mask: 0.8939  decode.d8.loss_dice: 0.7299
05/27 00:06:09 - mmengine - INFO - Iter(train) [111050/160000]  base_lr: 3.4441e-05 lr: 3.4441e-06  eta: 5:37:02  time: 0.4160  data_time: 0.0099  memory: 5971  grad_norm: 316.4995  loss: 19.0928  decode.loss_cls: 0.1896  decode.loss_mask: 1.0599  decode.loss_dice: 0.6529  decode.d0.loss_cls: 0.6573  decode.d0.loss_mask: 0.9474  decode.d0.loss_dice: 0.6351  decode.d1.loss_cls: 0.1668  decode.d1.loss_mask: 1.0587  decode.d1.loss_dice: 0.6574  decode.d2.loss_cls: 0.1722  decode.d2.loss_mask: 1.0517  decode.d2.loss_dice: 0.6555  decode.d3.loss_cls: 0.1956  decode.d3.loss_mask: 1.0038  decode.d3.loss_dice: 0.6277  decode.d4.loss_cls: 0.1983  decode.d4.loss_mask: 1.0002  decode.d4.loss_dice: 0.6334  decode.d5.loss_cls: 0.1516  decode.d5.loss_mask: 1.0798  decode.d5.loss_dice: 0.6352  decode.d6.loss_cls: 0.1149  decode.d6.loss_mask: 1.0953  decode.d6.loss_dice: 0.6767  decode.d7.loss_cls: 0.1405  decode.d7.loss_mask: 1.0788  decode.d7.loss_dice: 0.6816  decode.d8.loss_cls: 0.1668  decode.d8.loss_mask: 1.0510  decode.d8.loss_dice: 0.6572
05/27 00:06:30 - mmengine - INFO - Iter(train) [111100/160000]  base_lr: 3.4409e-05 lr: 3.4409e-06  eta: 5:36:42  time: 0.4159  data_time: 0.0099  memory: 5974  grad_norm: 728.9158  loss: 23.9749  decode.loss_cls: 0.1527  decode.loss_mask: 1.2430  decode.loss_dice: 0.9686  decode.d0.loss_cls: 0.6258  decode.d0.loss_mask: 1.1484  decode.d0.loss_dice: 0.9516  decode.d1.loss_cls: 0.1603  decode.d1.loss_mask: 1.2299  decode.d1.loss_dice: 0.9638  decode.d2.loss_cls: 0.1747  decode.d2.loss_mask: 1.2299  decode.d2.loss_dice: 0.9794  decode.d3.loss_cls: 0.1646  decode.d3.loss_mask: 1.2315  decode.d3.loss_dice: 0.9616  decode.d4.loss_cls: 0.1665  decode.d4.loss_mask: 1.2252  decode.d4.loss_dice: 0.9594  decode.d5.loss_cls: 0.1615  decode.d5.loss_mask: 1.2362  decode.d5.loss_dice: 0.9699  decode.d6.loss_cls: 0.1380  decode.d6.loss_mask: 1.2399  decode.d6.loss_dice: 0.9739  decode.d7.loss_cls: 0.1622  decode.d7.loss_mask: 1.2332  decode.d7.loss_dice: 0.9637  decode.d8.loss_cls: 0.1752  decode.d8.loss_mask: 1.2324  decode.d8.loss_dice: 0.9520
05/27 00:06:51 - mmengine - INFO - Iter(train) [111150/160000]  base_lr: 3.4377e-05 lr: 3.4377e-06  eta: 5:36:21  time: 0.4148  data_time: 0.0099  memory: 5972  grad_norm: 791.5641  loss: 23.4932  decode.loss_cls: 0.2507  decode.loss_mask: 1.1427  decode.loss_dice: 0.9117  decode.d0.loss_cls: 0.7983  decode.d0.loss_mask: 1.0722  decode.d0.loss_dice: 0.8992  decode.d1.loss_cls: 0.2621  decode.d1.loss_mask: 1.1534  decode.d1.loss_dice: 0.9130  decode.d2.loss_cls: 0.2322  decode.d2.loss_mask: 1.1607  decode.d2.loss_dice: 0.9316  decode.d3.loss_cls: 0.2542  decode.d3.loss_mask: 1.1080  decode.d3.loss_dice: 0.8958  decode.d4.loss_cls: 0.2540  decode.d4.loss_mask: 1.1339  decode.d4.loss_dice: 0.9341  decode.d5.loss_cls: 0.2281  decode.d5.loss_mask: 1.1285  decode.d5.loss_dice: 0.9201  decode.d6.loss_cls: 0.2447  decode.d6.loss_mask: 1.1513  decode.d6.loss_dice: 0.9215  decode.d7.loss_cls: 0.2401  decode.d7.loss_mask: 1.1229  decode.d7.loss_dice: 0.9074  decode.d8.loss_cls: 0.2580  decode.d8.loss_mask: 1.1487  decode.d8.loss_dice: 0.9141
05/27 00:07:12 - mmengine - INFO - Iter(train) [111200/160000]  base_lr: 3.4346e-05 lr: 3.4346e-06  eta: 5:36:00  time: 0.4156  data_time: 0.0098  memory: 5967  grad_norm: 768.7217  loss: 22.5403  decode.loss_cls: 0.1729  decode.loss_mask: 1.1610  decode.loss_dice: 0.8194  decode.d0.loss_cls: 0.6653  decode.d0.loss_mask: 1.1983  decode.d0.loss_dice: 0.8389  decode.d1.loss_cls: 0.1617  decode.d1.loss_mask: 1.1931  decode.d1.loss_dice: 0.8245  decode.d2.loss_cls: 0.2161  decode.d2.loss_mask: 1.1630  decode.d2.loss_dice: 0.8301  decode.d3.loss_cls: 0.2315  decode.d3.loss_mask: 1.1605  decode.d3.loss_dice: 0.8115  decode.d4.loss_cls: 0.1977  decode.d4.loss_mask: 1.1729  decode.d4.loss_dice: 0.8166  decode.d5.loss_cls: 0.2101  decode.d5.loss_mask: 1.1892  decode.d5.loss_dice: 0.8377  decode.d6.loss_cls: 0.2046  decode.d6.loss_mask: 1.1937  decode.d6.loss_dice: 0.8248  decode.d7.loss_cls: 0.2311  decode.d7.loss_mask: 1.1923  decode.d7.loss_dice: 0.8160  decode.d8.loss_cls: 0.1995  decode.d8.loss_mask: 1.1778  decode.d8.loss_dice: 0.8285
05/27 00:07:32 - mmengine - INFO - Iter(train) [111250/160000]  base_lr: 3.4314e-05 lr: 3.4314e-06  eta: 5:35:40  time: 0.4145  data_time: 0.0098  memory: 5975  grad_norm: 654.6341  loss: 22.4011  decode.loss_cls: 0.3024  decode.loss_mask: 1.1115  decode.loss_dice: 0.7347  decode.d0.loss_cls: 0.8625  decode.d0.loss_mask: 1.0868  decode.d0.loss_dice: 0.7318  decode.d1.loss_cls: 0.2820  decode.d1.loss_mask: 1.2062  decode.d1.loss_dice: 0.7653  decode.d2.loss_cls: 0.3180  decode.d2.loss_mask: 1.1254  decode.d2.loss_dice: 0.7612  decode.d3.loss_cls: 0.2928  decode.d3.loss_mask: 1.1532  decode.d3.loss_dice: 0.7580  decode.d4.loss_cls: 0.3125  decode.d4.loss_mask: 1.1457  decode.d4.loss_dice: 0.7614  decode.d5.loss_cls: 0.2747  decode.d5.loss_mask: 1.1452  decode.d5.loss_dice: 0.7440  decode.d6.loss_cls: 0.2852  decode.d6.loss_mask: 1.1258  decode.d6.loss_dice: 0.7223  decode.d7.loss_cls: 0.3084  decode.d7.loss_mask: 1.1883  decode.d7.loss_dice: 0.7448  decode.d8.loss_cls: 0.2718  decode.d8.loss_mask: 1.1442  decode.d8.loss_dice: 0.7348
05/27 00:07:53 - mmengine - INFO - Iter(train) [111300/160000]  base_lr: 3.4282e-05 lr: 3.4282e-06  eta: 5:35:19  time: 0.4156  data_time: 0.0099  memory: 5969  grad_norm: 735.3740  loss: 21.2690  decode.loss_cls: 0.2548  decode.loss_mask: 1.0145  decode.loss_dice: 0.8189  decode.d0.loss_cls: 0.6998  decode.d0.loss_mask: 0.9840  decode.d0.loss_dice: 0.8072  decode.d1.loss_cls: 0.2207  decode.d1.loss_mask: 0.9984  decode.d1.loss_dice: 0.8228  decode.d2.loss_cls: 0.2648  decode.d2.loss_mask: 1.0186  decode.d2.loss_dice: 0.7956  decode.d3.loss_cls: 0.2478  decode.d3.loss_mask: 1.0168  decode.d3.loss_dice: 0.8329  decode.d4.loss_cls: 0.2351  decode.d4.loss_mask: 1.0181  decode.d4.loss_dice: 0.8497  decode.d5.loss_cls: 0.2551  decode.d5.loss_mask: 1.0140  decode.d5.loss_dice: 0.8230  decode.d6.loss_cls: 0.2508  decode.d6.loss_mask: 1.0125  decode.d6.loss_dice: 0.8265  decode.d7.loss_cls: 0.2430  decode.d7.loss_mask: 1.0159  decode.d7.loss_dice: 0.8200  decode.d8.loss_cls: 0.2531  decode.d8.loss_mask: 1.0227  decode.d8.loss_dice: 0.8317
05/27 00:08:14 - mmengine - INFO - Iter(train) [111350/160000]  base_lr: 3.4251e-05 lr: 3.4251e-06  eta: 5:34:59  time: 0.4148  data_time: 0.0098  memory: 5982  grad_norm: 342.2570  loss: 19.5527  decode.loss_cls: 0.1427  decode.loss_mask: 1.0519  decode.loss_dice: 0.7052  decode.d0.loss_cls: 0.6972  decode.d0.loss_mask: 1.0378  decode.d0.loss_dice: 0.6861  decode.d1.loss_cls: 0.1497  decode.d1.loss_mask: 1.0614  decode.d1.loss_dice: 0.6984  decode.d2.loss_cls: 0.1481  decode.d2.loss_mask: 1.0523  decode.d2.loss_dice: 0.7002  decode.d3.loss_cls: 0.1372  decode.d3.loss_mask: 1.0527  decode.d3.loss_dice: 0.7113  decode.d4.loss_cls: 0.1483  decode.d4.loss_mask: 1.0625  decode.d4.loss_dice: 0.7121  decode.d5.loss_cls: 0.1553  decode.d5.loss_mask: 1.0544  decode.d5.loss_dice: 0.7063  decode.d6.loss_cls: 0.1484  decode.d6.loss_mask: 1.0602  decode.d6.loss_dice: 0.7033  decode.d7.loss_cls: 0.1376  decode.d7.loss_mask: 1.0535  decode.d7.loss_dice: 0.6998  decode.d8.loss_cls: 0.1335  decode.d8.loss_mask: 1.0515  decode.d8.loss_dice: 0.6937
05/27 00:08:35 - mmengine - INFO - Iter(train) [111400/160000]  base_lr: 3.4219e-05 lr: 3.4219e-06  eta: 5:34:38  time: 0.4144  data_time: 0.0098  memory: 5969  grad_norm: 1047.4058  loss: 22.0281  decode.loss_cls: 0.1651  decode.loss_mask: 1.1301  decode.loss_dice: 0.8347  decode.d0.loss_cls: 0.7722  decode.d0.loss_mask: 1.1852  decode.d0.loss_dice: 0.8424  decode.d1.loss_cls: 0.1678  decode.d1.loss_mask: 1.1442  decode.d1.loss_dice: 0.8415  decode.d2.loss_cls: 0.1354  decode.d2.loss_mask: 1.1479  decode.d2.loss_dice: 0.8270  decode.d3.loss_cls: 0.1887  decode.d3.loss_mask: 1.1556  decode.d3.loss_dice: 0.8213  decode.d4.loss_cls: 0.1873  decode.d4.loss_mask: 1.1435  decode.d4.loss_dice: 0.8297  decode.d5.loss_cls: 0.1701  decode.d5.loss_mask: 1.1205  decode.d5.loss_dice: 0.8222  decode.d6.loss_cls: 0.1642  decode.d6.loss_mask: 1.1487  decode.d6.loss_dice: 0.8378  decode.d7.loss_cls: 0.1835  decode.d7.loss_mask: 1.1164  decode.d7.loss_dice: 0.8188  decode.d8.loss_cls: 0.1468  decode.d8.loss_mask: 1.1521  decode.d8.loss_dice: 0.8274
05/27 00:08:56 - mmengine - INFO - Iter(train) [111450/160000]  base_lr: 3.4187e-05 lr: 3.4187e-06  eta: 5:34:17  time: 0.4150  data_time: 0.0098  memory: 5966  grad_norm: 524.0994  loss: 21.5581  decode.loss_cls: 0.1772  decode.loss_mask: 1.0517  decode.loss_dice: 0.7851  decode.d0.loss_cls: 0.7344  decode.d0.loss_mask: 1.0677  decode.d0.loss_dice: 0.7957  decode.d1.loss_cls: 0.2490  decode.d1.loss_mask: 1.1142  decode.d1.loss_dice: 0.8016  decode.d2.loss_cls: 0.2299  decode.d2.loss_mask: 1.1103  decode.d2.loss_dice: 0.8094  decode.d3.loss_cls: 0.2219  decode.d3.loss_mask: 1.0897  decode.d3.loss_dice: 0.8033  decode.d4.loss_cls: 0.2050  decode.d4.loss_mask: 1.1034  decode.d4.loss_dice: 0.8264  decode.d5.loss_cls: 0.1832  decode.d5.loss_mask: 1.1222  decode.d5.loss_dice: 0.8122  decode.d6.loss_cls: 0.2446  decode.d6.loss_mask: 1.0668  decode.d6.loss_dice: 0.7915  decode.d7.loss_cls: 0.1890  decode.d7.loss_mask: 1.1082  decode.d7.loss_dice: 0.8067  decode.d8.loss_cls: 0.1744  decode.d8.loss_mask: 1.0684  decode.d8.loss_dice: 0.8152
05/27 00:09:16 - mmengine - INFO - Iter(train) [111500/160000]  base_lr: 3.4156e-05 lr: 3.4156e-06  eta: 5:33:57  time: 0.4142  data_time: 0.0098  memory: 5975  grad_norm: 570.8589  loss: 22.0554  decode.loss_cls: 0.2513  decode.loss_mask: 1.1747  decode.loss_dice: 0.7560  decode.d0.loss_cls: 0.6761  decode.d0.loss_mask: 1.1224  decode.d0.loss_dice: 0.7066  decode.d1.loss_cls: 0.2654  decode.d1.loss_mask: 1.1694  decode.d1.loss_dice: 0.7412  decode.d2.loss_cls: 0.2410  decode.d2.loss_mask: 1.1943  decode.d2.loss_dice: 0.7371  decode.d3.loss_cls: 0.2195  decode.d3.loss_mask: 1.1942  decode.d3.loss_dice: 0.7480  decode.d4.loss_cls: 0.2571  decode.d4.loss_mask: 1.2211  decode.d4.loss_dice: 0.7388  decode.d5.loss_cls: 0.2537  decode.d5.loss_mask: 1.2201  decode.d5.loss_dice: 0.7203  decode.d6.loss_cls: 0.2869  decode.d6.loss_mask: 1.1071  decode.d6.loss_dice: 0.7003  decode.d7.loss_cls: 0.2981  decode.d7.loss_mask: 1.1662  decode.d7.loss_dice: 0.7109  decode.d8.loss_cls: 0.2854  decode.d8.loss_mask: 1.1506  decode.d8.loss_dice: 0.7418
05/27 00:09:37 - mmengine - INFO - Iter(train) [111550/160000]  base_lr: 3.4124e-05 lr: 3.4124e-06  eta: 5:33:36  time: 0.4145  data_time: 0.0098  memory: 5984  grad_norm: 653.7110  loss: 20.3444  decode.loss_cls: 0.1848  decode.loss_mask: 1.0303  decode.loss_dice: 0.7539  decode.d0.loss_cls: 0.7336  decode.d0.loss_mask: 1.0615  decode.d0.loss_dice: 0.7443  decode.d1.loss_cls: 0.2123  decode.d1.loss_mask: 1.0396  decode.d1.loss_dice: 0.7401  decode.d2.loss_cls: 0.1946  decode.d2.loss_mask: 1.0313  decode.d2.loss_dice: 0.7376  decode.d3.loss_cls: 0.2108  decode.d3.loss_mask: 1.0441  decode.d3.loss_dice: 0.7378  decode.d4.loss_cls: 0.1996  decode.d4.loss_mask: 1.0228  decode.d4.loss_dice: 0.7231  decode.d5.loss_cls: 0.2229  decode.d5.loss_mask: 1.0261  decode.d5.loss_dice: 0.7264  decode.d6.loss_cls: 0.2396  decode.d6.loss_mask: 1.0075  decode.d6.loss_dice: 0.7415  decode.d7.loss_cls: 0.2026  decode.d7.loss_mask: 1.0324  decode.d7.loss_dice: 0.7471  decode.d8.loss_cls: 0.1778  decode.d8.loss_mask: 1.0580  decode.d8.loss_dice: 0.7602
05/27 00:09:58 - mmengine - INFO - Iter(train) [111600/160000]  base_lr: 3.4092e-05 lr: 3.4092e-06  eta: 5:33:15  time: 0.4158  data_time: 0.0099  memory: 5971  grad_norm: 605.2802  loss: 18.0741  decode.loss_cls: 0.1462  decode.loss_mask: 0.9808  decode.loss_dice: 0.6417  decode.d0.loss_cls: 0.5633  decode.d0.loss_mask: 0.9581  decode.d0.loss_dice: 0.6159  decode.d1.loss_cls: 0.1167  decode.d1.loss_mask: 1.0169  decode.d1.loss_dice: 0.6411  decode.d2.loss_cls: 0.1264  decode.d2.loss_mask: 1.0186  decode.d2.loss_dice: 0.6194  decode.d3.loss_cls: 0.0957  decode.d3.loss_mask: 1.0142  decode.d3.loss_dice: 0.6293  decode.d4.loss_cls: 0.1550  decode.d4.loss_mask: 0.9953  decode.d4.loss_dice: 0.6147  decode.d5.loss_cls: 0.1806  decode.d5.loss_mask: 0.9959  decode.d5.loss_dice: 0.6144  decode.d6.loss_cls: 0.1558  decode.d6.loss_mask: 0.9963  decode.d6.loss_dice: 0.6309  decode.d7.loss_cls: 0.1521  decode.d7.loss_mask: 1.0052  decode.d7.loss_dice: 0.6290  decode.d8.loss_cls: 0.1565  decode.d8.loss_mask: 0.9854  decode.d8.loss_dice: 0.6226
05/27 00:10:19 - mmengine - INFO - Iter(train) [111650/160000]  base_lr: 3.4061e-05 lr: 3.4061e-06  eta: 5:32:55  time: 0.4149  data_time: 0.0098  memory: 5980  grad_norm: 572.8740  loss: 22.5995  decode.loss_cls: 0.2383  decode.loss_mask: 1.0665  decode.loss_dice: 0.9102  decode.d0.loss_cls: 0.7933  decode.d0.loss_mask: 1.0187  decode.d0.loss_dice: 0.8474  decode.d1.loss_cls: 0.3227  decode.d1.loss_mask: 1.0779  decode.d1.loss_dice: 0.9074  decode.d2.loss_cls: 0.2761  decode.d2.loss_mask: 1.0492  decode.d2.loss_dice: 0.8936  decode.d3.loss_cls: 0.2200  decode.d3.loss_mask: 1.0874  decode.d3.loss_dice: 0.8927  decode.d4.loss_cls: 0.2142  decode.d4.loss_mask: 1.0932  decode.d4.loss_dice: 0.9036  decode.d5.loss_cls: 0.2297  decode.d5.loss_mask: 1.0589  decode.d5.loss_dice: 0.8951  decode.d6.loss_cls: 0.2149  decode.d6.loss_mask: 1.0782  decode.d6.loss_dice: 0.9151  decode.d7.loss_cls: 0.2388  decode.d7.loss_mask: 1.0516  decode.d7.loss_dice: 0.9091  decode.d8.loss_cls: 0.1988  decode.d8.loss_mask: 1.0933  decode.d8.loss_dice: 0.9036
05/27 00:10:39 - mmengine - INFO - Iter(train) [111700/160000]  base_lr: 3.4029e-05 lr: 3.4029e-06  eta: 5:32:34  time: 0.4143  data_time: 0.0098  memory: 5980  grad_norm: 518.8335  loss: 17.4138  decode.loss_cls: 0.2264  decode.loss_mask: 0.9350  decode.loss_dice: 0.5451  decode.d0.loss_cls: 0.6054  decode.d0.loss_mask: 0.8742  decode.d0.loss_dice: 0.5592  decode.d1.loss_cls: 0.1917  decode.d1.loss_mask: 0.9735  decode.d1.loss_dice: 0.5403  decode.d2.loss_cls: 0.2190  decode.d2.loss_mask: 0.9704  decode.d2.loss_dice: 0.5440  decode.d3.loss_cls: 0.2083  decode.d3.loss_mask: 0.9487  decode.d3.loss_dice: 0.5350  decode.d4.loss_cls: 0.1701  decode.d4.loss_mask: 0.9738  decode.d4.loss_dice: 0.5619  decode.d5.loss_cls: 0.1918  decode.d5.loss_mask: 0.9656  decode.d5.loss_dice: 0.5553  decode.d6.loss_cls: 0.1963  decode.d6.loss_mask: 0.9650  decode.d6.loss_dice: 0.5489  decode.d7.loss_cls: 0.1833  decode.d7.loss_mask: 0.9654  decode.d7.loss_dice: 0.5438  decode.d8.loss_cls: 0.2164  decode.d8.loss_mask: 0.9642  decode.d8.loss_dice: 0.5360
05/27 00:11:00 - mmengine - INFO - Iter(train) [111750/160000]  base_lr: 3.3997e-05 lr: 3.3997e-06  eta: 5:32:14  time: 0.4148  data_time: 0.0098  memory: 5966  grad_norm: 614.4506  loss: 20.5121  decode.loss_cls: 0.2326  decode.loss_mask: 1.0697  decode.loss_dice: 0.6862  decode.d0.loss_cls: 0.6768  decode.d0.loss_mask: 1.0931  decode.d0.loss_dice: 0.7018  decode.d1.loss_cls: 0.2396  decode.d1.loss_mask: 1.0977  decode.d1.loss_dice: 0.7034  decode.d2.loss_cls: 0.2145  decode.d2.loss_mask: 1.0706  decode.d2.loss_dice: 0.6804  decode.d3.loss_cls: 0.2446  decode.d3.loss_mask: 1.0721  decode.d3.loss_dice: 0.6831  decode.d4.loss_cls: 0.2256  decode.d4.loss_mask: 1.0888  decode.d4.loss_dice: 0.7051  decode.d5.loss_cls: 0.2272  decode.d5.loss_mask: 1.0798  decode.d5.loss_dice: 0.6938  decode.d6.loss_cls: 0.2278  decode.d6.loss_mask: 1.0977  decode.d6.loss_dice: 0.7076  decode.d7.loss_cls: 0.2030  decode.d7.loss_mask: 1.0745  decode.d7.loss_dice: 0.6952  decode.d8.loss_cls: 0.2102  decode.d8.loss_mask: 1.1078  decode.d8.loss_dice: 0.7018
05/27 00:11:21 - mmengine - INFO - Iter(train) [111800/160000]  base_lr: 3.3965e-05 lr: 3.3965e-06  eta: 5:31:53  time: 0.4157  data_time: 0.0098  memory: 5966  grad_norm: 1340.4442  loss: 24.6112  decode.loss_cls: 0.2436  decode.loss_mask: 1.3196  decode.loss_dice: 0.8721  decode.d0.loss_cls: 0.7983  decode.d0.loss_mask: 1.2963  decode.d0.loss_dice: 0.8362  decode.d1.loss_cls: 0.2424  decode.d1.loss_mask: 1.3069  decode.d1.loss_dice: 0.8767  decode.d2.loss_cls: 0.2742  decode.d2.loss_mask: 1.2765  decode.d2.loss_dice: 0.8368  decode.d3.loss_cls: 0.2479  decode.d3.loss_mask: 1.3090  decode.d3.loss_dice: 0.8543  decode.d4.loss_cls: 0.2916  decode.d4.loss_mask: 1.3065  decode.d4.loss_dice: 0.8662  decode.d5.loss_cls: 0.2437  decode.d5.loss_mask: 1.3102  decode.d5.loss_dice: 0.8412  decode.d6.loss_cls: 0.2341  decode.d6.loss_mask: 1.3259  decode.d6.loss_dice: 0.8484  decode.d7.loss_cls: 0.2398  decode.d7.loss_mask: 1.3166  decode.d7.loss_dice: 0.8419  decode.d8.loss_cls: 0.2460  decode.d8.loss_mask: 1.2823  decode.d8.loss_dice: 0.8257
05/27 00:11:42 - mmengine - INFO - Iter(train) [111850/160000]  base_lr: 3.3934e-05 lr: 3.3934e-06  eta: 5:31:32  time: 0.4148  data_time: 0.0098  memory: 5968  grad_norm: 852.2203  loss: 19.5536  decode.loss_cls: 0.2314  decode.loss_mask: 1.0869  decode.loss_dice: 0.6559  decode.d0.loss_cls: 0.7104  decode.d0.loss_mask: 0.9818  decode.d0.loss_dice: 0.6390  decode.d1.loss_cls: 0.2489  decode.d1.loss_mask: 1.0131  decode.d1.loss_dice: 0.6452  decode.d2.loss_cls: 0.2134  decode.d2.loss_mask: 1.0003  decode.d2.loss_dice: 0.6421  decode.d3.loss_cls: 0.2551  decode.d3.loss_mask: 0.9928  decode.d3.loss_dice: 0.6414  decode.d4.loss_cls: 0.2397  decode.d4.loss_mask: 1.0219  decode.d4.loss_dice: 0.6313  decode.d5.loss_cls: 0.1949  decode.d5.loss_mask: 1.0212  decode.d5.loss_dice: 0.6557  decode.d6.loss_cls: 0.2514  decode.d6.loss_mask: 1.0229  decode.d6.loss_dice: 0.6508  decode.d7.loss_cls: 0.2537  decode.d7.loss_mask: 1.0666  decode.d7.loss_dice: 0.6359  decode.d8.loss_cls: 0.2206  decode.d8.loss_mask: 1.0797  decode.d8.loss_dice: 0.6495
05/27 00:12:02 - mmengine - INFO - Iter(train) [111900/160000]  base_lr: 3.3902e-05 lr: 3.3902e-06  eta: 5:31:12  time: 0.4147  data_time: 0.0099  memory: 5969  grad_norm: 476.6081  loss: 18.5109  decode.loss_cls: 0.2029  decode.loss_mask: 1.0129  decode.loss_dice: 0.6192  decode.d0.loss_cls: 0.6044  decode.d0.loss_mask: 0.9914  decode.d0.loss_dice: 0.6174  decode.d1.loss_cls: 0.1493  decode.d1.loss_mask: 1.0353  decode.d1.loss_dice: 0.6243  decode.d2.loss_cls: 0.1688  decode.d2.loss_mask: 1.0086  decode.d2.loss_dice: 0.6255  decode.d3.loss_cls: 0.1700  decode.d3.loss_mask: 1.0146  decode.d3.loss_dice: 0.6112  decode.d4.loss_cls: 0.1569  decode.d4.loss_mask: 1.0055  decode.d4.loss_dice: 0.6146  decode.d5.loss_cls: 0.1940  decode.d5.loss_mask: 1.0258  decode.d5.loss_dice: 0.6175  decode.d6.loss_cls: 0.1581  decode.d6.loss_mask: 1.0159  decode.d6.loss_dice: 0.6286  decode.d7.loss_cls: 0.1889  decode.d7.loss_mask: 1.0055  decode.d7.loss_dice: 0.6276  decode.d8.loss_cls: 0.1878  decode.d8.loss_mask: 1.0261  decode.d8.loss_dice: 0.6025
05/27 00:12:23 - mmengine - INFO - Iter(train) [111950/160000]  base_lr: 3.3870e-05 lr: 3.3870e-06  eta: 5:30:51  time: 0.4162  data_time: 0.0101  memory: 5966  grad_norm: 889.0927  loss: 23.2881  decode.loss_cls: 0.2745  decode.loss_mask: 1.1779  decode.loss_dice: 0.8718  decode.d0.loss_cls: 0.7239  decode.d0.loss_mask: 1.1342  decode.d0.loss_dice: 0.8407  decode.d1.loss_cls: 0.2891  decode.d1.loss_mask: 1.1786  decode.d1.loss_dice: 0.8550  decode.d2.loss_cls: 0.2645  decode.d2.loss_mask: 1.1767  decode.d2.loss_dice: 0.8416  decode.d3.loss_cls: 0.2459  decode.d3.loss_mask: 1.1700  decode.d3.loss_dice: 0.8193  decode.d4.loss_cls: 0.2641  decode.d4.loss_mask: 1.1737  decode.d4.loss_dice: 0.8396  decode.d5.loss_cls: 0.3008  decode.d5.loss_mask: 1.1524  decode.d5.loss_dice: 0.8306  decode.d6.loss_cls: 0.3003  decode.d6.loss_mask: 1.1404  decode.d6.loss_dice: 0.8355  decode.d7.loss_cls: 0.2702  decode.d7.loss_mask: 1.1670  decode.d7.loss_dice: 0.8317  decode.d8.loss_cls: 0.2700  decode.d8.loss_mask: 1.1766  decode.d8.loss_dice: 0.8714
05/27 00:12:44 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 00:12:44 - mmengine - INFO - Iter(train) [112000/160000]  base_lr: 3.3839e-05 lr: 3.3839e-06  eta: 5:30:31  time: 0.4162  data_time: 0.0101  memory: 5976  grad_norm: 914.0808  loss: 19.3524  decode.loss_cls: 0.1830  decode.loss_mask: 1.0589  decode.loss_dice: 0.6474  decode.d0.loss_cls: 0.7178  decode.d0.loss_mask: 0.9917  decode.d0.loss_dice: 0.6388  decode.d1.loss_cls: 0.2065  decode.d1.loss_mask: 1.0360  decode.d1.loss_dice: 0.6331  decode.d2.loss_cls: 0.1695  decode.d2.loss_mask: 1.0580  decode.d2.loss_dice: 0.6400  decode.d3.loss_cls: 0.1937  decode.d3.loss_mask: 1.0540  decode.d3.loss_dice: 0.6431  decode.d4.loss_cls: 0.2243  decode.d4.loss_mask: 1.0046  decode.d4.loss_dice: 0.6296  decode.d5.loss_cls: 0.2192  decode.d5.loss_mask: 1.0566  decode.d5.loss_dice: 0.6401  decode.d6.loss_cls: 0.1839  decode.d6.loss_mask: 1.0620  decode.d6.loss_dice: 0.6552  decode.d7.loss_cls: 0.2113  decode.d7.loss_mask: 1.0565  decode.d7.loss_dice: 0.6484  decode.d8.loss_cls: 0.1758  decode.d8.loss_mask: 1.0607  decode.d8.loss_dice: 0.6526
05/27 00:13:05 - mmengine - INFO - Iter(train) [112050/160000]  base_lr: 3.3807e-05 lr: 3.3807e-06  eta: 5:30:10  time: 0.4163  data_time: 0.0101  memory: 5976  grad_norm: 1054.5030  loss: 24.6240  decode.loss_cls: 0.3989  decode.loss_mask: 1.1470  decode.loss_dice: 0.8669  decode.d0.loss_cls: 0.8627  decode.d0.loss_mask: 1.0912  decode.d0.loss_dice: 0.8712  decode.d1.loss_cls: 0.4012  decode.d1.loss_mask: 1.1449  decode.d1.loss_dice: 0.8874  decode.d2.loss_cls: 0.3565  decode.d2.loss_mask: 1.1581  decode.d2.loss_dice: 0.8855  decode.d3.loss_cls: 0.3567  decode.d3.loss_mask: 1.1530  decode.d3.loss_dice: 0.8920  decode.d4.loss_cls: 0.3815  decode.d4.loss_mask: 1.1543  decode.d4.loss_dice: 0.8708  decode.d5.loss_cls: 0.3921  decode.d5.loss_mask: 1.1662  decode.d5.loss_dice: 0.8966  decode.d6.loss_cls: 0.3608  decode.d6.loss_mask: 1.1734  decode.d6.loss_dice: 0.8943  decode.d7.loss_cls: 0.3586  decode.d7.loss_mask: 1.1383  decode.d7.loss_dice: 0.8866  decode.d8.loss_cls: 0.3434  decode.d8.loss_mask: 1.2115  decode.d8.loss_dice: 0.9224
05/27 00:13:26 - mmengine - INFO - Iter(train) [112100/160000]  base_lr: 3.3775e-05 lr: 3.3775e-06  eta: 5:29:49  time: 0.4158  data_time: 0.0101  memory: 5966  grad_norm: 503.9163  loss: 22.3847  decode.loss_cls: 0.1680  decode.loss_mask: 1.1628  decode.loss_dice: 0.8814  decode.d0.loss_cls: 0.6668  decode.d0.loss_mask: 1.1097  decode.d0.loss_dice: 0.7942  decode.d1.loss_cls: 0.1387  decode.d1.loss_mask: 1.2081  decode.d1.loss_dice: 0.8709  decode.d2.loss_cls: 0.1671  decode.d2.loss_mask: 1.1714  decode.d2.loss_dice: 0.8590  decode.d3.loss_cls: 0.1903  decode.d3.loss_mask: 1.1732  decode.d3.loss_dice: 0.8384  decode.d4.loss_cls: 0.1985  decode.d4.loss_mask: 1.1867  decode.d4.loss_dice: 0.8678  decode.d5.loss_cls: 0.1853  decode.d5.loss_mask: 1.1530  decode.d5.loss_dice: 0.8543  decode.d6.loss_cls: 0.2043  decode.d6.loss_mask: 1.1605  decode.d6.loss_dice: 0.8511  decode.d7.loss_cls: 0.1894  decode.d7.loss_mask: 1.1133  decode.d7.loss_dice: 0.8419  decode.d8.loss_cls: 0.1136  decode.d8.loss_mask: 1.1830  decode.d8.loss_dice: 0.8823
05/27 00:13:46 - mmengine - INFO - Iter(train) [112150/160000]  base_lr: 3.3743e-05 lr: 3.3743e-06  eta: 5:29:29  time: 0.4144  data_time: 0.0098  memory: 5981  grad_norm: 523.7413  loss: 22.9063  decode.loss_cls: 0.3036  decode.loss_mask: 1.1229  decode.loss_dice: 0.7876  decode.d0.loss_cls: 0.8270  decode.d0.loss_mask: 1.0446  decode.d0.loss_dice: 0.7809  decode.d1.loss_cls: 0.3220  decode.d1.loss_mask: 1.0927  decode.d1.loss_dice: 0.7973  decode.d2.loss_cls: 0.3162  decode.d2.loss_mask: 1.1047  decode.d2.loss_dice: 0.8038  decode.d3.loss_cls: 0.3281  decode.d3.loss_mask: 1.0928  decode.d3.loss_dice: 0.7928  decode.d4.loss_cls: 0.3333  decode.d4.loss_mask: 1.0707  decode.d4.loss_dice: 0.8026  decode.d5.loss_cls: 0.3085  decode.d5.loss_mask: 1.1302  decode.d5.loss_dice: 0.8228  decode.d6.loss_cls: 0.3133  decode.d6.loss_mask: 1.2115  decode.d6.loss_dice: 0.8161  decode.d7.loss_cls: 0.3202  decode.d7.loss_mask: 1.1016  decode.d7.loss_dice: 0.8109  decode.d8.loss_cls: 0.3054  decode.d8.loss_mask: 1.2373  decode.d8.loss_dice: 0.8047
05/27 00:14:07 - mmengine - INFO - Iter(train) [112200/160000]  base_lr: 3.3712e-05 lr: 3.3712e-06  eta: 5:29:08  time: 0.4150  data_time: 0.0098  memory: 5998  grad_norm: 600.0182  loss: 22.3076  decode.loss_cls: 0.2040  decode.loss_mask: 1.1991  decode.loss_dice: 0.7848  decode.d0.loss_cls: 0.7512  decode.d0.loss_mask: 1.1358  decode.d0.loss_dice: 0.7971  decode.d1.loss_cls: 0.2224  decode.d1.loss_mask: 1.1401  decode.d1.loss_dice: 0.7813  decode.d2.loss_cls: 0.2176  decode.d2.loss_mask: 1.1807  decode.d2.loss_dice: 0.8021  decode.d3.loss_cls: 0.2060  decode.d3.loss_mask: 1.1734  decode.d3.loss_dice: 0.7877  decode.d4.loss_cls: 0.2254  decode.d4.loss_mask: 1.1634  decode.d4.loss_dice: 0.7993  decode.d5.loss_cls: 0.1936  decode.d5.loss_mask: 1.1654  decode.d5.loss_dice: 0.7959  decode.d6.loss_cls: 0.2383  decode.d6.loss_mask: 1.1650  decode.d6.loss_dice: 0.7910  decode.d7.loss_cls: 0.2076  decode.d7.loss_mask: 1.1776  decode.d7.loss_dice: 0.8034  decode.d8.loss_cls: 0.2148  decode.d8.loss_mask: 1.1754  decode.d8.loss_dice: 0.8084
05/27 00:14:28 - mmengine - INFO - Iter(train) [112250/160000]  base_lr: 3.3680e-05 lr: 3.3680e-06  eta: 5:28:48  time: 0.4148  data_time: 0.0098  memory: 5970  grad_norm: 796.3629  loss: 19.4003  decode.loss_cls: 0.2011  decode.loss_mask: 0.9807  decode.loss_dice: 0.6447  decode.d0.loss_cls: 0.7670  decode.d0.loss_mask: 0.9853  decode.d0.loss_dice: 0.6492  decode.d1.loss_cls: 0.1836  decode.d1.loss_mask: 1.0525  decode.d1.loss_dice: 0.6898  decode.d2.loss_cls: 0.1638  decode.d2.loss_mask: 1.0086  decode.d2.loss_dice: 0.6942  decode.d3.loss_cls: 0.1716  decode.d3.loss_mask: 1.0239  decode.d3.loss_dice: 0.6918  decode.d4.loss_cls: 0.1680  decode.d4.loss_mask: 1.0240  decode.d4.loss_dice: 0.6839  decode.d5.loss_cls: 0.1632  decode.d5.loss_mask: 1.0380  decode.d5.loss_dice: 0.6890  decode.d6.loss_cls: 0.1692  decode.d6.loss_mask: 1.0115  decode.d6.loss_dice: 0.7140  decode.d7.loss_cls: 0.1860  decode.d7.loss_mask: 1.0481  decode.d7.loss_dice: 0.7009  decode.d8.loss_cls: 0.1992  decode.d8.loss_mask: 1.0153  decode.d8.loss_dice: 0.6820
05/27 00:14:49 - mmengine - INFO - Iter(train) [112300/160000]  base_lr: 3.3648e-05 lr: 3.3648e-06  eta: 5:28:27  time: 0.4148  data_time: 0.0098  memory: 5968  grad_norm: 828.1290  loss: 19.6526  decode.loss_cls: 0.1441  decode.loss_mask: 1.0463  decode.loss_dice: 0.7280  decode.d0.loss_cls: 0.6326  decode.d0.loss_mask: 0.9845  decode.d0.loss_dice: 0.6862  decode.d1.loss_cls: 0.1331  decode.d1.loss_mask: 1.0620  decode.d1.loss_dice: 0.7437  decode.d2.loss_cls: 0.1638  decode.d2.loss_mask: 1.0301  decode.d2.loss_dice: 0.7117  decode.d3.loss_cls: 0.1918  decode.d3.loss_mask: 1.0389  decode.d3.loss_dice: 0.7098  decode.d4.loss_cls: 0.1616  decode.d4.loss_mask: 1.0382  decode.d4.loss_dice: 0.7305  decode.d5.loss_cls: 0.1371  decode.d5.loss_mask: 1.0631  decode.d5.loss_dice: 0.7329  decode.d6.loss_cls: 0.1303  decode.d6.loss_mask: 1.0734  decode.d6.loss_dice: 0.7425  decode.d7.loss_cls: 0.1388  decode.d7.loss_mask: 1.0462  decode.d7.loss_dice: 0.7263  decode.d8.loss_cls: 0.1669  decode.d8.loss_mask: 1.0493  decode.d8.loss_dice: 0.7090
05/27 00:15:10 - mmengine - INFO - Iter(train) [112350/160000]  base_lr: 3.3616e-05 lr: 3.3616e-06  eta: 5:28:06  time: 0.4151  data_time: 0.0100  memory: 5973  grad_norm: 614.2549  loss: 22.6482  decode.loss_cls: 0.3278  decode.loss_mask: 1.0095  decode.loss_dice: 0.8202  decode.d0.loss_cls: 0.8462  decode.d0.loss_mask: 1.0557  decode.d0.loss_dice: 0.8238  decode.d1.loss_cls: 0.3648  decode.d1.loss_mask: 1.0424  decode.d1.loss_dice: 0.8720  decode.d2.loss_cls: 0.3455  decode.d2.loss_mask: 1.0428  decode.d2.loss_dice: 0.8346  decode.d3.loss_cls: 0.3035  decode.d3.loss_mask: 1.1126  decode.d3.loss_dice: 0.8494  decode.d4.loss_cls: 0.3274  decode.d4.loss_mask: 1.0296  decode.d4.loss_dice: 0.8146  decode.d5.loss_cls: 0.3403  decode.d5.loss_mask: 1.0594  decode.d5.loss_dice: 0.8137  decode.d6.loss_cls: 0.2877  decode.d6.loss_mask: 1.0823  decode.d6.loss_dice: 0.8544  decode.d7.loss_cls: 0.3260  decode.d7.loss_mask: 1.0430  decode.d7.loss_dice: 0.8405  decode.d8.loss_cls: 0.3184  decode.d8.loss_mask: 1.0152  decode.d8.loss_dice: 0.8450
05/27 00:15:30 - mmengine - INFO - Iter(train) [112400/160000]  base_lr: 3.3585e-05 lr: 3.3585e-06  eta: 5:27:46  time: 0.4154  data_time: 0.0098  memory: 5980  grad_norm: 460.4188  loss: 16.2886  decode.loss_cls: 0.2010  decode.loss_mask: 0.8233  decode.loss_dice: 0.5878  decode.d0.loss_cls: 0.6272  decode.d0.loss_mask: 0.7804  decode.d0.loss_dice: 0.5608  decode.d1.loss_cls: 0.1739  decode.d1.loss_mask: 0.8160  decode.d1.loss_dice: 0.5817  decode.d2.loss_cls: 0.1620  decode.d2.loss_mask: 0.8354  decode.d2.loss_dice: 0.6045  decode.d3.loss_cls: 0.1460  decode.d3.loss_mask: 0.8339  decode.d3.loss_dice: 0.6009  decode.d4.loss_cls: 0.1427  decode.d4.loss_mask: 0.8362  decode.d4.loss_dice: 0.6132  decode.d5.loss_cls: 0.1464  decode.d5.loss_mask: 0.8233  decode.d5.loss_dice: 0.6068  decode.d6.loss_cls: 0.1671  decode.d6.loss_mask: 0.8233  decode.d6.loss_dice: 0.5846  decode.d7.loss_cls: 0.1824  decode.d7.loss_mask: 0.8203  decode.d7.loss_dice: 0.6037  decode.d8.loss_cls: 0.1755  decode.d8.loss_mask: 0.8248  decode.d8.loss_dice: 0.6037
05/27 00:15:51 - mmengine - INFO - Iter(train) [112450/160000]  base_lr: 3.3553e-05 lr: 3.3553e-06  eta: 5:27:25  time: 0.4153  data_time: 0.0098  memory: 5967  grad_norm: 471.9517  loss: 16.6243  decode.loss_cls: 0.1073  decode.loss_mask: 0.8240  decode.loss_dice: 0.6532  decode.d0.loss_cls: 0.6093  decode.d0.loss_mask: 0.7750  decode.d0.loss_dice: 0.6288  decode.d1.loss_cls: 0.1477  decode.d1.loss_mask: 0.8212  decode.d1.loss_dice: 0.6568  decode.d2.loss_cls: 0.1644  decode.d2.loss_mask: 0.8305  decode.d2.loss_dice: 0.6521  decode.d3.loss_cls: 0.1428  decode.d3.loss_mask: 0.8256  decode.d3.loss_dice: 0.6596  decode.d4.loss_cls: 0.1580  decode.d4.loss_mask: 0.7913  decode.d4.loss_dice: 0.6350  decode.d5.loss_cls: 0.1913  decode.d5.loss_mask: 0.8020  decode.d5.loss_dice: 0.6306  decode.d6.loss_cls: 0.2002  decode.d6.loss_mask: 0.7807  decode.d6.loss_dice: 0.6294  decode.d7.loss_cls: 0.2035  decode.d7.loss_mask: 0.8044  decode.d7.loss_dice: 0.6722  decode.d8.loss_cls: 0.1402  decode.d8.loss_mask: 0.8205  decode.d8.loss_dice: 0.6668
05/27 00:16:12 - mmengine - INFO - Iter(train) [112500/160000]  base_lr: 3.3521e-05 lr: 3.3521e-06  eta: 5:27:04  time: 0.4148  data_time: 0.0099  memory: 5974  grad_norm: 515.3345  loss: 17.7590  decode.loss_cls: 0.1539  decode.loss_mask: 0.8785  decode.loss_dice: 0.6633  decode.d0.loss_cls: 0.6007  decode.d0.loss_mask: 0.8765  decode.d0.loss_dice: 0.6575  decode.d1.loss_cls: 0.1756  decode.d1.loss_mask: 0.9014  decode.d1.loss_dice: 0.6763  decode.d2.loss_cls: 0.1759  decode.d2.loss_mask: 0.8787  decode.d2.loss_dice: 0.6765  decode.d3.loss_cls: 0.1770  decode.d3.loss_mask: 0.9040  decode.d3.loss_dice: 0.6667  decode.d4.loss_cls: 0.1910  decode.d4.loss_mask: 0.8958  decode.d4.loss_dice: 0.6659  decode.d5.loss_cls: 0.1756  decode.d5.loss_mask: 0.9015  decode.d5.loss_dice: 0.6705  decode.d6.loss_cls: 0.1564  decode.d6.loss_mask: 0.9140  decode.d6.loss_dice: 0.6691  decode.d7.loss_cls: 0.1624  decode.d7.loss_mask: 0.9026  decode.d7.loss_dice: 0.6729  decode.d8.loss_cls: 0.1638  decode.d8.loss_mask: 0.8907  decode.d8.loss_dice: 0.6646
05/27 00:16:33 - mmengine - INFO - Iter(train) [112550/160000]  base_lr: 3.3489e-05 lr: 3.3489e-06  eta: 5:26:44  time: 0.4139  data_time: 0.0099  memory: 5970  grad_norm: 416.8484  loss: 14.9048  decode.loss_cls: 0.0963  decode.loss_mask: 0.7862  decode.loss_dice: 0.5635  decode.d0.loss_cls: 0.5522  decode.d0.loss_mask: 0.7698  decode.d0.loss_dice: 0.5802  decode.d1.loss_cls: 0.1097  decode.d1.loss_mask: 0.7888  decode.d1.loss_dice: 0.5468  decode.d2.loss_cls: 0.0738  decode.d2.loss_mask: 0.7896  decode.d2.loss_dice: 0.5551  decode.d3.loss_cls: 0.0834  decode.d3.loss_mask: 0.8251  decode.d3.loss_dice: 0.5550  decode.d4.loss_cls: 0.0917  decode.d4.loss_mask: 0.7904  decode.d4.loss_dice: 0.5669  decode.d5.loss_cls: 0.0846  decode.d5.loss_mask: 0.7815  decode.d5.loss_dice: 0.5584  decode.d6.loss_cls: 0.0877  decode.d6.loss_mask: 0.8193  decode.d6.loss_dice: 0.5792  decode.d7.loss_cls: 0.0844  decode.d7.loss_mask: 0.7837  decode.d7.loss_dice: 0.5703  decode.d8.loss_cls: 0.0745  decode.d8.loss_mask: 0.7933  decode.d8.loss_dice: 0.5632
05/27 00:16:53 - mmengine - INFO - Iter(train) [112600/160000]  base_lr: 3.3458e-05 lr: 3.3458e-06  eta: 5:26:23  time: 0.4145  data_time: 0.0098  memory: 5980  grad_norm: 650.9922  loss: 20.1266  decode.loss_cls: 0.1432  decode.loss_mask: 1.0582  decode.loss_dice: 0.7366  decode.d0.loss_cls: 0.7184  decode.d0.loss_mask: 1.0113  decode.d0.loss_dice: 0.7213  decode.d1.loss_cls: 0.1255  decode.d1.loss_mask: 1.0994  decode.d1.loss_dice: 0.7712  decode.d2.loss_cls: 0.1259  decode.d2.loss_mask: 1.0902  decode.d2.loss_dice: 0.7575  decode.d3.loss_cls: 0.1433  decode.d3.loss_mask: 1.0874  decode.d3.loss_dice: 0.7500  decode.d4.loss_cls: 0.1261  decode.d4.loss_mask: 1.0659  decode.d4.loss_dice: 0.7526  decode.d5.loss_cls: 0.1326  decode.d5.loss_mask: 1.0766  decode.d5.loss_dice: 0.7486  decode.d6.loss_cls: 0.1211  decode.d6.loss_mask: 1.0919  decode.d6.loss_dice: 0.7679  decode.d7.loss_cls: 0.1306  decode.d7.loss_mask: 1.0722  decode.d7.loss_dice: 0.7614  decode.d8.loss_cls: 0.1173  decode.d8.loss_mask: 1.0715  decode.d8.loss_dice: 0.7511
05/27 00:17:14 - mmengine - INFO - Iter(train) [112650/160000]  base_lr: 3.3426e-05 lr: 3.3426e-06  eta: 5:26:03  time: 0.4149  data_time: 0.0099  memory: 5974  grad_norm: 546.5440  loss: 19.4044  decode.loss_cls: 0.2218  decode.loss_mask: 0.9927  decode.loss_dice: 0.6976  decode.d0.loss_cls: 0.6790  decode.d0.loss_mask: 1.0158  decode.d0.loss_dice: 0.6887  decode.d1.loss_cls: 0.2032  decode.d1.loss_mask: 1.0206  decode.d1.loss_dice: 0.7011  decode.d2.loss_cls: 0.1661  decode.d2.loss_mask: 0.9896  decode.d2.loss_dice: 0.7029  decode.d3.loss_cls: 0.1727  decode.d3.loss_mask: 0.9922  decode.d3.loss_dice: 0.6993  decode.d4.loss_cls: 0.1865  decode.d4.loss_mask: 0.9963  decode.d4.loss_dice: 0.7130  decode.d5.loss_cls: 0.1838  decode.d5.loss_mask: 1.0004  decode.d5.loss_dice: 0.7016  decode.d6.loss_cls: 0.2167  decode.d6.loss_mask: 1.0021  decode.d6.loss_dice: 0.6771  decode.d7.loss_cls: 0.1900  decode.d7.loss_mask: 1.0074  decode.d7.loss_dice: 0.6809  decode.d8.loss_cls: 0.1935  decode.d8.loss_mask: 1.0157  decode.d8.loss_dice: 0.6961
05/27 00:17:35 - mmengine - INFO - Iter(train) [112700/160000]  base_lr: 3.3394e-05 lr: 3.3394e-06  eta: 5:25:42  time: 0.4150  data_time: 0.0098  memory: 5975  grad_norm: 448.9053  loss: 19.3974  decode.loss_cls: 0.2367  decode.loss_mask: 0.8987  decode.loss_dice: 0.7878  decode.d0.loss_cls: 0.7192  decode.d0.loss_mask: 0.8758  decode.d0.loss_dice: 0.7310  decode.d1.loss_cls: 0.2349  decode.d1.loss_mask: 0.8811  decode.d1.loss_dice: 0.7466  decode.d2.loss_cls: 0.2429  decode.d2.loss_mask: 0.9139  decode.d2.loss_dice: 0.7502  decode.d3.loss_cls: 0.2431  decode.d3.loss_mask: 0.9050  decode.d3.loss_dice: 0.7469  decode.d4.loss_cls: 0.2314  decode.d4.loss_mask: 0.9013  decode.d4.loss_dice: 0.7669  decode.d5.loss_cls: 0.2251  decode.d5.loss_mask: 0.9125  decode.d5.loss_dice: 0.7688  decode.d6.loss_cls: 0.2489  decode.d6.loss_mask: 0.8900  decode.d6.loss_dice: 0.7630  decode.d7.loss_cls: 0.2401  decode.d7.loss_mask: 0.8798  decode.d7.loss_dice: 0.7562  decode.d8.loss_cls: 0.2343  decode.d8.loss_mask: 0.8885  decode.d8.loss_dice: 0.7767
05/27 00:17:56 - mmengine - INFO - Iter(train) [112750/160000]  base_lr: 3.3362e-05 lr: 3.3362e-06  eta: 5:25:21  time: 0.4149  data_time: 0.0098  memory: 5968  grad_norm: 750.7024  loss: 18.4983  decode.loss_cls: 0.2539  decode.loss_mask: 0.8410  decode.loss_dice: 0.7121  decode.d0.loss_cls: 0.6761  decode.d0.loss_mask: 0.8405  decode.d0.loss_dice: 0.7527  decode.d1.loss_cls: 0.2295  decode.d1.loss_mask: 0.8288  decode.d1.loss_dice: 0.7482  decode.d2.loss_cls: 0.2748  decode.d2.loss_mask: 0.8292  decode.d2.loss_dice: 0.6975  decode.d3.loss_cls: 0.2782  decode.d3.loss_mask: 0.8299  decode.d3.loss_dice: 0.7091  decode.d4.loss_cls: 0.2736  decode.d4.loss_mask: 0.8240  decode.d4.loss_dice: 0.6902  decode.d5.loss_cls: 0.2830  decode.d5.loss_mask: 0.8357  decode.d5.loss_dice: 0.7101  decode.d6.loss_cls: 0.2506  decode.d6.loss_mask: 0.8344  decode.d6.loss_dice: 0.7374  decode.d7.loss_cls: 0.2353  decode.d7.loss_mask: 0.8274  decode.d7.loss_dice: 0.7156  decode.d8.loss_cls: 0.2684  decode.d8.loss_mask: 0.8173  decode.d8.loss_dice: 0.6937
05/27 00:18:17 - mmengine - INFO - Iter(train) [112800/160000]  base_lr: 3.3331e-05 lr: 3.3331e-06  eta: 5:25:01  time: 0.4139  data_time: 0.0098  memory: 5969  grad_norm: 468.1911  loss: 18.5094  decode.loss_cls: 0.1117  decode.loss_mask: 1.0216  decode.loss_dice: 0.6512  decode.d0.loss_cls: 0.6142  decode.d0.loss_mask: 0.9996  decode.d0.loss_dice: 0.6401  decode.d1.loss_cls: 0.1506  decode.d1.loss_mask: 1.0256  decode.d1.loss_dice: 0.6709  decode.d2.loss_cls: 0.1548  decode.d2.loss_mask: 0.9976  decode.d2.loss_dice: 0.6534  decode.d3.loss_cls: 0.1408  decode.d3.loss_mask: 0.9997  decode.d3.loss_dice: 0.6579  decode.d4.loss_cls: 0.1352  decode.d4.loss_mask: 1.0331  decode.d4.loss_dice: 0.6609  decode.d5.loss_cls: 0.1407  decode.d5.loss_mask: 1.0279  decode.d5.loss_dice: 0.6480  decode.d6.loss_cls: 0.1334  decode.d6.loss_mask: 1.0064  decode.d6.loss_dice: 0.6497  decode.d7.loss_cls: 0.1264  decode.d7.loss_mask: 1.0207  decode.d7.loss_dice: 0.6524  decode.d8.loss_cls: 0.1180  decode.d8.loss_mask: 1.0178  decode.d8.loss_dice: 0.6492
05/27 00:18:37 - mmengine - INFO - Iter(train) [112850/160000]  base_lr: 3.3299e-05 lr: 3.3299e-06  eta: 5:24:40  time: 0.4142  data_time: 0.0098  memory: 5969  grad_norm: 341.3323  loss: 17.9822  decode.loss_cls: 0.1920  decode.loss_mask: 0.8838  decode.loss_dice: 0.6658  decode.d0.loss_cls: 0.6285  decode.d0.loss_mask: 0.8721  decode.d0.loss_dice: 0.6613  decode.d1.loss_cls: 0.1962  decode.d1.loss_mask: 0.8927  decode.d1.loss_dice: 0.6466  decode.d2.loss_cls: 0.2306  decode.d2.loss_mask: 0.8765  decode.d2.loss_dice: 0.6318  decode.d3.loss_cls: 0.2206  decode.d3.loss_mask: 0.8708  decode.d3.loss_dice: 0.6351  decode.d4.loss_cls: 0.1844  decode.d4.loss_mask: 1.0192  decode.d4.loss_dice: 0.6763  decode.d5.loss_cls: 0.2301  decode.d5.loss_mask: 0.9085  decode.d5.loss_dice: 0.6521  decode.d6.loss_cls: 0.1989  decode.d6.loss_mask: 0.8853  decode.d6.loss_dice: 0.6362  decode.d7.loss_cls: 0.1999  decode.d7.loss_mask: 0.8873  decode.d7.loss_dice: 0.6467  decode.d8.loss_cls: 0.2029  decode.d8.loss_mask: 0.8863  decode.d8.loss_dice: 0.6637
05/27 00:18:58 - mmengine - INFO - Iter(train) [112900/160000]  base_lr: 3.3267e-05 lr: 3.3267e-06  eta: 5:24:19  time: 0.4146  data_time: 0.0098  memory: 5975  grad_norm: 279.0355  loss: 15.8830  decode.loss_cls: 0.1361  decode.loss_mask: 0.8267  decode.loss_dice: 0.5658  decode.d0.loss_cls: 0.5833  decode.d0.loss_mask: 0.8138  decode.d0.loss_dice: 0.5660  decode.d1.loss_cls: 0.1531  decode.d1.loss_mask: 0.8208  decode.d1.loss_dice: 0.5848  decode.d2.loss_cls: 0.1569  decode.d2.loss_mask: 0.8233  decode.d2.loss_dice: 0.5725  decode.d3.loss_cls: 0.1577  decode.d3.loss_mask: 0.8132  decode.d3.loss_dice: 0.5575  decode.d4.loss_cls: 0.1083  decode.d4.loss_mask: 0.8254  decode.d4.loss_dice: 0.5982  decode.d5.loss_cls: 0.1471  decode.d5.loss_mask: 0.8286  decode.d5.loss_dice: 0.5803  decode.d6.loss_cls: 0.1529  decode.d6.loss_mask: 0.8171  decode.d6.loss_dice: 0.5829  decode.d7.loss_cls: 0.1429  decode.d7.loss_mask: 0.8113  decode.d7.loss_dice: 0.5833  decode.d8.loss_cls: 0.1441  decode.d8.loss_mask: 0.8385  decode.d8.loss_dice: 0.5907
05/27 00:19:19 - mmengine - INFO - Iter(train) [112950/160000]  base_lr: 3.3235e-05 lr: 3.3235e-06  eta: 5:23:59  time: 0.4149  data_time: 0.0099  memory: 5979  grad_norm: 1140.6975  loss: 19.1608  decode.loss_cls: 0.1406  decode.loss_mask: 1.0236  decode.loss_dice: 0.6592  decode.d0.loss_cls: 0.6818  decode.d0.loss_mask: 0.9837  decode.d0.loss_dice: 0.6605  decode.d1.loss_cls: 0.1790  decode.d1.loss_mask: 1.0819  decode.d1.loss_dice: 0.6652  decode.d2.loss_cls: 0.1647  decode.d2.loss_mask: 1.0136  decode.d2.loss_dice: 0.6669  decode.d3.loss_cls: 0.1976  decode.d3.loss_mask: 1.0369  decode.d3.loss_dice: 0.6569  decode.d4.loss_cls: 0.1715  decode.d4.loss_mask: 1.0772  decode.d4.loss_dice: 0.6855  decode.d5.loss_cls: 0.1451  decode.d5.loss_mask: 1.0450  decode.d5.loss_dice: 0.6748  decode.d6.loss_cls: 0.1430  decode.d6.loss_mask: 1.0704  decode.d6.loss_dice: 0.6834  decode.d7.loss_cls: 0.1992  decode.d7.loss_mask: 1.0041  decode.d7.loss_dice: 0.6419  decode.d8.loss_cls: 0.1453  decode.d8.loss_mask: 1.0239  decode.d8.loss_dice: 0.6384
05/27 00:19:40 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 00:19:40 - mmengine - INFO - Iter(train) [113000/160000]  base_lr: 3.3203e-05 lr: 3.3203e-06  eta: 5:23:38  time: 0.4156  data_time: 0.0099  memory: 5966  grad_norm: 873.0229  loss: 24.6261  decode.loss_cls: 0.2381  decode.loss_mask: 1.2732  decode.loss_dice: 0.8350  decode.d0.loss_cls: 0.6841  decode.d0.loss_mask: 1.3548  decode.d0.loss_dice: 0.8390  decode.d1.loss_cls: 0.3381  decode.d1.loss_mask: 1.3093  decode.d1.loss_dice: 0.8608  decode.d2.loss_cls: 0.2547  decode.d2.loss_mask: 1.3168  decode.d2.loss_dice: 0.8448  decode.d3.loss_cls: 0.2499  decode.d3.loss_mask: 1.3139  decode.d3.loss_dice: 0.8637  decode.d4.loss_cls: 0.2271  decode.d4.loss_mask: 1.2994  decode.d4.loss_dice: 0.8586  decode.d5.loss_cls: 0.2394  decode.d5.loss_mask: 1.3405  decode.d5.loss_dice: 0.8629  decode.d6.loss_cls: 0.2791  decode.d6.loss_mask: 1.2878  decode.d6.loss_dice: 0.8458  decode.d7.loss_cls: 0.2539  decode.d7.loss_mask: 1.2972  decode.d7.loss_dice: 0.8629  decode.d8.loss_cls: 0.2548  decode.d8.loss_mask: 1.2948  decode.d8.loss_dice: 0.8457
05/27 00:20:00 - mmengine - INFO - Iter(train) [113050/160000]  base_lr: 3.3172e-05 lr: 3.3172e-06  eta: 5:23:18  time: 0.4167  data_time: 0.0098  memory: 5968  grad_norm: 464.9715  loss: 16.4440  decode.loss_cls: 0.1640  decode.loss_mask: 0.8592  decode.loss_dice: 0.6243  decode.d0.loss_cls: 0.4926  decode.d0.loss_mask: 0.8226  decode.d0.loss_dice: 0.5888  decode.d1.loss_cls: 0.1804  decode.d1.loss_mask: 0.8374  decode.d1.loss_dice: 0.6009  decode.d2.loss_cls: 0.1740  decode.d2.loss_mask: 0.8163  decode.d2.loss_dice: 0.5826  decode.d3.loss_cls: 0.1581  decode.d3.loss_mask: 0.8393  decode.d3.loss_dice: 0.6326  decode.d4.loss_cls: 0.1665  decode.d4.loss_mask: 0.8310  decode.d4.loss_dice: 0.6189  decode.d5.loss_cls: 0.1448  decode.d5.loss_mask: 0.8444  decode.d5.loss_dice: 0.6187  decode.d6.loss_cls: 0.1398  decode.d6.loss_mask: 0.8458  decode.d6.loss_dice: 0.6043  decode.d7.loss_cls: 0.1466  decode.d7.loss_mask: 0.8636  decode.d7.loss_dice: 0.5954  decode.d8.loss_cls: 0.1415  decode.d8.loss_mask: 0.8774  decode.d8.loss_dice: 0.6325
05/27 00:20:21 - mmengine - INFO - Iter(train) [113100/160000]  base_lr: 3.3140e-05 lr: 3.3140e-06  eta: 5:22:57  time: 0.4148  data_time: 0.0098  memory: 5983  grad_norm: 534.4493  loss: 18.9390  decode.loss_cls: 0.1117  decode.loss_mask: 1.0439  decode.loss_dice: 0.6816  decode.d0.loss_cls: 0.7013  decode.d0.loss_mask: 0.9741  decode.d0.loss_dice: 0.6917  decode.d1.loss_cls: 0.1670  decode.d1.loss_mask: 1.0463  decode.d1.loss_dice: 0.6826  decode.d2.loss_cls: 0.1595  decode.d2.loss_mask: 1.0258  decode.d2.loss_dice: 0.6729  decode.d3.loss_cls: 0.1166  decode.d3.loss_mask: 1.0296  decode.d3.loss_dice: 0.6714  decode.d4.loss_cls: 0.1270  decode.d4.loss_mask: 1.0275  decode.d4.loss_dice: 0.6652  decode.d5.loss_cls: 0.1399  decode.d5.loss_mask: 1.0341  decode.d5.loss_dice: 0.6744  decode.d6.loss_cls: 0.1310  decode.d6.loss_mask: 1.0254  decode.d6.loss_dice: 0.6708  decode.d7.loss_cls: 0.1517  decode.d7.loss_mask: 1.0010  decode.d7.loss_dice: 0.6591  decode.d8.loss_cls: 0.1349  decode.d8.loss_mask: 1.0420  decode.d8.loss_dice: 0.6792
05/27 00:20:42 - mmengine - INFO - Iter(train) [113150/160000]  base_lr: 3.3108e-05 lr: 3.3108e-06  eta: 5:22:36  time: 0.4141  data_time: 0.0099  memory: 5967  grad_norm: 353.7675  loss: 17.7810  decode.loss_cls: 0.1136  decode.loss_mask: 0.9590  decode.loss_dice: 0.6161  decode.d0.loss_cls: 0.5638  decode.d0.loss_mask: 1.0096  decode.d0.loss_dice: 0.6493  decode.d1.loss_cls: 0.1554  decode.d1.loss_mask: 0.9788  decode.d1.loss_dice: 0.6295  decode.d2.loss_cls: 0.1410  decode.d2.loss_mask: 0.9682  decode.d2.loss_dice: 0.6367  decode.d3.loss_cls: 0.1404  decode.d3.loss_mask: 0.9611  decode.d3.loss_dice: 0.6226  decode.d4.loss_cls: 0.1201  decode.d4.loss_mask: 0.9709  decode.d4.loss_dice: 0.6224  decode.d5.loss_cls: 0.1382  decode.d5.loss_mask: 0.9558  decode.d5.loss_dice: 0.6177  decode.d6.loss_cls: 0.1266  decode.d6.loss_mask: 0.9977  decode.d6.loss_dice: 0.6215  decode.d7.loss_cls: 0.1383  decode.d7.loss_mask: 0.9808  decode.d7.loss_dice: 0.6119  decode.d8.loss_cls: 0.1331  decode.d8.loss_mask: 0.9877  decode.d8.loss_dice: 0.6131
05/27 00:21:03 - mmengine - INFO - Iter(train) [113200/160000]  base_lr: 3.3076e-05 lr: 3.3076e-06  eta: 5:22:16  time: 0.4141  data_time: 0.0099  memory: 5974  grad_norm: 630.2133  loss: 20.8037  decode.loss_cls: 0.2349  decode.loss_mask: 1.0638  decode.loss_dice: 0.7045  decode.d0.loss_cls: 0.6315  decode.d0.loss_mask: 1.0616  decode.d0.loss_dice: 0.6862  decode.d1.loss_cls: 0.2304  decode.d1.loss_mask: 1.1136  decode.d1.loss_dice: 0.7101  decode.d2.loss_cls: 0.2091  decode.d2.loss_mask: 1.1748  decode.d2.loss_dice: 0.7418  decode.d3.loss_cls: 0.2738  decode.d3.loss_mask: 1.1175  decode.d3.loss_dice: 0.7213  decode.d4.loss_cls: 0.2420  decode.d4.loss_mask: 1.0821  decode.d4.loss_dice: 0.7231  decode.d5.loss_cls: 0.2383  decode.d5.loss_mask: 1.1002  decode.d5.loss_dice: 0.7116  decode.d6.loss_cls: 0.2707  decode.d6.loss_mask: 1.0828  decode.d6.loss_dice: 0.6984  decode.d7.loss_cls: 0.2238  decode.d7.loss_mask: 1.0582  decode.d7.loss_dice: 0.6864  decode.d8.loss_cls: 0.2353  decode.d8.loss_mask: 1.0683  decode.d8.loss_dice: 0.7076
05/27 00:21:24 - mmengine - INFO - Iter(train) [113250/160000]  base_lr: 3.3044e-05 lr: 3.3044e-06  eta: 5:21:55  time: 0.4150  data_time: 0.0098  memory: 5976  grad_norm: 613.8361  loss: 17.8759  decode.loss_cls: 0.1402  decode.loss_mask: 0.9264  decode.loss_dice: 0.6813  decode.d0.loss_cls: 0.6904  decode.d0.loss_mask: 0.9116  decode.d0.loss_dice: 0.7071  decode.d1.loss_cls: 0.1366  decode.d1.loss_mask: 0.8916  decode.d1.loss_dice: 0.6819  decode.d2.loss_cls: 0.1397  decode.d2.loss_mask: 0.9042  decode.d2.loss_dice: 0.6787  decode.d3.loss_cls: 0.1269  decode.d3.loss_mask: 0.9099  decode.d3.loss_dice: 0.6759  decode.d4.loss_cls: 0.1307  decode.d4.loss_mask: 0.9224  decode.d4.loss_dice: 0.6865  decode.d5.loss_cls: 0.1308  decode.d5.loss_mask: 0.9356  decode.d5.loss_dice: 0.6969  decode.d6.loss_cls: 0.1245  decode.d6.loss_mask: 0.9368  decode.d6.loss_dice: 0.6886  decode.d7.loss_cls: 0.1478  decode.d7.loss_mask: 0.8921  decode.d7.loss_dice: 0.6587  decode.d8.loss_cls: 0.1509  decode.d8.loss_mask: 0.9083  decode.d8.loss_dice: 0.6632
05/27 00:21:44 - mmengine - INFO - Iter(train) [113300/160000]  base_lr: 3.3013e-05 lr: 3.3013e-06  eta: 5:21:35  time: 0.4148  data_time: 0.0098  memory: 5971  grad_norm: 465.2006  loss: 20.1228  decode.loss_cls: 0.2022  decode.loss_mask: 0.9677  decode.loss_dice: 0.7910  decode.d0.loss_cls: 0.6791  decode.d0.loss_mask: 0.8776  decode.d0.loss_dice: 0.8005  decode.d1.loss_cls: 0.2641  decode.d1.loss_mask: 0.9153  decode.d1.loss_dice: 0.7920  decode.d2.loss_cls: 0.2122  decode.d2.loss_mask: 0.9341  decode.d2.loss_dice: 0.8018  decode.d3.loss_cls: 0.2349  decode.d3.loss_mask: 0.9389  decode.d3.loss_dice: 0.7814  decode.d4.loss_cls: 0.2168  decode.d4.loss_mask: 0.9426  decode.d4.loss_dice: 0.7992  decode.d5.loss_cls: 0.2304  decode.d5.loss_mask: 0.9541  decode.d5.loss_dice: 0.7960  decode.d6.loss_cls: 0.2323  decode.d6.loss_mask: 0.9746  decode.d6.loss_dice: 0.8023  decode.d7.loss_cls: 0.2480  decode.d7.loss_mask: 0.9657  decode.d7.loss_dice: 0.8191  decode.d8.loss_cls: 0.2180  decode.d8.loss_mask: 0.9372  decode.d8.loss_dice: 0.7939
05/27 00:22:05 - mmengine - INFO - Iter(train) [113350/160000]  base_lr: 3.2981e-05 lr: 3.2981e-06  eta: 5:21:14  time: 0.4143  data_time: 0.0098  memory: 5969  grad_norm: 522.9437  loss: 16.2013  decode.loss_cls: 0.0883  decode.loss_mask: 0.8952  decode.loss_dice: 0.5942  decode.d0.loss_cls: 0.5902  decode.d0.loss_mask: 0.8841  decode.d0.loss_dice: 0.6237  decode.d1.loss_cls: 0.0851  decode.d1.loss_mask: 0.8944  decode.d1.loss_dice: 0.6013  decode.d2.loss_cls: 0.0785  decode.d2.loss_mask: 0.9011  decode.d2.loss_dice: 0.6220  decode.d3.loss_cls: 0.0815  decode.d3.loss_mask: 0.8894  decode.d3.loss_dice: 0.6107  decode.d4.loss_cls: 0.0740  decode.d4.loss_mask: 0.8828  decode.d4.loss_dice: 0.6016  decode.d5.loss_cls: 0.0594  decode.d5.loss_mask: 0.8378  decode.d5.loss_dice: 0.5964  decode.d6.loss_cls: 0.0702  decode.d6.loss_mask: 0.8924  decode.d6.loss_dice: 0.5994  decode.d7.loss_cls: 0.0855  decode.d7.loss_mask: 0.8862  decode.d7.loss_dice: 0.6033  decode.d8.loss_cls: 0.0792  decode.d8.loss_mask: 0.8898  decode.d8.loss_dice: 0.6036
05/27 00:22:26 - mmengine - INFO - Iter(train) [113400/160000]  base_lr: 3.2949e-05 lr: 3.2949e-06  eta: 5:20:53  time: 0.4142  data_time: 0.0099  memory: 5967  grad_norm: 514.5059  loss: 21.0111  decode.loss_cls: 0.1787  decode.loss_mask: 1.1178  decode.loss_dice: 0.7366  decode.d0.loss_cls: 0.7659  decode.d0.loss_mask: 1.0606  decode.d0.loss_dice: 0.7285  decode.d1.loss_cls: 0.2151  decode.d1.loss_mask: 1.1141  decode.d1.loss_dice: 0.7590  decode.d2.loss_cls: 0.1985  decode.d2.loss_mask: 1.1361  decode.d2.loss_dice: 0.7579  decode.d3.loss_cls: 0.2005  decode.d3.loss_mask: 1.1111  decode.d3.loss_dice: 0.7331  decode.d4.loss_cls: 0.2000  decode.d4.loss_mask: 1.1119  decode.d4.loss_dice: 0.7437  decode.d5.loss_cls: 0.2373  decode.d5.loss_mask: 1.0900  decode.d5.loss_dice: 0.7207  decode.d6.loss_cls: 0.1799  decode.d6.loss_mask: 1.0889  decode.d6.loss_dice: 0.7442  decode.d7.loss_cls: 0.1853  decode.d7.loss_mask: 1.1104  decode.d7.loss_dice: 0.7392  decode.d8.loss_cls: 0.1737  decode.d8.loss_mask: 1.1249  decode.d8.loss_dice: 0.7473
05/27 00:22:47 - mmengine - INFO - Iter(train) [113450/160000]  base_lr: 3.2917e-05 lr: 3.2917e-06  eta: 5:20:33  time: 0.4145  data_time: 0.0099  memory: 5967  grad_norm: 664.2001  loss: 22.5405  decode.loss_cls: 0.2419  decode.loss_mask: 1.1391  decode.loss_dice: 0.8140  decode.d0.loss_cls: 0.7628  decode.d0.loss_mask: 1.1800  decode.d0.loss_dice: 0.8219  decode.d1.loss_cls: 0.2295  decode.d1.loss_mask: 1.1429  decode.d1.loss_dice: 0.8093  decode.d2.loss_cls: 0.2437  decode.d2.loss_mask: 1.1510  decode.d2.loss_dice: 0.8023  decode.d3.loss_cls: 0.2539  decode.d3.loss_mask: 1.1552  decode.d3.loss_dice: 0.8073  decode.d4.loss_cls: 0.1986  decode.d4.loss_mask: 1.1562  decode.d4.loss_dice: 0.8090  decode.d5.loss_cls: 0.2525  decode.d5.loss_mask: 1.1538  decode.d5.loss_dice: 0.8127  decode.d6.loss_cls: 0.2629  decode.d6.loss_mask: 1.1453  decode.d6.loss_dice: 0.8235  decode.d7.loss_cls: 0.2425  decode.d7.loss_mask: 1.1395  decode.d7.loss_dice: 0.8174  decode.d8.loss_cls: 0.2310  decode.d8.loss_mask: 1.1270  decode.d8.loss_dice: 0.8139
05/27 00:23:07 - mmengine - INFO - Iter(train) [113500/160000]  base_lr: 3.2885e-05 lr: 3.2885e-06  eta: 5:20:12  time: 0.4146  data_time: 0.0099  memory: 5966  grad_norm: 376.2711  loss: 19.2854  decode.loss_cls: 0.1483  decode.loss_mask: 1.0285  decode.loss_dice: 0.6865  decode.d0.loss_cls: 0.6157  decode.d0.loss_mask: 0.9995  decode.d0.loss_dice: 0.7324  decode.d1.loss_cls: 0.1344  decode.d1.loss_mask: 1.0682  decode.d1.loss_dice: 0.7193  decode.d2.loss_cls: 0.1390  decode.d2.loss_mask: 1.0407  decode.d2.loss_dice: 0.7175  decode.d3.loss_cls: 0.1097  decode.d3.loss_mask: 1.0325  decode.d3.loss_dice: 0.7177  decode.d4.loss_cls: 0.0929  decode.d4.loss_mask: 1.0603  decode.d4.loss_dice: 0.7162  decode.d5.loss_cls: 0.1143  decode.d5.loss_mask: 1.0574  decode.d5.loss_dice: 0.7181  decode.d6.loss_cls: 0.1321  decode.d6.loss_mask: 1.0425  decode.d6.loss_dice: 0.7170  decode.d7.loss_cls: 0.1124  decode.d7.loss_mask: 1.0502  decode.d7.loss_dice: 0.7178  decode.d8.loss_cls: 0.1083  decode.d8.loss_mask: 1.0412  decode.d8.loss_dice: 0.7148
05/27 00:23:28 - mmengine - INFO - Iter(train) [113550/160000]  base_lr: 3.2853e-05 lr: 3.2853e-06  eta: 5:19:51  time: 0.4149  data_time: 0.0099  memory: 5970  grad_norm: 400.4602  loss: 17.5432  decode.loss_cls: 0.0461  decode.loss_mask: 0.9707  decode.loss_dice: 0.7027  decode.d0.loss_cls: 0.6188  decode.d0.loss_mask: 0.8708  decode.d0.loss_dice: 0.6828  decode.d1.loss_cls: 0.0723  decode.d1.loss_mask: 0.9138  decode.d1.loss_dice: 0.6685  decode.d2.loss_cls: 0.0734  decode.d2.loss_mask: 0.9649  decode.d2.loss_dice: 0.6808  decode.d3.loss_cls: 0.0452  decode.d3.loss_mask: 0.9666  decode.d3.loss_dice: 0.6956  decode.d4.loss_cls: 0.0462  decode.d4.loss_mask: 0.9958  decode.d4.loss_dice: 0.7112  decode.d5.loss_cls: 0.0733  decode.d5.loss_mask: 0.9296  decode.d5.loss_dice: 0.6878  decode.d6.loss_cls: 0.0434  decode.d6.loss_mask: 0.9634  decode.d6.loss_dice: 0.6997  decode.d7.loss_cls: 0.0489  decode.d7.loss_mask: 0.9624  decode.d7.loss_dice: 0.7023  decode.d8.loss_cls: 0.0499  decode.d8.loss_mask: 0.9498  decode.d8.loss_dice: 0.7065
05/27 00:23:49 - mmengine - INFO - Iter(train) [113600/160000]  base_lr: 3.2822e-05 lr: 3.2822e-06  eta: 5:19:31  time: 0.4157  data_time: 0.0101  memory: 5971  grad_norm: 468.2811  loss: 17.5902  decode.loss_cls: 0.3028  decode.loss_mask: 0.7420  decode.loss_dice: 0.6993  decode.d0.loss_cls: 0.8368  decode.d0.loss_mask: 0.7272  decode.d0.loss_dice: 0.6050  decode.d1.loss_cls: 0.2961  decode.d1.loss_mask: 0.7639  decode.d1.loss_dice: 0.6837  decode.d2.loss_cls: 0.2778  decode.d2.loss_mask: 0.7751  decode.d2.loss_dice: 0.6516  decode.d3.loss_cls: 0.2956  decode.d3.loss_mask: 0.7424  decode.d3.loss_dice: 0.6160  decode.d4.loss_cls: 0.3010  decode.d4.loss_mask: 0.7462  decode.d4.loss_dice: 0.6499  decode.d5.loss_cls: 0.3043  decode.d5.loss_mask: 0.7815  decode.d5.loss_dice: 0.6737  decode.d6.loss_cls: 0.3451  decode.d6.loss_mask: 0.7664  decode.d6.loss_dice: 0.6700  decode.d7.loss_cls: 0.3062  decode.d7.loss_mask: 0.7297  decode.d7.loss_dice: 0.6251  decode.d8.loss_cls: 0.3198  decode.d8.loss_mask: 0.7301  decode.d8.loss_dice: 0.6257
05/27 00:24:10 - mmengine - INFO - Iter(train) [113650/160000]  base_lr: 3.2790e-05 lr: 3.2790e-06  eta: 5:19:10  time: 0.4153  data_time: 0.0101  memory: 5975  grad_norm: 650.5870  loss: 18.6566  decode.loss_cls: 0.1458  decode.loss_mask: 1.0300  decode.loss_dice: 0.6267  decode.d0.loss_cls: 0.6820  decode.d0.loss_mask: 0.9602  decode.d0.loss_dice: 0.5951  decode.d1.loss_cls: 0.1555  decode.d1.loss_mask: 1.0367  decode.d1.loss_dice: 0.6517  decode.d2.loss_cls: 0.1439  decode.d2.loss_mask: 1.0170  decode.d2.loss_dice: 0.6358  decode.d3.loss_cls: 0.1459  decode.d3.loss_mask: 1.0500  decode.d3.loss_dice: 0.6560  decode.d4.loss_cls: 0.1280  decode.d4.loss_mask: 1.0684  decode.d4.loss_dice: 0.6586  decode.d5.loss_cls: 0.1262  decode.d5.loss_mask: 1.0401  decode.d5.loss_dice: 0.6360  decode.d6.loss_cls: 0.1663  decode.d6.loss_mask: 1.0091  decode.d6.loss_dice: 0.6416  decode.d7.loss_cls: 0.1337  decode.d7.loss_mask: 1.0440  decode.d7.loss_dice: 0.6507  decode.d8.loss_cls: 0.1599  decode.d8.loss_mask: 1.0265  decode.d8.loss_dice: 0.6353
05/27 00:24:31 - mmengine - INFO - Iter(train) [113700/160000]  base_lr: 3.2758e-05 lr: 3.2758e-06  eta: 5:18:50  time: 0.4171  data_time: 0.0102  memory: 5968  grad_norm: 351.9707  loss: 17.6058  decode.loss_cls: 0.1348  decode.loss_mask: 0.9242  decode.loss_dice: 0.6497  decode.d0.loss_cls: 0.5454  decode.d0.loss_mask: 0.8576  decode.d0.loss_dice: 0.6316  decode.d1.loss_cls: 0.1599  decode.d1.loss_mask: 0.9297  decode.d1.loss_dice: 0.6421  decode.d2.loss_cls: 0.1672  decode.d2.loss_mask: 0.9339  decode.d2.loss_dice: 0.6543  decode.d3.loss_cls: 0.1398  decode.d3.loss_mask: 0.9249  decode.d3.loss_dice: 0.6499  decode.d4.loss_cls: 0.1469  decode.d4.loss_mask: 0.9187  decode.d4.loss_dice: 0.6409  decode.d5.loss_cls: 0.1483  decode.d5.loss_mask: 0.9341  decode.d5.loss_dice: 0.6616  decode.d6.loss_cls: 0.1685  decode.d6.loss_mask: 0.9149  decode.d6.loss_dice: 0.6456  decode.d7.loss_cls: 0.1572  decode.d7.loss_mask: 0.9279  decode.d7.loss_dice: 0.6454  decode.d8.loss_cls: 0.1617  decode.d8.loss_mask: 0.9360  decode.d8.loss_dice: 0.6530
05/27 00:24:51 - mmengine - INFO - Iter(train) [113750/160000]  base_lr: 3.2726e-05 lr: 3.2726e-06  eta: 5:18:29  time: 0.4162  data_time: 0.0100  memory: 5966  grad_norm: 661.0855  loss: 20.2903  decode.loss_cls: 0.1618  decode.loss_mask: 1.0604  decode.loss_dice: 0.7192  decode.d0.loss_cls: 0.6355  decode.d0.loss_mask: 1.0602  decode.d0.loss_dice: 0.7287  decode.d1.loss_cls: 0.1566  decode.d1.loss_mask: 1.1035  decode.d1.loss_dice: 0.7379  decode.d2.loss_cls: 0.1273  decode.d2.loss_mask: 1.1514  decode.d2.loss_dice: 0.7546  decode.d3.loss_cls: 0.1614  decode.d3.loss_mask: 1.0778  decode.d3.loss_dice: 0.7169  decode.d4.loss_cls: 0.1790  decode.d4.loss_mask: 1.0680  decode.d4.loss_dice: 0.7213  decode.d5.loss_cls: 0.1871  decode.d5.loss_mask: 1.0645  decode.d5.loss_dice: 0.7288  decode.d6.loss_cls: 0.1262  decode.d6.loss_mask: 1.1737  decode.d6.loss_dice: 0.7551  decode.d7.loss_cls: 0.1734  decode.d7.loss_mask: 1.0890  decode.d7.loss_dice: 0.7190  decode.d8.loss_cls: 0.1475  decode.d8.loss_mask: 1.0763  decode.d8.loss_dice: 0.7281
05/27 00:25:12 - mmengine - INFO - Iter(train) [113800/160000]  base_lr: 3.2694e-05 lr: 3.2694e-06  eta: 5:18:08  time: 0.4148  data_time: 0.0099  memory: 5979  grad_norm: 275.0470  loss: 16.9284  decode.loss_cls: 0.2989  decode.loss_mask: 0.7034  decode.loss_dice: 0.6296  decode.d0.loss_cls: 0.6438  decode.d0.loss_mask: 0.7330  decode.d0.loss_dice: 0.6373  decode.d1.loss_cls: 0.2975  decode.d1.loss_mask: 0.7209  decode.d1.loss_dice: 0.6420  decode.d2.loss_cls: 0.2899  decode.d2.loss_mask: 0.7287  decode.d2.loss_dice: 0.6243  decode.d3.loss_cls: 0.2829  decode.d3.loss_mask: 0.7195  decode.d3.loss_dice: 0.6320  decode.d4.loss_cls: 0.3262  decode.d4.loss_mask: 0.7560  decode.d4.loss_dice: 0.6372  decode.d5.loss_cls: 0.2993  decode.d5.loss_mask: 0.7235  decode.d5.loss_dice: 0.6383  decode.d6.loss_cls: 0.2996  decode.d6.loss_mask: 0.7328  decode.d6.loss_dice: 0.6446  decode.d7.loss_cls: 0.2900  decode.d7.loss_mask: 0.7214  decode.d7.loss_dice: 0.6383  decode.d8.loss_cls: 0.3136  decode.d8.loss_mask: 0.7084  decode.d8.loss_dice: 0.6156
05/27 00:25:33 - mmengine - INFO - Iter(train) [113850/160000]  base_lr: 3.2662e-05 lr: 3.2662e-06  eta: 5:17:48  time: 0.4152  data_time: 0.0100  memory: 5975  grad_norm: 598.2279  loss: 20.4579  decode.loss_cls: 0.1354  decode.loss_mask: 1.0565  decode.loss_dice: 0.7629  decode.d0.loss_cls: 0.7605  decode.d0.loss_mask: 1.0440  decode.d0.loss_dice: 0.7789  decode.d1.loss_cls: 0.2250  decode.d1.loss_mask: 1.0523  decode.d1.loss_dice: 0.7584  decode.d2.loss_cls: 0.1689  decode.d2.loss_mask: 1.0590  decode.d2.loss_dice: 0.7507  decode.d3.loss_cls: 0.1409  decode.d3.loss_mask: 1.0831  decode.d3.loss_dice: 0.7505  decode.d4.loss_cls: 0.1666  decode.d4.loss_mask: 1.0494  decode.d4.loss_dice: 0.7479  decode.d5.loss_cls: 0.1756  decode.d5.loss_mask: 1.0587  decode.d5.loss_dice: 0.7545  decode.d6.loss_cls: 0.1957  decode.d6.loss_mask: 1.0592  decode.d6.loss_dice: 0.7487  decode.d7.loss_cls: 0.1641  decode.d7.loss_mask: 1.0648  decode.d7.loss_dice: 0.7731  decode.d8.loss_cls: 0.1727  decode.d8.loss_mask: 1.0460  decode.d8.loss_dice: 0.7539
05/27 00:25:54 - mmengine - INFO - Iter(train) [113900/160000]  base_lr: 3.2631e-05 lr: 3.2631e-06  eta: 5:17:27  time: 0.4143  data_time: 0.0099  memory: 5971  grad_norm: 652.8038  loss: 20.9609  decode.loss_cls: 0.2012  decode.loss_mask: 1.1057  decode.loss_dice: 0.7606  decode.d0.loss_cls: 0.7724  decode.d0.loss_mask: 1.0428  decode.d0.loss_dice: 0.7199  decode.d1.loss_cls: 0.2152  decode.d1.loss_mask: 1.0549  decode.d1.loss_dice: 0.7628  decode.d2.loss_cls: 0.2094  decode.d2.loss_mask: 1.0689  decode.d2.loss_dice: 0.7490  decode.d3.loss_cls: 0.1920  decode.d3.loss_mask: 1.0650  decode.d3.loss_dice: 0.7381  decode.d4.loss_cls: 0.1870  decode.d4.loss_mask: 1.0832  decode.d4.loss_dice: 0.7571  decode.d5.loss_cls: 0.1927  decode.d5.loss_mask: 1.1162  decode.d5.loss_dice: 0.7782  decode.d6.loss_cls: 0.1882  decode.d6.loss_mask: 1.1447  decode.d6.loss_dice: 0.7719  decode.d7.loss_cls: 0.2076  decode.d7.loss_mask: 1.0935  decode.d7.loss_dice: 0.7443  decode.d8.loss_cls: 0.2032  decode.d8.loss_mask: 1.0789  decode.d8.loss_dice: 0.7564
05/27 00:26:14 - mmengine - INFO - Iter(train) [113950/160000]  base_lr: 3.2599e-05 lr: 3.2599e-06  eta: 5:17:07  time: 0.4148  data_time: 0.0099  memory: 5975  grad_norm: 570.7758  loss: 21.8418  decode.loss_cls: 0.1766  decode.loss_mask: 1.1352  decode.loss_dice: 0.7974  decode.d0.loss_cls: 0.6484  decode.d0.loss_mask: 1.1185  decode.d0.loss_dice: 0.7859  decode.d1.loss_cls: 0.1609  decode.d1.loss_mask: 1.1610  decode.d1.loss_dice: 0.8036  decode.d2.loss_cls: 0.1892  decode.d2.loss_mask: 1.1386  decode.d2.loss_dice: 0.8015  decode.d3.loss_cls: 0.1507  decode.d3.loss_mask: 1.1542  decode.d3.loss_dice: 0.7937  decode.d4.loss_cls: 0.1661  decode.d4.loss_mask: 1.1915  decode.d4.loss_dice: 0.8200  decode.d5.loss_cls: 0.1651  decode.d5.loss_mask: 1.2059  decode.d5.loss_dice: 0.8331  decode.d6.loss_cls: 0.1903  decode.d6.loss_mask: 1.1872  decode.d6.loss_dice: 0.7863  decode.d7.loss_cls: 0.1799  decode.d7.loss_mask: 1.1337  decode.d7.loss_dice: 0.8082  decode.d8.loss_cls: 0.1664  decode.d8.loss_mask: 1.1615  decode.d8.loss_dice: 0.8312
05/27 00:26:35 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 00:26:35 - mmengine - INFO - Iter(train) [114000/160000]  base_lr: 3.2567e-05 lr: 3.2567e-06  eta: 5:16:46  time: 0.4146  data_time: 0.0099  memory: 5973  grad_norm: 530.6069  loss: 19.4963  decode.loss_cls: 0.1724  decode.loss_mask: 0.9944  decode.loss_dice: 0.7497  decode.d0.loss_cls: 0.6516  decode.d0.loss_mask: 0.9684  decode.d0.loss_dice: 0.7671  decode.d1.loss_cls: 0.1989  decode.d1.loss_mask: 0.9890  decode.d1.loss_dice: 0.7185  decode.d2.loss_cls: 0.1766  decode.d2.loss_mask: 0.9800  decode.d2.loss_dice: 0.7250  decode.d3.loss_cls: 0.1699  decode.d3.loss_mask: 0.9782  decode.d3.loss_dice: 0.7194  decode.d4.loss_cls: 0.2055  decode.d4.loss_mask: 0.9603  decode.d4.loss_dice: 0.7120  decode.d5.loss_cls: 0.1913  decode.d5.loss_mask: 0.9888  decode.d5.loss_dice: 0.7339  decode.d6.loss_cls: 0.2092  decode.d6.loss_mask: 0.9856  decode.d6.loss_dice: 0.7303  decode.d7.loss_cls: 0.2092  decode.d7.loss_mask: 0.9603  decode.d7.loss_dice: 0.7344  decode.d8.loss_cls: 0.1833  decode.d8.loss_mask: 0.9937  decode.d8.loss_dice: 0.7397
05/27 00:26:56 - mmengine - INFO - Iter(train) [114050/160000]  base_lr: 3.2535e-05 lr: 3.2535e-06  eta: 5:16:25  time: 0.4144  data_time: 0.0099  memory: 5976  grad_norm: 697.8764  loss: 21.1487  decode.loss_cls: 0.2260  decode.loss_mask: 1.1157  decode.loss_dice: 0.7547  decode.d0.loss_cls: 0.6644  decode.d0.loss_mask: 1.0360  decode.d0.loss_dice: 0.7414  decode.d1.loss_cls: 0.2972  decode.d1.loss_mask: 1.0657  decode.d1.loss_dice: 0.7338  decode.d2.loss_cls: 0.2566  decode.d2.loss_mask: 1.0578  decode.d2.loss_dice: 0.7428  decode.d3.loss_cls: 0.2942  decode.d3.loss_mask: 1.0691  decode.d3.loss_dice: 0.7249  decode.d4.loss_cls: 0.2978  decode.d4.loss_mask: 1.0516  decode.d4.loss_dice: 0.7026  decode.d5.loss_cls: 0.2720  decode.d5.loss_mask: 1.0669  decode.d5.loss_dice: 0.7296  decode.d6.loss_cls: 0.2354  decode.d6.loss_mask: 1.0572  decode.d6.loss_dice: 0.7390  decode.d7.loss_cls: 0.2266  decode.d7.loss_mask: 1.1172  decode.d7.loss_dice: 0.7662  decode.d8.loss_cls: 0.2280  decode.d8.loss_mask: 1.1138  decode.d8.loss_dice: 0.7646
05/27 00:27:17 - mmengine - INFO - Iter(train) [114100/160000]  base_lr: 3.2503e-05 lr: 3.2503e-06  eta: 5:16:05  time: 0.4158  data_time: 0.0099  memory: 5982  grad_norm: 1094.3272  loss: 20.9020  decode.loss_cls: 0.2260  decode.loss_mask: 1.0668  decode.loss_dice: 0.7117  decode.d0.loss_cls: 0.7230  decode.d0.loss_mask: 1.0534  decode.d0.loss_dice: 0.6595  decode.d1.loss_cls: 0.1688  decode.d1.loss_mask: 1.1597  decode.d1.loss_dice: 0.7544  decode.d2.loss_cls: 0.2105  decode.d2.loss_mask: 1.0926  decode.d2.loss_dice: 0.7309  decode.d3.loss_cls: 0.1724  decode.d3.loss_mask: 1.1416  decode.d3.loss_dice: 0.7450  decode.d4.loss_cls: 0.1708  decode.d4.loss_mask: 1.1679  decode.d4.loss_dice: 0.7456  decode.d5.loss_cls: 0.1642  decode.d5.loss_mask: 1.2088  decode.d5.loss_dice: 0.7640  decode.d6.loss_cls: 0.1849  decode.d6.loss_mask: 1.1500  decode.d6.loss_dice: 0.7467  decode.d7.loss_cls: 0.2375  decode.d7.loss_mask: 1.0564  decode.d7.loss_dice: 0.7114  decode.d8.loss_cls: 0.2500  decode.d8.loss_mask: 1.0355  decode.d8.loss_dice: 0.6917
05/27 00:27:38 - mmengine - INFO - Iter(train) [114150/160000]  base_lr: 3.2471e-05 lr: 3.2471e-06  eta: 5:15:44  time: 0.4162  data_time: 0.0101  memory: 5982  grad_norm: 770.9870  loss: 21.2014  decode.loss_cls: 0.2720  decode.loss_mask: 1.0959  decode.loss_dice: 0.6870  decode.d0.loss_cls: 0.7877  decode.d0.loss_mask: 1.0351  decode.d0.loss_dice: 0.6777  decode.d1.loss_cls: 0.2642  decode.d1.loss_mask: 1.0802  decode.d1.loss_dice: 0.6983  decode.d2.loss_cls: 0.2726  decode.d2.loss_mask: 1.0948  decode.d2.loss_dice: 0.7062  decode.d3.loss_cls: 0.2182  decode.d3.loss_mask: 1.1316  decode.d3.loss_dice: 0.7150  decode.d4.loss_cls: 0.2419  decode.d4.loss_mask: 1.0809  decode.d4.loss_dice: 0.6969  decode.d5.loss_cls: 0.1781  decode.d5.loss_mask: 1.1715  decode.d5.loss_dice: 0.7704  decode.d6.loss_cls: 0.2018  decode.d6.loss_mask: 1.1693  decode.d6.loss_dice: 0.7416  decode.d7.loss_cls: 0.2898  decode.d7.loss_mask: 1.1327  decode.d7.loss_dice: 0.7271  decode.d8.loss_cls: 0.2477  decode.d8.loss_mask: 1.0984  decode.d8.loss_dice: 0.7170
05/27 00:27:58 - mmengine - INFO - Iter(train) [114200/160000]  base_lr: 3.2439e-05 lr: 3.2439e-06  eta: 5:15:23  time: 0.4153  data_time: 0.0100  memory: 5966  grad_norm: 592.8275  loss: 19.1598  decode.loss_cls: 0.1248  decode.loss_mask: 1.0021  decode.loss_dice: 0.7523  decode.d0.loss_cls: 0.5970  decode.d0.loss_mask: 0.9408  decode.d0.loss_dice: 0.7473  decode.d1.loss_cls: 0.1680  decode.d1.loss_mask: 0.9574  decode.d1.loss_dice: 0.7556  decode.d2.loss_cls: 0.1681  decode.d2.loss_mask: 0.9553  decode.d2.loss_dice: 0.7237  decode.d3.loss_cls: 0.1370  decode.d3.loss_mask: 0.9588  decode.d3.loss_dice: 0.7542  decode.d4.loss_cls: 0.1645  decode.d4.loss_mask: 0.9619  decode.d4.loss_dice: 0.7588  decode.d5.loss_cls: 0.1558  decode.d5.loss_mask: 0.9679  decode.d5.loss_dice: 0.7727  decode.d6.loss_cls: 0.1594  decode.d6.loss_mask: 0.9679  decode.d6.loss_dice: 0.7536  decode.d7.loss_cls: 0.1683  decode.d7.loss_mask: 0.9830  decode.d7.loss_dice: 0.7427  decode.d8.loss_cls: 0.1551  decode.d8.loss_mask: 0.9637  decode.d8.loss_dice: 0.7419
05/27 00:28:19 - mmengine - INFO - Iter(train) [114250/160000]  base_lr: 3.2408e-05 lr: 3.2408e-06  eta: 5:15:03  time: 0.4170  data_time: 0.0110  memory: 5971  grad_norm: 417.9476  loss: 16.1873  decode.loss_cls: 0.0798  decode.loss_mask: 0.8923  decode.loss_dice: 0.6087  decode.d0.loss_cls: 0.5881  decode.d0.loss_mask: 0.8213  decode.d0.loss_dice: 0.5285  decode.d1.loss_cls: 0.1114  decode.d1.loss_mask: 0.8701  decode.d1.loss_dice: 0.6014  decode.d2.loss_cls: 0.0930  decode.d2.loss_mask: 0.8809  decode.d2.loss_dice: 0.5975  decode.d3.loss_cls: 0.0609  decode.d3.loss_mask: 0.8925  decode.d3.loss_dice: 0.6148  decode.d4.loss_cls: 0.0960  decode.d4.loss_mask: 0.8742  decode.d4.loss_dice: 0.6004  decode.d5.loss_cls: 0.1043  decode.d5.loss_mask: 0.8780  decode.d5.loss_dice: 0.6067  decode.d6.loss_cls: 0.0813  decode.d6.loss_mask: 0.9062  decode.d6.loss_dice: 0.6204  decode.d7.loss_cls: 0.1150  decode.d7.loss_mask: 0.8867  decode.d7.loss_dice: 0.6013  decode.d8.loss_cls: 0.0651  decode.d8.loss_mask: 0.8921  decode.d8.loss_dice: 0.6184
05/27 00:28:40 - mmengine - INFO - Iter(train) [114300/160000]  base_lr: 3.2376e-05 lr: 3.2376e-06  eta: 5:14:42  time: 0.4147  data_time: 0.0099  memory: 5972  grad_norm: 930.4459  loss: 17.3488  decode.loss_cls: 0.1238  decode.loss_mask: 0.9167  decode.loss_dice: 0.6888  decode.d0.loss_cls: 0.5765  decode.d0.loss_mask: 0.8604  decode.d0.loss_dice: 0.6782  decode.d1.loss_cls: 0.1283  decode.d1.loss_mask: 0.8653  decode.d1.loss_dice: 0.6778  decode.d2.loss_cls: 0.1743  decode.d2.loss_mask: 0.8525  decode.d2.loss_dice: 0.6523  decode.d3.loss_cls: 0.1721  decode.d3.loss_mask: 0.8358  decode.d3.loss_dice: 0.6577  decode.d4.loss_cls: 0.1659  decode.d4.loss_mask: 0.8449  decode.d4.loss_dice: 0.6811  decode.d5.loss_cls: 0.1457  decode.d5.loss_mask: 0.8691  decode.d5.loss_dice: 0.6942  decode.d6.loss_cls: 0.1503  decode.d6.loss_mask: 0.8613  decode.d6.loss_dice: 0.6761  decode.d7.loss_cls: 0.1130  decode.d7.loss_mask: 0.9075  decode.d7.loss_dice: 0.6867  decode.d8.loss_cls: 0.1437  decode.d8.loss_mask: 0.8558  decode.d8.loss_dice: 0.6932
05/27 00:29:01 - mmengine - INFO - Iter(train) [114350/160000]  base_lr: 3.2344e-05 lr: 3.2344e-06  eta: 5:14:22  time: 0.4166  data_time: 0.0099  memory: 5980  grad_norm: 495.0967  loss: 19.7253  decode.loss_cls: 0.2212  decode.loss_mask: 0.9900  decode.loss_dice: 0.7180  decode.d0.loss_cls: 0.7465  decode.d0.loss_mask: 0.9349  decode.d0.loss_dice: 0.6709  decode.d1.loss_cls: 0.2594  decode.d1.loss_mask: 0.9560  decode.d1.loss_dice: 0.7380  decode.d2.loss_cls: 0.2671  decode.d2.loss_mask: 0.9848  decode.d2.loss_dice: 0.7218  decode.d3.loss_cls: 0.2269  decode.d3.loss_mask: 0.9498  decode.d3.loss_dice: 0.6812  decode.d4.loss_cls: 0.2515  decode.d4.loss_mask: 0.9717  decode.d4.loss_dice: 0.7137  decode.d5.loss_cls: 0.2434  decode.d5.loss_mask: 0.9621  decode.d5.loss_dice: 0.7125  decode.d6.loss_cls: 0.2527  decode.d6.loss_mask: 0.9743  decode.d6.loss_dice: 0.7331  decode.d7.loss_cls: 0.2552  decode.d7.loss_mask: 0.9594  decode.d7.loss_dice: 0.7154  decode.d8.loss_cls: 0.2380  decode.d8.loss_mask: 0.9749  decode.d8.loss_dice: 0.7009
05/27 00:29:22 - mmengine - INFO - Iter(train) [114400/160000]  base_lr: 3.2312e-05 lr: 3.2312e-06  eta: 5:14:01  time: 0.4150  data_time: 0.0099  memory: 5986  grad_norm: 434.0179  loss: 18.0323  decode.loss_cls: 0.1252  decode.loss_mask: 0.9675  decode.loss_dice: 0.6784  decode.d0.loss_cls: 0.6086  decode.d0.loss_mask: 0.9370  decode.d0.loss_dice: 0.6504  decode.d1.loss_cls: 0.1233  decode.d1.loss_mask: 0.9561  decode.d1.loss_dice: 0.6921  decode.d2.loss_cls: 0.1139  decode.d2.loss_mask: 0.9706  decode.d2.loss_dice: 0.7013  decode.d3.loss_cls: 0.1185  decode.d3.loss_mask: 0.9619  decode.d3.loss_dice: 0.6779  decode.d4.loss_cls: 0.1424  decode.d4.loss_mask: 0.9583  decode.d4.loss_dice: 0.6542  decode.d5.loss_cls: 0.1069  decode.d5.loss_mask: 0.9690  decode.d5.loss_dice: 0.6749  decode.d6.loss_cls: 0.1179  decode.d6.loss_mask: 0.9590  decode.d6.loss_dice: 0.6702  decode.d7.loss_cls: 0.1166  decode.d7.loss_mask: 0.9506  decode.d7.loss_dice: 0.6674  decode.d8.loss_cls: 0.1130  decode.d8.loss_mask: 0.9679  decode.d8.loss_dice: 0.6810
05/27 00:29:42 - mmengine - INFO - Iter(train) [114450/160000]  base_lr: 3.2280e-05 lr: 3.2280e-06  eta: 5:13:40  time: 0.4148  data_time: 0.0099  memory: 5971  grad_norm: 346.6186  loss: 18.6382  decode.loss_cls: 0.2236  decode.loss_mask: 0.9052  decode.loss_dice: 0.6382  decode.d0.loss_cls: 0.7325  decode.d0.loss_mask: 0.8701  decode.d0.loss_dice: 0.6543  decode.d1.loss_cls: 0.2647  decode.d1.loss_mask: 0.9109  decode.d1.loss_dice: 0.6548  decode.d2.loss_cls: 0.2395  decode.d2.loss_mask: 0.9381  decode.d2.loss_dice: 0.7053  decode.d3.loss_cls: 0.2557  decode.d3.loss_mask: 0.9073  decode.d3.loss_dice: 0.6650  decode.d4.loss_cls: 0.2289  decode.d4.loss_mask: 0.9410  decode.d4.loss_dice: 0.6490  decode.d5.loss_cls: 0.2359  decode.d5.loss_mask: 0.9263  decode.d5.loss_dice: 0.6517  decode.d6.loss_cls: 0.2213  decode.d6.loss_mask: 0.9241  decode.d6.loss_dice: 0.6634  decode.d7.loss_cls: 0.2277  decode.d7.loss_mask: 0.9019  decode.d7.loss_dice: 0.6877  decode.d8.loss_cls: 0.2327  decode.d8.loss_mask: 0.9183  decode.d8.loss_dice: 0.6632
05/27 00:30:03 - mmengine - INFO - Iter(train) [114500/160000]  base_lr: 3.2248e-05 lr: 3.2248e-06  eta: 5:13:20  time: 0.4141  data_time: 0.0098  memory: 5967  grad_norm: 736.8549  loss: 16.0390  decode.loss_cls: 0.1256  decode.loss_mask: 0.8507  decode.loss_dice: 0.5772  decode.d0.loss_cls: 0.6008  decode.d0.loss_mask: 0.8133  decode.d0.loss_dice: 0.5549  decode.d1.loss_cls: 0.1498  decode.d1.loss_mask: 0.8446  decode.d1.loss_dice: 0.5425  decode.d2.loss_cls: 0.1366  decode.d2.loss_mask: 0.8606  decode.d2.loss_dice: 0.5898  decode.d3.loss_cls: 0.1537  decode.d3.loss_mask: 0.8589  decode.d3.loss_dice: 0.6238  decode.d4.loss_cls: 0.1795  decode.d4.loss_mask: 0.8360  decode.d4.loss_dice: 0.5563  decode.d5.loss_cls: 0.1355  decode.d5.loss_mask: 0.8382  decode.d5.loss_dice: 0.5642  decode.d6.loss_cls: 0.1160  decode.d6.loss_mask: 0.8641  decode.d6.loss_dice: 0.6169  decode.d7.loss_cls: 0.1255  decode.d7.loss_mask: 0.8494  decode.d7.loss_dice: 0.5481  decode.d8.loss_cls: 0.1115  decode.d8.loss_mask: 0.8508  decode.d8.loss_dice: 0.5643
05/27 00:30:24 - mmengine - INFO - Iter(train) [114550/160000]  base_lr: 3.2216e-05 lr: 3.2216e-06  eta: 5:12:59  time: 0.4142  data_time: 0.0099  memory: 5969  grad_norm: 596.3139  loss: 20.4726  decode.loss_cls: 0.1946  decode.loss_mask: 1.0281  decode.loss_dice: 0.7159  decode.d0.loss_cls: 0.6306  decode.d0.loss_mask: 1.0551  decode.d0.loss_dice: 0.7562  decode.d1.loss_cls: 0.2192  decode.d1.loss_mask: 1.0509  decode.d1.loss_dice: 0.7132  decode.d2.loss_cls: 0.2178  decode.d2.loss_mask: 1.0373  decode.d2.loss_dice: 0.7465  decode.d3.loss_cls: 0.1828  decode.d3.loss_mask: 1.1080  decode.d3.loss_dice: 0.7713  decode.d4.loss_cls: 0.1870  decode.d4.loss_mask: 1.1059  decode.d4.loss_dice: 0.7783  decode.d5.loss_cls: 0.1937  decode.d5.loss_mask: 1.0766  decode.d5.loss_dice: 0.7845  decode.d6.loss_cls: 0.2073  decode.d6.loss_mask: 1.0309  decode.d6.loss_dice: 0.7355  decode.d7.loss_cls: 0.2083  decode.d7.loss_mask: 1.0581  decode.d7.loss_dice: 0.7515  decode.d8.loss_cls: 0.1939  decode.d8.loss_mask: 1.0203  decode.d8.loss_dice: 0.7134
05/27 00:30:45 - mmengine - INFO - Iter(train) [114600/160000]  base_lr: 3.2184e-05 lr: 3.2184e-06  eta: 5:12:39  time: 0.4150  data_time: 0.0099  memory: 5969  grad_norm: 617.2831  loss: 20.5523  decode.loss_cls: 0.0731  decode.loss_mask: 1.1341  decode.loss_dice: 0.7408  decode.d0.loss_cls: 0.6649  decode.d0.loss_mask: 1.1445  decode.d0.loss_dice: 0.7495  decode.d1.loss_cls: 0.1018  decode.d1.loss_mask: 1.1785  decode.d1.loss_dice: 0.7511  decode.d2.loss_cls: 0.0877  decode.d2.loss_mask: 1.1483  decode.d2.loss_dice: 0.7405  decode.d3.loss_cls: 0.1350  decode.d3.loss_mask: 1.1349  decode.d3.loss_dice: 0.7427  decode.d4.loss_cls: 0.1160  decode.d4.loss_mask: 1.1185  decode.d4.loss_dice: 0.7232  decode.d5.loss_cls: 0.1653  decode.d5.loss_mask: 1.0932  decode.d5.loss_dice: 0.7569  decode.d6.loss_cls: 0.1089  decode.d6.loss_mask: 1.1294  decode.d6.loss_dice: 0.7672  decode.d7.loss_cls: 0.1403  decode.d7.loss_mask: 1.1308  decode.d7.loss_dice: 0.7756  decode.d8.loss_cls: 0.1380  decode.d8.loss_mask: 1.1231  decode.d8.loss_dice: 0.7385
05/27 00:31:05 - mmengine - INFO - Iter(train) [114650/160000]  base_lr: 3.2152e-05 lr: 3.2152e-06  eta: 5:12:18  time: 0.4153  data_time: 0.0098  memory: 5968  grad_norm: 602.3053  loss: 18.7342  decode.loss_cls: 0.0850  decode.loss_mask: 1.0041  decode.loss_dice: 0.7107  decode.d0.loss_cls: 0.5838  decode.d0.loss_mask: 1.0239  decode.d0.loss_dice: 0.7037  decode.d1.loss_cls: 0.1223  decode.d1.loss_mask: 1.0547  decode.d1.loss_dice: 0.7205  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 1.0550  decode.d2.loss_dice: 0.7185  decode.d3.loss_cls: 0.1194  decode.d3.loss_mask: 1.0079  decode.d3.loss_dice: 0.7001  decode.d4.loss_cls: 0.0733  decode.d4.loss_mask: 1.0241  decode.d4.loss_dice: 0.7104  decode.d5.loss_cls: 0.1178  decode.d5.loss_mask: 1.0174  decode.d5.loss_dice: 0.7112  decode.d6.loss_cls: 0.0979  decode.d6.loss_mask: 1.0162  decode.d6.loss_dice: 0.7048  decode.d7.loss_cls: 0.0875  decode.d7.loss_mask: 1.0183  decode.d7.loss_dice: 0.6987  decode.d8.loss_cls: 0.0802  decode.d8.loss_mask: 1.0066  decode.d8.loss_dice: 0.6976
05/27 00:31:26 - mmengine - INFO - Iter(train) [114700/160000]  base_lr: 3.2121e-05 lr: 3.2121e-06  eta: 5:11:57  time: 0.4147  data_time: 0.0099  memory: 5968  grad_norm: 403.0629  loss: 16.0244  decode.loss_cls: 0.1540  decode.loss_mask: 0.8250  decode.loss_dice: 0.5914  decode.d0.loss_cls: 0.6361  decode.d0.loss_mask: 0.7804  decode.d0.loss_dice: 0.5854  decode.d1.loss_cls: 0.1560  decode.d1.loss_mask: 0.8487  decode.d1.loss_dice: 0.6074  decode.d2.loss_cls: 0.1429  decode.d2.loss_mask: 0.8209  decode.d2.loss_dice: 0.6092  decode.d3.loss_cls: 0.1471  decode.d3.loss_mask: 0.8081  decode.d3.loss_dice: 0.6026  decode.d4.loss_cls: 0.1455  decode.d4.loss_mask: 0.7933  decode.d4.loss_dice: 0.6082  decode.d5.loss_cls: 0.1636  decode.d5.loss_mask: 0.7906  decode.d5.loss_dice: 0.6022  decode.d6.loss_cls: 0.1261  decode.d6.loss_mask: 0.8044  decode.d6.loss_dice: 0.6253  decode.d7.loss_cls: 0.1433  decode.d7.loss_mask: 0.7867  decode.d7.loss_dice: 0.5956  decode.d8.loss_cls: 0.1396  decode.d8.loss_mask: 0.7923  decode.d8.loss_dice: 0.5923
05/27 00:31:47 - mmengine - INFO - Iter(train) [114750/160000]  base_lr: 3.2089e-05 lr: 3.2089e-06  eta: 5:11:37  time: 0.4161  data_time: 0.0098  memory: 5971  grad_norm: 469.4142  loss: 21.7791  decode.loss_cls: 0.2083  decode.loss_mask: 1.1174  decode.loss_dice: 0.7600  decode.d0.loss_cls: 0.6996  decode.d0.loss_mask: 1.1145  decode.d0.loss_dice: 0.7719  decode.d1.loss_cls: 0.2213  decode.d1.loss_mask: 1.1244  decode.d1.loss_dice: 0.7843  decode.d2.loss_cls: 0.2245  decode.d2.loss_mask: 1.1127  decode.d2.loss_dice: 0.7796  decode.d3.loss_cls: 0.2129  decode.d3.loss_mask: 1.1134  decode.d3.loss_dice: 0.7793  decode.d4.loss_cls: 0.2221  decode.d4.loss_mask: 1.1435  decode.d4.loss_dice: 0.7877  decode.d5.loss_cls: 0.1757  decode.d5.loss_mask: 1.1466  decode.d5.loss_dice: 0.8228  decode.d6.loss_cls: 0.1906  decode.d6.loss_mask: 1.1632  decode.d6.loss_dice: 0.7928  decode.d7.loss_cls: 0.1860  decode.d7.loss_mask: 1.1423  decode.d7.loss_dice: 0.8303  decode.d8.loss_cls: 0.2172  decode.d8.loss_mask: 1.1568  decode.d8.loss_dice: 0.7772
05/27 00:32:08 - mmengine - INFO - Iter(train) [114800/160000]  base_lr: 3.2057e-05 lr: 3.2057e-06  eta: 5:11:16  time: 0.4151  data_time: 0.0099  memory: 5984  grad_norm: 444.5195  loss: 18.5665  decode.loss_cls: 0.2148  decode.loss_mask: 0.8968  decode.loss_dice: 0.6562  decode.d0.loss_cls: 0.6909  decode.d0.loss_mask: 0.8767  decode.d0.loss_dice: 0.6851  decode.d1.loss_cls: 0.2644  decode.d1.loss_mask: 0.8950  decode.d1.loss_dice: 0.6533  decode.d2.loss_cls: 0.2313  decode.d2.loss_mask: 0.9479  decode.d2.loss_dice: 0.6769  decode.d3.loss_cls: 0.2711  decode.d3.loss_mask: 0.9233  decode.d3.loss_dice: 0.6593  decode.d4.loss_cls: 0.2636  decode.d4.loss_mask: 0.8842  decode.d4.loss_dice: 0.6669  decode.d5.loss_cls: 0.2661  decode.d5.loss_mask: 0.8900  decode.d5.loss_dice: 0.6714  decode.d6.loss_cls: 0.2410  decode.d6.loss_mask: 0.8763  decode.d6.loss_dice: 0.6713  decode.d7.loss_cls: 0.2253  decode.d7.loss_mask: 0.9001  decode.d7.loss_dice: 0.6720  decode.d8.loss_cls: 0.2513  decode.d8.loss_mask: 0.8805  decode.d8.loss_dice: 0.6636
05/27 00:32:29 - mmengine - INFO - Iter(train) [114850/160000]  base_lr: 3.2025e-05 lr: 3.2025e-06  eta: 5:10:55  time: 0.4155  data_time: 0.0099  memory: 5976  grad_norm: 414.9874  loss: 21.0936  decode.loss_cls: 0.2027  decode.loss_mask: 1.1237  decode.loss_dice: 0.7145  decode.d0.loss_cls: 0.6715  decode.d0.loss_mask: 1.1040  decode.d0.loss_dice: 0.7050  decode.d1.loss_cls: 0.2191  decode.d1.loss_mask: 1.1487  decode.d1.loss_dice: 0.7304  decode.d2.loss_cls: 0.2020  decode.d2.loss_mask: 1.1689  decode.d2.loss_dice: 0.7336  decode.d3.loss_cls: 0.2157  decode.d3.loss_mask: 1.1277  decode.d3.loss_dice: 0.7189  decode.d4.loss_cls: 0.2269  decode.d4.loss_mask: 1.1193  decode.d4.loss_dice: 0.7062  decode.d5.loss_cls: 0.2016  decode.d5.loss_mask: 1.1509  decode.d5.loss_dice: 0.7310  decode.d6.loss_cls: 0.2234  decode.d6.loss_mask: 1.1062  decode.d6.loss_dice: 0.7094  decode.d7.loss_cls: 0.2108  decode.d7.loss_mask: 1.1371  decode.d7.loss_dice: 0.7158  decode.d8.loss_cls: 0.2044  decode.d8.loss_mask: 1.1333  decode.d8.loss_dice: 0.7306
05/27 00:32:49 - mmengine - INFO - Iter(train) [114900/160000]  base_lr: 3.1993e-05 lr: 3.1993e-06  eta: 5:10:35  time: 0.4159  data_time: 0.0099  memory: 5975  grad_norm: 396.6989  loss: 22.4656  decode.loss_cls: 0.2609  decode.loss_mask: 1.1316  decode.loss_dice: 0.7652  decode.d0.loss_cls: 0.7952  decode.d0.loss_mask: 1.1112  decode.d0.loss_dice: 0.7538  decode.d1.loss_cls: 0.2404  decode.d1.loss_mask: 1.1651  decode.d1.loss_dice: 0.7904  decode.d2.loss_cls: 0.2374  decode.d2.loss_mask: 1.1867  decode.d2.loss_dice: 0.7802  decode.d3.loss_cls: 0.2351  decode.d3.loss_mask: 1.1874  decode.d3.loss_dice: 0.7853  decode.d4.loss_cls: 0.2362  decode.d4.loss_mask: 1.1809  decode.d4.loss_dice: 0.7885  decode.d5.loss_cls: 0.2449  decode.d5.loss_mask: 1.1530  decode.d5.loss_dice: 0.7558  decode.d6.loss_cls: 0.2516  decode.d6.loss_mask: 1.1559  decode.d6.loss_dice: 0.7921  decode.d7.loss_cls: 0.2788  decode.d7.loss_mask: 1.1843  decode.d7.loss_dice: 0.8029  decode.d8.loss_cls: 0.2724  decode.d8.loss_mask: 1.1657  decode.d8.loss_dice: 0.7765
05/27 00:33:10 - mmengine - INFO - Iter(train) [114950/160000]  base_lr: 3.1961e-05 lr: 3.1961e-06  eta: 5:10:14  time: 0.4158  data_time: 0.0101  memory: 5980  grad_norm: 710.2902  loss: 18.5532  decode.loss_cls: 0.2219  decode.loss_mask: 0.9229  decode.loss_dice: 0.6760  decode.d0.loss_cls: 0.6354  decode.d0.loss_mask: 0.8498  decode.d0.loss_dice: 0.6937  decode.d1.loss_cls: 0.2435  decode.d1.loss_mask: 0.8876  decode.d1.loss_dice: 0.7015  decode.d2.loss_cls: 0.2113  decode.d2.loss_mask: 0.9097  decode.d2.loss_dice: 0.7039  decode.d3.loss_cls: 0.2139  decode.d3.loss_mask: 0.8980  decode.d3.loss_dice: 0.6960  decode.d4.loss_cls: 0.2436  decode.d4.loss_mask: 0.9112  decode.d4.loss_dice: 0.6894  decode.d5.loss_cls: 0.2157  decode.d5.loss_mask: 0.9023  decode.d5.loss_dice: 0.6851  decode.d6.loss_cls: 0.2157  decode.d6.loss_mask: 0.8822  decode.d6.loss_dice: 0.7004  decode.d7.loss_cls: 0.2135  decode.d7.loss_mask: 0.9060  decode.d7.loss_dice: 0.7160  decode.d8.loss_cls: 0.2218  decode.d8.loss_mask: 0.8948  decode.d8.loss_dice: 0.6905
05/27 00:33:31 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 00:33:31 - mmengine - INFO - Iter(train) [115000/160000]  base_lr: 3.1929e-05 lr: 3.1929e-06  eta: 5:09:54  time: 0.4158  data_time: 0.0099  memory: 5983  grad_norm: 1490.6259  loss: 18.9271  decode.loss_cls: 0.1545  decode.loss_mask: 1.0103  decode.loss_dice: 0.6819  decode.d0.loss_cls: 0.6112  decode.d0.loss_mask: 1.0474  decode.d0.loss_dice: 0.7136  decode.d1.loss_cls: 0.1366  decode.d1.loss_mask: 1.0068  decode.d1.loss_dice: 0.6845  decode.d2.loss_cls: 0.1257  decode.d2.loss_mask: 1.0020  decode.d2.loss_dice: 0.7002  decode.d3.loss_cls: 0.1201  decode.d3.loss_mask: 1.0073  decode.d3.loss_dice: 0.6972  decode.d4.loss_cls: 0.1394  decode.d4.loss_mask: 1.0421  decode.d4.loss_dice: 0.7136  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 1.0308  decode.d5.loss_dice: 0.7060  decode.d6.loss_cls: 0.1488  decode.d6.loss_mask: 0.9903  decode.d6.loss_dice: 0.6840  decode.d7.loss_cls: 0.1283  decode.d7.loss_mask: 1.0097  decode.d7.loss_dice: 0.6911  decode.d8.loss_cls: 0.1307  decode.d8.loss_mask: 1.0139  decode.d8.loss_dice: 0.6897
05/27 00:33:31 - mmengine - INFO - Saving checkpoint at 115000 iterations
05/27 00:33:35 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:08  time: 0.0482  data_time: 0.0012  memory: 1391  
05/27 00:33:38 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:04  time: 0.0475  data_time: 0.0012  memory: 1205  
05/27 00:33:40 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:03  time: 0.0504  data_time: 0.0013  memory: 1596  
05/27 00:33:43 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0483  data_time: 0.0012  memory: 1298  
05/27 00:33:45 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:57  time: 0.0476  data_time: 0.0013  memory: 1298  
05/27 00:33:47 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0478  data_time: 0.0012  memory: 1279  
05/27 00:33:50 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:53  time: 0.0480  data_time: 0.0012  memory: 1224  
05/27 00:33:52 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0488  data_time: 0.0012  memory: 1298  
05/27 00:33:55 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0475  data_time: 0.0013  memory: 1298  
05/27 00:33:57 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0523  data_time: 0.0013  memory: 1725  
05/27 00:34:00 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0479  data_time: 0.0012  memory: 1336  
05/27 00:34:02 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0481  data_time: 0.0013  memory: 1298  
05/27 00:34:04 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0485  data_time: 0.0012  memory: 1205  
05/27 00:34:07 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0501  data_time: 0.0013  memory: 1316  
05/27 00:34:09 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0477  data_time: 0.0012  memory: 1279  
05/27 00:34:12 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0512  data_time: 0.0012  memory: 1410  
05/27 00:34:14 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0477  data_time: 0.0013  memory: 1279  
05/27 00:34:16 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0485  data_time: 0.0013  memory: 1205  
05/27 00:34:19 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0485  data_time: 0.0012  memory: 1205  
05/27 00:34:21 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0477  data_time: 0.0012  memory: 1336  
05/27 00:34:24 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0479  data_time: 0.0012  memory: 1246  
05/27 00:34:26 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0500  data_time: 0.0012  memory: 1503  
05/27 00:34:29 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0477  data_time: 0.0012  memory: 1261  
05/27 00:34:31 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0485  data_time: 0.0012  memory: 1298  
05/27 00:34:33 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0477  data_time: 0.0013  memory: 1447  
05/27 00:34:36 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0477  data_time: 0.0012  memory: 1298  
05/27 00:34:38 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0491  data_time: 0.0012  memory: 1279  
05/27 00:34:41 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0478  data_time: 0.0012  memory: 1205  
05/27 00:34:43 - mmengine - INFO - per class results:
05/27 00:34:43 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.68 | 97.81 |
|  aeroplane  | 92.56 | 96.05 |
|   bicycle   | 44.32 | 95.72 |
|     bird    |  94.0 | 95.91 |
|     boat    | 60.66 | 90.44 |
|    bottle   | 84.54 | 90.74 |
|     bus     | 95.28 |  98.0 |
|     car     | 92.44 | 95.33 |
|     cat     | 93.88 | 96.14 |
|    chair    | 44.03 | 57.29 |
|     cow     | 84.01 |  88.0 |
| diningtable | 66.39 | 72.62 |
|     dog     | 91.29 | 97.86 |
|    horse    | 89.21 | 96.62 |
|  motorbike  | 90.15 | 93.85 |
|    person   | 91.52 | 94.81 |
| pottedplant | 73.86 | 87.63 |
|    sheep    | 80.26 | 92.11 |
|     sofa    | 56.87 | 68.55 |
|    train    | 93.36 | 95.92 |
|  tvmonitor  |  84.7 | 85.67 |
+-------------+-------+-------+
05/27 00:34:43 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 96.0000  mIoU: 80.9100  mAcc: 89.8600  data_time: 0.0013  time: 0.0481
05/27 00:35:04 - mmengine - INFO - Iter(train) [115050/160000]  base_lr: 3.1897e-05 lr: 3.1897e-06  eta: 5:09:33  time: 0.4148  data_time: 0.0098  memory: 5967  grad_norm: 481.7648  loss: 18.4926  decode.loss_cls: 0.2296  decode.loss_mask: 0.8524  decode.loss_dice: 0.6475  decode.d0.loss_cls: 0.6693  decode.d0.loss_mask: 0.9235  decode.d0.loss_dice: 0.6694  decode.d1.loss_cls: 0.2341  decode.d1.loss_mask: 0.9419  decode.d1.loss_dice: 0.6932  decode.d2.loss_cls: 0.2153  decode.d2.loss_mask: 0.9377  decode.d2.loss_dice: 0.6779  decode.d3.loss_cls: 0.2309  decode.d3.loss_mask: 0.8704  decode.d3.loss_dice: 0.6577  decode.d4.loss_cls: 0.2460  decode.d4.loss_mask: 0.9565  decode.d4.loss_dice: 0.6722  decode.d5.loss_cls: 0.2044  decode.d5.loss_mask: 0.9239  decode.d5.loss_dice: 0.6760  decode.d6.loss_cls: 0.1852  decode.d6.loss_mask: 0.9454  decode.d6.loss_dice: 0.6951  decode.d7.loss_cls: 0.2027  decode.d7.loss_mask: 0.9828  decode.d7.loss_dice: 0.6610  decode.d8.loss_cls: 0.1864  decode.d8.loss_mask: 0.8532  decode.d8.loss_dice: 0.6509
05/27 00:35:25 - mmengine - INFO - Iter(train) [115100/160000]  base_lr: 3.1865e-05 lr: 3.1865e-06  eta: 5:09:12  time: 0.4157  data_time: 0.0098  memory: 5975  grad_norm: 619.4154  loss: 20.6840  decode.loss_cls: 0.1791  decode.loss_mask: 1.0896  decode.loss_dice: 0.7570  decode.d0.loss_cls: 0.7774  decode.d0.loss_mask: 1.0405  decode.d0.loss_dice: 0.7153  decode.d1.loss_cls: 0.2398  decode.d1.loss_mask: 1.0277  decode.d1.loss_dice: 0.7135  decode.d2.loss_cls: 0.2141  decode.d2.loss_mask: 1.0869  decode.d2.loss_dice: 0.7375  decode.d3.loss_cls: 0.1478  decode.d3.loss_mask: 1.1190  decode.d3.loss_dice: 0.7350  decode.d4.loss_cls: 0.1642  decode.d4.loss_mask: 1.0660  decode.d4.loss_dice: 0.7218  decode.d5.loss_cls: 0.2010  decode.d5.loss_mask: 1.0389  decode.d5.loss_dice: 0.7206  decode.d6.loss_cls: 0.1886  decode.d6.loss_mask: 1.1482  decode.d6.loss_dice: 0.7598  decode.d7.loss_cls: 0.2297  decode.d7.loss_mask: 1.1472  decode.d7.loss_dice: 0.7699  decode.d8.loss_cls: 0.1748  decode.d8.loss_mask: 1.0476  decode.d8.loss_dice: 0.7255
05/27 00:35:45 - mmengine - INFO - Iter(train) [115150/160000]  base_lr: 3.1833e-05 lr: 3.1833e-06  eta: 5:08:52  time: 0.4169  data_time: 0.0099  memory: 5969  grad_norm: 392.6341  loss: 17.5883  decode.loss_cls: 0.2100  decode.loss_mask: 0.8251  decode.loss_dice: 0.6496  decode.d0.loss_cls: 0.6576  decode.d0.loss_mask: 0.8095  decode.d0.loss_dice: 0.6818  decode.d1.loss_cls: 0.2694  decode.d1.loss_mask: 0.8080  decode.d1.loss_dice: 0.6652  decode.d2.loss_cls: 0.2142  decode.d2.loss_mask: 0.8130  decode.d2.loss_dice: 0.6725  decode.d3.loss_cls: 0.2277  decode.d3.loss_mask: 0.8153  decode.d3.loss_dice: 0.6639  decode.d4.loss_cls: 0.2091  decode.d4.loss_mask: 0.8258  decode.d4.loss_dice: 0.6583  decode.d5.loss_cls: 0.2196  decode.d5.loss_mask: 0.8190  decode.d5.loss_dice: 0.6637  decode.d6.loss_cls: 0.2353  decode.d6.loss_mask: 0.8223  decode.d6.loss_dice: 0.6733  decode.d7.loss_cls: 0.2486  decode.d7.loss_mask: 0.8244  decode.d7.loss_dice: 0.6792  decode.d8.loss_cls: 0.2320  decode.d8.loss_mask: 0.8281  decode.d8.loss_dice: 0.6669
05/27 00:36:06 - mmengine - INFO - Iter(train) [115200/160000]  base_lr: 3.1801e-05 lr: 3.1801e-06  eta: 5:08:31  time: 0.4157  data_time: 0.0098  memory: 5994  grad_norm: 624.8831  loss: 19.6645  decode.loss_cls: 0.2251  decode.loss_mask: 1.0058  decode.loss_dice: 0.6657  decode.d0.loss_cls: 0.6652  decode.d0.loss_mask: 0.9901  decode.d0.loss_dice: 0.6860  decode.d1.loss_cls: 0.2216  decode.d1.loss_mask: 0.9836  decode.d1.loss_dice: 0.6786  decode.d2.loss_cls: 0.2153  decode.d2.loss_mask: 0.9823  decode.d2.loss_dice: 0.7039  decode.d3.loss_cls: 0.2489  decode.d3.loss_mask: 1.0120  decode.d3.loss_dice: 0.7050  decode.d4.loss_cls: 0.1951  decode.d4.loss_mask: 1.0145  decode.d4.loss_dice: 0.7009  decode.d5.loss_cls: 0.2010  decode.d5.loss_mask: 1.0095  decode.d5.loss_dice: 0.7054  decode.d6.loss_cls: 0.2420  decode.d6.loss_mask: 1.0018  decode.d6.loss_dice: 0.7074  decode.d7.loss_cls: 0.2113  decode.d7.loss_mask: 1.0493  decode.d7.loss_dice: 0.7135  decode.d8.loss_cls: 0.1930  decode.d8.loss_mask: 1.0457  decode.d8.loss_dice: 0.6852
05/27 00:36:27 - mmengine - INFO - Iter(train) [115250/160000]  base_lr: 3.1769e-05 lr: 3.1769e-06  eta: 5:08:11  time: 0.4170  data_time: 0.0098  memory: 5973  grad_norm: 460.1929  loss: 17.2709  decode.loss_cls: 0.1571  decode.loss_mask: 0.8718  decode.loss_dice: 0.6393  decode.d0.loss_cls: 0.6361  decode.d0.loss_mask: 0.8252  decode.d0.loss_dice: 0.6061  decode.d1.loss_cls: 0.1580  decode.d1.loss_mask: 0.8872  decode.d1.loss_dice: 0.6888  decode.d2.loss_cls: 0.1589  decode.d2.loss_mask: 0.8819  decode.d2.loss_dice: 0.6528  decode.d3.loss_cls: 0.1778  decode.d3.loss_mask: 0.8851  decode.d3.loss_dice: 0.6561  decode.d4.loss_cls: 0.1258  decode.d4.loss_mask: 0.8785  decode.d4.loss_dice: 0.6560  decode.d5.loss_cls: 0.1276  decode.d5.loss_mask: 0.8702  decode.d5.loss_dice: 0.6499  decode.d6.loss_cls: 0.1732  decode.d6.loss_mask: 0.8666  decode.d6.loss_dice: 0.6492  decode.d7.loss_cls: 0.1606  decode.d7.loss_mask: 0.8825  decode.d7.loss_dice: 0.6598  decode.d8.loss_cls: 0.1541  decode.d8.loss_mask: 0.8815  decode.d8.loss_dice: 0.6528
05/27 00:36:48 - mmengine - INFO - Iter(train) [115300/160000]  base_lr: 3.1737e-05 lr: 3.1737e-06  eta: 5:07:50  time: 0.4164  data_time: 0.0099  memory: 5966  grad_norm: 553.6618  loss: 21.6221  decode.loss_cls: 0.2372  decode.loss_mask: 1.0831  decode.loss_dice: 0.7627  decode.d0.loss_cls: 0.6987  decode.d0.loss_mask: 1.1059  decode.d0.loss_dice: 0.8083  decode.d1.loss_cls: 0.2501  decode.d1.loss_mask: 1.1293  decode.d1.loss_dice: 0.7997  decode.d2.loss_cls: 0.2606  decode.d2.loss_mask: 1.0813  decode.d2.loss_dice: 0.7996  decode.d3.loss_cls: 0.2224  decode.d3.loss_mask: 1.0852  decode.d3.loss_dice: 0.7649  decode.d4.loss_cls: 0.2505  decode.d4.loss_mask: 1.0781  decode.d4.loss_dice: 0.7682  decode.d5.loss_cls: 0.2487  decode.d5.loss_mask: 1.0872  decode.d5.loss_dice: 0.7514  decode.d6.loss_cls: 0.2321  decode.d6.loss_mask: 1.0841  decode.d6.loss_dice: 0.7739  decode.d7.loss_cls: 0.2335  decode.d7.loss_mask: 1.0982  decode.d7.loss_dice: 0.8211  decode.d8.loss_cls: 0.2320  decode.d8.loss_mask: 1.1009  decode.d8.loss_dice: 0.7732
05/27 00:37:09 - mmengine - INFO - Iter(train) [115350/160000]  base_lr: 3.1705e-05 lr: 3.1705e-06  eta: 5:07:29  time: 0.4178  data_time: 0.0101  memory: 5968  grad_norm: 557.8481  loss: 21.0229  decode.loss_cls: 0.1795  decode.loss_mask: 1.1133  decode.loss_dice: 0.7969  decode.d0.loss_cls: 0.6690  decode.d0.loss_mask: 1.0431  decode.d0.loss_dice: 0.7418  decode.d1.loss_cls: 0.1949  decode.d1.loss_mask: 1.0767  decode.d1.loss_dice: 0.7584  decode.d2.loss_cls: 0.2687  decode.d2.loss_mask: 1.1038  decode.d2.loss_dice: 0.7563  decode.d3.loss_cls: 0.2199  decode.d3.loss_mask: 1.0657  decode.d3.loss_dice: 0.7241  decode.d4.loss_cls: 0.1830  decode.d4.loss_mask: 1.0844  decode.d4.loss_dice: 0.7862  decode.d5.loss_cls: 0.1879  decode.d5.loss_mask: 1.0939  decode.d5.loss_dice: 0.7776  decode.d6.loss_cls: 0.1861  decode.d6.loss_mask: 1.0867  decode.d6.loss_dice: 0.7780  decode.d7.loss_cls: 0.2222  decode.d7.loss_mask: 1.0989  decode.d7.loss_dice: 0.7720  decode.d8.loss_cls: 0.2153  decode.d8.loss_mask: 1.0955  decode.d8.loss_dice: 0.7432
05/27 00:37:30 - mmengine - INFO - Iter(train) [115400/160000]  base_lr: 3.1673e-05 lr: 3.1673e-06  eta: 5:07:09  time: 0.4189  data_time: 0.0102  memory: 5971  grad_norm: 354.8431  loss: 16.3271  decode.loss_cls: 0.1346  decode.loss_mask: 0.8622  decode.loss_dice: 0.5984  decode.d0.loss_cls: 0.6456  decode.d0.loss_mask: 0.8233  decode.d0.loss_dice: 0.5721  decode.d1.loss_cls: 0.1733  decode.d1.loss_mask: 0.8509  decode.d1.loss_dice: 0.5978  decode.d2.loss_cls: 0.1491  decode.d2.loss_mask: 0.8470  decode.d2.loss_dice: 0.5891  decode.d3.loss_cls: 0.1230  decode.d3.loss_mask: 0.8449  decode.d3.loss_dice: 0.5963  decode.d4.loss_cls: 0.1475  decode.d4.loss_mask: 0.8695  decode.d4.loss_dice: 0.5925  decode.d5.loss_cls: 0.1335  decode.d5.loss_mask: 0.8556  decode.d5.loss_dice: 0.5945  decode.d6.loss_cls: 0.1364  decode.d6.loss_mask: 0.8473  decode.d6.loss_dice: 0.6028  decode.d7.loss_cls: 0.1048  decode.d7.loss_mask: 0.8474  decode.d7.loss_dice: 0.6067  decode.d8.loss_cls: 0.1334  decode.d8.loss_mask: 0.8553  decode.d8.loss_dice: 0.5924
05/27 00:37:51 - mmengine - INFO - Iter(train) [115450/160000]  base_lr: 3.1642e-05 lr: 3.1642e-06  eta: 5:06:48  time: 0.4170  data_time: 0.0103  memory: 5970  grad_norm: 394.9705  loss: 16.6843  decode.loss_cls: 0.1407  decode.loss_mask: 0.8387  decode.loss_dice: 0.6094  decode.d0.loss_cls: 0.6084  decode.d0.loss_mask: 0.8183  decode.d0.loss_dice: 0.6383  decode.d1.loss_cls: 0.1495  decode.d1.loss_mask: 0.8525  decode.d1.loss_dice: 0.6379  decode.d2.loss_cls: 0.1626  decode.d2.loss_mask: 0.8401  decode.d2.loss_dice: 0.6460  decode.d3.loss_cls: 0.1672  decode.d3.loss_mask: 0.8351  decode.d3.loss_dice: 0.6297  decode.d4.loss_cls: 0.1590  decode.d4.loss_mask: 0.8290  decode.d4.loss_dice: 0.6372  decode.d5.loss_cls: 0.1614  decode.d5.loss_mask: 0.8489  decode.d5.loss_dice: 0.6261  decode.d6.loss_cls: 0.1369  decode.d6.loss_mask: 0.8423  decode.d6.loss_dice: 0.6353  decode.d7.loss_cls: 0.1597  decode.d7.loss_mask: 0.8245  decode.d7.loss_dice: 0.6289  decode.d8.loss_cls: 0.1494  decode.d8.loss_mask: 0.8399  decode.d8.loss_dice: 0.6313
05/27 00:38:12 - mmengine - INFO - Iter(train) [115500/160000]  base_lr: 3.1610e-05 lr: 3.1610e-06  eta: 5:06:28  time: 0.4146  data_time: 0.0101  memory: 5971  grad_norm: 904.1473  loss: 18.9924  decode.loss_cls: 0.1655  decode.loss_mask: 0.9933  decode.loss_dice: 0.6672  decode.d0.loss_cls: 0.6566  decode.d0.loss_mask: 1.0324  decode.d0.loss_dice: 0.6549  decode.d1.loss_cls: 0.1567  decode.d1.loss_mask: 1.0357  decode.d1.loss_dice: 0.6823  decode.d2.loss_cls: 0.1450  decode.d2.loss_mask: 1.0263  decode.d2.loss_dice: 0.6639  decode.d3.loss_cls: 0.1702  decode.d3.loss_mask: 1.0220  decode.d3.loss_dice: 0.6511  decode.d4.loss_cls: 0.1862  decode.d4.loss_mask: 1.0099  decode.d4.loss_dice: 0.6556  decode.d5.loss_cls: 0.1761  decode.d5.loss_mask: 1.0348  decode.d5.loss_dice: 0.6602  decode.d6.loss_cls: 0.1910  decode.d6.loss_mask: 1.0143  decode.d6.loss_dice: 0.6502  decode.d7.loss_cls: 0.1543  decode.d7.loss_mask: 1.0305  decode.d7.loss_dice: 0.6382  decode.d8.loss_cls: 0.1887  decode.d8.loss_mask: 1.0151  decode.d8.loss_dice: 0.6643
05/27 00:38:33 - mmengine - INFO - Iter(train) [115550/160000]  base_lr: 3.1578e-05 lr: 3.1578e-06  eta: 5:06:07  time: 0.4148  data_time: 0.0099  memory: 5976  grad_norm: 693.2605  loss: 18.7863  decode.loss_cls: 0.2137  decode.loss_mask: 0.9424  decode.loss_dice: 0.6703  decode.d0.loss_cls: 0.6130  decode.d0.loss_mask: 0.9686  decode.d0.loss_dice: 0.6606  decode.d1.loss_cls: 0.2066  decode.d1.loss_mask: 0.9578  decode.d1.loss_dice: 0.6776  decode.d2.loss_cls: 0.2202  decode.d2.loss_mask: 0.9746  decode.d2.loss_dice: 0.6706  decode.d3.loss_cls: 0.2432  decode.d3.loss_mask: 0.9443  decode.d3.loss_dice: 0.6518  decode.d4.loss_cls: 0.2057  decode.d4.loss_mask: 0.9592  decode.d4.loss_dice: 0.6889  decode.d5.loss_cls: 0.1860  decode.d5.loss_mask: 0.9466  decode.d5.loss_dice: 0.6726  decode.d6.loss_cls: 0.2374  decode.d6.loss_mask: 0.9569  decode.d6.loss_dice: 0.6734  decode.d7.loss_cls: 0.1918  decode.d7.loss_mask: 0.9679  decode.d7.loss_dice: 0.6756  decode.d8.loss_cls: 0.1964  decode.d8.loss_mask: 0.9521  decode.d8.loss_dice: 0.6603
05/27 00:38:53 - mmengine - INFO - Iter(train) [115600/160000]  base_lr: 3.1546e-05 lr: 3.1546e-06  eta: 5:05:47  time: 0.4149  data_time: 0.0099  memory: 5980  grad_norm: 723.1973  loss: 20.1446  decode.loss_cls: 0.1748  decode.loss_mask: 1.0443  decode.loss_dice: 0.7201  decode.d0.loss_cls: 0.7199  decode.d0.loss_mask: 1.0299  decode.d0.loss_dice: 0.7020  decode.d1.loss_cls: 0.1538  decode.d1.loss_mask: 1.0680  decode.d1.loss_dice: 0.7551  decode.d2.loss_cls: 0.1695  decode.d2.loss_mask: 1.0543  decode.d2.loss_dice: 0.7224  decode.d3.loss_cls: 0.1808  decode.d3.loss_mask: 1.0296  decode.d3.loss_dice: 0.7346  decode.d4.loss_cls: 0.2053  decode.d4.loss_mask: 1.0475  decode.d4.loss_dice: 0.7428  decode.d5.loss_cls: 0.1736  decode.d5.loss_mask: 1.0827  decode.d5.loss_dice: 0.7490  decode.d6.loss_cls: 0.1747  decode.d6.loss_mask: 1.0597  decode.d6.loss_dice: 0.7102  decode.d7.loss_cls: 0.2120  decode.d7.loss_mask: 1.0210  decode.d7.loss_dice: 0.7231  decode.d8.loss_cls: 0.1877  decode.d8.loss_mask: 1.0538  decode.d8.loss_dice: 0.7424
05/27 00:39:14 - mmengine - INFO - Iter(train) [115650/160000]  base_lr: 3.1514e-05 lr: 3.1514e-06  eta: 5:05:26  time: 0.4138  data_time: 0.0098  memory: 5971  grad_norm: 438.4883  loss: 21.0435  decode.loss_cls: 0.0853  decode.loss_mask: 1.2499  decode.loss_dice: 0.7449  decode.d0.loss_cls: 0.5917  decode.d0.loss_mask: 1.1707  decode.d0.loss_dice: 0.7250  decode.d1.loss_cls: 0.0906  decode.d1.loss_mask: 1.2659  decode.d1.loss_dice: 0.7428  decode.d2.loss_cls: 0.1014  decode.d2.loss_mask: 1.2492  decode.d2.loss_dice: 0.7326  decode.d3.loss_cls: 0.0895  decode.d3.loss_mask: 1.2281  decode.d3.loss_dice: 0.7230  decode.d4.loss_cls: 0.0850  decode.d4.loss_mask: 1.2304  decode.d4.loss_dice: 0.7305  decode.d5.loss_cls: 0.1149  decode.d5.loss_mask: 1.1875  decode.d5.loss_dice: 0.7238  decode.d6.loss_cls: 0.1125  decode.d6.loss_mask: 1.2348  decode.d6.loss_dice: 0.7407  decode.d7.loss_cls: 0.1080  decode.d7.loss_mask: 1.2159  decode.d7.loss_dice: 0.7317  decode.d8.loss_cls: 0.0791  decode.d8.loss_mask: 1.2275  decode.d8.loss_dice: 0.7307
05/27 00:39:35 - mmengine - INFO - Iter(train) [115700/160000]  base_lr: 3.1482e-05 lr: 3.1482e-06  eta: 5:05:05  time: 0.4148  data_time: 0.0099  memory: 5974  grad_norm: 421.5020  loss: 17.3870  decode.loss_cls: 0.1278  decode.loss_mask: 1.0240  decode.loss_dice: 0.5594  decode.d0.loss_cls: 0.5979  decode.d0.loss_mask: 0.9501  decode.d0.loss_dice: 0.5559  decode.d1.loss_cls: 0.1323  decode.d1.loss_mask: 1.0096  decode.d1.loss_dice: 0.5410  decode.d2.loss_cls: 0.1929  decode.d2.loss_mask: 0.9610  decode.d2.loss_dice: 0.5354  decode.d3.loss_cls: 0.1552  decode.d3.loss_mask: 1.0098  decode.d3.loss_dice: 0.5387  decode.d4.loss_cls: 0.1408  decode.d4.loss_mask: 1.0198  decode.d4.loss_dice: 0.5567  decode.d5.loss_cls: 0.1619  decode.d5.loss_mask: 0.9770  decode.d5.loss_dice: 0.5601  decode.d6.loss_cls: 0.1269  decode.d6.loss_mask: 0.9986  decode.d6.loss_dice: 0.5516  decode.d7.loss_cls: 0.1323  decode.d7.loss_mask: 1.0339  decode.d7.loss_dice: 0.5567  decode.d8.loss_cls: 0.1217  decode.d8.loss_mask: 1.0042  decode.d8.loss_dice: 0.5540
05/27 00:39:56 - mmengine - INFO - Iter(train) [115750/160000]  base_lr: 3.1450e-05 lr: 3.1450e-06  eta: 5:04:45  time: 0.4148  data_time: 0.0098  memory: 5981  grad_norm: 469.1750  loss: 16.1395  decode.loss_cls: 0.0991  decode.loss_mask: 0.8588  decode.loss_dice: 0.6033  decode.d0.loss_cls: 0.5753  decode.d0.loss_mask: 0.8480  decode.d0.loss_dice: 0.6119  decode.d1.loss_cls: 0.1202  decode.d1.loss_mask: 0.8662  decode.d1.loss_dice: 0.6162  decode.d2.loss_cls: 0.1126  decode.d2.loss_mask: 0.8460  decode.d2.loss_dice: 0.6057  decode.d3.loss_cls: 0.1289  decode.d3.loss_mask: 0.8383  decode.d3.loss_dice: 0.5917  decode.d4.loss_cls: 0.1390  decode.d4.loss_mask: 0.8244  decode.d4.loss_dice: 0.5805  decode.d5.loss_cls: 0.1534  decode.d5.loss_mask: 0.8382  decode.d5.loss_dice: 0.5912  decode.d6.loss_cls: 0.1211  decode.d6.loss_mask: 0.8613  decode.d6.loss_dice: 0.6069  decode.d7.loss_cls: 0.1327  decode.d7.loss_mask: 0.8385  decode.d7.loss_dice: 0.5901  decode.d8.loss_cls: 0.1145  decode.d8.loss_mask: 0.8324  decode.d8.loss_dice: 0.5931
05/27 00:40:17 - mmengine - INFO - Iter(train) [115800/160000]  base_lr: 3.1418e-05 lr: 3.1418e-06  eta: 5:04:24  time: 0.4146  data_time: 0.0099  memory: 5971  grad_norm: 663.1589  loss: 20.6569  decode.loss_cls: 0.1543  decode.loss_mask: 1.1003  decode.loss_dice: 0.7327  decode.d0.loss_cls: 0.5912  decode.d0.loss_mask: 1.1145  decode.d0.loss_dice: 0.7187  decode.d1.loss_cls: 0.1345  decode.d1.loss_mask: 1.1297  decode.d1.loss_dice: 0.7441  decode.d2.loss_cls: 0.1623  decode.d2.loss_mask: 1.1398  decode.d2.loss_dice: 0.7385  decode.d3.loss_cls: 0.1372  decode.d3.loss_mask: 1.1374  decode.d3.loss_dice: 0.7428  decode.d4.loss_cls: 0.1596  decode.d4.loss_mask: 1.1328  decode.d4.loss_dice: 0.7474  decode.d5.loss_cls: 0.1472  decode.d5.loss_mask: 1.1409  decode.d5.loss_dice: 0.7484  decode.d6.loss_cls: 0.1235  decode.d6.loss_mask: 1.1426  decode.d6.loss_dice: 0.7694  decode.d7.loss_cls: 0.1395  decode.d7.loss_mask: 1.1264  decode.d7.loss_dice: 0.7599  decode.d8.loss_cls: 0.1343  decode.d8.loss_mask: 1.1479  decode.d8.loss_dice: 0.7589
05/27 00:40:37 - mmengine - INFO - Iter(train) [115850/160000]  base_lr: 3.1386e-05 lr: 3.1386e-06  eta: 5:04:03  time: 0.4144  data_time: 0.0098  memory: 5969  grad_norm: 609.0193  loss: 20.3276  decode.loss_cls: 0.2898  decode.loss_mask: 1.0107  decode.loss_dice: 0.6796  decode.d0.loss_cls: 0.7877  decode.d0.loss_mask: 0.9762  decode.d0.loss_dice: 0.6594  decode.d1.loss_cls: 0.3079  decode.d1.loss_mask: 1.0205  decode.d1.loss_dice: 0.6809  decode.d2.loss_cls: 0.2907  decode.d2.loss_mask: 1.0360  decode.d2.loss_dice: 0.6786  decode.d3.loss_cls: 0.2979  decode.d3.loss_mask: 1.0212  decode.d3.loss_dice: 0.6823  decode.d4.loss_cls: 0.2664  decode.d4.loss_mask: 0.9955  decode.d4.loss_dice: 0.6740  decode.d5.loss_cls: 0.3145  decode.d5.loss_mask: 1.0384  decode.d5.loss_dice: 0.6770  decode.d6.loss_cls: 0.2576  decode.d6.loss_mask: 1.0055  decode.d6.loss_dice: 0.6871  decode.d7.loss_cls: 0.2757  decode.d7.loss_mask: 1.0285  decode.d7.loss_dice: 0.6904  decode.d8.loss_cls: 0.2609  decode.d8.loss_mask: 1.0347  decode.d8.loss_dice: 0.7019
05/27 00:40:58 - mmengine - INFO - Iter(train) [115900/160000]  base_lr: 3.1354e-05 lr: 3.1354e-06  eta: 5:03:43  time: 0.4154  data_time: 0.0099  memory: 5969  grad_norm: 467.0434  loss: 19.7134  decode.loss_cls: 0.2230  decode.loss_mask: 0.9641  decode.loss_dice: 0.7164  decode.d0.loss_cls: 0.6593  decode.d0.loss_mask: 0.9557  decode.d0.loss_dice: 0.7434  decode.d1.loss_cls: 0.2295  decode.d1.loss_mask: 0.9475  decode.d1.loss_dice: 0.7115  decode.d2.loss_cls: 0.2320  decode.d2.loss_mask: 0.9632  decode.d2.loss_dice: 0.7180  decode.d3.loss_cls: 0.1904  decode.d3.loss_mask: 1.0141  decode.d3.loss_dice: 0.7430  decode.d4.loss_cls: 0.1907  decode.d4.loss_mask: 0.9809  decode.d4.loss_dice: 0.7156  decode.d5.loss_cls: 0.2201  decode.d5.loss_mask: 0.9951  decode.d5.loss_dice: 0.7556  decode.d6.loss_cls: 0.2715  decode.d6.loss_mask: 0.9472  decode.d6.loss_dice: 0.7424  decode.d7.loss_cls: 0.2364  decode.d7.loss_mask: 0.9566  decode.d7.loss_dice: 0.7410  decode.d8.loss_cls: 0.2305  decode.d8.loss_mask: 0.9795  decode.d8.loss_dice: 0.7391
05/27 00:41:19 - mmengine - INFO - Iter(train) [115950/160000]  base_lr: 3.1322e-05 lr: 3.1322e-06  eta: 5:03:22  time: 0.4151  data_time: 0.0098  memory: 5980  grad_norm: 607.2823  loss: 15.7791  decode.loss_cls: 0.0733  decode.loss_mask: 0.9251  decode.loss_dice: 0.5346  decode.d0.loss_cls: 0.6296  decode.d0.loss_mask: 0.7965  decode.d0.loss_dice: 0.5218  decode.d1.loss_cls: 0.1138  decode.d1.loss_mask: 0.8744  decode.d1.loss_dice: 0.5395  decode.d2.loss_cls: 0.1303  decode.d2.loss_mask: 0.8891  decode.d2.loss_dice: 0.5309  decode.d3.loss_cls: 0.1504  decode.d3.loss_mask: 0.8132  decode.d3.loss_dice: 0.5097  decode.d4.loss_cls: 0.1102  decode.d4.loss_mask: 0.8998  decode.d4.loss_dice: 0.5357  decode.d5.loss_cls: 0.0964  decode.d5.loss_mask: 0.9011  decode.d5.loss_dice: 0.5328  decode.d6.loss_cls: 0.1082  decode.d6.loss_mask: 0.9382  decode.d6.loss_dice: 0.5387  decode.d7.loss_cls: 0.1162  decode.d7.loss_mask: 0.9047  decode.d7.loss_dice: 0.5482  decode.d8.loss_cls: 0.0930  decode.d8.loss_mask: 0.8958  decode.d8.loss_dice: 0.5277
05/27 00:41:40 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 00:41:40 - mmengine - INFO - Iter(train) [116000/160000]  base_lr: 3.1290e-05 lr: 3.1290e-06  eta: 5:03:02  time: 0.4158  data_time: 0.0099  memory: 5967  grad_norm: 946.1954  loss: 20.1777  decode.loss_cls: 0.1589  decode.loss_mask: 1.0479  decode.loss_dice: 0.7285  decode.d0.loss_cls: 0.6574  decode.d0.loss_mask: 1.0558  decode.d0.loss_dice: 0.7281  decode.d1.loss_cls: 0.1944  decode.d1.loss_mask: 1.0156  decode.d1.loss_dice: 0.7249  decode.d2.loss_cls: 0.2194  decode.d2.loss_mask: 1.0498  decode.d2.loss_dice: 0.7267  decode.d3.loss_cls: 0.1832  decode.d3.loss_mask: 1.0216  decode.d3.loss_dice: 0.7066  decode.d4.loss_cls: 0.2038  decode.d4.loss_mask: 1.0499  decode.d4.loss_dice: 0.7413  decode.d5.loss_cls: 0.1815  decode.d5.loss_mask: 1.0795  decode.d5.loss_dice: 0.7542  decode.d6.loss_cls: 0.1869  decode.d6.loss_mask: 1.0453  decode.d6.loss_dice: 0.7159  decode.d7.loss_cls: 0.1787  decode.d7.loss_mask: 1.0549  decode.d7.loss_dice: 0.7603  decode.d8.loss_cls: 0.1970  decode.d8.loss_mask: 1.0735  decode.d8.loss_dice: 0.7359
05/27 00:42:00 - mmengine - INFO - Iter(train) [116050/160000]  base_lr: 3.1258e-05 lr: 3.1258e-06  eta: 5:02:41  time: 0.4161  data_time: 0.0109  memory: 5983  grad_norm: 846.5321  loss: 19.7336  decode.loss_cls: 0.2319  decode.loss_mask: 0.9546  decode.loss_dice: 0.7195  decode.d0.loss_cls: 0.7597  decode.d0.loss_mask: 0.8816  decode.d0.loss_dice: 0.7021  decode.d1.loss_cls: 0.2719  decode.d1.loss_mask: 0.9755  decode.d1.loss_dice: 0.7300  decode.d2.loss_cls: 0.2329  decode.d2.loss_mask: 1.0112  decode.d2.loss_dice: 0.7452  decode.d3.loss_cls: 0.2447  decode.d3.loss_mask: 0.9520  decode.d3.loss_dice: 0.7169  decode.d4.loss_cls: 0.2308  decode.d4.loss_mask: 0.9152  decode.d4.loss_dice: 0.7014  decode.d5.loss_cls: 0.2379  decode.d5.loss_mask: 0.9328  decode.d5.loss_dice: 0.7302  decode.d6.loss_cls: 0.2423  decode.d6.loss_mask: 0.9544  decode.d6.loss_dice: 0.7452  decode.d7.loss_cls: 0.2459  decode.d7.loss_mask: 0.9453  decode.d7.loss_dice: 0.7410  decode.d8.loss_cls: 0.2260  decode.d8.loss_mask: 1.0143  decode.d8.loss_dice: 0.7413
05/27 00:42:21 - mmengine - INFO - Iter(train) [116100/160000]  base_lr: 3.1226e-05 lr: 3.1226e-06  eta: 5:02:20  time: 0.4147  data_time: 0.0099  memory: 5968  grad_norm: 524.8833  loss: 23.6137  decode.loss_cls: 0.3134  decode.loss_mask: 1.1128  decode.loss_dice: 0.8071  decode.d0.loss_cls: 0.7680  decode.d0.loss_mask: 1.1398  decode.d0.loss_dice: 0.8427  decode.d1.loss_cls: 0.2734  decode.d1.loss_mask: 1.1541  decode.d1.loss_dice: 0.8386  decode.d2.loss_cls: 0.3340  decode.d2.loss_mask: 1.1401  decode.d2.loss_dice: 0.8093  decode.d3.loss_cls: 0.3424  decode.d3.loss_mask: 1.1528  decode.d3.loss_dice: 0.8363  decode.d4.loss_cls: 0.3467  decode.d4.loss_mask: 1.1966  decode.d4.loss_dice: 0.8643  decode.d5.loss_cls: 0.3176  decode.d5.loss_mask: 1.1791  decode.d5.loss_dice: 0.8651  decode.d6.loss_cls: 0.3111  decode.d6.loss_mask: 1.1218  decode.d6.loss_dice: 0.8292  decode.d7.loss_cls: 0.3474  decode.d7.loss_mask: 1.1531  decode.d7.loss_dice: 0.8499  decode.d8.loss_cls: 0.3298  decode.d8.loss_mask: 1.1936  decode.d8.loss_dice: 0.8436
05/27 00:42:42 - mmengine - INFO - Iter(train) [116150/160000]  base_lr: 3.1194e-05 lr: 3.1194e-06  eta: 5:02:00  time: 0.4160  data_time: 0.0098  memory: 5971  grad_norm: 543.3355  loss: 19.6721  decode.loss_cls: 0.1472  decode.loss_mask: 1.0884  decode.loss_dice: 0.6748  decode.d0.loss_cls: 0.6734  decode.d0.loss_mask: 1.0610  decode.d0.loss_dice: 0.6336  decode.d1.loss_cls: 0.1336  decode.d1.loss_mask: 1.0849  decode.d1.loss_dice: 0.7000  decode.d2.loss_cls: 0.1468  decode.d2.loss_mask: 1.0800  decode.d2.loss_dice: 0.6832  decode.d3.loss_cls: 0.1382  decode.d3.loss_mask: 1.0820  decode.d3.loss_dice: 0.6647  decode.d4.loss_cls: 0.1545  decode.d4.loss_mask: 1.0636  decode.d4.loss_dice: 0.6771  decode.d5.loss_cls: 0.1719  decode.d5.loss_mask: 1.1445  decode.d5.loss_dice: 0.6957  decode.d6.loss_cls: 0.1308  decode.d6.loss_mask: 1.1079  decode.d6.loss_dice: 0.6974  decode.d7.loss_cls: 0.1722  decode.d7.loss_mask: 1.0877  decode.d7.loss_dice: 0.6754  decode.d8.loss_cls: 0.1528  decode.d8.loss_mask: 1.0768  decode.d8.loss_dice: 0.6721
05/27 00:43:03 - mmengine - INFO - Iter(train) [116200/160000]  base_lr: 3.1162e-05 lr: 3.1162e-06  eta: 5:01:39  time: 0.4139  data_time: 0.0099  memory: 5981  grad_norm: 631.0171  loss: 18.3883  decode.loss_cls: 0.1953  decode.loss_mask: 0.8958  decode.loss_dice: 0.6667  decode.d0.loss_cls: 0.7888  decode.d0.loss_mask: 0.8904  decode.d0.loss_dice: 0.7085  decode.d1.loss_cls: 0.1811  decode.d1.loss_mask: 0.8928  decode.d1.loss_dice: 0.6848  decode.d2.loss_cls: 0.1967  decode.d2.loss_mask: 0.9060  decode.d2.loss_dice: 0.7029  decode.d3.loss_cls: 0.2246  decode.d3.loss_mask: 0.8805  decode.d3.loss_dice: 0.6734  decode.d4.loss_cls: 0.2098  decode.d4.loss_mask: 0.8812  decode.d4.loss_dice: 0.6804  decode.d5.loss_cls: 0.1936  decode.d5.loss_mask: 0.9092  decode.d5.loss_dice: 0.6955  decode.d6.loss_cls: 0.2077  decode.d6.loss_mask: 0.8799  decode.d6.loss_dice: 0.6880  decode.d7.loss_cls: 0.1970  decode.d7.loss_mask: 0.8898  decode.d7.loss_dice: 0.6909  decode.d8.loss_cls: 0.2059  decode.d8.loss_mask: 0.9027  decode.d8.loss_dice: 0.6682
05/27 00:43:24 - mmengine - INFO - Iter(train) [116250/160000]  base_lr: 3.1130e-05 lr: 3.1130e-06  eta: 5:01:18  time: 0.4147  data_time: 0.0098  memory: 5971  grad_norm: 340.7472  loss: 18.1037  decode.loss_cls: 0.2416  decode.loss_mask: 0.8988  decode.loss_dice: 0.6299  decode.d0.loss_cls: 0.5943  decode.d0.loss_mask: 0.8970  decode.d0.loss_dice: 0.6412  decode.d1.loss_cls: 0.2373  decode.d1.loss_mask: 0.8715  decode.d1.loss_dice: 0.6098  decode.d2.loss_cls: 0.2254  decode.d2.loss_mask: 0.9097  decode.d2.loss_dice: 0.6315  decode.d3.loss_cls: 0.2491  decode.d3.loss_mask: 0.8673  decode.d3.loss_dice: 0.6176  decode.d4.loss_cls: 0.2673  decode.d4.loss_mask: 0.8725  decode.d4.loss_dice: 0.6016  decode.d5.loss_cls: 0.2451  decode.d5.loss_mask: 0.9159  decode.d5.loss_dice: 0.6278  decode.d6.loss_cls: 0.2535  decode.d6.loss_mask: 0.9219  decode.d6.loss_dice: 0.6456  decode.d7.loss_cls: 0.2752  decode.d7.loss_mask: 0.9249  decode.d7.loss_dice: 0.6367  decode.d8.loss_cls: 0.2624  decode.d8.loss_mask: 0.8960  decode.d8.loss_dice: 0.6351
05/27 00:43:44 - mmengine - INFO - Iter(train) [116300/160000]  base_lr: 3.1098e-05 lr: 3.1098e-06  eta: 5:00:58  time: 0.4150  data_time: 0.0098  memory: 5982  grad_norm: 407.5051  loss: 18.1544  decode.loss_cls: 0.0770  decode.loss_mask: 0.9844  decode.loss_dice: 0.7025  decode.d0.loss_cls: 0.6523  decode.d0.loss_mask: 0.8978  decode.d0.loss_dice: 0.6809  decode.d1.loss_cls: 0.1432  decode.d1.loss_mask: 1.0048  decode.d1.loss_dice: 0.7208  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.9948  decode.d2.loss_dice: 0.7357  decode.d3.loss_cls: 0.1103  decode.d3.loss_mask: 0.9234  decode.d3.loss_dice: 0.6982  decode.d4.loss_cls: 0.0930  decode.d4.loss_mask: 0.9927  decode.d4.loss_dice: 0.7198  decode.d5.loss_cls: 0.0716  decode.d5.loss_mask: 0.9459  decode.d5.loss_dice: 0.7158  decode.d6.loss_cls: 0.1169  decode.d6.loss_mask: 0.9307  decode.d6.loss_dice: 0.6998  decode.d7.loss_cls: 0.1362  decode.d7.loss_mask: 0.9339  decode.d7.loss_dice: 0.6929  decode.d8.loss_cls: 0.0854  decode.d8.loss_mask: 0.9330  decode.d8.loss_dice: 0.6991
05/27 00:44:05 - mmengine - INFO - Iter(train) [116350/160000]  base_lr: 3.1066e-05 lr: 3.1066e-06  eta: 5:00:37  time: 0.4147  data_time: 0.0097  memory: 5975  grad_norm: 435.5337  loss: 17.0809  decode.loss_cls: 0.1724  decode.loss_mask: 0.7743  decode.loss_dice: 0.6821  decode.d0.loss_cls: 0.5515  decode.d0.loss_mask: 0.7634  decode.d0.loss_dice: 0.6859  decode.d1.loss_cls: 0.2370  decode.d1.loss_mask: 0.7573  decode.d1.loss_dice: 0.6845  decode.d2.loss_cls: 0.2121  decode.d2.loss_mask: 0.7506  decode.d2.loss_dice: 0.6730  decode.d3.loss_cls: 0.1734  decode.d3.loss_mask: 0.8364  decode.d3.loss_dice: 0.7005  decode.d4.loss_cls: 0.2367  decode.d4.loss_mask: 0.7566  decode.d4.loss_dice: 0.6708  decode.d5.loss_cls: 0.2553  decode.d5.loss_mask: 0.7491  decode.d5.loss_dice: 0.6735  decode.d6.loss_cls: 0.2290  decode.d6.loss_mask: 0.7983  decode.d6.loss_dice: 0.6797  decode.d7.loss_cls: 0.2254  decode.d7.loss_mask: 0.7947  decode.d7.loss_dice: 0.6857  decode.d8.loss_cls: 0.1983  decode.d8.loss_mask: 0.7803  decode.d8.loss_dice: 0.6931
05/27 00:44:26 - mmengine - INFO - Iter(train) [116400/160000]  base_lr: 3.1034e-05 lr: 3.1034e-06  eta: 5:00:17  time: 0.4173  data_time: 0.0124  memory: 5968  grad_norm: 653.2774  loss: 20.3402  decode.loss_cls: 0.2722  decode.loss_mask: 0.9824  decode.loss_dice: 0.7201  decode.d0.loss_cls: 0.6503  decode.d0.loss_mask: 0.9783  decode.d0.loss_dice: 0.7353  decode.d1.loss_cls: 0.2448  decode.d1.loss_mask: 1.0224  decode.d1.loss_dice: 0.7561  decode.d2.loss_cls: 0.2185  decode.d2.loss_mask: 1.0068  decode.d2.loss_dice: 0.7620  decode.d3.loss_cls: 0.2604  decode.d3.loss_mask: 0.9833  decode.d3.loss_dice: 0.7461  decode.d4.loss_cls: 0.2604  decode.d4.loss_mask: 0.9774  decode.d4.loss_dice: 0.7374  decode.d5.loss_cls: 0.2579  decode.d5.loss_mask: 0.9814  decode.d5.loss_dice: 0.7331  decode.d6.loss_cls: 0.2670  decode.d6.loss_mask: 0.9867  decode.d6.loss_dice: 0.7433  decode.d7.loss_cls: 0.2697  decode.d7.loss_mask: 1.0009  decode.d7.loss_dice: 0.7703  decode.d8.loss_cls: 0.2531  decode.d8.loss_mask: 1.0044  decode.d8.loss_dice: 0.7582
05/27 00:44:47 - mmengine - INFO - Iter(train) [116450/160000]  base_lr: 3.1002e-05 lr: 3.1002e-06  eta: 4:59:56  time: 0.4151  data_time: 0.0097  memory: 5987  grad_norm: 635.8717  loss: 19.4699  decode.loss_cls: 0.2209  decode.loss_mask: 0.8687  decode.loss_dice: 0.7591  decode.d0.loss_cls: 0.8139  decode.d0.loss_mask: 0.8781  decode.d0.loss_dice: 0.7582  decode.d1.loss_cls: 0.2868  decode.d1.loss_mask: 0.8634  decode.d1.loss_dice: 0.7190  decode.d2.loss_cls: 0.1957  decode.d2.loss_mask: 0.9376  decode.d2.loss_dice: 0.7716  decode.d3.loss_cls: 0.2296  decode.d3.loss_mask: 0.9172  decode.d3.loss_dice: 0.7612  decode.d4.loss_cls: 0.2248  decode.d4.loss_mask: 0.9151  decode.d4.loss_dice: 0.7672  decode.d5.loss_cls: 0.2051  decode.d5.loss_mask: 0.9270  decode.d5.loss_dice: 0.7833  decode.d6.loss_cls: 0.2136  decode.d6.loss_mask: 0.9209  decode.d6.loss_dice: 0.7816  decode.d7.loss_cls: 0.2022  decode.d7.loss_mask: 0.9202  decode.d7.loss_dice: 0.7681  decode.d8.loss_cls: 0.2453  decode.d8.loss_mask: 0.8619  decode.d8.loss_dice: 0.7528
05/27 00:45:07 - mmengine - INFO - Iter(train) [116500/160000]  base_lr: 3.0970e-05 lr: 3.0970e-06  eta: 4:59:35  time: 0.4159  data_time: 0.0097  memory: 5975  grad_norm: 674.1246  loss: 19.6841  decode.loss_cls: 0.2127  decode.loss_mask: 0.9461  decode.loss_dice: 0.7000  decode.d0.loss_cls: 0.7454  decode.d0.loss_mask: 0.9006  decode.d0.loss_dice: 0.7291  decode.d1.loss_cls: 0.2617  decode.d1.loss_mask: 0.9971  decode.d1.loss_dice: 0.7289  decode.d2.loss_cls: 0.2451  decode.d2.loss_mask: 0.9908  decode.d2.loss_dice: 0.7229  decode.d3.loss_cls: 0.2264  decode.d3.loss_mask: 0.9893  decode.d3.loss_dice: 0.7030  decode.d4.loss_cls: 0.2463  decode.d4.loss_mask: 0.9881  decode.d4.loss_dice: 0.7024  decode.d5.loss_cls: 0.2192  decode.d5.loss_mask: 1.0054  decode.d5.loss_dice: 0.7038  decode.d6.loss_cls: 0.2328  decode.d6.loss_mask: 0.9843  decode.d6.loss_dice: 0.7025  decode.d7.loss_cls: 0.2812  decode.d7.loss_mask: 0.9530  decode.d7.loss_dice: 0.6953  decode.d8.loss_cls: 0.2276  decode.d8.loss_mask: 0.9550  decode.d8.loss_dice: 0.6880
05/27 00:45:28 - mmengine - INFO - Iter(train) [116550/160000]  base_lr: 3.0938e-05 lr: 3.0938e-06  eta: 4:59:15  time: 0.4160  data_time: 0.0097  memory: 5970  grad_norm: 560.7601  loss: 16.5854  decode.loss_cls: 0.1076  decode.loss_mask: 0.8178  decode.loss_dice: 0.6612  decode.d0.loss_cls: 0.6479  decode.d0.loss_mask: 0.7896  decode.d0.loss_dice: 0.6169  decode.d1.loss_cls: 0.1413  decode.d1.loss_mask: 0.8138  decode.d1.loss_dice: 0.6522  decode.d2.loss_cls: 0.1486  decode.d2.loss_mask: 0.8127  decode.d2.loss_dice: 0.6435  decode.d3.loss_cls: 0.1587  decode.d3.loss_mask: 0.8169  decode.d3.loss_dice: 0.6736  decode.d4.loss_cls: 0.1672  decode.d4.loss_mask: 0.8260  decode.d4.loss_dice: 0.6602  decode.d5.loss_cls: 0.1395  decode.d5.loss_mask: 0.8216  decode.d5.loss_dice: 0.6759  decode.d6.loss_cls: 0.1475  decode.d6.loss_mask: 0.8180  decode.d6.loss_dice: 0.6532  decode.d7.loss_cls: 0.1101  decode.d7.loss_mask: 0.8182  decode.d7.loss_dice: 0.6459  decode.d8.loss_cls: 0.1184  decode.d8.loss_mask: 0.8140  decode.d8.loss_dice: 0.6674
05/27 00:45:49 - mmengine - INFO - Iter(train) [116600/160000]  base_lr: 3.0905e-05 lr: 3.0905e-06  eta: 4:58:54  time: 0.4155  data_time: 0.0097  memory: 5966  grad_norm: 1057.8635  loss: 21.6661  decode.loss_cls: 0.2220  decode.loss_mask: 1.0765  decode.loss_dice: 0.8272  decode.d0.loss_cls: 0.7176  decode.d0.loss_mask: 1.0116  decode.d0.loss_dice: 0.7965  decode.d1.loss_cls: 0.2333  decode.d1.loss_mask: 1.1060  decode.d1.loss_dice: 0.8177  decode.d2.loss_cls: 0.2299  decode.d2.loss_mask: 1.0710  decode.d2.loss_dice: 0.8101  decode.d3.loss_cls: 0.1725  decode.d3.loss_mask: 1.1249  decode.d3.loss_dice: 0.8133  decode.d4.loss_cls: 0.2163  decode.d4.loss_mask: 1.0831  decode.d4.loss_dice: 0.7945  decode.d5.loss_cls: 0.2132  decode.d5.loss_mask: 1.1088  decode.d5.loss_dice: 0.8070  decode.d6.loss_cls: 0.2234  decode.d6.loss_mask: 1.0880  decode.d6.loss_dice: 0.8269  decode.d7.loss_cls: 0.2049  decode.d7.loss_mask: 1.1012  decode.d7.loss_dice: 0.8071  decode.d8.loss_cls: 0.2277  decode.d8.loss_mask: 1.0924  decode.d8.loss_dice: 0.8417
05/27 00:46:10 - mmengine - INFO - Iter(train) [116650/160000]  base_lr: 3.0873e-05 lr: 3.0873e-06  eta: 4:58:34  time: 0.4148  data_time: 0.0097  memory: 5969  grad_norm: 350.3192  loss: 16.6044  decode.loss_cls: 0.0848  decode.loss_mask: 0.9255  decode.loss_dice: 0.6037  decode.d0.loss_cls: 0.5186  decode.d0.loss_mask: 0.9177  decode.d0.loss_dice: 0.5997  decode.d1.loss_cls: 0.0818  decode.d1.loss_mask: 0.9307  decode.d1.loss_dice: 0.6023  decode.d2.loss_cls: 0.1075  decode.d2.loss_mask: 0.9251  decode.d2.loss_dice: 0.5876  decode.d3.loss_cls: 0.0913  decode.d3.loss_mask: 0.9159  decode.d3.loss_dice: 0.6034  decode.d4.loss_cls: 0.1014  decode.d4.loss_mask: 0.9118  decode.d4.loss_dice: 0.5950  decode.d5.loss_cls: 0.0997  decode.d5.loss_mask: 0.9203  decode.d5.loss_dice: 0.5929  decode.d6.loss_cls: 0.0794  decode.d6.loss_mask: 0.9416  decode.d6.loss_dice: 0.6097  decode.d7.loss_cls: 0.0801  decode.d7.loss_mask: 0.9418  decode.d7.loss_dice: 0.6076  decode.d8.loss_cls: 0.0802  decode.d8.loss_mask: 0.9416  decode.d8.loss_dice: 0.6059
05/27 00:46:31 - mmengine - INFO - Iter(train) [116700/160000]  base_lr: 3.0841e-05 lr: 3.0841e-06  eta: 4:58:13  time: 0.4143  data_time: 0.0097  memory: 5969  grad_norm: 418.0502  loss: 19.3714  decode.loss_cls: 0.0442  decode.loss_mask: 1.1276  decode.loss_dice: 0.7166  decode.d0.loss_cls: 0.5409  decode.d0.loss_mask: 1.0375  decode.d0.loss_dice: 0.6832  decode.d1.loss_cls: 0.0434  decode.d1.loss_mask: 1.1488  decode.d1.loss_dice: 0.7081  decode.d2.loss_cls: 0.0489  decode.d2.loss_mask: 1.1474  decode.d2.loss_dice: 0.7215  decode.d3.loss_cls: 0.0449  decode.d3.loss_mask: 1.1424  decode.d3.loss_dice: 0.7116  decode.d4.loss_cls: 0.0641  decode.d4.loss_mask: 1.1448  decode.d4.loss_dice: 0.7015  decode.d5.loss_cls: 0.0489  decode.d5.loss_mask: 1.1455  decode.d5.loss_dice: 0.7101  decode.d6.loss_cls: 0.0486  decode.d6.loss_mask: 1.1528  decode.d6.loss_dice: 0.7105  decode.d7.loss_cls: 0.0433  decode.d7.loss_mask: 1.1322  decode.d7.loss_dice: 0.7093  decode.d8.loss_cls: 0.0405  decode.d8.loss_mask: 1.1391  decode.d8.loss_dice: 0.7134
05/27 00:46:51 - mmengine - INFO - Iter(train) [116750/160000]  base_lr: 3.0809e-05 lr: 3.0809e-06  eta: 4:57:52  time: 0.4144  data_time: 0.0098  memory: 5969  grad_norm: 487.7262  loss: 19.7995  decode.loss_cls: 0.1407  decode.loss_mask: 1.0746  decode.loss_dice: 0.7182  decode.d0.loss_cls: 0.6670  decode.d0.loss_mask: 1.0144  decode.d0.loss_dice: 0.7042  decode.d1.loss_cls: 0.1883  decode.d1.loss_mask: 1.0341  decode.d1.loss_dice: 0.7012  decode.d2.loss_cls: 0.1645  decode.d2.loss_mask: 1.0845  decode.d2.loss_dice: 0.7161  decode.d3.loss_cls: 0.1440  decode.d3.loss_mask: 1.1043  decode.d3.loss_dice: 0.7243  decode.d4.loss_cls: 0.1672  decode.d4.loss_mask: 1.0698  decode.d4.loss_dice: 0.7024  decode.d5.loss_cls: 0.1702  decode.d5.loss_mask: 1.0140  decode.d5.loss_dice: 0.6936  decode.d6.loss_cls: 0.1695  decode.d6.loss_mask: 1.0212  decode.d6.loss_dice: 0.7046  decode.d7.loss_cls: 0.1752  decode.d7.loss_mask: 1.0669  decode.d7.loss_dice: 0.7201  decode.d8.loss_cls: 0.1589  decode.d8.loss_mask: 1.0689  decode.d8.loss_dice: 0.7166
05/27 00:47:12 - mmengine - INFO - Iter(train) [116800/160000]  base_lr: 3.0777e-05 lr: 3.0777e-06  eta: 4:57:32  time: 0.4149  data_time: 0.0097  memory: 5968  grad_norm: 353.9520  loss: 19.6146  decode.loss_cls: 0.1519  decode.loss_mask: 1.0336  decode.loss_dice: 0.7207  decode.d0.loss_cls: 0.6328  decode.d0.loss_mask: 0.9744  decode.d0.loss_dice: 0.7099  decode.d1.loss_cls: 0.1907  decode.d1.loss_mask: 1.0174  decode.d1.loss_dice: 0.7318  decode.d2.loss_cls: 0.1751  decode.d2.loss_mask: 1.0378  decode.d2.loss_dice: 0.7363  decode.d3.loss_cls: 0.1596  decode.d3.loss_mask: 1.0263  decode.d3.loss_dice: 0.7361  decode.d4.loss_cls: 0.1561  decode.d4.loss_mask: 1.0454  decode.d4.loss_dice: 0.7247  decode.d5.loss_cls: 0.1483  decode.d5.loss_mask: 1.0446  decode.d5.loss_dice: 0.7261  decode.d6.loss_cls: 0.1978  decode.d6.loss_mask: 1.0118  decode.d6.loss_dice: 0.7256  decode.d7.loss_cls: 0.1883  decode.d7.loss_mask: 1.0023  decode.d7.loss_dice: 0.7034  decode.d8.loss_cls: 0.1739  decode.d8.loss_mask: 1.0029  decode.d8.loss_dice: 0.7292
05/27 00:47:33 - mmengine - INFO - Iter(train) [116850/160000]  base_lr: 3.0745e-05 lr: 3.0745e-06  eta: 4:57:11  time: 0.4150  data_time: 0.0097  memory: 5967  grad_norm: 408.3605  loss: 18.0277  decode.loss_cls: 0.1400  decode.loss_mask: 1.0274  decode.loss_dice: 0.6140  decode.d0.loss_cls: 0.6139  decode.d0.loss_mask: 0.9629  decode.d0.loss_dice: 0.6056  decode.d1.loss_cls: 0.1341  decode.d1.loss_mask: 1.0307  decode.d1.loss_dice: 0.6091  decode.d2.loss_cls: 0.1274  decode.d2.loss_mask: 1.0165  decode.d2.loss_dice: 0.6180  decode.d3.loss_cls: 0.1283  decode.d3.loss_mask: 0.9880  decode.d3.loss_dice: 0.6109  decode.d4.loss_cls: 0.1260  decode.d4.loss_mask: 1.0050  decode.d4.loss_dice: 0.6002  decode.d5.loss_cls: 0.1305  decode.d5.loss_mask: 1.0185  decode.d5.loss_dice: 0.6207  decode.d6.loss_cls: 0.1323  decode.d6.loss_mask: 1.0308  decode.d6.loss_dice: 0.6272  decode.d7.loss_cls: 0.1333  decode.d7.loss_mask: 0.9994  decode.d7.loss_dice: 0.6154  decode.d8.loss_cls: 0.1568  decode.d8.loss_mask: 1.0066  decode.d8.loss_dice: 0.5981
05/27 00:47:54 - mmengine - INFO - Iter(train) [116900/160000]  base_lr: 3.0713e-05 lr: 3.0713e-06  eta: 4:56:50  time: 0.4151  data_time: 0.0098  memory: 5975  grad_norm: 326.8625  loss: 17.4715  decode.loss_cls: 0.1108  decode.loss_mask: 0.9424  decode.loss_dice: 0.6208  decode.d0.loss_cls: 0.6260  decode.d0.loss_mask: 0.9255  decode.d0.loss_dice: 0.5941  decode.d1.loss_cls: 0.1335  decode.d1.loss_mask: 0.9640  decode.d1.loss_dice: 0.6178  decode.d2.loss_cls: 0.1472  decode.d2.loss_mask: 0.9592  decode.d2.loss_dice: 0.5990  decode.d3.loss_cls: 0.1615  decode.d3.loss_mask: 0.9393  decode.d3.loss_dice: 0.6033  decode.d4.loss_cls: 0.1469  decode.d4.loss_mask: 0.9281  decode.d4.loss_dice: 0.5983  decode.d5.loss_cls: 0.1623  decode.d5.loss_mask: 0.9497  decode.d5.loss_dice: 0.6109  decode.d6.loss_cls: 0.1511  decode.d6.loss_mask: 0.9401  decode.d6.loss_dice: 0.6098  decode.d7.loss_cls: 0.1455  decode.d7.loss_mask: 0.9588  decode.d7.loss_dice: 0.6317  decode.d8.loss_cls: 0.1362  decode.d8.loss_mask: 0.9471  decode.d8.loss_dice: 0.6106
05/27 00:48:14 - mmengine - INFO - Iter(train) [116950/160000]  base_lr: 3.0681e-05 lr: 3.0681e-06  eta: 4:56:30  time: 0.4137  data_time: 0.0098  memory: 5967  grad_norm: 394.7198  loss: 18.5427  decode.loss_cls: 0.1613  decode.loss_mask: 0.9910  decode.loss_dice: 0.6678  decode.d0.loss_cls: 0.5409  decode.d0.loss_mask: 0.9914  decode.d0.loss_dice: 0.6938  decode.d1.loss_cls: 0.1770  decode.d1.loss_mask: 0.9332  decode.d1.loss_dice: 0.6704  decode.d2.loss_cls: 0.1789  decode.d2.loss_mask: 0.9528  decode.d2.loss_dice: 0.6844  decode.d3.loss_cls: 0.1677  decode.d3.loss_mask: 0.9620  decode.d3.loss_dice: 0.6517  decode.d4.loss_cls: 0.1894  decode.d4.loss_mask: 0.9214  decode.d4.loss_dice: 0.6559  decode.d5.loss_cls: 0.1992  decode.d5.loss_mask: 0.9271  decode.d5.loss_dice: 0.6615  decode.d6.loss_cls: 0.2012  decode.d6.loss_mask: 0.9980  decode.d6.loss_dice: 0.6795  decode.d7.loss_cls: 0.1813  decode.d7.loss_mask: 1.0012  decode.d7.loss_dice: 0.6824  decode.d8.loss_cls: 0.1779  decode.d8.loss_mask: 0.9817  decode.d8.loss_dice: 0.6607
05/27 00:48:35 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 00:48:35 - mmengine - INFO - Iter(train) [117000/160000]  base_lr: 3.0649e-05 lr: 3.0649e-06  eta: 4:56:09  time: 0.4147  data_time: 0.0097  memory: 5968  grad_norm: 760.6075  loss: 20.1157  decode.loss_cls: 0.1465  decode.loss_mask: 1.0812  decode.loss_dice: 0.7435  decode.d0.loss_cls: 0.7903  decode.d0.loss_mask: 0.9732  decode.d0.loss_dice: 0.7036  decode.d1.loss_cls: 0.1900  decode.d1.loss_mask: 1.0316  decode.d1.loss_dice: 0.7110  decode.d2.loss_cls: 0.1871  decode.d2.loss_mask: 1.0584  decode.d2.loss_dice: 0.7308  decode.d3.loss_cls: 0.1155  decode.d3.loss_mask: 1.0928  decode.d3.loss_dice: 0.7475  decode.d4.loss_cls: 0.1574  decode.d4.loss_mask: 1.0670  decode.d4.loss_dice: 0.7106  decode.d5.loss_cls: 0.1328  decode.d5.loss_mask: 1.0819  decode.d5.loss_dice: 0.7280  decode.d6.loss_cls: 0.1401  decode.d6.loss_mask: 1.0819  decode.d6.loss_dice: 0.7441  decode.d7.loss_cls: 0.1495  decode.d7.loss_mask: 1.1034  decode.d7.loss_dice: 0.7494  decode.d8.loss_cls: 0.1344  decode.d8.loss_mask: 1.0917  decode.d8.loss_dice: 0.7405
05/27 00:48:56 - mmengine - INFO - Iter(train) [117050/160000]  base_lr: 3.0617e-05 lr: 3.0617e-06  eta: 4:55:48  time: 0.4147  data_time: 0.0099  memory: 5979  grad_norm: 659.6159  loss: 19.8528  decode.loss_cls: 0.1505  decode.loss_mask: 1.0648  decode.loss_dice: 0.7223  decode.d0.loss_cls: 0.6315  decode.d0.loss_mask: 0.9805  decode.d0.loss_dice: 0.7028  decode.d1.loss_cls: 0.2164  decode.d1.loss_mask: 1.0491  decode.d1.loss_dice: 0.6808  decode.d2.loss_cls: 0.1505  decode.d2.loss_mask: 1.0602  decode.d2.loss_dice: 0.7097  decode.d3.loss_cls: 0.1853  decode.d3.loss_mask: 1.0949  decode.d3.loss_dice: 0.7006  decode.d4.loss_cls: 0.1935  decode.d4.loss_mask: 1.0627  decode.d4.loss_dice: 0.6995  decode.d5.loss_cls: 0.1659  decode.d5.loss_mask: 1.0470  decode.d5.loss_dice: 0.6920  decode.d6.loss_cls: 0.1590  decode.d6.loss_mask: 1.0634  decode.d6.loss_dice: 0.7246  decode.d7.loss_cls: 0.1977  decode.d7.loss_mask: 1.1022  decode.d7.loss_dice: 0.7123  decode.d8.loss_cls: 0.1993  decode.d8.loss_mask: 1.0609  decode.d8.loss_dice: 0.6731
05/27 00:49:17 - mmengine - INFO - Iter(train) [117100/160000]  base_lr: 3.0585e-05 lr: 3.0585e-06  eta: 4:55:28  time: 0.4148  data_time: 0.0098  memory: 5969  grad_norm: 806.7162  loss: 19.4185  decode.loss_cls: 0.0835  decode.loss_mask: 1.0430  decode.loss_dice: 0.7133  decode.d0.loss_cls: 0.6228  decode.d0.loss_mask: 1.0112  decode.d0.loss_dice: 0.6907  decode.d1.loss_cls: 0.1133  decode.d1.loss_mask: 1.1195  decode.d1.loss_dice: 0.7486  decode.d2.loss_cls: 0.0617  decode.d2.loss_mask: 1.1054  decode.d2.loss_dice: 0.7513  decode.d3.loss_cls: 0.0925  decode.d3.loss_mask: 1.0557  decode.d3.loss_dice: 0.7217  decode.d4.loss_cls: 0.1045  decode.d4.loss_mask: 1.0637  decode.d4.loss_dice: 0.7368  decode.d5.loss_cls: 0.0931  decode.d5.loss_mask: 1.0871  decode.d5.loss_dice: 0.7323  decode.d6.loss_cls: 0.1005  decode.d6.loss_mask: 1.0508  decode.d6.loss_dice: 0.7373  decode.d7.loss_cls: 0.0932  decode.d7.loss_mask: 1.0629  decode.d7.loss_dice: 0.7291  decode.d8.loss_cls: 0.0785  decode.d8.loss_mask: 1.0805  decode.d8.loss_dice: 0.7342
05/27 00:49:38 - mmengine - INFO - Iter(train) [117150/160000]  base_lr: 3.0553e-05 lr: 3.0553e-06  eta: 4:55:07  time: 0.4170  data_time: 0.0102  memory: 5971  grad_norm: 343.7607  loss: 18.1048  decode.loss_cls: 0.1544  decode.loss_mask: 0.8742  decode.loss_dice: 0.6908  decode.d0.loss_cls: 0.6822  decode.d0.loss_mask: 0.8713  decode.d0.loss_dice: 0.7137  decode.d1.loss_cls: 0.1983  decode.d1.loss_mask: 0.8754  decode.d1.loss_dice: 0.7216  decode.d2.loss_cls: 0.2090  decode.d2.loss_mask: 0.8683  decode.d2.loss_dice: 0.7113  decode.d3.loss_cls: 0.1904  decode.d3.loss_mask: 0.8602  decode.d3.loss_dice: 0.6885  decode.d4.loss_cls: 0.1885  decode.d4.loss_mask: 0.8664  decode.d4.loss_dice: 0.6950  decode.d5.loss_cls: 0.1851  decode.d5.loss_mask: 0.8579  decode.d5.loss_dice: 0.6990  decode.d6.loss_cls: 0.1811  decode.d6.loss_mask: 0.8710  decode.d6.loss_dice: 0.7306  decode.d7.loss_cls: 0.1747  decode.d7.loss_mask: 0.8732  decode.d7.loss_dice: 0.7175  decode.d8.loss_cls: 0.1711  decode.d8.loss_mask: 0.8715  decode.d8.loss_dice: 0.7127
05/27 00:49:58 - mmengine - INFO - Iter(train) [117200/160000]  base_lr: 3.0521e-05 lr: 3.0521e-06  eta: 4:54:47  time: 0.4148  data_time: 0.0098  memory: 5967  grad_norm: 535.3834  loss: 18.8450  decode.loss_cls: 0.1370  decode.loss_mask: 0.9979  decode.loss_dice: 0.6916  decode.d0.loss_cls: 0.5475  decode.d0.loss_mask: 0.9720  decode.d0.loss_dice: 0.6772  decode.d1.loss_cls: 0.1169  decode.d1.loss_mask: 1.0186  decode.d1.loss_dice: 0.7208  decode.d2.loss_cls: 0.1403  decode.d2.loss_mask: 0.9944  decode.d2.loss_dice: 0.7019  decode.d3.loss_cls: 0.1317  decode.d3.loss_mask: 1.0181  decode.d3.loss_dice: 0.7091  decode.d4.loss_cls: 0.1265  decode.d4.loss_mask: 1.0061  decode.d4.loss_dice: 0.7041  decode.d5.loss_cls: 0.1559  decode.d5.loss_mask: 1.0087  decode.d5.loss_dice: 0.6996  decode.d6.loss_cls: 0.1362  decode.d6.loss_mask: 1.0086  decode.d6.loss_dice: 0.6963  decode.d7.loss_cls: 0.1393  decode.d7.loss_mask: 1.0206  decode.d7.loss_dice: 0.7102  decode.d8.loss_cls: 0.1273  decode.d8.loss_mask: 1.0176  decode.d8.loss_dice: 0.7129
05/27 00:50:19 - mmengine - INFO - Iter(train) [117250/160000]  base_lr: 3.0489e-05 lr: 3.0489e-06  eta: 4:54:26  time: 0.4155  data_time: 0.0097  memory: 5972  grad_norm: 638.3499  loss: 20.4928  decode.loss_cls: 0.1706  decode.loss_mask: 1.0794  decode.loss_dice: 0.7147  decode.d0.loss_cls: 0.7106  decode.d0.loss_mask: 1.0331  decode.d0.loss_dice: 0.7092  decode.d1.loss_cls: 0.1961  decode.d1.loss_mask: 1.1180  decode.d1.loss_dice: 0.7419  decode.d2.loss_cls: 0.1483  decode.d2.loss_mask: 1.0978  decode.d2.loss_dice: 0.7745  decode.d3.loss_cls: 0.1775  decode.d3.loss_mask: 1.1097  decode.d3.loss_dice: 0.7503  decode.d4.loss_cls: 0.1890  decode.d4.loss_mask: 1.0797  decode.d4.loss_dice: 0.7275  decode.d5.loss_cls: 0.1935  decode.d5.loss_mask: 1.0800  decode.d5.loss_dice: 0.7354  decode.d6.loss_cls: 0.1656  decode.d6.loss_mask: 1.0780  decode.d6.loss_dice: 0.7380  decode.d7.loss_cls: 0.2036  decode.d7.loss_mask: 1.0797  decode.d7.loss_dice: 0.7308  decode.d8.loss_cls: 0.1786  decode.d8.loss_mask: 1.0684  decode.d8.loss_dice: 0.7132
05/27 00:50:40 - mmengine - INFO - Iter(train) [117300/160000]  base_lr: 3.0456e-05 lr: 3.0456e-06  eta: 4:54:05  time: 0.4164  data_time: 0.0097  memory: 5966  grad_norm: 562.3401  loss: 20.2564  decode.loss_cls: 0.2395  decode.loss_mask: 0.9746  decode.loss_dice: 0.7109  decode.d0.loss_cls: 0.7523  decode.d0.loss_mask: 0.9321  decode.d0.loss_dice: 0.7243  decode.d1.loss_cls: 0.1400  decode.d1.loss_mask: 1.0459  decode.d1.loss_dice: 0.7727  decode.d2.loss_cls: 0.2297  decode.d2.loss_mask: 1.0799  decode.d2.loss_dice: 0.7727  decode.d3.loss_cls: 0.2969  decode.d3.loss_mask: 0.9878  decode.d3.loss_dice: 0.7460  decode.d4.loss_cls: 0.2516  decode.d4.loss_mask: 0.9765  decode.d4.loss_dice: 0.7193  decode.d5.loss_cls: 0.2331  decode.d5.loss_mask: 1.0001  decode.d5.loss_dice: 0.7230  decode.d6.loss_cls: 0.2057  decode.d6.loss_mask: 1.0416  decode.d6.loss_dice: 0.7498  decode.d7.loss_cls: 0.1971  decode.d7.loss_mask: 1.0444  decode.d7.loss_dice: 0.7747  decode.d8.loss_cls: 0.2281  decode.d8.loss_mask: 0.9864  decode.d8.loss_dice: 0.7197
05/27 00:51:01 - mmengine - INFO - Iter(train) [117350/160000]  base_lr: 3.0424e-05 lr: 3.0424e-06  eta: 4:53:45  time: 0.4151  data_time: 0.0097  memory: 5983  grad_norm: 699.1506  loss: 17.6207  decode.loss_cls: 0.2570  decode.loss_mask: 0.9141  decode.loss_dice: 0.5513  decode.d0.loss_cls: 0.6928  decode.d0.loss_mask: 0.8937  decode.d0.loss_dice: 0.5715  decode.d1.loss_cls: 0.2861  decode.d1.loss_mask: 0.8849  decode.d1.loss_dice: 0.5693  decode.d2.loss_cls: 0.2442  decode.d2.loss_mask: 0.9157  decode.d2.loss_dice: 0.5711  decode.d3.loss_cls: 0.1977  decode.d3.loss_mask: 0.9157  decode.d3.loss_dice: 0.5657  decode.d4.loss_cls: 0.2423  decode.d4.loss_mask: 0.9003  decode.d4.loss_dice: 0.5757  decode.d5.loss_cls: 0.2093  decode.d5.loss_mask: 0.9362  decode.d5.loss_dice: 0.5734  decode.d6.loss_cls: 0.2723  decode.d6.loss_mask: 0.8654  decode.d6.loss_dice: 0.5517  decode.d7.loss_cls: 0.2134  decode.d7.loss_mask: 0.9411  decode.d7.loss_dice: 0.5755  decode.d8.loss_cls: 0.2351  decode.d8.loss_mask: 0.9249  decode.d8.loss_dice: 0.5735
05/27 00:51:21 - mmengine - INFO - Iter(train) [117400/160000]  base_lr: 3.0392e-05 lr: 3.0392e-06  eta: 4:53:24  time: 0.4149  data_time: 0.0097  memory: 5971  grad_norm: 689.1395  loss: 24.8484  decode.loss_cls: 0.2839  decode.loss_mask: 1.3105  decode.loss_dice: 0.8769  decode.d0.loss_cls: 0.7740  decode.d0.loss_mask: 1.2320  decode.d0.loss_dice: 0.8739  decode.d1.loss_cls: 0.2956  decode.d1.loss_mask: 1.2524  decode.d1.loss_dice: 0.8857  decode.d2.loss_cls: 0.2857  decode.d2.loss_mask: 1.2430  decode.d2.loss_dice: 0.8699  decode.d3.loss_cls: 0.3039  decode.d3.loss_mask: 1.2602  decode.d3.loss_dice: 0.8713  decode.d4.loss_cls: 0.2815  decode.d4.loss_mask: 1.2928  decode.d4.loss_dice: 0.8776  decode.d5.loss_cls: 0.2514  decode.d5.loss_mask: 1.2740  decode.d5.loss_dice: 0.8550  decode.d6.loss_cls: 0.2659  decode.d6.loss_mask: 1.3229  decode.d6.loss_dice: 0.8880  decode.d7.loss_cls: 0.2767  decode.d7.loss_mask: 1.3160  decode.d7.loss_dice: 0.8725  decode.d8.loss_cls: 0.2780  decode.d8.loss_mask: 1.2941  decode.d8.loss_dice: 0.8832
05/27 00:51:42 - mmengine - INFO - Iter(train) [117450/160000]  base_lr: 3.0360e-05 lr: 3.0360e-06  eta: 4:53:03  time: 0.4143  data_time: 0.0097  memory: 5967  grad_norm: 613.5919  loss: 21.4688  decode.loss_cls: 0.1570  decode.loss_mask: 1.1847  decode.loss_dice: 0.7746  decode.d0.loss_cls: 0.5860  decode.d0.loss_mask: 1.2053  decode.d0.loss_dice: 0.7498  decode.d1.loss_cls: 0.1390  decode.d1.loss_mask: 1.2008  decode.d1.loss_dice: 0.7674  decode.d2.loss_cls: 0.1448  decode.d2.loss_mask: 1.1992  decode.d2.loss_dice: 0.7549  decode.d3.loss_cls: 0.1331  decode.d3.loss_mask: 1.2266  decode.d3.loss_dice: 0.7566  decode.d4.loss_cls: 0.1312  decode.d4.loss_mask: 1.2044  decode.d4.loss_dice: 0.7635  decode.d5.loss_cls: 0.1534  decode.d5.loss_mask: 1.1873  decode.d5.loss_dice: 0.7518  decode.d6.loss_cls: 0.1400  decode.d6.loss_mask: 1.1812  decode.d6.loss_dice: 0.7680  decode.d7.loss_cls: 0.1526  decode.d7.loss_mask: 1.2084  decode.d7.loss_dice: 0.7695  decode.d8.loss_cls: 0.1497  decode.d8.loss_mask: 1.1732  decode.d8.loss_dice: 0.7551
05/27 00:52:03 - mmengine - INFO - Iter(train) [117500/160000]  base_lr: 3.0328e-05 lr: 3.0328e-06  eta: 4:52:43  time: 0.4132  data_time: 0.0098  memory: 5974  grad_norm: 600.7690  loss: 20.8379  decode.loss_cls: 0.1408  decode.loss_mask: 1.1632  decode.loss_dice: 0.7110  decode.d0.loss_cls: 0.6222  decode.d0.loss_mask: 1.1289  decode.d0.loss_dice: 0.7311  decode.d1.loss_cls: 0.1516  decode.d1.loss_mask: 1.1521  decode.d1.loss_dice: 0.7163  decode.d2.loss_cls: 0.1435  decode.d2.loss_mask: 1.1799  decode.d2.loss_dice: 0.7142  decode.d3.loss_cls: 0.1513  decode.d3.loss_mask: 1.1510  decode.d3.loss_dice: 0.7253  decode.d4.loss_cls: 0.1759  decode.d4.loss_mask: 1.1655  decode.d4.loss_dice: 0.7115  decode.d5.loss_cls: 0.1532  decode.d5.loss_mask: 1.1505  decode.d5.loss_dice: 0.7207  decode.d6.loss_cls: 0.1777  decode.d6.loss_mask: 1.1806  decode.d6.loss_dice: 0.7237  decode.d7.loss_cls: 0.1671  decode.d7.loss_mask: 1.1580  decode.d7.loss_dice: 0.7133  decode.d8.loss_cls: 0.1785  decode.d8.loss_mask: 1.1581  decode.d8.loss_dice: 0.7213
05/27 00:52:24 - mmengine - INFO - Iter(train) [117550/160000]  base_lr: 3.0296e-05 lr: 3.0296e-06  eta: 4:52:22  time: 0.4148  data_time: 0.0097  memory: 5972  grad_norm: 476.6521  loss: 17.2048  decode.loss_cls: 0.1826  decode.loss_mask: 0.8969  decode.loss_dice: 0.6188  decode.d0.loss_cls: 0.6180  decode.d0.loss_mask: 0.8812  decode.d0.loss_dice: 0.6197  decode.d1.loss_cls: 0.2120  decode.d1.loss_mask: 0.8781  decode.d1.loss_dice: 0.6174  decode.d2.loss_cls: 0.1924  decode.d2.loss_mask: 0.8853  decode.d2.loss_dice: 0.6004  decode.d3.loss_cls: 0.1942  decode.d3.loss_mask: 0.8895  decode.d3.loss_dice: 0.6030  decode.d4.loss_cls: 0.1892  decode.d4.loss_mask: 0.8915  decode.d4.loss_dice: 0.5868  decode.d5.loss_cls: 0.1889  decode.d5.loss_mask: 0.8813  decode.d5.loss_dice: 0.5926  decode.d6.loss_cls: 0.1783  decode.d6.loss_mask: 0.9024  decode.d6.loss_dice: 0.6091  decode.d7.loss_cls: 0.1798  decode.d7.loss_mask: 0.8624  decode.d7.loss_dice: 0.5876  decode.d8.loss_cls: 0.1935  decode.d8.loss_mask: 0.8722  decode.d8.loss_dice: 0.5997
05/27 00:52:45 - mmengine - INFO - Iter(train) [117600/160000]  base_lr: 3.0264e-05 lr: 3.0264e-06  eta: 4:52:02  time: 0.4144  data_time: 0.0097  memory: 5976  grad_norm: 1033.4728  loss: 19.7960  decode.loss_cls: 0.2132  decode.loss_mask: 1.0451  decode.loss_dice: 0.6302  decode.d0.loss_cls: 0.6804  decode.d0.loss_mask: 1.0320  decode.d0.loss_dice: 0.6364  decode.d1.loss_cls: 0.2004  decode.d1.loss_mask: 1.0687  decode.d1.loss_dice: 0.6536  decode.d2.loss_cls: 0.1984  decode.d2.loss_mask: 1.0753  decode.d2.loss_dice: 0.6536  decode.d3.loss_cls: 0.2298  decode.d3.loss_mask: 1.0544  decode.d3.loss_dice: 0.6712  decode.d4.loss_cls: 0.2125  decode.d4.loss_mask: 1.0794  decode.d4.loss_dice: 0.6648  decode.d5.loss_cls: 0.2092  decode.d5.loss_mask: 1.0469  decode.d5.loss_dice: 0.6750  decode.d6.loss_cls: 0.2146  decode.d6.loss_mask: 1.0899  decode.d6.loss_dice: 0.6649  decode.d7.loss_cls: 0.2269  decode.d7.loss_mask: 1.0783  decode.d7.loss_dice: 0.6497  decode.d8.loss_cls: 0.2193  decode.d8.loss_mask: 1.0691  decode.d8.loss_dice: 0.6527
05/27 00:53:05 - mmengine - INFO - Iter(train) [117650/160000]  base_lr: 3.0232e-05 lr: 3.0232e-06  eta: 4:51:41  time: 0.4140  data_time: 0.0098  memory: 5980  grad_norm: 537.8600  loss: 18.0100  decode.loss_cls: 0.0960  decode.loss_mask: 0.9376  decode.loss_dice: 0.7036  decode.d0.loss_cls: 0.5759  decode.d0.loss_mask: 0.9240  decode.d0.loss_dice: 0.6771  decode.d1.loss_cls: 0.1727  decode.d1.loss_mask: 0.9098  decode.d1.loss_dice: 0.6733  decode.d2.loss_cls: 0.1486  decode.d2.loss_mask: 0.9293  decode.d2.loss_dice: 0.7081  decode.d3.loss_cls: 0.1265  decode.d3.loss_mask: 0.9262  decode.d3.loss_dice: 0.6858  decode.d4.loss_cls: 0.1294  decode.d4.loss_mask: 0.9274  decode.d4.loss_dice: 0.6905  decode.d5.loss_cls: 0.1486  decode.d5.loss_mask: 0.9215  decode.d5.loss_dice: 0.6856  decode.d6.loss_cls: 0.1244  decode.d6.loss_mask: 0.9654  decode.d6.loss_dice: 0.7003  decode.d7.loss_cls: 0.1254  decode.d7.loss_mask: 0.9420  decode.d7.loss_dice: 0.7226  decode.d8.loss_cls: 0.1039  decode.d8.loss_mask: 0.9374  decode.d8.loss_dice: 0.6911
05/27 00:53:26 - mmengine - INFO - Iter(train) [117700/160000]  base_lr: 3.0200e-05 lr: 3.0200e-06  eta: 4:51:20  time: 0.4144  data_time: 0.0097  memory: 5976  grad_norm: 650.0933  loss: 16.9809  decode.loss_cls: 0.0933  decode.loss_mask: 0.8812  decode.loss_dice: 0.6326  decode.d0.loss_cls: 0.6738  decode.d0.loss_mask: 0.8341  decode.d0.loss_dice: 0.5988  decode.d1.loss_cls: 0.1251  decode.d1.loss_mask: 0.8920  decode.d1.loss_dice: 0.6611  decode.d2.loss_cls: 0.1489  decode.d2.loss_mask: 0.8878  decode.d2.loss_dice: 0.6487  decode.d3.loss_cls: 0.1288  decode.d3.loss_mask: 0.8876  decode.d3.loss_dice: 0.6347  decode.d4.loss_cls: 0.1438  decode.d4.loss_mask: 0.8920  decode.d4.loss_dice: 0.6397  decode.d5.loss_cls: 0.1207  decode.d5.loss_mask: 0.8851  decode.d5.loss_dice: 0.6282  decode.d6.loss_cls: 0.1557  decode.d6.loss_mask: 0.8829  decode.d6.loss_dice: 0.6167  decode.d7.loss_cls: 0.1275  decode.d7.loss_mask: 0.8930  decode.d7.loss_dice: 0.6330  decode.d8.loss_cls: 0.1328  decode.d8.loss_mask: 0.8834  decode.d8.loss_dice: 0.6180
05/27 00:53:47 - mmengine - INFO - Iter(train) [117750/160000]  base_lr: 3.0167e-05 lr: 3.0167e-06  eta: 4:51:00  time: 0.4144  data_time: 0.0097  memory: 5968  grad_norm: 614.6747  loss: 18.7207  decode.loss_cls: 0.2371  decode.loss_mask: 0.9640  decode.loss_dice: 0.6607  decode.d0.loss_cls: 0.6574  decode.d0.loss_mask: 0.9478  decode.d0.loss_dice: 0.6538  decode.d1.loss_cls: 0.2073  decode.d1.loss_mask: 0.9439  decode.d1.loss_dice: 0.6644  decode.d2.loss_cls: 0.2258  decode.d2.loss_mask: 0.9473  decode.d2.loss_dice: 0.6644  decode.d3.loss_cls: 0.2278  decode.d3.loss_mask: 0.9351  decode.d3.loss_dice: 0.6454  decode.d4.loss_cls: 0.2306  decode.d4.loss_mask: 0.9270  decode.d4.loss_dice: 0.6440  decode.d5.loss_cls: 0.2139  decode.d5.loss_mask: 0.9653  decode.d5.loss_dice: 0.6580  decode.d6.loss_cls: 0.2080  decode.d6.loss_mask: 0.9495  decode.d6.loss_dice: 0.6695  decode.d7.loss_cls: 0.1868  decode.d7.loss_mask: 0.9570  decode.d7.loss_dice: 0.6729  decode.d8.loss_cls: 0.2082  decode.d8.loss_mask: 0.9732  decode.d8.loss_dice: 0.6744
05/27 00:54:08 - mmengine - INFO - Iter(train) [117800/160000]  base_lr: 3.0135e-05 lr: 3.0135e-06  eta: 4:50:39  time: 0.4153  data_time: 0.0098  memory: 5976  grad_norm: 538.0431  loss: 19.3912  decode.loss_cls: 0.0898  decode.loss_mask: 1.1080  decode.loss_dice: 0.6978  decode.d0.loss_cls: 0.6541  decode.d0.loss_mask: 1.0937  decode.d0.loss_dice: 0.7095  decode.d1.loss_cls: 0.1408  decode.d1.loss_mask: 1.0657  decode.d1.loss_dice: 0.6905  decode.d2.loss_cls: 0.1498  decode.d2.loss_mask: 1.0963  decode.d2.loss_dice: 0.6904  decode.d3.loss_cls: 0.1483  decode.d3.loss_mask: 1.0837  decode.d3.loss_dice: 0.6668  decode.d4.loss_cls: 0.1306  decode.d4.loss_mask: 1.0882  decode.d4.loss_dice: 0.6908  decode.d5.loss_cls: 0.1200  decode.d5.loss_mask: 1.0611  decode.d5.loss_dice: 0.6552  decode.d6.loss_cls: 0.1218  decode.d6.loss_mask: 1.0562  decode.d6.loss_dice: 0.6683  decode.d7.loss_cls: 0.1161  decode.d7.loss_mask: 1.0612  decode.d7.loss_dice: 0.6639  decode.d8.loss_cls: 0.1097  decode.d8.loss_mask: 1.0924  decode.d8.loss_dice: 0.6706
05/27 00:54:28 - mmengine - INFO - Iter(train) [117850/160000]  base_lr: 3.0103e-05 lr: 3.0103e-06  eta: 4:50:18  time: 0.4161  data_time: 0.0098  memory: 5970  grad_norm: 550.1049  loss: 22.3622  decode.loss_cls: 0.2135  decode.loss_mask: 1.0939  decode.loss_dice: 0.8907  decode.d0.loss_cls: 0.6747  decode.d0.loss_mask: 1.0498  decode.d0.loss_dice: 0.8792  decode.d1.loss_cls: 0.2511  decode.d1.loss_mask: 1.1316  decode.d1.loss_dice: 0.9046  decode.d2.loss_cls: 0.1965  decode.d2.loss_mask: 1.1149  decode.d2.loss_dice: 0.8791  decode.d3.loss_cls: 0.1980  decode.d3.loss_mask: 1.1022  decode.d3.loss_dice: 0.8542  decode.d4.loss_cls: 0.2261  decode.d4.loss_mask: 1.0827  decode.d4.loss_dice: 0.8800  decode.d5.loss_cls: 0.2443  decode.d5.loss_mask: 1.0395  decode.d5.loss_dice: 0.8595  decode.d6.loss_cls: 0.2572  decode.d6.loss_mask: 1.0574  decode.d6.loss_dice: 0.8695  decode.d7.loss_cls: 0.2495  decode.d7.loss_mask: 1.0873  decode.d7.loss_dice: 0.8586  decode.d8.loss_cls: 0.2357  decode.d8.loss_mask: 1.1064  decode.d8.loss_dice: 0.8747
05/27 00:54:49 - mmengine - INFO - Iter(train) [117900/160000]  base_lr: 3.0071e-05 lr: 3.0071e-06  eta: 4:49:58  time: 0.4148  data_time: 0.0098  memory: 5968  grad_norm: 621.0476  loss: 21.6297  decode.loss_cls: 0.1847  decode.loss_mask: 1.2001  decode.loss_dice: 0.7424  decode.d0.loss_cls: 0.6261  decode.d0.loss_mask: 1.1243  decode.d0.loss_dice: 0.7096  decode.d1.loss_cls: 0.1448  decode.d1.loss_mask: 1.2203  decode.d1.loss_dice: 0.7464  decode.d2.loss_cls: 0.1706  decode.d2.loss_mask: 1.1638  decode.d2.loss_dice: 0.7410  decode.d3.loss_cls: 0.1562  decode.d3.loss_mask: 1.2859  decode.d3.loss_dice: 0.7734  decode.d4.loss_cls: 0.1865  decode.d4.loss_mask: 1.1996  decode.d4.loss_dice: 0.7485  decode.d5.loss_cls: 0.1998  decode.d5.loss_mask: 1.1602  decode.d5.loss_dice: 0.7532  decode.d6.loss_cls: 0.2028  decode.d6.loss_mask: 1.1969  decode.d6.loss_dice: 0.7422  decode.d7.loss_cls: 0.1770  decode.d7.loss_mask: 1.1859  decode.d7.loss_dice: 0.7374  decode.d8.loss_cls: 0.1468  decode.d8.loss_mask: 1.2309  decode.d8.loss_dice: 0.7723
05/27 00:55:10 - mmengine - INFO - Iter(train) [117950/160000]  base_lr: 3.0039e-05 lr: 3.0039e-06  eta: 4:49:37  time: 0.4160  data_time: 0.0097  memory: 5974  grad_norm: 654.7703  loss: 19.5723  decode.loss_cls: 0.1638  decode.loss_mask: 1.0275  decode.loss_dice: 0.6561  decode.d0.loss_cls: 0.5921  decode.d0.loss_mask: 1.0386  decode.d0.loss_dice: 0.6843  decode.d1.loss_cls: 0.1477  decode.d1.loss_mask: 1.0493  decode.d1.loss_dice: 0.6913  decode.d2.loss_cls: 0.1248  decode.d2.loss_mask: 1.1152  decode.d2.loss_dice: 0.6876  decode.d3.loss_cls: 0.1223  decode.d3.loss_mask: 1.1372  decode.d3.loss_dice: 0.6961  decode.d4.loss_cls: 0.1676  decode.d4.loss_mask: 1.0602  decode.d4.loss_dice: 0.7002  decode.d5.loss_cls: 0.1644  decode.d5.loss_mask: 1.0502  decode.d5.loss_dice: 0.6838  decode.d6.loss_cls: 0.2028  decode.d6.loss_mask: 1.0044  decode.d6.loss_dice: 0.6724  decode.d7.loss_cls: 0.1786  decode.d7.loss_mask: 1.1093  decode.d7.loss_dice: 0.7394  decode.d8.loss_cls: 0.1696  decode.d8.loss_mask: 1.0314  decode.d8.loss_dice: 0.7042
05/27 00:55:31 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 00:55:31 - mmengine - INFO - Iter(train) [118000/160000]  base_lr: 3.0007e-05 lr: 3.0007e-06  eta: 4:49:17  time: 0.4157  data_time: 0.0098  memory: 5981  grad_norm: 423.9563  loss: 14.7530  decode.loss_cls: 0.0547  decode.loss_mask: 0.7871  decode.loss_dice: 0.5701  decode.d0.loss_cls: 0.5361  decode.d0.loss_mask: 0.7406  decode.d0.loss_dice: 0.5546  decode.d1.loss_cls: 0.1121  decode.d1.loss_mask: 0.7779  decode.d1.loss_dice: 0.5683  decode.d2.loss_cls: 0.0970  decode.d2.loss_mask: 0.7712  decode.d2.loss_dice: 0.5634  decode.d3.loss_cls: 0.1150  decode.d3.loss_mask: 0.7709  decode.d3.loss_dice: 0.5628  decode.d4.loss_cls: 0.1222  decode.d4.loss_mask: 0.7710  decode.d4.loss_dice: 0.5660  decode.d5.loss_cls: 0.1097  decode.d5.loss_mask: 0.7654  decode.d5.loss_dice: 0.5582  decode.d6.loss_cls: 0.0878  decode.d6.loss_mask: 0.7707  decode.d6.loss_dice: 0.5723  decode.d7.loss_cls: 0.0856  decode.d7.loss_mask: 0.7724  decode.d7.loss_dice: 0.5689  decode.d8.loss_cls: 0.0633  decode.d8.loss_mask: 0.7866  decode.d8.loss_dice: 0.5711
05/27 00:55:52 - mmengine - INFO - Iter(train) [118050/160000]  base_lr: 2.9975e-05 lr: 2.9975e-06  eta: 4:48:56  time: 0.4153  data_time: 0.0097  memory: 5974  grad_norm: 591.8655  loss: 17.4005  decode.loss_cls: 0.1875  decode.loss_mask: 0.9006  decode.loss_dice: 0.5615  decode.d0.loss_cls: 0.6380  decode.d0.loss_mask: 0.9419  decode.d0.loss_dice: 0.6022  decode.d1.loss_cls: 0.2119  decode.d1.loss_mask: 0.8743  decode.d1.loss_dice: 0.5776  decode.d2.loss_cls: 0.1805  decode.d2.loss_mask: 0.8936  decode.d2.loss_dice: 0.5665  decode.d3.loss_cls: 0.1795  decode.d3.loss_mask: 0.9186  decode.d3.loss_dice: 0.5544  decode.d4.loss_cls: 0.1619  decode.d4.loss_mask: 0.9475  decode.d4.loss_dice: 0.6169  decode.d5.loss_cls: 0.2306  decode.d5.loss_mask: 0.9441  decode.d5.loss_dice: 0.5959  decode.d6.loss_cls: 0.1985  decode.d6.loss_mask: 0.9113  decode.d6.loss_dice: 0.5844  decode.d7.loss_cls: 0.1759  decode.d7.loss_mask: 0.9292  decode.d7.loss_dice: 0.6126  decode.d8.loss_cls: 0.1755  decode.d8.loss_mask: 0.9329  decode.d8.loss_dice: 0.5948
05/27 00:56:12 - mmengine - INFO - Iter(train) [118100/160000]  base_lr: 2.9942e-05 lr: 2.9942e-06  eta: 4:48:35  time: 0.4155  data_time: 0.0099  memory: 5969  grad_norm: 824.5983  loss: 20.3372  decode.loss_cls: 0.1264  decode.loss_mask: 1.1042  decode.loss_dice: 0.7477  decode.d0.loss_cls: 0.6072  decode.d0.loss_mask: 1.0852  decode.d0.loss_dice: 0.7381  decode.d1.loss_cls: 0.1385  decode.d1.loss_mask: 1.1360  decode.d1.loss_dice: 0.7329  decode.d2.loss_cls: 0.1360  decode.d2.loss_mask: 1.1107  decode.d2.loss_dice: 0.7060  decode.d3.loss_cls: 0.1583  decode.d3.loss_mask: 1.0992  decode.d3.loss_dice: 0.7029  decode.d4.loss_cls: 0.1265  decode.d4.loss_mask: 1.1094  decode.d4.loss_dice: 0.7247  decode.d5.loss_cls: 0.1111  decode.d5.loss_mask: 1.0885  decode.d5.loss_dice: 0.7071  decode.d6.loss_cls: 0.1724  decode.d6.loss_mask: 1.1391  decode.d6.loss_dice: 0.7632  decode.d7.loss_cls: 0.1577  decode.d7.loss_mask: 1.1298  decode.d7.loss_dice: 0.7575  decode.d8.loss_cls: 0.1460  decode.d8.loss_mask: 1.1397  decode.d8.loss_dice: 0.7350
05/27 00:56:33 - mmengine - INFO - Iter(train) [118150/160000]  base_lr: 2.9910e-05 lr: 2.9910e-06  eta: 4:48:15  time: 0.4149  data_time: 0.0097  memory: 5975  grad_norm: 609.9037  loss: 19.1821  decode.loss_cls: 0.1539  decode.loss_mask: 0.9984  decode.loss_dice: 0.6916  decode.d0.loss_cls: 0.8487  decode.d0.loss_mask: 0.9420  decode.d0.loss_dice: 0.6894  decode.d1.loss_cls: 0.1827  decode.d1.loss_mask: 1.0205  decode.d1.loss_dice: 0.6820  decode.d2.loss_cls: 0.2253  decode.d2.loss_mask: 0.9495  decode.d2.loss_dice: 0.6498  decode.d3.loss_cls: 0.2368  decode.d3.loss_mask: 0.9748  decode.d3.loss_dice: 0.6776  decode.d4.loss_cls: 0.2012  decode.d4.loss_mask: 0.9712  decode.d4.loss_dice: 0.6775  decode.d5.loss_cls: 0.2163  decode.d5.loss_mask: 0.9533  decode.d5.loss_dice: 0.6440  decode.d6.loss_cls: 0.1856  decode.d6.loss_mask: 1.0208  decode.d6.loss_dice: 0.7075  decode.d7.loss_cls: 0.1651  decode.d7.loss_mask: 0.9999  decode.d7.loss_dice: 0.6897  decode.d8.loss_cls: 0.1751  decode.d8.loss_mask: 0.9826  decode.d8.loss_dice: 0.6691
05/27 00:56:54 - mmengine - INFO - Iter(train) [118200/160000]  base_lr: 2.9878e-05 lr: 2.9878e-06  eta: 4:47:54  time: 0.4152  data_time: 0.0098  memory: 5974  grad_norm: 703.5537  loss: 21.2324  decode.loss_cls: 0.2323  decode.loss_mask: 1.1014  decode.loss_dice: 0.7245  decode.d0.loss_cls: 0.8661  decode.d0.loss_mask: 0.9966  decode.d0.loss_dice: 0.7171  decode.d1.loss_cls: 0.2436  decode.d1.loss_mask: 1.1039  decode.d1.loss_dice: 0.7374  decode.d2.loss_cls: 0.2009  decode.d2.loss_mask: 1.1058  decode.d2.loss_dice: 0.7370  decode.d3.loss_cls: 0.1988  decode.d3.loss_mask: 1.1081  decode.d3.loss_dice: 0.7395  decode.d4.loss_cls: 0.2265  decode.d4.loss_mask: 1.1374  decode.d4.loss_dice: 0.7404  decode.d5.loss_cls: 0.2441  decode.d5.loss_mask: 1.1116  decode.d5.loss_dice: 0.7384  decode.d6.loss_cls: 0.2574  decode.d6.loss_mask: 1.0930  decode.d6.loss_dice: 0.7271  decode.d7.loss_cls: 0.2658  decode.d7.loss_mask: 1.0808  decode.d7.loss_dice: 0.7165  decode.d8.loss_cls: 0.2140  decode.d8.loss_mask: 1.1342  decode.d8.loss_dice: 0.7322
05/27 00:57:15 - mmengine - INFO - Iter(train) [118250/160000]  base_lr: 2.9846e-05 lr: 2.9846e-06  eta: 4:47:33  time: 0.4154  data_time: 0.0097  memory: 5968  grad_norm: 651.5884  loss: 27.4923  decode.loss_cls: 0.3703  decode.loss_mask: 1.3877  decode.loss_dice: 0.9703  decode.d0.loss_cls: 0.8524  decode.d0.loss_mask: 1.2537  decode.d0.loss_dice: 0.9847  decode.d1.loss_cls: 0.3848  decode.d1.loss_mask: 1.3297  decode.d1.loss_dice: 0.9940  decode.d2.loss_cls: 0.3342  decode.d2.loss_mask: 1.4014  decode.d2.loss_dice: 1.0040  decode.d3.loss_cls: 0.3304  decode.d3.loss_mask: 1.4041  decode.d3.loss_dice: 0.9957  decode.d4.loss_cls: 0.3858  decode.d4.loss_mask: 1.3712  decode.d4.loss_dice: 0.9711  decode.d5.loss_cls: 0.3689  decode.d5.loss_mask: 1.3511  decode.d5.loss_dice: 0.9654  decode.d6.loss_cls: 0.3837  decode.d6.loss_mask: 1.3659  decode.d6.loss_dice: 0.9956  decode.d7.loss_cls: 0.3635  decode.d7.loss_mask: 1.3424  decode.d7.loss_dice: 0.9844  decode.d8.loss_cls: 0.3550  decode.d8.loss_mask: 1.3372  decode.d8.loss_dice: 0.9537
05/27 00:57:35 - mmengine - INFO - Iter(train) [118300/160000]  base_lr: 2.9814e-05 lr: 2.9814e-06  eta: 4:47:13  time: 0.4151  data_time: 0.0098  memory: 5975  grad_norm: 534.7530  loss: 20.7711  decode.loss_cls: 0.2568  decode.loss_mask: 1.0368  decode.loss_dice: 0.7143  decode.d0.loss_cls: 0.6555  decode.d0.loss_mask: 1.0630  decode.d0.loss_dice: 0.7461  decode.d1.loss_cls: 0.2544  decode.d1.loss_mask: 1.1021  decode.d1.loss_dice: 0.7153  decode.d2.loss_cls: 0.2723  decode.d2.loss_mask: 1.0564  decode.d2.loss_dice: 0.7266  decode.d3.loss_cls: 0.2399  decode.d3.loss_mask: 1.0583  decode.d3.loss_dice: 0.6972  decode.d4.loss_cls: 0.2604  decode.d4.loss_mask: 1.0467  decode.d4.loss_dice: 0.7345  decode.d5.loss_cls: 0.2239  decode.d5.loss_mask: 1.0851  decode.d5.loss_dice: 0.7106  decode.d6.loss_cls: 0.2761  decode.d6.loss_mask: 1.0311  decode.d6.loss_dice: 0.7103  decode.d7.loss_cls: 0.2640  decode.d7.loss_mask: 1.0610  decode.d7.loss_dice: 0.7391  decode.d8.loss_cls: 0.2457  decode.d8.loss_mask: 1.0690  decode.d8.loss_dice: 0.7185
05/27 00:57:56 - mmengine - INFO - Iter(train) [118350/160000]  base_lr: 2.9782e-05 lr: 2.9782e-06  eta: 4:46:52  time: 0.4250  data_time: 0.0098  memory: 5976  grad_norm: 944.0686  loss: 20.7581  decode.loss_cls: 0.2435  decode.loss_mask: 1.0646  decode.loss_dice: 0.7076  decode.d0.loss_cls: 0.7205  decode.d0.loss_mask: 1.0802  decode.d0.loss_dice: 0.7342  decode.d1.loss_cls: 0.2712  decode.d1.loss_mask: 1.0845  decode.d1.loss_dice: 0.7135  decode.d2.loss_cls: 0.2806  decode.d2.loss_mask: 1.0584  decode.d2.loss_dice: 0.6888  decode.d3.loss_cls: 0.2410  decode.d3.loss_mask: 1.0501  decode.d3.loss_dice: 0.6780  decode.d4.loss_cls: 0.2272  decode.d4.loss_mask: 1.0944  decode.d4.loss_dice: 0.7332  decode.d5.loss_cls: 0.2332  decode.d5.loss_mask: 1.1044  decode.d5.loss_dice: 0.7204  decode.d6.loss_cls: 0.2740  decode.d6.loss_mask: 1.0332  decode.d6.loss_dice: 0.6645  decode.d7.loss_cls: 0.3210  decode.d7.loss_mask: 1.0098  decode.d7.loss_dice: 0.6742  decode.d8.loss_cls: 0.2897  decode.d8.loss_mask: 1.0678  decode.d8.loss_dice: 0.6945
05/27 00:58:17 - mmengine - INFO - Iter(train) [118400/160000]  base_lr: 2.9749e-05 lr: 2.9749e-06  eta: 4:46:32  time: 0.4166  data_time: 0.0111  memory: 5979  grad_norm: 446.8170  loss: 17.7780  decode.loss_cls: 0.0972  decode.loss_mask: 0.9799  decode.loss_dice: 0.6429  decode.d0.loss_cls: 0.6591  decode.d0.loss_mask: 0.9436  decode.d0.loss_dice: 0.6627  decode.d1.loss_cls: 0.0990  decode.d1.loss_mask: 1.0124  decode.d1.loss_dice: 0.6772  decode.d2.loss_cls: 0.1009  decode.d2.loss_mask: 0.9747  decode.d2.loss_dice: 0.6634  decode.d3.loss_cls: 0.1131  decode.d3.loss_mask: 0.9971  decode.d3.loss_dice: 0.6302  decode.d4.loss_cls: 0.1256  decode.d4.loss_mask: 0.9330  decode.d4.loss_dice: 0.6245  decode.d5.loss_cls: 0.1143  decode.d5.loss_mask: 0.9503  decode.d5.loss_dice: 0.6302  decode.d6.loss_cls: 0.0908  decode.d6.loss_mask: 0.9670  decode.d6.loss_dice: 0.6460  decode.d7.loss_cls: 0.0966  decode.d7.loss_mask: 0.9803  decode.d7.loss_dice: 0.6391  decode.d8.loss_cls: 0.0974  decode.d8.loss_mask: 0.9765  decode.d8.loss_dice: 0.6531
05/27 00:58:38 - mmengine - INFO - Iter(train) [118450/160000]  base_lr: 2.9717e-05 lr: 2.9717e-06  eta: 4:46:11  time: 0.4155  data_time: 0.0097  memory: 5969  grad_norm: 517.3752  loss: 17.2629  decode.loss_cls: 0.1315  decode.loss_mask: 0.8720  decode.loss_dice: 0.6412  decode.d0.loss_cls: 0.6840  decode.d0.loss_mask: 0.8249  decode.d0.loss_dice: 0.5952  decode.d1.loss_cls: 0.1667  decode.d1.loss_mask: 0.8953  decode.d1.loss_dice: 0.6623  decode.d2.loss_cls: 0.1654  decode.d2.loss_mask: 0.8655  decode.d2.loss_dice: 0.6504  decode.d3.loss_cls: 0.1599  decode.d3.loss_mask: 0.8606  decode.d3.loss_dice: 0.6507  decode.d4.loss_cls: 0.1514  decode.d4.loss_mask: 0.9031  decode.d4.loss_dice: 0.6652  decode.d5.loss_cls: 0.1451  decode.d5.loss_mask: 0.8862  decode.d5.loss_dice: 0.6680  decode.d6.loss_cls: 0.1415  decode.d6.loss_mask: 0.8773  decode.d6.loss_dice: 0.6588  decode.d7.loss_cls: 0.1386  decode.d7.loss_mask: 0.8839  decode.d7.loss_dice: 0.6702  decode.d8.loss_cls: 0.1148  decode.d8.loss_mask: 0.8856  decode.d8.loss_dice: 0.6477
05/27 00:58:59 - mmengine - INFO - Iter(train) [118500/160000]  base_lr: 2.9685e-05 lr: 2.9685e-06  eta: 4:45:50  time: 0.4175  data_time: 0.0097  memory: 5966  grad_norm: 310.4961  loss: 17.7142  decode.loss_cls: 0.2201  decode.loss_mask: 0.8409  decode.loss_dice: 0.6654  decode.d0.loss_cls: 0.6767  decode.d0.loss_mask: 0.8132  decode.d0.loss_dice: 0.6546  decode.d1.loss_cls: 0.2325  decode.d1.loss_mask: 0.8150  decode.d1.loss_dice: 0.6853  decode.d2.loss_cls: 0.2020  decode.d2.loss_mask: 0.8339  decode.d2.loss_dice: 0.6995  decode.d3.loss_cls: 0.2349  decode.d3.loss_mask: 0.8289  decode.d3.loss_dice: 0.7002  decode.d4.loss_cls: 0.2161  decode.d4.loss_mask: 0.8286  decode.d4.loss_dice: 0.6787  decode.d5.loss_cls: 0.2054  decode.d5.loss_mask: 0.8366  decode.d5.loss_dice: 0.7019  decode.d6.loss_cls: 0.2295  decode.d6.loss_mask: 0.8073  decode.d6.loss_dice: 0.6737  decode.d7.loss_cls: 0.2704  decode.d7.loss_mask: 0.8146  decode.d7.loss_dice: 0.6733  decode.d8.loss_cls: 0.2213  decode.d8.loss_mask: 0.7937  decode.d8.loss_dice: 0.6600
05/27 00:59:19 - mmengine - INFO - Iter(train) [118550/160000]  base_lr: 2.9653e-05 lr: 2.9653e-06  eta: 4:45:30  time: 0.4152  data_time: 0.0097  memory: 5967  grad_norm: 768.2401  loss: 21.7022  decode.loss_cls: 0.3221  decode.loss_mask: 0.9459  decode.loss_dice: 0.8395  decode.d0.loss_cls: 0.7806  decode.d0.loss_mask: 0.9344  decode.d0.loss_dice: 0.7770  decode.d1.loss_cls: 0.3521  decode.d1.loss_mask: 0.9530  decode.d1.loss_dice: 0.8214  decode.d2.loss_cls: 0.3453  decode.d2.loss_mask: 0.9823  decode.d2.loss_dice: 0.8178  decode.d3.loss_cls: 0.3461  decode.d3.loss_mask: 0.9838  decode.d3.loss_dice: 0.8247  decode.d4.loss_cls: 0.3539  decode.d4.loss_mask: 0.9484  decode.d4.loss_dice: 0.8147  decode.d5.loss_cls: 0.3569  decode.d5.loss_mask: 0.9763  decode.d5.loss_dice: 0.8158  decode.d6.loss_cls: 0.3840  decode.d6.loss_mask: 0.9302  decode.d6.loss_dice: 0.8002  decode.d7.loss_cls: 0.3003  decode.d7.loss_mask: 1.0037  decode.d7.loss_dice: 0.8316  decode.d8.loss_cls: 0.2977  decode.d8.loss_mask: 1.0127  decode.d8.loss_dice: 0.8498
05/27 00:59:40 - mmengine - INFO - Iter(train) [118600/160000]  base_lr: 2.9621e-05 lr: 2.9621e-06  eta: 4:45:09  time: 0.4145  data_time: 0.0098  memory: 5976  grad_norm: 573.7649  loss: 17.8846  decode.loss_cls: 0.1510  decode.loss_mask: 0.9369  decode.loss_dice: 0.6458  decode.d0.loss_cls: 0.6398  decode.d0.loss_mask: 0.8630  decode.d0.loss_dice: 0.6518  decode.d1.loss_cls: 0.1180  decode.d1.loss_mask: 0.9404  decode.d1.loss_dice: 0.6662  decode.d2.loss_cls: 0.1481  decode.d2.loss_mask: 0.9474  decode.d2.loss_dice: 0.6735  decode.d3.loss_cls: 0.1854  decode.d3.loss_mask: 0.8991  decode.d3.loss_dice: 0.6292  decode.d4.loss_cls: 0.1730  decode.d4.loss_mask: 0.9409  decode.d4.loss_dice: 0.6596  decode.d5.loss_cls: 0.1687  decode.d5.loss_mask: 0.9491  decode.d5.loss_dice: 0.6570  decode.d6.loss_cls: 0.1863  decode.d6.loss_mask: 0.9284  decode.d6.loss_dice: 0.6439  decode.d7.loss_cls: 0.1581  decode.d7.loss_mask: 0.9222  decode.d7.loss_dice: 0.6522  decode.d8.loss_cls: 0.1221  decode.d8.loss_mask: 0.9576  decode.d8.loss_dice: 0.6699
05/27 01:00:01 - mmengine - INFO - Iter(train) [118650/160000]  base_lr: 2.9588e-05 lr: 2.9588e-06  eta: 4:44:48  time: 0.4151  data_time: 0.0097  memory: 5966  grad_norm: 1014.1249  loss: 18.0024  decode.loss_cls: 0.1653  decode.loss_mask: 1.0083  decode.loss_dice: 0.6101  decode.d0.loss_cls: 0.6241  decode.d0.loss_mask: 0.9120  decode.d0.loss_dice: 0.6038  decode.d1.loss_cls: 0.1414  decode.d1.loss_mask: 0.9741  decode.d1.loss_dice: 0.6289  decode.d2.loss_cls: 0.1694  decode.d2.loss_mask: 0.9731  decode.d2.loss_dice: 0.6126  decode.d3.loss_cls: 0.1446  decode.d3.loss_mask: 1.0234  decode.d3.loss_dice: 0.6199  decode.d4.loss_cls: 0.1811  decode.d4.loss_mask: 0.9641  decode.d4.loss_dice: 0.5997  decode.d5.loss_cls: 0.1492  decode.d5.loss_mask: 1.0383  decode.d5.loss_dice: 0.6166  decode.d6.loss_cls: 0.1681  decode.d6.loss_mask: 1.0024  decode.d6.loss_dice: 0.5987  decode.d7.loss_cls: 0.1603  decode.d7.loss_mask: 0.9787  decode.d7.loss_dice: 0.6079  decode.d8.loss_cls: 0.1824  decode.d8.loss_mask: 0.9516  decode.d8.loss_dice: 0.5924
05/27 01:00:22 - mmengine - INFO - Iter(train) [118700/160000]  base_lr: 2.9556e-05 lr: 2.9556e-06  eta: 4:44:28  time: 0.4148  data_time: 0.0098  memory: 5972  grad_norm: 591.5803  loss: 16.8361  decode.loss_cls: 0.1035  decode.loss_mask: 0.8808  decode.loss_dice: 0.6207  decode.d0.loss_cls: 0.5469  decode.d0.loss_mask: 0.8953  decode.d0.loss_dice: 0.6302  decode.d1.loss_cls: 0.1540  decode.d1.loss_mask: 0.8876  decode.d1.loss_dice: 0.6388  decode.d2.loss_cls: 0.1403  decode.d2.loss_mask: 0.8839  decode.d2.loss_dice: 0.6327  decode.d3.loss_cls: 0.1311  decode.d3.loss_mask: 0.8783  decode.d3.loss_dice: 0.6352  decode.d4.loss_cls: 0.1259  decode.d4.loss_mask: 0.8884  decode.d4.loss_dice: 0.6235  decode.d5.loss_cls: 0.1289  decode.d5.loss_mask: 0.8865  decode.d5.loss_dice: 0.6416  decode.d6.loss_cls: 0.1022  decode.d6.loss_mask: 0.8907  decode.d6.loss_dice: 0.6407  decode.d7.loss_cls: 0.1232  decode.d7.loss_mask: 0.8782  decode.d7.loss_dice: 0.6237  decode.d8.loss_cls: 0.1184  decode.d8.loss_mask: 0.8829  decode.d8.loss_dice: 0.6218
05/27 01:00:43 - mmengine - INFO - Iter(train) [118750/160000]  base_lr: 2.9524e-05 lr: 2.9524e-06  eta: 4:44:07  time: 0.4154  data_time: 0.0097  memory: 5982  grad_norm: 591.7892  loss: 19.8290  decode.loss_cls: 0.2256  decode.loss_mask: 0.9803  decode.loss_dice: 0.6993  decode.d0.loss_cls: 0.6755  decode.d0.loss_mask: 0.9977  decode.d0.loss_dice: 0.7311  decode.d1.loss_cls: 0.2525  decode.d1.loss_mask: 0.9875  decode.d1.loss_dice: 0.7059  decode.d2.loss_cls: 0.2371  decode.d2.loss_mask: 0.9784  decode.d2.loss_dice: 0.7165  decode.d3.loss_cls: 0.2356  decode.d3.loss_mask: 0.9853  decode.d3.loss_dice: 0.7161  decode.d4.loss_cls: 0.2195  decode.d4.loss_mask: 0.9763  decode.d4.loss_dice: 0.7319  decode.d5.loss_cls: 0.2447  decode.d5.loss_mask: 0.9848  decode.d5.loss_dice: 0.7155  decode.d6.loss_cls: 0.2547  decode.d6.loss_mask: 0.9877  decode.d6.loss_dice: 0.7212  decode.d7.loss_cls: 0.2383  decode.d7.loss_mask: 0.9807  decode.d7.loss_dice: 0.7167  decode.d8.loss_cls: 0.2047  decode.d8.loss_mask: 1.0299  decode.d8.loss_dice: 0.6978
05/27 01:01:03 - mmengine - INFO - Iter(train) [118800/160000]  base_lr: 2.9492e-05 lr: 2.9492e-06  eta: 4:43:47  time: 0.4147  data_time: 0.0098  memory: 5975  grad_norm: 539.8404  loss: 16.5585  decode.loss_cls: 0.0727  decode.loss_mask: 0.9454  decode.loss_dice: 0.5868  decode.d0.loss_cls: 0.5110  decode.d0.loss_mask: 0.9320  decode.d0.loss_dice: 0.5759  decode.d1.loss_cls: 0.0800  decode.d1.loss_mask: 0.9610  decode.d1.loss_dice: 0.5905  decode.d2.loss_cls: 0.0857  decode.d2.loss_mask: 0.9440  decode.d2.loss_dice: 0.5841  decode.d3.loss_cls: 0.0708  decode.d3.loss_mask: 0.9511  decode.d3.loss_dice: 0.5844  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 0.9620  decode.d4.loss_dice: 0.5883  decode.d5.loss_cls: 0.0845  decode.d5.loss_mask: 0.9436  decode.d5.loss_dice: 0.5976  decode.d6.loss_cls: 0.0660  decode.d6.loss_mask: 0.9607  decode.d6.loss_dice: 0.5978  decode.d7.loss_cls: 0.0833  decode.d7.loss_mask: 0.9354  decode.d7.loss_dice: 0.5875  decode.d8.loss_cls: 0.0671  decode.d8.loss_mask: 0.9444  decode.d8.loss_dice: 0.5937
05/27 01:01:24 - mmengine - INFO - Iter(train) [118850/160000]  base_lr: 2.9460e-05 lr: 2.9460e-06  eta: 4:43:26  time: 0.4150  data_time: 0.0098  memory: 5983  grad_norm: 486.5867  loss: 14.1371  decode.loss_cls: 0.0777  decode.loss_mask: 0.7378  decode.loss_dice: 0.5515  decode.d0.loss_cls: 0.5524  decode.d0.loss_mask: 0.7333  decode.d0.loss_dice: 0.5368  decode.d1.loss_cls: 0.0980  decode.d1.loss_mask: 0.7391  decode.d1.loss_dice: 0.5558  decode.d2.loss_cls: 0.0896  decode.d2.loss_mask: 0.7450  decode.d2.loss_dice: 0.5442  decode.d3.loss_cls: 0.0762  decode.d3.loss_mask: 0.7393  decode.d3.loss_dice: 0.5529  decode.d4.loss_cls: 0.0741  decode.d4.loss_mask: 0.7403  decode.d4.loss_dice: 0.5417  decode.d5.loss_cls: 0.0820  decode.d5.loss_mask: 0.7351  decode.d5.loss_dice: 0.5585  decode.d6.loss_cls: 0.0871  decode.d6.loss_mask: 0.7309  decode.d6.loss_dice: 0.5620  decode.d7.loss_cls: 0.0755  decode.d7.loss_mask: 0.7349  decode.d7.loss_dice: 0.5496  decode.d8.loss_cls: 0.0659  decode.d8.loss_mask: 0.7311  decode.d8.loss_dice: 0.5389
05/27 01:01:45 - mmengine - INFO - Iter(train) [118900/160000]  base_lr: 2.9427e-05 lr: 2.9427e-06  eta: 4:43:05  time: 0.4159  data_time: 0.0099  memory: 5974  grad_norm: 427.4448  loss: 19.6995  decode.loss_cls: 0.2061  decode.loss_mask: 0.9651  decode.loss_dice: 0.7313  decode.d0.loss_cls: 0.6064  decode.d0.loss_mask: 1.0208  decode.d0.loss_dice: 0.7704  decode.d1.loss_cls: 0.2027  decode.d1.loss_mask: 1.0428  decode.d1.loss_dice: 0.7352  decode.d2.loss_cls: 0.2016  decode.d2.loss_mask: 0.9768  decode.d2.loss_dice: 0.7290  decode.d3.loss_cls: 0.1988  decode.d3.loss_mask: 0.9726  decode.d3.loss_dice: 0.7258  decode.d4.loss_cls: 0.1978  decode.d4.loss_mask: 0.9568  decode.d4.loss_dice: 0.7254  decode.d5.loss_cls: 0.2093  decode.d5.loss_mask: 0.9766  decode.d5.loss_dice: 0.7317  decode.d6.loss_cls: 0.2359  decode.d6.loss_mask: 0.9763  decode.d6.loss_dice: 0.7452  decode.d7.loss_cls: 0.2452  decode.d7.loss_mask: 0.9619  decode.d7.loss_dice: 0.7318  decode.d8.loss_cls: 0.2017  decode.d8.loss_mask: 0.9745  decode.d8.loss_dice: 0.7441
05/27 01:02:06 - mmengine - INFO - Iter(train) [118950/160000]  base_lr: 2.9395e-05 lr: 2.9395e-06  eta: 4:42:45  time: 0.4147  data_time: 0.0098  memory: 5967  grad_norm: 308.1024  loss: 15.1851  decode.loss_cls: 0.0760  decode.loss_mask: 0.8242  decode.loss_dice: 0.5605  decode.d0.loss_cls: 0.4703  decode.d0.loss_mask: 0.8440  decode.d0.loss_dice: 0.5833  decode.d1.loss_cls: 0.0915  decode.d1.loss_mask: 0.8207  decode.d1.loss_dice: 0.5633  decode.d2.loss_cls: 0.0731  decode.d2.loss_mask: 0.8305  decode.d2.loss_dice: 0.5660  decode.d3.loss_cls: 0.0701  decode.d3.loss_mask: 0.8378  decode.d3.loss_dice: 0.5799  decode.d4.loss_cls: 0.1043  decode.d4.loss_mask: 0.8194  decode.d4.loss_dice: 0.5773  decode.d5.loss_cls: 0.0781  decode.d5.loss_mask: 0.8254  decode.d5.loss_dice: 0.5741  decode.d6.loss_cls: 0.0628  decode.d6.loss_mask: 0.8374  decode.d6.loss_dice: 0.5732  decode.d7.loss_cls: 0.0890  decode.d7.loss_mask: 0.8217  decode.d7.loss_dice: 0.5714  decode.d8.loss_cls: 0.0753  decode.d8.loss_mask: 0.8280  decode.d8.loss_dice: 0.5566
05/27 01:02:27 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 01:02:27 - mmengine - INFO - Iter(train) [119000/160000]  base_lr: 2.9363e-05 lr: 2.9363e-06  eta: 4:42:24  time: 0.4159  data_time: 0.0098  memory: 5969  grad_norm: 447.4986  loss: 20.1274  decode.loss_cls: 0.2012  decode.loss_mask: 1.0034  decode.loss_dice: 0.7415  decode.d0.loss_cls: 0.7288  decode.d0.loss_mask: 0.9442  decode.d0.loss_dice: 0.7310  decode.d1.loss_cls: 0.2071  decode.d1.loss_mask: 1.0282  decode.d1.loss_dice: 0.7413  decode.d2.loss_cls: 0.2219  decode.d2.loss_mask: 1.0320  decode.d2.loss_dice: 0.7469  decode.d3.loss_cls: 0.2035  decode.d3.loss_mask: 1.0147  decode.d3.loss_dice: 0.7276  decode.d4.loss_cls: 0.2304  decode.d4.loss_mask: 1.0246  decode.d4.loss_dice: 0.6990  decode.d5.loss_cls: 0.2321  decode.d5.loss_mask: 1.0159  decode.d5.loss_dice: 0.7422  decode.d6.loss_cls: 0.2298  decode.d6.loss_mask: 1.0042  decode.d6.loss_dice: 0.7625  decode.d7.loss_cls: 0.2141  decode.d7.loss_mask: 0.9997  decode.d7.loss_dice: 0.7206  decode.d8.loss_cls: 0.2275  decode.d8.loss_mask: 1.0047  decode.d8.loss_dice: 0.7468
05/27 01:02:47 - mmengine - INFO - Iter(train) [119050/160000]  base_lr: 2.9331e-05 lr: 2.9331e-06  eta: 4:42:03  time: 0.4159  data_time: 0.0098  memory: 5975  grad_norm: 530.3410  loss: 22.8644  decode.loss_cls: 0.2011  decode.loss_mask: 1.2231  decode.loss_dice: 0.8017  decode.d0.loss_cls: 0.7473  decode.d0.loss_mask: 1.1484  decode.d0.loss_dice: 0.8180  decode.d1.loss_cls: 0.2326  decode.d1.loss_mask: 1.2195  decode.d1.loss_dice: 0.8186  decode.d2.loss_cls: 0.2251  decode.d2.loss_mask: 1.1980  decode.d2.loss_dice: 0.8029  decode.d3.loss_cls: 0.2153  decode.d3.loss_mask: 1.2152  decode.d3.loss_dice: 0.8244  decode.d4.loss_cls: 0.2286  decode.d4.loss_mask: 1.1910  decode.d4.loss_dice: 0.8079  decode.d5.loss_cls: 0.2189  decode.d5.loss_mask: 1.1919  decode.d5.loss_dice: 0.8048  decode.d6.loss_cls: 0.2245  decode.d6.loss_mask: 1.1988  decode.d6.loss_dice: 0.8199  decode.d7.loss_cls: 0.2475  decode.d7.loss_mask: 1.1819  decode.d7.loss_dice: 0.7975  decode.d8.loss_cls: 0.2278  decode.d8.loss_mask: 1.2213  decode.d8.loss_dice: 0.8110
05/27 01:03:08 - mmengine - INFO - Iter(train) [119100/160000]  base_lr: 2.9299e-05 lr: 2.9299e-06  eta: 4:41:43  time: 0.4146  data_time: 0.0098  memory: 5975  grad_norm: 324.2663  loss: 18.2046  decode.loss_cls: 0.1110  decode.loss_mask: 0.9721  decode.loss_dice: 0.6790  decode.d0.loss_cls: 0.6191  decode.d0.loss_mask: 0.9225  decode.d0.loss_dice: 0.6602  decode.d1.loss_cls: 0.1269  decode.d1.loss_mask: 0.9568  decode.d1.loss_dice: 0.6800  decode.d2.loss_cls: 0.1315  decode.d2.loss_mask: 0.9856  decode.d2.loss_dice: 0.6900  decode.d3.loss_cls: 0.1447  decode.d3.loss_mask: 0.9514  decode.d3.loss_dice: 0.6822  decode.d4.loss_cls: 0.1333  decode.d4.loss_mask: 0.9565  decode.d4.loss_dice: 0.6817  decode.d5.loss_cls: 0.1116  decode.d5.loss_mask: 0.9578  decode.d5.loss_dice: 0.6889  decode.d6.loss_cls: 0.1120  decode.d6.loss_mask: 0.9882  decode.d6.loss_dice: 0.6778  decode.d7.loss_cls: 0.1259  decode.d7.loss_mask: 0.9896  decode.d7.loss_dice: 0.6976  decode.d8.loss_cls: 0.1470  decode.d8.loss_mask: 0.9449  decode.d8.loss_dice: 0.6791
05/27 01:03:29 - mmengine - INFO - Iter(train) [119150/160000]  base_lr: 2.9266e-05 lr: 2.9266e-06  eta: 4:41:22  time: 0.4153  data_time: 0.0099  memory: 5969  grad_norm: 437.0780  loss: 19.8705  decode.loss_cls: 0.1851  decode.loss_mask: 1.0573  decode.loss_dice: 0.6885  decode.d0.loss_cls: 0.7799  decode.d0.loss_mask: 0.9779  decode.d0.loss_dice: 0.6670  decode.d1.loss_cls: 0.1845  decode.d1.loss_mask: 1.0438  decode.d1.loss_dice: 0.6963  decode.d2.loss_cls: 0.1977  decode.d2.loss_mask: 1.0150  decode.d2.loss_dice: 0.6818  decode.d3.loss_cls: 0.1938  decode.d3.loss_mask: 1.0295  decode.d3.loss_dice: 0.7054  decode.d4.loss_cls: 0.1683  decode.d4.loss_mask: 1.0745  decode.d4.loss_dice: 0.7506  decode.d5.loss_cls: 0.1855  decode.d5.loss_mask: 1.0564  decode.d5.loss_dice: 0.6992  decode.d6.loss_cls: 0.2448  decode.d6.loss_mask: 1.0491  decode.d6.loss_dice: 0.6870  decode.d7.loss_cls: 0.2025  decode.d7.loss_mask: 1.0431  decode.d7.loss_dice: 0.6857  decode.d8.loss_cls: 0.1801  decode.d8.loss_mask: 1.0366  decode.d8.loss_dice: 0.7036
05/27 01:03:50 - mmengine - INFO - Iter(train) [119200/160000]  base_lr: 2.9234e-05 lr: 2.9234e-06  eta: 4:41:02  time: 0.4145  data_time: 0.0100  memory: 5966  grad_norm: 842.9839  loss: 24.3524  decode.loss_cls: 0.3105  decode.loss_mask: 1.1867  decode.loss_dice: 0.8378  decode.d0.loss_cls: 0.8141  decode.d0.loss_mask: 1.1653  decode.d0.loss_dice: 0.8451  decode.d1.loss_cls: 0.3166  decode.d1.loss_mask: 1.2788  decode.d1.loss_dice: 0.8736  decode.d2.loss_cls: 0.2799  decode.d2.loss_mask: 1.3157  decode.d2.loss_dice: 0.8956  decode.d3.loss_cls: 0.2786  decode.d3.loss_mask: 1.2370  decode.d3.loss_dice: 0.8553  decode.d4.loss_cls: 0.3007  decode.d4.loss_mask: 1.2320  decode.d4.loss_dice: 0.8538  decode.d5.loss_cls: 0.2834  decode.d5.loss_mask: 1.2366  decode.d5.loss_dice: 0.8681  decode.d6.loss_cls: 0.3076  decode.d6.loss_mask: 1.2039  decode.d6.loss_dice: 0.8647  decode.d7.loss_cls: 0.2804  decode.d7.loss_mask: 1.2325  decode.d7.loss_dice: 0.8601  decode.d8.loss_cls: 0.3218  decode.d8.loss_mask: 1.1789  decode.d8.loss_dice: 0.8371
05/27 01:04:11 - mmengine - INFO - Iter(train) [119250/160000]  base_lr: 2.9202e-05 lr: 2.9202e-06  eta: 4:40:41  time: 0.4157  data_time: 0.0100  memory: 5967  grad_norm: 571.6643  loss: 21.0635  decode.loss_cls: 0.2763  decode.loss_mask: 1.0283  decode.loss_dice: 0.7266  decode.d0.loss_cls: 0.7481  decode.d0.loss_mask: 1.0166  decode.d0.loss_dice: 0.7331  decode.d1.loss_cls: 0.2929  decode.d1.loss_mask: 1.0655  decode.d1.loss_dice: 0.7358  decode.d2.loss_cls: 0.3355  decode.d2.loss_mask: 1.0059  decode.d2.loss_dice: 0.7244  decode.d3.loss_cls: 0.2534  decode.d3.loss_mask: 1.1245  decode.d3.loss_dice: 0.7925  decode.d4.loss_cls: 0.2463  decode.d4.loss_mask: 1.0975  decode.d4.loss_dice: 0.7610  decode.d5.loss_cls: 0.2962  decode.d5.loss_mask: 1.0244  decode.d5.loss_dice: 0.7115  decode.d6.loss_cls: 0.3228  decode.d6.loss_mask: 0.9921  decode.d6.loss_dice: 0.7169  decode.d7.loss_cls: 0.2893  decode.d7.loss_mask: 1.0235  decode.d7.loss_dice: 0.7092  decode.d8.loss_cls: 0.2675  decode.d8.loss_mask: 1.0284  decode.d8.loss_dice: 0.7174
05/27 01:04:31 - mmengine - INFO - Iter(train) [119300/160000]  base_lr: 2.9170e-05 lr: 2.9170e-06  eta: 4:40:20  time: 0.4151  data_time: 0.0099  memory: 5972  grad_norm: 562.5248  loss: 18.4218  decode.loss_cls: 0.2130  decode.loss_mask: 0.9269  decode.loss_dice: 0.6423  decode.d0.loss_cls: 0.5944  decode.d0.loss_mask: 0.9416  decode.d0.loss_dice: 0.6382  decode.d1.loss_cls: 0.2127  decode.d1.loss_mask: 0.9080  decode.d1.loss_dice: 0.6312  decode.d2.loss_cls: 0.1884  decode.d2.loss_mask: 1.0129  decode.d2.loss_dice: 0.6605  decode.d3.loss_cls: 0.1573  decode.d3.loss_mask: 1.0052  decode.d3.loss_dice: 0.6531  decode.d4.loss_cls: 0.1695  decode.d4.loss_mask: 1.0075  decode.d4.loss_dice: 0.6750  decode.d5.loss_cls: 0.1502  decode.d5.loss_mask: 1.0118  decode.d5.loss_dice: 0.6601  decode.d6.loss_cls: 0.2037  decode.d6.loss_mask: 0.9222  decode.d6.loss_dice: 0.6584  decode.d7.loss_cls: 0.1728  decode.d7.loss_mask: 0.9892  decode.d7.loss_dice: 0.6652  decode.d8.loss_cls: 0.2002  decode.d8.loss_mask: 0.9094  decode.d8.loss_dice: 0.6406
05/27 01:04:52 - mmengine - INFO - Iter(train) [119350/160000]  base_lr: 2.9137e-05 lr: 2.9137e-06  eta: 4:40:00  time: 0.4152  data_time: 0.0099  memory: 5969  grad_norm: 706.0908  loss: 21.8478  decode.loss_cls: 0.2689  decode.loss_mask: 1.1475  decode.loss_dice: 0.7145  decode.d0.loss_cls: 0.8094  decode.d0.loss_mask: 0.9886  decode.d0.loss_dice: 0.6668  decode.d1.loss_cls: 0.2629  decode.d1.loss_mask: 1.2010  decode.d1.loss_dice: 0.7280  decode.d2.loss_cls: 0.2662  decode.d2.loss_mask: 1.1419  decode.d2.loss_dice: 0.7206  decode.d3.loss_cls: 0.2689  decode.d3.loss_mask: 1.1445  decode.d3.loss_dice: 0.7453  decode.d4.loss_cls: 0.2663  decode.d4.loss_mask: 1.2186  decode.d4.loss_dice: 0.7424  decode.d5.loss_cls: 0.2459  decode.d5.loss_mask: 1.2001  decode.d5.loss_dice: 0.7142  decode.d6.loss_cls: 0.2672  decode.d6.loss_mask: 1.1561  decode.d6.loss_dice: 0.7262  decode.d7.loss_cls: 0.3161  decode.d7.loss_mask: 1.0772  decode.d7.loss_dice: 0.7093  decode.d8.loss_cls: 0.2466  decode.d8.loss_mask: 1.1502  decode.d8.loss_dice: 0.7366
05/27 01:05:13 - mmengine - INFO - Iter(train) [119400/160000]  base_lr: 2.9105e-05 lr: 2.9105e-06  eta: 4:39:39  time: 0.4165  data_time: 0.0099  memory: 5979  grad_norm: 394.6726  loss: 19.1869  decode.loss_cls: 0.1574  decode.loss_mask: 1.0027  decode.loss_dice: 0.7484  decode.d0.loss_cls: 0.6969  decode.d0.loss_mask: 0.9021  decode.d0.loss_dice: 0.7164  decode.d1.loss_cls: 0.1727  decode.d1.loss_mask: 0.9588  decode.d1.loss_dice: 0.7222  decode.d2.loss_cls: 0.1658  decode.d2.loss_mask: 0.9608  decode.d2.loss_dice: 0.7196  decode.d3.loss_cls: 0.1885  decode.d3.loss_mask: 0.9540  decode.d3.loss_dice: 0.7245  decode.d4.loss_cls: 0.1436  decode.d4.loss_mask: 1.0250  decode.d4.loss_dice: 0.7398  decode.d5.loss_cls: 0.1608  decode.d5.loss_mask: 0.9683  decode.d5.loss_dice: 0.7362  decode.d6.loss_cls: 0.1888  decode.d6.loss_mask: 0.9541  decode.d6.loss_dice: 0.7435  decode.d7.loss_cls: 0.1395  decode.d7.loss_mask: 1.0000  decode.d7.loss_dice: 0.7381  decode.d8.loss_cls: 0.1435  decode.d8.loss_mask: 0.9861  decode.d8.loss_dice: 0.7287
05/27 01:05:34 - mmengine - INFO - Iter(train) [119450/160000]  base_lr: 2.9073e-05 lr: 2.9073e-06  eta: 4:39:18  time: 0.4156  data_time: 0.0099  memory: 5971  grad_norm: 284.6740  loss: 17.7489  decode.loss_cls: 0.1534  decode.loss_mask: 0.9748  decode.loss_dice: 0.5738  decode.d0.loss_cls: 0.6752  decode.d0.loss_mask: 0.9231  decode.d0.loss_dice: 0.5727  decode.d1.loss_cls: 0.1904  decode.d1.loss_mask: 0.9793  decode.d1.loss_dice: 0.6046  decode.d2.loss_cls: 0.1688  decode.d2.loss_mask: 0.9647  decode.d2.loss_dice: 0.5653  decode.d3.loss_cls: 0.1660  decode.d3.loss_mask: 0.9751  decode.d3.loss_dice: 0.5789  decode.d4.loss_cls: 0.1577  decode.d4.loss_mask: 0.9759  decode.d4.loss_dice: 0.5881  decode.d5.loss_cls: 0.1749  decode.d5.loss_mask: 0.9865  decode.d5.loss_dice: 0.5917  decode.d6.loss_cls: 0.2090  decode.d6.loss_mask: 0.9592  decode.d6.loss_dice: 0.5829  decode.d7.loss_cls: 0.1881  decode.d7.loss_mask: 0.9668  decode.d7.loss_dice: 0.6036  decode.d8.loss_cls: 0.1503  decode.d8.loss_mask: 0.9658  decode.d8.loss_dice: 0.5825
05/27 01:05:55 - mmengine - INFO - Iter(train) [119500/160000]  base_lr: 2.9040e-05 lr: 2.9040e-06  eta: 4:38:58  time: 0.4156  data_time: 0.0100  memory: 5969  grad_norm: 395.5044  loss: 17.9847  decode.loss_cls: 0.2181  decode.loss_mask: 0.8327  decode.loss_dice: 0.6993  decode.d0.loss_cls: 0.7448  decode.d0.loss_mask: 0.8022  decode.d0.loss_dice: 0.7156  decode.d1.loss_cls: 0.2028  decode.d1.loss_mask: 0.8304  decode.d1.loss_dice: 0.7008  decode.d2.loss_cls: 0.2177  decode.d2.loss_mask: 0.8257  decode.d2.loss_dice: 0.7034  decode.d3.loss_cls: 0.2257  decode.d3.loss_mask: 0.8255  decode.d3.loss_dice: 0.6873  decode.d4.loss_cls: 0.2067  decode.d4.loss_mask: 0.8282  decode.d4.loss_dice: 0.7053  decode.d5.loss_cls: 0.2056  decode.d5.loss_mask: 0.8228  decode.d5.loss_dice: 0.6963  decode.d6.loss_cls: 0.2455  decode.d6.loss_mask: 0.8293  decode.d6.loss_dice: 0.7057  decode.d7.loss_cls: 0.2383  decode.d7.loss_mask: 0.8195  decode.d7.loss_dice: 0.6920  decode.d8.loss_cls: 0.2547  decode.d8.loss_mask: 0.8179  decode.d8.loss_dice: 0.6849
05/27 01:06:15 - mmengine - INFO - Iter(train) [119550/160000]  base_lr: 2.9008e-05 lr: 2.9008e-06  eta: 4:38:37  time: 0.4151  data_time: 0.0099  memory: 5966  grad_norm: 519.0785  loss: 16.0474  decode.loss_cls: 0.1447  decode.loss_mask: 0.8590  decode.loss_dice: 0.5881  decode.d0.loss_cls: 0.5869  decode.d0.loss_mask: 0.8458  decode.d0.loss_dice: 0.5835  decode.d1.loss_cls: 0.1418  decode.d1.loss_mask: 0.8720  decode.d1.loss_dice: 0.5880  decode.d2.loss_cls: 0.1113  decode.d2.loss_mask: 0.8535  decode.d2.loss_dice: 0.5792  decode.d3.loss_cls: 0.1228  decode.d3.loss_mask: 0.8487  decode.d3.loss_dice: 0.5752  decode.d4.loss_cls: 0.1097  decode.d4.loss_mask: 0.8475  decode.d4.loss_dice: 0.5944  decode.d5.loss_cls: 0.1344  decode.d5.loss_mask: 0.8419  decode.d5.loss_dice: 0.5653  decode.d6.loss_cls: 0.1589  decode.d6.loss_mask: 0.8292  decode.d6.loss_dice: 0.5750  decode.d7.loss_cls: 0.1572  decode.d7.loss_mask: 0.8109  decode.d7.loss_dice: 0.5709  decode.d8.loss_cls: 0.1305  decode.d8.loss_mask: 0.8452  decode.d8.loss_dice: 0.5760
05/27 01:06:36 - mmengine - INFO - Iter(train) [119600/160000]  base_lr: 2.8976e-05 lr: 2.8976e-06  eta: 4:38:17  time: 0.4147  data_time: 0.0100  memory: 5967  grad_norm: 905.7775  loss: 18.5925  decode.loss_cls: 0.1081  decode.loss_mask: 1.0187  decode.loss_dice: 0.6572  decode.d0.loss_cls: 0.4842  decode.d0.loss_mask: 1.0144  decode.d0.loss_dice: 0.6465  decode.d1.loss_cls: 0.1124  decode.d1.loss_mask: 1.0642  decode.d1.loss_dice: 0.6814  decode.d2.loss_cls: 0.0859  decode.d2.loss_mask: 1.0420  decode.d2.loss_dice: 0.6659  decode.d3.loss_cls: 0.0973  decode.d3.loss_mask: 1.0741  decode.d3.loss_dice: 0.6836  decode.d4.loss_cls: 0.0851  decode.d4.loss_mask: 1.0527  decode.d4.loss_dice: 0.6780  decode.d5.loss_cls: 0.0862  decode.d5.loss_mask: 1.0655  decode.d5.loss_dice: 0.6891  decode.d6.loss_cls: 0.0775  decode.d6.loss_mask: 1.0543  decode.d6.loss_dice: 0.6776  decode.d7.loss_cls: 0.0992  decode.d7.loss_mask: 1.0592  decode.d7.loss_dice: 0.6734  decode.d8.loss_cls: 0.1029  decode.d8.loss_mask: 1.0672  decode.d8.loss_dice: 0.6887
05/27 01:06:57 - mmengine - INFO - Iter(train) [119650/160000]  base_lr: 2.8944e-05 lr: 2.8944e-06  eta: 4:37:56  time: 0.4166  data_time: 0.0101  memory: 6004  grad_norm: 741.0917  loss: 22.6555  decode.loss_cls: 0.2295  decode.loss_mask: 1.1921  decode.loss_dice: 0.7936  decode.d0.loss_cls: 0.8290  decode.d0.loss_mask: 1.0981  decode.d0.loss_dice: 0.7837  decode.d1.loss_cls: 0.2328  decode.d1.loss_mask: 1.1618  decode.d1.loss_dice: 0.7897  decode.d2.loss_cls: 0.2146  decode.d2.loss_mask: 1.2069  decode.d2.loss_dice: 0.7939  decode.d3.loss_cls: 0.2383  decode.d3.loss_mask: 1.1700  decode.d3.loss_dice: 0.7813  decode.d4.loss_cls: 0.2146  decode.d4.loss_mask: 1.1600  decode.d4.loss_dice: 0.7925  decode.d5.loss_cls: 0.2331  decode.d5.loss_mask: 1.1674  decode.d5.loss_dice: 0.8016  decode.d6.loss_cls: 0.2269  decode.d6.loss_mask: 1.1960  decode.d6.loss_dice: 0.8199  decode.d7.loss_cls: 0.2588  decode.d7.loss_mask: 1.2015  decode.d7.loss_dice: 0.8122  decode.d8.loss_cls: 0.2361  decode.d8.loss_mask: 1.2095  decode.d8.loss_dice: 0.8099
05/27 01:07:18 - mmengine - INFO - Iter(train) [119700/160000]  base_lr: 2.8911e-05 lr: 2.8911e-06  eta: 4:37:35  time: 0.4250  data_time: 0.0098  memory: 5972  grad_norm: 496.1433  loss: 20.2715  decode.loss_cls: 0.1074  decode.loss_mask: 1.1052  decode.loss_dice: 0.7769  decode.d0.loss_cls: 0.5740  decode.d0.loss_mask: 1.0341  decode.d0.loss_dice: 0.7516  decode.d1.loss_cls: 0.1194  decode.d1.loss_mask: 1.1490  decode.d1.loss_dice: 0.7469  decode.d2.loss_cls: 0.0746  decode.d2.loss_mask: 1.1674  decode.d2.loss_dice: 0.7704  decode.d3.loss_cls: 0.0826  decode.d3.loss_mask: 1.1249  decode.d3.loss_dice: 0.7646  decode.d4.loss_cls: 0.1110  decode.d4.loss_mask: 1.1236  decode.d4.loss_dice: 0.7377  decode.d5.loss_cls: 0.1001  decode.d5.loss_mask: 1.1324  decode.d5.loss_dice: 0.7519  decode.d6.loss_cls: 0.1123  decode.d6.loss_mask: 1.0923  decode.d6.loss_dice: 0.7616  decode.d7.loss_cls: 0.1171  decode.d7.loss_mask: 1.1206  decode.d7.loss_dice: 0.7609  decode.d8.loss_cls: 0.0881  decode.d8.loss_mask: 1.1314  decode.d8.loss_dice: 0.7814
05/27 01:07:39 - mmengine - INFO - Iter(train) [119750/160000]  base_lr: 2.8879e-05 lr: 2.8879e-06  eta: 4:37:15  time: 0.4152  data_time: 0.0098  memory: 5966  grad_norm: 630.2070  loss: 19.4285  decode.loss_cls: 0.2262  decode.loss_mask: 1.0029  decode.loss_dice: 0.6492  decode.d0.loss_cls: 0.6713  decode.d0.loss_mask: 0.9855  decode.d0.loss_dice: 0.6533  decode.d1.loss_cls: 0.2382  decode.d1.loss_mask: 1.0318  decode.d1.loss_dice: 0.6775  decode.d2.loss_cls: 0.2356  decode.d2.loss_mask: 1.0314  decode.d2.loss_dice: 0.6520  decode.d3.loss_cls: 0.2383  decode.d3.loss_mask: 1.0149  decode.d3.loss_dice: 0.6340  decode.d4.loss_cls: 0.2144  decode.d4.loss_mask: 1.0019  decode.d4.loss_dice: 0.6561  decode.d5.loss_cls: 0.2371  decode.d5.loss_mask: 1.0310  decode.d5.loss_dice: 0.6534  decode.d6.loss_cls: 0.2462  decode.d6.loss_mask: 1.0186  decode.d6.loss_dice: 0.6822  decode.d7.loss_cls: 0.1968  decode.d7.loss_mask: 1.0277  decode.d7.loss_dice: 0.6646  decode.d8.loss_cls: 0.2334  decode.d8.loss_mask: 0.9830  decode.d8.loss_dice: 0.6401
05/27 01:07:59 - mmengine - INFO - Iter(train) [119800/160000]  base_lr: 2.8847e-05 lr: 2.8847e-06  eta: 4:36:54  time: 0.4157  data_time: 0.0099  memory: 5980  grad_norm: 576.7016  loss: 20.5191  decode.loss_cls: 0.1896  decode.loss_mask: 1.0038  decode.loss_dice: 0.7526  decode.d0.loss_cls: 0.7216  decode.d0.loss_mask: 1.0029  decode.d0.loss_dice: 0.7828  decode.d1.loss_cls: 0.2214  decode.d1.loss_mask: 1.0484  decode.d1.loss_dice: 0.7566  decode.d2.loss_cls: 0.2342  decode.d2.loss_mask: 0.9964  decode.d2.loss_dice: 0.7422  decode.d3.loss_cls: 0.2251  decode.d3.loss_mask: 0.9874  decode.d3.loss_dice: 0.7407  decode.d4.loss_cls: 0.2509  decode.d4.loss_mask: 1.0156  decode.d4.loss_dice: 0.7582  decode.d5.loss_cls: 0.2358  decode.d5.loss_mask: 1.0339  decode.d5.loss_dice: 0.7731  decode.d6.loss_cls: 0.2147  decode.d6.loss_mask: 1.0156  decode.d6.loss_dice: 0.7812  decode.d7.loss_cls: 0.2009  decode.d7.loss_mask: 1.0732  decode.d7.loss_dice: 0.7637  decode.d8.loss_cls: 0.1946  decode.d8.loss_mask: 1.0416  decode.d8.loss_dice: 0.7605
05/27 01:08:20 - mmengine - INFO - Iter(train) [119850/160000]  base_lr: 2.8815e-05 lr: 2.8815e-06  eta: 4:36:33  time: 0.4150  data_time: 0.0099  memory: 5979  grad_norm: 571.7457  loss: 19.0795  decode.loss_cls: 0.1908  decode.loss_mask: 0.9574  decode.loss_dice: 0.7072  decode.d0.loss_cls: 0.5698  decode.d0.loss_mask: 0.9932  decode.d0.loss_dice: 0.6970  decode.d1.loss_cls: 0.2045  decode.d1.loss_mask: 0.9717  decode.d1.loss_dice: 0.6926  decode.d2.loss_cls: 0.2002  decode.d2.loss_mask: 0.9521  decode.d2.loss_dice: 0.6913  decode.d3.loss_cls: 0.1802  decode.d3.loss_mask: 0.9797  decode.d3.loss_dice: 0.6969  decode.d4.loss_cls: 0.2107  decode.d4.loss_mask: 0.9761  decode.d4.loss_dice: 0.7066  decode.d5.loss_cls: 0.1768  decode.d5.loss_mask: 0.9938  decode.d5.loss_dice: 0.7273  decode.d6.loss_cls: 0.1982  decode.d6.loss_mask: 0.9965  decode.d6.loss_dice: 0.7083  decode.d7.loss_cls: 0.2119  decode.d7.loss_mask: 0.9471  decode.d7.loss_dice: 0.6925  decode.d8.loss_cls: 0.2030  decode.d8.loss_mask: 0.9592  decode.d8.loss_dice: 0.6868
05/27 01:08:41 - mmengine - INFO - Iter(train) [119900/160000]  base_lr: 2.8782e-05 lr: 2.8782e-06  eta: 4:36:13  time: 0.4151  data_time: 0.0098  memory: 5976  grad_norm: 355.4001  loss: 16.7211  decode.loss_cls: 0.0683  decode.loss_mask: 0.9314  decode.loss_dice: 0.6305  decode.d0.loss_cls: 0.5648  decode.d0.loss_mask: 0.8689  decode.d0.loss_dice: 0.5832  decode.d1.loss_cls: 0.0934  decode.d1.loss_mask: 0.9188  decode.d1.loss_dice: 0.6283  decode.d2.loss_cls: 0.0656  decode.d2.loss_mask: 0.9094  decode.d2.loss_dice: 0.6371  decode.d3.loss_cls: 0.0929  decode.d3.loss_mask: 0.9231  decode.d3.loss_dice: 0.6584  decode.d4.loss_cls: 0.0661  decode.d4.loss_mask: 0.9142  decode.d4.loss_dice: 0.6374  decode.d5.loss_cls: 0.0648  decode.d5.loss_mask: 0.9240  decode.d5.loss_dice: 0.6423  decode.d6.loss_cls: 0.1012  decode.d6.loss_mask: 0.9068  decode.d6.loss_dice: 0.6178  decode.d7.loss_cls: 0.1155  decode.d7.loss_mask: 0.9071  decode.d7.loss_dice: 0.6180  decode.d8.loss_cls: 0.0661  decode.d8.loss_mask: 0.9275  decode.d8.loss_dice: 0.6384
05/27 01:09:02 - mmengine - INFO - Iter(train) [119950/160000]  base_lr: 2.8750e-05 lr: 2.8750e-06  eta: 4:35:52  time: 0.4141  data_time: 0.0098  memory: 5969  grad_norm: 971.5422  loss: 21.3208  decode.loss_cls: 0.2853  decode.loss_mask: 1.0755  decode.loss_dice: 0.7547  decode.d0.loss_cls: 0.8520  decode.d0.loss_mask: 0.9703  decode.d0.loss_dice: 0.7542  decode.d1.loss_cls: 0.3111  decode.d1.loss_mask: 1.0167  decode.d1.loss_dice: 0.7504  decode.d2.loss_cls: 0.3000  decode.d2.loss_mask: 1.0295  decode.d2.loss_dice: 0.7719  decode.d3.loss_cls: 0.2859  decode.d3.loss_mask: 1.0393  decode.d3.loss_dice: 0.7534  decode.d4.loss_cls: 0.3250  decode.d4.loss_mask: 1.0135  decode.d4.loss_dice: 0.7434  decode.d5.loss_cls: 0.3199  decode.d5.loss_mask: 1.0152  decode.d5.loss_dice: 0.7476  decode.d6.loss_cls: 0.3141  decode.d6.loss_mask: 1.0064  decode.d6.loss_dice: 0.7353  decode.d7.loss_cls: 0.3045  decode.d7.loss_mask: 1.0349  decode.d7.loss_dice: 0.7404  decode.d8.loss_cls: 0.2835  decode.d8.loss_mask: 1.0480  decode.d8.loss_dice: 0.7390
05/27 01:09:23 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 01:09:23 - mmengine - INFO - Iter(train) [120000/160000]  base_lr: 2.8718e-05 lr: 2.8718e-06  eta: 4:35:32  time: 0.4158  data_time: 0.0098  memory: 5968  grad_norm: 379.6424  loss: 20.1238  decode.loss_cls: 0.2649  decode.loss_mask: 0.9434  decode.loss_dice: 0.7337  decode.d0.loss_cls: 0.7866  decode.d0.loss_mask: 0.9151  decode.d0.loss_dice: 0.7250  decode.d1.loss_cls: 0.2818  decode.d1.loss_mask: 0.9470  decode.d1.loss_dice: 0.7414  decode.d2.loss_cls: 0.2895  decode.d2.loss_mask: 0.9487  decode.d2.loss_dice: 0.7361  decode.d3.loss_cls: 0.2592  decode.d3.loss_mask: 0.9510  decode.d3.loss_dice: 0.7251  decode.d4.loss_cls: 0.2705  decode.d4.loss_mask: 0.9462  decode.d4.loss_dice: 0.7291  decode.d5.loss_cls: 0.2764  decode.d5.loss_mask: 0.9582  decode.d5.loss_dice: 0.7345  decode.d6.loss_cls: 0.2890  decode.d6.loss_mask: 0.9687  decode.d6.loss_dice: 0.7545  decode.d7.loss_cls: 0.2353  decode.d7.loss_mask: 0.9853  decode.d7.loss_dice: 0.7347  decode.d8.loss_cls: 0.2529  decode.d8.loss_mask: 0.9915  decode.d8.loss_dice: 0.7485
05/27 01:09:23 - mmengine - INFO - Saving checkpoint at 120000 iterations
05/27 01:09:27 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:08  time: 0.0492  data_time: 0.0012  memory: 1391  
05/27 01:09:29 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:04  time: 0.0487  data_time: 0.0012  memory: 1205  
05/27 01:09:32 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:03  time: 0.0502  data_time: 0.0012  memory: 1596  
05/27 01:09:34 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0483  data_time: 0.0012  memory: 1298  
05/27 01:09:37 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:57  time: 0.0476  data_time: 0.0012  memory: 1298  
05/27 01:09:39 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0477  data_time: 0.0012  memory: 1279  
05/27 01:09:41 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:52  time: 0.0480  data_time: 0.0012  memory: 1224  
05/27 01:09:44 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0487  data_time: 0.0012  memory: 1298  
05/27 01:09:46 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0474  data_time: 0.0012  memory: 1298  
05/27 01:09:49 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0512  data_time: 0.0012  memory: 1725  
05/27 01:09:51 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0478  data_time: 0.0012  memory: 1336  
05/27 01:09:53 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0481  data_time: 0.0012  memory: 1298  
05/27 01:09:56 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0482  data_time: 0.0012  memory: 1205  
05/27 01:09:58 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0489  data_time: 0.0012  memory: 1316  
05/27 01:10:01 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0475  data_time: 0.0012  memory: 1279  
05/27 01:10:03 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0512  data_time: 0.0012  memory: 1410  
05/27 01:10:06 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0476  data_time: 0.0012  memory: 1279  
05/27 01:10:08 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0486  data_time: 0.0012  memory: 1205  
05/27 01:10:10 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0483  data_time: 0.0012  memory: 1205  
05/27 01:10:13 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0478  data_time: 0.0012  memory: 1336  
05/27 01:10:15 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0476  data_time: 0.0012  memory: 1246  
05/27 01:10:18 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0499  data_time: 0.0012  memory: 1503  
05/27 01:10:20 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0475  data_time: 0.0012  memory: 1261  
05/27 01:10:22 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0486  data_time: 0.0012  memory: 1298  
05/27 01:10:25 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0478  data_time: 0.0012  memory: 1447  
05/27 01:10:27 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0479  data_time: 0.0012  memory: 1298  
05/27 01:10:30 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0490  data_time: 0.0012  memory: 1279  
05/27 01:10:32 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0477  data_time: 0.0012  memory: 1205  
05/27 01:10:34 - mmengine - INFO - per class results:
05/27 01:10:34 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.43 | 97.35 |
|  aeroplane  | 89.99 | 98.55 |
|   bicycle   | 45.93 | 96.62 |
|     bird    | 94.79 | 97.75 |
|     boat    | 71.72 | 87.76 |
|    bottle   | 83.37 | 94.59 |
|     bus     | 94.49 | 98.22 |
|     car     | 89.77 | 94.43 |
|     cat     | 95.19 | 99.24 |
|    chair    | 49.89 | 66.25 |
|     cow     | 89.28 | 95.07 |
| diningtable | 60.17 | 62.35 |
|     dog     | 90.21 | 97.69 |
|    horse    | 88.98 |  95.8 |
|  motorbike  | 86.37 | 95.11 |
|    person   | 90.64 | 95.43 |
| pottedplant | 71.17 | 85.02 |
|    sheep    |  85.8 | 92.45 |
|     sofa    | 59.21 | 70.11 |
|    train    | 87.43 | 96.93 |
|  tvmonitor  | 81.32 | 86.74 |
+-------------+-------+-------+
05/27 01:10:34 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.8900  mIoU: 81.0100  mAcc: 90.6400  data_time: 0.0013  time: 0.0482
05/27 01:10:55 - mmengine - INFO - Iter(train) [120050/160000]  base_lr: 2.8685e-05 lr: 2.8685e-06  eta: 4:35:11  time: 0.4161  data_time: 0.0099  memory: 5968  grad_norm: 292.7642  loss: 13.4686  decode.loss_cls: 0.0663  decode.loss_mask: 0.7838  decode.loss_dice: 0.4679  decode.d0.loss_cls: 0.5356  decode.d0.loss_mask: 0.7186  decode.d0.loss_dice: 0.4395  decode.d1.loss_cls: 0.0789  decode.d1.loss_mask: 0.7754  decode.d1.loss_dice: 0.4746  decode.d2.loss_cls: 0.0826  decode.d2.loss_mask: 0.7583  decode.d2.loss_dice: 0.4710  decode.d3.loss_cls: 0.0932  decode.d3.loss_mask: 0.7577  decode.d3.loss_dice: 0.4658  decode.d4.loss_cls: 0.0921  decode.d4.loss_mask: 0.7402  decode.d4.loss_dice: 0.4622  decode.d5.loss_cls: 0.0890  decode.d5.loss_mask: 0.7553  decode.d5.loss_dice: 0.4617  decode.d6.loss_cls: 0.0893  decode.d6.loss_mask: 0.7473  decode.d6.loss_dice: 0.4611  decode.d7.loss_cls: 0.0852  decode.d7.loss_mask: 0.7474  decode.d7.loss_dice: 0.4640  decode.d8.loss_cls: 0.0872  decode.d8.loss_mask: 0.7446  decode.d8.loss_dice: 0.4728
05/27 01:11:16 - mmengine - INFO - Iter(train) [120100/160000]  base_lr: 2.8653e-05 lr: 2.8653e-06  eta: 4:34:50  time: 0.4157  data_time: 0.0099  memory: 5966  grad_norm: 621.3232  loss: 21.1537  decode.loss_cls: 0.2126  decode.loss_mask: 1.0882  decode.loss_dice: 0.8092  decode.d0.loss_cls: 0.7784  decode.d0.loss_mask: 1.0195  decode.d0.loss_dice: 0.7480  decode.d1.loss_cls: 0.2714  decode.d1.loss_mask: 1.0308  decode.d1.loss_dice: 0.8082  decode.d2.loss_cls: 0.2317  decode.d2.loss_mask: 1.0420  decode.d2.loss_dice: 0.7759  decode.d3.loss_cls: 0.2393  decode.d3.loss_mask: 1.0631  decode.d3.loss_dice: 0.7880  decode.d4.loss_cls: 0.1932  decode.d4.loss_mask: 1.0497  decode.d4.loss_dice: 0.7968  decode.d5.loss_cls: 0.1910  decode.d5.loss_mask: 1.0758  decode.d5.loss_dice: 0.8160  decode.d6.loss_cls: 0.2042  decode.d6.loss_mask: 1.0493  decode.d6.loss_dice: 0.8144  decode.d7.loss_cls: 0.2093  decode.d7.loss_mask: 1.0446  decode.d7.loss_dice: 0.7682  decode.d8.loss_cls: 0.2103  decode.d8.loss_mask: 1.0705  decode.d8.loss_dice: 0.7542
05/27 01:11:37 - mmengine - INFO - Iter(train) [120150/160000]  base_lr: 2.8621e-05 lr: 2.8621e-06  eta: 4:34:30  time: 0.4156  data_time: 0.0099  memory: 5977  grad_norm: 415.8149  loss: 21.9756  decode.loss_cls: 0.2619  decode.loss_mask: 1.1080  decode.loss_dice: 0.7869  decode.d0.loss_cls: 0.7965  decode.d0.loss_mask: 1.0101  decode.d0.loss_dice: 0.7819  decode.d1.loss_cls: 0.2919  decode.d1.loss_mask: 1.0772  decode.d1.loss_dice: 0.7858  decode.d2.loss_cls: 0.2813  decode.d2.loss_mask: 1.0869  decode.d2.loss_dice: 0.7710  decode.d3.loss_cls: 0.2623  decode.d3.loss_mask: 1.0923  decode.d3.loss_dice: 0.7807  decode.d4.loss_cls: 0.2798  decode.d4.loss_mask: 1.0899  decode.d4.loss_dice: 0.8027  decode.d5.loss_cls: 0.2576  decode.d5.loss_mask: 1.0810  decode.d5.loss_dice: 0.7946  decode.d6.loss_cls: 0.2467  decode.d6.loss_mask: 1.0878  decode.d6.loss_dice: 0.7774  decode.d7.loss_cls: 0.3037  decode.d7.loss_mask: 1.1268  decode.d7.loss_dice: 0.7844  decode.d8.loss_cls: 0.2864  decode.d8.loss_mask: 1.1056  decode.d8.loss_dice: 0.7765
05/27 01:11:58 - mmengine - INFO - Iter(train) [120200/160000]  base_lr: 2.8588e-05 lr: 2.8588e-06  eta: 4:34:09  time: 0.4166  data_time: 0.0099  memory: 5967  grad_norm: 1158.2985  loss: 19.0693  decode.loss_cls: 0.1305  decode.loss_mask: 1.0458  decode.loss_dice: 0.6756  decode.d0.loss_cls: 0.7646  decode.d0.loss_mask: 0.9081  decode.d0.loss_dice: 0.6250  decode.d1.loss_cls: 0.1686  decode.d1.loss_mask: 0.9592  decode.d1.loss_dice: 0.6669  decode.d2.loss_cls: 0.1905  decode.d2.loss_mask: 0.9836  decode.d2.loss_dice: 0.6849  decode.d3.loss_cls: 0.1928  decode.d3.loss_mask: 0.9747  decode.d3.loss_dice: 0.6782  decode.d4.loss_cls: 0.1228  decode.d4.loss_mask: 1.0369  decode.d4.loss_dice: 0.7089  decode.d5.loss_cls: 0.1187  decode.d5.loss_mask: 1.0595  decode.d5.loss_dice: 0.7054  decode.d6.loss_cls: 0.1993  decode.d6.loss_mask: 0.9715  decode.d6.loss_dice: 0.6612  decode.d7.loss_cls: 0.1598  decode.d7.loss_mask: 1.0761  decode.d7.loss_dice: 0.7187  decode.d8.loss_cls: 0.1979  decode.d8.loss_mask: 1.0085  decode.d8.loss_dice: 0.6747
05/27 01:12:19 - mmengine - INFO - Iter(train) [120250/160000]  base_lr: 2.8556e-05 lr: 2.8556e-06  eta: 4:33:48  time: 0.4171  data_time: 0.0100  memory: 5985  grad_norm: 497.7575  loss: 20.6737  decode.loss_cls: 0.2897  decode.loss_mask: 0.9909  decode.loss_dice: 0.7263  decode.d0.loss_cls: 0.7966  decode.d0.loss_mask: 0.9870  decode.d0.loss_dice: 0.7146  decode.d1.loss_cls: 0.2388  decode.d1.loss_mask: 1.0166  decode.d1.loss_dice: 0.7386  decode.d2.loss_cls: 0.2639  decode.d2.loss_mask: 1.0447  decode.d2.loss_dice: 0.7337  decode.d3.loss_cls: 0.3015  decode.d3.loss_mask: 0.9647  decode.d3.loss_dice: 0.7210  decode.d4.loss_cls: 0.3065  decode.d4.loss_mask: 0.9896  decode.d4.loss_dice: 0.7108  decode.d5.loss_cls: 0.2785  decode.d5.loss_mask: 1.0297  decode.d5.loss_dice: 0.7388  decode.d6.loss_cls: 0.2917  decode.d6.loss_mask: 1.0055  decode.d6.loss_dice: 0.7329  decode.d7.loss_cls: 0.3067  decode.d7.loss_mask: 0.9927  decode.d7.loss_dice: 0.7210  decode.d8.loss_cls: 0.2784  decode.d8.loss_mask: 1.0252  decode.d8.loss_dice: 0.7371
05/27 01:12:40 - mmengine - INFO - Iter(train) [120300/160000]  base_lr: 2.8524e-05 lr: 2.8524e-06  eta: 4:33:28  time: 0.4168  data_time: 0.0100  memory: 5980  grad_norm: 399.8116  loss: 17.9239  decode.loss_cls: 0.1869  decode.loss_mask: 0.8887  decode.loss_dice: 0.6815  decode.d0.loss_cls: 0.7568  decode.d0.loss_mask: 0.8132  decode.d0.loss_dice: 0.6363  decode.d1.loss_cls: 0.1929  decode.d1.loss_mask: 0.8998  decode.d1.loss_dice: 0.6970  decode.d2.loss_cls: 0.1809  decode.d2.loss_mask: 0.8835  decode.d2.loss_dice: 0.6844  decode.d3.loss_cls: 0.1478  decode.d3.loss_mask: 0.8770  decode.d3.loss_dice: 0.6705  decode.d4.loss_cls: 0.1558  decode.d4.loss_mask: 0.8761  decode.d4.loss_dice: 0.6930  decode.d5.loss_cls: 0.1530  decode.d5.loss_mask: 0.8846  decode.d5.loss_dice: 0.6696  decode.d6.loss_cls: 0.1899  decode.d6.loss_mask: 0.8885  decode.d6.loss_dice: 0.6814  decode.d7.loss_cls: 0.1923  decode.d7.loss_mask: 0.8892  decode.d7.loss_dice: 0.6815  decode.d8.loss_cls: 0.1776  decode.d8.loss_mask: 0.9021  decode.d8.loss_dice: 0.6922
05/27 01:13:00 - mmengine - INFO - Iter(train) [120350/160000]  base_lr: 2.8491e-05 lr: 2.8491e-06  eta: 4:33:07  time: 0.4172  data_time: 0.0099  memory: 5971  grad_norm: 1067.5403  loss: 21.8027  decode.loss_cls: 0.2600  decode.loss_mask: 1.0678  decode.loss_dice: 0.8416  decode.d0.loss_cls: 0.8017  decode.d0.loss_mask: 1.0236  decode.d0.loss_dice: 0.7914  decode.d1.loss_cls: 0.3026  decode.d1.loss_mask: 1.0458  decode.d1.loss_dice: 0.8099  decode.d2.loss_cls: 0.3323  decode.d2.loss_mask: 0.9859  decode.d2.loss_dice: 0.7653  decode.d3.loss_cls: 0.2499  decode.d3.loss_mask: 1.0159  decode.d3.loss_dice: 0.8071  decode.d4.loss_cls: 0.3054  decode.d4.loss_mask: 1.0005  decode.d4.loss_dice: 0.7921  decode.d5.loss_cls: 0.2790  decode.d5.loss_mask: 1.0128  decode.d5.loss_dice: 0.8164  decode.d6.loss_cls: 0.2521  decode.d6.loss_mask: 1.0899  decode.d6.loss_dice: 0.8562  decode.d7.loss_cls: 0.2150  decode.d7.loss_mask: 1.0968  decode.d7.loss_dice: 0.8376  decode.d8.loss_cls: 0.2825  decode.d8.loss_mask: 1.0373  decode.d8.loss_dice: 0.8283
05/27 01:13:21 - mmengine - INFO - Iter(train) [120400/160000]  base_lr: 2.8459e-05 lr: 2.8459e-06  eta: 4:32:47  time: 0.4168  data_time: 0.0099  memory: 5967  grad_norm: 541.0376  loss: 17.5973  decode.loss_cls: 0.1576  decode.loss_mask: 0.8542  decode.loss_dice: 0.6820  decode.d0.loss_cls: 0.6523  decode.d0.loss_mask: 0.8947  decode.d0.loss_dice: 0.7024  decode.d1.loss_cls: 0.1486  decode.d1.loss_mask: 0.8693  decode.d1.loss_dice: 0.6717  decode.d2.loss_cls: 0.1312  decode.d2.loss_mask: 0.8690  decode.d2.loss_dice: 0.6734  decode.d3.loss_cls: 0.1260  decode.d3.loss_mask: 0.8844  decode.d3.loss_dice: 0.6940  decode.d4.loss_cls: 0.1048  decode.d4.loss_mask: 0.8963  decode.d4.loss_dice: 0.6844  decode.d5.loss_cls: 0.1301  decode.d5.loss_mask: 0.8886  decode.d5.loss_dice: 0.6898  decode.d6.loss_cls: 0.1157  decode.d6.loss_mask: 0.9339  decode.d6.loss_dice: 0.7142  decode.d7.loss_cls: 0.1572  decode.d7.loss_mask: 0.8879  decode.d7.loss_dice: 0.6893  decode.d8.loss_cls: 0.1459  decode.d8.loss_mask: 0.8591  decode.d8.loss_dice: 0.6892
05/27 01:13:42 - mmengine - INFO - Iter(train) [120450/160000]  base_lr: 2.8427e-05 lr: 2.8427e-06  eta: 4:32:26  time: 0.4165  data_time: 0.0099  memory: 5980  grad_norm: 287.0806  loss: 16.7503  decode.loss_cls: 0.1090  decode.loss_mask: 0.9114  decode.loss_dice: 0.5856  decode.d0.loss_cls: 0.6385  decode.d0.loss_mask: 0.9117  decode.d0.loss_dice: 0.6073  decode.d1.loss_cls: 0.1216  decode.d1.loss_mask: 0.9053  decode.d1.loss_dice: 0.5931  decode.d2.loss_cls: 0.1219  decode.d2.loss_mask: 0.9107  decode.d2.loss_dice: 0.5909  decode.d3.loss_cls: 0.1231  decode.d3.loss_mask: 0.9045  decode.d3.loss_dice: 0.5858  decode.d4.loss_cls: 0.1540  decode.d4.loss_mask: 0.8997  decode.d4.loss_dice: 0.5878  decode.d5.loss_cls: 0.1529  decode.d5.loss_mask: 0.8932  decode.d5.loss_dice: 0.5871  decode.d6.loss_cls: 0.1459  decode.d6.loss_mask: 0.8964  decode.d6.loss_dice: 0.5850  decode.d7.loss_cls: 0.1346  decode.d7.loss_mask: 0.8969  decode.d7.loss_dice: 0.5804  decode.d8.loss_cls: 0.1097  decode.d8.loss_mask: 0.9178  decode.d8.loss_dice: 0.5886
05/27 01:14:03 - mmengine - INFO - Iter(train) [120500/160000]  base_lr: 2.8394e-05 lr: 2.8394e-06  eta: 4:32:05  time: 0.4187  data_time: 0.0099  memory: 5975  grad_norm: 416.9447  loss: 19.8153  decode.loss_cls: 0.2243  decode.loss_mask: 0.9491  decode.loss_dice: 0.7846  decode.d0.loss_cls: 0.7500  decode.d0.loss_mask: 0.8777  decode.d0.loss_dice: 0.7651  decode.d1.loss_cls: 0.2315  decode.d1.loss_mask: 0.9239  decode.d1.loss_dice: 0.7601  decode.d2.loss_cls: 0.2429  decode.d2.loss_mask: 0.9322  decode.d2.loss_dice: 0.7775  decode.d3.loss_cls: 0.2265  decode.d3.loss_mask: 0.9115  decode.d3.loss_dice: 0.7728  decode.d4.loss_cls: 0.2363  decode.d4.loss_mask: 0.9230  decode.d4.loss_dice: 0.7588  decode.d5.loss_cls: 0.2191  decode.d5.loss_mask: 0.9372  decode.d5.loss_dice: 0.7559  decode.d6.loss_cls: 0.2372  decode.d6.loss_mask: 0.9258  decode.d6.loss_dice: 0.7801  decode.d7.loss_cls: 0.2482  decode.d7.loss_mask: 0.9359  decode.d7.loss_dice: 0.7850  decode.d8.loss_cls: 0.2454  decode.d8.loss_mask: 0.9220  decode.d8.loss_dice: 0.7756
05/27 01:14:24 - mmengine - INFO - Iter(train) [120550/160000]  base_lr: 2.8362e-05 lr: 2.8362e-06  eta: 4:31:45  time: 0.4166  data_time: 0.0099  memory: 5965  grad_norm: 441.3607  loss: 21.6976  decode.loss_cls: 0.1702  decode.loss_mask: 1.2042  decode.loss_dice: 0.7082  decode.d0.loss_cls: 0.7350  decode.d0.loss_mask: 1.1376  decode.d0.loss_dice: 0.6820  decode.d1.loss_cls: 0.2728  decode.d1.loss_mask: 1.1996  decode.d1.loss_dice: 0.7057  decode.d2.loss_cls: 0.1669  decode.d2.loss_mask: 1.2330  decode.d2.loss_dice: 0.7120  decode.d3.loss_cls: 0.2126  decode.d3.loss_mask: 1.2306  decode.d3.loss_dice: 0.7074  decode.d4.loss_cls: 0.1998  decode.d4.loss_mask: 1.2203  decode.d4.loss_dice: 0.7066  decode.d5.loss_cls: 0.1852  decode.d5.loss_mask: 1.2170  decode.d5.loss_dice: 0.7089  decode.d6.loss_cls: 0.2077  decode.d6.loss_mask: 1.2137  decode.d6.loss_dice: 0.7425  decode.d7.loss_cls: 0.2054  decode.d7.loss_mask: 1.2174  decode.d7.loss_dice: 0.7123  decode.d8.loss_cls: 0.1762  decode.d8.loss_mask: 1.2092  decode.d8.loss_dice: 0.6975
05/27 01:14:45 - mmengine - INFO - Iter(train) [120600/160000]  base_lr: 2.8330e-05 lr: 2.8330e-06  eta: 4:31:24  time: 0.4168  data_time: 0.0099  memory: 5971  grad_norm: 541.9603  loss: 21.3131  decode.loss_cls: 0.1387  decode.loss_mask: 1.1523  decode.loss_dice: 0.7686  decode.d0.loss_cls: 0.7052  decode.d0.loss_mask: 1.1261  decode.d0.loss_dice: 0.7273  decode.d1.loss_cls: 0.1932  decode.d1.loss_mask: 1.1728  decode.d1.loss_dice: 0.7858  decode.d2.loss_cls: 0.1444  decode.d2.loss_mask: 1.1715  decode.d2.loss_dice: 0.7937  decode.d3.loss_cls: 0.1267  decode.d3.loss_mask: 1.1565  decode.d3.loss_dice: 0.7587  decode.d4.loss_cls: 0.1662  decode.d4.loss_mask: 1.1735  decode.d4.loss_dice: 0.7793  decode.d5.loss_cls: 0.1282  decode.d5.loss_mask: 1.1654  decode.d5.loss_dice: 0.7806  decode.d6.loss_cls: 0.1387  decode.d6.loss_mask: 1.1617  decode.d6.loss_dice: 0.7760  decode.d7.loss_cls: 0.1069  decode.d7.loss_mask: 1.1640  decode.d7.loss_dice: 0.7925  decode.d8.loss_cls: 0.1121  decode.d8.loss_mask: 1.1589  decode.d8.loss_dice: 0.7875
05/27 01:15:06 - mmengine - INFO - Iter(train) [120650/160000]  base_lr: 2.8297e-05 lr: 2.8297e-06  eta: 4:31:04  time: 0.4161  data_time: 0.0100  memory: 5975  grad_norm: 340.4887  loss: 15.1687  decode.loss_cls: 0.1766  decode.loss_mask: 0.7126  decode.loss_dice: 0.5424  decode.d0.loss_cls: 0.6284  decode.d0.loss_mask: 0.7515  decode.d0.loss_dice: 0.5714  decode.d1.loss_cls: 0.1881  decode.d1.loss_mask: 0.7447  decode.d1.loss_dice: 0.5760  decode.d2.loss_cls: 0.2039  decode.d2.loss_mask: 0.7263  decode.d2.loss_dice: 0.5650  decode.d3.loss_cls: 0.1888  decode.d3.loss_mask: 0.7134  decode.d3.loss_dice: 0.5315  decode.d4.loss_cls: 0.1665  decode.d4.loss_mask: 0.7348  decode.d4.loss_dice: 0.5726  decode.d5.loss_cls: 0.1838  decode.d5.loss_mask: 0.7251  decode.d5.loss_dice: 0.5555  decode.d6.loss_cls: 0.1605  decode.d6.loss_mask: 0.7373  decode.d6.loss_dice: 0.5776  decode.d7.loss_cls: 0.1843  decode.d7.loss_mask: 0.7469  decode.d7.loss_dice: 0.5511  decode.d8.loss_cls: 0.1781  decode.d8.loss_mask: 0.7194  decode.d8.loss_dice: 0.5546
05/27 01:15:26 - mmengine - INFO - Iter(train) [120700/160000]  base_lr: 2.8265e-05 lr: 2.8265e-06  eta: 4:30:43  time: 0.4162  data_time: 0.0100  memory: 5971  grad_norm: 622.8152  loss: 22.5004  decode.loss_cls: 0.2645  decode.loss_mask: 1.1495  decode.loss_dice: 0.7678  decode.d0.loss_cls: 0.7129  decode.d0.loss_mask: 1.0747  decode.d0.loss_dice: 0.7931  decode.d1.loss_cls: 0.3581  decode.d1.loss_mask: 1.0734  decode.d1.loss_dice: 0.7606  decode.d2.loss_cls: 0.3222  decode.d2.loss_mask: 1.1065  decode.d2.loss_dice: 0.7777  decode.d3.loss_cls: 0.2938  decode.d3.loss_mask: 1.1475  decode.d3.loss_dice: 0.8060  decode.d4.loss_cls: 0.3177  decode.d4.loss_mask: 1.1237  decode.d4.loss_dice: 0.7820  decode.d5.loss_cls: 0.3816  decode.d5.loss_mask: 1.0656  decode.d5.loss_dice: 0.7560  decode.d6.loss_cls: 0.3532  decode.d6.loss_mask: 1.0490  decode.d6.loss_dice: 0.7423  decode.d7.loss_cls: 0.3012  decode.d7.loss_mask: 1.1590  decode.d7.loss_dice: 0.7964  decode.d8.loss_cls: 0.2462  decode.d8.loss_mask: 1.2370  decode.d8.loss_dice: 0.7810
05/27 01:15:47 - mmengine - INFO - Iter(train) [120750/160000]  base_lr: 2.8233e-05 lr: 2.8233e-06  eta: 4:30:22  time: 0.4163  data_time: 0.0100  memory: 5970  grad_norm: 652.9499  loss: 21.0201  decode.loss_cls: 0.1860  decode.loss_mask: 0.9768  decode.loss_dice: 0.8274  decode.d0.loss_cls: 0.7332  decode.d0.loss_mask: 1.0125  decode.d0.loss_dice: 0.8466  decode.d1.loss_cls: 0.2523  decode.d1.loss_mask: 1.0212  decode.d1.loss_dice: 0.8560  decode.d2.loss_cls: 0.2396  decode.d2.loss_mask: 0.9980  decode.d2.loss_dice: 0.8367  decode.d3.loss_cls: 0.2414  decode.d3.loss_mask: 0.9667  decode.d3.loss_dice: 0.8210  decode.d4.loss_cls: 0.2160  decode.d4.loss_mask: 0.9706  decode.d4.loss_dice: 0.8345  decode.d5.loss_cls: 0.2160  decode.d5.loss_mask: 0.9933  decode.d5.loss_dice: 0.8156  decode.d6.loss_cls: 0.2471  decode.d6.loss_mask: 0.9726  decode.d6.loss_dice: 0.8473  decode.d7.loss_cls: 0.2329  decode.d7.loss_mask: 0.9842  decode.d7.loss_dice: 0.8581  decode.d8.loss_cls: 0.2199  decode.d8.loss_mask: 0.9771  decode.d8.loss_dice: 0.8195
05/27 01:16:08 - mmengine - INFO - Iter(train) [120800/160000]  base_lr: 2.8200e-05 lr: 2.8200e-06  eta: 4:30:02  time: 0.4162  data_time: 0.0100  memory: 5976  grad_norm: 1563.8948  loss: 19.4645  decode.loss_cls: 0.1004  decode.loss_mask: 1.1572  decode.loss_dice: 0.6399  decode.d0.loss_cls: 0.6002  decode.d0.loss_mask: 1.0125  decode.d0.loss_dice: 0.5968  decode.d1.loss_cls: 0.1497  decode.d1.loss_mask: 1.1362  decode.d1.loss_dice: 0.6566  decode.d2.loss_cls: 0.1237  decode.d2.loss_mask: 1.1429  decode.d2.loss_dice: 0.6429  decode.d3.loss_cls: 0.1227  decode.d3.loss_mask: 1.1315  decode.d3.loss_dice: 0.6276  decode.d4.loss_cls: 0.1113  decode.d4.loss_mask: 1.1575  decode.d4.loss_dice: 0.6452  decode.d5.loss_cls: 0.1301  decode.d5.loss_mask: 1.1546  decode.d5.loss_dice: 0.6370  decode.d6.loss_cls: 0.1220  decode.d6.loss_mask: 1.1750  decode.d6.loss_dice: 0.6465  decode.d7.loss_cls: 0.1178  decode.d7.loss_mask: 1.1712  decode.d7.loss_dice: 0.6440  decode.d8.loss_cls: 0.1482  decode.d8.loss_mask: 1.1381  decode.d8.loss_dice: 0.6251
05/27 01:16:29 - mmengine - INFO - Iter(train) [120850/160000]  base_lr: 2.8168e-05 lr: 2.8168e-06  eta: 4:29:41  time: 0.4174  data_time: 0.0100  memory: 5971  grad_norm: 364.0897  loss: 17.6777  decode.loss_cls: 0.1916  decode.loss_mask: 0.8618  decode.loss_dice: 0.6590  decode.d0.loss_cls: 0.5931  decode.d0.loss_mask: 0.8647  decode.d0.loss_dice: 0.6824  decode.d1.loss_cls: 0.1944  decode.d1.loss_mask: 0.8695  decode.d1.loss_dice: 0.6694  decode.d2.loss_cls: 0.1935  decode.d2.loss_mask: 0.8949  decode.d2.loss_dice: 0.6493  decode.d3.loss_cls: 0.1881  decode.d3.loss_mask: 0.8560  decode.d3.loss_dice: 0.6447  decode.d4.loss_cls: 0.2215  decode.d4.loss_mask: 0.8748  decode.d4.loss_dice: 0.6475  decode.d5.loss_cls: 0.1716  decode.d5.loss_mask: 0.8974  decode.d5.loss_dice: 0.6613  decode.d6.loss_cls: 0.2223  decode.d6.loss_mask: 0.8854  decode.d6.loss_dice: 0.6751  decode.d7.loss_cls: 0.1936  decode.d7.loss_mask: 0.8608  decode.d7.loss_dice: 0.6641  decode.d8.loss_cls: 0.1879  decode.d8.loss_mask: 0.8552  decode.d8.loss_dice: 0.6468
05/27 01:16:50 - mmengine - INFO - Iter(train) [120900/160000]  base_lr: 2.8135e-05 lr: 2.8135e-06  eta: 4:29:21  time: 0.4170  data_time: 0.0100  memory: 5965  grad_norm: 563.4634  loss: 17.8786  decode.loss_cls: 0.1587  decode.loss_mask: 0.9568  decode.loss_dice: 0.6081  decode.d0.loss_cls: 0.6640  decode.d0.loss_mask: 0.9515  decode.d0.loss_dice: 0.6149  decode.d1.loss_cls: 0.1579  decode.d1.loss_mask: 0.9549  decode.d1.loss_dice: 0.6315  decode.d2.loss_cls: 0.1329  decode.d2.loss_mask: 0.9608  decode.d2.loss_dice: 0.6248  decode.d3.loss_cls: 0.1798  decode.d3.loss_mask: 0.9453  decode.d3.loss_dice: 0.6085  decode.d4.loss_cls: 0.1514  decode.d4.loss_mask: 0.9626  decode.d4.loss_dice: 0.6171  decode.d5.loss_cls: 0.1603  decode.d5.loss_mask: 0.9601  decode.d5.loss_dice: 0.6246  decode.d6.loss_cls: 0.1707  decode.d6.loss_mask: 0.9653  decode.d6.loss_dice: 0.6213  decode.d7.loss_cls: 0.1833  decode.d7.loss_mask: 0.9583  decode.d7.loss_dice: 0.6213  decode.d8.loss_cls: 0.1610  decode.d8.loss_mask: 0.9611  decode.d8.loss_dice: 0.6098
05/27 01:17:11 - mmengine - INFO - Iter(train) [120950/160000]  base_lr: 2.8103e-05 lr: 2.8103e-06  eta: 4:29:00  time: 0.4171  data_time: 0.0099  memory: 5980  grad_norm: 460.1171  loss: 17.1320  decode.loss_cls: 0.1570  decode.loss_mask: 0.8599  decode.loss_dice: 0.6342  decode.d0.loss_cls: 0.6425  decode.d0.loss_mask: 0.8269  decode.d0.loss_dice: 0.6436  decode.d1.loss_cls: 0.1666  decode.d1.loss_mask: 0.8981  decode.d1.loss_dice: 0.6427  decode.d2.loss_cls: 0.1575  decode.d2.loss_mask: 0.8992  decode.d2.loss_dice: 0.6526  decode.d3.loss_cls: 0.1617  decode.d3.loss_mask: 0.8539  decode.d3.loss_dice: 0.6184  decode.d4.loss_cls: 0.1199  decode.d4.loss_mask: 0.9061  decode.d4.loss_dice: 0.6460  decode.d5.loss_cls: 0.1315  decode.d5.loss_mask: 0.9072  decode.d5.loss_dice: 0.6452  decode.d6.loss_cls: 0.1553  decode.d6.loss_mask: 0.8697  decode.d6.loss_dice: 0.6392  decode.d7.loss_cls: 0.1343  decode.d7.loss_mask: 0.8564  decode.d7.loss_dice: 0.6424  decode.d8.loss_cls: 0.1212  decode.d8.loss_mask: 0.9021  decode.d8.loss_dice: 0.6409
05/27 01:17:31 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 01:17:31 - mmengine - INFO - Iter(train) [121000/160000]  base_lr: 2.8071e-05 lr: 2.8071e-06  eta: 4:28:39  time: 0.4168  data_time: 0.0099  memory: 5966  grad_norm: 505.0911  loss: 20.8135  decode.loss_cls: 0.2079  decode.loss_mask: 1.0703  decode.loss_dice: 0.7366  decode.d0.loss_cls: 0.6749  decode.d0.loss_mask: 1.0957  decode.d0.loss_dice: 0.8084  decode.d1.loss_cls: 0.2156  decode.d1.loss_mask: 1.0602  decode.d1.loss_dice: 0.7460  decode.d2.loss_cls: 0.2009  decode.d2.loss_mask: 1.1060  decode.d2.loss_dice: 0.7570  decode.d3.loss_cls: 0.2185  decode.d3.loss_mask: 1.0833  decode.d3.loss_dice: 0.7232  decode.d4.loss_cls: 0.2242  decode.d4.loss_mask: 1.0809  decode.d4.loss_dice: 0.7378  decode.d5.loss_cls: 0.2231  decode.d5.loss_mask: 1.0819  decode.d5.loss_dice: 0.7442  decode.d6.loss_cls: 0.2119  decode.d6.loss_mask: 1.0502  decode.d6.loss_dice: 0.7335  decode.d7.loss_cls: 0.1784  decode.d7.loss_mask: 1.0703  decode.d7.loss_dice: 0.7403  decode.d8.loss_cls: 0.2070  decode.d8.loss_mask: 1.0824  decode.d8.loss_dice: 0.7429
05/27 01:17:52 - mmengine - INFO - Iter(train) [121050/160000]  base_lr: 2.8038e-05 lr: 2.8038e-06  eta: 4:28:19  time: 0.4163  data_time: 0.0099  memory: 5980  grad_norm: 703.4949  loss: 16.8717  decode.loss_cls: 0.1447  decode.loss_mask: 0.8985  decode.loss_dice: 0.6268  decode.d0.loss_cls: 0.6224  decode.d0.loss_mask: 0.8231  decode.d0.loss_dice: 0.5880  decode.d1.loss_cls: 0.1493  decode.d1.loss_mask: 0.9011  decode.d1.loss_dice: 0.6425  decode.d2.loss_cls: 0.1568  decode.d2.loss_mask: 0.8725  decode.d2.loss_dice: 0.6102  decode.d3.loss_cls: 0.1274  decode.d3.loss_mask: 0.9001  decode.d3.loss_dice: 0.6395  decode.d4.loss_cls: 0.1368  decode.d4.loss_mask: 0.8908  decode.d4.loss_dice: 0.6448  decode.d5.loss_cls: 0.1427  decode.d5.loss_mask: 0.8902  decode.d5.loss_dice: 0.6212  decode.d6.loss_cls: 0.1360  decode.d6.loss_mask: 0.8656  decode.d6.loss_dice: 0.6076  decode.d7.loss_cls: 0.1436  decode.d7.loss_mask: 0.8704  decode.d7.loss_dice: 0.6188  decode.d8.loss_cls: 0.1368  decode.d8.loss_mask: 0.8659  decode.d8.loss_dice: 0.5977
05/27 01:18:13 - mmengine - INFO - Iter(train) [121100/160000]  base_lr: 2.8006e-05 lr: 2.8006e-06  eta: 4:27:58  time: 0.4164  data_time: 0.0099  memory: 5971  grad_norm: 602.9270  loss: 20.4656  decode.loss_cls: 0.2155  decode.loss_mask: 1.0973  decode.loss_dice: 0.7119  decode.d0.loss_cls: 0.7777  decode.d0.loss_mask: 1.0435  decode.d0.loss_dice: 0.6728  decode.d1.loss_cls: 0.2390  decode.d1.loss_mask: 1.1294  decode.d1.loss_dice: 0.6913  decode.d2.loss_cls: 0.2389  decode.d2.loss_mask: 1.0703  decode.d2.loss_dice: 0.6740  decode.d3.loss_cls: 0.2204  decode.d3.loss_mask: 1.1180  decode.d3.loss_dice: 0.6853  decode.d4.loss_cls: 0.2640  decode.d4.loss_mask: 1.0449  decode.d4.loss_dice: 0.6607  decode.d5.loss_cls: 0.2756  decode.d5.loss_mask: 1.0565  decode.d5.loss_dice: 0.6781  decode.d6.loss_cls: 0.2502  decode.d6.loss_mask: 1.0274  decode.d6.loss_dice: 0.6734  decode.d7.loss_cls: 0.2415  decode.d7.loss_mask: 1.0216  decode.d7.loss_dice: 0.6754  decode.d8.loss_cls: 0.2782  decode.d8.loss_mask: 1.0749  decode.d8.loss_dice: 0.6577
05/27 01:18:34 - mmengine - INFO - Iter(train) [121150/160000]  base_lr: 2.7973e-05 lr: 2.7973e-06  eta: 4:27:38  time: 0.4159  data_time: 0.0100  memory: 5981  grad_norm: 937.8832  loss: 19.4395  decode.loss_cls: 0.1375  decode.loss_mask: 1.0623  decode.loss_dice: 0.6848  decode.d0.loss_cls: 0.6399  decode.d0.loss_mask: 0.9607  decode.d0.loss_dice: 0.6458  decode.d1.loss_cls: 0.1704  decode.d1.loss_mask: 1.0841  decode.d1.loss_dice: 0.6799  decode.d2.loss_cls: 0.1667  decode.d2.loss_mask: 1.0809  decode.d2.loss_dice: 0.6669  decode.d3.loss_cls: 0.1805  decode.d3.loss_mask: 1.0000  decode.d3.loss_dice: 0.6849  decode.d4.loss_cls: 0.1350  decode.d4.loss_mask: 1.0842  decode.d4.loss_dice: 0.7005  decode.d5.loss_cls: 0.1623  decode.d5.loss_mask: 1.0916  decode.d5.loss_dice: 0.6840  decode.d6.loss_cls: 0.1128  decode.d6.loss_mask: 1.0888  decode.d6.loss_dice: 0.7016  decode.d7.loss_cls: 0.1642  decode.d7.loss_mask: 1.0676  decode.d7.loss_dice: 0.6802  decode.d8.loss_cls: 0.1790  decode.d8.loss_mask: 1.0778  decode.d8.loss_dice: 0.6644
05/27 01:18:55 - mmengine - INFO - Iter(train) [121200/160000]  base_lr: 2.7941e-05 lr: 2.7941e-06  eta: 4:27:17  time: 0.4173  data_time: 0.0099  memory: 5966  grad_norm: 558.3806  loss: 17.4336  decode.loss_cls: 0.1148  decode.loss_mask: 0.8725  decode.loss_dice: 0.6842  decode.d0.loss_cls: 0.6526  decode.d0.loss_mask: 0.8450  decode.d0.loss_dice: 0.6458  decode.d1.loss_cls: 0.1898  decode.d1.loss_mask: 0.8810  decode.d1.loss_dice: 0.6637  decode.d2.loss_cls: 0.1505  decode.d2.loss_mask: 0.8837  decode.d2.loss_dice: 0.6732  decode.d3.loss_cls: 0.1150  decode.d3.loss_mask: 0.8741  decode.d3.loss_dice: 0.6865  decode.d4.loss_cls: 0.1320  decode.d4.loss_mask: 0.9098  decode.d4.loss_dice: 0.7051  decode.d5.loss_cls: 0.1268  decode.d5.loss_mask: 0.8791  decode.d5.loss_dice: 0.6908  decode.d6.loss_cls: 0.1161  decode.d6.loss_mask: 0.8698  decode.d6.loss_dice: 0.6985  decode.d7.loss_cls: 0.1527  decode.d7.loss_mask: 0.8711  decode.d7.loss_dice: 0.6761  decode.d8.loss_cls: 0.1277  decode.d8.loss_mask: 0.8719  decode.d8.loss_dice: 0.6737
05/27 01:19:16 - mmengine - INFO - Iter(train) [121250/160000]  base_lr: 2.7909e-05 lr: 2.7909e-06  eta: 4:26:56  time: 0.4160  data_time: 0.0099  memory: 5970  grad_norm: 465.1085  loss: 17.7447  decode.loss_cls: 0.2761  decode.loss_mask: 0.7452  decode.loss_dice: 0.6550  decode.d0.loss_cls: 0.6725  decode.d0.loss_mask: 0.7841  decode.d0.loss_dice: 0.7143  decode.d1.loss_cls: 0.2690  decode.d1.loss_mask: 0.7910  decode.d1.loss_dice: 0.6675  decode.d2.loss_cls: 0.2560  decode.d2.loss_mask: 0.7851  decode.d2.loss_dice: 0.6698  decode.d3.loss_cls: 0.2690  decode.d3.loss_mask: 0.7934  decode.d3.loss_dice: 0.6697  decode.d4.loss_cls: 0.3072  decode.d4.loss_mask: 0.7903  decode.d4.loss_dice: 0.6848  decode.d5.loss_cls: 0.2746  decode.d5.loss_mask: 0.8130  decode.d5.loss_dice: 0.6973  decode.d6.loss_cls: 0.2616  decode.d6.loss_mask: 0.7922  decode.d6.loss_dice: 0.6817  decode.d7.loss_cls: 0.2479  decode.d7.loss_mask: 0.7886  decode.d7.loss_dice: 0.6798  decode.d8.loss_cls: 0.2501  decode.d8.loss_mask: 0.7870  decode.d8.loss_dice: 0.6709
05/27 01:19:37 - mmengine - INFO - Iter(train) [121300/160000]  base_lr: 2.7876e-05 lr: 2.7876e-06  eta: 4:26:36  time: 0.4150  data_time: 0.0099  memory: 5975  grad_norm: 459.1594  loss: 18.3004  decode.loss_cls: 0.1640  decode.loss_mask: 0.9546  decode.loss_dice: 0.6310  decode.d0.loss_cls: 0.6056  decode.d0.loss_mask: 0.9131  decode.d0.loss_dice: 0.6492  decode.d1.loss_cls: 0.2134  decode.d1.loss_mask: 0.9517  decode.d1.loss_dice: 0.6506  decode.d2.loss_cls: 0.1595  decode.d2.loss_mask: 0.9943  decode.d2.loss_dice: 0.6364  decode.d3.loss_cls: 0.1688  decode.d3.loss_mask: 0.9649  decode.d3.loss_dice: 0.6479  decode.d4.loss_cls: 0.1417  decode.d4.loss_mask: 1.0060  decode.d4.loss_dice: 0.6556  decode.d5.loss_cls: 0.1445  decode.d5.loss_mask: 0.9829  decode.d5.loss_dice: 0.6421  decode.d6.loss_cls: 0.1474  decode.d6.loss_mask: 1.0022  decode.d6.loss_dice: 0.6533  decode.d7.loss_cls: 0.1611  decode.d7.loss_mask: 0.9842  decode.d7.loss_dice: 0.6625  decode.d8.loss_cls: 0.1761  decode.d8.loss_mask: 0.9879  decode.d8.loss_dice: 0.6481
05/27 01:19:58 - mmengine - INFO - Iter(train) [121350/160000]  base_lr: 2.7844e-05 lr: 2.7844e-06  eta: 4:26:15  time: 0.4163  data_time: 0.0099  memory: 5986  grad_norm: 317.1891  loss: 15.8648  decode.loss_cls: 0.0679  decode.loss_mask: 0.8374  decode.loss_dice: 0.6241  decode.d0.loss_cls: 0.4967  decode.d0.loss_mask: 0.8012  decode.d0.loss_dice: 0.6177  decode.d1.loss_cls: 0.0770  decode.d1.loss_mask: 0.8457  decode.d1.loss_dice: 0.6359  decode.d2.loss_cls: 0.0981  decode.d2.loss_mask: 0.8497  decode.d2.loss_dice: 0.6410  decode.d3.loss_cls: 0.0814  decode.d3.loss_mask: 0.8496  decode.d3.loss_dice: 0.6276  decode.d4.loss_cls: 0.0754  decode.d4.loss_mask: 0.8417  decode.d4.loss_dice: 0.6378  decode.d5.loss_cls: 0.0739  decode.d5.loss_mask: 0.8445  decode.d5.loss_dice: 0.6370  decode.d6.loss_cls: 0.0724  decode.d6.loss_mask: 0.8388  decode.d6.loss_dice: 0.6315  decode.d7.loss_cls: 0.0772  decode.d7.loss_mask: 0.8288  decode.d7.loss_dice: 0.6235  decode.d8.loss_cls: 0.0679  decode.d8.loss_mask: 0.8344  decode.d8.loss_dice: 0.6289
05/27 01:20:18 - mmengine - INFO - Iter(train) [121400/160000]  base_lr: 2.7811e-05 lr: 2.7811e-06  eta: 4:25:54  time: 0.4156  data_time: 0.0098  memory: 5971  grad_norm: 532.3252  loss: 19.2539  decode.loss_cls: 0.1647  decode.loss_mask: 1.0186  decode.loss_dice: 0.6630  decode.d0.loss_cls: 0.6327  decode.d0.loss_mask: 1.0409  decode.d0.loss_dice: 0.6827  decode.d1.loss_cls: 0.2501  decode.d1.loss_mask: 0.9996  decode.d1.loss_dice: 0.6631  decode.d2.loss_cls: 0.1900  decode.d2.loss_mask: 1.0185  decode.d2.loss_dice: 0.6540  decode.d3.loss_cls: 0.2276  decode.d3.loss_mask: 1.0070  decode.d3.loss_dice: 0.6554  decode.d4.loss_cls: 0.2685  decode.d4.loss_mask: 0.9905  decode.d4.loss_dice: 0.6431  decode.d5.loss_cls: 0.2451  decode.d5.loss_mask: 1.0127  decode.d5.loss_dice: 0.6378  decode.d6.loss_cls: 0.2207  decode.d6.loss_mask: 1.0100  decode.d6.loss_dice: 0.6482  decode.d7.loss_cls: 0.1594  decode.d7.loss_mask: 1.0393  decode.d7.loss_dice: 0.6736  decode.d8.loss_cls: 0.1764  decode.d8.loss_mask: 1.0031  decode.d8.loss_dice: 0.6576
05/27 01:20:39 - mmengine - INFO - Iter(train) [121450/160000]  base_lr: 2.7779e-05 lr: 2.7779e-06  eta: 4:25:34  time: 0.4169  data_time: 0.0099  memory: 5966  grad_norm: 408.9606  loss: 18.4985  decode.loss_cls: 0.1577  decode.loss_mask: 0.9028  decode.loss_dice: 0.7538  decode.d0.loss_cls: 0.7025  decode.d0.loss_mask: 0.8508  decode.d0.loss_dice: 0.6903  decode.d1.loss_cls: 0.1921  decode.d1.loss_mask: 0.8926  decode.d1.loss_dice: 0.7370  decode.d2.loss_cls: 0.1667  decode.d2.loss_mask: 0.8827  decode.d2.loss_dice: 0.7470  decode.d3.loss_cls: 0.1661  decode.d3.loss_mask: 0.8899  decode.d3.loss_dice: 0.7276  decode.d4.loss_cls: 0.1620  decode.d4.loss_mask: 0.8869  decode.d4.loss_dice: 0.7563  decode.d5.loss_cls: 0.1409  decode.d5.loss_mask: 0.9000  decode.d5.loss_dice: 0.7772  decode.d6.loss_cls: 0.1502  decode.d6.loss_mask: 0.9103  decode.d6.loss_dice: 0.7727  decode.d7.loss_cls: 0.1362  decode.d7.loss_mask: 0.8858  decode.d7.loss_dice: 0.7440  decode.d8.loss_cls: 0.1613  decode.d8.loss_mask: 0.9038  decode.d8.loss_dice: 0.7511
05/27 01:21:00 - mmengine - INFO - Iter(train) [121500/160000]  base_lr: 2.7747e-05 lr: 2.7747e-06  eta: 4:25:13  time: 0.4164  data_time: 0.0100  memory: 5971  grad_norm: 660.3466  loss: 21.0158  decode.loss_cls: 0.1745  decode.loss_mask: 1.0999  decode.loss_dice: 0.7426  decode.d0.loss_cls: 0.6912  decode.d0.loss_mask: 1.1103  decode.d0.loss_dice: 0.7280  decode.d1.loss_cls: 0.1725  decode.d1.loss_mask: 1.1915  decode.d1.loss_dice: 0.7806  decode.d2.loss_cls: 0.1803  decode.d2.loss_mask: 1.0792  decode.d2.loss_dice: 0.7460  decode.d3.loss_cls: 0.1871  decode.d3.loss_mask: 1.0927  decode.d3.loss_dice: 0.7396  decode.d4.loss_cls: 0.1911  decode.d4.loss_mask: 1.1247  decode.d4.loss_dice: 0.7660  decode.d5.loss_cls: 0.1733  decode.d5.loss_mask: 1.1197  decode.d5.loss_dice: 0.7711  decode.d6.loss_cls: 0.1810  decode.d6.loss_mask: 1.1291  decode.d6.loss_dice: 0.7705  decode.d7.loss_cls: 0.1652  decode.d7.loss_mask: 1.1458  decode.d7.loss_dice: 0.7474  decode.d8.loss_cls: 0.1920  decode.d8.loss_mask: 1.0970  decode.d8.loss_dice: 0.7260
05/27 01:21:21 - mmengine - INFO - Iter(train) [121550/160000]  base_lr: 2.7714e-05 lr: 2.7714e-06  eta: 4:24:53  time: 0.4163  data_time: 0.0100  memory: 5968  grad_norm: 486.0225  loss: 24.7725  decode.loss_cls: 0.2262  decode.loss_mask: 1.2630  decode.loss_dice: 0.8998  decode.d0.loss_cls: 0.7233  decode.d0.loss_mask: 1.1488  decode.d0.loss_dice: 0.9035  decode.d1.loss_cls: 0.2842  decode.d1.loss_mask: 1.2751  decode.d1.loss_dice: 0.9021  decode.d2.loss_cls: 0.2597  decode.d2.loss_mask: 1.2590  decode.d2.loss_dice: 0.9020  decode.d3.loss_cls: 0.2482  decode.d3.loss_mask: 1.2485  decode.d3.loss_dice: 0.9240  decode.d4.loss_cls: 0.2374  decode.d4.loss_mask: 1.3153  decode.d4.loss_dice: 0.9183  decode.d5.loss_cls: 0.2635  decode.d5.loss_mask: 1.2887  decode.d5.loss_dice: 0.9316  decode.d6.loss_cls: 0.2273  decode.d6.loss_mask: 1.3141  decode.d6.loss_dice: 0.9417  decode.d7.loss_cls: 0.2137  decode.d7.loss_mask: 1.3304  decode.d7.loss_dice: 0.9347  decode.d8.loss_cls: 0.1976  decode.d8.loss_mask: 1.2718  decode.d8.loss_dice: 0.9189
05/27 01:21:42 - mmengine - INFO - Iter(train) [121600/160000]  base_lr: 2.7682e-05 lr: 2.7682e-06  eta: 4:24:32  time: 0.4156  data_time: 0.0100  memory: 5967  grad_norm: 924.2647  loss: 21.1648  decode.loss_cls: 0.2050  decode.loss_mask: 1.0570  decode.loss_dice: 0.7778  decode.d0.loss_cls: 0.7602  decode.d0.loss_mask: 1.0211  decode.d0.loss_dice: 0.7977  decode.d1.loss_cls: 0.2068  decode.d1.loss_mask: 1.0795  decode.d1.loss_dice: 0.7916  decode.d2.loss_cls: 0.2526  decode.d2.loss_mask: 1.0297  decode.d2.loss_dice: 0.7746  decode.d3.loss_cls: 0.2459  decode.d3.loss_mask: 1.0513  decode.d3.loss_dice: 0.7743  decode.d4.loss_cls: 0.1892  decode.d4.loss_mask: 1.1184  decode.d4.loss_dice: 0.8179  decode.d5.loss_cls: 0.2153  decode.d5.loss_mask: 1.0708  decode.d5.loss_dice: 0.7724  decode.d6.loss_cls: 0.2077  decode.d6.loss_mask: 1.0495  decode.d6.loss_dice: 0.7567  decode.d7.loss_cls: 0.1853  decode.d7.loss_mask: 1.1105  decode.d7.loss_dice: 0.7893  decode.d8.loss_cls: 0.1922  decode.d8.loss_mask: 1.0920  decode.d8.loss_dice: 0.7727
05/27 01:22:03 - mmengine - INFO - Iter(train) [121650/160000]  base_lr: 2.7649e-05 lr: 2.7649e-06  eta: 4:24:11  time: 0.4163  data_time: 0.0101  memory: 5967  grad_norm: 231.8439  loss: 17.8241  decode.loss_cls: 0.2377  decode.loss_mask: 0.8795  decode.loss_dice: 0.6250  decode.d0.loss_cls: 0.6314  decode.d0.loss_mask: 0.8615  decode.d0.loss_dice: 0.6781  decode.d1.loss_cls: 0.2476  decode.d1.loss_mask: 0.8613  decode.d1.loss_dice: 0.6389  decode.d2.loss_cls: 0.2678  decode.d2.loss_mask: 0.8660  decode.d2.loss_dice: 0.6434  decode.d3.loss_cls: 0.2187  decode.d3.loss_mask: 0.8735  decode.d3.loss_dice: 0.6334  decode.d4.loss_cls: 0.2174  decode.d4.loss_mask: 0.8591  decode.d4.loss_dice: 0.6106  decode.d5.loss_cls: 0.2150  decode.d5.loss_mask: 0.8657  decode.d5.loss_dice: 0.6160  decode.d6.loss_cls: 0.2476  decode.d6.loss_mask: 0.8729  decode.d6.loss_dice: 0.6731  decode.d7.loss_cls: 0.2493  decode.d7.loss_mask: 0.8570  decode.d7.loss_dice: 0.6369  decode.d8.loss_cls: 0.2329  decode.d8.loss_mask: 0.8745  decode.d8.loss_dice: 0.6324
05/27 01:22:23 - mmengine - INFO - Iter(train) [121700/160000]  base_lr: 2.7617e-05 lr: 2.7617e-06  eta: 4:23:51  time: 0.4149  data_time: 0.0099  memory: 5967  grad_norm: 290.9203  loss: 16.9610  decode.loss_cls: 0.2134  decode.loss_mask: 0.8127  decode.loss_dice: 0.6309  decode.d0.loss_cls: 0.6643  decode.d0.loss_mask: 0.7789  decode.d0.loss_dice: 0.6135  decode.d1.loss_cls: 0.2186  decode.d1.loss_mask: 0.8147  decode.d1.loss_dice: 0.6129  decode.d2.loss_cls: 0.2367  decode.d2.loss_mask: 0.8053  decode.d2.loss_dice: 0.5995  decode.d3.loss_cls: 0.2408  decode.d3.loss_mask: 0.8143  decode.d3.loss_dice: 0.5928  decode.d4.loss_cls: 0.2474  decode.d4.loss_mask: 0.8096  decode.d4.loss_dice: 0.6081  decode.d5.loss_cls: 0.2670  decode.d5.loss_mask: 0.8030  decode.d5.loss_dice: 0.6019  decode.d6.loss_cls: 0.2524  decode.d6.loss_mask: 0.7998  decode.d6.loss_dice: 0.5988  decode.d7.loss_cls: 0.2447  decode.d7.loss_mask: 0.8059  decode.d7.loss_dice: 0.6186  decode.d8.loss_cls: 0.2438  decode.d8.loss_mask: 0.8019  decode.d8.loss_dice: 0.6086
05/27 01:22:44 - mmengine - INFO - Iter(train) [121750/160000]  base_lr: 2.7584e-05 lr: 2.7584e-06  eta: 4:23:30  time: 0.4161  data_time: 0.0100  memory: 5976  grad_norm: 461.8369  loss: 15.3555  decode.loss_cls: 0.1239  decode.loss_mask: 0.8206  decode.loss_dice: 0.5062  decode.d0.loss_cls: 0.5413  decode.d0.loss_mask: 0.8560  decode.d0.loss_dice: 0.5362  decode.d1.loss_cls: 0.1769  decode.d1.loss_mask: 0.7999  decode.d1.loss_dice: 0.5326  decode.d2.loss_cls: 0.1528  decode.d2.loss_mask: 0.8172  decode.d2.loss_dice: 0.5295  decode.d3.loss_cls: 0.1316  decode.d3.loss_mask: 0.8363  decode.d3.loss_dice: 0.5259  decode.d4.loss_cls: 0.1393  decode.d4.loss_mask: 0.8369  decode.d4.loss_dice: 0.5181  decode.d5.loss_cls: 0.1461  decode.d5.loss_mask: 0.8353  decode.d5.loss_dice: 0.5200  decode.d6.loss_cls: 0.1276  decode.d6.loss_mask: 0.8356  decode.d6.loss_dice: 0.5191  decode.d7.loss_cls: 0.1249  decode.d7.loss_mask: 0.8587  decode.d7.loss_dice: 0.5272  decode.d8.loss_cls: 0.1276  decode.d8.loss_mask: 0.8355  decode.d8.loss_dice: 0.5170
05/27 01:23:05 - mmengine - INFO - Iter(train) [121800/160000]  base_lr: 2.7552e-05 lr: 2.7552e-06  eta: 4:23:09  time: 0.4159  data_time: 0.0099  memory: 5970  grad_norm: 375.0981  loss: 18.8498  decode.loss_cls: 0.2650  decode.loss_mask: 0.9556  decode.loss_dice: 0.6696  decode.d0.loss_cls: 0.6351  decode.d0.loss_mask: 0.9198  decode.d0.loss_dice: 0.6487  decode.d1.loss_cls: 0.2560  decode.d1.loss_mask: 0.9698  decode.d1.loss_dice: 0.6661  decode.d2.loss_cls: 0.2727  decode.d2.loss_mask: 0.8883  decode.d2.loss_dice: 0.6288  decode.d3.loss_cls: 0.2788  decode.d3.loss_mask: 0.9588  decode.d3.loss_dice: 0.6299  decode.d4.loss_cls: 0.2805  decode.d4.loss_mask: 0.9563  decode.d4.loss_dice: 0.6389  decode.d5.loss_cls: 0.2738  decode.d5.loss_mask: 0.9412  decode.d5.loss_dice: 0.6361  decode.d6.loss_cls: 0.2691  decode.d6.loss_mask: 0.9447  decode.d6.loss_dice: 0.6563  decode.d7.loss_cls: 0.2668  decode.d7.loss_mask: 0.8842  decode.d7.loss_dice: 0.6366  decode.d8.loss_cls: 0.2578  decode.d8.loss_mask: 0.9250  decode.d8.loss_dice: 0.6393
05/27 01:23:26 - mmengine - INFO - Iter(train) [121850/160000]  base_lr: 2.7519e-05 lr: 2.7519e-06  eta: 4:22:49  time: 0.4157  data_time: 0.0099  memory: 5975  grad_norm: 379.1753  loss: 18.9945  decode.loss_cls: 0.2886  decode.loss_mask: 0.9168  decode.loss_dice: 0.6643  decode.d0.loss_cls: 0.7665  decode.d0.loss_mask: 0.9045  decode.d0.loss_dice: 0.6773  decode.d1.loss_cls: 0.1992  decode.d1.loss_mask: 0.9479  decode.d1.loss_dice: 0.6725  decode.d2.loss_cls: 0.2249  decode.d2.loss_mask: 0.9437  decode.d2.loss_dice: 0.6648  decode.d3.loss_cls: 0.2090  decode.d3.loss_mask: 0.9481  decode.d3.loss_dice: 0.6791  decode.d4.loss_cls: 0.2477  decode.d4.loss_mask: 0.9562  decode.d4.loss_dice: 0.6567  decode.d5.loss_cls: 0.2561  decode.d5.loss_mask: 0.9383  decode.d5.loss_dice: 0.6810  decode.d6.loss_cls: 0.2190  decode.d6.loss_mask: 0.9458  decode.d6.loss_dice: 0.6616  decode.d7.loss_cls: 0.2301  decode.d7.loss_mask: 0.9343  decode.d7.loss_dice: 0.6780  decode.d8.loss_cls: 0.2454  decode.d8.loss_mask: 0.9447  decode.d8.loss_dice: 0.6924
05/27 01:23:47 - mmengine - INFO - Iter(train) [121900/160000]  base_lr: 2.7487e-05 lr: 2.7487e-06  eta: 4:22:28  time: 0.4160  data_time: 0.0098  memory: 5970  grad_norm: 904.0778  loss: 21.6555  decode.loss_cls: 0.1583  decode.loss_mask: 1.2214  decode.loss_dice: 0.7406  decode.d0.loss_cls: 0.6293  decode.d0.loss_mask: 1.1827  decode.d0.loss_dice: 0.7124  decode.d1.loss_cls: 0.1911  decode.d1.loss_mask: 1.2174  decode.d1.loss_dice: 0.7499  decode.d2.loss_cls: 0.1316  decode.d2.loss_mask: 1.2333  decode.d2.loss_dice: 0.7489  decode.d3.loss_cls: 0.1382  decode.d3.loss_mask: 1.2319  decode.d3.loss_dice: 0.7415  decode.d4.loss_cls: 0.1502  decode.d4.loss_mask: 1.2324  decode.d4.loss_dice: 0.7350  decode.d5.loss_cls: 0.1466  decode.d5.loss_mask: 1.2282  decode.d5.loss_dice: 0.7385  decode.d6.loss_cls: 0.1633  decode.d6.loss_mask: 1.2251  decode.d6.loss_dice: 0.7552  decode.d7.loss_cls: 0.1655  decode.d7.loss_mask: 1.2115  decode.d7.loss_dice: 0.7522  decode.d8.loss_cls: 0.1568  decode.d8.loss_mask: 1.2210  decode.d8.loss_dice: 0.7453
05/27 01:24:08 - mmengine - INFO - Iter(train) [121950/160000]  base_lr: 2.7455e-05 lr: 2.7455e-06  eta: 4:22:08  time: 0.4163  data_time: 0.0099  memory: 5971  grad_norm: 467.5580  loss: 20.4699  decode.loss_cls: 0.3547  decode.loss_mask: 0.9261  decode.loss_dice: 0.6937  decode.d0.loss_cls: 0.8748  decode.d0.loss_mask: 0.8831  decode.d0.loss_dice: 0.6860  decode.d1.loss_cls: 0.2951  decode.d1.loss_mask: 0.9912  decode.d1.loss_dice: 0.7189  decode.d2.loss_cls: 0.3849  decode.d2.loss_mask: 0.9585  decode.d2.loss_dice: 0.6878  decode.d3.loss_cls: 0.3073  decode.d3.loss_mask: 0.9919  decode.d3.loss_dice: 0.7164  decode.d4.loss_cls: 0.3354  decode.d4.loss_mask: 0.9552  decode.d4.loss_dice: 0.6889  decode.d5.loss_cls: 0.3646  decode.d5.loss_mask: 0.9146  decode.d5.loss_dice: 0.6989  decode.d6.loss_cls: 0.2938  decode.d6.loss_mask: 1.0077  decode.d6.loss_dice: 0.7344  decode.d7.loss_cls: 0.2928  decode.d7.loss_mask: 0.9598  decode.d7.loss_dice: 0.6964  decode.d8.loss_cls: 0.3644  decode.d8.loss_mask: 0.9601  decode.d8.loss_dice: 0.7327
05/27 01:24:28 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 01:24:28 - mmengine - INFO - Iter(train) [122000/160000]  base_lr: 2.7422e-05 lr: 2.7422e-06  eta: 4:21:47  time: 0.4162  data_time: 0.0099  memory: 5968  grad_norm: 593.3187  loss: 17.2833  decode.loss_cls: 0.1555  decode.loss_mask: 0.8830  decode.loss_dice: 0.6655  decode.d0.loss_cls: 0.4949  decode.d0.loss_mask: 0.8730  decode.d0.loss_dice: 0.6537  decode.d1.loss_cls: 0.1163  decode.d1.loss_mask: 0.8953  decode.d1.loss_dice: 0.6748  decode.d2.loss_cls: 0.1461  decode.d2.loss_mask: 0.8904  decode.d2.loss_dice: 0.6850  decode.d3.loss_cls: 0.1309  decode.d3.loss_mask: 0.8979  decode.d3.loss_dice: 0.6701  decode.d4.loss_cls: 0.1359  decode.d4.loss_mask: 0.8855  decode.d4.loss_dice: 0.6698  decode.d5.loss_cls: 0.1467  decode.d5.loss_mask: 0.8883  decode.d5.loss_dice: 0.6750  decode.d6.loss_cls: 0.1373  decode.d6.loss_mask: 0.8836  decode.d6.loss_dice: 0.6692  decode.d7.loss_cls: 0.1364  decode.d7.loss_mask: 0.8871  decode.d7.loss_dice: 0.6672  decode.d8.loss_cls: 0.1324  decode.d8.loss_mask: 0.8786  decode.d8.loss_dice: 0.6580
05/27 01:24:49 - mmengine - INFO - Iter(train) [122050/160000]  base_lr: 2.7390e-05 lr: 2.7390e-06  eta: 4:21:26  time: 0.4166  data_time: 0.0099  memory: 5972  grad_norm: 233.9325  loss: 16.1176  decode.loss_cls: 0.0782  decode.loss_mask: 0.9201  decode.loss_dice: 0.5882  decode.d0.loss_cls: 0.6152  decode.d0.loss_mask: 0.8221  decode.d0.loss_dice: 0.5502  decode.d1.loss_cls: 0.1113  decode.d1.loss_mask: 0.8964  decode.d1.loss_dice: 0.5741  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.9015  decode.d2.loss_dice: 0.5699  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 0.9062  decode.d3.loss_dice: 0.5763  decode.d4.loss_cls: 0.0978  decode.d4.loss_mask: 0.9123  decode.d4.loss_dice: 0.5723  decode.d5.loss_cls: 0.0671  decode.d5.loss_mask: 0.9158  decode.d5.loss_dice: 0.5828  decode.d6.loss_cls: 0.0724  decode.d6.loss_mask: 0.9036  decode.d6.loss_dice: 0.5766  decode.d7.loss_cls: 0.0771  decode.d7.loss_mask: 0.9196  decode.d7.loss_dice: 0.5895  decode.d8.loss_cls: 0.0794  decode.d8.loss_mask: 0.9113  decode.d8.loss_dice: 0.5829
05/27 01:25:10 - mmengine - INFO - Iter(train) [122100/160000]  base_lr: 2.7357e-05 lr: 2.7357e-06  eta: 4:21:06  time: 0.4161  data_time: 0.0099  memory: 5978  grad_norm: 588.5450  loss: 22.6990  decode.loss_cls: 0.2423  decode.loss_mask: 1.0857  decode.loss_dice: 0.8888  decode.d0.loss_cls: 0.7187  decode.d0.loss_mask: 1.0328  decode.d0.loss_dice: 0.8837  decode.d1.loss_cls: 0.2383  decode.d1.loss_mask: 1.1241  decode.d1.loss_dice: 0.8723  decode.d2.loss_cls: 0.2310  decode.d2.loss_mask: 1.1130  decode.d2.loss_dice: 0.8785  decode.d3.loss_cls: 0.1894  decode.d3.loss_mask: 1.1287  decode.d3.loss_dice: 0.9159  decode.d4.loss_cls: 0.2259  decode.d4.loss_mask: 1.1200  decode.d4.loss_dice: 0.8920  decode.d5.loss_cls: 0.2130  decode.d5.loss_mask: 1.1262  decode.d5.loss_dice: 0.9365  decode.d6.loss_cls: 0.2475  decode.d6.loss_mask: 1.1174  decode.d6.loss_dice: 0.8750  decode.d7.loss_cls: 0.2294  decode.d7.loss_mask: 1.0719  decode.d7.loss_dice: 0.8950  decode.d8.loss_cls: 0.1930  decode.d8.loss_mask: 1.1319  decode.d8.loss_dice: 0.8813
05/27 01:25:31 - mmengine - INFO - Iter(train) [122150/160000]  base_lr: 2.7325e-05 lr: 2.7325e-06  eta: 4:20:45  time: 0.4155  data_time: 0.0099  memory: 5967  grad_norm: 742.7229  loss: 18.7824  decode.loss_cls: 0.1591  decode.loss_mask: 0.9465  decode.loss_dice: 0.6969  decode.d0.loss_cls: 0.6326  decode.d0.loss_mask: 0.9385  decode.d0.loss_dice: 0.7120  decode.d1.loss_cls: 0.1706  decode.d1.loss_mask: 0.9829  decode.d1.loss_dice: 0.7222  decode.d2.loss_cls: 0.1552  decode.d2.loss_mask: 0.9617  decode.d2.loss_dice: 0.7174  decode.d3.loss_cls: 0.2137  decode.d3.loss_mask: 0.9363  decode.d3.loss_dice: 0.6932  decode.d4.loss_cls: 0.1607  decode.d4.loss_mask: 0.9793  decode.d4.loss_dice: 0.6948  decode.d5.loss_cls: 0.1994  decode.d5.loss_mask: 0.9586  decode.d5.loss_dice: 0.7017  decode.d6.loss_cls: 0.2091  decode.d6.loss_mask: 0.9410  decode.d6.loss_dice: 0.6849  decode.d7.loss_cls: 0.1542  decode.d7.loss_mask: 0.9442  decode.d7.loss_dice: 0.7191  decode.d8.loss_cls: 0.1278  decode.d8.loss_mask: 0.9672  decode.d8.loss_dice: 0.7016
05/27 01:25:52 - mmengine - INFO - Iter(train) [122200/160000]  base_lr: 2.7292e-05 lr: 2.7292e-06  eta: 4:20:25  time: 0.4158  data_time: 0.0099  memory: 5968  grad_norm: 520.8697  loss: 21.3630  decode.loss_cls: 0.2263  decode.loss_mask: 1.1558  decode.loss_dice: 0.7314  decode.d0.loss_cls: 0.7301  decode.d0.loss_mask: 1.0443  decode.d0.loss_dice: 0.6757  decode.d1.loss_cls: 0.2165  decode.d1.loss_mask: 1.1577  decode.d1.loss_dice: 0.7163  decode.d2.loss_cls: 0.2471  decode.d2.loss_mask: 1.1337  decode.d2.loss_dice: 0.7209  decode.d3.loss_cls: 0.2700  decode.d3.loss_mask: 1.1376  decode.d3.loss_dice: 0.7058  decode.d4.loss_cls: 0.2296  decode.d4.loss_mask: 1.1674  decode.d4.loss_dice: 0.7331  decode.d5.loss_cls: 0.2294  decode.d5.loss_mask: 1.1387  decode.d5.loss_dice: 0.7073  decode.d6.loss_cls: 0.2368  decode.d6.loss_mask: 1.1349  decode.d6.loss_dice: 0.7133  decode.d7.loss_cls: 0.2631  decode.d7.loss_mask: 1.1338  decode.d7.loss_dice: 0.7069  decode.d8.loss_cls: 0.2104  decode.d8.loss_mask: 1.1618  decode.d8.loss_dice: 0.7273
05/27 01:26:13 - mmengine - INFO - Iter(train) [122250/160000]  base_lr: 2.7260e-05 lr: 2.7260e-06  eta: 4:20:04  time: 0.4158  data_time: 0.0098  memory: 5969  grad_norm: 992.4974  loss: 21.9280  decode.loss_cls: 0.2248  decode.loss_mask: 1.1467  decode.loss_dice: 0.7442  decode.d0.loss_cls: 0.7519  decode.d0.loss_mask: 1.0826  decode.d0.loss_dice: 0.7366  decode.d1.loss_cls: 0.2850  decode.d1.loss_mask: 1.1271  decode.d1.loss_dice: 0.7562  decode.d2.loss_cls: 0.2593  decode.d2.loss_mask: 1.1668  decode.d2.loss_dice: 0.7682  decode.d3.loss_cls: 0.2319  decode.d3.loss_mask: 1.1512  decode.d3.loss_dice: 0.7571  decode.d4.loss_cls: 0.2343  decode.d4.loss_mask: 1.1578  decode.d4.loss_dice: 0.7682  decode.d5.loss_cls: 0.2230  decode.d5.loss_mask: 1.1453  decode.d5.loss_dice: 0.7687  decode.d6.loss_cls: 0.2375  decode.d6.loss_mask: 1.1530  decode.d6.loss_dice: 0.7648  decode.d7.loss_cls: 0.2387  decode.d7.loss_mask: 1.1563  decode.d7.loss_dice: 0.7690  decode.d8.loss_cls: 0.2055  decode.d8.loss_mask: 1.1550  decode.d8.loss_dice: 0.7610
05/27 01:26:33 - mmengine - INFO - Iter(train) [122300/160000]  base_lr: 2.7227e-05 lr: 2.7227e-06  eta: 4:19:43  time: 0.4155  data_time: 0.0099  memory: 5974  grad_norm: 447.7892  loss: 19.9336  decode.loss_cls: 0.1941  decode.loss_mask: 1.0339  decode.loss_dice: 0.7052  decode.d0.loss_cls: 0.7293  decode.d0.loss_mask: 1.0744  decode.d0.loss_dice: 0.7266  decode.d1.loss_cls: 0.2395  decode.d1.loss_mask: 1.0310  decode.d1.loss_dice: 0.7300  decode.d2.loss_cls: 0.2105  decode.d2.loss_mask: 1.0229  decode.d2.loss_dice: 0.7268  decode.d3.loss_cls: 0.1790  decode.d3.loss_mask: 1.0100  decode.d3.loss_dice: 0.7068  decode.d4.loss_cls: 0.2227  decode.d4.loss_mask: 1.0166  decode.d4.loss_dice: 0.7036  decode.d5.loss_cls: 0.2070  decode.d5.loss_mask: 1.0010  decode.d5.loss_dice: 0.6668  decode.d6.loss_cls: 0.2272  decode.d6.loss_mask: 1.0181  decode.d6.loss_dice: 0.7108  decode.d7.loss_cls: 0.2108  decode.d7.loss_mask: 1.0025  decode.d7.loss_dice: 0.7030  decode.d8.loss_cls: 0.2068  decode.d8.loss_mask: 1.0113  decode.d8.loss_dice: 0.7052
05/27 01:26:54 - mmengine - INFO - Iter(train) [122350/160000]  base_lr: 2.7195e-05 lr: 2.7195e-06  eta: 4:19:23  time: 0.4163  data_time: 0.0099  memory: 5971  grad_norm: 355.0090  loss: 18.5669  decode.loss_cls: 0.1955  decode.loss_mask: 0.9445  decode.loss_dice: 0.6472  decode.d0.loss_cls: 0.6889  decode.d0.loss_mask: 0.8982  decode.d0.loss_dice: 0.6689  decode.d1.loss_cls: 0.2025  decode.d1.loss_mask: 0.9664  decode.d1.loss_dice: 0.6502  decode.d2.loss_cls: 0.1961  decode.d2.loss_mask: 0.9508  decode.d2.loss_dice: 0.6638  decode.d3.loss_cls: 0.2159  decode.d3.loss_mask: 0.9520  decode.d3.loss_dice: 0.6481  decode.d4.loss_cls: 0.2078  decode.d4.loss_mask: 0.9526  decode.d4.loss_dice: 0.6585  decode.d5.loss_cls: 0.1854  decode.d5.loss_mask: 0.9622  decode.d5.loss_dice: 0.6667  decode.d6.loss_cls: 0.1995  decode.d6.loss_mask: 0.9605  decode.d6.loss_dice: 0.6565  decode.d7.loss_cls: 0.2219  decode.d7.loss_mask: 0.9677  decode.d7.loss_dice: 0.6567  decode.d8.loss_cls: 0.1853  decode.d8.loss_mask: 0.9486  decode.d8.loss_dice: 0.6481
05/27 01:27:15 - mmengine - INFO - Iter(train) [122400/160000]  base_lr: 2.7162e-05 lr: 2.7162e-06  eta: 4:19:02  time: 0.4161  data_time: 0.0098  memory: 5971  grad_norm: 574.6399  loss: 17.0280  decode.loss_cls: 0.1707  decode.loss_mask: 0.8399  decode.loss_dice: 0.6311  decode.d0.loss_cls: 0.6793  decode.d0.loss_mask: 0.8211  decode.d0.loss_dice: 0.6150  decode.d1.loss_cls: 0.1923  decode.d1.loss_mask: 0.8301  decode.d1.loss_dice: 0.6508  decode.d2.loss_cls: 0.2047  decode.d2.loss_mask: 0.8325  decode.d2.loss_dice: 0.6259  decode.d3.loss_cls: 0.1760  decode.d3.loss_mask: 0.8347  decode.d3.loss_dice: 0.6145  decode.d4.loss_cls: 0.2025  decode.d4.loss_mask: 0.8313  decode.d4.loss_dice: 0.6218  decode.d5.loss_cls: 0.1630  decode.d5.loss_mask: 0.8413  decode.d5.loss_dice: 0.6278  decode.d6.loss_cls: 0.1910  decode.d6.loss_mask: 0.8500  decode.d6.loss_dice: 0.6418  decode.d7.loss_cls: 0.1912  decode.d7.loss_mask: 0.8555  decode.d7.loss_dice: 0.6320  decode.d8.loss_cls: 0.1535  decode.d8.loss_mask: 0.8628  decode.d8.loss_dice: 0.6439
05/27 01:27:36 - mmengine - INFO - Iter(train) [122450/160000]  base_lr: 2.7130e-05 lr: 2.7130e-06  eta: 4:18:41  time: 0.4156  data_time: 0.0099  memory: 5969  grad_norm: 447.6899  loss: 24.0949  decode.loss_cls: 0.2110  decode.loss_mask: 1.3188  decode.loss_dice: 0.7985  decode.d0.loss_cls: 0.6945  decode.d0.loss_mask: 1.2826  decode.d0.loss_dice: 0.8239  decode.d1.loss_cls: 0.2203  decode.d1.loss_mask: 1.3147  decode.d1.loss_dice: 0.8121  decode.d2.loss_cls: 0.1968  decode.d2.loss_mask: 1.3400  decode.d2.loss_dice: 0.8279  decode.d3.loss_cls: 0.2047  decode.d3.loss_mask: 1.3512  decode.d3.loss_dice: 0.8286  decode.d4.loss_cls: 0.1885  decode.d4.loss_mask: 1.3498  decode.d4.loss_dice: 0.8451  decode.d5.loss_cls: 0.2079  decode.d5.loss_mask: 1.3385  decode.d5.loss_dice: 0.8086  decode.d6.loss_cls: 0.2201  decode.d6.loss_mask: 1.3393  decode.d6.loss_dice: 0.8014  decode.d7.loss_cls: 0.1954  decode.d7.loss_mask: 1.3546  decode.d7.loss_dice: 0.8379  decode.d8.loss_cls: 0.2008  decode.d8.loss_mask: 1.3479  decode.d8.loss_dice: 0.8334
05/27 01:27:57 - mmengine - INFO - Iter(train) [122500/160000]  base_lr: 2.7097e-05 lr: 2.7097e-06  eta: 4:18:21  time: 0.4152  data_time: 0.0098  memory: 5971  grad_norm: 481.7621  loss: 18.5862  decode.loss_cls: 0.1536  decode.loss_mask: 0.9634  decode.loss_dice: 0.6895  decode.d0.loss_cls: 0.5632  decode.d0.loss_mask: 0.9692  decode.d0.loss_dice: 0.6837  decode.d1.loss_cls: 0.1531  decode.d1.loss_mask: 1.0008  decode.d1.loss_dice: 0.6933  decode.d2.loss_cls: 0.1556  decode.d2.loss_mask: 0.9429  decode.d2.loss_dice: 0.6658  decode.d3.loss_cls: 0.1760  decode.d3.loss_mask: 0.9533  decode.d3.loss_dice: 0.6495  decode.d4.loss_cls: 0.1699  decode.d4.loss_mask: 0.9594  decode.d4.loss_dice: 0.6644  decode.d5.loss_cls: 0.1776  decode.d5.loss_mask: 0.9961  decode.d5.loss_dice: 0.6951  decode.d6.loss_cls: 0.1244  decode.d6.loss_mask: 1.0202  decode.d6.loss_dice: 0.7096  decode.d7.loss_cls: 0.1456  decode.d7.loss_mask: 0.9726  decode.d7.loss_dice: 0.6960  decode.d8.loss_cls: 0.1390  decode.d8.loss_mask: 0.9959  decode.d8.loss_dice: 0.7074
05/27 01:28:18 - mmengine - INFO - Iter(train) [122550/160000]  base_lr: 2.7065e-05 lr: 2.7065e-06  eta: 4:18:00  time: 0.4179  data_time: 0.0112  memory: 5976  grad_norm: 410.2917  loss: 16.5545  decode.loss_cls: 0.1621  decode.loss_mask: 0.8666  decode.loss_dice: 0.5901  decode.d0.loss_cls: 0.6124  decode.d0.loss_mask: 0.8676  decode.d0.loss_dice: 0.6066  decode.d1.loss_cls: 0.1994  decode.d1.loss_mask: 0.8603  decode.d1.loss_dice: 0.5560  decode.d2.loss_cls: 0.1961  decode.d2.loss_mask: 0.8507  decode.d2.loss_dice: 0.6078  decode.d3.loss_cls: 0.1542  decode.d3.loss_mask: 0.8619  decode.d3.loss_dice: 0.5584  decode.d4.loss_cls: 0.1661  decode.d4.loss_mask: 0.8690  decode.d4.loss_dice: 0.5797  decode.d5.loss_cls: 0.1752  decode.d5.loss_mask: 0.8372  decode.d5.loss_dice: 0.5770  decode.d6.loss_cls: 0.1651  decode.d6.loss_mask: 0.8543  decode.d6.loss_dice: 0.6087  decode.d7.loss_cls: 0.1786  decode.d7.loss_mask: 0.8358  decode.d7.loss_dice: 0.5527  decode.d8.loss_cls: 0.1655  decode.d8.loss_mask: 0.8485  decode.d8.loss_dice: 0.5910
05/27 01:28:38 - mmengine - INFO - Iter(train) [122600/160000]  base_lr: 2.7032e-05 lr: 2.7032e-06  eta: 4:17:40  time: 0.4176  data_time: 0.0106  memory: 5968  grad_norm: 810.4572  loss: 20.3575  decode.loss_cls: 0.1981  decode.loss_mask: 1.0481  decode.loss_dice: 0.7521  decode.d0.loss_cls: 0.6966  decode.d0.loss_mask: 0.9828  decode.d0.loss_dice: 0.7189  decode.d1.loss_cls: 0.2116  decode.d1.loss_mask: 1.0686  decode.d1.loss_dice: 0.7529  decode.d2.loss_cls: 0.2279  decode.d2.loss_mask: 1.0524  decode.d2.loss_dice: 0.7445  decode.d3.loss_cls: 0.1954  decode.d3.loss_mask: 1.0361  decode.d3.loss_dice: 0.7403  decode.d4.loss_cls: 0.2172  decode.d4.loss_mask: 1.0412  decode.d4.loss_dice: 0.7438  decode.d5.loss_cls: 0.1810  decode.d5.loss_mask: 1.0543  decode.d5.loss_dice: 0.7598  decode.d6.loss_cls: 0.1949  decode.d6.loss_mask: 1.0261  decode.d6.loss_dice: 0.7397  decode.d7.loss_cls: 0.2159  decode.d7.loss_mask: 1.0403  decode.d7.loss_dice: 0.7290  decode.d8.loss_cls: 0.1898  decode.d8.loss_mask: 1.0500  decode.d8.loss_dice: 0.7482
05/27 01:28:59 - mmengine - INFO - Iter(train) [122650/160000]  base_lr: 2.7000e-05 lr: 2.7000e-06  eta: 4:17:19  time: 0.4173  data_time: 0.0099  memory: 5966  grad_norm: 546.1453  loss: 20.8871  decode.loss_cls: 0.2371  decode.loss_mask: 1.0844  decode.loss_dice: 0.7434  decode.d0.loss_cls: 0.6148  decode.d0.loss_mask: 1.1015  decode.d0.loss_dice: 0.7545  decode.d1.loss_cls: 0.2132  decode.d1.loss_mask: 1.0854  decode.d1.loss_dice: 0.7596  decode.d2.loss_cls: 0.2041  decode.d2.loss_mask: 1.0701  decode.d2.loss_dice: 0.7486  decode.d3.loss_cls: 0.1902  decode.d3.loss_mask: 1.0971  decode.d3.loss_dice: 0.7454  decode.d4.loss_cls: 0.2036  decode.d4.loss_mask: 1.0676  decode.d4.loss_dice: 0.7485  decode.d5.loss_cls: 0.2285  decode.d5.loss_mask: 1.0756  decode.d5.loss_dice: 0.7502  decode.d6.loss_cls: 0.2098  decode.d6.loss_mask: 1.0633  decode.d6.loss_dice: 0.7491  decode.d7.loss_cls: 0.2593  decode.d7.loss_mask: 1.0813  decode.d7.loss_dice: 0.7600  decode.d8.loss_cls: 0.2320  decode.d8.loss_mask: 1.0705  decode.d8.loss_dice: 0.7387
05/27 01:29:20 - mmengine - INFO - Iter(train) [122700/160000]  base_lr: 2.6967e-05 lr: 2.6967e-06  eta: 4:16:58  time: 0.4156  data_time: 0.0100  memory: 5969  grad_norm: 396.4758  loss: 14.8708  decode.loss_cls: 0.0875  decode.loss_mask: 0.8023  decode.loss_dice: 0.5402  decode.d0.loss_cls: 0.5787  decode.d0.loss_mask: 0.7806  decode.d0.loss_dice: 0.5320  decode.d1.loss_cls: 0.1089  decode.d1.loss_mask: 0.8404  decode.d1.loss_dice: 0.5540  decode.d2.loss_cls: 0.0927  decode.d2.loss_mask: 0.8037  decode.d2.loss_dice: 0.5353  decode.d3.loss_cls: 0.0835  decode.d3.loss_mask: 0.8111  decode.d3.loss_dice: 0.5380  decode.d4.loss_cls: 0.0877  decode.d4.loss_mask: 0.8012  decode.d4.loss_dice: 0.5430  decode.d5.loss_cls: 0.0916  decode.d5.loss_mask: 0.8037  decode.d5.loss_dice: 0.5450  decode.d6.loss_cls: 0.1030  decode.d6.loss_mask: 0.8033  decode.d6.loss_dice: 0.5368  decode.d7.loss_cls: 0.0796  decode.d7.loss_mask: 0.8054  decode.d7.loss_dice: 0.5478  decode.d8.loss_cls: 0.0889  decode.d8.loss_mask: 0.8044  decode.d8.loss_dice: 0.5404
05/27 01:29:41 - mmengine - INFO - Iter(train) [122750/160000]  base_lr: 2.6934e-05 lr: 2.6934e-06  eta: 4:16:38  time: 0.4160  data_time: 0.0099  memory: 5975  grad_norm: 614.8650  loss: 22.0060  decode.loss_cls: 0.1520  decode.loss_mask: 1.1530  decode.loss_dice: 0.8518  decode.d0.loss_cls: 0.7462  decode.d0.loss_mask: 1.1157  decode.d0.loss_dice: 0.7943  decode.d1.loss_cls: 0.1606  decode.d1.loss_mask: 1.1401  decode.d1.loss_dice: 0.8334  decode.d2.loss_cls: 0.1639  decode.d2.loss_mask: 1.1461  decode.d2.loss_dice: 0.8398  decode.d3.loss_cls: 0.1626  decode.d3.loss_mask: 1.1194  decode.d3.loss_dice: 0.8412  decode.d4.loss_cls: 0.1654  decode.d4.loss_mask: 1.1056  decode.d4.loss_dice: 0.8138  decode.d5.loss_cls: 0.1552  decode.d5.loss_mask: 1.1474  decode.d5.loss_dice: 0.8384  decode.d6.loss_cls: 0.1847  decode.d6.loss_mask: 1.1785  decode.d6.loss_dice: 0.8574  decode.d7.loss_cls: 0.1833  decode.d7.loss_mask: 1.1430  decode.d7.loss_dice: 0.8403  decode.d8.loss_cls: 0.1552  decode.d8.loss_mask: 1.1656  decode.d8.loss_dice: 0.8524
05/27 01:30:02 - mmengine - INFO - Iter(train) [122800/160000]  base_lr: 2.6902e-05 lr: 2.6902e-06  eta: 4:16:17  time: 0.4165  data_time: 0.0100  memory: 5971  grad_norm: 512.1050  loss: 19.1790  decode.loss_cls: 0.1539  decode.loss_mask: 1.0460  decode.loss_dice: 0.6968  decode.d0.loss_cls: 0.7016  decode.d0.loss_mask: 0.9927  decode.d0.loss_dice: 0.6683  decode.d1.loss_cls: 0.1722  decode.d1.loss_mask: 1.0444  decode.d1.loss_dice: 0.6605  decode.d2.loss_cls: 0.1558  decode.d2.loss_mask: 1.0589  decode.d2.loss_dice: 0.6682  decode.d3.loss_cls: 0.1230  decode.d3.loss_mask: 1.0433  decode.d3.loss_dice: 0.6759  decode.d4.loss_cls: 0.1290  decode.d4.loss_mask: 1.0321  decode.d4.loss_dice: 0.6706  decode.d5.loss_cls: 0.1612  decode.d5.loss_mask: 1.0229  decode.d5.loss_dice: 0.6825  decode.d6.loss_cls: 0.1799  decode.d6.loss_mask: 1.0201  decode.d6.loss_dice: 0.6567  decode.d7.loss_cls: 0.1876  decode.d7.loss_mask: 1.0195  decode.d7.loss_dice: 0.6748  decode.d8.loss_cls: 0.1369  decode.d8.loss_mask: 1.0566  decode.d8.loss_dice: 0.6870
05/27 01:30:23 - mmengine - INFO - Iter(train) [122850/160000]  base_lr: 2.6869e-05 lr: 2.6869e-06  eta: 4:15:56  time: 0.4167  data_time: 0.0100  memory: 5975  grad_norm: 377.4498  loss: 18.0220  decode.loss_cls: 0.2346  decode.loss_mask: 0.8659  decode.loss_dice: 0.6354  decode.d0.loss_cls: 0.6980  decode.d0.loss_mask: 0.9603  decode.d0.loss_dice: 0.6940  decode.d1.loss_cls: 0.2101  decode.d1.loss_mask: 0.8865  decode.d1.loss_dice: 0.6493  decode.d2.loss_cls: 0.2452  decode.d2.loss_mask: 0.8685  decode.d2.loss_dice: 0.6371  decode.d3.loss_cls: 0.2184  decode.d3.loss_mask: 0.8676  decode.d3.loss_dice: 0.6063  decode.d4.loss_cls: 0.2256  decode.d4.loss_mask: 0.8820  decode.d4.loss_dice: 0.6261  decode.d5.loss_cls: 0.2219  decode.d5.loss_mask: 0.8631  decode.d5.loss_dice: 0.6499  decode.d6.loss_cls: 0.2261  decode.d6.loss_mask: 0.8782  decode.d6.loss_dice: 0.6445  decode.d7.loss_cls: 0.2297  decode.d7.loss_mask: 0.8841  decode.d7.loss_dice: 0.6580  decode.d8.loss_cls: 0.2280  decode.d8.loss_mask: 0.8808  decode.d8.loss_dice: 0.6471
05/27 01:30:43 - mmengine - INFO - Iter(train) [122900/160000]  base_lr: 2.6837e-05 lr: 2.6837e-06  eta: 4:15:36  time: 0.4157  data_time: 0.0099  memory: 5966  grad_norm: 484.4594  loss: 14.8492  decode.loss_cls: 0.1511  decode.loss_mask: 0.7536  decode.loss_dice: 0.5184  decode.d0.loss_cls: 0.5627  decode.d0.loss_mask: 0.7300  decode.d0.loss_dice: 0.5333  decode.d1.loss_cls: 0.1459  decode.d1.loss_mask: 0.7800  decode.d1.loss_dice: 0.5493  decode.d2.loss_cls: 0.1429  decode.d2.loss_mask: 0.7862  decode.d2.loss_dice: 0.5329  decode.d3.loss_cls: 0.1437  decode.d3.loss_mask: 0.7748  decode.d3.loss_dice: 0.5380  decode.d4.loss_cls: 0.1484  decode.d4.loss_mask: 0.7400  decode.d4.loss_dice: 0.5211  decode.d5.loss_cls: 0.1510  decode.d5.loss_mask: 0.7510  decode.d5.loss_dice: 0.5259  decode.d6.loss_cls: 0.1577  decode.d6.loss_mask: 0.7617  decode.d6.loss_dice: 0.5353  decode.d7.loss_cls: 0.1944  decode.d7.loss_mask: 0.7599  decode.d7.loss_dice: 0.5489  decode.d8.loss_cls: 0.1506  decode.d8.loss_mask: 0.7497  decode.d8.loss_dice: 0.5107
05/27 01:31:04 - mmengine - INFO - Iter(train) [122950/160000]  base_lr: 2.6804e-05 lr: 2.6804e-06  eta: 4:15:15  time: 0.4157  data_time: 0.0099  memory: 5969  grad_norm: 556.1772  loss: 22.4444  decode.loss_cls: 0.1944  decode.loss_mask: 1.1792  decode.loss_dice: 0.8231  decode.d0.loss_cls: 0.7840  decode.d0.loss_mask: 1.1343  decode.d0.loss_dice: 0.7784  decode.d1.loss_cls: 0.2166  decode.d1.loss_mask: 1.1487  decode.d1.loss_dice: 0.8203  decode.d2.loss_cls: 0.1922  decode.d2.loss_mask: 1.1643  decode.d2.loss_dice: 0.8254  decode.d3.loss_cls: 0.2138  decode.d3.loss_mask: 1.1448  decode.d3.loss_dice: 0.8122  decode.d4.loss_cls: 0.1796  decode.d4.loss_mask: 1.1950  decode.d4.loss_dice: 0.8037  decode.d5.loss_cls: 0.2145  decode.d5.loss_mask: 1.1592  decode.d5.loss_dice: 0.8000  decode.d6.loss_cls: 0.2026  decode.d6.loss_mask: 1.2066  decode.d6.loss_dice: 0.8585  decode.d7.loss_cls: 0.1779  decode.d7.loss_mask: 1.1948  decode.d7.loss_dice: 0.8187  decode.d8.loss_cls: 0.1952  decode.d8.loss_mask: 1.1718  decode.d8.loss_dice: 0.8347
05/27 01:31:25 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 01:31:25 - mmengine - INFO - Iter(train) [123000/160000]  base_lr: 2.6772e-05 lr: 2.6772e-06  eta: 4:14:55  time: 0.4155  data_time: 0.0099  memory: 5966  grad_norm: 524.8704  loss: 21.2608  decode.loss_cls: 0.1910  decode.loss_mask: 1.0764  decode.loss_dice: 0.8096  decode.d0.loss_cls: 0.6341  decode.d0.loss_mask: 1.0814  decode.d0.loss_dice: 0.7927  decode.d1.loss_cls: 0.2007  decode.d1.loss_mask: 1.0878  decode.d1.loss_dice: 0.8214  decode.d2.loss_cls: 0.2478  decode.d2.loss_mask: 1.0652  decode.d2.loss_dice: 0.7846  decode.d3.loss_cls: 0.2343  decode.d3.loss_mask: 1.0384  decode.d3.loss_dice: 0.7739  decode.d4.loss_cls: 0.2083  decode.d4.loss_mask: 1.0939  decode.d4.loss_dice: 0.8092  decode.d5.loss_cls: 0.2076  decode.d5.loss_mask: 1.0591  decode.d5.loss_dice: 0.7846  decode.d6.loss_cls: 0.2231  decode.d6.loss_mask: 1.0554  decode.d6.loss_dice: 0.8142  decode.d7.loss_cls: 0.2259  decode.d7.loss_mask: 1.0718  decode.d7.loss_dice: 0.7769  decode.d8.loss_cls: 0.2041  decode.d8.loss_mask: 1.0766  decode.d8.loss_dice: 0.8107
05/27 01:31:46 - mmengine - INFO - Iter(train) [123050/160000]  base_lr: 2.6739e-05 lr: 2.6739e-06  eta: 4:14:34  time: 0.4163  data_time: 0.0100  memory: 5987  grad_norm: 420.3874  loss: 18.3657  decode.loss_cls: 0.2535  decode.loss_mask: 0.8193  decode.loss_dice: 0.7024  decode.d0.loss_cls: 0.7687  decode.d0.loss_mask: 0.8415  decode.d0.loss_dice: 0.7304  decode.d1.loss_cls: 0.2572  decode.d1.loss_mask: 0.8308  decode.d1.loss_dice: 0.7116  decode.d2.loss_cls: 0.2684  decode.d2.loss_mask: 0.8254  decode.d2.loss_dice: 0.6873  decode.d3.loss_cls: 0.2706  decode.d3.loss_mask: 0.8186  decode.d3.loss_dice: 0.7088  decode.d4.loss_cls: 0.2197  decode.d4.loss_mask: 0.8171  decode.d4.loss_dice: 0.6926  decode.d5.loss_cls: 0.2176  decode.d5.loss_mask: 0.8355  decode.d5.loss_dice: 0.6988  decode.d6.loss_cls: 0.2372  decode.d6.loss_mask: 0.8322  decode.d6.loss_dice: 0.7329  decode.d7.loss_cls: 0.2290  decode.d7.loss_mask: 0.8335  decode.d7.loss_dice: 0.7275  decode.d8.loss_cls: 0.2541  decode.d8.loss_mask: 0.8352  decode.d8.loss_dice: 0.7083
05/27 01:32:07 - mmengine - INFO - Iter(train) [123100/160000]  base_lr: 2.6707e-05 lr: 2.6707e-06  eta: 4:14:13  time: 0.4153  data_time: 0.0099  memory: 5966  grad_norm: 475.1743  loss: 18.0088  decode.loss_cls: 0.1942  decode.loss_mask: 0.9677  decode.loss_dice: 0.5906  decode.d0.loss_cls: 0.6375  decode.d0.loss_mask: 0.9396  decode.d0.loss_dice: 0.6150  decode.d1.loss_cls: 0.2684  decode.d1.loss_mask: 0.9449  decode.d1.loss_dice: 0.6089  decode.d2.loss_cls: 0.2032  decode.d2.loss_mask: 0.9903  decode.d2.loss_dice: 0.5989  decode.d3.loss_cls: 0.2079  decode.d3.loss_mask: 0.9375  decode.d3.loss_dice: 0.5848  decode.d4.loss_cls: 0.1964  decode.d4.loss_mask: 0.9471  decode.d4.loss_dice: 0.5949  decode.d5.loss_cls: 0.2097  decode.d5.loss_mask: 0.9576  decode.d5.loss_dice: 0.6089  decode.d6.loss_cls: 0.1974  decode.d6.loss_mask: 0.9519  decode.d6.loss_dice: 0.5931  decode.d7.loss_cls: 0.1958  decode.d7.loss_mask: 0.9374  decode.d7.loss_dice: 0.5945  decode.d8.loss_cls: 0.1868  decode.d8.loss_mask: 0.9555  decode.d8.loss_dice: 0.5928
05/27 01:32:28 - mmengine - INFO - Iter(train) [123150/160000]  base_lr: 2.6674e-05 lr: 2.6674e-06  eta: 4:13:53  time: 0.4159  data_time: 0.0100  memory: 5976  grad_norm: 512.9944  loss: 18.1203  decode.loss_cls: 0.2081  decode.loss_mask: 0.9221  decode.loss_dice: 0.6271  decode.d0.loss_cls: 0.6100  decode.d0.loss_mask: 0.8799  decode.d0.loss_dice: 0.6527  decode.d1.loss_cls: 0.2160  decode.d1.loss_mask: 0.9472  decode.d1.loss_dice: 0.6460  decode.d2.loss_cls: 0.1903  decode.d2.loss_mask: 0.9339  decode.d2.loss_dice: 0.6298  decode.d3.loss_cls: 0.2158  decode.d3.loss_mask: 0.9309  decode.d3.loss_dice: 0.6370  decode.d4.loss_cls: 0.2296  decode.d4.loss_mask: 0.9328  decode.d4.loss_dice: 0.6340  decode.d5.loss_cls: 0.2161  decode.d5.loss_mask: 0.9274  decode.d5.loss_dice: 0.6398  decode.d6.loss_cls: 0.2116  decode.d6.loss_mask: 0.9140  decode.d6.loss_dice: 0.6425  decode.d7.loss_cls: 0.1619  decode.d7.loss_mask: 0.9363  decode.d7.loss_dice: 0.6622  decode.d8.loss_cls: 0.1799  decode.d8.loss_mask: 0.9410  decode.d8.loss_dice: 0.6447
05/27 01:32:48 - mmengine - INFO - Iter(train) [123200/160000]  base_lr: 2.6641e-05 lr: 2.6641e-06  eta: 4:13:32  time: 0.4155  data_time: 0.0099  memory: 5971  grad_norm: 2327.1071  loss: 19.9592  decode.loss_cls: 0.1786  decode.loss_mask: 1.0890  decode.loss_dice: 0.6627  decode.d0.loss_cls: 0.7323  decode.d0.loss_mask: 1.0320  decode.d0.loss_dice: 0.6621  decode.d1.loss_cls: 0.2005  decode.d1.loss_mask: 1.1174  decode.d1.loss_dice: 0.6682  decode.d2.loss_cls: 0.1871  decode.d2.loss_mask: 1.0628  decode.d2.loss_dice: 0.6562  decode.d3.loss_cls: 0.1845  decode.d3.loss_mask: 1.0977  decode.d3.loss_dice: 0.6581  decode.d4.loss_cls: 0.1851  decode.d4.loss_mask: 1.0986  decode.d4.loss_dice: 0.6567  decode.d5.loss_cls: 0.1760  decode.d5.loss_mask: 1.1040  decode.d5.loss_dice: 0.6866  decode.d6.loss_cls: 0.1972  decode.d6.loss_mask: 1.1087  decode.d6.loss_dice: 0.6686  decode.d7.loss_cls: 0.1833  decode.d7.loss_mask: 1.1105  decode.d7.loss_dice: 0.6609  decode.d8.loss_cls: 0.1677  decode.d8.loss_mask: 1.1037  decode.d8.loss_dice: 0.6623
05/27 01:33:09 - mmengine - INFO - Iter(train) [123250/160000]  base_lr: 2.6609e-05 lr: 2.6609e-06  eta: 4:13:11  time: 0.4156  data_time: 0.0099  memory: 5970  grad_norm: 651.0013  loss: 21.7018  decode.loss_cls: 0.1690  decode.loss_mask: 1.1411  decode.loss_dice: 0.7971  decode.d0.loss_cls: 0.6043  decode.d0.loss_mask: 1.1446  decode.d0.loss_dice: 0.7684  decode.d1.loss_cls: 0.1554  decode.d1.loss_mask: 1.1532  decode.d1.loss_dice: 0.8148  decode.d2.loss_cls: 0.2230  decode.d2.loss_mask: 1.1376  decode.d2.loss_dice: 0.7995  decode.d3.loss_cls: 0.2114  decode.d3.loss_mask: 1.1354  decode.d3.loss_dice: 0.7971  decode.d4.loss_cls: 0.1840  decode.d4.loss_mask: 1.1722  decode.d4.loss_dice: 0.8103  decode.d5.loss_cls: 0.1827  decode.d5.loss_mask: 1.1206  decode.d5.loss_dice: 0.8012  decode.d6.loss_cls: 0.1846  decode.d6.loss_mask: 1.1349  decode.d6.loss_dice: 0.8089  decode.d7.loss_cls: 0.1919  decode.d7.loss_mask: 1.1469  decode.d7.loss_dice: 0.7986  decode.d8.loss_cls: 0.1733  decode.d8.loss_mask: 1.1370  decode.d8.loss_dice: 0.8025
05/27 01:33:30 - mmengine - INFO - Iter(train) [123300/160000]  base_lr: 2.6576e-05 lr: 2.6576e-06  eta: 4:12:51  time: 0.4168  data_time: 0.0099  memory: 6005  grad_norm: 831.6313  loss: 16.7493  decode.loss_cls: 0.1051  decode.loss_mask: 0.8558  decode.loss_dice: 0.6544  decode.d0.loss_cls: 0.5931  decode.d0.loss_mask: 0.8536  decode.d0.loss_dice: 0.6137  decode.d1.loss_cls: 0.1006  decode.d1.loss_mask: 0.8585  decode.d1.loss_dice: 0.6531  decode.d2.loss_cls: 0.1115  decode.d2.loss_mask: 0.9073  decode.d2.loss_dice: 0.6357  decode.d3.loss_cls: 0.1012  decode.d3.loss_mask: 0.8579  decode.d3.loss_dice: 0.6545  decode.d4.loss_cls: 0.0919  decode.d4.loss_mask: 0.8898  decode.d4.loss_dice: 0.6492  decode.d5.loss_cls: 0.1091  decode.d5.loss_mask: 0.8834  decode.d5.loss_dice: 0.6641  decode.d6.loss_cls: 0.1638  decode.d6.loss_mask: 0.8394  decode.d6.loss_dice: 0.6251  decode.d7.loss_cls: 0.1088  decode.d7.loss_mask: 0.8852  decode.d7.loss_dice: 0.6556  decode.d8.loss_cls: 0.1245  decode.d8.loss_mask: 0.8554  decode.d8.loss_dice: 0.6484
05/27 01:33:51 - mmengine - INFO - Iter(train) [123350/160000]  base_lr: 2.6544e-05 lr: 2.6544e-06  eta: 4:12:30  time: 0.4157  data_time: 0.0099  memory: 5980  grad_norm: 349.5645  loss: 16.3914  decode.loss_cls: 0.0900  decode.loss_mask: 0.8631  decode.loss_dice: 0.6276  decode.d0.loss_cls: 0.5841  decode.d0.loss_mask: 0.8864  decode.d0.loss_dice: 0.6392  decode.d1.loss_cls: 0.1122  decode.d1.loss_mask: 0.8670  decode.d1.loss_dice: 0.6104  decode.d2.loss_cls: 0.1107  decode.d2.loss_mask: 0.8621  decode.d2.loss_dice: 0.6296  decode.d3.loss_cls: 0.0985  decode.d3.loss_mask: 0.8628  decode.d3.loss_dice: 0.6138  decode.d4.loss_cls: 0.1069  decode.d4.loss_mask: 0.8659  decode.d4.loss_dice: 0.6266  decode.d5.loss_cls: 0.1174  decode.d5.loss_mask: 0.8615  decode.d5.loss_dice: 0.6099  decode.d6.loss_cls: 0.0924  decode.d6.loss_mask: 0.8646  decode.d6.loss_dice: 0.6096  decode.d7.loss_cls: 0.1090  decode.d7.loss_mask: 0.8692  decode.d7.loss_dice: 0.6205  decode.d8.loss_cls: 0.0982  decode.d8.loss_mask: 0.8642  decode.d8.loss_dice: 0.6180
05/27 01:34:12 - mmengine - INFO - Iter(train) [123400/160000]  base_lr: 2.6511e-05 lr: 2.6511e-06  eta: 4:12:10  time: 0.4162  data_time: 0.0098  memory: 5976  grad_norm: 716.7886  loss: 20.7498  decode.loss_cls: 0.1568  decode.loss_mask: 1.1422  decode.loss_dice: 0.7841  decode.d0.loss_cls: 0.7405  decode.d0.loss_mask: 1.0229  decode.d0.loss_dice: 0.7192  decode.d1.loss_cls: 0.2049  decode.d1.loss_mask: 1.0596  decode.d1.loss_dice: 0.7572  decode.d2.loss_cls: 0.1648  decode.d2.loss_mask: 1.0680  decode.d2.loss_dice: 0.7651  decode.d3.loss_cls: 0.1321  decode.d3.loss_mask: 1.1351  decode.d3.loss_dice: 0.7694  decode.d4.loss_cls: 0.1461  decode.d4.loss_mask: 1.1117  decode.d4.loss_dice: 0.7477  decode.d5.loss_cls: 0.1795  decode.d5.loss_mask: 1.0688  decode.d5.loss_dice: 0.7471  decode.d6.loss_cls: 0.1714  decode.d6.loss_mask: 1.1457  decode.d6.loss_dice: 0.7899  decode.d7.loss_cls: 0.1812  decode.d7.loss_mask: 1.1052  decode.d7.loss_dice: 0.7593  decode.d8.loss_cls: 0.1620  decode.d8.loss_mask: 1.0660  decode.d8.loss_dice: 0.7460
05/27 01:34:33 - mmengine - INFO - Iter(train) [123450/160000]  base_lr: 2.6478e-05 lr: 2.6478e-06  eta: 4:11:49  time: 0.4174  data_time: 0.0099  memory: 5966  grad_norm: 342.8341  loss: 17.9762  decode.loss_cls: 0.2033  decode.loss_mask: 0.8986  decode.loss_dice: 0.6418  decode.d0.loss_cls: 0.7488  decode.d0.loss_mask: 0.8422  decode.d0.loss_dice: 0.6291  decode.d1.loss_cls: 0.2151  decode.d1.loss_mask: 0.9151  decode.d1.loss_dice: 0.6512  decode.d2.loss_cls: 0.1981  decode.d2.loss_mask: 0.9012  decode.d2.loss_dice: 0.6442  decode.d3.loss_cls: 0.1980  decode.d3.loss_mask: 0.8881  decode.d3.loss_dice: 0.6318  decode.d4.loss_cls: 0.1851  decode.d4.loss_mask: 0.9388  decode.d4.loss_dice: 0.6659  decode.d5.loss_cls: 0.1726  decode.d5.loss_mask: 0.8931  decode.d5.loss_dice: 0.6528  decode.d6.loss_cls: 0.2059  decode.d6.loss_mask: 0.8938  decode.d6.loss_dice: 0.6368  decode.d7.loss_cls: 0.1620  decode.d7.loss_mask: 0.9410  decode.d7.loss_dice: 0.6617  decode.d8.loss_cls: 0.1960  decode.d8.loss_mask: 0.9105  decode.d8.loss_dice: 0.6535
05/27 01:34:53 - mmengine - INFO - Iter(train) [123500/160000]  base_lr: 2.6446e-05 lr: 2.6446e-06  eta: 4:11:28  time: 0.4158  data_time: 0.0098  memory: 5968  grad_norm: 365.7030  loss: 20.0846  decode.loss_cls: 0.2432  decode.loss_mask: 0.9864  decode.loss_dice: 0.7357  decode.d0.loss_cls: 0.6781  decode.d0.loss_mask: 0.9288  decode.d0.loss_dice: 0.7056  decode.d1.loss_cls: 0.2536  decode.d1.loss_mask: 0.9825  decode.d1.loss_dice: 0.7451  decode.d2.loss_cls: 0.2806  decode.d2.loss_mask: 0.9869  decode.d2.loss_dice: 0.7408  decode.d3.loss_cls: 0.2254  decode.d3.loss_mask: 0.9924  decode.d3.loss_dice: 0.7510  decode.d4.loss_cls: 0.2539  decode.d4.loss_mask: 0.9795  decode.d4.loss_dice: 0.7470  decode.d5.loss_cls: 0.2449  decode.d5.loss_mask: 0.9792  decode.d5.loss_dice: 0.7510  decode.d6.loss_cls: 0.2573  decode.d6.loss_mask: 0.9921  decode.d6.loss_dice: 0.7626  decode.d7.loss_cls: 0.2253  decode.d7.loss_mask: 0.9710  decode.d7.loss_dice: 0.7487  decode.d8.loss_cls: 0.2349  decode.d8.loss_mask: 0.9621  decode.d8.loss_dice: 0.7389
05/27 01:35:14 - mmengine - INFO - Iter(train) [123550/160000]  base_lr: 2.6413e-05 lr: 2.6413e-06  eta: 4:11:08  time: 0.4160  data_time: 0.0099  memory: 5969  grad_norm: 423.4237  loss: 18.4436  decode.loss_cls: 0.1388  decode.loss_mask: 0.9456  decode.loss_dice: 0.7223  decode.d0.loss_cls: 0.6258  decode.d0.loss_mask: 0.9722  decode.d0.loss_dice: 0.7587  decode.d1.loss_cls: 0.1469  decode.d1.loss_mask: 0.9313  decode.d1.loss_dice: 0.7231  decode.d2.loss_cls: 0.1075  decode.d2.loss_mask: 0.9617  decode.d2.loss_dice: 0.7347  decode.d3.loss_cls: 0.1237  decode.d3.loss_mask: 0.9128  decode.d3.loss_dice: 0.7350  decode.d4.loss_cls: 0.0998  decode.d4.loss_mask: 0.9199  decode.d4.loss_dice: 0.7298  decode.d5.loss_cls: 0.1014  decode.d5.loss_mask: 0.9369  decode.d5.loss_dice: 0.7460  decode.d6.loss_cls: 0.1195  decode.d6.loss_mask: 0.9330  decode.d6.loss_dice: 0.7227  decode.d7.loss_cls: 0.1073  decode.d7.loss_mask: 0.9405  decode.d7.loss_dice: 0.7495  decode.d8.loss_cls: 0.1055  decode.d8.loss_mask: 0.9455  decode.d8.loss_dice: 0.7462
05/27 01:35:35 - mmengine - INFO - Iter(train) [123600/160000]  base_lr: 2.6381e-05 lr: 2.6381e-06  eta: 4:10:47  time: 0.4159  data_time: 0.0099  memory: 5992  grad_norm: 504.4859  loss: 21.9520  decode.loss_cls: 0.2500  decode.loss_mask: 1.1206  decode.loss_dice: 0.8199  decode.d0.loss_cls: 0.7424  decode.d0.loss_mask: 1.0556  decode.d0.loss_dice: 0.7970  decode.d1.loss_cls: 0.2737  decode.d1.loss_mask: 1.0965  decode.d1.loss_dice: 0.8009  decode.d2.loss_cls: 0.3188  decode.d2.loss_mask: 1.0640  decode.d2.loss_dice: 0.7795  decode.d3.loss_cls: 0.2802  decode.d3.loss_mask: 1.0944  decode.d3.loss_dice: 0.8062  decode.d4.loss_cls: 0.2526  decode.d4.loss_mask: 1.0796  decode.d4.loss_dice: 0.7938  decode.d5.loss_cls: 0.2502  decode.d5.loss_mask: 1.0574  decode.d5.loss_dice: 0.7852  decode.d6.loss_cls: 0.2855  decode.d6.loss_mask: 1.0657  decode.d6.loss_dice: 0.7651  decode.d7.loss_cls: 0.2280  decode.d7.loss_mask: 1.1538  decode.d7.loss_dice: 0.7908  decode.d8.loss_cls: 0.2013  decode.d8.loss_mask: 1.1192  decode.d8.loss_dice: 0.8238
05/27 01:35:56 - mmengine - INFO - Iter(train) [123650/160000]  base_lr: 2.6348e-05 lr: 2.6348e-06  eta: 4:10:26  time: 0.4156  data_time: 0.0099  memory: 5965  grad_norm: 756.5460  loss: 17.4917  decode.loss_cls: 0.0915  decode.loss_mask: 0.9740  decode.loss_dice: 0.6369  decode.d0.loss_cls: 0.5420  decode.d0.loss_mask: 0.9700  decode.d0.loss_dice: 0.6524  decode.d1.loss_cls: 0.1252  decode.d1.loss_mask: 0.9491  decode.d1.loss_dice: 0.6288  decode.d2.loss_cls: 0.1325  decode.d2.loss_mask: 0.9522  decode.d2.loss_dice: 0.6445  decode.d3.loss_cls: 0.1245  decode.d3.loss_mask: 0.9315  decode.d3.loss_dice: 0.6183  decode.d4.loss_cls: 0.1191  decode.d4.loss_mask: 0.9783  decode.d4.loss_dice: 0.6190  decode.d5.loss_cls: 0.1111  decode.d5.loss_mask: 0.9568  decode.d5.loss_dice: 0.6240  decode.d6.loss_cls: 0.0989  decode.d6.loss_mask: 0.9741  decode.d6.loss_dice: 0.6189  decode.d7.loss_cls: 0.0927  decode.d7.loss_mask: 0.9702  decode.d7.loss_dice: 0.6333  decode.d8.loss_cls: 0.1211  decode.d8.loss_mask: 0.9679  decode.d8.loss_dice: 0.6328
05/27 01:36:17 - mmengine - INFO - Iter(train) [123700/160000]  base_lr: 2.6315e-05 lr: 2.6315e-06  eta: 4:10:06  time: 0.4157  data_time: 0.0100  memory: 5971  grad_norm: 571.8461  loss: 18.4917  decode.loss_cls: 0.1773  decode.loss_mask: 0.9202  decode.loss_dice: 0.7154  decode.d0.loss_cls: 0.5659  decode.d0.loss_mask: 0.8847  decode.d0.loss_dice: 0.7395  decode.d1.loss_cls: 0.1401  decode.d1.loss_mask: 0.9404  decode.d1.loss_dice: 0.7416  decode.d2.loss_cls: 0.1688  decode.d2.loss_mask: 0.9123  decode.d2.loss_dice: 0.7221  decode.d3.loss_cls: 0.1648  decode.d3.loss_mask: 0.9067  decode.d3.loss_dice: 0.7241  decode.d4.loss_cls: 0.1615  decode.d4.loss_mask: 0.9151  decode.d4.loss_dice: 0.7493  decode.d5.loss_cls: 0.1643  decode.d5.loss_mask: 0.9176  decode.d5.loss_dice: 0.7364  decode.d6.loss_cls: 0.1765  decode.d6.loss_mask: 0.9134  decode.d6.loss_dice: 0.7275  decode.d7.loss_cls: 0.1317  decode.d7.loss_mask: 0.9345  decode.d7.loss_dice: 0.7468  decode.d8.loss_cls: 0.1439  decode.d8.loss_mask: 0.9169  decode.d8.loss_dice: 0.7325
05/27 01:36:38 - mmengine - INFO - Iter(train) [123750/160000]  base_lr: 2.6283e-05 lr: 2.6283e-06  eta: 4:09:45  time: 0.4155  data_time: 0.0100  memory: 5966  grad_norm: 332.1714  loss: 14.5737  decode.loss_cls: 0.1172  decode.loss_mask: 0.7480  decode.loss_dice: 0.5602  decode.d0.loss_cls: 0.5285  decode.d0.loss_mask: 0.7413  decode.d0.loss_dice: 0.5487  decode.d1.loss_cls: 0.1213  decode.d1.loss_mask: 0.7316  decode.d1.loss_dice: 0.5634  decode.d2.loss_cls: 0.0916  decode.d2.loss_mask: 0.7518  decode.d2.loss_dice: 0.5647  decode.d3.loss_cls: 0.0922  decode.d3.loss_mask: 0.7473  decode.d3.loss_dice: 0.5610  decode.d4.loss_cls: 0.0981  decode.d4.loss_mask: 0.7457  decode.d4.loss_dice: 0.5579  decode.d5.loss_cls: 0.1258  decode.d5.loss_mask: 0.7340  decode.d5.loss_dice: 0.5564  decode.d6.loss_cls: 0.1079  decode.d6.loss_mask: 0.7502  decode.d6.loss_dice: 0.5619  decode.d7.loss_cls: 0.0959  decode.d7.loss_mask: 0.7533  decode.d7.loss_dice: 0.5675  decode.d8.loss_cls: 0.1240  decode.d8.loss_mask: 0.7676  decode.d8.loss_dice: 0.5589
05/27 01:36:58 - mmengine - INFO - Iter(train) [123800/160000]  base_lr: 2.6250e-05 lr: 2.6250e-06  eta: 4:09:25  time: 0.4162  data_time: 0.0099  memory: 5966  grad_norm: 820.3516  loss: 18.0545  decode.loss_cls: 0.0903  decode.loss_mask: 1.0024  decode.loss_dice: 0.6249  decode.d0.loss_cls: 0.6477  decode.d0.loss_mask: 1.0127  decode.d0.loss_dice: 0.6549  decode.d1.loss_cls: 0.1344  decode.d1.loss_mask: 1.0047  decode.d1.loss_dice: 0.6376  decode.d2.loss_cls: 0.1228  decode.d2.loss_mask: 1.0131  decode.d2.loss_dice: 0.6316  decode.d3.loss_cls: 0.0641  decode.d3.loss_mask: 1.0175  decode.d3.loss_dice: 0.6498  decode.d4.loss_cls: 0.1034  decode.d4.loss_mask: 1.0129  decode.d4.loss_dice: 0.6538  decode.d5.loss_cls: 0.0856  decode.d5.loss_mask: 1.0198  decode.d5.loss_dice: 0.6511  decode.d6.loss_cls: 0.0972  decode.d6.loss_mask: 1.0126  decode.d6.loss_dice: 0.6479  decode.d7.loss_cls: 0.0970  decode.d7.loss_mask: 1.0019  decode.d7.loss_dice: 0.6301  decode.d8.loss_cls: 0.1018  decode.d8.loss_mask: 1.0009  decode.d8.loss_dice: 0.6299
05/27 01:37:19 - mmengine - INFO - Iter(train) [123850/160000]  base_lr: 2.6218e-05 lr: 2.6218e-06  eta: 4:09:04  time: 0.4157  data_time: 0.0099  memory: 5983  grad_norm: 798.0382  loss: 23.8677  decode.loss_cls: 0.1841  decode.loss_mask: 1.2610  decode.loss_dice: 0.8765  decode.d0.loss_cls: 0.9470  decode.d0.loss_mask: 1.1617  decode.d0.loss_dice: 0.7614  decode.d1.loss_cls: 0.2762  decode.d1.loss_mask: 1.2039  decode.d1.loss_dice: 0.8470  decode.d2.loss_cls: 0.1962  decode.d2.loss_mask: 1.2547  decode.d2.loss_dice: 0.8505  decode.d3.loss_cls: 0.2057  decode.d3.loss_mask: 1.2524  decode.d3.loss_dice: 0.8475  decode.d4.loss_cls: 0.2050  decode.d4.loss_mask: 1.2638  decode.d4.loss_dice: 0.8683  decode.d5.loss_cls: 0.2061  decode.d5.loss_mask: 1.2368  decode.d5.loss_dice: 0.8482  decode.d6.loss_cls: 0.2431  decode.d6.loss_mask: 1.2629  decode.d6.loss_dice: 0.8746  decode.d7.loss_cls: 0.1910  decode.d7.loss_mask: 1.3083  decode.d7.loss_dice: 0.8666  decode.d8.loss_cls: 0.1878  decode.d8.loss_mask: 1.2953  decode.d8.loss_dice: 0.8843
05/27 01:37:40 - mmengine - INFO - Iter(train) [123900/160000]  base_lr: 2.6185e-05 lr: 2.6185e-06  eta: 4:08:43  time: 0.4164  data_time: 0.0107  memory: 5967  grad_norm: 522.7692  loss: 20.1413  decode.loss_cls: 0.1922  decode.loss_mask: 0.9644  decode.loss_dice: 0.7842  decode.d0.loss_cls: 0.6503  decode.d0.loss_mask: 0.9742  decode.d0.loss_dice: 0.7727  decode.d1.loss_cls: 0.2270  decode.d1.loss_mask: 0.9825  decode.d1.loss_dice: 0.7821  decode.d2.loss_cls: 0.2553  decode.d2.loss_mask: 0.9684  decode.d2.loss_dice: 0.7819  decode.d3.loss_cls: 0.2280  decode.d3.loss_mask: 0.9546  decode.d3.loss_dice: 0.7679  decode.d4.loss_cls: 0.1894  decode.d4.loss_mask: 0.9878  decode.d4.loss_dice: 0.8135  decode.d5.loss_cls: 0.1616  decode.d5.loss_mask: 0.9849  decode.d5.loss_dice: 0.7904  decode.d6.loss_cls: 0.2221  decode.d6.loss_mask: 0.9654  decode.d6.loss_dice: 0.7949  decode.d7.loss_cls: 0.1754  decode.d7.loss_mask: 1.0029  decode.d7.loss_dice: 0.8079  decode.d8.loss_cls: 0.2199  decode.d8.loss_mask: 0.9718  decode.d8.loss_dice: 0.7677
05/27 01:38:01 - mmengine - INFO - Iter(train) [123950/160000]  base_lr: 2.6152e-05 lr: 2.6152e-06  eta: 4:08:23  time: 0.4169  data_time: 0.0103  memory: 5980  grad_norm: 817.1336  loss: 20.4098  decode.loss_cls: 0.1826  decode.loss_mask: 1.0597  decode.loss_dice: 0.7199  decode.d0.loss_cls: 0.6861  decode.d0.loss_mask: 1.0229  decode.d0.loss_dice: 0.7363  decode.d1.loss_cls: 0.2199  decode.d1.loss_mask: 1.0646  decode.d1.loss_dice: 0.7403  decode.d2.loss_cls: 0.2344  decode.d2.loss_mask: 1.0560  decode.d2.loss_dice: 0.7087  decode.d3.loss_cls: 0.2102  decode.d3.loss_mask: 1.0443  decode.d3.loss_dice: 0.7153  decode.d4.loss_cls: 0.2113  decode.d4.loss_mask: 1.1032  decode.d4.loss_dice: 0.7519  decode.d5.loss_cls: 0.2032  decode.d5.loss_mask: 1.0619  decode.d5.loss_dice: 0.7234  decode.d6.loss_cls: 0.2199  decode.d6.loss_mask: 1.0292  decode.d6.loss_dice: 0.7091  decode.d7.loss_cls: 0.1770  decode.d7.loss_mask: 1.1113  decode.d7.loss_dice: 0.7310  decode.d8.loss_cls: 0.2268  decode.d8.loss_mask: 1.0438  decode.d8.loss_dice: 0.7053
05/27 01:38:22 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 01:38:22 - mmengine - INFO - Iter(train) [124000/160000]  base_lr: 2.6120e-05 lr: 2.6120e-06  eta: 4:08:02  time: 0.4157  data_time: 0.0099  memory: 5967  grad_norm: 1139.4464  loss: 17.9162  decode.loss_cls: 0.2038  decode.loss_mask: 0.8441  decode.loss_dice: 0.6504  decode.d0.loss_cls: 0.7692  decode.d0.loss_mask: 0.8913  decode.d0.loss_dice: 0.7011  decode.d1.loss_cls: 0.2501  decode.d1.loss_mask: 0.8957  decode.d1.loss_dice: 0.6831  decode.d2.loss_cls: 0.2309  decode.d2.loss_mask: 0.8350  decode.d2.loss_dice: 0.6557  decode.d3.loss_cls: 0.2618  decode.d3.loss_mask: 0.8520  decode.d3.loss_dice: 0.6422  decode.d4.loss_cls: 0.2362  decode.d4.loss_mask: 0.8413  decode.d4.loss_dice: 0.6426  decode.d5.loss_cls: 0.2258  decode.d5.loss_mask: 0.8379  decode.d5.loss_dice: 0.6542  decode.d6.loss_cls: 0.2129  decode.d6.loss_mask: 0.8351  decode.d6.loss_dice: 0.6405  decode.d7.loss_cls: 0.2224  decode.d7.loss_mask: 0.8455  decode.d7.loss_dice: 0.6409  decode.d8.loss_cls: 0.1946  decode.d8.loss_mask: 0.8462  decode.d8.loss_dice: 0.6737
05/27 01:38:43 - mmengine - INFO - Iter(train) [124050/160000]  base_lr: 2.6087e-05 lr: 2.6087e-06  eta: 4:07:41  time: 0.4151  data_time: 0.0099  memory: 5975  grad_norm: 991.5932  loss: 17.5659  decode.loss_cls: 0.1767  decode.loss_mask: 0.8735  decode.loss_dice: 0.6260  decode.d0.loss_cls: 0.6226  decode.d0.loss_mask: 0.9254  decode.d0.loss_dice: 0.6647  decode.d1.loss_cls: 0.1829  decode.d1.loss_mask: 0.8986  decode.d1.loss_dice: 0.6362  decode.d2.loss_cls: 0.1858  decode.d2.loss_mask: 0.9039  decode.d2.loss_dice: 0.6472  decode.d3.loss_cls: 0.1736  decode.d3.loss_mask: 0.8786  decode.d3.loss_dice: 0.6389  decode.d4.loss_cls: 0.1862  decode.d4.loss_mask: 0.8902  decode.d4.loss_dice: 0.6499  decode.d5.loss_cls: 0.2234  decode.d5.loss_mask: 0.8774  decode.d5.loss_dice: 0.6395  decode.d6.loss_cls: 0.1864  decode.d6.loss_mask: 0.8813  decode.d6.loss_dice: 0.6485  decode.d7.loss_cls: 0.1573  decode.d7.loss_mask: 0.8782  decode.d7.loss_dice: 0.6382  decode.d8.loss_cls: 0.1842  decode.d8.loss_mask: 0.8726  decode.d8.loss_dice: 0.6179
05/27 01:39:03 - mmengine - INFO - Iter(train) [124100/160000]  base_lr: 2.6054e-05 lr: 2.6054e-06  eta: 4:07:21  time: 0.4162  data_time: 0.0104  memory: 5987  grad_norm: 483.8978  loss: 20.2850  decode.loss_cls: 0.2214  decode.loss_mask: 1.0627  decode.loss_dice: 0.6814  decode.d0.loss_cls: 0.7116  decode.d0.loss_mask: 1.0477  decode.d0.loss_dice: 0.6636  decode.d1.loss_cls: 0.2483  decode.d1.loss_mask: 1.0429  decode.d1.loss_dice: 0.6393  decode.d2.loss_cls: 0.2583  decode.d2.loss_mask: 1.0429  decode.d2.loss_dice: 0.6456  decode.d3.loss_cls: 0.2342  decode.d3.loss_mask: 1.0665  decode.d3.loss_dice: 0.6660  decode.d4.loss_cls: 0.2356  decode.d4.loss_mask: 1.0581  decode.d4.loss_dice: 0.6750  decode.d5.loss_cls: 0.2070  decode.d5.loss_mask: 1.1388  decode.d5.loss_dice: 0.6900  decode.d6.loss_cls: 0.2560  decode.d6.loss_mask: 1.1233  decode.d6.loss_dice: 0.6647  decode.d7.loss_cls: 0.2551  decode.d7.loss_mask: 1.0811  decode.d7.loss_dice: 0.6783  decode.d8.loss_cls: 0.2481  decode.d8.loss_mask: 1.0603  decode.d8.loss_dice: 0.6809
05/27 01:39:24 - mmengine - INFO - Iter(train) [124150/160000]  base_lr: 2.6022e-05 lr: 2.6022e-06  eta: 4:07:00  time: 0.4160  data_time: 0.0099  memory: 5975  grad_norm: 368.2693  loss: 18.4347  decode.loss_cls: 0.1400  decode.loss_mask: 0.9594  decode.loss_dice: 0.6992  decode.d0.loss_cls: 0.5483  decode.d0.loss_mask: 0.9369  decode.d0.loss_dice: 0.6884  decode.d1.loss_cls: 0.1432  decode.d1.loss_mask: 0.9636  decode.d1.loss_dice: 0.7021  decode.d2.loss_cls: 0.1587  decode.d2.loss_mask: 0.9566  decode.d2.loss_dice: 0.7092  decode.d3.loss_cls: 0.1473  decode.d3.loss_mask: 0.9548  decode.d3.loss_dice: 0.7011  decode.d4.loss_cls: 0.1457  decode.d4.loss_mask: 0.9619  decode.d4.loss_dice: 0.7003  decode.d5.loss_cls: 0.1375  decode.d5.loss_mask: 0.9572  decode.d5.loss_dice: 0.6985  decode.d6.loss_cls: 0.1528  decode.d6.loss_mask: 0.9617  decode.d6.loss_dice: 0.6968  decode.d7.loss_cls: 0.1679  decode.d7.loss_mask: 0.9593  decode.d7.loss_dice: 0.6919  decode.d8.loss_cls: 0.1432  decode.d8.loss_mask: 0.9580  decode.d8.loss_dice: 0.6933
05/27 01:39:45 - mmengine - INFO - Iter(train) [124200/160000]  base_lr: 2.5989e-05 lr: 2.5989e-06  eta: 4:06:40  time: 0.4153  data_time: 0.0099  memory: 5969  grad_norm: 508.2412  loss: 19.2796  decode.loss_cls: 0.2235  decode.loss_mask: 0.8957  decode.loss_dice: 0.7030  decode.d0.loss_cls: 0.6247  decode.d0.loss_mask: 0.9272  decode.d0.loss_dice: 0.7625  decode.d1.loss_cls: 0.2562  decode.d1.loss_mask: 0.9382  decode.d1.loss_dice: 0.7346  decode.d2.loss_cls: 0.2169  decode.d2.loss_mask: 0.9506  decode.d2.loss_dice: 0.7348  decode.d3.loss_cls: 0.2237  decode.d3.loss_mask: 0.9344  decode.d3.loss_dice: 0.7307  decode.d4.loss_cls: 0.2279  decode.d4.loss_mask: 0.9215  decode.d4.loss_dice: 0.7388  decode.d5.loss_cls: 0.2215  decode.d5.loss_mask: 0.9167  decode.d5.loss_dice: 0.7387  decode.d6.loss_cls: 0.2022  decode.d6.loss_mask: 0.9134  decode.d6.loss_dice: 0.7397  decode.d7.loss_cls: 0.2534  decode.d7.loss_mask: 0.9179  decode.d7.loss_dice: 0.7523  decode.d8.loss_cls: 0.2110  decode.d8.loss_mask: 0.9237  decode.d8.loss_dice: 0.7441
05/27 01:40:06 - mmengine - INFO - Iter(train) [124250/160000]  base_lr: 2.5956e-05 lr: 2.5956e-06  eta: 4:06:19  time: 0.4165  data_time: 0.0099  memory: 5968  grad_norm: 554.2558  loss: 18.9519  decode.loss_cls: 0.1928  decode.loss_mask: 0.9927  decode.loss_dice: 0.7279  decode.d0.loss_cls: 0.6348  decode.d0.loss_mask: 0.9661  decode.d0.loss_dice: 0.6871  decode.d1.loss_cls: 0.1815  decode.d1.loss_mask: 0.9644  decode.d1.loss_dice: 0.7038  decode.d2.loss_cls: 0.1597  decode.d2.loss_mask: 0.9592  decode.d2.loss_dice: 0.7044  decode.d3.loss_cls: 0.1721  decode.d3.loss_mask: 0.9657  decode.d3.loss_dice: 0.6863  decode.d4.loss_cls: 0.1594  decode.d4.loss_mask: 0.9757  decode.d4.loss_dice: 0.6950  decode.d5.loss_cls: 0.1532  decode.d5.loss_mask: 0.9811  decode.d5.loss_dice: 0.7241  decode.d6.loss_cls: 0.1532  decode.d6.loss_mask: 0.9581  decode.d6.loss_dice: 0.7058  decode.d7.loss_cls: 0.1788  decode.d7.loss_mask: 0.9653  decode.d7.loss_dice: 0.7149  decode.d8.loss_cls: 0.1684  decode.d8.loss_mask: 0.9776  decode.d8.loss_dice: 0.7425
05/27 01:40:27 - mmengine - INFO - Iter(train) [124300/160000]  base_lr: 2.5924e-05 lr: 2.5924e-06  eta: 4:05:58  time: 0.4161  data_time: 0.0100  memory: 5969  grad_norm: 731.7260  loss: 15.6594  decode.loss_cls: 0.1062  decode.loss_mask: 0.8210  decode.loss_dice: 0.5761  decode.d0.loss_cls: 0.7045  decode.d0.loss_mask: 0.7517  decode.d0.loss_dice: 0.5734  decode.d1.loss_cls: 0.1075  decode.d1.loss_mask: 0.8272  decode.d1.loss_dice: 0.5898  decode.d2.loss_cls: 0.1356  decode.d2.loss_mask: 0.8065  decode.d2.loss_dice: 0.5859  decode.d3.loss_cls: 0.1247  decode.d3.loss_mask: 0.8313  decode.d3.loss_dice: 0.6055  decode.d4.loss_cls: 0.1343  decode.d4.loss_mask: 0.8078  decode.d4.loss_dice: 0.5759  decode.d5.loss_cls: 0.1171  decode.d5.loss_mask: 0.8132  decode.d5.loss_dice: 0.5760  decode.d6.loss_cls: 0.1340  decode.d6.loss_mask: 0.8025  decode.d6.loss_dice: 0.5781  decode.d7.loss_cls: 0.1291  decode.d7.loss_mask: 0.7843  decode.d7.loss_dice: 0.5807  decode.d8.loss_cls: 0.1102  decode.d8.loss_mask: 0.8017  decode.d8.loss_dice: 0.5679
05/27 01:40:48 - mmengine - INFO - Iter(train) [124350/160000]  base_lr: 2.5891e-05 lr: 2.5891e-06  eta: 4:05:38  time: 0.4158  data_time: 0.0099  memory: 5968  grad_norm: 900.6557  loss: 19.0637  decode.loss_cls: 0.1948  decode.loss_mask: 0.9276  decode.loss_dice: 0.7084  decode.d0.loss_cls: 0.5986  decode.d0.loss_mask: 1.0048  decode.d0.loss_dice: 0.7230  decode.d1.loss_cls: 0.2379  decode.d1.loss_mask: 0.9440  decode.d1.loss_dice: 0.7095  decode.d2.loss_cls: 0.2315  decode.d2.loss_mask: 0.9271  decode.d2.loss_dice: 0.6779  decode.d3.loss_cls: 0.2327  decode.d3.loss_mask: 0.9427  decode.d3.loss_dice: 0.6931  decode.d4.loss_cls: 0.2306  decode.d4.loss_mask: 0.9174  decode.d4.loss_dice: 0.6834  decode.d5.loss_cls: 0.2221  decode.d5.loss_mask: 0.9330  decode.d5.loss_dice: 0.6952  decode.d6.loss_cls: 0.2362  decode.d6.loss_mask: 0.9362  decode.d6.loss_dice: 0.7175  decode.d7.loss_cls: 0.2448  decode.d7.loss_mask: 0.9574  decode.d7.loss_dice: 0.7115  decode.d8.loss_cls: 0.1951  decode.d8.loss_mask: 0.9447  decode.d8.loss_dice: 0.6849
05/27 01:41:08 - mmengine - INFO - Iter(train) [124400/160000]  base_lr: 2.5858e-05 lr: 2.5858e-06  eta: 4:05:17  time: 0.4163  data_time: 0.0099  memory: 5975  grad_norm: 450.8538  loss: 20.1876  decode.loss_cls: 0.1572  decode.loss_mask: 1.0669  decode.loss_dice: 0.7213  decode.d0.loss_cls: 0.7287  decode.d0.loss_mask: 0.9922  decode.d0.loss_dice: 0.7017  decode.d1.loss_cls: 0.1688  decode.d1.loss_mask: 1.0993  decode.d1.loss_dice: 0.7455  decode.d2.loss_cls: 0.1563  decode.d2.loss_mask: 1.0696  decode.d2.loss_dice: 0.7373  decode.d3.loss_cls: 0.1578  decode.d3.loss_mask: 1.0634  decode.d3.loss_dice: 0.7358  decode.d4.loss_cls: 0.1833  decode.d4.loss_mask: 1.0672  decode.d4.loss_dice: 0.7300  decode.d5.loss_cls: 0.1584  decode.d5.loss_mask: 1.0974  decode.d5.loss_dice: 0.7512  decode.d6.loss_cls: 0.1597  decode.d6.loss_mask: 1.0688  decode.d6.loss_dice: 0.7387  decode.d7.loss_cls: 0.1588  decode.d7.loss_mask: 1.0745  decode.d7.loss_dice: 0.7360  decode.d8.loss_cls: 0.1627  decode.d8.loss_mask: 1.0682  decode.d8.loss_dice: 0.7306
05/27 01:41:29 - mmengine - INFO - Iter(train) [124450/160000]  base_lr: 2.5826e-05 lr: 2.5826e-06  eta: 4:04:56  time: 0.4164  data_time: 0.0099  memory: 5984  grad_norm: 346.6499  loss: 17.1829  decode.loss_cls: 0.1117  decode.loss_mask: 0.9415  decode.loss_dice: 0.6371  decode.d0.loss_cls: 0.5087  decode.d0.loss_mask: 0.9041  decode.d0.loss_dice: 0.6313  decode.d1.loss_cls: 0.1027  decode.d1.loss_mask: 0.9443  decode.d1.loss_dice: 0.6291  decode.d2.loss_cls: 0.0783  decode.d2.loss_mask: 0.9414  decode.d2.loss_dice: 0.6449  decode.d3.loss_cls: 0.0952  decode.d3.loss_mask: 0.9506  decode.d3.loss_dice: 0.6462  decode.d4.loss_cls: 0.0862  decode.d4.loss_mask: 0.9429  decode.d4.loss_dice: 0.6341  decode.d5.loss_cls: 0.0935  decode.d5.loss_mask: 0.9332  decode.d5.loss_dice: 0.6253  decode.d6.loss_cls: 0.1081  decode.d6.loss_mask: 0.9483  decode.d6.loss_dice: 0.6441  decode.d7.loss_cls: 0.0929  decode.d7.loss_mask: 0.9552  decode.d7.loss_dice: 0.6492  decode.d8.loss_cls: 0.0945  decode.d8.loss_mask: 0.9561  decode.d8.loss_dice: 0.6520
05/27 01:41:50 - mmengine - INFO - Iter(train) [124500/160000]  base_lr: 2.5793e-05 lr: 2.5793e-06  eta: 4:04:36  time: 0.4167  data_time: 0.0100  memory: 5973  grad_norm: 617.0058  loss: 19.3509  decode.loss_cls: 0.1927  decode.loss_mask: 0.9911  decode.loss_dice: 0.7059  decode.d0.loss_cls: 0.5464  decode.d0.loss_mask: 0.9779  decode.d0.loss_dice: 0.7080  decode.d1.loss_cls: 0.1947  decode.d1.loss_mask: 1.0010  decode.d1.loss_dice: 0.7173  decode.d2.loss_cls: 0.1743  decode.d2.loss_mask: 0.9944  decode.d2.loss_dice: 0.7295  decode.d3.loss_cls: 0.1730  decode.d3.loss_mask: 1.0000  decode.d3.loss_dice: 0.7192  decode.d4.loss_cls: 0.1767  decode.d4.loss_mask: 1.0078  decode.d4.loss_dice: 0.7258  decode.d5.loss_cls: 0.1819  decode.d5.loss_mask: 1.0003  decode.d5.loss_dice: 0.7410  decode.d6.loss_cls: 0.1730  decode.d6.loss_mask: 1.0073  decode.d6.loss_dice: 0.7268  decode.d7.loss_cls: 0.1780  decode.d7.loss_mask: 1.0022  decode.d7.loss_dice: 0.7128  decode.d8.loss_cls: 0.1935  decode.d8.loss_mask: 0.9921  decode.d8.loss_dice: 0.7063
05/27 01:42:11 - mmengine - INFO - Iter(train) [124550/160000]  base_lr: 2.5760e-05 lr: 2.5760e-06  eta: 4:04:15  time: 0.4153  data_time: 0.0098  memory: 5968  grad_norm: 736.5192  loss: 18.4172  decode.loss_cls: 0.1368  decode.loss_mask: 0.9618  decode.loss_dice: 0.7071  decode.d0.loss_cls: 0.5974  decode.d0.loss_mask: 0.9004  decode.d0.loss_dice: 0.6914  decode.d1.loss_cls: 0.1447  decode.d1.loss_mask: 0.9662  decode.d1.loss_dice: 0.6923  decode.d2.loss_cls: 0.1308  decode.d2.loss_mask: 0.9576  decode.d2.loss_dice: 0.7051  decode.d3.loss_cls: 0.1339  decode.d3.loss_mask: 0.9601  decode.d3.loss_dice: 0.7045  decode.d4.loss_cls: 0.1475  decode.d4.loss_mask: 0.9739  decode.d4.loss_dice: 0.7159  decode.d5.loss_cls: 0.1285  decode.d5.loss_mask: 0.9628  decode.d5.loss_dice: 0.7133  decode.d6.loss_cls: 0.1363  decode.d6.loss_mask: 0.9591  decode.d6.loss_dice: 0.7016  decode.d7.loss_cls: 0.1403  decode.d7.loss_mask: 0.9563  decode.d7.loss_dice: 0.7050  decode.d8.loss_cls: 0.1358  decode.d8.loss_mask: 0.9522  decode.d8.loss_dice: 0.6983
05/27 01:42:32 - mmengine - INFO - Iter(train) [124600/160000]  base_lr: 2.5727e-05 lr: 2.5727e-06  eta: 4:03:54  time: 0.4170  data_time: 0.0099  memory: 5984  grad_norm: 564.8629  loss: 20.3801  decode.loss_cls: 0.2824  decode.loss_mask: 1.0180  decode.loss_dice: 0.6815  decode.d0.loss_cls: 0.8254  decode.d0.loss_mask: 0.9748  decode.d0.loss_dice: 0.6987  decode.d1.loss_cls: 0.2840  decode.d1.loss_mask: 1.0011  decode.d1.loss_dice: 0.6796  decode.d2.loss_cls: 0.2811  decode.d2.loss_mask: 1.0238  decode.d2.loss_dice: 0.6862  decode.d3.loss_cls: 0.2664  decode.d3.loss_mask: 0.9976  decode.d3.loss_dice: 0.6857  decode.d4.loss_cls: 0.2161  decode.d4.loss_mask: 1.0475  decode.d4.loss_dice: 0.7181  decode.d5.loss_cls: 0.2182  decode.d5.loss_mask: 1.0452  decode.d5.loss_dice: 0.7447  decode.d6.loss_cls: 0.2456  decode.d6.loss_mask: 1.0434  decode.d6.loss_dice: 0.7207  decode.d7.loss_cls: 0.2952  decode.d7.loss_mask: 1.0445  decode.d7.loss_dice: 0.6775  decode.d8.loss_cls: 0.2966  decode.d8.loss_mask: 1.0028  decode.d8.loss_dice: 0.6775
05/27 01:42:53 - mmengine - INFO - Iter(train) [124650/160000]  base_lr: 2.5695e-05 lr: 2.5695e-06  eta: 4:03:34  time: 0.4157  data_time: 0.0099  memory: 5966  grad_norm: 501.1866  loss: 15.6675  decode.loss_cls: 0.1374  decode.loss_mask: 0.8688  decode.loss_dice: 0.5097  decode.d0.loss_cls: 0.5562  decode.d0.loss_mask: 0.8703  decode.d0.loss_dice: 0.5316  decode.d1.loss_cls: 0.1193  decode.d1.loss_mask: 0.9083  decode.d1.loss_dice: 0.5366  decode.d2.loss_cls: 0.1143  decode.d2.loss_mask: 0.8765  decode.d2.loss_dice: 0.5161  decode.d3.loss_cls: 0.1101  decode.d3.loss_mask: 0.8535  decode.d3.loss_dice: 0.5130  decode.d4.loss_cls: 0.1122  decode.d4.loss_mask: 0.8703  decode.d4.loss_dice: 0.5146  decode.d5.loss_cls: 0.1578  decode.d5.loss_mask: 0.8911  decode.d5.loss_dice: 0.5284  decode.d6.loss_cls: 0.1226  decode.d6.loss_mask: 0.8716  decode.d6.loss_dice: 0.5245  decode.d7.loss_cls: 0.0866  decode.d7.loss_mask: 0.9026  decode.d7.loss_dice: 0.5437  decode.d8.loss_cls: 0.1236  decode.d8.loss_mask: 0.8627  decode.d8.loss_dice: 0.5337
05/27 01:43:13 - mmengine - INFO - Iter(train) [124700/160000]  base_lr: 2.5662e-05 lr: 2.5662e-06  eta: 4:03:13  time: 0.4161  data_time: 0.0099  memory: 5969  grad_norm: 526.5240  loss: 20.0564  decode.loss_cls: 0.2251  decode.loss_mask: 1.0196  decode.loss_dice: 0.6876  decode.d0.loss_cls: 0.6899  decode.d0.loss_mask: 1.0449  decode.d0.loss_dice: 0.7114  decode.d1.loss_cls: 0.2375  decode.d1.loss_mask: 1.0482  decode.d1.loss_dice: 0.7404  decode.d2.loss_cls: 0.1422  decode.d2.loss_mask: 1.0584  decode.d2.loss_dice: 0.7391  decode.d3.loss_cls: 0.1901  decode.d3.loss_mask: 1.0187  decode.d3.loss_dice: 0.7248  decode.d4.loss_cls: 0.1604  decode.d4.loss_mask: 1.0757  decode.d4.loss_dice: 0.7050  decode.d5.loss_cls: 0.2138  decode.d5.loss_mask: 1.0657  decode.d5.loss_dice: 0.7179  decode.d6.loss_cls: 0.1716  decode.d6.loss_mask: 1.0485  decode.d6.loss_dice: 0.7364  decode.d7.loss_cls: 0.1639  decode.d7.loss_mask: 1.0451  decode.d7.loss_dice: 0.7360  decode.d8.loss_cls: 0.1768  decode.d8.loss_mask: 1.0418  decode.d8.loss_dice: 0.7198
05/27 01:43:34 - mmengine - INFO - Iter(train) [124750/160000]  base_lr: 2.5629e-05 lr: 2.5629e-06  eta: 4:02:53  time: 0.4163  data_time: 0.0099  memory: 5972  grad_norm: 483.6172  loss: 17.3023  decode.loss_cls: 0.1194  decode.loss_mask: 0.8962  decode.loss_dice: 0.6658  decode.d0.loss_cls: 0.6862  decode.d0.loss_mask: 0.8258  decode.d0.loss_dice: 0.6616  decode.d1.loss_cls: 0.1788  decode.d1.loss_mask: 0.8671  decode.d1.loss_dice: 0.6532  decode.d2.loss_cls: 0.1701  decode.d2.loss_mask: 0.8624  decode.d2.loss_dice: 0.6425  decode.d3.loss_cls: 0.1591  decode.d3.loss_mask: 0.8504  decode.d3.loss_dice: 0.6439  decode.d4.loss_cls: 0.1467  decode.d4.loss_mask: 0.9016  decode.d4.loss_dice: 0.6446  decode.d5.loss_cls: 0.1394  decode.d5.loss_mask: 0.8854  decode.d5.loss_dice: 0.6546  decode.d6.loss_cls: 0.1639  decode.d6.loss_mask: 0.8576  decode.d6.loss_dice: 0.6507  decode.d7.loss_cls: 0.2258  decode.d7.loss_mask: 0.8265  decode.d7.loss_dice: 0.6518  decode.d8.loss_cls: 0.1208  decode.d8.loss_mask: 0.8897  decode.d8.loss_dice: 0.6607
05/27 01:43:55 - mmengine - INFO - Iter(train) [124800/160000]  base_lr: 2.5597e-05 lr: 2.5597e-06  eta: 4:02:32  time: 0.4163  data_time: 0.0099  memory: 5975  grad_norm: 455.9398  loss: 17.3703  decode.loss_cls: 0.0654  decode.loss_mask: 0.9472  decode.loss_dice: 0.6777  decode.d0.loss_cls: 0.6235  decode.d0.loss_mask: 0.9075  decode.d0.loss_dice: 0.6404  decode.d1.loss_cls: 0.0844  decode.d1.loss_mask: 0.9543  decode.d1.loss_dice: 0.6709  decode.d2.loss_cls: 0.0892  decode.d2.loss_mask: 0.9372  decode.d2.loss_dice: 0.6624  decode.d3.loss_cls: 0.0737  decode.d3.loss_mask: 0.9441  decode.d3.loss_dice: 0.6762  decode.d4.loss_cls: 0.0780  decode.d4.loss_mask: 0.9480  decode.d4.loss_dice: 0.6665  decode.d5.loss_cls: 0.0804  decode.d5.loss_mask: 0.9373  decode.d5.loss_dice: 0.6744  decode.d6.loss_cls: 0.0734  decode.d6.loss_mask: 0.9348  decode.d6.loss_dice: 0.6660  decode.d7.loss_cls: 0.0724  decode.d7.loss_mask: 0.9406  decode.d7.loss_dice: 0.6599  decode.d8.loss_cls: 0.0831  decode.d8.loss_mask: 0.9344  decode.d8.loss_dice: 0.6671
05/27 01:44:16 - mmengine - INFO - Iter(train) [124850/160000]  base_lr: 2.5564e-05 lr: 2.5564e-06  eta: 4:02:11  time: 0.4166  data_time: 0.0099  memory: 5976  grad_norm: 604.3313  loss: 20.6677  decode.loss_cls: 0.2162  decode.loss_mask: 1.0655  decode.loss_dice: 0.7714  decode.d0.loss_cls: 0.6344  decode.d0.loss_mask: 1.0423  decode.d0.loss_dice: 0.7895  decode.d1.loss_cls: 0.1809  decode.d1.loss_mask: 1.0406  decode.d1.loss_dice: 0.7618  decode.d2.loss_cls: 0.1729  decode.d2.loss_mask: 1.0551  decode.d2.loss_dice: 0.7515  decode.d3.loss_cls: 0.1886  decode.d3.loss_mask: 1.0760  decode.d3.loss_dice: 0.7671  decode.d4.loss_cls: 0.1845  decode.d4.loss_mask: 1.0576  decode.d4.loss_dice: 0.7545  decode.d5.loss_cls: 0.1848  decode.d5.loss_mask: 1.0820  decode.d5.loss_dice: 0.7719  decode.d6.loss_cls: 0.2162  decode.d6.loss_mask: 1.0562  decode.d6.loss_dice: 0.7700  decode.d7.loss_cls: 0.2169  decode.d7.loss_mask: 1.0486  decode.d7.loss_dice: 0.7743  decode.d8.loss_cls: 0.1735  decode.d8.loss_mask: 1.0758  decode.d8.loss_dice: 0.7870
05/27 01:44:37 - mmengine - INFO - Iter(train) [124900/160000]  base_lr: 2.5531e-05 lr: 2.5531e-06  eta: 4:01:51  time: 0.4171  data_time: 0.0099  memory: 5967  grad_norm: 394.1547  loss: 18.4576  decode.loss_cls: 0.2156  decode.loss_mask: 0.8437  decode.loss_dice: 0.6858  decode.d0.loss_cls: 0.7730  decode.d0.loss_mask: 0.8620  decode.d0.loss_dice: 0.7053  decode.d1.loss_cls: 0.2629  decode.d1.loss_mask: 0.8873  decode.d1.loss_dice: 0.7110  decode.d2.loss_cls: 0.2043  decode.d2.loss_mask: 0.8852  decode.d2.loss_dice: 0.7087  decode.d3.loss_cls: 0.2640  decode.d3.loss_mask: 0.8496  decode.d3.loss_dice: 0.6952  decode.d4.loss_cls: 0.2398  decode.d4.loss_mask: 0.8573  decode.d4.loss_dice: 0.7000  decode.d5.loss_cls: 0.2381  decode.d5.loss_mask: 0.8475  decode.d5.loss_dice: 0.6874  decode.d6.loss_cls: 0.2123  decode.d6.loss_mask: 0.8502  decode.d6.loss_dice: 0.7102  decode.d7.loss_cls: 0.2335  decode.d7.loss_mask: 0.8643  decode.d7.loss_dice: 0.6779  decode.d8.loss_cls: 0.2294  decode.d8.loss_mask: 0.8632  decode.d8.loss_dice: 0.6930
05/27 01:44:58 - mmengine - INFO - Iter(train) [124950/160000]  base_lr: 2.5498e-05 lr: 2.5498e-06  eta: 4:01:30  time: 0.4171  data_time: 0.0099  memory: 5980  grad_norm: 1189.7181  loss: 24.5922  decode.loss_cls: 0.3409  decode.loss_mask: 1.1768  decode.loss_dice: 0.7961  decode.d0.loss_cls: 0.8416  decode.d0.loss_mask: 1.2305  decode.d0.loss_dice: 0.7991  decode.d1.loss_cls: 0.3151  decode.d1.loss_mask: 1.3087  decode.d1.loss_dice: 0.9072  decode.d2.loss_cls: 0.3492  decode.d2.loss_mask: 1.2634  decode.d2.loss_dice: 0.8280  decode.d3.loss_cls: 0.3387  decode.d3.loss_mask: 1.2055  decode.d3.loss_dice: 0.8063  decode.d4.loss_cls: 0.3744  decode.d4.loss_mask: 1.2220  decode.d4.loss_dice: 0.8402  decode.d5.loss_cls: 0.3794  decode.d5.loss_mask: 1.2240  decode.d5.loss_dice: 0.8017  decode.d6.loss_cls: 0.3808  decode.d6.loss_mask: 1.2161  decode.d6.loss_dice: 0.8078  decode.d7.loss_cls: 0.3906  decode.d7.loss_mask: 1.2521  decode.d7.loss_dice: 0.8235  decode.d8.loss_cls: 0.3649  decode.d8.loss_mask: 1.1911  decode.d8.loss_dice: 0.8166
05/27 01:45:19 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 01:45:19 - mmengine - INFO - Iter(train) [125000/160000]  base_lr: 2.5466e-05 lr: 2.5466e-06  eta: 4:01:09  time: 0.4163  data_time: 0.0099  memory: 5966  grad_norm: 472.8608  loss: 16.3622  decode.loss_cls: 0.1095  decode.loss_mask: 0.8418  decode.loss_dice: 0.6090  decode.d0.loss_cls: 0.6104  decode.d0.loss_mask: 0.8345  decode.d0.loss_dice: 0.6508  decode.d1.loss_cls: 0.1317  decode.d1.loss_mask: 0.8406  decode.d1.loss_dice: 0.6031  decode.d2.loss_cls: 0.1457  decode.d2.loss_mask: 0.8420  decode.d2.loss_dice: 0.6144  decode.d3.loss_cls: 0.1154  decode.d3.loss_mask: 0.8517  decode.d3.loss_dice: 0.6205  decode.d4.loss_cls: 0.1323  decode.d4.loss_mask: 0.8595  decode.d4.loss_dice: 0.6123  decode.d5.loss_cls: 0.1354  decode.d5.loss_mask: 0.8250  decode.d5.loss_dice: 0.6115  decode.d6.loss_cls: 0.1124  decode.d6.loss_mask: 0.8472  decode.d6.loss_dice: 0.6294  decode.d7.loss_cls: 0.1428  decode.d7.loss_mask: 0.8512  decode.d7.loss_dice: 0.6185  decode.d8.loss_cls: 0.1162  decode.d8.loss_mask: 0.8375  decode.d8.loss_dice: 0.6096
05/27 01:45:19 - mmengine - INFO - Saving checkpoint at 125000 iterations
05/27 01:45:23 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:07  time: 0.0480  data_time: 0.0012  memory: 1391  
05/27 01:45:25 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:04  time: 0.0476  data_time: 0.0012  memory: 1205  
05/27 01:45:28 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:03  time: 0.0504  data_time: 0.0012  memory: 1596  
05/27 01:45:30 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0487  data_time: 0.0012  memory: 1298  
05/27 01:45:33 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:58  time: 0.0478  data_time: 0.0012  memory: 1298  
05/27 01:45:35 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0479  data_time: 0.0012  memory: 1279  
05/27 01:45:38 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:53  time: 0.0479  data_time: 0.0012  memory: 1224  
05/27 01:45:40 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0488  data_time: 0.0012  memory: 1298  
05/27 01:45:42 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0474  data_time: 0.0012  memory: 1298  
05/27 01:45:45 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0512  data_time: 0.0012  memory: 1725  
05/27 01:45:47 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0489  data_time: 0.0013  memory: 1336  
05/27 01:45:50 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0480  data_time: 0.0012  memory: 1298  
05/27 01:45:52 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0481  data_time: 0.0012  memory: 1205  
05/27 01:45:54 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0488  data_time: 0.0012  memory: 1316  
05/27 01:45:57 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0487  data_time: 0.0013  memory: 1279  
05/27 01:45:59 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0512  data_time: 0.0012  memory: 1410  
05/27 01:46:02 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0475  data_time: 0.0013  memory: 1279  
05/27 01:46:04 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0485  data_time: 0.0012  memory: 1205  
05/27 01:46:06 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0484  data_time: 0.0012  memory: 1205  
05/27 01:46:09 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0478  data_time: 0.0012  memory: 1336  
05/27 01:46:11 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0476  data_time: 0.0012  memory: 1246  
05/27 01:46:14 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0498  data_time: 0.0012  memory: 1503  
05/27 01:46:16 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0476  data_time: 0.0012  memory: 1261  
05/27 01:46:19 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0484  data_time: 0.0012  memory: 1298  
05/27 01:46:21 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0477  data_time: 0.0012  memory: 1447  
05/27 01:46:23 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0475  data_time: 0.0012  memory: 1298  
05/27 01:46:26 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0489  data_time: 0.0012  memory: 1279  
05/27 01:46:28 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0476  data_time: 0.0012  memory: 1205  
05/27 01:46:31 - mmengine - INFO - per class results:
05/27 01:46:31 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.69 | 97.77 |
|  aeroplane  | 92.36 | 96.17 |
|   bicycle   | 44.06 | 92.99 |
|     bird    | 95.86 | 98.15 |
|     boat    | 71.25 | 91.64 |
|    bottle   | 84.56 | 93.63 |
|     bus     |  96.0 |  98.0 |
|     car     | 91.93 | 95.13 |
|     cat     | 94.72 | 97.27 |
|    chair    | 42.57 | 50.03 |
|     cow     | 91.15 | 96.24 |
| diningtable | 60.55 | 63.91 |
|     dog     | 90.16 | 96.77 |
|    horse    |  91.2 | 96.67 |
|  motorbike  | 89.62 | 97.15 |
|    person   | 90.25 |  94.7 |
| pottedplant | 71.24 | 88.33 |
|    sheep    |  85.8 | 92.31 |
|     sofa    | 61.86 | 76.24 |
|    train    | 89.65 | 96.42 |
|  tvmonitor  | 82.54 | 85.07 |
+-------------+-------+-------+
05/27 01:46:31 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 96.0900  mIoU: 81.5700  mAcc: 90.2200  data_time: 0.0013  time: 0.0481
05/27 01:46:31 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_100000.pth is removed
05/27 01:46:32 - mmengine - INFO - The best checkpoint with 81.5700 mIoU at 125000 iter is saved to best_mIoU_iter_125000.pth.
05/27 01:46:55 - mmengine - INFO - Iter(train) [125050/160000]  base_lr: 2.5433e-05 lr: 2.5433e-06  eta: 4:00:50  time: 0.4163  data_time: 0.0100  memory: 5969  grad_norm: 641.1844  loss: 17.7430  decode.loss_cls: 0.2571  decode.loss_mask: 0.8248  decode.loss_dice: 0.6130  decode.d0.loss_cls: 0.6178  decode.d0.loss_mask: 0.8505  decode.d0.loss_dice: 0.7057  decode.d1.loss_cls: 0.2628  decode.d1.loss_mask: 0.8520  decode.d1.loss_dice: 0.6586  decode.d2.loss_cls: 0.2502  decode.d2.loss_mask: 0.8593  decode.d2.loss_dice: 0.6620  decode.d3.loss_cls: 0.2371  decode.d3.loss_mask: 0.8309  decode.d3.loss_dice: 0.6429  decode.d4.loss_cls: 0.2220  decode.d4.loss_mask: 0.8187  decode.d4.loss_dice: 0.6367  decode.d5.loss_cls: 0.2042  decode.d5.loss_mask: 0.8451  decode.d5.loss_dice: 0.6703  decode.d6.loss_cls: 0.2672  decode.d6.loss_mask: 0.8402  decode.d6.loss_dice: 0.6657  decode.d7.loss_cls: 0.2066  decode.d7.loss_mask: 0.8376  decode.d7.loss_dice: 0.6651  decode.d8.loss_cls: 0.2168  decode.d8.loss_mask: 0.8582  decode.d8.loss_dice: 0.6639
05/27 01:47:16 - mmengine - INFO - Iter(train) [125100/160000]  base_lr: 2.5400e-05 lr: 2.5400e-06  eta: 4:00:29  time: 0.4165  data_time: 0.0100  memory: 5980  grad_norm: 702.2478  loss: 20.9647  decode.loss_cls: 0.3240  decode.loss_mask: 0.9572  decode.loss_dice: 0.7071  decode.d0.loss_cls: 0.9057  decode.d0.loss_mask: 0.9608  decode.d0.loss_dice: 0.7301  decode.d1.loss_cls: 0.2661  decode.d1.loss_mask: 1.0300  decode.d1.loss_dice: 0.7739  decode.d2.loss_cls: 0.2836  decode.d2.loss_mask: 0.9918  decode.d2.loss_dice: 0.7472  decode.d3.loss_cls: 0.2758  decode.d3.loss_mask: 0.9916  decode.d3.loss_dice: 0.7670  decode.d4.loss_cls: 0.3121  decode.d4.loss_mask: 1.0037  decode.d4.loss_dice: 0.7599  decode.d5.loss_cls: 0.3224  decode.d5.loss_mask: 0.9801  decode.d5.loss_dice: 0.7404  decode.d6.loss_cls: 0.3238  decode.d6.loss_mask: 0.9752  decode.d6.loss_dice: 0.7659  decode.d7.loss_cls: 0.2994  decode.d7.loss_mask: 0.9951  decode.d7.loss_dice: 0.7501  decode.d8.loss_cls: 0.3051  decode.d8.loss_mask: 0.9898  decode.d8.loss_dice: 0.7298
05/27 01:47:36 - mmengine - INFO - Iter(train) [125150/160000]  base_lr: 2.5367e-05 lr: 2.5367e-06  eta: 4:00:09  time: 0.4173  data_time: 0.0098  memory: 5970  grad_norm: 387.5486  loss: 18.2606  decode.loss_cls: 0.2247  decode.loss_mask: 0.8782  decode.loss_dice: 0.6877  decode.d0.loss_cls: 0.6663  decode.d0.loss_mask: 0.8654  decode.d0.loss_dice: 0.7068  decode.d1.loss_cls: 0.2355  decode.d1.loss_mask: 0.8801  decode.d1.loss_dice: 0.7168  decode.d2.loss_cls: 0.2183  decode.d2.loss_mask: 0.8760  decode.d2.loss_dice: 0.6865  decode.d3.loss_cls: 0.2243  decode.d3.loss_mask: 0.8833  decode.d3.loss_dice: 0.6912  decode.d4.loss_cls: 0.2123  decode.d4.loss_mask: 0.8823  decode.d4.loss_dice: 0.7029  decode.d5.loss_cls: 0.2036  decode.d5.loss_mask: 0.8613  decode.d5.loss_dice: 0.6918  decode.d6.loss_cls: 0.1836  decode.d6.loss_mask: 0.8621  decode.d6.loss_dice: 0.6845  decode.d7.loss_cls: 0.1974  decode.d7.loss_mask: 0.8558  decode.d7.loss_dice: 0.6720  decode.d8.loss_cls: 0.2426  decode.d8.loss_mask: 0.8993  decode.d8.loss_dice: 0.6680
05/27 01:47:57 - mmengine - INFO - Iter(train) [125200/160000]  base_lr: 2.5335e-05 lr: 2.5335e-06  eta: 3:59:48  time: 0.4162  data_time: 0.0099  memory: 5968  grad_norm: 805.6910  loss: 23.1451  decode.loss_cls: 0.2424  decode.loss_mask: 1.2634  decode.loss_dice: 0.7766  decode.d0.loss_cls: 0.6756  decode.d0.loss_mask: 1.1945  decode.d0.loss_dice: 0.7633  decode.d1.loss_cls: 0.2454  decode.d1.loss_mask: 1.2649  decode.d1.loss_dice: 0.7687  decode.d2.loss_cls: 0.2331  decode.d2.loss_mask: 1.2744  decode.d2.loss_dice: 0.7850  decode.d3.loss_cls: 0.2225  decode.d3.loss_mask: 1.2724  decode.d3.loss_dice: 0.7674  decode.d4.loss_cls: 0.2403  decode.d4.loss_mask: 1.2636  decode.d4.loss_dice: 0.7720  decode.d5.loss_cls: 0.2215  decode.d5.loss_mask: 1.2807  decode.d5.loss_dice: 0.7734  decode.d6.loss_cls: 0.2384  decode.d6.loss_mask: 1.2821  decode.d6.loss_dice: 0.7945  decode.d7.loss_cls: 0.2262  decode.d7.loss_mask: 1.2784  decode.d7.loss_dice: 0.7749  decode.d8.loss_cls: 0.2074  decode.d8.loss_mask: 1.2727  decode.d8.loss_dice: 0.7693
05/27 01:48:18 - mmengine - INFO - Iter(train) [125250/160000]  base_lr: 2.5302e-05 lr: 2.5302e-06  eta: 3:59:27  time: 0.4163  data_time: 0.0099  memory: 5967  grad_norm: 494.3200  loss: 16.1043  decode.loss_cls: 0.0768  decode.loss_mask: 0.8083  decode.loss_dice: 0.5996  decode.d0.loss_cls: 0.6532  decode.d0.loss_mask: 0.7756  decode.d0.loss_dice: 0.5882  decode.d1.loss_cls: 0.1280  decode.d1.loss_mask: 0.8626  decode.d1.loss_dice: 0.6405  decode.d2.loss_cls: 0.1385  decode.d2.loss_mask: 0.8501  decode.d2.loss_dice: 0.6459  decode.d3.loss_cls: 0.1263  decode.d3.loss_mask: 0.8558  decode.d3.loss_dice: 0.6262  decode.d4.loss_cls: 0.1099  decode.d4.loss_mask: 0.8178  decode.d4.loss_dice: 0.6231  decode.d5.loss_cls: 0.1323  decode.d5.loss_mask: 0.8019  decode.d5.loss_dice: 0.6065  decode.d6.loss_cls: 0.1123  decode.d6.loss_mask: 0.8117  decode.d6.loss_dice: 0.6114  decode.d7.loss_cls: 0.0981  decode.d7.loss_mask: 0.8369  decode.d7.loss_dice: 0.6278  decode.d8.loss_cls: 0.1126  decode.d8.loss_mask: 0.8086  decode.d8.loss_dice: 0.6177
05/27 01:48:39 - mmengine - INFO - Iter(train) [125300/160000]  base_lr: 2.5269e-05 lr: 2.5269e-06  eta: 3:59:07  time: 0.4165  data_time: 0.0099  memory: 5978  grad_norm: 272.5140  loss: 13.9785  decode.loss_cls: 0.0601  decode.loss_mask: 0.7556  decode.loss_dice: 0.5258  decode.d0.loss_cls: 0.5363  decode.d0.loss_mask: 0.7382  decode.d0.loss_dice: 0.5136  decode.d1.loss_cls: 0.0865  decode.d1.loss_mask: 0.7569  decode.d1.loss_dice: 0.5239  decode.d2.loss_cls: 0.0869  decode.d2.loss_mask: 0.7576  decode.d2.loss_dice: 0.5278  decode.d3.loss_cls: 0.0655  decode.d3.loss_mask: 0.7570  decode.d3.loss_dice: 0.5281  decode.d4.loss_cls: 0.0743  decode.d4.loss_mask: 0.7596  decode.d4.loss_dice: 0.5253  decode.d5.loss_cls: 0.0679  decode.d5.loss_mask: 0.7573  decode.d5.loss_dice: 0.5262  decode.d6.loss_cls: 0.0835  decode.d6.loss_mask: 0.7545  decode.d6.loss_dice: 0.5231  decode.d7.loss_cls: 0.0612  decode.d7.loss_mask: 0.7587  decode.d7.loss_dice: 0.5261  decode.d8.loss_cls: 0.0526  decode.d8.loss_mask: 0.7620  decode.d8.loss_dice: 0.5266
05/27 01:49:00 - mmengine - INFO - Iter(train) [125350/160000]  base_lr: 2.5236e-05 lr: 2.5236e-06  eta: 3:58:46  time: 0.4168  data_time: 0.0099  memory: 5967  grad_norm: 1099.1209  loss: 21.5327  decode.loss_cls: 0.2410  decode.loss_mask: 1.0970  decode.loss_dice: 0.7513  decode.d0.loss_cls: 0.7368  decode.d0.loss_mask: 1.1150  decode.d0.loss_dice: 0.7994  decode.d1.loss_cls: 0.2577  decode.d1.loss_mask: 1.0727  decode.d1.loss_dice: 0.7642  decode.d2.loss_cls: 0.2834  decode.d2.loss_mask: 1.0436  decode.d2.loss_dice: 0.7485  decode.d3.loss_cls: 0.2724  decode.d3.loss_mask: 1.1094  decode.d3.loss_dice: 0.7633  decode.d4.loss_cls: 0.2539  decode.d4.loss_mask: 1.1033  decode.d4.loss_dice: 0.7648  decode.d5.loss_cls: 0.2770  decode.d5.loss_mask: 1.0645  decode.d5.loss_dice: 0.7457  decode.d6.loss_cls: 0.2902  decode.d6.loss_mask: 1.0625  decode.d6.loss_dice: 0.7255  decode.d7.loss_cls: 0.2569  decode.d7.loss_mask: 1.1087  decode.d7.loss_dice: 0.7554  decode.d8.loss_cls: 0.2536  decode.d8.loss_mask: 1.0764  decode.d8.loss_dice: 0.7387
05/27 01:49:21 - mmengine - INFO - Iter(train) [125400/160000]  base_lr: 2.5204e-05 lr: 2.5204e-06  eta: 3:58:25  time: 0.4171  data_time: 0.0099  memory: 5969  grad_norm: 613.6231  loss: 17.8421  decode.loss_cls: 0.1293  decode.loss_mask: 0.8855  decode.loss_dice: 0.7228  decode.d0.loss_cls: 0.6862  decode.d0.loss_mask: 0.8302  decode.d0.loss_dice: 0.6767  decode.d1.loss_cls: 0.1582  decode.d1.loss_mask: 0.9124  decode.d1.loss_dice: 0.7153  decode.d2.loss_cls: 0.1117  decode.d2.loss_mask: 0.9203  decode.d2.loss_dice: 0.7237  decode.d3.loss_cls: 0.1027  decode.d3.loss_mask: 0.9155  decode.d3.loss_dice: 0.7111  decode.d4.loss_cls: 0.1117  decode.d4.loss_mask: 0.8961  decode.d4.loss_dice: 0.7109  decode.d5.loss_cls: 0.1055  decode.d5.loss_mask: 0.9224  decode.d5.loss_dice: 0.7266  decode.d6.loss_cls: 0.1019  decode.d6.loss_mask: 0.9036  decode.d6.loss_dice: 0.7224  decode.d7.loss_cls: 0.1284  decode.d7.loss_mask: 0.8818  decode.d7.loss_dice: 0.7202  decode.d8.loss_cls: 0.0940  decode.d8.loss_mask: 0.9019  decode.d8.loss_dice: 0.7134
05/27 01:49:42 - mmengine - INFO - Iter(train) [125450/160000]  base_lr: 2.5171e-05 lr: 2.5171e-06  eta: 3:58:05  time: 0.4173  data_time: 0.0102  memory: 5966  grad_norm: 1040.7621  loss: 17.5065  decode.loss_cls: 0.1466  decode.loss_mask: 0.8745  decode.loss_dice: 0.7202  decode.d0.loss_cls: 0.7136  decode.d0.loss_mask: 0.7997  decode.d0.loss_dice: 0.6662  decode.d1.loss_cls: 0.1288  decode.d1.loss_mask: 0.8510  decode.d1.loss_dice: 0.6898  decode.d2.loss_cls: 0.1297  decode.d2.loss_mask: 0.8551  decode.d2.loss_dice: 0.6991  decode.d3.loss_cls: 0.1450  decode.d3.loss_mask: 0.8604  decode.d3.loss_dice: 0.7018  decode.d4.loss_cls: 0.1476  decode.d4.loss_mask: 0.8546  decode.d4.loss_dice: 0.7017  decode.d5.loss_cls: 0.1429  decode.d5.loss_mask: 0.8701  decode.d5.loss_dice: 0.6941  decode.d6.loss_cls: 0.1747  decode.d6.loss_mask: 0.8468  decode.d6.loss_dice: 0.6966  decode.d7.loss_cls: 0.1565  decode.d7.loss_mask: 0.8584  decode.d7.loss_dice: 0.6910  decode.d8.loss_cls: 0.1352  decode.d8.loss_mask: 0.8519  decode.d8.loss_dice: 0.7029
05/27 01:50:03 - mmengine - INFO - Iter(train) [125500/160000]  base_lr: 2.5138e-05 lr: 2.5138e-06  eta: 3:57:44  time: 0.4187  data_time: 0.0103  memory: 5969  grad_norm: 770.1580  loss: 17.1006  decode.loss_cls: 0.1296  decode.loss_mask: 0.9282  decode.loss_dice: 0.6416  decode.d0.loss_cls: 0.6046  decode.d0.loss_mask: 0.9326  decode.d0.loss_dice: 0.6261  decode.d1.loss_cls: 0.1348  decode.d1.loss_mask: 0.9426  decode.d1.loss_dice: 0.6324  decode.d2.loss_cls: 0.1365  decode.d2.loss_mask: 0.8681  decode.d2.loss_dice: 0.5899  decode.d3.loss_cls: 0.1481  decode.d3.loss_mask: 0.8920  decode.d3.loss_dice: 0.6079  decode.d4.loss_cls: 0.1504  decode.d4.loss_mask: 0.9003  decode.d4.loss_dice: 0.6115  decode.d5.loss_cls: 0.1461  decode.d5.loss_mask: 0.8817  decode.d5.loss_dice: 0.6182  decode.d6.loss_cls: 0.1473  decode.d6.loss_mask: 0.8703  decode.d6.loss_dice: 0.6057  decode.d7.loss_cls: 0.1447  decode.d7.loss_mask: 0.9168  decode.d7.loss_dice: 0.6235  decode.d8.loss_cls: 0.1246  decode.d8.loss_mask: 0.9111  decode.d8.loss_dice: 0.6335
05/27 01:50:23 - mmengine - INFO - Iter(train) [125550/160000]  base_lr: 2.5105e-05 lr: 2.5105e-06  eta: 3:57:24  time: 0.4155  data_time: 0.0099  memory: 5987  grad_norm: 339.6128  loss: 19.9151  decode.loss_cls: 0.1684  decode.loss_mask: 0.9930  decode.loss_dice: 0.7846  decode.d0.loss_cls: 0.7953  decode.d0.loss_mask: 0.9045  decode.d0.loss_dice: 0.7328  decode.d1.loss_cls: 0.1809  decode.d1.loss_mask: 1.0038  decode.d1.loss_dice: 0.7917  decode.d2.loss_cls: 0.1716  decode.d2.loss_mask: 1.0133  decode.d2.loss_dice: 0.7918  decode.d3.loss_cls: 0.1325  decode.d3.loss_mask: 1.0319  decode.d3.loss_dice: 0.8001  decode.d4.loss_cls: 0.1387  decode.d4.loss_mask: 1.0176  decode.d4.loss_dice: 0.7914  decode.d5.loss_cls: 0.1238  decode.d5.loss_mask: 1.0049  decode.d5.loss_dice: 0.7902  decode.d6.loss_cls: 0.1633  decode.d6.loss_mask: 0.9715  decode.d6.loss_dice: 0.7643  decode.d7.loss_cls: 0.1610  decode.d7.loss_mask: 1.0008  decode.d7.loss_dice: 0.7741  decode.d8.loss_cls: 0.1563  decode.d8.loss_mask: 1.0027  decode.d8.loss_dice: 0.7583
05/27 01:50:44 - mmengine - INFO - Iter(train) [125600/160000]  base_lr: 2.5072e-05 lr: 2.5072e-06  eta: 3:57:03  time: 0.4165  data_time: 0.0100  memory: 5971  grad_norm: 295.0085  loss: 15.7768  decode.loss_cls: 0.0818  decode.loss_mask: 0.8566  decode.loss_dice: 0.5888  decode.d0.loss_cls: 0.4803  decode.d0.loss_mask: 0.8467  decode.d0.loss_dice: 0.5887  decode.d1.loss_cls: 0.1028  decode.d1.loss_mask: 0.8614  decode.d1.loss_dice: 0.5882  decode.d2.loss_cls: 0.0878  decode.d2.loss_mask: 0.8572  decode.d2.loss_dice: 0.5874  decode.d3.loss_cls: 0.0897  decode.d3.loss_mask: 0.8571  decode.d3.loss_dice: 0.5826  decode.d4.loss_cls: 0.0942  decode.d4.loss_mask: 0.8567  decode.d4.loss_dice: 0.5865  decode.d5.loss_cls: 0.1011  decode.d5.loss_mask: 0.8621  decode.d5.loss_dice: 0.5918  decode.d6.loss_cls: 0.0891  decode.d6.loss_mask: 0.8576  decode.d6.loss_dice: 0.5917  decode.d7.loss_cls: 0.0799  decode.d7.loss_mask: 0.8606  decode.d7.loss_dice: 0.5921  decode.d8.loss_cls: 0.1053  decode.d8.loss_mask: 0.8594  decode.d8.loss_dice: 0.5919
05/27 01:51:05 - mmengine - INFO - Iter(train) [125650/160000]  base_lr: 2.5040e-05 lr: 2.5040e-06  eta: 3:56:42  time: 0.4164  data_time: 0.0099  memory: 5971  grad_norm: 759.7973  loss: 19.6511  decode.loss_cls: 0.1227  decode.loss_mask: 1.0621  decode.loss_dice: 0.7041  decode.d0.loss_cls: 0.5345  decode.d0.loss_mask: 1.0957  decode.d0.loss_dice: 0.7172  decode.d1.loss_cls: 0.0951  decode.d1.loss_mask: 1.1539  decode.d1.loss_dice: 0.7306  decode.d2.loss_cls: 0.0801  decode.d2.loss_mask: 1.1390  decode.d2.loss_dice: 0.7334  decode.d3.loss_cls: 0.1140  decode.d3.loss_mask: 1.0820  decode.d3.loss_dice: 0.7253  decode.d4.loss_cls: 0.1012  decode.d4.loss_mask: 1.1088  decode.d4.loss_dice: 0.7186  decode.d5.loss_cls: 0.1139  decode.d5.loss_mask: 1.0881  decode.d5.loss_dice: 0.7095  decode.d6.loss_cls: 0.1125  decode.d6.loss_mask: 1.0775  decode.d6.loss_dice: 0.7183  decode.d7.loss_cls: 0.0763  decode.d7.loss_mask: 1.0984  decode.d7.loss_dice: 0.7316  decode.d8.loss_cls: 0.1176  decode.d8.loss_mask: 1.0759  decode.d8.loss_dice: 0.7134
05/27 01:51:26 - mmengine - INFO - Iter(train) [125700/160000]  base_lr: 2.5007e-05 lr: 2.5007e-06  eta: 3:56:22  time: 0.4157  data_time: 0.0100  memory: 5970  grad_norm: 530.4631  loss: 20.9400  decode.loss_cls: 0.1632  decode.loss_mask: 1.0443  decode.loss_dice: 0.8036  decode.d0.loss_cls: 0.6911  decode.d0.loss_mask: 1.0420  decode.d0.loss_dice: 0.8043  decode.d1.loss_cls: 0.1738  decode.d1.loss_mask: 1.0614  decode.d1.loss_dice: 0.8078  decode.d2.loss_cls: 0.1796  decode.d2.loss_mask: 1.0682  decode.d2.loss_dice: 0.8057  decode.d3.loss_cls: 0.1750  decode.d3.loss_mask: 1.0556  decode.d3.loss_dice: 0.7929  decode.d4.loss_cls: 0.1790  decode.d4.loss_mask: 1.0694  decode.d4.loss_dice: 0.8114  decode.d5.loss_cls: 0.1648  decode.d5.loss_mask: 1.0548  decode.d5.loss_dice: 0.7967  decode.d6.loss_cls: 0.1854  decode.d6.loss_mask: 1.0896  decode.d6.loss_dice: 0.8163  decode.d7.loss_cls: 0.1663  decode.d7.loss_mask: 1.0912  decode.d7.loss_dice: 0.8007  decode.d8.loss_cls: 0.2011  decode.d8.loss_mask: 1.0562  decode.d8.loss_dice: 0.7885
05/27 01:51:47 - mmengine - INFO - Iter(train) [125750/160000]  base_lr: 2.4974e-05 lr: 2.4974e-06  eta: 3:56:01  time: 0.4165  data_time: 0.0099  memory: 5971  grad_norm: 1117.1804  loss: 18.0756  decode.loss_cls: 0.1943  decode.loss_mask: 0.9268  decode.loss_dice: 0.6179  decode.d0.loss_cls: 0.6496  decode.d0.loss_mask: 0.9282  decode.d0.loss_dice: 0.6344  decode.d1.loss_cls: 0.1708  decode.d1.loss_mask: 1.0210  decode.d1.loss_dice: 0.6711  decode.d2.loss_cls: 0.2001  decode.d2.loss_mask: 0.9511  decode.d2.loss_dice: 0.6278  decode.d3.loss_cls: 0.1791  decode.d3.loss_mask: 0.9269  decode.d3.loss_dice: 0.5949  decode.d4.loss_cls: 0.2304  decode.d4.loss_mask: 0.9105  decode.d4.loss_dice: 0.6267  decode.d5.loss_cls: 0.2085  decode.d5.loss_mask: 0.9094  decode.d5.loss_dice: 0.5940  decode.d6.loss_cls: 0.1980  decode.d6.loss_mask: 0.9134  decode.d6.loss_dice: 0.6074  decode.d7.loss_cls: 0.1543  decode.d7.loss_mask: 0.9821  decode.d7.loss_dice: 0.6451  decode.d8.loss_cls: 0.1678  decode.d8.loss_mask: 0.9779  decode.d8.loss_dice: 0.6559
05/27 01:52:08 - mmengine - INFO - Iter(train) [125800/160000]  base_lr: 2.4941e-05 lr: 2.4941e-06  eta: 3:55:40  time: 0.4160  data_time: 0.0101  memory: 5975  grad_norm: 381.2836  loss: 18.8295  decode.loss_cls: 0.1083  decode.loss_mask: 1.0369  decode.loss_dice: 0.7053  decode.d0.loss_cls: 0.5227  decode.d0.loss_mask: 1.0516  decode.d0.loss_dice: 0.7142  decode.d1.loss_cls: 0.0755  decode.d1.loss_mask: 1.0329  decode.d1.loss_dice: 0.7068  decode.d2.loss_cls: 0.0897  decode.d2.loss_mask: 1.0489  decode.d2.loss_dice: 0.7139  decode.d3.loss_cls: 0.0792  decode.d3.loss_mask: 1.0330  decode.d3.loss_dice: 0.7094  decode.d4.loss_cls: 0.0782  decode.d4.loss_mask: 1.0414  decode.d4.loss_dice: 0.7153  decode.d5.loss_cls: 0.0736  decode.d5.loss_mask: 1.0422  decode.d5.loss_dice: 0.7194  decode.d6.loss_cls: 0.0751  decode.d6.loss_mask: 1.0397  decode.d6.loss_dice: 0.7136  decode.d7.loss_cls: 0.0791  decode.d7.loss_mask: 1.0447  decode.d7.loss_dice: 0.7180  decode.d8.loss_cls: 0.0829  decode.d8.loss_mask: 1.0554  decode.d8.loss_dice: 0.7226
05/27 01:52:28 - mmengine - INFO - Iter(train) [125850/160000]  base_lr: 2.4908e-05 lr: 2.4908e-06  eta: 3:55:20  time: 0.4162  data_time: 0.0100  memory: 5969  grad_norm: 872.4411  loss: 21.1883  decode.loss_cls: 0.2476  decode.loss_mask: 1.0858  decode.loss_dice: 0.7438  decode.d0.loss_cls: 0.6671  decode.d0.loss_mask: 1.0466  decode.d0.loss_dice: 0.7558  decode.d1.loss_cls: 0.2516  decode.d1.loss_mask: 1.0878  decode.d1.loss_dice: 0.7452  decode.d2.loss_cls: 0.2477  decode.d2.loss_mask: 1.0760  decode.d2.loss_dice: 0.7376  decode.d3.loss_cls: 0.2679  decode.d3.loss_mask: 1.0814  decode.d3.loss_dice: 0.7434  decode.d4.loss_cls: 0.2617  decode.d4.loss_mask: 1.0756  decode.d4.loss_dice: 0.7360  decode.d5.loss_cls: 0.2283  decode.d5.loss_mask: 1.0795  decode.d5.loss_dice: 0.7657  decode.d6.loss_cls: 0.2369  decode.d6.loss_mask: 1.0921  decode.d6.loss_dice: 0.7652  decode.d7.loss_cls: 0.2623  decode.d7.loss_mask: 1.0770  decode.d7.loss_dice: 0.7433  decode.d8.loss_cls: 0.2461  decode.d8.loss_mask: 1.0811  decode.d8.loss_dice: 0.7520
05/27 01:52:49 - mmengine - INFO - Iter(train) [125900/160000]  base_lr: 2.4876e-05 lr: 2.4876e-06  eta: 3:54:59  time: 0.4160  data_time: 0.0099  memory: 5969  grad_norm: 566.6436  loss: 18.9585  decode.loss_cls: 0.2522  decode.loss_mask: 0.9578  decode.loss_dice: 0.6818  decode.d0.loss_cls: 0.6387  decode.d0.loss_mask: 0.9233  decode.d0.loss_dice: 0.6652  decode.d1.loss_cls: 0.2337  decode.d1.loss_mask: 0.9657  decode.d1.loss_dice: 0.6790  decode.d2.loss_cls: 0.2351  decode.d2.loss_mask: 0.9612  decode.d2.loss_dice: 0.6588  decode.d3.loss_cls: 0.1858  decode.d3.loss_mask: 0.9515  decode.d3.loss_dice: 0.6866  decode.d4.loss_cls: 0.1884  decode.d4.loss_mask: 0.9775  decode.d4.loss_dice: 0.6834  decode.d5.loss_cls: 0.2063  decode.d5.loss_mask: 0.9549  decode.d5.loss_dice: 0.6793  decode.d6.loss_cls: 0.2669  decode.d6.loss_mask: 0.9477  decode.d6.loss_dice: 0.6829  decode.d7.loss_cls: 0.2007  decode.d7.loss_mask: 0.9618  decode.d7.loss_dice: 0.6943  decode.d8.loss_cls: 0.2530  decode.d8.loss_mask: 0.9319  decode.d8.loss_dice: 0.6530
05/27 01:53:10 - mmengine - INFO - Iter(train) [125950/160000]  base_lr: 2.4843e-05 lr: 2.4843e-06  eta: 3:54:38  time: 0.4158  data_time: 0.0100  memory: 5972  grad_norm: 650.9209  loss: 15.9745  decode.loss_cls: 0.1612  decode.loss_mask: 0.7832  decode.loss_dice: 0.5932  decode.d0.loss_cls: 0.6133  decode.d0.loss_mask: 0.7575  decode.d0.loss_dice: 0.5999  decode.d1.loss_cls: 0.2038  decode.d1.loss_mask: 0.7922  decode.d1.loss_dice: 0.5951  decode.d2.loss_cls: 0.2043  decode.d2.loss_mask: 0.7658  decode.d2.loss_dice: 0.6182  decode.d3.loss_cls: 0.1893  decode.d3.loss_mask: 0.7626  decode.d3.loss_dice: 0.5956  decode.d4.loss_cls: 0.1849  decode.d4.loss_mask: 0.7758  decode.d4.loss_dice: 0.5957  decode.d5.loss_cls: 0.1790  decode.d5.loss_mask: 0.7694  decode.d5.loss_dice: 0.6160  decode.d6.loss_cls: 0.1903  decode.d6.loss_mask: 0.7327  decode.d6.loss_dice: 0.5964  decode.d7.loss_cls: 0.1847  decode.d7.loss_mask: 0.7665  decode.d7.loss_dice: 0.5907  decode.d8.loss_cls: 0.1756  decode.d8.loss_mask: 0.7594  decode.d8.loss_dice: 0.6225
05/27 01:53:31 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 01:53:31 - mmengine - INFO - Iter(train) [126000/160000]  base_lr: 2.4810e-05 lr: 2.4810e-06  eta: 3:54:18  time: 0.4161  data_time: 0.0100  memory: 5967  grad_norm: 351.7074  loss: 17.2909  decode.loss_cls: 0.1474  decode.loss_mask: 0.8987  decode.loss_dice: 0.5672  decode.d0.loss_cls: 0.6345  decode.d0.loss_mask: 0.9704  decode.d0.loss_dice: 0.5955  decode.d1.loss_cls: 0.1712  decode.d1.loss_mask: 0.9339  decode.d1.loss_dice: 0.6198  decode.d2.loss_cls: 0.1755  decode.d2.loss_mask: 0.9791  decode.d2.loss_dice: 0.6014  decode.d3.loss_cls: 0.1718  decode.d3.loss_mask: 0.9259  decode.d3.loss_dice: 0.5944  decode.d4.loss_cls: 0.1500  decode.d4.loss_mask: 0.9098  decode.d4.loss_dice: 0.5740  decode.d5.loss_cls: 0.1563  decode.d5.loss_mask: 0.9281  decode.d5.loss_dice: 0.5955  decode.d6.loss_cls: 0.1698  decode.d6.loss_mask: 0.9160  decode.d6.loss_dice: 0.5867  decode.d7.loss_cls: 0.1510  decode.d7.loss_mask: 0.9297  decode.d7.loss_dice: 0.5956  decode.d8.loss_cls: 0.1268  decode.d8.loss_mask: 0.9351  decode.d8.loss_dice: 0.5799
05/27 01:53:52 - mmengine - INFO - Iter(train) [126050/160000]  base_lr: 2.4777e-05 lr: 2.4777e-06  eta: 3:53:57  time: 0.4159  data_time: 0.0099  memory: 5976  grad_norm: 348.5608  loss: 16.7413  decode.loss_cls: 0.1083  decode.loss_mask: 0.8532  decode.loss_dice: 0.6415  decode.d0.loss_cls: 0.5828  decode.d0.loss_mask: 0.8642  decode.d0.loss_dice: 0.6459  decode.d1.loss_cls: 0.1474  decode.d1.loss_mask: 0.8671  decode.d1.loss_dice: 0.6395  decode.d2.loss_cls: 0.1170  decode.d2.loss_mask: 0.8552  decode.d2.loss_dice: 0.6447  decode.d3.loss_cls: 0.1111  decode.d3.loss_mask: 0.8237  decode.d3.loss_dice: 0.6360  decode.d4.loss_cls: 0.1480  decode.d4.loss_mask: 0.8687  decode.d4.loss_dice: 0.6421  decode.d5.loss_cls: 0.1423  decode.d5.loss_mask: 0.8629  decode.d5.loss_dice: 0.6467  decode.d6.loss_cls: 0.1541  decode.d6.loss_mask: 0.8597  decode.d6.loss_dice: 0.6441  decode.d7.loss_cls: 0.1112  decode.d7.loss_mask: 0.8584  decode.d7.loss_dice: 0.6379  decode.d8.loss_cls: 0.1190  decode.d8.loss_mask: 0.8632  decode.d8.loss_dice: 0.6453
05/27 01:54:13 - mmengine - INFO - Iter(train) [126100/160000]  base_lr: 2.4744e-05 lr: 2.4744e-06  eta: 3:53:37  time: 0.4167  data_time: 0.0099  memory: 5980  grad_norm: 622.2380  loss: 21.0432  decode.loss_cls: 0.1369  decode.loss_mask: 1.1368  decode.loss_dice: 0.7770  decode.d0.loss_cls: 0.7185  decode.d0.loss_mask: 1.0417  decode.d0.loss_dice: 0.7076  decode.d1.loss_cls: 0.1888  decode.d1.loss_mask: 1.1340  decode.d1.loss_dice: 0.7621  decode.d2.loss_cls: 0.1705  decode.d2.loss_mask: 1.1335  decode.d2.loss_dice: 0.7746  decode.d3.loss_cls: 0.1701  decode.d3.loss_mask: 1.1545  decode.d3.loss_dice: 0.7626  decode.d4.loss_cls: 0.1562  decode.d4.loss_mask: 1.1313  decode.d4.loss_dice: 0.7518  decode.d5.loss_cls: 0.1473  decode.d5.loss_mask: 1.1411  decode.d5.loss_dice: 0.7778  decode.d6.loss_cls: 0.1555  decode.d6.loss_mask: 1.1270  decode.d6.loss_dice: 0.7611  decode.d7.loss_cls: 0.1634  decode.d7.loss_mask: 1.1208  decode.d7.loss_dice: 0.7735  decode.d8.loss_cls: 0.1715  decode.d8.loss_mask: 1.1384  decode.d8.loss_dice: 0.7570
05/27 01:54:33 - mmengine - INFO - Iter(train) [126150/160000]  base_lr: 2.4711e-05 lr: 2.4711e-06  eta: 3:53:16  time: 0.4173  data_time: 0.0099  memory: 5967  grad_norm: 487.9257  loss: 18.0805  decode.loss_cls: 0.0996  decode.loss_mask: 0.9944  decode.loss_dice: 0.6732  decode.d0.loss_cls: 0.5922  decode.d0.loss_mask: 0.9809  decode.d0.loss_dice: 0.6673  decode.d1.loss_cls: 0.1184  decode.d1.loss_mask: 0.9995  decode.d1.loss_dice: 0.6845  decode.d2.loss_cls: 0.0984  decode.d2.loss_mask: 0.9910  decode.d2.loss_dice: 0.6668  decode.d3.loss_cls: 0.0916  decode.d3.loss_mask: 0.9945  decode.d3.loss_dice: 0.6659  decode.d4.loss_cls: 0.0856  decode.d4.loss_mask: 0.9967  decode.d4.loss_dice: 0.6859  decode.d5.loss_cls: 0.0865  decode.d5.loss_mask: 0.9897  decode.d5.loss_dice: 0.6646  decode.d6.loss_cls: 0.0965  decode.d6.loss_mask: 0.9895  decode.d6.loss_dice: 0.6613  decode.d7.loss_cls: 0.0918  decode.d7.loss_mask: 0.9875  decode.d7.loss_dice: 0.6701  decode.d8.loss_cls: 0.0943  decode.d8.loss_mask: 0.9974  decode.d8.loss_dice: 0.6653
05/27 01:54:54 - mmengine - INFO - Iter(train) [126200/160000]  base_lr: 2.4679e-05 lr: 2.4679e-06  eta: 3:52:55  time: 0.4160  data_time: 0.0098  memory: 5976  grad_norm: 514.2970  loss: 18.0434  decode.loss_cls: 0.2140  decode.loss_mask: 0.7925  decode.loss_dice: 0.7386  decode.d0.loss_cls: 0.7711  decode.d0.loss_mask: 0.7622  decode.d0.loss_dice: 0.6916  decode.d1.loss_cls: 0.2482  decode.d1.loss_mask: 0.8164  decode.d1.loss_dice: 0.7446  decode.d2.loss_cls: 0.2338  decode.d2.loss_mask: 0.7824  decode.d2.loss_dice: 0.7270  decode.d3.loss_cls: 0.2097  decode.d3.loss_mask: 0.7872  decode.d3.loss_dice: 0.7138  decode.d4.loss_cls: 0.2282  decode.d4.loss_mask: 0.7827  decode.d4.loss_dice: 0.7379  decode.d5.loss_cls: 0.2152  decode.d5.loss_mask: 0.8145  decode.d5.loss_dice: 0.7394  decode.d6.loss_cls: 0.2101  decode.d6.loss_mask: 0.8246  decode.d6.loss_dice: 0.7777  decode.d7.loss_cls: 0.1982  decode.d7.loss_mask: 0.8063  decode.d7.loss_dice: 0.7550  decode.d8.loss_cls: 0.2256  decode.d8.loss_mask: 0.7766  decode.d8.loss_dice: 0.7183
05/27 01:55:15 - mmengine - INFO - Iter(train) [126250/160000]  base_lr: 2.4646e-05 lr: 2.4646e-06  eta: 3:52:35  time: 0.4160  data_time: 0.0099  memory: 5966  grad_norm: 358.6883  loss: 17.4367  decode.loss_cls: 0.1826  decode.loss_mask: 0.8507  decode.loss_dice: 0.6268  decode.d0.loss_cls: 0.6341  decode.d0.loss_mask: 0.8640  decode.d0.loss_dice: 0.6175  decode.d1.loss_cls: 0.2320  decode.d1.loss_mask: 0.8436  decode.d1.loss_dice: 0.6163  decode.d2.loss_cls: 0.2271  decode.d2.loss_mask: 0.8583  decode.d2.loss_dice: 0.6043  decode.d3.loss_cls: 0.1744  decode.d3.loss_mask: 0.9075  decode.d3.loss_dice: 0.6375  decode.d4.loss_cls: 0.1766  decode.d4.loss_mask: 0.8909  decode.d4.loss_dice: 0.6339  decode.d5.loss_cls: 0.1755  decode.d5.loss_mask: 0.9119  decode.d5.loss_dice: 0.6337  decode.d6.loss_cls: 0.1512  decode.d6.loss_mask: 0.9180  decode.d6.loss_dice: 0.6543  decode.d7.loss_cls: 0.1606  decode.d7.loss_mask: 0.9144  decode.d7.loss_dice: 0.6509  decode.d8.loss_cls: 0.2051  decode.d8.loss_mask: 0.8459  decode.d8.loss_dice: 0.6376
05/27 01:55:36 - mmengine - INFO - Iter(train) [126300/160000]  base_lr: 2.4613e-05 lr: 2.4613e-06  eta: 3:52:14  time: 0.4160  data_time: 0.0100  memory: 5966  grad_norm: 579.6376  loss: 20.6684  decode.loss_cls: 0.1470  decode.loss_mask: 1.1144  decode.loss_dice: 0.7541  decode.d0.loss_cls: 0.7998  decode.d0.loss_mask: 0.9873  decode.d0.loss_dice: 0.7297  decode.d1.loss_cls: 0.1651  decode.d1.loss_mask: 1.1186  decode.d1.loss_dice: 0.7527  decode.d2.loss_cls: 0.1292  decode.d2.loss_mask: 1.1193  decode.d2.loss_dice: 0.7676  decode.d3.loss_cls: 0.1644  decode.d3.loss_mask: 1.1091  decode.d3.loss_dice: 0.7381  decode.d4.loss_cls: 0.1557  decode.d4.loss_mask: 1.1090  decode.d4.loss_dice: 0.7588  decode.d5.loss_cls: 0.1353  decode.d5.loss_mask: 1.1153  decode.d5.loss_dice: 0.7524  decode.d6.loss_cls: 0.1615  decode.d6.loss_mask: 1.1126  decode.d6.loss_dice: 0.7458  decode.d7.loss_cls: 0.1406  decode.d7.loss_mask: 1.1307  decode.d7.loss_dice: 0.7543  decode.d8.loss_cls: 0.1220  decode.d8.loss_mask: 1.1269  decode.d8.loss_dice: 0.7511
05/27 01:55:57 - mmengine - INFO - Iter(train) [126350/160000]  base_lr: 2.4580e-05 lr: 2.4580e-06  eta: 3:51:53  time: 0.4160  data_time: 0.0099  memory: 5971  grad_norm: 613.2550  loss: 16.7541  decode.loss_cls: 0.0605  decode.loss_mask: 0.9400  decode.loss_dice: 0.6065  decode.d0.loss_cls: 0.5721  decode.d0.loss_mask: 0.9208  decode.d0.loss_dice: 0.6050  decode.d1.loss_cls: 0.0839  decode.d1.loss_mask: 0.9625  decode.d1.loss_dice: 0.6101  decode.d2.loss_cls: 0.0805  decode.d2.loss_mask: 0.9698  decode.d2.loss_dice: 0.6099  decode.d3.loss_cls: 0.0877  decode.d3.loss_mask: 0.9408  decode.d3.loss_dice: 0.6001  decode.d4.loss_cls: 0.0581  decode.d4.loss_mask: 0.9546  decode.d4.loss_dice: 0.6164  decode.d5.loss_cls: 0.0616  decode.d5.loss_mask: 0.9590  decode.d5.loss_dice: 0.6092  decode.d6.loss_cls: 0.0581  decode.d6.loss_mask: 0.9554  decode.d6.loss_dice: 0.6071  decode.d7.loss_cls: 0.0746  decode.d7.loss_mask: 0.9328  decode.d7.loss_dice: 0.5971  decode.d8.loss_cls: 0.0585  decode.d8.loss_mask: 0.9487  decode.d8.loss_dice: 0.6129
05/27 01:56:18 - mmengine - INFO - Iter(train) [126400/160000]  base_lr: 2.4547e-05 lr: 2.4547e-06  eta: 3:51:33  time: 0.4163  data_time: 0.0100  memory: 5969  grad_norm: 558.4069  loss: 23.3005  decode.loss_cls: 0.2523  decode.loss_mask: 1.1219  decode.loss_dice: 0.9029  decode.d0.loss_cls: 0.8687  decode.d0.loss_mask: 1.0006  decode.d0.loss_dice: 0.8428  decode.d1.loss_cls: 0.2281  decode.d1.loss_mask: 1.1483  decode.d1.loss_dice: 0.9111  decode.d2.loss_cls: 0.2942  decode.d2.loss_mask: 1.1236  decode.d2.loss_dice: 0.8848  decode.d3.loss_cls: 0.3193  decode.d3.loss_mask: 1.1206  decode.d3.loss_dice: 0.8718  decode.d4.loss_cls: 0.3309  decode.d4.loss_mask: 1.1084  decode.d4.loss_dice: 0.8651  decode.d5.loss_cls: 0.3001  decode.d5.loss_mask: 1.1029  decode.d5.loss_dice: 0.8901  decode.d6.loss_cls: 0.2891  decode.d6.loss_mask: 1.0868  decode.d6.loss_dice: 0.8727  decode.d7.loss_cls: 0.2573  decode.d7.loss_mask: 1.1288  decode.d7.loss_dice: 0.8924  decode.d8.loss_cls: 0.2882  decode.d8.loss_mask: 1.1002  decode.d8.loss_dice: 0.8964
05/27 01:56:38 - mmengine - INFO - Iter(train) [126450/160000]  base_lr: 2.4514e-05 lr: 2.4514e-06  eta: 3:51:12  time: 0.4168  data_time: 0.0099  memory: 5970  grad_norm: 324.7227  loss: 16.7330  decode.loss_cls: 0.1420  decode.loss_mask: 0.8491  decode.loss_dice: 0.6245  decode.d0.loss_cls: 0.5952  decode.d0.loss_mask: 0.8900  decode.d0.loss_dice: 0.6379  decode.d1.loss_cls: 0.1392  decode.d1.loss_mask: 0.8486  decode.d1.loss_dice: 0.6376  decode.d2.loss_cls: 0.1504  decode.d2.loss_mask: 0.8459  decode.d2.loss_dice: 0.6359  decode.d3.loss_cls: 0.1382  decode.d3.loss_mask: 0.8403  decode.d3.loss_dice: 0.6438  decode.d4.loss_cls: 0.1422  decode.d4.loss_mask: 0.8545  decode.d4.loss_dice: 0.6248  decode.d5.loss_cls: 0.1360  decode.d5.loss_mask: 0.8513  decode.d5.loss_dice: 0.6245  decode.d6.loss_cls: 0.1297  decode.d6.loss_mask: 0.8582  decode.d6.loss_dice: 0.6288  decode.d7.loss_cls: 0.1275  decode.d7.loss_mask: 0.8848  decode.d7.loss_dice: 0.6363  decode.d8.loss_cls: 0.1417  decode.d8.loss_mask: 0.8509  decode.d8.loss_dice: 0.6231
05/27 01:56:59 - mmengine - INFO - Iter(train) [126500/160000]  base_lr: 2.4481e-05 lr: 2.4481e-06  eta: 3:50:51  time: 0.4166  data_time: 0.0100  memory: 5967  grad_norm: 723.4293  loss: 20.8194  decode.loss_cls: 0.1901  decode.loss_mask: 1.0868  decode.loss_dice: 0.7381  decode.d0.loss_cls: 0.6759  decode.d0.loss_mask: 1.0727  decode.d0.loss_dice: 0.6894  decode.d1.loss_cls: 0.3101  decode.d1.loss_mask: 1.0515  decode.d1.loss_dice: 0.7009  decode.d2.loss_cls: 0.2353  decode.d2.loss_mask: 1.0784  decode.d2.loss_dice: 0.7173  decode.d3.loss_cls: 0.2159  decode.d3.loss_mask: 1.0768  decode.d3.loss_dice: 0.7498  decode.d4.loss_cls: 0.2219  decode.d4.loss_mask: 1.0785  decode.d4.loss_dice: 0.7643  decode.d5.loss_cls: 0.2114  decode.d5.loss_mask: 1.1328  decode.d5.loss_dice: 0.7402  decode.d6.loss_cls: 0.2249  decode.d6.loss_mask: 1.0669  decode.d6.loss_dice: 0.7295  decode.d7.loss_cls: 0.2280  decode.d7.loss_mask: 1.0847  decode.d7.loss_dice: 0.7485  decode.d8.loss_cls: 0.2212  decode.d8.loss_mask: 1.0620  decode.d8.loss_dice: 0.7156
05/27 01:57:20 - mmengine - INFO - Iter(train) [126550/160000]  base_lr: 2.4448e-05 lr: 2.4448e-06  eta: 3:50:31  time: 0.4155  data_time: 0.0099  memory: 5970  grad_norm: 481.7879  loss: 19.1088  decode.loss_cls: 0.2137  decode.loss_mask: 0.9249  decode.loss_dice: 0.6861  decode.d0.loss_cls: 0.7054  decode.d0.loss_mask: 0.9177  decode.d0.loss_dice: 0.7060  decode.d1.loss_cls: 0.1979  decode.d1.loss_mask: 0.9401  decode.d1.loss_dice: 0.7196  decode.d2.loss_cls: 0.2328  decode.d2.loss_mask: 0.9343  decode.d2.loss_dice: 0.6753  decode.d3.loss_cls: 0.2133  decode.d3.loss_mask: 0.9492  decode.d3.loss_dice: 0.7076  decode.d4.loss_cls: 0.2317  decode.d4.loss_mask: 0.9437  decode.d4.loss_dice: 0.7370  decode.d5.loss_cls: 0.2234  decode.d5.loss_mask: 0.9413  decode.d5.loss_dice: 0.6811  decode.d6.loss_cls: 0.2431  decode.d6.loss_mask: 0.9343  decode.d6.loss_dice: 0.6855  decode.d7.loss_cls: 0.2266  decode.d7.loss_mask: 0.9605  decode.d7.loss_dice: 0.7291  decode.d8.loss_cls: 0.1986  decode.d8.loss_mask: 0.9452  decode.d8.loss_dice: 0.7035
05/27 01:57:41 - mmengine - INFO - Iter(train) [126600/160000]  base_lr: 2.4416e-05 lr: 2.4416e-06  eta: 3:50:10  time: 0.4163  data_time: 0.0099  memory: 5975  grad_norm: 438.9148  loss: 18.2671  decode.loss_cls: 0.1683  decode.loss_mask: 0.9299  decode.loss_dice: 0.6308  decode.d0.loss_cls: 0.6329  decode.d0.loss_mask: 0.9645  decode.d0.loss_dice: 0.6343  decode.d1.loss_cls: 0.2270  decode.d1.loss_mask: 0.9432  decode.d1.loss_dice: 0.6517  decode.d2.loss_cls: 0.1938  decode.d2.loss_mask: 0.9564  decode.d2.loss_dice: 0.6337  decode.d3.loss_cls: 0.2297  decode.d3.loss_mask: 0.9334  decode.d3.loss_dice: 0.6221  decode.d4.loss_cls: 0.1772  decode.d4.loss_mask: 0.9495  decode.d4.loss_dice: 0.6194  decode.d5.loss_cls: 0.1983  decode.d5.loss_mask: 0.9531  decode.d5.loss_dice: 0.6186  decode.d6.loss_cls: 0.2319  decode.d6.loss_mask: 0.9459  decode.d6.loss_dice: 0.6436  decode.d7.loss_cls: 0.2178  decode.d7.loss_mask: 0.9270  decode.d7.loss_dice: 0.6315  decode.d8.loss_cls: 0.1801  decode.d8.loss_mask: 0.9670  decode.d8.loss_dice: 0.6546
05/27 01:58:02 - mmengine - INFO - Iter(train) [126650/160000]  base_lr: 2.4383e-05 lr: 2.4383e-06  eta: 3:49:50  time: 0.4153  data_time: 0.0098  memory: 5975  grad_norm: 683.8726  loss: 20.0226  decode.loss_cls: 0.1840  decode.loss_mask: 1.0238  decode.loss_dice: 0.7195  decode.d0.loss_cls: 0.7974  decode.d0.loss_mask: 1.0094  decode.d0.loss_dice: 0.6667  decode.d1.loss_cls: 0.2388  decode.d1.loss_mask: 0.9997  decode.d1.loss_dice: 0.7154  decode.d2.loss_cls: 0.2704  decode.d2.loss_mask: 1.0129  decode.d2.loss_dice: 0.6810  decode.d3.loss_cls: 0.2185  decode.d3.loss_mask: 1.0378  decode.d3.loss_dice: 0.7008  decode.d4.loss_cls: 0.2853  decode.d4.loss_mask: 1.0000  decode.d4.loss_dice: 0.6843  decode.d5.loss_cls: 0.1914  decode.d5.loss_mask: 1.0384  decode.d5.loss_dice: 0.6734  decode.d6.loss_cls: 0.2441  decode.d6.loss_mask: 0.9874  decode.d6.loss_dice: 0.6784  decode.d7.loss_cls: 0.2771  decode.d7.loss_mask: 1.0116  decode.d7.loss_dice: 0.7202  decode.d8.loss_cls: 0.2637  decode.d8.loss_mask: 1.0008  decode.d8.loss_dice: 0.6906
05/27 01:58:23 - mmengine - INFO - Iter(train) [126700/160000]  base_lr: 2.4350e-05 lr: 2.4350e-06  eta: 3:49:29  time: 0.4162  data_time: 0.0100  memory: 5966  grad_norm: 640.2489  loss: 15.8448  decode.loss_cls: 0.0363  decode.loss_mask: 0.8545  decode.loss_dice: 0.6336  decode.d0.loss_cls: 0.6207  decode.d0.loss_mask: 0.8656  decode.d0.loss_dice: 0.6199  decode.d1.loss_cls: 0.0536  decode.d1.loss_mask: 0.8461  decode.d1.loss_dice: 0.6230  decode.d2.loss_cls: 0.0580  decode.d2.loss_mask: 0.8514  decode.d2.loss_dice: 0.6259  decode.d3.loss_cls: 0.0582  decode.d3.loss_mask: 0.8462  decode.d3.loss_dice: 0.6161  decode.d4.loss_cls: 0.0554  decode.d4.loss_mask: 0.8522  decode.d4.loss_dice: 0.6237  decode.d5.loss_cls: 0.0578  decode.d5.loss_mask: 0.8443  decode.d5.loss_dice: 0.6230  decode.d6.loss_cls: 0.0621  decode.d6.loss_mask: 0.8410  decode.d6.loss_dice: 0.6014  decode.d7.loss_cls: 0.0769  decode.d7.loss_mask: 0.8627  decode.d7.loss_dice: 0.6167  decode.d8.loss_cls: 0.0565  decode.d8.loss_mask: 0.8534  decode.d8.loss_dice: 0.6083
05/27 01:58:43 - mmengine - INFO - Iter(train) [126750/160000]  base_lr: 2.4317e-05 lr: 2.4317e-06  eta: 3:49:08  time: 0.4158  data_time: 0.0099  memory: 5971  grad_norm: 643.0595  loss: 20.4640  decode.loss_cls: 0.2543  decode.loss_mask: 0.9677  decode.loss_dice: 0.7608  decode.d0.loss_cls: 0.6918  decode.d0.loss_mask: 0.9542  decode.d0.loss_dice: 0.8282  decode.d1.loss_cls: 0.2771  decode.d1.loss_mask: 0.9525  decode.d1.loss_dice: 0.7378  decode.d2.loss_cls: 0.2933  decode.d2.loss_mask: 0.9642  decode.d2.loss_dice: 0.7633  decode.d3.loss_cls: 0.2745  decode.d3.loss_mask: 0.9516  decode.d3.loss_dice: 0.7796  decode.d4.loss_cls: 0.2559  decode.d4.loss_mask: 0.9685  decode.d4.loss_dice: 0.7817  decode.d5.loss_cls: 0.2702  decode.d5.loss_mask: 0.9703  decode.d5.loss_dice: 0.7765  decode.d6.loss_cls: 0.2488  decode.d6.loss_mask: 0.9662  decode.d6.loss_dice: 0.7819  decode.d7.loss_cls: 0.2541  decode.d7.loss_mask: 0.9622  decode.d7.loss_dice: 0.7654  decode.d8.loss_cls: 0.2757  decode.d8.loss_mask: 0.9535  decode.d8.loss_dice: 0.7822
05/27 01:59:04 - mmengine - INFO - Iter(train) [126800/160000]  base_lr: 2.4284e-05 lr: 2.4284e-06  eta: 3:48:48  time: 0.4172  data_time: 0.0098  memory: 5966  grad_norm: 625.3797  loss: 22.7611  decode.loss_cls: 0.2570  decode.loss_mask: 1.0809  decode.loss_dice: 0.8529  decode.d0.loss_cls: 0.8743  decode.d0.loss_mask: 1.0503  decode.d0.loss_dice: 0.8116  decode.d1.loss_cls: 0.3115  decode.d1.loss_mask: 1.1188  decode.d1.loss_dice: 0.8472  decode.d2.loss_cls: 0.2862  decode.d2.loss_mask: 1.1059  decode.d2.loss_dice: 0.8573  decode.d3.loss_cls: 0.2776  decode.d3.loss_mask: 1.0612  decode.d3.loss_dice: 0.8339  decode.d4.loss_cls: 0.2704  decode.d4.loss_mask: 1.0951  decode.d4.loss_dice: 0.8252  decode.d5.loss_cls: 0.3237  decode.d5.loss_mask: 1.1293  decode.d5.loss_dice: 0.8047  decode.d6.loss_cls: 0.3173  decode.d6.loss_mask: 1.1032  decode.d6.loss_dice: 0.8177  decode.d7.loss_cls: 0.2956  decode.d7.loss_mask: 1.0859  decode.d7.loss_dice: 0.8156  decode.d8.loss_cls: 0.2692  decode.d8.loss_mask: 1.1154  decode.d8.loss_dice: 0.8661
05/27 01:59:25 - mmengine - INFO - Iter(train) [126850/160000]  base_lr: 2.4251e-05 lr: 2.4251e-06  eta: 3:48:27  time: 0.4159  data_time: 0.0099  memory: 5969  grad_norm: 408.0815  loss: 20.3640  decode.loss_cls: 0.1925  decode.loss_mask: 1.0885  decode.loss_dice: 0.7264  decode.d0.loss_cls: 0.5905  decode.d0.loss_mask: 1.0494  decode.d0.loss_dice: 0.7434  decode.d1.loss_cls: 0.1469  decode.d1.loss_mask: 1.0887  decode.d1.loss_dice: 0.7666  decode.d2.loss_cls: 0.1670  decode.d2.loss_mask: 1.0933  decode.d2.loss_dice: 0.7584  decode.d3.loss_cls: 0.1763  decode.d3.loss_mask: 1.0902  decode.d3.loss_dice: 0.7391  decode.d4.loss_cls: 0.1129  decode.d4.loss_mask: 1.1090  decode.d4.loss_dice: 0.7713  decode.d5.loss_cls: 0.1397  decode.d5.loss_mask: 1.1013  decode.d5.loss_dice: 0.7597  decode.d6.loss_cls: 0.1589  decode.d6.loss_mask: 1.0754  decode.d6.loss_dice: 0.7225  decode.d7.loss_cls: 0.1547  decode.d7.loss_mask: 1.1017  decode.d7.loss_dice: 0.7508  decode.d8.loss_cls: 0.1535  decode.d8.loss_mask: 1.0895  decode.d8.loss_dice: 0.7458
05/27 01:59:46 - mmengine - INFO - Iter(train) [126900/160000]  base_lr: 2.4218e-05 lr: 2.4218e-06  eta: 3:48:06  time: 0.4160  data_time: 0.0099  memory: 5971  grad_norm: 333.4768  loss: 17.9940  decode.loss_cls: 0.1681  decode.loss_mask: 0.8422  decode.loss_dice: 0.7308  decode.d0.loss_cls: 0.6467  decode.d0.loss_mask: 0.8181  decode.d0.loss_dice: 0.7434  decode.d1.loss_cls: 0.1457  decode.d1.loss_mask: 0.8397  decode.d1.loss_dice: 0.7210  decode.d2.loss_cls: 0.1984  decode.d2.loss_mask: 0.8471  decode.d2.loss_dice: 0.7372  decode.d3.loss_cls: 0.1647  decode.d3.loss_mask: 0.8389  decode.d3.loss_dice: 0.7412  decode.d4.loss_cls: 0.1924  decode.d4.loss_mask: 0.8339  decode.d4.loss_dice: 0.7117  decode.d5.loss_cls: 0.1882  decode.d5.loss_mask: 0.8476  decode.d5.loss_dice: 0.7434  decode.d6.loss_cls: 0.2359  decode.d6.loss_mask: 0.8303  decode.d6.loss_dice: 0.7173  decode.d7.loss_cls: 0.1760  decode.d7.loss_mask: 0.8401  decode.d7.loss_dice: 0.7117  decode.d8.loss_cls: 0.1980  decode.d8.loss_mask: 0.8408  decode.d8.loss_dice: 0.7433
05/27 02:00:07 - mmengine - INFO - Iter(train) [126950/160000]  base_lr: 2.4185e-05 lr: 2.4185e-06  eta: 3:47:46  time: 0.4158  data_time: 0.0099  memory: 5966  grad_norm: 397.6662  loss: 16.8487  decode.loss_cls: 0.2411  decode.loss_mask: 0.7485  decode.loss_dice: 0.5925  decode.d0.loss_cls: 0.8017  decode.d0.loss_mask: 0.7616  decode.d0.loss_dice: 0.6232  decode.d1.loss_cls: 0.2263  decode.d1.loss_mask: 0.7793  decode.d1.loss_dice: 0.6450  decode.d2.loss_cls: 0.2514  decode.d2.loss_mask: 0.7822  decode.d2.loss_dice: 0.6296  decode.d3.loss_cls: 0.2602  decode.d3.loss_mask: 0.7645  decode.d3.loss_dice: 0.6168  decode.d4.loss_cls: 0.2495  decode.d4.loss_mask: 0.7649  decode.d4.loss_dice: 0.6048  decode.d5.loss_cls: 0.2039  decode.d5.loss_mask: 0.8062  decode.d5.loss_dice: 0.6354  decode.d6.loss_cls: 0.2288  decode.d6.loss_mask: 0.7844  decode.d6.loss_dice: 0.6264  decode.d7.loss_cls: 0.2176  decode.d7.loss_mask: 0.7815  decode.d7.loss_dice: 0.6096  decode.d8.loss_cls: 0.2225  decode.d8.loss_mask: 0.7778  decode.d8.loss_dice: 0.6114
05/27 02:00:28 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 02:00:28 - mmengine - INFO - Iter(train) [127000/160000]  base_lr: 2.4152e-05 lr: 2.4152e-06  eta: 3:47:25  time: 0.4151  data_time: 0.0099  memory: 5989  grad_norm: 764.5274  loss: 19.0166  decode.loss_cls: 0.1403  decode.loss_mask: 1.0096  decode.loss_dice: 0.6540  decode.d0.loss_cls: 0.6264  decode.d0.loss_mask: 1.0085  decode.d0.loss_dice: 0.6854  decode.d1.loss_cls: 0.1753  decode.d1.loss_mask: 1.0175  decode.d1.loss_dice: 0.6822  decode.d2.loss_cls: 0.1583  decode.d2.loss_mask: 1.0069  decode.d2.loss_dice: 0.6737  decode.d3.loss_cls: 0.1516  decode.d3.loss_mask: 1.0153  decode.d3.loss_dice: 0.6885  decode.d4.loss_cls: 0.1700  decode.d4.loss_mask: 1.0128  decode.d4.loss_dice: 0.6880  decode.d5.loss_cls: 0.1489  decode.d5.loss_mask: 1.0068  decode.d5.loss_dice: 0.6938  decode.d6.loss_cls: 0.1832  decode.d6.loss_mask: 1.0182  decode.d6.loss_dice: 0.6947  decode.d7.loss_cls: 0.1559  decode.d7.loss_mask: 1.0156  decode.d7.loss_dice: 0.6913  decode.d8.loss_cls: 0.1585  decode.d8.loss_mask: 1.0011  decode.d8.loss_dice: 0.6845
05/27 02:00:48 - mmengine - INFO - Iter(train) [127050/160000]  base_lr: 2.4119e-05 lr: 2.4119e-06  eta: 3:47:04  time: 0.4160  data_time: 0.0099  memory: 5971  grad_norm: 531.7966  loss: 18.8743  decode.loss_cls: 0.1471  decode.loss_mask: 1.0489  decode.loss_dice: 0.6390  decode.d0.loss_cls: 0.6456  decode.d0.loss_mask: 1.0442  decode.d0.loss_dice: 0.7112  decode.d1.loss_cls: 0.1640  decode.d1.loss_mask: 1.0433  decode.d1.loss_dice: 0.6569  decode.d2.loss_cls: 0.1138  decode.d2.loss_mask: 1.0301  decode.d2.loss_dice: 0.6588  decode.d3.loss_cls: 0.1175  decode.d3.loss_mask: 1.0339  decode.d3.loss_dice: 0.6507  decode.d4.loss_cls: 0.1412  decode.d4.loss_mask: 1.0390  decode.d4.loss_dice: 0.6756  decode.d5.loss_cls: 0.1165  decode.d5.loss_mask: 1.0252  decode.d5.loss_dice: 0.6688  decode.d6.loss_cls: 0.1229  decode.d6.loss_mask: 1.0521  decode.d6.loss_dice: 0.6810  decode.d7.loss_cls: 0.1219  decode.d7.loss_mask: 1.0337  decode.d7.loss_dice: 0.6626  decode.d8.loss_cls: 0.1423  decode.d8.loss_mask: 1.0370  decode.d8.loss_dice: 0.6494
05/27 02:01:09 - mmengine - INFO - Iter(train) [127100/160000]  base_lr: 2.4086e-05 lr: 2.4086e-06  eta: 3:46:44  time: 0.4159  data_time: 0.0099  memory: 5980  grad_norm: 472.0753  loss: 21.1977  decode.loss_cls: 0.1813  decode.loss_mask: 1.0817  decode.loss_dice: 0.7765  decode.d0.loss_cls: 0.8104  decode.d0.loss_mask: 1.0287  decode.d0.loss_dice: 0.7704  decode.d1.loss_cls: 0.1350  decode.d1.loss_mask: 1.1173  decode.d1.loss_dice: 0.8490  decode.d2.loss_cls: 0.1428  decode.d2.loss_mask: 1.0866  decode.d2.loss_dice: 0.8009  decode.d3.loss_cls: 0.1284  decode.d3.loss_mask: 1.1360  decode.d3.loss_dice: 0.7979  decode.d4.loss_cls: 0.1344  decode.d4.loss_mask: 1.1304  decode.d4.loss_dice: 0.8171  decode.d5.loss_cls: 0.1489  decode.d5.loss_mask: 1.1046  decode.d5.loss_dice: 0.7997  decode.d6.loss_cls: 0.1454  decode.d6.loss_mask: 1.1174  decode.d6.loss_dice: 0.8263  decode.d7.loss_cls: 0.1891  decode.d7.loss_mask: 1.0946  decode.d7.loss_dice: 0.7752  decode.d8.loss_cls: 0.1543  decode.d8.loss_mask: 1.1106  decode.d8.loss_dice: 0.8068
05/27 02:01:30 - mmengine - INFO - Iter(train) [127150/160000]  base_lr: 2.4053e-05 lr: 2.4053e-06  eta: 3:46:23  time: 0.4165  data_time: 0.0099  memory: 5967  grad_norm: 395.0000  loss: 16.2237  decode.loss_cls: 0.1504  decode.loss_mask: 0.8117  decode.loss_dice: 0.6027  decode.d0.loss_cls: 0.5716  decode.d0.loss_mask: 0.8223  decode.d0.loss_dice: 0.6469  decode.d1.loss_cls: 0.1572  decode.d1.loss_mask: 0.8245  decode.d1.loss_dice: 0.6243  decode.d2.loss_cls: 0.0969  decode.d2.loss_mask: 0.8186  decode.d2.loss_dice: 0.6496  decode.d3.loss_cls: 0.1440  decode.d3.loss_mask: 0.8071  decode.d3.loss_dice: 0.6051  decode.d4.loss_cls: 0.1318  decode.d4.loss_mask: 0.8115  decode.d4.loss_dice: 0.6304  decode.d5.loss_cls: 0.1272  decode.d5.loss_mask: 0.8172  decode.d5.loss_dice: 0.6173  decode.d6.loss_cls: 0.1285  decode.d6.loss_mask: 0.8125  decode.d6.loss_dice: 0.6230  decode.d7.loss_cls: 0.1700  decode.d7.loss_mask: 0.8175  decode.d7.loss_dice: 0.6092  decode.d8.loss_cls: 0.1702  decode.d8.loss_mask: 0.8098  decode.d8.loss_dice: 0.6147
05/27 02:01:51 - mmengine - INFO - Iter(train) [127200/160000]  base_lr: 2.4020e-05 lr: 2.4020e-06  eta: 3:46:02  time: 0.4155  data_time: 0.0098  memory: 5976  grad_norm: 551.1761  loss: 19.5330  decode.loss_cls: 0.2545  decode.loss_mask: 0.9587  decode.loss_dice: 0.7013  decode.d0.loss_cls: 0.6671  decode.d0.loss_mask: 0.9567  decode.d0.loss_dice: 0.7384  decode.d1.loss_cls: 0.2370  decode.d1.loss_mask: 0.9424  decode.d1.loss_dice: 0.7296  decode.d2.loss_cls: 0.2384  decode.d2.loss_mask: 0.9362  decode.d2.loss_dice: 0.7192  decode.d3.loss_cls: 0.2526  decode.d3.loss_mask: 0.9432  decode.d3.loss_dice: 0.7116  decode.d4.loss_cls: 0.2580  decode.d4.loss_mask: 0.9365  decode.d4.loss_dice: 0.7284  decode.d5.loss_cls: 0.2441  decode.d5.loss_mask: 0.9340  decode.d5.loss_dice: 0.6950  decode.d6.loss_cls: 0.2853  decode.d6.loss_mask: 0.8791  decode.d6.loss_dice: 0.6960  decode.d7.loss_cls: 0.2736  decode.d7.loss_mask: 0.9662  decode.d7.loss_dice: 0.7261  decode.d8.loss_cls: 0.2666  decode.d8.loss_mask: 0.9491  decode.d8.loss_dice: 0.7080
05/27 02:02:12 - mmengine - INFO - Iter(train) [127250/160000]  base_lr: 2.3987e-05 lr: 2.3987e-06  eta: 3:45:42  time: 0.4154  data_time: 0.0099  memory: 5976  grad_norm: 641.2852  loss: 18.1677  decode.loss_cls: 0.1528  decode.loss_mask: 0.9025  decode.loss_dice: 0.7082  decode.d0.loss_cls: 0.6830  decode.d0.loss_mask: 0.8288  decode.d0.loss_dice: 0.6808  decode.d1.loss_cls: 0.1621  decode.d1.loss_mask: 0.9138  decode.d1.loss_dice: 0.7447  decode.d2.loss_cls: 0.1395  decode.d2.loss_mask: 0.9048  decode.d2.loss_dice: 0.7176  decode.d3.loss_cls: 0.1459  decode.d3.loss_mask: 0.8881  decode.d3.loss_dice: 0.7145  decode.d4.loss_cls: 0.1479  decode.d4.loss_mask: 0.9020  decode.d4.loss_dice: 0.7155  decode.d5.loss_cls: 0.1541  decode.d5.loss_mask: 0.9103  decode.d5.loss_dice: 0.6705  decode.d6.loss_cls: 0.1819  decode.d6.loss_mask: 0.8946  decode.d6.loss_dice: 0.7278  decode.d7.loss_cls: 0.1754  decode.d7.loss_mask: 0.9197  decode.d7.loss_dice: 0.7327  decode.d8.loss_cls: 0.1770  decode.d8.loss_mask: 0.8764  decode.d8.loss_dice: 0.6948
05/27 02:02:32 - mmengine - INFO - Iter(train) [127300/160000]  base_lr: 2.3955e-05 lr: 2.3955e-06  eta: 3:45:21  time: 0.4154  data_time: 0.0099  memory: 5967  grad_norm: 689.1151  loss: 18.5617  decode.loss_cls: 0.1961  decode.loss_mask: 0.9622  decode.loss_dice: 0.6312  decode.d0.loss_cls: 0.6204  decode.d0.loss_mask: 0.9795  decode.d0.loss_dice: 0.6519  decode.d1.loss_cls: 0.2320  decode.d1.loss_mask: 0.9624  decode.d1.loss_dice: 0.6400  decode.d2.loss_cls: 0.1957  decode.d2.loss_mask: 0.9601  decode.d2.loss_dice: 0.6300  decode.d3.loss_cls: 0.2150  decode.d3.loss_mask: 0.9682  decode.d3.loss_dice: 0.6374  decode.d4.loss_cls: 0.2200  decode.d4.loss_mask: 0.9810  decode.d4.loss_dice: 0.6245  decode.d5.loss_cls: 0.2190  decode.d5.loss_mask: 0.9538  decode.d5.loss_dice: 0.6227  decode.d6.loss_cls: 0.2220  decode.d6.loss_mask: 0.9868  decode.d6.loss_dice: 0.6325  decode.d7.loss_cls: 0.2122  decode.d7.loss_mask: 0.9550  decode.d7.loss_dice: 0.6092  decode.d8.loss_cls: 0.2118  decode.d8.loss_mask: 0.9727  decode.d8.loss_dice: 0.6563
05/27 02:02:53 - mmengine - INFO - Iter(train) [127350/160000]  base_lr: 2.3922e-05 lr: 2.3922e-06  eta: 3:45:01  time: 0.4155  data_time: 0.0099  memory: 5966  grad_norm: 447.8550  loss: 18.7651  decode.loss_cls: 0.1877  decode.loss_mask: 0.9447  decode.loss_dice: 0.6866  decode.d0.loss_cls: 0.7094  decode.d0.loss_mask: 0.8928  decode.d0.loss_dice: 0.6428  decode.d1.loss_cls: 0.2344  decode.d1.loss_mask: 0.9279  decode.d1.loss_dice: 0.6820  decode.d2.loss_cls: 0.2117  decode.d2.loss_mask: 0.9488  decode.d2.loss_dice: 0.6905  decode.d3.loss_cls: 0.2086  decode.d3.loss_mask: 0.9449  decode.d3.loss_dice: 0.6815  decode.d4.loss_cls: 0.1910  decode.d4.loss_mask: 0.9411  decode.d4.loss_dice: 0.6729  decode.d5.loss_cls: 0.1968  decode.d5.loss_mask: 0.9584  decode.d5.loss_dice: 0.6708  decode.d6.loss_cls: 0.2477  decode.d6.loss_mask: 0.9058  decode.d6.loss_dice: 0.6700  decode.d7.loss_cls: 0.2182  decode.d7.loss_mask: 0.9292  decode.d7.loss_dice: 0.6845  decode.d8.loss_cls: 0.2569  decode.d8.loss_mask: 0.9303  decode.d8.loss_dice: 0.6971
05/27 02:03:14 - mmengine - INFO - Iter(train) [127400/160000]  base_lr: 2.3889e-05 lr: 2.3889e-06  eta: 3:44:40  time: 0.4162  data_time: 0.0099  memory: 5969  grad_norm: 367.1464  loss: 18.9550  decode.loss_cls: 0.1867  decode.loss_mask: 1.0048  decode.loss_dice: 0.6308  decode.d0.loss_cls: 0.6742  decode.d0.loss_mask: 1.0182  decode.d0.loss_dice: 0.6594  decode.d1.loss_cls: 0.1687  decode.d1.loss_mask: 1.0456  decode.d1.loss_dice: 0.6548  decode.d2.loss_cls: 0.1995  decode.d2.loss_mask: 1.0064  decode.d2.loss_dice: 0.6226  decode.d3.loss_cls: 0.1495  decode.d3.loss_mask: 1.0465  decode.d3.loss_dice: 0.6471  decode.d4.loss_cls: 0.1424  decode.d4.loss_mask: 1.0476  decode.d4.loss_dice: 0.6583  decode.d5.loss_cls: 0.1478  decode.d5.loss_mask: 1.0250  decode.d5.loss_dice: 0.6495  decode.d6.loss_cls: 0.1509  decode.d6.loss_mask: 1.0103  decode.d6.loss_dice: 0.6413  decode.d7.loss_cls: 0.1626  decode.d7.loss_mask: 1.0595  decode.d7.loss_dice: 0.6529  decode.d8.loss_cls: 0.1686  decode.d8.loss_mask: 1.0631  decode.d8.loss_dice: 0.6603
05/27 02:03:35 - mmengine - INFO - Iter(train) [127450/160000]  base_lr: 2.3856e-05 lr: 2.3856e-06  eta: 3:44:19  time: 0.4184  data_time: 0.0102  memory: 5966  grad_norm: 558.8162  loss: 17.8858  decode.loss_cls: 0.1511  decode.loss_mask: 0.9777  decode.loss_dice: 0.6159  decode.d0.loss_cls: 0.5729  decode.d0.loss_mask: 0.9876  decode.d0.loss_dice: 0.5806  decode.d1.loss_cls: 0.1752  decode.d1.loss_mask: 0.9987  decode.d1.loss_dice: 0.6030  decode.d2.loss_cls: 0.1479  decode.d2.loss_mask: 0.9795  decode.d2.loss_dice: 0.5965  decode.d3.loss_cls: 0.1871  decode.d3.loss_mask: 1.0027  decode.d3.loss_dice: 0.5987  decode.d4.loss_cls: 0.1521  decode.d4.loss_mask: 0.9771  decode.d4.loss_dice: 0.5763  decode.d5.loss_cls: 0.1259  decode.d5.loss_mask: 1.0344  decode.d5.loss_dice: 0.5888  decode.d6.loss_cls: 0.1682  decode.d6.loss_mask: 0.9878  decode.d6.loss_dice: 0.5888  decode.d7.loss_cls: 0.1679  decode.d7.loss_mask: 0.9902  decode.d7.loss_dice: 0.5991  decode.d8.loss_cls: 0.1919  decode.d8.loss_mask: 0.9821  decode.d8.loss_dice: 0.5798
05/27 02:03:56 - mmengine - INFO - Iter(train) [127500/160000]  base_lr: 2.3823e-05 lr: 2.3823e-06  eta: 3:43:59  time: 0.4165  data_time: 0.0098  memory: 5976  grad_norm: 443.1555  loss: 17.2093  decode.loss_cls: 0.1845  decode.loss_mask: 0.8743  decode.loss_dice: 0.6158  decode.d0.loss_cls: 0.6511  decode.d0.loss_mask: 0.8169  decode.d0.loss_dice: 0.5990  decode.d1.loss_cls: 0.1898  decode.d1.loss_mask: 0.8658  decode.d1.loss_dice: 0.6157  decode.d2.loss_cls: 0.1842  decode.d2.loss_mask: 0.8560  decode.d2.loss_dice: 0.6215  decode.d3.loss_cls: 0.2106  decode.d3.loss_mask: 0.8397  decode.d3.loss_dice: 0.6183  decode.d4.loss_cls: 0.1836  decode.d4.loss_mask: 0.8711  decode.d4.loss_dice: 0.6244  decode.d5.loss_cls: 0.1819  decode.d5.loss_mask: 0.8693  decode.d5.loss_dice: 0.6174  decode.d6.loss_cls: 0.1863  decode.d6.loss_mask: 0.8822  decode.d6.loss_dice: 0.6229  decode.d7.loss_cls: 0.1522  decode.d7.loss_mask: 0.9137  decode.d7.loss_dice: 0.6255  decode.d8.loss_cls: 0.1552  decode.d8.loss_mask: 0.9297  decode.d8.loss_dice: 0.6507
05/27 02:04:17 - mmengine - INFO - Iter(train) [127550/160000]  base_lr: 2.3790e-05 lr: 2.3790e-06  eta: 3:43:38  time: 0.4162  data_time: 0.0099  memory: 5966  grad_norm: 286.0091  loss: 17.6385  decode.loss_cls: 0.1030  decode.loss_mask: 0.9586  decode.loss_dice: 0.6251  decode.d0.loss_cls: 0.5643  decode.d0.loss_mask: 0.9894  decode.d0.loss_dice: 0.6625  decode.d1.loss_cls: 0.1270  decode.d1.loss_mask: 0.9853  decode.d1.loss_dice: 0.6389  decode.d2.loss_cls: 0.1223  decode.d2.loss_mask: 0.9715  decode.d2.loss_dice: 0.6443  decode.d3.loss_cls: 0.1264  decode.d3.loss_mask: 0.9607  decode.d3.loss_dice: 0.6286  decode.d4.loss_cls: 0.1216  decode.d4.loss_mask: 0.9593  decode.d4.loss_dice: 0.6288  decode.d5.loss_cls: 0.1230  decode.d5.loss_mask: 0.9634  decode.d5.loss_dice: 0.6338  decode.d6.loss_cls: 0.1172  decode.d6.loss_mask: 0.9594  decode.d6.loss_dice: 0.6243  decode.d7.loss_cls: 0.1218  decode.d7.loss_mask: 0.9528  decode.d7.loss_dice: 0.6356  decode.d8.loss_cls: 0.1002  decode.d8.loss_mask: 0.9523  decode.d8.loss_dice: 0.6373
05/27 02:04:38 - mmengine - INFO - Iter(train) [127600/160000]  base_lr: 2.3757e-05 lr: 2.3757e-06  eta: 3:43:17  time: 0.4165  data_time: 0.0099  memory: 5965  grad_norm: 723.0663  loss: 16.2501  decode.loss_cls: 0.0637  decode.loss_mask: 0.9116  decode.loss_dice: 0.6232  decode.d0.loss_cls: 0.6219  decode.d0.loss_mask: 0.8264  decode.d0.loss_dice: 0.6067  decode.d1.loss_cls: 0.0529  decode.d1.loss_mask: 0.8800  decode.d1.loss_dice: 0.6203  decode.d2.loss_cls: 0.0516  decode.d2.loss_mask: 0.9037  decode.d2.loss_dice: 0.6374  decode.d3.loss_cls: 0.0500  decode.d3.loss_mask: 0.8904  decode.d3.loss_dice: 0.6239  decode.d4.loss_cls: 0.0565  decode.d4.loss_mask: 0.8870  decode.d4.loss_dice: 0.6299  decode.d5.loss_cls: 0.0582  decode.d5.loss_mask: 0.9071  decode.d5.loss_dice: 0.6279  decode.d6.loss_cls: 0.1158  decode.d6.loss_mask: 0.8602  decode.d6.loss_dice: 0.6029  decode.d7.loss_cls: 0.0494  decode.d7.loss_mask: 0.8928  decode.d7.loss_dice: 0.6245  decode.d8.loss_cls: 0.0572  decode.d8.loss_mask: 0.8948  decode.d8.loss_dice: 0.6222
05/27 02:04:58 - mmengine - INFO - Iter(train) [127650/160000]  base_lr: 2.3724e-05 lr: 2.3724e-06  eta: 3:42:57  time: 0.4159  data_time: 0.0098  memory: 5965  grad_norm: 450.5336  loss: 16.0059  decode.loss_cls: 0.1678  decode.loss_mask: 0.8595  decode.loss_dice: 0.5260  decode.d0.loss_cls: 0.6049  decode.d0.loss_mask: 0.8215  decode.d0.loss_dice: 0.5040  decode.d1.loss_cls: 0.1947  decode.d1.loss_mask: 0.8517  decode.d1.loss_dice: 0.5252  decode.d2.loss_cls: 0.2022  decode.d2.loss_mask: 0.8444  decode.d2.loss_dice: 0.5267  decode.d3.loss_cls: 0.1750  decode.d3.loss_mask: 0.8474  decode.d3.loss_dice: 0.5352  decode.d4.loss_cls: 0.1539  decode.d4.loss_mask: 0.8470  decode.d4.loss_dice: 0.5439  decode.d5.loss_cls: 0.1814  decode.d5.loss_mask: 0.8589  decode.d5.loss_dice: 0.5298  decode.d6.loss_cls: 0.1936  decode.d6.loss_mask: 0.8476  decode.d6.loss_dice: 0.5257  decode.d7.loss_cls: 0.1827  decode.d7.loss_mask: 0.8510  decode.d7.loss_dice: 0.5388  decode.d8.loss_cls: 0.1529  decode.d8.loss_mask: 0.8630  decode.d8.loss_dice: 0.5495
05/27 02:05:19 - mmengine - INFO - Iter(train) [127700/160000]  base_lr: 2.3691e-05 lr: 2.3691e-06  eta: 3:42:36  time: 0.4161  data_time: 0.0098  memory: 5968  grad_norm: 381.9271  loss: 18.7812  decode.loss_cls: 0.1108  decode.loss_mask: 1.0108  decode.loss_dice: 0.6954  decode.d0.loss_cls: 0.7105  decode.d0.loss_mask: 0.9903  decode.d0.loss_dice: 0.6915  decode.d1.loss_cls: 0.0808  decode.d1.loss_mask: 1.0177  decode.d1.loss_dice: 0.7209  decode.d2.loss_cls: 0.0999  decode.d2.loss_mask: 1.0025  decode.d2.loss_dice: 0.6991  decode.d3.loss_cls: 0.1312  decode.d3.loss_mask: 0.9780  decode.d3.loss_dice: 0.6942  decode.d4.loss_cls: 0.1206  decode.d4.loss_mask: 1.0051  decode.d4.loss_dice: 0.7151  decode.d5.loss_cls: 0.1288  decode.d5.loss_mask: 0.9910  decode.d5.loss_dice: 0.6991  decode.d6.loss_cls: 0.0928  decode.d6.loss_mask: 1.0190  decode.d6.loss_dice: 0.7293  decode.d7.loss_cls: 0.1088  decode.d7.loss_mask: 1.0151  decode.d7.loss_dice: 0.7299  decode.d8.loss_cls: 0.0897  decode.d8.loss_mask: 1.0022  decode.d8.loss_dice: 0.7011
05/27 02:05:40 - mmengine - INFO - Iter(train) [127750/160000]  base_lr: 2.3658e-05 lr: 2.3658e-06  eta: 3:42:15  time: 0.4158  data_time: 0.0099  memory: 5967  grad_norm: 522.5048  loss: 18.2299  decode.loss_cls: 0.1935  decode.loss_mask: 0.8934  decode.loss_dice: 0.6411  decode.d0.loss_cls: 0.7015  decode.d0.loss_mask: 0.8971  decode.d0.loss_dice: 0.6448  decode.d1.loss_cls: 0.2119  decode.d1.loss_mask: 0.9394  decode.d1.loss_dice: 0.6536  decode.d2.loss_cls: 0.2101  decode.d2.loss_mask: 0.9637  decode.d2.loss_dice: 0.6559  decode.d3.loss_cls: 0.2216  decode.d3.loss_mask: 0.9221  decode.d3.loss_dice: 0.6469  decode.d4.loss_cls: 0.2264  decode.d4.loss_mask: 0.8974  decode.d4.loss_dice: 0.6383  decode.d5.loss_cls: 0.1875  decode.d5.loss_mask: 0.9251  decode.d5.loss_dice: 0.6712  decode.d6.loss_cls: 0.2214  decode.d6.loss_mask: 0.9219  decode.d6.loss_dice: 0.6517  decode.d7.loss_cls: 0.2024  decode.d7.loss_mask: 0.9199  decode.d7.loss_dice: 0.6503  decode.d8.loss_cls: 0.2004  decode.d8.loss_mask: 0.8923  decode.d8.loss_dice: 0.6269
05/27 02:06:01 - mmengine - INFO - Iter(train) [127800/160000]  base_lr: 2.3625e-05 lr: 2.3625e-06  eta: 3:41:55  time: 0.4155  data_time: 0.0099  memory: 5983  grad_norm: 457.8281  loss: 20.2170  decode.loss_cls: 0.2565  decode.loss_mask: 1.0048  decode.loss_dice: 0.7096  decode.d0.loss_cls: 0.7617  decode.d0.loss_mask: 0.9852  decode.d0.loss_dice: 0.7113  decode.d1.loss_cls: 0.2737  decode.d1.loss_mask: 0.9990  decode.d1.loss_dice: 0.7067  decode.d2.loss_cls: 0.2764  decode.d2.loss_mask: 0.9993  decode.d2.loss_dice: 0.6986  decode.d3.loss_cls: 0.2554  decode.d3.loss_mask: 1.0182  decode.d3.loss_dice: 0.7182  decode.d4.loss_cls: 0.2360  decode.d4.loss_mask: 1.0243  decode.d4.loss_dice: 0.7240  decode.d5.loss_cls: 0.2563  decode.d5.loss_mask: 1.0166  decode.d5.loss_dice: 0.7130  decode.d6.loss_cls: 0.2425  decode.d6.loss_mask: 1.0217  decode.d6.loss_dice: 0.6758  decode.d7.loss_cls: 0.2727  decode.d7.loss_mask: 0.9985  decode.d7.loss_dice: 0.6985  decode.d8.loss_cls: 0.2515  decode.d8.loss_mask: 1.0075  decode.d8.loss_dice: 0.7035
05/27 02:06:22 - mmengine - INFO - Iter(train) [127850/160000]  base_lr: 2.3592e-05 lr: 2.3592e-06  eta: 3:41:34  time: 0.4165  data_time: 0.0099  memory: 5976  grad_norm: 641.9933  loss: 20.7876  decode.loss_cls: 0.1306  decode.loss_mask: 1.1860  decode.loss_dice: 0.7351  decode.d0.loss_cls: 0.5779  decode.d0.loss_mask: 1.1087  decode.d0.loss_dice: 0.6920  decode.d1.loss_cls: 0.1375  decode.d1.loss_mask: 1.1585  decode.d1.loss_dice: 0.7348  decode.d2.loss_cls: 0.1384  decode.d2.loss_mask: 1.1655  decode.d2.loss_dice: 0.7468  decode.d3.loss_cls: 0.1272  decode.d3.loss_mask: 1.1695  decode.d3.loss_dice: 0.7230  decode.d4.loss_cls: 0.1356  decode.d4.loss_mask: 1.1856  decode.d4.loss_dice: 0.7247  decode.d5.loss_cls: 0.1295  decode.d5.loss_mask: 1.1671  decode.d5.loss_dice: 0.7183  decode.d6.loss_cls: 0.1124  decode.d6.loss_mask: 1.1572  decode.d6.loss_dice: 0.7272  decode.d7.loss_cls: 0.1450  decode.d7.loss_mask: 1.2160  decode.d7.loss_dice: 0.7604  decode.d8.loss_cls: 0.1325  decode.d8.loss_mask: 1.2075  decode.d8.loss_dice: 0.7370
05/27 02:06:43 - mmengine - INFO - Iter(train) [127900/160000]  base_lr: 2.3559e-05 lr: 2.3559e-06  eta: 3:41:14  time: 0.4159  data_time: 0.0099  memory: 5976  grad_norm: 605.2096  loss: 20.1210  decode.loss_cls: 0.2153  decode.loss_mask: 1.0595  decode.loss_dice: 0.7196  decode.d0.loss_cls: 0.6634  decode.d0.loss_mask: 1.0938  decode.d0.loss_dice: 0.7689  decode.d1.loss_cls: 0.2070  decode.d1.loss_mask: 1.0470  decode.d1.loss_dice: 0.7315  decode.d2.loss_cls: 0.2127  decode.d2.loss_mask: 1.0026  decode.d2.loss_dice: 0.7103  decode.d3.loss_cls: 0.2117  decode.d3.loss_mask: 1.0103  decode.d3.loss_dice: 0.7155  decode.d4.loss_cls: 0.1996  decode.d4.loss_mask: 1.0040  decode.d4.loss_dice: 0.7177  decode.d5.loss_cls: 0.1677  decode.d5.loss_mask: 1.0412  decode.d5.loss_dice: 0.7337  decode.d6.loss_cls: 0.1977  decode.d6.loss_mask: 1.0375  decode.d6.loss_dice: 0.7168  decode.d7.loss_cls: 0.2127  decode.d7.loss_mask: 1.0399  decode.d7.loss_dice: 0.7265  decode.d8.loss_cls: 0.2104  decode.d8.loss_mask: 1.0319  decode.d8.loss_dice: 0.7146
05/27 02:07:03 - mmengine - INFO - Iter(train) [127950/160000]  base_lr: 2.3526e-05 lr: 2.3526e-06  eta: 3:40:53  time: 0.4164  data_time: 0.0099  memory: 5966  grad_norm: 436.1305  loss: 17.7490  decode.loss_cls: 0.1180  decode.loss_mask: 1.0144  decode.loss_dice: 0.6123  decode.d0.loss_cls: 0.5677  decode.d0.loss_mask: 0.9972  decode.d0.loss_dice: 0.6034  decode.d1.loss_cls: 0.1035  decode.d1.loss_mask: 1.0203  decode.d1.loss_dice: 0.6094  decode.d2.loss_cls: 0.0869  decode.d2.loss_mask: 1.0005  decode.d2.loss_dice: 0.6041  decode.d3.loss_cls: 0.1103  decode.d3.loss_mask: 1.0230  decode.d3.loss_dice: 0.6053  decode.d4.loss_cls: 0.0994  decode.d4.loss_mask: 1.0290  decode.d4.loss_dice: 0.6072  decode.d5.loss_cls: 0.1010  decode.d5.loss_mask: 1.0182  decode.d5.loss_dice: 0.6062  decode.d6.loss_cls: 0.0829  decode.d6.loss_mask: 1.0217  decode.d6.loss_dice: 0.6088  decode.d7.loss_cls: 0.1064  decode.d7.loss_mask: 1.0340  decode.d7.loss_dice: 0.6395  decode.d8.loss_cls: 0.0918  decode.d8.loss_mask: 1.0167  decode.d8.loss_dice: 0.6100
05/27 02:07:24 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 02:07:24 - mmengine - INFO - Iter(train) [128000/160000]  base_lr: 2.3493e-05 lr: 2.3493e-06  eta: 3:40:32  time: 0.4148  data_time: 0.0098  memory: 5965  grad_norm: 697.5053  loss: 20.0484  decode.loss_cls: 0.1649  decode.loss_mask: 1.0538  decode.loss_dice: 0.7302  decode.d0.loss_cls: 0.6703  decode.d0.loss_mask: 1.0661  decode.d0.loss_dice: 0.7331  decode.d1.loss_cls: 0.1783  decode.d1.loss_mask: 1.0680  decode.d1.loss_dice: 0.7337  decode.d2.loss_cls: 0.1570  decode.d2.loss_mask: 1.0595  decode.d2.loss_dice: 0.7310  decode.d3.loss_cls: 0.1498  decode.d3.loss_mask: 1.0495  decode.d3.loss_dice: 0.7363  decode.d4.loss_cls: 0.1829  decode.d4.loss_mask: 1.0547  decode.d4.loss_dice: 0.7197  decode.d5.loss_cls: 0.1681  decode.d5.loss_mask: 1.0514  decode.d5.loss_dice: 0.7200  decode.d6.loss_cls: 0.2013  decode.d6.loss_mask: 1.0457  decode.d6.loss_dice: 0.7082  decode.d7.loss_cls: 0.1998  decode.d7.loss_mask: 1.0504  decode.d7.loss_dice: 0.7178  decode.d8.loss_cls: 0.1710  decode.d8.loss_mask: 1.0520  decode.d8.loss_dice: 0.7240
05/27 02:07:45 - mmengine - INFO - Iter(train) [128050/160000]  base_lr: 2.3459e-05 lr: 2.3459e-06  eta: 3:40:12  time: 0.4159  data_time: 0.0098  memory: 5976  grad_norm: 511.4380  loss: 20.8163  decode.loss_cls: 0.1979  decode.loss_mask: 0.9915  decode.loss_dice: 0.8326  decode.d0.loss_cls: 0.7316  decode.d0.loss_mask: 0.9495  decode.d0.loss_dice: 0.8463  decode.d1.loss_cls: 0.2335  decode.d1.loss_mask: 1.0082  decode.d1.loss_dice: 0.8356  decode.d2.loss_cls: 0.2242  decode.d2.loss_mask: 0.9496  decode.d2.loss_dice: 0.8228  decode.d3.loss_cls: 0.2234  decode.d3.loss_mask: 0.9627  decode.d3.loss_dice: 0.8311  decode.d4.loss_cls: 0.2503  decode.d4.loss_mask: 0.9609  decode.d4.loss_dice: 0.8283  decode.d5.loss_cls: 0.2129  decode.d5.loss_mask: 0.9887  decode.d5.loss_dice: 0.8363  decode.d6.loss_cls: 0.2250  decode.d6.loss_mask: 0.9590  decode.d6.loss_dice: 0.8258  decode.d7.loss_cls: 0.1971  decode.d7.loss_mask: 0.9928  decode.d7.loss_dice: 0.8390  decode.d8.loss_cls: 0.2452  decode.d8.loss_mask: 0.9749  decode.d8.loss_dice: 0.8397
05/27 02:08:06 - mmengine - INFO - Iter(train) [128100/160000]  base_lr: 2.3426e-05 lr: 2.3426e-06  eta: 3:39:51  time: 0.4160  data_time: 0.0098  memory: 5966  grad_norm: 801.8923  loss: 20.7183  decode.loss_cls: 0.2429  decode.loss_mask: 1.0557  decode.loss_dice: 0.7674  decode.d0.loss_cls: 0.6819  decode.d0.loss_mask: 0.9259  decode.d0.loss_dice: 0.7346  decode.d1.loss_cls: 0.2850  decode.d1.loss_mask: 1.0134  decode.d1.loss_dice: 0.7580  decode.d2.loss_cls: 0.3118  decode.d2.loss_mask: 1.0213  decode.d2.loss_dice: 0.7416  decode.d3.loss_cls: 0.2775  decode.d3.loss_mask: 0.9943  decode.d3.loss_dice: 0.7406  decode.d4.loss_cls: 0.2839  decode.d4.loss_mask: 1.0237  decode.d4.loss_dice: 0.7701  decode.d5.loss_cls: 0.2943  decode.d5.loss_mask: 0.9822  decode.d5.loss_dice: 0.7306  decode.d6.loss_cls: 0.3006  decode.d6.loss_mask: 0.9312  decode.d6.loss_dice: 0.7245  decode.d7.loss_cls: 0.2843  decode.d7.loss_mask: 1.0085  decode.d7.loss_dice: 0.7442  decode.d8.loss_cls: 0.2628  decode.d8.loss_mask: 1.0609  decode.d8.loss_dice: 0.7647
05/27 02:08:27 - mmengine - INFO - Iter(train) [128150/160000]  base_lr: 2.3393e-05 lr: 2.3393e-06  eta: 3:39:30  time: 0.4166  data_time: 0.0099  memory: 5970  grad_norm: 607.5353  loss: 19.5959  decode.loss_cls: 0.1817  decode.loss_mask: 1.0518  decode.loss_dice: 0.6794  decode.d0.loss_cls: 0.6688  decode.d0.loss_mask: 1.0021  decode.d0.loss_dice: 0.6371  decode.d1.loss_cls: 0.2141  decode.d1.loss_mask: 1.0517  decode.d1.loss_dice: 0.6696  decode.d2.loss_cls: 0.1953  decode.d2.loss_mask: 1.0501  decode.d2.loss_dice: 0.6754  decode.d3.loss_cls: 0.1801  decode.d3.loss_mask: 1.0494  decode.d3.loss_dice: 0.6754  decode.d4.loss_cls: 0.1895  decode.d4.loss_mask: 1.0537  decode.d4.loss_dice: 0.6769  decode.d5.loss_cls: 0.1959  decode.d5.loss_mask: 1.0617  decode.d5.loss_dice: 0.6758  decode.d6.loss_cls: 0.2046  decode.d6.loss_mask: 1.0649  decode.d6.loss_dice: 0.6778  decode.d7.loss_cls: 0.1909  decode.d7.loss_mask: 1.0530  decode.d7.loss_dice: 0.6632  decode.d8.loss_cls: 0.1836  decode.d8.loss_mask: 1.0593  decode.d8.loss_dice: 0.6631
05/27 02:08:48 - mmengine - INFO - Iter(train) [128200/160000]  base_lr: 2.3360e-05 lr: 2.3360e-06  eta: 3:39:10  time: 0.4166  data_time: 0.0100  memory: 5966  grad_norm: 510.8599  loss: 21.8068  decode.loss_cls: 0.2089  decode.loss_mask: 1.0677  decode.loss_dice: 0.7976  decode.d0.loss_cls: 0.7558  decode.d0.loss_mask: 1.0864  decode.d0.loss_dice: 0.7905  decode.d1.loss_cls: 0.2461  decode.d1.loss_mask: 1.0980  decode.d1.loss_dice: 0.8012  decode.d2.loss_cls: 0.2184  decode.d2.loss_mask: 1.1021  decode.d2.loss_dice: 0.8037  decode.d3.loss_cls: 0.2501  decode.d3.loss_mask: 1.1079  decode.d3.loss_dice: 0.7851  decode.d4.loss_cls: 0.2274  decode.d4.loss_mask: 1.1188  decode.d4.loss_dice: 0.7829  decode.d5.loss_cls: 0.2306  decode.d5.loss_mask: 1.1008  decode.d5.loss_dice: 0.7924  decode.d6.loss_cls: 0.2528  decode.d6.loss_mask: 1.1117  decode.d6.loss_dice: 0.7994  decode.d7.loss_cls: 0.2843  decode.d7.loss_mask: 1.0910  decode.d7.loss_dice: 0.7845  decode.d8.loss_cls: 0.2242  decode.d8.loss_mask: 1.0856  decode.d8.loss_dice: 0.8009
05/27 02:09:08 - mmengine - INFO - Iter(train) [128250/160000]  base_lr: 2.3327e-05 lr: 2.3327e-06  eta: 3:38:49  time: 0.4163  data_time: 0.0099  memory: 5968  grad_norm: 322.1482  loss: 16.0849  decode.loss_cls: 0.0722  decode.loss_mask: 0.9278  decode.loss_dice: 0.5660  decode.d0.loss_cls: 0.5487  decode.d0.loss_mask: 0.8848  decode.d0.loss_dice: 0.5648  decode.d1.loss_cls: 0.0629  decode.d1.loss_mask: 0.9220  decode.d1.loss_dice: 0.5716  decode.d2.loss_cls: 0.0700  decode.d2.loss_mask: 0.9384  decode.d2.loss_dice: 0.5611  decode.d3.loss_cls: 0.0756  decode.d3.loss_mask: 0.9176  decode.d3.loss_dice: 0.5646  decode.d4.loss_cls: 0.0698  decode.d4.loss_mask: 0.9394  decode.d4.loss_dice: 0.5686  decode.d5.loss_cls: 0.0737  decode.d5.loss_mask: 0.9249  decode.d5.loss_dice: 0.5597  decode.d6.loss_cls: 0.0704  decode.d6.loss_mask: 0.9451  decode.d6.loss_dice: 0.5576  decode.d7.loss_cls: 0.0691  decode.d7.loss_mask: 0.9293  decode.d7.loss_dice: 0.5562  decode.d8.loss_cls: 0.0633  decode.d8.loss_mask: 0.9401  decode.d8.loss_dice: 0.5695
05/27 02:09:29 - mmengine - INFO - Iter(train) [128300/160000]  base_lr: 2.3294e-05 lr: 2.3294e-06  eta: 3:38:28  time: 0.4172  data_time: 0.0099  memory: 5980  grad_norm: 365.6866  loss: 16.0022  decode.loss_cls: 0.1382  decode.loss_mask: 0.7906  decode.loss_dice: 0.6027  decode.d0.loss_cls: 0.6028  decode.d0.loss_mask: 0.7892  decode.d0.loss_dice: 0.6168  decode.d1.loss_cls: 0.1306  decode.d1.loss_mask: 0.7997  decode.d1.loss_dice: 0.6130  decode.d2.loss_cls: 0.1542  decode.d2.loss_mask: 0.7832  decode.d2.loss_dice: 0.6049  decode.d3.loss_cls: 0.1539  decode.d3.loss_mask: 0.7929  decode.d3.loss_dice: 0.6176  decode.d4.loss_cls: 0.1403  decode.d4.loss_mask: 0.8017  decode.d4.loss_dice: 0.6118  decode.d5.loss_cls: 0.1504  decode.d5.loss_mask: 0.7957  decode.d5.loss_dice: 0.6085  decode.d6.loss_cls: 0.1662  decode.d6.loss_mask: 0.8031  decode.d6.loss_dice: 0.6143  decode.d7.loss_cls: 0.1515  decode.d7.loss_mask: 0.7981  decode.d7.loss_dice: 0.6066  decode.d8.loss_cls: 0.1518  decode.d8.loss_mask: 0.7956  decode.d8.loss_dice: 0.6162
05/27 02:09:50 - mmengine - INFO - Iter(train) [128350/160000]  base_lr: 2.3261e-05 lr: 2.3261e-06  eta: 3:38:08  time: 0.4162  data_time: 0.0099  memory: 5973  grad_norm: 627.2310  loss: 19.7237  decode.loss_cls: 0.1911  decode.loss_mask: 0.9967  decode.loss_dice: 0.7277  decode.d0.loss_cls: 0.6309  decode.d0.loss_mask: 0.9562  decode.d0.loss_dice: 0.7119  decode.d1.loss_cls: 0.2495  decode.d1.loss_mask: 0.9876  decode.d1.loss_dice: 0.7100  decode.d2.loss_cls: 0.2253  decode.d2.loss_mask: 0.9668  decode.d2.loss_dice: 0.7289  decode.d3.loss_cls: 0.2206  decode.d3.loss_mask: 0.9749  decode.d3.loss_dice: 0.7113  decode.d4.loss_cls: 0.2125  decode.d4.loss_mask: 0.9935  decode.d4.loss_dice: 0.7191  decode.d5.loss_cls: 0.2139  decode.d5.loss_mask: 0.9960  decode.d5.loss_dice: 0.7151  decode.d6.loss_cls: 0.2118  decode.d6.loss_mask: 1.0078  decode.d6.loss_dice: 0.7176  decode.d7.loss_cls: 0.2211  decode.d7.loss_mask: 1.0712  decode.d7.loss_dice: 0.7295  decode.d8.loss_cls: 0.1985  decode.d8.loss_mask: 0.9990  decode.d8.loss_dice: 0.7278
05/27 02:10:11 - mmengine - INFO - Iter(train) [128400/160000]  base_lr: 2.3228e-05 lr: 2.3228e-06  eta: 3:37:47  time: 0.4161  data_time: 0.0100  memory: 5975  grad_norm: 535.4930  loss: 19.7567  decode.loss_cls: 0.2204  decode.loss_mask: 0.9016  decode.loss_dice: 0.7885  decode.d0.loss_cls: 0.7405  decode.d0.loss_mask: 0.8862  decode.d0.loss_dice: 0.7925  decode.d1.loss_cls: 0.2443  decode.d1.loss_mask: 0.9180  decode.d1.loss_dice: 0.8160  decode.d2.loss_cls: 0.2318  decode.d2.loss_mask: 0.8938  decode.d2.loss_dice: 0.7894  decode.d3.loss_cls: 0.2517  decode.d3.loss_mask: 0.8883  decode.d3.loss_dice: 0.7921  decode.d4.loss_cls: 0.2373  decode.d4.loss_mask: 0.8830  decode.d4.loss_dice: 0.7871  decode.d5.loss_cls: 0.2188  decode.d5.loss_mask: 0.9123  decode.d5.loss_dice: 0.8063  decode.d6.loss_cls: 0.2210  decode.d6.loss_mask: 0.9086  decode.d6.loss_dice: 0.8007  decode.d7.loss_cls: 0.2366  decode.d7.loss_mask: 0.8851  decode.d7.loss_dice: 0.7772  decode.d8.loss_cls: 0.2378  decode.d8.loss_mask: 0.8961  decode.d8.loss_dice: 0.7937
05/27 02:10:32 - mmengine - INFO - Iter(train) [128450/160000]  base_lr: 2.3195e-05 lr: 2.3195e-06  eta: 3:37:27  time: 0.4165  data_time: 0.0100  memory: 5966  grad_norm: 683.4549  loss: 19.0622  decode.loss_cls: 0.1020  decode.loss_mask: 1.0456  decode.loss_dice: 0.6763  decode.d0.loss_cls: 0.5773  decode.d0.loss_mask: 1.0945  decode.d0.loss_dice: 0.6786  decode.d1.loss_cls: 0.0877  decode.d1.loss_mask: 1.0606  decode.d1.loss_dice: 0.7229  decode.d2.loss_cls: 0.1180  decode.d2.loss_mask: 1.0964  decode.d2.loss_dice: 0.6935  decode.d3.loss_cls: 0.0771  decode.d3.loss_mask: 1.1202  decode.d3.loss_dice: 0.7215  decode.d4.loss_cls: 0.0921  decode.d4.loss_mask: 1.0630  decode.d4.loss_dice: 0.7029  decode.d5.loss_cls: 0.0791  decode.d5.loss_mask: 1.0830  decode.d5.loss_dice: 0.7142  decode.d6.loss_cls: 0.1182  decode.d6.loss_mask: 1.0205  decode.d6.loss_dice: 0.6682  decode.d7.loss_cls: 0.1013  decode.d7.loss_mask: 1.0359  decode.d7.loss_dice: 0.6935  decode.d8.loss_cls: 0.1019  decode.d8.loss_mask: 1.0463  decode.d8.loss_dice: 0.6699
05/27 02:10:53 - mmengine - INFO - Iter(train) [128500/160000]  base_lr: 2.3162e-05 lr: 2.3162e-06  eta: 3:37:06  time: 0.4164  data_time: 0.0099  memory: 5966  grad_norm: 486.0920  loss: 21.1485  decode.loss_cls: 0.1170  decode.loss_mask: 1.1710  decode.loss_dice: 0.7892  decode.d0.loss_cls: 0.6319  decode.d0.loss_mask: 1.0718  decode.d0.loss_dice: 0.7156  decode.d1.loss_cls: 0.1379  decode.d1.loss_mask: 1.1509  decode.d1.loss_dice: 0.7675  decode.d2.loss_cls: 0.1514  decode.d2.loss_mask: 1.1492  decode.d2.loss_dice: 0.7865  decode.d3.loss_cls: 0.1475  decode.d3.loss_mask: 1.1441  decode.d3.loss_dice: 0.7973  decode.d4.loss_cls: 0.1567  decode.d4.loss_mask: 1.1356  decode.d4.loss_dice: 0.7728  decode.d5.loss_cls: 0.1524  decode.d5.loss_mask: 1.1469  decode.d5.loss_dice: 0.7771  decode.d6.loss_cls: 0.1396  decode.d6.loss_mask: 1.1538  decode.d6.loss_dice: 0.7770  decode.d7.loss_cls: 0.1312  decode.d7.loss_mask: 1.1846  decode.d7.loss_dice: 0.7952  decode.d8.loss_cls: 0.1253  decode.d8.loss_mask: 1.1636  decode.d8.loss_dice: 0.8081
05/27 02:11:14 - mmengine - INFO - Iter(train) [128550/160000]  base_lr: 2.3129e-05 lr: 2.3129e-06  eta: 3:36:45  time: 0.4162  data_time: 0.0099  memory: 5966  grad_norm: 909.9974  loss: 19.1445  decode.loss_cls: 0.3052  decode.loss_mask: 0.9079  decode.loss_dice: 0.6654  decode.d0.loss_cls: 0.7860  decode.d0.loss_mask: 0.9157  decode.d0.loss_dice: 0.6810  decode.d1.loss_cls: 0.2520  decode.d1.loss_mask: 0.8966  decode.d1.loss_dice: 0.6730  decode.d2.loss_cls: 0.2888  decode.d2.loss_mask: 0.9081  decode.d2.loss_dice: 0.6742  decode.d3.loss_cls: 0.2860  decode.d3.loss_mask: 0.9040  decode.d3.loss_dice: 0.6821  decode.d4.loss_cls: 0.2524  decode.d4.loss_mask: 0.9119  decode.d4.loss_dice: 0.6708  decode.d5.loss_cls: 0.2678  decode.d5.loss_mask: 0.9266  decode.d5.loss_dice: 0.6826  decode.d6.loss_cls: 0.2780  decode.d6.loss_mask: 0.9061  decode.d6.loss_dice: 0.6690  decode.d7.loss_cls: 0.2970  decode.d7.loss_mask: 0.9084  decode.d7.loss_dice: 0.6730  decode.d8.loss_cls: 0.2595  decode.d8.loss_mask: 0.9320  decode.d8.loss_dice: 0.6835
05/27 02:11:34 - mmengine - INFO - Iter(train) [128600/160000]  base_lr: 2.3096e-05 lr: 2.3096e-06  eta: 3:36:25  time: 0.4159  data_time: 0.0099  memory: 5976  grad_norm: 689.9378  loss: 19.7082  decode.loss_cls: 0.1459  decode.loss_mask: 1.0878  decode.loss_dice: 0.6846  decode.d0.loss_cls: 0.6283  decode.d0.loss_mask: 0.9978  decode.d0.loss_dice: 0.6543  decode.d1.loss_cls: 0.2347  decode.d1.loss_mask: 1.0321  decode.d1.loss_dice: 0.6612  decode.d2.loss_cls: 0.2124  decode.d2.loss_mask: 0.9883  decode.d2.loss_dice: 0.6722  decode.d3.loss_cls: 0.2351  decode.d3.loss_mask: 1.0059  decode.d3.loss_dice: 0.6665  decode.d4.loss_cls: 0.2250  decode.d4.loss_mask: 1.0767  decode.d4.loss_dice: 0.6592  decode.d5.loss_cls: 0.2282  decode.d5.loss_mask: 1.0009  decode.d5.loss_dice: 0.6595  decode.d6.loss_cls: 0.2166  decode.d6.loss_mask: 1.0286  decode.d6.loss_dice: 0.6882  decode.d7.loss_cls: 0.2088  decode.d7.loss_mask: 1.1380  decode.d7.loss_dice: 0.7037  decode.d8.loss_cls: 0.1986  decode.d8.loss_mask: 1.0813  decode.d8.loss_dice: 0.6878
05/27 02:11:55 - mmengine - INFO - Iter(train) [128650/160000]  base_lr: 2.3063e-05 lr: 2.3063e-06  eta: 3:36:04  time: 0.4159  data_time: 0.0099  memory: 5975  grad_norm: 599.8905  loss: 19.1576  decode.loss_cls: 0.1977  decode.loss_mask: 1.0174  decode.loss_dice: 0.6576  decode.d0.loss_cls: 0.7762  decode.d0.loss_mask: 0.9846  decode.d0.loss_dice: 0.6864  decode.d1.loss_cls: 0.1960  decode.d1.loss_mask: 1.0063  decode.d1.loss_dice: 0.6688  decode.d2.loss_cls: 0.2129  decode.d2.loss_mask: 0.9870  decode.d2.loss_dice: 0.6485  decode.d3.loss_cls: 0.1713  decode.d3.loss_mask: 1.0051  decode.d3.loss_dice: 0.6480  decode.d4.loss_cls: 0.1827  decode.d4.loss_mask: 0.9970  decode.d4.loss_dice: 0.6616  decode.d5.loss_cls: 0.1779  decode.d5.loss_mask: 1.0172  decode.d5.loss_dice: 0.6964  decode.d6.loss_cls: 0.1787  decode.d6.loss_mask: 1.0275  decode.d6.loss_dice: 0.6947  decode.d7.loss_cls: 0.2088  decode.d7.loss_mask: 0.9871  decode.d7.loss_dice: 0.6562  decode.d8.loss_cls: 0.1605  decode.d8.loss_mask: 1.0093  decode.d8.loss_dice: 0.6384
05/27 02:12:16 - mmengine - INFO - Iter(train) [128700/160000]  base_lr: 2.3029e-05 lr: 2.3029e-06  eta: 3:35:43  time: 0.4157  data_time: 0.0099  memory: 5967  grad_norm: 625.6562  loss: 14.7001  decode.loss_cls: 0.0420  decode.loss_mask: 0.8724  decode.loss_dice: 0.4914  decode.d0.loss_cls: 0.4767  decode.d0.loss_mask: 0.8807  decode.d0.loss_dice: 0.5080  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 0.8658  decode.d1.loss_dice: 0.4950  decode.d2.loss_cls: 0.0619  decode.d2.loss_mask: 0.8740  decode.d2.loss_dice: 0.5002  decode.d3.loss_cls: 0.0574  decode.d3.loss_mask: 0.8762  decode.d3.loss_dice: 0.5006  decode.d4.loss_cls: 0.0580  decode.d4.loss_mask: 0.8709  decode.d4.loss_dice: 0.4939  decode.d5.loss_cls: 0.0607  decode.d5.loss_mask: 0.8644  decode.d5.loss_dice: 0.5002  decode.d6.loss_cls: 0.0737  decode.d6.loss_mask: 0.8661  decode.d6.loss_dice: 0.4872  decode.d7.loss_cls: 0.0519  decode.d7.loss_mask: 0.8755  decode.d7.loss_dice: 0.5025  decode.d8.loss_cls: 0.0466  decode.d8.loss_mask: 0.8728  decode.d8.loss_dice: 0.4985
05/27 02:12:37 - mmengine - INFO - Iter(train) [128750/160000]  base_lr: 2.2996e-05 lr: 2.2996e-06  eta: 3:35:23  time: 0.4161  data_time: 0.0100  memory: 5966  grad_norm: 597.5732  loss: 20.7141  decode.loss_cls: 0.2489  decode.loss_mask: 1.0777  decode.loss_dice: 0.6871  decode.d0.loss_cls: 0.6896  decode.d0.loss_mask: 0.9817  decode.d0.loss_dice: 0.6875  decode.d1.loss_cls: 0.2460  decode.d1.loss_mask: 1.1124  decode.d1.loss_dice: 0.7207  decode.d2.loss_cls: 0.2596  decode.d2.loss_mask: 1.1346  decode.d2.loss_dice: 0.7084  decode.d3.loss_cls: 0.2514  decode.d3.loss_mask: 1.0800  decode.d3.loss_dice: 0.6824  decode.d4.loss_cls: 0.2757  decode.d4.loss_mask: 1.0733  decode.d4.loss_dice: 0.6818  decode.d5.loss_cls: 0.2672  decode.d5.loss_mask: 1.0792  decode.d5.loss_dice: 0.6927  decode.d6.loss_cls: 0.2702  decode.d6.loss_mask: 1.0768  decode.d6.loss_dice: 0.6742  decode.d7.loss_cls: 0.2590  decode.d7.loss_mask: 1.0733  decode.d7.loss_dice: 0.7052  decode.d8.loss_cls: 0.2541  decode.d8.loss_mask: 1.0737  decode.d8.loss_dice: 0.6900
05/27 02:12:58 - mmengine - INFO - Iter(train) [128800/160000]  base_lr: 2.2963e-05 lr: 2.2963e-06  eta: 3:35:02  time: 0.4163  data_time: 0.0098  memory: 5967  grad_norm: 889.0541  loss: 22.7238  decode.loss_cls: 0.1725  decode.loss_mask: 1.3100  decode.loss_dice: 0.7329  decode.d0.loss_cls: 0.6806  decode.d0.loss_mask: 1.2582  decode.d0.loss_dice: 0.6992  decode.d1.loss_cls: 0.2455  decode.d1.loss_mask: 1.3118  decode.d1.loss_dice: 0.7337  decode.d2.loss_cls: 0.1667  decode.d2.loss_mask: 1.3387  decode.d2.loss_dice: 0.7503  decode.d3.loss_cls: 0.2420  decode.d3.loss_mask: 1.2556  decode.d3.loss_dice: 0.7013  decode.d4.loss_cls: 0.1898  decode.d4.loss_mask: 1.3220  decode.d4.loss_dice: 0.7280  decode.d5.loss_cls: 0.1910  decode.d5.loss_mask: 1.2989  decode.d5.loss_dice: 0.7168  decode.d6.loss_cls: 0.2270  decode.d6.loss_mask: 1.2642  decode.d6.loss_dice: 0.6979  decode.d7.loss_cls: 0.1896  decode.d7.loss_mask: 1.3036  decode.d7.loss_dice: 0.7218  decode.d8.loss_cls: 0.1730  decode.d8.loss_mask: 1.3372  decode.d8.loss_dice: 0.7638
05/27 02:13:19 - mmengine - INFO - Iter(train) [128850/160000]  base_lr: 2.2930e-05 lr: 2.2930e-06  eta: 3:34:41  time: 0.4163  data_time: 0.0100  memory: 5973  grad_norm: 365.3255  loss: 15.3020  decode.loss_cls: 0.0865  decode.loss_mask: 0.7801  decode.loss_dice: 0.6069  decode.d0.loss_cls: 0.5083  decode.d0.loss_mask: 0.7791  decode.d0.loss_dice: 0.5902  decode.d1.loss_cls: 0.0729  decode.d1.loss_mask: 0.8002  decode.d1.loss_dice: 0.6102  decode.d2.loss_cls: 0.1469  decode.d2.loss_mask: 0.7789  decode.d2.loss_dice: 0.5921  decode.d3.loss_cls: 0.0896  decode.d3.loss_mask: 0.7880  decode.d3.loss_dice: 0.5799  decode.d4.loss_cls: 0.1038  decode.d4.loss_mask: 0.7859  decode.d4.loss_dice: 0.6137  decode.d5.loss_cls: 0.1276  decode.d5.loss_mask: 0.7707  decode.d5.loss_dice: 0.5919  decode.d6.loss_cls: 0.0857  decode.d6.loss_mask: 0.7990  decode.d6.loss_dice: 0.6199  decode.d7.loss_cls: 0.0833  decode.d7.loss_mask: 0.7972  decode.d7.loss_dice: 0.6227  decode.d8.loss_cls: 0.0842  decode.d8.loss_mask: 0.7855  decode.d8.loss_dice: 0.6209
05/27 02:13:39 - mmengine - INFO - Iter(train) [128900/160000]  base_lr: 2.2897e-05 lr: 2.2897e-06  eta: 3:34:21  time: 0.4160  data_time: 0.0099  memory: 5968  grad_norm: 557.9505  loss: 17.4613  decode.loss_cls: 0.0924  decode.loss_mask: 0.9240  decode.loss_dice: 0.7046  decode.d0.loss_cls: 0.5737  decode.d0.loss_mask: 0.8493  decode.d0.loss_dice: 0.6510  decode.d1.loss_cls: 0.1042  decode.d1.loss_mask: 0.8946  decode.d1.loss_dice: 0.6876  decode.d2.loss_cls: 0.1087  decode.d2.loss_mask: 0.9206  decode.d2.loss_dice: 0.6980  decode.d3.loss_cls: 0.1158  decode.d3.loss_mask: 0.9001  decode.d3.loss_dice: 0.6856  decode.d4.loss_cls: 0.0986  decode.d4.loss_mask: 0.9143  decode.d4.loss_dice: 0.7023  decode.d5.loss_cls: 0.1182  decode.d5.loss_mask: 0.9024  decode.d5.loss_dice: 0.6986  decode.d6.loss_cls: 0.1074  decode.d6.loss_mask: 0.9098  decode.d6.loss_dice: 0.6905  decode.d7.loss_cls: 0.1006  decode.d7.loss_mask: 0.9158  decode.d7.loss_dice: 0.6925  decode.d8.loss_cls: 0.0888  decode.d8.loss_mask: 0.9116  decode.d8.loss_dice: 0.6998
05/27 02:14:00 - mmengine - INFO - Iter(train) [128950/160000]  base_lr: 2.2864e-05 lr: 2.2864e-06  eta: 3:34:00  time: 0.4154  data_time: 0.0099  memory: 5974  grad_norm: 709.1651  loss: 16.6683  decode.loss_cls: 0.1097  decode.loss_mask: 0.8756  decode.loss_dice: 0.6173  decode.d0.loss_cls: 0.6814  decode.d0.loss_mask: 0.8169  decode.d0.loss_dice: 0.5770  decode.d1.loss_cls: 0.1568  decode.d1.loss_mask: 0.8550  decode.d1.loss_dice: 0.6153  decode.d2.loss_cls: 0.1511  decode.d2.loss_mask: 0.8599  decode.d2.loss_dice: 0.6102  decode.d3.loss_cls: 0.1556  decode.d3.loss_mask: 0.8386  decode.d3.loss_dice: 0.5871  decode.d4.loss_cls: 0.1239  decode.d4.loss_mask: 0.8960  decode.d4.loss_dice: 0.6420  decode.d5.loss_cls: 0.1189  decode.d5.loss_mask: 0.8869  decode.d5.loss_dice: 0.6226  decode.d6.loss_cls: 0.1270  decode.d6.loss_mask: 0.8701  decode.d6.loss_dice: 0.6213  decode.d7.loss_cls: 0.1206  decode.d7.loss_mask: 0.8849  decode.d7.loss_dice: 0.6244  decode.d8.loss_cls: 0.1082  decode.d8.loss_mask: 0.8893  decode.d8.loss_dice: 0.6246
05/27 02:14:21 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 02:14:21 - mmengine - INFO - Iter(train) [129000/160000]  base_lr: 2.2831e-05 lr: 2.2831e-06  eta: 3:33:39  time: 0.4159  data_time: 0.0099  memory: 5976  grad_norm: 1008.5081  loss: 20.8825  decode.loss_cls: 0.2115  decode.loss_mask: 1.0396  decode.loss_dice: 0.7554  decode.d0.loss_cls: 0.7315  decode.d0.loss_mask: 1.0376  decode.d0.loss_dice: 0.7853  decode.d1.loss_cls: 0.2145  decode.d1.loss_mask: 1.0277  decode.d1.loss_dice: 0.7745  decode.d2.loss_cls: 0.1993  decode.d2.loss_mask: 1.0522  decode.d2.loss_dice: 0.8018  decode.d3.loss_cls: 0.2260  decode.d3.loss_mask: 1.0468  decode.d3.loss_dice: 0.7790  decode.d4.loss_cls: 0.2131  decode.d4.loss_mask: 1.0429  decode.d4.loss_dice: 0.7942  decode.d5.loss_cls: 0.2280  decode.d5.loss_mask: 1.0458  decode.d5.loss_dice: 0.7875  decode.d6.loss_cls: 0.2098  decode.d6.loss_mask: 1.0481  decode.d6.loss_dice: 0.7801  decode.d7.loss_cls: 0.2251  decode.d7.loss_mask: 1.0236  decode.d7.loss_dice: 0.7785  decode.d8.loss_cls: 0.2129  decode.d8.loss_mask: 1.0282  decode.d8.loss_dice: 0.7820
05/27 02:14:42 - mmengine - INFO - Iter(train) [129050/160000]  base_lr: 2.2798e-05 lr: 2.2798e-06  eta: 3:33:19  time: 0.4156  data_time: 0.0100  memory: 5997  grad_norm: 422.9003  loss: 17.1192  decode.loss_cls: 0.2147  decode.loss_mask: 0.8373  decode.loss_dice: 0.6267  decode.d0.loss_cls: 0.7395  decode.d0.loss_mask: 0.7826  decode.d0.loss_dice: 0.5716  decode.d1.loss_cls: 0.2173  decode.d1.loss_mask: 0.8198  decode.d1.loss_dice: 0.6286  decode.d2.loss_cls: 0.2070  decode.d2.loss_mask: 0.8233  decode.d2.loss_dice: 0.6180  decode.d3.loss_cls: 0.2090  decode.d3.loss_mask: 0.8267  decode.d3.loss_dice: 0.6293  decode.d4.loss_cls: 0.2067  decode.d4.loss_mask: 0.8338  decode.d4.loss_dice: 0.6325  decode.d5.loss_cls: 0.1946  decode.d5.loss_mask: 0.8288  decode.d5.loss_dice: 0.6297  decode.d6.loss_cls: 0.2081  decode.d6.loss_mask: 0.8431  decode.d6.loss_dice: 0.6215  decode.d7.loss_cls: 0.1821  decode.d7.loss_mask: 0.8410  decode.d7.loss_dice: 0.6426  decode.d8.loss_cls: 0.2346  decode.d8.loss_mask: 0.8348  decode.d8.loss_dice: 0.6338
05/27 02:15:03 - mmengine - INFO - Iter(train) [129100/160000]  base_lr: 2.2764e-05 lr: 2.2764e-06  eta: 3:32:58  time: 0.4175  data_time: 0.0100  memory: 5969  grad_norm: 314.1046  loss: 16.5130  decode.loss_cls: 0.0977  decode.loss_mask: 0.8630  decode.loss_dice: 0.6055  decode.d0.loss_cls: 0.6313  decode.d0.loss_mask: 0.8288  decode.d0.loss_dice: 0.5863  decode.d1.loss_cls: 0.0992  decode.d1.loss_mask: 0.8877  decode.d1.loss_dice: 0.6211  decode.d2.loss_cls: 0.1158  decode.d2.loss_mask: 0.8759  decode.d2.loss_dice: 0.6040  decode.d3.loss_cls: 0.0952  decode.d3.loss_mask: 0.9183  decode.d3.loss_dice: 0.6194  decode.d4.loss_cls: 0.0843  decode.d4.loss_mask: 0.9130  decode.d4.loss_dice: 0.6109  decode.d5.loss_cls: 0.1074  decode.d5.loss_mask: 0.8819  decode.d5.loss_dice: 0.6065  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.8895  decode.d6.loss_dice: 0.6354  decode.d7.loss_cls: 0.0604  decode.d7.loss_mask: 0.9399  decode.d7.loss_dice: 0.6473  decode.d8.loss_cls: 0.0963  decode.d8.loss_mask: 0.8771  decode.d8.loss_dice: 0.6164
05/27 02:15:24 - mmengine - INFO - Iter(train) [129150/160000]  base_lr: 2.2731e-05 lr: 2.2731e-06  eta: 3:32:38  time: 0.4171  data_time: 0.0101  memory: 5969  grad_norm: 440.8461  loss: 18.2946  decode.loss_cls: 0.0596  decode.loss_mask: 1.0380  decode.loss_dice: 0.6793  decode.d0.loss_cls: 0.6117  decode.d0.loss_mask: 0.9539  decode.d0.loss_dice: 0.6649  decode.d1.loss_cls: 0.0751  decode.d1.loss_mask: 1.0324  decode.d1.loss_dice: 0.6661  decode.d2.loss_cls: 0.0660  decode.d2.loss_mask: 1.0370  decode.d2.loss_dice: 0.6849  decode.d3.loss_cls: 0.0660  decode.d3.loss_mask: 1.0355  decode.d3.loss_dice: 0.6838  decode.d4.loss_cls: 0.0869  decode.d4.loss_mask: 1.0329  decode.d4.loss_dice: 0.6806  decode.d5.loss_cls: 0.0570  decode.d5.loss_mask: 1.0393  decode.d5.loss_dice: 0.6974  decode.d6.loss_cls: 0.0631  decode.d6.loss_mask: 1.0349  decode.d6.loss_dice: 0.6984  decode.d7.loss_cls: 0.0706  decode.d7.loss_mask: 1.0336  decode.d7.loss_dice: 0.6659  decode.d8.loss_cls: 0.0563  decode.d8.loss_mask: 1.0365  decode.d8.loss_dice: 0.6868
05/27 02:15:45 - mmengine - INFO - Iter(train) [129200/160000]  base_lr: 2.2698e-05 lr: 2.2698e-06  eta: 3:32:17  time: 0.4168  data_time: 0.0099  memory: 5980  grad_norm: 382.4518  loss: 15.4112  decode.loss_cls: 0.0864  decode.loss_mask: 0.8197  decode.loss_dice: 0.5748  decode.d0.loss_cls: 0.5666  decode.d0.loss_mask: 0.7894  decode.d0.loss_dice: 0.5579  decode.d1.loss_cls: 0.0872  decode.d1.loss_mask: 0.8413  decode.d1.loss_dice: 0.5856  decode.d2.loss_cls: 0.0835  decode.d2.loss_mask: 0.8540  decode.d2.loss_dice: 0.5911  decode.d3.loss_cls: 0.0822  decode.d3.loss_mask: 0.8238  decode.d3.loss_dice: 0.5840  decode.d4.loss_cls: 0.0825  decode.d4.loss_mask: 0.8286  decode.d4.loss_dice: 0.5811  decode.d5.loss_cls: 0.0708  decode.d5.loss_mask: 0.8471  decode.d5.loss_dice: 0.5730  decode.d6.loss_cls: 0.0797  decode.d6.loss_mask: 0.8392  decode.d6.loss_dice: 0.5899  decode.d7.loss_cls: 0.0821  decode.d7.loss_mask: 0.8465  decode.d7.loss_dice: 0.5728  decode.d8.loss_cls: 0.0812  decode.d8.loss_mask: 0.8332  decode.d8.loss_dice: 0.5756
05/27 02:16:05 - mmengine - INFO - Iter(train) [129250/160000]  base_lr: 2.2665e-05 lr: 2.2665e-06  eta: 3:31:56  time: 0.4168  data_time: 0.0099  memory: 5976  grad_norm: 816.6413  loss: 21.3579  decode.loss_cls: 0.1953  decode.loss_mask: 1.1404  decode.loss_dice: 0.7774  decode.d0.loss_cls: 0.6033  decode.d0.loss_mask: 1.1090  decode.d0.loss_dice: 0.7367  decode.d1.loss_cls: 0.2083  decode.d1.loss_mask: 1.1675  decode.d1.loss_dice: 0.7746  decode.d2.loss_cls: 0.2281  decode.d2.loss_mask: 1.1253  decode.d2.loss_dice: 0.7549  decode.d3.loss_cls: 0.2094  decode.d3.loss_mask: 1.1155  decode.d3.loss_dice: 0.7370  decode.d4.loss_cls: 0.2066  decode.d4.loss_mask: 1.1092  decode.d4.loss_dice: 0.7710  decode.d5.loss_cls: 0.2195  decode.d5.loss_mask: 1.1224  decode.d5.loss_dice: 0.7603  decode.d6.loss_cls: 0.1996  decode.d6.loss_mask: 1.1462  decode.d6.loss_dice: 0.7840  decode.d7.loss_cls: 0.1994  decode.d7.loss_mask: 1.1203  decode.d7.loss_dice: 0.7420  decode.d8.loss_cls: 0.1998  decode.d8.loss_mask: 1.1371  decode.d8.loss_dice: 0.7581
05/27 02:16:26 - mmengine - INFO - Iter(train) [129300/160000]  base_lr: 2.2632e-05 lr: 2.2632e-06  eta: 3:31:36  time: 0.4168  data_time: 0.0098  memory: 5968  grad_norm: 511.7845  loss: 20.1310  decode.loss_cls: 0.2249  decode.loss_mask: 1.0657  decode.loss_dice: 0.7187  decode.d0.loss_cls: 0.6298  decode.d0.loss_mask: 1.0719  decode.d0.loss_dice: 0.7160  decode.d1.loss_cls: 0.2502  decode.d1.loss_mask: 1.0391  decode.d1.loss_dice: 0.6918  decode.d2.loss_cls: 0.2358  decode.d2.loss_mask: 1.0542  decode.d2.loss_dice: 0.6903  decode.d3.loss_cls: 0.2214  decode.d3.loss_mask: 1.0300  decode.d3.loss_dice: 0.6957  decode.d4.loss_cls: 0.2193  decode.d4.loss_mask: 1.0368  decode.d4.loss_dice: 0.7053  decode.d5.loss_cls: 0.2184  decode.d5.loss_mask: 1.0416  decode.d5.loss_dice: 0.7021  decode.d6.loss_cls: 0.2263  decode.d6.loss_mask: 1.0296  decode.d6.loss_dice: 0.6955  decode.d7.loss_cls: 0.2102  decode.d7.loss_mask: 1.0396  decode.d7.loss_dice: 0.7088  decode.d8.loss_cls: 0.2284  decode.d8.loss_mask: 1.0310  decode.d8.loss_dice: 0.7025
05/27 02:16:47 - mmengine - INFO - Iter(train) [129350/160000]  base_lr: 2.2599e-05 lr: 2.2599e-06  eta: 3:31:15  time: 0.4178  data_time: 0.0100  memory: 5971  grad_norm: 403.2877  loss: 20.4557  decode.loss_cls: 0.1937  decode.loss_mask: 1.0563  decode.loss_dice: 0.7201  decode.d0.loss_cls: 0.7244  decode.d0.loss_mask: 1.0081  decode.d0.loss_dice: 0.7559  decode.d1.loss_cls: 0.2376  decode.d1.loss_mask: 1.0552  decode.d1.loss_dice: 0.7614  decode.d2.loss_cls: 0.1831  decode.d2.loss_mask: 1.0533  decode.d2.loss_dice: 0.7659  decode.d3.loss_cls: 0.1983  decode.d3.loss_mask: 1.0253  decode.d3.loss_dice: 0.7349  decode.d4.loss_cls: 0.1963  decode.d4.loss_mask: 1.0667  decode.d4.loss_dice: 0.7503  decode.d5.loss_cls: 0.2067  decode.d5.loss_mask: 1.0278  decode.d5.loss_dice: 0.7451  decode.d6.loss_cls: 0.1894  decode.d6.loss_mask: 1.0593  decode.d6.loss_dice: 0.7404  decode.d7.loss_cls: 0.2101  decode.d7.loss_mask: 1.0790  decode.d7.loss_dice: 0.7466  decode.d8.loss_cls: 0.2051  decode.d8.loss_mask: 1.0355  decode.d8.loss_dice: 0.7238
05/27 02:17:08 - mmengine - INFO - Iter(train) [129400/160000]  base_lr: 2.2565e-05 lr: 2.2565e-06  eta: 3:30:54  time: 0.4169  data_time: 0.0100  memory: 5969  grad_norm: 352.1653  loss: 18.3030  decode.loss_cls: 0.1299  decode.loss_mask: 0.9884  decode.loss_dice: 0.6959  decode.d0.loss_cls: 0.6189  decode.d0.loss_mask: 0.9595  decode.d0.loss_dice: 0.7003  decode.d1.loss_cls: 0.1285  decode.d1.loss_mask: 0.9565  decode.d1.loss_dice: 0.7028  decode.d2.loss_cls: 0.1090  decode.d2.loss_mask: 0.9678  decode.d2.loss_dice: 0.7045  decode.d3.loss_cls: 0.1236  decode.d3.loss_mask: 0.9417  decode.d3.loss_dice: 0.6704  decode.d4.loss_cls: 0.1147  decode.d4.loss_mask: 0.9809  decode.d4.loss_dice: 0.7113  decode.d5.loss_cls: 0.1046  decode.d5.loss_mask: 0.9714  decode.d5.loss_dice: 0.7038  decode.d6.loss_cls: 0.1353  decode.d6.loss_mask: 0.9557  decode.d6.loss_dice: 0.7027  decode.d7.loss_cls: 0.1083  decode.d7.loss_mask: 0.9636  decode.d7.loss_dice: 0.6988  decode.d8.loss_cls: 0.1016  decode.d8.loss_mask: 0.9614  decode.d8.loss_dice: 0.6912
05/27 02:17:29 - mmengine - INFO - Iter(train) [129450/160000]  base_lr: 2.2532e-05 lr: 2.2532e-06  eta: 3:30:34  time: 0.4174  data_time: 0.0099  memory: 5989  grad_norm: 520.8697  loss: 18.9893  decode.loss_cls: 0.1832  decode.loss_mask: 0.9216  decode.loss_dice: 0.7281  decode.d0.loss_cls: 0.6785  decode.d0.loss_mask: 0.9402  decode.d0.loss_dice: 0.7414  decode.d1.loss_cls: 0.1644  decode.d1.loss_mask: 0.9632  decode.d1.loss_dice: 0.7633  decode.d2.loss_cls: 0.1579  decode.d2.loss_mask: 0.9399  decode.d2.loss_dice: 0.7241  decode.d3.loss_cls: 0.1427  decode.d3.loss_mask: 0.9754  decode.d3.loss_dice: 0.7380  decode.d4.loss_cls: 0.1756  decode.d4.loss_mask: 0.9552  decode.d4.loss_dice: 0.7560  decode.d5.loss_cls: 0.1515  decode.d5.loss_mask: 0.9491  decode.d5.loss_dice: 0.7377  decode.d6.loss_cls: 0.1576  decode.d6.loss_mask: 0.9510  decode.d6.loss_dice: 0.7462  decode.d7.loss_cls: 0.1641  decode.d7.loss_mask: 0.9211  decode.d7.loss_dice: 0.7462  decode.d8.loss_cls: 0.1448  decode.d8.loss_mask: 0.9267  decode.d8.loss_dice: 0.7450
05/27 02:17:50 - mmengine - INFO - Iter(train) [129500/160000]  base_lr: 2.2499e-05 lr: 2.2499e-06  eta: 3:30:13  time: 0.4162  data_time: 0.0099  memory: 5973  grad_norm: 584.6886  loss: 21.6179  decode.loss_cls: 0.0813  decode.loss_mask: 1.2748  decode.loss_dice: 0.7570  decode.d0.loss_cls: 0.5900  decode.d0.loss_mask: 1.2277  decode.d0.loss_dice: 0.7739  decode.d1.loss_cls: 0.1030  decode.d1.loss_mask: 1.2613  decode.d1.loss_dice: 0.7596  decode.d2.loss_cls: 0.0959  decode.d2.loss_mask: 1.2598  decode.d2.loss_dice: 0.7660  decode.d3.loss_cls: 0.0729  decode.d3.loss_mask: 1.2798  decode.d3.loss_dice: 0.7558  decode.d4.loss_cls: 0.0890  decode.d4.loss_mask: 1.2522  decode.d4.loss_dice: 0.7462  decode.d5.loss_cls: 0.1073  decode.d5.loss_mask: 1.2593  decode.d5.loss_dice: 0.7546  decode.d6.loss_cls: 0.1256  decode.d6.loss_mask: 1.2380  decode.d6.loss_dice: 0.7498  decode.d7.loss_cls: 0.0920  decode.d7.loss_mask: 1.2751  decode.d7.loss_dice: 0.7584  decode.d8.loss_cls: 0.0869  decode.d8.loss_mask: 1.2675  decode.d8.loss_dice: 0.7571
05/27 02:18:11 - mmengine - INFO - Iter(train) [129550/160000]  base_lr: 2.2466e-05 lr: 2.2466e-06  eta: 3:29:52  time: 0.4170  data_time: 0.0100  memory: 5967  grad_norm: 684.0015  loss: 20.2491  decode.loss_cls: 0.1838  decode.loss_mask: 0.9735  decode.loss_dice: 0.7771  decode.d0.loss_cls: 0.6953  decode.d0.loss_mask: 0.9848  decode.d0.loss_dice: 0.8049  decode.d1.loss_cls: 0.1873  decode.d1.loss_mask: 1.0108  decode.d1.loss_dice: 0.8128  decode.d2.loss_cls: 0.1929  decode.d2.loss_mask: 0.9981  decode.d2.loss_dice: 0.7771  decode.d3.loss_cls: 0.1586  decode.d3.loss_mask: 1.0276  decode.d3.loss_dice: 0.8077  decode.d4.loss_cls: 0.1781  decode.d4.loss_mask: 1.0341  decode.d4.loss_dice: 0.8086  decode.d5.loss_cls: 0.1670  decode.d5.loss_mask: 1.0160  decode.d5.loss_dice: 0.8070  decode.d6.loss_cls: 0.2033  decode.d6.loss_mask: 0.9730  decode.d6.loss_dice: 0.7689  decode.d7.loss_cls: 0.1691  decode.d7.loss_mask: 0.9991  decode.d7.loss_dice: 0.8064  decode.d8.loss_cls: 0.1431  decode.d8.loss_mask: 0.9974  decode.d8.loss_dice: 0.7858
05/27 02:18:32 - mmengine - INFO - Iter(train) [129600/160000]  base_lr: 2.2433e-05 lr: 2.2433e-06  eta: 3:29:32  time: 0.4169  data_time: 0.0099  memory: 5973  grad_norm: 646.1020  loss: 18.7408  decode.loss_cls: 0.2252  decode.loss_mask: 0.9244  decode.loss_dice: 0.6584  decode.d0.loss_cls: 0.6805  decode.d0.loss_mask: 0.9099  decode.d0.loss_dice: 0.6552  decode.d1.loss_cls: 0.2221  decode.d1.loss_mask: 0.9371  decode.d1.loss_dice: 0.6734  decode.d2.loss_cls: 0.2270  decode.d2.loss_mask: 0.9238  decode.d2.loss_dice: 0.6698  decode.d3.loss_cls: 0.2053  decode.d3.loss_mask: 0.9358  decode.d3.loss_dice: 0.7182  decode.d4.loss_cls: 0.2439  decode.d4.loss_mask: 0.9229  decode.d4.loss_dice: 0.6646  decode.d5.loss_cls: 0.2244  decode.d5.loss_mask: 0.9601  decode.d5.loss_dice: 0.6810  decode.d6.loss_cls: 0.2602  decode.d6.loss_mask: 0.9460  decode.d6.loss_dice: 0.6735  decode.d7.loss_cls: 0.2213  decode.d7.loss_mask: 0.9249  decode.d7.loss_dice: 0.6682  decode.d8.loss_cls: 0.2248  decode.d8.loss_mask: 0.9184  decode.d8.loss_dice: 0.6406
05/27 02:18:52 - mmengine - INFO - Iter(train) [129650/160000]  base_lr: 2.2399e-05 lr: 2.2399e-06  eta: 3:29:11  time: 0.4168  data_time: 0.0099  memory: 5980  grad_norm: 468.5076  loss: 19.7805  decode.loss_cls: 0.1639  decode.loss_mask: 1.0167  decode.loss_dice: 0.7317  decode.d0.loss_cls: 0.6419  decode.d0.loss_mask: 1.0142  decode.d0.loss_dice: 0.7238  decode.d1.loss_cls: 0.2587  decode.d1.loss_mask: 0.9850  decode.d1.loss_dice: 0.6925  decode.d2.loss_cls: 0.1899  decode.d2.loss_mask: 0.9862  decode.d2.loss_dice: 0.7225  decode.d3.loss_cls: 0.1900  decode.d3.loss_mask: 1.0316  decode.d3.loss_dice: 0.7342  decode.d4.loss_cls: 0.1979  decode.d4.loss_mask: 0.9846  decode.d4.loss_dice: 0.7256  decode.d5.loss_cls: 0.1796  decode.d5.loss_mask: 1.0101  decode.d5.loss_dice: 0.7289  decode.d6.loss_cls: 0.1897  decode.d6.loss_mask: 1.0277  decode.d6.loss_dice: 0.7448  decode.d7.loss_cls: 0.2232  decode.d7.loss_mask: 1.0249  decode.d7.loss_dice: 0.7214  decode.d8.loss_cls: 0.2092  decode.d8.loss_mask: 1.0178  decode.d8.loss_dice: 0.7122
05/27 02:19:13 - mmengine - INFO - Iter(train) [129700/160000]  base_lr: 2.2366e-05 lr: 2.2366e-06  eta: 3:28:51  time: 0.4168  data_time: 0.0101  memory: 5971  grad_norm: 346.3739  loss: 16.9868  decode.loss_cls: 0.1989  decode.loss_mask: 0.8672  decode.loss_dice: 0.5537  decode.d0.loss_cls: 0.6706  decode.d0.loss_mask: 0.8545  decode.d0.loss_dice: 0.5694  decode.d1.loss_cls: 0.1830  decode.d1.loss_mask: 0.9332  decode.d1.loss_dice: 0.5833  decode.d2.loss_cls: 0.1732  decode.d2.loss_mask: 0.9194  decode.d2.loss_dice: 0.5837  decode.d3.loss_cls: 0.2047  decode.d3.loss_mask: 0.9096  decode.d3.loss_dice: 0.5780  decode.d4.loss_cls: 0.1546  decode.d4.loss_mask: 0.9163  decode.d4.loss_dice: 0.5659  decode.d5.loss_cls: 0.1923  decode.d5.loss_mask: 0.8659  decode.d5.loss_dice: 0.5509  decode.d6.loss_cls: 0.1998  decode.d6.loss_mask: 0.8786  decode.d6.loss_dice: 0.5709  decode.d7.loss_cls: 0.1766  decode.d7.loss_mask: 0.9166  decode.d7.loss_dice: 0.5781  decode.d8.loss_cls: 0.1616  decode.d8.loss_mask: 0.9072  decode.d8.loss_dice: 0.5694
05/27 02:19:34 - mmengine - INFO - Iter(train) [129750/160000]  base_lr: 2.2333e-05 lr: 2.2333e-06  eta: 3:28:30  time: 0.4172  data_time: 0.0100  memory: 5988  grad_norm: 396.3303  loss: 14.9650  decode.loss_cls: 0.0317  decode.loss_mask: 0.8247  decode.loss_dice: 0.5850  decode.d0.loss_cls: 0.5248  decode.d0.loss_mask: 0.7509  decode.d0.loss_dice: 0.5500  decode.d1.loss_cls: 0.0905  decode.d1.loss_mask: 0.8146  decode.d1.loss_dice: 0.5632  decode.d2.loss_cls: 0.0842  decode.d2.loss_mask: 0.8239  decode.d2.loss_dice: 0.5636  decode.d3.loss_cls: 0.0911  decode.d3.loss_mask: 0.8114  decode.d3.loss_dice: 0.5506  decode.d4.loss_cls: 0.1068  decode.d4.loss_mask: 0.8018  decode.d4.loss_dice: 0.5544  decode.d5.loss_cls: 0.1166  decode.d5.loss_mask: 0.8060  decode.d5.loss_dice: 0.5509  decode.d6.loss_cls: 0.0858  decode.d6.loss_mask: 0.8096  decode.d6.loss_dice: 0.5715  decode.d7.loss_cls: 0.0770  decode.d7.loss_mask: 0.8134  decode.d7.loss_dice: 0.5760  decode.d8.loss_cls: 0.0511  decode.d8.loss_mask: 0.8236  decode.d8.loss_dice: 0.5601
05/27 02:19:55 - mmengine - INFO - Iter(train) [129800/160000]  base_lr: 2.2300e-05 lr: 2.2300e-06  eta: 3:28:09  time: 0.4165  data_time: 0.0099  memory: 5986  grad_norm: 373.8989  loss: 17.8405  decode.loss_cls: 0.1384  decode.loss_mask: 0.9141  decode.loss_dice: 0.6606  decode.d0.loss_cls: 0.6307  decode.d0.loss_mask: 0.8889  decode.d0.loss_dice: 0.6538  decode.d1.loss_cls: 0.1617  decode.d1.loss_mask: 0.9160  decode.d1.loss_dice: 0.6658  decode.d2.loss_cls: 0.1592  decode.d2.loss_mask: 0.9355  decode.d2.loss_dice: 0.6749  decode.d3.loss_cls: 0.1225  decode.d3.loss_mask: 0.9212  decode.d3.loss_dice: 0.6836  decode.d4.loss_cls: 0.1276  decode.d4.loss_mask: 0.9357  decode.d4.loss_dice: 0.6873  decode.d5.loss_cls: 0.1445  decode.d5.loss_mask: 0.9109  decode.d5.loss_dice: 0.6671  decode.d6.loss_cls: 0.1553  decode.d6.loss_mask: 0.9222  decode.d6.loss_dice: 0.6775  decode.d7.loss_cls: 0.1266  decode.d7.loss_mask: 0.9340  decode.d7.loss_dice: 0.6784  decode.d8.loss_cls: 0.1410  decode.d8.loss_mask: 0.9277  decode.d8.loss_dice: 0.6780
05/27 02:20:16 - mmengine - INFO - Iter(train) [129850/160000]  base_lr: 2.2267e-05 lr: 2.2267e-06  eta: 3:27:49  time: 0.4171  data_time: 0.0100  memory: 5967  grad_norm: 857.1553  loss: 19.4689  decode.loss_cls: 0.1360  decode.loss_mask: 1.0426  decode.loss_dice: 0.7078  decode.d0.loss_cls: 0.6007  decode.d0.loss_mask: 1.0169  decode.d0.loss_dice: 0.6761  decode.d1.loss_cls: 0.1540  decode.d1.loss_mask: 1.0793  decode.d1.loss_dice: 0.6936  decode.d2.loss_cls: 0.1268  decode.d2.loss_mask: 1.0678  decode.d2.loss_dice: 0.7172  decode.d3.loss_cls: 0.1556  decode.d3.loss_mask: 1.0546  decode.d3.loss_dice: 0.7001  decode.d4.loss_cls: 0.1578  decode.d4.loss_mask: 1.0570  decode.d4.loss_dice: 0.6915  decode.d5.loss_cls: 0.1317  decode.d5.loss_mask: 1.0723  decode.d5.loss_dice: 0.7038  decode.d6.loss_cls: 0.1299  decode.d6.loss_mask: 1.0679  decode.d6.loss_dice: 0.7208  decode.d7.loss_cls: 0.1441  decode.d7.loss_mask: 1.0845  decode.d7.loss_dice: 0.7180  decode.d8.loss_cls: 0.1282  decode.d8.loss_mask: 1.0300  decode.d8.loss_dice: 0.7022
05/27 02:20:37 - mmengine - INFO - Iter(train) [129900/160000]  base_lr: 2.2233e-05 lr: 2.2233e-06  eta: 3:27:28  time: 0.4182  data_time: 0.0099  memory: 5976  grad_norm: 478.7870  loss: 17.9270  decode.loss_cls: 0.1171  decode.loss_mask: 0.9666  decode.loss_dice: 0.6486  decode.d0.loss_cls: 0.5473  decode.d0.loss_mask: 0.9795  decode.d0.loss_dice: 0.6416  decode.d1.loss_cls: 0.1990  decode.d1.loss_mask: 0.9745  decode.d1.loss_dice: 0.6274  decode.d2.loss_cls: 0.1391  decode.d2.loss_mask: 0.9399  decode.d2.loss_dice: 0.6442  decode.d3.loss_cls: 0.1692  decode.d3.loss_mask: 0.9640  decode.d3.loss_dice: 0.6363  decode.d4.loss_cls: 0.1560  decode.d4.loss_mask: 0.9465  decode.d4.loss_dice: 0.6265  decode.d5.loss_cls: 0.1183  decode.d5.loss_mask: 0.9803  decode.d5.loss_dice: 0.6514  decode.d6.loss_cls: 0.1460  decode.d6.loss_mask: 0.9754  decode.d6.loss_dice: 0.6528  decode.d7.loss_cls: 0.1463  decode.d7.loss_mask: 0.9759  decode.d7.loss_dice: 0.6577  decode.d8.loss_cls: 0.1333  decode.d8.loss_mask: 0.9378  decode.d8.loss_dice: 0.6286
05/27 02:20:58 - mmengine - INFO - Iter(train) [129950/160000]  base_lr: 2.2200e-05 lr: 2.2200e-06  eta: 3:27:07  time: 0.4170  data_time: 0.0101  memory: 5970  grad_norm: 414.9891  loss: 20.4782  decode.loss_cls: 0.1796  decode.loss_mask: 1.0734  decode.loss_dice: 0.7386  decode.d0.loss_cls: 0.6550  decode.d0.loss_mask: 1.0178  decode.d0.loss_dice: 0.6938  decode.d1.loss_cls: 0.1801  decode.d1.loss_mask: 1.0498  decode.d1.loss_dice: 0.7288  decode.d2.loss_cls: 0.1921  decode.d2.loss_mask: 1.0781  decode.d2.loss_dice: 0.7718  decode.d3.loss_cls: 0.2033  decode.d3.loss_mask: 1.0757  decode.d3.loss_dice: 0.7202  decode.d4.loss_cls: 0.2197  decode.d4.loss_mask: 1.0864  decode.d4.loss_dice: 0.7446  decode.d5.loss_cls: 0.1807  decode.d5.loss_mask: 1.0759  decode.d5.loss_dice: 0.7379  decode.d6.loss_cls: 0.1454  decode.d6.loss_mask: 1.1320  decode.d6.loss_dice: 0.7607  decode.d7.loss_cls: 0.1920  decode.d7.loss_mask: 1.0654  decode.d7.loss_dice: 0.7379  decode.d8.loss_cls: 0.2010  decode.d8.loss_mask: 1.0835  decode.d8.loss_dice: 0.7569
05/27 02:21:19 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 02:21:19 - mmengine - INFO - Iter(train) [130000/160000]  base_lr: 2.2167e-05 lr: 2.2167e-06  eta: 3:26:47  time: 0.4165  data_time: 0.0101  memory: 5966  grad_norm: 789.7992  loss: 19.4178  decode.loss_cls: 0.1868  decode.loss_mask: 1.0325  decode.loss_dice: 0.7038  decode.d0.loss_cls: 0.7233  decode.d0.loss_mask: 0.9419  decode.d0.loss_dice: 0.6890  decode.d1.loss_cls: 0.2445  decode.d1.loss_mask: 1.0190  decode.d1.loss_dice: 0.7064  decode.d2.loss_cls: 0.1469  decode.d2.loss_mask: 1.0231  decode.d2.loss_dice: 0.7189  decode.d3.loss_cls: 0.1820  decode.d3.loss_mask: 1.0139  decode.d3.loss_dice: 0.7097  decode.d4.loss_cls: 0.1660  decode.d4.loss_mask: 1.0312  decode.d4.loss_dice: 0.7175  decode.d5.loss_cls: 0.1420  decode.d5.loss_mask: 1.0085  decode.d5.loss_dice: 0.7068  decode.d6.loss_cls: 0.2025  decode.d6.loss_mask: 1.0263  decode.d6.loss_dice: 0.6902  decode.d7.loss_cls: 0.1685  decode.d7.loss_mask: 0.9890  decode.d7.loss_dice: 0.6852  decode.d8.loss_cls: 0.1277  decode.d8.loss_mask: 1.0184  decode.d8.loss_dice: 0.6962
05/27 02:21:19 - mmengine - INFO - Saving checkpoint at 130000 iterations
05/27 02:21:23 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:07  time: 0.0477  data_time: 0.0012  memory: 1391  
05/27 02:21:25 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:04  time: 0.0473  data_time: 0.0012  memory: 1205  
05/27 02:21:28 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:02  time: 0.0502  data_time: 0.0012  memory: 1596  
05/27 02:21:30 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0484  data_time: 0.0012  memory: 1298  
05/27 02:21:33 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:57  time: 0.0477  data_time: 0.0012  memory: 1298  
05/27 02:21:35 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0475  data_time: 0.0012  memory: 1279  
05/27 02:21:37 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:52  time: 0.0478  data_time: 0.0012  memory: 1224  
05/27 02:21:40 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0487  data_time: 0.0012  memory: 1298  
05/27 02:21:42 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:47  time: 0.0471  data_time: 0.0012  memory: 1298  
05/27 02:21:45 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0511  data_time: 0.0013  memory: 1725  
05/27 02:21:47 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0487  data_time: 0.0012  memory: 1336  
05/27 02:21:49 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0479  data_time: 0.0012  memory: 1298  
05/27 02:21:52 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0481  data_time: 0.0012  memory: 1205  
05/27 02:21:54 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:35  time: 0.0489  data_time: 0.0012  memory: 1316  
05/27 02:21:57 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0475  data_time: 0.0012  memory: 1279  
05/27 02:21:59 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0511  data_time: 0.0012  memory: 1410  
05/27 02:22:01 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0477  data_time: 0.0012  memory: 1279  
05/27 02:22:04 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0483  data_time: 0.0012  memory: 1205  
05/27 02:22:06 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:23  time: 0.0482  data_time: 0.0012  memory: 1205  
05/27 02:22:09 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0476  data_time: 0.0012  memory: 1336  
05/27 02:22:11 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0474  data_time: 0.0012  memory: 1246  
05/27 02:22:13 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0497  data_time: 0.0012  memory: 1503  
05/27 02:22:16 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0476  data_time: 0.0013  memory: 1261  
05/27 02:22:18 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0484  data_time: 0.0012  memory: 1298  
05/27 02:22:21 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0476  data_time: 0.0012  memory: 1447  
05/27 02:22:23 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0474  data_time: 0.0012  memory: 1298  
05/27 02:22:26 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0490  data_time: 0.0012  memory: 1279  
05/27 02:22:28 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0477  data_time: 0.0012  memory: 1205  
05/27 02:22:30 - mmengine - INFO - per class results:
05/27 02:22:30 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.54 | 97.62 |
|  aeroplane  | 93.45 | 98.37 |
|   bicycle   | 44.47 | 92.29 |
|     bird    | 96.04 | 98.19 |
|     boat    | 68.95 |  91.4 |
|    bottle   | 84.85 | 94.57 |
|     bus     | 95.91 | 97.94 |
|     car     |  91.5 | 95.37 |
|     cat     | 94.91 | 97.47 |
|    chair    | 49.28 |  69.6 |
|     cow     | 90.95 | 95.85 |
| diningtable | 59.66 | 62.14 |
|     dog     | 92.06 | 98.41 |
|    horse    | 89.46 | 97.05 |
|  motorbike  | 88.62 | 94.01 |
|    person   | 90.93 |  95.0 |
| pottedplant | 73.17 | 89.42 |
|    sheep    | 88.35 | 92.46 |
|     sofa    | 56.33 | 65.36 |
|    train    | 90.95 | 96.51 |
|  tvmonitor  | 85.23 | 88.54 |
+-------------+-------+-------+
05/27 02:22:30 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 96.0500  mIoU: 81.9300  mAcc: 90.8400  data_time: 0.0013  time: 0.0479
05/27 02:22:30 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_125000.pth is removed
05/27 02:22:32 - mmengine - INFO - The best checkpoint with 81.9300 mIoU at 130000 iter is saved to best_mIoU_iter_130000.pth.
05/27 02:22:55 - mmengine - INFO - Iter(train) [130050/160000]  base_lr: 2.2134e-05 lr: 2.2134e-06  eta: 3:26:27  time: 0.4170  data_time: 0.0099  memory: 5969  grad_norm: 767.8965  loss: 19.8989  decode.loss_cls: 0.1546  decode.loss_mask: 1.1227  decode.loss_dice: 0.6883  decode.d0.loss_cls: 0.5678  decode.d0.loss_mask: 1.0450  decode.d0.loss_dice: 0.7187  decode.d1.loss_cls: 0.1029  decode.d1.loss_mask: 1.1192  decode.d1.loss_dice: 0.7171  decode.d2.loss_cls: 0.1136  decode.d2.loss_mask: 1.0603  decode.d2.loss_dice: 0.7193  decode.d3.loss_cls: 0.1091  decode.d3.loss_mask: 1.1166  decode.d3.loss_dice: 0.7381  decode.d4.loss_cls: 0.1612  decode.d4.loss_mask: 1.0740  decode.d4.loss_dice: 0.7137  decode.d5.loss_cls: 0.1295  decode.d5.loss_mask: 1.0978  decode.d5.loss_dice: 0.7350  decode.d6.loss_cls: 0.1276  decode.d6.loss_mask: 1.1231  decode.d6.loss_dice: 0.7449  decode.d7.loss_cls: 0.0934  decode.d7.loss_mask: 1.1095  decode.d7.loss_dice: 0.7347  decode.d8.loss_cls: 0.1175  decode.d8.loss_mask: 1.1209  decode.d8.loss_dice: 0.7225
05/27 02:23:15 - mmengine - INFO - Iter(train) [130100/160000]  base_lr: 2.2100e-05 lr: 2.2100e-06  eta: 3:26:06  time: 0.4179  data_time: 0.0100  memory: 5976  grad_norm: 877.6719  loss: 19.7771  decode.loss_cls: 0.1230  decode.loss_mask: 1.1100  decode.loss_dice: 0.7016  decode.d0.loss_cls: 0.5898  decode.d0.loss_mask: 1.0810  decode.d0.loss_dice: 0.7158  decode.d1.loss_cls: 0.1032  decode.d1.loss_mask: 1.1121  decode.d1.loss_dice: 0.7197  decode.d2.loss_cls: 0.1276  decode.d2.loss_mask: 1.1084  decode.d2.loss_dice: 0.6790  decode.d3.loss_cls: 0.1367  decode.d3.loss_mask: 1.1212  decode.d3.loss_dice: 0.6983  decode.d4.loss_cls: 0.1371  decode.d4.loss_mask: 1.1044  decode.d4.loss_dice: 0.7140  decode.d5.loss_cls: 0.1446  decode.d5.loss_mask: 1.1110  decode.d5.loss_dice: 0.6923  decode.d6.loss_cls: 0.1353  decode.d6.loss_mask: 1.1076  decode.d6.loss_dice: 0.6885  decode.d7.loss_cls: 0.1387  decode.d7.loss_mask: 1.0964  decode.d7.loss_dice: 0.6819  decode.d8.loss_cls: 0.1205  decode.d8.loss_mask: 1.0952  decode.d8.loss_dice: 0.6822
05/27 02:23:36 - mmengine - INFO - Iter(train) [130150/160000]  base_lr: 2.2067e-05 lr: 2.2067e-06  eta: 3:25:46  time: 0.4177  data_time: 0.0099  memory: 5985  grad_norm: 328.5986  loss: 15.1608  decode.loss_cls: 0.0733  decode.loss_mask: 0.8033  decode.loss_dice: 0.5718  decode.d0.loss_cls: 0.6030  decode.d0.loss_mask: 0.8067  decode.d0.loss_dice: 0.5892  decode.d1.loss_cls: 0.0677  decode.d1.loss_mask: 0.8032  decode.d1.loss_dice: 0.5880  decode.d2.loss_cls: 0.0733  decode.d2.loss_mask: 0.8104  decode.d2.loss_dice: 0.5896  decode.d3.loss_cls: 0.0811  decode.d3.loss_mask: 0.8069  decode.d3.loss_dice: 0.5833  decode.d4.loss_cls: 0.0680  decode.d4.loss_mask: 0.8085  decode.d4.loss_dice: 0.5829  decode.d5.loss_cls: 0.0686  decode.d5.loss_mask: 0.8089  decode.d5.loss_dice: 0.5797  decode.d6.loss_cls: 0.0754  decode.d6.loss_mask: 0.8085  decode.d6.loss_dice: 0.5836  decode.d7.loss_cls: 0.0813  decode.d7.loss_mask: 0.8104  decode.d7.loss_dice: 0.5806  decode.d8.loss_cls: 0.0754  decode.d8.loss_mask: 0.7956  decode.d8.loss_dice: 0.5827
05/27 02:23:57 - mmengine - INFO - Iter(train) [130200/160000]  base_lr: 2.2034e-05 lr: 2.2034e-06  eta: 3:25:25  time: 0.4174  data_time: 0.0100  memory: 5975  grad_norm: 706.4295  loss: 17.7320  decode.loss_cls: 0.1473  decode.loss_mask: 0.9188  decode.loss_dice: 0.6591  decode.d0.loss_cls: 0.6773  decode.d0.loss_mask: 0.8481  decode.d0.loss_dice: 0.6617  decode.d1.loss_cls: 0.1511  decode.d1.loss_mask: 0.9256  decode.d1.loss_dice: 0.6854  decode.d2.loss_cls: 0.1633  decode.d2.loss_mask: 0.9145  decode.d2.loss_dice: 0.6603  decode.d3.loss_cls: 0.1296  decode.d3.loss_mask: 0.9310  decode.d3.loss_dice: 0.6743  decode.d4.loss_cls: 0.1678  decode.d4.loss_mask: 0.8834  decode.d4.loss_dice: 0.6707  decode.d5.loss_cls: 0.1581  decode.d5.loss_mask: 0.8879  decode.d5.loss_dice: 0.6677  decode.d6.loss_cls: 0.1563  decode.d6.loss_mask: 0.8894  decode.d6.loss_dice: 0.6652  decode.d7.loss_cls: 0.1396  decode.d7.loss_mask: 0.9053  decode.d7.loss_dice: 0.6631  decode.d8.loss_cls: 0.1425  decode.d8.loss_mask: 0.9136  decode.d8.loss_dice: 0.6739
05/27 02:24:18 - mmengine - INFO - Iter(train) [130250/160000]  base_lr: 2.2001e-05 lr: 2.2001e-06  eta: 3:25:04  time: 0.4171  data_time: 0.0100  memory: 5979  grad_norm: 647.1798  loss: 19.6865  decode.loss_cls: 0.1526  decode.loss_mask: 1.0571  decode.loss_dice: 0.7074  decode.d0.loss_cls: 0.6564  decode.d0.loss_mask: 1.0034  decode.d0.loss_dice: 0.6974  decode.d1.loss_cls: 0.1675  decode.d1.loss_mask: 1.0615  decode.d1.loss_dice: 0.7012  decode.d2.loss_cls: 0.1154  decode.d2.loss_mask: 1.0737  decode.d2.loss_dice: 0.6994  decode.d3.loss_cls: 0.1591  decode.d3.loss_mask: 1.0585  decode.d3.loss_dice: 0.7026  decode.d4.loss_cls: 0.1455  decode.d4.loss_mask: 1.0838  decode.d4.loss_dice: 0.7056  decode.d5.loss_cls: 0.1499  decode.d5.loss_mask: 1.0625  decode.d5.loss_dice: 0.7224  decode.d6.loss_cls: 0.1550  decode.d6.loss_mask: 1.0867  decode.d6.loss_dice: 0.7226  decode.d7.loss_cls: 0.1431  decode.d7.loss_mask: 1.0738  decode.d7.loss_dice: 0.7138  decode.d8.loss_cls: 0.1632  decode.d8.loss_mask: 1.0492  decode.d8.loss_dice: 0.6961
05/27 02:24:39 - mmengine - INFO - Iter(train) [130300/160000]  base_lr: 2.1967e-05 lr: 2.1967e-06  eta: 3:24:44  time: 0.4176  data_time: 0.0099  memory: 5976  grad_norm: 542.2440  loss: 16.4833  decode.loss_cls: 0.1268  decode.loss_mask: 0.8266  decode.loss_dice: 0.6288  decode.d0.loss_cls: 0.6161  decode.d0.loss_mask: 0.8299  decode.d0.loss_dice: 0.6133  decode.d1.loss_cls: 0.1329  decode.d1.loss_mask: 0.8617  decode.d1.loss_dice: 0.6374  decode.d2.loss_cls: 0.1453  decode.d2.loss_mask: 0.8354  decode.d2.loss_dice: 0.6197  decode.d3.loss_cls: 0.1015  decode.d3.loss_mask: 0.8462  decode.d3.loss_dice: 0.6574  decode.d4.loss_cls: 0.1371  decode.d4.loss_mask: 0.8393  decode.d4.loss_dice: 0.6256  decode.d5.loss_cls: 0.1297  decode.d5.loss_mask: 0.8311  decode.d5.loss_dice: 0.6341  decode.d6.loss_cls: 0.1069  decode.d6.loss_mask: 0.8492  decode.d6.loss_dice: 0.6505  decode.d7.loss_cls: 0.1567  decode.d7.loss_mask: 0.8167  decode.d7.loss_dice: 0.6091  decode.d8.loss_cls: 0.1409  decode.d8.loss_mask: 0.8473  decode.d8.loss_dice: 0.6302
05/27 02:25:00 - mmengine - INFO - Iter(train) [130350/160000]  base_lr: 2.1934e-05 lr: 2.1934e-06  eta: 3:24:23  time: 0.4179  data_time: 0.0100  memory: 5969  grad_norm: 526.5066  loss: 16.6271  decode.loss_cls: 0.0801  decode.loss_mask: 0.9005  decode.loss_dice: 0.6464  decode.d0.loss_cls: 0.6532  decode.d0.loss_mask: 0.8050  decode.d0.loss_dice: 0.6006  decode.d1.loss_cls: 0.0747  decode.d1.loss_mask: 0.8865  decode.d1.loss_dice: 0.6465  decode.d2.loss_cls: 0.0925  decode.d2.loss_mask: 0.8871  decode.d2.loss_dice: 0.6401  decode.d3.loss_cls: 0.0897  decode.d3.loss_mask: 0.8890  decode.d3.loss_dice: 0.6289  decode.d4.loss_cls: 0.0888  decode.d4.loss_mask: 0.8949  decode.d4.loss_dice: 0.6405  decode.d5.loss_cls: 0.0956  decode.d5.loss_mask: 0.8843  decode.d5.loss_dice: 0.6303  decode.d6.loss_cls: 0.0925  decode.d6.loss_mask: 0.8902  decode.d6.loss_dice: 0.6347  decode.d7.loss_cls: 0.0947  decode.d7.loss_mask: 0.8922  decode.d7.loss_dice: 0.6306  decode.d8.loss_cls: 0.0945  decode.d8.loss_mask: 0.8982  decode.d8.loss_dice: 0.6443
05/27 02:25:21 - mmengine - INFO - Iter(train) [130400/160000]  base_lr: 2.1901e-05 lr: 2.1901e-06  eta: 3:24:02  time: 0.4172  data_time: 0.0098  memory: 5976  grad_norm: 497.1331  loss: 20.2250  decode.loss_cls: 0.2134  decode.loss_mask: 1.0217  decode.loss_dice: 0.7136  decode.d0.loss_cls: 0.6601  decode.d0.loss_mask: 1.0310  decode.d0.loss_dice: 0.7424  decode.d1.loss_cls: 0.2141  decode.d1.loss_mask: 1.0357  decode.d1.loss_dice: 0.7197  decode.d2.loss_cls: 0.2291  decode.d2.loss_mask: 1.0598  decode.d2.loss_dice: 0.7263  decode.d3.loss_cls: 0.2282  decode.d3.loss_mask: 1.0416  decode.d3.loss_dice: 0.6986  decode.d4.loss_cls: 0.2404  decode.d4.loss_mask: 1.0543  decode.d4.loss_dice: 0.7262  decode.d5.loss_cls: 0.2264  decode.d5.loss_mask: 1.0563  decode.d5.loss_dice: 0.7263  decode.d6.loss_cls: 0.2212  decode.d6.loss_mask: 1.0267  decode.d6.loss_dice: 0.7065  decode.d7.loss_cls: 0.2125  decode.d7.loss_mask: 1.0350  decode.d7.loss_dice: 0.7371  decode.d8.loss_cls: 0.2235  decode.d8.loss_mask: 1.0060  decode.d8.loss_dice: 0.6913
05/27 02:25:42 - mmengine - INFO - Iter(train) [130450/160000]  base_lr: 2.1867e-05 lr: 2.1867e-06  eta: 3:23:42  time: 0.4179  data_time: 0.0100  memory: 5982  grad_norm: 650.4828  loss: 21.9766  decode.loss_cls: 0.1604  decode.loss_mask: 1.1456  decode.loss_dice: 0.8036  decode.d0.loss_cls: 0.6771  decode.d0.loss_mask: 1.1390  decode.d0.loss_dice: 0.8204  decode.d1.loss_cls: 0.1705  decode.d1.loss_mask: 1.1464  decode.d1.loss_dice: 0.8106  decode.d2.loss_cls: 0.1618  decode.d2.loss_mask: 1.1824  decode.d2.loss_dice: 0.8050  decode.d3.loss_cls: 0.1711  decode.d3.loss_mask: 1.2081  decode.d3.loss_dice: 0.8493  decode.d4.loss_cls: 0.1814  decode.d4.loss_mask: 1.1684  decode.d4.loss_dice: 0.8299  decode.d5.loss_cls: 0.1745  decode.d5.loss_mask: 1.1319  decode.d5.loss_dice: 0.7959  decode.d6.loss_cls: 0.1713  decode.d6.loss_mask: 1.1577  decode.d6.loss_dice: 0.8214  decode.d7.loss_cls: 0.1763  decode.d7.loss_mask: 1.1491  decode.d7.loss_dice: 0.8159  decode.d8.loss_cls: 0.1928  decode.d8.loss_mask: 1.1520  decode.d8.loss_dice: 0.8067
05/27 02:26:03 - mmengine - INFO - Iter(train) [130500/160000]  base_lr: 2.1834e-05 lr: 2.1834e-06  eta: 3:23:21  time: 0.4177  data_time: 0.0100  memory: 5982  grad_norm: 339.0228  loss: 15.5099  decode.loss_cls: 0.0745  decode.loss_mask: 0.8896  decode.loss_dice: 0.5545  decode.d0.loss_cls: 0.5075  decode.d0.loss_mask: 0.8438  decode.d0.loss_dice: 0.5338  decode.d1.loss_cls: 0.1210  decode.d1.loss_mask: 0.8745  decode.d1.loss_dice: 0.5277  decode.d2.loss_cls: 0.0641  decode.d2.loss_mask: 0.8781  decode.d2.loss_dice: 0.5490  decode.d3.loss_cls: 0.0767  decode.d3.loss_mask: 0.8888  decode.d3.loss_dice: 0.5386  decode.d4.loss_cls: 0.0772  decode.d4.loss_mask: 0.8861  decode.d4.loss_dice: 0.5481  decode.d5.loss_cls: 0.0872  decode.d5.loss_mask: 0.8787  decode.d5.loss_dice: 0.5323  decode.d6.loss_cls: 0.0683  decode.d6.loss_mask: 0.8879  decode.d6.loss_dice: 0.5625  decode.d7.loss_cls: 0.0852  decode.d7.loss_mask: 0.8830  decode.d7.loss_dice: 0.5569  decode.d8.loss_cls: 0.0841  decode.d8.loss_mask: 0.8870  decode.d8.loss_dice: 0.5633
05/27 02:26:23 - mmengine - INFO - Iter(train) [130550/160000]  base_lr: 2.1801e-05 lr: 2.1801e-06  eta: 3:23:00  time: 0.4174  data_time: 0.0100  memory: 5988  grad_norm: 323.8081  loss: 16.1308  decode.loss_cls: 0.1196  decode.loss_mask: 0.8278  decode.loss_dice: 0.5619  decode.d0.loss_cls: 0.6246  decode.d0.loss_mask: 0.8455  decode.d0.loss_dice: 0.6129  decode.d1.loss_cls: 0.1503  decode.d1.loss_mask: 0.8500  decode.d1.loss_dice: 0.6035  decode.d2.loss_cls: 0.1548  decode.d2.loss_mask: 0.8583  decode.d2.loss_dice: 0.5911  decode.d3.loss_cls: 0.1182  decode.d3.loss_mask: 0.8673  decode.d3.loss_dice: 0.5937  decode.d4.loss_cls: 0.1282  decode.d4.loss_mask: 0.8351  decode.d4.loss_dice: 0.5815  decode.d5.loss_cls: 0.1202  decode.d5.loss_mask: 0.8530  decode.d5.loss_dice: 0.5923  decode.d6.loss_cls: 0.1381  decode.d6.loss_mask: 0.8552  decode.d6.loss_dice: 0.5741  decode.d7.loss_cls: 0.1252  decode.d7.loss_mask: 0.8365  decode.d7.loss_dice: 0.5812  decode.d8.loss_cls: 0.1142  decode.d8.loss_mask: 0.8476  decode.d8.loss_dice: 0.5692
05/27 02:26:44 - mmengine - INFO - Iter(train) [130600/160000]  base_lr: 2.1767e-05 lr: 2.1767e-06  eta: 3:22:40  time: 0.4169  data_time: 0.0100  memory: 5968  grad_norm: 456.8268  loss: 16.2952  decode.loss_cls: 0.1221  decode.loss_mask: 0.8068  decode.loss_dice: 0.6121  decode.d0.loss_cls: 0.4928  decode.d0.loss_mask: 0.8329  decode.d0.loss_dice: 0.6149  decode.d1.loss_cls: 0.1174  decode.d1.loss_mask: 0.8577  decode.d1.loss_dice: 0.6144  decode.d2.loss_cls: 0.1029  decode.d2.loss_mask: 0.8615  decode.d2.loss_dice: 0.6349  decode.d3.loss_cls: 0.1172  decode.d3.loss_mask: 0.8532  decode.d3.loss_dice: 0.6147  decode.d4.loss_cls: 0.0838  decode.d4.loss_mask: 0.8611  decode.d4.loss_dice: 0.6446  decode.d5.loss_cls: 0.1354  decode.d5.loss_mask: 0.8686  decode.d5.loss_dice: 0.6323  decode.d6.loss_cls: 0.1036  decode.d6.loss_mask: 0.8633  decode.d6.loss_dice: 0.6444  decode.d7.loss_cls: 0.1053  decode.d7.loss_mask: 0.8627  decode.d7.loss_dice: 0.6395  decode.d8.loss_cls: 0.1296  decode.d8.loss_mask: 0.8435  decode.d8.loss_dice: 0.6219
05/27 02:27:05 - mmengine - INFO - Iter(train) [130650/160000]  base_lr: 2.1734e-05 lr: 2.1734e-06  eta: 3:22:19  time: 0.4171  data_time: 0.0100  memory: 5966  grad_norm: 408.1398  loss: 19.3101  decode.loss_cls: 0.1236  decode.loss_mask: 1.0362  decode.loss_dice: 0.7543  decode.d0.loss_cls: 0.6050  decode.d0.loss_mask: 0.9893  decode.d0.loss_dice: 0.7171  decode.d1.loss_cls: 0.1319  decode.d1.loss_mask: 1.0203  decode.d1.loss_dice: 0.7330  decode.d2.loss_cls: 0.1073  decode.d2.loss_mask: 1.0195  decode.d2.loss_dice: 0.7484  decode.d3.loss_cls: 0.1438  decode.d3.loss_mask: 1.0162  decode.d3.loss_dice: 0.7459  decode.d4.loss_cls: 0.1115  decode.d4.loss_mask: 1.0262  decode.d4.loss_dice: 0.7456  decode.d5.loss_cls: 0.1327  decode.d5.loss_mask: 1.0117  decode.d5.loss_dice: 0.7409  decode.d6.loss_cls: 0.1367  decode.d6.loss_mask: 1.0108  decode.d6.loss_dice: 0.7495  decode.d7.loss_cls: 0.1205  decode.d7.loss_mask: 1.0236  decode.d7.loss_dice: 0.7478  decode.d8.loss_cls: 0.0997  decode.d8.loss_mask: 1.0266  decode.d8.loss_dice: 0.7347
05/27 02:27:26 - mmengine - INFO - Iter(train) [130700/160000]  base_lr: 2.1701e-05 lr: 2.1701e-06  eta: 3:21:59  time: 0.4172  data_time: 0.0101  memory: 5983  grad_norm: 275.8470  loss: 13.6513  decode.loss_cls: 0.0664  decode.loss_mask: 0.7517  decode.loss_dice: 0.4945  decode.d0.loss_cls: 0.4889  decode.d0.loss_mask: 0.7587  decode.d0.loss_dice: 0.4961  decode.d1.loss_cls: 0.0669  decode.d1.loss_mask: 0.7778  decode.d1.loss_dice: 0.5330  decode.d2.loss_cls: 0.0670  decode.d2.loss_mask: 0.7460  decode.d2.loss_dice: 0.4961  decode.d3.loss_cls: 0.0572  decode.d3.loss_mask: 0.7517  decode.d3.loss_dice: 0.5015  decode.d4.loss_cls: 0.0628  decode.d4.loss_mask: 0.7598  decode.d4.loss_dice: 0.5116  decode.d5.loss_cls: 0.0548  decode.d5.loss_mask: 0.7518  decode.d5.loss_dice: 0.4984  decode.d6.loss_cls: 0.0547  decode.d6.loss_mask: 0.7550  decode.d6.loss_dice: 0.4955  decode.d7.loss_cls: 0.0580  decode.d7.loss_mask: 0.7593  decode.d7.loss_dice: 0.5195  decode.d8.loss_cls: 0.0669  decode.d8.loss_mask: 0.7517  decode.d8.loss_dice: 0.4983
05/27 02:27:47 - mmengine - INFO - Iter(train) [130750/160000]  base_lr: 2.1667e-05 lr: 2.1667e-06  eta: 3:21:38  time: 0.4172  data_time: 0.0100  memory: 5996  grad_norm: 551.8190  loss: 16.5021  decode.loss_cls: 0.1029  decode.loss_mask: 0.8777  decode.loss_dice: 0.6374  decode.d0.loss_cls: 0.5361  decode.d0.loss_mask: 0.8752  decode.d0.loss_dice: 0.6086  decode.d1.loss_cls: 0.1112  decode.d1.loss_mask: 0.8902  decode.d1.loss_dice: 0.6252  decode.d2.loss_cls: 0.0989  decode.d2.loss_mask: 0.8701  decode.d2.loss_dice: 0.6227  decode.d3.loss_cls: 0.1140  decode.d3.loss_mask: 0.8749  decode.d3.loss_dice: 0.6176  decode.d4.loss_cls: 0.0821  decode.d4.loss_mask: 0.8952  decode.d4.loss_dice: 0.6421  decode.d5.loss_cls: 0.0719  decode.d5.loss_mask: 0.8865  decode.d5.loss_dice: 0.6360  decode.d6.loss_cls: 0.1034  decode.d6.loss_mask: 0.8901  decode.d6.loss_dice: 0.6265  decode.d7.loss_cls: 0.0900  decode.d7.loss_mask: 0.8788  decode.d7.loss_dice: 0.6231  decode.d8.loss_cls: 0.0901  decode.d8.loss_mask: 0.8808  decode.d8.loss_dice: 0.6427
05/27 02:28:08 - mmengine - INFO - Iter(train) [130800/160000]  base_lr: 2.1634e-05 lr: 2.1634e-06  eta: 3:21:17  time: 0.4178  data_time: 0.0099  memory: 5983  grad_norm: 600.2617  loss: 16.3321  decode.loss_cls: 0.0574  decode.loss_mask: 0.8969  decode.loss_dice: 0.6145  decode.d0.loss_cls: 0.5679  decode.d0.loss_mask: 0.9026  decode.d0.loss_dice: 0.5905  decode.d1.loss_cls: 0.0648  decode.d1.loss_mask: 0.9218  decode.d1.loss_dice: 0.6371  decode.d2.loss_cls: 0.0654  decode.d2.loss_mask: 0.9036  decode.d2.loss_dice: 0.6057  decode.d3.loss_cls: 0.0607  decode.d3.loss_mask: 0.9020  decode.d3.loss_dice: 0.6035  decode.d4.loss_cls: 0.0649  decode.d4.loss_mask: 0.9106  decode.d4.loss_dice: 0.6120  decode.d5.loss_cls: 0.0727  decode.d5.loss_mask: 0.9105  decode.d5.loss_dice: 0.6079  decode.d6.loss_cls: 0.0653  decode.d6.loss_mask: 0.9199  decode.d6.loss_dice: 0.6211  decode.d7.loss_cls: 0.0683  decode.d7.loss_mask: 0.8981  decode.d7.loss_dice: 0.6143  decode.d8.loss_cls: 0.0581  decode.d8.loss_mask: 0.9012  decode.d8.loss_dice: 0.6130
05/27 02:28:29 - mmengine - INFO - Iter(train) [130850/160000]  base_lr: 2.1601e-05 lr: 2.1601e-06  eta: 3:20:57  time: 0.4184  data_time: 0.0099  memory: 5966  grad_norm: 837.6224  loss: 21.2129  decode.loss_cls: 0.1803  decode.loss_mask: 1.1290  decode.loss_dice: 0.7503  decode.d0.loss_cls: 0.7857  decode.d0.loss_mask: 1.0364  decode.d0.loss_dice: 0.7507  decode.d1.loss_cls: 0.2170  decode.d1.loss_mask: 1.1374  decode.d1.loss_dice: 0.7734  decode.d2.loss_cls: 0.2167  decode.d2.loss_mask: 1.0996  decode.d2.loss_dice: 0.7386  decode.d3.loss_cls: 0.1960  decode.d3.loss_mask: 1.0925  decode.d3.loss_dice: 0.7218  decode.d4.loss_cls: 0.2154  decode.d4.loss_mask: 1.0921  decode.d4.loss_dice: 0.7209  decode.d5.loss_cls: 0.1615  decode.d5.loss_mask: 1.1580  decode.d5.loss_dice: 0.7685  decode.d6.loss_cls: 0.2039  decode.d6.loss_mask: 1.1283  decode.d6.loss_dice: 0.7696  decode.d7.loss_cls: 0.2204  decode.d7.loss_mask: 1.1020  decode.d7.loss_dice: 0.7423  decode.d8.loss_cls: 0.2121  decode.d8.loss_mask: 1.1268  decode.d8.loss_dice: 0.7656
05/27 02:28:50 - mmengine - INFO - Iter(train) [130900/160000]  base_lr: 2.1567e-05 lr: 2.1567e-06  eta: 3:20:36  time: 0.4172  data_time: 0.0100  memory: 5969  grad_norm: 477.9203  loss: 18.6226  decode.loss_cls: 0.1251  decode.loss_mask: 1.0076  decode.loss_dice: 0.7012  decode.d0.loss_cls: 0.7674  decode.d0.loss_mask: 0.8721  decode.d0.loss_dice: 0.6487  decode.d1.loss_cls: 0.1687  decode.d1.loss_mask: 0.9655  decode.d1.loss_dice: 0.6667  decode.d2.loss_cls: 0.1448  decode.d2.loss_mask: 0.9841  decode.d2.loss_dice: 0.6934  decode.d3.loss_cls: 0.1737  decode.d3.loss_mask: 0.9799  decode.d3.loss_dice: 0.6774  decode.d4.loss_cls: 0.1496  decode.d4.loss_mask: 0.9853  decode.d4.loss_dice: 0.6790  decode.d5.loss_cls: 0.1564  decode.d5.loss_mask: 0.9589  decode.d5.loss_dice: 0.6780  decode.d6.loss_cls: 0.1331  decode.d6.loss_mask: 0.9821  decode.d6.loss_dice: 0.6931  decode.d7.loss_cls: 0.1419  decode.d7.loss_mask: 0.9805  decode.d7.loss_dice: 0.6935  decode.d8.loss_cls: 0.1322  decode.d8.loss_mask: 0.9913  decode.d8.loss_dice: 0.6917
05/27 02:29:11 - mmengine - INFO - Iter(train) [130950/160000]  base_lr: 2.1534e-05 lr: 2.1534e-06  eta: 3:20:15  time: 0.4176  data_time: 0.0099  memory: 5968  grad_norm: 432.5627  loss: 19.5979  decode.loss_cls: 0.2287  decode.loss_mask: 0.9692  decode.loss_dice: 0.7062  decode.d0.loss_cls: 0.8233  decode.d0.loss_mask: 0.9203  decode.d0.loss_dice: 0.7128  decode.d1.loss_cls: 0.2511  decode.d1.loss_mask: 0.9491  decode.d1.loss_dice: 0.6981  decode.d2.loss_cls: 0.2385  decode.d2.loss_mask: 0.9686  decode.d2.loss_dice: 0.7168  decode.d3.loss_cls: 0.2405  decode.d3.loss_mask: 0.9679  decode.d3.loss_dice: 0.6991  decode.d4.loss_cls: 0.2417  decode.d4.loss_mask: 0.9606  decode.d4.loss_dice: 0.6959  decode.d5.loss_cls: 0.2268  decode.d5.loss_mask: 0.9485  decode.d5.loss_dice: 0.7083  decode.d6.loss_cls: 0.2426  decode.d6.loss_mask: 0.9522  decode.d6.loss_dice: 0.7071  decode.d7.loss_cls: 0.2396  decode.d7.loss_mask: 0.9556  decode.d7.loss_dice: 0.7220  decode.d8.loss_cls: 0.2461  decode.d8.loss_mask: 0.9467  decode.d8.loss_dice: 0.7140
05/27 02:29:31 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 02:29:31 - mmengine - INFO - Iter(train) [131000/160000]  base_lr: 2.1501e-05 lr: 2.1501e-06  eta: 3:19:55  time: 0.4174  data_time: 0.0098  memory: 5973  grad_norm: 763.8669  loss: 20.7354  decode.loss_cls: 0.1845  decode.loss_mask: 1.0788  decode.loss_dice: 0.7272  decode.d0.loss_cls: 0.6831  decode.d0.loss_mask: 1.1147  decode.d0.loss_dice: 0.7810  decode.d1.loss_cls: 0.1843  decode.d1.loss_mask: 1.0998  decode.d1.loss_dice: 0.7455  decode.d2.loss_cls: 0.1847  decode.d2.loss_mask: 1.1359  decode.d2.loss_dice: 0.7213  decode.d3.loss_cls: 0.1706  decode.d3.loss_mask: 1.1020  decode.d3.loss_dice: 0.7396  decode.d4.loss_cls: 0.1562  decode.d4.loss_mask: 1.1365  decode.d4.loss_dice: 0.7352  decode.d5.loss_cls: 0.1775  decode.d5.loss_mask: 1.1259  decode.d5.loss_dice: 0.7272  decode.d6.loss_cls: 0.1570  decode.d6.loss_mask: 1.1024  decode.d6.loss_dice: 0.7594  decode.d7.loss_cls: 0.1653  decode.d7.loss_mask: 1.1046  decode.d7.loss_dice: 0.7521  decode.d8.loss_cls: 0.1693  decode.d8.loss_mask: 1.0858  decode.d8.loss_dice: 0.7280
05/27 02:29:52 - mmengine - INFO - Iter(train) [131050/160000]  base_lr: 2.1467e-05 lr: 2.1467e-06  eta: 3:19:34  time: 0.4174  data_time: 0.0099  memory: 5966  grad_norm: 367.9414  loss: 17.9337  decode.loss_cls: 0.2191  decode.loss_mask: 0.8360  decode.loss_dice: 0.6205  decode.d0.loss_cls: 0.8174  decode.d0.loss_mask: 0.8943  decode.d0.loss_dice: 0.6239  decode.d1.loss_cls: 0.2097  decode.d1.loss_mask: 0.8871  decode.d1.loss_dice: 0.6547  decode.d2.loss_cls: 0.2194  decode.d2.loss_mask: 0.8685  decode.d2.loss_dice: 0.6364  decode.d3.loss_cls: 0.2277  decode.d3.loss_mask: 0.8555  decode.d3.loss_dice: 0.6375  decode.d4.loss_cls: 0.2082  decode.d4.loss_mask: 0.8637  decode.d4.loss_dice: 0.6703  decode.d5.loss_cls: 0.1932  decode.d5.loss_mask: 0.8791  decode.d5.loss_dice: 0.6328  decode.d6.loss_cls: 0.2095  decode.d6.loss_mask: 0.8721  decode.d6.loss_dice: 0.6454  decode.d7.loss_cls: 0.2502  decode.d7.loss_mask: 0.8932  decode.d7.loss_dice: 0.6721  decode.d8.loss_cls: 0.1951  decode.d8.loss_mask: 0.8875  decode.d8.loss_dice: 0.6535
05/27 02:30:13 - mmengine - INFO - Iter(train) [131100/160000]  base_lr: 2.1434e-05 lr: 2.1434e-06  eta: 3:19:13  time: 0.4168  data_time: 0.0098  memory: 5980  grad_norm: 466.3828  loss: 17.1927  decode.loss_cls: 0.2071  decode.loss_mask: 0.8764  decode.loss_dice: 0.6083  decode.d0.loss_cls: 0.7840  decode.d0.loss_mask: 0.8144  decode.d0.loss_dice: 0.5708  decode.d1.loss_cls: 0.2463  decode.d1.loss_mask: 0.8387  decode.d1.loss_dice: 0.6021  decode.d2.loss_cls: 0.2316  decode.d2.loss_mask: 0.8280  decode.d2.loss_dice: 0.5782  decode.d3.loss_cls: 0.2127  decode.d3.loss_mask: 0.8444  decode.d3.loss_dice: 0.5844  decode.d4.loss_cls: 0.2133  decode.d4.loss_mask: 0.8370  decode.d4.loss_dice: 0.5954  decode.d5.loss_cls: 0.2220  decode.d5.loss_mask: 0.8503  decode.d5.loss_dice: 0.6101  decode.d6.loss_cls: 0.2269  decode.d6.loss_mask: 0.8506  decode.d6.loss_dice: 0.5992  decode.d7.loss_cls: 0.2258  decode.d7.loss_mask: 0.8564  decode.d7.loss_dice: 0.6069  decode.d8.loss_cls: 0.2022  decode.d8.loss_mask: 0.8661  decode.d8.loss_dice: 0.6032
05/27 02:30:34 - mmengine - INFO - Iter(train) [131150/160000]  base_lr: 2.1401e-05 lr: 2.1401e-06  eta: 3:18:53  time: 0.4179  data_time: 0.0098  memory: 5975  grad_norm: 333.4771  loss: 19.0903  decode.loss_cls: 0.1578  decode.loss_mask: 0.9976  decode.loss_dice: 0.7134  decode.d0.loss_cls: 0.6616  decode.d0.loss_mask: 0.9800  decode.d0.loss_dice: 0.7077  decode.d1.loss_cls: 0.1670  decode.d1.loss_mask: 0.9929  decode.d1.loss_dice: 0.7103  decode.d2.loss_cls: 0.1575  decode.d2.loss_mask: 0.9851  decode.d2.loss_dice: 0.7097  decode.d3.loss_cls: 0.1486  decode.d3.loss_mask: 0.9860  decode.d3.loss_dice: 0.7114  decode.d4.loss_cls: 0.1523  decode.d4.loss_mask: 0.9912  decode.d4.loss_dice: 0.7054  decode.d5.loss_cls: 0.1410  decode.d5.loss_mask: 1.0005  decode.d5.loss_dice: 0.7104  decode.d6.loss_cls: 0.1816  decode.d6.loss_mask: 0.9917  decode.d6.loss_dice: 0.7053  decode.d7.loss_cls: 0.1718  decode.d7.loss_mask: 0.9894  decode.d7.loss_dice: 0.7150  decode.d8.loss_cls: 0.1453  decode.d8.loss_mask: 0.9935  decode.d8.loss_dice: 0.7093
05/27 02:30:55 - mmengine - INFO - Iter(train) [131200/160000]  base_lr: 2.1367e-05 lr: 2.1367e-06  eta: 3:18:32  time: 0.4194  data_time: 0.0103  memory: 5976  grad_norm: 310.7850  loss: 16.9655  decode.loss_cls: 0.1512  decode.loss_mask: 0.8648  decode.loss_dice: 0.6069  decode.d0.loss_cls: 0.6506  decode.d0.loss_mask: 0.8399  decode.d0.loss_dice: 0.6672  decode.d1.loss_cls: 0.1995  decode.d1.loss_mask: 0.8538  decode.d1.loss_dice: 0.6107  decode.d2.loss_cls: 0.1646  decode.d2.loss_mask: 0.8542  decode.d2.loss_dice: 0.6183  decode.d3.loss_cls: 0.2009  decode.d3.loss_mask: 0.8561  decode.d3.loss_dice: 0.6266  decode.d4.loss_cls: 0.1680  decode.d4.loss_mask: 0.8446  decode.d4.loss_dice: 0.6002  decode.d5.loss_cls: 0.1675  decode.d5.loss_mask: 0.8502  decode.d5.loss_dice: 0.6100  decode.d6.loss_cls: 0.1904  decode.d6.loss_mask: 0.8468  decode.d6.loss_dice: 0.6301  decode.d7.loss_cls: 0.1620  decode.d7.loss_mask: 0.8606  decode.d7.loss_dice: 0.6338  decode.d8.loss_cls: 0.1559  decode.d8.loss_mask: 0.8529  decode.d8.loss_dice: 0.6272
05/27 02:31:16 - mmengine - INFO - Iter(train) [131250/160000]  base_lr: 2.1334e-05 lr: 2.1334e-06  eta: 3:18:12  time: 0.4168  data_time: 0.0099  memory: 5980  grad_norm: 642.7608  loss: 23.7407  decode.loss_cls: 0.1466  decode.loss_mask: 1.2625  decode.loss_dice: 0.8811  decode.d0.loss_cls: 0.8411  decode.d0.loss_mask: 1.1618  decode.d0.loss_dice: 0.8247  decode.d1.loss_cls: 0.1921  decode.d1.loss_mask: 1.2649  decode.d1.loss_dice: 0.8774  decode.d2.loss_cls: 0.1641  decode.d2.loss_mask: 1.3007  decode.d2.loss_dice: 0.8760  decode.d3.loss_cls: 0.1264  decode.d3.loss_mask: 1.3098  decode.d3.loss_dice: 0.8904  decode.d4.loss_cls: 0.2017  decode.d4.loss_mask: 1.2727  decode.d4.loss_dice: 0.8566  decode.d5.loss_cls: 0.1608  decode.d5.loss_mask: 1.2994  decode.d5.loss_dice: 0.8679  decode.d6.loss_cls: 0.1673  decode.d6.loss_mask: 1.2843  decode.d6.loss_dice: 0.8803  decode.d7.loss_cls: 0.1559  decode.d7.loss_mask: 1.2692  decode.d7.loss_dice: 0.8911  decode.d8.loss_cls: 0.1864  decode.d8.loss_mask: 1.2624  decode.d8.loss_dice: 0.8650
05/27 02:31:37 - mmengine - INFO - Iter(train) [131300/160000]  base_lr: 2.1300e-05 lr: 2.1300e-06  eta: 3:17:51  time: 0.4179  data_time: 0.0098  memory: 5969  grad_norm: 813.8185  loss: 22.5994  decode.loss_cls: 0.2510  decode.loss_mask: 1.1580  decode.loss_dice: 0.7872  decode.d0.loss_cls: 0.8022  decode.d0.loss_mask: 1.1416  decode.d0.loss_dice: 0.7934  decode.d1.loss_cls: 0.2877  decode.d1.loss_mask: 1.1691  decode.d1.loss_dice: 0.7945  decode.d2.loss_cls: 0.2860  decode.d2.loss_mask: 1.1551  decode.d2.loss_dice: 0.7857  decode.d3.loss_cls: 0.2643  decode.d3.loss_mask: 1.1576  decode.d3.loss_dice: 0.7938  decode.d4.loss_cls: 0.2360  decode.d4.loss_mask: 1.1518  decode.d4.loss_dice: 0.7796  decode.d5.loss_cls: 0.1963  decode.d5.loss_mask: 1.1974  decode.d5.loss_dice: 0.8079  decode.d6.loss_cls: 0.2499  decode.d6.loss_mask: 1.1832  decode.d6.loss_dice: 0.7963  decode.d7.loss_cls: 0.2324  decode.d7.loss_mask: 1.1789  decode.d7.loss_dice: 0.7975  decode.d8.loss_cls: 0.2449  decode.d8.loss_mask: 1.1453  decode.d8.loss_dice: 0.7746
05/27 02:31:58 - mmengine - INFO - Iter(train) [131350/160000]  base_lr: 2.1267e-05 lr: 2.1267e-06  eta: 3:17:30  time: 0.4186  data_time: 0.0099  memory: 5967  grad_norm: 426.2922  loss: 16.1437  decode.loss_cls: 0.0902  decode.loss_mask: 0.8835  decode.loss_dice: 0.6041  decode.d0.loss_cls: 0.6418  decode.d0.loss_mask: 0.8242  decode.d0.loss_dice: 0.6079  decode.d1.loss_cls: 0.1230  decode.d1.loss_mask: 0.8196  decode.d1.loss_dice: 0.5895  decode.d2.loss_cls: 0.1174  decode.d2.loss_mask: 0.8724  decode.d2.loss_dice: 0.6068  decode.d3.loss_cls: 0.1356  decode.d3.loss_mask: 0.8265  decode.d3.loss_dice: 0.5820  decode.d4.loss_cls: 0.1401  decode.d4.loss_mask: 0.8190  decode.d4.loss_dice: 0.5943  decode.d5.loss_cls: 0.0959  decode.d5.loss_mask: 0.8841  decode.d5.loss_dice: 0.5984  decode.d6.loss_cls: 0.0882  decode.d6.loss_mask: 0.8465  decode.d6.loss_dice: 0.6078  decode.d7.loss_cls: 0.0977  decode.d7.loss_mask: 0.8837  decode.d7.loss_dice: 0.5984  decode.d8.loss_cls: 0.0855  decode.d8.loss_mask: 0.8779  decode.d8.loss_dice: 0.6018
05/27 02:32:19 - mmengine - INFO - Iter(train) [131400/160000]  base_lr: 2.1234e-05 lr: 2.1234e-06  eta: 3:17:10  time: 0.4165  data_time: 0.0099  memory: 5979  grad_norm: 307.0974  loss: 14.4558  decode.loss_cls: 0.0562  decode.loss_mask: 0.8137  decode.loss_dice: 0.5280  decode.d0.loss_cls: 0.4568  decode.d0.loss_mask: 0.8059  decode.d0.loss_dice: 0.5509  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.8116  decode.d1.loss_dice: 0.5262  decode.d2.loss_cls: 0.0520  decode.d2.loss_mask: 0.8128  decode.d2.loss_dice: 0.5285  decode.d3.loss_cls: 0.0578  decode.d3.loss_mask: 0.8224  decode.d3.loss_dice: 0.5268  decode.d4.loss_cls: 0.0605  decode.d4.loss_mask: 0.8290  decode.d4.loss_dice: 0.5328  decode.d5.loss_cls: 0.0579  decode.d5.loss_mask: 0.8126  decode.d5.loss_dice: 0.5306  decode.d6.loss_cls: 0.0729  decode.d6.loss_mask: 0.8111  decode.d6.loss_dice: 0.5256  decode.d7.loss_cls: 0.0634  decode.d7.loss_mask: 0.8165  decode.d7.loss_dice: 0.5291  decode.d8.loss_cls: 0.0535  decode.d8.loss_mask: 0.8204  decode.d8.loss_dice: 0.5272
05/27 02:32:39 - mmengine - INFO - Iter(train) [131450/160000]  base_lr: 2.1200e-05 lr: 2.1200e-06  eta: 3:16:49  time: 0.4175  data_time: 0.0100  memory: 5966  grad_norm: 683.7955  loss: 23.3019  decode.loss_cls: 0.1665  decode.loss_mask: 1.2662  decode.loss_dice: 0.8406  decode.d0.loss_cls: 0.7048  decode.d0.loss_mask: 1.2128  decode.d0.loss_dice: 0.8022  decode.d1.loss_cls: 0.1648  decode.d1.loss_mask: 1.2858  decode.d1.loss_dice: 0.8434  decode.d2.loss_cls: 0.1999  decode.d2.loss_mask: 1.2843  decode.d2.loss_dice: 0.8386  decode.d3.loss_cls: 0.1749  decode.d3.loss_mask: 1.2727  decode.d3.loss_dice: 0.8305  decode.d4.loss_cls: 0.1626  decode.d4.loss_mask: 1.2778  decode.d4.loss_dice: 0.8250  decode.d5.loss_cls: 0.1704  decode.d5.loss_mask: 1.2685  decode.d5.loss_dice: 0.8262  decode.d6.loss_cls: 0.1998  decode.d6.loss_mask: 1.2736  decode.d6.loss_dice: 0.8337  decode.d7.loss_cls: 0.1820  decode.d7.loss_mask: 1.2800  decode.d7.loss_dice: 0.8365  decode.d8.loss_cls: 0.1885  decode.d8.loss_mask: 1.2626  decode.d8.loss_dice: 0.8267
05/27 02:33:00 - mmengine - INFO - Iter(train) [131500/160000]  base_lr: 2.1167e-05 lr: 2.1167e-06  eta: 3:16:28  time: 0.4170  data_time: 0.0099  memory: 5967  grad_norm: 501.5417  loss: 17.2491  decode.loss_cls: 0.1866  decode.loss_mask: 0.8796  decode.loss_dice: 0.5907  decode.d0.loss_cls: 0.5927  decode.d0.loss_mask: 0.8884  decode.d0.loss_dice: 0.5984  decode.d1.loss_cls: 0.2527  decode.d1.loss_mask: 0.8978  decode.d1.loss_dice: 0.6099  decode.d2.loss_cls: 0.1831  decode.d2.loss_mask: 0.8781  decode.d2.loss_dice: 0.6086  decode.d3.loss_cls: 0.1540  decode.d3.loss_mask: 0.8818  decode.d3.loss_dice: 0.6138  decode.d4.loss_cls: 0.1862  decode.d4.loss_mask: 0.8887  decode.d4.loss_dice: 0.6086  decode.d5.loss_cls: 0.1582  decode.d5.loss_mask: 0.8940  decode.d5.loss_dice: 0.6153  decode.d6.loss_cls: 0.1947  decode.d6.loss_mask: 0.8775  decode.d6.loss_dice: 0.5955  decode.d7.loss_cls: 0.2377  decode.d7.loss_mask: 0.8844  decode.d7.loss_dice: 0.6129  decode.d8.loss_cls: 0.2020  decode.d8.loss_mask: 0.8807  decode.d8.loss_dice: 0.5966
05/27 02:33:21 - mmengine - INFO - Iter(train) [131550/160000]  base_lr: 2.1133e-05 lr: 2.1133e-06  eta: 3:16:08  time: 0.4168  data_time: 0.0099  memory: 5976  grad_norm: 500.2549  loss: 20.9154  decode.loss_cls: 0.2364  decode.loss_mask: 1.0106  decode.loss_dice: 0.7646  decode.d0.loss_cls: 0.8306  decode.d0.loss_mask: 0.9455  decode.d0.loss_dice: 0.7616  decode.d1.loss_cls: 0.3341  decode.d1.loss_mask: 1.0290  decode.d1.loss_dice: 0.7638  decode.d2.loss_cls: 0.2687  decode.d2.loss_mask: 0.9928  decode.d2.loss_dice: 0.7719  decode.d3.loss_cls: 0.2637  decode.d3.loss_mask: 1.0256  decode.d3.loss_dice: 0.7685  decode.d4.loss_cls: 0.2855  decode.d4.loss_mask: 1.0073  decode.d4.loss_dice: 0.7546  decode.d5.loss_cls: 0.2669  decode.d5.loss_mask: 0.9992  decode.d5.loss_dice: 0.7614  decode.d6.loss_cls: 0.2149  decode.d6.loss_mask: 0.9997  decode.d6.loss_dice: 0.7948  decode.d7.loss_cls: 0.2166  decode.d7.loss_mask: 1.0114  decode.d7.loss_dice: 0.7773  decode.d8.loss_cls: 0.2593  decode.d8.loss_mask: 1.0190  decode.d8.loss_dice: 0.7798
05/27 02:33:42 - mmengine - INFO - Iter(train) [131600/160000]  base_lr: 2.1100e-05 lr: 2.1100e-06  eta: 3:15:47  time: 0.4164  data_time: 0.0099  memory: 5971  grad_norm: 626.2233  loss: 22.6241  decode.loss_cls: 0.1288  decode.loss_mask: 1.1622  decode.loss_dice: 0.8802  decode.d0.loss_cls: 0.6403  decode.d0.loss_mask: 1.1879  decode.d0.loss_dice: 0.8851  decode.d1.loss_cls: 0.1427  decode.d1.loss_mask: 1.2035  decode.d1.loss_dice: 0.8852  decode.d2.loss_cls: 0.1291  decode.d2.loss_mask: 1.1817  decode.d2.loss_dice: 0.8885  decode.d3.loss_cls: 0.1470  decode.d3.loss_mask: 1.1808  decode.d3.loss_dice: 0.8949  decode.d4.loss_cls: 0.1525  decode.d4.loss_mask: 1.1956  decode.d4.loss_dice: 0.9037  decode.d5.loss_cls: 0.1423  decode.d5.loss_mask: 1.2126  decode.d5.loss_dice: 0.8922  decode.d6.loss_cls: 0.1377  decode.d6.loss_mask: 1.1553  decode.d6.loss_dice: 0.8725  decode.d7.loss_cls: 0.1549  decode.d7.loss_mask: 1.1913  decode.d7.loss_dice: 0.8962  decode.d8.loss_cls: 0.1538  decode.d8.loss_mask: 1.1568  decode.d8.loss_dice: 0.8686
05/27 02:34:03 - mmengine - INFO - Iter(train) [131650/160000]  base_lr: 2.1066e-05 lr: 2.1066e-06  eta: 3:15:26  time: 0.4174  data_time: 0.0100  memory: 5971  grad_norm: 337.8280  loss: 18.7960  decode.loss_cls: 0.1150  decode.loss_mask: 1.0120  decode.loss_dice: 0.6711  decode.d0.loss_cls: 0.6836  decode.d0.loss_mask: 0.9730  decode.d0.loss_dice: 0.6790  decode.d1.loss_cls: 0.1462  decode.d1.loss_mask: 1.0278  decode.d1.loss_dice: 0.6818  decode.d2.loss_cls: 0.1488  decode.d2.loss_mask: 1.0011  decode.d2.loss_dice: 0.6710  decode.d3.loss_cls: 0.1314  decode.d3.loss_mask: 1.0314  decode.d3.loss_dice: 0.6729  decode.d4.loss_cls: 0.1280  decode.d4.loss_mask: 1.0360  decode.d4.loss_dice: 0.6814  decode.d5.loss_cls: 0.1429  decode.d5.loss_mask: 1.0221  decode.d5.loss_dice: 0.6781  decode.d6.loss_cls: 0.1448  decode.d6.loss_mask: 1.0162  decode.d6.loss_dice: 0.6673  decode.d7.loss_cls: 0.1266  decode.d7.loss_mask: 1.0169  decode.d7.loss_dice: 0.6841  decode.d8.loss_cls: 0.1363  decode.d8.loss_mask: 0.9996  decode.d8.loss_dice: 0.6694
05/27 02:34:24 - mmengine - INFO - Iter(train) [131700/160000]  base_lr: 2.1033e-05 lr: 2.1033e-06  eta: 3:15:06  time: 0.4165  data_time: 0.0099  memory: 5965  grad_norm: 568.1665  loss: 14.8637  decode.loss_cls: 0.1040  decode.loss_mask: 0.7744  decode.loss_dice: 0.5622  decode.d0.loss_cls: 0.5581  decode.d0.loss_mask: 0.8157  decode.d0.loss_dice: 0.5919  decode.d1.loss_cls: 0.1095  decode.d1.loss_mask: 0.8055  decode.d1.loss_dice: 0.5771  decode.d2.loss_cls: 0.0986  decode.d2.loss_mask: 0.7767  decode.d2.loss_dice: 0.5514  decode.d3.loss_cls: 0.1147  decode.d3.loss_mask: 0.7643  decode.d3.loss_dice: 0.5257  decode.d4.loss_cls: 0.1049  decode.d4.loss_mask: 0.7736  decode.d4.loss_dice: 0.5341  decode.d5.loss_cls: 0.0959  decode.d5.loss_mask: 0.7709  decode.d5.loss_dice: 0.5529  decode.d6.loss_cls: 0.1152  decode.d6.loss_mask: 0.7718  decode.d6.loss_dice: 0.5463  decode.d7.loss_cls: 0.1044  decode.d7.loss_mask: 0.7703  decode.d7.loss_dice: 0.5637  decode.d8.loss_cls: 0.1012  decode.d8.loss_mask: 0.7736  decode.d8.loss_dice: 0.5554
05/27 02:34:45 - mmengine - INFO - Iter(train) [131750/160000]  base_lr: 2.1000e-05 lr: 2.1000e-06  eta: 3:14:45  time: 0.4165  data_time: 0.0099  memory: 5980  grad_norm: 345.2491  loss: 16.3504  decode.loss_cls: 0.0467  decode.loss_mask: 0.9062  decode.loss_dice: 0.6198  decode.d0.loss_cls: 0.5941  decode.d0.loss_mask: 0.8895  decode.d0.loss_dice: 0.6254  decode.d1.loss_cls: 0.0556  decode.d1.loss_mask: 0.9476  decode.d1.loss_dice: 0.6257  decode.d2.loss_cls: 0.0675  decode.d2.loss_mask: 0.9086  decode.d2.loss_dice: 0.6173  decode.d3.loss_cls: 0.0805  decode.d3.loss_mask: 0.8983  decode.d3.loss_dice: 0.5952  decode.d4.loss_cls: 0.0651  decode.d4.loss_mask: 0.9153  decode.d4.loss_dice: 0.6258  decode.d5.loss_cls: 0.0476  decode.d5.loss_mask: 0.9015  decode.d5.loss_dice: 0.6327  decode.d6.loss_cls: 0.0716  decode.d6.loss_mask: 0.8986  decode.d6.loss_dice: 0.6039  decode.d7.loss_cls: 0.0416  decode.d7.loss_mask: 0.9008  decode.d7.loss_dice: 0.6144  decode.d8.loss_cls: 0.0427  decode.d8.loss_mask: 0.9008  decode.d8.loss_dice: 0.6102
05/27 02:35:05 - mmengine - INFO - Iter(train) [131800/160000]  base_lr: 2.0966e-05 lr: 2.0966e-06  eta: 3:14:24  time: 0.4172  data_time: 0.0100  memory: 5972  grad_norm: 375.0928  loss: 20.5831  decode.loss_cls: 0.1832  decode.loss_mask: 1.0751  decode.loss_dice: 0.7543  decode.d0.loss_cls: 0.7905  decode.d0.loss_mask: 1.0375  decode.d0.loss_dice: 0.7307  decode.d1.loss_cls: 0.2186  decode.d1.loss_mask: 1.0402  decode.d1.loss_dice: 0.7277  decode.d2.loss_cls: 0.1863  decode.d2.loss_mask: 1.0611  decode.d2.loss_dice: 0.7599  decode.d3.loss_cls: 0.1847  decode.d3.loss_mask: 1.0726  decode.d3.loss_dice: 0.7593  decode.d4.loss_cls: 0.1930  decode.d4.loss_mask: 1.0832  decode.d4.loss_dice: 0.7743  decode.d5.loss_cls: 0.1814  decode.d5.loss_mask: 1.0783  decode.d5.loss_dice: 0.7409  decode.d6.loss_cls: 0.2064  decode.d6.loss_mask: 1.0370  decode.d6.loss_dice: 0.7491  decode.d7.loss_cls: 0.1840  decode.d7.loss_mask: 1.0507  decode.d7.loss_dice: 0.7546  decode.d8.loss_cls: 0.1971  decode.d8.loss_mask: 1.0277  decode.d8.loss_dice: 0.7437
05/27 02:35:26 - mmengine - INFO - Iter(train) [131850/160000]  base_lr: 2.0933e-05 lr: 2.0933e-06  eta: 3:14:04  time: 0.4168  data_time: 0.0099  memory: 5980  grad_norm: 559.9429  loss: 17.0027  decode.loss_cls: 0.1356  decode.loss_mask: 0.8990  decode.loss_dice: 0.6380  decode.d0.loss_cls: 0.5451  decode.d0.loss_mask: 0.8947  decode.d0.loss_dice: 0.6306  decode.d1.loss_cls: 0.1318  decode.d1.loss_mask: 0.8820  decode.d1.loss_dice: 0.6389  decode.d2.loss_cls: 0.1367  decode.d2.loss_mask: 0.8956  decode.d2.loss_dice: 0.6507  decode.d3.loss_cls: 0.1297  decode.d3.loss_mask: 0.8818  decode.d3.loss_dice: 0.6379  decode.d4.loss_cls: 0.1467  decode.d4.loss_mask: 0.8820  decode.d4.loss_dice: 0.6459  decode.d5.loss_cls: 0.1417  decode.d5.loss_mask: 0.8737  decode.d5.loss_dice: 0.6423  decode.d6.loss_cls: 0.1098  decode.d6.loss_mask: 0.8746  decode.d6.loss_dice: 0.6311  decode.d7.loss_cls: 0.1147  decode.d7.loss_mask: 0.9028  decode.d7.loss_dice: 0.6519  decode.d8.loss_cls: 0.1329  decode.d8.loss_mask: 0.8881  decode.d8.loss_dice: 0.6363
05/27 02:35:47 - mmengine - INFO - Iter(train) [131900/160000]  base_lr: 2.0899e-05 lr: 2.0899e-06  eta: 3:13:43  time: 0.4172  data_time: 0.0099  memory: 5968  grad_norm: 518.2897  loss: 16.0577  decode.loss_cls: 0.0935  decode.loss_mask: 0.8866  decode.loss_dice: 0.5793  decode.d0.loss_cls: 0.6045  decode.d0.loss_mask: 0.8578  decode.d0.loss_dice: 0.5798  decode.d1.loss_cls: 0.1100  decode.d1.loss_mask: 0.8728  decode.d1.loss_dice: 0.5906  decode.d2.loss_cls: 0.0993  decode.d2.loss_mask: 0.8756  decode.d2.loss_dice: 0.5920  decode.d3.loss_cls: 0.0692  decode.d3.loss_mask: 0.8945  decode.d3.loss_dice: 0.5796  decode.d4.loss_cls: 0.0646  decode.d4.loss_mask: 0.9066  decode.d4.loss_dice: 0.5934  decode.d5.loss_cls: 0.0661  decode.d5.loss_mask: 0.8968  decode.d5.loss_dice: 0.5925  decode.d6.loss_cls: 0.1142  decode.d6.loss_mask: 0.8424  decode.d6.loss_dice: 0.5789  decode.d7.loss_cls: 0.0647  decode.d7.loss_mask: 0.8959  decode.d7.loss_dice: 0.5885  decode.d8.loss_cls: 0.0921  decode.d8.loss_mask: 0.8851  decode.d8.loss_dice: 0.5912
05/27 02:36:08 - mmengine - INFO - Iter(train) [131950/160000]  base_lr: 2.0866e-05 lr: 2.0866e-06  eta: 3:13:23  time: 0.4159  data_time: 0.0099  memory: 5975  grad_norm: 433.6836  loss: 16.4489  decode.loss_cls: 0.0879  decode.loss_mask: 0.9376  decode.loss_dice: 0.5808  decode.d0.loss_cls: 0.5112  decode.d0.loss_mask: 0.9266  decode.d0.loss_dice: 0.5623  decode.d1.loss_cls: 0.0954  decode.d1.loss_mask: 0.9219  decode.d1.loss_dice: 0.5837  decode.d2.loss_cls: 0.0900  decode.d2.loss_mask: 0.9319  decode.d2.loss_dice: 0.5778  decode.d3.loss_cls: 0.0859  decode.d3.loss_mask: 0.9368  decode.d3.loss_dice: 0.5831  decode.d4.loss_cls: 0.0918  decode.d4.loss_mask: 0.9253  decode.d4.loss_dice: 0.5814  decode.d5.loss_cls: 0.0947  decode.d5.loss_mask: 0.9368  decode.d5.loss_dice: 0.5807  decode.d6.loss_cls: 0.1237  decode.d6.loss_mask: 0.9256  decode.d6.loss_dice: 0.5719  decode.d7.loss_cls: 0.0875  decode.d7.loss_mask: 0.9449  decode.d7.loss_dice: 0.5813  decode.d8.loss_cls: 0.0880  decode.d8.loss_mask: 0.9307  decode.d8.loss_dice: 0.5715
05/27 02:36:29 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 02:36:29 - mmengine - INFO - Iter(train) [132000/160000]  base_lr: 2.0832e-05 lr: 2.0832e-06  eta: 3:13:02  time: 0.4167  data_time: 0.0100  memory: 5972  grad_norm: 339.6959  loss: 16.0265  decode.loss_cls: 0.0984  decode.loss_mask: 0.8394  decode.loss_dice: 0.6006  decode.d0.loss_cls: 0.5095  decode.d0.loss_mask: 0.8148  decode.d0.loss_dice: 0.6182  decode.d1.loss_cls: 0.1376  decode.d1.loss_mask: 0.8489  decode.d1.loss_dice: 0.6112  decode.d2.loss_cls: 0.1313  decode.d2.loss_mask: 0.8568  decode.d2.loss_dice: 0.5782  decode.d3.loss_cls: 0.1290  decode.d3.loss_mask: 0.8615  decode.d3.loss_dice: 0.6015  decode.d4.loss_cls: 0.1037  decode.d4.loss_mask: 0.8551  decode.d4.loss_dice: 0.6071  decode.d5.loss_cls: 0.1252  decode.d5.loss_mask: 0.8472  decode.d5.loss_dice: 0.5846  decode.d6.loss_cls: 0.1094  decode.d6.loss_mask: 0.8562  decode.d6.loss_dice: 0.6065  decode.d7.loss_cls: 0.1091  decode.d7.loss_mask: 0.8497  decode.d7.loss_dice: 0.5913  decode.d8.loss_cls: 0.1120  decode.d8.loss_mask: 0.8421  decode.d8.loss_dice: 0.5904
05/27 02:36:50 - mmengine - INFO - Iter(train) [132050/160000]  base_lr: 2.0799e-05 lr: 2.0799e-06  eta: 3:12:41  time: 0.4169  data_time: 0.0099  memory: 5976  grad_norm: 604.1724  loss: 20.1128  decode.loss_cls: 0.2286  decode.loss_mask: 1.0232  decode.loss_dice: 0.6943  decode.d0.loss_cls: 0.6881  decode.d0.loss_mask: 0.9816  decode.d0.loss_dice: 0.6962  decode.d1.loss_cls: 0.2149  decode.d1.loss_mask: 1.0286  decode.d1.loss_dice: 0.7182  decode.d2.loss_cls: 0.2101  decode.d2.loss_mask: 1.0792  decode.d2.loss_dice: 0.7144  decode.d3.loss_cls: 0.2036  decode.d3.loss_mask: 1.0273  decode.d3.loss_dice: 0.7052  decode.d4.loss_cls: 0.1912  decode.d4.loss_mask: 1.0265  decode.d4.loss_dice: 0.7072  decode.d5.loss_cls: 0.2068  decode.d5.loss_mask: 1.0351  decode.d5.loss_dice: 0.7063  decode.d6.loss_cls: 0.2258  decode.d6.loss_mask: 1.0806  decode.d6.loss_dice: 0.7345  decode.d7.loss_cls: 0.2113  decode.d7.loss_mask: 1.0274  decode.d7.loss_dice: 0.7328  decode.d8.loss_cls: 0.2222  decode.d8.loss_mask: 1.0435  decode.d8.loss_dice: 0.7483
05/27 02:37:11 - mmengine - INFO - Iter(train) [132100/160000]  base_lr: 2.0765e-05 lr: 2.0765e-06  eta: 3:12:21  time: 0.4178  data_time: 0.0099  memory: 5972  grad_norm: 410.7137  loss: 17.1184  decode.loss_cls: 0.1815  decode.loss_mask: 0.8286  decode.loss_dice: 0.6157  decode.d0.loss_cls: 0.6676  decode.d0.loss_mask: 0.8645  decode.d0.loss_dice: 0.6659  decode.d1.loss_cls: 0.2267  decode.d1.loss_mask: 0.8343  decode.d1.loss_dice: 0.6389  decode.d2.loss_cls: 0.2187  decode.d2.loss_mask: 0.8499  decode.d2.loss_dice: 0.6332  decode.d3.loss_cls: 0.1737  decode.d3.loss_mask: 0.8441  decode.d3.loss_dice: 0.6299  decode.d4.loss_cls: 0.1688  decode.d4.loss_mask: 0.8503  decode.d4.loss_dice: 0.6416  decode.d5.loss_cls: 0.1890  decode.d5.loss_mask: 0.8303  decode.d5.loss_dice: 0.6256  decode.d6.loss_cls: 0.1888  decode.d6.loss_mask: 0.8183  decode.d6.loss_dice: 0.6281  decode.d7.loss_cls: 0.1767  decode.d7.loss_mask: 0.8398  decode.d7.loss_dice: 0.6420  decode.d8.loss_cls: 0.1900  decode.d8.loss_mask: 0.8275  decode.d8.loss_dice: 0.6284
05/27 02:37:32 - mmengine - INFO - Iter(train) [132150/160000]  base_lr: 2.0732e-05 lr: 2.0732e-06  eta: 3:12:00  time: 0.4171  data_time: 0.0100  memory: 5968  grad_norm: 425.6933  loss: 18.0615  decode.loss_cls: 0.1115  decode.loss_mask: 1.0301  decode.loss_dice: 0.6462  decode.d0.loss_cls: 0.6460  decode.d0.loss_mask: 0.9873  decode.d0.loss_dice: 0.6064  decode.d1.loss_cls: 0.1273  decode.d1.loss_mask: 1.0074  decode.d1.loss_dice: 0.6218  decode.d2.loss_cls: 0.1234  decode.d2.loss_mask: 1.0015  decode.d2.loss_dice: 0.6049  decode.d3.loss_cls: 0.1241  decode.d3.loss_mask: 0.9875  decode.d3.loss_dice: 0.6136  decode.d4.loss_cls: 0.1345  decode.d4.loss_mask: 1.0044  decode.d4.loss_dice: 0.6185  decode.d5.loss_cls: 0.1172  decode.d5.loss_mask: 1.0352  decode.d5.loss_dice: 0.6232  decode.d6.loss_cls: 0.1199  decode.d6.loss_mask: 0.9855  decode.d6.loss_dice: 0.6062  decode.d7.loss_cls: 0.0765  decode.d7.loss_mask: 1.0711  decode.d7.loss_dice: 0.6505  decode.d8.loss_cls: 0.1237  decode.d8.loss_mask: 1.0298  decode.d8.loss_dice: 0.6264
05/27 02:37:52 - mmengine - INFO - Iter(train) [132200/160000]  base_lr: 2.0698e-05 lr: 2.0698e-06  eta: 3:11:39  time: 0.4166  data_time: 0.0099  memory: 5987  grad_norm: 373.2083  loss: 17.4559  decode.loss_cls: 0.1259  decode.loss_mask: 0.8981  decode.loss_dice: 0.6638  decode.d0.loss_cls: 0.6044  decode.d0.loss_mask: 0.8743  decode.d0.loss_dice: 0.6714  decode.d1.loss_cls: 0.1184  decode.d1.loss_mask: 0.8981  decode.d1.loss_dice: 0.6760  decode.d2.loss_cls: 0.0927  decode.d2.loss_mask: 0.9046  decode.d2.loss_dice: 0.6879  decode.d3.loss_cls: 0.1072  decode.d3.loss_mask: 0.8988  decode.d3.loss_dice: 0.6870  decode.d4.loss_cls: 0.1384  decode.d4.loss_mask: 0.8889  decode.d4.loss_dice: 0.6743  decode.d5.loss_cls: 0.1266  decode.d5.loss_mask: 0.9036  decode.d5.loss_dice: 0.6899  decode.d6.loss_cls: 0.1431  decode.d6.loss_mask: 0.8855  decode.d6.loss_dice: 0.6777  decode.d7.loss_cls: 0.1533  decode.d7.loss_mask: 0.8834  decode.d7.loss_dice: 0.6716  decode.d8.loss_cls: 0.1533  decode.d8.loss_mask: 0.8853  decode.d8.loss_dice: 0.6723
05/27 02:38:13 - mmengine - INFO - Iter(train) [132250/160000]  base_lr: 2.0665e-05 lr: 2.0665e-06  eta: 3:11:19  time: 0.4167  data_time: 0.0101  memory: 5976  grad_norm: 536.0517  loss: 17.1928  decode.loss_cls: 0.1056  decode.loss_mask: 0.9265  decode.loss_dice: 0.6410  decode.d0.loss_cls: 0.6795  decode.d0.loss_mask: 0.8762  decode.d0.loss_dice: 0.6240  decode.d1.loss_cls: 0.0922  decode.d1.loss_mask: 0.9302  decode.d1.loss_dice: 0.6316  decode.d2.loss_cls: 0.1137  decode.d2.loss_mask: 0.9334  decode.d2.loss_dice: 0.6216  decode.d3.loss_cls: 0.1161  decode.d3.loss_mask: 0.9169  decode.d3.loss_dice: 0.6261  decode.d4.loss_cls: 0.1146  decode.d4.loss_mask: 0.9280  decode.d4.loss_dice: 0.6132  decode.d5.loss_cls: 0.0995  decode.d5.loss_mask: 0.9586  decode.d5.loss_dice: 0.6742  decode.d6.loss_cls: 0.0951  decode.d6.loss_mask: 0.9221  decode.d6.loss_dice: 0.6502  decode.d7.loss_cls: 0.1012  decode.d7.loss_mask: 0.9250  decode.d7.loss_dice: 0.6331  decode.d8.loss_cls: 0.1180  decode.d8.loss_mask: 0.8983  decode.d8.loss_dice: 0.6272
05/27 02:38:34 - mmengine - INFO - Iter(train) [132300/160000]  base_lr: 2.0631e-05 lr: 2.0631e-06  eta: 3:10:58  time: 0.4162  data_time: 0.0099  memory: 5969  grad_norm: 579.3588  loss: 17.6697  decode.loss_cls: 0.2198  decode.loss_mask: 0.8766  decode.loss_dice: 0.6496  decode.d0.loss_cls: 0.6797  decode.d0.loss_mask: 0.8336  decode.d0.loss_dice: 0.6654  decode.d1.loss_cls: 0.2434  decode.d1.loss_mask: 0.8484  decode.d1.loss_dice: 0.6468  decode.d2.loss_cls: 0.2022  decode.d2.loss_mask: 0.8735  decode.d2.loss_dice: 0.6603  decode.d3.loss_cls: 0.2327  decode.d3.loss_mask: 0.8439  decode.d3.loss_dice: 0.6566  decode.d4.loss_cls: 0.1839  decode.d4.loss_mask: 0.8618  decode.d4.loss_dice: 0.6492  decode.d5.loss_cls: 0.1933  decode.d5.loss_mask: 0.8574  decode.d5.loss_dice: 0.6268  decode.d6.loss_cls: 0.2204  decode.d6.loss_mask: 0.8667  decode.d6.loss_dice: 0.6311  decode.d7.loss_cls: 0.2136  decode.d7.loss_mask: 0.8643  decode.d7.loss_dice: 0.6450  decode.d8.loss_cls: 0.2138  decode.d8.loss_mask: 0.8717  decode.d8.loss_dice: 0.6382
05/27 02:38:55 - mmengine - INFO - Iter(train) [132350/160000]  base_lr: 2.0598e-05 lr: 2.0598e-06  eta: 3:10:37  time: 0.4165  data_time: 0.0099  memory: 5967  grad_norm: 720.0694  loss: 14.9476  decode.loss_cls: 0.1209  decode.loss_mask: 0.8013  decode.loss_dice: 0.5511  decode.d0.loss_cls: 0.6004  decode.d0.loss_mask: 0.8056  decode.d0.loss_dice: 0.5411  decode.d1.loss_cls: 0.0960  decode.d1.loss_mask: 0.7869  decode.d1.loss_dice: 0.5358  decode.d2.loss_cls: 0.0985  decode.d2.loss_mask: 0.7902  decode.d2.loss_dice: 0.5441  decode.d3.loss_cls: 0.0845  decode.d3.loss_mask: 0.7985  decode.d3.loss_dice: 0.5542  decode.d4.loss_cls: 0.0925  decode.d4.loss_mask: 0.7885  decode.d4.loss_dice: 0.5472  decode.d5.loss_cls: 0.0997  decode.d5.loss_mask: 0.7948  decode.d5.loss_dice: 0.5585  decode.d6.loss_cls: 0.1145  decode.d6.loss_mask: 0.7892  decode.d6.loss_dice: 0.5460  decode.d7.loss_cls: 0.1210  decode.d7.loss_mask: 0.8054  decode.d7.loss_dice: 0.5476  decode.d8.loss_cls: 0.1032  decode.d8.loss_mask: 0.7954  decode.d8.loss_dice: 0.5349
05/27 02:39:16 - mmengine - INFO - Iter(train) [132400/160000]  base_lr: 2.0564e-05 lr: 2.0564e-06  eta: 3:10:17  time: 0.4178  data_time: 0.0098  memory: 5967  grad_norm: 818.9923  loss: 22.2060  decode.loss_cls: 0.3119  decode.loss_mask: 1.1182  decode.loss_dice: 0.7660  decode.d0.loss_cls: 0.7402  decode.d0.loss_mask: 1.1319  decode.d0.loss_dice: 0.7881  decode.d1.loss_cls: 0.2518  decode.d1.loss_mask: 1.1276  decode.d1.loss_dice: 0.7903  decode.d2.loss_cls: 0.2571  decode.d2.loss_mask: 1.1436  decode.d2.loss_dice: 0.7913  decode.d3.loss_cls: 0.2293  decode.d3.loss_mask: 1.1868  decode.d3.loss_dice: 0.7764  decode.d4.loss_cls: 0.2720  decode.d4.loss_mask: 1.1537  decode.d4.loss_dice: 0.7670  decode.d5.loss_cls: 0.1928  decode.d5.loss_mask: 1.1838  decode.d5.loss_dice: 0.7848  decode.d6.loss_cls: 0.3384  decode.d6.loss_mask: 1.0388  decode.d6.loss_dice: 0.7757  decode.d7.loss_cls: 0.2827  decode.d7.loss_mask: 1.0833  decode.d7.loss_dice: 0.7901  decode.d8.loss_cls: 0.2844  decode.d8.loss_mask: 1.0739  decode.d8.loss_dice: 0.7740
05/27 02:39:37 - mmengine - INFO - Iter(train) [132450/160000]  base_lr: 2.0531e-05 lr: 2.0531e-06  eta: 3:09:56  time: 0.4185  data_time: 0.0099  memory: 5968  grad_norm: 627.8762  loss: 19.1789  decode.loss_cls: 0.1557  decode.loss_mask: 0.9300  decode.loss_dice: 0.7736  decode.d0.loss_cls: 0.6886  decode.d0.loss_mask: 0.9020  decode.d0.loss_dice: 0.7276  decode.d1.loss_cls: 0.1362  decode.d1.loss_mask: 0.9277  decode.d1.loss_dice: 0.7731  decode.d2.loss_cls: 0.1687  decode.d2.loss_mask: 0.9267  decode.d2.loss_dice: 0.7722  decode.d3.loss_cls: 0.1581  decode.d3.loss_mask: 0.9458  decode.d3.loss_dice: 0.7842  decode.d4.loss_cls: 0.1702  decode.d4.loss_mask: 0.9287  decode.d4.loss_dice: 0.7700  decode.d5.loss_cls: 0.1641  decode.d5.loss_mask: 0.9295  decode.d5.loss_dice: 0.7732  decode.d6.loss_cls: 0.1605  decode.d6.loss_mask: 0.9367  decode.d6.loss_dice: 0.7948  decode.d7.loss_cls: 0.1929  decode.d7.loss_mask: 0.9340  decode.d7.loss_dice: 0.7812  decode.d8.loss_cls: 0.1748  decode.d8.loss_mask: 0.9255  decode.d8.loss_dice: 0.7727
05/27 02:39:58 - mmengine - INFO - Iter(train) [132500/160000]  base_lr: 2.0497e-05 lr: 2.0497e-06  eta: 3:09:35  time: 0.4172  data_time: 0.0099  memory: 5967  grad_norm: 531.7105  loss: 17.5440  decode.loss_cls: 0.1344  decode.loss_mask: 0.8894  decode.loss_dice: 0.6866  decode.d0.loss_cls: 0.6729  decode.d0.loss_mask: 0.8521  decode.d0.loss_dice: 0.6473  decode.d1.loss_cls: 0.1499  decode.d1.loss_mask: 0.8764  decode.d1.loss_dice: 0.6658  decode.d2.loss_cls: 0.1776  decode.d2.loss_mask: 0.8655  decode.d2.loss_dice: 0.6624  decode.d3.loss_cls: 0.1582  decode.d3.loss_mask: 0.8784  decode.d3.loss_dice: 0.6687  decode.d4.loss_cls: 0.1667  decode.d4.loss_mask: 0.8840  decode.d4.loss_dice: 0.6836  decode.d5.loss_cls: 0.1599  decode.d5.loss_mask: 0.8788  decode.d5.loss_dice: 0.6769  decode.d6.loss_cls: 0.1449  decode.d6.loss_mask: 0.8731  decode.d6.loss_dice: 0.6687  decode.d7.loss_cls: 0.1684  decode.d7.loss_mask: 0.8798  decode.d7.loss_dice: 0.6746  decode.d8.loss_cls: 0.1498  decode.d8.loss_mask: 0.8757  decode.d8.loss_dice: 0.6738
05/27 02:40:19 - mmengine - INFO - Iter(train) [132550/160000]  base_lr: 2.0464e-05 lr: 2.0464e-06  eta: 3:09:15  time: 0.4173  data_time: 0.0099  memory: 5967  grad_norm: 412.8127  loss: 16.5489  decode.loss_cls: 0.2300  decode.loss_mask: 0.8384  decode.loss_dice: 0.5516  decode.d0.loss_cls: 0.7369  decode.d0.loss_mask: 0.7872  decode.d0.loss_dice: 0.5446  decode.d1.loss_cls: 0.2560  decode.d1.loss_mask: 0.7976  decode.d1.loss_dice: 0.5481  decode.d2.loss_cls: 0.2374  decode.d2.loss_mask: 0.7887  decode.d2.loss_dice: 0.5365  decode.d3.loss_cls: 0.2448  decode.d3.loss_mask: 0.8448  decode.d3.loss_dice: 0.5444  decode.d4.loss_cls: 0.2082  decode.d4.loss_mask: 0.8574  decode.d4.loss_dice: 0.5368  decode.d5.loss_cls: 0.2047  decode.d5.loss_mask: 0.8700  decode.d5.loss_dice: 0.5582  decode.d6.loss_cls: 0.2457  decode.d6.loss_mask: 0.8128  decode.d6.loss_dice: 0.5549  decode.d7.loss_cls: 0.2460  decode.d7.loss_mask: 0.8053  decode.d7.loss_dice: 0.5501  decode.d8.loss_cls: 0.2408  decode.d8.loss_mask: 0.8190  decode.d8.loss_dice: 0.5518
05/27 02:40:39 - mmengine - INFO - Iter(train) [132600/160000]  base_lr: 2.0430e-05 lr: 2.0430e-06  eta: 3:08:54  time: 0.4169  data_time: 0.0098  memory: 5968  grad_norm: 319.7784  loss: 17.0165  decode.loss_cls: 0.1483  decode.loss_mask: 0.8427  decode.loss_dice: 0.6533  decode.d0.loss_cls: 0.4907  decode.d0.loss_mask: 0.8804  decode.d0.loss_dice: 0.6536  decode.d1.loss_cls: 0.1387  decode.d1.loss_mask: 0.8782  decode.d1.loss_dice: 0.6663  decode.d2.loss_cls: 0.1372  decode.d2.loss_mask: 0.8607  decode.d2.loss_dice: 0.6706  decode.d3.loss_cls: 0.1485  decode.d3.loss_mask: 0.8489  decode.d3.loss_dice: 0.6475  decode.d4.loss_cls: 0.1243  decode.d4.loss_mask: 0.8756  decode.d4.loss_dice: 0.6528  decode.d5.loss_cls: 0.1638  decode.d5.loss_mask: 0.8486  decode.d5.loss_dice: 0.6573  decode.d6.loss_cls: 0.1531  decode.d6.loss_mask: 0.8568  decode.d6.loss_dice: 0.6385  decode.d7.loss_cls: 0.1558  decode.d7.loss_mask: 0.8785  decode.d7.loss_dice: 0.6585  decode.d8.loss_cls: 0.1602  decode.d8.loss_mask: 0.8602  decode.d8.loss_dice: 0.6670
05/27 02:41:00 - mmengine - INFO - Iter(train) [132650/160000]  base_lr: 2.0397e-05 lr: 2.0397e-06  eta: 3:08:33  time: 0.4174  data_time: 0.0099  memory: 5971  grad_norm: 480.5597  loss: 17.0848  decode.loss_cls: 0.1241  decode.loss_mask: 0.8973  decode.loss_dice: 0.6332  decode.d0.loss_cls: 0.6015  decode.d0.loss_mask: 0.8544  decode.d0.loss_dice: 0.6155  decode.d1.loss_cls: 0.2212  decode.d1.loss_mask: 0.8687  decode.d1.loss_dice: 0.6171  decode.d2.loss_cls: 0.1215  decode.d2.loss_mask: 0.8990  decode.d2.loss_dice: 0.6314  decode.d3.loss_cls: 0.1130  decode.d3.loss_mask: 0.8882  decode.d3.loss_dice: 0.6469  decode.d4.loss_cls: 0.1357  decode.d4.loss_mask: 0.9049  decode.d4.loss_dice: 0.6180  decode.d5.loss_cls: 0.1332  decode.d5.loss_mask: 0.9061  decode.d5.loss_dice: 0.6427  decode.d6.loss_cls: 0.0968  decode.d6.loss_mask: 0.9038  decode.d6.loss_dice: 0.6565  decode.d7.loss_cls: 0.0988  decode.d7.loss_mask: 0.9315  decode.d7.loss_dice: 0.6439  decode.d8.loss_cls: 0.1024  decode.d8.loss_mask: 0.9290  decode.d8.loss_dice: 0.6486
05/27 02:41:21 - mmengine - INFO - Iter(train) [132700/160000]  base_lr: 2.0363e-05 lr: 2.0363e-06  eta: 3:08:13  time: 0.4168  data_time: 0.0100  memory: 5966  grad_norm: 801.4525  loss: 19.8146  decode.loss_cls: 0.2346  decode.loss_mask: 0.9529  decode.loss_dice: 0.7329  decode.d0.loss_cls: 0.6638  decode.d0.loss_mask: 0.9128  decode.d0.loss_dice: 0.7762  decode.d1.loss_cls: 0.3044  decode.d1.loss_mask: 0.9365  decode.d1.loss_dice: 0.7561  decode.d2.loss_cls: 0.2525  decode.d2.loss_mask: 0.9365  decode.d2.loss_dice: 0.7379  decode.d3.loss_cls: 0.2428  decode.d3.loss_mask: 0.9554  decode.d3.loss_dice: 0.7344  decode.d4.loss_cls: 0.2733  decode.d4.loss_mask: 0.9365  decode.d4.loss_dice: 0.7430  decode.d5.loss_cls: 0.2572  decode.d5.loss_mask: 0.9515  decode.d5.loss_dice: 0.7384  decode.d6.loss_cls: 0.2676  decode.d6.loss_mask: 0.9404  decode.d6.loss_dice: 0.7351  decode.d7.loss_cls: 0.2323  decode.d7.loss_mask: 0.9453  decode.d7.loss_dice: 0.7248  decode.d8.loss_cls: 0.2306  decode.d8.loss_mask: 0.9593  decode.d8.loss_dice: 0.7496
05/27 02:41:42 - mmengine - INFO - Iter(train) [132750/160000]  base_lr: 2.0329e-05 lr: 2.0329e-06  eta: 3:07:52  time: 0.4175  data_time: 0.0099  memory: 5970  grad_norm: 552.9262  loss: 15.8728  decode.loss_cls: 0.0986  decode.loss_mask: 0.8226  decode.loss_dice: 0.6133  decode.d0.loss_cls: 0.5448  decode.d0.loss_mask: 0.8008  decode.d0.loss_dice: 0.5693  decode.d1.loss_cls: 0.1130  decode.d1.loss_mask: 0.8383  decode.d1.loss_dice: 0.6277  decode.d2.loss_cls: 0.0737  decode.d2.loss_mask: 0.8269  decode.d2.loss_dice: 0.6189  decode.d3.loss_cls: 0.0999  decode.d3.loss_mask: 0.8359  decode.d3.loss_dice: 0.6346  decode.d4.loss_cls: 0.1108  decode.d4.loss_mask: 0.8123  decode.d4.loss_dice: 0.6105  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.8255  decode.d5.loss_dice: 0.6339  decode.d6.loss_cls: 0.0969  decode.d6.loss_mask: 0.8331  decode.d6.loss_dice: 0.6301  decode.d7.loss_cls: 0.1004  decode.d7.loss_mask: 0.8346  decode.d7.loss_dice: 0.6358  decode.d8.loss_cls: 0.0963  decode.d8.loss_mask: 0.8324  decode.d8.loss_dice: 0.6294
05/27 02:42:03 - mmengine - INFO - Iter(train) [132800/160000]  base_lr: 2.0296e-05 lr: 2.0296e-06  eta: 3:07:31  time: 0.4169  data_time: 0.0100  memory: 5973  grad_norm: 323.1525  loss: 15.7461  decode.loss_cls: 0.1509  decode.loss_mask: 0.7539  decode.loss_dice: 0.6012  decode.d0.loss_cls: 0.6750  decode.d0.loss_mask: 0.7247  decode.d0.loss_dice: 0.5872  decode.d1.loss_cls: 0.1470  decode.d1.loss_mask: 0.8031  decode.d1.loss_dice: 0.6300  decode.d2.loss_cls: 0.2013  decode.d2.loss_mask: 0.7461  decode.d2.loss_dice: 0.5800  decode.d3.loss_cls: 0.1687  decode.d3.loss_mask: 0.7542  decode.d3.loss_dice: 0.5941  decode.d4.loss_cls: 0.1724  decode.d4.loss_mask: 0.7604  decode.d4.loss_dice: 0.5921  decode.d5.loss_cls: 0.1925  decode.d5.loss_mask: 0.7696  decode.d5.loss_dice: 0.5935  decode.d6.loss_cls: 0.1410  decode.d6.loss_mask: 0.7585  decode.d6.loss_dice: 0.5914  decode.d7.loss_cls: 0.1542  decode.d7.loss_mask: 0.7737  decode.d7.loss_dice: 0.6086  decode.d8.loss_cls: 0.1433  decode.d8.loss_mask: 0.7704  decode.d8.loss_dice: 0.6070
05/27 02:42:24 - mmengine - INFO - Iter(train) [132850/160000]  base_lr: 2.0262e-05 lr: 2.0262e-06  eta: 3:07:11  time: 0.4165  data_time: 0.0099  memory: 5969  grad_norm: 601.0864  loss: 19.4777  decode.loss_cls: 0.1934  decode.loss_mask: 1.0196  decode.loss_dice: 0.6861  decode.d0.loss_cls: 0.6828  decode.d0.loss_mask: 1.0051  decode.d0.loss_dice: 0.7248  decode.d1.loss_cls: 0.1493  decode.d1.loss_mask: 1.0074  decode.d1.loss_dice: 0.6919  decode.d2.loss_cls: 0.1983  decode.d2.loss_mask: 1.0193  decode.d2.loss_dice: 0.6900  decode.d3.loss_cls: 0.1634  decode.d3.loss_mask: 1.0149  decode.d3.loss_dice: 0.6938  decode.d4.loss_cls: 0.1836  decode.d4.loss_mask: 1.0295  decode.d4.loss_dice: 0.6734  decode.d5.loss_cls: 0.1699  decode.d5.loss_mask: 1.0253  decode.d5.loss_dice: 0.6903  decode.d6.loss_cls: 0.1371  decode.d6.loss_mask: 1.0569  decode.d6.loss_dice: 0.7245  decode.d7.loss_cls: 0.1644  decode.d7.loss_mask: 1.0738  decode.d7.loss_dice: 0.7044  decode.d8.loss_cls: 0.1805  decode.d8.loss_mask: 1.0352  decode.d8.loss_dice: 0.6888
05/27 02:42:45 - mmengine - INFO - Iter(train) [132900/160000]  base_lr: 2.0229e-05 lr: 2.0229e-06  eta: 3:06:50  time: 0.4169  data_time: 0.0100  memory: 5966  grad_norm: 508.6217  loss: 18.2805  decode.loss_cls: 0.1516  decode.loss_mask: 1.0009  decode.loss_dice: 0.6382  decode.d0.loss_cls: 0.5927  decode.d0.loss_mask: 0.8837  decode.d0.loss_dice: 0.6345  decode.d1.loss_cls: 0.1392  decode.d1.loss_mask: 1.1052  decode.d1.loss_dice: 0.6515  decode.d2.loss_cls: 0.1354  decode.d2.loss_mask: 0.9942  decode.d2.loss_dice: 0.6250  decode.d3.loss_cls: 0.1533  decode.d3.loss_mask: 0.9960  decode.d3.loss_dice: 0.6242  decode.d4.loss_cls: 0.1551  decode.d4.loss_mask: 0.9741  decode.d4.loss_dice: 0.6238  decode.d5.loss_cls: 0.1629  decode.d5.loss_mask: 0.9819  decode.d5.loss_dice: 0.6218  decode.d6.loss_cls: 0.1505  decode.d6.loss_mask: 0.9982  decode.d6.loss_dice: 0.6277  decode.d7.loss_cls: 0.1660  decode.d7.loss_mask: 0.9860  decode.d7.loss_dice: 0.6399  decode.d8.loss_cls: 0.1347  decode.d8.loss_mask: 1.0926  decode.d8.loss_dice: 0.6398
05/27 02:43:06 - mmengine - INFO - Iter(train) [132950/160000]  base_lr: 2.0195e-05 lr: 2.0195e-06  eta: 3:06:30  time: 0.4166  data_time: 0.0099  memory: 5974  grad_norm: 485.2633  loss: 17.4063  decode.loss_cls: 0.1002  decode.loss_mask: 0.9667  decode.loss_dice: 0.6256  decode.d0.loss_cls: 0.5864  decode.d0.loss_mask: 0.9729  decode.d0.loss_dice: 0.6254  decode.d1.loss_cls: 0.1161  decode.d1.loss_mask: 0.9902  decode.d1.loss_dice: 0.6266  decode.d2.loss_cls: 0.1269  decode.d2.loss_mask: 0.9814  decode.d2.loss_dice: 0.6139  decode.d3.loss_cls: 0.1136  decode.d3.loss_mask: 0.9523  decode.d3.loss_dice: 0.6169  decode.d4.loss_cls: 0.1131  decode.d4.loss_mask: 0.9644  decode.d4.loss_dice: 0.6155  decode.d5.loss_cls: 0.1283  decode.d5.loss_mask: 0.9420  decode.d5.loss_dice: 0.5971  decode.d6.loss_cls: 0.1116  decode.d6.loss_mask: 0.9562  decode.d6.loss_dice: 0.5907  decode.d7.loss_cls: 0.1000  decode.d7.loss_mask: 0.9887  decode.d7.loss_dice: 0.6095  decode.d8.loss_cls: 0.1291  decode.d8.loss_mask: 0.9416  decode.d8.loss_dice: 0.6035
05/27 02:43:27 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 02:43:27 - mmengine - INFO - Iter(train) [133000/160000]  base_lr: 2.0161e-05 lr: 2.0161e-06  eta: 3:06:09  time: 0.4178  data_time: 0.0101  memory: 5984  grad_norm: 348.4259  loss: 17.9381  decode.loss_cls: 0.1272  decode.loss_mask: 0.9031  decode.loss_dice: 0.6923  decode.d0.loss_cls: 0.7501  decode.d0.loss_mask: 0.8691  decode.d0.loss_dice: 0.6482  decode.d1.loss_cls: 0.1466  decode.d1.loss_mask: 0.9436  decode.d1.loss_dice: 0.7005  decode.d2.loss_cls: 0.1545  decode.d2.loss_mask: 0.9066  decode.d2.loss_dice: 0.6909  decode.d3.loss_cls: 0.1196  decode.d3.loss_mask: 0.8967  decode.d3.loss_dice: 0.6854  decode.d4.loss_cls: 0.1419  decode.d4.loss_mask: 0.9041  decode.d4.loss_dice: 0.6987  decode.d5.loss_cls: 0.1598  decode.d5.loss_mask: 0.9016  decode.d5.loss_dice: 0.6858  decode.d6.loss_cls: 0.1357  decode.d6.loss_mask: 0.8991  decode.d6.loss_dice: 0.6706  decode.d7.loss_cls: 0.1506  decode.d7.loss_mask: 0.9205  decode.d7.loss_dice: 0.6786  decode.d8.loss_cls: 0.1652  decode.d8.loss_mask: 0.9104  decode.d8.loss_dice: 0.6812
05/27 02:43:47 - mmengine - INFO - Iter(train) [133050/160000]  base_lr: 2.0128e-05 lr: 2.0128e-06  eta: 3:05:48  time: 0.4177  data_time: 0.0100  memory: 5989  grad_norm: 996.9724  loss: 24.1941  decode.loss_cls: 0.2415  decode.loss_mask: 1.3258  decode.loss_dice: 0.8269  decode.d0.loss_cls: 0.7750  decode.d0.loss_mask: 1.2077  decode.d0.loss_dice: 0.7959  decode.d1.loss_cls: 0.2601  decode.d1.loss_mask: 1.2942  decode.d1.loss_dice: 0.8230  decode.d2.loss_cls: 0.2579  decode.d2.loss_mask: 1.3002  decode.d2.loss_dice: 0.8367  decode.d3.loss_cls: 0.2603  decode.d3.loss_mask: 1.2934  decode.d3.loss_dice: 0.7954  decode.d4.loss_cls: 0.3175  decode.d4.loss_mask: 1.2775  decode.d4.loss_dice: 0.8162  decode.d5.loss_cls: 0.2726  decode.d5.loss_mask: 1.3091  decode.d5.loss_dice: 0.8081  decode.d6.loss_cls: 0.2105  decode.d6.loss_mask: 1.3483  decode.d6.loss_dice: 0.8272  decode.d7.loss_cls: 0.2152  decode.d7.loss_mask: 1.3515  decode.d7.loss_dice: 0.8367  decode.d8.loss_cls: 0.2296  decode.d8.loss_mask: 1.2685  decode.d8.loss_dice: 0.8115
05/27 02:44:08 - mmengine - INFO - Iter(train) [133100/160000]  base_lr: 2.0094e-05 lr: 2.0094e-06  eta: 3:05:28  time: 0.4192  data_time: 0.0099  memory: 5966  grad_norm: 486.4996  loss: 18.6707  decode.loss_cls: 0.1266  decode.loss_mask: 1.0278  decode.loss_dice: 0.6804  decode.d0.loss_cls: 0.6437  decode.d0.loss_mask: 0.9726  decode.d0.loss_dice: 0.6736  decode.d1.loss_cls: 0.1413  decode.d1.loss_mask: 1.0015  decode.d1.loss_dice: 0.6820  decode.d2.loss_cls: 0.1387  decode.d2.loss_mask: 1.0208  decode.d2.loss_dice: 0.6743  decode.d3.loss_cls: 0.1353  decode.d3.loss_mask: 1.0121  decode.d3.loss_dice: 0.6647  decode.d4.loss_cls: 0.1538  decode.d4.loss_mask: 0.9795  decode.d4.loss_dice: 0.6524  decode.d5.loss_cls: 0.1303  decode.d5.loss_mask: 1.0076  decode.d5.loss_dice: 0.6721  decode.d6.loss_cls: 0.1537  decode.d6.loss_mask: 0.9942  decode.d6.loss_dice: 0.6762  decode.d7.loss_cls: 0.1503  decode.d7.loss_mask: 1.0044  decode.d7.loss_dice: 0.6692  decode.d8.loss_cls: 0.1522  decode.d8.loss_mask: 0.9976  decode.d8.loss_dice: 0.6820
05/27 02:44:29 - mmengine - INFO - Iter(train) [133150/160000]  base_lr: 2.0061e-05 lr: 2.0061e-06  eta: 3:05:07  time: 0.4175  data_time: 0.0100  memory: 5976  grad_norm: 608.3612  loss: 19.7241  decode.loss_cls: 0.2393  decode.loss_mask: 0.9947  decode.loss_dice: 0.7010  decode.d0.loss_cls: 0.6669  decode.d0.loss_mask: 0.9346  decode.d0.loss_dice: 0.6954  decode.d1.loss_cls: 0.2326  decode.d1.loss_mask: 1.0118  decode.d1.loss_dice: 0.7064  decode.d2.loss_cls: 0.2527  decode.d2.loss_mask: 0.9639  decode.d2.loss_dice: 0.6837  decode.d3.loss_cls: 0.2618  decode.d3.loss_mask: 0.9586  decode.d3.loss_dice: 0.6892  decode.d4.loss_cls: 0.2856  decode.d4.loss_mask: 0.9470  decode.d4.loss_dice: 0.6932  decode.d5.loss_cls: 0.2473  decode.d5.loss_mask: 0.9933  decode.d5.loss_dice: 0.7063  decode.d6.loss_cls: 0.2270  decode.d6.loss_mask: 1.0360  decode.d6.loss_dice: 0.7247  decode.d7.loss_cls: 0.2614  decode.d7.loss_mask: 0.9662  decode.d7.loss_dice: 0.7057  decode.d8.loss_cls: 0.2499  decode.d8.loss_mask: 0.9826  decode.d8.loss_dice: 0.7050
05/27 02:44:50 - mmengine - INFO - Iter(train) [133200/160000]  base_lr: 2.0027e-05 lr: 2.0027e-06  eta: 3:04:46  time: 0.4186  data_time: 0.0100  memory: 5975  grad_norm: 388.1755  loss: 15.6819  decode.loss_cls: 0.1599  decode.loss_mask: 0.7592  decode.loss_dice: 0.6188  decode.d0.loss_cls: 0.5357  decode.d0.loss_mask: 0.7402  decode.d0.loss_dice: 0.6255  decode.d1.loss_cls: 0.1788  decode.d1.loss_mask: 0.7758  decode.d1.loss_dice: 0.6058  decode.d2.loss_cls: 0.1562  decode.d2.loss_mask: 0.7609  decode.d2.loss_dice: 0.6186  decode.d3.loss_cls: 0.1606  decode.d3.loss_mask: 0.7452  decode.d3.loss_dice: 0.5966  decode.d4.loss_cls: 0.1433  decode.d4.loss_mask: 0.7565  decode.d4.loss_dice: 0.6211  decode.d5.loss_cls: 0.1712  decode.d5.loss_mask: 0.7546  decode.d5.loss_dice: 0.6015  decode.d6.loss_cls: 0.1152  decode.d6.loss_mask: 0.7516  decode.d6.loss_dice: 0.6576  decode.d7.loss_cls: 0.1490  decode.d7.loss_mask: 0.7514  decode.d7.loss_dice: 0.6396  decode.d8.loss_cls: 0.1618  decode.d8.loss_mask: 0.7583  decode.d8.loss_dice: 0.6111
05/27 02:45:11 - mmengine - INFO - Iter(train) [133250/160000]  base_lr: 1.9993e-05 lr: 1.9993e-06  eta: 3:04:26  time: 0.4175  data_time: 0.0099  memory: 5966  grad_norm: 327.5276  loss: 14.6894  decode.loss_cls: 0.0752  decode.loss_mask: 0.7950  decode.loss_dice: 0.5270  decode.d0.loss_cls: 0.5619  decode.d0.loss_mask: 0.7600  decode.d0.loss_dice: 0.5179  decode.d1.loss_cls: 0.0876  decode.d1.loss_mask: 0.8026  decode.d1.loss_dice: 0.5421  decode.d2.loss_cls: 0.0847  decode.d2.loss_mask: 0.8131  decode.d2.loss_dice: 0.5386  decode.d3.loss_cls: 0.0886  decode.d3.loss_mask: 0.8107  decode.d3.loss_dice: 0.5392  decode.d4.loss_cls: 0.0927  decode.d4.loss_mask: 0.8127  decode.d4.loss_dice: 0.5379  decode.d5.loss_cls: 0.1021  decode.d5.loss_mask: 0.8153  decode.d5.loss_dice: 0.5308  decode.d6.loss_cls: 0.1110  decode.d6.loss_mask: 0.7974  decode.d6.loss_dice: 0.5349  decode.d7.loss_cls: 0.0943  decode.d7.loss_mask: 0.7838  decode.d7.loss_dice: 0.5250  decode.d8.loss_cls: 0.0887  decode.d8.loss_mask: 0.7969  decode.d8.loss_dice: 0.5217
05/27 02:45:32 - mmengine - INFO - Iter(train) [133300/160000]  base_lr: 1.9960e-05 lr: 1.9960e-06  eta: 3:04:05  time: 0.4171  data_time: 0.0099  memory: 5971  grad_norm: 611.1785  loss: 19.4613  decode.loss_cls: 0.2911  decode.loss_mask: 0.8719  decode.loss_dice: 0.7078  decode.d0.loss_cls: 0.7626  decode.d0.loss_mask: 0.9100  decode.d0.loss_dice: 0.6849  decode.d1.loss_cls: 0.3623  decode.d1.loss_mask: 0.8862  decode.d1.loss_dice: 0.7115  decode.d2.loss_cls: 0.2735  decode.d2.loss_mask: 0.9357  decode.d2.loss_dice: 0.7298  decode.d3.loss_cls: 0.2810  decode.d3.loss_mask: 0.8803  decode.d3.loss_dice: 0.6992  decode.d4.loss_cls: 0.2673  decode.d4.loss_mask: 0.8796  decode.d4.loss_dice: 0.7285  decode.d5.loss_cls: 0.2821  decode.d5.loss_mask: 0.8733  decode.d5.loss_dice: 0.7264  decode.d6.loss_cls: 0.2532  decode.d6.loss_mask: 0.8940  decode.d6.loss_dice: 0.7263  decode.d7.loss_cls: 0.2579  decode.d7.loss_mask: 0.9186  decode.d7.loss_dice: 0.7485  decode.d8.loss_cls: 0.2847  decode.d8.loss_mask: 0.8932  decode.d8.loss_dice: 0.7401
05/27 02:45:53 - mmengine - INFO - Iter(train) [133350/160000]  base_lr: 1.9926e-05 lr: 1.9926e-06  eta: 3:03:44  time: 0.4163  data_time: 0.0099  memory: 5967  grad_norm: 487.4081  loss: 18.2097  decode.loss_cls: 0.2036  decode.loss_mask: 0.9441  decode.loss_dice: 0.6027  decode.d0.loss_cls: 0.8104  decode.d0.loss_mask: 0.9210  decode.d0.loss_dice: 0.5965  decode.d1.loss_cls: 0.2430  decode.d1.loss_mask: 0.9801  decode.d1.loss_dice: 0.6533  decode.d2.loss_cls: 0.2151  decode.d2.loss_mask: 0.9280  decode.d2.loss_dice: 0.6218  decode.d3.loss_cls: 0.1865  decode.d3.loss_mask: 0.9247  decode.d3.loss_dice: 0.6044  decode.d4.loss_cls: 0.1894  decode.d4.loss_mask: 0.9410  decode.d4.loss_dice: 0.6138  decode.d5.loss_cls: 0.1800  decode.d5.loss_mask: 0.9626  decode.d5.loss_dice: 0.6313  decode.d6.loss_cls: 0.1832  decode.d6.loss_mask: 0.9316  decode.d6.loss_dice: 0.6072  decode.d7.loss_cls: 0.1860  decode.d7.loss_mask: 0.9457  decode.d7.loss_dice: 0.6123  decode.d8.loss_cls: 0.2210  decode.d8.loss_mask: 0.9564  decode.d8.loss_dice: 0.6128
05/27 02:46:14 - mmengine - INFO - Iter(train) [133400/160000]  base_lr: 1.9892e-05 lr: 1.9892e-06  eta: 3:03:24  time: 0.4170  data_time: 0.0099  memory: 5968  grad_norm: 604.7667  loss: 19.0150  decode.loss_cls: 0.2294  decode.loss_mask: 0.9208  decode.loss_dice: 0.6624  decode.d0.loss_cls: 0.7166  decode.d0.loss_mask: 0.8833  decode.d0.loss_dice: 0.7029  decode.d1.loss_cls: 0.2369  decode.d1.loss_mask: 0.9319  decode.d1.loss_dice: 0.7093  decode.d2.loss_cls: 0.1913  decode.d2.loss_mask: 0.9461  decode.d2.loss_dice: 0.6956  decode.d3.loss_cls: 0.1773  decode.d3.loss_mask: 0.9476  decode.d3.loss_dice: 0.6816  decode.d4.loss_cls: 0.2367  decode.d4.loss_mask: 0.9608  decode.d4.loss_dice: 0.6833  decode.d5.loss_cls: 0.1529  decode.d5.loss_mask: 0.9944  decode.d5.loss_dice: 0.6972  decode.d6.loss_cls: 0.2164  decode.d6.loss_mask: 0.9680  decode.d6.loss_dice: 0.6829  decode.d7.loss_cls: 0.2207  decode.d7.loss_mask: 0.9934  decode.d7.loss_dice: 0.7187  decode.d8.loss_cls: 0.1885  decode.d8.loss_mask: 0.9611  decode.d8.loss_dice: 0.7070
05/27 02:46:35 - mmengine - INFO - Iter(train) [133450/160000]  base_lr: 1.9859e-05 lr: 1.9859e-06  eta: 3:03:03  time: 0.4191  data_time: 0.0100  memory: 5966  grad_norm: 467.1822  loss: 19.6232  decode.loss_cls: 0.1393  decode.loss_mask: 1.0481  decode.loss_dice: 0.7077  decode.d0.loss_cls: 0.7395  decode.d0.loss_mask: 1.0161  decode.d0.loss_dice: 0.6620  decode.d1.loss_cls: 0.1655  decode.d1.loss_mask: 1.0429  decode.d1.loss_dice: 0.6897  decode.d2.loss_cls: 0.1245  decode.d2.loss_mask: 1.0722  decode.d2.loss_dice: 0.7142  decode.d3.loss_cls: 0.1341  decode.d3.loss_mask: 1.0552  decode.d3.loss_dice: 0.7082  decode.d4.loss_cls: 0.1703  decode.d4.loss_mask: 1.0467  decode.d4.loss_dice: 0.6999  decode.d5.loss_cls: 0.1696  decode.d5.loss_mask: 1.0380  decode.d5.loss_dice: 0.6934  decode.d6.loss_cls: 0.1507  decode.d6.loss_mask: 1.0774  decode.d6.loss_dice: 0.7251  decode.d7.loss_cls: 0.1320  decode.d7.loss_mask: 1.0693  decode.d7.loss_dice: 0.7136  decode.d8.loss_cls: 0.1500  decode.d8.loss_mask: 1.0595  decode.d8.loss_dice: 0.7086
05/27 02:46:55 - mmengine - INFO - Iter(train) [133500/160000]  base_lr: 1.9825e-05 lr: 1.9825e-06  eta: 3:02:42  time: 0.4176  data_time: 0.0100  memory: 5968  grad_norm: 419.1673  loss: 16.9065  decode.loss_cls: 0.1321  decode.loss_mask: 0.8767  decode.loss_dice: 0.6209  decode.d0.loss_cls: 0.6136  decode.d0.loss_mask: 0.8831  decode.d0.loss_dice: 0.6351  decode.d1.loss_cls: 0.1465  decode.d1.loss_mask: 0.8865  decode.d1.loss_dice: 0.6354  decode.d2.loss_cls: 0.1438  decode.d2.loss_mask: 0.8728  decode.d2.loss_dice: 0.6263  decode.d3.loss_cls: 0.1341  decode.d3.loss_mask: 0.8612  decode.d3.loss_dice: 0.6128  decode.d4.loss_cls: 0.1482  decode.d4.loss_mask: 0.8683  decode.d4.loss_dice: 0.6227  decode.d5.loss_cls: 0.1332  decode.d5.loss_mask: 0.8687  decode.d5.loss_dice: 0.6282  decode.d6.loss_cls: 0.1408  decode.d6.loss_mask: 0.8600  decode.d6.loss_dice: 0.6295  decode.d7.loss_cls: 0.1538  decode.d7.loss_mask: 0.8769  decode.d7.loss_dice: 0.6269  decode.d8.loss_cls: 0.1541  decode.d8.loss_mask: 0.8806  decode.d8.loss_dice: 0.6336
05/27 02:47:16 - mmengine - INFO - Iter(train) [133550/160000]  base_lr: 1.9791e-05 lr: 1.9791e-06  eta: 3:02:22  time: 0.4169  data_time: 0.0099  memory: 5967  grad_norm: 586.9890  loss: 17.0976  decode.loss_cls: 0.0889  decode.loss_mask: 0.9344  decode.loss_dice: 0.6285  decode.d0.loss_cls: 0.5482  decode.d0.loss_mask: 0.9476  decode.d0.loss_dice: 0.6502  decode.d1.loss_cls: 0.1096  decode.d1.loss_mask: 0.9416  decode.d1.loss_dice: 0.6076  decode.d2.loss_cls: 0.1148  decode.d2.loss_mask: 0.9371  decode.d2.loss_dice: 0.6264  decode.d3.loss_cls: 0.1145  decode.d3.loss_mask: 0.9190  decode.d3.loss_dice: 0.6118  decode.d4.loss_cls: 0.1193  decode.d4.loss_mask: 0.9341  decode.d4.loss_dice: 0.6200  decode.d5.loss_cls: 0.1103  decode.d5.loss_mask: 0.9261  decode.d5.loss_dice: 0.6131  decode.d6.loss_cls: 0.1265  decode.d6.loss_mask: 0.9335  decode.d6.loss_dice: 0.6129  decode.d7.loss_cls: 0.0920  decode.d7.loss_mask: 0.9540  decode.d7.loss_dice: 0.6157  decode.d8.loss_cls: 0.1112  decode.d8.loss_mask: 0.9372  decode.d8.loss_dice: 0.6115
05/27 02:47:37 - mmengine - INFO - Iter(train) [133600/160000]  base_lr: 1.9758e-05 lr: 1.9758e-06  eta: 3:02:01  time: 0.4178  data_time: 0.0100  memory: 5974  grad_norm: 493.4573  loss: 20.7245  decode.loss_cls: 0.1679  decode.loss_mask: 1.0308  decode.loss_dice: 0.7973  decode.d0.loss_cls: 0.8004  decode.d0.loss_mask: 1.0093  decode.d0.loss_dice: 0.8177  decode.d1.loss_cls: 0.1452  decode.d1.loss_mask: 1.0586  decode.d1.loss_dice: 0.8363  decode.d2.loss_cls: 0.1372  decode.d2.loss_mask: 1.0538  decode.d2.loss_dice: 0.8113  decode.d3.loss_cls: 0.1267  decode.d3.loss_mask: 1.0486  decode.d3.loss_dice: 0.8155  decode.d4.loss_cls: 0.1348  decode.d4.loss_mask: 1.0627  decode.d4.loss_dice: 0.8096  decode.d5.loss_cls: 0.1272  decode.d5.loss_mask: 1.0722  decode.d5.loss_dice: 0.8223  decode.d6.loss_cls: 0.1421  decode.d6.loss_mask: 1.0608  decode.d6.loss_dice: 0.8072  decode.d7.loss_cls: 0.1744  decode.d7.loss_mask: 1.0757  decode.d7.loss_dice: 0.8012  decode.d8.loss_cls: 0.1566  decode.d8.loss_mask: 1.0287  decode.d8.loss_dice: 0.7927
05/27 02:47:58 - mmengine - INFO - Iter(train) [133650/160000]  base_lr: 1.9724e-05 lr: 1.9724e-06  eta: 3:01:40  time: 0.4173  data_time: 0.0100  memory: 5966  grad_norm: 474.0722  loss: 16.9502  decode.loss_cls: 0.1533  decode.loss_mask: 0.8359  decode.loss_dice: 0.6372  decode.d0.loss_cls: 0.6259  decode.d0.loss_mask: 0.9126  decode.d0.loss_dice: 0.6526  decode.d1.loss_cls: 0.1676  decode.d1.loss_mask: 0.8602  decode.d1.loss_dice: 0.6435  decode.d2.loss_cls: 0.1637  decode.d2.loss_mask: 0.8361  decode.d2.loss_dice: 0.6371  decode.d3.loss_cls: 0.1512  decode.d3.loss_mask: 0.8388  decode.d3.loss_dice: 0.6345  decode.d4.loss_cls: 0.1672  decode.d4.loss_mask: 0.8377  decode.d4.loss_dice: 0.6399  decode.d5.loss_cls: 0.1481  decode.d5.loss_mask: 0.8369  decode.d5.loss_dice: 0.6277  decode.d6.loss_cls: 0.1537  decode.d6.loss_mask: 0.8496  decode.d6.loss_dice: 0.6563  decode.d7.loss_cls: 0.1605  decode.d7.loss_mask: 0.8558  decode.d7.loss_dice: 0.6419  decode.d8.loss_cls: 0.1576  decode.d8.loss_mask: 0.8352  decode.d8.loss_dice: 0.6319
05/27 02:48:19 - mmengine - INFO - Iter(train) [133700/160000]  base_lr: 1.9690e-05 lr: 1.9690e-06  eta: 3:01:20  time: 0.4186  data_time: 0.0103  memory: 5979  grad_norm: 452.7438  loss: 17.9318  decode.loss_cls: 0.2685  decode.loss_mask: 0.7775  decode.loss_dice: 0.6969  decode.d0.loss_cls: 0.7153  decode.d0.loss_mask: 0.8317  decode.d0.loss_dice: 0.6908  decode.d1.loss_cls: 0.1919  decode.d1.loss_mask: 0.8251  decode.d1.loss_dice: 0.7460  decode.d2.loss_cls: 0.2936  decode.d2.loss_mask: 0.7650  decode.d2.loss_dice: 0.6709  decode.d3.loss_cls: 0.2594  decode.d3.loss_mask: 0.7961  decode.d3.loss_dice: 0.6851  decode.d4.loss_cls: 0.2524  decode.d4.loss_mask: 0.8023  decode.d4.loss_dice: 0.6840  decode.d5.loss_cls: 0.2397  decode.d5.loss_mask: 0.8001  decode.d5.loss_dice: 0.6981  decode.d6.loss_cls: 0.2453  decode.d6.loss_mask: 0.8106  decode.d6.loss_dice: 0.7177  decode.d7.loss_cls: 0.2389  decode.d7.loss_mask: 0.7929  decode.d7.loss_dice: 0.7114  decode.d8.loss_cls: 0.2112  decode.d8.loss_mask: 0.7971  decode.d8.loss_dice: 0.7163
05/27 02:48:40 - mmengine - INFO - Iter(train) [133750/160000]  base_lr: 1.9657e-05 lr: 1.9657e-06  eta: 3:00:59  time: 0.4195  data_time: 0.0103  memory: 5971  grad_norm: 604.6264  loss: 20.2940  decode.loss_cls: 0.1937  decode.loss_mask: 0.9757  decode.loss_dice: 0.8173  decode.d0.loss_cls: 0.6303  decode.d0.loss_mask: 0.9727  decode.d0.loss_dice: 0.8134  decode.d1.loss_cls: 0.2252  decode.d1.loss_mask: 1.0026  decode.d1.loss_dice: 0.8072  decode.d2.loss_cls: 0.1777  decode.d2.loss_mask: 0.9708  decode.d2.loss_dice: 0.8052  decode.d3.loss_cls: 0.1838  decode.d3.loss_mask: 0.9689  decode.d3.loss_dice: 0.8223  decode.d4.loss_cls: 0.2023  decode.d4.loss_mask: 0.9698  decode.d4.loss_dice: 0.8023  decode.d5.loss_cls: 0.2111  decode.d5.loss_mask: 0.9699  decode.d5.loss_dice: 0.8140  decode.d6.loss_cls: 0.1894  decode.d6.loss_mask: 0.9634  decode.d6.loss_dice: 0.8150  decode.d7.loss_cls: 0.2366  decode.d7.loss_mask: 0.9713  decode.d7.loss_dice: 0.8187  decode.d8.loss_cls: 0.1611  decode.d8.loss_mask: 0.9783  decode.d8.loss_dice: 0.8240
05/27 02:49:01 - mmengine - INFO - Iter(train) [133800/160000]  base_lr: 1.9623e-05 lr: 1.9623e-06  eta: 3:00:39  time: 0.4165  data_time: 0.0101  memory: 5966  grad_norm: 449.2767  loss: 16.5640  decode.loss_cls: 0.1569  decode.loss_mask: 0.8364  decode.loss_dice: 0.6123  decode.d0.loss_cls: 0.6108  decode.d0.loss_mask: 0.8925  decode.d0.loss_dice: 0.5845  decode.d1.loss_cls: 0.1465  decode.d1.loss_mask: 0.8466  decode.d1.loss_dice: 0.6144  decode.d2.loss_cls: 0.1518  decode.d2.loss_mask: 0.8626  decode.d2.loss_dice: 0.6268  decode.d3.loss_cls: 0.1373  decode.d3.loss_mask: 0.8462  decode.d3.loss_dice: 0.6126  decode.d4.loss_cls: 0.1563  decode.d4.loss_mask: 0.8433  decode.d4.loss_dice: 0.6109  decode.d5.loss_cls: 0.1559  decode.d5.loss_mask: 0.8425  decode.d5.loss_dice: 0.6060  decode.d6.loss_cls: 0.1778  decode.d6.loss_mask: 0.8548  decode.d6.loss_dice: 0.6082  decode.d7.loss_cls: 0.1459  decode.d7.loss_mask: 0.8416  decode.d7.loss_dice: 0.6109  decode.d8.loss_cls: 0.1385  decode.d8.loss_mask: 0.8294  decode.d8.loss_dice: 0.6040
05/27 02:49:22 - mmengine - INFO - Iter(train) [133850/160000]  base_lr: 1.9589e-05 lr: 1.9589e-06  eta: 3:00:18  time: 0.4169  data_time: 0.0100  memory: 5973  grad_norm: 610.8077  loss: 21.1553  decode.loss_cls: 0.2026  decode.loss_mask: 1.1044  decode.loss_dice: 0.7418  decode.d0.loss_cls: 0.7679  decode.d0.loss_mask: 1.0810  decode.d0.loss_dice: 0.7101  decode.d1.loss_cls: 0.2151  decode.d1.loss_mask: 1.0827  decode.d1.loss_dice: 0.7534  decode.d2.loss_cls: 0.2211  decode.d2.loss_mask: 1.1228  decode.d2.loss_dice: 0.7542  decode.d3.loss_cls: 0.2081  decode.d3.loss_mask: 1.0897  decode.d3.loss_dice: 0.7892  decode.d4.loss_cls: 0.2139  decode.d4.loss_mask: 1.1080  decode.d4.loss_dice: 0.7465  decode.d5.loss_cls: 0.2194  decode.d5.loss_mask: 1.0966  decode.d5.loss_dice: 0.7269  decode.d6.loss_cls: 0.2644  decode.d6.loss_mask: 1.0777  decode.d6.loss_dice: 0.7606  decode.d7.loss_cls: 0.1883  decode.d7.loss_mask: 1.0951  decode.d7.loss_dice: 0.7547  decode.d8.loss_cls: 0.2032  decode.d8.loss_mask: 1.0957  decode.d8.loss_dice: 0.7602
05/27 02:49:43 - mmengine - INFO - Iter(train) [133900/160000]  base_lr: 1.9556e-05 lr: 1.9556e-06  eta: 2:59:57  time: 0.4177  data_time: 0.0100  memory: 5969  grad_norm: 588.1066  loss: 19.4245  decode.loss_cls: 0.1604  decode.loss_mask: 1.0733  decode.loss_dice: 0.6612  decode.d0.loss_cls: 0.6474  decode.d0.loss_mask: 1.0230  decode.d0.loss_dice: 0.6502  decode.d1.loss_cls: 0.1969  decode.d1.loss_mask: 1.0586  decode.d1.loss_dice: 0.6699  decode.d2.loss_cls: 0.1787  decode.d2.loss_mask: 1.0512  decode.d2.loss_dice: 0.6581  decode.d3.loss_cls: 0.1601  decode.d3.loss_mask: 1.0701  decode.d3.loss_dice: 0.6592  decode.d4.loss_cls: 0.1643  decode.d4.loss_mask: 1.0591  decode.d4.loss_dice: 0.6786  decode.d5.loss_cls: 0.1633  decode.d5.loss_mask: 1.0803  decode.d5.loss_dice: 0.6974  decode.d6.loss_cls: 0.1571  decode.d6.loss_mask: 1.0664  decode.d6.loss_dice: 0.6677  decode.d7.loss_cls: 0.1638  decode.d7.loss_mask: 1.0595  decode.d7.loss_dice: 0.6503  decode.d8.loss_cls: 0.1710  decode.d8.loss_mask: 1.0624  decode.d8.loss_dice: 0.6653
05/27 02:50:04 - mmengine - INFO - Iter(train) [133950/160000]  base_lr: 1.9522e-05 lr: 1.9522e-06  eta: 2:59:37  time: 0.4185  data_time: 0.0100  memory: 5966  grad_norm: 714.2890  loss: 20.8926  decode.loss_cls: 0.2082  decode.loss_mask: 1.0539  decode.loss_dice: 0.7687  decode.d0.loss_cls: 0.8169  decode.d0.loss_mask: 0.9803  decode.d0.loss_dice: 0.7321  decode.d1.loss_cls: 0.2369  decode.d1.loss_mask: 1.0342  decode.d1.loss_dice: 0.7659  decode.d2.loss_cls: 0.2349  decode.d2.loss_mask: 1.0354  decode.d2.loss_dice: 0.7652  decode.d3.loss_cls: 0.2398  decode.d3.loss_mask: 1.0462  decode.d3.loss_dice: 0.7704  decode.d4.loss_cls: 0.2138  decode.d4.loss_mask: 1.0531  decode.d4.loss_dice: 0.7785  decode.d5.loss_cls: 0.2264  decode.d5.loss_mask: 1.0540  decode.d5.loss_dice: 0.7580  decode.d6.loss_cls: 0.2313  decode.d6.loss_mask: 1.0409  decode.d6.loss_dice: 0.7580  decode.d7.loss_cls: 0.1924  decode.d7.loss_mask: 1.0627  decode.d7.loss_dice: 0.7737  decode.d8.loss_cls: 0.2130  decode.d8.loss_mask: 1.0648  decode.d8.loss_dice: 0.7829
05/27 02:50:24 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 02:50:24 - mmengine - INFO - Iter(train) [134000/160000]  base_lr: 1.9488e-05 lr: 1.9488e-06  eta: 2:59:16  time: 0.4174  data_time: 0.0100  memory: 5975  grad_norm: 497.6778  loss: 17.9384  decode.loss_cls: 0.2013  decode.loss_mask: 0.8555  decode.loss_dice: 0.7131  decode.d0.loss_cls: 0.6290  decode.d0.loss_mask: 0.8117  decode.d0.loss_dice: 0.6755  decode.d1.loss_cls: 0.2084  decode.d1.loss_mask: 0.8475  decode.d1.loss_dice: 0.6842  decode.d2.loss_cls: 0.2149  decode.d2.loss_mask: 0.8477  decode.d2.loss_dice: 0.7113  decode.d3.loss_cls: 0.2066  decode.d3.loss_mask: 0.8443  decode.d3.loss_dice: 0.7084  decode.d4.loss_cls: 0.1941  decode.d4.loss_mask: 0.8775  decode.d4.loss_dice: 0.7238  decode.d5.loss_cls: 0.1984  decode.d5.loss_mask: 0.8506  decode.d5.loss_dice: 0.7209  decode.d6.loss_cls: 0.1900  decode.d6.loss_mask: 0.8548  decode.d6.loss_dice: 0.7173  decode.d7.loss_cls: 0.1984  decode.d7.loss_mask: 0.8363  decode.d7.loss_dice: 0.6969  decode.d8.loss_cls: 0.2051  decode.d8.loss_mask: 0.8347  decode.d8.loss_dice: 0.6803
05/27 02:50:45 - mmengine - INFO - Iter(train) [134050/160000]  base_lr: 1.9454e-05 lr: 1.9454e-06  eta: 2:58:55  time: 0.4172  data_time: 0.0100  memory: 5965  grad_norm: 1547.8611  loss: 18.1201  decode.loss_cls: 0.1044  decode.loss_mask: 0.9919  decode.loss_dice: 0.6783  decode.d0.loss_cls: 0.5939  decode.d0.loss_mask: 0.9750  decode.d0.loss_dice: 0.6489  decode.d1.loss_cls: 0.1094  decode.d1.loss_mask: 0.9950  decode.d1.loss_dice: 0.6731  decode.d2.loss_cls: 0.1114  decode.d2.loss_mask: 1.0083  decode.d2.loss_dice: 0.6701  decode.d3.loss_cls: 0.0989  decode.d3.loss_mask: 1.0027  decode.d3.loss_dice: 0.6575  decode.d4.loss_cls: 0.1061  decode.d4.loss_mask: 1.0010  decode.d4.loss_dice: 0.6787  decode.d5.loss_cls: 0.0861  decode.d5.loss_mask: 1.0081  decode.d5.loss_dice: 0.6670  decode.d6.loss_cls: 0.1103  decode.d6.loss_mask: 1.0059  decode.d6.loss_dice: 0.6694  decode.d7.loss_cls: 0.0732  decode.d7.loss_mask: 0.9917  decode.d7.loss_dice: 0.6571  decode.d8.loss_cls: 0.0874  decode.d8.loss_mask: 1.0038  decode.d8.loss_dice: 0.6556
05/27 02:51:06 - mmengine - INFO - Iter(train) [134100/160000]  base_lr: 1.9421e-05 lr: 1.9421e-06  eta: 2:58:35  time: 0.4176  data_time: 0.0100  memory: 5971  grad_norm: 467.7815  loss: 19.6495  decode.loss_cls: 0.2054  decode.loss_mask: 1.0062  decode.loss_dice: 0.7092  decode.d0.loss_cls: 0.7600  decode.d0.loss_mask: 0.9646  decode.d0.loss_dice: 0.7188  decode.d1.loss_cls: 0.1815  decode.d1.loss_mask: 0.9844  decode.d1.loss_dice: 0.7345  decode.d2.loss_cls: 0.2141  decode.d2.loss_mask: 0.9708  decode.d2.loss_dice: 0.6944  decode.d3.loss_cls: 0.1970  decode.d3.loss_mask: 0.9978  decode.d3.loss_dice: 0.7024  decode.d4.loss_cls: 0.2533  decode.d4.loss_mask: 0.9934  decode.d4.loss_dice: 0.7151  decode.d5.loss_cls: 0.1879  decode.d5.loss_mask: 0.9843  decode.d5.loss_dice: 0.7137  decode.d6.loss_cls: 0.2112  decode.d6.loss_mask: 0.9876  decode.d6.loss_dice: 0.7477  decode.d7.loss_cls: 0.1802  decode.d7.loss_mask: 0.9808  decode.d7.loss_dice: 0.7104  decode.d8.loss_cls: 0.2173  decode.d8.loss_mask: 1.0009  decode.d8.loss_dice: 0.7242
05/27 02:51:27 - mmengine - INFO - Iter(train) [134150/160000]  base_lr: 1.9387e-05 lr: 1.9387e-06  eta: 2:58:14  time: 0.4177  data_time: 0.0100  memory: 5967  grad_norm: 630.5496  loss: 17.4998  decode.loss_cls: 0.1557  decode.loss_mask: 0.9189  decode.loss_dice: 0.5993  decode.d0.loss_cls: 0.6078  decode.d0.loss_mask: 0.9030  decode.d0.loss_dice: 0.6065  decode.d1.loss_cls: 0.1971  decode.d1.loss_mask: 0.9100  decode.d1.loss_dice: 0.6224  decode.d2.loss_cls: 0.1969  decode.d2.loss_mask: 0.9051  decode.d2.loss_dice: 0.6136  decode.d3.loss_cls: 0.1729  decode.d3.loss_mask: 0.9068  decode.d3.loss_dice: 0.6018  decode.d4.loss_cls: 0.1856  decode.d4.loss_mask: 0.9196  decode.d4.loss_dice: 0.6196  decode.d5.loss_cls: 0.1824  decode.d5.loss_mask: 0.8928  decode.d5.loss_dice: 0.6061  decode.d6.loss_cls: 0.1992  decode.d6.loss_mask: 0.9086  decode.d6.loss_dice: 0.5928  decode.d7.loss_cls: 0.1925  decode.d7.loss_mask: 0.9204  decode.d7.loss_dice: 0.6048  decode.d8.loss_cls: 0.1804  decode.d8.loss_mask: 0.9730  decode.d8.loss_dice: 0.6043
05/27 02:51:48 - mmengine - INFO - Iter(train) [134200/160000]  base_lr: 1.9353e-05 lr: 1.9353e-06  eta: 2:57:53  time: 0.4164  data_time: 0.0100  memory: 5966  grad_norm: 474.9787  loss: 17.5149  decode.loss_cls: 0.1435  decode.loss_mask: 0.9277  decode.loss_dice: 0.6207  decode.d0.loss_cls: 0.6408  decode.d0.loss_mask: 0.9098  decode.d0.loss_dice: 0.6258  decode.d1.loss_cls: 0.1869  decode.d1.loss_mask: 0.9088  decode.d1.loss_dice: 0.5890  decode.d2.loss_cls: 0.1236  decode.d2.loss_mask: 0.9257  decode.d2.loss_dice: 0.6298  decode.d3.loss_cls: 0.2102  decode.d3.loss_mask: 0.9036  decode.d3.loss_dice: 0.6120  decode.d4.loss_cls: 0.1220  decode.d4.loss_mask: 0.9353  decode.d4.loss_dice: 0.6329  decode.d5.loss_cls: 0.1467  decode.d5.loss_mask: 0.9587  decode.d5.loss_dice: 0.6517  decode.d6.loss_cls: 0.1542  decode.d6.loss_mask: 0.9484  decode.d6.loss_dice: 0.6254  decode.d7.loss_cls: 0.1653  decode.d7.loss_mask: 0.9090  decode.d7.loss_dice: 0.6018  decode.d8.loss_cls: 0.1539  decode.d8.loss_mask: 0.9260  decode.d8.loss_dice: 0.6258
05/27 02:52:09 - mmengine - INFO - Iter(train) [134250/160000]  base_lr: 1.9319e-05 lr: 1.9319e-06  eta: 2:57:33  time: 0.4174  data_time: 0.0104  memory: 5975  grad_norm: 462.1505  loss: 17.6976  decode.loss_cls: 0.1211  decode.loss_mask: 0.9830  decode.loss_dice: 0.5992  decode.d0.loss_cls: 0.6954  decode.d0.loss_mask: 0.9421  decode.d0.loss_dice: 0.5961  decode.d1.loss_cls: 0.1261  decode.d1.loss_mask: 0.9598  decode.d1.loss_dice: 0.6360  decode.d2.loss_cls: 0.1233  decode.d2.loss_mask: 0.9529  decode.d2.loss_dice: 0.6094  decode.d3.loss_cls: 0.1573  decode.d3.loss_mask: 0.9737  decode.d3.loss_dice: 0.6055  decode.d4.loss_cls: 0.1475  decode.d4.loss_mask: 0.9652  decode.d4.loss_dice: 0.5894  decode.d5.loss_cls: 0.1589  decode.d5.loss_mask: 0.9586  decode.d5.loss_dice: 0.6010  decode.d6.loss_cls: 0.1373  decode.d6.loss_mask: 0.9875  decode.d6.loss_dice: 0.5990  decode.d7.loss_cls: 0.1378  decode.d7.loss_mask: 0.9852  decode.d7.loss_dice: 0.6190  decode.d8.loss_cls: 0.1310  decode.d8.loss_mask: 0.9797  decode.d8.loss_dice: 0.6198
05/27 02:52:30 - mmengine - INFO - Iter(train) [134300/160000]  base_lr: 1.9286e-05 lr: 1.9286e-06  eta: 2:57:12  time: 0.4176  data_time: 0.0100  memory: 5982  grad_norm: 536.1307  loss: 20.5435  decode.loss_cls: 0.1427  decode.loss_mask: 1.1042  decode.loss_dice: 0.7278  decode.d0.loss_cls: 0.7220  decode.d0.loss_mask: 1.0830  decode.d0.loss_dice: 0.7470  decode.d1.loss_cls: 0.1457  decode.d1.loss_mask: 1.1098  decode.d1.loss_dice: 0.7409  decode.d2.loss_cls: 0.1507  decode.d2.loss_mask: 1.1191  decode.d2.loss_dice: 0.7345  decode.d3.loss_cls: 0.1488  decode.d3.loss_mask: 1.0997  decode.d3.loss_dice: 0.7217  decode.d4.loss_cls: 0.1637  decode.d4.loss_mask: 1.1176  decode.d4.loss_dice: 0.7454  decode.d5.loss_cls: 0.1456  decode.d5.loss_mask: 1.1122  decode.d5.loss_dice: 0.7397  decode.d6.loss_cls: 0.1518  decode.d6.loss_mask: 1.1218  decode.d6.loss_dice: 0.7383  decode.d7.loss_cls: 0.1483  decode.d7.loss_mask: 1.1032  decode.d7.loss_dice: 0.7481  decode.d8.loss_cls: 0.1529  decode.d8.loss_mask: 1.1187  decode.d8.loss_dice: 0.7388
05/27 02:52:51 - mmengine - INFO - Iter(train) [134350/160000]  base_lr: 1.9252e-05 lr: 1.9252e-06  eta: 2:56:51  time: 0.4169  data_time: 0.0099  memory: 5966  grad_norm: 421.6579  loss: 16.6363  decode.loss_cls: 0.1579  decode.loss_mask: 0.8355  decode.loss_dice: 0.6076  decode.d0.loss_cls: 0.6421  decode.d0.loss_mask: 0.8765  decode.d0.loss_dice: 0.6190  decode.d1.loss_cls: 0.1562  decode.d1.loss_mask: 0.8454  decode.d1.loss_dice: 0.6172  decode.d2.loss_cls: 0.1450  decode.d2.loss_mask: 0.8435  decode.d2.loss_dice: 0.6161  decode.d3.loss_cls: 0.1395  decode.d3.loss_mask: 0.8442  decode.d3.loss_dice: 0.6070  decode.d4.loss_cls: 0.1635  decode.d4.loss_mask: 0.8454  decode.d4.loss_dice: 0.6083  decode.d5.loss_cls: 0.1696  decode.d5.loss_mask: 0.8365  decode.d5.loss_dice: 0.6121  decode.d6.loss_cls: 0.1715  decode.d6.loss_mask: 0.8388  decode.d6.loss_dice: 0.6219  decode.d7.loss_cls: 0.1487  decode.d7.loss_mask: 0.8401  decode.d7.loss_dice: 0.6219  decode.d8.loss_cls: 0.1601  decode.d8.loss_mask: 0.8284  decode.d8.loss_dice: 0.6170
05/27 02:53:12 - mmengine - INFO - Iter(train) [134400/160000]  base_lr: 1.9218e-05 lr: 1.9218e-06  eta: 2:56:31  time: 0.4175  data_time: 0.0100  memory: 5970  grad_norm: 413.8584  loss: 22.3459  decode.loss_cls: 0.1957  decode.loss_mask: 1.1592  decode.loss_dice: 0.8308  decode.d0.loss_cls: 0.7107  decode.d0.loss_mask: 1.0817  decode.d0.loss_dice: 0.7769  decode.d1.loss_cls: 0.2359  decode.d1.loss_mask: 1.1514  decode.d1.loss_dice: 0.8218  decode.d2.loss_cls: 0.2199  decode.d2.loss_mask: 1.1259  decode.d2.loss_dice: 0.8378  decode.d3.loss_cls: 0.2240  decode.d3.loss_mask: 1.1484  decode.d3.loss_dice: 0.8347  decode.d4.loss_cls: 0.2046  decode.d4.loss_mask: 1.1582  decode.d4.loss_dice: 0.8224  decode.d5.loss_cls: 0.2514  decode.d5.loss_mask: 1.1534  decode.d5.loss_dice: 0.8142  decode.d6.loss_cls: 0.1989  decode.d6.loss_mask: 1.1641  decode.d6.loss_dice: 0.8458  decode.d7.loss_cls: 0.2443  decode.d7.loss_mask: 1.1499  decode.d7.loss_dice: 0.8228  decode.d8.loss_cls: 0.2256  decode.d8.loss_mask: 1.1166  decode.d8.loss_dice: 0.8188
05/27 02:53:33 - mmengine - INFO - Iter(train) [134450/160000]  base_lr: 1.9184e-05 lr: 1.9184e-06  eta: 2:56:10  time: 0.4167  data_time: 0.0100  memory: 5974  grad_norm: 723.7819  loss: 18.7611  decode.loss_cls: 0.2042  decode.loss_mask: 0.9383  decode.loss_dice: 0.6835  decode.d0.loss_cls: 0.6888  decode.d0.loss_mask: 0.9259  decode.d0.loss_dice: 0.6722  decode.d1.loss_cls: 0.1986  decode.d1.loss_mask: 0.9876  decode.d1.loss_dice: 0.6639  decode.d2.loss_cls: 0.1573  decode.d2.loss_mask: 0.9801  decode.d2.loss_dice: 0.6655  decode.d3.loss_cls: 0.1838  decode.d3.loss_mask: 0.9704  decode.d3.loss_dice: 0.6561  decode.d4.loss_cls: 0.2164  decode.d4.loss_mask: 0.9716  decode.d4.loss_dice: 0.6513  decode.d5.loss_cls: 0.1576  decode.d5.loss_mask: 0.9896  decode.d5.loss_dice: 0.6807  decode.d6.loss_cls: 0.1501  decode.d6.loss_mask: 1.0154  decode.d6.loss_dice: 0.6921  decode.d7.loss_cls: 0.1480  decode.d7.loss_mask: 0.9875  decode.d7.loss_dice: 0.6770  decode.d8.loss_cls: 0.1652  decode.d8.loss_mask: 1.0002  decode.d8.loss_dice: 0.6823
05/27 02:53:53 - mmengine - INFO - Iter(train) [134500/160000]  base_lr: 1.9151e-05 lr: 1.9151e-06  eta: 2:55:49  time: 0.4170  data_time: 0.0100  memory: 5969  grad_norm: 400.5325  loss: 21.0307  decode.loss_cls: 0.2341  decode.loss_mask: 1.0510  decode.loss_dice: 0.7466  decode.d0.loss_cls: 0.6720  decode.d0.loss_mask: 1.0492  decode.d0.loss_dice: 0.7527  decode.d1.loss_cls: 0.2686  decode.d1.loss_mask: 1.0435  decode.d1.loss_dice: 0.7845  decode.d2.loss_cls: 0.2177  decode.d2.loss_mask: 1.0606  decode.d2.loss_dice: 0.7718  decode.d3.loss_cls: 0.2891  decode.d3.loss_mask: 1.0254  decode.d3.loss_dice: 0.7462  decode.d4.loss_cls: 0.2297  decode.d4.loss_mask: 1.0588  decode.d4.loss_dice: 0.7659  decode.d5.loss_cls: 0.2668  decode.d5.loss_mask: 1.0504  decode.d5.loss_dice: 0.7567  decode.d6.loss_cls: 0.3036  decode.d6.loss_mask: 1.0415  decode.d6.loss_dice: 0.7470  decode.d7.loss_cls: 0.2445  decode.d7.loss_mask: 1.0619  decode.d7.loss_dice: 0.7475  decode.d8.loss_cls: 0.2429  decode.d8.loss_mask: 1.0518  decode.d8.loss_dice: 0.7489
05/27 02:54:14 - mmengine - INFO - Iter(train) [134550/160000]  base_lr: 1.9117e-05 lr: 1.9117e-06  eta: 2:55:29  time: 0.4165  data_time: 0.0100  memory: 5966  grad_norm: 388.3046  loss: 18.5687  decode.loss_cls: 0.1909  decode.loss_mask: 0.9713  decode.loss_dice: 0.6327  decode.d0.loss_cls: 0.6995  decode.d0.loss_mask: 0.9452  decode.d0.loss_dice: 0.6529  decode.d1.loss_cls: 0.2127  decode.d1.loss_mask: 0.9957  decode.d1.loss_dice: 0.6817  decode.d2.loss_cls: 0.1791  decode.d2.loss_mask: 0.9652  decode.d2.loss_dice: 0.6592  decode.d3.loss_cls: 0.1796  decode.d3.loss_mask: 0.9626  decode.d3.loss_dice: 0.6331  decode.d4.loss_cls: 0.1969  decode.d4.loss_mask: 0.9782  decode.d4.loss_dice: 0.6333  decode.d5.loss_cls: 0.2191  decode.d5.loss_mask: 0.9427  decode.d5.loss_dice: 0.6413  decode.d6.loss_cls: 0.1795  decode.d6.loss_mask: 0.9807  decode.d6.loss_dice: 0.6286  decode.d7.loss_cls: 0.1863  decode.d7.loss_mask: 0.9720  decode.d7.loss_dice: 0.6580  decode.d8.loss_cls: 0.1656  decode.d8.loss_mask: 0.9804  decode.d8.loss_dice: 0.6447
05/27 02:54:35 - mmengine - INFO - Iter(train) [134600/160000]  base_lr: 1.9083e-05 lr: 1.9083e-06  eta: 2:55:08  time: 0.4176  data_time: 0.0100  memory: 5971  grad_norm: 338.0837  loss: 14.5829  decode.loss_cls: 0.0923  decode.loss_mask: 0.7570  decode.loss_dice: 0.5711  decode.d0.loss_cls: 0.5204  decode.d0.loss_mask: 0.6949  decode.d0.loss_dice: 0.5304  decode.d1.loss_cls: 0.1236  decode.d1.loss_mask: 0.7479  decode.d1.loss_dice: 0.5695  decode.d2.loss_cls: 0.1062  decode.d2.loss_mask: 0.7489  decode.d2.loss_dice: 0.5698  decode.d3.loss_cls: 0.0797  decode.d3.loss_mask: 0.7527  decode.d3.loss_dice: 0.5829  decode.d4.loss_cls: 0.0919  decode.d4.loss_mask: 0.7697  decode.d4.loss_dice: 0.5810  decode.d5.loss_cls: 0.0846  decode.d5.loss_mask: 0.7627  decode.d5.loss_dice: 0.5701  decode.d6.loss_cls: 0.0976  decode.d6.loss_mask: 0.7510  decode.d6.loss_dice: 0.5696  decode.d7.loss_cls: 0.0953  decode.d7.loss_mask: 0.7494  decode.d7.loss_dice: 0.5818  decode.d8.loss_cls: 0.1027  decode.d8.loss_mask: 0.7550  decode.d8.loss_dice: 0.5732
05/27 02:54:56 - mmengine - INFO - Iter(train) [134650/160000]  base_lr: 1.9049e-05 lr: 1.9049e-06  eta: 2:54:48  time: 0.4166  data_time: 0.0100  memory: 5969  grad_norm: 570.3701  loss: 16.1936  decode.loss_cls: 0.0592  decode.loss_mask: 0.8981  decode.loss_dice: 0.6204  decode.d0.loss_cls: 0.6014  decode.d0.loss_mask: 0.7510  decode.d0.loss_dice: 0.6168  decode.d1.loss_cls: 0.0974  decode.d1.loss_mask: 0.8965  decode.d1.loss_dice: 0.6449  decode.d2.loss_cls: 0.0684  decode.d2.loss_mask: 0.8984  decode.d2.loss_dice: 0.6102  decode.d3.loss_cls: 0.0644  decode.d3.loss_mask: 0.8981  decode.d3.loss_dice: 0.6122  decode.d4.loss_cls: 0.0713  decode.d4.loss_mask: 0.9165  decode.d4.loss_dice: 0.6373  decode.d5.loss_cls: 0.0617  decode.d5.loss_mask: 0.8859  decode.d5.loss_dice: 0.6186  decode.d6.loss_cls: 0.1046  decode.d6.loss_mask: 0.8098  decode.d6.loss_dice: 0.6229  decode.d7.loss_cls: 0.0641  decode.d7.loss_mask: 0.8959  decode.d7.loss_dice: 0.6174  decode.d8.loss_cls: 0.0559  decode.d8.loss_mask: 0.8810  decode.d8.loss_dice: 0.6133
05/27 02:55:17 - mmengine - INFO - Iter(train) [134700/160000]  base_lr: 1.9015e-05 lr: 1.9015e-06  eta: 2:54:27  time: 0.4179  data_time: 0.0101  memory: 5968  grad_norm: 574.8268  loss: 21.8558  decode.loss_cls: 0.1111  decode.loss_mask: 1.2002  decode.loss_dice: 0.7968  decode.d0.loss_cls: 0.6634  decode.d0.loss_mask: 1.1876  decode.d0.loss_dice: 0.7909  decode.d1.loss_cls: 0.1704  decode.d1.loss_mask: 1.1820  decode.d1.loss_dice: 0.8123  decode.d2.loss_cls: 0.1396  decode.d2.loss_mask: 1.1896  decode.d2.loss_dice: 0.8063  decode.d3.loss_cls: 0.1690  decode.d3.loss_mask: 1.1711  decode.d3.loss_dice: 0.7973  decode.d4.loss_cls: 0.1114  decode.d4.loss_mask: 1.2166  decode.d4.loss_dice: 0.8165  decode.d5.loss_cls: 0.1222  decode.d5.loss_mask: 1.2219  decode.d5.loss_dice: 0.8043  decode.d6.loss_cls: 0.1482  decode.d6.loss_mask: 1.2030  decode.d6.loss_dice: 0.8240  decode.d7.loss_cls: 0.1249  decode.d7.loss_mask: 1.1758  decode.d7.loss_dice: 0.7920  decode.d8.loss_cls: 0.1084  decode.d8.loss_mask: 1.2083  decode.d8.loss_dice: 0.7906
05/27 02:55:38 - mmengine - INFO - Iter(train) [134750/160000]  base_lr: 1.8981e-05 lr: 1.8981e-06  eta: 2:54:06  time: 0.4182  data_time: 0.0100  memory: 5972  grad_norm: 866.4148  loss: 17.7776  decode.loss_cls: 0.2177  decode.loss_mask: 0.8656  decode.loss_dice: 0.6008  decode.d0.loss_cls: 0.6427  decode.d0.loss_mask: 0.9395  decode.d0.loss_dice: 0.6448  decode.d1.loss_cls: 0.1943  decode.d1.loss_mask: 0.9305  decode.d1.loss_dice: 0.6603  decode.d2.loss_cls: 0.2434  decode.d2.loss_mask: 0.9087  decode.d2.loss_dice: 0.6120  decode.d3.loss_cls: 0.2253  decode.d3.loss_mask: 0.8949  decode.d3.loss_dice: 0.5996  decode.d4.loss_cls: 0.1907  decode.d4.loss_mask: 0.9056  decode.d4.loss_dice: 0.6301  decode.d5.loss_cls: 0.2259  decode.d5.loss_mask: 0.8641  decode.d5.loss_dice: 0.6054  decode.d6.loss_cls: 0.2577  decode.d6.loss_mask: 0.8631  decode.d6.loss_dice: 0.5949  decode.d7.loss_cls: 0.2414  decode.d7.loss_mask: 0.8688  decode.d7.loss_dice: 0.6125  decode.d8.loss_cls: 0.2338  decode.d8.loss_mask: 0.8790  decode.d8.loss_dice: 0.6242
05/27 02:55:59 - mmengine - INFO - Iter(train) [134800/160000]  base_lr: 1.8948e-05 lr: 1.8948e-06  eta: 2:53:46  time: 0.4204  data_time: 0.0104  memory: 5972  grad_norm: 438.9659  loss: 16.6339  decode.loss_cls: 0.2054  decode.loss_mask: 0.8171  decode.loss_dice: 0.6197  decode.d0.loss_cls: 0.7050  decode.d0.loss_mask: 0.7294  decode.d0.loss_dice: 0.5633  decode.d1.loss_cls: 0.3020  decode.d1.loss_mask: 0.7514  decode.d1.loss_dice: 0.6159  decode.d2.loss_cls: 0.2492  decode.d2.loss_mask: 0.7512  decode.d2.loss_dice: 0.6192  decode.d3.loss_cls: 0.2219  decode.d3.loss_mask: 0.7638  decode.d3.loss_dice: 0.6193  decode.d4.loss_cls: 0.2488  decode.d4.loss_mask: 0.7541  decode.d4.loss_dice: 0.6146  decode.d5.loss_cls: 0.2479  decode.d5.loss_mask: 0.7535  decode.d5.loss_dice: 0.6085  decode.d6.loss_cls: 0.2573  decode.d6.loss_mask: 0.7478  decode.d6.loss_dice: 0.5919  decode.d7.loss_cls: 0.2646  decode.d7.loss_mask: 0.7530  decode.d7.loss_dice: 0.6094  decode.d8.loss_cls: 0.2039  decode.d8.loss_mask: 0.8209  decode.d8.loss_dice: 0.6239
05/27 02:56:20 - mmengine - INFO - Iter(train) [134850/160000]  base_lr: 1.8914e-05 lr: 1.8914e-06  eta: 2:53:25  time: 0.4182  data_time: 0.0099  memory: 5967  grad_norm: 625.3020  loss: 19.9989  decode.loss_cls: 0.1942  decode.loss_mask: 0.9836  decode.loss_dice: 0.7626  decode.d0.loss_cls: 0.7820  decode.d0.loss_mask: 0.9509  decode.d0.loss_dice: 0.7790  decode.d1.loss_cls: 0.1974  decode.d1.loss_mask: 1.0107  decode.d1.loss_dice: 0.7877  decode.d2.loss_cls: 0.1842  decode.d2.loss_mask: 0.9722  decode.d2.loss_dice: 0.7542  decode.d3.loss_cls: 0.1876  decode.d3.loss_mask: 0.9689  decode.d3.loss_dice: 0.7692  decode.d4.loss_cls: 0.1965  decode.d4.loss_mask: 0.9710  decode.d4.loss_dice: 0.7696  decode.d5.loss_cls: 0.2066  decode.d5.loss_mask: 0.9796  decode.d5.loss_dice: 0.7868  decode.d6.loss_cls: 0.2003  decode.d6.loss_mask: 0.9894  decode.d6.loss_dice: 0.7738  decode.d7.loss_cls: 0.1491  decode.d7.loss_mask: 0.9752  decode.d7.loss_dice: 0.7836  decode.d8.loss_cls: 0.1649  decode.d8.loss_mask: 0.9795  decode.d8.loss_dice: 0.7884
05/27 02:56:41 - mmengine - INFO - Iter(train) [134900/160000]  base_lr: 1.8880e-05 lr: 1.8880e-06  eta: 2:53:04  time: 0.4167  data_time: 0.0100  memory: 5970  grad_norm: 579.8497  loss: 22.4617  decode.loss_cls: 0.1795  decode.loss_mask: 1.2198  decode.loss_dice: 0.7975  decode.d0.loss_cls: 0.5969  decode.d0.loss_mask: 1.2618  decode.d0.loss_dice: 0.7842  decode.d1.loss_cls: 0.1588  decode.d1.loss_mask: 1.2028  decode.d1.loss_dice: 0.8212  decode.d2.loss_cls: 0.1843  decode.d2.loss_mask: 1.2185  decode.d2.loss_dice: 0.8060  decode.d3.loss_cls: 0.1699  decode.d3.loss_mask: 1.1998  decode.d3.loss_dice: 0.8055  decode.d4.loss_cls: 0.1720  decode.d4.loss_mask: 1.2226  decode.d4.loss_dice: 0.8040  decode.d5.loss_cls: 0.1792  decode.d5.loss_mask: 1.2371  decode.d5.loss_dice: 0.8184  decode.d6.loss_cls: 0.1980  decode.d6.loss_mask: 1.2039  decode.d6.loss_dice: 0.7999  decode.d7.loss_cls: 0.2228  decode.d7.loss_mask: 1.1795  decode.d7.loss_dice: 0.8091  decode.d8.loss_cls: 0.2165  decode.d8.loss_mask: 1.1803  decode.d8.loss_dice: 0.8117
05/27 02:57:02 - mmengine - INFO - Iter(train) [134950/160000]  base_lr: 1.8846e-05 lr: 1.8846e-06  eta: 2:52:44  time: 0.4172  data_time: 0.0099  memory: 5971  grad_norm: 530.9158  loss: 20.7386  decode.loss_cls: 0.1574  decode.loss_mask: 1.0953  decode.loss_dice: 0.7913  decode.d0.loss_cls: 0.7149  decode.d0.loss_mask: 1.0518  decode.d0.loss_dice: 0.7739  decode.d1.loss_cls: 0.1704  decode.d1.loss_mask: 1.0748  decode.d1.loss_dice: 0.7751  decode.d2.loss_cls: 0.1651  decode.d2.loss_mask: 1.0699  decode.d2.loss_dice: 0.7827  decode.d3.loss_cls: 0.1731  decode.d3.loss_mask: 1.0711  decode.d3.loss_dice: 0.7801  decode.d4.loss_cls: 0.1664  decode.d4.loss_mask: 1.0645  decode.d4.loss_dice: 0.7729  decode.d5.loss_cls: 0.1637  decode.d5.loss_mask: 1.0790  decode.d5.loss_dice: 0.7754  decode.d6.loss_cls: 0.1536  decode.d6.loss_mask: 1.0930  decode.d6.loss_dice: 0.7870  decode.d7.loss_cls: 0.1760  decode.d7.loss_mask: 1.0762  decode.d7.loss_dice: 0.7702  decode.d8.loss_cls: 0.1751  decode.d8.loss_mask: 1.0610  decode.d8.loss_dice: 0.7778
05/27 02:57:22 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 02:57:22 - mmengine - INFO - Iter(train) [135000/160000]  base_lr: 1.8812e-05 lr: 1.8812e-06  eta: 2:52:23  time: 0.4189  data_time: 0.0103  memory: 5981  grad_norm: 342.0175  loss: 18.1537  decode.loss_cls: 0.1585  decode.loss_mask: 0.9482  decode.loss_dice: 0.6443  decode.d0.loss_cls: 0.7219  decode.d0.loss_mask: 0.9314  decode.d0.loss_dice: 0.6301  decode.d1.loss_cls: 0.1928  decode.d1.loss_mask: 0.9464  decode.d1.loss_dice: 0.6342  decode.d2.loss_cls: 0.1708  decode.d2.loss_mask: 0.9565  decode.d2.loss_dice: 0.6648  decode.d3.loss_cls: 0.1532  decode.d3.loss_mask: 0.9463  decode.d3.loss_dice: 0.6524  decode.d4.loss_cls: 0.1769  decode.d4.loss_mask: 0.9605  decode.d4.loss_dice: 0.6434  decode.d5.loss_cls: 0.1663  decode.d5.loss_mask: 0.9531  decode.d5.loss_dice: 0.6461  decode.d6.loss_cls: 0.1534  decode.d6.loss_mask: 0.9481  decode.d6.loss_dice: 0.6475  decode.d7.loss_cls: 0.1501  decode.d7.loss_mask: 0.9438  decode.d7.loss_dice: 0.6503  decode.d8.loss_cls: 0.1749  decode.d8.loss_mask: 0.9446  decode.d8.loss_dice: 0.6432
05/27 02:57:22 - mmengine - INFO - Saving checkpoint at 135000 iterations
05/27 02:57:27 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:09  time: 0.0501  data_time: 0.0023  memory: 1391  
05/27 02:57:29 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:05  time: 0.0477  data_time: 0.0012  memory: 1205  
05/27 02:57:32 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:03  time: 0.0504  data_time: 0.0013  memory: 1596  
05/27 02:57:34 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0485  data_time: 0.0012  memory: 1298  
05/27 02:57:37 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:58  time: 0.0478  data_time: 0.0012  memory: 1298  
05/27 02:57:39 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0476  data_time: 0.0012  memory: 1279  
05/27 02:57:41 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:53  time: 0.0477  data_time: 0.0012  memory: 1224  
05/27 02:57:44 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0490  data_time: 0.0012  memory: 1298  
05/27 02:57:46 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0473  data_time: 0.0012  memory: 1298  
05/27 02:57:49 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0512  data_time: 0.0013  memory: 1725  
05/27 02:57:51 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0478  data_time: 0.0012  memory: 1336  
05/27 02:57:54 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0479  data_time: 0.0012  memory: 1298  
05/27 02:57:56 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0485  data_time: 0.0012  memory: 1205  
05/27 02:57:58 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0489  data_time: 0.0012  memory: 1316  
05/27 02:58:01 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0475  data_time: 0.0012  memory: 1279  
05/27 02:58:03 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0512  data_time: 0.0012  memory: 1410  
05/27 02:58:06 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0475  data_time: 0.0012  memory: 1279  
05/27 02:58:08 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0485  data_time: 0.0012  memory: 1205  
05/27 02:58:10 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0483  data_time: 0.0012  memory: 1205  
05/27 02:58:13 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0480  data_time: 0.0012  memory: 1336  
05/27 02:58:15 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0476  data_time: 0.0012  memory: 1246  
05/27 02:58:18 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0500  data_time: 0.0012  memory: 1503  
05/27 02:58:20 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0475  data_time: 0.0013  memory: 1261  
05/27 02:58:22 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0485  data_time: 0.0012  memory: 1298  
05/27 02:58:25 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0478  data_time: 0.0012  memory: 1447  
05/27 02:58:27 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0475  data_time: 0.0012  memory: 1298  
05/27 02:58:30 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0490  data_time: 0.0012  memory: 1279  
05/27 02:58:32 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0477  data_time: 0.0012  memory: 1205  
05/27 02:58:34 - mmengine - INFO - per class results:
05/27 02:58:34 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.83 | 97.38 |
|  aeroplane  | 93.05 | 95.93 |
|   bicycle   | 45.32 | 96.52 |
|     bird    | 96.19 | 98.43 |
|     boat    |  70.0 | 94.36 |
|    bottle   | 84.87 | 94.79 |
|     bus     | 93.98 | 97.74 |
|     car     | 90.72 |  95.4 |
|     cat     | 95.66 | 98.38 |
|    chair    | 43.07 |  76.2 |
|     cow     | 84.34 | 88.91 |
| diningtable | 67.97 | 73.65 |
|     dog     | 93.11 | 98.63 |
|    horse    | 88.13 | 97.82 |
|  motorbike  | 88.93 | 92.45 |
|    person   |  91.1 | 94.49 |
| pottedplant | 69.63 |  85.8 |
|    sheep    | 82.63 | 92.33 |
|     sofa    | 49.48 | 61.99 |
|    train    | 90.93 | 95.95 |
|  tvmonitor  | 84.34 | 88.07 |
+-------------+-------+-------+
05/27 02:58:34 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 95.9100  mIoU: 80.9200  mAcc: 91.2000  data_time: 0.0013  time: 0.0481
05/27 02:58:55 - mmengine - INFO - Iter(train) [135050/160000]  base_lr: 1.8778e-05 lr: 1.8778e-06  eta: 2:52:02  time: 0.4169  data_time: 0.0100  memory: 5994  grad_norm: 462.1910  loss: 20.4265  decode.loss_cls: 0.1400  decode.loss_mask: 1.0769  decode.loss_dice: 0.7825  decode.d0.loss_cls: 0.6721  decode.d0.loss_mask: 1.0393  decode.d0.loss_dice: 0.7438  decode.d1.loss_cls: 0.1864  decode.d1.loss_mask: 1.0866  decode.d1.loss_dice: 0.7584  decode.d2.loss_cls: 0.1590  decode.d2.loss_mask: 1.0847  decode.d2.loss_dice: 0.7678  decode.d3.loss_cls: 0.1404  decode.d3.loss_mask: 1.0610  decode.d3.loss_dice: 0.7683  decode.d4.loss_cls: 0.1546  decode.d4.loss_mask: 1.0821  decode.d4.loss_dice: 0.7555  decode.d5.loss_cls: 0.1481  decode.d5.loss_mask: 1.0777  decode.d5.loss_dice: 0.7816  decode.d6.loss_cls: 0.1643  decode.d6.loss_mask: 1.0640  decode.d6.loss_dice: 0.7604  decode.d7.loss_cls: 0.1552  decode.d7.loss_mask: 1.0662  decode.d7.loss_dice: 0.7629  decode.d8.loss_cls: 0.1456  decode.d8.loss_mask: 1.0743  decode.d8.loss_dice: 0.7668
05/27 02:59:16 - mmengine - INFO - Iter(train) [135100/160000]  base_lr: 1.8745e-05 lr: 1.8745e-06  eta: 2:51:42  time: 0.4172  data_time: 0.0100  memory: 5970  grad_norm: 462.5294  loss: 17.2595  decode.loss_cls: 0.2547  decode.loss_mask: 0.8272  decode.loss_dice: 0.6013  decode.d0.loss_cls: 0.6021  decode.d0.loss_mask: 0.8153  decode.d0.loss_dice: 0.5862  decode.d1.loss_cls: 0.2502  decode.d1.loss_mask: 0.8350  decode.d1.loss_dice: 0.6148  decode.d2.loss_cls: 0.2340  decode.d2.loss_mask: 0.8257  decode.d2.loss_dice: 0.6269  decode.d3.loss_cls: 0.2702  decode.d3.loss_mask: 0.8063  decode.d3.loss_dice: 0.6040  decode.d4.loss_cls: 0.2807  decode.d4.loss_mask: 0.8342  decode.d4.loss_dice: 0.6283  decode.d5.loss_cls: 0.2433  decode.d5.loss_mask: 0.8384  decode.d5.loss_dice: 0.6251  decode.d6.loss_cls: 0.2068  decode.d6.loss_mask: 0.8422  decode.d6.loss_dice: 0.6287  decode.d7.loss_cls: 0.2303  decode.d7.loss_mask: 0.8410  decode.d7.loss_dice: 0.6093  decode.d8.loss_cls: 0.2602  decode.d8.loss_mask: 0.8243  decode.d8.loss_dice: 0.6124
05/27 02:59:37 - mmengine - INFO - Iter(train) [135150/160000]  base_lr: 1.8711e-05 lr: 1.8711e-06  eta: 2:51:21  time: 0.4193  data_time: 0.0101  memory: 5968  grad_norm: 335.1931  loss: 17.8982  decode.loss_cls: 0.1049  decode.loss_mask: 0.9461  decode.loss_dice: 0.6983  decode.d0.loss_cls: 0.6027  decode.d0.loss_mask: 0.9326  decode.d0.loss_dice: 0.6695  decode.d1.loss_cls: 0.1407  decode.d1.loss_mask: 0.9497  decode.d1.loss_dice: 0.6968  decode.d2.loss_cls: 0.1247  decode.d2.loss_mask: 0.9393  decode.d2.loss_dice: 0.6860  decode.d3.loss_cls: 0.1036  decode.d3.loss_mask: 0.9331  decode.d3.loss_dice: 0.6954  decode.d4.loss_cls: 0.0906  decode.d4.loss_mask: 0.9305  decode.d4.loss_dice: 0.6956  decode.d5.loss_cls: 0.1104  decode.d5.loss_mask: 0.9378  decode.d5.loss_dice: 0.7028  decode.d6.loss_cls: 0.0839  decode.d6.loss_mask: 0.9416  decode.d6.loss_dice: 0.7079  decode.d7.loss_cls: 0.0921  decode.d7.loss_mask: 0.9427  decode.d7.loss_dice: 0.6944  decode.d8.loss_cls: 0.1054  decode.d8.loss_mask: 0.9466  decode.d8.loss_dice: 0.6925
05/27 02:59:58 - mmengine - INFO - Iter(train) [135200/160000]  base_lr: 1.8677e-05 lr: 1.8677e-06  eta: 2:51:00  time: 0.4172  data_time: 0.0099  memory: 5974  grad_norm: 467.6656  loss: 16.5783  decode.loss_cls: 0.0281  decode.loss_mask: 0.9582  decode.loss_dice: 0.6200  decode.d0.loss_cls: 0.5522  decode.d0.loss_mask: 0.9274  decode.d0.loss_dice: 0.6001  decode.d1.loss_cls: 0.0317  decode.d1.loss_mask: 0.9538  decode.d1.loss_dice: 0.6343  decode.d2.loss_cls: 0.0268  decode.d2.loss_mask: 0.9552  decode.d2.loss_dice: 0.6280  decode.d3.loss_cls: 0.0252  decode.d3.loss_mask: 0.9562  decode.d3.loss_dice: 0.6262  decode.d4.loss_cls: 0.0242  decode.d4.loss_mask: 0.9641  decode.d4.loss_dice: 0.6274  decode.d5.loss_cls: 0.0257  decode.d5.loss_mask: 0.9579  decode.d5.loss_dice: 0.6239  decode.d6.loss_cls: 0.0287  decode.d6.loss_mask: 0.9541  decode.d6.loss_dice: 0.6210  decode.d7.loss_cls: 0.0271  decode.d7.loss_mask: 0.9500  decode.d7.loss_dice: 0.6163  decode.d8.loss_cls: 0.0420  decode.d8.loss_mask: 0.9573  decode.d8.loss_dice: 0.6352
05/27 03:00:19 - mmengine - INFO - Iter(train) [135250/160000]  base_lr: 1.8643e-05 lr: 1.8643e-06  eta: 2:50:40  time: 0.4165  data_time: 0.0099  memory: 5975  grad_norm: 475.4599  loss: 19.8352  decode.loss_cls: 0.2473  decode.loss_mask: 0.9205  decode.loss_dice: 0.7513  decode.d0.loss_cls: 0.6631  decode.d0.loss_mask: 0.9221  decode.d0.loss_dice: 0.7865  decode.d1.loss_cls: 0.3120  decode.d1.loss_mask: 0.9138  decode.d1.loss_dice: 0.7271  decode.d2.loss_cls: 0.3006  decode.d2.loss_mask: 0.9114  decode.d2.loss_dice: 0.7350  decode.d3.loss_cls: 0.2994  decode.d3.loss_mask: 0.9119  decode.d3.loss_dice: 0.7427  decode.d4.loss_cls: 0.2927  decode.d4.loss_mask: 0.9164  decode.d4.loss_dice: 0.7665  decode.d5.loss_cls: 0.2548  decode.d5.loss_mask: 0.9102  decode.d5.loss_dice: 0.7295  decode.d6.loss_cls: 0.2358  decode.d6.loss_mask: 0.9540  decode.d6.loss_dice: 0.7898  decode.d7.loss_cls: 0.2790  decode.d7.loss_mask: 0.9072  decode.d7.loss_dice: 0.7538  decode.d8.loss_cls: 0.2360  decode.d8.loss_mask: 0.9132  decode.d8.loss_dice: 0.7515
05/27 03:00:40 - mmengine - INFO - Iter(train) [135300/160000]  base_lr: 1.8609e-05 lr: 1.8609e-06  eta: 2:50:19  time: 0.4162  data_time: 0.0099  memory: 5971  grad_norm: 434.5917  loss: 18.5251  decode.loss_cls: 0.0898  decode.loss_mask: 1.0474  decode.loss_dice: 0.6923  decode.d0.loss_cls: 0.5594  decode.d0.loss_mask: 0.9797  decode.d0.loss_dice: 0.6743  decode.d1.loss_cls: 0.1184  decode.d1.loss_mask: 1.0013  decode.d1.loss_dice: 0.7095  decode.d2.loss_cls: 0.0927  decode.d2.loss_mask: 1.0038  decode.d2.loss_dice: 0.6885  decode.d3.loss_cls: 0.0711  decode.d3.loss_mask: 1.0076  decode.d3.loss_dice: 0.6880  decode.d4.loss_cls: 0.1343  decode.d4.loss_mask: 0.9714  decode.d4.loss_dice: 0.6988  decode.d5.loss_cls: 0.0842  decode.d5.loss_mask: 1.0526  decode.d5.loss_dice: 0.7071  decode.d6.loss_cls: 0.1057  decode.d6.loss_mask: 1.0242  decode.d6.loss_dice: 0.6903  decode.d7.loss_cls: 0.1153  decode.d7.loss_mask: 1.0188  decode.d7.loss_dice: 0.6896  decode.d8.loss_cls: 0.0935  decode.d8.loss_mask: 1.0103  decode.d8.loss_dice: 0.7052
05/27 03:01:01 - mmengine - INFO - Iter(train) [135350/160000]  base_lr: 1.8575e-05 lr: 1.8575e-06  eta: 2:49:58  time: 0.4173  data_time: 0.0100  memory: 5972  grad_norm: 489.2454  loss: 18.5021  decode.loss_cls: 0.1873  decode.loss_mask: 0.9316  decode.loss_dice: 0.6739  decode.d0.loss_cls: 0.6265  decode.d0.loss_mask: 0.8956  decode.d0.loss_dice: 0.6774  decode.d1.loss_cls: 0.2136  decode.d1.loss_mask: 0.9391  decode.d1.loss_dice: 0.7372  decode.d2.loss_cls: 0.1564  decode.d2.loss_mask: 0.9371  decode.d2.loss_dice: 0.7116  decode.d3.loss_cls: 0.1540  decode.d3.loss_mask: 0.9327  decode.d3.loss_dice: 0.7087  decode.d4.loss_cls: 0.1923  decode.d4.loss_mask: 0.9336  decode.d4.loss_dice: 0.6754  decode.d5.loss_cls: 0.1913  decode.d5.loss_mask: 0.9355  decode.d5.loss_dice: 0.6887  decode.d6.loss_cls: 0.1769  decode.d6.loss_mask: 0.9317  decode.d6.loss_dice: 0.6942  decode.d7.loss_cls: 0.1607  decode.d7.loss_mask: 0.9362  decode.d7.loss_dice: 0.7054  decode.d8.loss_cls: 0.1671  decode.d8.loss_mask: 0.9410  decode.d8.loss_dice: 0.6895
05/27 03:01:22 - mmengine - INFO - Iter(train) [135400/160000]  base_lr: 1.8541e-05 lr: 1.8541e-06  eta: 2:49:38  time: 0.4177  data_time: 0.0099  memory: 5966  grad_norm: 359.0162  loss: 15.0706  decode.loss_cls: 0.0905  decode.loss_mask: 0.7611  decode.loss_dice: 0.5748  decode.d0.loss_cls: 0.5711  decode.d0.loss_mask: 0.7746  decode.d0.loss_dice: 0.5744  decode.d1.loss_cls: 0.0898  decode.d1.loss_mask: 0.8007  decode.d1.loss_dice: 0.6096  decode.d2.loss_cls: 0.1241  decode.d2.loss_mask: 0.7664  decode.d2.loss_dice: 0.5640  decode.d3.loss_cls: 0.0794  decode.d3.loss_mask: 0.7783  decode.d3.loss_dice: 0.5987  decode.d4.loss_cls: 0.0931  decode.d4.loss_mask: 0.7845  decode.d4.loss_dice: 0.5926  decode.d5.loss_cls: 0.1079  decode.d5.loss_mask: 0.7733  decode.d5.loss_dice: 0.5850  decode.d6.loss_cls: 0.1117  decode.d6.loss_mask: 0.7722  decode.d6.loss_dice: 0.5824  decode.d7.loss_cls: 0.0782  decode.d7.loss_mask: 0.7882  decode.d7.loss_dice: 0.5952  decode.d8.loss_cls: 0.0870  decode.d8.loss_mask: 0.7680  decode.d8.loss_dice: 0.5941
05/27 03:01:42 - mmengine - INFO - Iter(train) [135450/160000]  base_lr: 1.8507e-05 lr: 1.8507e-06  eta: 2:49:17  time: 0.4171  data_time: 0.0100  memory: 5970  grad_norm: 1092.2072  loss: 20.5562  decode.loss_cls: 0.2800  decode.loss_mask: 0.9868  decode.loss_dice: 0.7467  decode.d0.loss_cls: 0.7715  decode.d0.loss_mask: 0.9357  decode.d0.loss_dice: 0.7406  decode.d1.loss_cls: 0.2868  decode.d1.loss_mask: 1.0205  decode.d1.loss_dice: 0.7707  decode.d2.loss_cls: 0.2809  decode.d2.loss_mask: 0.9631  decode.d2.loss_dice: 0.7364  decode.d3.loss_cls: 0.2720  decode.d3.loss_mask: 0.9945  decode.d3.loss_dice: 0.7516  decode.d4.loss_cls: 0.2564  decode.d4.loss_mask: 0.9843  decode.d4.loss_dice: 0.7638  decode.d5.loss_cls: 0.2485  decode.d5.loss_mask: 0.9536  decode.d5.loss_dice: 0.7543  decode.d6.loss_cls: 0.2680  decode.d6.loss_mask: 0.9912  decode.d6.loss_dice: 0.7839  decode.d7.loss_cls: 0.2597  decode.d7.loss_mask: 0.9804  decode.d7.loss_dice: 0.7635  decode.d8.loss_cls: 0.2355  decode.d8.loss_mask: 1.0112  decode.d8.loss_dice: 0.7640
05/27 03:02:03 - mmengine - INFO - Iter(train) [135500/160000]  base_lr: 1.8473e-05 lr: 1.8473e-06  eta: 2:48:56  time: 0.4172  data_time: 0.0099  memory: 5970  grad_norm: 533.9514  loss: 18.5770  decode.loss_cls: 0.2568  decode.loss_mask: 0.9046  decode.loss_dice: 0.6255  decode.d0.loss_cls: 0.7476  decode.d0.loss_mask: 0.8268  decode.d0.loss_dice: 0.5929  decode.d1.loss_cls: 0.2726  decode.d1.loss_mask: 0.9488  decode.d1.loss_dice: 0.6575  decode.d2.loss_cls: 0.2756  decode.d2.loss_mask: 0.9263  decode.d2.loss_dice: 0.6446  decode.d3.loss_cls: 0.2712  decode.d3.loss_mask: 0.8985  decode.d3.loss_dice: 0.6241  decode.d4.loss_cls: 0.2954  decode.d4.loss_mask: 0.9259  decode.d4.loss_dice: 0.6329  decode.d5.loss_cls: 0.2933  decode.d5.loss_mask: 0.8928  decode.d5.loss_dice: 0.6221  decode.d6.loss_cls: 0.2904  decode.d6.loss_mask: 0.8844  decode.d6.loss_dice: 0.6566  decode.d7.loss_cls: 0.2271  decode.d7.loss_mask: 0.9321  decode.d7.loss_dice: 0.6419  decode.d8.loss_cls: 0.2484  decode.d8.loss_mask: 0.9062  decode.d8.loss_dice: 0.6542
05/27 03:02:24 - mmengine - INFO - Iter(train) [135550/160000]  base_lr: 1.8439e-05 lr: 1.8439e-06  eta: 2:48:36  time: 0.4172  data_time: 0.0099  memory: 5969  grad_norm: 489.5319  loss: 17.3105  decode.loss_cls: 0.0996  decode.loss_mask: 0.9281  decode.loss_dice: 0.6773  decode.d0.loss_cls: 0.5807  decode.d0.loss_mask: 0.9272  decode.d0.loss_dice: 0.6712  decode.d1.loss_cls: 0.1094  decode.d1.loss_mask: 0.9400  decode.d1.loss_dice: 0.6776  decode.d2.loss_cls: 0.0824  decode.d2.loss_mask: 0.9132  decode.d2.loss_dice: 0.6719  decode.d3.loss_cls: 0.0756  decode.d3.loss_mask: 0.9171  decode.d3.loss_dice: 0.6605  decode.d4.loss_cls: 0.0639  decode.d4.loss_mask: 0.9305  decode.d4.loss_dice: 0.6599  decode.d5.loss_cls: 0.0703  decode.d5.loss_mask: 0.9295  decode.d5.loss_dice: 0.6698  decode.d6.loss_cls: 0.0757  decode.d6.loss_mask: 0.9272  decode.d6.loss_dice: 0.6737  decode.d7.loss_cls: 0.0984  decode.d7.loss_mask: 0.9281  decode.d7.loss_dice: 0.6822  decode.d8.loss_cls: 0.0761  decode.d8.loss_mask: 0.9287  decode.d8.loss_dice: 0.6649
05/27 03:02:45 - mmengine - INFO - Iter(train) [135600/160000]  base_lr: 1.8405e-05 lr: 1.8405e-06  eta: 2:48:15  time: 0.4163  data_time: 0.0099  memory: 5966  grad_norm: 453.2170  loss: 18.0422  decode.loss_cls: 0.1800  decode.loss_mask: 0.9009  decode.loss_dice: 0.7110  decode.d0.loss_cls: 0.7219  decode.d0.loss_mask: 0.7657  decode.d0.loss_dice: 0.6936  decode.d1.loss_cls: 0.2310  decode.d1.loss_mask: 0.8275  decode.d1.loss_dice: 0.6933  decode.d2.loss_cls: 0.2055  decode.d2.loss_mask: 0.8455  decode.d2.loss_dice: 0.6879  decode.d3.loss_cls: 0.2222  decode.d3.loss_mask: 0.8301  decode.d3.loss_dice: 0.7071  decode.d4.loss_cls: 0.2391  decode.d4.loss_mask: 0.8309  decode.d4.loss_dice: 0.7023  decode.d5.loss_cls: 0.2262  decode.d5.loss_mask: 0.8287  decode.d5.loss_dice: 0.6948  decode.d6.loss_cls: 0.2460  decode.d6.loss_mask: 0.7743  decode.d6.loss_dice: 0.6882  decode.d7.loss_cls: 0.2670  decode.d7.loss_mask: 0.7937  decode.d7.loss_dice: 0.7245  decode.d8.loss_cls: 0.1979  decode.d8.loss_mask: 0.9073  decode.d8.loss_dice: 0.6985
05/27 03:03:06 - mmengine - INFO - Iter(train) [135650/160000]  base_lr: 1.8371e-05 lr: 1.8371e-06  eta: 2:47:54  time: 0.4170  data_time: 0.0099  memory: 5969  grad_norm: 343.6683  loss: 15.6852  decode.loss_cls: 0.1257  decode.loss_mask: 0.7456  decode.loss_dice: 0.6237  decode.d0.loss_cls: 0.5181  decode.d0.loss_mask: 0.8619  decode.d0.loss_dice: 0.6667  decode.d1.loss_cls: 0.1792  decode.d1.loss_mask: 0.7827  decode.d1.loss_dice: 0.6776  decode.d2.loss_cls: 0.1276  decode.d2.loss_mask: 0.7673  decode.d2.loss_dice: 0.6566  decode.d3.loss_cls: 0.1263  decode.d3.loss_mask: 0.7455  decode.d3.loss_dice: 0.6240  decode.d4.loss_cls: 0.1153  decode.d4.loss_mask: 0.7455  decode.d4.loss_dice: 0.6210  decode.d5.loss_cls: 0.1186  decode.d5.loss_mask: 0.7380  decode.d5.loss_dice: 0.6213  decode.d6.loss_cls: 0.1135  decode.d6.loss_mask: 0.7375  decode.d6.loss_dice: 0.6179  decode.d7.loss_cls: 0.1276  decode.d7.loss_mask: 0.7479  decode.d7.loss_dice: 0.6368  decode.d8.loss_cls: 0.1358  decode.d8.loss_mask: 0.7477  decode.d8.loss_dice: 0.6323
05/27 03:03:27 - mmengine - INFO - Iter(train) [135700/160000]  base_lr: 1.8337e-05 lr: 1.8337e-06  eta: 2:47:34  time: 0.4174  data_time: 0.0098  memory: 5966  grad_norm: 322.0246  loss: 18.1789  decode.loss_cls: 0.1190  decode.loss_mask: 0.9624  decode.loss_dice: 0.7064  decode.d0.loss_cls: 0.5570  decode.d0.loss_mask: 0.9032  decode.d0.loss_dice: 0.7034  decode.d1.loss_cls: 0.1512  decode.d1.loss_mask: 0.9030  decode.d1.loss_dice: 0.7028  decode.d2.loss_cls: 0.1076  decode.d2.loss_mask: 0.9521  decode.d2.loss_dice: 0.7198  decode.d3.loss_cls: 0.1136  decode.d3.loss_mask: 0.9623  decode.d3.loss_dice: 0.7197  decode.d4.loss_cls: 0.1073  decode.d4.loss_mask: 0.9631  decode.d4.loss_dice: 0.7166  decode.d5.loss_cls: 0.1027  decode.d5.loss_mask: 0.9506  decode.d5.loss_dice: 0.7070  decode.d6.loss_cls: 0.1383  decode.d6.loss_mask: 0.9515  decode.d6.loss_dice: 0.7081  decode.d7.loss_cls: 0.1014  decode.d7.loss_mask: 0.9586  decode.d7.loss_dice: 0.7215  decode.d8.loss_cls: 0.1070  decode.d8.loss_mask: 0.9536  decode.d8.loss_dice: 0.7083
05/27 03:03:48 - mmengine - INFO - Iter(train) [135750/160000]  base_lr: 1.8304e-05 lr: 1.8304e-06  eta: 2:47:13  time: 0.4174  data_time: 0.0099  memory: 5969  grad_norm: 595.1523  loss: 21.9546  decode.loss_cls: 0.1588  decode.loss_mask: 1.1581  decode.loss_dice: 0.7883  decode.d0.loss_cls: 0.7752  decode.d0.loss_mask: 1.1272  decode.d0.loss_dice: 0.8209  decode.d1.loss_cls: 0.1888  decode.d1.loss_mask: 1.1764  decode.d1.loss_dice: 0.8028  decode.d2.loss_cls: 0.2154  decode.d2.loss_mask: 1.1327  decode.d2.loss_dice: 0.7676  decode.d3.loss_cls: 0.1678  decode.d3.loss_mask: 1.1577  decode.d3.loss_dice: 0.8215  decode.d4.loss_cls: 0.1839  decode.d4.loss_mask: 1.1479  decode.d4.loss_dice: 0.8123  decode.d5.loss_cls: 0.1828  decode.d5.loss_mask: 1.1280  decode.d5.loss_dice: 0.7702  decode.d6.loss_cls: 0.1839  decode.d6.loss_mask: 1.1630  decode.d6.loss_dice: 0.8192  decode.d7.loss_cls: 0.1906  decode.d7.loss_mask: 1.1726  decode.d7.loss_dice: 0.8173  decode.d8.loss_cls: 0.1730  decode.d8.loss_mask: 1.1540  decode.d8.loss_dice: 0.7967
05/27 03:04:09 - mmengine - INFO - Iter(train) [135800/160000]  base_lr: 1.8270e-05 lr: 1.8270e-06  eta: 2:46:53  time: 0.4173  data_time: 0.0100  memory: 5993  grad_norm: 591.1024  loss: 20.0650  decode.loss_cls: 0.2206  decode.loss_mask: 0.9914  decode.loss_dice: 0.7136  decode.d0.loss_cls: 0.7522  decode.d0.loss_mask: 0.9643  decode.d0.loss_dice: 0.7307  decode.d1.loss_cls: 0.2443  decode.d1.loss_mask: 1.0070  decode.d1.loss_dice: 0.7358  decode.d2.loss_cls: 0.2975  decode.d2.loss_mask: 0.9788  decode.d2.loss_dice: 0.7099  decode.d3.loss_cls: 0.2456  decode.d3.loss_mask: 0.9920  decode.d3.loss_dice: 0.7225  decode.d4.loss_cls: 0.2681  decode.d4.loss_mask: 0.9951  decode.d4.loss_dice: 0.7232  decode.d5.loss_cls: 0.2269  decode.d5.loss_mask: 0.9874  decode.d5.loss_dice: 0.7230  decode.d6.loss_cls: 0.2676  decode.d6.loss_mask: 0.9762  decode.d6.loss_dice: 0.7238  decode.d7.loss_cls: 0.2677  decode.d7.loss_mask: 0.9679  decode.d7.loss_dice: 0.7125  decode.d8.loss_cls: 0.2371  decode.d8.loss_mask: 0.9690  decode.d8.loss_dice: 0.7131
05/27 03:04:30 - mmengine - INFO - Iter(train) [135850/160000]  base_lr: 1.8236e-05 lr: 1.8236e-06  eta: 2:46:32  time: 0.4169  data_time: 0.0098  memory: 5971  grad_norm: 451.4387  loss: 14.7377  decode.loss_cls: 0.0853  decode.loss_mask: 0.7788  decode.loss_dice: 0.5804  decode.d0.loss_cls: 0.5312  decode.d0.loss_mask: 0.7490  decode.d0.loss_dice: 0.5884  decode.d1.loss_cls: 0.1045  decode.d1.loss_mask: 0.7362  decode.d1.loss_dice: 0.5686  decode.d2.loss_cls: 0.0632  decode.d2.loss_mask: 0.7736  decode.d2.loss_dice: 0.5818  decode.d3.loss_cls: 0.0655  decode.d3.loss_mask: 0.7745  decode.d3.loss_dice: 0.5827  decode.d4.loss_cls: 0.0571  decode.d4.loss_mask: 0.7871  decode.d4.loss_dice: 0.5857  decode.d5.loss_cls: 0.0649  decode.d5.loss_mask: 0.7684  decode.d5.loss_dice: 0.5796  decode.d6.loss_cls: 0.0643  decode.d6.loss_mask: 0.7949  decode.d6.loss_dice: 0.5993  decode.d7.loss_cls: 0.0927  decode.d7.loss_mask: 0.7595  decode.d7.loss_dice: 0.5831  decode.d8.loss_cls: 0.0602  decode.d8.loss_mask: 0.7871  decode.d8.loss_dice: 0.5899
05/27 03:04:51 - mmengine - INFO - Iter(train) [135900/160000]  base_lr: 1.8202e-05 lr: 1.8202e-06  eta: 2:46:11  time: 0.4173  data_time: 0.0099  memory: 5979  grad_norm: 396.5053  loss: 19.2322  decode.loss_cls: 0.0774  decode.loss_mask: 1.1074  decode.loss_dice: 0.6660  decode.d0.loss_cls: 0.5778  decode.d0.loss_mask: 1.0421  decode.d0.loss_dice: 0.6959  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 1.1801  decode.d1.loss_dice: 0.6868  decode.d2.loss_cls: 0.0626  decode.d2.loss_mask: 1.1635  decode.d2.loss_dice: 0.6666  decode.d3.loss_cls: 0.0784  decode.d3.loss_mask: 1.1033  decode.d3.loss_dice: 0.6721  decode.d4.loss_cls: 0.0903  decode.d4.loss_mask: 1.0982  decode.d4.loss_dice: 0.6567  decode.d5.loss_cls: 0.0709  decode.d5.loss_mask: 1.1704  decode.d5.loss_dice: 0.6637  decode.d6.loss_cls: 0.0620  decode.d6.loss_mask: 1.1708  decode.d6.loss_dice: 0.6876  decode.d7.loss_cls: 0.0896  decode.d7.loss_mask: 1.1056  decode.d7.loss_dice: 0.6603  decode.d8.loss_cls: 0.1152  decode.d8.loss_mask: 1.0683  decode.d8.loss_dice: 0.6605
05/27 03:05:11 - mmengine - INFO - Iter(train) [135950/160000]  base_lr: 1.8168e-05 lr: 1.8168e-06  eta: 2:45:51  time: 0.4166  data_time: 0.0098  memory: 5976  grad_norm: 489.0229  loss: 17.4147  decode.loss_cls: 0.2037  decode.loss_mask: 0.8836  decode.loss_dice: 0.5842  decode.d0.loss_cls: 0.6426  decode.d0.loss_mask: 0.9000  decode.d0.loss_dice: 0.6011  decode.d1.loss_cls: 0.2088  decode.d1.loss_mask: 0.8989  decode.d1.loss_dice: 0.5987  decode.d2.loss_cls: 0.1970  decode.d2.loss_mask: 0.9081  decode.d2.loss_dice: 0.5940  decode.d3.loss_cls: 0.1844  decode.d3.loss_mask: 0.9292  decode.d3.loss_dice: 0.6033  decode.d4.loss_cls: 0.1494  decode.d4.loss_mask: 0.9243  decode.d4.loss_dice: 0.6010  decode.d5.loss_cls: 0.1799  decode.d5.loss_mask: 0.9070  decode.d5.loss_dice: 0.6000  decode.d6.loss_cls: 0.1935  decode.d6.loss_mask: 0.9089  decode.d6.loss_dice: 0.5961  decode.d7.loss_cls: 0.2124  decode.d7.loss_mask: 0.9042  decode.d7.loss_dice: 0.5915  decode.d8.loss_cls: 0.1827  decode.d8.loss_mask: 0.9334  decode.d8.loss_dice: 0.5927
05/27 03:05:32 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 03:05:32 - mmengine - INFO - Iter(train) [136000/160000]  base_lr: 1.8134e-05 lr: 1.8134e-06  eta: 2:45:30  time: 0.4174  data_time: 0.0098  memory: 5970  grad_norm: 440.8501  loss: 17.4822  decode.loss_cls: 0.0789  decode.loss_mask: 0.9340  decode.loss_dice: 0.6967  decode.d0.loss_cls: 0.6177  decode.d0.loss_mask: 0.9037  decode.d0.loss_dice: 0.6775  decode.d1.loss_cls: 0.1262  decode.d1.loss_mask: 0.9285  decode.d1.loss_dice: 0.6766  decode.d2.loss_cls: 0.1083  decode.d2.loss_mask: 0.9180  decode.d2.loss_dice: 0.6761  decode.d3.loss_cls: 0.0945  decode.d3.loss_mask: 0.9183  decode.d3.loss_dice: 0.6760  decode.d4.loss_cls: 0.0969  decode.d4.loss_mask: 0.9297  decode.d4.loss_dice: 0.6767  decode.d5.loss_cls: 0.0777  decode.d5.loss_mask: 0.9381  decode.d5.loss_dice: 0.6634  decode.d6.loss_cls: 0.0779  decode.d6.loss_mask: 0.9307  decode.d6.loss_dice: 0.6862  decode.d7.loss_cls: 0.0714  decode.d7.loss_mask: 0.9318  decode.d7.loss_dice: 0.6761  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.9362  decode.d8.loss_dice: 0.6842
05/27 03:05:53 - mmengine - INFO - Iter(train) [136050/160000]  base_lr: 1.8100e-05 lr: 1.8100e-06  eta: 2:45:09  time: 0.4167  data_time: 0.0098  memory: 5969  grad_norm: 434.1622  loss: 15.0823  decode.loss_cls: 0.0901  decode.loss_mask: 0.7991  decode.loss_dice: 0.5316  decode.d0.loss_cls: 0.5407  decode.d0.loss_mask: 0.7677  decode.d0.loss_dice: 0.5406  decode.d1.loss_cls: 0.1599  decode.d1.loss_mask: 0.8236  decode.d1.loss_dice: 0.5461  decode.d2.loss_cls: 0.1213  decode.d2.loss_mask: 0.8213  decode.d2.loss_dice: 0.5494  decode.d3.loss_cls: 0.1359  decode.d3.loss_mask: 0.8123  decode.d3.loss_dice: 0.5367  decode.d4.loss_cls: 0.1313  decode.d4.loss_mask: 0.7931  decode.d4.loss_dice: 0.5231  decode.d5.loss_cls: 0.1291  decode.d5.loss_mask: 0.7914  decode.d5.loss_dice: 0.5261  decode.d6.loss_cls: 0.1059  decode.d6.loss_mask: 0.8255  decode.d6.loss_dice: 0.5475  decode.d7.loss_cls: 0.0758  decode.d7.loss_mask: 0.8550  decode.d7.loss_dice: 0.5494  decode.d8.loss_cls: 0.1013  decode.d8.loss_mask: 0.8106  decode.d8.loss_dice: 0.5409
05/27 03:06:14 - mmengine - INFO - Iter(train) [136100/160000]  base_lr: 1.8066e-05 lr: 1.8066e-06  eta: 2:44:49  time: 0.4163  data_time: 0.0098  memory: 5968  grad_norm: 286.1494  loss: 16.4396  decode.loss_cls: 0.0745  decode.loss_mask: 0.8689  decode.loss_dice: 0.6642  decode.d0.loss_cls: 0.5126  decode.d0.loss_mask: 0.8419  decode.d0.loss_dice: 0.6442  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 0.8719  decode.d1.loss_dice: 0.6787  decode.d2.loss_cls: 0.0754  decode.d2.loss_mask: 0.8716  decode.d2.loss_dice: 0.6605  decode.d3.loss_cls: 0.0610  decode.d3.loss_mask: 0.8713  decode.d3.loss_dice: 0.6632  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.8642  decode.d4.loss_dice: 0.6599  decode.d5.loss_cls: 0.0595  decode.d5.loss_mask: 0.8711  decode.d5.loss_dice: 0.6656  decode.d6.loss_cls: 0.0721  decode.d6.loss_mask: 0.8704  decode.d6.loss_dice: 0.6735  decode.d7.loss_cls: 0.0616  decode.d7.loss_mask: 0.8665  decode.d7.loss_dice: 0.6714  decode.d8.loss_cls: 0.0640  decode.d8.loss_mask: 0.8709  decode.d8.loss_dice: 0.6896
05/27 03:06:35 - mmengine - INFO - Iter(train) [136150/160000]  base_lr: 1.8032e-05 lr: 1.8032e-06  eta: 2:44:28  time: 0.4170  data_time: 0.0098  memory: 5967  grad_norm: 507.5386  loss: 18.2012  decode.loss_cls: 0.2217  decode.loss_mask: 0.8663  decode.loss_dice: 0.6853  decode.d0.loss_cls: 0.6465  decode.d0.loss_mask: 0.8955  decode.d0.loss_dice: 0.7148  decode.d1.loss_cls: 0.2497  decode.d1.loss_mask: 0.8747  decode.d1.loss_dice: 0.6965  decode.d2.loss_cls: 0.2052  decode.d2.loss_mask: 0.8866  decode.d2.loss_dice: 0.6793  decode.d3.loss_cls: 0.1850  decode.d3.loss_mask: 0.8851  decode.d3.loss_dice: 0.6842  decode.d4.loss_cls: 0.1849  decode.d4.loss_mask: 0.8766  decode.d4.loss_dice: 0.6751  decode.d5.loss_cls: 0.1878  decode.d5.loss_mask: 0.8765  decode.d5.loss_dice: 0.7081  decode.d6.loss_cls: 0.1914  decode.d6.loss_mask: 0.8827  decode.d6.loss_dice: 0.6912  decode.d7.loss_cls: 0.1942  decode.d7.loss_mask: 0.8782  decode.d7.loss_dice: 0.6865  decode.d8.loss_cls: 0.2249  decode.d8.loss_mask: 0.8768  decode.d8.loss_dice: 0.6901
05/27 03:06:56 - mmengine - INFO - Iter(train) [136200/160000]  base_lr: 1.7998e-05 lr: 1.7998e-06  eta: 2:44:07  time: 0.4162  data_time: 0.0098  memory: 5966  grad_norm: 517.9454  loss: 16.8561  decode.loss_cls: 0.0868  decode.loss_mask: 0.9475  decode.loss_dice: 0.5874  decode.d0.loss_cls: 0.6235  decode.d0.loss_mask: 0.9025  decode.d0.loss_dice: 0.5854  decode.d1.loss_cls: 0.1055  decode.d1.loss_mask: 0.9478  decode.d1.loss_dice: 0.5876  decode.d2.loss_cls: 0.0926  decode.d2.loss_mask: 0.9536  decode.d2.loss_dice: 0.5867  decode.d3.loss_cls: 0.0983  decode.d3.loss_mask: 0.9382  decode.d3.loss_dice: 0.5961  decode.d4.loss_cls: 0.0896  decode.d4.loss_mask: 0.9388  decode.d4.loss_dice: 0.6096  decode.d5.loss_cls: 0.0981  decode.d5.loss_mask: 0.9620  decode.d5.loss_dice: 0.5862  decode.d6.loss_cls: 0.0998  decode.d6.loss_mask: 0.9482  decode.d6.loss_dice: 0.5824  decode.d7.loss_cls: 0.0923  decode.d7.loss_mask: 0.9571  decode.d7.loss_dice: 0.6146  decode.d8.loss_cls: 0.0857  decode.d8.loss_mask: 0.9649  decode.d8.loss_dice: 0.5870
05/27 03:07:17 - mmengine - INFO - Iter(train) [136250/160000]  base_lr: 1.7964e-05 lr: 1.7964e-06  eta: 2:43:47  time: 0.4168  data_time: 0.0099  memory: 5965  grad_norm: 476.1957  loss: 19.1748  decode.loss_cls: 0.1604  decode.loss_mask: 1.0127  decode.loss_dice: 0.6900  decode.d0.loss_cls: 0.6055  decode.d0.loss_mask: 0.9876  decode.d0.loss_dice: 0.7145  decode.d1.loss_cls: 0.2395  decode.d1.loss_mask: 1.0345  decode.d1.loss_dice: 0.6773  decode.d2.loss_cls: 0.1616  decode.d2.loss_mask: 1.0157  decode.d2.loss_dice: 0.6955  decode.d3.loss_cls: 0.1753  decode.d3.loss_mask: 1.0087  decode.d3.loss_dice: 0.6949  decode.d4.loss_cls: 0.1666  decode.d4.loss_mask: 1.0194  decode.d4.loss_dice: 0.6952  decode.d5.loss_cls: 0.1531  decode.d5.loss_mask: 1.0024  decode.d5.loss_dice: 0.6926  decode.d6.loss_cls: 0.1710  decode.d6.loss_mask: 0.9964  decode.d6.loss_dice: 0.6790  decode.d7.loss_cls: 0.1549  decode.d7.loss_mask: 1.0068  decode.d7.loss_dice: 0.6974  decode.d8.loss_cls: 0.1843  decode.d8.loss_mask: 1.0014  decode.d8.loss_dice: 0.6806
05/27 03:07:37 - mmengine - INFO - Iter(train) [136300/160000]  base_lr: 1.7929e-05 lr: 1.7929e-06  eta: 2:43:26  time: 0.4184  data_time: 0.0098  memory: 5982  grad_norm: 438.8990  loss: 18.5673  decode.loss_cls: 0.1361  decode.loss_mask: 0.9848  decode.loss_dice: 0.6555  decode.d0.loss_cls: 0.6019  decode.d0.loss_mask: 1.0093  decode.d0.loss_dice: 0.6625  decode.d1.loss_cls: 0.1443  decode.d1.loss_mask: 1.0132  decode.d1.loss_dice: 0.6726  decode.d2.loss_cls: 0.1319  decode.d2.loss_mask: 1.0254  decode.d2.loss_dice: 0.6687  decode.d3.loss_cls: 0.1541  decode.d3.loss_mask: 1.0026  decode.d3.loss_dice: 0.6674  decode.d4.loss_cls: 0.1408  decode.d4.loss_mask: 1.0148  decode.d4.loss_dice: 0.6658  decode.d5.loss_cls: 0.1663  decode.d5.loss_mask: 1.0051  decode.d5.loss_dice: 0.6484  decode.d6.loss_cls: 0.1420  decode.d6.loss_mask: 0.9979  decode.d6.loss_dice: 0.6626  decode.d7.loss_cls: 0.1420  decode.d7.loss_mask: 1.0131  decode.d7.loss_dice: 0.6559  decode.d8.loss_cls: 0.1174  decode.d8.loss_mask: 1.0127  decode.d8.loss_dice: 0.6520
05/27 03:07:58 - mmengine - INFO - Iter(train) [136350/160000]  base_lr: 1.7895e-05 lr: 1.7895e-06  eta: 2:43:05  time: 0.4174  data_time: 0.0098  memory: 5972  grad_norm: 558.1326  loss: 18.0184  decode.loss_cls: 0.1417  decode.loss_mask: 0.9281  decode.loss_dice: 0.6764  decode.d0.loss_cls: 0.6136  decode.d0.loss_mask: 0.9075  decode.d0.loss_dice: 0.6428  decode.d1.loss_cls: 0.1777  decode.d1.loss_mask: 0.9173  decode.d1.loss_dice: 0.6639  decode.d2.loss_cls: 0.1388  decode.d2.loss_mask: 0.9265  decode.d2.loss_dice: 0.6585  decode.d3.loss_cls: 0.1573  decode.d3.loss_mask: 0.9190  decode.d3.loss_dice: 0.6715  decode.d4.loss_cls: 0.1528  decode.d4.loss_mask: 0.9128  decode.d4.loss_dice: 0.6804  decode.d5.loss_cls: 0.1330  decode.d5.loss_mask: 0.9256  decode.d5.loss_dice: 0.6877  decode.d6.loss_cls: 0.1748  decode.d6.loss_mask: 0.9213  decode.d6.loss_dice: 0.6665  decode.d7.loss_cls: 0.1880  decode.d7.loss_mask: 0.9353  decode.d7.loss_dice: 0.6783  decode.d8.loss_cls: 0.1775  decode.d8.loss_mask: 0.9484  decode.d8.loss_dice: 0.6955
05/27 03:08:19 - mmengine - INFO - Iter(train) [136400/160000]  base_lr: 1.7861e-05 lr: 1.7861e-06  eta: 2:42:45  time: 0.4172  data_time: 0.0099  memory: 5986  grad_norm: 487.9823  loss: 20.6578  decode.loss_cls: 0.2333  decode.loss_mask: 0.9831  decode.loss_dice: 0.7738  decode.d0.loss_cls: 0.7583  decode.d0.loss_mask: 0.9430  decode.d0.loss_dice: 0.7988  decode.d1.loss_cls: 0.2295  decode.d1.loss_mask: 0.9905  decode.d1.loss_dice: 0.7975  decode.d2.loss_cls: 0.2079  decode.d2.loss_mask: 0.9945  decode.d2.loss_dice: 0.8148  decode.d3.loss_cls: 0.2523  decode.d3.loss_mask: 0.9851  decode.d3.loss_dice: 0.7807  decode.d4.loss_cls: 0.2532  decode.d4.loss_mask: 0.9878  decode.d4.loss_dice: 0.7924  decode.d5.loss_cls: 0.2547  decode.d5.loss_mask: 0.9793  decode.d5.loss_dice: 0.8046  decode.d6.loss_cls: 0.2345  decode.d6.loss_mask: 0.9862  decode.d6.loss_dice: 0.8116  decode.d7.loss_cls: 0.2259  decode.d7.loss_mask: 1.0035  decode.d7.loss_dice: 0.7944  decode.d8.loss_cls: 0.2149  decode.d8.loss_mask: 0.9835  decode.d8.loss_dice: 0.7880
05/27 03:08:40 - mmengine - INFO - Iter(train) [136450/160000]  base_lr: 1.7827e-05 lr: 1.7827e-06  eta: 2:42:24  time: 0.4173  data_time: 0.0098  memory: 5967  grad_norm: 349.2135  loss: 14.2718  decode.loss_cls: 0.0358  decode.loss_mask: 0.8085  decode.loss_dice: 0.5204  decode.d0.loss_cls: 0.4893  decode.d0.loss_mask: 0.8181  decode.d0.loss_dice: 0.5259  decode.d1.loss_cls: 0.0440  decode.d1.loss_mask: 0.8377  decode.d1.loss_dice: 0.5141  decode.d2.loss_cls: 0.0436  decode.d2.loss_mask: 0.8269  decode.d2.loss_dice: 0.5114  decode.d3.loss_cls: 0.0405  decode.d3.loss_mask: 0.8279  decode.d3.loss_dice: 0.5282  decode.d4.loss_cls: 0.0512  decode.d4.loss_mask: 0.8322  decode.d4.loss_dice: 0.5189  decode.d5.loss_cls: 0.0410  decode.d5.loss_mask: 0.8243  decode.d5.loss_dice: 0.5183  decode.d6.loss_cls: 0.0418  decode.d6.loss_mask: 0.8140  decode.d6.loss_dice: 0.5168  decode.d7.loss_cls: 0.0355  decode.d7.loss_mask: 0.8190  decode.d7.loss_dice: 0.5179  decode.d8.loss_cls: 0.0364  decode.d8.loss_mask: 0.8152  decode.d8.loss_dice: 0.5171
05/27 03:09:01 - mmengine - INFO - Iter(train) [136500/160000]  base_lr: 1.7793e-05 lr: 1.7793e-06  eta: 2:42:03  time: 0.4169  data_time: 0.0098  memory: 5988  grad_norm: 1016.6474  loss: 20.3085  decode.loss_cls: 0.1862  decode.loss_mask: 0.9827  decode.loss_dice: 0.8093  decode.d0.loss_cls: 0.7543  decode.d0.loss_mask: 0.9672  decode.d0.loss_dice: 0.7730  decode.d1.loss_cls: 0.2395  decode.d1.loss_mask: 0.9798  decode.d1.loss_dice: 0.7710  decode.d2.loss_cls: 0.1959  decode.d2.loss_mask: 0.9960  decode.d2.loss_dice: 0.8041  decode.d3.loss_cls: 0.1846  decode.d3.loss_mask: 0.9620  decode.d3.loss_dice: 0.7773  decode.d4.loss_cls: 0.2231  decode.d4.loss_mask: 0.9759  decode.d4.loss_dice: 0.7972  decode.d5.loss_cls: 0.2186  decode.d5.loss_mask: 0.9911  decode.d5.loss_dice: 0.8055  decode.d6.loss_cls: 0.2062  decode.d6.loss_mask: 0.9839  decode.d6.loss_dice: 0.7760  decode.d7.loss_cls: 0.2151  decode.d7.loss_mask: 0.9890  decode.d7.loss_dice: 0.7810  decode.d8.loss_cls: 0.1883  decode.d8.loss_mask: 0.9785  decode.d8.loss_dice: 0.7962
05/27 03:09:22 - mmengine - INFO - Iter(train) [136550/160000]  base_lr: 1.7759e-05 lr: 1.7759e-06  eta: 2:41:43  time: 0.4169  data_time: 0.0099  memory: 5969  grad_norm: 448.7734  loss: 17.1872  decode.loss_cls: 0.1208  decode.loss_mask: 0.8470  decode.loss_dice: 0.6818  decode.d0.loss_cls: 0.6207  decode.d0.loss_mask: 0.8359  decode.d0.loss_dice: 0.6735  decode.d1.loss_cls: 0.1663  decode.d1.loss_mask: 0.8524  decode.d1.loss_dice: 0.6842  decode.d2.loss_cls: 0.1321  decode.d2.loss_mask: 0.8661  decode.d2.loss_dice: 0.6915  decode.d3.loss_cls: 0.1518  decode.d3.loss_mask: 0.8366  decode.d3.loss_dice: 0.6748  decode.d4.loss_cls: 0.1674  decode.d4.loss_mask: 0.8390  decode.d4.loss_dice: 0.6700  decode.d5.loss_cls: 0.1237  decode.d5.loss_mask: 0.8641  decode.d5.loss_dice: 0.6838  decode.d6.loss_cls: 0.1351  decode.d6.loss_mask: 0.8476  decode.d6.loss_dice: 0.6733  decode.d7.loss_cls: 0.1358  decode.d7.loss_mask: 0.8510  decode.d7.loss_dice: 0.6864  decode.d8.loss_cls: 0.1287  decode.d8.loss_mask: 0.8578  decode.d8.loss_dice: 0.6880
05/27 03:09:43 - mmengine - INFO - Iter(train) [136600/160000]  base_lr: 1.7725e-05 lr: 1.7725e-06  eta: 2:41:22  time: 0.4271  data_time: 0.0098  memory: 5967  grad_norm: 879.7128  loss: 18.6429  decode.loss_cls: 0.1209  decode.loss_mask: 1.0063  decode.loss_dice: 0.6954  decode.d0.loss_cls: 0.6371  decode.d0.loss_mask: 1.0083  decode.d0.loss_dice: 0.6534  decode.d1.loss_cls: 0.0894  decode.d1.loss_mask: 1.0580  decode.d1.loss_dice: 0.7022  decode.d2.loss_cls: 0.1002  decode.d2.loss_mask: 1.0603  decode.d2.loss_dice: 0.7052  decode.d3.loss_cls: 0.0988  decode.d3.loss_mask: 1.0289  decode.d3.loss_dice: 0.6743  decode.d4.loss_cls: 0.0963  decode.d4.loss_mask: 1.0152  decode.d4.loss_dice: 0.6771  decode.d5.loss_cls: 0.0988  decode.d5.loss_mask: 1.0253  decode.d5.loss_dice: 0.6956  decode.d6.loss_cls: 0.1015  decode.d6.loss_mask: 1.0158  decode.d6.loss_dice: 0.6836  decode.d7.loss_cls: 0.1016  decode.d7.loss_mask: 1.0264  decode.d7.loss_dice: 0.6810  decode.d8.loss_cls: 0.1047  decode.d8.loss_mask: 1.0056  decode.d8.loss_dice: 0.6759
05/27 03:10:04 - mmengine - INFO - Iter(train) [136650/160000]  base_lr: 1.7691e-05 lr: 1.7691e-06  eta: 2:41:01  time: 0.4174  data_time: 0.0099  memory: 5975  grad_norm: 301.5710  loss: 20.3755  decode.loss_cls: 0.2171  decode.loss_mask: 0.9779  decode.loss_dice: 0.8008  decode.d0.loss_cls: 0.6502  decode.d0.loss_mask: 0.9783  decode.d0.loss_dice: 0.7945  decode.d1.loss_cls: 0.1836  decode.d1.loss_mask: 0.9895  decode.d1.loss_dice: 0.8083  decode.d2.loss_cls: 0.2006  decode.d2.loss_mask: 0.9847  decode.d2.loss_dice: 0.7885  decode.d3.loss_cls: 0.2454  decode.d3.loss_mask: 0.9621  decode.d3.loss_dice: 0.7776  decode.d4.loss_cls: 0.2202  decode.d4.loss_mask: 0.9724  decode.d4.loss_dice: 0.8025  decode.d5.loss_cls: 0.2137  decode.d5.loss_mask: 0.9747  decode.d5.loss_dice: 0.8067  decode.d6.loss_cls: 0.2534  decode.d6.loss_mask: 0.9758  decode.d6.loss_dice: 0.7900  decode.d7.loss_cls: 0.2274  decode.d7.loss_mask: 0.9825  decode.d7.loss_dice: 0.7984  decode.d8.loss_cls: 0.2413  decode.d8.loss_mask: 0.9765  decode.d8.loss_dice: 0.7809
05/27 03:10:25 - mmengine - INFO - Iter(train) [136700/160000]  base_lr: 1.7657e-05 lr: 1.7657e-06  eta: 2:40:41  time: 0.4165  data_time: 0.0098  memory: 5984  grad_norm: 550.1287  loss: 17.5837  decode.loss_cls: 0.1367  decode.loss_mask: 0.9028  decode.loss_dice: 0.6721  decode.d0.loss_cls: 0.6913  decode.d0.loss_mask: 0.8435  decode.d0.loss_dice: 0.6836  decode.d1.loss_cls: 0.1620  decode.d1.loss_mask: 0.8909  decode.d1.loss_dice: 0.7126  decode.d2.loss_cls: 0.1329  decode.d2.loss_mask: 0.8625  decode.d2.loss_dice: 0.7198  decode.d3.loss_cls: 0.1550  decode.d3.loss_mask: 0.8511  decode.d3.loss_dice: 0.6789  decode.d4.loss_cls: 0.1598  decode.d4.loss_mask: 0.8499  decode.d4.loss_dice: 0.6704  decode.d5.loss_cls: 0.1557  decode.d5.loss_mask: 0.8514  decode.d5.loss_dice: 0.6892  decode.d6.loss_cls: 0.1493  decode.d6.loss_mask: 0.8714  decode.d6.loss_dice: 0.6829  decode.d7.loss_cls: 0.1496  decode.d7.loss_mask: 0.8611  decode.d7.loss_dice: 0.6888  decode.d8.loss_cls: 0.1630  decode.d8.loss_mask: 0.8526  decode.d8.loss_dice: 0.6928
05/27 03:10:45 - mmengine - INFO - Iter(train) [136750/160000]  base_lr: 1.7623e-05 lr: 1.7623e-06  eta: 2:40:20  time: 0.4169  data_time: 0.0097  memory: 5981  grad_norm: 520.0682  loss: 19.6223  decode.loss_cls: 0.2307  decode.loss_mask: 1.0563  decode.loss_dice: 0.6806  decode.d0.loss_cls: 0.7150  decode.d0.loss_mask: 0.9562  decode.d0.loss_dice: 0.6683  decode.d1.loss_cls: 0.2178  decode.d1.loss_mask: 1.0038  decode.d1.loss_dice: 0.7006  decode.d2.loss_cls: 0.2395  decode.d2.loss_mask: 0.9793  decode.d2.loss_dice: 0.6998  decode.d3.loss_cls: 0.2175  decode.d3.loss_mask: 0.9986  decode.d3.loss_dice: 0.6930  decode.d4.loss_cls: 0.2414  decode.d4.loss_mask: 0.9880  decode.d4.loss_dice: 0.6686  decode.d5.loss_cls: 0.2435  decode.d5.loss_mask: 1.0076  decode.d5.loss_dice: 0.6802  decode.d6.loss_cls: 0.2076  decode.d6.loss_mask: 1.0241  decode.d6.loss_dice: 0.6802  decode.d7.loss_cls: 0.2174  decode.d7.loss_mask: 0.9855  decode.d7.loss_dice: 0.6737  decode.d8.loss_cls: 0.2492  decode.d8.loss_mask: 1.0276  decode.d8.loss_dice: 0.6704
05/27 03:11:06 - mmengine - INFO - Iter(train) [136800/160000]  base_lr: 1.7589e-05 lr: 1.7589e-06  eta: 2:39:59  time: 0.4170  data_time: 0.0099  memory: 5967  grad_norm: 378.6016  loss: 16.6779  decode.loss_cls: 0.1417  decode.loss_mask: 0.9034  decode.loss_dice: 0.5344  decode.d0.loss_cls: 0.6226  decode.d0.loss_mask: 0.9300  decode.d0.loss_dice: 0.5748  decode.d1.loss_cls: 0.0812  decode.d1.loss_mask: 0.9872  decode.d1.loss_dice: 0.6077  decode.d2.loss_cls: 0.1547  decode.d2.loss_mask: 0.9062  decode.d2.loss_dice: 0.5689  decode.d3.loss_cls: 0.1559  decode.d3.loss_mask: 0.9021  decode.d3.loss_dice: 0.5595  decode.d4.loss_cls: 0.1516  decode.d4.loss_mask: 0.8841  decode.d4.loss_dice: 0.5627  decode.d5.loss_cls: 0.1583  decode.d5.loss_mask: 0.8847  decode.d5.loss_dice: 0.5455  decode.d6.loss_cls: 0.1600  decode.d6.loss_mask: 0.9207  decode.d6.loss_dice: 0.5455  decode.d7.loss_cls: 0.1262  decode.d7.loss_mask: 0.9378  decode.d7.loss_dice: 0.5609  decode.d8.loss_cls: 0.1479  decode.d8.loss_mask: 0.9061  decode.d8.loss_dice: 0.5554
05/27 03:11:27 - mmengine - INFO - Iter(train) [136850/160000]  base_lr: 1.7555e-05 lr: 1.7555e-06  eta: 2:39:39  time: 0.4171  data_time: 0.0098  memory: 5970  grad_norm: 444.6474  loss: 18.2869  decode.loss_cls: 0.0657  decode.loss_mask: 1.0739  decode.loss_dice: 0.6488  decode.d0.loss_cls: 0.5044  decode.d0.loss_mask: 1.0364  decode.d0.loss_dice: 0.6255  decode.d1.loss_cls: 0.0765  decode.d1.loss_mask: 1.0727  decode.d1.loss_dice: 0.6433  decode.d2.loss_cls: 0.0674  decode.d2.loss_mask: 1.0775  decode.d2.loss_dice: 0.6478  decode.d3.loss_cls: 0.0613  decode.d3.loss_mask: 1.0771  decode.d3.loss_dice: 0.6505  decode.d4.loss_cls: 0.0643  decode.d4.loss_mask: 1.0746  decode.d4.loss_dice: 0.6403  decode.d5.loss_cls: 0.0689  decode.d5.loss_mask: 1.0744  decode.d5.loss_dice: 0.6478  decode.d6.loss_cls: 0.0938  decode.d6.loss_mask: 1.0700  decode.d6.loss_dice: 0.6345  decode.d7.loss_cls: 0.0963  decode.d7.loss_mask: 1.0653  decode.d7.loss_dice: 0.6363  decode.d8.loss_cls: 0.0758  decode.d8.loss_mask: 1.0728  decode.d8.loss_dice: 0.6429
05/27 03:11:48 - mmengine - INFO - Iter(train) [136900/160000]  base_lr: 1.7520e-05 lr: 1.7520e-06  eta: 2:39:18  time: 0.4172  data_time: 0.0098  memory: 5968  grad_norm: 446.9485  loss: 16.4703  decode.loss_cls: 0.1925  decode.loss_mask: 0.7370  decode.loss_dice: 0.6407  decode.d0.loss_cls: 0.6076  decode.d0.loss_mask: 0.7553  decode.d0.loss_dice: 0.6594  decode.d1.loss_cls: 0.2137  decode.d1.loss_mask: 0.7472  decode.d1.loss_dice: 0.6330  decode.d2.loss_cls: 0.1746  decode.d2.loss_mask: 0.7498  decode.d2.loss_dice: 0.6456  decode.d3.loss_cls: 0.1934  decode.d3.loss_mask: 0.7691  decode.d3.loss_dice: 0.6576  decode.d4.loss_cls: 0.1797  decode.d4.loss_mask: 0.7614  decode.d4.loss_dice: 0.6550  decode.d5.loss_cls: 0.1866  decode.d5.loss_mask: 0.7947  decode.d5.loss_dice: 0.6860  decode.d6.loss_cls: 0.2006  decode.d6.loss_mask: 0.7456  decode.d6.loss_dice: 0.6547  decode.d7.loss_cls: 0.1909  decode.d7.loss_mask: 0.7767  decode.d7.loss_dice: 0.6570  decode.d8.loss_cls: 0.1909  decode.d8.loss_mask: 0.7718  decode.d8.loss_dice: 0.6422
05/27 03:12:09 - mmengine - INFO - Iter(train) [136950/160000]  base_lr: 1.7486e-05 lr: 1.7486e-06  eta: 2:38:57  time: 0.4169  data_time: 0.0099  memory: 5976  grad_norm: 778.4563  loss: 23.1081  decode.loss_cls: 0.1555  decode.loss_mask: 1.2468  decode.loss_dice: 0.8779  decode.d0.loss_cls: 0.6618  decode.d0.loss_mask: 1.1741  decode.d0.loss_dice: 0.8102  decode.d1.loss_cls: 0.2257  decode.d1.loss_mask: 1.2375  decode.d1.loss_dice: 0.8445  decode.d2.loss_cls: 0.2099  decode.d2.loss_mask: 1.2299  decode.d2.loss_dice: 0.8404  decode.d3.loss_cls: 0.1904  decode.d3.loss_mask: 1.2128  decode.d3.loss_dice: 0.8353  decode.d4.loss_cls: 0.2043  decode.d4.loss_mask: 1.2208  decode.d4.loss_dice: 0.8214  decode.d5.loss_cls: 0.1739  decode.d5.loss_mask: 1.2695  decode.d5.loss_dice: 0.8557  decode.d6.loss_cls: 0.1825  decode.d6.loss_mask: 1.2487  decode.d6.loss_dice: 0.8546  decode.d7.loss_cls: 0.2129  decode.d7.loss_mask: 1.1950  decode.d7.loss_dice: 0.8270  decode.d8.loss_cls: 0.1853  decode.d8.loss_mask: 1.2477  decode.d8.loss_dice: 0.8560
05/27 03:12:30 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 03:12:30 - mmengine - INFO - Iter(train) [137000/160000]  base_lr: 1.7452e-05 lr: 1.7452e-06  eta: 2:38:37  time: 0.4173  data_time: 0.0099  memory: 5976  grad_norm: 518.9478  loss: 16.6084  decode.loss_cls: 0.1338  decode.loss_mask: 0.8970  decode.loss_dice: 0.5483  decode.d0.loss_cls: 0.5039  decode.d0.loss_mask: 0.9388  decode.d0.loss_dice: 0.5763  decode.d1.loss_cls: 0.1332  decode.d1.loss_mask: 0.9158  decode.d1.loss_dice: 0.5672  decode.d2.loss_cls: 0.1059  decode.d2.loss_mask: 0.9517  decode.d2.loss_dice: 0.5853  decode.d3.loss_cls: 0.1543  decode.d3.loss_mask: 0.9151  decode.d3.loss_dice: 0.5687  decode.d4.loss_cls: 0.1373  decode.d4.loss_mask: 0.9093  decode.d4.loss_dice: 0.5536  decode.d5.loss_cls: 0.1335  decode.d5.loss_mask: 0.9162  decode.d5.loss_dice: 0.5598  decode.d6.loss_cls: 0.1593  decode.d6.loss_mask: 0.9071  decode.d6.loss_dice: 0.5600  decode.d7.loss_cls: 0.1183  decode.d7.loss_mask: 0.9293  decode.d7.loss_dice: 0.5770  decode.d8.loss_cls: 0.1687  decode.d8.loss_mask: 0.9164  decode.d8.loss_dice: 0.5672
05/27 03:12:51 - mmengine - INFO - Iter(train) [137050/160000]  base_lr: 1.7418e-05 lr: 1.7418e-06  eta: 2:38:16  time: 0.4168  data_time: 0.0098  memory: 5966  grad_norm: 601.9312  loss: 17.3600  decode.loss_cls: 0.1413  decode.loss_mask: 0.8509  decode.loss_dice: 0.6775  decode.d0.loss_cls: 0.6694  decode.d0.loss_mask: 0.8553  decode.d0.loss_dice: 0.6654  decode.d1.loss_cls: 0.1895  decode.d1.loss_mask: 0.8566  decode.d1.loss_dice: 0.6770  decode.d2.loss_cls: 0.1915  decode.d2.loss_mask: 0.8370  decode.d2.loss_dice: 0.6613  decode.d3.loss_cls: 0.1717  decode.d3.loss_mask: 0.8323  decode.d3.loss_dice: 0.6628  decode.d4.loss_cls: 0.1772  decode.d4.loss_mask: 0.8404  decode.d4.loss_dice: 0.6650  decode.d5.loss_cls: 0.1728  decode.d5.loss_mask: 0.8552  decode.d5.loss_dice: 0.6820  decode.d6.loss_cls: 0.1579  decode.d6.loss_mask: 0.8381  decode.d6.loss_dice: 0.6759  decode.d7.loss_cls: 0.1607  decode.d7.loss_mask: 0.8506  decode.d7.loss_dice: 0.6788  decode.d8.loss_cls: 0.1775  decode.d8.loss_mask: 0.8258  decode.d8.loss_dice: 0.6626
05/27 03:13:12 - mmengine - INFO - Iter(train) [137100/160000]  base_lr: 1.7384e-05 lr: 1.7384e-06  eta: 2:37:55  time: 0.4167  data_time: 0.0098  memory: 5971  grad_norm: 554.6194  loss: 17.7775  decode.loss_cls: 0.1071  decode.loss_mask: 0.9351  decode.loss_dice: 0.6737  decode.d0.loss_cls: 0.6982  decode.d0.loss_mask: 0.9497  decode.d0.loss_dice: 0.6709  decode.d1.loss_cls: 0.1568  decode.d1.loss_mask: 0.9361  decode.d1.loss_dice: 0.6553  decode.d2.loss_cls: 0.1230  decode.d2.loss_mask: 0.9417  decode.d2.loss_dice: 0.6539  decode.d3.loss_cls: 0.1223  decode.d3.loss_mask: 0.9266  decode.d3.loss_dice: 0.6529  decode.d4.loss_cls: 0.1251  decode.d4.loss_mask: 0.9206  decode.d4.loss_dice: 0.6563  decode.d5.loss_cls: 0.1146  decode.d5.loss_mask: 0.9331  decode.d5.loss_dice: 0.6665  decode.d6.loss_cls: 0.1334  decode.d6.loss_mask: 0.9180  decode.d6.loss_dice: 0.6701  decode.d7.loss_cls: 0.1266  decode.d7.loss_mask: 0.9336  decode.d7.loss_dice: 0.6592  decode.d8.loss_cls: 0.1235  decode.d8.loss_mask: 0.9182  decode.d8.loss_dice: 0.6752
05/27 03:13:32 - mmengine - INFO - Iter(train) [137150/160000]  base_lr: 1.7350e-05 lr: 1.7350e-06  eta: 2:37:35  time: 0.4162  data_time: 0.0098  memory: 5966  grad_norm: 734.8065  loss: 20.0416  decode.loss_cls: 0.2464  decode.loss_mask: 0.9814  decode.loss_dice: 0.7156  decode.d0.loss_cls: 0.7514  decode.d0.loss_mask: 0.9853  decode.d0.loss_dice: 0.6783  decode.d1.loss_cls: 0.2572  decode.d1.loss_mask: 0.9787  decode.d1.loss_dice: 0.7303  decode.d2.loss_cls: 0.2646  decode.d2.loss_mask: 0.9637  decode.d2.loss_dice: 0.6893  decode.d3.loss_cls: 0.2528  decode.d3.loss_mask: 1.0134  decode.d3.loss_dice: 0.7025  decode.d4.loss_cls: 0.2176  decode.d4.loss_mask: 1.0167  decode.d4.loss_dice: 0.7117  decode.d5.loss_cls: 0.2602  decode.d5.loss_mask: 1.0022  decode.d5.loss_dice: 0.7231  decode.d6.loss_cls: 0.2664  decode.d6.loss_mask: 0.9862  decode.d6.loss_dice: 0.7007  decode.d7.loss_cls: 0.2471  decode.d7.loss_mask: 1.0007  decode.d7.loss_dice: 0.7152  decode.d8.loss_cls: 0.2390  decode.d8.loss_mask: 1.0325  decode.d8.loss_dice: 0.7116
05/27 03:13:53 - mmengine - INFO - Iter(train) [137200/160000]  base_lr: 1.7316e-05 lr: 1.7316e-06  eta: 2:37:14  time: 0.4171  data_time: 0.0098  memory: 5980  grad_norm: 418.4487  loss: 18.8618  decode.loss_cls: 0.2181  decode.loss_mask: 0.9722  decode.loss_dice: 0.6589  decode.d0.loss_cls: 0.6639  decode.d0.loss_mask: 0.9223  decode.d0.loss_dice: 0.6595  decode.d1.loss_cls: 0.2414  decode.d1.loss_mask: 0.9445  decode.d1.loss_dice: 0.6908  decode.d2.loss_cls: 0.2299  decode.d2.loss_mask: 0.9111  decode.d2.loss_dice: 0.6637  decode.d3.loss_cls: 0.2427  decode.d3.loss_mask: 0.9361  decode.d3.loss_dice: 0.6820  decode.d4.loss_cls: 0.2354  decode.d4.loss_mask: 0.9085  decode.d4.loss_dice: 0.6580  decode.d5.loss_cls: 0.2537  decode.d5.loss_mask: 0.8885  decode.d5.loss_dice: 0.6541  decode.d6.loss_cls: 0.2388  decode.d6.loss_mask: 0.9841  decode.d6.loss_dice: 0.7260  decode.d7.loss_cls: 0.2553  decode.d7.loss_mask: 0.9313  decode.d7.loss_dice: 0.6765  decode.d8.loss_cls: 0.2201  decode.d8.loss_mask: 0.9267  decode.d8.loss_dice: 0.6675
05/27 03:14:14 - mmengine - INFO - Iter(train) [137250/160000]  base_lr: 1.7281e-05 lr: 1.7281e-06  eta: 2:36:53  time: 0.4172  data_time: 0.0098  memory: 5982  grad_norm: 668.7787  loss: 17.8654  decode.loss_cls: 0.1778  decode.loss_mask: 0.9062  decode.loss_dice: 0.6243  decode.d0.loss_cls: 0.6818  decode.d0.loss_mask: 0.9056  decode.d0.loss_dice: 0.6073  decode.d1.loss_cls: 0.1595  decode.d1.loss_mask: 0.9228  decode.d1.loss_dice: 0.6418  decode.d2.loss_cls: 0.1996  decode.d2.loss_mask: 0.9360  decode.d2.loss_dice: 0.6479  decode.d3.loss_cls: 0.1979  decode.d3.loss_mask: 0.9258  decode.d3.loss_dice: 0.6304  decode.d4.loss_cls: 0.1655  decode.d4.loss_mask: 0.9517  decode.d4.loss_dice: 0.6541  decode.d5.loss_cls: 0.1727  decode.d5.loss_mask: 0.9311  decode.d5.loss_dice: 0.6371  decode.d6.loss_cls: 0.1974  decode.d6.loss_mask: 0.9179  decode.d6.loss_dice: 0.6274  decode.d7.loss_cls: 0.1547  decode.d7.loss_mask: 0.9442  decode.d7.loss_dice: 0.6424  decode.d8.loss_cls: 0.1781  decode.d8.loss_mask: 0.9002  decode.d8.loss_dice: 0.6261
05/27 03:14:35 - mmengine - INFO - Iter(train) [137300/160000]  base_lr: 1.7247e-05 lr: 1.7247e-06  eta: 2:36:33  time: 0.4164  data_time: 0.0098  memory: 5970  grad_norm: 613.2575  loss: 19.6582  decode.loss_cls: 0.1488  decode.loss_mask: 0.9934  decode.loss_dice: 0.7440  decode.d0.loss_cls: 0.5694  decode.d0.loss_mask: 1.0334  decode.d0.loss_dice: 0.7768  decode.d1.loss_cls: 0.1205  decode.d1.loss_mask: 1.0902  decode.d1.loss_dice: 0.7548  decode.d2.loss_cls: 0.1822  decode.d2.loss_mask: 0.9784  decode.d2.loss_dice: 0.7093  decode.d3.loss_cls: 0.1319  decode.d3.loss_mask: 1.0818  decode.d3.loss_dice: 0.7371  decode.d4.loss_cls: 0.1714  decode.d4.loss_mask: 1.0036  decode.d4.loss_dice: 0.7154  decode.d5.loss_cls: 0.1640  decode.d5.loss_mask: 0.9993  decode.d5.loss_dice: 0.7303  decode.d6.loss_cls: 0.1373  decode.d6.loss_mask: 1.0716  decode.d6.loss_dice: 0.7298  decode.d7.loss_cls: 0.1321  decode.d7.loss_mask: 1.0632  decode.d7.loss_dice: 0.7332  decode.d8.loss_cls: 0.1235  decode.d8.loss_mask: 1.0758  decode.d8.loss_dice: 0.7558
05/27 03:14:56 - mmengine - INFO - Iter(train) [137350/160000]  base_lr: 1.7213e-05 lr: 1.7213e-06  eta: 2:36:12  time: 0.4172  data_time: 0.0098  memory: 5976  grad_norm: 459.5044  loss: 17.7411  decode.loss_cls: 0.1733  decode.loss_mask: 0.7954  decode.loss_dice: 0.7486  decode.d0.loss_cls: 0.6447  decode.d0.loss_mask: 0.8179  decode.d0.loss_dice: 0.7392  decode.d1.loss_cls: 0.2033  decode.d1.loss_mask: 0.7932  decode.d1.loss_dice: 0.7323  decode.d2.loss_cls: 0.2056  decode.d2.loss_mask: 0.7863  decode.d2.loss_dice: 0.7241  decode.d3.loss_cls: 0.2106  decode.d3.loss_mask: 0.7878  decode.d3.loss_dice: 0.7288  decode.d4.loss_cls: 0.1749  decode.d4.loss_mask: 0.8048  decode.d4.loss_dice: 0.7436  decode.d5.loss_cls: 0.1831  decode.d5.loss_mask: 0.7935  decode.d5.loss_dice: 0.7313  decode.d6.loss_cls: 0.1943  decode.d6.loss_mask: 0.8002  decode.d6.loss_dice: 0.7476  decode.d7.loss_cls: 0.2117  decode.d7.loss_mask: 0.7890  decode.d7.loss_dice: 0.7411  decode.d8.loss_cls: 0.2126  decode.d8.loss_mask: 0.7988  decode.d8.loss_dice: 0.7236
05/27 03:15:17 - mmengine - INFO - Iter(train) [137400/160000]  base_lr: 1.7179e-05 lr: 1.7179e-06  eta: 2:35:51  time: 0.4179  data_time: 0.0098  memory: 5975  grad_norm: 504.4291  loss: 19.1397  decode.loss_cls: 0.2460  decode.loss_mask: 0.9440  decode.loss_dice: 0.7279  decode.d0.loss_cls: 0.6968  decode.d0.loss_mask: 0.8904  decode.d0.loss_dice: 0.6812  decode.d1.loss_cls: 0.2734  decode.d1.loss_mask: 0.9018  decode.d1.loss_dice: 0.7135  decode.d2.loss_cls: 0.2489  decode.d2.loss_mask: 0.8922  decode.d2.loss_dice: 0.6913  decode.d3.loss_cls: 0.2651  decode.d3.loss_mask: 0.9149  decode.d3.loss_dice: 0.6925  decode.d4.loss_cls: 0.2472  decode.d4.loss_mask: 0.9355  decode.d4.loss_dice: 0.6835  decode.d5.loss_cls: 0.2353  decode.d5.loss_mask: 0.9167  decode.d5.loss_dice: 0.7178  decode.d6.loss_cls: 0.2399  decode.d6.loss_mask: 0.8960  decode.d6.loss_dice: 0.7029  decode.d7.loss_cls: 0.2506  decode.d7.loss_mask: 0.9064  decode.d7.loss_dice: 0.7157  decode.d8.loss_cls: 0.2642  decode.d8.loss_mask: 0.9329  decode.d8.loss_dice: 0.7152
05/27 03:15:38 - mmengine - INFO - Iter(train) [137450/160000]  base_lr: 1.7145e-05 lr: 1.7145e-06  eta: 2:35:31  time: 0.4176  data_time: 0.0097  memory: 5976  grad_norm: 383.0273  loss: 16.6199  decode.loss_cls: 0.1641  decode.loss_mask: 0.8170  decode.loss_dice: 0.6548  decode.d0.loss_cls: 0.5132  decode.d0.loss_mask: 0.8547  decode.d0.loss_dice: 0.6602  decode.d1.loss_cls: 0.1119  decode.d1.loss_mask: 0.8711  decode.d1.loss_dice: 0.6640  decode.d2.loss_cls: 0.1386  decode.d2.loss_mask: 0.8099  decode.d2.loss_dice: 0.6591  decode.d3.loss_cls: 0.1417  decode.d3.loss_mask: 0.8097  decode.d3.loss_dice: 0.6577  decode.d4.loss_cls: 0.1261  decode.d4.loss_mask: 0.8307  decode.d4.loss_dice: 0.6668  decode.d5.loss_cls: 0.1203  decode.d5.loss_mask: 0.8251  decode.d5.loss_dice: 0.6631  decode.d6.loss_cls: 0.1046  decode.d6.loss_mask: 0.8538  decode.d6.loss_dice: 0.6711  decode.d7.loss_cls: 0.1408  decode.d7.loss_mask: 0.8313  decode.d7.loss_dice: 0.6561  decode.d8.loss_cls: 0.1353  decode.d8.loss_mask: 0.8192  decode.d8.loss_dice: 0.6479
05/27 03:15:59 - mmengine - INFO - Iter(train) [137500/160000]  base_lr: 1.7110e-05 lr: 1.7110e-06  eta: 2:35:10  time: 0.4177  data_time: 0.0098  memory: 5968  grad_norm: 545.8662  loss: 17.3234  decode.loss_cls: 0.1845  decode.loss_mask: 0.8499  decode.loss_dice: 0.6429  decode.d0.loss_cls: 0.6888  decode.d0.loss_mask: 0.8244  decode.d0.loss_dice: 0.6339  decode.d1.loss_cls: 0.2066  decode.d1.loss_mask: 0.8715  decode.d1.loss_dice: 0.6735  decode.d2.loss_cls: 0.1645  decode.d2.loss_mask: 0.8560  decode.d2.loss_dice: 0.6497  decode.d3.loss_cls: 0.1840  decode.d3.loss_mask: 0.8528  decode.d3.loss_dice: 0.6457  decode.d4.loss_cls: 0.1909  decode.d4.loss_mask: 0.8568  decode.d4.loss_dice: 0.6519  decode.d5.loss_cls: 0.1812  decode.d5.loss_mask: 0.8556  decode.d5.loss_dice: 0.6534  decode.d6.loss_cls: 0.1608  decode.d6.loss_mask: 0.8540  decode.d6.loss_dice: 0.6397  decode.d7.loss_cls: 0.1780  decode.d7.loss_mask: 0.8667  decode.d7.loss_dice: 0.6342  decode.d8.loss_cls: 0.1370  decode.d8.loss_mask: 0.8697  decode.d8.loss_dice: 0.6646
05/27 03:16:19 - mmengine - INFO - Iter(train) [137550/160000]  base_lr: 1.7076e-05 lr: 1.7076e-06  eta: 2:34:49  time: 0.4170  data_time: 0.0098  memory: 5967  grad_norm: 1219.9133  loss: 18.1288  decode.loss_cls: 0.2046  decode.loss_mask: 0.9440  decode.loss_dice: 0.6145  decode.d0.loss_cls: 0.6526  decode.d0.loss_mask: 0.9002  decode.d0.loss_dice: 0.6047  decode.d1.loss_cls: 0.2138  decode.d1.loss_mask: 0.9491  decode.d1.loss_dice: 0.6259  decode.d2.loss_cls: 0.2452  decode.d2.loss_mask: 0.9219  decode.d2.loss_dice: 0.6342  decode.d3.loss_cls: 0.2286  decode.d3.loss_mask: 0.9255  decode.d3.loss_dice: 0.6271  decode.d4.loss_cls: 0.2051  decode.d4.loss_mask: 0.9526  decode.d4.loss_dice: 0.6470  decode.d5.loss_cls: 0.1924  decode.d5.loss_mask: 0.9427  decode.d5.loss_dice: 0.6311  decode.d6.loss_cls: 0.1918  decode.d6.loss_mask: 0.9462  decode.d6.loss_dice: 0.6310  decode.d7.loss_cls: 0.1882  decode.d7.loss_mask: 0.9537  decode.d7.loss_dice: 0.6356  decode.d8.loss_cls: 0.2280  decode.d8.loss_mask: 0.9026  decode.d8.loss_dice: 0.5891
05/27 03:16:40 - mmengine - INFO - Iter(train) [137600/160000]  base_lr: 1.7042e-05 lr: 1.7042e-06  eta: 2:34:29  time: 0.4178  data_time: 0.0098  memory: 5977  grad_norm: 413.2581  loss: 16.8267  decode.loss_cls: 0.1793  decode.loss_mask: 0.8461  decode.loss_dice: 0.5836  decode.d0.loss_cls: 0.6542  decode.d0.loss_mask: 0.8035  decode.d0.loss_dice: 0.5692  decode.d1.loss_cls: 0.2053  decode.d1.loss_mask: 0.8537  decode.d1.loss_dice: 0.6143  decode.d2.loss_cls: 0.1932  decode.d2.loss_mask: 0.8469  decode.d2.loss_dice: 0.5919  decode.d3.loss_cls: 0.2066  decode.d3.loss_mask: 0.8441  decode.d3.loss_dice: 0.6021  decode.d4.loss_cls: 0.1855  decode.d4.loss_mask: 0.8474  decode.d4.loss_dice: 0.5948  decode.d5.loss_cls: 0.2189  decode.d5.loss_mask: 0.8373  decode.d5.loss_dice: 0.5826  decode.d6.loss_cls: 0.2018  decode.d6.loss_mask: 0.8416  decode.d6.loss_dice: 0.6037  decode.d7.loss_cls: 0.1840  decode.d7.loss_mask: 0.8574  decode.d7.loss_dice: 0.5938  decode.d8.loss_cls: 0.2131  decode.d8.loss_mask: 0.8638  decode.d8.loss_dice: 0.6074
05/27 03:17:01 - mmengine - INFO - Iter(train) [137650/160000]  base_lr: 1.7008e-05 lr: 1.7008e-06  eta: 2:34:08  time: 0.4164  data_time: 0.0097  memory: 5973  grad_norm: 528.8887  loss: 17.2056  decode.loss_cls: 0.1676  decode.loss_mask: 0.9065  decode.loss_dice: 0.6136  decode.d0.loss_cls: 0.5901  decode.d0.loss_mask: 0.8916  decode.d0.loss_dice: 0.6047  decode.d1.loss_cls: 0.1683  decode.d1.loss_mask: 0.8957  decode.d1.loss_dice: 0.6004  decode.d2.loss_cls: 0.1628  decode.d2.loss_mask: 0.8857  decode.d2.loss_dice: 0.5949  decode.d3.loss_cls: 0.1686  decode.d3.loss_mask: 0.9058  decode.d3.loss_dice: 0.6147  decode.d4.loss_cls: 0.1810  decode.d4.loss_mask: 0.9024  decode.d4.loss_dice: 0.6032  decode.d5.loss_cls: 0.1592  decode.d5.loss_mask: 0.8919  decode.d5.loss_dice: 0.6042  decode.d6.loss_cls: 0.1639  decode.d6.loss_mask: 0.9317  decode.d6.loss_dice: 0.6142  decode.d7.loss_cls: 0.1770  decode.d7.loss_mask: 0.8979  decode.d7.loss_dice: 0.6024  decode.d8.loss_cls: 0.1929  decode.d8.loss_mask: 0.9110  decode.d8.loss_dice: 0.6020
05/27 03:17:22 - mmengine - INFO - Iter(train) [137700/160000]  base_lr: 1.6973e-05 lr: 1.6973e-06  eta: 2:33:47  time: 0.4168  data_time: 0.0100  memory: 5975  grad_norm: 818.9236  loss: 22.4604  decode.loss_cls: 0.2506  decode.loss_mask: 1.2075  decode.loss_dice: 0.7403  decode.d0.loss_cls: 0.7619  decode.d0.loss_mask: 1.1659  decode.d0.loss_dice: 0.7657  decode.d1.loss_cls: 0.2476  decode.d1.loss_mask: 1.2090  decode.d1.loss_dice: 0.7505  decode.d2.loss_cls: 0.2132  decode.d2.loss_mask: 1.2457  decode.d2.loss_dice: 0.7585  decode.d3.loss_cls: 0.1947  decode.d3.loss_mask: 1.2183  decode.d3.loss_dice: 0.7355  decode.d4.loss_cls: 0.2574  decode.d4.loss_mask: 1.1858  decode.d4.loss_dice: 0.7459  decode.d5.loss_cls: 0.2542  decode.d5.loss_mask: 1.2011  decode.d5.loss_dice: 0.7440  decode.d6.loss_cls: 0.2373  decode.d6.loss_mask: 1.2184  decode.d6.loss_dice: 0.7571  decode.d7.loss_cls: 0.2247  decode.d7.loss_mask: 1.2310  decode.d7.loss_dice: 0.7563  decode.d8.loss_cls: 0.2293  decode.d8.loss_mask: 1.2075  decode.d8.loss_dice: 0.7452
05/27 03:17:43 - mmengine - INFO - Iter(train) [137750/160000]  base_lr: 1.6939e-05 lr: 1.6939e-06  eta: 2:33:27  time: 0.4169  data_time: 0.0099  memory: 5966  grad_norm: 540.0027  loss: 21.2294  decode.loss_cls: 0.1654  decode.loss_mask: 1.0487  decode.loss_dice: 0.8566  decode.d0.loss_cls: 0.7918  decode.d0.loss_mask: 0.9676  decode.d0.loss_dice: 0.8059  decode.d1.loss_cls: 0.2327  decode.d1.loss_mask: 1.0656  decode.d1.loss_dice: 0.8439  decode.d2.loss_cls: 0.1974  decode.d2.loss_mask: 1.0431  decode.d2.loss_dice: 0.8391  decode.d3.loss_cls: 0.2267  decode.d3.loss_mask: 1.0154  decode.d3.loss_dice: 0.7976  decode.d4.loss_cls: 0.2124  decode.d4.loss_mask: 1.0107  decode.d4.loss_dice: 0.8235  decode.d5.loss_cls: 0.2010  decode.d5.loss_mask: 1.0517  decode.d5.loss_dice: 0.8371  decode.d6.loss_cls: 0.1740  decode.d6.loss_mask: 1.0696  decode.d6.loss_dice: 0.8421  decode.d7.loss_cls: 0.1628  decode.d7.loss_mask: 1.0647  decode.d7.loss_dice: 0.8509  decode.d8.loss_cls: 0.1796  decode.d8.loss_mask: 1.0280  decode.d8.loss_dice: 0.8237
05/27 03:18:04 - mmengine - INFO - Iter(train) [137800/160000]  base_lr: 1.6905e-05 lr: 1.6905e-06  eta: 2:33:06  time: 0.4182  data_time: 0.0100  memory: 5979  grad_norm: 447.0943  loss: 21.6370  decode.loss_cls: 0.1320  decode.loss_mask: 1.1373  decode.loss_dice: 0.8363  decode.d0.loss_cls: 0.6252  decode.d0.loss_mask: 1.1529  decode.d0.loss_dice: 0.8238  decode.d1.loss_cls: 0.1702  decode.d1.loss_mask: 1.1413  decode.d1.loss_dice: 0.8262  decode.d2.loss_cls: 0.1679  decode.d2.loss_mask: 1.1414  decode.d2.loss_dice: 0.8030  decode.d3.loss_cls: 0.1563  decode.d3.loss_mask: 1.1519  decode.d3.loss_dice: 0.8451  decode.d4.loss_cls: 0.1390  decode.d4.loss_mask: 1.1286  decode.d4.loss_dice: 0.8202  decode.d5.loss_cls: 0.1686  decode.d5.loss_mask: 1.1404  decode.d5.loss_dice: 0.8207  decode.d6.loss_cls: 0.1456  decode.d6.loss_mask: 1.1392  decode.d6.loss_dice: 0.8274  decode.d7.loss_cls: 0.1737  decode.d7.loss_mask: 1.1255  decode.d7.loss_dice: 0.7974  decode.d8.loss_cls: 0.1314  decode.d8.loss_mask: 1.1319  decode.d8.loss_dice: 0.8366
05/27 03:18:25 - mmengine - INFO - Iter(train) [137850/160000]  base_lr: 1.6871e-05 lr: 1.6871e-06  eta: 2:32:45  time: 0.4175  data_time: 0.0099  memory: 5966  grad_norm: 575.7365  loss: 19.8848  decode.loss_cls: 0.0892  decode.loss_mask: 1.0758  decode.loss_dice: 0.7535  decode.d0.loss_cls: 0.5761  decode.d0.loss_mask: 1.0844  decode.d0.loss_dice: 0.7690  decode.d1.loss_cls: 0.0893  decode.d1.loss_mask: 1.0993  decode.d1.loss_dice: 0.7911  decode.d2.loss_cls: 0.0887  decode.d2.loss_mask: 1.0951  decode.d2.loss_dice: 0.7695  decode.d3.loss_cls: 0.0742  decode.d3.loss_mask: 1.0986  decode.d3.loss_dice: 0.7735  decode.d4.loss_cls: 0.0913  decode.d4.loss_mask: 1.0811  decode.d4.loss_dice: 0.7530  decode.d5.loss_cls: 0.0849  decode.d5.loss_mask: 1.0948  decode.d5.loss_dice: 0.7555  decode.d6.loss_cls: 0.0802  decode.d6.loss_mask: 1.0873  decode.d6.loss_dice: 0.7709  decode.d7.loss_cls: 0.1046  decode.d7.loss_mask: 1.0746  decode.d7.loss_dice: 0.7481  decode.d8.loss_cls: 0.0947  decode.d8.loss_mask: 1.0778  decode.d8.loss_dice: 0.7587
05/27 03:18:46 - mmengine - INFO - Iter(train) [137900/160000]  base_lr: 1.6836e-05 lr: 1.6836e-06  eta: 2:32:25  time: 0.4171  data_time: 0.0099  memory: 5967  grad_norm: 553.8836  loss: 16.3752  decode.loss_cls: 0.1375  decode.loss_mask: 0.8309  decode.loss_dice: 0.5896  decode.d0.loss_cls: 0.6037  decode.d0.loss_mask: 0.8527  decode.d0.loss_dice: 0.6108  decode.d1.loss_cls: 0.1275  decode.d1.loss_mask: 0.8707  decode.d1.loss_dice: 0.6254  decode.d2.loss_cls: 0.1235  decode.d2.loss_mask: 0.8596  decode.d2.loss_dice: 0.6183  decode.d3.loss_cls: 0.1206  decode.d3.loss_mask: 0.8417  decode.d3.loss_dice: 0.5932  decode.d4.loss_cls: 0.1548  decode.d4.loss_mask: 0.8516  decode.d4.loss_dice: 0.6038  decode.d5.loss_cls: 0.1342  decode.d5.loss_mask: 0.8590  decode.d5.loss_dice: 0.6133  decode.d6.loss_cls: 0.1347  decode.d6.loss_mask: 0.8468  decode.d6.loss_dice: 0.5938  decode.d7.loss_cls: 0.1374  decode.d7.loss_mask: 0.8452  decode.d7.loss_dice: 0.6097  decode.d8.loss_cls: 0.1391  decode.d8.loss_mask: 0.8426  decode.d8.loss_dice: 0.6037
05/27 03:19:07 - mmengine - INFO - Iter(train) [137950/160000]  base_lr: 1.6802e-05 lr: 1.6802e-06  eta: 2:32:04  time: 0.4169  data_time: 0.0099  memory: 5970  grad_norm: 357.1608  loss: 17.4519  decode.loss_cls: 0.1239  decode.loss_mask: 0.8848  decode.loss_dice: 0.6674  decode.d0.loss_cls: 0.5709  decode.d0.loss_mask: 0.8883  decode.d0.loss_dice: 0.6788  decode.d1.loss_cls: 0.0905  decode.d1.loss_mask: 0.9240  decode.d1.loss_dice: 0.7217  decode.d2.loss_cls: 0.0987  decode.d2.loss_mask: 0.9273  decode.d2.loss_dice: 0.6895  decode.d3.loss_cls: 0.0990  decode.d3.loss_mask: 0.9320  decode.d3.loss_dice: 0.6899  decode.d4.loss_cls: 0.0922  decode.d4.loss_mask: 0.9420  decode.d4.loss_dice: 0.6881  decode.d5.loss_cls: 0.0811  decode.d5.loss_mask: 0.9425  decode.d5.loss_dice: 0.6926  decode.d6.loss_cls: 0.0907  decode.d6.loss_mask: 0.9052  decode.d6.loss_dice: 0.6831  decode.d7.loss_cls: 0.0991  decode.d7.loss_mask: 0.8801  decode.d7.loss_dice: 0.6721  decode.d8.loss_cls: 0.1179  decode.d8.loss_mask: 0.8817  decode.d8.loss_dice: 0.6964
05/27 03:19:28 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 03:19:28 - mmengine - INFO - Iter(train) [138000/160000]  base_lr: 1.6768e-05 lr: 1.6768e-06  eta: 2:31:43  time: 0.4175  data_time: 0.0100  memory: 5984  grad_norm: 663.3171  loss: 16.7898  decode.loss_cls: 0.0460  decode.loss_mask: 0.9348  decode.loss_dice: 0.6392  decode.d0.loss_cls: 0.5156  decode.d0.loss_mask: 0.8966  decode.d0.loss_dice: 0.6268  decode.d1.loss_cls: 0.0609  decode.d1.loss_mask: 0.9198  decode.d1.loss_dice: 0.6548  decode.d2.loss_cls: 0.0838  decode.d2.loss_mask: 0.9161  decode.d2.loss_dice: 0.6574  decode.d3.loss_cls: 0.0674  decode.d3.loss_mask: 0.9266  decode.d3.loss_dice: 0.6486  decode.d4.loss_cls: 0.0465  decode.d4.loss_mask: 0.9347  decode.d4.loss_dice: 0.6533  decode.d5.loss_cls: 0.0465  decode.d5.loss_mask: 0.9471  decode.d5.loss_dice: 0.6488  decode.d6.loss_cls: 0.0500  decode.d6.loss_mask: 0.9445  decode.d6.loss_dice: 0.6327  decode.d7.loss_cls: 0.0543  decode.d7.loss_mask: 0.9358  decode.d7.loss_dice: 0.6434  decode.d8.loss_cls: 0.0464  decode.d8.loss_mask: 0.9510  decode.d8.loss_dice: 0.6604
05/27 03:19:48 - mmengine - INFO - Iter(train) [138050/160000]  base_lr: 1.6733e-05 lr: 1.6733e-06  eta: 2:31:23  time: 0.4173  data_time: 0.0099  memory: 5967  grad_norm: 1121.6174  loss: 21.2685  decode.loss_cls: 0.3301  decode.loss_mask: 1.0004  decode.loss_dice: 0.7587  decode.d0.loss_cls: 0.8536  decode.d0.loss_mask: 0.9936  decode.d0.loss_dice: 0.7813  decode.d1.loss_cls: 0.2994  decode.d1.loss_mask: 1.0018  decode.d1.loss_dice: 0.7602  decode.d2.loss_cls: 0.3529  decode.d2.loss_mask: 0.9860  decode.d2.loss_dice: 0.7467  decode.d3.loss_cls: 0.3591  decode.d3.loss_mask: 0.9663  decode.d3.loss_dice: 0.7370  decode.d4.loss_cls: 0.3184  decode.d4.loss_mask: 0.9872  decode.d4.loss_dice: 0.7762  decode.d5.loss_cls: 0.3385  decode.d5.loss_mask: 0.9833  decode.d5.loss_dice: 0.7353  decode.d6.loss_cls: 0.3353  decode.d6.loss_mask: 0.9777  decode.d6.loss_dice: 0.7235  decode.d7.loss_cls: 0.3526  decode.d7.loss_mask: 0.9858  decode.d7.loss_dice: 0.7485  decode.d8.loss_cls: 0.3344  decode.d8.loss_mask: 0.9795  decode.d8.loss_dice: 0.7650
05/27 03:20:09 - mmengine - INFO - Iter(train) [138100/160000]  base_lr: 1.6699e-05 lr: 1.6699e-06  eta: 2:31:02  time: 0.4190  data_time: 0.0101  memory: 5973  grad_norm: 433.1015  loss: 18.3609  decode.loss_cls: 0.2431  decode.loss_mask: 0.8626  decode.loss_dice: 0.6951  decode.d0.loss_cls: 0.7181  decode.d0.loss_mask: 0.8135  decode.d0.loss_dice: 0.7219  decode.d1.loss_cls: 0.2167  decode.d1.loss_mask: 0.8612  decode.d1.loss_dice: 0.7260  decode.d2.loss_cls: 0.2224  decode.d2.loss_mask: 0.8696  decode.d2.loss_dice: 0.7269  decode.d3.loss_cls: 0.2196  decode.d3.loss_mask: 0.8532  decode.d3.loss_dice: 0.7011  decode.d4.loss_cls: 0.2477  decode.d4.loss_mask: 0.8477  decode.d4.loss_dice: 0.6934  decode.d5.loss_cls: 0.1993  decode.d5.loss_mask: 0.8698  decode.d5.loss_dice: 0.7113  decode.d6.loss_cls: 0.2082  decode.d6.loss_mask: 0.8554  decode.d6.loss_dice: 0.6958  decode.d7.loss_cls: 0.1958  decode.d7.loss_mask: 0.8605  decode.d7.loss_dice: 0.7288  decode.d8.loss_cls: 0.2190  decode.d8.loss_mask: 0.8742  decode.d8.loss_dice: 0.7025
05/27 03:20:30 - mmengine - INFO - Iter(train) [138150/160000]  base_lr: 1.6665e-05 lr: 1.6665e-06  eta: 2:30:41  time: 0.4164  data_time: 0.0099  memory: 5965  grad_norm: 526.6584  loss: 21.9441  decode.loss_cls: 0.1698  decode.loss_mask: 1.1721  decode.loss_dice: 0.7736  decode.d0.loss_cls: 0.6863  decode.d0.loss_mask: 1.0927  decode.d0.loss_dice: 0.7641  decode.d1.loss_cls: 0.2110  decode.d1.loss_mask: 1.1849  decode.d1.loss_dice: 0.7916  decode.d2.loss_cls: 0.1631  decode.d2.loss_mask: 1.1480  decode.d2.loss_dice: 0.7776  decode.d3.loss_cls: 0.1746  decode.d3.loss_mask: 1.2315  decode.d3.loss_dice: 0.7962  decode.d4.loss_cls: 0.1809  decode.d4.loss_mask: 1.2069  decode.d4.loss_dice: 0.7728  decode.d5.loss_cls: 0.1579  decode.d5.loss_mask: 1.2103  decode.d5.loss_dice: 0.8257  decode.d6.loss_cls: 0.1868  decode.d6.loss_mask: 1.1808  decode.d6.loss_dice: 0.7937  decode.d7.loss_cls: 0.1762  decode.d7.loss_mask: 1.1913  decode.d7.loss_dice: 0.7842  decode.d8.loss_cls: 0.1431  decode.d8.loss_mask: 1.1856  decode.d8.loss_dice: 0.8111
05/27 03:20:51 - mmengine - INFO - Iter(train) [138200/160000]  base_lr: 1.6630e-05 lr: 1.6630e-06  eta: 2:30:21  time: 0.4173  data_time: 0.0099  memory: 5971  grad_norm: 441.8730  loss: 17.8629  decode.loss_cls: 0.1040  decode.loss_mask: 0.9190  decode.loss_dice: 0.6805  decode.d0.loss_cls: 0.7104  decode.d0.loss_mask: 0.9146  decode.d0.loss_dice: 0.6704  decode.d1.loss_cls: 0.1270  decode.d1.loss_mask: 0.9413  decode.d1.loss_dice: 0.7332  decode.d2.loss_cls: 0.1301  decode.d2.loss_mask: 0.9152  decode.d2.loss_dice: 0.6929  decode.d3.loss_cls: 0.1135  decode.d3.loss_mask: 0.9423  decode.d3.loss_dice: 0.7092  decode.d4.loss_cls: 0.1069  decode.d4.loss_mask: 0.9254  decode.d4.loss_dice: 0.6896  decode.d5.loss_cls: 0.1025  decode.d5.loss_mask: 0.9164  decode.d5.loss_dice: 0.7002  decode.d6.loss_cls: 0.0963  decode.d6.loss_mask: 0.9301  decode.d6.loss_dice: 0.6840  decode.d7.loss_cls: 0.0947  decode.d7.loss_mask: 0.9157  decode.d7.loss_dice: 0.6878  decode.d8.loss_cls: 0.0977  decode.d8.loss_mask: 0.9218  decode.d8.loss_dice: 0.6902
05/27 03:21:12 - mmengine - INFO - Iter(train) [138250/160000]  base_lr: 1.6596e-05 lr: 1.6596e-06  eta: 2:30:00  time: 0.4170  data_time: 0.0099  memory: 5966  grad_norm: 525.5190  loss: 17.4067  decode.loss_cls: 0.1705  decode.loss_mask: 0.9156  decode.loss_dice: 0.6176  decode.d0.loss_cls: 0.5783  decode.d0.loss_mask: 0.9254  decode.d0.loss_dice: 0.6327  decode.d1.loss_cls: 0.1516  decode.d1.loss_mask: 0.9067  decode.d1.loss_dice: 0.6108  decode.d2.loss_cls: 0.1701  decode.d2.loss_mask: 0.8966  decode.d2.loss_dice: 0.6059  decode.d3.loss_cls: 0.1858  decode.d3.loss_mask: 0.8911  decode.d3.loss_dice: 0.6012  decode.d4.loss_cls: 0.1585  decode.d4.loss_mask: 0.9291  decode.d4.loss_dice: 0.6342  decode.d5.loss_cls: 0.1605  decode.d5.loss_mask: 0.9292  decode.d5.loss_dice: 0.6169  decode.d6.loss_cls: 0.1780  decode.d6.loss_mask: 0.9398  decode.d6.loss_dice: 0.6294  decode.d7.loss_cls: 0.1934  decode.d7.loss_mask: 0.8970  decode.d7.loss_dice: 0.6054  decode.d8.loss_cls: 0.1675  decode.d8.loss_mask: 0.9082  decode.d8.loss_dice: 0.5997
05/27 03:21:33 - mmengine - INFO - Iter(train) [138300/160000]  base_lr: 1.6562e-05 lr: 1.6562e-06  eta: 2:29:39  time: 0.4168  data_time: 0.0100  memory: 5976  grad_norm: 1014.0942  loss: 19.6696  decode.loss_cls: 0.1323  decode.loss_mask: 1.1639  decode.loss_dice: 0.6710  decode.d0.loss_cls: 0.5396  decode.d0.loss_mask: 1.1316  decode.d0.loss_dice: 0.6998  decode.d1.loss_cls: 0.1573  decode.d1.loss_mask: 1.0960  decode.d1.loss_dice: 0.6549  decode.d2.loss_cls: 0.0970  decode.d2.loss_mask: 1.1589  decode.d2.loss_dice: 0.6627  decode.d3.loss_cls: 0.1189  decode.d3.loss_mask: 1.1075  decode.d3.loss_dice: 0.6683  decode.d4.loss_cls: 0.1425  decode.d4.loss_mask: 1.0914  decode.d4.loss_dice: 0.6831  decode.d5.loss_cls: 0.1071  decode.d5.loss_mask: 1.1265  decode.d5.loss_dice: 0.6887  decode.d6.loss_cls: 0.1462  decode.d6.loss_mask: 1.0852  decode.d6.loss_dice: 0.6562  decode.d7.loss_cls: 0.1440  decode.d7.loss_mask: 1.1468  decode.d7.loss_dice: 0.6727  decode.d8.loss_cls: 0.1659  decode.d8.loss_mask: 1.1006  decode.d8.loss_dice: 0.6529
05/27 03:21:54 - mmengine - INFO - Iter(train) [138350/160000]  base_lr: 1.6527e-05 lr: 1.6527e-06  eta: 2:29:19  time: 0.4170  data_time: 0.0099  memory: 5976  grad_norm: 508.3424  loss: 18.5488  decode.loss_cls: 0.2172  decode.loss_mask: 0.8843  decode.loss_dice: 0.6896  decode.d0.loss_cls: 0.7105  decode.d0.loss_mask: 0.8603  decode.d0.loss_dice: 0.6550  decode.d1.loss_cls: 0.2925  decode.d1.loss_mask: 0.8953  decode.d1.loss_dice: 0.6847  decode.d2.loss_cls: 0.2725  decode.d2.loss_mask: 0.8624  decode.d2.loss_dice: 0.6642  decode.d3.loss_cls: 0.2497  decode.d3.loss_mask: 0.8588  decode.d3.loss_dice: 0.6742  decode.d4.loss_cls: 0.2429  decode.d4.loss_mask: 0.8814  decode.d4.loss_dice: 0.6856  decode.d5.loss_cls: 0.2678  decode.d5.loss_mask: 0.8781  decode.d5.loss_dice: 0.6755  decode.d6.loss_cls: 0.2410  decode.d6.loss_mask: 0.8751  decode.d6.loss_dice: 0.7027  decode.d7.loss_cls: 0.2826  decode.d7.loss_mask: 0.8722  decode.d7.loss_dice: 0.6828  decode.d8.loss_cls: 0.2294  decode.d8.loss_mask: 0.8754  decode.d8.loss_dice: 0.6847
05/27 03:22:15 - mmengine - INFO - Iter(train) [138400/160000]  base_lr: 1.6493e-05 lr: 1.6493e-06  eta: 2:28:58  time: 0.4168  data_time: 0.0099  memory: 5971  grad_norm: 650.5410  loss: 20.3934  decode.loss_cls: 0.1930  decode.loss_mask: 1.0582  decode.loss_dice: 0.7630  decode.d0.loss_cls: 0.7415  decode.d0.loss_mask: 0.9891  decode.d0.loss_dice: 0.7320  decode.d1.loss_cls: 0.2249  decode.d1.loss_mask: 1.0052  decode.d1.loss_dice: 0.7249  decode.d2.loss_cls: 0.2081  decode.d2.loss_mask: 1.0237  decode.d2.loss_dice: 0.7321  decode.d3.loss_cls: 0.1909  decode.d3.loss_mask: 1.0477  decode.d3.loss_dice: 0.7511  decode.d4.loss_cls: 0.2211  decode.d4.loss_mask: 1.0151  decode.d4.loss_dice: 0.7256  decode.d5.loss_cls: 0.1799  decode.d5.loss_mask: 1.0847  decode.d5.loss_dice: 0.7647  decode.d6.loss_cls: 0.1992  decode.d6.loss_mask: 1.0669  decode.d6.loss_dice: 0.7565  decode.d7.loss_cls: 0.2113  decode.d7.loss_mask: 1.0341  decode.d7.loss_dice: 0.7518  decode.d8.loss_cls: 0.1868  decode.d8.loss_mask: 1.0529  decode.d8.loss_dice: 0.7574
05/27 03:22:35 - mmengine - INFO - Iter(train) [138450/160000]  base_lr: 1.6459e-05 lr: 1.6459e-06  eta: 2:28:37  time: 0.4169  data_time: 0.0099  memory: 5969  grad_norm: 369.7495  loss: 18.0394  decode.loss_cls: 0.1611  decode.loss_mask: 0.9248  decode.loss_dice: 0.6822  decode.d0.loss_cls: 0.5448  decode.d0.loss_mask: 0.8978  decode.d0.loss_dice: 0.6742  decode.d1.loss_cls: 0.1058  decode.d1.loss_mask: 0.9393  decode.d1.loss_dice: 0.7104  decode.d2.loss_cls: 0.1383  decode.d2.loss_mask: 0.9449  decode.d2.loss_dice: 0.6944  decode.d3.loss_cls: 0.1306  decode.d3.loss_mask: 0.9502  decode.d3.loss_dice: 0.7052  decode.d4.loss_cls: 0.1445  decode.d4.loss_mask: 0.9254  decode.d4.loss_dice: 0.6844  decode.d5.loss_cls: 0.1305  decode.d5.loss_mask: 0.9350  decode.d5.loss_dice: 0.6799  decode.d6.loss_cls: 0.1157  decode.d6.loss_mask: 0.9457  decode.d6.loss_dice: 0.7292  decode.d7.loss_cls: 0.1509  decode.d7.loss_mask: 0.9374  decode.d7.loss_dice: 0.7050  decode.d8.loss_cls: 0.1243  decode.d8.loss_mask: 0.9242  decode.d8.loss_dice: 0.7034
05/27 03:22:56 - mmengine - INFO - Iter(train) [138500/160000]  base_lr: 1.6424e-05 lr: 1.6424e-06  eta: 2:28:17  time: 0.4175  data_time: 0.0099  memory: 5976  grad_norm: 1019.8553  loss: 23.0861  decode.loss_cls: 0.1600  decode.loss_mask: 1.2344  decode.loss_dice: 0.8584  decode.d0.loss_cls: 0.6766  decode.d0.loss_mask: 1.1966  decode.d0.loss_dice: 0.8337  decode.d1.loss_cls: 0.1793  decode.d1.loss_mask: 1.2682  decode.d1.loss_dice: 0.8815  decode.d2.loss_cls: 0.1416  decode.d2.loss_mask: 1.2510  decode.d2.loss_dice: 0.8867  decode.d3.loss_cls: 0.1714  decode.d3.loss_mask: 1.2050  decode.d3.loss_dice: 0.8374  decode.d4.loss_cls: 0.1584  decode.d4.loss_mask: 1.2395  decode.d4.loss_dice: 0.8816  decode.d5.loss_cls: 0.1972  decode.d5.loss_mask: 1.2270  decode.d5.loss_dice: 0.8563  decode.d6.loss_cls: 0.1730  decode.d6.loss_mask: 1.2237  decode.d6.loss_dice: 0.8638  decode.d7.loss_cls: 0.1318  decode.d7.loss_mask: 1.2294  decode.d7.loss_dice: 0.8607  decode.d8.loss_cls: 0.1697  decode.d8.loss_mask: 1.2213  decode.d8.loss_dice: 0.8710
05/27 03:23:17 - mmengine - INFO - Iter(train) [138550/160000]  base_lr: 1.6390e-05 lr: 1.6390e-06  eta: 2:27:56  time: 0.4164  data_time: 0.0099  memory: 5975  grad_norm: 334.1986  loss: 17.8213  decode.loss_cls: 0.1787  decode.loss_mask: 0.8430  decode.loss_dice: 0.6932  decode.d0.loss_cls: 0.6584  decode.d0.loss_mask: 0.8685  decode.d0.loss_dice: 0.6980  decode.d1.loss_cls: 0.2138  decode.d1.loss_mask: 0.8267  decode.d1.loss_dice: 0.7255  decode.d2.loss_cls: 0.1806  decode.d2.loss_mask: 0.8418  decode.d2.loss_dice: 0.6932  decode.d3.loss_cls: 0.1962  decode.d3.loss_mask: 0.8237  decode.d3.loss_dice: 0.6898  decode.d4.loss_cls: 0.2016  decode.d4.loss_mask: 0.8415  decode.d4.loss_dice: 0.7029  decode.d5.loss_cls: 0.1942  decode.d5.loss_mask: 0.8376  decode.d5.loss_dice: 0.6912  decode.d6.loss_cls: 0.1962  decode.d6.loss_mask: 0.8480  decode.d6.loss_dice: 0.7261  decode.d7.loss_cls: 0.1975  decode.d7.loss_mask: 0.8430  decode.d7.loss_dice: 0.7021  decode.d8.loss_cls: 0.1938  decode.d8.loss_mask: 0.8265  decode.d8.loss_dice: 0.6882
05/27 03:23:38 - mmengine - INFO - Iter(train) [138600/160000]  base_lr: 1.6356e-05 lr: 1.6356e-06  eta: 2:27:35  time: 0.4183  data_time: 0.0099  memory: 5973  grad_norm: 542.3743  loss: 16.3704  decode.loss_cls: 0.0556  decode.loss_mask: 0.9289  decode.loss_dice: 0.5767  decode.d0.loss_cls: 0.6211  decode.d0.loss_mask: 0.9065  decode.d0.loss_dice: 0.5784  decode.d1.loss_cls: 0.0798  decode.d1.loss_mask: 0.9432  decode.d1.loss_dice: 0.5782  decode.d2.loss_cls: 0.1024  decode.d2.loss_mask: 0.9352  decode.d2.loss_dice: 0.5775  decode.d3.loss_cls: 0.0960  decode.d3.loss_mask: 0.9225  decode.d3.loss_dice: 0.5618  decode.d4.loss_cls: 0.1037  decode.d4.loss_mask: 0.9331  decode.d4.loss_dice: 0.5640  decode.d5.loss_cls: 0.0820  decode.d5.loss_mask: 0.9382  decode.d5.loss_dice: 0.5832  decode.d6.loss_cls: 0.0910  decode.d6.loss_mask: 0.9258  decode.d6.loss_dice: 0.5738  decode.d7.loss_cls: 0.0637  decode.d7.loss_mask: 0.9219  decode.d7.loss_dice: 0.5622  decode.d8.loss_cls: 0.0704  decode.d8.loss_mask: 0.9218  decode.d8.loss_dice: 0.5716
05/27 03:23:59 - mmengine - INFO - Iter(train) [138650/160000]  base_lr: 1.6321e-05 lr: 1.6321e-06  eta: 2:27:15  time: 0.4174  data_time: 0.0099  memory: 5966  grad_norm: 530.1865  loss: 18.8681  decode.loss_cls: 0.1384  decode.loss_mask: 1.0464  decode.loss_dice: 0.6417  decode.d0.loss_cls: 0.6038  decode.d0.loss_mask: 1.0013  decode.d0.loss_dice: 0.6155  decode.d1.loss_cls: 0.1762  decode.d1.loss_mask: 1.0240  decode.d1.loss_dice: 0.6488  decode.d2.loss_cls: 0.1321  decode.d2.loss_mask: 1.0565  decode.d2.loss_dice: 0.6699  decode.d3.loss_cls: 0.1330  decode.d3.loss_mask: 1.0599  decode.d3.loss_dice: 0.6528  decode.d4.loss_cls: 0.1701  decode.d4.loss_mask: 1.0384  decode.d4.loss_dice: 0.6490  decode.d5.loss_cls: 0.1363  decode.d5.loss_mask: 1.0647  decode.d5.loss_dice: 0.6625  decode.d6.loss_cls: 0.0975  decode.d6.loss_mask: 1.1020  decode.d6.loss_dice: 0.6894  decode.d7.loss_cls: 0.1494  decode.d7.loss_mask: 1.0348  decode.d7.loss_dice: 0.6647  decode.d8.loss_cls: 0.1331  decode.d8.loss_mask: 1.0299  decode.d8.loss_dice: 0.6460
05/27 03:24:20 - mmengine - INFO - Iter(train) [138700/160000]  base_lr: 1.6287e-05 lr: 1.6287e-06  eta: 2:26:54  time: 0.4183  data_time: 0.0100  memory: 5971  grad_norm: 655.3325  loss: 23.5567  decode.loss_cls: 0.1961  decode.loss_mask: 1.2749  decode.loss_dice: 0.8534  decode.d0.loss_cls: 0.7335  decode.d0.loss_mask: 1.1894  decode.d0.loss_dice: 0.8338  decode.d1.loss_cls: 0.1908  decode.d1.loss_mask: 1.2810  decode.d1.loss_dice: 0.8602  decode.d2.loss_cls: 0.1862  decode.d2.loss_mask: 1.2642  decode.d2.loss_dice: 0.8422  decode.d3.loss_cls: 0.2082  decode.d3.loss_mask: 1.2518  decode.d3.loss_dice: 0.8497  decode.d4.loss_cls: 0.2203  decode.d4.loss_mask: 1.2604  decode.d4.loss_dice: 0.8367  decode.d5.loss_cls: 0.1949  decode.d5.loss_mask: 1.2686  decode.d5.loss_dice: 0.8525  decode.d6.loss_cls: 0.1865  decode.d6.loss_mask: 1.2578  decode.d6.loss_dice: 0.8509  decode.d7.loss_cls: 0.1892  decode.d7.loss_mask: 1.2802  decode.d7.loss_dice: 0.8497  decode.d8.loss_cls: 0.1818  decode.d8.loss_mask: 1.2726  decode.d8.loss_dice: 0.8393
05/27 03:24:41 - mmengine - INFO - Iter(train) [138750/160000]  base_lr: 1.6252e-05 lr: 1.6252e-06  eta: 2:26:33  time: 0.4166  data_time: 0.0099  memory: 5970  grad_norm: 697.1528  loss: 21.4469  decode.loss_cls: 0.0986  decode.loss_mask: 1.2635  decode.loss_dice: 0.7519  decode.d0.loss_cls: 0.5849  decode.d0.loss_mask: 1.1224  decode.d0.loss_dice: 0.6873  decode.d1.loss_cls: 0.1235  decode.d1.loss_mask: 1.2609  decode.d1.loss_dice: 0.7525  decode.d2.loss_cls: 0.1239  decode.d2.loss_mask: 1.2886  decode.d2.loss_dice: 0.7547  decode.d3.loss_cls: 0.1122  decode.d3.loss_mask: 1.2562  decode.d3.loss_dice: 0.7348  decode.d4.loss_cls: 0.1166  decode.d4.loss_mask: 1.2695  decode.d4.loss_dice: 0.7454  decode.d5.loss_cls: 0.1198  decode.d5.loss_mask: 1.2301  decode.d5.loss_dice: 0.7322  decode.d6.loss_cls: 0.1107  decode.d6.loss_mask: 1.2553  decode.d6.loss_dice: 0.7362  decode.d7.loss_cls: 0.0939  decode.d7.loss_mask: 1.2595  decode.d7.loss_dice: 0.7439  decode.d8.loss_cls: 0.1046  decode.d8.loss_mask: 1.2636  decode.d8.loss_dice: 0.7497
05/27 03:25:02 - mmengine - INFO - Iter(train) [138800/160000]  base_lr: 1.6218e-05 lr: 1.6218e-06  eta: 2:26:13  time: 0.4165  data_time: 0.0098  memory: 5981  grad_norm: 708.3291  loss: 20.3879  decode.loss_cls: 0.1627  decode.loss_mask: 1.0477  decode.loss_dice: 0.7711  decode.d0.loss_cls: 0.6356  decode.d0.loss_mask: 1.0731  decode.d0.loss_dice: 0.7835  decode.d1.loss_cls: 0.1982  decode.d1.loss_mask: 1.0416  decode.d1.loss_dice: 0.7507  decode.d2.loss_cls: 0.1776  decode.d2.loss_mask: 1.0670  decode.d2.loss_dice: 0.7476  decode.d3.loss_cls: 0.1604  decode.d3.loss_mask: 1.0336  decode.d3.loss_dice: 0.7544  decode.d4.loss_cls: 0.1879  decode.d4.loss_mask: 1.0561  decode.d4.loss_dice: 0.7613  decode.d5.loss_cls: 0.1704  decode.d5.loss_mask: 1.0473  decode.d5.loss_dice: 0.7624  decode.d6.loss_cls: 0.1632  decode.d6.loss_mask: 1.0768  decode.d6.loss_dice: 0.7679  decode.d7.loss_cls: 0.1961  decode.d7.loss_mask: 1.0639  decode.d7.loss_dice: 0.7630  decode.d8.loss_cls: 0.1715  decode.d8.loss_mask: 1.0357  decode.d8.loss_dice: 0.7596
05/27 03:25:23 - mmengine - INFO - Iter(train) [138850/160000]  base_lr: 1.6184e-05 lr: 1.6184e-06  eta: 2:25:52  time: 0.4172  data_time: 0.0098  memory: 5971  grad_norm: 765.8106  loss: 14.0456  decode.loss_cls: 0.0927  decode.loss_mask: 0.7228  decode.loss_dice: 0.5454  decode.d0.loss_cls: 0.5065  decode.d0.loss_mask: 0.7303  decode.d0.loss_dice: 0.5366  decode.d1.loss_cls: 0.1017  decode.d1.loss_mask: 0.7380  decode.d1.loss_dice: 0.5726  decode.d2.loss_cls: 0.0771  decode.d2.loss_mask: 0.7217  decode.d2.loss_dice: 0.5513  decode.d3.loss_cls: 0.0860  decode.d3.loss_mask: 0.7230  decode.d3.loss_dice: 0.5429  decode.d4.loss_cls: 0.0868  decode.d4.loss_mask: 0.7237  decode.d4.loss_dice: 0.5441  decode.d5.loss_cls: 0.0850  decode.d5.loss_mask: 0.7243  decode.d5.loss_dice: 0.5579  decode.d6.loss_cls: 0.0915  decode.d6.loss_mask: 0.7229  decode.d6.loss_dice: 0.5380  decode.d7.loss_cls: 0.0927  decode.d7.loss_mask: 0.7293  decode.d7.loss_dice: 0.5467  decode.d8.loss_cls: 0.0923  decode.d8.loss_mask: 0.7192  decode.d8.loss_dice: 0.5425
05/27 03:25:44 - mmengine - INFO - Iter(train) [138900/160000]  base_lr: 1.6149e-05 lr: 1.6149e-06  eta: 2:25:31  time: 0.4171  data_time: 0.0098  memory: 5979  grad_norm: 640.2209  loss: 15.4164  decode.loss_cls: 0.0404  decode.loss_mask: 0.8886  decode.loss_dice: 0.5285  decode.d0.loss_cls: 0.5667  decode.d0.loss_mask: 0.9058  decode.d0.loss_dice: 0.5281  decode.d1.loss_cls: 0.0572  decode.d1.loss_mask: 0.8993  decode.d1.loss_dice: 0.5430  decode.d2.loss_cls: 0.0426  decode.d2.loss_mask: 0.9052  decode.d2.loss_dice: 0.5431  decode.d3.loss_cls: 0.0464  decode.d3.loss_mask: 0.8930  decode.d3.loss_dice: 0.5269  decode.d4.loss_cls: 0.0534  decode.d4.loss_mask: 0.9156  decode.d4.loss_dice: 0.5480  decode.d5.loss_cls: 0.0437  decode.d5.loss_mask: 0.9196  decode.d5.loss_dice: 0.5561  decode.d6.loss_cls: 0.0422  decode.d6.loss_mask: 0.9044  decode.d6.loss_dice: 0.5490  decode.d7.loss_cls: 0.0406  decode.d7.loss_mask: 0.8988  decode.d7.loss_dice: 0.5416  decode.d8.loss_cls: 0.0610  decode.d8.loss_mask: 0.8923  decode.d8.loss_dice: 0.5350
05/27 03:26:04 - mmengine - INFO - Iter(train) [138950/160000]  base_lr: 1.6115e-05 lr: 1.6115e-06  eta: 2:25:11  time: 0.4173  data_time: 0.0099  memory: 5976  grad_norm: 482.5515  loss: 18.5126  decode.loss_cls: 0.2205  decode.loss_mask: 0.9566  decode.loss_dice: 0.6543  decode.d0.loss_cls: 0.6877  decode.d0.loss_mask: 0.8977  decode.d0.loss_dice: 0.6375  decode.d1.loss_cls: 0.2555  decode.d1.loss_mask: 0.9192  decode.d1.loss_dice: 0.6470  decode.d2.loss_cls: 0.2744  decode.d2.loss_mask: 0.8998  decode.d2.loss_dice: 0.6230  decode.d3.loss_cls: 0.2214  decode.d3.loss_mask: 0.9224  decode.d3.loss_dice: 0.6417  decode.d4.loss_cls: 0.2373  decode.d4.loss_mask: 0.9318  decode.d4.loss_dice: 0.6386  decode.d5.loss_cls: 0.2418  decode.d5.loss_mask: 0.9114  decode.d5.loss_dice: 0.6285  decode.d6.loss_cls: 0.2399  decode.d6.loss_mask: 0.9346  decode.d6.loss_dice: 0.6425  decode.d7.loss_cls: 0.2253  decode.d7.loss_mask: 0.9363  decode.d7.loss_dice: 0.6579  decode.d8.loss_cls: 0.2227  decode.d8.loss_mask: 0.9485  decode.d8.loss_dice: 0.6566
05/27 03:26:25 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 03:26:25 - mmengine - INFO - Iter(train) [139000/160000]  base_lr: 1.6080e-05 lr: 1.6080e-06  eta: 2:24:50  time: 0.4221  data_time: 0.0103  memory: 5972  grad_norm: 272.5216  loss: 17.6456  decode.loss_cls: 0.1360  decode.loss_mask: 0.9221  decode.loss_dice: 0.6313  decode.d0.loss_cls: 0.6481  decode.d0.loss_mask: 0.8915  decode.d0.loss_dice: 0.6439  decode.d1.loss_cls: 0.1824  decode.d1.loss_mask: 0.9260  decode.d1.loss_dice: 0.6345  decode.d2.loss_cls: 0.1804  decode.d2.loss_mask: 0.9245  decode.d2.loss_dice: 0.6309  decode.d3.loss_cls: 0.1842  decode.d3.loss_mask: 0.9229  decode.d3.loss_dice: 0.6179  decode.d4.loss_cls: 0.1623  decode.d4.loss_mask: 0.9204  decode.d4.loss_dice: 0.6227  decode.d5.loss_cls: 0.1589  decode.d5.loss_mask: 0.9102  decode.d5.loss_dice: 0.6277  decode.d6.loss_cls: 0.1663  decode.d6.loss_mask: 0.9527  decode.d6.loss_dice: 0.6656  decode.d7.loss_cls: 0.1469  decode.d7.loss_mask: 0.9117  decode.d7.loss_dice: 0.6395  decode.d8.loss_cls: 0.1405  decode.d8.loss_mask: 0.9119  decode.d8.loss_dice: 0.6318
05/27 03:26:46 - mmengine - INFO - Iter(train) [139050/160000]  base_lr: 1.6046e-05 lr: 1.6046e-06  eta: 2:24:30  time: 0.4175  data_time: 0.0101  memory: 5975  grad_norm: 437.9829  loss: 16.1832  decode.loss_cls: 0.1880  decode.loss_mask: 0.8110  decode.loss_dice: 0.5568  decode.d0.loss_cls: 0.6290  decode.d0.loss_mask: 0.8034  decode.d0.loss_dice: 0.5941  decode.d1.loss_cls: 0.2049  decode.d1.loss_mask: 0.8305  decode.d1.loss_dice: 0.5852  decode.d2.loss_cls: 0.2183  decode.d2.loss_mask: 0.7979  decode.d2.loss_dice: 0.5813  decode.d3.loss_cls: 0.2298  decode.d3.loss_mask: 0.7963  decode.d3.loss_dice: 0.6016  decode.d4.loss_cls: 0.1990  decode.d4.loss_mask: 0.7782  decode.d4.loss_dice: 0.5640  decode.d5.loss_cls: 0.1704  decode.d5.loss_mask: 0.8389  decode.d5.loss_dice: 0.5757  decode.d6.loss_cls: 0.1755  decode.d6.loss_mask: 0.8039  decode.d6.loss_dice: 0.5751  decode.d7.loss_cls: 0.1889  decode.d7.loss_mask: 0.7888  decode.d7.loss_dice: 0.5646  decode.d8.loss_cls: 0.2125  decode.d8.loss_mask: 0.7684  decode.d8.loss_dice: 0.5512
05/27 03:27:07 - mmengine - INFO - Iter(train) [139100/160000]  base_lr: 1.6011e-05 lr: 1.6011e-06  eta: 2:24:09  time: 0.4182  data_time: 0.0099  memory: 5969  grad_norm: 402.3460  loss: 20.1600  decode.loss_cls: 0.2300  decode.loss_mask: 1.0377  decode.loss_dice: 0.7025  decode.d0.loss_cls: 0.5997  decode.d0.loss_mask: 1.0550  decode.d0.loss_dice: 0.7184  decode.d1.loss_cls: 0.2314  decode.d1.loss_mask: 1.0412  decode.d1.loss_dice: 0.6982  decode.d2.loss_cls: 0.2573  decode.d2.loss_mask: 1.0437  decode.d2.loss_dice: 0.6870  decode.d3.loss_cls: 0.2428  decode.d3.loss_mask: 1.0279  decode.d3.loss_dice: 0.6919  decode.d4.loss_cls: 0.2305  decode.d4.loss_mask: 1.0396  decode.d4.loss_dice: 0.6824  decode.d5.loss_cls: 0.2640  decode.d5.loss_mask: 1.0250  decode.d5.loss_dice: 0.6965  decode.d6.loss_cls: 0.2375  decode.d6.loss_mask: 1.0488  decode.d6.loss_dice: 0.6994  decode.d7.loss_cls: 0.2348  decode.d7.loss_mask: 1.0394  decode.d7.loss_dice: 0.6965  decode.d8.loss_cls: 0.2494  decode.d8.loss_mask: 1.0498  decode.d8.loss_dice: 0.7018
05/27 03:27:28 - mmengine - INFO - Iter(train) [139150/160000]  base_lr: 1.5977e-05 lr: 1.5977e-06  eta: 2:23:48  time: 0.4172  data_time: 0.0099  memory: 5967  grad_norm: 676.1015  loss: 21.5564  decode.loss_cls: 0.1435  decode.loss_mask: 1.1952  decode.loss_dice: 0.8080  decode.d0.loss_cls: 0.6482  decode.d0.loss_mask: 1.1291  decode.d0.loss_dice: 0.7670  decode.d1.loss_cls: 0.1185  decode.d1.loss_mask: 1.1603  decode.d1.loss_dice: 0.7941  decode.d2.loss_cls: 0.1885  decode.d2.loss_mask: 1.1377  decode.d2.loss_dice: 0.7984  decode.d3.loss_cls: 0.1666  decode.d3.loss_mask: 1.1388  decode.d3.loss_dice: 0.7748  decode.d4.loss_cls: 0.1269  decode.d4.loss_mask: 1.1486  decode.d4.loss_dice: 0.8015  decode.d5.loss_cls: 0.1334  decode.d5.loss_mask: 1.1576  decode.d5.loss_dice: 0.8379  decode.d6.loss_cls: 0.1492  decode.d6.loss_mask: 1.1699  decode.d6.loss_dice: 0.8042  decode.d7.loss_cls: 0.1609  decode.d7.loss_mask: 1.1502  decode.d7.loss_dice: 0.8244  decode.d8.loss_cls: 0.1742  decode.d8.loss_mask: 1.1318  decode.d8.loss_dice: 0.8171
05/27 03:27:49 - mmengine - INFO - Iter(train) [139200/160000]  base_lr: 1.5942e-05 lr: 1.5942e-06  eta: 2:23:28  time: 0.4183  data_time: 0.0099  memory: 5969  grad_norm: 323.9719  loss: 16.3940  decode.loss_cls: 0.1599  decode.loss_mask: 0.8304  decode.loss_dice: 0.6015  decode.d0.loss_cls: 0.6166  decode.d0.loss_mask: 0.8277  decode.d0.loss_dice: 0.5941  decode.d1.loss_cls: 0.1746  decode.d1.loss_mask: 0.8396  decode.d1.loss_dice: 0.6022  decode.d2.loss_cls: 0.1859  decode.d2.loss_mask: 0.8282  decode.d2.loss_dice: 0.5826  decode.d3.loss_cls: 0.1466  decode.d3.loss_mask: 0.8862  decode.d3.loss_dice: 0.6052  decode.d4.loss_cls: 0.1293  decode.d4.loss_mask: 0.8352  decode.d4.loss_dice: 0.6084  decode.d5.loss_cls: 0.1387  decode.d5.loss_mask: 0.8223  decode.d5.loss_dice: 0.5999  decode.d6.loss_cls: 0.1097  decode.d6.loss_mask: 0.8494  decode.d6.loss_dice: 0.6043  decode.d7.loss_cls: 0.1544  decode.d7.loss_mask: 0.8207  decode.d7.loss_dice: 0.6000  decode.d8.loss_cls: 0.1033  decode.d8.loss_mask: 0.9143  decode.d8.loss_dice: 0.6231
05/27 03:28:10 - mmengine - INFO - Iter(train) [139250/160000]  base_lr: 1.5908e-05 lr: 1.5908e-06  eta: 2:23:07  time: 0.4206  data_time: 0.0100  memory: 5973  grad_norm: 394.3533  loss: 16.4047  decode.loss_cls: 0.0793  decode.loss_mask: 0.9193  decode.loss_dice: 0.5879  decode.d0.loss_cls: 0.5997  decode.d0.loss_mask: 0.9110  decode.d0.loss_dice: 0.5848  decode.d1.loss_cls: 0.1038  decode.d1.loss_mask: 0.9410  decode.d1.loss_dice: 0.5998  decode.d2.loss_cls: 0.0817  decode.d2.loss_mask: 0.9095  decode.d2.loss_dice: 0.5921  decode.d3.loss_cls: 0.0857  decode.d3.loss_mask: 0.9099  decode.d3.loss_dice: 0.5847  decode.d4.loss_cls: 0.0920  decode.d4.loss_mask: 0.9146  decode.d4.loss_dice: 0.5789  decode.d5.loss_cls: 0.0854  decode.d5.loss_mask: 0.9108  decode.d5.loss_dice: 0.5760  decode.d6.loss_cls: 0.0897  decode.d6.loss_mask: 0.9160  decode.d6.loss_dice: 0.5799  decode.d7.loss_cls: 0.0964  decode.d7.loss_mask: 0.9086  decode.d7.loss_dice: 0.5837  decode.d8.loss_cls: 0.0965  decode.d8.loss_mask: 0.9034  decode.d8.loss_dice: 0.5827
05/27 03:28:31 - mmengine - INFO - Iter(train) [139300/160000]  base_lr: 1.5873e-05 lr: 1.5873e-06  eta: 2:22:46  time: 0.4183  data_time: 0.0099  memory: 5969  grad_norm: 431.2859  loss: 16.1591  decode.loss_cls: 0.0657  decode.loss_mask: 0.9196  decode.loss_dice: 0.5953  decode.d0.loss_cls: 0.5547  decode.d0.loss_mask: 0.8837  decode.d0.loss_dice: 0.6150  decode.d1.loss_cls: 0.0552  decode.d1.loss_mask: 0.9097  decode.d1.loss_dice: 0.5894  decode.d2.loss_cls: 0.0682  decode.d2.loss_mask: 0.9107  decode.d2.loss_dice: 0.5997  decode.d3.loss_cls: 0.0568  decode.d3.loss_mask: 0.9089  decode.d3.loss_dice: 0.5946  decode.d4.loss_cls: 0.0591  decode.d4.loss_mask: 0.9096  decode.d4.loss_dice: 0.5938  decode.d5.loss_cls: 0.0541  decode.d5.loss_mask: 0.9106  decode.d5.loss_dice: 0.5989  decode.d6.loss_cls: 0.0689  decode.d6.loss_mask: 0.9017  decode.d6.loss_dice: 0.5783  decode.d7.loss_cls: 0.0652  decode.d7.loss_mask: 0.9227  decode.d7.loss_dice: 0.6077  decode.d8.loss_cls: 0.0628  decode.d8.loss_mask: 0.9112  decode.d8.loss_dice: 0.5875
05/27 03:28:52 - mmengine - INFO - Iter(train) [139350/160000]  base_lr: 1.5839e-05 lr: 1.5839e-06  eta: 2:22:26  time: 0.4182  data_time: 0.0100  memory: 5983  grad_norm: 410.3557  loss: 17.8649  decode.loss_cls: 0.1676  decode.loss_mask: 0.9314  decode.loss_dice: 0.6168  decode.d0.loss_cls: 0.5613  decode.d0.loss_mask: 0.9320  decode.d0.loss_dice: 0.6603  decode.d1.loss_cls: 0.1855  decode.d1.loss_mask: 0.9258  decode.d1.loss_dice: 0.6648  decode.d2.loss_cls: 0.2111  decode.d2.loss_mask: 0.9376  decode.d2.loss_dice: 0.6330  decode.d3.loss_cls: 0.1909  decode.d3.loss_mask: 0.9354  decode.d3.loss_dice: 0.6488  decode.d4.loss_cls: 0.1886  decode.d4.loss_mask: 0.9319  decode.d4.loss_dice: 0.6363  decode.d5.loss_cls: 0.1547  decode.d5.loss_mask: 0.9340  decode.d5.loss_dice: 0.6320  decode.d6.loss_cls: 0.1409  decode.d6.loss_mask: 0.9574  decode.d6.loss_dice: 0.6487  decode.d7.loss_cls: 0.1771  decode.d7.loss_mask: 0.9450  decode.d7.loss_dice: 0.6084  decode.d8.loss_cls: 0.1575  decode.d8.loss_mask: 0.9315  decode.d8.loss_dice: 0.6185
05/27 03:29:13 - mmengine - INFO - Iter(train) [139400/160000]  base_lr: 1.5804e-05 lr: 1.5804e-06  eta: 2:22:05  time: 0.4174  data_time: 0.0100  memory: 5975  grad_norm: 849.7916  loss: 20.7231  decode.loss_cls: 0.1886  decode.loss_mask: 1.1030  decode.loss_dice: 0.7427  decode.d0.loss_cls: 0.7530  decode.d0.loss_mask: 1.0663  decode.d0.loss_dice: 0.7278  decode.d1.loss_cls: 0.1737  decode.d1.loss_mask: 1.1091  decode.d1.loss_dice: 0.7287  decode.d2.loss_cls: 0.2192  decode.d2.loss_mask: 1.0737  decode.d2.loss_dice: 0.7087  decode.d3.loss_cls: 0.2133  decode.d3.loss_mask: 1.0651  decode.d3.loss_dice: 0.7170  decode.d4.loss_cls: 0.1862  decode.d4.loss_mask: 1.1025  decode.d4.loss_dice: 0.7275  decode.d5.loss_cls: 0.1965  decode.d5.loss_mask: 1.0802  decode.d5.loss_dice: 0.7243  decode.d6.loss_cls: 0.2034  decode.d6.loss_mask: 1.0867  decode.d6.loss_dice: 0.7173  decode.d7.loss_cls: 0.1628  decode.d7.loss_mask: 1.1565  decode.d7.loss_dice: 0.7445  decode.d8.loss_cls: 0.2095  decode.d8.loss_mask: 1.1056  decode.d8.loss_dice: 0.7296
05/27 03:29:34 - mmengine - INFO - Iter(train) [139450/160000]  base_lr: 1.5770e-05 lr: 1.5770e-06  eta: 2:21:44  time: 0.4165  data_time: 0.0099  memory: 5969  grad_norm: 449.3463  loss: 17.3749  decode.loss_cls: 0.1784  decode.loss_mask: 0.9612  decode.loss_dice: 0.6186  decode.d0.loss_cls: 0.5320  decode.d0.loss_mask: 0.9131  decode.d0.loss_dice: 0.5563  decode.d1.loss_cls: 0.1202  decode.d1.loss_mask: 0.9724  decode.d1.loss_dice: 0.6184  decode.d2.loss_cls: 0.1225  decode.d2.loss_mask: 0.9609  decode.d2.loss_dice: 0.6105  decode.d3.loss_cls: 0.1599  decode.d3.loss_mask: 0.9559  decode.d3.loss_dice: 0.5880  decode.d4.loss_cls: 0.1805  decode.d4.loss_mask: 0.9466  decode.d4.loss_dice: 0.5981  decode.d5.loss_cls: 0.1285  decode.d5.loss_mask: 0.9550  decode.d5.loss_dice: 0.5981  decode.d6.loss_cls: 0.1241  decode.d6.loss_mask: 0.9568  decode.d6.loss_dice: 0.6003  decode.d7.loss_cls: 0.1065  decode.d7.loss_mask: 0.9578  decode.d7.loss_dice: 0.6122  decode.d8.loss_cls: 0.1575  decode.d8.loss_mask: 0.9695  decode.d8.loss_dice: 0.6150
05/27 03:29:55 - mmengine - INFO - Iter(train) [139500/160000]  base_lr: 1.5735e-05 lr: 1.5735e-06  eta: 2:21:24  time: 0.4170  data_time: 0.0099  memory: 5970  grad_norm: 714.3176  loss: 21.7957  decode.loss_cls: 0.2084  decode.loss_mask: 1.1676  decode.loss_dice: 0.7913  decode.d0.loss_cls: 0.6804  decode.d0.loss_mask: 1.0775  decode.d0.loss_dice: 0.8170  decode.d1.loss_cls: 0.1872  decode.d1.loss_mask: 1.1642  decode.d1.loss_dice: 0.7918  decode.d2.loss_cls: 0.1818  decode.d2.loss_mask: 1.1427  decode.d2.loss_dice: 0.7920  decode.d3.loss_cls: 0.2139  decode.d3.loss_mask: 1.1448  decode.d3.loss_dice: 0.7892  decode.d4.loss_cls: 0.2093  decode.d4.loss_mask: 1.1295  decode.d4.loss_dice: 0.7992  decode.d5.loss_cls: 0.2157  decode.d5.loss_mask: 1.1520  decode.d5.loss_dice: 0.7867  decode.d6.loss_cls: 0.2168  decode.d6.loss_mask: 1.1208  decode.d6.loss_dice: 0.7964  decode.d7.loss_cls: 0.1803  decode.d7.loss_mask: 1.1281  decode.d7.loss_dice: 0.8087  decode.d8.loss_cls: 0.1801  decode.d8.loss_mask: 1.1195  decode.d8.loss_dice: 0.8029
05/27 03:30:16 - mmengine - INFO - Iter(train) [139550/160000]  base_lr: 1.5701e-05 lr: 1.5701e-06  eta: 2:21:03  time: 0.4187  data_time: 0.0101  memory: 5986  grad_norm: 720.9069  loss: 18.6151  decode.loss_cls: 0.1743  decode.loss_mask: 0.9678  decode.loss_dice: 0.6474  decode.d0.loss_cls: 0.6425  decode.d0.loss_mask: 0.9568  decode.d0.loss_dice: 0.6691  decode.d1.loss_cls: 0.1987  decode.d1.loss_mask: 0.9665  decode.d1.loss_dice: 0.6791  decode.d2.loss_cls: 0.1998  decode.d2.loss_mask: 0.9521  decode.d2.loss_dice: 0.6591  decode.d3.loss_cls: 0.1899  decode.d3.loss_mask: 1.0350  decode.d3.loss_dice: 0.6634  decode.d4.loss_cls: 0.1788  decode.d4.loss_mask: 0.9714  decode.d4.loss_dice: 0.6588  decode.d5.loss_cls: 0.1683  decode.d5.loss_mask: 0.9751  decode.d5.loss_dice: 0.6477  decode.d6.loss_cls: 0.1834  decode.d6.loss_mask: 0.9165  decode.d6.loss_dice: 0.6470  decode.d7.loss_cls: 0.1908  decode.d7.loss_mask: 0.9908  decode.d7.loss_dice: 0.6778  decode.d8.loss_cls: 0.1840  decode.d8.loss_mask: 0.9676  decode.d8.loss_dice: 0.6555
05/27 03:30:37 - mmengine - INFO - Iter(train) [139600/160000]  base_lr: 1.5666e-05 lr: 1.5666e-06  eta: 2:20:42  time: 0.4182  data_time: 0.0100  memory: 5976  grad_norm: 625.0016  loss: 18.8555  decode.loss_cls: 0.1369  decode.loss_mask: 0.9340  decode.loss_dice: 0.7063  decode.d0.loss_cls: 0.6093  decode.d0.loss_mask: 1.0178  decode.d0.loss_dice: 0.7214  decode.d1.loss_cls: 0.1654  decode.d1.loss_mask: 1.0063  decode.d1.loss_dice: 0.7242  decode.d2.loss_cls: 0.1388  decode.d2.loss_mask: 0.9895  decode.d2.loss_dice: 0.7315  decode.d3.loss_cls: 0.1561  decode.d3.loss_mask: 0.9850  decode.d3.loss_dice: 0.7228  decode.d4.loss_cls: 0.1588  decode.d4.loss_mask: 0.9601  decode.d4.loss_dice: 0.7269  decode.d5.loss_cls: 0.1554  decode.d5.loss_mask: 0.9731  decode.d5.loss_dice: 0.7128  decode.d6.loss_cls: 0.1518  decode.d6.loss_mask: 0.9627  decode.d6.loss_dice: 0.7023  decode.d7.loss_cls: 0.1422  decode.d7.loss_mask: 0.9620  decode.d7.loss_dice: 0.6996  decode.d8.loss_cls: 0.1432  decode.d8.loss_mask: 0.9531  decode.d8.loss_dice: 0.7060
05/27 03:30:58 - mmengine - INFO - Iter(train) [139650/160000]  base_lr: 1.5632e-05 lr: 1.5632e-06  eta: 2:20:22  time: 0.4177  data_time: 0.0100  memory: 5973  grad_norm: 719.3108  loss: 19.2032  decode.loss_cls: 0.2109  decode.loss_mask: 0.9940  decode.loss_dice: 0.6823  decode.d0.loss_cls: 0.6663  decode.d0.loss_mask: 1.0021  decode.d0.loss_dice: 0.6529  decode.d1.loss_cls: 0.1690  decode.d1.loss_mask: 1.0136  decode.d1.loss_dice: 0.6873  decode.d2.loss_cls: 0.1905  decode.d2.loss_mask: 1.0304  decode.d2.loss_dice: 0.6877  decode.d3.loss_cls: 0.1859  decode.d3.loss_mask: 0.9847  decode.d3.loss_dice: 0.6785  decode.d4.loss_cls: 0.2149  decode.d4.loss_mask: 0.9714  decode.d4.loss_dice: 0.6715  decode.d5.loss_cls: 0.1565  decode.d5.loss_mask: 1.0334  decode.d5.loss_dice: 0.6825  decode.d6.loss_cls: 0.1856  decode.d6.loss_mask: 0.9991  decode.d6.loss_dice: 0.6820  decode.d7.loss_cls: 0.1751  decode.d7.loss_mask: 1.0203  decode.d7.loss_dice: 0.6934  decode.d8.loss_cls: 0.1742  decode.d8.loss_mask: 1.0200  decode.d8.loss_dice: 0.6874
05/27 03:31:18 - mmengine - INFO - Iter(train) [139700/160000]  base_lr: 1.5597e-05 lr: 1.5597e-06  eta: 2:20:01  time: 0.4181  data_time: 0.0099  memory: 5984  grad_norm: 850.8691  loss: 20.4531  decode.loss_cls: 0.1299  decode.loss_mask: 1.0454  decode.loss_dice: 0.8292  decode.d0.loss_cls: 0.5354  decode.d0.loss_mask: 1.0311  decode.d0.loss_dice: 0.8409  decode.d1.loss_cls: 0.1247  decode.d1.loss_mask: 1.0277  decode.d1.loss_dice: 0.8229  decode.d2.loss_cls: 0.1371  decode.d2.loss_mask: 1.0380  decode.d2.loss_dice: 0.8319  decode.d3.loss_cls: 0.1250  decode.d3.loss_mask: 1.0371  decode.d3.loss_dice: 0.8266  decode.d4.loss_cls: 0.1535  decode.d4.loss_mask: 1.0251  decode.d4.loss_dice: 0.8247  decode.d5.loss_cls: 0.1224  decode.d5.loss_mask: 1.0469  decode.d5.loss_dice: 0.8403  decode.d6.loss_cls: 0.1126  decode.d6.loss_mask: 1.0566  decode.d6.loss_dice: 0.8301  decode.d7.loss_cls: 0.1259  decode.d7.loss_mask: 1.0447  decode.d7.loss_dice: 0.8537  decode.d8.loss_cls: 0.1523  decode.d8.loss_mask: 1.0456  decode.d8.loss_dice: 0.8359
05/27 03:31:40 - mmengine - INFO - Iter(train) [139750/160000]  base_lr: 1.5562e-05 lr: 1.5562e-06  eta: 2:19:40  time: 0.4179  data_time: 0.0100  memory: 5966  grad_norm: 722.5994  loss: 17.4448  decode.loss_cls: 0.0728  decode.loss_mask: 0.9530  decode.loss_dice: 0.6266  decode.d0.loss_cls: 0.6018  decode.d0.loss_mask: 0.9493  decode.d0.loss_dice: 0.6170  decode.d1.loss_cls: 0.1241  decode.d1.loss_mask: 1.0167  decode.d1.loss_dice: 0.6375  decode.d2.loss_cls: 0.0908  decode.d2.loss_mask: 0.9617  decode.d2.loss_dice: 0.6141  decode.d3.loss_cls: 0.1072  decode.d3.loss_mask: 0.9595  decode.d3.loss_dice: 0.6144  decode.d4.loss_cls: 0.1116  decode.d4.loss_mask: 0.9796  decode.d4.loss_dice: 0.6103  decode.d5.loss_cls: 0.1266  decode.d5.loss_mask: 0.9517  decode.d5.loss_dice: 0.6073  decode.d6.loss_cls: 0.1245  decode.d6.loss_mask: 0.9641  decode.d6.loss_dice: 0.6089  decode.d7.loss_cls: 0.1438  decode.d7.loss_mask: 0.9490  decode.d7.loss_dice: 0.6255  decode.d8.loss_cls: 0.1186  decode.d8.loss_mask: 0.9576  decode.d8.loss_dice: 0.6189
05/27 03:32:00 - mmengine - INFO - Iter(train) [139800/160000]  base_lr: 1.5528e-05 lr: 1.5528e-06  eta: 2:19:20  time: 0.4194  data_time: 0.0116  memory: 5967  grad_norm: 727.5686  loss: 21.3929  decode.loss_cls: 0.2229  decode.loss_mask: 1.1327  decode.loss_dice: 0.6865  decode.d0.loss_cls: 0.6857  decode.d0.loss_mask: 1.0584  decode.d0.loss_dice: 0.6861  decode.d1.loss_cls: 0.1899  decode.d1.loss_mask: 1.2221  decode.d1.loss_dice: 0.7038  decode.d2.loss_cls: 0.2451  decode.d2.loss_mask: 1.1945  decode.d2.loss_dice: 0.6930  decode.d3.loss_cls: 0.2396  decode.d3.loss_mask: 1.1509  decode.d3.loss_dice: 0.6806  decode.d4.loss_cls: 0.1704  decode.d4.loss_mask: 1.2503  decode.d4.loss_dice: 0.7225  decode.d5.loss_cls: 0.2267  decode.d5.loss_mask: 1.1964  decode.d5.loss_dice: 0.7358  decode.d6.loss_cls: 0.2277  decode.d6.loss_mask: 1.1579  decode.d6.loss_dice: 0.7127  decode.d7.loss_cls: 0.2365  decode.d7.loss_mask: 1.1356  decode.d7.loss_dice: 0.7232  decode.d8.loss_cls: 0.1934  decode.d8.loss_mask: 1.2086  decode.d8.loss_dice: 0.7032
05/27 03:32:21 - mmengine - INFO - Iter(train) [139850/160000]  base_lr: 1.5493e-05 lr: 1.5493e-06  eta: 2:18:59  time: 0.4180  data_time: 0.0101  memory: 5967  grad_norm: 352.7732  loss: 15.5442  decode.loss_cls: 0.0559  decode.loss_mask: 0.8200  decode.loss_dice: 0.6291  decode.d0.loss_cls: 0.5214  decode.d0.loss_mask: 0.7996  decode.d0.loss_dice: 0.6305  decode.d1.loss_cls: 0.0980  decode.d1.loss_mask: 0.8336  decode.d1.loss_dice: 0.5910  decode.d2.loss_cls: 0.0846  decode.d2.loss_mask: 0.8229  decode.d2.loss_dice: 0.6215  decode.d3.loss_cls: 0.0824  decode.d3.loss_mask: 0.8265  decode.d3.loss_dice: 0.6075  decode.d4.loss_cls: 0.0849  decode.d4.loss_mask: 0.8213  decode.d4.loss_dice: 0.6066  decode.d5.loss_cls: 0.0906  decode.d5.loss_mask: 0.8163  decode.d5.loss_dice: 0.6014  decode.d6.loss_cls: 0.0965  decode.d6.loss_mask: 0.8128  decode.d6.loss_dice: 0.5978  decode.d7.loss_cls: 0.0778  decode.d7.loss_mask: 0.8197  decode.d7.loss_dice: 0.6050  decode.d8.loss_cls: 0.0573  decode.d8.loss_mask: 0.8238  decode.d8.loss_dice: 0.6080
05/27 03:32:42 - mmengine - INFO - Iter(train) [139900/160000]  base_lr: 1.5459e-05 lr: 1.5459e-06  eta: 2:18:38  time: 0.4176  data_time: 0.0100  memory: 5966  grad_norm: 552.7721  loss: 19.0193  decode.loss_cls: 0.1569  decode.loss_mask: 1.0099  decode.loss_dice: 0.7043  decode.d0.loss_cls: 0.6228  decode.d0.loss_mask: 0.9628  decode.d0.loss_dice: 0.6745  decode.d1.loss_cls: 0.1322  decode.d1.loss_mask: 1.0112  decode.d1.loss_dice: 0.7149  decode.d2.loss_cls: 0.1294  decode.d2.loss_mask: 1.0517  decode.d2.loss_dice: 0.7315  decode.d3.loss_cls: 0.1183  decode.d3.loss_mask: 1.0487  decode.d3.loss_dice: 0.7194  decode.d4.loss_cls: 0.1319  decode.d4.loss_mask: 1.0053  decode.d4.loss_dice: 0.7033  decode.d5.loss_cls: 0.1317  decode.d5.loss_mask: 0.9917  decode.d5.loss_dice: 0.7072  decode.d6.loss_cls: 0.1422  decode.d6.loss_mask: 0.9892  decode.d6.loss_dice: 0.7025  decode.d7.loss_cls: 0.1352  decode.d7.loss_mask: 1.0067  decode.d7.loss_dice: 0.7078  decode.d8.loss_cls: 0.1747  decode.d8.loss_mask: 1.0010  decode.d8.loss_dice: 0.7001
05/27 03:33:03 - mmengine - INFO - Iter(train) [139950/160000]  base_lr: 1.5424e-05 lr: 1.5424e-06  eta: 2:18:18  time: 0.4171  data_time: 0.0100  memory: 5969  grad_norm: 659.6552  loss: 17.4602  decode.loss_cls: 0.1237  decode.loss_mask: 0.9642  decode.loss_dice: 0.5920  decode.d0.loss_cls: 0.5730  decode.d0.loss_mask: 0.9378  decode.d0.loss_dice: 0.6105  decode.d1.loss_cls: 0.1498  decode.d1.loss_mask: 0.9856  decode.d1.loss_dice: 0.6061  decode.d2.loss_cls: 0.1505  decode.d2.loss_mask: 0.9670  decode.d2.loss_dice: 0.5995  decode.d3.loss_cls: 0.1318  decode.d3.loss_mask: 0.9655  decode.d3.loss_dice: 0.5963  decode.d4.loss_cls: 0.1282  decode.d4.loss_mask: 0.9700  decode.d4.loss_dice: 0.6047  decode.d5.loss_cls: 0.1434  decode.d5.loss_mask: 0.9707  decode.d5.loss_dice: 0.6036  decode.d6.loss_cls: 0.1225  decode.d6.loss_mask: 0.9759  decode.d6.loss_dice: 0.6047  decode.d7.loss_cls: 0.1408  decode.d7.loss_mask: 0.9641  decode.d7.loss_dice: 0.5946  decode.d8.loss_cls: 0.1115  decode.d8.loss_mask: 0.9706  decode.d8.loss_dice: 0.6014
05/27 03:33:24 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 03:33:24 - mmengine - INFO - Iter(train) [140000/160000]  base_lr: 1.5389e-05 lr: 1.5389e-06  eta: 2:17:57  time: 0.4178  data_time: 0.0101  memory: 5971  grad_norm: 362.0510  loss: 15.7242  decode.loss_cls: 0.0779  decode.loss_mask: 0.8836  decode.loss_dice: 0.5634  decode.d0.loss_cls: 0.6411  decode.d0.loss_mask: 0.7981  decode.d0.loss_dice: 0.5971  decode.d1.loss_cls: 0.0767  decode.d1.loss_mask: 0.8775  decode.d1.loss_dice: 0.5671  decode.d2.loss_cls: 0.0787  decode.d2.loss_mask: 0.8640  decode.d2.loss_dice: 0.5686  decode.d3.loss_cls: 0.0905  decode.d3.loss_mask: 0.8475  decode.d3.loss_dice: 0.5601  decode.d4.loss_cls: 0.0766  decode.d4.loss_mask: 0.8668  decode.d4.loss_dice: 0.5648  decode.d5.loss_cls: 0.0831  decode.d5.loss_mask: 0.8661  decode.d5.loss_dice: 0.5638  decode.d6.loss_cls: 0.0579  decode.d6.loss_mask: 0.8930  decode.d6.loss_dice: 0.5800  decode.d7.loss_cls: 0.0945  decode.d7.loss_mask: 0.8787  decode.d7.loss_dice: 0.5706  decode.d8.loss_cls: 0.0872  decode.d8.loss_mask: 0.8760  decode.d8.loss_dice: 0.5732
05/27 03:33:24 - mmengine - INFO - Saving checkpoint at 140000 iterations
05/27 03:33:28 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:07  time: 0.0475  data_time: 0.0012  memory: 1391  
05/27 03:33:31 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:04  time: 0.0473  data_time: 0.0012  memory: 1205  
05/27 03:33:33 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:02  time: 0.0501  data_time: 0.0013  memory: 1596  
05/27 03:33:36 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0484  data_time: 0.0012  memory: 1298  
05/27 03:33:38 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:57  time: 0.0477  data_time: 0.0012  memory: 1298  
05/27 03:33:41 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0476  data_time: 0.0012  memory: 1279  
05/27 03:33:43 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:52  time: 0.0477  data_time: 0.0012  memory: 1224  
05/27 03:33:45 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0487  data_time: 0.0012  memory: 1298  
05/27 03:33:48 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0471  data_time: 0.0012  memory: 1298  
05/27 03:33:50 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0512  data_time: 0.0013  memory: 1725  
05/27 03:33:53 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0477  data_time: 0.0012  memory: 1336  
05/27 03:33:55 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0480  data_time: 0.0012  memory: 1298  
05/27 03:33:57 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0482  data_time: 0.0012  memory: 1205  
05/27 03:34:00 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0489  data_time: 0.0012  memory: 1316  
05/27 03:34:02 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0474  data_time: 0.0012  memory: 1279  
05/27 03:34:05 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0512  data_time: 0.0012  memory: 1410  
05/27 03:34:07 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0490  data_time: 0.0013  memory: 1279  
05/27 03:34:09 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0483  data_time: 0.0012  memory: 1205  
05/27 03:34:12 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:23  time: 0.0483  data_time: 0.0012  memory: 1205  
05/27 03:34:14 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0477  data_time: 0.0012  memory: 1336  
05/27 03:34:17 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0475  data_time: 0.0012  memory: 1246  
05/27 03:34:19 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0499  data_time: 0.0013  memory: 1503  
05/27 03:34:21 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0475  data_time: 0.0012  memory: 1261  
05/27 03:34:24 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0487  data_time: 0.0012  memory: 1298  
05/27 03:34:26 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0478  data_time: 0.0012  memory: 1447  
05/27 03:34:29 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0474  data_time: 0.0012  memory: 1298  
05/27 03:34:31 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0490  data_time: 0.0012  memory: 1279  
05/27 03:34:34 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0477  data_time: 0.0012  memory: 1205  
05/27 03:34:36 - mmengine - INFO - per class results:
05/27 03:34:36 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.86 | 97.58 |
|  aeroplane  | 94.02 | 98.33 |
|   bicycle   | 43.62 | 95.88 |
|     bird    | 96.44 | 98.36 |
|     boat    | 72.56 | 93.54 |
|    bottle   | 85.28 | 95.33 |
|     bus     | 95.93 |  97.9 |
|     car     | 91.27 | 94.47 |
|     cat     | 95.18 | 97.64 |
|    chair    | 45.15 | 59.75 |
|     cow     | 91.67 | 97.46 |
| diningtable | 64.78 | 68.36 |
|     dog     |  91.9 |  98.3 |
|    horse    | 90.77 | 95.61 |
|  motorbike  | 92.29 | 96.65 |
|    person   | 90.98 | 95.11 |
| pottedplant | 72.77 | 88.63 |
|    sheep    | 89.27 | 92.32 |
|     sofa    | 63.54 | 80.75 |
|    train    | 89.26 | 95.27 |
|  tvmonitor  | 84.65 | 88.42 |
+-------------+-------+-------+
05/27 03:34:36 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 96.2600  mIoU: 82.7200  mAcc: 91.7000  data_time: 0.0013  time: 0.0480
05/27 03:34:36 - mmengine - INFO - The previous best checkpoint /pfs/work7/workspace/scratch/ma_dschader-team_project_fss2024/benchmarking_robustness/semantic_segmentation/work_dirs/mask2former_swin-t_8xb2-160k_voc12aug-512x512/best_mIoU_iter_130000.pth is removed
05/27 03:34:37 - mmengine - INFO - The best checkpoint with 82.7200 mIoU at 140000 iter is saved to best_mIoU_iter_140000.pth.
05/27 03:35:00 - mmengine - INFO - Iter(train) [140050/160000]  base_lr: 1.5355e-05 lr: 1.5355e-06  eta: 2:17:37  time: 0.4179  data_time: 0.0101  memory: 5974  grad_norm: 600.4325  loss: 17.8886  decode.loss_cls: 0.1507  decode.loss_mask: 0.9087  decode.loss_dice: 0.6370  decode.d0.loss_cls: 0.6711  decode.d0.loss_mask: 0.9214  decode.d0.loss_dice: 0.6724  decode.d1.loss_cls: 0.1731  decode.d1.loss_mask: 0.9343  decode.d1.loss_dice: 0.6567  decode.d2.loss_cls: 0.1525  decode.d2.loss_mask: 0.9614  decode.d2.loss_dice: 0.6586  decode.d3.loss_cls: 0.1538  decode.d3.loss_mask: 0.9621  decode.d3.loss_dice: 0.6769  decode.d4.loss_cls: 0.1660  decode.d4.loss_mask: 0.9264  decode.d4.loss_dice: 0.6447  decode.d5.loss_cls: 0.1489  decode.d5.loss_mask: 0.9256  decode.d5.loss_dice: 0.6527  decode.d6.loss_cls: 0.1317  decode.d6.loss_mask: 0.9419  decode.d6.loss_dice: 0.6579  decode.d7.loss_cls: 0.1061  decode.d7.loss_mask: 0.9294  decode.d7.loss_dice: 0.6533  decode.d8.loss_cls: 0.1610  decode.d8.loss_mask: 0.9100  decode.d8.loss_dice: 0.6424
05/27 03:35:21 - mmengine - INFO - Iter(train) [140100/160000]  base_lr: 1.5320e-05 lr: 1.5320e-06  eta: 2:17:16  time: 0.4202  data_time: 0.0102  memory: 5971  grad_norm: 810.3166  loss: 16.7458  decode.loss_cls: 0.1778  decode.loss_mask: 0.8181  decode.loss_dice: 0.6047  decode.d0.loss_cls: 0.6326  decode.d0.loss_mask: 0.8389  decode.d0.loss_dice: 0.6330  decode.d1.loss_cls: 0.1830  decode.d1.loss_mask: 0.8237  decode.d1.loss_dice: 0.6110  decode.d2.loss_cls: 0.1842  decode.d2.loss_mask: 0.8385  decode.d2.loss_dice: 0.6327  decode.d3.loss_cls: 0.1912  decode.d3.loss_mask: 0.8216  decode.d3.loss_dice: 0.6209  decode.d4.loss_cls: 0.2035  decode.d4.loss_mask: 0.8172  decode.d4.loss_dice: 0.6111  decode.d5.loss_cls: 0.1594  decode.d5.loss_mask: 0.8312  decode.d5.loss_dice: 0.6265  decode.d6.loss_cls: 0.1917  decode.d6.loss_mask: 0.8247  decode.d6.loss_dice: 0.6233  decode.d7.loss_cls: 0.1792  decode.d7.loss_mask: 0.8221  decode.d7.loss_dice: 0.6128  decode.d8.loss_cls: 0.1797  decode.d8.loss_mask: 0.8336  decode.d8.loss_dice: 0.6179
05/27 03:35:42 - mmengine - INFO - Iter(train) [140150/160000]  base_lr: 1.5285e-05 lr: 1.5285e-06  eta: 2:16:55  time: 0.4168  data_time: 0.0100  memory: 5974  grad_norm: 613.3222  loss: 17.8239  decode.loss_cls: 0.1343  decode.loss_mask: 0.9495  decode.loss_dice: 0.6685  decode.d0.loss_cls: 0.6788  decode.d0.loss_mask: 0.8907  decode.d0.loss_dice: 0.6390  decode.d1.loss_cls: 0.1393  decode.d1.loss_mask: 0.9320  decode.d1.loss_dice: 0.6665  decode.d2.loss_cls: 0.1249  decode.d2.loss_mask: 0.9331  decode.d2.loss_dice: 0.6678  decode.d3.loss_cls: 0.1467  decode.d3.loss_mask: 0.8883  decode.d3.loss_dice: 0.6490  decode.d4.loss_cls: 0.1426  decode.d4.loss_mask: 0.9146  decode.d4.loss_dice: 0.6634  decode.d5.loss_cls: 0.1687  decode.d5.loss_mask: 0.9320  decode.d5.loss_dice: 0.6667  decode.d6.loss_cls: 0.1592  decode.d6.loss_mask: 0.9466  decode.d6.loss_dice: 0.6675  decode.d7.loss_cls: 0.1270  decode.d7.loss_mask: 0.9445  decode.d7.loss_dice: 0.6616  decode.d8.loss_cls: 0.1335  decode.d8.loss_mask: 0.9394  decode.d8.loss_dice: 0.6482
05/27 03:36:03 - mmengine - INFO - Iter(train) [140200/160000]  base_lr: 1.5251e-05 lr: 1.5251e-06  eta: 2:16:35  time: 0.4177  data_time: 0.0100  memory: 5988  grad_norm: 658.2207  loss: 17.9689  decode.loss_cls: 0.0609  decode.loss_mask: 1.0029  decode.loss_dice: 0.6846  decode.d0.loss_cls: 0.4983  decode.d0.loss_mask: 0.9894  decode.d0.loss_dice: 0.6605  decode.d1.loss_cls: 0.0836  decode.d1.loss_mask: 1.0246  decode.d1.loss_dice: 0.6853  decode.d2.loss_cls: 0.0964  decode.d2.loss_mask: 0.9936  decode.d2.loss_dice: 0.6693  decode.d3.loss_cls: 0.1065  decode.d3.loss_mask: 0.9838  decode.d3.loss_dice: 0.6535  decode.d4.loss_cls: 0.0672  decode.d4.loss_mask: 1.0162  decode.d4.loss_dice: 0.6889  decode.d5.loss_cls: 0.1049  decode.d5.loss_mask: 0.9917  decode.d5.loss_dice: 0.6520  decode.d6.loss_cls: 0.0973  decode.d6.loss_mask: 0.9896  decode.d6.loss_dice: 0.6717  decode.d7.loss_cls: 0.1019  decode.d7.loss_mask: 0.9876  decode.d7.loss_dice: 0.6609  decode.d8.loss_cls: 0.0952  decode.d8.loss_mask: 0.9897  decode.d8.loss_dice: 0.6609
05/27 03:36:24 - mmengine - INFO - Iter(train) [140250/160000]  base_lr: 1.5216e-05 lr: 1.5216e-06  eta: 2:16:14  time: 0.4171  data_time: 0.0100  memory: 5967  grad_norm: 669.7039  loss: 20.4812  decode.loss_cls: 0.1378  decode.loss_mask: 1.0851  decode.loss_dice: 0.7370  decode.d0.loss_cls: 0.7211  decode.d0.loss_mask: 1.0558  decode.d0.loss_dice: 0.7568  decode.d1.loss_cls: 0.1944  decode.d1.loss_mask: 1.0866  decode.d1.loss_dice: 0.7318  decode.d2.loss_cls: 0.1815  decode.d2.loss_mask: 1.0596  decode.d2.loss_dice: 0.7482  decode.d3.loss_cls: 0.1881  decode.d3.loss_mask: 1.0858  decode.d3.loss_dice: 0.7786  decode.d4.loss_cls: 0.1766  decode.d4.loss_mask: 1.0788  decode.d4.loss_dice: 0.7535  decode.d5.loss_cls: 0.1776  decode.d5.loss_mask: 1.0421  decode.d5.loss_dice: 0.7486  decode.d6.loss_cls: 0.1895  decode.d6.loss_mask: 1.0674  decode.d6.loss_dice: 0.7677  decode.d7.loss_cls: 0.1763  decode.d7.loss_mask: 1.0456  decode.d7.loss_dice: 0.7503  decode.d8.loss_cls: 0.1818  decode.d8.loss_mask: 1.0555  decode.d8.loss_dice: 0.7218
05/27 03:36:45 - mmengine - INFO - Iter(train) [140300/160000]  base_lr: 1.5181e-05 lr: 1.5181e-06  eta: 2:15:53  time: 0.4181  data_time: 0.0100  memory: 5967  grad_norm: 334.5662  loss: 15.4978  decode.loss_cls: 0.1652  decode.loss_mask: 0.7954  decode.loss_dice: 0.5512  decode.d0.loss_cls: 0.6452  decode.d0.loss_mask: 0.7766  decode.d0.loss_dice: 0.5363  decode.d1.loss_cls: 0.1394  decode.d1.loss_mask: 0.8326  decode.d1.loss_dice: 0.5719  decode.d2.loss_cls: 0.1375  decode.d2.loss_mask: 0.8261  decode.d2.loss_dice: 0.5533  decode.d3.loss_cls: 0.1489  decode.d3.loss_mask: 0.7941  decode.d3.loss_dice: 0.5656  decode.d4.loss_cls: 0.1318  decode.d4.loss_mask: 0.8073  decode.d4.loss_dice: 0.5559  decode.d5.loss_cls: 0.1535  decode.d5.loss_mask: 0.7843  decode.d5.loss_dice: 0.5413  decode.d6.loss_cls: 0.1570  decode.d6.loss_mask: 0.7871  decode.d6.loss_dice: 0.5628  decode.d7.loss_cls: 0.1376  decode.d7.loss_mask: 0.8004  decode.d7.loss_dice: 0.5472  decode.d8.loss_cls: 0.1391  decode.d8.loss_mask: 0.7984  decode.d8.loss_dice: 0.5549
05/27 03:37:06 - mmengine - INFO - Iter(train) [140350/160000]  base_lr: 1.5147e-05 lr: 1.5147e-06  eta: 2:15:33  time: 0.4171  data_time: 0.0100  memory: 5968  grad_norm: 518.0239  loss: 19.3608  decode.loss_cls: 0.1693  decode.loss_mask: 1.0240  decode.loss_dice: 0.6531  decode.d0.loss_cls: 0.6462  decode.d0.loss_mask: 1.0256  decode.d0.loss_dice: 0.7224  decode.d1.loss_cls: 0.1824  decode.d1.loss_mask: 1.0378  decode.d1.loss_dice: 0.6597  decode.d2.loss_cls: 0.2102  decode.d2.loss_mask: 1.0136  decode.d2.loss_dice: 0.6755  decode.d3.loss_cls: 0.1782  decode.d3.loss_mask: 1.0195  decode.d3.loss_dice: 0.6472  decode.d4.loss_cls: 0.1592  decode.d4.loss_mask: 1.0574  decode.d4.loss_dice: 0.6714  decode.d5.loss_cls: 0.1909  decode.d5.loss_mask: 1.0210  decode.d5.loss_dice: 0.6612  decode.d6.loss_cls: 0.1702  decode.d6.loss_mask: 1.0643  decode.d6.loss_dice: 0.6742  decode.d7.loss_cls: 0.1599  decode.d7.loss_mask: 1.0767  decode.d7.loss_dice: 0.6815  decode.d8.loss_cls: 0.2260  decode.d8.loss_mask: 1.0176  decode.d8.loss_dice: 0.6644
05/27 03:37:27 - mmengine - INFO - Iter(train) [140400/160000]  base_lr: 1.5112e-05 lr: 1.5112e-06  eta: 2:15:12  time: 0.4175  data_time: 0.0100  memory: 5969  grad_norm: 781.2039  loss: 19.8391  decode.loss_cls: 0.1338  decode.loss_mask: 1.0494  decode.loss_dice: 0.7011  decode.d0.loss_cls: 0.6967  decode.d0.loss_mask: 1.0893  decode.d0.loss_dice: 0.6904  decode.d1.loss_cls: 0.1556  decode.d1.loss_mask: 1.1362  decode.d1.loss_dice: 0.7073  decode.d2.loss_cls: 0.1462  decode.d2.loss_mask: 1.0781  decode.d2.loss_dice: 0.7030  decode.d3.loss_cls: 0.1001  decode.d3.loss_mask: 1.1482  decode.d3.loss_dice: 0.7219  decode.d4.loss_cls: 0.1244  decode.d4.loss_mask: 1.1157  decode.d4.loss_dice: 0.6860  decode.d5.loss_cls: 0.1317  decode.d5.loss_mask: 1.0573  decode.d5.loss_dice: 0.6800  decode.d6.loss_cls: 0.1333  decode.d6.loss_mask: 1.0913  decode.d6.loss_dice: 0.6995  decode.d7.loss_cls: 0.0814  decode.d7.loss_mask: 1.1198  decode.d7.loss_dice: 0.7083  decode.d8.loss_cls: 0.0838  decode.d8.loss_mask: 1.1282  decode.d8.loss_dice: 0.7410
05/27 03:37:48 - mmengine - INFO - Iter(train) [140450/160000]  base_lr: 1.5077e-05 lr: 1.5077e-06  eta: 2:14:51  time: 0.4184  data_time: 0.0100  memory: 5967  grad_norm: 539.1612  loss: 18.2114  decode.loss_cls: 0.2079  decode.loss_mask: 0.8699  decode.loss_dice: 0.6641  decode.d0.loss_cls: 0.7012  decode.d0.loss_mask: 0.8736  decode.d0.loss_dice: 0.6771  decode.d1.loss_cls: 0.2777  decode.d1.loss_mask: 0.8741  decode.d1.loss_dice: 0.6743  decode.d2.loss_cls: 0.2406  decode.d2.loss_mask: 0.8898  decode.d2.loss_dice: 0.6732  decode.d3.loss_cls: 0.2384  decode.d3.loss_mask: 0.8827  decode.d3.loss_dice: 0.6627  decode.d4.loss_cls: 0.2164  decode.d4.loss_mask: 0.8723  decode.d4.loss_dice: 0.6705  decode.d5.loss_cls: 0.2110  decode.d5.loss_mask: 0.8803  decode.d5.loss_dice: 0.6760  decode.d6.loss_cls: 0.2142  decode.d6.loss_mask: 0.8405  decode.d6.loss_dice: 0.6765  decode.d7.loss_cls: 0.2389  decode.d7.loss_mask: 0.8640  decode.d7.loss_dice: 0.6815  decode.d8.loss_cls: 0.1978  decode.d8.loss_mask: 0.8898  decode.d8.loss_dice: 0.6742
05/27 03:38:09 - mmengine - INFO - Iter(train) [140500/160000]  base_lr: 1.5043e-05 lr: 1.5043e-06  eta: 2:14:31  time: 0.4189  data_time: 0.0099  memory: 5966  grad_norm: 758.7644  loss: 19.6485  decode.loss_cls: 0.1517  decode.loss_mask: 1.0501  decode.loss_dice: 0.6939  decode.d0.loss_cls: 0.5878  decode.d0.loss_mask: 1.0482  decode.d0.loss_dice: 0.7145  decode.d1.loss_cls: 0.1970  decode.d1.loss_mask: 1.0558  decode.d1.loss_dice: 0.7120  decode.d2.loss_cls: 0.1496  decode.d2.loss_mask: 1.0594  decode.d2.loss_dice: 0.7065  decode.d3.loss_cls: 0.1599  decode.d3.loss_mask: 1.0409  decode.d3.loss_dice: 0.6899  decode.d4.loss_cls: 0.1715  decode.d4.loss_mask: 1.0432  decode.d4.loss_dice: 0.7029  decode.d5.loss_cls: 0.1658  decode.d5.loss_mask: 1.0613  decode.d5.loss_dice: 0.6980  decode.d6.loss_cls: 0.1579  decode.d6.loss_mask: 1.0563  decode.d6.loss_dice: 0.7147  decode.d7.loss_cls: 0.1648  decode.d7.loss_mask: 1.0629  decode.d7.loss_dice: 0.7131  decode.d8.loss_cls: 0.1633  decode.d8.loss_mask: 1.0542  decode.d8.loss_dice: 0.7012
05/27 03:38:30 - mmengine - INFO - Iter(train) [140550/160000]  base_lr: 1.5008e-05 lr: 1.5008e-06  eta: 2:14:10  time: 0.4184  data_time: 0.0099  memory: 5966  grad_norm: 612.5173  loss: 18.8178  decode.loss_cls: 0.2233  decode.loss_mask: 0.8529  decode.loss_dice: 0.7633  decode.d0.loss_cls: 0.7031  decode.d0.loss_mask: 0.8202  decode.d0.loss_dice: 0.7246  decode.d1.loss_cls: 0.2289  decode.d1.loss_mask: 0.8429  decode.d1.loss_dice: 0.7404  decode.d2.loss_cls: 0.2176  decode.d2.loss_mask: 0.8420  decode.d2.loss_dice: 0.7470  decode.d3.loss_cls: 0.2387  decode.d3.loss_mask: 0.8566  decode.d3.loss_dice: 0.7565  decode.d4.loss_cls: 0.2376  decode.d4.loss_mask: 0.8476  decode.d4.loss_dice: 0.7654  decode.d5.loss_cls: 0.2329  decode.d5.loss_mask: 0.8665  decode.d5.loss_dice: 0.7620  decode.d6.loss_cls: 0.2572  decode.d6.loss_mask: 0.8478  decode.d6.loss_dice: 0.7748  decode.d7.loss_cls: 0.2227  decode.d7.loss_mask: 0.8463  decode.d7.loss_dice: 0.7446  decode.d8.loss_cls: 0.2305  decode.d8.loss_mask: 0.8446  decode.d8.loss_dice: 0.7792
05/27 03:38:50 - mmengine - INFO - Iter(train) [140600/160000]  base_lr: 1.4973e-05 lr: 1.4973e-06  eta: 2:13:49  time: 0.4177  data_time: 0.0100  memory: 5977  grad_norm: 516.1029  loss: 15.9053  decode.loss_cls: 0.1461  decode.loss_mask: 0.7969  decode.loss_dice: 0.6016  decode.d0.loss_cls: 0.5500  decode.d0.loss_mask: 0.8181  decode.d0.loss_dice: 0.5939  decode.d1.loss_cls: 0.1835  decode.d1.loss_mask: 0.8097  decode.d1.loss_dice: 0.5832  decode.d2.loss_cls: 0.1606  decode.d2.loss_mask: 0.8064  decode.d2.loss_dice: 0.5852  decode.d3.loss_cls: 0.1742  decode.d3.loss_mask: 0.8076  decode.d3.loss_dice: 0.5654  decode.d4.loss_cls: 0.1890  decode.d4.loss_mask: 0.8076  decode.d4.loss_dice: 0.5651  decode.d5.loss_cls: 0.1588  decode.d5.loss_mask: 0.8146  decode.d5.loss_dice: 0.5655  decode.d6.loss_cls: 0.1444  decode.d6.loss_mask: 0.8091  decode.d6.loss_dice: 0.5766  decode.d7.loss_cls: 0.1372  decode.d7.loss_mask: 0.8069  decode.d7.loss_dice: 0.6054  decode.d8.loss_cls: 0.1424  decode.d8.loss_mask: 0.8122  decode.d8.loss_dice: 0.5880
05/27 03:39:11 - mmengine - INFO - Iter(train) [140650/160000]  base_lr: 1.4939e-05 lr: 1.4939e-06  eta: 2:13:29  time: 0.4178  data_time: 0.0099  memory: 5969  grad_norm: 751.0260  loss: 17.0511  decode.loss_cls: 0.2268  decode.loss_mask: 0.7723  decode.loss_dice: 0.6718  decode.d0.loss_cls: 0.6305  decode.d0.loss_mask: 0.7670  decode.d0.loss_dice: 0.6771  decode.d1.loss_cls: 0.1974  decode.d1.loss_mask: 0.7786  decode.d1.loss_dice: 0.6959  decode.d2.loss_cls: 0.2239  decode.d2.loss_mask: 0.7479  decode.d2.loss_dice: 0.6724  decode.d3.loss_cls: 0.2059  decode.d3.loss_mask: 0.8041  decode.d3.loss_dice: 0.7118  decode.d4.loss_cls: 0.2320  decode.d4.loss_mask: 0.7428  decode.d4.loss_dice: 0.6592  decode.d5.loss_cls: 0.2279  decode.d5.loss_mask: 0.7371  decode.d5.loss_dice: 0.6613  decode.d6.loss_cls: 0.2433  decode.d6.loss_mask: 0.7317  decode.d6.loss_dice: 0.6757  decode.d7.loss_cls: 0.1905  decode.d7.loss_mask: 0.8035  decode.d7.loss_dice: 0.7269  decode.d8.loss_cls: 0.2397  decode.d8.loss_mask: 0.7321  decode.d8.loss_dice: 0.6641
05/27 03:39:32 - mmengine - INFO - Iter(train) [140700/160000]  base_lr: 1.4904e-05 lr: 1.4904e-06  eta: 2:13:08  time: 0.4181  data_time: 0.0099  memory: 5976  grad_norm: 507.6405  loss: 19.2190  decode.loss_cls: 0.1440  decode.loss_mask: 1.0666  decode.loss_dice: 0.6379  decode.d0.loss_cls: 0.6651  decode.d0.loss_mask: 1.0090  decode.d0.loss_dice: 0.6575  decode.d1.loss_cls: 0.1725  decode.d1.loss_mask: 1.0751  decode.d1.loss_dice: 0.6398  decode.d2.loss_cls: 0.1644  decode.d2.loss_mask: 1.0782  decode.d2.loss_dice: 0.6588  decode.d3.loss_cls: 0.1425  decode.d3.loss_mask: 1.0773  decode.d3.loss_dice: 0.6295  decode.d4.loss_cls: 0.1535  decode.d4.loss_mask: 1.0656  decode.d4.loss_dice: 0.6322  decode.d5.loss_cls: 0.1504  decode.d5.loss_mask: 1.0746  decode.d5.loss_dice: 0.6466  decode.d6.loss_cls: 0.1477  decode.d6.loss_mask: 1.0769  decode.d6.loss_dice: 0.6383  decode.d7.loss_cls: 0.1667  decode.d7.loss_mask: 1.1093  decode.d7.loss_dice: 0.6686  decode.d8.loss_cls: 0.1670  decode.d8.loss_mask: 1.0685  decode.d8.loss_dice: 0.6349
05/27 03:39:53 - mmengine - INFO - Iter(train) [140750/160000]  base_lr: 1.4869e-05 lr: 1.4869e-06  eta: 2:12:47  time: 0.4170  data_time: 0.0099  memory: 5966  grad_norm: 352.9985  loss: 17.0325  decode.loss_cls: 0.1408  decode.loss_mask: 0.8473  decode.loss_dice: 0.6277  decode.d0.loss_cls: 0.6380  decode.d0.loss_mask: 0.8787  decode.d0.loss_dice: 0.6611  decode.d1.loss_cls: 0.2329  decode.d1.loss_mask: 0.8343  decode.d1.loss_dice: 0.6358  decode.d2.loss_cls: 0.1938  decode.d2.loss_mask: 0.8411  decode.d2.loss_dice: 0.6374  decode.d3.loss_cls: 0.2066  decode.d3.loss_mask: 0.8298  decode.d3.loss_dice: 0.6254  decode.d4.loss_cls: 0.1804  decode.d4.loss_mask: 0.8298  decode.d4.loss_dice: 0.6171  decode.d5.loss_cls: 0.1961  decode.d5.loss_mask: 0.8213  decode.d5.loss_dice: 0.6122  decode.d6.loss_cls: 0.1618  decode.d6.loss_mask: 0.8354  decode.d6.loss_dice: 0.6341  decode.d7.loss_cls: 0.1908  decode.d7.loss_mask: 0.8601  decode.d7.loss_dice: 0.6451  decode.d8.loss_cls: 0.1430  decode.d8.loss_mask: 0.8464  decode.d8.loss_dice: 0.6284
05/27 03:40:14 - mmengine - INFO - Iter(train) [140800/160000]  base_lr: 1.4834e-05 lr: 1.4834e-06  eta: 2:12:27  time: 0.4173  data_time: 0.0099  memory: 5979  grad_norm: 286.6521  loss: 15.2591  decode.loss_cls: 0.1160  decode.loss_mask: 0.8038  decode.loss_dice: 0.5923  decode.d0.loss_cls: 0.5899  decode.d0.loss_mask: 0.7505  decode.d0.loss_dice: 0.5393  decode.d1.loss_cls: 0.1353  decode.d1.loss_mask: 0.7828  decode.d1.loss_dice: 0.5849  decode.d2.loss_cls: 0.0850  decode.d2.loss_mask: 0.8056  decode.d2.loss_dice: 0.5957  decode.d3.loss_cls: 0.1121  decode.d3.loss_mask: 0.7990  decode.d3.loss_dice: 0.5694  decode.d4.loss_cls: 0.1053  decode.d4.loss_mask: 0.7897  decode.d4.loss_dice: 0.5711  decode.d5.loss_cls: 0.0795  decode.d5.loss_mask: 0.8047  decode.d5.loss_dice: 0.5921  decode.d6.loss_cls: 0.0829  decode.d6.loss_mask: 0.8088  decode.d6.loss_dice: 0.5913  decode.d7.loss_cls: 0.1252  decode.d7.loss_mask: 0.7799  decode.d7.loss_dice: 0.5789  decode.d8.loss_cls: 0.0786  decode.d8.loss_mask: 0.8069  decode.d8.loss_dice: 0.6023
05/27 03:40:35 - mmengine - INFO - Iter(train) [140850/160000]  base_lr: 1.4799e-05 lr: 1.4799e-06  eta: 2:12:06  time: 0.4188  data_time: 0.0100  memory: 5976  grad_norm: 404.6837  loss: 19.2497  decode.loss_cls: 0.2031  decode.loss_mask: 0.9455  decode.loss_dice: 0.7058  decode.d0.loss_cls: 0.7102  decode.d0.loss_mask: 0.9405  decode.d0.loss_dice: 0.7259  decode.d1.loss_cls: 0.2385  decode.d1.loss_mask: 0.9415  decode.d1.loss_dice: 0.7043  decode.d2.loss_cls: 0.2179  decode.d2.loss_mask: 0.9366  decode.d2.loss_dice: 0.6983  decode.d3.loss_cls: 0.1972  decode.d3.loss_mask: 0.9648  decode.d3.loss_dice: 0.7156  decode.d4.loss_cls: 0.2139  decode.d4.loss_mask: 0.9432  decode.d4.loss_dice: 0.7111  decode.d5.loss_cls: 0.2256  decode.d5.loss_mask: 0.9369  decode.d5.loss_dice: 0.7080  decode.d6.loss_cls: 0.2305  decode.d6.loss_mask: 0.9626  decode.d6.loss_dice: 0.7156  decode.d7.loss_cls: 0.2212  decode.d7.loss_mask: 0.9249  decode.d7.loss_dice: 0.7155  decode.d8.loss_cls: 0.2156  decode.d8.loss_mask: 0.9522  decode.d8.loss_dice: 0.7273
05/27 03:40:56 - mmengine - INFO - Iter(train) [140900/160000]  base_lr: 1.4765e-05 lr: 1.4765e-06  eta: 2:11:45  time: 0.4169  data_time: 0.0099  memory: 5972  grad_norm: 790.3442  loss: 21.4502  decode.loss_cls: 0.1809  decode.loss_mask: 1.1097  decode.loss_dice: 0.8099  decode.d0.loss_cls: 0.6223  decode.d0.loss_mask: 1.0979  decode.d0.loss_dice: 0.8287  decode.d1.loss_cls: 0.1790  decode.d1.loss_mask: 1.0838  decode.d1.loss_dice: 0.7902  decode.d2.loss_cls: 0.1796  decode.d2.loss_mask: 1.0912  decode.d2.loss_dice: 0.8336  decode.d3.loss_cls: 0.2364  decode.d3.loss_mask: 1.0865  decode.d3.loss_dice: 0.7896  decode.d4.loss_cls: 0.1818  decode.d4.loss_mask: 1.0984  decode.d4.loss_dice: 0.8111  decode.d5.loss_cls: 0.1883  decode.d5.loss_mask: 1.1118  decode.d5.loss_dice: 0.8069  decode.d6.loss_cls: 0.1863  decode.d6.loss_mask: 1.1232  decode.d6.loss_dice: 0.8207  decode.d7.loss_cls: 0.1834  decode.d7.loss_mask: 1.1089  decode.d7.loss_dice: 0.8151  decode.d8.loss_cls: 0.2081  decode.d8.loss_mask: 1.0910  decode.d8.loss_dice: 0.7957
05/27 03:41:17 - mmengine - INFO - Iter(train) [140950/160000]  base_lr: 1.4730e-05 lr: 1.4730e-06  eta: 2:11:25  time: 0.4185  data_time: 0.0099  memory: 5971  grad_norm: 451.1074  loss: 15.5264  decode.loss_cls: 0.1012  decode.loss_mask: 0.8258  decode.loss_dice: 0.5490  decode.d0.loss_cls: 0.6555  decode.d0.loss_mask: 0.8028  decode.d0.loss_dice: 0.5209  decode.d1.loss_cls: 0.1429  decode.d1.loss_mask: 0.8365  decode.d1.loss_dice: 0.5427  decode.d2.loss_cls: 0.1102  decode.d2.loss_mask: 0.8358  decode.d2.loss_dice: 0.5453  decode.d3.loss_cls: 0.1010  decode.d3.loss_mask: 0.8396  decode.d3.loss_dice: 0.5597  decode.d4.loss_cls: 0.1183  decode.d4.loss_mask: 0.8381  decode.d4.loss_dice: 0.5495  decode.d5.loss_cls: 0.1228  decode.d5.loss_mask: 0.8348  decode.d5.loss_dice: 0.5522  decode.d6.loss_cls: 0.1717  decode.d6.loss_mask: 0.8167  decode.d6.loss_dice: 0.5314  decode.d7.loss_cls: 0.1315  decode.d7.loss_mask: 0.8368  decode.d7.loss_dice: 0.5476  decode.d8.loss_cls: 0.1045  decode.d8.loss_mask: 0.8391  decode.d8.loss_dice: 0.5625
05/27 03:41:38 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 03:41:38 - mmengine - INFO - Iter(train) [141000/160000]  base_lr: 1.4695e-05 lr: 1.4695e-06  eta: 2:11:04  time: 0.4189  data_time: 0.0102  memory: 5970  grad_norm: 408.5628  loss: 16.7700  decode.loss_cls: 0.1759  decode.loss_mask: 0.9037  decode.loss_dice: 0.5762  decode.d0.loss_cls: 0.6070  decode.d0.loss_mask: 0.8785  decode.d0.loss_dice: 0.5773  decode.d1.loss_cls: 0.1898  decode.d1.loss_mask: 0.8813  decode.d1.loss_dice: 0.5874  decode.d2.loss_cls: 0.1719  decode.d2.loss_mask: 0.8932  decode.d2.loss_dice: 0.5660  decode.d3.loss_cls: 0.1396  decode.d3.loss_mask: 0.8891  decode.d3.loss_dice: 0.5727  decode.d4.loss_cls: 0.1664  decode.d4.loss_mask: 0.8847  decode.d4.loss_dice: 0.5660  decode.d5.loss_cls: 0.1586  decode.d5.loss_mask: 0.8927  decode.d5.loss_dice: 0.5851  decode.d6.loss_cls: 0.1911  decode.d6.loss_mask: 0.8565  decode.d6.loss_dice: 0.5916  decode.d7.loss_cls: 0.1711  decode.d7.loss_mask: 0.8581  decode.d7.loss_dice: 0.5897  decode.d8.loss_cls: 0.1762  decode.d8.loss_mask: 0.8982  decode.d8.loss_dice: 0.5739
05/27 03:41:59 - mmengine - INFO - Iter(train) [141050/160000]  base_lr: 1.4660e-05 lr: 1.4660e-06  eta: 2:10:43  time: 0.4192  data_time: 0.0103  memory: 5980  grad_norm: 534.5694  loss: 24.1377  decode.loss_cls: 0.4131  decode.loss_mask: 1.1198  decode.loss_dice: 0.8349  decode.d0.loss_cls: 0.9777  decode.d0.loss_mask: 1.1377  decode.d0.loss_dice: 0.8800  decode.d1.loss_cls: 0.4053  decode.d1.loss_mask: 1.0966  decode.d1.loss_dice: 0.8533  decode.d2.loss_cls: 0.3871  decode.d2.loss_mask: 1.1265  decode.d2.loss_dice: 0.8371  decode.d3.loss_cls: 0.4176  decode.d3.loss_mask: 1.1096  decode.d3.loss_dice: 0.8437  decode.d4.loss_cls: 0.4260  decode.d4.loss_mask: 1.0737  decode.d4.loss_dice: 0.8478  decode.d5.loss_cls: 0.4095  decode.d5.loss_mask: 1.0918  decode.d5.loss_dice: 0.8437  decode.d6.loss_cls: 0.4119  decode.d6.loss_mask: 1.0897  decode.d6.loss_dice: 0.8568  decode.d7.loss_cls: 0.4084  decode.d7.loss_mask: 1.0779  decode.d7.loss_dice: 0.8443  decode.d8.loss_cls: 0.3623  decode.d8.loss_mask: 1.1114  decode.d8.loss_dice: 0.8424
05/27 03:42:20 - mmengine - INFO - Iter(train) [141100/160000]  base_lr: 1.4625e-05 lr: 1.4625e-06  eta: 2:10:23  time: 0.4179  data_time: 0.0101  memory: 5975  grad_norm: 505.2892  loss: 17.7010  decode.loss_cls: 0.1238  decode.loss_mask: 0.9589  decode.loss_dice: 0.6342  decode.d0.loss_cls: 0.6397  decode.d0.loss_mask: 0.8991  decode.d0.loss_dice: 0.6402  decode.d1.loss_cls: 0.1493  decode.d1.loss_mask: 0.9492  decode.d1.loss_dice: 0.6165  decode.d2.loss_cls: 0.1049  decode.d2.loss_mask: 0.9624  decode.d2.loss_dice: 0.6377  decode.d3.loss_cls: 0.1514  decode.d3.loss_mask: 0.9385  decode.d3.loss_dice: 0.6310  decode.d4.loss_cls: 0.1337  decode.d4.loss_mask: 0.9696  decode.d4.loss_dice: 0.6426  decode.d5.loss_cls: 0.1151  decode.d5.loss_mask: 0.9559  decode.d5.loss_dice: 0.6457  decode.d6.loss_cls: 0.1448  decode.d6.loss_mask: 0.9533  decode.d6.loss_dice: 0.6513  decode.d7.loss_cls: 0.1176  decode.d7.loss_mask: 0.9554  decode.d7.loss_dice: 0.6501  decode.d8.loss_cls: 0.1202  decode.d8.loss_mask: 0.9598  decode.d8.loss_dice: 0.6490
05/27 03:42:41 - mmengine - INFO - Iter(train) [141150/160000]  base_lr: 1.4591e-05 lr: 1.4591e-06  eta: 2:10:02  time: 0.4189  data_time: 0.0099  memory: 5969  grad_norm: 484.4479  loss: 14.2963  decode.loss_cls: 0.1161  decode.loss_mask: 0.7246  decode.loss_dice: 0.5296  decode.d0.loss_cls: 0.6391  decode.d0.loss_mask: 0.7169  decode.d0.loss_dice: 0.5403  decode.d1.loss_cls: 0.1284  decode.d1.loss_mask: 0.7326  decode.d1.loss_dice: 0.5394  decode.d2.loss_cls: 0.0870  decode.d2.loss_mask: 0.7266  decode.d2.loss_dice: 0.5324  decode.d3.loss_cls: 0.1003  decode.d3.loss_mask: 0.7306  decode.d3.loss_dice: 0.5499  decode.d4.loss_cls: 0.0930  decode.d4.loss_mask: 0.7584  decode.d4.loss_dice: 0.5505  decode.d5.loss_cls: 0.1096  decode.d5.loss_mask: 0.7316  decode.d5.loss_dice: 0.5420  decode.d6.loss_cls: 0.0978  decode.d6.loss_mask: 0.7315  decode.d6.loss_dice: 0.5409  decode.d7.loss_cls: 0.1102  decode.d7.loss_mask: 0.7313  decode.d7.loss_dice: 0.5269  decode.d8.loss_cls: 0.0948  decode.d8.loss_mask: 0.7519  decode.d8.loss_dice: 0.5318
05/27 03:43:02 - mmengine - INFO - Iter(train) [141200/160000]  base_lr: 1.4556e-05 lr: 1.4556e-06  eta: 2:09:41  time: 0.4167  data_time: 0.0099  memory: 5965  grad_norm: 482.0575  loss: 15.7884  decode.loss_cls: 0.1061  decode.loss_mask: 0.8591  decode.loss_dice: 0.5716  decode.d0.loss_cls: 0.5736  decode.d0.loss_mask: 0.8256  decode.d0.loss_dice: 0.5714  decode.d1.loss_cls: 0.0821  decode.d1.loss_mask: 0.8904  decode.d1.loss_dice: 0.5976  decode.d2.loss_cls: 0.1119  decode.d2.loss_mask: 0.8519  decode.d2.loss_dice: 0.5718  decode.d3.loss_cls: 0.0904  decode.d3.loss_mask: 0.8578  decode.d3.loss_dice: 0.5728  decode.d4.loss_cls: 0.1021  decode.d4.loss_mask: 0.8608  decode.d4.loss_dice: 0.5901  decode.d5.loss_cls: 0.0881  decode.d5.loss_mask: 0.8530  decode.d5.loss_dice: 0.5875  decode.d6.loss_cls: 0.0995  decode.d6.loss_mask: 0.8520  decode.d6.loss_dice: 0.5707  decode.d7.loss_cls: 0.0868  decode.d7.loss_mask: 0.8584  decode.d7.loss_dice: 0.5704  decode.d8.loss_cls: 0.1025  decode.d8.loss_mask: 0.8605  decode.d8.loss_dice: 0.5719
05/27 03:43:23 - mmengine - INFO - Iter(train) [141250/160000]  base_lr: 1.4521e-05 lr: 1.4521e-06  eta: 2:09:21  time: 0.4174  data_time: 0.0099  memory: 5976  grad_norm: 327.7389  loss: 15.8246  decode.loss_cls: 0.1161  decode.loss_mask: 0.8353  decode.loss_dice: 0.5500  decode.d0.loss_cls: 0.6258  decode.d0.loss_mask: 0.8063  decode.d0.loss_dice: 0.5395  decode.d1.loss_cls: 0.1394  decode.d1.loss_mask: 0.8459  decode.d1.loss_dice: 0.5662  decode.d2.loss_cls: 0.1247  decode.d2.loss_mask: 0.8520  decode.d2.loss_dice: 0.5570  decode.d3.loss_cls: 0.1482  decode.d3.loss_mask: 0.8519  decode.d3.loss_dice: 0.5580  decode.d4.loss_cls: 0.1316  decode.d4.loss_mask: 0.8473  decode.d4.loss_dice: 0.5410  decode.d5.loss_cls: 0.1468  decode.d5.loss_mask: 0.8463  decode.d5.loss_dice: 0.5515  decode.d6.loss_cls: 0.1770  decode.d6.loss_mask: 0.8475  decode.d6.loss_dice: 0.5563  decode.d7.loss_cls: 0.1488  decode.d7.loss_mask: 0.8455  decode.d7.loss_dice: 0.5495  decode.d8.loss_cls: 0.1347  decode.d8.loss_mask: 0.8347  decode.d8.loss_dice: 0.5497
05/27 03:43:43 - mmengine - INFO - Iter(train) [141300/160000]  base_lr: 1.4486e-05 lr: 1.4486e-06  eta: 2:09:00  time: 0.4180  data_time: 0.0099  memory: 5967  grad_norm: 413.1932  loss: 18.7624  decode.loss_cls: 0.1754  decode.loss_mask: 0.9346  decode.loss_dice: 0.7430  decode.d0.loss_cls: 0.6423  decode.d0.loss_mask: 0.8792  decode.d0.loss_dice: 0.6969  decode.d1.loss_cls: 0.2159  decode.d1.loss_mask: 0.9209  decode.d1.loss_dice: 0.7408  decode.d2.loss_cls: 0.1891  decode.d2.loss_mask: 0.9220  decode.d2.loss_dice: 0.7516  decode.d3.loss_cls: 0.2344  decode.d3.loss_mask: 0.8931  decode.d3.loss_dice: 0.7154  decode.d4.loss_cls: 0.2200  decode.d4.loss_mask: 0.8779  decode.d4.loss_dice: 0.7350  decode.d5.loss_cls: 0.2505  decode.d5.loss_mask: 0.8598  decode.d5.loss_dice: 0.6842  decode.d6.loss_cls: 0.1807  decode.d6.loss_mask: 0.9293  decode.d6.loss_dice: 0.7276  decode.d7.loss_cls: 0.1958  decode.d7.loss_mask: 0.9128  decode.d7.loss_dice: 0.7222  decode.d8.loss_cls: 0.1904  decode.d8.loss_mask: 0.8977  decode.d8.loss_dice: 0.7241
05/27 03:44:04 - mmengine - INFO - Iter(train) [141350/160000]  base_lr: 1.4451e-05 lr: 1.4451e-06  eta: 2:08:39  time: 0.4174  data_time: 0.0099  memory: 5971  grad_norm: 682.0184  loss: 20.3677  decode.loss_cls: 0.1946  decode.loss_mask: 1.0898  decode.loss_dice: 0.7304  decode.d0.loss_cls: 0.6675  decode.d0.loss_mask: 1.0428  decode.d0.loss_dice: 0.7234  decode.d1.loss_cls: 0.1861  decode.d1.loss_mask: 1.0800  decode.d1.loss_dice: 0.7356  decode.d2.loss_cls: 0.2160  decode.d2.loss_mask: 1.0878  decode.d2.loss_dice: 0.7082  decode.d3.loss_cls: 0.2001  decode.d3.loss_mask: 1.0545  decode.d3.loss_dice: 0.6977  decode.d4.loss_cls: 0.2167  decode.d4.loss_mask: 1.0433  decode.d4.loss_dice: 0.7035  decode.d5.loss_cls: 0.1821  decode.d5.loss_mask: 1.0683  decode.d5.loss_dice: 0.7053  decode.d6.loss_cls: 0.2130  decode.d6.loss_mask: 1.0785  decode.d6.loss_dice: 0.7126  decode.d7.loss_cls: 0.2085  decode.d7.loss_mask: 1.0767  decode.d7.loss_dice: 0.7312  decode.d8.loss_cls: 0.2236  decode.d8.loss_mask: 1.0736  decode.d8.loss_dice: 0.7163
05/27 03:44:25 - mmengine - INFO - Iter(train) [141400/160000]  base_lr: 1.4416e-05 lr: 1.4416e-06  eta: 2:08:19  time: 0.4173  data_time: 0.0100  memory: 5980  grad_norm: 438.3665  loss: 19.2242  decode.loss_cls: 0.2237  decode.loss_mask: 0.8919  decode.loss_dice: 0.7269  decode.d0.loss_cls: 0.7964  decode.d0.loss_mask: 0.8936  decode.d0.loss_dice: 0.7038  decode.d1.loss_cls: 0.3084  decode.d1.loss_mask: 0.8719  decode.d1.loss_dice: 0.7256  decode.d2.loss_cls: 0.2872  decode.d2.loss_mask: 0.8978  decode.d2.loss_dice: 0.7019  decode.d3.loss_cls: 0.2518  decode.d3.loss_mask: 0.8900  decode.d3.loss_dice: 0.7234  decode.d4.loss_cls: 0.3020  decode.d4.loss_mask: 0.8930  decode.d4.loss_dice: 0.7030  decode.d5.loss_cls: 0.2520  decode.d5.loss_mask: 0.8977  decode.d5.loss_dice: 0.7112  decode.d6.loss_cls: 0.2740  decode.d6.loss_mask: 0.8865  decode.d6.loss_dice: 0.6939  decode.d7.loss_cls: 0.2488  decode.d7.loss_mask: 0.8908  decode.d7.loss_dice: 0.7293  decode.d8.loss_cls: 0.2517  decode.d8.loss_mask: 0.8807  decode.d8.loss_dice: 0.7152
05/27 03:44:46 - mmengine - INFO - Iter(train) [141450/160000]  base_lr: 1.4381e-05 lr: 1.4381e-06  eta: 2:07:58  time: 0.4177  data_time: 0.0100  memory: 5975  grad_norm: 490.0885  loss: 18.6120  decode.loss_cls: 0.1764  decode.loss_mask: 0.9422  decode.loss_dice: 0.6879  decode.d0.loss_cls: 0.6831  decode.d0.loss_mask: 0.9295  decode.d0.loss_dice: 0.6683  decode.d1.loss_cls: 0.2129  decode.d1.loss_mask: 0.9496  decode.d1.loss_dice: 0.6834  decode.d2.loss_cls: 0.2004  decode.d2.loss_mask: 0.9447  decode.d2.loss_dice: 0.6902  decode.d3.loss_cls: 0.1463  decode.d3.loss_mask: 0.9652  decode.d3.loss_dice: 0.7035  decode.d4.loss_cls: 0.1673  decode.d4.loss_mask: 0.9523  decode.d4.loss_dice: 0.6876  decode.d5.loss_cls: 0.1786  decode.d5.loss_mask: 0.9429  decode.d5.loss_dice: 0.6919  decode.d6.loss_cls: 0.1816  decode.d6.loss_mask: 0.9469  decode.d6.loss_dice: 0.6844  decode.d7.loss_cls: 0.1661  decode.d7.loss_mask: 0.9479  decode.d7.loss_dice: 0.6880  decode.d8.loss_cls: 0.1585  decode.d8.loss_mask: 0.9441  decode.d8.loss_dice: 0.6900
05/27 03:45:07 - mmengine - INFO - Iter(train) [141500/160000]  base_lr: 1.4347e-05 lr: 1.4347e-06  eta: 2:07:37  time: 0.4186  data_time: 0.0099  memory: 5974  grad_norm: 882.8722  loss: 19.4965  decode.loss_cls: 0.1422  decode.loss_mask: 0.9499  decode.loss_dice: 0.7653  decode.d0.loss_cls: 0.8271  decode.d0.loss_mask: 0.9039  decode.d0.loss_dice: 0.7238  decode.d1.loss_cls: 0.1861  decode.d1.loss_mask: 0.9601  decode.d1.loss_dice: 0.7630  decode.d2.loss_cls: 0.1990  decode.d2.loss_mask: 0.9662  decode.d2.loss_dice: 0.7506  decode.d3.loss_cls: 0.1987  decode.d3.loss_mask: 0.9520  decode.d3.loss_dice: 0.7446  decode.d4.loss_cls: 0.1967  decode.d4.loss_mask: 0.9649  decode.d4.loss_dice: 0.7554  decode.d5.loss_cls: 0.1962  decode.d5.loss_mask: 0.9581  decode.d5.loss_dice: 0.7513  decode.d6.loss_cls: 0.1962  decode.d6.loss_mask: 0.9546  decode.d6.loss_dice: 0.7432  decode.d7.loss_cls: 0.1733  decode.d7.loss_mask: 0.9563  decode.d7.loss_dice: 0.7468  decode.d8.loss_cls: 0.1530  decode.d8.loss_mask: 0.9528  decode.d8.loss_dice: 0.7651
05/27 03:45:28 - mmengine - INFO - Iter(train) [141550/160000]  base_lr: 1.4312e-05 lr: 1.4312e-06  eta: 2:07:17  time: 0.4176  data_time: 0.0099  memory: 5980  grad_norm: 595.0535  loss: 19.9437  decode.loss_cls: 0.1248  decode.loss_mask: 1.1089  decode.loss_dice: 0.6785  decode.d0.loss_cls: 0.6957  decode.d0.loss_mask: 0.9814  decode.d0.loss_dice: 0.6488  decode.d1.loss_cls: 0.1927  decode.d1.loss_mask: 1.0616  decode.d1.loss_dice: 0.6637  decode.d2.loss_cls: 0.1349  decode.d2.loss_mask: 1.1322  decode.d2.loss_dice: 0.6969  decode.d3.loss_cls: 0.2252  decode.d3.loss_mask: 1.1012  decode.d3.loss_dice: 0.6755  decode.d4.loss_cls: 0.1932  decode.d4.loss_mask: 1.1499  decode.d4.loss_dice: 0.6803  decode.d5.loss_cls: 0.1583  decode.d5.loss_mask: 1.0824  decode.d5.loss_dice: 0.6997  decode.d6.loss_cls: 0.1884  decode.d6.loss_mask: 1.0955  decode.d6.loss_dice: 0.7010  decode.d7.loss_cls: 0.1334  decode.d7.loss_mask: 1.1308  decode.d7.loss_dice: 0.7036  decode.d8.loss_cls: 0.1567  decode.d8.loss_mask: 1.0986  decode.d8.loss_dice: 0.6500
05/27 03:45:49 - mmengine - INFO - Iter(train) [141600/160000]  base_lr: 1.4277e-05 lr: 1.4277e-06  eta: 2:06:56  time: 0.4188  data_time: 0.0100  memory: 5966  grad_norm: 717.4074  loss: 18.9801  decode.loss_cls: 0.3399  decode.loss_mask: 0.8260  decode.loss_dice: 0.6267  decode.d0.loss_cls: 0.8141  decode.d0.loss_mask: 0.9352  decode.d0.loss_dice: 0.6869  decode.d1.loss_cls: 0.3340  decode.d1.loss_mask: 0.8684  decode.d1.loss_dice: 0.6748  decode.d2.loss_cls: 0.3081  decode.d2.loss_mask: 0.8703  decode.d2.loss_dice: 0.6703  decode.d3.loss_cls: 0.3218  decode.d3.loss_mask: 0.8575  decode.d3.loss_dice: 0.6757  decode.d4.loss_cls: 0.3028  decode.d4.loss_mask: 0.8737  decode.d4.loss_dice: 0.6445  decode.d5.loss_cls: 0.3157  decode.d5.loss_mask: 0.8918  decode.d5.loss_dice: 0.6700  decode.d6.loss_cls: 0.2917  decode.d6.loss_mask: 0.8624  decode.d6.loss_dice: 0.6458  decode.d7.loss_cls: 0.3316  decode.d7.loss_mask: 0.8526  decode.d7.loss_dice: 0.6370  decode.d8.loss_cls: 0.3469  decode.d8.loss_mask: 0.8387  decode.d8.loss_dice: 0.6652
05/27 03:46:10 - mmengine - INFO - Iter(train) [141650/160000]  base_lr: 1.4242e-05 lr: 1.4242e-06  eta: 2:06:35  time: 0.4176  data_time: 0.0099  memory: 5969  grad_norm: 608.1158  loss: 18.1097  decode.loss_cls: 0.1288  decode.loss_mask: 0.9150  decode.loss_dice: 0.6823  decode.d0.loss_cls: 0.6789  decode.d0.loss_mask: 0.8968  decode.d0.loss_dice: 0.6662  decode.d1.loss_cls: 0.2083  decode.d1.loss_mask: 0.9287  decode.d1.loss_dice: 0.6722  decode.d2.loss_cls: 0.1617  decode.d2.loss_mask: 0.9463  decode.d2.loss_dice: 0.6899  decode.d3.loss_cls: 0.1627  decode.d3.loss_mask: 0.9105  decode.d3.loss_dice: 0.6711  decode.d4.loss_cls: 0.1570  decode.d4.loss_mask: 0.9235  decode.d4.loss_dice: 0.6932  decode.d5.loss_cls: 0.1603  decode.d5.loss_mask: 0.9166  decode.d5.loss_dice: 0.6893  decode.d6.loss_cls: 0.1596  decode.d6.loss_mask: 0.8963  decode.d6.loss_dice: 0.6711  decode.d7.loss_cls: 0.1626  decode.d7.loss_mask: 0.9092  decode.d7.loss_dice: 0.6852  decode.d8.loss_cls: 0.1497  decode.d8.loss_mask: 0.9264  decode.d8.loss_dice: 0.6900
05/27 03:46:31 - mmengine - INFO - Iter(train) [141700/160000]  base_lr: 1.4207e-05 lr: 1.4207e-06  eta: 2:06:15  time: 0.4175  data_time: 0.0100  memory: 5972  grad_norm: 642.3513  loss: 17.1190  decode.loss_cls: 0.1105  decode.loss_mask: 0.9375  decode.loss_dice: 0.5873  decode.d0.loss_cls: 0.5938  decode.d0.loss_mask: 0.9222  decode.d0.loss_dice: 0.5837  decode.d1.loss_cls: 0.1338  decode.d1.loss_mask: 0.9651  decode.d1.loss_dice: 0.6044  decode.d2.loss_cls: 0.1224  decode.d2.loss_mask: 0.9626  decode.d2.loss_dice: 0.6002  decode.d3.loss_cls: 0.1343  decode.d3.loss_mask: 0.9647  decode.d3.loss_dice: 0.6045  decode.d4.loss_cls: 0.1160  decode.d4.loss_mask: 0.9503  decode.d4.loss_dice: 0.5922  decode.d5.loss_cls: 0.1160  decode.d5.loss_mask: 0.9403  decode.d5.loss_dice: 0.5836  decode.d6.loss_cls: 0.1421  decode.d6.loss_mask: 0.9510  decode.d6.loss_dice: 0.5903  decode.d7.loss_cls: 0.1230  decode.d7.loss_mask: 0.9532  decode.d7.loss_dice: 0.5825  decode.d8.loss_cls: 0.1133  decode.d8.loss_mask: 0.9434  decode.d8.loss_dice: 0.5947
05/27 03:46:52 - mmengine - INFO - Iter(train) [141750/160000]  base_lr: 1.4172e-05 lr: 1.4172e-06  eta: 2:05:54  time: 0.4166  data_time: 0.0098  memory: 5989  grad_norm: 559.1293  loss: 18.3452  decode.loss_cls: 0.1573  decode.loss_mask: 1.0191  decode.loss_dice: 0.6361  decode.d0.loss_cls: 0.6060  decode.d0.loss_mask: 0.9473  decode.d0.loss_dice: 0.6246  decode.d1.loss_cls: 0.1854  decode.d1.loss_mask: 0.9733  decode.d1.loss_dice: 0.6459  decode.d2.loss_cls: 0.2135  decode.d2.loss_mask: 0.9548  decode.d2.loss_dice: 0.6174  decode.d3.loss_cls: 0.1960  decode.d3.loss_mask: 0.9523  decode.d3.loss_dice: 0.6420  decode.d4.loss_cls: 0.1469  decode.d4.loss_mask: 0.9979  decode.d4.loss_dice: 0.6518  decode.d5.loss_cls: 0.1673  decode.d5.loss_mask: 0.9866  decode.d5.loss_dice: 0.6423  decode.d6.loss_cls: 0.1913  decode.d6.loss_mask: 0.9687  decode.d6.loss_dice: 0.6361  decode.d7.loss_cls: 0.1933  decode.d7.loss_mask: 0.9619  decode.d7.loss_dice: 0.6524  decode.d8.loss_cls: 0.1776  decode.d8.loss_mask: 0.9701  decode.d8.loss_dice: 0.6295
05/27 03:47:13 - mmengine - INFO - Iter(train) [141800/160000]  base_lr: 1.4137e-05 lr: 1.4137e-06  eta: 2:05:33  time: 0.4176  data_time: 0.0099  memory: 5967  grad_norm: 400.7854  loss: 14.8198  decode.loss_cls: 0.1107  decode.loss_mask: 0.7961  decode.loss_dice: 0.5235  decode.d0.loss_cls: 0.5239  decode.d0.loss_mask: 0.8079  decode.d0.loss_dice: 0.5245  decode.d1.loss_cls: 0.1289  decode.d1.loss_mask: 0.7872  decode.d1.loss_dice: 0.5264  decode.d2.loss_cls: 0.1386  decode.d2.loss_mask: 0.7867  decode.d2.loss_dice: 0.5275  decode.d3.loss_cls: 0.1368  decode.d3.loss_mask: 0.7864  decode.d3.loss_dice: 0.5279  decode.d4.loss_cls: 0.1460  decode.d4.loss_mask: 0.7844  decode.d4.loss_dice: 0.5331  decode.d5.loss_cls: 0.1193  decode.d5.loss_mask: 0.7863  decode.d5.loss_dice: 0.5267  decode.d6.loss_cls: 0.1159  decode.d6.loss_mask: 0.7920  decode.d6.loss_dice: 0.5262  decode.d7.loss_cls: 0.1099  decode.d7.loss_mask: 0.7929  decode.d7.loss_dice: 0.5261  decode.d8.loss_cls: 0.1167  decode.d8.loss_mask: 0.7830  decode.d8.loss_dice: 0.5284
05/27 03:47:33 - mmengine - INFO - Iter(train) [141850/160000]  base_lr: 1.4102e-05 lr: 1.4102e-06  eta: 2:05:13  time: 0.4179  data_time: 0.0099  memory: 5988  grad_norm: 443.1957  loss: 21.7186  decode.loss_cls: 0.2273  decode.loss_mask: 1.1062  decode.loss_dice: 0.7839  decode.d0.loss_cls: 0.7651  decode.d0.loss_mask: 1.1371  decode.d0.loss_dice: 0.8045  decode.d1.loss_cls: 0.2236  decode.d1.loss_mask: 1.0995  decode.d1.loss_dice: 0.7820  decode.d2.loss_cls: 0.2118  decode.d2.loss_mask: 1.0876  decode.d2.loss_dice: 0.7821  decode.d3.loss_cls: 0.2227  decode.d3.loss_mask: 1.1017  decode.d3.loss_dice: 0.7728  decode.d4.loss_cls: 0.2621  decode.d4.loss_mask: 1.0951  decode.d4.loss_dice: 0.7659  decode.d5.loss_cls: 0.2474  decode.d5.loss_mask: 1.0863  decode.d5.loss_dice: 0.7722  decode.d6.loss_cls: 0.2809  decode.d6.loss_mask: 1.0956  decode.d6.loss_dice: 0.7706  decode.d7.loss_cls: 0.2540  decode.d7.loss_mask: 1.1015  decode.d7.loss_dice: 0.7861  decode.d8.loss_cls: 0.2355  decode.d8.loss_mask: 1.0752  decode.d8.loss_dice: 0.7821
05/27 03:47:54 - mmengine - INFO - Iter(train) [141900/160000]  base_lr: 1.4067e-05 lr: 1.4067e-06  eta: 2:04:52  time: 0.4174  data_time: 0.0099  memory: 5980  grad_norm: 314.9484  loss: 14.5267  decode.loss_cls: 0.1115  decode.loss_mask: 0.7338  decode.loss_dice: 0.5537  decode.d0.loss_cls: 0.6151  decode.d0.loss_mask: 0.6437  decode.d0.loss_dice: 0.5471  decode.d1.loss_cls: 0.1211  decode.d1.loss_mask: 0.7440  decode.d1.loss_dice: 0.5459  decode.d2.loss_cls: 0.1161  decode.d2.loss_mask: 0.7593  decode.d2.loss_dice: 0.5608  decode.d3.loss_cls: 0.1105  decode.d3.loss_mask: 0.7455  decode.d3.loss_dice: 0.5609  decode.d4.loss_cls: 0.1318  decode.d4.loss_mask: 0.7364  decode.d4.loss_dice: 0.5636  decode.d5.loss_cls: 0.1141  decode.d5.loss_mask: 0.7443  decode.d5.loss_dice: 0.5654  decode.d6.loss_cls: 0.1406  decode.d6.loss_mask: 0.7029  decode.d6.loss_dice: 0.5275  decode.d7.loss_cls: 0.1131  decode.d7.loss_mask: 0.7477  decode.d7.loss_dice: 0.5642  decode.d8.loss_cls: 0.1063  decode.d8.loss_mask: 0.7440  decode.d8.loss_dice: 0.5556
05/27 03:48:15 - mmengine - INFO - Iter(train) [141950/160000]  base_lr: 1.4032e-05 lr: 1.4032e-06  eta: 2:04:31  time: 0.4178  data_time: 0.0100  memory: 5975  grad_norm: 570.9168  loss: 22.3822  decode.loss_cls: 0.1837  decode.loss_mask: 1.1718  decode.loss_dice: 0.8053  decode.d0.loss_cls: 0.7044  decode.d0.loss_mask: 1.0838  decode.d0.loss_dice: 0.7821  decode.d1.loss_cls: 0.2262  decode.d1.loss_mask: 1.2006  decode.d1.loss_dice: 0.8188  decode.d2.loss_cls: 0.1716  decode.d2.loss_mask: 1.1906  decode.d2.loss_dice: 0.7992  decode.d3.loss_cls: 0.1650  decode.d3.loss_mask: 1.2244  decode.d3.loss_dice: 0.8211  decode.d4.loss_cls: 0.1825  decode.d4.loss_mask: 1.2129  decode.d4.loss_dice: 0.8159  decode.d5.loss_cls: 0.1635  decode.d5.loss_mask: 1.2130  decode.d5.loss_dice: 0.8214  decode.d6.loss_cls: 0.1689  decode.d6.loss_mask: 1.2125  decode.d6.loss_dice: 0.8371  decode.d7.loss_cls: 0.1777  decode.d7.loss_mask: 1.2057  decode.d7.loss_dice: 0.8147  decode.d8.loss_cls: 0.1943  decode.d8.loss_mask: 1.2015  decode.d8.loss_dice: 0.8119
05/27 03:48:36 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 03:48:36 - mmengine - INFO - Iter(train) [142000/160000]  base_lr: 1.3997e-05 lr: 1.3997e-06  eta: 2:04:11  time: 0.4171  data_time: 0.0099  memory: 5976  grad_norm: 364.4757  loss: 20.2621  decode.loss_cls: 0.2039  decode.loss_mask: 1.0687  decode.loss_dice: 0.6752  decode.d0.loss_cls: 0.7117  decode.d0.loss_mask: 1.0043  decode.d0.loss_dice: 0.6719  decode.d1.loss_cls: 0.2281  decode.d1.loss_mask: 1.0873  decode.d1.loss_dice: 0.6864  decode.d2.loss_cls: 0.2434  decode.d2.loss_mask: 1.0869  decode.d2.loss_dice: 0.6819  decode.d3.loss_cls: 0.2136  decode.d3.loss_mask: 1.0670  decode.d3.loss_dice: 0.6774  decode.d4.loss_cls: 0.2121  decode.d4.loss_mask: 1.1084  decode.d4.loss_dice: 0.6865  decode.d5.loss_cls: 0.1758  decode.d5.loss_mask: 1.1158  decode.d5.loss_dice: 0.7195  decode.d6.loss_cls: 0.1954  decode.d6.loss_mask: 1.0851  decode.d6.loss_dice: 0.6747  decode.d7.loss_cls: 0.2286  decode.d7.loss_mask: 1.0736  decode.d7.loss_dice: 0.6899  decode.d8.loss_cls: 0.2106  decode.d8.loss_mask: 1.0894  decode.d8.loss_dice: 0.6888
05/27 03:48:57 - mmengine - INFO - Iter(train) [142050/160000]  base_lr: 1.3962e-05 lr: 1.3962e-06  eta: 2:03:50  time: 0.4182  data_time: 0.0099  memory: 5981  grad_norm: 536.6888  loss: 20.9597  decode.loss_cls: 0.2362  decode.loss_mask: 1.0909  decode.loss_dice: 0.7523  decode.d0.loss_cls: 0.7491  decode.d0.loss_mask: 1.0947  decode.d0.loss_dice: 0.7797  decode.d1.loss_cls: 0.2073  decode.d1.loss_mask: 1.0854  decode.d1.loss_dice: 0.7288  decode.d2.loss_cls: 0.2005  decode.d2.loss_mask: 1.0892  decode.d2.loss_dice: 0.7158  decode.d3.loss_cls: 0.2061  decode.d3.loss_mask: 1.0609  decode.d3.loss_dice: 0.7250  decode.d4.loss_cls: 0.2184  decode.d4.loss_mask: 1.1154  decode.d4.loss_dice: 0.7219  decode.d5.loss_cls: 0.2066  decode.d5.loss_mask: 1.1059  decode.d5.loss_dice: 0.7367  decode.d6.loss_cls: 0.2174  decode.d6.loss_mask: 1.0604  decode.d6.loss_dice: 0.7585  decode.d7.loss_cls: 0.1925  decode.d7.loss_mask: 1.0994  decode.d7.loss_dice: 0.7587  decode.d8.loss_cls: 0.2129  decode.d8.loss_mask: 1.0721  decode.d8.loss_dice: 0.7606
05/27 03:49:18 - mmengine - INFO - Iter(train) [142100/160000]  base_lr: 1.3927e-05 lr: 1.3927e-06  eta: 2:03:29  time: 0.4180  data_time: 0.0100  memory: 5971  grad_norm: 599.9900  loss: 15.0891  decode.loss_cls: 0.1232  decode.loss_mask: 0.7443  decode.loss_dice: 0.5946  decode.d0.loss_cls: 0.5773  decode.d0.loss_mask: 0.7370  decode.d0.loss_dice: 0.5731  decode.d1.loss_cls: 0.1400  decode.d1.loss_mask: 0.7228  decode.d1.loss_dice: 0.5859  decode.d2.loss_cls: 0.1201  decode.d2.loss_mask: 0.7422  decode.d2.loss_dice: 0.6123  decode.d3.loss_cls: 0.1226  decode.d3.loss_mask: 0.7411  decode.d3.loss_dice: 0.5994  decode.d4.loss_cls: 0.1324  decode.d4.loss_mask: 0.7433  decode.d4.loss_dice: 0.5913  decode.d5.loss_cls: 0.1288  decode.d5.loss_mask: 0.7468  decode.d5.loss_dice: 0.6074  decode.d6.loss_cls: 0.1460  decode.d6.loss_mask: 0.7384  decode.d6.loss_dice: 0.5765  decode.d7.loss_cls: 0.1302  decode.d7.loss_mask: 0.7468  decode.d7.loss_dice: 0.5981  decode.d8.loss_cls: 0.1166  decode.d8.loss_mask: 0.7464  decode.d8.loss_dice: 0.6044
05/27 03:49:39 - mmengine - INFO - Iter(train) [142150/160000]  base_lr: 1.3892e-05 lr: 1.3892e-06  eta: 2:03:09  time: 0.4186  data_time: 0.0099  memory: 5972  grad_norm: 616.4327  loss: 18.6442  decode.loss_cls: 0.1881  decode.loss_mask: 1.0008  decode.loss_dice: 0.6719  decode.d0.loss_cls: 0.6756  decode.d0.loss_mask: 0.9555  decode.d0.loss_dice: 0.6510  decode.d1.loss_cls: 0.2803  decode.d1.loss_mask: 0.9241  decode.d1.loss_dice: 0.6478  decode.d2.loss_cls: 0.1835  decode.d2.loss_mask: 0.9916  decode.d2.loss_dice: 0.6395  decode.d3.loss_cls: 0.2053  decode.d3.loss_mask: 0.9921  decode.d3.loss_dice: 0.6414  decode.d4.loss_cls: 0.2319  decode.d4.loss_mask: 0.9122  decode.d4.loss_dice: 0.6098  decode.d5.loss_cls: 0.2325  decode.d5.loss_mask: 0.9912  decode.d5.loss_dice: 0.6339  decode.d6.loss_cls: 0.2075  decode.d6.loss_mask: 0.9413  decode.d6.loss_dice: 0.6265  decode.d7.loss_cls: 0.2588  decode.d7.loss_mask: 0.9261  decode.d7.loss_dice: 0.6199  decode.d8.loss_cls: 0.2286  decode.d8.loss_mask: 0.9434  decode.d8.loss_dice: 0.6320
05/27 03:50:00 - mmengine - INFO - Iter(train) [142200/160000]  base_lr: 1.3857e-05 lr: 1.3857e-06  eta: 2:02:48  time: 0.4183  data_time: 0.0099  memory: 5987  grad_norm: 462.4544  loss: 17.0241  decode.loss_cls: 0.0997  decode.loss_mask: 0.8942  decode.loss_dice: 0.6526  decode.d0.loss_cls: 0.5898  decode.d0.loss_mask: 0.8898  decode.d0.loss_dice: 0.6538  decode.d1.loss_cls: 0.0984  decode.d1.loss_mask: 0.8999  decode.d1.loss_dice: 0.6636  decode.d2.loss_cls: 0.0944  decode.d2.loss_mask: 0.8988  decode.d2.loss_dice: 0.6604  decode.d3.loss_cls: 0.1045  decode.d3.loss_mask: 0.9057  decode.d3.loss_dice: 0.6531  decode.d4.loss_cls: 0.0950  decode.d4.loss_mask: 0.9025  decode.d4.loss_dice: 0.6552  decode.d5.loss_cls: 0.0982  decode.d5.loss_mask: 0.9007  decode.d5.loss_dice: 0.6540  decode.d6.loss_cls: 0.0929  decode.d6.loss_mask: 0.8978  decode.d6.loss_dice: 0.6541  decode.d7.loss_cls: 0.1018  decode.d7.loss_mask: 0.8955  decode.d7.loss_dice: 0.6554  decode.d8.loss_cls: 0.1014  decode.d8.loss_mask: 0.9006  decode.d8.loss_dice: 0.6602
05/27 03:50:21 - mmengine - INFO - Iter(train) [142250/160000]  base_lr: 1.3822e-05 lr: 1.3822e-06  eta: 2:02:27  time: 0.4189  data_time: 0.0101  memory: 5970  grad_norm: 395.9982  loss: 18.2360  decode.loss_cls: 0.1820  decode.loss_mask: 0.9319  decode.loss_dice: 0.6630  decode.d0.loss_cls: 0.6246  decode.d0.loss_mask: 0.9229  decode.d0.loss_dice: 0.6552  decode.d1.loss_cls: 0.1766  decode.d1.loss_mask: 0.9736  decode.d1.loss_dice: 0.6766  decode.d2.loss_cls: 0.1422  decode.d2.loss_mask: 0.9724  decode.d2.loss_dice: 0.6726  decode.d3.loss_cls: 0.1667  decode.d3.loss_mask: 0.9393  decode.d3.loss_dice: 0.6621  decode.d4.loss_cls: 0.1404  decode.d4.loss_mask: 0.9730  decode.d4.loss_dice: 0.6809  decode.d5.loss_cls: 0.1282  decode.d5.loss_mask: 0.9674  decode.d5.loss_dice: 0.6787  decode.d6.loss_cls: 0.1390  decode.d6.loss_mask: 0.9397  decode.d6.loss_dice: 0.6772  decode.d7.loss_cls: 0.1273  decode.d7.loss_mask: 0.9704  decode.d7.loss_dice: 0.6947  decode.d8.loss_cls: 0.1857  decode.d8.loss_mask: 0.9301  decode.d8.loss_dice: 0.6414
05/27 03:50:42 - mmengine - INFO - Iter(train) [142300/160000]  base_lr: 1.3787e-05 lr: 1.3787e-06  eta: 2:02:07  time: 0.4189  data_time: 0.0099  memory: 5974  grad_norm: 722.1222  loss: 20.9389  decode.loss_cls: 0.1869  decode.loss_mask: 1.1431  decode.loss_dice: 0.7373  decode.d0.loss_cls: 0.6487  decode.d0.loss_mask: 1.0936  decode.d0.loss_dice: 0.7181  decode.d1.loss_cls: 0.1883  decode.d1.loss_mask: 1.1441  decode.d1.loss_dice: 0.7272  decode.d2.loss_cls: 0.1647  decode.d2.loss_mask: 1.1568  decode.d2.loss_dice: 0.7231  decode.d3.loss_cls: 0.1725  decode.d3.loss_mask: 1.1267  decode.d3.loss_dice: 0.7029  decode.d4.loss_cls: 0.1806  decode.d4.loss_mask: 1.1282  decode.d4.loss_dice: 0.7233  decode.d5.loss_cls: 0.1979  decode.d5.loss_mask: 1.1274  decode.d5.loss_dice: 0.7317  decode.d6.loss_cls: 0.2246  decode.d6.loss_mask: 1.1291  decode.d6.loss_dice: 0.7378  decode.d7.loss_cls: 0.1872  decode.d7.loss_mask: 1.1427  decode.d7.loss_dice: 0.7276  decode.d8.loss_cls: 0.2052  decode.d8.loss_mask: 1.1252  decode.d8.loss_dice: 0.7363
05/27 03:51:03 - mmengine - INFO - Iter(train) [142350/160000]  base_lr: 1.3752e-05 lr: 1.3752e-06  eta: 2:01:46  time: 0.4189  data_time: 0.0099  memory: 5980  grad_norm: 417.8801  loss: 21.5201  decode.loss_cls: 0.1633  decode.loss_mask: 1.0816  decode.loss_dice: 0.8452  decode.d0.loss_cls: 0.6192  decode.d0.loss_mask: 1.0714  decode.d0.loss_dice: 0.8409  decode.d1.loss_cls: 0.2156  decode.d1.loss_mask: 1.0896  decode.d1.loss_dice: 0.8022  decode.d2.loss_cls: 0.1576  decode.d2.loss_mask: 1.0947  decode.d2.loss_dice: 0.8558  decode.d3.loss_cls: 0.1619  decode.d3.loss_mask: 1.1128  decode.d3.loss_dice: 0.8547  decode.d4.loss_cls: 0.1646  decode.d4.loss_mask: 1.1450  decode.d4.loss_dice: 0.8521  decode.d5.loss_cls: 0.1621  decode.d5.loss_mask: 1.0657  decode.d5.loss_dice: 0.8280  decode.d6.loss_cls: 0.1614  decode.d6.loss_mask: 1.0821  decode.d6.loss_dice: 0.8495  decode.d7.loss_cls: 0.1566  decode.d7.loss_mask: 1.0956  decode.d7.loss_dice: 0.8571  decode.d8.loss_cls: 0.1533  decode.d8.loss_mask: 1.1316  decode.d8.loss_dice: 0.8491
05/27 03:51:24 - mmengine - INFO - Iter(train) [142400/160000]  base_lr: 1.3717e-05 lr: 1.3717e-06  eta: 2:01:25  time: 0.4174  data_time: 0.0100  memory: 5973  grad_norm: 325.7865  loss: 15.3350  decode.loss_cls: 0.1147  decode.loss_mask: 0.8533  decode.loss_dice: 0.5118  decode.d0.loss_cls: 0.5000  decode.d0.loss_mask: 0.8523  decode.d0.loss_dice: 0.5117  decode.d1.loss_cls: 0.0829  decode.d1.loss_mask: 0.9141  decode.d1.loss_dice: 0.5200  decode.d2.loss_cls: 0.1159  decode.d2.loss_mask: 0.8536  decode.d2.loss_dice: 0.5138  decode.d3.loss_cls: 0.0860  decode.d3.loss_mask: 0.9030  decode.d3.loss_dice: 0.5168  decode.d4.loss_cls: 0.0885  decode.d4.loss_mask: 0.9065  decode.d4.loss_dice: 0.5150  decode.d5.loss_cls: 0.1278  decode.d5.loss_mask: 0.8546  decode.d5.loss_dice: 0.5072  decode.d6.loss_cls: 0.0936  decode.d6.loss_mask: 0.9128  decode.d6.loss_dice: 0.5264  decode.d7.loss_cls: 0.1208  decode.d7.loss_mask: 0.8478  decode.d7.loss_dice: 0.5055  decode.d8.loss_cls: 0.1137  decode.d8.loss_mask: 0.8577  decode.d8.loss_dice: 0.5071
05/27 03:51:45 - mmengine - INFO - Iter(train) [142450/160000]  base_lr: 1.3682e-05 lr: 1.3682e-06  eta: 2:01:05  time: 0.4178  data_time: 0.0100  memory: 5968  grad_norm: 418.1879  loss: 20.9015  decode.loss_cls: 0.1772  decode.loss_mask: 1.0436  decode.loss_dice: 0.8019  decode.d0.loss_cls: 0.6880  decode.d0.loss_mask: 1.0428  decode.d0.loss_dice: 0.7830  decode.d1.loss_cls: 0.2063  decode.d1.loss_mask: 1.0655  decode.d1.loss_dice: 0.8047  decode.d2.loss_cls: 0.1613  decode.d2.loss_mask: 1.0687  decode.d2.loss_dice: 0.8172  decode.d3.loss_cls: 0.1817  decode.d3.loss_mask: 1.0427  decode.d3.loss_dice: 0.7898  decode.d4.loss_cls: 0.1964  decode.d4.loss_mask: 1.0498  decode.d4.loss_dice: 0.7885  decode.d5.loss_cls: 0.1946  decode.d5.loss_mask: 1.0560  decode.d5.loss_dice: 0.8051  decode.d6.loss_cls: 0.1599  decode.d6.loss_mask: 1.0620  decode.d6.loss_dice: 0.8291  decode.d7.loss_cls: 0.2092  decode.d7.loss_mask: 1.0485  decode.d7.loss_dice: 0.7925  decode.d8.loss_cls: 0.1880  decode.d8.loss_mask: 1.0445  decode.d8.loss_dice: 0.8031
05/27 03:52:06 - mmengine - INFO - Iter(train) [142500/160000]  base_lr: 1.3647e-05 lr: 1.3647e-06  eta: 2:00:44  time: 0.4177  data_time: 0.0099  memory: 5987  grad_norm: 550.7482  loss: 17.4142  decode.loss_cls: 0.1918  decode.loss_mask: 0.8849  decode.loss_dice: 0.6296  decode.d0.loss_cls: 0.6146  decode.d0.loss_mask: 0.8562  decode.d0.loss_dice: 0.6291  decode.d1.loss_cls: 0.2018  decode.d1.loss_mask: 0.8913  decode.d1.loss_dice: 0.6394  decode.d2.loss_cls: 0.2079  decode.d2.loss_mask: 0.8887  decode.d2.loss_dice: 0.6321  decode.d3.loss_cls: 0.1646  decode.d3.loss_mask: 0.8917  decode.d3.loss_dice: 0.6324  decode.d4.loss_cls: 0.1662  decode.d4.loss_mask: 0.8987  decode.d4.loss_dice: 0.6386  decode.d5.loss_cls: 0.1527  decode.d5.loss_mask: 0.9017  decode.d5.loss_dice: 0.6428  decode.d6.loss_cls: 0.1753  decode.d6.loss_mask: 0.8909  decode.d6.loss_dice: 0.6333  decode.d7.loss_cls: 0.1383  decode.d7.loss_mask: 0.8849  decode.d7.loss_dice: 0.6356  decode.d8.loss_cls: 0.1909  decode.d8.loss_mask: 0.8805  decode.d8.loss_dice: 0.6275
05/27 03:52:26 - mmengine - INFO - Iter(train) [142550/160000]  base_lr: 1.3612e-05 lr: 1.3612e-06  eta: 2:00:23  time: 0.4175  data_time: 0.0100  memory: 5966  grad_norm: 847.2853  loss: 20.6274  decode.loss_cls: 0.2281  decode.loss_mask: 1.0793  decode.loss_dice: 0.6911  decode.d0.loss_cls: 0.7191  decode.d0.loss_mask: 1.0156  decode.d0.loss_dice: 0.6934  decode.d1.loss_cls: 0.2279  decode.d1.loss_mask: 1.0609  decode.d1.loss_dice: 0.6867  decode.d2.loss_cls: 0.1763  decode.d2.loss_mask: 1.1371  decode.d2.loss_dice: 0.7495  decode.d3.loss_cls: 0.2940  decode.d3.loss_mask: 1.0773  decode.d3.loss_dice: 0.6899  decode.d4.loss_cls: 0.2482  decode.d4.loss_mask: 1.0710  decode.d4.loss_dice: 0.6926  decode.d5.loss_cls: 0.2124  decode.d5.loss_mask: 1.0888  decode.d5.loss_dice: 0.7197  decode.d6.loss_cls: 0.3292  decode.d6.loss_mask: 1.0255  decode.d6.loss_dice: 0.6818  decode.d7.loss_cls: 0.2441  decode.d7.loss_mask: 1.0508  decode.d7.loss_dice: 0.7245  decode.d8.loss_cls: 0.2477  decode.d8.loss_mask: 1.0804  decode.d8.loss_dice: 0.6846
05/27 03:52:47 - mmengine - INFO - Iter(train) [142600/160000]  base_lr: 1.3577e-05 lr: 1.3577e-06  eta: 2:00:03  time: 0.4183  data_time: 0.0100  memory: 5966  grad_norm: 287.1449  loss: 17.6506  decode.loss_cls: 0.1255  decode.loss_mask: 0.9068  decode.loss_dice: 0.6759  decode.d0.loss_cls: 0.5543  decode.d0.loss_mask: 0.8640  decode.d0.loss_dice: 0.6632  decode.d1.loss_cls: 0.1131  decode.d1.loss_mask: 0.9186  decode.d1.loss_dice: 0.6993  decode.d2.loss_cls: 0.1618  decode.d2.loss_mask: 0.9052  decode.d2.loss_dice: 0.6850  decode.d3.loss_cls: 0.1419  decode.d3.loss_mask: 0.9111  decode.d3.loss_dice: 0.6820  decode.d4.loss_cls: 0.1042  decode.d4.loss_mask: 0.9144  decode.d4.loss_dice: 0.6887  decode.d5.loss_cls: 0.1162  decode.d5.loss_mask: 0.9083  decode.d5.loss_dice: 0.6886  decode.d6.loss_cls: 0.1466  decode.d6.loss_mask: 0.9158  decode.d6.loss_dice: 0.6819  decode.d7.loss_cls: 0.1635  decode.d7.loss_mask: 0.8985  decode.d7.loss_dice: 0.6810  decode.d8.loss_cls: 0.1490  decode.d8.loss_mask: 0.9067  decode.d8.loss_dice: 0.6796
05/27 03:53:08 - mmengine - INFO - Iter(train) [142650/160000]  base_lr: 1.3541e-05 lr: 1.3541e-06  eta: 1:59:42  time: 0.4187  data_time: 0.0100  memory: 5971  grad_norm: 430.6113  loss: 18.7301  decode.loss_cls: 0.1365  decode.loss_mask: 0.9749  decode.loss_dice: 0.7096  decode.d0.loss_cls: 0.5759  decode.d0.loss_mask: 0.9110  decode.d0.loss_dice: 0.6705  decode.d1.loss_cls: 0.1530  decode.d1.loss_mask: 0.9721  decode.d1.loss_dice: 0.7036  decode.d2.loss_cls: 0.1284  decode.d2.loss_mask: 0.9940  decode.d2.loss_dice: 0.7168  decode.d3.loss_cls: 0.1294  decode.d3.loss_mask: 0.9784  decode.d3.loss_dice: 0.7233  decode.d4.loss_cls: 0.1370  decode.d4.loss_mask: 0.9863  decode.d4.loss_dice: 0.7208  decode.d5.loss_cls: 0.1468  decode.d5.loss_mask: 1.0071  decode.d5.loss_dice: 0.7313  decode.d6.loss_cls: 0.1342  decode.d6.loss_mask: 0.9784  decode.d6.loss_dice: 0.7100  decode.d7.loss_cls: 0.1566  decode.d7.loss_mask: 0.9901  decode.d7.loss_dice: 0.7242  decode.d8.loss_cls: 0.1377  decode.d8.loss_mask: 0.9799  decode.d8.loss_dice: 0.7122
05/27 03:53:29 - mmengine - INFO - Iter(train) [142700/160000]  base_lr: 1.3506e-05 lr: 1.3506e-06  eta: 1:59:21  time: 0.4189  data_time: 0.0100  memory: 5965  grad_norm: 378.8481  loss: 14.5019  decode.loss_cls: 0.0974  decode.loss_mask: 0.7688  decode.loss_dice: 0.5131  decode.d0.loss_cls: 0.6848  decode.d0.loss_mask: 0.7143  decode.d0.loss_dice: 0.4975  decode.d1.loss_cls: 0.1572  decode.d1.loss_mask: 0.7692  decode.d1.loss_dice: 0.5304  decode.d2.loss_cls: 0.1097  decode.d2.loss_mask: 0.8042  decode.d2.loss_dice: 0.5453  decode.d3.loss_cls: 0.1249  decode.d3.loss_mask: 0.7651  decode.d3.loss_dice: 0.5041  decode.d4.loss_cls: 0.1104  decode.d4.loss_mask: 0.7601  decode.d4.loss_dice: 0.5051  decode.d5.loss_cls: 0.1226  decode.d5.loss_mask: 0.7658  decode.d5.loss_dice: 0.5125  decode.d6.loss_cls: 0.0885  decode.d6.loss_mask: 0.7724  decode.d6.loss_dice: 0.5192  decode.d7.loss_cls: 0.1286  decode.d7.loss_mask: 0.7659  decode.d7.loss_dice: 0.5006  decode.d8.loss_cls: 0.1163  decode.d8.loss_mask: 0.7615  decode.d8.loss_dice: 0.4862
05/27 03:53:50 - mmengine - INFO - Iter(train) [142750/160000]  base_lr: 1.3471e-05 lr: 1.3471e-06  eta: 1:59:01  time: 0.4185  data_time: 0.0100  memory: 5971  grad_norm: 571.2903  loss: 18.1268  decode.loss_cls: 0.1584  decode.loss_mask: 0.9425  decode.loss_dice: 0.6348  decode.d0.loss_cls: 0.6730  decode.d0.loss_mask: 0.9070  decode.d0.loss_dice: 0.6115  decode.d1.loss_cls: 0.1969  decode.d1.loss_mask: 0.9519  decode.d1.loss_dice: 0.6399  decode.d2.loss_cls: 0.1908  decode.d2.loss_mask: 0.9628  decode.d2.loss_dice: 0.6432  decode.d3.loss_cls: 0.1451  decode.d3.loss_mask: 0.9622  decode.d3.loss_dice: 0.6426  decode.d4.loss_cls: 0.1773  decode.d4.loss_mask: 0.9593  decode.d4.loss_dice: 0.6456  decode.d5.loss_cls: 0.1858  decode.d5.loss_mask: 0.9558  decode.d5.loss_dice: 0.6452  decode.d6.loss_cls: 0.1837  decode.d6.loss_mask: 0.9471  decode.d6.loss_dice: 0.6592  decode.d7.loss_cls: 0.1957  decode.d7.loss_mask: 0.9364  decode.d7.loss_dice: 0.6282  decode.d8.loss_cls: 0.1638  decode.d8.loss_mask: 0.9403  decode.d8.loss_dice: 0.6407
05/27 03:54:11 - mmengine - INFO - Iter(train) [142800/160000]  base_lr: 1.3436e-05 lr: 1.3436e-06  eta: 1:58:40  time: 0.4175  data_time: 0.0099  memory: 5965  grad_norm: 601.1392  loss: 17.6481  decode.loss_cls: 0.1504  decode.loss_mask: 0.8925  decode.loss_dice: 0.6495  decode.d0.loss_cls: 0.6766  decode.d0.loss_mask: 0.8825  decode.d0.loss_dice: 0.6377  decode.d1.loss_cls: 0.2081  decode.d1.loss_mask: 0.8939  decode.d1.loss_dice: 0.6478  decode.d2.loss_cls: 0.2004  decode.d2.loss_mask: 0.9044  decode.d2.loss_dice: 0.6493  decode.d3.loss_cls: 0.1880  decode.d3.loss_mask: 0.9014  decode.d3.loss_dice: 0.6312  decode.d4.loss_cls: 0.1677  decode.d4.loss_mask: 0.8889  decode.d4.loss_dice: 0.6689  decode.d5.loss_cls: 0.1633  decode.d5.loss_mask: 0.9015  decode.d5.loss_dice: 0.6647  decode.d6.loss_cls: 0.1699  decode.d6.loss_mask: 0.8876  decode.d6.loss_dice: 0.6375  decode.d7.loss_cls: 0.1716  decode.d7.loss_mask: 0.8875  decode.d7.loss_dice: 0.6342  decode.d8.loss_cls: 0.1567  decode.d8.loss_mask: 0.8939  decode.d8.loss_dice: 0.6405
05/27 03:54:32 - mmengine - INFO - Iter(train) [142850/160000]  base_lr: 1.3401e-05 lr: 1.3401e-06  eta: 1:58:19  time: 0.4188  data_time: 0.0101  memory: 5965  grad_norm: 577.8327  loss: 19.5173  decode.loss_cls: 0.1307  decode.loss_mask: 0.9931  decode.loss_dice: 0.7405  decode.d0.loss_cls: 0.6958  decode.d0.loss_mask: 1.0045  decode.d0.loss_dice: 0.7800  decode.d1.loss_cls: 0.2039  decode.d1.loss_mask: 0.9903  decode.d1.loss_dice: 0.7260  decode.d2.loss_cls: 0.1529  decode.d2.loss_mask: 0.9971  decode.d2.loss_dice: 0.7500  decode.d3.loss_cls: 0.1589  decode.d3.loss_mask: 0.9768  decode.d3.loss_dice: 0.7374  decode.d4.loss_cls: 0.1465  decode.d4.loss_mask: 0.9972  decode.d4.loss_dice: 0.7528  decode.d5.loss_cls: 0.1791  decode.d5.loss_mask: 0.9738  decode.d5.loss_dice: 0.7339  decode.d6.loss_cls: 0.1376  decode.d6.loss_mask: 1.0394  decode.d6.loss_dice: 0.7621  decode.d7.loss_cls: 0.1592  decode.d7.loss_mask: 0.9960  decode.d7.loss_dice: 0.7404  decode.d8.loss_cls: 0.1547  decode.d8.loss_mask: 0.9797  decode.d8.loss_dice: 0.7270
05/27 03:54:53 - mmengine - INFO - Iter(train) [142900/160000]  base_lr: 1.3366e-05 lr: 1.3366e-06  eta: 1:57:59  time: 0.4174  data_time: 0.0099  memory: 5968  grad_norm: 374.4168  loss: 19.3771  decode.loss_cls: 0.1343  decode.loss_mask: 0.9934  decode.loss_dice: 0.6918  decode.d0.loss_cls: 0.6121  decode.d0.loss_mask: 0.9934  decode.d0.loss_dice: 0.7215  decode.d1.loss_cls: 0.1693  decode.d1.loss_mask: 1.0202  decode.d1.loss_dice: 0.7080  decode.d2.loss_cls: 0.1816  decode.d2.loss_mask: 1.0303  decode.d2.loss_dice: 0.7076  decode.d3.loss_cls: 0.1864  decode.d3.loss_mask: 1.0260  decode.d3.loss_dice: 0.7060  decode.d4.loss_cls: 0.2071  decode.d4.loss_mask: 1.0191  decode.d4.loss_dice: 0.7062  decode.d5.loss_cls: 0.1789  decode.d5.loss_mask: 1.0097  decode.d5.loss_dice: 0.7032  decode.d6.loss_cls: 0.1960  decode.d6.loss_mask: 1.0133  decode.d6.loss_dice: 0.7042  decode.d7.loss_cls: 0.1647  decode.d7.loss_mask: 1.0078  decode.d7.loss_dice: 0.7083  decode.d8.loss_cls: 0.1771  decode.d8.loss_mask: 1.0062  decode.d8.loss_dice: 0.6935
05/27 03:55:14 - mmengine - INFO - Iter(train) [142950/160000]  base_lr: 1.3330e-05 lr: 1.3330e-06  eta: 1:57:38  time: 0.4169  data_time: 0.0099  memory: 5967  grad_norm: 465.1646  loss: 15.5597  decode.loss_cls: 0.1214  decode.loss_mask: 0.8080  decode.loss_dice: 0.5764  decode.d0.loss_cls: 0.5751  decode.d0.loss_mask: 0.8055  decode.d0.loss_dice: 0.5657  decode.d1.loss_cls: 0.1394  decode.d1.loss_mask: 0.8148  decode.d1.loss_dice: 0.5760  decode.d2.loss_cls: 0.1265  decode.d2.loss_mask: 0.8102  decode.d2.loss_dice: 0.5878  decode.d3.loss_cls: 0.1214  decode.d3.loss_mask: 0.8094  decode.d3.loss_dice: 0.5770  decode.d4.loss_cls: 0.1187  decode.d4.loss_mask: 0.8083  decode.d4.loss_dice: 0.5810  decode.d5.loss_cls: 0.1096  decode.d5.loss_mask: 0.8071  decode.d5.loss_dice: 0.5768  decode.d6.loss_cls: 0.1225  decode.d6.loss_mask: 0.8158  decode.d6.loss_dice: 0.5845  decode.d7.loss_cls: 0.1280  decode.d7.loss_mask: 0.8082  decode.d7.loss_dice: 0.5804  decode.d8.loss_cls: 0.1230  decode.d8.loss_mask: 0.8080  decode.d8.loss_dice: 0.5731
05/27 03:55:35 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 03:55:35 - mmengine - INFO - Iter(train) [143000/160000]  base_lr: 1.3295e-05 lr: 1.3295e-06  eta: 1:57:17  time: 0.4179  data_time: 0.0099  memory: 5968  grad_norm: 416.1596  loss: 18.1438  decode.loss_cls: 0.1956  decode.loss_mask: 0.8702  decode.loss_dice: 0.6788  decode.d0.loss_cls: 0.7391  decode.d0.loss_mask: 0.8501  decode.d0.loss_dice: 0.6625  decode.d1.loss_cls: 0.1834  decode.d1.loss_mask: 0.8840  decode.d1.loss_dice: 0.7035  decode.d2.loss_cls: 0.2016  decode.d2.loss_mask: 0.8896  decode.d2.loss_dice: 0.6789  decode.d3.loss_cls: 0.2096  decode.d3.loss_mask: 0.8769  decode.d3.loss_dice: 0.6651  decode.d4.loss_cls: 0.2062  decode.d4.loss_mask: 0.8758  decode.d4.loss_dice: 0.6804  decode.d5.loss_cls: 0.1837  decode.d5.loss_mask: 0.8905  decode.d5.loss_dice: 0.7081  decode.d6.loss_cls: 0.1928  decode.d6.loss_mask: 0.8815  decode.d6.loss_dice: 0.6760  decode.d7.loss_cls: 0.2264  decode.d7.loss_mask: 0.8740  decode.d7.loss_dice: 0.6881  decode.d8.loss_cls: 0.1811  decode.d8.loss_mask: 0.8825  decode.d8.loss_dice: 0.7079
05/27 03:55:56 - mmengine - INFO - Iter(train) [143050/160000]  base_lr: 1.3260e-05 lr: 1.3260e-06  eta: 1:56:57  time: 0.4188  data_time: 0.0100  memory: 5985  grad_norm: 597.1429  loss: 21.7500  decode.loss_cls: 0.2424  decode.loss_mask: 1.1259  decode.loss_dice: 0.7644  decode.d0.loss_cls: 0.7482  decode.d0.loss_mask: 1.1063  decode.d0.loss_dice: 0.7591  decode.d1.loss_cls: 0.2679  decode.d1.loss_mask: 1.1079  decode.d1.loss_dice: 0.7676  decode.d2.loss_cls: 0.2298  decode.d2.loss_mask: 1.1423  decode.d2.loss_dice: 0.7641  decode.d3.loss_cls: 0.2003  decode.d3.loss_mask: 1.1726  decode.d3.loss_dice: 0.7905  decode.d4.loss_cls: 0.1952  decode.d4.loss_mask: 1.1302  decode.d4.loss_dice: 0.7727  decode.d5.loss_cls: 0.2266  decode.d5.loss_mask: 1.1073  decode.d5.loss_dice: 0.7617  decode.d6.loss_cls: 0.2176  decode.d6.loss_mask: 1.1129  decode.d6.loss_dice: 0.7613  decode.d7.loss_cls: 0.2607  decode.d7.loss_mask: 1.1227  decode.d7.loss_dice: 0.7740  decode.d8.loss_cls: 0.2407  decode.d8.loss_mask: 1.1139  decode.d8.loss_dice: 0.7628
05/27 03:56:17 - mmengine - INFO - Iter(train) [143100/160000]  base_lr: 1.3225e-05 lr: 1.3225e-06  eta: 1:56:36  time: 0.4184  data_time: 0.0099  memory: 5966  grad_norm: 634.5760  loss: 20.1289  decode.loss_cls: 0.1837  decode.loss_mask: 1.0707  decode.loss_dice: 0.6998  decode.d0.loss_cls: 0.7729  decode.d0.loss_mask: 1.0040  decode.d0.loss_dice: 0.6918  decode.d1.loss_cls: 0.1984  decode.d1.loss_mask: 1.0695  decode.d1.loss_dice: 0.6864  decode.d2.loss_cls: 0.2013  decode.d2.loss_mask: 1.0749  decode.d2.loss_dice: 0.6976  decode.d3.loss_cls: 0.1966  decode.d3.loss_mask: 1.0771  decode.d3.loss_dice: 0.7172  decode.d4.loss_cls: 0.2080  decode.d4.loss_mask: 1.0617  decode.d4.loss_dice: 0.7083  decode.d5.loss_cls: 0.1727  decode.d5.loss_mask: 1.0565  decode.d5.loss_dice: 0.7252  decode.d6.loss_cls: 0.1781  decode.d6.loss_mask: 1.0527  decode.d6.loss_dice: 0.7250  decode.d7.loss_cls: 0.2074  decode.d7.loss_mask: 1.0535  decode.d7.loss_dice: 0.6972  decode.d8.loss_cls: 0.1887  decode.d8.loss_mask: 1.0667  decode.d8.loss_dice: 0.6853
05/27 03:56:38 - mmengine - INFO - Iter(train) [143150/160000]  base_lr: 1.3190e-05 lr: 1.3190e-06  eta: 1:56:15  time: 0.4175  data_time: 0.0099  memory: 5974  grad_norm: 551.5847  loss: 18.1379  decode.loss_cls: 0.1202  decode.loss_mask: 0.9199  decode.loss_dice: 0.6988  decode.d0.loss_cls: 0.6899  decode.d0.loss_mask: 0.8876  decode.d0.loss_dice: 0.6760  decode.d1.loss_cls: 0.1718  decode.d1.loss_mask: 0.9750  decode.d1.loss_dice: 0.7105  decode.d2.loss_cls: 0.1563  decode.d2.loss_mask: 0.9215  decode.d2.loss_dice: 0.6554  decode.d3.loss_cls: 0.1590  decode.d3.loss_mask: 0.9216  decode.d3.loss_dice: 0.6885  decode.d4.loss_cls: 0.1572  decode.d4.loss_mask: 0.9329  decode.d4.loss_dice: 0.6817  decode.d5.loss_cls: 0.1637  decode.d5.loss_mask: 0.9202  decode.d5.loss_dice: 0.6890  decode.d6.loss_cls: 0.1466  decode.d6.loss_mask: 0.9259  decode.d6.loss_dice: 0.6578  decode.d7.loss_cls: 0.1503  decode.d7.loss_mask: 0.9197  decode.d7.loss_dice: 0.6756  decode.d8.loss_cls: 0.1418  decode.d8.loss_mask: 0.9260  decode.d8.loss_dice: 0.6974
05/27 03:56:59 - mmengine - INFO - Iter(train) [143200/160000]  base_lr: 1.3154e-05 lr: 1.3154e-06  eta: 1:55:55  time: 0.4175  data_time: 0.0099  memory: 5968  grad_norm: 387.9238  loss: 19.4584  decode.loss_cls: 0.3091  decode.loss_mask: 0.8960  decode.loss_dice: 0.6449  decode.d0.loss_cls: 0.7977  decode.d0.loss_mask: 0.8517  decode.d0.loss_dice: 0.6661  decode.d1.loss_cls: 0.3477  decode.d1.loss_mask: 0.8638  decode.d1.loss_dice: 0.6947  decode.d2.loss_cls: 0.3165  decode.d2.loss_mask: 0.9241  decode.d2.loss_dice: 0.6722  decode.d3.loss_cls: 0.2703  decode.d3.loss_mask: 0.9413  decode.d3.loss_dice: 0.6751  decode.d4.loss_cls: 0.3428  decode.d4.loss_mask: 0.9348  decode.d4.loss_dice: 0.6398  decode.d5.loss_cls: 0.3665  decode.d5.loss_mask: 0.9552  decode.d5.loss_dice: 0.6876  decode.d6.loss_cls: 0.3348  decode.d6.loss_mask: 0.9581  decode.d6.loss_dice: 0.6613  decode.d7.loss_cls: 0.3406  decode.d7.loss_mask: 0.8903  decode.d7.loss_dice: 0.6607  decode.d8.loss_cls: 0.3170  decode.d8.loss_mask: 0.8665  decode.d8.loss_dice: 0.6312
05/27 03:57:20 - mmengine - INFO - Iter(train) [143250/160000]  base_lr: 1.3119e-05 lr: 1.3119e-06  eta: 1:55:34  time: 0.4189  data_time: 0.0100  memory: 5967  grad_norm: 746.4154  loss: 16.9136  decode.loss_cls: 0.1321  decode.loss_mask: 0.9041  decode.loss_dice: 0.6086  decode.d0.loss_cls: 0.5769  decode.d0.loss_mask: 0.9036  decode.d0.loss_dice: 0.6219  decode.d1.loss_cls: 0.1529  decode.d1.loss_mask: 0.8758  decode.d1.loss_dice: 0.6146  decode.d2.loss_cls: 0.1278  decode.d2.loss_mask: 0.9047  decode.d2.loss_dice: 0.6130  decode.d3.loss_cls: 0.1387  decode.d3.loss_mask: 0.9111  decode.d3.loss_dice: 0.6223  decode.d4.loss_cls: 0.1491  decode.d4.loss_mask: 0.8963  decode.d4.loss_dice: 0.5963  decode.d5.loss_cls: 0.1430  decode.d5.loss_mask: 0.8974  decode.d5.loss_dice: 0.6088  decode.d6.loss_cls: 0.1517  decode.d6.loss_mask: 0.8959  decode.d6.loss_dice: 0.6021  decode.d7.loss_cls: 0.1304  decode.d7.loss_mask: 0.8982  decode.d7.loss_dice: 0.6064  decode.d8.loss_cls: 0.1304  decode.d8.loss_mask: 0.8967  decode.d8.loss_dice: 0.6025
05/27 03:57:40 - mmengine - INFO - Iter(train) [143300/160000]  base_lr: 1.3084e-05 lr: 1.3084e-06  eta: 1:55:13  time: 0.4186  data_time: 0.0100  memory: 5974  grad_norm: 393.6581  loss: 19.5413  decode.loss_cls: 0.1094  decode.loss_mask: 1.1665  decode.loss_dice: 0.6432  decode.d0.loss_cls: 0.5689  decode.d0.loss_mask: 1.0326  decode.d0.loss_dice: 0.6147  decode.d1.loss_cls: 0.1238  decode.d1.loss_mask: 1.1523  decode.d1.loss_dice: 0.6534  decode.d2.loss_cls: 0.1157  decode.d2.loss_mask: 1.1497  decode.d2.loss_dice: 0.6426  decode.d3.loss_cls: 0.0955  decode.d3.loss_mask: 1.1600  decode.d3.loss_dice: 0.6490  decode.d4.loss_cls: 0.1437  decode.d4.loss_mask: 1.1372  decode.d4.loss_dice: 0.6449  decode.d5.loss_cls: 0.1289  decode.d5.loss_mask: 1.1601  decode.d5.loss_dice: 0.6457  decode.d6.loss_cls: 0.1269  decode.d6.loss_mask: 1.1689  decode.d6.loss_dice: 0.6405  decode.d7.loss_cls: 0.1249  decode.d7.loss_mask: 1.1569  decode.d7.loss_dice: 0.6376  decode.d8.loss_cls: 0.1380  decode.d8.loss_mask: 1.1614  decode.d8.loss_dice: 0.6484
05/27 03:58:01 - mmengine - INFO - Iter(train) [143350/160000]  base_lr: 1.3049e-05 lr: 1.3049e-06  eta: 1:54:53  time: 0.4182  data_time: 0.0099  memory: 5966  grad_norm: 481.7160  loss: 17.2938  decode.loss_cls: 0.1856  decode.loss_mask: 0.8124  decode.loss_dice: 0.6598  decode.d0.loss_cls: 0.6601  decode.d0.loss_mask: 0.8117  decode.d0.loss_dice: 0.6738  decode.d1.loss_cls: 0.1866  decode.d1.loss_mask: 0.8341  decode.d1.loss_dice: 0.6831  decode.d2.loss_cls: 0.1589  decode.d2.loss_mask: 0.8352  decode.d2.loss_dice: 0.6874  decode.d3.loss_cls: 0.1944  decode.d3.loss_mask: 0.8222  decode.d3.loss_dice: 0.6652  decode.d4.loss_cls: 0.1877  decode.d4.loss_mask: 0.8237  decode.d4.loss_dice: 0.6730  decode.d5.loss_cls: 0.1930  decode.d5.loss_mask: 0.8310  decode.d5.loss_dice: 0.6568  decode.d6.loss_cls: 0.1644  decode.d6.loss_mask: 0.8344  decode.d6.loss_dice: 0.6897  decode.d7.loss_cls: 0.1897  decode.d7.loss_mask: 0.8253  decode.d7.loss_dice: 0.6706  decode.d8.loss_cls: 0.1854  decode.d8.loss_mask: 0.8133  decode.d8.loss_dice: 0.6853
05/27 03:58:22 - mmengine - INFO - Iter(train) [143400/160000]  base_lr: 1.3013e-05 lr: 1.3013e-06  eta: 1:54:32  time: 0.4174  data_time: 0.0099  memory: 5969  grad_norm: 562.0720  loss: 18.0786  decode.loss_cls: 0.1203  decode.loss_mask: 0.9504  decode.loss_dice: 0.6847  decode.d0.loss_cls: 0.6207  decode.d0.loss_mask: 0.9625  decode.d0.loss_dice: 0.6587  decode.d1.loss_cls: 0.1309  decode.d1.loss_mask: 0.9520  decode.d1.loss_dice: 0.6774  decode.d2.loss_cls: 0.1106  decode.d2.loss_mask: 0.9679  decode.d2.loss_dice: 0.6782  decode.d3.loss_cls: 0.1295  decode.d3.loss_mask: 0.9415  decode.d3.loss_dice: 0.6628  decode.d4.loss_cls: 0.1398  decode.d4.loss_mask: 0.9623  decode.d4.loss_dice: 0.6835  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.9738  decode.d5.loss_dice: 0.6875  decode.d6.loss_cls: 0.1087  decode.d6.loss_mask: 0.9632  decode.d6.loss_dice: 0.6815  decode.d7.loss_cls: 0.1499  decode.d7.loss_mask: 0.9479  decode.d7.loss_dice: 0.6752  decode.d8.loss_cls: 0.1148  decode.d8.loss_mask: 0.9571  decode.d8.loss_dice: 0.6756
05/27 03:58:43 - mmengine - INFO - Iter(train) [143450/160000]  base_lr: 1.2978e-05 lr: 1.2978e-06  eta: 1:54:11  time: 0.4184  data_time: 0.0100  memory: 5973  grad_norm: 864.3070  loss: 19.4807  decode.loss_cls: 0.1901  decode.loss_mask: 1.0402  decode.loss_dice: 0.6729  decode.d0.loss_cls: 0.6371  decode.d0.loss_mask: 1.0568  decode.d0.loss_dice: 0.6855  decode.d1.loss_cls: 0.1758  decode.d1.loss_mask: 1.0417  decode.d1.loss_dice: 0.6774  decode.d2.loss_cls: 0.1358  decode.d2.loss_mask: 1.0636  decode.d2.loss_dice: 0.6842  decode.d3.loss_cls: 0.1995  decode.d3.loss_mask: 1.0251  decode.d3.loss_dice: 0.6721  decode.d4.loss_cls: 0.1538  decode.d4.loss_mask: 1.0580  decode.d4.loss_dice: 0.6869  decode.d5.loss_cls: 0.1790  decode.d5.loss_mask: 1.0677  decode.d5.loss_dice: 0.6962  decode.d6.loss_cls: 0.1695  decode.d6.loss_mask: 1.0443  decode.d6.loss_dice: 0.6855  decode.d7.loss_cls: 0.1456  decode.d7.loss_mask: 1.0623  decode.d7.loss_dice: 0.6951  decode.d8.loss_cls: 0.1518  decode.d8.loss_mask: 1.0470  decode.d8.loss_dice: 0.6806
05/27 03:59:04 - mmengine - INFO - Iter(train) [143500/160000]  base_lr: 1.2943e-05 lr: 1.2943e-06  eta: 1:53:51  time: 0.4178  data_time: 0.0099  memory: 5969  grad_norm: 582.1456  loss: 16.5373  decode.loss_cls: 0.1306  decode.loss_mask: 0.8587  decode.loss_dice: 0.6444  decode.d0.loss_cls: 0.6099  decode.d0.loss_mask: 0.8554  decode.d0.loss_dice: 0.6068  decode.d1.loss_cls: 0.1313  decode.d1.loss_mask: 0.8659  decode.d1.loss_dice: 0.6365  decode.d2.loss_cls: 0.1413  decode.d2.loss_mask: 0.8479  decode.d2.loss_dice: 0.6167  decode.d3.loss_cls: 0.1258  decode.d3.loss_mask: 0.8447  decode.d3.loss_dice: 0.6174  decode.d4.loss_cls: 0.1662  decode.d4.loss_mask: 0.8398  decode.d4.loss_dice: 0.6173  decode.d5.loss_cls: 0.1532  decode.d5.loss_mask: 0.8396  decode.d5.loss_dice: 0.6215  decode.d6.loss_cls: 0.1297  decode.d6.loss_mask: 0.8408  decode.d6.loss_dice: 0.6224  decode.d7.loss_cls: 0.1532  decode.d7.loss_mask: 0.8313  decode.d7.loss_dice: 0.6061  decode.d8.loss_cls: 0.1495  decode.d8.loss_mask: 0.8270  decode.d8.loss_dice: 0.6065
05/27 03:59:25 - mmengine - INFO - Iter(train) [143550/160000]  base_lr: 1.2908e-05 lr: 1.2908e-06  eta: 1:53:30  time: 0.4176  data_time: 0.0099  memory: 5966  grad_norm: 319.5643  loss: 14.7010  decode.loss_cls: 0.1441  decode.loss_mask: 0.6826  decode.loss_dice: 0.5755  decode.d0.loss_cls: 0.6742  decode.d0.loss_mask: 0.6394  decode.d0.loss_dice: 0.6012  decode.d1.loss_cls: 0.1691  decode.d1.loss_mask: 0.6635  decode.d1.loss_dice: 0.5859  decode.d2.loss_cls: 0.1631  decode.d2.loss_mask: 0.6916  decode.d2.loss_dice: 0.5817  decode.d3.loss_cls: 0.1423  decode.d3.loss_mask: 0.7029  decode.d3.loss_dice: 0.6042  decode.d4.loss_cls: 0.1375  decode.d4.loss_mask: 0.6839  decode.d4.loss_dice: 0.5961  decode.d5.loss_cls: 0.1379  decode.d5.loss_mask: 0.6815  decode.d5.loss_dice: 0.5828  decode.d6.loss_cls: 0.1658  decode.d6.loss_mask: 0.6715  decode.d6.loss_dice: 0.5842  decode.d7.loss_cls: 0.1468  decode.d7.loss_mask: 0.6966  decode.d7.loss_dice: 0.5879  decode.d8.loss_cls: 0.1688  decode.d8.loss_mask: 0.6496  decode.d8.loss_dice: 0.5886
05/27 03:59:46 - mmengine - INFO - Iter(train) [143600/160000]  base_lr: 1.2872e-05 lr: 1.2872e-06  eta: 1:53:09  time: 0.4174  data_time: 0.0099  memory: 5974  grad_norm: 293.4521  loss: 13.7757  decode.loss_cls: 0.1035  decode.loss_mask: 0.6976  decode.loss_dice: 0.5400  decode.d0.loss_cls: 0.5277  decode.d0.loss_mask: 0.6990  decode.d0.loss_dice: 0.5391  decode.d1.loss_cls: 0.0546  decode.d1.loss_mask: 0.7084  decode.d1.loss_dice: 0.5897  decode.d2.loss_cls: 0.0796  decode.d2.loss_mask: 0.7024  decode.d2.loss_dice: 0.5577  decode.d3.loss_cls: 0.0777  decode.d3.loss_mask: 0.6994  decode.d3.loss_dice: 0.5579  decode.d4.loss_cls: 0.0709  decode.d4.loss_mask: 0.6917  decode.d4.loss_dice: 0.5521  decode.d5.loss_cls: 0.0733  decode.d5.loss_mask: 0.6985  decode.d5.loss_dice: 0.5594  decode.d6.loss_cls: 0.0758  decode.d6.loss_mask: 0.6954  decode.d6.loss_dice: 0.5595  decode.d7.loss_cls: 0.0819  decode.d7.loss_mask: 0.6942  decode.d7.loss_dice: 0.5533  decode.d8.loss_cls: 0.0792  decode.d8.loss_mask: 0.6976  decode.d8.loss_dice: 0.5586
05/27 04:00:07 - mmengine - INFO - Iter(train) [143650/160000]  base_lr: 1.2837e-05 lr: 1.2837e-06  eta: 1:52:48  time: 0.4186  data_time: 0.0100  memory: 5970  grad_norm: 465.7471  loss: 16.6688  decode.loss_cls: 0.2052  decode.loss_mask: 0.7831  decode.loss_dice: 0.5789  decode.d0.loss_cls: 0.7306  decode.d0.loss_mask: 0.7559  decode.d0.loss_dice: 0.6111  decode.d1.loss_cls: 0.1837  decode.d1.loss_mask: 0.8320  decode.d1.loss_dice: 0.6272  decode.d2.loss_cls: 0.1991  decode.d2.loss_mask: 0.7966  decode.d2.loss_dice: 0.5919  decode.d3.loss_cls: 0.2116  decode.d3.loss_mask: 0.8289  decode.d3.loss_dice: 0.6445  decode.d4.loss_cls: 0.2130  decode.d4.loss_mask: 0.8167  decode.d4.loss_dice: 0.6072  decode.d5.loss_cls: 0.1918  decode.d5.loss_mask: 0.8041  decode.d5.loss_dice: 0.6109  decode.d6.loss_cls: 0.1884  decode.d6.loss_mask: 0.8152  decode.d6.loss_dice: 0.6029  decode.d7.loss_cls: 0.2204  decode.d7.loss_mask: 0.8138  decode.d7.loss_dice: 0.6150  decode.d8.loss_cls: 0.1831  decode.d8.loss_mask: 0.7928  decode.d8.loss_dice: 0.6135
05/27 04:00:28 - mmengine - INFO - Iter(train) [143700/160000]  base_lr: 1.2802e-05 lr: 1.2802e-06  eta: 1:52:28  time: 0.4188  data_time: 0.0099  memory: 5975  grad_norm: 599.9606  loss: 19.0677  decode.loss_cls: 0.1749  decode.loss_mask: 0.9814  decode.loss_dice: 0.6620  decode.d0.loss_cls: 0.6193  decode.d0.loss_mask: 0.9870  decode.d0.loss_dice: 0.6605  decode.d1.loss_cls: 0.1957  decode.d1.loss_mask: 1.0054  decode.d1.loss_dice: 0.6932  decode.d2.loss_cls: 0.2010  decode.d2.loss_mask: 0.9868  decode.d2.loss_dice: 0.6596  decode.d3.loss_cls: 0.1879  decode.d3.loss_mask: 1.0093  decode.d3.loss_dice: 0.6870  decode.d4.loss_cls: 0.1798  decode.d4.loss_mask: 1.0041  decode.d4.loss_dice: 0.6857  decode.d5.loss_cls: 0.1818  decode.d5.loss_mask: 1.0089  decode.d5.loss_dice: 0.6844  decode.d6.loss_cls: 0.1879  decode.d6.loss_mask: 1.0002  decode.d6.loss_dice: 0.6808  decode.d7.loss_cls: 0.1715  decode.d7.loss_mask: 1.0037  decode.d7.loss_dice: 0.7201  decode.d8.loss_cls: 0.1903  decode.d8.loss_mask: 0.9839  decode.d8.loss_dice: 0.6736
05/27 04:00:49 - mmengine - INFO - Iter(train) [143750/160000]  base_lr: 1.2766e-05 lr: 1.2766e-06  eta: 1:52:07  time: 0.4186  data_time: 0.0100  memory: 5966  grad_norm: 373.4188  loss: 16.5421  decode.loss_cls: 0.2033  decode.loss_mask: 0.7929  decode.loss_dice: 0.6243  decode.d0.loss_cls: 0.6110  decode.d0.loss_mask: 0.7689  decode.d0.loss_dice: 0.6294  decode.d1.loss_cls: 0.2131  decode.d1.loss_mask: 0.7997  decode.d1.loss_dice: 0.6301  decode.d2.loss_cls: 0.1993  decode.d2.loss_mask: 0.7980  decode.d2.loss_dice: 0.6350  decode.d3.loss_cls: 0.1820  decode.d3.loss_mask: 0.7994  decode.d3.loss_dice: 0.6182  decode.d4.loss_cls: 0.1879  decode.d4.loss_mask: 0.7931  decode.d4.loss_dice: 0.6190  decode.d5.loss_cls: 0.1943  decode.d5.loss_mask: 0.7691  decode.d5.loss_dice: 0.6132  decode.d6.loss_cls: 0.1998  decode.d6.loss_mask: 0.7894  decode.d6.loss_dice: 0.6310  decode.d7.loss_cls: 0.2063  decode.d7.loss_mask: 0.7985  decode.d7.loss_dice: 0.6368  decode.d8.loss_cls: 0.2052  decode.d8.loss_mask: 0.7831  decode.d8.loss_dice: 0.6108
05/27 04:01:10 - mmengine - INFO - Iter(train) [143800/160000]  base_lr: 1.2731e-05 lr: 1.2731e-06  eta: 1:51:46  time: 0.4184  data_time: 0.0099  memory: 5980  grad_norm: 636.6711  loss: 17.9479  decode.loss_cls: 0.2419  decode.loss_mask: 0.8787  decode.loss_dice: 0.6562  decode.d0.loss_cls: 0.6235  decode.d0.loss_mask: 0.8341  decode.d0.loss_dice: 0.6835  decode.d1.loss_cls: 0.2511  decode.d1.loss_mask: 0.8400  decode.d1.loss_dice: 0.6440  decode.d2.loss_cls: 0.2460  decode.d2.loss_mask: 0.8465  decode.d2.loss_dice: 0.6496  decode.d3.loss_cls: 0.2330  decode.d3.loss_mask: 0.8401  decode.d3.loss_dice: 0.6300  decode.d4.loss_cls: 0.2439  decode.d4.loss_mask: 0.8935  decode.d4.loss_dice: 0.6521  decode.d5.loss_cls: 0.2330  decode.d5.loss_mask: 0.9077  decode.d5.loss_dice: 0.6506  decode.d6.loss_cls: 0.2194  decode.d6.loss_mask: 0.8768  decode.d6.loss_dice: 0.6314  decode.d7.loss_cls: 0.2271  decode.d7.loss_mask: 0.8793  decode.d7.loss_dice: 0.6553  decode.d8.loss_cls: 0.2368  decode.d8.loss_mask: 0.8802  decode.d8.loss_dice: 0.6625
05/27 04:01:31 - mmengine - INFO - Iter(train) [143850/160000]  base_lr: 1.2695e-05 lr: 1.2695e-06  eta: 1:51:26  time: 0.4172  data_time: 0.0099  memory: 5969  grad_norm: 645.4633  loss: 17.0676  decode.loss_cls: 0.0559  decode.loss_mask: 0.9938  decode.loss_dice: 0.6269  decode.d0.loss_cls: 0.5550  decode.d0.loss_mask: 0.9374  decode.d0.loss_dice: 0.5925  decode.d1.loss_cls: 0.0960  decode.d1.loss_mask: 0.9885  decode.d1.loss_dice: 0.6245  decode.d2.loss_cls: 0.0903  decode.d2.loss_mask: 0.9475  decode.d2.loss_dice: 0.5920  decode.d3.loss_cls: 0.0603  decode.d3.loss_mask: 1.0009  decode.d3.loss_dice: 0.6335  decode.d4.loss_cls: 0.0902  decode.d4.loss_mask: 0.9382  decode.d4.loss_dice: 0.5929  decode.d5.loss_cls: 0.0895  decode.d5.loss_mask: 0.9535  decode.d5.loss_dice: 0.6129  decode.d6.loss_cls: 0.0879  decode.d6.loss_mask: 0.9589  decode.d6.loss_dice: 0.6066  decode.d7.loss_cls: 0.0794  decode.d7.loss_mask: 0.9614  decode.d7.loss_dice: 0.6072  decode.d8.loss_cls: 0.0670  decode.d8.loss_mask: 0.9988  decode.d8.loss_dice: 0.6281
05/27 04:01:52 - mmengine - INFO - Iter(train) [143900/160000]  base_lr: 1.2660e-05 lr: 1.2660e-06  eta: 1:51:05  time: 0.4175  data_time: 0.0099  memory: 5971  grad_norm: 414.3853  loss: 17.3273  decode.loss_cls: 0.1308  decode.loss_mask: 0.8823  decode.loss_dice: 0.6206  decode.d0.loss_cls: 0.7105  decode.d0.loss_mask: 0.8882  decode.d0.loss_dice: 0.6619  decode.d1.loss_cls: 0.1829  decode.d1.loss_mask: 0.8743  decode.d1.loss_dice: 0.6246  decode.d2.loss_cls: 0.1642  decode.d2.loss_mask: 0.8880  decode.d2.loss_dice: 0.6114  decode.d3.loss_cls: 0.1701  decode.d3.loss_mask: 0.9173  decode.d3.loss_dice: 0.6322  decode.d4.loss_cls: 0.1846  decode.d4.loss_mask: 0.8921  decode.d4.loss_dice: 0.6366  decode.d5.loss_cls: 0.1522  decode.d5.loss_mask: 0.8935  decode.d5.loss_dice: 0.6298  decode.d6.loss_cls: 0.1494  decode.d6.loss_mask: 0.8820  decode.d6.loss_dice: 0.6375  decode.d7.loss_cls: 0.1302  decode.d7.loss_mask: 0.8950  decode.d7.loss_dice: 0.6352  decode.d8.loss_cls: 0.1175  decode.d8.loss_mask: 0.8887  decode.d8.loss_dice: 0.6437
05/27 04:02:13 - mmengine - INFO - Iter(train) [143950/160000]  base_lr: 1.2625e-05 lr: 1.2625e-06  eta: 1:50:44  time: 0.4189  data_time: 0.0100  memory: 5975  grad_norm: 574.9334  loss: 20.4504  decode.loss_cls: 0.1554  decode.loss_mask: 1.0848  decode.loss_dice: 0.7353  decode.d0.loss_cls: 0.6857  decode.d0.loss_mask: 1.1034  decode.d0.loss_dice: 0.7521  decode.d1.loss_cls: 0.1616  decode.d1.loss_mask: 1.1064  decode.d1.loss_dice: 0.7804  decode.d2.loss_cls: 0.1401  decode.d2.loss_mask: 1.1586  decode.d2.loss_dice: 0.7330  decode.d3.loss_cls: 0.1596  decode.d3.loss_mask: 1.0802  decode.d3.loss_dice: 0.7408  decode.d4.loss_cls: 0.1365  decode.d4.loss_mask: 1.0928  decode.d4.loss_dice: 0.7512  decode.d5.loss_cls: 0.1199  decode.d5.loss_mask: 1.1031  decode.d5.loss_dice: 0.7475  decode.d6.loss_cls: 0.1131  decode.d6.loss_mask: 1.1099  decode.d6.loss_dice: 0.7615  decode.d7.loss_cls: 0.1311  decode.d7.loss_mask: 1.0797  decode.d7.loss_dice: 0.7481  decode.d8.loss_cls: 0.1548  decode.d8.loss_mask: 1.0889  decode.d8.loss_dice: 0.7349
05/27 04:02:34 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 04:02:34 - mmengine - INFO - Iter(train) [144000/160000]  base_lr: 1.2589e-05 lr: 1.2589e-06  eta: 1:50:24  time: 0.4174  data_time: 0.0100  memory: 5966  grad_norm: 302.5659  loss: 17.0169  decode.loss_cls: 0.1129  decode.loss_mask: 0.9148  decode.loss_dice: 0.6162  decode.d0.loss_cls: 0.5513  decode.d0.loss_mask: 0.9400  decode.d0.loss_dice: 0.6236  decode.d1.loss_cls: 0.1759  decode.d1.loss_mask: 0.8945  decode.d1.loss_dice: 0.5963  decode.d2.loss_cls: 0.1488  decode.d2.loss_mask: 0.8997  decode.d2.loss_dice: 0.5924  decode.d3.loss_cls: 0.1534  decode.d3.loss_mask: 0.9033  decode.d3.loss_dice: 0.5851  decode.d4.loss_cls: 0.1554  decode.d4.loss_mask: 0.9102  decode.d4.loss_dice: 0.5949  decode.d5.loss_cls: 0.1547  decode.d5.loss_mask: 0.9061  decode.d5.loss_dice: 0.5956  decode.d6.loss_cls: 0.1344  decode.d6.loss_mask: 0.9029  decode.d6.loss_dice: 0.6199  decode.d7.loss_cls: 0.1734  decode.d7.loss_mask: 0.8975  decode.d7.loss_dice: 0.5922  decode.d8.loss_cls: 0.1423  decode.d8.loss_mask: 0.9181  decode.d8.loss_dice: 0.6113
05/27 04:02:55 - mmengine - INFO - Iter(train) [144050/160000]  base_lr: 1.2554e-05 lr: 1.2554e-06  eta: 1:50:03  time: 0.4298  data_time: 0.0099  memory: 5971  grad_norm: 613.0532  loss: 19.4520  decode.loss_cls: 0.1189  decode.loss_mask: 1.0871  decode.loss_dice: 0.7100  decode.d0.loss_cls: 0.6459  decode.d0.loss_mask: 1.0742  decode.d0.loss_dice: 0.6742  decode.d1.loss_cls: 0.1133  decode.d1.loss_mask: 1.0920  decode.d1.loss_dice: 0.7274  decode.d2.loss_cls: 0.0988  decode.d2.loss_mask: 1.0660  decode.d2.loss_dice: 0.7027  decode.d3.loss_cls: 0.0984  decode.d3.loss_mask: 1.0884  decode.d3.loss_dice: 0.7142  decode.d4.loss_cls: 0.1077  decode.d4.loss_mask: 1.0896  decode.d4.loss_dice: 0.6995  decode.d5.loss_cls: 0.1045  decode.d5.loss_mask: 1.0936  decode.d5.loss_dice: 0.6980  decode.d6.loss_cls: 0.0922  decode.d6.loss_mask: 1.0889  decode.d6.loss_dice: 0.7076  decode.d7.loss_cls: 0.1332  decode.d7.loss_mask: 1.0632  decode.d7.loss_dice: 0.6801  decode.d8.loss_cls: 0.1150  decode.d8.loss_mask: 1.0686  decode.d8.loss_dice: 0.6989
05/27 04:03:16 - mmengine - INFO - Iter(train) [144100/160000]  base_lr: 1.2518e-05 lr: 1.2518e-06  eta: 1:49:42  time: 0.4176  data_time: 0.0100  memory: 5990  grad_norm: 805.9746  loss: 16.9370  decode.loss_cls: 0.1741  decode.loss_mask: 0.8647  decode.loss_dice: 0.6185  decode.d0.loss_cls: 0.5338  decode.d0.loss_mask: 0.8621  decode.d0.loss_dice: 0.6345  decode.d1.loss_cls: 0.1284  decode.d1.loss_mask: 0.8984  decode.d1.loss_dice: 0.6294  decode.d2.loss_cls: 0.1434  decode.d2.loss_mask: 0.8767  decode.d2.loss_dice: 0.6111  decode.d3.loss_cls: 0.1766  decode.d3.loss_mask: 0.8860  decode.d3.loss_dice: 0.6252  decode.d4.loss_cls: 0.1444  decode.d4.loss_mask: 0.8887  decode.d4.loss_dice: 0.6284  decode.d5.loss_cls: 0.1389  decode.d5.loss_mask: 0.8885  decode.d5.loss_dice: 0.6107  decode.d6.loss_cls: 0.1671  decode.d6.loss_mask: 0.8584  decode.d6.loss_dice: 0.6269  decode.d7.loss_cls: 0.1983  decode.d7.loss_mask: 0.8627  decode.d7.loss_dice: 0.6200  decode.d8.loss_cls: 0.1706  decode.d8.loss_mask: 0.8502  decode.d8.loss_dice: 0.6203
05/27 04:03:37 - mmengine - INFO - Iter(train) [144150/160000]  base_lr: 1.2483e-05 lr: 1.2483e-06  eta: 1:49:22  time: 0.4180  data_time: 0.0101  memory: 5969  grad_norm: 560.1437  loss: 19.1672  decode.loss_cls: 0.0866  decode.loss_mask: 1.0365  decode.loss_dice: 0.7508  decode.d0.loss_cls: 0.5288  decode.d0.loss_mask: 1.0072  decode.d0.loss_dice: 0.7267  decode.d1.loss_cls: 0.1117  decode.d1.loss_mask: 1.0237  decode.d1.loss_dice: 0.7261  decode.d2.loss_cls: 0.1245  decode.d2.loss_mask: 1.0449  decode.d2.loss_dice: 0.7266  decode.d3.loss_cls: 0.1034  decode.d3.loss_mask: 1.0339  decode.d3.loss_dice: 0.7476  decode.d4.loss_cls: 0.1233  decode.d4.loss_mask: 1.0288  decode.d4.loss_dice: 0.7353  decode.d5.loss_cls: 0.1292  decode.d5.loss_mask: 1.0116  decode.d5.loss_dice: 0.7254  decode.d6.loss_cls: 0.1140  decode.d6.loss_mask: 1.0242  decode.d6.loss_dice: 0.7422  decode.d7.loss_cls: 0.1007  decode.d7.loss_mask: 1.0068  decode.d7.loss_dice: 0.7336  decode.d8.loss_cls: 0.1108  decode.d8.loss_mask: 1.0423  decode.d8.loss_dice: 0.7599
05/27 04:03:58 - mmengine - INFO - Iter(train) [144200/160000]  base_lr: 1.2448e-05 lr: 1.2448e-06  eta: 1:49:01  time: 0.4183  data_time: 0.0100  memory: 5972  grad_norm: 281.2168  loss: 17.2635  decode.loss_cls: 0.2449  decode.loss_mask: 0.6734  decode.loss_dice: 0.7513  decode.d0.loss_cls: 0.7421  decode.d0.loss_mask: 0.6773  decode.d0.loss_dice: 0.7626  decode.d1.loss_cls: 0.3408  decode.d1.loss_mask: 0.6790  decode.d1.loss_dice: 0.7444  decode.d2.loss_cls: 0.2419  decode.d2.loss_mask: 0.6813  decode.d2.loss_dice: 0.7152  decode.d3.loss_cls: 0.2272  decode.d3.loss_mask: 0.6831  decode.d3.loss_dice: 0.7328  decode.d4.loss_cls: 0.2970  decode.d4.loss_mask: 0.6721  decode.d4.loss_dice: 0.6878  decode.d5.loss_cls: 0.2692  decode.d5.loss_mask: 0.6790  decode.d5.loss_dice: 0.7120  decode.d6.loss_cls: 0.2812  decode.d6.loss_mask: 0.6911  decode.d6.loss_dice: 0.7477  decode.d7.loss_cls: 0.2679  decode.d7.loss_mask: 0.6758  decode.d7.loss_dice: 0.7210  decode.d8.loss_cls: 0.2536  decode.d8.loss_mask: 0.6773  decode.d8.loss_dice: 0.7338
05/27 04:04:18 - mmengine - INFO - Iter(train) [144250/160000]  base_lr: 1.2412e-05 lr: 1.2412e-06  eta: 1:48:40  time: 0.4182  data_time: 0.0101  memory: 5969  grad_norm: 542.3952  loss: 17.5032  decode.loss_cls: 0.1275  decode.loss_mask: 0.8679  decode.loss_dice: 0.6957  decode.d0.loss_cls: 0.6443  decode.d0.loss_mask: 0.8778  decode.d0.loss_dice: 0.6590  decode.d1.loss_cls: 0.2220  decode.d1.loss_mask: 0.8797  decode.d1.loss_dice: 0.6705  decode.d2.loss_cls: 0.1812  decode.d2.loss_mask: 0.8703  decode.d2.loss_dice: 0.6355  decode.d3.loss_cls: 0.1825  decode.d3.loss_mask: 0.8799  decode.d3.loss_dice: 0.6334  decode.d4.loss_cls: 0.1880  decode.d4.loss_mask: 0.8863  decode.d4.loss_dice: 0.6423  decode.d5.loss_cls: 0.1296  decode.d5.loss_mask: 0.8992  decode.d5.loss_dice: 0.6717  decode.d6.loss_cls: 0.1409  decode.d6.loss_mask: 0.8857  decode.d6.loss_dice: 0.6486  decode.d7.loss_cls: 0.1812  decode.d7.loss_mask: 0.8710  decode.d7.loss_dice: 0.6470  decode.d8.loss_cls: 0.1288  decode.d8.loss_mask: 0.8818  decode.d8.loss_dice: 0.6734
05/27 04:04:39 - mmengine - INFO - Iter(train) [144300/160000]  base_lr: 1.2377e-05 lr: 1.2377e-06  eta: 1:48:20  time: 0.4182  data_time: 0.0100  memory: 5971  grad_norm: 299.6403  loss: 15.9936  decode.loss_cls: 0.1185  decode.loss_mask: 0.8271  decode.loss_dice: 0.6031  decode.d0.loss_cls: 0.6818  decode.d0.loss_mask: 0.7946  decode.d0.loss_dice: 0.6080  decode.d1.loss_cls: 0.1557  decode.d1.loss_mask: 0.8153  decode.d1.loss_dice: 0.5901  decode.d2.loss_cls: 0.1314  decode.d2.loss_mask: 0.8186  decode.d2.loss_dice: 0.5882  decode.d3.loss_cls: 0.1063  decode.d3.loss_mask: 0.8312  decode.d3.loss_dice: 0.6024  decode.d4.loss_cls: 0.1597  decode.d4.loss_mask: 0.8138  decode.d4.loss_dice: 0.5818  decode.d5.loss_cls: 0.1207  decode.d5.loss_mask: 0.8246  decode.d5.loss_dice: 0.6019  decode.d6.loss_cls: 0.1446  decode.d6.loss_mask: 0.8193  decode.d6.loss_dice: 0.5741  decode.d7.loss_cls: 0.1233  decode.d7.loss_mask: 0.8292  decode.d7.loss_dice: 0.6021  decode.d8.loss_cls: 0.1112  decode.d8.loss_mask: 0.8254  decode.d8.loss_dice: 0.5895
05/27 04:05:00 - mmengine - INFO - Iter(train) [144350/160000]  base_lr: 1.2341e-05 lr: 1.2341e-06  eta: 1:47:59  time: 0.4178  data_time: 0.0100  memory: 5987  grad_norm: 385.5329  loss: 19.1784  decode.loss_cls: 0.1745  decode.loss_mask: 1.0612  decode.loss_dice: 0.6621  decode.d0.loss_cls: 0.5609  decode.d0.loss_mask: 1.0392  decode.d0.loss_dice: 0.6346  decode.d1.loss_cls: 0.1738  decode.d1.loss_mask: 1.0500  decode.d1.loss_dice: 0.6671  decode.d2.loss_cls: 0.1539  decode.d2.loss_mask: 1.0741  decode.d2.loss_dice: 0.6716  decode.d3.loss_cls: 0.1689  decode.d3.loss_mask: 1.0624  decode.d3.loss_dice: 0.6504  decode.d4.loss_cls: 0.1404  decode.d4.loss_mask: 1.0441  decode.d4.loss_dice: 0.6590  decode.d5.loss_cls: 0.1362  decode.d5.loss_mask: 1.0538  decode.d5.loss_dice: 0.6598  decode.d6.loss_cls: 0.1439  decode.d6.loss_mask: 1.0789  decode.d6.loss_dice: 0.6646  decode.d7.loss_cls: 0.1568  decode.d7.loss_mask: 1.0882  decode.d7.loss_dice: 0.6522  decode.d8.loss_cls: 0.1398  decode.d8.loss_mask: 1.0820  decode.d8.loss_dice: 0.6741
05/27 04:05:21 - mmengine - INFO - Iter(train) [144400/160000]  base_lr: 1.2306e-05 lr: 1.2306e-06  eta: 1:47:38  time: 0.4177  data_time: 0.0100  memory: 5975  grad_norm: 620.8189  loss: 22.0662  decode.loss_cls: 0.2509  decode.loss_mask: 1.0487  decode.loss_dice: 0.8331  decode.d0.loss_cls: 0.6925  decode.d0.loss_mask: 1.0497  decode.d0.loss_dice: 0.8072  decode.d1.loss_cls: 0.3167  decode.d1.loss_mask: 1.0533  decode.d1.loss_dice: 0.8113  decode.d2.loss_cls: 0.3096  decode.d2.loss_mask: 1.0518  decode.d2.loss_dice: 0.8231  decode.d3.loss_cls: 0.2743  decode.d3.loss_mask: 1.0862  decode.d3.loss_dice: 0.8289  decode.d4.loss_cls: 0.2810  decode.d4.loss_mask: 1.0796  decode.d4.loss_dice: 0.8470  decode.d5.loss_cls: 0.2990  decode.d5.loss_mask: 1.0604  decode.d5.loss_dice: 0.8179  decode.d6.loss_cls: 0.2944  decode.d6.loss_mask: 1.0476  decode.d6.loss_dice: 0.8104  decode.d7.loss_cls: 0.2618  decode.d7.loss_mask: 1.0638  decode.d7.loss_dice: 0.8260  decode.d8.loss_cls: 0.2528  decode.d8.loss_mask: 1.0617  decode.d8.loss_dice: 0.8257
05/27 04:05:42 - mmengine - INFO - Iter(train) [144450/160000]  base_lr: 1.2270e-05 lr: 1.2270e-06  eta: 1:47:18  time: 0.4185  data_time: 0.0100  memory: 5967  grad_norm: 716.9520  loss: 19.6759  decode.loss_cls: 0.2170  decode.loss_mask: 0.9905  decode.loss_dice: 0.6639  decode.d0.loss_cls: 0.8346  decode.d0.loss_mask: 0.9452  decode.d0.loss_dice: 0.7014  decode.d1.loss_cls: 0.2589  decode.d1.loss_mask: 0.9916  decode.d1.loss_dice: 0.7017  decode.d2.loss_cls: 0.1893  decode.d2.loss_mask: 1.0463  decode.d2.loss_dice: 0.7069  decode.d3.loss_cls: 0.2073  decode.d3.loss_mask: 1.0054  decode.d3.loss_dice: 0.6632  decode.d4.loss_cls: 0.2140  decode.d4.loss_mask: 1.0087  decode.d4.loss_dice: 0.6835  decode.d5.loss_cls: 0.1918  decode.d5.loss_mask: 1.0023  decode.d5.loss_dice: 0.6881  decode.d6.loss_cls: 0.1974  decode.d6.loss_mask: 1.0085  decode.d6.loss_dice: 0.7045  decode.d7.loss_cls: 0.2102  decode.d7.loss_mask: 1.0426  decode.d7.loss_dice: 0.6789  decode.d8.loss_cls: 0.2309  decode.d8.loss_mask: 1.0116  decode.d8.loss_dice: 0.6799
05/27 04:06:03 - mmengine - INFO - Iter(train) [144500/160000]  base_lr: 1.2235e-05 lr: 1.2235e-06  eta: 1:46:57  time: 0.4174  data_time: 0.0101  memory: 5974  grad_norm: 617.3387  loss: 22.0199  decode.loss_cls: 0.2626  decode.loss_mask: 1.0759  decode.loss_dice: 0.8159  decode.d0.loss_cls: 0.7329  decode.d0.loss_mask: 1.0927  decode.d0.loss_dice: 0.7778  decode.d1.loss_cls: 0.3151  decode.d1.loss_mask: 1.0687  decode.d1.loss_dice: 0.8390  decode.d2.loss_cls: 0.2599  decode.d2.loss_mask: 1.0966  decode.d2.loss_dice: 0.8113  decode.d3.loss_cls: 0.2665  decode.d3.loss_mask: 1.0760  decode.d3.loss_dice: 0.8142  decode.d4.loss_cls: 0.3036  decode.d4.loss_mask: 1.0498  decode.d4.loss_dice: 0.8027  decode.d5.loss_cls: 0.2933  decode.d5.loss_mask: 1.0744  decode.d5.loss_dice: 0.7793  decode.d6.loss_cls: 0.2707  decode.d6.loss_mask: 1.0678  decode.d6.loss_dice: 0.7908  decode.d7.loss_cls: 0.2387  decode.d7.loss_mask: 1.1027  decode.d7.loss_dice: 0.8039  decode.d8.loss_cls: 0.2420  decode.d8.loss_mask: 1.0830  decode.d8.loss_dice: 0.8125
05/27 04:06:24 - mmengine - INFO - Iter(train) [144550/160000]  base_lr: 1.2199e-05 lr: 1.2199e-06  eta: 1:46:36  time: 0.4183  data_time: 0.0101  memory: 5969  grad_norm: 453.3509  loss: 17.1943  decode.loss_cls: 0.1966  decode.loss_mask: 0.8965  decode.loss_dice: 0.5742  decode.d0.loss_cls: 0.7494  decode.d0.loss_mask: 0.8621  decode.d0.loss_dice: 0.5885  decode.d1.loss_cls: 0.1992  decode.d1.loss_mask: 0.8787  decode.d1.loss_dice: 0.5885  decode.d2.loss_cls: 0.1815  decode.d2.loss_mask: 0.9003  decode.d2.loss_dice: 0.5908  decode.d3.loss_cls: 0.1866  decode.d3.loss_mask: 0.9094  decode.d3.loss_dice: 0.5962  decode.d4.loss_cls: 0.1936  decode.d4.loss_mask: 0.8914  decode.d4.loss_dice: 0.5989  decode.d5.loss_cls: 0.1747  decode.d5.loss_mask: 0.8887  decode.d5.loss_dice: 0.5956  decode.d6.loss_cls: 0.1917  decode.d6.loss_mask: 0.8644  decode.d6.loss_dice: 0.5751  decode.d7.loss_cls: 0.1817  decode.d7.loss_mask: 0.8931  decode.d7.loss_dice: 0.5862  decode.d8.loss_cls: 0.1996  decode.d8.loss_mask: 0.8894  decode.d8.loss_dice: 0.5717
05/27 04:06:45 - mmengine - INFO - Iter(train) [144600/160000]  base_lr: 1.2164e-05 lr: 1.2164e-06  eta: 1:46:16  time: 0.4186  data_time: 0.0100  memory: 5976  grad_norm: 380.6209  loss: 18.7860  decode.loss_cls: 0.2008  decode.loss_mask: 0.9028  decode.loss_dice: 0.7006  decode.d0.loss_cls: 0.7405  decode.d0.loss_mask: 0.8862  decode.d0.loss_dice: 0.7026  decode.d1.loss_cls: 0.2515  decode.d1.loss_mask: 0.9343  decode.d1.loss_dice: 0.6944  decode.d2.loss_cls: 0.2260  decode.d2.loss_mask: 0.9049  decode.d2.loss_dice: 0.7080  decode.d3.loss_cls: 0.1980  decode.d3.loss_mask: 0.9475  decode.d3.loss_dice: 0.6984  decode.d4.loss_cls: 0.1897  decode.d4.loss_mask: 0.9482  decode.d4.loss_dice: 0.7100  decode.d5.loss_cls: 0.1851  decode.d5.loss_mask: 0.8997  decode.d5.loss_dice: 0.7022  decode.d6.loss_cls: 0.1965  decode.d6.loss_mask: 0.9397  decode.d6.loss_dice: 0.7111  decode.d7.loss_cls: 0.2106  decode.d7.loss_mask: 0.9007  decode.d7.loss_dice: 0.6886  decode.d8.loss_cls: 0.1996  decode.d8.loss_mask: 0.9024  decode.d8.loss_dice: 0.7055
05/27 04:07:06 - mmengine - INFO - Iter(train) [144650/160000]  base_lr: 1.2128e-05 lr: 1.2128e-06  eta: 1:45:55  time: 0.4184  data_time: 0.0101  memory: 5976  grad_norm: 474.4254  loss: 20.6695  decode.loss_cls: 0.2055  decode.loss_mask: 1.0129  decode.loss_dice: 0.7632  decode.d0.loss_cls: 0.7712  decode.d0.loss_mask: 0.9867  decode.d0.loss_dice: 0.7718  decode.d1.loss_cls: 0.2140  decode.d1.loss_mask: 1.0406  decode.d1.loss_dice: 0.7859  decode.d2.loss_cls: 0.2164  decode.d2.loss_mask: 1.0304  decode.d2.loss_dice: 0.8034  decode.d3.loss_cls: 0.2136  decode.d3.loss_mask: 1.0134  decode.d3.loss_dice: 0.7619  decode.d4.loss_cls: 0.2145  decode.d4.loss_mask: 1.0099  decode.d4.loss_dice: 0.7835  decode.d5.loss_cls: 0.2008  decode.d5.loss_mask: 1.0209  decode.d5.loss_dice: 0.7883  decode.d6.loss_cls: 0.2231  decode.d6.loss_mask: 1.0328  decode.d6.loss_dice: 0.7803  decode.d7.loss_cls: 0.2091  decode.d7.loss_mask: 1.0275  decode.d7.loss_dice: 0.7792  decode.d8.loss_cls: 0.2111  decode.d8.loss_mask: 1.0187  decode.d8.loss_dice: 0.7788
05/27 04:07:27 - mmengine - INFO - Iter(train) [144700/160000]  base_lr: 1.2093e-05 lr: 1.2093e-06  eta: 1:45:34  time: 0.4177  data_time: 0.0101  memory: 5966  grad_norm: 464.4824  loss: 15.1414  decode.loss_cls: 0.1217  decode.loss_mask: 0.8242  decode.loss_dice: 0.5143  decode.d0.loss_cls: 0.4967  decode.d0.loss_mask: 0.8462  decode.d0.loss_dice: 0.5417  decode.d1.loss_cls: 0.1120  decode.d1.loss_mask: 0.8577  decode.d1.loss_dice: 0.5372  decode.d2.loss_cls: 0.0999  decode.d2.loss_mask: 0.8370  decode.d2.loss_dice: 0.5265  decode.d3.loss_cls: 0.1113  decode.d3.loss_mask: 0.8336  decode.d3.loss_dice: 0.5177  decode.d4.loss_cls: 0.1089  decode.d4.loss_mask: 0.8381  decode.d4.loss_dice: 0.5282  decode.d5.loss_cls: 0.1118  decode.d5.loss_mask: 0.8393  decode.d5.loss_dice: 0.5268  decode.d6.loss_cls: 0.1100  decode.d6.loss_mask: 0.8339  decode.d6.loss_dice: 0.5253  decode.d7.loss_cls: 0.1161  decode.d7.loss_mask: 0.8407  decode.d7.loss_dice: 0.5175  decode.d8.loss_cls: 0.1213  decode.d8.loss_mask: 0.8323  decode.d8.loss_dice: 0.5134
05/27 04:07:48 - mmengine - INFO - Iter(train) [144750/160000]  base_lr: 1.2057e-05 lr: 1.2057e-06  eta: 1:45:14  time: 0.4184  data_time: 0.0101  memory: 5973  grad_norm: 424.8094  loss: 21.5053  decode.loss_cls: 0.2089  decode.loss_mask: 1.0667  decode.loss_dice: 0.8174  decode.d0.loss_cls: 0.7944  decode.d0.loss_mask: 1.0158  decode.d0.loss_dice: 0.7859  decode.d1.loss_cls: 0.2448  decode.d1.loss_mask: 1.0476  decode.d1.loss_dice: 0.7910  decode.d2.loss_cls: 0.2504  decode.d2.loss_mask: 1.0430  decode.d2.loss_dice: 0.7761  decode.d3.loss_cls: 0.2430  decode.d3.loss_mask: 1.0298  decode.d3.loss_dice: 0.7908  decode.d4.loss_cls: 0.2371  decode.d4.loss_mask: 1.0843  decode.d4.loss_dice: 0.8252  decode.d5.loss_cls: 0.1856  decode.d5.loss_mask: 1.1126  decode.d5.loss_dice: 0.8222  decode.d6.loss_cls: 0.2349  decode.d6.loss_mask: 1.0877  decode.d6.loss_dice: 0.8303  decode.d7.loss_cls: 0.2292  decode.d7.loss_mask: 1.0427  decode.d7.loss_dice: 0.8005  decode.d8.loss_cls: 0.2214  decode.d8.loss_mask: 1.0762  decode.d8.loss_dice: 0.8096
05/27 04:08:09 - mmengine - INFO - Iter(train) [144800/160000]  base_lr: 1.2021e-05 lr: 1.2021e-06  eta: 1:44:53  time: 0.4186  data_time: 0.0101  memory: 5973  grad_norm: 307.2814  loss: 16.1100  decode.loss_cls: 0.1386  decode.loss_mask: 0.8918  decode.loss_dice: 0.5430  decode.d0.loss_cls: 0.6284  decode.d0.loss_mask: 0.8755  decode.d0.loss_dice: 0.5451  decode.d1.loss_cls: 0.1673  decode.d1.loss_mask: 0.8892  decode.d1.loss_dice: 0.5491  decode.d2.loss_cls: 0.1209  decode.d2.loss_mask: 0.8920  decode.d2.loss_dice: 0.5449  decode.d3.loss_cls: 0.1204  decode.d3.loss_mask: 0.8860  decode.d3.loss_dice: 0.5441  decode.d4.loss_cls: 0.1174  decode.d4.loss_mask: 0.8905  decode.d4.loss_dice: 0.5486  decode.d5.loss_cls: 0.1070  decode.d5.loss_mask: 0.8885  decode.d5.loss_dice: 0.5446  decode.d6.loss_cls: 0.1295  decode.d6.loss_mask: 0.8863  decode.d6.loss_dice: 0.5521  decode.d7.loss_cls: 0.1209  decode.d7.loss_mask: 0.8889  decode.d7.loss_dice: 0.5521  decode.d8.loss_cls: 0.1211  decode.d8.loss_mask: 0.8845  decode.d8.loss_dice: 0.5414
05/27 04:08:30 - mmengine - INFO - Iter(train) [144850/160000]  base_lr: 1.1986e-05 lr: 1.1986e-06  eta: 1:44:32  time: 0.4182  data_time: 0.0101  memory: 5975  grad_norm: 500.8539  loss: 19.4077  decode.loss_cls: 0.1303  decode.loss_mask: 1.0546  decode.loss_dice: 0.6719  decode.d0.loss_cls: 0.6995  decode.d0.loss_mask: 0.9940  decode.d0.loss_dice: 0.6698  decode.d1.loss_cls: 0.1497  decode.d1.loss_mask: 1.0338  decode.d1.loss_dice: 0.6841  decode.d2.loss_cls: 0.1191  decode.d2.loss_mask: 1.0662  decode.d2.loss_dice: 0.7011  decode.d3.loss_cls: 0.1639  decode.d3.loss_mask: 1.0325  decode.d3.loss_dice: 0.6773  decode.d4.loss_cls: 0.1475  decode.d4.loss_mask: 1.0735  decode.d4.loss_dice: 0.6832  decode.d5.loss_cls: 0.1379  decode.d5.loss_mask: 1.1040  decode.d5.loss_dice: 0.7038  decode.d6.loss_cls: 0.1228  decode.d6.loss_mask: 1.0951  decode.d6.loss_dice: 0.7028  decode.d7.loss_cls: 0.1437  decode.d7.loss_mask: 1.0639  decode.d7.loss_dice: 0.6937  decode.d8.loss_cls: 0.1228  decode.d8.loss_mask: 1.0750  decode.d8.loss_dice: 0.6904
05/27 04:08:51 - mmengine - INFO - Iter(train) [144900/160000]  base_lr: 1.1950e-05 lr: 1.1950e-06  eta: 1:44:12  time: 0.4178  data_time: 0.0100  memory: 5967  grad_norm: 457.7078  loss: 16.4539  decode.loss_cls: 0.0951  decode.loss_mask: 0.8150  decode.loss_dice: 0.6781  decode.d0.loss_cls: 0.6380  decode.d0.loss_mask: 0.8131  decode.d0.loss_dice: 0.6725  decode.d1.loss_cls: 0.0884  decode.d1.loss_mask: 0.8159  decode.d1.loss_dice: 0.6913  decode.d2.loss_cls: 0.0837  decode.d2.loss_mask: 0.8062  decode.d2.loss_dice: 0.6833  decode.d3.loss_cls: 0.1002  decode.d3.loss_mask: 0.8177  decode.d3.loss_dice: 0.6908  decode.d4.loss_cls: 0.0789  decode.d4.loss_mask: 0.8164  decode.d4.loss_dice: 0.6993  decode.d5.loss_cls: 0.0728  decode.d5.loss_mask: 0.8164  decode.d5.loss_dice: 0.6897  decode.d6.loss_cls: 0.0814  decode.d6.loss_mask: 0.8157  decode.d6.loss_dice: 0.6948  decode.d7.loss_cls: 0.1063  decode.d7.loss_mask: 0.8155  decode.d7.loss_dice: 0.6867  decode.d8.loss_cls: 0.0912  decode.d8.loss_mask: 0.8136  decode.d8.loss_dice: 0.6860
05/27 04:09:12 - mmengine - INFO - Iter(train) [144950/160000]  base_lr: 1.1915e-05 lr: 1.1915e-06  eta: 1:43:51  time: 0.4179  data_time: 0.0101  memory: 5972  grad_norm: 524.2402  loss: 20.0580  decode.loss_cls: 0.1887  decode.loss_mask: 1.0626  decode.loss_dice: 0.6821  decode.d0.loss_cls: 0.6700  decode.d0.loss_mask: 1.0889  decode.d0.loss_dice: 0.7106  decode.d1.loss_cls: 0.2235  decode.d1.loss_mask: 1.0945  decode.d1.loss_dice: 0.7053  decode.d2.loss_cls: 0.2132  decode.d2.loss_mask: 1.0481  decode.d2.loss_dice: 0.6814  decode.d3.loss_cls: 0.2205  decode.d3.loss_mask: 1.0463  decode.d3.loss_dice: 0.6808  decode.d4.loss_cls: 0.2133  decode.d4.loss_mask: 1.0564  decode.d4.loss_dice: 0.6788  decode.d5.loss_cls: 0.1777  decode.d5.loss_mask: 1.0707  decode.d5.loss_dice: 0.6810  decode.d6.loss_cls: 0.1724  decode.d6.loss_mask: 1.0883  decode.d6.loss_dice: 0.7117  decode.d7.loss_cls: 0.1808  decode.d7.loss_mask: 1.0694  decode.d7.loss_dice: 0.6916  decode.d8.loss_cls: 0.1935  decode.d8.loss_mask: 1.0742  decode.d8.loss_dice: 0.6819
05/27 04:09:32 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 04:09:32 - mmengine - INFO - Iter(train) [145000/160000]  base_lr: 1.1879e-05 lr: 1.1879e-06  eta: 1:43:30  time: 0.4177  data_time: 0.0101  memory: 5969  grad_norm: 433.0814  loss: 16.3519  decode.loss_cls: 0.1241  decode.loss_mask: 0.8067  decode.loss_dice: 0.6325  decode.d0.loss_cls: 0.6688  decode.d0.loss_mask: 0.7710  decode.d0.loss_dice: 0.6588  decode.d1.loss_cls: 0.1588  decode.d1.loss_mask: 0.7999  decode.d1.loss_dice: 0.6344  decode.d2.loss_cls: 0.1452  decode.d2.loss_mask: 0.8043  decode.d2.loss_dice: 0.6383  decode.d3.loss_cls: 0.1441  decode.d3.loss_mask: 0.8040  decode.d3.loss_dice: 0.6345  decode.d4.loss_cls: 0.1347  decode.d4.loss_mask: 0.7958  decode.d4.loss_dice: 0.6354  decode.d5.loss_cls: 0.1422  decode.d5.loss_mask: 0.7973  decode.d5.loss_dice: 0.6338  decode.d6.loss_cls: 0.1525  decode.d6.loss_mask: 0.8008  decode.d6.loss_dice: 0.6341  decode.d7.loss_cls: 0.1677  decode.d7.loss_mask: 0.8063  decode.d7.loss_dice: 0.6482  decode.d8.loss_cls: 0.1438  decode.d8.loss_mask: 0.7998  decode.d8.loss_dice: 0.6339
05/27 04:09:32 - mmengine - INFO - Saving checkpoint at 145000 iterations
05/27 04:09:37 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:08  time: 0.0482  data_time: 0.0012  memory: 1391  
05/27 04:09:39 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:04  time: 0.0481  data_time: 0.0013  memory: 1205  
05/27 04:09:42 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:02  time: 0.0502  data_time: 0.0012  memory: 1596  
05/27 04:09:44 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0485  data_time: 0.0012  memory: 1298  
05/27 04:09:47 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:57  time: 0.0477  data_time: 0.0012  memory: 1298  
05/27 04:09:49 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0475  data_time: 0.0012  memory: 1279  
05/27 04:09:51 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:52  time: 0.0477  data_time: 0.0012  memory: 1224  
05/27 04:09:54 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0487  data_time: 0.0012  memory: 1298  
05/27 04:09:56 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0472  data_time: 0.0013  memory: 1298  
05/27 04:09:59 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0512  data_time: 0.0012  memory: 1725  
05/27 04:10:01 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0478  data_time: 0.0012  memory: 1336  
05/27 04:10:03 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0482  data_time: 0.0012  memory: 1298  
05/27 04:10:06 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0481  data_time: 0.0012  memory: 1205  
05/27 04:10:08 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0489  data_time: 0.0012  memory: 1316  
05/27 04:10:11 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0475  data_time: 0.0013  memory: 1279  
05/27 04:10:13 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0512  data_time: 0.0013  memory: 1410  
05/27 04:10:15 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0479  data_time: 0.0012  memory: 1279  
05/27 04:10:18 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0486  data_time: 0.0012  memory: 1205  
05/27 04:10:20 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:23  time: 0.0485  data_time: 0.0012  memory: 1205  
05/27 04:10:23 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0476  data_time: 0.0012  memory: 1336  
05/27 04:10:25 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0476  data_time: 0.0012  memory: 1246  
05/27 04:10:28 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0499  data_time: 0.0013  memory: 1503  
05/27 04:10:30 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0475  data_time: 0.0012  memory: 1261  
05/27 04:10:32 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0485  data_time: 0.0012  memory: 1298  
05/27 04:10:35 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0477  data_time: 0.0012  memory: 1447  
05/27 04:10:37 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0480  data_time: 0.0013  memory: 1298  
05/27 04:10:40 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0499  data_time: 0.0013  memory: 1279  
05/27 04:10:42 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0478  data_time: 0.0012  memory: 1205  
05/27 04:10:44 - mmengine - INFO - per class results:
05/27 04:10:44 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.92 | 97.57 |
|  aeroplane  | 92.09 | 96.14 |
|   bicycle   | 44.14 |  96.8 |
|     bird    | 94.34 | 98.58 |
|     boat    |  68.3 |  89.9 |
|    bottle   | 85.44 | 96.22 |
|     bus     | 95.45 | 97.94 |
|     car     | 91.81 | 95.65 |
|     cat     | 94.45 | 97.05 |
|    chair    | 44.62 | 72.06 |
|     cow     | 90.98 | 97.17 |
| diningtable | 69.41 | 72.51 |
|     dog     | 90.15 | 98.33 |
|    horse    | 90.18 | 95.15 |
|  motorbike  | 92.26 |  96.5 |
|    person   |  90.6 | 93.83 |
| pottedplant | 72.56 | 91.36 |
|    sheep    | 88.66 |  92.4 |
|     sofa    |  55.6 |  64.3 |
|    train    | 88.32 | 96.39 |
|  tvmonitor  | 85.73 | 88.56 |
+-------------+-------+-------+
05/27 04:10:44 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 96.1100  mIoU: 81.9500  mAcc: 91.6400  data_time: 0.0013  time: 0.0480
05/27 04:11:05 - mmengine - INFO - Iter(train) [145050/160000]  base_lr: 1.1843e-05 lr: 1.1843e-06  eta: 1:43:10  time: 0.4181  data_time: 0.0101  memory: 5975  grad_norm: 527.5118  loss: 21.4819  decode.loss_cls: 0.1745  decode.loss_mask: 1.0920  decode.loss_dice: 0.8014  decode.d0.loss_cls: 0.7528  decode.d0.loss_mask: 1.1946  decode.d0.loss_dice: 0.8519  decode.d1.loss_cls: 0.1871  decode.d1.loss_mask: 1.0691  decode.d1.loss_dice: 0.8029  decode.d2.loss_cls: 0.2250  decode.d2.loss_mask: 1.1016  decode.d2.loss_dice: 0.7814  decode.d3.loss_cls: 0.1887  decode.d3.loss_mask: 1.0592  decode.d3.loss_dice: 0.7666  decode.d4.loss_cls: 0.1848  decode.d4.loss_mask: 1.0993  decode.d4.loss_dice: 0.8095  decode.d5.loss_cls: 0.1686  decode.d5.loss_mask: 1.0899  decode.d5.loss_dice: 0.8022  decode.d6.loss_cls: 0.2083  decode.d6.loss_mask: 1.0807  decode.d6.loss_dice: 0.8136  decode.d7.loss_cls: 0.1755  decode.d7.loss_mask: 1.0641  decode.d7.loss_dice: 0.7990  decode.d8.loss_cls: 0.2131  decode.d8.loss_mask: 1.1067  decode.d8.loss_dice: 0.8176
05/27 04:11:26 - mmengine - INFO - Iter(train) [145100/160000]  base_lr: 1.1808e-05 lr: 1.1808e-06  eta: 1:42:49  time: 0.4187  data_time: 0.0102  memory: 5968  grad_norm: 341.5434  loss: 16.5102  decode.loss_cls: 0.1125  decode.loss_mask: 0.8078  decode.loss_dice: 0.6337  decode.d0.loss_cls: 0.7130  decode.d0.loss_mask: 0.7892  decode.d0.loss_dice: 0.6092  decode.d1.loss_cls: 0.1513  decode.d1.loss_mask: 0.8191  decode.d1.loss_dice: 0.6229  decode.d2.loss_cls: 0.1070  decode.d2.loss_mask: 0.8519  decode.d2.loss_dice: 0.6395  decode.d3.loss_cls: 0.1158  decode.d3.loss_mask: 0.8545  decode.d3.loss_dice: 0.6288  decode.d4.loss_cls: 0.1173  decode.d4.loss_mask: 0.8811  decode.d4.loss_dice: 0.6627  decode.d5.loss_cls: 0.1334  decode.d5.loss_mask: 0.8604  decode.d5.loss_dice: 0.6513  decode.d6.loss_cls: 0.1354  decode.d6.loss_mask: 0.8193  decode.d6.loss_dice: 0.6284  decode.d7.loss_cls: 0.1214  decode.d7.loss_mask: 0.8147  decode.d7.loss_dice: 0.6303  decode.d8.loss_cls: 0.1213  decode.d8.loss_mask: 0.8223  decode.d8.loss_dice: 0.6547
05/27 04:11:47 - mmengine - INFO - Iter(train) [145150/160000]  base_lr: 1.1772e-05 lr: 1.1772e-06  eta: 1:42:28  time: 0.4185  data_time: 0.0100  memory: 5975  grad_norm: 703.4245  loss: 21.2816  decode.loss_cls: 0.1760  decode.loss_mask: 1.1559  decode.loss_dice: 0.7388  decode.d0.loss_cls: 0.6892  decode.d0.loss_mask: 1.1732  decode.d0.loss_dice: 0.7413  decode.d1.loss_cls: 0.2277  decode.d1.loss_mask: 1.1230  decode.d1.loss_dice: 0.7266  decode.d2.loss_cls: 0.2339  decode.d2.loss_mask: 1.1075  decode.d2.loss_dice: 0.7284  decode.d3.loss_cls: 0.2189  decode.d3.loss_mask: 1.1294  decode.d3.loss_dice: 0.7201  decode.d4.loss_cls: 0.2169  decode.d4.loss_mask: 1.1323  decode.d4.loss_dice: 0.7345  decode.d5.loss_cls: 0.2069  decode.d5.loss_mask: 1.1081  decode.d5.loss_dice: 0.7276  decode.d6.loss_cls: 0.2187  decode.d6.loss_mask: 1.1116  decode.d6.loss_dice: 0.7308  decode.d7.loss_cls: 0.2449  decode.d7.loss_mask: 1.1371  decode.d7.loss_dice: 0.7397  decode.d8.loss_cls: 0.1990  decode.d8.loss_mask: 1.1366  decode.d8.loss_dice: 0.7471
05/27 04:12:08 - mmengine - INFO - Iter(train) [145200/160000]  base_lr: 1.1736e-05 lr: 1.1736e-06  eta: 1:42:07  time: 0.4186  data_time: 0.0100  memory: 5973  grad_norm: 632.0698  loss: 17.6639  decode.loss_cls: 0.1814  decode.loss_mask: 0.8959  decode.loss_dice: 0.6310  decode.d0.loss_cls: 0.5922  decode.d0.loss_mask: 0.9150  decode.d0.loss_dice: 0.6053  decode.d1.loss_cls: 0.1834  decode.d1.loss_mask: 0.9233  decode.d1.loss_dice: 0.6568  decode.d2.loss_cls: 0.1812  decode.d2.loss_mask: 0.8998  decode.d2.loss_dice: 0.6439  decode.d3.loss_cls: 0.1673  decode.d3.loss_mask: 0.9613  decode.d3.loss_dice: 0.6401  decode.d4.loss_cls: 0.1763  decode.d4.loss_mask: 0.8821  decode.d4.loss_dice: 0.6290  decode.d5.loss_cls: 0.1779  decode.d5.loss_mask: 0.8812  decode.d5.loss_dice: 0.6309  decode.d6.loss_cls: 0.1706  decode.d6.loss_mask: 0.8975  decode.d6.loss_dice: 0.6331  decode.d7.loss_cls: 0.1613  decode.d7.loss_mask: 0.9570  decode.d7.loss_dice: 0.6500  decode.d8.loss_cls: 0.1665  decode.d8.loss_mask: 0.9179  decode.d8.loss_dice: 0.6549
05/27 04:12:29 - mmengine - INFO - Iter(train) [145250/160000]  base_lr: 1.1701e-05 lr: 1.1701e-06  eta: 1:41:47  time: 0.4182  data_time: 0.0101  memory: 5980  grad_norm: 579.0774  loss: 21.4607  decode.loss_cls: 0.2992  decode.loss_mask: 1.1132  decode.loss_dice: 0.6765  decode.d0.loss_cls: 0.7542  decode.d0.loss_mask: 1.0608  decode.d0.loss_dice: 0.7044  decode.d1.loss_cls: 0.3213  decode.d1.loss_mask: 1.1028  decode.d1.loss_dice: 0.6635  decode.d2.loss_cls: 0.2953  decode.d2.loss_mask: 1.1518  decode.d2.loss_dice: 0.6848  decode.d3.loss_cls: 0.2930  decode.d3.loss_mask: 1.0971  decode.d3.loss_dice: 0.7017  decode.d4.loss_cls: 0.3169  decode.d4.loss_mask: 1.1129  decode.d4.loss_dice: 0.6622  decode.d5.loss_cls: 0.2986  decode.d5.loss_mask: 1.1038  decode.d5.loss_dice: 0.6693  decode.d6.loss_cls: 0.3461  decode.d6.loss_mask: 1.0937  decode.d6.loss_dice: 0.6676  decode.d7.loss_cls: 0.3530  decode.d7.loss_mask: 1.1084  decode.d7.loss_dice: 0.6742  decode.d8.loss_cls: 0.3318  decode.d8.loss_mask: 1.1293  decode.d8.loss_dice: 0.6732
05/27 04:12:50 - mmengine - INFO - Iter(train) [145300/160000]  base_lr: 1.1665e-05 lr: 1.1665e-06  eta: 1:41:26  time: 0.4185  data_time: 0.0100  memory: 5968  grad_norm: 464.3154  loss: 18.6357  decode.loss_cls: 0.2350  decode.loss_mask: 0.9232  decode.loss_dice: 0.6519  decode.d0.loss_cls: 0.7912  decode.d0.loss_mask: 0.9034  decode.d0.loss_dice: 0.6426  decode.d1.loss_cls: 0.2325  decode.d1.loss_mask: 0.9013  decode.d1.loss_dice: 0.6093  decode.d2.loss_cls: 0.2455  decode.d2.loss_mask: 0.9267  decode.d2.loss_dice: 0.6367  decode.d3.loss_cls: 0.2604  decode.d3.loss_mask: 0.9188  decode.d3.loss_dice: 0.6485  decode.d4.loss_cls: 0.2786  decode.d4.loss_mask: 0.9232  decode.d4.loss_dice: 0.6542  decode.d5.loss_cls: 0.2327  decode.d5.loss_mask: 0.9328  decode.d5.loss_dice: 0.6399  decode.d6.loss_cls: 0.2769  decode.d6.loss_mask: 0.9000  decode.d6.loss_dice: 0.6407  decode.d7.loss_cls: 0.2581  decode.d7.loss_mask: 0.9177  decode.d7.loss_dice: 0.6263  decode.d8.loss_cls: 0.2632  decode.d8.loss_mask: 0.9279  decode.d8.loss_dice: 0.6362
05/27 04:13:11 - mmengine - INFO - Iter(train) [145350/160000]  base_lr: 1.1629e-05 lr: 1.1629e-06  eta: 1:41:05  time: 0.4205  data_time: 0.0101  memory: 5981  grad_norm: 711.5109  loss: 18.7516  decode.loss_cls: 0.2460  decode.loss_mask: 0.9557  decode.loss_dice: 0.5860  decode.d0.loss_cls: 0.7939  decode.d0.loss_mask: 0.9190  decode.d0.loss_dice: 0.5849  decode.d1.loss_cls: 0.2461  decode.d1.loss_mask: 0.9799  decode.d1.loss_dice: 0.6302  decode.d2.loss_cls: 0.2537  decode.d2.loss_mask: 0.9726  decode.d2.loss_dice: 0.6263  decode.d3.loss_cls: 0.2487  decode.d3.loss_mask: 0.9673  decode.d3.loss_dice: 0.5983  decode.d4.loss_cls: 0.2752  decode.d4.loss_mask: 0.9357  decode.d4.loss_dice: 0.6166  decode.d5.loss_cls: 0.2460  decode.d5.loss_mask: 0.9536  decode.d5.loss_dice: 0.6180  decode.d6.loss_cls: 0.2710  decode.d6.loss_mask: 0.9839  decode.d6.loss_dice: 0.5945  decode.d7.loss_cls: 0.2705  decode.d7.loss_mask: 0.9520  decode.d7.loss_dice: 0.6255  decode.d8.loss_cls: 0.2235  decode.d8.loss_mask: 0.9634  decode.d8.loss_dice: 0.6136
05/27 04:13:32 - mmengine - INFO - Iter(train) [145400/160000]  base_lr: 1.1593e-05 lr: 1.1593e-06  eta: 1:40:45  time: 0.4174  data_time: 0.0099  memory: 5969  grad_norm: 1684.6514  loss: 17.8526  decode.loss_cls: 0.1931  decode.loss_mask: 0.9155  decode.loss_dice: 0.6163  decode.d0.loss_cls: 0.6716  decode.d0.loss_mask: 0.9268  decode.d0.loss_dice: 0.6090  decode.d1.loss_cls: 0.2644  decode.d1.loss_mask: 0.8993  decode.d1.loss_dice: 0.5899  decode.d2.loss_cls: 0.2320  decode.d2.loss_mask: 0.8878  decode.d2.loss_dice: 0.5798  decode.d3.loss_cls: 0.2211  decode.d3.loss_mask: 0.9192  decode.d3.loss_dice: 0.5984  decode.d4.loss_cls: 0.2466  decode.d4.loss_mask: 0.8996  decode.d4.loss_dice: 0.5837  decode.d5.loss_cls: 0.2245  decode.d5.loss_mask: 0.9879  decode.d5.loss_dice: 0.6411  decode.d6.loss_cls: 0.2207  decode.d6.loss_mask: 0.9277  decode.d6.loss_dice: 0.6060  decode.d7.loss_cls: 0.2211  decode.d7.loss_mask: 0.8952  decode.d7.loss_dice: 0.5912  decode.d8.loss_cls: 0.2142  decode.d8.loss_mask: 0.8865  decode.d8.loss_dice: 0.5824
05/27 04:13:53 - mmengine - INFO - Iter(train) [145450/160000]  base_lr: 1.1558e-05 lr: 1.1558e-06  eta: 1:40:24  time: 0.4178  data_time: 0.0100  memory: 5967  grad_norm: 466.8964  loss: 14.9419  decode.loss_cls: 0.0315  decode.loss_mask: 0.8482  decode.loss_dice: 0.5717  decode.d0.loss_cls: 0.4683  decode.d0.loss_mask: 0.8421  decode.d0.loss_dice: 0.5766  decode.d1.loss_cls: 0.0343  decode.d1.loss_mask: 0.8454  decode.d1.loss_dice: 0.5783  decode.d2.loss_cls: 0.0339  decode.d2.loss_mask: 0.8397  decode.d2.loss_dice: 0.5693  decode.d3.loss_cls: 0.0360  decode.d3.loss_mask: 0.8455  decode.d3.loss_dice: 0.5756  decode.d4.loss_cls: 0.0351  decode.d4.loss_mask: 0.8418  decode.d4.loss_dice: 0.5697  decode.d5.loss_cls: 0.0311  decode.d5.loss_mask: 0.8429  decode.d5.loss_dice: 0.5762  decode.d6.loss_cls: 0.0337  decode.d6.loss_mask: 0.8423  decode.d6.loss_dice: 0.5746  decode.d7.loss_cls: 0.0323  decode.d7.loss_mask: 0.8496  decode.d7.loss_dice: 0.5752  decode.d8.loss_cls: 0.0306  decode.d8.loss_mask: 0.8406  decode.d8.loss_dice: 0.5697
05/27 04:14:14 - mmengine - INFO - Iter(train) [145500/160000]  base_lr: 1.1522e-05 lr: 1.1522e-06  eta: 1:40:03  time: 0.4180  data_time: 0.0100  memory: 5966  grad_norm: 828.5261  loss: 19.9360  decode.loss_cls: 0.1947  decode.loss_mask: 1.0747  decode.loss_dice: 0.6739  decode.d0.loss_cls: 0.8093  decode.d0.loss_mask: 1.0338  decode.d0.loss_dice: 0.6786  decode.d1.loss_cls: 0.2114  decode.d1.loss_mask: 1.0587  decode.d1.loss_dice: 0.7006  decode.d2.loss_cls: 0.1933  decode.d2.loss_mask: 1.0358  decode.d2.loss_dice: 0.6726  decode.d3.loss_cls: 0.1801  decode.d3.loss_mask: 1.0430  decode.d3.loss_dice: 0.6776  decode.d4.loss_cls: 0.1980  decode.d4.loss_mask: 1.0592  decode.d4.loss_dice: 0.6769  decode.d5.loss_cls: 0.2080  decode.d5.loss_mask: 1.0694  decode.d5.loss_dice: 0.6793  decode.d6.loss_cls: 0.1600  decode.d6.loss_mask: 1.0805  decode.d6.loss_dice: 0.6851  decode.d7.loss_cls: 0.1868  decode.d7.loss_mask: 1.0923  decode.d7.loss_dice: 0.6907  decode.d8.loss_cls: 0.1807  decode.d8.loss_mask: 1.0572  decode.d8.loss_dice: 0.6736
05/27 04:14:35 - mmengine - INFO - Iter(train) [145550/160000]  base_lr: 1.1486e-05 lr: 1.1486e-06  eta: 1:39:43  time: 0.4176  data_time: 0.0100  memory: 5965  grad_norm: 255.9831  loss: 12.7631  decode.loss_cls: 0.0754  decode.loss_mask: 0.6583  decode.loss_dice: 0.4766  decode.d0.loss_cls: 0.5412  decode.d0.loss_mask: 0.6504  decode.d0.loss_dice: 0.5208  decode.d1.loss_cls: 0.1143  decode.d1.loss_mask: 0.6452  decode.d1.loss_dice: 0.4687  decode.d2.loss_cls: 0.0995  decode.d2.loss_mask: 0.6457  decode.d2.loss_dice: 0.4607  decode.d3.loss_cls: 0.1014  decode.d3.loss_mask: 0.6505  decode.d3.loss_dice: 0.4735  decode.d4.loss_cls: 0.1124  decode.d4.loss_mask: 0.6589  decode.d4.loss_dice: 0.4580  decode.d5.loss_cls: 0.0888  decode.d5.loss_mask: 0.6774  decode.d5.loss_dice: 0.4821  decode.d6.loss_cls: 0.1067  decode.d6.loss_mask: 0.6506  decode.d6.loss_dice: 0.4817  decode.d7.loss_cls: 0.0864  decode.d7.loss_mask: 0.6668  decode.d7.loss_dice: 0.4875  decode.d8.loss_cls: 0.0829  decode.d8.loss_mask: 0.6608  decode.d8.loss_dice: 0.4798
05/27 04:14:56 - mmengine - INFO - Iter(train) [145600/160000]  base_lr: 1.1450e-05 lr: 1.1450e-06  eta: 1:39:22  time: 0.4180  data_time: 0.0100  memory: 5980  grad_norm: 868.0338  loss: 20.0675  decode.loss_cls: 0.1771  decode.loss_mask: 1.0829  decode.loss_dice: 0.7019  decode.d0.loss_cls: 0.7418  decode.d0.loss_mask: 1.0748  decode.d0.loss_dice: 0.6842  decode.d1.loss_cls: 0.1305  decode.d1.loss_mask: 1.1143  decode.d1.loss_dice: 0.7377  decode.d2.loss_cls: 0.1254  decode.d2.loss_mask: 1.1094  decode.d2.loss_dice: 0.7042  decode.d3.loss_cls: 0.1728  decode.d3.loss_mask: 1.0788  decode.d3.loss_dice: 0.6885  decode.d4.loss_cls: 0.1670  decode.d4.loss_mask: 1.1336  decode.d4.loss_dice: 0.7341  decode.d5.loss_cls: 0.1695  decode.d5.loss_mask: 1.0576  decode.d5.loss_dice: 0.7047  decode.d6.loss_cls: 0.1289  decode.d6.loss_mask: 1.0783  decode.d6.loss_dice: 0.7092  decode.d7.loss_cls: 0.1823  decode.d7.loss_mask: 1.0662  decode.d7.loss_dice: 0.7031  decode.d8.loss_cls: 0.1702  decode.d8.loss_mask: 1.0408  decode.d8.loss_dice: 0.6976
05/27 04:15:17 - mmengine - INFO - Iter(train) [145650/160000]  base_lr: 1.1415e-05 lr: 1.1415e-06  eta: 1:39:01  time: 0.4188  data_time: 0.0101  memory: 5973  grad_norm: 658.2185  loss: 21.8029  decode.loss_cls: 0.1387  decode.loss_mask: 1.1734  decode.loss_dice: 0.8124  decode.d0.loss_cls: 0.7879  decode.d0.loss_mask: 1.0330  decode.d0.loss_dice: 0.7817  decode.d1.loss_cls: 0.1886  decode.d1.loss_mask: 1.1354  decode.d1.loss_dice: 0.8233  decode.d2.loss_cls: 0.1876  decode.d2.loss_mask: 1.1605  decode.d2.loss_dice: 0.8184  decode.d3.loss_cls: 0.1775  decode.d3.loss_mask: 1.1373  decode.d3.loss_dice: 0.8239  decode.d4.loss_cls: 0.2356  decode.d4.loss_mask: 1.1391  decode.d4.loss_dice: 0.8207  decode.d5.loss_cls: 0.2029  decode.d5.loss_mask: 1.1147  decode.d5.loss_dice: 0.7956  decode.d6.loss_cls: 0.1541  decode.d6.loss_mask: 1.1212  decode.d6.loss_dice: 0.7956  decode.d7.loss_cls: 0.2196  decode.d7.loss_mask: 1.1397  decode.d7.loss_dice: 0.7896  decode.d8.loss_cls: 0.2057  decode.d8.loss_mask: 1.1076  decode.d8.loss_dice: 0.7817
05/27 04:15:38 - mmengine - INFO - Iter(train) [145700/160000]  base_lr: 1.1379e-05 lr: 1.1379e-06  eta: 1:38:41  time: 0.4185  data_time: 0.0100  memory: 5980  grad_norm: 468.9183  loss: 15.3184  decode.loss_cls: 0.0876  decode.loss_mask: 0.7658  decode.loss_dice: 0.5930  decode.d0.loss_cls: 0.5489  decode.d0.loss_mask: 0.7734  decode.d0.loss_dice: 0.6018  decode.d1.loss_cls: 0.1069  decode.d1.loss_mask: 0.7909  decode.d1.loss_dice: 0.6021  decode.d2.loss_cls: 0.0972  decode.d2.loss_mask: 0.7687  decode.d2.loss_dice: 0.6033  decode.d3.loss_cls: 0.0775  decode.d3.loss_mask: 0.8032  decode.d3.loss_dice: 0.6088  decode.d4.loss_cls: 0.0790  decode.d4.loss_mask: 0.8227  decode.d4.loss_dice: 0.6128  decode.d5.loss_cls: 0.1090  decode.d5.loss_mask: 0.7709  decode.d5.loss_dice: 0.5899  decode.d6.loss_cls: 0.0807  decode.d6.loss_mask: 0.8204  decode.d6.loss_dice: 0.6120  decode.d7.loss_cls: 0.0995  decode.d7.loss_mask: 0.7778  decode.d7.loss_dice: 0.5999  decode.d8.loss_cls: 0.0835  decode.d8.loss_mask: 0.8104  decode.d8.loss_dice: 0.6208
05/27 04:15:59 - mmengine - INFO - Iter(train) [145750/160000]  base_lr: 1.1343e-05 lr: 1.1343e-06  eta: 1:38:20  time: 0.4175  data_time: 0.0100  memory: 5967  grad_norm: 324.8171  loss: 15.3253  decode.loss_cls: 0.0772  decode.loss_mask: 0.8687  decode.loss_dice: 0.5529  decode.d0.loss_cls: 0.4728  decode.d0.loss_mask: 0.8734  decode.d0.loss_dice: 0.5661  decode.d1.loss_cls: 0.0521  decode.d1.loss_mask: 0.8845  decode.d1.loss_dice: 0.5577  decode.d2.loss_cls: 0.0475  decode.d2.loss_mask: 0.8726  decode.d2.loss_dice: 0.5586  decode.d3.loss_cls: 0.0670  decode.d3.loss_mask: 0.8576  decode.d3.loss_dice: 0.5381  decode.d4.loss_cls: 0.0520  decode.d4.loss_mask: 0.8669  decode.d4.loss_dice: 0.5539  decode.d5.loss_cls: 0.0603  decode.d5.loss_mask: 0.8674  decode.d5.loss_dice: 0.5528  decode.d6.loss_cls: 0.0811  decode.d6.loss_mask: 0.8714  decode.d6.loss_dice: 0.5582  decode.d7.loss_cls: 0.0844  decode.d7.loss_mask: 0.8687  decode.d7.loss_dice: 0.5524  decode.d8.loss_cls: 0.0946  decode.d8.loss_mask: 0.8680  decode.d8.loss_dice: 0.5463
05/27 04:16:19 - mmengine - INFO - Iter(train) [145800/160000]  base_lr: 1.1307e-05 lr: 1.1307e-06  eta: 1:37:59  time: 0.4176  data_time: 0.0101  memory: 5973  grad_norm: 388.3450  loss: 21.4905  decode.loss_cls: 0.1941  decode.loss_mask: 1.1344  decode.loss_dice: 0.7560  decode.d0.loss_cls: 0.6378  decode.d0.loss_mask: 1.1327  decode.d0.loss_dice: 0.7531  decode.d1.loss_cls: 0.2587  decode.d1.loss_mask: 1.1358  decode.d1.loss_dice: 0.7462  decode.d2.loss_cls: 0.2330  decode.d2.loss_mask: 1.1364  decode.d2.loss_dice: 0.7276  decode.d3.loss_cls: 0.2031  decode.d3.loss_mask: 1.1322  decode.d3.loss_dice: 0.7437  decode.d4.loss_cls: 0.2318  decode.d4.loss_mask: 1.1267  decode.d4.loss_dice: 0.7368  decode.d5.loss_cls: 0.1584  decode.d5.loss_mask: 1.1925  decode.d5.loss_dice: 0.7576  decode.d6.loss_cls: 0.1803  decode.d6.loss_mask: 1.1807  decode.d6.loss_dice: 0.7665  decode.d7.loss_cls: 0.1827  decode.d7.loss_mask: 1.1934  decode.d7.loss_dice: 0.7701  decode.d8.loss_cls: 0.2328  decode.d8.loss_mask: 1.1251  decode.d8.loss_dice: 0.7302
05/27 04:16:40 - mmengine - INFO - Iter(train) [145850/160000]  base_lr: 1.1271e-05 lr: 1.1271e-06  eta: 1:37:39  time: 0.4200  data_time: 0.0101  memory: 5967  grad_norm: 455.1626  loss: 18.4137  decode.loss_cls: 0.0918  decode.loss_mask: 0.9620  decode.loss_dice: 0.7138  decode.d0.loss_cls: 0.7041  decode.d0.loss_mask: 0.9289  decode.d0.loss_dice: 0.6873  decode.d1.loss_cls: 0.1201  decode.d1.loss_mask: 0.9508  decode.d1.loss_dice: 0.7172  decode.d2.loss_cls: 0.1292  decode.d2.loss_mask: 0.9330  decode.d2.loss_dice: 0.7051  decode.d3.loss_cls: 0.1489  decode.d3.loss_mask: 0.9552  decode.d3.loss_dice: 0.6899  decode.d4.loss_cls: 0.0990  decode.d4.loss_mask: 0.9749  decode.d4.loss_dice: 0.7163  decode.d5.loss_cls: 0.0967  decode.d5.loss_mask: 0.9615  decode.d5.loss_dice: 0.7261  decode.d6.loss_cls: 0.1297  decode.d6.loss_mask: 0.9541  decode.d6.loss_dice: 0.7191  decode.d7.loss_cls: 0.1222  decode.d7.loss_mask: 0.9589  decode.d7.loss_dice: 0.7171  decode.d8.loss_cls: 0.1233  decode.d8.loss_mask: 0.9620  decode.d8.loss_dice: 0.7155
05/27 04:17:01 - mmengine - INFO - Iter(train) [145900/160000]  base_lr: 1.1235e-05 lr: 1.1235e-06  eta: 1:37:18  time: 0.4172  data_time: 0.0101  memory: 5971  grad_norm: 498.7964  loss: 18.0009  decode.loss_cls: 0.1671  decode.loss_mask: 0.8899  decode.loss_dice: 0.6619  decode.d0.loss_cls: 0.6809  decode.d0.loss_mask: 0.8685  decode.d0.loss_dice: 0.6584  decode.d1.loss_cls: 0.2473  decode.d1.loss_mask: 0.8920  decode.d1.loss_dice: 0.6623  decode.d2.loss_cls: 0.1889  decode.d2.loss_mask: 0.8777  decode.d2.loss_dice: 0.6907  decode.d3.loss_cls: 0.1683  decode.d3.loss_mask: 0.8889  decode.d3.loss_dice: 0.6756  decode.d4.loss_cls: 0.1896  decode.d4.loss_mask: 0.8998  decode.d4.loss_dice: 0.6992  decode.d5.loss_cls: 0.1874  decode.d5.loss_mask: 0.8823  decode.d5.loss_dice: 0.6676  decode.d6.loss_cls: 0.2050  decode.d6.loss_mask: 0.8847  decode.d6.loss_dice: 0.6883  decode.d7.loss_cls: 0.1750  decode.d7.loss_mask: 0.8793  decode.d7.loss_dice: 0.6811  decode.d8.loss_cls: 0.1801  decode.d8.loss_mask: 0.8864  decode.d8.loss_dice: 0.6767
05/27 04:17:22 - mmengine - INFO - Iter(train) [145950/160000]  base_lr: 1.1200e-05 lr: 1.1200e-06  eta: 1:36:57  time: 0.4182  data_time: 0.0100  memory: 5966  grad_norm: 481.5679  loss: 15.6346  decode.loss_cls: 0.1377  decode.loss_mask: 0.8008  decode.loss_dice: 0.5601  decode.d0.loss_cls: 0.6457  decode.d0.loss_mask: 0.7724  decode.d0.loss_dice: 0.5513  decode.d1.loss_cls: 0.1261  decode.d1.loss_mask: 0.8279  decode.d1.loss_dice: 0.6055  decode.d2.loss_cls: 0.1376  decode.d2.loss_mask: 0.8103  decode.d2.loss_dice: 0.5838  decode.d3.loss_cls: 0.1564  decode.d3.loss_mask: 0.8013  decode.d3.loss_dice: 0.5335  decode.d4.loss_cls: 0.1258  decode.d4.loss_mask: 0.8134  decode.d4.loss_dice: 0.5858  decode.d5.loss_cls: 0.1330  decode.d5.loss_mask: 0.8172  decode.d5.loss_dice: 0.5857  decode.d6.loss_cls: 0.1437  decode.d6.loss_mask: 0.7951  decode.d6.loss_dice: 0.5636  decode.d7.loss_cls: 0.1553  decode.d7.loss_mask: 0.7968  decode.d7.loss_dice: 0.5574  decode.d8.loss_cls: 0.1269  decode.d8.loss_mask: 0.8087  decode.d8.loss_dice: 0.5759
05/27 04:17:43 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 04:17:43 - mmengine - INFO - Iter(train) [146000/160000]  base_lr: 1.1164e-05 lr: 1.1164e-06  eta: 1:36:37  time: 0.4177  data_time: 0.0100  memory: 5966  grad_norm: 878.7701  loss: 19.5977  decode.loss_cls: 0.1957  decode.loss_mask: 1.0337  decode.loss_dice: 0.7231  decode.d0.loss_cls: 0.7214  decode.d0.loss_mask: 0.9367  decode.d0.loss_dice: 0.6520  decode.d1.loss_cls: 0.2191  decode.d1.loss_mask: 0.9749  decode.d1.loss_dice: 0.7148  decode.d2.loss_cls: 0.2093  decode.d2.loss_mask: 0.9838  decode.d2.loss_dice: 0.6896  decode.d3.loss_cls: 0.2254  decode.d3.loss_mask: 0.9843  decode.d3.loss_dice: 0.7051  decode.d4.loss_cls: 0.2431  decode.d4.loss_mask: 1.0065  decode.d4.loss_dice: 0.7193  decode.d5.loss_cls: 0.2194  decode.d5.loss_mask: 1.0198  decode.d5.loss_dice: 0.7253  decode.d6.loss_cls: 0.2333  decode.d6.loss_mask: 0.9814  decode.d6.loss_dice: 0.6834  decode.d7.loss_cls: 0.2481  decode.d7.loss_mask: 0.9752  decode.d7.loss_dice: 0.6840  decode.d8.loss_cls: 0.2236  decode.d8.loss_mask: 0.9963  decode.d8.loss_dice: 0.6699
05/27 04:18:04 - mmengine - INFO - Iter(train) [146050/160000]  base_lr: 1.1128e-05 lr: 1.1128e-06  eta: 1:36:16  time: 0.4179  data_time: 0.0100  memory: 5966  grad_norm: 634.6059  loss: 19.5936  decode.loss_cls: 0.0811  decode.loss_mask: 1.0455  decode.loss_dice: 0.7531  decode.d0.loss_cls: 0.5486  decode.d0.loss_mask: 1.0414  decode.d0.loss_dice: 0.7340  decode.d1.loss_cls: 0.0803  decode.d1.loss_mask: 1.0803  decode.d1.loss_dice: 0.7655  decode.d2.loss_cls: 0.1170  decode.d2.loss_mask: 1.0722  decode.d2.loss_dice: 0.7477  decode.d3.loss_cls: 0.0927  decode.d3.loss_mask: 1.0643  decode.d3.loss_dice: 0.7458  decode.d4.loss_cls: 0.1162  decode.d4.loss_mask: 1.0647  decode.d4.loss_dice: 0.7577  decode.d5.loss_cls: 0.1347  decode.d5.loss_mask: 1.0786  decode.d5.loss_dice: 0.7319  decode.d6.loss_cls: 0.1442  decode.d6.loss_mask: 1.0536  decode.d6.loss_dice: 0.7204  decode.d7.loss_cls: 0.1003  decode.d7.loss_mask: 1.0509  decode.d7.loss_dice: 0.7575  decode.d8.loss_cls: 0.0900  decode.d8.loss_mask: 1.0666  decode.d8.loss_dice: 0.7567
05/27 04:18:25 - mmengine - INFO - Iter(train) [146100/160000]  base_lr: 1.1092e-05 lr: 1.1092e-06  eta: 1:35:55  time: 0.4178  data_time: 0.0101  memory: 5969  grad_norm: 463.1056  loss: 22.2470  decode.loss_cls: 0.2664  decode.loss_mask: 1.1228  decode.loss_dice: 0.8042  decode.d0.loss_cls: 0.7625  decode.d0.loss_mask: 1.0552  decode.d0.loss_dice: 0.7840  decode.d1.loss_cls: 0.2790  decode.d1.loss_mask: 1.1264  decode.d1.loss_dice: 0.8003  decode.d2.loss_cls: 0.2582  decode.d2.loss_mask: 1.1070  decode.d2.loss_dice: 0.8099  decode.d3.loss_cls: 0.2368  decode.d3.loss_mask: 1.0953  decode.d3.loss_dice: 0.7983  decode.d4.loss_cls: 0.2512  decode.d4.loss_mask: 1.1349  decode.d4.loss_dice: 0.8307  decode.d5.loss_cls: 0.2523  decode.d5.loss_mask: 1.1019  decode.d5.loss_dice: 0.7985  decode.d6.loss_cls: 0.2490  decode.d6.loss_mask: 1.1230  decode.d6.loss_dice: 0.8163  decode.d7.loss_cls: 0.2229  decode.d7.loss_mask: 1.1212  decode.d7.loss_dice: 0.8354  decode.d8.loss_cls: 0.2643  decode.d8.loss_mask: 1.1197  decode.d8.loss_dice: 0.8191
05/27 04:18:46 - mmengine - INFO - Iter(train) [146150/160000]  base_lr: 1.1056e-05 lr: 1.1056e-06  eta: 1:35:35  time: 0.4176  data_time: 0.0100  memory: 5966  grad_norm: 503.1370  loss: 20.4542  decode.loss_cls: 0.2428  decode.loss_mask: 1.0678  decode.loss_dice: 0.7105  decode.d0.loss_cls: 0.7881  decode.d0.loss_mask: 1.0157  decode.d0.loss_dice: 0.7022  decode.d1.loss_cls: 0.2230  decode.d1.loss_mask: 1.0425  decode.d1.loss_dice: 0.7029  decode.d2.loss_cls: 0.2232  decode.d2.loss_mask: 1.0371  decode.d2.loss_dice: 0.6843  decode.d3.loss_cls: 0.2324  decode.d3.loss_mask: 1.0397  decode.d3.loss_dice: 0.6939  decode.d4.loss_cls: 0.2227  decode.d4.loss_mask: 1.0597  decode.d4.loss_dice: 0.7151  decode.d5.loss_cls: 0.2044  decode.d5.loss_mask: 1.0717  decode.d5.loss_dice: 0.7137  decode.d6.loss_cls: 0.2037  decode.d6.loss_mask: 1.1172  decode.d6.loss_dice: 0.7432  decode.d7.loss_cls: 0.2112  decode.d7.loss_mask: 1.0697  decode.d7.loss_dice: 0.7328  decode.d8.loss_cls: 0.2148  decode.d8.loss_mask: 1.0674  decode.d8.loss_dice: 0.7007
05/27 04:19:07 - mmengine - INFO - Iter(train) [146200/160000]  base_lr: 1.1020e-05 lr: 1.1020e-06  eta: 1:35:14  time: 0.4197  data_time: 0.0100  memory: 5965  grad_norm: 598.5909  loss: 19.5482  decode.loss_cls: 0.1671  decode.loss_mask: 1.0509  decode.loss_dice: 0.7103  decode.d0.loss_cls: 0.6901  decode.d0.loss_mask: 0.9376  decode.d0.loss_dice: 0.6585  decode.d1.loss_cls: 0.1302  decode.d1.loss_mask: 1.0656  decode.d1.loss_dice: 0.6881  decode.d2.loss_cls: 0.1523  decode.d2.loss_mask: 1.0648  decode.d2.loss_dice: 0.6935  decode.d3.loss_cls: 0.1282  decode.d3.loss_mask: 1.0578  decode.d3.loss_dice: 0.7011  decode.d4.loss_cls: 0.1608  decode.d4.loss_mask: 1.0675  decode.d4.loss_dice: 0.7210  decode.d5.loss_cls: 0.1423  decode.d5.loss_mask: 1.0789  decode.d5.loss_dice: 0.7048  decode.d6.loss_cls: 0.1393  decode.d6.loss_mask: 1.0691  decode.d6.loss_dice: 0.7052  decode.d7.loss_cls: 0.1517  decode.d7.loss_mask: 1.0682  decode.d7.loss_dice: 0.7183  decode.d8.loss_cls: 0.1545  decode.d8.loss_mask: 1.0577  decode.d8.loss_dice: 0.7126
05/27 04:19:28 - mmengine - INFO - Iter(train) [146250/160000]  base_lr: 1.0984e-05 lr: 1.0984e-06  eta: 1:34:53  time: 0.4182  data_time: 0.0102  memory: 5975  grad_norm: 1467.7468  loss: 18.0676  decode.loss_cls: 0.1474  decode.loss_mask: 0.8662  decode.loss_dice: 0.7109  decode.d0.loss_cls: 0.6629  decode.d0.loss_mask: 0.8292  decode.d0.loss_dice: 0.7262  decode.d1.loss_cls: 0.1780  decode.d1.loss_mask: 0.8941  decode.d1.loss_dice: 0.7125  decode.d2.loss_cls: 0.1721  decode.d2.loss_mask: 0.8766  decode.d2.loss_dice: 0.7043  decode.d3.loss_cls: 0.1712  decode.d3.loss_mask: 0.8768  decode.d3.loss_dice: 0.7160  decode.d4.loss_cls: 0.1757  decode.d4.loss_mask: 0.8873  decode.d4.loss_dice: 0.7043  decode.d5.loss_cls: 0.1584  decode.d5.loss_mask: 0.8797  decode.d5.loss_dice: 0.7169  decode.d6.loss_cls: 0.1706  decode.d6.loss_mask: 0.8796  decode.d6.loss_dice: 0.7197  decode.d7.loss_cls: 0.1619  decode.d7.loss_mask: 0.8827  decode.d7.loss_dice: 0.7207  decode.d8.loss_cls: 0.1508  decode.d8.loss_mask: 0.8837  decode.d8.loss_dice: 0.7314
05/27 04:19:49 - mmengine - INFO - Iter(train) [146300/160000]  base_lr: 1.0948e-05 lr: 1.0948e-06  eta: 1:34:32  time: 0.4183  data_time: 0.0101  memory: 5967  grad_norm: 753.4537  loss: 18.1604  decode.loss_cls: 0.1278  decode.loss_mask: 0.9288  decode.loss_dice: 0.6985  decode.d0.loss_cls: 0.7239  decode.d0.loss_mask: 0.8923  decode.d0.loss_dice: 0.6693  decode.d1.loss_cls: 0.1517  decode.d1.loss_mask: 0.9378  decode.d1.loss_dice: 0.7003  decode.d2.loss_cls: 0.1602  decode.d2.loss_mask: 0.9266  decode.d2.loss_dice: 0.6532  decode.d3.loss_cls: 0.1781  decode.d3.loss_mask: 0.9248  decode.d3.loss_dice: 0.6690  decode.d4.loss_cls: 0.1228  decode.d4.loss_mask: 0.9272  decode.d4.loss_dice: 0.7037  decode.d5.loss_cls: 0.1232  decode.d5.loss_mask: 0.9561  decode.d5.loss_dice: 0.7087  decode.d6.loss_cls: 0.1704  decode.d6.loss_mask: 0.9170  decode.d6.loss_dice: 0.6900  decode.d7.loss_cls: 0.1519  decode.d7.loss_mask: 0.9239  decode.d7.loss_dice: 0.6852  decode.d8.loss_cls: 0.1423  decode.d8.loss_mask: 0.9053  decode.d8.loss_dice: 0.6906
05/27 04:20:10 - mmengine - INFO - Iter(train) [146350/160000]  base_lr: 1.0912e-05 lr: 1.0912e-06  eta: 1:34:12  time: 0.4179  data_time: 0.0101  memory: 5966  grad_norm: 616.1285  loss: 19.1768  decode.loss_cls: 0.2381  decode.loss_mask: 0.9443  decode.loss_dice: 0.6566  decode.d0.loss_cls: 0.7222  decode.d0.loss_mask: 0.9564  decode.d0.loss_dice: 0.6549  decode.d1.loss_cls: 0.2689  decode.d1.loss_mask: 0.9553  decode.d1.loss_dice: 0.6527  decode.d2.loss_cls: 0.2196  decode.d2.loss_mask: 0.9893  decode.d2.loss_dice: 0.6655  decode.d3.loss_cls: 0.2769  decode.d3.loss_mask: 0.9510  decode.d3.loss_dice: 0.6720  decode.d4.loss_cls: 0.2840  decode.d4.loss_mask: 0.9413  decode.d4.loss_dice: 0.6549  decode.d5.loss_cls: 0.2569  decode.d5.loss_mask: 0.9686  decode.d5.loss_dice: 0.6619  decode.d6.loss_cls: 0.2532  decode.d6.loss_mask: 0.9435  decode.d6.loss_dice: 0.6555  decode.d7.loss_cls: 0.2682  decode.d7.loss_mask: 0.9460  decode.d7.loss_dice: 0.6570  decode.d8.loss_cls: 0.2535  decode.d8.loss_mask: 0.9560  decode.d8.loss_dice: 0.6527
05/27 04:20:31 - mmengine - INFO - Iter(train) [146400/160000]  base_lr: 1.0876e-05 lr: 1.0876e-06  eta: 1:33:51  time: 0.4173  data_time: 0.0101  memory: 5969  grad_norm: 586.2695  loss: 23.8609  decode.loss_cls: 0.1885  decode.loss_mask: 1.3144  decode.loss_dice: 0.8120  decode.d0.loss_cls: 0.8888  decode.d0.loss_mask: 1.1644  decode.d0.loss_dice: 0.7640  decode.d1.loss_cls: 0.2516  decode.d1.loss_mask: 1.2853  decode.d1.loss_dice: 0.7986  decode.d2.loss_cls: 0.2766  decode.d2.loss_mask: 1.2860  decode.d2.loss_dice: 0.8112  decode.d3.loss_cls: 0.2179  decode.d3.loss_mask: 1.3249  decode.d3.loss_dice: 0.7975  decode.d4.loss_cls: 0.1784  decode.d4.loss_mask: 1.3411  decode.d4.loss_dice: 0.8363  decode.d5.loss_cls: 0.2027  decode.d5.loss_mask: 1.3163  decode.d5.loss_dice: 0.8105  decode.d6.loss_cls: 0.1981  decode.d6.loss_mask: 1.3191  decode.d6.loss_dice: 0.8205  decode.d7.loss_cls: 0.2273  decode.d7.loss_mask: 1.2863  decode.d7.loss_dice: 0.8007  decode.d8.loss_cls: 0.2242  decode.d8.loss_mask: 1.3036  decode.d8.loss_dice: 0.8141
05/27 04:20:52 - mmengine - INFO - Iter(train) [146450/160000]  base_lr: 1.0840e-05 lr: 1.0840e-06  eta: 1:33:30  time: 0.4190  data_time: 0.0101  memory: 5967  grad_norm: 853.3105  loss: 17.5729  decode.loss_cls: 0.1241  decode.loss_mask: 0.9474  decode.loss_dice: 0.6183  decode.d0.loss_cls: 0.6670  decode.d0.loss_mask: 0.9086  decode.d0.loss_dice: 0.6059  decode.d1.loss_cls: 0.1603  decode.d1.loss_mask: 0.8965  decode.d1.loss_dice: 0.6108  decode.d2.loss_cls: 0.1256  decode.d2.loss_mask: 0.9718  decode.d2.loss_dice: 0.6259  decode.d3.loss_cls: 0.1500  decode.d3.loss_mask: 0.9323  decode.d3.loss_dice: 0.6336  decode.d4.loss_cls: 0.1681  decode.d4.loss_mask: 0.9141  decode.d4.loss_dice: 0.6143  decode.d5.loss_cls: 0.1345  decode.d5.loss_mask: 0.9835  decode.d5.loss_dice: 0.6593  decode.d6.loss_cls: 0.1564  decode.d6.loss_mask: 0.9312  decode.d6.loss_dice: 0.6188  decode.d7.loss_cls: 0.1520  decode.d7.loss_mask: 0.9196  decode.d7.loss_dice: 0.6241  decode.d8.loss_cls: 0.1550  decode.d8.loss_mask: 0.9340  decode.d8.loss_dice: 0.6297
05/27 04:21:13 - mmengine - INFO - Iter(train) [146500/160000]  base_lr: 1.0804e-05 lr: 1.0804e-06  eta: 1:33:10  time: 0.4179  data_time: 0.0101  memory: 5976  grad_norm: 766.3243  loss: 24.7016  decode.loss_cls: 0.2590  decode.loss_mask: 1.3701  decode.loss_dice: 0.8490  decode.d0.loss_cls: 0.7285  decode.d0.loss_mask: 1.3124  decode.d0.loss_dice: 0.7892  decode.d1.loss_cls: 0.2914  decode.d1.loss_mask: 1.3200  decode.d1.loss_dice: 0.7996  decode.d2.loss_cls: 0.3004  decode.d2.loss_mask: 1.2767  decode.d2.loss_dice: 0.7862  decode.d3.loss_cls: 0.2955  decode.d3.loss_mask: 1.3368  decode.d3.loss_dice: 0.8173  decode.d4.loss_cls: 0.2628  decode.d4.loss_mask: 1.3365  decode.d4.loss_dice: 0.7933  decode.d5.loss_cls: 0.2989  decode.d5.loss_mask: 1.3246  decode.d5.loss_dice: 0.8210  decode.d6.loss_cls: 0.2968  decode.d6.loss_mask: 1.3382  decode.d6.loss_dice: 0.8045  decode.d7.loss_cls: 0.2905  decode.d7.loss_mask: 1.3668  decode.d7.loss_dice: 0.8366  decode.d8.loss_cls: 0.2528  decode.d8.loss_mask: 1.3467  decode.d8.loss_dice: 0.7997
05/27 04:21:33 - mmengine - INFO - Iter(train) [146550/160000]  base_lr: 1.0768e-05 lr: 1.0768e-06  eta: 1:32:49  time: 0.4184  data_time: 0.0101  memory: 5967  grad_norm: 294.1988  loss: 18.0081  decode.loss_cls: 0.0994  decode.loss_mask: 0.9493  decode.loss_dice: 0.6848  decode.d0.loss_cls: 0.5420  decode.d0.loss_mask: 0.9883  decode.d0.loss_dice: 0.6975  decode.d1.loss_cls: 0.1666  decode.d1.loss_mask: 0.9764  decode.d1.loss_dice: 0.6976  decode.d2.loss_cls: 0.0976  decode.d2.loss_mask: 0.9761  decode.d2.loss_dice: 0.6949  decode.d3.loss_cls: 0.0927  decode.d3.loss_mask: 0.9610  decode.d3.loss_dice: 0.6828  decode.d4.loss_cls: 0.1089  decode.d4.loss_mask: 0.9520  decode.d4.loss_dice: 0.6805  decode.d5.loss_cls: 0.1116  decode.d5.loss_mask: 0.9504  decode.d5.loss_dice: 0.6800  decode.d6.loss_cls: 0.0877  decode.d6.loss_mask: 0.9676  decode.d6.loss_dice: 0.6839  decode.d7.loss_cls: 0.1038  decode.d7.loss_mask: 0.9531  decode.d7.loss_dice: 0.6889  decode.d8.loss_cls: 0.0953  decode.d8.loss_mask: 0.9465  decode.d8.loss_dice: 0.6910
05/27 04:21:54 - mmengine - INFO - Iter(train) [146600/160000]  base_lr: 1.0732e-05 lr: 1.0732e-06  eta: 1:32:28  time: 0.4185  data_time: 0.0101  memory: 5965  grad_norm: 700.4042  loss: 18.5535  decode.loss_cls: 0.1700  decode.loss_mask: 0.9429  decode.loss_dice: 0.6675  decode.d0.loss_cls: 0.6328  decode.d0.loss_mask: 0.9381  decode.d0.loss_dice: 0.6559  decode.d1.loss_cls: 0.1512  decode.d1.loss_mask: 0.9451  decode.d1.loss_dice: 0.6854  decode.d2.loss_cls: 0.1704  decode.d2.loss_mask: 0.9545  decode.d2.loss_dice: 0.6717  decode.d3.loss_cls: 0.1956  decode.d3.loss_mask: 0.9614  decode.d3.loss_dice: 0.6676  decode.d4.loss_cls: 0.1775  decode.d4.loss_mask: 0.9682  decode.d4.loss_dice: 0.6891  decode.d5.loss_cls: 0.1713  decode.d5.loss_mask: 0.9878  decode.d5.loss_dice: 0.6813  decode.d6.loss_cls: 0.2141  decode.d6.loss_mask: 0.9364  decode.d6.loss_dice: 0.6680  decode.d7.loss_cls: 0.2053  decode.d7.loss_mask: 0.9559  decode.d7.loss_dice: 0.6889  decode.d8.loss_cls: 0.1689  decode.d8.loss_mask: 0.9625  decode.d8.loss_dice: 0.6680
05/27 04:22:15 - mmengine - INFO - Iter(train) [146650/160000]  base_lr: 1.0696e-05 lr: 1.0696e-06  eta: 1:32:08  time: 0.4173  data_time: 0.0101  memory: 5969  grad_norm: 361.2747  loss: 18.8971  decode.loss_cls: 0.1529  decode.loss_mask: 0.9601  decode.loss_dice: 0.7194  decode.d0.loss_cls: 0.6344  decode.d0.loss_mask: 0.9483  decode.d0.loss_dice: 0.7365  decode.d1.loss_cls: 0.1683  decode.d1.loss_mask: 0.9603  decode.d1.loss_dice: 0.7349  decode.d2.loss_cls: 0.1414  decode.d2.loss_mask: 0.9670  decode.d2.loss_dice: 0.7335  decode.d3.loss_cls: 0.1495  decode.d3.loss_mask: 0.9671  decode.d3.loss_dice: 0.7160  decode.d4.loss_cls: 0.1726  decode.d4.loss_mask: 0.9478  decode.d4.loss_dice: 0.7065  decode.d5.loss_cls: 0.1606  decode.d5.loss_mask: 0.9597  decode.d5.loss_dice: 0.7263  decode.d6.loss_cls: 0.1546  decode.d6.loss_mask: 0.9607  decode.d6.loss_dice: 0.7247  decode.d7.loss_cls: 0.1496  decode.d7.loss_mask: 0.9744  decode.d7.loss_dice: 0.7248  decode.d8.loss_cls: 0.1684  decode.d8.loss_mask: 0.9486  decode.d8.loss_dice: 0.7283
05/27 04:22:36 - mmengine - INFO - Iter(train) [146700/160000]  base_lr: 1.0660e-05 lr: 1.0660e-06  eta: 1:31:47  time: 0.4179  data_time: 0.0100  memory: 5973  grad_norm: 492.5646  loss: 16.1667  decode.loss_cls: 0.1577  decode.loss_mask: 0.8328  decode.loss_dice: 0.5556  decode.d0.loss_cls: 0.5803  decode.d0.loss_mask: 0.7991  decode.d0.loss_dice: 0.5993  decode.d1.loss_cls: 0.1288  decode.d1.loss_mask: 0.8537  decode.d1.loss_dice: 0.6140  decode.d2.loss_cls: 0.1357  decode.d2.loss_mask: 0.8475  decode.d2.loss_dice: 0.6037  decode.d3.loss_cls: 0.1778  decode.d3.loss_mask: 0.8282  decode.d3.loss_dice: 0.5810  decode.d4.loss_cls: 0.1592  decode.d4.loss_mask: 0.8674  decode.d4.loss_dice: 0.5920  decode.d5.loss_cls: 0.1442  decode.d5.loss_mask: 0.8328  decode.d5.loss_dice: 0.5969  decode.d6.loss_cls: 0.1572  decode.d6.loss_mask: 0.8297  decode.d6.loss_dice: 0.5621  decode.d7.loss_cls: 0.1393  decode.d7.loss_mask: 0.8297  decode.d7.loss_dice: 0.6022  decode.d8.loss_cls: 0.1647  decode.d8.loss_mask: 0.8412  decode.d8.loss_dice: 0.5527
05/27 04:22:57 - mmengine - INFO - Iter(train) [146750/160000]  base_lr: 1.0624e-05 lr: 1.0624e-06  eta: 1:31:26  time: 0.4175  data_time: 0.0100  memory: 5973  grad_norm: 375.7225  loss: 16.6116  decode.loss_cls: 0.1595  decode.loss_mask: 0.7852  decode.loss_dice: 0.6057  decode.d0.loss_cls: 0.7328  decode.d0.loss_mask: 0.8019  decode.d0.loss_dice: 0.6269  decode.d1.loss_cls: 0.1915  decode.d1.loss_mask: 0.7951  decode.d1.loss_dice: 0.6173  decode.d2.loss_cls: 0.1765  decode.d2.loss_mask: 0.8024  decode.d2.loss_dice: 0.6158  decode.d3.loss_cls: 0.1999  decode.d3.loss_mask: 0.7898  decode.d3.loss_dice: 0.6126  decode.d4.loss_cls: 0.1981  decode.d4.loss_mask: 0.8052  decode.d4.loss_dice: 0.6273  decode.d5.loss_cls: 0.2135  decode.d5.loss_mask: 0.8103  decode.d5.loss_dice: 0.6368  decode.d6.loss_cls: 0.1781  decode.d6.loss_mask: 0.8018  decode.d6.loss_dice: 0.6298  decode.d7.loss_cls: 0.1915  decode.d7.loss_mask: 0.7995  decode.d7.loss_dice: 0.6323  decode.d8.loss_cls: 0.1752  decode.d8.loss_mask: 0.7826  decode.d8.loss_dice: 0.6168
05/27 04:23:18 - mmengine - INFO - Iter(train) [146800/160000]  base_lr: 1.0588e-05 lr: 1.0588e-06  eta: 1:31:06  time: 0.4189  data_time: 0.0100  memory: 5966  grad_norm: 411.8544  loss: 16.0791  decode.loss_cls: 0.0767  decode.loss_mask: 0.9267  decode.loss_dice: 0.5478  decode.d0.loss_cls: 0.5912  decode.d0.loss_mask: 0.8508  decode.d0.loss_dice: 0.5427  decode.d1.loss_cls: 0.0956  decode.d1.loss_mask: 0.9370  decode.d1.loss_dice: 0.5461  decode.d2.loss_cls: 0.0895  decode.d2.loss_mask: 0.9375  decode.d2.loss_dice: 0.5503  decode.d3.loss_cls: 0.0969  decode.d3.loss_mask: 0.9169  decode.d3.loss_dice: 0.5316  decode.d4.loss_cls: 0.0712  decode.d4.loss_mask: 0.9395  decode.d4.loss_dice: 0.5465  decode.d5.loss_cls: 0.0811  decode.d5.loss_mask: 0.9507  decode.d5.loss_dice: 0.5546  decode.d6.loss_cls: 0.0885  decode.d6.loss_mask: 0.9384  decode.d6.loss_dice: 0.5444  decode.d7.loss_cls: 0.0854  decode.d7.loss_mask: 0.9419  decode.d7.loss_dice: 0.5493  decode.d8.loss_cls: 0.0730  decode.d8.loss_mask: 0.9325  decode.d8.loss_dice: 0.5448
05/27 04:23:39 - mmengine - INFO - Iter(train) [146850/160000]  base_lr: 1.0552e-05 lr: 1.0552e-06  eta: 1:30:45  time: 0.4188  data_time: 0.0102  memory: 5967  grad_norm: 391.7551  loss: 19.9301  decode.loss_cls: 0.0297  decode.loss_mask: 1.1786  decode.loss_dice: 0.7415  decode.d0.loss_cls: 0.6162  decode.d0.loss_mask: 1.0842  decode.d0.loss_dice: 0.7254  decode.d1.loss_cls: 0.0598  decode.d1.loss_mask: 1.1594  decode.d1.loss_dice: 0.7284  decode.d2.loss_cls: 0.0692  decode.d2.loss_mask: 1.1424  decode.d2.loss_dice: 0.7110  decode.d3.loss_cls: 0.0375  decode.d3.loss_mask: 1.1865  decode.d3.loss_dice: 0.7277  decode.d4.loss_cls: 0.0458  decode.d4.loss_mask: 1.1639  decode.d4.loss_dice: 0.7228  decode.d5.loss_cls: 0.0344  decode.d5.loss_mask: 1.1845  decode.d5.loss_dice: 0.7324  decode.d6.loss_cls: 0.0336  decode.d6.loss_mask: 1.1840  decode.d6.loss_dice: 0.7337  decode.d7.loss_cls: 0.0499  decode.d7.loss_mask: 1.1681  decode.d7.loss_dice: 0.7260  decode.d8.loss_cls: 0.0317  decode.d8.loss_mask: 1.1778  decode.d8.loss_dice: 0.7439
05/27 04:24:00 - mmengine - INFO - Iter(train) [146900/160000]  base_lr: 1.0516e-05 lr: 1.0516e-06  eta: 1:30:24  time: 0.4176  data_time: 0.0100  memory: 5974  grad_norm: 746.8920  loss: 23.1125  decode.loss_cls: 0.2511  decode.loss_mask: 1.2424  decode.loss_dice: 0.7862  decode.d0.loss_cls: 0.6152  decode.d0.loss_mask: 1.1990  decode.d0.loss_dice: 0.8024  decode.d1.loss_cls: 0.2803  decode.d1.loss_mask: 1.2676  decode.d1.loss_dice: 0.7832  decode.d2.loss_cls: 0.2506  decode.d2.loss_mask: 1.2127  decode.d2.loss_dice: 0.7644  decode.d3.loss_cls: 0.2771  decode.d3.loss_mask: 1.2139  decode.d3.loss_dice: 0.7631  decode.d4.loss_cls: 0.2399  decode.d4.loss_mask: 1.2492  decode.d4.loss_dice: 0.7808  decode.d5.loss_cls: 0.2782  decode.d5.loss_mask: 1.2192  decode.d5.loss_dice: 0.7554  decode.d6.loss_cls: 0.2537  decode.d6.loss_mask: 1.2476  decode.d6.loss_dice: 0.8198  decode.d7.loss_cls: 0.2959  decode.d7.loss_mask: 1.2302  decode.d7.loss_dice: 0.7741  decode.d8.loss_cls: 0.2188  decode.d8.loss_mask: 1.2479  decode.d8.loss_dice: 0.7928
05/27 04:24:21 - mmengine - INFO - Iter(train) [146950/160000]  base_lr: 1.0480e-05 lr: 1.0480e-06  eta: 1:30:04  time: 0.4178  data_time: 0.0100  memory: 5976  grad_norm: 487.0012  loss: 17.1810  decode.loss_cls: 0.1979  decode.loss_mask: 0.8674  decode.loss_dice: 0.5917  decode.d0.loss_cls: 0.6055  decode.d0.loss_mask: 0.8432  decode.d0.loss_dice: 0.6284  decode.d1.loss_cls: 0.1788  decode.d1.loss_mask: 0.8818  decode.d1.loss_dice: 0.6073  decode.d2.loss_cls: 0.1694  decode.d2.loss_mask: 0.9028  decode.d2.loss_dice: 0.6173  decode.d3.loss_cls: 0.1630  decode.d3.loss_mask: 0.9058  decode.d3.loss_dice: 0.6198  decode.d4.loss_cls: 0.1998  decode.d4.loss_mask: 0.8670  decode.d4.loss_dice: 0.5970  decode.d5.loss_cls: 0.1824  decode.d5.loss_mask: 0.9052  decode.d5.loss_dice: 0.6096  decode.d6.loss_cls: 0.1936  decode.d6.loss_mask: 0.8944  decode.d6.loss_dice: 0.6217  decode.d7.loss_cls: 0.1958  decode.d7.loss_mask: 0.8700  decode.d7.loss_dice: 0.6016  decode.d8.loss_cls: 0.1876  decode.d8.loss_mask: 0.8655  decode.d8.loss_dice: 0.6097
05/27 04:24:42 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 04:24:42 - mmengine - INFO - Iter(train) [147000/160000]  base_lr: 1.0443e-05 lr: 1.0443e-06  eta: 1:29:43  time: 0.4187  data_time: 0.0101  memory: 5971  grad_norm: 605.7513  loss: 19.9790  decode.loss_cls: 0.2926  decode.loss_mask: 0.9385  decode.loss_dice: 0.7268  decode.d0.loss_cls: 0.7147  decode.d0.loss_mask: 1.0269  decode.d0.loss_dice: 0.7311  decode.d1.loss_cls: 0.2783  decode.d1.loss_mask: 0.9753  decode.d1.loss_dice: 0.6887  decode.d2.loss_cls: 0.2754  decode.d2.loss_mask: 0.9298  decode.d2.loss_dice: 0.6832  decode.d3.loss_cls: 0.2579  decode.d3.loss_mask: 0.9532  decode.d3.loss_dice: 0.7174  decode.d4.loss_cls: 0.2332  decode.d4.loss_mask: 0.9545  decode.d4.loss_dice: 0.6944  decode.d5.loss_cls: 0.2665  decode.d5.loss_mask: 0.9487  decode.d5.loss_dice: 0.7227  decode.d6.loss_cls: 0.1876  decode.d6.loss_mask: 1.0579  decode.d6.loss_dice: 0.7202  decode.d7.loss_cls: 0.2449  decode.d7.loss_mask: 1.0275  decode.d7.loss_dice: 0.7257  decode.d8.loss_cls: 0.2370  decode.d8.loss_mask: 1.0442  decode.d8.loss_dice: 0.7244
05/27 04:25:03 - mmengine - INFO - Iter(train) [147050/160000]  base_lr: 1.0407e-05 lr: 1.0407e-06  eta: 1:29:22  time: 0.4180  data_time: 0.0101  memory: 5971  grad_norm: 636.3856  loss: 21.7528  decode.loss_cls: 0.3073  decode.loss_mask: 1.0664  decode.loss_dice: 0.7719  decode.d0.loss_cls: 0.7395  decode.d0.loss_mask: 0.9718  decode.d0.loss_dice: 0.7626  decode.d1.loss_cls: 0.3404  decode.d1.loss_mask: 1.0909  decode.d1.loss_dice: 0.7728  decode.d2.loss_cls: 0.3394  decode.d2.loss_mask: 1.0319  decode.d2.loss_dice: 0.7568  decode.d3.loss_cls: 0.3048  decode.d3.loss_mask: 1.0490  decode.d3.loss_dice: 0.7667  decode.d4.loss_cls: 0.3323  decode.d4.loss_mask: 1.0353  decode.d4.loss_dice: 0.7690  decode.d5.loss_cls: 0.2939  decode.d5.loss_mask: 1.0512  decode.d5.loss_dice: 0.7788  decode.d6.loss_cls: 0.3076  decode.d6.loss_mask: 1.0654  decode.d6.loss_dice: 0.7915  decode.d7.loss_cls: 0.3203  decode.d7.loss_mask: 1.0416  decode.d7.loss_dice: 0.7674  decode.d8.loss_cls: 0.3101  decode.d8.loss_mask: 1.0450  decode.d8.loss_dice: 0.7713
05/27 04:25:24 - mmengine - INFO - Iter(train) [147100/160000]  base_lr: 1.0371e-05 lr: 1.0371e-06  eta: 1:29:01  time: 0.4187  data_time: 0.0101  memory: 5976  grad_norm: 387.9089  loss: 17.3019  decode.loss_cls: 0.1362  decode.loss_mask: 0.9165  decode.loss_dice: 0.6192  decode.d0.loss_cls: 0.7018  decode.d0.loss_mask: 0.9099  decode.d0.loss_dice: 0.6310  decode.d1.loss_cls: 0.1443  decode.d1.loss_mask: 0.9060  decode.d1.loss_dice: 0.5934  decode.d2.loss_cls: 0.1957  decode.d2.loss_mask: 0.8740  decode.d2.loss_dice: 0.5855  decode.d3.loss_cls: 0.1687  decode.d3.loss_mask: 0.8823  decode.d3.loss_dice: 0.5964  decode.d4.loss_cls: 0.1538  decode.d4.loss_mask: 0.9181  decode.d4.loss_dice: 0.5991  decode.d5.loss_cls: 0.1230  decode.d5.loss_mask: 0.9337  decode.d5.loss_dice: 0.6298  decode.d6.loss_cls: 0.1568  decode.d6.loss_mask: 0.9263  decode.d6.loss_dice: 0.6275  decode.d7.loss_cls: 0.1586  decode.d7.loss_mask: 0.9217  decode.d7.loss_dice: 0.6256  decode.d8.loss_cls: 0.1283  decode.d8.loss_mask: 0.9180  decode.d8.loss_dice: 0.6207
05/27 04:25:45 - mmengine - INFO - Iter(train) [147150/160000]  base_lr: 1.0335e-05 lr: 1.0335e-06  eta: 1:28:41  time: 0.4183  data_time: 0.0100  memory: 5973  grad_norm: 401.0427  loss: 16.1030  decode.loss_cls: 0.1463  decode.loss_mask: 0.7728  decode.loss_dice: 0.6270  decode.d0.loss_cls: 0.6489  decode.d0.loss_mask: 0.7431  decode.d0.loss_dice: 0.6095  decode.d1.loss_cls: 0.1625  decode.d1.loss_mask: 0.7947  decode.d1.loss_dice: 0.6385  decode.d2.loss_cls: 0.1471  decode.d2.loss_mask: 0.7760  decode.d2.loss_dice: 0.6282  decode.d3.loss_cls: 0.1426  decode.d3.loss_mask: 0.7941  decode.d3.loss_dice: 0.6333  decode.d4.loss_cls: 0.1336  decode.d4.loss_mask: 0.7939  decode.d4.loss_dice: 0.6515  decode.d5.loss_cls: 0.1343  decode.d5.loss_mask: 0.7951  decode.d5.loss_dice: 0.6304  decode.d6.loss_cls: 0.1395  decode.d6.loss_mask: 0.7753  decode.d6.loss_dice: 0.6568  decode.d7.loss_cls: 0.1338  decode.d7.loss_mask: 0.7860  decode.d7.loss_dice: 0.6304  decode.d8.loss_cls: 0.1305  decode.d8.loss_mask: 0.8158  decode.d8.loss_dice: 0.6314
05/27 04:26:06 - mmengine - INFO - Iter(train) [147200/160000]  base_lr: 1.0299e-05 lr: 1.0299e-06  eta: 1:28:20  time: 0.4181  data_time: 0.0100  memory: 5969  grad_norm: 314.2914  loss: 17.0246  decode.loss_cls: 0.1855  decode.loss_mask: 0.8052  decode.loss_dice: 0.6524  decode.d0.loss_cls: 0.7385  decode.d0.loss_mask: 0.7859  decode.d0.loss_dice: 0.6426  decode.d1.loss_cls: 0.1750  decode.d1.loss_mask: 0.8239  decode.d1.loss_dice: 0.6574  decode.d2.loss_cls: 0.1989  decode.d2.loss_mask: 0.8113  decode.d2.loss_dice: 0.6446  decode.d3.loss_cls: 0.1691  decode.d3.loss_mask: 0.8145  decode.d3.loss_dice: 0.6380  decode.d4.loss_cls: 0.1818  decode.d4.loss_mask: 0.8303  decode.d4.loss_dice: 0.6514  decode.d5.loss_cls: 0.1894  decode.d5.loss_mask: 0.8305  decode.d5.loss_dice: 0.6481  decode.d6.loss_cls: 0.1838  decode.d6.loss_mask: 0.8098  decode.d6.loss_dice: 0.6456  decode.d7.loss_cls: 0.1801  decode.d7.loss_mask: 0.8213  decode.d7.loss_dice: 0.6521  decode.d8.loss_cls: 0.1915  decode.d8.loss_mask: 0.8064  decode.d8.loss_dice: 0.6598
05/27 04:26:27 - mmengine - INFO - Iter(train) [147250/160000]  base_lr: 1.0263e-05 lr: 1.0263e-06  eta: 1:27:59  time: 0.4183  data_time: 0.0101  memory: 5979  grad_norm: 449.6484  loss: 16.5380  decode.loss_cls: 0.1079  decode.loss_mask: 0.8604  decode.loss_dice: 0.6179  decode.d0.loss_cls: 0.6437  decode.d0.loss_mask: 0.8322  decode.d0.loss_dice: 0.6102  decode.d1.loss_cls: 0.1546  decode.d1.loss_mask: 0.8424  decode.d1.loss_dice: 0.6165  decode.d2.loss_cls: 0.1447  decode.d2.loss_mask: 0.8380  decode.d2.loss_dice: 0.6223  decode.d3.loss_cls: 0.1279  decode.d3.loss_mask: 0.8560  decode.d3.loss_dice: 0.6274  decode.d4.loss_cls: 0.1475  decode.d4.loss_mask: 0.8649  decode.d4.loss_dice: 0.6206  decode.d5.loss_cls: 0.1284  decode.d5.loss_mask: 0.8689  decode.d5.loss_dice: 0.6288  decode.d6.loss_cls: 0.1475  decode.d6.loss_mask: 0.8402  decode.d6.loss_dice: 0.6244  decode.d7.loss_cls: 0.1189  decode.d7.loss_mask: 0.8533  decode.d7.loss_dice: 0.6213  decode.d8.loss_cls: 0.1084  decode.d8.loss_mask: 0.8435  decode.d8.loss_dice: 0.6192
05/27 04:26:48 - mmengine - INFO - Iter(train) [147300/160000]  base_lr: 1.0226e-05 lr: 1.0226e-06  eta: 1:27:39  time: 0.4192  data_time: 0.0100  memory: 5974  grad_norm: 468.4122  loss: 16.9373  decode.loss_cls: 0.1200  decode.loss_mask: 0.8258  decode.loss_dice: 0.6755  decode.d0.loss_cls: 0.6326  decode.d0.loss_mask: 0.8337  decode.d0.loss_dice: 0.6923  decode.d1.loss_cls: 0.1237  decode.d1.loss_mask: 0.8443  decode.d1.loss_dice: 0.6870  decode.d2.loss_cls: 0.1554  decode.d2.loss_mask: 0.8636  decode.d2.loss_dice: 0.6868  decode.d3.loss_cls: 0.1344  decode.d3.loss_mask: 0.8133  decode.d3.loss_dice: 0.6537  decode.d4.loss_cls: 0.1244  decode.d4.loss_mask: 0.8514  decode.d4.loss_dice: 0.6706  decode.d5.loss_cls: 0.1459  decode.d5.loss_mask: 0.8227  decode.d5.loss_dice: 0.6527  decode.d6.loss_cls: 0.1341  decode.d6.loss_mask: 0.8392  decode.d6.loss_dice: 0.6594  decode.d7.loss_cls: 0.1294  decode.d7.loss_mask: 0.8438  decode.d7.loss_dice: 0.6832  decode.d8.loss_cls: 0.1238  decode.d8.loss_mask: 0.8407  decode.d8.loss_dice: 0.6740
05/27 04:27:09 - mmengine - INFO - Iter(train) [147350/160000]  base_lr: 1.0190e-05 lr: 1.0190e-06  eta: 1:27:18  time: 0.4209  data_time: 0.0101  memory: 5981  grad_norm: 763.3591  loss: 15.4359  decode.loss_cls: 0.0616  decode.loss_mask: 0.8420  decode.loss_dice: 0.5863  decode.d0.loss_cls: 0.4662  decode.d0.loss_mask: 0.8497  decode.d0.loss_dice: 0.6085  decode.d1.loss_cls: 0.0458  decode.d1.loss_mask: 0.8517  decode.d1.loss_dice: 0.6044  decode.d2.loss_cls: 0.0842  decode.d2.loss_mask: 0.8355  decode.d2.loss_dice: 0.5862  decode.d3.loss_cls: 0.0673  decode.d3.loss_mask: 0.8390  decode.d3.loss_dice: 0.5891  decode.d4.loss_cls: 0.0648  decode.d4.loss_mask: 0.8326  decode.d4.loss_dice: 0.5813  decode.d5.loss_cls: 0.0569  decode.d5.loss_mask: 0.8413  decode.d5.loss_dice: 0.5842  decode.d6.loss_cls: 0.0844  decode.d6.loss_mask: 0.8521  decode.d6.loss_dice: 0.5997  decode.d7.loss_cls: 0.0824  decode.d7.loss_mask: 0.8389  decode.d7.loss_dice: 0.5921  decode.d8.loss_cls: 0.0692  decode.d8.loss_mask: 0.8463  decode.d8.loss_dice: 0.5921
05/27 04:27:30 - mmengine - INFO - Iter(train) [147400/160000]  base_lr: 1.0154e-05 lr: 1.0154e-06  eta: 1:26:57  time: 0.4184  data_time: 0.0100  memory: 5967  grad_norm: 753.6456  loss: 20.1612  decode.loss_cls: 0.2695  decode.loss_mask: 0.9692  decode.loss_dice: 0.7511  decode.d0.loss_cls: 0.7615  decode.d0.loss_mask: 0.9876  decode.d0.loss_dice: 0.7370  decode.d1.loss_cls: 0.2913  decode.d1.loss_mask: 0.9937  decode.d1.loss_dice: 0.7499  decode.d2.loss_cls: 0.2178  decode.d2.loss_mask: 0.9919  decode.d2.loss_dice: 0.7454  decode.d3.loss_cls: 0.2207  decode.d3.loss_mask: 0.9762  decode.d3.loss_dice: 0.7267  decode.d4.loss_cls: 0.2188  decode.d4.loss_mask: 0.9919  decode.d4.loss_dice: 0.7404  decode.d5.loss_cls: 0.2828  decode.d5.loss_mask: 0.9722  decode.d5.loss_dice: 0.7329  decode.d6.loss_cls: 0.2585  decode.d6.loss_mask: 0.9621  decode.d6.loss_dice: 0.7326  decode.d7.loss_cls: 0.2360  decode.d7.loss_mask: 0.9623  decode.d7.loss_dice: 0.7396  decode.d8.loss_cls: 0.2678  decode.d8.loss_mask: 0.9503  decode.d8.loss_dice: 0.7232
05/27 04:27:51 - mmengine - INFO - Iter(train) [147450/160000]  base_lr: 1.0118e-05 lr: 1.0118e-06  eta: 1:26:37  time: 0.4190  data_time: 0.0101  memory: 5965  grad_norm: 677.2774  loss: 17.4533  decode.loss_cls: 0.0763  decode.loss_mask: 0.9591  decode.loss_dice: 0.6548  decode.d0.loss_cls: 0.5949  decode.d0.loss_mask: 0.9276  decode.d0.loss_dice: 0.6769  decode.d1.loss_cls: 0.0975  decode.d1.loss_mask: 0.9580  decode.d1.loss_dice: 0.6599  decode.d2.loss_cls: 0.0878  decode.d2.loss_mask: 0.9492  decode.d2.loss_dice: 0.6499  decode.d3.loss_cls: 0.0586  decode.d3.loss_mask: 0.9690  decode.d3.loss_dice: 0.6697  decode.d4.loss_cls: 0.0836  decode.d4.loss_mask: 0.9705  decode.d4.loss_dice: 0.6588  decode.d5.loss_cls: 0.0765  decode.d5.loss_mask: 0.9412  decode.d5.loss_dice: 0.6635  decode.d6.loss_cls: 0.0744  decode.d6.loss_mask: 0.9436  decode.d6.loss_dice: 0.6594  decode.d7.loss_cls: 0.0544  decode.d7.loss_mask: 0.9733  decode.d7.loss_dice: 0.6615  decode.d8.loss_cls: 0.0750  decode.d8.loss_mask: 0.9703  decode.d8.loss_dice: 0.6582
05/27 04:28:12 - mmengine - INFO - Iter(train) [147500/160000]  base_lr: 1.0081e-05 lr: 1.0081e-06  eta: 1:26:16  time: 0.4197  data_time: 0.0101  memory: 5970  grad_norm: 897.2053  loss: 18.2332  decode.loss_cls: 0.2733  decode.loss_mask: 0.8141  decode.loss_dice: 0.6809  decode.d0.loss_cls: 0.8524  decode.d0.loss_mask: 0.7767  decode.d0.loss_dice: 0.6626  decode.d1.loss_cls: 0.3098  decode.d1.loss_mask: 0.8058  decode.d1.loss_dice: 0.6817  decode.d2.loss_cls: 0.2918  decode.d2.loss_mask: 0.7958  decode.d2.loss_dice: 0.6882  decode.d3.loss_cls: 0.3264  decode.d3.loss_mask: 0.8131  decode.d3.loss_dice: 0.6618  decode.d4.loss_cls: 0.3211  decode.d4.loss_mask: 0.7929  decode.d4.loss_dice: 0.6642  decode.d5.loss_cls: 0.2559  decode.d5.loss_mask: 0.8054  decode.d5.loss_dice: 0.6763  decode.d6.loss_cls: 0.3104  decode.d6.loss_mask: 0.7852  decode.d6.loss_dice: 0.6638  decode.d7.loss_cls: 0.2792  decode.d7.loss_mask: 0.7948  decode.d7.loss_dice: 0.6590  decode.d8.loss_cls: 0.3187  decode.d8.loss_mask: 0.8070  decode.d8.loss_dice: 0.6648
05/27 04:28:33 - mmengine - INFO - Iter(train) [147550/160000]  base_lr: 1.0045e-05 lr: 1.0045e-06  eta: 1:25:55  time: 0.4188  data_time: 0.0100  memory: 5980  grad_norm: 686.3416  loss: 20.7642  decode.loss_cls: 0.1685  decode.loss_mask: 1.1209  decode.loss_dice: 0.7440  decode.d0.loss_cls: 0.7908  decode.d0.loss_mask: 1.0062  decode.d0.loss_dice: 0.7010  decode.d1.loss_cls: 0.1562  decode.d1.loss_mask: 1.1347  decode.d1.loss_dice: 0.7494  decode.d2.loss_cls: 0.1834  decode.d2.loss_mask: 1.0991  decode.d2.loss_dice: 0.7421  decode.d3.loss_cls: 0.2099  decode.d3.loss_mask: 1.0956  decode.d3.loss_dice: 0.7278  decode.d4.loss_cls: 0.2221  decode.d4.loss_mask: 1.1129  decode.d4.loss_dice: 0.7258  decode.d5.loss_cls: 0.2075  decode.d5.loss_mask: 1.1048  decode.d5.loss_dice: 0.7243  decode.d6.loss_cls: 0.2085  decode.d6.loss_mask: 1.0806  decode.d6.loss_dice: 0.7268  decode.d7.loss_cls: 0.1836  decode.d7.loss_mask: 1.1043  decode.d7.loss_dice: 0.7299  decode.d8.loss_cls: 0.1938  decode.d8.loss_mask: 1.0948  decode.d8.loss_dice: 0.7149
05/27 04:28:54 - mmengine - INFO - Iter(train) [147600/160000]  base_lr: 1.0009e-05 lr: 1.0009e-06  eta: 1:25:35  time: 0.4180  data_time: 0.0100  memory: 5970  grad_norm: 234.7373  loss: 14.3848  decode.loss_cls: 0.1255  decode.loss_mask: 0.7435  decode.loss_dice: 0.5256  decode.d0.loss_cls: 0.5393  decode.d0.loss_mask: 0.7409  decode.d0.loss_dice: 0.5083  decode.d1.loss_cls: 0.1527  decode.d1.loss_mask: 0.7347  decode.d1.loss_dice: 0.5028  decode.d2.loss_cls: 0.1343  decode.d2.loss_mask: 0.7415  decode.d2.loss_dice: 0.5255  decode.d3.loss_cls: 0.1311  decode.d3.loss_mask: 0.7463  decode.d3.loss_dice: 0.5317  decode.d4.loss_cls: 0.1546  decode.d4.loss_mask: 0.7410  decode.d4.loss_dice: 0.5082  decode.d5.loss_cls: 0.1265  decode.d5.loss_mask: 0.7397  decode.d5.loss_dice: 0.5312  decode.d6.loss_cls: 0.1179  decode.d6.loss_mask: 0.7434  decode.d6.loss_dice: 0.5396  decode.d7.loss_cls: 0.1213  decode.d7.loss_mask: 0.7441  decode.d7.loss_dice: 0.5320  decode.d8.loss_cls: 0.1303  decode.d8.loss_mask: 0.7437  decode.d8.loss_dice: 0.5278
05/27 04:29:14 - mmengine - INFO - Iter(train) [147650/160000]  base_lr: 9.9723e-06 lr: 9.9723e-07  eta: 1:25:14  time: 0.4192  data_time: 0.0100  memory: 5966  grad_norm: 552.6983  loss: 18.5306  decode.loss_cls: 0.1877  decode.loss_mask: 0.9843  decode.loss_dice: 0.6400  decode.d0.loss_cls: 0.6374  decode.d0.loss_mask: 1.0668  decode.d0.loss_dice: 0.6298  decode.d1.loss_cls: 0.2036  decode.d1.loss_mask: 0.9927  decode.d1.loss_dice: 0.6657  decode.d2.loss_cls: 0.1870  decode.d2.loss_mask: 0.9805  decode.d2.loss_dice: 0.6393  decode.d3.loss_cls: 0.1694  decode.d3.loss_mask: 1.0042  decode.d3.loss_dice: 0.6313  decode.d4.loss_cls: 0.1378  decode.d4.loss_mask: 0.9963  decode.d4.loss_dice: 0.6417  decode.d5.loss_cls: 0.1561  decode.d5.loss_mask: 0.9963  decode.d5.loss_dice: 0.6489  decode.d6.loss_cls: 0.1808  decode.d6.loss_mask: 0.9751  decode.d6.loss_dice: 0.6252  decode.d7.loss_cls: 0.1752  decode.d7.loss_mask: 0.9852  decode.d7.loss_dice: 0.6191  decode.d8.loss_cls: 0.1806  decode.d8.loss_mask: 0.9744  decode.d8.loss_dice: 0.6181
05/27 04:29:36 - mmengine - INFO - Iter(train) [147700/160000]  base_lr: 9.9359e-06 lr: 9.9359e-07  eta: 1:24:53  time: 0.4184  data_time: 0.0100  memory: 5975  grad_norm: 563.2437  loss: 19.7952  decode.loss_cls: 0.1284  decode.loss_mask: 1.0251  decode.loss_dice: 0.7446  decode.d0.loss_cls: 0.6606  decode.d0.loss_mask: 0.9993  decode.d0.loss_dice: 0.7177  decode.d1.loss_cls: 0.1493  decode.d1.loss_mask: 1.0400  decode.d1.loss_dice: 0.7435  decode.d2.loss_cls: 0.1798  decode.d2.loss_mask: 1.0462  decode.d2.loss_dice: 0.7320  decode.d3.loss_cls: 0.1720  decode.d3.loss_mask: 1.0486  decode.d3.loss_dice: 0.7421  decode.d4.loss_cls: 0.1756  decode.d4.loss_mask: 1.0426  decode.d4.loss_dice: 0.7476  decode.d5.loss_cls: 0.1399  decode.d5.loss_mask: 1.0419  decode.d5.loss_dice: 0.7483  decode.d6.loss_cls: 0.1564  decode.d6.loss_mask: 1.0524  decode.d6.loss_dice: 0.7415  decode.d7.loss_cls: 0.1336  decode.d7.loss_mask: 1.0502  decode.d7.loss_dice: 0.7591  decode.d8.loss_cls: 0.1333  decode.d8.loss_mask: 1.0136  decode.d8.loss_dice: 0.7302
05/27 04:29:57 - mmengine - INFO - Iter(train) [147750/160000]  base_lr: 9.8996e-06 lr: 9.8996e-07  eta: 1:24:33  time: 0.4185  data_time: 0.0100  memory: 5973  grad_norm: 471.9881  loss: 18.2469  decode.loss_cls: 0.1700  decode.loss_mask: 0.9400  decode.loss_dice: 0.6754  decode.d0.loss_cls: 0.6719  decode.d0.loss_mask: 0.8630  decode.d0.loss_dice: 0.6844  decode.d1.loss_cls: 0.1550  decode.d1.loss_mask: 0.9317  decode.d1.loss_dice: 0.6852  decode.d2.loss_cls: 0.1647  decode.d2.loss_mask: 0.9227  decode.d2.loss_dice: 0.6940  decode.d3.loss_cls: 0.1572  decode.d3.loss_mask: 0.9208  decode.d3.loss_dice: 0.6858  decode.d4.loss_cls: 0.1532  decode.d4.loss_mask: 0.9198  decode.d4.loss_dice: 0.6789  decode.d5.loss_cls: 0.1653  decode.d5.loss_mask: 0.9313  decode.d5.loss_dice: 0.6885  decode.d6.loss_cls: 0.1688  decode.d6.loss_mask: 0.9322  decode.d6.loss_dice: 0.6859  decode.d7.loss_cls: 0.1649  decode.d7.loss_mask: 0.9498  decode.d7.loss_dice: 0.6943  decode.d8.loss_cls: 0.1723  decode.d8.loss_mask: 0.9157  decode.d8.loss_dice: 0.7044
05/27 04:30:18 - mmengine - INFO - Iter(train) [147800/160000]  base_lr: 9.8632e-06 lr: 9.8632e-07  eta: 1:24:12  time: 0.4193  data_time: 0.0100  memory: 5969  grad_norm: 531.1501  loss: 19.1327  decode.loss_cls: 0.1306  decode.loss_mask: 1.0370  decode.loss_dice: 0.6717  decode.d0.loss_cls: 0.5161  decode.d0.loss_mask: 1.0032  decode.d0.loss_dice: 0.7150  decode.d1.loss_cls: 0.1752  decode.d1.loss_mask: 1.0146  decode.d1.loss_dice: 0.6649  decode.d2.loss_cls: 0.1790  decode.d2.loss_mask: 1.0815  decode.d2.loss_dice: 0.6560  decode.d3.loss_cls: 0.1871  decode.d3.loss_mask: 1.0359  decode.d3.loss_dice: 0.6664  decode.d4.loss_cls: 0.1744  decode.d4.loss_mask: 1.0417  decode.d4.loss_dice: 0.6560  decode.d5.loss_cls: 0.1728  decode.d5.loss_mask: 1.0365  decode.d5.loss_dice: 0.6814  decode.d6.loss_cls: 0.1834  decode.d6.loss_mask: 1.0388  decode.d6.loss_dice: 0.6649  decode.d7.loss_cls: 0.1775  decode.d7.loss_mask: 1.0411  decode.d7.loss_dice: 0.6557  decode.d8.loss_cls: 0.1764  decode.d8.loss_mask: 1.0231  decode.d8.loss_dice: 0.6749
05/27 04:30:38 - mmengine - INFO - Iter(train) [147850/160000]  base_lr: 9.8268e-06 lr: 9.8268e-07  eta: 1:23:51  time: 0.4192  data_time: 0.0100  memory: 5975  grad_norm: 569.7893  loss: 18.7005  decode.loss_cls: 0.3040  decode.loss_mask: 0.8304  decode.loss_dice: 0.6478  decode.d0.loss_cls: 0.8727  decode.d0.loss_mask: 0.8101  decode.d0.loss_dice: 0.6733  decode.d1.loss_cls: 0.3636  decode.d1.loss_mask: 0.8298  decode.d1.loss_dice: 0.6704  decode.d2.loss_cls: 0.3534  decode.d2.loss_mask: 0.8343  decode.d2.loss_dice: 0.6376  decode.d3.loss_cls: 0.3368  decode.d3.loss_mask: 0.8315  decode.d3.loss_dice: 0.6359  decode.d4.loss_cls: 0.3141  decode.d4.loss_mask: 0.8573  decode.d4.loss_dice: 0.6549  decode.d5.loss_cls: 0.3391  decode.d5.loss_mask: 0.8387  decode.d5.loss_dice: 0.6447  decode.d6.loss_cls: 0.3224  decode.d6.loss_mask: 0.8479  decode.d6.loss_dice: 0.6434  decode.d7.loss_cls: 0.3302  decode.d7.loss_mask: 0.8437  decode.d7.loss_dice: 0.6531  decode.d8.loss_cls: 0.3167  decode.d8.loss_mask: 0.8291  decode.d8.loss_dice: 0.6337
05/27 04:30:59 - mmengine - INFO - Iter(train) [147900/160000]  base_lr: 9.7904e-06 lr: 9.7904e-07  eta: 1:23:31  time: 0.4183  data_time: 0.0099  memory: 5980  grad_norm: 497.1833  loss: 16.4698  decode.loss_cls: 0.0769  decode.loss_mask: 0.9104  decode.loss_dice: 0.6076  decode.d0.loss_cls: 0.5815  decode.d0.loss_mask: 0.8912  decode.d0.loss_dice: 0.6141  decode.d1.loss_cls: 0.0796  decode.d1.loss_mask: 0.9126  decode.d1.loss_dice: 0.5933  decode.d2.loss_cls: 0.0850  decode.d2.loss_mask: 0.9063  decode.d2.loss_dice: 0.5901  decode.d3.loss_cls: 0.0863  decode.d3.loss_mask: 0.9092  decode.d3.loss_dice: 0.6017  decode.d4.loss_cls: 0.0836  decode.d4.loss_mask: 0.9055  decode.d4.loss_dice: 0.6040  decode.d5.loss_cls: 0.0841  decode.d5.loss_mask: 0.9099  decode.d5.loss_dice: 0.5986  decode.d6.loss_cls: 0.0885  decode.d6.loss_mask: 0.9064  decode.d6.loss_dice: 0.6058  decode.d7.loss_cls: 0.0895  decode.d7.loss_mask: 0.9232  decode.d7.loss_dice: 0.6182  decode.d8.loss_cls: 0.0814  decode.d8.loss_mask: 0.9123  decode.d8.loss_dice: 0.6129
05/27 04:31:20 - mmengine - INFO - Iter(train) [147950/160000]  base_lr: 9.7540e-06 lr: 9.7540e-07  eta: 1:23:10  time: 0.4192  data_time: 0.0099  memory: 5972  grad_norm: 823.3651  loss: 22.9926  decode.loss_cls: 0.2566  decode.loss_mask: 1.1720  decode.loss_dice: 0.8205  decode.d0.loss_cls: 0.7332  decode.d0.loss_mask: 1.1537  decode.d0.loss_dice: 0.8157  decode.d1.loss_cls: 0.2519  decode.d1.loss_mask: 1.1767  decode.d1.loss_dice: 0.8509  decode.d2.loss_cls: 0.2765  decode.d2.loss_mask: 1.2174  decode.d2.loss_dice: 0.8306  decode.d3.loss_cls: 0.2863  decode.d3.loss_mask: 1.1534  decode.d3.loss_dice: 0.7946  decode.d4.loss_cls: 0.2598  decode.d4.loss_mask: 1.1424  decode.d4.loss_dice: 0.8159  decode.d5.loss_cls: 0.3039  decode.d5.loss_mask: 1.1270  decode.d5.loss_dice: 0.7907  decode.d6.loss_cls: 0.2385  decode.d6.loss_mask: 1.1523  decode.d6.loss_dice: 0.8086  decode.d7.loss_cls: 0.3128  decode.d7.loss_mask: 1.1503  decode.d7.loss_dice: 0.8273  decode.d8.loss_cls: 0.2642  decode.d8.loss_mask: 1.1769  decode.d8.loss_dice: 0.8317
05/27 04:31:41 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 04:31:41 - mmengine - INFO - Iter(train) [148000/160000]  base_lr: 9.7176e-06 lr: 9.7176e-07  eta: 1:22:49  time: 0.4187  data_time: 0.0099  memory: 5971  grad_norm: 593.4885  loss: 15.8999  decode.loss_cls: 0.1355  decode.loss_mask: 0.8255  decode.loss_dice: 0.5885  decode.d0.loss_cls: 0.5575  decode.d0.loss_mask: 0.8595  decode.d0.loss_dice: 0.6124  decode.d1.loss_cls: 0.1524  decode.d1.loss_mask: 0.8246  decode.d1.loss_dice: 0.5913  decode.d2.loss_cls: 0.1312  decode.d2.loss_mask: 0.8179  decode.d2.loss_dice: 0.5644  decode.d3.loss_cls: 0.1380  decode.d3.loss_mask: 0.8213  decode.d3.loss_dice: 0.5778  decode.d4.loss_cls: 0.1416  decode.d4.loss_mask: 0.8211  decode.d4.loss_dice: 0.5685  decode.d5.loss_cls: 0.1265  decode.d5.loss_mask: 0.8310  decode.d5.loss_dice: 0.5845  decode.d6.loss_cls: 0.1233  decode.d6.loss_mask: 0.8389  decode.d6.loss_dice: 0.5821  decode.d7.loss_cls: 0.1231  decode.d7.loss_mask: 0.8323  decode.d7.loss_dice: 0.5940  decode.d8.loss_cls: 0.1178  decode.d8.loss_mask: 0.8235  decode.d8.loss_dice: 0.5937
05/27 04:32:02 - mmengine - INFO - Iter(train) [148050/160000]  base_lr: 9.6811e-06 lr: 9.6811e-07  eta: 1:22:28  time: 0.4187  data_time: 0.0100  memory: 5976  grad_norm: 381.6123  loss: 21.8379  decode.loss_cls: 0.1688  decode.loss_mask: 1.1245  decode.loss_dice: 0.8354  decode.d0.loss_cls: 0.6472  decode.d0.loss_mask: 1.0633  decode.d0.loss_dice: 0.8098  decode.d1.loss_cls: 0.2097  decode.d1.loss_mask: 1.1097  decode.d1.loss_dice: 0.8337  decode.d2.loss_cls: 0.2015  decode.d2.loss_mask: 1.1183  decode.d2.loss_dice: 0.8279  decode.d3.loss_cls: 0.2089  decode.d3.loss_mask: 1.1301  decode.d3.loss_dice: 0.8221  decode.d4.loss_cls: 0.2215  decode.d4.loss_mask: 1.1191  decode.d4.loss_dice: 0.8293  decode.d5.loss_cls: 0.1978  decode.d5.loss_mask: 1.1052  decode.d5.loss_dice: 0.8151  decode.d6.loss_cls: 0.1826  decode.d6.loss_mask: 1.1414  decode.d6.loss_dice: 0.8310  decode.d7.loss_cls: 0.2019  decode.d7.loss_mask: 1.1177  decode.d7.loss_dice: 0.8347  decode.d8.loss_cls: 0.1698  decode.d8.loss_mask: 1.1304  decode.d8.loss_dice: 0.8294
05/27 04:32:23 - mmengine - INFO - Iter(train) [148100/160000]  base_lr: 9.6447e-06 lr: 9.6447e-07  eta: 1:22:08  time: 0.4189  data_time: 0.0099  memory: 5970  grad_norm: 288.9959  loss: 17.2516  decode.loss_cls: 0.1190  decode.loss_mask: 0.9200  decode.loss_dice: 0.6204  decode.d0.loss_cls: 0.6974  decode.d0.loss_mask: 0.8969  decode.d0.loss_dice: 0.6080  decode.d1.loss_cls: 0.1455  decode.d1.loss_mask: 0.9236  decode.d1.loss_dice: 0.6270  decode.d2.loss_cls: 0.1281  decode.d2.loss_mask: 0.9271  decode.d2.loss_dice: 0.6204  decode.d3.loss_cls: 0.1538  decode.d3.loss_mask: 0.9303  decode.d3.loss_dice: 0.6206  decode.d4.loss_cls: 0.1264  decode.d4.loss_mask: 0.9121  decode.d4.loss_dice: 0.6178  decode.d5.loss_cls: 0.1316  decode.d5.loss_mask: 0.9072  decode.d5.loss_dice: 0.6248  decode.d6.loss_cls: 0.1199  decode.d6.loss_mask: 0.9123  decode.d6.loss_dice: 0.6290  decode.d7.loss_cls: 0.1233  decode.d7.loss_mask: 0.9187  decode.d7.loss_dice: 0.6287  decode.d8.loss_cls: 0.1195  decode.d8.loss_mask: 0.9156  decode.d8.loss_dice: 0.6267
05/27 04:32:44 - mmengine - INFO - Iter(train) [148150/160000]  base_lr: 9.6082e-06 lr: 9.6082e-07  eta: 1:21:47  time: 0.4195  data_time: 0.0101  memory: 5968  grad_norm: 585.2725  loss: 17.5950  decode.loss_cls: 0.1559  decode.loss_mask: 0.9443  decode.loss_dice: 0.6041  decode.d0.loss_cls: 0.6596  decode.d0.loss_mask: 0.9534  decode.d0.loss_dice: 0.5974  decode.d1.loss_cls: 0.1343  decode.d1.loss_mask: 0.9636  decode.d1.loss_dice: 0.6099  decode.d2.loss_cls: 0.1784  decode.d2.loss_mask: 0.9457  decode.d2.loss_dice: 0.5995  decode.d3.loss_cls: 0.1547  decode.d3.loss_mask: 0.9602  decode.d3.loss_dice: 0.6172  decode.d4.loss_cls: 0.1336  decode.d4.loss_mask: 0.9459  decode.d4.loss_dice: 0.6074  decode.d5.loss_cls: 0.1603  decode.d5.loss_mask: 0.9464  decode.d5.loss_dice: 0.5978  decode.d6.loss_cls: 0.1999  decode.d6.loss_mask: 0.9314  decode.d6.loss_dice: 0.6006  decode.d7.loss_cls: 0.1591  decode.d7.loss_mask: 0.9229  decode.d7.loss_dice: 0.5879  decode.d8.loss_cls: 0.1507  decode.d8.loss_mask: 0.9531  decode.d8.loss_dice: 0.6196
05/27 04:33:05 - mmengine - INFO - Iter(train) [148200/160000]  base_lr: 9.5717e-06 lr: 9.5717e-07  eta: 1:21:26  time: 0.4181  data_time: 0.0099  memory: 5967  grad_norm: 598.9007  loss: 19.0516  decode.loss_cls: 0.1550  decode.loss_mask: 1.0138  decode.loss_dice: 0.6729  decode.d0.loss_cls: 0.5890  decode.d0.loss_mask: 1.0000  decode.d0.loss_dice: 0.6396  decode.d1.loss_cls: 0.1871  decode.d1.loss_mask: 1.0037  decode.d1.loss_dice: 0.6718  decode.d2.loss_cls: 0.1574  decode.d2.loss_mask: 1.0215  decode.d2.loss_dice: 0.6710  decode.d3.loss_cls: 0.1850  decode.d3.loss_mask: 1.0153  decode.d3.loss_dice: 0.6797  decode.d4.loss_cls: 0.2265  decode.d4.loss_mask: 1.0056  decode.d4.loss_dice: 0.6893  decode.d5.loss_cls: 0.1744  decode.d5.loss_mask: 1.0249  decode.d5.loss_dice: 0.6804  decode.d6.loss_cls: 0.1894  decode.d6.loss_mask: 1.0240  decode.d6.loss_dice: 0.6878  decode.d7.loss_cls: 0.1810  decode.d7.loss_mask: 1.0087  decode.d7.loss_dice: 0.6732  decode.d8.loss_cls: 0.1634  decode.d8.loss_mask: 1.0037  decode.d8.loss_dice: 0.6565
05/27 04:33:26 - mmengine - INFO - Iter(train) [148250/160000]  base_lr: 9.5352e-06 lr: 9.5352e-07  eta: 1:21:06  time: 0.4181  data_time: 0.0100  memory: 5965  grad_norm: 408.8837  loss: 17.4360  decode.loss_cls: 0.1653  decode.loss_mask: 0.9006  decode.loss_dice: 0.6613  decode.d0.loss_cls: 0.6665  decode.d0.loss_mask: 0.8700  decode.d0.loss_dice: 0.6094  decode.d1.loss_cls: 0.1868  decode.d1.loss_mask: 0.9099  decode.d1.loss_dice: 0.6425  decode.d2.loss_cls: 0.1608  decode.d2.loss_mask: 0.8899  decode.d2.loss_dice: 0.6292  decode.d3.loss_cls: 0.1387  decode.d3.loss_mask: 0.9016  decode.d3.loss_dice: 0.6433  decode.d4.loss_cls: 0.1234  decode.d4.loss_mask: 0.8968  decode.d4.loss_dice: 0.6493  decode.d5.loss_cls: 0.1534  decode.d5.loss_mask: 0.9011  decode.d5.loss_dice: 0.6277  decode.d6.loss_cls: 0.1604  decode.d6.loss_mask: 0.8982  decode.d6.loss_dice: 0.6249  decode.d7.loss_cls: 0.1582  decode.d7.loss_mask: 0.9059  decode.d7.loss_dice: 0.6524  decode.d8.loss_cls: 0.1442  decode.d8.loss_mask: 0.9039  decode.d8.loss_dice: 0.6604
05/27 04:33:47 - mmengine - INFO - Iter(train) [148300/160000]  base_lr: 9.4986e-06 lr: 9.4986e-07  eta: 1:20:45  time: 0.4193  data_time: 0.0100  memory: 5972  grad_norm: 332.0720  loss: 19.3362  decode.loss_cls: 0.1319  decode.loss_mask: 1.0493  decode.loss_dice: 0.7397  decode.d0.loss_cls: 0.5454  decode.d0.loss_mask: 1.0289  decode.d0.loss_dice: 0.7356  decode.d1.loss_cls: 0.1493  decode.d1.loss_mask: 1.0067  decode.d1.loss_dice: 0.7377  decode.d2.loss_cls: 0.1268  decode.d2.loss_mask: 1.0323  decode.d2.loss_dice: 0.7322  decode.d3.loss_cls: 0.1151  decode.d3.loss_mask: 1.0360  decode.d3.loss_dice: 0.7310  decode.d4.loss_cls: 0.1347  decode.d4.loss_mask: 1.0335  decode.d4.loss_dice: 0.7452  decode.d5.loss_cls: 0.1317  decode.d5.loss_mask: 1.0194  decode.d5.loss_dice: 0.7347  decode.d6.loss_cls: 0.1405  decode.d6.loss_mask: 1.0197  decode.d6.loss_dice: 0.7361  decode.d7.loss_cls: 0.1365  decode.d7.loss_mask: 1.0071  decode.d7.loss_dice: 0.7227  decode.d8.loss_cls: 0.1230  decode.d8.loss_mask: 1.0165  decode.d8.loss_dice: 0.7373
05/27 04:34:08 - mmengine - INFO - Iter(train) [148350/160000]  base_lr: 9.4621e-06 lr: 9.4621e-07  eta: 1:20:24  time: 0.4189  data_time: 0.0101  memory: 5968  grad_norm: 211.1376  loss: 14.1645  decode.loss_cls: 0.0411  decode.loss_mask: 0.7841  decode.loss_dice: 0.5569  decode.d0.loss_cls: 0.4373  decode.d0.loss_mask: 0.7751  decode.d0.loss_dice: 0.5447  decode.d1.loss_cls: 0.0421  decode.d1.loss_mask: 0.7820  decode.d1.loss_dice: 0.5535  decode.d2.loss_cls: 0.0405  decode.d2.loss_mask: 0.7864  decode.d2.loss_dice: 0.5490  decode.d3.loss_cls: 0.0411  decode.d3.loss_mask: 0.7862  decode.d3.loss_dice: 0.5444  decode.d4.loss_cls: 0.0445  decode.d4.loss_mask: 0.7860  decode.d4.loss_dice: 0.5524  decode.d5.loss_cls: 0.0460  decode.d5.loss_mask: 0.7821  decode.d5.loss_dice: 0.5497  decode.d6.loss_cls: 0.0421  decode.d6.loss_mask: 0.7824  decode.d6.loss_dice: 0.5567  decode.d7.loss_cls: 0.0444  decode.d7.loss_mask: 0.7836  decode.d7.loss_dice: 0.5545  decode.d8.loss_cls: 0.0411  decode.d8.loss_mask: 0.7762  decode.d8.loss_dice: 0.5583
05/27 04:34:29 - mmengine - INFO - Iter(train) [148400/160000]  base_lr: 9.4255e-06 lr: 9.4255e-07  eta: 1:20:04  time: 0.4192  data_time: 0.0099  memory: 5972  grad_norm: 479.8422  loss: 16.9423  decode.loss_cls: 0.1145  decode.loss_mask: 0.8777  decode.loss_dice: 0.6318  decode.d0.loss_cls: 0.6834  decode.d0.loss_mask: 0.8843  decode.d0.loss_dice: 0.6109  decode.d1.loss_cls: 0.1084  decode.d1.loss_mask: 0.9118  decode.d1.loss_dice: 0.6381  decode.d2.loss_cls: 0.0957  decode.d2.loss_mask: 0.9357  decode.d2.loss_dice: 0.6318  decode.d3.loss_cls: 0.1026  decode.d3.loss_mask: 0.8809  decode.d3.loss_dice: 0.6398  decode.d4.loss_cls: 0.1197  decode.d4.loss_mask: 0.8832  decode.d4.loss_dice: 0.6364  decode.d5.loss_cls: 0.1234  decode.d5.loss_mask: 0.8972  decode.d5.loss_dice: 0.6453  decode.d6.loss_cls: 0.1232  decode.d6.loss_mask: 0.8785  decode.d6.loss_dice: 0.6367  decode.d7.loss_cls: 0.1125  decode.d7.loss_mask: 0.8799  decode.d7.loss_dice: 0.6245  decode.d8.loss_cls: 0.1155  decode.d8.loss_mask: 0.8884  decode.d8.loss_dice: 0.6307
05/27 04:34:50 - mmengine - INFO - Iter(train) [148450/160000]  base_lr: 9.3890e-06 lr: 9.3890e-07  eta: 1:19:43  time: 0.4196  data_time: 0.0101  memory: 5969  grad_norm: 340.6149  loss: 17.4616  decode.loss_cls: 0.2110  decode.loss_mask: 0.8364  decode.loss_dice: 0.6672  decode.d0.loss_cls: 0.5937  decode.d0.loss_mask: 0.8264  decode.d0.loss_dice: 0.6796  decode.d1.loss_cls: 0.1953  decode.d1.loss_mask: 0.8410  decode.d1.loss_dice: 0.6398  decode.d2.loss_cls: 0.2029  decode.d2.loss_mask: 0.8363  decode.d2.loss_dice: 0.6717  decode.d3.loss_cls: 0.2003  decode.d3.loss_mask: 0.8314  decode.d3.loss_dice: 0.6671  decode.d4.loss_cls: 0.2199  decode.d4.loss_mask: 0.8266  decode.d4.loss_dice: 0.6632  decode.d5.loss_cls: 0.2327  decode.d5.loss_mask: 0.8368  decode.d5.loss_dice: 0.6460  decode.d6.loss_cls: 0.1824  decode.d6.loss_mask: 0.8400  decode.d6.loss_dice: 0.6758  decode.d7.loss_cls: 0.1946  decode.d7.loss_mask: 0.8437  decode.d7.loss_dice: 0.6740  decode.d8.loss_cls: 0.1995  decode.d8.loss_mask: 0.8537  decode.d8.loss_dice: 0.6725
05/27 04:35:11 - mmengine - INFO - Iter(train) [148500/160000]  base_lr: 9.3524e-06 lr: 9.3524e-07  eta: 1:19:22  time: 0.4201  data_time: 0.0100  memory: 5974  grad_norm: 398.4636  loss: 17.1350  decode.loss_cls: 0.1318  decode.loss_mask: 0.8885  decode.loss_dice: 0.6373  decode.d0.loss_cls: 0.6234  decode.d0.loss_mask: 0.8898  decode.d0.loss_dice: 0.6219  decode.d1.loss_cls: 0.1452  decode.d1.loss_mask: 0.8785  decode.d1.loss_dice: 0.6343  decode.d2.loss_cls: 0.1292  decode.d2.loss_mask: 0.9030  decode.d2.loss_dice: 0.6469  decode.d3.loss_cls: 0.1269  decode.d3.loss_mask: 0.8905  decode.d3.loss_dice: 0.6483  decode.d4.loss_cls: 0.1330  decode.d4.loss_mask: 0.8845  decode.d4.loss_dice: 0.6339  decode.d5.loss_cls: 0.1404  decode.d5.loss_mask: 0.8660  decode.d5.loss_dice: 0.6217  decode.d6.loss_cls: 0.0935  decode.d6.loss_mask: 0.9466  decode.d6.loss_dice: 0.6565  decode.d7.loss_cls: 0.1486  decode.d7.loss_mask: 0.9009  decode.d7.loss_dice: 0.6313  decode.d8.loss_cls: 0.1163  decode.d8.loss_mask: 0.8984  decode.d8.loss_dice: 0.6679
05/27 04:35:32 - mmengine - INFO - Iter(train) [148550/160000]  base_lr: 9.3158e-06 lr: 9.3158e-07  eta: 1:19:02  time: 0.4197  data_time: 0.0100  memory: 5967  grad_norm: 878.8762  loss: 17.5695  decode.loss_cls: 0.2717  decode.loss_mask: 0.7758  decode.loss_dice: 0.6547  decode.d0.loss_cls: 0.7556  decode.d0.loss_mask: 0.7942  decode.d0.loss_dice: 0.6652  decode.d1.loss_cls: 0.2232  decode.d1.loss_mask: 0.8235  decode.d1.loss_dice: 0.6589  decode.d2.loss_cls: 0.2659  decode.d2.loss_mask: 0.7675  decode.d2.loss_dice: 0.6509  decode.d3.loss_cls: 0.2720  decode.d3.loss_mask: 0.7659  decode.d3.loss_dice: 0.6503  decode.d4.loss_cls: 0.2490  decode.d4.loss_mask: 0.7986  decode.d4.loss_dice: 0.6655  decode.d5.loss_cls: 0.2166  decode.d5.loss_mask: 0.8161  decode.d5.loss_dice: 0.6632  decode.d6.loss_cls: 0.2602  decode.d6.loss_mask: 0.7827  decode.d6.loss_dice: 0.6484  decode.d7.loss_cls: 0.2342  decode.d7.loss_mask: 0.8540  decode.d7.loss_dice: 0.6681  decode.d8.loss_cls: 0.2271  decode.d8.loss_mask: 0.8232  decode.d8.loss_dice: 0.6674
05/27 04:35:53 - mmengine - INFO - Iter(train) [148600/160000]  base_lr: 9.2792e-06 lr: 9.2792e-07  eta: 1:18:41  time: 0.4187  data_time: 0.0101  memory: 5975  grad_norm: 692.6451  loss: 18.4223  decode.loss_cls: 0.1599  decode.loss_mask: 0.9456  decode.loss_dice: 0.6818  decode.d0.loss_cls: 0.6148  decode.d0.loss_mask: 0.9315  decode.d0.loss_dice: 0.6769  decode.d1.loss_cls: 0.1375  decode.d1.loss_mask: 1.0087  decode.d1.loss_dice: 0.6725  decode.d2.loss_cls: 0.1414  decode.d2.loss_mask: 1.0008  decode.d2.loss_dice: 0.6762  decode.d3.loss_cls: 0.1427  decode.d3.loss_mask: 0.9476  decode.d3.loss_dice: 0.6839  decode.d4.loss_cls: 0.1722  decode.d4.loss_mask: 0.9557  decode.d4.loss_dice: 0.6776  decode.d5.loss_cls: 0.1553  decode.d5.loss_mask: 0.9544  decode.d5.loss_dice: 0.7005  decode.d6.loss_cls: 0.1608  decode.d6.loss_mask: 0.9465  decode.d6.loss_dice: 0.6813  decode.d7.loss_cls: 0.1596  decode.d7.loss_mask: 0.9519  decode.d7.loss_dice: 0.6823  decode.d8.loss_cls: 0.1347  decode.d8.loss_mask: 0.9757  decode.d8.loss_dice: 0.6918
05/27 04:36:14 - mmengine - INFO - Iter(train) [148650/160000]  base_lr: 9.2425e-06 lr: 9.2425e-07  eta: 1:18:20  time: 0.4190  data_time: 0.0100  memory: 5976  grad_norm: 429.2628  loss: 16.9996  decode.loss_cls: 0.0979  decode.loss_mask: 0.9091  decode.loss_dice: 0.6452  decode.d0.loss_cls: 0.5642  decode.d0.loss_mask: 0.8769  decode.d0.loss_dice: 0.6583  decode.d1.loss_cls: 0.1015  decode.d1.loss_mask: 0.9112  decode.d1.loss_dice: 0.6631  decode.d2.loss_cls: 0.0965  decode.d2.loss_mask: 0.9113  decode.d2.loss_dice: 0.6616  decode.d3.loss_cls: 0.1074  decode.d3.loss_mask: 0.9135  decode.d3.loss_dice: 0.6152  decode.d4.loss_cls: 0.0998  decode.d4.loss_mask: 0.9206  decode.d4.loss_dice: 0.6362  decode.d5.loss_cls: 0.1095  decode.d5.loss_mask: 0.9123  decode.d5.loss_dice: 0.6318  decode.d6.loss_cls: 0.1039  decode.d6.loss_mask: 0.9070  decode.d6.loss_dice: 0.6429  decode.d7.loss_cls: 0.0866  decode.d7.loss_mask: 0.9100  decode.d7.loss_dice: 0.6378  decode.d8.loss_cls: 0.1117  decode.d8.loss_mask: 0.9151  decode.d8.loss_dice: 0.6417
05/27 04:36:35 - mmengine - INFO - Iter(train) [148700/160000]  base_lr: 9.2059e-06 lr: 9.2059e-07  eta: 1:18:00  time: 0.4188  data_time: 0.0100  memory: 5966  grad_norm: 676.3146  loss: 17.0508  decode.loss_cls: 0.1740  decode.loss_mask: 0.8440  decode.loss_dice: 0.6038  decode.d0.loss_cls: 0.7104  decode.d0.loss_mask: 0.7998  decode.d0.loss_dice: 0.5939  decode.d1.loss_cls: 0.1646  decode.d1.loss_mask: 0.8524  decode.d1.loss_dice: 0.6308  decode.d2.loss_cls: 0.1770  decode.d2.loss_mask: 0.8546  decode.d2.loss_dice: 0.6126  decode.d3.loss_cls: 0.1807  decode.d3.loss_mask: 0.8699  decode.d3.loss_dice: 0.6291  decode.d4.loss_cls: 0.1545  decode.d4.loss_mask: 0.8869  decode.d4.loss_dice: 0.6545  decode.d5.loss_cls: 0.2024  decode.d5.loss_mask: 0.8698  decode.d5.loss_dice: 0.6345  decode.d6.loss_cls: 0.1719  decode.d6.loss_mask: 0.8584  decode.d6.loss_dice: 0.6057  decode.d7.loss_cls: 0.1942  decode.d7.loss_mask: 0.8573  decode.d7.loss_dice: 0.6155  decode.d8.loss_cls: 0.1946  decode.d8.loss_mask: 0.8498  decode.d8.loss_dice: 0.6032
05/27 04:36:56 - mmengine - INFO - Iter(train) [148750/160000]  base_lr: 9.1692e-06 lr: 9.1692e-07  eta: 1:17:39  time: 0.4182  data_time: 0.0101  memory: 5986  grad_norm: 448.3772  loss: 19.4436  decode.loss_cls: 0.0824  decode.loss_mask: 1.0994  decode.loss_dice: 0.6976  decode.d0.loss_cls: 0.6438  decode.d0.loss_mask: 1.0591  decode.d0.loss_dice: 0.7182  decode.d1.loss_cls: 0.0867  decode.d1.loss_mask: 1.1050  decode.d1.loss_dice: 0.6971  decode.d2.loss_cls: 0.1129  decode.d2.loss_mask: 1.0722  decode.d2.loss_dice: 0.6947  decode.d3.loss_cls: 0.0526  decode.d3.loss_mask: 1.1486  decode.d3.loss_dice: 0.7184  decode.d4.loss_cls: 0.0615  decode.d4.loss_mask: 1.1213  decode.d4.loss_dice: 0.7058  decode.d5.loss_cls: 0.0541  decode.d5.loss_mask: 1.1440  decode.d5.loss_dice: 0.7115  decode.d6.loss_cls: 0.1136  decode.d6.loss_mask: 1.0506  decode.d6.loss_dice: 0.6846  decode.d7.loss_cls: 0.0566  decode.d7.loss_mask: 1.1485  decode.d7.loss_dice: 0.7128  decode.d8.loss_cls: 0.0893  decode.d8.loss_mask: 1.0990  decode.d8.loss_dice: 0.7016
05/27 04:37:17 - mmengine - INFO - Iter(train) [148800/160000]  base_lr: 9.1325e-06 lr: 9.1325e-07  eta: 1:17:18  time: 0.4188  data_time: 0.0101  memory: 5967  grad_norm: 358.3504  loss: 15.0834  decode.loss_cls: 0.1656  decode.loss_mask: 0.8015  decode.loss_dice: 0.5144  decode.d0.loss_cls: 0.6108  decode.d0.loss_mask: 0.7870  decode.d0.loss_dice: 0.5289  decode.d1.loss_cls: 0.1983  decode.d1.loss_mask: 0.8010  decode.d1.loss_dice: 0.5153  decode.d2.loss_cls: 0.1488  decode.d2.loss_mask: 0.8021  decode.d2.loss_dice: 0.5010  decode.d3.loss_cls: 0.1390  decode.d3.loss_mask: 0.7970  decode.d3.loss_dice: 0.5071  decode.d4.loss_cls: 0.1481  decode.d4.loss_mask: 0.7933  decode.d4.loss_dice: 0.5219  decode.d5.loss_cls: 0.1419  decode.d5.loss_mask: 0.7975  decode.d5.loss_dice: 0.5039  decode.d6.loss_cls: 0.1163  decode.d6.loss_mask: 0.7977  decode.d6.loss_dice: 0.5214  decode.d7.loss_cls: 0.1152  decode.d7.loss_mask: 0.8106  decode.d7.loss_dice: 0.5339  decode.d8.loss_cls: 0.1563  decode.d8.loss_mask: 0.7971  decode.d8.loss_dice: 0.5104
05/27 04:37:38 - mmengine - INFO - Iter(train) [148850/160000]  base_lr: 9.0958e-06 lr: 9.0958e-07  eta: 1:16:57  time: 0.4188  data_time: 0.0101  memory: 5970  grad_norm: 1079.6466  loss: 19.4305  decode.loss_cls: 0.1916  decode.loss_mask: 1.0061  decode.loss_dice: 0.6817  decode.d0.loss_cls: 0.6669  decode.d0.loss_mask: 1.0378  decode.d0.loss_dice: 0.7194  decode.d1.loss_cls: 0.2276  decode.d1.loss_mask: 1.0118  decode.d1.loss_dice: 0.6742  decode.d2.loss_cls: 0.2201  decode.d2.loss_mask: 0.9931  decode.d2.loss_dice: 0.6854  decode.d3.loss_cls: 0.2015  decode.d3.loss_mask: 0.9928  decode.d3.loss_dice: 0.6856  decode.d4.loss_cls: 0.2015  decode.d4.loss_mask: 1.0022  decode.d4.loss_dice: 0.6756  decode.d5.loss_cls: 0.1945  decode.d5.loss_mask: 1.0211  decode.d5.loss_dice: 0.6962  decode.d6.loss_cls: 0.1934  decode.d6.loss_mask: 1.0020  decode.d6.loss_dice: 0.6935  decode.d7.loss_cls: 0.1674  decode.d7.loss_mask: 0.9990  decode.d7.loss_dice: 0.6798  decode.d8.loss_cls: 0.1926  decode.d8.loss_mask: 1.0233  decode.d8.loss_dice: 0.6928
05/27 04:37:59 - mmengine - INFO - Iter(train) [148900/160000]  base_lr: 9.0591e-06 lr: 9.0591e-07  eta: 1:16:37  time: 0.4189  data_time: 0.0101  memory: 5971  grad_norm: 957.1917  loss: 16.4808  decode.loss_cls: 0.2356  decode.loss_mask: 0.7849  decode.loss_dice: 0.5620  decode.d0.loss_cls: 0.6782  decode.d0.loss_mask: 0.8131  decode.d0.loss_dice: 0.5652  decode.d1.loss_cls: 0.2510  decode.d1.loss_mask: 0.7930  decode.d1.loss_dice: 0.5506  decode.d2.loss_cls: 0.2464  decode.d2.loss_mask: 0.8014  decode.d2.loss_dice: 0.5598  decode.d3.loss_cls: 0.2724  decode.d3.loss_mask: 0.7920  decode.d3.loss_dice: 0.5642  decode.d4.loss_cls: 0.2359  decode.d4.loss_mask: 0.7879  decode.d4.loss_dice: 0.5602  decode.d5.loss_cls: 0.2133  decode.d5.loss_mask: 0.8161  decode.d5.loss_dice: 0.5696  decode.d6.loss_cls: 0.2112  decode.d6.loss_mask: 0.8222  decode.d6.loss_dice: 0.5866  decode.d7.loss_cls: 0.2597  decode.d7.loss_mask: 0.7896  decode.d7.loss_dice: 0.5802  decode.d8.loss_cls: 0.2140  decode.d8.loss_mask: 0.7975  decode.d8.loss_dice: 0.5670
05/27 04:38:20 - mmengine - INFO - Iter(train) [148950/160000]  base_lr: 9.0224e-06 lr: 9.0224e-07  eta: 1:16:16  time: 0.4186  data_time: 0.0100  memory: 5970  grad_norm: 396.5555  loss: 16.7994  decode.loss_cls: 0.0475  decode.loss_mask: 0.9068  decode.loss_dice: 0.6656  decode.d0.loss_cls: 0.4942  decode.d0.loss_mask: 0.9169  decode.d0.loss_dice: 0.6549  decode.d1.loss_cls: 0.0377  decode.d1.loss_mask: 0.9138  decode.d1.loss_dice: 0.6830  decode.d2.loss_cls: 0.0378  decode.d2.loss_mask: 0.9100  decode.d2.loss_dice: 0.6727  decode.d3.loss_cls: 0.0474  decode.d3.loss_mask: 0.9202  decode.d3.loss_dice: 0.6698  decode.d4.loss_cls: 0.0368  decode.d4.loss_mask: 0.9194  decode.d4.loss_dice: 0.6895  decode.d5.loss_cls: 0.0407  decode.d5.loss_mask: 0.9242  decode.d5.loss_dice: 0.6889  decode.d6.loss_cls: 0.0546  decode.d6.loss_mask: 0.9177  decode.d6.loss_dice: 0.6708  decode.d7.loss_cls: 0.0549  decode.d7.loss_mask: 0.9137  decode.d7.loss_dice: 0.6719  decode.d8.loss_cls: 0.0522  decode.d8.loss_mask: 0.9161  decode.d8.loss_dice: 0.6698
05/27 04:38:41 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 04:38:41 - mmengine - INFO - Iter(train) [149000/160000]  base_lr: 8.9856e-06 lr: 8.9856e-07  eta: 1:15:55  time: 0.4180  data_time: 0.0100  memory: 5980  grad_norm: 489.0291  loss: 19.4206  decode.loss_cls: 0.2188  decode.loss_mask: 0.9444  decode.loss_dice: 0.7176  decode.d0.loss_cls: 0.7198  decode.d0.loss_mask: 0.9730  decode.d0.loss_dice: 0.7343  decode.d1.loss_cls: 0.1936  decode.d1.loss_mask: 0.9479  decode.d1.loss_dice: 0.7212  decode.d2.loss_cls: 0.2607  decode.d2.loss_mask: 0.9453  decode.d2.loss_dice: 0.7197  decode.d3.loss_cls: 0.2315  decode.d3.loss_mask: 0.9370  decode.d3.loss_dice: 0.7233  decode.d4.loss_cls: 0.2097  decode.d4.loss_mask: 0.9481  decode.d4.loss_dice: 0.7108  decode.d5.loss_cls: 0.1859  decode.d5.loss_mask: 0.9534  decode.d5.loss_dice: 0.7107  decode.d6.loss_cls: 0.2088  decode.d6.loss_mask: 0.9572  decode.d6.loss_dice: 0.7243  decode.d7.loss_cls: 0.2392  decode.d7.loss_mask: 0.9691  decode.d7.loss_dice: 0.7400  decode.d8.loss_cls: 0.2095  decode.d8.loss_mask: 0.9530  decode.d8.loss_dice: 0.7125
05/27 04:39:02 - mmengine - INFO - Iter(train) [149050/160000]  base_lr: 8.9488e-06 lr: 8.9488e-07  eta: 1:15:35  time: 0.4183  data_time: 0.0101  memory: 5966  grad_norm: 507.3074  loss: 15.2014  decode.loss_cls: 0.0982  decode.loss_mask: 0.7800  decode.loss_dice: 0.6028  decode.d0.loss_cls: 0.5540  decode.d0.loss_mask: 0.7514  decode.d0.loss_dice: 0.5607  decode.d1.loss_cls: 0.0863  decode.d1.loss_mask: 0.7764  decode.d1.loss_dice: 0.6067  decode.d2.loss_cls: 0.1193  decode.d2.loss_mask: 0.7688  decode.d2.loss_dice: 0.5889  decode.d3.loss_cls: 0.0837  decode.d3.loss_mask: 0.7762  decode.d3.loss_dice: 0.6027  decode.d4.loss_cls: 0.0666  decode.d4.loss_mask: 0.8233  decode.d4.loss_dice: 0.6234  decode.d5.loss_cls: 0.0844  decode.d5.loss_mask: 0.8153  decode.d5.loss_dice: 0.6120  decode.d6.loss_cls: 0.0947  decode.d6.loss_mask: 0.7673  decode.d6.loss_dice: 0.5931  decode.d7.loss_cls: 0.0825  decode.d7.loss_mask: 0.7967  decode.d7.loss_dice: 0.6032  decode.d8.loss_cls: 0.0877  decode.d8.loss_mask: 0.7940  decode.d8.loss_dice: 0.6016
05/27 04:39:23 - mmengine - INFO - Iter(train) [149100/160000]  base_lr: 8.9121e-06 lr: 8.9121e-07  eta: 1:15:14  time: 0.4188  data_time: 0.0101  memory: 5968  grad_norm: 726.4625  loss: 18.7977  decode.loss_cls: 0.0984  decode.loss_mask: 1.0325  decode.loss_dice: 0.6942  decode.d0.loss_cls: 0.7159  decode.d0.loss_mask: 0.9260  decode.d0.loss_dice: 0.6777  decode.d1.loss_cls: 0.0997  decode.d1.loss_mask: 1.0498  decode.d1.loss_dice: 0.6956  decode.d2.loss_cls: 0.1534  decode.d2.loss_mask: 1.0195  decode.d2.loss_dice: 0.6851  decode.d3.loss_cls: 0.1232  decode.d3.loss_mask: 1.0240  decode.d3.loss_dice: 0.6905  decode.d4.loss_cls: 0.1198  decode.d4.loss_mask: 1.0307  decode.d4.loss_dice: 0.6868  decode.d5.loss_cls: 0.1062  decode.d5.loss_mask: 1.0282  decode.d5.loss_dice: 0.6806  decode.d6.loss_cls: 0.1131  decode.d6.loss_mask: 1.0248  decode.d6.loss_dice: 0.6978  decode.d7.loss_cls: 0.1230  decode.d7.loss_mask: 1.0227  decode.d7.loss_dice: 0.6822  decode.d8.loss_cls: 0.1119  decode.d8.loss_mask: 1.0089  decode.d8.loss_dice: 0.6756
05/27 04:39:44 - mmengine - INFO - Iter(train) [149150/160000]  base_lr: 8.8753e-06 lr: 8.8753e-07  eta: 1:14:53  time: 0.4200  data_time: 0.0100  memory: 5969  grad_norm: 537.7154  loss: 15.4232  decode.loss_cls: 0.0690  decode.loss_mask: 0.8690  decode.loss_dice: 0.5468  decode.d0.loss_cls: 0.5275  decode.d0.loss_mask: 0.8144  decode.d0.loss_dice: 0.5390  decode.d1.loss_cls: 0.0740  decode.d1.loss_mask: 0.8646  decode.d1.loss_dice: 0.5605  decode.d2.loss_cls: 0.0718  decode.d2.loss_mask: 0.8793  decode.d2.loss_dice: 0.5624  decode.d3.loss_cls: 0.0703  decode.d3.loss_mask: 0.8721  decode.d3.loss_dice: 0.5528  decode.d4.loss_cls: 0.0696  decode.d4.loss_mask: 0.8857  decode.d4.loss_dice: 0.5605  decode.d5.loss_cls: 0.0674  decode.d5.loss_mask: 0.8822  decode.d5.loss_dice: 0.5498  decode.d6.loss_cls: 0.0729  decode.d6.loss_mask: 0.8848  decode.d6.loss_dice: 0.5523  decode.d7.loss_cls: 0.0698  decode.d7.loss_mask: 0.8896  decode.d7.loss_dice: 0.5574  decode.d8.loss_cls: 0.0650  decode.d8.loss_mask: 0.8874  decode.d8.loss_dice: 0.5553
05/27 04:40:05 - mmengine - INFO - Iter(train) [149200/160000]  base_lr: 8.8384e-06 lr: 8.8384e-07  eta: 1:14:33  time: 0.4189  data_time: 0.0101  memory: 5985  grad_norm: 603.5316  loss: 20.3085  decode.loss_cls: 0.1816  decode.loss_mask: 1.0327  decode.loss_dice: 0.7524  decode.d0.loss_cls: 0.6363  decode.d0.loss_mask: 1.0352  decode.d0.loss_dice: 0.7480  decode.d1.loss_cls: 0.2017  decode.d1.loss_mask: 1.0416  decode.d1.loss_dice: 0.7448  decode.d2.loss_cls: 0.1745  decode.d2.loss_mask: 1.0798  decode.d2.loss_dice: 0.7695  decode.d3.loss_cls: 0.2011  decode.d3.loss_mask: 1.0538  decode.d3.loss_dice: 0.7569  decode.d4.loss_cls: 0.2039  decode.d4.loss_mask: 1.0511  decode.d4.loss_dice: 0.7520  decode.d5.loss_cls: 0.1905  decode.d5.loss_mask: 1.0374  decode.d5.loss_dice: 0.7420  decode.d6.loss_cls: 0.1854  decode.d6.loss_mask: 1.0543  decode.d6.loss_dice: 0.7505  decode.d7.loss_cls: 0.1963  decode.d7.loss_mask: 1.0401  decode.d7.loss_dice: 0.7628  decode.d8.loss_cls: 0.1663  decode.d8.loss_mask: 1.0288  decode.d8.loss_dice: 0.7371
05/27 04:40:26 - mmengine - INFO - Iter(train) [149250/160000]  base_lr: 8.8016e-06 lr: 8.8016e-07  eta: 1:14:12  time: 0.4191  data_time: 0.0101  memory: 5982  grad_norm: 560.8676  loss: 18.8439  decode.loss_cls: 0.2815  decode.loss_mask: 0.8836  decode.loss_dice: 0.6250  decode.d0.loss_cls: 0.7628  decode.d0.loss_mask: 0.9054  decode.d0.loss_dice: 0.6600  decode.d1.loss_cls: 0.3190  decode.d1.loss_mask: 0.8949  decode.d1.loss_dice: 0.6419  decode.d2.loss_cls: 0.2891  decode.d2.loss_mask: 0.9525  decode.d2.loss_dice: 0.6595  decode.d3.loss_cls: 0.2876  decode.d3.loss_mask: 0.8769  decode.d3.loss_dice: 0.6330  decode.d4.loss_cls: 0.2597  decode.d4.loss_mask: 0.9218  decode.d4.loss_dice: 0.6153  decode.d5.loss_cls: 0.3217  decode.d5.loss_mask: 0.8925  decode.d5.loss_dice: 0.6340  decode.d6.loss_cls: 0.3381  decode.d6.loss_mask: 0.8840  decode.d6.loss_dice: 0.6484  decode.d7.loss_cls: 0.2942  decode.d7.loss_mask: 0.9111  decode.d7.loss_dice: 0.6219  decode.d8.loss_cls: 0.3010  decode.d8.loss_mask: 0.8901  decode.d8.loss_dice: 0.6374
05/27 04:40:47 - mmengine - INFO - Iter(train) [149300/160000]  base_lr: 8.7648e-06 lr: 8.7648e-07  eta: 1:13:51  time: 0.4185  data_time: 0.0101  memory: 5980  grad_norm: 442.4157  loss: 19.0498  decode.loss_cls: 0.2277  decode.loss_mask: 0.9076  decode.loss_dice: 0.7086  decode.d0.loss_cls: 0.6508  decode.d0.loss_mask: 0.8614  decode.d0.loss_dice: 0.7003  decode.d1.loss_cls: 0.2933  decode.d1.loss_mask: 0.9118  decode.d1.loss_dice: 0.7063  decode.d2.loss_cls: 0.2611  decode.d2.loss_mask: 0.8937  decode.d2.loss_dice: 0.7144  decode.d3.loss_cls: 0.2179  decode.d3.loss_mask: 0.9299  decode.d3.loss_dice: 0.7342  decode.d4.loss_cls: 0.2168  decode.d4.loss_mask: 0.9082  decode.d4.loss_dice: 0.7330  decode.d5.loss_cls: 0.2224  decode.d5.loss_mask: 0.9223  decode.d5.loss_dice: 0.7391  decode.d6.loss_cls: 0.2360  decode.d6.loss_mask: 0.9254  decode.d6.loss_dice: 0.7194  decode.d7.loss_cls: 0.2441  decode.d7.loss_mask: 0.8891  decode.d7.loss_dice: 0.7189  decode.d8.loss_cls: 0.2466  decode.d8.loss_mask: 0.9142  decode.d8.loss_dice: 0.6952
05/27 04:41:08 - mmengine - INFO - Iter(train) [149350/160000]  base_lr: 8.7279e-06 lr: 8.7279e-07  eta: 1:13:31  time: 0.4189  data_time: 0.0101  memory: 5966  grad_norm: 509.6844  loss: 18.0438  decode.loss_cls: 0.1581  decode.loss_mask: 0.9196  decode.loss_dice: 0.6655  decode.d0.loss_cls: 0.6369  decode.d0.loss_mask: 0.9069  decode.d0.loss_dice: 0.6740  decode.d1.loss_cls: 0.1698  decode.d1.loss_mask: 0.9132  decode.d1.loss_dice: 0.6799  decode.d2.loss_cls: 0.2215  decode.d2.loss_mask: 0.8886  decode.d2.loss_dice: 0.6294  decode.d3.loss_cls: 0.1981  decode.d3.loss_mask: 0.9107  decode.d3.loss_dice: 0.6553  decode.d4.loss_cls: 0.1989  decode.d4.loss_mask: 0.9030  decode.d4.loss_dice: 0.6516  decode.d5.loss_cls: 0.1831  decode.d5.loss_mask: 0.9026  decode.d5.loss_dice: 0.6585  decode.d6.loss_cls: 0.2001  decode.d6.loss_mask: 0.9120  decode.d6.loss_dice: 0.6562  decode.d7.loss_cls: 0.1885  decode.d7.loss_mask: 0.9174  decode.d7.loss_dice: 0.6768  decode.d8.loss_cls: 0.1718  decode.d8.loss_mask: 0.9179  decode.d8.loss_dice: 0.6777
05/27 04:41:29 - mmengine - INFO - Iter(train) [149400/160000]  base_lr: 8.6910e-06 lr: 8.6910e-07  eta: 1:13:10  time: 0.4192  data_time: 0.0100  memory: 5969  grad_norm: 431.8901  loss: 17.2110  decode.loss_cls: 0.1431  decode.loss_mask: 0.8704  decode.loss_dice: 0.6395  decode.d0.loss_cls: 0.5795  decode.d0.loss_mask: 0.8585  decode.d0.loss_dice: 0.6428  decode.d1.loss_cls: 0.1815  decode.d1.loss_mask: 0.8773  decode.d1.loss_dice: 0.6641  decode.d2.loss_cls: 0.1654  decode.d2.loss_mask: 0.8872  decode.d2.loss_dice: 0.6608  decode.d3.loss_cls: 0.1379  decode.d3.loss_mask: 0.8743  decode.d3.loss_dice: 0.6348  decode.d4.loss_cls: 0.1532  decode.d4.loss_mask: 0.8678  decode.d4.loss_dice: 0.6443  decode.d5.loss_cls: 0.1516  decode.d5.loss_mask: 0.8779  decode.d5.loss_dice: 0.6418  decode.d6.loss_cls: 0.1601  decode.d6.loss_mask: 0.8806  decode.d6.loss_dice: 0.6478  decode.d7.loss_cls: 0.1710  decode.d7.loss_mask: 0.8675  decode.d7.loss_dice: 0.6486  decode.d8.loss_cls: 0.1615  decode.d8.loss_mask: 0.8726  decode.d8.loss_dice: 0.6478
05/27 04:41:50 - mmengine - INFO - Iter(train) [149450/160000]  base_lr: 8.6541e-06 lr: 8.6541e-07  eta: 1:12:49  time: 0.4191  data_time: 0.0100  memory: 5976  grad_norm: 599.3132  loss: 17.2009  decode.loss_cls: 0.1505  decode.loss_mask: 0.8840  decode.loss_dice: 0.6355  decode.d0.loss_cls: 0.5994  decode.d0.loss_mask: 0.8723  decode.d0.loss_dice: 0.6747  decode.d1.loss_cls: 0.1304  decode.d1.loss_mask: 0.8712  decode.d1.loss_dice: 0.6554  decode.d2.loss_cls: 0.1745  decode.d2.loss_mask: 0.8718  decode.d2.loss_dice: 0.6486  decode.d3.loss_cls: 0.1512  decode.d3.loss_mask: 0.8784  decode.d3.loss_dice: 0.6366  decode.d4.loss_cls: 0.1393  decode.d4.loss_mask: 0.8837  decode.d4.loss_dice: 0.6393  decode.d5.loss_cls: 0.1426  decode.d5.loss_mask: 0.8759  decode.d5.loss_dice: 0.6494  decode.d6.loss_cls: 0.1333  decode.d6.loss_mask: 0.9010  decode.d6.loss_dice: 0.6581  decode.d7.loss_cls: 0.1594  decode.d7.loss_mask: 0.8758  decode.d7.loss_dice: 0.6471  decode.d8.loss_cls: 0.1449  decode.d8.loss_mask: 0.8759  decode.d8.loss_dice: 0.6405
05/27 04:42:11 - mmengine - INFO - Iter(train) [149500/160000]  base_lr: 8.6172e-06 lr: 8.6172e-07  eta: 1:12:28  time: 0.4202  data_time: 0.0100  memory: 5966  grad_norm: 678.8756  loss: 18.3945  decode.loss_cls: 0.1576  decode.loss_mask: 0.9777  decode.loss_dice: 0.6545  decode.d0.loss_cls: 0.7231  decode.d0.loss_mask: 0.8871  decode.d0.loss_dice: 0.6307  decode.d1.loss_cls: 0.1955  decode.d1.loss_mask: 0.9852  decode.d1.loss_dice: 0.6541  decode.d2.loss_cls: 0.1992  decode.d2.loss_mask: 0.9674  decode.d2.loss_dice: 0.6424  decode.d3.loss_cls: 0.1781  decode.d3.loss_mask: 0.9704  decode.d3.loss_dice: 0.6412  decode.d4.loss_cls: 0.2176  decode.d4.loss_mask: 0.9060  decode.d4.loss_dice: 0.6396  decode.d5.loss_cls: 0.1866  decode.d5.loss_mask: 0.9673  decode.d5.loss_dice: 0.6514  decode.d6.loss_cls: 0.1895  decode.d6.loss_mask: 0.9736  decode.d6.loss_dice: 0.6578  decode.d7.loss_cls: 0.1813  decode.d7.loss_mask: 0.9697  decode.d7.loss_dice: 0.6386  decode.d8.loss_cls: 0.2031  decode.d8.loss_mask: 0.9125  decode.d8.loss_dice: 0.6355
05/27 04:42:31 - mmengine - INFO - Iter(train) [149550/160000]  base_lr: 8.5802e-06 lr: 8.5802e-07  eta: 1:12:08  time: 0.4190  data_time: 0.0101  memory: 5972  grad_norm: 809.0447  loss: 19.3174  decode.loss_cls: 0.1225  decode.loss_mask: 1.0623  decode.loss_dice: 0.6978  decode.d0.loss_cls: 0.4623  decode.d0.loss_mask: 1.0610  decode.d0.loss_dice: 0.6600  decode.d1.loss_cls: 0.1299  decode.d1.loss_mask: 1.0898  decode.d1.loss_dice: 0.7254  decode.d2.loss_cls: 0.1080  decode.d2.loss_mask: 1.0834  decode.d2.loss_dice: 0.7170  decode.d3.loss_cls: 0.1252  decode.d3.loss_mask: 1.0869  decode.d3.loss_dice: 0.7100  decode.d4.loss_cls: 0.1284  decode.d4.loss_mask: 1.0753  decode.d4.loss_dice: 0.6951  decode.d5.loss_cls: 0.1303  decode.d5.loss_mask: 1.0711  decode.d5.loss_dice: 0.6977  decode.d6.loss_cls: 0.1266  decode.d6.loss_mask: 1.0785  decode.d6.loss_dice: 0.7017  decode.d7.loss_cls: 0.1243  decode.d7.loss_mask: 1.0719  decode.d7.loss_dice: 0.7118  decode.d8.loss_cls: 0.1104  decode.d8.loss_mask: 1.0572  decode.d8.loss_dice: 0.6955
05/27 04:42:52 - mmengine - INFO - Iter(train) [149600/160000]  base_lr: 8.5433e-06 lr: 8.5433e-07  eta: 1:11:47  time: 0.4191  data_time: 0.0101  memory: 5984  grad_norm: 804.4930  loss: 19.0188  decode.loss_cls: 0.1177  decode.loss_mask: 1.0133  decode.loss_dice: 0.7121  decode.d0.loss_cls: 0.6033  decode.d0.loss_mask: 0.9924  decode.d0.loss_dice: 0.7023  decode.d1.loss_cls: 0.1063  decode.d1.loss_mask: 1.0323  decode.d1.loss_dice: 0.7345  decode.d2.loss_cls: 0.0888  decode.d2.loss_mask: 1.0143  decode.d2.loss_dice: 0.7214  decode.d3.loss_cls: 0.1045  decode.d3.loss_mask: 0.9973  decode.d3.loss_dice: 0.7079  decode.d4.loss_cls: 0.1137  decode.d4.loss_mask: 1.0309  decode.d4.loss_dice: 0.7203  decode.d5.loss_cls: 0.1167  decode.d5.loss_mask: 1.0270  decode.d5.loss_dice: 0.7191  decode.d6.loss_cls: 0.1091  decode.d6.loss_mask: 1.0317  decode.d6.loss_dice: 0.7144  decode.d7.loss_cls: 0.0947  decode.d7.loss_mask: 1.0438  decode.d7.loss_dice: 0.7380  decode.d8.loss_cls: 0.1215  decode.d8.loss_mask: 1.0526  decode.d8.loss_dice: 0.7369
05/27 04:43:14 - mmengine - INFO - Iter(train) [149650/160000]  base_lr: 8.5063e-06 lr: 8.5063e-07  eta: 1:11:26  time: 0.4199  data_time: 0.0101  memory: 5968  grad_norm: 460.8578  loss: 17.4320  decode.loss_cls: 0.1364  decode.loss_mask: 0.9223  decode.loss_dice: 0.6245  decode.d0.loss_cls: 0.5021  decode.d0.loss_mask: 0.9488  decode.d0.loss_dice: 0.6332  decode.d1.loss_cls: 0.1543  decode.d1.loss_mask: 0.9299  decode.d1.loss_dice: 0.6179  decode.d2.loss_cls: 0.1289  decode.d2.loss_mask: 0.9310  decode.d2.loss_dice: 0.6390  decode.d3.loss_cls: 0.1500  decode.d3.loss_mask: 0.9313  decode.d3.loss_dice: 0.6254  decode.d4.loss_cls: 0.1514  decode.d4.loss_mask: 0.9329  decode.d4.loss_dice: 0.6080  decode.d5.loss_cls: 0.1566  decode.d5.loss_mask: 0.9233  decode.d5.loss_dice: 0.6361  decode.d6.loss_cls: 0.1500  decode.d6.loss_mask: 0.9205  decode.d6.loss_dice: 0.6317  decode.d7.loss_cls: 0.1656  decode.d7.loss_mask: 0.9319  decode.d7.loss_dice: 0.6236  decode.d8.loss_cls: 0.1603  decode.d8.loss_mask: 0.9352  decode.d8.loss_dice: 0.6298
05/27 04:43:35 - mmengine - INFO - Iter(train) [149700/160000]  base_lr: 8.4693e-06 lr: 8.4693e-07  eta: 1:11:06  time: 0.4197  data_time: 0.0100  memory: 5984  grad_norm: 327.3760  loss: 14.4507  decode.loss_cls: 0.0985  decode.loss_mask: 0.7189  decode.loss_dice: 0.5650  decode.d0.loss_cls: 0.5153  decode.d0.loss_mask: 0.7382  decode.d0.loss_dice: 0.5791  decode.d1.loss_cls: 0.1308  decode.d1.loss_mask: 0.7211  decode.d1.loss_dice: 0.5669  decode.d2.loss_cls: 0.1020  decode.d2.loss_mask: 0.7335  decode.d2.loss_dice: 0.5718  decode.d3.loss_cls: 0.0870  decode.d3.loss_mask: 0.7211  decode.d3.loss_dice: 0.5735  decode.d4.loss_cls: 0.0991  decode.d4.loss_mask: 0.7317  decode.d4.loss_dice: 0.5657  decode.d5.loss_cls: 0.1250  decode.d5.loss_mask: 0.7266  decode.d5.loss_dice: 0.5727  decode.d6.loss_cls: 0.1006  decode.d6.loss_mask: 0.7190  decode.d6.loss_dice: 0.5717  decode.d7.loss_cls: 0.1047  decode.d7.loss_mask: 0.7200  decode.d7.loss_dice: 0.5670  decode.d8.loss_cls: 0.1149  decode.d8.loss_mask: 0.7287  decode.d8.loss_dice: 0.5805
05/27 04:43:55 - mmengine - INFO - Iter(train) [149750/160000]  base_lr: 8.4323e-06 lr: 8.4323e-07  eta: 1:10:45  time: 0.4193  data_time: 0.0100  memory: 5974  grad_norm: 741.7274  loss: 17.9056  decode.loss_cls: 0.2115  decode.loss_mask: 0.8688  decode.loss_dice: 0.6469  decode.d0.loss_cls: 0.6260  decode.d0.loss_mask: 0.8812  decode.d0.loss_dice: 0.6714  decode.d1.loss_cls: 0.2051  decode.d1.loss_mask: 0.8868  decode.d1.loss_dice: 0.6699  decode.d2.loss_cls: 0.1996  decode.d2.loss_mask: 0.8765  decode.d2.loss_dice: 0.6569  decode.d3.loss_cls: 0.2014  decode.d3.loss_mask: 0.8983  decode.d3.loss_dice: 0.6687  decode.d4.loss_cls: 0.2051  decode.d4.loss_mask: 0.8864  decode.d4.loss_dice: 0.6597  decode.d5.loss_cls: 0.1957  decode.d5.loss_mask: 0.8878  decode.d5.loss_dice: 0.6677  decode.d6.loss_cls: 0.1754  decode.d6.loss_mask: 0.8886  decode.d6.loss_dice: 0.6783  decode.d7.loss_cls: 0.2129  decode.d7.loss_mask: 0.8954  decode.d7.loss_dice: 0.6453  decode.d8.loss_cls: 0.2107  decode.d8.loss_mask: 0.8741  decode.d8.loss_dice: 0.6537
05/27 04:44:17 - mmengine - INFO - Iter(train) [149800/160000]  base_lr: 8.3953e-06 lr: 8.3953e-07  eta: 1:10:24  time: 0.4184  data_time: 0.0100  memory: 5977  grad_norm: 514.7020  loss: 18.4156  decode.loss_cls: 0.3460  decode.loss_mask: 0.8378  decode.loss_dice: 0.5817  decode.d0.loss_cls: 0.7272  decode.d0.loss_mask: 0.8480  decode.d0.loss_dice: 0.6125  decode.d1.loss_cls: 0.3354  decode.d1.loss_mask: 0.8664  decode.d1.loss_dice: 0.6314  decode.d2.loss_cls: 0.3644  decode.d2.loss_mask: 0.8322  decode.d2.loss_dice: 0.6066  decode.d3.loss_cls: 0.3417  decode.d3.loss_mask: 0.8537  decode.d3.loss_dice: 0.5850  decode.d4.loss_cls: 0.3467  decode.d4.loss_mask: 0.8851  decode.d4.loss_dice: 0.6046  decode.d5.loss_cls: 0.3251  decode.d5.loss_mask: 0.8408  decode.d5.loss_dice: 0.5953  decode.d6.loss_cls: 0.3589  decode.d6.loss_mask: 0.8619  decode.d6.loss_dice: 0.5869  decode.d7.loss_cls: 0.3517  decode.d7.loss_mask: 0.8521  decode.d7.loss_dice: 0.6190  decode.d8.loss_cls: 0.3332  decode.d8.loss_mask: 0.8677  decode.d8.loss_dice: 0.6168
05/27 04:44:38 - mmengine - INFO - Iter(train) [149850/160000]  base_lr: 8.3582e-06 lr: 8.3582e-07  eta: 1:10:04  time: 0.4207  data_time: 0.0101  memory: 5966  grad_norm: 746.8630  loss: 14.7993  decode.loss_cls: 0.0813  decode.loss_mask: 0.8755  decode.loss_dice: 0.4900  decode.d0.loss_cls: 0.5645  decode.d0.loss_mask: 0.8036  decode.d0.loss_dice: 0.4793  decode.d1.loss_cls: 0.1295  decode.d1.loss_mask: 0.8662  decode.d1.loss_dice: 0.4975  decode.d2.loss_cls: 0.0841  decode.d2.loss_mask: 0.8629  decode.d2.loss_dice: 0.4873  decode.d3.loss_cls: 0.1016  decode.d3.loss_mask: 0.8676  decode.d3.loss_dice: 0.4862  decode.d4.loss_cls: 0.1086  decode.d4.loss_mask: 0.8740  decode.d4.loss_dice: 0.4864  decode.d5.loss_cls: 0.0983  decode.d5.loss_mask: 0.8358  decode.d5.loss_dice: 0.4685  decode.d6.loss_cls: 0.1320  decode.d6.loss_mask: 0.8323  decode.d6.loss_dice: 0.4731  decode.d7.loss_cls: 0.1002  decode.d7.loss_mask: 0.8414  decode.d7.loss_dice: 0.4656  decode.d8.loss_cls: 0.0936  decode.d8.loss_mask: 0.8398  decode.d8.loss_dice: 0.4728
05/27 04:44:59 - mmengine - INFO - Iter(train) [149900/160000]  base_lr: 8.3212e-06 lr: 8.3212e-07  eta: 1:09:43  time: 0.4186  data_time: 0.0101  memory: 5966  grad_norm: 619.6431  loss: 19.4774  decode.loss_cls: 0.1759  decode.loss_mask: 1.0001  decode.loss_dice: 0.6946  decode.d0.loss_cls: 0.7419  decode.d0.loss_mask: 0.9188  decode.d0.loss_dice: 0.6919  decode.d1.loss_cls: 0.1826  decode.d1.loss_mask: 0.9879  decode.d1.loss_dice: 0.6957  decode.d2.loss_cls: 0.2079  decode.d2.loss_mask: 1.0241  decode.d2.loss_dice: 0.6922  decode.d3.loss_cls: 0.1944  decode.d3.loss_mask: 1.0216  decode.d3.loss_dice: 0.6862  decode.d4.loss_cls: 0.2069  decode.d4.loss_mask: 1.0079  decode.d4.loss_dice: 0.7152  decode.d5.loss_cls: 0.2154  decode.d5.loss_mask: 0.9949  decode.d5.loss_dice: 0.6860  decode.d6.loss_cls: 0.1809  decode.d6.loss_mask: 1.0082  decode.d6.loss_dice: 0.6761  decode.d7.loss_cls: 0.1882  decode.d7.loss_mask: 1.0140  decode.d7.loss_dice: 0.6998  decode.d8.loss_cls: 0.1753  decode.d8.loss_mask: 1.0661  decode.d8.loss_dice: 0.7267
05/27 04:45:20 - mmengine - INFO - Iter(train) [149950/160000]  base_lr: 8.2841e-06 lr: 8.2841e-07  eta: 1:09:22  time: 0.4194  data_time: 0.0101  memory: 5996  grad_norm: 711.1764  loss: 19.1110  decode.loss_cls: 0.2902  decode.loss_mask: 0.8783  decode.loss_dice: 0.6819  decode.d0.loss_cls: 0.8086  decode.d0.loss_mask: 0.8463  decode.d0.loss_dice: 0.6837  decode.d1.loss_cls: 0.3172  decode.d1.loss_mask: 0.8825  decode.d1.loss_dice: 0.6866  decode.d2.loss_cls: 0.2650  decode.d2.loss_mask: 0.9415  decode.d2.loss_dice: 0.6871  decode.d3.loss_cls: 0.3324  decode.d3.loss_mask: 0.9103  decode.d3.loss_dice: 0.6740  decode.d4.loss_cls: 0.3331  decode.d4.loss_mask: 0.8191  decode.d4.loss_dice: 0.6529  decode.d5.loss_cls: 0.3061  decode.d5.loss_mask: 0.8475  decode.d5.loss_dice: 0.6587  decode.d6.loss_cls: 0.2803  decode.d6.loss_mask: 0.9103  decode.d6.loss_dice: 0.6858  decode.d7.loss_cls: 0.3007  decode.d7.loss_mask: 0.8705  decode.d7.loss_dice: 0.6676  decode.d8.loss_cls: 0.3153  decode.d8.loss_mask: 0.8837  decode.d8.loss_dice: 0.6937
05/27 04:45:41 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 04:45:41 - mmengine - INFO - Iter(train) [150000/160000]  base_lr: 8.2470e-06 lr: 8.2470e-07  eta: 1:09:02  time: 0.4196  data_time: 0.0100  memory: 5968  grad_norm: 899.9217  loss: 21.6794  decode.loss_cls: 0.2486  decode.loss_mask: 1.1119  decode.loss_dice: 0.7636  decode.d0.loss_cls: 0.7977  decode.d0.loss_mask: 0.9945  decode.d0.loss_dice: 0.7574  decode.d1.loss_cls: 0.2995  decode.d1.loss_mask: 1.0985  decode.d1.loss_dice: 0.7807  decode.d2.loss_cls: 0.2853  decode.d2.loss_mask: 1.0920  decode.d2.loss_dice: 0.7505  decode.d3.loss_cls: 0.2829  decode.d3.loss_mask: 1.0818  decode.d3.loss_dice: 0.7661  decode.d4.loss_cls: 0.3189  decode.d4.loss_mask: 1.0555  decode.d4.loss_dice: 0.7598  decode.d5.loss_cls: 0.2833  decode.d5.loss_mask: 1.0907  decode.d5.loss_dice: 0.7564  decode.d6.loss_cls: 0.2940  decode.d6.loss_mask: 1.0716  decode.d6.loss_dice: 0.7492  decode.d7.loss_cls: 0.2871  decode.d7.loss_mask: 1.0361  decode.d7.loss_dice: 0.7309  decode.d8.loss_cls: 0.2949  decode.d8.loss_mask: 1.0893  decode.d8.loss_dice: 0.7505
05/27 04:45:41 - mmengine - INFO - Saving checkpoint at 150000 iterations
05/27 04:45:45 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:07  time: 0.0477  data_time: 0.0012  memory: 1391  
05/27 04:45:47 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:04  time: 0.0480  data_time: 0.0014  memory: 1205  
05/27 04:45:50 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:02  time: 0.0503  data_time: 0.0012  memory: 1596  
05/27 04:45:52 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0483  data_time: 0.0012  memory: 1298  
05/27 04:45:55 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:57  time: 0.0476  data_time: 0.0012  memory: 1298  
05/27 04:45:57 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0483  data_time: 0.0015  memory: 1279  
05/27 04:45:59 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:52  time: 0.0477  data_time: 0.0012  memory: 1224  
05/27 04:46:02 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0486  data_time: 0.0012  memory: 1298  
05/27 04:46:04 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0475  data_time: 0.0013  memory: 1298  
05/27 04:46:07 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0512  data_time: 0.0012  memory: 1725  
05/27 04:46:09 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0478  data_time: 0.0013  memory: 1336  
05/27 04:46:11 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0487  data_time: 0.0012  memory: 1298  
05/27 04:46:14 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0481  data_time: 0.0012  memory: 1205  
05/27 04:46:16 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:35  time: 0.0487  data_time: 0.0012  memory: 1316  
05/27 04:46:19 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0475  data_time: 0.0012  memory: 1279  
05/27 04:46:21 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0510  data_time: 0.0012  memory: 1410  
05/27 04:46:24 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0475  data_time: 0.0012  memory: 1279  
05/27 04:46:26 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0483  data_time: 0.0012  memory: 1205  
05/27 04:46:28 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:23  time: 0.0484  data_time: 0.0012  memory: 1205  
05/27 04:46:31 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0476  data_time: 0.0012  memory: 1336  
05/27 04:46:33 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0473  data_time: 0.0012  memory: 1246  
05/27 04:46:36 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0499  data_time: 0.0012  memory: 1503  
05/27 04:46:38 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0475  data_time: 0.0012  memory: 1261  
05/27 04:46:40 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0484  data_time: 0.0012  memory: 1298  
05/27 04:46:43 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0475  data_time: 0.0012  memory: 1447  
05/27 04:46:45 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0474  data_time: 0.0012  memory: 1298  
05/27 04:46:48 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0489  data_time: 0.0012  memory: 1279  
05/27 04:46:50 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0476  data_time: 0.0012  memory: 1205  
05/27 04:46:52 - mmengine - INFO - per class results:
05/27 04:46:52 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.82 | 97.37 |
|  aeroplane  | 92.21 | 96.19 |
|   bicycle   | 44.85 | 97.34 |
|     bird    | 94.52 | 98.49 |
|     boat    | 68.27 | 91.03 |
|    bottle   | 84.82 | 95.24 |
|     bus     | 95.47 | 98.61 |
|     car     |  92.0 | 95.74 |
|     cat     | 95.11 | 97.57 |
|    chair    | 44.33 | 70.07 |
|     cow     | 90.86 | 97.35 |
| diningtable | 67.65 | 73.58 |
|     dog     | 91.88 | 98.55 |
|    horse    | 90.61 | 94.77 |
|  motorbike  | 92.52 | 96.57 |
|    person   | 90.59 | 95.24 |
| pottedplant | 72.92 | 91.22 |
|    sheep    | 88.71 | 92.41 |
|     sofa    | 58.88 |  69.1 |
|    train    |  87.4 | 95.63 |
|  tvmonitor  | 86.44 | 88.57 |
+-------------+-------+-------+
05/27 04:46:52 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 96.1200  mIoU: 82.1800  mAcc: 91.9400  data_time: 0.0013  time: 0.0480
05/27 04:47:13 - mmengine - INFO - Iter(train) [150050/160000]  base_lr: 8.2099e-06 lr: 8.2099e-07  eta: 1:08:41  time: 0.4185  data_time: 0.0101  memory: 5972  grad_norm: 484.6436  loss: 16.5178  decode.loss_cls: 0.1229  decode.loss_mask: 0.8347  decode.loss_dice: 0.6044  decode.d0.loss_cls: 0.6342  decode.d0.loss_mask: 0.8212  decode.d0.loss_dice: 0.5931  decode.d1.loss_cls: 0.1312  decode.d1.loss_mask: 0.8405  decode.d1.loss_dice: 0.6153  decode.d2.loss_cls: 0.1437  decode.d2.loss_mask: 0.8547  decode.d2.loss_dice: 0.6109  decode.d3.loss_cls: 0.1325  decode.d3.loss_mask: 0.8627  decode.d3.loss_dice: 0.6073  decode.d4.loss_cls: 0.1164  decode.d4.loss_mask: 0.8674  decode.d4.loss_dice: 0.6165  decode.d5.loss_cls: 0.1117  decode.d5.loss_mask: 0.8787  decode.d5.loss_dice: 0.6319  decode.d6.loss_cls: 0.1371  decode.d6.loss_mask: 0.8673  decode.d6.loss_dice: 0.6252  decode.d7.loss_cls: 0.1246  decode.d7.loss_mask: 0.8764  decode.d7.loss_dice: 0.6448  decode.d8.loss_cls: 0.1273  decode.d8.loss_mask: 0.8651  decode.d8.loss_dice: 0.6179
05/27 04:47:34 - mmengine - INFO - Iter(train) [150100/160000]  base_lr: 8.1727e-06 lr: 8.1727e-07  eta: 1:08:20  time: 0.4185  data_time: 0.0102  memory: 5975  grad_norm: 446.2358  loss: 15.8716  decode.loss_cls: 0.1379  decode.loss_mask: 0.8218  decode.loss_dice: 0.5739  decode.d0.loss_cls: 0.6329  decode.d0.loss_mask: 0.8265  decode.d0.loss_dice: 0.5943  decode.d1.loss_cls: 0.1657  decode.d1.loss_mask: 0.8005  decode.d1.loss_dice: 0.5748  decode.d2.loss_cls: 0.1234  decode.d2.loss_mask: 0.8246  decode.d2.loss_dice: 0.5749  decode.d3.loss_cls: 0.1230  decode.d3.loss_mask: 0.8238  decode.d3.loss_dice: 0.5750  decode.d4.loss_cls: 0.1275  decode.d4.loss_mask: 0.8229  decode.d4.loss_dice: 0.5803  decode.d5.loss_cls: 0.1544  decode.d5.loss_mask: 0.8225  decode.d5.loss_dice: 0.5636  decode.d6.loss_cls: 0.1372  decode.d6.loss_mask: 0.8238  decode.d6.loss_dice: 0.5627  decode.d7.loss_cls: 0.1457  decode.d7.loss_mask: 0.8230  decode.d7.loss_dice: 0.5788  decode.d8.loss_cls: 0.1601  decode.d8.loss_mask: 0.8204  decode.d8.loss_dice: 0.5757
05/27 04:47:55 - mmengine - INFO - Iter(train) [150150/160000]  base_lr: 8.1356e-06 lr: 8.1356e-07  eta: 1:07:59  time: 0.4185  data_time: 0.0101  memory: 5981  grad_norm: 508.3201  loss: 18.0660  decode.loss_cls: 0.2154  decode.loss_mask: 0.8280  decode.loss_dice: 0.6822  decode.d0.loss_cls: 0.7691  decode.d0.loss_mask: 0.8114  decode.d0.loss_dice: 0.7100  decode.d1.loss_cls: 0.3091  decode.d1.loss_mask: 0.8274  decode.d1.loss_dice: 0.6832  decode.d2.loss_cls: 0.2429  decode.d2.loss_mask: 0.8192  decode.d2.loss_dice: 0.7039  decode.d3.loss_cls: 0.2484  decode.d3.loss_mask: 0.8367  decode.d3.loss_dice: 0.6950  decode.d4.loss_cls: 0.2440  decode.d4.loss_mask: 0.8310  decode.d4.loss_dice: 0.6985  decode.d5.loss_cls: 0.2169  decode.d5.loss_mask: 0.8249  decode.d5.loss_dice: 0.6951  decode.d6.loss_cls: 0.2081  decode.d6.loss_mask: 0.8295  decode.d6.loss_dice: 0.7094  decode.d7.loss_cls: 0.2068  decode.d7.loss_mask: 0.8193  decode.d7.loss_dice: 0.6870  decode.d8.loss_cls: 0.2051  decode.d8.loss_mask: 0.8210  decode.d8.loss_dice: 0.6876
05/27 04:48:16 - mmengine - INFO - Iter(train) [150200/160000]  base_lr: 8.0984e-06 lr: 8.0984e-07  eta: 1:07:39  time: 0.4181  data_time: 0.0102  memory: 5973  grad_norm: 303.1090  loss: 16.9255  decode.loss_cls: 0.1584  decode.loss_mask: 0.8891  decode.loss_dice: 0.5797  decode.d0.loss_cls: 0.6079  decode.d0.loss_mask: 0.9079  decode.d0.loss_dice: 0.5726  decode.d1.loss_cls: 0.1344  decode.d1.loss_mask: 0.9733  decode.d1.loss_dice: 0.6276  decode.d2.loss_cls: 0.1206  decode.d2.loss_mask: 0.9271  decode.d2.loss_dice: 0.6075  decode.d3.loss_cls: 0.1308  decode.d3.loss_mask: 0.9284  decode.d3.loss_dice: 0.6078  decode.d4.loss_cls: 0.1501  decode.d4.loss_mask: 0.9061  decode.d4.loss_dice: 0.5853  decode.d5.loss_cls: 0.1360  decode.d5.loss_mask: 0.9136  decode.d5.loss_dice: 0.5956  decode.d6.loss_cls: 0.1346  decode.d6.loss_mask: 0.9050  decode.d6.loss_dice: 0.5795  decode.d7.loss_cls: 0.1562  decode.d7.loss_mask: 0.8899  decode.d7.loss_dice: 0.5749  decode.d8.loss_cls: 0.1419  decode.d8.loss_mask: 0.9028  decode.d8.loss_dice: 0.5810
05/27 04:48:37 - mmengine - INFO - Iter(train) [150250/160000]  base_lr: 8.0612e-06 lr: 8.0612e-07  eta: 1:07:18  time: 0.4188  data_time: 0.0102  memory: 5967  grad_norm: 483.3763  loss: 17.7725  decode.loss_cls: 0.1947  decode.loss_mask: 0.8626  decode.loss_dice: 0.6414  decode.d0.loss_cls: 0.6643  decode.d0.loss_mask: 0.8455  decode.d0.loss_dice: 0.6544  decode.d1.loss_cls: 0.2248  decode.d1.loss_mask: 0.8753  decode.d1.loss_dice: 0.6629  decode.d2.loss_cls: 0.1607  decode.d2.loss_mask: 0.9740  decode.d2.loss_dice: 0.6758  decode.d3.loss_cls: 0.1786  decode.d3.loss_mask: 0.8739  decode.d3.loss_dice: 0.6571  decode.d4.loss_cls: 0.1880  decode.d4.loss_mask: 0.8766  decode.d4.loss_dice: 0.6469  decode.d5.loss_cls: 0.1995  decode.d5.loss_mask: 0.8773  decode.d5.loss_dice: 0.6563  decode.d6.loss_cls: 0.1754  decode.d6.loss_mask: 0.8923  decode.d6.loss_dice: 0.6493  decode.d7.loss_cls: 0.1666  decode.d7.loss_mask: 0.9263  decode.d7.loss_dice: 0.6804  decode.d8.loss_cls: 0.1630  decode.d8.loss_mask: 0.8709  decode.d8.loss_dice: 0.6578
05/27 04:48:58 - mmengine - INFO - Iter(train) [150300/160000]  base_lr: 8.0240e-06 lr: 8.0240e-07  eta: 1:06:57  time: 0.4185  data_time: 0.0100  memory: 5971  grad_norm: 797.7105  loss: 21.4843  decode.loss_cls: 0.1697  decode.loss_mask: 1.1140  decode.loss_dice: 0.7826  decode.d0.loss_cls: 0.7667  decode.d0.loss_mask: 1.0771  decode.d0.loss_dice: 0.7791  decode.d1.loss_cls: 0.2126  decode.d1.loss_mask: 1.1174  decode.d1.loss_dice: 0.8052  decode.d2.loss_cls: 0.1901  decode.d2.loss_mask: 1.1331  decode.d2.loss_dice: 0.7951  decode.d3.loss_cls: 0.1846  decode.d3.loss_mask: 1.1129  decode.d3.loss_dice: 0.7801  decode.d4.loss_cls: 0.1817  decode.d4.loss_mask: 1.1192  decode.d4.loss_dice: 0.7891  decode.d5.loss_cls: 0.2145  decode.d5.loss_mask: 1.1202  decode.d5.loss_dice: 0.7740  decode.d6.loss_cls: 0.1936  decode.d6.loss_mask: 1.1178  decode.d6.loss_dice: 0.7785  decode.d7.loss_cls: 0.2009  decode.d7.loss_mask: 1.1175  decode.d7.loss_dice: 0.7847  decode.d8.loss_cls: 0.1935  decode.d8.loss_mask: 1.1110  decode.d8.loss_dice: 0.7680
05/27 04:49:19 - mmengine - INFO - Iter(train) [150350/160000]  base_lr: 7.9867e-06 lr: 7.9867e-07  eta: 1:06:37  time: 0.4185  data_time: 0.0100  memory: 5978  grad_norm: 487.9289  loss: 18.3428  decode.loss_cls: 0.2848  decode.loss_mask: 0.8347  decode.loss_dice: 0.6413  decode.d0.loss_cls: 0.8067  decode.d0.loss_mask: 0.8040  decode.d0.loss_dice: 0.6299  decode.d1.loss_cls: 0.2626  decode.d1.loss_mask: 0.8864  decode.d1.loss_dice: 0.6717  decode.d2.loss_cls: 0.2579  decode.d2.loss_mask: 0.8502  decode.d2.loss_dice: 0.6546  decode.d3.loss_cls: 0.2714  decode.d3.loss_mask: 0.8575  decode.d3.loss_dice: 0.6573  decode.d4.loss_cls: 0.2957  decode.d4.loss_mask: 0.8570  decode.d4.loss_dice: 0.6577  decode.d5.loss_cls: 0.3082  decode.d5.loss_mask: 0.8360  decode.d5.loss_dice: 0.6484  decode.d6.loss_cls: 0.2815  decode.d6.loss_mask: 0.8494  decode.d6.loss_dice: 0.6449  decode.d7.loss_cls: 0.2976  decode.d7.loss_mask: 0.8434  decode.d7.loss_dice: 0.6603  decode.d8.loss_cls: 0.2924  decode.d8.loss_mask: 0.8380  decode.d8.loss_dice: 0.6614
05/27 04:49:40 - mmengine - INFO - Iter(train) [150400/160000]  base_lr: 7.9495e-06 lr: 7.9495e-07  eta: 1:06:16  time: 0.4190  data_time: 0.0100  memory: 5965  grad_norm: 645.1554  loss: 19.7736  decode.loss_cls: 0.1334  decode.loss_mask: 1.0308  decode.loss_dice: 0.7391  decode.d0.loss_cls: 0.6985  decode.d0.loss_mask: 1.0193  decode.d0.loss_dice: 0.7272  decode.d1.loss_cls: 0.1791  decode.d1.loss_mask: 1.0089  decode.d1.loss_dice: 0.7299  decode.d2.loss_cls: 0.1688  decode.d2.loss_mask: 1.0503  decode.d2.loss_dice: 0.7319  decode.d3.loss_cls: 0.1416  decode.d3.loss_mask: 1.0354  decode.d3.loss_dice: 0.7323  decode.d4.loss_cls: 0.0998  decode.d4.loss_mask: 1.0885  decode.d4.loss_dice: 0.7594  decode.d5.loss_cls: 0.1622  decode.d5.loss_mask: 1.0360  decode.d5.loss_dice: 0.7317  decode.d6.loss_cls: 0.1701  decode.d6.loss_mask: 1.0243  decode.d6.loss_dice: 0.7146  decode.d7.loss_cls: 0.1613  decode.d7.loss_mask: 1.0453  decode.d7.loss_dice: 0.7152  decode.d8.loss_cls: 0.1295  decode.d8.loss_mask: 1.0536  decode.d8.loss_dice: 0.7551
05/27 04:50:01 - mmengine - INFO - Iter(train) [150450/160000]  base_lr: 7.9122e-06 lr: 7.9122e-07  eta: 1:05:55  time: 0.4194  data_time: 0.0101  memory: 5971  grad_norm: 279.9914  loss: 18.6008  decode.loss_cls: 0.1635  decode.loss_mask: 0.9412  decode.loss_dice: 0.7203  decode.d0.loss_cls: 0.6425  decode.d0.loss_mask: 0.9443  decode.d0.loss_dice: 0.7084  decode.d1.loss_cls: 0.1892  decode.d1.loss_mask: 0.9191  decode.d1.loss_dice: 0.7143  decode.d2.loss_cls: 0.1511  decode.d2.loss_mask: 0.9325  decode.d2.loss_dice: 0.7284  decode.d3.loss_cls: 0.1766  decode.d3.loss_mask: 0.9149  decode.d3.loss_dice: 0.7073  decode.d4.loss_cls: 0.1667  decode.d4.loss_mask: 0.9416  decode.d4.loss_dice: 0.7162  decode.d5.loss_cls: 0.1532  decode.d5.loss_mask: 0.9535  decode.d5.loss_dice: 0.7177  decode.d6.loss_cls: 0.1710  decode.d6.loss_mask: 0.9206  decode.d6.loss_dice: 0.6938  decode.d7.loss_cls: 0.1724  decode.d7.loss_mask: 0.9166  decode.d7.loss_dice: 0.7095  decode.d8.loss_cls: 0.1529  decode.d8.loss_mask: 0.9392  decode.d8.loss_dice: 0.7224
05/27 04:50:22 - mmengine - INFO - Iter(train) [150500/160000]  base_lr: 7.8749e-06 lr: 7.8749e-07  eta: 1:05:35  time: 0.4185  data_time: 0.0101  memory: 5967  grad_norm: 554.4636  loss: 20.2303  decode.loss_cls: 0.2094  decode.loss_mask: 1.0062  decode.loss_dice: 0.7538  decode.d0.loss_cls: 0.6940  decode.d0.loss_mask: 1.0273  decode.d0.loss_dice: 0.7667  decode.d1.loss_cls: 0.2160  decode.d1.loss_mask: 1.0319  decode.d1.loss_dice: 0.7507  decode.d2.loss_cls: 0.2160  decode.d2.loss_mask: 1.0019  decode.d2.loss_dice: 0.7318  decode.d3.loss_cls: 0.2058  decode.d3.loss_mask: 1.0061  decode.d3.loss_dice: 0.7366  decode.d4.loss_cls: 0.2192  decode.d4.loss_mask: 0.9987  decode.d4.loss_dice: 0.7376  decode.d5.loss_cls: 0.2213  decode.d5.loss_mask: 1.0053  decode.d5.loss_dice: 0.7689  decode.d6.loss_cls: 0.2178  decode.d6.loss_mask: 1.0044  decode.d6.loss_dice: 0.7447  decode.d7.loss_cls: 0.2300  decode.d7.loss_mask: 0.9993  decode.d7.loss_dice: 0.7561  decode.d8.loss_cls: 0.2166  decode.d8.loss_mask: 1.0109  decode.d8.loss_dice: 0.7452
05/27 04:50:43 - mmengine - INFO - Iter(train) [150550/160000]  base_lr: 7.8376e-06 lr: 7.8376e-07  eta: 1:05:14  time: 0.4182  data_time: 0.0101  memory: 5980  grad_norm: 540.8027  loss: 18.6643  decode.loss_cls: 0.1199  decode.loss_mask: 1.0149  decode.loss_dice: 0.7187  decode.d0.loss_cls: 0.6373  decode.d0.loss_mask: 0.9464  decode.d0.loss_dice: 0.7337  decode.d1.loss_cls: 0.1173  decode.d1.loss_mask: 0.9557  decode.d1.loss_dice: 0.6920  decode.d2.loss_cls: 0.1266  decode.d2.loss_mask: 0.9718  decode.d2.loss_dice: 0.7142  decode.d3.loss_cls: 0.1214  decode.d3.loss_mask: 0.9665  decode.d3.loss_dice: 0.6975  decode.d4.loss_cls: 0.1157  decode.d4.loss_mask: 1.0042  decode.d4.loss_dice: 0.7083  decode.d5.loss_cls: 0.1170  decode.d5.loss_mask: 0.9754  decode.d5.loss_dice: 0.7039  decode.d6.loss_cls: 0.1283  decode.d6.loss_mask: 0.9746  decode.d6.loss_dice: 0.7075  decode.d7.loss_cls: 0.1234  decode.d7.loss_mask: 0.9969  decode.d7.loss_dice: 0.7216  decode.d8.loss_cls: 0.1204  decode.d8.loss_mask: 1.0155  decode.d8.loss_dice: 0.7179
05/27 04:51:04 - mmengine - INFO - Iter(train) [150600/160000]  base_lr: 7.8003e-06 lr: 7.8003e-07  eta: 1:04:53  time: 0.4183  data_time: 0.0100  memory: 5971  grad_norm: 429.1734  loss: 18.6794  decode.loss_cls: 0.2072  decode.loss_mask: 0.9298  decode.loss_dice: 0.6707  decode.d0.loss_cls: 0.6797  decode.d0.loss_mask: 0.8945  decode.d0.loss_dice: 0.6875  decode.d1.loss_cls: 0.2272  decode.d1.loss_mask: 0.9310  decode.d1.loss_dice: 0.6814  decode.d2.loss_cls: 0.1978  decode.d2.loss_mask: 0.9366  decode.d2.loss_dice: 0.6896  decode.d3.loss_cls: 0.2326  decode.d3.loss_mask: 0.9387  decode.d3.loss_dice: 0.6909  decode.d4.loss_cls: 0.2117  decode.d4.loss_mask: 0.9258  decode.d4.loss_dice: 0.6871  decode.d5.loss_cls: 0.2108  decode.d5.loss_mask: 0.9321  decode.d5.loss_dice: 0.6800  decode.d6.loss_cls: 0.2096  decode.d6.loss_mask: 0.9188  decode.d6.loss_dice: 0.6740  decode.d7.loss_cls: 0.2206  decode.d7.loss_mask: 0.9309  decode.d7.loss_dice: 0.6839  decode.d8.loss_cls: 0.1909  decode.d8.loss_mask: 0.9276  decode.d8.loss_dice: 0.6805
05/27 04:51:25 - mmengine - INFO - Iter(train) [150650/160000]  base_lr: 7.7629e-06 lr: 7.7629e-07  eta: 1:04:32  time: 0.4180  data_time: 0.0101  memory: 5980  grad_norm: 472.2676  loss: 18.2440  decode.loss_cls: 0.2203  decode.loss_mask: 0.8217  decode.loss_dice: 0.6779  decode.d0.loss_cls: 0.7981  decode.d0.loss_mask: 0.8841  decode.d0.loss_dice: 0.7034  decode.d1.loss_cls: 0.2166  decode.d1.loss_mask: 0.8385  decode.d1.loss_dice: 0.6932  decode.d2.loss_cls: 0.2048  decode.d2.loss_mask: 0.8641  decode.d2.loss_dice: 0.7187  decode.d3.loss_cls: 0.2448  decode.d3.loss_mask: 0.8545  decode.d3.loss_dice: 0.6851  decode.d4.loss_cls: 0.2064  decode.d4.loss_mask: 0.8594  decode.d4.loss_dice: 0.6982  decode.d5.loss_cls: 0.1963  decode.d5.loss_mask: 0.8835  decode.d5.loss_dice: 0.7198  decode.d6.loss_cls: 0.2211  decode.d6.loss_mask: 0.8419  decode.d6.loss_dice: 0.6954  decode.d7.loss_cls: 0.2093  decode.d7.loss_mask: 0.8534  decode.d7.loss_dice: 0.6969  decode.d8.loss_cls: 0.2133  decode.d8.loss_mask: 0.8353  decode.d8.loss_dice: 0.6880
05/27 04:51:46 - mmengine - INFO - Iter(train) [150700/160000]  base_lr: 7.7255e-06 lr: 7.7255e-07  eta: 1:04:12  time: 0.4187  data_time: 0.0100  memory: 5971  grad_norm: 1516.9364  loss: 19.7312  decode.loss_cls: 0.1699  decode.loss_mask: 1.0739  decode.loss_dice: 0.7109  decode.d0.loss_cls: 0.6194  decode.d0.loss_mask: 0.9345  decode.d0.loss_dice: 0.6991  decode.d1.loss_cls: 0.1759  decode.d1.loss_mask: 1.0786  decode.d1.loss_dice: 0.7120  decode.d2.loss_cls: 0.1743  decode.d2.loss_mask: 1.0501  decode.d2.loss_dice: 0.6982  decode.d3.loss_cls: 0.1792  decode.d3.loss_mask: 1.0728  decode.d3.loss_dice: 0.6995  decode.d4.loss_cls: 0.1761  decode.d4.loss_mask: 1.0751  decode.d4.loss_dice: 0.7068  decode.d5.loss_cls: 0.1709  decode.d5.loss_mask: 1.0593  decode.d5.loss_dice: 0.7159  decode.d6.loss_cls: 0.1737  decode.d6.loss_mask: 1.0734  decode.d6.loss_dice: 0.7159  decode.d7.loss_cls: 0.1548  decode.d7.loss_mask: 1.0802  decode.d7.loss_dice: 0.6918  decode.d8.loss_cls: 0.1341  decode.d8.loss_mask: 1.0491  decode.d8.loss_dice: 0.7058
05/27 04:52:07 - mmengine - INFO - Iter(train) [150750/160000]  base_lr: 7.6882e-06 lr: 7.6882e-07  eta: 1:03:51  time: 0.4185  data_time: 0.0100  memory: 5976  grad_norm: 699.9996  loss: 21.9696  decode.loss_cls: 0.1104  decode.loss_mask: 1.2464  decode.loss_dice: 0.8168  decode.d0.loss_cls: 0.6544  decode.d0.loss_mask: 1.1587  decode.d0.loss_dice: 0.7904  decode.d1.loss_cls: 0.1311  decode.d1.loss_mask: 1.1940  decode.d1.loss_dice: 0.8095  decode.d2.loss_cls: 0.1258  decode.d2.loss_mask: 1.1988  decode.d2.loss_dice: 0.7896  decode.d3.loss_cls: 0.1207  decode.d3.loss_mask: 1.2392  decode.d3.loss_dice: 0.8000  decode.d4.loss_cls: 0.1176  decode.d4.loss_mask: 1.2388  decode.d4.loss_dice: 0.8034  decode.d5.loss_cls: 0.1153  decode.d5.loss_mask: 1.2378  decode.d5.loss_dice: 0.8112  decode.d6.loss_cls: 0.1075  decode.d6.loss_mask: 1.2331  decode.d6.loss_dice: 0.8071  decode.d7.loss_cls: 0.1269  decode.d7.loss_mask: 1.2359  decode.d7.loss_dice: 0.8114  decode.d8.loss_cls: 0.1436  decode.d8.loss_mask: 1.1922  decode.d8.loss_dice: 0.8016
05/27 04:52:28 - mmengine - INFO - Iter(train) [150800/160000]  base_lr: 7.6507e-06 lr: 7.6507e-07  eta: 1:03:30  time: 0.4179  data_time: 0.0099  memory: 5981  grad_norm: 379.7849  loss: 15.5171  decode.loss_cls: 0.0923  decode.loss_mask: 0.8500  decode.loss_dice: 0.5728  decode.d0.loss_cls: 0.5725  decode.d0.loss_mask: 0.8438  decode.d0.loss_dice: 0.5601  decode.d1.loss_cls: 0.0885  decode.d1.loss_mask: 0.8442  decode.d1.loss_dice: 0.5522  decode.d2.loss_cls: 0.0519  decode.d2.loss_mask: 0.8767  decode.d2.loss_dice: 0.5831  decode.d3.loss_cls: 0.0589  decode.d3.loss_mask: 0.8667  decode.d3.loss_dice: 0.5723  decode.d4.loss_cls: 0.0826  decode.d4.loss_mask: 0.8577  decode.d4.loss_dice: 0.5677  decode.d5.loss_cls: 0.1056  decode.d5.loss_mask: 0.8535  decode.d5.loss_dice: 0.5516  decode.d6.loss_cls: 0.0960  decode.d6.loss_mask: 0.8446  decode.d6.loss_dice: 0.5622  decode.d7.loss_cls: 0.0898  decode.d7.loss_mask: 0.8559  decode.d7.loss_dice: 0.5643  decode.d8.loss_cls: 0.1044  decode.d8.loss_mask: 0.8381  decode.d8.loss_dice: 0.5571
05/27 04:52:49 - mmengine - INFO - Iter(train) [150850/160000]  base_lr: 7.6133e-06 lr: 7.6133e-07  eta: 1:03:10  time: 0.4188  data_time: 0.0101  memory: 5966  grad_norm: 332.5566  loss: 18.5093  decode.loss_cls: 0.1070  decode.loss_mask: 1.0322  decode.loss_dice: 0.6460  decode.d0.loss_cls: 0.5104  decode.d0.loss_mask: 1.0506  decode.d0.loss_dice: 0.6597  decode.d1.loss_cls: 0.1491  decode.d1.loss_mask: 1.0406  decode.d1.loss_dice: 0.6620  decode.d2.loss_cls: 0.1065  decode.d2.loss_mask: 1.0426  decode.d2.loss_dice: 0.6649  decode.d3.loss_cls: 0.1212  decode.d3.loss_mask: 1.0248  decode.d3.loss_dice: 0.6510  decode.d4.loss_cls: 0.1422  decode.d4.loss_mask: 1.0362  decode.d4.loss_dice: 0.6521  decode.d5.loss_cls: 0.1655  decode.d5.loss_mask: 1.0222  decode.d5.loss_dice: 0.6504  decode.d6.loss_cls: 0.1258  decode.d6.loss_mask: 1.0262  decode.d6.loss_dice: 0.6505  decode.d7.loss_cls: 0.1143  decode.d7.loss_mask: 1.0183  decode.d7.loss_dice: 0.6380  decode.d8.loss_cls: 0.1281  decode.d8.loss_mask: 1.0297  decode.d8.loss_dice: 0.6412
05/27 04:53:10 - mmengine - INFO - Iter(train) [150900/160000]  base_lr: 7.5759e-06 lr: 7.5759e-07  eta: 1:02:49  time: 0.4182  data_time: 0.0100  memory: 5973  grad_norm: 494.4653  loss: 15.5475  decode.loss_cls: 0.0693  decode.loss_mask: 0.8412  decode.loss_dice: 0.5851  decode.d0.loss_cls: 0.5422  decode.d0.loss_mask: 0.8370  decode.d0.loss_dice: 0.5693  decode.d1.loss_cls: 0.0939  decode.d1.loss_mask: 0.8288  decode.d1.loss_dice: 0.5813  decode.d2.loss_cls: 0.1014  decode.d2.loss_mask: 0.8387  decode.d2.loss_dice: 0.5777  decode.d3.loss_cls: 0.0888  decode.d3.loss_mask: 0.8403  decode.d3.loss_dice: 0.5743  decode.d4.loss_cls: 0.1120  decode.d4.loss_mask: 0.8334  decode.d4.loss_dice: 0.5800  decode.d5.loss_cls: 0.0778  decode.d5.loss_mask: 0.8330  decode.d5.loss_dice: 0.5918  decode.d6.loss_cls: 0.0769  decode.d6.loss_mask: 0.8422  decode.d6.loss_dice: 0.5915  decode.d7.loss_cls: 0.0940  decode.d7.loss_mask: 0.8424  decode.d7.loss_dice: 0.5972  decode.d8.loss_cls: 0.0813  decode.d8.loss_mask: 0.8372  decode.d8.loss_dice: 0.5874
05/27 04:53:30 - mmengine - INFO - Iter(train) [150950/160000]  base_lr: 7.5384e-06 lr: 7.5384e-07  eta: 1:02:28  time: 0.4176  data_time: 0.0100  memory: 5967  grad_norm: 436.8642  loss: 16.7522  decode.loss_cls: 0.0690  decode.loss_mask: 0.9745  decode.loss_dice: 0.5868  decode.d0.loss_cls: 0.5826  decode.d0.loss_mask: 0.9376  decode.d0.loss_dice: 0.5735  decode.d1.loss_cls: 0.0619  decode.d1.loss_mask: 0.9533  decode.d1.loss_dice: 0.5946  decode.d2.loss_cls: 0.0721  decode.d2.loss_mask: 0.9617  decode.d2.loss_dice: 0.5987  decode.d3.loss_cls: 0.0984  decode.d3.loss_mask: 0.9645  decode.d3.loss_dice: 0.5961  decode.d4.loss_cls: 0.0686  decode.d4.loss_mask: 0.9621  decode.d4.loss_dice: 0.5934  decode.d5.loss_cls: 0.0794  decode.d5.loss_mask: 0.9574  decode.d5.loss_dice: 0.5983  decode.d6.loss_cls: 0.0571  decode.d6.loss_mask: 0.9683  decode.d6.loss_dice: 0.5936  decode.d7.loss_cls: 0.0664  decode.d7.loss_mask: 0.9601  decode.d7.loss_dice: 0.5880  decode.d8.loss_cls: 0.0730  decode.d8.loss_mask: 0.9696  decode.d8.loss_dice: 0.5917
05/27 04:53:51 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 04:53:51 - mmengine - INFO - Iter(train) [151000/160000]  base_lr: 7.5009e-06 lr: 7.5009e-07  eta: 1:02:08  time: 0.4182  data_time: 0.0100  memory: 5987  grad_norm: 648.9181  loss: 18.5618  decode.loss_cls: 0.1604  decode.loss_mask: 0.9200  decode.loss_dice: 0.6849  decode.d0.loss_cls: 0.6494  decode.d0.loss_mask: 0.9690  decode.d0.loss_dice: 0.7035  decode.d1.loss_cls: 0.1418  decode.d1.loss_mask: 0.9437  decode.d1.loss_dice: 0.7221  decode.d2.loss_cls: 0.1518  decode.d2.loss_mask: 0.9425  decode.d2.loss_dice: 0.6999  decode.d3.loss_cls: 0.1484  decode.d3.loss_mask: 0.9558  decode.d3.loss_dice: 0.6991  decode.d4.loss_cls: 0.1779  decode.d4.loss_mask: 0.9655  decode.d4.loss_dice: 0.7112  decode.d5.loss_cls: 0.1483  decode.d5.loss_mask: 0.9454  decode.d5.loss_dice: 0.6975  decode.d6.loss_cls: 0.1645  decode.d6.loss_mask: 0.9570  decode.d6.loss_dice: 0.6946  decode.d7.loss_cls: 0.1598  decode.d7.loss_mask: 0.9393  decode.d7.loss_dice: 0.6968  decode.d8.loss_cls: 0.1723  decode.d8.loss_mask: 0.9400  decode.d8.loss_dice: 0.6993
05/27 04:54:12 - mmengine - INFO - Iter(train) [151050/160000]  base_lr: 7.4634e-06 lr: 7.4634e-07  eta: 1:01:47  time: 0.4186  data_time: 0.0100  memory: 5969  grad_norm: 492.7534  loss: 16.1034  decode.loss_cls: 0.2122  decode.loss_mask: 0.7761  decode.loss_dice: 0.6155  decode.d0.loss_cls: 0.6266  decode.d0.loss_mask: 0.7585  decode.d0.loss_dice: 0.5984  decode.d1.loss_cls: 0.2410  decode.d1.loss_mask: 0.7294  decode.d1.loss_dice: 0.5758  decode.d2.loss_cls: 0.2211  decode.d2.loss_mask: 0.7543  decode.d2.loss_dice: 0.5777  decode.d3.loss_cls: 0.2347  decode.d3.loss_mask: 0.7499  decode.d3.loss_dice: 0.5823  decode.d4.loss_cls: 0.2246  decode.d4.loss_mask: 0.7679  decode.d4.loss_dice: 0.5879  decode.d5.loss_cls: 0.2065  decode.d5.loss_mask: 0.7728  decode.d5.loss_dice: 0.5795  decode.d6.loss_cls: 0.2378  decode.d6.loss_mask: 0.7321  decode.d6.loss_dice: 0.5854  decode.d7.loss_cls: 0.1979  decode.d7.loss_mask: 0.7768  decode.d7.loss_dice: 0.6033  decode.d8.loss_cls: 0.1850  decode.d8.loss_mask: 0.7912  decode.d8.loss_dice: 0.6011
05/27 04:54:33 - mmengine - INFO - Iter(train) [151100/160000]  base_lr: 7.4258e-06 lr: 7.4258e-07  eta: 1:01:26  time: 0.4192  data_time: 0.0101  memory: 5969  grad_norm: 645.5320  loss: 15.0628  decode.loss_cls: 0.0740  decode.loss_mask: 0.8081  decode.loss_dice: 0.5788  decode.d0.loss_cls: 0.5031  decode.d0.loss_mask: 0.8019  decode.d0.loss_dice: 0.5685  decode.d1.loss_cls: 0.1054  decode.d1.loss_mask: 0.8150  decode.d1.loss_dice: 0.5885  decode.d2.loss_cls: 0.0961  decode.d2.loss_mask: 0.8184  decode.d2.loss_dice: 0.5818  decode.d3.loss_cls: 0.0555  decode.d3.loss_mask: 0.8063  decode.d3.loss_dice: 0.5754  decode.d4.loss_cls: 0.0668  decode.d4.loss_mask: 0.8114  decode.d4.loss_dice: 0.5880  decode.d5.loss_cls: 0.0927  decode.d5.loss_mask: 0.8111  decode.d5.loss_dice: 0.5880  decode.d6.loss_cls: 0.0667  decode.d6.loss_mask: 0.8036  decode.d6.loss_dice: 0.5748  decode.d7.loss_cls: 0.0602  decode.d7.loss_mask: 0.8082  decode.d7.loss_dice: 0.5796  decode.d8.loss_cls: 0.0577  decode.d8.loss_mask: 0.8090  decode.d8.loss_dice: 0.5681
05/27 04:54:54 - mmengine - INFO - Iter(train) [151150/160000]  base_lr: 7.3883e-06 lr: 7.3883e-07  eta: 1:01:06  time: 0.4193  data_time: 0.0100  memory: 5969  grad_norm: 325.9736  loss: 19.3707  decode.loss_cls: 0.2476  decode.loss_mask: 0.9402  decode.loss_dice: 0.7123  decode.d0.loss_cls: 0.6760  decode.d0.loss_mask: 0.9303  decode.d0.loss_dice: 0.7503  decode.d1.loss_cls: 0.2452  decode.d1.loss_mask: 0.9567  decode.d1.loss_dice: 0.7531  decode.d2.loss_cls: 0.2223  decode.d2.loss_mask: 0.9312  decode.d2.loss_dice: 0.7124  decode.d3.loss_cls: 0.2205  decode.d3.loss_mask: 0.9496  decode.d3.loss_dice: 0.7062  decode.d4.loss_cls: 0.2202  decode.d4.loss_mask: 0.9354  decode.d4.loss_dice: 0.7330  decode.d5.loss_cls: 0.2161  decode.d5.loss_mask: 0.9542  decode.d5.loss_dice: 0.7388  decode.d6.loss_cls: 0.2017  decode.d6.loss_mask: 0.9193  decode.d6.loss_dice: 0.7273  decode.d7.loss_cls: 0.2284  decode.d7.loss_mask: 0.9432  decode.d7.loss_dice: 0.6981  decode.d8.loss_cls: 0.2521  decode.d8.loss_mask: 0.9458  decode.d8.loss_dice: 0.7031
05/27 04:55:15 - mmengine - INFO - Iter(train) [151200/160000]  base_lr: 7.3507e-06 lr: 7.3507e-07  eta: 1:00:45  time: 0.4193  data_time: 0.0101  memory: 5987  grad_norm: 457.2062  loss: 15.2272  decode.loss_cls: 0.1164  decode.loss_mask: 0.8013  decode.loss_dice: 0.5365  decode.d0.loss_cls: 0.5731  decode.d0.loss_mask: 0.7828  decode.d0.loss_dice: 0.5802  decode.d1.loss_cls: 0.1673  decode.d1.loss_mask: 0.7913  decode.d1.loss_dice: 0.5401  decode.d2.loss_cls: 0.1478  decode.d2.loss_mask: 0.8025  decode.d2.loss_dice: 0.5745  decode.d3.loss_cls: 0.1666  decode.d3.loss_mask: 0.7982  decode.d3.loss_dice: 0.5349  decode.d4.loss_cls: 0.1671  decode.d4.loss_mask: 0.7939  decode.d4.loss_dice: 0.5285  decode.d5.loss_cls: 0.1240  decode.d5.loss_mask: 0.7983  decode.d5.loss_dice: 0.5388  decode.d6.loss_cls: 0.1278  decode.d6.loss_mask: 0.8095  decode.d6.loss_dice: 0.5270  decode.d7.loss_cls: 0.1385  decode.d7.loss_mask: 0.7845  decode.d7.loss_dice: 0.5292  decode.d8.loss_cls: 0.1406  decode.d8.loss_mask: 0.7897  decode.d8.loss_dice: 0.5161
05/27 04:55:36 - mmengine - INFO - Iter(train) [151250/160000]  base_lr: 7.3131e-06 lr: 7.3131e-07  eta: 1:00:24  time: 0.4184  data_time: 0.0100  memory: 5970  grad_norm: 807.0200  loss: 20.6922  decode.loss_cls: 0.1387  decode.loss_mask: 1.1555  decode.loss_dice: 0.7492  decode.d0.loss_cls: 0.6936  decode.d0.loss_mask: 1.1355  decode.d0.loss_dice: 0.7324  decode.d1.loss_cls: 0.1460  decode.d1.loss_mask: 1.1545  decode.d1.loss_dice: 0.7735  decode.d2.loss_cls: 0.1619  decode.d2.loss_mask: 1.1214  decode.d2.loss_dice: 0.7046  decode.d3.loss_cls: 0.1519  decode.d3.loss_mask: 1.1240  decode.d3.loss_dice: 0.7006  decode.d4.loss_cls: 0.1555  decode.d4.loss_mask: 1.1326  decode.d4.loss_dice: 0.7085  decode.d5.loss_cls: 0.1656  decode.d5.loss_mask: 1.1274  decode.d5.loss_dice: 0.6991  decode.d6.loss_cls: 0.1329  decode.d6.loss_mask: 1.1492  decode.d6.loss_dice: 0.7169  decode.d7.loss_cls: 0.1455  decode.d7.loss_mask: 1.1466  decode.d7.loss_dice: 0.7362  decode.d8.loss_cls: 0.1277  decode.d8.loss_mask: 1.1571  decode.d8.loss_dice: 0.7481
05/27 04:55:57 - mmengine - INFO - Iter(train) [151300/160000]  base_lr: 7.2755e-06 lr: 7.2755e-07  eta: 1:00:03  time: 0.4189  data_time: 0.0100  memory: 5966  grad_norm: 445.3633  loss: 18.1433  decode.loss_cls: 0.2077  decode.loss_mask: 0.9105  decode.loss_dice: 0.6845  decode.d0.loss_cls: 0.7627  decode.d0.loss_mask: 0.8433  decode.d0.loss_dice: 0.6245  decode.d1.loss_cls: 0.2348  decode.d1.loss_mask: 0.9198  decode.d1.loss_dice: 0.6515  decode.d2.loss_cls: 0.2188  decode.d2.loss_mask: 0.8783  decode.d2.loss_dice: 0.6510  decode.d3.loss_cls: 0.2200  decode.d3.loss_mask: 0.8879  decode.d3.loss_dice: 0.6562  decode.d4.loss_cls: 0.2314  decode.d4.loss_mask: 0.8780  decode.d4.loss_dice: 0.6396  decode.d5.loss_cls: 0.2011  decode.d5.loss_mask: 0.9090  decode.d5.loss_dice: 0.6631  decode.d6.loss_cls: 0.2189  decode.d6.loss_mask: 0.8753  decode.d6.loss_dice: 0.6602  decode.d7.loss_cls: 0.2396  decode.d7.loss_mask: 0.8630  decode.d7.loss_dice: 0.6352  decode.d8.loss_cls: 0.2043  decode.d8.loss_mask: 0.9123  decode.d8.loss_dice: 0.6607
05/27 04:56:18 - mmengine - INFO - Iter(train) [151350/160000]  base_lr: 7.2378e-06 lr: 7.2378e-07  eta: 0:59:43  time: 0.4188  data_time: 0.0100  memory: 5976  grad_norm: 310.2161  loss: 18.6033  decode.loss_cls: 0.1507  decode.loss_mask: 0.9698  decode.loss_dice: 0.6652  decode.d0.loss_cls: 0.6909  decode.d0.loss_mask: 0.9732  decode.d0.loss_dice: 0.6777  decode.d1.loss_cls: 0.2071  decode.d1.loss_mask: 0.9554  decode.d1.loss_dice: 0.6538  decode.d2.loss_cls: 0.2001  decode.d2.loss_mask: 0.9611  decode.d2.loss_dice: 0.6518  decode.d3.loss_cls: 0.1490  decode.d3.loss_mask: 0.9765  decode.d3.loss_dice: 0.6616  decode.d4.loss_cls: 0.1806  decode.d4.loss_mask: 0.9660  decode.d4.loss_dice: 0.6508  decode.d5.loss_cls: 0.1613  decode.d5.loss_mask: 0.9687  decode.d5.loss_dice: 0.6571  decode.d6.loss_cls: 0.2042  decode.d6.loss_mask: 1.0140  decode.d6.loss_dice: 0.6644  decode.d7.loss_cls: 0.1889  decode.d7.loss_mask: 0.9662  decode.d7.loss_dice: 0.6509  decode.d8.loss_cls: 0.1714  decode.d8.loss_mask: 0.9602  decode.d8.loss_dice: 0.6544
05/27 04:56:39 - mmengine - INFO - Iter(train) [151400/160000]  base_lr: 7.2002e-06 lr: 7.2002e-07  eta: 0:59:22  time: 0.4202  data_time: 0.0112  memory: 5971  grad_norm: 911.4810  loss: 13.6615  decode.loss_cls: 0.0622  decode.loss_mask: 0.7674  decode.loss_dice: 0.4808  decode.d0.loss_cls: 0.5294  decode.d0.loss_mask: 0.7399  decode.d0.loss_dice: 0.4811  decode.d1.loss_cls: 0.0771  decode.d1.loss_mask: 0.7536  decode.d1.loss_dice: 0.4775  decode.d2.loss_cls: 0.0746  decode.d2.loss_mask: 0.7536  decode.d2.loss_dice: 0.4907  decode.d3.loss_cls: 0.0764  decode.d3.loss_mask: 0.7635  decode.d3.loss_dice: 0.5013  decode.d4.loss_cls: 0.0719  decode.d4.loss_mask: 0.7669  decode.d4.loss_dice: 0.4938  decode.d5.loss_cls: 0.0665  decode.d5.loss_mask: 0.7692  decode.d5.loss_dice: 0.4956  decode.d6.loss_cls: 0.0667  decode.d6.loss_mask: 0.7646  decode.d6.loss_dice: 0.4893  decode.d7.loss_cls: 0.0601  decode.d7.loss_mask: 0.7678  decode.d7.loss_dice: 0.4862  decode.d8.loss_cls: 0.0764  decode.d8.loss_mask: 0.7712  decode.d8.loss_dice: 0.4862
05/27 04:57:00 - mmengine - INFO - Iter(train) [151450/160000]  base_lr: 7.1625e-06 lr: 7.1625e-07  eta: 0:59:01  time: 0.4184  data_time: 0.0100  memory: 5969  grad_norm: 798.3601  loss: 17.7628  decode.loss_cls: 0.0775  decode.loss_mask: 0.9763  decode.loss_dice: 0.7063  decode.d0.loss_cls: 0.5623  decode.d0.loss_mask: 0.8906  decode.d0.loss_dice: 0.6445  decode.d1.loss_cls: 0.0712  decode.d1.loss_mask: 0.9552  decode.d1.loss_dice: 0.6989  decode.d2.loss_cls: 0.0830  decode.d2.loss_mask: 0.9738  decode.d2.loss_dice: 0.7078  decode.d3.loss_cls: 0.0623  decode.d3.loss_mask: 0.9669  decode.d3.loss_dice: 0.6953  decode.d4.loss_cls: 0.0776  decode.d4.loss_mask: 0.9615  decode.d4.loss_dice: 0.7024  decode.d5.loss_cls: 0.0582  decode.d5.loss_mask: 0.9683  decode.d5.loss_dice: 0.6952  decode.d6.loss_cls: 0.0817  decode.d6.loss_mask: 0.9608  decode.d6.loss_dice: 0.7014  decode.d7.loss_cls: 0.0743  decode.d7.loss_mask: 0.9571  decode.d7.loss_dice: 0.7028  decode.d8.loss_cls: 0.0739  decode.d8.loss_mask: 0.9706  decode.d8.loss_dice: 0.7048
05/27 04:57:21 - mmengine - INFO - Iter(train) [151500/160000]  base_lr: 7.1248e-06 lr: 7.1248e-07  eta: 0:58:41  time: 0.4182  data_time: 0.0099  memory: 5967  grad_norm: 435.0737  loss: 21.1165  decode.loss_cls: 0.2186  decode.loss_mask: 1.0526  decode.loss_dice: 0.7507  decode.d0.loss_cls: 0.6507  decode.d0.loss_mask: 1.0649  decode.d0.loss_dice: 0.7889  decode.d1.loss_cls: 0.2652  decode.d1.loss_mask: 1.1175  decode.d1.loss_dice: 0.7960  decode.d2.loss_cls: 0.2129  decode.d2.loss_mask: 1.0511  decode.d2.loss_dice: 0.7835  decode.d3.loss_cls: 0.1999  decode.d3.loss_mask: 1.1054  decode.d3.loss_dice: 0.7631  decode.d4.loss_cls: 0.2710  decode.d4.loss_mask: 1.0413  decode.d4.loss_dice: 0.7645  decode.d5.loss_cls: 0.2170  decode.d5.loss_mask: 1.0683  decode.d5.loss_dice: 0.7813  decode.d6.loss_cls: 0.2283  decode.d6.loss_mask: 1.0497  decode.d6.loss_dice: 0.7544  decode.d7.loss_cls: 0.2647  decode.d7.loss_mask: 1.0432  decode.d7.loss_dice: 0.7511  decode.d8.loss_cls: 0.2205  decode.d8.loss_mask: 1.0919  decode.d8.loss_dice: 0.7485
05/27 04:57:42 - mmengine - INFO - Iter(train) [151550/160000]  base_lr: 7.0870e-06 lr: 7.0870e-07  eta: 0:58:20  time: 0.4182  data_time: 0.0100  memory: 5966  grad_norm: 502.7853  loss: 16.4098  decode.loss_cls: 0.0919  decode.loss_mask: 0.9091  decode.loss_dice: 0.6010  decode.d0.loss_cls: 0.5535  decode.d0.loss_mask: 0.8816  decode.d0.loss_dice: 0.5784  decode.d1.loss_cls: 0.1329  decode.d1.loss_mask: 0.8776  decode.d1.loss_dice: 0.5820  decode.d2.loss_cls: 0.1075  decode.d2.loss_mask: 0.8984  decode.d2.loss_dice: 0.5910  decode.d3.loss_cls: 0.1090  decode.d3.loss_mask: 0.8931  decode.d3.loss_dice: 0.5885  decode.d4.loss_cls: 0.1131  decode.d4.loss_mask: 0.8961  decode.d4.loss_dice: 0.5924  decode.d5.loss_cls: 0.1159  decode.d5.loss_mask: 0.8739  decode.d5.loss_dice: 0.5952  decode.d6.loss_cls: 0.0854  decode.d6.loss_mask: 0.9048  decode.d6.loss_dice: 0.6046  decode.d7.loss_cls: 0.1167  decode.d7.loss_mask: 0.9011  decode.d7.loss_dice: 0.6014  decode.d8.loss_cls: 0.1126  decode.d8.loss_mask: 0.9028  decode.d8.loss_dice: 0.5981
05/27 04:58:03 - mmengine - INFO - Iter(train) [151600/160000]  base_lr: 7.0493e-06 lr: 7.0493e-07  eta: 0:57:59  time: 0.4186  data_time: 0.0100  memory: 5969  grad_norm: 443.3071  loss: 18.9997  decode.loss_cls: 0.1214  decode.loss_mask: 0.9566  decode.loss_dice: 0.7237  decode.d0.loss_cls: 0.5429  decode.d0.loss_mask: 0.9961  decode.d0.loss_dice: 0.7726  decode.d1.loss_cls: 0.1724  decode.d1.loss_mask: 0.9598  decode.d1.loss_dice: 0.7386  decode.d2.loss_cls: 0.1393  decode.d2.loss_mask: 0.9854  decode.d2.loss_dice: 0.7401  decode.d3.loss_cls: 0.1438  decode.d3.loss_mask: 0.9715  decode.d3.loss_dice: 0.7423  decode.d4.loss_cls: 0.1777  decode.d4.loss_mask: 0.9728  decode.d4.loss_dice: 0.7325  decode.d5.loss_cls: 0.1341  decode.d5.loss_mask: 0.9834  decode.d5.loss_dice: 0.7447  decode.d6.loss_cls: 0.1242  decode.d6.loss_mask: 0.9679  decode.d6.loss_dice: 0.7512  decode.d7.loss_cls: 0.1538  decode.d7.loss_mask: 0.9983  decode.d7.loss_dice: 0.7300  decode.d8.loss_cls: 0.1247  decode.d8.loss_mask: 0.9709  decode.d8.loss_dice: 0.7267
05/27 04:58:24 - mmengine - INFO - Iter(train) [151650/160000]  base_lr: 7.0115e-06 lr: 7.0115e-07  eta: 0:57:39  time: 0.4173  data_time: 0.0100  memory: 5966  grad_norm: 431.0455  loss: 19.0967  decode.loss_cls: 0.1512  decode.loss_mask: 1.0376  decode.loss_dice: 0.6129  decode.d0.loss_cls: 0.6672  decode.d0.loss_mask: 1.0489  decode.d0.loss_dice: 0.6712  decode.d1.loss_cls: 0.1699  decode.d1.loss_mask: 1.0537  decode.d1.loss_dice: 0.6448  decode.d2.loss_cls: 0.1603  decode.d2.loss_mask: 1.0770  decode.d2.loss_dice: 0.6606  decode.d3.loss_cls: 0.1616  decode.d3.loss_mask: 1.0564  decode.d3.loss_dice: 0.6547  decode.d4.loss_cls: 0.1593  decode.d4.loss_mask: 1.0473  decode.d4.loss_dice: 0.6518  decode.d5.loss_cls: 0.1558  decode.d5.loss_mask: 1.0628  decode.d5.loss_dice: 0.6579  decode.d6.loss_cls: 0.1379  decode.d6.loss_mask: 1.0479  decode.d6.loss_dice: 0.6544  decode.d7.loss_cls: 0.1654  decode.d7.loss_mask: 1.0435  decode.d7.loss_dice: 0.6384  decode.d8.loss_cls: 0.1446  decode.d8.loss_mask: 1.0599  decode.d8.loss_dice: 0.6419
05/27 04:58:45 - mmengine - INFO - Iter(train) [151700/160000]  base_lr: 6.9737e-06 lr: 6.9737e-07  eta: 0:57:18  time: 0.4198  data_time: 0.0100  memory: 5971  grad_norm: 799.8891  loss: 19.9787  decode.loss_cls: 0.2202  decode.loss_mask: 1.0025  decode.loss_dice: 0.7360  decode.d0.loss_cls: 0.6707  decode.d0.loss_mask: 0.9516  decode.d0.loss_dice: 0.7318  decode.d1.loss_cls: 0.2258  decode.d1.loss_mask: 0.9985  decode.d1.loss_dice: 0.7547  decode.d2.loss_cls: 0.2009  decode.d2.loss_mask: 1.0347  decode.d2.loss_dice: 0.7654  decode.d3.loss_cls: 0.2017  decode.d3.loss_mask: 1.0127  decode.d3.loss_dice: 0.7173  decode.d4.loss_cls: 0.1865  decode.d4.loss_mask: 1.0212  decode.d4.loss_dice: 0.7661  decode.d5.loss_cls: 0.2104  decode.d5.loss_mask: 1.0099  decode.d5.loss_dice: 0.7296  decode.d6.loss_cls: 0.2157  decode.d6.loss_mask: 0.9962  decode.d6.loss_dice: 0.7315  decode.d7.loss_cls: 0.1869  decode.d7.loss_mask: 1.0027  decode.d7.loss_dice: 0.7347  decode.d8.loss_cls: 0.2421  decode.d8.loss_mask: 0.9875  decode.d8.loss_dice: 0.7331
05/27 04:59:06 - mmengine - INFO - Iter(train) [151750/160000]  base_lr: 6.9359e-06 lr: 6.9359e-07  eta: 0:56:57  time: 0.4180  data_time: 0.0100  memory: 5976  grad_norm: 1023.2038  loss: 20.8279  decode.loss_cls: 0.1372  decode.loss_mask: 1.1445  decode.loss_dice: 0.7336  decode.d0.loss_cls: 0.6353  decode.d0.loss_mask: 1.1628  decode.d0.loss_dice: 0.7289  decode.d1.loss_cls: 0.1654  decode.d1.loss_mask: 1.1529  decode.d1.loss_dice: 0.7405  decode.d2.loss_cls: 0.1466  decode.d2.loss_mask: 1.1559  decode.d2.loss_dice: 0.7344  decode.d3.loss_cls: 0.1466  decode.d3.loss_mask: 1.1706  decode.d3.loss_dice: 0.7602  decode.d4.loss_cls: 0.1345  decode.d4.loss_mask: 1.1335  decode.d4.loss_dice: 0.7306  decode.d5.loss_cls: 0.1379  decode.d5.loss_mask: 1.1677  decode.d5.loss_dice: 0.7309  decode.d6.loss_cls: 0.1490  decode.d6.loss_mask: 1.1546  decode.d6.loss_dice: 0.7345  decode.d7.loss_cls: 0.1297  decode.d7.loss_mask: 1.1603  decode.d7.loss_dice: 0.7373  decode.d8.loss_cls: 0.1255  decode.d8.loss_mask: 1.1620  decode.d8.loss_dice: 0.7245
05/27 04:59:27 - mmengine - INFO - Iter(train) [151800/160000]  base_lr: 6.8981e-06 lr: 6.8981e-07  eta: 0:56:36  time: 0.4184  data_time: 0.0100  memory: 5966  grad_norm: 349.6313  loss: 18.4554  decode.loss_cls: 0.2093  decode.loss_mask: 0.8928  decode.loss_dice: 0.6935  decode.d0.loss_cls: 0.7295  decode.d0.loss_mask: 0.8830  decode.d0.loss_dice: 0.7342  decode.d1.loss_cls: 0.2204  decode.d1.loss_mask: 0.8668  decode.d1.loss_dice: 0.7006  decode.d2.loss_cls: 0.2581  decode.d2.loss_mask: 0.8356  decode.d2.loss_dice: 0.6989  decode.d3.loss_cls: 0.2590  decode.d3.loss_mask: 0.8369  decode.d3.loss_dice: 0.6818  decode.d4.loss_cls: 0.2387  decode.d4.loss_mask: 0.8562  decode.d4.loss_dice: 0.7046  decode.d5.loss_cls: 0.2362  decode.d5.loss_mask: 0.8529  decode.d5.loss_dice: 0.7104  decode.d6.loss_cls: 0.2313  decode.d6.loss_mask: 0.8619  decode.d6.loss_dice: 0.6836  decode.d7.loss_cls: 0.2223  decode.d7.loss_mask: 0.8734  decode.d7.loss_dice: 0.7180  decode.d8.loss_cls: 0.2123  decode.d8.loss_mask: 0.8562  decode.d8.loss_dice: 0.6967
05/27 04:59:48 - mmengine - INFO - Iter(train) [151850/160000]  base_lr: 6.8602e-06 lr: 6.8602e-07  eta: 0:56:16  time: 0.4195  data_time: 0.0100  memory: 5968  grad_norm: 762.1935  loss: 17.5642  decode.loss_cls: 0.1198  decode.loss_mask: 0.9653  decode.loss_dice: 0.6018  decode.d0.loss_cls: 0.5544  decode.d0.loss_mask: 1.0892  decode.d0.loss_dice: 0.6276  decode.d1.loss_cls: 0.1465  decode.d1.loss_mask: 0.9931  decode.d1.loss_dice: 0.5992  decode.d2.loss_cls: 0.1389  decode.d2.loss_mask: 0.9938  decode.d2.loss_dice: 0.6016  decode.d3.loss_cls: 0.1259  decode.d3.loss_mask: 1.0150  decode.d3.loss_dice: 0.6076  decode.d4.loss_cls: 0.1057  decode.d4.loss_mask: 0.9843  decode.d4.loss_dice: 0.5923  decode.d5.loss_cls: 0.1272  decode.d5.loss_mask: 0.9563  decode.d5.loss_dice: 0.5833  decode.d6.loss_cls: 0.1391  decode.d6.loss_mask: 0.9659  decode.d6.loss_dice: 0.5940  decode.d7.loss_cls: 0.0802  decode.d7.loss_mask: 0.9905  decode.d7.loss_dice: 0.5958  decode.d8.loss_cls: 0.1099  decode.d8.loss_mask: 0.9618  decode.d8.loss_dice: 0.5982
05/27 05:00:09 - mmengine - INFO - Iter(train) [151900/160000]  base_lr: 6.8223e-06 lr: 6.8223e-07  eta: 0:55:55  time: 0.4183  data_time: 0.0101  memory: 5970  grad_norm: 356.7060  loss: 17.1903  decode.loss_cls: 0.2057  decode.loss_mask: 0.8775  decode.loss_dice: 0.6059  decode.d0.loss_cls: 0.5988  decode.d0.loss_mask: 0.8708  decode.d0.loss_dice: 0.6314  decode.d1.loss_cls: 0.1686  decode.d1.loss_mask: 0.8720  decode.d1.loss_dice: 0.6154  decode.d2.loss_cls: 0.2070  decode.d2.loss_mask: 0.8695  decode.d2.loss_dice: 0.6121  decode.d3.loss_cls: 0.1991  decode.d3.loss_mask: 0.8681  decode.d3.loss_dice: 0.6059  decode.d4.loss_cls: 0.1985  decode.d4.loss_mask: 0.8843  decode.d4.loss_dice: 0.5931  decode.d5.loss_cls: 0.2117  decode.d5.loss_mask: 0.8808  decode.d5.loss_dice: 0.6017  decode.d6.loss_cls: 0.1999  decode.d6.loss_mask: 0.8820  decode.d6.loss_dice: 0.5977  decode.d7.loss_cls: 0.1944  decode.d7.loss_mask: 0.8765  decode.d7.loss_dice: 0.6009  decode.d8.loss_cls: 0.2042  decode.d8.loss_mask: 0.8704  decode.d8.loss_dice: 0.5863
05/27 05:00:30 - mmengine - INFO - Iter(train) [151950/160000]  base_lr: 6.7844e-06 lr: 6.7844e-07  eta: 0:55:34  time: 0.4184  data_time: 0.0100  memory: 5972  grad_norm: 356.0143  loss: 15.6275  decode.loss_cls: 0.0946  decode.loss_mask: 0.8413  decode.loss_dice: 0.5874  decode.d0.loss_cls: 0.5400  decode.d0.loss_mask: 0.8062  decode.d0.loss_dice: 0.5628  decode.d1.loss_cls: 0.1008  decode.d1.loss_mask: 0.8310  decode.d1.loss_dice: 0.5924  decode.d2.loss_cls: 0.0948  decode.d2.loss_mask: 0.8311  decode.d2.loss_dice: 0.5815  decode.d3.loss_cls: 0.0889  decode.d3.loss_mask: 0.8283  decode.d3.loss_dice: 0.5799  decode.d4.loss_cls: 0.0979  decode.d4.loss_mask: 0.8193  decode.d4.loss_dice: 0.5790  decode.d5.loss_cls: 0.1063  decode.d5.loss_mask: 0.8431  decode.d5.loss_dice: 0.5919  decode.d6.loss_cls: 0.1177  decode.d6.loss_mask: 0.8425  decode.d6.loss_dice: 0.5858  decode.d7.loss_cls: 0.1054  decode.d7.loss_mask: 0.8485  decode.d7.loss_dice: 0.5778  decode.d8.loss_cls: 0.1025  decode.d8.loss_mask: 0.8441  decode.d8.loss_dice: 0.6045
05/27 05:00:51 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 05:00:51 - mmengine - INFO - Iter(train) [152000/160000]  base_lr: 6.7465e-06 lr: 6.7465e-07  eta: 0:55:14  time: 0.4190  data_time: 0.0100  memory: 5967  grad_norm: 391.7200  loss: 18.6673  decode.loss_cls: 0.1283  decode.loss_mask: 0.9641  decode.loss_dice: 0.6862  decode.d0.loss_cls: 0.5688  decode.d0.loss_mask: 0.9321  decode.d0.loss_dice: 0.7139  decode.d1.loss_cls: 0.1291  decode.d1.loss_mask: 0.9921  decode.d1.loss_dice: 0.7223  decode.d2.loss_cls: 0.1731  decode.d2.loss_mask: 0.9885  decode.d2.loss_dice: 0.7101  decode.d3.loss_cls: 0.1622  decode.d3.loss_mask: 0.9782  decode.d3.loss_dice: 0.7082  decode.d4.loss_cls: 0.1363  decode.d4.loss_mask: 0.9724  decode.d4.loss_dice: 0.6965  decode.d5.loss_cls: 0.1560  decode.d5.loss_mask: 0.9728  decode.d5.loss_dice: 0.7121  decode.d6.loss_cls: 0.1470  decode.d6.loss_mask: 0.9743  decode.d6.loss_dice: 0.7024  decode.d7.loss_cls: 0.1596  decode.d7.loss_mask: 0.9662  decode.d7.loss_dice: 0.6841  decode.d8.loss_cls: 0.1675  decode.d8.loss_mask: 0.9719  decode.d8.loss_dice: 0.6913
05/27 05:01:12 - mmengine - INFO - Iter(train) [152050/160000]  base_lr: 6.7085e-06 lr: 6.7085e-07  eta: 0:54:53  time: 0.4280  data_time: 0.0100  memory: 5976  grad_norm: 502.9378  loss: 17.0395  decode.loss_cls: 0.1398  decode.loss_mask: 0.8612  decode.loss_dice: 0.6732  decode.d0.loss_cls: 0.6639  decode.d0.loss_mask: 0.8272  decode.d0.loss_dice: 0.6616  decode.d1.loss_cls: 0.1533  decode.d1.loss_mask: 0.8500  decode.d1.loss_dice: 0.6565  decode.d2.loss_cls: 0.1267  decode.d2.loss_mask: 0.8744  decode.d2.loss_dice: 0.6463  decode.d3.loss_cls: 0.1410  decode.d3.loss_mask: 0.8716  decode.d3.loss_dice: 0.6576  decode.d4.loss_cls: 0.1644  decode.d4.loss_mask: 0.8219  decode.d4.loss_dice: 0.6599  decode.d5.loss_cls: 0.1454  decode.d5.loss_mask: 0.8226  decode.d5.loss_dice: 0.6659  decode.d6.loss_cls: 0.1526  decode.d6.loss_mask: 0.8341  decode.d6.loss_dice: 0.6639  decode.d7.loss_cls: 0.1632  decode.d7.loss_mask: 0.8335  decode.d7.loss_dice: 0.6593  decode.d8.loss_cls: 0.1449  decode.d8.loss_mask: 0.8506  decode.d8.loss_dice: 0.6532
05/27 05:01:33 - mmengine - INFO - Iter(train) [152100/160000]  base_lr: 6.6705e-06 lr: 6.6705e-07  eta: 0:54:32  time: 0.4180  data_time: 0.0100  memory: 5966  grad_norm: 796.0913  loss: 19.2328  decode.loss_cls: 0.1486  decode.loss_mask: 1.0114  decode.loss_dice: 0.6528  decode.d0.loss_cls: 0.5795  decode.d0.loss_mask: 1.0264  decode.d0.loss_dice: 0.6683  decode.d1.loss_cls: 0.1679  decode.d1.loss_mask: 1.0810  decode.d1.loss_dice: 0.6765  decode.d2.loss_cls: 0.1339  decode.d2.loss_mask: 1.1111  decode.d2.loss_dice: 0.6841  decode.d3.loss_cls: 0.1355  decode.d3.loss_mask: 1.0461  decode.d3.loss_dice: 0.6774  decode.d4.loss_cls: 0.1628  decode.d4.loss_mask: 1.0145  decode.d4.loss_dice: 0.6698  decode.d5.loss_cls: 0.1530  decode.d5.loss_mask: 1.0673  decode.d5.loss_dice: 0.6745  decode.d6.loss_cls: 0.1495  decode.d6.loss_mask: 1.1014  decode.d6.loss_dice: 0.6767  decode.d7.loss_cls: 0.1688  decode.d7.loss_mask: 1.0358  decode.d7.loss_dice: 0.6727  decode.d8.loss_cls: 0.1486  decode.d8.loss_mask: 1.0603  decode.d8.loss_dice: 0.6764
05/27 05:01:54 - mmengine - INFO - Iter(train) [152150/160000]  base_lr: 6.6325e-06 lr: 6.6325e-07  eta: 0:54:12  time: 0.4186  data_time: 0.0101  memory: 5980  grad_norm: 1009.2607  loss: 17.8907  decode.loss_cls: 0.2263  decode.loss_mask: 0.8768  decode.loss_dice: 0.6190  decode.d0.loss_cls: 0.6012  decode.d0.loss_mask: 0.9260  decode.d0.loss_dice: 0.6342  decode.d1.loss_cls: 0.1785  decode.d1.loss_mask: 0.9443  decode.d1.loss_dice: 0.6405  decode.d2.loss_cls: 0.1663  decode.d2.loss_mask: 0.9559  decode.d2.loss_dice: 0.6512  decode.d3.loss_cls: 0.2400  decode.d3.loss_mask: 0.8803  decode.d3.loss_dice: 0.6370  decode.d4.loss_cls: 0.2175  decode.d4.loss_mask: 0.9087  decode.d4.loss_dice: 0.6178  decode.d5.loss_cls: 0.1801  decode.d5.loss_mask: 0.9177  decode.d5.loss_dice: 0.6354  decode.d6.loss_cls: 0.1673  decode.d6.loss_mask: 0.9214  decode.d6.loss_dice: 0.6373  decode.d7.loss_cls: 0.1747  decode.d7.loss_mask: 0.9427  decode.d7.loss_dice: 0.6602  decode.d8.loss_cls: 0.1901  decode.d8.loss_mask: 0.9126  decode.d8.loss_dice: 0.6298
05/27 05:02:15 - mmengine - INFO - Iter(train) [152200/160000]  base_lr: 6.5945e-06 lr: 6.5945e-07  eta: 0:53:51  time: 0.4191  data_time: 0.0101  memory: 5971  grad_norm: 634.6708  loss: 21.1331  decode.loss_cls: 0.2263  decode.loss_mask: 1.1881  decode.loss_dice: 0.6742  decode.d0.loss_cls: 0.7598  decode.d0.loss_mask: 1.0856  decode.d0.loss_dice: 0.6557  decode.d1.loss_cls: 0.2441  decode.d1.loss_mask: 1.1368  decode.d1.loss_dice: 0.6697  decode.d2.loss_cls: 0.2394  decode.d2.loss_mask: 1.1863  decode.d2.loss_dice: 0.6604  decode.d3.loss_cls: 0.2352  decode.d3.loss_mask: 1.1732  decode.d3.loss_dice: 0.6630  decode.d4.loss_cls: 0.2729  decode.d4.loss_mask: 1.1288  decode.d4.loss_dice: 0.6540  decode.d5.loss_cls: 0.2599  decode.d5.loss_mask: 1.1248  decode.d5.loss_dice: 0.6480  decode.d6.loss_cls: 0.2317  decode.d6.loss_mask: 1.2122  decode.d6.loss_dice: 0.6712  decode.d7.loss_cls: 0.2457  decode.d7.loss_mask: 1.1371  decode.d7.loss_dice: 0.6559  decode.d8.loss_cls: 0.2559  decode.d8.loss_mask: 1.1638  decode.d8.loss_dice: 0.6733
05/27 05:02:36 - mmengine - INFO - Iter(train) [152250/160000]  base_lr: 6.5564e-06 lr: 6.5564e-07  eta: 0:53:30  time: 0.4186  data_time: 0.0101  memory: 5970  grad_norm: 474.7756  loss: 19.9740  decode.loss_cls: 0.0775  decode.loss_mask: 1.1157  decode.loss_dice: 0.7274  decode.d0.loss_cls: 0.6879  decode.d0.loss_mask: 1.0399  decode.d0.loss_dice: 0.7121  decode.d1.loss_cls: 0.0908  decode.d1.loss_mask: 1.1161  decode.d1.loss_dice: 0.7406  decode.d2.loss_cls: 0.1038  decode.d2.loss_mask: 1.1257  decode.d2.loss_dice: 0.7368  decode.d3.loss_cls: 0.0861  decode.d3.loss_mask: 1.1448  decode.d3.loss_dice: 0.7328  decode.d4.loss_cls: 0.1057  decode.d4.loss_mask: 1.1264  decode.d4.loss_dice: 0.7342  decode.d5.loss_cls: 0.1109  decode.d5.loss_mask: 1.1188  decode.d5.loss_dice: 0.7138  decode.d6.loss_cls: 0.0845  decode.d6.loss_mask: 1.1333  decode.d6.loss_dice: 0.7280  decode.d7.loss_cls: 0.1139  decode.d7.loss_mask: 1.0776  decode.d7.loss_dice: 0.7246  decode.d8.loss_cls: 0.0805  decode.d8.loss_mask: 1.1390  decode.d8.loss_dice: 0.7449
05/27 05:02:57 - mmengine - INFO - Iter(train) [152300/160000]  base_lr: 6.5183e-06 lr: 6.5183e-07  eta: 0:53:09  time: 0.4182  data_time: 0.0099  memory: 5969  grad_norm: 805.4608  loss: 19.9794  decode.loss_cls: 0.1774  decode.loss_mask: 1.0477  decode.loss_dice: 0.7468  decode.d0.loss_cls: 0.7274  decode.d0.loss_mask: 0.9488  decode.d0.loss_dice: 0.6925  decode.d1.loss_cls: 0.2163  decode.d1.loss_mask: 0.9947  decode.d1.loss_dice: 0.7367  decode.d2.loss_cls: 0.2554  decode.d2.loss_mask: 0.9500  decode.d2.loss_dice: 0.7114  decode.d3.loss_cls: 0.2327  decode.d3.loss_mask: 0.9902  decode.d3.loss_dice: 0.7371  decode.d4.loss_cls: 0.2584  decode.d4.loss_mask: 0.9956  decode.d4.loss_dice: 0.7190  decode.d5.loss_cls: 0.2322  decode.d5.loss_mask: 1.0190  decode.d5.loss_dice: 0.7073  decode.d6.loss_cls: 0.2206  decode.d6.loss_mask: 1.0068  decode.d6.loss_dice: 0.7434  decode.d7.loss_cls: 0.1960  decode.d7.loss_mask: 1.0090  decode.d7.loss_dice: 0.7395  decode.d8.loss_cls: 0.2138  decode.d8.loss_mask: 1.0111  decode.d8.loss_dice: 0.7426
05/27 05:03:18 - mmengine - INFO - Iter(train) [152350/160000]  base_lr: 6.4802e-06 lr: 6.4802e-07  eta: 0:52:49  time: 0.4184  data_time: 0.0101  memory: 5980  grad_norm: 406.8414  loss: 21.4374  decode.loss_cls: 0.1807  decode.loss_mask: 1.1254  decode.loss_dice: 0.7359  decode.d0.loss_cls: 0.7882  decode.d0.loss_mask: 1.0383  decode.d0.loss_dice: 0.7016  decode.d1.loss_cls: 0.2668  decode.d1.loss_mask: 1.1217  decode.d1.loss_dice: 0.7522  decode.d2.loss_cls: 0.2467  decode.d2.loss_mask: 1.1068  decode.d2.loss_dice: 0.7306  decode.d3.loss_cls: 0.2162  decode.d3.loss_mask: 1.1393  decode.d3.loss_dice: 0.7379  decode.d4.loss_cls: 0.2676  decode.d4.loss_mask: 1.0967  decode.d4.loss_dice: 0.7446  decode.d5.loss_cls: 0.2488  decode.d5.loss_mask: 1.1068  decode.d5.loss_dice: 0.7306  decode.d6.loss_cls: 0.2871  decode.d6.loss_mask: 1.1252  decode.d6.loss_dice: 0.7586  decode.d7.loss_cls: 0.2321  decode.d7.loss_mask: 1.1175  decode.d7.loss_dice: 0.7460  decode.d8.loss_cls: 0.2279  decode.d8.loss_mask: 1.1163  decode.d8.loss_dice: 0.7432
05/27 05:03:39 - mmengine - INFO - Iter(train) [152400/160000]  base_lr: 6.4421e-06 lr: 6.4421e-07  eta: 0:52:28  time: 0.4184  data_time: 0.0099  memory: 5966  grad_norm: 417.3319  loss: 15.9565  decode.loss_cls: 0.1769  decode.loss_mask: 0.8126  decode.loss_dice: 0.5456  decode.d0.loss_cls: 0.6761  decode.d0.loss_mask: 0.7514  decode.d0.loss_dice: 0.5407  decode.d1.loss_cls: 0.1740  decode.d1.loss_mask: 0.8249  decode.d1.loss_dice: 0.5574  decode.d2.loss_cls: 0.1879  decode.d2.loss_mask: 0.8199  decode.d2.loss_dice: 0.5498  decode.d3.loss_cls: 0.1865  decode.d3.loss_mask: 0.8110  decode.d3.loss_dice: 0.5478  decode.d4.loss_cls: 0.1760  decode.d4.loss_mask: 0.8104  decode.d4.loss_dice: 0.5559  decode.d5.loss_cls: 0.1811  decode.d5.loss_mask: 0.8292  decode.d5.loss_dice: 0.5695  decode.d6.loss_cls: 0.1826  decode.d6.loss_mask: 0.8234  decode.d6.loss_dice: 0.5486  decode.d7.loss_cls: 0.2022  decode.d7.loss_mask: 0.8112  decode.d7.loss_dice: 0.5596  decode.d8.loss_cls: 0.1806  decode.d8.loss_mask: 0.8148  decode.d8.loss_dice: 0.5492
05/27 05:04:00 - mmengine - INFO - Iter(train) [152450/160000]  base_lr: 6.4039e-06 lr: 6.4039e-07  eta: 0:52:07  time: 0.4192  data_time: 0.0099  memory: 5972  grad_norm: 510.7317  loss: 17.8647  decode.loss_cls: 0.1225  decode.loss_mask: 0.9666  decode.loss_dice: 0.6426  decode.d0.loss_cls: 0.5855  decode.d0.loss_mask: 0.9830  decode.d0.loss_dice: 0.6671  decode.d1.loss_cls: 0.0942  decode.d1.loss_mask: 0.9737  decode.d1.loss_dice: 0.6574  decode.d2.loss_cls: 0.1217  decode.d2.loss_mask: 0.9682  decode.d2.loss_dice: 0.6609  decode.d3.loss_cls: 0.1501  decode.d3.loss_mask: 0.9746  decode.d3.loss_dice: 0.6310  decode.d4.loss_cls: 0.1316  decode.d4.loss_mask: 0.9608  decode.d4.loss_dice: 0.6432  decode.d5.loss_cls: 0.1103  decode.d5.loss_mask: 0.9697  decode.d5.loss_dice: 0.6457  decode.d6.loss_cls: 0.1373  decode.d6.loss_mask: 0.9651  decode.d6.loss_dice: 0.6416  decode.d7.loss_cls: 0.1033  decode.d7.loss_mask: 0.9636  decode.d7.loss_dice: 0.6541  decode.d8.loss_cls: 0.1178  decode.d8.loss_mask: 0.9725  decode.d8.loss_dice: 0.6489
05/27 05:04:21 - mmengine - INFO - Iter(train) [152500/160000]  base_lr: 6.3658e-06 lr: 6.3658e-07  eta: 0:51:47  time: 0.4192  data_time: 0.0099  memory: 5970  grad_norm: 389.2258  loss: 14.7232  decode.loss_cls: 0.0645  decode.loss_mask: 0.8276  decode.loss_dice: 0.5277  decode.d0.loss_cls: 0.4997  decode.d0.loss_mask: 0.8111  decode.d0.loss_dice: 0.5485  decode.d1.loss_cls: 0.0540  decode.d1.loss_mask: 0.8323  decode.d1.loss_dice: 0.5441  decode.d2.loss_cls: 0.0577  decode.d2.loss_mask: 0.8193  decode.d2.loss_dice: 0.5229  decode.d3.loss_cls: 0.0486  decode.d3.loss_mask: 0.8233  decode.d3.loss_dice: 0.5308  decode.d4.loss_cls: 0.0479  decode.d4.loss_mask: 0.8268  decode.d4.loss_dice: 0.5464  decode.d5.loss_cls: 0.0693  decode.d5.loss_mask: 0.8348  decode.d5.loss_dice: 0.5476  decode.d6.loss_cls: 0.0621  decode.d6.loss_mask: 0.8292  decode.d6.loss_dice: 0.5552  decode.d7.loss_cls: 0.0546  decode.d7.loss_mask: 0.8350  decode.d7.loss_dice: 0.5595  decode.d8.loss_cls: 0.0687  decode.d8.loss_mask: 0.8373  decode.d8.loss_dice: 0.5367
05/27 05:04:42 - mmengine - INFO - Iter(train) [152550/160000]  base_lr: 6.3275e-06 lr: 6.3275e-07  eta: 0:51:26  time: 0.4189  data_time: 0.0099  memory: 5970  grad_norm: 445.5161  loss: 16.4928  decode.loss_cls: 0.1501  decode.loss_mask: 0.8573  decode.loss_dice: 0.5843  decode.d0.loss_cls: 0.6582  decode.d0.loss_mask: 0.7972  decode.d0.loss_dice: 0.5759  decode.d1.loss_cls: 0.1315  decode.d1.loss_mask: 0.8555  decode.d1.loss_dice: 0.6072  decode.d2.loss_cls: 0.1159  decode.d2.loss_mask: 0.8736  decode.d2.loss_dice: 0.6286  decode.d3.loss_cls: 0.1321  decode.d3.loss_mask: 0.8533  decode.d3.loss_dice: 0.5967  decode.d4.loss_cls: 0.1383  decode.d4.loss_mask: 0.8545  decode.d4.loss_dice: 0.5965  decode.d5.loss_cls: 0.1362  decode.d5.loss_mask: 0.8958  decode.d5.loss_dice: 0.6123  decode.d6.loss_cls: 0.1362  decode.d6.loss_mask: 0.8833  decode.d6.loss_dice: 0.6113  decode.d7.loss_cls: 0.1353  decode.d7.loss_mask: 0.8755  decode.d7.loss_dice: 0.6038  decode.d8.loss_cls: 0.1301  decode.d8.loss_mask: 0.8629  decode.d8.loss_dice: 0.6034
05/27 05:05:02 - mmengine - INFO - Iter(train) [152600/160000]  base_lr: 6.2893e-06 lr: 6.2893e-07  eta: 0:51:05  time: 0.4189  data_time: 0.0099  memory: 5968  grad_norm: 691.3464  loss: 18.0326  decode.loss_cls: 0.2037  decode.loss_mask: 0.9058  decode.loss_dice: 0.6346  decode.d0.loss_cls: 0.6464  decode.d0.loss_mask: 0.9126  decode.d0.loss_dice: 0.6367  decode.d1.loss_cls: 0.2133  decode.d1.loss_mask: 0.9216  decode.d1.loss_dice: 0.6560  decode.d2.loss_cls: 0.1962  decode.d2.loss_mask: 0.9227  decode.d2.loss_dice: 0.6255  decode.d3.loss_cls: 0.2138  decode.d3.loss_mask: 0.9273  decode.d3.loss_dice: 0.6273  decode.d4.loss_cls: 0.1850  decode.d4.loss_mask: 0.9068  decode.d4.loss_dice: 0.6398  decode.d5.loss_cls: 0.1955  decode.d5.loss_mask: 0.9103  decode.d5.loss_dice: 0.6762  decode.d6.loss_cls: 0.2433  decode.d6.loss_mask: 0.8882  decode.d6.loss_dice: 0.6361  decode.d7.loss_cls: 0.1923  decode.d7.loss_mask: 0.9316  decode.d7.loss_dice: 0.6344  decode.d8.loss_cls: 0.2205  decode.d8.loss_mask: 0.9016  decode.d8.loss_dice: 0.6275
05/27 05:05:24 - mmengine - INFO - Iter(train) [152650/160000]  base_lr: 6.2511e-06 lr: 6.2511e-07  eta: 0:50:44  time: 0.4206  data_time: 0.0103  memory: 5965  grad_norm: 536.1076  loss: 19.3231  decode.loss_cls: 0.1406  decode.loss_mask: 1.0431  decode.loss_dice: 0.6716  decode.d0.loss_cls: 0.6337  decode.d0.loss_mask: 1.0625  decode.d0.loss_dice: 0.6888  decode.d1.loss_cls: 0.2057  decode.d1.loss_mask: 1.0708  decode.d1.loss_dice: 0.6751  decode.d2.loss_cls: 0.1721  decode.d2.loss_mask: 1.0467  decode.d2.loss_dice: 0.6635  decode.d3.loss_cls: 0.1579  decode.d3.loss_mask: 1.0572  decode.d3.loss_dice: 0.6633  decode.d4.loss_cls: 0.1596  decode.d4.loss_mask: 1.0493  decode.d4.loss_dice: 0.6639  decode.d5.loss_cls: 0.1669  decode.d5.loss_mask: 1.0491  decode.d5.loss_dice: 0.6603  decode.d6.loss_cls: 0.1720  decode.d6.loss_mask: 1.0485  decode.d6.loss_dice: 0.6682  decode.d7.loss_cls: 0.1755  decode.d7.loss_mask: 1.0375  decode.d7.loss_dice: 0.6637  decode.d8.loss_cls: 0.1496  decode.d8.loss_mask: 1.0442  decode.d8.loss_dice: 0.6624
05/27 05:05:44 - mmengine - INFO - Iter(train) [152700/160000]  base_lr: 6.2128e-06 lr: 6.2128e-07  eta: 0:50:24  time: 0.4191  data_time: 0.0103  memory: 5974  grad_norm: 436.5374  loss: 19.9161  decode.loss_cls: 0.1661  decode.loss_mask: 1.0406  decode.loss_dice: 0.7341  decode.d0.loss_cls: 0.6683  decode.d0.loss_mask: 1.0283  decode.d0.loss_dice: 0.7445  decode.d1.loss_cls: 0.1845  decode.d1.loss_mask: 1.0506  decode.d1.loss_dice: 0.7396  decode.d2.loss_cls: 0.1578  decode.d2.loss_mask: 1.0589  decode.d2.loss_dice: 0.7540  decode.d3.loss_cls: 0.1890  decode.d3.loss_mask: 1.0269  decode.d3.loss_dice: 0.7018  decode.d4.loss_cls: 0.1774  decode.d4.loss_mask: 1.0226  decode.d4.loss_dice: 0.7168  decode.d5.loss_cls: 0.1642  decode.d5.loss_mask: 1.0385  decode.d5.loss_dice: 0.7213  decode.d6.loss_cls: 0.1639  decode.d6.loss_mask: 1.0437  decode.d6.loss_dice: 0.7360  decode.d7.loss_cls: 0.2052  decode.d7.loss_mask: 1.0218  decode.d7.loss_dice: 0.7380  decode.d8.loss_cls: 0.1994  decode.d8.loss_mask: 1.0123  decode.d8.loss_dice: 0.7098
05/27 05:06:05 - mmengine - INFO - Iter(train) [152750/160000]  base_lr: 6.1745e-06 lr: 6.1745e-07  eta: 0:50:03  time: 0.4188  data_time: 0.0100  memory: 5976  grad_norm: 723.5033  loss: 17.8095  decode.loss_cls: 0.1887  decode.loss_mask: 0.8974  decode.loss_dice: 0.6945  decode.d0.loss_cls: 0.6833  decode.d0.loss_mask: 0.8532  decode.d0.loss_dice: 0.6935  decode.d1.loss_cls: 0.1754  decode.d1.loss_mask: 0.8673  decode.d1.loss_dice: 0.7017  decode.d2.loss_cls: 0.1819  decode.d2.loss_mask: 0.8492  decode.d2.loss_dice: 0.6830  decode.d3.loss_cls: 0.1957  decode.d3.loss_mask: 0.8609  decode.d3.loss_dice: 0.7022  decode.d4.loss_cls: 0.1780  decode.d4.loss_mask: 0.8477  decode.d4.loss_dice: 0.6789  decode.d5.loss_cls: 0.1752  decode.d5.loss_mask: 0.8613  decode.d5.loss_dice: 0.6930  decode.d6.loss_cls: 0.1793  decode.d6.loss_mask: 0.8619  decode.d6.loss_dice: 0.6878  decode.d7.loss_cls: 0.1480  decode.d7.loss_mask: 0.8595  decode.d7.loss_dice: 0.6965  decode.d8.loss_cls: 0.1880  decode.d8.loss_mask: 0.8512  decode.d8.loss_dice: 0.6752
05/27 05:06:26 - mmengine - INFO - Iter(train) [152800/160000]  base_lr: 6.1361e-06 lr: 6.1361e-07  eta: 0:49:42  time: 0.4190  data_time: 0.0100  memory: 5968  grad_norm: 375.0724  loss: 16.0107  decode.loss_cls: 0.1281  decode.loss_mask: 0.8014  decode.loss_dice: 0.6244  decode.d0.loss_cls: 0.5600  decode.d0.loss_mask: 0.8229  decode.d0.loss_dice: 0.6475  decode.d1.loss_cls: 0.1588  decode.d1.loss_mask: 0.8068  decode.d1.loss_dice: 0.6308  decode.d2.loss_cls: 0.1596  decode.d2.loss_mask: 0.7874  decode.d2.loss_dice: 0.6210  decode.d3.loss_cls: 0.1533  decode.d3.loss_mask: 0.7922  decode.d3.loss_dice: 0.6258  decode.d4.loss_cls: 0.1037  decode.d4.loss_mask: 0.8118  decode.d4.loss_dice: 0.6268  decode.d5.loss_cls: 0.1230  decode.d5.loss_mask: 0.7942  decode.d5.loss_dice: 0.6246  decode.d6.loss_cls: 0.1179  decode.d6.loss_mask: 0.8113  decode.d6.loss_dice: 0.6235  decode.d7.loss_cls: 0.1295  decode.d7.loss_mask: 0.7891  decode.d7.loss_dice: 0.6065  decode.d8.loss_cls: 0.1250  decode.d8.loss_mask: 0.7920  decode.d8.loss_dice: 0.6118
05/27 05:06:47 - mmengine - INFO - Iter(train) [152850/160000]  base_lr: 6.0978e-06 lr: 6.0978e-07  eta: 0:49:22  time: 0.4197  data_time: 0.0100  memory: 5971  grad_norm: 508.1202  loss: 20.3989  decode.loss_cls: 0.1870  decode.loss_mask: 0.9918  decode.loss_dice: 0.7932  decode.d0.loss_cls: 0.6533  decode.d0.loss_mask: 1.0337  decode.d0.loss_dice: 0.8095  decode.d1.loss_cls: 0.1982  decode.d1.loss_mask: 0.9840  decode.d1.loss_dice: 0.7741  decode.d2.loss_cls: 0.2069  decode.d2.loss_mask: 1.0162  decode.d2.loss_dice: 0.8073  decode.d3.loss_cls: 0.1915  decode.d3.loss_mask: 1.0123  decode.d3.loss_dice: 0.7939  decode.d4.loss_cls: 0.2010  decode.d4.loss_mask: 1.0010  decode.d4.loss_dice: 0.7962  decode.d5.loss_cls: 0.2006  decode.d5.loss_mask: 0.9922  decode.d5.loss_dice: 0.8014  decode.d6.loss_cls: 0.2097  decode.d6.loss_mask: 0.9896  decode.d6.loss_dice: 0.7855  decode.d7.loss_cls: 0.2098  decode.d7.loss_mask: 0.9851  decode.d7.loss_dice: 0.7854  decode.d8.loss_cls: 0.1941  decode.d8.loss_mask: 0.9993  decode.d8.loss_dice: 0.7953
05/27 05:07:08 - mmengine - INFO - Iter(train) [152900/160000]  base_lr: 6.0594e-06 lr: 6.0594e-07  eta: 0:49:01  time: 0.4198  data_time: 0.0100  memory: 5971  grad_norm: 489.2029  loss: 15.2675  decode.loss_cls: 0.1729  decode.loss_mask: 0.7313  decode.loss_dice: 0.5489  decode.d0.loss_cls: 0.6028  decode.d0.loss_mask: 0.7348  decode.d0.loss_dice: 0.5791  decode.d1.loss_cls: 0.1917  decode.d1.loss_mask: 0.7211  decode.d1.loss_dice: 0.5563  decode.d2.loss_cls: 0.2060  decode.d2.loss_mask: 0.7393  decode.d2.loss_dice: 0.5521  decode.d3.loss_cls: 0.2123  decode.d3.loss_mask: 0.7547  decode.d3.loss_dice: 0.5501  decode.d4.loss_cls: 0.1866  decode.d4.loss_mask: 0.7528  decode.d4.loss_dice: 0.5538  decode.d5.loss_cls: 0.1740  decode.d5.loss_mask: 0.7579  decode.d5.loss_dice: 0.5762  decode.d6.loss_cls: 0.1699  decode.d6.loss_mask: 0.7276  decode.d6.loss_dice: 0.5732  decode.d7.loss_cls: 0.1808  decode.d7.loss_mask: 0.7376  decode.d7.loss_dice: 0.5551  decode.d8.loss_cls: 0.1903  decode.d8.loss_mask: 0.7320  decode.d8.loss_dice: 0.5461
05/27 05:07:29 - mmengine - INFO - Iter(train) [152950/160000]  base_lr: 6.0209e-06 lr: 6.0209e-07  eta: 0:48:40  time: 0.4182  data_time: 0.0100  memory: 5990  grad_norm: 261.7664  loss: 15.9109  decode.loss_cls: 0.2042  decode.loss_mask: 0.7193  decode.loss_dice: 0.6231  decode.d0.loss_cls: 0.7295  decode.d0.loss_mask: 0.6990  decode.d0.loss_dice: 0.6051  decode.d1.loss_cls: 0.2388  decode.d1.loss_mask: 0.7088  decode.d1.loss_dice: 0.6200  decode.d2.loss_cls: 0.2078  decode.d2.loss_mask: 0.7180  decode.d2.loss_dice: 0.6274  decode.d3.loss_cls: 0.1998  decode.d3.loss_mask: 0.7142  decode.d3.loss_dice: 0.6034  decode.d4.loss_cls: 0.2176  decode.d4.loss_mask: 0.7083  decode.d4.loss_dice: 0.6042  decode.d5.loss_cls: 0.1991  decode.d5.loss_mask: 0.7195  decode.d5.loss_dice: 0.6290  decode.d6.loss_cls: 0.1894  decode.d6.loss_mask: 0.7218  decode.d6.loss_dice: 0.6306  decode.d7.loss_cls: 0.2160  decode.d7.loss_mask: 0.7187  decode.d7.loss_dice: 0.5988  decode.d8.loss_cls: 0.2114  decode.d8.loss_mask: 0.7085  decode.d8.loss_dice: 0.6197
05/27 05:07:50 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 05:07:50 - mmengine - INFO - Iter(train) [153000/160000]  base_lr: 5.9825e-06 lr: 5.9825e-07  eta: 0:48:20  time: 0.4197  data_time: 0.0101  memory: 5974  grad_norm: 650.4775  loss: 20.9586  decode.loss_cls: 0.1725  decode.loss_mask: 1.1073  decode.loss_dice: 0.7574  decode.d0.loss_cls: 0.6335  decode.d0.loss_mask: 1.1061  decode.d0.loss_dice: 0.7612  decode.d1.loss_cls: 0.1543  decode.d1.loss_mask: 1.0939  decode.d1.loss_dice: 0.7754  decode.d2.loss_cls: 0.1688  decode.d2.loss_mask: 1.1114  decode.d2.loss_dice: 0.7639  decode.d3.loss_cls: 0.1620  decode.d3.loss_mask: 1.1048  decode.d3.loss_dice: 0.7973  decode.d4.loss_cls: 0.1741  decode.d4.loss_mask: 1.1123  decode.d4.loss_dice: 0.7982  decode.d5.loss_cls: 0.1341  decode.d5.loss_mask: 1.1123  decode.d5.loss_dice: 0.8035  decode.d6.loss_cls: 0.1888  decode.d6.loss_mask: 1.1110  decode.d6.loss_dice: 0.7630  decode.d7.loss_cls: 0.1654  decode.d7.loss_mask: 1.1202  decode.d7.loss_dice: 0.7896  decode.d8.loss_cls: 0.1583  decode.d8.loss_mask: 1.0944  decode.d8.loss_dice: 0.7638
05/27 05:08:11 - mmengine - INFO - Iter(train) [153050/160000]  base_lr: 5.9440e-06 lr: 5.9440e-07  eta: 0:47:59  time: 0.4186  data_time: 0.0101  memory: 5971  grad_norm: 423.6616  loss: 16.0575  decode.loss_cls: 0.1187  decode.loss_mask: 0.8039  decode.loss_dice: 0.6080  decode.d0.loss_cls: 0.6667  decode.d0.loss_mask: 0.8107  decode.d0.loss_dice: 0.6250  decode.d1.loss_cls: 0.1353  decode.d1.loss_mask: 0.8155  decode.d1.loss_dice: 0.6341  decode.d2.loss_cls: 0.1354  decode.d2.loss_mask: 0.7921  decode.d2.loss_dice: 0.6118  decode.d3.loss_cls: 0.1081  decode.d3.loss_mask: 0.8029  decode.d3.loss_dice: 0.6158  decode.d4.loss_cls: 0.1379  decode.d4.loss_mask: 0.8121  decode.d4.loss_dice: 0.6209  decode.d5.loss_cls: 0.1196  decode.d5.loss_mask: 0.8102  decode.d5.loss_dice: 0.6213  decode.d6.loss_cls: 0.0939  decode.d6.loss_mask: 0.8131  decode.d6.loss_dice: 0.6442  decode.d7.loss_cls: 0.1358  decode.d7.loss_mask: 0.8040  decode.d7.loss_dice: 0.6130  decode.d8.loss_cls: 0.1282  decode.d8.loss_mask: 0.8104  decode.d8.loss_dice: 0.6089
05/27 05:08:32 - mmengine - INFO - Iter(train) [153100/160000]  base_lr: 5.9055e-06 lr: 5.9055e-07  eta: 0:47:38  time: 0.4286  data_time: 0.0101  memory: 5967  grad_norm: 641.3512  loss: 16.4159  decode.loss_cls: 0.1171  decode.loss_mask: 0.8979  decode.loss_dice: 0.5847  decode.d0.loss_cls: 0.5456  decode.d0.loss_mask: 0.8202  decode.d0.loss_dice: 0.5808  decode.d1.loss_cls: 0.1059  decode.d1.loss_mask: 0.8958  decode.d1.loss_dice: 0.5854  decode.d2.loss_cls: 0.1101  decode.d2.loss_mask: 0.9377  decode.d2.loss_dice: 0.5855  decode.d3.loss_cls: 0.1289  decode.d3.loss_mask: 0.8939  decode.d3.loss_dice: 0.5874  decode.d4.loss_cls: 0.1080  decode.d4.loss_mask: 0.9059  decode.d4.loss_dice: 0.5931  decode.d5.loss_cls: 0.1289  decode.d5.loss_mask: 0.9017  decode.d5.loss_dice: 0.5917  decode.d6.loss_cls: 0.0985  decode.d6.loss_mask: 0.8908  decode.d6.loss_dice: 0.5972  decode.d7.loss_cls: 0.1233  decode.d7.loss_mask: 0.9016  decode.d7.loss_dice: 0.6035  decode.d8.loss_cls: 0.0996  decode.d8.loss_mask: 0.9054  decode.d8.loss_dice: 0.5897
05/27 05:08:53 - mmengine - INFO - Iter(train) [153150/160000]  base_lr: 5.8670e-06 lr: 5.8670e-07  eta: 0:47:17  time: 0.4187  data_time: 0.0101  memory: 5969  grad_norm: 423.7639  loss: 16.2398  decode.loss_cls: 0.1589  decode.loss_mask: 0.8685  decode.loss_dice: 0.5513  decode.d0.loss_cls: 0.5282  decode.d0.loss_mask: 0.9247  decode.d0.loss_dice: 0.5835  decode.d1.loss_cls: 0.1064  decode.d1.loss_mask: 0.9240  decode.d1.loss_dice: 0.5524  decode.d2.loss_cls: 0.1552  decode.d2.loss_mask: 0.8791  decode.d2.loss_dice: 0.5415  decode.d3.loss_cls: 0.1660  decode.d3.loss_mask: 0.8604  decode.d3.loss_dice: 0.5416  decode.d4.loss_cls: 0.1431  decode.d4.loss_mask: 0.8833  decode.d4.loss_dice: 0.5560  decode.d5.loss_cls: 0.1167  decode.d5.loss_mask: 0.9131  decode.d5.loss_dice: 0.5619  decode.d6.loss_cls: 0.1892  decode.d6.loss_mask: 0.8615  decode.d6.loss_dice: 0.5378  decode.d7.loss_cls: 0.1357  decode.d7.loss_mask: 0.8995  decode.d7.loss_dice: 0.5466  decode.d8.loss_cls: 0.1537  decode.d8.loss_mask: 0.8663  decode.d8.loss_dice: 0.5336
05/27 05:09:14 - mmengine - INFO - Iter(train) [153200/160000]  base_lr: 5.8284e-06 lr: 5.8284e-07  eta: 0:46:57  time: 0.4195  data_time: 0.0100  memory: 5971  grad_norm: 555.5224  loss: 20.6146  decode.loss_cls: 0.1323  decode.loss_mask: 1.1152  decode.loss_dice: 0.7559  decode.d0.loss_cls: 0.6461  decode.d0.loss_mask: 1.1124  decode.d0.loss_dice: 0.7584  decode.d1.loss_cls: 0.1385  decode.d1.loss_mask: 1.1224  decode.d1.loss_dice: 0.7596  decode.d2.loss_cls: 0.1581  decode.d2.loss_mask: 1.0901  decode.d2.loss_dice: 0.7392  decode.d3.loss_cls: 0.1626  decode.d3.loss_mask: 1.0942  decode.d3.loss_dice: 0.7481  decode.d4.loss_cls: 0.1382  decode.d4.loss_mask: 1.1158  decode.d4.loss_dice: 0.7691  decode.d5.loss_cls: 0.1486  decode.d5.loss_mask: 1.1327  decode.d5.loss_dice: 0.7668  decode.d6.loss_cls: 0.1294  decode.d6.loss_mask: 1.1172  decode.d6.loss_dice: 0.7659  decode.d7.loss_cls: 0.1362  decode.d7.loss_mask: 1.1025  decode.d7.loss_dice: 0.7607  decode.d8.loss_cls: 0.1393  decode.d8.loss_mask: 1.0966  decode.d8.loss_dice: 0.7626
05/27 05:09:35 - mmengine - INFO - Iter(train) [153250/160000]  base_lr: 5.7899e-06 lr: 5.7899e-07  eta: 0:46:36  time: 0.4181  data_time: 0.0100  memory: 5976  grad_norm: 859.3290  loss: 20.3525  decode.loss_cls: 0.1538  decode.loss_mask: 1.1100  decode.loss_dice: 0.7387  decode.d0.loss_cls: 0.6527  decode.d0.loss_mask: 1.0733  decode.d0.loss_dice: 0.6913  decode.d1.loss_cls: 0.1340  decode.d1.loss_mask: 1.1283  decode.d1.loss_dice: 0.7404  decode.d2.loss_cls: 0.1364  decode.d2.loss_mask: 1.1203  decode.d2.loss_dice: 0.7469  decode.d3.loss_cls: 0.1428  decode.d3.loss_mask: 1.1262  decode.d3.loss_dice: 0.7306  decode.d4.loss_cls: 0.1348  decode.d4.loss_mask: 1.1035  decode.d4.loss_dice: 0.7268  decode.d5.loss_cls: 0.1364  decode.d5.loss_mask: 1.1137  decode.d5.loss_dice: 0.7347  decode.d6.loss_cls: 0.1419  decode.d6.loss_mask: 1.1060  decode.d6.loss_dice: 0.7291  decode.d7.loss_cls: 0.1440  decode.d7.loss_mask: 1.1259  decode.d7.loss_dice: 0.7388  decode.d8.loss_cls: 0.1580  decode.d8.loss_mask: 1.1011  decode.d8.loss_dice: 0.7323
05/27 05:09:56 - mmengine - INFO - Iter(train) [153300/160000]  base_lr: 5.7512e-06 lr: 5.7512e-07  eta: 0:46:15  time: 0.4180  data_time: 0.0100  memory: 5971  grad_norm: 577.3396  loss: 16.4404  decode.loss_cls: 0.1300  decode.loss_mask: 0.8756  decode.loss_dice: 0.5915  decode.d0.loss_cls: 0.6726  decode.d0.loss_mask: 0.8483  decode.d0.loss_dice: 0.5746  decode.d1.loss_cls: 0.1412  decode.d1.loss_mask: 0.8750  decode.d1.loss_dice: 0.5952  decode.d2.loss_cls: 0.0998  decode.d2.loss_mask: 0.8990  decode.d2.loss_dice: 0.5860  decode.d3.loss_cls: 0.1281  decode.d3.loss_mask: 0.8817  decode.d3.loss_dice: 0.5854  decode.d4.loss_cls: 0.1392  decode.d4.loss_mask: 0.8766  decode.d4.loss_dice: 0.5833  decode.d5.loss_cls: 0.1304  decode.d5.loss_mask: 0.8743  decode.d5.loss_dice: 0.5855  decode.d6.loss_cls: 0.1408  decode.d6.loss_mask: 0.8808  decode.d6.loss_dice: 0.5824  decode.d7.loss_cls: 0.1277  decode.d7.loss_mask: 0.8674  decode.d7.loss_dice: 0.5843  decode.d8.loss_cls: 0.1165  decode.d8.loss_mask: 0.8792  decode.d8.loss_dice: 0.5883
05/27 05:10:17 - mmengine - INFO - Iter(train) [153350/160000]  base_lr: 5.7126e-06 lr: 5.7126e-07  eta: 0:45:55  time: 0.4191  data_time: 0.0099  memory: 5974  grad_norm: 407.4899  loss: 15.2673  decode.loss_cls: 0.0734  decode.loss_mask: 0.8283  decode.loss_dice: 0.5871  decode.d0.loss_cls: 0.5428  decode.d0.loss_mask: 0.7932  decode.d0.loss_dice: 0.5729  decode.d1.loss_cls: 0.0959  decode.d1.loss_mask: 0.8208  decode.d1.loss_dice: 0.5703  decode.d2.loss_cls: 0.0878  decode.d2.loss_mask: 0.8247  decode.d2.loss_dice: 0.5937  decode.d3.loss_cls: 0.0727  decode.d3.loss_mask: 0.8150  decode.d3.loss_dice: 0.5887  decode.d4.loss_cls: 0.0791  decode.d4.loss_mask: 0.8180  decode.d4.loss_dice: 0.5838  decode.d5.loss_cls: 0.0839  decode.d5.loss_mask: 0.8188  decode.d5.loss_dice: 0.5805  decode.d6.loss_cls: 0.0736  decode.d6.loss_mask: 0.8191  decode.d6.loss_dice: 0.5763  decode.d7.loss_cls: 0.0718  decode.d7.loss_mask: 0.8230  decode.d7.loss_dice: 0.5918  decode.d8.loss_cls: 0.0767  decode.d8.loss_mask: 0.8227  decode.d8.loss_dice: 0.5812
05/27 05:10:38 - mmengine - INFO - Iter(train) [153400/160000]  base_lr: 5.6739e-06 lr: 5.6739e-07  eta: 0:45:34  time: 0.4187  data_time: 0.0101  memory: 5967  grad_norm: 347.8586  loss: 15.7532  decode.loss_cls: 0.1682  decode.loss_mask: 0.7998  decode.loss_dice: 0.5949  decode.d0.loss_cls: 0.6025  decode.d0.loss_mask: 0.7550  decode.d0.loss_dice: 0.5798  decode.d1.loss_cls: 0.1570  decode.d1.loss_mask: 0.8088  decode.d1.loss_dice: 0.6024  decode.d2.loss_cls: 0.1592  decode.d2.loss_mask: 0.7588  decode.d2.loss_dice: 0.5744  decode.d3.loss_cls: 0.1222  decode.d3.loss_mask: 0.8025  decode.d3.loss_dice: 0.5951  decode.d4.loss_cls: 0.1605  decode.d4.loss_mask: 0.7896  decode.d4.loss_dice: 0.5942  decode.d5.loss_cls: 0.1757  decode.d5.loss_mask: 0.7901  decode.d5.loss_dice: 0.5875  decode.d6.loss_cls: 0.1822  decode.d6.loss_mask: 0.7621  decode.d6.loss_dice: 0.5683  decode.d7.loss_cls: 0.1537  decode.d7.loss_mask: 0.8109  decode.d7.loss_dice: 0.5985  decode.d8.loss_cls: 0.1666  decode.d8.loss_mask: 0.7541  decode.d8.loss_dice: 0.5787
05/27 05:10:59 - mmengine - INFO - Iter(train) [153450/160000]  base_lr: 5.6352e-06 lr: 5.6352e-07  eta: 0:45:13  time: 0.4200  data_time: 0.0112  memory: 5973  grad_norm: 431.8195  loss: 15.0635  decode.loss_cls: 0.1088  decode.loss_mask: 0.7926  decode.loss_dice: 0.5350  decode.d0.loss_cls: 0.6024  decode.d0.loss_mask: 0.7771  decode.d0.loss_dice: 0.5757  decode.d1.loss_cls: 0.1328  decode.d1.loss_mask: 0.7741  decode.d1.loss_dice: 0.5157  decode.d2.loss_cls: 0.1121  decode.d2.loss_mask: 0.8070  decode.d2.loss_dice: 0.5771  decode.d3.loss_cls: 0.1117  decode.d3.loss_mask: 0.7933  decode.d3.loss_dice: 0.5388  decode.d4.loss_cls: 0.1014  decode.d4.loss_mask: 0.8205  decode.d4.loss_dice: 0.5764  decode.d5.loss_cls: 0.1067  decode.d5.loss_mask: 0.8142  decode.d5.loss_dice: 0.5502  decode.d6.loss_cls: 0.1067  decode.d6.loss_mask: 0.8084  decode.d6.loss_dice: 0.5289  decode.d7.loss_cls: 0.0955  decode.d7.loss_mask: 0.8091  decode.d7.loss_dice: 0.5682  decode.d8.loss_cls: 0.0984  decode.d8.loss_mask: 0.7961  decode.d8.loss_dice: 0.5284
05/27 05:11:20 - mmengine - INFO - Iter(train) [153500/160000]  base_lr: 5.5965e-06 lr: 5.5965e-07  eta: 0:44:53  time: 0.4189  data_time: 0.0099  memory: 5976  grad_norm: 602.7703  loss: 19.9583  decode.loss_cls: 0.1860  decode.loss_mask: 0.9750  decode.loss_dice: 0.7857  decode.d0.loss_cls: 0.8050  decode.d0.loss_mask: 0.9844  decode.d0.loss_dice: 0.7793  decode.d1.loss_cls: 0.2248  decode.d1.loss_mask: 0.9657  decode.d1.loss_dice: 0.7628  decode.d2.loss_cls: 0.1688  decode.d2.loss_mask: 1.0040  decode.d2.loss_dice: 0.7580  decode.d3.loss_cls: 0.1545  decode.d3.loss_mask: 1.0012  decode.d3.loss_dice: 0.7629  decode.d4.loss_cls: 0.1731  decode.d4.loss_mask: 0.9747  decode.d4.loss_dice: 0.7631  decode.d5.loss_cls: 0.1729  decode.d5.loss_mask: 0.9821  decode.d5.loss_dice: 0.7737  decode.d6.loss_cls: 0.2088  decode.d6.loss_mask: 0.9645  decode.d6.loss_dice: 0.7718  decode.d7.loss_cls: 0.1744  decode.d7.loss_mask: 0.9904  decode.d7.loss_dice: 0.7707  decode.d8.loss_cls: 0.2358  decode.d8.loss_mask: 0.9487  decode.d8.loss_dice: 0.7356
05/27 05:11:41 - mmengine - INFO - Iter(train) [153550/160000]  base_lr: 5.5577e-06 lr: 5.5577e-07  eta: 0:44:32  time: 0.4196  data_time: 0.0100  memory: 5975  grad_norm: 452.6871  loss: 14.3862  decode.loss_cls: 0.0580  decode.loss_mask: 0.7841  decode.loss_dice: 0.5338  decode.d0.loss_cls: 0.5412  decode.d0.loss_mask: 0.8390  decode.d0.loss_dice: 0.5729  decode.d1.loss_cls: 0.0611  decode.d1.loss_mask: 0.7892  decode.d1.loss_dice: 0.5244  decode.d2.loss_cls: 0.0703  decode.d2.loss_mask: 0.7896  decode.d2.loss_dice: 0.5320  decode.d3.loss_cls: 0.0808  decode.d3.loss_mask: 0.7802  decode.d3.loss_dice: 0.5316  decode.d4.loss_cls: 0.0665  decode.d4.loss_mask: 0.7832  decode.d4.loss_dice: 0.5320  decode.d5.loss_cls: 0.0833  decode.d5.loss_mask: 0.7731  decode.d5.loss_dice: 0.5222  decode.d6.loss_cls: 0.0655  decode.d6.loss_mask: 0.7785  decode.d6.loss_dice: 0.5329  decode.d7.loss_cls: 0.0644  decode.d7.loss_mask: 0.7829  decode.d7.loss_dice: 0.5318  decode.d8.loss_cls: 0.0608  decode.d8.loss_mask: 0.7872  decode.d8.loss_dice: 0.5340
05/27 05:12:02 - mmengine - INFO - Iter(train) [153600/160000]  base_lr: 5.5189e-06 lr: 5.5189e-07  eta: 0:44:11  time: 0.4182  data_time: 0.0100  memory: 5967  grad_norm: 565.3848  loss: 17.1236  decode.loss_cls: 0.2056  decode.loss_mask: 0.8187  decode.loss_dice: 0.6069  decode.d0.loss_cls: 0.6644  decode.d0.loss_mask: 0.8605  decode.d0.loss_dice: 0.6133  decode.d1.loss_cls: 0.2408  decode.d1.loss_mask: 0.8492  decode.d1.loss_dice: 0.5982  decode.d2.loss_cls: 0.2060  decode.d2.loss_mask: 0.8315  decode.d2.loss_dice: 0.6143  decode.d3.loss_cls: 0.2041  decode.d3.loss_mask: 0.8219  decode.d3.loss_dice: 0.6001  decode.d4.loss_cls: 0.2179  decode.d4.loss_mask: 0.8397  decode.d4.loss_dice: 0.6026  decode.d5.loss_cls: 0.2102  decode.d5.loss_mask: 0.8679  decode.d5.loss_dice: 0.6280  decode.d6.loss_cls: 0.1989  decode.d6.loss_mask: 0.8820  decode.d6.loss_dice: 0.6233  decode.d7.loss_cls: 0.2014  decode.d7.loss_mask: 0.8329  decode.d7.loss_dice: 0.6123  decode.d8.loss_cls: 0.1900  decode.d8.loss_mask: 0.8476  decode.d8.loss_dice: 0.6336
05/27 05:12:23 - mmengine - INFO - Iter(train) [153650/160000]  base_lr: 5.4801e-06 lr: 5.4801e-07  eta: 0:43:50  time: 0.4184  data_time: 0.0100  memory: 5972  grad_norm: 558.6187  loss: 21.8993  decode.loss_cls: 0.2140  decode.loss_mask: 1.0210  decode.loss_dice: 0.8470  decode.d0.loss_cls: 0.8533  decode.d0.loss_mask: 0.9920  decode.d0.loss_dice: 0.8617  decode.d1.loss_cls: 0.2555  decode.d1.loss_mask: 1.0396  decode.d1.loss_dice: 0.8733  decode.d2.loss_cls: 0.2515  decode.d2.loss_mask: 1.0234  decode.d2.loss_dice: 0.8550  decode.d3.loss_cls: 0.2406  decode.d3.loss_mask: 1.0165  decode.d3.loss_dice: 0.8613  decode.d4.loss_cls: 0.2219  decode.d4.loss_mask: 1.0403  decode.d4.loss_dice: 0.8758  decode.d5.loss_cls: 0.2283  decode.d5.loss_mask: 1.0329  decode.d5.loss_dice: 0.8665  decode.d6.loss_cls: 0.2946  decode.d6.loss_mask: 1.0145  decode.d6.loss_dice: 0.8696  decode.d7.loss_cls: 0.2150  decode.d7.loss_mask: 1.0390  decode.d7.loss_dice: 0.8778  decode.d8.loss_cls: 0.2051  decode.d8.loss_mask: 1.0341  decode.d8.loss_dice: 0.8784
05/27 05:12:44 - mmengine - INFO - Iter(train) [153700/160000]  base_lr: 5.4413e-06 lr: 5.4413e-07  eta: 0:43:30  time: 0.4190  data_time: 0.0100  memory: 5972  grad_norm: 537.5134  loss: 18.1679  decode.loss_cls: 0.1655  decode.loss_mask: 0.9132  decode.loss_dice: 0.6682  decode.d0.loss_cls: 0.6566  decode.d0.loss_mask: 0.8903  decode.d0.loss_dice: 0.6525  decode.d1.loss_cls: 0.1628  decode.d1.loss_mask: 0.9469  decode.d1.loss_dice: 0.7001  decode.d2.loss_cls: 0.1787  decode.d2.loss_mask: 0.9219  decode.d2.loss_dice: 0.6729  decode.d3.loss_cls: 0.1604  decode.d3.loss_mask: 0.9219  decode.d3.loss_dice: 0.6978  decode.d4.loss_cls: 0.1679  decode.d4.loss_mask: 0.9317  decode.d4.loss_dice: 0.6776  decode.d5.loss_cls: 0.1690  decode.d5.loss_mask: 0.9302  decode.d5.loss_dice: 0.6817  decode.d6.loss_cls: 0.1763  decode.d6.loss_mask: 0.9201  decode.d6.loss_dice: 0.6700  decode.d7.loss_cls: 0.1483  decode.d7.loss_mask: 0.9333  decode.d7.loss_dice: 0.6788  decode.d8.loss_cls: 0.1871  decode.d8.loss_mask: 0.9193  decode.d8.loss_dice: 0.6668
05/27 05:13:05 - mmengine - INFO - Iter(train) [153750/160000]  base_lr: 5.4024e-06 lr: 5.4024e-07  eta: 0:43:09  time: 0.4184  data_time: 0.0100  memory: 5970  grad_norm: 669.9552  loss: 20.3147  decode.loss_cls: 0.1330  decode.loss_mask: 1.0722  decode.loss_dice: 0.7663  decode.d0.loss_cls: 0.6565  decode.d0.loss_mask: 1.0396  decode.d0.loss_dice: 0.7292  decode.d1.loss_cls: 0.1936  decode.d1.loss_mask: 1.0482  decode.d1.loss_dice: 0.7625  decode.d2.loss_cls: 0.2061  decode.d2.loss_mask: 1.0466  decode.d2.loss_dice: 0.7407  decode.d3.loss_cls: 0.2173  decode.d3.loss_mask: 1.0394  decode.d3.loss_dice: 0.7272  decode.d4.loss_cls: 0.1884  decode.d4.loss_mask: 1.0491  decode.d4.loss_dice: 0.7320  decode.d5.loss_cls: 0.2018  decode.d5.loss_mask: 1.0771  decode.d5.loss_dice: 0.7549  decode.d6.loss_cls: 0.1500  decode.d6.loss_mask: 1.0582  decode.d6.loss_dice: 0.7547  decode.d7.loss_cls: 0.1831  decode.d7.loss_mask: 1.0445  decode.d7.loss_dice: 0.7533  decode.d8.loss_cls: 0.1777  decode.d8.loss_mask: 1.0578  decode.d8.loss_dice: 0.7539
05/27 05:13:26 - mmengine - INFO - Iter(train) [153800/160000]  base_lr: 5.3635e-06 lr: 5.3635e-07  eta: 0:42:48  time: 0.4185  data_time: 0.0099  memory: 5968  grad_norm: 345.3764  loss: 16.8735  decode.loss_cls: 0.0960  decode.loss_mask: 0.8886  decode.loss_dice: 0.6456  decode.d0.loss_cls: 0.5629  decode.d0.loss_mask: 0.9103  decode.d0.loss_dice: 0.6486  decode.d1.loss_cls: 0.1191  decode.d1.loss_mask: 0.8848  decode.d1.loss_dice: 0.6460  decode.d2.loss_cls: 0.1087  decode.d2.loss_mask: 0.9077  decode.d2.loss_dice: 0.6462  decode.d3.loss_cls: 0.1242  decode.d3.loss_mask: 0.8814  decode.d3.loss_dice: 0.6429  decode.d4.loss_cls: 0.0966  decode.d4.loss_mask: 0.8854  decode.d4.loss_dice: 0.6196  decode.d5.loss_cls: 0.1167  decode.d5.loss_mask: 0.9086  decode.d5.loss_dice: 0.6421  decode.d6.loss_cls: 0.0934  decode.d6.loss_mask: 0.8819  decode.d6.loss_dice: 0.6269  decode.d7.loss_cls: 0.1175  decode.d7.loss_mask: 0.8900  decode.d7.loss_dice: 0.6247  decode.d8.loss_cls: 0.1316  decode.d8.loss_mask: 0.8851  decode.d8.loss_dice: 0.6402
05/27 05:13:47 - mmengine - INFO - Iter(train) [153850/160000]  base_lr: 5.3245e-06 lr: 5.3245e-07  eta: 0:42:28  time: 0.4199  data_time: 0.0100  memory: 5975  grad_norm: 509.8442  loss: 18.4855  decode.loss_cls: 0.1610  decode.loss_mask: 0.9340  decode.loss_dice: 0.7027  decode.d0.loss_cls: 0.6346  decode.d0.loss_mask: 0.9094  decode.d0.loss_dice: 0.6802  decode.d1.loss_cls: 0.2028  decode.d1.loss_mask: 0.9359  decode.d1.loss_dice: 0.7063  decode.d2.loss_cls: 0.1761  decode.d2.loss_mask: 0.9286  decode.d2.loss_dice: 0.6971  decode.d3.loss_cls: 0.1735  decode.d3.loss_mask: 0.9353  decode.d3.loss_dice: 0.6984  decode.d4.loss_cls: 0.1820  decode.d4.loss_mask: 0.9331  decode.d4.loss_dice: 0.6897  decode.d5.loss_cls: 0.1759  decode.d5.loss_mask: 0.9329  decode.d5.loss_dice: 0.6971  decode.d6.loss_cls: 0.1701  decode.d6.loss_mask: 0.9314  decode.d6.loss_dice: 0.7021  decode.d7.loss_cls: 0.1606  decode.d7.loss_mask: 0.9317  decode.d7.loss_dice: 0.7051  decode.d8.loss_cls: 0.1500  decode.d8.loss_mask: 0.9403  decode.d8.loss_dice: 0.7074
05/27 05:14:08 - mmengine - INFO - Iter(train) [153900/160000]  base_lr: 5.2856e-06 lr: 5.2856e-07  eta: 0:42:07  time: 0.4190  data_time: 0.0100  memory: 5976  grad_norm: 537.3910  loss: 15.8628  decode.loss_cls: 0.2183  decode.loss_mask: 0.7612  decode.loss_dice: 0.5391  decode.d0.loss_cls: 0.6553  decode.d0.loss_mask: 0.8070  decode.d0.loss_dice: 0.5677  decode.d1.loss_cls: 0.2399  decode.d1.loss_mask: 0.7751  decode.d1.loss_dice: 0.5565  decode.d2.loss_cls: 0.2193  decode.d2.loss_mask: 0.7729  decode.d2.loss_dice: 0.5487  decode.d3.loss_cls: 0.2069  decode.d3.loss_mask: 0.7674  decode.d3.loss_dice: 0.5631  decode.d4.loss_cls: 0.2301  decode.d4.loss_mask: 0.7508  decode.d4.loss_dice: 0.5555  decode.d5.loss_cls: 0.2373  decode.d5.loss_mask: 0.7568  decode.d5.loss_dice: 0.5372  decode.d6.loss_cls: 0.2100  decode.d6.loss_mask: 0.7593  decode.d6.loss_dice: 0.5376  decode.d7.loss_cls: 0.2237  decode.d7.loss_mask: 0.7638  decode.d7.loss_dice: 0.5585  decode.d8.loss_cls: 0.2241  decode.d8.loss_mask: 0.7595  decode.d8.loss_dice: 0.5601
05/27 05:14:29 - mmengine - INFO - Iter(train) [153950/160000]  base_lr: 5.2466e-06 lr: 5.2466e-07  eta: 0:41:46  time: 0.4201  data_time: 0.0100  memory: 5971  grad_norm: 564.5904  loss: 20.6575  decode.loss_cls: 0.1668  decode.loss_mask: 1.1190  decode.loss_dice: 0.7065  decode.d0.loss_cls: 0.6422  decode.d0.loss_mask: 1.1050  decode.d0.loss_dice: 0.7261  decode.d1.loss_cls: 0.1721  decode.d1.loss_mask: 1.1323  decode.d1.loss_dice: 0.6993  decode.d2.loss_cls: 0.1700  decode.d2.loss_mask: 1.1032  decode.d2.loss_dice: 0.7098  decode.d3.loss_cls: 0.1578  decode.d3.loss_mask: 1.1480  decode.d3.loss_dice: 0.7346  decode.d4.loss_cls: 0.1271  decode.d4.loss_mask: 1.2082  decode.d4.loss_dice: 0.7379  decode.d5.loss_cls: 0.1401  decode.d5.loss_mask: 1.1489  decode.d5.loss_dice: 0.7341  decode.d6.loss_cls: 0.1228  decode.d6.loss_mask: 1.2302  decode.d6.loss_dice: 0.7398  decode.d7.loss_cls: 0.1561  decode.d7.loss_mask: 1.1368  decode.d7.loss_dice: 0.7167  decode.d8.loss_cls: 0.1576  decode.d8.loss_mask: 1.1211  decode.d8.loss_dice: 0.6872
05/27 05:14:50 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 05:14:50 - mmengine - INFO - Iter(train) [154000/160000]  base_lr: 5.2075e-06 lr: 5.2075e-07  eta: 0:41:25  time: 0.4202  data_time: 0.0101  memory: 5980  grad_norm: 316.2489  loss: 15.3256  decode.loss_cls: 0.0791  decode.loss_mask: 0.8200  decode.loss_dice: 0.5896  decode.d0.loss_cls: 0.5321  decode.d0.loss_mask: 0.8379  decode.d0.loss_dice: 0.6001  decode.d1.loss_cls: 0.0790  decode.d1.loss_mask: 0.8197  decode.d1.loss_dice: 0.5816  decode.d2.loss_cls: 0.0710  decode.d2.loss_mask: 0.8189  decode.d2.loss_dice: 0.5842  decode.d3.loss_cls: 0.0686  decode.d3.loss_mask: 0.8202  decode.d3.loss_dice: 0.5947  decode.d4.loss_cls: 0.0732  decode.d4.loss_mask: 0.8217  decode.d4.loss_dice: 0.5844  decode.d5.loss_cls: 0.0771  decode.d5.loss_mask: 0.8215  decode.d5.loss_dice: 0.5932  decode.d6.loss_cls: 0.0720  decode.d6.loss_mask: 0.8179  decode.d6.loss_dice: 0.5814  decode.d7.loss_cls: 0.0997  decode.d7.loss_mask: 0.8194  decode.d7.loss_dice: 0.5811  decode.d8.loss_cls: 0.0842  decode.d8.loss_mask: 0.8227  decode.d8.loss_dice: 0.5793
05/27 05:15:11 - mmengine - INFO - Iter(train) [154050/160000]  base_lr: 5.1684e-06 lr: 5.1684e-07  eta: 0:41:05  time: 0.4254  data_time: 0.0101  memory: 5966  grad_norm: 445.7845  loss: 17.0811  decode.loss_cls: 0.1670  decode.loss_mask: 0.8844  decode.loss_dice: 0.5732  decode.d0.loss_cls: 0.6752  decode.d0.loss_mask: 0.8823  decode.d0.loss_dice: 0.5853  decode.d1.loss_cls: 0.1879  decode.d1.loss_mask: 0.9015  decode.d1.loss_dice: 0.5856  decode.d2.loss_cls: 0.1537  decode.d2.loss_mask: 0.9370  decode.d2.loss_dice: 0.5858  decode.d3.loss_cls: 0.1338  decode.d3.loss_mask: 0.9015  decode.d3.loss_dice: 0.5828  decode.d4.loss_cls: 0.1642  decode.d4.loss_mask: 0.9069  decode.d4.loss_dice: 0.5827  decode.d5.loss_cls: 0.1785  decode.d5.loss_mask: 0.9349  decode.d5.loss_dice: 0.5935  decode.d6.loss_cls: 0.1656  decode.d6.loss_mask: 0.9307  decode.d6.loss_dice: 0.5894  decode.d7.loss_cls: 0.1793  decode.d7.loss_mask: 0.8887  decode.d7.loss_dice: 0.5849  decode.d8.loss_cls: 0.1790  decode.d8.loss_mask: 0.8858  decode.d8.loss_dice: 0.5800
05/27 05:15:32 - mmengine - INFO - Iter(train) [154100/160000]  base_lr: 5.1293e-06 lr: 5.1293e-07  eta: 0:40:44  time: 0.4186  data_time: 0.0100  memory: 5966  grad_norm: 889.2639  loss: 19.4308  decode.loss_cls: 0.2095  decode.loss_mask: 0.9872  decode.loss_dice: 0.6800  decode.d0.loss_cls: 0.5873  decode.d0.loss_mask: 1.0285  decode.d0.loss_dice: 0.7220  decode.d1.loss_cls: 0.1866  decode.d1.loss_mask: 1.0226  decode.d1.loss_dice: 0.7072  decode.d2.loss_cls: 0.2230  decode.d2.loss_mask: 0.9973  decode.d2.loss_dice: 0.6988  decode.d3.loss_cls: 0.2028  decode.d3.loss_mask: 0.9999  decode.d3.loss_dice: 0.6889  decode.d4.loss_cls: 0.2148  decode.d4.loss_mask: 1.0197  decode.d4.loss_dice: 0.7023  decode.d5.loss_cls: 0.1855  decode.d5.loss_mask: 1.0090  decode.d5.loss_dice: 0.6882  decode.d6.loss_cls: 0.1869  decode.d6.loss_mask: 1.0318  decode.d6.loss_dice: 0.7034  decode.d7.loss_cls: 0.2142  decode.d7.loss_mask: 1.0006  decode.d7.loss_dice: 0.6804  decode.d8.loss_cls: 0.1761  decode.d8.loss_mask: 0.9997  decode.d8.loss_dice: 0.6767
05/27 05:15:53 - mmengine - INFO - Iter(train) [154150/160000]  base_lr: 5.0902e-06 lr: 5.0902e-07  eta: 0:40:23  time: 0.4302  data_time: 0.0102  memory: 5972  grad_norm: 519.3877  loss: 16.2567  decode.loss_cls: 0.0979  decode.loss_mask: 0.9332  decode.loss_dice: 0.5671  decode.d0.loss_cls: 0.5564  decode.d0.loss_mask: 0.9184  decode.d0.loss_dice: 0.5452  decode.d1.loss_cls: 0.0927  decode.d1.loss_mask: 0.9379  decode.d1.loss_dice: 0.5765  decode.d2.loss_cls: 0.1128  decode.d2.loss_mask: 0.8944  decode.d2.loss_dice: 0.5464  decode.d3.loss_cls: 0.1041  decode.d3.loss_mask: 0.9315  decode.d3.loss_dice: 0.5677  decode.d4.loss_cls: 0.1073  decode.d4.loss_mask: 0.8917  decode.d4.loss_dice: 0.5434  decode.d5.loss_cls: 0.0916  decode.d5.loss_mask: 0.9258  decode.d5.loss_dice: 0.5640  decode.d6.loss_cls: 0.1061  decode.d6.loss_mask: 0.8998  decode.d6.loss_dice: 0.5574  decode.d7.loss_cls: 0.0952  decode.d7.loss_mask: 0.9268  decode.d7.loss_dice: 0.5674  decode.d8.loss_cls: 0.1000  decode.d8.loss_mask: 0.9255  decode.d8.loss_dice: 0.5723
05/27 05:16:14 - mmengine - INFO - Iter(train) [154200/160000]  base_lr: 5.0510e-06 lr: 5.0510e-07  eta: 0:40:03  time: 0.4188  data_time: 0.0101  memory: 5967  grad_norm: 407.3407  loss: 19.3930  decode.loss_cls: 0.2076  decode.loss_mask: 0.9933  decode.loss_dice: 0.7056  decode.d0.loss_cls: 0.7269  decode.d0.loss_mask: 0.9082  decode.d0.loss_dice: 0.6889  decode.d1.loss_cls: 0.2235  decode.d1.loss_mask: 0.9827  decode.d1.loss_dice: 0.6950  decode.d2.loss_cls: 0.2145  decode.d2.loss_mask: 1.0028  decode.d2.loss_dice: 0.7141  decode.d3.loss_cls: 0.1890  decode.d3.loss_mask: 1.0092  decode.d3.loss_dice: 0.7013  decode.d4.loss_cls: 0.2441  decode.d4.loss_mask: 0.9544  decode.d4.loss_dice: 0.6840  decode.d5.loss_cls: 0.2321  decode.d5.loss_mask: 0.9373  decode.d5.loss_dice: 0.6655  decode.d6.loss_cls: 0.2412  decode.d6.loss_mask: 0.9723  decode.d6.loss_dice: 0.6814  decode.d7.loss_cls: 0.2196  decode.d7.loss_mask: 1.0036  decode.d7.loss_dice: 0.6956  decode.d8.loss_cls: 0.2013  decode.d8.loss_mask: 1.0012  decode.d8.loss_dice: 0.6967
05/27 05:16:35 - mmengine - INFO - Iter(train) [154250/160000]  base_lr: 5.0118e-06 lr: 5.0118e-07  eta: 0:39:42  time: 0.4180  data_time: 0.0100  memory: 5967  grad_norm: 460.4380  loss: 17.1043  decode.loss_cls: 0.1087  decode.loss_mask: 0.8980  decode.loss_dice: 0.6685  decode.d0.loss_cls: 0.5427  decode.d0.loss_mask: 0.9292  decode.d0.loss_dice: 0.6504  decode.d1.loss_cls: 0.0845  decode.d1.loss_mask: 0.8992  decode.d1.loss_dice: 0.6640  decode.d2.loss_cls: 0.1261  decode.d2.loss_mask: 0.9123  decode.d2.loss_dice: 0.6677  decode.d3.loss_cls: 0.0967  decode.d3.loss_mask: 0.8985  decode.d3.loss_dice: 0.6665  decode.d4.loss_cls: 0.1295  decode.d4.loss_mask: 0.9021  decode.d4.loss_dice: 0.6562  decode.d5.loss_cls: 0.0941  decode.d5.loss_mask: 0.8870  decode.d5.loss_dice: 0.6579  decode.d6.loss_cls: 0.1236  decode.d6.loss_mask: 0.8944  decode.d6.loss_dice: 0.6556  decode.d7.loss_cls: 0.1035  decode.d7.loss_mask: 0.8848  decode.d7.loss_dice: 0.6593  decode.d8.loss_cls: 0.0927  decode.d8.loss_mask: 0.8886  decode.d8.loss_dice: 0.6621
05/27 05:16:56 - mmengine - INFO - Iter(train) [154300/160000]  base_lr: 4.9726e-06 lr: 4.9726e-07  eta: 0:39:21  time: 0.4187  data_time: 0.0100  memory: 5971  grad_norm: 551.1232  loss: 21.8784  decode.loss_cls: 0.2178  decode.loss_mask: 1.1026  decode.loss_dice: 0.7918  decode.d0.loss_cls: 0.6760  decode.d0.loss_mask: 1.1432  decode.d0.loss_dice: 0.8778  decode.d1.loss_cls: 0.1814  decode.d1.loss_mask: 1.1828  decode.d1.loss_dice: 0.8214  decode.d2.loss_cls: 0.2221  decode.d2.loss_mask: 1.1184  decode.d2.loss_dice: 0.8144  decode.d3.loss_cls: 0.2097  decode.d3.loss_mask: 1.0972  decode.d3.loss_dice: 0.8027  decode.d4.loss_cls: 0.1848  decode.d4.loss_mask: 1.1129  decode.d4.loss_dice: 0.8059  decode.d5.loss_cls: 0.2084  decode.d5.loss_mask: 1.1107  decode.d5.loss_dice: 0.7929  decode.d6.loss_cls: 0.2287  decode.d6.loss_mask: 1.1137  decode.d6.loss_dice: 0.8033  decode.d7.loss_cls: 0.2360  decode.d7.loss_mask: 1.1090  decode.d7.loss_dice: 0.7818  decode.d8.loss_cls: 0.1844  decode.d8.loss_mask: 1.1204  decode.d8.loss_dice: 0.8261
05/27 05:17:17 - mmengine - INFO - Iter(train) [154350/160000]  base_lr: 4.9333e-06 lr: 4.9333e-07  eta: 0:39:01  time: 0.4198  data_time: 0.0100  memory: 5980  grad_norm: 527.6158  loss: 16.1446  decode.loss_cls: 0.1581  decode.loss_mask: 0.8511  decode.loss_dice: 0.5666  decode.d0.loss_cls: 0.6262  decode.d0.loss_mask: 0.8326  decode.d0.loss_dice: 0.5543  decode.d1.loss_cls: 0.1547  decode.d1.loss_mask: 0.8516  decode.d1.loss_dice: 0.5596  decode.d2.loss_cls: 0.1612  decode.d2.loss_mask: 0.8363  decode.d2.loss_dice: 0.5522  decode.d3.loss_cls: 0.1674  decode.d3.loss_mask: 0.8402  decode.d3.loss_dice: 0.5562  decode.d4.loss_cls: 0.1785  decode.d4.loss_mask: 0.8419  decode.d4.loss_dice: 0.5586  decode.d5.loss_cls: 0.1661  decode.d5.loss_mask: 0.8485  decode.d5.loss_dice: 0.5610  decode.d6.loss_cls: 0.1614  decode.d6.loss_mask: 0.8506  decode.d6.loss_dice: 0.5593  decode.d7.loss_cls: 0.1644  decode.d7.loss_mask: 0.8540  decode.d7.loss_dice: 0.5676  decode.d8.loss_cls: 0.1502  decode.d8.loss_mask: 0.8482  decode.d8.loss_dice: 0.5662
05/27 05:17:38 - mmengine - INFO - Iter(train) [154400/160000]  base_lr: 4.8940e-06 lr: 4.8940e-07  eta: 0:38:40  time: 0.4196  data_time: 0.0101  memory: 5969  grad_norm: 467.2025  loss: 17.0319  decode.loss_cls: 0.0624  decode.loss_mask: 0.9351  decode.loss_dice: 0.6559  decode.d0.loss_cls: 0.4800  decode.d0.loss_mask: 0.8783  decode.d0.loss_dice: 0.6486  decode.d1.loss_cls: 0.0750  decode.d1.loss_mask: 0.9326  decode.d1.loss_dice: 0.6583  decode.d2.loss_cls: 0.0877  decode.d2.loss_mask: 0.9305  decode.d2.loss_dice: 0.6504  decode.d3.loss_cls: 0.0750  decode.d3.loss_mask: 0.9374  decode.d3.loss_dice: 0.6484  decode.d4.loss_cls: 0.0820  decode.d4.loss_mask: 0.9407  decode.d4.loss_dice: 0.6518  decode.d5.loss_cls: 0.0981  decode.d5.loss_mask: 0.9336  decode.d5.loss_dice: 0.6721  decode.d6.loss_cls: 0.0761  decode.d6.loss_mask: 0.9314  decode.d6.loss_dice: 0.6503  decode.d7.loss_cls: 0.0840  decode.d7.loss_mask: 0.9207  decode.d7.loss_dice: 0.6350  decode.d8.loss_cls: 0.0917  decode.d8.loss_mask: 0.9330  decode.d8.loss_dice: 0.6758
05/27 05:17:59 - mmengine - INFO - Iter(train) [154450/160000]  base_lr: 4.8547e-06 lr: 4.8547e-07  eta: 0:38:19  time: 0.4192  data_time: 0.0101  memory: 5976  grad_norm: 330.6153  loss: 17.7244  decode.loss_cls: 0.0861  decode.loss_mask: 0.9752  decode.loss_dice: 0.6635  decode.d0.loss_cls: 0.6267  decode.d0.loss_mask: 0.9183  decode.d0.loss_dice: 0.6570  decode.d1.loss_cls: 0.0986  decode.d1.loss_mask: 0.9832  decode.d1.loss_dice: 0.6625  decode.d2.loss_cls: 0.0876  decode.d2.loss_mask: 0.9762  decode.d2.loss_dice: 0.6579  decode.d3.loss_cls: 0.0913  decode.d3.loss_mask: 0.9749  decode.d3.loss_dice: 0.6705  decode.d4.loss_cls: 0.0817  decode.d4.loss_mask: 0.9655  decode.d4.loss_dice: 0.6628  decode.d5.loss_cls: 0.0880  decode.d5.loss_mask: 0.9696  decode.d5.loss_dice: 0.6595  decode.d6.loss_cls: 0.0942  decode.d6.loss_mask: 0.9691  decode.d6.loss_dice: 0.6634  decode.d7.loss_cls: 0.0876  decode.d7.loss_mask: 0.9675  decode.d7.loss_dice: 0.6576  decode.d8.loss_cls: 0.0851  decode.d8.loss_mask: 0.9750  decode.d8.loss_dice: 0.6687
05/27 05:18:20 - mmengine - INFO - Iter(train) [154500/160000]  base_lr: 4.8153e-06 lr: 4.8153e-07  eta: 0:37:58  time: 0.4202  data_time: 0.0100  memory: 5977  grad_norm: 421.0464  loss: 18.0846  decode.loss_cls: 0.1392  decode.loss_mask: 0.9363  decode.loss_dice: 0.6572  decode.d0.loss_cls: 0.7044  decode.d0.loss_mask: 0.9087  decode.d0.loss_dice: 0.6518  decode.d1.loss_cls: 0.1530  decode.d1.loss_mask: 0.9581  decode.d1.loss_dice: 0.6459  decode.d2.loss_cls: 0.1621  decode.d2.loss_mask: 0.9674  decode.d2.loss_dice: 0.6683  decode.d3.loss_cls: 0.1616  decode.d3.loss_mask: 0.9589  decode.d3.loss_dice: 0.6629  decode.d4.loss_cls: 0.1464  decode.d4.loss_mask: 0.9601  decode.d4.loss_dice: 0.6712  decode.d5.loss_cls: 0.1590  decode.d5.loss_mask: 0.9413  decode.d5.loss_dice: 0.6478  decode.d6.loss_cls: 0.1484  decode.d6.loss_mask: 0.9648  decode.d6.loss_dice: 0.6563  decode.d7.loss_cls: 0.1535  decode.d7.loss_mask: 0.9355  decode.d7.loss_dice: 0.6370  decode.d8.loss_cls: 0.1433  decode.d8.loss_mask: 0.9416  decode.d8.loss_dice: 0.6426
05/27 05:18:41 - mmengine - INFO - Iter(train) [154550/160000]  base_lr: 4.7759e-06 lr: 4.7759e-07  eta: 0:37:38  time: 0.4191  data_time: 0.0101  memory: 5967  grad_norm: 567.5500  loss: 15.0754  decode.loss_cls: 0.2016  decode.loss_mask: 0.6673  decode.loss_dice: 0.5816  decode.d0.loss_cls: 0.5551  decode.d0.loss_mask: 0.6605  decode.d0.loss_dice: 0.6111  decode.d1.loss_cls: 0.1964  decode.d1.loss_mask: 0.6715  decode.d1.loss_dice: 0.6128  decode.d2.loss_cls: 0.1859  decode.d2.loss_mask: 0.6981  decode.d2.loss_dice: 0.6128  decode.d3.loss_cls: 0.1880  decode.d3.loss_mask: 0.6818  decode.d3.loss_dice: 0.5699  decode.d4.loss_cls: 0.1966  decode.d4.loss_mask: 0.6622  decode.d4.loss_dice: 0.6032  decode.d5.loss_cls: 0.1712  decode.d5.loss_mask: 0.6791  decode.d5.loss_dice: 0.6064  decode.d6.loss_cls: 0.1994  decode.d6.loss_mask: 0.6803  decode.d6.loss_dice: 0.6117  decode.d7.loss_cls: 0.2126  decode.d7.loss_mask: 0.6548  decode.d7.loss_dice: 0.6125  decode.d8.loss_cls: 0.1946  decode.d8.loss_mask: 0.6840  decode.d8.loss_dice: 0.6125
05/27 05:19:02 - mmengine - INFO - Iter(train) [154600/160000]  base_lr: 4.7364e-06 lr: 4.7364e-07  eta: 0:37:17  time: 0.4192  data_time: 0.0100  memory: 5966  grad_norm: 558.6459  loss: 16.4077  decode.loss_cls: 0.1217  decode.loss_mask: 0.8603  decode.loss_dice: 0.6120  decode.d0.loss_cls: 0.7199  decode.d0.loss_mask: 0.7722  decode.d0.loss_dice: 0.5698  decode.d1.loss_cls: 0.1517  decode.d1.loss_mask: 0.8569  decode.d1.loss_dice: 0.6081  decode.d2.loss_cls: 0.1613  decode.d2.loss_mask: 0.8583  decode.d2.loss_dice: 0.5823  decode.d3.loss_cls: 0.1525  decode.d3.loss_mask: 0.8363  decode.d3.loss_dice: 0.6050  decode.d4.loss_cls: 0.1587  decode.d4.loss_mask: 0.8449  decode.d4.loss_dice: 0.5917  decode.d5.loss_cls: 0.1452  decode.d5.loss_mask: 0.8469  decode.d5.loss_dice: 0.5922  decode.d6.loss_cls: 0.1469  decode.d6.loss_mask: 0.8680  decode.d6.loss_dice: 0.5975  decode.d7.loss_cls: 0.1371  decode.d7.loss_mask: 0.8545  decode.d7.loss_dice: 0.5830  decode.d8.loss_cls: 0.1272  decode.d8.loss_mask: 0.8480  decode.d8.loss_dice: 0.5975
05/27 05:19:23 - mmengine - INFO - Iter(train) [154650/160000]  base_lr: 4.6969e-06 lr: 4.6969e-07  eta: 0:36:56  time: 0.4189  data_time: 0.0100  memory: 5969  grad_norm: 240.6535  loss: 15.5332  decode.loss_cls: 0.1424  decode.loss_mask: 0.7700  decode.loss_dice: 0.5683  decode.d0.loss_cls: 0.5335  decode.d0.loss_mask: 0.7935  decode.d0.loss_dice: 0.5762  decode.d1.loss_cls: 0.1637  decode.d1.loss_mask: 0.8293  decode.d1.loss_dice: 0.5816  decode.d2.loss_cls: 0.1755  decode.d2.loss_mask: 0.7614  decode.d2.loss_dice: 0.5546  decode.d3.loss_cls: 0.1373  decode.d3.loss_mask: 0.7961  decode.d3.loss_dice: 0.5481  decode.d4.loss_cls: 0.1481  decode.d4.loss_mask: 0.7971  decode.d4.loss_dice: 0.5559  decode.d5.loss_cls: 0.1843  decode.d5.loss_mask: 0.7646  decode.d5.loss_dice: 0.5599  decode.d6.loss_cls: 0.2016  decode.d6.loss_mask: 0.7788  decode.d6.loss_dice: 0.5662  decode.d7.loss_cls: 0.1613  decode.d7.loss_mask: 0.8069  decode.d7.loss_dice: 0.5456  decode.d8.loss_cls: 0.1817  decode.d8.loss_mask: 0.7810  decode.d8.loss_dice: 0.5690
05/27 05:19:44 - mmengine - INFO - Iter(train) [154700/160000]  base_lr: 4.6574e-06 lr: 4.6574e-07  eta: 0:36:36  time: 0.4195  data_time: 0.0101  memory: 5971  grad_norm: 319.2353  loss: 14.6722  decode.loss_cls: 0.0503  decode.loss_mask: 0.8220  decode.loss_dice: 0.5504  decode.d0.loss_cls: 0.5049  decode.d0.loss_mask: 0.8057  decode.d0.loss_dice: 0.5592  decode.d1.loss_cls: 0.0492  decode.d1.loss_mask: 0.8212  decode.d1.loss_dice: 0.5563  decode.d2.loss_cls: 0.0488  decode.d2.loss_mask: 0.8245  decode.d2.loss_dice: 0.5538  decode.d3.loss_cls: 0.0440  decode.d3.loss_mask: 0.8192  decode.d3.loss_dice: 0.5509  decode.d4.loss_cls: 0.0654  decode.d4.loss_mask: 0.8262  decode.d4.loss_dice: 0.5429  decode.d5.loss_cls: 0.0502  decode.d5.loss_mask: 0.8199  decode.d5.loss_dice: 0.5427  decode.d6.loss_cls: 0.0539  decode.d6.loss_mask: 0.8251  decode.d6.loss_dice: 0.5429  decode.d7.loss_cls: 0.0708  decode.d7.loss_mask: 0.8150  decode.d7.loss_dice: 0.5378  decode.d8.loss_cls: 0.0567  decode.d8.loss_mask: 0.8187  decode.d8.loss_dice: 0.5437
05/27 05:20:05 - mmengine - INFO - Iter(train) [154750/160000]  base_lr: 4.6178e-06 lr: 4.6178e-07  eta: 0:36:15  time: 0.4195  data_time: 0.0100  memory: 5973  grad_norm: 343.8911  loss: 17.6363  decode.loss_cls: 0.2177  decode.loss_mask: 0.8196  decode.loss_dice: 0.6861  decode.d0.loss_cls: 0.7271  decode.d0.loss_mask: 0.8034  decode.d0.loss_dice: 0.6882  decode.d1.loss_cls: 0.2204  decode.d1.loss_mask: 0.7880  decode.d1.loss_dice: 0.6797  decode.d2.loss_cls: 0.2131  decode.d2.loss_mask: 0.8157  decode.d2.loss_dice: 0.6835  decode.d3.loss_cls: 0.2382  decode.d3.loss_mask: 0.7639  decode.d3.loss_dice: 0.6536  decode.d4.loss_cls: 0.2194  decode.d4.loss_mask: 0.7856  decode.d4.loss_dice: 0.6640  decode.d5.loss_cls: 0.2345  decode.d5.loss_mask: 0.7935  decode.d5.loss_dice: 0.6769  decode.d6.loss_cls: 0.2215  decode.d6.loss_mask: 0.8242  decode.d6.loss_dice: 0.6894  decode.d7.loss_cls: 0.2003  decode.d7.loss_mask: 0.8558  decode.d7.loss_dice: 0.7076  decode.d8.loss_cls: 0.2169  decode.d8.loss_mask: 0.8533  decode.d8.loss_dice: 0.6953
05/27 05:20:26 - mmengine - INFO - Iter(train) [154800/160000]  base_lr: 4.5782e-06 lr: 4.5782e-07  eta: 0:35:54  time: 0.4190  data_time: 0.0101  memory: 5967  grad_norm: 294.7857  loss: 17.4442  decode.loss_cls: 0.1146  decode.loss_mask: 0.8428  decode.loss_dice: 0.7176  decode.d0.loss_cls: 0.6507  decode.d0.loss_mask: 0.8441  decode.d0.loss_dice: 0.7180  decode.d1.loss_cls: 0.1220  decode.d1.loss_mask: 0.8500  decode.d1.loss_dice: 0.7177  decode.d2.loss_cls: 0.1619  decode.d2.loss_mask: 0.8313  decode.d2.loss_dice: 0.6899  decode.d3.loss_cls: 0.1624  decode.d3.loss_mask: 0.8399  decode.d3.loss_dice: 0.6965  decode.d4.loss_cls: 0.1599  decode.d4.loss_mask: 0.8363  decode.d4.loss_dice: 0.7103  decode.d5.loss_cls: 0.1641  decode.d5.loss_mask: 0.8317  decode.d5.loss_dice: 0.6989  decode.d6.loss_cls: 0.1581  decode.d6.loss_mask: 0.8334  decode.d6.loss_dice: 0.7075  decode.d7.loss_cls: 0.1572  decode.d7.loss_mask: 0.8448  decode.d7.loss_dice: 0.7143  decode.d8.loss_cls: 0.1554  decode.d8.loss_mask: 0.8275  decode.d8.loss_dice: 0.6855
05/27 05:20:47 - mmengine - INFO - Iter(train) [154850/160000]  base_lr: 4.5386e-06 lr: 4.5386e-07  eta: 0:35:33  time: 0.4190  data_time: 0.0101  memory: 5972  grad_norm: 368.2198  loss: 15.7730  decode.loss_cls: 0.0975  decode.loss_mask: 0.8500  decode.loss_dice: 0.5702  decode.d0.loss_cls: 0.5475  decode.d0.loss_mask: 0.8311  decode.d0.loss_dice: 0.5665  decode.d1.loss_cls: 0.1266  decode.d1.loss_mask: 0.8586  decode.d1.loss_dice: 0.5738  decode.d2.loss_cls: 0.1160  decode.d2.loss_mask: 0.8581  decode.d2.loss_dice: 0.5781  decode.d3.loss_cls: 0.0945  decode.d3.loss_mask: 0.8478  decode.d3.loss_dice: 0.5733  decode.d4.loss_cls: 0.1211  decode.d4.loss_mask: 0.8526  decode.d4.loss_dice: 0.5748  decode.d5.loss_cls: 0.1065  decode.d5.loss_mask: 0.8539  decode.d5.loss_dice: 0.5727  decode.d6.loss_cls: 0.1019  decode.d6.loss_mask: 0.8577  decode.d6.loss_dice: 0.5750  decode.d7.loss_cls: 0.0925  decode.d7.loss_mask: 0.8580  decode.d7.loss_dice: 0.5762  decode.d8.loss_cls: 0.1086  decode.d8.loss_mask: 0.8577  decode.d8.loss_dice: 0.5743
05/27 05:21:08 - mmengine - INFO - Iter(train) [154900/160000]  base_lr: 4.4989e-06 lr: 4.4989e-07  eta: 0:35:13  time: 0.4196  data_time: 0.0101  memory: 5972  grad_norm: 173.1145  loss: 14.0765  decode.loss_cls: 0.0735  decode.loss_mask: 0.7702  decode.loss_dice: 0.5306  decode.d0.loss_cls: 0.4588  decode.d0.loss_mask: 0.7899  decode.d0.loss_dice: 0.5364  decode.d1.loss_cls: 0.0696  decode.d1.loss_mask: 0.7561  decode.d1.loss_dice: 0.5328  decode.d2.loss_cls: 0.0779  decode.d2.loss_mask: 0.7580  decode.d2.loss_dice: 0.5317  decode.d3.loss_cls: 0.0813  decode.d3.loss_mask: 0.7641  decode.d3.loss_dice: 0.5297  decode.d4.loss_cls: 0.0809  decode.d4.loss_mask: 0.7525  decode.d4.loss_dice: 0.5271  decode.d5.loss_cls: 0.0776  decode.d5.loss_mask: 0.7586  decode.d5.loss_dice: 0.5337  decode.d6.loss_cls: 0.0730  decode.d6.loss_mask: 0.7609  decode.d6.loss_dice: 0.5245  decode.d7.loss_cls: 0.0766  decode.d7.loss_mask: 0.7618  decode.d7.loss_dice: 0.5273  decode.d8.loss_cls: 0.0709  decode.d8.loss_mask: 0.7661  decode.d8.loss_dice: 0.5244
05/27 05:21:29 - mmengine - INFO - Iter(train) [154950/160000]  base_lr: 4.4592e-06 lr: 4.4592e-07  eta: 0:34:52  time: 0.4185  data_time: 0.0101  memory: 5975  grad_norm: 395.8678  loss: 16.2569  decode.loss_cls: 0.0947  decode.loss_mask: 0.8952  decode.loss_dice: 0.5830  decode.d0.loss_cls: 0.5609  decode.d0.loss_mask: 0.9317  decode.d0.loss_dice: 0.5791  decode.d1.loss_cls: 0.1012  decode.d1.loss_mask: 0.9193  decode.d1.loss_dice: 0.5944  decode.d2.loss_cls: 0.1045  decode.d2.loss_mask: 0.9207  decode.d2.loss_dice: 0.5809  decode.d3.loss_cls: 0.1205  decode.d3.loss_mask: 0.8768  decode.d3.loss_dice: 0.5734  decode.d4.loss_cls: 0.1124  decode.d4.loss_mask: 0.8680  decode.d4.loss_dice: 0.5689  decode.d5.loss_cls: 0.1068  decode.d5.loss_mask: 0.8617  decode.d5.loss_dice: 0.5518  decode.d6.loss_cls: 0.0895  decode.d6.loss_mask: 0.9089  decode.d6.loss_dice: 0.5879  decode.d7.loss_cls: 0.1005  decode.d7.loss_mask: 0.9035  decode.d7.loss_dice: 0.5949  decode.d8.loss_cls: 0.0960  decode.d8.loss_mask: 0.8906  decode.d8.loss_dice: 0.5793
05/27 05:21:50 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 05:21:50 - mmengine - INFO - Iter(train) [155000/160000]  base_lr: 4.4194e-06 lr: 4.4194e-07  eta: 0:34:31  time: 0.4210  data_time: 0.0101  memory: 5981  grad_norm: 388.7764  loss: 15.3303  decode.loss_cls: 0.1146  decode.loss_mask: 0.7383  decode.loss_dice: 0.6212  decode.d0.loss_cls: 0.6261  decode.d0.loss_mask: 0.7055  decode.d0.loss_dice: 0.6136  decode.d1.loss_cls: 0.1494  decode.d1.loss_mask: 0.7223  decode.d1.loss_dice: 0.6135  decode.d2.loss_cls: 0.1724  decode.d2.loss_mask: 0.7244  decode.d2.loss_dice: 0.6246  decode.d3.loss_cls: 0.1243  decode.d3.loss_mask: 0.7268  decode.d3.loss_dice: 0.6096  decode.d4.loss_cls: 0.1505  decode.d4.loss_mask: 0.7268  decode.d4.loss_dice: 0.6045  decode.d5.loss_cls: 0.1452  decode.d5.loss_mask: 0.7274  decode.d5.loss_dice: 0.6125  decode.d6.loss_cls: 0.1591  decode.d6.loss_mask: 0.7323  decode.d6.loss_dice: 0.6236  decode.d7.loss_cls: 0.1575  decode.d7.loss_mask: 0.7196  decode.d7.loss_dice: 0.6039  decode.d8.loss_cls: 0.1288  decode.d8.loss_mask: 0.7311  decode.d8.loss_dice: 0.6208
05/27 05:21:50 - mmengine - INFO - Saving checkpoint at 155000 iterations
05/27 05:21:55 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:07  time: 0.0480  data_time: 0.0012  memory: 1391  
05/27 05:21:57 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:05  time: 0.0476  data_time: 0.0013  memory: 1205  
05/27 05:22:00 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:03  time: 0.0502  data_time: 0.0012  memory: 1596  
05/27 05:22:02 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0484  data_time: 0.0012  memory: 1298  
05/27 05:22:05 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:57  time: 0.0476  data_time: 0.0012  memory: 1298  
05/27 05:22:07 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0487  data_time: 0.0013  memory: 1279  
05/27 05:22:09 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:52  time: 0.0478  data_time: 0.0012  memory: 1224  
05/27 05:22:12 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0488  data_time: 0.0013  memory: 1298  
05/27 05:22:14 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0474  data_time: 0.0012  memory: 1298  
05/27 05:22:17 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0512  data_time: 0.0012  memory: 1725  
05/27 05:22:19 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0479  data_time: 0.0012  memory: 1336  
05/27 05:22:21 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0480  data_time: 0.0012  memory: 1298  
05/27 05:22:24 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0483  data_time: 0.0012  memory: 1205  
05/27 05:22:26 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0488  data_time: 0.0012  memory: 1316  
05/27 05:22:29 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0476  data_time: 0.0013  memory: 1279  
05/27 05:22:31 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0513  data_time: 0.0012  memory: 1410  
05/27 05:22:34 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0477  data_time: 0.0012  memory: 1279  
05/27 05:22:36 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0486  data_time: 0.0012  memory: 1205  
05/27 05:22:38 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0484  data_time: 0.0012  memory: 1205  
05/27 05:22:41 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0478  data_time: 0.0012  memory: 1336  
05/27 05:22:43 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0478  data_time: 0.0013  memory: 1246  
05/27 05:22:46 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0498  data_time: 0.0012  memory: 1503  
05/27 05:22:48 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0479  data_time: 0.0012  memory: 1261  
05/27 05:22:50 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0485  data_time: 0.0012  memory: 1298  
05/27 05:22:53 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0477  data_time: 0.0012  memory: 1447  
05/27 05:22:55 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0476  data_time: 0.0012  memory: 1298  
05/27 05:22:58 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0490  data_time: 0.0012  memory: 1279  
05/27 05:23:00 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0477  data_time: 0.0013  memory: 1205  
05/27 05:23:02 - mmengine - INFO - per class results:
05/27 05:23:02 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.83 | 97.51 |
|  aeroplane  |  92.2 | 96.17 |
|   bicycle   | 45.11 | 97.09 |
|     bird    | 94.61 | 98.52 |
|     boat    | 66.77 | 93.05 |
|    bottle   | 84.99 | 95.06 |
|     bus     | 96.04 | 98.16 |
|     car     |  91.3 |  95.0 |
|     cat     | 95.71 | 98.15 |
|    chair    | 43.06 | 70.62 |
|     cow     | 90.83 |  97.4 |
| diningtable | 65.16 | 68.94 |
|     dog     | 91.86 | 98.57 |
|    horse    | 90.62 | 94.94 |
|  motorbike  | 92.42 | 96.62 |
|    person   | 90.76 | 94.84 |
| pottedplant | 73.15 | 91.13 |
|    sheep    | 89.01 | 92.34 |
|     sofa    | 54.08 | 63.23 |
|    train    | 90.52 | 96.54 |
|  tvmonitor  | 84.06 | 86.92 |
+-------------+-------+-------+
05/27 05:23:02 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 96.0700  mIoU: 81.8100  mAcc: 91.4700  data_time: 0.0013  time: 0.0481
05/27 05:23:23 - mmengine - INFO - Iter(train) [155050/160000]  base_lr: 4.3796e-06 lr: 4.3796e-07  eta: 0:34:11  time: 0.4187  data_time: 0.0102  memory: 5975  grad_norm: 420.7761  loss: 16.6355  decode.loss_cls: 0.1054  decode.loss_mask: 0.8965  decode.loss_dice: 0.6181  decode.d0.loss_cls: 0.6374  decode.d0.loss_mask: 0.8438  decode.d0.loss_dice: 0.6098  decode.d1.loss_cls: 0.0932  decode.d1.loss_mask: 0.9070  decode.d1.loss_dice: 0.6284  decode.d2.loss_cls: 0.1232  decode.d2.loss_mask: 0.8643  decode.d2.loss_dice: 0.5994  decode.d3.loss_cls: 0.1196  decode.d3.loss_mask: 0.8953  decode.d3.loss_dice: 0.5977  decode.d4.loss_cls: 0.0951  decode.d4.loss_mask: 0.8985  decode.d4.loss_dice: 0.6027  decode.d5.loss_cls: 0.1028  decode.d5.loss_mask: 0.9191  decode.d5.loss_dice: 0.6378  decode.d6.loss_cls: 0.1308  decode.d6.loss_mask: 0.8415  decode.d6.loss_dice: 0.5937  decode.d7.loss_cls: 0.1146  decode.d7.loss_mask: 0.9038  decode.d7.loss_dice: 0.6273  decode.d8.loss_cls: 0.1027  decode.d8.loss_mask: 0.9079  decode.d8.loss_dice: 0.6180
05/27 05:23:44 - mmengine - INFO - Iter(train) [155100/160000]  base_lr: 4.3398e-06 lr: 4.3398e-07  eta: 0:33:50  time: 0.4189  data_time: 0.0101  memory: 5976  grad_norm: 450.6711  loss: 17.9442  decode.loss_cls: 0.1290  decode.loss_mask: 0.9018  decode.loss_dice: 0.7091  decode.d0.loss_cls: 0.7435  decode.d0.loss_mask: 0.8649  decode.d0.loss_dice: 0.6902  decode.d1.loss_cls: 0.1218  decode.d1.loss_mask: 0.9083  decode.d1.loss_dice: 0.7075  decode.d2.loss_cls: 0.1236  decode.d2.loss_mask: 0.8974  decode.d2.loss_dice: 0.7181  decode.d3.loss_cls: 0.1299  decode.d3.loss_mask: 0.8957  decode.d3.loss_dice: 0.7090  decode.d4.loss_cls: 0.1292  decode.d4.loss_mask: 0.9153  decode.d4.loss_dice: 0.7048  decode.d5.loss_cls: 0.1324  decode.d5.loss_mask: 0.9073  decode.d5.loss_dice: 0.7024  decode.d6.loss_cls: 0.1262  decode.d6.loss_mask: 0.8952  decode.d6.loss_dice: 0.7024  decode.d7.loss_cls: 0.1144  decode.d7.loss_mask: 0.9097  decode.d7.loss_dice: 0.7061  decode.d8.loss_cls: 0.1317  decode.d8.loss_mask: 0.9062  decode.d8.loss_dice: 0.7111
05/27 05:24:05 - mmengine - INFO - Iter(train) [155150/160000]  base_lr: 4.2999e-06 lr: 4.2999e-07  eta: 0:33:29  time: 0.4187  data_time: 0.0100  memory: 5981  grad_norm: 419.4807  loss: 16.9473  decode.loss_cls: 0.1698  decode.loss_mask: 0.8240  decode.loss_dice: 0.6515  decode.d0.loss_cls: 0.6118  decode.d0.loss_mask: 0.8287  decode.d0.loss_dice: 0.6642  decode.d1.loss_cls: 0.1961  decode.d1.loss_mask: 0.7970  decode.d1.loss_dice: 0.6461  decode.d2.loss_cls: 0.1664  decode.d2.loss_mask: 0.8049  decode.d2.loss_dice: 0.6669  decode.d3.loss_cls: 0.1754  decode.d3.loss_mask: 0.8117  decode.d3.loss_dice: 0.6788  decode.d4.loss_cls: 0.1815  decode.d4.loss_mask: 0.8029  decode.d4.loss_dice: 0.6547  decode.d5.loss_cls: 0.1909  decode.d5.loss_mask: 0.8054  decode.d5.loss_dice: 0.6519  decode.d6.loss_cls: 0.1849  decode.d6.loss_mask: 0.8052  decode.d6.loss_dice: 0.6593  decode.d7.loss_cls: 0.1776  decode.d7.loss_mask: 0.8127  decode.d7.loss_dice: 0.6731  decode.d8.loss_cls: 0.1969  decode.d8.loss_mask: 0.8008  decode.d8.loss_dice: 0.6561
05/27 05:24:26 - mmengine - INFO - Iter(train) [155200/160000]  base_lr: 4.2600e-06 lr: 4.2600e-07  eta: 0:33:08  time: 0.4184  data_time: 0.0101  memory: 5969  grad_norm: 366.6592  loss: 15.9809  decode.loss_cls: 0.0376  decode.loss_mask: 0.9007  decode.loss_dice: 0.5954  decode.d0.loss_cls: 0.4648  decode.d0.loss_mask: 0.9545  decode.d0.loss_dice: 0.6143  decode.d1.loss_cls: 0.0893  decode.d1.loss_mask: 0.9182  decode.d1.loss_dice: 0.5962  decode.d2.loss_cls: 0.0616  decode.d2.loss_mask: 0.9115  decode.d2.loss_dice: 0.5907  decode.d3.loss_cls: 0.0428  decode.d3.loss_mask: 0.9117  decode.d3.loss_dice: 0.5997  decode.d4.loss_cls: 0.0476  decode.d4.loss_mask: 0.9040  decode.d4.loss_dice: 0.5878  decode.d5.loss_cls: 0.0404  decode.d5.loss_mask: 0.9080  decode.d5.loss_dice: 0.5863  decode.d6.loss_cls: 0.0424  decode.d6.loss_mask: 0.8978  decode.d6.loss_dice: 0.5892  decode.d7.loss_cls: 0.0364  decode.d7.loss_mask: 0.9122  decode.d7.loss_dice: 0.5980  decode.d8.loss_cls: 0.0380  decode.d8.loss_mask: 0.9088  decode.d8.loss_dice: 0.5952
05/27 05:24:47 - mmengine - INFO - Iter(train) [155250/160000]  base_lr: 4.2201e-06 lr: 4.2201e-07  eta: 0:32:48  time: 0.4191  data_time: 0.0101  memory: 5976  grad_norm: 317.4636  loss: 15.9635  decode.loss_cls: 0.0964  decode.loss_mask: 0.8933  decode.loss_dice: 0.5739  decode.d0.loss_cls: 0.5567  decode.d0.loss_mask: 0.8997  decode.d0.loss_dice: 0.5964  decode.d1.loss_cls: 0.0838  decode.d1.loss_mask: 0.9012  decode.d1.loss_dice: 0.5674  decode.d2.loss_cls: 0.0781  decode.d2.loss_mask: 0.8984  decode.d2.loss_dice: 0.5615  decode.d3.loss_cls: 0.0659  decode.d3.loss_mask: 0.8994  decode.d3.loss_dice: 0.5630  decode.d4.loss_cls: 0.0663  decode.d4.loss_mask: 0.8970  decode.d4.loss_dice: 0.5627  decode.d5.loss_cls: 0.0656  decode.d5.loss_mask: 0.9080  decode.d5.loss_dice: 0.5668  decode.d6.loss_cls: 0.0848  decode.d6.loss_mask: 0.8952  decode.d6.loss_dice: 0.5672  decode.d7.loss_cls: 0.0998  decode.d7.loss_mask: 0.9111  decode.d7.loss_dice: 0.5711  decode.d8.loss_cls: 0.0687  decode.d8.loss_mask: 0.9034  decode.d8.loss_dice: 0.5606
05/27 05:25:08 - mmengine - INFO - Iter(train) [155300/160000]  base_lr: 4.1801e-06 lr: 4.1801e-07  eta: 0:32:27  time: 0.4208  data_time: 0.0110  memory: 5979  grad_norm: 750.2977  loss: 17.9187  decode.loss_cls: 0.2003  decode.loss_mask: 0.8290  decode.loss_dice: 0.6916  decode.d0.loss_cls: 0.6298  decode.d0.loss_mask: 0.8194  decode.d0.loss_dice: 0.6375  decode.d1.loss_cls: 0.2086  decode.d1.loss_mask: 0.8512  decode.d1.loss_dice: 0.7091  decode.d2.loss_cls: 0.1963  decode.d2.loss_mask: 0.8439  decode.d2.loss_dice: 0.7089  decode.d3.loss_cls: 0.2083  decode.d3.loss_mask: 0.8531  decode.d3.loss_dice: 0.7097  decode.d4.loss_cls: 0.2021  decode.d4.loss_mask: 0.8457  decode.d4.loss_dice: 0.7130  decode.d5.loss_cls: 0.2062  decode.d5.loss_mask: 0.8399  decode.d5.loss_dice: 0.7222  decode.d6.loss_cls: 0.2295  decode.d6.loss_mask: 0.8364  decode.d6.loss_dice: 0.6914  decode.d7.loss_cls: 0.2229  decode.d7.loss_mask: 0.8319  decode.d7.loss_dice: 0.7175  decode.d8.loss_cls: 0.2046  decode.d8.loss_mask: 0.8418  decode.d8.loss_dice: 0.7169
05/27 05:25:29 - mmengine - INFO - Iter(train) [155350/160000]  base_lr: 4.1400e-06 lr: 4.1400e-07  eta: 0:32:06  time: 0.4199  data_time: 0.0102  memory: 5970  grad_norm: 550.3085  loss: 21.5568  decode.loss_cls: 0.2156  decode.loss_mask: 1.0935  decode.loss_dice: 0.7474  decode.d0.loss_cls: 0.7408  decode.d0.loss_mask: 1.1131  decode.d0.loss_dice: 0.7308  decode.d1.loss_cls: 0.2497  decode.d1.loss_mask: 1.1565  decode.d1.loss_dice: 0.7710  decode.d2.loss_cls: 0.2176  decode.d2.loss_mask: 1.1328  decode.d2.loss_dice: 0.7658  decode.d3.loss_cls: 0.2155  decode.d3.loss_mask: 1.1481  decode.d3.loss_dice: 0.7651  decode.d4.loss_cls: 0.2343  decode.d4.loss_mask: 1.1367  decode.d4.loss_dice: 0.7537  decode.d5.loss_cls: 0.1934  decode.d5.loss_mask: 1.1507  decode.d5.loss_dice: 0.7622  decode.d6.loss_cls: 0.1900  decode.d6.loss_mask: 1.1369  decode.d6.loss_dice: 0.7626  decode.d7.loss_cls: 0.2366  decode.d7.loss_mask: 1.1080  decode.d7.loss_dice: 0.7444  decode.d8.loss_cls: 0.2140  decode.d8.loss_mask: 1.1209  decode.d8.loss_dice: 0.7489
05/27 05:25:50 - mmengine - INFO - Iter(train) [155400/160000]  base_lr: 4.0999e-06 lr: 4.0999e-07  eta: 0:31:46  time: 0.4190  data_time: 0.0101  memory: 5967  grad_norm: 355.3812  loss: 15.2058  decode.loss_cls: 0.1090  decode.loss_mask: 0.7867  decode.loss_dice: 0.5618  decode.d0.loss_cls: 0.4652  decode.d0.loss_mask: 0.8222  decode.d0.loss_dice: 0.5875  decode.d1.loss_cls: 0.1099  decode.d1.loss_mask: 0.7900  decode.d1.loss_dice: 0.5715  decode.d2.loss_cls: 0.1145  decode.d2.loss_mask: 0.7996  decode.d2.loss_dice: 0.5749  decode.d3.loss_cls: 0.1027  decode.d3.loss_mask: 0.8143  decode.d3.loss_dice: 0.5748  decode.d4.loss_cls: 0.1044  decode.d4.loss_mask: 0.8126  decode.d4.loss_dice: 0.5807  decode.d5.loss_cls: 0.1006  decode.d5.loss_mask: 0.8063  decode.d5.loss_dice: 0.5765  decode.d6.loss_cls: 0.1029  decode.d6.loss_mask: 0.7992  decode.d6.loss_dice: 0.5689  decode.d7.loss_cls: 0.0695  decode.d7.loss_mask: 0.8208  decode.d7.loss_dice: 0.6135  decode.d8.loss_cls: 0.1001  decode.d8.loss_mask: 0.7970  decode.d8.loss_dice: 0.5682
05/27 05:26:11 - mmengine - INFO - Iter(train) [155450/160000]  base_lr: 4.0598e-06 lr: 4.0598e-07  eta: 0:31:25  time: 0.4188  data_time: 0.0102  memory: 5969  grad_norm: 893.0002  loss: 20.1658  decode.loss_cls: 0.0530  decode.loss_mask: 1.2243  decode.loss_dice: 0.6932  decode.d0.loss_cls: 0.5946  decode.d0.loss_mask: 1.1073  decode.d0.loss_dice: 0.6633  decode.d1.loss_cls: 0.0601  decode.d1.loss_mask: 1.2324  decode.d1.loss_dice: 0.6911  decode.d2.loss_cls: 0.0554  decode.d2.loss_mask: 1.2267  decode.d2.loss_dice: 0.7007  decode.d3.loss_cls: 0.0596  decode.d3.loss_mask: 1.2281  decode.d3.loss_dice: 0.6890  decode.d4.loss_cls: 0.0531  decode.d4.loss_mask: 1.2403  decode.d4.loss_dice: 0.6892  decode.d5.loss_cls: 0.0550  decode.d5.loss_mask: 1.2368  decode.d5.loss_dice: 0.6924  decode.d6.loss_cls: 0.0510  decode.d6.loss_mask: 1.2164  decode.d6.loss_dice: 0.6870  decode.d7.loss_cls: 0.0511  decode.d7.loss_mask: 1.2371  decode.d7.loss_dice: 0.7002  decode.d8.loss_cls: 0.0508  decode.d8.loss_mask: 1.2352  decode.d8.loss_dice: 0.6915
05/27 05:26:32 - mmengine - INFO - Iter(train) [155500/160000]  base_lr: 4.0196e-06 lr: 4.0196e-07  eta: 0:31:04  time: 0.4194  data_time: 0.0101  memory: 5976  grad_norm: 697.4416  loss: 19.6052  decode.loss_cls: 0.2422  decode.loss_mask: 0.9931  decode.loss_dice: 0.7038  decode.d0.loss_cls: 0.6869  decode.d0.loss_mask: 0.9447  decode.d0.loss_dice: 0.6920  decode.d1.loss_cls: 0.2766  decode.d1.loss_mask: 0.9675  decode.d1.loss_dice: 0.6816  decode.d2.loss_cls: 0.2386  decode.d2.loss_mask: 1.0140  decode.d2.loss_dice: 0.7067  decode.d3.loss_cls: 0.2467  decode.d3.loss_mask: 0.9759  decode.d3.loss_dice: 0.6805  decode.d4.loss_cls: 0.2649  decode.d4.loss_mask: 0.9586  decode.d4.loss_dice: 0.6828  decode.d5.loss_cls: 0.3047  decode.d5.loss_mask: 0.9432  decode.d5.loss_dice: 0.6669  decode.d6.loss_cls: 0.2622  decode.d6.loss_mask: 0.9703  decode.d6.loss_dice: 0.6747  decode.d7.loss_cls: 0.3020  decode.d7.loss_mask: 0.9293  decode.d7.loss_dice: 0.6644  decode.d8.loss_cls: 0.2755  decode.d8.loss_mask: 0.9640  decode.d8.loss_dice: 0.6910
05/27 05:26:53 - mmengine - INFO - Iter(train) [155550/160000]  base_lr: 3.9794e-06 lr: 3.9794e-07  eta: 0:30:43  time: 0.4189  data_time: 0.0101  memory: 5974  grad_norm: 435.6344  loss: 17.9930  decode.loss_cls: 0.1214  decode.loss_mask: 0.9852  decode.loss_dice: 0.6182  decode.d0.loss_cls: 0.6597  decode.d0.loss_mask: 0.9909  decode.d0.loss_dice: 0.6125  decode.d1.loss_cls: 0.1205  decode.d1.loss_mask: 0.9830  decode.d1.loss_dice: 0.6408  decode.d2.loss_cls: 0.1045  decode.d2.loss_mask: 1.0119  decode.d2.loss_dice: 0.6551  decode.d3.loss_cls: 0.1204  decode.d3.loss_mask: 1.0145  decode.d3.loss_dice: 0.6334  decode.d4.loss_cls: 0.1064  decode.d4.loss_mask: 0.9987  decode.d4.loss_dice: 0.6335  decode.d5.loss_cls: 0.1164  decode.d5.loss_mask: 1.0021  decode.d5.loss_dice: 0.6342  decode.d6.loss_cls: 0.1079  decode.d6.loss_mask: 0.9953  decode.d6.loss_dice: 0.6315  decode.d7.loss_cls: 0.1039  decode.d7.loss_mask: 1.0115  decode.d7.loss_dice: 0.6400  decode.d8.loss_cls: 0.0939  decode.d8.loss_mask: 1.0074  decode.d8.loss_dice: 0.6380
05/27 05:27:14 - mmengine - INFO - Iter(train) [155600/160000]  base_lr: 3.9391e-06 lr: 3.9391e-07  eta: 0:30:23  time: 0.4191  data_time: 0.0101  memory: 5975  grad_norm: 613.3365  loss: 19.5157  decode.loss_cls: 0.1362  decode.loss_mask: 1.0344  decode.loss_dice: 0.7883  decode.d0.loss_cls: 0.6660  decode.d0.loss_mask: 0.8999  decode.d0.loss_dice: 0.7257  decode.d1.loss_cls: 0.1766  decode.d1.loss_mask: 0.9513  decode.d1.loss_dice: 0.7673  decode.d2.loss_cls: 0.1727  decode.d2.loss_mask: 1.0212  decode.d2.loss_dice: 0.7387  decode.d3.loss_cls: 0.2008  decode.d3.loss_mask: 0.9618  decode.d3.loss_dice: 0.7110  decode.d4.loss_cls: 0.1824  decode.d4.loss_mask: 0.9801  decode.d4.loss_dice: 0.7405  decode.d5.loss_cls: 0.1819  decode.d5.loss_mask: 1.0008  decode.d5.loss_dice: 0.7311  decode.d6.loss_cls: 0.1653  decode.d6.loss_mask: 0.9995  decode.d6.loss_dice: 0.7531  decode.d7.loss_cls: 0.1961  decode.d7.loss_mask: 0.9494  decode.d7.loss_dice: 0.7527  decode.d8.loss_cls: 0.1495  decode.d8.loss_mask: 1.0114  decode.d8.loss_dice: 0.7698
05/27 05:27:35 - mmengine - INFO - Iter(train) [155650/160000]  base_lr: 3.8988e-06 lr: 3.8988e-07  eta: 0:30:02  time: 0.4192  data_time: 0.0101  memory: 5968  grad_norm: 697.2206  loss: 20.4723  decode.loss_cls: 0.1798  decode.loss_mask: 1.0441  decode.loss_dice: 0.7402  decode.d0.loss_cls: 0.6049  decode.d0.loss_mask: 1.0468  decode.d0.loss_dice: 0.7318  decode.d1.loss_cls: 0.1787  decode.d1.loss_mask: 1.1194  decode.d1.loss_dice: 0.7792  decode.d2.loss_cls: 0.1727  decode.d2.loss_mask: 1.0479  decode.d2.loss_dice: 0.7766  decode.d3.loss_cls: 0.2093  decode.d3.loss_mask: 1.0728  decode.d3.loss_dice: 0.7666  decode.d4.loss_cls: 0.1917  decode.d4.loss_mask: 1.0442  decode.d4.loss_dice: 0.7464  decode.d5.loss_cls: 0.2054  decode.d5.loss_mask: 1.0614  decode.d5.loss_dice: 0.7558  decode.d6.loss_cls: 0.1940  decode.d6.loss_mask: 1.0597  decode.d6.loss_dice: 0.7571  decode.d7.loss_cls: 0.1782  decode.d7.loss_mask: 1.0678  decode.d7.loss_dice: 0.7355  decode.d8.loss_cls: 0.1946  decode.d8.loss_mask: 1.0568  decode.d8.loss_dice: 0.7526
05/27 05:27:56 - mmengine - INFO - Iter(train) [155700/160000]  base_lr: 3.8585e-06 lr: 3.8585e-07  eta: 0:29:41  time: 0.4193  data_time: 0.0102  memory: 5968  grad_norm: 629.7968  loss: 18.6278  decode.loss_cls: 0.2620  decode.loss_mask: 0.8768  decode.loss_dice: 0.6899  decode.d0.loss_cls: 0.7217  decode.d0.loss_mask: 0.8576  decode.d0.loss_dice: 0.6697  decode.d1.loss_cls: 0.2687  decode.d1.loss_mask: 0.8652  decode.d1.loss_dice: 0.6857  decode.d2.loss_cls: 0.3120  decode.d2.loss_mask: 0.8516  decode.d2.loss_dice: 0.6993  decode.d3.loss_cls: 0.2561  decode.d3.loss_mask: 0.8960  decode.d3.loss_dice: 0.6919  decode.d4.loss_cls: 0.2472  decode.d4.loss_mask: 0.8636  decode.d4.loss_dice: 0.6871  decode.d5.loss_cls: 0.2523  decode.d5.loss_mask: 0.8729  decode.d5.loss_dice: 0.6832  decode.d6.loss_cls: 0.2592  decode.d6.loss_mask: 0.8583  decode.d6.loss_dice: 0.6605  decode.d7.loss_cls: 0.2559  decode.d7.loss_mask: 0.8720  decode.d7.loss_dice: 0.6839  decode.d8.loss_cls: 0.2433  decode.d8.loss_mask: 0.8842  decode.d8.loss_dice: 0.6999
05/27 05:28:17 - mmengine - INFO - Iter(train) [155750/160000]  base_lr: 3.8181e-06 lr: 3.8181e-07  eta: 0:29:21  time: 0.4191  data_time: 0.0101  memory: 5967  grad_norm: 503.2016  loss: 16.0227  decode.loss_cls: 0.0617  decode.loss_mask: 0.9329  decode.loss_dice: 0.5548  decode.d0.loss_cls: 0.5383  decode.d0.loss_mask: 0.8967  decode.d0.loss_dice: 0.5415  decode.d1.loss_cls: 0.0862  decode.d1.loss_mask: 0.9357  decode.d1.loss_dice: 0.5588  decode.d2.loss_cls: 0.0887  decode.d2.loss_mask: 0.9420  decode.d2.loss_dice: 0.5662  decode.d3.loss_cls: 0.0724  decode.d3.loss_mask: 0.9199  decode.d3.loss_dice: 0.5522  decode.d4.loss_cls: 0.0686  decode.d4.loss_mask: 0.9207  decode.d4.loss_dice: 0.5569  decode.d5.loss_cls: 0.0634  decode.d5.loss_mask: 0.9253  decode.d5.loss_dice: 0.5589  decode.d6.loss_cls: 0.0834  decode.d6.loss_mask: 0.9340  decode.d6.loss_dice: 0.5591  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 0.9409  decode.d7.loss_dice: 0.5651  decode.d8.loss_cls: 0.0571  decode.d8.loss_mask: 0.9218  decode.d8.loss_dice: 0.5549
05/27 05:28:38 - mmengine - INFO - Iter(train) [155800/160000]  base_lr: 3.7776e-06 lr: 3.7776e-07  eta: 0:29:00  time: 0.4188  data_time: 0.0101  memory: 5976  grad_norm: 486.8084  loss: 16.4560  decode.loss_cls: 0.1380  decode.loss_mask: 0.8459  decode.loss_dice: 0.6203  decode.d0.loss_cls: 0.7481  decode.d0.loss_mask: 0.7988  decode.d0.loss_dice: 0.5925  decode.d1.loss_cls: 0.1849  decode.d1.loss_mask: 0.8279  decode.d1.loss_dice: 0.6067  decode.d2.loss_cls: 0.1496  decode.d2.loss_mask: 0.8232  decode.d2.loss_dice: 0.5983  decode.d3.loss_cls: 0.1159  decode.d3.loss_mask: 0.8308  decode.d3.loss_dice: 0.6049  decode.d4.loss_cls: 0.1325  decode.d4.loss_mask: 0.8453  decode.d4.loss_dice: 0.6191  decode.d5.loss_cls: 0.1490  decode.d5.loss_mask: 0.8206  decode.d5.loss_dice: 0.6036  decode.d6.loss_cls: 0.1705  decode.d6.loss_mask: 0.8347  decode.d6.loss_dice: 0.5952  decode.d7.loss_cls: 0.1648  decode.d7.loss_mask: 0.8357  decode.d7.loss_dice: 0.6103  decode.d8.loss_cls: 0.1640  decode.d8.loss_mask: 0.8182  decode.d8.loss_dice: 0.6063
05/27 05:28:59 - mmengine - INFO - Iter(train) [155850/160000]  base_lr: 3.7371e-06 lr: 3.7371e-07  eta: 0:28:39  time: 0.4195  data_time: 0.0101  memory: 5968  grad_norm: 649.1803  loss: 23.1543  decode.loss_cls: 0.2459  decode.loss_mask: 1.2183  decode.loss_dice: 0.7938  decode.d0.loss_cls: 0.7976  decode.d0.loss_mask: 1.1688  decode.d0.loss_dice: 0.8007  decode.d1.loss_cls: 0.2821  decode.d1.loss_mask: 1.2192  decode.d1.loss_dice: 0.7964  decode.d2.loss_cls: 0.2478  decode.d2.loss_mask: 1.2135  decode.d2.loss_dice: 0.8073  decode.d3.loss_cls: 0.2851  decode.d3.loss_mask: 1.1970  decode.d3.loss_dice: 0.7931  decode.d4.loss_cls: 0.2632  decode.d4.loss_mask: 1.2028  decode.d4.loss_dice: 0.7714  decode.d5.loss_cls: 0.2339  decode.d5.loss_mask: 1.2161  decode.d5.loss_dice: 0.7894  decode.d6.loss_cls: 0.2327  decode.d6.loss_mask: 1.2237  decode.d6.loss_dice: 0.8103  decode.d7.loss_cls: 0.2602  decode.d7.loss_mask: 1.2212  decode.d7.loss_dice: 0.7994  decode.d8.loss_cls: 0.2391  decode.d8.loss_mask: 1.2259  decode.d8.loss_dice: 0.7985
05/27 05:29:20 - mmengine - INFO - Iter(train) [155900/160000]  base_lr: 3.6966e-06 lr: 3.6966e-07  eta: 0:28:19  time: 0.4206  data_time: 0.0101  memory: 5984  grad_norm: 1716.0277  loss: 18.4256  decode.loss_cls: 0.1196  decode.loss_mask: 0.9598  decode.loss_dice: 0.6858  decode.d0.loss_cls: 0.6571  decode.d0.loss_mask: 0.9579  decode.d0.loss_dice: 0.6637  decode.d1.loss_cls: 0.1097  decode.d1.loss_mask: 0.9747  decode.d1.loss_dice: 0.7182  decode.d2.loss_cls: 0.1521  decode.d2.loss_mask: 0.9720  decode.d2.loss_dice: 0.6849  decode.d3.loss_cls: 0.1323  decode.d3.loss_mask: 0.9884  decode.d3.loss_dice: 0.6938  decode.d4.loss_cls: 0.1142  decode.d4.loss_mask: 0.9893  decode.d4.loss_dice: 0.6856  decode.d5.loss_cls: 0.1125  decode.d5.loss_mask: 0.9865  decode.d5.loss_dice: 0.6921  decode.d6.loss_cls: 0.1328  decode.d6.loss_mask: 0.9778  decode.d6.loss_dice: 0.6838  decode.d7.loss_cls: 0.1113  decode.d7.loss_mask: 0.9818  decode.d7.loss_dice: 0.6936  decode.d8.loss_cls: 0.1056  decode.d8.loss_mask: 0.9872  decode.d8.loss_dice: 0.7017
05/27 05:29:41 - mmengine - INFO - Iter(train) [155950/160000]  base_lr: 3.6560e-06 lr: 3.6560e-07  eta: 0:27:58  time: 0.4207  data_time: 0.0101  memory: 5966  grad_norm: 191.1475  loss: 13.4358  decode.loss_cls: 0.1277  decode.loss_mask: 0.6237  decode.loss_dice: 0.5447  decode.d0.loss_cls: 0.6317  decode.d0.loss_mask: 0.5893  decode.d0.loss_dice: 0.5431  decode.d1.loss_cls: 0.1519  decode.d1.loss_mask: 0.6397  decode.d1.loss_dice: 0.5521  decode.d2.loss_cls: 0.1257  decode.d2.loss_mask: 0.6270  decode.d2.loss_dice: 0.5260  decode.d3.loss_cls: 0.1650  decode.d3.loss_mask: 0.6036  decode.d3.loss_dice: 0.5025  decode.d4.loss_cls: 0.1702  decode.d4.loss_mask: 0.6074  decode.d4.loss_dice: 0.5201  decode.d5.loss_cls: 0.1268  decode.d5.loss_mask: 0.6212  decode.d5.loss_dice: 0.5448  decode.d6.loss_cls: 0.1293  decode.d6.loss_mask: 0.6245  decode.d6.loss_dice: 0.5358  decode.d7.loss_cls: 0.1452  decode.d7.loss_mask: 0.6204  decode.d7.loss_dice: 0.5478  decode.d8.loss_cls: 0.1174  decode.d8.loss_mask: 0.6317  decode.d8.loss_dice: 0.5395
05/27 05:30:02 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 05:30:02 - mmengine - INFO - Iter(train) [156000/160000]  base_lr: 3.6153e-06 lr: 3.6153e-07  eta: 0:27:37  time: 0.4189  data_time: 0.0100  memory: 5987  grad_norm: 296.5326  loss: 15.7689  decode.loss_cls: 0.1137  decode.loss_mask: 0.7995  decode.loss_dice: 0.6145  decode.d0.loss_cls: 0.5810  decode.d0.loss_mask: 0.7949  decode.d0.loss_dice: 0.6265  decode.d1.loss_cls: 0.1600  decode.d1.loss_mask: 0.7698  decode.d1.loss_dice: 0.5921  decode.d2.loss_cls: 0.1266  decode.d2.loss_mask: 0.8050  decode.d2.loss_dice: 0.6074  decode.d3.loss_cls: 0.1333  decode.d3.loss_mask: 0.7743  decode.d3.loss_dice: 0.5886  decode.d4.loss_cls: 0.1327  decode.d4.loss_mask: 0.8039  decode.d4.loss_dice: 0.6093  decode.d5.loss_cls: 0.1255  decode.d5.loss_mask: 0.8088  decode.d5.loss_dice: 0.5996  decode.d6.loss_cls: 0.1104  decode.d6.loss_mask: 0.7789  decode.d6.loss_dice: 0.6152  decode.d7.loss_cls: 0.1900  decode.d7.loss_mask: 0.7590  decode.d7.loss_dice: 0.5984  decode.d8.loss_cls: 0.1324  decode.d8.loss_mask: 0.8057  decode.d8.loss_dice: 0.6118
05/27 05:30:23 - mmengine - INFO - Iter(train) [156050/160000]  base_lr: 3.5746e-06 lr: 3.5746e-07  eta: 0:27:16  time: 0.4198  data_time: 0.0102  memory: 5987  grad_norm: 630.5503  loss: 19.2686  decode.loss_cls: 0.1737  decode.loss_mask: 0.9638  decode.loss_dice: 0.7236  decode.d0.loss_cls: 0.7246  decode.d0.loss_mask: 0.9606  decode.d0.loss_dice: 0.7486  decode.d1.loss_cls: 0.1625  decode.d1.loss_mask: 0.9850  decode.d1.loss_dice: 0.7311  decode.d2.loss_cls: 0.1632  decode.d2.loss_mask: 0.9708  decode.d2.loss_dice: 0.7121  decode.d3.loss_cls: 0.1732  decode.d3.loss_mask: 0.9558  decode.d3.loss_dice: 0.7250  decode.d4.loss_cls: 0.1821  decode.d4.loss_mask: 0.9716  decode.d4.loss_dice: 0.7368  decode.d5.loss_cls: 0.1675  decode.d5.loss_mask: 0.9745  decode.d5.loss_dice: 0.7216  decode.d6.loss_cls: 0.1762  decode.d6.loss_mask: 0.9877  decode.d6.loss_dice: 0.7335  decode.d7.loss_cls: 0.1744  decode.d7.loss_mask: 0.9706  decode.d7.loss_dice: 0.7284  decode.d8.loss_cls: 0.1764  decode.d8.loss_mask: 0.9717  decode.d8.loss_dice: 0.7222
05/27 05:30:45 - mmengine - INFO - Iter(train) [156100/160000]  base_lr: 3.5339e-06 lr: 3.5339e-07  eta: 0:26:56  time: 0.4202  data_time: 0.0101  memory: 5982  grad_norm: 372.8318  loss: 16.8652  decode.loss_cls: 0.1873  decode.loss_mask: 0.7915  decode.loss_dice: 0.6213  decode.d0.loss_cls: 0.6865  decode.d0.loss_mask: 0.7978  decode.d0.loss_dice: 0.6410  decode.d1.loss_cls: 0.1883  decode.d1.loss_mask: 0.8308  decode.d1.loss_dice: 0.6581  decode.d2.loss_cls: 0.1762  decode.d2.loss_mask: 0.8495  decode.d2.loss_dice: 0.6437  decode.d3.loss_cls: 0.2015  decode.d3.loss_mask: 0.8039  decode.d3.loss_dice: 0.6305  decode.d4.loss_cls: 0.1940  decode.d4.loss_mask: 0.8073  decode.d4.loss_dice: 0.6314  decode.d5.loss_cls: 0.1894  decode.d5.loss_mask: 0.8122  decode.d5.loss_dice: 0.6324  decode.d6.loss_cls: 0.1979  decode.d6.loss_mask: 0.8188  decode.d6.loss_dice: 0.6280  decode.d7.loss_cls: 0.1843  decode.d7.loss_mask: 0.8115  decode.d7.loss_dice: 0.6353  decode.d8.loss_cls: 0.1805  decode.d8.loss_mask: 0.8026  decode.d8.loss_dice: 0.6316
05/27 05:31:06 - mmengine - INFO - Iter(train) [156150/160000]  base_lr: 3.4931e-06 lr: 3.4931e-07  eta: 0:26:35  time: 0.4187  data_time: 0.0100  memory: 5967  grad_norm: 387.8077  loss: 16.8854  decode.loss_cls: 0.1540  decode.loss_mask: 0.8715  decode.loss_dice: 0.6181  decode.d0.loss_cls: 0.5747  decode.d0.loss_mask: 0.9052  decode.d0.loss_dice: 0.6337  decode.d1.loss_cls: 0.1690  decode.d1.loss_mask: 0.8891  decode.d1.loss_dice: 0.6329  decode.d2.loss_cls: 0.1217  decode.d2.loss_mask: 0.8756  decode.d2.loss_dice: 0.6291  decode.d3.loss_cls: 0.1187  decode.d3.loss_mask: 0.8690  decode.d3.loss_dice: 0.6226  decode.d4.loss_cls: 0.1521  decode.d4.loss_mask: 0.8767  decode.d4.loss_dice: 0.6252  decode.d5.loss_cls: 0.1499  decode.d5.loss_mask: 0.8766  decode.d5.loss_dice: 0.6232  decode.d6.loss_cls: 0.1275  decode.d6.loss_mask: 0.8716  decode.d6.loss_dice: 0.6273  decode.d7.loss_cls: 0.1217  decode.d7.loss_mask: 0.8752  decode.d7.loss_dice: 0.6405  decode.d8.loss_cls: 0.1362  decode.d8.loss_mask: 0.8809  decode.d8.loss_dice: 0.6159
05/27 05:31:27 - mmengine - INFO - Iter(train) [156200/160000]  base_lr: 3.4522e-06 lr: 3.4522e-07  eta: 0:26:14  time: 0.4196  data_time: 0.0101  memory: 5971  grad_norm: 820.1269  loss: 16.7454  decode.loss_cls: 0.0716  decode.loss_mask: 0.9337  decode.loss_dice: 0.6324  decode.d0.loss_cls: 0.5603  decode.d0.loss_mask: 0.8889  decode.d0.loss_dice: 0.6171  decode.d1.loss_cls: 0.0602  decode.d1.loss_mask: 0.9306  decode.d1.loss_dice: 0.6431  decode.d2.loss_cls: 0.0713  decode.d2.loss_mask: 0.9438  decode.d2.loss_dice: 0.6453  decode.d3.loss_cls: 0.0792  decode.d3.loss_mask: 0.9273  decode.d3.loss_dice: 0.6285  decode.d4.loss_cls: 0.0689  decode.d4.loss_mask: 0.9262  decode.d4.loss_dice: 0.6295  decode.d5.loss_cls: 0.0702  decode.d5.loss_mask: 0.9304  decode.d5.loss_dice: 0.6225  decode.d6.loss_cls: 0.0694  decode.d6.loss_mask: 0.9359  decode.d6.loss_dice: 0.6221  decode.d7.loss_cls: 0.0678  decode.d7.loss_mask: 0.9247  decode.d7.loss_dice: 0.6300  decode.d8.loss_cls: 0.0668  decode.d8.loss_mask: 0.9243  decode.d8.loss_dice: 0.6233
05/27 05:31:48 - mmengine - INFO - Iter(train) [156250/160000]  base_lr: 3.4113e-06 lr: 3.4113e-07  eta: 0:25:54  time: 0.4203  data_time: 0.0101  memory: 5972  grad_norm: 404.4904  loss: 18.5022  decode.loss_cls: 0.2204  decode.loss_mask: 0.9021  decode.loss_dice: 0.6727  decode.d0.loss_cls: 0.7239  decode.d0.loss_mask: 0.9004  decode.d0.loss_dice: 0.7491  decode.d1.loss_cls: 0.1981  decode.d1.loss_mask: 0.9123  decode.d1.loss_dice: 0.6721  decode.d2.loss_cls: 0.2017  decode.d2.loss_mask: 0.9187  decode.d2.loss_dice: 0.6490  decode.d3.loss_cls: 0.2466  decode.d3.loss_mask: 0.8999  decode.d3.loss_dice: 0.6394  decode.d4.loss_cls: 0.2358  decode.d4.loss_mask: 0.9036  decode.d4.loss_dice: 0.6691  decode.d5.loss_cls: 0.2373  decode.d5.loss_mask: 0.8997  decode.d5.loss_dice: 0.6611  decode.d6.loss_cls: 0.2304  decode.d6.loss_mask: 0.9004  decode.d6.loss_dice: 0.6739  decode.d7.loss_cls: 0.2268  decode.d7.loss_mask: 0.9204  decode.d7.loss_dice: 0.6706  decode.d8.loss_cls: 0.1980  decode.d8.loss_mask: 0.9059  decode.d8.loss_dice: 0.6629
05/27 05:32:09 - mmengine - INFO - Iter(train) [156300/160000]  base_lr: 3.3704e-06 lr: 3.3704e-07  eta: 0:25:33  time: 0.4198  data_time: 0.0101  memory: 5975  grad_norm: 388.4118  loss: 19.5507  decode.loss_cls: 0.1806  decode.loss_mask: 0.9903  decode.loss_dice: 0.7142  decode.d0.loss_cls: 0.6442  decode.d0.loss_mask: 1.0207  decode.d0.loss_dice: 0.7711  decode.d1.loss_cls: 0.2276  decode.d1.loss_mask: 0.9947  decode.d1.loss_dice: 0.7072  decode.d2.loss_cls: 0.2125  decode.d2.loss_mask: 0.9779  decode.d2.loss_dice: 0.6975  decode.d3.loss_cls: 0.2292  decode.d3.loss_mask: 0.9855  decode.d3.loss_dice: 0.6820  decode.d4.loss_cls: 0.2056  decode.d4.loss_mask: 0.9793  decode.d4.loss_dice: 0.7047  decode.d5.loss_cls: 0.2452  decode.d5.loss_mask: 0.9833  decode.d5.loss_dice: 0.6916  decode.d6.loss_cls: 0.2092  decode.d6.loss_mask: 0.9902  decode.d6.loss_dice: 0.7123  decode.d7.loss_cls: 0.2166  decode.d7.loss_mask: 0.9914  decode.d7.loss_dice: 0.7099  decode.d8.loss_cls: 0.1980  decode.d8.loss_mask: 0.9843  decode.d8.loss_dice: 0.6939
05/27 05:32:29 - mmengine - INFO - Iter(train) [156350/160000]  base_lr: 3.3293e-06 lr: 3.3293e-07  eta: 0:25:12  time: 0.4186  data_time: 0.0101  memory: 5981  grad_norm: 499.0184  loss: 16.3745  decode.loss_cls: 0.1074  decode.loss_mask: 0.8995  decode.loss_dice: 0.5607  decode.d0.loss_cls: 0.6017  decode.d0.loss_mask: 0.8771  decode.d0.loss_dice: 0.5549  decode.d1.loss_cls: 0.0933  decode.d1.loss_mask: 0.9176  decode.d1.loss_dice: 0.5843  decode.d2.loss_cls: 0.1046  decode.d2.loss_mask: 0.9149  decode.d2.loss_dice: 0.5823  decode.d3.loss_cls: 0.1014  decode.d3.loss_mask: 0.9068  decode.d3.loss_dice: 0.5707  decode.d4.loss_cls: 0.0949  decode.d4.loss_mask: 0.9187  decode.d4.loss_dice: 0.5818  decode.d5.loss_cls: 0.1035  decode.d5.loss_mask: 0.9078  decode.d5.loss_dice: 0.5785  decode.d6.loss_cls: 0.1154  decode.d6.loss_mask: 0.9156  decode.d6.loss_dice: 0.5787  decode.d7.loss_cls: 0.1301  decode.d7.loss_mask: 0.9206  decode.d7.loss_dice: 0.5798  decode.d8.loss_cls: 0.1013  decode.d8.loss_mask: 0.9077  decode.d8.loss_dice: 0.5631
05/27 05:32:50 - mmengine - INFO - Iter(train) [156400/160000]  base_lr: 3.2883e-06 lr: 3.2883e-07  eta: 0:24:51  time: 0.4195  data_time: 0.0101  memory: 5975  grad_norm: 554.8004  loss: 21.2608  decode.loss_cls: 0.2036  decode.loss_mask: 1.1248  decode.loss_dice: 0.7120  decode.d0.loss_cls: 0.7146  decode.d0.loss_mask: 1.1266  decode.d0.loss_dice: 0.7270  decode.d1.loss_cls: 0.1897  decode.d1.loss_mask: 1.1606  decode.d1.loss_dice: 0.7189  decode.d2.loss_cls: 0.2014  decode.d2.loss_mask: 1.1542  decode.d2.loss_dice: 0.7151  decode.d3.loss_cls: 0.1812  decode.d3.loss_mask: 1.1810  decode.d3.loss_dice: 0.7167  decode.d4.loss_cls: 0.2044  decode.d4.loss_mask: 1.1535  decode.d4.loss_dice: 0.7142  decode.d5.loss_cls: 0.1857  decode.d5.loss_mask: 1.1599  decode.d5.loss_dice: 0.7215  decode.d6.loss_cls: 0.1959  decode.d6.loss_mask: 1.1665  decode.d6.loss_dice: 0.7223  decode.d7.loss_cls: 0.2245  decode.d7.loss_mask: 1.1438  decode.d7.loss_dice: 0.7324  decode.d8.loss_cls: 0.2331  decode.d8.loss_mask: 1.1538  decode.d8.loss_dice: 0.7217
05/27 05:33:11 - mmengine - INFO - Iter(train) [156450/160000]  base_lr: 3.2471e-06 lr: 3.2471e-07  eta: 0:24:31  time: 0.4186  data_time: 0.0102  memory: 5971  grad_norm: 405.6241  loss: 18.1208  decode.loss_cls: 0.0973  decode.loss_mask: 1.0674  decode.loss_dice: 0.5895  decode.d0.loss_cls: 0.5716  decode.d0.loss_mask: 1.0267  decode.d0.loss_dice: 0.5871  decode.d1.loss_cls: 0.1158  decode.d1.loss_mask: 1.0640  decode.d1.loss_dice: 0.6008  decode.d2.loss_cls: 0.1012  decode.d2.loss_mask: 1.0734  decode.d2.loss_dice: 0.6000  decode.d3.loss_cls: 0.1074  decode.d3.loss_mask: 1.0692  decode.d3.loss_dice: 0.5930  decode.d4.loss_cls: 0.1124  decode.d4.loss_mask: 1.0657  decode.d4.loss_dice: 0.5964  decode.d5.loss_cls: 0.0990  decode.d5.loss_mask: 1.0713  decode.d5.loss_dice: 0.6031  decode.d6.loss_cls: 0.0852  decode.d6.loss_mask: 1.0758  decode.d6.loss_dice: 0.6005  decode.d7.loss_cls: 0.1113  decode.d7.loss_mask: 1.0669  decode.d7.loss_dice: 0.5946  decode.d8.loss_cls: 0.1089  decode.d8.loss_mask: 1.0723  decode.d8.loss_dice: 0.5929
05/27 05:33:32 - mmengine - INFO - Iter(train) [156500/160000]  base_lr: 3.2059e-06 lr: 3.2059e-07  eta: 0:24:10  time: 0.4187  data_time: 0.0101  memory: 5980  grad_norm: 424.0611  loss: 15.2993  decode.loss_cls: 0.1261  decode.loss_mask: 0.7679  decode.loss_dice: 0.5519  decode.d0.loss_cls: 0.6162  decode.d0.loss_mask: 0.7569  decode.d0.loss_dice: 0.5977  decode.d1.loss_cls: 0.1906  decode.d1.loss_mask: 0.7721  decode.d1.loss_dice: 0.5829  decode.d2.loss_cls: 0.1723  decode.d2.loss_mask: 0.7643  decode.d2.loss_dice: 0.5603  decode.d3.loss_cls: 0.1400  decode.d3.loss_mask: 0.7690  decode.d3.loss_dice: 0.5749  decode.d4.loss_cls: 0.1552  decode.d4.loss_mask: 0.7691  decode.d4.loss_dice: 0.5495  decode.d5.loss_cls: 0.1359  decode.d5.loss_mask: 0.7750  decode.d5.loss_dice: 0.5548  decode.d6.loss_cls: 0.1762  decode.d6.loss_mask: 0.7671  decode.d6.loss_dice: 0.5550  decode.d7.loss_cls: 0.1326  decode.d7.loss_mask: 0.7759  decode.d7.loss_dice: 0.5712  decode.d8.loss_cls: 0.1317  decode.d8.loss_mask: 0.7675  decode.d8.loss_dice: 0.5395
05/27 05:33:53 - mmengine - INFO - Iter(train) [156550/160000]  base_lr: 3.1647e-06 lr: 3.1647e-07  eta: 0:23:49  time: 0.4189  data_time: 0.0101  memory: 5969  grad_norm: 385.1971  loss: 18.9438  decode.loss_cls: 0.1625  decode.loss_mask: 1.0470  decode.loss_dice: 0.6407  decode.d0.loss_cls: 0.6000  decode.d0.loss_mask: 0.9739  decode.d0.loss_dice: 0.6259  decode.d1.loss_cls: 0.1591  decode.d1.loss_mask: 1.0550  decode.d1.loss_dice: 0.6531  decode.d2.loss_cls: 0.1658  decode.d2.loss_mask: 1.0510  decode.d2.loss_dice: 0.6364  decode.d3.loss_cls: 0.1456  decode.d3.loss_mask: 1.0567  decode.d3.loss_dice: 0.6464  decode.d4.loss_cls: 0.1583  decode.d4.loss_mask: 1.0598  decode.d4.loss_dice: 0.6467  decode.d5.loss_cls: 0.1512  decode.d5.loss_mask: 1.0605  decode.d5.loss_dice: 0.6477  decode.d6.loss_cls: 0.1750  decode.d6.loss_mask: 1.0499  decode.d6.loss_dice: 0.6484  decode.d7.loss_cls: 0.1613  decode.d7.loss_mask: 1.0562  decode.d7.loss_dice: 0.6515  decode.d8.loss_cls: 0.1546  decode.d8.loss_mask: 1.0580  decode.d8.loss_dice: 0.6454
05/27 05:34:14 - mmengine - INFO - Iter(train) [156600/160000]  base_lr: 3.1234e-06 lr: 3.1234e-07  eta: 0:23:29  time: 0.4190  data_time: 0.0101  memory: 5979  grad_norm: 743.4583  loss: 14.6728  decode.loss_cls: 0.0934  decode.loss_mask: 0.8148  decode.loss_dice: 0.5035  decode.d0.loss_cls: 0.5725  decode.d0.loss_mask: 0.7734  decode.d0.loss_dice: 0.4891  decode.d1.loss_cls: 0.1356  decode.d1.loss_mask: 0.8124  decode.d1.loss_dice: 0.5043  decode.d2.loss_cls: 0.1164  decode.d2.loss_mask: 0.8067  decode.d2.loss_dice: 0.5054  decode.d3.loss_cls: 0.1128  decode.d3.loss_mask: 0.8057  decode.d3.loss_dice: 0.5069  decode.d4.loss_cls: 0.1070  decode.d4.loss_mask: 0.8229  decode.d4.loss_dice: 0.5120  decode.d5.loss_cls: 0.1039  decode.d5.loss_mask: 0.8207  decode.d5.loss_dice: 0.5070  decode.d6.loss_cls: 0.1060  decode.d6.loss_mask: 0.8170  decode.d6.loss_dice: 0.5040  decode.d7.loss_cls: 0.1062  decode.d7.loss_mask: 0.8302  decode.d7.loss_dice: 0.5073  decode.d8.loss_cls: 0.1112  decode.d8.loss_mask: 0.7732  decode.d8.loss_dice: 0.4915
05/27 05:34:35 - mmengine - INFO - Iter(train) [156650/160000]  base_lr: 3.0820e-06 lr: 3.0820e-07  eta: 0:23:08  time: 0.4183  data_time: 0.0102  memory: 5988  grad_norm: 447.7420  loss: 17.7801  decode.loss_cls: 0.1872  decode.loss_mask: 0.8931  decode.loss_dice: 0.6147  decode.d0.loss_cls: 0.6176  decode.d0.loss_mask: 0.9056  decode.d0.loss_dice: 0.6331  decode.d1.loss_cls: 0.2302  decode.d1.loss_mask: 0.9019  decode.d1.loss_dice: 0.6238  decode.d2.loss_cls: 0.2087  decode.d2.loss_mask: 0.9108  decode.d2.loss_dice: 0.6436  decode.d3.loss_cls: 0.1962  decode.d3.loss_mask: 0.8914  decode.d3.loss_dice: 0.6038  decode.d4.loss_cls: 0.2400  decode.d4.loss_mask: 0.8924  decode.d4.loss_dice: 0.6159  decode.d5.loss_cls: 0.2320  decode.d5.loss_mask: 0.9022  decode.d5.loss_dice: 0.6208  decode.d6.loss_cls: 0.2035  decode.d6.loss_mask: 0.8922  decode.d6.loss_dice: 0.6227  decode.d7.loss_cls: 0.2165  decode.d7.loss_mask: 0.9003  decode.d7.loss_dice: 0.6547  decode.d8.loss_cls: 0.2013  decode.d8.loss_mask: 0.8948  decode.d8.loss_dice: 0.6292
05/27 05:34:56 - mmengine - INFO - Iter(train) [156700/160000]  base_lr: 3.0406e-06 lr: 3.0406e-07  eta: 0:22:47  time: 0.4196  data_time: 0.0102  memory: 5969  grad_norm: 323.1960  loss: 17.3807  decode.loss_cls: 0.1035  decode.loss_mask: 0.9071  decode.loss_dice: 0.6712  decode.d0.loss_cls: 0.6369  decode.d0.loss_mask: 0.9619  decode.d0.loss_dice: 0.7078  decode.d1.loss_cls: 0.1071  decode.d1.loss_mask: 0.9064  decode.d1.loss_dice: 0.6643  decode.d2.loss_cls: 0.1024  decode.d2.loss_mask: 0.9006  decode.d2.loss_dice: 0.6598  decode.d3.loss_cls: 0.0991  decode.d3.loss_mask: 0.8982  decode.d3.loss_dice: 0.6736  decode.d4.loss_cls: 0.0890  decode.d4.loss_mask: 0.9179  decode.d4.loss_dice: 0.6667  decode.d5.loss_cls: 0.0951  decode.d5.loss_mask: 0.9130  decode.d5.loss_dice: 0.6674  decode.d6.loss_cls: 0.0993  decode.d6.loss_mask: 0.9146  decode.d6.loss_dice: 0.6824  decode.d7.loss_cls: 0.1103  decode.d7.loss_mask: 0.8985  decode.d7.loss_dice: 0.6580  decode.d8.loss_cls: 0.1111  decode.d8.loss_mask: 0.9023  decode.d8.loss_dice: 0.6551
05/27 05:35:17 - mmengine - INFO - Iter(train) [156750/160000]  base_lr: 2.9991e-06 lr: 2.9991e-07  eta: 0:22:26  time: 0.4196  data_time: 0.0101  memory: 5984  grad_norm: 547.5305  loss: 19.0484  decode.loss_cls: 0.1929  decode.loss_mask: 0.9077  decode.loss_dice: 0.7530  decode.d0.loss_cls: 0.7635  decode.d0.loss_mask: 0.8678  decode.d0.loss_dice: 0.6879  decode.d1.loss_cls: 0.2437  decode.d1.loss_mask: 0.9165  decode.d1.loss_dice: 0.7638  decode.d2.loss_cls: 0.2447  decode.d2.loss_mask: 0.8862  decode.d2.loss_dice: 0.7241  decode.d3.loss_cls: 0.2487  decode.d3.loss_mask: 0.8776  decode.d3.loss_dice: 0.7091  decode.d4.loss_cls: 0.2433  decode.d4.loss_mask: 0.8790  decode.d4.loss_dice: 0.7351  decode.d5.loss_cls: 0.2372  decode.d5.loss_mask: 0.8841  decode.d5.loss_dice: 0.7276  decode.d6.loss_cls: 0.2345  decode.d6.loss_mask: 0.8838  decode.d6.loss_dice: 0.7512  decode.d7.loss_cls: 0.2398  decode.d7.loss_mask: 0.8673  decode.d7.loss_dice: 0.7203  decode.d8.loss_cls: 0.2465  decode.d8.loss_mask: 0.8879  decode.d8.loss_dice: 0.7233
05/27 05:35:38 - mmengine - INFO - Iter(train) [156800/160000]  base_lr: 2.9575e-06 lr: 2.9575e-07  eta: 0:22:06  time: 0.4199  data_time: 0.0101  memory: 5969  grad_norm: 363.9785  loss: 18.6750  decode.loss_cls: 0.1207  decode.loss_mask: 1.0195  decode.loss_dice: 0.6678  decode.d0.loss_cls: 0.6955  decode.d0.loss_mask: 1.0058  decode.d0.loss_dice: 0.6548  decode.d1.loss_cls: 0.1634  decode.d1.loss_mask: 1.0051  decode.d1.loss_dice: 0.6737  decode.d2.loss_cls: 0.1523  decode.d2.loss_mask: 1.0065  decode.d2.loss_dice: 0.6740  decode.d3.loss_cls: 0.1491  decode.d3.loss_mask: 1.0117  decode.d3.loss_dice: 0.6584  decode.d4.loss_cls: 0.1466  decode.d4.loss_mask: 0.9805  decode.d4.loss_dice: 0.6664  decode.d5.loss_cls: 0.1478  decode.d5.loss_mask: 1.0001  decode.d5.loss_dice: 0.6616  decode.d6.loss_cls: 0.1695  decode.d6.loss_mask: 0.9975  decode.d6.loss_dice: 0.6599  decode.d7.loss_cls: 0.1611  decode.d7.loss_mask: 0.9966  decode.d7.loss_dice: 0.6563  decode.d8.loss_cls: 0.1504  decode.d8.loss_mask: 0.9767  decode.d8.loss_dice: 0.6457
05/27 05:36:00 - mmengine - INFO - Iter(train) [156850/160000]  base_lr: 2.9159e-06 lr: 2.9159e-07  eta: 0:21:45  time: 0.4194  data_time: 0.0102  memory: 5970  grad_norm: 653.6758  loss: 17.9072  decode.loss_cls: 0.2217  decode.loss_mask: 0.9167  decode.loss_dice: 0.5870  decode.d0.loss_cls: 0.6713  decode.d0.loss_mask: 0.9110  decode.d0.loss_dice: 0.6246  decode.d1.loss_cls: 0.1901  decode.d1.loss_mask: 0.9553  decode.d1.loss_dice: 0.6424  decode.d2.loss_cls: 0.2094  decode.d2.loss_mask: 0.9097  decode.d2.loss_dice: 0.6191  decode.d3.loss_cls: 0.2103  decode.d3.loss_mask: 0.9262  decode.d3.loss_dice: 0.6100  decode.d4.loss_cls: 0.2306  decode.d4.loss_mask: 0.9101  decode.d4.loss_dice: 0.5982  decode.d5.loss_cls: 0.2231  decode.d5.loss_mask: 0.9205  decode.d5.loss_dice: 0.6022  decode.d6.loss_cls: 0.2252  decode.d6.loss_mask: 0.9238  decode.d6.loss_dice: 0.6019  decode.d7.loss_cls: 0.1951  decode.d7.loss_mask: 0.9095  decode.d7.loss_dice: 0.6152  decode.d8.loss_cls: 0.1933  decode.d8.loss_mask: 0.9294  decode.d8.loss_dice: 0.6242
05/27 05:36:21 - mmengine - INFO - Iter(train) [156900/160000]  base_lr: 2.8742e-06 lr: 2.8742e-07  eta: 0:21:24  time: 0.4204  data_time: 0.0101  memory: 5976  grad_norm: 393.0372  loss: 17.8106  decode.loss_cls: 0.0548  decode.loss_mask: 0.9941  decode.loss_dice: 0.6748  decode.d0.loss_cls: 0.5990  decode.d0.loss_mask: 0.9645  decode.d0.loss_dice: 0.6537  decode.d1.loss_cls: 0.0465  decode.d1.loss_mask: 0.9959  decode.d1.loss_dice: 0.6851  decode.d2.loss_cls: 0.0640  decode.d2.loss_mask: 0.9956  decode.d2.loss_dice: 0.6768  decode.d3.loss_cls: 0.0834  decode.d3.loss_mask: 0.9934  decode.d3.loss_dice: 0.6594  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 0.9987  decode.d4.loss_dice: 0.6692  decode.d5.loss_cls: 0.0545  decode.d5.loss_mask: 1.0011  decode.d5.loss_dice: 0.6910  decode.d6.loss_cls: 0.0785  decode.d6.loss_mask: 0.9931  decode.d6.loss_dice: 0.6645  decode.d7.loss_cls: 0.0719  decode.d7.loss_mask: 0.9903  decode.d7.loss_dice: 0.6591  decode.d8.loss_cls: 0.0698  decode.d8.loss_mask: 0.9858  decode.d8.loss_dice: 0.6624
05/27 05:36:42 - mmengine - INFO - Iter(train) [156950/160000]  base_lr: 2.8325e-06 lr: 2.8325e-07  eta: 0:21:04  time: 0.4185  data_time: 0.0102  memory: 5969  grad_norm: 479.8447  loss: 17.3065  decode.loss_cls: 0.1407  decode.loss_mask: 0.8706  decode.loss_dice: 0.6530  decode.d0.loss_cls: 0.6449  decode.d0.loss_mask: 0.8609  decode.d0.loss_dice: 0.6596  decode.d1.loss_cls: 0.1589  decode.d1.loss_mask: 0.8741  decode.d1.loss_dice: 0.6584  decode.d2.loss_cls: 0.1575  decode.d2.loss_mask: 0.8796  decode.d2.loss_dice: 0.6366  decode.d3.loss_cls: 0.1608  decode.d3.loss_mask: 0.8817  decode.d3.loss_dice: 0.6487  decode.d4.loss_cls: 0.1584  decode.d4.loss_mask: 0.8743  decode.d4.loss_dice: 0.6638  decode.d5.loss_cls: 0.1593  decode.d5.loss_mask: 0.8741  decode.d5.loss_dice: 0.6425  decode.d6.loss_cls: 0.1637  decode.d6.loss_mask: 0.8793  decode.d6.loss_dice: 0.6428  decode.d7.loss_cls: 0.1489  decode.d7.loss_mask: 0.8842  decode.d7.loss_dice: 0.6337  decode.d8.loss_cls: 0.1604  decode.d8.loss_mask: 0.8748  decode.d8.loss_dice: 0.6603
05/27 05:37:03 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 05:37:03 - mmengine - INFO - Iter(train) [157000/160000]  base_lr: 2.7906e-06 lr: 2.7906e-07  eta: 0:20:43  time: 0.4191  data_time: 0.0101  memory: 5971  grad_norm: 371.8696  loss: 19.3743  decode.loss_cls: 0.1651  decode.loss_mask: 0.9861  decode.loss_dice: 0.6991  decode.d0.loss_cls: 0.7046  decode.d0.loss_mask: 0.9820  decode.d0.loss_dice: 0.7255  decode.d1.loss_cls: 0.2120  decode.d1.loss_mask: 0.9946  decode.d1.loss_dice: 0.7194  decode.d2.loss_cls: 0.1982  decode.d2.loss_mask: 1.0020  decode.d2.loss_dice: 0.7139  decode.d3.loss_cls: 0.1751  decode.d3.loss_mask: 0.9892  decode.d3.loss_dice: 0.7173  decode.d4.loss_cls: 0.1785  decode.d4.loss_mask: 0.9886  decode.d4.loss_dice: 0.6941  decode.d5.loss_cls: 0.1599  decode.d5.loss_mask: 0.9976  decode.d5.loss_dice: 0.7237  decode.d6.loss_cls: 0.1769  decode.d6.loss_mask: 0.9855  decode.d6.loss_dice: 0.7210  decode.d7.loss_cls: 0.1755  decode.d7.loss_mask: 1.0019  decode.d7.loss_dice: 0.7104  decode.d8.loss_cls: 0.1746  decode.d8.loss_mask: 0.9976  decode.d8.loss_dice: 0.7043
05/27 05:37:24 - mmengine - INFO - Iter(train) [157050/160000]  base_lr: 2.7487e-06 lr: 2.7487e-07  eta: 0:20:22  time: 0.4203  data_time: 0.0103  memory: 5969  grad_norm: 657.8172  loss: 20.7137  decode.loss_cls: 0.1800  decode.loss_mask: 1.1153  decode.loss_dice: 0.7526  decode.d0.loss_cls: 0.6436  decode.d0.loss_mask: 1.1245  decode.d0.loss_dice: 0.7607  decode.d1.loss_cls: 0.1715  decode.d1.loss_mask: 1.0992  decode.d1.loss_dice: 0.7613  decode.d2.loss_cls: 0.1463  decode.d2.loss_mask: 1.1358  decode.d2.loss_dice: 0.7385  decode.d3.loss_cls: 0.1674  decode.d3.loss_mask: 1.1057  decode.d3.loss_dice: 0.7404  decode.d4.loss_cls: 0.1872  decode.d4.loss_mask: 1.0938  decode.d4.loss_dice: 0.7245  decode.d5.loss_cls: 0.1425  decode.d5.loss_mask: 1.1183  decode.d5.loss_dice: 0.7553  decode.d6.loss_cls: 0.1378  decode.d6.loss_mask: 1.1230  decode.d6.loss_dice: 0.7449  decode.d7.loss_cls: 0.1612  decode.d7.loss_mask: 1.1076  decode.d7.loss_dice: 0.7417  decode.d8.loss_cls: 0.1776  decode.d8.loss_mask: 1.1238  decode.d8.loss_dice: 0.7316
05/27 05:37:45 - mmengine - INFO - Iter(train) [157100/160000]  base_lr: 2.7068e-06 lr: 2.7068e-07  eta: 0:20:01  time: 0.4203  data_time: 0.0101  memory: 5966  grad_norm: 482.7098  loss: 20.4856  decode.loss_cls: 0.2136  decode.loss_mask: 1.0606  decode.loss_dice: 0.7141  decode.d0.loss_cls: 0.6411  decode.d0.loss_mask: 0.9962  decode.d0.loss_dice: 0.7248  decode.d1.loss_cls: 0.2522  decode.d1.loss_mask: 1.0983  decode.d1.loss_dice: 0.7637  decode.d2.loss_cls: 0.2103  decode.d2.loss_mask: 1.0734  decode.d2.loss_dice: 0.7230  decode.d3.loss_cls: 0.2162  decode.d3.loss_mask: 1.0630  decode.d3.loss_dice: 0.7072  decode.d4.loss_cls: 0.2089  decode.d4.loss_mask: 1.0311  decode.d4.loss_dice: 0.7302  decode.d5.loss_cls: 0.2116  decode.d5.loss_mask: 1.1111  decode.d5.loss_dice: 0.7507  decode.d6.loss_cls: 0.2383  decode.d6.loss_mask: 1.0423  decode.d6.loss_dice: 0.7431  decode.d7.loss_cls: 0.1921  decode.d7.loss_mask: 1.0475  decode.d7.loss_dice: 0.7507  decode.d8.loss_cls: 0.2058  decode.d8.loss_mask: 1.0542  decode.d8.loss_dice: 0.7104
05/27 05:38:06 - mmengine - INFO - Iter(train) [157150/160000]  base_lr: 2.6647e-06 lr: 2.6647e-07  eta: 0:19:41  time: 0.4196  data_time: 0.0102  memory: 5969  grad_norm: 294.8250  loss: 17.9588  decode.loss_cls: 0.1559  decode.loss_mask: 0.9301  decode.loss_dice: 0.6484  decode.d0.loss_cls: 0.6163  decode.d0.loss_mask: 0.9275  decode.d0.loss_dice: 0.6421  decode.d1.loss_cls: 0.1731  decode.d1.loss_mask: 0.9291  decode.d1.loss_dice: 0.6602  decode.d2.loss_cls: 0.1710  decode.d2.loss_mask: 0.9409  decode.d2.loss_dice: 0.6659  decode.d3.loss_cls: 0.1560  decode.d3.loss_mask: 0.9375  decode.d3.loss_dice: 0.6551  decode.d4.loss_cls: 0.1430  decode.d4.loss_mask: 0.9299  decode.d4.loss_dice: 0.6515  decode.d5.loss_cls: 0.1452  decode.d5.loss_mask: 0.9422  decode.d5.loss_dice: 0.6639  decode.d6.loss_cls: 0.1660  decode.d6.loss_mask: 0.9488  decode.d6.loss_dice: 0.6594  decode.d7.loss_cls: 0.1695  decode.d7.loss_mask: 0.9365  decode.d7.loss_dice: 0.6529  decode.d8.loss_cls: 0.1604  decode.d8.loss_mask: 0.9300  decode.d8.loss_dice: 0.6506
05/27 05:38:27 - mmengine - INFO - Iter(train) [157200/160000]  base_lr: 2.6226e-06 lr: 2.6226e-07  eta: 0:19:20  time: 0.4191  data_time: 0.0101  memory: 5967  grad_norm: 643.3110  loss: 17.7920  decode.loss_cls: 0.1058  decode.loss_mask: 0.9064  decode.loss_dice: 0.7159  decode.d0.loss_cls: 0.5434  decode.d0.loss_mask: 0.9566  decode.d0.loss_dice: 0.7195  decode.d1.loss_cls: 0.0882  decode.d1.loss_mask: 0.9518  decode.d1.loss_dice: 0.7308  decode.d2.loss_cls: 0.1022  decode.d2.loss_mask: 0.9255  decode.d2.loss_dice: 0.7181  decode.d3.loss_cls: 0.1140  decode.d3.loss_mask: 0.9101  decode.d3.loss_dice: 0.7194  decode.d4.loss_cls: 0.1062  decode.d4.loss_mask: 0.8962  decode.d4.loss_dice: 0.7127  decode.d5.loss_cls: 0.1075  decode.d5.loss_mask: 0.8949  decode.d5.loss_dice: 0.7050  decode.d6.loss_cls: 0.1027  decode.d6.loss_mask: 0.9039  decode.d6.loss_dice: 0.7117  decode.d7.loss_cls: 0.0832  decode.d7.loss_mask: 0.9197  decode.d7.loss_dice: 0.7205  decode.d8.loss_cls: 0.0972  decode.d8.loss_mask: 0.9092  decode.d8.loss_dice: 0.7137
05/27 05:38:48 - mmengine - INFO - Iter(train) [157250/160000]  base_lr: 2.5804e-06 lr: 2.5804e-07  eta: 0:18:59  time: 0.4205  data_time: 0.0101  memory: 5987  grad_norm: 587.7442  loss: 18.4143  decode.loss_cls: 0.1562  decode.loss_mask: 1.0390  decode.loss_dice: 0.6473  decode.d0.loss_cls: 0.6570  decode.d0.loss_mask: 0.9455  decode.d0.loss_dice: 0.6024  decode.d1.loss_cls: 0.1646  decode.d1.loss_mask: 1.0170  decode.d1.loss_dice: 0.6512  decode.d2.loss_cls: 0.1690  decode.d2.loss_mask: 0.9930  decode.d2.loss_dice: 0.6350  decode.d3.loss_cls: 0.1275  decode.d3.loss_mask: 1.0104  decode.d3.loss_dice: 0.6465  decode.d4.loss_cls: 0.1594  decode.d4.loss_mask: 0.9786  decode.d4.loss_dice: 0.6288  decode.d5.loss_cls: 0.1393  decode.d5.loss_mask: 1.0165  decode.d5.loss_dice: 0.6486  decode.d6.loss_cls: 0.1602  decode.d6.loss_mask: 1.0113  decode.d6.loss_dice: 0.6316  decode.d7.loss_cls: 0.1557  decode.d7.loss_mask: 1.0100  decode.d7.loss_dice: 0.6436  decode.d8.loss_cls: 0.1658  decode.d8.loss_mask: 0.9770  decode.d8.loss_dice: 0.6261
05/27 05:39:09 - mmengine - INFO - Iter(train) [157300/160000]  base_lr: 2.5382e-06 lr: 2.5382e-07  eta: 0:18:38  time: 0.4196  data_time: 0.0101  memory: 5966  grad_norm: 287.1316  loss: 15.7064  decode.loss_cls: 0.1443  decode.loss_mask: 0.7997  decode.loss_dice: 0.5812  decode.d0.loss_cls: 0.6011  decode.d0.loss_mask: 0.7898  decode.d0.loss_dice: 0.5872  decode.d1.loss_cls: 0.1290  decode.d1.loss_mask: 0.8022  decode.d1.loss_dice: 0.5960  decode.d2.loss_cls: 0.1408  decode.d2.loss_mask: 0.7875  decode.d2.loss_dice: 0.5779  decode.d3.loss_cls: 0.1346  decode.d3.loss_mask: 0.7947  decode.d3.loss_dice: 0.5825  decode.d4.loss_cls: 0.1516  decode.d4.loss_mask: 0.7918  decode.d4.loss_dice: 0.5800  decode.d5.loss_cls: 0.1478  decode.d5.loss_mask: 0.7993  decode.d5.loss_dice: 0.5972  decode.d6.loss_cls: 0.1395  decode.d6.loss_mask: 0.7988  decode.d6.loss_dice: 0.5888  decode.d7.loss_cls: 0.1490  decode.d7.loss_mask: 0.8001  decode.d7.loss_dice: 0.5859  decode.d8.loss_cls: 0.1515  decode.d8.loss_mask: 0.7941  decode.d8.loss_dice: 0.5825
05/27 05:39:30 - mmengine - INFO - Iter(train) [157350/160000]  base_lr: 2.4958e-06 lr: 2.4958e-07  eta: 0:18:18  time: 0.4202  data_time: 0.0101  memory: 5965  grad_norm: 506.4200  loss: 20.0981  decode.loss_cls: 0.1946  decode.loss_mask: 1.0989  decode.loss_dice: 0.6647  decode.d0.loss_cls: 0.7095  decode.d0.loss_mask: 1.0391  decode.d0.loss_dice: 0.7006  decode.d1.loss_cls: 0.2377  decode.d1.loss_mask: 1.0597  decode.d1.loss_dice: 0.6817  decode.d2.loss_cls: 0.2578  decode.d2.loss_mask: 1.0813  decode.d2.loss_dice: 0.6810  decode.d3.loss_cls: 0.2150  decode.d3.loss_mask: 1.0698  decode.d3.loss_dice: 0.6726  decode.d4.loss_cls: 0.2290  decode.d4.loss_mask: 1.0344  decode.d4.loss_dice: 0.6568  decode.d5.loss_cls: 0.2174  decode.d5.loss_mask: 1.0675  decode.d5.loss_dice: 0.6485  decode.d6.loss_cls: 0.2531  decode.d6.loss_mask: 1.0204  decode.d6.loss_dice: 0.6678  decode.d7.loss_cls: 0.2366  decode.d7.loss_mask: 1.0582  decode.d7.loss_dice: 0.6593  decode.d8.loss_cls: 0.2336  decode.d8.loss_mask: 1.0744  decode.d8.loss_dice: 0.6772
05/27 05:39:51 - mmengine - INFO - Iter(train) [157400/160000]  base_lr: 2.4534e-06 lr: 2.4534e-07  eta: 0:17:57  time: 0.4194  data_time: 0.0101  memory: 5971  grad_norm: 643.2175  loss: 20.0442  decode.loss_cls: 0.1416  decode.loss_mask: 1.0483  decode.loss_dice: 0.7418  decode.d0.loss_cls: 0.7054  decode.d0.loss_mask: 0.9993  decode.d0.loss_dice: 0.7181  decode.d1.loss_cls: 0.1639  decode.d1.loss_mask: 1.0554  decode.d1.loss_dice: 0.7623  decode.d2.loss_cls: 0.1487  decode.d2.loss_mask: 1.0447  decode.d2.loss_dice: 0.7864  decode.d3.loss_cls: 0.1654  decode.d3.loss_mask: 1.0393  decode.d3.loss_dice: 0.7485  decode.d4.loss_cls: 0.1537  decode.d4.loss_mask: 1.0710  decode.d4.loss_dice: 0.7725  decode.d5.loss_cls: 0.1566  decode.d5.loss_mask: 1.0371  decode.d5.loss_dice: 0.7543  decode.d6.loss_cls: 0.1327  decode.d6.loss_mask: 1.0540  decode.d6.loss_dice: 0.7400  decode.d7.loss_cls: 0.1664  decode.d7.loss_mask: 1.0454  decode.d7.loss_dice: 0.7450  decode.d8.loss_cls: 0.1642  decode.d8.loss_mask: 1.0344  decode.d8.loss_dice: 0.7478
05/27 05:40:12 - mmengine - INFO - Iter(train) [157450/160000]  base_lr: 2.4109e-06 lr: 2.4109e-07  eta: 0:17:36  time: 0.4192  data_time: 0.0102  memory: 5971  grad_norm: 696.8958  loss: 18.0194  decode.loss_cls: 0.0664  decode.loss_mask: 0.9791  decode.loss_dice: 0.6553  decode.d0.loss_cls: 0.6918  decode.d0.loss_mask: 0.9838  decode.d0.loss_dice: 0.6678  decode.d1.loss_cls: 0.1170  decode.d1.loss_mask: 0.9949  decode.d1.loss_dice: 0.6807  decode.d2.loss_cls: 0.0857  decode.d2.loss_mask: 0.9867  decode.d2.loss_dice: 0.6642  decode.d3.loss_cls: 0.0957  decode.d3.loss_mask: 0.9831  decode.d3.loss_dice: 0.6717  decode.d4.loss_cls: 0.0791  decode.d4.loss_mask: 0.9875  decode.d4.loss_dice: 0.6728  decode.d5.loss_cls: 0.0765  decode.d5.loss_mask: 0.9898  decode.d5.loss_dice: 0.6763  decode.d6.loss_cls: 0.0784  decode.d6.loss_mask: 0.9921  decode.d6.loss_dice: 0.6728  decode.d7.loss_cls: 0.0889  decode.d7.loss_mask: 0.9889  decode.d7.loss_dice: 0.6661  decode.d8.loss_cls: 0.0874  decode.d8.loss_mask: 0.9793  decode.d8.loss_dice: 0.6596
05/27 05:40:33 - mmengine - INFO - Iter(train) [157500/160000]  base_lr: 2.3683e-06 lr: 2.3683e-07  eta: 0:17:16  time: 0.4187  data_time: 0.0101  memory: 5980  grad_norm: 332.0616  loss: 15.4108  decode.loss_cls: 0.0900  decode.loss_mask: 0.8345  decode.loss_dice: 0.5684  decode.d0.loss_cls: 0.5252  decode.d0.loss_mask: 0.8325  decode.d0.loss_dice: 0.5664  decode.d1.loss_cls: 0.1038  decode.d1.loss_mask: 0.8380  decode.d1.loss_dice: 0.5690  decode.d2.loss_cls: 0.1024  decode.d2.loss_mask: 0.8414  decode.d2.loss_dice: 0.5771  decode.d3.loss_cls: 0.0901  decode.d3.loss_mask: 0.8336  decode.d3.loss_dice: 0.5674  decode.d4.loss_cls: 0.0932  decode.d4.loss_mask: 0.8368  decode.d4.loss_dice: 0.5695  decode.d5.loss_cls: 0.0900  decode.d5.loss_mask: 0.8341  decode.d5.loss_dice: 0.5674  decode.d6.loss_cls: 0.1013  decode.d6.loss_mask: 0.8341  decode.d6.loss_dice: 0.5787  decode.d7.loss_cls: 0.0802  decode.d7.loss_mask: 0.8340  decode.d7.loss_dice: 0.5676  decode.d8.loss_cls: 0.0845  decode.d8.loss_mask: 0.8353  decode.d8.loss_dice: 0.5643
05/27 05:40:54 - mmengine - INFO - Iter(train) [157550/160000]  base_lr: 2.3256e-06 lr: 2.3256e-07  eta: 0:16:55  time: 0.4190  data_time: 0.0101  memory: 5982  grad_norm: 501.5717  loss: 15.5476  decode.loss_cls: 0.0609  decode.loss_mask: 0.8642  decode.loss_dice: 0.5595  decode.d0.loss_cls: 0.5081  decode.d0.loss_mask: 0.8513  decode.d0.loss_dice: 0.5669  decode.d1.loss_cls: 0.0714  decode.d1.loss_mask: 0.8843  decode.d1.loss_dice: 0.5782  decode.d2.loss_cls: 0.0666  decode.d2.loss_mask: 0.8840  decode.d2.loss_dice: 0.5741  decode.d3.loss_cls: 0.0626  decode.d3.loss_mask: 0.8805  decode.d3.loss_dice: 0.5745  decode.d4.loss_cls: 0.0688  decode.d4.loss_mask: 0.8689  decode.d4.loss_dice: 0.5747  decode.d5.loss_cls: 0.0644  decode.d5.loss_mask: 0.8802  decode.d5.loss_dice: 0.5753  decode.d6.loss_cls: 0.0652  decode.d6.loss_mask: 0.8703  decode.d6.loss_dice: 0.5732  decode.d7.loss_cls: 0.0768  decode.d7.loss_mask: 0.8697  decode.d7.loss_dice: 0.5640  decode.d8.loss_cls: 0.0689  decode.d8.loss_mask: 0.8725  decode.d8.loss_dice: 0.5676
05/27 05:41:15 - mmengine - INFO - Iter(train) [157600/160000]  base_lr: 2.2829e-06 lr: 2.2829e-07  eta: 0:16:34  time: 0.4200  data_time: 0.0102  memory: 5975  grad_norm: 447.2303  loss: 16.7316  decode.loss_cls: 0.1234  decode.loss_mask: 0.8761  decode.loss_dice: 0.6250  decode.d0.loss_cls: 0.5539  decode.d0.loss_mask: 0.8593  decode.d0.loss_dice: 0.6270  decode.d1.loss_cls: 0.1303  decode.d1.loss_mask: 0.8727  decode.d1.loss_dice: 0.6196  decode.d2.loss_cls: 0.1264  decode.d2.loss_mask: 0.8998  decode.d2.loss_dice: 0.6306  decode.d3.loss_cls: 0.1407  decode.d3.loss_mask: 0.8712  decode.d3.loss_dice: 0.6080  decode.d4.loss_cls: 0.1190  decode.d4.loss_mask: 0.8971  decode.d4.loss_dice: 0.6380  decode.d5.loss_cls: 0.1370  decode.d5.loss_mask: 0.8904  decode.d5.loss_dice: 0.6277  decode.d6.loss_cls: 0.1130  decode.d6.loss_mask: 0.8786  decode.d6.loss_dice: 0.6216  decode.d7.loss_cls: 0.1116  decode.d7.loss_mask: 0.8820  decode.d7.loss_dice: 0.6166  decode.d8.loss_cls: 0.1264  decode.d8.loss_mask: 0.8748  decode.d8.loss_dice: 0.6341
05/27 05:41:36 - mmengine - INFO - Iter(train) [157650/160000]  base_lr: 2.2400e-06 lr: 2.2400e-07  eta: 0:16:13  time: 0.4192  data_time: 0.0102  memory: 5971  grad_norm: 305.8352  loss: 14.6001  decode.loss_cls: 0.0946  decode.loss_mask: 0.7358  decode.loss_dice: 0.6110  decode.d0.loss_cls: 0.6397  decode.d0.loss_mask: 0.7037  decode.d0.loss_dice: 0.5716  decode.d1.loss_cls: 0.0895  decode.d1.loss_mask: 0.7020  decode.d1.loss_dice: 0.6109  decode.d2.loss_cls: 0.1144  decode.d2.loss_mask: 0.7217  decode.d2.loss_dice: 0.5834  decode.d3.loss_cls: 0.0816  decode.d3.loss_mask: 0.7266  decode.d3.loss_dice: 0.6086  decode.d4.loss_cls: 0.0863  decode.d4.loss_mask: 0.6999  decode.d4.loss_dice: 0.6120  decode.d5.loss_cls: 0.0895  decode.d5.loss_mask: 0.7065  decode.d5.loss_dice: 0.6234  decode.d6.loss_cls: 0.0615  decode.d6.loss_mask: 0.7032  decode.d6.loss_dice: 0.5985  decode.d7.loss_cls: 0.1256  decode.d7.loss_mask: 0.7026  decode.d7.loss_dice: 0.5731  decode.d8.loss_cls: 0.1095  decode.d8.loss_mask: 0.7126  decode.d8.loss_dice: 0.6006
05/27 05:41:57 - mmengine - INFO - Iter(train) [157700/160000]  base_lr: 2.1971e-06 lr: 2.1971e-07  eta: 0:15:53  time: 0.4197  data_time: 0.0101  memory: 5968  grad_norm: 551.3577  loss: 18.0302  decode.loss_cls: 0.0835  decode.loss_mask: 1.0158  decode.loss_dice: 0.6460  decode.d0.loss_cls: 0.7281  decode.d0.loss_mask: 0.9220  decode.d0.loss_dice: 0.6364  decode.d1.loss_cls: 0.1269  decode.d1.loss_mask: 0.9867  decode.d1.loss_dice: 0.6528  decode.d2.loss_cls: 0.0974  decode.d2.loss_mask: 0.9968  decode.d2.loss_dice: 0.6483  decode.d3.loss_cls: 0.1030  decode.d3.loss_mask: 0.9917  decode.d3.loss_dice: 0.6360  decode.d4.loss_cls: 0.1170  decode.d4.loss_mask: 0.9758  decode.d4.loss_dice: 0.6416  decode.d5.loss_cls: 0.1313  decode.d5.loss_mask: 0.9974  decode.d5.loss_dice: 0.6413  decode.d6.loss_cls: 0.1237  decode.d6.loss_mask: 0.9755  decode.d6.loss_dice: 0.6261  decode.d7.loss_cls: 0.1077  decode.d7.loss_mask: 1.0261  decode.d7.loss_dice: 0.6572  decode.d8.loss_cls: 0.1097  decode.d8.loss_mask: 0.9824  decode.d8.loss_dice: 0.6461
05/27 05:42:18 - mmengine - INFO - Iter(train) [157750/160000]  base_lr: 2.1541e-06 lr: 2.1541e-07  eta: 0:15:32  time: 0.4194  data_time: 0.0103  memory: 5984  grad_norm: 288.7976  loss: 14.1880  decode.loss_cls: 0.1302  decode.loss_mask: 0.7129  decode.loss_dice: 0.5460  decode.d0.loss_cls: 0.4928  decode.d0.loss_mask: 0.6989  decode.d0.loss_dice: 0.5429  decode.d1.loss_cls: 0.1515  decode.d1.loss_mask: 0.6978  decode.d1.loss_dice: 0.5149  decode.d2.loss_cls: 0.1064  decode.d2.loss_mask: 0.7141  decode.d2.loss_dice: 0.5478  decode.d3.loss_cls: 0.1308  decode.d3.loss_mask: 0.7126  decode.d3.loss_dice: 0.5409  decode.d4.loss_cls: 0.1313  decode.d4.loss_mask: 0.7127  decode.d4.loss_dice: 0.5332  decode.d5.loss_cls: 0.1376  decode.d5.loss_mask: 0.7051  decode.d5.loss_dice: 0.5350  decode.d6.loss_cls: 0.1323  decode.d6.loss_mask: 0.7119  decode.d6.loss_dice: 0.5432  decode.d7.loss_cls: 0.1283  decode.d7.loss_mask: 0.7281  decode.d7.loss_dice: 0.5486  decode.d8.loss_cls: 0.1403  decode.d8.loss_mask: 0.7109  decode.d8.loss_dice: 0.5490
05/27 05:42:39 - mmengine - INFO - Iter(train) [157800/160000]  base_lr: 2.1109e-06 lr: 2.1109e-07  eta: 0:15:11  time: 0.4187  data_time: 0.0101  memory: 5966  grad_norm: 325.2057  loss: 14.9112  decode.loss_cls: 0.1223  decode.loss_mask: 0.7427  decode.loss_dice: 0.5770  decode.d0.loss_cls: 0.4797  decode.d0.loss_mask: 0.7711  decode.d0.loss_dice: 0.6074  decode.d1.loss_cls: 0.1082  decode.d1.loss_mask: 0.7535  decode.d1.loss_dice: 0.5892  decode.d2.loss_cls: 0.1153  decode.d2.loss_mask: 0.7512  decode.d2.loss_dice: 0.5931  decode.d3.loss_cls: 0.1090  decode.d3.loss_mask: 0.7483  decode.d3.loss_dice: 0.5875  decode.d4.loss_cls: 0.1052  decode.d4.loss_mask: 0.7466  decode.d4.loss_dice: 0.5987  decode.d5.loss_cls: 0.1127  decode.d5.loss_mask: 0.7456  decode.d5.loss_dice: 0.5968  decode.d6.loss_cls: 0.1264  decode.d6.loss_mask: 0.7440  decode.d6.loss_dice: 0.5907  decode.d7.loss_cls: 0.1343  decode.d7.loss_mask: 0.7475  decode.d7.loss_dice: 0.5822  decode.d8.loss_cls: 0.0980  decode.d8.loss_mask: 0.7455  decode.d8.loss_dice: 0.5815
05/27 05:43:00 - mmengine - INFO - Iter(train) [157850/160000]  base_lr: 2.0677e-06 lr: 2.0677e-07  eta: 0:14:51  time: 0.4192  data_time: 0.0102  memory: 5965  grad_norm: 244.2280  loss: 16.2701  decode.loss_cls: 0.2134  decode.loss_mask: 0.7971  decode.loss_dice: 0.5878  decode.d0.loss_cls: 0.5984  decode.d0.loss_mask: 0.7755  decode.d0.loss_dice: 0.6249  decode.d1.loss_cls: 0.2612  decode.d1.loss_mask: 0.7861  decode.d1.loss_dice: 0.5933  decode.d2.loss_cls: 0.2046  decode.d2.loss_mask: 0.7745  decode.d2.loss_dice: 0.5726  decode.d3.loss_cls: 0.2253  decode.d3.loss_mask: 0.7830  decode.d3.loss_dice: 0.5888  decode.d4.loss_cls: 0.1973  decode.d4.loss_mask: 0.7857  decode.d4.loss_dice: 0.5853  decode.d5.loss_cls: 0.2052  decode.d5.loss_mask: 0.7961  decode.d5.loss_dice: 0.5878  decode.d6.loss_cls: 0.2246  decode.d6.loss_mask: 0.7946  decode.d6.loss_dice: 0.5913  decode.d7.loss_cls: 0.1901  decode.d7.loss_mask: 0.7880  decode.d7.loss_dice: 0.5837  decode.d8.loss_cls: 0.2009  decode.d8.loss_mask: 0.7798  decode.d8.loss_dice: 0.5731
05/27 05:43:21 - mmengine - INFO - Iter(train) [157900/160000]  base_lr: 2.0244e-06 lr: 2.0244e-07  eta: 0:14:30  time: 0.4190  data_time: 0.0101  memory: 5981  grad_norm: 324.2105  loss: 16.7871  decode.loss_cls: 0.1322  decode.loss_mask: 0.8897  decode.loss_dice: 0.5978  decode.d0.loss_cls: 0.6050  decode.d0.loss_mask: 0.9076  decode.d0.loss_dice: 0.5917  decode.d1.loss_cls: 0.1587  decode.d1.loss_mask: 0.8929  decode.d1.loss_dice: 0.5755  decode.d2.loss_cls: 0.1804  decode.d2.loss_mask: 0.8679  decode.d2.loss_dice: 0.5828  decode.d3.loss_cls: 0.1787  decode.d3.loss_mask: 0.8740  decode.d3.loss_dice: 0.6009  decode.d4.loss_cls: 0.1437  decode.d4.loss_mask: 0.8691  decode.d4.loss_dice: 0.5957  decode.d5.loss_cls: 0.1665  decode.d5.loss_mask: 0.8882  decode.d5.loss_dice: 0.5752  decode.d6.loss_cls: 0.1776  decode.d6.loss_mask: 0.8736  decode.d6.loss_dice: 0.6035  decode.d7.loss_cls: 0.1328  decode.d7.loss_mask: 0.8860  decode.d7.loss_dice: 0.6024  decode.d8.loss_cls: 0.1640  decode.d8.loss_mask: 0.8919  decode.d8.loss_dice: 0.5812
05/27 05:43:42 - mmengine - INFO - Iter(train) [157950/160000]  base_lr: 1.9809e-06 lr: 1.9809e-07  eta: 0:14:09  time: 0.4199  data_time: 0.0101  memory: 5990  grad_norm: 430.1575  loss: 17.8291  decode.loss_cls: 0.1253  decode.loss_mask: 0.9047  decode.loss_dice: 0.6875  decode.d0.loss_cls: 0.6107  decode.d0.loss_mask: 0.9145  decode.d0.loss_dice: 0.6921  decode.d1.loss_cls: 0.1261  decode.d1.loss_mask: 0.9200  decode.d1.loss_dice: 0.7027  decode.d2.loss_cls: 0.1338  decode.d2.loss_mask: 0.9202  decode.d2.loss_dice: 0.7035  decode.d3.loss_cls: 0.1005  decode.d3.loss_mask: 0.9178  decode.d3.loss_dice: 0.6990  decode.d4.loss_cls: 0.1168  decode.d4.loss_mask: 0.9187  decode.d4.loss_dice: 0.7045  decode.d5.loss_cls: 0.1306  decode.d5.loss_mask: 0.9156  decode.d5.loss_dice: 0.6983  decode.d6.loss_cls: 0.1071  decode.d6.loss_mask: 0.9144  decode.d6.loss_dice: 0.7041  decode.d7.loss_cls: 0.1414  decode.d7.loss_mask: 0.9106  decode.d7.loss_dice: 0.6850  decode.d8.loss_cls: 0.1258  decode.d8.loss_mask: 0.9042  decode.d8.loss_dice: 0.6936
05/27 05:44:03 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 05:44:03 - mmengine - INFO - Iter(train) [158000/160000]  base_lr: 1.9374e-06 lr: 1.9374e-07  eta: 0:13:48  time: 0.4192  data_time: 0.0101  memory: 5979  grad_norm: 515.7883  loss: 21.2219  decode.loss_cls: 0.1544  decode.loss_mask: 1.1470  decode.loss_dice: 0.7827  decode.d0.loss_cls: 0.7180  decode.d0.loss_mask: 1.0469  decode.d0.loss_dice: 0.7261  decode.d1.loss_cls: 0.2022  decode.d1.loss_mask: 1.1176  decode.d1.loss_dice: 0.7677  decode.d2.loss_cls: 0.1894  decode.d2.loss_mask: 1.1146  decode.d2.loss_dice: 0.7531  decode.d3.loss_cls: 0.2144  decode.d3.loss_mask: 1.1048  decode.d3.loss_dice: 0.7513  decode.d4.loss_cls: 0.1993  decode.d4.loss_mask: 1.1360  decode.d4.loss_dice: 0.7615  decode.d5.loss_cls: 0.1830  decode.d5.loss_mask: 1.1375  decode.d5.loss_dice: 0.7658  decode.d6.loss_cls: 0.1907  decode.d6.loss_mask: 1.0947  decode.d6.loss_dice: 0.7616  decode.d7.loss_cls: 0.1514  decode.d7.loss_mask: 1.1640  decode.d7.loss_dice: 0.8003  decode.d8.loss_cls: 0.1623  decode.d8.loss_mask: 1.1405  decode.d8.loss_dice: 0.7832
05/27 05:44:24 - mmengine - INFO - Iter(train) [158050/160000]  base_lr: 1.8938e-06 lr: 1.8938e-07  eta: 0:13:28  time: 0.4187  data_time: 0.0101  memory: 5975  grad_norm: 555.6412  loss: 20.6849  decode.loss_cls: 0.1701  decode.loss_mask: 1.0964  decode.loss_dice: 0.7041  decode.d0.loss_cls: 0.8091  decode.d0.loss_mask: 1.0338  decode.d0.loss_dice: 0.6675  decode.d1.loss_cls: 0.1611  decode.d1.loss_mask: 1.1362  decode.d1.loss_dice: 0.7299  decode.d2.loss_cls: 0.1873  decode.d2.loss_mask: 1.1263  decode.d2.loss_dice: 0.7063  decode.d3.loss_cls: 0.1963  decode.d3.loss_mask: 1.1028  decode.d3.loss_dice: 0.6997  decode.d4.loss_cls: 0.1885  decode.d4.loss_mask: 1.1747  decode.d4.loss_dice: 0.7093  decode.d5.loss_cls: 0.1761  decode.d5.loss_mask: 1.1685  decode.d5.loss_dice: 0.7168  decode.d6.loss_cls: 0.1602  decode.d6.loss_mask: 1.1356  decode.d6.loss_dice: 0.7310  decode.d7.loss_cls: 0.1679  decode.d7.loss_mask: 1.1325  decode.d7.loss_dice: 0.7179  decode.d8.loss_cls: 0.1964  decode.d8.loss_mask: 1.0923  decode.d8.loss_dice: 0.6903
05/27 05:44:45 - mmengine - INFO - Iter(train) [158100/160000]  base_lr: 1.8500e-06 lr: 1.8500e-07  eta: 0:13:07  time: 0.4192  data_time: 0.0101  memory: 5976  grad_norm: 549.6516  loss: 18.1177  decode.loss_cls: 0.1283  decode.loss_mask: 0.9315  decode.loss_dice: 0.7074  decode.d0.loss_cls: 0.6628  decode.d0.loss_mask: 0.8532  decode.d0.loss_dice: 0.6825  decode.d1.loss_cls: 0.1755  decode.d1.loss_mask: 0.9186  decode.d1.loss_dice: 0.7130  decode.d2.loss_cls: 0.1364  decode.d2.loss_mask: 0.9187  decode.d2.loss_dice: 0.7329  decode.d3.loss_cls: 0.1355  decode.d3.loss_mask: 0.9162  decode.d3.loss_dice: 0.6938  decode.d4.loss_cls: 0.1534  decode.d4.loss_mask: 0.9213  decode.d4.loss_dice: 0.6972  decode.d5.loss_cls: 0.1332  decode.d5.loss_mask: 0.9225  decode.d5.loss_dice: 0.7295  decode.d6.loss_cls: 0.1509  decode.d6.loss_mask: 0.8542  decode.d6.loss_dice: 0.6807  decode.d7.loss_cls: 0.1307  decode.d7.loss_mask: 0.9241  decode.d7.loss_dice: 0.7081  decode.d8.loss_cls: 0.1618  decode.d8.loss_mask: 0.9249  decode.d8.loss_dice: 0.7187
05/27 05:45:06 - mmengine - INFO - Iter(train) [158150/160000]  base_lr: 1.8061e-06 lr: 1.8061e-07  eta: 0:12:46  time: 0.4197  data_time: 0.0102  memory: 5984  grad_norm: 526.2525  loss: 19.1064  decode.loss_cls: 0.1643  decode.loss_mask: 0.9892  decode.loss_dice: 0.6990  decode.d0.loss_cls: 0.6476  decode.d0.loss_mask: 0.9943  decode.d0.loss_dice: 0.7069  decode.d1.loss_cls: 0.1938  decode.d1.loss_mask: 1.0188  decode.d1.loss_dice: 0.7051  decode.d2.loss_cls: 0.1817  decode.d2.loss_mask: 0.9817  decode.d2.loss_dice: 0.7010  decode.d3.loss_cls: 0.1712  decode.d3.loss_mask: 0.9797  decode.d3.loss_dice: 0.6918  decode.d4.loss_cls: 0.1673  decode.d4.loss_mask: 0.9953  decode.d4.loss_dice: 0.6989  decode.d5.loss_cls: 0.1407  decode.d5.loss_mask: 0.9837  decode.d5.loss_dice: 0.7157  decode.d6.loss_cls: 0.1753  decode.d6.loss_mask: 0.9698  decode.d6.loss_dice: 0.6848  decode.d7.loss_cls: 0.1610  decode.d7.loss_mask: 1.0020  decode.d7.loss_dice: 0.7391  decode.d8.loss_cls: 0.1427  decode.d8.loss_mask: 0.9855  decode.d8.loss_dice: 0.7186
05/27 05:45:27 - mmengine - INFO - Iter(train) [158200/160000]  base_lr: 1.7621e-06 lr: 1.7621e-07  eta: 0:12:26  time: 0.4205  data_time: 0.0101  memory: 5974  grad_norm: 649.1346  loss: 16.2570  decode.loss_cls: 0.0753  decode.loss_mask: 0.8846  decode.loss_dice: 0.6071  decode.d0.loss_cls: 0.4882  decode.d0.loss_mask: 0.9091  decode.d0.loss_dice: 0.6257  decode.d1.loss_cls: 0.1066  decode.d1.loss_mask: 0.9309  decode.d1.loss_dice: 0.6148  decode.d2.loss_cls: 0.1067  decode.d2.loss_mask: 0.8791  decode.d2.loss_dice: 0.5984  decode.d3.loss_cls: 0.0909  decode.d3.loss_mask: 0.8803  decode.d3.loss_dice: 0.6105  decode.d4.loss_cls: 0.0796  decode.d4.loss_mask: 0.8764  decode.d4.loss_dice: 0.6035  decode.d5.loss_cls: 0.0807  decode.d5.loss_mask: 0.8774  decode.d5.loss_dice: 0.6109  decode.d6.loss_cls: 0.0850  decode.d6.loss_mask: 0.8840  decode.d6.loss_dice: 0.6070  decode.d7.loss_cls: 0.0862  decode.d7.loss_mask: 0.8792  decode.d7.loss_dice: 0.6068  decode.d8.loss_cls: 0.0789  decode.d8.loss_mask: 0.8835  decode.d8.loss_dice: 0.6097
05/27 05:45:48 - mmengine - INFO - Iter(train) [158250/160000]  base_lr: 1.7180e-06 lr: 1.7180e-07  eta: 0:12:05  time: 0.4205  data_time: 0.0101  memory: 5971  grad_norm: 409.8551  loss: 17.7438  decode.loss_cls: 0.1296  decode.loss_mask: 0.8993  decode.loss_dice: 0.6791  decode.d0.loss_cls: 0.5812  decode.d0.loss_mask: 0.9794  decode.d0.loss_dice: 0.7001  decode.d1.loss_cls: 0.1052  decode.d1.loss_mask: 0.9818  decode.d1.loss_dice: 0.6982  decode.d2.loss_cls: 0.1018  decode.d2.loss_mask: 0.8999  decode.d2.loss_dice: 0.6887  decode.d3.loss_cls: 0.1206  decode.d3.loss_mask: 0.8985  decode.d3.loss_dice: 0.6962  decode.d4.loss_cls: 0.0893  decode.d4.loss_mask: 0.9827  decode.d4.loss_dice: 0.7024  decode.d5.loss_cls: 0.1231  decode.d5.loss_mask: 0.9088  decode.d5.loss_dice: 0.6919  decode.d6.loss_cls: 0.1082  decode.d6.loss_mask: 0.8997  decode.d6.loss_dice: 0.6742  decode.d7.loss_cls: 0.1201  decode.d7.loss_mask: 0.8920  decode.d7.loss_dice: 0.6796  decode.d8.loss_cls: 0.1306  decode.d8.loss_mask: 0.8977  decode.d8.loss_dice: 0.6840
05/27 05:46:09 - mmengine - INFO - Iter(train) [158300/160000]  base_lr: 1.6738e-06 lr: 1.6738e-07  eta: 0:11:44  time: 0.4196  data_time: 0.0101  memory: 5971  grad_norm: 398.8990  loss: 15.6476  decode.loss_cls: 0.0744  decode.loss_mask: 0.8522  decode.loss_dice: 0.5909  decode.d0.loss_cls: 0.6114  decode.d0.loss_mask: 0.8003  decode.d0.loss_dice: 0.5625  decode.d1.loss_cls: 0.1226  decode.d1.loss_mask: 0.8455  decode.d1.loss_dice: 0.5808  decode.d2.loss_cls: 0.1094  decode.d2.loss_mask: 0.8372  decode.d2.loss_dice: 0.5765  decode.d3.loss_cls: 0.0982  decode.d3.loss_mask: 0.8475  decode.d3.loss_dice: 0.5780  decode.d4.loss_cls: 0.0873  decode.d4.loss_mask: 0.8448  decode.d4.loss_dice: 0.5721  decode.d5.loss_cls: 0.0893  decode.d5.loss_mask: 0.8459  decode.d5.loss_dice: 0.5932  decode.d6.loss_cls: 0.0771  decode.d6.loss_mask: 0.8494  decode.d6.loss_dice: 0.5909  decode.d7.loss_cls: 0.0646  decode.d7.loss_mask: 0.8431  decode.d7.loss_dice: 0.6008  decode.d8.loss_cls: 0.0680  decode.d8.loss_mask: 0.8429  decode.d8.loss_dice: 0.5907
05/27 05:46:30 - mmengine - INFO - Iter(train) [158350/160000]  base_lr: 1.6294e-06 lr: 1.6294e-07  eta: 0:11:23  time: 0.4194  data_time: 0.0101  memory: 5968  grad_norm: 623.2608  loss: 17.1342  decode.loss_cls: 0.0871  decode.loss_mask: 0.8909  decode.loss_dice: 0.6711  decode.d0.loss_cls: 0.6005  decode.d0.loss_mask: 0.9144  decode.d0.loss_dice: 0.6922  decode.d1.loss_cls: 0.0908  decode.d1.loss_mask: 0.9174  decode.d1.loss_dice: 0.6753  decode.d2.loss_cls: 0.1138  decode.d2.loss_mask: 0.8834  decode.d2.loss_dice: 0.6706  decode.d3.loss_cls: 0.1124  decode.d3.loss_mask: 0.8443  decode.d3.loss_dice: 0.6539  decode.d4.loss_cls: 0.1051  decode.d4.loss_mask: 0.8982  decode.d4.loss_dice: 0.6762  decode.d5.loss_cls: 0.1046  decode.d5.loss_mask: 0.8674  decode.d5.loss_dice: 0.6716  decode.d6.loss_cls: 0.0930  decode.d6.loss_mask: 0.8984  decode.d6.loss_dice: 0.6871  decode.d7.loss_cls: 0.1033  decode.d7.loss_mask: 0.8938  decode.d7.loss_dice: 0.6613  decode.d8.loss_cls: 0.0947  decode.d8.loss_mask: 0.8881  decode.d8.loss_dice: 0.6733
05/27 05:46:51 - mmengine - INFO - Iter(train) [158400/160000]  base_lr: 1.5849e-06 lr: 1.5849e-07  eta: 0:11:03  time: 0.4212  data_time: 0.0104  memory: 5989  grad_norm: 296.7548  loss: 17.3538  decode.loss_cls: 0.2817  decode.loss_mask: 0.7866  decode.loss_dice: 0.6075  decode.d0.loss_cls: 0.7022  decode.d0.loss_mask: 0.7972  decode.d0.loss_dice: 0.6395  decode.d1.loss_cls: 0.3111  decode.d1.loss_mask: 0.7957  decode.d1.loss_dice: 0.6330  decode.d2.loss_cls: 0.2686  decode.d2.loss_mask: 0.8133  decode.d2.loss_dice: 0.6169  decode.d3.loss_cls: 0.2555  decode.d3.loss_mask: 0.8038  decode.d3.loss_dice: 0.6365  decode.d4.loss_cls: 0.2358  decode.d4.loss_mask: 0.7956  decode.d4.loss_dice: 0.6306  decode.d5.loss_cls: 0.2367  decode.d5.loss_mask: 0.7863  decode.d5.loss_dice: 0.6327  decode.d6.loss_cls: 0.2570  decode.d6.loss_mask: 0.7981  decode.d6.loss_dice: 0.6325  decode.d7.loss_cls: 0.2828  decode.d7.loss_mask: 0.8008  decode.d7.loss_dice: 0.6173  decode.d8.loss_cls: 0.2674  decode.d8.loss_mask: 0.7964  decode.d8.loss_dice: 0.6346
05/27 05:47:12 - mmengine - INFO - Iter(train) [158450/160000]  base_lr: 1.5403e-06 lr: 1.5403e-07  eta: 0:10:42  time: 0.4194  data_time: 0.0101  memory: 5967  grad_norm: 383.1832  loss: 15.9779  decode.loss_cls: 0.1844  decode.loss_mask: 0.7086  decode.loss_dice: 0.6397  decode.d0.loss_cls: 0.6001  decode.d0.loss_mask: 0.7867  decode.d0.loss_dice: 0.7024  decode.d1.loss_cls: 0.1615  decode.d1.loss_mask: 0.7392  decode.d1.loss_dice: 0.6703  decode.d2.loss_cls: 0.1847  decode.d2.loss_mask: 0.7189  decode.d2.loss_dice: 0.6561  decode.d3.loss_cls: 0.1727  decode.d3.loss_mask: 0.7126  decode.d3.loss_dice: 0.6286  decode.d4.loss_cls: 0.1947  decode.d4.loss_mask: 0.7162  decode.d4.loss_dice: 0.6478  decode.d5.loss_cls: 0.1870  decode.d5.loss_mask: 0.6996  decode.d5.loss_dice: 0.6323  decode.d6.loss_cls: 0.1751  decode.d6.loss_mask: 0.7117  decode.d6.loss_dice: 0.6513  decode.d7.loss_cls: 0.1964  decode.d7.loss_mask: 0.7173  decode.d7.loss_dice: 0.6607  decode.d8.loss_cls: 0.1744  decode.d8.loss_mask: 0.7026  decode.d8.loss_dice: 0.6444
05/27 05:47:33 - mmengine - INFO - Iter(train) [158500/160000]  base_lr: 1.4955e-06 lr: 1.4955e-07  eta: 0:10:21  time: 0.4197  data_time: 0.0101  memory: 5981  grad_norm: 375.0246  loss: 13.8410  decode.loss_cls: 0.0941  decode.loss_mask: 0.7410  decode.loss_dice: 0.4918  decode.d0.loss_cls: 0.5719  decode.d0.loss_mask: 0.6892  decode.d0.loss_dice: 0.4816  decode.d1.loss_cls: 0.1434  decode.d1.loss_mask: 0.7322  decode.d1.loss_dice: 0.4963  decode.d2.loss_cls: 0.1266  decode.d2.loss_mask: 0.7327  decode.d2.loss_dice: 0.4839  decode.d3.loss_cls: 0.1119  decode.d3.loss_mask: 0.7257  decode.d3.loss_dice: 0.4833  decode.d4.loss_cls: 0.1229  decode.d4.loss_mask: 0.7320  decode.d4.loss_dice: 0.4786  decode.d5.loss_cls: 0.1305  decode.d5.loss_mask: 0.7256  decode.d5.loss_dice: 0.4810  decode.d6.loss_cls: 0.1400  decode.d6.loss_mask: 0.7273  decode.d6.loss_dice: 0.4836  decode.d7.loss_cls: 0.1169  decode.d7.loss_mask: 0.7375  decode.d7.loss_dice: 0.4985  decode.d8.loss_cls: 0.1080  decode.d8.loss_mask: 0.7512  decode.d8.loss_dice: 0.5018
05/27 05:47:54 - mmengine - INFO - Iter(train) [158550/160000]  base_lr: 1.4505e-06 lr: 1.4505e-07  eta: 0:10:00  time: 0.4198  data_time: 0.0101  memory: 5990  grad_norm: 476.2277  loss: 18.8206  decode.loss_cls: 0.1265  decode.loss_mask: 1.0393  decode.loss_dice: 0.6478  decode.d0.loss_cls: 0.4995  decode.d0.loss_mask: 1.1041  decode.d0.loss_dice: 0.6900  decode.d1.loss_cls: 0.1320  decode.d1.loss_mask: 1.0696  decode.d1.loss_dice: 0.6728  decode.d2.loss_cls: 0.1287  decode.d2.loss_mask: 1.0555  decode.d2.loss_dice: 0.6497  decode.d3.loss_cls: 0.1236  decode.d3.loss_mask: 1.0591  decode.d3.loss_dice: 0.6447  decode.d4.loss_cls: 0.1278  decode.d4.loss_mask: 1.0441  decode.d4.loss_dice: 0.6467  decode.d5.loss_cls: 0.1166  decode.d5.loss_mask: 1.0636  decode.d5.loss_dice: 0.6499  decode.d6.loss_cls: 0.1299  decode.d6.loss_mask: 1.0616  decode.d6.loss_dice: 0.6605  decode.d7.loss_cls: 0.1302  decode.d7.loss_mask: 1.0594  decode.d7.loss_dice: 0.6520  decode.d8.loss_cls: 0.1346  decode.d8.loss_mask: 1.0511  decode.d8.loss_dice: 0.6498
05/27 05:48:15 - mmengine - INFO - Iter(train) [158600/160000]  base_lr: 1.4054e-06 lr: 1.4054e-07  eta: 0:09:40  time: 0.4187  data_time: 0.0101  memory: 5969  grad_norm: 449.3770  loss: 17.8769  decode.loss_cls: 0.1103  decode.loss_mask: 0.9616  decode.loss_dice: 0.6376  decode.d0.loss_cls: 0.6475  decode.d0.loss_mask: 0.9781  decode.d0.loss_dice: 0.7113  decode.d1.loss_cls: 0.1197  decode.d1.loss_mask: 0.9929  decode.d1.loss_dice: 0.6506  decode.d2.loss_cls: 0.1115  decode.d2.loss_mask: 0.9692  decode.d2.loss_dice: 0.6349  decode.d3.loss_cls: 0.1043  decode.d3.loss_mask: 0.9728  decode.d3.loss_dice: 0.6292  decode.d4.loss_cls: 0.1215  decode.d4.loss_mask: 0.9724  decode.d4.loss_dice: 0.6367  decode.d5.loss_cls: 0.1218  decode.d5.loss_mask: 0.9752  decode.d5.loss_dice: 0.6317  decode.d6.loss_cls: 0.1011  decode.d6.loss_mask: 0.9839  decode.d6.loss_dice: 0.6512  decode.d7.loss_cls: 0.1058  decode.d7.loss_mask: 0.9718  decode.d7.loss_dice: 0.6457  decode.d8.loss_cls: 0.1172  decode.d8.loss_mask: 0.9781  decode.d8.loss_dice: 0.6312
05/27 05:48:36 - mmengine - INFO - Iter(train) [158650/160000]  base_lr: 1.3602e-06 lr: 1.3602e-07  eta: 0:09:19  time: 0.4196  data_time: 0.0102  memory: 5965  grad_norm: 417.1663  loss: 17.5967  decode.loss_cls: 0.0905  decode.loss_mask: 1.0202  decode.loss_dice: 0.5811  decode.d0.loss_cls: 0.5657  decode.d0.loss_mask: 1.0075  decode.d0.loss_dice: 0.6243  decode.d1.loss_cls: 0.1234  decode.d1.loss_mask: 1.0020  decode.d1.loss_dice: 0.6040  decode.d2.loss_cls: 0.0822  decode.d2.loss_mask: 1.0495  decode.d2.loss_dice: 0.5949  decode.d3.loss_cls: 0.0958  decode.d3.loss_mask: 1.0460  decode.d3.loss_dice: 0.6036  decode.d4.loss_cls: 0.0920  decode.d4.loss_mask: 1.0201  decode.d4.loss_dice: 0.5925  decode.d5.loss_cls: 0.0750  decode.d5.loss_mask: 1.0509  decode.d5.loss_dice: 0.5907  decode.d6.loss_cls: 0.0836  decode.d6.loss_mask: 1.0140  decode.d6.loss_dice: 0.5854  decode.d7.loss_cls: 0.1127  decode.d7.loss_mask: 0.9937  decode.d7.loss_dice: 0.5896  decode.d8.loss_cls: 0.1095  decode.d8.loss_mask: 1.0065  decode.d8.loss_dice: 0.5896
05/27 05:48:57 - mmengine - INFO - Iter(train) [158700/160000]  base_lr: 1.3148e-06 lr: 1.3148e-07  eta: 0:08:58  time: 0.4193  data_time: 0.0101  memory: 5971  grad_norm: 357.4531  loss: 16.8086  decode.loss_cls: 0.0927  decode.loss_mask: 0.8794  decode.loss_dice: 0.6594  decode.d0.loss_cls: 0.5606  decode.d0.loss_mask: 0.8628  decode.d0.loss_dice: 0.6335  decode.d1.loss_cls: 0.1103  decode.d1.loss_mask: 0.8814  decode.d1.loss_dice: 0.6637  decode.d2.loss_cls: 0.1078  decode.d2.loss_mask: 0.8822  decode.d2.loss_dice: 0.6463  decode.d3.loss_cls: 0.0948  decode.d3.loss_mask: 0.8799  decode.d3.loss_dice: 0.6690  decode.d4.loss_cls: 0.1033  decode.d4.loss_mask: 0.8728  decode.d4.loss_dice: 0.6537  decode.d5.loss_cls: 0.1072  decode.d5.loss_mask: 0.8804  decode.d5.loss_dice: 0.6551  decode.d6.loss_cls: 0.1291  decode.d6.loss_mask: 0.8772  decode.d6.loss_dice: 0.6494  decode.d7.loss_cls: 0.0996  decode.d7.loss_mask: 0.8764  decode.d7.loss_dice: 0.6551  decode.d8.loss_cls: 0.1079  decode.d8.loss_mask: 0.8656  decode.d8.loss_dice: 0.6518
05/27 05:49:18 - mmengine - INFO - Iter(train) [158750/160000]  base_lr: 1.2692e-06 lr: 1.2692e-07  eta: 0:08:38  time: 0.4202  data_time: 0.0101  memory: 5966  grad_norm: 622.0530  loss: 19.0238  decode.loss_cls: 0.1569  decode.loss_mask: 1.0695  decode.loss_dice: 0.6550  decode.d0.loss_cls: 0.6166  decode.d0.loss_mask: 1.0206  decode.d0.loss_dice: 0.6365  decode.d1.loss_cls: 0.1736  decode.d1.loss_mask: 1.0770  decode.d1.loss_dice: 0.6632  decode.d2.loss_cls: 0.1410  decode.d2.loss_mask: 1.0775  decode.d2.loss_dice: 0.6639  decode.d3.loss_cls: 0.1599  decode.d3.loss_mask: 1.0604  decode.d3.loss_dice: 0.6757  decode.d4.loss_cls: 0.1666  decode.d4.loss_mask: 1.0035  decode.d4.loss_dice: 0.6544  decode.d5.loss_cls: 0.1578  decode.d5.loss_mask: 1.0597  decode.d5.loss_dice: 0.6700  decode.d6.loss_cls: 0.1811  decode.d6.loss_mask: 0.9836  decode.d6.loss_dice: 0.6593  decode.d7.loss_cls: 0.1799  decode.d7.loss_mask: 0.9935  decode.d7.loss_dice: 0.6649  decode.d8.loss_cls: 0.1582  decode.d8.loss_mask: 0.9982  decode.d8.loss_dice: 0.6459
05/27 05:49:39 - mmengine - INFO - Iter(train) [158800/160000]  base_lr: 1.2234e-06 lr: 1.2234e-07  eta: 0:08:17  time: 0.4198  data_time: 0.0101  memory: 5973  grad_norm: 336.5623  loss: 17.0294  decode.loss_cls: 0.1870  decode.loss_mask: 0.8352  decode.loss_dice: 0.6556  decode.d0.loss_cls: 0.7106  decode.d0.loss_mask: 0.8191  decode.d0.loss_dice: 0.6360  decode.d1.loss_cls: 0.2053  decode.d1.loss_mask: 0.8160  decode.d1.loss_dice: 0.6409  decode.d2.loss_cls: 0.1700  decode.d2.loss_mask: 0.8241  decode.d2.loss_dice: 0.6294  decode.d3.loss_cls: 0.1898  decode.d3.loss_mask: 0.8145  decode.d3.loss_dice: 0.6301  decode.d4.loss_cls: 0.1870  decode.d4.loss_mask: 0.8332  decode.d4.loss_dice: 0.6420  decode.d5.loss_cls: 0.1787  decode.d5.loss_mask: 0.8334  decode.d5.loss_dice: 0.6377  decode.d6.loss_cls: 0.1808  decode.d6.loss_mask: 0.8329  decode.d6.loss_dice: 0.6395  decode.d7.loss_cls: 0.1865  decode.d7.loss_mask: 0.8271  decode.d7.loss_dice: 0.6321  decode.d8.loss_cls: 0.1961  decode.d8.loss_mask: 0.8235  decode.d8.loss_dice: 0.6352
05/27 05:50:00 - mmengine - INFO - Iter(train) [158850/160000]  base_lr: 1.1774e-06 lr: 1.1774e-07  eta: 0:07:56  time: 0.4216  data_time: 0.0101  memory: 5966  grad_norm: 594.2968  loss: 20.4509  decode.loss_cls: 0.1552  decode.loss_mask: 1.0850  decode.loss_dice: 0.7074  decode.d0.loss_cls: 0.8570  decode.d0.loss_mask: 1.0921  decode.d0.loss_dice: 0.7141  decode.d1.loss_cls: 0.1825  decode.d1.loss_mask: 1.0932  decode.d1.loss_dice: 0.7140  decode.d2.loss_cls: 0.1497  decode.d2.loss_mask: 1.0859  decode.d2.loss_dice: 0.7195  decode.d3.loss_cls: 0.1510  decode.d3.loss_mask: 1.1271  decode.d3.loss_dice: 0.7203  decode.d4.loss_cls: 0.1634  decode.d4.loss_mask: 1.1102  decode.d4.loss_dice: 0.7215  decode.d5.loss_cls: 0.1460  decode.d5.loss_mask: 1.1123  decode.d5.loss_dice: 0.7234  decode.d6.loss_cls: 0.1281  decode.d6.loss_mask: 1.1151  decode.d6.loss_dice: 0.7318  decode.d7.loss_cls: 0.1629  decode.d7.loss_mask: 1.0981  decode.d7.loss_dice: 0.7209  decode.d8.loss_cls: 0.1554  decode.d8.loss_mask: 1.0981  decode.d8.loss_dice: 0.7098
05/27 05:50:21 - mmengine - INFO - Iter(train) [158900/160000]  base_lr: 1.1312e-06 lr: 1.1312e-07  eta: 0:07:35  time: 0.4187  data_time: 0.0101  memory: 5984  grad_norm: 703.5738  loss: 17.8741  decode.loss_cls: 0.1447  decode.loss_mask: 0.9356  decode.loss_dice: 0.6344  decode.d0.loss_cls: 0.7431  decode.d0.loss_mask: 0.8711  decode.d0.loss_dice: 0.6001  decode.d1.loss_cls: 0.1516  decode.d1.loss_mask: 0.9390  decode.d1.loss_dice: 0.6267  decode.d2.loss_cls: 0.1714  decode.d2.loss_mask: 0.9653  decode.d2.loss_dice: 0.6254  decode.d3.loss_cls: 0.1628  decode.d3.loss_mask: 0.9647  decode.d3.loss_dice: 0.6553  decode.d4.loss_cls: 0.1650  decode.d4.loss_mask: 0.9349  decode.d4.loss_dice: 0.6043  decode.d5.loss_cls: 0.1719  decode.d5.loss_mask: 0.9497  decode.d5.loss_dice: 0.6282  decode.d6.loss_cls: 0.1496  decode.d6.loss_mask: 0.9303  decode.d6.loss_dice: 0.6237  decode.d7.loss_cls: 0.1520  decode.d7.loss_mask: 0.9620  decode.d7.loss_dice: 0.6527  decode.d8.loss_cls: 0.1633  decode.d8.loss_mask: 0.9548  decode.d8.loss_dice: 0.6406
05/27 05:50:42 - mmengine - INFO - Iter(train) [158950/160000]  base_lr: 1.0848e-06 lr: 1.0848e-07  eta: 0:07:15  time: 0.4194  data_time: 0.0102  memory: 5969  grad_norm: 348.8119  loss: 15.7320  decode.loss_cls: 0.0658  decode.loss_mask: 0.8740  decode.loss_dice: 0.5755  decode.d0.loss_cls: 0.5738  decode.d0.loss_mask: 0.9031  decode.d0.loss_dice: 0.5781  decode.d1.loss_cls: 0.0633  decode.d1.loss_mask: 0.8748  decode.d1.loss_dice: 0.5730  decode.d2.loss_cls: 0.0704  decode.d2.loss_mask: 0.8754  decode.d2.loss_dice: 0.5774  decode.d3.loss_cls: 0.0699  decode.d3.loss_mask: 0.8864  decode.d3.loss_dice: 0.5742  decode.d4.loss_cls: 0.0533  decode.d4.loss_mask: 0.8864  decode.d4.loss_dice: 0.5885  decode.d5.loss_cls: 0.0648  decode.d5.loss_mask: 0.8769  decode.d5.loss_dice: 0.5831  decode.d6.loss_cls: 0.0611  decode.d6.loss_mask: 0.8798  decode.d6.loss_dice: 0.5832  decode.d7.loss_cls: 0.0522  decode.d7.loss_mask: 0.8807  decode.d7.loss_dice: 0.5780  decode.d8.loss_cls: 0.0486  decode.d8.loss_mask: 0.8844  decode.d8.loss_dice: 0.5760
05/27 05:51:03 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 05:51:03 - mmengine - INFO - Iter(train) [159000/160000]  base_lr: 1.0382e-06 lr: 1.0382e-07  eta: 0:06:54  time: 0.4190  data_time: 0.0101  memory: 5975  grad_norm: 365.6472  loss: 16.2191  decode.loss_cls: 0.0918  decode.loss_mask: 0.8478  decode.loss_dice: 0.6046  decode.d0.loss_cls: 0.6625  decode.d0.loss_mask: 0.8371  decode.d0.loss_dice: 0.6088  decode.d1.loss_cls: 0.1437  decode.d1.loss_mask: 0.8671  decode.d1.loss_dice: 0.6200  decode.d2.loss_cls: 0.0837  decode.d2.loss_mask: 0.8556  decode.d2.loss_dice: 0.6214  decode.d3.loss_cls: 0.0803  decode.d3.loss_mask: 0.8601  decode.d3.loss_dice: 0.6165  decode.d4.loss_cls: 0.0836  decode.d4.loss_mask: 0.8535  decode.d4.loss_dice: 0.6187  decode.d5.loss_cls: 0.0826  decode.d5.loss_mask: 0.8509  decode.d5.loss_dice: 0.6275  decode.d6.loss_cls: 0.0967  decode.d6.loss_mask: 0.8496  decode.d6.loss_dice: 0.6166  decode.d7.loss_cls: 0.0919  decode.d7.loss_mask: 0.8608  decode.d7.loss_dice: 0.6202  decode.d8.loss_cls: 0.0913  decode.d8.loss_mask: 0.8588  decode.d8.loss_dice: 0.6154
05/27 05:51:24 - mmengine - INFO - Iter(train) [159050/160000]  base_lr: 9.9139e-07 lr: 9.9139e-08  eta: 0:06:33  time: 0.4194  data_time: 0.0102  memory: 5967  grad_norm: 433.5513  loss: 16.9762  decode.loss_cls: 0.2111  decode.loss_mask: 0.7867  decode.loss_dice: 0.6198  decode.d0.loss_cls: 0.7697  decode.d0.loss_mask: 0.7817  decode.d0.loss_dice: 0.6078  decode.d1.loss_cls: 0.2589  decode.d1.loss_mask: 0.7736  decode.d1.loss_dice: 0.6428  decode.d2.loss_cls: 0.2450  decode.d2.loss_mask: 0.7917  decode.d2.loss_dice: 0.6225  decode.d3.loss_cls: 0.2350  decode.d3.loss_mask: 0.7862  decode.d3.loss_dice: 0.6084  decode.d4.loss_cls: 0.2131  decode.d4.loss_mask: 0.7967  decode.d4.loss_dice: 0.6257  decode.d5.loss_cls: 0.2297  decode.d5.loss_mask: 0.8175  decode.d5.loss_dice: 0.6403  decode.d6.loss_cls: 0.2285  decode.d6.loss_mask: 0.7863  decode.d6.loss_dice: 0.6094  decode.d7.loss_cls: 0.2153  decode.d7.loss_mask: 0.7735  decode.d7.loss_dice: 0.6490  decode.d8.loss_cls: 0.1978  decode.d8.loss_mask: 0.8008  decode.d8.loss_dice: 0.6522
05/27 05:51:45 - mmengine - INFO - Iter(train) [159100/160000]  base_lr: 9.4431e-07 lr: 9.4431e-08  eta: 0:06:13  time: 0.4194  data_time: 0.0103  memory: 5969  grad_norm: 883.8864  loss: 20.8043  decode.loss_cls: 0.1804  decode.loss_mask: 1.1111  decode.loss_dice: 0.7632  decode.d0.loss_cls: 0.7252  decode.d0.loss_mask: 1.0341  decode.d0.loss_dice: 0.7378  decode.d1.loss_cls: 0.1577  decode.d1.loss_mask: 1.1140  decode.d1.loss_dice: 0.7615  decode.d2.loss_cls: 0.1810  decode.d2.loss_mask: 1.0899  decode.d2.loss_dice: 0.7462  decode.d3.loss_cls: 0.1761  decode.d3.loss_mask: 1.0880  decode.d3.loss_dice: 0.7378  decode.d4.loss_cls: 0.1840  decode.d4.loss_mask: 1.0964  decode.d4.loss_dice: 0.7493  decode.d5.loss_cls: 0.1871  decode.d5.loss_mask: 1.0897  decode.d5.loss_dice: 0.7531  decode.d6.loss_cls: 0.1848  decode.d6.loss_mask: 1.0960  decode.d6.loss_dice: 0.7440  decode.d7.loss_cls: 0.1865  decode.d7.loss_mask: 1.1058  decode.d7.loss_dice: 0.7605  decode.d8.loss_cls: 0.1870  decode.d8.loss_mask: 1.1088  decode.d8.loss_dice: 0.7672
05/27 05:52:06 - mmengine - INFO - Iter(train) [159150/160000]  base_lr: 8.9696e-07 lr: 8.9696e-08  eta: 0:05:52  time: 0.4192  data_time: 0.0100  memory: 5976  grad_norm: 673.0878  loss: 16.1476  decode.loss_cls: 0.1021  decode.loss_mask: 0.8130  decode.loss_dice: 0.5871  decode.d0.loss_cls: 0.7126  decode.d0.loss_mask: 0.8007  decode.d0.loss_dice: 0.6081  decode.d1.loss_cls: 0.1334  decode.d1.loss_mask: 0.8217  decode.d1.loss_dice: 0.6170  decode.d2.loss_cls: 0.1117  decode.d2.loss_mask: 0.8295  decode.d2.loss_dice: 0.6067  decode.d3.loss_cls: 0.0996  decode.d3.loss_mask: 0.8477  decode.d3.loss_dice: 0.6169  decode.d4.loss_cls: 0.1208  decode.d4.loss_mask: 0.8372  decode.d4.loss_dice: 0.6188  decode.d5.loss_cls: 0.1323  decode.d5.loss_mask: 0.8270  decode.d5.loss_dice: 0.6085  decode.d6.loss_cls: 0.1151  decode.d6.loss_mask: 0.8422  decode.d6.loss_dice: 0.6141  decode.d7.loss_cls: 0.1120  decode.d7.loss_mask: 0.8357  decode.d7.loss_dice: 0.6114  decode.d8.loss_cls: 0.1054  decode.d8.loss_mask: 0.8410  decode.d8.loss_dice: 0.6183
05/27 05:52:27 - mmengine - INFO - Iter(train) [159200/160000]  base_lr: 8.4933e-07 lr: 8.4933e-08  eta: 0:05:31  time: 0.4203  data_time: 0.0101  memory: 5977  grad_norm: 567.5754  loss: 17.4817  decode.loss_cls: 0.1577  decode.loss_mask: 0.8761  decode.loss_dice: 0.6793  decode.d0.loss_cls: 0.7261  decode.d0.loss_mask: 0.8313  decode.d0.loss_dice: 0.6549  decode.d1.loss_cls: 0.1724  decode.d1.loss_mask: 0.8761  decode.d1.loss_dice: 0.6756  decode.d2.loss_cls: 0.1722  decode.d2.loss_mask: 0.8583  decode.d2.loss_dice: 0.6623  decode.d3.loss_cls: 0.1538  decode.d3.loss_mask: 0.8517  decode.d3.loss_dice: 0.6592  decode.d4.loss_cls: 0.1734  decode.d4.loss_mask: 0.8763  decode.d4.loss_dice: 0.6626  decode.d5.loss_cls: 0.1625  decode.d5.loss_mask: 0.8750  decode.d5.loss_dice: 0.6660  decode.d6.loss_cls: 0.1517  decode.d6.loss_mask: 0.8576  decode.d6.loss_dice: 0.6574  decode.d7.loss_cls: 0.1762  decode.d7.loss_mask: 0.8572  decode.d7.loss_dice: 0.6790  decode.d8.loss_cls: 0.1776  decode.d8.loss_mask: 0.8416  decode.d8.loss_dice: 0.6602
05/27 05:52:48 - mmengine - INFO - Iter(train) [159250/160000]  base_lr: 8.0140e-07 lr: 8.0140e-08  eta: 0:05:10  time: 0.4213  data_time: 0.0109  memory: 5982  grad_norm: 477.4937  loss: 17.8444  decode.loss_cls: 0.1755  decode.loss_mask: 0.9955  decode.loss_dice: 0.5984  decode.d0.loss_cls: 0.5156  decode.d0.loss_mask: 0.9864  decode.d0.loss_dice: 0.5964  decode.d1.loss_cls: 0.1422  decode.d1.loss_mask: 0.9882  decode.d1.loss_dice: 0.5999  decode.d2.loss_cls: 0.1561  decode.d2.loss_mask: 0.9778  decode.d2.loss_dice: 0.5934  decode.d3.loss_cls: 0.1806  decode.d3.loss_mask: 0.9828  decode.d3.loss_dice: 0.5954  decode.d4.loss_cls: 0.1738  decode.d4.loss_mask: 0.9818  decode.d4.loss_dice: 0.5966  decode.d5.loss_cls: 0.1690  decode.d5.loss_mask: 0.9825  decode.d5.loss_dice: 0.5997  decode.d6.loss_cls: 0.1640  decode.d6.loss_mask: 0.9814  decode.d6.loss_dice: 0.5993  decode.d7.loss_cls: 0.1670  decode.d7.loss_mask: 0.9907  decode.d7.loss_dice: 0.5921  decode.d8.loss_cls: 0.1599  decode.d8.loss_mask: 0.9978  decode.d8.loss_dice: 0.6046
05/27 05:53:09 - mmengine - INFO - Iter(train) [159300/160000]  base_lr: 7.5315e-07 lr: 7.5315e-08  eta: 0:04:50  time: 0.4201  data_time: 0.0102  memory: 5973  grad_norm: 902.0657  loss: 17.4810  decode.loss_cls: 0.1920  decode.loss_mask: 0.9040  decode.loss_dice: 0.5893  decode.d0.loss_cls: 0.6530  decode.d0.loss_mask: 0.8320  decode.d0.loss_dice: 0.5756  decode.d1.loss_cls: 0.1938  decode.d1.loss_mask: 0.9020  decode.d1.loss_dice: 0.6097  decode.d2.loss_cls: 0.1929  decode.d2.loss_mask: 0.9373  decode.d2.loss_dice: 0.6030  decode.d3.loss_cls: 0.1901  decode.d3.loss_mask: 0.9186  decode.d3.loss_dice: 0.5926  decode.d4.loss_cls: 0.2040  decode.d4.loss_mask: 0.9111  decode.d4.loss_dice: 0.6041  decode.d5.loss_cls: 0.1920  decode.d5.loss_mask: 0.9330  decode.d5.loss_dice: 0.5966  decode.d6.loss_cls: 0.2436  decode.d6.loss_mask: 0.9096  decode.d6.loss_dice: 0.5928  decode.d7.loss_cls: 0.1563  decode.d7.loss_mask: 0.9343  decode.d7.loss_dice: 0.6112  decode.d8.loss_cls: 0.2103  decode.d8.loss_mask: 0.9001  decode.d8.loss_dice: 0.5961
05/27 05:53:30 - mmengine - INFO - Iter(train) [159350/160000]  base_lr: 7.0456e-07 lr: 7.0456e-08  eta: 0:04:29  time: 0.4207  data_time: 0.0101  memory: 5967  grad_norm: 729.8688  loss: 18.5276  decode.loss_cls: 0.1953  decode.loss_mask: 0.9396  decode.loss_dice: 0.6595  decode.d0.loss_cls: 0.5873  decode.d0.loss_mask: 0.9297  decode.d0.loss_dice: 0.6652  decode.d1.loss_cls: 0.1787  decode.d1.loss_mask: 0.9309  decode.d1.loss_dice: 0.6876  decode.d2.loss_cls: 0.1785  decode.d2.loss_mask: 0.9575  decode.d2.loss_dice: 0.6693  decode.d3.loss_cls: 0.2153  decode.d3.loss_mask: 0.9667  decode.d3.loss_dice: 0.6559  decode.d4.loss_cls: 0.2057  decode.d4.loss_mask: 0.9356  decode.d4.loss_dice: 0.6657  decode.d5.loss_cls: 0.1948  decode.d5.loss_mask: 0.9434  decode.d5.loss_dice: 0.6803  decode.d6.loss_cls: 0.1960  decode.d6.loss_mask: 0.9594  decode.d6.loss_dice: 0.6769  decode.d7.loss_cls: 0.1988  decode.d7.loss_mask: 0.9424  decode.d7.loss_dice: 0.7079  decode.d8.loss_cls: 0.1849  decode.d8.loss_mask: 0.9529  decode.d8.loss_dice: 0.6660
05/27 05:53:51 - mmengine - INFO - Iter(train) [159400/160000]  base_lr: 6.5559e-07 lr: 6.5559e-08  eta: 0:04:08  time: 0.4194  data_time: 0.0100  memory: 5976  grad_norm: 452.2363  loss: 17.4064  decode.loss_cls: 0.1318  decode.loss_mask: 0.8819  decode.loss_dice: 0.6617  decode.d0.loss_cls: 0.6349  decode.d0.loss_mask: 0.9104  decode.d0.loss_dice: 0.6536  decode.d1.loss_cls: 0.1715  decode.d1.loss_mask: 0.8969  decode.d1.loss_dice: 0.6378  decode.d2.loss_cls: 0.1702  decode.d2.loss_mask: 0.9154  decode.d2.loss_dice: 0.6527  decode.d3.loss_cls: 0.1423  decode.d3.loss_mask: 0.8957  decode.d3.loss_dice: 0.6410  decode.d4.loss_cls: 0.1162  decode.d4.loss_mask: 0.8876  decode.d4.loss_dice: 0.6572  decode.d5.loss_cls: 0.1585  decode.d5.loss_mask: 0.8876  decode.d5.loss_dice: 0.6546  decode.d6.loss_cls: 0.1491  decode.d6.loss_mask: 0.8771  decode.d6.loss_dice: 0.6573  decode.d7.loss_cls: 0.1652  decode.d7.loss_mask: 0.8810  decode.d7.loss_dice: 0.6374  decode.d8.loss_cls: 0.1280  decode.d8.loss_mask: 0.8853  decode.d8.loss_dice: 0.6663
05/27 05:54:12 - mmengine - INFO - Iter(train) [159450/160000]  base_lr: 6.0621e-07 lr: 6.0621e-08  eta: 0:03:47  time: 0.4185  data_time: 0.0101  memory: 5970  grad_norm: 367.5900  loss: 19.7357  decode.loss_cls: 0.1208  decode.loss_mask: 1.1133  decode.loss_dice: 0.6872  decode.d0.loss_cls: 0.5615  decode.d0.loss_mask: 1.1199  decode.d0.loss_dice: 0.6838  decode.d1.loss_cls: 0.1393  decode.d1.loss_mask: 1.1081  decode.d1.loss_dice: 0.6797  decode.d2.loss_cls: 0.1239  decode.d2.loss_mask: 1.1108  decode.d2.loss_dice: 0.6883  decode.d3.loss_cls: 0.1373  decode.d3.loss_mask: 1.1196  decode.d3.loss_dice: 0.6842  decode.d4.loss_cls: 0.1284  decode.d4.loss_mask: 1.1106  decode.d4.loss_dice: 0.6757  decode.d5.loss_cls: 0.1428  decode.d5.loss_mask: 1.1242  decode.d5.loss_dice: 0.6859  decode.d6.loss_cls: 0.1244  decode.d6.loss_mask: 1.1208  decode.d6.loss_dice: 0.6860  decode.d7.loss_cls: 0.1261  decode.d7.loss_mask: 1.1120  decode.d7.loss_dice: 0.6864  decode.d8.loss_cls: 0.1311  decode.d8.loss_mask: 1.1150  decode.d8.loss_dice: 0.6885
05/27 05:54:33 - mmengine - INFO - Iter(train) [159500/160000]  base_lr: 5.5637e-07 lr: 5.5637e-08  eta: 0:03:27  time: 0.4183  data_time: 0.0101  memory: 5969  grad_norm: 717.5232  loss: 16.8271  decode.loss_cls: 0.1009  decode.loss_mask: 0.8608  decode.loss_dice: 0.6373  decode.d0.loss_cls: 0.5181  decode.d0.loss_mask: 0.8948  decode.d0.loss_dice: 0.6887  decode.d1.loss_cls: 0.1080  decode.d1.loss_mask: 0.8965  decode.d1.loss_dice: 0.6512  decode.d2.loss_cls: 0.0924  decode.d2.loss_mask: 0.9002  decode.d2.loss_dice: 0.6434  decode.d3.loss_cls: 0.0920  decode.d3.loss_mask: 0.8987  decode.d3.loss_dice: 0.6337  decode.d4.loss_cls: 0.0849  decode.d4.loss_mask: 0.8988  decode.d4.loss_dice: 0.6356  decode.d5.loss_cls: 0.0836  decode.d5.loss_mask: 0.9030  decode.d5.loss_dice: 0.6560  decode.d6.loss_cls: 0.0908  decode.d6.loss_mask: 0.9091  decode.d6.loss_dice: 0.6526  decode.d7.loss_cls: 0.0906  decode.d7.loss_mask: 0.8987  decode.d7.loss_dice: 0.6625  decode.d8.loss_cls: 0.0975  decode.d8.loss_mask: 0.9021  decode.d8.loss_dice: 0.6447
05/27 05:54:54 - mmengine - INFO - Iter(train) [159550/160000]  base_lr: 5.0604e-07 lr: 5.0604e-08  eta: 0:03:06  time: 0.4194  data_time: 0.0100  memory: 5980  grad_norm: 448.2697  loss: 17.4574  decode.loss_cls: 0.1217  decode.loss_mask: 0.9675  decode.loss_dice: 0.6067  decode.d0.loss_cls: 0.6691  decode.d0.loss_mask: 0.9371  decode.d0.loss_dice: 0.5951  decode.d1.loss_cls: 0.1164  decode.d1.loss_mask: 0.9778  decode.d1.loss_dice: 0.6304  decode.d2.loss_cls: 0.1363  decode.d2.loss_mask: 0.9551  decode.d2.loss_dice: 0.6137  decode.d3.loss_cls: 0.1405  decode.d3.loss_mask: 0.9385  decode.d3.loss_dice: 0.6079  decode.d4.loss_cls: 0.1427  decode.d4.loss_mask: 0.9549  decode.d4.loss_dice: 0.6091  decode.d5.loss_cls: 0.1302  decode.d5.loss_mask: 0.9367  decode.d5.loss_dice: 0.5951  decode.d6.loss_cls: 0.1353  decode.d6.loss_mask: 0.9728  decode.d6.loss_dice: 0.6234  decode.d7.loss_cls: 0.1284  decode.d7.loss_mask: 0.9553  decode.d7.loss_dice: 0.6172  decode.d8.loss_cls: 0.1351  decode.d8.loss_mask: 0.9250  decode.d8.loss_dice: 0.5822
05/27 05:55:15 - mmengine - INFO - Iter(train) [159600/160000]  base_lr: 4.5514e-07 lr: 4.5514e-08  eta: 0:02:45  time: 0.4184  data_time: 0.0100  memory: 5967  grad_norm: 309.3497  loss: 15.5993  decode.loss_cls: 0.1489  decode.loss_mask: 0.7938  decode.loss_dice: 0.5699  decode.d0.loss_cls: 0.5661  decode.d0.loss_mask: 0.7899  decode.d0.loss_dice: 0.5712  decode.d1.loss_cls: 0.1067  decode.d1.loss_mask: 0.8145  decode.d1.loss_dice: 0.5785  decode.d2.loss_cls: 0.1396  decode.d2.loss_mask: 0.7876  decode.d2.loss_dice: 0.5751  decode.d3.loss_cls: 0.1380  decode.d3.loss_mask: 0.7964  decode.d3.loss_dice: 0.5784  decode.d4.loss_cls: 0.1516  decode.d4.loss_mask: 0.7951  decode.d4.loss_dice: 0.5708  decode.d5.loss_cls: 0.1445  decode.d5.loss_mask: 0.8041  decode.d5.loss_dice: 0.5735  decode.d6.loss_cls: 0.1405  decode.d6.loss_mask: 0.8102  decode.d6.loss_dice: 0.5770  decode.d7.loss_cls: 0.1346  decode.d7.loss_mask: 0.8207  decode.d7.loss_dice: 0.5908  decode.d8.loss_cls: 0.1519  decode.d8.loss_mask: 0.8019  decode.d8.loss_dice: 0.5773
05/27 05:55:36 - mmengine - INFO - Iter(train) [159650/160000]  base_lr: 4.0360e-07 lr: 4.0360e-08  eta: 0:02:25  time: 0.4194  data_time: 0.0100  memory: 5971  grad_norm: 393.9461  loss: 16.1592  decode.loss_cls: 0.1509  decode.loss_mask: 0.7986  decode.loss_dice: 0.6040  decode.d0.loss_cls: 0.5486  decode.d0.loss_mask: 0.7776  decode.d0.loss_dice: 0.6408  decode.d1.loss_cls: 0.1989  decode.d1.loss_mask: 0.7851  decode.d1.loss_dice: 0.6129  decode.d2.loss_cls: 0.1728  decode.d2.loss_mask: 0.8069  decode.d2.loss_dice: 0.6264  decode.d3.loss_cls: 0.1671  decode.d3.loss_mask: 0.7926  decode.d3.loss_dice: 0.6067  decode.d4.loss_cls: 0.1604  decode.d4.loss_mask: 0.7997  decode.d4.loss_dice: 0.6182  decode.d5.loss_cls: 0.1792  decode.d5.loss_mask: 0.7912  decode.d5.loss_dice: 0.6053  decode.d6.loss_cls: 0.1872  decode.d6.loss_mask: 0.7810  decode.d6.loss_dice: 0.6141  decode.d7.loss_cls: 0.1553  decode.d7.loss_mask: 0.7856  decode.d7.loss_dice: 0.6118  decode.d8.loss_cls: 0.1859  decode.d8.loss_mask: 0.7845  decode.d8.loss_dice: 0.6098
05/27 05:55:57 - mmengine - INFO - Iter(train) [159700/160000]  base_lr: 3.5132e-07 lr: 3.5132e-08  eta: 0:02:04  time: 0.4205  data_time: 0.0100  memory: 5974  grad_norm: 500.4038  loss: 19.5236  decode.loss_cls: 0.2668  decode.loss_mask: 0.9299  decode.loss_dice: 0.6879  decode.d0.loss_cls: 0.7216  decode.d0.loss_mask: 0.9600  decode.d0.loss_dice: 0.7200  decode.d1.loss_cls: 0.2642  decode.d1.loss_mask: 0.9368  decode.d1.loss_dice: 0.7131  decode.d2.loss_cls: 0.3122  decode.d2.loss_mask: 0.9055  decode.d2.loss_dice: 0.6804  decode.d3.loss_cls: 0.2720  decode.d3.loss_mask: 0.9551  decode.d3.loss_dice: 0.6952  decode.d4.loss_cls: 0.2769  decode.d4.loss_mask: 0.9384  decode.d4.loss_dice: 0.6902  decode.d5.loss_cls: 0.2780  decode.d5.loss_mask: 0.9228  decode.d5.loss_dice: 0.7014  decode.d6.loss_cls: 0.2706  decode.d6.loss_mask: 0.9638  decode.d6.loss_dice: 0.6954  decode.d7.loss_cls: 0.2434  decode.d7.loss_mask: 0.9371  decode.d7.loss_dice: 0.6930  decode.d8.loss_cls: 0.2639  decode.d8.loss_mask: 0.9277  decode.d8.loss_dice: 0.7006
05/27 05:56:18 - mmengine - INFO - Iter(train) [159750/160000]  base_lr: 2.9815e-07 lr: 2.9815e-08  eta: 0:01:43  time: 0.4205  data_time: 0.0101  memory: 5969  grad_norm: 520.2864  loss: 19.4195  decode.loss_cls: 0.1769  decode.loss_mask: 1.0519  decode.loss_dice: 0.6428  decode.d0.loss_cls: 0.6737  decode.d0.loss_mask: 1.1057  decode.d0.loss_dice: 0.6590  decode.d1.loss_cls: 0.1558  decode.d1.loss_mask: 1.1073  decode.d1.loss_dice: 0.6992  decode.d2.loss_cls: 0.1910  decode.d2.loss_mask: 1.0688  decode.d2.loss_dice: 0.6540  decode.d3.loss_cls: 0.1948  decode.d3.loss_mask: 1.0603  decode.d3.loss_dice: 0.6503  decode.d4.loss_cls: 0.1737  decode.d4.loss_mask: 1.0837  decode.d4.loss_dice: 0.6341  decode.d5.loss_cls: 0.1747  decode.d5.loss_mask: 1.0694  decode.d5.loss_dice: 0.6436  decode.d6.loss_cls: 0.1713  decode.d6.loss_mask: 1.0670  decode.d6.loss_dice: 0.6392  decode.d7.loss_cls: 0.1898  decode.d7.loss_mask: 1.0308  decode.d7.loss_dice: 0.6109  decode.d8.loss_cls: 0.1595  decode.d8.loss_mask: 1.0521  decode.d8.loss_dice: 0.6280
05/27 05:56:40 - mmengine - INFO - Iter(train) [159800/160000]  base_lr: 2.4391e-07 lr: 2.4391e-08  eta: 0:01:22  time: 0.4206  data_time: 0.0100  memory: 5976  grad_norm: 694.8096  loss: 20.4462  decode.loss_cls: 0.2413  decode.loss_mask: 0.9451  decode.loss_dice: 0.7940  decode.d0.loss_cls: 0.8289  decode.d0.loss_mask: 0.9213  decode.d0.loss_dice: 0.7944  decode.d1.loss_cls: 0.2812  decode.d1.loss_mask: 0.8925  decode.d1.loss_dice: 0.7687  decode.d2.loss_cls: 0.2422  decode.d2.loss_mask: 0.9607  decode.d2.loss_dice: 0.7863  decode.d3.loss_cls: 0.2296  decode.d3.loss_mask: 0.9778  decode.d3.loss_dice: 0.7868  decode.d4.loss_cls: 0.2811  decode.d4.loss_mask: 0.9213  decode.d4.loss_dice: 0.8044  decode.d5.loss_cls: 0.2283  decode.d5.loss_mask: 0.9511  decode.d5.loss_dice: 0.8076  decode.d6.loss_cls: 0.2663  decode.d6.loss_mask: 0.9181  decode.d6.loss_dice: 0.7990  decode.d7.loss_cls: 0.2926  decode.d7.loss_mask: 0.9484  decode.d7.loss_dice: 0.7893  decode.d8.loss_cls: 0.2599  decode.d8.loss_mask: 0.9280  decode.d8.loss_dice: 0.8001
05/27 05:57:01 - mmengine - INFO - Iter(train) [159850/160000]  base_lr: 1.8827e-07 lr: 1.8827e-08  eta: 0:01:02  time: 0.4193  data_time: 0.0101  memory: 5976  grad_norm: 288.0373  loss: 16.5026  decode.loss_cls: 0.2117  decode.loss_mask: 0.7566  decode.loss_dice: 0.5808  decode.d0.loss_cls: 0.7654  decode.d0.loss_mask: 0.7028  decode.d0.loss_dice: 0.6120  decode.d1.loss_cls: 0.2550  decode.d1.loss_mask: 0.7591  decode.d1.loss_dice: 0.6194  decode.d2.loss_cls: 0.2044  decode.d2.loss_mask: 0.8161  decode.d2.loss_dice: 0.6165  decode.d3.loss_cls: 0.2389  decode.d3.loss_mask: 0.7686  decode.d3.loss_dice: 0.5744  decode.d4.loss_cls: 0.2261  decode.d4.loss_mask: 0.7579  decode.d4.loss_dice: 0.5817  decode.d5.loss_cls: 0.2214  decode.d5.loss_mask: 0.7653  decode.d5.loss_dice: 0.6164  decode.d6.loss_cls: 0.2646  decode.d6.loss_mask: 0.7684  decode.d6.loss_dice: 0.5990  decode.d7.loss_cls: 0.2528  decode.d7.loss_mask: 0.7505  decode.d7.loss_dice: 0.6067  decode.d8.loss_cls: 0.2466  decode.d8.loss_mask: 0.7647  decode.d8.loss_dice: 0.5986
05/27 05:57:22 - mmengine - INFO - Iter(train) [159900/160000]  base_lr: 1.3071e-07 lr: 1.3071e-08  eta: 0:00:41  time: 0.4194  data_time: 0.0100  memory: 5966  grad_norm: 520.6328  loss: 19.0801  decode.loss_cls: 0.1869  decode.loss_mask: 0.9421  decode.loss_dice: 0.6907  decode.d0.loss_cls: 0.6645  decode.d0.loss_mask: 0.9433  decode.d0.loss_dice: 0.7204  decode.d1.loss_cls: 0.2079  decode.d1.loss_mask: 0.9735  decode.d1.loss_dice: 0.7187  decode.d2.loss_cls: 0.2025  decode.d2.loss_mask: 0.9589  decode.d2.loss_dice: 0.7024  decode.d3.loss_cls: 0.1950  decode.d3.loss_mask: 0.9522  decode.d3.loss_dice: 0.6917  decode.d4.loss_cls: 0.1937  decode.d4.loss_mask: 0.9596  decode.d4.loss_dice: 0.7050  decode.d5.loss_cls: 0.1983  decode.d5.loss_mask: 0.9856  decode.d5.loss_dice: 0.7080  decode.d6.loss_cls: 0.1558  decode.d6.loss_mask: 0.9943  decode.d6.loss_dice: 0.7079  decode.d7.loss_cls: 0.2115  decode.d7.loss_mask: 0.9842  decode.d7.loss_dice: 0.7031  decode.d8.loss_cls: 0.1984  decode.d8.loss_mask: 0.9479  decode.d8.loss_dice: 0.6762
05/27 05:57:43 - mmengine - INFO - Iter(train) [159950/160000]  base_lr: 7.0043e-08 lr: 7.0043e-09  eta: 0:00:20  time: 0.4192  data_time: 0.0100  memory: 5973  grad_norm: 344.7477  loss: 15.0829  decode.loss_cls: 0.1831  decode.loss_mask: 0.6985  decode.loss_dice: 0.5625  decode.d0.loss_cls: 0.6279  decode.d0.loss_mask: 0.6982  decode.d0.loss_dice: 0.5882  decode.d1.loss_cls: 0.2021  decode.d1.loss_mask: 0.6977  decode.d1.loss_dice: 0.6003  decode.d2.loss_cls: 0.1842  decode.d2.loss_mask: 0.7099  decode.d2.loss_dice: 0.5726  decode.d3.loss_cls: 0.2127  decode.d3.loss_mask: 0.6960  decode.d3.loss_dice: 0.5506  decode.d4.loss_cls: 0.2191  decode.d4.loss_mask: 0.7073  decode.d4.loss_dice: 0.5403  decode.d5.loss_cls: 0.1853  decode.d5.loss_mask: 0.7114  decode.d5.loss_dice: 0.5675  decode.d6.loss_cls: 0.2166  decode.d6.loss_mask: 0.7053  decode.d6.loss_dice: 0.5616  decode.d7.loss_cls: 0.1615  decode.d7.loss_mask: 0.7155  decode.d7.loss_dice: 0.5792  decode.d8.loss_cls: 0.1677  decode.d8.loss_mask: 0.7110  decode.d8.loss_dice: 0.5492
05/27 05:58:04 - mmengine - INFO - Exp name: mask2former_swin-t_8xb2-160k_voc12aug-512x512_20240526_105312
05/27 05:58:04 - mmengine - INFO - Iter(train) [160000/160000]  base_lr: 0.0000e+00 lr: 0.0000e+00  eta: 0:00:00  time: 0.4188  data_time: 0.0101  memory: 5980  grad_norm: 305.6378  loss: 13.3438  decode.loss_cls: 0.0643  decode.loss_mask: 0.7043  decode.loss_dice: 0.5125  decode.d0.loss_cls: 0.5541  decode.d0.loss_mask: 0.6788  decode.d0.loss_dice: 0.4970  decode.d1.loss_cls: 0.0741  decode.d1.loss_mask: 0.7121  decode.d1.loss_dice: 0.5158  decode.d2.loss_cls: 0.0617  decode.d2.loss_mask: 0.7071  decode.d2.loss_dice: 0.5196  decode.d3.loss_cls: 0.0513  decode.d3.loss_mask: 0.7050  decode.d3.loss_dice: 0.5248  decode.d4.loss_cls: 0.0687  decode.d4.loss_mask: 0.7072  decode.d4.loss_dice: 0.5165  decode.d5.loss_cls: 0.0641  decode.d5.loss_mask: 0.7059  decode.d5.loss_dice: 0.5162  decode.d6.loss_cls: 0.0720  decode.d6.loss_mask: 0.7135  decode.d6.loss_dice: 0.5121  decode.d7.loss_cls: 0.0732  decode.d7.loss_mask: 0.7087  decode.d7.loss_dice: 0.5137  decode.d8.loss_cls: 0.0742  decode.d8.loss_mask: 0.7024  decode.d8.loss_dice: 0.5129
05/27 05:58:04 - mmengine - INFO - Saving checkpoint at 160000 iterations
05/27 05:58:08 - mmengine - INFO - Iter(val) [  50/1449]    eta: 0:01:08  time: 0.0479  data_time: 0.0013  memory: 1391  
05/27 05:58:11 - mmengine - INFO - Iter(val) [ 100/1449]    eta: 0:01:05  time: 0.0473  data_time: 0.0012  memory: 1205  
05/27 05:58:13 - mmengine - INFO - Iter(val) [ 150/1449]    eta: 0:01:03  time: 0.0500  data_time: 0.0012  memory: 1596  
05/27 05:58:15 - mmengine - INFO - Iter(val) [ 200/1449]    eta: 0:01:00  time: 0.0484  data_time: 0.0012  memory: 1298  
05/27 05:58:18 - mmengine - INFO - Iter(val) [ 250/1449]    eta: 0:00:57  time: 0.0475  data_time: 0.0012  memory: 1298  
05/27 05:58:20 - mmengine - INFO - Iter(val) [ 300/1449]    eta: 0:00:55  time: 0.0475  data_time: 0.0012  memory: 1279  
05/27 05:58:23 - mmengine - INFO - Iter(val) [ 350/1449]    eta: 0:00:52  time: 0.0476  data_time: 0.0012  memory: 1224  
05/27 05:58:25 - mmengine - INFO - Iter(val) [ 400/1449]    eta: 0:00:50  time: 0.0489  data_time: 0.0013  memory: 1298  
05/27 05:58:27 - mmengine - INFO - Iter(val) [ 450/1449]    eta: 0:00:48  time: 0.0473  data_time: 0.0012  memory: 1298  
05/27 05:58:30 - mmengine - INFO - Iter(val) [ 500/1449]    eta: 0:00:45  time: 0.0511  data_time: 0.0012  memory: 1725  
05/27 05:58:32 - mmengine - INFO - Iter(val) [ 550/1449]    eta: 0:00:43  time: 0.0477  data_time: 0.0012  memory: 1336  
05/27 05:58:35 - mmengine - INFO - Iter(val) [ 600/1449]    eta: 0:00:40  time: 0.0479  data_time: 0.0012  memory: 1298  
05/27 05:58:37 - mmengine - INFO - Iter(val) [ 650/1449]    eta: 0:00:38  time: 0.0496  data_time: 0.0012  memory: 1205  
05/27 05:58:39 - mmengine - INFO - Iter(val) [ 700/1449]    eta: 0:00:36  time: 0.0488  data_time: 0.0012  memory: 1316  
05/27 05:58:42 - mmengine - INFO - Iter(val) [ 750/1449]    eta: 0:00:33  time: 0.0473  data_time: 0.0012  memory: 1279  
05/27 05:58:44 - mmengine - INFO - Iter(val) [ 800/1449]    eta: 0:00:31  time: 0.0511  data_time: 0.0012  memory: 1410  
05/27 05:58:47 - mmengine - INFO - Iter(val) [ 850/1449]    eta: 0:00:28  time: 0.0484  data_time: 0.0015  memory: 1279  
05/27 05:58:49 - mmengine - INFO - Iter(val) [ 900/1449]    eta: 0:00:26  time: 0.0484  data_time: 0.0012  memory: 1205  
05/27 05:58:52 - mmengine - INFO - Iter(val) [ 950/1449]    eta: 0:00:24  time: 0.0483  data_time: 0.0012  memory: 1205  
05/27 05:58:54 - mmengine - INFO - Iter(val) [1000/1449]    eta: 0:00:21  time: 0.0477  data_time: 0.0012  memory: 1336  
05/27 05:58:56 - mmengine - INFO - Iter(val) [1050/1449]    eta: 0:00:19  time: 0.0476  data_time: 0.0013  memory: 1246  
05/27 05:58:59 - mmengine - INFO - Iter(val) [1100/1449]    eta: 0:00:16  time: 0.0498  data_time: 0.0012  memory: 1503  
05/27 05:59:01 - mmengine - INFO - Iter(val) [1150/1449]    eta: 0:00:14  time: 0.0473  data_time: 0.0012  memory: 1261  
05/27 05:59:04 - mmengine - INFO - Iter(val) [1200/1449]    eta: 0:00:11  time: 0.0487  data_time: 0.0012  memory: 1298  
05/27 05:59:06 - mmengine - INFO - Iter(val) [1250/1449]    eta: 0:00:09  time: 0.0477  data_time: 0.0012  memory: 1447  
05/27 05:59:08 - mmengine - INFO - Iter(val) [1300/1449]    eta: 0:00:07  time: 0.0475  data_time: 0.0012  memory: 1298  
05/27 05:59:11 - mmengine - INFO - Iter(val) [1350/1449]    eta: 0:00:04  time: 0.0489  data_time: 0.0013  memory: 1279  
05/27 05:59:13 - mmengine - INFO - Iter(val) [1400/1449]    eta: 0:00:02  time: 0.0478  data_time: 0.0012  memory: 1205  
05/27 05:59:16 - mmengine - INFO - per class results:
05/27 05:59:16 - mmengine - INFO - 
+-------------+-------+-------+
|    Class    |  IoU  |  Acc  |
+-------------+-------+-------+
|  background | 95.84 | 97.52 |
|  aeroplane  | 92.42 | 96.17 |
|   bicycle   | 45.48 | 96.51 |
|     bird    | 94.64 | 98.58 |
|     boat    | 67.09 | 92.74 |
|    bottle   | 85.26 | 95.37 |
|     bus     | 96.03 | 98.06 |
|     car     | 91.52 | 94.92 |
|     cat     | 95.71 |  98.2 |
|    chair    | 42.24 | 69.21 |
|     cow     | 90.79 |  97.4 |
| diningtable |  66.1 | 69.43 |
|     dog     | 91.82 | 98.61 |
|    horse    | 90.49 | 94.96 |
|  motorbike  | 92.61 | 96.41 |
|    person   | 90.65 | 95.16 |
| pottedplant | 70.53 | 89.94 |
|    sheep    |  88.7 | 92.38 |
|     sofa    | 53.82 | 62.33 |
|    train    | 90.45 | 96.36 |
|  tvmonitor  | 85.64 | 88.53 |
+-------------+-------+-------+
05/27 05:59:16 - mmengine - INFO - Iter(val) [1449/1449]    aAcc: 96.0800  mIoU: 81.8000  mAcc: 91.3700  data_time: 0.0013  time: 0.0480
Runtime: 68908

============================= JOB FEEDBACK =============================

NodeName=uc2n483
Job ID: 23631278
Array Job ID: 23630757_1
Cluster: uc2
User/Group: ma_dschader/ma_ma
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 16
CPU Utilized: 1-00:00:17
CPU Efficiency: 7.83% of 12-18:23:28 core-walltime
Job Wall-clock time: 19:08:58
Memory Utilized: 5.97 GB
Memory Efficiency: 5.97% of 100.00 GB
