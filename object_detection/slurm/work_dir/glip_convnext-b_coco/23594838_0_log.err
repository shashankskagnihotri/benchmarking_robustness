GpuFreq=control_disabled
config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]config.json: 100%|██████████| 570/570 [00:00<00:00, 3.83MB/s]
tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]tokenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 423kB/s]
vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 21.7MB/s]
tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 30.8MB/s]
model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]model.safetensors:   2%|▏         | 10.5M/440M [00:00<00:04, 87.3MB/s]model.safetensors:   7%|▋         | 31.5M/440M [00:00<00:03, 109MB/s] model.safetensors:  12%|█▏        | 52.4M/440M [00:00<00:03, 112MB/s]model.safetensors:  17%|█▋        | 73.4M/440M [00:00<00:03, 113MB/s]model.safetensors:  21%|██▏       | 94.4M/440M [00:00<00:03, 113MB/s]model.safetensors:  26%|██▌       | 115M/440M [00:01<00:02, 114MB/s] model.safetensors:  31%|███       | 136M/440M [00:01<00:02, 112MB/s]model.safetensors:  36%|███▌      | 157M/440M [00:01<00:02, 114MB/s]model.safetensors:  40%|████      | 178M/440M [00:01<00:02, 115MB/s]model.safetensors:  45%|████▌     | 199M/440M [00:01<00:02, 115MB/s]model.safetensors:  50%|████▉     | 220M/440M [00:01<00:01, 115MB/s]model.safetensors:  55%|█████▍    | 241M/440M [00:02<00:01, 115MB/s]model.safetensors:  60%|█████▉    | 262M/440M [00:02<00:01, 115MB/s]model.safetensors:  64%|██████▍   | 283M/440M [00:02<00:01, 114MB/s]model.safetensors:  69%|██████▉   | 304M/440M [00:02<00:01, 114MB/s]model.safetensors:  74%|███████▍  | 325M/440M [00:02<00:01, 114MB/s]model.safetensors:  79%|███████▊  | 346M/440M [00:03<00:00, 114MB/s]model.safetensors:  83%|████████▎ | 367M/440M [00:03<00:00, 114MB/s]model.safetensors:  88%|████████▊ | 388M/440M [00:03<00:00, 114MB/s]model.safetensors:  93%|█████████▎| 409M/440M [00:03<00:00, 114MB/s]model.safetensors:  98%|█████████▊| 430M/440M [00:03<00:00, 114MB/s]model.safetensors: 100%|██████████| 440M/440M [00:03<00:00, 114MB/s]
Downloading: "https://download.openmmlab.com/mmdetection/v3.0/glip/glip_tiny_a_mmdet-b3654169.pth" to /home/ma/ma_ma/ma_ruweber/.cache/torch/hub/checkpoints/glip_tiny_a_mmdet-b3654169.pth
/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/torch/nn/functional.py:4140: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.")
submitit WARNING (2024-05-14 01:27:58,753) - Bypassing signal SIGCONT
[05/14 01:27:58] submitit WARNING: Bypassing signal SIGCONT
submitit ERROR (2024-05-14 01:27:58,759) - Submitted job triggered an exception
[05/14 01:27:58] submitit ERROR: Submitted job triggered an exception
Traceback (most recent call last):
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/runpy.py", line 196, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/runpy.py", line 86, in _run_code
    exec(code, run_globals)
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/submitit/core/_submit.py", line 11, in <module>
    submitit_main()
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/submitit/core/submission.py", line 76, in submitit_main
    process_job(args.folder)
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/submitit/core/submission.py", line 69, in process_job
    raise error
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/submitit/core/submission.py", line 55, in process_job
    result = delayed.result()
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/submitit/core/utils.py", line 133, in result
    self._result = self.function(*self.args, **self.kwargs)
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/benchmarking_robustness/object_detection/new_trainer.py", line 88, in trainer
    runner.train()
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/mmengine/runner/runner.py", line 1777, in train
    model = self.train_loop.run()  # type: ignore
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/mmengine/runner/loops.py", line 96, in run
    self.run_epoch()
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/mmengine/runner/loops.py", line 112, in run_epoch
    self.run_iter(idx, data_batch)
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/mmengine/runner/loops.py", line 128, in run_iter
    outputs = self.runner.model.train_step(
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/mmengine/model/base_model/base_model.py", line 116, in train_step
    optim_wrapper.update_params(parsed_losses)
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/mmengine/optim/optimizer/optimizer_wrapper.py", line 196, in update_params
    self.backward(loss)
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/mmengine/optim/optimizer/optimizer_wrapper.py", line 220, in backward
    loss.backward(**kwargs)
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/torch/_tensor.py", line 492, in backward
    torch.autograd.backward(
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/torch/autograd/__init__.py", line 251, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/submitit/core/job_environment.py", line 200, in checkpoint_and_try_requeue
    timed_out = self.has_timed_out()
  File "/pfs/work7/workspace/scratch/ma_ruweber-team_project_fss2024/miniconda3/envs/benchmark/lib/python3.10/site-packages/submitit/core/job_environment.py", line 181, in has_timed_out
    guaranteed_walltime = min(max_walltime * 0.8, max_walltime - 10 * 60)
TypeError: can't multiply sequence by non-int of type 'float'
srun: error: uc2n486: task 0: Exited with exit code 1
