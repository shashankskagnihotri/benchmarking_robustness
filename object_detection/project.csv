data_time,coco/bbox_mAP,coco/bbox_mAP_m,coco/bbox_mAP_s,coco/bbox_mAP_50,coco/bbox_mAP_75,time,_step,_runtime,_timestamp,coco/bbox_mAP_l,_wandb.runtime,val_img.path,val_img.size,val_img._type,val_img.width,val_img.format,val_img.height,val_img.sha256,coco/segm_mAP_m,coco/segm_mAP_75,coco/segm_mAP_s,coco/segm_mAP_50,coco/segm_mAP,coco/segm_mAP_l,attack,resume,launcher,work_dir,data_root,load_from,log_level,img_scales,config_file,backend_args,dataset_type,tta_pipeline,vis_backends,default_scope,test_pipeline,train_pipeline,checkpoint_file,param_scheduler,model.neck.type,model.neck.num_outs,model.neck.in_channels,model.neck.start_level,model.neck.out_channels,model.neck.add_extra_convs,model.type,model.backbone.arch,model.backbone.type,model.backbone.with_cp,model.backbone.init_cfg.type,model.backbone.init_cfg.prefix,model.backbone.init_cfg.checkpoint,model.backbone.out_indices,model.backbone.drop_path_rate,model.backbone.gap_before_final_norm,model.backbone.layer_scale_init_value,model.test_cfg.nms.type,model.test_cfg.nms.iou_threshold,model.test_cfg.nms_pre,model.test_cfg.score_thr,model.test_cfg.max_per_img,model.test_cfg.min_bbox_size,model.bbox_head.type,model.bbox_head.loss_bbox.beta,model.bbox_head.loss_bbox.type,model.bbox_head.loss_bbox.loss_weight,model.bbox_head.bbox_coder.type,model.bbox_head.bbox_coder.target_stds,model.bbox_head.bbox_coder.target_means,model.bbox_head.in_channels,model.bbox_head.num_classes,model.bbox_head.feat_channels,model.bbox_head.stacked_convs,model.bbox_head.anchor_generator.type,model.bbox_head.anchor_generator.ratios,model.bbox_head.anchor_generator.strides,model.bbox_head.anchor_generator.octave_base_scale,model.bbox_head.anchor_generator.scales_per_octave,model.train_cfg.debug,model.train_cfg.sampler.type,model.train_cfg.assigner.type,model.train_cfg.assigner.min_pos_iou,model.train_cfg.assigner.neg_iou_thr,model.train_cfg.assigner.pos_iou_thr,model.train_cfg.assigner.ignore_iof_thr,model.train_cfg.pos_weight,model.train_cfg.allowed_border,model.data_preprocessor.std,model.data_preprocessor.mean,model.data_preprocessor.type,model.data_preprocessor.bgr_to_rgb,model.data_preprocessor.pad_size_divisor,env_cfg.mp_cfg.mp_start_method,env_cfg.mp_cfg.opencv_num_threads,env_cfg.dist_cfg.backend,env_cfg.cudnn_benchmark,val_cfg.type,test_cfg.type,train_cfg.type,train_cfg.max_epochs,train_cfg.val_interval,tta_model.type,tta_model.tta_cfg.nms.type,tta_model.tta_cfg.nms.iou_threshold,tta_model.tta_cfg.max_per_img,visualizer.name,visualizer.type,visualizer.vis_backends.type,visualizer.vis_backends.init_kwargs.name,visualizer.vis_backends.init_kwargs.group,visualizer.vis_backends.init_kwargs.config.attack,visualizer.vis_backends.init_kwargs.config.config_file,visualizer.vis_backends.init_kwargs.config.attack_kwargs.alpha,visualizer.vis_backends.init_kwargs.config.attack_kwargs.steps,visualizer.vis_backends.init_kwargs.config.attack_kwargs.epsilon,visualizer.vis_backends.init_kwargs.config.checkpoint_file,visualizer.vis_backends.init_kwargs.entity,visualizer.vis_backends.init_kwargs.project,attack_kwargs.alpha,attack_kwargs.steps,attack_kwargs.epsilon,auto_scale_lr.enable,auto_scale_lr.base_batch_size,default_hooks.timer.type,default_hooks.logger.type,default_hooks.logger.interval,default_hooks.checkpoint.type,default_hooks.checkpoint.interval,default_hooks.sampler_seed.type,default_hooks.visualization.draw,default_hooks.visualization.type,default_hooks.visualization.interval,default_hooks.param_scheduler.type,log_processor.type,log_processor.by_epoch,log_processor.window_size,optim_wrapper.type,optim_wrapper.clip_grad.max_norm,optim_wrapper.clip_grad.norm_type,optim_wrapper.optimizer.lr,optim_wrapper.optimizer.type,optim_wrapper.optimizer.momentum,optim_wrapper.optimizer.weight_decay,val_evaluator.type,val_evaluator.metric,val_evaluator.ann_file,val_evaluator.format_only,val_evaluator.backend_args,test_evaluator.type,test_evaluator.metric,test_evaluator.ann_file,test_evaluator.format_only,test_evaluator.backend_args,val_dataloader.dataset.type,val_dataloader.dataset.ann_file,val_dataloader.dataset.metainfo.classes,val_dataloader.dataset.metainfo.palette,val_dataloader.dataset.pipeline,val_dataloader.dataset.data_root,val_dataloader.dataset.data_prefix.img,val_dataloader.batch_size,test_dataloader.dataset.type,test_dataloader.dataset.ann_file,test_dataloader.dataset.metainfo.classes,test_dataloader.dataset.metainfo.palette,test_dataloader.dataset.pipeline,test_dataloader.dataset.data_root,test_dataloader.dataset.data_prefix.img,test_dataloader.batch_size,train_dataloader.dataset.type,train_dataloader.dataset.times,train_dataloader.dataset.dataset.type,train_dataloader.dataset.dataset.ann_file,train_dataloader.dataset.dataset.metainfo.classes,train_dataloader.dataset.dataset.metainfo.palette,train_dataloader.dataset.dataset.pipeline,train_dataloader.dataset.dataset.data_root,train_dataloader.dataset.dataset.filter_cfg.min_size,train_dataloader.dataset.dataset.filter_cfg.filter_empty_gt,train_dataloader.dataset.dataset.data_prefix.img,train_dataloader.dataset.dataset.backend_args,train_dataloader.batch_size,max_epochs,model.neck.act_cfg,model.neck.norm_cfg,model.neck.kernel_size,model.decoder.layer_cfg.ffn_cfg.act_cfg.type,model.decoder.layer_cfg.ffn_cfg.act_cfg.inplace,model.decoder.layer_cfg.ffn_cfg.num_fcs,model.decoder.layer_cfg.ffn_cfg.ffn_drop,model.decoder.layer_cfg.ffn_cfg.embed_dims,model.decoder.layer_cfg.ffn_cfg.feedforward_channels,model.decoder.layer_cfg.self_attn_cfg.dropout,model.decoder.layer_cfg.self_attn_cfg.num_heads,model.decoder.layer_cfg.self_attn_cfg.embed_dims,model.decoder.layer_cfg.self_attn_cfg.batch_first,model.decoder.layer_cfg.cross_attn_cfg.dropout,model.decoder.layer_cfg.cross_attn_cfg.num_heads,model.decoder.layer_cfg.cross_attn_cfg.embed_dims,model.decoder.layer_cfg.cross_attn_cfg.batch_first,model.decoder.num_layers,model.decoder.return_intermediate,model.encoder.layer_cfg.ffn_cfg.act_cfg.type,model.encoder.layer_cfg.ffn_cfg.act_cfg.inplace,model.encoder.layer_cfg.ffn_cfg.num_fcs,model.encoder.layer_cfg.ffn_cfg.ffn_drop,model.encoder.layer_cfg.ffn_cfg.embed_dims,model.encoder.layer_cfg.ffn_cfg.feedforward_channels,model.encoder.layer_cfg.self_attn_cfg.dropout,model.encoder.layer_cfg.self_attn_cfg.num_heads,model.encoder.layer_cfg.self_attn_cfg.embed_dims,model.encoder.layer_cfg.self_attn_cfg.batch_first,model.encoder.num_layers,model.backbone.depth,model.backbone.style,model.backbone.norm_cfg.type,model.backbone.norm_cfg.requires_grad,model.backbone.norm_eval,model.backbone.num_stages,model.backbone.frozen_stages,model.bbox_head.loss_cls.type,model.bbox_head.loss_cls.loss_weight,model.bbox_head.loss_cls.use_sigmoid,model.bbox_head.loss_cls.class_weight,model.bbox_head.loss_cls.bg_cls_weight,model.bbox_head.loss_iou.type,model.bbox_head.loss_iou.loss_weight,model.bbox_head.embed_dims,model.train_cfg.assigner.match_costs,model.num_queries,model.positional_encoding.normalize,model.positional_encoding.num_feats,optim_wrapper.paramwise_cfg.custom_keys.backbone.lr_mult,optim_wrapper.paramwise_cfg.custom_keys.backbone.decay_mult,val_dataloader.dataset.test_mode,val_dataloader.dataset.backend_args,val_dataloader.sampler.type,val_dataloader.sampler.shuffle,val_dataloader.drop_last,val_dataloader.num_workers,val_dataloader.persistent_workers,test_dataloader.dataset.test_mode,test_dataloader.dataset.backend_args,test_dataloader.sampler.type,test_dataloader.sampler.shuffle,test_dataloader.drop_last,test_dataloader.num_workers,test_dataloader.persistent_workers,train_dataloader.dataset.ann_file,train_dataloader.dataset.pipeline,train_dataloader.dataset.data_root,train_dataloader.dataset.filter_cfg.min_size,train_dataloader.dataset.filter_cfg.filter_empty_gt,train_dataloader.dataset.data_prefix.img,train_dataloader.dataset.backend_args,train_dataloader.sampler.type,train_dataloader.sampler.shuffle,train_dataloader.num_workers,train_dataloader.batch_sampler.type,train_dataloader.persistent_workers,model.roi_head.type,model.roi_head.bbox_head,model.roi_head.num_stages,model.roi_head.bbox_roi_extractor.type,model.roi_head.bbox_roi_extractor.roi_layer.type,model.roi_head.bbox_roi_extractor.roi_layer.output_size,model.roi_head.bbox_roi_extractor.roi_layer.sampling_ratio,model.roi_head.bbox_roi_extractor.out_channels,model.roi_head.bbox_roi_extractor.featmap_strides,model.roi_head.stage_loss_weights,model.rpn_head.type,model.rpn_head.loss_cls.type,model.rpn_head.loss_cls.loss_weight,model.rpn_head.loss_cls.use_sigmoid,model.rpn_head.loss_bbox.beta,model.rpn_head.loss_bbox.type,model.rpn_head.loss_bbox.loss_weight,model.rpn_head.bbox_coder.type,model.rpn_head.bbox_coder.target_stds,model.rpn_head.bbox_coder.target_means,model.rpn_head.in_channels,model.rpn_head.feat_channels,model.rpn_head.anchor_generator.type,model.rpn_head.anchor_generator.ratios,model.rpn_head.anchor_generator.scales,model.rpn_head.anchor_generator.strides,model.test_cfg.rpn.nms.type,model.test_cfg.rpn.nms.iou_threshold,model.test_cfg.rpn.nms_pre,model.test_cfg.rpn.max_per_img,model.test_cfg.rpn.min_bbox_size,model.test_cfg.rcnn.nms.type,model.test_cfg.rcnn.nms.iou_threshold,model.test_cfg.rcnn.score_thr,model.test_cfg.rcnn.max_per_img,model.train_cfg.rpn.debug,model.train_cfg.rpn.sampler.num,model.train_cfg.rpn.sampler.type,model.train_cfg.rpn.sampler.neg_pos_ub,model.train_cfg.rpn.sampler.pos_fraction,model.train_cfg.rpn.sampler.add_gt_as_proposals,model.train_cfg.rpn.assigner.type,model.train_cfg.rpn.assigner.min_pos_iou,model.train_cfg.rpn.assigner.neg_iou_thr,model.train_cfg.rpn.assigner.pos_iou_thr,model.train_cfg.rpn.assigner.ignore_iof_thr,model.train_cfg.rpn.assigner.match_low_quality,model.train_cfg.rpn.pos_weight,model.train_cfg.rpn.allowed_border,model.train_cfg.rcnn,model.train_cfg.rpn_proposal.nms.type,model.train_cfg.rpn_proposal.nms.iou_threshold,model.train_cfg.rpn_proposal.nms_pre,model.train_cfg.rpn_proposal.max_per_img,model.train_cfg.rpn_proposal.min_bbox_size,model.bbox_head.topk,model.bbox_head.loss_cls.alpha,model.bbox_head.loss_cls.gamma,model.bbox_head.score_voting,model.bbox_head.loss_centerness.type,model.bbox_head.loss_centerness.loss_weight,model.bbox_head.loss_centerness.use_sigmoid,model.bbox_head.reg_decoded_bbox,model.roi_head.mask_head.type,model.roi_head.mask_head.loss_mask.type,model.roi_head.mask_head.loss_mask.use_mask,model.roi_head.mask_head.loss_mask.loss_weight,model.roi_head.mask_head.num_convs,model.roi_head.mask_head.in_channels,model.roi_head.mask_head.num_classes,model.roi_head.mask_head.conv_out_channels,model.roi_head.mask_roi_extractor.type,model.roi_head.mask_roi_extractor.roi_layer.type,model.roi_head.mask_roi_extractor.roi_layer.output_size,model.roi_head.mask_roi_extractor.roi_layer.sampling_ratio,model.roi_head.mask_roi_extractor.out_channels,model.roi_head.mask_roi_extractor.featmap_strides,model.test_cfg.rcnn.mask_thr_binary,model.data_preprocessor.pad_mask,model.roi_head.bbox_head.type,model.roi_head.bbox_head.loss_cls.type,model.roi_head.bbox_head.loss_cls.loss_weight,model.roi_head.bbox_head.loss_cls.use_sigmoid,model.roi_head.bbox_head.loss_bbox.beta,model.roi_head.bbox_head.loss_bbox.type,model.roi_head.bbox_head.loss_bbox.loss_weight,model.roi_head.bbox_head.bbox_coder.type,model.roi_head.bbox_head.bbox_coder.target_stds,model.roi_head.bbox_head.bbox_coder.target_means,model.roi_head.bbox_head.in_channels,model.roi_head.bbox_head.num_classes,model.roi_head.bbox_head.roi_feat_size,model.roi_head.bbox_head.fc_out_channels,model.roi_head.bbox_head.reg_class_agnostic,model.train_cfg.rcnn.debug,model.train_cfg.rcnn.sampler.num,model.train_cfg.rcnn.sampler.type,model.train_cfg.rcnn.sampler.neg_pos_ub,model.train_cfg.rcnn.sampler.pos_fraction,model.train_cfg.rcnn.sampler.add_gt_as_proposals,model.train_cfg.rcnn.assigner.type,model.train_cfg.rcnn.assigner.min_pos_iou,model.train_cfg.rcnn.assigner.neg_iou_thr,model.train_cfg.rcnn.assigner.pos_iou_thr,model.train_cfg.rcnn.assigner.ignore_iof_thr,model.train_cfg.rcnn.assigner.match_low_quality,model.train_cfg.rcnn.pos_weight,model.train_cfg.rcnn.dynamic_rcnn.iou_topk,model.train_cfg.rcnn.dynamic_rcnn.beta_topk,model.train_cfg.rcnn.dynamic_rcnn.initial_iou,model.train_cfg.rcnn.dynamic_rcnn.initial_beta,model.train_cfg.rcnn.dynamic_rcnn.update_iter_interval,model.train_cfg.assigner.topk,model.bbox_head.sigma,model.bbox_head.strides,model.bbox_head.norm_cfg.type,model.bbox_head.norm_cfg.num_groups,model.bbox_head.norm_cfg.requires_grad,model.bbox_head.with_deform,model.bbox_head.scale_ranges,model.bbox_head.base_edge_list,model.neck.use_dcn,model.neck.num_deconv_filters,model.neck.num_deconv_kernels,model.test_cfg.topk,model.test_cfg.local_maximum_kernel,model.bbox_head.loss_wh.type,model.bbox_head.loss_wh.loss_weight,model.bbox_head.loss_offset.type,model.bbox_head.loss_offset.loss_weight,model.bbox_head.loss_center_heatmap.type,model.bbox_head.loss_center_heatmap.loss_weight,model.train_cfg,model.bbox_head.loss_cls.reduction,model.bbox_head.loss_bbox.eps,model.bbox_head.loss_bbox.reduction,model.bbox_head.bbox_coder.normalizer,model.train_cfg.assigner.neg_scale,model.train_cfg.assigner.pos_scale,model.train_cfg.assigner.min_pos_iof,model.neck.norm_cfg.type,model.neck.norm_cfg.num_groups,model.neck.norm_cfg.requires_grad,model.backbone.dcn.type,model.backbone.dcn.deform_groups,model.backbone.dcn.fallback_on_stride,model.backbone.stage_with_dcn,model.bbox_head.num_points,model.bbox_head.gradient_mul,model.bbox_head.point_strides,model.bbox_head.loss_bbox_init.beta,model.bbox_head.loss_bbox_init.type,model.bbox_head.loss_bbox_init.loss_weight,model.bbox_head.loss_bbox_refine.beta,model.bbox_head.loss_bbox_refine.type,model.bbox_head.loss_bbox_refine.loss_weight,model.bbox_head.point_base_scale,model.bbox_head.transform_method,model.bbox_head.point_feat_channels,model.train_cfg.init.debug,model.train_cfg.init.assigner.type,model.train_cfg.init.assigner.scale,model.train_cfg.init.assigner.pos_num,model.train_cfg.init.pos_weight,model.train_cfg.init.allowed_border,model.train_cfg.refine.debug,model.train_cfg.refine.assigner.type,model.train_cfg.refine.assigner.min_pos_iou,model.train_cfg.refine.assigner.neg_iou_thr,model.train_cfg.refine.assigner.pos_iou_thr,model.train_cfg.refine.assigner.ignore_iof_thr,model.train_cfg.refine.pos_weight,model.train_cfg.refine.allowed_border,norm_cfg.type,norm_cfg.num_groups,norm_cfg.requires_grad,model.neck.relu_before_extra_convs,model.bbox_head.use_vfl,model.bbox_head.loss_cls.iou_weighted,model.bbox_head.use_atss,model.bbox_head.center_sampling,model.bbox_head.dcn_on_last_conv,optim_wrapper.clip_grad,optim_wrapper.paramwise_cfg.bias_lr_mult,optim_wrapper.paramwise_cfg.bias_decay_mult,model.neck,model.roi_head.bbox_head.loss_bbox.alpha,model.roi_head.bbox_head.loss_bbox.gamma,model.train_cfg.rcnn.sampler.neg_sampler.type,model.train_cfg.rcnn.sampler.neg_sampler.num_bins,model.train_cfg.rcnn.sampler.neg_sampler.floor_thr,model.train_cfg.rcnn.sampler.neg_sampler.floor_fraction,model.train_cfg.rcnn.sampler.pos_sampler.type,model.dn_cfg.group_cfg.dynamic,model.dn_cfg.group_cfg.num_groups,model.dn_cfg.group_cfg.num_dn_queries,model.dn_cfg.box_noise_scale,model.dn_cfg.label_noise_scale,model.decoder.layer_cfg.cross_attn_cfg.num_levels,model.decoder.post_norm_cfg,model.dqs_cfg.type,model.dqs_cfg.iou_threshold,model.encoder.layer_cfg.self_attn_cfg.num_levels,model.bbox_head.sync_cls_avg_factor,model.as_two_stage,model.with_box_refine,model.dense_topk_ratio,model.num_feature_levels,model.positional_encoding.offset,model.positional_encoding.temperature,model.roi_head.bbox_head.with_reg,model.roi_head.grid_head.type,model.roi_head.grid_head.norm_cfg.type,model.roi_head.grid_head.norm_cfg.num_groups,model.roi_head.grid_head.loss_grid.type,model.roi_head.grid_head.loss_grid.loss_weight,model.roi_head.grid_head.loss_grid.use_sigmoid,model.roi_head.grid_head.num_convs,model.roi_head.grid_head.grid_points,model.roi_head.grid_head.in_channels,model.roi_head.grid_head.point_feat_channels,model.roi_head.grid_roi_extractor.type,model.roi_head.grid_roi_extractor.roi_layer.type,model.roi_head.grid_roi_extractor.roi_layer.output_size,model.roi_head.grid_roi_extractor.roi_layer.sampling_ratio,model.roi_head.grid_roi_extractor.out_channels,model.roi_head.grid_roi_extractor.featmap_strides,model.train_cfg.rcnn.pos_radius,model.train_cfg.rcnn.max_num_grid,model.decoder.layer_cfg.self_attn_cfg.attn_drop,model.decoder.layer_cfg.self_attn_cfg.cross_attn,model.decoder.layer_cfg.cross_attn_cfg.attn_drop,model.decoder.layer_cfg.cross_attn_cfg.cross_attn,num_stages,num_proposals,model.roi_head.proposal_feature_channel,model.rpn_head.num_proposals,model.rpn_head.proposal_feature_channel,model.test_cfg.rpn,model.train_cfg.rpn,model.roi_head.bbox_head.norm_cfg,model.roi_head.bbox_head.bbox_coder.num_buckets,model.roi_head.bbox_head.bbox_coder.scale_factor,model.roi_head.bbox_head.num_cls_fcs,model.roi_head.bbox_head.num_reg_fcs,model.roi_head.bbox_head.reg_pre_num,model.roi_head.bbox_head.reg_post_num,model.roi_head.bbox_head.loss_bbox_cls.type,model.roi_head.bbox_head.loss_bbox_cls.loss_weight,model.roi_head.bbox_head.loss_bbox_cls.use_sigmoid,model.roi_head.bbox_head.loss_bbox_reg.beta,model.roi_head.bbox_head.loss_bbox_reg.type,model.roi_head.bbox_head.loss_bbox_reg.loss_weight,model.roi_head.bbox_head.reg_pre_kernel,model.roi_head.bbox_head.cls_in_channels,model.roi_head.bbox_head.reg_in_channels,model.roi_head.bbox_head.reg_post_kernel,model.roi_head.bbox_head.cls_out_channels,model.roi_head.bbox_head.reg_feat_up_ratio,model.roi_head.bbox_head.reg_cls_out_channels,model.roi_head.bbox_head.reg_offset_out_channels,lang_model_name,model.backbone.depths,model.backbone.qk_scale,model.backbone.qkv_bias,model.backbone.drop_rate,model.backbone.mlp_ratio,model.backbone.num_heads,model.backbone.embed_dims,model.backbone.patch_norm,model.backbone.window_size,model.backbone.attn_drop_rate,model.backbone.convert_weights,model.bbox_head.early_fuse,model.bbox_head.use_checkpoint,model.bbox_head.lang_model_name,model.bbox_head.anchor_generator.center_offset,model.bbox_head.num_dyhead_blocks,model.train_cfg.assigner.iou_calculator.type,model.language_model.name,model.language_model.type,optim_wrapper.optimizer.betas,optim_wrapper.paramwise_cfg.custom_keys.norm.decay_mult,optim_wrapper.paramwise_cfg.custom_keys.absolute_pos_embed.decay_mult,optim_wrapper.paramwise_cfg.custom_keys.relative_position_bias_table.decay_mult,val_dataloader.dataset.return_classes,test_dataloader.dataset.return_classes,train_dataloader.dataset.dataset.return_classes,max_iters,image_size,pretrained,loss_lambda,num_classes,load_pipeline,num_dec_layer,batch_augments,model.use_lsj,model.backbone.pretrain_img_size,model.roi_head,model.rpn_head.anchor_generator.octave_base_scale,model.rpn_head.anchor_generator.scales_per_octave,model.test_cfg,model.bbox_head,model.query_head.type,model.query_head.dn_cfg.group_cfg.dynamic,model.query_head.dn_cfg.group_cfg.num_groups,model.query_head.dn_cfg.group_cfg.num_dn_queries,model.query_head.dn_cfg.box_noise_scale,model.query_head.dn_cfg.label_noise_scale,model.query_head.loss_cls.beta,model.query_head.loss_cls.type,model.query_head.loss_cls.loss_weight,model.query_head.loss_cls.use_sigmoid,model.query_head.loss_iou.type,model.query_head.loss_iou.loss_weight,model.query_head.loss_bbox.type,model.query_head.loss_bbox.loss_weight,model.query_head.num_query,model.query_head.in_channels,model.query_head.num_classes,model.query_head.transformer.type,model.query_head.transformer.decoder.type,model.query_head.transformer.decoder.num_layers,model.query_head.transformer.decoder.transformerlayers.type,model.query_head.transformer.decoder.transformerlayers.attn_cfgs,model.query_head.transformer.decoder.transformerlayers.ffn_dropout,model.query_head.transformer.decoder.transformerlayers.operation_order,model.query_head.transformer.decoder.transformerlayers.feedforward_channels,model.query_head.transformer.decoder.return_intermediate,model.query_head.transformer.encoder.type,model.query_head.transformer.encoder.with_cp,model.query_head.transformer.encoder.num_layers,model.query_head.transformer.encoder.transformerlayers.type,model.query_head.transformer.encoder.transformerlayers.attn_cfgs.type,model.query_head.transformer.encoder.transformerlayers.attn_cfgs.dropout,model.query_head.transformer.encoder.transformerlayers.attn_cfgs.embed_dims,model.query_head.transformer.encoder.transformerlayers.attn_cfgs.num_levels,model.query_head.transformer.encoder.transformerlayers.ffn_dropout,model.query_head.transformer.encoder.transformerlayers.operation_order,model.query_head.transformer.encoder.transformerlayers.feedforward_channels,model.query_head.transformer.num_co_heads,model.query_head.transformer.with_coord_feat,model.query_head.transformer.num_feature_levels,model.query_head.as_two_stage,model.query_head.positional_encoding.type,model.query_head.positional_encoding.normalize,model.query_head.positional_encoding.num_feats,model.query_head.positional_encoding.temperature,model.eval_module,model.data_preprocessor.batch_augments,val_cfg._scope_,test_cfg._scope_,visualizer._scope_,default_hooks.timer._scope_,default_hooks.logger._scope_,default_hooks.checkpoint._scope_,default_hooks.checkpoint.by_epoch,default_hooks.checkpoint.max_keep_ckpts,default_hooks.sampler_seed._scope_,default_hooks.visualization._scope_,default_hooks.param_scheduler._scope_,log_processor._scope_,val_evaluator._scope_,custom_imports.imports,custom_imports.allow_failed_imports,test_evaluator._scope_,val_dataloader.dataset._scope_,val_dataloader.sampler._scope_,test_dataloader.dataset._scope_,test_dataloader.sampler._scope_,train_dataloader.dataset._scope_,train_dataloader.sampler._scope_,num_levels,model.roi_head.bbox_head.num_fcs,model.roi_head.bbox_head.num_convs,model.roi_head.bbox_head.conv_out_channels,model.roi_head.reg_roi_scale_factor,optim_wrapper.paramwise_cfg.custom_keys.reference_points.lr_mult,optim_wrapper.paramwise_cfg.custom_keys.sampling_offsets.lr_mult,model.bbox_head.loss_iou.use_sigmoid,model.train_cfg.assigner.alpha,model.train_cfg.reg_assigner.topk,model.train_cfg.reg_assigner.type,model.train_cfg.reg_assigner.alpha,model.bbox_head.bbox_coder.num_buckets,model.bbox_head.bbox_coder.scale_factor,model.bbox_head.loss_bbox_cls.type,model.bbox_head.loss_bbox_cls.loss_weight,model.bbox_head.loss_bbox_cls.use_sigmoid,model.bbox_head.loss_bbox_reg.beta,model.bbox_head.loss_bbox_reg.type,model.bbox_head.loss_bbox_reg.loss_weight,model.bbox_head.approx_anchor_generator.type,model.bbox_head.approx_anchor_generator.ratios,model.bbox_head.approx_anchor_generator.strides,model.bbox_head.approx_anchor_generator.octave_base_scale,model.bbox_head.approx_anchor_generator.scales_per_octave,model.bbox_head.square_anchor_generator.type,model.bbox_head.square_anchor_generator.ratios,model.bbox_head.square_anchor_generator.scales,model.bbox_head.square_anchor_generator.strides,model.decoder.layer_cfg.self_attn_cfg.proj_drop,model.decoder.layer_cfg.cross_attn_cfg.proj_drop,model.decoder.query_dim,model.decoder.query_scale_type,model.decoder.with_modulated_hw_attn,model.num_patterns,model.with_random_refpoints,model.backbone.dcn.deformable_groups,model.bbox_head.num_dcn,model.bbox_head.loss_cls.beta,model.bbox_head.loss_cls.activated,model.bbox_head.anchor_type,model.bbox_head.initial_loss_cls.type,model.bbox_head.initial_loss_cls.alpha,model.bbox_head.initial_loss_cls.gamma,model.bbox_head.initial_loss_cls.activated,model.bbox_head.initial_loss_cls.loss_weight,model.bbox_head.initial_loss_cls.use_sigmoid,model.train_cfg.beta,model.train_cfg.alpha,model.train_cfg.initial_epoch,model.train_cfg.initial_assigner.topk,model.train_cfg.initial_assigner.type,base_lr,interval,checkpoint,custom_hooks,stage2_num_epochs,train_pipeline_stage2,model.neck.act_cfg.type,model.neck.act_cfg.inplace,model.neck.expand_ratio,model.neck.num_csp_blocks,model.backbone.strides,model.bbox_head.act_cfg.type,model.bbox_head.act_cfg.inplace,model.bbox_head.exp_on_reg,model.bbox_head.share_conv,model.bbox_head.with_objectness,model.bbox_head.anchor_generator.offset,model.bbox_head.pred_kernel_size,train_cfg.dynamic_intervals,optim_wrapper.paramwise_cfg.norm_decay_mult,optim_wrapper.paramwise_cfg.bypass_duplicate,val_evaluator.proposal_nums,test_evaluator.proposal_nums,train_dataloader.pin_memory,train_dataloader.batch_sampler,model.backbone.groups,model.backbone.base_width,visualizer.vis_backends.init_kwargs.config.attack_kwargs.targeted,visualizer.vis_backends.init_kwargs.config.attack_kwargs.random_start,attack_kwargs.targeted,attack_kwargs.random_start,visualizer.vis_backends.init_kwargs.config.attack_kwargs.norm,attack_kwargs.norm,name
0.007925040452811975,0.288,0.023,0.0,0.52,0.278,0.056036015459919805,5.0,379.2394361495972,1720392429.999793,0.393,378,media/images/val_img_4_6d1afb9031719edc2f56.png,391432.0,image-file,1000.0,png,375.0,6d1afb9031719edc2f56c691b109b92dd7b92d9c7656d37ac7ffe19a5a103b26,,,,,,,none,True,none,slurm/results/free_anchor_convnext-b_voc0712/none_epsilon0_alpha0_steps0,data/VOCdevkit/,models/free_anchor_convnext-b_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_convnext-b_voc0712/free_anchor_convnext-b_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_input,RetinaNet,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_convnext-b_voc0712,free_anchor_convnext-b_voc0712,none,models/free_anchor_convnext-b_voc0712/free_anchor_convnext-b_voc0712.py,0.0,0.0,0.0,models/free_anchor_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,0.0,0.0,0.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,free_anchor_convnext-b_voc0712
0.013465225315093992,0.399,0.435,0.176,0.604,0.417,0.04960075879096985,5.0,358.1478614807129,1720392292.8901165,0.594,357,media/images/val_img_4_a31b6008b251012a1c10.png,494147.0,image-file,850.0,png,640.0,a31b6008b251012a1c10da1d5662272a326676a2861a1d3d0bec9984b37b7efa,,,,,,,none,False,,slurm/results/DETR_R-50-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/DETR_R-50-FPN/latest.pth,INFO,,models/DETR_R-50-FPN/DETR_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/DETR_R-50-FPN/latest.pth,"[{'end': 150, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [100]}]",ChannelMapper,1.0,[2048],,256.0,,DETR,,ResNet,,Pretrained,,torchvision://resnet50,[3],,,,,,,,100.0,,DETRHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,150.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DETR_R-50-FPN,DETR_R-50-FPN,none,models/DETR_R-50-FPN/DETR_R-50-FPN.py,0.0,0.0,0.0,models/DETR_R-50-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0001,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,150.0,,,1.0,ReLU,True,2.0,0.1,256.0,2048.0,0.1,8.0,256.0,True,0.1,8.0,256.0,True,6.0,True,ReLU,True,2.0,0.1,256.0,2048.0,0.1,8.0,256.0,True,6.0,50.0,pytorch,BN,False,True,4.0,1.0,CrossEntropyLoss,1.0,False,1.0,0.1,GIoULoss,2.0,256.0,"[{'type': 'ClassificationCost', 'weight': 1}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",100.0,True,128.0,0.1,1.0,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,DETR_R-50-FPN
0.0135525249004364,0.43,0.471,0.238,0.605,0.459,0.09701670393943788,5.0,565.258650302887,1720392499.8285134,0.575,564,media/images/val_img_4_cf22c866cb4a6cecacfa.png,490464.0,image-file,850.0,png,640.0,cf22c866cb4a6cecacfa8b75a54eac4a71b8b61b5e4f23eb1595074c43ddaba8,,,,,,,none,False,,slurm/results/SABL Cascade R-CNN_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/SABL Cascade R-CNN_R-101-FPN/latest.pth,INFO,,models/SABL Cascade R-CNN_R-101-FPN/SABL Cascade R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/SABL Cascade R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,CascadeRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,SABL Cascade R-CNN_R-101-FPN,SABL Cascade R-CNN_R-101-FPN,none,models/SABL Cascade R-CNN_R-101-FPN/SABL Cascade R-CNN_R-101-FPN.py,0.0,0.0,0.0,models/SABL Cascade R-CNN_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,CascadeRoIHead,"[{'type': 'SABLHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'norm_cfg': None, 'bbox_coder': {'type': 'BucketingBBoxCoder', 'num_buckets': 14, 'scale_factor': 1.7}, 'num_classes': 80, 'num_cls_fcs': 1, 'num_reg_fcs': 0, 'reg_pre_num': 2, 'reg_post_num': 1, 'loss_bbox_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': True}, 'loss_bbox_reg': {'beta': 0.1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'roi_feat_size': 7, 'reg_pre_kernel': 3, 'cls_in_channels': 256, 'reg_in_channels': 256, 'reg_post_kernel': 3, 'cls_out_channels': 1024, 'reg_feat_up_ratio': 2, 'reg_class_agnostic': True, 'reg_cls_out_channels': 256, 'reg_offset_out_channels': 256}, {'type': 'SABLHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'norm_cfg': None, 'bbox_coder': {'type': 'BucketingBBoxCoder', 'num_buckets': 14, 'scale_factor': 1.5}, 'num_classes': 80, 'num_cls_fcs': 1, 'num_reg_fcs': 0, 'reg_pre_num': 2, 'reg_post_num': 1, 'loss_bbox_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': True}, 'loss_bbox_reg': {'beta': 0.1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'roi_feat_size': 7, 'reg_pre_kernel': 3, 'cls_in_channels': 256, 'reg_in_channels': 256, 'reg_post_kernel': 3, 'cls_out_channels': 1024, 'reg_feat_up_ratio': 2, 'reg_class_agnostic': True, 'reg_cls_out_channels': 256, 'reg_offset_out_channels': 256}, {'type': 'SABLHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'norm_cfg': None, 'bbox_coder': {'type': 'BucketingBBoxCoder', 'num_buckets': 14, 'scale_factor': 1.3}, 'num_classes': 80, 'num_cls_fcs': 1, 'num_reg_fcs': 0, 'reg_pre_num': 2, 'reg_post_num': 1, 'loss_bbox_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': True}, 'loss_bbox_reg': {'beta': 0.1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'roi_feat_size': 7, 'reg_pre_kernel': 3, 'cls_in_channels': 256, 'reg_in_channels': 256, 'reg_post_kernel': 3, 'cls_out_channels': 1024, 'reg_feat_up_ratio': 2, 'reg_class_agnostic': True, 'reg_cls_out_channels': 256, 'reg_offset_out_channels': 256}]",3.0,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]","[1, 0.5, 0.25]",RPNHead,CrossEntropyLoss,1.0,True,0.1111111111111111,SmoothL1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,0.0,"[{'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.5, 'neg_iou_thr': 0.5, 'pos_iou_thr': 0.5, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}, {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.6, 'neg_iou_thr': 0.6, 'pos_iou_thr': 0.6, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}, {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.7, 'neg_iou_thr': 0.7, 'pos_iou_thr': 0.7, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}]",nms,0.7,2000.0,2000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SABL Cascade R-CNN_R-101-FPN
0.013675462818145752,0.451,0.493,0.279,0.629,0.493,0.1475590090274811,5.0,875.1105906963348,1720392723.7226975,0.589,874,media/images/val_img_4_84abae96ad8ee93a1994.png,493412.0,image-file,850.0,png,640.0,84abae96ad8ee93a1994acc684adc525c36ff5cc28bcb261d0950a5d6151a009,,,,,,,none,False,,slurm/results/PAA_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/PAA_R-101-FPN/latest.pth,INFO,,models/PAA_R-101-FPN/PAA_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 640], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/PAA_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 36, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [28, 34]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,PAA,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,PAAHead,,GIoULoss,1.3,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,MaxIoUAssigner,0.0,0.1,0.1,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,36.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,PAA_R-101-FPN,PAA_R-101-FPN,none,models/PAA_R-101-FPN/PAA_R-101-FPN.py,0.0,0.0,0.0,models/PAA_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,36.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 640], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,0.25,2.0,True,CrossEntropyLoss,0.5,True,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,PAA_R-101-FPN
0.013284743642807007,0.425,0.465,0.235,0.607,0.464,0.07377906718254089,5.0,444.119286775589,1720392250.5378268,0.564,443,media/images/val_img_4_f338085857af413c8472.png,492418.0,image-file,850.0,png,640.0,f338085857af413c8472a362bec029f92b1d4c615b4611b4acc69ab4cd09659d,,,,,,,none,False,,slurm/results/Cascade R-CNN_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/Cascade R-CNN_R-101-FPN/latest.pth,INFO,,models/Cascade R-CNN_R-101-FPN/Cascade R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Cascade R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 20, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 19]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,CascadeRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,20.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Cascade R-CNN_R-101-FPN,Cascade R-CNN_R-101-FPN,none,models/Cascade R-CNN_R-101-FPN/Cascade R-CNN_R-101-FPN.py,0.0,0.0,0.0,models/Cascade R-CNN_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,CascadeRoIHead,"[{'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'loss_bbox': {'beta': 1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.1, 0.1, 0.2, 0.2], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_class_agnostic': True}, {'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'loss_bbox': {'beta': 1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.05, 0.05, 0.1, 0.1], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_class_agnostic': True}, {'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'loss_bbox': {'beta': 1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.033, 0.033, 0.067, 0.067], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_class_agnostic': True}]",3.0,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]","[1, 0.5, 0.25]",RPNHead,CrossEntropyLoss,1.0,True,0.1111111111111111,SmoothL1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,0.0,"[{'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.5, 'neg_iou_thr': 0.5, 'pos_iou_thr': 0.5, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}, {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.6, 'neg_iou_thr': 0.6, 'pos_iou_thr': 0.6, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}, {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.7, 'neg_iou_thr': 0.7, 'pos_iou_thr': 0.7, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}]",nms,0.7,2000.0,2000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Cascade R-CNN_R-101-FPN
0.02157299962043762,0.434,0.473,0.242,0.614,0.472,0.10513274054527284,5.0,639.2066607475281,1720392205.2858238,0.578,638,media/images/val_img_4_162fa3e911c630d8f667.png,492568.0,image-file,850.0,png,640.0,162fa3e911c630d8f667ab8865b6e329722e22d77d17819c586db688c8be5b96,0.41,0.41,0.174,0.588,0.378,0.555,none,False,,slurm/results/Cascade Mask R-CNN_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/Cascade Mask R-CNN_R-101-FPN/latest.pth,INFO,,models/Cascade Mask R-CNN_R-101-FPN/Cascade Mask R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Cascade Mask R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 20, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 19]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,CascadeRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,20.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Cascade Mask R-CNN_R-101-FPN,Cascade Mask R-CNN_R-101-FPN,none,models/Cascade Mask R-CNN_R-101-FPN/Cascade Mask R-CNN_R-101-FPN.py,0.0,0.0,0.0,models/Cascade Mask R-CNN_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,"['bbox', 'segm']",data/coco/annotations/instances_val2017.json,False,,CocoMetric,"['bbox', 'segm']",data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,CascadeRoIHead,"[{'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'loss_bbox': {'beta': 1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.1, 0.1, 0.2, 0.2], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_class_agnostic': True}, {'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'loss_bbox': {'beta': 1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.05, 0.05, 0.1, 0.1], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_class_agnostic': True}, {'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'loss_bbox': {'beta': 1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.033, 0.033, 0.067, 0.067], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_class_agnostic': True}]",3.0,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]","[1, 0.5, 0.25]",RPNHead,CrossEntropyLoss,1.0,True,0.1111111111111111,SmoothL1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,0.0,"[{'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.5, 'neg_iou_thr': 0.5, 'pos_iou_thr': 0.5, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'mask_size': 28, 'pos_weight': -1}, {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.6, 'neg_iou_thr': 0.6, 'pos_iou_thr': 0.6, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'mask_size': 28, 'pos_weight': -1}, {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.7, 'neg_iou_thr': 0.7, 'pos_iou_thr': 0.7, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'mask_size': 28, 'pos_weight': -1}]",nms,0.7,2000.0,2000.0,0.0,,,,,,,,,FCNMaskHead,CrossEntropyLoss,True,1.0,4.0,256.0,80.0,256.0,SingleRoIExtractor,RoIAlign,14.0,0.0,256.0,"[4, 8, 16, 32]",0.5,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Cascade Mask R-CNN_R-101-FPN
0.013233999729156494,0.389,0.419,0.221,0.576,0.427,0.05271570992469787,5.0,341.9798963069916,1720391906.0627992,0.517,341,media/images/val_img_4_051872c2727fee78ccec.png,489622.0,image-file,850.0,png,640.0,051872c2727fee78ccec2a79efa9bba33392d679c0db7c3fef3eab2dd7399e2e,,,,,,,none,False,,slurm/results/Dynamic R-CNN_R-50-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/Dynamic R-CNN_R-50-FPN/latest.pth,INFO,,models/Dynamic R-CNN_R-50-FPN/Dynamic R-CNN_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Dynamic R-CNN_R-50-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Dynamic R-CNN_R-50-FPN,Dynamic R-CNN_R-50-FPN,none,models/Dynamic R-CNN_R-50-FPN/Dynamic R-CNN_R-50-FPN.py,0.0,0.0,0.0,models/Dynamic R-CNN_R-50-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,DynamicRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.85,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.85,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,SmoothL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,7.0,1024.0,False,False,512.0,RandomSampler,-1.0,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,75.0,10.0,0.4,1.0,100.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Dynamic R-CNN_R-50-FPN
0.013289448022842407,0.415,0.459,0.242,0.599,0.452,0.06388065857887268,5.0,423.4855797290802,1720391866.9384856,0.533,423,media/images/val_img_4_29b4de2f3471af468cb5.png,489197.0,image-file,850.0,png,640.0,29b4de2f3471af468cb57206ccfe4520cc4a8e94e262e3580ed4a7ae972b4cfd,,,,,,,none,False,,slurm/results/ATSS_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/ATSS_R-101-FPN/latest.pth,INFO,,models/ATSS_R-101-FPN/ATSS_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/ATSS_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,ATSS_R-101-FPN,ATSS_R-101-FPN,none,models/ATSS_R-101-FPN/ATSS_R-101-FPN.py,0.0,0.0,0.0,models/ATSS_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,ATSS_R-101-FPN
0.009166395931370976,0.565,0.408,0.211,0.834,0.616,0.04134587068979413,5.0,293.37154603004456,1720391647.742593,0.622,292,media/images/val_img_4_4b75a19c3e572fcf82ba.png,351740.0,image-file,1000.0,png,375.0,4b75a19c3e572fcf82ba0bf9b3939ce6c93825ea5b32e4b6a09e4e7abb454e7b,,,,,,,none,True,none,slurm/results/free_anchor_r101_voc0712/none_epsilon0_alpha0_steps0,data/VOCdevkit/,models/free_anchor_r101_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_r101_voc0712/free_anchor_r101_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_r101_voc0712,free_anchor_r101_voc0712,none,models/free_anchor_r101_voc0712/free_anchor_r101_voc0712.py,0.0,0.0,0.0,models/free_anchor_r101_voc0712/epoch_4.pth,846186413151,attacks,0.0,0.0,0.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,free_anchor_r101_voc0712
,,,,,,,4.0,303.65125036239624,1720391656.7925982,,425,media/images/val_img_4_942ade7a3251d4678464.png,697448.0,image-file,850.0,png,640.0,942ade7a3251d4678464bbbeecdbc29b28f0205cd50d0d59ec5233e4f5199099,,,,,,,none,False,,slurm/results/RPN_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/RPN_R-101-FPN/latest.pth,INFO,,models/RPN_R-101-FPN/RPN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/RPN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,RPN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,RPN_R-101-FPN,RPN_R-101-FPN,none,models/RPN_R-101-FPN/RPN_R-101-FPN.py,0.0,0.0,0.0,models/RPN_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,proposal_fast,data/coco/annotations/instances_val2017.json,False,,CocoMetric,proposal_fast,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,24.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,2000.0,1000.0,0.0,,,,,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,,-1.0,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,RPN_R-101-FPN
0.013565667533874512,0.42,0.465,0.252,0.625,0.449,0.07198978371620178,5.0,458.44241976737976,1720391782.2728157,0.542,458,media/images/val_img_4_38de192cb369775f4143.png,493062.0,image-file,850.0,png,640.0,38de192cb369775f41439534ca355a1302c50bee0f6775da7b1fcd91738793cf,,,,,,,none,False,,slurm/results/FoveaBox_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/FoveaBox_R-101-FPN/latest.pth,INFO,,models/FoveaBox_R-101-FPN/FoveaBox_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomChoiceResize', 'scales': [[1333, 640], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/FoveaBox_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FOVEA,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,,FoveaHead,0.11,SmoothL1Loss,1.0,,,,256.0,80.0,256.0,4.0,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,FoveaBox_R-101-FPN,FoveaBox_R-101-FPN,none,models/FoveaBox_R-101-FPN/FoveaBox_R-101-FPN.py,0.0,0.0,0.0,models/FoveaBox_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,4.0,24.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomChoiceResize', 'scales': [[1333, 640], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,4.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.4,1.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.4,"[8, 16, 32, 64, 128]",GN,32.0,True,True,"[[1, 64], [32, 128], [64, 256], [128, 512], [256, 2048]]","[16, 32, 64, 128, 256]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FoveaBox_R-101-FPN
0.014511545753479004,0.295,0.329,0.102,0.461,0.314,0.026683119106292726,5.0,246.5411729812622,1720391450.993645,0.467,246,media/images/val_img_4_5325cf1f533c0cc30623.png,493471.0,image-file,850.0,png,640.0,5325cf1f533c0cc306233a1348efceaf8b306c459a0a84fd4a42e5ce6c116b54,,,,,,,none,False,,slurm/results/CenterNet_ResNet-18/none_epsilon0_alpha0_steps0,data/coco/,models/CenterNet_ResNet-18/latest.pth,INFO,,models/CenterNet_ResNet-18/CenterNet_ResNet-18.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'to_float32': True, 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'std': [1, 1, 1], 'mean': [0, 0, 0], 'type': 'RandomCenterCropPad', 'border': None, 'ratios': None, 'to_rgb': True, 'test_mode': True, 'test_pad_mode': ['logical_or', 31], 'test_pad_add_pix': 1}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'flip', 'flip_direction', 'border']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'to_float32': True, 'backend_args': None}, {'std': [1, 1, 1], 'mean': [0, 0, 0], 'type': 'RandomCenterCropPad', 'border': None, 'ratios': None, 'to_rgb': True, 'test_mode': True, 'test_pad_mode': ['logical_or', 31], 'test_pad_add_pix': 1}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'border']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PhotoMetricDistortion', 'hue_delta': 18, 'contrast_range': [0.5, 1.5], 'brightness_delta': 32, 'saturation_range': [0.5, 1.5]}, {'std': [1, 1, 1], 'mean': [0, 0, 0], 'type': 'RandomCenterCropPad', 'ratios': [0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3], 'to_rgb': True, 'crop_size': [512, 512], 'test_pad_mode': None}, {'type': 'Resize', 'scale': [512, 512], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/CenterNet_ResNet-18/latest.pth,"[{'end': 1000, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 28, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [18, 24]}]",CTResNetNeck,,512,,,,CenterNet,,ResNet,,Pretrained,,torchvision://resnet18,,,,,,,,,100.0,,CenterNetHead,,,,,,,64.0,80.0,64.0,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,28.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,CenterNet_ResNet-18,CenterNet_ResNet-18,none,models/CenterNet_ResNet-18/CenterNet_ResNet-18.py,0.0,0.0,0.0,models/CenterNet_ResNet-18/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,128.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'to_float32': True, 'backend_args': None}, {'std': [1, 1, 1], 'mean': [0, 0, 0], 'type': 'RandomCenterCropPad', 'border': None, 'ratios': None, 'to_rgb': True, 'test_mode': True, 'test_pad_mode': ['logical_or', 31], 'test_pad_add_pix': 1}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'border']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'to_float32': True, 'backend_args': None}, {'std': [1, 1, 1], 'mean': [0, 0, 0], 'type': 'RandomCenterCropPad', 'border': None, 'ratios': None, 'to_rgb': True, 'test_mode': True, 'test_pad_mode': ['logical_or', 31], 'test_pad_add_pix': 1}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'border']}]",data/coco/,val2017/,1.0,RepeatDataset,5.0,CocoDataset,annotations/instances_train2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PhotoMetricDistortion', 'hue_delta': 18, 'contrast_range': [0.5, 1.5], 'brightness_delta': 32, 'saturation_range': [0.5, 1.5]}, {'std': [1, 1, 1], 'mean': [0, 0, 0], 'type': 'RandomCenterCropPad', 'ratios': [0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3], 'to_rgb': True, 'crop_size': [512, 512], 'test_pad_mode': None}, {'type': 'Resize', 'scale': [512, 512], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,16.0,28.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,18.0,,BN,,False,,,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,,,,,,,,DefaultSampler,True,4.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,"[256, 128, 64]","[4, 4, 4]",100.0,3.0,L1Loss,0.1,L1Loss,1.0,GaussianFocalLoss,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,CenterNet_ResNet-18
0.008249833322452242,0.515,0.364,0.213,0.805,0.541,0.03396523285220181,5.0,239.8468346595764,1720391203.7754147,0.567,239,media/images/val_img_4_8805daa5479b247d3ee2.png,356092.0,image-file,1000.0,png,375.0,8805daa5479b247d3ee21908737f250f0e78d7fa917e67a0fa0b76aa6fcedd6d,,,,,,,none,True,none,slurm/results/fsaf_r50_voc0712/none_epsilon0_alpha0_steps0,data/VOCdevkit/,models/fsaf_r50_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_r50_voc0712/fsaf_r50_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_r50_voc0712,fsaf_r50_voc0712,none,models/fsaf_r50_voc0712/fsaf_r50_voc0712.py,0.0,0.0,0.0,models/fsaf_r50_voc0712/epoch_4.pth,846186413151,attacks,0.0,0.0,0.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,fsaf_r50_voc0712
0.00816274931183878,0.564,0.406,0.201,0.818,0.617,0.04060231245769868,5.0,279.16235518455505,1720391124.0666502,0.624,278,media/images/val_img_4_0b2dcbf8ccd90e2b23e9.png,349631.0,image-file,1000.0,png,374.0,0b2dcbf8ccd90e2b23e90c55a6e05b5ed50a179511e8d67352b70ccbbad41b8b,,,,,,,none,True,none,slurm/results/atss_r101_voc0712/none_epsilon0_alpha0_steps0,data/VOCdevkit/,models/atss_r101_voc0712/epoch_3.pth,INFO,,models/atss_r101_voc0712/atss_r101_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_r101_voc0712/epoch_3.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_r101_voc0712,atss_r101_voc0712,none,models/atss_r101_voc0712/atss_r101_voc0712.py,0.0,0.0,0.0,models/atss_r101_voc0712/epoch_3.pth,846186413151,attacks,0.0,0.0,0.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,atss_r101_voc0712
0.01322289776802063,0.429,0.471,0.251,0.638,0.465,0.0817312578201294,5.0,510.7505509853363,1720391354.249714,0.57,510,media/images/val_img_4_793f819713b06821c2f0.png,492208.0,image-file,850.0,png,640.0,793f819713b06821c2f0f5ebb4fe49c64f2ae9f3a3a5f8a621870d8d60a07c10,,,,,,,none,False,,slurm/results/RepPoints_R-101-FPN-DCN/none_epsilon0_alpha0_steps0,data/coco/,models/RepPoints_R-101-FPN-DCN/latest.pth,INFO,,models/RepPoints_R-101-FPN-DCN/RepPoints_R-101-FPN-DCN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/RepPoints_R-101-FPN-DCN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RepPointsDetector,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,RepPointsHead,,,,,,,256.0,80.0,256.0,3.0,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,RepPoints_R-101-FPN-DCN,RepPoints_R-101-FPN-DCN,none,models/RepPoints_R-101-FPN-DCN/RepPoints_R-101-FPN-DCN.py,0.0,0.0,0.0,models/RepPoints_R-101-FPN-DCN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,24.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,True,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,True,DCN,1.0,False,"[False, True, True, True]",9.0,0.1,"[8, 16, 32, 64, 128]",0.11,SmoothL1Loss,0.5,0.11,SmoothL1Loss,1.0,4.0,moment,256.0,False,PointAssigner,4.0,1.0,-1.0,-1.0,False,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,GN,32.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,RepPoints_R-101-FPN-DCN
0.013557447481155395,0.49,0.532,0.304,0.671,0.532,0.0863533664226532,5.0,532.9564719200134,1720391134.8232088,0.642,532,media/images/val_img_4_01af0573c2059c30774b.png,489366.0,image-file,850.0,png,640.0,01af0573c2059c30774becb4828546bad9dbe7aa6dca5dc280bd1b4ee1bdc463,,,,,,,none,False,,slurm/results/VarifocalNet_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/VarifocalNet_R-101-FPN/latest.pth,INFO,,models/VarifocalNet_R-101-FPN/VarifocalNet_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 480], [1333, 960]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/VarifocalNet_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.1}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,VFNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,VFNetHead,,GIoULoss,1.5,,,,256.0,80.0,256.0,3.0,,,,,,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,VarifocalNet_R-101-FPN,VarifocalNet_R-101-FPN,none,models/VarifocalNet_R-101-FPN/VarifocalNet_R-101-FPN.py,0.0,0.0,0.0,models/VarifocalNet_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,24.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,VarifocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 480], [1333, 960]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.75,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,"[8, 16, 32, 64, 128]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,DCNv2,1.0,False,"[False, True, True, True]",,,,,,,,GIoULoss,2.0,,,,,,,,,,,,,,,,,,,,,True,True,True,True,False,True,,2.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,VarifocalNet_R-101-FPN
0.008139024665566038,0.134,0.003,0.0,0.309,0.1,0.059261714427754686,5.0,362.6956305503845,1720390845.8799005,0.18,362,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,none,True,none,slurm/results/libra_rcnn_convnext-b_voc0712/none_epsilon0_alpha0_steps0,data/VOCdevkit/,models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_convnext-b_voc0712/libra_rcnn_convnext-b_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_convnext-b_voc0712,libra_rcnn_convnext-b_voc0712,none,models/libra_rcnn_convnext-b_voc0712/libra_rcnn_convnext-b_voc0712.py,0.0,0.0,0.0,models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,0.0,0.0,0.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,libra_rcnn_convnext-b_voc0712
0.008258846343803136,0.551,0.41,0.246,0.848,0.617,0.04347125472575757,5.0,279.57132935523987,1720390649.8763704,0.601,279,media/images/val_img_4_d728c19e9d8a1d96478b.png,355946.0,image-file,1000.0,png,375.0,d728c19e9d8a1d96478b7089a59e73eb604291150f83183907d78a3adb04db82,,,,,,,none,True,none,slurm/results/libra_rcnn_r101_voc0712/none_epsilon0_alpha0_steps0,data/VOCdevkit/,models/libra_rcnn_r101_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_r101_voc0712/libra_rcnn_r101_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_r101_voc0712,libra_rcnn_r101_voc0712,none,models/libra_rcnn_r101_voc0712/libra_rcnn_r101_voc0712.py,0.0,0.0,0.0,models/libra_rcnn_r101_voc0712/epoch_4.pth,846186413151,attacks,0.0,0.0,0.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,libra_rcnn_r101_voc0712
0.013376484107971192,0.521,0.547,0.367,0.689,0.573,0.24618833265304568,5.0,1428.7598385810852,1720391790.6914847,0.662,1428,media/images/val_img_4_45504b0cb21ac36c481f.png,490621.0,image-file,850.0,png,640.0,45504b0cb21ac36c481f731d7cd27d23b369d45534d1a433adba5977d5a9ecfc,,,,,,,none,False,,slurm/results/DDQ DETR-5scale_R-50-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/DDQ DETR-5scale_R-50-FPN/latest.pth,INFO,,models/DDQ DETR-5scale_R-50-FPN/DDQ DETR-5scale_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/DDQ DETR-5scale_R-50-FPN/latest.pth,"[{'end': 2000, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.0001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [11]}]",ChannelMapper,5.0,"[256, 512, 1024, 2048]",,256.0,,DDQDETR,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,300.0,,DDQDETRHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DDQ DETR-5scale_R-50-FPN,DDQ DETR-5scale_R-50-FPN,none,models/DDQ DETR-5scale_R-50-FPN/DDQ DETR-5scale_R-50-FPN.py,0.0,0.0,0.0,models/DDQ DETR-5scale_R-50-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0002,AdamW,,0.05,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,12.0,,,1.0,,,,0.0,256.0,2048.0,0.0,8.0,256.0,,0.0,,256.0,,6.0,True,,,,0.0,256.0,2048.0,0.0,,256.0,,6.0,50.0,pytorch,BN,False,True,4.0,1.0,FocalLoss,1.0,True,,,GIoULoss,2.0,,"[{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",900.0,True,128.0,0.1,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,False,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,,100.0,1.0,0.5,5.0,,nms,0.8,5.0,True,True,True,1.5,5.0,0.0,20.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,DDQ DETR-5scale_R-50-FPN
0.013492129755020142,0.404,0.439,0.227,0.585,0.436,0.0683779932975769,5.0,427.4678244590759,1720390433.6398814,0.53,426,media/images/val_img_4_1bbdf4bf99562deee871.png,491625.0,image-file,850.0,png,640.0,1bbdf4bf99562deee8713554f3218555dcea94898cf0577e9e9a05a6ffbc1804,,,,,,,none,False,,slurm/results/Grid R-CNN_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/Grid R-CNN_R-101-FPN/latest.pth,INFO,,models/Grid R-CNN_R-101-FPN/Grid R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Grid R-CNN_R-101-FPN/latest.pth,"[{'end': 3665, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.0125}, {'end': 25, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [17, 23]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,GridRCNN,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,25.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Grid R-CNN_R-101-FPN,Grid R-CNN_R-101-FPN,none,models/Grid R-CNN_R-101-FPN/Grid R-CNN_R-101-FPN.py,0.0,0.0,0.0,models/Grid R-CNN_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,25.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,GridRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,0.1111111111111111,SmoothL1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.3,0.03,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,,-1.0,0.0,,nms,0.7,2000.0,2000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,,,,,,,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,7.0,1024.0,False,False,512.0,RandomSampler,-1.0,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,GridHead,GN,36.0,CrossEntropyLoss,15.0,True,8.0,9.0,256.0,64.0,SingleRoIExtractor,RoIAlign,14.0,0.0,256.0,"[4, 8, 16, 32]",1.0,192.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Grid R-CNN_R-101-FPN
0.01317286057472229,0.41,0.445,0.204,0.619,0.435,0.05154379987716675,5.0,368.2890043258667,1720390247.1024573,0.599,367,media/images/val_img_4_519a27070216af6907e0.png,494445.0,image-file,850.0,png,640.0,519a27070216af6907e0af7c68c4e2bab7affc6c6c8535b3cbf9f8e93d6d99a2,,,,,,,none,False,,slurm/results/Conditional DETR_R-50-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/Conditional DETR_R-50-FPN/latest.pth,INFO,,models/Conditional DETR_R-50-FPN/Conditional DETR_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/Conditional DETR_R-50-FPN/latest.pth,"[{'end': 50, 'type': 'MultiStepLR', 'milestones': [40]}]",ChannelMapper,1.0,[2048],,256.0,,ConditionalDETR,,ResNet,,Pretrained,,torchvision://resnet50,[3],,,,,,,,100.0,,ConditionalDETRHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,50.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Conditional DETR_R-50-FPN,Conditional DETR_R-50-FPN,none,models/Conditional DETR_R-50-FPN/Conditional DETR_R-50-FPN.py,0.0,0.0,0.0,models/Conditional DETR_R-50-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0001,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,150.0,,,1.0,ReLU,True,2.0,0.1,256.0,2048.0,,8.0,256.0,,,8.0,256.0,,6.0,True,ReLU,True,2.0,0.1,256.0,2048.0,0.1,8.0,256.0,True,6.0,50.0,pytorch,BN,False,True,4.0,1.0,FocalLoss,2.0,True,,,GIoULoss,2.0,256.0,"[{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",300.0,True,128.0,0.1,1.0,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.1,False,0.1,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Conditional DETR_R-50-FPN
0.013065680360794068,0.462,0.492,0.295,0.651,0.504,0.0745264317035675,5.0,569.8080780506134,1720390328.19443,0.617,569,media/images/val_img_4_b6465e40a65ed90e8906.png,489376.0,image-file,850.0,png,640.0,b6465e40a65ed90e890674feefaa715e57134cc54bd4ea334c03c60c0325197f,,,,,,,none,False,,slurm/results/Sparse R-CNN_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/Sparse R-CNN_R-101-FPN/latest.pth,INFO,,models/Sparse R-CNN_R-101-FPN/Sparse R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/Sparse R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 36, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [27, 33]}]",FPN,4.0,"[256, 512, 1024, 2048]",0.0,256.0,on_input,SparseRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,36.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Sparse R-CNN_R-101-FPN,Sparse R-CNN_R-101-FPN,none,models/Sparse R-CNN_R-101-FPN/Sparse R-CNN_R-101-FPN.py,0.0,0.0,0.0,models/Sparse R-CNN_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,1.0,2.0,2.5e-05,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,36.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,SparseRoIHead,"[{'type': 'DIIHead', 'dropout': 0, 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 2, 'use_sigmoid': True}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5}, 'num_heads': 8, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_stds': [0.5, 0.5, 1, 1], 'target_means': [0, 0, 0, 0]}, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'in_channels': 256, 'num_classes': 80, 'num_cls_fcs': 1, 'num_ffn_fcs': 2, 'num_reg_fcs': 3, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}, 'in_channels': 256, 'out_channels': 256, 'feat_channels': 64, 'input_feat_shape': 7}, 'feedforward_channels': 2048}, {'type': 'DIIHead', 'dropout': 0, 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 2, 'use_sigmoid': True}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5}, 'num_heads': 8, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_stds': [0.5, 0.5, 1, 1], 'target_means': [0, 0, 0, 0]}, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'in_channels': 256, 'num_classes': 80, 'num_cls_fcs': 1, 'num_ffn_fcs': 2, 'num_reg_fcs': 3, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}, 'in_channels': 256, 'out_channels': 256, 'feat_channels': 64, 'input_feat_shape': 7}, 'feedforward_channels': 2048}, {'type': 'DIIHead', 'dropout': 0, 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 2, 'use_sigmoid': True}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5}, 'num_heads': 8, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_stds': [0.5, 0.5, 1, 1], 'target_means': [0, 0, 0, 0]}, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'in_channels': 256, 'num_classes': 80, 'num_cls_fcs': 1, 'num_ffn_fcs': 2, 'num_reg_fcs': 3, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}, 'in_channels': 256, 'out_channels': 256, 'feat_channels': 64, 'input_feat_shape': 7}, 'feedforward_channels': 2048}, {'type': 'DIIHead', 'dropout': 0, 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 2, 'use_sigmoid': True}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5}, 'num_heads': 8, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_stds': [0.5, 0.5, 1, 1], 'target_means': [0, 0, 0, 0]}, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'in_channels': 256, 'num_classes': 80, 'num_cls_fcs': 1, 'num_ffn_fcs': 2, 'num_reg_fcs': 3, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}, 'in_channels': 256, 'out_channels': 256, 'feat_channels': 64, 'input_feat_shape': 7}, 'feedforward_channels': 2048}, {'type': 'DIIHead', 'dropout': 0, 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 2, 'use_sigmoid': True}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5}, 'num_heads': 8, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_stds': [0.5, 0.5, 1, 1], 'target_means': [0, 0, 0, 0]}, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'in_channels': 256, 'num_classes': 80, 'num_cls_fcs': 1, 'num_ffn_fcs': 2, 'num_reg_fcs': 3, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}, 'in_channels': 256, 'out_channels': 256, 'feat_channels': 64, 'input_feat_shape': 7}, 'feedforward_channels': 2048}, {'type': 'DIIHead', 'dropout': 0, 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 2, 'use_sigmoid': True}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5}, 'num_heads': 8, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_stds': [0.5, 0.5, 1, 1], 'target_means': [0, 0, 0, 0]}, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'in_channels': 256, 'num_classes': 80, 'num_cls_fcs': 1, 'num_ffn_fcs': 2, 'num_reg_fcs': 3, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}, 'in_channels': 256, 'out_channels': 256, 'feat_channels': 64, 'input_feat_shape': 7}, 'feedforward_channels': 2048}]",6.0,SingleRoIExtractor,RoIAlign,7.0,2.0,256.0,"[4, 8, 16, 32]","[1, 1, 1, 1, 1, 1]",EmbeddingRPNHead,,,,,,,,,,,,,,,,,,,,,,,,300.0,,,,,,,,,,,,,,,"[{'sampler': {'type': 'PseudoSampler'}, 'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xyxy'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}, 'pos_weight': 1}, {'sampler': {'type': 'PseudoSampler'}, 'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xyxy'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}, 'pos_weight': 1}, {'sampler': {'type': 'PseudoSampler'}, 'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xyxy'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}, 'pos_weight': 1}, {'sampler': {'type': 'PseudoSampler'}, 'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xyxy'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}, 'pos_weight': 1}, {'sampler': {'type': 'PseudoSampler'}, 'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xyxy'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}, 'pos_weight': 1}, {'sampler': {'type': 'PseudoSampler'}, 'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xyxy'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}, 'pos_weight': 1}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.0,300.0,256.0,300.0,256.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Sparse R-CNN_R-101-FPN
0.01317477970123291,0.417,0.459,0.241,0.598,0.452,0.07282055492401122,5.0,446.0594115257263,1720389612.3907075,0.546,445,media/images/val_img_4_934e7b01e7da7b26ae78.png,492324.0,image-file,850.0,png,640.0,934e7b01e7da7b26ae786200c3e0b8b76db6ab2d9dcdf7de2dd4d3c6ddf53430,,,,,,,none,False,,slurm/results/SABL Faster R-CNN_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/SABL Faster R-CNN_R-101-FPN/latest.pth,INFO,,models/SABL Faster R-CNN_R-101-FPN/SABL Faster R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/SABL Faster R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,SABL Faster R-CNN_R-101-FPN,SABL Faster R-CNN_R-101-FPN,none,models/SABL Faster R-CNN_R-101-FPN/SABL Faster R-CNN_R-101-FPN.py,0.0,0.0,0.0,models/SABL Faster R-CNN_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,SABLHead,CrossEntropyLoss,1.0,False,,,,BucketingBBoxCoder,,,,80.0,7.0,,True,False,512.0,RandomSampler,-1.0,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,14.0,1.7,1.0,0.0,2.0,1.0,CrossEntropyLoss,1.0,True,0.1,SmoothL1Loss,1.0,3.0,256.0,256.0,3.0,1024.0,2.0,256.0,256.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SABL Faster R-CNN_R-101-FPN
0.018165153789520265,0.594,0.639,0.448,0.774,0.647,0.4285180741786957,5.0,2245.71715426445,1720391040.4631534,0.743,2245,media/images/val_img_4_d3932b9ecc641e2e8c68.png,489390.0,image-file,850.0,png,640.0,d3932b9ecc641e2e8c688a909c6f38a270dc9ad092296a866b2ec1d31a214294,,,,,,,none,False,,slurm/results/GLIP-L_Swin-L/none_epsilon0_alpha0_steps0,data/coco/,models/GLIP-L_Swin-L/latest.pth,INFO,,models/GLIP-L_Swin-L/GLIP-L_Swin-L.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None, 'imdecode_backend': 'pillow'}, {'type': 'FixScaleResize', 'scale': [800, 1333], 'backend': 'pillow', 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'text', 'custom_entities']}]","[{'type': 'LoadImageFromFile', 'backend_args': None, 'imdecode_backend': 'pillow'}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'GTBoxSubOne_GLIP'}, {'type': 'RandomChoiceResize', 'scales': [[1333, 480], [1333, 560], [1333, 640], [1333, 720], [1333, 800]], 'backend': 'pillow', 'keep_ratio': True, 'resize_type': 'FixScaleResize'}, {'prob': 0.5, 'type': 'RandomFlip_GLIP'}, {'type': 'FilterAnnotations', 'min_gt_bbox_wh': [1, 1]}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction', 'text', 'custom_entities']}]",models/GLIP-L_Swin-L/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN_DropBlock,5.0,"[384, 768, 1536]",0.0,256.0,on_output,GLIP,,SwinTransformer,False,,,,"[1, 2, 3]",0.4,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSVLFusionHead,,GIoULoss,2.0,DeltaXYWHBBoxCoderForGLIP,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,256.0,,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[57.375, 57.12, 58.395]","[103.53, 116.28, 123.675]",DetDataPreprocessor,False,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,GLIP-L_Swin-L,GLIP-L_Swin-L,none,models/GLIP-L_Swin-L/GLIP-L_Swin-L.py,0.0,0.0,0.0,models/GLIP-L_Swin-L/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,1.0,2.0,1e-05,AdamW,,0.05,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None, 'imdecode_backend': 'pillow'}, {'type': 'FixScaleResize', 'scale': [800, 1333], 'backend': 'pillow', 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'text', 'custom_entities']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None, 'imdecode_backend': 'pillow'}, {'type': 'FixScaleResize', 'scale': [800, 1333], 'backend': 'pillow', 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'text', 'custom_entities']}]",data/coco/,val2017/,1.0,RepeatDataset,2.0,CocoDataset,annotations/instances_train2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None, 'imdecode_backend': 'pillow'}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'GTBoxSubOne_GLIP'}, {'type': 'RandomChoiceResize', 'scales': [[1333, 480], [1333, 560], [1333, 640], [1333, 720], [1333, 800]], 'backend': 'pillow', 'keep_ratio': True, 'resize_type': 'FixScaleResize'}, {'prob': 0.5, 'type': 'RandomFlip_GLIP'}, {'type': 'FilterAnnotations', 'min_gt_bbox_wh': [1, 1]}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction', 'text', 'custom_entities']}]",data/coco/,32.0,True,train2017/,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,,,,,,,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,bert-base-uncased,"[2, 2, 18, 2]",,True,0.0,4.0,"[6, 12, 24, 48]",192.0,True,12.0,0.0,False,True,True,bert-base-uncased,0.5,8.0,BboxOverlaps2D_GLIP,bert-base-uncased,BertModel,"[0.9, 0.999]",0.0,0.0,0.0,True,True,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GLIP-L_Swin-L
0.02201964907646179,0.593,0.633,0.434,0.773,0.649,0.5791603294372558,5.0,3079.052577972412,1720391633.864247,0.755,3078,media/images/val_img_4_404de50f2bbd91be68a9.png,513411.0,image-file,850.0,png,640.0,404de50f2bbd91be68a9fb518f6428f1a888d481dcbaa92ed7a418dae6143c44,,,,,,,none,False,,slurm/results/Co-DINO_Swin-L/none_epsilon0_alpha0_steps0,data/coco/,models/Co-DINO_Swin-L/latest.pth,INFO,,models/Co-DINO_Swin-L/Co-DINO_Swin-L.py,,CocoDataset,,"[{'type': 'LocalVisBackend', '_scope_': 'mmdet'}]",mmdet,"[{'type': 'LoadImageFromFile'}, {'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'CopyPaste', 'max_num_pasted': 100}, {'type': 'PackDetInputs'}]",models/Co-DINO_Swin-L/latest.pth,"[{'type': 'MultiStepLR', 'milestones': [30]}]",ChannelMapper,5.0,"[192, 384, 768, 1536]",,256.0,,CoDETR,,SwinTransformer,False,Pretrained,,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth,"[0, 1, 2, 3]",0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,36.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Co-DINO_Swin-L,Co-DINO_Swin-L,none,models/Co-DINO_Swin-L/Co-DINO_Swin-L.py,0.0,0.0,0.0,models/Co-DINO_Swin-L/latest.pth,846186413151,attacks,0.0,0.0,0.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0002,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile'}, {'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile'}, {'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,MultiImageMixDataset,,CocoDataset,annotations/instances_train2017.json,,,"[{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'RandomResize', 'scale': [1280, 1280], 'keep_ratio': True, 'ratio_range': [0.1, 2]}, {'type': 'RandomCrop', 'crop_size': [1280, 1280], 'crop_type': 'absolute_range', 'recompute_bbox': True, 'allow_negative_crop': True}, {'type': 'FilterAnnotations', 'min_gt_bbox_wh': [0.01, 0.01]}, {'prob': 0.5, 'type': 'RandomFlip'}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}]",data/coco/,32.0,False,train2017/,,1.0,12.0,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.1,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,,"[{'type': 'CopyPaste', 'max_num_pasted': 100}, {'type': 'PackDetInputs'}]",,,,,,DefaultSampler,True,1.0,,True,,,,,,,,,,,RPNHead,CrossEntropyLoss,12.0,True,,L1Loss,12.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",,"[4, 8, 16, 32, 64, 128]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}}, {'rpn': {'debug': False, 'sampler': {'num': 256, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.5, 'add_gt_as_proposals': False}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.3, 'neg_iou_thr': 0.3, 'pos_iou_thr': 0.7, 'ignore_iof_thr': -1, 'match_low_quality': True}, 'pos_weight': -1, 'allowed_border': -1}, 'rcnn': {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.5, 'neg_iou_thr': 0.5, 'pos_iou_thr': 0.5, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}, 'rpn_proposal': {'nms': {'type': 'nms', 'iou_threshold': 0.7}, 'nms_pre': 4000, 'max_per_img': 1000, 'min_bbox_size': 0}}, {'debug': False, 'assigner': {'topk': 9, 'type': 'ATSSAssigner'}, 'pos_weight': -1, 'allowed_border': -1}]",,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[2, 2, 18, 2]",,True,0.0,4.0,"[6, 12, 24, 48]",192.0,True,12.0,0.0,True,,,,,,,,,,,,,,,,270000.0,"[1280, 1280]",https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth,2.0,80.0,"[{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'RandomResize', 'scale': [1280, 1280], 'keep_ratio': True, 'ratio_range': [0.1, 2]}, {'type': 'RandomCrop', 'crop_size': [1280, 1280], 'crop_type': 'absolute_range', 'recompute_bbox': True, 'allow_negative_crop': True}, {'type': 'FilterAnnotations', 'min_gt_bbox_wh': [0.01, 0.01]}, {'prob': 0.5, 'type': 'RandomFlip'}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}]",6.0,"[{'size': [1280, 1280], 'type': 'BatchFixedSizePad', 'pad_mask': True}]",True,384.0,"[{'type': 'CoStandardRoIHead', 'bbox_head': {'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 12, 'use_sigmoid': False}, 'loss_bbox': {'type': 'GIoULoss', 'loss_weight': 120}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.1, 0.1, 0.2, 0.2], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_decoded_bbox': True, 'reg_class_agnostic': False}, 'bbox_roi_extractor': {'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlign', 'output_size': 7, 'sampling_ratio': 0}, 'finest_scale': 56, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32, 64]}}]",4.0,3.0,"[{'nms': {'type': 'soft_nms', 'iou_threshold': 0.8}, 'max_per_img': 300}, {'rpn': {'nms': {'type': 'nms', 'iou_threshold': 0.7}, 'nms_pre': 1000, 'max_per_img': 1000, 'min_bbox_size': 0}, 'rcnn': {'nms': {'type': 'nms', 'iou_threshold': 0.5}, 'score_thr': 0, 'max_per_img': 100}}, {'nms': {'type': 'nms', 'iou_threshold': 0.6}, 'nms_pre': 1000, 'score_thr': 0, 'max_per_img': 100, 'min_bbox_size': 0}]","[{'type': 'CoATSSHead', 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 12, 'use_sigmoid': True}, 'loss_bbox': {'type': 'GIoULoss', 'loss_weight': 24}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.1, 0.1, 0.2, 0.2], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'feat_channels': 256, 'stacked_convs': 1, 'loss_centerness': {'type': 'CrossEntropyLoss', 'loss_weight': 12, 'use_sigmoid': True}, 'anchor_generator': {'type': 'AnchorGenerator', 'ratios': [1], 'strides': [4, 8, 16, 32, 64, 128], 'octave_base_scale': 8, 'scales_per_octave': 1}}]",CoDINOHead,True,,100.0,1.0,0.5,2.0,QualityFocalLoss,1.0,True,GIoULoss,2.0,L1Loss,5.0,900.0,2048.0,80.0,CoDinoTransformer,DinoTransformerDecoder,6.0,DetrTransformerDecoderLayer,"[{'type': 'MultiheadAttention', 'dropout': 0, 'num_heads': 8, 'embed_dims': 256}, {'type': 'MultiScaleDeformableAttention', 'dropout': 0, 'embed_dims': 256, 'num_levels': 5}]",0.0,"['self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm']",2048.0,True,DetrTransformerEncoder,6.0,6.0,BaseTransformerLayer,MultiScaleDeformableAttention,0.0,256.0,5.0,0.0,"['self_attn', 'norm', 'ffn', 'norm']",2048.0,2.0,False,5.0,True,SinePositionalEncoding,True,128.0,20.0,detr,"[{'size': [1280, 1280], 'type': 'BatchFixedSizePad', 'pad_mask': True}]",mmdet,mmdet,mmdet,mmdet,mmdet,mmdet,True,3.0,mmdet,mmdet,mmdet,mmdet,mmdet,['projects.CO-DETR.codetr'],False,mmdet,mmdet,mmdet,mmdet,mmdet,mmdet,mmdet,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Co-DINO_Swin-L
0.013228366804122925,0.583,0.622,0.415,0.771,0.642,0.32832126994132993,5.0,1843.432663679123,1720390277.7109597,0.735,1842,media/images/val_img_4_ecc38f8677f618731c7a.png,489870.0,image-file,850.0,png,640.0,ecc38f8677f618731c7a59ca9b58671eda3b725be5fc08f87be76aaab935bd86,,,,,,,none,False,,slurm/results/DINO_Swin-L/none_epsilon0_alpha0_steps0,data/coco/,models/DINO_Swin-L/latest.pth,INFO,,models/DINO_Swin-L/DINO_Swin-L.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/DINO_Swin-L/latest.pth,"[{'end': 36, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [27, 33]}]",ChannelMapper,5.0,"[192, 384, 768, 1536]",,256.0,,DINO,,SwinTransformer,True,Pretrained,,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth,"[0, 1, 2, 3]",0.2,,,,,,,300.0,,DINOHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,36.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DINO_Swin-L,DINO_Swin-L,none,models/DINO_Swin-L/DINO_Swin-L.py,0.0,0.0,0.0,models/DINO_Swin-L/latest.pth,846186413151,attacks,0.0,0.0,0.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0001,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,36.0,,,1.0,,,,0.0,256.0,2048.0,0.0,8.0,256.0,,0.0,,256.0,,6.0,True,,,,0.0,256.0,2048.0,0.0,,256.0,,6.0,,,,,,,,FocalLoss,1.0,True,,,GIoULoss,2.0,,"[{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",900.0,True,128.0,0.1,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,False,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,,100.0,1.0,0.5,5.0,,,,5.0,True,True,True,,5.0,0.0,20.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[2, 2, 18, 2]",,True,0.0,4.0,"[6, 12, 24, 48]",192.0,True,12.0,0.0,True,,,,,,,,,,,,,,,,,,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth,,,,,,,384.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,DINO_Swin-L
0.01314991307258606,0.4,0.436,0.229,0.594,0.435,0.1064157266139984,5.0,610.5891442298889,1720389044.4199605,0.528,610,media/images/val_img_4_e46d7d4f15a31580a3fe.png,491096.0,image-file,850.0,png,640.0,e46d7d4f15a31580a3fe0a66053325c64f02848529749dea74b39682da955c32,,,,,,,none,False,,slurm/results/Double Heads_R-50-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/Double Heads_R-50-FPN/latest.pth,INFO,,models/Double Heads_R-50-FPN/Double Heads_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Double Heads_R-50-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Double Heads_R-50-FPN,Double Heads_R-50-FPN,none,models/Double Heads_R-50-FPN/Double Heads_R-50-FPN.py,0.0,0.0,0.0,models/Double Heads_R-50-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,DoubleHeadRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,DoubleConvFCBBoxHead,CrossEntropyLoss,2.0,False,1.0,SmoothL1Loss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,7.0,1024.0,False,False,512.0,RandomSampler,-1.0,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,4.0,1024.0,1.3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Double Heads_R-50-FPN
0.012139427332162807,0.54,0.389,0.216,0.805,0.59,0.03784236926250739,5.0,262.34320855140686,1720388335.5681896,0.593,261,media/images/val_img_4_f91b5da09ca3c84b300c.png,351765.0,image-file,1000.0,png,375.0,f91b5da09ca3c84b300c052b0433d68711048f5c22ac02b5e148a1a88e56228a,,,,,,,none,True,none,slurm/results/atss_r50_voc0712/none_epsilon0_alpha0_steps0,data/VOCdevkit/,models/atss_r50_voc0712/epoch_4.pth,INFO,,models/atss_r50_voc0712/atss_r50_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_r50_voc0712,atss_r50_voc0712,none,models/atss_r50_voc0712/atss_r50_voc0712.py,0.0,0.0,0.0,models/atss_r50_voc0712/epoch_4.pth,846186413151,attacks,0.0,0.0,0.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,atss_r50_voc0712
0.013150541543960573,0.393,0.434,0.221,0.586,0.421,0.06145941958427429,5.0,404.82683062553406,1720388475.9218946,0.512,404,media/images/val_img_4_60acc162ee4e753d2f30.png,492190.0,image-file,850.0,png,640.0,60acc162ee4e753d2f30d74d8df12b13257ab38ad39886e515f7ae9cf8bcaafb,,,,,,,none,False,,slurm/results/FSAF_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/FSAF_R-101-FPN/latest.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/FSAF_R-101-FPN/FSAF_R-101-FPN.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/FSAF_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,80.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,FSAF_R-101-FPN,FSAF_R-101-FPN,none,models/FSAF_R-101-FPN/FSAF_R-101-FPN.py,0.0,0.0,0.0,models/FSAF_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FSAF_R-101-FPN
0.013237587785720826,0.501,0.534,0.327,0.679,0.546,0.09180505719184875,5.0,651.6401090621948,1720388603.89974,0.645,651,media/images/val_img_4_825a54ac9e80f122f0d5.png,490554.0,image-file,850.0,png,640.0,825a54ac9e80f122f0d572d743a5ffc9f574b2205517fc8b74e59070a248e057,,,,,,,none,False,,slurm/results/DINO_R-50-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/DINO_R-50-FPN/latest.pth,INFO,,models/DINO_R-50-FPN/DINO_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/DINO_R-50-FPN/latest.pth,"[{'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [11]}]",ChannelMapper,4.0,"[512, 1024, 2048]",,256.0,,DINO,,ResNet,,Pretrained,,torchvision://resnet50,"[1, 2, 3]",,,,,,,,300.0,,DINOHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DINO_R-50-FPN,DINO_R-50-FPN,none,models/DINO_R-50-FPN/DINO_R-50-FPN.py,0.0,0.0,0.0,models/DINO_R-50-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0002,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,12.0,,,1.0,,,,0.0,256.0,2048.0,0.0,8.0,256.0,,0.0,,256.0,,6.0,True,,,,0.0,256.0,2048.0,0.0,,256.0,,6.0,50.0,pytorch,BN,False,True,4.0,-1.0,FocalLoss,2.0,True,,,GIoULoss,2.0,,"[{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",900.0,True,128.0,0.1,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,False,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,,300.0,1.0,0.5,4.0,,,,4.0,True,True,True,,,-0.5,10000.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.1,0.1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,DINO_R-50-FPN
0.013165908718109132,0.417,0.448,0.236,0.6,0.453,0.055144778060913086,5.0,380.7768220901489,1720388331.6086302,0.551,380,media/images/val_img_4_d5580bbda851e367b134.png,492170.0,image-file,850.0,png,640.0,d5580bbda851e367b1349c6994e0f07368fffe838492ca96b76cc298dea476a9,,,,,,,none,False,,slurm/results/DDOD-ATSS_R-50-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/DDOD-ATSS_R-50-FPN/latest.pth,INFO,,models/DDOD-ATSS_R-50-FPN/DDOD-ATSS_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/DDOD-ATSS_R-50-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,DDOD,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,DDODHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DDOD-ATSS_R-50-FPN,DDOD-ATSS_R-50-FPN,none,models/DDOD-ATSS_R-50-FPN/DDOD-ATSS_R-50-FPN.py,0.0,0.0,0.0,models/DDOD-ATSS_R-50-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,CrossEntropyLoss,1.0,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,0.8,9.0,ATSSAssigner,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,DDOD-ATSS_R-50-FPN
0.013351298570632934,0.389,0.428,0.21,0.58,0.415,0.06687644119262695,5.0,438.2458384037018,1720388268.7741585,0.524,437,media/images/val_img_4_2646924fed0aa6ed18f0.png,492305.0,image-file,850.0,png,640.0,2646924fed0aa6ed18f0bafc967242e64cfbba899428d29dc956f264ce61e536,,,,,,,none,False,,slurm/results/RetinaNet_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/RetinaNet_R-101-FPN/latest.pth,INFO,,models/RetinaNet_R-101-FPN/RetinaNet_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/RetinaNet_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,RetinaHead,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,80.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,RetinaNet_R-101-FPN,RetinaNet_R-101-FPN,none,models/RetinaNet_R-101-FPN/RetinaNet_R-101-FPN.py,0.0,0.0,0.0,models/RetinaNet_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,RetinaNet_R-101-FPN
0.013275813055038452,0.418,0.462,0.247,0.625,0.458,0.0636508120059967,5.0,394.8856580257416,1720387984.972558,0.537,394,media/images/val_img_4_857497e0f0cccf9bec6e.png,491656.0,image-file,850.0,png,640.0,857497e0f0cccf9bec6e76412e0bd8530a537cc467ffb59b84ba4bfb6be9fb99,,,,,,,none,False,,slurm/results/Faster R-CNN_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/Faster R-CNN_R-101-FPN/latest.pth,INFO,,models/Faster R-CNN_R-101-FPN/Faster R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 640], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Faster R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [9, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Faster R-CNN_R-101-FPN,Faster R-CNN_R-101-FPN,none,models/Faster R-CNN_R-101-FPN/Faster R-CNN_R-101-FPN.py,0.0,0.0,0.0,models/Faster R-CNN_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,RepeatDataset,3.0,CocoDataset,annotations/instances_train2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 640], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,,,,,,,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,7.0,1024.0,False,False,512.0,RandomSampler,-1.0,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Faster R-CNN_R-101-FPN
0.013286916542053225,0.47,0.498,0.3,0.661,0.509,0.07702648954391479,5.0,495.5471501350403,1720387846.11786,0.619,495,media/images/val_img_4_d031b0664fa889c2c18e.png,494918.0,image-file,850.0,png,640.0,d031b0664fa889c2c18e62340153eed3d4f14b4dff018a637fa8f73015cdc957,,,,,,,none,False,,slurm/results/two-stage Deformable DETR_R-50-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/two-stage Deformable DETR_R-50-FPN/latest.pth,INFO,,models/two-stage Deformable DETR_R-50-FPN/two-stage Deformable DETR_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/two-stage Deformable DETR_R-50-FPN/latest.pth,"[{'end': 50, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [40]}]",ChannelMapper,4.0,"[512, 1024, 2048]",,256.0,,DeformableDETR,,ResNet,,Pretrained,,torchvision://resnet50,"[1, 2, 3]",,,,,,,,100.0,,DeformableDETRHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,50.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,two-stage Deformable DETR_R-50-FPN,two-stage Deformable DETR_R-50-FPN,none,models/two-stage Deformable DETR_R-50-FPN/two-stage Deformable DETR_R-50-FPN.py,0.0,0.0,0.0,models/two-stage Deformable DETR_R-50-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,,32.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0002,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,50.0,,,1.0,,,,0.1,256.0,1024.0,0.1,8.0,256.0,True,,,256.0,True,6.0,True,,,,0.1,256.0,1024.0,,,256.0,True,6.0,50.0,pytorch,BN,False,True,4.0,1.0,FocalLoss,2.0,True,,,GIoULoss,2.0,,"[{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",300.0,True,128.0,0.1,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,False,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,True,,4.0,-0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.1,0.1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,two-stage Deformable DETR_R-50-FPN
0.013186742687225342,0.405,0.447,0.234,0.613,0.435,0.07103002295494079,5.0,453.12101006507874,1720387802.204143,0.532,452,media/images/val_img_4_4393d3e8652890a2713c.png,491067.0,image-file,850.0,png,640.0,4393d3e8652890a2713c691704fe46eaed785af20fe7b0ac9f6212425c267a08,,,,,,,none,False,,slurm/results/RepPoints_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/RepPoints_R-101-FPN/latest.pth,INFO,,models/RepPoints_R-101-FPN/RepPoints_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/RepPoints_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RepPointsDetector,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,RepPointsHead,,,,,,,256.0,80.0,256.0,3.0,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,RepPoints_R-101-FPN,RepPoints_R-101-FPN,none,models/RepPoints_R-101-FPN/RepPoints_R-101-FPN.py,0.0,0.0,0.0,models/RepPoints_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,24.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,True,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,True,,,,,9.0,0.1,"[8, 16, 32, 64, 128]",0.11,SmoothL1Loss,0.5,0.11,SmoothL1Loss,1.0,4.0,moment,256.0,False,PointAssigner,4.0,1.0,-1.0,-1.0,False,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,GN,32.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,RepPoints_R-101-FPN
0.013011187314987184,0.436,0.484,0.274,0.629,0.472,0.07000576815605164,5.0,448.3891062736511,1720387676.7880564,0.557,447,media/images/val_img_4_99f4fa52ddbc801123ac.png,491269.0,image-file,850.0,png,640.0,99f4fa52ddbc801123ac986331872a129e594e066a9a85f1a29e52559e8be437,,,,,,,none,False,,slurm/results/SABL RetinaNet_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/SABL RetinaNet_R-101-FPN/latest.pth,INFO,,models/SABL RetinaNet_R-101-FPN/SABL RetinaNet_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 480], [1333, 960]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/SABL RetinaNet_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,SABLRetinaHead,,,,BucketingBBoxCoder,,,256.0,80.0,256.0,4.0,,,,,,False,PseudoSampler,ApproxMaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,SABL RetinaNet_R-101-FPN,SABL RetinaNet_R-101-FPN,none,models/SABL RetinaNet_R-101-FPN/SABL RetinaNet_R-101-FPN.py,0.0,0.0,0.0,models/SABL RetinaNet_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 480], [1333, 960]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,14.0,3.0,CrossEntropyLoss,1.5,True,0.1111111111111111,SmoothL1Loss,1.5,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,AnchorGenerator,[1],[4],"[8, 16, 32, 64, 128]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,SABL RetinaNet_R-101-FPN
0.0131092059135437,0.403,0.44,0.219,0.59,0.431,0.06481978011131287,5.0,448.85438203811646,1720387444.786718,0.542,448,media/images/val_img_4_01d5d6a9ba47896b0a6f.png,493379.0,image-file,850.0,png,640.0,01d5d6a9ba47896b0a6f4e7df9a0e7ebbd7b4d853aa93da017ef27c43497ab76,,,,,,,none,False,,slurm/results/FreeAnchor_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/FreeAnchor_R-101-FPN/latest.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/FreeAnchor_R-101-FPN/FreeAnchor_R-101-FPN.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/FreeAnchor_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,FreeAnchor_R-101-FPN,FreeAnchor_R-101-FPN,none,models/FreeAnchor_R-101-FPN/FreeAnchor_R-101-FPN.py,0.0,0.0,0.0,models/FreeAnchor_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FreeAnchor_R-101-FPN
0.01630979814529419,0.423,0.46,0.216,0.63,0.452,0.06358229279518128,5.0,600.4636693000793,1720387173.976015,0.613,599,media/images/val_img_4_e5cfb5fdcabc115600f2.png,490959.0,image-file,850.0,png,640.0,e5cfb5fdcabc115600f2fd67233596aeab458a5d34abf94825eb410bc5f977f3,,,,,,,none,False,,slurm/results/DAB-DETR_R-50-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/DAB-DETR_R-50-FPN/latest.pth,INFO,,models/DAB-DETR_R-50-FPN/DAB-DETR_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/DAB-DETR_R-50-FPN/latest.pth,"[{'end': 50, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [40]}]",ChannelMapper,1.0,[2048],,256.0,,DABDETR,,ResNet,,Pretrained,,torchvision://resnet50,[3],,,,,,,,300.0,,DABDETRHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,50.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DAB-DETR_R-50-FPN,DAB-DETR_R-50-FPN,none,models/DAB-DETR_R-50-FPN/DAB-DETR_R-50-FPN.py,0.0,0.0,0.0,models/DAB-DETR_R-50-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0001,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,50.0,,,1.0,PReLU,,2.0,0.0,256.0,2048.0,,8.0,256.0,,,8.0,256.0,,6.0,True,PReLU,,2.0,0.0,256.0,2048.0,0.0,8.0,256.0,True,6.0,50.0,pytorch,BN,False,True,4.0,1.0,FocalLoss,1.0,True,,,GIoULoss,2.0,256.0,"[{'eps': 1e-08, 'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",300.0,True,128.0,0.1,1.0,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,20.0,,,,,,,,,,,,,,,,,,,,0.0,False,0.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,0.0,4.0,cond_elewise,True,0.0,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,DAB-DETR_R-50-FPN
0.028555355865305995,0.547,0.399,0.248,0.825,0.587,0.06500397310000873,5.0,486.5955333709717,1720387060.1659904,0.603,485,media/images/val_img_4_09fa5ae3ba3650902409.png,355649.0,image-file,1000.0,png,375.0,09fa5ae3ba3650902409d9f48504bea34941db7e34d8d3fbc2fbe2eeb8f755a9,,,,,,,none,True,none,slurm/results/fsaf_r101_voc0712/none_epsilon0_alpha0_steps0,data/VOCdevkit/,models/fsaf_r101_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_r101_voc0712/fsaf_r101_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_r101_voc0712,fsaf_r101_voc0712,none,models/fsaf_r101_voc0712/fsaf_r101_voc0712.py,0.0,0.0,0.0,models/fsaf_r101_voc0712/epoch_4.pth,846186413151,attacks,0.0,0.0,0.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,fsaf_r101_voc0712
0.016460651111602782,0.493,0.534,0.322,0.668,0.536,0.10618561849594116,5.0,743.3129422664642,1720378877.1644282,0.64,742,media/images/val_img_4_2db1465073712d36a7df.png,490045.0,image-file,850.0,png,640.0,2db1465073712d36a7dfc9a6abb7f92e47d0e39fc89313fca19970b5e0f4aaea,,,,,,,none,False,,slurm/results/TOOD_R-101-dcnv2/none_epsilon0_alpha0_steps0,data/coco/,models/TOOD_R-101-dcnv2/latest.pth,INFO,,models/TOOD_R-101-dcnv2/TOOD_R-101-dcnv2.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 480], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/TOOD_R-101-dcnv2/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,TOOD,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,TOODHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,256.0,6.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,TaskAlignedAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,TOOD_R-101-dcnv2,TOOD_R-101-dcnv2,none,models/TOOD_R-101-dcnv2/TOOD_R-101-dcnv2.py,0.0,0.0,0.0,models/TOOD_R-101-dcnv2/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,24.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,QualityFocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 480], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,13.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,DCNv2,,False,"[False, True, True, True]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,2.0,2.0,True,anchor_free,FocalLoss,0.25,2.0,True,1.0,True,6.0,1.0,4.0,9.0,ATSSAssigner,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,TOOD_R-101-dcnv2
0.01498613796234131,0.587,0.629,0.416,0.768,0.646,0.24545500869750975,5.0,1496.968598127365,1720331359.7338462,0.743,1496,media/images/val_img_4_c6ee82b60b705b6eff1b.png,490931.0,image-file,850.0,png,640.0,c6ee82b60b705b6eff1b6daf172c8c6d878aa0fd7672d6d2aa06ae4673f3b012,,,,,,,none,False,,slurm/results/DDQ DETR-4scale_Swin-L/none_epsilon0_alpha0_steps0,data/coco/,models/DDQ DETR-4scale_Swin-L/latest.pth,INFO,,models/DDQ DETR-4scale_Swin-L/DDQ DETR-4scale_Swin-L.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/DDQ DETR-4scale_Swin-L/latest.pth,"[{'end': 2000, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.0001}, {'end': 30, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [20, 26]}]",ChannelMapper,4.0,"[384, 768, 1536]",,256.0,,DDQDETR,,SwinTransformer,False,Pretrained,,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth,"[1, 2, 3]",0.2,,,,,,,300.0,,DDQDETRHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,30.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DDQ DETR-4scale_Swin-L,DDQ DETR-4scale_Swin-L,none,models/DDQ DETR-4scale_Swin-L/DDQ DETR-4scale_Swin-L.py,0.0,0.0,0.0,models/DDQ DETR-4scale_Swin-L/latest.pth,846186413151,attacks,0.0,0.0,0.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0002,AdamW,,0.05,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,30.0,,,1.0,,,,0.0,256.0,2048.0,0.0,8.0,256.0,,0.0,,256.0,,6.0,True,,,,0.0,256.0,2048.0,0.0,,256.0,,6.0,,,,,,,,FocalLoss,1.0,True,,,GIoULoss,2.0,,"[{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",900.0,True,128.0,0.05,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,False,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,,100.0,1.0,0.5,4.0,,nms,0.8,4.0,True,True,True,1.5,,0.0,20.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[2, 2, 18, 2]",,True,0.0,4.0,"[6, 12, 24, 48]",192.0,True,12.0,0.0,True,,,,,,,,,,,,,,,,,,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth,,,,,,,384.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,DDQ DETR-4scale_Swin-L
0.008086956656872082,0.181,0.011,0.004,0.329,0.177,0.055055313632147926,5.0,347.1859176158905,1720325726.858245,0.248,346,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,none,True,none,slurm/results/fsaf_convnext-b_voc0712/none_epsilon0_alpha0_steps0,data/VOCdevkit/,models/fsaf_convnext-b_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_convnext-b_voc0712/fsaf_convnext-b_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_input,FSAF,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_convnext-b_voc0712,fsaf_convnext-b_voc0712,none,models/fsaf_convnext-b_voc0712/fsaf_convnext-b_voc0712.py,0.0,0.0,0.0,models/fsaf_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,0.0,0.0,0.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,fsaf_convnext-b_voc0712
0.032769777162037016,0.522,0.387,0.255,0.835,0.568,0.0668903628479657,5.0,475.1141998767853,1720325250.6863148,0.571,474,media/images/val_img_4_1002de27f03d18743022.png,357848.0,image-file,1000.0,png,375.0,1002de27f03d187430229adb4902aeaf78ae8457dce00be3bb07d13c2c92011b,,,,,,,none,True,none,slurm/results/libra_rcnn_r50_voc0712/none_epsilon0_alpha0_steps0,data/VOCdevkit/,models/libra_rcnn_r50_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_r50_voc0712/libra_rcnn_r50_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_r50_voc0712,libra_rcnn_r50_voc0712,none,models/libra_rcnn_r50_voc0712/libra_rcnn_r50_voc0712.py,0.0,0.0,0.0,models/libra_rcnn_r50_voc0712/epoch_4.pth,846186413151,attacks,0.0,0.0,0.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,libra_rcnn_r50_voc0712
,,,,,,,,,,,19,,,,,,,,,,,,,,none,,,,,,,,models/RTMDet-l_ConvNeXt-B/RTMDet-l_ConvNeXt-B.py,,,,,,,,models/RTMDet-l_ConvNeXt-B/latest.pth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,0.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,RTMDet-l_ConvNeXt-B
0.07176185059547424,0.564,0.601,0.416,0.741,0.618,1.2022248358726502,1.0,1494.8304228782654,1720309673.366911,0.71,1493,media/images/val_img_0_8177a6ac65f1da3bdda1.png,620644.0,image-file,1280.0,png,427.0,8177a6ac65f1da3bdda1454a6285993752a1c50e03febd185ef32dc82cdc6b7f,,,,,,,none,False,,slurm/results/RTMDet-l_Swin-B-P6/none_epsilon0_alpha0_steps0,data/coco/,models/RTMDet-l_Swin-B-P6/latest.pth,INFO,"[[1280, 1280], [640, 640], [1920, 1920]]",models/RTMDet-l_Swin-B-P6/RTMDet-l_Swin-B-P6.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'type': 'Resize', 'scale': [640, 640], 'keep_ratio': True}, {'type': 'Resize', 'scale': [1920, 1920], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'size': [1920, 1920], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'CachedMosaic', 'pad_val': 114, 'img_scale': [1280, 1280]}, {'type': 'RandomResize', 'scale': [2560, 2560], 'keep_ratio': True, 'ratio_range': [0.1, 2]}, {'type': 'RandomCrop', 'crop_size': [1280, 1280]}, {'type': 'YOLOXHSVRandomAug'}, {'prob': 0.5, 'type': 'RandomFlip'}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'CachedMixUp', 'pad_val': [114, 114, 114], 'img_scale': [1280, 1280], 'ratio_range': [1, 1], 'max_cached_images': 20}, {'type': 'PackDetInputs'}]",models/RTMDet-l_Swin-B-P6/latest.pth,"[{'end': 1000, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 1e-05}, {'end': 100, 'type': 'CosineAnnealingLR', 'T_max': 50, 'begin': 50, 'eta_min': 5e-05, 'by_epoch': True, 'convert_to_iter_based': True}]",CSPNeXtPAFPN,,"[256, 512, 1024, 2048]",,256.0,,RTMDet,,SwinTransformer,True,Pretrained,,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22k.pth,"[1, 2, 3, 4]",0.3,,,nms,0.65,30000.0,0.001,300.0,0.0,RTMDetSepBNHead,,GIoULoss,2.0,DistancePointBBoxCoder,,,256.0,80.0,256.0,2.0,MlvlPointGenerator,,"[8, 16, 32, 64]",,,False,,DynamicSoftLabelAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,100.0,10.0,DetTTAModel,nms,0.6,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,RTMDet-l_Swin-B-P6,RTMDet-l_Swin-B-P6,none,models/RTMDet-l_Swin-B-P6/RTMDet-l_Swin-B-P6.py,0.0,0.0,0.0,models/RTMDet-l_Swin-B-P6/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,10.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.001,AdamW,,0.05,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,5.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,5.0,CocoDataset,,,,,,,,,,,,16.0,100.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,QualityFocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,20.0,True,True,,DefaultSampler,False,False,20.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'CachedMosaic', 'pad_val': 114, 'img_scale': [1280, 1280]}, {'type': 'RandomResize', 'scale': [2560, 2560], 'keep_ratio': True, 'ratio_range': [0.1, 2]}, {'type': 'RandomCrop', 'crop_size': [1280, 1280]}, {'type': 'YOLOXHSVRandomAug'}, {'prob': 0.5, 'type': 'RandomFlip'}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'CachedMixUp', 'pad_val': [114, 114, 114], 'img_scale': [1280, 1280], 'ratio_range': [1, 1], 'max_cached_images': 20}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,20.0,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,13.0,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[2, 2, 18, 2, 1]",,True,0.0,4.0,"[4, 8, 16, 32, 64]",128.0,True,12.0,0.0,True,,,,,,,,,,,,,,,,,,,,,,,,,384.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,0.001,10.0,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22k.pth,"[{'type': 'EMAHook', 'ema_type': 'ExpMomentumEMA', 'momentum': 0.0002, 'priority': 49, 'update_buffers': True}, {'type': 'PipelineSwitchHook', 'switch_epoch': 90, 'switch_pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [1280, 1280], 'keep_ratio': True, 'ratio_range': [0.1, 2]}, {'type': 'RandomCrop', 'crop_size': [1280, 1280]}, {'type': 'YOLOXHSVRandomAug'}, {'prob': 0.5, 'type': 'RandomFlip'}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'PackDetInputs'}]}]",10.0,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [1280, 1280], 'keep_ratio': True, 'ratio_range': [0.1, 2]}, {'type': 'RandomCrop', 'crop_size': [1280, 1280]}, {'type': 'YOLOXHSVRandomAug'}, {'prob': 0.5, 'type': 'RandomFlip'}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'PackDetInputs'}]",SiLU,True,0.5,3.0,"[4, 2, 2, 2, 2]",SiLU,True,True,True,False,0.0,1.0,"[[90, 1]]",0.0,True,"[100, 1, 10]","[100, 1, 10]",True,,,,,,,,,,RTMDet-l_Swin-B-P6
0.013421723747253415,0.401,0.441,0.226,0.61,0.441,0.06716214418411255,5.0,426.0650382041931,1720292059.1518493,0.521,425,media/images/val_img_4_eee8215b2b85c1e70a45.png,492859.0,image-file,850.0,png,640.0,eee8215b2b85c1e70a456e1d9d08cf8d1f17d66a240d91ffbcb6f97e066d97b6,,,,,,,none,False,,slurm/results/Libra R-CNN_R-101-FPN/none_epsilon0_alpha0_steps0,data/coco/,models/Libra R-CNN_R-101-FPN/latest.pth,INFO,,models/Libra R-CNN_R-101-FPN/Libra R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Libra R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Libra R-CNN_R-101-FPN,Libra R-CNN_R-101-FPN,none,models/Libra R-CNN_R-101-FPN/Libra R-CNN_R-101-FPN.py,0.0,0.0,0.0,models/Libra R-CNN_R-101-FPN/latest.pth,846186413151,attacks,0.0,0.0,0.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,Libra R-CNN_R-101-FPN
0.033117350823417616,0.546,0.39,0.217,0.82,0.588,0.06343978639807143,5.0,506.89007687568665,1720290044.7597268,0.598,506,media/images/val_img_4_374ac682537bc06410d2.png,355173.0,image-file,1000.0,png,375.0,374ac682537bc06410d27101c3745e5b17f5a15cf77540e8b3580a0bb5fd876b,,,,,,,none,True,none,slurm/results/free_anchor_r50_voc0712/none_epsilon0_alpha0_steps0,data/VOCdevkit/,models/free_anchor_r50_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_r50_voc0712/free_anchor_r50_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_r50_voc0712,free_anchor_r50_voc0712,none,models/free_anchor_r50_voc0712/free_anchor_r50_voc0712.py,0.0,0.0,0.0,models/free_anchor_r50_voc0712/epoch_4.pth,846186413151,attacks,0.0,0.0,0.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,free_anchor_r50_voc0712
0.03296985230445862,0.41,0.452,0.239,0.609,0.44,0.13398884930610658,5.0,977.2347276210784,1720272946.4986076,0.54,976,media/images/val_img_4_7c662df1c1c732bc6131.png,492359.0,image-file,850.0,png,640.0,7c662df1c1c732bc6131dd334b047ff84feaf83bc1605308629d8f6d68824134,,,,,,,none,False,,./work_dirs/,data/coco/,mmdetection/checkpoints/retinanet_x101_64x4d_fpn_1x_coco_20200130-366f5af1.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",mmdetection/configs/retinanet/retinanet_x101-64x4d_fpn_1x_coco.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",mmdetection/checkpoints/retinanet_x101_64x4d_fpn_1x_coco_20200130-366f5af1.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNeXt,,Pretrained,,open-mmlab://resnext101_64x4d,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,RetinaHead,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,80.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,retinanet_x101-64x4d_fpn_1x_coco,retinanet_x101-64x4d_fpn_1x_coco,none,mmdetection/configs/retinanet/retinanet_x101-64x4d_fpn_1x_coco.py,,,,mmdetection/checkpoints/retinanet_x101_64x4d_fpn_1x_coco_20200130-366f5af1.pth,846186413151,attacks,,,,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,64.0,4.0,,,,,,,retinanet_x101-64x4d_fpn_1x_coco
0.013036901617050171,0.381,0.415,0.165,0.584,0.394,0.17684969401359557,6.0,1002.0930352211,1720144024.615065,0.568,1001,media/images/val_img_4_83eb04747b673d49d035.png,495666.0,image-file,850.0,png,640.0,83eb04747b673d49d035cef4f0cffdc7e52a1df67cdd84922519c266fb6ac667,,,,,,,pgd_attack,False,,slurm/results/DETR_R-50-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/DETR_R-50-FPN/latest.pth,INFO,,models/DETR_R-50-FPN/DETR_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/DETR_R-50-FPN/latest.pth,"[{'end': 150, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [100]}]",ChannelMapper,1.0,[2048],,256.0,,DETR,,ResNet,,Pretrained,,torchvision://resnet50,[3],,,,,,,,100.0,,DETRHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,150.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DETR_R-50-FPN,DETR_R-50-FPN,pgd_attack,models/DETR_R-50-FPN/DETR_R-50-FPN.py,2.5500000000000003,1.0,8.0,models/DETR_R-50-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0001,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,150.0,,,1.0,ReLU,True,2.0,0.1,256.0,2048.0,0.1,8.0,256.0,True,0.1,8.0,256.0,True,6.0,True,ReLU,True,2.0,0.1,256.0,2048.0,0.1,8.0,256.0,True,6.0,50.0,pytorch,BN,False,True,4.0,1.0,CrossEntropyLoss,1.0,False,1.0,0.1,GIoULoss,2.0,256.0,"[{'type': 'ClassificationCost', 'weight': 1}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",100.0,True,128.0,0.1,1.0,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,DETR_R-50-FPN
0.013537386798858644,0.43,0.471,0.238,0.605,0.459,0.34958162446022034,6.0,1851.039526462555,1720144768.3035824,0.575,1850,media/images/val_img_4_cf22c866cb4a6cecacfa.png,490464.0,image-file,850.0,png,640.0,cf22c866cb4a6cecacfa8b75a54eac4a71b8b61b5e4f23eb1595074c43ddaba8,,,,,,,pgd_attack,False,,slurm/results/SABL Cascade R-CNN_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/SABL Cascade R-CNN_R-101-FPN/latest.pth,INFO,,models/SABL Cascade R-CNN_R-101-FPN/SABL Cascade R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/SABL Cascade R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,CascadeRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,SABL Cascade R-CNN_R-101-FPN,SABL Cascade R-CNN_R-101-FPN,pgd_attack,models/SABL Cascade R-CNN_R-101-FPN/SABL Cascade R-CNN_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/SABL Cascade R-CNN_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,CascadeRoIHead,"[{'type': 'SABLHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'norm_cfg': None, 'bbox_coder': {'type': 'BucketingBBoxCoder', 'num_buckets': 14, 'scale_factor': 1.7}, 'num_classes': 80, 'num_cls_fcs': 1, 'num_reg_fcs': 0, 'reg_pre_num': 2, 'reg_post_num': 1, 'loss_bbox_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': True}, 'loss_bbox_reg': {'beta': 0.1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'roi_feat_size': 7, 'reg_pre_kernel': 3, 'cls_in_channels': 256, 'reg_in_channels': 256, 'reg_post_kernel': 3, 'cls_out_channels': 1024, 'reg_feat_up_ratio': 2, 'reg_class_agnostic': True, 'reg_cls_out_channels': 256, 'reg_offset_out_channels': 256}, {'type': 'SABLHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'norm_cfg': None, 'bbox_coder': {'type': 'BucketingBBoxCoder', 'num_buckets': 14, 'scale_factor': 1.5}, 'num_classes': 80, 'num_cls_fcs': 1, 'num_reg_fcs': 0, 'reg_pre_num': 2, 'reg_post_num': 1, 'loss_bbox_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': True}, 'loss_bbox_reg': {'beta': 0.1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'roi_feat_size': 7, 'reg_pre_kernel': 3, 'cls_in_channels': 256, 'reg_in_channels': 256, 'reg_post_kernel': 3, 'cls_out_channels': 1024, 'reg_feat_up_ratio': 2, 'reg_class_agnostic': True, 'reg_cls_out_channels': 256, 'reg_offset_out_channels': 256}, {'type': 'SABLHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'norm_cfg': None, 'bbox_coder': {'type': 'BucketingBBoxCoder', 'num_buckets': 14, 'scale_factor': 1.3}, 'num_classes': 80, 'num_cls_fcs': 1, 'num_reg_fcs': 0, 'reg_pre_num': 2, 'reg_post_num': 1, 'loss_bbox_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': True}, 'loss_bbox_reg': {'beta': 0.1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'roi_feat_size': 7, 'reg_pre_kernel': 3, 'cls_in_channels': 256, 'reg_in_channels': 256, 'reg_post_kernel': 3, 'cls_out_channels': 1024, 'reg_feat_up_ratio': 2, 'reg_class_agnostic': True, 'reg_cls_out_channels': 256, 'reg_offset_out_channels': 256}]",3.0,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]","[1, 0.5, 0.25]",RPNHead,CrossEntropyLoss,1.0,True,0.1111111111111111,SmoothL1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,0.0,"[{'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.5, 'neg_iou_thr': 0.5, 'pos_iou_thr': 0.5, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}, {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.6, 'neg_iou_thr': 0.6, 'pos_iou_thr': 0.6, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}, {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.7, 'neg_iou_thr': 0.7, 'pos_iou_thr': 0.7, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}]",nms,0.7,2000.0,2000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,SABL Cascade R-CNN_R-101-FPN
0.01316991047859192,0.415,0.453,0.224,0.596,0.45,0.2452923749923706,6.0,1325.4019529819489,1720142775.946814,0.553,1322,media/images/val_img_4_a5d361ded07c51b1da19.png,491770.0,image-file,850.0,png,640.0,a5d361ded07c51b1da19e5912b39e5547f9320d115cd3de75ea89627c7c8a755,,,,,,,pgd_attack,False,,slurm/results/Cascade R-CNN_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/Cascade R-CNN_R-101-FPN/latest.pth,INFO,,models/Cascade R-CNN_R-101-FPN/Cascade R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Cascade R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 20, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 19]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,CascadeRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,20.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Cascade R-CNN_R-101-FPN,Cascade R-CNN_R-101-FPN,pgd_attack,models/Cascade R-CNN_R-101-FPN/Cascade R-CNN_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/Cascade R-CNN_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,CascadeRoIHead,"[{'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'loss_bbox': {'beta': 1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.1, 0.1, 0.2, 0.2], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_class_agnostic': True}, {'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'loss_bbox': {'beta': 1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.05, 0.05, 0.1, 0.1], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_class_agnostic': True}, {'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'loss_bbox': {'beta': 1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.033, 0.033, 0.067, 0.067], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_class_agnostic': True}]",3.0,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]","[1, 0.5, 0.25]",RPNHead,CrossEntropyLoss,1.0,True,0.1111111111111111,SmoothL1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,0.0,"[{'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.5, 'neg_iou_thr': 0.5, 'pos_iou_thr': 0.5, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}, {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.6, 'neg_iou_thr': 0.6, 'pos_iou_thr': 0.6, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}, {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.7, 'neg_iou_thr': 0.7, 'pos_iou_thr': 0.7, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}]",nms,0.7,2000.0,2000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,Cascade R-CNN_R-101-FPN
0.01442555422782898,0.444,0.484,0.271,0.621,0.486,0.40923046956062314,6.0,2194.5148663520813,1720143065.7919545,0.58,2193,media/images/val_img_4_b57a6ccdad16a702785b.png,493818.0,image-file,850.0,png,640.0,b57a6ccdad16a702785b8df688be7efaec4dac55e4f3f86ff5018bd1da19381f,,,,,,,pgd_attack,False,,slurm/results/PAA_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/PAA_R-101-FPN/latest.pth,INFO,,models/PAA_R-101-FPN/PAA_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 640], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/PAA_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 36, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [28, 34]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,PAA,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,PAAHead,,GIoULoss,1.3,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,MaxIoUAssigner,0.0,0.1,0.1,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,36.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,PAA_R-101-FPN,PAA_R-101-FPN,pgd_attack,models/PAA_R-101-FPN/PAA_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/PAA_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,36.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 640], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,0.25,2.0,True,CrossEntropyLoss,0.5,True,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,PAA_R-101-FPN
0.020881562566757203,0.427,0.463,0.241,0.606,0.464,0.2953868856906891,6.0,1583.5361006259918,1720141321.7373087,0.57,1583,media/images/val_img_4_10dc13801a4dd38d99a3.png,492585.0,image-file,850.0,png,640.0,10dc13801a4dd38d99a3920ea117ee991827835c8195acf32a8904caa5da6892,0.4,0.4,0.171,0.578,0.371,0.548,pgd_attack,False,,slurm/results/Cascade Mask R-CNN_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/Cascade Mask R-CNN_R-101-FPN/latest.pth,INFO,,models/Cascade Mask R-CNN_R-101-FPN/Cascade Mask R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Cascade Mask R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 20, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 19]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,CascadeRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,20.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Cascade Mask R-CNN_R-101-FPN,Cascade Mask R-CNN_R-101-FPN,pgd_attack,models/Cascade Mask R-CNN_R-101-FPN/Cascade Mask R-CNN_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/Cascade Mask R-CNN_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,"['bbox', 'segm']",data/coco/annotations/instances_val2017.json,False,,CocoMetric,"['bbox', 'segm']",data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,CascadeRoIHead,"[{'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'loss_bbox': {'beta': 1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.1, 0.1, 0.2, 0.2], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_class_agnostic': True}, {'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'loss_bbox': {'beta': 1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.05, 0.05, 0.1, 0.1], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_class_agnostic': True}, {'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 1, 'use_sigmoid': False}, 'loss_bbox': {'beta': 1, 'type': 'SmoothL1Loss', 'loss_weight': 1}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.033, 0.033, 0.067, 0.067], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_class_agnostic': True}]",3.0,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]","[1, 0.5, 0.25]",RPNHead,CrossEntropyLoss,1.0,True,0.1111111111111111,SmoothL1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,0.0,"[{'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.5, 'neg_iou_thr': 0.5, 'pos_iou_thr': 0.5, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'mask_size': 28, 'pos_weight': -1}, {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.6, 'neg_iou_thr': 0.6, 'pos_iou_thr': 0.6, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'mask_size': 28, 'pos_weight': -1}, {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.7, 'neg_iou_thr': 0.7, 'pos_iou_thr': 0.7, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'mask_size': 28, 'pos_weight': -1}]",nms,0.7,2000.0,2000.0,0.0,,,,,,,,,FCNMaskHead,CrossEntropyLoss,True,1.0,4.0,256.0,80.0,256.0,SingleRoIExtractor,RoIAlign,14.0,0.0,256.0,"[4, 8, 16, 32]",0.5,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,Cascade Mask R-CNN_R-101-FPN
0.013162536096572875,0.381,0.41,0.212,0.567,0.42,0.15721694951057433,6.0,864.3178012371063,1720140358.3132951,0.506,863,media/images/val_img_4_042c8674be7b3972936a.png,490515.0,image-file,850.0,png,640.0,042c8674be7b3972936a407131724ec5c275d635e3c12f7442a5e2b7eca28778,,,,,,,pgd_attack,False,,slurm/results/Dynamic R-CNN_R-50-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/Dynamic R-CNN_R-50-FPN/latest.pth,INFO,,models/Dynamic R-CNN_R-50-FPN/Dynamic R-CNN_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Dynamic R-CNN_R-50-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Dynamic R-CNN_R-50-FPN,Dynamic R-CNN_R-50-FPN,pgd_attack,models/Dynamic R-CNN_R-50-FPN/Dynamic R-CNN_R-50-FPN.py,2.5500000000000003,1.0,8.0,models/Dynamic R-CNN_R-50-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,DynamicRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.85,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.85,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,SmoothL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,7.0,1024.0,False,False,512.0,RandomSampler,-1.0,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,75.0,10.0,0.4,1.0,100.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,Dynamic R-CNN_R-50-FPN
0.013506578540802002,0.408,0.451,0.235,0.59,0.443,0.221013672542572,6.0,1214.7818372249603,1720140709.4097033,0.527,1214,media/images/val_img_4_94442c656229c4ce12f0.png,489103.0,image-file,850.0,png,640.0,94442c656229c4ce12f0dd04b57453415c5f9bdb1cee953016a73bddbf0d0bb5,,,,,,,pgd_attack,False,,slurm/results/ATSS_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/ATSS_R-101-FPN/latest.pth,INFO,,models/ATSS_R-101-FPN/ATSS_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/ATSS_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,ATSS_R-101-FPN,ATSS_R-101-FPN,pgd_attack,models/ATSS_R-101-FPN/ATSS_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/ATSS_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,ATSS_R-101-FPN
,,,,,,,4.0,798.2146589756012,1720140171.394744,,1046,media/images/val_img_4_008a4361ef3672a1e28b.png,711343.0,image-file,850.0,png,640.0,008a4361ef3672a1e28b23cbd6845106136fa935b89a7894537b9260b427c476,,,,,,,pgd_attack,False,,slurm/results/RPN_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/RPN_R-101-FPN/latest.pth,INFO,,models/RPN_R-101-FPN/RPN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/RPN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,RPN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,RPN_R-101-FPN,RPN_R-101-FPN,pgd_attack,models/RPN_R-101-FPN/RPN_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/RPN_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,proposal_fast,data/coco/annotations/instances_val2017.json,False,,CocoMetric,proposal_fast,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,24.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,2000.0,1000.0,0.0,,,,,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,,-1.0,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,RPN_R-101-FPN
0.013365341567993164,0.286,0.318,0.098,0.45,0.303,0.056143368911743166,6.0,391.3825001716614,1720139643.1614273,0.454,390,media/images/val_img_4_1468959d9daf7882aa6e.png,492591.0,image-file,850.0,png,640.0,1468959d9daf7882aa6eaebacd3fb6ab21d23697193e81e9afe257c0b2ee6a4c,,,,,,,pgd_attack,False,,slurm/results/CenterNet_ResNet-18/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/CenterNet_ResNet-18/latest.pth,INFO,,models/CenterNet_ResNet-18/CenterNet_ResNet-18.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'to_float32': True, 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'std': [1, 1, 1], 'mean': [0, 0, 0], 'type': 'RandomCenterCropPad', 'border': None, 'ratios': None, 'to_rgb': True, 'test_mode': True, 'test_pad_mode': ['logical_or', 31], 'test_pad_add_pix': 1}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'flip', 'flip_direction', 'border']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'to_float32': True, 'backend_args': None}, {'std': [1, 1, 1], 'mean': [0, 0, 0], 'type': 'RandomCenterCropPad', 'border': None, 'ratios': None, 'to_rgb': True, 'test_mode': True, 'test_pad_mode': ['logical_or', 31], 'test_pad_add_pix': 1}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'border']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PhotoMetricDistortion', 'hue_delta': 18, 'contrast_range': [0.5, 1.5], 'brightness_delta': 32, 'saturation_range': [0.5, 1.5]}, {'std': [1, 1, 1], 'mean': [0, 0, 0], 'type': 'RandomCenterCropPad', 'ratios': [0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3], 'to_rgb': True, 'crop_size': [512, 512], 'test_pad_mode': None}, {'type': 'Resize', 'scale': [512, 512], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/CenterNet_ResNet-18/latest.pth,"[{'end': 1000, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 28, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [18, 24]}]",CTResNetNeck,,512,,,,CenterNet,,ResNet,,Pretrained,,torchvision://resnet18,,,,,,,,,100.0,,CenterNetHead,,,,,,,64.0,80.0,64.0,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,28.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,CenterNet_ResNet-18,CenterNet_ResNet-18,pgd_attack,models/CenterNet_ResNet-18/CenterNet_ResNet-18.py,2.5500000000000003,1.0,8.0,models/CenterNet_ResNet-18/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,128.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'to_float32': True, 'backend_args': None}, {'std': [1, 1, 1], 'mean': [0, 0, 0], 'type': 'RandomCenterCropPad', 'border': None, 'ratios': None, 'to_rgb': True, 'test_mode': True, 'test_pad_mode': ['logical_or', 31], 'test_pad_add_pix': 1}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'border']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'to_float32': True, 'backend_args': None}, {'std': [1, 1, 1], 'mean': [0, 0, 0], 'type': 'RandomCenterCropPad', 'border': None, 'ratios': None, 'to_rgb': True, 'test_mode': True, 'test_pad_mode': ['logical_or', 31], 'test_pad_add_pix': 1}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'border']}]",data/coco/,val2017/,1.0,RepeatDataset,5.0,CocoDataset,annotations/instances_train2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PhotoMetricDistortion', 'hue_delta': 18, 'contrast_range': [0.5, 1.5], 'brightness_delta': 32, 'saturation_range': [0.5, 1.5]}, {'std': [1, 1, 1], 'mean': [0, 0, 0], 'type': 'RandomCenterCropPad', 'ratios': [0.6, 0.7, 0.8, 0.9, 1, 1.1, 1.2, 1.3], 'to_rgb': True, 'crop_size': [512, 512], 'test_pad_mode': None}, {'type': 'Resize', 'scale': [512, 512], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,16.0,28.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,18.0,,BN,,False,,,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,,,,,,,,DefaultSampler,True,4.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,"[256, 128, 64]","[4, 4, 4]",100.0,3.0,L1Loss,0.1,L1Loss,1.0,GaussianFocalLoss,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,CenterNet_ResNet-18
0.013217636346817016,0.413,0.454,0.244,0.614,0.442,0.24554671621322632,6.0,1322.032128572464,1720140573.7547026,0.534,1321,media/images/val_img_4_2a5f836ee281f075fbcb.png,490484.0,image-file,850.0,png,640.0,2a5f836ee281f075fbcbd4680cb0be7c97cff5be6cc18be1bd0c51d1044da9ad,,,,,,,pgd_attack,False,,slurm/results/FoveaBox_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/FoveaBox_R-101-FPN/latest.pth,INFO,,models/FoveaBox_R-101-FPN/FoveaBox_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomChoiceResize', 'scales': [[1333, 640], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/FoveaBox_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FOVEA,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,,FoveaHead,0.11,SmoothL1Loss,1.0,,,,256.0,80.0,256.0,4.0,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,FoveaBox_R-101-FPN,FoveaBox_R-101-FPN,pgd_attack,models/FoveaBox_R-101-FPN/FoveaBox_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/FoveaBox_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,4.0,24.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomChoiceResize', 'scales': [[1333, 640], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,4.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.4,1.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.4,"[8, 16, 32, 64, 128]",GN,32.0,True,True,"[[1, 64], [32, 128], [64, 256], [128, 512], [256, 2048]]","[16, 32, 64, 128, 256]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,FoveaBox_R-101-FPN
,,,,,,,,,,,50,,,,,,,,,,,,,,pgd_attack,False,,slurm/results/RepPoints_R-101-FPN-DCN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/RepPoints_R-101-FPN-DCN/latest.pth,INFO,,models/RepPoints_R-101-FPN-DCN/RepPoints_R-101-FPN-DCN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/RepPoints_R-101-FPN-DCN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RepPointsDetector,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,RepPointsHead,,,,,,,256.0,80.0,256.0,3.0,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,RepPoints_R-101-FPN-DCN,RepPoints_R-101-FPN-DCN,pgd_attack,models/RepPoints_R-101-FPN-DCN/RepPoints_R-101-FPN-DCN.py,2.5500000000000003,1.0,8.0,models/RepPoints_R-101-FPN-DCN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,24.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,True,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,True,DCN,1.0,False,"[False, True, True, True]",9.0,0.1,"[8, 16, 32, 64, 128]",0.11,SmoothL1Loss,0.5,0.11,SmoothL1Loss,1.0,4.0,moment,256.0,False,PointAssigner,4.0,1.0,-1.0,-1.0,False,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,GN,32.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,RepPoints_R-101-FPN-DCN
,,,,,,,,,,,55,,,,,,,,,,,,,,pgd_attack,False,,slurm/results/VarifocalNet_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/VarifocalNet_R-101-FPN/latest.pth,INFO,,models/VarifocalNet_R-101-FPN/VarifocalNet_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 480], [1333, 960]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/VarifocalNet_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.1}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,VFNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,VFNetHead,,GIoULoss,1.5,,,,256.0,80.0,256.0,3.0,,,,,,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,VarifocalNet_R-101-FPN,VarifocalNet_R-101-FPN,pgd_attack,models/VarifocalNet_R-101-FPN/VarifocalNet_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/VarifocalNet_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,24.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,VarifocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 480], [1333, 960]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.75,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,"[8, 16, 32, 64, 128]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,DCNv2,1.0,False,"[False, True, True, True]",,,,,,,,GIoULoss,2.0,,,,,,,,,,,,,,,,,,,,,True,True,True,True,False,True,,2.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,VarifocalNet_R-101-FPN
,,,,,,,,,,,54,,,,,,,,,,,,,,pgd_attack,False,,slurm/results/DDQ DETR-5scale_R-50-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/DDQ DETR-5scale_R-50-FPN/latest.pth,INFO,,models/DDQ DETR-5scale_R-50-FPN/DDQ DETR-5scale_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/DDQ DETR-5scale_R-50-FPN/latest.pth,"[{'end': 2000, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.0001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [11]}]",ChannelMapper,5.0,"[256, 512, 1024, 2048]",,256.0,,DDQDETR,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,300.0,,DDQDETRHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DDQ DETR-5scale_R-50-FPN,DDQ DETR-5scale_R-50-FPN,pgd_attack,models/DDQ DETR-5scale_R-50-FPN/DDQ DETR-5scale_R-50-FPN.py,2.5500000000000003,1.0,8.0,models/DDQ DETR-5scale_R-50-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0002,AdamW,,0.05,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,12.0,,,1.0,,,,0.0,256.0,2048.0,0.0,8.0,256.0,,0.0,,256.0,,6.0,True,,,,0.0,256.0,2048.0,0.0,,256.0,,6.0,50.0,pytorch,BN,False,True,4.0,1.0,FocalLoss,1.0,True,,,GIoULoss,2.0,,"[{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",900.0,True,128.0,0.1,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,False,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,,100.0,1.0,0.5,5.0,,nms,0.8,5.0,True,True,True,1.5,5.0,0.0,20.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,DDQ DETR-5scale_R-50-FPN
0.013284896326065065,0.394,0.425,0.191,0.6,0.417,0.20716234130859376,6.0,1157.9317617416382,1720139323.9951236,0.58,1157,media/images/val_img_4_24567d1d3aedf6b9d9b6.png,494868.0,image-file,850.0,png,640.0,24567d1d3aedf6b9d9b698c9fdaa03b39b2014b6e1db265832966da1f94d095d,,,,,,,pgd_attack,False,,slurm/results/Conditional DETR_R-50-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/Conditional DETR_R-50-FPN/latest.pth,INFO,,models/Conditional DETR_R-50-FPN/Conditional DETR_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/Conditional DETR_R-50-FPN/latest.pth,"[{'end': 50, 'type': 'MultiStepLR', 'milestones': [40]}]",ChannelMapper,1.0,[2048],,256.0,,ConditionalDETR,,ResNet,,Pretrained,,torchvision://resnet50,[3],,,,,,,,100.0,,ConditionalDETRHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,50.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Conditional DETR_R-50-FPN,Conditional DETR_R-50-FPN,pgd_attack,models/Conditional DETR_R-50-FPN/Conditional DETR_R-50-FPN.py,2.5500000000000003,1.0,8.0,models/Conditional DETR_R-50-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0001,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,150.0,,,1.0,ReLU,True,2.0,0.1,256.0,2048.0,,8.0,256.0,,,8.0,256.0,,6.0,True,ReLU,True,2.0,0.1,256.0,2048.0,0.1,8.0,256.0,True,6.0,50.0,pytorch,BN,False,True,4.0,1.0,FocalLoss,2.0,True,,,GIoULoss,2.0,256.0,"[{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",300.0,True,128.0,0.1,1.0,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.1,False,0.1,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,Conditional DETR_R-50-FPN
0.013206663990020752,0.394,0.429,0.213,0.573,0.427,0.227798224401474,6.0,1223.525607585907,1720139380.7609606,0.52,1223,media/images/val_img_4_aa0eb0462c701cdcf79b.png,490202.0,image-file,850.0,png,640.0,aa0eb0462c701cdcf79b7f6ace5466636dcafcfc698803cc32ca4a6bb83de7fb,,,,,,,pgd_attack,False,,slurm/results/Grid R-CNN_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/Grid R-CNN_R-101-FPN/latest.pth,INFO,,models/Grid R-CNN_R-101-FPN/Grid R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Grid R-CNN_R-101-FPN/latest.pth,"[{'end': 3665, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.0125}, {'end': 25, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [17, 23]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,GridRCNN,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,25.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Grid R-CNN_R-101-FPN,Grid R-CNN_R-101-FPN,pgd_attack,models/Grid R-CNN_R-101-FPN/Grid R-CNN_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/Grid R-CNN_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,25.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,GridRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,0.1111111111111111,SmoothL1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.3,0.03,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,,-1.0,0.0,,nms,0.7,2000.0,2000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,,,,,,,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,7.0,1024.0,False,False,512.0,RandomSampler,-1.0,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,GridHead,GN,36.0,CrossEntropyLoss,15.0,True,8.0,9.0,256.0,64.0,SingleRoIExtractor,RoIAlign,14.0,0.0,256.0,"[4, 8, 16, 32]",1.0,192.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,Grid R-CNN_R-101-FPN
0.015116835832595826,0.45,0.482,0.286,0.641,0.49,0.2560257722854614,6.0,1468.8555042743685,1720139261.7364163,0.595,1468,media/images/val_img_4_d84eedf84eb5985ef94b.png,490580.0,image-file,850.0,png,640.0,d84eedf84eb5985ef94b4f0549195e5f974b9707769fc1145ca6614b1febc313,,,,,,,pgd_attack,False,,slurm/results/Sparse R-CNN_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/Sparse R-CNN_R-101-FPN/latest.pth,INFO,,models/Sparse R-CNN_R-101-FPN/Sparse R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/Sparse R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 36, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [27, 33]}]",FPN,4.0,"[256, 512, 1024, 2048]",0.0,256.0,on_input,SparseRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,36.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Sparse R-CNN_R-101-FPN,Sparse R-CNN_R-101-FPN,pgd_attack,models/Sparse R-CNN_R-101-FPN/Sparse R-CNN_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/Sparse R-CNN_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,1.0,2.0,2.5e-05,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,36.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,SparseRoIHead,"[{'type': 'DIIHead', 'dropout': 0, 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 2, 'use_sigmoid': True}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5}, 'num_heads': 8, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_stds': [0.5, 0.5, 1, 1], 'target_means': [0, 0, 0, 0]}, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'in_channels': 256, 'num_classes': 80, 'num_cls_fcs': 1, 'num_ffn_fcs': 2, 'num_reg_fcs': 3, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}, 'in_channels': 256, 'out_channels': 256, 'feat_channels': 64, 'input_feat_shape': 7}, 'feedforward_channels': 2048}, {'type': 'DIIHead', 'dropout': 0, 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 2, 'use_sigmoid': True}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5}, 'num_heads': 8, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_stds': [0.5, 0.5, 1, 1], 'target_means': [0, 0, 0, 0]}, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'in_channels': 256, 'num_classes': 80, 'num_cls_fcs': 1, 'num_ffn_fcs': 2, 'num_reg_fcs': 3, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}, 'in_channels': 256, 'out_channels': 256, 'feat_channels': 64, 'input_feat_shape': 7}, 'feedforward_channels': 2048}, {'type': 'DIIHead', 'dropout': 0, 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 2, 'use_sigmoid': True}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5}, 'num_heads': 8, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_stds': [0.5, 0.5, 1, 1], 'target_means': [0, 0, 0, 0]}, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'in_channels': 256, 'num_classes': 80, 'num_cls_fcs': 1, 'num_ffn_fcs': 2, 'num_reg_fcs': 3, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}, 'in_channels': 256, 'out_channels': 256, 'feat_channels': 64, 'input_feat_shape': 7}, 'feedforward_channels': 2048}, {'type': 'DIIHead', 'dropout': 0, 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 2, 'use_sigmoid': True}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5}, 'num_heads': 8, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_stds': [0.5, 0.5, 1, 1], 'target_means': [0, 0, 0, 0]}, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'in_channels': 256, 'num_classes': 80, 'num_cls_fcs': 1, 'num_ffn_fcs': 2, 'num_reg_fcs': 3, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}, 'in_channels': 256, 'out_channels': 256, 'feat_channels': 64, 'input_feat_shape': 7}, 'feedforward_channels': 2048}, {'type': 'DIIHead', 'dropout': 0, 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 2, 'use_sigmoid': True}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5}, 'num_heads': 8, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_stds': [0.5, 0.5, 1, 1], 'target_means': [0, 0, 0, 0]}, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'in_channels': 256, 'num_classes': 80, 'num_cls_fcs': 1, 'num_ffn_fcs': 2, 'num_reg_fcs': 3, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}, 'in_channels': 256, 'out_channels': 256, 'feat_channels': 64, 'input_feat_shape': 7}, 'feedforward_channels': 2048}, {'type': 'DIIHead', 'dropout': 0, 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 2, 'use_sigmoid': True}, 'loss_iou': {'type': 'GIoULoss', 'loss_weight': 2}, 'loss_bbox': {'type': 'L1Loss', 'loss_weight': 5}, 'num_heads': 8, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'clip_border': False, 'target_stds': [0.5, 0.5, 1, 1], 'target_means': [0, 0, 0, 0]}, 'ffn_act_cfg': {'type': 'ReLU', 'inplace': True}, 'in_channels': 256, 'num_classes': 80, 'num_cls_fcs': 1, 'num_ffn_fcs': 2, 'num_reg_fcs': 3, 'dynamic_conv_cfg': {'type': 'DynamicConv', 'act_cfg': {'type': 'ReLU', 'inplace': True}, 'norm_cfg': {'type': 'LN'}, 'in_channels': 256, 'out_channels': 256, 'feat_channels': 64, 'input_feat_shape': 7}, 'feedforward_channels': 2048}]",6.0,SingleRoIExtractor,RoIAlign,7.0,2.0,256.0,"[4, 8, 16, 32]","[1, 1, 1, 1, 1, 1]",EmbeddingRPNHead,,,,,,,,,,,,,,,,,,,,,,,,300.0,,,,,,,,,,,,,,,"[{'sampler': {'type': 'PseudoSampler'}, 'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xyxy'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}, 'pos_weight': 1}, {'sampler': {'type': 'PseudoSampler'}, 'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xyxy'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}, 'pos_weight': 1}, {'sampler': {'type': 'PseudoSampler'}, 'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xyxy'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}, 'pos_weight': 1}, {'sampler': {'type': 'PseudoSampler'}, 'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xyxy'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}, 'pos_weight': 1}, {'sampler': {'type': 'PseudoSampler'}, 'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xyxy'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}, 'pos_weight': 1}, {'sampler': {'type': 'PseudoSampler'}, 'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xyxy'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}, 'pos_weight': 1}]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,6.0,300.0,256.0,300.0,256.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,Sparse R-CNN_R-101-FPN
0.01514160499572754,0.417,0.459,0.241,0.598,0.452,0.23768700041770935,6.0,1271.262486219406,1720139063.4926353,0.546,1270,media/images/val_img_4_934e7b01e7da7b26ae78.png,492324.0,image-file,850.0,png,640.0,934e7b01e7da7b26ae786200c3e0b8b76db6ab2d9dcdf7de2dd4d3c6ddf53430,,,,,,,pgd_attack,False,,slurm/results/SABL Faster R-CNN_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/SABL Faster R-CNN_R-101-FPN/latest.pth,INFO,,models/SABL Faster R-CNN_R-101-FPN/SABL Faster R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/SABL Faster R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,SABL Faster R-CNN_R-101-FPN,SABL Faster R-CNN_R-101-FPN,pgd_attack,models/SABL Faster R-CNN_R-101-FPN/SABL Faster R-CNN_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/SABL Faster R-CNN_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,SABLHead,CrossEntropyLoss,1.0,False,,,,BucketingBBoxCoder,,,,80.0,7.0,,True,False,512.0,RandomSampler,-1.0,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,14.0,1.7,1.0,0.0,2.0,1.0,CrossEntropyLoss,1.0,True,0.1,SmoothL1Loss,1.0,3.0,256.0,256.0,3.0,1024.0,2.0,256.0,256.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,SABL Faster R-CNN_R-101-FPN
,,,,,,,,,,,47,,,,,,,,,,,,,,pgd_attack,False,,slurm/results/GLIP-L_Swin-L/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/GLIP-L_Swin-L/latest.pth,INFO,,models/GLIP-L_Swin-L/GLIP-L_Swin-L.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None, 'imdecode_backend': 'pillow'}, {'type': 'FixScaleResize', 'scale': [800, 1333], 'backend': 'pillow', 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'text', 'custom_entities']}]","[{'type': 'LoadImageFromFile', 'backend_args': None, 'imdecode_backend': 'pillow'}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'GTBoxSubOne_GLIP'}, {'type': 'RandomChoiceResize', 'scales': [[1333, 480], [1333, 560], [1333, 640], [1333, 720], [1333, 800]], 'backend': 'pillow', 'keep_ratio': True, 'resize_type': 'FixScaleResize'}, {'prob': 0.5, 'type': 'RandomFlip_GLIP'}, {'type': 'FilterAnnotations', 'min_gt_bbox_wh': [1, 1]}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction', 'text', 'custom_entities']}]",models/GLIP-L_Swin-L/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN_DropBlock,5.0,"[384, 768, 1536]",0.0,256.0,on_output,GLIP,,SwinTransformer,False,,,,"[1, 2, 3]",0.4,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSVLFusionHead,,GIoULoss,2.0,DeltaXYWHBBoxCoderForGLIP,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,256.0,,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[57.375, 57.12, 58.395]","[103.53, 116.28, 123.675]",DetDataPreprocessor,False,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,GLIP-L_Swin-L,GLIP-L_Swin-L,pgd_attack,models/GLIP-L_Swin-L/GLIP-L_Swin-L.py,2.5500000000000003,1.0,8.0,models/GLIP-L_Swin-L/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,1.0,2.0,1e-05,AdamW,,0.05,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None, 'imdecode_backend': 'pillow'}, {'type': 'FixScaleResize', 'scale': [800, 1333], 'backend': 'pillow', 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'text', 'custom_entities']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None, 'imdecode_backend': 'pillow'}, {'type': 'FixScaleResize', 'scale': [800, 1333], 'backend': 'pillow', 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'text', 'custom_entities']}]",data/coco/,val2017/,1.0,RepeatDataset,2.0,CocoDataset,annotations/instances_train2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None, 'imdecode_backend': 'pillow'}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'GTBoxSubOne_GLIP'}, {'type': 'RandomChoiceResize', 'scales': [[1333, 480], [1333, 560], [1333, 640], [1333, 720], [1333, 800]], 'backend': 'pillow', 'keep_ratio': True, 'resize_type': 'FixScaleResize'}, {'prob': 0.5, 'type': 'RandomFlip_GLIP'}, {'type': 'FilterAnnotations', 'min_gt_bbox_wh': [1, 1]}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction', 'text', 'custom_entities']}]",data/coco/,32.0,True,train2017/,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,,,,,,,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,bert-base-uncased,"[2, 2, 18, 2]",,True,0.0,4.0,"[6, 12, 24, 48]",192.0,True,12.0,0.0,False,True,True,bert-base-uncased,0.5,8.0,BboxOverlaps2D_GLIP,bert-base-uncased,BertModel,"[0.9, 0.999]",0.0,0.0,0.0,True,True,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,GLIP-L_Swin-L
,,,,,,,,,,,56,,,,,,,,,,,,,,pgd_attack,False,,slurm/results/Co-DINO_Swin-L/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/Co-DINO_Swin-L/latest.pth,INFO,,models/Co-DINO_Swin-L/Co-DINO_Swin-L.py,,CocoDataset,,"[{'type': 'LocalVisBackend', '_scope_': 'mmdet'}]",mmdet,"[{'type': 'LoadImageFromFile'}, {'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'CopyPaste', 'max_num_pasted': 100}, {'type': 'PackDetInputs'}]",models/Co-DINO_Swin-L/latest.pth,"[{'type': 'MultiStepLR', 'milestones': [30]}]",ChannelMapper,5.0,"[192, 384, 768, 1536]",,256.0,,CoDETR,,SwinTransformer,False,Pretrained,,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth,"[0, 1, 2, 3]",0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,36.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Co-DINO_Swin-L,Co-DINO_Swin-L,pgd_attack,models/Co-DINO_Swin-L/Co-DINO_Swin-L.py,2.5500000000000003,1.0,8.0,models/Co-DINO_Swin-L/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0002,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile'}, {'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile'}, {'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,MultiImageMixDataset,,CocoDataset,annotations/instances_train2017.json,,,"[{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'RandomResize', 'scale': [1280, 1280], 'keep_ratio': True, 'ratio_range': [0.1, 2]}, {'type': 'RandomCrop', 'crop_size': [1280, 1280], 'crop_type': 'absolute_range', 'recompute_bbox': True, 'allow_negative_crop': True}, {'type': 'FilterAnnotations', 'min_gt_bbox_wh': [0.01, 0.01]}, {'prob': 0.5, 'type': 'RandomFlip'}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}]",data/coco/,32.0,False,train2017/,,1.0,12.0,,,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.1,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,,"[{'type': 'CopyPaste', 'max_num_pasted': 100}, {'type': 'PackDetInputs'}]",,,,,,DefaultSampler,True,1.0,,True,,,,,,,,,,,RPNHead,CrossEntropyLoss,12.0,True,,L1Loss,12.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",,"[4, 8, 16, 32, 64, 128]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'assigner': {'type': 'HungarianAssigner', 'match_costs': [{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]}}, {'rpn': {'debug': False, 'sampler': {'num': 256, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.5, 'add_gt_as_proposals': False}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.3, 'neg_iou_thr': 0.3, 'pos_iou_thr': 0.7, 'ignore_iof_thr': -1, 'match_low_quality': True}, 'pos_weight': -1, 'allowed_border': -1}, 'rcnn': {'debug': False, 'sampler': {'num': 512, 'type': 'RandomSampler', 'neg_pos_ub': -1, 'pos_fraction': 0.25, 'add_gt_as_proposals': True}, 'assigner': {'type': 'MaxIoUAssigner', 'min_pos_iou': 0.5, 'neg_iou_thr': 0.5, 'pos_iou_thr': 0.5, 'ignore_iof_thr': -1, 'match_low_quality': False}, 'pos_weight': -1}, 'rpn_proposal': {'nms': {'type': 'nms', 'iou_threshold': 0.7}, 'nms_pre': 4000, 'max_per_img': 1000, 'min_bbox_size': 0}}, {'debug': False, 'assigner': {'topk': 9, 'type': 'ATSSAssigner'}, 'pos_weight': -1, 'allowed_border': -1}]",,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[2, 2, 18, 2]",,True,0.0,4.0,"[6, 12, 24, 48]",192.0,True,12.0,0.0,True,,,,,,,,,,,,,,,,270000.0,"[1280, 1280]",https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth,2.0,80.0,"[{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'RandomResize', 'scale': [1280, 1280], 'keep_ratio': True, 'ratio_range': [0.1, 2]}, {'type': 'RandomCrop', 'crop_size': [1280, 1280], 'crop_type': 'absolute_range', 'recompute_bbox': True, 'allow_negative_crop': True}, {'type': 'FilterAnnotations', 'min_gt_bbox_wh': [0.01, 0.01]}, {'prob': 0.5, 'type': 'RandomFlip'}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}]",6.0,"[{'size': [1280, 1280], 'type': 'BatchFixedSizePad', 'pad_mask': True}]",True,384.0,"[{'type': 'CoStandardRoIHead', 'bbox_head': {'type': 'Shared2FCBBoxHead', 'loss_cls': {'type': 'CrossEntropyLoss', 'loss_weight': 12, 'use_sigmoid': False}, 'loss_bbox': {'type': 'GIoULoss', 'loss_weight': 120}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.1, 0.1, 0.2, 0.2], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'roi_feat_size': 7, 'fc_out_channels': 1024, 'reg_decoded_bbox': True, 'reg_class_agnostic': False}, 'bbox_roi_extractor': {'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlign', 'output_size': 7, 'sampling_ratio': 0}, 'finest_scale': 56, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32, 64]}}]",4.0,3.0,"[{'nms': {'type': 'soft_nms', 'iou_threshold': 0.8}, 'max_per_img': 300}, {'rpn': {'nms': {'type': 'nms', 'iou_threshold': 0.7}, 'nms_pre': 1000, 'max_per_img': 1000, 'min_bbox_size': 0}, 'rcnn': {'nms': {'type': 'nms', 'iou_threshold': 0.5}, 'score_thr': 0, 'max_per_img': 100}}, {'nms': {'type': 'nms', 'iou_threshold': 0.6}, 'nms_pre': 1000, 'score_thr': 0, 'max_per_img': 100, 'min_bbox_size': 0}]","[{'type': 'CoATSSHead', 'loss_cls': {'type': 'FocalLoss', 'alpha': 0.25, 'gamma': 2, 'loss_weight': 12, 'use_sigmoid': True}, 'loss_bbox': {'type': 'GIoULoss', 'loss_weight': 24}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_stds': [0.1, 0.1, 0.2, 0.2], 'target_means': [0, 0, 0, 0]}, 'in_channels': 256, 'num_classes': 80, 'feat_channels': 256, 'stacked_convs': 1, 'loss_centerness': {'type': 'CrossEntropyLoss', 'loss_weight': 12, 'use_sigmoid': True}, 'anchor_generator': {'type': 'AnchorGenerator', 'ratios': [1], 'strides': [4, 8, 16, 32, 64, 128], 'octave_base_scale': 8, 'scales_per_octave': 1}}]",CoDINOHead,True,,100.0,1.0,0.5,2.0,QualityFocalLoss,1.0,True,GIoULoss,2.0,L1Loss,5.0,900.0,2048.0,80.0,CoDinoTransformer,DinoTransformerDecoder,6.0,DetrTransformerDecoderLayer,"[{'type': 'MultiheadAttention', 'dropout': 0, 'num_heads': 8, 'embed_dims': 256}, {'type': 'MultiScaleDeformableAttention', 'dropout': 0, 'embed_dims': 256, 'num_levels': 5}]",0.0,"['self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm']",2048.0,True,DetrTransformerEncoder,6.0,6.0,BaseTransformerLayer,MultiScaleDeformableAttention,0.0,256.0,5.0,0.0,"['self_attn', 'norm', 'ffn', 'norm']",2048.0,2.0,False,5.0,True,SinePositionalEncoding,True,128.0,20.0,detr,"[{'size': [1280, 1280], 'type': 'BatchFixedSizePad', 'pad_mask': True}]",mmdet,mmdet,mmdet,mmdet,mmdet,mmdet,True,3.0,mmdet,mmdet,mmdet,mmdet,mmdet,['projects.CO-DETR.codetr'],False,mmdet,mmdet,mmdet,mmdet,mmdet,mmdet,mmdet,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,Co-DINO_Swin-L
,,,,,,,,,,,60,,,,,,,,,,,,,,pgd_attack,False,,slurm/results/DINO_Swin-L/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/DINO_Swin-L/latest.pth,INFO,,models/DINO_Swin-L/DINO_Swin-L.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/DINO_Swin-L/latest.pth,"[{'end': 36, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [27, 33]}]",ChannelMapper,5.0,"[192, 384, 768, 1536]",,256.0,,DINO,,SwinTransformer,True,Pretrained,,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth,"[0, 1, 2, 3]",0.2,,,,,,,300.0,,DINOHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,36.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DINO_Swin-L,DINO_Swin-L,pgd_attack,models/DINO_Swin-L/DINO_Swin-L.py,2.5500000000000003,1.0,8.0,models/DINO_Swin-L/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0001,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,36.0,,,1.0,,,,0.0,256.0,2048.0,0.0,8.0,256.0,,0.0,,256.0,,6.0,True,,,,0.0,256.0,2048.0,0.0,,256.0,,6.0,,,,,,,,FocalLoss,1.0,True,,,GIoULoss,2.0,,"[{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",900.0,True,128.0,0.1,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,False,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,,100.0,1.0,0.5,5.0,,,,5.0,True,True,True,,5.0,0.0,20.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[2, 2, 18, 2]",,True,0.0,4.0,"[6, 12, 24, 48]",192.0,True,12.0,0.0,True,,,,,,,,,,,,,,,,,,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth,,,,,,,384.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,5.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,DINO_Swin-L
0.013344607305526734,0.386,0.427,0.213,0.579,0.413,0.21705151176452636,6.0,1188.6876599788666,1720138002.286015,0.503,1188,media/images/val_img_4_4c894f8b4b4c07d565e9.png,490250.0,image-file,850.0,png,640.0,4c894f8b4b4c07d565e98027e73d363f47901d7c4513f1001978af83153ab8aa,,,,,,,pgd_attack,False,,slurm/results/FSAF_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/FSAF_R-101-FPN/latest.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/FSAF_R-101-FPN/FSAF_R-101-FPN.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/FSAF_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,80.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,FSAF_R-101-FPN,FSAF_R-101-FPN,pgd_attack,models/FSAF_R-101-FPN/FSAF_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/FSAF_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,FSAF_R-101-FPN
0.01320076231956482,0.392,0.427,0.217,0.585,0.425,0.29281670398712156,6.0,1544.3908488750458,1720138357.6567638,0.519,1543,media/images/val_img_4_6cc6f3478e54bed17a1d.png,490458.0,image-file,850.0,png,640.0,6cc6f3478e54bed17a1d30c646c25c4fef895a0817f1be5bdf843034780b7145,,,,,,,pgd_attack,False,,slurm/results/Double Heads_R-50-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/Double Heads_R-50-FPN/latest.pth,INFO,,models/Double Heads_R-50-FPN/Double Heads_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Double Heads_R-50-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Double Heads_R-50-FPN,Double Heads_R-50-FPN,pgd_attack,models/Double Heads_R-50-FPN/Double Heads_R-50-FPN.py,2.5500000000000003,1.0,8.0,models/Double Heads_R-50-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,DoubleHeadRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,DoubleConvFCBBoxHead,CrossEntropyLoss,2.0,False,1.0,SmoothL1Loss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,7.0,1024.0,False,False,512.0,RandomSampler,-1.0,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,4.0,1024.0,1.3,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,Double Heads_R-50-FPN
,,,,,,,,,,,153,,,,,,,,,,,,,,pgd_attack,False,,slurm/results/DINO_R-50-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/DINO_R-50-FPN/latest.pth,INFO,,models/DINO_R-50-FPN/DINO_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/DINO_R-50-FPN/latest.pth,"[{'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [11]}]",ChannelMapper,4.0,"[512, 1024, 2048]",,256.0,,DINO,,ResNet,,Pretrained,,torchvision://resnet50,"[1, 2, 3]",,,,,,,,300.0,,DINOHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DINO_R-50-FPN,DINO_R-50-FPN,pgd_attack,models/DINO_R-50-FPN/DINO_R-50-FPN.py,2.5500000000000003,1.0,8.0,models/DINO_R-50-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0002,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,12.0,,,1.0,,,,0.0,256.0,2048.0,0.0,8.0,256.0,,0.0,,256.0,,6.0,True,,,,0.0,256.0,2048.0,0.0,,256.0,,6.0,50.0,pytorch,BN,False,True,4.0,-1.0,FocalLoss,2.0,True,,,GIoULoss,2.0,,"[{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",900.0,True,128.0,0.1,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,False,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,,300.0,1.0,0.5,4.0,,,,4.0,True,True,True,,,-0.5,10000.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.1,0.1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,DINO_R-50-FPN
0.013013068914413452,0.408,0.436,0.226,0.589,0.441,0.20049106702804564,6.0,1121.5902261734009,1720136716.923947,0.539,1121,media/images/val_img_4_28f0ae5e98011545c848.png,491709.0,image-file,850.0,png,640.0,28f0ae5e98011545c8482a4a7ce7a5494961f0f48b7041ca724008b43f703304,,,,,,,pgd_attack,False,,slurm/results/DDOD-ATSS_R-50-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/DDOD-ATSS_R-50-FPN/latest.pth,INFO,,models/DDOD-ATSS_R-50-FPN/DDOD-ATSS_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/DDOD-ATSS_R-50-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,DDOD,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,DDODHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DDOD-ATSS_R-50-FPN,DDOD-ATSS_R-50-FPN,pgd_attack,models/DDOD-ATSS_R-50-FPN/DDOD-ATSS_R-50-FPN.py,2.5500000000000003,1.0,8.0,models/DDOD-ATSS_R-50-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,CrossEntropyLoss,1.0,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,0.8,9.0,ATSSAssigner,0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,DDOD-ATSS_R-50-FPN
0.01611293263435364,0.384,0.421,0.209,0.573,0.409,0.21737273817062375,6.0,1265.8941085338593,1720136671.3256905,0.517,1265,media/images/val_img_4_434a1df963e9f99fef19.png,491769.0,image-file,850.0,png,640.0,434a1df963e9f99fef191b029b82adbdf1e97c78440209a28fce24decc7370d7,,,,,,,pgd_attack,False,,slurm/results/RetinaNet_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/RetinaNet_R-101-FPN/latest.pth,INFO,,models/RetinaNet_R-101-FPN/RetinaNet_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/RetinaNet_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,RetinaHead,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,80.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,RetinaNet_R-101-FPN,RetinaNet_R-101-FPN,pgd_attack,models/RetinaNet_R-101-FPN/RetinaNet_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/RetinaNet_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,RetinaNet_R-101-FPN
0.013407851839065552,0.41,0.451,0.242,0.614,0.448,0.20797427396774293,6.0,1119.72793507576,1720121158.7898211,0.523,1119,media/images/val_img_4_567741bf341664db494b.png,491221.0,image-file,850.0,png,640.0,567741bf341664db494bcc820687d04c1b7f35b525bbf7d20f570e718a457e29,,,,,,,pgd_attack,False,,slurm/results/Faster R-CNN_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/Faster R-CNN_R-101-FPN/latest.pth,INFO,,models/Faster R-CNN_R-101-FPN/Faster R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 640], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Faster R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [9, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",,256.0,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Faster R-CNN_R-101-FPN,Faster R-CNN_R-101-FPN,pgd_attack,models/Faster R-CNN_R-101-FPN/Faster R-CNN_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/Faster R-CNN_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,RepeatDataset,3.0,CocoDataset,annotations/instances_train2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 640], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,,,,,,,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,-1.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,7.0,1024.0,False,False,512.0,RandomSampler,-1.0,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,Faster R-CNN_R-101-FPN
,,,,,,,,,,,51,,,,,,,,,,,,,,pgd_attack,False,,slurm/results/RepPoints_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/RepPoints_R-101-FPN/latest.pth,INFO,,models/RepPoints_R-101-FPN/RepPoints_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/RepPoints_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RepPointsDetector,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,RepPointsHead,,,,,,,256.0,80.0,256.0,3.0,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,RepPoints_R-101-FPN,RepPoints_R-101-FPN,pgd_attack,models/RepPoints_R-101-FPN/RepPoints_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/RepPoints_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,24.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,True,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,True,,,,,9.0,0.1,"[8, 16, 32, 64, 128]",0.11,SmoothL1Loss,0.5,0.11,SmoothL1Loss,1.0,4.0,moment,256.0,False,PointAssigner,4.0,1.0,-1.0,-1.0,False,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,GN,32.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,RepPoints_R-101-FPN
,,,,,,,,,,,71,,,,,,,,,,,,,,pgd_attack,False,,slurm/results/two-stage Deformable DETR_R-50-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/two-stage Deformable DETR_R-50-FPN/latest.pth,INFO,,models/two-stage Deformable DETR_R-50-FPN/two-stage Deformable DETR_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/two-stage Deformable DETR_R-50-FPN/latest.pth,"[{'end': 50, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [40]}]",ChannelMapper,4.0,"[512, 1024, 2048]",,256.0,,DeformableDETR,,ResNet,,Pretrained,,torchvision://resnet50,"[1, 2, 3]",,,,,,,,100.0,,DeformableDETRHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,50.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,two-stage Deformable DETR_R-50-FPN,two-stage Deformable DETR_R-50-FPN,pgd_attack,models/two-stage Deformable DETR_R-50-FPN/two-stage Deformable DETR_R-50-FPN.py,2.5500000000000003,1.0,8.0,models/two-stage Deformable DETR_R-50-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,,32.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0002,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,50.0,,,1.0,,,,0.1,256.0,1024.0,0.1,8.0,256.0,True,,,256.0,True,6.0,True,,,,0.1,256.0,1024.0,,,256.0,True,6.0,50.0,pytorch,BN,False,True,4.0,1.0,FocalLoss,2.0,True,,,GIoULoss,2.0,,"[{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",300.0,True,128.0,0.1,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,False,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,True,True,,4.0,-0.5,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.1,0.1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,two-stage Deformable DETR_R-50-FPN
0.013546958923339843,0.426,0.471,0.256,0.617,0.461,0.225437730884552,6.0,1252.1647579669952,1720120842.409516,0.545,1251,media/images/val_img_4_045cac49853c385e8e3d.png,491385.0,image-file,850.0,png,640.0,045cac49853c385e8e3dd96f71d963ca30841c3745fb9e5a20a862e152063f51,,,,,,,pgd_attack,False,,slurm/results/SABL RetinaNet_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/SABL RetinaNet_R-101-FPN/latest.pth,INFO,,models/SABL RetinaNet_R-101-FPN/SABL RetinaNet_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 480], [1333, 960]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/SABL RetinaNet_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,SABLRetinaHead,,,,BucketingBBoxCoder,,,256.0,80.0,256.0,4.0,,,,,,False,PseudoSampler,ApproxMaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,SABL RetinaNet_R-101-FPN,SABL RetinaNet_R-101-FPN,pgd_attack,models/SABL RetinaNet_R-101-FPN/SABL RetinaNet_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/SABL RetinaNet_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 480], [1333, 960]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,14.0,3.0,CrossEntropyLoss,1.5,True,0.1111111111111111,SmoothL1Loss,1.5,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,AnchorGenerator,[1],[4],"[8, 16, 32, 64, 128]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,SABL RetinaNet_R-101-FPN
0.013410544776916503,0.396,0.432,0.214,0.583,0.425,0.2068497646808624,6.0,1147.5345702171326,1720119359.3987913,0.534,1147,media/images/val_img_4_d08636af36dcb10a30d6.png,494506.0,image-file,850.0,png,640.0,d08636af36dcb10a30d60cc4024c3f72880d0e81628d6065ddcf769a3aa0d7f7,,,,,,,pgd_attack,False,,slurm/results/FreeAnchor_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/FreeAnchor_R-101-FPN/latest.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/FreeAnchor_R-101-FPN/FreeAnchor_R-101-FPN.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/FreeAnchor_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,FreeAnchor_R-101-FPN,FreeAnchor_R-101-FPN,pgd_attack,models/FreeAnchor_R-101-FPN/FreeAnchor_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/FreeAnchor_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,FreeAnchor_R-101-FPN
0.013420206165313722,0.404,0.44,0.205,0.606,0.43,0.2359541307926178,6.0,1378.0873730182648,1720119104.657449,0.581,1377,media/images/val_img_4_350792e727fb1dcad987.png,491787.0,image-file,850.0,png,640.0,350792e727fb1dcad98719da0d3d1af67acab276e3bcb6edb2186b7d7f9e942c,,,,,,,pgd_attack,False,,slurm/results/DAB-DETR_R-50-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/DAB-DETR_R-50-FPN/latest.pth,INFO,,models/DAB-DETR_R-50-FPN/DAB-DETR_R-50-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/DAB-DETR_R-50-FPN/latest.pth,"[{'end': 50, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [40]}]",ChannelMapper,1.0,[2048],,256.0,,DABDETR,,ResNet,,Pretrained,,torchvision://resnet50,[3],,,,,,,,300.0,,DABDETRHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,50.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DAB-DETR_R-50-FPN,DAB-DETR_R-50-FPN,pgd_attack,models/DAB-DETR_R-50-FPN/DAB-DETR_R-50-FPN.py,2.5500000000000003,1.0,8.0,models/DAB-DETR_R-50-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0001,AdamW,,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,50.0,,,1.0,PReLU,,2.0,0.0,256.0,2048.0,,8.0,256.0,,,8.0,256.0,,6.0,True,PReLU,,2.0,0.0,256.0,2048.0,0.0,8.0,256.0,True,6.0,50.0,pytorch,BN,False,True,4.0,1.0,FocalLoss,1.0,True,,,GIoULoss,2.0,256.0,"[{'eps': 1e-08, 'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",300.0,True,128.0,0.1,1.0,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 1333], [500, 1333], [600, 1333]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,20.0,,,,,,,,,,,,,,,,,,,,0.0,False,0.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.0,0.0,4.0,cond_elewise,True,0.0,False,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,DAB-DETR_R-50-FPN
,,,,,,,,,,,50,,,,,,,,,,,,,,pgd_attack,False,,slurm/results/TOOD_R-101-dcnv2/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/TOOD_R-101-dcnv2/latest.pth,INFO,,models/TOOD_R-101-dcnv2/TOOD_R-101-dcnv2.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 480], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/TOOD_R-101-dcnv2/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 24, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [16, 22]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,TOOD,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,TOODHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,256.0,6.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,TaskAlignedAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,24.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,TOOD_R-101-dcnv2,TOOD_R-101-dcnv2,pgd_attack,models/TOOD_R-101-dcnv2/TOOD_R-101-dcnv2.py,2.5500000000000003,1.0,8.0,models/TOOD_R-101-dcnv2/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,24.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,QualityFocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [[1333, 480], [1333, 800]], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,13.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,DCNv2,,False,"[False, True, True, True]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,1.0,2.0,2.0,True,anchor_free,FocalLoss,0.25,2.0,True,1.0,True,6.0,1.0,4.0,9.0,ATSSAssigner,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,TOOD_R-101-dcnv2
,,,,,,,,,,,57,,,,,,,,,,,,,,pgd_attack,False,,slurm/results/DDQ DETR-4scale_Swin-L/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/DDQ DETR-4scale_Swin-L/latest.pth,INFO,,models/DDQ DETR-4scale_Swin-L/DDQ DETR-4scale_Swin-L.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",models/DDQ DETR-4scale_Swin-L/latest.pth,"[{'end': 2000, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.0001}, {'end': 30, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [20, 26]}]",ChannelMapper,4.0,"[384, 768, 1536]",,256.0,,DDQDETR,,SwinTransformer,False,Pretrained,,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth,"[1, 2, 3]",0.2,,,,,,,300.0,,DDQDETRHead,,L1Loss,5.0,,,,,80.0,,,,,,,,,,HungarianAssigner,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,1.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,30.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,DDQ DETR-4scale_Swin-L,DDQ DETR-4scale_Swin-L,pgd_attack,models/DDQ DETR-4scale_Swin-L/DDQ DETR-4scale_Swin-L.py,2.5500000000000003,1.0,8.0,models/DDQ DETR-4scale_Swin-L/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,0.1,2.0,0.0002,AdamW,,0.05,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,30.0,,,1.0,,,,0.0,256.0,2048.0,0.0,8.0,256.0,,0.0,,256.0,,6.0,True,,,,0.0,256.0,2048.0,0.0,,256.0,,6.0,,,,,,,,FocalLoss,1.0,True,,,GIoULoss,2.0,,"[{'type': 'FocalLossCost', 'weight': 2}, {'type': 'BBoxL1Cost', 'weight': 5, 'box_format': 'xywh'}, {'type': 'IoUCost', 'weight': 2, 'iou_mode': 'giou'}]",900.0,True,128.0,0.05,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'RandomChoice', 'transforms': [[{'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}], [{'type': 'RandomChoiceResize', 'scales': [[400, 4200], [500, 4200], [600, 4200]], 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_size': [384, 600], 'crop_type': 'absolute_range', 'allow_negative_crop': True}, {'type': 'RandomChoiceResize', 'scales': [[480, 1333], [512, 1333], [544, 1333], [576, 1333], [608, 1333], [640, 1333], [672, 1333], [704, 1333], [736, 1333], [768, 1333], [800, 1333]], 'keep_ratio': True}]]}, {'type': 'PackDetInputs'}]",data/coco/,32.0,False,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,True,,100.0,1.0,0.5,4.0,,nms,0.8,4.0,True,True,True,1.5,,0.0,20.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[2, 2, 18, 2]",,True,0.0,4.0,"[6, 12, 24, 48]",192.0,True,12.0,0.0,True,,,,,,,,,,,,,,,,,,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_large_patch4_window12_384_22k.pth,,,,,,,384.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,DDQ DETR-4scale_Swin-L
,,,,,,,,,,,2,,,,,,,,,,,,,,pgd_attack,,,,,,,,models/RTMDet-l_ConvNeXt-B/RTMDet-l_ConvNeXt-B.py,,,,,,,,models/RTMDet-l_ConvNeXt-B/latest.pth,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.5500000000000003,1.0,8.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,,,RTMDet-l_ConvNeXt-B
0.06648114323616028,0.542,0.577,0.391,0.718,0.59,4.314721484422684,2.0,4525.2838678359985,1720121401.7373369,0.687,4524,media/images/val_img_0_9d3d5ab2b1cfb0e86e64.png,629932.0,image-file,1280.0,png,427.0,9d3d5ab2b1cfb0e86e648da445f33af1940df00c30da000beb3c2de5c2294329,,,,,,,pgd_attack,False,,slurm/results/RTMDet-l_Swin-B-P6/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/RTMDet-l_Swin-B-P6/latest.pth,INFO,"[[1280, 1280], [640, 640], [1920, 1920]]",models/RTMDet-l_Swin-B-P6/RTMDet-l_Swin-B-P6.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'type': 'Resize', 'scale': [640, 640], 'keep_ratio': True}, {'type': 'Resize', 'scale': [1920, 1920], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'size': [1920, 1920], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'CachedMosaic', 'pad_val': 114, 'img_scale': [1280, 1280]}, {'type': 'RandomResize', 'scale': [2560, 2560], 'keep_ratio': True, 'ratio_range': [0.1, 2]}, {'type': 'RandomCrop', 'crop_size': [1280, 1280]}, {'type': 'YOLOXHSVRandomAug'}, {'prob': 0.5, 'type': 'RandomFlip'}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'CachedMixUp', 'pad_val': [114, 114, 114], 'img_scale': [1280, 1280], 'ratio_range': [1, 1], 'max_cached_images': 20}, {'type': 'PackDetInputs'}]",models/RTMDet-l_Swin-B-P6/latest.pth,"[{'end': 1000, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 1e-05}, {'end': 100, 'type': 'CosineAnnealingLR', 'T_max': 50, 'begin': 50, 'eta_min': 5e-05, 'by_epoch': True, 'convert_to_iter_based': True}]",CSPNeXtPAFPN,,"[256, 512, 1024, 2048]",,256.0,,RTMDet,,SwinTransformer,True,Pretrained,,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22k.pth,"[1, 2, 3, 4]",0.3,,,nms,0.65,30000.0,0.001,300.0,0.0,RTMDetSepBNHead,,GIoULoss,2.0,DistancePointBBoxCoder,,,256.0,80.0,256.0,2.0,MlvlPointGenerator,,"[8, 16, 32, 64]",,,False,,DynamicSoftLabelAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,100.0,10.0,DetTTAModel,nms,0.6,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,RTMDet-l_Swin-B-P6,RTMDet-l_Swin-B-P6,pgd_attack,models/RTMDet-l_Swin-B-P6/RTMDet-l_Swin-B-P6.py,2.5500000000000003,1.0,8.0,models/RTMDet-l_Swin-B-P6/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,10.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.001,AdamW,,0.05,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,5.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1280, 1280], 'keep_ratio': True}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,5.0,CocoDataset,,,,,,,,,,,,16.0,100.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,QualityFocalLoss,1.0,True,,,,,,,,,,,,True,,DefaultSampler,False,False,20.0,True,True,,DefaultSampler,False,False,20.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'CachedMosaic', 'pad_val': 114, 'img_scale': [1280, 1280]}, {'type': 'RandomResize', 'scale': [2560, 2560], 'keep_ratio': True, 'ratio_range': [0.1, 2]}, {'type': 'RandomCrop', 'crop_size': [1280, 1280]}, {'type': 'YOLOXHSVRandomAug'}, {'prob': 0.5, 'type': 'RandomFlip'}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'CachedMixUp', 'pad_val': [114, 114, 114], 'img_scale': [1280, 1280], 'ratio_range': [1, 1], 'max_cached_images': 20}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,20.0,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,13.0,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,GN,32.0,,,,,,,,,,0.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[2, 2, 18, 2, 1]",,True,0.0,4.0,"[4, 8, 16, 32, 64]",128.0,True,12.0,0.0,True,,,,,,,,,,,,,,,,,,,,,,,,,384.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,3.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,2.0,,,,,,,,,,,,,,0.001,10.0,https://github.com/SwinTransformer/storage/releases/download/v1.0.0/swin_base_patch4_window12_384_22k.pth,"[{'type': 'EMAHook', 'ema_type': 'ExpMomentumEMA', 'momentum': 0.0002, 'priority': 49, 'update_buffers': True}, {'type': 'PipelineSwitchHook', 'switch_epoch': 90, 'switch_pipeline': [{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [1280, 1280], 'keep_ratio': True, 'ratio_range': [0.1, 2]}, {'type': 'RandomCrop', 'crop_size': [1280, 1280]}, {'type': 'YOLOXHSVRandomAug'}, {'prob': 0.5, 'type': 'RandomFlip'}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'PackDetInputs'}]}]",10.0,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomResize', 'scale': [1280, 1280], 'keep_ratio': True, 'ratio_range': [0.1, 2]}, {'type': 'RandomCrop', 'crop_size': [1280, 1280]}, {'type': 'YOLOXHSVRandomAug'}, {'prob': 0.5, 'type': 'RandomFlip'}, {'size': [1280, 1280], 'type': 'Pad', 'pad_val': {'img': [114, 114, 114]}}, {'type': 'PackDetInputs'}]",SiLU,True,0.5,3.0,"[4, 2, 2, 2, 2]",SiLU,True,True,True,False,0.0,1.0,"[[90, 1]]",0.0,True,"[100, 1, 10]","[100, 1, 10]",True,,,,False,False,False,False,,,RTMDet-l_Swin-B-P6
0.01653296175003052,0.394,0.432,0.221,0.601,0.433,0.22220308256149293,6.0,1291.245159626007,1720118108.5088236,0.514,1290,media/images/val_img_4_348ba37fe465318f906c.png,491616.0,image-file,850.0,png,640.0,348ba37fe465318f906c3b4676b38deffbf4ff4c2751308c840d9164d44fc22e,,,,,,,pgd_attack,False,,slurm/results/Libra R-CNN_R-101-FPN/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/coco/,models/Libra R-CNN_R-101-FPN/latest.pth,INFO,,models/Libra R-CNN_R-101-FPN/Libra R-CNN_R-101-FPN.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/Libra R-CNN_R-101-FPN/latest.pth,"[{'end': 500, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 12, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [8, 11]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,12.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,Libra R-CNN_R-101-FPN,Libra R-CNN_R-101-FPN,pgd_attack,models/Libra R-CNN_R-101-FPN/Libra R-CNN_R-101-FPN.py,2.5500000000000003,1.0,8.0,models/Libra R-CNN_R-101-FPN/latest.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,False,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoMetric,bbox,data/coco/annotations/instances_val2017.json,False,,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,annotations/instances_val2017.json,,,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/coco/,val2017/,1.0,CocoDataset,,,,,,,,,,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,True,,DefaultSampler,False,False,2.0,True,True,,DefaultSampler,False,False,2.0,True,annotations/instances_train2017.json,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/coco/,32.0,True,train2017/,,DefaultSampler,True,2.0,AspectRatioBatchSampler,True,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,80.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,Libra R-CNN_R-101-FPN
0.021831557602923785,0.064,0.0,0.0,0.14,0.049,3.651105200909808,6.0,18253.722642183304,1720048990.7677732,0.1,18253,media/images/val_img_4_8cabb8de7378f3c0bf2c.png,426404.0,image-file,1000.0,png,375.0,8cabb8de7378f3c0bf2c09b481369112145d7c377952a882de55c7a4a7fd9bd8,,,,,,,bim_attack,True,none,slurm/results/free_anchor_convnext-b_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps20_norminf,data/VOCdevkit/,models/free_anchor_convnext-b_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_convnext-b_voc0712/free_anchor_convnext-b_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_input,RetinaNet,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_convnext-b_voc0712,free_anchor_convnext-b_voc0712,bim_attack,models/free_anchor_convnext-b_voc0712/free_anchor_convnext-b_voc0712.py,2.5500000000000003,20.0,8.0,models/free_anchor_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,free_anchor_convnext-b_voc0712
0.017486823103342687,0.017,0.0,0.0,0.062,0.006,3.8313754228252654,6.0,19116.685220241547,1720049853.4919903,0.025,19116,media/images/val_img_4_f01069d94271842955da.png,367102.0,image-file,1000.0,png,375.0,f01069d94271842955dad7f1545061ae630368605901df743d5eca5b30f4a360,,,,,,,bim_attack,True,none,slurm/results/libra_rcnn_convnext-b_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps20_norminf,data/VOCdevkit/,models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_convnext-b_voc0712/libra_rcnn_convnext-b_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_convnext-b_voc0712,libra_rcnn_convnext-b_voc0712,bim_attack,models/libra_rcnn_convnext-b_voc0712/libra_rcnn_convnext-b_voc0712.py,2.5500000000000003,20.0,8.0,models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,libra_rcnn_convnext-b_voc0712
0.008645311548520693,0.461,0.325,0.17,0.75,0.495,2.31152846657722,6.0,11579.688057661057,1720042315.718479,0.509,11578,media/images/val_img_4_787404b1210fd134d063.png,354000.0,image-file,1000.0,png,375.0,787404b1210fd134d063216114c3e0963fbe1fd5de12cbd56f4f0a1897f102fa,,,,,,,bim_attack,True,none,slurm/results/libra_rcnn_r101_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps20_norminf,data/VOCdevkit/,models/libra_rcnn_r101_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_r101_voc0712/libra_rcnn_r101_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_r101_voc0712,libra_rcnn_r101_voc0712,bim_attack,models/libra_rcnn_r101_voc0712/libra_rcnn_r101_voc0712.py,2.5500000000000003,20.0,8.0,models/libra_rcnn_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,libra_rcnn_r101_voc0712
0.010486834366442386,0.455,0.31,0.15,0.696,0.484,1.936641920366216,6.0,9736.548355340958,1720040472.5890584,0.507,9735,media/images/val_img_4_dfbc52f39ceb088967ed.png,346071.0,image-file,1000.0,png,374.0,dfbc52f39ceb088967ed8ed4165212edafac25d241015d354713e70d58dfda0d,,,,,,,bim_attack,True,none,slurm/results/atss_r101_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps20_norminf,data/VOCdevkit/,models/atss_r101_voc0712/epoch_3.pth,INFO,,models/atss_r101_voc0712/atss_r101_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_r101_voc0712/epoch_3.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_r101_voc0712,atss_r101_voc0712,bim_attack,models/atss_r101_voc0712/atss_r101_voc0712.py,2.5500000000000003,20.0,8.0,models/atss_r101_voc0712/epoch_3.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,atss_r101_voc0712
0.02602246812250117,0.368,0.254,0.118,0.632,0.369,1.549926895048795,6.0,7815.420278072357,1720038551.5035112,0.407,7814,media/images/val_img_4_4ae31f91aba0b982d2bf.png,355015.0,image-file,1000.0,png,375.0,4ae31f91aba0b982d2bf1dcfcd14f95b9ed05cb151b877574266e280745999fc,,,,,,,bim_attack,True,none,slurm/results/fsaf_r50_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps20_norminf,data/VOCdevkit/,models/fsaf_r50_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_r50_voc0712/fsaf_r50_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_r50_voc0712,fsaf_r50_voc0712,bim_attack,models/fsaf_r50_voc0712/fsaf_r50_voc0712.py,2.5500000000000003,20.0,8.0,models/fsaf_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,fsaf_r50_voc0712
0.010444441011114214,0.03,0.001,0.0,0.083,0.017,3.873371575592552,6.0,19325.73137116432,1720050061.619254,0.043,19325,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,bim_attack,True,none,slurm/results/fsaf_convnext-b_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps20_norminf,data/VOCdevkit/,models/fsaf_convnext-b_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_convnext-b_voc0712/fsaf_convnext-b_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_input,FSAF,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_convnext-b_voc0712,fsaf_convnext-b_voc0712,bim_attack,models/fsaf_convnext-b_voc0712/fsaf_convnext-b_voc0712.py,2.5500000000000003,20.0,8.0,models/fsaf_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,fsaf_convnext-b_voc0712
0.009487780469512786,0.413,0.292,0.196,0.711,0.436,1.6883883755928624,6.0,8491.777751684189,1720039227.6657517,0.456,8491,media/images/val_img_4_a99477043ca852448a42.png,358260.0,image-file,1000.0,png,375.0,a99477043ca852448a42426d7c338037e62bd86681b2e16977933751607e2c97,,,,,,,bim_attack,True,none,slurm/results/libra_rcnn_r50_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps20_norminf,data/VOCdevkit/,models/libra_rcnn_r50_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_r50_voc0712/libra_rcnn_r50_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_r50_voc0712,libra_rcnn_r50_voc0712,bim_attack,models/libra_rcnn_r50_voc0712/libra_rcnn_r50_voc0712.py,2.5500000000000003,20.0,8.0,models/libra_rcnn_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,libra_rcnn_r50_voc0712
0.011011869960810328,0.378,0.268,0.157,0.614,0.393,1.6106625431214057,6.0,8124.72351026535,1720038860.771808,0.415,8124,media/images/val_img_4_886c8a870f7792c863c7.png,351365.0,image-file,1000.0,png,375.0,886c8a870f7792c863c785a6af6c9e0bcedc928488a9de39ab7310714f61c7a5,,,,,,,bim_attack,True,none,slurm/results/atss_r50_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps20_norminf,data/VOCdevkit/,models/atss_r50_voc0712/epoch_4.pth,INFO,,models/atss_r50_voc0712/atss_r50_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_r50_voc0712,atss_r50_voc0712,bim_attack,models/atss_r50_voc0712/atss_r50_voc0712.py,2.5500000000000003,20.0,8.0,models/atss_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,atss_r50_voc0712
0.018605833941220323,0.472,0.325,0.151,0.731,0.502,1.8404238445937404,6.0,9271.469900131226,1720040007.516149,0.526,9270,media/images/val_img_4_e26bed63e45505fe353d.png,358964.0,image-file,1000.0,png,375.0,e26bed63e45505fe353df006b96871307b02c9e8201f0c016034fda28c96111d,,,,,,,bim_attack,True,none,slurm/results/free_anchor_r101_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps20_norminf,data/VOCdevkit/,models/free_anchor_r101_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_r101_voc0712/free_anchor_r101_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_r101_voc0712,free_anchor_r101_voc0712,bim_attack,models/free_anchor_r101_voc0712/free_anchor_r101_voc0712.py,2.5500000000000003,20.0,8.0,models/free_anchor_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,free_anchor_r101_voc0712
0.011694203572588066,0.453,0.312,0.187,0.723,0.475,1.9506777970448617,6.0,9736.41448354721,1720040355.0838485,0.504,9735,media/images/val_img_4_f34f1a395d4eec2ffcd9.png,357031.0,image-file,1000.0,png,375.0,f34f1a395d4eec2ffcd9b8d8e2cd465119ca6914c5f84b1ec972426e567a3136,,,,,,,bim_attack,True,none,slurm/results/fsaf_r101_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps20_norminf,data/VOCdevkit/,models/fsaf_r101_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_r101_voc0712/fsaf_r101_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_r101_voc0712,fsaf_r101_voc0712,bim_attack,models/fsaf_r101_voc0712/fsaf_r101_voc0712.py,2.5500000000000003,20.0,8.0,models/fsaf_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,fsaf_r101_voc0712
0.009083797203370495,0.412,0.279,0.189,0.669,0.422,1.3138483712920126,6.0,6596.63262796402,1720036973.050765,0.454,6596,media/images/val_img_4_9b76468adbe90754026c.png,354402.0,image-file,1000.0,png,375.0,9b76468adbe90754026cde55f2955c1c94daddd2be63557c7e01cc45fc066e08,,,,,,,bim_attack,True,none,slurm/results/free_anchor_r50_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps20_norminf,data/VOCdevkit/,models/free_anchor_r50_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_r50_voc0712/free_anchor_r50_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_r50_voc0712,free_anchor_r50_voc0712,bim_attack,models/free_anchor_r50_voc0712/free_anchor_r50_voc0712.py,2.5500000000000003,20.0,8.0,models/free_anchor_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,free_anchor_r50_voc0712
0.012295853025427544,0.067,0.002,0.0,0.15,0.05,4.028324189629912,6.0,20117.066366434097,1720050258.0520854,0.092,20116,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,bim_attack,True,none,slurm/results/atss_convnext-b_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps20_norminf,data/VOCdevkit/,models/atss_convnext-b_voc0712/epoch_4.pth,INFO,,models/atss_convnext-b_voc0712/atss_convnext-b_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_output,ATSS,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_convnext-b_voc0712,atss_convnext-b_voc0712,bim_attack,models/atss_convnext-b_voc0712/atss_convnext-b_voc0712.py,2.5500000000000003,20.0,8.0,models/atss_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,atss_convnext-b_voc0712
0.01909026121481871,0.066,0.0,0.0,0.141,0.051,3.6992582900341704,6.0,18435.9023373127,1720046503.4186294,0.101,18435,media/images/val_img_4_2c199f607dbe8923037b.png,426765.0,image-file,1000.0,png,375.0,2c199f607dbe8923037b0a9a3f36d91d6cdeef3e7cef63152df8f65d74d1b176,,,,,,,pgd_attack,True,none,slurm/results/free_anchor_convnext-b_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps20_random_startFalse,data/VOCdevkit/,models/free_anchor_convnext-b_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_convnext-b_voc0712/free_anchor_convnext-b_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_input,RetinaNet,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_convnext-b_voc0712,free_anchor_convnext-b_voc0712,pgd_attack,models/free_anchor_convnext-b_voc0712/free_anchor_convnext-b_voc0712.py,2.5500000000000003,20.0,8.0,models/free_anchor_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,free_anchor_convnext-b_voc0712
0.02022883402514212,0.473,0.326,0.182,0.731,0.505,1.7694321394977537,6.0,8860.686314344406,1720035092.3531013,0.526,8860,media/images/val_img_4_868afc70347f818974d4.png,358955.0,image-file,1000.0,png,375.0,868afc70347f818974d42f7c9538c4ae69f7f7637e14b3512431e260446c2a2d,,,,,,,pgd_attack,True,none,slurm/results/free_anchor_r101_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps20_random_startFalse,data/VOCdevkit/,models/free_anchor_r101_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_r101_voc0712/free_anchor_r101_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_r101_voc0712,free_anchor_r101_voc0712,pgd_attack,models/free_anchor_r101_voc0712/free_anchor_r101_voc0712.py,2.5500000000000003,20.0,8.0,models/free_anchor_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,free_anchor_r101_voc0712
0.024902967643237177,0.368,0.251,0.121,0.632,0.368,1.54182825660359,6.0,7787.422456502914,1720034016.6787474,0.407,7786,media/images/val_img_4_dfa77d3bda4e1649548d.png,354091.0,image-file,1000.0,png,375.0,dfa77d3bda4e1649548dcf5e1a36c3e218aca59e176347632007ea5a53894599,,,,,,,pgd_attack,True,none,slurm/results/fsaf_r50_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps20_random_startFalse,data/VOCdevkit/,models/fsaf_r50_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_r50_voc0712/fsaf_r50_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_r50_voc0712,fsaf_r50_voc0712,pgd_attack,models/fsaf_r50_voc0712/fsaf_r50_voc0712.py,2.5500000000000003,20.0,8.0,models/fsaf_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,fsaf_r50_voc0712
0.01659858065519866,0.455,0.311,0.15,0.696,0.485,2.1013004482815343,6.0,10574.717255115507,1720035975.271098,0.507,10574,media/images/val_img_4_76ab16259eb1851ffab1.png,346771.0,image-file,1000.0,png,374.0,76ab16259eb1851ffab17f5a5c682e98b43896ce8681a5c5500ca3e5c0f5be34,,,,,,,pgd_attack,True,none,slurm/results/atss_r101_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps20_random_startFalse,data/VOCdevkit/,models/atss_r101_voc0712/epoch_3.pth,INFO,,models/atss_r101_voc0712/atss_r101_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_r101_voc0712/epoch_3.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_r101_voc0712,atss_r101_voc0712,pgd_attack,models/atss_r101_voc0712/atss_r101_voc0712.py,2.5500000000000003,20.0,8.0,models/atss_r101_voc0712/epoch_3.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,atss_r101_voc0712
0.02219594408232059,0.016,0.0,0.0,0.057,0.005,3.8125620812039265,6.0,19050.525418758392,1720042890.6156178,0.023,19049,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,pgd_attack,True,none,slurm/results/libra_rcnn_convnext-b_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps20_random_startFalse,data/VOCdevkit/,models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_convnext-b_voc0712/libra_rcnn_convnext-b_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_convnext-b_voc0712,libra_rcnn_convnext-b_voc0712,pgd_attack,models/libra_rcnn_convnext-b_voc0712/libra_rcnn_convnext-b_voc0712.py,2.5500000000000003,20.0,8.0,models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,libra_rcnn_convnext-b_voc0712
0.008920475807474907,0.461,0.327,0.181,0.75,0.495,2.2268265472044733,6.0,11103.012039899826,1720033911.506815,0.51,11102,media/images/val_img_4_ea963eca4ab6c45d32ce.png,356146.0,image-file,1000.0,png,375.0,ea963eca4ab6c45d32ce198b7168aec55184d38c3fa2de4e4af788f9b7afb9a3,,,,,,,pgd_attack,True,none,slurm/results/libra_rcnn_r101_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps20_random_startFalse,data/VOCdevkit/,models/libra_rcnn_r101_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_r101_voc0712/libra_rcnn_r101_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_r101_voc0712,libra_rcnn_r101_voc0712,pgd_attack,models/libra_rcnn_r101_voc0712/libra_rcnn_r101_voc0712.py,2.5500000000000003,20.0,8.0,models/libra_rcnn_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,libra_rcnn_r101_voc0712
0.03146524422582222,0.378,0.266,0.157,0.614,0.392,1.60401422318463,6.0,8122.928977966309,1720030482.622682,0.415,8122,media/images/val_img_4_adfb1f5d3280afa39a9e.png,349640.0,image-file,1000.0,png,375.0,adfb1f5d3280afa39a9e5086fca2ed3d9c3700872320e18a4fbf90a9fa7d9e3b,,,,,,,pgd_attack,True,none,slurm/results/atss_r50_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps20_random_startFalse,data/VOCdevkit/,models/atss_r50_voc0712/epoch_4.pth,INFO,,models/atss_r50_voc0712/atss_r50_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_r50_voc0712,atss_r50_voc0712,pgd_attack,models/atss_r50_voc0712/atss_r50_voc0712.py,2.5500000000000003,20.0,8.0,models/atss_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,atss_r50_voc0712
0.03469807033511862,0.455,0.313,0.191,0.726,0.479,1.99909693246992,6.0,10075.75937795639,1720030232.147344,0.506,10074,media/images/val_img_4_acd8d13d010fb0fb4a59.png,357796.0,image-file,1000.0,png,375.0,acd8d13d010fb0fb4a5990ea96c1e91ad394c339845d4f185f0aa6a6203a154a,,,,,,,pgd_attack,True,none,slurm/results/fsaf_r101_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps20_random_startFalse,data/VOCdevkit/,models/fsaf_r101_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_r101_voc0712/fsaf_r101_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_r101_voc0712,fsaf_r101_voc0712,pgd_attack,models/fsaf_r101_voc0712/fsaf_r101_voc0712.py,2.5500000000000003,20.0,8.0,models/fsaf_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,fsaf_r101_voc0712
0.03653823450890643,0.031,0.001,0.0,0.084,0.017,4.005484536178854,6.0,20014.36642432213,1720026031.5158443,0.044,20012,media/images/val_img_4_12810c3471f43bdfdd0a.png,359550.0,image-file,1000.0,png,375.0,12810c3471f43bdfdd0adddce52085620af96f654948a42bd6d43da9d417a104,,,,,,,pgd_attack,True,none,slurm/results/fsaf_convnext-b_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps20_random_startFalse,data/VOCdevkit/,models/fsaf_convnext-b_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_convnext-b_voc0712/fsaf_convnext-b_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_input,FSAF,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_convnext-b_voc0712,fsaf_convnext-b_voc0712,pgd_attack,models/fsaf_convnext-b_voc0712/fsaf_convnext-b_voc0712.py,2.5500000000000003,20.0,8.0,models/fsaf_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,fsaf_convnext-b_voc0712
0.02495396173339696,0.413,0.288,0.191,0.71,0.432,1.6605166059875642,6.0,8380.874007225037,1720005630.6274512,0.458,8380,media/images/val_img_4_9fb82c90171702690c32.png,358535.0,image-file,1000.0,png,375.0,9fb82c90171702690c32a29281fed35b0d8be8b40480c0246f3602d63ec82764,,,,,,,pgd_attack,True,none,slurm/results/libra_rcnn_r50_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps20_random_startFalse,data/VOCdevkit/,models/libra_rcnn_r50_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_r50_voc0712/libra_rcnn_r50_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_r50_voc0712,libra_rcnn_r50_voc0712,pgd_attack,models/libra_rcnn_r50_voc0712/libra_rcnn_r50_voc0712.py,2.5500000000000003,20.0,8.0,models/libra_rcnn_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,libra_rcnn_r50_voc0712
0.07142183392211064,0.412,0.278,0.208,0.669,0.423,1.3961165446164558,6.0,7105.914972305298,1719996989.5352063,0.453,7103,media/images/val_img_4_3858b30779d3e39d2f2d.png,352377.0,image-file,1000.0,png,375.0,3858b30779d3e39d2f2d175d7e5ad9b1c7e4075ac092921cf94edcac5647365d,,,,,,,pgd_attack,True,none,slurm/results/free_anchor_r50_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps20_random_startFalse,data/VOCdevkit/,models/free_anchor_r50_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_r50_voc0712/free_anchor_r50_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_r50_voc0712,free_anchor_r50_voc0712,pgd_attack,models/free_anchor_r50_voc0712/free_anchor_r50_voc0712.py,2.5500000000000003,20.0,8.0,models/free_anchor_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,free_anchor_r50_voc0712
0.01675323248150227,0.068,0.003,0.0,0.152,0.054,4.024971761199024,6.0,20129.294162273407,1720010012.9146352,0.093,20128,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,pgd_attack,True,none,slurm/results/atss_convnext-b_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps20_random_startFalse,data/VOCdevkit/,models/atss_convnext-b_voc0712/epoch_4.pth,INFO,,models/atss_convnext-b_voc0712/atss_convnext-b_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_output,ATSS,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_convnext-b_voc0712,atss_convnext-b_voc0712,pgd_attack,models/atss_convnext-b_voc0712/atss_convnext-b_voc0712.py,2.5500000000000003,20.0,8.0,models/atss_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,20.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,atss_convnext-b_voc0712
0.008560462694035235,0.25,0.016,0.0,0.458,0.242,0.23665627565813285,6.0,1283.742662668228,1719960231.0841167,0.343,1283,media/images/val_img_4_aff93266ee46d86b6219.png,399270.0,image-file,1000.0,png,375.0,aff93266ee46d86b6219a37551499686526d9ace92dfde8cf6188e3c41e8a1b4,,,,,,,bim_attack,True,none,slurm/results/free_anchor_convnext-b_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps1_norminf,data/VOCdevkit/,models/free_anchor_convnext-b_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_convnext-b_voc0712/free_anchor_convnext-b_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_input,RetinaNet,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_convnext-b_voc0712,free_anchor_convnext-b_voc0712,bim_attack,models/free_anchor_convnext-b_voc0712/free_anchor_convnext-b_voc0712.py,2.5500000000000003,1.0,8.0,models/free_anchor_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,free_anchor_convnext-b_voc0712
0.008676406183364101,0.557,0.4,0.211,0.825,0.603,0.13019979541623758,6.0,741.0002980232239,1719959686.76042,0.614,740,media/images/val_img_4_407ff37ca0544ae1d0eb.png,355961.0,image-file,1000.0,png,375.0,407ff37ca0544ae1d0ebbfb90403980a90c2605a23880f31e8689e1b2fa70932,,,,,,,bim_attack,True,none,slurm/results/free_anchor_r101_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps1_norminf,data/VOCdevkit/,models/free_anchor_r101_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_r101_voc0712/free_anchor_r101_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_r101_voc0712,free_anchor_r101_voc0712,bim_attack,models/free_anchor_r101_voc0712/free_anchor_r101_voc0712.py,2.5500000000000003,1.0,8.0,models/free_anchor_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,free_anchor_r101_voc0712
0.008524234093200696,0.498,0.352,0.221,0.788,0.525,0.11176834230636698,6.0,637.8282005786896,1719959583.5687675,0.548,637,media/images/val_img_4_3df0bdae79397e00143d.png,354204.0,image-file,1000.0,png,375.0,3df0bdae79397e00143de6a4e8925c956bd9c5ac94fd009407c8dfb8341a66d6,,,,,,,bim_attack,True,none,slurm/results/fsaf_r50_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps1_norminf,data/VOCdevkit/,models/fsaf_r50_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_r50_voc0712/fsaf_r50_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_r50_voc0712,fsaf_r50_voc0712,bim_attack,models/fsaf_r50_voc0712/fsaf_r50_voc0712.py,2.5500000000000003,1.0,8.0,models/fsaf_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,fsaf_r50_voc0712
0.008303147480989884,0.554,0.399,0.205,0.809,0.605,0.13669525125689538,6.0,765.183670759201,1719959469.5123377,0.615,764,media/images/val_img_4_fd669ecd0972c0339522.png,345684.0,image-file,1000.0,png,374.0,fd669ecd0972c033952298d29a298613d5686a0c21c8010cb166db0a03dd1ea9,,,,,,,bim_attack,True,none,slurm/results/atss_r101_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps1_norminf,data/VOCdevkit/,models/atss_r101_voc0712/epoch_3.pth,INFO,,models/atss_r101_voc0712/atss_r101_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_r101_voc0712/epoch_3.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_r101_voc0712,atss_r101_voc0712,bim_attack,models/atss_r101_voc0712/atss_r101_voc0712.py,2.5500000000000003,1.0,8.0,models/atss_r101_voc0712/epoch_3.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,atss_r101_voc0712
0.008883963684445556,0.102,0.002,0.0,0.245,0.068,0.24893186074566315,6.0,1318.846251487732,1719959925.4994426,0.137,1318,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,bim_attack,True,none,slurm/results/libra_rcnn_convnext-b_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps1_norminf,data/VOCdevkit/,models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_convnext-b_voc0712/libra_rcnn_convnext-b_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_convnext-b_voc0712,libra_rcnn_convnext-b_voc0712,bim_attack,models/libra_rcnn_convnext-b_voc0712/libra_rcnn_convnext-b_voc0712.py,2.5500000000000003,1.0,8.0,models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,libra_rcnn_convnext-b_voc0712
0.008950015209959705,0.542,0.398,0.24,0.838,0.605,0.1566988057664686,6.0,855.9346449375153,1719958949.472523,0.593,855,media/images/val_img_4_2ac03c6f1f9def3b8fa1.png,355966.0,image-file,1000.0,png,375.0,2ac03c6f1f9def3b8fa14196a7485b5d6add169b839a52a1366e4fb2ffcf6b9b,,,,,,,bim_attack,True,none,slurm/results/libra_rcnn_r101_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps1_norminf,data/VOCdevkit/,models/libra_rcnn_r101_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_r101_voc0712/libra_rcnn_r101_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_r101_voc0712,libra_rcnn_r101_voc0712,bim_attack,models/libra_rcnn_r101_voc0712/libra_rcnn_r101_voc0712.py,2.5500000000000003,1.0,8.0,models/libra_rcnn_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,libra_rcnn_r101_voc0712
0.008445572183995253,0.526,0.375,0.213,0.791,0.572,0.1137934457935662,6.0,647.8744020462036,1719958621.603233,0.577,647,media/images/val_img_4_1d720341d75468b8dc34.png,352094.0,image-file,1000.0,png,375.0,1d720341d75468b8dc3471aabd383d4ad47352fca7d6f74566def859746ad172,,,,,,,bim_attack,True,none,slurm/results/atss_r50_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps1_norminf,data/VOCdevkit/,models/atss_r50_voc0712/epoch_4.pth,INFO,,models/atss_r50_voc0712/atss_r50_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_r50_voc0712,atss_r50_voc0712,bim_attack,models/atss_r50_voc0712/atss_r50_voc0712.py,2.5500000000000003,1.0,8.0,models/atss_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,atss_r50_voc0712
0.008564123307337261,0.143,0.008,0.005,0.275,0.137,0.2555084687253574,6.0,1349.8694722652435,1719959323.833913,0.196,1349,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,bim_attack,True,none,slurm/results/fsaf_convnext-b_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps1_norminf,data/VOCdevkit/,models/fsaf_convnext-b_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_convnext-b_voc0712/fsaf_convnext-b_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_input,FSAF,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_convnext-b_voc0712,fsaf_convnext-b_voc0712,bim_attack,models/fsaf_convnext-b_voc0712/fsaf_convnext-b_voc0712.py,2.5500000000000003,1.0,8.0,models/fsaf_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,fsaf_convnext-b_voc0712
0.008481326354481393,0.538,0.395,0.23,0.818,0.575,0.14167379596462978,6.0,778.8043794631958,1719958752.5229723,0.593,778,media/images/val_img_4_a34801c709cccd29eceb.png,355648.0,image-file,1000.0,png,375.0,a34801c709cccd29ecebbe45864b0c6752d410de125ff6dc297eaa8ffe0b743c,,,,,,,bim_attack,True,none,slurm/results/fsaf_r101_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps1_norminf,data/VOCdevkit/,models/fsaf_r101_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_r101_voc0712/fsaf_r101_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_r101_voc0712,fsaf_r101_voc0712,bim_attack,models/fsaf_r101_voc0712/fsaf_r101_voc0712.py,2.5500000000000003,1.0,8.0,models/fsaf_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,fsaf_r101_voc0712
0.008684397321408768,0.528,0.373,0.208,0.803,0.569,0.1014849148975005,6.0,610.6087119579315,1719958467.625272,0.58,610,media/images/val_img_4_40898397b2ab74748803.png,354156.0,image-file,1000.0,png,375.0,40898397b2ab747488038adb413dddfd835fffd46e774afbad2e153c7d065825,,,,,,,bim_attack,True,none,slurm/results/free_anchor_r50_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps1_norminf,data/VOCdevkit/,models/free_anchor_r50_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_r50_voc0712/free_anchor_r50_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_r50_voc0712,free_anchor_r50_voc0712,bim_attack,models/free_anchor_r50_voc0712/free_anchor_r50_voc0712.py,2.5500000000000003,1.0,8.0,models/free_anchor_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,free_anchor_r50_voc0712
0.01000951666459396,0.508,0.376,0.259,0.821,0.549,0.11706253756856812,6.0,650.7155654430389,1719958500.9414685,0.556,650,media/images/val_img_4_a3fe11967f053b0f16cc.png,356495.0,image-file,1000.0,png,375.0,a3fe11967f053b0f16cc17cad5e5e295ecf33febb6dda6211a73cc9817a349cb,,,,,,,bim_attack,True,none,slurm/results/libra_rcnn_r50_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps1_norminf,data/VOCdevkit/,models/libra_rcnn_r50_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_r50_voc0712/libra_rcnn_r50_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_r50_voc0712,libra_rcnn_r50_voc0712,bim_attack,models/libra_rcnn_r50_voc0712/libra_rcnn_r50_voc0712.py,2.5500000000000003,1.0,8.0,models/libra_rcnn_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,libra_rcnn_r50_voc0712
0.010326958222507636,0.25,0.016,0.0,0.458,0.242,0.23885627830724104,6.0,1302.4606873989103,1719958815.5883453,0.343,1301,media/images/val_img_4_aff93266ee46d86b6219.png,399270.0,image-file,1000.0,png,375.0,aff93266ee46d86b6219a37551499686526d9ace92dfde8cf6188e3c41e8a1b4,,,,,,,fgsm_attack,True,none,slurm/results/free_anchor_convnext-b_voc0712/FGSM_epsilon8_alpha51div20_targetedFalse_norminf,data/VOCdevkit/,models/free_anchor_convnext-b_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_convnext-b_voc0712/free_anchor_convnext-b_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_input,RetinaNet,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_convnext-b_voc0712,free_anchor_convnext-b_voc0712,fgsm_attack,models/free_anchor_convnext-b_voc0712/free_anchor_convnext-b_voc0712.py,2.5500000000000003,,8.0,models/free_anchor_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,free_anchor_convnext-b_voc0712
0.008842680686751977,0.182,0.008,0.006,0.325,0.178,0.2440046397647592,6.0,1310.7881681919098,1719958822.3779385,0.246,1310,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,bim_attack,True,none,slurm/results/atss_convnext-b_voc0712/BIM_epsilon8_alpha51div20_targetedFalse_steps1_norminf,data/VOCdevkit/,models/atss_convnext-b_voc0712/epoch_4.pth,INFO,,models/atss_convnext-b_voc0712/atss_convnext-b_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_output,ATSS,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_convnext-b_voc0712,atss_convnext-b_voc0712,bim_attack,models/atss_convnext-b_voc0712/atss_convnext-b_voc0712.py,2.5500000000000003,1.0,8.0,models/atss_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,atss_convnext-b_voc0712
0.008444508085245078,0.557,0.4,0.211,0.825,0.603,0.129417171772865,6.0,726.6880307197571,1719957846.3984048,0.614,726,media/images/val_img_4_407ff37ca0544ae1d0eb.png,355961.0,image-file,1000.0,png,375.0,407ff37ca0544ae1d0ebbfb90403980a90c2605a23880f31e8689e1b2fa70932,,,,,,,fgsm_attack,True,none,slurm/results/free_anchor_r101_voc0712/FGSM_epsilon8_alpha51div20_targetedFalse_norminf,data/VOCdevkit/,models/free_anchor_r101_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_r101_voc0712/free_anchor_r101_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_r101_voc0712,free_anchor_r101_voc0712,fgsm_attack,models/free_anchor_r101_voc0712/free_anchor_r101_voc0712.py,2.5500000000000003,,8.0,models/free_anchor_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,free_anchor_r101_voc0712
0.026351354301709876,0.498,0.352,0.221,0.788,0.525,0.13622683677773464,6.0,834.7135498523712,1719957888.7314608,0.548,834,media/images/val_img_4_3df0bdae79397e00143d.png,354204.0,image-file,1000.0,png,375.0,3df0bdae79397e00143de6a4e8925c956bd9c5ac94fd009407c8dfb8341a66d6,,,,,,,fgsm_attack,True,none,slurm/results/fsaf_r50_voc0712/FGSM_epsilon8_alpha51div20_targetedFalse_norminf,data/VOCdevkit/,models/fsaf_r50_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_r50_voc0712/fsaf_r50_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_r50_voc0712,fsaf_r50_voc0712,fgsm_attack,models/fsaf_r50_voc0712/fsaf_r50_voc0712.py,2.5500000000000003,,8.0,models/fsaf_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,fsaf_r50_voc0712
0.008429532337015431,0.554,0.399,0.205,0.809,0.605,0.1446386863312624,6.0,797.7580244541168,1719957675.8908503,0.615,797,media/images/val_img_4_fd669ecd0972c0339522.png,345684.0,image-file,1000.0,png,374.0,fd669ecd0972c033952298d29a298613d5686a0c21c8010cb166db0a03dd1ea9,,,,,,,fgsm_attack,True,none,slurm/results/atss_r101_voc0712/FGSM_epsilon8_alpha51div20_targetedFalse_norminf,data/VOCdevkit/,models/atss_r101_voc0712/epoch_3.pth,INFO,,models/atss_r101_voc0712/atss_r101_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_r101_voc0712/epoch_3.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_r101_voc0712,atss_r101_voc0712,fgsm_attack,models/atss_r101_voc0712/atss_r101_voc0712.py,2.5500000000000003,,8.0,models/atss_r101_voc0712/epoch_3.pth,846186413151,attacks,2.5500000000000003,,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,atss_r101_voc0712
0.008595473786062745,0.102,0.002,0.0,0.245,0.068,0.2510840908195331,6.0,1328.023372411728,1719957842.2753444,0.137,1327,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,fgsm_attack,True,none,slurm/results/libra_rcnn_convnext-b_voc0712/FGSM_epsilon8_alpha51div20_targetedFalse_norminf,data/VOCdevkit/,models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_convnext-b_voc0712/libra_rcnn_convnext-b_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_convnext-b_voc0712,libra_rcnn_convnext-b_voc0712,fgsm_attack,models/libra_rcnn_convnext-b_voc0712/libra_rcnn_convnext-b_voc0712.py,2.5500000000000003,,8.0,models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,libra_rcnn_convnext-b_voc0712
0.009328882164264866,0.542,0.398,0.24,0.838,0.605,0.1638148710892799,6.0,904.183783531189,1719957312.8015184,0.593,903,media/images/val_img_4_2ac03c6f1f9def3b8fa1.png,355966.0,image-file,1000.0,png,375.0,2ac03c6f1f9def3b8fa14196a7485b5d6add169b839a52a1366e4fb2ffcf6b9b,,,,,,,fgsm_attack,True,none,slurm/results/libra_rcnn_r101_voc0712/FGSM_epsilon8_alpha51div20_targetedFalse_norminf,data/VOCdevkit/,models/libra_rcnn_r101_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_r101_voc0712/libra_rcnn_r101_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_r101_voc0712,libra_rcnn_r101_voc0712,fgsm_attack,models/libra_rcnn_r101_voc0712/libra_rcnn_r101_voc0712.py,2.5500000000000003,,8.0,models/libra_rcnn_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,libra_rcnn_r101_voc0712
0.008528437586521925,0.526,0.375,0.213,0.791,0.572,0.1129379658994592,6.0,647.7375078201294,1719957042.1234748,0.577,647,media/images/val_img_4_1d720341d75468b8dc34.png,352094.0,image-file,1000.0,png,375.0,1d720341d75468b8dc3471aabd383d4ad47352fca7d6f74566def859746ad172,,,,,,,fgsm_attack,True,none,slurm/results/atss_r50_voc0712/FGSM_epsilon8_alpha51div20_targetedFalse_norminf,data/VOCdevkit/,models/atss_r50_voc0712/epoch_4.pth,INFO,,models/atss_r50_voc0712/atss_r50_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_r50_voc0712,atss_r50_voc0712,fgsm_attack,models/atss_r50_voc0712/atss_r50_voc0712.py,2.5500000000000003,,8.0,models/atss_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,atss_r50_voc0712
0.0084388122254373,0.538,0.395,0.23,0.818,0.575,0.13969041024124698,6.0,771.3291573524475,1719956798.0107474,0.593,770,media/images/val_img_4_a34801c709cccd29eceb.png,355648.0,image-file,1000.0,png,375.0,a34801c709cccd29ecebbe45864b0c6752d410de125ff6dc297eaa8ffe0b743c,,,,,,,fgsm_attack,True,none,slurm/results/fsaf_r101_voc0712/FGSM_epsilon8_alpha51div20_targetedFalse_norminf,data/VOCdevkit/,models/fsaf_r101_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_r101_voc0712/fsaf_r101_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_r101_voc0712,fsaf_r101_voc0712,fgsm_attack,models/fsaf_r101_voc0712/fsaf_r101_voc0712.py,2.5500000000000003,,8.0,models/fsaf_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,fsaf_r101_voc0712
0.009769575056248954,0.143,0.008,0.005,0.275,0.137,0.24634886524447663,6.0,1310.721382379532,1719957230.6754675,0.196,1310,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,fgsm_attack,True,none,slurm/results/fsaf_convnext-b_voc0712/FGSM_epsilon8_alpha51div20_targetedFalse_norminf,data/VOCdevkit/,models/fsaf_convnext-b_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_convnext-b_voc0712/fsaf_convnext-b_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_input,FSAF,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_convnext-b_voc0712,fsaf_convnext-b_voc0712,fgsm_attack,models/fsaf_convnext-b_voc0712/fsaf_convnext-b_voc0712.py,2.5500000000000003,,8.0,models/fsaf_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,fsaf_convnext-b_voc0712
0.01258778639473194,0.508,0.376,0.259,0.821,0.549,0.12602724375302157,6.0,713.6262044906616,1719956402.8893504,0.556,713,media/images/val_img_4_a3fe11967f053b0f16cc.png,356495.0,image-file,1000.0,png,375.0,a3fe11967f053b0f16cc17cad5e5e295ecf33febb6dda6211a73cc9817a349cb,,,,,,,fgsm_attack,True,none,slurm/results/libra_rcnn_r50_voc0712/FGSM_epsilon8_alpha51div20_targetedFalse_norminf,data/VOCdevkit/,models/libra_rcnn_r50_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_r50_voc0712/libra_rcnn_r50_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_r50_voc0712,libra_rcnn_r50_voc0712,fgsm_attack,models/libra_rcnn_r50_voc0712/libra_rcnn_r50_voc0712.py,2.5500000000000003,,8.0,models/libra_rcnn_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,libra_rcnn_r50_voc0712
0.008795727533979317,0.528,0.373,0.208,0.803,0.569,0.10073398349984544,6.0,593.0541527271271,1719955771.9645166,0.58,592,media/images/val_img_4_40898397b2ab74748803.png,354156.0,image-file,1000.0,png,375.0,40898397b2ab747488038adb413dddfd835fffd46e774afbad2e153c7d065825,,,,,,,fgsm_attack,True,none,slurm/results/free_anchor_r50_voc0712/FGSM_epsilon8_alpha51div20_targetedFalse_norminf,data/VOCdevkit/,models/free_anchor_r50_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_r50_voc0712/free_anchor_r50_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_r50_voc0712,free_anchor_r50_voc0712,fgsm_attack,models/free_anchor_r50_voc0712/free_anchor_r50_voc0712.py,2.5500000000000003,,8.0,models/free_anchor_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,free_anchor_r50_voc0712
0.00888708753102528,0.182,0.008,0.006,0.325,0.178,0.25512193704455305,6.0,1363.8298964500427,1719956302.0687163,0.246,1363,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,fgsm_attack,True,none,slurm/results/atss_convnext-b_voc0712/FGSM_epsilon8_alpha51div20_targetedFalse_norminf,data/VOCdevkit/,models/atss_convnext-b_voc0712/epoch_4.pth,INFO,,models/atss_convnext-b_voc0712/atss_convnext-b_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_output,ATSS,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_convnext-b_voc0712,atss_convnext-b_voc0712,fgsm_attack,models/atss_convnext-b_voc0712/atss_convnext-b_voc0712.py,2.5500000000000003,,8.0,models/atss_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,,False,,inf,inf,atss_convnext-b_voc0712
0.010223537653401817,0.25,0.016,0.0,0.458,0.242,0.23834937075617432,6.0,1304.9444432258606,1719955897.5121765,0.343,1304,media/images/val_img_4_aff93266ee46d86b6219.png,399270.0,image-file,1000.0,png,375.0,aff93266ee46d86b6219a37551499686526d9ace92dfde8cf6188e3c41e8a1b4,,,,,,,pgd_attack,True,none,slurm/results/free_anchor_convnext-b_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/VOCdevkit/,models/free_anchor_convnext-b_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_convnext-b_voc0712/free_anchor_convnext-b_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_input,RetinaNet,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_convnext-b_voc0712,free_anchor_convnext-b_voc0712,pgd_attack,models/free_anchor_convnext-b_voc0712/free_anchor_convnext-b_voc0712.py,2.5500000000000003,1.0,8.0,models/free_anchor_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,free_anchor_convnext-b_voc0712
0.008374678638519097,0.557,0.4,0.211,0.825,0.603,0.12903805248862008,6.0,730.0804553031921,1719955058.9127014,0.614,729,media/images/val_img_4_407ff37ca0544ae1d0eb.png,355961.0,image-file,1000.0,png,375.0,407ff37ca0544ae1d0ebbfb90403980a90c2605a23880f31e8689e1b2fa70932,,,,,,,pgd_attack,True,none,slurm/results/free_anchor_r101_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/VOCdevkit/,models/free_anchor_r101_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_r101_voc0712/free_anchor_r101_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_r101_voc0712,free_anchor_r101_voc0712,pgd_attack,models/free_anchor_r101_voc0712/free_anchor_r101_voc0712.py,2.5500000000000003,1.0,8.0,models/free_anchor_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,free_anchor_r101_voc0712
0.010424499581034872,0.554,0.399,0.205,0.809,0.605,0.1450690053434967,6.0,823.1660726070404,1719954471.5805306,0.615,822,media/images/val_img_4_fd669ecd0972c0339522.png,345684.0,image-file,1000.0,png,374.0,fd669ecd0972c033952298d29a298613d5686a0c21c8010cb166db0a03dd1ea9,,,,,,,pgd_attack,True,none,slurm/results/atss_r101_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/VOCdevkit/,models/atss_r101_voc0712/epoch_3.pth,INFO,,models/atss_r101_voc0712/atss_r101_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_r101_voc0712/epoch_3.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_r101_voc0712,atss_r101_voc0712,pgd_attack,models/atss_r101_voc0712/atss_r101_voc0712.py,2.5500000000000003,1.0,8.0,models/atss_r101_voc0712/epoch_3.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,atss_r101_voc0712
0.008432353069968545,0.498,0.352,0.221,0.788,0.525,0.111339540643305,6.0,623.1258671283722,1719954221.9870152,0.548,622,media/images/val_img_4_3df0bdae79397e00143d.png,354204.0,image-file,1000.0,png,375.0,3df0bdae79397e00143de6a4e8925c956bd9c5ac94fd009407c8dfb8341a66d6,,,,,,,pgd_attack,True,none,slurm/results/fsaf_r50_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/VOCdevkit/,models/fsaf_r50_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_r50_voc0712/fsaf_r50_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_r50_voc0712,fsaf_r50_voc0712,pgd_attack,models/fsaf_r50_voc0712/fsaf_r50_voc0712.py,2.5500000000000003,1.0,8.0,models/fsaf_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,fsaf_r50_voc0712
0.00854787531944566,0.102,0.002,0.0,0.245,0.068,0.25336272134555604,6.0,1335.5874345302582,1719954814.9919496,0.137,1335,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,pgd_attack,True,none,slurm/results/libra_rcnn_convnext-b_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/VOCdevkit/,models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_convnext-b_voc0712/libra_rcnn_convnext-b_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_convnext-b_voc0712,libra_rcnn_convnext-b_voc0712,pgd_attack,models/libra_rcnn_convnext-b_voc0712/libra_rcnn_convnext-b_voc0712.py,2.5500000000000003,1.0,8.0,models/libra_rcnn_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,libra_rcnn_convnext-b_voc0712
0.008966857824281277,0.542,0.398,0.24,0.838,0.605,0.1562594700263963,6.0,840.9965960979462,1719954196.3116992,0.593,840,media/images/val_img_4_2ac03c6f1f9def3b8fa1.png,355966.0,image-file,1000.0,png,375.0,2ac03c6f1f9def3b8fa14196a7485b5d6add169b839a52a1366e4fb2ffcf6b9b,,,,,,,pgd_attack,True,none,slurm/results/libra_rcnn_r101_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/VOCdevkit/,models/libra_rcnn_r101_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_r101_voc0712/libra_rcnn_r101_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_r101_voc0712,libra_rcnn_r101_voc0712,pgd_attack,models/libra_rcnn_r101_voc0712/libra_rcnn_r101_voc0712.py,2.5500000000000003,1.0,8.0,models/libra_rcnn_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,libra_rcnn_r101_voc0712
0.008399106747161107,0.526,0.375,0.213,0.791,0.572,0.11620456383441544,6.0,673.0298182964325,1719953177.4070172,0.577,672,media/images/val_img_4_1d720341d75468b8dc34.png,352094.0,image-file,1000.0,png,375.0,1d720341d75468b8dc3471aabd383d4ad47352fca7d6f74566def859746ad172,,,,,,,pgd_attack,True,none,slurm/results/atss_r50_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/VOCdevkit/,models/atss_r50_voc0712/epoch_4.pth,INFO,,models/atss_r50_voc0712/atss_r50_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_output,ATSS,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_r50_voc0712,atss_r50_voc0712,pgd_attack,models/atss_r50_voc0712/atss_r50_voc0712.py,2.5500000000000003,1.0,8.0,models/atss_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,atss_r50_voc0712
0.0340155995833183,0.538,0.395,0.23,0.818,0.575,0.17431606958544474,6.0,1056.878250837326,1719953501.0972707,0.593,1056,media/images/val_img_4_a34801c709cccd29eceb.png,355648.0,image-file,1000.0,png,375.0,a34801c709cccd29ecebbe45864b0c6752d410de125ff6dc297eaa8ffe0b743c,,,,,,,pgd_attack,True,none,slurm/results/fsaf_r101_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/VOCdevkit/,models/fsaf_r101_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_r101_voc0712/fsaf_r101_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_r101_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,FSAF,,ResNet,,Pretrained,,torchvision://resnet101,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_r101_voc0712,fsaf_r101_voc0712,pgd_attack,models/fsaf_r101_voc0712/fsaf_r101_voc0712.py,2.5500000000000003,1.0,8.0,models/fsaf_r101_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,101.0,pytorch,BN,True,True,4.0,1.0,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,fsaf_r101_voc0712
0.008623459304002422,0.143,0.008,0.005,0.275,0.137,0.2497510017589105,6.0,1321.7302465438845,1719953462.3268783,0.196,1321,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,pgd_attack,True,none,slurm/results/fsaf_convnext-b_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/VOCdevkit/,models/fsaf_convnext-b_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/fsaf_convnext-b_voc0712/fsaf_convnext-b_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/fsaf_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_input,FSAF,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.5,1000.0,0.05,100.0,0.0,FSAFHead,,IoULoss,1.0,TBLRBBoxCoder,,,256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",1.0,1.0,False,PseudoSampler,CenterRegionAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,fsaf_convnext-b_voc0712,fsaf_convnext-b_voc0712,pgd_attack,models/fsaf_convnext-b_voc0712/fsaf_convnext-b_voc0712.py,2.5500000000000003,1.0,8.0,models/fsaf_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,10.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,,,,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,none,1e-06,none,4.0,0.2,0.2,0.01,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,fsaf_convnext-b_voc0712
0.008372355730105668,0.508,0.376,0.259,0.821,0.549,0.11493949815044252,6.0,641.820858001709,1719952659.235834,0.556,641,media/images/val_img_4_a3fe11967f053b0f16cc.png,356495.0,image-file,1000.0,png,375.0,a3fe11967f053b0f16cc17cad5e5e295ecf33febb6dda6211a73cc9817a349cb,,,,,,,pgd_attack,True,none,slurm/results/libra_rcnn_r50_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/VOCdevkit/,models/libra_rcnn_r50_voc0712/epoch_4.pth,INFO,,models/libra_rcnn_r50_voc0712/libra_rcnn_r50_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/libra_rcnn_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",,,,,,,FasterRCNN,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,libra_rcnn_r50_voc0712,libra_rcnn_r50_voc0712,pgd_attack,models/libra_rcnn_r50_voc0712/libra_rcnn_r50_voc0712.py,2.5500000000000003,1.0,8.0,models/libra_rcnn_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.02,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,StandardRoIHead,,,SingleRoIExtractor,RoIAlign,7.0,0.0,256.0,"[4, 8, 16, 32]",,RPNHead,CrossEntropyLoss,1.0,True,,L1Loss,1.0,DeltaXYWHBBoxCoder,"[1, 1, 1, 1]","[0, 0, 0, 0]",256.0,256.0,AnchorGenerator,"[0.5, 1, 2]",[8],"[4, 8, 16, 32, 64]",nms,0.7,1000.0,1000.0,0.0,nms,0.5,0.05,100.0,False,256.0,RandomSampler,5.0,0.5,False,MaxIoUAssigner,0.3,0.3,0.7,-1.0,True,-1.0,-1.0,,nms,0.7,2000.0,1000.0,0.0,,,,,,,,,,,,,,,,,,,,,,,,,Shared2FCBBoxHead,CrossEntropyLoss,1.0,False,1.0,BalancedL1Loss,1.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,7.0,1024.0,False,False,512.0,CombinedSampler,,0.25,True,MaxIoUAssigner,0.5,0.5,0.5,-1.0,False,-1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,"[{'type': 'FPN', 'num_outs': 5, 'in_channels': [256, 512, 1024, 2048], 'out_channels': 256}, {'type': 'BFP', 'num_levels': 5, 'in_channels': 256, 'refine_type': 'non_local', 'refine_level': 2}]",0.5,1.5,IoUBalancedNegSampler,3.0,-1.0,0.0,InstanceBalancedPosSampler,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,libra_rcnn_r50_voc0712
0.029246646419766213,0.528,0.373,0.208,0.803,0.569,0.12918103205755746,6.0,819.9696707725525,1719951917.1336188,0.58,818,media/images/val_img_4_40898397b2ab74748803.png,354156.0,image-file,1000.0,png,375.0,40898397b2ab747488038adb413dddfd835fffd46e774afbad2e153c7d065825,,,,,,,pgd_attack,True,none,slurm/results/free_anchor_r50_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/VOCdevkit/,models/free_anchor_r50_voc0712/epoch_4.pth,INFO,"[[1333, 800], [666, 400], [2000, 1200]]",models/free_anchor_r50_voc0712/free_anchor_r50_voc0712.py,,CocoDataset,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'TestTimeAug', 'transforms': [[{'type': 'Resize', 'scale': [1333, 800], 'keep_ratio': True}, {'type': 'Resize', 'scale': [666, 400], 'keep_ratio': True}, {'type': 'Resize', 'scale': [2000, 1200], 'keep_ratio': True}], [{'prob': 1, 'type': 'RandomFlip'}, {'prob': 0, 'type': 'RandomFlip'}], [{'type': 'LoadAnnotations', 'with_bbox': True}], [{'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor', 'flip', 'flip_direction']}]]}]",[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/free_anchor_r50_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024, 2048]",1.0,256.0,on_input,RetinaNet,,ResNet,,Pretrained,,torchvision://resnet50,"[0, 1, 2, 3]",,,,nms,0.5,1000.0,0.05,100.0,0.0,FreeAnchorRetinaHead,0.11,SmoothL1Loss,0.75,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,"[0.5, 1, 2]","[8, 16, 32, 64, 128]",4.0,3.0,False,PseudoSampler,MaxIoUAssigner,0.0,0.4,0.5,-1.0,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,DetTTAModel,nms,0.5,100.0,visualizer,DetLocalVisualizer,WandbVisBackend,free_anchor_r50_voc0712,free_anchor_r50_voc0712,pgd_attack,models/free_anchor_r50_voc0712/free_anchor_r50_voc0712.py,2.5500000000000003,1.0,8.0,models/free_anchor_r50_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,35.0,2.0,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,50.0,pytorch,BN,True,True,4.0,1.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,free_anchor_r50_voc0712
0.029327591188069956,0.182,0.008,0.006,0.325,0.178,0.28198439979129625,6.0,1602.7362034320831,1719952378.5676334,0.246,1601,media/images/val_img_4_122bf584072db47bb36a.png,355597.0,image-file,1000.0,png,375.0,122bf584072db47bb36a9b24a34595a4aecb33be197a7da84916082b725f5256,,,,,,,pgd_attack,True,none,slurm/results/atss_convnext-b_voc0712/PGD_epsilon8_alpha51div20_targetedFalse_steps1_random_startFalse,data/VOCdevkit/,models/atss_convnext-b_voc0712/epoch_4.pth,INFO,,models/atss_convnext-b_voc0712/atss_convnext-b_voc0712.py,,CocoDataset,,[{'type': 'LocalVisBackend'}],mmdet,"[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",models/atss_convnext-b_voc0712/epoch_4.pth,"[{'end': 166, 'type': 'LinearLR', 'begin': 0, 'by_epoch': False, 'start_factor': 0.001}, {'end': 4, 'type': 'MultiStepLR', 'begin': 0, 'gamma': 0.1, 'by_epoch': True, 'milestones': [2, 3]}]",FPN,5.0,"[256, 512, 1024]",1.0,256.0,on_output,ATSS,base,mmpretrain.ConvNeXt,True,Pretrained,backbone.,https://download.openmmlab.com/mmclassification/v0/convnext/convnext-base_in21k-pre-3rdparty_in1k-384px_20221219-4570f792.pth,"[1, 2, 3]",0.7,False,1.0,nms,0.6,1000.0,0.05,100.0,0.0,ATSSHead,,GIoULoss,2.0,DeltaXYWHBBoxCoder,"[0.1, 0.1, 0.2, 0.2]","[0, 0, 0, 0]",256.0,20.0,256.0,4.0,AnchorGenerator,[1],"[8, 16, 32, 64, 128]",8.0,1.0,False,,ATSSAssigner,,,,,-1.0,-1.0,"[58.395, 57.12, 57.375]","[123.675, 116.28, 103.53]",DetDataPreprocessor,True,32.0,fork,0.0,nccl,False,ValLoop,TestLoop,EpochBasedTrainLoop,4.0,1.0,,,,,visualizer,DetLocalVisualizer,WandbVisBackend,atss_convnext-b_voc0712,atss_convnext-b_voc0712,pgd_attack,models/atss_convnext-b_voc0712/atss_convnext-b_voc0712.py,2.5500000000000003,1.0,8.0,models/atss_convnext-b_voc0712/epoch_4.pth,846186413151,attacks,2.5500000000000003,1.0,8.0,True,16.0,IterTimerHook,LoggerHook,50.0,CheckpointHook,1.0,DistSamplerSeedHook,True,DetVisualizationHook,1000.0,ParamSchedulerHook,LogProcessor,True,50.0,OptimWrapper,,,0.01,SGD,0.9,0.0001,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoMetric,bbox,data/VOCdevkit/voc_coco_fmt_annotations/voc07_test.json,False,,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,CocoDataset,voc_coco_fmt_annotations/voc07_test.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'PackDetInputs', 'meta_keys': ['img_id', 'img_path', 'ori_shape', 'img_shape', 'scale_factor']}]",data/VOCdevkit/,,1.0,RepeatDataset,3.0,CocoDataset,voc_coco_fmt_annotations/voc0712_trainval.json,"['aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor']","[[106, 0, 228], [119, 11, 32], [165, 42, 42], [0, 0, 192], [197, 226, 255], [0, 60, 100], [0, 0, 142], [255, 77, 255], [153, 69, 1], [120, 166, 157], [0, 182, 199], [0, 226, 252], [182, 182, 255], [0, 0, 230], [220, 20, 60], [163, 255, 0], [0, 82, 0], [3, 95, 161], [0, 80, 100], [183, 130, 88]]","[{'type': 'LoadImageFromFile', 'backend_args': None}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'Resize', 'scale': [1000, 600], 'keep_ratio': True}, {'prob': 0.5, 'type': 'RandomFlip'}, {'type': 'PackDetInputs'}]",data/VOCdevkit/,32.0,True,,,2.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,FocalLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,0.25,2.0,,CrossEntropyLoss,1.0,True,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,9.0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,False,False,False,False,,,atss_convnext-b_voc0712
